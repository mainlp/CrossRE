{"doc_key": "ai-dev-1", "ner": [[2, 2, "metrics"], [7, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 11, 2, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Here", ",", "accuracy", "is", "measured", "by", "the", "error", "rate", ",", "defined", "as", ":"], "sentence-detokenized": "Here, accuracy is measured by the error rate, defined as:", "token2charspan": [[0, 4], [4, 5], [6, 14], [15, 17], [18, 26], [27, 29], [30, 33], [34, 39], [40, 44], [44, 45], [46, 53], [54, 56], [56, 57]]}
{"doc_key": "ai-dev-2", "ner": [[4, 4, "algorithm"], [11, 13, "misc"], [15, 18, "algorithm"], [16, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 11, 13, "type-of", "", false, false], [4, 4, 15, 18, "related-to", "", false, false], [4, 4, 16, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "this", "respect", ",", "SVM", "is", "closely", "related", "to", "other", "fundamental", "classification", "algorithms", "such", "as", "regularised", "logistic", "least", "squares", "regression", "."], "sentence-detokenized": "In this respect, SVM is closely related to other fundamental classification algorithms such as regularised logistic least squares regression.", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 20], [21, 23], [24, 31], [32, 39], [40, 42], [43, 48], [49, 60], [61, 75], [76, 86], [87, 91], [92, 94], [95, 106], [107, 115], [116, 121], [122, 129], [130, 140], [140, 141]]}
{"doc_key": "ai-dev-3", "ner": [[0, 1, "person"], [3, 4, "person"], [14, 15, "person"], [17, 17, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 0, 1, "named", "actor_plays_character", false, false], [3, 4, 0, 1, "origin", "actor_plays_character", false, false], [17, 17, 14, 15, "named", "actor_plays_character", false, false], [17, 17, 14, 15, "origin", "actor_plays_character", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Brion", "James", "portrays", "Leon", "Kowalski", ",", "a", "replicant", "for", "combat", "and", "work", ",", "and", "Joanna", "Cassidy", "portrays", "Zhora", ",", "a", "replicant", "killer", "."], "sentence-detokenized": "Brion James portrays Leon Kowalski, a replicant for combat and work, and Joanna Cassidy portrays Zhora, a replicant killer.", "token2charspan": [[0, 5], [6, 11], [12, 20], [21, 25], [26, 34], [34, 35], [36, 37], [38, 47], [48, 51], [52, 58], [59, 62], [63, 67], [67, 68], [69, 72], [73, 79], [80, 87], [88, 96], [97, 102], [102, 103], [104, 105], [106, 115], [116, 122], [122, 123]]}
{"doc_key": "ai-dev-4", "ner": [[15, 18, "product"], [20, 20, "product"], [23, 23, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 18, 23, 23, "physical", "", false, false], [20, 20, 15, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "image", "scanned", ",", "stored", "and", "recreated", "in", "digital", "pixels", "was", "displayed", "on", "the", "Standard", "Eastern", "Automated", "Computer", "(", "SEAC", ")", "at", "NIST", "."], "sentence-detokenized": "The first image scanned, stored and recreated in digital pixels was displayed on the Standard Eastern Automated Computer (SEAC) at NIST.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [23, 24], [25, 31], [32, 35], [36, 45], [46, 48], [49, 56], [57, 63], [64, 67], [68, 77], [78, 80], [81, 84], [85, 93], [94, 101], [102, 111], [112, 120], [121, 122], [122, 126], [126, 127], [128, 130], [131, 135], [135, 136]]}
{"doc_key": "ai-dev-5", "ner": [[0, 6, "task"], [20, 21, "task"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 6, 20, 21, "part-of", "", false, false], [0, 6, 23, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Segmenting", "text", "into", "topics", "or", "discourse", "turns", "can", "be", "useful", "for", "some", "natural", "processing", "tasks", ":", "it", "can", "significantly", "improve", "information", "retrieval", "or", "speech", "recognition", "(", "by", "indexing", "/", "recognising", "documents", "more", "accurately", ",", "or", "by", "giving", "a", "specific", "part", "of", "the", "document", "relevant", "to", "the", "query", "as", "a", "result", ")", "."], "sentence-detokenized": "Segmenting text into topics or discourse turns can be useful for some natural processing tasks: it can significantly improve information retrieval or speech recognition (by indexing/recognising documents more accurately, or by giving a specific part of the document relevant to the query as a result).", "token2charspan": [[0, 10], [11, 15], [16, 20], [21, 27], [28, 30], [31, 40], [41, 46], [47, 50], [51, 53], [54, 60], [61, 64], [65, 69], [70, 77], [78, 88], [89, 94], [94, 95], [96, 98], [99, 102], [103, 116], [117, 124], [125, 136], [137, 146], [147, 149], [150, 156], [157, 168], [169, 170], [170, 172], [173, 181], [181, 182], [182, 193], [194, 203], [204, 208], [209, 219], [219, 220], [221, 223], [224, 226], [227, 233], [234, 235], [236, 244], [245, 249], [250, 252], [253, 256], [257, 265], [266, 274], [275, 277], [278, 281], [282, 287], [288, 290], [291, 292], [293, 299], [299, 300], [300, 301]]}
{"doc_key": "ai-dev-6", "ner": [[7, 8, "university"], [23, 27, "conference"], [20, 22, "university"], [33, 34, "researcher"], [36, 37, "researcher"], [39, 40, "researcher"], [42, 43, "researcher"], [45, 46, "researcher"], [48, 49, "researcher"], [51, 53, "researcher"], [55, 56, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[23, 27, 20, 22, "physical", "", false, false], [33, 34, 23, 27, "physical", "", false, false], [33, 34, 23, 27, "role", "", false, false], [33, 34, 23, 27, "temporal", "", false, false], [36, 37, 23, 27, "physical", "", false, false], [36, 37, 23, 27, "role", "", false, false], [36, 37, 23, 27, "temporal", "", false, false], [39, 40, 23, 27, "physical", "", false, false], [39, 40, 23, 27, "role", "", false, false], [39, 40, 23, 27, "temporal", "", false, false], [42, 43, 23, 27, "physical", "", false, false], [42, 43, 23, 27, "role", "", false, false], [42, 43, 23, 27, "temporal", "", false, false], [45, 46, 23, 27, "physical", "", false, false], [45, 46, 23, 27, "role", "", false, false], [45, 46, 23, 27, "temporal", "", false, false], [48, 49, 23, 27, "physical", "", false, false], [48, 49, 23, 27, "role", "", false, false], [48, 49, 23, 27, "temporal", "", false, false], [51, 53, 23, 27, "physical", "", false, false], [51, 53, 23, 27, "role", "", false, false], [51, 53, 23, 27, "temporal", "", false, false], [55, 56, 23, 27, "physical", "", false, false], [55, 56, 23, 27, "role", "", false, false], [55, 56, 23, 27, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "sentence": ["In", "1999", "he", "organised", "a", "symposium", "at", "Indiana", "University", ",", "and", "in", "April", "2000", "he", "organised", "a", "larger", "symposium", "at", "Stanford", "University", "entitled", "Spiritual", "Robots", ",", "where", "he", "chaired", "a", "panel", "consisting", "of", "Ray", "Kurzweil", ",", "Hans", "Moravec", ",", "Kevin", "Kelly", ",", "Ralph", "Merkle", ",", "Bill", "Joy", ",", "Frank", "Drake", ",", "John", "Henry", "Holland", "and", "John", "Koza", "."], "sentence-detokenized": "In 1999 he organised a symposium at Indiana University, and in April 2000 he organised a larger symposium at Stanford University entitled Spiritual Robots, where he chaired a panel consisting of Ray Kurzweil, Hans Moravec, Kevin Kelly, Ralph Merkle, Bill Joy, Frank Drake, John Henry Holland and John Koza.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 20], [21, 22], [23, 32], [33, 35], [36, 43], [44, 54], [54, 55], [56, 59], [60, 62], [63, 68], [69, 73], [74, 76], [77, 86], [87, 88], [89, 95], [96, 105], [106, 108], [109, 117], [118, 128], [129, 137], [138, 147], [148, 154], [154, 155], [156, 161], [162, 164], [165, 172], [173, 174], [175, 180], [181, 191], [192, 194], [195, 198], [199, 207], [207, 208], [209, 213], [214, 221], [221, 222], [223, 228], [229, 234], [234, 235], [236, 241], [242, 248], [248, 249], [250, 254], [255, 258], [258, 259], [260, 265], [266, 271], [271, 272], [273, 277], [278, 283], [284, 291], [292, 295], [296, 300], [301, 305], [305, 306]]}
{"doc_key": "ai-dev-7", "ner": [[9, 9, "metrics"], [10, 10, "metrics"], [13, 13, "metrics"], [14, 14, "metrics"], [19, 19, "metrics"], [39, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 9, 19, 19, "named", "", false, false], [10, 10, 9, 9, "named", "", false, false], [13, 13, 39, 39, "named", "", false, false], [14, 14, 13, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "calculation", "of", "the", "score", "takes", "into", "account", "the", "precision", "p", "and", "the", "recall", "r", "of", "the", "test", ":", "p", "is", "the", "number", "of", "correct", "positives", "divided", "by", "the", "number", "of", "total", "positives", "returned", "by", "the", "classifier", ",", "and", "r", "is", "the", "number", "of", "correct", "positives", "divided", "by", "the", "number", "of", "total", "relevant", "samples", "(", "all", "samples", "that", "should", "have", "been", "recognised", "as", "positive", ")", "."], "sentence-detokenized": "The calculation of the score takes into account the precision p and the recall r of the test: p is the number of correct positives divided by the number of total positives returned by the classifier, and r is the number of correct positives divided by the number of total relevant samples (all samples that should have been recognised as positive).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 22], [23, 28], [29, 34], [35, 39], [40, 47], [48, 51], [52, 61], [62, 63], [64, 67], [68, 71], [72, 78], [79, 80], [81, 83], [84, 87], [88, 92], [92, 93], [94, 95], [96, 98], [99, 102], [103, 109], [110, 112], [113, 120], [121, 130], [131, 138], [139, 141], [142, 145], [146, 152], [153, 155], [156, 161], [162, 171], [172, 180], [181, 183], [184, 187], [188, 198], [198, 199], [200, 203], [204, 205], [206, 208], [209, 212], [213, 219], [220, 222], [223, 230], [231, 240], [241, 248], [249, 251], [252, 255], [256, 262], [263, 265], [266, 271], [272, 280], [281, 288], [289, 290], [290, 293], [294, 301], [302, 306], [307, 313], [314, 318], [319, 323], [324, 334], [335, 337], [338, 346], [346, 347], [347, 348]]}
{"doc_key": "ai-dev-8", "ner": [[4, 6, "organisation"], [22, 24, "product"], [28, 31, "person"], [35, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 22, 24, "artifact", "", false, false], [22, 24, 28, 31, "win-defeat", "", false, false], [22, 24, 35, 35, "win-defeat", "", true, false], [28, 31, 35, 35, "win-defeat", "lose", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "the", "acquisition", "of", "Google", ",", "the", "company", "has", "made", "a", "number", "of", "significant", "achievements", ",", "perhaps", "most", "notably", "the", "creation", "of", "AlphaGo", ",", "which", "defeated", "world", "champion", "Lee", "Sedol", "in", "the", "tricky", "game", "of", "Go", "."], "sentence-detokenized": "Since the acquisition of Google, the company has made a number of significant achievements, perhaps most notably the creation of AlphaGo, which defeated world champion Lee Sedol in the tricky game of Go.", "token2charspan": [[0, 5], [6, 9], [10, 21], [22, 24], [25, 31], [31, 32], [33, 36], [37, 44], [45, 48], [49, 53], [54, 55], [56, 62], [63, 65], [66, 77], [78, 90], [90, 91], [92, 99], [100, 104], [105, 112], [113, 116], [117, 125], [126, 128], [129, 136], [136, 137], [138, 143], [144, 152], [153, 158], [159, 167], [168, 171], [172, 177], [178, 180], [181, 184], [185, 191], [192, 196], [197, 199], [200, 202], [202, 203]]}
{"doc_key": "ai-dev-9", "ner": [[14, 15, "misc"], [26, 27, "field"], [28, 30, "product"], [47, 49, "misc"], [52, 53, "misc"], [56, 56, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 15, 26, 27, "part-of", "", false, false], [14, 15, 52, 53, "named", "same", false, false], [28, 30, 47, 49, "related-to", "", false, false], [28, 30, 52, 53, "usage", "", false, false], [28, 30, 56, 56, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Representing", "words", "with", "respect", "to", "their", "context", "using", "dense", "fixed", "-", "size", "vectors", "(", "word", "embeddings", ")", "has", "become", "one", "of", "the", "building", "blocks", "in", "several", "NLP", "systems.The", "unsupervised", "disambiguation", "system", "uses", "the", "similarity", "between", "word", "meanings", "in", "a", "fixed", "context", "window", "to", "select", "the", "most", "appropriate", "word", "meaning", "using", "a", "pre-trained", "word", "embedding", "model", "and", "WordNet", "."], "sentence-detokenized": "Representing words with respect to their context using dense fixed-size vectors (word embeddings) has become one of the building blocks in several NLP systems.The unsupervised disambiguation system uses the similarity between word meanings in a fixed context window to select the most appropriate word meaning using a pre-trained word embedding model and WordNet.", "token2charspan": [[0, 12], [13, 18], [19, 23], [24, 31], [32, 34], [35, 40], [41, 48], [49, 54], [55, 60], [61, 66], [66, 67], [67, 71], [72, 79], [80, 81], [81, 85], [86, 96], [96, 97], [98, 101], [102, 108], [109, 112], [113, 115], [116, 119], [120, 128], [129, 135], [136, 138], [139, 146], [147, 150], [151, 162], [163, 175], [176, 190], [191, 197], [198, 202], [203, 206], [207, 217], [218, 225], [226, 230], [231, 239], [240, 242], [243, 244], [245, 250], [251, 258], [259, 265], [266, 268], [269, 275], [276, 279], [280, 284], [285, 296], [297, 301], [302, 309], [310, 315], [316, 317], [318, 329], [330, 334], [335, 344], [345, 350], [351, 354], [355, 362], [362, 363]]}
{"doc_key": "ai-dev-10", "ner": [[0, 2, "field"], [5, 6, "field"], [8, 17, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 0, 2, "part-of", "", false, false], [8, 17, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "techniques", ",", "either", "supervised", "learning", "or", "unsupervised", "learning", ",", "are", "used", "to", "automatically", "create", "such", "rules", "."], "sentence-detokenized": "Machine learning techniques, either supervised learning or unsupervised learning, are used to automatically create such rules.", "token2charspan": [[0, 7], [8, 16], [17, 27], [27, 28], [29, 35], [36, 46], [47, 55], [56, 58], [59, 71], [72, 80], [80, 81], [82, 85], [86, 90], [91, 93], [94, 107], [108, 114], [115, 119], [120, 125], [125, 126]]}
{"doc_key": "ai-dev-11", "ner": [[3, 3, "researcher"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1969", ",", "Scheinman", "invented", "the", "Stanford", "Arm", ","], "sentence-detokenized": "In 1969, Scheinman invented the Stanford Arm,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 27], [28, 31], [32, 40], [41, 44], [44, 45]]}
{"doc_key": "ai-dev-12", "ner": [[2, 3, "metrics"], [8, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Since", "the", "Log", "loss", "is", "differential", ",", "a", "gradient", "-", "based", "method", "can", "be", "used", "to", "optimise", "the", "model", "."], "sentence-detokenized": "Since the Log loss is differential, a gradient-based method can be used to optimise the model.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 18], [19, 21], [22, 34], [34, 35], [36, 37], [38, 46], [46, 47], [47, 52], [53, 59], [60, 63], [64, 66], [67, 71], [72, 74], [75, 83], [84, 87], [88, 93], [93, 94]]}
{"doc_key": "ai-dev-13", "ner": [[1, 2, "field"], [4, 6, "algorithm"], [8, 8, "algorithm"], [11, 13, "algorithm"], [16, 17, "field"], [27, 27, "task"], [29, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 6, 16, 17, "part-of", "", false, false], [8, 8, 4, 6, "named", "", false, false], [11, 13, 4, 6, "named", "", false, false], [16, 17, 1, 2, "part-of", "subfield", false, false], [27, 27, 16, 17, "part-of", "", false, false], [29, 30, 16, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "machine", "learning", ",", "support", "vector", "machines", "(", "SVMs", ",", "also", "support", "vector", "networks", ")", "are", "supervised", "learning", "models", "with", "learning", "algorithms", "that", "analyse", "data", "used", "for", "classification", "and", "regression", "analysis", "."], "sentence-detokenized": "In machine learning, support vector machines (SVMs, also support vector networks) are supervised learning models with learning algorithms that analyse data used for classification and regression analysis.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 28], [29, 35], [36, 44], [45, 46], [46, 50], [50, 51], [52, 56], [57, 64], [65, 71], [72, 80], [80, 81], [82, 85], [86, 96], [97, 105], [106, 112], [113, 117], [118, 126], [127, 137], [138, 142], [143, 150], [151, 155], [156, 160], [161, 164], [165, 179], [180, 183], [184, 194], [195, 203], [203, 204]]}
{"doc_key": "ai-dev-14", "ner": [[9, 10, "task"], [12, 12, "task"], [29, 29, "metrics"], [31, 31, "metrics"], [33, 33, "researcher"], [35, 35, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 12, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "2002", ")", "as", "an", "automatic", "metric", "for", "evaluating", "machine", "translation", "(", "MT", ")", ",", "many", "other", "methods", "have", "been", "proposed", "to", "revise", "or", "improve", "it", ",", "such", "as", "TER", ",", "METEOR", ",", "Banerjee", "and", "Lavie", ",", "(", "2005", ")", ",", "etc", "."], "sentence-detokenized": "(2002) as an automatic metric for evaluating machine translation (MT), many other methods have been proposed to revise or improve it, such as TER, METEOR, Banerjee and Lavie, (2005), etc.", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 9], [10, 12], [13, 22], [23, 29], [30, 33], [34, 44], [45, 52], [53, 64], [65, 66], [66, 68], [68, 69], [69, 70], [71, 75], [76, 81], [82, 89], [90, 94], [95, 99], [100, 108], [109, 111], [112, 118], [119, 121], [122, 129], [130, 132], [132, 133], [134, 138], [139, 141], [142, 145], [145, 146], [147, 153], [153, 154], [155, 163], [164, 167], [168, 173], [173, 174], [175, 176], [176, 180], [180, 181], [181, 182], [183, 186], [186, 187]]}
{"doc_key": "ai-dev-15", "ner": [[3, 6, "misc"], [8, 8, "organisation"], [9, 9, "organisation"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 9, 9, "origin", "", false, false], [9, 9, 8, 8, "part-of", "", false, false], [14, 15, 9, 9, "role", "", false, false], [17, 18, 9, 9, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "includes", "the", "above", "ontology", "created", "by", "the", "IEEE", "P1600.1", "working", "group", "(", "authors", "Ian", "Niles", "and", "Adam", "Pease", ")", "."], "sentence-detokenized": "It includes the above ontology created by the IEEE P1600.1 working group (authors Ian Niles and Adam Pease).", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 21], [22, 30], [31, 38], [39, 41], [42, 45], [46, 50], [51, 58], [59, 66], [67, 72], [73, 74], [74, 81], [82, 85], [86, 91], [92, 95], [96, 100], [101, 106], [106, 107], [107, 108]]}
{"doc_key": "ai-dev-16", "ner": [[1, 5, "misc"], [31, 33, "algorithm"], [35, 38, "algorithm"], [39, 42, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[31, 33, 1, 5, "part-of", "", true, false], [35, 38, 1, 5, "part-of", "", true, false], [39, 42, 35, 38, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "cryoelectron", "tomography", ",", "where", "a", "limited", "number", "of", "projections", "are", "acquired", "due", "to", "hardware", "limitations", "and", "to", "avoid", "damage", "to", "biological", "samples", ",", "it", "can", "be", "used", "in", "conjunction", "with", "compression", "detection", "techniques", "or", "regularisation", "functions", "(", "e.g.", "Huber", "loss", ")", "to", "improve", "reconstruction", "for", "better", "interpretation", "."], "sentence-detokenized": "In cryoelectron tomography, where a limited number of projections are acquired due to hardware limitations and to avoid damage to biological samples, it can be used in conjunction with compression detection techniques or regularisation functions (e.g. Huber loss) to improve reconstruction for better interpretation.", "token2charspan": [[0, 2], [3, 15], [16, 26], [26, 27], [28, 33], [34, 35], [36, 43], [44, 50], [51, 53], [54, 65], [66, 69], [70, 78], [79, 82], [83, 85], [86, 94], [95, 106], [107, 110], [111, 113], [114, 119], [120, 126], [127, 129], [130, 140], [141, 148], [148, 149], [150, 152], [153, 156], [157, 159], [160, 164], [165, 167], [168, 179], [180, 184], [185, 196], [197, 206], [207, 217], [218, 220], [221, 235], [236, 245], [246, 247], [247, 251], [252, 257], [258, 262], [262, 263], [264, 266], [267, 274], [275, 289], [290, 293], [294, 300], [301, 315], [315, 316]]}
{"doc_key": "ai-dev-17", "ner": [[1, 1, "misc"], [4, 4, "programlang"], [7, 10, "algorithm"], [9, 13, "algorithm"], [14, 19, "algorithm"], [21, 23, "product"], [26, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 1, 4, 4, "part-of", "", false, false], [7, 10, 1, 1, "type-of", "", false, false], [9, 13, 1, 1, "type-of", "", false, false], [14, 19, 1, 1, "type-of", "", false, false], [21, 23, 4, 4, "general-affiliation", "", true, false], [21, 23, 4, 4, "part-of", "", true, false], [26, 26, 21, 23, "role", "publishes", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Several", "whitening", "procedures", "in", "R", ",", "including", "ZCA", "and", "PCA", "whitening", "as", "well", "as", "CCA", "whitening", ",", "are", "available", "in", "the", "whitening", "R", "package", "published", "on", "CRAN", "."], "sentence-detokenized": "Several whitening procedures in R, including ZCA and PCA whitening as well as CCA whitening, are available in the whitening R package published on CRAN.", "token2charspan": [[0, 7], [8, 17], [18, 28], [29, 31], [32, 33], [33, 34], [35, 44], [45, 48], [49, 52], [53, 56], [57, 66], [67, 69], [70, 74], [75, 77], [78, 81], [82, 91], [91, 92], [93, 96], [97, 106], [107, 109], [110, 113], [114, 123], [124, 125], [126, 133], [134, 143], [144, 146], [147, 151], [151, 152]]}
{"doc_key": "ai-dev-18", "ner": [[31, 31, "product"], [33, 33, "product"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [41, 41, "product"], [44, 45, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[31, 31, 35, 35, "compare", "", false, false], [31, 31, 37, 37, "compare", "", false, false], [31, 31, 39, 39, "compare", "", false, false], [31, 31, 41, 41, "compare", "", false, false], [31, 31, 44, 45, "compare", "", false, false], [33, 33, 35, 35, "compare", "", false, false], [33, 33, 37, 37, "compare", "", false, false], [33, 33, 39, 39, "compare", "", false, false], [33, 33, 41, 41, "compare", "", false, false], [33, 33, 44, 45, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Today", ",", "the", "field", "has", "become", "even", "more", "challenging", "and", "complex", ",", "with", "languages", "and", "software", "available", "for", "the", "analysis", "and", "design", "of", "circuits", ",", "systems", "and", "signals", ",", "ranging", "from", "MATLAB", "and", "Simulink", "to", "NumPy", ",", "VHDL", ",", "PSpice", ",", "Verilog", "and", "even", "Assembly", "language", "."], "sentence-detokenized": "Today, the field has become even more challenging and complex, with languages and software available for the analysis and design of circuits, systems and signals, ranging from MATLAB and Simulink to NumPy, VHDL, PSpice, Verilog and even Assembly language.", "token2charspan": [[0, 5], [5, 6], [7, 10], [11, 16], [17, 20], [21, 27], [28, 32], [33, 37], [38, 49], [50, 53], [54, 61], [61, 62], [63, 67], [68, 77], [78, 81], [82, 90], [91, 100], [101, 104], [105, 108], [109, 117], [118, 121], [122, 128], [129, 131], [132, 140], [140, 141], [142, 149], [150, 153], [154, 161], [161, 162], [163, 170], [171, 175], [176, 182], [183, 186], [187, 195], [196, 198], [199, 204], [204, 205], [206, 210], [210, 211], [212, 218], [218, 219], [220, 227], [228, 231], [232, 236], [237, 245], [246, 254], [254, 255]]}
{"doc_key": "ai-dev-19", "ner": [[7, 10, "person"], [14, 16, "person"], [17, 20, "organisation"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[17, 20, 14, 16, "origin", "", false, false], [23, 23, 17, 20, "artifact", "builds", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "company", "was", "founded", "in", "1937", "by", "Kiichiro", "Toyoda", "as", "a", "separate", "company", "from", "Sakichi", "Toyoda", "'s", "Toyota", "Industries", "for", "the", "production", "of", "cars", "."], "sentence-detokenized": "The company was founded in 1937 by Kiichiro Toyoda as a separate company from Sakichi Toyoda's Toyota Industries for the production of cars.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 26], [27, 31], [32, 34], [35, 43], [44, 50], [51, 53], [54, 55], [56, 64], [65, 72], [73, 77], [78, 85], [86, 92], [92, 94], [95, 101], [102, 112], [113, 116], [117, 120], [121, 131], [132, 134], [135, 139], [139, 140]]}
{"doc_key": "ai-dev-20", "ner": [[0, 6, "field"], [57, 60, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[57, 60, 0, 6, "origin", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Unsupervised", "learning", ",", "on", "the", "other", "hand", ",", "is", "based", "on", "training", "data", "that", "has", "not", "been", "manually", "labelled", ",", "and", "tries", "to", "find", "internal", "patterns", "in", "the", "data", "that", "can", "be", "used", "to", "determine", "the", "correct", "output", "value", "for", "new", "instances", "of", "the", "data", ".", "A", "combination", "of", "the", "two", "that", "has", "recently", "been", "explored", "is", "semi-supervised", "learning", ",", "which", "uses", "a", "combination", "of", "labelled", "and", "unlabelled", "data", "(", "usually", "a", "small", "set", "of", "labelled", "data", "combined", "with", "a", "large", "amount", "of", "unlabelled", "data", ")", "."], "sentence-detokenized": "Unsupervised learning, on the other hand, is based on training data that has not been manually labelled, and tries to find internal patterns in the data that can be used to determine the correct output value for new instances of the data. A combination of the two that has recently been explored is semi-supervised learning, which uses a combination of labelled and unlabelled data (usually a small set of labelled data combined with a large amount of unlabelled data).", "token2charspan": [[0, 12], [13, 21], [21, 22], [23, 25], [26, 29], [30, 35], [36, 40], [40, 41], [42, 44], [45, 50], [51, 53], [54, 62], [63, 67], [68, 72], [73, 76], [77, 80], [81, 85], [86, 94], [95, 103], [103, 104], [105, 108], [109, 114], [115, 117], [118, 122], [123, 131], [132, 140], [141, 143], [144, 147], [148, 152], [153, 157], [158, 161], [162, 164], [165, 169], [170, 172], [173, 182], [183, 186], [187, 194], [195, 201], [202, 207], [208, 211], [212, 215], [216, 225], [226, 228], [229, 232], [233, 237], [237, 238], [239, 240], [241, 252], [253, 255], [256, 259], [260, 263], [264, 268], [269, 272], [273, 281], [282, 286], [287, 295], [296, 298], [299, 314], [315, 323], [323, 324], [325, 330], [331, 335], [336, 337], [338, 349], [350, 352], [353, 361], [362, 365], [366, 376], [377, 381], [382, 383], [383, 390], [391, 392], [393, 398], [399, 402], [403, 405], [406, 414], [415, 419], [420, 428], [429, 433], [434, 435], [436, 441], [442, 448], [449, 451], [452, 462], [463, 467], [467, 468], [468, 469]]}
{"doc_key": "ai-dev-21", "ner": [[18, 19, "organisation"], [20, 20, "product"], [22, 24, "organisation"], [25, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[20, 20, 18, 19, "artifact", "", false, false], [22, 24, 25, 25, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Despite", "these", "humanoid", "robots", "for", "utility", "purposes", ",", "there", "are", "some", "humanoid", "robots", "for", "fun", ",", "such", "as", "Sony", "'s", "QRIO", "and", "Wow", "Wee", "'s", "RoboSapien", "."], "sentence-detokenized": "Despite these humanoid robots for utility purposes, there are some humanoid robots for fun, such as Sony's QRIO and Wow Wee's RoboSapien.", "token2charspan": [[0, 7], [8, 13], [14, 22], [23, 29], [30, 33], [34, 41], [42, 50], [50, 51], [52, 57], [58, 61], [62, 66], [67, 75], [76, 82], [83, 86], [87, 90], [90, 91], [92, 96], [97, 99], [100, 104], [104, 106], [107, 111], [112, 115], [116, 119], [120, 123], [123, 125], [126, 136], [136, 137]]}
{"doc_key": "ai-dev-22", "ner": [[0, 2, "researcher"], [6, 14, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 6, 14, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Webber", "became", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "in", "1991", ","], "sentence-detokenized": "Webber became a member of the Association for the Advancement of Artificial Intelligence in 1991,", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 22], [23, 25], [26, 29], [30, 41], [42, 45], [46, 49], [50, 61], [62, 64], [65, 75], [76, 88], [89, 91], [92, 96], [96, 97]]}
{"doc_key": "ai-dev-23", "ner": [[6, 7, "field"], [11, 11, "field"], [20, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 23, 6, 7, "part-of", "task_part_of_field", false, false], [20, 23, 11, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "this", "company", ",", "he", "developed", "data", "mining", "and", "database", "technology", ",", "specifically", "high", "-", "level", "ontologies", "for", "intelligence", "and", "automatic", "natural", "language", "understanding", "."], "sentence-detokenized": "In this company, he developed data mining and database technology, specifically high-level ontologies for intelligence and automatic natural language understanding.", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 19], [20, 29], [30, 34], [35, 41], [42, 45], [46, 54], [55, 65], [65, 66], [67, 79], [80, 84], [84, 85], [85, 90], [91, 101], [102, 105], [106, 118], [119, 122], [123, 132], [133, 140], [141, 149], [150, 163], [163, 164]]}
{"doc_key": "ai-dev-24", "ner": [[24, 25, "misc"], [28, 31, "misc"], [37, 39, "misc"], [40, 40, "country"], [43, 44, "organisation"], [46, 46, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[24, 25, 40, 40, "physical", "", false, false], [28, 31, 40, 40, "physical", "", false, false], [37, 39, 40, 40, "physical", "", false, false], [43, 44, 46, 46, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "recent", "years", ",", "however", ",", "we", "have", "seen", "the", "emergence", "of", "various", "e-services", "and", "related", "initiatives", "in", "developing", "countries", ",", "such", "as", "the", "Nemmadi", "Project", ",", "the", "MCA21", "Mission", "Mode", "Project", "or", ",", "more", "recently", ",", "Digital", "India", "in", "India", ",", "the", "e-Governance", "Directorate", "in", "Pakistan", ",", "etc", "."], "sentence-detokenized": "In recent years, however, we have seen the emergence of various e-services and related initiatives in developing countries, such as the Nemmadi Project, the MCA21 Mission Mode Project or, more recently, Digital India in India, the e-Governance Directorate in Pakistan, etc.", "token2charspan": [[0, 2], [3, 9], [10, 15], [15, 16], [17, 24], [24, 25], [26, 28], [29, 33], [34, 38], [39, 42], [43, 52], [53, 55], [56, 63], [64, 74], [75, 78], [79, 86], [87, 98], [99, 101], [102, 112], [113, 122], [122, 123], [124, 128], [129, 131], [132, 135], [136, 143], [144, 151], [151, 152], [153, 156], [157, 162], [163, 170], [171, 175], [176, 183], [184, 186], [186, 187], [188, 192], [193, 201], [201, 202], [203, 210], [211, 216], [217, 219], [220, 225], [225, 226], [227, 230], [231, 243], [244, 255], [256, 258], [259, 267], [267, 268], [269, 272], [272, 273]]}
{"doc_key": "ai-dev-25", "ner": [[13, 15, "misc"], [17, 18, "field"], [20, 20, "field"], [23, 25, "university"], [26, 32, "university"], [8, 12, "university"], [37, 37, "misc"], [39, 40, "field"], [42, 57, "misc"], [43, 43, "university"], [44, 47, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[13, 15, 17, 18, "topic", "", false, false], [13, 15, 20, 20, "topic", "", false, false], [13, 15, 23, 25, "origin", "", false, false], [23, 25, 26, 32, "part-of", "", false, false], [8, 12, 23, 25, "part-of", "", false, false], [37, 37, 39, 40, "topic", "", false, false], [37, 37, 43, 43, "origin", "", false, false], [42, 57, 43, 43, "origin", "", false, false], [43, 43, 44, 47, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "1979", ",", "as", "a", "student", "of", "the", "Indian", "Statistical", "Institute", ",", "he", "obtained", "a", "PhD", "in", "Radio", "Physics", "and", "Electronics", "from", "the", "Rajabazar", "Science", "College", ",", "University", "of", "Calcutta", ",", "and", "in", "1982", "he", "obtained", "a", "PhD", "in", "Electrical", "Engineering", "from", "Imperial", "College", ",", "University", "of", "London", ",", "where", "he", "was", "awarded", "a", "Diploma", "of", "Imperial", "College", "."], "sentence-detokenized": "In 1979, as a student of the Indian Statistical Institute, he obtained a PhD in Radio Physics and Electronics from the Rajabazar Science College, University of Calcutta, and in 1982 he obtained a PhD in Electrical Engineering from Imperial College, University of London, where he was awarded a Diploma of Imperial College.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 13], [14, 21], [22, 24], [25, 28], [29, 35], [36, 47], [48, 57], [57, 58], [59, 61], [62, 70], [71, 72], [73, 76], [77, 79], [80, 85], [86, 93], [94, 97], [98, 109], [110, 114], [115, 118], [119, 128], [129, 136], [137, 144], [144, 145], [146, 156], [157, 159], [160, 168], [168, 169], [170, 173], [174, 176], [177, 181], [182, 184], [185, 193], [194, 195], [196, 199], [200, 202], [203, 213], [214, 225], [226, 230], [231, 239], [240, 247], [247, 248], [249, 259], [260, 262], [263, 269], [269, 270], [271, 276], [277, 279], [280, 283], [284, 291], [292, 293], [294, 301], [302, 304], [305, 313], [314, 321], [321, 322]]}
{"doc_key": "ai-dev-26", "ner": [[0, 1, "location"], [21, 23, "misc"], [29, 30, "misc"], [33, 35, "person"], [37, 38, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 23, 0, 1, "temporal", "", false, false], [29, 30, 0, 1, "temporal", "", false, false], [33, 35, 29, 30, "role", "actor_in", false, false], [37, 38, 29, 30, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Expo", "II", "was", "announced", "as", "the", "venue", "for", "the", "world", "premiere", "of", "several", "films", "never", "before", "shown", "in", "3D", ",", "including", "The", "Diamond", "Wizard", "and", "Universal", "'s", "short", "film", "Hawaiian", "Nights", ",", "starring", "Mamie", "Van", "Doren", "and", "Pinky", "Lee", "."], "sentence-detokenized": "Expo II was announced as the venue for the world premiere of several films never before shown in 3D, including The Diamond Wizard and Universal's short film Hawaiian Nights, starring Mamie Van Doren and Pinky Lee.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 24], [25, 28], [29, 34], [35, 38], [39, 42], [43, 48], [49, 57], [58, 60], [61, 68], [69, 74], [75, 80], [81, 87], [88, 93], [94, 96], [97, 99], [99, 100], [101, 110], [111, 114], [115, 122], [123, 129], [130, 133], [134, 143], [143, 145], [146, 151], [152, 156], [157, 165], [166, 172], [172, 173], [174, 182], [183, 188], [189, 192], [193, 198], [199, 202], [203, 208], [209, 212], [212, 213]]}
{"doc_key": "ai-dev-27", "ner": [[9, 10, "researcher"], [16, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 10, 16, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "maximum", "subclass", "problem", "was", "proposed", "in", "1977", "by", "Ulf", "Grenander", "as", "a", "simplified", "model", "for", "maximum", "likelihood", "estimation", "of", "patterns", "in", "digitised", "images", "."], "sentence-detokenized": "The maximum subclass problem was proposed in 1977 by Ulf Grenander as a simplified model for maximum likelihood estimation of patterns in digitised images.", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 28], [29, 32], [33, 41], [42, 44], [45, 49], [50, 52], [53, 56], [57, 66], [67, 69], [70, 71], [72, 82], [83, 88], [89, 92], [93, 100], [101, 111], [112, 122], [123, 125], [126, 134], [135, 137], [138, 147], [148, 154], [154, 155]]}
{"doc_key": "ai-dev-28", "ner": [[0, 1, "product"], [3, 4, "product"], [6, 8, "product"], [10, 11, "product"], [14, 15, "product"], [17, 20, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[24, 24, 0, 1, "part-of", "", false, false], [24, 24, 3, 4, "part-of", "", false, false], [24, 24, 6, 8, "part-of", "", false, false], [24, 24, 10, 11, "part-of", "", false, false], [24, 24, 14, 15, "part-of", "", false, false], [24, 24, 17, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["iPhone", "4S", ",", "iPad", "3", ",", "iPad", "Mini", "1G", ",", "iPad", "Air", ",", "iPad", "Pro", "1G", ",", "iPod", "Touch", "5", "G", "and", "later", "have", "Siri", ",", "the", "more", "advanced", "voice", "assistant", "."], "sentence-detokenized": "iPhone 4S, iPad 3, iPad Mini 1G, iPad Air, iPad Pro 1G, iPod Touch 5G and later have Siri, the more advanced voice assistant.", "token2charspan": [[0, 6], [7, 9], [9, 10], [11, 15], [16, 17], [17, 18], [19, 23], [24, 28], [29, 31], [31, 32], [33, 37], [38, 41], [41, 42], [43, 47], [48, 51], [52, 54], [54, 55], [56, 60], [61, 66], [67, 68], [68, 69], [70, 73], [74, 79], [80, 84], [85, 89], [89, 90], [91, 94], [95, 99], [100, 108], [109, 114], [115, 124], [124, 125]]}
{"doc_key": "ai-dev-29", "ner": [[6, 7, "metrics"], [10, 13, "metrics"], [15, 16, "metrics"], [43, 46, "metrics"], [51, 54, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 13, 43, 46, "named", "", false, false], [15, 16, 10, 13, "named", "", false, false], [43, 46, 51, 54, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["We", "can", "easily", "verify", "that", "the", "logistic", "loss", "and", "the", "binary", "cross", "-entropy", "loss", "(", "Log", "loss", ")", "are", "indeed", "the", "same", "(", "up", "to", "a", "multiplicative", "constant", "math", "\\", "frac", "{", "1", "}", "{", "\\", "log", "(", "2", ")", "}", "/", "The", "cross", "-entropy", "loss", "is", "closely", "related", "to", "the", "Kullback", "-", "Leibler", "divergence", "between", "the", "empirical", "distribution", "and", "the", "predicted", "distribution", "."], "sentence-detokenized": "We can easily verify that the logistic loss and the binary cross-entropy loss (Log loss) are indeed the same (up to a multiplicative constant math\\ frac {1} {\\ log (2)} / The cross-entropy loss is closely related to the Kullback-Leibler divergence between the empirical distribution and the predicted distribution.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 20], [21, 25], [26, 29], [30, 38], [39, 43], [44, 47], [48, 51], [52, 58], [59, 64], [64, 72], [73, 77], [78, 79], [79, 82], [83, 87], [87, 88], [89, 92], [93, 99], [100, 103], [104, 108], [109, 110], [110, 112], [113, 115], [116, 117], [118, 132], [133, 141], [142, 146], [146, 147], [148, 152], [153, 154], [154, 155], [155, 156], [157, 158], [158, 159], [160, 163], [164, 165], [165, 166], [166, 167], [167, 168], [169, 170], [171, 174], [175, 180], [180, 188], [189, 193], [194, 196], [197, 204], [205, 212], [213, 215], [216, 219], [220, 228], [228, 229], [229, 236], [237, 247], [248, 255], [256, 259], [260, 269], [270, 282], [283, 286], [287, 290], [291, 300], [301, 313], [313, 314]]}
{"doc_key": "ai-dev-30", "ner": [[0, 4, "algorithm"], [11, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 0, 4, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "EM", "algorithm", "is", "used", "to", "find", "the", "(", "local", ")", "maximum", "likelihood", "parameters", "of", "a", "statistical", "model", "in", "cases", "where", "the", "equations", "can", "not", "be", "solved", "directly", "."], "sentence-detokenized": "The EM algorithm is used to find the (local) maximum likelihood parameters of a statistical model in cases where the equations cannot be solved directly.", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 19], [20, 24], [25, 27], [28, 32], [33, 36], [37, 38], [38, 43], [43, 44], [45, 52], [53, 63], [64, 74], [75, 77], [78, 79], [80, 91], [92, 97], [98, 100], [101, 106], [107, 112], [113, 116], [117, 126], [127, 130], [130, 133], [134, 136], [137, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-dev-31", "ner": [[10, 11, "task"], [14, 20, "task"], [24, 24, "task"], [23, 26, "task"], [33, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "research", "has", "been", "fundamental", "for", "the", "development", "of", "modern", "speech", "synthesis", "techniques", ",", "reading", "machines", "for", "the", "blind", ",", "the", "study", "of", "speech", "perception", "and", "recognition", ",", "and", "the", "development", "of", "a", "motor", "theory", "of", "speech", "perception", "."], "sentence-detokenized": "This research has been fundamental for the development of modern speech synthesis techniques, reading machines for the blind, the study of speech perception and recognition, and the development of a motor theory of speech perception.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 22], [23, 34], [35, 38], [39, 42], [43, 54], [55, 57], [58, 64], [65, 71], [72, 81], [82, 92], [92, 93], [94, 101], [102, 110], [111, 114], [115, 118], [119, 124], [124, 125], [126, 129], [130, 135], [136, 138], [139, 145], [146, 156], [157, 160], [161, 172], [172, 173], [174, 177], [178, 181], [182, 193], [194, 196], [197, 198], [199, 204], [205, 211], [212, 214], [215, 221], [222, 232], [232, 233]]}
{"doc_key": "ai-dev-32", "ner": [[0, 1, "product"], [2, 4, "misc"], [6, 6, "misc"], [10, 12, "misc"], [15, 15, "product"], [17, 17, "product"], [19, 19, "product"], [24, 24, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 4, 0, 1, "origin", "", false, false], [2, 4, 10, 12, "type-of", "", false, false], [2, 4, 15, 15, "related-to", "program_for", false, false], [2, 4, 17, 17, "related-to", "program_for", false, false], [2, 4, 19, 19, "related-to", "program_for", false, false], [2, 4, 24, 24, "related-to", "program_for", false, false], [6, 6, 2, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "Arduino", "Integrated", "Development", "Environment", "(", "IDE", ")", "is", "a", "cross", "-platform", "application", "(", "for", "Windows", ",", "macOS", "and", "Linux", ")", "written", "in", "the", "Java", "programming", "language", "."], "sentence-detokenized": "The Arduino Integrated Development Environment (IDE) is a cross-platform application (for Windows, macOS and Linux) written in the Java programming language.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 34], [35, 46], [47, 48], [48, 51], [51, 52], [53, 55], [56, 57], [58, 63], [63, 72], [73, 84], [85, 86], [86, 89], [90, 97], [97, 98], [99, 104], [105, 108], [109, 114], [114, 115], [116, 123], [124, 126], [127, 130], [131, 135], [136, 147], [148, 156], [156, 157]]}
{"doc_key": "ai-dev-33", "ner": [[2, 3, "algorithm"], [15, 16, "field"], [9, 10, "researcher"], [12, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 15, 16, "opposite", "", false, false], [9, 10, 15, 16, "related-to", "works_with", false, false], [12, 14, 15, 16, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Research", "on", "neural", "networks", "stalled", "after", "the", "publication", "of", "Marvin", "Minsky", "and", "Seymour", "Papert", "'s", "machine", "learning", "research", "(", "1969", ")", "."], "sentence-detokenized": "Research on neural networks stalled after the publication of Marvin Minsky and Seymour Papert's machine learning research (1969).", "token2charspan": [[0, 8], [9, 11], [12, 18], [19, 27], [28, 35], [36, 41], [42, 45], [46, 57], [58, 60], [61, 67], [68, 74], [75, 78], [79, 86], [87, 93], [93, 95], [96, 103], [104, 112], [113, 121], [122, 123], [123, 127], [127, 128], [128, 129]]}
{"doc_key": "ai-dev-34", "ner": [[16, 17, "organisation"], [19, 19, "organisation"], [22, 24, "country"], [26, 29, "organisation"], [32, 32, "country"], [34, 35, "organisation"], [38, 38, "country"], [40, 40, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[26, 29, 22, 24, "general-affiliation", "", false, false], [34, 35, 32, 32, "general-affiliation", "", false, false], [40, 40, 38, 38, "general-affiliation", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Only", "a", "few", "non-Japanese", "companies", "managed", "to", "survive", "in", "this", "market", ",", "the", "main", "ones", "being", "Adept", "Technology", ",", "St\u00e4ubli", ",", "the", "Swedish", "-", "Swiss", "company", "ABB", "Asea", "Brown", "Boveri", ",", "the", "German", "company", "KUKA", "Robotics", "and", "the", "Italian", "company", "Comau", "."], "sentence-detokenized": "Only a few non-Japanese companies managed to survive in this market, the main ones being Adept Technology, St\u00e4ubli, the Swedish-Swiss company ABB Asea Brown Boveri, the German company KUKA Robotics and the Italian company Comau.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 23], [24, 33], [34, 41], [42, 44], [45, 52], [53, 55], [56, 60], [61, 67], [67, 68], [69, 72], [73, 77], [78, 82], [83, 88], [89, 94], [95, 105], [105, 106], [107, 114], [114, 115], [116, 119], [120, 127], [127, 128], [128, 133], [134, 141], [142, 145], [146, 150], [151, 156], [157, 163], [163, 164], [165, 168], [169, 175], [176, 183], [184, 188], [189, 197], [198, 201], [202, 205], [206, 213], [214, 221], [222, 227], [227, 228]]}
{"doc_key": "ai-dev-35", "ner": [[5, 8, "conference"], [11, 11, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 11, 5, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Research", "activities", "include", "the", "annual", "RuleML", "Symposium", ",", "also", "known", "as", "RuleML", "."], "sentence-detokenized": "Research activities include the annual RuleML Symposium, also known as RuleML.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 31], [32, 38], [39, 45], [46, 55], [55, 56], [57, 61], [62, 67], [68, 70], [71, 77], [77, 78]]}
{"doc_key": "ai-dev-36", "ner": [[9, 9, "field"], [11, 12, "field"], [14, 14, "field"], [16, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Concepts", "are", "used", "as", "formal", "tools", "or", "models", "in", "mathematics", ",", "computer", "science", ",", "databases", "and", "artificial", "intelligence", ",", "where", "they", "are", "sometimes", "called", "classes", ",", "schemas", "or", "categories", "."], "sentence-detokenized": "Concepts are used as formal tools or models in mathematics, computer science, databases and artificial intelligence, where they are sometimes called classes, schemas or categories.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 20], [21, 27], [28, 33], [34, 36], [37, 43], [44, 46], [47, 58], [58, 59], [60, 68], [69, 76], [76, 77], [78, 87], [88, 91], [92, 102], [103, 115], [115, 116], [117, 122], [123, 127], [128, 131], [132, 141], [142, 148], [149, 156], [156, 157], [158, 165], [166, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-dev-37", "ner": [[4, 8, "organisation"], [11, 16, "organisation"], [17, 17, "organisation"], [21, 24, "organisation"], [27, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "received", "awards", "from", "the", "American", "Psychological", "Association", ",", "the", "National", "Academy", "of", "Sciences", ",", "the", "Royal", "Society", ",", "the", "Association", "for", "Cognitive", "Neuroscience", "and", "the", "American", "Humanist", "Association", "."], "sentence-detokenized": "He has received awards from the American Psychological Association, the National Academy of Sciences, the Royal Society, the Association for Cognitive Neuroscience and the American Humanist Association.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 22], [23, 27], [28, 31], [32, 40], [41, 54], [55, 66], [66, 67], [68, 71], [72, 80], [81, 88], [89, 91], [92, 100], [100, 101], [102, 105], [106, 111], [112, 119], [119, 120], [121, 124], [125, 136], [137, 140], [141, 150], [151, 163], [164, 167], [168, 171], [172, 180], [181, 189], [190, 201], [201, 202]]}
{"doc_key": "ai-dev-38", "ner": [[4, 5, "person"], [7, 8, "person"], [10, 14, "person"], [18, 23, "person"], [24, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[24, 30, 18, 23, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "film", ",", "starring", "Harrison", "Ford", ",", "Rutger", "Hauer", "and", "Sean", "Young", ",", "is", "based", "on", "the", "novel", "by", "Philip", "K", ".", "Dick", "'s", "Do", "Androids", "Dream", "of", "Electric", "Sheep", "?", "(", "1968", ")", "."], "sentence-detokenized": "The film, starring Harrison Ford, Rutger Hauer and Sean Young, is based on the novel by Philip K. Dick's Do Androids Dream of Electric Sheep? (1968).", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 18], [19, 27], [28, 32], [32, 33], [34, 40], [41, 46], [47, 50], [51, 55], [56, 61], [61, 62], [63, 65], [66, 71], [72, 74], [75, 78], [79, 84], [85, 87], [88, 94], [95, 96], [96, 97], [98, 102], [102, 104], [105, 107], [108, 116], [117, 122], [123, 125], [126, 134], [135, 140], [140, 141], [142, 143], [143, 147], [147, 148], [148, 149]]}
{"doc_key": "ai-dev-39", "ner": [[0, 1, "task"], [3, 5, "algorithm"], [11, 12, "field"], [14, 15, "task"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 3, 5, "usage", "", false, false], [0, 1, 11, 12, "part-of", "task_part_of_field", false, false], [0, 1, 14, 15, "part-of", "task_part_of_field", false, false], [0, 1, 17, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Image", "segmentation", "using", "k-means", "clustering", "algorithms", "has", "long", "been", "used", "for", "pattern", "recognition", ",", "object", "detection", "and", "medical", "imaging", "."], "sentence-detokenized": "Image segmentation using k-means clustering algorithms has long been used for pattern recognition, object detection and medical imaging.", "token2charspan": [[0, 5], [6, 18], [19, 24], [25, 32], [33, 43], [44, 54], [55, 58], [59, 63], [64, 68], [69, 73], [74, 77], [78, 85], [86, 97], [97, 98], [99, 105], [106, 115], [116, 119], [120, 127], [128, 135], [135, 136]]}
{"doc_key": "ai-dev-40", "ner": [[14, 14, "algorithm"], [17, 20, "algorithm"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["General", "sampling", "from", "the", "truncated", "normal", "can", "be", "achieved", "with", "approximations", "of", "the", "normal", "CDF", "and", "the", "probit", "function", ",", "and", "R", "has", "a", "codertnorm", "(", ")", "/", "code", "function", "to", "generate", "truncated", "normal", "samples", "."], "sentence-detokenized": "General sampling from the truncated normal can be achieved with approximations of the normal CDF and the probit function, and R has a codertnorm()/code function to generate truncated normal samples.", "token2charspan": [[0, 7], [8, 16], [17, 21], [22, 25], [26, 35], [36, 42], [43, 46], [47, 49], [50, 58], [59, 63], [64, 78], [79, 81], [82, 85], [86, 92], [93, 96], [97, 100], [101, 104], [105, 111], [112, 120], [120, 121], [122, 125], [126, 127], [128, 131], [132, 133], [134, 144], [144, 145], [145, 146], [146, 147], [147, 151], [152, 160], [161, 163], [164, 172], [173, 182], [183, 189], [190, 197], [197, 198]]}
{"doc_key": "ai-dev-41", "ner": [[7, 8, "university"], [12, 13, "university"], [15, 17, "university"], [19, 21, "university"], [23, 24, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Honorary", "doctorates", "have", "also", "been", "awarded", "by", "Newcastle", "University", ",", "the", "University", "of", "Surrey", ",", "Tel", "Aviv", "University", ",", "Simon", "Fraser", "University", "and", "Troms\u00f8", "University", "."], "sentence-detokenized": "Honorary doctorates have also been awarded by Newcastle University, the University of Surrey, Tel Aviv University, Simon Fraser University and Troms\u00f8 University.", "token2charspan": [[0, 8], [9, 19], [20, 24], [25, 29], [30, 34], [35, 42], [43, 45], [46, 55], [56, 66], [66, 67], [68, 71], [72, 82], [83, 85], [86, 92], [92, 93], [94, 97], [98, 102], [103, 113], [113, 114], [115, 120], [121, 127], [128, 138], [139, 142], [143, 149], [150, 160], [160, 161]]}
{"doc_key": "ai-dev-42", "ner": [[0, 1, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "Java", "implementation", "that", "uses", "null", "field", "indices", ",", "together", "with", "a", "convenient", "method", "for", "printing", "the", "resolved", "order", "of", "operations", ":"], "sentence-detokenized": "A Java implementation that uses null field indices, together with a convenient method for printing the resolved order of operations:", "token2charspan": [[0, 1], [2, 6], [7, 21], [22, 26], [27, 31], [32, 36], [37, 42], [43, 50], [50, 51], [52, 60], [61, 65], [66, 67], [68, 78], [79, 85], [86, 89], [90, 98], [99, 102], [103, 111], [112, 117], [118, 120], [121, 131], [131, 132]]}
{"doc_key": "ai-dev-43", "ner": [[7, 8, "metrics"], [11, 17, "metrics"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 17, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Such", "networks", "are", "usually", "trained", "in", "the", "cross", "-entropy", "(", "or", "cross", "-entropy", ")", "regime", ",", "which", "is", "a", "non-linear", "version", "of", "multinomial", "logistic", "regression", "."], "sentence-detokenized": "Such networks are usually trained in the cross-entropy (or cross-entropy) regime, which is a non-linear version of multinomial logistic regression.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 25], [26, 33], [34, 36], [37, 40], [41, 46], [46, 54], [55, 56], [56, 58], [59, 64], [64, 72], [72, 73], [74, 80], [80, 81], [82, 87], [88, 90], [91, 92], [93, 103], [104, 111], [112, 114], [115, 126], [127, 135], [136, 146], [146, 147]]}
{"doc_key": "ai-dev-44", "ner": [[0, 0, "conference"], [3, 3, "misc"], [5, 12, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["ACL", "has", "a", "European", "(", "European", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ")"], "sentence-detokenized": "ACL has a European (European Chapter of the Association for Computational Linguistics)", "token2charspan": [[0, 3], [4, 7], [8, 9], [10, 18], [19, 20], [20, 28], [29, 36], [37, 39], [40, 43], [44, 55], [56, 59], [60, 73], [74, 85], [85, 86]]}
{"doc_key": "ai-dev-45", "ner": [[3, 4, "researcher"], [6, 11, "researcher"], [19, 19, "misc"], [21, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 19, 19, "role", "", false, false], [6, 11, 19, 19, "role", "", false, false], [19, 19, 21, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "professors", ",", "Hal", "Abelson", "and", "Gerald", "Jay", "Sussman", ",", "decided", "to", "remain", "neutral", "-", "their", "group", "was", "called", "Switzerland", "and", "Project", "MAC", "for", "the", "next", "30", "years", "."], "sentence-detokenized": "Two professors, Hal Abelson and Gerald Jay Sussman, decided to remain neutral - their group was called Switzerland and Project MAC for the next 30 years.", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 27], [28, 31], [32, 38], [39, 42], [43, 50], [50, 51], [52, 59], [60, 62], [63, 69], [70, 77], [78, 79], [80, 85], [86, 91], [92, 95], [96, 102], [103, 114], [115, 118], [119, 126], [127, 130], [131, 134], [135, 138], [139, 143], [144, 146], [147, 152], [152, 153]]}
{"doc_key": "ai-dev-46", "ner": [[1, 3, "misc"], [5, 5, "researcher"], [9, 11, "university"], [16, 20, "organisation"], [21, 25, "organisation"], [27, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 3, 5, 5, "temporal", "", false, false], [5, 5, 16, 20, "physical", "", false, false], [5, 5, 16, 20, "role", "", false, false], [5, 5, 21, 25, "role", "", false, false], [21, 25, 9, 11, "part-of", "", false, false], [27, 28, 21, 25, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["After", "completing", "his", "PhD", ",", "Ghahramani", "moved", "to", "the", "University", "of", "Toronto", "in", "1995", "as", "an", "ITRC", "postdoctoral", "fellow", "in", "the", "Artificial", "Intelligence", "Laboratory", ",", "working", "with", "Geoffrey", "Hinton", "."], "sentence-detokenized": "After completing his PhD, Ghahramani moved to the University of Toronto in 1995 as an ITRC postdoctoral fellow in the Artificial Intelligence Laboratory, working with Geoffrey Hinton.", "token2charspan": [[0, 5], [6, 16], [17, 20], [21, 24], [24, 25], [26, 36], [37, 42], [43, 45], [46, 49], [50, 60], [61, 63], [64, 71], [72, 74], [75, 79], [80, 82], [83, 85], [86, 90], [91, 103], [104, 110], [111, 113], [114, 117], [118, 128], [129, 141], [142, 152], [152, 153], [154, 161], [162, 166], [167, 175], [176, 182], [182, 183]]}
{"doc_key": "ai-dev-47", "ner": [[23, 24, "metrics"], [26, 26, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[26, 26, 23, 24, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Later", "work", "focused", "on", "solving", "these", "problems", ",", "but", "it", "was", "only", "with", "the", "advent", "of", "the", "modern", "computer", "and", "the", "popularisation", "of", "Maximum", "Likelihood", "(", "MLE", ")", "parameterisation", "techniques", "that", "research", "really", "took", "off", "."], "sentence-detokenized": "Later work focused on solving these problems, but it was only with the advent of the modern computer and the popularisation of Maximum Likelihood (MLE) parameterisation techniques that research really took off.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 21], [22, 29], [30, 35], [36, 44], [44, 45], [46, 49], [50, 52], [53, 56], [57, 61], [62, 66], [67, 70], [71, 77], [78, 80], [81, 84], [85, 91], [92, 100], [101, 104], [105, 108], [109, 123], [124, 126], [127, 134], [135, 145], [146, 147], [147, 150], [150, 151], [152, 168], [169, 179], [180, 184], [185, 193], [194, 200], [201, 205], [206, 209], [209, 210]]}
{"doc_key": "ai-dev-48", "ner": [[5, 7, "person"], [9, 10, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "series", "was", "produced", "by", "David", "Fincher", "and", "starred", "Kevin", "Spacey", "."], "sentence-detokenized": "The series was produced by David Fincher and starred Kevin Spacey.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 26], [27, 32], [33, 40], [41, 44], [45, 52], [53, 58], [59, 65], [65, 66]]}
{"doc_key": "ai-dev-49", "ner": [[16, 18, "metrics"], [20, 21, "algorithm"], [29, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 21, 29, 31, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Due", "to", "limited", "computing", "power", ",", "current", "in", "silico", "methods", "usually", "have", "to", "trade", "speed", "for", "accuracy", ";", "e.g.", "fast", "protein", "splicing", "methods", "are", "used", "instead", "of", "computationally", "expensive", "free", "energy", "calculations", "."], "sentence-detokenized": "Due to limited computing power, current in silico methods usually have to trade speed for accuracy; e.g. fast protein splicing methods are used instead of computationally expensive free energy calculations.", "token2charspan": [[0, 3], [4, 6], [7, 14], [15, 24], [25, 30], [30, 31], [32, 39], [40, 42], [43, 49], [50, 57], [58, 65], [66, 70], [71, 73], [74, 79], [80, 85], [86, 89], [90, 98], [98, 99], [100, 104], [105, 109], [110, 117], [118, 126], [127, 134], [135, 138], [139, 143], [144, 151], [152, 154], [155, 170], [171, 180], [181, 185], [186, 192], [193, 205], [205, 206]]}
{"doc_key": "ai-dev-50", "ner": [[6, 8, "country"], [10, 10, "country"], [12, 12, "country"], [14, 14, "country"], [16, 16, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "had", "more", "than", "30", "branches", "in", "the", "USA", ",", "Canada", ",", "Mexico", ",", "Brazil", "and", "Argentina", "."], "sentence-detokenized": "It had more than 30 branches in the USA, Canada, Mexico, Brazil and Argentina.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 19], [20, 28], [29, 31], [32, 35], [36, 39], [39, 40], [41, 47], [47, 48], [49, 55], [55, 56], [57, 63], [64, 67], [68, 77], [77, 78]]}
{"doc_key": "ai-dev-51", "ner": [[6, 8, "field"], [9, 12, "product"], [13, 15, "algorithm"], [18, 19, "task"], [21, 22, "task"], [29, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 12, 6, 8, "part-of", "", false, false], [9, 12, 13, 15, "usage", "", false, false], [18, 19, 6, 8, "part-of", "task_part_of_field", false, false], [18, 19, 29, 29, "related-to", "performs", false, false], [21, 22, 6, 8, "part-of", "task_part_of_field", false, false], [21, 22, 29, 29, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["An", "example", "of", "a", "typical", "computer", "vision", "for", "a", "face", "recognition", "system", "using", "k", "-", "NN", ",", "including", "feature", "extraction", "and", "dimensionality", "reduction", "pre-processing", "steps", "(", "typically", "implemented", "with", "OpenCV", ")", ":"], "sentence-detokenized": "An example of a typical computer vision for a face recognition system using k -NN, including feature extraction and dimensionality reduction pre-processing steps (typically implemented with OpenCV):", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 23], [24, 32], [33, 39], [40, 43], [44, 45], [46, 50], [51, 62], [63, 69], [70, 75], [76, 77], [78, 79], [79, 81], [81, 82], [83, 92], [93, 100], [101, 111], [112, 115], [116, 130], [131, 140], [141, 155], [156, 161], [162, 163], [163, 172], [173, 184], [185, 189], [190, 196], [196, 197], [197, 198]]}
{"doc_key": "ai-dev-52", "ner": [[9, 11, "algorithm"], [13, 13, "misc"], [15, 16, "misc"], [19, 20, "misc"], [24, 24, "programlang"], [26, 26, "product"], [30, 31, "algorithm"], [34, 35, "misc"], [37, 37, "misc"], [39, 39, "misc"], [41, 41, "misc"], [48, 48, "misc"], [51, 55, "misc"], [55, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "has", "a", "rich", "feature", "set", ",", "libraries", "for", "constraint", "logic", "programming", ",", "multithreading", ",", "unit", "testing", ",", "a", "graphical", "interface", ",", "integration", "with", "Java", ",", "ODBC", "and", "others", ",", "literate", "programming", ",", "a", "web", "server", ",", "SGML", ",", "RDF", ",", "RDFS", ",", "developer", "tools", "(", "including", "an", "IDE", "with", "a", "debugger", "and", "a", "GUI", "profiler", ")", "and", "extensive", "documentation", "."], "sentence-detokenized": "It has a rich feature set, libraries for constraint logic programming, multithreading, unit testing, a graphical interface, integration with Java, ODBC and others, literate programming, a web server, SGML, RDF, RDFS, developer tools (including an IDE with a debugger and a GUI profiler) and extensive documentation.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 13], [14, 21], [22, 25], [25, 26], [27, 36], [37, 40], [41, 51], [52, 57], [58, 69], [69, 70], [71, 85], [85, 86], [87, 91], [92, 99], [99, 100], [101, 102], [103, 112], [113, 122], [122, 123], [124, 135], [136, 140], [141, 145], [145, 146], [147, 151], [152, 155], [156, 162], [162, 163], [164, 172], [173, 184], [184, 185], [186, 187], [188, 191], [192, 198], [198, 199], [200, 204], [204, 205], [206, 209], [209, 210], [211, 215], [215, 216], [217, 226], [227, 232], [233, 234], [234, 243], [244, 246], [247, 250], [251, 255], [256, 257], [258, 266], [267, 270], [271, 272], [273, 276], [277, 285], [285, 286], [287, 290], [291, 300], [301, 314], [314, 315]]}
{"doc_key": "ai-dev-53", "ner": [[1, 2, "field"], [4, 7, "field"], [10, 12, "misc"], [14, 16, "misc"], [19, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 12, 1, 2, "part-of", "", true, false], [10, 12, 4, 7, "part-of", "", false, false], [10, 12, 19, 22, "type-of", "", false, false], [14, 16, 1, 2, "part-of", "", false, false], [14, 16, 4, 7, "part-of", "", false, false], [14, 16, 19, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "computer", "vision", "and", "image", "processing", ",", "the", "notion", "of", "scale", "space", "representation", "and", "Gaussian", "derivative", "operators", "is", "a", "canonical", "multi", "-scale", "representation", "."], "sentence-detokenized": "In computer vision and image processing, the notion of scale space representation and Gaussian derivative operators is a canonical multi-scale representation.", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 22], [23, 28], [29, 39], [39, 40], [41, 44], [45, 51], [52, 54], [55, 60], [61, 66], [67, 81], [82, 85], [86, 94], [95, 105], [106, 115], [116, 118], [119, 120], [121, 130], [131, 136], [136, 142], [143, 157], [157, 158]]}
{"doc_key": "ai-dev-54", "ner": [[7, 11, "organisation"], [20, 25, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 11, 20, 25, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "also", "the", "President", "of", "the", "Neural", "Information", "Processing", "Systems", "Foundation", ",", "a", "non-profit", "organisation", "that", "runs", "an", "annual", "conference", "on", "neural", "information", "processing", "systems", "."], "sentence-detokenized": "He is also the President of the Neural Information Processing Systems Foundation, a non-profit organisation that runs an annual conference on neural information processing systems.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 14], [15, 24], [25, 27], [28, 31], [32, 38], [39, 50], [51, 61], [62, 69], [70, 80], [80, 81], [82, 83], [84, 94], [95, 107], [108, 112], [113, 117], [118, 120], [121, 127], [128, 138], [139, 141], [142, 148], [149, 160], [161, 171], [172, 179], [179, 180]]}
{"doc_key": "ai-dev-55", "ner": [[1, 2, "task"], [6, 23, "metrics"], [13, 14, "misc"], [24, 24, "task"], [18, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 6, 23, "usage", "", false, false], [6, 23, 13, 14, "type-of", "", false, false], [24, 24, 18, 22, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["For", "regression", "analysis", "problems", ",", "the", "squared", "error", "can", "be", "used", "as", "the", "loss", "function", ",", "and", "the", "cross", "-entropy", "can", "be", "used", "for", "classification", "."], "sentence-detokenized": "For regression analysis problems, the squared error can be used as the loss function, and the cross-entropy can be used for classification.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 32], [32, 33], [34, 37], [38, 45], [46, 51], [52, 55], [56, 58], [59, 63], [64, 66], [67, 70], [71, 75], [76, 84], [84, 85], [86, 89], [90, 93], [94, 99], [99, 107], [108, 111], [112, 114], [115, 119], [120, 123], [124, 138], [138, 139]]}
{"doc_key": "ai-dev-56", "ner": [[0, 3, "researcher"], [18, 21, "conference"], [26, 29, "conference"], [35, 35, "university"], [38, 39, "field"], [49, 113, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 18, 21, "role", "", false, false], [0, 3, 35, 35, "physical", "", false, false], [0, 3, 35, 35, "role", "", false, false], [0, 3, 49, 113, "role", "", false, false], [18, 21, 26, 29, "named", "same", false, false], [35, 35, 38, 39, "related-to", "subject_of_study_at", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Lafferty", "has", "held", "a", "number", "of", "prestigious", "positions", ",", "including", ":", "program", "co-chair", "and", "general", "co-chair", "of", "the", "Neural", "Information", "Processing", "Systems", "Foundation", "'s", "Conference", "on", "Neural", "Information", "Processing", "Systems", ";", "2", ")", "co-editor", "of", "CMU", "'s", "new", "Machine", "Learning", "PhD", "program", ";", "3", ")", "associate", "editor", "of", "the", "Journal", "of", "Machine", "Learning", "Research", ";", "4", ")", "associate", "editor", "of", "the", "Journal", "of", "Machine", "Learning", "Research", ";", "5", ")", "associate", "editor", "of", "the", "Journal", "of", "Machine", "Learning", "Research", ";", "6", ")", "associate", "editor", "of", "the", "Journal", "of", "Machine", "Learning", "Research", ";", "7", ")", "associate", "editor", "of", "the", "Journal", "of", "Machine", "Learning", "Research", ";", "8", ")", "associate", "editor", "of", "the", "Journal", "of", "Machine", "Learning", "Research"], "sentence-detokenized": "Lafferty has held a number of prestigious positions, including: program co-chair and general co-chair of the Neural Information Processing Systems Foundation's Conference on Neural Information Processing Systems; 2) co-editor of CMU's new Machine Learning PhD program; 3) associate editor of the Journal of Machine Learning Research; 4) associate editor of the Journal of Machine Learning Research; 5) associate editor of the Journal of Machine Learning Research; 6) associate editor of the Journal of Machine Learning Research; 7) associate editor of the Journal of Machine Learning Research; 8) associate editor of the Journal of Machine Learning Research", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 19], [20, 26], [27, 29], [30, 41], [42, 51], [51, 52], [53, 62], [62, 63], [64, 71], [72, 80], [81, 84], [85, 92], [93, 101], [102, 104], [105, 108], [109, 115], [116, 127], [128, 138], [139, 146], [147, 157], [157, 159], [160, 170], [171, 173], [174, 180], [181, 192], [193, 203], [204, 211], [211, 212], [213, 214], [214, 215], [216, 225], [226, 228], [229, 232], [232, 234], [235, 238], [239, 246], [247, 255], [256, 259], [260, 267], [267, 268], [269, 270], [270, 271], [272, 281], [282, 288], [289, 291], [292, 295], [296, 303], [304, 306], [307, 314], [315, 323], [324, 332], [332, 333], [334, 335], [335, 336], [337, 346], [347, 353], [354, 356], [357, 360], [361, 368], [369, 371], [372, 379], [380, 388], [389, 397], [397, 398], [399, 400], [400, 401], [402, 411], [412, 418], [419, 421], [422, 425], [426, 433], [434, 436], [437, 444], [445, 453], [454, 462], [462, 463], [464, 465], [465, 466], [467, 476], [477, 483], [484, 486], [487, 490], [491, 498], [499, 501], [502, 509], [510, 518], [519, 527], [527, 528], [529, 530], [530, 531], [532, 541], [542, 548], [549, 551], [552, 555], [556, 563], [564, 566], [567, 574], [575, 583], [584, 592], [592, 593], [594, 595], [595, 596], [597, 606], [607, 613], [614, 616], [617, 620], [621, 628], [629, 631], [632, 639], [640, 648], [649, 657]]}
{"doc_key": "ai-dev-57", "ner": [[0, 3, "misc"], [4, 4, "algorithm"], [6, 6, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 0, 3, "type-of", "", false, false], [6, 6, 0, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Convex", "algorithms", "such", "as", "AdaBoost", "and", "LogitBoost", "can", "be", "overwhelmed", "by", "random", "noise", ",", "so", "they", "can", "not", "learn", "basic", "and", "learnable", "combinations", "of", "weak", "hypotheses", "."], "sentence-detokenized": "Convex algorithms such as AdaBoost and LogitBoost can be overwhelmed by random noise, so they cannot learn basic and learnable combinations of weak hypotheses.", "token2charspan": [[0, 6], [7, 17], [18, 22], [23, 25], [26, 34], [35, 38], [39, 49], [50, 53], [54, 56], [57, 68], [69, 71], [72, 78], [79, 84], [84, 85], [86, 88], [89, 93], [94, 97], [97, 100], [101, 106], [107, 112], [113, 116], [117, 126], [127, 139], [140, 142], [143, 147], [148, 158], [158, 159]]}
{"doc_key": "ai-dev-58", "ner": [[0, 0, "product"], [3, 15, "product"], [11, 24, "algorithm"], [21, 22, "algorithm"], [25, 30, "task"], [32, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 15, "type-of", "", false, false], [0, 0, 11, 24, "usage", "", false, false], [0, 0, 21, 22, "usage", "", false, false], [21, 22, 25, 30, "related-to", "used_for", true, false], [21, 22, 32, 34, "related-to", "used_for", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Apertium", "is", "a", "shallow", "-", "transfer", "machine", "translation", "system", "that", "uses", "finite", "-", "state", "transducers", "for", "all", "lexical", "transformations", ",", "and", "hidden", "Markov", "models", "for", "part", "-", "of", "-", "speech", "tagging", "or", "word", "category", "disambiguation", "."], "sentence-detokenized": "Apertium is a shallow-transfer machine translation system that uses finite-state transducers for all lexical transformations, and hidden Markov models for part-of-speech tagging or word category disambiguation.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 21], [21, 22], [22, 30], [31, 38], [39, 50], [51, 57], [58, 62], [63, 67], [68, 74], [74, 75], [75, 80], [81, 92], [93, 96], [97, 100], [101, 108], [109, 124], [124, 125], [126, 129], [130, 136], [137, 143], [144, 150], [151, 154], [155, 159], [159, 160], [160, 162], [162, 163], [163, 169], [170, 177], [178, 180], [181, 185], [186, 194], [195, 209], [209, 210]]}
{"doc_key": "ai-dev-59", "ner": [[0, 2, "misc"], [13, 16, "metrics"], [29, 35, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 13, 16, "related-to", "", true, false], [13, 16, 29, 35, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "natural", "gradient", "mathE", "f", "(", "x", ")", "/", "math", ",", "corresponding", "to", "Fisher", "'s", "information", "metric", "(", "a", "measure", "of", "the", "information", "distance", "between", "probability", "distributions", "and", "the", "relative", "entropy", "curve", ")", ",", "now", "reads", "as", "follows"], "sentence-detokenized": "The natural gradient mathE f (x) / math, corresponding to Fisher's information metric (a measure of the information distance between probability distributions and the relative entropy curve), now reads as follows", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 26], [27, 28], [29, 30], [30, 31], [31, 32], [33, 34], [35, 39], [39, 40], [41, 54], [55, 57], [58, 64], [64, 66], [67, 78], [79, 85], [86, 87], [87, 88], [89, 96], [97, 99], [100, 103], [104, 115], [116, 124], [125, 132], [133, 144], [145, 158], [159, 162], [163, 166], [167, 175], [176, 183], [184, 189], [189, 190], [190, 191], [192, 195], [196, 201], [202, 204], [205, 212]]}
{"doc_key": "ai-dev-60", "ner": [[0, 3, "programlang"], [6, 9, "product"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 9, 0, 3, "origin", "", false, false], [11, 11, 0, 3, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "S", "programming", "language", "inspired", "the", "S", "'", "-", "PLUS", "and", "R", "systems", "."], "sentence-detokenized": "The S programming language inspired the S '-PLUS and R systems.", "token2charspan": [[0, 3], [4, 5], [6, 17], [18, 26], [27, 35], [36, 39], [40, 41], [42, 43], [43, 44], [44, 48], [49, 52], [53, 54], [55, 62], [62, 63]]}
{"doc_key": "ai-dev-61", "ner": [[5, 7, "product"], [10, 10, "product"], [12, 16, "product"], [18, 20, "researcher"], [22, 23, "researcher"], [25, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 7, 10, 10, "named", "same", false, false], [12, 16, 10, 10, "origin", "derived_from", false, false], [12, 16, 18, 20, "origin", "", false, false], [12, 16, 22, 23, "origin", "", false, false], [12, 16, 25, 26, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "most", "influential", "implementation", "of", "Planner", "was", "a", "subset", "of", "Planner", "called", "Micro", "-", "Planner", ",", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "."], "sentence-detokenized": "The most influential implementation of Planner was a subset of Planner called Micro-Planner, implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd.", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 35], [36, 38], [39, 46], [47, 50], [51, 52], [53, 59], [60, 62], [63, 70], [71, 77], [78, 83], [83, 84], [84, 91], [91, 92], [93, 104], [105, 107], [108, 114], [115, 118], [119, 126], [126, 127], [128, 134], [135, 143], [144, 147], [148, 153], [154, 162], [162, 163]]}
{"doc_key": "ai-dev-62", "ner": [[4, 6, "country"], [8, 10, "researcher"], [20, 20, "misc"], [21, 27, "university"], [32, 35, "misc"], [38, 38, "misc"], [45, 47, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [[8, 10, 4, 6, "general-affiliation", "from_country", false, false], [21, 27, 20, 20, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "1779", ",", "the", "German", "-", "Danish", "scientist", "Christian", "Gottlieb", "Kratzenstein", "won", "first", "prize", "in", "a", "competition", "run", "by", "the", "Russian", "Imperial", "Academy", "of", "Sciences", "and", "Arts", "for", "models", "of", "the", "human", "vocal", "tract", "that", "produced", "five", "long", "vowels", "(", "in", "the", "notation", "of", "the", "International", "Phonetic", "Alphabet", ":"], "sentence-detokenized": "In 1779, the German-Danish scientist Christian Gottlieb Kratzenstein won first prize in a competition run by the Russian Imperial Academy of Sciences and Arts for models of the human vocal tract that produced five long vowels (in the notation of the International Phonetic Alphabet:", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 19], [19, 20], [20, 26], [27, 36], [37, 46], [47, 55], [56, 68], [69, 72], [73, 78], [79, 84], [85, 87], [88, 89], [90, 101], [102, 105], [106, 108], [109, 112], [113, 120], [121, 129], [130, 137], [138, 140], [141, 149], [150, 153], [154, 158], [159, 162], [163, 169], [170, 172], [173, 176], [177, 182], [183, 188], [189, 194], [195, 199], [200, 208], [209, 213], [214, 218], [219, 225], [226, 227], [227, 229], [230, 233], [234, 242], [243, 245], [246, 249], [250, 263], [264, 272], [273, 281], [281, 282]]}
{"doc_key": "ai-dev-63", "ner": [[3, 4, "product"], [6, 7, "misc"], [10, 15, "misc"], [31, 35, "misc"], [54, 55, "task"], [59, 60, "product"], [62, 62, "product"], [66, 69, "task"], [68, 68, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 4, 59, 60, "related-to", "supports_program", false, false], [3, 4, 62, 62, "related-to", "supports_program", false, false], [6, 7, 3, 4, "part-of", "", false, false], [10, 15, 3, 4, "part-of", "", false, false], [31, 35, 3, 4, "part-of", "", false, false], [54, 55, 3, 4, "part-of", "", false, false], [66, 69, 3, 4, "part-of", "", false, false], [68, 68, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["New", "features", "in", "Office", "XP", "include", "Smart", "Tags", ",", "a", "selection", "-", "based", "search", "function", "that", "recognises", "different", "types", "of", "text", "in", "a", "document", "so", "users", "can", "take", "additional", "actions", ";", "a", "Task", "Pane", "interface", "that", "consolidates", "popular", "menu", "bar", "commands", "on", "the", "right", "side", "of", "the", "screen", "for", "quick", "access", ";", "new", "document", "collaboration", "options", ",", "support", "for", "MSN", "Groups", "and", "SharePoint", ";", "and", "integrated", "handwriting", "and", "speech", "recognition", "."], "sentence-detokenized": "New features in Office XP include Smart Tags, a selection-based search function that recognises different types of text in a document so users can take additional actions; a Task Pane interface that consolidates popular menu bar commands on the right side of the screen for quick access; new document collaboration options, support for MSN Groups and SharePoint; and integrated handwriting and speech recognition.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 22], [23, 25], [26, 33], [34, 39], [40, 44], [44, 45], [46, 47], [48, 57], [57, 58], [58, 63], [64, 70], [71, 79], [80, 84], [85, 95], [96, 105], [106, 111], [112, 114], [115, 119], [120, 122], [123, 124], [125, 133], [134, 136], [137, 142], [143, 146], [147, 151], [152, 162], [163, 170], [170, 171], [172, 173], [174, 178], [179, 183], [184, 193], [194, 198], [199, 211], [212, 219], [220, 224], [225, 228], [229, 237], [238, 240], [241, 244], [245, 250], [251, 255], [256, 258], [259, 262], [263, 269], [270, 273], [274, 279], [280, 286], [286, 287], [288, 291], [292, 300], [301, 314], [315, 322], [322, 323], [324, 331], [332, 335], [336, 339], [340, 346], [347, 350], [351, 361], [361, 362], [363, 366], [367, 377], [378, 389], [390, 393], [394, 400], [401, 412], [412, 413]]}
{"doc_key": "ai-dev-64", "ner": [[11, 12, "algorithm"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 15, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "many", "applications", ",", "the", "units", "of", "these", "networks", "use", "the", "sigmoid", "function", "as", "an", "activation", "function", "."], "sentence-detokenized": "In many applications, the units of these networks use the sigmoid function as an activation function.", "token2charspan": [[0, 2], [3, 7], [8, 20], [20, 21], [22, 25], [26, 31], [32, 34], [35, 40], [41, 49], [50, 53], [54, 57], [58, 65], [66, 74], [75, 77], [78, 80], [81, 91], [92, 100], [100, 101]]}
{"doc_key": "ai-dev-65", "ner": [[0, 0, "researcher"], [8, 18, "organisation"], [21, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 18, "role", "", false, false], [0, 0, 21, 28, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Mehler", "was", "elected", "a", "Foreign", "Honorary", "Member", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "in", "2001", "and", "a", "Fellow", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "in", "2003", "."], "sentence-detokenized": "Mehler was elected a Foreign Honorary Member of the American Academy of Arts and Sciences in 2001 and a Fellow of the American Association for the Advancement of Science in 2003.", "token2charspan": [[0, 6], [7, 10], [11, 18], [19, 20], [21, 28], [29, 37], [38, 44], [45, 47], [48, 51], [52, 60], [61, 68], [69, 71], [72, 76], [77, 80], [81, 89], [90, 92], [93, 97], [98, 101], [102, 103], [104, 110], [111, 113], [114, 117], [118, 126], [127, 138], [139, 142], [143, 146], [147, 158], [159, 161], [162, 169], [170, 172], [173, 177], [177, 178]]}
{"doc_key": "ai-dev-66", "ner": [[4, 6, "task"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 9, 10, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Extending", "this", "concept", "to", "non", "-binary", "classifications", "yields", "a", "confusion", "matrix", "."], "sentence-detokenized": "Extending this concept to non-binary classifications yields a confusion matrix.", "token2charspan": [[0, 9], [10, 14], [15, 22], [23, 25], [26, 29], [29, 36], [37, 52], [53, 59], [60, 61], [62, 71], [72, 78], [78, 79]]}
{"doc_key": "ai-dev-67", "ner": [[14, 16, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "updated", "estimate", "of", "the", "measurement", "noise", "variance", "can", "be", "obtained", "by", "calculating", "the", "maximum", "likelihood", "of"], "sentence-detokenized": "An updated estimate of the measurement noise variance can be obtained by calculating the maximum likelihood of", "token2charspan": [[0, 2], [3, 10], [11, 19], [20, 22], [23, 26], [27, 38], [39, 44], [45, 53], [54, 57], [58, 60], [61, 69], [70, 72], [73, 84], [85, 88], [89, 96], [97, 107], [108, 110]]}
{"doc_key": "ai-dev-68", "ner": [[1, 2, "field"], [5, 5, "algorithm"], [8, 9, "field"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 8, 9, "usage", "", true, false], [5, 5, 12, 13, "related-to", "", true, false], [8, 9, 1, 2, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "machine", "learning", ",", "a", "perceptron", "is", "a", "supervised", "learning", "algorithm", "for", "binary", "classification", "."], "sentence-detokenized": "In machine learning, a perceptron is a supervised learning algorithm for binary classification.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 22], [23, 33], [34, 36], [37, 38], [39, 49], [50, 58], [59, 68], [69, 72], [73, 79], [80, 94], [94, 95]]}
{"doc_key": "ai-dev-69", "ner": [[10, 11, "field"], [13, 13, "field"], [17, 22, "conference"], [25, 29, "conference"], [32, 38, "conference"], [41, 45, "conference"], [48, 52, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[17, 22, 10, 11, "topic", "", false, false], [17, 22, 13, 13, "topic", "", false, false], [25, 29, 10, 11, "topic", "", false, false], [25, 29, 13, 13, "topic", "", false, false], [32, 38, 10, 11, "topic", "", false, false], [32, 38, 13, 13, "topic", "", false, false], [41, 45, 10, 11, "topic", "", false, false], [41, 45, 13, 13, "topic", "", false, false], [48, 52, 10, 11, "topic", "", false, false], [48, 52, 13, 13, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["She", "has", "also", "been", "area", "chair", "of", "several", "conferences", "on", "machine", "learning", "and", "vision", ",", "including", "the", "Conference", "on", "Neural", "Information", "Processing", "Systems", ",", "the", "International", "Conference", "on", "Learning", "Representations", ",", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "the", "International", "Conference", "on", "Computer", "Vision", "and", "the", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "She has also been area chair of several conferences on machine learning and vision, including the Conference on Neural Information Processing Systems, the International Conference on Learning Representations, the Conference on Computer Vision and Pattern Recognition, the International Conference on Computer Vision and the European Conference on Computer Vision.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 17], [18, 22], [23, 28], [29, 31], [32, 39], [40, 51], [52, 54], [55, 62], [63, 71], [72, 75], [76, 82], [82, 83], [84, 93], [94, 97], [98, 108], [109, 111], [112, 118], [119, 130], [131, 141], [142, 149], [149, 150], [151, 154], [155, 168], [169, 179], [180, 182], [183, 191], [192, 207], [207, 208], [209, 212], [213, 223], [224, 226], [227, 235], [236, 242], [243, 246], [247, 254], [255, 266], [266, 267], [268, 271], [272, 285], [286, 296], [297, 299], [300, 308], [309, 315], [316, 319], [320, 323], [324, 332], [333, 343], [344, 346], [347, 355], [356, 362], [362, 363]]}
{"doc_key": "ai-dev-70", "ner": [[0, 4, "algorithm"], [8, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 10, 0, 4, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "condensation", "algorithm", "was", "also", "applied", "to", "the", "face", "recognition", "system", "in", "the", "video", "."], "sentence-detokenized": "The condensation algorithm was also applied to the face recognition system in the video.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 30], [31, 35], [36, 43], [44, 46], [47, 50], [51, 55], [56, 67], [68, 74], [75, 77], [78, 81], [82, 87], [87, 88]]}
{"doc_key": "ai-dev-71", "ner": [[7, 10, "task"], [2, 6, "organisation"], [11, 14, "conference"], [15, 19, "academicjournal"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 14, 7, 10, "topic", "", false, false], [11, 14, 2, 6, "origin", "", false, false], [15, 19, 7, 10, "topic", "", false, false], [15, 19, 2, 6, "origin", "", true, false], [23, 23, 15, 19, "role", "edited_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Part", "of", "ELRA", "'s", "mission", "is", "to", "disseminate", "information", "through", "the", "LREC", "conference", "and", "the", "Language", "Resources", "and", "Evaluation", "Journal", ",", "published", "by", "Springer", "."], "sentence-detokenized": "Part of ELRA's mission is to disseminate information through the LREC conference and the Language Resources and Evaluation Journal, published by Springer.", "token2charspan": [[0, 4], [5, 7], [8, 12], [12, 14], [15, 22], [23, 25], [26, 28], [29, 40], [41, 52], [53, 60], [61, 64], [65, 69], [70, 80], [81, 84], [85, 88], [89, 97], [98, 107], [108, 111], [112, 122], [123, 130], [130, 131], [132, 141], [142, 144], [145, 153], [153, 154]]}
{"doc_key": "ai-dev-72", "ner": [[1, 8, "field"], [10, 11, "field"], [13, 15, "field"], [17, 20, "field"], [50, 53, "field"], [57, 58, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 8, 50, 53, "named", "", false, false], [13, 15, 1, 8, "named", "", false, false], [57, 58, 10, 11, "part-of", "", true, false], [57, 58, 13, 15, "part-of", "", true, false], [57, 58, 50, 53, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "linear", "time", "invariant", "(", "LTI", ")", "systems", "theory", ",", "control", "theory", "and", "digital", "signal", "processing", "or", "signal", "processing", ",", "the", "relationship", "between", "the", "input", "signal", ",", "math\\displaystyle", "x", "(", "t", ")", "/", "math", ",", "and", "the", "output", "signal", ",", "math\\", "displaystyle", "y", "(", "t", ")", "/", "math", ",", "of", "an", "LTI", "system", "is", "governed", "by", "the", "convolution", "operation", ":"], "sentence-detokenized": "In linear time invariant (LTI) systems theory, control theory and digital signal processing or signal processing, the relationship between the input signal, math\\displaystyle x(t)/math, and the output signal, math\\displaystyle y(t)/math, of an LTI system is governed by the convolution operation:", "token2charspan": [[0, 2], [3, 9], [10, 14], [15, 24], [25, 26], [26, 29], [29, 30], [31, 38], [39, 45], [45, 46], [47, 54], [55, 61], [62, 65], [66, 73], [74, 80], [81, 91], [92, 94], [95, 101], [102, 112], [112, 113], [114, 117], [118, 130], [131, 138], [139, 142], [143, 148], [149, 155], [155, 156], [157, 174], [175, 176], [176, 177], [177, 178], [178, 179], [179, 180], [180, 184], [184, 185], [186, 189], [190, 193], [194, 200], [201, 207], [207, 208], [209, 214], [214, 226], [227, 228], [228, 229], [229, 230], [230, 231], [231, 232], [232, 236], [236, 237], [238, 240], [241, 243], [244, 247], [248, 254], [255, 257], [258, 266], [267, 269], [270, 273], [274, 285], [286, 295], [295, 296]]}
{"doc_key": "ai-dev-73", "ner": [[16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 31, "field"], [33, 34, "product"], [36, 37, "field"], [39, 39, "field"], [41, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Because", "of", "its", "generality", ",", "this", "area", "is", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "game", "theory", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimisation", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Because of its generality, this area is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimisation, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 25], [25, 26], [27, 31], [32, 36], [37, 39], [40, 47], [48, 50], [51, 55], [56, 61], [62, 73], [73, 74], [75, 79], [80, 82], [83, 87], [88, 94], [94, 95], [96, 103], [104, 110], [110, 111], [112, 122], [123, 131], [131, 132], [133, 144], [145, 151], [151, 152], [153, 163], [163, 164], [164, 169], [170, 182], [182, 183], [184, 195], [196, 203], [203, 204], [205, 210], [211, 223], [223, 224], [225, 235], [236, 239], [240, 247], [248, 258], [258, 259]]}
{"doc_key": "ai-dev-74", "ner": [[0, 2, "algorithm"], [12, 13, "field"], [19, 21, "algorithm"], [23, 24, "algorithm"], [28, 29, "algorithm"], [32, 32, "algorithm"], [33, 37, "researcher"], [39, 40, "researcher"], [42, 44, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[12, 13, 0, 2, "usage", "", true, false], [19, 21, 12, 13, "part-of", "", true, false], [23, 24, 12, 13, "part-of", "", true, false], [28, 29, 12, 13, "part-of", "", true, false], [32, 32, 12, 13, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Stochastic", "gradient", "descent", "is", "a", "popular", "algorithm", "for", "learning", "many", "models", "in", "machine", "learning", ",", "including", "(", "linear", ")", "support", "vector", "machines", ",", "logistic", "regression", "(", "see", "e.g.", "Vowpal", "Wabbit", ")", "and", "graphical", "models", ".", "Jenny", "Rose", "Finkel", ",", "Alex", "Kleeman", ",", "Christopher", "D.", "Manning", "(", "2008", ")", "."], "sentence-detokenized": "Stochastic gradient descent is a popular algorithm for learning many models in machine learning, including (linear) support vector machines, logistic regression (see e.g. Vowpal Wabbit) and graphical models. Jenny Rose Finkel, Alex Kleeman, Christopher D. Manning (2008).", "token2charspan": [[0, 10], [11, 19], [20, 27], [28, 30], [31, 32], [33, 40], [41, 50], [51, 54], [55, 63], [64, 68], [69, 75], [76, 78], [79, 86], [87, 95], [95, 96], [97, 106], [107, 108], [108, 114], [114, 115], [116, 123], [124, 130], [131, 139], [139, 140], [141, 149], [150, 160], [161, 162], [162, 165], [166, 170], [171, 177], [178, 184], [184, 185], [186, 189], [190, 199], [200, 206], [206, 207], [208, 213], [214, 218], [219, 225], [225, 226], [227, 231], [232, 239], [239, 240], [241, 252], [253, 255], [256, 263], [264, 265], [265, 269], [269, 270], [270, 271]]}
{"doc_key": "ai-dev-75", "ner": [[8, 8, "organisation"], [12, 13, "product"], [21, 21, "country"], [23, 26, "university"], [28, 28, "location"], [30, 32, "university"], [34, 34, "location"], [36, 37, "university"], [39, 39, "location"], [41, 43, "university"], [45, 45, "location"], [47, 48, "university"], [50, 50, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 23, 26, "role", "donates_to", false, false], [8, 8, 30, 32, "role", "donates_to", false, false], [8, 8, 36, 37, "role", "donates_to", false, false], [8, 8, 41, 43, "role", "donates_to", false, false], [8, 8, 47, 48, "role", "donates_to", false, false], [12, 13, 8, 8, "origin", "donates", true, false], [23, 26, 28, 28, "physical", "", false, false], [28, 28, 21, 21, "physical", "", false, false], [30, 32, 34, 34, "physical", "", false, false], [34, 34, 21, 21, "physical", "", false, false], [36, 37, 39, 39, "physical", "", false, false], [39, 39, 21, 21, "physical", "", false, false], [41, 43, 45, 45, "physical", "", false, false], [45, 45, 21, 21, "physical", "", false, false], [47, 48, 50, 50, "physical", "", false, false], [50, 50, 21, 21, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "sentence": ["In", "August", "2011", ",", "it", "was", "announced", "that", "Hitachi", "would", "donate", "an", "electron", "microscope", "to", "each", "of", "the", "five", "universities", "in", "Indonesia", "(", "University", "of", "North", "Sumatra", "in", "Medan", ",", "Indonesian", "Christian", "University", "in", "Jakarta", ",", "Padjadjaran", "University", "in", "Bandung", ",", "Jenderal", "Soedirman", "University", "in", "Purwokerto", "and", "Muhammadiyah", "University", "in", "Malang", ")", "."], "sentence-detokenized": "In August 2011, it was announced that Hitachi would donate an electron microscope to each of the five universities in Indonesia (University of North Sumatra in Medan, Indonesian Christian University in Jakarta, Padjadjaran University in Bandung, Jenderal Soedirman University in Purwokerto and Muhammadiyah University in Malang).", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 18], [19, 22], [23, 32], [33, 37], [38, 45], [46, 51], [52, 58], [59, 61], [62, 70], [71, 81], [82, 84], [85, 89], [90, 92], [93, 96], [97, 101], [102, 114], [115, 117], [118, 127], [128, 129], [129, 139], [140, 142], [143, 148], [149, 156], [157, 159], [160, 165], [165, 166], [167, 177], [178, 187], [188, 198], [199, 201], [202, 209], [209, 210], [211, 222], [223, 233], [234, 236], [237, 244], [244, 245], [246, 254], [255, 264], [265, 275], [276, 278], [279, 289], [290, 293], [294, 306], [307, 317], [318, 320], [321, 327], [327, 328], [328, 329]]}
{"doc_key": "ai-dev-76", "ner": [[0, 0, "field"], [3, 6, "field"], [8, 9, "algorithm"], [11, 26, "algorithm"], [21, 22, "field"], [27, 28, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 6, "part-of", "", false, false], [0, 0, 21, 22, "related-to", "", true, false], [0, 0, 27, 28, "related-to", "", true, false], [8, 9, 0, 0, "type-of", "", false, false], [11, 26, 0, 0, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Optimisation", "techniques", "for", "operations", "research", ",", "such", "as", "linear", "programming", "or", "dynamic", "programming", ",", "are", "often", "impractical", "for", "large", "-", "scale", "software", "engineering", "problems", "due", "to", "their", "computational", "complexity", "."], "sentence-detokenized": "Optimisation techniques for operations research, such as linear programming or dynamic programming, are often impractical for large-scale software engineering problems due to their computational complexity.", "token2charspan": [[0, 12], [13, 23], [24, 27], [28, 38], [39, 47], [47, 48], [49, 53], [54, 56], [57, 63], [64, 75], [76, 78], [79, 86], [87, 98], [98, 99], [100, 103], [104, 109], [110, 121], [122, 125], [126, 131], [131, 132], [132, 137], [138, 146], [147, 158], [159, 167], [168, 171], [172, 174], [175, 180], [181, 194], [195, 205], [205, 206]]}
{"doc_key": "ai-dev-77", "ner": [[0, 0, "metrics"], [6, 6, "metrics"], [8, 10, "metrics"], [15, 22, "metrics"], [17, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 6, "compare", "", false, false], [0, 0, 8, 10, "compare", "", false, false], [15, 22, 8, 10, "part-of", "", false, false], [17, 18, 8, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sensitivity", "is", "not", "the", "same", "as", "precision", "or", "positive", "predictive", "value", "(", "the", "ratio", "of", "correct", "to", "false", "positives", ")", ",", "which", "is", "about", "both", "the", "proportion", "of", "true", "positives", "in", "the", "population", "tested", "and", "the", "test", "."], "sentence-detokenized": "Sensitivity is not the same as precision or positive predictive value (the ratio of correct to false positives), which is about both the proportion of true positives in the population tested and the test.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 22], [23, 27], [28, 30], [31, 40], [41, 43], [44, 52], [53, 63], [64, 69], [70, 71], [71, 74], [75, 80], [81, 83], [84, 91], [92, 94], [95, 100], [101, 110], [110, 111], [111, 112], [113, 118], [119, 121], [122, 127], [128, 132], [133, 136], [137, 147], [148, 150], [151, 155], [156, 165], [166, 168], [169, 172], [173, 183], [184, 190], [191, 194], [195, 198], [199, 203], [203, 204]]}
{"doc_key": "ai-dev-78", "ner": [[0, 1, "person"], [9, 9, "product"], [12, 12, "person"], [30, 30, "person"], [38, 40, "person"], [49, 50, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6], "relations": [[9, 9, 0, 1, "artifact", "", false, false], [38, 40, 49, 50, "role", "convinces", false, false], [49, 50, 9, 9, "role", "producer", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Hampton", "Fancher", "'s", "script", "!", "--", "originally", "not", "titled", "Android", "-", "see", "Sammon", ",", "pp.", "32", "and", "38", "for", "an", "explanation", "--", "was", "an", "optioned", "script", "published", "in", "1977", ".", "Sammon", ",", "pp.", "23", "-", "30", ".", "Producer", "Michael", "Deeley", "was", "interested", "in", "Fancher", "'s", "draft", "and", "persuaded", "director", "Ridley", "Scott", "to", "shoot", "it", "."], "sentence-detokenized": "Hampton Fancher's script! -- originally not titled Android - see Sammon, pp. 32 and 38 for an explanation -- was an optioned script published in 1977. Sammon, pp. 23-30. Producer Michael Deeley was interested in Fancher's draft and persuaded director Ridley Scott to shoot it.", "token2charspan": [[0, 7], [8, 15], [15, 17], [18, 24], [24, 25], [26, 28], [29, 39], [40, 43], [44, 50], [51, 58], [59, 60], [61, 64], [65, 71], [71, 72], [73, 76], [77, 79], [80, 83], [84, 86], [87, 90], [91, 93], [94, 105], [106, 108], [109, 112], [113, 115], [116, 124], [125, 131], [132, 141], [142, 144], [145, 149], [149, 150], [151, 157], [157, 158], [159, 162], [163, 165], [165, 166], [166, 168], [168, 169], [170, 178], [179, 186], [187, 193], [194, 197], [198, 208], [209, 211], [212, 219], [219, 221], [222, 227], [228, 231], [232, 241], [242, 250], [251, 257], [258, 263], [264, 266], [267, 272], [273, 275], [275, 276]]}
{"doc_key": "ai-dev-79", "ner": [[0, 1, "field"], [3, 4, "task"], [6, 8, "task"], [10, 12, "misc"], [14, 15, "field"], [17, 19, "task"], [21, 22, "task"], [24, 25, "field"], [28, 31, "task"], [33, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 4, 0, 1, "part-of", "", false, false], [6, 8, 0, 1, "part-of", "", false, false], [10, 12, 0, 1, "part-of", "", false, false], [14, 15, 0, 1, "part-of", "", false, false], [17, 19, 0, 1, "part-of", "", false, false], [21, 22, 0, 1, "part-of", "", false, false], [24, 25, 0, 1, "part-of", "", false, false], [28, 31, 0, 1, "part-of", "", false, false], [33, 33, 0, 1, "part-of", "", false, false], [35, 36, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Text", "analysis", "includes", "information", "retrieval", ",", "lexical", "analysis", "to", "study", "word", "frequency", "distribution", ",", "pattern", "recognition", ",", "tagging", "/", "annotation", ",", "information", "extraction", ",", "data", "mining", "techniques", "including", "link", "and", "association", "analysis", ",", "visualisation", "and", "predictive", "analytics", "."], "sentence-detokenized": "Text analysis includes information retrieval, lexical analysis to study word frequency distribution, pattern recognition, tagging/annotation, information extraction, data mining techniques including link and association analysis, visualisation and predictive analytics.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 34], [35, 44], [44, 45], [46, 53], [54, 62], [63, 65], [66, 71], [72, 76], [77, 86], [87, 99], [99, 100], [101, 108], [109, 120], [120, 121], [122, 129], [129, 130], [130, 140], [140, 141], [142, 153], [154, 164], [164, 165], [166, 170], [171, 177], [178, 188], [189, 198], [199, 203], [204, 207], [208, 219], [220, 228], [228, 229], [230, 243], [244, 247], [248, 258], [259, 268], [268, 269]]}
{"doc_key": "ai-dev-80", "ner": [[3, 5, "product"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 3, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Several", "metrics", "use", "WordNet", ",", "a", "hand", "-", "crafted", "lexicon", "of", "English", "words", "."], "sentence-detokenized": "Several metrics use WordNet, a hand-crafted lexicon of English words.", "token2charspan": [[0, 7], [8, 15], [16, 19], [20, 27], [27, 28], [29, 30], [31, 35], [35, 36], [36, 43], [44, 51], [52, 54], [55, 62], [63, 68], [68, 69]]}
{"doc_key": "ai-dev-81", "ner": [[8, 9, "field"], [11, 12, "task"], [0, 15, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "answer", "retrieval", "system", "uses", "a", "combination", "of", "computational", "linguistics", ",", "information", "retrieval", "and", "knowledge", "representation", "techniques", "."], "sentence-detokenized": "The answer retrieval system uses a combination of computational linguistics, information retrieval and knowledge representation techniques.", "token2charspan": [[0, 3], [4, 10], [11, 20], [21, 27], [28, 32], [33, 34], [35, 46], [47, 49], [50, 63], [64, 75], [75, 76], [77, 88], [89, 98], [99, 102], [103, 112], [113, 127], [128, 138], [138, 139]]}
{"doc_key": "ai-dev-82", "ner": [[5, 8, "metrics"], [12, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 8, 12, 15, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "performance", "metric", ",", "the", "uncertainty", "coefficient", "is", "preferred", "to", "simple", "precision", "as", "it", "is", "not", "affected", "by", "the", "relative", "sizes", "of", "the", "different", "classes", "."], "sentence-detokenized": "As a performance metric, the uncertainty coefficient is preferred to simple precision as it is not affected by the relative sizes of the different classes.", "token2charspan": [[0, 2], [3, 4], [5, 16], [17, 23], [23, 24], [25, 28], [29, 40], [41, 52], [53, 55], [56, 65], [66, 68], [69, 75], [76, 85], [86, 88], [89, 91], [92, 94], [95, 98], [99, 107], [108, 110], [111, 114], [115, 123], [124, 129], [130, 132], [133, 136], [137, 146], [147, 154], [154, 155]]}
{"doc_key": "ai-dev-83", "ner": [[9, 10, "algorithm"], [12, 13, "algorithm"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Researchers", "have", "used", "a", "number", "of", "methods", "such", "as", "optical", "flow", ",", "Kalman", "filtering", ",", "hidden", "Markov", "models", ",", "etc", "."], "sentence-detokenized": "Researchers have used a number of methods such as optical flow, Kalman filtering, hidden Markov models, etc.", "token2charspan": [[0, 11], [12, 16], [17, 21], [22, 23], [24, 30], [31, 33], [34, 41], [42, 46], [47, 49], [50, 57], [58, 62], [62, 63], [64, 70], [71, 80], [80, 81], [82, 88], [89, 95], [96, 102], [102, 103], [104, 107], [107, 108]]}
{"doc_key": "ai-dev-84", "ner": [[14, 18, "conference"], [38, 41, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "has", "served", "as", "President", ",", "Vice", "-", "President", "and", "Secretary", "-", "Treasurer", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "and", "as", "a", "member", "of", "the", "Board", "of", "Directors", "and", "Secretary", "of", "the", "Board", "of", "Directors", "of", "the", "Association", "for", "Computational", "Research", "."], "sentence-detokenized": "She has served as President, Vice-President and Secretary-Treasurer of the Association for Computational Linguistics, and as a member of the Board of Directors and Secretary of the Board of Directors of the Association for Computational Research.", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 17], [18, 27], [27, 28], [29, 33], [33, 34], [34, 43], [44, 47], [48, 57], [57, 58], [58, 67], [68, 70], [71, 74], [75, 86], [87, 90], [91, 104], [105, 116], [116, 117], [118, 121], [122, 124], [125, 126], [127, 133], [134, 136], [137, 140], [141, 146], [147, 149], [150, 159], [160, 163], [164, 173], [174, 176], [177, 180], [181, 186], [187, 189], [190, 199], [200, 202], [203, 206], [207, 218], [219, 222], [223, 236], [237, 245], [245, 246]]}
{"doc_key": "ai-dev-85", "ner": [[6, 6, "programlang"], [8, 8, "product"], [10, 10, "programlang"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 10, 10, "compare", "", false, false], [6, 6, 12, 13, "related-to", "supports", false, false], [8, 8, 10, 10, "compare", "", false, false], [8, 8, 12, 13, "related-to", "supports", false, false], [10, 10, 12, 13, "related-to", "supports", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Like", "other", "similar", "languages", "such", "as", "APL", "and", "MATLAB", ",", "R", "supports", "matrix", "arithmetic", "."], "sentence-detokenized": "Like other similar languages such as APL and MATLAB, R supports matrix arithmetic.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 28], [29, 33], [34, 36], [37, 40], [41, 44], [45, 51], [51, 52], [53, 54], [55, 63], [64, 70], [71, 81], [81, 82]]}
{"doc_key": "ai-dev-86", "ner": [[10, 11, "misc"], [8, 9, "organisation"], [15, 16, "researcher"], [19, 21, "university"], [25, 30, "misc"], [5, 5, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 11, 8, 9, "physical", "", false, false], [10, 11, 25, 30, "temporal", "", false, false], [15, 16, 10, 11, "role", "arranges", false, false], [15, 16, 19, 21, "role", "works_for", false, false], [5, 5, 10, 11, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["On", "7", "June", "2014", ",", "Goostman", "won", "the", "Royal", "Society", "Turing", "Test", ",", "organised", "by", "Kevin", "Warwick", "of", "the", "University", "of", "Reading", "to", "mark", "the", "60th", "anniversary", "of", "Turing", "'s", "death", ",", "because", "33", "%", "of", "the", "judges", "were", "convinced", "that", "the", "robot", "was", "human", "."], "sentence-detokenized": "On 7 June 2014, Goostman won the Royal Society Turing Test, organised by Kevin Warwick of the University of Reading to mark the 60th anniversary of Turing's death, because 33% of the judges were convinced that the robot was human.", "token2charspan": [[0, 2], [3, 4], [5, 9], [10, 14], [14, 15], [16, 24], [25, 28], [29, 32], [33, 38], [39, 46], [47, 53], [54, 58], [58, 59], [60, 69], [70, 72], [73, 78], [79, 86], [87, 89], [90, 93], [94, 104], [105, 107], [108, 115], [116, 118], [119, 123], [124, 127], [128, 132], [133, 144], [145, 147], [148, 154], [154, 156], [157, 162], [162, 163], [164, 171], [172, 174], [174, 175], [176, 178], [179, 182], [183, 189], [190, 194], [195, 204], [205, 209], [210, 213], [214, 219], [220, 223], [224, 229], [229, 230]]}
{"doc_key": "ai-dev-87", "ner": [[0, 2, "product"], [5, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "collaborative", "robot", ",", "or", "cobot", ",", "is", "a", "robot", "that", "can", "work", "safely", "and", "efficiently", "with", "human", "workers", "to", "perform", "simple", "industrial", "tasks", "."], "sentence-detokenized": "A collaborative robot, or cobot, is a robot that can work safely and efficiently with human workers to perform simple industrial tasks.", "token2charspan": [[0, 1], [2, 15], [16, 21], [21, 22], [23, 25], [26, 31], [31, 32], [33, 35], [36, 37], [38, 43], [44, 48], [49, 52], [53, 57], [58, 64], [65, 68], [69, 80], [81, 85], [86, 91], [92, 99], [100, 102], [103, 110], [111, 117], [118, 128], [129, 134], [134, 135]]}
{"doc_key": "ai-dev-88", "ner": [[13, 14, "field"], [17, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "task"], [29, 30, "task"], [32, 34, "task"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[17, 18, 13, 14, "part-of", "task_part_of_field", false, false], [20, 21, 13, 14, "part-of", "task_part_of_field", false, false], [23, 24, 13, 14, "part-of", "task_part_of_field", false, false], [26, 27, 13, 14, "part-of", "task_part_of_field", false, false], [29, 30, 13, 14, "part-of", "task_part_of_field", false, false], [32, 34, 13, 14, "part-of", "task_part_of_field", false, false], [36, 37, 13, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["This", "general", "framework", "has", "been", "applied", "to", "a", "wide", "variety", "of", "problems", "in", "computer", "vision", ",", "including", "feature", "detection", ",", "feature", "classification", ",", "image", "segmentation", ",", "image", "matching", ",", "motion", "estimation", ",", "shape", "feature", "computation", "and", "object", "recognition", "."], "sentence-detokenized": "This general framework has been applied to a wide variety of problems in computer vision, including feature detection, feature classification, image segmentation, image matching, motion estimation, shape feature computation and object recognition.", "token2charspan": [[0, 4], [5, 12], [13, 22], [23, 26], [27, 31], [32, 39], [40, 42], [43, 44], [45, 49], [50, 57], [58, 60], [61, 69], [70, 72], [73, 81], [82, 88], [88, 89], [90, 99], [100, 107], [108, 117], [117, 118], [119, 126], [127, 141], [141, 142], [143, 148], [149, 161], [161, 162], [163, 168], [169, 177], [177, 178], [179, 185], [186, 196], [196, 197], [198, 203], [204, 211], [212, 223], [224, 227], [228, 234], [235, 246], [246, 247]]}
{"doc_key": "ai-dev-89", "ner": [[12, 13, "task"], [15, 17, "algorithm"], [6, 19, "algorithm"], [28, 29, "algorithm"], [33, 34, "algorithm"], [37, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 13, 15, 17, "part-of", "", false, false], [12, 13, 6, 19, "usage", "", false, false], [15, 17, 28, 29, "named", "same", false, false], [28, 29, 33, 34, "related-to", "", false, false], [28, 29, 37, 38, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "many", "practical", "applications", ",", "the", "maximum", "likelihood", "method", "is", "used", "in", "parameter", "estimation", "for", "naive", "Bayesian", "models", ";", "in", "other", "words", ",", "we", "can", "work", "with", "a", "naive", "Bayesian", "model", "without", "accepting", "Bayesian", "likelihood", "or", "using", "Bayesian", "methods", "."], "sentence-detokenized": "In many practical applications, the maximum likelihood method is used in parameter estimation for naive Bayesian models; in other words, we can work with a naive Bayesian model without accepting Bayesian likelihood or using Bayesian methods.", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 30], [30, 31], [32, 35], [36, 43], [44, 54], [55, 61], [62, 64], [65, 69], [70, 72], [73, 82], [83, 93], [94, 97], [98, 103], [104, 112], [113, 119], [119, 120], [121, 123], [124, 129], [130, 135], [135, 136], [137, 139], [140, 143], [144, 148], [149, 153], [154, 155], [156, 161], [162, 170], [171, 176], [177, 184], [185, 194], [195, 203], [204, 214], [215, 217], [218, 223], [224, 232], [233, 240], [240, 241]]}
{"doc_key": "ai-dev-90", "ner": [[2, 4, "researcher"], [6, 7, "misc"], [12, 15, "university"], [17, 19, "researcher"], [21, 22, "misc"], [26, 26, "university"], [28, 28, "university"], [31, 31, "misc"], [37, 39, "university"], [45, 48, "misc"], [50, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[2, 4, 12, 15, "physical", "", false, false], [2, 4, 12, 15, "role", "", false, false], [2, 4, 17, 19, "social", "brothers", false, false], [6, 7, 2, 4, "named", "", false, false], [17, 19, 26, 26, "physical", "", false, false], [17, 19, 26, 26, "role", "", false, false], [17, 19, 28, 28, "physical", "", false, false], [17, 19, 28, 28, "role", "", false, false], [17, 19, 37, 39, "physical", "", false, false], [17, 19, 37, 39, "role", "", false, false], [21, 22, 17, 19, "named", "", false, false], [31, 31, 17, 19, "origin", "", false, false], [45, 48, 17, 19, "artifact", "", false, false], [45, 48, 50, 53, "part-of", "part", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Brothers", "-", "Victor", "Gershevich", "Katz", ",", "American", "mathematician", ",", "professor", "at", "the", "Massachusetts", "Institute", "of", "Technology", ";", "Mikhail", "Gershevich", "Katz", ",", "Israeli", "mathematician", ",", "graduate", "of", "Harvard", "and", "Columbia", "Universities", "(", "Ph.D.", "1984", ")", ",", "professor", "at", "Bar-", "Ilan", "University", ",", "author", "of", "the", "monograph", "Systolic", "Geometry", "and", "Topology", "(", "Mathematical", "Surveys", "and", "Monographs", ",", "vol", "."], "sentence-detokenized": "Brothers - Victor Gershevich Katz, American mathematician, professor at the Massachusetts Institute of Technology; Mikhail Gershevich Katz, Israeli mathematician, graduate of Harvard and Columbia Universities (Ph.D. 1984), professor at Bar-Ilan University, author of the monograph Systolic Geometry and Topology (Mathematical Surveys and Monographs, vol.", "token2charspan": [[0, 8], [9, 10], [11, 17], [18, 28], [29, 33], [33, 34], [35, 43], [44, 57], [57, 58], [59, 68], [69, 71], [72, 75], [76, 89], [90, 99], [100, 102], [103, 113], [113, 114], [115, 122], [123, 133], [134, 138], [138, 139], [140, 147], [148, 161], [161, 162], [163, 171], [172, 174], [175, 182], [183, 186], [187, 195], [196, 208], [209, 210], [210, 215], [216, 220], [220, 221], [221, 222], [223, 232], [233, 235], [236, 240], [240, 244], [245, 255], [255, 256], [257, 263], [264, 266], [267, 270], [271, 280], [281, 289], [290, 298], [299, 302], [303, 311], [312, 313], [313, 325], [326, 333], [334, 337], [338, 348], [348, 349], [350, 353], [353, 354]]}
{"doc_key": "ai-dev-91", "ner": [[3, 4, "person"], [10, 12, "conference"], [15, 21, "organisation"], [22, 28, "location"], [33, 33, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 10, 12, "physical", "", false, false], [3, 4, 10, 12, "role", "", false, false], [3, 4, 15, 21, "role", "", false, false], [15, 21, 22, 28, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2000", ",", "Manuel", "Toharia", ",", "a", "speaker", "at", "previous", "Campus", "Parties", "and", "Director", "of", "the", "Principe", "Felipe", "Science", "Museum", "in", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", ",", "proposed", "to", "expand", "Ragageles", "and", "make", "the", "event", "more", "international", "by", "moving", "it", "to", "this", "famous", "museum", "."], "sentence-detokenized": "In 2000, Manuel Toharia, a speaker at previous Campus Parties and Director of the Principe Felipe Science Museum in the City of Arts and Sciences in Valencia, proposed to expand Ragageles and make the event more international by moving it to this famous museum.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 23], [23, 24], [25, 26], [27, 34], [35, 37], [38, 46], [47, 53], [54, 61], [62, 65], [66, 74], [75, 77], [78, 81], [82, 90], [91, 97], [98, 105], [106, 112], [113, 115], [116, 119], [120, 124], [125, 127], [128, 132], [133, 136], [137, 145], [146, 148], [149, 157], [157, 158], [159, 167], [168, 170], [171, 177], [178, 187], [188, 191], [192, 196], [197, 200], [201, 206], [207, 211], [212, 225], [226, 228], [229, 235], [236, 238], [239, 241], [242, 246], [247, 253], [254, 260], [260, 261]]}
{"doc_key": "ai-dev-92", "ner": [[4, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Within", "20", "minutes", ",", "the", "facial", "recognition", "system", "recognises", "personal", "data", ",", "including", "family", "name", ",", "ID", "number", "and", "address", ",", "displayed", "on", "the", "street", "on", "a", "billboard", "."], "sentence-detokenized": "Within 20 minutes, the facial recognition system recognises personal data, including family name, ID number and address, displayed on the street on a billboard.", "token2charspan": [[0, 6], [7, 9], [10, 17], [17, 18], [19, 22], [23, 29], [30, 41], [42, 48], [49, 59], [60, 68], [69, 73], [73, 74], [75, 84], [85, 91], [92, 96], [96, 97], [98, 100], [101, 107], [108, 111], [112, 119], [119, 120], [121, 130], [131, 133], [134, 137], [138, 144], [145, 147], [148, 149], [150, 159], [159, 160]]}
{"doc_key": "ai-dev-93", "ner": [[6, 7, "field"], [9, 11, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Recent", "research", "is", "increasingly", "focusing", "on", "unsupervised", "learning", "and", "semi-supervised", "learning", "algorithms", "."], "sentence-detokenized": "Recent research is increasingly focusing on unsupervised learning and semi-supervised learning algorithms.", "token2charspan": [[0, 6], [7, 15], [16, 18], [19, 31], [32, 40], [41, 43], [44, 56], [57, 65], [66, 69], [70, 85], [86, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-dev-94", "ner": [[4, 5, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Calculating", "this", "example", "with", "Python", "code", ":"], "sentence-detokenized": "Calculating this example with Python code:", "token2charspan": [[0, 11], [12, 16], [17, 24], [25, 29], [30, 36], [37, 41], [41, 42]]}
{"doc_key": "ai-dev-95", "ner": [[7, 9, "task"], [15, 16, "field"], [19, 22, "algorithm"], [24, 24, "algorithm"], [28, 31, "algorithm"], [35, 36, "researcher"], [38, 39, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[19, 22, 15, 16, "part-of", "", false, false], [19, 22, 28, 31, "type-of", "", false, false], [19, 22, 35, 36, "origin", "", false, false], [19, 22, 38, 39, "origin", "", false, false], [24, 24, 19, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Today", ",", "however", ",", "many", "aspects", "of", "speech", "recognition", "have", "been", "taken", "over", "by", "a", "deep", "learning", "method", "called", "Long", "Short", "Term", "Memory", "(", "LSTM", ")", ",", "a", "recurrent", "neural", "network", "published", "in", "1997", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Today, however, many aspects of speech recognition have been taken over by a deep learning method called Long Short Term Memory (LSTM), a recurrent neural network published in 1997 by Sepp Hochreiter and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 5], [5, 6], [7, 14], [14, 15], [16, 20], [21, 28], [29, 31], [32, 38], [39, 50], [51, 55], [56, 60], [61, 66], [67, 71], [72, 74], [75, 76], [77, 81], [82, 90], [91, 97], [98, 104], [105, 109], [110, 115], [116, 120], [121, 127], [128, 129], [129, 133], [133, 134], [134, 135], [136, 137], [138, 147], [148, 154], [155, 162], [163, 172], [173, 175], [176, 180], [181, 183], [184, 188], [189, 199], [200, 203], [204, 210], [211, 222], [222, 223]]}
{"doc_key": "ai-dev-96", "ner": [[10, 10, "algorithm"], [12, 15, "algorithm"], [19, 19, "algorithm"], [24, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 12, 15, "compare", "", false, false], [10, 10, 24, 24, "named", "same", false, false], [19, 19, 24, 24, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "preliminary", "experimental", "results", "with", "high", "-", "noise", "datasets", ",", "BrownBoost", "outperformed", "AdaBoost", "in", "generalisation", "error", ";", "however", ",", "LogitBoost", "performed", "as", "well", "as", "BrownBoost", "."], "sentence-detokenized": "In preliminary experimental results with high-noise datasets, BrownBoost outperformed AdaBoost in generalisation error; however, LogitBoost performed as well as BrownBoost.", "token2charspan": [[0, 2], [3, 14], [15, 27], [28, 35], [36, 40], [41, 45], [45, 46], [46, 51], [52, 60], [60, 61], [62, 72], [73, 85], [86, 94], [95, 97], [98, 112], [113, 118], [118, 119], [120, 127], [127, 128], [129, 139], [140, 149], [150, 152], [153, 157], [158, 160], [161, 171], [171, 172]]}
{"doc_key": "ai-dev-97", "ner": [[0, 4, "algorithm"], [5, 7, "researcher"], [10, 11, "country"], [12, 14, "researcher"], [18, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 5, 7, "part-of", "", false, false], [5, 7, 10, 11, "physical", "", false, false], [18, 20, 12, 14, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Evolutionary", "programming", "was", "introduced", "by", "Lawrence", "J.", "Fogel", "in", "the", "USA", "and", "John", "Henry", "Holland", "called", "his", "method", "the", "genetic", "algorithm", "."], "sentence-detokenized": "Evolutionary programming was introduced by Lawrence J. Fogel in the USA and John Henry Holland called his method the genetic algorithm.", "token2charspan": [[0, 12], [13, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 54], [55, 60], [61, 63], [64, 67], [68, 71], [72, 75], [76, 80], [81, 86], [87, 94], [95, 101], [102, 105], [106, 112], [113, 116], [117, 124], [125, 134], [134, 135]]}
{"doc_key": "ai-dev-98", "ner": [[2, 2, "researcher"], [4, 4, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 10, 11, "role", "", false, false], [2, 2, 13, 14, "role", "", false, false], [2, 2, 16, 17, "role", "", false, false], [2, 2, 19, 22, "role", "", false, false], [4, 4, 10, 11, "role", "", false, false], [4, 4, 13, 14, "role", "", false, false], [4, 4, 16, 17, "role", "", false, false], [4, 4, 19, 22, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Calculations", "by", "Doug", ",", "Alan", "and", "their", "colleagues", "(", "including", "Marvin", "Minsky", ",", "Allen", "Newell", ",", "Edward", "Feigenbaum", "and", "John", "McCarthy", ")", "showed", "that", "this", "effort", "would", "require", "between", "1000", "and", "3000", "man", "-", "years", "of", "work", ",", "far", "beyond", "the", "standard", "academic", "project", "model", "."], "sentence-detokenized": "Calculations by Doug, Alan and their colleagues (including Marvin Minsky, Allen Newell, Edward Feigenbaum and John McCarthy) showed that this effort would require between 1000 and 3000 man-years of work, far beyond the standard academic project model.", "token2charspan": [[0, 12], [13, 15], [16, 20], [20, 21], [22, 26], [27, 30], [31, 36], [37, 47], [48, 49], [49, 58], [59, 65], [66, 72], [72, 73], [74, 79], [80, 86], [86, 87], [88, 94], [95, 105], [106, 109], [110, 114], [115, 123], [123, 124], [125, 131], [132, 136], [137, 141], [142, 148], [149, 154], [155, 162], [163, 170], [171, 175], [176, 179], [180, 184], [185, 188], [188, 189], [189, 194], [195, 197], [198, 202], [202, 203], [204, 207], [208, 214], [215, 218], [219, 227], [228, 236], [237, 244], [245, 250], [250, 251]]}
{"doc_key": "ai-dev-99", "ner": [[4, 6, "metrics"], [10, 11, "metrics"], [13, 15, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 10, 11, "part-of", "implemented_in", false, false], [13, 15, 18, 18, "part-of", "implemented_in", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Common", "measures", "are", "the", "mean", "squared", "error", "measure", "implemented", "in", "MSECriterion", "and", "the", "cross", "-entropy", "measure", "implemented", "in", "NLLCriterion", "."], "sentence-detokenized": "Common measures are the mean squared error measure implemented in MSECriterion and the cross-entropy measure implemented in NLLCriterion.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 23], [24, 28], [29, 36], [37, 42], [43, 50], [51, 62], [63, 65], [66, 78], [79, 82], [83, 86], [87, 92], [92, 100], [101, 108], [109, 120], [121, 123], [124, 136], [136, 137]]}
{"doc_key": "ai-dev-100", "ner": [[0, 1, "researcher"], [11, 11, "organisation"], [17, 30, "misc"], [31, 40, "conference"], [41, 55, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 11, 11, "role", "", false, false], [0, 1, 31, 40, "role", "", false, false], [0, 1, 41, 55, "role", "", false, false], [17, 30, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Zurada", "has", "served", "the", "engineering", "profession", "as", "a", "long", "-", "time", "IEEE", "volunteer", ":", "he", "served", "as", "IEEE", "Vice", "President", "for", "Technical", "Activities", "(", "TAB", "Chair", ")", "in", "2014", ",", "IEEE", "Computational", "Intelligence", "Society", "President", "in", "2004", "-", "05", ",", "and", "ADCOM", "member", "in", "2009", "-", "14", ",", "2016", "-", "18", ",", "and", "in", "previous", "years", "."], "sentence-detokenized": "Zurada has served the engineering profession as a long-time IEEE volunteer: he served as IEEE Vice President for Technical Activities (TAB Chair) in 2014, IEEE Computational Intelligence Society President in 2004-05, and ADCOM member in 2009-14, 2016-18, and in previous years.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 21], [22, 33], [34, 44], [45, 47], [48, 49], [50, 54], [54, 55], [55, 59], [60, 64], [65, 74], [74, 75], [76, 78], [79, 85], [86, 88], [89, 93], [94, 98], [99, 108], [109, 112], [113, 122], [123, 133], [134, 135], [135, 138], [139, 144], [144, 145], [146, 148], [149, 153], [153, 154], [155, 159], [160, 173], [174, 186], [187, 194], [195, 204], [205, 207], [208, 212], [212, 213], [213, 215], [215, 216], [217, 220], [221, 226], [227, 233], [234, 236], [237, 241], [241, 242], [242, 244], [244, 245], [246, 250], [250, 251], [251, 253], [253, 254], [255, 258], [259, 261], [262, 270], [271, 276], [276, 277]]}
{"doc_key": "ai-dev-101", "ner": [[3, 4, "field"], [12, 13, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 13, 3, 4, "part-of", "", false, false], [15, 16, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "general", ",", "computational", "linguistics", "includes", ",", "among", "others", ",", "linguists", ",", "computer", "scientists", ",", "artificial", "intelligence", "experts", ",", "mathematicians", ",", "logicians", ",", "philosophers", ",", "cognitive", "scientists", ",", "cognitive", "psychologists", ",", "psycholinguists", ",", "anthropologists", "and", "neuroscientists", "."], "sentence-detokenized": "In general, computational linguistics includes, among others, linguists, computer scientists, artificial intelligence experts, mathematicians, logicians, philosophers, cognitive scientists, cognitive psychologists, psycholinguists, anthropologists and neuroscientists.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 25], [26, 37], [38, 46], [46, 47], [48, 53], [54, 60], [60, 61], [62, 71], [71, 72], [73, 81], [82, 92], [92, 93], [94, 104], [105, 117], [118, 125], [125, 126], [127, 141], [141, 142], [143, 152], [152, 153], [154, 166], [166, 167], [168, 177], [178, 188], [188, 189], [190, 199], [200, 213], [213, 214], [215, 230], [230, 231], [232, 247], [248, 251], [252, 267], [267, 268]]}
{"doc_key": "ai-dev-102", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "-", "term", "memory", "are", "often", "used", "to", "exploit", "correlations", "between", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and long-term memory are often used to exploit correlations between frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [82, 83], [83, 87], [88, 94], [95, 98], [99, 104], [105, 109], [110, 112], [113, 120], [121, 133], [134, 141], [142, 148], [148, 149]]}
{"doc_key": "ai-dev-103", "ner": [[0, 2, "product"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Unimate", "was", "the", "first", "industrial", "robot", ","], "sentence-detokenized": "Unimate was the first industrial robot,", "token2charspan": [[0, 7], [8, 11], [12, 15], [16, 21], [22, 32], [33, 38], [38, 39]]}
{"doc_key": "ai-dev-104", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [0, 0, "researcher"], [13, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 13, 15, "win-defeat", "", false, false], [7, 8, 13, 15, "win-defeat", "", false, false], [0, 0, 13, 15, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Bengio", ",", "along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "was", "awarded", "the", "2018", "Turing", "Prize", "."], "sentence-detokenized": "Bengio, along with Geoffrey Hinton and Yann LeCun, was awarded the 2018 Turing Prize.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 18], [19, 27], [28, 34], [35, 38], [39, 43], [44, 49], [49, 50], [51, 54], [55, 62], [63, 66], [67, 71], [72, 78], [79, 84], [84, 85]]}
{"doc_key": "ai-dev-105", "ner": [[8, 8, "country"], [19, 22, "misc"], [28, 29, "country"], [32, 33, "organisation"], [37, 40, "person"], [41, 42, "person"], [49, 53, "misc"], [57, 57, "country"], [63, 63, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[19, 22, 8, 8, "physical", "filmed_in", false, false], [37, 40, 32, 33, "role", "host", false, false], [41, 42, 32, 33, "role", "reporter", false, false], [49, 53, 8, 8, "physical", "filmed_in", false, false], [49, 53, 57, 57, "physical", "distributed_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Additional", "series", "were", "filmed", "on", "location", "in", "the", "UK", "for", "specific", "sectors", "of", "the", "global", "market", ",", "including", "two", "Robot", "Wars", "Extreme", "Warriors", "series", "with", "contestants", "from", "the", "United", "States", "for", "the", "TNN", "network", "(", "hosted", "by", "Mick", "Foley", ",", "with", "Rebecca", "Grant", "as", "field", "reporter", ")", ",", "two", "Dutch", "Robot", "Wars", "series", "for", "distribution", "in", "the", "Netherlands", ",", "and", "one", "series", "for", "Germany", "."], "sentence-detokenized": "Additional series were filmed on location in the UK for specific sectors of the global market, including two Robot Wars Extreme Warriors series with contestants from the United States for the TNN network (hosted by Mick Foley, with Rebecca Grant as field reporter), two Dutch Robot Wars series for distribution in the Netherlands, and one series for Germany.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 29], [30, 32], [33, 41], [42, 44], [45, 48], [49, 51], [52, 55], [56, 64], [65, 72], [73, 75], [76, 79], [80, 86], [87, 93], [93, 94], [95, 104], [105, 108], [109, 114], [115, 119], [120, 127], [128, 136], [137, 143], [144, 148], [149, 160], [161, 165], [166, 169], [170, 176], [177, 183], [184, 187], [188, 191], [192, 195], [196, 203], [204, 205], [205, 211], [212, 214], [215, 219], [220, 225], [225, 226], [227, 231], [232, 239], [240, 245], [246, 248], [249, 254], [255, 263], [263, 264], [264, 265], [266, 269], [270, 275], [276, 281], [282, 286], [287, 293], [294, 297], [298, 310], [311, 313], [314, 317], [318, 329], [329, 330], [331, 334], [335, 338], [339, 345], [346, 349], [350, 357], [357, 358]]}
{"doc_key": "ai-dev-106", "ner": [[6, 7, "researcher"], [12, 14, "product"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 12, 14, "role", "", false, false], [28, 29, 12, 14, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Since", "1986", ",", "Miller", "has", "spent", "several", "years", "leading", "the", "development", "of", "WordNet", ",", "a", "large", "-", "scale", "computer", "-", "readable", "electronic", "manual", "used", "in", "applications", "such", "as", "search", "engines", "."], "sentence-detokenized": "Since 1986, Miller has spent several years leading the development of WordNet, a large-scale computer-readable electronic manual used in applications such as search engines.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 18], [19, 22], [23, 28], [29, 36], [37, 42], [43, 50], [51, 54], [55, 66], [67, 69], [70, 77], [77, 78], [79, 80], [81, 86], [86, 87], [87, 92], [93, 101], [101, 102], [102, 110], [111, 121], [122, 128], [129, 133], [134, 136], [137, 149], [150, 154], [155, 157], [158, 164], [165, 172], [172, 173]]}
{"doc_key": "ai-dev-107", "ner": [[3, 5, "algorithm"], [7, 10, "algorithm"], [13, 15, "researcher"], [20, 23, "organisation"], [27, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 13, 15, "origin", "", false, false], [3, 5, 27, 29, "win-defeat", "", false, false], [7, 10, 13, 15, "origin", "", false, false], [7, 10, 27, 29, "win-defeat", "", false, false], [13, 15, 20, 23, "physical", "", false, false], [13, 15, 20, 23, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Since", "2009", ",", "recurrent", "neural", "networks", "and", "deep", "feedforward", "neural", "networks", "developed", "in", "J\u00fcrgen", "Schmidhuber", "'s", "research", "group", "at", "the", "IDSIA", "lab", "in", "Switzerland", "have", "won", "several", "international", "handwriting", "competitions", "."], "sentence-detokenized": "Since 2009, recurrent neural networks and deep feedforward neural networks developed in J\u00fcrgen Schmidhuber's research group at the IDSIA lab in Switzerland have won several international handwriting competitions.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 21], [22, 28], [29, 37], [38, 41], [42, 46], [47, 58], [59, 65], [66, 74], [75, 84], [85, 87], [88, 94], [95, 106], [106, 108], [109, 117], [118, 123], [124, 126], [127, 130], [131, 136], [137, 140], [141, 143], [144, 155], [156, 160], [161, 164], [165, 172], [173, 186], [187, 198], [199, 211], [211, 212]]}
{"doc_key": "ai-dev-108", "ner": [[5, 6, "programlang"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "software", "is", "implemented", "in", "C", "++", "and", "wrapped", "in", "Python", "."], "sentence-detokenized": "The software is implemented in C++ and wrapped in Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 30], [31, 32], [32, 34], [35, 38], [39, 46], [47, 49], [50, 56], [56, 57]]}
{"doc_key": "ai-dev-109", "ner": [[7, 9, "country"], [3, 15, "misc"], [20, 21, "misc"], [33, 33, "misc"], [36, 36, "misc"], [38, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 21, 7, 9, "temporal", "", false, false], [20, 21, 3, 15, "artifact", "", false, false], [20, 21, 38, 38, "physical", "", false, false], [36, 36, 33, 33, "named", "", false, false], [36, 36, 38, 38, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1857", ",", "at", "the", "request", "of", "the", "Tokugawa", "shogunate", ",", "a", "group", "of", "Dutch", "engineers", "began", "construction", "of", "the", "Nagasaki", "Yotetsusho", ",", "a", "modern", "western", "-", "style", "foundry", "and", "shipyard", "near", "the", "Dutch", "settlement", "of", "Dejima", "in", "Nagasaki", "."], "sentence-detokenized": "In 1857, at the request of the Tokugawa shogunate, a group of Dutch engineers began construction of the Nagasaki Yotetsusho, a modern western-style foundry and shipyard near the Dutch settlement of Dejima in Nagasaki.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 39], [40, 49], [49, 50], [51, 52], [53, 58], [59, 61], [62, 67], [68, 77], [78, 83], [84, 96], [97, 99], [100, 103], [104, 112], [113, 123], [123, 124], [125, 126], [127, 133], [134, 141], [141, 142], [142, 147], [148, 155], [156, 159], [160, 168], [169, 173], [174, 177], [178, 183], [184, 194], [195, 197], [198, 204], [205, 207], [208, 216], [216, 217]]}
{"doc_key": "ai-dev-110", "ner": [[7, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["We", "measure", "as", "accurately", "as", "possible", "the", "mean", "squared", "error", "between", "mathy", "/", "math", "and", "math\\hat", "{", "f", "}", "(", "x", ";", "D", ")", "/", "math", ":", "we", "want", "math", "(", "y", "-\\hat", "{", "f", "}", "(", "x", ";", "D", ")", ")", "^", "2", "/", "math", "to", "be", "minimal", ",", "both", "for", "mathx", "_", "1", ",\\", "points", ",", "x", "_n", "/", "math", "and", "for", "points", "outside", "our", "sample", "."], "sentence-detokenized": "We measure as accurately as possible the mean squared error between mathy/math and math\\hat {f} (x; D) / math: we want math (y -\\hat {f} (x; D)) ^ 2 / math to be minimal, both for mathx _ 1,\\ points, x _n / math and for points outside our sample.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 24], [25, 27], [28, 36], [37, 40], [41, 45], [46, 53], [54, 59], [60, 67], [68, 73], [73, 74], [74, 78], [79, 82], [83, 91], [92, 93], [93, 94], [94, 95], [96, 97], [97, 98], [98, 99], [100, 101], [101, 102], [103, 104], [105, 109], [109, 110], [111, 113], [114, 118], [119, 123], [124, 125], [125, 126], [127, 132], [133, 134], [134, 135], [135, 136], [137, 138], [138, 139], [139, 140], [141, 142], [142, 143], [143, 144], [145, 146], [147, 148], [149, 150], [151, 155], [156, 158], [159, 161], [162, 169], [169, 170], [171, 175], [176, 179], [180, 185], [186, 187], [188, 189], [189, 191], [192, 198], [198, 199], [200, 201], [202, 204], [205, 206], [207, 211], [212, 215], [216, 219], [220, 226], [227, 234], [235, 238], [239, 245], [245, 246]]}
{"doc_key": "ai-dev-111", "ner": [[2, 5, "researcher"], [9, 13, "organisation"], [20, 27, "product"], [32, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 5, 9, 13, "role", "", false, false], [20, 27, 9, 13, "temporal", "", false, false], [20, 27, 32, 33, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "then", "invited", "Wydner", "to", "the", "annual", "meeting", "of", "the", "American", "Translators", "Association", "in", "October", "the", "following", "year", ",", "where", "Weidner", "'s", "machine", "translation", "system", "was", "hailed", "as", "the", "expected", "breakthrough", "in", "machine", "translation", "."], "sentence-detokenized": "He then invited Wydner to the annual meeting of the American Translators Association in October the following year, where Weidner's machine translation system was hailed as the expected breakthrough in machine translation.", "token2charspan": [[0, 2], [3, 7], [8, 15], [16, 22], [23, 25], [26, 29], [30, 36], [37, 44], [45, 47], [48, 51], [52, 60], [61, 72], [73, 84], [85, 87], [88, 95], [96, 99], [100, 109], [110, 114], [114, 115], [116, 121], [122, 129], [129, 131], [132, 139], [140, 151], [152, 158], [159, 162], [163, 169], [170, 172], [173, 176], [177, 185], [186, 198], [199, 201], [202, 209], [210, 221], [221, 222]]}
{"doc_key": "ai-dev-112", "ner": [[8, 12, "conference"], [14, 14, "conference"], [2, 2, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 8, 12, "named", "", false, false], [14, 14, 8, 12, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Researchers", "from", "Google", "presented", "this", "work", "at", "the", "2018", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "conference", "."], "sentence-detokenized": "Researchers from Google presented this work at the 2018 Neural Information Processing Systems (NeurIPS) conference.", "token2charspan": [[0, 11], [12, 16], [17, 23], [24, 33], [34, 38], [39, 43], [44, 46], [47, 50], [51, 55], [56, 62], [63, 74], [75, 85], [86, 93], [94, 95], [95, 102], [102, 103], [104, 114], [114, 115]]}
{"doc_key": "ai-dev-113", "ner": [[0, 4, "algorithm"], [10, 12, "algorithm"], [15, 18, "metrics"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 4, 10, 12, "usage", "", false, false], [10, 12, 15, 18, "related-to", "", true, false], [15, 18, 23, 25, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Baum", "-", "Welch", "algorithm", "uses", "the", "well", "-", "known", "EM", "algorithm", "to", "find", "the", "maximum", "likelihood", "estimate", "of", "the", "parameters", "of", "the", "hidden", "Markov", "model", "given", "a", "set", "of", "observed", "feature", "vectors", "."], "sentence-detokenized": "The Baum-Welch algorithm uses the well-known EM algorithm to find the maximum likelihood estimate of the parameters of the hidden Markov model given a set of observed feature vectors.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 14], [15, 24], [25, 29], [30, 33], [34, 38], [38, 39], [39, 44], [45, 47], [48, 57], [58, 60], [61, 65], [66, 69], [70, 77], [78, 88], [89, 97], [98, 100], [101, 104], [105, 115], [116, 118], [119, 122], [123, 129], [130, 136], [137, 142], [143, 148], [149, 150], [151, 154], [155, 157], [158, 166], [167, 174], [175, 182], [182, 183]]}
{"doc_key": "ai-dev-114", "ner": [[9, 9, "product"], [11, 11, "product"], [29, 30, "misc"], [35, 43, "product"], [53, 53, "programlang"], [46, 52, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 9, 11, 11, "compare", "", false, false], [29, 30, 11, 11, "part-of", "", false, false], [35, 43, 11, 11, "part-of", "", false, false], [46, 52, 11, 11, "part-of", "", false, false], [46, 52, 53, 53, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": [")", "In", "addition", "to", "the", "taxonomic", "information", "contained", "in", "OpenCyc", ",", "ResearchCyc", "includes", "significantly", "more", "semantic", "knowledge", "(", "i.e.", "additional", "facts", "and", "rules", ")", "involving", "the", "concepts", "in", "its", "knowledge", "base", ";", "it", "also", "includes", "an", "extensive", "lexicon", ",", "parsing", "and", "English", "generation", "tools", ",", "and", "interfaces", "for", "knowledge", "editing", "and", "querying", "in", "Java", "."], "sentence-detokenized": ") In addition to the taxonomic information contained in OpenCyc, ResearchCyc includes significantly more semantic knowledge (i.e. additional facts and rules) involving the concepts in its knowledge base; it also includes an extensive lexicon, parsing and English generation tools, and interfaces for knowledge editing and querying in Java.", "token2charspan": [[0, 1], [2, 4], [5, 13], [14, 16], [17, 20], [21, 30], [31, 42], [43, 52], [53, 55], [56, 63], [63, 64], [65, 76], [77, 85], [86, 99], [100, 104], [105, 113], [114, 123], [124, 125], [125, 129], [130, 140], [141, 146], [147, 150], [151, 156], [156, 157], [158, 167], [168, 171], [172, 180], [181, 183], [184, 187], [188, 197], [198, 202], [202, 203], [204, 206], [207, 211], [212, 220], [221, 223], [224, 233], [234, 241], [241, 242], [243, 250], [251, 254], [255, 262], [263, 273], [274, 279], [279, 280], [281, 284], [285, 295], [296, 299], [300, 309], [310, 317], [318, 321], [322, 330], [331, 333], [334, 338], [338, 339]]}
{"doc_key": "ai-dev-115", "ner": [[0, 2, "algorithm"], [5, 6, "task"], [10, 11, "field"], [13, 14, "field"], [16, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 5, 6, "type-of", "", false, false], [5, 6, 10, 11, "part-of", "task_part_of_field", false, false], [5, 6, 13, 14, "part-of", "task_part_of_field", false, false], [5, 6, 16, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Hough", "transform", "is", "a", "feature", "extraction", "technique", "used", "in", "image", "analysis", ",", "computer", "vision", "and", "digital", "image", "processing", "."], "sentence-detokenized": "The Hough transform is a feature extraction technique used in image analysis, computer vision and digital image processing.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 22], [23, 24], [25, 32], [33, 43], [44, 53], [54, 58], [59, 61], [62, 67], [68, 76], [76, 77], [78, 86], [87, 93], [94, 97], [98, 105], [106, 111], [112, 122], [122, 123]]}
{"doc_key": "ai-dev-116", "ner": [[20, 20, "product"], [22, 26, "product"], [3, 3, "organisation"], [5, 5, "product"], [7, 12, "researcher"], [15, 16, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 20, 22, 26, "named", "", false, false], [20, 20, 3, 3, "artifact", "", false, false], [20, 20, 5, 5, "origin", "developed_from", false, false], [5, 5, 7, 12, "artifact", "", false, false], [15, 16, 3, 3, "role", "supported", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1978", ",", "Unimation", "of", "Vicarm", "(", "Victor", "Scheinman", ")", ",", "with", "the", "support", "of", "General", "Motors", ",", "developed", "the", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "robot", "."], "sentence-detokenized": "In 1978, Unimation of Vicarm (Victor Scheinman), with the support of General Motors, developed the PUMA (Programmable Universal Machine for Assembly) robot.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 21], [22, 28], [29, 30], [30, 36], [37, 46], [46, 47], [47, 48], [49, 53], [54, 57], [58, 65], [66, 68], [69, 76], [77, 83], [83, 84], [85, 94], [95, 98], [99, 103], [104, 105], [105, 117], [118, 127], [128, 135], [136, 139], [140, 148], [148, 149], [150, 155], [155, 156]]}
{"doc_key": "ai-dev-117", "ner": [[0, 1, "algorithm"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 7, 8, "origin", "", false, false], [0, 1, 10, 11, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "LSTM", "was", "proposed", "in", "1997", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "The LSTM was proposed in 1997 by Sepp Hochreiter and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 21], [22, 24], [25, 29], [30, 32], [33, 37], [38, 48], [49, 52], [53, 59], [60, 71], [71, 72]]}
{"doc_key": "ai-dev-118", "ner": [[11, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formatted", "as", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be formatted as a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 33], [34, 36], [37, 38], [39, 40], [41, 42], [43, 44], [45, 56], [57, 62], [63, 65], [66, 75], [76, 82], [83, 85], [86, 93], [93, 94]]}
{"doc_key": "ai-dev-119", "ner": [[8, 8, "conference"], [11, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "was", "also", "instrumental", "in", "the", "founding", "of", "ELRA", "and", "the", "LREC", "Conference", "."], "sentence-detokenized": "He was also instrumental in the founding of ELRA and the LREC Conference.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 24], [25, 27], [28, 31], [32, 40], [41, 43], [44, 48], [49, 52], [53, 56], [57, 61], [62, 72], [72, 73]]}
{"doc_key": "ai-dev-120", "ner": [[17, 18, "misc"], [20, 22, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 22, 17, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "popular", "application", "for", "batch", "robots", "in", "today", "'s", "industry", "is", "a", "pick", "-", "and", "-", "place", "assembly", "robot", "called", "SCARA", ",", "which", "has", "four", "degrees", "of", "freedom", "."], "sentence-detokenized": "A popular application for batch robots in today's industry is a pick-and-place assembly robot called SCARA, which has four degrees of freedom.", "token2charspan": [[0, 1], [2, 9], [10, 21], [22, 25], [26, 31], [32, 38], [39, 41], [42, 47], [47, 49], [50, 58], [59, 61], [62, 63], [64, 68], [68, 69], [69, 72], [72, 73], [73, 78], [79, 87], [88, 93], [94, 100], [101, 106], [106, 107], [108, 113], [114, 117], [118, 122], [123, 130], [131, 133], [134, 141], [141, 142]]}
{"doc_key": "ai-dev-121", "ner": [[15, 23, "conference"], [25, 25, "conference"], [29, 32, "conference"], [41, 41, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[25, 25, 15, 23, "named", "", false, false], [41, 41, 29, 32, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "one", "of", "the", "founding", "members", "and", "former", "chair", "(", "2006-2008", ")", "of", "the", "Special", "Interest", "Group", "on", "the", "Web", "as", "a", "Corpus", "(", "SIGWAC", ")", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "one", "of", "the", "founding", "organisers", "of", "the", "SENSEVAL", "project", "."], "sentence-detokenized": "He was one of the founding members and former chair (2006-2008) of the Special Interest Group on the Web as a Corpus (SIGWAC) of the Association for Computational Linguistics and one of the founding organisers of the SENSEVAL project.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 13], [14, 17], [18, 26], [27, 34], [35, 38], [39, 45], [46, 51], [52, 53], [53, 62], [62, 63], [64, 66], [67, 70], [71, 78], [79, 87], [88, 93], [94, 96], [97, 100], [101, 104], [105, 107], [108, 109], [110, 116], [117, 118], [118, 124], [124, 125], [126, 128], [129, 132], [133, 144], [145, 148], [149, 162], [163, 174], [175, 178], [179, 182], [183, 185], [186, 189], [190, 198], [199, 209], [210, 212], [213, 216], [217, 225], [226, 233], [233, 234]]}
{"doc_key": "ai-dev-122", "ner": [[0, 1, "product"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "LinguaStream", "platform", "offers", "a", "comprehensive", "Java", "API", "."], "sentence-detokenized": "The LinguaStream platform offers a comprehensive Java API.", "token2charspan": [[0, 3], [4, 16], [17, 25], [26, 32], [33, 34], [35, 48], [49, 53], [54, 57], [57, 58]]}
{"doc_key": "ai-dev-123", "ner": [[15, 17, "programlang"], [18, 20, "misc"], [23, 25, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 17, 23, 25, "type-of", "", false, false], [18, 20, 23, 25, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "robot", "kit", "is", "based", "on", "the", "Android", "operating", "system", "and", "can", "be", "programmed", "with", "Java", ",", "the", "Blocks", "programming", "interface", "or", "other", "Android", "software", "systems", "."], "sentence-detokenized": "The robot kit is based on the Android operating system and can be programmed with Java, the Blocks programming interface or other Android software systems.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 16], [17, 22], [23, 25], [26, 29], [30, 37], [38, 47], [48, 54], [55, 58], [59, 62], [63, 65], [66, 76], [77, 81], [82, 86], [86, 87], [88, 91], [92, 98], [99, 110], [111, 120], [121, 123], [124, 129], [130, 137], [138, 146], [147, 154], [154, 155]]}
{"doc_key": "ai-dev-124", "ner": [[11, 18, "algorithm"], [15, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "way", "the", "linked", "list", "is", "defined", "determines", "the", "use", "of", "depth", "-", "first", "or", "breadth", "-", "first", "search", "."], "sentence-detokenized": "The way the linked list is defined determines the use of depth-first or breadth-first search.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 18], [19, 23], [24, 26], [27, 34], [35, 45], [46, 49], [50, 53], [54, 56], [57, 62], [62, 63], [63, 68], [69, 71], [72, 79], [79, 80], [80, 85], [86, 92], [92, 93]]}
{"doc_key": "ai-dev-125", "ner": [[21, 22, "task"], [26, 28, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "regions", "could", "signal", "the", "presence", "of", "objects", "or", "parts", "of", "objects", "in", "the", "image", "domain", ",", "which", "is", "used", "for", "object", "recognition", "and", "/", "or", "video", "object", "tracking", "."], "sentence-detokenized": "These regions could signal the presence of objects or parts of objects in the image domain, which is used for object recognition and/or video object tracking.", "token2charspan": [[0, 5], [6, 13], [14, 19], [20, 26], [27, 30], [31, 39], [40, 42], [43, 50], [51, 53], [54, 59], [60, 62], [63, 70], [71, 73], [74, 77], [78, 83], [84, 90], [90, 91], [92, 97], [98, 100], [101, 105], [106, 109], [110, 116], [117, 128], [129, 132], [132, 133], [133, 135], [136, 141], [142, 148], [149, 157], [157, 158]]}
{"doc_key": "ai-dev-126", "ner": [[3, 5, "algorithm"], [7, 9, "product"], [13, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 3, 5, "type-of", "", false, false], [7, 9, 13, 13, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "a", "semantic", "network", "is", "WordNet", ",", "the", "lexical", "database", "of", "English", "."], "sentence-detokenized": "An example of a semantic network is WordNet, the lexical database of English.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 24], [25, 32], [33, 35], [36, 43], [43, 44], [45, 48], [49, 56], [57, 65], [66, 68], [69, 76], [76, 77]]}
{"doc_key": "ai-dev-127", "ner": [[0, 1, "task"], [7, 8, "field"], [10, 12, "field"], [21, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 7, 8, "part-of", "", false, false], [0, 1, 10, 12, "named", "same", false, false], [0, 1, 10, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Speech", "recognition", "is", "an", "interdisciplinary", "sub-field", "of", "computer", "science", "and", "computational", "linguistics", "that", "develops", "methodologies", "and", "technologies", "that", "enable", "the", "computational", "recognition", "and", "translation", "of", "spoken", "language", "into", "text", "."], "sentence-detokenized": "Speech recognition is an interdisciplinary sub-field of computer science and computational linguistics that develops methodologies and technologies that enable the computational recognition and translation of spoken language into text.", "token2charspan": [[0, 6], [7, 18], [19, 21], [22, 24], [25, 42], [43, 52], [53, 55], [56, 64], [65, 72], [73, 76], [77, 90], [91, 102], [103, 107], [108, 116], [117, 130], [131, 134], [135, 147], [148, 152], [153, 159], [160, 163], [164, 177], [178, 189], [190, 193], [194, 205], [206, 208], [209, 215], [216, 224], [225, 229], [230, 234], [234, 235]]}
{"doc_key": "ai-dev-128", "ner": [[0, 2, "field"], [9, 11, "misc"], [16, 18, "field"], [15, 15, "task"], [20, 23, "task"], [42, 42, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 42, 42, "named", "same", false, false], [16, 18, 0, 2, "part-of", "subfield", false, false], [15, 15, 0, 2, "part-of", "", false, false], [15, 15, 16, 18, "part-of", "", false, false], [20, 23, 16, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Artificial", "Intelligence", "has", "retained", "most", "of", "the", "attention", "on", "useful", "ontologies", "in", "sub-fields", "such", "as", "machine", "natural", "language", "processing", "and", "knowledge", "representation", ",", "but", "ontology", "editors", "are", "often", "used", "in", "different", "domains", "such", "as", "education", ",", "without", "the", "intention", "of", "contributing", "to", "AI", "."], "sentence-detokenized": "Artificial Intelligence has retained most of the attention on useful ontologies in sub-fields such as machine natural language processing and knowledge representation, but ontology editors are often used in different domains such as education, without the intention of contributing to AI.", "token2charspan": [[0, 10], [11, 23], [24, 27], [28, 36], [37, 41], [42, 44], [45, 48], [49, 58], [59, 61], [62, 68], [69, 79], [80, 82], [83, 93], [94, 98], [99, 101], [102, 109], [110, 117], [118, 126], [127, 137], [138, 141], [142, 151], [152, 166], [166, 167], [168, 171], [172, 180], [181, 188], [189, 192], [193, 198], [199, 203], [204, 206], [207, 216], [217, 224], [225, 229], [230, 232], [233, 242], [242, 243], [244, 251], [252, 255], [256, 265], [266, 268], [269, 281], [282, 284], [285, 287], [287, 288]]}
{"doc_key": "ai-dev-129", "ner": [[6, 11, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 11, 12, 13, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["This", "update", "rule", "is", "actually", "a", "stochastic", "update", "of", "gradient", "descent", "for", "linear", "regression", "."], "sentence-detokenized": "This update rule is actually a stochastic update of gradient descent for linear regression.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 19], [20, 28], [29, 30], [31, 41], [42, 48], [49, 51], [52, 60], [61, 68], [69, 72], [73, 79], [80, 90], [90, 91]]}
{"doc_key": "ai-dev-130", "ner": [[5, 10, "organisation"], [13, 16, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "was", "elected", "to", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "the", "National", "Academy", "of", "Sciences", "and", "received", "numerous", "awards", ":"], "sentence-detokenized": "He was elected to the American Academy of Arts and Sciences and the National Academy of Sciences and received numerous awards:", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 21], [22, 30], [31, 38], [39, 41], [42, 46], [47, 50], [51, 59], [60, 63], [64, 67], [68, 76], [77, 84], [85, 87], [88, 96], [97, 100], [101, 109], [110, 118], [119, 125], [125, 126]]}
{"doc_key": "ai-dev-131", "ner": [[7, 8, "organisation"], [13, 14, "person"], [16, 20, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 13, 14, "related-to", "written_about_by", false, false], [7, 8, 16, 20, "related-to", "written_about_by", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "recent", "school", "of", "thought", "on", "Honda", "'s", "strategy", "was", "presented", "by", "Gary", "Hamel", "and", "C.K", ".", "Prahalad", "in", "1989", "."], "sentence-detokenized": "The most recent school of thought on Honda's strategy was presented by Gary Hamel and C.K. Prahalad in 1989.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 22], [23, 25], [26, 33], [34, 36], [37, 42], [42, 44], [45, 53], [54, 57], [58, 67], [68, 70], [71, 75], [76, 81], [82, 85], [86, 89], [89, 90], [91, 99], [100, 102], [103, 107], [107, 108]]}
{"doc_key": "ai-dev-132", "ner": [[1, 1, "metrics"], [5, 6, "metrics"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 5, 6, "related-to", "calculates", true, false], [1, 1, 17, 17, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["While", "BLEU", "simply", "calculates", "the", "precision", "of", "the", "n-grams", "and", "gives", "each", "one", "the", "same", "weight", ",", "NIST", "also", "calculates", "how", "informative", "a", "particular", "n-", "gram", "is", "."], "sentence-detokenized": "While BLEU simply calculates the precision of the n-grams and gives each one the same weight, NIST also calculates how informative a particular n-gram is.", "token2charspan": [[0, 5], [6, 10], [11, 17], [18, 28], [29, 32], [33, 42], [43, 45], [46, 49], [50, 57], [58, 61], [62, 67], [68, 72], [73, 76], [77, 80], [81, 85], [86, 92], [92, 93], [94, 98], [99, 103], [104, 114], [115, 118], [119, 130], [131, 132], [133, 143], [144, 146], [146, 150], [151, 153], [153, 154]]}
{"doc_key": "ai-dev-133", "ner": [[4, 7, "misc"], [8, 13, "conference"], [15, 15, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 7, 8, 13, "temporal", "", false, false], [15, 15, 8, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "awarded", "the", "2019", "Lifetime", "Achievement", "Award", "by", "the", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "."], "sentence-detokenized": "He was awarded the 2019 Lifetime Achievement Award by the Association for Computational Linguistics (ACL).", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 18], [19, 23], [24, 32], [33, 44], [45, 50], [51, 53], [54, 57], [58, 69], [70, 73], [74, 87], [88, 99], [100, 101], [101, 104], [104, 105], [105, 106]]}
{"doc_key": "ai-dev-134", "ner": [[0, 2, "researcher"], [5, 11, "organisation"], [13, 16, "organisation"], [19, 24, "conference"], [26, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 5, 11, "role", "", false, false], [0, 2, 19, 24, "role", "", false, false], [13, 16, 5, 11, "named", "", false, false], [26, 26, 19, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sycara", "is", "a", "Fellow", "of", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", "and", "a", "member", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Sycara is a Fellow of the Institute of Electrical and Electronics Engineers (IEEE) and a member of the American Association for Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 18], [19, 21], [22, 25], [26, 35], [36, 38], [39, 49], [50, 53], [54, 65], [66, 75], [76, 77], [77, 81], [81, 82], [83, 86], [87, 88], [89, 95], [96, 98], [99, 102], [103, 111], [112, 123], [124, 127], [128, 138], [139, 151], [152, 153], [153, 157], [157, 158], [158, 159]]}
{"doc_key": "ai-dev-135", "ner": [[2, 2, "product"], [11, 13, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 11, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "following", "MATLAB", "code", "shows", "a", "concrete", "solution", "for", "solving", "the", "non-linear", "system", "of", "equations", "presented", "in", "the", "previous", "section", "."], "sentence-detokenized": "The following MATLAB code shows a concrete solution for solving the non-linear system of equations presented in the previous section.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 31], [32, 33], [34, 42], [43, 51], [52, 55], [56, 63], [64, 67], [68, 78], [79, 85], [86, 88], [89, 98], [99, 108], [109, 111], [112, 115], [116, 124], [125, 132], [132, 133]]}
{"doc_key": "ai-dev-136", "ner": [[4, 6, "product"], [14, 18, "field"], [37, 38, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 14, 18, "related-to", "trained_by", true, false], [4, 6, 37, 38, "related-to", "trained_by", true, false], [14, 18, 37, 38, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "many", "cases", ",", "pattern", "recognition", "systems", "are", "trained", "on", "labelled", "training", "data", "(", "supervised", "learning", ")", ",", "but", "when", "labelled", "data", "is", "not", "available", ",", "other", "algorithms", "can", "be", "used", "to", "detect", "previously", "unknown", "patterns", "(", "unsupervised", "learning", ")", "."], "sentence-detokenized": "In many cases, pattern recognition systems are trained on labelled training data (supervised learning), but when labelled data is not available, other algorithms can be used to detect previously unknown patterns (unsupervised learning).", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 22], [23, 34], [35, 42], [43, 46], [47, 54], [55, 57], [58, 66], [67, 75], [76, 80], [81, 82], [82, 92], [93, 101], [101, 102], [102, 103], [104, 107], [108, 112], [113, 121], [122, 126], [127, 129], [130, 133], [134, 143], [143, 144], [145, 150], [151, 161], [162, 165], [166, 168], [169, 173], [174, 176], [177, 183], [184, 194], [195, 202], [203, 211], [212, 213], [213, 225], [226, 234], [234, 235], [235, 236]]}
{"doc_key": "ai-dev-137", "ner": [[11, 14, "researcher"], [6, 7, "country"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 14, 6, 7, "physical", "", false, false], [11, 14, 24, 25, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "was", "first", "used", "in", "the", "USA", "in", "the", "1960s", "by", "Lawrence", "J.", "Fogel", "to", "use", "simulated", "evolution", "as", "a", "learning", "process", "to", "create", "artificial", "intelligence", "."], "sentence-detokenized": "It was first used in the USA in the 1960s by Lawrence J. Fogel to use simulated evolution as a learning process to create artificial intelligence.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 17], [18, 20], [21, 24], [25, 28], [29, 31], [32, 35], [36, 41], [42, 44], [45, 53], [54, 56], [57, 62], [63, 65], [66, 69], [70, 79], [80, 89], [90, 92], [93, 94], [95, 103], [104, 111], [112, 114], [115, 121], [122, 132], [133, 145], [145, 146]]}
{"doc_key": "ai-dev-138", "ner": [[0, 1, "field"], [10, 11, "field"], [14, 14, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 10, 11, "part-of", "", false, false], [14, 14, 10, 11, "part-of", "", false, false], [16, 17, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Reinforcement", "learning", "is", "one", "of", "the", "three", "basic", "paradigms", "of", "machine", "learning", ",", "alongside", "supervised", "and", "unsupervised", "learning", "."], "sentence-detokenized": "Reinforcement learning is one of the three basic paradigms of machine learning, alongside supervised and unsupervised learning.", "token2charspan": [[0, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 42], [43, 48], [49, 58], [59, 61], [62, 69], [70, 78], [78, 79], [80, 89], [90, 100], [101, 104], [105, 117], [118, 126], [126, 127]]}
{"doc_key": "ai-dev-139", "ner": [[5, 5, "field"], [10, 10, "programlang"], [28, 29, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 28, 29, "usage", "applies", false, false], [10, 10, 28, 29, "usage", "applies", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "such", "cases", ",", "cloud", "computing", "and", "the", "open", "source", "R", "programming", "language", "can", "help", "smaller", "banks", "to", "deploy", "risk", "analytics", "and", "support", "monitoring", "at", "branch", "level", "using", "predictive", "analytics", "."], "sentence-detokenized": "In such cases, cloud computing and the open source R programming language can help smaller banks to deploy risk analytics and support monitoring at branch level using predictive analytics.", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 20], [21, 30], [31, 34], [35, 38], [39, 43], [44, 50], [51, 52], [53, 64], [65, 73], [74, 77], [78, 82], [83, 90], [91, 96], [97, 99], [100, 106], [107, 111], [112, 121], [122, 125], [126, 133], [134, 144], [145, 147], [148, 154], [155, 160], [161, 166], [167, 177], [178, 187], [187, 188]]}
{"doc_key": "ai-dev-140", "ner": [[13, 16, "researcher"], [19, 22, "algorithm"], [24, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 16, 24, 25, "named", "same", false, false], [19, 22, 13, 16, "origin", "proves_function", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["One", "of", "the", "first", "versions", "of", "the", "theorem", "was", "proved", "in", "1989", "by", "George", "Cybenko", "for", "the", "activation", "functions", "of", "the", "sigmoid", "function", ".", "Cybenko", "G.", "(", "1989", ")", ",", "2", "(", "4", ")", ",", "303-314", "."], "sentence-detokenized": "One of the first versions of the theorem was proved in 1989 by George Cybenko for the activation functions of the sigmoid function. Cybenko G. (1989), 2 (4), 303-314.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [17, 25], [26, 28], [29, 32], [33, 40], [41, 44], [45, 51], [52, 54], [55, 59], [60, 62], [63, 69], [70, 77], [78, 81], [82, 85], [86, 96], [97, 106], [107, 109], [110, 113], [114, 121], [122, 130], [130, 131], [132, 139], [140, 142], [143, 144], [144, 148], [148, 149], [149, 150], [151, 152], [153, 154], [154, 155], [155, 156], [156, 157], [158, 165], [165, 166]]}
{"doc_key": "ai-dev-141", "ner": [[6, 9, "algorithm"], [10, 11, "metrics"], [17, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 6, 9, "part-of", "", false, false], [17, 20, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "this", "process", ",", "known", "as", "cross", "-checking", ",", "the", "MSE", "is", "often", "referred", "to", "as", "the", "mean", "squared", "forecast", "error", "and", "is", "calculated", "as"], "sentence-detokenized": "In this process, known as cross-checking, the MSE is often referred to as the mean squared forecast error and is calculated as", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 22], [23, 25], [26, 31], [31, 40], [40, 41], [42, 45], [46, 49], [50, 52], [53, 58], [59, 67], [68, 70], [71, 73], [74, 77], [78, 82], [83, 90], [91, 99], [100, 105], [106, 109], [110, 112], [113, 123], [124, 126]]}
{"doc_key": "ai-dev-142", "ner": [[0, 0, "task"], [3, 5, "task"], [7, 12, "task"], [19, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 5, "compare", "", false, false], [3, 5, 19, 21, "part-of", "", false, false], [7, 12, 3, 5, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OMR", "differs", "from", "Optical", "Character", "Recognition", "(", "OCR", ")", "in", "general", "in", "that", "it", "does", "not", "require", "a", "sophisticated", "pattern", "recognition", "mechanism", "."], "sentence-detokenized": "OMR differs from Optical Character Recognition (OCR) in general in that it does not require a sophisticated pattern recognition mechanism.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 24], [25, 34], [35, 46], [47, 48], [48, 51], [51, 52], [53, 55], [56, 63], [64, 66], [67, 71], [72, 74], [75, 79], [80, 83], [84, 91], [92, 93], [94, 107], [108, 115], [116, 127], [128, 137], [137, 138]]}
{"doc_key": "ai-dev-143", "ner": [[11, 11, "location"], [13, 13, "location"], [15, 15, "location"], [19, 20, "location"], [22, 23, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 13, 15, 15, "physical", "", false, false], [19, 20, 13, 13, "physical", "", false, false], [22, 23, 13, 13, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2018", "and", "2019", ",", "the", "Championships", "will", "be", "held", "in", "Houston", "and", "Detroit", ",", "Michigan", ",", "at", "the", "TCF", "Center", "and", "Ford", "Field", "."], "sentence-detokenized": "In 2018 and 2019, the Championships will be held in Houston and Detroit, Michigan, at the TCF Center and Ford Field.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 16], [16, 17], [18, 21], [22, 35], [36, 40], [41, 43], [44, 48], [49, 51], [52, 59], [60, 63], [64, 71], [71, 72], [73, 81], [81, 82], [83, 85], [86, 89], [90, 93], [94, 100], [101, 104], [105, 109], [110, 115], [115, 116]]}
{"doc_key": "ai-dev-144", "ner": [[0, 0, "task"], [10, 11, "task"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 0, 0, "part-of", "", false, false], [13, 14, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "thought", "of", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multi-class", "classification", "."], "sentence-detokenized": "Classification can be thought of as two separate problems - binary classification and multi-class classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 29], [30, 32], [33, 35], [36, 39], [40, 48], [49, 57], [58, 59], [60, 66], [67, 81], [82, 85], [86, 97], [98, 112], [112, 113]]}
{"doc_key": "ai-dev-145", "ner": [[4, 5, "product"], [8, 9, "product"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 4, 5, "type-of", "", false, false], [12, 13, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "examples", "of", "popular", "parallel", "robots", "are", "the", "Stewart", "platform", "and", "the", "Delta", "robot", "."], "sentence-detokenized": "Two examples of popular parallel robots are the Stewart platform and the Delta robot.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 23], [24, 32], [33, 39], [40, 43], [44, 47], [48, 55], [56, 64], [65, 68], [69, 72], [73, 78], [79, 84], [84, 85]]}
{"doc_key": "ai-dev-146", "ner": [[4, 9, "algorithm"], [21, 21, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 9, 21, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "However", ",", "the", "ReLU", "activation", "function", ",", "which", "is", "undifferentiated", "at", "0", ",", "has", "become", "quite", "popular", ",", "e.g.", "in", "AlexNet", ")", "."], "sentence-detokenized": "(However, the ReLU activation function, which is undifferentiated at 0, has become quite popular, e.g. in AlexNet).", "token2charspan": [[0, 1], [1, 8], [8, 9], [10, 13], [14, 18], [19, 29], [30, 38], [38, 39], [40, 45], [46, 48], [49, 65], [66, 68], [69, 70], [70, 71], [72, 75], [76, 82], [83, 88], [89, 96], [96, 97], [98, 102], [103, 105], [106, 113], [113, 114], [114, 115]]}
{"doc_key": "ai-dev-147", "ner": [[0, 2, "metrics"], [10, 12, "task"], [14, 14, "task"], [17, 18, "task"], [20, 23, "task"], [24, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 24, 24, "named", "", true, false], [10, 12, 0, 2, "usage", "", true, false], [14, 14, 10, 12, "part-of", "", false, false], [17, 18, 10, 12, "part-of", "", false, false], [20, 23, 10, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["F", "-", "scores", "are", "widely", "used", "in", "the", "field", "of", "information", "retrieval", "to", "measure", "search", "performance", ",", "document", "ranking", "and", "query", "ranking", ",", "so", "F_beta", "is", "widely", "used", "."], "sentence-detokenized": "F-scores are widely used in the field of information retrieval to measure search performance, document ranking and query ranking, so F_beta is widely used.", "token2charspan": [[0, 1], [1, 2], [2, 8], [9, 12], [13, 19], [20, 24], [25, 27], [28, 31], [32, 37], [38, 40], [41, 52], [53, 62], [63, 65], [66, 73], [74, 80], [81, 92], [92, 93], [94, 102], [103, 110], [111, 114], [115, 120], [121, 128], [128, 129], [130, 132], [133, 139], [140, 142], [143, 149], [150, 154], [154, 155]]}
{"doc_key": "ai-dev-148", "ner": [[17, 18, "algorithm"], [20, 20, "algorithm"], [23, 24, "algorithm"], [26, 26, "algorithm"], [29, 31, "algorithm"], [33, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 20, 17, 18, "named", "", false, false], [26, 26, 23, 24, "named", "", false, false], [33, 36, 29, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "is", "done", "by", "modelling", "the", "received", "signal", "and", "then", "using", "a", "statistical", "estimation", "method", "such", "as", "maximum", "likelihood", "(", "ML", ")", ",", "majority", "voting", "(", "MV", ")", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "to", "decide", "which", "target", "in", "the", "library", "best", "fits", "the", "model", "built", "from", "the", "received", "signal", "."], "sentence-detokenized": "This is done by modelling the received signal and then using a statistical estimation method such as maximum likelihood (ML), majority voting (MV) or maximum a posteriori (MAP) to decide which target in the library best fits the model built from the received signal.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 15], [16, 25], [26, 29], [30, 38], [39, 45], [46, 49], [50, 54], [55, 60], [61, 62], [63, 74], [75, 85], [86, 92], [93, 97], [98, 100], [101, 108], [109, 119], [120, 121], [121, 123], [123, 124], [124, 125], [126, 134], [135, 141], [142, 143], [143, 145], [145, 146], [147, 149], [150, 157], [158, 159], [160, 170], [171, 172], [172, 175], [175, 176], [177, 179], [180, 186], [187, 192], [193, 199], [200, 202], [203, 206], [207, 214], [215, 219], [220, 224], [225, 228], [229, 234], [235, 240], [241, 245], [246, 249], [250, 258], [259, 265], [265, 266]]}
{"doc_key": "ai-dev-149", "ner": [[0, 1, "researcher"], [2, 3, "misc"], [5, 15, "field"], [8, 12, "university"], [16, 16, "misc"], [18, 27, "field"], [21, 22, "university"], [28, 28, "misc"], [30, 41, "field"], [34, 37, "university"], [44, 64, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 8, 12, "physical", "", false, false], [0, 1, 8, 12, "role", "", false, false], [0, 1, 21, 22, "physical", "", false, false], [0, 1, 21, 22, "role", "", false, false], [0, 1, 34, 37, "physical", "", false, false], [0, 1, 34, 37, "role", "", false, false], [2, 3, 0, 1, "origin", "", false, false], [2, 3, 5, 15, "topic", "", false, false], [16, 16, 0, 1, "origin", "", false, false], [16, 16, 18, 27, "topic", "", false, false], [28, 28, 0, 1, "origin", "", false, false], [28, 28, 30, 41, "topic", "", false, false], [44, 64, 28, 28, "named", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Sowa", "received", "his", "B.S.", "in", "Mathematics", "from", "the", "Massachusetts", "Institute", "of", "Technology", "in", "1962", ",", "his", "M.S.", "in", "Applied", "Mathematics", "from", "Harvard", "University", "in", "1966", ",", "and", "his", "Ph.D.", "in", "Computer", "Science", "from", "the", "Vrije", "Universiteit", "Brussel", "in", "1999", ",", "with", "a", "dissertation", "entitled", "Representing", "Knowledge", ":", "Logical", ",", "Philosophical", ",", "and", "Computational", "Foundations", "(", "Knowledge", "Knowledge", ":", "Logical", ",", "Philosophical", ",", "and", "Computational", "Foundations", ")", "."], "sentence-detokenized": "Sowa received his B.S. in Mathematics from the Massachusetts Institute of Technology in 1962, his M.S. in Applied Mathematics from Harvard University in 1966, and his Ph.D. in Computer Science from the Vrije Universiteit Brussel in 1999, with a dissertation entitled Representing Knowledge: Logical, Philosophical, and Computational Foundations (Knowledge Knowledge: Logical, Philosophical, and Computational Foundations).", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 22], [23, 25], [26, 37], [38, 42], [43, 46], [47, 60], [61, 70], [71, 73], [74, 84], [85, 87], [88, 92], [92, 93], [94, 97], [98, 102], [103, 105], [106, 113], [114, 125], [126, 130], [131, 138], [139, 149], [150, 152], [153, 157], [157, 158], [159, 162], [163, 166], [167, 172], [173, 175], [176, 184], [185, 192], [193, 197], [198, 201], [202, 207], [208, 220], [221, 228], [229, 231], [232, 236], [236, 237], [238, 242], [243, 244], [245, 257], [258, 266], [267, 279], [280, 289], [289, 290], [291, 298], [298, 299], [300, 313], [313, 314], [315, 318], [319, 332], [333, 344], [345, 346], [346, 355], [356, 365], [365, 366], [367, 374], [374, 375], [376, 389], [389, 390], [391, 394], [395, 408], [409, 420], [420, 421], [421, 422]]}
{"doc_key": "ai-dev-150", "ner": [[1, 2, "task"], [9, 10, "task"], [18, 18, "metrics"], [20, 21, "metrics"], [23, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 9, 10, "general-affiliation", "", false, false], [18, 18, 1, 2, "part-of", "", true, false], [20, 21, 1, 2, "part-of", "", true, false], [23, 24, 1, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "paraphrase", "recognition", "can", "be", "thought", "of", "as", "a", "classification", "problem", ",", "most", "standard", "evaluation", "metrics", "such", "as", "accuracy", ",", "f1", "score", "or", "ROC", "curve", "perform", "reasonably", "well", "."], "sentence-detokenized": "Since paraphrase recognition can be thought of as a classification problem, most standard evaluation metrics such as accuracy, f1 score or ROC curve perform reasonably well.", "token2charspan": [[0, 5], [6, 16], [17, 28], [29, 32], [33, 35], [36, 43], [44, 46], [47, 49], [50, 51], [52, 66], [67, 74], [74, 75], [76, 80], [81, 89], [90, 100], [101, 108], [109, 113], [114, 116], [117, 125], [125, 126], [127, 129], [130, 135], [136, 138], [139, 142], [143, 148], [149, 156], [157, 167], [168, 172], [172, 173]]}
{"doc_key": "ai-dev-151", "ner": [[17, 19, "algorithm"], [26, 27, "algorithm"], [29, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 19, 26, 27, "opposite", "not_suited_for", false, false], [17, 19, 29, 30, "opposite", "not_suited_for", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "makes", "it", "practical", "for", "analysing", "large", "datasets", "(", "hundreds", "or", "thousands", "of", "taxa", ")", "and", "for", "extracting", "data", "for", "which", "other", "analysis", "methods", "(", "e.g.", "maximum", "parsimony", ",", "maximum", "likelihood", ")", "may", "be", "computationally", "prohibitive", "."], "sentence-detokenized": "This makes it practical for analysing large datasets (hundreds or thousands of taxa) and for extracting data for which other analysis methods (e.g. maximum parsimony, maximum likelihood) may be computationally prohibitive.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 37], [38, 43], [44, 52], [53, 54], [54, 62], [63, 65], [66, 75], [76, 78], [79, 83], [83, 84], [85, 88], [89, 92], [93, 103], [104, 108], [109, 112], [113, 118], [119, 124], [125, 133], [134, 141], [142, 143], [143, 147], [148, 155], [156, 165], [165, 166], [167, 174], [175, 185], [185, 186], [187, 190], [191, 193], [194, 209], [210, 221], [221, 222]]}
{"doc_key": "ai-dev-152", "ner": [[4, 6, "programlang"], [12, 23, "organisation"], [17, 17, "organisation"], [28, 28, "programlang"], [32, 48, "organisation"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[17, 17, 12, 23, "named", "", false, false], [32, 48, 4, 6, "role", "submits", true, false], [32, 48, 12, 23, "role", "submits_to", true, false]], "relations_mapping_to_source": [1, 3, 4], "sentence": ["In", "2002", ",", "the", "DAML", "+", "OIL", "language", "was", "submitted", "to", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", "on", "the", "basis", "of", "the", "work", "done", "by", "the", "DAML", "implementers", "and", "the", "Ad", "Hoc", "Joint", "Committee", "on", "Markup", "Languages", "of", "the", "European", "Union", "and", "the", "United", "States", "of", "America", "."], "sentence-detokenized": "In 2002, the DAML+OIL language was submitted to the World Wide Web Consortium (W3C) on the basis of the work done by the DAML implementers and the Ad Hoc Joint Committee on Markup Languages of the European Union and the United States of America.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [17, 18], [18, 21], [22, 30], [31, 34], [35, 44], [45, 47], [48, 51], [52, 57], [58, 62], [63, 66], [67, 77], [78, 79], [79, 82], [82, 83], [84, 86], [87, 90], [91, 96], [97, 99], [100, 103], [104, 108], [109, 113], [114, 116], [117, 120], [121, 125], [126, 138], [139, 142], [143, 146], [147, 149], [150, 153], [154, 159], [160, 169], [170, 172], [173, 179], [180, 189], [190, 192], [193, 196], [197, 205], [206, 211], [212, 215], [216, 219], [220, 226], [227, 233], [234, 236], [237, 244], [244, 245]]}
{"doc_key": "ai-dev-153", "ner": [[3, 5, "misc"], [7, 8, "misc"], [11, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 3, 5, "part-of", "", true, false], [11, 17, 3, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "non-linear", "normalisation", "is", "when", "the", "normalisation", "follows", "a", "sigmoid", "function", ",", "in", "which", "case", "the", "normalised", "image", "is", "calculated", "using", "the", "formula"], "sentence-detokenized": "An example of non-linear normalisation is when the normalisation follows a sigmoid function, in which case the normalised image is calculated using the formula", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 24], [25, 38], [39, 41], [42, 46], [47, 50], [51, 64], [65, 72], [73, 74], [75, 82], [83, 91], [91, 92], [93, 95], [96, 101], [102, 106], [107, 110], [111, 121], [122, 127], [128, 130], [131, 141], [142, 147], [148, 151], [152, 159]]}
{"doc_key": "ai-dev-154", "ner": [[5, 5, "metrics"], [10, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 10, 12, "related-to", "used_together", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "pointed", "out", "that", "accuracy", "is", "usually", "associated", "with", "recall", ",", "so", "this", "problem", "should", "be", "rectified", "."], "sentence-detokenized": "It was pointed out that accuracy is usually associated with recall, so this problem should be rectified.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 18], [19, 23], [24, 32], [33, 35], [36, 43], [44, 54], [55, 59], [60, 66], [66, 67], [68, 70], [71, 75], [76, 83], [84, 90], [91, 93], [94, 103], [103, 104]]}
{"doc_key": "ai-dev-155", "ner": [[5, 8, "metrics"], [11, 19, "metrics"], [24, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[24, 25, 11, 19, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Commonly", "used", "metrics", "are", "the", "root", "mean", "square", "error", "and", "the", "root", "mean", "square", "error", ",", "the", "latter", "of", "which", "was", "used", "for", "the", "Netflix", "Prize", "."], "sentence-detokenized": "Commonly used metrics are the root mean square error and the root mean square error, the latter of which was used for the Netflix Prize.", "token2charspan": [[0, 8], [9, 13], [14, 21], [22, 25], [26, 29], [30, 34], [35, 39], [40, 46], [47, 52], [53, 56], [57, 60], [61, 65], [66, 70], [71, 77], [78, 83], [83, 84], [85, 88], [89, 95], [96, 98], [99, 104], [105, 108], [109, 113], [114, 117], [118, 121], [122, 129], [130, 135], [135, 136]]}
{"doc_key": "ai-dev-156", "ner": [[8, 14, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "August", "2016", ",", "a", "research", "programme", "with", "University", "College", "Hospital", "was", "announced", ",", "aiming", "to", "develop", "an", "algorithm", "that", "will", "automatically", "distinguish", "between", "healthy", "and", "cancerous", "tissues", "in", "the", "head", "and", "neck", "area", "."], "sentence-detokenized": "In August 2016, a research programme with University College Hospital was announced, aiming to develop an algorithm that will automatically distinguish between healthy and cancerous tissues in the head and neck area.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 17], [18, 26], [27, 36], [37, 41], [42, 52], [53, 60], [61, 69], [70, 73], [74, 83], [83, 84], [85, 91], [92, 94], [95, 102], [103, 105], [106, 115], [116, 120], [121, 125], [126, 139], [140, 151], [152, 159], [160, 167], [168, 171], [172, 181], [182, 189], [190, 192], [193, 196], [197, 201], [202, 205], [206, 210], [211, 215], [215, 216]]}
{"doc_key": "ai-dev-157", "ner": [[3, 4, "researcher"], [16, 18, "organisation"], [21, 24, "organisation"], [27, 30, "organisation"], [33, 38, "organisation"], [41, 47, "organisation"], [50, 53, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 4, 16, 18, "role", "", false, false], [3, 4, 21, 24, "role", "", false, false], [3, 4, 27, 30, "role", "", false, false], [3, 4, 33, 38, "role", "", false, false], [3, 4, 41, 47, "role", "", false, false], [3, 4, 50, 53, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "impact", "of", "Posner", "'s", "theoretical", "and", "empirical", "contributions", "has", "been", "recognised", "through", "memberships", "in", "the", "American", "Psychological", "Association", ",", "the", "Association", "for", "Psychological", "Science", ",", "the", "Association", "of", "Experimental", "Psychologists", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "The impact of Posner's theoretical and empirical contributions has been recognised through memberships in the American Psychological Association, the Association for Psychological Science, the Association of Experimental Psychologists, the American Academy of Arts and Sciences, the American Association for the Advancement of Science and the National Academy of Sciences.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 20], [20, 22], [23, 34], [35, 38], [39, 48], [49, 62], [63, 66], [67, 71], [72, 82], [83, 90], [91, 102], [103, 105], [106, 109], [110, 118], [119, 132], [133, 144], [144, 145], [146, 149], [150, 161], [162, 165], [166, 179], [180, 187], [187, 188], [189, 192], [193, 204], [205, 207], [208, 220], [221, 234], [234, 235], [236, 239], [240, 248], [249, 256], [257, 259], [260, 264], [265, 268], [269, 277], [277, 278], [279, 282], [283, 291], [292, 303], [304, 307], [308, 311], [312, 323], [324, 326], [327, 334], [335, 338], [339, 342], [343, 351], [352, 359], [360, 362], [363, 371], [371, 372]]}
{"doc_key": "ai-dev-158", "ner": [[2, 3, "product"], [7, 8, "field"], [12, 13, "task"], [15, 17, "task"], [19, 19, "task"], [22, 24, "task"], [26, 26, "task"], [29, 30, "field"], [32, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 3, 7, 8, "usage", "", false, false], [12, 13, 7, 8, "part-of", "", false, false], [15, 17, 7, 8, "part-of", "", false, false], [19, 19, 15, 17, "named", "", false, false], [22, 24, 7, 8, "part-of", "", false, false], [26, 26, 22, 24, "named", "", false, false], [29, 30, 7, 8, "part-of", "", false, false], [32, 33, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["These", "intelligent", "chatbots", "use", "all", "kinds", "of", "artificial", "intelligence", ",", "such", "as", "image", "moderation", "and", "natural", "language", "understanding", "(", "NLU", ")", ",", "natural", "language", "generation", "(", "NLG", ")", ",", "machine", "learning", "and", "deep", "learning", "."], "sentence-detokenized": "These intelligent chatbots use all kinds of artificial intelligence, such as image moderation and natural language understanding (NLU), natural language generation (NLG), machine learning and deep learning.", "token2charspan": [[0, 5], [6, 17], [18, 26], [27, 30], [31, 34], [35, 40], [41, 43], [44, 54], [55, 67], [67, 68], [69, 73], [74, 76], [77, 82], [83, 93], [94, 97], [98, 105], [106, 114], [115, 128], [129, 130], [130, 133], [133, 134], [134, 135], [136, 143], [144, 152], [153, 163], [164, 165], [165, 168], [168, 169], [169, 170], [171, 178], [179, 187], [188, 191], [192, 196], [197, 205], [205, 206]]}
{"doc_key": "ai-dev-159", "ner": [[7, 9, "metrics"], [11, 11, "metrics"], [14, 14, "metrics"], [17, 26, "metrics"], [29, 31, "metrics"], [33, 33, "metrics"], [36, 43, "metrics"], [47, 49, "metrics"], [51, 51, "metrics"], [54, 63, "metrics"], [66, 68, "metrics"], [70, 70, "metrics"], [73, 79, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[11, 11, 7, 9, "named", "", false, false], [14, 14, 7, 9, "named", "", false, false], [17, 26, 7, 9, "named", "", false, false], [33, 33, 29, 31, "named", "", false, false], [36, 43, 29, 31, "named", "", false, false], [51, 51, 47, 49, "named", "", false, false], [54, 63, 47, 49, "named", "", false, false], [70, 70, 66, 68, "named", "", false, false], [73, 79, 66, 68, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "ratios", "in", "the", "row", "are", "the", "positive", "predictive", "value", "(", "PPV", ",", "aka", "precision", ")", "(", "TP", "/", "(", "TP", "+", "FP", ")", ")", ",", "complemented", "by", "the", "FALSE", "Discovery", "Rate", "(", "FDR", ")", "(", "FP", "/", "(", "TP", "+", "FP", ")", ")", ";", "and", "the", "negative", "predictive", "value", "(", "NPV", ")", "(", "TN", "/", "(", "TN", "+", "FN", ")", ")", ",", "complemented", "by", "the", "FALSE", "Omission", "Rate", "(", "FOR", ")", "(", "FN", "/", "(", "TN", "+", "FN", ")", ")", "."], "sentence-detokenized": "The ratios in the row are the positive predictive value (PPV, aka precision) (TP / (TP + FP)), complemented by the FALSE Discovery Rate (FDR) (FP / (TP + FP)); and the negative predictive value (NPV) (TN / (TN + FN)), complemented by the FALSE Omission Rate (FOR) (FN / (TN + FN)).", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 17], [18, 21], [22, 25], [26, 29], [30, 38], [39, 49], [50, 55], [56, 57], [57, 60], [60, 61], [62, 65], [66, 75], [75, 76], [77, 78], [78, 80], [81, 82], [83, 84], [84, 86], [87, 88], [89, 91], [91, 92], [92, 93], [93, 94], [95, 107], [108, 110], [111, 114], [115, 120], [121, 130], [131, 135], [136, 137], [137, 140], [140, 141], [142, 143], [143, 145], [146, 147], [148, 149], [149, 151], [152, 153], [154, 156], [156, 157], [157, 158], [158, 159], [160, 163], [164, 167], [168, 176], [177, 187], [188, 193], [194, 195], [195, 198], [198, 199], [200, 201], [201, 203], [204, 205], [206, 207], [207, 209], [210, 211], [212, 214], [214, 215], [215, 216], [216, 217], [218, 230], [231, 233], [234, 237], [238, 243], [244, 252], [253, 257], [258, 259], [259, 262], [262, 263], [264, 265], [265, 267], [268, 269], [270, 271], [271, 273], [274, 275], [276, 278], [278, 279], [279, 280], [280, 281]]}
{"doc_key": "ai-dev-160", "ner": [[8, 9, "misc"], [15, 16, "algorithm"], [18, 18, "algorithm"], [22, 24, "algorithm"], [26, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[18, 18, 15, 16, "named", "", false, false], [26, 26, 22, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "information", "is", "a", "mix", "of", "sitemaps", "and", "RSS", "feeds", "and", "is", "generated", "using", "the", "Information", "Model", "(", "IM", ")", "and", "the", "Biomedical", "Resource", "Ontology", "(", "BRO", ")", "."], "sentence-detokenized": "The information is a mix of sitemaps and RSS feeds and is generated using the Information Model (IM) and the Biomedical Resource Ontology (BRO).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 20], [21, 24], [25, 27], [28, 36], [37, 40], [41, 44], [45, 50], [51, 54], [55, 57], [58, 67], [68, 73], [74, 77], [78, 89], [90, 95], [96, 97], [97, 99], [99, 100], [101, 104], [105, 108], [109, 119], [120, 128], [129, 137], [138, 139], [139, 142], [142, 143], [143, 144]]}
{"doc_key": "ai-dev-161", "ner": [[1, 2, "task"], [7, 9, "algorithm"], [11, 17, "algorithm"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 11, 17, "origin", "based_on", false, false], [11, 17, 7, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Newer", "text", "recognition", "is", "based", "on", "a", "recurrent", "neural", "network", "(", "long", "-", "term", "short", "-", "term", "memory", ")", "and", "does", "not", "require", "a", "language", "model", "."], "sentence-detokenized": "Newer text recognition is based on a recurrent neural network (long-term short-term memory) and does not require a language model.", "token2charspan": [[0, 5], [6, 10], [11, 22], [23, 25], [26, 31], [32, 34], [35, 36], [37, 46], [47, 53], [54, 61], [62, 63], [63, 67], [67, 68], [68, 72], [73, 78], [78, 79], [79, 83], [84, 90], [90, 91], [92, 95], [96, 100], [101, 104], [105, 112], [113, 114], [115, 123], [124, 129], [129, 130]]}
{"doc_key": "ai-dev-162", "ner": [[1, 2, "misc"], [5, 6, "metrics"], [9, 10, "algorithm"], [14, 15, "metrics"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 1, 2, "type-of", "", false, false], [9, 10, 5, 6, "related-to", "", true, false], [14, 15, 1, 2, "type-of", "", false, false], [18, 19, 14, 15, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Popular", "loss", "functions", "include", "the", "rate", "loss", "(", "for", "linear", "SVMs", ")", "and", "the", "log", "loss", "(", "for", "logistic", "regression", ")", "."], "sentence-detokenized": "Popular loss functions include the rate loss (for linear SVMs) and the log loss (for logistic regression).", "token2charspan": [[0, 7], [8, 12], [13, 22], [23, 30], [31, 34], [35, 39], [40, 44], [45, 46], [46, 49], [50, 56], [57, 61], [61, 62], [63, 66], [67, 70], [71, 74], [75, 79], [80, 81], [81, 84], [85, 93], [94, 104], [104, 105], [105, 106]]}
{"doc_key": "ai-dev-163", "ner": [[0, 0, "metrics"], [10, 14, "metrics"], [16, 16, "metrics"], [19, 21, "metrics"], [23, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 10, 14, "compare", "", false, false], [0, 0, 19, 21, "compare", "", false, false], [16, 16, 10, 14, "named", "", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SSIM", "is", "designed", "to", "improve", "on", "traditional", "methods", "such", "as", "Peak", "Signal", "to", "Noise", "Ratio", "(", "PSNR", ")", "and", "Mean", "Square", "Error", "(", "MSE", ")", "."], "sentence-detokenized": "SSIM is designed to improve on traditional methods such as Peak Signal to Noise Ratio (PSNR) and Mean Square Error (MSE).", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 19], [20, 27], [28, 30], [31, 42], [43, 50], [51, 55], [56, 58], [59, 63], [64, 70], [71, 73], [74, 79], [80, 85], [86, 87], [87, 91], [91, 92], [93, 96], [97, 101], [102, 108], [109, 114], [115, 116], [116, 119], [119, 120], [120, 121]]}
{"doc_key": "ai-dev-164", "ner": [[11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "work", "inspired", "the", "next", "generation", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "His work inspired the next generation of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 26], [27, 37], [38, 40], [41, 49], [50, 61], [62, 66], [67, 69], [70, 76], [77, 83], [83, 84], [85, 89], [90, 97], [98, 101], [102, 106], [107, 113], [113, 114]]}
{"doc_key": "ai-dev-165", "ner": [[10, 13, "algorithm"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 10, 13, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["Furthermore", ",", "pulse", "training", "is", "not", "differentiated", ",", "which", "makes", "back", "-", "propagation", "based", "training", "methods", "such", "as", "gradient", "descent", "impossible", "."], "sentence-detokenized": "Furthermore, pulse training is not differentiated, which makes back-propagation based training methods such as gradient descent impossible.", "token2charspan": [[0, 11], [11, 12], [13, 18], [19, 27], [28, 30], [31, 34], [35, 49], [49, 50], [51, 56], [57, 62], [63, 67], [67, 68], [68, 79], [80, 85], [86, 94], [95, 102], [103, 107], [108, 110], [111, 119], [120, 127], [128, 138], [138, 139]]}
{"doc_key": "ai-dev-166", "ner": [[8, 11, "metrics"], [15, 17, "metrics"], [18, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 15, 17, "related-to", "describes", false, false], [15, 17, 18, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "relationships", "can", "be", "simply", "represented", "by", "a", "confusion", "matrix", ",", "a", "table", "describing", "the", "accuracy", "of", "the", "classification", "model", "."], "sentence-detokenized": "These relationships can be simply represented by a confusion matrix, a table describing the accuracy of the classification model.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 26], [27, 33], [34, 45], [46, 48], [49, 50], [51, 60], [61, 67], [67, 68], [69, 70], [71, 76], [77, 87], [88, 91], [92, 100], [101, 103], [104, 107], [108, 122], [123, 128], [128, 129]]}
{"doc_key": "ai-dev-167", "ner": [[6, 10, "conference"], [12, 12, "conference"], [0, 0, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 12, 6, 10, "named", "", false, false], [0, 0, 6, 10, "physical", "", false, false], [0, 0, 6, 10, "role", "", false, false], [0, 0, 6, 10, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Google", "researchers", "present", "work", "at", "the", "2018", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "conference"], "sentence-detokenized": "Google researchers present work at the 2018 Neural Information Processing Systems (NeurIPS) conference", "token2charspan": [[0, 6], [7, 18], [19, 26], [27, 31], [32, 34], [35, 38], [39, 43], [44, 50], [51, 62], [63, 73], [74, 81], [82, 83], [83, 90], [90, 91], [92, 102]]}
{"doc_key": "ai-dev-168", "ner": [[2, 5, "university"], [8, 8, "product"], [18, 19, "misc"], [17, 17, "conference"], [27, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 8, 18, 19, "win-defeat", "", false, false], [18, 19, 17, 17, "temporal", "", false, false], [27, 30, 17, 17, "part-of", "", false, false], [27, 30, 17, 17, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "at", "Duke", "University", ",", "he", "worked", "on", "PROVERB", ",", "an", "automated", "crossword", "solver", "that", "won", "the", "AAAI", "Outstanding", "Paper", "Award", "in", "1999", "and", "participated", "in", "the", "American", "Crossword", "Puzzle", "Tournament", "."], "sentence-detokenized": "While at Duke University, he worked on PROVERB, an automated crossword solver that won the AAAI Outstanding Paper Award in 1999 and participated in the American Crossword Puzzle Tournament.", "token2charspan": [[0, 5], [6, 8], [9, 13], [14, 24], [24, 25], [26, 28], [29, 35], [36, 38], [39, 46], [46, 47], [48, 50], [51, 60], [61, 70], [71, 77], [78, 82], [83, 86], [87, 90], [91, 95], [96, 107], [108, 113], [114, 119], [120, 122], [123, 127], [128, 131], [132, 144], [145, 147], [148, 151], [152, 160], [161, 170], [171, 177], [178, 188], [188, 189]]}
{"doc_key": "ai-dev-169", "ner": [[5, 6, "location"], [8, 11, "location"], [17, 17, "country"], [19, 19, "country"], [21, 21, "country"], [23, 23, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 6, 8, 11, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "company", "was", "headquartered", "in", "Rochester", "Hills", ",", "Michigan", ",", "and", "had", "10", "regional", "locations", "in", "the", "US", ",", "Canada", ",", "Mexico", "and", "Brazil", "."], "sentence-detokenized": "The company was headquartered in Rochester Hills, Michigan, and had 10 regional locations in the US, Canada, Mexico and Brazil.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 29], [30, 32], [33, 42], [43, 48], [48, 49], [50, 58], [58, 59], [60, 63], [64, 67], [68, 70], [71, 79], [80, 89], [90, 92], [93, 96], [97, 99], [99, 100], [101, 107], [107, 108], [109, 115], [116, 119], [120, 126], [126, 127]]}
{"doc_key": "ai-dev-170", "ner": [[12, 12, "product"], [14, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "joins", "a", "collection", "of", "historically", "important", "robots", "that", "includes", "the", "early", "Unimate", "and", "Odetics", "'", "Odex", "1", "."], "sentence-detokenized": "It joins a collection of historically important robots that includes the early Unimate and Odetics' Odex 1.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 21], [22, 24], [25, 37], [38, 47], [48, 54], [55, 59], [60, 68], [69, 72], [73, 78], [79, 86], [87, 90], [91, 98], [98, 99], [100, 104], [105, 106], [106, 107]]}
{"doc_key": "ai-dev-171", "ner": [[7, 8, "researcher"], [12, 12, "organisation"], [13, 15, "researcher"], [25, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 12, 12, "physical", "", false, false], [7, 8, 12, 12, "role", "", false, false], [13, 15, 12, 12, "physical", "", false, false], [13, 15, 12, 12, "role", "", false, false], [13, 15, 25, 27, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["This", "issue", "'s", "guest", "editor", "will", "be", "David", "'s", "former", "colleague", "at", "NIST", ",", "Judah", "Levine", ",", "who", "is", "the", "most", "recent", "recipient", "of", "the", "I.I", ".", "Ravi", "Award", "."], "sentence-detokenized": "This issue's guest editor will be David's former colleague at NIST, Judah Levine, who is the most recent recipient of the I.I. Ravi Award.", "token2charspan": [[0, 4], [5, 10], [10, 12], [13, 18], [19, 25], [26, 30], [31, 33], [34, 39], [39, 41], [42, 48], [49, 58], [59, 61], [62, 66], [66, 67], [68, 73], [74, 80], [80, 81], [82, 85], [86, 88], [89, 92], [93, 97], [98, 104], [105, 114], [115, 117], [118, 121], [122, 125], [125, 126], [127, 131], [132, 137], [137, 138]]}
{"doc_key": "ai-dev-172", "ner": [[12, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "can", "be", "grouped", "into", "a", "2", "\u00d7", "2", "contingency", "table", "(", "confusion", "matrix", ")", ",", "usually", "with", "the", "test", "result", "on", "the", "vertical", "axis", "and", "the", "actual", "situation", "on", "the", "horizontal", "axis", "."], "sentence-detokenized": "These can be grouped into a 2 \u00d7 2 contingency table (confusion matrix), usually with the test result on the vertical axis and the actual situation on the horizontal axis.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 20], [21, 25], [26, 27], [28, 29], [30, 31], [32, 33], [34, 45], [46, 51], [52, 53], [53, 62], [63, 69], [69, 70], [70, 71], [72, 79], [80, 84], [85, 88], [89, 93], [94, 100], [101, 103], [104, 107], [108, 116], [117, 121], [122, 125], [126, 129], [130, 136], [137, 146], [147, 149], [150, 153], [154, 164], [165, 169], [169, 170]]}
{"doc_key": "ai-dev-173", "ner": [[0, 4, "product"], [8, 8, "product"], [10, 10, "product"], [12, 13, "product"], [16, 19, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 8, 8, "part-of", "", false, false], [0, 4, 10, 10, "part-of", "", false, false], [0, 4, 12, 13, "part-of", "", false, false], [0, 4, 16, 19, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Apple", "'s", "iOS", "operating", "system", ",", "used", "on", "iPhone", ",", "iPad", "and", "iPod", "Touch", ",", "uses", "VoiceOver", "speech", "synthesis", "accessibility", "."], "sentence-detokenized": "Apple's iOS operating system, used on iPhone, iPad and iPod Touch, uses VoiceOver speech synthesis accessibility.", "token2charspan": [[0, 5], [5, 7], [8, 11], [12, 21], [22, 28], [28, 29], [30, 34], [35, 37], [38, 44], [44, 45], [46, 50], [51, 54], [55, 59], [60, 65], [65, 66], [67, 71], [72, 81], [82, 88], [89, 98], [99, 112], [112, 113]]}
{"doc_key": "ai-dev-174", "ner": [[7, 9, "conference"], [13, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "the", "best", "system", "entering", "MUC", "-", "7", "achieved", "93.39", "%", "F", "-", "meryl", ",", "while", "human", "annotators", "achieved", "97.6", "%", "and", "96.95", "%", "."], "sentence-detokenized": "For example, the best system entering MUC-7 achieved 93.39% F-meryl, while human annotators achieved 97.6% and 96.95%.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 37], [38, 41], [41, 42], [42, 43], [44, 52], [53, 58], [58, 59], [60, 61], [61, 62], [62, 67], [67, 68], [69, 74], [75, 80], [81, 91], [92, 100], [101, 105], [105, 106], [107, 110], [111, 116], [116, 117], [117, 118]]}
{"doc_key": "ai-dev-175", "ner": [[9, 11, "algorithm"], [13, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 13, 9, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "uses", "standard", "neural", "network", "training", "algorithms", "such", "as", "stochastic", "gradient", "descent", "with", "backpropagation", "."], "sentence-detokenized": "This uses standard neural network training algorithms such as stochastic gradient descent with backpropagation.", "token2charspan": [[0, 4], [5, 9], [10, 18], [19, 25], [26, 33], [34, 42], [43, 53], [54, 58], [59, 61], [62, 72], [73, 81], [82, 89], [90, 94], [95, 110], [110, 111]]}
{"doc_key": "ai-dev-176", "ner": [[0, 3, "organisation"], [26, 26, "country"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 26, 26, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Rotten", "Tomatoes", "ranks", "it", "among", "the", "top", "1000", "websites", ",", "the", "400th", "best", "in", "the", "world", "according", "to", "Alexa", ",", "and", "the", "150th", "best", "in", "the", "US", "alone", "."], "sentence-detokenized": "Rotten Tomatoes ranks it among the top 1000 websites, the 400th best in the world according to Alexa, and the 150th best in the US alone.", "token2charspan": [[0, 6], [7, 15], [16, 21], [22, 24], [25, 30], [31, 34], [35, 38], [39, 43], [44, 52], [52, 53], [54, 57], [58, 63], [64, 68], [69, 71], [72, 75], [76, 81], [82, 91], [92, 94], [95, 100], [100, 101], [102, 105], [106, 109], [110, 115], [116, 120], [121, 123], [124, 127], [128, 130], [131, 136], [136, 137]]}
{"doc_key": "ai-dev-177", "ner": [[16, 19, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "general", ",", "all", "learning", "appears", "as", "a", "gradual", "change", "over", "time", ",", "but", "it", "describes", "a", "sigmoid", "function", "that", "takes", "different", "shapes", "depending", "on", "the", "time", "scale", "of", "the", "observation", "."], "sentence-detokenized": "In general, all learning appears as a gradual change over time, but it describes a sigmoid function that takes different shapes depending on the time scale of the observation.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 24], [25, 32], [33, 35], [36, 37], [38, 45], [46, 52], [53, 57], [58, 62], [62, 63], [64, 67], [68, 70], [71, 80], [81, 82], [83, 90], [91, 99], [100, 104], [105, 110], [111, 120], [121, 127], [128, 137], [138, 140], [141, 144], [145, 149], [150, 155], [156, 158], [159, 162], [163, 174], [174, 175]]}
{"doc_key": "ai-dev-178", "ner": [[0, 1, "metrics"], [7, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 7, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "SSD", "is", "also", "known", "as", "the", "root", "mean", "square", "error", "."], "sentence-detokenized": "The SSD is also known as the root mean square error.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 15], [16, 21], [22, 24], [25, 28], [29, 33], [34, 38], [39, 45], [46, 51], [51, 52]]}
{"doc_key": "ai-dev-179", "ner": [[0, 2, "algorithm"], [4, 5, "algorithm"], [8, 13, "algorithm"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 22, 23, "related-to", "can_be_related_to", true, false], [4, 5, 22, 23, "related-to", "can_be_related_to", true, false], [8, 13, 22, 23, "related-to", "can_be_related_to", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Learning", "decision", "trees", ",", "neural", "networks", "or", "a", "naive", "Bayes", "classifier", "can", "be", "used", "in", "combination", "with", "model", "quality", "measures", "such", "as", "balanced", "accuracy", "."], "sentence-detokenized": "Learning decision trees, neural networks or a naive Bayes classifier can be used in combination with model quality measures such as balanced accuracy.", "token2charspan": [[0, 8], [9, 17], [18, 23], [23, 24], [25, 31], [32, 40], [41, 43], [44, 45], [46, 51], [52, 57], [58, 68], [69, 72], [73, 75], [76, 80], [81, 83], [84, 95], [96, 100], [101, 106], [107, 114], [115, 123], [124, 128], [129, 131], [132, 140], [141, 149], [149, 150]]}
{"doc_key": "ai-dev-180", "ner": [[16, 16, "conference"], [22, 30, "conference"], [26, 27, "misc"], [34, 36, "product"], [42, 46, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[26, 27, 22, 30, "origin", "", false, false], [26, 27, 22, 30, "temporal", "", false, false], [34, 36, 26, 27, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "is", "a", "past", "president", "(", "1979", ")", "and", "founding", "member", "(", "2011", ")", "of", "the", "ACL", ",", "co-founder", "of", "the", "1992", "Association", "for", "Computing", "Machinery", "Software", "Systems", "Award", "for", "his", "contribution", "to", "the", "Interlisp", "software", "system", ",", "and", "a", "Fellow", "of", "the", "Association", "for", "Computing", "Machinery", "."], "sentence-detokenized": "He is a past president (1979) and founding member (2011) of the ACL, co-founder of the 1992 Association for Computing Machinery Software Systems Award for his contribution to the Interlisp software system, and a Fellow of the Association for Computing Machinery.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 22], [23, 24], [24, 28], [28, 29], [30, 33], [34, 42], [43, 49], [50, 51], [51, 55], [55, 56], [57, 59], [60, 63], [64, 67], [67, 68], [69, 79], [80, 82], [83, 86], [87, 91], [92, 103], [104, 107], [108, 117], [118, 127], [128, 136], [137, 144], [145, 150], [151, 154], [155, 158], [159, 171], [172, 174], [175, 178], [179, 188], [189, 197], [198, 204], [204, 205], [206, 209], [210, 211], [212, 218], [219, 221], [222, 225], [226, 237], [238, 241], [242, 251], [252, 261], [261, 262]]}
{"doc_key": "ai-dev-181", "ner": [[7, 8, "researcher"], [10, 14, "researcher"], [3, 3, "researcher"], [0, 1, "researcher"], [26, 32, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 26, 32, "related-to", "", false, false], [10, 14, 26, 32, "related-to", "", false, false], [3, 3, 26, 32, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Cade", "Metz", "considers", "Bengio", ",", "along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "to", "be", "one", "of", "the", "three", "people", "most", "responsible", "for", "the", "development", "of", "deep", "learning", "in", "the", "1990s", "and", "2000s", "."], "sentence-detokenized": "Cade Metz considers Bengio, along with Geoffrey Hinton and Yann LeCun, to be one of the three people most responsible for the development of deep learning in the 1990s and 2000s.", "token2charspan": [[0, 4], [5, 9], [10, 19], [20, 26], [26, 27], [28, 33], [34, 38], [39, 47], [48, 54], [55, 58], [59, 63], [64, 69], [69, 70], [71, 73], [74, 76], [77, 80], [81, 83], [84, 87], [88, 93], [94, 100], [101, 105], [106, 117], [118, 121], [122, 125], [126, 137], [138, 140], [141, 145], [146, 154], [155, 157], [158, 161], [162, 167], [168, 171], [172, 177], [177, 178]]}
{"doc_key": "ai-dev-182", "ner": [[1, 2, "field"], [4, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "information", "theory", "and", "computer", "science", ",", "a", "code", "is", "usually", "thought", "of", "as", "an", "algorithm", "that", "uniquely", "represents", "symbols", "from", "some", "source", "alphabet", "with", "encoded", "strings", "that", "may", "be", "in", "some", "other", "target", "alphabet", "."], "sentence-detokenized": "In information theory and computer science, a code is usually thought of as an algorithm that uniquely represents symbols from some source alphabet with encoded strings that may be in some other target alphabet.", "token2charspan": [[0, 2], [3, 14], [15, 21], [22, 25], [26, 34], [35, 42], [42, 43], [44, 45], [46, 50], [51, 53], [54, 61], [62, 69], [70, 72], [73, 75], [76, 78], [79, 88], [89, 93], [94, 102], [103, 113], [114, 121], [122, 126], [127, 131], [132, 138], [139, 147], [148, 152], [153, 160], [161, 168], [169, 173], [174, 177], [178, 180], [181, 183], [184, 188], [189, 194], [195, 201], [202, 210], [210, 211]]}
{"doc_key": "ai-dev-183", "ner": [[0, 4, "algorithm"], [14, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 17, 0, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "sigmoid", "function", ",", "which", "is", "a", "relatively", "simple", "non", "-linear", "function", "like", "the", "logistic", "function", ",", "also", "has", "an", "easily", "computable", "derivative", ",", "which", "can", "be", "important", "when", "calculating", "network", "weight", "updates", "."], "sentence-detokenized": "The sigmoid function, which is a relatively simple non-linear function like the logistic function, also has an easily computable derivative, which can be important when calculating network weight updates.", "token2charspan": [[0, 3], [4, 11], [12, 20], [20, 21], [22, 27], [28, 30], [31, 32], [33, 43], [44, 50], [51, 54], [54, 61], [62, 70], [71, 75], [76, 79], [80, 88], [89, 97], [97, 98], [99, 103], [104, 107], [108, 110], [111, 117], [118, 128], [129, 139], [139, 140], [141, 146], [147, 150], [151, 153], [154, 163], [164, 168], [169, 180], [181, 188], [189, 195], [196, 203], [203, 204]]}
{"doc_key": "ai-dev-184", "ner": [[0, 1, "person"], [6, 6, "location"], [8, 8, "location"], [10, 12, "country"], [15, 15, "country"], [18, 20, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 6, 6, "physical", "", false, false], [6, 6, 8, 8, "physical", "", false, false], [8, 8, 10, 12, "physical", "", false, false], [8, 8, 15, 15, "physical", "", false, false], [8, 8, 18, 20, "physical", "", false, false], [15, 15, 10, 12, "origin", "", false, false], [18, 20, 15, 15, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["\u010capek", "was", "born", "in", "1887", "in", "Hronov", ",", "Bohemia", "(", "Austria", "-", "Hungary", ",", "later", "Czechoslovakia", ",", "now", "the", "Czech", "Republic", ")", "."], "sentence-detokenized": "\u010capek was born in 1887 in Hronov, Bohemia (Austria-Hungary, later Czechoslovakia, now the Czech Republic).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 41], [42, 43], [43, 50], [50, 51], [51, 58], [58, 59], [60, 65], [66, 80], [80, 81], [82, 85], [86, 89], [90, 95], [96, 104], [104, 105], [105, 106]]}
{"doc_key": "ai-dev-185", "ner": [[5, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "specialised", "software", "can", "narrate", "RSS", "feeds", "."], "sentence-detokenized": "Some specialised software can narrate RSS feeds.", "token2charspan": [[0, 4], [5, 16], [17, 25], [26, 29], [30, 37], [38, 41], [42, 47], [47, 48]]}
{"doc_key": "ai-dev-186", "ner": [[6, 7, "task"], [11, 12, "task"], [14, 14, "task"], [16, 16, "task"], [19, 20, "task"], [31, 32, "task"], [37, 38, "task"], [41, 43, "product"], [45, 46, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7, 8, 9], "relations": [[6, 7, 11, 12, "related-to", "", true, false], [6, 7, 14, 14, "related-to", "", true, false], [6, 7, 16, 16, "related-to", "", true, false], [41, 43, 37, 38, "type-of", "", false, false], [45, 46, 37, 38, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4, 5], "sentence": ["Aspects", "of", "ontology", "editors", "include", ":", "visual", "navigation", "capabilities", "within", "the", "knowledge", "model", ",", "inference", "and", "extraction", "engines", ",", "module", "support", ",", "import", "and", "export", "of", "foreign", "knowledge", "representation", "languages", "for", "ontology", "matching", ",", "and", "support", "for", "meta", "-ontologies", "such", "as", "OWL", "-", "S", ",", "Dublin", "Core", ",", "etc", "."], "sentence-detokenized": "Aspects of ontology editors include: visual navigation capabilities within the knowledge model, inference and extraction engines, module support, import and export of foreign knowledge representation languages for ontology matching, and support for meta-ontologies such as OWL-S, Dublin Core, etc.", "token2charspan": [[0, 7], [8, 10], [11, 19], [20, 27], [28, 35], [35, 36], [37, 43], [44, 54], [55, 67], [68, 74], [75, 78], [79, 88], [89, 94], [94, 95], [96, 105], [106, 109], [110, 120], [121, 128], [128, 129], [130, 136], [137, 144], [144, 145], [146, 152], [153, 156], [157, 163], [164, 166], [167, 174], [175, 184], [185, 199], [200, 209], [210, 213], [214, 222], [223, 231], [231, 232], [233, 236], [237, 244], [245, 248], [249, 253], [253, 264], [265, 269], [270, 272], [273, 276], [276, 277], [277, 278], [278, 279], [280, 286], [287, 291], [291, 292], [293, 296], [296, 297]]}
{"doc_key": "ai-dev-187", "ner": [[0, 1, "organisation"], [6, 11, "misc"], [13, 17, "task"], [20, 21, "field"], [23, 23, "misc"], [25, 31, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 11, 0, 1, "origin", "", false, false], [13, 17, 6, 11, "part-of", "", false, false], [20, 21, 6, 11, "part-of", "", false, false], [23, 23, 20, 21, "type-of", "", false, false], [25, 31, 20, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "FBI", "has", "also", "introduced", "a", "Next", "Generation", "Identification", "programme", ",", "which", "includes", "facial", "recognition", "as", "well", "as", "more", "traditional", "biometrics", "such", "as", "fingerprints", "and", "iris", "scans", ",", "which", "can", "be", "obtained", "from", "criminal", "and", "civil", "databases", "."], "sentence-detokenized": "The FBI has also introduced a Next Generation Identification programme, which includes facial recognition as well as more traditional biometrics such as fingerprints and iris scans, which can be obtained from criminal and civil databases.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 16], [17, 27], [28, 29], [30, 34], [35, 45], [46, 60], [61, 70], [70, 71], [72, 77], [78, 86], [87, 93], [94, 105], [106, 108], [109, 113], [114, 116], [117, 121], [122, 133], [134, 144], [145, 149], [150, 152], [153, 165], [166, 169], [170, 174], [175, 180], [180, 181], [182, 187], [188, 191], [192, 194], [195, 203], [204, 208], [209, 217], [218, 221], [222, 227], [228, 237], [237, 238]]}
{"doc_key": "ai-dev-188", "ner": [[5, 6, "person"], [8, 9, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "2016", "season", ",", "Samantha", "Ponder", "replaced", "Molly", "McGrath", "as", "host", "."], "sentence-detokenized": "In the 2016 season, Samantha Ponder replaced Molly McGrath as host.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [18, 19], [20, 28], [29, 35], [36, 44], [45, 50], [51, 58], [59, 61], [62, 66], [66, 67]]}
{"doc_key": "ai-dev-189", "ner": [[3, 8, "algorithm"], [17, 21, "misc"], [23, 23, "misc"], [25, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "adversarial", "search", "algorithm", "that", "is", "often", "used", "for", "hardware", "two", "-", "player", "games", "(", "tic", "-", "tac", "-", "toe", ",", "chess", ",", "Go", ",", "etc", "."], "sentence-detokenized": "This is an adversarial search algorithm that is often used for hardware two-player games (tic-tac-toe, chess, Go, etc.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 29], [30, 39], [40, 44], [45, 47], [48, 53], [54, 58], [59, 62], [63, 71], [72, 75], [75, 76], [76, 82], [83, 88], [89, 90], [90, 93], [93, 94], [94, 97], [97, 98], [98, 101], [101, 102], [103, 108], [108, 109], [110, 112], [112, 113], [114, 117], [117, 118]]}
{"doc_key": "ai-dev-190", "ner": [[5, 5, "field"], [7, 8, "field"], [10, 14, "field"], [16, 17, "field"], [19, 20, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "includes", "the", "fields", "of", "computer", "or", "machine", "vision", "and", "medical", "imaging", ",", "and", "often", "uses", "pattern", "recognition", ",", "digital", "geometry", "and", "signal", "processing", "."], "sentence-detokenized": "It includes the fields of computer or machine vision and medical imaging, and often uses pattern recognition, digital geometry and signal processing.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 22], [23, 25], [26, 34], [35, 37], [38, 45], [46, 52], [53, 56], [57, 64], [65, 72], [72, 73], [74, 77], [78, 83], [84, 88], [89, 96], [97, 108], [108, 109], [110, 117], [118, 126], [127, 130], [131, 137], [138, 148], [148, 149]]}
{"doc_key": "ai-dev-191", "ner": [[5, 12, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "in", "a", "face", "recognition", "system", ",", "the", "input", "is", "an", "image", "of", "a", "person", "'s", "face", "and", "the", "output", "is", "the", "person", "'s", "name", "."], "sentence-detokenized": "For example, in a face recognition system, the input is an image of a person's face and the output is the person's name.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 17], [18, 22], [23, 34], [35, 41], [41, 42], [43, 46], [47, 52], [53, 55], [56, 58], [59, 64], [65, 67], [68, 69], [70, 76], [76, 78], [79, 83], [84, 87], [88, 91], [92, 98], [99, 101], [102, 105], [106, 112], [112, 114], [115, 119], [119, 120]]}
{"doc_key": "ai-dev-192", "ner": [[0, 2, "organisation"], [4, 6, "product"], [12, 13, "product"], [16, 19, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 4, 6, "artifact", "", false, false], [4, 6, 12, 13, "part-of", "", false, false], [12, 13, 4, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Apple", "Inc.", "has", "introduced", "Face", "ID", "as", "biometric", "authentication", "on", "its", "flagship", "iPhone", "X", ",", "replacing", "Touch", "ID", ",", "a", "fingerprint", "-", "based", "system", "."], "sentence-detokenized": "Apple Inc. has introduced Face ID as biometric authentication on its flagship iPhone X, replacing Touch ID, a fingerprint-based system.", "token2charspan": [[0, 5], [6, 10], [11, 14], [15, 25], [26, 30], [31, 33], [34, 36], [37, 46], [47, 61], [62, 64], [65, 68], [69, 77], [78, 84], [85, 86], [86, 87], [88, 97], [98, 103], [104, 106], [106, 107], [108, 109], [110, 121], [121, 122], [122, 127], [128, 134], [134, 135]]}
{"doc_key": "ai-dev-193", "ner": [[3, 5, "metrics"], [8, 9, "metrics"], [23, 27, "metrics"], [30, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Or", "combine", "the", "F", "-", "measure", "with", "the", "R-", "squared", "estimated", "for", "the", "raw", "output", "of", "the", "model", "and", "the", "target", ";", "or", "the", "cost", "/", "benefit", "matrix", "with", "the", "correlation", "coefficient", ",", "and", "so", "on", "."], "sentence-detokenized": "Or combine the F-measure with the R-squared estimated for the raw output of the model and the target; or the cost/benefit matrix with the correlation coefficient, and so on.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 16], [16, 17], [17, 24], [25, 29], [30, 33], [34, 36], [36, 43], [44, 53], [54, 57], [58, 61], [62, 65], [66, 72], [73, 75], [76, 79], [80, 85], [86, 89], [90, 93], [94, 100], [100, 101], [102, 104], [105, 108], [109, 113], [113, 114], [114, 121], [122, 128], [129, 133], [134, 137], [138, 149], [150, 161], [161, 162], [163, 166], [167, 169], [170, 172], [172, 173]]}
{"doc_key": "ai-dev-194", "ner": [[0, 6, "conference"], [17, 19, "location"], [21, 21, "location"], [24, 28, "location"], [29, 29, "location"], [31, 31, "country"], [38, 40, "location"], [44, 48, "location"], [49, 49, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 6, 17, 19, "physical", "", false, false], [0, 6, 24, 28, "physical", "", false, false], [0, 6, 38, 40, "physical", "", false, false], [0, 6, 44, 48, "physical", "", false, false], [17, 19, 21, 21, "physical", "", false, false], [24, 28, 29, 29, "physical", "", false, false], [29, 29, 31, 31, "physical", "", false, false], [38, 40, 49, 49, "physical", "", false, false], [44, 48, 49, 49, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "Spanish", "edition", "of", "the", "Campus", "Party", "has", "been", "held", "for", "the", "past", "15", "years", "at", "the", "Colegio", "Miguel", "Hern\u00e1ndez", ",", "Ceulaj", "and", "the", "Benalm\u00e1dena", "Municipal", "Sports", "Arena", "in", "Malaga", ",", "Spain", ",", "as", "well", "as", "at", "the", "Valencia", "County", "Fair", "and", "the", "Valencia", "City", "of", "Arts", "and", "Sciences", "."], "sentence-detokenized": "The Spanish edition of the Campus Party has been held for the past 15 years at the Colegio Miguel Hern\u00e1ndez, Ceulaj and the Benalm\u00e1dena Municipal Sports Arena in Malaga, Spain, as well as at the Valencia County Fair and the Valencia City of Arts and Sciences.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 22], [23, 26], [27, 33], [34, 39], [40, 43], [44, 48], [49, 53], [54, 57], [58, 61], [62, 66], [67, 69], [70, 75], [76, 78], [79, 82], [83, 90], [91, 97], [98, 107], [107, 108], [109, 115], [116, 119], [120, 123], [124, 135], [136, 145], [146, 152], [153, 158], [159, 161], [162, 168], [168, 169], [170, 175], [175, 176], [177, 179], [180, 184], [185, 187], [188, 190], [191, 194], [195, 203], [204, 210], [211, 215], [216, 219], [220, 223], [224, 232], [233, 237], [238, 240], [241, 245], [246, 249], [250, 258], [258, 259]]}
{"doc_key": "ai-dev-195", "ner": [[0, 2, "product"], [15, 15, "programlang"], [18, 18, "product"], [20, 21, "product"], [24, 24, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 15, 0, 2, "general-affiliation", "", false, false], [18, 18, 15, 15, "part-of", "", false, false], [20, 21, 15, 15, "part-of", "", false, false], [24, 24, 0, 2, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Gnuplot", "can", "be", "used", "in", "a", "variety", "of", "programming", "languages", "to", "graph", "data", ",", "including", "Perl", "(", "via", "PDL", "and", "CPAN", "packages", ")", ",", "Python", "(", "via", ")", "."], "sentence-detokenized": "Gnuplot can be used in a variety of programming languages to graph data, including Perl (via PDL and CPAN packages), Python (via).", "token2charspan": [[0, 7], [8, 11], [12, 14], [15, 19], [20, 22], [23, 24], [25, 32], [33, 35], [36, 47], [48, 57], [58, 60], [61, 66], [67, 71], [71, 72], [73, 82], [83, 87], [88, 89], [89, 92], [93, 96], [97, 100], [101, 105], [106, 114], [114, 115], [115, 116], [117, 123], [124, 125], [125, 128], [128, 129], [129, 130]]}
{"doc_key": "ai-dev-196", "ner": [[3, 6, "product"], [19, 19, "conference"], [21, 21, "conference"], [35, 35, "conference"], [37, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 19, 3, 6, "topic", "", false, false], [21, 21, 3, 6, "topic", "", false, false], [35, 35, 3, 6, "topic", "", false, false], [37, 37, 3, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "field", "of", "speech", "dialogue", "systems", "is", "quite", "large", "and", "includes", "research", "(", "presented", "at", "scientific", "conferences", "such", "as", "SIGdial", "and", "Interspeech", ")", "and", "a", "large", "industrial", "sector", "(", "with", "its", "own", "meetings", "such", "as", "SpeechTek", "and", "AVIOS", ")", "."], "sentence-detokenized": "The field of speech dialogue systems is quite large and includes research (presented at scientific conferences such as SIGdial and Interspeech) and a large industrial sector (with its own meetings such as SpeechTek and AVIOS).", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 28], [29, 36], [37, 39], [40, 45], [46, 51], [52, 55], [56, 64], [65, 73], [74, 75], [75, 84], [85, 87], [88, 98], [99, 110], [111, 115], [116, 118], [119, 126], [127, 130], [131, 142], [142, 143], [144, 147], [148, 149], [150, 155], [156, 166], [167, 173], [174, 175], [175, 179], [180, 183], [184, 187], [188, 196], [197, 201], [202, 204], [205, 214], [215, 218], [219, 224], [224, 225], [225, 226]]}
{"doc_key": "ai-dev-197", "ner": [[2, 4, "field"], [7, 8, "task"], [10, 12, "task"], [14, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 2, 4, "part-of", "task_part_of_field", false, false], [10, 12, 2, 4, "part-of", "task_part_of_field", false, false], [14, 16, 2, 4, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Challenges", "in", "natural", "language", "processing", "often", "include", "speech", "recognition", ",", "natural", "language", "understanding", "and", "natural", "language", "production", "."], "sentence-detokenized": "Challenges in natural language processing often include speech recognition, natural language understanding and natural language production.", "token2charspan": [[0, 10], [11, 13], [14, 21], [22, 30], [31, 41], [42, 47], [48, 55], [56, 62], [63, 74], [74, 75], [76, 83], [84, 92], [93, 106], [107, 110], [111, 118], [119, 127], [128, 138], [138, 139]]}
{"doc_key": "ai-dev-198", "ner": [[5, 5, "product"], [7, 7, "product"], [26, 28, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 7, 7, "part-of", "", false, false], [5, 5, 26, 28, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "such", "as", "Siri", "on", "iOS", ",", "work", "on", "a", "similar", "pattern", "recognition", "technique", "to", "text", "-", "based", "systems", ",", "but", "the", "former", "use", "speech", "recognition", "for", "user", "input", "."], "sentence-detokenized": "These systems, such as Siri on iOS, work on a similar pattern recognition technique to text-based systems, but the former use speech recognition for user input.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 22], [23, 27], [28, 30], [31, 34], [34, 35], [36, 40], [41, 43], [44, 45], [46, 53], [54, 61], [62, 73], [74, 83], [84, 86], [87, 91], [91, 92], [92, 97], [98, 105], [105, 106], [107, 110], [111, 114], [115, 121], [122, 125], [126, 132], [133, 144], [145, 148], [149, 153], [154, 159], [159, 160]]}
{"doc_key": "ai-dev-199", "ner": [[1, 8, "algorithm"], [20, 21, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 8, 20, 21, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["More", "exotic", "goodness", "-", "of", "-", "fit", "functions", "that", "examine", "the", "granularity", "of", "the", "model", "include", "the", "area", "under", "the", "ROC", "curve", "and", "the", "rank", "measure", "."], "sentence-detokenized": "More exotic goodness-of-fit functions that examine the granularity of the model include the area under the ROC curve and the rank measure.", "token2charspan": [[0, 4], [5, 11], [12, 20], [20, 21], [21, 23], [23, 24], [24, 27], [28, 37], [38, 42], [43, 50], [51, 54], [55, 66], [67, 69], [70, 73], [74, 79], [80, 87], [88, 91], [92, 96], [97, 102], [103, 106], [107, 110], [111, 116], [117, 120], [121, 124], [125, 129], [130, 137], [137, 138]]}
{"doc_key": "ai-dev-200", "ner": [[2, 6, "product"], [7, 10, "researcher"], [14, 18, "product"], [22, 25, "organisation"], [27, 31, "organisation"], [37, 39, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 6, 7, 10, "origin", "", false, false], [7, 10, 22, 25, "role", "", false, false], [14, 18, 7, 10, "origin", "", false, false], [27, 31, 22, 25, "named", "", false, false], [37, 39, 22, 25, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "term", "Semantic", "Web", "was", "coined", "by", "Tim", "Berners", "-", "Lee", ",", "inventor", "of", "the", "World", "Wide", "Web", "and", "director", "of", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "which", "is", "responsible", "for", "developing", "the", "proposed", "Semantic", "Web", "standards", "."], "sentence-detokenized": "The term Semantic Web was coined by Tim Berners-Lee, inventor of the World Wide Web and director of the World Wide Web Consortium (W3C), which is responsible for developing the proposed Semantic Web standards.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 25], [26, 32], [33, 35], [36, 39], [40, 47], [47, 48], [48, 51], [51, 52], [53, 61], [62, 64], [65, 68], [69, 74], [75, 79], [80, 83], [84, 87], [88, 96], [97, 99], [100, 103], [104, 109], [110, 114], [115, 118], [119, 129], [130, 131], [131, 134], [134, 135], [135, 136], [137, 142], [143, 145], [146, 157], [158, 161], [162, 172], [173, 176], [177, 185], [186, 194], [195, 198], [199, 208], [208, 209]]}
{"doc_key": "ai-dev-201", "ner": [[0, 1, "task"], [5, 5, "task"], [12, 13, "product"], [15, 19, "product"], [21, 21, "product"], [24, 25, "product"], [32, 34, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 12, 13, "opposite", "", false, false], [0, 1, 15, 19, "opposite", "", false, false], [0, 1, 24, 25, "opposite", "", false, false], [0, 1, 32, 34, "part-of", "", false, false], [5, 5, 0, 1, "named", "", false, false], [21, 21, 15, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Machine", "translation", ",", "sometimes", "abbreviated", "MT", "(", "not", "to", "be", "confused", "with", "computer-assisted", "translation", ",", "machine", "-", "assisted", "human", "translation", "(", "MAHT", ")", "or", "interactive", "translation", ")", ",", "is", "a", "subfield", "of", "computational", "linguistics", "that", "studies", "the", "use", "of", "software", "to", "translate", "text", "or", "speech", "from", "one", "language", "into", "another", "."], "sentence-detokenized": "Machine translation, sometimes abbreviated MT (not to be confused with computer-assisted translation, machine-assisted human translation (MAHT) or interactive translation), is a subfield of computational linguistics that studies the use of software to translate text or speech from one language into another.", "token2charspan": [[0, 7], [8, 19], [19, 20], [21, 30], [31, 42], [43, 45], [46, 47], [47, 50], [51, 53], [54, 56], [57, 65], [66, 70], [71, 88], [89, 100], [100, 101], [102, 109], [109, 110], [110, 118], [119, 124], [125, 136], [137, 138], [138, 142], [142, 143], [144, 146], [147, 158], [159, 170], [170, 171], [171, 172], [173, 175], [176, 177], [178, 186], [187, 189], [190, 203], [204, 215], [216, 220], [221, 228], [229, 232], [233, 236], [237, 239], [240, 248], [249, 251], [252, 261], [262, 266], [267, 269], [270, 276], [277, 281], [282, 285], [286, 294], [295, 299], [300, 307], [307, 308]]}
{"doc_key": "ai-dev-202", "ner": [[1, 10, "product"], [8, 8, "university"], [13, 14, "researcher"], [16, 17, "researcher"], [48, 49, "location"], [51, 51, "location"], [42, 47, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 10, 13, 14, "artifact", "", false, false], [1, 10, 16, 17, "artifact", "", false, false], [13, 14, 8, 8, "physical", "", false, false], [13, 14, 8, 8, "role", "", false, false], [16, 17, 8, 8, "physical", "", false, false], [16, 17, 8, 8, "role", "", false, false], [48, 49, 51, 51, "physical", "", false, false], [42, 47, 48, 49, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Early", "MT", "interlanguage", "systems", "were", "also", "built", "at", "Stanford", "in", "the", "1970s", "by", "Roger", "Schank", "and", "Yorick", "Wilks", ";", "the", "former", "became", "the", "basis", "of", "a", "commercial", "resource", "transfer", "system", ",", "and", "the", "code", "of", "the", "latter", "is", "preserved", "as", "the", "first", "machine", "translation", "interlanguage", "system", "by", "the", "Computer", "Museum", "in", "Boston", "."], "sentence-detokenized": "Early MT interlanguage systems were also built at Stanford in the 1970s by Roger Schank and Yorick Wilks; the former became the basis of a commercial resource transfer system, and the code of the latter is preserved as the first machine translation interlanguage system by the Computer Museum in Boston.", "token2charspan": [[0, 5], [6, 8], [9, 22], [23, 30], [31, 35], [36, 40], [41, 46], [47, 49], [50, 58], [59, 61], [62, 65], [66, 71], [72, 74], [75, 80], [81, 87], [88, 91], [92, 98], [99, 104], [104, 105], [106, 109], [110, 116], [117, 123], [124, 127], [128, 133], [134, 136], [137, 138], [139, 149], [150, 158], [159, 167], [168, 174], [174, 175], [176, 179], [180, 183], [184, 188], [189, 191], [192, 195], [196, 202], [203, 205], [206, 215], [216, 218], [219, 222], [223, 228], [229, 236], [237, 248], [249, 262], [263, 269], [270, 272], [273, 276], [277, 285], [286, 292], [293, 295], [296, 302], [302, 303]]}
{"doc_key": "ai-dev-203", "ner": [[0, 0, "researcher"], [6, 10, "conference"], [12, 13, "conference"], [20, 25, "conference"], [27, 28, "conference"], [34, 39, "organisation"], [48, 48, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 6, 10, "role", "", false, false], [0, 0, 20, 25, "role", "", false, false], [0, 0, 34, 39, "role", "", false, false], [0, 0, 48, 48, "role", "", false, false], [12, 13, 6, 10, "named", "", false, false], [27, 28, 20, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sycara", "was", "program", "chair", "of", "the", "Second", "International", "Semantic", "Web", "Conference", "(", "ISWC", "2003", ")", ",", "general", "chair", "of", "the", "Second", "International", "Conference", "on", "Autonomous", "Agents", "(", "Agents", "98", ")", ",", "chair", "of", "the", "steering", "committee", "of", "the", "Agents", "Conference", "(", "1999-2001", ")", ",", "and", "chair", "of", "the", "AAAI", "Fellowship", "Committee", "(", "1993-1999", ")", ";"], "sentence-detokenized": "Sycara was program chair of the Second International Semantic Web Conference (ISWC 2003), general chair of the Second International Conference on Autonomous Agents (Agents 98), chair of the steering committee of the Agents Conference (1999-2001), and chair of the AAAI Fellowship Committee (1993-1999);", "token2charspan": [[0, 6], [7, 10], [11, 18], [19, 24], [25, 27], [28, 31], [32, 38], [39, 52], [53, 61], [62, 65], [66, 76], [77, 78], [78, 82], [83, 87], [87, 88], [88, 89], [90, 97], [98, 103], [104, 106], [107, 110], [111, 117], [118, 131], [132, 142], [143, 145], [146, 156], [157, 163], [164, 165], [165, 171], [172, 174], [174, 175], [175, 176], [177, 182], [183, 185], [186, 189], [190, 198], [199, 208], [209, 211], [212, 215], [216, 222], [223, 233], [234, 235], [235, 244], [244, 245], [245, 246], [247, 250], [251, 256], [257, 259], [260, 263], [264, 268], [269, 279], [280, 289], [290, 291], [291, 300], [300, 301], [301, 302]]}
{"doc_key": "ai-dev-204", "ner": [[11, 11, "conference"], [13, 16, "conference"], [18, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 16, 11, 11, "named", "", false, false], [18, 20, 11, 11, "part-of", "", false, false], [18, 20, 11, 11, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2016", ",", "she", "was", "selected", "as", "the", "winner", "of", "the", "ACL", "(", "Association", "for", "Computational", "Linguistics", ")", "Lifetime", "Achievement", "Award", "."], "sentence-detokenized": "In 2016, she was selected as the winner of the ACL (Association for Computational Linguistics) Lifetime Achievement Award.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 25], [26, 28], [29, 32], [33, 39], [40, 42], [43, 46], [47, 50], [51, 52], [52, 63], [64, 67], [68, 81], [82, 93], [93, 94], [95, 103], [104, 115], [116, 121], [121, 122]]}
{"doc_key": "ai-dev-205", "ner": [[0, 1, "researcher"], [3, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", ",", "Y", ".", "Bengio", ",", "P.", "Frasconi", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Sepp Hochreiter, Y. Bengio, P. Frasconi and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 15], [15, 16], [17, 18], [18, 19], [20, 26], [26, 27], [28, 30], [31, 39], [40, 43], [44, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-206", "ner": [[0, 5, "product"], [8, 9, "misc"], [11, 14, "programlang"], [16, 23, "product"], [33, 33, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 5, 11, 14, "usage", "", false, false], [11, 14, 8, 9, "type-of", "", false, false], [11, 14, 16, 23, "related-to", "", false, false], [33, 33, 0, 5, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["For", "example", ",", "the", "A.L.I.C.E.", "system", "uses", "a", "markup", "language", "called", "AIML", ",", "specific", "to", "its", "dialogue", "system", "function", ",", "which", "has", "since", "been", "adopted", "by", "various", "other", "developers", "of", "so", "-", "called", "Alicebots", "."], "sentence-detokenized": "For example, the A.L.I.C.E. system uses a markup language called AIML, specific to its dialogue system function, which has since been adopted by various other developers of so-called Alicebots.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 27], [28, 34], [35, 39], [40, 41], [42, 48], [49, 57], [58, 64], [65, 69], [69, 70], [71, 79], [80, 82], [83, 86], [87, 95], [96, 102], [103, 111], [111, 112], [113, 118], [119, 122], [123, 128], [129, 133], [134, 141], [142, 144], [145, 152], [153, 158], [159, 169], [170, 172], [173, 175], [175, 176], [176, 182], [183, 192], [192, 193]]}
{"doc_key": "ai-dev-207", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2000", ",", "she", "was", "elected", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2000, she was elected a member of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 24], [25, 26], [27, 33], [34, 36], [37, 40], [41, 52], [53, 56], [57, 60], [61, 72], [73, 75], [76, 86], [87, 99], [99, 100]]}
{"doc_key": "ai-dev-208", "ner": [[0, 2, "misc"], [4, 4, "misc"], [10, 16, "misc"], [23, 25, "algorithm"], [33, 34, "field"], [36, 37, "field"], [39, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 10, 16, "type-of", "", false, false], [0, 2, 33, 34, "related-to", "performs", true, false], [0, 2, 36, 37, "related-to", "performs", true, false], [0, 2, 39, 40, "related-to", "performs", true, false], [4, 4, 0, 2, "named", "", false, false], [23, 25, 10, 16, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Learning", "Classifier", "Systems", "(", "LCS", ")", "are", "a", "family", "of", "rule", "-", "based", "machine", "learning", "algorithms", "that", "combine", "a", "detection", "component", ",", "usually", "a", "genetic", "algorithm", ",", "with", "a", "learning", "component", "that", "performs", "supervised", "learning", ",", "reinforcement", "learning", "or", "unsupervised", "learning", "."], "sentence-detokenized": "Learning Classifier Systems (LCS) are a family of rule-based machine learning algorithms that combine a detection component, usually a genetic algorithm, with a learning component that performs supervised learning, reinforcement learning or unsupervised learning.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 29], [29, 32], [32, 33], [34, 37], [38, 39], [40, 46], [47, 49], [50, 54], [54, 55], [55, 60], [61, 68], [69, 77], [78, 88], [89, 93], [94, 101], [102, 103], [104, 113], [114, 123], [123, 124], [125, 132], [133, 134], [135, 142], [143, 152], [152, 153], [154, 158], [159, 160], [161, 169], [170, 179], [180, 184], [185, 193], [194, 204], [205, 213], [213, 214], [215, 228], [229, 237], [238, 240], [241, 253], [254, 262], [262, 263]]}
{"doc_key": "ai-dev-209", "ner": [[15, 17, "algorithm"], [20, 20, "algorithm"], [29, 31, "algorithm"], [33, 34, "misc"], [43, 49, "algorithm"], [52, 61, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[15, 17, 29, 31, "origin", "", false, false], [15, 17, 33, 34, "usage", "", false, false], [20, 20, 15, 17, "named", "", false, false], [43, 49, 33, 34, "type-of", "", false, false], [43, 49, 52, 61, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "unknown", "parameters", "in", "each", "\u03b2subk", "/", "sub", "vector", "are", "usually", "jointly", "estimated", "by", "the", "maximum", "a", "posteriori", "estimate", "(", "MAP", ")", ",", "which", "is", "an", "extension", "of", "the", "maximum", "likelihood", "using", "a", "regularisation", "of", "the", "weights", "to", "avoid", "pathological", "solutions", "(", "usually", "a", "quadratic", "regularisation", "function", ",", "equivalent", "to", "fitting", "a", "Gaussian", "prior", "distribution", "of", "weights", "with", "zero", "mean", ",", "but", "other", "distributions", "are", "also", "possible", ")", "."], "sentence-detokenized": "The unknown parameters in each \u03b2subk/sub vector are usually jointly estimated by the maximum a posteriori estimate (MAP), which is an extension of the maximum likelihood using a regularisation of the weights to avoid pathological solutions (usually a quadratic regularisation function, equivalent to fitting a Gaussian prior distribution of weights with zero mean, but other distributions are also possible).", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 25], [26, 30], [31, 36], [36, 37], [37, 40], [41, 47], [48, 51], [52, 59], [60, 67], [68, 77], [78, 80], [81, 84], [85, 92], [93, 94], [95, 105], [106, 114], [115, 116], [116, 119], [119, 120], [120, 121], [122, 127], [128, 130], [131, 133], [134, 143], [144, 146], [147, 150], [151, 158], [159, 169], [170, 175], [176, 177], [178, 192], [193, 195], [196, 199], [200, 207], [208, 210], [211, 216], [217, 229], [230, 239], [240, 241], [241, 248], [249, 250], [251, 260], [261, 275], [276, 284], [284, 285], [286, 296], [297, 299], [300, 307], [308, 309], [310, 318], [319, 324], [325, 337], [338, 340], [341, 348], [349, 353], [354, 358], [359, 363], [363, 364], [365, 368], [369, 374], [375, 388], [389, 392], [393, 397], [398, 406], [406, 407], [407, 408]]}
{"doc_key": "ai-dev-210", "ner": [[9, 11, "researcher"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 9, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "hierarchical", "structure", "of", "words", "was", "made", "explicit", "in", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "The hierarchical structure of words was made explicit in George Miller's Wordnet.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 29], [30, 35], [36, 39], [40, 44], [45, 53], [54, 56], [57, 63], [64, 70], [70, 72], [73, 80], [80, 81]]}
{"doc_key": "ai-dev-211", "ner": [[6, 11, "conference"], [16, 20, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 20, 6, 11, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Their", "capabilities", "are", "illustrated", "by", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", ",", "a", "benchmark", "for", "object", "classification", "and", "detection", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "Their capabilities are illustrated by the ImageNet Large Scale Visual Recognition Challenge, a benchmark for object classification and detection with millions of images and hundreds of object classes.", "token2charspan": [[0, 5], [6, 18], [19, 22], [23, 34], [35, 37], [38, 41], [42, 50], [51, 56], [57, 62], [63, 69], [70, 81], [82, 91], [91, 92], [93, 94], [95, 104], [105, 108], [109, 115], [116, 130], [131, 134], [135, 144], [145, 149], [150, 158], [159, 161], [162, 168], [169, 172], [173, 181], [182, 184], [185, 191], [192, 199], [199, 200]]}
{"doc_key": "ai-dev-212", "ner": [[1, 9, "misc"], [25, 25, "misc"], [27, 30, "person"], [32, 32, "misc"], [37, 50, "person"], [43, 45, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[25, 25, 1, 9, "general-affiliation", "", false, false], [32, 32, 1, 9, "general-affiliation", "", false, false], [32, 32, 27, 30, "artifact", "", false, false], [43, 45, 1, 9, "general-affiliation", "", false, false], [43, 45, 37, 50, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "science", "fiction", ",", "female", "-", "looking", "robots", "are", "often", "designed", "to", "be", "used", "as", "domestic", "servants", "and", "sex", "slaves", ",", "as", "in", "the", "film", "Westworld", ",", "Paul", "J.", "McAuley", "'s", "novel", "Fairyland", "(", "1995", ")", "and", "Lester", "del", "Rey", "'s", "short", "story", "Helen", "O'", "Loy", "(", "1938", ")", ",", "but", "sometimes", "as", "warriors", ",", "assassins", "or", "workers", "."], "sentence-detokenized": "In science fiction, female-looking robots are often designed to be used as domestic servants and sex slaves, as in the film Westworld, Paul J. McAuley's novel Fairyland (1995) and Lester del Rey's short story Helen O'Loy (1938), but sometimes as warriors, assassins or workers.", "token2charspan": [[0, 2], [3, 10], [11, 18], [18, 19], [20, 26], [26, 27], [27, 34], [35, 41], [42, 45], [46, 51], [52, 60], [61, 63], [64, 66], [67, 71], [72, 74], [75, 83], [84, 92], [93, 96], [97, 100], [101, 107], [107, 108], [109, 111], [112, 114], [115, 118], [119, 123], [124, 133], [133, 134], [135, 139], [140, 142], [143, 150], [150, 152], [153, 158], [159, 168], [169, 170], [170, 174], [174, 175], [176, 179], [180, 186], [187, 190], [191, 194], [194, 196], [197, 202], [203, 208], [209, 214], [215, 217], [217, 220], [221, 222], [222, 226], [226, 227], [227, 228], [229, 232], [233, 242], [243, 245], [246, 254], [254, 255], [256, 265], [266, 268], [269, 276], [276, 277]]}
{"doc_key": "ai-dev-213", "ner": [[0, 1, "task"], [3, 4, "task"], [6, 7, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["question", "answering", ",", "speech", "recognition", "and", "machine", "translation", "."], "sentence-detokenized": "question answering, speech recognition and machine translation.", "token2charspan": [[0, 8], [9, 18], [18, 19], [20, 26], [27, 38], [39, 42], [43, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-214", "ner": [[5, 6, "researcher"], [9, 17, "organisation"], [15, 18, "location"], [20, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 9, 17, "role", "", false, false], [9, 17, 15, 18, "physical", "", false, false], [15, 18, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "his", "seminal", "paper", ",", "Harry", "Blum", "of", "the", "Air", "Force", "Cambridge", "Research", "Laboratories", "at", "Hanscom", "Air", "Force", "Base", "in", "Bedford", ",", "Massachusetts", ",", "identified", "a", "central", "axis", "for", "calculating", "the", "skeleton", "of", "a", "shape", "using", "an", "intuitive", "model", "of", "fire", "spread", "in", "a", "grass", "field", ",", "where", "the", "field", "has", "the", "shape", "of", "a", "given", "shape", "."], "sentence-detokenized": "In his seminal paper, Harry Blum of the Air Force Cambridge Research Laboratories at Hanscom Air Force Base in Bedford, Massachusetts, identified a central axis for calculating the skeleton of a shape using an intuitive model of fire spread in a grass field, where the field has the shape of a given shape.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 20], [20, 21], [22, 27], [28, 32], [33, 35], [36, 39], [40, 43], [44, 49], [50, 59], [60, 68], [69, 81], [82, 84], [85, 92], [93, 96], [97, 102], [103, 107], [108, 110], [111, 118], [118, 119], [120, 133], [133, 134], [135, 145], [146, 147], [148, 155], [156, 160], [161, 164], [165, 176], [177, 180], [181, 189], [190, 192], [193, 194], [195, 200], [201, 206], [207, 209], [210, 219], [220, 225], [226, 228], [229, 233], [234, 240], [241, 243], [244, 245], [246, 251], [252, 257], [257, 258], [259, 264], [265, 268], [269, 274], [275, 278], [279, 282], [283, 288], [289, 291], [292, 293], [294, 299], [300, 305], [305, 306]]}
{"doc_key": "ai-dev-215", "ner": [[14, 14, "algorithm"], [16, 16, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 19, 20, "compare", "", false, false], [16, 16, 19, 20, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "contrast", "to", "boosting", "algorithms", "that", "analytically", "minimise", "a", "convex", "loss", "function", "(", "e.g.", "AdaBoost", "and", "LogitBoost", ")", ",", "Brown", "Boost", "solves", "a", "system", "of", "two", "equations", "and", "two", "unknowns", "using", "standard", "numerical", "methods", "."], "sentence-detokenized": "In contrast to boosting algorithms that analytically minimise a convex loss function (e.g. AdaBoost and LogitBoost), BrownBoost solves a system of two equations and two unknowns using standard numerical methods.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 23], [24, 34], [35, 39], [40, 52], [53, 61], [62, 63], [64, 70], [71, 75], [76, 84], [85, 86], [86, 90], [91, 99], [100, 103], [104, 114], [114, 115], [115, 116], [117, 122], [122, 127], [128, 134], [135, 136], [137, 143], [144, 146], [147, 150], [151, 160], [161, 164], [165, 168], [169, 177], [178, 183], [184, 192], [193, 202], [203, 210], [210, 211]]}
{"doc_key": "ai-dev-216", "ner": [[0, 2, "researcher"], [9, 13, "misc"], [18, 24, "conference"], [26, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 9, 13, "win-defeat", "", false, false], [0, 2, 18, 24, "role", "", false, false], [26, 26, 18, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Getoor", "has", "received", "several", "best", "paper", "awards", ",", "an", "NSF", "Career", "Award", "and", "is", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Getoor has received several best paper awards, an NSF Career Award and is a member of the Association for the Advancement of Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 27], [28, 32], [33, 38], [39, 45], [45, 46], [47, 49], [50, 53], [54, 60], [61, 66], [67, 70], [71, 73], [74, 75], [76, 82], [83, 85], [86, 89], [90, 101], [102, 105], [106, 109], [110, 121], [122, 124], [125, 135], [136, 148], [149, 150], [150, 154], [154, 155], [155, 156]]}
{"doc_key": "ai-dev-217", "ner": [[0, 3, "misc"], [8, 14, "misc"], [19, 22, "misc"], [27, 33, "misc"], [38, 39, "misc"], [43, 49, "university"], [54, 61, "misc"], [66, 74, "misc"], [79, 83, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Fellow", "of", "the", "ACM", "(", "2015", ")", "br", "Fellow", "of", "the", "Association", "for", "Computational", "Linguistics", "(", "2011", ")", "br", "Fellow", "of", "the", "AAAI", "(", "1994", ")", "br", "Fellow", "of", "the", "International", "Speech", "Communication", "Association", "(", "2011", ")", "br", "Honorary", "Doctorate", "(", "Hedersdoctorate", ")", "from", "the", "Royal", "Institute", "of", "Technology", "KTH", "(", "2007", ")", "br", "Columbia", "Engineering", "School", "Alumni", "Association", "Distinguished", "Teaching", "Award", "(", "2009", ")", "br", "IEEE", "James", "L.", "Flanagan", "Speech", "and", "Audio", "Processing", "Award", "(", "2011", ")", "br", "ISCA", "Medal", "for", "Scientific", "Achievement", "(", "2011", ")"], "sentence-detokenized": "Fellow of the ACM (2015) br Fellow of the Association for Computational Linguistics (2011) br Fellow of the AAAI (1994) br Fellow of the International Speech Communication Association (2011) br Honorary Doctorate (Hedersdoctorate) from the Royal Institute of Technology KTH (2007) br Columbia Engineering School Alumni Association Distinguished Teaching Award (2009) br IEEE James L. Flanagan Speech and Audio Processing Award (2011) br ISCA Medal for Scientific Achievement (2011)", "token2charspan": [[0, 6], [7, 9], [10, 13], [14, 17], [18, 19], [19, 23], [23, 24], [25, 27], [28, 34], [35, 37], [38, 41], [42, 53], [54, 57], [58, 71], [72, 83], [84, 85], [85, 89], [89, 90], [91, 93], [94, 100], [101, 103], [104, 107], [108, 112], [113, 114], [114, 118], [118, 119], [120, 122], [123, 129], [130, 132], [133, 136], [137, 150], [151, 157], [158, 171], [172, 183], [184, 185], [185, 189], [189, 190], [191, 193], [194, 202], [203, 212], [213, 214], [214, 229], [229, 230], [231, 235], [236, 239], [240, 245], [246, 255], [256, 258], [259, 269], [270, 273], [274, 275], [275, 279], [279, 280], [281, 283], [284, 292], [293, 304], [305, 311], [312, 318], [319, 330], [331, 344], [345, 353], [354, 359], [360, 361], [361, 365], [365, 366], [367, 369], [370, 374], [375, 380], [381, 383], [384, 392], [393, 399], [400, 403], [404, 409], [410, 420], [421, 426], [427, 428], [428, 432], [432, 433], [434, 436], [437, 441], [442, 447], [448, 451], [452, 462], [463, 474], [475, 476], [476, 480], [480, 481]]}
{"doc_key": "ai-dev-218", "ner": [[6, 6, "university"], [15, 18, "task"], [32, 35, "metrics"], [19, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[32, 35, 19, 27, "opposite", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["A", "disappointing", "result", "of", "the", "same", "Stanford", "study", "(", "and", "of", "other", "attempts", "to", "improve", "named", "entity", "recognition", "translation", ")", "is", "that", "the", "inclusion", "of", "named", "entity", "translation", "methods", "often", "reduces", "the", "bilingual", "evaluation", "results", "in", "translation", "."], "sentence-detokenized": "A disappointing result of the same Stanford study (and of other attempts to improve named entity recognition translation) is that the inclusion of named entity translation methods often reduces the bilingual evaluation results in translation.", "token2charspan": [[0, 1], [2, 15], [16, 22], [23, 25], [26, 29], [30, 34], [35, 43], [44, 49], [50, 51], [51, 54], [55, 57], [58, 63], [64, 72], [73, 75], [76, 83], [84, 89], [90, 96], [97, 108], [109, 120], [120, 121], [122, 124], [125, 129], [130, 133], [134, 143], [144, 146], [147, 152], [153, 159], [160, 171], [172, 179], [180, 185], [186, 193], [194, 197], [198, 207], [208, 218], [219, 226], [227, 229], [230, 241], [241, 242]]}
{"doc_key": "ai-dev-219", "ner": [[0, 0, "organisation"], [12, 14, "organisation"], [17, 23, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 12, 14, "role", "works_with", false, false], [0, 0, 17, 23, "role", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Medtronic", "uses", "the", "PM", "data", "it", "collects", "and", "works", "with", "researchers", "at", "Johns", "Hopkins", "Hospital", "and", "the", "University", "of", "Washington", "School", "of", "Medicine", "to", "help", "answer", "specific", "questions", "about", "heart", "disease", ",", "such", "as", "whether", "a", "weak", "heart", "causes", "arrhythmia", "or", "vice", "versa", "."], "sentence-detokenized": "Medtronic uses the PM data it collects and works with researchers at Johns Hopkins Hospital and the University of Washington School of Medicine to help answer specific questions about heart disease, such as whether a weak heart causes arrhythmia or vice versa.", "token2charspan": [[0, 9], [10, 14], [15, 18], [19, 21], [22, 26], [27, 29], [30, 38], [39, 42], [43, 48], [49, 53], [54, 65], [66, 68], [69, 74], [75, 82], [83, 91], [92, 95], [96, 99], [100, 110], [111, 113], [114, 124], [125, 131], [132, 134], [135, 143], [144, 146], [147, 151], [152, 158], [159, 167], [168, 177], [178, 183], [184, 189], [190, 197], [197, 198], [199, 203], [204, 206], [207, 214], [215, 216], [217, 221], [222, 227], [228, 234], [235, 245], [246, 248], [249, 253], [254, 259], [259, 260]]}
{"doc_key": "ai-dev-220", "ner": [[4, 5, "organisation"], [9, 10, "misc"], [13, 14, "person"], [16, 17, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 4, 5, "artifact", "made_by_studio", false, false], [13, 14, 9, 10, "role", "", false, false], [16, 17, 9, 10, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "was", "followed", "by", "Paramount", "'s", "first", "feature", "film", ",", "Sangaree", ",", "with", "Fernando", "Lamas", "and", "Arlene", "Dahl", "."], "sentence-detokenized": "This was followed by Paramount's first feature film, Sangaree, with Fernando Lamas and Arlene Dahl.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 20], [21, 30], [30, 32], [33, 38], [39, 46], [47, 51], [51, 52], [53, 61], [61, 62], [63, 67], [68, 76], [77, 82], [83, 86], [87, 93], [94, 98], [98, 99]]}
{"doc_key": "ai-dev-221", "ner": [[0, 0, "programlang"], [8, 10, "researcher"], [12, 13, "researcher"], [15, 16, "organisation"], [18, 20, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 10, "origin", "", false, false], [0, 0, 12, 13, "origin", "", false, false], [8, 10, 15, 16, "physical", "", false, false], [8, 10, 15, 16, "role", "", false, false], [12, 13, 18, 20, "physical", "", false, false], [12, 13, 18, 20, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["KRL", "is", "a", "knowledge", "representation", "language", "developed", "by", "Daniel", "G.", "Bobrow", "and", "Terry", "Winograd", "at", "Xerox", "PARC", "and", "Stanford", "University", "respectively", "."], "sentence-detokenized": "KRL is a knowledge representation language developed by Daniel G. Bobrow and Terry Winograd at Xerox PARC and Stanford University respectively.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 18], [19, 33], [34, 42], [43, 52], [53, 55], [56, 62], [63, 65], [66, 72], [73, 76], [77, 82], [83, 91], [92, 94], [95, 100], [101, 105], [106, 109], [110, 118], [119, 129], [130, 142], [142, 143]]}
{"doc_key": "ai-dev-222", "ner": [[29, 36, "conference"], [0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 14, "researcher"], [20, 21, "task"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[29, 36, 20, 21, "topic", "", true, false], [0, 1, 29, 36, "physical", "", false, false], [0, 1, 29, 36, "role", "", false, false], [0, 1, 29, 36, "temporal", "", false, false], [3, 4, 29, 36, "physical", "", false, false], [3, 4, 29, 36, "role", "", false, false], [3, 4, 29, 36, "temporal", "", false, false], [6, 7, 29, 36, "physical", "", false, false], [6, 7, 29, 36, "role", "", false, false], [6, 7, 29, 36, "temporal", "", false, false], [9, 14, 29, 36, "physical", "", false, false], [9, 14, 29, 36, "role", "", false, false], [9, 14, 29, 36, "temporal", "", false, false], [20, 21, 23, 25, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Qiang", "Zhu", ",", "Shai", "Avidan", ",", "Mei-Chen", "Yeh", "and", "Kwang", "-", "Ting", "Cheng", "presented", "an", "algorithm", "to", "significantly", "speed", "up", "human", "detection", "using", "HOG", "descriptor", "methods", "at", "the", "2006", "IEEE", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "."], "sentence-detokenized": "Qiang Zhu, Shai Avidan, Mei-Chen Yeh and Kwang-Ting Cheng presented an algorithm to significantly speed up human detection using HOG descriptor methods at the 2006 IEEE Conference on Computer Vision and Pattern Recognition.", "token2charspan": [[0, 5], [6, 9], [9, 10], [11, 15], [16, 22], [22, 23], [24, 32], [33, 36], [37, 40], [41, 46], [46, 47], [47, 51], [52, 57], [58, 67], [68, 70], [71, 80], [81, 83], [84, 97], [98, 103], [104, 106], [107, 112], [113, 122], [123, 128], [129, 132], [133, 143], [144, 151], [152, 154], [155, 158], [159, 163], [164, 168], [169, 179], [180, 182], [183, 191], [192, 198], [199, 202], [203, 210], [211, 222], [222, 223]]}
{"doc_key": "ai-dev-223", "ner": [[0, 0, "researcher"], [7, 9, "conference"], [10, 13, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 7, 9, "role", "", false, false], [0, 0, 10, 13, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hayes", "is", "an", "honorary", "member", "of", "the", "AAAI", "and", "the", "Society", "for", "Cognitive", "Science", "."], "sentence-detokenized": "Hayes is an honorary member of the AAAI and the Society for Cognitive Science.", "token2charspan": [[0, 5], [6, 8], [9, 11], [12, 20], [21, 27], [28, 30], [31, 34], [35, 39], [40, 43], [44, 47], [48, 55], [56, 59], [60, 69], [70, 77], [77, 78]]}
{"doc_key": "ai-dev-224", "ner": [[0, 3, "misc"], [5, 5, "field"], [7, 8, "field"], [10, 11, "field"], [13, 13, "field"], [15, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 32, "field"], [41, 42, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[0, 3, 5, 5, "part-of", "", false, false], [0, 3, 5, 5, "usage", "", false, false], [0, 3, 7, 8, "part-of", "", false, false], [0, 3, 7, 8, "usage", "", false, false], [0, 3, 10, 11, "part-of", "", false, false], [0, 3, 10, 11, "usage", "", false, false], [0, 3, 13, 13, "part-of", "", false, false], [0, 3, 13, 13, "usage", "", false, false], [0, 3, 15, 16, "part-of", "", false, false], [0, 3, 15, 16, "usage", "", false, false], [0, 3, 18, 19, "part-of", "", false, false], [0, 3, 18, 19, "usage", "", false, false], [0, 3, 21, 22, "part-of", "", false, false], [0, 3, 21, 22, "usage", "", false, false], [0, 3, 24, 24, "part-of", "", false, false], [0, 3, 24, 24, "usage", "", false, false], [0, 3, 26, 27, "part-of", "", false, false], [0, 3, 26, 27, "usage", "", false, false], [0, 3, 29, 29, "part-of", "", false, false], [0, 3, 29, 29, "usage", "", false, false], [0, 3, 31, 32, "part-of", "", false, false], [0, 3, 31, 32, "usage", "", false, false], [0, 3, 41, 42, "part-of", "", false, false], [0, 3, 41, 42, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "sentence": ["Time", "series", "are", "used", "in", "statistics", ",", "signal", "processing", ",", "pattern", "recognition", ",", "econometrics", ",", "mathematical", "finance", ",", "weather", "forecasting", ",", "earthquake", "prediction", ",", "electroencephalography", ",", "surveillance", "engineering", ",", "astronomy", ",", "communication", "engineering", "and", ",", "in", "general", ",", "all", "areas", "of", "applied", "science", "and", "engineering", "involving", "time", "measurements", "."], "sentence-detokenized": "Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, earthquake prediction, electroencephalography, surveillance engineering, astronomy, communication engineering and, in general, all areas of applied science and engineering involving time measurements.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 23], [24, 34], [34, 35], [36, 42], [43, 53], [53, 54], [55, 62], [63, 74], [74, 75], [76, 88], [88, 89], [90, 102], [103, 110], [110, 111], [112, 119], [120, 131], [131, 132], [133, 143], [144, 154], [154, 155], [156, 178], [178, 179], [180, 192], [193, 204], [204, 205], [206, 215], [215, 216], [217, 230], [231, 242], [243, 246], [246, 247], [248, 250], [251, 258], [258, 259], [260, 263], [264, 269], [270, 272], [273, 280], [281, 288], [289, 292], [293, 304], [305, 314], [315, 319], [320, 332], [332, 333]]}
{"doc_key": "ai-dev-225", "ner": [[13, 16, "metrics"], [34, 36, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "principle", ",", "exact", "restoration", "in", "its", "feasible", "range", "can", "be", "solved", "with", "maximum", "likelihood", ",", "but", "this", "implies", "solving", "a", "constrained", "or", "regularised", "cutting", "problem", "such", "as", "minimum", "bisection", ",", "which", "is", "usually", "NP", "-", "complete", "."], "sentence-detokenized": "In principle, exact restoration in its feasible range can be solved with maximum likelihood, but this implies solving a constrained or regularised cutting problem such as minimum bisection, which is usually NP-complete.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 19], [20, 31], [32, 34], [35, 38], [39, 47], [48, 53], [54, 57], [58, 60], [61, 67], [68, 72], [73, 80], [81, 91], [91, 92], [93, 96], [97, 101], [102, 109], [110, 117], [118, 119], [120, 131], [132, 134], [135, 146], [147, 154], [155, 162], [163, 167], [168, 170], [171, 178], [179, 188], [188, 189], [190, 195], [196, 198], [199, 206], [207, 209], [209, 210], [210, 218], [218, 219]]}
{"doc_key": "ai-dev-226", "ner": [[2, 10, "task"], [11, 11, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 11, 2, 10, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["in", "its", "pedestrian", "detection", "work", ",", "first", "described", "at", "the", "2009", "BMVC", "conference", "."], "sentence-detokenized": "in its pedestrian detection work, first described at the 2009 BMVC conference.", "token2charspan": [[0, 2], [3, 6], [7, 17], [18, 27], [28, 32], [32, 33], [34, 39], [40, 49], [50, 52], [53, 56], [57, 61], [62, 66], [67, 77], [77, 78]]}
{"doc_key": "ai-dev-227", "ner": [[16, 22, "conference"], [3, 3, "researcher"], [6, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 16, 22, "physical", "", false, false], [3, 3, 16, 22, "role", "", false, false], [3, 3, 6, 13, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2007", ",", "Terzopoulos", "received", "the", "first", "IEEE", "PAMI", "Computer", "Vision", "Distinguished", "Researcher", "Award", "at", "the", "International", "Conference", "on", "Computer", "Vision", "for", "his", "pioneering", "and", "sustained", "research", "on", "deformable", "models", "and", "their", "applications", "."], "sentence-detokenized": "In 2007, Terzopoulos received the first IEEE PAMI Computer Vision Distinguished Researcher Award at the International Conference on Computer Vision for his pioneering and sustained research on deformable models and their applications.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 29], [30, 33], [34, 39], [40, 44], [45, 49], [50, 58], [59, 65], [66, 79], [80, 90], [91, 96], [97, 99], [100, 103], [104, 117], [118, 128], [129, 131], [132, 140], [141, 147], [148, 151], [152, 155], [156, 166], [167, 170], [171, 180], [181, 189], [190, 192], [193, 203], [204, 210], [211, 214], [215, 220], [221, 233], [233, 234]]}
{"doc_key": "ai-dev-228", "ner": [[0, 1, "task"], [4, 5, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 4, 5, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cluster", "analysis", ",", "or", "cluster", "analysis", ",", "involves", "grouping", "data", "points", "into", "clusters", "so", "that", "objects", "in", "the", "same", "cluster", "are", "as", "similar", "as", "possible", "and", "objects", "belonging", "to", "different", "clusters", "are", "as", "dissimilar", "as", "possible", "."], "sentence-detokenized": "Cluster analysis, or cluster analysis, involves grouping data points into clusters so that objects in the same cluster are as similar as possible and objects belonging to different clusters are as dissimilar as possible.", "token2charspan": [[0, 7], [8, 16], [16, 17], [18, 20], [21, 28], [29, 37], [37, 38], [39, 47], [48, 56], [57, 61], [62, 68], [69, 73], [74, 82], [83, 85], [86, 90], [91, 98], [99, 101], [102, 105], [106, 110], [111, 118], [119, 122], [123, 125], [126, 133], [134, 136], [137, 145], [146, 149], [150, 157], [158, 167], [168, 170], [171, 180], [181, 189], [190, 193], [194, 196], [197, 207], [208, 210], [211, 219], [219, 220]]}
{"doc_key": "ai-dev-229", "ner": [[8, 12, "field"], [15, 16, "field"], [18, 19, "task"], [21, 22, "field"], [25, 26, "field"], [28, 29, "field"], [32, 33, "field"], [36, 37, "task"], [39, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 12, 15, 16, "named", "", false, false], [8, 12, 21, 22, "named", "", false, false], [8, 12, 28, 29, "named", "", false, false], [18, 19, 15, 16, "part-of", "task_part_of_field", false, false], [25, 26, 21, 22, "part-of", "", false, false], [32, 33, 28, 29, "part-of", "", false, false], [36, 37, 32, 33, "part-of", "", false, false], [39, 39, 32, 33, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["(", "2005", ")", ",", "three", "different", "views", "of", "text", "mining", "can", "be", "distinguished", ",", "namely", "text", "mining", "as", "information", "extraction", ",", "text", "mining", "as", "text", "data", "mining", "and", "text", "mining", "as", "a", "data", "mining", "process", "(", "knowledge", "discovery", "in", "databases", ")", ".", "Hotho", ",", "A.", ",", "N\u00fcrnberger", ",", "A.", "and", "Paa\u00df", ",", "G.", "(", "2005", ")", "."], "sentence-detokenized": "(2005), three different views of text mining can be distinguished, namely text mining as information extraction, text mining as text data mining and text mining as a data mining process (knowledge discovery in databases). Hotho, A., N\u00fcrnberger, A. and Paa\u00df, G. (2005).", "token2charspan": [[0, 1], [1, 5], [5, 6], [6, 7], [8, 13], [14, 23], [24, 29], [30, 32], [33, 37], [38, 44], [45, 48], [49, 51], [52, 65], [65, 66], [67, 73], [74, 78], [79, 85], [86, 88], [89, 100], [101, 111], [111, 112], [113, 117], [118, 124], [125, 127], [128, 132], [133, 137], [138, 144], [145, 148], [149, 153], [154, 160], [161, 163], [164, 165], [166, 170], [171, 177], [178, 185], [186, 187], [187, 196], [197, 206], [207, 209], [210, 219], [219, 220], [220, 221], [222, 227], [227, 228], [229, 231], [231, 232], [233, 243], [243, 244], [245, 247], [248, 251], [252, 256], [256, 257], [258, 260], [261, 262], [262, 266], [266, 267], [267, 268]]}
{"doc_key": "ai-dev-230", "ner": [[0, 2, "product"], [14, 19, "location"], [21, 21, "location"], [23, 23, "location"], [33, 36, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 14, 19, "related-to", "developed_for", false, false], [14, 19, 21, 21, "physical", "", false, false], [21, 21, 23, 23, "physical", "", false, false], [33, 36, 0, 2, "role", "buys", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Rancho", "Arm", "was", "developed", "as", "a", "robotic", "arm", "to", "assist", "disabled", "patients", "at", "Rancho", "Los", "Amigos", "National", "Rehabilitation", "Centre", "in", "Downey", ",", "California", ";", "this", "computer", "-", "controlled", "arm", "was", "purchased", "by", "Stanford", "University", "in", "1963", "."], "sentence-detokenized": "The Rancho Arm was developed as a robotic arm to assist disabled patients at Rancho Los Amigos National Rehabilitation Centre in Downey, California; this computer-controlled arm was purchased by Stanford University in 1963.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 18], [19, 28], [29, 31], [32, 33], [34, 41], [42, 45], [46, 48], [49, 55], [56, 64], [65, 73], [74, 76], [77, 83], [84, 87], [88, 94], [95, 103], [104, 118], [119, 125], [126, 128], [129, 135], [135, 136], [137, 147], [147, 148], [149, 153], [154, 162], [162, 163], [163, 173], [174, 177], [178, 181], [182, 191], [192, 194], [195, 203], [204, 214], [215, 217], [218, 222], [222, 223]]}
{"doc_key": "ai-dev-231", "ner": [[1, 1, "university"], [3, 3, "researcher"], [9, 12, "organisation"], [20, 23, "organisation"], [26, 27, "researcher"], [29, 31, "researcher"], [40, 41, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 1, 1, "physical", "", false, false], [3, 3, 1, 1, "role", "", false, false], [3, 3, 9, 12, "role", "founder", false, false], [3, 3, 20, 23, "role", "founder", false, false], [20, 23, 40, 41, "physical", "", false, false], [26, 27, 20, 23, "role", "founder", false, false], [29, 31, 20, 23, "role", "founder", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["At", "UCSD", ",", "Norman", "was", "a", "founder", "of", "the", "Institute", "for", "Cognitive", "Science", "and", "one", "of", "the", "organisers", "of", "the", "Society", "for", "Cognitive", "Science", "(", "with", "Roger", "Schank", ",", "Allan", "M.", "Collins", "and", "others", ")", ",", "which", "first", "met", "at", "UCSD", "in", "1979", "."], "sentence-detokenized": "At UCSD, Norman was a founder of the Institute for Cognitive Science and one of the organisers of the Society for Cognitive Science (with Roger Schank, Allan M. Collins and others), which first met at UCSD in 1979.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 21], [22, 29], [30, 32], [33, 36], [37, 46], [47, 50], [51, 60], [61, 68], [69, 72], [73, 76], [77, 79], [80, 83], [84, 94], [95, 97], [98, 101], [102, 109], [110, 113], [114, 123], [124, 131], [132, 133], [133, 137], [138, 143], [144, 150], [150, 151], [152, 157], [158, 160], [161, 168], [169, 172], [173, 179], [179, 180], [180, 181], [182, 187], [188, 193], [194, 197], [198, 200], [201, 205], [206, 208], [209, 213], [213, 214]]}
{"doc_key": "ai-dev-232", "ner": [[7, 8, "product"], [10, 11, "product"], [13, 14, "product"], [16, 18, "product"], [20, 21, "product"], [23, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 21, 16, 18, "type-of", "", false, false], [23, 28, 16, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "commonly", "used", "robot", "configurations", "are", "joint", "robots", ",", "SCARA", "robots", ",", "delta", "robots", "and", "Cartesian", "coordinate", "robots", "(", "gantry", "robots", "or", "x", "-", "y", "-", "z", "robots", ")", "."], "sentence-detokenized": "The most commonly used robot configurations are joint robots, SCARA robots, delta robots and Cartesian coordinate robots (gantry robots or x-y-z robots).", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 28], [29, 43], [44, 47], [48, 53], [54, 60], [60, 61], [62, 67], [68, 74], [74, 75], [76, 81], [82, 88], [89, 92], [93, 102], [103, 113], [114, 120], [121, 122], [122, 128], [129, 135], [136, 138], [139, 140], [140, 141], [141, 142], [142, 143], [143, 144], [145, 151], [151, 152], [152, 153]]}
{"doc_key": "ai-dev-233", "ner": [[8, 8, "programlang"], [9, 10, "misc"], [15, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 8, 8, "part-of", "", false, false], [15, 15, 9, 10, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["You", "can", "also", "use", "it", "directly", "with", "the", "Perl", "TM", "module", "(", "which", "also", "supports", "LTM", ")", "."], "sentence-detokenized": "You can also use it directly with the Perl TM module (which also supports LTM).", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 16], [17, 19], [20, 28], [29, 33], [34, 37], [38, 42], [43, 45], [46, 52], [53, 54], [54, 59], [60, 64], [65, 73], [74, 77], [77, 78], [78, 79]]}
{"doc_key": "ai-dev-234", "ner": [[0, 1, "country"], [4, 13, "organisation"], [14, 14, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 13, 0, 1, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "US", "team", "from", "Newton", "Labs", "won", "the", "competition", ",", "which", "was", "broadcast", "on", "CNN", "."], "sentence-detokenized": "The US team from Newton Labs won the competition, which was broadcast on CNN.", "token2charspan": [[0, 3], [4, 6], [7, 11], [12, 16], [17, 23], [24, 28], [29, 32], [33, 36], [37, 48], [48, 49], [50, 55], [56, 59], [60, 69], [70, 72], [73, 76], [76, 77]]}
{"doc_key": "ai-dev-235", "ner": [[0, 4, "misc"], [11, 13, "person"], [15, 16, "person"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 13, 0, 4, "role", "directs", false, false], [15, 16, 0, 4, "role", "acts_in", false, false], [18, 19, 0, 4, "role", "acts_in", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Butler", "'s", "in", "Love", ",", "a", "short", "film", "directed", "by", "David", "Arquette", "and", "starring", "Elizabeth", "Berkley", "and", "Thomas", "Jane", ",", "was", "released", "on", "23", "June", "2008", "."], "sentence-detokenized": "The Butler's in Love, a short film directed by David Arquette and starring Elizabeth Berkley and Thomas Jane, was released on 23 June 2008.", "token2charspan": [[0, 3], [4, 10], [10, 12], [13, 15], [16, 20], [20, 21], [22, 23], [24, 29], [30, 34], [35, 43], [44, 46], [47, 52], [53, 61], [62, 65], [66, 74], [75, 84], [85, 92], [93, 96], [97, 103], [104, 108], [108, 109], [110, 113], [114, 122], [123, 125], [126, 128], [129, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-dev-236", "ner": [[0, 0, "product"], [10, 12, "field"], [18, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 18, 18, "general-affiliation", "", false, false], [10, 12, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "for", "example", ",", "is", "a", "resource", "that", "includes", "a", "taxonomy", "whose", "elements", "are", "the", "meanings", "of", "English", "words", "."], "sentence-detokenized": "WordNet, for example, is a resource that includes a taxonomy whose elements are the meanings of English words.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 20], [20, 21], [22, 24], [25, 26], [27, 35], [36, 40], [41, 49], [50, 51], [52, 60], [61, 66], [67, 75], [76, 79], [80, 83], [84, 92], [93, 95], [96, 103], [104, 109], [109, 110]]}
{"doc_key": "ai-dev-237", "ner": [[1, 6, "product"], [7, 7, "product"], [9, 9, "product"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 1, 6, "type-of", "", false, false], [7, 7, 17, 18, "related-to", "ability_to", false, false], [9, 9, 1, 6, "type-of", "", false, false], [9, 9, 17, 18, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Existing", "humanoid", "robot", "systems", ",", "such", "as", "ASIMO", "and", "QRIO", ",", "use", "a", "number", "of", "motors", "to", "move", "around", "."], "sentence-detokenized": "Existing humanoid robot systems, such as ASIMO and QRIO, use a number of motors to move around.", "token2charspan": [[0, 8], [9, 17], [18, 23], [24, 31], [31, 32], [33, 37], [38, 40], [41, 46], [47, 50], [51, 55], [55, 56], [57, 60], [61, 62], [63, 69], [70, 72], [73, 79], [80, 82], [83, 87], [88, 94], [94, 95]]}
{"doc_key": "ai-dev-238", "ner": [[0, 0, "metrics"], [8, 9, "metrics"], [11, 11, "metrics"], [13, 16, "misc"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 9, 0, 0, "part-of", "", false, false], [11, 11, 0, 0, "part-of", "", false, false], [13, 16, 0, 0, "part-of", "", false, false], [18, 18, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LEPOR", "is", "designed", "with", "the", "factors", "of", "improved", "length", "penalty", ",", "precision", ",", "n-", "gram", "phrase", "penalty", "and", "recall", "."], "sentence-detokenized": "LEPOR is designed with the factors of improved length penalty, precision, n-gram phrase penalty and recall.", "token2charspan": [[0, 5], [6, 8], [9, 17], [18, 22], [23, 26], [27, 34], [35, 37], [38, 46], [47, 53], [54, 61], [61, 62], [63, 72], [72, 73], [74, 76], [76, 80], [81, 87], [88, 95], [96, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-dev-239", "ner": [[5, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "based", "on", "the", "metrics", "for", "assessing", "bilingualism", ",", "but", "with", "some", "modifications", "."], "sentence-detokenized": "It is based on the metrics for assessing bilingualism, but with some modifications.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 14], [15, 18], [19, 26], [27, 30], [31, 40], [41, 53], [53, 54], [55, 58], [59, 63], [64, 68], [69, 82], [82, 83]]}
{"doc_key": "ai-dev-240", "ner": [[8, 8, "product"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "of", "a", "MATLAB", "/", "Octave", "implementation", ":"], "sentence-detokenized": "This is an example of a MATLAB/ Octave implementation:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 23], [24, 30], [30, 31], [32, 38], [39, 53], [53, 54]]}
{"doc_key": "ai-dev-241", "ner": [[11, 11, "programlang"], [13, 13, "programlang"], [15, 15, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "designed", "for", "use", "in", "several", "computing", "languages", ",", "including", "Python", ",", "Ruby", "and", "Scheme", "."], "sentence-detokenized": "It is designed for use in several computing languages, including Python, Ruby and Scheme.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 18], [19, 22], [23, 25], [26, 33], [34, 43], [44, 53], [53, 54], [55, 64], [65, 71], [71, 72], [73, 77], [78, 81], [82, 88], [88, 89]]}
{"doc_key": "ai-dev-242", "ner": [[0, 3, "researcher"], [6, 7, "organisation"], [12, 14, "conference"], [19, 20, "academicjournal"], [25, 27, "organisation"], [33, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 6, 7, "role", "", false, false], [0, 3, 12, 14, "role", "", false, false], [0, 3, 19, 20, "role", "", false, false], [0, 3, 25, 27, "role", "", false, false], [0, 3, 33, 37, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hayes", "has", "served", "as", "Secretary", "of", "the", "AISB", ",", "President", "and", "Trustee", "of", "the", "IJCAI", ",", "Associate", "Editor", "of", "Artificial", "Intelligence", ",", "Governor", "of", "the", "Cognitive", "Science", "Society", ",", "and", "President", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "."], "sentence-detokenized": "Hayes has served as Secretary of the AISB, President and Trustee of the IJCAI, Associate Editor of Artificial Intelligence, Governor of the Cognitive Science Society, and President of the American Association for Artificial Intelligence.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 32], [33, 36], [37, 41], [41, 42], [43, 52], [53, 56], [57, 64], [65, 67], [68, 71], [72, 77], [77, 78], [79, 88], [89, 95], [96, 98], [99, 109], [110, 122], [122, 123], [124, 132], [133, 135], [136, 139], [140, 149], [150, 157], [158, 165], [165, 166], [167, 170], [171, 180], [181, 183], [184, 187], [188, 196], [197, 208], [209, 212], [213, 223], [224, 236], [236, 237]]}
{"doc_key": "ai-dev-243", "ner": [[4, 14, "misc"], [16, 20, "misc"], [23, 24, "person"], [27, 31, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 24, 4, 14, "role", "directed_by", false, false], [23, 24, 16, 20, "role", "directed_by", false, false], [23, 24, 27, 31, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "of", "them", ",", "Now", "is", "the", "Time", "(", "to", "Put", "On", "Your", "Glasses", ")", "and", "Around", "is", "Around", ",", "were", "directed", "by", "Norman", "McLaren", "for", "the", "National", "Film", "Board", "of", "Canada", "in", "1951", "."], "sentence-detokenized": "Two of them, Now is the Time (to Put On Your Glasses) and Around is Around, were directed by Norman McLaren for the National Film Board of Canada in 1951.", "token2charspan": [[0, 3], [4, 6], [7, 11], [11, 12], [13, 16], [17, 19], [20, 23], [24, 28], [29, 30], [30, 32], [33, 36], [37, 39], [40, 44], [45, 52], [52, 53], [54, 57], [58, 64], [65, 67], [68, 74], [74, 75], [76, 80], [81, 89], [90, 92], [93, 99], [100, 107], [108, 111], [112, 115], [116, 124], [125, 129], [130, 135], [136, 138], [139, 145], [146, 148], [149, 153], [153, 154]]}
{"doc_key": "ai-dev-244", "ner": [[3, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "aim", "of", "a", "recommender", "system", "is", "to", "predict", "the", "target", "user", "'s", "preference", "for", "a", "particular", "item", "."], "sentence-detokenized": "The aim of a recommender system is to predict the target user's preference for a particular item.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 12], [13, 24], [25, 31], [32, 34], [35, 37], [38, 45], [46, 49], [50, 56], [57, 61], [61, 63], [64, 74], [75, 78], [79, 80], [81, 91], [92, 96], [96, 97]]}
{"doc_key": "ai-dev-245", "ner": [[0, 0, "algorithm"], [4, 4, "field"], [6, 6, "field"], [8, 9, "field"], [11, 13, "field"], [15, 18, "field"], [17, 17, "field"], [20, 20, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 4, "part-of", "", true, false], [0, 0, 6, 6, "part-of", "", true, false], [0, 0, 8, 9, "part-of", "", true, false], [0, 0, 11, 13, "part-of", "", true, false], [0, 0, 15, 18, "part-of", "", true, false], [0, 0, 17, 17, "part-of", "", true, false], [0, 0, 20, 20, "part-of", "", true, false], [0, 0, 22, 23, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Convolution", "is", "used", "in", "probability", ",", "statistics", ",", "computer", "vision", ",", "natural", "language", "processing", ",", "image", "and", "signal", "processing", ",", "engineering", "and", "differential", "equations", "."], "sentence-detokenized": "Convolution is used in probability, statistics, computer vision, natural language processing, image and signal processing, engineering and differential equations.", "token2charspan": [[0, 11], [12, 14], [15, 19], [20, 22], [23, 34], [34, 35], [36, 46], [46, 47], [48, 56], [57, 63], [63, 64], [65, 72], [73, 81], [82, 92], [92, 93], [94, 99], [100, 103], [104, 110], [111, 121], [121, 122], [123, 134], [135, 138], [139, 151], [152, 161], [161, 162]]}
{"doc_key": "ai-dev-246", "ner": [[0, 0, "field"], [3, 5, "task"], [7, 8, "task"], [10, 10, "task"], [11, 11, "task"], [12, 12, "task"], [14, 15, "task"], [17, 18, "task"], [20, 21, "task"], [23, 23, "task"], [26, 27, "task"], [29, 29, "field"], [31, 31, "field"], [33, 35, "field"], [37, 37, "field"], [39, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[0, 0, 3, 5, "part-of", "", true, false], [0, 0, 7, 8, "part-of", "", true, false], [0, 0, 10, 10, "part-of", "", true, false], [0, 0, 11, 11, "part-of", "", true, false], [0, 0, 12, 12, "part-of", "", true, false], [0, 0, 14, 15, "part-of", "", true, false], [0, 0, 17, 18, "part-of", "", true, false], [0, 0, 20, 21, "part-of", "", true, false], [0, 0, 23, 23, "part-of", "", true, false], [0, 0, 26, 27, "part-of", "", true, false], [0, 0, 29, 29, "part-of", "", true, false], [0, 0, 31, 31, "part-of", "", true, false], [0, 0, 33, 35, "part-of", "", true, false], [0, 0, 37, 37, "part-of", "", true, false], [0, 0, 39, 39, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["DSP", "applications", "include", "audio", "signal", "processing", ",", "audio", "compression", ",", "digital", "image", "processing", ",", "video", "compression", ",", "speech", "processing", ",", "speech", "recognition", ",", "digital", "communications", ",", "digital", "synthesizers", ",", "radar", ",", "sonar", ",", "financial", "signal", "processing", ",", "seismology", "and", "biomedicine", "."], "sentence-detokenized": "DSP applications include audio signal processing, audio compression, digital image processing, video compression, speech processing, speech recognition, digital communications, digital synthesizers, radar, sonar, financial signal processing, seismology and biomedicine.", "token2charspan": [[0, 3], [4, 16], [17, 24], [25, 30], [31, 37], [38, 48], [48, 49], [50, 55], [56, 67], [67, 68], [69, 76], [77, 82], [83, 93], [93, 94], [95, 100], [101, 112], [112, 113], [114, 120], [121, 131], [131, 132], [133, 139], [140, 151], [151, 152], [153, 160], [161, 175], [175, 176], [177, 184], [185, 197], [197, 198], [199, 204], [204, 205], [206, 211], [211, 212], [213, 222], [223, 229], [230, 240], [240, 241], [242, 252], [253, 256], [257, 268], [268, 269]]}
{"doc_key": "ai-dev-247", "ner": [[11, 14, "misc"], [22, 23, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "20", "February", "1912", "-", "11", "August", "2011", ")", "was", "an", "American", "inventor", ",", "best", "known", "for", "creating", "the", "first", "industrial", "robot", ",", "Unimate", "."], "sentence-detokenized": "(20 February 1912 - 11 August 2011) was an American inventor, best known for creating the first industrial robot, Unimate.", "token2charspan": [[0, 1], [1, 3], [4, 12], [13, 17], [18, 19], [20, 22], [23, 29], [30, 34], [34, 35], [36, 39], [40, 42], [43, 51], [52, 60], [60, 61], [62, 66], [67, 72], [73, 76], [77, 85], [86, 89], [90, 95], [96, 106], [107, 112], [112, 113], [114, 121], [121, 122]]}
{"doc_key": "ai-dev-248", "ner": [[1, 3, "researcher"], [5, 7, "researcher"], [9, 9, "researcher"], [20, 25, "algorithm"], [27, 31, "algorithm"], [35, 36, "task"], [37, 40, "algorithm"], [43, 44, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 3, 20, 25, "related-to", "writes_about", true, false], [5, 7, 20, 25, "related-to", "writes_about", true, false], [9, 9, 20, 25, "related-to", "writes_about", true, false], [20, 25, 27, 31, "related-to", "", true, false], [35, 36, 37, 40, "related-to", "", true, false], [43, 44, 37, 40, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["With", "David", "E.", "Rumelhart", "and", "Ronald", "J.", "Williams", ",", "Hinton", "co-authored", "a", "highly", "cited", "paper", "published", "in", "1986", "that", "popularized", "a", "back", "-", "propagation", "algorithm", "for", "training", "multi-layer", "neural", "networks", ",", "the", "dramatic", "milestone", "in", "image", "recognition", "AlexNet", ",", "designed", "by", "his", "student", "Alex", "Krizhevsky", "{{", "cite", "web"], "sentence-detokenized": "With David E. Rumelhart and Ronald J. Williams, Hinton co-authored a highly cited paper published in 1986 that popularized a back-propagation algorithm for training multi-layer neural networks, the dramatic milestone in image recognition AlexNet, designed by his student Alex Krizhevsky {{cite web", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 34], [35, 37], [38, 46], [46, 47], [48, 54], [55, 66], [67, 68], [69, 75], [76, 81], [82, 87], [88, 97], [98, 100], [101, 105], [106, 110], [111, 122], [123, 124], [125, 129], [129, 130], [130, 141], [142, 151], [152, 155], [156, 164], [165, 176], [177, 183], [184, 192], [192, 193], [194, 197], [198, 206], [207, 216], [217, 219], [220, 225], [226, 237], [238, 245], [245, 246], [247, 255], [256, 258], [259, 262], [263, 270], [271, 275], [276, 286], [287, 289], [289, 293], [294, 297]]}
{"doc_key": "ai-dev-249", "ner": [[12, 14, "metrics"], [17, 20, "metrics"], [23, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "predicted", "value", "is", "continuously", "distributed", ",", "we", "can", "use", "the", "mean", "squared", "error", ",", "the", "root", "mean", "squared", "error", "or", "the", "mean", "absolute", "deviation", "to", "summarise", "the", "errors", "."], "sentence-detokenized": "When the predicted value is continuously distributed, we can use the mean squared error, the root mean squared error or the mean absolute deviation to summarise the errors.", "token2charspan": [[0, 4], [5, 8], [9, 18], [19, 24], [25, 27], [28, 40], [41, 52], [52, 53], [54, 56], [57, 60], [61, 64], [65, 68], [69, 73], [74, 81], [82, 87], [87, 88], [89, 92], [93, 97], [98, 102], [103, 110], [111, 116], [117, 119], [120, 123], [124, 128], [129, 137], [138, 147], [148, 150], [151, 160], [161, 164], [165, 171], [171, 172]]}
{"doc_key": "ai-dev-250", "ner": [[0, 2, "algorithm"], [9, 12, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 9, 12, "part-of", "", true, false], [0, 2, 13, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Conceptual", "clustering", "developed", "mainly", "in", "the", "1980s", "as", "a", "machine", "learning", "paradigm", "for", "unsupervised", "learning", "."], "sentence-detokenized": "Conceptual clustering developed mainly in the 1980s as a machine learning paradigm for unsupervised learning.", "token2charspan": [[0, 10], [11, 21], [22, 31], [32, 38], [39, 41], [42, 45], [46, 51], [52, 54], [55, 56], [57, 64], [65, 73], [74, 82], [83, 86], [87, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-dev-251", "ner": [[2, 3, "product"], [27, 32, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "machine", "translator", "can", "not", "recognise", "the", "named", "entities", ",", "it", "may", "mistranslate", "them", "as", "common", "nouns", ",", "which", "would", "probably", "not", "affect", "the", "translation", "score", "in", "a", "bilingual", "evaluation", ",", "but", "would", "change", "the", "human", "readability", "of", "the", "text", "."], "sentence-detokenized": "If the machine translator cannot recognise the named entities, it may mistranslate them as common nouns, which would probably not affect the translation score in a bilingual evaluation, but would change the human readability of the text.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 25], [26, 29], [29, 32], [33, 42], [43, 46], [47, 52], [53, 61], [61, 62], [63, 65], [66, 69], [70, 82], [83, 87], [88, 90], [91, 97], [98, 103], [103, 104], [105, 110], [111, 116], [117, 125], [126, 129], [130, 136], [137, 140], [141, 152], [153, 158], [159, 161], [162, 163], [164, 173], [174, 184], [184, 185], [186, 189], [190, 195], [196, 202], [203, 206], [207, 212], [213, 224], [225, 227], [228, 231], [232, 236], [236, 237]]}
{"doc_key": "ai-dev-252", "ner": [[0, 1, "researcher"], [10, 11, "misc"], [12, 18, "conference"], [20, 22, "location"], [24, 24, "country"], [39, 44, "researcher"], [48, 49, "researcher"], [52, 54, "university"], [56, 57, "researcher"], [59, 60, "researcher"], [62, 63, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 11, "related-to", "writes_about", false, false], [0, 1, 12, 18, "temporal", "", true, false], [12, 18, 20, 22, "physical", "", false, false], [20, 22, 24, 24, "physical", "", false, false], [48, 49, 52, 54, "physical", "", false, false], [48, 49, 52, 54, "role", "", false, false], [56, 57, 52, 54, "physical", "", false, false], [56, 57, 52, 54, "role", "", false, false], [59, 60, 52, 54, "physical", "", false, false], [59, 60, 52, 54, "role", "", false, false], [62, 63, 52, 54, "physical", "", false, false], [62, 63, 52, 54, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Roger", "Schank", ",", "1969", ",", "A", "conceptual", "dependency", "parser", "for", "natural", "language", "Proceedings", "of", "the", "1969", "on", "Computational", "linguistics", ",", "S\u00e5ng", "-", "S\u00e4by", ",", "Sweden", ",", "pages", "1-", "3", "This", "model", ",", "which", "was", "partly", "influenced", "by", "the", "work", "of", "Sydney", "Lamb", ",", "has", "been", "used", "extensively", "by", "Schank", "'s", "students", "at", "Yale", ",", "such", "as", "Robert", "Wilensky", ",", "Wendy", "Lehnert", "and", "Janet", "Kolodner", "."], "sentence-detokenized": "Roger Schank, 1969, A conceptual dependency parser for natural language Proceedings of the 1969 on Computational linguistics, S\u00e5ng-S\u00e4by, Sweden, pages 1-3 This model, which was partly influenced by the work of Sydney Lamb, has been used extensively by Schank's students at Yale, such as Robert Wilensky, Wendy Lehnert and Janet Kolodner.", "token2charspan": [[0, 5], [6, 12], [12, 13], [14, 18], [18, 19], [20, 21], [22, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 71], [72, 83], [84, 86], [87, 90], [91, 95], [96, 98], [99, 112], [113, 124], [124, 125], [126, 130], [130, 131], [131, 135], [135, 136], [137, 143], [143, 144], [145, 150], [151, 153], [153, 154], [155, 159], [160, 165], [165, 166], [167, 172], [173, 176], [177, 183], [184, 194], [195, 197], [198, 201], [202, 206], [207, 209], [210, 216], [217, 221], [221, 222], [223, 226], [227, 231], [232, 236], [237, 248], [249, 251], [252, 258], [258, 260], [261, 269], [270, 272], [273, 277], [277, 278], [279, 283], [284, 286], [287, 293], [294, 302], [302, 303], [304, 309], [310, 317], [318, 321], [322, 327], [328, 336], [336, 337]]}
{"doc_key": "ai-dev-253", "ner": [[2, 4, "algorithm"], [6, 6, "algorithm"], [13, 13, "algorithm"], [15, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 2, 4, "named", "", false, false], [13, 13, 2, 4, "named", "", false, false], [15, 18, 2, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Improved", "Maximum", "Likelihood", "Method", "(", "IMLM", ")", "is", "a", "combination", "of", "two", "MLM", "(", "Maximum", "Likelihood", ")", "estimators", "."], "sentence-detokenized": "The Improved Maximum Likelihood Method (IMLM) is a combination of two MLM (Maximum Likelihood) estimators.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 31], [32, 38], [39, 40], [40, 44], [44, 45], [46, 48], [49, 50], [51, 62], [63, 65], [66, 69], [70, 73], [74, 75], [75, 82], [83, 93], [93, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-dev-254", "ner": [[22, 23, "metrics"], [26, 27, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[26, 27, 22, 23, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["These", "methods", "can", "also", "analyse", "the", "output", "of", "a", "programme", "and", "its", "usability", ",", "so", "they", "may", "include", "an", "analysis", "of", "its", "confusion", "matrix", "(", "or", "confusion", "table", ")", "."], "sentence-detokenized": "These methods can also analyse the output of a programme and its usability, so they may include an analysis of its confusion matrix (or confusion table).", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 22], [23, 30], [31, 34], [35, 41], [42, 44], [45, 46], [47, 56], [57, 60], [61, 64], [65, 74], [74, 75], [76, 78], [79, 83], [84, 87], [88, 95], [96, 98], [99, 107], [108, 110], [111, 114], [115, 124], [125, 131], [132, 133], [133, 135], [136, 145], [146, 151], [151, 152], [152, 153]]}
{"doc_key": "ai-dev-255", "ner": [[0, 0, "product"], [5, 6, "researcher"], [8, 9, "researcher"], [11, 14, "researcher"], [18, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 6, "origin", "", false, false], [0, 0, 8, 9, "origin", "", false, false], [0, 0, 11, 14, "origin", "", false, false], [0, 0, 18, 24, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SURF", "was", "first", "published", "by", "Herbert", "Bay", ",", "Tinne", "Tuytelaars", "and", "Luc", "Van", "Gool", "and", "presented", "at", "the", "European", "Conference", "on", "Computer", "Vision", "in", "2006", "."], "sentence-detokenized": "SURF was first published by Herbert Bay, Tinne Tuytelaars and Luc Van Gool and presented at the European Conference on Computer Vision in 2006.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 24], [25, 27], [28, 35], [36, 39], [39, 40], [41, 46], [47, 57], [58, 61], [62, 65], [66, 69], [70, 74], [75, 78], [79, 88], [89, 91], [92, 95], [96, 104], [105, 115], [116, 118], [119, 127], [128, 134], [135, 137], [138, 142], [142, 143]]}
{"doc_key": "ai-dev-256", "ner": [[0, 0, "task"], [7, 8, "field"], [10, 11, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 8, "part-of", "", false, false], [0, 0, 10, 11, "part-of", "", false, false], [0, 0, 13, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OCR", "is", "an", "area", "of", "research", "in", "pattern", "recognition", ",", "artificial", "intelligence", "and", "computer", "vision", "."], "sentence-detokenized": "OCR is an area of research in pattern recognition, artificial intelligence and computer vision.", "token2charspan": [[0, 3], [4, 6], [7, 9], [10, 14], [15, 17], [18, 26], [27, 29], [30, 37], [38, 49], [49, 50], [51, 61], [62, 74], [75, 78], [79, 87], [88, 94], [94, 95]]}
{"doc_key": "ai-dev-257", "ner": [[6, 8, "metrics"], [11, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 15, 11, 13, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Continuing", "with", "the", "example", "using", "the", "maximum", "likelihood", "estimator", ",", "the", "probability", "density", "function", "(", "pdf", ")", "of", "the", "noise", "for", "a", "single", "mathwn", "/", "math", "sample", "is", "as", "follows"], "sentence-detokenized": "Continuing with the example using the maximum likelihood estimator, the probability density function (pdf) of the noise for a single mathwn/math sample is as follows", "token2charspan": [[0, 10], [11, 15], [16, 19], [20, 27], [28, 33], [34, 37], [38, 45], [46, 56], [57, 66], [66, 67], [68, 71], [72, 83], [84, 91], [92, 100], [101, 102], [102, 105], [105, 106], [107, 109], [110, 113], [114, 119], [120, 123], [124, 125], [126, 132], [133, 139], [139, 140], [140, 144], [145, 151], [152, 154], [155, 157], [158, 165]]}
{"doc_key": "ai-dev-258", "ner": [[2, 3, "field"], [5, 6, "task"], [8, 9, "task"], [11, 12, "task"], [14, 15, "task"], [17, 19, "task"], [21, 21, "task"], [23, 23, "task"], [25, 26, "task"], [28, 29, "task"], [31, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[5, 6, 2, 3, "part-of", "", false, false], [8, 9, 2, 3, "part-of", "", false, false], [11, 12, 2, 3, "part-of", "", false, false], [14, 15, 2, 3, "part-of", "", false, false], [17, 19, 2, 3, "part-of", "", false, false], [21, 21, 2, 3, "part-of", "", false, false], [23, 23, 2, 3, "part-of", "", false, false], [25, 26, 2, 3, "part-of", "", false, false], [28, 29, 2, 3, "part-of", "", false, false], [31, 33, 2, 3, "part-of", "", false, false], [35, 36, 2, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Sub-areas", "of", "computer", "vision", "include", "scene", "reconstruction", ",", "event", "detection", ",", "video", "tracking", ",", "object", "recognition", ",", "3D", "pose", "estimation", ",", "learning", ",", "indexing", ",", "motion", "estimation", ",", "visual", "control", ",", "3D", "scene", "modelling", "and", "image", "restoration", "."], "sentence-detokenized": "Sub-areas of computer vision include scene reconstruction, event detection, video tracking, object recognition, 3D pose estimation, learning, indexing, motion estimation, visual control, 3D scene modelling and image restoration.", "token2charspan": [[0, 9], [10, 12], [13, 21], [22, 28], [29, 36], [37, 42], [43, 57], [57, 58], [59, 64], [65, 74], [74, 75], [76, 81], [82, 90], [90, 91], [92, 98], [99, 110], [110, 111], [112, 114], [115, 119], [120, 130], [130, 131], [132, 140], [140, 141], [142, 150], [150, 151], [152, 158], [159, 169], [169, 170], [171, 177], [178, 185], [185, 186], [187, 189], [190, 195], [196, 205], [206, 209], [210, 215], [216, 227], [227, 228]]}
{"doc_key": "ai-dev-259", "ner": [[11, 16, "conference"], [3, 3, "researcher"], [7, 8, "misc"], [33, 35, "conference"], [28, 28, "researcher"], [30, 35, "researcher"], [20, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 16, 33, 35, "named", "", false, false], [3, 3, 7, 8, "win-defeat", "", false, false], [3, 3, 20, 22, "related-to", "writes_about", true, false], [7, 8, 11, 16, "temporal", "", false, false], [28, 28, 7, 8, "win-defeat", "", false, true], [28, 28, 20, 22, "related-to", "writes_about", true, false], [30, 35, 7, 8, "win-defeat", "", false, true], [30, 35, 20, 22, "related-to", "writes_about", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["In", "2013", ",", "Terzopoulos", "was", "awarded", "the", "Helmholtz", "Prize", "at", "the", "International", "Conference", "on", "Computer", "Vision", "for", "his", "paper", "on", "active", "contour", "models", ",", "which", "he", "co-authored", "with", "Kass", "and", "Witkin", "at", "the", "1987", "ICCV", "conference", "."], "sentence-detokenized": "In 2013, Terzopoulos was awarded the Helmholtz Prize at the International Conference on Computer Vision for his paper on active contour models, which he co-authored with Kass and Witkin at the 1987 ICCV conference.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 24], [25, 32], [33, 36], [37, 46], [47, 52], [53, 55], [56, 59], [60, 73], [74, 84], [85, 87], [88, 96], [97, 103], [104, 107], [108, 111], [112, 117], [118, 120], [121, 127], [128, 135], [136, 142], [142, 143], [144, 149], [150, 152], [153, 164], [165, 169], [170, 174], [175, 178], [179, 185], [186, 188], [189, 192], [193, 197], [198, 202], [203, 213], [213, 214]]}
{"doc_key": "ai-dev-260", "ner": [[16, 17, "task"], [19, 21, "algorithm"], [23, 24, "algorithm"], [26, 28, "algorithm"], [30, 31, "algorithm"], [33, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[16, 17, 19, 21, "usage", "", true, false], [16, 17, 23, 24, "usage", "", true, false], [16, 17, 26, 28, "usage", "", true, false], [16, 17, 30, 31, "usage", "", true, false], [16, 17, 33, 34, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["If", "the", "regularisation", "function", "There", "are", "many", "algorithms", "for", "solving", "such", "problems", ";", "popular", "ones", "for", "linear", "classification", "are", "stochastic", "gradient", "descent", ",", "gradient", "descent", ",", "L", "-", "BFGS", ",", "coordinate", "descent", "and", "Newton", "'s", "method", "."], "sentence-detokenized": "If the regularisation function There are many algorithms for solving such problems; popular ones for linear classification are stochastic gradient descent, gradient descent, L-BFGS, coordinate descent and Newton's method.", "token2charspan": [[0, 2], [3, 6], [7, 21], [22, 30], [31, 36], [37, 40], [41, 45], [46, 56], [57, 60], [61, 68], [69, 73], [74, 82], [82, 83], [84, 91], [92, 96], [97, 100], [101, 107], [108, 122], [123, 126], [127, 137], [138, 146], [147, 154], [154, 155], [156, 164], [165, 172], [172, 173], [174, 175], [175, 176], [176, 180], [180, 181], [182, 192], [193, 200], [201, 204], [205, 211], [211, 213], [214, 220], [220, 221]]}
{"doc_key": "ai-dev-261", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [13, 14, "researcher"], [16, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 13, 14, "origin", "", false, false], [5, 5, 0, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Long", "Short", "Term", "Memory", "(", "LSTM", ")", "networks", "were", "invented", "in", "1997", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "and", "have", "achieved", "records", "in", "accuracy", "in", "several", "application", "areas", "."], "sentence-detokenized": "Long Short Term Memory (LSTM) networks were invented in 1997 by Sepp Hochreiter and J\u00fcrgen Schmidhuber and have achieved records in accuracy in several application areas.", "token2charspan": [[0, 4], [5, 10], [11, 15], [16, 22], [23, 24], [24, 28], [28, 29], [30, 38], [39, 43], [44, 52], [53, 55], [56, 60], [61, 63], [64, 68], [69, 79], [80, 83], [84, 90], [91, 102], [103, 106], [107, 111], [112, 120], [121, 128], [129, 131], [132, 140], [141, 143], [144, 151], [152, 163], [164, 169], [169, 170]]}
{"doc_key": "ai-dev-262", "ner": [[0, 1, "product"], [4, 6, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 4, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["TN", "was", "developed", "at", "Massachusetts", "General", "Hospital", "and", "has", "been", "tested", "in", "several", "scenarios", ",", "including", "identifying", "smoking", "status", ",", "family", "history", "of", "coronary", "artery", "disease", "and", "identifying", "patients", "with", "sleep", "disorders", ","], "sentence-detokenized": "TN was developed at Massachusetts General Hospital and has been tested in several scenarios, including identifying smoking status, family history of coronary artery disease and identifying patients with sleep disorders,", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 33], [34, 41], [42, 50], [51, 54], [55, 58], [59, 63], [64, 70], [71, 73], [74, 81], [82, 91], [91, 92], [93, 102], [103, 114], [115, 122], [123, 129], [129, 130], [131, 137], [138, 145], [146, 148], [149, 157], [158, 164], [165, 172], [173, 176], [177, 188], [189, 197], [198, 202], [203, 208], [209, 218], [218, 219]]}
{"doc_key": "ai-dev-263", "ner": [[3, 3, "researcher"], [8, 13, "product"], [15, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 13, "role", "sells", false, false], [8, 13, 15, 18, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "delivered", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was delivered to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 75], [76, 78], [79, 86], [87, 93], [94, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-dev-264", "ner": [[0, 4, "conference"], [14, 15, "location"], [18, 18, "location"], [20, 25, "country"], [34, 34, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 14, 15, "physical", "", false, false], [14, 15, 18, 18, "physical", "", false, false], [18, 18, 20, 25, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Party", "Europe", "Campus", "took", "place", "from", "14", "to", "18", "April", "2010", "at", "the", "Caja", "M\u00e1gica", "Hotel", "in", "Madrid", ",", "Spain", ",", "and", "was", "attended", "by", "800", "participants", "from", "all", "27", "EU", "Member", "States", "."], "sentence-detokenized": "The Party Europe Campus took place from 14 to 18 April 2010 at the Caja M\u00e1gica Hotel in Madrid, Spain, and was attended by 800 participants from all 27 EU Member States.", "token2charspan": [[0, 3], [4, 9], [10, 16], [17, 23], [24, 28], [29, 34], [35, 39], [40, 42], [43, 45], [46, 48], [49, 54], [55, 59], [60, 62], [63, 66], [67, 71], [72, 78], [79, 84], [85, 87], [88, 94], [94, 95], [96, 101], [101, 102], [103, 106], [107, 110], [111, 119], [120, 122], [123, 126], [127, 139], [140, 144], [145, 148], [149, 151], [152, 154], [155, 161], [162, 168], [168, 169]]}
{"doc_key": "ai-dev-265", "ner": [[7, 7, "organisation"], [9, 14, "organisation"], [16, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 19, 7, 7, "origin", "", false, false], [16, 19, 9, 14, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2016", ",", "a", "collaboration", "between", "DeepMind", "and", "Moorfields", "Eye", "Hospital", "was", "announced", "to", "develop", "AI", "applications", "in", "healthcare", "."], "sentence-detokenized": "In July 2016, a collaboration between DeepMind and Moorfields Eye Hospital was announced to develop AI applications in healthcare.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 15], [16, 29], [30, 37], [38, 46], [47, 50], [51, 61], [62, 65], [66, 74], [75, 78], [79, 88], [89, 91], [92, 99], [100, 102], [103, 115], [116, 118], [119, 129], [129, 130]]}
{"doc_key": "ai-dev-266", "ner": [[5, 6, "misc"], [14, 15, "university"], [17, 17, "university"], [19, 20, "university"], [22, 23, "university"], [25, 25, "university"], [27, 27, "university"], [29, 32, "university"], [34, 35, "university"], [37, 38, "university"], [40, 40, "university"], [43, 45, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[5, 6, 14, 15, "physical", "", false, false], [5, 6, 17, 17, "physical", "", false, false], [5, 6, 19, 20, "physical", "", false, false], [5, 6, 22, 23, "physical", "", false, false], [5, 6, 25, 25, "physical", "", false, false], [5, 6, 27, 27, "physical", "", false, false], [5, 6, 29, 32, "physical", "", false, false], [5, 6, 34, 35, "physical", "", false, false], [5, 6, 37, 38, "physical", "", false, false], [5, 6, 40, 40, "physical", "", false, false], [5, 6, 43, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["In", "the", "end", ",", "11", "PR2", "certificates", "were", "awarded", "to", "different", "institutions", ",", "including", "Freiburg", "University", ",", "Bosch", ",", "Georgia", "Tech", ",", "KU", "Leuven", ",", "MIT", ",", "Stanford", ",", "Technical", "University", "of", "Munich", ",", "UC", "Berkeley", ",", "U", "Penn", ",", "USC", "and", "the", "University", "of", "Tokyo", "."], "sentence-detokenized": "In the end, 11 PR2 certificates were awarded to different institutions, including Freiburg University, Bosch, Georgia Tech, KU Leuven, MIT, Stanford, Technical University of Munich, UC Berkeley, U Penn, USC and the University of Tokyo.", "token2charspan": [[0, 2], [3, 6], [7, 10], [10, 11], [12, 14], [15, 18], [19, 31], [32, 36], [37, 44], [45, 47], [48, 57], [58, 70], [70, 71], [72, 81], [82, 90], [91, 101], [101, 102], [103, 108], [108, 109], [110, 117], [118, 122], [122, 123], [124, 126], [127, 133], [133, 134], [135, 138], [138, 139], [140, 148], [148, 149], [150, 159], [160, 170], [171, 173], [174, 180], [180, 181], [182, 184], [185, 193], [193, 194], [195, 196], [197, 201], [201, 202], [203, 206], [207, 210], [211, 214], [215, 225], [226, 228], [229, 234], [234, 235]]}
{"doc_key": "ai-dev-267", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [7, 7, "metrics"], [9, 9, "metrics"], [18, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 18, 19, "part-of", "", false, false], [5, 5, 18, 19, "part-of", "", false, false], [7, 7, 18, 19, "part-of", "", false, false], [9, 9, 18, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "number", "of", "TPs", ",", "TNs", ",", "FPs", "and", "FNs", "is", "usually", "stored", "in", "a", "table", "called", "a", "confusion", "matrix", "."], "sentence-detokenized": "The number of TPs, TNs, FPs and FNs is usually stored in a table called a confusion matrix.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 17], [17, 18], [19, 22], [22, 23], [24, 27], [28, 31], [32, 35], [36, 38], [39, 46], [47, 53], [54, 56], [57, 58], [59, 64], [65, 71], [72, 73], [74, 83], [84, 90], [90, 91]]}
{"doc_key": "ai-dev-268", "ner": [[0, 1, "metrics"], [3, 4, "metrics"], [6, 7, "metrics"], [10, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Information", "gain", ",", "cross", "-entropy", ",", "mutual", "information", "and", "the", "likelihood", "ratio", "are", "commonly", "used", "as", "a", "set", "of", "functions", "."], "sentence-detokenized": "Information gain, cross-entropy, mutual information and the likelihood ratio are commonly used as a set of functions.", "token2charspan": [[0, 11], [12, 16], [16, 17], [18, 23], [23, 31], [31, 32], [33, 39], [40, 51], [52, 55], [56, 59], [60, 70], [71, 76], [77, 80], [81, 89], [90, 94], [95, 97], [98, 99], [100, 103], [104, 106], [107, 116], [116, 117]]}
{"doc_key": "ai-dev-269", "ner": [[11, 12, "task"], [14, 15, "task"], [17, 17, "task"], [19, 19, "task"], [21, 21, "task"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[23, 23, 21, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "successfully", "applied", "to", "a", "variety", "of", "problems", "including", "robot", "control", ",", "elevator", "scheduling", ",", "telecommunications", ",", "chessboard", "and", "Go", "(", "AlphaGo", ")", "."], "sentence-detokenized": "It has been successfully applied to a variety of problems including robot control, elevator scheduling, telecommunications, chessboard and Go (AlphaGo).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 24], [25, 32], [33, 35], [36, 37], [38, 45], [46, 48], [49, 57], [58, 67], [68, 73], [74, 81], [81, 82], [83, 91], [92, 102], [102, 103], [104, 122], [122, 123], [124, 134], [135, 138], [139, 141], [142, 143], [143, 150], [150, 151], [151, 152]]}
{"doc_key": "ai-dev-270", "ner": [[11, 12, "misc"], [17, 22, "university"], [23, 23, "location"], [25, 28, "location"], [29, 33, "location"], [37, 40, "location"], [41, 41, "location"], [43, 43, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 17, 22, "physical", "", false, false], [17, 22, 23, 23, "physical", "", false, false], [23, 23, 25, 28, "physical", "", false, false], [29, 33, 37, 40, "physical", "", false, false], [37, 40, 41, 41, "physical", "", false, false], [41, 41, 43, 43, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "the", "inaugural", "year", "of", "Mission", "8", ",", "the", "US", "venue", "was", "held", "at", "the", "Georgia", "Institute", "of", "Technology", "campus", "in", "Atlanta", ",", "Georgia", ",", "and", "the", "Asia", "-", "Pacific", "venue", "was", "held", "at", "the", "Beihang", "University", "Gymnasium", "in", "Beijing", ",", "China", "."], "sentence-detokenized": "In 2018, the inaugural year of Mission 8, the US venue was held at the Georgia Institute of Technology campus in Atlanta, Georgia, and the Asia-Pacific venue was held at the Beihang University Gymnasium in Beijing, China.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 22], [23, 27], [28, 30], [31, 38], [39, 40], [40, 41], [42, 45], [46, 48], [49, 54], [55, 58], [59, 63], [64, 66], [67, 70], [71, 78], [79, 88], [89, 91], [92, 102], [103, 109], [110, 112], [113, 120], [120, 121], [122, 129], [129, 130], [131, 134], [135, 138], [139, 143], [143, 144], [144, 151], [152, 157], [158, 161], [162, 166], [167, 169], [170, 173], [174, 181], [182, 192], [193, 202], [203, 205], [206, 213], [213, 214], [215, 220], [220, 221]]}
{"doc_key": "ai-dev-271", "ner": [[0, 2, "field"], [6, 7, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 7, "origin", "", false, false], [0, 2, 6, 7, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "is", "closely", "linked", "to", "pattern", "recognition", "and", "is", "rooted", "in", "artificial", "intelligence", "."], "sentence-detokenized": "Machine learning is closely linked to pattern recognition and is rooted in artificial intelligence.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 34], [35, 37], [38, 45], [46, 57], [58, 61], [62, 64], [65, 71], [72, 74], [75, 85], [86, 98], [98, 99]]}
{"doc_key": "ai-dev-272", "ner": [[3, 4, "programlang"], [14, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "contains", "3", "Java", "games", ",", "controlled", "by", "remote", "control", "and", "displayed", "on", "the", "LCD", "screen", "."], "sentence-detokenized": "It contains 3 Java games, controlled by remote control and displayed on the LCD screen.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 18], [19, 24], [24, 25], [26, 36], [37, 39], [40, 46], [47, 54], [55, 58], [59, 68], [69, 71], [72, 75], [76, 79], [80, 86], [86, 87]]}
{"doc_key": "ai-dev-273", "ner": [[7, 18, "task"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 21, 7, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "commercially", "viable", "but", "specialised", "technique", "for", "assessing", "the", "position", "of", "the", "articulated", "body", "based", "on", "computer", "vision", "is", "optical", "motion", "capture", "."], "sentence-detokenized": "A commercially viable but specialised technique for assessing the position of the articulated body based on computer vision is optical motion capture.", "token2charspan": [[0, 1], [2, 14], [15, 21], [22, 25], [26, 37], [38, 47], [48, 51], [52, 61], [62, 65], [66, 74], [75, 77], [78, 81], [82, 93], [94, 98], [99, 104], [105, 107], [108, 116], [117, 123], [124, 126], [127, 134], [135, 141], [142, 149], [149, 150]]}
{"doc_key": "ai-dev-274", "ner": [[0, 3, "organisation"], [10, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 10, 11, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "SMC", "index", "is", "very", "similar", "to", "the", "more", "popular", "Jaccard", "index", "."], "sentence-detokenized": "The SMC index is very similar to the more popular Jaccard index.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 21], [22, 29], [30, 32], [33, 36], [37, 41], [42, 49], [50, 57], [58, 63], [63, 64]]}
{"doc_key": "ai-dev-275", "ner": [[0, 0, "product"], [2, 6, "product"], [8, 11, "product"], [20, 21, "researcher"], [26, 26, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 11, "named", "", false, false], [0, 0, 20, 21, "artifact", "", false, false], [0, 0, 26, 26, "artifact", "", false, false], [2, 6, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", "or", "Programmable", "Universal", "Manipulation", "Arm", ")", "is", "an", "industrial", "robotic", "arm", "developed", "by", "Victor", "Scheinman", "at", "the", "pioneering", "company", "Unimation", "."], "sentence-detokenized": "PUMA (Programmable Universal Machine for Assembly or Programmable Universal Manipulation Arm) is an industrial robotic arm developed by Victor Scheinman at the pioneering company Unimation.", "token2charspan": [[0, 4], [5, 6], [6, 18], [19, 28], [29, 36], [37, 40], [41, 49], [50, 52], [53, 65], [66, 75], [76, 88], [89, 92], [92, 93], [94, 96], [97, 99], [100, 110], [111, 118], [119, 122], [123, 132], [133, 135], [136, 142], [143, 152], [153, 155], [156, 159], [160, 170], [171, 178], [179, 188], [188, 189]]}
{"doc_key": "ai-dev-276", "ner": [[4, 4, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "written", "in", "Python", "."], "sentence-detokenized": "It is written in Python.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 23], [23, 24]]}
{"doc_key": "ai-dev-277", "ner": [[0, 1, "misc"], [2, 2, "misc"], [12, 12, "field"], [14, 15, "field"], [17, 17, "field"], [20, 20, "field"], [23, 24, "field"], [26, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 2, 2, "related-to", "metric_for", true, false], [0, 1, 12, 12, "part-of", "", false, false], [0, 1, 14, 15, "part-of", "", false, false], [0, 1, 17, 17, "part-of", "", false, false], [0, 1, 20, 20, "part-of", "", false, false], [0, 1, 23, 24, "part-of", "", false, false], [0, 1, 26, 26, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Bandwidth", "in", "hertz", "is", "a", "central", "concept", "in", "many", "fields", ",", "including", "electronics", ",", "information", "theory", ",", "digital", "communications", ",", "radio", "communications", ",", "signal", "processing", "and", "spectroscopy", ",", "and", "is", "one", "of", "the", "factors", "that", "determine", "the", "performance", "of", "a", "given", "communication", "channel", "."], "sentence-detokenized": "Bandwidth in hertz is a central concept in many fields, including electronics, information theory, digital communications, radio communications, signal processing and spectroscopy, and is one of the factors that determine the performance of a given communication channel.", "token2charspan": [[0, 9], [10, 12], [13, 18], [19, 21], [22, 23], [24, 31], [32, 39], [40, 42], [43, 47], [48, 54], [54, 55], [56, 65], [66, 77], [77, 78], [79, 90], [91, 97], [97, 98], [99, 106], [107, 121], [121, 122], [123, 128], [129, 143], [143, 144], [145, 151], [152, 162], [163, 166], [167, 179], [179, 180], [181, 184], [185, 187], [188, 191], [192, 194], [195, 198], [199, 206], [207, 211], [212, 221], [222, 225], [226, 237], [238, 240], [241, 242], [243, 248], [249, 262], [263, 270], [270, 271]]}
{"doc_key": "ai-dev-278", "ner": [[8, 8, "algorithm"], [10, 10, "algorithm"], [16, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 16, 22, "part-of", "", false, false], [10, 10, 16, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["If", "convex", "loss", "is", "used", "(", "as", "in", "AdaBoost", ",", "LogitBoost", "and", "all", "members", "of", "the", "AnyBoost", "family", "of", "algorithms", ")", ",", "then", "the", "case", "with", "the", "larger", "difference", "will", "be", "given", "less", "(", "or", "the", "same", ")", "weight", "as", "the", "case", "with", "the", "smaller", "difference", "."], "sentence-detokenized": "If convex loss is used (as in AdaBoost, LogitBoost and all members of the AnyBoost family of algorithms), then the case with the larger difference will be given less (or the same) weight as the case with the smaller difference.", "token2charspan": [[0, 2], [3, 9], [10, 14], [15, 17], [18, 22], [23, 24], [24, 26], [27, 29], [30, 38], [38, 39], [40, 50], [51, 54], [55, 58], [59, 66], [67, 69], [70, 73], [74, 82], [83, 89], [90, 92], [93, 103], [103, 104], [104, 105], [106, 110], [111, 114], [115, 119], [120, 124], [125, 128], [129, 135], [136, 146], [147, 151], [152, 154], [155, 160], [161, 165], [166, 167], [167, 169], [170, 173], [174, 178], [178, 179], [180, 186], [187, 189], [190, 193], [194, 198], [199, 203], [204, 207], [208, 215], [216, 226], [226, 227]]}
{"doc_key": "ai-dev-279", "ner": [[0, 2, "researcher"], [5, 6, "researcher"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sepp", "Hochreiter", "'s", "1991", "thesis", "Sepp", "Hochreiter", "."], "sentence-detokenized": "Sepp Hochreiter's 1991 thesis Sepp Hochreiter.", "token2charspan": [[0, 4], [5, 15], [15, 17], [18, 22], [23, 29], [30, 34], [35, 45], [45, 46]]}
{"doc_key": "ai-dev-280", "ner": [[4, 5, "algorithm"], [7, 7, "algorithm"], [10, 11, "algorithm"], [14, 14, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"], [27, 28, "algorithm"], [31, 32, "algorithm"], [34, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 7, 4, 5, "named", "", false, false], [14, 14, 10, 11, "named", "", false, false], [17, 19, 27, 28, "related-to", "", true, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Typical", "discriminative", "models", "include", "logistic", "regression", "(", "LR", ")", ",", "support", "vector", "machines", "(", "SVM", ")", ",", "conditional", "random", "fields", "(", "CRF", ")", "(", "defined", "over", "an", "undirected", "graph", ")", ",", "decision", "trees", ",", "neural", "networks", "and", "many", "others", "."], "sentence-detokenized": "Typical discriminative models include logistic regression (LR), support vector machines (SVM), conditional random fields (CRF) (defined over an undirected graph), decision trees, neural networks and many others.", "token2charspan": [[0, 7], [8, 22], [23, 29], [30, 37], [38, 46], [47, 57], [58, 59], [59, 61], [61, 62], [62, 63], [64, 71], [72, 78], [79, 87], [88, 89], [89, 92], [92, 93], [93, 94], [95, 106], [107, 113], [114, 120], [121, 122], [122, 125], [125, 126], [127, 128], [128, 135], [136, 140], [141, 143], [144, 154], [155, 160], [160, 161], [161, 162], [163, 171], [172, 177], [177, 178], [179, 185], [186, 194], [195, 198], [199, 203], [204, 210], [210, 211]]}
{"doc_key": "ai-dev-281", "ner": [[11, 14, "metrics"], [35, 37, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "then", "possible", "to", "use", "these", "probabilities", "to", "estimate", "the", "root", "mean", "square", "error", "(", "or", "other", "similar", "measure", ")", "between", "the", "probabilities", "and", "the", "actual", "values", ",", "and", "then", "combine", "this", "with", "the", "confusion", "matrix", "to", "generate", "very", "efficient", "logistic", "regression", "goodness", "-", "of", "-", "fit", "functions", "."], "sentence-detokenized": "It is then possible to use these probabilities to estimate the root mean square error (or other similar measure) between the probabilities and the actual values, and then combine this with the confusion matrix to generate very efficient logistic regression goodness-of-fit functions.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 19], [20, 22], [23, 26], [27, 32], [33, 46], [47, 49], [50, 58], [59, 62], [63, 67], [68, 72], [73, 79], [80, 85], [86, 87], [87, 89], [90, 95], [96, 103], [104, 111], [111, 112], [113, 120], [121, 124], [125, 138], [139, 142], [143, 146], [147, 153], [154, 160], [160, 161], [162, 165], [166, 170], [171, 178], [179, 183], [184, 188], [189, 192], [193, 202], [203, 209], [210, 212], [213, 221], [222, 226], [227, 236], [237, 245], [246, 256], [257, 265], [265, 266], [266, 268], [268, 269], [269, 272], [273, 282], [282, 283]]}
{"doc_key": "ai-dev-282", "ner": [[0, 1, "product"], [7, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 7, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VoiceOver", "was", "first", "used", "in", "2005", "in", "Mac", "OS", "X", "Tiger", "(", "10.4", ")", "."], "sentence-detokenized": "VoiceOver was first used in 2005 in Mac OS X Tiger (10.4).", "token2charspan": [[0, 9], [10, 13], [14, 19], [20, 24], [25, 27], [28, 32], [33, 35], [36, 39], [40, 42], [43, 44], [45, 50], [51, 52], [52, 56], [56, 57], [57, 58]]}
{"doc_key": "ai-dev-283", "ner": [[12, 15, "algorithm"], [18, 20, "misc"], [25, 26, "metrics"], [29, 37, "algorithm"], [61, 66, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 15, 18, 20, "related-to", "applied_to", false, false], [25, 26, 18, 20, "type-of", "", false, false], [25, 26, 29, 37, "related-to", "used_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "practice", ",", "machine", "learning", "algorithms", "deal", "with", "this", "by", "using", "a", "convex", "approximation", "of", "the", "0", "-", "1", "loss", "function", "(", "such", "as", "the", "hinge", "loss", "for", "a", "support", "vector", "machine", ")", ",", "which", "is", "easier", "to", "optimise", ",", "or", "by", "introducing", "assumptions", "on", "the", "mathP", "(", "x", ",", "y", ")", "/", "math", "distribution", "(", "and", "thus", "ceasing", "to", "be", "agnostic", "learning", "algorithms", ",", "for", "which", "the", "above", "result", "holds", ")", "."], "sentence-detokenized": "In practice, machine learning algorithms deal with this by using a convex approximation of the 0-1 loss function (such as the hinge loss for a support vector machine), which is easier to optimise, or by introducing assumptions on the mathP (x, y)/math distribution (and thus ceasing to be agnostic learning algorithms, for which the above result holds).", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 20], [21, 29], [30, 40], [41, 45], [46, 50], [51, 55], [56, 58], [59, 64], [65, 66], [67, 73], [74, 87], [88, 90], [91, 94], [95, 96], [96, 97], [97, 98], [99, 103], [104, 112], [113, 114], [114, 118], [119, 121], [122, 125], [126, 131], [132, 136], [137, 140], [141, 142], [143, 150], [151, 157], [158, 165], [165, 166], [166, 167], [168, 173], [174, 176], [177, 183], [184, 186], [187, 195], [195, 196], [197, 199], [200, 202], [203, 214], [215, 226], [227, 229], [230, 233], [234, 239], [240, 241], [241, 242], [242, 243], [244, 245], [245, 246], [246, 247], [247, 251], [252, 264], [265, 266], [266, 269], [270, 274], [275, 282], [283, 285], [286, 288], [289, 297], [298, 306], [307, 317], [317, 318], [319, 322], [323, 328], [329, 332], [333, 338], [339, 345], [346, 351], [351, 352], [352, 353]]}
{"doc_key": "ai-dev-284", "ner": [[0, 0, "misc"], [11, 15, "field"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 15, "usage", "", false, false], [0, 0, 20, 20, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Westworld", "(", "1973", ")", "was", "the", "first", "feature", "film", "to", "use", "digital", "image", "processing", "on", "a", "photograph", "to", "simulate", "the", "android", "gaze", "."], "sentence-detokenized": "Westworld (1973) was the first feature film to use digital image processing on a photograph to simulate the android gaze.", "token2charspan": [[0, 9], [10, 11], [11, 15], [15, 16], [17, 20], [21, 24], [25, 30], [31, 38], [39, 43], [44, 46], [47, 50], [51, 58], [59, 64], [65, 75], [76, 78], [79, 80], [81, 91], [92, 94], [95, 103], [104, 107], [108, 115], [116, 120], [120, 121]]}
{"doc_key": "ai-dev-285", "ner": [[7, 8, "task"], [10, 11, "task"], [13, 13, "task"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "now", "also", "widely", "used", "in", "speech", "recognition", ",", "speech", "synthesis", ",", "diarisation", ",", "Xavier", "Anguera", "et", "al", "."], "sentence-detokenized": "It is now also widely used in speech recognition, speech synthesis, diarisation, Xavier Anguera et al.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 14], [15, 21], [22, 26], [27, 29], [30, 36], [37, 48], [48, 49], [50, 56], [57, 66], [66, 67], [68, 79], [79, 80], [81, 87], [88, 95], [96, 98], [99, 101], [101, 102]]}
{"doc_key": "ai-dev-286", "ner": [[10, 14, "algorithm"], [19, 20, "algorithm"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 20, 10, 14, "type-of", "", false, false], [23, 25, 10, 14, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Here", ",", "the", "math", "/", "sigma", "/", "math", "is", "an", "element", "-", "wise", "activation", "function", ",", "such", "as", "a", "sigmoid", "function", "or", "a", "rectified", "linear", "unit", "."], "sentence-detokenized": "Here, the math/sigma/math is an element-wise activation function, such as a sigmoid function or a rectified linear unit.", "token2charspan": [[0, 4], [4, 5], [6, 9], [10, 14], [14, 15], [15, 20], [20, 21], [21, 25], [26, 28], [29, 31], [32, 39], [39, 40], [40, 44], [45, 55], [56, 64], [64, 65], [66, 70], [71, 73], [74, 75], [76, 83], [84, 92], [93, 95], [96, 97], [98, 107], [108, 114], [115, 119], [119, 120]]}
{"doc_key": "ai-dev-287", "ner": [[13, 15, "algorithm"], [23, 23, "misc"], [25, 25, "misc"], [27, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "phonetics", "-", "based", "approaches", "(", "i.e", ".", "all", "models", "based", "on", "the", "hidden", "Markov", "model", ")", "require", "separate", "components", "and", "training", "for", "pronunciation", ",", "acoustic", "and", "language", "models", "."], "sentence-detokenized": "Traditional phonetics-based approaches (i.e. all models based on the hidden Markov model) require separate components and training for pronunciation, acoustic and language models.", "token2charspan": [[0, 11], [12, 21], [21, 22], [22, 27], [28, 38], [39, 40], [40, 43], [43, 44], [45, 48], [49, 55], [56, 61], [62, 64], [65, 68], [69, 75], [76, 82], [83, 88], [88, 89], [90, 97], [98, 106], [107, 117], [118, 121], [122, 130], [131, 134], [135, 148], [148, 149], [150, 158], [159, 162], [163, 171], [172, 178], [178, 179]]}
{"doc_key": "ai-dev-288", "ner": [[0, 5, "algorithm"], [7, 8, "field"], [10, 11, "field"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 5, 13, 14, "related-to", "used_for", false, false], [7, 8, 0, 5, "usage", "", false, false], [10, 11, 0, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Roberts", "cross", "operator", "is", "used", "in", "image", "processing", "and", "computer", "vision", "to", "detect", "edges", "."], "sentence-detokenized": "The Roberts cross operator is used in image processing and computer vision to detect edges.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 37], [38, 43], [44, 54], [55, 58], [59, 67], [68, 74], [75, 77], [78, 84], [85, 90], [90, 91]]}
{"doc_key": "ai-dev-289", "ner": [[0, 1, "metrics"], [3, 3, "metrics"], [25, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 25, 25, "opposite", "", false, false], [3, 3, 25, 25, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "sensitivity", "and", "specificity", "values", "do", "not", "depend", "on", "the", "percentage", "of", "positive", "cases", "in", "the", "population", "(", "as", "opposed", "to", ",", "for", "example", ",", "accuracy", ")", "."], "sentence-detokenized": "The sensitivity and specificity values do not depend on the percentage of positive cases in the population (as opposed to, for example, accuracy).", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 31], [32, 38], [39, 41], [42, 45], [46, 52], [53, 55], [56, 59], [60, 70], [71, 73], [74, 82], [83, 88], [89, 91], [92, 95], [96, 106], [107, 108], [108, 110], [111, 118], [119, 121], [121, 122], [123, 126], [127, 134], [134, 135], [136, 144], [144, 145], [145, 146]]}
{"doc_key": "ai-dev-290", "ner": [[2, 3, "algorithm"], [16, 16, "misc"], [9, 10, "researcher"], [12, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 16, 2, 3, "topic", "", false, false], [16, 16, 9, 10, "artifact", "", false, false], [16, 16, 12, 14, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["However", ",", "perceptron", "models", "became", "very", "unpopular", "thanks", "to", "Marvin", "Minsky", "and", "Seymour", "Papert", "'s", "book", "Perceptrons", ",", "published", "in", "1969", "."], "sentence-detokenized": "However, perceptron models became very unpopular thanks to Marvin Minsky and Seymour Papert's book Perceptrons, published in 1969.", "token2charspan": [[0, 7], [7, 8], [9, 19], [20, 26], [27, 33], [34, 38], [39, 48], [49, 55], [56, 58], [59, 65], [66, 72], [73, 76], [77, 84], [85, 91], [91, 93], [94, 98], [99, 110], [110, 111], [112, 121], [122, 124], [125, 129], [129, 130]]}
{"doc_key": "ai-dev-291", "ner": [[3, 7, "conference"], [0, 2, "organisation"], [19, 21, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 7, 19, 21, "topic", "", false, false], [0, 2, 3, 7, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "annual", "NIST", "Document", "Understanding", "Conferences", "have", "developed", "sophisticated", "criteria", "for", "evaluating", "techniques", "that", "take", "on", "the", "challenge", "of", "summarising", "multiple", "documents", "."], "sentence-detokenized": "The annual NIST Document Understanding Conferences have developed sophisticated criteria for evaluating techniques that take on the challenge of summarising multiple documents.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 24], [25, 38], [39, 50], [51, 55], [56, 65], [66, 79], [80, 88], [89, 92], [93, 103], [104, 114], [115, 119], [120, 124], [125, 127], [128, 131], [132, 141], [142, 144], [145, 156], [157, 165], [166, 175], [175, 176]]}
{"doc_key": "ai-dev-292", "ner": [[0, 2, "product"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 19, 21, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "parallel", "manipulator", "is", "designed", "so", "that", "each", "chain", "is", "usually", "short", ",", "simple", "and", "therefore", ",", "compared", "to", "a", "sequential", "manipulator", ",", "can", "be", "rigid", "against", "unwanted", "movements", "."], "sentence-detokenized": "A parallel manipulator is designed so that each chain is usually short, simple and therefore, compared to a sequential manipulator, can be rigid against unwanted movements.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 34], [35, 37], [38, 42], [43, 47], [48, 53], [54, 56], [57, 64], [65, 70], [70, 71], [72, 78], [79, 82], [83, 92], [92, 93], [94, 102], [103, 105], [106, 107], [108, 118], [119, 130], [130, 131], [132, 135], [136, 138], [139, 144], [145, 152], [153, 161], [162, 171], [171, 172]]}
{"doc_key": "ai-dev-293", "ner": [[27, 27, "misc"], [29, 33, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "the", "manipulator", "that", "allows", "the", "robot", "to", "move", ",", "and", "the", "design", "of", "these", "systems", "can", "be", "classified", "into", "several", "common", "types", ",", "such", "as", "SCARA", "and", "Cartesian", "coordinate", "robots", ",", "which", "use", "different", "coordinate", "systems", "to", "guide", "the", "machine", "'s", "arms", "."], "sentence-detokenized": "It is the manipulator that allows the robot to move, and the design of these systems can be classified into several common types, such as SCARA and Cartesian coordinate robots, which use different coordinate systems to guide the machine's arms.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 21], [22, 26], [27, 33], [34, 37], [38, 43], [44, 46], [47, 51], [51, 52], [53, 56], [57, 60], [61, 67], [68, 70], [71, 76], [77, 84], [85, 88], [89, 91], [92, 102], [103, 107], [108, 115], [116, 122], [123, 128], [128, 129], [130, 134], [135, 137], [138, 143], [144, 147], [148, 157], [158, 168], [169, 175], [175, 176], [177, 182], [183, 186], [187, 196], [197, 207], [208, 215], [216, 218], [219, 224], [225, 228], [229, 236], [236, 238], [239, 243], [243, 244]]}
{"doc_key": "ai-dev-294", "ner": [[2, 5, "country"], [9, 13, "organisation"], [16, 23, "organisation"], [24, 26, "organisation"], [29, 31, "organisation"], [34, 40, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 13, 2, 5, "physical", "", false, false], [16, 23, 2, 5, "physical", "", false, false], [24, 26, 2, 5, "physical", "", false, false], [29, 31, 2, 5, "physical", "", false, false], [34, 40, 2, 5, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "USA", ",", "he", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Linguistic", "Society", ",", "the", "American", "Philosophical", "Association", "and", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In the USA, he is a member of the National Academy of Sciences, the American Academy of Arts and Sciences, the American Linguistic Society, the American Philosophical Association and the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 6], [7, 10], [10, 11], [12, 14], [15, 17], [18, 19], [20, 26], [27, 29], [30, 33], [34, 42], [43, 50], [51, 53], [54, 62], [62, 63], [64, 67], [68, 76], [77, 84], [85, 87], [88, 92], [93, 96], [97, 105], [105, 106], [107, 110], [111, 119], [120, 130], [131, 138], [138, 139], [140, 143], [144, 152], [153, 166], [167, 178], [179, 182], [183, 186], [187, 195], [196, 207], [208, 211], [212, 215], [216, 227], [228, 230], [231, 238], [238, 239]]}
{"doc_key": "ai-dev-295", "ner": [[13, 15, "algorithm"], [17, 20, "algorithm"], [21, 23, "algorithm"], [28, 30, "algorithm"], [34, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 15, 21, 23, "named", "", false, false], [17, 20, 13, 15, "named", "", false, false], [21, 23, 28, 30, "compare", "", false, false], [21, 23, 34, 35, "related-to", "performs", false, false], [28, 30, 34, 35, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["They", "became", "very", "popular", "in", "the", "1990s", "due", "to", "the", "popularity", "of", "the", "support", "vector", "machine", "(", "SVM", ")", ",", "when", "SVM", "was", "shown", "to", "be", "competitive", "with", "neural", "networks", "in", "tasks", "such", "as", "handwriting", "recognition", "."], "sentence-detokenized": "They became very popular in the 1990s due to the popularity of the support vector machine (SVM), when SVM was shown to be competitive with neural networks in tasks such as handwriting recognition.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 24], [25, 27], [28, 31], [32, 37], [38, 41], [42, 44], [45, 48], [49, 59], [60, 62], [63, 66], [67, 74], [75, 81], [82, 89], [90, 91], [91, 94], [94, 95], [95, 96], [97, 101], [102, 105], [106, 109], [110, 115], [116, 118], [119, 121], [122, 133], [134, 138], [139, 145], [146, 154], [155, 157], [158, 163], [164, 168], [169, 171], [172, 183], [184, 195], [195, 196]]}
{"doc_key": "ai-dev-296", "ner": [[2, 3, "misc"], [9, 11, "misc"], [12, 13, "algorithm"], [21, 24, "misc"], [25, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 11, "usage", "", false, false], [2, 3, 21, 24, "usage", "", false, false], [9, 11, 12, 13, "origin", "result_of_algorithm", false, false], [21, 24, 25, 26, "origin", "result_of_algorithm", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "empirical", "whitening", "transformation", "is", "obtained", "by", "estimating", "the", "covariance", "(", "e.g.", "maximum", "likelihood", ")", "and", "then", "constructing", "the", "corresponding", "estimated", "whitening", "matrix", "(", "e.g.", "Cholesky", "decomposition", ")", "."], "sentence-detokenized": "The empirical whitening transformation is obtained by estimating the covariance (e.g. maximum likelihood) and then constructing the corresponding estimated whitening matrix (e.g. Cholesky decomposition).", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 38], [39, 41], [42, 50], [51, 53], [54, 64], [65, 68], [69, 79], [80, 81], [81, 85], [86, 93], [94, 104], [104, 105], [106, 109], [110, 114], [115, 127], [128, 131], [132, 145], [146, 155], [156, 165], [166, 172], [173, 174], [174, 178], [179, 187], [188, 201], [201, 202], [202, 203]]}
{"doc_key": "ai-dev-297", "ner": [[0, 2, "organisation"], [8, 10, "product"], [23, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 0, 2, "artifact", "", false, false], [23, 24, 0, 2, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["IAI", "is", "the", "world", "'s", "largest", "manufacturer", "of", "Cartesian", "coordinate", "robots", "and", "an", "established", "leader", "in", "low", "-", "cost", ",", "high", "-", "performance", "SCARA", "robots", "."], "sentence-detokenized": "IAI is the world's largest manufacturer of Cartesian coordinate robots and an established leader in low-cost, high-performance SCARA robots.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [16, 18], [19, 26], [27, 39], [40, 42], [43, 52], [53, 63], [64, 70], [71, 74], [75, 77], [78, 89], [90, 96], [97, 99], [100, 103], [103, 104], [104, 108], [108, 109], [110, 114], [114, 115], [115, 126], [127, 132], [133, 139], [139, 140]]}
{"doc_key": "ai-dev-298", "ner": [[10, 11, "field"], [13, 14, "field"], [16, 17, "field"], [19, 20, "field"], [22, 24, "field"], [27, 27, "field"], [29, 29, "field"], [31, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["Formal", "concept", "analysis", "has", "practical", "applications", "in", "areas", "such", "as", "data", "mining", ",", "text", "mining", ",", "machine", "learning", ",", "knowledge", "management", ",", "the", "semantic", "web", ",", "software", "development", ",", "chemistry", "and", "biology", "."], "sentence-detokenized": "Formal concept analysis has practical applications in areas such as data mining, text mining, machine learning, knowledge management, the semantic web, software development, chemistry and biology.", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 27], [28, 37], [38, 50], [51, 53], [54, 59], [60, 64], [65, 67], [68, 72], [73, 79], [79, 80], [81, 85], [86, 92], [92, 93], [94, 101], [102, 110], [110, 111], [112, 121], [122, 132], [132, 133], [134, 137], [138, 146], [147, 150], [150, 151], [152, 160], [161, 172], [172, 173], [174, 183], [184, 187], [188, 195], [195, 196]]}
{"doc_key": "ai-dev-299", "ner": [[1, 2, "field"], [4, 6, "field"], [10, 11, "field"], [17, 20, "field"], [26, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 17, 20, "part-of", "", false, false], [4, 6, 26, 28, "topic", "", false, false], [10, 11, 4, 6, "named", "", false, false], [17, 20, 1, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", ",", "machine", "learning", "theory", "(", "or", "just", "learning", "theory", ")", "is", "a", "subfield", "of", "artificial", "intelligence", "that", "studies", "the", "design", "and", "analysis", "of", "machine", "learning", "algorithms", "."], "sentence-detokenized": "In computer science, machine learning theory (or just learning theory) is a subfield of artificial intelligence that studies the design and analysis of machine learning algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 28], [29, 37], [38, 44], [45, 46], [46, 48], [49, 53], [54, 62], [63, 69], [69, 70], [71, 73], [74, 75], [76, 84], [85, 87], [88, 98], [99, 111], [112, 116], [117, 124], [125, 128], [129, 135], [136, 139], [140, 148], [149, 151], [152, 159], [160, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-dev-300", "ner": [[0, 1, "algorithm"], [3, 3, "algorithm"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 0, 1, "named", "", false, false], [10, 10, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Collaborative", "filtering", "(", "CF", ")", "is", "a", "technique", "used", "in", "recommender", "systems", "."], "sentence-detokenized": "Collaborative filtering (CF) is a technique used in recommender systems.", "token2charspan": [[0, 13], [14, 23], [24, 25], [25, 27], [27, 28], [29, 31], [32, 33], [34, 43], [44, 48], [49, 51], [52, 63], [64, 71], [71, 72]]}
{"doc_key": "ai-dev-301", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "false", "positive", "rate", "is", "the", "proportion", "of", "all", "negative", "results", "where", "the", "test", "result", "is", "still", "positive", ",", "i.e.", "the", "conditional", "probability", "of", "a", "positive", "test", "result", "for", "an", "event", "that", "was", "not", "present", "."], "sentence-detokenized": "The false positive rate is the proportion of all negative results where the test result is still positive, i.e. the conditional probability of a positive test result for an event that was not present.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 23], [24, 26], [27, 30], [31, 41], [42, 44], [45, 48], [49, 57], [58, 65], [66, 71], [72, 75], [76, 80], [81, 87], [88, 90], [91, 96], [97, 105], [105, 106], [107, 111], [112, 115], [116, 127], [128, 139], [140, 142], [143, 144], [145, 153], [154, 158], [159, 165], [166, 169], [170, 172], [173, 178], [179, 183], [184, 187], [188, 191], [192, 199], [199, 200]]}
{"doc_key": "ai-dev-302", "ner": [[1, 15, "misc"], [38, 39, "metrics"], [42, 43, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 15, 38, 39, "topic", "", false, false], [1, 15, 42, 43, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "VLDB", "'", "8", ":", "Proceedings", "of", "the", "34th", "International", "Conference", "on", "Very", "Large", "Data", "Bases", ",", "pages", "422-433", ".", "showed", "that", "the", "given", "values", "for", "mathC", "/", "math", "and", "mathK", "/", "math", "generally", "imply", "a", "relatively", "low", "precision", "of", "iteratively", "computed", "SimRank", "results", "."], "sentence-detokenized": "In VLDB '8: Proceedings of the 34th International Conference on Very Large Data Bases, pages 422-433. showed that the given values for mathC/math and mathK/math generally imply a relatively low precision of iteratively computed SimRank results.", "token2charspan": [[0, 2], [3, 7], [8, 9], [9, 10], [10, 11], [12, 23], [24, 26], [27, 30], [31, 35], [36, 49], [50, 60], [61, 63], [64, 68], [69, 74], [75, 79], [80, 85], [85, 86], [87, 92], [93, 100], [100, 101], [102, 108], [109, 113], [114, 117], [118, 123], [124, 130], [131, 134], [135, 140], [140, 141], [141, 145], [146, 149], [150, 155], [155, 156], [156, 160], [161, 170], [171, 176], [177, 178], [179, 189], [190, 193], [194, 203], [204, 206], [207, 218], [219, 227], [228, 235], [236, 243], [243, 244]]}
{"doc_key": "ai-dev-303", "ner": [[0, 4, "misc"], [5, 5, "misc"], [15, 15, "person"], [17, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 0, 4, "general-affiliation", "", false, false], [5, 5, 15, 15, "artifact", "", false, false], [5, 5, 17, 19, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "sci", "-", "fi", "drama", "Sense8", "debuted", "in", "June", "2015", ",", "written", "and", "produced", "by", "Wachowski", "and", "J.", "Michael", "Straczynski", "."], "sentence-detokenized": "The sci-fi drama Sense8 debuted in June 2015, written and produced by Wachowski and J. Michael Straczynski.", "token2charspan": [[0, 3], [4, 7], [7, 8], [8, 10], [11, 16], [17, 23], [24, 31], [32, 34], [35, 39], [40, 44], [44, 45], [46, 53], [54, 57], [58, 66], [67, 69], [70, 79], [80, 83], [84, 86], [87, 94], [95, 106], [106, 107]]}
{"doc_key": "ai-dev-304", "ner": [[1, 1, "misc"], [6, 9, "product"], [28, 34, "misc"], [38, 38, "country"], [40, 40, "country"], [42, 42, "country"], [44, 44, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 1, 6, 9, "topic", "", false, false], [38, 38, 28, 34, "type-of", "", false, false], [40, 40, 28, 34, "type-of", "", false, false], [42, 42, 28, 34, "type-of", "", false, false], [44, 44, 28, 34, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Although", "Eurotra", "never", "delivered", "a", "functioning", "MT", "system", ",", "the", "project", "had", "a", "long", "-", "term", "and", "far", "-", "reaching", "impact", "on", "the", "emerging", "language", "industries", "in", "the", "European", "Member", "States", ",", "especially", "in", "the", "southern", "countries", "of", "Greece", ",", "Italy", ",", "Spain", "and", "Portugal", "."], "sentence-detokenized": "Although Eurotra never delivered a functioning MT system, the project had a long-term and far-reaching impact on the emerging language industries in the European Member States, especially in the southern countries of Greece, Italy, Spain and Portugal.", "token2charspan": [[0, 8], [9, 16], [17, 22], [23, 32], [33, 34], [35, 46], [47, 49], [50, 56], [56, 57], [58, 61], [62, 69], [70, 73], [74, 75], [76, 80], [80, 81], [81, 85], [86, 89], [90, 93], [93, 94], [94, 102], [103, 109], [110, 112], [113, 116], [117, 125], [126, 134], [135, 145], [146, 148], [149, 152], [153, 161], [162, 168], [169, 175], [175, 176], [177, 187], [188, 190], [191, 194], [195, 203], [204, 213], [214, 216], [217, 223], [223, 224], [225, 230], [230, 231], [232, 237], [238, 241], [242, 250], [250, 251]]}
{"doc_key": "ai-dev-305", "ner": [[0, 5, "algorithm"], [8, 10, "task"], [18, 20, "task"], [22, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 10, 0, 5, "usage", "", true, false], [18, 20, 8, 10, "named", "", false, false], [22, 22, 18, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "automatic", "encoder", "has", "been", "successfully", "applied", "to", "machine", "translation", "of", "human", "languages", ",", "commonly", "referred", "to", "as", "neural", "machine", "translation", "(", "NMT", ")", "."], "sentence-detokenized": "The automatic encoder has been successfully applied to machine translation of human languages, commonly referred to as neural machine translation (NMT).", "token2charspan": [[0, 3], [4, 13], [14, 21], [22, 25], [26, 30], [31, 43], [44, 51], [52, 54], [55, 62], [63, 74], [75, 77], [78, 83], [84, 93], [93, 94], [95, 103], [104, 112], [113, 115], [116, 118], [119, 125], [126, 133], [134, 145], [146, 147], [147, 150], [150, 151], [151, 152]]}
{"doc_key": "ai-dev-306", "ner": [[9, 11, "metrics"], [13, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Popular", "examples", "of", "likelihood", "-", "based", "fitness", "functions", "include", "maximum", "likelihood", "estimation", "and", "loss", "-", "on", "-", "odds", "."], "sentence-detokenized": "Popular examples of likelihood-based fitness functions include maximum likelihood estimation and loss-on-odds.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 30], [30, 31], [31, 36], [37, 44], [45, 54], [55, 62], [63, 70], [71, 81], [82, 92], [93, 96], [97, 101], [101, 102], [102, 104], [104, 105], [105, 109], [109, 110]]}
{"doc_key": "ai-dev-307", "ner": [[0, 1, "field"], [11, 13, "task"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 13, 0, 1, "part-of", "", false, false], [15, 16, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Data", "mining", "is", "a", "related", "field", "of", "study", "that", "focuses", "on", "exploratory", "data", "analysis", "with", "unsupervised", "learning", "."], "sentence-detokenized": "Data mining is a related field of study that focuses on exploratory data analysis with unsupervised learning.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 16], [17, 24], [25, 30], [31, 33], [34, 39], [40, 44], [45, 52], [53, 55], [56, 67], [68, 72], [73, 81], [82, 86], [87, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-dev-308", "ner": [[0, 1, "algorithm"], [13, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 13, 15, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "filtering", "involves", "techniques", "for", "matching", "people", "with", "similar", "interests", "and", "building", "a", "recommendation", "system", "on", "that", "basis", "."], "sentence-detokenized": "Collaborative filtering involves techniques for matching people with similar interests and building a recommendation system on that basis.", "token2charspan": [[0, 13], [14, 23], [24, 32], [33, 43], [44, 47], [48, 56], [57, 63], [64, 68], [69, 76], [77, 86], [87, 90], [91, 99], [100, 101], [102, 116], [117, 123], [124, 126], [127, 131], [132, 137], [137, 138]]}
{"doc_key": "ai-dev-309", "ner": [[1, 7, "algorithm"], [11, 11, "programlang"], [14, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 17, 1, 7, "type-of", "", false, false], [14, 17, 11, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Many", "WordNet", "-", "based", "word", "similarity", "algorithms", "are", "implemented", "in", "a", "Perl", "package", "called", "WordNet", ":", ":", "Similarity", "."], "sentence-detokenized": "Many WordNet-based word similarity algorithms are implemented in a Perl package called WordNet:: Similarity.", "token2charspan": [[0, 4], [5, 12], [12, 13], [13, 18], [19, 23], [24, 34], [35, 45], [46, 49], [50, 61], [62, 64], [65, 66], [67, 71], [72, 79], [80, 86], [87, 94], [94, 95], [95, 96], [97, 107], [107, 108]]}
{"doc_key": "ai-dev-310", "ner": [[6, 6, "conference"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 21, "researcher"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[10, 11, 6, 6, "temporal", "", false, false], [13, 14, 6, 6, "temporal", "", false, false], [16, 21, 6, 6, "temporal", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["A", "second", "paper", "presented", "at", "the", "CVPR", "2000", "conference", "by", "Erik", "Miller", ",", "Nicholas", "Matsakis", "and", "Paul", "Viola", "will", "also", "be", "discussed", "."], "sentence-detokenized": "A second paper presented at the CVPR 2000 conference by Erik Miller, Nicholas Matsakis and Paul Viola will also be discussed.", "token2charspan": [[0, 1], [2, 8], [9, 14], [15, 24], [25, 27], [28, 31], [32, 36], [37, 41], [42, 52], [53, 55], [56, 60], [61, 67], [67, 68], [69, 77], [78, 86], [87, 90], [91, 95], [96, 101], [102, 106], [107, 111], [112, 114], [115, 124], [124, 125]]}
{"doc_key": "ai-dev-311", "ner": [[0, 1, "algorithm"], [8, 9, "misc"], [16, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 16, 17, "compare", "", false, false], [16, 17, 8, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["QC", "has", "not", "been", "evaluated", "against", "traditional", "modern", "clustering", "algorithms", ",", "with", "the", "exception", "of", "the", "Jaccard", "index", "."], "sentence-detokenized": "QC has not been evaluated against traditional modern clustering algorithms, with the exception of the Jaccard index.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 15], [16, 25], [26, 33], [34, 45], [46, 52], [53, 63], [64, 74], [74, 75], [76, 80], [81, 84], [85, 94], [95, 97], [98, 101], [102, 109], [110, 115], [115, 116]]}
{"doc_key": "ai-dev-312", "ner": [[2, 7, "misc"], [8, 10, "misc"], [11, 15, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 2, 7, "physical", "", false, false], [8, 10, 11, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "the", "VEX", "Robotics", "World", "Championships", ",", "the", "Parade", "of", "Nations", "takes", "place", "at", "Freedom", "Hall", ",", "with", "hundreds", "of", "students", "from", "more", "than", "30", "countries", "taking", "part", "."], "sentence-detokenized": "During the VEX Robotics World Championships, the Parade of Nations takes place at Freedom Hall, with hundreds of students from more than 30 countries taking part.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 23], [24, 29], [30, 43], [43, 44], [45, 48], [49, 55], [56, 58], [59, 66], [67, 72], [73, 78], [79, 81], [82, 89], [90, 94], [94, 95], [96, 100], [101, 109], [110, 112], [113, 121], [122, 126], [127, 131], [132, 136], [137, 139], [140, 149], [150, 156], [157, 161], [161, 162]]}
{"doc_key": "ai-dev-313", "ner": [[4, 7, "metrics"], [9, 9, "metrics"], [12, 14, "metrics"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 4, 7, "named", "", false, false], [16, 16, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Other", "accuracy", "indicators", "include", "Single", "Word", "Error", "Rate", "(", "SWER", ")", "and", "Command", "Success", "Rate", "(", "CSR", ")", "."], "sentence-detokenized": "Other accuracy indicators include Single Word Error Rate (SWER) and Command Success Rate (CSR).", "token2charspan": [[0, 5], [6, 14], [15, 25], [26, 33], [34, 40], [41, 45], [46, 51], [52, 56], [57, 58], [58, 62], [62, 63], [64, 67], [68, 75], [76, 83], [84, 88], [89, 90], [90, 93], [93, 94], [94, 95]]}
{"doc_key": "ai-dev-314", "ner": [[7, 8, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "presented", "their", "method", "and", "results", "at", "SIGGRAPH", "2000", "."], "sentence-detokenized": "They presented their method and results at SIGGRAPH 2000.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 27], [28, 31], [32, 39], [40, 42], [43, 51], [52, 56], [56, 57]]}
{"doc_key": "ai-dev-315", "ner": [[0, 3, "conference"], [6, 6, "misc"], [8, 15, "misc"], [16, 17, "conference"], [20, 34, "researcher"], [35, 38, "researcher"], [40, 42, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 6, 6, "origin", "", false, false], [6, 6, 16, 17, "physical", "", false, false], [6, 6, 16, 17, "temporal", "", false, false], [6, 6, 20, 34, "origin", "", false, false], [6, 6, 35, 38, "origin", "", false, false], [8, 15, 6, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "KDD", "conference", "evolved", "from", "the", "KDD", "(", "Knowledge", "Discovery", "and", "Data", "Mining", ")", "workshops", "at", "AAAI", "conferences", "started", "by", "Gregory", "I", ".", "Piatetsky", "-", "Shapiro", "in", "1989", ",", "1991", "and", "1993", ",", "and", "by", "Usama", "Fayyad", "in", "1994", ".", "Machinery", "|", "ACM", "."], "sentence-detokenized": "The KDD conference evolved from the KDD (Knowledge Discovery and Data Mining) workshops at AAAI conferences started by Gregory I. Piatetsky-Shapiro in 1989, 1991 and 1993, and by Usama Fayyad in 1994. Machinery | ACM.", "token2charspan": [[0, 3], [4, 7], [8, 18], [19, 26], [27, 31], [32, 35], [36, 39], [40, 41], [41, 50], [51, 60], [61, 64], [65, 69], [70, 76], [76, 77], [78, 87], [88, 90], [91, 95], [96, 107], [108, 115], [116, 118], [119, 126], [127, 128], [128, 129], [130, 139], [139, 140], [140, 147], [148, 150], [151, 155], [155, 156], [157, 161], [162, 165], [166, 170], [170, 171], [172, 175], [176, 178], [179, 184], [185, 191], [192, 194], [195, 199], [199, 200], [201, 210], [211, 212], [213, 216], [216, 217]]}
{"doc_key": "ai-dev-316", "ner": [[6, 10, "conference"], [12, 12, "conference"], [16, 21, "organisation"], [23, 23, "organisation"], [27, 31, "conference"], [33, 33, "conference"], [37, 43, "conference"], [45, 45, "conference"], [49, 55, "conference"], [57, 57, "conference"], [61, 66, "conference"], [68, 68, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[12, 12, 6, 10, "named", "", false, false], [23, 23, 16, 21, "named", "", false, false], [33, 33, 27, 31, "named", "", false, false], [45, 45, 37, 43, "named", "", false, false], [57, 57, 49, 55, "named", "", false, false], [68, 68, 61, 66, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["He", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "Computing", "Machinery", "(", "ACM", ")", ",", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", ",", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", ",", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "(", "AAAS", ")", "and", "the", "Society", "for", "Optics", "and", "Photonics", "Engineering", "(", "SPIE", ")", "."], "sentence-detokenized": "He was elected a Fellow of the Association for Computing Machinery (ACM), the Institute of Electrical and Electronics Engineers (IEEE), the International Association for Pattern Recognition (IAPR), the Association for the Advancement of Artificial Intelligence (AAAI), the American Association for the Advancement of Science (AAAS) and the Society for Optics and Photonics Engineering (SPIE).", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 16], [17, 23], [24, 26], [27, 30], [31, 42], [43, 46], [47, 56], [57, 66], [67, 68], [68, 71], [71, 72], [72, 73], [74, 77], [78, 87], [88, 90], [91, 101], [102, 105], [106, 117], [118, 127], [128, 129], [129, 133], [133, 134], [134, 135], [136, 139], [140, 153], [154, 165], [166, 169], [170, 177], [178, 189], [190, 191], [191, 195], [195, 196], [196, 197], [198, 201], [202, 213], [214, 217], [218, 221], [222, 233], [234, 236], [237, 247], [248, 260], [261, 262], [262, 266], [266, 267], [267, 268], [269, 272], [273, 281], [282, 293], [294, 297], [298, 301], [302, 313], [314, 316], [317, 324], [325, 326], [326, 330], [330, 331], [332, 335], [336, 339], [340, 347], [348, 351], [352, 358], [359, 362], [363, 372], [373, 384], [385, 386], [386, 390], [390, 391], [391, 392]]}
{"doc_key": "ai-dev-317", "ner": [[0, 1, "field"], [3, 4, "field"], [15, 16, "field"], [30, 31, "field"], [50, 53, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 15, 16, "named", "", false, false], [3, 4, 30, 31, "named", "", false, false], [30, 31, 50, 53, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "learning", "and", "data", "mining", "often", "use", "the", "same", "methods", "and", "overlap", "considerably", ",", "but", "machine", "learning", "focuses", "on", "prediction", "based", "on", "known", "features", "extracted", "from", "training", "data", ",", "while", "data", "mining", "focuses", "on", "discovering", "(", "previously", ")", "unknown", "features", "in", "the", "data", "(", "this", "is", "the", "analysis", "step", "in", "knowledge", "discovery", "in", "datasets", ")", "."], "sentence-detokenized": "Machine learning and data mining often use the same methods and overlap considerably, but machine learning focuses on prediction based on known features extracted from training data, while data mining focuses on discovering (previously) unknown features in the data (this is the analysis step in knowledge discovery in datasets).", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 25], [26, 32], [33, 38], [39, 42], [43, 46], [47, 51], [52, 59], [60, 63], [64, 71], [72, 84], [84, 85], [86, 89], [90, 97], [98, 106], [107, 114], [115, 117], [118, 128], [129, 134], [135, 137], [138, 143], [144, 152], [153, 162], [163, 167], [168, 176], [177, 181], [181, 182], [183, 188], [189, 193], [194, 200], [201, 208], [209, 211], [212, 223], [224, 225], [225, 235], [235, 236], [237, 244], [245, 253], [254, 256], [257, 260], [261, 265], [266, 267], [267, 271], [272, 274], [275, 278], [279, 287], [288, 292], [293, 295], [296, 305], [306, 315], [316, 318], [319, 327], [327, 328], [328, 329]]}
{"doc_key": "ai-dev-318", "ner": [[0, 1, "product"], [4, 7, "programlang"], [12, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 4, 7, "general-affiliation", "", false, false], [0, 1, 4, 7, "related-to", "runs_on", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Indy", "is", "written", "in", "Java", ",", "so", "it", "works", "on", "most", "modern", "operating", "systems", "."], "sentence-detokenized": "Indy is written in Java, so it works on most modern operating systems.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 23], [23, 24], [25, 27], [28, 30], [31, 36], [37, 39], [40, 44], [45, 51], [52, 61], [62, 69], [69, 70]]}
{"doc_key": "ai-dev-319", "ner": [[0, 0, "algorithm"], [5, 7, "algorithm"], [9, 9, "algorithm"], [15, 17, "algorithm"], [19, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 7, "type-of", "", true, false], [9, 9, 5, 7, "named", "", false, false], [15, 17, 5, 7, "type-of", "", true, false], [19, 19, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["NMF", "is", "an", "example", "of", "non-negative", "quadratic", "programming", "(", "NQP", ")", ",", "just", "like", "the", "support", "vector", "machine", "(", "SVM", ")", "."], "sentence-detokenized": "NMF is an example of non-negative quadratic programming (NQP), just like the support vector machine (SVM).", "token2charspan": [[0, 3], [4, 6], [7, 9], [10, 17], [18, 20], [21, 33], [34, 43], [44, 55], [56, 57], [57, 60], [60, 61], [61, 62], [63, 67], [68, 72], [73, 76], [77, 84], [85, 91], [92, 99], [100, 101], [101, 104], [104, 105], [105, 106]]}
{"doc_key": "ai-dev-320", "ner": [[8, 9, "misc"], [12, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 12, 17, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["The", "method", "is", "based", "on", "the", "estimation", "of", "conditional", "probabilities", "using", "a", "non-parametric", "maximum", "likelihood", "method", ",", "which", "leads", "to"], "sentence-detokenized": "The method is based on the estimation of conditional probabilities using a non-parametric maximum likelihood method, which leads to", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 26], [27, 37], [38, 40], [41, 52], [53, 66], [67, 72], [73, 74], [75, 89], [90, 97], [98, 108], [109, 115], [115, 116], [117, 122], [123, 128], [129, 131]]}
{"doc_key": "ai-dev-321", "ner": [[7, 7, "algorithm"], [9, 11, "algorithm"], [13, 16, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Basic", "concepts", "involved", "in", "spectral", "estimation", "include", "autocorrelation", ",", "multidimensional", "Fourier", "transform", ",", "root", "mean", "square", "error", "and", "entropy", "."], "sentence-detokenized": "Basic concepts involved in spectral estimation include autocorrelation, multidimensional Fourier transform, root mean square error and entropy.", "token2charspan": [[0, 5], [6, 14], [15, 23], [24, 26], [27, 35], [36, 46], [47, 54], [55, 70], [70, 71], [72, 88], [89, 96], [97, 106], [106, 107], [108, 112], [113, 117], [118, 124], [125, 130], [131, 134], [135, 142], [142, 143]]}
{"doc_key": "ai-dev-322", "ner": [[3, 5, "algorithm"], [9, 9, "field"], [11, 11, "algorithm"], [13, 15, "algorithm"], [17, 18, "task"], [20, 20, "field"], [22, 22, "field"], [24, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 5, 9, 9, "part-of", "", false, false], [3, 5, 11, 11, "part-of", "", false, false], [3, 5, 13, 15, "part-of", "", false, false], [3, 5, 17, 18, "part-of", "", false, false], [3, 5, 20, 20, "part-of", "", false, false], [3, 5, 22, 22, "part-of", "", false, false], [3, 5, 24, 25, "part-of", "", false, false], [3, 5, 27, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "applications", "of", "kernel", "methods", "are", "diverse", "and", "include", "geostatistics", ",", "kriging", ",", "inverse", "distance", "weighting", ",", "3D", "reconstruction", ",", "bioinformatics", ",", "chemoinformatics", ",", "information", "extraction", "and", "handwriting", "recognition", "."], "sentence-detokenized": "The applications of kernel methods are diverse and include geostatistics, kriging, inverse distance weighting, 3D reconstruction, bioinformatics, chemoinformatics, information extraction and handwriting recognition.", "token2charspan": [[0, 3], [4, 16], [17, 19], [20, 26], [27, 34], [35, 38], [39, 46], [47, 50], [51, 58], [59, 72], [72, 73], [74, 81], [81, 82], [83, 90], [91, 99], [100, 109], [109, 110], [111, 113], [114, 128], [128, 129], [130, 144], [144, 145], [146, 162], [162, 163], [164, 175], [176, 186], [187, 190], [191, 202], [203, 214], [214, 215]]}
{"doc_key": "ai-dev-323", "ner": [[14, 18, "product"], [20, 20, "product"], [23, 24, "organisation"], [25, 29, "product"], [31, 31, "product"], [35, 36, "product"], [38, 39, "product"], [42, 43, "product"], [45, 47, "product"], [51, 52, "product"], [54, 56, "product"], [58, 63, "product"], [66, 67, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[14, 18, 35, 36, "compare", "", false, false], [14, 18, 38, 39, "compare", "", false, false], [14, 18, 42, 43, "compare", "", false, false], [14, 18, 45, 47, "compare", "", false, false], [14, 18, 51, 52, "compare", "", false, false], [14, 18, 54, 56, "compare", "", false, false], [14, 18, 58, 63, "compare", "", false, false], [14, 18, 66, 67, "compare", "", false, false], [20, 20, 14, 18, "named", "", false, false], [25, 29, 23, 24, "artifact", "", false, false], [25, 29, 35, 36, "compare", "", false, false], [25, 29, 38, 39, "compare", "", false, false], [25, 29, 42, 43, "compare", "", false, false], [25, 29, 45, 47, "compare", "", false, false], [25, 29, 51, 52, "compare", "", false, false], [25, 29, 54, 56, "compare", "", false, false], [25, 29, 58, 63, "compare", "", false, false], [25, 29, 66, 67, "compare", "", false, false], [31, 31, 25, 29, "named", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "sentence": ["Robots", "can", "be", "autonomous", "or", "semi-autonomous", "and", "range", "from", "humanoids", "such", "as", "Honda", "'s", "Advanced", "Step", "in", "Innovative", "Mobility", "(", "ASIMO", ")", "and", "TOSY", "'s", "TOSY", "Ping", "Pong", "Playing", "Robot", "(", "TOPIO", ")", ",", "to", "industrial", "robots", ",", "medical", "robots", ",", "patient", "assistance", "robots", ",", "therapy", "dog", "robots", ",", "collectively", "programmed", "swarm", "robots", ",", "drones", "such", "as", "the", "General", "Atomics", "MQ", "-", "1", "Predator", "and", "even", "microscopic", "nanorobots", "."], "sentence-detokenized": "Robots can be autonomous or semi-autonomous and range from humanoids such as Honda's Advanced Step in Innovative Mobility (ASIMO) and TOSY's TOSY Ping Pong Playing Robot (TOPIO), to industrial robots, medical robots, patient assistance robots, therapy dog robots, collectively programmed swarm robots, drones such as the General Atomics MQ-1 Predator and even microscopic nanorobots.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 24], [25, 27], [28, 43], [44, 47], [48, 53], [54, 58], [59, 68], [69, 73], [74, 76], [77, 82], [82, 84], [85, 93], [94, 98], [99, 101], [102, 112], [113, 121], [122, 123], [123, 128], [128, 129], [130, 133], [134, 138], [138, 140], [141, 145], [146, 150], [151, 155], [156, 163], [164, 169], [170, 171], [171, 176], [176, 177], [177, 178], [179, 181], [182, 192], [193, 199], [199, 200], [201, 208], [209, 215], [215, 216], [217, 224], [225, 235], [236, 242], [242, 243], [244, 251], [252, 255], [256, 262], [262, 263], [264, 276], [277, 287], [288, 293], [294, 300], [300, 301], [302, 308], [309, 313], [314, 316], [317, 320], [321, 328], [329, 336], [337, 339], [339, 340], [340, 341], [342, 350], [351, 354], [355, 359], [360, 371], [372, 382], [382, 383]]}
{"doc_key": "ai-dev-324", "ner": [[0, 0, "product"], [2, 4, "product"], [21, 31, "university"], [8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 8, 9, "artifact", "", false, false], [0, 0, 11, 12, "artifact", "", false, false], [0, 0, 14, 15, "artifact", "", false, false], [0, 0, 17, 18, "artifact", "", false, false], [2, 4, 8, 9, "artifact", "", false, false], [2, 4, 11, 12, "artifact", "", false, false], [2, 4, 14, 15, "artifact", "", false, false], [2, 4, 17, 18, "artifact", "", false, false], [8, 9, 21, 31, "physical", "", false, false], [11, 12, 21, 31, "physical", "", false, false], [14, 15, 21, 31, "physical", "", false, false], [17, 18, 21, 31, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Freddy", "and", "Freddy", "II", "were", "robots", "built", "by", "Pat", "Ambler", ",", "Robin", "Popplestone", ",", "Austin", "Tate", "and", "Donald", "Mitchie", "at", "the", "University", "of", "Edinburgh", "'s", "School", "of", "Informatics", ",", "which", "were", "able", "to", "assemble", "wooden", "blocks", "in", "a", "matter", "of", "hours", "."], "sentence-detokenized": "Freddy and Freddy II were robots built by Pat Ambler, Robin Popplestone, Austin Tate and Donald Mitchie at the University of Edinburgh's School of Informatics, which were able to assemble wooden blocks in a matter of hours.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 20], [21, 25], [26, 32], [33, 38], [39, 41], [42, 45], [46, 52], [52, 53], [54, 59], [60, 71], [71, 72], [73, 79], [80, 84], [85, 88], [89, 95], [96, 103], [104, 106], [107, 110], [111, 121], [122, 124], [125, 134], [134, 136], [137, 143], [144, 146], [147, 158], [158, 159], [160, 165], [166, 170], [171, 175], [176, 178], [179, 187], [188, 194], [195, 201], [202, 204], [205, 206], [207, 213], [214, 216], [217, 222], [222, 223]]}
{"doc_key": "ai-dev-325", "ner": [[6, 6, "location"], [8, 10, "country"], [15, 19, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 8, 10, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "spent", "his", "childhood", "years", "in", "Paris", ",", "France", ",", "where", "his", "parents", "emigrated", "from", "Lithuania", "in", "the", "early", "1920s", "."], "sentence-detokenized": "He spent his childhood years in Paris, France, where his parents emigrated from Lithuania in the early 1920s.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 22], [23, 28], [29, 31], [32, 37], [37, 38], [39, 45], [45, 46], [47, 52], [53, 56], [57, 64], [65, 74], [75, 79], [80, 89], [90, 92], [93, 96], [97, 102], [103, 108], [108, 109]]}
{"doc_key": "ai-dev-326", "ner": [[0, 1, "researcher"], [5, 8, "misc"], [14, 17, "organisation"], [10, 13, "university"], [24, 28, "university"], [31, 32, "university"], [35, 38, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 5, 8, "role", "", false, false], [0, 1, 10, 13, "physical", "", false, false], [0, 1, 24, 28, "role", "", false, false], [0, 1, 31, 32, "role", "", false, false], [0, 1, 35, 38, "role", "", false, false], [5, 8, 14, 17, "part-of", "", false, false], [14, 17, 10, 13, "part-of", "", false, false], [31, 32, 24, 28, "part-of", "", false, false], [35, 38, 24, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Dr", "Paulos", "previously", "held", "the", "Cooper-", "Siegel", "Associate", "Professorship", "at", "Carnegie", "Mellon", "University", "'s", "School", "of", "Computer", "Science", ",", "where", "he", "worked", "at", "the", "Human", "-", "Computer", "Interaction", "Institute", ",", "the", "Robotics", "Institute", "and", "the", "Center", "for", "Entertainment", "Technology", "."], "sentence-detokenized": "Dr Paulos previously held the Cooper-Siegel Associate Professorship at Carnegie Mellon University's School of Computer Science, where he worked at the Human-Computer Interaction Institute, the Robotics Institute and the Center for Entertainment Technology.", "token2charspan": [[0, 2], [3, 9], [10, 20], [21, 25], [26, 29], [30, 37], [37, 43], [44, 53], [54, 67], [68, 70], [71, 79], [80, 86], [87, 97], [97, 99], [100, 106], [107, 109], [110, 118], [119, 126], [126, 127], [128, 133], [134, 136], [137, 143], [144, 146], [147, 150], [151, 156], [156, 157], [157, 165], [166, 177], [178, 187], [187, 188], [189, 192], [193, 201], [202, 211], [212, 215], [216, 219], [220, 226], [227, 230], [231, 244], [245, 255], [255, 256]]}
{"doc_key": "ai-dev-327", "ner": [[3, 4, "researcher"], [6, 7, "university"], [10, 13, "product"], [17, 23, "product"], [25, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 6, 7, "physical", "", false, false], [3, 4, 6, 7, "role", "", false, false], [10, 13, 3, 4, "artifact", "", false, false], [10, 13, 17, 23, "type-of", "", false, false], [10, 13, 25, 29, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1969", ",", "Victor", "Scheinman", "at", "Stanford", "University", "invented", "the", "Stanford", "Arm", ",", "an", "all", "-", "electric", "six", "-", "axis", "articulated", "robot", "designed", "to", "allow", "the", "arm", "to", "be", "saved", "."], "sentence-detokenized": "In 1969, Victor Scheinman at Stanford University invented the Stanford Arm, an all-electric six-axis articulated robot designed to allow the arm to be saved.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 25], [26, 28], [29, 37], [38, 48], [49, 57], [58, 61], [62, 70], [71, 74], [74, 75], [76, 78], [79, 82], [82, 83], [83, 91], [92, 95], [95, 96], [96, 100], [101, 112], [113, 118], [119, 127], [128, 130], [131, 136], [137, 140], [141, 144], [145, 147], [148, 150], [151, 156], [156, 157]]}
{"doc_key": "ai-dev-328", "ner": [[5, 8, "product"], [15, 16, "field"], [18, 22, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 8, 15, 16, "related-to", "", false, false], [5, 8, 18, 22, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "creation", "and", "implementation", "of", "chatbots", "is", "still", "an", "emerging", "field", ",", "strongly", "linked", "to", "artificial", "intelligence", "and", "machine", "learning", ",", "and", "the", "solutions", "offered", ",", "while", "having", "obvious", "advantages", ",", "have", "some", "important", "limitations", "in", "terms", "of", "functionality", "and", "use", "cases", "."], "sentence-detokenized": "The creation and implementation of chatbots is still an emerging field, strongly linked to artificial intelligence and machine learning, and the solutions offered, while having obvious advantages, have some important limitations in terms of functionality and use cases.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 31], [32, 34], [35, 43], [44, 46], [47, 52], [53, 55], [56, 64], [65, 70], [70, 71], [72, 80], [81, 87], [88, 90], [91, 101], [102, 114], [115, 118], [119, 126], [127, 135], [135, 136], [137, 140], [141, 144], [145, 154], [155, 162], [162, 163], [164, 169], [170, 176], [177, 184], [185, 195], [195, 196], [197, 201], [202, 206], [207, 216], [217, 228], [229, 231], [232, 237], [238, 240], [241, 254], [255, 258], [259, 262], [263, 268], [268, 269]]}
{"doc_key": "ai-dev-329", "ner": [[9, 12, "university"], [13, 14, "product"], [23, 26, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 14, 9, 12, "part-of", "", true, false], [23, 26, 13, 14, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "far", "as", "freely", "available", "resources", "are", "concerned", ",", "Carnegie", "Mellon", "University", "'s", "Sphinx", "toolkit", "is", "one", "place", "where", "you", "can", "learn", "about", "speech", "recognition", "and", "start", "experimenting", "."], "sentence-detokenized": "As far as freely available resources are concerned, Carnegie Mellon University's Sphinx toolkit is one place where you can learn about speech recognition and start experimenting.", "token2charspan": [[0, 2], [3, 6], [7, 9], [10, 16], [17, 26], [27, 36], [37, 40], [41, 50], [50, 51], [52, 60], [61, 67], [68, 78], [78, 80], [81, 87], [88, 95], [96, 98], [99, 102], [103, 108], [109, 114], [115, 118], [119, 122], [123, 128], [129, 134], [135, 141], [142, 153], [154, 157], [158, 163], [164, 177], [177, 178]]}
{"doc_key": "ai-dev-330", "ner": [[2, 6, "misc"], [12, 19, "misc"], [21, 24, "misc"], [26, 27, "university"], [28, 28, "location"], [30, 34, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 6, 12, 19, "temporal", "", false, false], [21, 24, 12, 19, "named", "", false, false], [21, 24, 28, 28, "physical", "", false, false], [26, 27, 21, 24, "role", "", false, false], [28, 28, 30, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "official", "RoboCup", "was", "preceded", "by", "the", "(", "often", "unrecognised", ")", "first", "international", "football", "tournament", "for", "the", "Microrobot", "World", "Cup", "(", "MIROSOT", ")", ",", "organised", "by", "KAIST", "in", "Taejon", ",", "Korea", ",", "in", "November", "1996", "."], "sentence-detokenized": "The official RoboCup was preceded by the (often unrecognised) first international football tournament for the Microrobot World Cup (MIROSOT), organised by KAIST in Taejon, Korea, in November 1996.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 24], [25, 33], [34, 36], [37, 40], [41, 42], [42, 47], [48, 60], [60, 61], [62, 67], [68, 81], [82, 90], [91, 101], [102, 105], [106, 109], [110, 120], [121, 126], [127, 130], [131, 132], [132, 139], [139, 140], [140, 141], [142, 151], [152, 154], [155, 160], [161, 163], [164, 170], [170, 171], [172, 177], [177, 178], [179, 181], [182, 190], [191, 195], [195, 196]]}
{"doc_key": "ai-dev-331", "ner": [[5, 6, "metrics"], [23, 25, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", "to", "the", "standard", "hinge", "loss", "math", "(", "1-", "yf", "(", "x", ")", ")", "_", "+", "/", "for", "signed", "data", ",", "the", "loss", "function", "math", "(", "-", "1", "|", "f", "(", "x", ")", "|", ")", "_", "+", "/", "math", "for", "unsigned", "data", "is", "introduced", "by", "letting", "mathy", "=\\", "the", "name", "of", "the", "operator", "{", "sign", "}", "{", "f", "(", "x", ")", "}", "/", "math", "."], "sentence-detokenized": "In addition to the standard hinge loss math (1-yf (x)) _ + / for signed data, the loss function math (-1 | f (x) |) _ + / math for unsigned data is introduced by letting mathy =\\ the name of the operator {sign} {f (x)} / math.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 27], [28, 33], [34, 38], [39, 43], [44, 45], [45, 47], [47, 49], [50, 51], [51, 52], [52, 53], [53, 54], [55, 56], [57, 58], [59, 60], [61, 64], [65, 71], [72, 76], [76, 77], [78, 81], [82, 86], [87, 95], [96, 100], [101, 102], [102, 103], [103, 104], [105, 106], [107, 108], [109, 110], [110, 111], [111, 112], [113, 114], [114, 115], [116, 117], [118, 119], [120, 121], [122, 126], [127, 130], [131, 139], [140, 144], [145, 147], [148, 158], [159, 161], [162, 169], [170, 175], [176, 178], [179, 182], [183, 187], [188, 190], [191, 194], [195, 203], [204, 205], [205, 209], [209, 210], [211, 212], [212, 213], [214, 215], [215, 216], [216, 217], [217, 218], [219, 220], [221, 225], [225, 226]]}
{"doc_key": "ai-dev-332", "ner": [[0, 1, "misc"], [7, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 7, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "RLS", "is", "designed", "to", "minimise", "the", "root", "mean", "square", "error", "between", "the", "predicted", "values", "and", "the", "true", "labels", ",", "taking", "into", "account", "regularisation", "."], "sentence-detokenized": "The RLS is designed to minimise the root mean square error between the predicted values and the true labels, taking into account regularisation.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 19], [20, 22], [23, 31], [32, 35], [36, 40], [41, 45], [46, 52], [53, 58], [59, 66], [67, 70], [71, 80], [81, 87], [88, 91], [92, 95], [96, 100], [101, 107], [107, 108], [109, 115], [116, 120], [121, 128], [129, 143], [143, 144]]}
{"doc_key": "ai-dev-333", "ner": [[7, 9, "algorithm"], [12, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 9, 12, 15, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Essentially", ",", "it", "is", "a", "combination", "of", "maximum", "likelihood", "estimation", "with", "a", "regularisation", "process", "that", "favours", "simpler", "models", "over", "more", "complex", "ones", "."], "sentence-detokenized": "Essentially, it is a combination of maximum likelihood estimation with a regularisation process that favours simpler models over more complex ones.", "token2charspan": [[0, 11], [11, 12], [13, 15], [16, 18], [19, 20], [21, 32], [33, 35], [36, 43], [44, 54], [55, 65], [66, 70], [71, 72], [73, 87], [88, 95], [96, 100], [101, 108], [109, 116], [117, 123], [124, 128], [129, 133], [134, 141], [142, 146], [146, 147]]}
{"doc_key": "ai-dev-334", "ner": [[0, 4, "metrics"], [10, 10, "metrics"], [12, 12, "metrics"], [14, 15, "misc"], [20, 22, "misc"], [36, 39, "algorithm"], [40, 45, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 10, 0, 4, "named", "", false, false], [12, 12, 0, 4, "named", "", false, false], [14, 15, 20, 22, "related-to", "", false, false], [14, 15, 36, 39, "related-to", "ratio", false, false], [36, 39, 40, 45, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "rate", "of", "true", "positives", "is", "also", "known", "as", "the", "sensitivity", ",", "recall", "or", "detection", "probability", "(", "up", "to", "a", "threshold", "of", "discrimination", ")", "of", "the", "probability", "of", "detection", "on", "the", "y", "-axis", "compared", "to", "the", "cumulative", "distribution", "function", "of", "the", "probability", "of", "a", "false", "alarm", "on", "the", "x-", "axis", "."], "sentence-detokenized": "The rate of true positives is also known as the sensitivity, recall or detection probability (up to a threshold of discrimination) of the probability of detection on the y-axis compared to the cumulative distribution function of the probability of a false alarm on the x-axis.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 16], [17, 26], [27, 29], [30, 34], [35, 40], [41, 43], [44, 47], [48, 59], [59, 60], [61, 67], [68, 70], [71, 80], [81, 92], [93, 94], [94, 96], [97, 99], [100, 101], [102, 111], [112, 114], [115, 129], [129, 130], [131, 133], [134, 137], [138, 149], [150, 152], [153, 162], [163, 165], [166, 169], [170, 171], [171, 176], [177, 185], [186, 188], [189, 192], [193, 203], [204, 216], [217, 225], [226, 228], [229, 232], [233, 244], [245, 247], [248, 249], [250, 255], [256, 261], [262, 264], [265, 268], [269, 271], [271, 275], [275, 276]]}
{"doc_key": "ai-dev-335", "ner": [[1, 9, "misc"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 10, 1, 9, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "English", ",", "an", "example", "of", "a", "semantic", "network", "is", "WordNet", "."], "sentence-detokenized": "In English, an example of a semantic network is WordNet.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 14], [15, 22], [23, 25], [26, 27], [28, 36], [37, 44], [45, 47], [48, 55], [55, 56]]}
{"doc_key": "ai-dev-336", "ner": [[5, 8, "product"], [11, 14, "product"], [25, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[25, 28, 5, 8, "usage", "", false, false], [25, 28, 11, 14, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Long", "-", "term", "use", "of", "speech", "recognition", "software", "in", "conjunction", "with", "word", "processors", "has", "shown", "benefits", "for", "enhancing", "short", "-", "term", "memory", "in", "patients", "with", "cerebral", "AVMs", "treated", "by", "resection", "."], "sentence-detokenized": "Long-term use of speech recognition software in conjunction with word processors has shown benefits for enhancing short-term memory in patients with cerebral AVMs treated by resection.", "token2charspan": [[0, 4], [4, 5], [5, 9], [10, 13], [14, 16], [17, 23], [24, 35], [36, 44], [45, 47], [48, 59], [60, 64], [65, 69], [70, 80], [81, 84], [85, 90], [91, 99], [100, 103], [104, 113], [114, 119], [119, 120], [120, 124], [125, 131], [132, 134], [135, 143], [144, 148], [149, 157], [158, 162], [163, 170], [171, 173], [174, 183], [183, 184]]}
{"doc_key": "ai-dev-337", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Its", "main", "editors", "were", "Ron", "Sun", ",", "Vasant", "Honavar", "and", "Gregg", "Oden", "(", "from", "1999", "to", "2014", ")", "."], "sentence-detokenized": "Its main editors were Ron Sun, Vasant Honavar and Gregg Oden (from 1999 to 2014).", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 21], [22, 25], [26, 29], [29, 30], [31, 37], [38, 45], [46, 49], [50, 55], [56, 60], [61, 62], [62, 66], [67, 71], [72, 74], [75, 79], [79, 80], [80, 81]]}
{"doc_key": "ai-dev-338", "ner": [[7, 11, "product"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 11, 12, 13, "opposite", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Their", "\"", "parallel", "\"", "difference", "from", "a", "serial", "manipulator", "is", "that", "the", "end", "-effector", "(", "or", "\"", "arm", "\"", ")", "of", "this", "link", "(", "or", "\"", "arm", "\"", ")", "is", "directly", "connected", "to", "it", "s", "base", "by", "a", "number", "(", "usually", "three", "or", "six", ")", "of", "separate", "and", "independent", "links", "operating", "simultaneously", "."], "sentence-detokenized": "Their \"parallel\" difference from a serial manipulator is that the end-effector (or \"arm\") of this link (or \"arm\") is directly connected to its base by a number (usually three or six) of separate and independent links operating simultaneously.", "token2charspan": [[0, 5], [6, 7], [7, 15], [15, 16], [17, 27], [28, 32], [33, 34], [35, 41], [42, 53], [54, 56], [57, 61], [62, 65], [66, 69], [69, 78], [79, 80], [80, 82], [83, 84], [84, 87], [87, 88], [88, 89], [90, 92], [93, 97], [98, 102], [103, 104], [104, 106], [107, 108], [108, 111], [111, 112], [112, 113], [114, 116], [117, 125], [126, 135], [136, 138], [139, 141], [141, 142], [143, 147], [148, 150], [151, 152], [153, 159], [160, 161], [161, 168], [169, 174], [175, 177], [178, 181], [181, 182], [183, 185], [186, 194], [195, 198], [199, 210], [211, 216], [217, 226], [227, 241], [241, 242]]}
{"doc_key": "ai-dev-339", "ner": [[5, 8, "researcher"], [18, 19, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "thesis", "advisor", "was", "Professor", "Cordell", "Green", ",", "and", "his", "thesis", "committee", "/", "constitution", "committee", "consisted", "of", "Professors", "Edward", "Feigenbaum", "Joshua", "Lederberg", ",", "Paul", "Cohen", ",", "Allen", "Newell", ",", "Herbert", "Simon", ",", "."], "sentence-detokenized": "His thesis advisor was Professor Cordell Green, and his thesis committee/constitution committee consisted of Professors Edward Feigenbaum Joshua Lederberg, Paul Cohen, Allen Newell, Herbert Simon,.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 22], [23, 32], [33, 40], [41, 46], [46, 47], [48, 51], [52, 55], [56, 62], [63, 72], [72, 73], [73, 85], [86, 95], [96, 105], [106, 108], [109, 119], [120, 126], [127, 137], [138, 144], [145, 154], [154, 155], [156, 160], [161, 166], [166, 167], [168, 173], [174, 180], [180, 181], [182, 189], [190, 195], [195, 196], [196, 197]]}
{"doc_key": "ai-dev-340", "ner": [[3, 6, "metrics"], [8, 11, "metrics"], [13, 15, "metrics"], [17, 19, "metrics"], [21, 24, "metrics"], [26, 28, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "functions", "include", "root", "mean", "square", "error", ",", "root", "mean", "square", "error", ",", "mean", "absolute", "error", ",", "relative", "square", "error", ",", "root", "relative", "square", "error", ",", "relative", "absolute", "error", "and", "others", "."], "sentence-detokenized": "Such functions include root mean square error, root mean square error, mean absolute error, relative square error, root relative square error, relative absolute error and others.", "token2charspan": [[0, 4], [5, 14], [15, 22], [23, 27], [28, 32], [33, 39], [40, 45], [45, 46], [47, 51], [52, 56], [57, 63], [64, 69], [69, 70], [71, 75], [76, 84], [85, 90], [90, 91], [92, 100], [101, 107], [108, 113], [113, 114], [115, 119], [120, 128], [129, 135], [136, 141], [141, 142], [143, 151], [152, 160], [161, 166], [167, 170], [171, 177], [177, 178]]}
{"doc_key": "ai-dev-341", "ner": [[4, 4, "programlang"], [6, 6, "programlang"], [8, 10, "programlang"]], "ner_mapping_to_source": [0, 1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Bindings", "are", "available", "in", "Python", ",", "Java", "and", "MATLAB", "/", "OCTAVE", "."], "sentence-detokenized": "Bindings are available in Python, Java and MATLAB/OCTAVE.", "token2charspan": [[0, 8], [9, 12], [13, 22], [23, 25], [26, 32], [32, 33], [34, 38], [39, 42], [43, 49], [49, 50], [50, 56], [56, 57]]}
{"doc_key": "ai-dev-342", "ner": [[0, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "MATLAB", "implementation", "is", "available", "on", "the", "website", "."], "sentence-detokenized": "The MATLAB implementation is available on the website.", "token2charspan": [[0, 3], [4, 10], [11, 25], [26, 28], [29, 38], [39, 41], [42, 45], [46, 53], [53, 54]]}
{"doc_key": "ai-dev-343", "ner": [[0, 5, "researcher"], [8, 9, "field"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 5, "origin", "", false, false], [8, 9, 13, 14, "origin", "", false, false], [8, 9, 16, 17, "origin", "", false, false], [8, 9, 19, 20, "origin", "", false, false], [8, 9, 22, 25, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["John", "McCarthy", "is", "one", "of", "the", "founders", "of", "artificial", "intelligence", ",", "along", "with", "Alan", "Turing", ",", "Marvin", "Minsky", ",", "Allen", "Newell", "and", "Herbert", "A", ".", "Simon", "."], "sentence-detokenized": "John McCarthy is one of the founders of artificial intelligence, along with Alan Turing, Marvin Minsky, Allen Newell and Herbert A. Simon.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 23], [24, 27], [28, 36], [37, 39], [40, 50], [51, 63], [63, 64], [65, 70], [71, 75], [76, 80], [81, 87], [87, 88], [89, 95], [96, 102], [102, 103], [104, 109], [110, 116], [117, 120], [121, 128], [129, 130], [130, 131], [132, 137], [137, 138]]}
{"doc_key": "ai-dev-344", "ner": [[10, 12, "product"], [18, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "parallel", "manipulator", "is", "a", "mechanical", "system", "that", "uses", "multiple", "serial", "manipulators", "to", "support", "a", "single", "platform", "or", "end-effector", "."], "sentence-detokenized": "A parallel manipulator is a mechanical system that uses multiple serial manipulators to support a single platform or end-effector.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 27], [28, 38], [39, 45], [46, 50], [51, 55], [56, 64], [65, 71], [72, 84], [85, 87], [88, 95], [96, 97], [98, 104], [105, 113], [114, 116], [117, 129], [129, 130]]}
{"doc_key": "ai-dev-345", "ner": [[0, 0, "product"], [3, 4, "task"], [7, 7, "product"], [9, 20, "product"], [27, 27, "misc"], [30, 30, "misc"], [33, 34, "misc"], [37, 42, "task"], [45, 47, "product"], [50, 51, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 7, 0, 0, "part-of", "", false, false], [7, 7, 3, 4, "type-of", "", false, false], [9, 20, 7, 7, "named", "", false, false], [27, 27, 7, 7, "part-of", "", false, false], [30, 30, 7, 7, "part-of", "", false, false], [33, 34, 7, 7, "part-of", "", false, false], [37, 42, 7, 7, "part-of", "", false, false], [45, 47, 7, 7, "part-of", "", false, false], [50, 51, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["GATE", "includes", "an", "information", "extraction", "system", "called", "ANNIE", "(", "A", "Nearly", "-", "New", "Information", "Extraction", "System", ")", ",", "which", "is", "a", "set", "of", "modules", "consisting", "of", "a", "tokenizer", ",", "a", "gazetteer", ",", "a", "sentence", "splitter", ",", "a", "part", "-", "of", "-", "speech", "tagger", ",", "a", "named", "entity", "recognizer", "and", "a", "coreference", "tagger", "."], "sentence-detokenized": "GATE includes an information extraction system called ANNIE (A Nearly-New Information Extraction System), which is a set of modules consisting of a tokenizer, a gazetteer, a sentence splitter, a part-of-speech tagger, a named entity recognizer and a coreference tagger.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 28], [29, 39], [40, 46], [47, 53], [54, 59], [60, 61], [61, 62], [63, 69], [69, 70], [70, 73], [74, 85], [86, 96], [97, 103], [103, 104], [104, 105], [106, 111], [112, 114], [115, 116], [117, 120], [121, 123], [124, 131], [132, 142], [143, 145], [146, 147], [148, 157], [157, 158], [159, 160], [161, 170], [170, 171], [172, 173], [174, 182], [183, 191], [191, 192], [193, 194], [195, 199], [199, 200], [200, 202], [202, 203], [203, 209], [210, 216], [216, 217], [218, 219], [220, 225], [226, 232], [233, 243], [244, 247], [248, 249], [250, 261], [262, 268], [268, 269]]}
{"doc_key": "ai-dev-346", "ner": [[3, 5, "university"], [10, 17, "country"], [21, 24, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "graduated", "from", "Moscow", "State", "University", "and", "went", "to", "the", "United", "States", "in", "November", "1978", ",", "following", "a", "personal", "intervention", "by", "Senator", "Edward", "M.", "Kennedy", "."], "sentence-detokenized": "He graduated from Moscow State University and went to the United States in November 1978, following a personal intervention by Senator Edward M. Kennedy.", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 24], [25, 30], [31, 41], [42, 45], [46, 50], [51, 53], [54, 57], [58, 64], [65, 71], [72, 74], [75, 83], [84, 88], [88, 89], [90, 99], [100, 101], [102, 110], [111, 123], [124, 126], [127, 134], [135, 141], [142, 144], [145, 152], [152, 153]]}
{"doc_key": "ai-dev-347", "ner": [[4, 6, "organisation"], [10, 15, "misc"], [19, 20, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 10, 15, "win-defeat", "", false, false], [10, 15, 19, 20, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2017", ",", "the", "DeepMind", "AlphaGo", "team", "was", "awarded", "the", "first", "IJCAI", "Marvin", "Minsky", "Medal", "for", "outstanding", "achievements", "in", "artificial", "intelligence", "."], "sentence-detokenized": "In 2017, the DeepMind AlphaGo team was awarded the first IJCAI Marvin Minsky Medal for outstanding achievements in artificial intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 21], [22, 29], [30, 34], [35, 38], [39, 46], [47, 50], [51, 56], [57, 62], [63, 69], [70, 76], [77, 82], [83, 86], [87, 98], [99, 111], [112, 114], [115, 125], [126, 138], [138, 139]]}
{"doc_key": "ai-dev-348", "ner": [[1, 4, "misc"], [5, 7, "misc"], [11, 11, "misc"], [19, 20, "misc"], [24, 25, "misc"], [31, 31, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 4, 5, 7, "related-to", "is_recorded_by", false, false], [5, 7, 11, 11, "cause-effect", "", false, false], [5, 7, 11, 11, "physical", "", false, false], [5, 7, 19, 20, "physical", "", false, false], [5, 7, 31, 31, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "anomalous", "propagation", "pathways", "include", "troposatter", "caused", "by", "irregularities", "in", "the", "troposphere", ",", "scattering", "from", "meteors", ",", "refraction", "in", "ionised", "regions", "and", "layers", "of", "the", "ionosphere", ",", "and", "reflection", "from", "the", "ionosphere", "."], "sentence-detokenized": "Other anomalous propagation pathways include troposatter caused by irregularities in the troposphere, scattering from meteors, refraction in ionised regions and layers of the ionosphere, and reflection from the ionosphere.", "token2charspan": [[0, 5], [6, 15], [16, 27], [28, 36], [37, 44], [45, 56], [57, 63], [64, 66], [67, 81], [82, 84], [85, 88], [89, 100], [100, 101], [102, 112], [113, 117], [118, 125], [125, 126], [127, 137], [138, 140], [141, 148], [149, 156], [157, 160], [161, 167], [168, 170], [171, 174], [175, 185], [185, 186], [187, 190], [191, 201], [202, 206], [207, 210], [211, 221], [221, 222]]}
{"doc_key": "ai-dev-349", "ner": [[0, 2, "field"], [3, 3, "field"], [7, 7, "field"], [9, 10, "field"], [12, 13, "field"], [15, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 7, 7, "part-of", "", false, false], [0, 2, 9, 10, "part-of", "", false, false], [0, 2, 12, 13, "part-of", "", false, false], [0, 2, 15, 20, "part-of", "", false, false], [3, 3, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Natural", "language", "processing", "is", "a", "sub-field", "of", "linguistics", ",", "computer", "science", ",", "information", "engineering", "and", "artificial", "intelligence", "that", "deals", "with", "the", "interactions", "between", "computers", "and", "human", "(", "natural", ")", "languages", ",", "in", "particular", "how", "to", "program", "computers", "to", "process", "and", "analyse", "large", "amounts", "of", "natural", "language", "data", "."], "sentence-detokenized": "Natural language processing is a sub-field of linguistics, computer science, information engineering and artificial intelligence that deals with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyse large amounts of natural language data.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 30], [31, 32], [33, 42], [43, 45], [46, 57], [57, 58], [59, 67], [68, 75], [75, 76], [77, 88], [89, 100], [101, 104], [105, 115], [116, 128], [129, 133], [134, 139], [140, 144], [145, 148], [149, 161], [162, 169], [170, 179], [180, 183], [184, 189], [190, 191], [191, 198], [198, 199], [200, 209], [209, 210], [211, 213], [214, 224], [225, 228], [229, 231], [232, 239], [240, 249], [250, 252], [253, 260], [261, 264], [265, 272], [273, 278], [279, 286], [287, 289], [290, 297], [298, 306], [307, 311], [311, 312]]}
{"doc_key": "ai-dev-350", "ner": [[8, 9, "organisation"], [11, 12, "organisation"], [14, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "active", "youth", "-", "led", "climate", "groups", "include", "Extinction", "Rebellion", ",", "Sunrise", "Movement", ",", "SustainUS", "and", "others", "working", "at", "transnational", "and", "local", "levels", "."], "sentence-detokenized": "Other active youth-led climate groups include Extinction Rebellion, Sunrise Movement, SustainUS and others working at transnational and local levels.", "token2charspan": [[0, 5], [6, 12], [13, 18], [18, 19], [19, 22], [23, 30], [31, 37], [38, 45], [46, 56], [57, 66], [66, 67], [68, 75], [76, 84], [84, 85], [86, 95], [96, 99], [100, 106], [107, 114], [115, 117], [118, 131], [132, 135], [136, 141], [142, 148], [148, 149]]}
