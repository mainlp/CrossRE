{"doc_key": "ai-train-1", "ner": [[3, 7, "product"], [14, 15, "field"], [17, 18, "task"], [20, 21, "task"], [25, 27, "task"], [32, 33, "field"], [31, 35, "researcher"], [37, 39, "researcher"], [41, 44, "researcher"], [46, 47, "researcher"], [49, 51, "researcher"], [53, 54, "researcher"], [56, 57, "researcher"], [59, 60, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[3, 7, 14, 15, "part-of", "", false, false], [3, 7, 14, 15, "usage", "", false, false], [3, 7, 17, 18, "part-of", "", false, false], [3, 7, 17, 18, "usage", "", false, false], [3, 7, 20, 21, "part-of", "", false, false], [3, 7, 20, 21, "usage", "", false, false], [3, 7, 32, 33, "part-of", "", false, false], [3, 7, 32, 33, "usage", "", false, false], [25, 27, 20, 21, "part-of", "", false, false], [25, 27, 20, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Popular", "approaches", "to", "opinion", "-", "based", "recommender", "systems", "use", "a", "variety", "of", "techniques", "including", "text", "mining", ",", "information", "retrieval", ",", "sentiment", "analysis", "(", "see", "also", "Multimodal", "Sentiment", "Analysis", ")", ",", "and", "X.Y.", "deep", "learning", ".", "Feng", ",", "H", ".", "Zhang", ",", "Y", ".", "J.", "Ren", ",", "P.H.", "Shang", ",", "Y", ".", "Zhu", ",", "Y.C.", "Liang", ",", "R.C.", "Guan", ",", "D.", "Xu", ",", "(", "2019", ")", ",", ",", "21", "(", "5", ")", ":", "e12957", "."], "sentence-detokenized": "Popular approaches to opinion-based recommender systems use a variety of techniques including text mining, information retrieval, sentiment analysis (see also Multimodal Sentiment Analysis), and X.Y. deep learning. Feng, H. Zhang, Y. J. Ren, P.H. Shang, Y. Zhu, Y.C. Liang, R.C. Guan, D. Xu, (2019),, 21(5): e12957.", "token2charspan": [[0, 7], [8, 18], [19, 21], [22, 29], [29, 30], [30, 35], [36, 47], [48, 55], [56, 59], [60, 61], [62, 69], [70, 72], [73, 83], [84, 93], [94, 98], [99, 105], [105, 106], [107, 118], [119, 128], [128, 129], [130, 139], [140, 148], [149, 150], [150, 153], [154, 158], [159, 169], [170, 179], [180, 188], [188, 189], [189, 190], [191, 194], [195, 199], [200, 204], [205, 213], [213, 214], [215, 219], [219, 220], [221, 222], [222, 223], [224, 229], [229, 230], [231, 232], [232, 233], [234, 236], [237, 240], [240, 241], [242, 246], [247, 252], [252, 253], [254, 255], [255, 256], [257, 260], [260, 261], [262, 266], [267, 272], [272, 273], [274, 278], [279, 283], [283, 284], [285, 287], [288, 290], [290, 291], [292, 293], [293, 297], [297, 298], [298, 299], [299, 300], [301, 303], [303, 304], [304, 305], [305, 306], [306, 307], [308, 314], [314, 315]]}
{"doc_key": "ai-train-2", "ner": [[8, 8, "university"], [12, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 13, 8, 8, "physical", "", false, false], [12, 13, 8, 8, "role", "", false, false], [15, 16, 8, 8, "physical", "", false, false], [15, 16, 8, 8, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Advocates", "of", "procedural", "representations", "have", "focused", "particularly", "on", "MIT", ",", "led", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "."], "sentence-detokenized": "Advocates of procedural representations have focused particularly on MIT, led by Marvin Minsky and Seymour Papert.", "token2charspan": [[0, 9], [10, 12], [13, 23], [24, 39], [40, 44], [45, 52], [53, 65], [66, 68], [69, 72], [72, 73], [74, 77], [78, 80], [81, 87], [88, 94], [95, 98], [99, 106], [107, 113], [113, 114]]}
{"doc_key": "ai-train-3", "ner": [[10, 10, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "standard", "interface", "and", "the", "calculator", "interface", "are", "written", "in", "Java", "."], "sentence-detokenized": "The standard interface and the calculator interface are written in Java.", "token2charspan": [[0, 3], [4, 12], [13, 22], [23, 26], [27, 30], [31, 41], [42, 51], [52, 55], [56, 63], [64, 66], [67, 71], [71, 72]]}
{"doc_key": "ai-train-4", "ner": [[0, 0, "product"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 20, 20, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["Octave", "helps", "in", "numerically", "solving", "linear", "and", "non-linear", "problems", "and", "performing", "other", "numerical", "experiments", "using", "a", "program", "that", "is", "mostly", "MATLAB", "compatible", "."], "sentence-detokenized": "Octave helps in numerically solving linear and non-linear problems and performing other numerical experiments using a program that is mostly MATLAB compatible.", "token2charspan": [[0, 6], [7, 12], [13, 15], [16, 27], [28, 35], [36, 42], [43, 46], [47, 57], [58, 66], [67, 70], [71, 81], [82, 87], [88, 97], [98, 109], [110, 115], [116, 117], [118, 125], [126, 130], [131, 133], [134, 140], [141, 147], [148, 158], [158, 159]]}
{"doc_key": "ai-train-5", "ner": [[2, 8, "algorithm"], [11, 12, "misc"], [13, 15, "researcher"], [21, 23, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 8, 13, 15, "origin", "", false, false], [11, 12, 13, 15, "origin", "", false, false], [13, 15, 21, 23, "physical", "", false, false], [13, 15, 21, 23, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Variants", "of", "the", "back", "-", "propagation", "algorithm", ",", "as", "well", "as", "unsupervised", "methods", "by", "Geoff", "Hinton", "and", "his", "colleagues", "at", "the", "University", "of", "Toronto", ",", "can", "be", "used", "to", "train", "deep", ",", "highly", "nonlinear", "neural", "architectures", ",", "{", "{", "cite", "journal"], "sentence-detokenized": "Variants of the back-propagation algorithm, as well as unsupervised methods by Geoff Hinton and his colleagues at the University of Toronto, can be used to train deep, highly nonlinear neural architectures, {{cite journal", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 20], [20, 21], [21, 32], [33, 42], [42, 43], [44, 46], [47, 51], [52, 54], [55, 67], [68, 75], [76, 78], [79, 84], [85, 91], [92, 95], [96, 99], [100, 110], [111, 113], [114, 117], [118, 128], [129, 131], [132, 139], [139, 140], [141, 144], [145, 147], [148, 152], [153, 155], [156, 161], [162, 166], [166, 167], [168, 174], [175, 184], [185, 191], [192, 205], [205, 206], [207, 208], [208, 209], [209, 213], [214, 221]]}
{"doc_key": "ai-train-6", "ner": [[3, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", "equivalently", "using", "DCG", "notation", ":"], "sentence-detokenized": "or equivalently using DCG notation:", "token2charspan": [[0, 2], [3, 15], [16, 21], [22, 25], [26, 34], [34, 35]]}
{"doc_key": "ai-train-7", "ner": [[0, 3, "algorithm"], [7, 9, "algorithm"], [14, 16, "algorithm"], [19, 23, "algorithm"], [25, 27, "algorithm"], [29, 32, "algorithm"], [43, 45, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 7, 9, "type-of", "", false, false], [0, 3, 14, 16, "usage", "part-of?", true, false], [14, 16, 19, 23, "compare", "", false, false], [25, 27, 19, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Self", "-", "organizing", "maps", "differ", "from", "other", "artificial", "neural", "networks", "in", "that", "they", "use", "competitive", "learning", "as", "opposed", "to", "error", "-correcting", "learning", ",", "such", "as", "back", "-", "propagation", "with", "gradient", "descent", ",", "and", "in", "that", "they", "use", "a", "neighborhood", "function", "to", "preserve", "the", "topological", "properties", "of", "the", "input", "space", "."], "sentence-detokenized": "Self-organizing maps differ from other artificial neural networks in that they use competitive learning as opposed to error-correcting learning, such as back-propagation with gradient descent, and in that they use a neighborhood function to preserve the topological properties of the input space.", "token2charspan": [[0, 4], [4, 5], [5, 15], [16, 20], [21, 27], [28, 32], [33, 38], [39, 49], [50, 56], [57, 65], [66, 68], [69, 73], [74, 78], [79, 82], [83, 94], [95, 103], [104, 106], [107, 114], [115, 117], [118, 123], [123, 134], [135, 143], [143, 144], [145, 149], [150, 152], [153, 157], [157, 158], [158, 169], [170, 174], [175, 183], [184, 191], [191, 192], [193, 196], [197, 199], [200, 204], [205, 209], [210, 213], [214, 215], [216, 228], [229, 237], [238, 240], [241, 249], [250, 253], [254, 265], [266, 276], [277, 279], [280, 283], [284, 289], [290, 295], [295, 296]]}
{"doc_key": "ai-train-8", "ner": [[10, 12, "organisation"], [24, 30, "misc"], [35, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Since", "the", "early", "1990s", ",", "several", "authorities", ",", "including", "the", "Audio", "Engineering", "Society", ",", "have", "recommended", "that", "dynamic", "range", "measurements", "be", "made", "with", "the", "audio", "signal", "present", ",", "which", "is", "then", "filtered", "out", "in", "the", "noise", "floor", "measurements", "used", "to", "determine", "dynamic", "range", ".", "This", "avoids", "questionable", "measurements", "based", "on", "the", "use", "of", "blank", "media", "or", "sound", "attenuation", "circuits", "."], "sentence-detokenized": "Since the early 1990s, several authorities, including the Audio Engineering Society, have recommended that dynamic range measurements be made with the audio signal present, which is then filtered out in the noise floor measurements used to determine dynamic range. This avoids questionable measurements based on the use of blank media or sound attenuation circuits.", "token2charspan": [[0, 5], [6, 9], [10, 15], [16, 21], [21, 22], [23, 30], [31, 42], [42, 43], [44, 53], [54, 57], [58, 63], [64, 75], [76, 83], [83, 84], [85, 89], [90, 101], [102, 106], [107, 114], [115, 120], [121, 133], [134, 136], [137, 141], [142, 146], [147, 150], [151, 156], [157, 163], [164, 171], [171, 172], [173, 178], [179, 181], [182, 186], [187, 195], [196, 199], [200, 202], [203, 206], [207, 212], [213, 218], [219, 231], [232, 236], [237, 239], [240, 249], [250, 257], [258, 263], [263, 264], [265, 269], [270, 276], [277, 289], [290, 302], [303, 308], [309, 311], [312, 315], [316, 319], [320, 322], [323, 328], [329, 334], [335, 337], [338, 343], [344, 355], [356, 364], [364, 365]]}
{"doc_key": "ai-train-9", "ner": [[4, 5, "misc"], [16, 17, "task"], [19, 20, "task"], [22, 23, "task"], [25, 26, "task"], [28, 28, "task"], [29, 33, "task"], [36, 38, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 16, 17, "part-of", "concept_used_in", true, false], [4, 5, 19, 20, "part-of", "concept_used_in", false, false], [4, 5, 22, 23, "part-of", "concept_used_in", false, false], [4, 5, 25, 26, "part-of", "concept_used_in", false, false], [4, 5, 28, 28, "part-of", "concept_used_in", false, false], [4, 5, 29, 33, "part-of", "concept_used_in", false, false], [4, 5, 36, 38, "part-of", "concept_used_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Techniques", "used", "in", "creating", "custom", "faces", "and", "using", "them", "for", "recognition", "are", "also", "used", "outside", "of", "face", "recognition", ":", "handwriting", "recognition", ",", "lip", "reading", ",", "voice", "recognition", ",", "sign", "language", "/", "hand", "gesture", "interpretation", ",", "and", "medical", "image", "analysis", "."], "sentence-detokenized": "Techniques used in creating custom faces and using them for recognition are also used outside of face recognition: handwriting recognition, lip reading, voice recognition, sign language/hand gesture interpretation, and medical image analysis.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 27], [28, 34], [35, 40], [41, 44], [45, 50], [51, 55], [56, 59], [60, 71], [72, 75], [76, 80], [81, 85], [86, 93], [94, 96], [97, 101], [102, 113], [113, 114], [115, 126], [127, 138], [138, 139], [140, 143], [144, 151], [151, 152], [153, 158], [159, 170], [170, 171], [172, 176], [177, 185], [185, 186], [186, 190], [191, 198], [199, 213], [213, 214], [215, 218], [219, 226], [227, 232], [233, 241], [241, 242]]}
{"doc_key": "ai-train-10", "ner": [[0, 3, "organisation"], [6, 10, "organisation"], [12, 12, "organisation"], [16, 19, "organisation"], [22, 27, "organisation"], [30, 35, "organisation"], [36, 39, "organisation"], [41, 41, "organisation"], [46, 51, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[6, 10, 0, 3, "part-of", "", false, false], [12, 12, 6, 10, "named", "", false, false], [16, 19, 0, 3, "part-of", "", false, false], [22, 27, 0, 3, "part-of", "", false, false], [30, 35, 0, 3, "part-of", "", false, false], [36, 39, 0, 3, "part-of", "", false, false], [41, 41, 36, 39, "named", "", false, false], [46, 51, 0, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "National", "Science", "Foundation", "represented", "the", "National", "Aeronautics", "and", "Space", "Administration", "(", "NASA", ")", ",", "the", "U.S.", "Department", "of", "Energy", ",", "the", "U.S.", "Department", "of", "Commerce", "'s", "NIST", ",", "the", "U.S.", "Department", "of", "Defense", "'s", "Defense", "Advanced", "Research", "Projects", "Agency", "(", "DARPA", ")", ",", "and", "the", "Office", "of", "Naval", "Research", ",", "which", "coordinated", "studies", "to", "inform", "strategic", "planners", "in", "their", "deliberations", "."], "sentence-detokenized": "The National Science Foundation represented the National Aeronautics and Space Administration (NASA), the U.S. Department of Energy, the U.S. Department of Commerce's NIST, the U.S. Department of Defense's Defense Advanced Research Projects Agency (DARPA), and the Office of Naval Research, which coordinated studies to inform strategic planners in their deliberations.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 31], [32, 43], [44, 47], [48, 56], [57, 68], [69, 72], [73, 78], [79, 93], [94, 95], [95, 99], [99, 100], [100, 101], [102, 105], [106, 110], [111, 121], [122, 124], [125, 131], [131, 132], [133, 136], [137, 141], [142, 152], [153, 155], [156, 164], [164, 166], [167, 171], [171, 172], [173, 176], [177, 181], [182, 192], [193, 195], [196, 203], [203, 205], [206, 213], [214, 222], [223, 231], [232, 240], [241, 247], [248, 249], [249, 254], [254, 255], [255, 256], [257, 260], [261, 264], [265, 271], [272, 274], [275, 280], [281, 289], [289, 290], [291, 296], [297, 308], [309, 316], [317, 319], [320, 326], [327, 336], [337, 345], [346, 348], [349, 354], [355, 368], [368, 369]]}
{"doc_key": "ai-train-11", "ner": [[8, 12, "metrics"], [13, 16, "algorithm"], [0, 1, "researcher"], [19, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 12, 13, 16, "part-of", "", false, false], [0, 1, 19, 21, "related-to", "added_appendix_to_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Ronald", "Fisher", "proposed", "a", "fast", "method", "for", "computing", "maximum", "likelihood", "estimates", "for", "the", "probit", "model", "as", "an", "addendum", "to", "Bliss", "'s", "1935", "paper", "."], "sentence-detokenized": "Ronald Fisher proposed a fast method for computing maximum likelihood estimates for the probit model as an addendum to Bliss's 1935 paper.", "token2charspan": [[0, 6], [7, 13], [14, 22], [23, 24], [25, 29], [30, 36], [37, 40], [41, 50], [51, 58], [59, 69], [70, 79], [80, 83], [84, 87], [88, 94], [95, 100], [101, 103], [104, 106], [107, 115], [116, 118], [119, 124], [124, 126], [127, 131], [132, 137], [137, 138]]}
{"doc_key": "ai-train-12", "ner": [[10, 11, "product"], [13, 15, "product"], [17, 17, "organisation"], [19, 19, "product"], [27, 29, "organisation"], [29, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[19, 19, 13, 15, "usage", "uses_software", false, false], [19, 19, 17, 17, "artifact", "", false, false], [19, 19, 29, 29, "named", "", false, false], [29, 29, 27, 29, "artifact", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Some", "of", "these", "programs", "are", "available", "online", ",", "such", "as", "Google", "Translate", "and", "SYSTRAN", ",", "which", "powers", "AltaVista", "'s", "BabelFish", "(", "since", "May", "9", ",", "2008", ",", "Yahoo", "'s", "Babelfish", ")", "."], "sentence-detokenized": "Some of these programs are available online, such as Google Translate and SYSTRAN, which powers AltaVista's BabelFish (since May 9, 2008, Yahoo's Babelfish).", "token2charspan": [[0, 4], [5, 7], [8, 13], [14, 22], [23, 26], [27, 36], [37, 43], [43, 44], [45, 49], [50, 52], [53, 59], [60, 69], [70, 73], [74, 81], [81, 82], [83, 88], [89, 95], [96, 105], [105, 107], [108, 117], [118, 119], [119, 124], [125, 128], [129, 130], [130, 131], [132, 136], [136, 137], [138, 143], [143, 145], [146, 155], [155, 156], [156, 157]]}
{"doc_key": "ai-train-13", "ner": [[3, 3, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [20, 22, "field"], [26, 27, "misc"], [31, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 3, 20, 22, "related-to", "", true, false], [3, 3, 26, 27, "related-to", "", true, false], [3, 3, 31, 31, "related-to", "", true, false], [7, 8, 20, 22, "related-to", "", true, false], [7, 8, 26, 27, "related-to", "", true, false], [7, 8, 31, 31, "related-to", "", true, false], [10, 11, 20, 22, "related-to", "", true, false], [10, 11, 26, 27, "related-to", "", true, false], [10, 11, 31, 31, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "2002", ",", "Hutter", ",", "together", "with", "J\u00fcrgen", "Schmidhuber", "and", "Shane", "Legg", ",", "developed", "and", "published", "a", "mathematical", "theory", "of", "artificial", "general", "intelligence", "based", "on", "idealized", "intelligent", "agents", "and", "reward", "-motivated", "reinforcement", "."], "sentence-detokenized": "In 2002, Hutter, together with J\u00fcrgen Schmidhuber and Shane Legg, developed and published a mathematical theory of artificial general intelligence based on idealized intelligent agents and reward-motivated reinforcement.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [15, 16], [17, 25], [26, 30], [31, 37], [38, 49], [50, 53], [54, 59], [60, 64], [64, 65], [66, 75], [76, 79], [80, 89], [90, 91], [92, 104], [105, 111], [112, 114], [115, 125], [126, 133], [134, 146], [147, 152], [153, 155], [156, 165], [166, 177], [178, 184], [185, 188], [189, 195], [195, 205], [206, 219], [219, 220]]}
{"doc_key": "ai-train-14", "ner": [[11, 11, "metrics"], [13, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 11, 13, 19, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "most", "common", "way", "is", "to", "use", "the", "so", "-", "called", "ROUGE", "(", "Recall", "-", "Oriented", "Understudy", "for", "Gisting", "Evaluation", ")", "measure", "."], "sentence-detokenized": "The most common way is to use the so-called ROUGE (Recall-Oriented Understudy for Gisting Evaluation) measure.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 19], [20, 22], [23, 25], [26, 29], [30, 33], [34, 36], [36, 37], [37, 43], [44, 49], [50, 51], [51, 57], [57, 58], [58, 66], [67, 77], [78, 81], [82, 89], [90, 100], [100, 101], [102, 109], [109, 110]]}
{"doc_key": "ai-train-15", "ner": [[0, 0, "product"], [15, 15, "programlang"], [17, 17, "programlang"], [19, 20, "researcher"], [22, 23, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 15, 15, "related-to", "", false, false], [0, 0, 17, 17, "related-to", "", false, false], [19, 20, 22, 23, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["RapidMiner", "provides", "learning", "schemes", ",", "models", "and", "algorithms", "and", "can", "be", "extended", "with", "scripts", "in", "R", "and", "Python", ".", "David", "Norris", ",", "Bloor", "Research", ",", "November", "13", ",", "2013", "."], "sentence-detokenized": "RapidMiner provides learning schemes, models and algorithms and can be extended with scripts in R and Python. David Norris, Bloor Research, November 13, 2013.", "token2charspan": [[0, 10], [11, 19], [20, 28], [29, 36], [36, 37], [38, 44], [45, 48], [49, 59], [60, 63], [64, 67], [68, 70], [71, 79], [80, 84], [85, 92], [93, 95], [96, 97], [98, 101], [102, 108], [108, 109], [110, 115], [116, 122], [122, 123], [124, 129], [130, 138], [138, 139], [140, 148], [149, 151], [151, 152], [153, 157], [157, 158]]}
{"doc_key": "ai-train-16", "ner": [[0, 0, "product"], [10, 11, "field"], [13, 14, "task"], [19, 22, "misc"], [33, 35, "programlang"], [38, 39, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 10, 11, "related-to", "", false, false], [0, 0, 13, 14, "related-to", "", false, false], [0, 0, 38, 39, "related-to", "", true, false], [19, 22, 0, 0, "part-of", "", false, false], [38, 39, 33, 35, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["tity", "includes", "a", "set", "of", "visualization", "tools", "and", "algorithms", "for", "data", "analysis", "and", "predictive", "modeling", ",", "along", "with", "a", "graphical", "user", "interface", "for", "easy", "access", "to", "these", "functions", ".", "but", "the", "latest", "fully", "Java", "-", "based", "version", "(", "Weka", "3", ")", ",", "whose", "development", "began", "in", "1997", ",", "is", "now", "used", "in", "many", "different", "application", "areas", ",", "especially", "for", "educational", "purposes", "and", "research", "."], "sentence-detokenized": "tity includes a set of visualization tools and algorithms for data analysis and predictive modeling, along with a graphical user interface for easy access to these functions. but the latest fully Java-based version (Weka 3), whose development began in 1997, is now used in many different application areas, especially for educational purposes and research.", "token2charspan": [[0, 4], [5, 13], [14, 15], [16, 19], [20, 22], [23, 36], [37, 42], [43, 46], [47, 57], [58, 61], [62, 66], [67, 75], [76, 79], [80, 90], [91, 99], [99, 100], [101, 106], [107, 111], [112, 113], [114, 123], [124, 128], [129, 138], [139, 142], [143, 147], [148, 154], [155, 157], [158, 163], [164, 173], [173, 174], [175, 178], [179, 182], [183, 189], [190, 195], [196, 200], [200, 201], [201, 206], [207, 214], [215, 216], [216, 220], [221, 222], [222, 223], [223, 224], [225, 230], [231, 242], [243, 248], [249, 251], [252, 256], [256, 257], [258, 260], [261, 264], [265, 269], [270, 272], [273, 277], [278, 287], [288, 299], [300, 305], [305, 306], [307, 317], [318, 321], [322, 333], [334, 342], [343, 346], [347, 355], [355, 356]]}
{"doc_key": "ai-train-17", "ner": [[0, 0, "product"], [12, 20, "misc"], [23, 24, "misc"], [25, 35, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 20, 0, 0, "topic", "", false, false], [12, 20, 23, 24, "win-defeat", "", false, false], [23, 24, 25, 35, "temporal", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Eurisko", "made", "many", "interesting", "discoveries", "and", "gained", "considerable", "notoriety", "with", "his", "work", "Heuretics", ":", "The", "Theoretical", "and", "Study", "of", "Heuristic", "Rules", "winning", "the", "best", "paper", "award", "at", "the", "1982", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "conference", "."], "sentence-detokenized": "Eurisko made many interesting discoveries and gained considerable notoriety with his work Heuretics: The Theoretical and Study of Heuristic Rules winning the best paper award at the 1982 Association for the Advancement of Artificial Intelligence conference.", "token2charspan": [[0, 7], [8, 12], [13, 17], [18, 29], [30, 41], [42, 45], [46, 52], [53, 65], [66, 75], [76, 80], [81, 84], [85, 89], [90, 99], [99, 100], [101, 104], [105, 116], [117, 120], [121, 126], [127, 129], [130, 139], [140, 145], [146, 153], [154, 157], [158, 162], [163, 168], [169, 174], [175, 177], [178, 181], [182, 186], [187, 198], [199, 202], [203, 206], [207, 218], [219, 221], [222, 232], [233, 245], [246, 256], [256, 257]]}
{"doc_key": "ai-train-18", "ner": [[10, 16, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "order", "to", "account", "for", "multiple", "subjects", ",", "a", "separate", "hinge", "loss", "is", "calculated", "for", "each", "capsule", "."], "sentence-detokenized": "In order to account for multiple subjects, a separate hinge loss is calculated for each capsule.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 19], [20, 23], [24, 32], [33, 41], [41, 42], [43, 44], [45, 53], [54, 59], [60, 64], [65, 67], [68, 78], [79, 82], [83, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-train-19", "ner": [[8, 10, "product"], [12, 13, "product"], [15, 16, "product"], [18, 20, "product"], [22, 30, "product"], [32, 33, "product"], [38, 44, "product"], [46, 47, "product"], [49, 50, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 10, 32, 33, "type-of", "", false, false], [12, 13, 32, 33, "type-of", "", false, false], [15, 16, 32, 33, "type-of", "", false, false], [18, 20, 32, 33, "type-of", "", false, false], [22, 30, 32, 33, "type-of", "", false, false], [46, 47, 38, 44, "type-of", "", false, false], [49, 50, 38, 44, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["With", "the", "advent", "of", "conversational", "assistants", "such", "as", "Apple", "'s", "Siri", ",", "Amazon", "Alexa", ",", "Google", "Assistant", ",", "Microsoft", "'s", "Cortana", "and", "Samsung", "'s", "Bixby", ",", "it", "is", "now", "possible", "to", "access", "voice", "portals", "through", "mobile", "devices", "and", "Far", "Field", "'s", "smart", "voice", "speakers", "such", "as", "Amazon", "Echo", "and", "Google", "Home", "."], "sentence-detokenized": "With the advent of conversational assistants such as Apple's Siri, Amazon Alexa, Google Assistant, Microsoft's Cortana and Samsung's Bixby, it is now possible to access voice portals through mobile devices and Far Field's smart voice speakers such as Amazon Echo and Google Home.", "token2charspan": [[0, 4], [5, 8], [9, 15], [16, 18], [19, 33], [34, 44], [45, 49], [50, 52], [53, 58], [58, 60], [61, 65], [65, 66], [67, 73], [74, 79], [79, 80], [81, 87], [88, 97], [97, 98], [99, 108], [108, 110], [111, 118], [119, 122], [123, 130], [130, 132], [133, 138], [138, 139], [140, 142], [143, 145], [146, 149], [150, 158], [159, 161], [162, 168], [169, 174], [175, 182], [183, 190], [191, 197], [198, 205], [206, 209], [210, 213], [214, 219], [219, 221], [222, 227], [228, 233], [234, 242], [243, 247], [248, 250], [251, 257], [258, 262], [263, 266], [267, 273], [274, 278], [278, 279]]}
{"doc_key": "ai-train-20", "ner": [[2, 3, "field"], [6, 8, "algorithm"], [10, 12, "algorithm"], [14, 16, "algorithm"], [19, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 8, 2, 3, "type-of", "", false, false], [10, 12, 2, 3, "type-of", "", false, false], [14, 16, 2, 3, "type-of", "", false, false], [19, 19, 2, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Examples", "of", "supervised", "learning", "are", "the", "Naive", "Bayes", "classifier", ",", "support", "vector", "machine", ",", "mixture", "of", "Gaussians", ",", "and", "networks", "."], "sentence-detokenized": "Examples of supervised learning are the Naive Bayes classifier, support vector machine, mixture of Gaussians, and networks.", "token2charspan": [[0, 8], [9, 11], [12, 22], [23, 31], [32, 35], [36, 39], [40, 45], [46, 51], [52, 62], [62, 63], [64, 71], [72, 78], [79, 86], [86, 87], [88, 95], [96, 98], [99, 108], [108, 109], [110, 113], [114, 122], [122, 123]]}
{"doc_key": "ai-train-21", "ner": [[0, 2, "algorithm"], [26, 28, "algorithm"], [30, 31, "task"], [34, 35, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 26, 28, "part-of", "", true, false], [34, 35, 30, 31, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "OSD", "algorithm", "can", "be", "used", "to", "derive", "math", "O", "(", "\\", "sqrt", "{", "T}", ")", "/", "math", "regret", "bounds", "for", "an", "online", "version", "of", "a", "support", "vector", "machine", "for", "classification", "that", "uses", "the", "hinge", "loss", "math", "in", "_t", "(", "w", ")", "=\\", "max", "\\", "{", "0", ",", "1", "-", "y", "_t", "(", "w", "\\", "cdot", "x", "_t", ")", "\\}", "/", "math"], "sentence-detokenized": "The OSD algorithm can be used to derive math O(\\ sqrt {T})/math regret bounds for an online version of a support vector machine for classification that uses the hinge loss math in _t (w)=\\ max\\ {0, 1 - y _t (w\\ cdot x _t)\\} / math", "token2charspan": [[0, 3], [4, 7], [8, 17], [18, 21], [22, 24], [25, 29], [30, 32], [33, 39], [40, 44], [45, 46], [46, 47], [47, 48], [49, 53], [54, 55], [55, 57], [57, 58], [58, 59], [59, 63], [64, 70], [71, 77], [78, 81], [82, 84], [85, 91], [92, 99], [100, 102], [103, 104], [105, 112], [113, 119], [120, 127], [128, 131], [132, 146], [147, 151], [152, 156], [157, 160], [161, 166], [167, 171], [172, 176], [177, 179], [180, 182], [183, 184], [184, 185], [185, 186], [186, 188], [189, 192], [192, 193], [194, 195], [195, 196], [196, 197], [198, 199], [200, 201], [202, 203], [204, 206], [207, 208], [208, 209], [209, 210], [211, 215], [216, 217], [218, 220], [220, 221], [221, 223], [224, 225], [226, 230]]}
{"doc_key": "ai-train-22", "ner": [[2, 3, "task"], [5, 6, "task"], [8, 8, "task"], [10, 11, "task"], [13, 14, "task"], [16, 17, "task"], [19, 20, "task"], [22, 24, "task"], [26, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Applications", "include", "object", "recognition", ",", "robotic", "mapping", "and", "navigation", ",", "image", "fusion", ",", "3D", "modelling", ",", "gesture", "recognition", ",", "video", "tracking", ",", "individual", "wildlife", "identification", "and", "motion", "matches", "."], "sentence-detokenized": "Applications include object recognition, robotic mapping and navigation, image fusion, 3D modelling, gesture recognition, video tracking, individual wildlife identification and motion matches.", "token2charspan": [[0, 12], [13, 20], [21, 27], [28, 39], [39, 40], [41, 48], [49, 56], [57, 60], [61, 71], [71, 72], [73, 78], [79, 85], [85, 86], [87, 89], [90, 99], [99, 100], [101, 108], [109, 120], [120, 121], [122, 127], [128, 136], [136, 137], [138, 148], [149, 157], [158, 172], [173, 176], [177, 183], [184, 191], [191, 192]]}
{"doc_key": "ai-train-23", "ner": [[0, 10, "task"], [15, 16, "university"], [18, 20, "university"], [22, 23, "university"], [25, 26, "university"], [28, 33, "university"], [35, 37, "university"], [39, 41, "university"], [43, 44, "university"], [46, 51, "university"], [53, 53, "university"], [58, 62, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[0, 10, 15, 16, "related-to", "", true, false], [0, 10, 18, 20, "related-to", "", true, false], [0, 10, 22, 23, "related-to", "", true, false], [0, 10, 25, 26, "related-to", "", true, false], [0, 10, 28, 33, "related-to", "", true, false], [0, 10, 35, 37, "related-to", "", true, false], [0, 10, 39, 41, "related-to", "", true, false], [0, 10, 43, 44, "related-to", "", true, false], [0, 10, 46, 51, "related-to", "", true, false], [0, 10, 53, 53, "related-to", "", true, false], [0, 10, 58, 62, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["A", "number", "of", "groups", "and", "companies", "are", "working", "on", "location", "estimation", ",", "including", "groups", "at", "Brown", "University", ",", "Carnegie", "Mellon", "University", ",", "MPI", "Saarbruecken", ",", "Stanford", "University", ",", "University", "of", "California", ",", "San", "Diego", ",", "University", "of", "Toronto", ",", "\u00c9cole", "Centrale", "Paris", ",", "ETH", "Zurich", ",", "National", "University", "of", "Science", "and", "Technology", "(", "NUST", ")", ",", "and", "the", "University", "of", "California", ",", "Irvine", "."], "sentence-detokenized": "A number of groups and companies are working on location estimation, including groups at Brown University, Carnegie Mellon University, MPI Saarbruecken, Stanford University, University of California, San Diego, University of Toronto, \u00c9cole Centrale Paris, ETH Zurich, National University of Science and Technology (NUST), and the University of California, Irvine.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 18], [19, 22], [23, 32], [33, 36], [37, 44], [45, 47], [48, 56], [57, 67], [67, 68], [69, 78], [79, 85], [86, 88], [89, 94], [95, 105], [105, 106], [107, 115], [116, 122], [123, 133], [133, 134], [135, 138], [139, 151], [151, 152], [153, 161], [162, 172], [172, 173], [174, 184], [185, 187], [188, 198], [198, 199], [200, 203], [204, 209], [209, 210], [211, 221], [222, 224], [225, 232], [232, 233], [234, 239], [240, 248], [249, 254], [254, 255], [256, 259], [260, 266], [266, 267], [268, 276], [277, 287], [288, 290], [291, 298], [299, 302], [303, 313], [314, 315], [315, 319], [319, 320], [320, 321], [322, 325], [326, 329], [330, 340], [341, 343], [344, 354], [354, 355], [356, 362], [362, 363]]}
{"doc_key": "ai-train-24", "ner": [[0, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sigmoid", "cross", "entropy", "loss", "function", "is", "used", "to", "predict", "K", "independent", "probability", "values", "in", "mathematics", "0,1", "/", "mat", "."], "sentence-detokenized": "The sigmoid cross entropy loss function is used to predict K independent probability values in mathematics 0,1 / mat.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 25], [26, 30], [31, 39], [40, 42], [43, 47], [48, 50], [51, 58], [59, 60], [61, 72], [73, 84], [85, 91], [92, 94], [95, 106], [107, 110], [111, 112], [113, 116], [116, 117]]}
{"doc_key": "ai-train-25", "ner": [[10, 19, "misc"], [13, 14, "field"], [16, 17, "field"], [20, 22, "university"], [25, 25, "country"], [28, 30, "misc"], [33, 36, "university"], [38, 38, "country"], [5, 7, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[10, 19, 13, 14, "topic", "", false, false], [10, 19, 16, 17, "topic", "", false, false], [10, 19, 20, 22, "physical", "", true, false], [20, 22, 25, 25, "physical", "", false, false], [28, 30, 33, 36, "physical", "", true, false], [33, 36, 38, 38, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Before", "becoming", "a", "professor", "at", "Cambridge", ",", "he", "held", "the", "Johann", "Bernoulli", "Chair", "in", "Mathematics", "and", "Computer", "Science", "at", "the", "University", "of", "Groningen", "in", "the", "Netherlands", "and", "the", "Toshiba", "Endowed", "Chair", "at", "the", "Tokyo", "Institute", "of", "Technology", "in", "Japan", "."], "sentence-detokenized": "Before becoming a professor at Cambridge, he held the Johann Bernoulli Chair in Mathematics and Computer Science at the University of Groningen in the Netherlands and the Toshiba Endowed Chair at the Tokyo Institute of Technology in Japan.", "token2charspan": [[0, 6], [7, 15], [16, 17], [18, 27], [28, 30], [31, 40], [40, 41], [42, 44], [45, 49], [50, 53], [54, 60], [61, 70], [71, 76], [77, 79], [80, 91], [92, 95], [96, 104], [105, 112], [113, 115], [116, 119], [120, 130], [131, 133], [134, 143], [144, 146], [147, 150], [151, 162], [163, 166], [167, 170], [171, 178], [179, 186], [187, 192], [193, 195], [196, 199], [200, 205], [206, 215], [216, 218], [219, 229], [230, 232], [233, 238], [238, 239]]}
{"doc_key": "ai-train-26", "ner": [[7, 8, "algorithm"], [12, 16, "algorithm"], [18, 22, "algorithm"], [26, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 12, 16, "usage", "", true, false], [12, 16, 26, 27, "origin", "", false, false], [12, 16, 29, 30, "origin", "", false, false], [18, 22, 12, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Another", "technique", "that", "is", "mainly", "used", "in", "recurrent", "neural", "networks", "is", "the", "long", "short", "-", "term", "memory", "(", "LSTM", ")", "network", "from", "1997", ",", "created", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Another technique that is mainly used in recurrent neural networks is the long short-term memory (LSTM) network from 1997, created by Sepp Hochreiter and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 7], [8, 17], [18, 22], [23, 25], [26, 32], [33, 37], [38, 40], [41, 50], [51, 57], [58, 66], [67, 69], [70, 73], [74, 78], [79, 84], [84, 85], [85, 89], [90, 96], [97, 98], [98, 102], [102, 103], [104, 111], [112, 116], [117, 121], [121, 122], [123, 130], [131, 133], [134, 138], [139, 149], [150, 153], [154, 160], [161, 172], [172, 173]]}
{"doc_key": "ai-train-27", "ner": [[4, 5, "programlang"], [8, 9, "product"], [15, 15, "product"], [46, 46, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 4, 5, "general-affiliation", "", false, false], [8, 9, 15, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "inclusion", "of", "a", "C", "++", "interpreter", "(", "CI", "NT", "up", "to", "version", "5.34", ",", "Cling", "from", "version", "6", "onwards", ")", "makes", "this", "package", "very", "versatile", ",", "as", "it", "can", "be", "used", "in", "interactive", ",", "scripted", "and", "compiled", "mode", ",", "similar", "to", "commercial", "products", "such", "as", "MATLAB", "."], "sentence-detokenized": "The inclusion of a C++ interpreter (CINT up to version 5.34, Cling from version 6 onwards) makes this package very versatile, as it can be used in interactive, scripted and compiled mode, similar to commercial products such as MATLAB.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 18], [19, 20], [20, 22], [23, 34], [35, 36], [36, 38], [38, 40], [41, 43], [44, 46], [47, 54], [55, 59], [59, 60], [61, 66], [67, 71], [72, 79], [80, 81], [82, 89], [89, 90], [91, 96], [97, 101], [102, 109], [110, 114], [115, 124], [124, 125], [126, 128], [129, 131], [132, 135], [136, 138], [139, 143], [144, 146], [147, 158], [158, 159], [160, 168], [169, 172], [173, 181], [182, 186], [186, 187], [188, 195], [196, 198], [199, 209], [210, 218], [219, 223], [224, 226], [227, 233], [233, 234]]}
{"doc_key": "ai-train-28", "ner": [[0, 3, "product"], [21, 23, "field"], [27, 28, "task"], [30, 32, "task"], [34, 35, "task"], [38, 39, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 21, 23, "related-to", "", false, false], [27, 28, 21, 23, "part-of", "", false, false], [30, 32, 21, 23, "part-of", "", false, false], [34, 35, 21, 23, "part-of", "", false, false], [38, 39, 21, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Voice", "user", "interfaces", "that", "interpret", "and", "manage", "conversation", "state", "are", "challenging", "to", "design", "because", "of", "the", "inherent", "difficulty", "of", "integrating", "complex", "natural", "language", "processing", "tasks", "such", "as", "coreference", "resolution", ",", "named", "entity", "recognition", ",", "information", "retrieval", ",", "and", "dialogue", "management", "."], "sentence-detokenized": "Voice user interfaces that interpret and manage conversation state are challenging to design because of the inherent difficulty of integrating complex natural language processing tasks such as coreference resolution, named entity recognition, information retrieval, and dialogue management.", "token2charspan": [[0, 5], [6, 10], [11, 21], [22, 26], [27, 36], [37, 40], [41, 47], [48, 60], [61, 66], [67, 70], [71, 82], [83, 85], [86, 92], [93, 100], [101, 103], [104, 107], [108, 116], [117, 127], [128, 130], [131, 142], [143, 150], [151, 158], [159, 167], [168, 178], [179, 184], [185, 189], [190, 192], [193, 204], [205, 215], [215, 216], [217, 222], [223, 229], [230, 241], [241, 242], [243, 254], [255, 264], [264, 265], [266, 269], [270, 278], [279, 289], [289, 290]]}
{"doc_key": "ai-train-29", "ner": [[5, 7, "algorithm"], [9, 12, "algorithm"], [15, 17, "researcher"], [22, 26, "organisation"], [35, 36, "field"], [38, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 7, 15, 17, "origin", "", false, false], [5, 7, 35, 36, "part-of", "", false, false], [5, 7, 38, 39, "part-of", "", false, false], [9, 12, 15, 17, "origin", "", false, false], [9, 12, 35, 36, "part-of", "", false, false], [9, 12, 38, 39, "part-of", "", false, false], [15, 17, 22, 26, "physical", "", false, false], [15, 17, 22, 26, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Between", "2009", "and", "2012", ",", "recurrent", "neural", "networks", "and", "deep", "feedforward", "neural", "networks", "developed", "in", "J\u00fcrgen", "Schmidhuber", "'s", "research", "group", "at", "the", "Swiss", "artificial", "intelligence", "laboratory", "IDSIA", "won", "eight", "international", "competitions", "in", "the", "field", "of", "pattern", "recognition", "and", "machine", "learning", "."], "sentence-detokenized": "Between 2009 and 2012, recurrent neural networks and deep feedforward neural networks developed in J\u00fcrgen Schmidhuber's research group at the Swiss artificial intelligence laboratory IDSIA won eight international competitions in the field of pattern recognition and machine learning.", "token2charspan": [[0, 7], [8, 12], [13, 16], [17, 21], [21, 22], [23, 32], [33, 39], [40, 48], [49, 52], [53, 57], [58, 69], [70, 76], [77, 85], [86, 95], [96, 98], [99, 105], [106, 117], [117, 119], [120, 128], [129, 134], [135, 137], [138, 141], [142, 147], [148, 158], [159, 171], [172, 182], [183, 188], [189, 192], [193, 198], [199, 212], [213, 225], [226, 228], [229, 232], [233, 238], [239, 241], [242, 249], [250, 261], [262, 265], [266, 273], [274, 282], [282, 283]]}
{"doc_key": "ai-train-30", "ner": [[1, 3, "product"], [6, 7, "product"], [9, 10, "product"], [14, 17, "task"], [16, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 6, 7, "usage", "", false, false], [1, 3, 9, 10, "usage", "", false, false], [1, 3, 14, 17, "usage", "", true, false], [1, 3, 16, 16, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Modern", "Windows", "desktop", "systems", "can", "use", "SAPI", "4", "and", "SAPI", "5", "components", "to", "support", "speech", "and", "speech", "synthesis", "."], "sentence-detokenized": "Modern Windows desktop systems can use SAPI 4 and SAPI 5 components to support speech and speech synthesis.", "token2charspan": [[0, 6], [7, 14], [15, 22], [23, 30], [31, 34], [35, 38], [39, 43], [44, 45], [46, 49], [50, 54], [55, 56], [57, 67], [68, 70], [71, 78], [79, 85], [86, 89], [90, 96], [97, 106], [106, 107]]}
{"doc_key": "ai-train-31", "ner": [[7, 11, "misc"], [13, 13, "field"], [16, 20, "university"], [25, 28, "field"], [31, 34, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 11, 13, 13, "topic", "topic_of_award", false, false], [7, 11, 16, 20, "origin", "", true, false], [25, 28, 31, 34, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "received", "two", "honorary", "degrees", ",", "one", "S.V.", "della", "laurea", "ad", "honorem", "in", "psychology", "from", "the", "University", "of", "Padua", "in", "1995", "and", "one", "doctorate", "in", "industrial", "design", "and", "engineering", "from", "the", "Technical", "University", "of", "Delft", "."], "sentence-detokenized": "He received two honorary degrees, one S.V. della laurea ad honorem in psychology from the University of Padua in 1995 and one doctorate in industrial design and engineering from the Technical University of Delft.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 24], [25, 32], [32, 33], [34, 37], [38, 42], [43, 48], [49, 55], [56, 58], [59, 66], [67, 69], [70, 80], [81, 85], [86, 89], [90, 100], [101, 103], [104, 109], [110, 112], [113, 117], [118, 121], [122, 125], [126, 135], [136, 138], [139, 149], [150, 156], [157, 160], [161, 172], [173, 177], [178, 181], [182, 191], [192, 202], [203, 205], [206, 211], [211, 212]]}
{"doc_key": "ai-train-32", "ner": [[4, 7, "researcher"], [11, 14, "organisation"], [16, 16, "location"], [18, 19, "researcher"], [28, 30, "misc"], [44, 47, "misc"], [64, 66, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 7, 11, 14, "physical", "", false, false], [4, 7, 11, 14, "role", "", false, false], [11, 14, 16, 16, "physical", "", false, false], [18, 19, 28, 30, "related-to", "works_with", true, false], [18, 19, 44, 47, "related-to", "works_with", true, false], [18, 19, 64, 66, "related-to", "works_with", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Along", "with", "longtime", "collaborator", "Laurent", "Cohen", ",", "a", "neurologist", "at", "the", "Piti\u00e9", "-", "Salp\u00eatri\u00e8re", "Hospital", "in", "Paris", ",", "Dehaene", "also", "identified", "patients", "with", "lesions", "in", "different", "regions", "of", "the", "temporal", "lobe", "with", "impaired", "multiplication", "but", "preserved", "subtraction", "(", "which", "is", "related", "to", "lesions", "of", "the", "inferior", "temporal", "lobe", ")", "and", "others", "with", "impaired", "subtraction", "but", "preserved", "multiplication", "(", "which", "is", "related", "to", "lesions", "of", "the", "intraparietal", "sulcus", ")", "."], "sentence-detokenized": "Along with longtime collaborator Laurent Cohen, a neurologist at the Piti\u00e9-Salp\u00eatri\u00e8re Hospital in Paris, Dehaene also identified patients with lesions in different regions of the temporal lobe with impaired multiplication but preserved subtraction (which is related to lesions of the inferior temporal lobe) and others with impaired subtraction but preserved multiplication (which is related to lesions of the intraparietal sulcus).", "token2charspan": [[0, 5], [6, 10], [11, 19], [20, 32], [33, 40], [41, 46], [46, 47], [48, 49], [50, 61], [62, 64], [65, 68], [69, 74], [74, 75], [75, 86], [87, 95], [96, 98], [99, 104], [104, 105], [106, 113], [114, 118], [119, 129], [130, 138], [139, 143], [144, 151], [152, 154], [155, 164], [165, 172], [173, 175], [176, 179], [180, 188], [189, 193], [194, 198], [199, 207], [208, 222], [223, 226], [227, 236], [237, 248], [249, 250], [250, 255], [256, 258], [259, 266], [267, 269], [270, 277], [278, 280], [281, 284], [285, 293], [294, 302], [303, 307], [307, 308], [309, 312], [313, 319], [320, 324], [325, 333], [334, 345], [346, 349], [350, 359], [360, 374], [375, 376], [376, 381], [382, 384], [385, 392], [393, 395], [396, 403], [404, 406], [407, 410], [411, 424], [425, 431], [431, 432], [432, 433]]}
{"doc_key": "ai-train-33", "ner": [[6, 9, "product"], [13, 16, "misc"], [18, 19, "misc"], [28, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 16, 6, 9, "topic", "", false, false], [18, 19, 6, 9, "topic", "", false, false], [28, 28, 6, 9, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["More", "recently", ",", "fictional", "depictions", "of", "artificially", "intelligent", "robots", "in", "films", "such", "as", "A.I", ".", "Artificial", "Intelligence", "and", "Ex", "Machina", ",", "and", "in", "the", "2016", "television", "adaptation", "of", "Westworld", "."], "sentence-detokenized": "More recently, fictional depictions of artificially intelligent robots in films such as A.I. Artificial Intelligence and Ex Machina, and in the 2016 television adaptation of Westworld.", "token2charspan": [[0, 4], [5, 13], [13, 14], [15, 24], [25, 35], [36, 38], [39, 51], [52, 63], [64, 70], [71, 73], [74, 79], [80, 84], [85, 87], [88, 91], [91, 92], [93, 103], [104, 116], [117, 120], [121, 123], [124, 131], [131, 132], [133, 136], [137, 139], [140, 143], [144, 148], [149, 159], [160, 170], [171, 173], [174, 183], [183, 184]]}
{"doc_key": "ai-train-34", "ner": [[7, 8, "field"], [10, 12, "algorithm"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 12, 7, 8, "part-of", "", false, false], [14, 15, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "of", "the", "main", "methods", "used", "in", "unsupervised", "learning", "are", "principal", "component", "analysis", "and", "cluster", "analysis", "."], "sentence-detokenized": "Two of the main methods used in unsupervised learning are principal component analysis and cluster analysis.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 15], [16, 23], [24, 28], [29, 31], [32, 44], [45, 53], [54, 57], [58, 67], [68, 77], [78, 86], [87, 90], [91, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-train-35", "ner": [[0, 4, "organisation"], [24, 25, "misc"], [30, 31, "misc"], [33, 35, "person"], [40, 41, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[24, 25, 0, 4, "artifact", "", false, false], [30, 31, 0, 4, "artifact", "", false, false], [30, 31, 33, 35, "role", "director_of", false, false], [30, 31, 40, 41, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Walt", "Disney", "Company", "also", "began", "to", "make", "greater", "use", "of", "3D", "films", "in", "special", "venues", "to", "impress", "audiences", ",", "with", "notable", "examples", "being", "Enchanted", "Voyages", "(", "1982", ")", "and", "Captain", "EO", "(", "Francis", "Ford", "Coppola", ",", "1986", ",", "starring", "Michael", "Jackson", ")", "."], "sentence-detokenized": "The Walt Disney Company also began to make greater use of 3D films in special venues to impress audiences, with notable examples being Enchanted Voyages (1982) and Captain EO (Francis Ford Coppola, 1986, starring Michael Jackson).", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 23], [24, 28], [29, 34], [35, 37], [38, 42], [43, 50], [51, 54], [55, 57], [58, 60], [61, 66], [67, 69], [70, 77], [78, 84], [85, 87], [88, 95], [96, 105], [105, 106], [107, 111], [112, 119], [120, 128], [129, 134], [135, 144], [145, 152], [153, 154], [154, 158], [158, 159], [160, 163], [164, 171], [172, 174], [175, 176], [176, 183], [184, 188], [189, 196], [196, 197], [198, 202], [202, 203], [204, 212], [213, 220], [221, 228], [228, 229], [229, 230]]}
{"doc_key": "ai-train-36", "ner": [[9, 11, "field"], [16, 21, "task"], [23, 24, "task"], [26, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 21, 9, 11, "part-of", "", false, false], [23, 24, 9, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Since", "2002", ",", "perceptron", "training", "has", "become", "popular", "in", "natural", "language", "processing", "for", "tasks", "such", "as", "part", "-", "of", "-", "speech", "tagging", "and", "syntactic", "parsing", "(", "Collins", ",", "2002", ")", "."], "sentence-detokenized": "Since 2002, perceptron training has become popular in natural language processing for tasks such as part-of-speech tagging and syntactic parsing (Collins, 2002).", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 22], [23, 31], [32, 35], [36, 42], [43, 50], [51, 53], [54, 61], [62, 70], [71, 81], [82, 85], [86, 91], [92, 96], [97, 99], [100, 104], [104, 105], [105, 107], [107, 108], [108, 114], [115, 122], [123, 126], [127, 136], [137, 144], [145, 146], [146, 153], [153, 154], [155, 159], [159, 160], [160, 161]]}
{"doc_key": "ai-train-37", "ner": [[2, 3, "product"], [9, 13, "organisation"], [14, 15, "organisation"], [17, 17, "country"], [20, 23, "product"], [27, 29, "researcher"], [37, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 13, 2, 3, "role", "introduces_to_market", true, false], [14, 15, 2, 3, "role", "introduces_to_market", true, false], [14, 15, 17, 17, "physical", "", false, false], [20, 23, 37, 37, "related-to", "sold_to", true, false], [27, 29, 20, 23, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "first", "palletizing", "robot", "was", "introduced", "in", "1963", "by", "Fuji", "Yusoki", "Kogyo", "Company", ".", "KUKA", "robotics", "in", "Germany", "and", "the", "programmable", "universal", "assembly", "machine", "was", "invented", "by", "Victor", "Scheinman", "in", "1976", "and", "his", "design", "was", "sold", "to", "Unimation", "."], "sentence-detokenized": "The first palletizing robot was introduced in 1963 by Fuji Yusoki Kogyo Company. KUKA robotics in Germany and the programmable universal assembly machine was invented by Victor Scheinman in 1976 and his design was sold to Unimation.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 27], [28, 31], [32, 42], [43, 45], [46, 50], [51, 53], [54, 58], [59, 65], [66, 71], [72, 79], [79, 80], [81, 85], [86, 94], [95, 97], [98, 105], [106, 109], [110, 113], [114, 126], [127, 136], [137, 145], [146, 153], [154, 157], [158, 166], [167, 169], [170, 176], [177, 186], [187, 189], [190, 194], [195, 198], [199, 202], [203, 209], [210, 213], [214, 218], [219, 221], [222, 231], [231, 232]]}
{"doc_key": "ai-train-38", "ner": [[10, 12, "conference"], [5, 5, "researcher"], [21, 23, "field"], [34, 35, "researcher"], [42, 45, "researcher"], [56, 56, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 10, 12, "role", "president_of", false, false], [5, 5, 34, 35, "role", "colleagues", false, false], [21, 23, 56, 56, "named", "same", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "mid-1990s", ",", "when", "Hayes", "was", "president", "of", "the", "AAAI", ",", "he", "launched", "a", "series", "of", "attacks", "on", "critics", "of", "AI", ",", "mostly", "couched", "in", "ironic", "terms", ",", "and", "(", "with", "his", "colleague", "Kenneth", "Ford", ")", "invented", "a", "prize", "named", "after", "Simon", "Newcomb", "to", "be", "awarded", "for", "the", "most", "ridiculous", "argument", "refuting", "the", "possibility", "of", "AI", "."], "sentence-detokenized": "In the mid-1990s, when Hayes was president of the AAAI, he launched a series of attacks on critics of AI, mostly couched in ironic terms, and (with his colleague Kenneth Ford) invented a prize named after Simon Newcomb to be awarded for the most ridiculous argument refuting the possibility of AI.", "token2charspan": [[0, 2], [3, 6], [7, 16], [16, 17], [18, 22], [23, 28], [29, 32], [33, 42], [43, 45], [46, 49], [50, 54], [54, 55], [56, 58], [59, 67], [68, 69], [70, 76], [77, 79], [80, 87], [88, 90], [91, 98], [99, 101], [102, 104], [104, 105], [106, 112], [113, 120], [121, 123], [124, 130], [131, 136], [136, 137], [138, 141], [142, 143], [143, 147], [148, 151], [152, 161], [162, 169], [170, 174], [174, 175], [176, 184], [185, 186], [187, 192], [193, 198], [199, 204], [205, 210], [211, 218], [219, 221], [222, 224], [225, 232], [233, 236], [237, 240], [241, 245], [246, 256], [257, 265], [266, 274], [275, 278], [279, 290], [291, 293], [294, 296], [296, 297]]}
{"doc_key": "ai-train-39", "ner": [[14, 21, "algorithm"], [41, 43, "algorithm"], [55, 58, "algorithm"], [63, 66, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 21, 41, 43, "named", "same", false, false], [55, 58, 14, 21, "type-of", "", false, false], [63, 66, 14, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "optimal", "value", "of", "math", "/", "alpha", "/", "math", "can", "be", "found", "using", "a", "line", "search", "algorithm", ",", "that", "is", ",", "the", "size", "of", "math", "/", "alpha", "/", "math", "is", "determined", "by", "finding", "the", "value", "that", "minimizes", "S", ",", "usually", "by", "searching", "the", "rows", "in", "the", "interval", "math0", "/", "alpha", "1", "/", "math", "or", "by", "a", "backward", "line", "search", ",", "such", "as", "an", "Armijo", "-", "line", "search", "."], "sentence-detokenized": "The optimal value of math/alpha/math can be found using a line search algorithm, that is, the size of math/alpha/math is determined by finding the value that minimizes S, usually by searching the rows in the interval math0/alpha 1/math or by a backward line search, such as an Armijo-line search.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 20], [21, 25], [25, 26], [26, 31], [31, 32], [32, 36], [37, 40], [41, 43], [44, 49], [50, 55], [56, 57], [58, 62], [63, 69], [70, 79], [79, 80], [81, 85], [86, 88], [88, 89], [90, 93], [94, 98], [99, 101], [102, 106], [106, 107], [107, 112], [112, 113], [113, 117], [118, 120], [121, 131], [132, 134], [135, 142], [143, 146], [147, 152], [153, 157], [158, 167], [168, 169], [169, 170], [171, 178], [179, 181], [182, 191], [192, 195], [196, 200], [201, 203], [204, 207], [208, 216], [217, 222], [222, 223], [223, 228], [229, 230], [230, 231], [231, 235], [236, 238], [239, 241], [242, 243], [244, 252], [253, 257], [258, 264], [264, 265], [266, 270], [271, 273], [274, 276], [277, 283], [283, 284], [284, 288], [289, 295], [295, 296]]}
{"doc_key": "ai-train-40", "ner": [[2, 9, "algorithm"], [6, 12, "algorithm"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "discusses", "breadth", "-", "first", "and", "depth", "-", "first", "search", "techniques", ",", "but", "ultimately", "concludes", "that", "the", "results", "represent", "expert", "systems", "that", "embody", "a", "wealth", "of", "technical", "knowledge", ",", "but", "do", "not", "shed", "much", "light", "on", "the", "mental", "processes", "that", "people", "use", "to", "solve", "such", "puzzles", "."], "sentence-detokenized": "He discusses breadth-first and depth-first search techniques, but ultimately concludes that the results represent expert systems that embody a wealth of technical knowledge, but do not shed much light on the mental processes that people use to solve such puzzles.", "token2charspan": [[0, 2], [3, 12], [13, 20], [20, 21], [21, 26], [27, 30], [31, 36], [36, 37], [37, 42], [43, 49], [50, 60], [60, 61], [62, 65], [66, 76], [77, 86], [87, 91], [92, 95], [96, 103], [104, 113], [114, 120], [121, 128], [129, 133], [134, 140], [141, 142], [143, 149], [150, 152], [153, 162], [163, 172], [172, 173], [174, 177], [178, 180], [181, 184], [185, 189], [190, 194], [195, 200], [201, 203], [204, 207], [208, 214], [215, 224], [225, 229], [230, 236], [237, 240], [241, 243], [244, 249], [250, 254], [255, 262], [262, 263]]}
{"doc_key": "ai-train-41", "ner": [[0, 1, "task"], [3, 6, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Speech", "recognition", "and", "speech", "synthesis", "deal", "with", "how", "computers", "can", "be", "used", "to", "understand", "or", "produce", "spoken", "speech", "."], "sentence-detokenized": "Speech recognition and speech synthesis deal with how computers can be used to understand or produce spoken speech.", "token2charspan": [[0, 6], [7, 18], [19, 22], [23, 29], [30, 39], [40, 44], [45, 49], [50, 53], [54, 63], [64, 67], [68, 70], [71, 75], [76, 78], [79, 89], [90, 92], [93, 100], [101, 107], [108, 114], [114, 115]]}
{"doc_key": "ai-train-42", "ner": [[13, 14, "algorithm"], [29, 31, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "math", "theta", "^", "{", "*}", "/", "math", "is", "usually", "estimated", "using", "a", "maximum", "likelihood", "procedure", "(", "math\\", "theta", "^{", "*}", "=\\", "theta^{", "ML}", "/", "math", ")", "or", "a", "maximum", "posteriori", "procedure", "(", "math\\", "theta", "^{", "*}", "=\\", "theta", "^{", "MAP", "}", "/", "math", ")", "."], "sentence-detokenized": "This math theta ^ {*} / math is usually estimated using a maximum likelihood procedure (math\\ theta^{*} =\\ theta^{ML} / math) or a maximum posteriori procedure (math\\ theta^{*} =\\ theta^{MAP} / math).", "token2charspan": [[0, 4], [5, 9], [10, 15], [16, 17], [18, 19], [19, 21], [22, 23], [24, 28], [29, 31], [32, 39], [40, 49], [50, 55], [56, 57], [58, 65], [66, 76], [77, 86], [87, 88], [88, 93], [94, 99], [99, 101], [101, 103], [104, 106], [107, 114], [114, 117], [118, 119], [120, 124], [124, 125], [126, 128], [129, 130], [131, 138], [139, 149], [150, 159], [160, 161], [161, 166], [167, 172], [172, 174], [174, 176], [177, 179], [180, 185], [185, 187], [187, 190], [190, 191], [192, 193], [194, 198], [198, 199], [199, 200]]}
{"doc_key": "ai-train-43", "ner": [[9, 10, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "less", "widespread", "languages", "use", "the", "open", "-", "source", "eSpeak", "synthesizer", "to", "speak", ",", "which", "produces", "a", "robotic", ",", "awkward", "voice", "that", "can", "be", "difficult", "to", "understand", "."], "sentence-detokenized": "Some less widespread languages use the open-source eSpeak synthesizer to speak, which produces a robotic, awkward voice that can be difficult to understand.", "token2charspan": [[0, 4], [5, 9], [10, 20], [21, 30], [31, 34], [35, 38], [39, 43], [43, 44], [44, 50], [51, 57], [58, 69], [70, 72], [73, 78], [78, 79], [80, 85], [86, 94], [95, 96], [97, 104], [104, 105], [106, 113], [114, 119], [120, 124], [125, 128], [129, 131], [132, 141], [142, 144], [145, 155], [155, 156]]}
{"doc_key": "ai-train-44", "ner": [[21, 21, "programlang"], [37, 38, "programlang"], [40, 40, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 21, 37, 38, "compare", "", false, false], [21, 21, 40, 40, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Although", "it", "is", "mainly", "used", "by", "statisticians", "and", "other", "professionals", "who", "need", "an", "environment", "for", "statistical", "computing", "and", "software", "development", ",", "R", "can", "also", "function", "as", "a", "general", "matrix", "computation", "tool", "-", "with", "performance", "benchmarks", "comparable", "to", "GNU", "Octave", "or", "MATLAB", "."], "sentence-detokenized": "Although it is mainly used by statisticians and other professionals who need an environment for statistical computing and software development, R can also function as a general matrix computation tool - with performance benchmarks comparable to GNU Octave or MATLAB.", "token2charspan": [[0, 8], [9, 11], [12, 14], [15, 21], [22, 26], [27, 29], [30, 43], [44, 47], [48, 53], [54, 67], [68, 71], [72, 76], [77, 79], [80, 91], [92, 95], [96, 107], [108, 117], [118, 121], [122, 130], [131, 142], [142, 143], [144, 145], [146, 149], [150, 154], [155, 163], [164, 166], [167, 168], [169, 176], [177, 183], [184, 195], [196, 200], [201, 202], [203, 207], [208, 219], [220, 230], [231, 241], [242, 244], [245, 248], [249, 255], [256, 258], [259, 265], [265, 266]]}
{"doc_key": "ai-train-45", "ner": [[0, 0, "algorithm"], [3, 4, "field"], [8, 11, "misc"], [12, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 4, "part-of", "", false, false], [0, 0, 12, 14, "origin", "", false, false], [8, 11, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Heterodyning", "is", "a", "signal", "processing", "technique", "invented", "by", "Canadian", "inventor", "and", "engineer", "Reginald", "Fessenden", "that", "creates", "new", "frequencies", "by", "combining", "two", "frequencies", "."], "sentence-detokenized": "Heterodyning is a signal processing technique invented by Canadian inventor and engineer Reginald Fessenden that creates new frequencies by combining two frequencies.", "token2charspan": [[0, 12], [13, 15], [16, 17], [18, 24], [25, 35], [36, 45], [46, 54], [55, 57], [58, 66], [67, 75], [76, 79], [80, 88], [89, 97], [98, 107], [108, 112], [113, 120], [121, 124], [125, 136], [137, 139], [140, 149], [150, 153], [154, 165], [165, 166]]}
{"doc_key": "ai-train-46", "ner": [[15, 17, "person"], [18, 18, "misc"], [22, 24, "organisation"], [27, 28, "organisation"], [29, 31, "misc"], [33, 34, "person"], [37, 37, "organisation"], [39, 41, "misc"], [43, 44, "person"], [46, 47, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[15, 17, 18, 18, "role", "actor_in", false, false], [18, 18, 22, 24, "artifact", "", false, false], [29, 31, 27, 28, "artifact", "", false, false], [33, 34, 29, 31, "role", "actor_in", false, false], [39, 41, 37, 37, "artifact", "", false, false], [43, 44, 39, 41, "role", "actor_in", false, false], [46, 47, 39, 41, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["A", "few", "other", "films", "that", "helped", "put", "3D", "back", "on", "the", "map", "this", "month", "were", "John", "Wayne", "'s", "Hondo", "(", "distributed", "by", "Warner", "Bros", ".", ")", ",", "Columbia", "'s", "Miss", "Sadie", "Thompson", "starring", "Rita", "Hayworth", ",", "and", "Paramount", "'s", "Money", "From", "Home", "starring", "Dean", "Martin", "and", "Jerry", "Lewis", "."], "sentence-detokenized": "A few other films that helped put 3D back on the map this month were John Wayne's Hondo (distributed by Warner Bros. ), Columbia's Miss Sadie Thompson starring Rita Hayworth, and Paramount's Money From Home starring Dean Martin and Jerry Lewis.", "token2charspan": [[0, 1], [2, 5], [6, 11], [12, 17], [18, 22], [23, 29], [30, 33], [34, 36], [37, 41], [42, 44], [45, 48], [49, 52], [53, 57], [58, 63], [64, 68], [69, 73], [74, 79], [79, 81], [82, 87], [88, 89], [89, 100], [101, 103], [104, 110], [111, 115], [115, 116], [117, 118], [118, 119], [120, 128], [128, 130], [131, 135], [136, 141], [142, 150], [151, 159], [160, 164], [165, 173], [173, 174], [175, 178], [179, 188], [188, 190], [191, 196], [197, 201], [202, 206], [207, 215], [216, 220], [221, 227], [228, 231], [232, 237], [238, 243], [243, 244]]}
{"doc_key": "ai-train-47", "ner": [[0, 0, "product"], [3, 6, "field"], [7, 8, "task"], [12, 12, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 8, "general-affiliation", "", false, false], [0, 0, 12, 12, "artifact", "", false, false], [7, 8, 3, 6, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["DeepFace", "is", "a", "deep", "learning", "-", "based", "facial", "recognition", "system", "created", "by", "Facebook", "'s", "research", "group", "."], "sentence-detokenized": "DeepFace is a deep learning-based facial recognition system created by Facebook's research group.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 18], [19, 27], [27, 28], [28, 33], [34, 40], [41, 52], [53, 59], [60, 67], [68, 70], [71, 79], [79, 81], [82, 90], [91, 96], [96, 97]]}
{"doc_key": "ai-train-48", "ner": [[0, 1, "field"], [8, 10, "conference"], [15, 19, "field"], [25, 27, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 15, 19, "part-of", "subfield", false, false], [8, 10, 0, 1, "topic", "", false, false], [25, 27, 0, 1, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Geometry", "processing", "is", "a", "frequent", "research", "topic", "at", "SIGGRAPH", ",", "the", "premier", "academic", "conference", "on", "computer", "graphics", ",", "and", "a", "major", "theme", "of", "the", "annual", "Geometry", "Processing", "Symposium", "."], "sentence-detokenized": "Geometry processing is a frequent research topic at SIGGRAPH, the premier academic conference on computer graphics, and a major theme of the annual Geometry Processing Symposium.", "token2charspan": [[0, 8], [9, 19], [20, 22], [23, 24], [25, 33], [34, 42], [43, 48], [49, 51], [52, 60], [60, 61], [62, 65], [66, 73], [74, 82], [83, 93], [94, 96], [97, 105], [106, 114], [114, 115], [116, 119], [120, 121], [122, 127], [128, 133], [134, 136], [137, 140], [141, 147], [148, 156], [157, 167], [168, 177], [177, 178]]}
{"doc_key": "ai-train-49", "ner": [[0, 1, "task"], [3, 4, "task"], [13, 15, "algorithm"], [17, 17, "algorithm"], [20, 22, "algorithm"], [24, 24, "algorithm"], [27, 29, "algorithm"], [31, 31, "algorithm"], [36, 40, "misc"], [43, 45, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[13, 15, 36, 40, "general-affiliation", "", false, false], [17, 17, 13, 15, "named", "", false, false], [20, 22, 36, 40, "general-affiliation", "", false, false], [24, 24, 20, 22, "named", "", false, false], [27, 29, 36, 40, "general-affiliation", "", false, false], [31, 31, 27, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Feature", "extraction", "and", "dimension", "reduction", "can", "be", "combined", "into", "a", "single", "step", "using", "principal", "component", "analysis", "(", "PCA", ")", ",", "linear", "discriminant", "analysis", "(", "LDA", ")", "or", "canonical", "correlation", "analysis", "(", "CCA", ")", "techniques", "as", "a", "preprocessing", "step", ",", "followed", "by", "clustering", "using", "k", "-", "NN", "on", "the", "feature", "vectors", "in", "the", "reduced", "dimension", "space", "."], "sentence-detokenized": "Feature extraction and dimension reduction can be combined into a single step using principal component analysis (PCA), linear discriminant analysis (LDA) or canonical correlation analysis (CCA) techniques as a preprocessing step, followed by clustering using k -NN on the feature vectors in the reduced dimension space.", "token2charspan": [[0, 7], [8, 18], [19, 22], [23, 32], [33, 42], [43, 46], [47, 49], [50, 58], [59, 63], [64, 65], [66, 72], [73, 77], [78, 83], [84, 93], [94, 103], [104, 112], [113, 114], [114, 117], [117, 118], [118, 119], [120, 126], [127, 139], [140, 148], [149, 150], [150, 153], [153, 154], [155, 157], [158, 167], [168, 179], [180, 188], [189, 190], [190, 193], [193, 194], [195, 205], [206, 208], [209, 210], [211, 224], [225, 229], [229, 230], [231, 239], [240, 242], [243, 253], [254, 259], [260, 261], [262, 263], [263, 265], [266, 268], [269, 272], [273, 280], [281, 288], [289, 291], [292, 295], [296, 303], [304, 313], [314, 319], [319, 320]]}
{"doc_key": "ai-train-50", "ner": [[0, 2, "algorithm"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 9, 10, "related-to", "good_at", true, false], [0, 2, 12, 13, "related-to", "good_at", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Artificial", "neural", "networks", "are", "computational", "models", "that", "excel", "in", "machine", "learning", "and", "pattern", "recognition", "."], "sentence-detokenized": "Artificial neural networks are computational models that excel in machine learning and pattern recognition.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 30], [31, 44], [45, 51], [52, 56], [57, 62], [63, 65], [66, 73], [74, 82], [83, 86], [87, 94], [95, 106], [106, 107]]}
{"doc_key": "ai-train-51", "ner": [[1, 2, "researcher"], [4, 5, "researcher"], [7, 11, "misc"], [13, 17, "conference"], [19, 19, "conference"], [36, 38, "algorithm"], [39, 40, "researcher"], [42, 44, "researcher"], [46, 52, "misc"], [54, 63, "conference"], [65, 65, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[7, 11, 1, 2, "artifact", "", false, false], [7, 11, 4, 5, "artifact", "", false, false], [7, 11, 13, 17, "temporal", "", false, false], [19, 19, 13, 17, "named", "", false, false], [46, 52, 36, 38, "topic", "", false, false], [46, 52, 39, 40, "artifact", "", false, false], [46, 52, 42, 44, "artifact", "", false, false], [46, 52, 54, 63, "temporal", "", false, false], [65, 65, 54, 63, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": [",", "C.", "Papageorgiou", "and", "T.", "Poggio", ",", "A", "Trainable", "Pedestrian", "Detection", "system", ",", "International", "Journal", "of", "Computer", "Vision", "(", "IJCV", ")", ",", "pages", "1", ":", "15", "-", "33", ",", "2000", "others", "use", "local", "features", "such", "as", "histogram", "oriented", "gradients", "N.", "Dalal", ",", "B", ".", "Triggs", ",", "Histograms", "of", "oriented", "gradients", "for", "human", "detection", ",", "IEEE", "Computer", "Society", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", ",", "pages", "1", ":", "886-893", ",", "2005", "descriptors", "."], "sentence-detokenized": ", C. Papageorgiou and T. Poggio, A Trainable Pedestrian Detection system, International Journal of Computer Vision (IJCV), pages 1: 15-33, 2000 others use local features such as histogram oriented gradients N. Dalal, B. Triggs, Histograms of oriented gradients for human detection, IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), pages 1: 886-893, 2005 descriptors.", "token2charspan": [[0, 1], [2, 4], [5, 17], [18, 21], [22, 24], [25, 31], [31, 32], [33, 34], [35, 44], [45, 55], [56, 65], [66, 72], [72, 73], [74, 87], [88, 95], [96, 98], [99, 107], [108, 114], [115, 116], [116, 120], [120, 121], [121, 122], [123, 128], [129, 130], [130, 131], [132, 134], [134, 135], [135, 137], [137, 138], [139, 143], [144, 150], [151, 154], [155, 160], [161, 169], [170, 174], [175, 177], [178, 187], [188, 196], [197, 206], [207, 209], [210, 215], [215, 216], [217, 218], [218, 219], [220, 226], [226, 227], [228, 238], [239, 241], [242, 250], [251, 260], [261, 264], [265, 270], [271, 280], [280, 281], [282, 286], [287, 295], [296, 303], [304, 314], [315, 317], [318, 326], [327, 333], [334, 337], [338, 345], [346, 357], [358, 359], [359, 363], [363, 364], [364, 365], [366, 371], [372, 373], [373, 374], [375, 382], [382, 383], [384, 388], [389, 400], [400, 401]]}
{"doc_key": "ai-train-52", "ner": [[0, 1, "algorithm"], [6, 9, "algorithm"], [14, 14, "task"], [15, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 6, 9, "type-of", "", false, false], [14, 14, 0, 1, "usage", "", true, false], [14, 14, 15, 19, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["An", "autoencoder", "is", "a", "type", "of", "artificial", "neural", "network", "that", "is", "used", "to", "learn", "functions", "in", "an", "unsupervised", "learning", "manner", "."], "sentence-detokenized": "An autoencoder is a type of artificial neural network that is used to learn functions in an unsupervised learning manner.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 19], [20, 24], [25, 27], [28, 38], [39, 45], [46, 53], [54, 58], [59, 61], [62, 66], [67, 69], [70, 75], [76, 85], [86, 88], [89, 91], [92, 104], [105, 113], [114, 120], [120, 121]]}
{"doc_key": "ai-train-53", "ner": [[0, 0, "researcher"], [5, 7, "organisation"], [11, 12, "field"], [14, 15, "field"], [21, 25, "organisation"], [27, 27, "organisation"], [33, 34, "field"], [36, 37, "field"], [43, 43, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 5, 7, "role", "fellow_of", false, false], [0, 0, 11, 12, "related-to", "contributes_to", false, false], [0, 0, 14, 15, "related-to", "contributes_to", false, false], [0, 0, 21, 25, "role", "fellow_of", false, false], [0, 0, 33, 34, "related-to", "contributes_to", false, false], [0, 0, 36, 37, "related-to", "contributes_to", false, false], [27, 27, 21, 25, "named", "", false, false], [43, 43, 21, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Haralick", "is", "a", "Fellow", "of", "the", "IEEE", "for", "his", "contributions", "in", "computer", "vision", "and", "image", "processing", "and", "a", "Fellow", "of", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", "for", "his", "contributions", "in", "pattern", "recognition", ",", "image", "processing", ",", "and", "for", "service", "to", "IAPR", "."], "sentence-detokenized": "Haralick is a Fellow of the IEEE for his contributions in computer vision and image processing and a Fellow of the International Association for Pattern Recognition (IAPR) for his contributions in pattern recognition, image processing, and for service to IAPR.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 20], [21, 23], [24, 27], [28, 32], [33, 36], [37, 40], [41, 54], [55, 57], [58, 66], [67, 73], [74, 77], [78, 83], [84, 94], [95, 98], [99, 100], [101, 107], [108, 110], [111, 114], [115, 128], [129, 140], [141, 144], [145, 152], [153, 164], [165, 166], [166, 170], [170, 171], [172, 175], [176, 179], [180, 193], [194, 196], [197, 204], [205, 216], [216, 217], [218, 223], [224, 234], [234, 235], [236, 239], [240, 243], [244, 251], [252, 254], [255, 259], [259, 260]]}
{"doc_key": "ai-train-54", "ner": [[4, 9, "task"], [11, 13, "algorithm"], [15, 18, "algorithm"], [24, 25, "researcher"], [27, 28, "organisation"], [30, 31, "researcher"], [34, 36, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 9, 11, 13, "usage", "", false, false], [11, 13, 24, 25, "origin", "", true, false], [11, 13, 30, 31, "origin", "", true, false], [15, 18, 11, 13, "named", "", false, false], [24, 25, 27, 28, "physical", "", false, false], [24, 25, 27, 28, "role", "", false, false], [30, 31, 34, 36, "physical", "", false, false], [30, 31, 34, 36, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "first", "attempt", "at", "end", "-", "to", "-", "end", "ASR", "was", "Connectionist", "Temporal", "Classification", "(", "CTC", ")", "based", "systems", ",", "introduced", "in", "2014", "by", "Alex", "Graves", "of", "Google", "DeepMind", "and", "Navdeep", "Jaitly", "of", "the", "University", "of", "Toronto", "."], "sentence-detokenized": "The first attempt at end-to-end ASR was Connectionist Temporal Classification (CTC) based systems, introduced in 2014 by Alex Graves of Google DeepMind and Navdeep Jaitly of the University of Toronto.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 20], [21, 24], [24, 25], [25, 27], [27, 28], [28, 31], [32, 35], [36, 39], [40, 53], [54, 62], [63, 77], [78, 79], [79, 82], [82, 83], [84, 89], [90, 97], [97, 98], [99, 109], [110, 112], [113, 117], [118, 120], [121, 125], [126, 132], [133, 135], [136, 142], [143, 151], [152, 155], [156, 163], [164, 170], [171, 173], [174, 177], [178, 188], [189, 191], [192, 199], [199, 200]]}
{"doc_key": "ai-train-55", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [10, 11, "algorithm"], [13, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 0, 2, "named", "", false, false], [10, 11, 0, 2, "type-of", "", false, false], [13, 13, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Linear-", "fractional", "programming", "(", "LFP", ")", "is", "a", "generalization", "of", "linear", "programming", "(", "LP", ")", "."], "sentence-detokenized": "Linear-fractional programming (LFP) is a generalization of linear programming (LP).", "token2charspan": [[0, 7], [7, 17], [18, 29], [30, 31], [31, 34], [34, 35], [36, 38], [39, 40], [41, 55], [56, 58], [59, 65], [66, 77], [78, 79], [79, 81], [81, 82], [82, 83]]}
{"doc_key": "ai-train-56", "ner": [[0, 0, "researcher"], [8, 13, "misc"], [16, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 13, "win-defeat", "", false, false], [8, 13, 16, 23, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lafferty", "has", "won", "numerous", "awards", ",", "including", "two", "Test", "-", "of", "-", "Time", "awards", "at", "the", "2011", "and", "2012", "International", "Conference", "on", "Machine", "Learning", ","], "sentence-detokenized": "Lafferty has won numerous awards, including two Test-of-Time awards at the 2011 and 2012 International Conference on Machine Learning,", "token2charspan": [[0, 8], [9, 12], [13, 16], [17, 25], [26, 32], [32, 33], [34, 43], [44, 47], [48, 52], [52, 53], [53, 55], [55, 56], [56, 60], [61, 67], [68, 70], [71, 74], [75, 79], [80, 83], [84, 88], [89, 102], [103, 113], [114, 116], [117, 124], [125, 133], [133, 134]]}
{"doc_key": "ai-train-57", "ner": [[10, 10, "product"], [12, 12, "programlang"], [25, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["With", "the", "advent", "of", "component", "-", "based", "frameworks", "such", "as", ".NET", "and", "Java", ",", "component", "-", "based", "development", "environments", "are", "able", "to", "deploy", "the", "developed", "neural", "network", "into", "these", "frameworks", "as", "inherited", "components", "."], "sentence-detokenized": "With the advent of component-based frameworks such as .NET and Java, component-based development environments are able to deploy the developed neural network into these frameworks as inherited components.", "token2charspan": [[0, 4], [5, 8], [9, 15], [16, 18], [19, 28], [28, 29], [29, 34], [35, 45], [46, 50], [51, 53], [54, 58], [59, 62], [63, 67], [67, 68], [69, 78], [78, 79], [79, 84], [85, 96], [97, 109], [110, 113], [114, 118], [119, 121], [122, 128], [129, 132], [133, 142], [143, 149], [150, 157], [158, 162], [163, 168], [169, 179], [180, 182], [183, 192], [193, 203], [203, 204]]}
{"doc_key": "ai-train-58", "ner": [[2, 2, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Similar", "to", "BLEU", ",", "the", "basic", "unit", "of", "evaluation", "is", "the", "sentence", ",", "the", "algorithm", "first", "creates", "an", "alignment", "(", "see", "illustrations", ")", "between", "two", "sentences", ",", "the", "candidate", "translation", "string", "and", "the", "reference", "translation", "string", "."], "sentence-detokenized": "Similar to BLEU, the basic unit of evaluation is the sentence, the algorithm first creates an alignment (see illustrations) between two sentences, the candidate translation string and the reference translation string.", "token2charspan": [[0, 7], [8, 10], [11, 15], [15, 16], [17, 20], [21, 26], [27, 31], [32, 34], [35, 45], [46, 48], [49, 52], [53, 61], [61, 62], [63, 66], [67, 76], [77, 82], [83, 90], [91, 93], [94, 103], [104, 105], [105, 108], [109, 122], [122, 123], [124, 131], [132, 135], [136, 145], [145, 146], [147, 150], [151, 160], [161, 172], [173, 179], [180, 183], [184, 187], [188, 197], [198, 209], [210, 216], [216, 217]]}
{"doc_key": "ai-train-59", "ner": [[7, 12, "conference"], [20, 20, "task"], [22, 24, "task"], [26, 36, "metrics"], [28, 34, "metrics"], [41, 44, "conference"], [46, 46, "conference"], [49, 49, "location"], [51, 51, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 12, 20, 20, "related-to", "subject_at", false, false], [7, 12, 22, 24, "related-to", "subject_at", false, false], [26, 36, 7, 12, "temporal", "", false, false], [28, 34, 26, 36, "named", "", true, false], [46, 46, 41, 44, "named", "", false, false], [49, 49, 51, 51, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["One", "of", "the", "metrics", "used", "at", "the", "annual", "NIST", "document", "understanding", "conferences", "where", "research", "groups", "present", "their", "systems", "for", "both", "summarization", "and", "translation", "tasks", "is", "the", "ROUGE", "(", "Recall", "-", "Oriented", "Understudy", "for", "Gisting", "Evaluation", ")", "metric", ",", "In", "Advances", "of", "Neural", "Information", "Processing", "Systems", "(", "NIPS", ")", ",", "Montreal", ",", "Canada", ",", "December", "-", "2014", "."], "sentence-detokenized": "One of the metrics used at the annual NIST document understanding conferences where research groups present their systems for both summarization and translation tasks is the ROUGE (Recall-Oriented Understudy for Gisting Evaluation) metric, In Advances of Neural Information Processing Systems (NIPS), Montreal, Canada, December - 2014.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 18], [19, 23], [24, 26], [27, 30], [31, 37], [38, 42], [43, 51], [52, 65], [66, 77], [78, 83], [84, 92], [93, 99], [100, 107], [108, 113], [114, 121], [122, 125], [126, 130], [131, 144], [145, 148], [149, 160], [161, 166], [167, 169], [170, 173], [174, 179], [180, 181], [181, 187], [187, 188], [188, 196], [197, 207], [208, 211], [212, 219], [220, 230], [230, 231], [232, 238], [238, 239], [240, 242], [243, 251], [252, 254], [255, 261], [262, 273], [274, 284], [285, 292], [293, 294], [294, 298], [298, 299], [299, 300], [301, 309], [309, 310], [311, 317], [317, 318], [319, 327], [328, 329], [330, 334], [334, 335]]}
{"doc_key": "ai-train-60", "ner": [[5, 5, "programlang"], [7, 7, "product"], [9, 10, "programlang"], [14, 14, "product"], [18, 20, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 5, 9, 10, "type-of", "", false, false], [5, 5, 18, 20, "named", "", false, false], [7, 7, 9, 10, "part-of", "", false, false], [7, 7, 14, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Same", "implementation", ",", "run", "in", "Java", "with", "JShell", "(", "Java", "9", "minimum", ")", ":", "codejshell", "scriptfile", "/", "codesyntaxhighlight", "lang", "=", "java"], "sentence-detokenized": "Same implementation, run in Java with JShell (Java 9 minimum): codejshell scriptfile/codesyntaxhighlight lang=java", "token2charspan": [[0, 4], [5, 19], [19, 20], [21, 24], [25, 27], [28, 32], [33, 37], [38, 44], [45, 46], [46, 50], [51, 52], [53, 60], [60, 61], [61, 62], [63, 73], [74, 84], [84, 85], [85, 104], [105, 109], [109, 110], [110, 114]]}
{"doc_key": "ai-train-61", "ner": [[0, 3, "metrics"], [7, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 7, 10, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "NIST", "metric", "is", "based", "on", "the", "BLEU", "metric", ",", "but", "with", "some", "changes", "."], "sentence-detokenized": "The NIST metric is based on the BLEU metric, but with some changes.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 18], [19, 24], [25, 27], [28, 31], [32, 36], [37, 43], [43, 44], [45, 48], [49, 53], [54, 58], [59, 66], [66, 67]]}
{"doc_key": "ai-train-62", "ner": [[6, 6, "country"], [10, 12, "university"], [15, 17, "university"], [24, 27, "product"], [29, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 12, 6, 6, "physical", "", false, false], [15, 17, 6, 6, "physical", "", false, false], [24, 27, 10, 12, "origin", "", false, false], [24, 27, 15, 17, "origin", "", false, false], [24, 27, 29, 32, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "late", "1980s", ",", "two", "Dutch", "universities", ",", "the", "University", "of", "Groningen", "and", "the", "University", "of", "Twente", ",", "jointly", "started", "a", "project", "called", "Knowledge", "Graphs", ",", "which", "are", "semantic", "networks", ",", "but", "with", "the", "additional", "restriction", "that", "edges", "are", "restricted", "to", "a", "limited", "set", "of", "possible", "relations", "in", "order", "to", "facilitate", "algebras", "on", "the", "graph", "."], "sentence-detokenized": "In the late 1980s, two Dutch universities, the University of Groningen and the University of Twente, jointly started a project called Knowledge Graphs, which are semantic networks, but with the additional restriction that edges are restricted to a limited set of possible relations in order to facilitate algebras on the graph.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 17], [17, 18], [19, 22], [23, 28], [29, 41], [41, 42], [43, 46], [47, 57], [58, 60], [61, 70], [71, 74], [75, 78], [79, 89], [90, 92], [93, 99], [99, 100], [101, 108], [109, 116], [117, 118], [119, 126], [127, 133], [134, 143], [144, 150], [150, 151], [152, 157], [158, 161], [162, 170], [171, 179], [179, 180], [181, 184], [185, 189], [190, 193], [194, 204], [205, 216], [217, 221], [222, 227], [228, 231], [232, 242], [243, 245], [246, 247], [248, 255], [256, 259], [260, 262], [263, 271], [272, 281], [282, 284], [285, 290], [291, 293], [294, 304], [305, 313], [314, 316], [317, 320], [321, 326], [326, 327]]}
{"doc_key": "ai-train-63", "ner": [[0, 1, "product"], [17, 21, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 17, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Grammar", "checking", "is", "most", "often", "implemented", "as", "a", "feature", "of", "a", "larger", "program", ",", "such", "as", "a", "word", "processor", ",", "but", "it", "is", "also", "available", "as", "a", "standalone", "application", "that", "can", "be", "activated", "within", "programs", "that", "work", "with", "editable", "text", "."], "sentence-detokenized": "Grammar checking is most often implemented as a feature of a larger program, such as a word processor, but it is also available as a standalone application that can be activated within programs that work with editable text.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 24], [25, 30], [31, 42], [43, 45], [46, 47], [48, 55], [56, 58], [59, 60], [61, 67], [68, 75], [75, 76], [77, 81], [82, 84], [85, 86], [87, 91], [92, 101], [101, 102], [103, 106], [107, 109], [110, 112], [113, 117], [118, 127], [128, 130], [131, 132], [133, 143], [144, 155], [156, 160], [161, 164], [165, 167], [168, 177], [178, 184], [185, 193], [194, 198], [199, 203], [204, 208], [209, 217], [218, 222], [222, 223]]}
{"doc_key": "ai-train-64", "ner": [[6, 12, "organisation"], [15, 21, "conference"], [25, 27, "organisation"], [33, 35, "conference"], [37, 39, "conference"], [42, 44, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ",", "and", "the", "Cognitive", "Science", "Society", ",", "and", "an", "editor", "of", "J.", "Automated", "Reasoning", ",", "J.", "Learning", "Sciences", ",", "and", "J.", "Applied", "Ontology", "."], "sentence-detokenized": "He is a member of the American Association for the Advancement of Science, the Association for the Advancement of Artificial Intelligence, and the Cognitive Science Society, and an editor of J. Automated Reasoning, J. Learning Sciences, and J. Applied Ontology.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 42], [43, 46], [47, 50], [51, 62], [63, 65], [66, 73], [73, 74], [75, 78], [79, 90], [91, 94], [95, 98], [99, 110], [111, 113], [114, 124], [125, 137], [137, 138], [139, 142], [143, 146], [147, 156], [157, 164], [165, 172], [172, 173], [174, 177], [178, 180], [181, 187], [188, 190], [191, 193], [194, 203], [204, 213], [213, 214], [215, 217], [218, 226], [227, 235], [235, 236], [237, 240], [241, 243], [244, 251], [252, 260], [260, 261]]}
{"doc_key": "ai-train-65", "ner": [[0, 2, "algorithm"], [4, 7, "algorithm"], [10, 14, "task"], [23, 24, "researcher"], [26, 27, "university"], [29, 30, "researcher"], [32, 35, "organisation"], [37, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 10, 14, "type-of", "", false, false], [0, 2, 23, 24, "origin", "", false, false], [0, 2, 29, 30, "origin", "", false, false], [4, 7, 0, 2, "named", "", false, false], [23, 24, 26, 27, "physical", "", false, false], [23, 24, 26, 27, "role", "", false, false], [29, 30, 32, 35, "role", "", false, false], [37, 37, 32, 35, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Linear", "Predictive", "Coding", "(", "LPC", ")", ",", "a", "form", "of", "speech", "coding", ",", "began", "to", "be", "developed", "in", "1966", "by", "the", "work", "of", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "."], "sentence-detokenized": "Linear Predictive Coding (LPC), a form of speech coding, began to be developed in 1966 by the work of Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT).", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [30, 31], [32, 33], [34, 38], [39, 41], [42, 48], [49, 55], [55, 56], [57, 62], [63, 65], [66, 68], [69, 78], [79, 81], [82, 86], [87, 89], [90, 93], [94, 98], [99, 101], [102, 110], [111, 118], [119, 121], [122, 128], [129, 139], [140, 143], [144, 149], [150, 155], [156, 158], [159, 165], [166, 175], [176, 179], [180, 189], [190, 191], [191, 194], [194, 195], [195, 196]]}
{"doc_key": "ai-train-66", "ner": [[54, 57, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Further", ",", "if", "the", "signal", "is", "ergodic", ",", "all", "sample", "paths", "exhibit", "the", "same", "time", "average", ",", "and", "hence", "mathR", "_", "x", "^{", "n/T", "_", "0", "}", "(", "\\", "tau", ")", "=\\", "widehat", "{", "R", "}", "_", "x", "^", "{", "n", "/", "T", "_", "0", "}", "(", "\\", "tau", ")", "/", "math", "in", "the", "mean", "square", "error", "sense", "."], "sentence-detokenized": "Further, if the signal is ergodic, all sample paths exhibit the same time average, and hence mathR _ x^{n/T _ 0} (\\ tau) =\\ widehat {R} _ x ^ {n / T _ 0} (\\ tau) / math in the mean square error sense.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 15], [16, 22], [23, 25], [26, 33], [33, 34], [35, 38], [39, 45], [46, 51], [52, 59], [60, 63], [64, 68], [69, 73], [74, 81], [81, 82], [83, 86], [87, 92], [93, 98], [99, 100], [101, 102], [102, 104], [104, 107], [108, 109], [110, 111], [111, 112], [113, 114], [114, 115], [116, 119], [119, 120], [121, 123], [124, 131], [132, 133], [133, 134], [134, 135], [136, 137], [138, 139], [140, 141], [142, 143], [143, 144], [145, 146], [147, 148], [149, 150], [151, 152], [152, 153], [154, 155], [155, 156], [157, 160], [160, 161], [162, 163], [164, 168], [169, 171], [172, 175], [176, 180], [181, 187], [188, 193], [194, 199], [199, 200]]}
{"doc_key": "ai-train-67", "ner": [[0, 1, "task"], [3, 4, "task"], [13, 15, "algorithm"], [17, 17, "algorithm"], [20, 22, "algorithm"], [24, 24, "algorithm"], [27, 29, "algorithm"], [31, 31, "algorithm"], [35, 37, "algorithm"], [39, 39, "algorithm"], [44, 48, "misc"], [49, 51, "algorithm"], [54, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[13, 15, 44, 48, "related-to", "", false, false], [17, 17, 13, 15, "named", "", false, false], [20, 22, 44, 48, "related-to", "", false, false], [24, 24, 20, 22, "named", "", false, false], [27, 29, 44, 48, "related-to", "", false, false], [31, 31, 27, 29, "named", "", false, false], [35, 37, 44, 48, "related-to", "", false, false], [39, 39, 35, 37, "named", "", false, false], [49, 51, 54, 55, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Feature", "extraction", "and", "dimension", "reduction", "can", "be", "combined", "into", "a", "single", "step", "using", "principal", "component", "analysis", "(", "PCA", ")", ",", "linear", "discriminant", "analysis", "(", "LDA", ")", ",", "canonical", "correlation", "analysis", "(", "CCA", ")", ",", "or", "nonnegative", "matrix", "factorization", "(", "NMF", ")", "techniques", "as", "a", "preprocessing", "step", ",", "followed", "by", "K", "-", "NN", "clustering", "on", "feature", "vectors", "in", "the", "space", "of", "reduced", "dimensions", "."], "sentence-detokenized": "Feature extraction and dimension reduction can be combined into a single step using principal component analysis (PCA), linear discriminant analysis (LDA), canonical correlation analysis (CCA), or nonnegative matrix factorization (NMF) techniques as a preprocessing step, followed by K-NN clustering on feature vectors in the space of reduced dimensions.", "token2charspan": [[0, 7], [8, 18], [19, 22], [23, 32], [33, 42], [43, 46], [47, 49], [50, 58], [59, 63], [64, 65], [66, 72], [73, 77], [78, 83], [84, 93], [94, 103], [104, 112], [113, 114], [114, 117], [117, 118], [118, 119], [120, 126], [127, 139], [140, 148], [149, 150], [150, 153], [153, 154], [154, 155], [156, 165], [166, 177], [178, 186], [187, 188], [188, 191], [191, 192], [192, 193], [194, 196], [197, 208], [209, 215], [216, 229], [230, 231], [231, 234], [234, 235], [236, 246], [247, 249], [250, 251], [252, 265], [266, 270], [270, 271], [272, 280], [281, 283], [284, 285], [285, 286], [286, 288], [289, 299], [300, 302], [303, 310], [311, 318], [319, 321], [322, 325], [326, 331], [332, 334], [335, 342], [343, 353], [353, 354]]}
{"doc_key": "ai-train-68", "ner": [[3, 3, "programlang"], [5, 5, "programlang"], [7, 7, "programlang"], [9, 9, "programlang"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 15, 3, 3, "related-to", "program_type_compatible_with", false, false], [15, 15, 5, 5, "related-to", "program_type_compatible_with", false, false], [15, 15, 7, 7, "related-to", "program_type_compatible_with", false, false], [15, 15, 9, 9, "related-to", "program_type_compatible_with", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Libraries", "written", "in", "Perl", ",", "Java", ",", "ActiveX", "or", ".NET", "can", "be", "called", "directly", "from", "MATLAB", ","], "sentence-detokenized": "Libraries written in Perl, Java, ActiveX or .NET can be called directly from MATLAB,", "token2charspan": [[0, 9], [10, 17], [18, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 40], [41, 43], [44, 48], [49, 52], [53, 55], [56, 62], [63, 71], [72, 76], [77, 83], [83, 84]]}
{"doc_key": "ai-train-69", "ner": [[3, 8, "task"], [11, 15, "task"], [31, 32, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 8, 11, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "task", "of", "recognizing", "named", "entities", "in", "a", "text", "is", "called", "named", "entity", "recognition", ",", "while", "the", "task", "of", "determining", "the", "identity", "of", "named", "entities", "mentioned", "in", "the", "text", "is", "called", "entity", "matching", "."], "sentence-detokenized": "The task of recognizing named entities in a text is called named entity recognition, while the task of determining the identity of named entities mentioned in the text is called entity matching.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 23], [24, 29], [30, 38], [39, 41], [42, 43], [44, 48], [49, 51], [52, 58], [59, 64], [65, 71], [72, 83], [83, 84], [85, 90], [91, 94], [95, 99], [100, 102], [103, 114], [115, 118], [119, 127], [128, 130], [131, 136], [137, 145], [146, 155], [156, 158], [159, 162], [163, 167], [168, 170], [171, 177], [178, 184], [185, 193], [193, 194]]}
{"doc_key": "ai-train-70", "ner": [[0, 1, "algorithm"], [29, 29, "programlang"], [27, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 27, 27, "part-of", "", true, false], [27, 27, 29, 29, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "sigmoid", "functions", "and", "derivations", "used", "in", "the", "package", "were", "originally", "part", "of", "the", "package", ",", "but", "since", "version", "0.8.0", "they", "have", "been", "released", "in", "a", "separate", "sigmoid", "package", "to", "allow", "more", "general", "use", "."], "sentence-detokenized": "The sigmoid functions and derivations used in the package were originally part of the package, but since version 0.8.0 they have been released in a separate sigmoid package to allow more general use.", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 25], [26, 37], [38, 42], [43, 45], [46, 49], [50, 57], [58, 62], [63, 73], [74, 78], [79, 81], [82, 85], [86, 93], [93, 94], [95, 98], [99, 104], [105, 112], [113, 118], [119, 123], [124, 128], [129, 133], [134, 142], [143, 145], [146, 147], [148, 156], [157, 164], [165, 172], [173, 175], [176, 181], [182, 186], [187, 194], [195, 198], [198, 199]]}
{"doc_key": "ai-train-71", "ner": [[0, 1, "programlang"], [19, 23, "organisation"], [25, 25, "organisation"], [28, 28, "location"], [30, 30, "location"], [7, 8, "researcher"], [10, 11, "researcher"], [13, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 7, 8, "artifact", "", true, false], [0, 1, 10, 11, "artifact", "", true, false], [0, 1, 13, 16, "artifact", "", true, false], [25, 25, 19, 23, "named", "", false, false], [25, 25, 28, 28, "physical", "", false, false], [28, 28, 30, 30, "physical", "", false, false], [7, 8, 19, 23, "role", "", false, false], [10, 11, 19, 23, "role", "", false, false], [13, 16, 19, 23, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "logo", "was", "created", "in", "1967", "by", "Wally", "Feurzeig", ",", "Cynthia", "Solomon", "and", "Seymour", "Papert", "at", "the", "research", "firm", "Bolt", ",", "Beranek", "and", "Newman", "(", "BBN", ")", "in", "Cambridge", ",", "Massachusetts", "."], "sentence-detokenized": "The logo was created in 1967 by Wally Feurzeig, Cynthia Solomon and Seymour Papert at the research firm Bolt, Beranek and Newman (BBN) in Cambridge, Massachusetts.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 20], [21, 23], [24, 28], [29, 31], [32, 37], [38, 46], [46, 47], [48, 55], [56, 63], [64, 67], [68, 75], [76, 82], [83, 85], [86, 89], [90, 98], [99, 103], [104, 108], [108, 109], [110, 117], [118, 121], [122, 128], [129, 130], [130, 133], [133, 134], [135, 137], [138, 147], [147, 148], [149, 162], [162, 163]]}
{"doc_key": "ai-train-72", "ner": [[0, 0, "misc"], [8, 9, "field"], [17, 18, "field"], [22, 23, "algorithm"], [26, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 9, "part-of", "", false, false], [0, 0, 17, 18, "compare", "", false, false], [22, 23, 17, 18, "part-of", "", false, false], [26, 28, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Neuroevolution", "is", "commonly", "used", "as", "part", "of", "the", "reinforcement", "learning", "paradigm", "and", "can", "be", "compared", "to", "conventional", "deep", "learning", "techniques", "that", "use", "gradient", "descent", "on", "a", "neural", "network", "with", "a", "fixed", "topology", "."], "sentence-detokenized": "Neuroevolution is commonly used as part of the reinforcement learning paradigm and can be compared to conventional deep learning techniques that use gradient descent on a neural network with a fixed topology.", "token2charspan": [[0, 14], [15, 17], [18, 26], [27, 31], [32, 34], [35, 39], [40, 42], [43, 46], [47, 60], [61, 69], [70, 78], [79, 82], [83, 86], [87, 89], [90, 98], [99, 101], [102, 114], [115, 119], [120, 128], [129, 139], [140, 144], [145, 148], [149, 157], [158, 165], [166, 168], [169, 170], [171, 177], [178, 185], [186, 190], [191, 192], [193, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-train-73", "ner": [[4, 5, "algorithm"], [56, 58, "metrics"], [60, 60, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[60, 60, 56, 58, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["If", "we", "use", "the", "least", "squares", "method", "to", "fit", "a", "hyperplane", "-", "shaped", "function", "\u0177", "=", "a", "+", "\u03b2", "supT", "/", "sup", "x", "to", "the", "data", "(", "x", "sub", "i", "/", "sub", ",", "y", "sub", "i", "/", "sub", ")", "sub", "1", "\u2264", "i", "\u2264", "n", "/", "sub", ",", "we", "could", "then", "evaluate", "the", "fit", "using", "the", "mean", "squared", "error", "(", "MSE", ")", "."], "sentence-detokenized": "If we use the least squares method to fit a hyperplane-shaped function \u0177 = a + \u03b2 supT / sup x to the data (x sub i / sub, y sub i / sub) sub 1 \u2264 i \u2264 n / sub, we could then evaluate the fit using the mean squared error (MSE).", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 13], [14, 19], [20, 27], [28, 34], [35, 37], [38, 41], [42, 43], [44, 54], [54, 55], [55, 61], [62, 70], [71, 72], [73, 74], [75, 76], [77, 78], [79, 80], [81, 85], [86, 87], [88, 91], [92, 93], [94, 96], [97, 100], [101, 105], [106, 107], [107, 108], [109, 112], [113, 114], [115, 116], [117, 120], [120, 121], [122, 123], [124, 127], [128, 129], [130, 131], [132, 135], [135, 136], [137, 140], [141, 142], [143, 144], [145, 146], [147, 148], [149, 150], [151, 152], [153, 156], [156, 157], [158, 160], [161, 166], [167, 171], [172, 180], [181, 184], [185, 188], [189, 194], [195, 198], [199, 203], [204, 211], [212, 217], [218, 219], [219, 222], [222, 223], [223, 224]]}
{"doc_key": "ai-train-74", "ner": [[6, 6, "country"], [8, 8, "country"], [10, 10, "country"], [12, 12, "country"], [14, 14, "country"], [16, 16, "country"], [18, 18, "country"], [20, 20, "country"], [22, 22, "country"], [24, 24, "country"], [26, 26, "country"], [28, 28, "country"], [30, 30, "country"], [32, 32, "country"], [34, 34, "country"], [36, 37, "country"], [39, 39, "country"], [41, 41, "country"], [43, 43, "country"], [45, 45, "country"], [47, 49, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "company", "has", "international", "offices", "in", "Australia", ",", "Brazil", ",", "Canada", ",", "China", ",", "Germany", ",", "India", ",", "Italy", ",", "Japan", ",", "Korea", ",", "Lithuania", ",", "Poland", ",", "Malaysia", ",", "Philippines", ",", "Russia", ",", "Singapore", ",", "South", "Africa", ",", "Spain", ",", "Taiwan", ",", "Thailand", ",", "Turkey", "and", "the", "United", "Kingdom", "."], "sentence-detokenized": "The company has international offices in Australia, Brazil, Canada, China, Germany, India, Italy, Japan, Korea, Lithuania, Poland, Malaysia, Philippines, Russia, Singapore, South Africa, Spain, Taiwan, Thailand, Turkey and the United Kingdom.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 29], [30, 37], [38, 40], [41, 50], [50, 51], [52, 58], [58, 59], [60, 66], [66, 67], [68, 73], [73, 74], [75, 82], [82, 83], [84, 89], [89, 90], [91, 96], [96, 97], [98, 103], [103, 104], [105, 110], [110, 111], [112, 121], [121, 122], [123, 129], [129, 130], [131, 139], [139, 140], [141, 152], [152, 153], [154, 160], [160, 161], [162, 171], [171, 172], [173, 178], [179, 185], [185, 186], [187, 192], [192, 193], [194, 200], [200, 201], [202, 210], [210, 211], [212, 218], [219, 222], [223, 226], [227, 233], [234, 241], [241, 242]]}
{"doc_key": "ai-train-75", "ner": [[3, 3, "misc"], [5, 9, "field"], [17, 17, "organisation"], [14, 24, "university"], [28, 30, "organisation"], [32, 39, "university"], [43, 44, "university"], [46, 47, "university"], [51, 53, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 3, 5, 9, "topic", "", false, false], [3, 3, 17, 17, "origin", "", false, false], [3, 3, 14, 24, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "received", "his", "PhD", "in", "Electrical", "Engineering", "and", "Computer", "Science", "(", "2000", ")", "from", "the", "Universities", "of", "Inria", "and", "Nice", "Sophia", "Antipolis", "and", "has", "held", "permanent", "positions", "at", "Siemens", "Corporate", "Technology", ",", "\u00c9cole", "des", "ponts", "ParisTech", ",", "as", "well", "as", "visiting", "positions", "at", "Rutgers", "University", ",", "Yale", "University", ",", "and", "the", "University", "of", "Houston", "."], "sentence-detokenized": "He received his PhD in Electrical Engineering and Computer Science (2000) from the Universities of Inria and Nice Sophia Antipolis and has held permanent positions at Siemens Corporate Technology, \u00c9cole des ponts ParisTech, as well as visiting positions at Rutgers University, Yale University, and the University of Houston.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 19], [20, 22], [23, 33], [34, 45], [46, 49], [50, 58], [59, 66], [67, 68], [68, 72], [72, 73], [74, 78], [79, 82], [83, 95], [96, 98], [99, 104], [105, 108], [109, 113], [114, 120], [121, 130], [131, 134], [135, 138], [139, 143], [144, 153], [154, 163], [164, 166], [167, 174], [175, 184], [185, 195], [195, 196], [197, 202], [203, 206], [207, 212], [213, 222], [222, 223], [224, 226], [227, 231], [232, 234], [235, 243], [244, 253], [254, 256], [257, 264], [265, 275], [275, 276], [277, 281], [282, 292], [292, 293], [294, 297], [298, 301], [302, 312], [313, 315], [316, 323], [323, 324]]}
{"doc_key": "ai-train-76", "ner": [[8, 9, "researcher"], [11, 25, "researcher"], [15, 16, "product"], [19, 20, "country"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 25, 8, 9, "role", "licensing_patent_to", false, false], [11, 25, 19, 20, "physical", "", false, false], [22, 22, 11, 25, "artifact", "", false, false], [22, 22, 15, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Based", "on", "the", "original", "patent", "granted", "to", "inventor", "George", "Devol", ",", "Engelberger", "developed", "the", "first", "industrial", "robot", "in", "the", "United", "States", ",", "Unimate", ",", "in", "the", "1950s", "."], "sentence-detokenized": "Based on the original patent granted to inventor George Devol, Engelberger developed the first industrial robot in the United States, Unimate, in the 1950s.", "token2charspan": [[0, 5], [6, 8], [9, 12], [13, 21], [22, 28], [29, 36], [37, 39], [40, 48], [49, 55], [56, 61], [61, 62], [63, 74], [75, 84], [85, 88], [89, 94], [95, 105], [106, 111], [112, 114], [115, 118], [119, 125], [126, 132], [132, 133], [134, 141], [141, 142], [143, 145], [146, 149], [150, 155], [155, 156]]}
{"doc_key": "ai-train-77", "ner": [[4, 5, "task"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "input", "is", "called", "speech", "recognition", "and", "the", "output", "is", "called", "speech", "synthesis", "."], "sentence-detokenized": "The input is called speech recognition and the output is called speech synthesis.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 26], [27, 38], [39, 42], [43, 46], [47, 53], [54, 56], [57, 63], [64, 70], [71, 80], [80, 81]]}
{"doc_key": "ai-train-78", "ner": [[0, 0, "programlang"], [3, 3, "programlang"], [11, 11, "programlang"], [14, 18, "programlang"], [24, 24, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 11, 11, "named", "", false, false], [3, 3, 0, 0, "origin", "descendant_of", false, false], [3, 3, 14, 18, "general-affiliation", "", false, false], [3, 3, 24, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["CLIPS", "descendants", "include", "Jess", "(", "a", "rule", "-", "based", "part", "of", "CLIPS", "rewritten", "in", "Java", ",", "later", "expanded", "in", "a", "different", "direction", ")", ",", "JESS", "was", "originally", "inspired", "by"], "sentence-detokenized": "CLIPS descendants include Jess (a rule-based part of CLIPS rewritten in Java, later expanded in a different direction), JESS was originally inspired by", "token2charspan": [[0, 5], [6, 17], [18, 25], [26, 30], [31, 32], [32, 33], [34, 38], [38, 39], [39, 44], [45, 49], [50, 52], [53, 58], [59, 68], [69, 71], [72, 76], [76, 77], [78, 83], [84, 92], [93, 95], [96, 97], [98, 107], [108, 117], [117, 118], [118, 119], [120, 124], [125, 128], [129, 139], [140, 148], [149, 151]]}
{"doc_key": "ai-train-79", "ner": [[6, 9, "product"], [11, 15, "product"], [16, 17, "organisation"], [21, 22, "product"], [42, 43, "product"], [45, 48, "product"], [62, 63, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 15, 6, 9, "type-of", "", false, false], [16, 17, 11, 15, "usage", "", false, false], [21, 22, 16, 17, "artifact", "", false, false], [42, 43, 16, 17, "origin", "", true, false], [42, 43, 62, 63, "related-to", "", true, false], [45, 48, 16, 17, "origin", "", true, false], [45, 48, 62, 63, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["She", "has", "also", "created", "flexible", "intelligent", "AGV", "applications", ",", "designing", "the", "Motivity", "control", "system", "used", "by", "RMT", "Robotics", "to", "develop", "its", "ADAM", "iAGV", "(", "Self", "-", "Guided", "Vehicle", ")", ",", "which", "is", "used", "for", "complex", "pick", "and", "place", "operations", "in", "conjunction", "with", "gantry", "systems", "and", "industrial", "robot", "arms", "used", "in", "primary", "automotive", "delivery", "plants", "to", "move", "products", "from", "process", "to", "process", "in", "non-linear", "configurations", "."], "sentence-detokenized": "She has also created flexible intelligent AGV applications, designing the Motivity control system used by RMT Robotics to develop its ADAM iAGV (Self-Guided Vehicle), which is used for complex pick and place operations in conjunction with gantry systems and industrial robot arms used in primary automotive delivery plants to move products from process to process in non-linear configurations.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 20], [21, 29], [30, 41], [42, 45], [46, 58], [58, 59], [60, 69], [70, 73], [74, 82], [83, 90], [91, 97], [98, 102], [103, 105], [106, 109], [110, 118], [119, 121], [122, 129], [130, 133], [134, 138], [139, 143], [144, 145], [145, 149], [149, 150], [150, 156], [157, 164], [164, 165], [165, 166], [167, 172], [173, 175], [176, 180], [181, 184], [185, 192], [193, 197], [198, 201], [202, 207], [208, 218], [219, 221], [222, 233], [234, 238], [239, 245], [246, 253], [254, 257], [258, 268], [269, 274], [275, 279], [280, 284], [285, 287], [288, 295], [296, 306], [307, 315], [316, 322], [323, 325], [326, 330], [331, 339], [340, 344], [345, 352], [353, 355], [356, 363], [364, 366], [367, 377], [378, 392], [392, 393]]}
{"doc_key": "ai-train-80", "ner": [[8, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "\u03b2", "parameters", "are", "usually", "estimated", "by", "the", "maximum", "likelihood", "method", "."], "sentence-detokenized": "The \u03b2 parameters are usually estimated by the maximum likelihood method.", "token2charspan": [[0, 3], [4, 5], [6, 16], [17, 20], [21, 28], [29, 38], [39, 41], [42, 45], [46, 53], [54, 64], [65, 71], [71, 72]]}
{"doc_key": "ai-train-81", "ner": [[0, 1, "task"], [5, 5, "metrics"], [7, 7, "metrics"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 0, 1, "part-of", "", false, false], [7, 7, 0, 1, "part-of", "", false, false], [10, 10, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Information", "retrieval", "metrics", "such", "as", "precision", "and", "recall", ",", "or", "DCG", ",", "are", "useful", "for", "assessing", "the", "quality", "of", "a", "recommendation", "method", "."], "sentence-detokenized": "Information retrieval metrics such as precision and recall, or DCG, are useful for assessing the quality of a recommendation method.", "token2charspan": [[0, 11], [12, 21], [22, 29], [30, 34], [35, 37], [38, 47], [48, 51], [52, 58], [58, 59], [60, 62], [63, 66], [66, 67], [68, 71], [72, 78], [79, 82], [83, 92], [93, 96], [97, 104], [105, 107], [108, 109], [110, 124], [125, 131], [131, 132]]}
{"doc_key": "ai-train-82", "ner": [[6, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "typical", "factory", "contains", "hundreds", "of", "industrial", "robots", "working", "on", "fully", "automated", "production", "lines", ",", "with", "one", "robot", "for", "every", "ten", "human", "workers", "."], "sentence-detokenized": "A typical factory contains hundreds of industrial robots working on fully automated production lines, with one robot for every ten human workers.", "token2charspan": [[0, 1], [2, 9], [10, 17], [18, 26], [27, 35], [36, 38], [39, 49], [50, 56], [57, 64], [65, 67], [68, 73], [74, 83], [84, 94], [95, 100], [100, 101], [102, 106], [107, 110], [111, 116], [117, 120], [121, 126], [127, 130], [131, 136], [137, 144], [144, 145]]}
{"doc_key": "ai-train-83", "ner": [[5, 5, "product"], [13, 14, "field"], [18, 19, "task"], [21, 22, "task"], [24, 25, "task"], [27, 28, "task"], [30, 31, "task"], [34, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[13, 14, 5, 5, "usage", "", false, true], [18, 19, 13, 14, "part-of", "", false, false], [21, 22, 13, 14, "part-of", "", false, false], [24, 25, 13, 14, "part-of", "", false, false], [27, 28, 13, 14, "part-of", "", false, false], [30, 31, 13, 14, "part-of", "", false, false], [34, 35, 13, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "the", "past", "decade", ",", "PCNNs", "have", "been", "used", "in", "a", "variety", "of", "image", "processing", "applications", "including", ":", "image", "segmentation", ",", "feature", "generation", ",", "face", "extraction", ",", "motion", "detection", ",", "region", "magnification", ",", "and", "noise", "reduction", "."], "sentence-detokenized": "In the past decade, PCNNs have been used in a variety of image processing applications including: image segmentation, feature generation, face extraction, motion detection, region magnification, and noise reduction.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [18, 19], [20, 25], [26, 30], [31, 35], [36, 40], [41, 43], [44, 45], [46, 53], [54, 56], [57, 62], [63, 73], [74, 86], [87, 96], [96, 97], [98, 103], [104, 116], [116, 117], [118, 125], [126, 136], [136, 137], [138, 142], [143, 153], [153, 154], [155, 161], [162, 171], [171, 172], [173, 179], [180, 193], [193, 194], [195, 198], [199, 204], [205, 214], [214, 215]]}
{"doc_key": "ai-train-84", "ner": [[0, 2, "researcher"], [15, 17, "field"], [22, 24, "misc"], [28, 34, "conference"], [36, 36, "conference"], [40, 42, "misc"], [46, 50, "conference"], [45, 51, "conference"], [55, 59, "conference"], [61, 61, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 2, 15, 17, "related-to", "contributes_to", false, false], [0, 2, 22, 24, "win-defeat", "", false, false], [0, 2, 40, 42, "win-defeat", "", false, false], [22, 24, 28, 34, "temporal", "", false, false], [36, 36, 28, 34, "named", "", false, false], [40, 42, 46, 50, "temporal", "", false, false], [40, 42, 55, 59, "temporal", "", false, false], [45, 51, 46, 50, "named", "", false, false], [61, 61, 55, 59, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Xu", "has", "published", "more", "than", "50", "papers", "in", "international", "conferences", "and", "journals", "in", "the", "field", "of", "computer", "vision", ",", "and", "won", "the", "best", "paper", "award", "at", "the", "2012", "International", "Conference", "on", "Non-Photorealistic", "Rendering", "and", "Animation", "(", "NPAR", ")", "and", "the", "best", "reviewer", "award", "at", "the", "2012", "Asian", "Conference", "on", "Computer", "Vision", "ACCV", "and", "the", "2015", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "."], "sentence-detokenized": "Xu has published more than 50 papers in international conferences and journals in the field of computer vision, and won the best paper award at the 2012 International Conference on Non-Photorealistic Rendering and Animation (NPAR) and the best reviewer award at the 2012 Asian Conference on Computer Vision ACCV and the 2015 International Conference on Computer Vision (ICCV).", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 21], [22, 26], [27, 29], [30, 36], [37, 39], [40, 53], [54, 65], [66, 69], [70, 78], [79, 81], [82, 85], [86, 91], [92, 94], [95, 103], [104, 110], [110, 111], [112, 115], [116, 119], [120, 123], [124, 128], [129, 134], [135, 140], [141, 143], [144, 147], [148, 152], [153, 166], [167, 177], [178, 180], [181, 199], [200, 209], [210, 213], [214, 223], [224, 225], [225, 229], [229, 230], [231, 234], [235, 238], [239, 243], [244, 252], [253, 258], [259, 261], [262, 265], [266, 270], [271, 276], [277, 287], [288, 290], [291, 299], [300, 306], [307, 311], [312, 315], [316, 319], [320, 324], [325, 338], [339, 349], [350, 352], [353, 361], [362, 368], [369, 370], [370, 374], [374, 375], [375, 376]]}
{"doc_key": "ai-train-85", "ner": [[0, 0, "programlang"], [2, 3, "field"], [5, 6, "field"], [9, 10, "misc"], [13, 15, "researcher"], [16, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 2, 3, "part-of", "", false, false], [0, 0, 5, 6, "part-of", "", false, false], [0, 0, 9, 10, "type-of", "", false, false], [16, 18, 0, 0, "usage", "", false, false], [16, 18, 13, 15, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["CycL", "in", "Computer", "Science", "and", "Artificial", "Intelligence", "is", "the", "ontology", "language", "used", "in", "Doug", "Lenat", "'s", "Cyc", "artificial", "project", "."], "sentence-detokenized": "CycL in Computer Science and Artificial Intelligence is the ontology language used in Doug Lenat's Cyc artificial project.", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 24], [25, 28], [29, 39], [40, 52], [53, 55], [56, 59], [60, 68], [69, 77], [78, 82], [83, 85], [86, 90], [91, 96], [96, 98], [99, 102], [103, 113], [114, 121], [121, 122]]}
{"doc_key": "ai-train-86", "ner": [[2, 3, "task"], [6, 8, "metrics"], [15, 18, "metrics"], [21, 28, "metrics"], [37, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 8, 2, 3, "part-of", "", false, false], [15, 18, 6, 8, "named", "", false, false], [21, 28, 6, 8, "named", "", false, false], [37, 39, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Also", "in", "regression", "analysis", ",", "the", "mean", "squared", "error", ",", "often", "referred", "to", "as", "the", "mean", "squared", "prediction", "error", "or", "the", "out", "-", "of", "-", "sample", "mean", "squared", "error", ",", "can", "refer", "to", "the", "mean", "of", "the", "squared", "deviations", "of", "the", "predictions", "from", "the", "true", "values", "in", "the", "out", "-", "of", "-", "sample", "test", "space", "that", "are", "generated", "by", "the", "model", "estimated", "in", "a", "particular", "sample", "space", "."], "sentence-detokenized": "Also in regression analysis, the mean squared error, often referred to as the mean squared prediction error or the out-of-sample mean squared error, can refer to the mean of the squared deviations of the predictions from the true values in the out-of-sample test space that are generated by the model estimated in a particular sample space.", "token2charspan": [[0, 4], [5, 7], [8, 18], [19, 27], [27, 28], [29, 32], [33, 37], [38, 45], [46, 51], [51, 52], [53, 58], [59, 67], [68, 70], [71, 73], [74, 77], [78, 82], [83, 90], [91, 101], [102, 107], [108, 110], [111, 114], [115, 118], [118, 119], [119, 121], [121, 122], [122, 128], [129, 133], [134, 141], [142, 147], [147, 148], [149, 152], [153, 158], [159, 161], [162, 165], [166, 170], [171, 173], [174, 177], [178, 185], [186, 196], [197, 199], [200, 203], [204, 215], [216, 220], [221, 224], [225, 229], [230, 236], [237, 239], [240, 243], [244, 247], [247, 248], [248, 250], [250, 251], [251, 257], [258, 262], [263, 268], [269, 273], [274, 277], [278, 287], [288, 290], [291, 294], [295, 300], [301, 310], [311, 313], [314, 315], [316, 326], [327, 333], [334, 339], [339, 340]]}
{"doc_key": "ai-train-87", "ner": [[6, 8, "algorithm"], [10, 11, "algorithm"], [19, 22, "algorithm"], [35, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 8, 10, 11, "compare", "", false, false], [6, 8, 19, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "terms", "of", "results", ",", "the", "C", "-", "HOG", "and", "R-", "HOG", "block", "descriptors", "perform", "comparably", ",", "with", "the", "C", "-", "HOG", "descriptors", "retaining", "a", "slight", "advantage", "in", "the", "false", "detection", "rate", "at", "a", "fixed", "FALSE", "positive", "rate", "in", "both", "datasets", "."], "sentence-detokenized": "In terms of results, the C-HOG and R-HOG block descriptors perform comparably, with the C-HOG descriptors retaining a slight advantage in the false detection rate at a fixed FALSE positive rate in both datasets.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 19], [19, 20], [21, 24], [25, 26], [26, 27], [27, 30], [31, 34], [35, 37], [37, 40], [41, 46], [47, 58], [59, 66], [67, 77], [77, 78], [79, 83], [84, 87], [88, 89], [89, 90], [90, 93], [94, 105], [106, 115], [116, 117], [118, 124], [125, 134], [135, 137], [138, 141], [142, 147], [148, 157], [158, 162], [163, 165], [166, 167], [168, 173], [174, 179], [180, 188], [189, 193], [194, 196], [197, 201], [202, 210], [210, 211]]}
{"doc_key": "ai-train-88", "ner": [[4, 6, "algorithm"], [8, 8, "misc"], [10, 12, "algorithm"], [14, 15, "algorithm"], [18, 19, "algorithm"], [21, 23, "algorithm"], [25, 27, "algorithm"], [29, 30, "misc"], [36, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[4, 6, 8, 8, "usage", "", false, false], [10, 12, 29, 30, "usage", "", false, false], [14, 15, 29, 30, "usage", "", false, false], [18, 19, 29, 30, "usage", "", false, false], [21, 23, 29, 30, "usage", "", false, false], [25, 27, 29, 30, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Popular", "recognition", "algorithms", "include", "principal", "component", "analysis", "using", "eigenfaces", ",", "linear", "discriminant", "analysis", ",", "elastic", "matching", "using", "the", "Fisherface", "algorithm", ",", "hidden", "Markov", "model", ",", "multilinear", "subspace", "learning", "using", "tensor", "representation", ",", "and", "neural", "-", "motivated", "dynamic", "link", "matching", "."], "sentence-detokenized": "Popular recognition algorithms include principal component analysis using eigenfaces, linear discriminant analysis, elastic matching using the Fisherface algorithm, hidden Markov model, multilinear subspace learning using tensor representation, and neural-motivated dynamic link matching.", "token2charspan": [[0, 7], [8, 19], [20, 30], [31, 38], [39, 48], [49, 58], [59, 67], [68, 73], [74, 84], [84, 85], [86, 92], [93, 105], [106, 114], [114, 115], [116, 123], [124, 132], [133, 138], [139, 142], [143, 153], [154, 163], [163, 164], [165, 171], [172, 178], [179, 184], [184, 185], [186, 197], [198, 206], [207, 215], [216, 221], [222, 228], [229, 243], [243, 244], [245, 248], [249, 255], [255, 256], [256, 265], [266, 273], [274, 278], [279, 287], [287, 288]]}
{"doc_key": "ai-train-89", "ner": [[2, 7, "misc"], [12, 18, "location"], [40, 42, "location"], [57, 57, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 18, 2, 7, "temporal", "", false, false], [40, 42, 2, 7, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Starting", "with", "the", "2019", "Toronto", "International", "Film", "Festival", ",", "screenings", "at", "the", "Scotiabank", "Theatre", "Toronto", "-", "one", "of", "the", "festival", "'s", "main", "venues", "-", "may", "be", "limited", ",", "and", "films", "will", "be", "allowed", "to", "screen", "elsewhere", "(", "such", "as", "the", "TIFF", "Bell", "Lightbox", "and", "other", "local", "theatres", ")", "if", "they", "are", "distributed", "by", "a", "service", "such", "as", "Netflix", "."], "sentence-detokenized": "Starting with the 2019 Toronto International Film Festival, screenings at the Scotiabank Theatre Toronto - one of the festival's main venues - may be limited, and films will be allowed to screen elsewhere (such as the TIFF Bell Lightbox and other local theatres) if they are distributed by a service such as Netflix.", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 22], [23, 30], [31, 44], [45, 49], [50, 58], [58, 59], [60, 70], [71, 73], [74, 77], [78, 88], [89, 96], [97, 104], [105, 106], [107, 110], [111, 113], [114, 117], [118, 126], [126, 128], [129, 133], [134, 140], [141, 142], [143, 146], [147, 149], [150, 157], [157, 158], [159, 162], [163, 168], [169, 173], [174, 176], [177, 184], [185, 187], [188, 194], [195, 204], [205, 206], [206, 210], [211, 213], [214, 217], [218, 222], [223, 227], [228, 236], [237, 240], [241, 246], [247, 252], [253, 261], [261, 262], [263, 265], [266, 270], [271, 274], [275, 286], [287, 289], [290, 291], [292, 299], [300, 304], [305, 307], [308, 315], [315, 316]]}
{"doc_key": "ai-train-90", "ner": [[0, 0, "organisation"], [9, 10, "researcher"], [6, 7, "organisation"], [13, 13, "researcher"], [20, 25, "product"], [33, 34, "researcher"], [38, 40, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 6, 7, "related-to", "purchases", false, false], [9, 10, 13, 13, "named", "same", false, false], [9, 10, 33, 34, "named", "same", false, false], [6, 7, 9, 10, "origin", "founded_by", false, false], [20, 25, 0, 0, "artifact", "", false, false], [38, 40, 33, 34, "artifact", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "was", "purchased", "in", "1977", "by", "Vicarm", "Inc", ".", "Victor", "Scheinman", "and", "with", "his", "help", "created", "and", "began", "manufacturing", "the", "Programmable", "Universal", "Assembly", "Machine", ",", "a", "new", "model", "of", "robotic", "arm", ",", "using", "Scheinman", "'s", "cutting", "-", "edge", "VAL", "programming", "language", "."], "sentence-detokenized": "Unimation was purchased in 1977 by Vicarm Inc. Victor Scheinman and with his help created and began manufacturing the Programmable Universal Assembly Machine, a new model of robotic arm, using Scheinman's cutting-edge VAL programming language.", "token2charspan": [[0, 9], [10, 13], [14, 23], [24, 26], [27, 31], [32, 34], [35, 41], [42, 45], [45, 46], [47, 53], [54, 63], [64, 67], [68, 72], [73, 76], [77, 81], [82, 89], [90, 93], [94, 99], [100, 113], [114, 117], [118, 130], [131, 140], [141, 149], [150, 157], [157, 158], [159, 160], [161, 164], [165, 170], [171, 173], [174, 181], [182, 185], [185, 186], [187, 192], [193, 202], [202, 204], [205, 212], [212, 213], [213, 217], [218, 221], [222, 233], [234, 242], [242, 243]]}
{"doc_key": "ai-train-91", "ner": [[0, 1, "product"], [6, 6, "programlang"], [9, 11, "algorithm"], [14, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 6, 6, "general-affiliation", "", false, false], [0, 1, 9, 11, "origin", "implementation_of", false, false], [0, 1, 14, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["J", "48", "is", "an", "open", "source", "Java", "implementation", "of", "the", "C4.5", "algorithm", "in", "the", "Weka", "data", "mining", "tool", "."], "sentence-detokenized": "J48 is an open source Java implementation of the C4.5 algorithm in the Weka data mining tool.", "token2charspan": [[0, 1], [1, 3], [4, 6], [7, 9], [10, 14], [15, 21], [22, 26], [27, 41], [42, 44], [45, 48], [49, 53], [54, 63], [64, 66], [67, 70], [71, 75], [76, 80], [81, 87], [88, 92], [92, 93]]}
{"doc_key": "ai-train-92", "ner": [[0, 2, "metrics"], [14, 15, "product"], [22, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 14, 15, "win-defeat", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "2004", "SSIM", "paper", "has", "been", "cited", "more", "than", "20,000", "times", ",", "according", "to", "Google", "Scholar", ",", "and", "also", "won", "the", "2016", "IEEE", "Signal", "Processing", "Society", "Sustained", "Impact", "Award", ",", "which", "recognizes", "a", "paper", "with", "an", "unusually", "high", "impact", "for", "at", "least", "10", "years", "after", "its", "publication", "."], "sentence-detokenized": "The 2004 SSIM paper has been cited more than 20,000 times, according to Google Scholar, and also won the 2016 IEEE Signal Processing Society Sustained Impact Award, which recognizes a paper with an unusually high impact for at least 10 years after its publication.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 19], [20, 23], [24, 28], [29, 34], [35, 39], [40, 44], [45, 51], [52, 57], [57, 58], [59, 68], [69, 71], [72, 78], [79, 86], [86, 87], [88, 91], [92, 96], [97, 100], [101, 104], [105, 109], [110, 114], [115, 121], [122, 132], [133, 140], [141, 150], [151, 157], [158, 163], [163, 164], [165, 170], [171, 181], [182, 183], [184, 189], [190, 194], [195, 197], [198, 207], [208, 212], [213, 219], [220, 223], [224, 226], [227, 232], [233, 235], [236, 241], [242, 247], [248, 251], [252, 263], [263, 264]]}
{"doc_key": "ai-train-93", "ner": [[0, 3, "task"], [18, 26, "product"], [33, 35, "product"], [38, 38, "organisation"], [39, 41, "product"], [44, 44, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 38, 38, "artifact", "", false, false], [18, 26, 0, 3, "related-to", "performs", false, false], [18, 26, 33, 35, "part-of", "", false, false], [38, 38, 44, 44, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Speech", "synthesis", "is", "approaching", "complete", "indistinguishability", "from", "the", "real", "human", "voice", ",", "with", "the", "introduction", "in", "2016", "of", "Adobe", "Voco", "voice", "editing", "and", "generation", "software", ",", "a", "prototype", "to", "be", "part", "of", "the", "Adobe", "Creative", "Suite", ",", "and", "DeepMind", "WaveNet", ",", "a", "prototype", "from", "Google", "."], "sentence-detokenized": "Speech synthesis is approaching complete indistinguishability from the real human voice, with the introduction in 2016 of Adobe Voco voice editing and generation software, a prototype to be part of the Adobe Creative Suite, and DeepMind WaveNet, a prototype from Google.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 31], [32, 40], [41, 61], [62, 66], [67, 70], [71, 75], [76, 81], [82, 87], [87, 88], [89, 93], [94, 97], [98, 110], [111, 113], [114, 118], [119, 121], [122, 127], [128, 132], [133, 138], [139, 146], [147, 150], [151, 161], [162, 170], [170, 171], [172, 173], [174, 183], [184, 186], [187, 189], [190, 194], [195, 197], [198, 201], [202, 207], [208, 216], [217, 222], [222, 223], [224, 227], [228, 236], [237, 244], [244, 245], [246, 247], [248, 257], [258, 262], [263, 269], [269, 270]]}
{"doc_key": "ai-train-94", "ner": [[0, 0, "researcher"], [7, 11, "organisation"], [14, 22, "organisation"], [26, 26, "conference"], [34, 38, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 7, 11, "role", "", false, false], [0, 0, 14, 22, "role", "", false, false], [0, 0, 26, 26, "role", "", false, false], [0, 0, 34, 38, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Poggio", "is", "an", "Honorary", "Fellow", "of", "the", "Neuroscience", "Research", "Program", ",", "a", "Fellow", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "a", "founding", "member", "of", "AAAI", ",", "and", "a", "founding", "member", "of", "the", "McGovern", "Institute", "for", "Brain", "Research", "."], "sentence-detokenized": "Poggio is an Honorary Fellow of the Neuroscience Research Program, a Fellow of the American Academy of Arts and Sciences, a founding member of AAAI, and a founding member of the McGovern Institute for Brain Research.", "token2charspan": [[0, 6], [7, 9], [10, 12], [13, 21], [22, 28], [29, 31], [32, 35], [36, 48], [49, 57], [58, 65], [65, 66], [67, 68], [69, 75], [76, 78], [79, 82], [83, 91], [92, 99], [100, 102], [103, 107], [108, 111], [112, 120], [120, 121], [122, 123], [124, 132], [133, 139], [140, 142], [143, 147], [147, 148], [149, 152], [153, 154], [155, 163], [164, 170], [171, 173], [174, 177], [178, 186], [187, 196], [197, 200], [201, 206], [207, 215], [215, 216]]}
{"doc_key": "ai-train-95", "ner": [[9, 10, "task"], [13, 13, "task"], [20, 21, "task"], [26, 26, "misc"], [27, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 10, 20, 21, "cause-effect", "", false, false], [13, 13, 20, 21, "cause-effect", "", false, false], [27, 28, 20, 21, "topic", "", false, false], [27, 28, 26, 26, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "1990s", ",", "based", "on", "the", "successes", "in", "speech", "recognition", "and", "speech", "synthesis", ",", "research", "in", "the", "field", "of", "speech", "translation", "was", "initiated", "in", "the", "German", "Verbmobil", "project", "."], "sentence-detokenized": "In the 1990s, based on the successes in speech recognition and speech synthesis, research in the field of speech translation was initiated in the German Verbmobil project.", "token2charspan": [[0, 2], [3, 6], [7, 12], [12, 13], [14, 19], [20, 22], [23, 26], [27, 36], [37, 39], [40, 46], [47, 58], [59, 62], [63, 69], [70, 79], [79, 80], [81, 89], [90, 92], [93, 96], [97, 102], [103, 105], [106, 112], [113, 124], [125, 128], [129, 138], [139, 141], [142, 145], [146, 152], [153, 162], [163, 170], [170, 171]]}
{"doc_key": "ai-train-96", "ner": [[3, 4, "researcher"], [8, 9, "researcher"], [11, 12, "researcher"], [15, 16, "algorithm"], [20, 26, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 8, 9, "role", "", false, false], [15, 16, 3, 4, "origin", "", false, false], [15, 16, 8, 9, "origin", "", false, false], [15, 16, 11, 12, "origin", "", false, false], [15, 16, 25, 25, "part-of", "", false, false], [20, 26, 15, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "1999", ",", "Felix", "Gers", "and", "his", "advisors", "J\u00fcrgen", "Schmidhuber", "and", "Fred", "Cummins", "introduced", "the", "forget", "gate", "(", "also", "called", "keep", "gate", ")", "into", "the", "LSTM", "architecture", ","], "sentence-detokenized": "In 1999, Felix Gers and his advisors J\u00fcrgen Schmidhuber and Fred Cummins introduced the forget gate (also called keep gate) into the LSTM architecture,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 19], [20, 23], [24, 27], [28, 36], [37, 43], [44, 55], [56, 59], [60, 64], [65, 72], [73, 83], [84, 87], [88, 94], [95, 99], [100, 101], [101, 105], [106, 112], [113, 117], [118, 122], [122, 123], [124, 128], [129, 132], [133, 137], [138, 150], [150, 151]]}
{"doc_key": "ai-train-97", "ner": [[1, 3, "field"], [5, 12, "field"], [9, 11, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 11, 1, 3, "part-of", "", false, false], [9, 11, 5, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "digital", "signal", "processing", "and", "information", "theory", ",", "the", "normalized", "sinusoidal", "function", "is", "commonly", "defined", "as", "follows"], "sentence-detokenized": "In digital signal processing and information theory, the normalized sinusoidal function is commonly defined as follows", "token2charspan": [[0, 2], [3, 10], [11, 17], [18, 28], [29, 32], [33, 44], [45, 51], [51, 52], [53, 56], [57, 67], [68, 78], [79, 87], [88, 90], [91, 99], [100, 107], [108, 110], [111, 118]]}
{"doc_key": "ai-train-98", "ner": [[2, 3, "field"], [9, 12, "researcher"], [16, 20, "conference"], [23, 27, "organisation"], [29, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 12, "origin", "coined_term", false, false], [9, 12, 16, 20, "role", "", false, false], [9, 12, 23, 27, "role", "", false, false], [29, 29, 23, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "computational", "linguistics", "itself", "was", "first", "used", "by", "David", "Hays", ",", "a", "founding", "member", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "the", "International", "Committee", "for", "Computational", "Linguistics", "(", "ICCL", ")", "."], "sentence-detokenized": "The term computational linguistics itself was first used by David Hays, a founding member of the Association for Computational Linguistics and the International Committee for Computational Linguistics (ICCL).", "token2charspan": [[0, 3], [4, 8], [9, 22], [23, 34], [35, 41], [42, 45], [46, 51], [52, 56], [57, 59], [60, 65], [66, 70], [70, 71], [72, 73], [74, 82], [83, 89], [90, 92], [93, 96], [97, 108], [109, 112], [113, 126], [127, 138], [139, 142], [143, 146], [147, 160], [161, 170], [171, 174], [175, 188], [189, 200], [201, 202], [202, 206], [206, 207], [207, 208]]}
{"doc_key": "ai-train-99", "ner": [[8, 15, "misc"], [10, 10, "misc"], [34, 36, "metrics"], [38, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[38, 38, 34, 36, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["59", ",", "pp.", "2547-2553", ",", "October", "2011", "In", "one", "-dimensional", "DPD", "based", "on", "polynomials", "with", "memory", "(", "or", "without", "memory", ")", ",", "to", "solve", "the", "coefficients", "of", "the", "digital", "predeformer", "polynomials", "and", "minimize", "the", "mean", "square", "error", "(", "MSE", ")", ",", "the", "distorted", "output", "of", "the", "nonlinear", "system", "must", "be", "resampled", "at", "a", "rate", "that", "allows", "the", "nonlinear", "products", "of", "order", "of", "the", "digital", "predeformer", "to", "be", "captured", "."], "sentence-detokenized": "59, pp. 2547-2553, October 2011 In one-dimensional DPD based on polynomials with memory (or without memory), to solve the coefficients of the digital predeformer polynomials and minimize the mean square error (MSE), the distorted output of the nonlinear system must be resampled at a rate that allows the nonlinear products of order of the digital predeformer to be captured.", "token2charspan": [[0, 2], [2, 3], [4, 7], [8, 17], [17, 18], [19, 26], [27, 31], [32, 34], [35, 38], [38, 50], [51, 54], [55, 60], [61, 63], [64, 75], [76, 80], [81, 87], [88, 89], [89, 91], [92, 99], [100, 106], [106, 107], [107, 108], [109, 111], [112, 117], [118, 121], [122, 134], [135, 137], [138, 141], [142, 149], [150, 161], [162, 173], [174, 177], [178, 186], [187, 190], [191, 195], [196, 202], [203, 208], [209, 210], [210, 213], [213, 214], [214, 215], [216, 219], [220, 229], [230, 236], [237, 239], [240, 243], [244, 253], [254, 260], [261, 265], [266, 268], [269, 278], [279, 281], [282, 283], [284, 288], [289, 293], [294, 300], [301, 304], [305, 314], [315, 323], [324, 326], [327, 332], [333, 335], [336, 339], [340, 347], [348, 359], [360, 362], [363, 365], [366, 374], [374, 375]]}
{"doc_key": "ai-train-100", "ner": [[0, 1, "researcher"], [9, 9, "location"], [11, 12, "location"], [14, 15, "country"], [19, 19, "location"], [21, 21, "country"], [35, 42, "organisation"], [45, 48, "organisation"], [50, 50, "location"], [58, 59, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 1, 9, 9, "physical", "", false, false], [0, 1, 45, 48, "physical", "", false, false], [0, 1, 58, 59, "role", "", false, false], [9, 9, 11, 12, "physical", "", false, false], [11, 12, 14, 15, "physical", "", false, false], [35, 42, 45, 48, "part-of", "", false, false], [45, 48, 50, 50, "physical", "", false, false], [58, 59, 35, 42, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Boris", "Katz", "(", "born", "October", "5", ",", "1947", "in", "Chisinau", ",", "Moldavian", "SSR", ",", "Soviet", "Union", ",", "(", "now", "Chisinau", ",", "Moldova", ")", ")", "is", "an", "American", "senior", "research", "scientist", "(", "computer", "scientist", ")", "at", "MIT", "'s", "Computer", "Science", "and", "Artificial", "Intelligence", "Laboratory", "at", "the", "Massachusetts", "Institute", "of", "Technology", "in", "Cambridge", "and", "the", "leader", "of", "the", "lab", "'s", "InfoLab", "group", "."], "sentence-detokenized": "Boris Katz (born October 5, 1947 in Chisinau, Moldavian SSR, Soviet Union, (now Chisinau, Moldova)) is an American senior research scientist (computer scientist) at MIT's Computer Science and Artificial Intelligence Laboratory at the Massachusetts Institute of Technology in Cambridge and the leader of the lab's InfoLab group.", "token2charspan": [[0, 5], [6, 10], [11, 12], [12, 16], [17, 24], [25, 26], [26, 27], [28, 32], [33, 35], [36, 44], [44, 45], [46, 55], [56, 59], [59, 60], [61, 67], [68, 73], [73, 74], [75, 76], [76, 79], [80, 88], [88, 89], [90, 97], [97, 98], [98, 99], [100, 102], [103, 105], [106, 114], [115, 121], [122, 130], [131, 140], [141, 142], [142, 150], [151, 160], [160, 161], [162, 164], [165, 168], [168, 170], [171, 179], [180, 187], [188, 191], [192, 202], [203, 215], [216, 226], [227, 229], [230, 233], [234, 247], [248, 257], [258, 260], [261, 271], [272, 274], [275, 284], [285, 288], [289, 292], [293, 299], [300, 302], [303, 306], [307, 310], [310, 312], [313, 320], [321, 326], [326, 327]]}
