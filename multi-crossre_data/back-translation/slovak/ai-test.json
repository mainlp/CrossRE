{"doc_key": "ai-test-1", "ner": [[6, 8, "algorithm"], [10, 11, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "approaches", "of", "generative", "models", "include", "naive", "Bayes", "classifiers", ",", "Gaussian", "mixture", "models", ",", "variational", "autoencoders", ",", "and", "others", "."], "sentence-detokenized": "Typical approaches of generative models include naive Bayes classifiers, Gaussian mixture models, variational autoencoders, and others.", "token2charspan": [[0, 7], [8, 18], [19, 21], [22, 32], [33, 39], [40, 47], [48, 53], [54, 59], [60, 71], [71, 72], [73, 81], [82, 89], [90, 96], [96, 97], [98, 109], [110, 122], [122, 123], [124, 127], [128, 134], [134, 135]]}
{"doc_key": "ai-test-2", "ner": [[5, 5, "organisation"], [11, 11, "conference"], [14, 20, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 11, 11, "role", "", false, false], [14, 20, 11, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Finally", ",", "every", "other", "year", "ELRA", "organises", "a", "major", "conference", ",", "LREC", ",", "the", "International", "Conference", "on", "Language", "Resources", "and", "Evaluation", "."], "sentence-detokenized": "Finally, every other year ELRA organises a major conference, LREC, the International Conference on Language Resources and Evaluation.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 20], [21, 25], [26, 30], [31, 40], [41, 42], [43, 48], [49, 59], [59, 60], [61, 65], [65, 66], [67, 70], [71, 84], [85, 95], [96, 98], [99, 107], [108, 117], [118, 121], [122, 132], [132, 133]]}
{"doc_key": "ai-test-3", "ner": [[7, 10, "algorithm"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "task", "is", "usually", "to", "derive", "a", "maximum", "likelihood", "estimate", "of", "the", "HMM", "parameters", "given", "the", "output", "sequences", "."], "sentence-detokenized": "The task is usually to derive a maximum likelihood estimate of the HMM parameters given the output sequences.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 19], [20, 22], [23, 29], [30, 31], [32, 39], [40, 50], [51, 59], [60, 62], [63, 66], [67, 70], [71, 81], [82, 87], [88, 91], [92, 98], [99, 108], [108, 109]]}
{"doc_key": "ai-test-4", "ner": [[1, 2, "algorithm"], [4, 8, "algorithm"], [9, 9, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 9, 9, "compare", "", false, false], [4, 8, 9, 9, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Unlike", "neural", "networks", "and", "support", "vector", "machines", ",", "the", "AdaBoost", "training", "process", "selects", "only", "those", "features", "that", "are", "known", "to", "improve", "the", "predictive", "power", "of", "the", "model", ",", "thus", "reducing", "dimensionality", "and", "potentially", "improving", "execution", "time", "because", "there", "is", "no", "need", "to", "compute", "irrelevant", "features", "."], "sentence-detokenized": "Unlike neural networks and support vector machines, the AdaBoost training process selects only those features that are known to improve the predictive power of the model, thus reducing dimensionality and potentially improving execution time because there is no need to compute irrelevant features.", "token2charspan": [[0, 6], [7, 13], [14, 22], [23, 26], [27, 34], [35, 41], [42, 50], [50, 51], [52, 55], [56, 64], [65, 73], [74, 81], [82, 89], [90, 94], [95, 100], [101, 109], [110, 114], [115, 118], [119, 124], [125, 127], [128, 135], [136, 139], [140, 150], [151, 156], [157, 159], [160, 163], [164, 169], [169, 170], [171, 175], [176, 184], [185, 199], [200, 203], [204, 215], [216, 225], [226, 235], [236, 240], [241, 248], [249, 254], [255, 257], [258, 260], [261, 265], [266, 268], [269, 276], [277, 287], [288, 296], [296, 297]]}
{"doc_key": "ai-test-5", "ner": [[0, 0, "misc"], [11, 14, "misc"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 14, "part-of", "", false, false], [11, 14, 15, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Troponymy", "is", "one", "of", "the", "possible", "relationships", "between", "verbs", "in", "the", "semantic", "network", "of", "the", "Word", "Net", "database", "."], "sentence-detokenized": "Troponymy is one of the possible relationships between verbs in the semantic network of the WordNet database.", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 19], [20, 23], [24, 32], [33, 46], [47, 54], [55, 60], [61, 63], [64, 67], [68, 76], [77, 84], [85, 87], [88, 91], [92, 96], [96, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-test-6", "ner": [[8, 9, "task"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 11, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "framework", "language", "is", "a", "technology", "used", "to", "represent", "knowledge", "in", "artificial", "intelligence", "."], "sentence-detokenized": "A framework language is a technology used to represent knowledge in artificial intelligence.", "token2charspan": [[0, 1], [2, 11], [12, 20], [21, 23], [24, 25], [26, 36], [37, 41], [42, 44], [45, 54], [55, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-7", "ner": [[0, 0, "metrics"], [5, 7, "metrics"], [13, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 5, 7, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "the", "bilingual", "assessment", "understudy", "in", "the", "calculation", "of", "the", "brevity", "penalty", ",", "as", "small", "variations", "in", "translation", "length", "do", "not", "have", "as", "much", "impact", "on", "the", "overall", "score", "."], "sentence-detokenized": "NIST also differs from the bilingual assessment understudy in the calculation of the brevity penalty, as small variations in translation length do not have as much impact on the overall score.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 26], [27, 36], [37, 47], [48, 58], [59, 61], [62, 65], [66, 77], [78, 80], [81, 84], [85, 92], [93, 100], [100, 101], [102, 104], [105, 110], [111, 121], [122, 124], [125, 136], [137, 143], [144, 146], [147, 150], [151, 155], [156, 158], [159, 163], [164, 170], [171, 173], [174, 177], [178, 185], [186, 191], [191, 192]]}
{"doc_key": "ai-test-8", "ner": [[17, 19, "algorithm"], [22, 24, "algorithm"], [36, 38, "field"], [48, 49, "algorithm"], [51, 53, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[17, 19, 36, 38, "usage", "", false, false], [22, 24, 36, 38, "usage", "", false, false], [48, 49, 36, 38, "type-of", "", false, false], [51, 53, 36, 38, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "model", "is", "initially", "fitted", "to", "a", "set", "of", "trained", "data", ",", "The", "model", "(", "e.g.", ",", "a", "neural", "network", "or", "a", "naive", "Bayes", "classifier", ")", "is", "trained", "on", "the", "set", "of", "trained", "data", "using", "a", "supervised", "learning", "method", ",", "for", "example", ",", "using", "optimization", "methods", "such", "as", "gradient", "descent", "or", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The model is initially fitted to a set of trained data, The model (e.g., a neural network or a naive Bayes classifier) is trained on the set of trained data using a supervised learning method, for example, using optimization methods such as gradient descent or stochastic gradient descent.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 22], [23, 29], [30, 32], [33, 34], [35, 38], [39, 41], [42, 49], [50, 54], [54, 55], [56, 59], [60, 65], [66, 67], [67, 71], [71, 72], [73, 74], [75, 81], [82, 89], [90, 92], [93, 94], [95, 100], [101, 106], [107, 117], [117, 118], [119, 121], [122, 129], [130, 132], [133, 136], [137, 140], [141, 143], [144, 151], [152, 156], [157, 162], [163, 164], [165, 175], [176, 184], [185, 191], [191, 192], [193, 196], [197, 204], [204, 205], [206, 211], [212, 224], [225, 232], [233, 237], [238, 240], [241, 249], [250, 257], [258, 260], [261, 271], [272, 280], [281, 288], [288, 289]]}
{"doc_key": "ai-test-9", "ner": [[0, 2, "product"], [8, 9, "task"], [11, 11, "task"], [13, 15, "task"], [18, 19, "task"], [25, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 2, "usage", "", true, false], [11, 11, 0, 2, "usage", "", true, false], [13, 15, 0, 2, "usage", "", true, false], [18, 19, 0, 2, "usage", "", true, false], [25, 28, 0, 2, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Frame", "Net", "is", "used", "in", "applications", "such", "as", "question", "answering", ",", "paraphrasing", ",", "textual", "context", "recognition", ",", "and", "information", "extraction", ",", "either", "directly", "or", "through", "semantic", "role", "labeling", "tools", "."], "sentence-detokenized": "FrameNet is used in applications such as question answering, paraphrasing, textual context recognition, and information extraction, either directly or through semantic role labeling tools.", "token2charspan": [[0, 5], [5, 8], [9, 11], [12, 16], [17, 19], [20, 32], [33, 37], [38, 40], [41, 49], [50, 59], [59, 60], [61, 73], [73, 74], [75, 82], [83, 90], [91, 102], [102, 103], [104, 107], [108, 119], [120, 130], [130, 131], [132, 138], [139, 147], [148, 150], [151, 158], [159, 167], [168, 172], [173, 181], [182, 187], [187, 188]]}
{"doc_key": "ai-test-10", "ner": [[6, 9, "field"], [11, 11, "misc"], [14, 14, "product"], [17, 17, "misc"], [20, 20, "product"], [23, 24, "field"], [27, 27, "product"], [30, 32, "misc"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [42, 45, "misc"], [46, 47, "product"], [49, 50, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[14, 14, 11, 11, "general-affiliation", "", false, false], [20, 20, 17, 17, "general-affiliation", "", false, false], [27, 27, 23, 24, "general-affiliation", "", false, false], [35, 35, 30, 32, "type-of", "", false, false], [37, 37, 30, 32, "type-of", "", false, false], [39, 39, 30, 32, "type-of", "", false, false], [46, 47, 42, 45, "general-affiliation", "", false, false], [49, 50, 42, 45, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["This", "includes", "programs", "such", "as", "data", "analysis", "and", "extraction", "tools", ",", "spreadsheets", "(", "e.g.", "Excel", ")", ",", "databases", "(", "e.g.", "Access", ")", ",", "statistical", "analysis", "(", "e.g.", "SAS", ")", ",", "general", "auditing", "software", "(", "e.g.", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "business", "intelligence", "(", "e.g.", "Crystal", "Reports", "and", "Business", "Objects", ")", ",", "etc", "."], "sentence-detokenized": "This includes programs such as data analysis and extraction tools, spreadsheets (e.g. Excel), databases (e.g. Access), statistical analysis (e.g. SAS), general auditing software (e.g. ACL, Arbutus, EAS), business intelligence (e.g. Crystal Reports and Business Objects), etc.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 27], [28, 30], [31, 35], [36, 44], [45, 48], [49, 59], [60, 65], [65, 66], [67, 79], [80, 81], [81, 85], [86, 91], [91, 92], [92, 93], [94, 103], [104, 105], [105, 109], [110, 116], [116, 117], [117, 118], [119, 130], [131, 139], [140, 141], [141, 145], [146, 149], [149, 150], [150, 151], [152, 159], [160, 168], [169, 177], [178, 179], [179, 183], [184, 187], [187, 188], [189, 196], [196, 197], [198, 201], [201, 202], [202, 203], [204, 212], [213, 225], [226, 227], [227, 231], [232, 239], [240, 247], [248, 251], [252, 260], [261, 268], [268, 269], [269, 270], [271, 274], [274, 275]]}
{"doc_key": "ai-test-11", "ner": [[0, 1, "organisation"], [5, 8, "researcher"], [12, 12, "organisation"], [15, 16, "product"], [21, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 8, "origin", "", false, false], [5, 8, 12, 12, "role", "", false, false], [15, 16, 21, 22, "type-of", "", false, false], [21, 22, 5, 8, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Rethink", "Robotics", "-", "founded", "by", "Rodney", "Brooks", ",", "who", "previously", "worked", "for", "iRobot", "-", "introduced", "Baxter", "in", "September", "2012", "as", "an", "industrial", "robot", "designed", "to", "safely", "interact", "with", "nearby", "human", "workers", "and", "programmable", "to", "perform", "simple", "tasks", "."], "sentence-detokenized": "Rethink Robotics - founded by Rodney Brooks, who previously worked for iRobot - introduced Baxter in September 2012 as an industrial robot designed to safely interact with nearby human workers and programmable to perform simple tasks.", "token2charspan": [[0, 7], [8, 16], [17, 18], [19, 26], [27, 29], [30, 36], [37, 43], [43, 44], [45, 48], [49, 59], [60, 66], [67, 70], [71, 77], [78, 79], [80, 90], [91, 97], [98, 100], [101, 110], [111, 115], [116, 118], [119, 121], [122, 132], [133, 138], [139, 147], [148, 150], [151, 157], [158, 166], [167, 171], [172, 178], [179, 184], [185, 192], [193, 196], [197, 209], [210, 212], [213, 220], [221, 227], [228, 233], [233, 234]]}
{"doc_key": "ai-test-12", "ner": [[1, 2, "field"], [5, 6, "task"], [8, 9, "task"], [11, 14, "task"], [16, 18, "task"], [20, 21, "task"], [23, 24, "task"], [27, 29, "task"], [36, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 6, 1, 2, "part-of", "task_part_of_field", false, false], [8, 9, 1, 2, "part-of", "task_part_of_field", false, false], [11, 14, 1, 2, "part-of", "task_part_of_field", false, false], [16, 18, 1, 2, "part-of", "task_part_of_field", false, false], [20, 21, 1, 2, "part-of", "task_part_of_field", false, false], [23, 24, 1, 2, "part-of", "task_part_of_field", false, false], [27, 29, 1, 2, "part-of", "task_part_of_field", false, false], [36, 38, 1, 2, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Typical", "text", "mining", "tasks", "include", "text", "categorization", ",", "text", "clustering", ",", "concept", "/", "entity", "extraction", ",", "granular", "taxonomy", "formation", ",", "sentiment", "analysis", ",", "document", "summarization", ",", "and", "entity", "relationship", "modeling", "(", "i.e.", ",", "learning", "relationships", "between", "named", "entity", "recognitions", ")", "."], "sentence-detokenized": "Typical text mining tasks include text categorization, text clustering, concept/entity extraction, granular taxonomy formation, sentiment analysis, document summarization, and entity relationship modeling (i.e., learning relationships between named entity recognitions).", "token2charspan": [[0, 7], [8, 12], [13, 19], [20, 25], [26, 33], [34, 38], [39, 53], [53, 54], [55, 59], [60, 70], [70, 71], [72, 79], [79, 80], [80, 86], [87, 97], [97, 98], [99, 107], [108, 116], [117, 126], [126, 127], [128, 137], [138, 146], [146, 147], [148, 156], [157, 170], [170, 171], [172, 175], [176, 182], [183, 195], [196, 204], [205, 206], [206, 210], [210, 211], [212, 220], [221, 234], [235, 242], [243, 248], [249, 255], [256, 268], [268, 269], [269, 270]]}
{"doc_key": "ai-test-13", "ner": [[0, 3, "metrics"], [5, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nevertheless", ",", "the", "accuracy", "or", "TRUE", "negative", "rate", "decreases", "with", "such", "systems", "."], "sentence-detokenized": "Nevertheless, the accuracy or TRUE negative rate decreases with such systems.", "token2charspan": [[0, 12], [12, 13], [14, 17], [18, 26], [27, 29], [30, 34], [35, 43], [44, 48], [49, 58], [59, 63], [64, 68], [69, 76], [76, 77]]}
{"doc_key": "ai-test-14", "ner": [[4, 6, "task"], [7, 8, "misc"], [13, 18, "misc"], [26, 26, "product"], [28, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 4, 6, "temporal", "", false, false], [13, 18, 7, 8, "named", "", false, false], [26, 26, 7, 8, "usage", "", false, false], [28, 30, 7, 8, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "special", "case", "of", "keyword", "recognition", "is", "wake", "word", "detection", "(", "also", "called", "hot", "word", ")", ",", "which", "is", "used", "by", "personal", "digital", "assistants", "such", "as", "Alexa", "or", "Siri", "to", "wake", "up", "when", "their", "name", "is", "spoken", "."], "sentence-detokenized": "A special case of keyword recognition is wake word detection (also called hot word), which is used by personal digital assistants such as Alexa or Siri to wake up when their name is spoken.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 17], [18, 25], [26, 37], [38, 40], [41, 45], [46, 50], [51, 60], [61, 62], [62, 66], [67, 73], [74, 77], [78, 82], [82, 83], [83, 84], [85, 90], [91, 93], [94, 98], [99, 101], [102, 110], [111, 118], [119, 129], [130, 134], [135, 137], [138, 143], [144, 146], [147, 151], [152, 154], [155, 159], [160, 162], [163, 167], [168, 173], [174, 178], [179, 181], [182, 188], [188, 189]]}
{"doc_key": "ai-test-15", "ner": [[0, 0, "programlang"], [9, 9, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 0, 0, "part-of", "", false, false], [11, 11, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "is", "an", "open", "source", "programming", "language", "that", "combines", "Prolog", "with", "Java", "."], "sentence-detokenized": "Prova is an open source programming language that combines Prolog with Java.", "token2charspan": [[0, 5], [6, 8], [9, 11], [12, 16], [17, 23], [24, 35], [36, 44], [45, 49], [50, 58], [59, 65], [66, 70], [71, 75], [75, 76]]}
{"doc_key": "ai-test-16", "ner": [[3, 4, "organisation"], [9, 9, "organisation"], [16, 18, "product"], [29, 31, "country"], [35, 38, "organisation"], [46, 47, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 9, 9, "part-of", "", false, false], [3, 4, 9, 9, "role", "sells", false, false], [3, 4, 29, 31, "role", "sells_to", false, false], [35, 38, 46, 47, "opposite", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "1987", ",", "Tocibai", "Machine", ",", "a", "subsidiary", "of", "Toshiba", ",", "was", "accused", "of", "illegally", "selling", "CNC", "milling", "machines", "used", "to", "manufacture", "ultra", "-", "quiet", "submarine", "propellers", "to", "the", "Soviet", "Union", "in", "violation", "of", "the", "CoCom", "Agreement", ",", "an", "international", "embargo", "imposed", "on", "certain", "countries", "to", "COMECON", "countries", "."], "sentence-detokenized": "In 1987, Tocibai Machine, a subsidiary of Toshiba, was accused of illegally selling CNC milling machines used to manufacture ultra-quiet submarine propellers to the Soviet Union in violation of the CoCom Agreement, an international embargo imposed on certain countries to COMECON countries.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 24], [24, 25], [26, 27], [28, 38], [39, 41], [42, 49], [49, 50], [51, 54], [55, 62], [63, 65], [66, 75], [76, 83], [84, 87], [88, 95], [96, 104], [105, 109], [110, 112], [113, 124], [125, 130], [130, 131], [131, 136], [137, 146], [147, 157], [158, 160], [161, 164], [165, 171], [172, 177], [178, 180], [181, 190], [191, 193], [194, 197], [198, 203], [204, 213], [213, 214], [215, 217], [218, 231], [232, 239], [240, 247], [248, 250], [251, 258], [259, 268], [269, 271], [272, 279], [280, 289], [289, 290]]}
{"doc_key": "ai-test-17", "ner": [[0, 1, "researcher"], [7, 12, "product"], [20, 25, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 12, 0, 1, "artifact", "", false, false], [7, 12, 20, 25, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Engelberger", "'s", "most", "famous", "invention", ",", "the", "Unimate", "industrial", "robotic", "arm", ",", "was", "inducted", "into", "the", "first", "inductees", "of", "the", "Robot", "Hall", "of", "Fame", "in", "2003", "."], "sentence-detokenized": "Engelberger's most famous invention, the Unimate industrial robotic arm, was inducted into the first inductees of the Robot Hall of Fame in 2003.", "token2charspan": [[0, 11], [11, 13], [14, 18], [19, 25], [26, 35], [35, 36], [37, 40], [41, 48], [49, 59], [60, 67], [68, 71], [71, 72], [73, 76], [77, 85], [86, 90], [91, 94], [95, 100], [101, 110], [111, 113], [114, 117], [118, 123], [124, 128], [129, 131], [132, 136], [137, 139], [140, 144], [144, 145]]}
{"doc_key": "ai-test-18", "ner": [[3, 7, "misc"], [8, 8, "misc"], [10, 10, "person"], [16, 17, "field"], [13, 15, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 7, 8, 8, "usage", "", false, false], [10, 10, 16, 17, "role", "", false, false], [16, 17, 13, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Originally", "controlled", "through", "static", "html", "web", "pages", "using", "CGI", ",", "Dalton", "introduced", "a", "Java", "-", "based", "augmented", "reality", "interface", "that", "met", "with", "limited", "success", "."], "sentence-detokenized": "Originally controlled through static html web pages using CGI, Dalton introduced a Java-based augmented reality interface that met with limited success.", "token2charspan": [[0, 10], [11, 21], [22, 29], [30, 36], [37, 41], [42, 45], [46, 51], [52, 57], [58, 61], [61, 62], [63, 69], [70, 80], [81, 82], [83, 87], [87, 88], [88, 93], [94, 103], [104, 111], [112, 121], [122, 126], [127, 130], [131, 135], [136, 143], [144, 151], [151, 152]]}
{"doc_key": "ai-test-19", "ner": [[5, 7, "task"], [10, 10, "organisation"], [26, 26, "conference"], [30, 31, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 7, 10, 10, "origin", "", false, false], [26, 26, 30, 31, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "publication", "on", "the", "LMF", "specification", "as", "ratified", "by", "ISO", "(", "this", "article", "became", "(", "in", "2015", ")", "the", "9th", "most", "cited", "article", "in", "the", "LREC", "conferences", "from", "the", "LREC", "documents", ")", ":"], "sentence-detokenized": "The first publication on the LMF specification as ratified by ISO (this article became (in 2015) the 9th most cited article in the LREC conferences from the LREC documents):", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 24], [25, 28], [29, 32], [33, 46], [47, 49], [50, 58], [59, 61], [62, 65], [66, 67], [67, 71], [72, 79], [80, 86], [87, 88], [88, 90], [91, 95], [95, 96], [97, 100], [101, 104], [105, 109], [110, 115], [116, 123], [124, 126], [127, 130], [131, 135], [136, 147], [148, 152], [153, 156], [157, 161], [162, 171], [171, 172], [172, 173]]}
{"doc_key": "ai-test-20", "ner": [[0, 2, "metrics"], [15, 16, "metrics"], [17, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 16, 0, 2, "usage", "", false, false], [15, 16, 17, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "confusion", "matrix", "or", "matching", "matrix", "is", "often", "used", "as", "a", "tool", "to", "verify", "the", "accuracy", "of", "k", "-", "NN", "classification", "."], "sentence-detokenized": "The confusion matrix or matching matrix is often used as a tool to verify the accuracy of k -NN classification.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 23], [24, 32], [33, 39], [40, 42], [43, 48], [49, 53], [54, 56], [57, 58], [59, 63], [64, 66], [67, 73], [74, 77], [78, 86], [87, 89], [90, 91], [92, 93], [93, 95], [96, 110], [110, 111]]}
{"doc_key": "ai-test-21", "ner": [[0, 1, "algorithm"], [12, 12, "field"], [14, 15, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 12, "part-of", "", false, false], [0, 1, 14, 15, "part-of", "", false, false], [0, 1, 18, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", "is", "one", "of", "the", "predictive", "modeling", "approaches", "used", "in", "statistics", ",", "data", "mining", ",", "and", "machine", "learning", "."], "sentence-detokenized": "Decision tree learning is one of the predictive modeling approaches used in statistics, data mining, and machine learning.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 47], [48, 56], [57, 67], [68, 72], [73, 75], [76, 86], [86, 87], [88, 92], [93, 99], [99, 100], [101, 104], [105, 112], [113, 121], [121, 122]]}
{"doc_key": "ai-test-22", "ner": [[5, 6, "misc"], [14, 15, "field"], [19, 21, "algorithm"], [23, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 14, 15, "related-to", "", true, false], [19, 21, 14, 15, "type-of", "", false, false], [23, 23, 14, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["At", "runtime", ",", "the", "target", "sentence", "prosody", "is", "loaded", "onto", "these", "minimal", "units", "using", "signal", "processing", "techniques", "such", "as", "linear", "predictive", "coding", ",", "PSOLA"], "sentence-detokenized": "At runtime, the target sentence prosody is loaded onto these minimal units using signal processing techniques such as linear predictive coding, PSOLA", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 22], [23, 31], [32, 39], [40, 42], [43, 49], [50, 54], [55, 60], [61, 68], [69, 74], [75, 80], [81, 87], [88, 98], [99, 109], [110, 114], [115, 117], [118, 124], [125, 135], [136, 142], [142, 143], [144, 149]]}
{"doc_key": "ai-test-23", "ner": [[3, 4, "field"], [6, 9, "field"], [17, 20, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 20, 3, 4, "usage", "", true, false], [17, 20, 6, 9, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "approach", "uses", "artificial", "intelligence", "and", "machine", "learning", "to", "allow", "researchers", "to", "visibly", "compare", "conventional", "and", "thermal", "images", "of", "the", "face", "."], "sentence-detokenized": "This approach uses artificial intelligence and machine learning to allow researchers to visibly compare conventional and thermal images of the face.", "token2charspan": [[0, 4], [5, 13], [14, 18], [19, 29], [30, 42], [43, 46], [47, 54], [55, 63], [64, 66], [67, 72], [73, 84], [85, 87], [88, 95], [96, 103], [104, 116], [117, 120], [121, 128], [129, 135], [136, 138], [139, 142], [143, 147], [147, 148]]}
{"doc_key": "ai-test-24", "ner": [[1, 2, "field"], [4, 5, "algorithm"], [12, 13, "task"], [16, 17, "misc"], [23, 24, "field"], [26, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 1, 2, "part-of", "", false, false], [4, 5, 12, 13, "topic", "", false, false], [12, 13, 16, 17, "origin", "", false, false], [23, 24, 1, 2, "part-of", "", false, false], [23, 24, 4, 5, "topic", "", false, false], [26, 28, 1, 2, "part-of", "", false, false], [26, 28, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "computer", "science", ",", "evolutionary", "computation", "is", "a", "group", "of", "algorithms", "for", "global", "optimization", "inspired", "by", "biological", "evolution", ",", "and", "a", "subfield", "of", "artificial", "intelligence", "and", "soft", "computing", "that", "studies", "these", "algorithms", "."], "sentence-detokenized": "In computer science, evolutionary computation is a group of algorithms for global optimization inspired by biological evolution, and a subfield of artificial intelligence and soft computing that studies these algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 33], [34, 45], [46, 48], [49, 50], [51, 56], [57, 59], [60, 70], [71, 74], [75, 81], [82, 94], [95, 103], [104, 106], [107, 117], [118, 127], [127, 128], [129, 132], [133, 134], [135, 143], [144, 146], [147, 157], [158, 170], [171, 174], [175, 179], [180, 189], [190, 194], [195, 202], [203, 208], [209, 219], [219, 220]]}
{"doc_key": "ai-test-25", "ner": [[14, 15, "metrics"], [18, 21, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "it", "is", "possible", "to", "combine", "a", "certain", "measure", "based", "on", "the", "confusion", "matrix", "with", "the", "root", "mean", "square", "error", "evaluated", "between", "the", "raw", "model", "outputs", "and", "the", "actual", "values", "."], "sentence-detokenized": "For example, it is possible to combine a certain measure based on the confusion matrix with the root mean square error evaluated between the raw model outputs and the actual values.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 18], [19, 27], [28, 30], [31, 38], [39, 40], [41, 48], [49, 56], [57, 62], [63, 65], [66, 69], [70, 79], [80, 86], [87, 91], [92, 95], [96, 100], [101, 105], [106, 112], [113, 118], [119, 128], [129, 136], [137, 140], [141, 144], [145, 150], [151, 158], [159, 162], [163, 166], [167, 173], [174, 180], [180, 181]]}
{"doc_key": "ai-test-26", "ner": [[8, 11, "product"], [12, 12, "researcher"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 11, 12, 12, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Most", "of", "them", "are", "the", "result", "of", "the", "word2vec", "model", "created", "by", "Mikolov", "et", "al", ".", "or", "its", "variants", "."], "sentence-detokenized": "Most of them are the result of the word2vec model created by Mikolov et al. or its variants.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 16], [17, 20], [21, 27], [28, 30], [31, 34], [35, 43], [44, 49], [50, 57], [58, 60], [61, 68], [69, 71], [72, 74], [74, 75], [76, 78], [79, 82], [83, 91], [91, 92]]}
{"doc_key": "ai-test-27", "ner": [[12, 12, "conference"], [15, 19, "conference"], [21, 21, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 21, 15, 19, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["During", "this", "period", ",", "a", "total", "of", "43", "publications", "were", "recognized", "at", "CVPR", "and", "the", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "."], "sentence-detokenized": "During this period, a total of 43 publications were recognized at CVPR and the International Conference on Computer Vision (ICCV).", "token2charspan": [[0, 6], [7, 11], [12, 18], [18, 19], [20, 21], [22, 27], [28, 30], [31, 33], [34, 46], [47, 51], [52, 62], [63, 65], [66, 70], [71, 74], [75, 78], [79, 92], [93, 103], [104, 106], [107, 115], [116, 122], [123, 124], [124, 128], [128, 129], [129, 130]]}
{"doc_key": "ai-test-28", "ner": [[0, 0, "product"], [9, 13, "field"], [19, 20, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 9, 13, "general-affiliation", "platform_for_education_about", false, false], [19, 20, 0, 0, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["AIBO", "is", "often", "used", "as", "an", "inexpensive", "platform", "for", "AI", "education", "and", "research", "because", "it", "integrates", "a", "computer", ",", "computer", "vision", ",", "and", "articulators", "in", "a", "package", "that", "is", "much", "cheaper", "than", "conventional", "research", "robots", "."], "sentence-detokenized": "AIBO is often used as an inexpensive platform for AI education and research because it integrates a computer, computer vision, and articulators in a package that is much cheaper than conventional research robots.", "token2charspan": [[0, 4], [5, 7], [8, 13], [14, 18], [19, 21], [22, 24], [25, 36], [37, 45], [46, 49], [50, 52], [53, 62], [63, 66], [67, 75], [76, 83], [84, 86], [87, 97], [98, 99], [100, 108], [108, 109], [110, 118], [119, 125], [125, 126], [127, 130], [131, 143], [144, 146], [147, 148], [149, 156], [157, 161], [162, 164], [165, 169], [170, 177], [178, 182], [183, 195], [196, 204], [205, 211], [211, 212]]}
{"doc_key": "ai-test-29", "ner": [[7, 12, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "served", "as", "program", "chair", "for", "the", "International", "Conference", "on", "Computer", "Vision", "2021", "."], "sentence-detokenized": "She served as program chair for the International Conference on Computer Vision 2021.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 21], [22, 27], [28, 31], [32, 35], [36, 49], [50, 60], [61, 63], [64, 72], [73, 79], [80, 84], [84, 85]]}
{"doc_key": "ai-test-30", "ner": [[11, 11, "researcher"], [5, 6, "organisation"], [16, 18, "organisation"], [25, 26, "organisation"], [33, 36, "product"], [38, 38, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 5, 6, "role", "", false, false], [11, 11, 16, 18, "role", "", true, false], [16, 18, 25, 26, "role", "develops_with", false, false], [33, 36, 16, 18, "artifact", "", false, false], [38, 38, 33, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["After", "receiving", "a", "grant", "from", "Unimation", "to", "develop", "his", "designs", ",", "Scheinman", "sold", "the", "designs", "to", "Unimation", ",", "which", "further", "developed", "them", "with", "support", "from", "General", "Motors", "and", "later", "marketed", "them", "as", "the", "Programmable", "Universal", "Assembly", "Machine", "(", "PUMA", ")", "."], "sentence-detokenized": "After receiving a grant from Unimation to develop his designs, Scheinman sold the designs to Unimation, which further developed them with support from General Motors and later marketed them as the Programmable Universal Assembly Machine (PUMA).", "token2charspan": [[0, 5], [6, 15], [16, 17], [18, 23], [24, 28], [29, 38], [39, 41], [42, 49], [50, 53], [54, 61], [61, 62], [63, 72], [73, 77], [78, 81], [82, 89], [90, 92], [93, 102], [102, 103], [104, 109], [110, 117], [118, 127], [128, 132], [133, 137], [138, 145], [146, 150], [151, 158], [159, 165], [166, 169], [170, 175], [176, 184], [185, 189], [190, 192], [193, 196], [197, 209], [210, 219], [220, 228], [229, 236], [237, 238], [238, 242], [242, 243], [243, 244]]}
{"doc_key": "ai-test-31", "ner": [[6, 9, "task"], [8, 10, "task"], [14, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 6, 9, "general-affiliation", "works_with", false, false], [14, 14, 8, 10, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "survey", "of", "calibration", "methods", "for", "binary", "and", "multiclass", "classification", "tasks", "is", "given", "by", "Gebel", "(", "2009", ")", "."], "sentence-detokenized": "A survey of calibration methods for binary and multiclass classification tasks is given by Gebel (2009).", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 23], [24, 31], [32, 35], [36, 42], [43, 46], [47, 57], [58, 72], [73, 78], [79, 81], [82, 87], [88, 90], [91, 96], [97, 98], [98, 102], [102, 103], [103, 104]]}
{"doc_key": "ai-test-32", "ner": [[7, 9, "task"], [11, 11, "task"], [14, 15, "task"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "working", "in", "areas", "such", "as", "Optical", "Character", "Recognition", "(", "OCR", ")", ",", "speech", "synthesis", ",", "speech", "recognition", "technology", "and", "electronic", "keyboard", "tools", "."], "sentence-detokenized": "He is working in areas such as Optical Character Recognition (OCR), speech synthesis, speech recognition technology and electronic keyboard tools.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 22], [23, 27], [28, 30], [31, 38], [39, 48], [49, 60], [61, 62], [62, 65], [65, 66], [66, 67], [68, 74], [75, 84], [84, 85], [86, 92], [93, 104], [105, 115], [116, 119], [120, 130], [131, 139], [140, 145], [145, 146]]}
{"doc_key": "ai-test-33", "ner": [[13, 17, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "newer", "and", "state", "-", "of", "-", "the", "-", "art", "techniques", ",", "the", "Kaldi", "toolkit", "can", "be", "used", "."], "sentence-detokenized": "For newer and state-of-the-art techniques, the Kaldi toolkit can be used.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 19], [19, 20], [20, 22], [22, 23], [23, 26], [26, 27], [27, 30], [31, 41], [41, 42], [43, 46], [47, 52], [53, 60], [61, 64], [65, 67], [68, 72], [72, 73]]}
{"doc_key": "ai-test-34", "ner": [[0, 2, "researcher"], [7, 12, "organisation"], [15, 19, "organisation"], [22, 24, "organisation"], [30, 31, "researcher"], [32, 35, "organisation"], [41, 45, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 7, 12, "role", "", false, false], [0, 2, 15, 19, "role", "", false, false], [0, 2, 22, 24, "role", "", false, false], [0, 2, 32, 35, "role", "", false, false], [0, 2, 41, 45, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Johnson", "-", "Laird", "is", "a", "Fellow", "of", "the", "American", "Philosophical", "Society", ",", "a", "Fellow", "of", "the", "Royal", "Society", ",", "a", "Fellow", "of", "the", "British", "Academy", ",", "a", "Fellow", "of", "the", "William", "James", "Association", "for", "Psychological", "Science", ",", "and", "a", "Fellow", "of", "the", "Society", "for", "Cognitive", "Science", "."], "sentence-detokenized": "Johnson-Laird is a Fellow of the American Philosophical Society, a Fellow of the Royal Society, a Fellow of the British Academy, a Fellow of the William James Association for Psychological Science, and a Fellow of the Society for Cognitive Science.", "token2charspan": [[0, 7], [7, 8], [8, 13], [14, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 41], [42, 55], [56, 63], [63, 64], [65, 66], [67, 73], [74, 76], [77, 80], [81, 86], [87, 94], [94, 95], [96, 97], [98, 104], [105, 107], [108, 111], [112, 119], [120, 127], [127, 128], [129, 130], [131, 137], [138, 140], [141, 144], [145, 152], [153, 158], [159, 170], [171, 174], [175, 188], [189, 196], [196, 197], [198, 201], [202, 203], [204, 210], [211, 213], [214, 217], [218, 225], [226, 229], [230, 239], [240, 247], [247, 248]]}
{"doc_key": "ai-test-35", "ner": [[3, 8, "conference"], [10, 11, "researcher"], [13, 14, "researcher"], [17, 18, "researcher"], [21, 23, "algorithm"], [26, 30, "task"], [32, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 11, 3, 8, "physical", "", false, false], [10, 11, 3, 8, "temporal", "", false, false], [13, 14, 3, 8, "physical", "", false, false], [13, 14, 3, 8, "temporal", "", false, false], [17, 18, 3, 8, "physical", "", false, false], [17, 18, 3, 8, "temporal", "", false, false], [21, 23, 17, 18, "role", "extends", false, false], [26, 30, 17, 18, "role", "extends", false, false], [32, 32, 26, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["At", "the", "2010", "IEEE", "International", "Conference", "on", "Image", "Processing", ",", "Rui", "Hu", ",", "Mark", "Banard", ",", "and", "John", "Collomosse", "extended", "the", "HOG", "descriptor", "for", "use", "in", "sketch", "-", "based", "image", "retrieval", "(", "SBIR", ")", "."], "sentence-detokenized": "At the 2010 IEEE International Conference on Image Processing, Rui Hu, Mark Banard, and John Collomosse extended the HOG descriptor for use in sketch-based image retrieval (SBIR).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 30], [31, 41], [42, 44], [45, 50], [51, 61], [61, 62], [63, 66], [67, 69], [69, 70], [71, 75], [76, 82], [82, 83], [84, 87], [88, 92], [93, 103], [104, 112], [113, 116], [117, 120], [121, 131], [132, 135], [136, 139], [140, 142], [143, 149], [149, 150], [150, 155], [156, 161], [162, 171], [172, 173], [173, 177], [177, 178], [178, 179]]}
{"doc_key": "ai-test-36", "ner": [[0, 0, "metrics"], [6, 6, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["BLEU", "uses", "a", "modified", "form", "of", "precision", "to", "compare", "a", "candidate", "translation", "against", "multiple", "reference", "translations", "."], "sentence-detokenized": "BLEU uses a modified form of precision to compare a candidate translation against multiple reference translations.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 20], [21, 25], [26, 28], [29, 38], [39, 41], [42, 49], [50, 51], [52, 61], [62, 73], [74, 81], [82, 90], [91, 100], [101, 113], [113, 114]]}
{"doc_key": "ai-test-37", "ner": [[31, 35, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "case", "of", "a", "general", "basis", "space", "math", "(", "Y", ",\\", "mathcal", "{", "B", "},\\", "nu", ")", "/", "math", "(", "i.e.", "a", "basis", "space", "that", "is", "not", "countable", ")", ",", "relative", "entropy", "is", "usually", "considered", "."], "sentence-detokenized": "In the case of a general basis space math (Y,\\ mathcal {B},\\ nu) / math (i.e. a basis space that is not countable), relative entropy is usually considered.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 16], [17, 24], [25, 30], [31, 36], [37, 41], [42, 43], [43, 44], [44, 46], [47, 54], [55, 56], [56, 57], [57, 60], [61, 63], [63, 64], [65, 66], [67, 71], [72, 73], [73, 77], [78, 79], [80, 85], [86, 91], [92, 96], [97, 99], [100, 103], [104, 113], [113, 114], [114, 115], [116, 124], [125, 132], [133, 135], [136, 143], [144, 154], [154, 155]]}
{"doc_key": "ai-test-38", "ner": [[10, 11, "country"], [12, 14, "organisation"], [16, 16, "organisation"], [21, 21, "country"], [19, 20, "organisation"], [23, 23, "organisation"], [27, 29, "organisation"], [31, 32, "country"], [33, 38, "organisation"], [40, 44, "organisation"], [47, 47, "misc"], [48, 48, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[12, 14, 10, 11, "physical", "", false, false], [16, 16, 12, 14, "named", "", false, false], [19, 20, 21, 21, "physical", "", false, false], [23, 23, 19, 20, "named", "", false, false], [33, 38, 31, 32, "physical", "", false, false], [40, 44, 33, 38, "named", "", false, false], [47, 47, 48, 48, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "October", "2011", ",", "an", "already", "existing", "partnership", "with", "the", "United", "States", "National", "Park", "Service", "(", "NPS", ")", ",", "Historic", "Scotland", "UK", "(", "HS", ")", ",", "the", "World", "Monuments", "Fund", "and", "Mexico", "'s", "National", "Institute", "for", "Anthropology", "and", "History", "(", "INAH", ")", "was", "significantly", "expanded", ",", ",", "CyArk", "website"], "sentence-detokenized": "In October 2011, an already existing partnership with the United States National Park Service (NPS), Historic Scotland UK (HS), the World Monuments Fund and Mexico's National Institute for Anthropology and History (INAH) was significantly expanded,, CyArk website", "token2charspan": [[0, 2], [3, 10], [11, 15], [15, 16], [17, 19], [20, 27], [28, 36], [37, 48], [49, 53], [54, 57], [58, 64], [65, 71], [72, 80], [81, 85], [86, 93], [94, 95], [95, 98], [98, 99], [99, 100], [101, 109], [110, 118], [119, 121], [122, 123], [123, 125], [125, 126], [126, 127], [128, 131], [132, 137], [138, 147], [148, 152], [153, 156], [157, 163], [163, 165], [166, 174], [175, 184], [185, 188], [189, 201], [202, 205], [206, 213], [214, 215], [215, 219], [219, 220], [221, 224], [225, 238], [239, 247], [247, 248], [248, 249], [250, 255], [256, 263]]}
{"doc_key": "ai-test-39", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [10, 10, "product"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 10, 10, "part-of", "", false, false], [0, 1, 12, 12, "part-of", "", false, false], [10, 10, 6, 7, "general-affiliation", "", false, false], [12, 12, 6, 7, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kernel", "SVMs", "are", "available", "in", "many", "machine", "learning", "toolkits", "including", "LIBSVM", ",", "MATLAB", "and", "others", "."], "sentence-detokenized": "Kernel SVMs are available in many machine learning toolkits including LIBSVM, MATLAB and others.", "token2charspan": [[0, 6], [7, 11], [12, 15], [16, 25], [26, 28], [29, 33], [34, 41], [42, 50], [51, 59], [60, 69], [70, 76], [76, 77], [78, 84], [85, 88], [89, 95], [95, 96]]}
{"doc_key": "ai-test-40", "ner": [[2, 6, "misc"], [12, 13, "location"], [15, 17, "location"], [19, 20, "country"], [23, 25, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 6, 12, 13, "physical", "", false, false], [2, 6, 23, 25, "temporal", "", false, false], [12, 13, 15, 17, "physical", "", false, false], [15, 17, 19, 20, "physical", "", false, false], [23, 25, 12, 13, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "2009", "Loebner", "Prize", "was", "held", "on", "6", "September", "2009", "at", "the", "Brighton", "Centre", "in", "Brighton", ",", "UK", ",", "as", "part", "of", "the", "Interspeech", "2009", "conference", "."], "sentence-detokenized": "The 2009 Loebner Prize was held on 6 September 2009 at the Brighton Centre in Brighton, UK, as part of the Interspeech 2009 conference.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 26], [27, 31], [32, 34], [35, 36], [37, 46], [47, 51], [52, 54], [55, 58], [59, 67], [68, 74], [75, 77], [78, 86], [86, 87], [88, 90], [90, 91], [92, 94], [95, 99], [100, 102], [103, 106], [107, 118], [119, 123], [124, 134], [134, 135]]}
{"doc_key": "ai-test-41", "ner": [[0, 3, "product"], [10, 10, "product"], [16, 18, "product"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 21, 0, 3, "part-of", "", false, false], [19, 21, 10, 10, "part-of", "", false, false], [19, 21, 16, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "QRIO", "humanoid", "robot", "was", "designed", "as", "a", "successor", "to", "AIBO", "and", "uses", "the", "same", "basic", "R", "-", "CODE", "Aperios", "operating", "system", "."], "sentence-detokenized": "The QRIO humanoid robot was designed as a successor to AIBO and uses the same basic R-CODE Aperios operating system.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 23], [24, 27], [28, 36], [37, 39], [40, 41], [42, 51], [52, 54], [55, 59], [60, 63], [64, 68], [69, 72], [73, 77], [78, 83], [84, 85], [85, 86], [86, 90], [91, 98], [99, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-test-42", "ner": [[0, 1, "misc"], [6, 6, "algorithm"], [11, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 0, 1, "cause-effect", "", true, false], [11, 13, 0, 1, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Speech", "curves", "are", "generated", "from", "the", "HMMs", "themselves", "based", "on", "the", "maximum", "likelihood", "criterion", "."], "sentence-detokenized": "Speech curves are generated from the HMMs themselves based on the maximum likelihood criterion.", "token2charspan": [[0, 6], [7, 13], [14, 17], [18, 27], [28, 32], [33, 36], [37, 41], [42, 52], [53, 58], [59, 61], [62, 65], [66, 73], [74, 84], [85, 94], [94, 95]]}
{"doc_key": "ai-test-43", "ner": [[0, 1, "product"], [5, 8, "task"], [10, 12, "task"], [16, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 5, 8, "type-of", "", false, false], [0, 1, 10, 12, "type-of", "", false, false], [0, 1, 16, 18, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "is", "a", "free", "multilingual", "statistical", "machine", "translation", "and", "neural", "machine", "translation", "service", "developed", "by", "Google", "to", "translate", "text", "and", "web", "pages", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Google Translate is a free multilingual statistical machine translation and neural machine translation service developed by Google to translate text and web pages from one language to another.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 39], [40, 51], [52, 59], [60, 71], [72, 75], [76, 82], [83, 90], [91, 102], [103, 110], [111, 120], [121, 123], [124, 130], [131, 133], [134, 143], [144, 148], [149, 152], [153, 156], [157, 162], [163, 167], [168, 171], [172, 180], [181, 183], [184, 191], [191, 192]]}
{"doc_key": "ai-test-44", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [15, 18, "field"], [22, 24, "task"], [27, 27, "task"], [29, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[22, 24, 5, 6, "part-of", "", false, true], [22, 24, 8, 9, "part-of", "", false, true], [22, 24, 11, 12, "part-of", "", false, true], [27, 27, 5, 6, "part-of", "", false, true], [27, 27, 8, 9, "part-of", "", false, true], [27, 27, 11, 12, "part-of", "", false, true], [29, 33, 5, 6, "part-of", "", false, true], [29, 33, 8, 9, "part-of", "", false, true], [29, 33, 11, 12, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Skeletons", "are", "widely", "used", "in", "computer", "vision", ",", "image", "analysis", ",", "pattern", "recognition", ",", "and", "digital", "image", "processing", "for", "purposes", "such", "as", "optical", "character", "recognition", ",", "fingerprint", "recognition", ",", "visual", "inspection", ",", "or", "compression", "."], "sentence-detokenized": "Skeletons are widely used in computer vision, image analysis, pattern recognition, and digital image processing for purposes such as optical character recognition, fingerprint recognition, visual inspection, or compression.", "token2charspan": [[0, 9], [10, 13], [14, 20], [21, 25], [26, 28], [29, 37], [38, 44], [44, 45], [46, 51], [52, 60], [60, 61], [62, 69], [70, 81], [81, 82], [83, 86], [87, 94], [95, 100], [101, 111], [112, 115], [116, 124], [125, 129], [130, 132], [133, 140], [141, 150], [151, 162], [162, 163], [164, 175], [176, 187], [187, 188], [189, 195], [196, 206], [206, 207], [208, 210], [211, 222], [222, 223]]}
{"doc_key": "ai-test-45", "ner": [[0, 6, "conference"], [11, 15, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 6, 11, 15, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "is", "the", "benchmark", "in", "object", "classification", "and", "detection", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "The ImageNet Large Scale Visual Recognition Challenge is the benchmark in object classification and detection with millions of images and hundreds of object classes.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 24], [25, 31], [32, 43], [44, 53], [54, 56], [57, 60], [61, 70], [71, 73], [74, 80], [81, 95], [96, 99], [100, 109], [110, 114], [115, 123], [124, 126], [127, 133], [134, 137], [138, 146], [147, 149], [150, 156], [157, 164], [164, 165]]}
{"doc_key": "ai-test-46", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [16, 19, "misc"], [22, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 16, 19, "part-of", "", false, false], [0, 0, 22, 25, "part-of", "", false, false], [4, 5, 16, 19, "part-of", "", false, false], [4, 5, 22, 25, "part-of", "", false, false], [7, 8, 16, 19, "part-of", "", false, false], [7, 8, 22, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Bengio", ",", "along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "are", "hailed", "by", "some", "as", "the", "godfathers", "of", "artificial", "intelligence", "and", "the", "godfathers", "of", "deep", "learning", "."], "sentence-detokenized": "Bengio, along with Geoffrey Hinton and Yann LeCun, are hailed by some as the godfathers of artificial intelligence and the godfathers of deep learning.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 18], [19, 27], [28, 34], [35, 38], [39, 43], [44, 49], [49, 50], [51, 54], [55, 61], [62, 64], [65, 69], [70, 72], [73, 76], [77, 87], [88, 90], [91, 101], [102, 114], [115, 118], [119, 122], [123, 133], [134, 136], [137, 141], [142, 150], [150, 151]]}
{"doc_key": "ai-test-47", "ner": [[6, 7, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "life", "member", "of", "the", "IEEE", "."], "sentence-detokenized": "He is a life member of the IEEE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 19], [20, 22], [23, 26], [27, 31], [31, 32]]}
{"doc_key": "ai-test-48", "ner": [[0, 2, "organisation"], [13, 18, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 13, 18, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NSA", "Bethesda", "is", "responsible", "for", "base", "operational", "support", "for", "its", "primary", "tenant", ",", "Walter", "Reed", "National", "Military", "Medical", "Center", "."], "sentence-detokenized": "NSA Bethesda is responsible for base operational support for its primary tenant, Walter Reed National Military Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 31], [32, 36], [37, 48], [49, 56], [57, 60], [61, 64], [65, 72], [73, 79], [79, 80], [81, 87], [88, 92], [93, 101], [102, 110], [111, 118], [119, 125], [125, 126]]}
{"doc_key": "ai-test-49", "ner": [[7, 8, "field"], [10, 11, "field"], [14, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "three", "main", "paradigms", "of", "learning", "are", "supervised", "learning", ",", "unsupervised", "learning", ",", "and", "learning", "by", "reinforcement", "."], "sentence-detokenized": "The three main paradigms of learning are supervised learning, unsupervised learning, and learning by reinforcement.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 24], [25, 27], [28, 36], [37, 40], [41, 51], [52, 60], [60, 61], [62, 74], [75, 83], [83, 84], [85, 88], [89, 97], [98, 100], [101, 114], [114, 115]]}
{"doc_key": "ai-test-50", "ner": [[2, 2, "task"], [4, 6, "task"], [10, 14, "task"], [16, 17, "task"], [19, 21, "task"], [23, 24, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Examples", "include", "checking", ",", "planning", "and", "scheduling", ",", "ability", "to", "answer", "diagnostic", "and", "consumer", "questions", ",", "handwriting", "recognition", ",", "natural", "language", "understanding", ",", "speech", "recognition", ",", "and", "facial", "recognition", "."], "sentence-detokenized": "Examples include checking, planning and scheduling, ability to answer diagnostic and consumer questions, handwriting recognition, natural language understanding, speech recognition, and facial recognition.", "token2charspan": [[0, 8], [9, 16], [17, 25], [25, 26], [27, 35], [36, 39], [40, 50], [50, 51], [52, 59], [60, 62], [63, 69], [70, 80], [81, 84], [85, 93], [94, 103], [103, 104], [105, 116], [117, 128], [128, 129], [130, 137], [138, 146], [147, 160], [160, 161], [162, 168], [169, 180], [180, 181], [182, 185], [186, 192], [193, 204], [204, 205]]}
{"doc_key": "ai-test-51", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1991", ",", "he", "was", "elected", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "1990", ",", "founding", "member", ")", "."], "sentence-detokenized": "In 1991, he was elected a member of the Association for the Advancement of Artificial Intelligence (1990, founding member).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [99, 100], [100, 104], [104, 105], [106, 114], [115, 121], [121, 122], [122, 123]]}
{"doc_key": "ai-test-52", "ner": [[11, 12, "misc"], [15, 16, "algorithm"], [27, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "by", "formulating", "the", "problem", "as", "a", "solution", "of", "the", "Toeplitz", "matrix", "and", "using", "Levinson", "recursion", ",", "we", "can", "estimate", "the", "filter", "with", "the", "smallest", "possible", "mean", "squared", "error", "quite", "quickly", "."], "sentence-detokenized": "However, by formulating the problem as a solution of the Toeplitz matrix and using Levinson recursion, we can estimate the filter with the smallest possible mean squared error quite quickly.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 23], [24, 27], [28, 35], [36, 38], [39, 40], [41, 49], [50, 52], [53, 56], [57, 65], [66, 72], [73, 76], [77, 82], [83, 91], [92, 101], [101, 102], [103, 105], [106, 109], [110, 118], [119, 122], [123, 129], [130, 134], [135, 138], [139, 147], [148, 156], [157, 161], [162, 169], [170, 175], [176, 181], [182, 189], [189, 190]]}
{"doc_key": "ai-test-53", "ner": [[5, 15, "conference"], [16, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 15, 16, 20, "physical", "", false, false], [16, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2011", ",", "the", "15th", "edition", "of", "Campus", "Party", "Spain", "will", "take", "place", "in", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", "."], "sentence-detokenized": "In July 2011, the 15th edition of Campus Party Spain will take place in the City of Arts and Sciences in Valencia.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 22], [23, 30], [31, 33], [34, 40], [41, 46], [47, 52], [53, 57], [58, 62], [63, 68], [69, 71], [72, 75], [76, 80], [81, 83], [84, 88], [89, 92], [93, 101], [102, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-test-54", "ner": [[14, 14, "product"], [16, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Often", "this", "is", "only", "possible", "at", "the", "very", "end", "of", "complicated", "games", "such", "as", "chess", "or", "go", ",", "because", "it", "is", "not", "computationally", "possible", "to", "look", "ahead", "to", "the", "end", "of", "the", "game", ",", "except", "at", "the", "end", ",", "and", "instead", "finite", "values", "are", "assigned", "to", "positions", "as", "estimates", "of", "the", "degree", "of", "belief", "that", "they", "will", "lead", "to", "a", "win", "for", "one", "player", "or", "the", "other", "."], "sentence-detokenized": "Often this is only possible at the very end of complicated games such as chess or go, because it is not computationally possible to look ahead to the end of the game, except at the end, and instead finite values are assigned to positions as estimates of the degree of belief that they will lead to a win for one player or the other.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 18], [19, 27], [28, 30], [31, 34], [35, 39], [40, 43], [44, 46], [47, 58], [59, 64], [65, 69], [70, 72], [73, 78], [79, 81], [82, 84], [84, 85], [86, 93], [94, 96], [97, 99], [100, 103], [104, 119], [120, 128], [129, 131], [132, 136], [137, 142], [143, 145], [146, 149], [150, 153], [154, 156], [157, 160], [161, 165], [165, 166], [167, 173], [174, 176], [177, 180], [181, 184], [184, 185], [186, 189], [190, 197], [198, 204], [205, 211], [212, 215], [216, 224], [225, 227], [228, 237], [238, 240], [241, 250], [251, 253], [254, 257], [258, 264], [265, 267], [268, 274], [275, 279], [280, 284], [285, 289], [290, 294], [295, 297], [298, 299], [300, 303], [304, 307], [308, 311], [312, 318], [319, 321], [322, 325], [326, 331], [331, 332]]}
{"doc_key": "ai-test-55", "ner": [[4, 6, "algorithm"], [23, 24, "algorithm"], [26, 27, "algorithm"], [30, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 23, 24, "compare", "", false, false], [4, 6, 26, 27, "compare", "", false, false], [4, 6, 30, 32, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "difference", "between", "the", "multinomial", "logit", "model", "and", "many", "other", "methods", ",", "models", ",", "algorithms", ",", "etc.", "with", "the", "same", "basic", "setup", "(", "perceptron", "algorithm", ",", "support", "vector", "machines", ",", "linear", "discriminant", "analysis", ",", "etc", "."], "sentence-detokenized": "The difference between the multinomial logit model and many other methods, models, algorithms, etc. with the same basic setup (perceptron algorithm, support vector machines, linear discriminant analysis, etc.", "token2charspan": [[0, 3], [4, 14], [15, 22], [23, 26], [27, 38], [39, 44], [45, 50], [51, 54], [55, 59], [60, 65], [66, 73], [73, 74], [75, 81], [81, 82], [83, 93], [93, 94], [95, 99], [100, 104], [105, 108], [109, 113], [114, 119], [120, 125], [126, 127], [127, 137], [138, 147], [147, 148], [149, 156], [157, 163], [164, 172], [172, 173], [174, 180], [181, 193], [194, 202], [202, 203], [204, 207], [207, 208]]}
{"doc_key": "ai-test-56", "ner": [[0, 3, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Association", "for", "Computational", "Linguistics", ",", "ed."], "sentence-detokenized": "Association for Computational Linguistics, ed.", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [41, 42], [43, 46]]}
{"doc_key": "ai-test-57", "ner": [[3, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "a", "computer", "face", "recognition", "system", ",", "each", "face", "is", "represented", "by", "a", "large", "number", "of", "pixel", "values", "."], "sentence-detokenized": "In a computer face recognition system, each face is represented by a large number of pixel values.", "token2charspan": [[0, 2], [3, 4], [5, 13], [14, 18], [19, 30], [31, 37], [37, 38], [39, 43], [44, 48], [49, 51], [52, 63], [64, 66], [67, 68], [69, 74], [75, 81], [82, 84], [85, 90], [91, 97], [97, 98]]}
{"doc_key": "ai-test-58", "ner": [[5, 8, "person"], [13, 15, "organisation"], [22, 24, "country"], [25, 25, "person"], [35, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 8, 13, 15, "role", "", false, false], [5, 8, 22, 24, "physical", "", false, false], [25, 25, 35, 37, "origin", "", false, false], [25, 25, 35, 37, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2002", ",", "his", "son", "Daniel", "Pearl", ",", "a", "journalist", "working", "for", "the", "Wall", "Street", "Journal", ",", "was", "kidnapped", "and", "murdered", "in", "Pakistan", ",", "leading", "Judea", "and", "other", "family", "members", "and", "friends", "to", "establish", "the", "Daniel", "Pearl", "Foundation", "."], "sentence-detokenized": "In 2002, his son Daniel Pearl, a journalist working for the Wall Street Journal, was kidnapped and murdered in Pakistan, leading Judea and other family members and friends to establish the Daniel Pearl Foundation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 23], [24, 29], [29, 30], [31, 32], [33, 43], [44, 51], [52, 55], [56, 59], [60, 64], [65, 71], [72, 79], [79, 80], [81, 84], [85, 94], [95, 98], [99, 107], [108, 110], [111, 119], [119, 120], [121, 128], [129, 134], [135, 138], [139, 144], [145, 151], [152, 159], [160, 163], [164, 171], [172, 174], [175, 184], [185, 188], [189, 195], [196, 201], [202, 212], [212, 213]]}
{"doc_key": "ai-test-59", "ner": [[4, 8, "organisation"], [16, 17, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 8, 16, 17, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "late", "2006", ",", "Red", "Envelope", "Entertainment", "expanded", "into", "original", "content", "production", "with", "filmmakers", "such", "as", "John", "Waters", "."], "sentence-detokenized": "In late 2006, Red Envelope Entertainment expanded into original content production with filmmakers such as John Waters.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 26], [27, 40], [41, 49], [50, 54], [55, 63], [64, 71], [72, 82], [83, 87], [88, 98], [99, 103], [104, 106], [107, 111], [112, 118], [118, 119]]}
{"doc_key": "ai-test-60", "ner": [[7, 11, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "building", "is", "now", "part", "of", "the", "Beth", "Israel", "Deaconess", "Medical", "Center", "."], "sentence-detokenized": "The building is now part of the Beth Israel Deaconess Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 31], [32, 36], [37, 43], [44, 53], [54, 61], [62, 68], [68, 69]]}
{"doc_key": "ai-test-61", "ner": [[18, 19, "field"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "common", "theme", "of", "this", "thesis", "is", "the", "adoption", "of", "a", "sign", "-", "theoretic", "perspective", "on", "issues", "of", "artificial", "intelligence", "and", "knowledge", "representation", "."], "sentence-detokenized": "A common theme of this thesis is the adoption of a sign-theoretic perspective on issues of artificial intelligence and knowledge representation.", "token2charspan": [[0, 1], [2, 8], [9, 14], [15, 17], [18, 22], [23, 29], [30, 32], [33, 36], [37, 45], [46, 48], [49, 50], [51, 55], [55, 56], [56, 65], [66, 77], [78, 80], [81, 87], [88, 90], [91, 101], [102, 114], [115, 118], [119, 128], [129, 143], [143, 144]]}
{"doc_key": "ai-test-62", "ner": [[5, 7, "task"], [9, 9, "task"], [15, 16, "task"], [39, 40, "task"], [42, 45, "task"], [48, 50, "task"], [52, 52, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 7, 15, 16, "type-of", "", false, false], [5, 7, 48, 50, "compare", "", false, false], [5, 7, 48, 50, "opposite", "", false, false], [9, 9, 5, 7, "named", "", false, false], [39, 40, 48, 50, "part-of", "", false, false], [42, 45, 48, 50, "part-of", "", false, false], [48, 50, 15, 16, "type-of", "", false, false], [52, 52, 48, 50, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["For", "example", ",", "the", "term", "neural", "machine", "translation", "(", "NMT", ")", "highlights", "the", "fact", "that", "machine", "translation", "approaches", "based", "on", "deep", "learning", "directly", "learn", "sequence", "-", "to", "-", "sequence", "transformations", ",", "eliminating", "the", "need", "for", "intermediate", "steps", "such", "as", "word", "alignment", "and", "language", "modeling", "that", "were", "used", "in", "statistical", "machine", "translation", "(", "SMT", ")", "."], "sentence-detokenized": "For example, the term neural machine translation (NMT) highlights the fact that machine translation approaches based on deep learning directly learn sequence-to-sequence transformations, eliminating the need for intermediate steps such as word alignment and language modeling that were used in statistical machine translation (SMT).", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 36], [37, 48], [49, 50], [50, 53], [53, 54], [55, 65], [66, 69], [70, 74], [75, 79], [80, 87], [88, 99], [100, 110], [111, 116], [117, 119], [120, 124], [125, 133], [134, 142], [143, 148], [149, 157], [157, 158], [158, 160], [160, 161], [161, 169], [170, 185], [185, 186], [187, 198], [199, 202], [203, 207], [208, 211], [212, 224], [225, 230], [231, 235], [236, 238], [239, 243], [244, 253], [254, 257], [258, 266], [267, 275], [276, 280], [281, 285], [286, 290], [291, 293], [294, 305], [306, 313], [314, 325], [326, 327], [327, 330], [330, 331], [331, 332]]}
{"doc_key": "ai-test-63", "ner": [[6, 6, "field"], [11, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 6, 11, 12, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Most", "of", "the", "research", "in", "the", "WSD", "area", "is", "done", "using", "Word", "Net", "as", "a", "reference", "inventory", "of", "meanings", "."], "sentence-detokenized": "Most of the research in the WSD area is done using WordNet as a reference inventory of meanings.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 20], [21, 23], [24, 27], [28, 31], [32, 36], [37, 39], [40, 44], [45, 50], [51, 55], [55, 58], [59, 61], [62, 63], [64, 73], [74, 83], [84, 86], [87, 95], [95, 96]]}
{"doc_key": "ai-test-64", "ner": [[2, 3, "misc"], [10, 11, "researcher"], [13, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 2, 3, "general-affiliation", "", false, true], [13, 14, 2, 3, "general-affiliation", "", false, true]], "relations_mapping_to_source": [0, 1], "sentence": ["Notable", "former", "PhD", "students", "and", "postdocs", "in", "his", "group", "include", "Richard", "Zemel", "and", "Zoubin", "Ghahramani", "."], "sentence-detokenized": "Notable former PhD students and postdocs in his group include Richard Zemel and Zoubin Ghahramani.", "token2charspan": [[0, 7], [8, 14], [15, 18], [19, 27], [28, 31], [32, 40], [41, 43], [44, 47], [48, 53], [54, 61], [62, 69], [70, 75], [76, 79], [80, 86], [87, 97], [97, 98]]}
{"doc_key": "ai-test-65", "ner": [[7, 8, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 14, 15, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Each", "prediction", "result", "or", "instance", "of", "the", "confusion", "matrix", "represents", "one", "point", "in", "the", "ROC", "space", "."], "sentence-detokenized": "Each prediction result or instance of the confusion matrix represents one point in the ROC space.", "token2charspan": [[0, 4], [5, 15], [16, 22], [23, 25], [26, 34], [35, 37], [38, 41], [42, 51], [52, 58], [59, 69], [70, 73], [74, 79], [80, 82], [83, 86], [87, 90], [91, 96], [96, 97]]}
{"doc_key": "ai-test-66", "ner": [[3, 3, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [14, 19, "product"], [22, 24, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 22, 24, "physical", "", false, false], [7, 8, 22, 24, "physical", "", false, false], [10, 11, 22, 24, "physical", "", false, false], [14, 19, 3, 3, "artifact", "", false, false], [14, 19, 7, 8, "artifact", "", false, false], [14, 19, 10, 11, "artifact", "", false, false], [14, 19, 22, 24, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "1997", ",", "Thrun", "and", "his", "colleagues", "Wolfram", "Burgard", "and", "Dieter", "Fox", "developed", "the", "world", "'s", "first", "robotic", "tour", "guide", "at", "the", "Deutsches", "Museum", "Bonn", "(", "1997", ")", "."], "sentence-detokenized": "In 1997, Thrun and his colleagues Wolfram Burgard and Dieter Fox developed the world's first robotic tour guide at the Deutsches Museum Bonn (1997).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 18], [19, 22], [23, 33], [34, 41], [42, 49], [50, 53], [54, 60], [61, 64], [65, 74], [75, 78], [79, 84], [84, 86], [87, 92], [93, 100], [101, 105], [106, 111], [112, 114], [115, 118], [119, 128], [129, 135], [136, 140], [141, 142], [142, 146], [146, 147], [147, 148]]}
{"doc_key": "ai-test-67", "ner": [[0, 1, "product"], [7, 7, "misc"], [21, 23, "field"], [25, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 0, 1, "part-of", "", false, false], [21, 23, 0, 1, "usage", "", false, false], [25, 27, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Word", "Net", "is", "a", "lexical", "database", "of", "semantic", "relations", "between", "words", "in", "more", "than", "200", "languages.Its", "main", "use", "is", "in", "automatic", "natural", "language", "processing", "and", "artificial", "intelligence", "applications", "."], "sentence-detokenized": "WordNet is a lexical database of semantic relations between words in more than 200 languages.Its main use is in automatic natural language processing and artificial intelligence applications.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 32], [33, 41], [42, 51], [52, 59], [60, 65], [66, 68], [69, 73], [74, 78], [79, 82], [83, 96], [97, 101], [102, 105], [106, 108], [109, 111], [112, 121], [122, 129], [130, 138], [139, 149], [150, 153], [154, 164], [165, 177], [178, 190], [190, 191]]}
{"doc_key": "ai-test-68", "ner": [[2, 3, "field"], [17, 20, "conference"], [23, 31, "conference"], [33, 33, "conference"], [36, 36, "conference"], [4, 5, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[17, 20, 2, 3, "topic", "", false, false], [17, 20, 4, 5, "topic", "", false, false], [23, 31, 2, 3, "topic", "", false, false], [23, 31, 4, 5, "topic", "", false, false], [33, 33, 2, 3, "topic", "", false, false], [33, 33, 4, 5, "topic", "", false, false], [36, 36, 2, 3, "topic", "", false, false], [36, 36, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Papers", "on", "natural", "language", "processing", "are", "beginning", "to", "appear", "at", "natural", "language", "processing", "conferences", "such", "as", "the", "Association", "for", "Computational", "Linguistics", ",", "the", "North", "American", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "EMNLP", ",", "and", "HLT", "."], "sentence-detokenized": "Papers on natural language processing are beginning to appear at natural language processing conferences such as the Association for Computational Linguistics, the North American Chapter of the Association for Computational Linguistics, EMNLP, and HLT.", "token2charspan": [[0, 6], [7, 9], [10, 17], [18, 26], [27, 37], [38, 41], [42, 51], [52, 54], [55, 61], [62, 64], [65, 72], [73, 81], [82, 92], [93, 104], [105, 109], [110, 112], [113, 116], [117, 128], [129, 132], [133, 146], [147, 158], [158, 159], [160, 163], [164, 169], [170, 178], [179, 186], [187, 189], [190, 193], [194, 205], [206, 209], [210, 223], [224, 235], [235, 236], [237, 242], [242, 243], [244, 247], [248, 251], [251, 252]]}
{"doc_key": "ai-test-69", "ner": [[3, 3, "programlang"], [20, 24, "misc"], [33, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "set", "of", "Java", "programs", "uses", "a", "lexicon", "to", "handle", "variation", "in", "biomedical", "texts", "by", "linking", "words", "according", "to", "their", "parts", "of", "speech", ",", "which", "can", "be", "useful", "for", "searching", "the", "Web", "or", "electronic", "medical", "records", "."], "sentence-detokenized": "A set of Java programs uses a lexicon to handle variation in biomedical texts by linking words according to their parts of speech, which can be useful for searching the Web or electronic medical records.", "token2charspan": [[0, 1], [2, 5], [6, 8], [9, 13], [14, 22], [23, 27], [28, 29], [30, 37], [38, 40], [41, 47], [48, 57], [58, 60], [61, 71], [72, 77], [78, 80], [81, 88], [89, 94], [95, 104], [105, 107], [108, 113], [114, 119], [120, 122], [123, 129], [129, 130], [131, 136], [137, 140], [141, 143], [144, 150], [151, 154], [155, 164], [165, 168], [169, 172], [173, 175], [176, 186], [187, 194], [195, 202], [202, 203]]}
{"doc_key": "ai-test-70", "ner": [[7, 7, "algorithm"], [9, 9, "algorithm"], [11, 11, "algorithm"], [13, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "many", "newer", "algorithms", "such", "as", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", "and", "others", "."], "sentence-detokenized": "There are many newer algorithms such as LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost and others.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 20], [21, 31], [32, 36], [37, 39], [40, 47], [47, 48], [49, 59], [59, 60], [61, 71], [71, 72], [73, 80], [80, 81], [82, 91], [92, 95], [96, 102], [102, 103]]}
{"doc_key": "ai-test-71", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "of", "a", "Python", "implementation", ":"], "sentence-detokenized": "This is an example of a Python implementation:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 23], [24, 30], [31, 45], [45, 46]]}
{"doc_key": "ai-test-72", "ner": [[0, 0, "organisation"], [2, 2, "product"], [7, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 0, 0, "artifact", "made_by_company", false, false], [7, 12, 2, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Mattel", "'s", "Intellivision", "game", "console", "offered", "the", "Intellivoice", "Voice", "Synthesis", "module", "in", "1982", "."], "sentence-detokenized": "Mattel's Intellivision game console offered the Intellivoice Voice Synthesis module in 1982.", "token2charspan": [[0, 6], [6, 8], [9, 22], [23, 27], [28, 35], [36, 43], [44, 47], [48, 60], [61, 66], [67, 76], [77, 83], [84, 86], [87, 91], [91, 92]]}
{"doc_key": "ai-test-73", "ner": [[5, 8, "task"], [10, 16, "task"], [18, 19, "field"], [21, 23, "task"], [27, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 16, 5, 8, "part-of", "", false, false], [18, 19, 5, 8, "part-of", "", false, false], [21, 23, 5, 8, "part-of", "", false, false], [27, 31, 21, 23, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "has", "also", "worked", "on", "machine", "translation", ",", "both", "on", "high", "-", "precision", "knowledge", "-", "based", "MT", "and", "machine", "learning", "for", "statistical", "machine", "translation", "(", "e.g.", ",", "MT", "based", "on", "generalized", "examples", ")", "."], "sentence-detokenized": "He has also worked on machine translation, both on high-precision knowledge-based MT and machine learning for statistical machine translation (e.g., MT based on generalized examples).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 21], [22, 29], [30, 41], [41, 42], [43, 47], [48, 50], [51, 55], [55, 56], [56, 65], [66, 75], [75, 76], [76, 81], [82, 84], [85, 88], [89, 96], [97, 105], [106, 109], [110, 121], [122, 129], [130, 141], [142, 143], [143, 147], [147, 148], [149, 151], [152, 157], [158, 160], [161, 172], [173, 181], [181, 182], [182, 183]]}
{"doc_key": "ai-test-74", "ner": [[0, 1, "misc"], [7, 7, "misc"], [21, 22, "algorithm"], [24, 25, "field"], [27, 28, "field"], [30, 30, "field"], [32, 33, "field"], [35, 35, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 21, 22, "general-affiliation", "", false, false], [0, 1, 24, 25, "general-affiliation", "", false, false], [0, 1, 27, 28, "general-affiliation", "", false, false], [0, 1, 30, 30, "general-affiliation", "", false, false], [0, 1, 32, 33, "general-affiliation", "", false, false], [0, 1, 35, 35, "general-affiliation", "", false, false], [7, 7, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "usually", "referred", "to", "as", "Mathematica", ")", "is", "an", "advanced", "technical", "computing", "system", "covering", "most", "technical", "areas", "-", "including", "neural", "networks", ",", "machine", "learning", ",", "image", "processing", ",", "geometry", ",", "data", "science", ",", "visualization", ",", "and", "more", "."], "sentence-detokenized": "Wolfram Mathematica (usually referred to as Mathematica) is an advanced technical computing system covering most technical areas - including neural networks, machine learning, image processing, geometry, data science, visualization, and more.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 28], [29, 37], [38, 40], [41, 43], [44, 55], [55, 56], [57, 59], [60, 62], [63, 71], [72, 81], [82, 91], [92, 98], [99, 107], [108, 112], [113, 122], [123, 128], [129, 130], [131, 140], [141, 147], [148, 156], [156, 157], [158, 165], [166, 174], [174, 175], [176, 181], [182, 192], [192, 193], [194, 202], [202, 203], [204, 208], [209, 216], [216, 217], [218, 231], [231, 232], [233, 236], [237, 241], [241, 242]]}
{"doc_key": "ai-test-75", "ner": [[2, 6, "product"], [10, 13, "researcher"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 17, 2, 6, "type-of", "", false, false], [17, 17, 10, 13, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "digitally", "controlled", "and", "programmable", "robot", "was", "invented", "by", "George", "Devol", "in", "1954", "and", "eventually", "named", "Unimate", "."], "sentence-detokenized": "The first digitally controlled and programmable robot was invented by George Devol in 1954 and eventually named Unimate.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 30], [31, 34], [35, 47], [48, 53], [54, 57], [58, 66], [67, 69], [70, 76], [77, 82], [83, 85], [86, 90], [91, 94], [95, 105], [106, 111], [112, 119], [119, 120]]}
{"doc_key": "ai-test-76", "ner": [[2, 2, "algorithm"], [4, 4, "algorithm"], [19, 22, "task"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 4, 4, "compare", "", false, false], [4, 4, 19, 22, "general-affiliation", "", false, false], [4, 4, 21, 22, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Similar", "to", "DBNs", ",", "DBMs", "can", "learn", "complex", "and", "abstract", "internal", "representations", "of", "input", "data", "in", "tasks", "such", "as", "object", "or", "speech", "recognition", ",", "using", "limited", "labeled", "data", "to", "fine", "-", "tune", "representations", "created", "using", "a", "large", "set", "of", "unlabeled", "sensory", "input", "data", "."], "sentence-detokenized": "Similar to DBNs, DBMs can learn complex and abstract internal representations of input data in tasks such as object or speech recognition, using limited labeled data to fine-tune representations created using a large set of unlabeled sensory input data.", "token2charspan": [[0, 7], [8, 10], [11, 15], [15, 16], [17, 21], [22, 25], [26, 31], [32, 39], [40, 43], [44, 52], [53, 61], [62, 77], [78, 80], [81, 86], [87, 91], [92, 94], [95, 100], [101, 105], [106, 108], [109, 115], [116, 118], [119, 125], [126, 137], [137, 138], [139, 144], [145, 152], [153, 160], [161, 165], [166, 168], [169, 173], [173, 174], [174, 178], [179, 194], [195, 202], [203, 208], [209, 210], [211, 216], [217, 220], [221, 223], [224, 233], [234, 241], [242, 247], [248, 252], [252, 253]]}
{"doc_key": "ai-test-77", "ner": [[6, 10, "task"], [14, 14, "conference"], [16, 16, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 6, 10, "topic", "", false, false], [16, 16, 6, 10, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "scientific", "conferences", "where", "papers", "on", "vision", "-", "based", "activity", "recognition", "often", "appear", "are", "ICCV", "and", "CVPR", "."], "sentence-detokenized": "The scientific conferences where papers on vision-based activity recognition often appear are ICCV and CVPR.", "token2charspan": [[0, 3], [4, 14], [15, 26], [27, 32], [33, 39], [40, 42], [43, 49], [49, 50], [50, 55], [56, 64], [65, 76], [77, 82], [83, 89], [90, 93], [94, 98], [99, 102], [103, 107], [107, 108]]}
{"doc_key": "ai-test-78", "ner": [[1, 3, "field"], [4, 5, "algorithm"], [7, 7, "algorithm"], [16, 17, "metrics"], [19, 21, "metrics"], [23, 23, "metrics"], [36, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 5, 1, 3, "part-of", "", false, false], [4, 5, 16, 17, "related-to", "finds", false, false], [4, 5, 19, 21, "related-to", "finds", false, false], [4, 5, 36, 37, "related-to", "", false, false], [7, 7, 4, 5, "named", "", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "statistics", ",", "the", "expectation", "maximization", "(", "EM", ")", "algorithm", "is", "an", "iterative", "method", "for", "finding", "maximum", "likelihood", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "parameter", "estimates", "in", "statistical", "models", "where", "the", "model", "depends", "on", "unobserved", "latent", "variables", "."], "sentence-detokenized": "In statistics, the expectation maximization (EM) algorithm is an iterative method for finding maximum likelihood or maximum a posteriori (MAP) parameter estimates in statistical models where the model depends on unobserved latent variables.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 30], [31, 43], [44, 45], [45, 47], [47, 48], [49, 58], [59, 61], [62, 64], [65, 74], [75, 81], [82, 85], [86, 93], [94, 101], [102, 112], [113, 115], [116, 123], [124, 125], [126, 136], [137, 138], [138, 141], [141, 142], [143, 152], [153, 162], [163, 165], [166, 177], [178, 184], [185, 190], [191, 194], [195, 200], [201, 208], [209, 211], [212, 222], [223, 229], [230, 239], [239, 240]]}
{"doc_key": "ai-test-79", "ner": [[5, 7, "metrics"], [9, 13, "metrics"], [14, 16, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 13, 5, 7, "named", "", false, false], [18, 18, 14, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Similarly", ",", "investigators", "sometimes", "report", "false", "positive", "rates", "(", "FPRs", ")", "as", "well", "as", "false", "negative", "rates", "(", "FNRs", ")", "."], "sentence-detokenized": "Similarly, investigators sometimes report false positive rates (FPRs) as well as false negative rates (FNRs).", "token2charspan": [[0, 9], [9, 10], [11, 24], [25, 34], [35, 41], [42, 47], [48, 56], [57, 62], [63, 64], [64, 68], [68, 69], [70, 72], [73, 77], [78, 80], [81, 86], [87, 95], [96, 101], [102, 103], [103, 107], [107, 108], [108, 109]]}
{"doc_key": "ai-test-80", "ner": [[6, 13, "metrics"], [15, 16, "field"], [19, 21, "metrics"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 16, 6, 13, "usage", "", false, false], [23, 24, 19, 21, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "concept", "is", "similar", "to", "the", "signal", "-", "to", "-", "noise", "ratio", "used", "in", "the", "natural", "sciences", "and", "the", "confusion", "matrix", "used", "in", "artificial", "intelligence", "."], "sentence-detokenized": "This concept is similar to the signal-to-noise ratio used in the natural sciences and the confusion matrix used in artificial intelligence.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 23], [24, 26], [27, 30], [31, 37], [37, 38], [38, 40], [40, 41], [41, 46], [47, 52], [53, 57], [58, 60], [61, 64], [65, 72], [73, 81], [82, 85], [86, 89], [90, 99], [100, 106], [107, 111], [112, 114], [115, 125], [126, 138], [138, 139]]}
{"doc_key": "ai-test-81", "ner": [[0, 5, "field"], [10, 13, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [30, 34, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 5, 10, 13, "general-affiliation", "", false, false], [0, 5, 17, 18, "general-affiliation", "", false, false], [0, 5, 20, 21, "general-affiliation", "", false, false], [30, 34, 0, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Human", "Augmentation", "Code", "of", "Ethics", ",", "originally", "introduced", "by", "Steve", "Mann", "in", "2004", "and", "refined", "by", "Ray", "Kurzweil", "and", "Marvin", "Minsky", "in", "2013", ",", "was", "finally", "ratified", "at", "the", "Virtual", "Reality", "Toronto", "conference", "on", "June", "25", ",", "2017", "."], "sentence-detokenized": "The Human Augmentation Code of Ethics, originally introduced by Steve Mann in 2004 and refined by Ray Kurzweil and Marvin Minsky in 2013, was finally ratified at the Virtual Reality Toronto conference on June 25, 2017.", "token2charspan": [[0, 3], [4, 9], [10, 22], [23, 27], [28, 30], [31, 37], [37, 38], [39, 49], [50, 60], [61, 63], [64, 69], [70, 74], [75, 77], [78, 82], [83, 86], [87, 94], [95, 97], [98, 101], [102, 110], [111, 114], [115, 121], [122, 128], [129, 131], [132, 136], [136, 137], [138, 141], [142, 149], [150, 158], [159, 161], [162, 165], [166, 173], [174, 181], [182, 189], [190, 200], [201, 203], [204, 208], [209, 211], [211, 212], [213, 217], [217, 218]]}
{"doc_key": "ai-test-82", "ner": [[2, 4, "person"], [10, 12, "organisation"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 4, 10, 12, "role", "directed_for", false, false], [2, 4, 18, 19, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1913", "Walter", "R.", "Booth", "directed", "10", "films", "for", "the", "British", "company", "Kinoplastikon", ",", "probably", "in", "collaboration", "with", "Cecil", "Hepworth", "."], "sentence-detokenized": "In 1913 Walter R. Booth directed 10 films for the British company Kinoplastikon, probably in collaboration with Cecil Hepworth.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 17], [18, 23], [24, 32], [33, 35], [36, 41], [42, 45], [46, 49], [50, 57], [58, 65], [66, 79], [79, 80], [81, 89], [90, 92], [93, 106], [107, 111], [112, 117], [118, 126], [126, 127]]}
{"doc_key": "ai-test-83", "ner": [[10, 11, "location"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "introduced", "their", "new", "robot", "in", "1961", "at", "the", "Chicago", "Cow", "Palace", "."], "sentence-detokenized": "They introduced their new robot in 1961 at the Chicago Cow Palace.", "token2charspan": [[0, 4], [5, 15], [16, 21], [22, 25], [26, 31], [32, 34], [35, 39], [40, 42], [43, 46], [47, 54], [55, 58], [59, 65], [65, 66]]}
{"doc_key": "ai-test-84", "ner": [[2, 2, "product"], [6, 8, "task"], [10, 11, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 6, 8, "usage", "", false, false], [2, 2, 10, 11, "usage", "", false, false], [2, 2, 16, 17, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["While", "some", "chatbot", "applications", "use", "extensive", "word", "classification", "processes", ",", "natural", "language", "processing", "engines", "and", "sophisticated", "artificial", "intelligence", ",", "others", "simply", "look", "up", "generic", "keywords", "and", "generate", "answers", "using", "common", "phrases", "retrieved", "from", "a", "relevant", "library", "or", "database", "."], "sentence-detokenized": "While some chatbot applications use extensive word classification processes, natural language processing engines and sophisticated artificial intelligence, others simply look up generic keywords and generate answers using common phrases retrieved from a relevant library or database.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 31], [32, 35], [36, 45], [46, 50], [51, 65], [66, 75], [75, 76], [77, 84], [85, 93], [94, 104], [105, 112], [113, 116], [117, 130], [131, 141], [142, 154], [154, 155], [156, 162], [163, 169], [170, 174], [175, 177], [178, 185], [186, 194], [195, 198], [199, 207], [208, 215], [216, 221], [222, 228], [229, 236], [237, 246], [247, 251], [252, 253], [254, 262], [263, 270], [271, 273], [274, 282], [282, 283]]}
{"doc_key": "ai-test-85", "ner": [[5, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Designed", "in", "2016", ",", "the", "WaveNet", "model", "achieves", "great", "speech", "quality", "performance", "."], "sentence-detokenized": "Designed in 2016, the WaveNet model achieves great speech quality performance.", "token2charspan": [[0, 8], [9, 11], [12, 16], [16, 17], [18, 21], [22, 29], [30, 35], [36, 44], [45, 50], [51, 57], [58, 65], [66, 77], [77, 78]]}
{"doc_key": "ai-test-86", "ner": [[4, 4, "product"], [6, 7, "misc"], [9, 10, "misc"], [12, 13, "misc"], [16, 17, "misc"], [20, 22, "organisation"], [24, 24, "organisation"], [26, 29, "organisation"], [31, 31, "organisation"], [33, 36, "organisation"], [38, 39, "organisation"], [41, 41, "organisation"], [43, 45, "organisation"], [47, 47, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 4, 6, 7, "general-affiliation", "", false, false], [4, 4, 9, 10, "general-affiliation", "", false, false], [4, 4, 12, 13, "general-affiliation", "", false, false], [4, 4, 16, 17, "general-affiliation", "", false, false], [20, 22, 4, 4, "usage", "", false, false], [24, 24, 4, 4, "usage", "", false, false], [26, 29, 4, 4, "usage", "", false, false], [31, 31, 4, 4, "usage", "", false, false], [33, 36, 4, 4, "usage", "", false, false], [38, 39, 4, 4, "usage", "", false, false], [41, 41, 4, 4, "usage", "", false, false], [43, 45, 4, 4, "usage", "", false, false], [47, 47, 4, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organizations", "known", "to", "use", "ALE", "for", "emergency", "management", ",", "disaster", "relief", ",", "routine", "communications", ",", "or", "emergency", "response", ":", "the", "American", "Red", "Cross", ",", "FEMA", ",", "Disaster", "Medical", "Assistance", "Teams", ",", "NATO", ",", "Federal", "Bureau", "of", "Investigation", ",", "United", "Nations", ",", "AT&T", ",", "Civil", "Air", "Patrol", "(", "ARES", ")", "."], "sentence-detokenized": "Organizations known to use ALE for emergency management, disaster relief, routine communications, or emergency response: the American Red Cross, FEMA, Disaster Medical Assistance Teams, NATO, Federal Bureau of Investigation, United Nations, AT&T, Civil Air Patrol (ARES).", "token2charspan": [[0, 13], [14, 19], [20, 22], [23, 26], [27, 30], [31, 34], [35, 44], [45, 55], [55, 56], [57, 65], [66, 72], [72, 73], [74, 81], [82, 96], [96, 97], [98, 100], [101, 110], [111, 119], [119, 120], [121, 124], [125, 133], [134, 137], [138, 143], [143, 144], [145, 149], [149, 150], [151, 159], [160, 167], [168, 178], [179, 184], [184, 185], [186, 190], [190, 191], [192, 199], [200, 206], [207, 209], [210, 223], [223, 224], [225, 231], [232, 239], [239, 240], [241, 245], [245, 246], [247, 252], [253, 256], [257, 263], [264, 265], [265, 269], [269, 270], [270, 271]]}
{"doc_key": "ai-test-87", "ner": [[6, 9, "algorithm"], [16, 21, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", ",", "for", "simplicity", ",", "the", "Kronecker", "delta", "is", "used", "(", "cf", ".", "the", "derivative", "of", "the", "sigmoid", "function", ",", "which", "is", "expressed", "via", "the", "function", "itself", ")", "."], "sentence-detokenized": "Here, for simplicity, the Kronecker delta is used (cf. the derivative of the sigmoid function, which is expressed via the function itself).", "token2charspan": [[0, 4], [4, 5], [6, 9], [10, 20], [20, 21], [22, 25], [26, 35], [36, 41], [42, 44], [45, 49], [50, 51], [51, 53], [53, 54], [55, 58], [59, 69], [70, 72], [73, 76], [77, 84], [85, 93], [93, 94], [95, 100], [101, 103], [104, 113], [114, 117], [118, 121], [122, 130], [131, 137], [137, 138], [138, 139]]}
{"doc_key": "ai-test-88", "ner": [[11, 12, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "theory", "is", "based", "on", "philosophical", "foundations", "and", "was", "founded", "by", "Ray", "Solomonoff", "around", "1960", ".", "Samuel", "Rathmanner", "and", "Marcus", "Hutter", "."], "sentence-detokenized": "This theory is based on philosophical foundations and was founded by Ray Solomonoff around 1960. Samuel Rathmanner and Marcus Hutter.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 20], [21, 23], [24, 37], [38, 49], [50, 53], [54, 57], [58, 65], [66, 68], [69, 72], [73, 83], [84, 90], [91, 95], [95, 96], [97, 103], [104, 114], [115, 118], [119, 125], [126, 132], [132, 133]]}
{"doc_key": "ai-test-89", "ner": [[0, 0, "product"], [12, 13, "misc"], [16, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 12, 13, "type-of", "", false, false], [0, 0, 16, 20, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "a", "freely", "available", "database", "that", "was", "originally", "designed", "as", "a", "semantic", "network", "based", "on", "psycholinguistic", "principles", ",", "has", "been", "expanded", "to", "include", "definitions", "and", "is", "now", "also", "considered", "a", "dictionary", "."], "sentence-detokenized": "WordNet, a freely available database that was originally designed as a semantic network based on psycholinguistic principles, has been expanded to include definitions and is now also considered a dictionary.", "token2charspan": [[0, 7], [7, 8], [9, 10], [11, 17], [18, 27], [28, 36], [37, 41], [42, 45], [46, 56], [57, 65], [66, 68], [69, 70], [71, 79], [80, 87], [88, 93], [94, 96], [97, 113], [114, 124], [124, 125], [126, 129], [130, 134], [135, 143], [144, 146], [147, 154], [155, 166], [167, 170], [171, 173], [174, 177], [178, 182], [183, 193], [194, 195], [196, 206], [206, 207]]}
{"doc_key": "ai-test-90", "ner": [[2, 3, "field"], [12, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 2, 3, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Advances", "in", "computational", "imaging", "research", "are", "featured", "in", "several", "venues", ",", "including", "SIGGRAPH", "publications", "and", "."], "sentence-detokenized": "Advances in computational imaging research are featured in several venues, including SIGGRAPH publications and.", "token2charspan": [[0, 8], [9, 11], [12, 25], [26, 33], [34, 42], [43, 46], [47, 55], [56, 58], [59, 66], [67, 73], [73, 74], [75, 84], [85, 93], [94, 106], [107, 110], [110, 111]]}
{"doc_key": "ai-test-91", "ner": [[0, 4, "task"], [10, 11, "task"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 0, 4, "part-of", "", false, false], [13, 14, 0, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "thought", "of", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multi-class", "classification", "."], "sentence-detokenized": "Classification can be thought of as two separate problems - binary classification and multi-class classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 29], [30, 32], [33, 35], [36, 39], [40, 48], [49, 57], [58, 59], [60, 66], [67, 81], [82, 85], [86, 97], [98, 112], [112, 113]]}
{"doc_key": "ai-test-92", "ner": [[12, 12, "algorithm"], [16, 17, "algorithm"], [20, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 17, 12, 12, "type-of", "", false, false], [20, 20, 16, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Advanced", "gene", "finders", "for", "both", "prokaryotic", "and", "eukaryotic", "genomes", "typically", "use", "complex", "probabilistic", "models", "such", "as", "Hidden", "Markov", "Models", "(", "HMMs", ")", "that", "combine", "information", "from", "different", "signal", "and", "content", "measurements", "."], "sentence-detokenized": "Advanced gene finders for both prokaryotic and eukaryotic genomes typically use complex probabilistic models such as Hidden Markov Models (HMMs) that combine information from different signal and content measurements.", "token2charspan": [[0, 8], [9, 13], [14, 21], [22, 25], [26, 30], [31, 42], [43, 46], [47, 57], [58, 65], [66, 75], [76, 79], [80, 87], [88, 101], [102, 108], [109, 113], [114, 116], [117, 123], [124, 130], [131, 137], [138, 139], [139, 143], [143, 144], [145, 149], [150, 157], [158, 169], [170, 174], [175, 184], [185, 191], [192, 195], [196, 203], [204, 216], [216, 217]]}
{"doc_key": "ai-test-93", "ner": [[0, 0, "misc"], [2, 2, "misc"], [7, 9, "field"], [11, 12, "algorithm"], [15, 16, "algorithm"], [19, 19, "algorithm"], [30, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 7, 9, "part-of", "", false, false], [0, 0, 11, 12, "usage", "", false, false], [2, 2, 0, 0, "named", "", false, false], [15, 16, 0, 0, "origin", "", true, false], [19, 19, 15, 16, "named", "", false, false], [30, 31, 0, 0, "origin", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Neuroevolution", "or", "neuroevolution", "is", "a", "form", "of", "artificial", "intelligence", "that", "uses", "evolutionary", "algorithms", "to", "generate", "artificial", "neural", "networks", "(", "ANNs", ")", ",", "parameters", ",", "topology", ",", "and", "rules", ".", "and", "evolutionary", "robotics", "."], "sentence-detokenized": "Neuroevolution or neuroevolution is a form of artificial intelligence that uses evolutionary algorithms to generate artificial neural networks (ANNs), parameters, topology, and rules. and evolutionary robotics.", "token2charspan": [[0, 14], [15, 17], [18, 32], [33, 35], [36, 37], [38, 42], [43, 45], [46, 56], [57, 69], [70, 74], [75, 79], [80, 92], [93, 103], [104, 106], [107, 115], [116, 126], [127, 133], [134, 142], [143, 144], [144, 148], [148, 149], [149, 150], [151, 161], [161, 162], [163, 171], [171, 172], [173, 176], [177, 182], [182, 183], [184, 187], [188, 200], [201, 209], [209, 210]]}
{"doc_key": "ai-test-94", "ner": [[1, 1, "organisation"], [6, 6, "metrics"], [8, 8, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 1, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "IBM", "designed", "and", "implemented", "the", "BLEU", "system", "Papineni", "et", "al", "."], "sentence-detokenized": "Since IBM designed and implemented the BLEU system Papineni et al.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 22], [23, 34], [35, 38], [39, 43], [44, 50], [51, 59], [60, 62], [63, 65], [65, 66]]}
{"doc_key": "ai-test-95", "ner": [[9, 16, "conference"], [18, 20, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 20, 9, 16, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2009", ",", "experts", "attended", "a", "conference", "organised", "by", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "to", "discuss", "whether", "computers", "and", "robots", "might", "be", "able", "to", "gain", "some", "autonomy", ",", "and", "to", "what", "extent", "these", "capabilities", "might", "pose", "a", "threat", "or", "danger", "."], "sentence-detokenized": "In 2009, experts attended a conference organised by the Association for the Advancement of Artificial Intelligence (AAAI) to discuss whether computers and robots might be able to gain some autonomy, and to what extent these capabilities might pose a threat or danger.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 25], [26, 27], [28, 38], [39, 48], [49, 51], [52, 55], [56, 67], [68, 71], [72, 75], [76, 87], [88, 90], [91, 101], [102, 114], [115, 116], [116, 120], [120, 121], [122, 124], [125, 132], [133, 140], [141, 150], [151, 154], [155, 161], [162, 167], [168, 170], [171, 175], [176, 178], [179, 183], [184, 188], [189, 197], [197, 198], [199, 202], [203, 205], [206, 210], [211, 217], [218, 223], [224, 236], [237, 242], [243, 247], [248, 249], [250, 256], [257, 259], [260, 266], [266, 267]]}
{"doc_key": "ai-test-96", "ner": [[23, 24, "researcher"], [26, 27, "researcher"], [29, 34, "task"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[29, 34, 23, 24, "artifact", "", false, false], [29, 34, 26, 27, "artifact", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["After", "boosting", ",", "a", "classifier", "constructed", "from", "200", "features", "could", "yield", "a", "95", "%", "detection", "rate", "at", "^", "{", "-", "5", "}", "/", "P.", "Viola", ",", "M.", "Jones", ",", "Robust", "Real", "-", "time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "After boosting, a classifier constructed from 200 features could yield a 95% detection rate at ^ {-5} / P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 17], [18, 28], [29, 40], [41, 45], [46, 49], [50, 58], [59, 64], [65, 70], [71, 72], [73, 75], [75, 76], [77, 86], [87, 91], [92, 94], [95, 96], [97, 98], [98, 99], [99, 100], [100, 101], [102, 103], [104, 106], [107, 112], [112, 113], [114, 116], [117, 122], [122, 123], [124, 130], [131, 135], [135, 136], [136, 140], [141, 147], [148, 157], [157, 158], [159, 163], [163, 164]]}
{"doc_key": "ai-test-97", "ner": [[6, 6, "programlang"], [9, 9, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "website", "was", "originally", "based", "on", "Perl", ",", "but", "IMDb", "no", "longer", "discloses", "what", "software", "it", "uses", "for", "security", "reasons", "."], "sentence-detokenized": "The website was originally based on Perl, but IMDb no longer discloses what software it uses for security reasons.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 26], [27, 32], [33, 35], [36, 40], [40, 41], [42, 45], [46, 50], [51, 53], [54, 60], [61, 70], [71, 75], [76, 84], [85, 87], [88, 92], [93, 96], [97, 105], [106, 113], [113, 114]]}
{"doc_key": "ai-test-98", "ner": [[5, 6, "researcher"], [8, 9, "researcher"], [11, 14, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "startup", "was", "founded", "by", "Demis", "Hassabis", ",", "Shane", "Legg", "and", "Mustafa", "Suleyman", "in", "2010", "."], "sentence-detokenized": "The startup was founded by Demis Hassabis, Shane Legg and Mustafa Suleyman in 2010.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 26], [27, 32], [33, 41], [41, 42], [43, 48], [49, 53], [54, 57], [58, 65], [66, 74], [75, 77], [78, 82], [82, 83]]}
{"doc_key": "ai-test-99", "ner": [[4, 5, "misc"], [8, 10, "metrics"], [23, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 4, 5, "type-of", "", false, false], [23, 24, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "very", "commonly", "used", "loss", "functions", "are", "the", "mean", "squared", "error", ",", "mathL", "(", "a", ")", "=", "a^2", "/", "math", ",", "and", "the", "absolute", "loss", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "/", "math", "."], "sentence-detokenized": "Two very commonly used loss functions are the mean squared error, mathL (a) = a^2/math, and the absolute loss, mathL (a) = |a |/math.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 27], [28, 37], [38, 41], [42, 45], [46, 50], [51, 58], [59, 64], [64, 65], [66, 71], [72, 73], [73, 74], [74, 75], [76, 77], [78, 81], [81, 82], [82, 86], [86, 87], [88, 91], [92, 95], [96, 104], [105, 109], [109, 110], [111, 116], [117, 118], [118, 119], [119, 120], [121, 122], [123, 124], [124, 125], [126, 127], [127, 128], [128, 132], [132, 133]]}
{"doc_key": "ai-test-100", "ner": [[3, 5, "algorithm"], [12, 14, "algorithm"], [16, 19, "algorithm"], [20, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 12, 14, "type-of", "example_of", false, false], [12, 14, 20, 23, "related-to", "", false, false], [16, 19, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "soft", "-margin", "support", "vector", "machine", "described", "above", "is", "an", "example", "of", "empirical", "risk", "minimization", "(", "ERM", ")", "for", "a", "loss", "in", "the", "sling", "."], "sentence-detokenized": "The soft-margin support vector machine described above is an example of empirical risk minimization (ERM) for a loss in the sling.", "token2charspan": [[0, 3], [4, 8], [8, 15], [16, 23], [24, 30], [31, 38], [39, 48], [49, 54], [55, 57], [58, 60], [61, 68], [69, 71], [72, 81], [82, 86], [87, 99], [100, 101], [101, 104], [104, 105], [106, 109], [110, 111], [112, 116], [117, 119], [120, 123], [124, 129], [129, 130]]}
{"doc_key": "ai-test-101", "ner": [[0, 2, "field"], [7, 7, "task"], [9, 11, "task"], [22, 22, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 11, 0, 2, "origin", "", false, false], [9, 11, 7, 7, "type-of", "", false, false], [22, 22, 9, 11, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "deep", "learning", "-", "based", "approach", "to", "MT", ",", "neural", "machine", "translation", ",", "has", "seen", "rapid", "advances", "in", "recent", "years", ",", "and", "Google", "has", "announced", "that", "its", "translation", "services", "now", "use", "this", "technology", "instead", "of", "previous", "statistical", "methods", "."], "sentence-detokenized": "A deep learning-based approach to MT, neural machine translation, has seen rapid advances in recent years, and Google has announced that its translation services now use this technology instead of previous statistical methods.", "token2charspan": [[0, 1], [2, 6], [7, 15], [15, 16], [16, 21], [22, 30], [31, 33], [34, 36], [36, 37], [38, 44], [45, 52], [53, 64], [64, 65], [66, 69], [70, 74], [75, 80], [81, 89], [90, 92], [93, 99], [100, 105], [105, 106], [107, 110], [111, 117], [118, 121], [122, 131], [132, 136], [137, 140], [141, 152], [153, 161], [162, 165], [166, 169], [170, 174], [175, 185], [186, 193], [194, 196], [197, 205], [206, 217], [218, 225], [225, 226]]}
{"doc_key": "ai-test-102", "ner": [[7, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "working", "with", "large", "corpora", "such", "as", "WordNet", ",", "this", "usually", "results", "in", "very", "high", "performance", "gains", "."], "sentence-detokenized": "When working with large corpora such as WordNet, this usually results in very high performance gains.", "token2charspan": [[0, 4], [5, 12], [13, 17], [18, 23], [24, 31], [32, 36], [37, 39], [40, 47], [47, 48], [49, 53], [54, 61], [62, 69], [70, 72], [73, 77], [78, 82], [83, 94], [95, 100], [100, 101]]}
{"doc_key": "ai-test-103", "ner": [[0, 3, "task"], [5, 7, "field"], [14, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 14, 18, "part-of", "", false, false], [14, 18, 5, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Face", "detection", "is", "used", "in", "biometrics", ",", "often", "as", "part", "of", "(", "or", "alongside", ")", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Face detection is used in biometrics, often as part of (or alongside) a facial recognition system.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 22], [23, 25], [26, 36], [36, 37], [38, 43], [44, 46], [47, 51], [52, 54], [55, 56], [56, 58], [59, 68], [68, 69], [70, 71], [72, 78], [79, 90], [91, 97], [97, 98]]}
{"doc_key": "ai-test-104", "ner": [[2, 4, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["trained", "using", "maximum", "likelihood", "estimation", "."], "sentence-detokenized": "trained using maximum likelihood estimation.", "token2charspan": [[0, 7], [8, 13], [14, 21], [22, 32], [33, 43], [43, 44]]}
{"doc_key": "ai-test-105", "ner": [[3, 3, "country"], [5, 9, "organisation"], [13, 13, "location"], [15, 15, "country"], [17, 20, "organisation"], [22, 24, "country"], [28, 28, "organisation"], [33, 35, "organisation"], [37, 39, "country"], [48, 51, "organisation"], [53, 55, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[5, 9, 13, 13, "physical", "", false, false], [13, 13, 15, 15, "physical", "", false, false], [17, 20, 22, 24, "physical", "", false, false], [33, 35, 37, 39, "physical", "", false, false], [48, 51, 53, 55, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ltd", ".", "in", "Thailand", ";", "Komatsu", "(", "Shanghai", ")", "Ltd.", "in", "1996", "in", "Shanghai", ",", "China", ";", "Industrial", "Power", "Alliance", "Ltd.", "in", "Japan", ",", "a", "joint", "venture", "with", "Cummins", ",", "in", "1998", ";", "L&T-", "Komatsu", "Limited", "in", "India", "in", "1998", "(", "shares", "sold", "in", "2013", ")", ";", "and", "Komatsu", "Brasil", "International", "Ltda.", "in", "Brazil", "in", "1998", "."], "sentence-detokenized": "Ltd. in Thailand; Komatsu (Shanghai) Ltd. in 1996 in Shanghai, China; Industrial Power Alliance Ltd. in Japan, a joint venture with Cummins, in 1998; L&T-Komatsu Limited in India in 1998 (shares sold in 2013); and Komatsu Brasil International Ltda. in Brazil in 1998.", "token2charspan": [[0, 3], [3, 4], [5, 7], [8, 16], [16, 17], [18, 25], [26, 27], [27, 35], [35, 36], [37, 41], [42, 44], [45, 49], [50, 52], [53, 61], [61, 62], [63, 68], [68, 69], [70, 80], [81, 86], [87, 95], [96, 100], [101, 103], [104, 109], [109, 110], [111, 112], [113, 118], [119, 126], [127, 131], [132, 139], [139, 140], [141, 143], [144, 148], [148, 149], [150, 154], [154, 161], [162, 169], [170, 172], [173, 178], [179, 181], [182, 186], [187, 188], [188, 194], [195, 199], [200, 202], [203, 207], [207, 208], [208, 209], [210, 213], [214, 221], [222, 228], [229, 242], [243, 248], [249, 251], [252, 258], [259, 261], [262, 266], [266, 267]]}
{"doc_key": "ai-test-106", "ner": [[0, 0, "organisation"], [3, 7, "misc"], [8, 8, "misc"], [10, 11, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 11, 0, 0, "physical", "", false, false], [10, 11, 3, 7, "general-affiliation", "", false, false], [10, 11, 8, 8, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["dgp", "occasionally", "hosts", "artists", "in", "residence", "(", "e.g.", "Oscar", "winner", "Chris", "Landreth", "."], "sentence-detokenized": "dgp occasionally hosts artists in residence (e.g. Oscar winner Chris Landreth.", "token2charspan": [[0, 3], [4, 16], [17, 22], [23, 30], [31, 33], [34, 43], [44, 45], [45, 49], [50, 55], [56, 62], [63, 68], [69, 77], [77, 78]]}
{"doc_key": "ai-test-107", "ner": [[6, 8, "misc"], [10, 12, "misc"], [14, 17, "misc"], [21, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "currently", "includes", "four", "sub-competitions", "-", "RoboMaster", "Robotics", "Competition", ",", "RoboMaster", "Technical", "Challenge", ",", "ICRA", "RoboMaster", "AI", "Challenge", "and", "the", "new", "RoboMaster", "Youth", "Tournament", "."], "sentence-detokenized": "It currently includes four sub-competitions - RoboMaster Robotics Competition, RoboMaster Technical Challenge, ICRA RoboMaster AI Challenge and the new RoboMaster Youth Tournament.", "token2charspan": [[0, 2], [3, 12], [13, 21], [22, 26], [27, 43], [44, 45], [46, 56], [57, 65], [66, 77], [77, 78], [79, 89], [90, 99], [100, 109], [109, 110], [111, 115], [116, 126], [127, 129], [130, 139], [140, 143], [144, 147], [148, 151], [152, 162], [163, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-test-108", "ner": [[7, 8, "field"], [15, 17, "algorithm"], [21, 22, "algorithm"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 21, 22, "usage", "", false, false], [7, 8, 24, 25, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "the", "early", "2000s", ",", "the", "dominant", "speech", "processing", "strategy", "began", "to", "shift", "from", "the", "hidden", "Markov", "model", "to", "more", "advanced", "neural", "networks", "and", "deep", "learning", "."], "sentence-detokenized": "In the early 2000s, the dominant speech processing strategy began to shift from the hidden Markov model to more advanced neural networks and deep learning.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 18], [18, 19], [20, 23], [24, 32], [33, 39], [40, 50], [51, 59], [60, 65], [66, 68], [69, 74], [75, 79], [80, 83], [84, 90], [91, 97], [98, 103], [104, 106], [107, 111], [112, 120], [121, 127], [128, 136], [137, 140], [141, 145], [146, 154], [154, 155]]}
{"doc_key": "ai-test-109", "ner": [[7, 12, "misc"], [14, 16, "metrics"], [19, 21, "metrics"], [28, 30, "metrics"], [33, 35, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 16, 19, 21, "related-to", "equal", false, false], [28, 30, 33, 35, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "equivalent", "expression", "in", "the", "case", "of", "a", "binary", "target", "rate", "is", "that", "the", "TRUE", "positive", "rate", "and", "the", "FALSE", "positive", "rate", "are", "equal", "(", "and", "thus", "the", "FALSE", "negative", "rate", "and", "the", "TRUE", "negative", "rate", "are", "equal", ")", "for", "each", "value", "of", "the", "sensitive", "characteristics", ":"], "sentence-detokenized": "Another equivalent expression in the case of a binary target rate is that the TRUE positive rate and the FALSE positive rate are equal (and thus the FALSE negative rate and the TRUE negative rate are equal) for each value of the sensitive characteristics:", "token2charspan": [[0, 7], [8, 18], [19, 29], [30, 32], [33, 36], [37, 41], [42, 44], [45, 46], [47, 53], [54, 60], [61, 65], [66, 68], [69, 73], [74, 77], [78, 82], [83, 91], [92, 96], [97, 100], [101, 104], [105, 110], [111, 119], [120, 124], [125, 128], [129, 134], [135, 136], [136, 139], [140, 144], [145, 148], [149, 154], [155, 163], [164, 168], [169, 172], [173, 176], [177, 181], [182, 190], [191, 195], [196, 199], [200, 205], [205, 206], [207, 210], [211, 215], [216, 221], [222, 224], [225, 228], [229, 238], [239, 254], [254, 255]]}
{"doc_key": "ai-test-110", "ner": [[0, 0, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["MATLAB", "function", ","], "sentence-detokenized": "MATLAB function,", "token2charspan": [[0, 6], [7, 15], [15, 16]]}
{"doc_key": "ai-test-111", "ner": [[0, 2, "product"], [7, 11, "misc"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 11, 0, 2, "part-of", "", false, false], [16, 17, 0, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "articulated", "robot", "is", "a", "robot", "with", "rotating", "joints", "(", "e.g.", "a", "foot", "robot", "or", "an", "industrial", "robot", ")", "."], "sentence-detokenized": "An articulated robot is a robot with rotating joints (e.g. a foot robot or an industrial robot).", "token2charspan": [[0, 2], [3, 14], [15, 20], [21, 23], [24, 25], [26, 31], [32, 36], [37, 45], [46, 52], [53, 54], [54, 58], [59, 60], [61, 65], [66, 71], [72, 74], [75, 77], [78, 88], [89, 94], [94, 95], [95, 96]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [5, 6, "product"], [8, 9, "product"], [13, 13, "misc"], [20, 23, "product"], [26, 28, "misc"], [32, 32, "location"], [34, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 13, 13, "general-affiliation", "nationality", false, false], [0, 0, 26, 28, "usage", "", false, false], [0, 0, 32, 32, "physical", "", false, false], [5, 6, 0, 0, "named", "", false, false], [8, 9, 0, 0, "named", "", false, false], [32, 32, 34, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "also", "known", "as", "Pandora", "Media", "or", "Pandora", "Radio", ")", "is", "an", "American", "Internet", "radio", "music", "streaming", "service", "and", "automated", "recommendation", "system", "powered", "by", "the", "Music", "Genome", "Project", "and", "based", "in", "Oakland", ",", "California", "."], "sentence-detokenized": "Pandora (also known as Pandora Media or Pandora Radio) is an American Internet radio music streaming service and automated recommendation system powered by the Music Genome Project and based in Oakland, California.", "token2charspan": [[0, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 30], [31, 36], [37, 39], [40, 47], [48, 53], [53, 54], [55, 57], [58, 60], [61, 69], [70, 78], [79, 84], [85, 90], [91, 100], [101, 108], [109, 112], [113, 122], [123, 137], [138, 144], [145, 152], [153, 155], [156, 159], [160, 165], [166, 172], [173, 180], [181, 184], [185, 190], [191, 193], [194, 201], [201, 202], [203, 213], [213, 214]]}
{"doc_key": "ai-test-113", "ner": [[10, 14, "organisation"], [20, 22, "organisation"], [30, 36, "conference"], [41, 41, "conference"], [43, 43, "conference"], [45, 45, "conference"], [47, 47, "conference"], [49, 49, "conference"], [51, 51, "conference"], [53, 53, "conference"], [55, 55, "conference"], [57, 57, "conference"], [60, 60, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "member", "of", "the", "Board", "of", "Directors", "of", "the", "International", "Machine", "Learning", "Society", ",", "a", "member", "of", "the", "AAAI", "Executive", "Board", ",", "co-chair", "of", "the", "PC", "for", "the", "2011", "ICML", "conference", ",", "and", "has", "served", "as", "senior", "PC", "for", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "UAI", ",", "VLDB", ",", "WSDM", ",", "and", "WWW", "conferences", "."], "sentence-detokenized": "She is a member of the Board of Directors of the International Machine Learning Society, a member of the AAAI Executive Board, co-chair of the PC for the 2011 ICML conference, and has served as senior PC for AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM, and WWW conferences.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 15], [16, 18], [19, 22], [23, 28], [29, 31], [32, 41], [42, 44], [45, 48], [49, 62], [63, 70], [71, 79], [80, 87], [87, 88], [89, 90], [91, 97], [98, 100], [101, 104], [105, 109], [110, 119], [120, 125], [125, 126], [127, 135], [136, 138], [139, 142], [143, 145], [146, 149], [150, 153], [154, 158], [159, 163], [164, 174], [174, 175], [176, 179], [180, 183], [184, 190], [191, 193], [194, 200], [201, 203], [204, 207], [208, 212], [212, 213], [214, 218], [218, 219], [220, 225], [225, 226], [227, 231], [231, 232], [233, 236], [236, 237], [238, 244], [244, 245], [246, 249], [249, 250], [251, 255], [255, 256], [257, 261], [261, 262], [263, 266], [267, 270], [271, 282], [282, 283]]}
{"doc_key": "ai-test-114", "ner": [[0, 2, "researcher"], [5, 10, "organisation"], [12, 12, "organisation"], [17, 19, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 10, "role", "", false, false], [12, 12, 5, 10, "named", "", false, false], [17, 19, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", "of", "the", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", "has", "developed", "a", "robocrane", "where", "the", "platform", "hangs", "on", "six", "cables", "instead", "of", "being", "supported", "by", "six", "connectors", "."], "sentence-detokenized": "James S. Albus of the National Institute of Standards and Technology (NIST) has developed a robocrane where the platform hangs on six cables instead of being supported by six connectors.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 17], [18, 21], [22, 30], [31, 40], [41, 43], [44, 53], [54, 57], [58, 68], [69, 70], [70, 74], [74, 75], [76, 79], [80, 89], [90, 91], [92, 101], [102, 107], [108, 111], [112, 120], [121, 126], [127, 129], [130, 133], [134, 140], [141, 148], [149, 151], [152, 157], [158, 167], [168, 170], [171, 174], [175, 185], [185, 186]]}
{"doc_key": "ai-test-115", "ner": [[3, 6, "algorithm"], [8, 9, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 3, 6, "type-of", "", false, false], [13, 14, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "class", "of", "direct", "search", "algorithms", "are", "various", "evolutionary", "algorithms", ",", "such", "as", "genetic", "algorithms", "."], "sentence-detokenized": "Another class of direct search algorithms are various evolutionary algorithms, such as genetic algorithms.", "token2charspan": [[0, 7], [8, 13], [14, 16], [17, 23], [24, 30], [31, 41], [42, 45], [46, 53], [54, 66], [67, 77], [77, 78], [79, 83], [84, 86], [87, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-test-116", "ner": [[0, 0, "organisation"], [3, 3, "misc"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 0, 0, "named", "", false, false], [6, 7, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["KUKA", "is", "a", "German", "manufacturer", "of", "industrial", "robots", "and", "solutions", "for", "production", "automation", "."], "sentence-detokenized": "KUKA is a German manufacturer of industrial robots and solutions for production automation.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 16], [17, 29], [30, 32], [33, 43], [44, 50], [51, 54], [55, 64], [65, 68], [69, 79], [80, 90], [90, 91]]}
{"doc_key": "ai-test-117", "ner": [[5, 5, "misc"], [12, 14, "person"], [15, 21, "misc"], [23, 23, "person"], [26, 26, "misc"], [28, 30, "person"], [31, 32, "misc"], [34, 39, "person"], [37, 39, "misc"], [41, 44, "person"], [44, 48, "misc"], [51, 53, "person"], [54, 57, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[12, 14, 5, 5, "usage", "", false, false], [15, 21, 12, 14, "artifact", "", false, false], [23, 23, 5, 5, "usage", "", false, false], [26, 26, 23, 23, "artifact", "", false, false], [28, 30, 5, 5, "usage", "", false, false], [31, 32, 28, 30, "artifact", "", false, false], [34, 39, 5, 5, "usage", "", false, false], [37, 39, 34, 39, "artifact", "", false, false], [41, 44, 5, 5, "usage", "", false, false], [44, 48, 41, 44, "artifact", "", false, false], [51, 53, 5, 5, "usage", "", false, false], [54, 57, 51, 53, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Other", "films", "shot", "by", "the", "IMAX", "camera", "between", "2016", "and", "2020", "were", "Zack", "Snyder", "'s", "Batman", "v", "Superman", ":", "Dawn", "of", "Justice", ",", "Clint", "Eastwood", "'s", "Sully", ",", "Damien", "Chazelle", "'s", "First", "Man", ",", "Patty", "Jenkins", "'", "Wonder", "Woman", "1984", ",", "Cary", "Joji", "Fukunaga", "'s", "No", "Time", "to", "Die", ",", "and", "Joseph", "Kosinski", "'s", "Top", "Gun", ":", "Maverick", "."], "sentence-detokenized": "Other films shot by the IMAX camera between 2016 and 2020 were Zack Snyder's Batman v Superman: Dawn of Justice, Clint Eastwood's Sully, Damien Chazelle's First Man, Patty Jenkins' Wonder Woman 1984, Cary Joji Fukunaga's No Time to Die, and Joseph Kosinski's Top Gun: Maverick.", "token2charspan": [[0, 5], [6, 11], [12, 16], [17, 19], [20, 23], [24, 28], [29, 35], [36, 43], [44, 48], [49, 52], [53, 57], [58, 62], [63, 67], [68, 74], [74, 76], [77, 83], [84, 85], [86, 94], [94, 95], [96, 100], [101, 103], [104, 111], [111, 112], [113, 118], [119, 127], [127, 129], [130, 135], [135, 136], [137, 143], [144, 152], [152, 154], [155, 160], [161, 164], [164, 165], [166, 171], [172, 179], [179, 180], [181, 187], [188, 193], [194, 198], [198, 199], [200, 204], [205, 209], [210, 218], [218, 220], [221, 223], [224, 228], [229, 231], [232, 235], [235, 236], [237, 240], [241, 247], [248, 256], [256, 258], [259, 262], [263, 266], [266, 267], [268, 276], [276, 277]]}
{"doc_key": "ai-test-118", "ner": [[4, 6, "misc"], [10, 12, "organisation"], [14, 20, "organisation"], [25, 27, "misc"], [32, 33, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 25, 27, "named", "", false, false], [10, 12, 4, 6, "usage", "", false, false], [10, 12, 32, 33, "physical", "", false, false], [14, 20, 10, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "trial", "version", "of", "MICR", "E13B", "was", "shown", "to", "the", "American", "Banking", "Association", "(", "ABA", ")", "in", "July", "1956", ",", "which", "adopted", "it", "as", "the", "MICR", "standard", "for", "negotiable", "documents", "in", "the", "United", "States", "in", "1958", "."], "sentence-detokenized": "A trial version of MICR E13B was shown to the American Banking Association (ABA) in July 1956, which adopted it as the MICR standard for negotiable documents in the United States in 1958.", "token2charspan": [[0, 1], [2, 7], [8, 15], [16, 18], [19, 23], [24, 28], [29, 32], [33, 38], [39, 41], [42, 45], [46, 54], [55, 62], [63, 74], [75, 76], [76, 79], [79, 80], [81, 83], [84, 88], [89, 93], [93, 94], [95, 100], [101, 108], [109, 111], [112, 114], [115, 118], [119, 123], [124, 132], [133, 136], [137, 147], [148, 157], [158, 160], [161, 164], [165, 171], [172, 178], [179, 181], [182, 186], [186, 187]]}
{"doc_key": "ai-test-119", "ner": [[0, 3, "misc"], [15, 16, "field"], [19, 20, "field"], [23, 23, "field"], [25, 26, "field"], [28, 28, "field"], [31, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 16, 0, 3, "usage", "", false, false], [19, 20, 15, 16, "part-of", "", false, false], [23, 23, 0, 3, "usage", "", false, false], [25, 26, 0, 3, "usage", "", false, false], [28, 28, 0, 3, "usage", "", false, false], [31, 31, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Local", "search", "algorithms", "are", "widely", "applied", "to", "many", "challenging", "computational", "problems", ",", "including", "problems", "in", "computer", "science", "(", "especially", "artificial", "intelligence", ")", ",", "mathematics", ",", "operations", "research", ",", "engineering", ",", "and", "bioinformatics", "."], "sentence-detokenized": "Local search algorithms are widely applied to many challenging computational problems, including problems in computer science (especially artificial intelligence), mathematics, operations research, engineering, and bioinformatics.", "token2charspan": [[0, 5], [6, 12], [13, 23], [24, 27], [28, 34], [35, 42], [43, 45], [46, 50], [51, 62], [63, 76], [77, 85], [85, 86], [87, 96], [97, 105], [106, 108], [109, 117], [118, 125], [126, 127], [127, 137], [138, 148], [149, 161], [161, 162], [162, 163], [164, 175], [175, 176], [177, 187], [188, 196], [196, 197], [198, 209], [209, 210], [211, 214], [215, 229], [229, 230]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [8, 8, "location"], [10, 10, "country"], [14, 14, "country"], [23, 24, "algorithm"], [26, 26, "algorithm"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 8, 8, "physical", "", false, false], [0, 1, 14, 14, "general-affiliation", "nationality", false, false], [0, 1, 23, 24, "general-affiliation", "topic_of_study", false, false], [0, 1, 26, 26, "general-affiliation", "topic_of_study", false, false], [8, 8, 10, 10, "physical", "", false, false], [26, 26, 28, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "born", "3", "September", "1947", "in", "Wallersdorf", ",", "Germany", ")", "is", "a", "German", "psychologist", "who", "has", "worked", "on", "the", "use", "of", "bounded", "rationality", "and", "heuristics", "in", "decision", "making", "."], "sentence-detokenized": "Gerd Gigerenzer (born 3 September 1947 in Wallersdorf, Germany) is a German psychologist who has worked on the use of bounded rationality and heuristics in decision making.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 21], [22, 23], [24, 33], [34, 38], [39, 41], [42, 53], [53, 54], [55, 62], [62, 63], [64, 66], [67, 68], [69, 75], [76, 88], [89, 92], [93, 96], [97, 103], [104, 106], [107, 110], [111, 114], [115, 117], [118, 125], [126, 137], [138, 141], [142, 152], [153, 155], [156, 164], [165, 171], [171, 172]]}
{"doc_key": "ai-test-121", "ner": [[2, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["minimize", "the", "mean", "squared", "error", "."], "sentence-detokenized": "minimize the mean squared error.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 25], [26, 31], [31, 32]]}
{"doc_key": "ai-test-122", "ner": [[12, 13, "misc"], [16, 17, "organisation"], [32, 36, "field"], [50, 51, "misc"], [60, 62, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 13, 16, 17, "origin", "", false, false], [50, 51, 60, 62, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["But", "even", "an", "official", "language", "with", "a", "governing", "academy", ",", "such", "as", "standard", "French", "with", "the", "French", "Academy", ",", "is", "classified", "as", "a", "natural", "language", "(", "e.g.", ",", "in", "the", "domain", "of", "natural", "language", "processing", ")", "because", "its", "normative", "points", "make", "it", "neither", "sufficiently", "constructed", "to", "be", "classified", "as", "a", "constructed", "language", "nor", "sufficiently", "controlled", "to", "be", "classified", "as", "a", "controlled", "natural", "language", "."], "sentence-detokenized": "But even an official language with a governing academy, such as standard French with the French Academy, is classified as a natural language (e.g., in the domain of natural language processing) because its normative points make it neither sufficiently constructed to be classified as a constructed language nor sufficiently controlled to be classified as a controlled natural language.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 20], [21, 29], [30, 34], [35, 36], [37, 46], [47, 54], [54, 55], [56, 60], [61, 63], [64, 72], [73, 79], [80, 84], [85, 88], [89, 95], [96, 103], [103, 104], [105, 107], [108, 118], [119, 121], [122, 123], [124, 131], [132, 140], [141, 142], [142, 146], [146, 147], [148, 150], [151, 154], [155, 161], [162, 164], [165, 172], [173, 181], [182, 192], [192, 193], [194, 201], [202, 205], [206, 215], [216, 222], [223, 227], [228, 230], [231, 238], [239, 251], [252, 263], [264, 266], [267, 269], [270, 280], [281, 283], [284, 285], [286, 297], [298, 306], [307, 310], [311, 323], [324, 334], [335, 337], [338, 340], [341, 351], [352, 354], [355, 356], [357, 367], [368, 375], [376, 384], [384, 385]]}
{"doc_key": "ai-test-123", "ner": [[9, 9, "metrics"], [11, 12, "metrics"], [14, 17, "metrics"], [33, 34, "metrics"], [36, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 17, 11, 12, "named", "", false, false], [36, 36, 33, 34, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "several", "other", "metrics", ",", "the", "simplest", "being", "accuracy", "or", "proportion", "correct", "(", "FC", ")", ",", "which", "measures", "the", "proportion", "of", "all", "cases", "that", "are", "correctly", "categorized", ";", "the", "complement", "is", "the", "proportion", "incorrect", "(", "FiC", ")", "."], "sentence-detokenized": "There are several other metrics, the simplest being accuracy or proportion correct (FC), which measures the proportion of all cases that are correctly categorized; the complement is the proportion incorrect (FiC).", "token2charspan": [[0, 5], [6, 9], [10, 17], [18, 23], [24, 31], [31, 32], [33, 36], [37, 45], [46, 51], [52, 60], [61, 63], [64, 74], [75, 82], [83, 84], [84, 86], [86, 87], [87, 88], [89, 94], [95, 103], [104, 107], [108, 118], [119, 121], [122, 125], [126, 131], [132, 136], [137, 140], [141, 150], [151, 162], [162, 163], [164, 167], [168, 178], [179, 181], [182, 185], [186, 196], [197, 206], [207, 208], [208, 211], [211, 212], [212, 213]]}
{"doc_key": "ai-test-124", "ner": [[0, 0, "researcher"], [3, 8, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 3, 8, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cardie", "joined", "the", "Association", "for", "Computational", "Linguistics", "in", "2016", "."], "sentence-detokenized": "Cardie joined the Association for Computational Linguistics in 2016.", "token2charspan": [[0, 6], [7, 13], [14, 17], [18, 29], [30, 33], [34, 47], [48, 59], [60, 62], [63, 67], [67, 68]]}
{"doc_key": "ai-test-125", "ner": [[13, 16, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Learning", "the", "parameters", "of", "math", "\\", "theta", "/", "math", "is", "usually", "done", "by", "learning", "the", "maximum", "likelihood", "for", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i", ";\\", "theta", ")", "/", "math", "."], "sentence-detokenized": "Learning the parameters of math\\ theta / math is usually done by learning the maximum likelihood for mathp (Y _ i | X _ i;\\ theta) / math.", "token2charspan": [[0, 8], [9, 12], [13, 23], [24, 26], [27, 31], [31, 32], [33, 38], [39, 40], [41, 45], [46, 48], [49, 56], [57, 61], [62, 64], [65, 73], [74, 77], [78, 85], [86, 96], [97, 100], [101, 106], [107, 108], [108, 109], [110, 111], [112, 113], [114, 115], [116, 117], [118, 119], [120, 121], [121, 123], [124, 129], [129, 130], [131, 132], [133, 137], [137, 138]]}
{"doc_key": "ai-test-126", "ner": [[0, 1, "task"], [3, 6, "algorithm"], [8, 9, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 0, 1, "usage", "", true, false], [8, 9, 3, 6, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cluster", "analysis", "and", "factorization", "of", "nonnegative", "matrices", "for", "descriptive", "mining", "."], "sentence-detokenized": "Cluster analysis and factorization of nonnegative matrices for descriptive mining.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 34], [35, 37], [38, 49], [50, 58], [59, 62], [63, 74], [75, 81], [81, 82]]}
{"doc_key": "ai-test-127", "ner": [[1, 2, "field"], [5, 8, "field"], [14, 17, "field"], [19, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 17, 1, 2, "part-of", "", false, false], [14, 17, 5, 8, "part-of", "", false, false], [19, 23, 1, 2, "part-of", "", false, false], [19, 23, 5, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", "and", "the", "information", "technology", "it", "enables", ",", "the", "ability", "of", "computers", "to", "process", "natural", "language", "and", "machine", "learning", "has", "been", "a", "long", "-", "standing", "challenge", "."], "sentence-detokenized": "In computer science and the information technology it enables, the ability of computers to process natural language and machine learning has been a long-standing challenge.", "token2charspan": [[0, 2], [3, 11], [12, 19], [20, 23], [24, 27], [28, 39], [40, 50], [51, 53], [54, 61], [61, 62], [63, 66], [67, 74], [75, 77], [78, 87], [88, 90], [91, 98], [99, 106], [107, 115], [116, 119], [120, 127], [128, 136], [137, 140], [141, 145], [146, 147], [148, 152], [152, 153], [153, 161], [162, 171], [171, 172]]}
{"doc_key": "ai-test-128", "ner": [[4, 6, "algorithm"], [10, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 10, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "The", "code", "for", "extracting", "Gabor", "signs", "from", "images", "in", "MATLAB", "can", "be", "found", "at"], "sentence-detokenized": "(The code for extracting Gabor signs from images in MATLAB can be found at", "token2charspan": [[0, 1], [1, 4], [5, 9], [10, 13], [14, 24], [25, 30], [31, 36], [37, 41], [42, 48], [49, 51], [52, 58], [59, 62], [63, 65], [66, 71], [72, 74]]}
{"doc_key": "ai-test-129", "ner": [[0, 0, "misc"], [13, 15, "algorithm"], [19, 19, "task"], [21, 21, "task"], [23, 24, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 13, 15, "general-affiliation", "", false, false], [0, 0, 19, 19, "related-to", "solves_problem_of_type", false, false], [0, 0, 21, 21, "related-to", "solves_problem_of_type", false, false], [0, 0, 23, 24, "related-to", "solves_problem_of_type", false, false], [0, 0, 27, 28, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["NeuralExpert", "focuses", "the", "design", "specifications", "on", "the", "type", "of", "problem", "the", "user", "wants", "the", "neural", "network", "to", "solve", "(", "classification", ",", "prediction", ",", "feature", "approximation", ",", "or", "cluster", "analysis", ")", "."], "sentence-detokenized": "NeuralExpert focuses the design specifications on the type of problem the user wants the neural network to solve (classification, prediction, feature approximation, or cluster analysis).", "token2charspan": [[0, 12], [13, 20], [21, 24], [25, 31], [32, 46], [47, 49], [50, 53], [54, 58], [59, 61], [62, 69], [70, 73], [74, 78], [79, 84], [85, 88], [89, 95], [96, 103], [104, 106], [107, 112], [113, 114], [114, 128], [128, 129], [130, 140], [140, 141], [142, 149], [150, 163], [163, 164], [165, 167], [168, 175], [176, 184], [184, 185], [185, 186]]}
{"doc_key": "ai-test-130", "ner": [[1, 6, "misc"], [29, 31, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "size", "of", "the", "quantization", "step", "(", "\u0394", ")", "is", "small", "compared", "to", "the", "deviation", "of", "the", "quantized", "signal", ",", "it", "is", "relatively", "easy", "to", "show", "that", "the", "mean", "squared", "error", "due", "to", "such", "a", "rounding", "operation", "will", "be", "approximately", "math", "\\", "Delta^2/12", "/math.math"], "sentence-detokenized": "If the size of the quantization step (\u0394) is small compared to the deviation of the quantized signal, it is relatively easy to show that the mean squared error due to such a rounding operation will be approximately math\\Delta^2/12/math.math", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 18], [19, 31], [32, 36], [37, 38], [38, 39], [39, 40], [41, 43], [44, 49], [50, 58], [59, 61], [62, 65], [66, 75], [76, 78], [79, 82], [83, 92], [93, 99], [99, 100], [101, 103], [104, 106], [107, 117], [118, 122], [123, 125], [126, 130], [131, 135], [136, 139], [140, 144], [145, 152], [153, 158], [159, 162], [163, 165], [166, 170], [171, 172], [173, 181], [182, 191], [192, 196], [197, 199], [200, 213], [214, 218], [218, 219], [219, 229], [229, 239]]}
{"doc_key": "ai-test-131", "ner": [[15, 15, "product"], [23, 26, "researcher"], [28, 29, "researcher"], [31, 33, "researcher"], [35, 36, "researcher"], [38, 40, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Creating", "a", "rich", "lexicon", "with", "a", "suitable", "ontology", "requires", "considerable", "effort", ",", "e.g.", ",", "the", "Wordnet", "lexicon", "took", "many", "years", "of", "work", ".", "G.", "A", ".", "Miller", ",", "R.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Gross", ",", "K", ".", "Miller", "."], "sentence-detokenized": "Creating a rich lexicon with a suitable ontology requires considerable effort, e.g., the Wordnet lexicon took many years of work. G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 8], [9, 10], [11, 15], [16, 23], [24, 28], [29, 30], [31, 39], [40, 48], [49, 57], [58, 70], [71, 77], [77, 78], [79, 83], [83, 84], [85, 88], [89, 96], [97, 104], [105, 109], [110, 114], [115, 120], [121, 123], [124, 128], [128, 129], [130, 132], [133, 134], [134, 135], [136, 142], [142, 143], [144, 146], [147, 155], [155, 156], [157, 159], [160, 162], [163, 171], [171, 172], [173, 175], [176, 181], [181, 182], [183, 184], [184, 185], [186, 192], [192, 193]]}
{"doc_key": "ai-test-132", "ner": [[0, 0, "organisation"], [16, 17, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 17, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Kawasaki", "'s", "portfolio", "also", "includes", "retractable", "roofs", ",", "floors", "and", "other", "huge", "structures", "such", "as", "the", "Sapporo", "Dome", "retractable", "surface", "."], "sentence-detokenized": "Kawasaki's portfolio also includes retractable roofs, floors and other huge structures such as the Sapporo Dome retractable surface.", "token2charspan": [[0, 8], [8, 10], [11, 20], [21, 25], [26, 34], [35, 46], [47, 52], [52, 53], [54, 60], [61, 64], [65, 70], [71, 75], [76, 86], [87, 91], [92, 94], [95, 98], [99, 106], [107, 111], [112, 123], [124, 131], [131, 132]]}
{"doc_key": "ai-test-133", "ner": [[0, 3, "metrics"], [5, 7, "metrics"], [9, 11, "metrics"], [17, 18, "metrics"], [39, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 17, 18, "related-to", "", false, false], [0, 3, 39, 39, "opposite", "alternative_to", false, false], [5, 7, 0, 3, "type-of", "", false, false], [9, 11, 0, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kappa", "statistics", ",", "such", "as", "Fleiss", "'", "kappa", "and", "Cohen", "'s", "kappa", ",", "are", "methods", "for", "calculating", "inter-rater", "reliability", "based", "on", "various", "assumptions", "about", "marginal", "or", "prior", "distributions", ",", "and", "are", "increasingly", "used", "as", "alternatives", "to", "chance", "-", "corrected", "accuracy", "in", "other", "contexts", "."], "sentence-detokenized": "Kappa statistics, such as Fleiss' kappa and Cohen's kappa, are methods for calculating inter-rater reliability based on various assumptions about marginal or prior distributions, and are increasingly used as alternatives to chance-corrected accuracy in other contexts.", "token2charspan": [[0, 5], [6, 16], [16, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 39], [40, 43], [44, 49], [49, 51], [52, 57], [57, 58], [59, 62], [63, 70], [71, 74], [75, 86], [87, 98], [99, 110], [111, 116], [117, 119], [120, 127], [128, 139], [140, 145], [146, 154], [155, 157], [158, 163], [164, 177], [177, 178], [179, 182], [183, 186], [187, 199], [200, 204], [205, 207], [208, 220], [221, 223], [224, 230], [230, 231], [231, 240], [241, 249], [250, 252], [253, 258], [259, 267], [267, 268]]}
{"doc_key": "ai-test-134", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [19, 19, "researcher"], [28, 30, "algorithm"], [32, 38, "algorithm"], [40, 40, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 19, 19, "role", "student_of", false, false], [7, 8, 19, 19, "role", "student_of", false, false], [10, 11, 19, 19, "role", "student_of", false, false], [13, 14, 19, 19, "role", "student_of", false, false], [32, 38, 4, 5, "origin", "", false, false], [32, 38, 7, 8, "origin", "", false, false], [32, 38, 10, 11, "origin", "", false, false], [32, 38, 13, 14, "origin", "", false, false], [32, 38, 19, 19, "origin", "", false, false], [32, 38, 28, 30, "type-of", "", false, false], [40, 40, 32, 38, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Along", "with", "his", "students", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Graves", ",", "and", "others", ",", "Schmidhuber", "published", "increasingly", "sophisticated", "versions", "of", "a", "type", "of", "recurrent", "neural", "network", "called", "long", "-", "term", "short", "-", "term", "memory", "(", "LSTM", ")", "."], "sentence-detokenized": "Along with his students Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Graves, and others, Schmidhuber published increasingly sophisticated versions of a type of recurrent neural network called long-term short-term memory (LSTM).", "token2charspan": [[0, 5], [6, 10], [11, 14], [15, 23], [24, 28], [29, 39], [39, 40], [41, 46], [47, 51], [51, 52], [53, 57], [58, 65], [65, 66], [67, 71], [72, 78], [78, 79], [80, 83], [84, 90], [90, 91], [92, 103], [104, 113], [114, 126], [127, 140], [141, 149], [150, 152], [153, 154], [155, 159], [160, 162], [163, 172], [173, 179], [180, 187], [188, 194], [195, 199], [199, 200], [200, 204], [205, 210], [210, 211], [211, 215], [216, 222], [223, 224], [224, 228], [228, 229], [229, 230]]}
{"doc_key": "ai-test-135", "ner": [[4, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "The", "first", "Cobot", "KUKA", "LBR", "3", "is", "launched", "."], "sentence-detokenized": "2004 - The first Cobot KUKA LBR 3 is launched.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 16], [17, 22], [23, 27], [28, 31], [32, 33], [34, 36], [37, 45], [45, 46]]}
{"doc_key": "ai-test-136", "ner": [[10, 12, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Two", "shallow", "approaches", "used", "for", "training", "and", "subsequent", "disambiguation", "are", "Naive", "Bayes", "classifier", "and", "decision", "trees", "."], "sentence-detokenized": "Two shallow approaches used for training and subsequent disambiguation are Naive Bayes classifier and decision trees.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 27], [28, 31], [32, 40], [41, 44], [45, 55], [56, 70], [71, 74], [75, 80], [81, 86], [87, 97], [98, 101], [102, 110], [111, 116], [116, 117]]}
{"doc_key": "ai-test-137", "ner": [[5, 5, "misc"], [12, 13, "person"], [15, 17, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 12, 13, "origin", "", false, false], [5, 5, 15, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "practical", "forms", "of", "photography", "were", "introduced", "in", "January", "1839", "by", "Louis", "Daguerre", "and", "Henry", "Fox", "Talbot", "."], "sentence-detokenized": "The first practical forms of photography were introduced in January 1839 by Louis Daguerre and Henry Fox Talbot.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 25], [26, 28], [29, 40], [41, 45], [46, 56], [57, 59], [60, 67], [68, 72], [73, 75], [76, 81], [82, 90], [91, 94], [95, 100], [101, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-138", "ner": [[3, 5, "task"], [7, 8, "task"], [18, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 18, 18, "part-of", "task_part_of_field", false, false], [7, 8, 18, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "speech", "synthesis", "combined", "with", "speech", "recognition", "enables", "interaction", "with", "mobile", "devices", "through", "language", "processing", "interfaces", "."], "sentence-detokenized": "For example, speech synthesis combined with speech recognition enables interaction with mobile devices through language processing interfaces.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 19], [20, 29], [30, 38], [39, 43], [44, 50], [51, 62], [63, 70], [71, 82], [83, 87], [88, 94], [95, 102], [103, 110], [111, 119], [120, 130], [131, 141], [141, 142]]}
{"doc_key": "ai-test-139", "ner": [[0, 2, "product"], [14, 14, "programlang"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 14, 14, "general-affiliation", "", false, false], [0, 2, 16, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Phidgets", "can", "be", "programmed", "using", "a", "variety", "of", "software", "and", "programming", "languages", ",", "from", "Java", "to", "Microsoft", "Excel", "."], "sentence-detokenized": "Phidgets can be programmed using a variety of software and programming languages, from Java to Microsoft Excel.", "token2charspan": [[0, 8], [9, 12], [13, 15], [16, 26], [27, 32], [33, 34], [35, 42], [43, 45], [46, 54], [55, 58], [59, 70], [71, 80], [80, 81], [82, 86], [87, 91], [92, 94], [95, 104], [105, 110], [110, 111]]}
{"doc_key": "ai-test-140", "ner": [[2, 3, "field"], [9, 10, "researcher"], [12, 17, "misc"], [23, 24, "field"], [26, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 10, "origin", "", false, false], [9, 10, 23, 24, "general-affiliation", "topic_of_study", false, false], [9, 10, 26, 27, "general-affiliation", "topic_of_study", false, false], [12, 17, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "machine", "learning", "was", "coined", "in", "1959", "by", "Arthur", "Samuel", ",", "an", "American", "IBM", "employee", "and", "a", "pioneer", "in", "the", "field", "of", "computer", "games", "and", "artificial", "intelligence", "."], "sentence-detokenized": "The term machine learning was coined in 1959 by Arthur Samuel, an American IBM employee and a pioneer in the field of computer games and artificial intelligence.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 25], [26, 29], [30, 36], [37, 39], [40, 44], [45, 47], [48, 54], [55, 61], [61, 62], [63, 65], [66, 74], [75, 78], [79, 87], [88, 91], [92, 93], [94, 101], [102, 104], [105, 108], [109, 114], [115, 117], [118, 126], [127, 132], [133, 136], [137, 147], [148, 160], [160, 161]]}
{"doc_key": "ai-test-141", "ner": [[0, 1, "misc"], [2, 3, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Israeli", "poet", "David", "Avidan", ",", "fascinated", "by", "future", "technologies", "and", "their", "relationship", "to", "art", ",", "wanted", "to", "explore", "the", "use", "of", "computers", "in", "writing", "literature", "."], "sentence-detokenized": "Israeli poet David Avidan, fascinated by future technologies and their relationship to art, wanted to explore the use of computers in writing literature.", "token2charspan": [[0, 7], [8, 12], [13, 18], [19, 25], [25, 26], [27, 37], [38, 40], [41, 47], [48, 60], [61, 64], [65, 70], [71, 83], [84, 86], [87, 90], [90, 91], [92, 98], [99, 101], [102, 109], [110, 113], [114, 117], [118, 120], [121, 130], [131, 133], [134, 141], [142, 152], [152, 153]]}
{"doc_key": "ai-test-142", "ner": [[0, 6, "misc"], [9, 9, "organisation"], [16, 18, "location"], [29, 32, "location"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[9, 9, 0, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "part", "of", "the", "GATEway", "project", "in", "2017", ",", "Oxbotica", "trialled", "seven", "autonomous", "shuttle", "buses", "in", "Greenwich", ",", "travelling", "along", "a", "two", "-", "kilometre", "coastal", "path", "near", "London", "'s", "O2", "Arena", "on", "a", "route", "also", "used", "by", "pedestrians", "and", "cyclists", "."], "sentence-detokenized": "As part of the GATEway project in 2017, Oxbotica trialled seven autonomous shuttle buses in Greenwich, travelling along a two-kilometre coastal path near London's O2 Arena on a route also used by pedestrians and cyclists.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 22], [23, 30], [31, 33], [34, 38], [38, 39], [40, 48], [49, 57], [58, 63], [64, 74], [75, 82], [83, 88], [89, 91], [92, 101], [101, 102], [103, 113], [114, 119], [120, 121], [122, 125], [125, 126], [126, 135], [136, 143], [144, 148], [149, 153], [154, 160], [160, 162], [163, 165], [166, 171], [172, 174], [175, 176], [177, 182], [183, 187], [188, 192], [193, 195], [196, 207], [208, 211], [212, 220], [220, 221]]}
{"doc_key": "ai-test-143", "ner": [[8, 9, "task"], [13, 17, "metrics"], [24, 26, "misc"], [27, 27, "metrics"], [29, 29, "metrics"], [32, 32, "metrics"], [34, 34, "metrics"], [36, 37, "metrics"], [40, 40, "metrics"], [42, 42, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[13, 17, 24, 26, "related-to", "is_a", false, false], [13, 17, 27, 27, "usage", "", false, false], [13, 17, 29, 29, "usage", "", false, false], [27, 27, 32, 32, "named", "same", false, false], [29, 29, 42, 42, "named", "same", false, false], [32, 32, 40, 40, "opposite", "", false, false], [32, 32, 42, 42, "opposite", "", false, false], [34, 34, 32, 32, "named", "", false, false], [36, 37, 32, 32, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["An", "unrelated", "but", "commonly", "used", "combination", "of", "basic", "information", "retrieval", "statistics", "is", "the", "F", "-", "score", ",", "which", "is", "a", "(", "possibly", "weighted", ")", "harmonic", "average", "of", "recall", "and", "precision", ",", "where", "recall", "=", "sensitivity", "=", "TRUE", "positive", ",", "but", "specificity", "and", "precision", "are", "entirely", "different", "measures", "."], "sentence-detokenized": "An unrelated but commonly used combination of basic information retrieval statistics is the F-score, which is a (possibly weighted) harmonic average of recall and precision, where recall = sensitivity = TRUE positive, but specificity and precision are entirely different measures.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 25], [26, 30], [31, 42], [43, 45], [46, 51], [52, 63], [64, 73], [74, 84], [85, 87], [88, 91], [92, 93], [93, 94], [94, 99], [99, 100], [101, 106], [107, 109], [110, 111], [112, 113], [113, 121], [122, 130], [130, 131], [132, 140], [141, 148], [149, 151], [152, 158], [159, 162], [163, 172], [172, 173], [174, 179], [180, 186], [187, 188], [189, 200], [201, 202], [203, 207], [208, 216], [216, 217], [218, 221], [222, 233], [234, 237], [238, 247], [248, 251], [252, 260], [261, 270], [271, 279], [279, 280]]}
{"doc_key": "ai-test-144", "ner": [[0, 1, "field"], [10, 10, "field"], [12, 12, "field"], [14, 14, "field"], [16, 17, "field"], [19, 21, "field"], [28, 29, "product"], [31, 34, "product"], [36, 37, "product"], [39, 41, "product"], [52, 54, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 10, "origin", "takes_inspiration_from", false, false], [0, 1, 12, 12, "origin", "takes_inspiration_from", false, false], [0, 1, 14, 14, "origin", "takes_inspiration_from", false, false], [0, 1, 16, 17, "origin", "takes_inspiration_from", false, false], [0, 1, 19, 21, "origin", "takes_inspiration_from", false, false], [28, 29, 0, 1, "origin", "", false, false], [31, 34, 0, 1, "origin", "", false, false], [36, 37, 0, 1, "origin", "", false, false], [39, 41, 0, 1, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Neuromorphic", "engineering", "is", "an", "interdisciplinary", "subject", "that", "draws", "inspiration", "from", "biology", ",", "physics", ",", "mathematics", ",", "computer", "science", "and", "electronic", "engineering", "to", "design", "artificial", "nervous", "systems", "such", "as", "vision", "systems", ",", "head", "-", "eye", "systems", ",", "auditory", "processors", "and", "autonomous", "robots", "whose", "physical", "architecture", "and", "design", "principles", "are", "based", "on", "those", "of", "biological", "nervous", "systems", "."], "sentence-detokenized": "Neuromorphic engineering is an interdisciplinary subject that draws inspiration from biology, physics, mathematics, computer science and electronic engineering to design artificial nervous systems such as vision systems, head-eye systems, auditory processors and autonomous robots whose physical architecture and design principles are based on those of biological nervous systems.", "token2charspan": [[0, 12], [13, 24], [25, 27], [28, 30], [31, 48], [49, 56], [57, 61], [62, 67], [68, 79], [80, 84], [85, 92], [92, 93], [94, 101], [101, 102], [103, 114], [114, 115], [116, 124], [125, 132], [133, 136], [137, 147], [148, 159], [160, 162], [163, 169], [170, 180], [181, 188], [189, 196], [197, 201], [202, 204], [205, 211], [212, 219], [219, 220], [221, 225], [225, 226], [226, 229], [230, 237], [237, 238], [239, 247], [248, 258], [259, 262], [263, 273], [274, 280], [281, 286], [287, 295], [296, 308], [309, 312], [313, 319], [320, 330], [331, 334], [335, 340], [341, 343], [344, 349], [350, 352], [353, 363], [364, 371], [372, 379], [379, 380]]}
{"doc_key": "ai-test-145", "ner": [[3, 5, "metrics"], [9, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 9, 3, 5, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Specifically", ",", "the", "BIBO", "stability", "criterion", "requires", "that", "the", "ROC", "of", "the", "system", "includes", "the", "unit", "circle", "."], "sentence-detokenized": "Specifically, the BIBO stability criterion requires that the ROC of the system includes the unit circle.", "token2charspan": [[0, 12], [12, 13], [14, 17], [18, 22], [23, 32], [33, 42], [43, 51], [52, 56], [57, 60], [61, 64], [65, 67], [68, 71], [72, 78], [79, 87], [88, 91], [92, 96], [97, 103], [103, 104]]}
{"doc_key": "ai-test-146", "ner": [[7, 7, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "The", "program", "has", "been", "rewritten", "in", "Java", "since", "1998", "."], "sentence-detokenized": "2 The program has been rewritten in Java since 1998.", "token2charspan": [[0, 1], [2, 5], [6, 13], [14, 17], [18, 22], [23, 32], [33, 35], [36, 40], [41, 46], [47, 51], [51, 52]]}
{"doc_key": "ai-test-147", "ner": [[0, 1, "metrics"], [8, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 8, 9, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "MCC", "can", "be", "calculated", "directly", "from", "the", "confusion", "matrix", "using", "the", "formula", ":"], "sentence-detokenized": "The MCC can be calculated directly from the confusion matrix using the formula:", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 25], [26, 34], [35, 39], [40, 43], [44, 53], [54, 60], [61, 66], [67, 70], [71, 78], [78, 79]]}
{"doc_key": "ai-test-148", "ner": [[8, 13, "organisation"], [20, 25, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 13, 20, 25, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "developed", "by", "a", "team", "at", "the", "MIT", "-", "IBM", "Watson", "AI", "Lab", "and", "was", "first", "presented", "at", "the", "2018", "International", "Conference", "on", "Learning", "Representations", "."], "sentence-detokenized": "It was developed by a team at the MIT-IBM Watson AI Lab and was first presented at the 2018 International Conference on Learning Representations.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 29], [30, 33], [34, 37], [37, 38], [38, 41], [42, 48], [49, 51], [52, 55], [56, 59], [60, 63], [64, 69], [70, 79], [80, 82], [83, 86], [87, 91], [92, 105], [106, 116], [117, 119], [120, 128], [129, 144], [144, 145]]}
{"doc_key": "ai-test-149", "ner": [[1, 5, "metrics"], [16, 17, "metrics"], [19, 25, "metrics"], [50, 50, "metrics"], [52, 52, "metrics"], [58, 60, "metrics"], [64, 64, "metrics"], [66, 66, "metrics"], [69, 71, "metrics"], [76, 76, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[16, 17, 50, 50, "type-of", "", false, false], [16, 17, 58, 60, "related-to", "collapses_to_identity", false, false], [19, 25, 52, 52, "type-of", "", false, false], [19, 25, 58, 60, "related-to", "collapses_to_identity", false, false], [19, 25, 69, 71, "named", "same", false, false], [64, 64, 76, 76, "related-to", "collapses_to_identity", false, false], [66, 66, 76, 76, "related-to", "collapses_to_identity", false, false], [69, 71, 76, 76, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["If", "the", "true", "prevalences", "of", "the", "two", "positive", "variables", "are", "the", "same", "as", "predicted", "in", "the", "Fleiss", "kappa", "and", "F", "-", "score", ",", "i.e.", ",", "the", "number", "of", "positive", "predictions", "is", "identical", "to", "the", "number", "of", "positive", "classes", "in", "the", "dichotomous", "(", "two", "-", "class", ")", "case", ",", "the", "differential", "kappa", "and", "correlation", "measures", "collapse", "to", "identity", "with", "Youden", "'s", "J", ",", "and", "the", "recall", ",", "precision", ",", "and", "F", "-", "score", "are", "similarly", "identical", "to", "accuracy", "."], "sentence-detokenized": "If the true prevalences of the two positive variables are the same as predicted in the Fleiss kappa and F-score, i.e., the number of positive predictions is identical to the number of positive classes in the dichotomous (two-class) case, the differential kappa and correlation measures collapse to identity with Youden's J, and the recall, precision, and F-score are similarly identical to accuracy.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 23], [24, 26], [27, 30], [31, 34], [35, 43], [44, 53], [54, 57], [58, 61], [62, 66], [67, 69], [70, 79], [80, 82], [83, 86], [87, 93], [94, 99], [100, 103], [104, 105], [105, 106], [106, 111], [111, 112], [113, 117], [117, 118], [119, 122], [123, 129], [130, 132], [133, 141], [142, 153], [154, 156], [157, 166], [167, 169], [170, 173], [174, 180], [181, 183], [184, 192], [193, 200], [201, 203], [204, 207], [208, 219], [220, 221], [221, 224], [224, 225], [225, 230], [230, 231], [232, 236], [236, 237], [238, 241], [242, 254], [255, 260], [261, 264], [265, 276], [277, 285], [286, 294], [295, 297], [298, 306], [307, 311], [312, 318], [318, 320], [321, 322], [322, 323], [324, 327], [328, 331], [332, 338], [338, 339], [340, 349], [349, 350], [351, 354], [355, 356], [356, 357], [357, 362], [363, 366], [367, 376], [377, 386], [387, 389], [390, 398], [398, 399]]}
{"doc_key": "ai-test-150", "ner": [[1, 7, "misc"], [5, 5, "misc"], [9, 9, "conference"], [14, 17, "task"], [18, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 7, 9, 9, "part-of", "", false, false], [1, 7, 9, 9, "physical", "", false, false], [1, 7, 9, 9, "temporal", "", false, false], [5, 5, 1, 7, "named", "", false, false], [14, 17, 1, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Building", "Educational", "Applications", "(", "BEA", ")", "workshop", "at", "NAACL", "2013", "featured", "the", "first", "NLI", "collaborative", "task", ".", "Tetreault", "et", "al", ",", "2013", "The", "competition", "attracted", "29", "teams", "from", "around", "the", "world", ",", "24", "of", "which", "also", "published", "a", "paper", "describing", "their", "systems", "and", "approaches", "."], "sentence-detokenized": "The Building Educational Applications (BEA) workshop at NAACL 2013 featured the first NLI collaborative task. Tetreault et al, 2013 The competition attracted 29 teams from around the world, 24 of which also published a paper describing their systems and approaches.", "token2charspan": [[0, 3], [4, 12], [13, 24], [25, 37], [38, 39], [39, 42], [42, 43], [44, 52], [53, 55], [56, 61], [62, 66], [67, 75], [76, 79], [80, 85], [86, 89], [90, 103], [104, 108], [108, 109], [110, 119], [120, 122], [123, 125], [125, 126], [127, 131], [132, 135], [136, 147], [148, 157], [158, 160], [161, 166], [167, 171], [172, 178], [179, 182], [183, 188], [188, 189], [190, 192], [193, 195], [196, 201], [202, 206], [207, 216], [217, 218], [219, 224], [225, 235], [236, 241], [242, 249], [250, 253], [254, 264], [264, 265]]}
{"doc_key": "ai-test-151", "ner": [[0, 2, "algorithm"], [5, 8, "algorithm"], [15, 16, "misc"], [20, 23, "misc"], [37, 38, "misc"], [41, 42, "algorithm"], [45, 45, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 5, 8, "type-of", "", false, false], [0, 2, 15, 16, "related-to", "finds", false, false], [20, 23, 15, 16, "type-of", "", false, false], [45, 45, 41, 42, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Viterbi", "algorithm", "is", "a", "dynamic", "programming", "algorithm", "for", "finding", "the", "most", "probable", "sequence", "of", "hidden", "states", ",", "called", "the", "Viterbi", "path", ",", "that", "leads", "to", "a", "sequence", "of", "observed", "events", ",", "especially", "in", "the", "context", "of", "Markov", "information", "sources", "and", "hidden", "Markov", "models", "(", "HMMs", ")", "."], "sentence-detokenized": "The Viterbi algorithm is a dynamic programming algorithm for finding the most probable sequence of hidden states, called the Viterbi path, that leads to a sequence of observed events, especially in the context of Markov information sources and hidden Markov models (HMMs).", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 24], [25, 26], [27, 34], [35, 46], [47, 56], [57, 60], [61, 68], [69, 72], [73, 77], [78, 86], [87, 95], [96, 98], [99, 105], [106, 112], [112, 113], [114, 120], [121, 124], [125, 132], [133, 137], [137, 138], [139, 143], [144, 149], [150, 152], [153, 154], [155, 163], [164, 166], [167, 175], [176, 182], [182, 183], [184, 194], [195, 197], [198, 201], [202, 209], [210, 212], [213, 219], [220, 231], [232, 239], [240, 243], [244, 250], [251, 257], [258, 264], [265, 266], [266, 270], [270, 271], [271, 272]]}
{"doc_key": "ai-test-152", "ner": [[1, 1, "field"], [3, 5, "algorithm"], [8, 9, "misc"], [12, 13, "algorithm"], [15, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 1, 1, "part-of", "", false, false], [3, 5, 8, 9, "general-affiliation", "", false, false], [3, 5, 12, 13, "related-to", "generalizes_from", false, false], [3, 5, 15, 20, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "statistics", ",", "multinomial", "logistic", "regression", "is", "a", "classification", "method", "that", "generalizes", "logistic", "regression", "to", "multiclass", "classification", ",", "i.e.", ",", "with", "more", "than", "two", "possible", "discrete", "outcomes", "."], "sentence-detokenized": "In statistics, multinomial logistic regression is a classification method that generalizes logistic regression to multiclass classification, i.e., with more than two possible discrete outcomes.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 26], [27, 35], [36, 46], [47, 49], [50, 51], [52, 66], [67, 73], [74, 78], [79, 90], [91, 99], [100, 110], [111, 113], [114, 124], [125, 139], [139, 140], [141, 145], [145, 146], [147, 151], [152, 156], [157, 161], [162, 165], [166, 174], [175, 183], [184, 192], [192, 193]]}
{"doc_key": "ai-test-153", "ner": [[0, 2, "algorithm"], [9, 10, "field"], [12, 16, "field"], [18, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 9, 10, "part-of", "", false, false], [0, 2, 12, 16, "part-of", "", false, false], [18, 18, 0, 2, "usage", "", true, false], [20, 21, 0, 2, "usage", "", true, false], [23, 24, 0, 2, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hidden", "Markov", "models", "are", "known", "for", "their", "applications", "to", "reinforcement", "learning", "and", "temporal", "pattern", "recognition", ",", "such", "as", "speech", ",", "handwriting", "recognition", ",", "gesture", "recognition", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Hidden Markov models are known for their applications to reinforcement learning and temporal pattern recognition, such as speech, handwriting recognition, gesture recognition, Thad Starner, Alex Pentland.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 30], [31, 34], [35, 40], [41, 53], [54, 56], [57, 70], [71, 79], [80, 83], [84, 92], [93, 100], [101, 112], [112, 113], [114, 118], [119, 121], [122, 128], [128, 129], [130, 141], [142, 153], [153, 154], [155, 162], [163, 174], [174, 175], [176, 180], [181, 188], [188, 189], [190, 194], [195, 203], [203, 204]]}
{"doc_key": "ai-test-154", "ner": [[6, 14, "misc"], [31, 34, "metrics"], [36, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 14, 36, 38, "named", "", false, false], [31, 34, 36, 38, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Essentially", ",", "this", "means", "that", "if", "a", "given", "gram", "occurred", "more", "than", "k", "times", "in", "training", ",", "the", "conditional", "probability", "of", "a", "word", "given", "it", "s", "history", "is", "proportional", "to", "the", "maximum", "likelihood", "estimate", "of", "that", "n", "-", "gram", "."], "sentence-detokenized": "Essentially, this means that if a given gram occurred more than k times in training, the conditional probability of a word given its history is proportional to the maximum likelihood estimate of that n-gram.", "token2charspan": [[0, 11], [11, 12], [13, 17], [18, 23], [24, 28], [29, 31], [32, 33], [34, 39], [40, 44], [45, 53], [54, 58], [59, 63], [64, 65], [66, 71], [72, 74], [75, 83], [83, 84], [85, 88], [89, 100], [101, 112], [113, 115], [116, 117], [118, 122], [123, 128], [129, 131], [131, 132], [133, 140], [141, 143], [144, 156], [157, 159], [160, 163], [164, 171], [172, 182], [183, 191], [192, 194], [195, 199], [200, 201], [201, 202], [202, 206], [206, 207]]}
{"doc_key": "ai-test-155", "ner": [[4, 5, "task"], [7, 8, "task"], [11, 15, "task"], [17, 21, "task"], [30, 33, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[30, 33, 17, 21, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "interested", "in", "knowledge", "representation", ",", "rational", "reasoning", ",", "and", "natural", "language", "understanding", ",", "believing", "that", "a", "deep", "understanding", "of", "language", "can", "currently", "only", "be", "achieved", "through", "the", "expressive", "hand", "-", "engineering", "of", "semantically", "rich", "formalisms", "in", "conjunction", "with", "statistical", "preferences", "."], "sentence-detokenized": "He is interested in knowledge representation, rational reasoning, and natural language understanding, believing that a deep understanding of language can currently only be achieved through the expressive hand-engineering of semantically rich formalisms in conjunction with statistical preferences.", "token2charspan": [[0, 2], [3, 5], [6, 16], [17, 19], [20, 29], [30, 44], [44, 45], [46, 54], [55, 64], [64, 65], [66, 69], [70, 77], [78, 86], [87, 100], [100, 101], [102, 111], [112, 116], [117, 118], [119, 123], [124, 137], [138, 140], [141, 149], [150, 153], [154, 163], [164, 168], [169, 171], [172, 180], [181, 188], [189, 192], [193, 203], [204, 208], [208, 209], [209, 220], [221, 223], [224, 236], [237, 241], [242, 252], [253, 255], [256, 267], [268, 272], [273, 284], [285, 296], [296, 297]]}
{"doc_key": "ai-test-156", "ner": [[1, 1, "programlang"], [3, 3, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "JavaScript", ",", "Python", "or"], "sentence-detokenized": "In JavaScript, Python or", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 21], [22, 24]]}
{"doc_key": "ai-test-157", "ner": [[0, 2, "misc"], [6, 9, "misc"], [11, 11, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 9, "part-of", "", false, false], [6, 9, 11, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Newcomb", "Awards", "are", "announced", "in", "AI", "Magazine", ",", "published", "by", "AAAI", "."], "sentence-detokenized": "The Newcomb Awards are announced in AI Magazine, published by AAAI.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 22], [23, 32], [33, 35], [36, 38], [39, 47], [47, 48], [49, 58], [59, 61], [62, 66], [66, 67]]}
{"doc_key": "ai-test-158", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "squared", "error", "on", "a", "test", "set", "of", "100", "specimens", "is", "0.084", ",", "which", "is", "less", "than", "the", "unnormalized", "error", "."], "sentence-detokenized": "The mean squared error on a test set of 100 specimens is 0.084, which is less than the unnormalized error.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 25], [26, 27], [28, 32], [33, 36], [37, 39], [40, 43], [44, 53], [54, 56], [57, 62], [62, 63], [64, 69], [70, 72], [73, 77], [78, 82], [83, 86], [87, 99], [100, 105], [105, 106]]}
{"doc_key": "ai-test-159", "ner": [[0, 4, "metrics"], [8, 14, "field"], [20, 22, "task"], [24, 24, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 14, 0, 4, "usage", "", false, false], [20, 22, 8, 14, "part-of", "task_part_of_field", false, false], [24, 24, 20, 22, "named", "", false, false], [27, 28, 8, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["F", "-", "scores", "are", "widely", "used", "in", "the", "natural", "language", "processing", "literature", ",", "for", "example", ",", "in", "the", "evaluation", "of", "named", "entity", "recognition", "(", "NER", ")", "and", "word", "segmentation", "."], "sentence-detokenized": "F-scores are widely used in the natural language processing literature, for example, in the evaluation of named entity recognition (NER) and word segmentation.", "token2charspan": [[0, 1], [1, 2], [2, 8], [9, 12], [13, 19], [20, 24], [25, 27], [28, 31], [32, 39], [40, 48], [49, 59], [60, 70], [70, 71], [72, 75], [76, 83], [83, 84], [85, 87], [88, 91], [92, 102], [103, 105], [106, 111], [112, 118], [119, 130], [131, 132], [132, 135], [135, 136], [137, 140], [141, 145], [146, 158], [158, 159]]}
{"doc_key": "ai-test-160", "ner": [[0, 0, "product"], [5, 8, "product"], [17, 18, "misc"], [21, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 17, 18, "related-to", "performs_task", false, false], [0, 0, 21, 22, "related-to", "performs_task", false, false], [5, 8, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Chatbots", "are", "typically", "used", "in", "dialog", "systems", "for", "a", "variety", "of", "purposes", ",", "including", "customer", "service", ",", "routing", "requests", ",", "or", "gathering", "information", "."], "sentence-detokenized": "Chatbots are typically used in dialog systems for a variety of purposes, including customer service, routing requests, or gathering information.", "token2charspan": [[0, 8], [9, 12], [13, 22], [23, 27], [28, 30], [31, 37], [38, 45], [46, 49], [50, 51], [52, 59], [60, 62], [63, 71], [71, 72], [73, 82], [83, 91], [92, 99], [99, 100], [101, 108], [109, 117], [117, 118], [119, 121], [122, 131], [132, 143], [143, 144]]}
{"doc_key": "ai-test-161", "ner": [[3, 9, "conference"], [13, 21, "conference"], [30, 40, "conference"], [47, 47, "conference"], [51, 54, "conference"], [57, 58, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 21, 3, 9, "named", "", false, false], [30, 40, 3, 9, "named", "", false, false], [47, 47, 30, 40, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Important", "journals", "include", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "later", "renamed", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "and", ",", "as", "of", "September", "2014", ",", "renamed", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "-", "after", "the", "merger", "with", "the", "ACM", "publication", ")", ",", "Computer", "Speech", "and", "Language", ",", "and", "Speech", "Communication", "."], "sentence-detokenized": "Important journals include IEEE Transactions on Speech and Audio Processing (later renamed IEEE Transactions on Audio, Speech and Language Processing and, as of September 2014, renamed IEEE/ACM Transactions on Audio, Speech and Language Processing - after the merger with the ACM publication), Computer Speech and Language, and Speech Communication.", "token2charspan": [[0, 9], [10, 18], [19, 26], [27, 31], [32, 44], [45, 47], [48, 54], [55, 58], [59, 64], [65, 75], [76, 77], [77, 82], [83, 90], [91, 95], [96, 108], [109, 111], [112, 117], [117, 118], [119, 125], [126, 129], [130, 138], [139, 149], [150, 153], [153, 154], [155, 157], [158, 160], [161, 170], [171, 175], [175, 176], [177, 184], [185, 189], [189, 190], [190, 193], [194, 206], [207, 209], [210, 215], [215, 216], [217, 223], [224, 227], [228, 236], [237, 247], [248, 249], [250, 255], [256, 259], [260, 266], [267, 271], [272, 275], [276, 279], [280, 291], [291, 292], [292, 293], [294, 302], [303, 309], [310, 313], [314, 322], [322, 323], [324, 327], [328, 334], [335, 348], [348, 349]]}
{"doc_key": "ai-test-162", "ner": [[0, 2, "algorithm"], [5, 6, "task"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 0, 2, "usage", "", false, false], [5, 6, 8, 9, "part-of", "task_part_of_field", false, false], [5, 6, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["EM", "is", "often", "used", "for", "data", "clustering", "in", "machine", "learning", "and", "computer", "vision", "."], "sentence-detokenized": "EM is often used for data clustering in machine learning and computer vision.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 16], [17, 20], [21, 25], [26, 36], [37, 39], [40, 47], [48, 56], [57, 60], [61, 69], [70, 76], [76, 77]]}
{"doc_key": "ai-test-163", "ner": [[9, 11, "metrics"], [25, 27, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 25, 27, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["Although", "there", "is", "no", "perfect", "way", "to", "describe", "the", "confusion", "matrix", "of", "positive", "and", "negative", "TRUE", "and", "FALSE", "outcomes", "by", "a", "single", "number", ",", "the", "Matthews", "correlation", "coefficient", "is", "generally", "considered", "to", "be", "one", "of", "the", "best", "measures", "."], "sentence-detokenized": "Although there is no perfect way to describe the confusion matrix of positive and negative TRUE and FALSE outcomes by a single number, the Matthews correlation coefficient is generally considered to be one of the best measures.", "token2charspan": [[0, 8], [9, 14], [15, 17], [18, 20], [21, 28], [29, 32], [33, 35], [36, 44], [45, 48], [49, 58], [59, 65], [66, 68], [69, 77], [78, 81], [82, 90], [91, 95], [96, 99], [100, 105], [106, 114], [115, 117], [118, 119], [120, 126], [127, 133], [133, 134], [135, 138], [139, 147], [148, 159], [160, 171], [172, 174], [175, 184], [185, 195], [196, 198], [199, 201], [202, 205], [206, 208], [209, 212], [213, 217], [218, 226], [226, 227]]}
{"doc_key": "ai-test-164", "ner": [[11, 12, "field"], [28, 31, "field"], [33, 36, "field"], [38, 39, "algorithm"], [41, 42, "task"], [44, 45, "algorithm"], [50, 52, "algorithm"], [54, 57, "algorithm"], [61, 66, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[33, 36, 28, 31, "part-of", "subfield", false, false], [38, 39, 33, 36, "part-of", "", false, true], [41, 42, 33, 36, "part-of", "", false, true], [44, 45, 33, 36, "part-of", "", false, true], [50, 52, 33, 36, "part-of", "", false, true], [54, 57, 33, 36, "part-of", "", false, true], [61, 66, 33, 36, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["With", "the", "increasing", "size", "and", "complexity", "of", "datasets", ",", "direct", "practical", "data", "analysis", "has", "been", "extended", "to", "indirect", ",", "automated", "data", "processing", ",", "aided", "by", "further", "discoveries", "in", "computer", "science", ",", "especially", "in", "machine", "learning", ",", "such", "as", "neural", "networks", ",", "cluster", "analysis", ",", "genetic", "algorithms", "(", "1950s", ")", ",", "decision", "tree", "learning", "and", "decision", "rules", "(", "1960s", ")", ",", "and", "support", "vector", "machines", "(", "1990", "s", ")", "."], "sentence-detokenized": "With the increasing size and complexity of datasets, direct practical data analysis has been extended to indirect, automated data processing, aided by further discoveries in computer science, especially in machine learning, such as neural networks, cluster analysis, genetic algorithms (1950s), decision tree learning and decision rules (1960s), and support vector machines (1990s).", "token2charspan": [[0, 4], [5, 8], [9, 19], [20, 24], [25, 28], [29, 39], [40, 42], [43, 51], [51, 52], [53, 59], [60, 69], [70, 74], [75, 83], [84, 87], [88, 92], [93, 101], [102, 104], [105, 113], [113, 114], [115, 124], [125, 129], [130, 140], [140, 141], [142, 147], [148, 150], [151, 158], [159, 170], [171, 173], [174, 182], [183, 190], [190, 191], [192, 202], [203, 205], [206, 213], [214, 222], [222, 223], [224, 228], [229, 231], [232, 238], [239, 247], [247, 248], [249, 256], [257, 265], [265, 266], [267, 274], [275, 285], [286, 287], [287, 292], [292, 293], [293, 294], [295, 303], [304, 308], [309, 317], [318, 321], [322, 330], [331, 336], [337, 338], [338, 343], [343, 344], [344, 345], [346, 349], [350, 357], [358, 364], [365, 373], [374, 375], [375, 379], [379, 380], [380, 381], [381, 382]]}
{"doc_key": "ai-test-165", "ner": [[6, 6, "researcher"], [25, 26, "misc"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[25, 26, 6, 6, "artifact", "", false, false], [25, 26, 15, 16, "artifact", "", false, false], [25, 26, 18, 19, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "fall", "of", "2005", ",", "Thrun", ",", "along", "with", "his", "long", "-", "time", "collaborators", "Dieter", "Fox", "and", "Wolfram", "Burgard", ",", "published", "a", "textbook", "entitled", "Probabilistic", "Robotics", "."], "sentence-detokenized": "In the fall of 2005, Thrun, along with his long-time collaborators Dieter Fox and Wolfram Burgard, published a textbook entitled Probabilistic Robotics.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 19], [19, 20], [21, 26], [26, 27], [28, 33], [34, 38], [39, 42], [43, 47], [47, 48], [48, 52], [53, 66], [67, 73], [74, 77], [78, 81], [82, 89], [90, 97], [97, 98], [99, 108], [109, 110], [111, 119], [120, 128], [129, 142], [143, 151], [151, 152]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "and", "Pereiramath", "as", "follows", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum and Pereiramath as follows:", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 37], [38, 49], [50, 52], [53, 60], [60, 61]]}
{"doc_key": "ai-test-167", "ner": [[0, 1, "task"], [3, 3, "task"], [7, 8, "field"], [14, 15, "field"], [17, 19, "field"], [21, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 14, 15, "part-of", "task_part_of_field", false, false], [0, 1, 17, 19, "part-of", "task_part_of_field", false, false], [3, 3, 0, 1, "named", "", false, false], [14, 15, 7, 8, "part-of", "subfield", false, false], [17, 19, 7, 8, "part-of", "subfield", false, false], [21, 23, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Question", "answering", "(", "QA", ")", "is", "a", "computer", "science", "discipline", "within", "the", "fields", "of", "information", "retrieval", "and", "Natural", "Language", "Processing", "(", "NLP", ")", "that", "deals", "with", "building", "systems", "that", "automatically", "answer", "questions", "asked", "by", "humans", "in", "natural", "language", "."], "sentence-detokenized": "Question answering (QA) is a computer science discipline within the fields of information retrieval and Natural Language Processing (NLP) that deals with building systems that automatically answer questions asked by humans in natural language.", "token2charspan": [[0, 8], [9, 18], [19, 20], [20, 22], [22, 23], [24, 26], [27, 28], [29, 37], [38, 45], [46, 56], [57, 63], [64, 67], [68, 74], [75, 77], [78, 89], [90, 99], [100, 103], [104, 111], [112, 120], [121, 131], [132, 133], [133, 136], [136, 137], [138, 142], [143, 148], [149, 153], [154, 162], [163, 170], [171, 175], [176, 189], [190, 196], [197, 206], [207, 212], [213, 215], [216, 222], [223, 225], [226, 233], [234, 242], [242, 243]]}
{"doc_key": "ai-test-168", "ner": [[9, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "the", "version", "of", "the", "metric", "used", "in", "NIST", "evaluations", "prior", "to", "2009", "used", "the", "shortest", "reference", "sentence", "instead", "."], "sentence-detokenized": "However, the version of the metric used in NIST evaluations prior to 2009 used the shortest reference sentence instead.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 20], [21, 23], [24, 27], [28, 34], [35, 39], [40, 42], [43, 47], [48, 59], [60, 65], [66, 68], [69, 73], [74, 78], [79, 82], [83, 91], [92, 101], [102, 110], [111, 118], [118, 119]]}
{"doc_key": "ai-test-169", "ner": [[6, 6, "person"], [14, 14, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["On", "August", "27", ",", "2018", ",", "Toyota", "announced", "a", "$", "500", "million", "investment", "in", "Uber", "autonomous", "vehicles", "."], "sentence-detokenized": "On August 27, 2018, Toyota announced a $500 million investment in Uber autonomous vehicles.", "token2charspan": [[0, 2], [3, 9], [10, 12], [12, 13], [14, 18], [18, 19], [20, 26], [27, 36], [37, 38], [39, 40], [40, 43], [44, 51], [52, 62], [63, 65], [66, 70], [71, 81], [82, 90], [90, 91]]}
{"doc_key": "ai-test-170", "ner": [[5, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sampling", "maximum", "is", "a", "maximum", "likelihood", "estimate", "of", "the", "population", "maximum", ",", "but", "as", "noted", "above", ",", "it", "is", "biased", "."], "sentence-detokenized": "The sampling maximum is a maximum likelihood estimate of the population maximum, but as noted above, it is biased.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 23], [24, 25], [26, 33], [34, 44], [45, 53], [54, 56], [57, 60], [61, 71], [72, 79], [79, 80], [81, 84], [85, 87], [88, 93], [94, 99], [99, 100], [101, 103], [104, 106], [107, 113], [113, 114]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [3, 3, "misc"], [6, 9, "metrics"], [17, 19, "algorithm"], [21, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 3, "related-to", "overcomes", false, false], [0, 0, 6, 9, "related-to", "increases", false, false], [3, 3, 17, 19, "opposite", "", false, false], [3, 3, 21, 23, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LSI", "helps", "overcome", "synonymy", "by", "increasing", "recall", ",", "which", "is", "one", "of", "the", "most", "problematic", "limitations", "in", "Boolean", "keyword", "queries", "and", "vector", "space", "models", "."], "sentence-detokenized": "LSI helps overcome synonymy by increasing recall, which is one of the most problematic limitations in Boolean keyword queries and vector space models.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 27], [28, 30], [31, 41], [42, 48], [48, 49], [50, 55], [56, 58], [59, 62], [63, 65], [66, 69], [70, 74], [75, 86], [87, 98], [99, 101], [102, 109], [110, 117], [118, 125], [126, 129], [130, 136], [137, 142], [143, 149], [149, 150]]}
{"doc_key": "ai-test-172", "ner": [[0, 0, "task"], [19, 19, "programlang"], [21, 21, "programlang"], [23, 23, "programlang"], [25, 26, "programlang"], [28, 28, "programlang"], [30, 30, "programlang"], [32, 32, "programlang"], [34, 34, "programlang"], [36, 36, "programlang"], [38, 38, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 0, 19, 19, "general-affiliation", "", false, false], [0, 0, 21, 21, "general-affiliation", "", false, false], [0, 0, 23, 23, "general-affiliation", "", false, false], [0, 0, 25, 26, "general-affiliation", "", false, false], [0, 0, 28, 28, "general-affiliation", "", false, false], [0, 0, 30, 30, "general-affiliation", "", false, false], [0, 0, 32, 32, "general-affiliation", "", false, false], [0, 0, 34, 34, "general-affiliation", "", false, false], [0, 0, 36, 36, "general-affiliation", "", false, false], [0, 0, 38, 38, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Data", "acquisition", "applications", "are", "usually", "controlled", "by", "software", "programs", "created", "using", "various", "general", "-", "purpose", "programming", "languages", "such", "as", "Assembly", ",", "BASIC", ",", "C", ",", "C", "++", ",", "C#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", ",", "etc."], "sentence-detokenized": "Data acquisition applications are usually controlled by software programs created using various general-purpose programming languages such as Assembly, BASIC, C, C++, C#, Fortran, Java, LabVIEW, Lisp, Pascal, etc.", "token2charspan": [[0, 4], [5, 16], [17, 29], [30, 33], [34, 41], [42, 52], [53, 55], [56, 64], [65, 73], [74, 81], [82, 87], [88, 95], [96, 103], [103, 104], [104, 111], [112, 123], [124, 133], [134, 138], [139, 141], [142, 150], [150, 151], [152, 157], [157, 158], [159, 160], [160, 161], [162, 163], [163, 165], [165, 166], [167, 169], [169, 170], [171, 178], [178, 179], [180, 184], [184, 185], [186, 193], [193, 194], [195, 199], [199, 200], [201, 207], [207, 208], [209, 213]]}
{"doc_key": "ai-test-173", "ner": [[3, 3, "organisation"], [6, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 9, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2003", ",", "Honda", "advertised", "its", "Cog", "in", "the", "UK", "and", "on", "the", "internet", "."], "sentence-detokenized": "In 2003, Honda advertised its Cog in the UK and on the internet.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 29], [30, 33], [34, 36], [37, 40], [41, 43], [44, 47], [48, 50], [51, 54], [55, 63], [63, 64]]}
{"doc_key": "ai-test-174", "ner": [[0, 4, "conference"], [6, 7, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 6, 7, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Association", "for", "Computational", "Linguistics", "defines", "computational", "linguistics", "as", ":"], "sentence-detokenized": "The Association for Computational Linguistics defines computational linguistics as:", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 33], [34, 45], [46, 53], [54, 67], [68, 79], [80, 82], [82, 83]]}
{"doc_key": "ai-test-175", "ner": [[0, 23, "algorithm"], [9, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 23, 9, 13, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["Expectation", "maximization", "algorithms", "can", "be", "used", "to", "compute", "approximate", "maximum", "likelihood", "estimates", "of", "the", "unknown", "state", "space", "parameters", "under", "minimum", "-bias", "filters", "and", "smoothes", "."], "sentence-detokenized": "Expectation maximization algorithms can be used to compute approximate maximum likelihood estimates of the unknown state space parameters under minimum-bias filters and smoothes.", "token2charspan": [[0, 11], [12, 24], [25, 35], [36, 39], [40, 42], [43, 47], [48, 50], [51, 58], [59, 70], [71, 78], [79, 89], [90, 99], [100, 102], [103, 106], [107, 114], [115, 120], [121, 126], [127, 137], [138, 143], [144, 151], [151, 156], [157, 164], [165, 168], [169, 177], [177, 178]]}
{"doc_key": "ai-test-176", "ner": [[5, 5, "misc"], [7, 9, "person"], [11, 12, "person"], [14, 15, "person"], [18, 19, "misc"], [20, 21, "person"], [24, 25, "person"], [29, 29, "person"], [31, 32, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 9, 5, 5, "role", "actor_in", false, false], [11, 12, 5, 5, "role", "actor_in", false, false], [14, 15, 5, 5, "role", "actor_in", false, false], [20, 21, 18, 19, "role", "model_for", false, false], [29, 29, 31, 32, "social", "family", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Among", "the", "correspondents", "were", "former", "Baywatch", "actresses", "Donna", "D'", "Errico", ",", "Carmen", "Electra", "and", "Traci", "Bingham", ",", "former", "Playboy", "Playmate", "Heidi", "Mark", ",", "comedian", "Arj", "Barker", "and", "identical", "twins", "Randy", "and", "Jason", "Sklar", "."], "sentence-detokenized": "Among the correspondents were former Baywatch actresses Donna D'Errico, Carmen Electra and Traci Bingham, former Playboy Playmate Heidi Mark, comedian Arj Barker and identical twins Randy and Jason Sklar.", "token2charspan": [[0, 5], [6, 9], [10, 24], [25, 29], [30, 36], [37, 45], [46, 55], [56, 61], [62, 64], [64, 70], [70, 71], [72, 78], [79, 86], [87, 90], [91, 96], [97, 104], [104, 105], [106, 112], [113, 120], [121, 129], [130, 135], [136, 140], [140, 141], [142, 150], [151, 154], [155, 161], [162, 165], [166, 175], [176, 181], [182, 187], [188, 191], [192, 197], [198, 203], [203, 204]]}
{"doc_key": "ai-test-177", "ner": [[8, 9, "task"], [11, 11, "task"], [17, 19, "product"], [22, 23, "task"], [25, 28, "task"], [31, 32, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 8, 9, "named", "", false, false], [17, 19, 8, 9, "general-affiliation", "", false, false], [25, 28, 22, 23, "named", "", false, false], [31, 32, 22, 23, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "is", "commonly", "used", "to", "generate", "representations", "for", "speech", "recognition", "(", "ASR", ")", ",", "e.g.", ",", "the", "CMU", "Sphinx", "system", ",", "and", "speech", "synthesis", "(", "TTS", ")", ",", "e.g.", ",", "the", "Festival", "system", "."], "sentence-detokenized": "It is commonly used to generate representations for speech recognition (ASR), e.g., the CMU Sphinx system, and speech synthesis (TTS), e.g., the Festival system.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 19], [20, 22], [23, 31], [32, 47], [48, 51], [52, 58], [59, 70], [71, 72], [72, 75], [75, 76], [76, 77], [78, 82], [82, 83], [84, 87], [88, 91], [92, 98], [99, 105], [105, 106], [107, 110], [111, 117], [118, 127], [128, 129], [129, 132], [132, 133], [133, 134], [135, 139], [139, 140], [141, 144], [145, 153], [154, 160], [160, 161]]}
{"doc_key": "ai-test-178", "ner": [[0, 0, "metrics"], [2, 4, "metrics"], [6, 6, "metrics"], [12, 12, "metrics"], [27, 28, "metrics"], [30, 30, "metrics"], [41, 42, "metrics"], [44, 44, "metrics"], [46, 48, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 4, 0, 0, "named", "", false, false], [6, 6, 2, 4, "named", "", false, false], [12, 12, 0, 0, "named", "", false, false], [30, 30, 27, 28, "named", "", false, false], [44, 44, 41, 42, "named", "", false, false], [46, 48, 41, 42, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sensitivity", "or", "TRUE", "Positive", "Rate", "(", "TPR", ")", ",", "also", "known", "as", "recall", ",", "is", "the", "proportion", "of", "people", "who", "have", "tested", "positive", "and", "are", "positive", "(", "TRUE", "Positive", ",", "TP", ")", "out", "of", "all", "people", "who", "are", "true", "positives", "(", "Condition", "Positive", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "Sensitivity or TRUE Positive Rate (TPR), also known as recall, is the proportion of people who have tested positive and are positive (TRUE Positive, TP) out of all people who are true positives (Condition Positive, CP = TP + FN).", "token2charspan": [[0, 11], [12, 14], [15, 19], [20, 28], [29, 33], [34, 35], [35, 38], [38, 39], [39, 40], [41, 45], [46, 51], [52, 54], [55, 61], [61, 62], [63, 65], [66, 69], [70, 80], [81, 83], [84, 90], [91, 94], [95, 99], [100, 106], [107, 115], [116, 119], [120, 123], [124, 132], [133, 134], [134, 138], [139, 147], [147, 148], [149, 151], [151, 152], [153, 156], [157, 159], [160, 163], [164, 170], [171, 174], [175, 178], [179, 183], [184, 193], [194, 195], [195, 204], [205, 213], [213, 214], [215, 217], [218, 219], [220, 222], [223, 224], [225, 227], [227, 228], [228, 229]]}
{"doc_key": "ai-test-179", "ner": [[1, 2, "task"], [10, 10, "conference"], [12, 13, "conference"], [15, 15, "conference"], [17, 19, "conference"], [22, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6], "relations": [[10, 10, 1, 2, "topic", "", false, false], [12, 13, 1, 2, "topic", "", false, false], [15, 15, 1, 2, "topic", "", false, false], [17, 19, 1, 2, "topic", "", false, false], [22, 23, 1, 2, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4, 5], "sentence": ["Popular", "speech", "recognition", "conferences", "held", "every", "year", "or", "two", "include", "SpeechTEK", "and", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", ",", "and", "IEEE", "ASRU", "."], "sentence-detokenized": "Popular speech recognition conferences held every year or two include SpeechTEK and SpeechTEK Europe, ICASSP, Interspeech/Eurospeech, and IEEE ASRU.", "token2charspan": [[0, 7], [8, 14], [15, 26], [27, 38], [39, 43], [44, 49], [50, 54], [55, 57], [58, 61], [62, 69], [70, 79], [80, 83], [84, 93], [94, 100], [100, 101], [102, 108], [108, 109], [110, 121], [121, 122], [122, 132], [132, 133], [134, 137], [138, 142], [143, 147], [147, 148]]}
{"doc_key": "ai-test-180", "ner": [[0, 0, "researcher"], [3, 5, "researcher"], [16, 18, "product"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 21, 0, 0, "artifact", "", false, false], [21, 21, 3, 5, "artifact", "", false, false], [21, 21, 16, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Devol", "worked", "with", "Engelberger", ",", "who", "was", "the", "company", "'s", "president", ",", "to", "develop", "and", "manufacture", "an", "industrial", "robot", "under", "the", "Unimate", "brand", "."], "sentence-detokenized": "Devol worked with Engelberger, who was the company's president, to develop and manufacture an industrial robot under the Unimate brand.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 29], [29, 30], [31, 34], [35, 38], [39, 42], [43, 50], [50, 52], [53, 62], [62, 63], [64, 66], [67, 74], [75, 78], [79, 90], [91, 93], [94, 104], [105, 110], [111, 116], [117, 120], [121, 128], [129, 134], [134, 135]]}
{"doc_key": "ai-test-181", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [9, 14, "algorithm"], [23, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 9, 14, "general-affiliation", "", false, false], [5, 5, 0, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "hidden", "Markov", "model", "(", "HMM", ")", "is", "a", "statistical", "Markov", "model", "in", "which", "the", "system", "being", "modeled", "is", "assumed", "to", "be", "a", "Markov", "process", "with", "unobserved", "(", "hidden", ")", "states", "."], "sentence-detokenized": "A hidden Markov model (HMM) is a statistical Markov model in which the system being modeled is assumed to be a Markov process with unobserved (hidden) states.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [22, 23], [23, 26], [26, 27], [28, 30], [31, 32], [33, 44], [45, 51], [52, 57], [58, 60], [61, 66], [67, 70], [71, 77], [78, 83], [84, 91], [92, 94], [95, 102], [103, 105], [106, 108], [109, 110], [111, 117], [118, 125], [126, 130], [131, 141], [142, 143], [143, 149], [149, 150], [151, 157], [157, 158]]}
{"doc_key": "ai-test-182", "ner": [[18, 20, "metrics"], [22, 24, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "property", ",", "which", "is", "undesirable", "in", "many", "applications", ",", "has", "led", "researchers", "to", "use", "alternatives", "such", "as", "mean", "absolute", "error", "or", "median", "-", "based", "alternatives", "."], "sentence-detokenized": "This property, which is undesirable in many applications, has led researchers to use alternatives such as mean absolute error or median-based alternatives.", "token2charspan": [[0, 4], [5, 13], [13, 14], [15, 20], [21, 23], [24, 35], [36, 38], [39, 43], [44, 56], [56, 57], [58, 61], [62, 65], [66, 77], [78, 80], [81, 84], [85, 97], [98, 102], [103, 105], [106, 110], [111, 119], [120, 125], [126, 128], [129, 135], [135, 136], [136, 141], [142, 154], [154, 155]]}
{"doc_key": "ai-test-183", "ner": [[21, 22, "algorithm"], [30, 31, "field"], [34, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 22, 30, 31, "part-of", "", false, false], [21, 22, 34, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Such", "a", "sequence", "(", "which", "at", "each", "stage", "depends", "on", "the", "outcome", "of", "examining", "the", "previous", "attributes", ")", "is", "called", "a", "decision", "tree", "and", "is", "applied", "in", "a", "field", "of", "machine", "learning", "known", "as", "decision", "tree", "learning", "."], "sentence-detokenized": "Such a sequence (which at each stage depends on the outcome of examining the previous attributes) is called a decision tree and is applied in a field of machine learning known as decision tree learning.", "token2charspan": [[0, 4], [5, 6], [7, 15], [16, 17], [17, 22], [23, 25], [26, 30], [31, 36], [37, 44], [45, 47], [48, 51], [52, 59], [60, 62], [63, 72], [73, 76], [77, 85], [86, 96], [96, 97], [98, 100], [101, 107], [108, 109], [110, 118], [119, 123], [124, 127], [128, 130], [131, 138], [139, 141], [142, 143], [144, 149], [150, 152], [153, 160], [161, 169], [170, 175], [176, 178], [179, 187], [188, 192], [193, 201], [201, 202]]}
{"doc_key": "ai-test-184", "ner": [[2, 3, "task"], [5, 5, "algorithm"], [15, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 5, 5, "compare", "", false, false], [15, 18, 5, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Similar", "to", "factor", "analysis", ",", "LCA", "can", "be", "used", "to", "classify", "cases", "according", "to", "their", "maximum", "likelihood", "class", "membership", "."], "sentence-detokenized": "Similar to factor analysis, LCA can be used to classify cases according to their maximum likelihood class membership.", "token2charspan": [[0, 7], [8, 10], [11, 17], [18, 26], [26, 27], [28, 31], [32, 35], [36, 38], [39, 43], [44, 46], [47, 55], [56, 61], [62, 71], [72, 74], [75, 80], [81, 88], [89, 99], [100, 105], [106, 116], [116, 117]]}
{"doc_key": "ai-test-185", "ner": [[0, 3, "algorithm"], [6, 8, "metrics"], [10, 10, "metrics"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 6, 8, "usage", "", false, false], [6, 8, 12, 13, "related-to", "", false, false], [10, 10, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Supervised", "neural", "networks", "that", "use", "a", "mean", "squared", "error", "(", "MSE", ")", "cost", "function", "can", "use", "formal", "statistical", "methods", "to", "determine", "the", "credibility", "of", "the", "trained", "model", "."], "sentence-detokenized": "Supervised neural networks that use a mean squared error (MSE) cost function can use formal statistical methods to determine the credibility of the trained model.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 31], [32, 35], [36, 37], [38, 42], [43, 50], [51, 56], [57, 58], [58, 61], [61, 62], [63, 67], [68, 76], [77, 80], [81, 84], [85, 91], [92, 103], [104, 111], [112, 114], [115, 124], [125, 128], [129, 140], [141, 143], [144, 147], [148, 155], [156, 161], [161, 162]]}
{"doc_key": "ai-test-186", "ner": [[16, 17, "algorithm"], [20, 22, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 17, 20, 22, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "can", "be", "directly", "expressed", "as", "a", "linear", "program", ",", "but", "it", "is", "also", "equivalent", "to", "Tikhonov", "regularization", "with", "a", "hanging", "loss", "function", ",", "mathV", "(", "f", "(", "x", ")", ",", "y", ")", "=\\", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "math", ":"], "sentence-detokenized": "This can be directly expressed as a linear program, but it is also equivalent to Tikhonov regularization with a hanging loss function, mathV (f (x), y) =\\ max (0, 1 - yf (x)) / math:", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 20], [21, 30], [31, 33], [34, 35], [36, 42], [43, 50], [50, 51], [52, 55], [56, 58], [59, 61], [62, 66], [67, 77], [78, 80], [81, 89], [90, 104], [105, 109], [110, 111], [112, 119], [120, 124], [125, 133], [133, 134], [135, 140], [141, 142], [142, 143], [144, 145], [145, 146], [146, 147], [147, 148], [149, 150], [150, 151], [152, 154], [155, 158], [159, 160], [160, 161], [161, 162], [163, 164], [165, 166], [167, 169], [170, 171], [171, 172], [172, 173], [173, 174], [175, 176], [177, 181], [181, 182]]}
{"doc_key": "ai-test-187", "ner": [[6, 7, "researcher"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "technique", "was", "described", "in", "Breiman", "'s", "original", "work", "and", "is", "implemented", "in", "the", "R", "package", "randomForest", "."], "sentence-detokenized": "The following technique was described in Breiman's original work and is implemented in the R package randomForest.", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 27], [28, 37], [38, 40], [41, 48], [48, 50], [51, 59], [60, 64], [65, 68], [69, 71], [72, 83], [84, 86], [87, 90], [91, 92], [93, 100], [101, 113], [113, 114]]}
{"doc_key": "ai-test-188", "ner": [[7, 7, "metrics"], [40, 40, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "image", "quality", "measurements", ",", "such", "as", "PSNR", ",", "are", "usually", "performed", "on", "fixed", "-", "resolution", "images", "and", "do", "not", "take", "into", "account", "some", "aspects", "of", "the", "human", "visual", "system", ",", "such", "as", "the", "change", "in", "spatial", "resolution", "on", "the", "retina", "."], "sentence-detokenized": "Traditional image quality measurements, such as PSNR, are usually performed on fixed-resolution images and do not take into account some aspects of the human visual system, such as the change in spatial resolution on the retina.", "token2charspan": [[0, 11], [12, 17], [18, 25], [26, 38], [38, 39], [40, 44], [45, 47], [48, 52], [52, 53], [54, 57], [58, 65], [66, 75], [76, 78], [79, 84], [84, 85], [85, 95], [96, 102], [103, 106], [107, 109], [110, 113], [114, 118], [119, 123], [124, 131], [132, 136], [137, 144], [145, 147], [148, 151], [152, 157], [158, 164], [165, 171], [171, 172], [173, 177], [178, 180], [181, 184], [185, 191], [192, 194], [195, 202], [203, 213], [214, 216], [217, 220], [221, 227], [227, 228]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [10, 12, "person"], [16, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 21, "role", "", false, false], [3, 4, 16, 21, "role", "", false, false], [6, 7, 16, 21, "role", "", false, false], [16, 21, 10, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Dru", "and", "Macdonald", "Carey", "starred", "in", "Jack", "Broder", "'s", "colorful", "production", "of", "Hannah", "Lee", ",", "which", "opened", "on", "June", "19", ",", "1953", "."], "sentence-detokenized": "John Ireland, Joanne Dru and Macdonald Carey starred in Jack Broder's colorful production of Hannah Lee, which opened on June 19, 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 55], [56, 60], [61, 67], [67, 69], [70, 78], [79, 89], [90, 92], [93, 99], [100, 103], [103, 104], [105, 110], [111, 117], [118, 120], [121, 125], [126, 128], [128, 129], [130, 134], [134, 135]]}
{"doc_key": "ai-test-190", "ner": [[4, 5, "task"], [9, 11, "field"], [16, 16, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 9, 11, "usage", "", false, false], [16, 16, 9, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "process", "is", "called", "image", "registration", "and", "uses", "various", "computer", "vision", "methods", ",", "mostly", "related", "to", "tracking", "."], "sentence-detokenized": "This process is called image registration and uses various computer vision methods, mostly related to tracking.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 22], [23, 28], [29, 41], [42, 45], [46, 50], [51, 58], [59, 67], [68, 74], [75, 82], [82, 83], [84, 90], [91, 98], [99, 101], [102, 110], [110, 111]]}
{"doc_key": "ai-test-191", "ner": [[16, 18, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["We", "now", "begin", "to", "explain", "the", "various", "possible", "relationships", "between", "the", "predicted", "and", "actual", "outcome", ":", "The", "confusion", "matrix"], "sentence-detokenized": "We now begin to explain the various possible relationships between the predicted and actual outcome: The confusion matrix", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 23], [24, 27], [28, 35], [36, 44], [45, 58], [59, 66], [67, 70], [71, 80], [81, 84], [85, 91], [92, 99], [99, 100], [101, 104], [105, 114], [115, 121]]}
{"doc_key": "ai-test-192", "ner": [[0, 1, "product"], [2, 4, "misc"], [6, 6, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 2, 4, "part-of", "", false, false], [0, 1, 2, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "VOICEBOX", "speech", "processing", "toolbox", "for", "MATLAB", "implements", "the", "conversion", "and", "its", "inversion", "as", ":"], "sentence-detokenized": "The VOICEBOX speech processing toolbox for MATLAB implements the conversion and its inversion as:", "token2charspan": [[0, 3], [4, 12], [13, 19], [20, 30], [31, 38], [39, 42], [43, 49], [50, 60], [61, 64], [65, 75], [76, 79], [80, 83], [84, 93], [94, 96], [96, 97]]}
{"doc_key": "ai-test-193", "ner": [[0, 0, "programlang"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 9, "general-affiliation", "", false, false], [0, 0, 11, 12, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "is", "a", "logic", "programming", "language", "associated", "with", "artificial", "intelligence", "and", "computational", "linguistics", "."], "sentence-detokenized": "Prolog is a logic programming language associated with artificial intelligence and computational linguistics.", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 17], [18, 29], [30, 38], [39, 49], [50, 54], [55, 65], [66, 78], [79, 82], [83, 96], [97, 108], [108, 109]]}
{"doc_key": "ai-test-194", "ner": [[0, 0, "researcher"], [9, 9, "field"], [11, 11, "field"], [20, 20, "organisation"], [23, 26, "organisation"], [30, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 9, 9, "related-to", "works_with_topic", false, false], [0, 0, 11, 11, "related-to", "works_with_topic", false, false], [0, 0, 20, 20, "role", "", false, false], [0, 0, 23, 26, "role", "", false, false], [0, 0, 30, 33, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "has", "received", "numerous", "awards", "for", "her", "contributions", "to", "neuroscience", "and", "psychology", ",", "including", "fellowships", "in", "the", "Royal", "Society", "of", "London", ",", "the", "Royal", "Society", "of", "Canada", ",", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner has received numerous awards for her contributions to neuroscience and psychology, including fellowships in the Royal Society of London, the Royal Society of Canada, and the National Academy of Sciences.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 28], [29, 35], [36, 39], [40, 43], [44, 57], [58, 60], [61, 73], [74, 77], [78, 88], [88, 89], [90, 99], [100, 111], [112, 114], [115, 118], [119, 124], [125, 132], [133, 135], [136, 142], [142, 143], [144, 147], [148, 153], [154, 161], [162, 164], [165, 171], [171, 172], [173, 176], [177, 180], [181, 189], [190, 197], [198, 200], [201, 209], [209, 210]]}
{"doc_key": "ai-test-195", "ner": [[8, 12, "field"], [13, 14, "task"], [16, 17, "task"], [19, 20, "task"], [22, 23, "task"], [26, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 14, 8, 12, "part-of", "task_part_of_field", false, false], [16, 17, 8, 12, "part-of", "task_part_of_field", false, false], [19, 20, 8, 12, "part-of", "task_part_of_field", false, false], [22, 23, 8, 12, "part-of", "task_part_of_field", false, false], [26, 26, 8, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["By", "combining", "these", "operators", ",", "algorithms", "for", "many", "image", "processing", "tasks", "such", "as", "feature", "extraction", ",", "image", "segmentation", ",", "image", "sharpening", ",", "image", "filtering", ",", "and", "classification", "can", "be", "obtained", "."], "sentence-detokenized": "By combining these operators, algorithms for many image processing tasks such as feature extraction, image segmentation, image sharpening, image filtering, and classification can be obtained.", "token2charspan": [[0, 2], [3, 12], [13, 18], [19, 28], [28, 29], [30, 40], [41, 44], [45, 49], [50, 55], [56, 66], [67, 72], [73, 77], [78, 80], [81, 88], [89, 99], [99, 100], [101, 106], [107, 119], [119, 120], [121, 126], [127, 137], [137, 138], [139, 144], [145, 154], [154, 155], [156, 159], [160, 174], [175, 178], [179, 181], [182, 190], [190, 191]]}
{"doc_key": "ai-test-196", "ner": [[7, 9, "university"], [15, 16, "organisation"], [18, 19, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 19, 15, 16, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "has", "been", "a", "professor", "at", "the", "Coll\u00e8ge", "de", "France", "since", "2017", "and", "Director", "of", "INSERM", "562", ",", "Cognitive", "Neuroimaging", ",", "since", "1989", "."], "sentence-detokenized": "He has been a professor at the Coll\u00e8ge de France since 2017 and Director of INSERM 562, Cognitive Neuroimaging, since 1989.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 13], [14, 23], [24, 26], [27, 30], [31, 38], [39, 41], [42, 48], [49, 54], [55, 59], [60, 63], [64, 72], [73, 75], [76, 82], [83, 86], [86, 87], [88, 97], [98, 110], [110, 111], [112, 117], [118, 122], [122, 123]]}
{"doc_key": "ai-test-197", "ner": [[12, 18, "algorithm"], [15, 18, "algorithm"], [23, 23, "algorithm"], [25, 31, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 25, 31, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["There", "are", "many", "approaches", "to", "learning", "these", "embeddings", ",", "in", "particular", "using", "Bayesian", "clustering", "or", "energy", "-", "based", "frameworks", ",", "and", "more", "recently", "TransE", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", "2013", ")", "."], "sentence-detokenized": "There are many approaches to learning these embeddings, in particular using Bayesian clustering or energy-based frameworks, and more recently TransE (Conference on Neural Information Processing Systems 2013).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 25], [26, 28], [29, 37], [38, 43], [44, 54], [54, 55], [56, 58], [59, 69], [70, 75], [76, 84], [85, 95], [96, 98], [99, 105], [105, 106], [106, 111], [112, 122], [122, 123], [124, 127], [128, 132], [133, 141], [142, 148], [149, 150], [150, 160], [161, 163], [164, 170], [171, 182], [183, 193], [194, 201], [202, 206], [206, 207], [207, 208]]}
{"doc_key": "ai-test-198", "ner": [[6, 8, "metrics"], [9, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 13, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "is", "an", "alternative", "to", "the", "Word", "Error", "Rate", ",", "which", "is", "used", "in", "several", "countries", "."], "sentence-detokenized": "It is an alternative to the Word Error Rate, which is used in several countries.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 20], [21, 23], [24, 27], [28, 32], [33, 38], [39, 43], [43, 44], [45, 50], [51, 53], [54, 58], [59, 61], [62, 69], [70, 79], [79, 80]]}
{"doc_key": "ai-test-199", "ner": [[0, 0, "algorithm"], [9, 10, "task"], [12, 13, "task"], [15, 16, "task"], [18, 20, "task"], [22, 26, "task"], [28, 29, "task"], [44, 44, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[9, 10, 0, 0, "usage", "", false, false], [12, 13, 0, 0, "usage", "", false, false], [15, 16, 0, 0, "usage", "", false, false], [18, 20, 0, 0, "usage", "", false, false], [22, 26, 0, 0, "usage", "", false, false], [28, 29, 0, 0, "usage", "", false, false], [44, 44, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["ANNs", "are", "used", "for", "a", "variety", "of", "tasks", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "tabletop", "and", "video", "game", "playing", ",", "medical", "diagnosis", ",", "and", "even", "activities", "traditionally", "thought", "to", "be", "reserved", "for", "humans", ",", "such", "as", "painting", "."], "sentence-detokenized": "ANNs are used for a variety of tasks including computer vision, speech recognition, machine translation, social network filtering, tabletop and video game playing, medical diagnosis, and even activities traditionally thought to be reserved for humans, such as painting.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 17], [18, 19], [20, 27], [28, 30], [31, 36], [37, 46], [47, 55], [56, 62], [62, 63], [64, 70], [71, 82], [82, 83], [84, 91], [92, 103], [103, 104], [105, 111], [112, 119], [120, 129], [129, 130], [131, 139], [140, 143], [144, 149], [150, 154], [155, 162], [162, 163], [164, 171], [172, 181], [181, 182], [183, 186], [187, 191], [192, 202], [203, 216], [217, 224], [225, 227], [228, 230], [231, 239], [240, 243], [244, 250], [250, 251], [252, 256], [257, 259], [260, 268], [268, 269]]}
{"doc_key": "ai-test-200", "ner": [[0, 4, "product"], [6, 6, "product"], [28, 30, "field"], [32, 32, "field"], [37, 37, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 28, 30, "related-to", "", false, false], [0, 4, 37, 37, "general-affiliation", "", false, false], [6, 6, 0, 4, "named", "", false, false], [32, 32, 28, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "is", "an", "open", "-", "source", "research", "platform", "and", "a", "set", "of", "voice", ",", "audio", ",", "speech", ",", "text", ",", "and", "natural", "language", "processing", "(", "NLP", ")", "algorithms", "written", "in", "Java", "and", "organized", "into", "a", "modular", "and", "extensible", "framework", "that", "seeks", "to", "facilitate", "the", "addition", "of", "new", "algorithms", "."], "sentence-detokenized": "The Modular Audio Recognition Framework (MARF) is an open-source research platform and a set of voice, audio, speech, text, and natural language processing (NLP) algorithms written in Java and organized into a modular and extensible framework that seeks to facilitate the addition of new algorithms.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 29], [30, 39], [40, 41], [41, 45], [45, 46], [47, 49], [50, 52], [53, 57], [57, 58], [58, 64], [65, 73], [74, 82], [83, 86], [87, 88], [89, 92], [93, 95], [96, 101], [101, 102], [103, 108], [108, 109], [110, 116], [116, 117], [118, 122], [122, 123], [124, 127], [128, 135], [136, 144], [145, 155], [156, 157], [157, 160], [160, 161], [162, 172], [173, 180], [181, 183], [184, 188], [189, 192], [193, 202], [203, 207], [208, 209], [210, 217], [218, 221], [222, 232], [233, 242], [243, 247], [248, 253], [254, 256], [257, 267], [268, 271], [272, 280], [281, 283], [284, 287], [288, 298], [298, 299]]}
{"doc_key": "ai-test-201", "ner": [[11, 13, "organisation"], [20, 20, "country"], [21, 23, "organisation"], [26, 27, "organisation"], [30, 32, "task"], [48, 52, "organisation"], [46, 47, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[21, 23, 20, 20, "physical", "", false, false], [21, 23, 30, 32, "usage", "", false, false], [21, 23, 48, 52, "named", "", false, false], [26, 27, 20, 20, "physical", "", false, false], [26, 27, 30, 32, "usage", "", false, false], [48, 52, 46, 47, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "a", "report", "by", "civil", "liberties", "and", "rights", "organisation", "Big", "Brother", "Watch", "revealed", "that", "two", "UK", "police", "forces", ",", "South", "Wales", "Police", "and", "the", "Metropolitan", "Police", ",", "use", "live", "facial", "recognition", "at", "public", "events", "and", "in", "public", "spaces.In", "September", "2019", ",", "the", "use", "of", "facial", "recognition", "by", "South", "Wales", "Police", "was", "made", "legal", "."], "sentence-detokenized": "In 2018, a report by civil liberties and rights organisation Big Brother Watch revealed that two UK police forces, South Wales Police and the Metropolitan Police, use live facial recognition at public events and in public spaces.In September 2019, the use of facial recognition by South Wales Police was made legal.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 20], [21, 26], [27, 36], [37, 40], [41, 47], [48, 60], [61, 64], [65, 72], [73, 78], [79, 87], [88, 92], [93, 96], [97, 99], [100, 106], [107, 113], [113, 114], [115, 120], [121, 126], [127, 133], [134, 137], [138, 141], [142, 154], [155, 161], [161, 162], [163, 166], [167, 171], [172, 178], [179, 190], [191, 193], [194, 200], [201, 207], [208, 211], [212, 214], [215, 221], [222, 231], [232, 241], [242, 246], [246, 247], [248, 251], [252, 255], [256, 258], [259, 265], [266, 277], [278, 280], [281, 286], [287, 292], [293, 299], [300, 303], [304, 308], [309, 314], [314, 315]]}
{"doc_key": "ai-test-202", "ner": [[0, 0, "product"], [5, 7, "programlang"], [14, 15, "field"], [17, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 7, "general-affiliation", "", false, false], [0, 0, 14, 15, "related-to", "", false, false], [0, 0, 17, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "has", "been", "ported", "to", "R", ",", "a", "freely", "available", "language", "and", "environment", "for", "statistical", "computing", "and", "graphics", "."], "sentence-detokenized": "ANIMAL has been ported to R, a freely available language and environment for statistical computing and graphics.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 22], [23, 25], [26, 27], [27, 28], [29, 30], [31, 37], [38, 47], [48, 56], [57, 60], [61, 72], [73, 76], [77, 88], [89, 98], [99, 102], [103, 111], [111, 112]]}
{"doc_key": "ai-test-203", "ner": [[0, 6, "algorithm"], [8, 10, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 6, 17, 19, "opposite", "alternative to", false, false], [8, 10, 0, 6, "named", "", false, false], [21, 21, 17, 19, "named", "", false, false], [24, 26, 0, 6, "usage", "", false, false], [24, 26, 17, 19, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "time", "-", "inhomogeneous", "hidden", "Bernoulli", "model", "(", "TI", "-", "HBM", ")", "is", "an", "alternative", "to", "the", "hidden", "Markov", "model", "(", "HMM", ")", "for", "automatic", "speech", "recognition", "."], "sentence-detokenized": "The time-inhomogeneous hidden Bernoulli model (TI-HBM) is an alternative to the hidden Markov model (HMM) for automatic speech recognition.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 22], [23, 29], [30, 39], [40, 45], [46, 47], [47, 49], [49, 50], [50, 53], [53, 54], [55, 57], [58, 60], [61, 72], [73, 75], [76, 79], [80, 86], [87, 93], [94, 99], [100, 101], [101, 104], [104, 105], [106, 109], [110, 119], [120, 126], [127, 138], [138, 139]]}
{"doc_key": "ai-test-204", "ner": [[7, 7, "organisation"], [5, 5, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 7, 5, 5, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "July", "2016", ",", "during", "SIGGRAPH", ",", "Nvidia", "demonstrated", "a", "new", "rendering", "method", "with", "foveation", "that", "it", "claimed", "was", "invisible", "to", "users", "."], "sentence-detokenized": "In July 2016, during SIGGRAPH, Nvidia demonstrated a new rendering method with foveation that it claimed was invisible to users.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 20], [21, 29], [29, 30], [31, 37], [38, 50], [51, 52], [53, 56], [57, 66], [67, 73], [74, 78], [79, 88], [89, 93], [94, 96], [97, 104], [105, 108], [109, 118], [119, 121], [122, 127], [127, 128]]}
{"doc_key": "ai-test-205", "ner": [[5, 7, "misc"], [10, 11, "researcher"], [18, 19, "researcher"], [21, 24, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 7, 10, 11, "origin", "", false, false], [5, 7, 18, 19, "origin", "", false, false], [5, 7, 21, 24, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Both", "are", "based", "on", "the", "speech", "act", "theory", "developed", "by", "John", "Searle", "in", "the", "1960s", "and", "extended", "by", "Terry", "Winograd", "and", "Flores", "in", "the", "1970s", "."], "sentence-detokenized": "Both are based on the speech act theory developed by John Searle in the 1960s and extended by Terry Winograd and Flores in the 1970s.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 17], [18, 21], [22, 28], [29, 32], [33, 39], [40, 49], [50, 52], [53, 57], [58, 64], [65, 67], [68, 71], [72, 77], [78, 81], [82, 90], [91, 93], [94, 99], [100, 108], [109, 112], [113, 119], [120, 122], [123, 126], [127, 132], [132, 133]]}
{"doc_key": "ai-test-206", "ner": [[0, 3, "algorithm"], [21, 23, "researcher"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 21, 23, "related-to", "", false, false], [24, 24, 21, 23, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Neural", "network", "models", "of", "concept", "formation", "and", "knowledge", "structure", "have", "opened", "up", "powerful", "hierarchical", "models", "of", "knowledge", "organization", ",", "such", "as", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "Neural network models of concept formation and knowledge structure have opened up powerful hierarchical models of knowledge organization, such as George Miller's Wordnet.", "token2charspan": [[0, 6], [7, 14], [15, 21], [22, 24], [25, 32], [33, 42], [43, 46], [47, 56], [57, 66], [67, 71], [72, 78], [79, 81], [82, 90], [91, 103], [104, 110], [111, 113], [114, 123], [124, 136], [136, 137], [138, 142], [143, 145], [146, 152], [153, 159], [159, 161], [162, 169], [169, 170]]}
{"doc_key": "ai-test-207", "ner": [[0, 1, "algorithm"], [16, 17, "field"], [20, 22, "product"], [25, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 16, 17, "part-of", "", false, false], [0, 1, 25, 27, "part-of", "", false, false], [20, 22, 16, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Template", "matching", "has", "various", "applications", "and", "is", "used", ",", "for", "example", ",", "in", "the", "field", "of", "facial", "recognition", "(", "see", "facial", "recognition", "system", ")", "and", "medical", "image", "processing", "."], "sentence-detokenized": "Template matching has various applications and is used, for example, in the field of facial recognition (see facial recognition system) and medical image processing.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 29], [30, 42], [43, 46], [47, 49], [50, 54], [54, 55], [56, 59], [60, 67], [67, 68], [69, 71], [72, 75], [76, 81], [82, 84], [85, 91], [92, 103], [104, 105], [105, 108], [109, 115], [116, 127], [128, 134], [134, 135], [136, 139], [140, 147], [148, 153], [154, 164], [164, 165]]}
{"doc_key": "ai-test-208", "ner": [[9, 10, "researcher"], [12, 13, "researcher"], [17, 26, "organisation"], [28, 28, "organisation"], [36, 37, "algorithm"], [41, 46, "conference"], [48, 48, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 10, 17, 26, "role", "", false, false], [9, 10, 41, 46, "physical", "", false, false], [9, 10, 41, 46, "temporal", "", false, false], [9, 10, 48, 48, "physical", "", false, false], [12, 13, 17, 26, "role", "", false, false], [12, 13, 41, 46, "temporal", "", false, false], [28, 28, 17, 26, "named", "", false, false], [41, 46, 36, 37, "topic", "", false, false], [48, 48, 41, 46, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["However", ",", "use", "only", "became", "widespread", "in", "2005", "when", "Navneet", "Dalal", "and", "Bill", "Triggs", ",", "researchers", "at", "the", "French", "National", "Institute", "for", "Research", "in", "Informatics", "and", "Automation", "(", "INRIA", ")", ",", "presented", "their", "complementary", "work", "on", "HOG", "descriptors", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "However, use only became widespread in 2005 when Navneet Dalal and Bill Triggs, researchers at the French National Institute for Research in Informatics and Automation (INRIA), presented their complementary work on HOG descriptors at the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 17], [18, 24], [25, 35], [36, 38], [39, 43], [44, 48], [49, 56], [57, 62], [63, 66], [67, 71], [72, 78], [78, 79], [80, 91], [92, 94], [95, 98], [99, 105], [106, 114], [115, 124], [125, 128], [129, 137], [138, 140], [141, 152], [153, 156], [157, 167], [168, 169], [169, 174], [174, 175], [175, 176], [177, 186], [187, 192], [193, 206], [207, 211], [212, 214], [215, 218], [219, 230], [231, 233], [234, 237], [238, 248], [249, 251], [252, 260], [261, 267], [268, 271], [272, 279], [280, 291], [292, 293], [293, 297], [297, 298], [298, 299]]}
{"doc_key": "ai-test-209", "ner": [[4, 7, "university"], [17, 19, "organisation"], [21, 24, "organisation"], [29, 32, "field"], [36, 38, "researcher"], [40, 42, "researcher"], [45, 47, "researcher"], [49, 53, "organisation"], [57, 59, "organisation"], [64, 65, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[21, 24, 29, 32, "related-to", "", false, false], [36, 38, 21, 24, "physical", "", false, false], [36, 38, 21, 24, "role", "", false, false], [40, 42, 21, 24, "physical", "", false, false], [40, 42, 21, 24, "role", "", false, false], [45, 47, 21, 24, "physical", "", false, false], [45, 47, 21, 24, "role", "", false, false], [64, 65, 57, 59, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Prior", "to", "joining", "the", "Penn", "faculty", "in", "2002", ",", "he", "spent", "ten", "years", "(", "1991-2001", ")", "at", "AT", "&T", "Labs", "and", "Bell", "Labs", ",", "including", "as", "head", "of", "the", "Artificial", "Intelligence", "Department", "with", "colleagues", "such", "as", "Michael", "L.", "Littman", ",", "David", "A.", "McAllester", ",", "and", "Richard", "S.", "Sutton", ",", "the", "Secure", "Systems", "Research", "Department", ",", "and", "the", "Machine", "Learning", "Department", "with", "members", "such", "as", "Michael", "Collins", "and", "senior", ")", "."], "sentence-detokenized": "Prior to joining the Penn faculty in 2002, he spent ten years (1991-2001) at AT&T Labs and Bell Labs, including as head of the Artificial Intelligence Department with colleagues such as Michael L. Littman, David A. McAllester, and Richard S. Sutton, the Secure Systems Research Department, and the Machine Learning Department with members such as Michael Collins and senior).", "token2charspan": [[0, 5], [6, 8], [9, 16], [17, 20], [21, 25], [26, 33], [34, 36], [37, 41], [41, 42], [43, 45], [46, 51], [52, 55], [56, 61], [62, 63], [63, 72], [72, 73], [74, 76], [77, 79], [79, 81], [82, 86], [87, 90], [91, 95], [96, 100], [100, 101], [102, 111], [112, 114], [115, 119], [120, 122], [123, 126], [127, 137], [138, 150], [151, 161], [162, 166], [167, 177], [178, 182], [183, 185], [186, 193], [194, 196], [197, 204], [204, 205], [206, 211], [212, 214], [215, 225], [225, 226], [227, 230], [231, 238], [239, 241], [242, 248], [248, 249], [250, 253], [254, 260], [261, 268], [269, 277], [278, 288], [288, 289], [290, 293], [294, 297], [298, 305], [306, 314], [315, 325], [326, 330], [331, 338], [339, 343], [344, 346], [347, 354], [355, 362], [363, 366], [367, 373], [373, 374], [374, 375]]}
{"doc_key": "ai-test-210", "ner": [[6, 8, "field"], [13, 14, "field"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 8, 13, 14, "compare", "", false, false], [23, 24, 13, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["If", "the", "data", "is", "unlabeled", ",", "supervised", "learning", "is", "not", "possible", "and", "an", "unsupervised", "learning", "approach", "is", "needed", "that", "attempts", "to", "find", "natural", "cluster", "analysis", "into", "groups", "and", "then", "map", "the", "new", "data", "into", "these", "formed", "groups", "."], "sentence-detokenized": "If the data is unlabeled, supervised learning is not possible and an unsupervised learning approach is needed that attempts to find natural cluster analysis into groups and then map the new data into these formed groups.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 24], [24, 25], [26, 36], [37, 45], [46, 48], [49, 52], [53, 61], [62, 65], [66, 68], [69, 81], [82, 90], [91, 99], [100, 102], [103, 109], [110, 114], [115, 123], [124, 126], [127, 131], [132, 139], [140, 147], [148, 156], [157, 161], [162, 168], [169, 172], [173, 177], [178, 181], [182, 185], [186, 189], [190, 194], [195, 199], [200, 205], [206, 212], [213, 219], [219, 220]]}
{"doc_key": "ai-test-211", "ner": [[3, 4, "field"], [15, 18, "organisation"], [25, 26, "field"], [28, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 15, 18, "origin", "", false, false], [3, 4, 25, 26, "part-of", "", false, false], [3, 4, 28, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "field", "of", "computer", "science", "developed", "in", "the", "1950s", "in", "academic", "institutions", "such", "as", "the", "MIT", "A.I", ".", "Lab", ",", "originally", "as", "a", "branch", "of", "artificial", "intelligence", "and", "robotics", "."], "sentence-detokenized": "This field of computer science developed in the 1950s in academic institutions such as the MIT A.I. Lab, originally as a branch of artificial intelligence and robotics.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 30], [31, 40], [41, 43], [44, 47], [48, 53], [54, 56], [57, 65], [66, 78], [79, 83], [84, 86], [87, 90], [91, 94], [95, 98], [98, 99], [100, 103], [103, 104], [105, 115], [116, 118], [119, 120], [121, 127], [128, 130], [131, 141], [142, 154], [155, 158], [159, 167], [167, 168]]}
{"doc_key": "ai-test-212", "ner": [[8, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "equation", "can", "also", "be", "replaced", "by", "the", "logarithm", "loss", "equation", ",", "which", "is", "given", "below", ":"], "sentence-detokenized": "This equation can also be replaced by the logarithm loss equation, which is given below:", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 22], [23, 25], [26, 34], [35, 37], [38, 41], [42, 51], [52, 56], [57, 65], [65, 66], [67, 72], [73, 75], [76, 81], [82, 87], [87, 88]]}
{"doc_key": "ai-test-213", "ner": [[0, 3, "organisation"], [6, 10, "organisation"], [14, 18, "university"], [20, 20, "university"], [22, 23, "university"], [27, 29, "university"], [31, 32, "country"], [36, 36, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 3, 36, 36, "related-to", "research_leader_in_field", false, false], [6, 10, 0, 3, "named", "", false, false], [6, 10, 36, 36, "related-to", "research_leader_in_field", false, false], [14, 18, 36, 36, "related-to", "research_leader_in_field", false, false], [20, 20, 36, 36, "related-to", "research_leader_in_field", false, false], [22, 23, 36, 36, "related-to", "research_leader_in_field", false, false], [27, 29, 31, 32, "physical", "", false, false], [27, 29, 36, 36, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "Shirley", "Ryan", "AbilityLab", "(", "formerly", "the", "Rehabilitation", "Institute", "of", "Chicago", ")", ",", "the", "University", "of", "California", "at", "Berkeley", ",", "MIT", ",", "Stanford", "University", ",", "and", "the", "University", "of", "Twente", "in", "the", "Netherlands", "are", "leaders", "in", "biomechatronics", "research", "."], "sentence-detokenized": "The Shirley Ryan AbilityLab (formerly the Rehabilitation Institute of Chicago), the University of California at Berkeley, MIT, Stanford University, and the University of Twente in the Netherlands are leaders in biomechatronics research.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 27], [28, 29], [29, 37], [38, 41], [42, 56], [57, 66], [67, 69], [70, 77], [77, 78], [78, 79], [80, 83], [84, 94], [95, 97], [98, 108], [109, 111], [112, 120], [120, 121], [122, 125], [125, 126], [127, 135], [136, 146], [146, 147], [148, 151], [152, 155], [156, 166], [167, 169], [170, 176], [177, 179], [180, 183], [184, 195], [196, 199], [200, 207], [208, 210], [211, 226], [227, 235], [235, 236]]}
{"doc_key": "ai-test-214", "ner": [[28, 34, "metrics"], [45, 46, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "a", "set", "of", "forecast", "values", "and", "a", "corresponding", "set", "of", "actual", "values", "for", "X", "over", "different", "time", "periods", ",", "a", "common", "evaluation", "technique", "is", "to", "use", "the", "root", "mean", "square", "error", "of", "the", "forecast", ";", "other", "measures", "are", "also", "available", "(", "see", "Forecasting", "#", "Forecasting", "accuracy", ")", "."], "sentence-detokenized": "For a set of forecast values and a corresponding set of actual values for X over different time periods, a common evaluation technique is to use the root mean square error of the forecast; other measures are also available (see Forecasting # Forecasting accuracy).", "token2charspan": [[0, 3], [4, 5], [6, 9], [10, 12], [13, 21], [22, 28], [29, 32], [33, 34], [35, 48], [49, 52], [53, 55], [56, 62], [63, 69], [70, 73], [74, 75], [76, 80], [81, 90], [91, 95], [96, 103], [103, 104], [105, 106], [107, 113], [114, 124], [125, 134], [135, 137], [138, 140], [141, 144], [145, 148], [149, 153], [154, 158], [159, 165], [166, 171], [172, 174], [175, 178], [179, 187], [187, 188], [189, 194], [195, 203], [204, 207], [208, 212], [213, 222], [223, 224], [224, 227], [228, 239], [240, 241], [242, 253], [254, 262], [262, 263], [263, 264]]}
{"doc_key": "ai-test-215", "ner": [[15, 18, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "measures", ",", "such", "as", "the", "proportion", "of", "correct", "predictions", "(", "also", "referred", "to", "as", "accuracy", ")", ",", "are", "not", "useful", "if", "the", "two", "classes", "are", "very", "different", "in", "size", "."], "sentence-detokenized": "Other measures, such as the proportion of correct predictions (also referred to as accuracy), are not useful if the two classes are very different in size.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 20], [21, 23], [24, 27], [28, 38], [39, 41], [42, 49], [50, 61], [62, 63], [63, 67], [68, 76], [77, 79], [80, 82], [83, 91], [91, 92], [92, 93], [94, 97], [98, 101], [102, 108], [109, 111], [112, 115], [116, 119], [120, 127], [128, 131], [132, 136], [137, 146], [147, 149], [150, 154], [154, 155]]}
{"doc_key": "ai-test-216", "ner": [[5, 5, "product"], [13, 17, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 13, 17, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "alpha", "version", "of", "OpenCV", "was", "released", "to", "the", "public", "at", "the", "Computer", "Vision", "and", "Pattern", "Recognition", "Conference", "in", "2000", ",", "and", "five", "beta", "versions", "were", "released", "between", "2001", "and", "2005", "."], "sentence-detokenized": "The first alpha version of OpenCV was released to the public at the Computer Vision and Pattern Recognition Conference in 2000, and five beta versions were released between 2001 and 2005.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [24, 26], [27, 33], [34, 37], [38, 46], [47, 49], [50, 53], [54, 60], [61, 63], [64, 67], [68, 76], [77, 83], [84, 87], [88, 95], [96, 107], [108, 118], [119, 121], [122, 126], [126, 127], [128, 131], [132, 136], [137, 141], [142, 150], [151, 155], [156, 164], [165, 172], [173, 177], [178, 181], [182, 186], [186, 187]]}
{"doc_key": "ai-test-217", "ner": [[22, 22, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Results", "were", "presented", "that", "provide", "a", "correlation", "of", "up", "to", "0.964", "with", "human", "judgment", "at", "the", "corpus", "level", "compared", "to", "the", "achieved", "BLEU", "value", "of", "0.817", "on", "the", "same", "dataset", "."], "sentence-detokenized": "Results were presented that provide a correlation of up to 0.964 with human judgment at the corpus level compared to the achieved BLEU value of 0.817 on the same dataset.", "token2charspan": [[0, 7], [8, 12], [13, 22], [23, 27], [28, 35], [36, 37], [38, 49], [50, 52], [53, 55], [56, 58], [59, 64], [65, 69], [70, 75], [76, 84], [85, 87], [88, 91], [92, 98], [99, 104], [105, 113], [114, 116], [117, 120], [121, 129], [130, 134], [135, 140], [141, 143], [144, 149], [150, 152], [153, 156], [157, 161], [162, 169], [169, 170]]}
{"doc_key": "ai-test-218", "ner": [[4, 4, "metrics"], [18, 18, "metrics"], [20, 22, "metrics"], [24, 28, "metrics"], [38, 41, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 18, 18, "compare", "", false, false], [4, 4, 20, 22, "compare", "", false, false], [4, 4, 24, 28, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "early", "version", "of", "VMAF", "was", "shown", "to", "outperform", "other", "image", "and", "video", "quality", "metrics", ",", "such", "as", "SSIM", ",", "PSNR", "-", "HVS", "and", "VQM", "-", "VFD", ",", "on", "three", "of", "the", "four", "datasets", "in", "terms", "of", "prediction", "accuracy", "when", "compared", "to", "subjective", "evaluations", "."], "sentence-detokenized": "The early version of VMAF was shown to outperform other image and video quality metrics, such as SSIM, PSNR -HVS and VQM-VFD, on three of the four datasets in terms of prediction accuracy when compared to subjective evaluations.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 20], [21, 25], [26, 29], [30, 35], [36, 38], [39, 49], [50, 55], [56, 61], [62, 65], [66, 71], [72, 79], [80, 87], [87, 88], [89, 93], [94, 96], [97, 101], [101, 102], [103, 107], [108, 109], [109, 112], [113, 116], [117, 120], [120, 121], [121, 124], [124, 125], [126, 128], [129, 134], [135, 137], [138, 141], [142, 146], [147, 155], [156, 158], [159, 164], [165, 167], [168, 178], [179, 187], [188, 192], [193, 201], [202, 204], [205, 215], [216, 227], [227, 228]]}
{"doc_key": "ai-test-219", "ner": [[20, 23, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 23, 28, 29, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "example", ",", "the", "ambiguity", "of", "the", "word", "\"", "mouse", "\"", "(", "animal", "or", "device", ")", "is", "not", "relevant", "in", "machine", "translation", ",", "but", "it", "is", "relevant", "in", "information", "retrieval", "."], "sentence-detokenized": "For example, the ambiguity of the word \"mouse\" (animal or device) is not relevant in machine translation, but it is relevant in information retrieval.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 26], [27, 29], [30, 33], [34, 38], [39, 40], [40, 45], [45, 46], [47, 48], [48, 54], [55, 57], [58, 64], [64, 65], [66, 68], [69, 72], [73, 81], [82, 84], [85, 92], [93, 104], [104, 105], [106, 109], [110, 112], [113, 115], [116, 124], [125, 127], [128, 139], [140, 149], [149, 150]]}
{"doc_key": "ai-test-220", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [9, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 1, "usage", "", false, false], [9, 10, 6, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Geometric", "hashing", "was", "originally", "proposed", "in", "computer", "vision", "to", "recognize", "objects", "in", "2D", "and", "3D", ","], "sentence-detokenized": "Geometric hashing was originally proposed in computer vision to recognize objects in 2D and 3D,", "token2charspan": [[0, 9], [10, 17], [18, 21], [22, 32], [33, 41], [42, 44], [45, 53], [54, 60], [61, 63], [64, 73], [74, 81], [82, 84], [85, 87], [88, 91], [92, 94], [94, 95]]}
{"doc_key": "ai-test-221", "ner": [[9, 10, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 15, 9, 10, "part-of", "subfield", false, false], [17, 18, 9, 10, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "forms", "one", "of", "the", "three", "main", "categories", "of", "machine", "learning", ",", "along", "with", "supervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "It forms one of the three main categories of machine learning, along with supervised learning and reinforcement learning.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 15], [16, 19], [20, 25], [26, 30], [31, 41], [42, 44], [45, 52], [53, 61], [61, 62], [63, 68], [69, 73], [74, 84], [85, 93], [94, 97], [98, 111], [112, 120], [120, 121]]}
{"doc_key": "ai-test-222", "ner": [[0, 8, "field"], [16, 16, "field"], [17, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 31, "field"], [33, 34, "field"], [36, 37, "field"], [39, 39, "field"], [42, 43, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 8, 16, 16, "part-of", "subfield", false, false], [0, 8, 17, 20, "part-of", "subfield", false, false], [0, 8, 22, 23, "part-of", "subfield", false, false], [0, 8, 25, 26, "part-of", "subfield", false, false], [0, 8, 28, 31, "part-of", "subfield", false, false], [0, 8, 33, 34, "part-of", "subfield", false, false], [0, 8, 36, 37, "part-of", "subfield", false, false], [0, 8, 39, 39, "part-of", "subfield", false, false], [0, 8, 42, 43, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Reinforcement", "learning", ",", "due", "to", "its", "generality", ",", "is", "studied", "in", "many", "other", "disciplines", "such", "as", "game", "theory", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimization", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", ",", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Reinforcement learning, due to its generality, is studied in many other disciplines such as game theory, control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, statistics, and genetic algorithms.", "token2charspan": [[0, 13], [14, 22], [22, 23], [24, 27], [28, 30], [31, 34], [35, 45], [45, 46], [47, 49], [50, 57], [58, 60], [61, 65], [66, 71], [72, 83], [84, 88], [89, 91], [92, 96], [97, 103], [103, 104], [105, 112], [113, 119], [119, 120], [121, 131], [132, 140], [140, 141], [142, 153], [154, 160], [160, 161], [162, 172], [172, 173], [173, 178], [179, 191], [191, 192], [193, 204], [205, 212], [212, 213], [214, 219], [220, 232], [232, 233], [234, 244], [244, 245], [246, 249], [250, 257], [258, 268], [268, 269]]}
{"doc_key": "ai-test-223", "ner": [[0, 1, "field"], [6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "related-to", "", false, false], [0, 1, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pattern", "recognition", "is", "closely", "related", "to", "artificial", "intelligence", "and", "machine", "learning", ","], "sentence-detokenized": "Pattern recognition is closely related to artificial intelligence and machine learning,", "token2charspan": [[0, 7], [8, 19], [20, 22], [23, 30], [31, 38], [39, 41], [42, 52], [53, 65], [66, 69], [70, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-224", "ner": [[11, 12, "algorithm"], [15, 17, "field"], [18, 21, "field"], [30, 31, "task"], [33, 33, "task"], [35, 36, "task"], [38, 39, "algorithm"], [42, 44, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 15, 17, "related-to", "", false, false], [11, 12, 18, 21, "related-to", "", false, false], [30, 31, 11, 12, "usage", "", true, false], [33, 33, 11, 12, "usage", "", true, false], [35, 36, 11, 12, "usage", "", true, false], [38, 39, 11, 12, "usage", "", true, false], [42, 44, 11, 12, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["This", "software", "is", "used", "to", "design", ",", "train", ",", "and", "deploy", "neural", "network", "models", "(", "supervised", "learning", "and", "unsupervised", "learning", ")", "to", "perform", "a", "wide", "range", "of", "tasks", "such", "as", "data", "mining", ",", "classification", ",", "feature", "approximation", ",", "multivariate", "regression", ",", "and", "time", "series", "prediction", "."], "sentence-detokenized": "This software is used to design, train, and deploy neural network models (supervised learning and unsupervised learning) to perform a wide range of tasks such as data mining, classification, feature approximation, multivariate regression, and time series prediction.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 21], [22, 24], [25, 31], [31, 32], [33, 38], [38, 39], [40, 43], [44, 50], [51, 57], [58, 65], [66, 72], [73, 74], [74, 84], [85, 93], [94, 97], [98, 110], [111, 119], [119, 120], [121, 123], [124, 131], [132, 133], [134, 138], [139, 144], [145, 147], [148, 153], [154, 158], [159, 161], [162, 166], [167, 173], [173, 174], [175, 189], [189, 190], [191, 198], [199, 212], [212, 213], [214, 226], [227, 237], [237, 238], [239, 242], [243, 247], [248, 254], [255, 265], [265, 266]]}
{"doc_key": "ai-test-225", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2016", ",", "he", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2016, he was elected a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [98, 99]]}
{"doc_key": "ai-test-226", "ner": [[6, 9, "organisation"], [16, 21, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", "(", "since", "2005", ")", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "(", "since", "2009", ")", ","], "sentence-detokenized": "She is a member of the National Academy of Sciences (since 2005), the American Academy of Arts and Sciences (since 2009),", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 15], [16, 18], [19, 22], [23, 31], [32, 39], [40, 42], [43, 51], [52, 53], [53, 58], [59, 63], [63, 64], [64, 65], [66, 69], [70, 78], [79, 86], [87, 89], [90, 94], [95, 98], [99, 107], [108, 109], [109, 114], [115, 119], [119, 120], [120, 121]]}
{"doc_key": "ai-test-227", "ner": [[3, 5, "misc"], [8, 15, "product"], [16, 16, "country"], [18, 18, "country"], [23, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 15, 3, 5, "temporal", "", false, false], [8, 15, 16, 16, "physical", "", false, false], [8, 15, 18, 18, "physical", "", false, false], [8, 15, 23, 24, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "the", "1973", "Yom", "Kippur", "War", ",", "Soviet", "surface", "-", "to", "-", "air", "missile", "batteries", "in", "Egypt", "and", "Syria", "inflicted", "heavy", "damage", "on", "Israeli", "fighters", "."], "sentence-detokenized": "During the 1973 Yom Kippur War, Soviet surface-to-air missile batteries in Egypt and Syria inflicted heavy damage on Israeli fighters.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 26], [27, 30], [30, 31], [32, 38], [39, 46], [46, 47], [47, 49], [49, 50], [50, 53], [54, 61], [62, 71], [72, 74], [75, 80], [81, 84], [85, 90], [91, 100], [101, 106], [107, 113], [114, 116], [117, 124], [125, 133], [133, 134]]}
{"doc_key": "ai-test-228", "ner": [[10, 11, "product"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 17, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Another", "resource", "(", "free", ",", "but", "copyrighted", ")", "is", "the", "HTK", "book", "(", "and", "the", "accompanying", "HTK", "toolkit", ")", "."], "sentence-detokenized": "Another resource (free, but copyrighted) is the HTK book (and the accompanying HTK toolkit).", "token2charspan": [[0, 7], [8, 16], [17, 18], [18, 22], [22, 23], [24, 27], [28, 39], [39, 40], [41, 43], [44, 47], [48, 51], [52, 56], [57, 58], [58, 61], [62, 65], [66, 78], [79, 82], [83, 90], [90, 91], [91, 92]]}
{"doc_key": "ai-test-229", "ner": [[6, 10, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "were", "adopted", "at", "the", "2004", "AAAI", "Spring", "Symposium", ",", "where", "linguists", ",", "computer", "scientists", ",", "and", "other", "interested", "researchers", "first", "aligned", "interests", "and", "proposed", "common", "tasks", "and", "reference", "datasets", "for", "systematic", "computational", "research", "on", "affect", ",", "attraction", ",", "subjectivity", ",", "and", "sentiment", "in", "text", "."], "sentence-detokenized": "- were adopted at the 2004 AAAI Spring Symposium, where linguists, computer scientists, and other interested researchers first aligned interests and proposed common tasks and reference datasets for systematic computational research on affect, attraction, subjectivity, and sentiment in text.", "token2charspan": [[0, 1], [2, 6], [7, 14], [15, 17], [18, 21], [22, 26], [27, 31], [32, 38], [39, 48], [48, 49], [50, 55], [56, 65], [65, 66], [67, 75], [76, 86], [86, 87], [88, 91], [92, 97], [98, 108], [109, 120], [121, 126], [127, 134], [135, 144], [145, 148], [149, 157], [158, 164], [165, 170], [171, 174], [175, 184], [185, 193], [194, 197], [198, 208], [209, 222], [223, 231], [232, 234], [235, 241], [241, 242], [243, 253], [253, 254], [255, 267], [267, 268], [269, 272], [273, 282], [283, 285], [286, 290], [290, 291]]}
{"doc_key": "ai-test-230", "ner": [[12, 17, "task"], [25, 26, "task"], [28, 30, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "single", "grid", "can", "be", "analysed", "in", "terms", "of", "both", "content", "(", "inspection", "at", "a", "glance", ")", "and", "structure", "(", "the", "main", "techniques", "used", "are", "cluster", "analysis", ",", "principal", "component", "analysis", "and", "various", "structural", "indices", "relating", "to", "the", "complexity", "and", "extent", "of", "the", "assessments", ")", "."], "sentence-detokenized": "A single grid can be analysed in terms of both content (inspection at a glance) and structure (the main techniques used are cluster analysis, principal component analysis and various structural indices relating to the complexity and extent of the assessments).", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 17], [18, 20], [21, 29], [30, 32], [33, 38], [39, 41], [42, 46], [47, 54], [55, 56], [56, 66], [67, 69], [70, 71], [72, 78], [78, 79], [80, 83], [84, 93], [94, 95], [95, 98], [99, 103], [104, 114], [115, 119], [120, 123], [124, 131], [132, 140], [140, 141], [142, 151], [152, 161], [162, 170], [171, 174], [175, 182], [183, 193], [194, 201], [202, 210], [211, 213], [214, 217], [218, 228], [229, 232], [233, 239], [240, 242], [243, 246], [247, 258], [258, 259], [259, 260]]}
{"doc_key": "ai-test-231", "ner": [[3, 3, "organisation"], [9, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2018", ",", "Toyota", "was", "considered", "a", "laggard", "in", "self", "-", "driving", "vehicles", "and", "needed", "innovation", "."], "sentence-detokenized": "In 2018, Toyota was considered a laggard in self-driving vehicles and needed innovation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 30], [31, 32], [33, 40], [41, 43], [44, 48], [48, 49], [49, 56], [57, 65], [66, 69], [70, 76], [77, 87], [87, 88]]}
{"doc_key": "ai-test-232", "ner": [[38, 41, "misc"], [43, 44, "misc"], [46, 49, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "targets", "include", "natural", "objects", "such", "as", "land", ",", "sea", ",", "precipitation", "(", "such", "as", "rain", ",", "snow", "or", "hail", ")", ",", "sandstorms", ",", "animals", "(", "especially", "birds", ")", ",", "atmospheric", "turbulence", "and", "other", "atmospheric", "effects", "such", "as", "reflections", "from", "the", "ionosphere", ",", "meteor", "tracks", "and", "three", "-", "body", "scattering", "."], "sentence-detokenized": "Such targets include natural objects such as land, sea, precipitation (such as rain, snow or hail), sandstorms, animals (especially birds), atmospheric turbulence and other atmospheric effects such as reflections from the ionosphere, meteor tracks and three-body scattering.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 28], [29, 36], [37, 41], [42, 44], [45, 49], [49, 50], [51, 54], [54, 55], [56, 69], [70, 71], [71, 75], [76, 78], [79, 83], [83, 84], [85, 89], [90, 92], [93, 97], [97, 98], [98, 99], [100, 110], [110, 111], [112, 119], [120, 121], [121, 131], [132, 137], [137, 138], [138, 139], [140, 151], [152, 162], [163, 166], [167, 172], [173, 184], [185, 192], [193, 197], [198, 200], [201, 212], [213, 217], [218, 221], [222, 232], [232, 233], [234, 240], [241, 247], [248, 251], [252, 257], [257, 258], [258, 262], [263, 273], [273, 274]]}
{"doc_key": "ai-test-233", "ner": [[17, 18, "product"], [37, 38, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "planning", "and", "control", ",", "the", "fundamental", "difference", "between", "humanoids", "and", "other", "types", "of", "robots", "(", "e.g.", "industrial", "robots", ")", "is", "that", "the", "robot", "'s", "motion", "must", "be", "human", "-", "like", ",", "using", "leg", "locomotion", ",", "especially", "bipedal", "walking", "."], "sentence-detokenized": "In planning and control, the fundamental difference between humanoids and other types of robots (e.g. industrial robots) is that the robot's motion must be human-like, using leg locomotion, especially bipedal walking.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 23], [23, 24], [25, 28], [29, 40], [41, 51], [52, 59], [60, 69], [70, 73], [74, 79], [80, 85], [86, 88], [89, 95], [96, 97], [97, 101], [102, 112], [113, 119], [119, 120], [121, 123], [124, 128], [129, 132], [133, 138], [138, 140], [141, 147], [148, 152], [153, 155], [156, 161], [161, 162], [162, 166], [166, 167], [168, 173], [174, 177], [178, 188], [188, 189], [190, 200], [201, 208], [209, 216], [216, 217]]}
{"doc_key": "ai-test-234", "ner": [[14, 16, "algorithm"], [24, 27, "misc"], [29, 29, "metrics"], [1, 6, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "curvature", "is", "very", "different", "in", "different", "directions", "for", "a", "given", "function", ",", "the", "gradient", "descent", "may", "take", "many", "iterations", "to", "compute", "a", "local", "minimum", "with", "the", "desired", "accuracy", "."], "sentence-detokenized": "If the curvature is very different in different directions for a given function, the gradient descent may take many iterations to compute a local minimum with the desired accuracy.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 24], [25, 34], [35, 37], [38, 47], [48, 58], [59, 62], [63, 64], [65, 70], [71, 79], [79, 80], [81, 84], [85, 93], [94, 101], [102, 105], [106, 110], [111, 115], [116, 126], [127, 129], [130, 137], [138, 139], [140, 145], [146, 153], [154, 158], [159, 162], [163, 170], [171, 179], [179, 180]]}
{"doc_key": "ai-test-235", "ner": [[0, 6, "misc"], [10, 15, "misc"], [17, 23, "conference"], [24, 28, "location"], [25, 26, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 6, 10, 15, "part-of", "", true, false], [17, 23, 24, 28, "physical", "", false, true], [24, 28, 25, 26, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "RoboCup", "1997", "2D", "Soccer", "Simulation", "League", "was", "the", "first", "RoboCup", "competition", "held", "in", "conjunction", "with", "the", "International", "Joint", "Conference", "on", "Artificial", "Intelligence", "in", "Nagoya", ",", "Japan", ",", "from", "23", "to", "29", "August", "1997", "."], "sentence-detokenized": "The RoboCup 1997 2D Soccer Simulation League was the first RoboCup competition held in conjunction with the International Joint Conference on Artificial Intelligence in Nagoya, Japan, from 23 to 29 August 1997.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 19], [20, 26], [27, 37], [38, 44], [45, 48], [49, 52], [53, 58], [59, 66], [67, 78], [79, 83], [84, 86], [87, 98], [99, 103], [104, 107], [108, 121], [122, 127], [128, 138], [139, 141], [142, 152], [153, 165], [166, 168], [169, 175], [175, 176], [177, 182], [182, 183], [184, 188], [189, 191], [192, 194], [195, 197], [198, 204], [205, 209], [209, 210]]}
{"doc_key": "ai-test-236", "ner": [[8, 10, "programlang"], [11, 11, "programlang"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Additional", "programming", "options", "include", "a", "built", "-", "in", "Python", "environment", "and", "R", "console", "and", "support", "for", "Rserve", "."], "sentence-detokenized": "Additional programming options include a built-in Python environment and R console and support for Rserve.", "token2charspan": [[0, 10], [11, 22], [23, 30], [31, 38], [39, 40], [41, 46], [46, 47], [47, 49], [50, 56], [57, 68], [69, 72], [73, 74], [75, 82], [83, 86], [87, 94], [95, 98], [99, 105], [105, 106]]}
{"doc_key": "ai-test-237", "ner": [[1, 1, "location"], [8, 9, "field"], [11, 11, "field"], [16, 17, "researcher"], [19, 20, "researcher"], [23, 28, "researcher"], [31, 32, "field"], [36, 37, "field"], [40, 41, "field"], [46, 46, "field"], [49, 52, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[16, 17, 11, 11, "related-to", "contributes_to_field", true, false], [19, 20, 11, 11, "related-to", "contributes_to_field", true, false], [23, 28, 11, 11, "related-to", "contributes_to_field", true, false], [40, 41, 36, 37, "part-of", "", false, false], [46, 46, 40, 41, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["From", "Bonn", ",", "he", "made", "fundamental", "contributions", "to", "artificial", "intelligence", "and", "robotics", "(", "his", "students", "included", "Wolfram", "Burgard", ",", "Dieter", "Fox", ",", "and", "Sebastian", "Thrun", ")", "and", "to", "the", "development", "of", "software", "engineering", ",", "especially", "in", "civil", "engineering", ",", "and", "information", "systems", ",", "especially", "in", "the", "geosciences.He", "received", "the", "AAAI", "Classic", "Paper", "award", "2016.2014", "."], "sentence-detokenized": "From Bonn, he made fundamental contributions to artificial intelligence and robotics (his students included Wolfram Burgard, Dieter Fox, and Sebastian Thrun) and to the development of software engineering, especially in civil engineering, and information systems, especially in the geosciences.He received the AAAI Classic Paper award 2016.2014.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 13], [14, 18], [19, 30], [31, 44], [45, 47], [48, 58], [59, 71], [72, 75], [76, 84], [85, 86], [86, 89], [90, 98], [99, 107], [108, 115], [116, 123], [123, 124], [125, 131], [132, 135], [135, 136], [137, 140], [141, 150], [151, 156], [156, 157], [158, 161], [162, 164], [165, 168], [169, 180], [181, 183], [184, 192], [193, 204], [204, 205], [206, 216], [217, 219], [220, 225], [226, 237], [237, 238], [239, 242], [243, 254], [255, 262], [262, 263], [264, 274], [275, 277], [278, 281], [282, 296], [297, 305], [306, 309], [310, 314], [315, 322], [323, 328], [329, 334], [335, 344], [344, 345]]}
{"doc_key": "ai-test-238", "ner": [[2, 9, "conference"], [17, 18, "location"], [20, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 9, 17, 18, "physical", "", false, false], [17, 18, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "first", "Campus", "Party", "in", "the", "USA", "will", "take", "place", "from", "August", "20", "-", "22", "at", "the", "TCF", "Center", "in", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "The first Campus Party in the USA will take place from August 20-22 at the TCF Center in Detroit, Michigan.", "token2charspan": [[0, 3], [4, 9], [10, 16], [17, 22], [23, 25], [26, 29], [30, 33], [34, 38], [39, 43], [44, 49], [50, 54], [55, 61], [62, 64], [64, 65], [65, 67], [68, 70], [71, 74], [75, 78], [79, 85], [86, 88], [89, 96], [96, 97], [98, 106], [106, 107]]}
{"doc_key": "ai-test-239", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [12, 14, "misc"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 12, 14, "win-defeat", "", false, false], [5, 6, 12, 14, "win-defeat", "", false, false], [8, 8, 12, 14, "win-defeat", "", false, false], [12, 14, 22, 24, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Along", "with", "Yann", "LeCun", "and", "Yoshua", "Bengi", ",", "Hinton", "won", "the", "2018", "Turing", "Prize", "for", "conceptual", "and", "technical", "breakthroughs", "that", "have", "made", "deep", "neural", "networks", "a", "critical", "part", "of", "computing", "."], "sentence-detokenized": "Along with Yann LeCun and Yoshua Bengi, Hinton won the 2018 Turing Prize for conceptual and technical breakthroughs that have made deep neural networks a critical part of computing.", "token2charspan": [[0, 5], [6, 10], [11, 15], [16, 21], [22, 25], [26, 32], [33, 38], [38, 39], [40, 46], [47, 50], [51, 54], [55, 59], [60, 66], [67, 72], [73, 76], [77, 87], [88, 91], [92, 101], [102, 115], [116, 120], [121, 125], [126, 130], [131, 135], [136, 142], [143, 151], [152, 153], [154, 162], [163, 167], [168, 170], [171, 180], [180, 181]]}
{"doc_key": "ai-test-240", "ner": [[0, 3, "product"], [10, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 10, 14, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Euler", "Math", "Toolbox", "uses", "a", "matrix", "language", "similar", "to", "MATLAB", ",", "which", "has", "been", "developed", "since", "the", "1970s", "."], "sentence-detokenized": "The Euler Math Toolbox uses a matrix language similar to MATLAB, which has been developed since the 1970s.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 22], [23, 27], [28, 29], [30, 36], [37, 45], [46, 53], [54, 56], [57, 63], [63, 64], [65, 70], [71, 74], [75, 79], [80, 89], [90, 95], [96, 99], [100, 105], [105, 106]]}
{"doc_key": "ai-test-241", "ner": [[6, 6, "programlang"], [8, 9, "programlang"], [11, 11, "programlang"], [13, 13, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "languages", "allow", "this", "(", "e.g.", "Scheme", ",", "Common", "Lisp", ",", "Perl", "or", "D", ")", "."], "sentence-detokenized": "Some languages allow this (e.g. Scheme, Common Lisp, Perl or D).", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 25], [26, 27], [27, 31], [32, 38], [38, 39], [40, 46], [47, 51], [51, 52], [53, 57], [58, 60], [61, 62], [62, 63], [63, 64]]}
{"doc_key": "ai-test-242", "ner": [[13, 18, "misc"], [3, 4, "researcher"], [6, 7, "researcher"], [21, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 18, 3, 4, "artifact", "", false, false], [13, 18, 6, 7, "artifact", "", false, false], [13, 18, 21, 22, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1969", ",", "Marvin", "Minsky", "and", "Seymour", "Papert", "showed", "in", "their", "famous", "book", "Perceptrons", "that", "it", "is", "impossible", "to", "learn", "the", "XOR", "function", "for", "these", "classes", "of", "networks", "."], "sentence-detokenized": "In 1969, Marvin Minsky and Seymour Papert showed in their famous book Perceptrons that it is impossible to learn the XOR function for these classes of networks.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 22], [23, 26], [27, 34], [35, 41], [42, 48], [49, 51], [52, 57], [58, 64], [65, 69], [70, 81], [82, 86], [87, 89], [90, 92], [93, 103], [104, 106], [107, 112], [113, 116], [117, 120], [121, 129], [130, 133], [134, 139], [140, 147], [148, 150], [151, 159], [159, 160]]}
{"doc_key": "ai-test-243", "ner": [[4, 8, "misc"], [13, 14, "product"], [19, 24, "organisation"], [27, 33, "organisation"], [36, 41, "location"], [43, 43, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[19, 24, 13, 14, "usage", "", false, false], [19, 24, 36, 41, "physical", "", false, false], [27, 33, 19, 24, "named", "", false, false], [36, 41, 43, 43, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "large", "number", "of", "Russian", "scientific", "and", "technical", "documents", "were", "translated", "using", "the", "SYSTRAN", "system", "under", "the", "auspices", "of", "the", "USAF", "'s", "Foreign", "Technology", "Division", "(", "later", "the", "National", "Air", "and", "Space", "Intelligence", "Center", ")", "at", "Wright", "-", "Patterson", "Air", "Force", "Base", "in", "Ohio", "."], "sentence-detokenized": "A large number of Russian scientific and technical documents were translated using the SYSTRAN system under the auspices of the USAF's Foreign Technology Division (later the National Air and Space Intelligence Center) at Wright-Patterson Air Force Base in Ohio.", "token2charspan": [[0, 1], [2, 7], [8, 14], [15, 17], [18, 25], [26, 36], [37, 40], [41, 50], [51, 60], [61, 65], [66, 76], [77, 82], [83, 86], [87, 94], [95, 101], [102, 107], [108, 111], [112, 120], [121, 123], [124, 127], [128, 132], [132, 134], [135, 142], [143, 153], [154, 162], [163, 164], [164, 169], [170, 173], [174, 182], [183, 186], [187, 190], [191, 196], [197, 209], [210, 216], [216, 217], [218, 220], [221, 227], [227, 228], [228, 237], [238, 241], [242, 247], [248, 252], [253, 255], [256, 260], [260, 261]]}
{"doc_key": "ai-test-244", "ner": [[0, 4, "field"], [5, 6, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Partially", "supervised", "learning", "is", "between", "unsupervised", "learning", "(", "without", "any", "labeled", "learning", "data", ")", "and", "supervised", "learning", "(", "with", "fully", "labeled", "learning", "data", ")", "."], "sentence-detokenized": "Partially supervised learning is between unsupervised learning (without any labeled learning data) and supervised learning (with fully labeled learning data).", "token2charspan": [[0, 9], [10, 20], [21, 29], [30, 32], [33, 40], [41, 53], [54, 62], [63, 64], [64, 71], [72, 75], [76, 83], [84, 92], [93, 97], [97, 98], [99, 102], [103, 113], [114, 122], [123, 124], [124, 128], [129, 134], [135, 142], [143, 151], [152, 156], [156, 157], [157, 158]]}
{"doc_key": "ai-test-245", "ner": [[0, 4, "algorithm"], [9, 12, "algorithm"], [31, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 9, 12, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Ann", "-", "gram", "model", "is", "a", "type", "of", "probabilistic", "language", "model", "for", "predicting", "the", "next", "item", "in", "such", "a", "sequence", "in", "the", "form", "of", "an", "(", "n", "-", "1", ")", "Markov", "model", "."], "sentence-detokenized": "The Ann -gram model is a type of probabilistic language model for predicting the next item in such a sequence in the form of an (n - 1) Markov model.", "token2charspan": [[0, 3], [4, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 24], [25, 29], [30, 32], [33, 46], [47, 55], [56, 61], [62, 65], [66, 76], [77, 80], [81, 85], [86, 90], [91, 93], [94, 98], [99, 100], [101, 109], [110, 112], [113, 116], [117, 121], [122, 124], [125, 127], [128, 129], [129, 130], [131, 132], [133, 134], [134, 135], [136, 142], [143, 148], [148, 149]]}
{"doc_key": "ai-test-246", "ner": [[0, 2, "organisation"], [4, 4, "product"], [8, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 4, 4, "usage", "", false, false], [8, 14, 0, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Cleveland", "Clinic", "used", "Cyc", "to", "create", "a", "natural", "language", "biomedical", "information", "retrieval", "interface", "that", "incorporates", "decades", "of", "cardiac", "surgery", "information", "."], "sentence-detokenized": "The Cleveland Clinic used Cyc to create a natural language biomedical information retrieval interface that incorporates decades of cardiac surgery information.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 29], [30, 32], [33, 39], [40, 41], [42, 49], [50, 58], [59, 69], [70, 81], [82, 91], [92, 101], [102, 106], [107, 119], [120, 127], [128, 130], [131, 138], [139, 146], [147, 158], [158, 159]]}
{"doc_key": "ai-test-247", "ner": [[6, 7, "country"], [9, 9, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 9, 9, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "incident", "soured", "relations", "between", "the", "United", "States", "and", "Japan", "and", "led", "to", "the", "arrest", "and", "prosecution", "of", "two", "executives", ",", "as", "well", "as", "the", "imposition", "of", "sanctions", "on", "the", "company", "by", "both", "countries", "."], "sentence-detokenized": "The incident soured relations between the United States and Japan and led to the arrest and prosecution of two executives, as well as the imposition of sanctions on the company by both countries.", "token2charspan": [[0, 3], [4, 12], [13, 19], [20, 29], [30, 37], [38, 41], [42, 48], [49, 55], [56, 59], [60, 65], [66, 69], [70, 73], [74, 76], [77, 80], [81, 87], [88, 91], [92, 103], [104, 106], [107, 110], [111, 121], [121, 122], [123, 125], [126, 130], [131, 133], [134, 137], [138, 148], [149, 151], [152, 161], [162, 164], [165, 168], [169, 176], [177, 179], [180, 184], [185, 194], [194, 195]]}
{"doc_key": "ai-test-248", "ner": [[6, 8, "algorithm"], [11, 14, "field"], [21, 24, "misc"], [32, 32, "misc"], [35, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 8, 11, 14, "type-of", "", false, false], [21, 24, 11, 14, "part-of", "", true, false], [32, 32, 11, 14, "part-of", "", true, false], [35, 38, 11, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["When", "modeling", "is", "done", "using", "an", "artificial", "neural", "network", "or", "other", "machine", "learning", ",", "the", "optimization", "of", "the", "parameters", "is", "called", "training", ",", "while", "the", "optimization", "of", "the", "model", "hyperparameters", "is", "called", "tuning", ",", "and", "cross-validation", "is", "often", "used", "."], "sentence-detokenized": "When modeling is done using an artificial neural network or other machine learning, the optimization of the parameters is called training, while the optimization of the model hyperparameters is called tuning, and cross-validation is often used.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 21], [22, 27], [28, 30], [31, 41], [42, 48], [49, 56], [57, 59], [60, 65], [66, 73], [74, 82], [82, 83], [84, 87], [88, 100], [101, 103], [104, 107], [108, 118], [119, 121], [122, 128], [129, 137], [137, 138], [139, 144], [145, 148], [149, 161], [162, 164], [165, 168], [169, 174], [175, 190], [191, 193], [194, 200], [201, 207], [207, 208], [209, 212], [213, 229], [230, 232], [233, 238], [239, 243], [243, 244]]}
{"doc_key": "ai-test-249", "ner": [[9, 9, "country"], [11, 11, "country"], [13, 14, "country"], [21, 23, "organisation"], [24, 24, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 23, 24, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "localised", "versions", "of", "the", "site", "available", "in", "the", "UK", ",", "India", "and", "Australia", "were", "shut", "down", "following", "the", "takeover", "of", "Rotten", "Tomatoes", "by", "Fandango", "."], "sentence-detokenized": "The localised versions of the site available in the UK, India and Australia were shut down following the takeover of Rotten Tomatoes by Fandango.", "token2charspan": [[0, 3], [4, 13], [14, 22], [23, 25], [26, 29], [30, 34], [35, 44], [45, 47], [48, 51], [52, 54], [54, 55], [56, 61], [62, 65], [66, 75], [76, 80], [81, 85], [86, 90], [91, 100], [101, 104], [105, 113], [114, 116], [117, 123], [124, 132], [133, 135], [136, 144], [144, 145]]}
{"doc_key": "ai-test-250", "ner": [[0, 1, "task"], [11, 12, "metrics"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 11, 12, "related-to", "", false, false], [11, 12, 24, 25, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "NER", "model", "is", "one", "of", "several", "methods", "for", "determining", "the", "accuracy", "of", "captions", "in", "live", "television", "broadcasts", "and", "events", "that", "are", "produced", "using", "speech", "recognition", "."], "sentence-detokenized": "The NER model is one of several methods for determining the accuracy of captions in live television broadcasts and events that are produced using speech recognition.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 20], [21, 23], [24, 31], [32, 39], [40, 43], [44, 55], [56, 59], [60, 68], [69, 71], [72, 80], [81, 83], [84, 88], [89, 99], [100, 110], [111, 114], [115, 121], [122, 126], [127, 130], [131, 139], [140, 145], [146, 152], [153, 164], [164, 165]]}
{"doc_key": "ai-test-251", "ner": [[0, 0, "researcher"], [4, 5, "university"], [8, 10, "university"], [11, 13, "location"], [14, 18, "university"], [20, 21, "university"], [23, 23, "location"], [27, 32, "university"], [35, 35, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 5, "physical", "", false, false], [0, 0, 4, 5, "role", "", false, false], [0, 0, 8, 10, "physical", "", false, false], [0, 0, 8, 10, "role", "", false, false], [0, 0, 14, 18, "physical", "", false, false], [0, 0, 14, 18, "role", "", false, false], [0, 0, 20, 21, "physical", "", false, false], [0, 0, 20, 21, "role", "", false, false], [0, 0, 27, 32, "physical", "", false, false], [0, 0, 27, 32, "role", "", false, false], [8, 10, 11, 13, "physical", "", false, false], [14, 18, 23, 23, "physical", "", false, false], [20, 21, 23, 23, "physical", "", false, false], [27, 32, 35, 35, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Atran", "has", "taught", "at", "Cambridge", "University", ",", "the", "Hebrew", "University", "of", "Jerusalem", ",", "the", "\u00c9cole", "pratique", "des", "hautes", "\u00e9tudes", "and", "\u00c9cole", "Polytechnique", "in", "Paris", ",", "and", "the", "John", "Jay", "College", "of", "Criminal", "Justice", "in", "New", "York", "."], "sentence-detokenized": "Atran has taught at Cambridge University, the Hebrew University of Jerusalem, the \u00c9cole pratique des hautes \u00e9tudes and \u00c9cole Polytechnique in Paris, and the John Jay College of Criminal Justice in New York.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 40], [40, 41], [42, 45], [46, 52], [53, 63], [64, 66], [67, 76], [76, 77], [78, 81], [82, 87], [88, 96], [97, 100], [101, 107], [108, 114], [115, 118], [119, 124], [125, 138], [139, 141], [142, 147], [147, 148], [149, 152], [153, 156], [157, 161], [162, 165], [166, 173], [174, 176], [177, 185], [186, 193], [194, 196], [197, 200], [201, 205], [205, 206]]}
{"doc_key": "ai-test-252", "ner": [[0, 0, "product"], [4, 6, "task"], [11, 12, "researcher"], [14, 14, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 6, "origin", "", false, false], [0, 0, 4, 6, "related-to", "", false, false], [4, 6, 14, 14, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "was", "an", "early", "natural", "language", "understanding", "computer", "program", "developed", "by", "Terry", "Winograd", "at", "MIT", "in", "1968", "-", "1970", "."], "sentence-detokenized": "SHRDLU was an early natural language understanding computer program developed by Terry Winograd at MIT in 1968-1970.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 19], [20, 27], [28, 36], [37, 50], [51, 59], [60, 67], [68, 77], [78, 80], [81, 86], [87, 95], [96, 98], [99, 102], [103, 105], [106, 110], [110, 111], [111, 115], [115, 116]]}
{"doc_key": "ai-test-253", "ner": [[6, 7, "misc"], [10, 12, "field"], [13, 17, "university"], [19, 19, "location"], [22, 23, "country"], [28, 29, "university"], [33, 34, "misc"], [36, 39, "field"], [41, 47, "university"], [48, 48, "misc"], [51, 53, "field"], [57, 57, "misc"], [63, 69, "university"], [72, 73, "field"], [77, 78, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[6, 7, 10, 12, "topic", "", false, false], [6, 7, 13, 17, "origin", "", false, false], [13, 17, 19, 19, "physical", "", false, false], [13, 17, 28, 29, "role", "affiliated_with", false, false], [19, 19, 22, 23, "physical", "", false, false], [33, 34, 36, 39, "topic", "", false, false], [33, 34, 41, 47, "origin", "", false, false], [48, 48, 51, 53, "topic", "", false, false], [57, 57, 63, 69, "origin", "", false, false], [57, 57, 72, 73, "topic", "", false, false], [77, 78, 63, 69, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["In", "1982", ",", "he", "received", "a", "Bachelor", "'s", "degree", "in", "Electronics", "Engineering", "from", "B.M.S", ".", "College", "of", "Engineering", "in", "Bangalore", ",", "India", ",", "when", "it", "was", "affiliated", "with", "Bangalore", "University", ",", "earned", "a", "M.S.", "degree", "in", "electrical", "and", "computer", "engineering", "from", "Drexel", "University", "in", "1984", ",", "and", "an", "M.S.", "degree", "in", "computer", "science", "in", "1989", "and", "a", "Ph.D.", "degree", "in", "1990", "from", "the", "University", "of", "Wisconsin", "-", "Madison", ",", "where", "he", "studied", "artificial", "intelligence", "and", "collaborated", "with", "Leonard", "Uhr", "."], "sentence-detokenized": "In 1982, he received a Bachelor's degree in Electronics Engineering from B.M.S. College of Engineering in Bangalore, India, when it was affiliated with Bangalore University, earned a M.S. degree in electrical and computer engineering from Drexel University in 1984, and an M.S. degree in computer science in 1989 and a Ph.D. degree in 1990 from the University of Wisconsin-Madison, where he studied artificial intelligence and collaborated with Leonard Uhr.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 20], [21, 22], [23, 31], [31, 33], [34, 40], [41, 43], [44, 55], [56, 67], [68, 72], [73, 78], [78, 79], [80, 87], [88, 90], [91, 102], [103, 105], [106, 115], [115, 116], [117, 122], [122, 123], [124, 128], [129, 131], [132, 135], [136, 146], [147, 151], [152, 161], [162, 172], [172, 173], [174, 180], [181, 182], [183, 187], [188, 194], [195, 197], [198, 208], [209, 212], [213, 221], [222, 233], [234, 238], [239, 245], [246, 256], [257, 259], [260, 264], [264, 265], [266, 269], [270, 272], [273, 277], [278, 284], [285, 287], [288, 296], [297, 304], [305, 307], [308, 312], [313, 316], [317, 318], [319, 324], [325, 331], [332, 334], [335, 339], [340, 344], [345, 348], [349, 359], [360, 362], [363, 372], [372, 373], [373, 380], [380, 381], [382, 387], [388, 390], [391, 398], [399, 409], [410, 422], [423, 426], [427, 439], [440, 444], [445, 452], [453, 456], [456, 457]]}
{"doc_key": "ai-test-254", "ner": [[5, 7, "metrics"], [9, 12, "metrics"], [18, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 12, 5, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Accuracy", "is", "usually", "evaluated", "using", "word", "error", "rate", "(", "WER", ")", ",", "while", "speed", "is", "measured", "using", "a", "real", "-", "time", "factor", "."], "sentence-detokenized": "Accuracy is usually evaluated using word error rate (WER), while speed is measured using a real-time factor.", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 29], [30, 35], [36, 40], [41, 46], [47, 51], [52, 53], [53, 56], [56, 57], [57, 58], [59, 64], [65, 70], [71, 73], [74, 82], [83, 88], [89, 90], [91, 95], [95, 96], [96, 100], [101, 107], [107, 108]]}
{"doc_key": "ai-test-255", "ner": [[3, 4, "researcher"], [8, 13, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 8, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1971", ",", "Terry", "Winograd", "developed", "the", "first", "natural", "language", "processing", "engine", "that", "could", "interpret", "naturally", "written", "commands", "in", "a", "simple", "rule", "-", "driven", "environment", "."], "sentence-detokenized": "In 1971, Terry Winograd developed the first natural language processing engine that could interpret naturally written commands in a simple rule-driven environment.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 33], [34, 37], [38, 43], [44, 51], [52, 60], [61, 71], [72, 78], [79, 83], [84, 89], [90, 99], [100, 109], [110, 117], [118, 126], [127, 129], [130, 131], [132, 138], [139, 143], [143, 144], [144, 150], [151, 162], [162, 163]]}
{"doc_key": "ai-test-256", "ner": [[4, 5, "field"], [7, 8, "researcher"], [10, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 7, 8, "related-to", "", false, false], [4, 5, 10, 13, "related-to", "", false, false], [4, 5, 15, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "field", "of", "artificial", "intelligence", ",", "Marvin", "Minsky", ",", "Herbert", "A", ".", "Simon", "and", "Allen", "Newell", "."], "sentence-detokenized": "In the field of artificial intelligence, Marvin Minsky, Herbert A. Simon and Allen Newell.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 26], [27, 39], [39, 40], [41, 47], [48, 54], [54, 55], [56, 63], [64, 65], [65, 66], [67, 72], [73, 76], [77, 82], [83, 89], [89, 90]]}
{"doc_key": "ai-test-257", "ner": [[9, 10, "field"], [32, 33, "field"], [35, 36, "field"], [39, 41, "field"], [49, 52, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[32, 33, 9, 10, "origin", "", true, false], [32, 33, 9, 10, "part-of", "", false, false], [32, 33, 39, 41, "compare", "", false, false], [35, 36, 9, 10, "origin", "", true, false], [35, 36, 9, 10, "part-of", "", false, false], [35, 36, 39, 41, "compare", "", false, false], [39, 41, 9, 10, "origin", "", true, false], [39, 41, 9, 10, "part-of", "", false, false], [39, 41, 49, 52, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "the", "second", "half", "of", "the", "20th", "century", ",", "electrical", "engineering", "itself", "split", "into", "several", "disciplines", "that", "specialise", "in", "the", "design", "and", "analysis", "of", "systems", "that", "manipulate", "physical", "signals", ";", "examples", "include", "electronic", "engineering", "and", "computer", "engineering", ";", "while", "design", "engineering", "evolved", "to", "deal", "with", "the", "functional", "design", "of", "user", "-", "machine", "interfaces", "."], "sentence-detokenized": "In the second half of the 20th century, electrical engineering itself split into several disciplines that specialise in the design and analysis of systems that manipulate physical signals; examples include electronic engineering and computer engineering; while design engineering evolved to deal with the functional design of user-machine interfaces.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 21], [22, 25], [26, 30], [31, 38], [38, 39], [40, 50], [51, 62], [63, 69], [70, 75], [76, 80], [81, 88], [89, 100], [101, 105], [106, 116], [117, 119], [120, 123], [124, 130], [131, 134], [135, 143], [144, 146], [147, 154], [155, 159], [160, 170], [171, 179], [180, 187], [187, 188], [189, 197], [198, 205], [206, 216], [217, 228], [229, 232], [233, 241], [242, 253], [253, 254], [255, 260], [261, 267], [268, 279], [280, 287], [288, 290], [291, 295], [296, 300], [301, 304], [305, 315], [316, 322], [323, 325], [326, 330], [330, 331], [331, 338], [339, 349], [349, 350]]}
{"doc_key": "ai-test-258", "ner": [[6, 6, "metrics"], [8, 9, "metrics"], [11, 14, "metrics"], [47, 49, "metrics"], [56, 58, "metrics"], [62, 68, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 14, 8, 9, "named", "", false, false], [47, 49, 56, 58, "named", "", false, false], [56, 58, 62, 68, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Probably", "the", "simplest", "statistic", "is", "the", "accuracy", "or", "correct", "fraction", "(", "FC", ")", ",", "which", "measures", "the", "proportion", "of", "all", "cases", "that", "are", "correctly", "classified", ";", "it", "is", "the", "ratio", "of", "the", "number", "of", "correct", "classifications", "to", "the", "total", "number", "of", "correct", "or", "incorrect", "classifications", ":", "(", "TP", "+", "TN", ")", "/", "total", "population", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "Probably the simplest statistic is the accuracy or correct fraction (FC), which measures the proportion of all cases that are correctly classified; it is the ratio of the number of correct classifications to the total number of correct or incorrect classifications: (TP + TN)/total population = (TP + TN)/(TP + TN + FP + FN).", "token2charspan": [[0, 8], [9, 12], [13, 21], [22, 31], [32, 34], [35, 38], [39, 47], [48, 50], [51, 58], [59, 67], [68, 69], [69, 71], [71, 72], [72, 73], [74, 79], [80, 88], [89, 92], [93, 103], [104, 106], [107, 110], [111, 116], [117, 121], [122, 125], [126, 135], [136, 146], [146, 147], [148, 150], [151, 153], [154, 157], [158, 163], [164, 166], [167, 170], [171, 177], [178, 180], [181, 188], [189, 204], [205, 207], [208, 211], [212, 217], [218, 224], [225, 227], [228, 235], [236, 238], [239, 248], [249, 264], [264, 265], [266, 267], [267, 269], [270, 271], [272, 274], [274, 275], [275, 276], [276, 281], [282, 292], [293, 294], [295, 296], [296, 298], [299, 300], [301, 303], [303, 304], [304, 305], [305, 306], [306, 308], [309, 310], [311, 313], [314, 315], [316, 318], [319, 320], [321, 323], [323, 324], [324, 325]]}
{"doc_key": "ai-test-259", "ner": [[15, 23, "conference"], [25, 37, "conference"], [32, 32, "location"], [37, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 23, 32, 32, "physical", "", false, false], [25, 37, 15, 23, "named", "", false, false], [37, 37, 15, 23, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "academic", "community", ",", "the", "main", "forums", "for", "research", "began", "in", "1995", "when", "the", "first", "international", "conference", "on", "Data", "Mining", "and", "Knowledge", "Discovery", "(", "KDD", "-", "95", ")", "was", "launched", "in", "Montreal", "under", "the", "auspices", "of", "AAAI", "."], "sentence-detokenized": "In the academic community, the main forums for research began in 1995 when the first international conference on Data Mining and Knowledge Discovery (KDD-95) was launched in Montreal under the auspices of AAAI.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 25], [25, 26], [27, 30], [31, 35], [36, 42], [43, 46], [47, 55], [56, 61], [62, 64], [65, 69], [70, 74], [75, 78], [79, 84], [85, 98], [99, 109], [110, 112], [113, 117], [118, 124], [125, 128], [129, 138], [139, 148], [149, 150], [150, 153], [153, 154], [154, 156], [156, 157], [158, 161], [162, 170], [171, 173], [174, 182], [183, 188], [189, 192], [193, 201], [202, 204], [205, 209], [209, 210]]}
{"doc_key": "ai-test-260", "ner": [[10, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "this", "approach", ",", "models", "are", "developed", "using", "various", "data", "mining", "and", "machine", "learning", "algorithms", "to", "predict", "users", "'", "ratings", "of", "unrated", "items", "."], "sentence-detokenized": "In this approach, models are developed using various data mining and machine learning algorithms to predict users' ratings of unrated items.", "token2charspan": [[0, 2], [3, 7], [8, 16], [16, 17], [18, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 57], [58, 64], [65, 68], [69, 76], [77, 85], [86, 96], [97, 99], [100, 107], [108, 113], [113, 114], [115, 122], [123, 125], [126, 133], [134, 139], [139, 140]]}
{"doc_key": "ai-test-261", "ner": [[10, 10, "algorithm"], [15, 17, "algorithm"], [19, 20, "algorithm"], [27, 28, "misc"], [31, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 10, 15, 17, "related-to", "equivalent", false, false], [15, 17, 19, 20, "usage", "", false, false], [19, 20, 31, 32, "usage", "", false, false], [31, 32, 27, 28, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Based", "on", "the", "above", "discussion", ",", "we", "see", "that", "the", "SVM", "technique", "is", "equivalent", "to", "the", "empirical", "risk", "with", "Tikhonov", "regularization", ",", "where", "in", "this", "case", "the", "loss", "function", "is", "the", "hanging", "loss"], "sentence-detokenized": "Based on the above discussion, we see that the SVM technique is equivalent to the empirical risk with Tikhonov regularization, where in this case the loss function is the hanging loss", "token2charspan": [[0, 5], [6, 8], [9, 12], [13, 18], [19, 29], [29, 30], [31, 33], [34, 37], [38, 42], [43, 46], [47, 50], [51, 60], [61, 63], [64, 74], [75, 77], [78, 81], [82, 91], [92, 96], [97, 101], [102, 110], [111, 125], [125, 126], [127, 132], [133, 135], [136, 140], [141, 145], [146, 149], [150, 154], [155, 163], [164, 166], [167, 170], [171, 178], [179, 183]]}
{"doc_key": "ai-test-262", "ner": [[6, 9, "person"], [11, 12, "person"], [15, 15, "organisation"], [17, 18, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[17, 18, 15, 15, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "2015", "edition", "was", "hosted", "by", "Molly", "McGrath", ",", "with", "commentators", "Chris", "Rose", "and", "former", "UFC", "fighter", "Kenny", "Florian", "."], "sentence-detokenized": "The 2015 edition was hosted by Molly McGrath, with commentators Chris Rose and former UFC fighter Kenny Florian.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 27], [28, 30], [31, 36], [37, 44], [44, 45], [46, 50], [51, 63], [64, 69], [70, 74], [75, 78], [79, 85], [86, 89], [90, 97], [98, 103], [104, 111], [111, 112]]}
{"doc_key": "ai-test-263", "ner": [[3, 5, "product"], [9, 11, "researcher"], [13, 14, "researcher"], [17, 18, "researcher"], [19, 19, "researcher"], [22, 22, "researcher"], [33, 35, "task"], [32, 32, "product"], [39, 39, "researcher"], [44, 47, "task"], [48, 52, "researcher"], [53, 57, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12], "relations": [[3, 5, 9, 11, "origin", "", false, false], [3, 5, 13, 14, "origin", "", false, false], [3, 5, 17, 18, "origin", "", false, false], [3, 5, 19, 19, "origin", "", false, false], [13, 14, 39, 39, "named", "same", false, false], [17, 18, 22, 22, "named", "same", false, false], [33, 35, 32, 32, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 7], "sentence": ["A", "subset", "called", "Micro", "-", "Planner", "was", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", ",", "and", "Terry", "Winograd", "Sussman", ",", "and", "Winograd", "1971", ",", "and", "has", "been", "used", "in", "Winograd", "'s", "SHRDLU", "natural", "language", "understanding", "program", ",", "in", "Eugene", "Charniak", "'s", "work", "on", "story", "understanding", ",", "in", "Thorne", "McCarty", "'s", "work", "on", "legal", "reasoning", ",", "and", "in", "several", "other", "projects", "."], "sentence-detokenized": "A subset called Micro-Planner was implemented by Gerald Jay Sussman, Eugene Charniak, and Terry Winograd Sussman, and Winograd 1971, and has been used in Winograd's SHRDLU natural language understanding program, in Eugene Charniak's work on story understanding, in Thorne McCarty's work on legal reasoning, and in several other projects.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [21, 22], [22, 29], [30, 33], [34, 45], [46, 48], [49, 55], [56, 59], [60, 67], [67, 68], [69, 75], [76, 84], [84, 85], [86, 89], [90, 95], [96, 104], [105, 112], [112, 113], [114, 117], [118, 126], [127, 131], [131, 132], [133, 136], [137, 140], [141, 145], [146, 150], [151, 153], [154, 162], [162, 164], [165, 171], [172, 179], [180, 188], [189, 202], [203, 210], [210, 211], [212, 214], [215, 221], [222, 230], [230, 232], [233, 237], [238, 240], [241, 246], [247, 260], [260, 261], [262, 264], [265, 271], [272, 279], [279, 281], [282, 286], [287, 289], [290, 295], [296, 305], [305, 306], [307, 310], [311, 313], [314, 321], [322, 327], [328, 336], [336, 337]]}
{"doc_key": "ai-test-264", "ner": [[0, 2, "product"], [10, 13, "product"], [15, 17, "task"], [19, 20, "task"], [22, 24, "task"], [26, 27, "task"], [29, 30, "task"], [34, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 13, 0, 2, "usage", "", true, false], [15, 17, 10, 13, "part-of", "", true, false], [19, 20, 10, 13, "part-of", "", true, false], [22, 24, 10, 13, "part-of", "", true, false], [26, 27, 10, 13, "part-of", "", true, false], [29, 30, 10, 13, "part-of", "", true, false], [34, 37, 10, 13, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Word", "Net", "is", "used", "for", "a", "variety", "of", "purposes", "in", "information", "systems", ",", "such", "as", "word", "sense", "disambiguation", ",", "information", "retrieval", ",", "automatic", "text", "classification", ",", "automatic", "summarization", ",", "machine", "translation", ",", "and", "even", "automatic", "crossword", "puzzle", "generation", "."], "sentence-detokenized": "WordNet is used for a variety of purposes in information systems, such as word sense disambiguation, information retrieval, automatic text classification, automatic summarization, machine translation, and even automatic crossword puzzle generation.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 15], [16, 19], [20, 21], [22, 29], [30, 32], [33, 41], [42, 44], [45, 56], [57, 64], [64, 65], [66, 70], [71, 73], [74, 78], [79, 84], [85, 99], [99, 100], [101, 112], [113, 122], [122, 123], [124, 133], [134, 138], [139, 153], [153, 154], [155, 164], [165, 178], [178, 179], [180, 187], [188, 199], [199, 200], [201, 204], [205, 209], [210, 219], [220, 229], [230, 236], [237, 247], [247, 248]]}
{"doc_key": "ai-test-265", "ner": [[0, 0, "researcher"], [6, 9, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 9, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Keutzer", "was", "appointed", "a", "Fellow", "of", "the", "IEEE", "in", "1996", "."], "sentence-detokenized": "Keutzer was appointed a Fellow of the IEEE in 1996.", "token2charspan": [[0, 7], [8, 11], [12, 21], [22, 23], [24, 30], [31, 33], [34, 37], [38, 42], [43, 45], [46, 50], [50, 51]]}
{"doc_key": "ai-test-266", "ner": [[8, 12, "algorithm"], [57, 58, "misc"], [68, 69, "algorithm"], [71, 72, "algorithm"], [74, 75, "algorithm"], [78, 79, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[68, 69, 57, 58, "type-of", "", false, false], [71, 72, 57, 58, "type-of", "", false, false], [74, 75, 57, 58, "type-of", "", false, false], [78, 79, 57, 58, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "widely", "used", "type", "of", "composition", "is", "the", "nonlinear", "weighted", "sum", ",", "where", "math", "\\", "textstyle", "f", "(", "x", ")", "=", "K", "\\", "left", "(", "\\", "sum", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "\\", "right", ")", "/", "math", ",", "where", "math", "\\", "textstyle", "K", "/", "math", "(", "commonly", "referred", "to", "as", "the", "activation", "function", ")", "is", "some", "predefined", "function", ",", "such", "as", "a", "hyperbolic", "tangent", ",", "sigmoid", "function", ",", "softmax", "function", ",", "or", "rectifier", "function", "."], "sentence-detokenized": "A widely used type of composition is the nonlinear weighted sum, where math\\ textstyle f (x) = K\\ left (\\ sum _ i w _ i g _ i (x)\\ right) / math, where math\\ textstyle K / math (commonly referred to as the activation function) is some predefined function, such as a hyperbolic tangent, sigmoid function, softmax function, or rectifier function.", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 18], [19, 21], [22, 33], [34, 36], [37, 40], [41, 50], [51, 59], [60, 63], [63, 64], [65, 70], [71, 75], [75, 76], [77, 86], [87, 88], [89, 90], [90, 91], [91, 92], [93, 94], [95, 96], [96, 97], [98, 102], [103, 104], [104, 105], [106, 109], [110, 111], [112, 113], [114, 115], [116, 117], [118, 119], [120, 121], [122, 123], [124, 125], [126, 127], [127, 128], [128, 129], [129, 130], [131, 136], [136, 137], [138, 139], [140, 144], [144, 145], [146, 151], [152, 156], [156, 157], [158, 167], [168, 169], [170, 171], [172, 176], [177, 178], [178, 186], [187, 195], [196, 198], [199, 201], [202, 205], [206, 216], [217, 225], [225, 226], [227, 229], [230, 234], [235, 245], [246, 254], [254, 255], [256, 260], [261, 263], [264, 265], [266, 276], [277, 284], [284, 285], [286, 293], [294, 302], [302, 303], [304, 311], [312, 320], [320, 321], [322, 324], [325, 334], [335, 343], [343, 344]]}
{"doc_key": "ai-test-267", "ner": [[3, 3, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "movie", "Westworld", ",", "female", "robots", "actually", "engaged", "in", "sexual", "intercourse", "with", "human", "males", "within", "a", "fictional", "holiday", "world", "that", "customers", "paid", "for", "."], "sentence-detokenized": "In the movie Westworld, female robots actually engaged in sexual intercourse with human males within a fictional holiday world that customers paid for.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [22, 23], [24, 30], [31, 37], [38, 46], [47, 54], [55, 57], [58, 64], [65, 76], [77, 81], [82, 87], [88, 93], [94, 100], [101, 102], [103, 112], [113, 120], [121, 126], [127, 131], [132, 141], [142, 146], [147, 150], [150, 151]]}
{"doc_key": "ai-test-268", "ner": [[6, 12, "task"], [21, 26, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 12, 21, 26, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Usually", ",", "the", "process", "starts", "with", "extracting", "terminology", "and", "concepts", "or", "nouns", "from", "the", "plain", "text", "using", "linguistic", "processors", "such", "as", "part", "-", "of", "-", "speech", "tagging", "and", "phrase", "splitting", "."], "sentence-detokenized": "Usually, the process starts with extracting terminology and concepts or nouns from the plain text using linguistic processors such as part-of-speech tagging and phrase splitting.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 20], [21, 27], [28, 32], [33, 43], [44, 55], [56, 59], [60, 68], [69, 71], [72, 77], [78, 82], [83, 86], [87, 92], [93, 97], [98, 103], [104, 114], [115, 125], [126, 130], [131, 133], [134, 138], [138, 139], [139, 141], [141, 142], [142, 148], [149, 156], [157, 160], [161, 167], [168, 177], [177, 178]]}
{"doc_key": "ai-test-269", "ner": [[11, 13, "field"], [16, 17, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 17, 11, 13, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "demonstrated", "its", "performance", "on", "several", "problems", "of", "interest", "to", "the", "machine", "learning", "community", ",", "including", "handwriting", "recognition", "."], "sentence-detokenized": "They demonstrated its performance on several problems of interest to the machine learning community, including handwriting recognition.", "token2charspan": [[0, 4], [5, 17], [18, 21], [22, 33], [34, 36], [37, 44], [45, 53], [54, 56], [57, 65], [66, 68], [69, 72], [73, 80], [81, 89], [90, 99], [99, 100], [101, 110], [111, 122], [123, 134], [134, 135]]}
{"doc_key": "ai-test-270", "ner": [[2, 7, "university"], [4, 4, "researcher"], [11, 12, "researcher"], [20, 21, "product"], [18, 19, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 2, 7, "physical", "", false, false], [4, 4, 2, 7, "role", "", false, false], [20, 21, 11, 12, "origin", "", false, false], [20, 21, 18, 19, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "at", "Stanford", ",", "Scheinman", "was", "awarded", "a", "scholarship", "sponsored", "by", "George", "Devol", ",", "inventor", "of", "the", "first", "industrial", "robot", ",", "Unimate", "."], "sentence-detokenized": "While at Stanford, Scheinman was awarded a scholarship sponsored by George Devol, inventor of the first industrial robot, Unimate.", "token2charspan": [[0, 5], [6, 8], [9, 17], [17, 18], [19, 28], [29, 32], [33, 40], [41, 42], [43, 54], [55, 64], [65, 67], [68, 74], [75, 80], [80, 81], [82, 90], [91, 93], [94, 97], [98, 103], [104, 114], [115, 120], [120, 121], [122, 129], [129, 130]]}
{"doc_key": "ai-test-271", "ner": [[5, 6, "task"], [8, 10, "metrics"], [12, 12, "metrics"], [21, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 8, 10, "usage", "", true, false], [12, 12, 8, 10, "named", "", false, false], [21, 23, 8, 10, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Although", "originally", "used", "to", "evaluate", "machine", "translations", ",", "bilingual", "understudy", "evaluation", "(", "BLEU", ")", "has", "also", "been", "successfully", "used", "to", "evaluate", "paraphrase", "generation", "models", "."], "sentence-detokenized": "Although originally used to evaluate machine translations, bilingual understudy evaluation (BLEU) has also been successfully used to evaluate paraphrase generation models.", "token2charspan": [[0, 8], [9, 19], [20, 24], [25, 27], [28, 36], [37, 44], [45, 57], [57, 58], [59, 68], [69, 79], [80, 90], [91, 92], [92, 96], [96, 97], [98, 101], [102, 106], [107, 111], [112, 124], [125, 129], [130, 132], [133, 141], [142, 152], [153, 163], [164, 170], [170, 171]]}
{"doc_key": "ai-test-272", "ner": [[0, 0, "organisation"], [6, 8, "organisation"], [10, 12, "organisation"], [14, 14, "product"], [16, 16, "country"], [18, 18, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 8, "role", "licenses_to", false, false], [0, 0, 10, 12, "role", "licenses_to", false, false], [6, 8, 16, 16, "physical", "", false, false], [10, 12, 18, 18, "physical", "", false, false], [14, 14, 6, 8, "artifact", "produces", false, false], [14, 14, 10, 12, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "later", "licensed", "its", "technology", "to", "Kawasaki", "Heavy", "Industries", "and", "GKN", ",", "which", "manufacture", "Unimates", "in", "Japan", "and", "England", "."], "sentence-detokenized": "Unimation later licensed its technology to Kawasaki Heavy Industries and GKN, which manufacture Unimates in Japan and England.", "token2charspan": [[0, 9], [10, 15], [16, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 57], [58, 68], [69, 72], [73, 76], [76, 77], [78, 83], [84, 95], [96, 104], [105, 107], [108, 113], [114, 117], [118, 125], [125, 126]]}
{"doc_key": "ai-test-273", "ner": [[20, 21, "conference"], [38, 39, "field"], [57, 61, "field"], [63, 63, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[38, 39, 57, 61, "compare", "", false, false], [63, 63, 57, 61, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Much", "of", "the", "confusion", "between", "the", "two", "research", "communities", "(", "which", "often", "have", "separate", "conferences", "and", "separate", "journals", ",", "with", "ECML", "PKDD", "being", "a", "major", "exception", ")", "stems", "from", "the", "underlying", "assumptions", "with", "which", "they", "work", ":", "in", "machine", "learning", ",", "performance", "is", "typically", "evaluated", "with", "respect", "to", "the", "ability", "to", "reproduce", "known", "knowledge", ",", "whereas", "in", "knowledge", "discovery", "and", "data", "mining", "(", "KDD", ")", ",", "the", "key", "task", "is", "the", "discovery", "of", "previously", "unknown", "knowledge", "."], "sentence-detokenized": "Much of the confusion between the two research communities (which often have separate conferences and separate journals, with ECML PKDD being a major exception) stems from the underlying assumptions with which they work: in machine learning, performance is typically evaluated with respect to the ability to reproduce known knowledge, whereas in knowledge discovery and data mining (KDD), the key task is the discovery of previously unknown knowledge.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 29], [30, 33], [34, 37], [38, 46], [47, 58], [59, 60], [60, 65], [66, 71], [72, 76], [77, 85], [86, 97], [98, 101], [102, 110], [111, 119], [119, 120], [121, 125], [126, 130], [131, 135], [136, 141], [142, 143], [144, 149], [150, 159], [159, 160], [161, 166], [167, 171], [172, 175], [176, 186], [187, 198], [199, 203], [204, 209], [210, 214], [215, 219], [219, 220], [221, 223], [224, 231], [232, 240], [240, 241], [242, 253], [254, 256], [257, 266], [267, 276], [277, 281], [282, 289], [290, 292], [293, 296], [297, 304], [305, 307], [308, 317], [318, 323], [324, 333], [333, 334], [335, 342], [343, 345], [346, 355], [356, 365], [366, 369], [370, 374], [375, 381], [382, 383], [383, 386], [386, 387], [387, 388], [389, 392], [393, 396], [397, 401], [402, 404], [405, 408], [409, 418], [419, 421], [422, 432], [433, 440], [441, 450], [450, 451]]}
{"doc_key": "ai-test-274", "ner": [[0, 1, "algorithm"], [9, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 9, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Hidden", "Markov", "models", "are", "the", "basis", "of", "most", "modern", "automatic", "speech", "recognition", "systems", "."], "sentence-detokenized": "Hidden Markov models are the basis of most modern automatic speech recognition systems.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 28], [29, 34], [35, 37], [38, 42], [43, 49], [50, 59], [60, 66], [67, 78], [79, 86], [86, 87]]}
{"doc_key": "ai-test-275", "ner": [[4, 4, "location"], [6, 7, "country"], [11, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 6, 7, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": [",", "a", "company", "in", "Bangalore", ",", "India", "that", "specializes", "in", "online", "handwriting", "recognition", "software", "."], "sentence-detokenized": ", a company in Bangalore, India that specializes in online handwriting recognition software.", "token2charspan": [[0, 1], [2, 3], [4, 11], [12, 14], [15, 24], [24, 25], [26, 31], [32, 36], [37, 48], [49, 51], [52, 58], [59, 70], [71, 82], [83, 91], [91, 92]]}
{"doc_key": "ai-test-276", "ner": [[24, 25, "misc"], [50, 50, "metrics"], [52, 56, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[50, 50, 52, 56, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Do", "repeated", "translations", "converge", "to", "a", "single", "expression", "in", "both", "languages", "?", "I.e.", "does", "the", "translation", "method", "exhibit", "stationarity", "or", "does", "it", "produce", "a", "canonical", "form", "?", "Does", "the", "translation", "become", "stationary", "without", "losing", "the", "original", "meaning", "?", "This", "metric", "has", "been", "criticized", "because", "it", "does", "not", "correlate", "well", "with", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "results", "."], "sentence-detokenized": "Do repeated translations converge to a single expression in both languages? I.e. does the translation method exhibit stationarity or does it produce a canonical form? Does the translation become stationary without losing the original meaning? This metric has been criticized because it does not correlate well with BLEU (BiLingual Evaluation Understudy) results.", "token2charspan": [[0, 2], [3, 11], [12, 24], [25, 33], [34, 36], [37, 38], [39, 45], [46, 56], [57, 59], [60, 64], [65, 74], [74, 75], [76, 80], [81, 85], [86, 89], [90, 101], [102, 108], [109, 116], [117, 129], [130, 132], [133, 137], [138, 140], [141, 148], [149, 150], [151, 160], [161, 165], [165, 166], [167, 171], [172, 175], [176, 187], [188, 194], [195, 205], [206, 213], [214, 220], [221, 224], [225, 233], [234, 241], [241, 242], [243, 247], [248, 254], [255, 258], [259, 263], [264, 274], [275, 282], [283, 285], [286, 290], [291, 294], [295, 304], [305, 309], [310, 314], [315, 319], [320, 321], [321, 330], [331, 341], [342, 352], [352, 353], [354, 361], [361, 362]]}
{"doc_key": "ai-test-277", "ner": [[6, 10, "organisation"], [13, 20, "organisation"], [22, 25, "university"], [31, 31, "university"], [28, 30, "field"], [34, 38, "organisation"], [41, 56, "organisation"], [54, 57, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[13, 20, 22, 25, "part-of", "", false, false], [31, 31, 28, 30, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "is", "a", "member", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", ",", "the", "Center", "for", "Advanced", "Study", "in", "the", "Behavioral", "Sciences", "at", "Stanford", "University", ",", "the", "Center", "for", "Cognitive", "Science", "at", "MIT", ",", "the", "Canadian", "Institute", "for", "Advanced", "Research", ",", "the", "Canadian", "Psychological", "Association", ",", "and", "was", "elected", "a", "Fellow", "of", "the", "Royal", "Society", "of", "Canada", "in", "1998", "."], "sentence-detokenized": "He is a member of the American Association for Artificial Intelligence, the Center for Advanced Study in the Behavioral Sciences at Stanford University, the Center for Cognitive Science at MIT, the Canadian Institute for Advanced Research, the Canadian Psychological Association, and was elected a Fellow of the Royal Society of Canada in 1998.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 42], [43, 46], [47, 57], [58, 70], [70, 71], [72, 75], [76, 82], [83, 86], [87, 95], [96, 101], [102, 104], [105, 108], [109, 119], [120, 128], [129, 131], [132, 140], [141, 151], [151, 152], [153, 156], [157, 163], [164, 167], [168, 177], [178, 185], [186, 188], [189, 192], [192, 193], [194, 197], [198, 206], [207, 216], [217, 220], [221, 229], [230, 238], [238, 239], [240, 243], [244, 252], [253, 266], [267, 278], [278, 279], [280, 283], [284, 287], [288, 295], [296, 297], [298, 304], [305, 307], [308, 311], [312, 317], [318, 325], [326, 328], [329, 335], [336, 338], [339, 343], [343, 344]]}
{"doc_key": "ai-test-278", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [16, 19, "misc"], [22, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 16, 19, "part-of", "", false, false], [0, 0, 22, 25, "part-of", "", false, false], [4, 5, 16, 19, "part-of", "", false, false], [4, 5, 22, 25, "part-of", "", false, false], [7, 8, 16, 19, "part-of", "", false, false], [7, 8, 22, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", "-", "along", "with", "Yoshua", "Bengi", "and", "Yann", "LeCun", "-", "are", "hailed", "by", "some", "as", "the", "godfathers", "of", "artificial", "intelligence", "and", "the", "godfathers", "of", "deep", "learning", "."], "sentence-detokenized": "Hinton - along with Yoshua Bengi and Yann LeCun - are hailed by some as the godfathers of artificial intelligence and the godfathers of deep learning.", "token2charspan": [[0, 6], [7, 8], [9, 14], [15, 19], [20, 26], [27, 32], [33, 36], [37, 41], [42, 47], [48, 49], [50, 53], [54, 60], [61, 63], [64, 68], [69, 71], [72, 75], [76, 86], [87, 89], [90, 100], [101, 113], [114, 117], [118, 121], [122, 132], [133, 135], [136, 140], [141, 149], [149, 150]]}
{"doc_key": "ai-test-279", "ner": [[7, 9, "product"], [19, 19, "misc"], [21, 22, "misc"], [23, 23, "product"], [25, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 9, 19, 19, "related-to", "", false, false], [7, 9, 21, 22, "related-to", "", false, false], [19, 19, 23, 23, "named", "same", false, false], [25, 26, 23, 23, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "lightweight", "open", "-", "source", "speech", "project", "eSpeak", ",", "which", "has", "its", "own", "approach", "to", "synthesis", ",", "experimented", "with", "Mandarin", "and", "Cantonese", ".", "eSpeak", "used", "Google", "Translate", "from", "May", "2010", "to", "2010", "."], "sentence-detokenized": "The lightweight open-source speech project eSpeak, which has its own approach to synthesis, experimented with Mandarin and Cantonese. eSpeak used Google Translate from May 2010 to 2010.", "token2charspan": [[0, 3], [4, 15], [16, 20], [20, 21], [21, 27], [28, 34], [35, 42], [43, 49], [49, 50], [51, 56], [57, 60], [61, 64], [65, 68], [69, 77], [78, 80], [81, 90], [90, 91], [92, 104], [105, 109], [110, 118], [119, 122], [123, 132], [132, 133], [134, 140], [141, 145], [146, 152], [153, 162], [163, 167], [168, 171], [172, 176], [177, 179], [180, 184], [184, 185]]}
{"doc_key": "ai-test-280", "ner": [[3, 10, "product"], [19, 20, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 10, 19, 20, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1982", ",", "Automatic", "Mouth", "Software", "was", "also", "released", ",", "which", "was", "the", "first", "commercial", "full", "-", "software", "voice", "synthesis", "program", "."], "sentence-detokenized": "In 1982, Automatic Mouth Software was also released, which was the first commercial full-software voice synthesis program.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 24], [25, 33], [34, 37], [38, 42], [43, 51], [51, 52], [53, 58], [59, 62], [63, 66], [67, 72], [73, 83], [84, 88], [88, 89], [89, 97], [98, 103], [104, 113], [114, 121], [121, 122]]}
{"doc_key": "ai-test-281", "ner": [[6, 8, "metrics"], [10, 10, "metrics"], [13, 13, "metrics"], [15, 15, "metrics"], [18, 25, "metrics"], [30, 32, "metrics"], [34, 34, "metrics"], [37, 43, "metrics"], [47, 49, "metrics"], [51, 51, "metrics"], [54, 54, "metrics"], [56, 56, "metrics"], [59, 66, "metrics"], [71, 73, "metrics"], [75, 75, "metrics"], [78, 84, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[10, 10, 6, 8, "named", "", false, false], [13, 13, 6, 8, "named", "", false, false], [15, 15, 6, 8, "named", "", false, false], [18, 25, 6, 8, "named", "", false, false], [34, 34, 30, 32, "named", "", false, false], [37, 43, 30, 32, "named", "", false, false], [51, 51, 47, 49, "named", "", false, false], [54, 54, 47, 49, "named", "", false, false], [56, 56, 47, 49, "named", "", false, false], [59, 66, 47, 49, "named", "", false, false], [75, 75, 71, 73, "named", "", false, false], [78, 84, 71, 73, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["The", "ratios", "in", "the", "columns", "are", "TRUE", "Positive", "Rate", "(", "TPR", ",", "alias", "sensitivity", "or", "recall", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "with", "the", "complement", "FALSE", "Negative", "Rate", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ";", "and", "TRUE", "Negative", "Rate", "(", "TNR", ",", "alias", "specificity", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", ",", "with", "the", "complement", "FALSE", "Positive", "Rate", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "The ratios in the columns are TRUE Positive Rate (TPR, alias sensitivity or recall) (TP/(TP+FN)), with the complement FALSE Negative Rate (FNR) (FN/(TP+FN)); and TRUE Negative Rate (TNR, alias specificity, SPC) (TN/(TN+FP)), with the complement FALSE Positive Rate (FPR) (FP/(TN+FP)).", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 17], [18, 25], [26, 29], [30, 34], [35, 43], [44, 48], [49, 50], [50, 53], [53, 54], [55, 60], [61, 72], [73, 75], [76, 82], [82, 83], [84, 85], [85, 87], [87, 88], [88, 89], [89, 91], [91, 92], [92, 94], [94, 95], [95, 96], [96, 97], [98, 102], [103, 106], [107, 117], [118, 123], [124, 132], [133, 137], [138, 139], [139, 142], [142, 143], [144, 145], [145, 147], [147, 148], [148, 149], [149, 151], [151, 152], [152, 154], [154, 155], [155, 156], [156, 157], [158, 161], [162, 166], [167, 175], [176, 180], [181, 182], [182, 185], [185, 186], [187, 192], [193, 204], [204, 205], [206, 209], [209, 210], [211, 212], [212, 214], [214, 215], [215, 216], [216, 218], [218, 219], [219, 221], [221, 222], [222, 223], [223, 224], [225, 229], [230, 233], [234, 244], [245, 250], [251, 259], [260, 264], [265, 266], [266, 269], [269, 270], [271, 272], [272, 274], [274, 275], [275, 276], [276, 278], [278, 279], [279, 281], [281, 282], [282, 283], [283, 284]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 2, "person"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 15, 15, "role", "working_with", false, false], [2, 2, 15, 15, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "and", "Weber", "have", "also", "collaborated", "on", "many", "other", "robots", ",", "and", "their", "experience", "with", "Kismet"], "sentence-detokenized": "Edsinger and Weber have also collaborated on many other robots, and their experience with Kismet", "token2charspan": [[0, 8], [9, 12], [13, 18], [19, 23], [24, 28], [29, 41], [42, 44], [45, 49], [50, 55], [56, 62], [62, 63], [64, 67], [68, 73], [74, 84], [85, 89], [90, 96]]}
{"doc_key": "ai-test-283", "ner": [[0, 4, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 11, 11, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["R", "functions", "are", "also", "available", "from", "several", "scripting", "languages", "such", "as", "Python", "."], "sentence-detokenized": "R functions are also available from several scripting languages such as Python.", "token2charspan": [[0, 1], [2, 11], [12, 15], [16, 20], [21, 30], [31, 35], [36, 43], [44, 53], [54, 63], [64, 68], [69, 71], [72, 78], [78, 79]]}
{"doc_key": "ai-test-284", "ner": [[0, 0, "programlang"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "was", "one", "of", "the", "first", "robotic", "languages", "and", "was", "used", "in", "Unimate", "robots", "."], "sentence-detokenized": "VAL was one of the first robotic languages and was used in Unimate robots.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 18], [19, 24], [25, 32], [33, 42], [43, 46], [47, 50], [51, 55], [56, 58], [59, 66], [67, 73], [73, 74]]}
{"doc_key": "ai-test-285", "ner": [[10, 15, "conference"], [17, 17, "conference"], [21, 21, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 15, 21, 21, "physical", "", false, false], [17, 17, 10, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["They", "first", "presented", "their", "database", "as", "a", "poster", "at", "the", "2009", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "conference", "in", "Florida", "."], "sentence-detokenized": "They first presented their database as a poster at the 2009 Computer Vision and Pattern Recognition (CVPR) conference in Florida.", "token2charspan": [[0, 4], [5, 10], [11, 20], [21, 26], [27, 35], [36, 38], [39, 40], [41, 47], [48, 50], [51, 54], [55, 59], [60, 68], [69, 75], [76, 79], [80, 87], [88, 99], [100, 101], [101, 105], [105, 106], [107, 117], [118, 120], [121, 128], [128, 129]]}
{"doc_key": "ai-test-286", "ner": [[0, 2, "misc"], [11, 12, "task"], [14, 15, "field"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 12, 0, 2, "type-of", "", false, false], [14, 15, 0, 2, "type-of", "", false, false], [17, 18, 0, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Categorization", "tasks", "where", "no", "labels", "are", "supplied", "are", "referred", "to", "as", "unsupervised", "classification", ",", "unsupervised", "learning", ",", "cluster", "analysis", "."], "sentence-detokenized": "Categorization tasks where no labels are supplied are referred to as unsupervised classification, unsupervised learning, cluster analysis.", "token2charspan": [[0, 14], [15, 20], [21, 26], [27, 29], [30, 36], [37, 40], [41, 49], [50, 53], [54, 62], [63, 65], [66, 68], [69, 81], [82, 96], [96, 97], [98, 110], [111, 119], [119, 120], [121, 128], [129, 137], [137, 138]]}
{"doc_key": "ai-test-287", "ner": [[2, 3, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "needs", "object", "recognition", ",", "people", "recognition", "and", "localization", ",", "and", "more", "emotion", "recognition", "."], "sentence-detokenized": "It needs object recognition, people recognition and localization, and more emotion recognition.", "token2charspan": [[0, 2], [3, 8], [9, 15], [16, 27], [27, 28], [29, 35], [36, 47], [48, 51], [52, 64], [64, 65], [66, 69], [70, 74], [75, 82], [83, 94], [94, 95]]}
{"doc_key": "ai-test-288", "ner": [[6, 6, "misc"], [8, 8, "misc"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "process", "is", "complex", "and", "involves", "encoding", "and", "recall", "or", "retrieval", "."], "sentence-detokenized": "This process is complex and involves encoding and recall or retrieval.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 23], [24, 27], [28, 36], [37, 45], [46, 49], [50, 56], [57, 59], [60, 69], [69, 70]]}
{"doc_key": "ai-test-289", "ner": [[10, 11, "product"], [15, 16, "product"], [31, 33, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 15, 16, "named", "", false, false], [10, 11, 31, 33, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "also", "known", "as", "parallel", "robots", "or", "generalized", "Stewart", "platforms", "(", "in", "a", "Stewart", "platform", ",", "actuators", "are", "paired", "on", "both", "the", "base", "and", "the", "platform", ")", ",", "are", "articulated", "robots", "that", "use", "similar", "mechanisms", "to", "move", "either", "the", "robot", "on", "the", "base", "or", "one", "or", "more", "manipulator", "arms", "."], "sentence-detokenized": "These systems, also known as parallel robots or generalized Stewart platforms (in a Stewart platform, actuators are paired on both the base and the platform), are articulated robots that use similar mechanisms to move either the robot on the base or one or more manipulator arms.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 25], [26, 28], [29, 37], [38, 44], [45, 47], [48, 59], [60, 67], [68, 77], [78, 79], [79, 81], [82, 83], [84, 91], [92, 100], [100, 101], [102, 111], [112, 115], [116, 122], [123, 125], [126, 130], [131, 134], [135, 139], [140, 143], [144, 147], [148, 156], [156, 157], [157, 158], [159, 162], [163, 174], [175, 181], [182, 186], [187, 190], [191, 198], [199, 209], [210, 212], [213, 217], [218, 224], [225, 228], [229, 234], [235, 237], [238, 241], [242, 246], [247, 249], [250, 253], [254, 256], [257, 261], [262, 273], [274, 278], [278, 279]]}
{"doc_key": "ai-test-290", "ner": [[0, 1, "field"], [6, 7, "field"], [13, 16, "field"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 6, 7, "part-of", "subfield", false, false], [0, 1, 13, 16, "compare", "", false, false], [13, 16, 21, 22, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "vision", "as", "a", "discipline", "of", "systems", "engineering", "can", "be", "considered", "distinct", "from", "computer", "vision", ",", "which", "is", "a", "form", "of", "computer", "science", "."], "sentence-detokenized": "Machine vision as a discipline of systems engineering can be considered distinct from computer vision, which is a form of computer science.", "token2charspan": [[0, 7], [8, 14], [15, 17], [18, 19], [20, 30], [31, 33], [34, 41], [42, 53], [54, 57], [58, 60], [61, 71], [72, 80], [81, 85], [86, 94], [95, 101], [101, 102], [103, 108], [109, 111], [112, 113], [114, 118], [119, 121], [122, 130], [131, 138], [138, 139]]}
{"doc_key": "ai-test-291", "ner": [[4, 8, "algorithm"], [9, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 8, 9, 11, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "activation", "function", "of", "LSTM", "gates", "is", "often", "a", "logistic", "sigmoid", "function", "."], "sentence-detokenized": "The activation function of LSTM gates is often a logistic sigmoid function.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 26], [27, 31], [32, 37], [38, 40], [41, 46], [47, 48], [49, 57], [58, 65], [66, 74], [74, 75]]}
{"doc_key": "ai-test-292", "ner": [[5, 6, "metrics"], [19, 21, "metrics"], [23, 26, "metrics"], [31, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 19, 21, "named", "", false, false], [5, 6, 31, 33, "named", "", false, false], [23, 26, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "other", "words", ",", "the", "sample", "mean", "is", "a", "(", "necessarily", "unique", ")", "efficient", "estimator", ",", "and", "hence", "a", "minimum", "variance", "estimator", "(", "MVUE", ")", ",", "in", "addition", "to", "being", "a", "maximum", "likelihood", "estimator", "."], "sentence-detokenized": "In other words, the sample mean is a (necessarily unique) efficient estimator, and hence a minimum variance estimator (MVUE), in addition to being a maximum likelihood estimator.", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 19], [20, 26], [27, 31], [32, 34], [35, 36], [37, 38], [38, 49], [50, 56], [56, 57], [58, 67], [68, 77], [77, 78], [79, 82], [83, 88], [89, 90], [91, 98], [99, 107], [108, 117], [118, 119], [119, 123], [123, 124], [124, 125], [126, 128], [129, 137], [138, 140], [141, 146], [147, 148], [149, 156], [157, 167], [168, 177], [177, 178]]}
{"doc_key": "ai-test-293", "ner": [[3, 4, "academicjournal"], [7, 9, "researcher"], [11, 12, "researcher"], [15, 16, "researcher"], [24, 24, "product"], [27, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 24, 24, "topic", "", false, false], [3, 4, 27, 28, "topic", "", false, false], [7, 9, 3, 4, "role", "", false, false], [11, 12, 3, 4, "role", "", false, false], [15, 16, 3, 4, "role", "", false, false], [24, 24, 27, 28, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "a", "2001", "Scientific", "American", "article", ",", "Berners", "-", "Lee", ",", "James", "Hendler", ",", "and", "Ora", "Lassila", "described", "the", "expected", "evolution", "of", "the", "existing", "Web", "into", "the", "Semantic", "Web", "."], "sentence-detokenized": "In a 2001 Scientific American article, Berners-Lee, James Hendler, and Ora Lassila described the expected evolution of the existing Web into the Semantic Web.", "token2charspan": [[0, 2], [3, 4], [5, 9], [10, 20], [21, 29], [30, 37], [37, 38], [39, 46], [46, 47], [47, 50], [50, 51], [52, 57], [58, 65], [65, 66], [67, 70], [71, 74], [75, 82], [83, 92], [93, 96], [97, 105], [106, 115], [116, 118], [119, 122], [123, 131], [132, 135], [136, 140], [141, 144], [145, 153], [154, 157], [157, 158]]}
{"doc_key": "ai-test-294", "ner": [[10, 11, "misc"], [13, 13, "person"], [20, 24, "person"]], "ner_mapping_to_source": [0, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "number", "of", "then", "lesser", "-", "known", "actors", "appeared", "in", "Blade", "Runner", ":", "Sammon", ",", "pp.", "92", "-", "93", ".", "Nina", "Axelrod", "auditioned", "for", "the", "role", "."], "sentence-detokenized": "A number of then lesser-known actors appeared in Blade Runner: Sammon, pp. 92-93. Nina Axelrod auditioned for the role.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 16], [17, 23], [23, 24], [24, 29], [30, 36], [37, 45], [46, 48], [49, 54], [55, 61], [61, 62], [63, 69], [69, 70], [71, 74], [75, 77], [77, 78], [78, 80], [80, 81], [82, 86], [87, 94], [95, 105], [106, 109], [110, 113], [114, 118], [118, 119]]}
{"doc_key": "ai-test-295", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [12, 16, "university"], [21, 23, "product"], [25, 25, "product"], [39, 40, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 12, 16, "physical", "", false, false], [3, 4, 12, 16, "physical", "", false, false], [6, 7, 12, 16, "physical", "", false, false], [9, 10, 12, 16, "physical", "", false, false], [12, 16, 39, 40, "physical", "", true, false], [21, 23, 12, 16, "temporal", "", false, false], [25, 25, 12, 16, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Gerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "and", "Terry", "Winograd", "visited", "Edinburgh", "University", "in", "1971", "to", "spread", "the", "word", "about", "Micro", "-", "Planner", "and", "SHRDLU", "and", "to", "question", "the", "Unified", "Proof", "Procedure", "approach", "that", "was", "the", "mainstay", "of", "the", "Edinburgh", "logicians", "."], "sentence-detokenized": "Gerry Sussman, Eugene Charniak, Seymour Papert and Terry Winograd visited Edinburgh University in 1971 to spread the word about Micro-Planner and SHRDLU and to question the Unified Proof Procedure approach that was the mainstay of the Edinburgh logicians.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 21], [22, 30], [30, 31], [32, 39], [40, 46], [47, 50], [51, 56], [57, 65], [66, 73], [74, 83], [84, 94], [95, 97], [98, 102], [103, 105], [106, 112], [113, 116], [117, 121], [122, 127], [128, 133], [133, 134], [134, 141], [142, 145], [146, 152], [153, 156], [157, 159], [160, 168], [169, 172], [173, 180], [181, 186], [187, 196], [197, 205], [206, 210], [211, 214], [215, 218], [219, 227], [228, 230], [231, 234], [235, 244], [245, 254], [254, 255]]}
{"doc_key": "ai-test-296", "ner": [[0, 1, "researcher"], [7, 9, "field"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 11, 12, "role", "inspires", false, false], [0, 1, 14, 15, "role", "inspires", false, false], [0, 1, 17, 18, "role", "inspires", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Walter", "'s", "work", "inspired", "subsequent", "generations", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "Walter's work inspired subsequent generations of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 6], [6, 8], [9, 13], [14, 22], [23, 33], [34, 45], [46, 48], [49, 57], [58, 69], [70, 74], [75, 77], [78, 84], [85, 91], [91, 92], [93, 97], [98, 105], [106, 109], [110, 114], [115, 121], [121, 122]]}
{"doc_key": "ai-test-297", "ner": [[7, 7, "algorithm"], [9, 10, "researcher"], [16, 22, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 9, 10, "origin", "", false, false], [7, 7, 16, 22, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Subsequently", ",", "a", "similar", "GPU", "-", "based", "CNN", "by", "Alex", "Krizhevsky", "et", "al", ".", "won", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "2012", "."], "sentence-detokenized": "Subsequently, a similar GPU-based CNN by Alex Krizhevsky et al. won the ImageNet Large Scale Visual Recognition Challenge 2012.", "token2charspan": [[0, 12], [12, 13], [14, 15], [16, 23], [24, 27], [27, 28], [28, 33], [34, 37], [38, 40], [41, 45], [46, 56], [57, 59], [60, 62], [62, 63], [64, 67], [68, 71], [72, 80], [81, 86], [87, 92], [93, 99], [100, 111], [112, 121], [122, 126], [126, 127]]}
{"doc_key": "ai-test-298", "ner": [[2, 4, "misc"], [9, 10, "metrics"], [13, 14, "metrics"], [19, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 2, 4, "type-of", "", false, false], [13, 14, 2, 4, "type-of", "", false, false], [13, 14, 19, 21, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Commonly", "used", "loss", "functions", "for", "probabilistic", "classification", "include", "the", "logarithmic", "loss", "and", "the", "Brier", "score", "between", "the", "predicted", "and", "true", "probability", "distributions", "."], "sentence-detokenized": "Commonly used loss functions for probabilistic classification include the logarithmic loss and the Brier score between the predicted and true probability distributions.", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 28], [29, 32], [33, 46], [47, 61], [62, 69], [70, 73], [74, 85], [86, 90], [91, 94], [95, 98], [99, 104], [105, 110], [111, 118], [119, 122], [123, 132], [133, 136], [137, 141], [142, 153], [154, 167], [167, 168]]}
{"doc_key": "ai-test-299", "ner": [[4, 4, "organisation"], [11, 12, "field"], [8, 8, "organisation"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 11, 12, "general-affiliation", "field_of_study", false, false], [4, 4, 16, 17, "part-of", "", false, false], [8, 8, 4, 4, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "May", "2016", ",", "NtechLab", "was", "accepted", "into", "NIST", "'s", "official", "biometric", "technology", "testing", "among", "three", "Russian", "companies", "."], "sentence-detokenized": "In May 2016, NtechLab was accepted into NIST's official biometric technology testing among three Russian companies.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [13, 21], [22, 25], [26, 34], [35, 39], [40, 44], [44, 46], [47, 55], [56, 65], [66, 76], [77, 84], [85, 90], [91, 96], [97, 104], [105, 114], [114, 115]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "floating", "-", "point", "numbers", "only", "have", "a", "certain", "mathematical", "precision", "."], "sentence-detokenized": "However, floating-point numbers only have a certain mathematical precision.", "token2charspan": [[0, 7], [7, 8], [9, 17], [17, 18], [18, 23], [24, 31], [32, 36], [37, 41], [42, 43], [44, 51], [52, 64], [65, 74], [74, 75]]}
{"doc_key": "ai-test-301", "ner": [[5, 5, "organisation"], [12, 16, "conference"], [18, 18, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 12, 16, "role", "contributes_to", false, false], [18, 18, 12, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2015", ",", "many", "of", "SenseTime", "'s", "papers", "were", "accepted", "for", "the", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "conference", "."], "sentence-detokenized": "In 2015, many of SenseTime's papers were accepted for the Computer Vision and Pattern Recognition (CVPR) conference.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 13], [14, 16], [17, 26], [26, 28], [29, 35], [36, 40], [41, 49], [50, 53], [54, 57], [58, 66], [67, 73], [74, 77], [78, 85], [86, 97], [98, 99], [99, 103], [103, 104], [105, 115], [115, 116]]}
{"doc_key": "ai-test-302", "ner": [[5, 7, "task"], [9, 9, "task"], [11, 12, "task"], [14, 17, "task"], [20, 20, "field"], [22, 24, "misc"], [28, 34, "conference"], [41, 43, "misc"], [45, 46, "conference"], [64, 66, "misc"], [70, 70, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[5, 7, 20, 20, "part-of", "task_part_of_field", false, false], [9, 9, 5, 7, "named", "", false, false], [11, 12, 20, 20, "part-of", "task_part_of_field", false, false], [14, 17, 11, 12, "named", "", false, false], [22, 24, 28, 34, "temporal", "", false, false], [41, 43, 45, 46, "temporal", "", false, false], [64, 66, 70, 70, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["He", "co-developed", "optimal", "algorithms", "for", "structure", "from", "motion", "(", "SFM", "or", "Visual", "SLAM", ",", "simultaneous", "localization", "and", "mapping", ",", "in", "robotics", ";", "best", "paper", "award", "at", "the", "1998", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ")", ",", "characterized", "its", "ambiguity", "(", "David", "Marr", "Award", "at", "ICCV", "1999", ")", ",", "and", "also", "characterized", "the", "identifiability", "and", "observability", "of", "fusion", "of", "visual", "and", "inertial", "sensors", "(", "best", "paper", "award", "at", "the", "2015", "Robotics", "Conference", ")", "."], "sentence-detokenized": "He co-developed optimal algorithms for structure from motion (SFM or Visual SLAM, simultaneous localization and mapping, in robotics; best paper award at the 1998 Conference on Computer Vision and Pattern Recognition), characterized its ambiguity (David Marr Award at ICCV 1999), and also characterized the identifiability and observability of fusion of visual and inertial sensors (best paper award at the 2015 Robotics Conference).", "token2charspan": [[0, 2], [3, 15], [16, 23], [24, 34], [35, 38], [39, 48], [49, 53], [54, 60], [61, 62], [62, 65], [66, 68], [69, 75], [76, 80], [80, 81], [82, 94], [95, 107], [108, 111], [112, 119], [119, 120], [121, 123], [124, 132], [132, 133], [134, 138], [139, 144], [145, 150], [151, 153], [154, 157], [158, 162], [163, 173], [174, 176], [177, 185], [186, 192], [193, 196], [197, 204], [205, 216], [216, 217], [217, 218], [219, 232], [233, 236], [237, 246], [247, 248], [248, 253], [254, 258], [259, 264], [265, 267], [268, 272], [273, 277], [277, 278], [278, 279], [280, 283], [284, 288], [289, 302], [303, 306], [307, 322], [323, 326], [327, 340], [341, 343], [344, 350], [351, 353], [354, 360], [361, 364], [365, 373], [374, 381], [382, 383], [383, 387], [388, 393], [394, 399], [400, 402], [403, 406], [407, 411], [412, 420], [421, 431], [431, 432], [432, 433]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 44], [45, 48], [49, 52], [53, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-304", "ner": [[0, 1, "task"], [7, 8, "field"], [10, 11, "field"], [13, 16, "field"], [21, 22, "task"], [24, 24, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 7, 8, "part-of", "task_part_of_field", false, false], [0, 1, 10, 11, "part-of", "task_part_of_field", false, false], [0, 1, 13, 16, "part-of", "task_part_of_field", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 24, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Edge", "detection", "is", "an", "essential", "tool", "in", "image", "processing", ",", "machine", "vision", "and", "computer", "vision", ",", "especially", "in", "the", "areas", "of", "feature", "detection", "and", "extraction", "."], "sentence-detokenized": "Edge detection is an essential tool in image processing, machine vision and computer vision, especially in the areas of feature detection and extraction.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 20], [21, 30], [31, 35], [36, 38], [39, 44], [45, 55], [55, 56], [57, 64], [65, 71], [72, 75], [76, 84], [85, 91], [91, 92], [93, 103], [104, 106], [107, 110], [111, 116], [117, 119], [120, 127], [128, 137], [138, 141], [142, 152], [152, 153]]}
{"doc_key": "ai-test-305", "ner": [[8, 9, "misc"], [26, 31, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "example", "would", "be", "a", "variable", "such", "as", "outdoor", "temperature", "(", "mathtemp", "/", "math", ")", ",", "which", "in", "a", "given", "application", "can", "be", "recorded", "to", "several", "decimal", "places", "(", "depending", "on", "the", "sensing", "device", ")", "."], "sentence-detokenized": "An example would be a variable such as outdoor temperature (mathtemp / math), which in a given application can be recorded to several decimal places (depending on the sensing device).", "token2charspan": [[0, 2], [3, 10], [11, 16], [17, 19], [20, 21], [22, 30], [31, 35], [36, 38], [39, 46], [47, 58], [59, 60], [60, 68], [69, 70], [71, 75], [75, 76], [76, 77], [78, 83], [84, 86], [87, 88], [89, 94], [95, 106], [107, 110], [111, 113], [114, 122], [123, 125], [126, 133], [134, 141], [142, 148], [149, 150], [150, 159], [160, 162], [163, 166], [167, 174], [175, 181], [181, 182], [182, 183]]}
{"doc_key": "ai-test-306", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 12, "person"], [15, 16, "person"], [18, 18, "misc"], [22, 22, "misc"], [24, 25, "person"], [27, 27, "organisation"], [29, 30, "person"], [32, 32, "organisation"], [34, 36, "person"], [37, 37, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[24, 25, 18, 18, "part-of", "", false, false], [24, 25, 22, 22, "role", "", false, false], [29, 30, 27, 27, "role", "", false, false], [34, 36, 32, 32, "role", "youtuber", false, false], [37, 37, 34, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Fon", "Davis", ",", "Jessica", "Chobot", "and", "Leland", "Melvin", "return", ",", "as", "well", "as", "guest", "actor", "Clark", "Gregg", ",", "MythBusters", "host", "and", "former", "Battlebots", "builder", "Adam", "Savage", ",", "NFL", "player", "Vernon", "Davis", "and", "YouTube", "star", "Michael", "Stevens", "aka", "Vsauce", "."], "sentence-detokenized": "Fon Davis, Jessica Chobot and Leland Melvin return, as well as guest actor Clark Gregg, MythBusters host and former Battlebots builder Adam Savage, NFL player Vernon Davis and YouTube star Michael Stevens aka Vsauce.", "token2charspan": [[0, 3], [4, 9], [9, 10], [11, 18], [19, 25], [26, 29], [30, 36], [37, 43], [44, 50], [50, 51], [52, 54], [55, 59], [60, 62], [63, 68], [69, 74], [75, 80], [81, 86], [86, 87], [88, 99], [100, 104], [105, 108], [109, 115], [116, 126], [127, 134], [135, 139], [140, 146], [146, 147], [148, 151], [152, 158], [159, 165], [166, 171], [172, 175], [176, 183], [184, 188], [189, 196], [197, 204], [205, 208], [209, 215], [215, 216]]}
{"doc_key": "ai-test-307", "ner": [[17, 18, "algorithm"], [19, 23, "algorithm"], [25, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 25, 27, "part-of", "", false, false], [19, 23, 25, 27, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "these", "methods", "have", "never", "triumphed", "over", "the", "technology", "of", "a", "non-uniform", "internal", "hand", "-", "crafted", "Gaussian", "mixture", "model", "/", "hidden", "Markov", "model", "(", "GMM", "-", "HMM", ")", "based", "on", "generative", "speech", "models", "trained", "in", "a", "discriminative", "manner", "."], "sentence-detokenized": "However, these methods have never triumphed over the technology of a non-uniform internal hand-crafted Gaussian mixture model/hidden Markov model (GMM-HMM) based on generative speech models trained in a discriminative manner.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 22], [23, 27], [28, 33], [34, 43], [44, 48], [49, 52], [53, 63], [64, 66], [67, 68], [69, 80], [81, 89], [90, 94], [94, 95], [95, 102], [103, 111], [112, 119], [120, 125], [125, 126], [126, 132], [133, 139], [140, 145], [146, 147], [147, 150], [150, 151], [151, 154], [154, 155], [156, 161], [162, 164], [165, 175], [176, 182], [183, 189], [190, 197], [198, 200], [201, 202], [203, 217], [218, 224], [224, 225]]}
{"doc_key": "ai-test-308", "ner": [[4, 4, "product"], [6, 7, "programlang"], [9, 9, "programlang"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Software", "packages", "such", "as", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", "and", "SciPy", "provide", "convenient", "ways", "to", "use", "these", "different", "methods", "."], "sentence-detokenized": "Software packages such as MATLAB, GNU Octave, Scilab and SciPy provide convenient ways to use these different methods.", "token2charspan": [[0, 8], [9, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 37], [38, 44], [44, 45], [46, 52], [53, 56], [57, 62], [63, 70], [71, 81], [82, 86], [87, 89], [90, 93], [94, 99], [100, 109], [110, 117], [117, 118]]}
{"doc_key": "ai-test-309", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [11, 11, "task"], [16, 17, "researcher"], [19, 20, "university"], [22, 23, "researcher"], [25, 28, "organisation"], [30, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 11, 11, "related-to", "", false, false], [0, 2, 16, 17, "origin", "", false, false], [0, 2, 22, 23, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [16, 17, 19, 20, "physical", "", false, false], [16, 17, 19, 20, "role", "", false, false], [22, 23, 25, 28, "physical", "", false, false], [22, 23, 25, 28, "role", "", false, false], [30, 33, 25, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Linear", "Predictive", "Coding", "(", "LPC", ")", ",", "a", "speech", "processing", "algorithm", ",", "was", "first", "proposed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", "."], "sentence-detokenized": "Linear Predictive Coding (LPC), a speech processing algorithm, was first proposed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [30, 31], [32, 33], [34, 40], [41, 51], [52, 61], [61, 62], [63, 66], [67, 72], [73, 81], [82, 84], [85, 93], [94, 101], [102, 104], [105, 111], [112, 122], [123, 126], [127, 132], [133, 138], [139, 141], [142, 148], [149, 158], [159, 162], [163, 172], [173, 174], [174, 177], [177, 178], [179, 181], [182, 186], [186, 187]]}
{"doc_key": "ai-test-310", "ner": [[20, 27, "conference"], [29, 29, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[29, 29, 20, 27, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2006", ",", "on", "the", "occasion", "of", "the", "25th", "anniversary", "of", "the", "algorithm", ",", "a", "workshop", "was", "organized", "at", "the", "International", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "to", "summarize", "recent", "contributions", "and", "changes", "to", "the", "original", "algorithm", ",", "mostly", "to", "improve", "the", "speed", "of", "the", "algorithm", ",", "the", "robustness", "and", "accuracy", "of", "the", "estimated", "solution", ",", "and", "to", "reduce", "the", "dependence", "on", "user", "-", "defined", "constants", "."], "sentence-detokenized": "In 2006, on the occasion of the 25th anniversary of the algorithm, a workshop was organized at the International Conference on Computer Vision and Pattern Recognition (CVPR) to summarize recent contributions and changes to the original algorithm, mostly to improve the speed of the algorithm, the robustness and accuracy of the estimated solution, and to reduce the dependence on user-defined constants.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 24], [25, 27], [28, 31], [32, 36], [37, 48], [49, 51], [52, 55], [56, 65], [65, 66], [67, 68], [69, 77], [78, 81], [82, 91], [92, 94], [95, 98], [99, 112], [113, 123], [124, 126], [127, 135], [136, 142], [143, 146], [147, 154], [155, 166], [167, 168], [168, 172], [172, 173], [174, 176], [177, 186], [187, 193], [194, 207], [208, 211], [212, 219], [220, 222], [223, 226], [227, 235], [236, 245], [245, 246], [247, 253], [254, 256], [257, 264], [265, 268], [269, 274], [275, 277], [278, 281], [282, 291], [291, 292], [293, 296], [297, 307], [308, 311], [312, 320], [321, 323], [324, 327], [328, 337], [338, 346], [346, 347], [348, 351], [352, 354], [355, 361], [362, 365], [366, 376], [377, 379], [380, 384], [384, 385], [385, 392], [393, 402], [402, 403]]}
{"doc_key": "ai-test-311", "ner": [[4, 6, "university"], [9, 12, "organisation"], [14, 16, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Members", "went", "to", "the", "University", "of", "Debrecen", ",", "the", "Hungarian", "Academy", "of", "Sciences", ",", "E\u00f6tv\u00f6s", "Lor\u00e1nd", "University", ",", "etc", "."], "sentence-detokenized": "Members went to the University of Debrecen, the Hungarian Academy of Sciences, E\u00f6tv\u00f6s Lor\u00e1nd University, etc.", "token2charspan": [[0, 7], [8, 12], [13, 15], [16, 19], [20, 30], [31, 33], [34, 42], [42, 43], [44, 47], [48, 57], [58, 65], [66, 68], [69, 77], [77, 78], [79, 85], [86, 92], [93, 103], [103, 104], [105, 108], [108, 109]]}
{"doc_key": "ai-test-312", "ner": [[3, 3, "algorithm"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 17, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "extend", "the", "SVM", "to", "cases", "where", "the", "data", "are", "not", "linearly", "separable", ",", "we", "introduce", "a", "loss", "function", ","], "sentence-detokenized": "To extend the SVM to cases where the data are not linearly separable, we introduce a loss function,", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 17], [18, 20], [21, 26], [27, 32], [33, 36], [37, 41], [42, 45], [46, 49], [50, 58], [59, 68], [68, 69], [70, 72], [73, 82], [83, 84], [85, 89], [90, 98], [98, 99]]}
{"doc_key": "ai-test-313", "ner": [[0, 0, "programlang"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 10, 11, "origin", "", false, false], [0, 0, 13, 14, "origin", "", false, false], [0, 0, 16, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Logo", "is", "an", "educational", "programming", "language", "designed", "in", "1967", "by", "Wally", "Feurzeig", ",", "Seymour", "Papert", "and", "Cynthia", "Solomon", "."], "sentence-detokenized": "Logo is an educational programming language designed in 1967 by Wally Feurzeig, Seymour Papert and Cynthia Solomon.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 34], [35, 43], [44, 52], [53, 55], [56, 60], [61, 63], [64, 69], [70, 78], [78, 79], [80, 87], [88, 94], [95, 98], [99, 106], [107, 114], [114, 115]]}
{"doc_key": "ai-test-314", "ner": [[0, 3, "organisation"], [8, 12, "organisation"], [14, 17, "location"], [19, 19, "location"], [21, 23, "location"], [32, 37, "product"], [44, 47, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 8, 12, "role", "works_for", false, false], [8, 12, 14, 17, "physical", "", false, false], [14, 17, 19, 19, "physical", "", false, false], [19, 19, 21, 23, "physical", "", false, false], [32, 37, 0, 3, "origin", "", false, false], [44, 47, 32, 37, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "Eyring", "Research", "Institute", "was", "instrumental", "to", "the", "U.S.", "Air", "Force", "Missile", "Directorate", "at", "Hill", "Air", "Force", "Base", "near", "Ogden", ",", "Utah", ",", "which", ",", "under", "strict", "military", "secrecy", ",", "developed", "the", "intelligent", "systems", "technology", "software", "that", "was", "the", "basis", "of", "the", "later-", "named", "Reagan", "Star", "Wars", "program", "."], "sentence-detokenized": "The Eyring Research Institute was instrumental to the U.S. Air Force Missile Directorate at Hill Air Force Base near Ogden, Utah, which, under strict military secrecy, developed the intelligent systems technology software that was the basis of the later-named Reagan Star Wars program.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 29], [30, 33], [34, 46], [47, 49], [50, 53], [54, 58], [59, 62], [63, 68], [69, 76], [77, 88], [89, 91], [92, 96], [97, 100], [101, 106], [107, 111], [112, 116], [117, 122], [122, 123], [124, 128], [128, 129], [130, 135], [135, 136], [137, 142], [143, 149], [150, 158], [159, 166], [166, 167], [168, 177], [178, 181], [182, 193], [194, 201], [202, 212], [213, 221], [222, 226], [227, 230], [231, 234], [235, 240], [241, 243], [244, 247], [248, 254], [254, 259], [260, 266], [267, 271], [272, 276], [277, 284], [284, 285]]}
{"doc_key": "ai-test-315", "ner": [[21, 22, "field"], [0, 7, "researcher"], [9, 10, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Over", "the", "decades", ",", "John", "F", ".", "Sowa", "and", "John", "Zachman", "(", "1992", ")", "have", "explored", "and", "developed", "new", "areas", "of", "computer", "science", "ranging", "from", "compilers", ",", "programming", "languages", ",", "and", "system", "architecture", "."], "sentence-detokenized": "Over the decades, John F. Sowa and John Zachman (1992) have explored and developed new areas of computer science ranging from compilers, programming languages, and system architecture.", "token2charspan": [[0, 4], [5, 8], [9, 16], [16, 17], [18, 22], [23, 24], [24, 25], [26, 30], [31, 34], [35, 39], [40, 47], [48, 49], [49, 53], [53, 54], [55, 59], [60, 68], [69, 72], [73, 82], [83, 86], [87, 92], [93, 95], [96, 104], [105, 112], [113, 120], [121, 125], [126, 135], [135, 136], [137, 148], [149, 158], [158, 159], [160, 163], [164, 170], [171, 183], [183, 184]]}
{"doc_key": "ai-test-316", "ner": [[0, 2, "algorithm"], [7, 10, "algorithm"], [12, 13, "algorithm"], [18, 19, "field"], [21, 22, "field"], [26, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 10, 0, 2, "named", "", false, false], [12, 13, 0, 2, "named", "", false, false], [18, 19, 0, 2, "usage", "", false, false], [21, 22, 0, 2, "usage", "", false, false], [26, 30, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Sobel", "operator", ",", "sometimes", "called", "the", "Sobel", "-", "Feldman", "operator", "or", "Sobel", "filter", ",", "is", "used", "in", "image", "processing", "and", "computer", "vision", ",", "particularly", "in", "edge", "detection", "algorithms", ",", "where", "it", "produces", "an", "image", "with", "highlighted", "edges", "."], "sentence-detokenized": "The Sobel operator, sometimes called the Sobel-Feldman operator or Sobel filter, is used in image processing and computer vision, particularly in edge detection algorithms, where it produces an image with highlighted edges.", "token2charspan": [[0, 3], [4, 9], [10, 18], [18, 19], [20, 29], [30, 36], [37, 40], [41, 46], [46, 47], [47, 54], [55, 63], [64, 66], [67, 72], [73, 79], [79, 80], [81, 83], [84, 88], [89, 91], [92, 97], [98, 108], [109, 112], [113, 121], [122, 128], [128, 129], [130, 142], [143, 145], [146, 150], [151, 160], [161, 171], [171, 172], [173, 178], [179, 181], [182, 190], [191, 193], [194, 199], [200, 204], [205, 216], [217, 222], [222, 223]]}
{"doc_key": "ai-test-317", "ner": [[0, 0, "algorithm"], [3, 6, "field"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 3, 6, "compare", "", false, false], [0, 0, 3, 6, "type-of", "", false, false], [0, 0, 12, 12, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["LDA", "is", "a", "supervised", "learning", "algorithm", "that", "uses", "data", "labels", ",", "while", "PCA", "is", "a", "learning", "algorithm", "that", "ignores", "labels", "."], "sentence-detokenized": "LDA is a supervised learning algorithm that uses data labels, while PCA is a learning algorithm that ignores labels.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 19], [20, 28], [29, 38], [39, 43], [44, 48], [49, 53], [54, 60], [60, 61], [62, 67], [68, 71], [72, 74], [75, 76], [77, 85], [86, 95], [96, 100], [101, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-test-318", "ner": [[5, 5, "algorithm"], [7, 9, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "linear", "classification", "algorithms", "include", "Winnow", ",", "support", "vector", "machine", "and", "logistic", "regression", "."], "sentence-detokenized": "Other linear classification algorithms include Winnow, support vector machine and logistic regression.", "token2charspan": [[0, 5], [6, 12], [13, 27], [28, 38], [39, 46], [47, 53], [53, 54], [55, 62], [63, 69], [70, 77], [78, 81], [82, 90], [91, 101], [101, 102]]}
{"doc_key": "ai-test-319", "ner": [[0, 0, "product"], [6, 7, "programlang"], [16, 17, "product"], [19, 19, "programlang"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 7, "general-affiliation", "", true, false], [0, 0, 16, 17, "general-affiliation", "", true, false], [0, 0, 19, 19, "general-affiliation", "", true, false], [0, 0, 22, 22, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["VTK", "consists", "of", "a", "library", "of", "C", "++", "classes", "and", "several", "interpreted", "interface", "layers", ",", "including", "Tcl/", "Tk", ",", "Java", ",", "and", "Python", "."], "sentence-detokenized": "VTK consists of a library of C++ classes and several interpreted interface layers, including Tcl/Tk, Java, and Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 17], [18, 25], [26, 28], [29, 30], [30, 32], [33, 40], [41, 44], [45, 52], [53, 64], [65, 74], [75, 81], [81, 82], [83, 92], [93, 97], [97, 99], [99, 100], [101, 105], [105, 106], [107, 110], [111, 117], [117, 118]]}
{"doc_key": "ai-test-320", "ner": [[8, 10, "task"], [17, 19, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Even", "text", "produced", "by", "processing", "spontaneous", "speech", "using", "automatic", "speech", "recognition", "and", "printed", "or", "handwritten", "text", "using", "optical", "character", "recognition", "contains", "processing", "noise", "."], "sentence-detokenized": "Even text produced by processing spontaneous speech using automatic speech recognition and printed or handwritten text using optical character recognition contains processing noise.", "token2charspan": [[0, 4], [5, 9], [10, 18], [19, 21], [22, 32], [33, 44], [45, 51], [52, 57], [58, 67], [68, 74], [75, 86], [87, 90], [91, 98], [99, 101], [102, 113], [114, 118], [119, 124], [125, 132], [133, 142], [143, 154], [155, 163], [164, 174], [175, 180], [180, 181]]}
{"doc_key": "ai-test-321", "ner": [[0, 0, "researcher"], [10, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 10, 12, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "has", "written", "several", "books", "and", "directed", "the", "development", "of", "WordNet", ",", "an", "online", "database", "of", "word", "phrases", "usable", "in", "computer", "programs", "."], "sentence-detokenized": "Miller has written several books and directed the development of WordNet, an online database of word phrases usable in computer programs.", "token2charspan": [[0, 6], [7, 10], [11, 18], [19, 26], [27, 32], [33, 36], [37, 45], [46, 49], [50, 61], [62, 64], [65, 72], [72, 73], [74, 76], [77, 83], [84, 92], [93, 95], [96, 100], [101, 108], [109, 115], [116, 118], [119, 127], [128, 136], [136, 137]]}
{"doc_key": "ai-test-322", "ner": [[1, 1, "field"], [7, 9, "organisation"], [12, 13, "country"], [15, 16, "person"], [18, 20, "person"], [22, 23, "person"], [25, 26, "person"], [29, 30, "country"], [32, 35, "location"], [36, 38, "misc"], [39, 40, "person"], [42, 43, "person"], [45, 45, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[7, 9, 12, 13, "physical", "", false, false], [15, 16, 29, 30, "physical", "", false, false], [18, 20, 29, 30, "physical", "", false, false], [22, 23, 29, 30, "physical", "", false, false], [25, 26, 29, 30, "physical", "", false, false], [32, 35, 1, 1, "general-affiliation", "", false, false], [32, 35, 39, 40, "artifact", "", false, false], [36, 38, 39, 40, "named", "", false, false], [42, 43, 45, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Contemporary", "automata", "are", "represented", "by", "works", "by", "Cabaret", "Mechanical", "Theatre", "in", "the", "United", "Kingdom", ",", "Dug", "North", "and", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", ",", "Joe", "Jones", "in", "the", "United", "States", ",", "Le", "D\u00e9fenseur", "du", "Temps", "by", "French", "artist", "Jacques", "Monestier", "and", "Fran\u00e7ois", "Junod", "in", "Switzerland", "."], "sentence-detokenized": "Contemporary automata are represented by works by Cabaret Mechanical Theatre in the United Kingdom, Dug North and Chomick + Meder, Arthur Ganson, Joe Jones in the United States, Le D\u00e9fenseur du Temps by French artist Jacques Monestier and Fran\u00e7ois Junod in Switzerland.", "token2charspan": [[0, 12], [13, 21], [22, 25], [26, 37], [38, 40], [41, 46], [47, 49], [50, 57], [58, 68], [69, 76], [77, 79], [80, 83], [84, 90], [91, 98], [98, 99], [100, 103], [104, 109], [110, 113], [114, 121], [122, 123], [124, 129], [129, 130], [131, 137], [138, 144], [144, 145], [146, 149], [150, 155], [156, 158], [159, 162], [163, 169], [170, 176], [176, 177], [178, 180], [181, 190], [191, 193], [194, 199], [200, 202], [203, 209], [210, 216], [217, 224], [225, 234], [235, 238], [239, 247], [248, 253], [254, 256], [257, 268], [268, 269]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 22, 22, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "includes", "the", "standard", "codefor", "/", "code", "and", "codewhile", "/", "code", "loops", ",", "but", "(", "as", "in", "other", "similar", "applications", "such", "as", "R", ")", "it", "is", "recommended", "to", "use", "vector", "notation", ",", "which", "is", "often", "faster", "to", "execute", "."], "sentence-detokenized": "MATLAB includes the standard codefor/code and codewhile/code loops, but (as in other similar applications such as R) it is recommended to use vector notation, which is often faster to execute.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 28], [29, 36], [36, 37], [37, 41], [42, 45], [46, 55], [55, 56], [56, 60], [61, 66], [66, 67], [68, 71], [72, 73], [73, 75], [76, 78], [79, 84], [85, 92], [93, 105], [106, 110], [111, 113], [114, 115], [115, 116], [117, 119], [120, 122], [123, 134], [135, 137], [138, 141], [142, 148], [149, 157], [157, 158], [159, 164], [165, 167], [168, 173], [174, 180], [181, 183], [184, 191], [191, 192]]}
{"doc_key": "ai-test-324", "ner": [[0, 0, "researcher"], [6, 9, "conference"], [16, 17, "field"], [20, 26, "misc"], [29, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 20, 26, "win-defeat", "", false, false], [0, 0, 29, 38, "win-defeat", "", false, false], [20, 26, 6, 9, "temporal", "", false, false], [20, 26, 16, 17, "topic", "", false, false], [29, 38, 6, 9, "temporal", "", false, false], [29, 38, 16, 17, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pausch", "received", "two", "awards", "from", "the", "Association", "for", "Computing", "Machinery", "in", "2007", "for", "his", "achievements", "in", "computer", "education", ":", "the", "Karl", "V", ".", "Karlstrom", "Outstanding", "Educator", "Award", "and", "the", "ACM", "SIGCSE", "Award", "for", "outstanding", "contributions", "to", "computer", "science", "education", "."], "sentence-detokenized": "Pausch received two awards from the Association for Computing Machinery in 2007 for his achievements in computer education: the Karl V. Karlstrom Outstanding Educator Award and the ACM SIGCSE Award for outstanding contributions to computer science education.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 26], [27, 31], [32, 35], [36, 47], [48, 51], [52, 61], [62, 71], [72, 74], [75, 79], [80, 83], [84, 87], [88, 100], [101, 103], [104, 112], [113, 122], [122, 123], [124, 127], [128, 132], [133, 134], [134, 135], [136, 145], [146, 157], [158, 166], [167, 172], [173, 176], [177, 180], [181, 184], [185, 191], [192, 197], [198, 201], [202, 213], [214, 227], [228, 230], [231, 239], [240, 247], [248, 257], [257, 258]]}
{"doc_key": "ai-test-325", "ner": [[3, 3, "person"], [8, 11, "product"], [9, 9, "product"], [15, 16, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 8, 11, "role", "sells", false, false], [8, 11, 9, 9, "general-affiliation", "", false, false], [8, 11, 15, 16, "physical", "shipped_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "delivered", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was delivered to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 75], [76, 78], [79, 86], [87, 93], [94, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-test-326", "ner": [[0, 1, "algorithm"], [5, 7, "field"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 0, 1, "usage", "", false, false], [11, 12, 5, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Semantic", "networks", "are", "used", "in", "natural", "language", "processing", "applications", "such", "as", "semantic", "parsing", "."], "sentence-detokenized": "Semantic networks are used in natural language processing applications such as semantic parsing.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 26], [27, 29], [30, 37], [38, 46], [47, 57], [58, 70], [71, 75], [76, 78], [79, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-test-327", "ner": [[4, 5, "field"], [7, 8, "field"], [10, 11, "task"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 8, 4, 5, "usage", "", false, false], [10, 11, 4, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Some", "successful", "applications", "of", "deep", "learning", "are", "computer", "vision", "and", "speech", "recognition", ".", "Honglak", "Lee", ",", "Roger", "Grosse", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y", ".", "Ng", "."], "sentence-detokenized": "Some successful applications of deep learning are computer vision and speech recognition. Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 4], [5, 15], [16, 28], [29, 31], [32, 36], [37, 45], [46, 49], [50, 58], [59, 65], [66, 69], [70, 76], [77, 88], [88, 89], [90, 97], [98, 101], [101, 102], [103, 108], [109, 115], [115, 116], [117, 123], [124, 133], [133, 134], [135, 141], [142, 143], [143, 144], [145, 147], [147, 148]]}
{"doc_key": "ai-test-328", "ner": [[5, 9, "product"], [15, 15, "misc"], [18, 18, "misc"], [24, 24, "product"], [28, 29, "task"], [31, 32, "task"], [34, 35, "task"], [37, 39, "field"], [41, 42, "task"], [44, 45, "field"], [47, 48, "task"], [50, 51, "task"], [53, 55, "task"], [58, 59, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[5, 9, 15, 15, "physical", "travels_to", false, false], [5, 9, 18, 18, "physical", "travels_to", false, false], [24, 24, 5, 9, "part-of", "", false, false], [24, 24, 5, 9, "role", "maintains", false, false], [24, 24, 28, 29, "related-to", "has_ability_to", false, false], [24, 24, 31, 32, "related-to", "has_ability_to", false, false], [24, 24, 34, 35, "related-to", "has_ability_to", false, false], [24, 24, 37, 39, "related-to", "has_ability_to", false, false], [24, 24, 41, 42, "related-to", "has_ability_to", false, false], [24, 24, 44, 45, "related-to", "has_ability_to", false, false], [24, 24, 47, 48, "related-to", "has_ability_to", false, false], [24, 24, 50, 51, "related-to", "has_ability_to", false, false], [24, 24, 53, 55, "related-to", "has_ability_to", false, false], [24, 24, 58, 59, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["In", "addition", "to", "maintaining", "the", "Discovery", "One", "spacecraft", "'s", "systems", "during", "an", "interplanetary", "mission", "to", "Jupiter", "(", "or", "Saturn", "in", "the", "novel", ")", ",", "HAL", "is", "capable", "of", "speech", "synthesis", ",", "speech", "recognition", ",", "facial", "recognition", ",", "natural", "language", "processing", ",", "lip", "reading", ",", "art", "appreciation", ",", "affective", "computing", ",", "automated", "reasoning", ",", "piloting", "a", "spacecraft", ",", "and", "playing", "chess", "."], "sentence-detokenized": "In addition to maintaining the Discovery One spacecraft's systems during an interplanetary mission to Jupiter (or Saturn in the novel), HAL is capable of speech synthesis, speech recognition, facial recognition, natural language processing, lip reading, art appreciation, affective computing, automated reasoning, piloting a spacecraft, and playing chess.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 40], [41, 44], [45, 55], [55, 57], [58, 65], [66, 72], [73, 75], [76, 90], [91, 98], [99, 101], [102, 109], [110, 111], [111, 113], [114, 120], [121, 123], [124, 127], [128, 133], [133, 134], [134, 135], [136, 139], [140, 142], [143, 150], [151, 153], [154, 160], [161, 170], [170, 171], [172, 178], [179, 190], [190, 191], [192, 198], [199, 210], [210, 211], [212, 219], [220, 228], [229, 239], [239, 240], [241, 244], [245, 252], [252, 253], [254, 257], [258, 270], [270, 271], [272, 281], [282, 291], [291, 292], [293, 302], [303, 312], [312, 313], [314, 322], [323, 324], [325, 335], [335, 336], [337, 340], [341, 348], [349, 354], [354, 355]]}
{"doc_key": "ai-test-329", "ner": [[0, 1, "researcher"], [4, 4, "country"], [7, 8, "country"], [11, 11, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 4, "physical", "", false, false], [0, 1, 7, 8, "physical", "", false, false], [0, 1, 11, 11, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dr.", "Julesz", "emigrated", "from", "Hungary", "to", "the", "United", "States", "after", "the", "Soviet", "invasion", "in", "1956", "."], "sentence-detokenized": "Dr. Julesz emigrated from Hungary to the United States after the Soviet invasion in 1956.", "token2charspan": [[0, 3], [4, 10], [11, 20], [21, 25], [26, 33], [34, 36], [37, 40], [41, 47], [48, 54], [55, 60], [61, 64], [65, 71], [72, 80], [81, 83], [84, 88], [88, 89]]}
{"doc_key": "ai-test-330", "ner": [[4, 6, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "activation", "functions", "of", "the", "sigmoid", "function", "use", "the", "second", "nonlinearity", "for", "large", "inputs", ":", "math", "\\", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+\\", "exp", "(", "-", "v", "_", "i", ")", ")", "^", "{", "-1", "}", "/", "math", "."], "sentence-detokenized": "The activation functions of the sigmoid function use the second nonlinearity for large inputs: math\\ phi (v _ i) = (1 +\\ exp (-v _ i)) ^ {-1} / math.", "token2charspan": [[0, 3], [4, 14], [15, 24], [25, 27], [28, 31], [32, 39], [40, 48], [49, 52], [53, 56], [57, 63], [64, 76], [77, 80], [81, 86], [87, 93], [93, 94], [95, 99], [99, 100], [101, 104], [105, 106], [106, 107], [108, 109], [110, 111], [111, 112], [113, 114], [115, 116], [116, 117], [118, 120], [121, 124], [125, 126], [126, 127], [127, 128], [129, 130], [131, 132], [132, 133], [133, 134], [135, 136], [137, 138], [138, 140], [140, 141], [142, 143], [144, 148], [148, 149]]}
{"doc_key": "ai-test-331", "ner": [[10, 12, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "probabilities", "are", "used", "to", "determine", "the", "target", "using", "a", "maximum", "likelihood", "decision", "."], "sentence-detokenized": "These probabilities are used to determine the target using a maximum likelihood decision.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 28], [29, 31], [32, 41], [42, 45], [46, 52], [53, 58], [59, 60], [61, 68], [69, 79], [80, 88], [88, 89]]}
{"doc_key": "ai-test-332", "ner": [[6, 10, "university"], [14, 16, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1984", "he", "transferred", "to", "the", "University", "of", "Konstanz", "and", "in", "1990", "to", "the", "University", "of", "Salzburg", "."], "sentence-detokenized": "In 1984 he transferred to the University of Konstanz and in 1990 to the University of Salzburg.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 22], [23, 25], [26, 29], [30, 40], [41, 43], [44, 52], [53, 56], [57, 59], [60, 64], [65, 67], [68, 71], [72, 82], [83, 85], [86, 94], [94, 95]]}
{"doc_key": "ai-test-333", "ner": [[6, 7, "metrics"], [9, 11, "metrics"], [13, 15, "metrics"], [17, 17, "metrics"], [19, 20, "metrics"], [22, 24, "metrics"], [28, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 11, 6, 7, "origin", "based_on", false, false], [13, 15, 6, 7, "origin", "based_on", false, false], [17, 17, 6, 7, "origin", "based_on", false, false], [19, 20, 6, 7, "origin", "based_on", false, false], [22, 24, 6, 7, "origin", "based_on", false, false], [28, 32, 6, 7, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Popular", "suitability", "functions", "based", "on", "the", "confusion", "matrix", "include", "sensitivity", "/", "specificity", ",", "recall", "/", "accuracy", ",", "F-measure", ",", "Jaccard", "similarity", ",", "Matthews", "correlation", "coefficient", ",", "and", "a", "cost", "/", "benefit", "matrix", "that", "combines", "the", "costs", "and", "benefits", "associated", "with", "4", "different", "types", "of", "classifications", "."], "sentence-detokenized": "Popular suitability functions based on the confusion matrix include sensitivity/specificity, recall/accuracy, F-measure, Jaccard similarity, Matthews correlation coefficient, and a cost/benefit matrix that combines the costs and benefits associated with 4 different types of classifications.", "token2charspan": [[0, 7], [8, 19], [20, 29], [30, 35], [36, 38], [39, 42], [43, 52], [53, 59], [60, 67], [68, 79], [79, 80], [80, 91], [91, 92], [93, 99], [99, 100], [100, 108], [108, 109], [110, 119], [119, 120], [121, 128], [129, 139], [139, 140], [141, 149], [150, 161], [162, 173], [173, 174], [175, 178], [179, 180], [181, 185], [185, 186], [186, 193], [194, 200], [201, 205], [206, 214], [215, 218], [219, 224], [225, 228], [229, 237], [238, 248], [249, 253], [254, 255], [256, 265], [266, 271], [272, 274], [275, 290], [290, 291]]}
{"doc_key": "ai-test-334", "ner": [[6, 6, "product"], [8, 8, "product"], [10, 10, "product"], [12, 12, "product"], [15, 17, "programlang"], [27, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[27, 29, 6, 6, "part-of", "", false, false], [27, 29, 8, 8, "part-of", "", false, false], [27, 29, 10, 10, "part-of", "", false, false], [27, 29, 12, 12, "part-of", "", false, false], [27, 29, 15, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Common", "numerical", "programming", "environments", "such", "as", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", ",", "and", "the", "R", "language", "provide", "some", "simpler", "feature", "extraction", "techniques", "(", "e.g.", ",", "principal", "component", "analysis", ")", "via", "built", "-", "in", "commands", "."], "sentence-detokenized": "Common numerical programming environments such as MATLAB, SciLab, NumPy, Sklearn, and the R language provide some simpler feature extraction techniques (e.g., principal component analysis) via built-in commands.", "token2charspan": [[0, 6], [7, 16], [17, 28], [29, 41], [42, 46], [47, 49], [50, 56], [56, 57], [58, 64], [64, 65], [66, 71], [71, 72], [73, 80], [80, 81], [82, 85], [86, 89], [90, 91], [92, 100], [101, 108], [109, 113], [114, 121], [122, 129], [130, 140], [141, 151], [152, 153], [153, 157], [157, 158], [159, 168], [169, 178], [179, 187], [187, 188], [189, 192], [193, 198], [198, 199], [199, 201], [202, 210], [210, 211]]}
{"doc_key": "ai-test-335", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Industrial", "robots", "have", "been", "implemented", "to", "collaborate", "with", "humans", "to", "perform", "industrial", "manufacturing", "tasks", "."], "sentence-detokenized": "Industrial robots have been implemented to collaborate with humans to perform industrial manufacturing tasks.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 27], [28, 39], [40, 42], [43, 54], [55, 59], [60, 66], [67, 69], [70, 77], [78, 88], [89, 102], [103, 108], [108, 109]]}
{"doc_key": "ai-test-336", "ner": [[6, 15, "field"], [8, 11, "researcher"], [21, 22, "field"], [24, 25, "field"], [28, 29, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 15, 21, 22, "related-to", "", false, false], [6, 15, 24, 25, "related-to", "", false, false], [6, 15, 28, 29, "related-to", "", false, false], [8, 11, 6, 15, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "first", "published", "work", "on", "CG", ",", "John", "F", ".", "Sowa", "applied", "them", "to", "a", "wide", "range", "of", "topics", "in", "artificial", "intelligence", ",", "computer", "science", ",", "and", "cognitive", "science", "."], "sentence-detokenized": "In the first published work on CG, John F. Sowa applied them to a wide range of topics in artificial intelligence, computer science, and cognitive science.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [23, 27], [28, 30], [31, 33], [33, 34], [35, 39], [40, 41], [41, 42], [43, 47], [48, 55], [56, 60], [61, 63], [64, 65], [66, 70], [71, 76], [77, 79], [80, 86], [87, 89], [90, 100], [101, 113], [113, 114], [115, 123], [124, 131], [131, 132], [133, 136], [137, 146], [147, 154], [154, 155]]}
{"doc_key": "ai-test-337", "ner": [[0, 1, "metrics"], [4, 4, "metrics"], [10, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 4, 4, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "BLEU", "in", "the", "calculation", "of", "the", "brevity", "penalty", ",", "as", "small", "variations", "in", "translation", "length", "do", "not", "have", "such", "an", "impact", "on", "the", "overall", "score", "."], "sentence-detokenized": "NIST also differs from BLEU in the calculation of the brevity penalty, as small variations in translation length do not have such an impact on the overall score.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 46], [47, 49], [50, 53], [54, 61], [62, 69], [69, 70], [71, 73], [74, 79], [80, 90], [91, 93], [94, 105], [106, 112], [113, 115], [116, 119], [120, 124], [125, 129], [130, 132], [133, 139], [140, 142], [143, 146], [147, 154], [155, 160], [160, 161]]}
{"doc_key": "ai-test-338", "ner": [[0, 5, "misc"], [15, 15, "conference"], [23, 25, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 5, 15, 15, "temporal", "", false, false], [0, 5, 23, 25, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "IJCAI", "Award", "for", "Research", "Excellence", "is", "an", "award", "given", "twice", "a", "year", "at", "the", "IJCAI", "conference", "to", "researchers", "in", "the", "field", "of", "Artificial", "Intelligence", "in", "recognition", "of", "excellence", "in", "their", "careers", "."], "sentence-detokenized": "The IJCAI Award for Research Excellence is an award given twice a year at the IJCAI conference to researchers in the field of Artificial Intelligence in recognition of excellence in their careers.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 19], [20, 28], [29, 39], [40, 42], [43, 45], [46, 51], [52, 57], [58, 63], [64, 65], [66, 70], [71, 73], [74, 77], [78, 83], [84, 94], [95, 97], [98, 109], [110, 112], [113, 116], [117, 122], [123, 125], [126, 136], [137, 149], [150, 152], [153, 164], [165, 167], [168, 178], [179, 181], [182, 187], [188, 195], [195, 196]]}
{"doc_key": "ai-test-339", "ner": [[0, 0, "researcher"], [8, 11, "conference"], [18, 24, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 11, "role", "", false, false], [0, 0, 18, 24, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lenat", "was", "one", "of", "the", "original", "members", "of", "AAAI", "and", "is", "the", "only", "person", "to", "serve", "on", "the", "scientific", "advisory", "boards", "of", "Microsoft", "and", "Apple", "."], "sentence-detokenized": "Lenat was one of the original members of AAAI and is the only person to serve on the scientific advisory boards of Microsoft and Apple.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 16], [17, 20], [21, 29], [30, 37], [38, 40], [41, 45], [46, 49], [50, 52], [53, 56], [57, 61], [62, 68], [69, 71], [72, 77], [78, 80], [81, 84], [85, 95], [96, 104], [105, 111], [112, 114], [115, 124], [125, 128], [129, 134], [134, 135]]}
{"doc_key": "ai-test-340", "ner": [[0, 0, "algorithm"], [5, 6, "misc"], [10, 15, "metrics"], [19, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 6, "related-to", "minimise", false, false], [10, 15, 5, 6, "type-of", "", false, false], [19, 19, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autoencoders", "are", "trained", "to", "minimize", "reconstruction", "errors", "(", "e.g.", ",", "mean", "squared", "error", ")", ",", "often", "referred", "to", "as", "loss", ":"], "sentence-detokenized": "Autoencoders are trained to minimize reconstruction errors (e.g., mean squared error), often referred to as loss:", "token2charspan": [[0, 12], [13, 16], [17, 24], [25, 27], [28, 36], [37, 51], [52, 58], [59, 60], [60, 64], [64, 65], [66, 70], [71, 78], [79, 84], [84, 85], [85, 86], [87, 92], [93, 101], [102, 104], [105, 107], [108, 112], [112, 113]]}
{"doc_key": "ai-test-341", "ner": [[28, 32, "misc"], [34, 34, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[34, 34, 28, 32, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "alternative", "to", "using", "definitions", "is", "to", "consider", "the", "general", "relatedness", "of", "word", "senses", "and", "calculate", "the", "similarity", "of", "each", "pair", "of", "word", "senses", "based", "on", "a", "given", "lexical", "knowledge", "base", ",", "such", "as", "WordNet", "."], "sentence-detokenized": "An alternative to using definitions is to consider the general relatedness of word senses and calculate the similarity of each pair of word senses based on a given lexical knowledge base, such as WordNet.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 23], [24, 35], [36, 38], [39, 41], [42, 50], [51, 54], [55, 62], [63, 74], [75, 77], [78, 82], [83, 89], [90, 93], [94, 103], [104, 107], [108, 118], [119, 121], [122, 126], [127, 131], [132, 134], [135, 139], [140, 146], [147, 152], [153, 155], [156, 157], [158, 163], [164, 171], [172, 181], [182, 186], [186, 187], [188, 192], [193, 195], [196, 203], [203, 204]]}
{"doc_key": "ai-test-342", "ner": [[0, 2, "algorithm"], [9, 13, "researcher"], [17, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 9, 13, "origin", "", false, false], [9, 13, 17, 19, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD", "-", "Lambda", "is", "a", "learning", "algorithm", "invented", "by", "Richard", "S.", "Sutton", "based", "on", "previous", "work", "by", "Arthur", "Samuel", "on", "temporal", "difference", "learning", "."], "sentence-detokenized": "TD-Lambda is a learning algorithm invented by Richard S. Sutton based on previous work by Arthur Samuel on temporal difference learning.", "token2charspan": [[0, 2], [2, 3], [3, 9], [10, 12], [13, 14], [15, 23], [24, 33], [34, 42], [43, 45], [46, 53], [54, 56], [57, 63], [64, 69], [70, 72], [73, 81], [82, 86], [87, 89], [90, 96], [97, 103], [104, 106], [107, 115], [116, 126], [127, 135], [135, 136]]}
{"doc_key": "ai-test-343", "ner": [[1, 2, "field"], [4, 18, "field"], [6, 7, "task"], [11, 13, "task"], [15, 15, "task"], [19, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 7, 1, 2, "part-of", "task_part_of_field", false, false], [6, 7, 4, 18, "part-of", "task_part_of_field", false, false], [11, 13, 6, 7, "named", "", false, false], [15, 15, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "data", "mining", "and", "statistics", ",", "hierarchical", "clustering", "(", "also", "called", "hierarchical", "cluster", "analysis", "or", "HCA", ")", "is", "a", "cluster", "analysis", "method", "that", "aims", "to", "create", "a", "hierarchy", "of", "clusters", "."], "sentence-detokenized": "In data mining and statistics, hierarchical clustering (also called hierarchical cluster analysis or HCA) is a cluster analysis method that aims to create a hierarchy of clusters.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 18], [19, 29], [29, 30], [31, 43], [44, 54], [55, 56], [56, 60], [61, 67], [68, 80], [81, 88], [89, 97], [98, 100], [101, 104], [104, 105], [106, 108], [109, 110], [111, 118], [119, 127], [128, 134], [135, 139], [140, 144], [145, 147], [148, 154], [155, 156], [157, 166], [167, 169], [170, 178], [178, 179]]}
{"doc_key": "ai-test-344", "ner": [[3, 7, "algorithm"], [8, 11, "field"], [10, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 7, 8, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "concept", "of", "deconvolution", "is", "widely", "used", "in", "signal", "and", "image", "processing", "techniques", "."], "sentence-detokenized": "The concept of deconvolution is widely used in signal and image processing techniques.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 28], [29, 31], [32, 38], [39, 43], [44, 46], [47, 53], [54, 57], [58, 63], [64, 74], [75, 85], [85, 86]]}
{"doc_key": "ai-test-345", "ner": [[0, 1, "algorithm"], [23, 24, "misc"], [27, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 23, 24, "related-to", "enhances", false, false], [0, 1, 23, 24, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cognitive", "maps", "are", "used", "to", "build", "and", "accumulate", "spatial", "knowledge", ",", "allowing", "the", "mind", "'s", "eye", "to", "visualize", "images", "in", "order", "to", "reduce", "cognitive", "load", ",", "improve", "memorization", "and", "learning", "of", "information", "."], "sentence-detokenized": "Cognitive maps are used to build and accumulate spatial knowledge, allowing the mind's eye to visualize images in order to reduce cognitive load, improve memorization and learning of information.", "token2charspan": [[0, 9], [10, 14], [15, 18], [19, 23], [24, 26], [27, 32], [33, 36], [37, 47], [48, 55], [56, 65], [65, 66], [67, 75], [76, 79], [80, 84], [84, 86], [87, 90], [91, 93], [94, 103], [104, 110], [111, 113], [114, 119], [120, 122], [123, 129], [130, 139], [140, 144], [144, 145], [146, 153], [154, 166], [167, 170], [171, 179], [180, 182], [183, 194], [194, 195]]}
{"doc_key": "ai-test-346", "ner": [[9, 9, "programlang"], [11, 12, "programlang"], [14, 14, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": [",", "which", "usually", "provide", "bindings", "to", "languages", "such", "as", "Python", ",", "C", "++", ",", "Java", ")", "."], "sentence-detokenized": ", which usually provide bindings to languages such as Python, C++, Java).", "token2charspan": [[0, 1], [2, 7], [8, 15], [16, 23], [24, 32], [33, 35], [36, 45], [46, 50], [51, 53], [54, 60], [60, 61], [62, 63], [63, 65], [65, 66], [67, 71], [71, 72], [72, 73]]}
{"doc_key": "ai-test-347", "ner": [[0, 3, "product"], [5, 5, "product"], [16, 16, "task"], [23, 25, "task"], [28, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 16, 16, "usage", "", false, false], [0, 3, 23, 25, "usage", "", false, false], [0, 3, 28, 40, "usage", "", false, false], [5, 5, 0, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "voice", "user", "interface", "(", "VUI", ")", "enables", "spoken", "human", "-", "computer", "interaction", ",", "with", "speech", "recognition", "used", "to", "understand", "spoken", "commands", "and", "answers", "to", "questions", ",", "and", "text", "-", "to", "-", "speech", "conversion", "typically", "used", "to", "play", "back", "the", "answers", "."], "sentence-detokenized": "A voice user interface (VUI) enables spoken human-computer interaction, with speech recognition used to understand spoken commands and answers to questions, and text-to-speech conversion typically used to play back the answers.", "token2charspan": [[0, 1], [2, 7], [8, 12], [13, 22], [23, 24], [24, 27], [27, 28], [29, 36], [37, 43], [44, 49], [49, 50], [50, 58], [59, 70], [70, 71], [72, 76], [77, 83], [84, 95], [96, 100], [101, 103], [104, 114], [115, 121], [122, 130], [131, 134], [135, 142], [143, 145], [146, 155], [155, 156], [157, 160], [161, 165], [165, 166], [166, 168], [168, 169], [169, 175], [176, 186], [187, 196], [197, 201], [202, 204], [205, 209], [210, 214], [215, 218], [219, 226], [226, 227]]}
{"doc_key": "ai-test-348", "ner": [[0, 0, "programlang"], [3, 4, "misc"], [7, 7, "programlang"], [11, 14, "researcher"], [16, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 4, "general-affiliation", "is_a", false, false], [0, 0, 7, 7, "general-affiliation", "made_with", false, false], [0, 0, 11, 14, "origin", "", false, false], [11, 14, 16, 17, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Jess", "is", "a", "rule", "engine", "for", "the", "Java", "platform", "developed", "by", "Ernest", "Friedman", "-", "Hill", "of", "Sandia", "National", "."], "sentence-detokenized": "Jess is a rule engine for the Java platform developed by Ernest Friedman-Hill of Sandia National.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 14], [15, 21], [22, 25], [26, 29], [30, 34], [35, 43], [44, 53], [54, 56], [57, 63], [64, 72], [72, 73], [73, 77], [78, 80], [81, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-test-349", "ner": [[4, 7, "algorithm"], [20, 26, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 7, 20, 26, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "the", "case", "of", "multilayer", "perceptrons", ",", "where", "there", "is", "a", "hidden", "layer", ",", "more", "complex", "algorithms", ",", "such", "as", "back", "-", "propagation", ",", "must", "be", "used", "."], "sentence-detokenized": "In the case of multilayer perceptrons, where there is a hidden layer, more complex algorithms, such as back-propagation, must be used.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 25], [26, 37], [37, 38], [39, 44], [45, 50], [51, 53], [54, 55], [56, 62], [63, 68], [68, 69], [70, 74], [75, 82], [83, 93], [93, 94], [95, 99], [100, 102], [103, 107], [107, 108], [108, 119], [119, 120], [121, 125], [126, 128], [129, 133], [133, 134]]}
{"doc_key": "ai-test-350", "ner": [[0, 0, "product"], [2, 6, "product"], [10, 14, "algorithm"], [17, 18, "field"], [21, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 6, 0, 0, "part-of", "", false, false], [2, 6, 10, 14, "usage", "", false, true], [10, 14, 17, 18, "related-to", "performs", false, false], [21, 27, 17, 18, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Google", "Translate", "'s", "neural", "machine", "translation", "system", "uses", "a", "large", "artificial", "neural", "network", "that", "attempts", "to", "perform", "deep", "learning", ",", "especially", "networks", "with", "long", "short", "-", "term", "memory", "."], "sentence-detokenized": "Google Translate's neural machine translation system uses a large artificial neural network that attempts to perform deep learning, especially networks with long short-term memory.", "token2charspan": [[0, 6], [7, 16], [16, 18], [19, 25], [26, 33], [34, 45], [46, 52], [53, 57], [58, 59], [60, 65], [66, 76], [77, 83], [84, 91], [92, 96], [97, 105], [106, 108], [109, 116], [117, 121], [122, 130], [130, 131], [132, 142], [143, 151], [152, 156], [157, 161], [162, 167], [167, 168], [168, 172], [173, 179], [179, 180]]}
{"doc_key": "ai-test-351", "ner": [[14, 14, "researcher"], [16, 16, "researcher"], [18, 18, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Various", "methods", "for", "this", "purpose", "were", "developed", "in", "the", "1980s", "and", "early", "1990s", "by", "Werbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Pearlmutter", "and", "others", "."], "sentence-detokenized": "Various methods for this purpose were developed in the 1980s and early 1990s by Werbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Pearlmutter and others.", "token2charspan": [[0, 7], [8, 15], [16, 19], [20, 24], [25, 32], [33, 37], [38, 47], [48, 50], [51, 54], [55, 60], [61, 64], [65, 70], [71, 76], [77, 79], [80, 86], [86, 87], [88, 96], [96, 97], [98, 106], [106, 107], [108, 114], [115, 126], [126, 127], [128, 132], [133, 143], [143, 144], [145, 156], [157, 160], [161, 167], [167, 168]]}
{"doc_key": "ai-test-352", "ner": [[1, 1, "organisation"], [2, 3, "organisation"], [8, 9, "organisation"], [11, 14, "task"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 8, 9, "role", "licenses_from", false, false], [2, 3, 1, 1, "named", "", false, false], [15, 15, 1, 1, "origin", "", false, false], [15, 15, 11, 14, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["|", "Apple", "Apple", "Inc.", "originally", "licensed", "software", "from", "Nuance", "that", "enables", "speech", "recognition", "for", "its", "Siri", "digital", "assistant", "."], "sentence-detokenized": "| Apple Apple Inc. originally licensed software from Nuance that enables speech recognition for its Siri digital assistant.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 18], [19, 29], [30, 38], [39, 47], [48, 52], [53, 59], [60, 64], [65, 72], [73, 79], [80, 91], [92, 95], [96, 99], [100, 104], [105, 112], [113, 122], [122, 123]]}
{"doc_key": "ai-test-353", "ner": [[0, 0, "organisation"], [4, 6, "misc"], [8, 9, "person"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 6, "role", "releases_movies_in_genre", false, false], [8, 9, 0, 0, "role", "directs_for", false, false], [13, 14, 0, 0, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "has", "released", "several", "3D", "westerns", "produced", "by", "Sam", "Katzman", "and", "directed", "by", "William", "Castle", "."], "sentence-detokenized": "Columbia has released several 3D westerns produced by Sam Katzman and directed by William Castle.", "token2charspan": [[0, 8], [9, 12], [13, 21], [22, 29], [30, 32], [33, 41], [42, 50], [51, 53], [54, 57], [58, 65], [66, 69], [70, 78], [79, 81], [82, 89], [90, 96], [96, 97]]}
{"doc_key": "ai-test-354", "ner": [[6, 7, "field"], [9, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "includes", "knowledge", "and", "research", "in", "computer", "science", ",", "linguistics", "and", "computer", "engineering", "."], "sentence-detokenized": "It includes knowledge and research in computer science, linguistics and computer engineering.", "token2charspan": [[0, 2], [3, 11], [12, 21], [22, 25], [26, 34], [35, 37], [38, 46], [47, 54], [54, 55], [56, 67], [68, 71], [72, 80], [81, 92], [92, 93]]}
{"doc_key": "ai-test-355", "ner": [[5, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", "is", "an", "example", "of", "R", "code", ":"], "sentence-detokenized": "Here is an example of R code:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 23], [24, 28], [28, 29]]}
{"doc_key": "ai-test-356", "ner": [[0, 2, "metrics"], [8, 12, "metrics"], [14, 14, "metrics"], [17, 19, "metrics"], [21, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 8, 12, "part-of", "plotted_into", false, false], [0, 2, 17, 19, "part-of", "plotted_into", false, false], [14, 14, 8, 12, "named", "", false, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "ROC", "curve", "is", "generated", "by", "plotting", "the", "ratio", "of", "TRUE", "positive", "rate", "(", "TPR", ")", "and", "FALSE", "positive", "rate", "(", "FPR", ")", "at", "different", "threshold", "settings", "."], "sentence-detokenized": "The ROC curve is generated by plotting the ratio of TRUE positive rate (TPR) and FALSE positive rate (FPR) at different threshold settings.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 26], [27, 29], [30, 38], [39, 42], [43, 48], [49, 51], [52, 56], [57, 65], [66, 70], [71, 72], [72, 75], [75, 76], [77, 80], [81, 86], [87, 95], [96, 100], [101, 102], [102, 105], [105, 106], [107, 109], [110, 119], [120, 129], [130, 138], [138, 139]]}
{"doc_key": "ai-test-357", "ner": [[2, 3, "field"], [6, 7, "researcher"], [9, 10, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 2, 3, "related-to", "researches_field", false, false], [9, 10, 2, 3, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["After", "the", "machine", "learning", "research", "of", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", ",", "research", "stagnated", ","], "sentence-detokenized": "After the machine learning research of Marvin Minsky and Seymour Papert (1969), research stagnated,", "token2charspan": [[0, 5], [6, 9], [10, 17], [18, 26], [27, 35], [36, 38], [39, 45], [46, 52], [53, 56], [57, 64], [65, 71], [72, 73], [73, 77], [77, 78], [78, 79], [80, 88], [89, 98], [98, 99]]}
{"doc_key": "ai-test-358", "ner": [[8, 8, "task"], [11, 12, "programlang"], [14, 16, "product"], [18, 19, "programlang"], [21, 21, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 8, 11, 12, "related-to", "used_to_build", false, false], [8, 8, 14, 16, "related-to", "used_to_build", false, false], [8, 8, 18, 19, "related-to", "used_to_build", false, false], [8, 8, 21, 21, "related-to", "used_to_build", false, false], [8, 8, 24, 24, "related-to", "used_to_build", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "programming", "environments", "that", "are", "used", "to", "create", "DAQ", "applications", "include", "ladder", "logic", ",", "Visual", "C", "++", ",", "Visual", "Basic", ",", "LabVIEW", ",", "and", "MATLAB", "."], "sentence-detokenized": "Other programming environments that are used to create DAQ applications include ladder logic, Visual C++, Visual Basic, LabVIEW, and MATLAB.", "token2charspan": [[0, 5], [6, 17], [18, 30], [31, 35], [36, 39], [40, 44], [45, 47], [48, 54], [55, 58], [59, 71], [72, 79], [80, 86], [87, 92], [92, 93], [94, 100], [101, 102], [102, 104], [104, 105], [106, 112], [113, 118], [118, 119], [120, 127], [127, 128], [129, 132], [133, 139], [139, 140]]}
{"doc_key": "ai-test-359", "ner": [[16, 17, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "metric", "was", "designed", "to", "eliminate", "some", "of", "the", "problems", "that", "occur", "in", "the", "more", "popular", "BLEU", "metric", ",", "and", "also", "to", "achieve", "a", "good", "correlation", "with", "human", "judgment", "at", "the", "sentence", "or", "segment", "level", "."], "sentence-detokenized": "This metric was designed to eliminate some of the problems that occur in the more popular BLEU metric, and also to achieve a good correlation with human judgment at the sentence or segment level.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 24], [25, 27], [28, 37], [38, 42], [43, 45], [46, 49], [50, 58], [59, 63], [64, 69], [70, 72], [73, 76], [77, 81], [82, 89], [90, 94], [95, 101], [101, 102], [103, 106], [107, 111], [112, 114], [115, 122], [123, 124], [125, 129], [130, 141], [142, 146], [147, 152], [153, 161], [162, 164], [165, 168], [169, 177], [178, 180], [181, 188], [189, 194], [194, 195]]}
{"doc_key": "ai-test-360", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [12, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", ",", "and", "long", "-", "term", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "semantic", "correlations", "between", "successive", "frames", "of", "a", "video", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks, and long-term short-term memory are often used to exploit semantic correlations between successive frames of a video.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [73, 74], [75, 78], [79, 83], [83, 84], [84, 88], [89, 94], [94, 95], [95, 99], [100, 106], [107, 110], [111, 116], [117, 121], [122, 124], [125, 132], [133, 141], [142, 154], [155, 162], [163, 173], [174, 180], [181, 183], [184, 185], [186, 191], [191, 192]]}
{"doc_key": "ai-test-361", "ner": [[6, 6, "product"], [7, 7, "product"], [14, 19, "product"], [23, 26, "product"], [39, 42, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 14, 19, "artifact", "", false, false], [6, 6, 39, 42, "named", "", false, false], [7, 7, 6, 6, "named", "", false, false], [23, 26, 14, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Mass", "-", "produced", "printed", "circuit", "boards", "(", "PCBs", ")", "are", "almost", "exclusively", "manufactured", "using", "pick", "-", "and", "-", "place", "robots", ",", "usually", "with", "SCARA", "manipulators", ",", "which", "pick", "small", "electronic", "components", "from", "belts", "or", "trays", "and", "place", "them", "onto", "PCBs", "with", "great", "precision", "."], "sentence-detokenized": "Mass-produced printed circuit boards (PCBs) are almost exclusively manufactured using pick-and-place robots, usually with SCARA manipulators, which pick small electronic components from belts or trays and place them onto PCBs with great precision.", "token2charspan": [[0, 4], [4, 5], [5, 13], [14, 21], [22, 29], [30, 36], [37, 38], [38, 42], [42, 43], [44, 47], [48, 54], [55, 66], [67, 79], [80, 85], [86, 90], [90, 91], [91, 94], [94, 95], [95, 100], [101, 107], [107, 108], [109, 116], [117, 121], [122, 127], [128, 140], [140, 141], [142, 147], [148, 152], [153, 158], [159, 169], [170, 180], [181, 185], [186, 191], [192, 194], [195, 200], [201, 204], [205, 210], [211, 215], [216, 220], [221, 225], [226, 230], [231, 236], [237, 246], [246, 247]]}
{"doc_key": "ai-test-362", "ner": [[4, 9, "field"], [15, 15, "algorithm"], [22, 23, "researcher"], [25, 26, "researcher"], [29, 32, "researcher"], [37, 38, "algorithm"], [40, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 15, 4, 9, "part-of", "", false, false], [15, 15, 22, 23, "origin", "", false, false], [15, 15, 25, 26, "origin", "", false, false], [15, 15, 29, 32, "origin", "", false, false], [15, 15, 37, 38, "type-of", "", false, false], [37, 38, 40, 41, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "the", "context", "of", "machine", "learning", ",", "where", "it", "is", "most", "commonly", "applied", "today", ",", "LDA", "was", "independently", "discovered", "in", "2003", "by", "David", "Blei", ",", "Andrew", "Ng", ",", "and", "Michael", "I", ".", "Jordan", "and", "introduced", "as", "a", "graphical", "model", "for", "topic", "discovery", "."], "sentence-detokenized": "In the context of machine learning, where it is most commonly applied today, LDA was independently discovered in 2003 by David Blei, Andrew Ng, and Michael I. Jordan and introduced as a graphical model for topic discovery.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 25], [26, 34], [34, 35], [36, 41], [42, 44], [45, 47], [48, 52], [53, 61], [62, 69], [70, 75], [75, 76], [77, 80], [81, 84], [85, 98], [99, 109], [110, 112], [113, 117], [118, 120], [121, 126], [127, 131], [131, 132], [133, 139], [140, 142], [142, 143], [144, 147], [148, 155], [156, 157], [157, 158], [159, 165], [166, 169], [170, 180], [181, 183], [184, 185], [186, 195], [196, 201], [202, 205], [206, 211], [212, 221], [221, 222]]}
{"doc_key": "ai-test-363", "ner": [[9, 10, "task"], [12, 12, "misc"], [15, 15, "metrics"], [17, 17, "metrics"], [20, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 10, 12, 12, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["Performance", "measures", "on", "the", "test", "data", "of", "eight", "naive", "WSIs", "at", "different", "tauopathies", "resulted", "in", "recall", ",", "accuracy", ",", "and", "F1", "scores", "of", "0.92", ",", "0.72", ",", "and", "0.81", ",", "respectively", "."], "sentence-detokenized": "Performance measures on the test data of eight naive WSIs at different tauopathies resulted in recall, accuracy, and F1 scores of 0.92, 0.72, and 0.81, respectively.", "token2charspan": [[0, 11], [12, 20], [21, 23], [24, 27], [28, 32], [33, 37], [38, 40], [41, 46], [47, 52], [53, 57], [58, 60], [61, 70], [71, 82], [83, 91], [92, 94], [95, 101], [101, 102], [103, 111], [111, 112], [113, 116], [117, 119], [120, 126], [127, 129], [130, 134], [134, 135], [136, 140], [140, 141], [142, 145], [146, 150], [150, 151], [152, 164], [164, 165]]}
{"doc_key": "ai-test-364", "ner": [[2, 6, "field"], [9, 10, "field"], [13, 17, "field"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 6, 13, 17, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Using", "advanced", "augmented", "reality", "technologies", "(", "e.g.", ",", "adding", "computer", "vision", ",", "incorporating", "augmented", "reality", "cameras", "into", "a", "smartphone", ",", "and", "object", "recognition", ")", ",", "information", "about", "the", "user", "'s", "surrounding", "real", "world", "becomes", "interactive", "and", "digitally", "manipulatable", "."], "sentence-detokenized": "Using advanced augmented reality technologies (e.g., adding computer vision, incorporating augmented reality cameras into a smartphone, and object recognition), information about the user's surrounding real world becomes interactive and digitally manipulatable.", "token2charspan": [[0, 5], [6, 14], [15, 24], [25, 32], [33, 45], [46, 47], [47, 51], [51, 52], [53, 59], [60, 68], [69, 75], [75, 76], [77, 90], [91, 100], [101, 108], [109, 116], [117, 121], [122, 123], [124, 134], [134, 135], [136, 139], [140, 146], [147, 158], [158, 159], [159, 160], [161, 172], [173, 178], [179, 182], [183, 187], [187, 189], [190, 201], [202, 206], [207, 212], [213, 220], [221, 232], [233, 236], [237, 246], [247, 260], [260, 261]]}
{"doc_key": "ai-test-365", "ner": [[3, 3, "researcher"], [5, 7, "organisation"], [13, 14, "field"], [23, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 5, 7, "role", "forms_company", false, false], [5, 7, 13, 14, "related-to", "works_with", false, false], [5, 7, 23, 25, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2014", ",", "Schmidhuber", "founded", "Nnaisense", ",", "which", "works", "on", "commercial", "applications", "of", "AI", "in", "areas", "such", "as", "finance", ",", "heavy", "industry", "and", "self", "-", "driving", "cars", "."], "sentence-detokenized": "In 2014, Schmidhuber founded Nnaisense, which works on commercial applications of AI in areas such as finance, heavy industry and self-driving cars.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 28], [29, 38], [38, 39], [40, 45], [46, 51], [52, 54], [55, 65], [66, 78], [79, 81], [82, 84], [85, 87], [88, 93], [94, 98], [99, 101], [102, 109], [109, 110], [111, 116], [117, 125], [126, 129], [130, 134], [134, 135], [135, 142], [143, 147], [147, 148]]}
{"doc_key": "ai-test-366", "ner": [[25, 29, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Not", "only", "does", "this", "change", "the", "performance", "of", "all", "subsequent", "tests", "on", "the", "retained", "explanatory", "model", ",", "but", "it", "may", "introduce", "bias", "and", "change", "the", "root", "mean", "square", "error", "of", "the", "estimate", "."], "sentence-detokenized": "Not only does this change the performance of all subsequent tests on the retained explanatory model, but it may introduce bias and change the root mean square error of the estimate.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 18], [19, 25], [26, 29], [30, 41], [42, 44], [45, 48], [49, 59], [60, 65], [66, 68], [69, 72], [73, 81], [82, 93], [94, 99], [99, 100], [101, 104], [105, 107], [108, 111], [112, 121], [122, 126], [127, 130], [131, 137], [138, 141], [142, 146], [147, 151], [152, 158], [159, 164], [165, 167], [168, 171], [172, 180], [180, 181]]}
{"doc_key": "ai-test-367", "ner": [[0, 3, "misc"], [6, 6, "algorithm"], [9, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 0, 3, "usage", "", false, false], [6, 6, 9, 10, "topic", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Bigrams", "are", "used", "in", "most", "successful", "language", "models", "for", "speech", "recognition", "."], "sentence-detokenized": "Bigrams are used in most successful language models for speech recognition.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 19], [20, 24], [25, 35], [36, 44], [45, 51], [52, 55], [56, 62], [63, 74], [74, 75]]}
{"doc_key": "ai-test-368", "ner": [[4, 5, "field"], [11, 13, "misc"], [19, 21, "misc"], [27, 29, "organisation"], [32, 34, "misc"], [40, 43, "organisation"], [46, 48, "misc"], [54, 58, "organisation"], [62, 64, "misc"], [70, 73, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[11, 13, 4, 5, "topic", "", false, false], [19, 21, 27, 29, "origin", "", false, false], [32, 34, 40, 43, "origin", "", false, false], [46, 48, 54, 58, "origin", "", false, false], [62, 64, 70, 73, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["For", "his", "research", "in", "cognitive", "psychology", ",", "he", "has", "received", "the", "Early", "Career", "Award", "(", "1984", ")", "and", "the", "Boyd", "McCandless", "Award", "(", "1986", ")", "from", "the", "American", "Psychological", "Association", ",", "the", "Troland", "Research", "Award", "(", "1993", ")", "from", "the", "National", "Academy", "of", "Sciences", ",", "the", "Henry", "Dale", "Award", "(", "2004", ")", "from", "the", "Royal", "Institute", "of", "Great", "Britain", ",", "and", "the", "George", "Miller", "Award", "(", "2010", ")", "from", "the", "Society", "for", "Cognitive", "Neuroscience", "."], "sentence-detokenized": "For his research in cognitive psychology, he has received the Early Career Award (1984) and the Boyd McCandless Award (1986) from the American Psychological Association, the Troland Research Award (1993) from the National Academy of Sciences, the Henry Dale Award (2004) from the Royal Institute of Great Britain, and the George Miller Award (2010) from the Society for Cognitive Neuroscience.", "token2charspan": [[0, 3], [4, 7], [8, 16], [17, 19], [20, 29], [30, 40], [40, 41], [42, 44], [45, 48], [49, 57], [58, 61], [62, 67], [68, 74], [75, 80], [81, 82], [82, 86], [86, 87], [88, 91], [92, 95], [96, 100], [101, 111], [112, 117], [118, 119], [119, 123], [123, 124], [125, 129], [130, 133], [134, 142], [143, 156], [157, 168], [168, 169], [170, 173], [174, 181], [182, 190], [191, 196], [197, 198], [198, 202], [202, 203], [204, 208], [209, 212], [213, 221], [222, 229], [230, 232], [233, 241], [241, 242], [243, 246], [247, 252], [253, 257], [258, 263], [264, 265], [265, 269], [269, 270], [271, 275], [276, 279], [280, 285], [286, 295], [296, 298], [299, 304], [305, 312], [312, 313], [314, 317], [318, 321], [322, 328], [329, 335], [336, 341], [342, 343], [343, 347], [347, 348], [349, 353], [354, 357], [358, 365], [366, 369], [370, 379], [380, 392], [392, 393]]}
{"doc_key": "ai-test-369", "ner": [[0, 0, "misc"], [6, 6, "misc"], [9, 11, "product"], [15, 15, "researcher"], [17, 17, "researcher"], [27, 28, "researcher"], [30, 31, "researcher"], [24, 25, "task"], [33, 36, "researcher"], [38, 42, "researcher"], [43, 44, "task"], [46, 46, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[0, 0, 6, 6, "named", "", false, false], [0, 0, 46, 46, "named", "", false, false], [6, 6, 15, 15, "origin", "", false, false], [6, 6, 17, 17, "origin", "", false, false], [6, 6, 24, 25, "related-to", "used_for", false, false], [9, 11, 6, 6, "usage", "", false, false], [9, 11, 43, 44, "named", "", false, false], [27, 28, 6, 6, "usage", "", false, false], [27, 28, 33, 36, "named", "same", false, false], [30, 31, 6, 6, "usage", "", false, false], [30, 31, 38, 42, "named", "same", false, false], [43, 44, 46, 46, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Eigenface", "(", "The", "approach", "of", "using", "eigenfaces", "for", "a", "face", "recognition", "system", "was", "developed", "by", "Sirovich", "and", "Kirby", "(", "1987", ")", "and", "used", "in", "face", "classification", "by", "Matthew", "Turk", "and", "Alex", "Pentland", ".", "Turk", ",", "Matthew", "A", "and", "Pentland", ",", "Alex", "P", ".", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "Eigenface (The approach of using eigenfaces for a face recognition system was developed by Sirovich and Kirby (1987) and used in face classification by Matthew Turk and Alex Pentland. Turk, Matthew A and Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 9], [10, 11], [11, 14], [15, 23], [24, 26], [27, 32], [33, 43], [44, 47], [48, 49], [50, 54], [55, 66], [67, 73], [74, 77], [78, 87], [88, 90], [91, 99], [100, 103], [104, 109], [110, 111], [111, 115], [115, 116], [117, 120], [121, 125], [126, 128], [129, 133], [134, 148], [149, 151], [152, 159], [160, 164], [165, 168], [169, 173], [174, 182], [182, 183], [184, 188], [188, 189], [190, 197], [198, 199], [200, 203], [204, 212], [212, 213], [214, 218], [219, 220], [220, 221], [222, 226], [227, 238], [239, 244], [245, 255], [255, 256]]}
{"doc_key": "ai-test-370", "ner": [[6, 11, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "lexical", "dictionary", ",", "such", "as", "WordNet", ",", "can", "then", "be", "used", "to", "understand", "the", "context", "."], "sentence-detokenized": "A lexical dictionary, such as WordNet, can then be used to understand the context.", "token2charspan": [[0, 1], [2, 9], [10, 20], [20, 21], [22, 26], [27, 29], [30, 37], [37, 38], [39, 42], [43, 47], [48, 50], [51, 55], [56, 58], [59, 69], [70, 73], [74, 81], [81, 82]]}
{"doc_key": "ai-test-371", "ner": [[0, 0, "misc"], [8, 8, "misc"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 8, "part-of", "", false, false], [8, 8, 15, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hyponymy", "is", "the", "most", "commonly", "encoded", "relationship", "between", "synsets", "used", "in", "lexical", "databases", "such", "as", "WordNet", "."], "sentence-detokenized": "Hyponymy is the most commonly encoded relationship between synsets used in lexical databases such as WordNet.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 20], [21, 29], [30, 37], [38, 50], [51, 58], [59, 66], [67, 71], [72, 74], [75, 82], [83, 92], [93, 97], [98, 100], [101, 108], [108, 109]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [7, 8, "programlang"], [10, 12, "programlang"], [41, 42, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 8, "general-affiliation", "", false, false], [0, 0, 10, 12, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "offers", "open", "-", "source", "libraries", "in", "C", "++", "and", "Java", ",", "but", "many", "clients", "rely", "on", "community", "-", "developed", "libraries", ";", "for", "example", ",", "the", "libraries", "include", "built", "-", "in", "functions", "for", "extracting", "data", "(", "array", "-", "style", ")", "from", "DAP", "servers", "."], "sentence-detokenized": "OPeNDAP offers open-source libraries in C++ and Java, but many clients rely on community-developed libraries; for example, the libraries include built-in functions for extracting data (array-style) from DAP servers.", "token2charspan": [[0, 7], [8, 14], [15, 19], [19, 20], [20, 26], [27, 36], [37, 39], [40, 41], [41, 43], [44, 47], [48, 52], [52, 53], [54, 57], [58, 62], [63, 70], [71, 75], [76, 78], [79, 88], [88, 89], [89, 98], [99, 108], [108, 109], [110, 113], [114, 121], [121, 122], [123, 126], [127, 136], [137, 144], [145, 150], [150, 151], [151, 153], [154, 163], [164, 167], [168, 178], [179, 183], [184, 185], [185, 190], [190, 191], [191, 196], [196, 197], [198, 202], [203, 206], [207, 214], [214, 215]]}
{"doc_key": "ai-test-373", "ner": [[4, 5, "misc"], [7, 8, "product"], [17, 17, "country"], [30, 31, "misc"], [44, 44, "organisation"], [46, 46, "product"], [54, 54, "organisation"], [50, 53, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 17, 17, "opposite", "", false, false], [7, 8, 17, 17, "artifact", "", false, false], [30, 31, 7, 8, "part-of", "", false, false], [46, 46, 44, 44, "artifact", "", false, false], [50, 53, 54, 54, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["On", "this", "page", ",", "Samurai", "Damashii", "exaggerated", "the", "Senkousha", "as", "a", "crystallization", "of", "four", "thousand", "years", "of", "Chinese", "scientific", "knowledge", ",", "commented", "on", "its", "crude", "design", "(", "e.g.", ",", "the", "Chinese", "cannon", "on", "its", "crotch", ")", ",", "and", "placed", "its", "picture", "between", "images", "of", "Honda", "'s", "ASIMO", "and", "Sony", "'s", "QRIO", "SDR", "-", "3X", "to", "compare", "."], "sentence-detokenized": "On this page, Samurai Damashii exaggerated the Senkousha as a crystallization of four thousand years of Chinese scientific knowledge, commented on its crude design (e.g., the Chinese cannon on its crotch), and placed its picture between images of Honda's ASIMO and Sony's QRIO SDR-3X to compare.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 21], [22, 30], [31, 42], [43, 46], [47, 56], [57, 59], [60, 61], [62, 77], [78, 80], [81, 85], [86, 94], [95, 100], [101, 103], [104, 111], [112, 122], [123, 132], [132, 133], [134, 143], [144, 146], [147, 150], [151, 156], [157, 163], [164, 165], [165, 169], [169, 170], [171, 174], [175, 182], [183, 189], [190, 192], [193, 196], [197, 203], [203, 204], [204, 205], [206, 209], [210, 216], [217, 220], [221, 228], [229, 236], [237, 243], [244, 246], [247, 252], [252, 254], [255, 260], [261, 264], [265, 269], [269, 271], [272, 276], [277, 280], [280, 281], [281, 283], [284, 286], [287, 294], [294, 295]]}
{"doc_key": "ai-test-374", "ner": [[8, 9, "algorithm"], [20, 20, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 20, 20, "part-of", "includes_functionality_of", false, false], [8, 9, 22, 22, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "also", "many", "programming", "libraries", "that", "include", "neural", "network", "functions", "that", "can", "be", "used", "in", "custom", "implementations", "(", "e.g.", "TensorFlow", ",", "Theano", ",", "etc", "."], "sentence-detokenized": "There are also many programming libraries that include neural network functions that can be used in custom implementations (e.g. TensorFlow, Theano, etc.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 19], [20, 31], [32, 41], [42, 46], [47, 54], [55, 61], [62, 69], [70, 79], [80, 84], [85, 88], [89, 91], [92, 96], [97, 99], [100, 106], [107, 122], [123, 124], [124, 128], [129, 139], [139, 140], [141, 147], [147, 148], [149, 152], [152, 153]]}
{"doc_key": "ai-test-375", "ner": [[6, 9, "conference"], [11, 11, "organisation"], [13, 19, "conference"], [21, 21, "conference"], [24, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", ",", "IEEE", ",", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "IAPR", ",", "and", "SPIE", "."], "sentence-detokenized": "He is a member of the Association for Computing Machinery, IEEE, American Association for the Advancement of Science, IAPR, and SPIE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 33], [34, 37], [38, 47], [48, 57], [57, 58], [59, 63], [63, 64], [65, 73], [74, 85], [86, 89], [90, 93], [94, 105], [106, 108], [109, 116], [116, 117], [118, 122], [122, 123], [124, 127], [128, 132], [132, 133]]}
{"doc_key": "ai-test-376", "ner": [[4, 7, "organisation"], [9, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 7, 9, 11, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "trial", "run", "of", "the", "RET", "in", "2011", "with", "facial", "recognition", "system", "cameras", "mounted", "on", "trams", "ensured", "that", "people", "who", "were", "banned", "from", "the", "city", "'s", "trams", "did", "not", "sneak", "off", "anyway", "."], "sentence-detokenized": "A trial run of the RET in 2011 with facial recognition system cameras mounted on trams ensured that people who were banned from the city's trams did not sneak off anyway.", "token2charspan": [[0, 1], [2, 7], [8, 11], [12, 14], [15, 18], [19, 22], [23, 25], [26, 30], [31, 35], [36, 42], [43, 54], [55, 61], [62, 69], [70, 77], [78, 80], [81, 86], [87, 94], [95, 99], [100, 106], [107, 110], [111, 115], [116, 122], [123, 127], [128, 131], [132, 136], [136, 138], [139, 144], [145, 148], [149, 152], [153, 158], [159, 162], [163, 169], [169, 170]]}
{"doc_key": "ai-test-377", "ner": [[8, 10, "person"], [12, 12, "organisation"], [18, 19, "person"], [21, 27, "person"], [28, 29, "person"], [31, 32, "person"], [34, 35, "person"], [37, 38, "person"], [40, 41, "person"], [43, 44, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[8, 10, 12, 12, "role", "works_for", false, false], [18, 19, 12, 12, "role", "works_for", false, false], [21, 27, 12, 12, "role", "works_for", false, false], [28, 29, 12, 12, "role", "works_for", false, false], [31, 32, 12, 12, "role", "works_for", false, false], [34, 35, 12, 12, "role", "works_for", false, false], [37, 38, 12, 12, "role", "works_for", false, false], [40, 41, 12, 12, "role", "works_for", false, false], [43, 44, 12, 12, "role", "works_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "film", ",", "which", "was", "an", "adaptation", "of", "Cole", "Porter", "'s", "popular", "Broadway", "musical", ",", "starred", "MGM", "singers", "Howard", "Keel", "and", "Kathryn", "Grayson", ",", "who", "were", "seconded", "by", "Ann", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Van", ",", "James", "Whitmore", ",", "Kurt", "Kasznar", "and", "Tommy", "Rall", "."], "sentence-detokenized": "The film, which was an adaptation of Cole Porter's popular Broadway musical, starred MGM singers Howard Keel and Kathryn Grayson, who were seconded by Ann Miller, Keenan Wynn, Bobby Van, James Whitmore, Kurt Kasznar and Tommy Rall.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 15], [16, 19], [20, 22], [23, 33], [34, 36], [37, 41], [42, 48], [48, 50], [51, 58], [59, 67], [68, 75], [75, 76], [77, 84], [85, 88], [89, 96], [97, 103], [104, 108], [109, 112], [113, 120], [121, 128], [128, 129], [130, 133], [134, 138], [139, 147], [148, 150], [151, 154], [155, 161], [161, 162], [163, 169], [170, 174], [174, 175], [176, 181], [182, 185], [185, 186], [187, 192], [193, 201], [201, 202], [203, 207], [208, 215], [216, 219], [220, 225], [226, 230], [230, 231]]}
{"doc_key": "ai-test-378", "ner": [[18, 23, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "applications", "should", "streamline", "call", "flow", ",", "minimize", "prompts", ",", "eliminate", "unnecessary", "repetition", ",", "and", "enable", "a", "sophisticated", "system", "of", "mixed", "dialogue", "initiatives", "that", "allow", "callers", "to", "enter", "multiple", "pieces", "of", "information", "in", "a", "single", "utterance", "and", "in", "any", "order", "or", "combination", "."], "sentence-detokenized": "Such applications should streamline call flow, minimize prompts, eliminate unnecessary repetition, and enable a sophisticated system of mixed dialogue initiatives that allow callers to enter multiple pieces of information in a single utterance and in any order or combination.", "token2charspan": [[0, 4], [5, 17], [18, 24], [25, 35], [36, 40], [41, 45], [45, 46], [47, 55], [56, 63], [63, 64], [65, 74], [75, 86], [87, 97], [97, 98], [99, 102], [103, 109], [110, 111], [112, 125], [126, 132], [133, 135], [136, 141], [142, 150], [151, 162], [163, 167], [168, 173], [174, 181], [182, 184], [185, 190], [191, 199], [200, 206], [207, 209], [210, 221], [222, 224], [225, 226], [227, 233], [234, 243], [244, 247], [248, 250], [251, 254], [255, 260], [261, 263], [264, 275], [275, 276]]}
{"doc_key": "ai-test-379", "ner": [[4, 5, "algorithm"], [8, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 17, 4, 5, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "such", ",", "traditional", "gradient", "descent", "(", "or", "stochastic", "gradient", "descent", ")", "methods", "can", "be", "adapted", ",", "where", "instead", "of", "taking", "a", "step", "in", "the", "direction", "of", "the", "gradient", "of", "the", "function", ",", "a", "step", "is", "taken", "in", "the", "direction", "of", "a", "vector", "selected", "from", "the", "subgradient", "of", "the", "function", "."], "sentence-detokenized": "As such, traditional gradient descent (or stochastic gradient descent) methods can be adapted, where instead of taking a step in the direction of the gradient of the function, a step is taken in the direction of a vector selected from the subgradient of the function.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 29], [30, 37], [38, 39], [39, 41], [42, 52], [53, 61], [62, 69], [69, 70], [71, 78], [79, 82], [83, 85], [86, 93], [93, 94], [95, 100], [101, 108], [109, 111], [112, 118], [119, 120], [121, 125], [126, 128], [129, 132], [133, 142], [143, 145], [146, 149], [150, 158], [159, 161], [162, 165], [166, 174], [174, 175], [176, 177], [178, 182], [183, 185], [186, 191], [192, 194], [195, 198], [199, 208], [209, 211], [212, 213], [214, 220], [221, 229], [230, 234], [235, 238], [239, 250], [251, 253], [254, 257], [258, 266], [266, 267]]}
{"doc_key": "ai-test-380", "ner": [[11, 14, "metrics"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "it", "is", "assumed", "that", "the", "distortion", "is", "measured", "using", "the", "root", "mean", "square", "error", ",", "the", "distortion", "D", "is", "given", ":"], "sentence-detokenized": "If it is assumed that the distortion is measured using the root mean square error, the distortion D is given:", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 16], [17, 21], [22, 25], [26, 36], [37, 39], [40, 48], [49, 54], [55, 58], [59, 63], [64, 68], [69, 75], [76, 81], [81, 82], [83, 86], [87, 97], [98, 99], [100, 102], [103, 108], [108, 109]]}
{"doc_key": "ai-test-381", "ner": [[0, 0, "algorithm"], [4, 11, "field"], [19, 20, "task"], [22, 23, "task"], [25, 27, "task"], [29, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 4, 11, "part-of", "", false, false], [19, 20, 0, 0, "part-of", "", false, false], [22, 23, 0, 0, "part-of", "", false, false], [25, 27, 0, 0, "part-of", "", false, false], [29, 30, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["MLPs", "were", "a", "popular", "machine", "learning", "solution", "in", "the", "1980s", ",", "which", "found", "applications", "in", "various", "fields", "such", "as", "speech", "recognition", ",", "image", "recognition", "and", "machine", "translation", "software", ",", "neural", "networks", "."], "sentence-detokenized": "MLPs were a popular machine learning solution in the 1980s, which found applications in various fields such as speech recognition, image recognition and machine translation software, neural networks.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 19], [20, 27], [28, 36], [37, 45], [46, 48], [49, 52], [53, 58], [58, 59], [60, 65], [66, 71], [72, 84], [85, 87], [88, 95], [96, 102], [103, 107], [108, 110], [111, 117], [118, 129], [129, 130], [131, 136], [137, 148], [149, 152], [153, 160], [161, 172], [173, 181], [181, 182], [183, 189], [190, 198], [198, 199]]}
{"doc_key": "ai-test-382", "ner": [[0, 0, "researcher"], [3, 3, "misc"], [6, 10, "university"], [15, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 10, "physical", "", false, false], [0, 0, 6, 10, "role", "", false, false], [3, 3, 0, 0, "origin", "", false, false], [15, 17, 0, 0, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "received", "his", "Ph.D.", "from", "the", "University", "of", "Toronto", "in", "1979", "under", "the", "direction", "of", "C.", "Raymond", "Perrault", ","], "sentence-detokenized": "Allen received his Ph.D. from the University of Toronto in 1979 under the direction of C. Raymond Perrault,", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 24], [25, 29], [30, 33], [34, 44], [45, 47], [48, 55], [56, 58], [59, 63], [64, 69], [70, 73], [74, 83], [84, 86], [87, 89], [90, 97], [98, 106], [106, 107]]}
{"doc_key": "ai-test-383", "ner": [[0, 0, "product"], [5, 9, "field"], [10, 10, "product"], [12, 12, "product"], [14, 14, "product"], [20, 21, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 5, 9, "related-to", "supports", false, false], [10, 10, 5, 9, "type-of", "", true, false], [12, 12, 5, 9, "type-of", "", true, false], [14, 14, 5, 9, "type-of", "", true, false], [14, 14, 20, 21, "related-to", "converting_to", true, false], [24, 24, 5, 9, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["OpenCV", "supports", "some", "models", "from", "deep", "learning", "frameworks", "such", "as", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "after", "conversion", "to", "the", "ONNX", "model", ")", "and", "Caffe", "according", "to", "a", "defined", "list", "of", "supported", "layers", "."], "sentence-detokenized": "OpenCV supports some models from deep learning frameworks such as TensorFlow, Torch, PyTorch (after conversion to the ONNX model) and Caffe according to a defined list of supported layers.", "token2charspan": [[0, 6], [7, 15], [16, 20], [21, 27], [28, 32], [33, 37], [38, 46], [47, 57], [58, 62], [63, 65], [66, 76], [76, 77], [78, 83], [83, 84], [85, 92], [93, 94], [94, 99], [100, 110], [111, 113], [114, 117], [118, 122], [123, 128], [128, 129], [130, 133], [134, 139], [140, 149], [150, 152], [153, 154], [155, 162], [163, 167], [168, 170], [171, 180], [181, 187], [187, 188]]}
{"doc_key": "ai-test-384", "ner": [[2, 2, "researcher"], [9, 12, "organisation"], [14, 17, "organisation"], [24, 28, "organisation"], [21, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 9, 12, "role", "", false, false], [2, 2, 24, 28, "role", "", false, false], [2, 2, 21, 23, "related-to", "lectures_in", false, false], [14, 17, 9, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Previously", ",", "Christensen", "was", "the", "founding", "chair", "of", "the", "European", "Robotics", "Research", "Network", "(", "EURON", ")", "and", "a", "Distinguished", "Lecturer", "in", "Robotics", "for", "the", "IEEE", "Robotics", "and", "Automation", "Society", "."], "sentence-detokenized": "Previously, Christensen was the founding chair of the European Robotics Research Network (EURON) and a Distinguished Lecturer in Robotics for the IEEE Robotics and Automation Society.", "token2charspan": [[0, 10], [10, 11], [12, 23], [24, 27], [28, 31], [32, 40], [41, 46], [47, 49], [50, 53], [54, 62], [63, 71], [72, 80], [81, 88], [89, 90], [90, 95], [95, 96], [97, 100], [101, 102], [103, 116], [117, 125], [126, 128], [129, 137], [138, 141], [142, 145], [146, 150], [151, 159], [160, 163], [164, 174], [175, 182], [182, 183]]}
{"doc_key": "ai-test-385", "ner": [[7, 7, "field"], [9, 11, "university"], [13, 13, "location"], [15, 23, "country"], [24, 24, "misc"], [26, 27, "field"], [29, 32, "organisation"], [34, 36, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[9, 11, 13, 13, "physical", "", false, false], [13, 13, 15, 23, "physical", "", false, false], [24, 24, 26, 27, "topic", "", false, false], [29, 32, 34, 36, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "received", "a", "master", "'s", "degree", "in", "mathematics", "from", "Samarkand", "State", "University", "in", "Samarkand", ",", "Uzbek", "Soviet", "Socialist", "Republic", ",", "in", "1958", "and", "a", "doctorate", "in", "statistics", "from", "the", "Institute", "of", "Management", "Sciences", "in", "Moscow", "in", "1964", "."], "sentence-detokenized": "He received a master's degree in mathematics from Samarkand State University in Samarkand, Uzbek Soviet Socialist Republic, in 1958 and a doctorate in statistics from the Institute of Management Sciences in Moscow in 1964.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 20], [20, 22], [23, 29], [30, 32], [33, 44], [45, 49], [50, 59], [60, 65], [66, 76], [77, 79], [80, 89], [89, 90], [91, 96], [97, 103], [104, 113], [114, 122], [122, 123], [124, 126], [127, 131], [132, 135], [136, 137], [138, 147], [148, 150], [151, 161], [162, 166], [167, 170], [171, 180], [181, 183], [184, 194], [195, 203], [204, 206], [207, 213], [214, 216], [217, 221], [221, 222]]}
{"doc_key": "ai-test-386", "ner": [[4, 4, "organisation"], [10, 15, "product"], [33, 34, "field"], [36, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 33, 34, "usage", "", false, false], [4, 4, 36, 38, "usage", "", false, false], [10, 15, 4, 4, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Increasingly", ",", "however", ",", "Cycorp", "is", "working", "to", "ensure", "that", "the", "Cyc", "system", "is", "able", "to", "communicate", "with", "end", "users", "in", "natural", "language", "and", "assist", "in", "the", "ongoing", "process", "of", "knowledge", "creation", "through", "machine", "learning", "and", "natural", "language", "understanding", "."], "sentence-detokenized": "Increasingly, however, Cycorp is working to ensure that the Cyc system is able to communicate with end users in natural language and assist in the ongoing process of knowledge creation through machine learning and natural language understanding.", "token2charspan": [[0, 12], [12, 13], [14, 21], [21, 22], [23, 29], [30, 32], [33, 40], [41, 43], [44, 50], [51, 55], [56, 59], [60, 63], [64, 70], [71, 73], [74, 78], [79, 81], [82, 93], [94, 98], [99, 102], [103, 108], [109, 111], [112, 119], [120, 128], [129, 132], [133, 139], [140, 142], [143, 146], [147, 154], [155, 162], [163, 165], [166, 175], [176, 184], [185, 192], [193, 200], [201, 209], [210, 213], [214, 221], [222, 230], [231, 244], [244, 245]]}
{"doc_key": "ai-test-387", "ner": [[55, 55, "metrics"], [57, 57, "metrics"], [59, 59, "metrics"], [61, 64, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "when", "looking", "for", "the", "most", "appropriate", "classifier", "for", "a", "given", "problem", ",", "the", "training", "dataset", "is", "used", "to", "train", "candidate", "algorithms", ",", "the", "validation", "dataset", "is", "used", "to", "compare", "their", "performance", "and", "decide", "which", "one", "to", "use", ",", "and", "finally", ",", "the", "testing", "dataset", "is", "used", "to", "obtain", "performance", "characteristics", "such", "as", "accuracy", ",", "sensitivity", ",", "specificity", ",", "F-", "measure", ",", "etc", "."], "sentence-detokenized": "For example, when looking for the most appropriate classifier for a given problem, the training dataset is used to train candidate algorithms, the validation dataset is used to compare their performance and decide which one to use, and finally, the testing dataset is used to obtain performance characteristics such as accuracy, sensitivity, specificity, F-measure, etc.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [18, 25], [26, 29], [30, 33], [34, 38], [39, 50], [51, 61], [62, 65], [66, 67], [68, 73], [74, 81], [81, 82], [83, 86], [87, 95], [96, 103], [104, 106], [107, 111], [112, 114], [115, 120], [121, 130], [131, 141], [141, 142], [143, 146], [147, 157], [158, 165], [166, 168], [169, 173], [174, 176], [177, 184], [185, 190], [191, 202], [203, 206], [207, 213], [214, 219], [220, 223], [224, 226], [227, 230], [230, 231], [232, 235], [236, 243], [243, 244], [245, 248], [249, 256], [257, 264], [265, 267], [268, 272], [273, 275], [276, 282], [283, 294], [295, 310], [311, 315], [316, 318], [319, 327], [327, 328], [329, 340], [340, 341], [342, 353], [353, 354], [355, 357], [357, 364], [364, 365], [366, 369], [369, 370]]}
{"doc_key": "ai-test-388", "ner": [[0, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "root", "mean", "square", "error", "is", "0.15", "."], "sentence-detokenized": "The root mean square error is 0.15.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 20], [21, 26], [27, 29], [30, 34], [34, 35]]}
{"doc_key": "ai-test-389", "ner": [[7, 8, "misc"], [4, 4, "organisation"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 7, 8, "role", "", false, false], [13, 14, 7, 8, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1979", ",", "the", "IEEE", "held", "a", "Micromouse", "competition", ",", "as", "reported", "in", "Spectrum", "magazine", "."], "sentence-detokenized": "In 1979, the IEEE held a Micromouse competition, as reported in Spectrum magazine.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 22], [23, 24], [25, 35], [36, 47], [47, 48], [49, 51], [52, 60], [61, 63], [64, 72], [73, 81], [81, 82]]}
{"doc_key": "ai-test-390", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [11, 13, "task"], [15, 19, "task"], [18, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 6, 7, "part-of", "", false, false], [11, 13, 6, 7, "part-of", "task_part_of_field", false, false], [15, 19, 6, 7, "part-of", "task_part_of_field", false, false], [18, 18, 6, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Gabor", "space", "is", "very", "useful", "in", "image", "processing", "applications", "such", "as", "optical", "character", "recognition", ",", "iris", "recognition", "and", "fingerprint", "recognition", "."], "sentence-detokenized": "Gabor space is very useful in image processing applications such as optical character recognition, iris recognition and fingerprint recognition.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 19], [20, 26], [27, 29], [30, 35], [36, 46], [47, 59], [60, 64], [65, 67], [68, 75], [76, 85], [86, 97], [97, 98], [99, 103], [104, 115], [116, 119], [120, 131], [132, 143], [143, 144]]}
{"doc_key": "ai-test-391", "ner": [[7, 7, "programlang"], [9, 9, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", "via", "the", "high", "level", "interfaces", "for", "Java", "and", "Tcl", "."], "sentence-detokenized": "or via the high level interfaces for Java and Tcl.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 15], [16, 21], [22, 32], [33, 36], [37, 41], [42, 45], [46, 49], [49, 50]]}
{"doc_key": "ai-test-392", "ner": [[10, 13, "algorithm"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 13, 22, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "recent", "research", ",", "kernel", "-", "based", "methods", "such", "as", "support", "vector", "machines", "have", "been", "shown", "to", "have", "excellent", "performance", "in", "a", "controlled", "process", "."], "sentence-detokenized": "In recent research, kernel-based methods such as support vector machines have been shown to have excellent performance in a controlled process.", "token2charspan": [[0, 2], [3, 9], [10, 18], [18, 19], [20, 26], [26, 27], [27, 32], [33, 40], [41, 45], [46, 48], [49, 56], [57, 63], [64, 72], [73, 77], [78, 82], [83, 88], [89, 91], [92, 96], [97, 106], [107, 118], [119, 121], [122, 123], [124, 134], [135, 142], [142, 143]]}
{"doc_key": "ai-test-393", "ner": [[6, 6, "misc"], [12, 12, "researcher"], [14, 14, "researcher"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 12, 22, 22, "usage", "", false, false], [14, 14, 22, 22, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "analysis", "of", "the", "relationship", "between", "ozone", "and", "temperature", "(", "data", "from", "Rousseeuw", "and", "Leroy", "(", "1986", ")", ",", "analysis", "performed", "in", "R", ")", "is", "presented", "to", "illustrate", "the", "basic", "principles", "of", "bagging", "."], "sentence-detokenized": "An analysis of the relationship between ozone and temperature (data from Rousseeuw and Leroy (1986), analysis performed in R) is presented to illustrate the basic principles of bagging.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 31], [32, 39], [40, 45], [46, 49], [50, 61], [62, 63], [63, 67], [68, 72], [73, 82], [83, 86], [87, 92], [93, 94], [94, 98], [98, 99], [99, 100], [101, 109], [110, 119], [120, 122], [123, 124], [124, 125], [126, 128], [129, 138], [139, 141], [142, 152], [153, 156], [157, 162], [163, 173], [174, 176], [177, 184], [184, 185]]}
{"doc_key": "ai-test-394", "ner": [[0, 1, "organisation"], [11, 11, "product"], [18, 19, "product"], [21, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 0, 1, "artifact", "", false, false], [18, 19, 0, 1, "artifact", "", false, false], [21, 23, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Denso", "Wave", "is", "a", "subsidiary", "that", "manufactures", "automatic", "identification", "products", "(", "barcode", "scanners", "and", "related", "products", ")", ",", "industrial", "robots", "and", "programmable", "logic", "controllers", "."], "sentence-detokenized": "Denso Wave is a subsidiary that manufactures automatic identification products (barcode scanners and related products), industrial robots and programmable logic controllers.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 15], [16, 26], [27, 31], [32, 44], [45, 54], [55, 69], [70, 78], [79, 80], [80, 87], [88, 96], [97, 100], [101, 108], [109, 117], [117, 118], [118, 119], [120, 130], [131, 137], [138, 141], [142, 154], [155, 160], [161, 172], [172, 173]]}
{"doc_key": "ai-test-395", "ner": [[2, 4, "metrics"], [8, 9, "metrics"], [19, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 4, 19, 20, "compare", "", false, false], [8, 9, 2, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Where", "a", "bilingual", "evaluation", "study", "simply", "calculates", "the", "accuracy", "of", "the", "n-grams", "and", "gives", "equal", "weight", "to", "each", ",", "NIST", "also", "calculates", "how", "informative", "a", "particular", "n-", "gram", "is", "."], "sentence-detokenized": "Where a bilingual evaluation study simply calculates the accuracy of the n-grams and gives equal weight to each, NIST also calculates how informative a particular n-gram is.", "token2charspan": [[0, 5], [6, 7], [8, 17], [18, 28], [29, 34], [35, 41], [42, 52], [53, 56], [57, 65], [66, 68], [69, 72], [73, 80], [81, 84], [85, 90], [91, 96], [97, 103], [104, 106], [107, 111], [111, 112], [113, 117], [118, 122], [123, 133], [134, 137], [138, 149], [150, 151], [152, 162], [163, 165], [165, 169], [170, 172], [172, 173]]}
{"doc_key": "ai-test-396", "ner": [[10, 10, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "are", "mainly", "used", "in", "tree", "likelihood", "calculations", "(", "in", "Bayesian", "and", "maximum", "likelihood", "approaches", "to", "tree", "estimation", ")", "and", "are", "used", "to", "estimate", "the", "evolutionary", "distance", "between", "sequences", "based", "on", "observed", "differences", "between", "sequences", "."], "sentence-detokenized": "They are mainly used in tree likelihood calculations (in Bayesian and maximum likelihood approaches to tree estimation) and are used to estimate the evolutionary distance between sequences based on observed differences between sequences.", "token2charspan": [[0, 4], [5, 8], [9, 15], [16, 20], [21, 23], [24, 28], [29, 39], [40, 52], [53, 54], [54, 56], [57, 65], [66, 69], [70, 77], [78, 88], [89, 99], [100, 102], [103, 107], [108, 118], [118, 119], [120, 123], [124, 127], [128, 132], [133, 135], [136, 144], [145, 148], [149, 161], [162, 170], [171, 178], [179, 188], [189, 194], [195, 197], [198, 206], [207, 218], [219, 226], [227, 236], [236, 237]]}
{"doc_key": "ai-test-397", "ner": [[0, 3, "conference"], [20, 21, "misc"], [23, 23, "misc"], [46, 47, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 20, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Audio", "Engineering", "Society", "recommends", "a", "sampling", "rate", "of", "48", "kHz", "for", "most", "applications", ",", "but", "recognizes", "44.1", "kHz", "for", "compact", "disc", "(", "CD", ")", "and", "other", "consumer", "use", ",", "32", "kHz", "for", "transmission", "-", "related", "applications", ",", "and", "96", "kHz", "for", "higher", "bandwidth", "or", "relaxed", "anti-aliasing", "filter", "ing", "."], "sentence-detokenized": "The Audio Engineering Society recommends a sampling rate of 48 kHz for most applications, but recognizes 44.1 kHz for compact disc (CD) and other consumer use, 32 kHz for transmission-related applications, and 96 kHz for higher bandwidth or relaxed anti-aliasing filter ing.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 29], [30, 40], [41, 42], [43, 51], [52, 56], [57, 59], [60, 62], [63, 66], [67, 70], [71, 75], [76, 88], [88, 89], [90, 93], [94, 104], [105, 109], [110, 113], [114, 117], [118, 125], [126, 130], [131, 132], [132, 134], [134, 135], [136, 139], [140, 145], [146, 154], [155, 158], [158, 159], [160, 162], [163, 166], [167, 170], [171, 183], [183, 184], [184, 191], [192, 204], [204, 205], [206, 209], [210, 212], [213, 216], [217, 220], [221, 227], [228, 237], [238, 240], [241, 248], [249, 262], [263, 269], [270, 273], [273, 274]]}
{"doc_key": "ai-test-398", "ner": [[9, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sources", "for", "affective", "words", "and", "concepts", "were", "created", "for", "WordNet", "{", "{", "cite", "journal"], "sentence-detokenized": "Sources for affective words and concepts were created for WordNet {{cite journal", "token2charspan": [[0, 7], [8, 11], [12, 21], [22, 27], [28, 31], [32, 40], [41, 45], [46, 53], [54, 57], [58, 65], [66, 67], [67, 68], [68, 72], [73, 80]]}
{"doc_key": "ai-test-399", "ner": [[2, 5, "misc"], [23, 24, "person"], [29, 32, "person"], [37, 39, "person"], [45, 51, "organisation"], [68, 69, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[29, 32, 37, 39, "role", "acts_in", false, false], [45, 51, 37, 39, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "a", "red", "and", "green", "anaglyph", ",", "viewers", "were", "presented", "with", "three", "reels", "of", "tests", "that", "included", "rural", "scenes", ",", "test", "footage", "of", "Marie", "Doro", ",", "a", "segment", "of", "John", "B", ".", "Mason", "playing", "several", "passages", "from", "Jim", "the", "Penman", "(", "a", "film", "released", "by", "Famous", "Players", "-", "Lasky", "the", "same", "year", ",", "but", "not", "in", "3D", ")", ",", "oriental", "dancers", ",", "and", "a", "reel", "of", "footage", "of", "Niagara", "Falls", "."], "sentence-detokenized": "In a red and green anaglyph, viewers were presented with three reels of tests that included rural scenes, test footage of Marie Doro, a segment of John B. Mason playing several passages from Jim the Penman (a film released by Famous Players-Lasky the same year, but not in 3D), oriental dancers, and a reel of footage of Niagara Falls.", "token2charspan": [[0, 2], [3, 4], [5, 8], [9, 12], [13, 18], [19, 27], [27, 28], [29, 36], [37, 41], [42, 51], [52, 56], [57, 62], [63, 68], [69, 71], [72, 77], [78, 82], [83, 91], [92, 97], [98, 104], [104, 105], [106, 110], [111, 118], [119, 121], [122, 127], [128, 132], [132, 133], [134, 135], [136, 143], [144, 146], [147, 151], [152, 153], [153, 154], [155, 160], [161, 168], [169, 176], [177, 185], [186, 190], [191, 194], [195, 198], [199, 205], [206, 207], [207, 208], [209, 213], [214, 222], [223, 225], [226, 232], [233, 240], [240, 241], [241, 246], [247, 250], [251, 255], [256, 260], [260, 261], [262, 265], [266, 269], [270, 272], [273, 275], [275, 276], [276, 277], [278, 286], [287, 294], [294, 295], [296, 299], [300, 301], [302, 306], [307, 309], [310, 317], [318, 320], [321, 328], [329, 334], [334, 335]]}
{"doc_key": "ai-test-400", "ner": [[7, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "special", "way", "of", "implementing", "maximum", "likelihood", "estimation", "for", "this", "problem", "."], "sentence-detokenized": "This is a special way of implementing maximum likelihood estimation for this problem.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 17], [18, 21], [22, 24], [25, 37], [38, 45], [46, 56], [57, 67], [68, 71], [72, 76], [77, 84], [84, 85]]}
{"doc_key": "ai-test-401", "ner": [[0, 6, "product"], [11, 11, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Web", "servers", "suitable", "for", "crawlers", ",", "and", "integrates", "site", "map", "and", "RSS", "feed", "features", "into", "a", "decentralized", "mechanism", "for", "computational", "biologists", "and", "bioinformaticians", "to", "openly", "broadcast", "and", "retrieve", "metadata", "about", "biomedical", "resources", "."], "sentence-detokenized": "Web servers suitable for crawlers, and integrates site map and RSS feed features into a decentralized mechanism for computational biologists and bioinformaticians to openly broadcast and retrieve metadata about biomedical resources.", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 24], [25, 33], [33, 34], [35, 38], [39, 49], [50, 54], [55, 58], [59, 62], [63, 66], [67, 71], [72, 80], [81, 85], [86, 87], [88, 101], [102, 111], [112, 115], [116, 129], [130, 140], [141, 144], [145, 162], [163, 165], [166, 172], [173, 182], [183, 186], [187, 195], [196, 204], [205, 210], [211, 221], [222, 231], [231, 232]]}
{"doc_key": "ai-test-402", "ner": [[5, 12, "misc"], [15, 20, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "covered", "by", "the", "American", "National", "Standards", "Institute", "/", "NISO", "standard", "Z39.50", "and", "the", "International", "Organization", "for", "Standardization", "standard", "23950", "."], "sentence-detokenized": "It is covered by the American National Standards Institute/NISO standard Z39.50 and the International Organization for Standardization standard 23950.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 20], [21, 29], [30, 38], [39, 48], [49, 58], [58, 59], [59, 63], [64, 72], [73, 79], [80, 83], [84, 87], [88, 101], [102, 114], [115, 118], [119, 134], [135, 143], [144, 149], [149, 150]]}
{"doc_key": "ai-test-403", "ner": [[13, 17, "misc"], [23, 23, "metrics"], [26, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "encoder", "and", "decoder", "are", "trained", "to", "take", "a", "phrase", "and", "reproduce", "the", "single", "-", "phase", "distribution", "of", "the", "corresponding", "paraphrase", "by", "minimizing", "perplexity", "using", "simple", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The encoder and decoder are trained to take a phrase and reproduce the single-phase distribution of the corresponding paraphrase by minimizing perplexity using simple stochastic gradient descent.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 27], [28, 35], [36, 38], [39, 43], [44, 45], [46, 52], [53, 56], [57, 66], [67, 70], [71, 77], [77, 78], [78, 83], [84, 96], [97, 99], [100, 103], [104, 117], [118, 128], [129, 131], [132, 142], [143, 153], [154, 159], [160, 166], [167, 177], [178, 186], [187, 194], [194, 195]]}
{"doc_key": "ai-test-404", "ner": [[4, 5, "field"], [8, 10, "task"], [12, 17, "task"], [29, 33, "task"], [35, 41, "task"], [44, 49, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 10, 4, 5, "part-of", "task_part_of_field", false, false], [12, 17, 4, 5, "part-of", "task_part_of_field", false, false], [29, 33, 4, 5, "part-of", "task_part_of_field", false, false], [35, 41, 4, 5, "part-of", "task_part_of_field", false, false], [44, 49, 4, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "typical", "applications", "of", "pattern", "recognition", "techniques", "are", "automatic", "speech", "recognition", ",", "classification", "of", "text", "into", "several", "categories", "(", "e.g.", ",", "spam", "/", "non", "-spam", "email", "messages", ")", ",", "handwriting", "recognition", "on", "mail", "envelopes", ",", "automatic", "recognition", "of", "images", "of", "human", "faces", ",", "or", "handwriting", "image", "extraction", "from", "medical", "forms", "."], "sentence-detokenized": "Other typical applications of pattern recognition techniques are automatic speech recognition, classification of text into several categories (e.g., spam/non-spam email messages), handwriting recognition on mail envelopes, automatic recognition of images of human faces, or handwriting image extraction from medical forms.", "token2charspan": [[0, 5], [6, 13], [14, 26], [27, 29], [30, 37], [38, 49], [50, 60], [61, 64], [65, 74], [75, 81], [82, 93], [93, 94], [95, 109], [110, 112], [113, 117], [118, 122], [123, 130], [131, 141], [142, 143], [143, 147], [147, 148], [149, 153], [153, 154], [154, 157], [157, 162], [163, 168], [169, 177], [177, 178], [178, 179], [180, 191], [192, 203], [204, 206], [207, 211], [212, 221], [221, 222], [223, 232], [233, 244], [245, 247], [248, 254], [255, 257], [258, 263], [264, 269], [269, 270], [271, 273], [274, 285], [286, 291], [292, 302], [303, 307], [308, 315], [316, 321], [321, 322]]}
{"doc_key": "ai-test-405", "ner": [[0, 6, "algorithm"], [11, 12, "field"], [14, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 28, "task"], [31, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 12, 0, 6, "usage", "", false, false], [14, 15, 0, 6, "usage", "", false, false], [17, 18, 0, 6, "usage", "", false, false], [20, 22, 0, 6, "usage", "", false, false], [24, 28, 0, 6, "usage", "", false, false], [31, 32, 0, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Artificial", "neural", "networks", "are", "used", "for", "a", "variety", "of", "tasks", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "tabletop", "and", "video", "game", "playing", ",", "and", "medical", "diagnostics", "."], "sentence-detokenized": "Artificial neural networks are used for a variety of tasks including computer vision, speech recognition, machine translation, social network filtering, tabletop and video game playing, and medical diagnostics.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 30], [31, 35], [36, 39], [40, 41], [42, 49], [50, 52], [53, 58], [59, 68], [69, 77], [78, 84], [84, 85], [86, 92], [93, 104], [104, 105], [106, 113], [114, 125], [125, 126], [127, 133], [134, 141], [142, 151], [151, 152], [153, 161], [162, 165], [166, 171], [172, 176], [177, 184], [184, 185], [186, 189], [190, 197], [198, 209], [209, 210]]}
{"doc_key": "ai-test-406", "ner": [[2, 3, "organisation"], [4, 4, "product"], [14, 15, "product"], [18, 18, "organisation"], [19, 20, "product"], [22, 22, "product"], [24, 26, "product"], [28, 28, "product"], [30, 30, "programlang"], [39, 41, "field"], [44, 44, "product"], [50, 50, "algorithm"], [52, 52, "algorithm"], [55, 55, "algorithm"], [59, 59, "product"], [69, 69, "task"], [73, 75, "algorithm"], [78, 78, "product"], [80, 80, "product"], [83, 85, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "relations": [[4, 4, 2, 3, "origin", "", false, false], [4, 4, 14, 15, "named", "same", false, false], [4, 4, 44, 44, "named", "same", false, false], [30, 30, 39, 41, "related-to", "used_for", false, false], [50, 50, 30, 30, "part-of", "", true, false], [50, 50, 44, 44, "origin", "", true, false], [52, 52, 30, 30, "part-of", "", true, false], [52, 52, 44, 44, "origin", "", true, false], [55, 55, 30, 30, "part-of", "", true, false], [55, 55, 44, 44, "origin", "", true, false], [59, 59, 69, 69, "related-to", "used_for", false, false], [73, 75, 59, 59, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Examples", "are", "Salford", "Systems", "CART", "(", "which", "licenses", "the", "proprietary", "code", "of", "the", "original", "CART", "authors", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "an", "open", "-", "source", "software", "environment", "for", "statistical", "computing", "that", "includes", "several", "CART", "implementations", ",", "such", "as", "the", "rpart", ",", "party", ",", "and", "randomForest", "packages", ")", ",", "Weka", "(", "a", "free", "and", "open", "-", "source", "package", "for", "data-mining", ",", "includes", "many", "decision", "tree", "algorithms", ")", ",", "Orange", ",", "KNIME", ",", "a", "Microsoft", "SQL", "Server", "programming", "language", ")", "."], "sentence-detokenized": "Examples are Salford Systems CART (which licenses the proprietary code of the original CART authors), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (an open-source software environment for statistical computing that includes several CART implementations, such as the rpart, party, and randomForest packages), Weka (a free and open-source package for data-mining, includes many decision tree algorithms), Orange, KNIME, a Microsoft SQL Server programming language).", "token2charspan": [[0, 8], [9, 12], [13, 20], [21, 28], [29, 33], [34, 35], [35, 40], [41, 49], [50, 53], [54, 65], [66, 70], [71, 73], [74, 77], [78, 86], [87, 91], [92, 99], [99, 100], [100, 101], [102, 105], [106, 110], [111, 118], [118, 119], [120, 130], [130, 131], [132, 135], [136, 146], [147, 152], [152, 153], [154, 160], [160, 161], [162, 163], [164, 165], [165, 167], [168, 172], [172, 173], [173, 179], [180, 188], [189, 200], [201, 204], [205, 216], [217, 226], [227, 231], [232, 240], [241, 248], [249, 253], [254, 269], [269, 270], [271, 275], [276, 278], [279, 282], [283, 288], [288, 289], [290, 295], [295, 296], [297, 300], [301, 313], [314, 322], [322, 323], [323, 324], [325, 329], [330, 331], [331, 332], [333, 337], [338, 341], [342, 346], [346, 347], [347, 353], [354, 361], [362, 365], [366, 377], [377, 378], [379, 387], [388, 392], [393, 401], [402, 406], [407, 417], [417, 418], [418, 419], [420, 426], [426, 427], [428, 433], [433, 434], [435, 436], [437, 446], [447, 450], [451, 457], [458, 469], [470, 478], [478, 479], [479, 480]]}
{"doc_key": "ai-test-407", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [10, 11, "researcher"], [13, 14, "university"], [16, 17, "researcher"], [19, 22, "organisation"], [24, 26, "organisation"], [33, 35, "researcher"], [37, 39, "researcher"], [41, 43, "organisation"], [55, 59, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 10, 11, "origin", "", false, false], [0, 2, 16, 17, "origin", "", false, false], [0, 2, 33, 35, "origin", "", false, false], [0, 2, 37, 39, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [10, 11, 13, 14, "physical", "", false, false], [10, 11, 13, 14, "role", "", false, false], [16, 17, 19, 22, "physical", "", false, false], [16, 17, 19, 22, "role", "", false, false], [24, 26, 19, 22, "named", "", false, false], [33, 35, 41, 43, "physical", "", false, false], [33, 35, 41, 43, "role", "", false, false], [37, 39, 41, 43, "physical", "", false, false], [37, 39, 41, 43, "role", "", false, false], [55, 59, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Linear", "Predictive", "Coding", "(", "LPC", ")", "was", "first", "developed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", "and", "then", "further", "developed", "by", "Bishnu", "S.", "Atal", "and", "Manfred", "R.", "Schroeder", "at", "Bell", "Labs", "in", "the", "early", "to", "mid-1970s", ",", "becoming", "the", "basis", "of", "the", "first", "DSP", "chips", "for", "speech", "synthesis", "in", "the", "late", "1970s", "."], "sentence-detokenized": "Linear Predictive Coding (LPC) was first developed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966 and then further developed by Bishnu S. Atal and Manfred R. Schroeder at Bell Labs in the early to mid-1970s, becoming the basis of the first DSP chips for speech synthesis in the late 1970s.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [31, 34], [35, 40], [41, 50], [51, 53], [54, 62], [63, 70], [71, 73], [74, 80], [81, 91], [92, 95], [96, 101], [102, 107], [108, 110], [111, 117], [118, 127], [128, 131], [132, 141], [142, 143], [143, 146], [146, 147], [148, 150], [151, 155], [156, 159], [160, 164], [165, 172], [173, 182], [183, 185], [186, 192], [193, 195], [196, 200], [201, 204], [205, 212], [213, 215], [216, 225], [226, 228], [229, 233], [234, 238], [239, 241], [242, 245], [246, 251], [252, 254], [255, 264], [264, 265], [266, 274], [275, 278], [279, 284], [285, 287], [288, 291], [292, 297], [298, 301], [302, 307], [308, 311], [312, 318], [319, 328], [329, 331], [332, 335], [336, 340], [341, 346], [346, 347]]}
{"doc_key": "ai-test-408", "ner": [[0, 3, "metrics"], [8, 8, "metrics"], [10, 14, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 0, 3, "part-of", "", false, false], [10, 14, 0, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "F", "-", "score", "is", "a", "combination", "of", "precision", "and", "recall", ",", "resulting", "in", "a", "single", "score", "."], "sentence-detokenized": "The F-score is a combination of precision and recall, resulting in a single score.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 16], [17, 28], [29, 31], [32, 41], [42, 45], [46, 52], [52, 53], [54, 63], [64, 66], [67, 68], [69, 75], [76, 81], [81, 82]]}
{"doc_key": "ai-test-409", "ner": [[0, 1, "field"], [8, 10, "task"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 0, 1, "part-of", "task_part_of_field", false, false], [15, 17, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Image", "analysis", "tasks", "can", "be", "as", "simple", "as", "reading", "barcodes", "or", "as", "sophisticated", "as", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Image analysis tasks can be as simple as reading barcodes or as sophisticated as a facial recognition system.", "token2charspan": [[0, 5], [6, 14], [15, 20], [21, 24], [25, 27], [28, 30], [31, 37], [38, 40], [41, 48], [49, 57], [58, 60], [61, 63], [64, 77], [78, 80], [81, 82], [83, 89], [90, 101], [102, 108], [108, 109]]}
{"doc_key": "ai-test-410", "ner": [[5, 8, "algorithm"], [27, 28, "algorithm"], [35, 37, "algorithm"], [41, 41, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[35, 37, 27, 28, "type-of", "", false, false], [41, 41, 35, 37, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "special", "case", "of", "linear", "support", "-", "vector", "machines", "can", "be", "more", "efficiently", "addressed", "by", "the", "same", "kind", "of", "algorithms", "to", "optimize", "it", "s", "close", "relative", ",", "logistic", "regression", ";", "this", "class", "of", "algorithms", "includes", "Stochastic", "Gradient", "Descent", "(", "e.g.", ",", "PEGASOS", ")", "."], "sentence-detokenized": "The special case of linear support-vector machines can be more efficiently addressed by the same kind of algorithms to optimize its close relative, logistic regression; this class of algorithms includes Stochastic Gradient Descent (e.g., PEGASOS).", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 19], [20, 26], [27, 34], [34, 35], [35, 41], [42, 50], [51, 54], [55, 57], [58, 62], [63, 74], [75, 84], [85, 87], [88, 91], [92, 96], [97, 101], [102, 104], [105, 115], [116, 118], [119, 127], [128, 130], [130, 131], [132, 137], [138, 146], [146, 147], [148, 156], [157, 167], [167, 168], [169, 173], [174, 179], [180, 182], [183, 193], [194, 202], [203, 213], [214, 222], [223, 230], [231, 232], [232, 236], [236, 237], [238, 245], [245, 246], [246, 247]]}
{"doc_key": "ai-test-411", "ner": [[1, 1, "product"], [4, 4, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 4, 4, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["When", "Siri", "on", "an", "iOS", "device", "asks", "Do", "you", "have", "a", "pet", "?", ",", "one", "of", "the", "answers", "is", "I", "used", "to", "have", "an", "AIBO", "."], "sentence-detokenized": "When Siri on an iOS device asks Do you have a pet?, one of the answers is I used to have an AIBO.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 15], [16, 19], [20, 26], [27, 31], [32, 34], [35, 38], [39, 43], [44, 45], [46, 49], [49, 50], [50, 51], [52, 55], [56, 58], [59, 62], [63, 70], [71, 73], [74, 75], [76, 80], [81, 83], [84, 88], [89, 91], [92, 96], [96, 97]]}
{"doc_key": "ai-test-412", "ner": [[1, 8, "task"], [5, 7, "metrics"], [10, 10, "metrics"], [12, 12, "metrics"], [15, 15, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 7, 1, 8, "part-of", "", false, false], [10, 10, 5, 7, "named", "", false, false], [12, 12, 1, 8, "part-of", "", false, false], [15, 15, 12, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "information", "retrieval", ",", "the", "positive", "predictive", "value", "is", "called", "accuracy", "and", "sensitivity", "is", "called", "recall", "."], "sentence-detokenized": "In information retrieval, the positive predictive value is called accuracy and sensitivity is called recall.", "token2charspan": [[0, 2], [3, 14], [15, 24], [24, 25], [26, 29], [30, 38], [39, 49], [50, 55], [56, 58], [59, 65], [66, 74], [75, 78], [79, 90], [91, 93], [94, 100], [101, 107], [107, 108]]}
{"doc_key": "ai-test-413", "ner": [[9, 10, "field"], [12, 12, "task"], [14, 14, "task"], [16, 17, "task"], [34, 35, "task"], [37, 38, "task"], [40, 43, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 12, 9, 10, "part-of", "task_part_of_field", false, false], [14, 14, 9, 10, "part-of", "task_part_of_field", false, false], [16, 17, 9, 10, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["His", "research", "has", "mainly", "focused", "on", "areas", "such", "as", "text", "mining", "(", "extraction", ",", "categorization", ",", "novelty", "detection", ")", "and", "on", "new", "theoretical", "frameworks", "such", "as", "unified", "utility", "-", "based", "theory", ",", "which", "combines", "information", "retrieval", ",", "automatic", "summarization", ",", "free", "text", "question", "answering", ",", "and", "related", "tasks", "."], "sentence-detokenized": "His research has mainly focused on areas such as text mining (extraction, categorization, novelty detection) and on new theoretical frameworks such as unified utility-based theory, which combines information retrieval, automatic summarization, free text question answering, and related tasks.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 23], [24, 31], [32, 34], [35, 40], [41, 45], [46, 48], [49, 53], [54, 60], [61, 62], [62, 72], [72, 73], [74, 88], [88, 89], [90, 97], [98, 107], [107, 108], [109, 112], [113, 115], [116, 119], [120, 131], [132, 142], [143, 147], [148, 150], [151, 158], [159, 166], [166, 167], [167, 172], [173, 179], [179, 180], [181, 186], [187, 195], [196, 207], [208, 217], [217, 218], [219, 228], [229, 242], [242, 243], [244, 248], [249, 253], [254, 262], [263, 272], [272, 273], [274, 277], [278, 285], [286, 291], [291, 292]]}
{"doc_key": "ai-test-414", "ner": [[0, 1, "product"], [6, 8, "product"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 8, 0, 1, "part-of", "", false, false], [14, 15, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Delta", "robots", "have", "base", "-", "mounted", "rotary", "actuators", "that", "move", "a", "lightweight", ",", "rigid", "parallelogram", "arm", "."], "sentence-detokenized": "Delta robots have base-mounted rotary actuators that move a lightweight, rigid parallelogram arm.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 22], [22, 23], [23, 30], [31, 37], [38, 47], [48, 52], [53, 57], [58, 59], [60, 71], [71, 72], [73, 78], [79, 92], [93, 96], [96, 97]]}
{"doc_key": "ai-test-415", "ner": [[8, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "into", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated into a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 39], [40, 41], [42, 43], [44, 45], [46, 47], [48, 59], [60, 65], [66, 68], [69, 78], [79, 85], [86, 88], [89, 96], [96, 97]]}
{"doc_key": "ai-test-416", "ner": [[4, 7, "field"], [30, 31, "task"], [37, 38, "task"], [44, 46, "task"], [48, 50, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[30, 31, 4, 7, "part-of", "task_part_of_field", false, false], [37, 38, 4, 7, "part-of", "task_part_of_field", false, false], [44, 46, 4, 7, "part-of", "task_part_of_field", false, false], [48, 50, 4, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "actual", "task", "of", "data", "mining", "is", "the", "semi-automatic", "or", "automatic", "analysis", "of", "large", "amounts", "of", "data", "to", "extract", "unknown", ",", "interesting", "patterns", "such", "as", "groups", "of", "data", "records", "(", "cluster", "analysis", ")", ",", "unusual", "records", "(", "anomaly", "detection", ")", ",", "and", "dependencies", "(", "association", "rule", "mining", ",", "sequential", "pattern", "mining", ")", "."], "sentence-detokenized": "The actual task of data mining is the semi-automatic or automatic analysis of large amounts of data to extract unknown, interesting patterns such as groups of data records (cluster analysis), unusual records (anomaly detection), and dependencies (association rule mining, sequential pattern mining).", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 18], [19, 23], [24, 30], [31, 33], [34, 37], [38, 52], [53, 55], [56, 65], [66, 74], [75, 77], [78, 83], [84, 91], [92, 94], [95, 99], [100, 102], [103, 110], [111, 118], [118, 119], [120, 131], [132, 140], [141, 145], [146, 148], [149, 155], [156, 158], [159, 163], [164, 171], [172, 173], [173, 180], [181, 189], [189, 190], [190, 191], [192, 199], [200, 207], [208, 209], [209, 216], [217, 226], [226, 227], [227, 228], [229, 232], [233, 245], [246, 247], [247, 258], [259, 263], [264, 270], [270, 271], [272, 282], [283, 290], [291, 297], [297, 298], [298, 299]]}
{"doc_key": "ai-test-417", "ner": [[2, 11, "product"], [5, 6, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 11, 5, 6, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "a", "recommender", "system", ",", "sentiment", "analysis", "has", "proven", "to", "be", "a", "valuable", "technique", "."], "sentence-detokenized": "For a recommender system, sentiment analysis has proven to be a valuable technique.", "token2charspan": [[0, 3], [4, 5], [6, 17], [18, 24], [24, 25], [26, 35], [36, 44], [45, 48], [49, 55], [56, 58], [59, 61], [62, 63], [64, 72], [73, 82], [82, 83]]}
{"doc_key": "ai-test-418", "ner": [[0, 1, "misc"], [9, 14, "product"], [26, 33, "organisation"], [34, 35, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 9, 14, "usage", "", false, false], [26, 33, 34, 35, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Germans", "accidentally", "chose", "the", "working", "frequency", "of", "the", "Wotan", "system", "very", "badly", ",", "operating", "at", "45", "MHz", ",", "which", "was", "precisely", "the", "frequency", "of", "the", "BBC", "'s", "powerful", "but", "non-functional", "television", "transmitter", "at", "Alexandra", "Palace", "."], "sentence-detokenized": "The Germans accidentally chose the working frequency of the Wotan system very badly, operating at 45 MHz, which was precisely the frequency of the BBC's powerful but non-functional television transmitter at Alexandra Palace.", "token2charspan": [[0, 3], [4, 11], [12, 24], [25, 30], [31, 34], [35, 42], [43, 52], [53, 55], [56, 59], [60, 65], [66, 72], [73, 77], [78, 83], [83, 84], [85, 94], [95, 97], [98, 100], [101, 104], [104, 105], [106, 111], [112, 115], [116, 125], [126, 129], [130, 139], [140, 142], [143, 146], [147, 150], [150, 152], [153, 161], [162, 165], [166, 180], [181, 191], [192, 203], [204, 206], [207, 216], [217, 223], [223, 224]]}
{"doc_key": "ai-test-419", "ner": [[8, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "into", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated into a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 39], [40, 41], [42, 43], [44, 45], [46, 47], [48, 59], [60, 65], [66, 68], [69, 78], [79, 85], [86, 88], [89, 96], [96, 97]]}
{"doc_key": "ai-test-420", "ner": [[1, 3, "misc"], [8, 8, "misc"], [12, 12, "product"], [14, 14, "product"], [16, 18, "product"], [26, 28, "misc"], [36, 37, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 12, 8, 8, "usage", "", false, false], [14, 14, 8, 8, "usage", "", false, false], [16, 18, 14, 14, "named", "", false, false], [26, 28, 8, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "Semantic", "Web", "applications", "and", "in", "fairly", "popular", "RDF", "applications", "such", "as", "RSS", "and", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "resources", "are", "usually", "represented", "using", "URIs", ",", "which", "deliberately", "tag", "the", "actual", "data", "on", "the", "World", "Wide", "Web", "and", "can", "be", "used", "to", "access", "it", "."], "sentence-detokenized": "In Semantic Web applications and in fairly popular RDF applications such as RSS and FOAF (Friend a Friend), resources are usually represented using URIs, which deliberately tag the actual data on the World Wide Web and can be used to access it.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 28], [29, 32], [33, 35], [36, 42], [43, 50], [51, 54], [55, 67], [68, 72], [73, 75], [76, 79], [80, 83], [84, 88], [89, 90], [90, 96], [97, 98], [99, 105], [105, 106], [106, 107], [108, 117], [118, 121], [122, 129], [130, 141], [142, 147], [148, 152], [152, 153], [154, 159], [160, 172], [173, 176], [177, 180], [181, 187], [188, 192], [193, 195], [196, 199], [200, 205], [206, 210], [211, 214], [215, 218], [219, 222], [223, 225], [226, 230], [231, 233], [234, 240], [241, 243], [243, 244]]}
{"doc_key": "ai-test-421", "ner": [[0, 7, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "has", "studied", "this", "topic", "in", "detail"], "sentence-detokenized": "The Association for the Advancement of Artificial Intelligence has studied this topic in detail", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 35], [36, 38], [39, 49], [50, 62], [63, 66], [67, 74], [75, 79], [80, 85], [86, 88], [89, 95]]}
{"doc_key": "ai-test-422", "ner": [[0, 6, "product"], [18, 20, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 20, 0, 6, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Apple", "Macintosh", "speech", "system", ",", "which", "started", "as", "a", "curiosity", ",", "has", "evolved", "into", "a", "fully", "supported", "PlainTalk", "program", "for", "people", "with", "vision", "problems", "."], "sentence-detokenized": "The Apple Macintosh speech system, which started as a curiosity, has evolved into a fully supported PlainTalk program for people with vision problems.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 26], [27, 33], [33, 34], [35, 40], [41, 48], [49, 51], [52, 53], [54, 63], [63, 64], [65, 68], [69, 76], [77, 81], [82, 83], [84, 89], [90, 99], [100, 109], [110, 117], [118, 121], [122, 128], [129, 133], [134, 140], [141, 149], [149, 150]]}
{"doc_key": "ai-test-423", "ner": [[5, 5, "field"], [7, 8, "task"], [10, 11, "task"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 5, 5, "part-of", "task_part_of_field", false, false], [10, 11, 5, 5, "part-of", "task_part_of_field", false, false], [13, 14, 5, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Other", "applications", "of", "ontologies", "within", "NLP", "include", "information", "retrieval", ",", "information", "extraction", "and", "automatic", "summarization", "."], "sentence-detokenized": "Other applications of ontologies within NLP include information retrieval, information extraction and automatic summarization.", "token2charspan": [[0, 5], [6, 18], [19, 21], [22, 32], [33, 39], [40, 43], [44, 51], [52, 63], [64, 73], [73, 74], [75, 86], [87, 97], [98, 101], [102, 111], [112, 125], [125, 126]]}
{"doc_key": "ai-test-424", "ner": [[7, 15, "organisation"], [18, 22, "organisation"], [26, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Institute", "is", "working", "closely", "with", "the", "Janelia", "Farm", "Campus", "of", "the", "Howard", "Hughes", "Medical", "Institute", ",", "the", "Allen", "Institute", "for", "Brain", "Science", ",", "and", "the", "National", "Institutes", "of", "Health", "to", "develop", "better", "methods", "for", "reconstructing", "neuronal", "architectures", "."], "sentence-detokenized": "The Institute is working closely with the Janelia Farm Campus of the Howard Hughes Medical Institute, the Allen Institute for Brain Science, and the National Institutes of Health to develop better methods for reconstructing neuronal architectures.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 24], [25, 32], [33, 37], [38, 41], [42, 49], [50, 54], [55, 61], [62, 64], [65, 68], [69, 75], [76, 82], [83, 90], [91, 100], [100, 101], [102, 105], [106, 111], [112, 121], [122, 125], [126, 131], [132, 139], [139, 140], [141, 144], [145, 148], [149, 157], [158, 168], [169, 171], [172, 178], [179, 181], [182, 189], [190, 196], [197, 204], [205, 208], [209, 223], [224, 232], [233, 246], [246, 247]]}
{"doc_key": "ai-test-425", "ner": [[2, 2, "organisation"], [5, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 2, 2, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Recently", ",", "Google", "announced", "that", "Google", "Translate", "will", "translate", "approximately", "enough", "text", "in", "one", "day", "(", "2012", ")", "to", "fill", "1", "million", "books", "."], "sentence-detokenized": "Recently, Google announced that Google Translate will translate approximately enough text in one day (2012) to fill 1 million books.", "token2charspan": [[0, 8], [8, 9], [10, 16], [17, 26], [27, 31], [32, 38], [39, 48], [49, 53], [54, 63], [64, 77], [78, 84], [85, 89], [90, 92], [93, 96], [97, 100], [101, 102], [102, 106], [106, 107], [108, 110], [111, 115], [116, 117], [118, 125], [126, 131], [131, 132]]}
{"doc_key": "ai-test-426", "ner": [[13, 14, "country"], [17, 18, "country"], [20, 20, "country"], [22, 22, "country"], [24, 24, "country"], [26, 27, "country"], [39, 40, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Events", "are", "held", "all", "over", "the", "world", "and", "are", "most", "popular", "in", "the", "United", "Kingdom", ",", "the", "United", "States", ",", "Japan", ",", "Singapore", ",", "India", ",", "South", "Korea", "and", "are", "becoming", "popular", "in", "countries", "in", "the", "subcontinent", "such", "as", "Sri", "Lanka", "."], "sentence-detokenized": "Events are held all over the world and are most popular in the United Kingdom, the United States, Japan, Singapore, India, South Korea and are becoming popular in countries in the subcontinent such as Sri Lanka.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 24], [25, 28], [29, 34], [35, 38], [39, 42], [43, 47], [48, 55], [56, 58], [59, 62], [63, 69], [70, 77], [77, 78], [79, 82], [83, 89], [90, 96], [96, 97], [98, 103], [103, 104], [105, 114], [114, 115], [116, 121], [121, 122], [123, 128], [129, 134], [135, 138], [139, 142], [143, 151], [152, 159], [160, 162], [163, 172], [173, 175], [176, 179], [180, 192], [193, 197], [198, 200], [201, 204], [205, 210], [210, 211]]}
{"doc_key": "ai-test-427", "ner": [[6, 6, "programlang"], [11, 11, "programlang"], [13, 13, "programlang"], [15, 16, "programlang"], [18, 18, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "packages", "are", "developed", "primarily", "in", "R", "and", "sometimes", "also", "in", "Java", ",", "C", ",", "C", "++", "and", "Fortran", "."], "sentence-detokenized": "These packages are developed primarily in R and sometimes also in Java, C, C++ and Fortran.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 28], [29, 38], [39, 41], [42, 43], [44, 47], [48, 57], [58, 62], [63, 65], [66, 70], [70, 71], [72, 73], [73, 74], [75, 76], [76, 78], [79, 82], [83, 90], [90, 91]]}
{"doc_key": "ai-test-428", "ner": [[4, 9, "conference"], [11, 11, "conference"], [14, 14, "researcher"], [16, 16, "researcher"], [20, 22, "researcher"], [24, 27, "algorithm"], [30, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 11, 4, 9, "named", "", false, false], [14, 14, 4, 9, "physical", "", false, false], [14, 14, 4, 9, "role", "", false, false], [14, 14, 20, 22, "role", "teams_up_with", false, false], [14, 14, 24, 27, "usage", "", false, false], [16, 16, 4, 9, "physical", "", false, false], [16, 16, 4, 9, "role", "", false, false], [16, 16, 20, 22, "role", "teams_up_with", false, false], [16, 16, 24, 27, "usage", "", false, false], [20, 22, 4, 9, "physical", "", false, false], [20, 22, 4, 9, "role", "", false, false], [20, 22, 24, 27, "usage", "", false, false], [24, 27, 30, 35, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["As", "part", "of", "the", "2006", "European", "Conference", "on", "Computer", "Vision", "(", "ECCV", ")", ",", "Dalal", "and", "Triggs", "teamed", "up", "with", "Cordelia", "Schmid", "to", "apply", "HOG", "detectors", "to", "the", "problem", "of", "detecting", "people", "in", "movies", "and", "videos", "."], "sentence-detokenized": "As part of the 2006 European Conference on Computer Vision (ECCV), Dalal and Triggs teamed up with Cordelia Schmid to apply HOG detectors to the problem of detecting people in movies and videos.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 19], [20, 28], [29, 39], [40, 42], [43, 51], [52, 58], [59, 60], [60, 64], [64, 65], [65, 66], [67, 72], [73, 76], [77, 83], [84, 90], [91, 93], [94, 98], [99, 107], [108, 114], [115, 117], [118, 123], [124, 127], [128, 137], [138, 140], [141, 144], [145, 152], [153, 155], [156, 165], [166, 172], [173, 175], [176, 182], [183, 186], [187, 193], [193, 194]]}
{"doc_key": "ai-test-429", "ner": [[3, 3, "metrics"], [5, 7, "metrics"], [10, 12, "task"], [18, 20, "metrics"], [22, 25, "metrics"], [28, 28, "metrics"], [31, 33, "metrics"], [35, 35, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 3, 10, 12, "related-to", "measured_with", false, false], [5, 7, 10, 12, "related-to", "measured_with", false, false], [18, 20, 10, 12, "related-to", "measured_with", false, false], [22, 25, 18, 20, "named", "", false, false], [28, 28, 18, 20, "named", "", false, false], [35, 35, 31, 33, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "addition", "to", "sensitivity", "and", "specificity", ",", "the", "performance", "of", "a", "binary", "classification", "test", "can", "be", "measured", "using", "positive", "predictive", "value", "(", "PPV", ")", ",", "also", "known", "as", "accuracy", ",", "and", "negative", "predictive", "value", "(", "NPV", ")", "."], "sentence-detokenized": "In addition to sensitivity and specificity, the performance of a binary classification test can be measured using positive predictive value (PPV), also known as accuracy, and negative predictive value (NPV).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 42], [42, 43], [44, 47], [48, 59], [60, 62], [63, 64], [65, 71], [72, 86], [87, 91], [92, 95], [96, 98], [99, 107], [108, 113], [114, 122], [123, 133], [134, 139], [140, 141], [141, 144], [144, 145], [145, 146], [147, 151], [152, 157], [158, 160], [161, 169], [169, 170], [171, 174], [175, 183], [184, 194], [195, 200], [201, 202], [202, 205], [205, 206], [206, 207]]}
{"doc_key": "ai-test-430", "ner": [[14, 16, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "models", "may", "partially", "account", "for", "overlapping", "correspondences", "(", "for", "example", ",", "using", "the", "Jaccard", "index", "criterion", "."], "sentence-detokenized": "Such models may partially account for overlapping correspondences (for example, using the Jaccard index criterion.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 25], [26, 33], [34, 37], [38, 49], [50, 65], [66, 67], [67, 70], [71, 78], [78, 79], [80, 85], [86, 89], [90, 97], [98, 103], [104, 113], [113, 114]]}
{"doc_key": "ai-test-431", "ner": [[22, 27, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Further", ",", "in", "the", "case", "of", "single", "-", "sample", "estimation", ",", "it", "highlights", "philosophical", "issues", "and", "potential", "misunderstandings", "in", "the", "use", "of", "maximum", "likelihood", "estimators", "and", "likelihood", "functions", "."], "sentence-detokenized": "Further, in the case of single-sample estimation, it highlights philosophical issues and potential misunderstandings in the use of maximum likelihood estimators and likelihood functions.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 15], [16, 20], [21, 23], [24, 30], [30, 31], [31, 37], [38, 48], [48, 49], [50, 52], [53, 63], [64, 77], [78, 84], [85, 88], [89, 98], [99, 116], [117, 119], [120, 123], [124, 127], [128, 130], [131, 138], [139, 149], [150, 160], [161, 164], [165, 175], [176, 185], [185, 186]]}
