{"doc_key": "ai-dev-1", "ner": [[4, 4, "metrics"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 10, 4, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["In", "this", "case", ",", "accuracy", "is", "measured", "by", "the", "error", "rate", "defined", "as", ":"], "sentence-detokenized": "In this case, accuracy is measured by the error rate defined as:", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 22], [23, 25], [26, 34], [35, 37], [38, 41], [42, 47], [48, 52], [53, 60], [61, 63], [63, 64]]}
{"doc_key": "ai-dev-2", "ner": [[4, 4, "algorithm"], [11, 12, "misc"], [16, 18, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 11, 12, "type-of", "", false, false], [4, 4, 16, 18, "related-to", "", false, false], [4, 4, 19, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["From", "this", "perspective", ",", "SVM", "is", "closely", "related", "to", "other", "basic", "classification", "algorithms", ",", "such", "as", "regularised", "least", "squares", "logistic", "regression", "."], "sentence-detokenized": "From this perspective, SVM is closely related to other basic classification algorithms, such as regularised least squares logistic regression.", "token2charspan": [[0, 4], [5, 9], [10, 21], [21, 22], [23, 26], [27, 29], [30, 37], [38, 45], [46, 48], [49, 54], [55, 60], [61, 75], [76, 86], [86, 87], [88, 92], [93, 95], [96, 107], [108, 113], [114, 121], [122, 130], [131, 141], [141, 142]]}
{"doc_key": "ai-dev-3", "ner": [[0, 1, "person"], [3, 4, "person"], [15, 16, "person"], [18, 18, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 0, 1, "named", "actor_plays_character", false, false], [3, 4, 0, 1, "origin", "actor_plays_character", false, false], [18, 18, 15, 16, "named", "actor_plays_character", false, false], [18, 18, 15, 16, "origin", "actor_plays_character", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Brion", "James", "portrays", "Leon", "Kowalski", ",", "the", "fighting", ",", "working", "-", "class", "replicant", ",", "and", "Joanna", "Cassidy", "plays", "Zhora", ",", "the", "assassin", "replicant", "."], "sentence-detokenized": "Brion James portrays Leon Kowalski, the fighting, working-class replicant, and Joanna Cassidy plays Zhora, the assassin replicant.", "token2charspan": [[0, 5], [6, 11], [12, 20], [21, 25], [26, 34], [34, 35], [36, 39], [40, 48], [48, 49], [50, 57], [57, 58], [58, 63], [64, 73], [73, 74], [75, 78], [79, 85], [86, 93], [94, 99], [100, 105], [105, 106], [107, 110], [111, 119], [120, 129], [129, 130]]}
{"doc_key": "ai-dev-4", "ner": [[20, 22, "product"], [19, 24, "product"], [26, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 22, 26, 27, "physical", "", false, false], [19, 24, 20, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "image", ",", "which", "was", "scanned", ",", "stored", "and", "recreated", "in", "digital", "pixels", ",", "was", "displayed", "on", "the", "Standards", "East", "Automatic", "Computer", "(", "SEAC", ")", "at", "NIST", "."], "sentence-detokenized": "The first image, which was scanned, stored and recreated in digital pixels, was displayed on the Standards East Automatic Computer (SEAC) at NIST.", "token2charspan": [[0, 3], [4, 9], [10, 15], [15, 16], [17, 22], [23, 26], [27, 34], [34, 35], [36, 42], [43, 46], [47, 56], [57, 59], [60, 67], [68, 74], [74, 75], [76, 79], [80, 89], [90, 92], [93, 96], [97, 106], [107, 111], [112, 121], [122, 130], [131, 132], [132, 136], [136, 137], [138, 140], [141, 145], [145, 146]]}
{"doc_key": "ai-dev-5", "ner": [[0, 6, "task"], [20, 21, "task"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 6, 20, 21, "part-of", "", false, false], [0, 6, 23, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Segmenting", "text", "into", "topics", "or", "discourse", "turns", "can", "be", "useful", "in", "some", "natural", "processing", "tasks", ":", "it", "can", "significantly", "improve", "information", "retrieval", "or", "speech", "recognition", "(", "by", "indexing", "/", "identifying", "documents", "more", "precisely", "or", "by", "returning", "a", "specific", "part", "of", "a", "document", "corresponding", "to", "a", "query", ")", "."], "sentence-detokenized": "Segmenting text into topics or discourse turns can be useful in some natural processing tasks: it can significantly improve information retrieval or speech recognition (by indexing/identifying documents more precisely or by returning a specific part of a document corresponding to a query).", "token2charspan": [[0, 10], [11, 15], [16, 20], [21, 27], [28, 30], [31, 40], [41, 46], [47, 50], [51, 53], [54, 60], [61, 63], [64, 68], [69, 76], [77, 87], [88, 93], [93, 94], [95, 97], [98, 101], [102, 115], [116, 123], [124, 135], [136, 145], [146, 148], [149, 155], [156, 167], [168, 169], [169, 171], [172, 180], [180, 181], [181, 192], [193, 202], [203, 207], [208, 217], [218, 220], [221, 223], [224, 233], [234, 235], [236, 244], [245, 249], [250, 252], [253, 254], [255, 263], [264, 277], [278, 280], [281, 282], [283, 288], [288, 289], [289, 290]]}
{"doc_key": "ai-dev-6", "ner": [[5, 8, "university"], [17, 18, "conference"], [20, 23, "university"], [33, 34, "researcher"], [36, 37, "researcher"], [39, 40, "researcher"], [42, 43, "researcher"], [45, 46, "researcher"], [48, 49, "researcher"], [51, 53, "researcher"], [55, 56, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[17, 18, 20, 23, "physical", "", false, false], [33, 34, 17, 18, "physical", "", false, false], [33, 34, 17, 18, "role", "", false, false], [33, 34, 17, 18, "temporal", "", false, false], [36, 37, 17, 18, "physical", "", false, false], [36, 37, 17, 18, "role", "", false, false], [36, 37, 17, 18, "temporal", "", false, false], [39, 40, 17, 18, "physical", "", false, false], [39, 40, 17, 18, "role", "", false, false], [39, 40, 17, 18, "temporal", "", false, false], [42, 43, 17, 18, "physical", "", false, false], [42, 43, 17, 18, "role", "", false, false], [42, 43, 17, 18, "temporal", "", false, false], [45, 46, 17, 18, "physical", "", false, false], [45, 46, 17, 18, "role", "", false, false], [45, 46, 17, 18, "temporal", "", false, false], [48, 49, 17, 18, "physical", "", false, false], [48, 49, 17, 18, "role", "", false, false], [48, 49, 17, 18, "temporal", "", false, false], [51, 53, 17, 18, "physical", "", false, false], [51, 53, 17, 18, "role", "", false, false], [51, 53, 17, 18, "temporal", "", false, false], [55, 56, 17, 18, "physical", "", false, false], [55, 56, 17, 18, "role", "", false, false], [55, 56, 17, 18, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "sentence": ["He", "organized", "such", "a", "symposium", "at", "Indiana", "University", "in", "1999", ",", "and", "a", "larger", "symposium", "on", "\"", "Mental", "Robots", "\"", "at", "Stanford", "University", "in", "April", "2000", ",", "where", "he", "moderated", "a", "panel", "including", "Ray", "Kurzweil", ",", "Hans", "Moravec", ",", "Kevin", "Kelly", ",", "Ralph", "Merkle", ",", "Bill", "Joy", ",", "Frank", "Drake", ",", "John", "Henry", "Holland", "and", "John", "Koza", "."], "sentence-detokenized": "He organized such a symposium at Indiana University in 1999, and a larger symposium on \"Mental Robots\" at Stanford University in April 2000, where he moderated a panel including Ray Kurzweil, Hans Moravec, Kevin Kelly, Ralph Merkle, Bill Joy, Frank Drake, John Henry Holland and John Koza.", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 19], [20, 29], [30, 32], [33, 40], [41, 51], [52, 54], [55, 59], [59, 60], [61, 64], [65, 66], [67, 73], [74, 83], [84, 86], [87, 88], [88, 94], [95, 101], [101, 102], [103, 105], [106, 114], [115, 125], [126, 128], [129, 134], [135, 139], [139, 140], [141, 146], [147, 149], [150, 159], [160, 161], [162, 167], [168, 177], [178, 181], [182, 190], [190, 191], [192, 196], [197, 204], [204, 205], [206, 211], [212, 217], [217, 218], [219, 224], [225, 231], [231, 232], [233, 237], [238, 241], [241, 242], [243, 248], [249, 254], [254, 255], [256, 260], [261, 266], [267, 274], [275, 278], [279, 283], [284, 288], [288, 289]]}
{"doc_key": "ai-dev-7", "ner": [[8, 10, "metrics"], [11, 12, "metrics"], [14, 14, "metrics"], [15, 15, "metrics"], [17, 17, "metrics"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 10, 17, 17, "named", "", false, false], [11, 12, 8, 10, "named", "", false, false], [14, 14, 37, 37, "named", "", false, false], [15, 15, 14, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "score", "is", "calculated", "taking", "into", "account", "both", "the", "test", "precision", "p", "and", "the", "recall", "r", ":", "p", "is", "the", "number", "of", "true", "positives", "divided", "by", "the", "number", "of", "all", "positives", "returned", "by", "the", "classifier", ",", "and", "r", "is", "the", "number", "of", "true", "positives", "divided", "by", "the", "number", "of", "all", "relevant", "samples", "(", "all", "samples", "that", "should", "have", "been", "positive", ")", "."], "sentence-detokenized": "The score is calculated taking into account both the test precision p and the recall r: p is the number of true positives divided by the number of all positives returned by the classifier, and r is the number of true positives divided by the number of all relevant samples (all samples that should have been positive).", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 23], [24, 30], [31, 35], [36, 43], [44, 48], [49, 52], [53, 57], [58, 67], [68, 69], [70, 73], [74, 77], [78, 84], [85, 86], [86, 87], [88, 89], [90, 92], [93, 96], [97, 103], [104, 106], [107, 111], [112, 121], [122, 129], [130, 132], [133, 136], [137, 143], [144, 146], [147, 150], [151, 160], [161, 169], [170, 172], [173, 176], [177, 187], [187, 188], [189, 192], [193, 194], [195, 197], [198, 201], [202, 208], [209, 211], [212, 216], [217, 226], [227, 234], [235, 237], [238, 241], [242, 248], [249, 251], [252, 255], [256, 264], [265, 272], [273, 274], [274, 277], [278, 285], [286, 290], [291, 297], [298, 302], [303, 307], [308, 316], [316, 317], [317, 318]]}
{"doc_key": "ai-dev-8", "ner": [[4, 6, "organisation"], [26, 26, "product"], [34, 36, "person"], [39, 41, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 26, 26, "artifact", "", false, false], [26, 26, 34, 36, "win-defeat", "", false, false], [26, 26, 39, 41, "win-defeat", "", true, false], [34, 36, 39, 41, "win-defeat", "lose", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "its", "acquisition", "by", "Google", ",", "the", "company", "has", "made", "a", "number", "of", "notable", "achievements", ",", "perhaps", "the", "most", "notable", "of", "which", "is", "the", "creation", "of", "AlphaGo", ",", "the", "program", "that", "defeated", "world", "champion", "Lee", "Sedol", "in", "a", "challenging", "game", "of", "Go", "."], "sentence-detokenized": "Since its acquisition by Google, the company has made a number of notable achievements, perhaps the most notable of which is the creation of AlphaGo, the program that defeated world champion Lee Sedol in a challenging game of Go.", "token2charspan": [[0, 5], [6, 9], [10, 21], [22, 24], [25, 31], [31, 32], [33, 36], [37, 44], [45, 48], [49, 53], [54, 55], [56, 62], [63, 65], [66, 73], [74, 86], [86, 87], [88, 95], [96, 99], [100, 104], [105, 112], [113, 115], [116, 121], [122, 124], [125, 128], [129, 137], [138, 140], [141, 148], [148, 149], [150, 153], [154, 161], [162, 166], [167, 175], [176, 181], [182, 190], [191, 194], [195, 200], [201, 203], [204, 205], [206, 217], [218, 222], [223, 225], [226, 228], [228, 229]]}
{"doc_key": "ai-dev-9", "ner": [[16, 17, "misc"], [32, 34, "product"], [51, 52, "misc"], [57, 57, "misc"], [61, 61, "product"]], "ner_mapping_to_source": [0, 2, 3, 4, 5], "relations": [[16, 17, 57, 57, "named", "same", false, false], [32, 34, 51, 52, "related-to", "", false, false], [32, 34, 57, 57, "usage", "", false, false], [32, 34, 61, 61, "usage", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4], "sentence": ["The", "representation", "of", "words", "in", "their", "context", "by", "means", "of", "fixed", "-", "size", "dense", "vectors", "(", "word", "embeddings", ")", "has", "become", "one", "of", "the", "basic", "blocks", "of", "several", "NLP", "systems", ".", "An", "unsupervised", "disambiguation", "system", "uses", "the", "similarity", "of", "word", "meanings", "in", "a", "fixed", "context", "window", "to", "select", "the", "most", "appropriate", "word", "meaning", ",", "using", "a", "pre-trained", "word", "embedding", "model", "and", "WordNet", "."], "sentence-detokenized": "The representation of words in their context by means of fixed-size dense vectors (word embeddings) has become one of the basic blocks of several NLP systems. An unsupervised disambiguation system uses the similarity of word meanings in a fixed context window to select the most appropriate word meaning, using a pre-trained word embedding model and WordNet.", "token2charspan": [[0, 3], [4, 18], [19, 21], [22, 27], [28, 30], [31, 36], [37, 44], [45, 47], [48, 53], [54, 56], [57, 62], [62, 63], [63, 67], [68, 73], [74, 81], [82, 83], [83, 87], [88, 98], [98, 99], [100, 103], [104, 110], [111, 114], [115, 117], [118, 121], [122, 127], [128, 134], [135, 137], [138, 145], [146, 149], [150, 157], [157, 158], [159, 161], [162, 174], [175, 189], [190, 196], [197, 201], [202, 205], [206, 216], [217, 219], [220, 224], [225, 233], [234, 236], [237, 238], [239, 244], [245, 252], [253, 259], [260, 262], [263, 269], [270, 273], [274, 278], [279, 290], [291, 295], [296, 303], [303, 304], [305, 310], [311, 312], [313, 324], [325, 329], [330, 339], [340, 345], [346, 349], [350, 357], [357, 358]]}
{"doc_key": "ai-dev-10", "ner": [[0, 1, "field"], [5, 6, "field"], [8, 9, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 0, 1, "part-of", "", false, false], [8, 9, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "methods", ",", "either", "supervised", "learning", "or", "unsupervised", "learning", ",", "have", "been", "used", "to", "automatically", "induce", "such", "rules", "."], "sentence-detokenized": "Machine learning methods, either supervised learning or unsupervised learning, have been used to automatically induce such rules.", "token2charspan": [[0, 7], [8, 16], [17, 24], [24, 25], [26, 32], [33, 43], [44, 52], [53, 55], [56, 68], [69, 77], [77, 78], [79, 83], [84, 88], [89, 93], [94, 96], [97, 110], [111, 117], [118, 122], [123, 128], [128, 129]]}
{"doc_key": "ai-dev-11", "ner": [[3, 3, "researcher"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1969", ",", "Scheinman", "invented", "the", "Stanford", "Hand", ","], "sentence-detokenized": "In 1969, Scheinman invented the Stanford Hand,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 27], [28, 31], [32, 40], [41, 45], [45, 46]]}
{"doc_key": "ai-dev-12", "ner": [[2, 3, "metrics"], [7, 11, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Since", "the", "log", "loss", "is", "differentiable", ",", "a", "gradient", "-", "based", "method", "can", "be", "used", "to", "optimise", "the", "model", "."], "sentence-detokenized": "Since the log loss is differentiable, a gradient-based method can be used to optimise the model.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 18], [19, 21], [22, 36], [36, 37], [38, 39], [40, 48], [48, 49], [49, 54], [55, 61], [62, 65], [66, 68], [69, 73], [74, 76], [77, 85], [86, 89], [90, 95], [95, 96]]}
{"doc_key": "ai-dev-13", "ner": [[0, 5, "field"], [6, 6, "algorithm"], [8, 8, "algorithm"], [13, 15, "algorithm"], [18, 18, "field"], [27, 28, "task"], [30, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[6, 6, 18, 18, "part-of", "", false, false], [8, 8, 6, 6, "named", "", false, false], [13, 15, 6, 6, "named", "", false, false], [18, 18, 0, 5, "part-of", "subfield", false, false], [27, 28, 18, 18, "part-of", "", false, false], [30, 31, 18, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "machine", "learning", ",", "Support", "Vector", "Machines", "(", "SVMs", ",", "also", "known", "as", "Support", "Vector", "Networks", ")", "are", "supervised", "learning", "models", "whose", "learning", "algorithms", "analyse", "data", "used", "for", "classification", "and", "regression", "analysis", "."], "sentence-detokenized": "In machine learning, Support Vector Machines (SVMs, also known as Support Vector Networks) are supervised learning models whose learning algorithms analyse data used for classification and regression analysis.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 28], [29, 35], [36, 44], [45, 46], [46, 50], [50, 51], [52, 56], [57, 62], [63, 65], [66, 73], [74, 80], [81, 89], [89, 90], [91, 94], [95, 105], [106, 114], [115, 121], [122, 127], [128, 136], [137, 147], [148, 155], [156, 160], [161, 165], [166, 169], [170, 184], [185, 188], [189, 199], [200, 208], [208, 209]]}
{"doc_key": "ai-dev-14", "ner": [[11, 11, "task"], [10, 13, "task"], [30, 30, "metrics"], [32, 32, "metrics"], [34, 34, "researcher"], [36, 36, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 13, 11, 11, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": [",", "(", "2002", ")", "as", "an", "automatic", "metric", "for", "evaluating", "machine", "translation", "(", "MT", ")", ",", "several", "other", "methods", "have", "been", "proposed", "to", "revise", "or", "improve", "it", ",", "such", "as", "TER", ",", "METEOR", ",", "Banerjee", "and", "Lavie", ",", "(", "2005", ")", ",", "etc", "."], "sentence-detokenized": ", (2002) as an automatic metric for evaluating machine translation (MT), several other methods have been proposed to revise or improve it, such as TER, METEOR, Banerjee and Lavie, (2005), etc.", "token2charspan": [[0, 1], [2, 3], [3, 7], [7, 8], [9, 11], [12, 14], [15, 24], [25, 31], [32, 35], [36, 46], [47, 54], [55, 66], [67, 68], [68, 70], [70, 71], [71, 72], [73, 80], [81, 86], [87, 94], [95, 99], [100, 104], [105, 113], [114, 116], [117, 123], [124, 126], [127, 134], [135, 137], [137, 138], [139, 143], [144, 146], [147, 150], [150, 151], [152, 158], [158, 159], [160, 168], [169, 172], [173, 178], [178, 179], [180, 181], [181, 185], [185, 186], [186, 187], [188, 191], [191, 192]]}
{"doc_key": "ai-dev-15", "ner": [[2, 4, "misc"], [9, 9, "organisation"], [12, 12, "organisation"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 12, 12, "origin", "", false, false], [12, 12, 9, 9, "part-of", "", false, false], [15, 16, 12, 12, "role", "", false, false], [18, 19, 12, 12, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "includes", "the", "upper", "ontology", ",", "created", "by", "the", "IEEE", "working", "group", "P1600.1", "(", "originally", "Ian", "Niles", "and", "Adam", "Pease", ")", "."], "sentence-detokenized": "It includes the upper ontology, created by the IEEE working group P1600.1 (originally Ian Niles and Adam Pease).", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 21], [22, 30], [30, 31], [32, 39], [40, 42], [43, 46], [47, 51], [52, 59], [60, 65], [66, 73], [74, 75], [75, 85], [86, 89], [90, 95], [96, 99], [100, 104], [105, 110], [110, 111], [111, 112]]}
{"doc_key": "ai-dev-16", "ner": [[0, 2, "misc"], [32, 34, "algorithm"], [36, 37, "algorithm"], [40, 41, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[32, 34, 0, 2, "part-of", "", true, false], [36, 37, 0, 2, "part-of", "", true, false], [40, 41, 36, 37, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "cryoelectron", "tomography", ",", "where", "there", "are", "a", "limited", "number", "of", "projections", "due", "to", "hardware", "limitations", "and", "to", "avoid", "damage", "to", "the", "biological", "sample", ",", "it", "can", "be", "used", "in", "combination", "with", "compressive", "sensing", "techniques", "or", "regularization", "functions", "(", "e.g.", "Huber", "loss", ")", "to", "improve", "the", "reconstruction", "for", "better", "interpretation", "."], "sentence-detokenized": "In cryoelectron tomography, where there are a limited number of projections due to hardware limitations and to avoid damage to the biological sample, it can be used in combination with compressive sensing techniques or regularization functions (e.g. Huber loss) to improve the reconstruction for better interpretation.", "token2charspan": [[0, 2], [3, 15], [16, 26], [26, 27], [28, 33], [34, 39], [40, 43], [44, 45], [46, 53], [54, 60], [61, 63], [64, 75], [76, 79], [80, 82], [83, 91], [92, 103], [104, 107], [108, 110], [111, 116], [117, 123], [124, 126], [127, 130], [131, 141], [142, 148], [148, 149], [150, 152], [153, 156], [157, 159], [160, 164], [165, 167], [168, 179], [180, 184], [185, 196], [197, 204], [205, 215], [216, 218], [219, 233], [234, 243], [244, 245], [245, 249], [250, 255], [256, 260], [260, 261], [262, 264], [265, 272], [273, 276], [277, 291], [292, 295], [296, 302], [303, 317], [317, 318]]}
{"doc_key": "ai-dev-17", "ner": [[8, 9, "programlang"], [12, 13, "algorithm"], [15, 18, "algorithm"], [21, 22, "algorithm"], [26, 30, "product"], [32, 33, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [[26, 30, 8, 9, "general-affiliation", "", true, false], [26, 30, 8, 9, "part-of", "", true, false], [32, 33, 26, 30, "role", "publishes", false, false]], "relations_mapping_to_source": [4, 5, 6], "sentence": ["The", "implementation", "of", "a", "number", "of", "whitening", "procedures", "in", "R", ",", "including", "ZCA", "whitening", "and", "PCA", "whitening", ",", "as", "well", "as", "CCA", "whitening", ",", "is", "available", "in", "the", "whitening", "R", "package", "published", "in", "CRAN", "."], "sentence-detokenized": "The implementation of a number of whitening procedures in R, including ZCA whitening and PCA whitening, as well as CCA whitening, is available in the whitening R package published in CRAN.", "token2charspan": [[0, 3], [4, 18], [19, 21], [22, 23], [24, 30], [31, 33], [34, 43], [44, 54], [55, 57], [58, 59], [59, 60], [61, 70], [71, 74], [75, 84], [85, 88], [89, 92], [93, 102], [102, 103], [104, 106], [107, 111], [112, 114], [115, 118], [119, 128], [128, 129], [130, 132], [133, 142], [143, 145], [146, 149], [150, 159], [160, 161], [162, 169], [170, 179], [180, 182], [183, 187], [187, 188]]}
{"doc_key": "ai-dev-18", "ner": [[30, 30, "product"], [32, 32, "product"], [34, 34, "product"], [36, 36, "product"], [38, 38, "product"], [40, 40, "product"], [43, 44, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[30, 30, 34, 34, "compare", "", false, false], [30, 30, 36, 36, "compare", "", false, false], [30, 30, 38, 38, "compare", "", false, false], [30, 30, 40, 40, "compare", "", false, false], [30, 30, 43, 44, "compare", "", false, false], [32, 32, 34, 34, "compare", "", false, false], [32, 32, 36, 36, "compare", "", false, false], [32, 32, 38, 38, "compare", "", false, false], [32, 32, 40, 40, "compare", "", false, false], [32, 32, 43, 44, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Nowadays", ",", "the", "field", "has", "become", "even", "more", "daunting", "and", "complex", ",", "with", "the", "addition", "of", "languages", "and", "software", "for", "analysing", "and", "designing", "circuits", ",", "systems", "and", "signals", ",", "from", "MATLAB", "and", "Simulink", "to", "NumPy", ",", "VHDL", ",", "PSpice", ",", "Verilog", "and", "even", "assembly", "language", "."], "sentence-detokenized": "Nowadays, the field has become even more daunting and complex, with the addition of languages and software for analysing and designing circuits, systems and signals, from MATLAB and Simulink to NumPy, VHDL, PSpice, Verilog and even assembly language.", "token2charspan": [[0, 8], [8, 9], [10, 13], [14, 19], [20, 23], [24, 30], [31, 35], [36, 40], [41, 49], [50, 53], [54, 61], [61, 62], [63, 67], [68, 71], [72, 80], [81, 83], [84, 93], [94, 97], [98, 106], [107, 110], [111, 120], [121, 124], [125, 134], [135, 143], [143, 144], [145, 152], [153, 156], [157, 164], [164, 165], [166, 170], [171, 177], [178, 181], [182, 190], [191, 193], [194, 199], [199, 200], [201, 205], [205, 206], [207, 213], [213, 214], [215, 222], [223, 226], [227, 231], [232, 240], [241, 249], [249, 250]]}
{"doc_key": "ai-dev-19", "ner": [[5, 7, "person"], [15, 16, "person"], [18, 19, "organisation"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[18, 19, 15, 16, "origin", "", false, false], [22, 22, 18, 19, "artifact", "builds", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "company", "was", "founded", "by", "Kiichiro", "Toyoda", "in", "1937", "as", "a", "spin", "-", "off", "of", "Sakichi", "Toyoda", "'s", "Toyota", "Industries", "to", "create", "cars", "."], "sentence-detokenized": "The company was founded by Kiichiro Toyoda in 1937 as a spin-off of Sakichi Toyoda's Toyota Industries to create cars.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 26], [27, 35], [36, 42], [43, 45], [46, 50], [51, 53], [54, 55], [56, 60], [60, 61], [61, 64], [65, 67], [68, 75], [76, 82], [82, 84], [85, 91], [92, 102], [103, 105], [106, 112], [113, 117], [117, 118]]}
{"doc_key": "ai-dev-20", "ner": [[0, 6, "field"], [54, 55, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[54, 55, 0, 6, "origin", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Unsupervised", "learning", ",", "on", "the", "other", "hand", ",", "assumes", "training", "data", "that", "has", "not", "been", "manually", "labelled", "and", "tries", "to", "find", "patterns", "in", "the", "data", "that", "can", "then", "be", "used", "to", "determine", "the", "correct", "output", "value", "for", "new", "data", "sets", ".", "More", "recently", ",", "a", "combination", "of", "the", "two", "methods", "has", "been", "explored", "-", "semi-supervised", "learning", "using", "a", "combination", "of", "labelled", "and", "unlabelled", "data", "(", "typically", "a", "small", "amount", "of", "labelled", "data", "with", "a", "large", "amount", "of", "unlabelled", "data", ")", "."], "sentence-detokenized": "Unsupervised learning, on the other hand, assumes training data that has not been manually labelled and tries to find patterns in the data that can then be used to determine the correct output value for new data sets. More recently, a combination of the two methods has been explored - semi-supervised learning using a combination of labelled and unlabelled data (typically a small amount of labelled data with a large amount of unlabelled data).", "token2charspan": [[0, 12], [13, 21], [21, 22], [23, 25], [26, 29], [30, 35], [36, 40], [40, 41], [42, 49], [50, 58], [59, 63], [64, 68], [69, 72], [73, 76], [77, 81], [82, 90], [91, 99], [100, 103], [104, 109], [110, 112], [113, 117], [118, 126], [127, 129], [130, 133], [134, 138], [139, 143], [144, 147], [148, 152], [153, 155], [156, 160], [161, 163], [164, 173], [174, 177], [178, 185], [186, 192], [193, 198], [199, 202], [203, 206], [207, 211], [212, 216], [216, 217], [218, 222], [223, 231], [231, 232], [233, 234], [235, 246], [247, 249], [250, 253], [254, 257], [258, 265], [266, 269], [270, 274], [275, 283], [284, 285], [286, 301], [302, 310], [311, 316], [317, 318], [319, 330], [331, 333], [334, 342], [343, 346], [347, 357], [358, 362], [363, 364], [364, 373], [374, 375], [376, 381], [382, 388], [389, 391], [392, 400], [401, 405], [406, 410], [411, 412], [413, 418], [419, 425], [426, 428], [429, 439], [440, 444], [444, 445], [445, 446]]}
{"doc_key": "ai-dev-21", "ner": [[24, 24, "product"], [26, 27, "organisation"], [29, 29, "product"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[26, 27, 29, 29, "artifact", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Despite", "these", "humanoid", "robots", "being", "designed", "for", "utilitarian", "purposes", ",", "there", "are", "also", "some", "humanoid", "robots", "designed", "for", "entertainment", ",", "such", "as", "Sony", "'s", "QRIO", "and", "Wow", "Wee", "'s", "RoboSapien", "."], "sentence-detokenized": "Despite these humanoid robots being designed for utilitarian purposes, there are also some humanoid robots designed for entertainment, such as Sony's QRIO and Wow Wee's RoboSapien.", "token2charspan": [[0, 7], [8, 13], [14, 22], [23, 29], [30, 35], [36, 44], [45, 48], [49, 60], [61, 69], [69, 70], [71, 76], [77, 80], [81, 85], [86, 90], [91, 99], [100, 106], [107, 115], [116, 119], [120, 133], [133, 134], [135, 139], [140, 142], [143, 147], [147, 149], [150, 154], [155, 158], [159, 162], [163, 166], [166, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-dev-22", "ner": [[0, 0, "researcher"], [6, 13, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 13, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Webber", "became", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "in", "1991", ","], "sentence-detokenized": "Webber became a member of the Association for the Advancement of Artificial Intelligence in 1991,", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 22], [23, 25], [26, 29], [30, 41], [42, 45], [46, 49], [50, 61], [62, 64], [65, 75], [76, 88], [89, 91], [92, 96], [96, 97]]}
{"doc_key": "ai-dev-23", "ner": [[17, 23, "task"]], "ner_mapping_to_source": [2], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "this", "company", "he", "developed", "data", "mining", "and", "database", "technologies", ",", "more", "specifically", "high", "-", "level", "ontologies", "for", "intelligence", "and", "automatic", "natural", "language", "understanding", "."], "sentence-detokenized": "In this company he developed data mining and database technologies, more specifically high-level ontologies for intelligence and automatic natural language understanding.", "token2charspan": [[0, 2], [3, 7], [8, 15], [16, 18], [19, 28], [29, 33], [34, 40], [41, 44], [45, 53], [54, 66], [66, 67], [68, 72], [73, 85], [86, 90], [90, 91], [91, 96], [97, 107], [108, 111], [112, 124], [125, 128], [129, 138], [139, 146], [147, 155], [156, 169], [169, 170]]}
{"doc_key": "ai-dev-24", "ner": [[22, 23, "misc"], [26, 29, "misc"], [31, 32, "misc"], [37, 38, "country"], [41, 43, "organisation"], [44, 45, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[22, 23, 37, 38, "physical", "", false, false], [26, 29, 37, 38, "physical", "", false, false], [31, 32, 37, 38, "physical", "", false, false], [41, 43, 44, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["However", ",", "in", "recent", "years", ",", "developing", "countries", "have", "witnessed", "the", "emergence", "of", "various", "e-services", "and", "related", "initiatives", ",", "such", "as", "the", "Nemmadi", "project", ",", "the", "MCA21", "Mission", "Mode", "Project", "or", "Digital", "India", "even", "more", "so", ",", "in", "India", ";", "the", "Electronic", "Government", "Directorate", "in", "Pakistan", ",", "etc."], "sentence-detokenized": "However, in recent years, developing countries have witnessed the emergence of various e-services and related initiatives, such as the Nemmadi project, the MCA21 Mission Mode Project or Digital India even more so, in India; the Electronic Government Directorate in Pakistan, etc.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 18], [19, 24], [24, 25], [26, 36], [37, 46], [47, 51], [52, 61], [62, 65], [66, 75], [76, 78], [79, 86], [87, 97], [98, 101], [102, 109], [110, 121], [121, 122], [123, 127], [128, 130], [131, 134], [135, 142], [143, 150], [150, 151], [152, 155], [156, 161], [162, 169], [170, 174], [175, 182], [183, 185], [186, 193], [194, 199], [200, 204], [205, 209], [210, 212], [212, 213], [214, 216], [217, 222], [222, 223], [224, 227], [228, 238], [239, 249], [250, 261], [262, 264], [265, 273], [273, 274], [275, 279]]}
{"doc_key": "ai-dev-25", "ner": [[2, 3, "misc"], [5, 6, "field"], [8, 10, "field"], [11, 11, "university"], [15, 17, "university"], [24, 27, "university"], [32, 32, "misc"], [34, 35, "field"], [37, 41, "misc"], [40, 40, "university"], [43, 47, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[2, 3, 5, 6, "topic", "", false, false], [2, 3, 8, 10, "topic", "", false, false], [2, 3, 11, 11, "origin", "", false, false], [11, 11, 15, 17, "part-of", "", false, false], [24, 27, 11, 11, "part-of", "", false, false], [32, 32, 34, 35, "topic", "", false, false], [32, 32, 40, 40, "origin", "", false, false], [37, 41, 40, 40, "origin", "", false, false], [40, 40, 43, 47, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["He", "obtained", "a", "PhD", "in", "Radio", "Physics", "and", "Electronics", "from", "the", "Rajabazar", "Research", "College", ",", "University", "of", "Calcutta", ",", "as", "a", "student", "of", "the", "Indian", "Statistical", "Institute", "in", "1979", ",", "and", "another", "PhD", "in", "Electrical", "Engineering", "with", "a", "Diploma", "from", "Imperial", "College", ",", "University", "of", "London", ",", "in", "1982", "."], "sentence-detokenized": "He obtained a PhD in Radio Physics and Electronics from the Rajabazar Research College, University of Calcutta, as a student of the Indian Statistical Institute in 1979, and another PhD in Electrical Engineering with a Diploma from Imperial College, University of London, in 1982.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 17], [18, 20], [21, 26], [27, 34], [35, 38], [39, 50], [51, 55], [56, 59], [60, 69], [70, 78], [79, 86], [86, 87], [88, 98], [99, 101], [102, 110], [110, 111], [112, 114], [115, 116], [117, 124], [125, 127], [128, 131], [132, 138], [139, 150], [151, 160], [161, 163], [164, 168], [168, 169], [170, 173], [174, 181], [182, 185], [186, 188], [189, 199], [200, 211], [212, 216], [217, 218], [219, 226], [227, 231], [232, 240], [241, 248], [248, 249], [250, 260], [261, 263], [264, 270], [270, 271], [272, 274], [275, 279], [279, 280]]}
{"doc_key": "ai-dev-26", "ner": [[0, 1, "location"], [18, 20, "misc"], [26, 28, "misc"], [29, 31, "person"], [33, 34, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[18, 20, 0, 1, "temporal", "", false, false], [26, 28, 0, 1, "temporal", "", false, false], [29, 31, 26, 28, "role", "actor_in", false, false], [33, 34, 26, 28, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Expo", "II", "announced", "that", "several", "films", "that", "have", "not", "been", "seen", "in", "3D", "before", "will", "premiere", ",", "including", "The", "Diamond", "Wizard", "and", "Universal", "'s", "short", "film", "Hawaiian", "Nights", "with", "Mamie", "Van", "Doren", "and", "Pinky", "Lee", "."], "sentence-detokenized": "Expo II announced that several films that have not been seen in 3D before will premiere, including The Diamond Wizard and Universal's short film Hawaiian Nights with Mamie Van Doren and Pinky Lee.", "token2charspan": [[0, 4], [5, 7], [8, 17], [18, 22], [23, 30], [31, 36], [37, 41], [42, 46], [47, 50], [51, 55], [56, 60], [61, 63], [64, 66], [67, 73], [74, 78], [79, 87], [87, 88], [89, 98], [99, 102], [103, 110], [111, 117], [118, 121], [122, 131], [131, 133], [134, 139], [140, 144], [145, 153], [154, 160], [161, 165], [166, 171], [172, 175], [176, 181], [182, 185], [186, 191], [192, 195], [195, 196]]}
{"doc_key": "ai-dev-27", "ner": [[0, 1, "researcher"], [13, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 13, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Ulf", "Grenander", "proposed", "in", "1977", "the", "maximum", "subgrid", "problem", "as", "a", "simplified", "model", "for", "estimating", "the", "maximum", "likelihood", "of", "patterns", "in", "digitized", "images", "."], "sentence-detokenized": "Ulf Grenander proposed in 1977 the maximum subgrid problem as a simplified model for estimating the maximum likelihood of patterns in digitized images.", "token2charspan": [[0, 3], [4, 13], [14, 22], [23, 25], [26, 30], [31, 34], [35, 42], [43, 50], [51, 58], [59, 61], [62, 63], [64, 74], [75, 80], [81, 84], [85, 95], [96, 99], [100, 107], [108, 118], [119, 121], [122, 130], [131, 133], [134, 143], [144, 150], [150, 151]]}
{"doc_key": "ai-dev-28", "ner": [[0, 1, "product"], [3, 4, "product"], [6, 8, "product"], [10, 11, "product"], [13, 15, "product"], [17, 20, "product"], [27, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[27, 27, 0, 1, "part-of", "", false, false], [27, 27, 3, 4, "part-of", "", false, false], [27, 27, 6, 8, "part-of", "", false, false], [27, 27, 10, 11, "part-of", "", false, false], [27, 27, 13, 15, "part-of", "", false, false], [27, 27, 17, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["iPhone", "4S", ",", "iPad", "3", ",", "iPad", "Mini", "1G", ",", "iPad", "Air", ",", "iPad", "Pro", "1G", ",", "iPod", "Touch", "5", "G", "and", "later", "models", "all", "come", "with", "Siri", ",", "an", "advanced", "voice", "assistant", "."], "sentence-detokenized": "iPhone 4S, iPad 3, iPad Mini 1G, iPad Air, iPad Pro 1G, iPod Touch 5G and later models all come with Siri, an advanced voice assistant.", "token2charspan": [[0, 6], [7, 9], [9, 10], [11, 15], [16, 17], [17, 18], [19, 23], [24, 28], [29, 31], [31, 32], [33, 37], [38, 41], [41, 42], [43, 47], [48, 51], [52, 54], [54, 55], [56, 60], [61, 66], [67, 68], [68, 69], [70, 73], [74, 79], [80, 86], [87, 90], [91, 95], [96, 100], [101, 105], [105, 106], [107, 109], [110, 118], [119, 124], [125, 134], [134, 135]]}
{"doc_key": "ai-dev-29", "ner": [[7, 8, "metrics"], [11, 14, "metrics"], [16, 18, "metrics"], [39, 39, "metrics"], [44, 48, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 14, 39, 39, "named", "", false, false], [16, 18, 11, 14, "named", "", false, false], [39, 39, 44, 48, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["It", "is", "easy", "to", "verify", "that", "the", "logistic", "loss", "and", "the", "binary", "cross", "-tropy", "loss", "(", "log", "-", "loss", ")", "are", "in", "fact", "the", "same", "(", "up", "to", "the", "multiplicative", "constant", "math\\frac", "{", "1", "}", ")", ".", "{", "crossentropy", "loss", "is", "closely", "related", "to", "the", "Kullback", "-", "Leibler", "difference", "between", "the", "empirical", "and", "the", "predicted", "distribution", "."], "sentence-detokenized": "It is easy to verify that the logistic loss and the binary cross-tropy loss (log-loss) are in fact the same (up to the multiplicative constant math\\frac {1}). {crossentropy loss is closely related to the Kullback-Leibler difference between the empirical and the predicted distribution.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 13], [14, 20], [21, 25], [26, 29], [30, 38], [39, 43], [44, 47], [48, 51], [52, 58], [59, 64], [64, 70], [71, 75], [76, 77], [77, 80], [80, 81], [81, 85], [85, 86], [87, 90], [91, 93], [94, 98], [99, 102], [103, 107], [108, 109], [109, 111], [112, 114], [115, 118], [119, 133], [134, 142], [143, 152], [153, 154], [154, 155], [155, 156], [156, 157], [157, 158], [159, 160], [160, 172], [173, 177], [178, 180], [181, 188], [189, 196], [197, 199], [200, 203], [204, 212], [212, 213], [213, 220], [221, 231], [232, 239], [240, 243], [244, 253], [254, 257], [258, 261], [262, 271], [272, 284], [284, 285]]}
{"doc_key": "ai-dev-30", "ner": [[0, 4, "algorithm"], [11, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 0, 4, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "EM", "algorithm", "is", "used", "to", "find", "the", "(", "local", ")", "maximum", "likelihood", "parameters", "of", "a", "statistical", "model", "in", "cases", "where", "the", "equations", "can", "not", "be", "solved", "directly", "."], "sentence-detokenized": "The EM algorithm is used to find the (local) maximum likelihood parameters of a statistical model in cases where the equations cannot be solved directly.", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 19], [20, 24], [25, 27], [28, 32], [33, 36], [37, 38], [38, 43], [43, 44], [45, 52], [53, 63], [64, 74], [75, 77], [78, 79], [80, 91], [92, 97], [98, 100], [101, 106], [107, 112], [113, 116], [117, 126], [127, 130], [130, 133], [134, 136], [137, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-dev-31", "ner": [[10, 11, "task"], [14, 15, "task"], [19, 20, "task"], [22, 23, "task"], [26, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "research", "provided", "the", "basis", "for", "the", "development", "of", "modern", "speech", "synthesis", "techniques", ",", "blind", "readers", ",", "research", "into", "speech", "perception", "and", "speech", "recognition", ",", "and", "motor", "theory", "of", "speech", "perception", "."], "sentence-detokenized": "This research provided the basis for the development of modern speech synthesis techniques, blind readers, research into speech perception and speech recognition, and motor theory of speech perception.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 26], [27, 32], [33, 36], [37, 40], [41, 52], [53, 55], [56, 62], [63, 69], [70, 79], [80, 90], [90, 91], [92, 97], [98, 105], [105, 106], [107, 115], [116, 120], [121, 127], [128, 138], [139, 142], [143, 149], [150, 161], [161, 162], [163, 166], [167, 172], [173, 179], [180, 182], [183, 189], [190, 200], [200, 201]]}
{"doc_key": "ai-dev-32", "ner": [[0, 2, "product"], [3, 4, "misc"], [6, 6, "misc"], [10, 12, "misc"], [14, 14, "product"], [16, 16, "product"], [18, 18, "product"], [23, 23, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 4, 0, 2, "origin", "", false, false], [3, 4, 10, 12, "type-of", "", false, false], [3, 4, 14, 14, "related-to", "program_for", false, false], [3, 4, 16, 16, "related-to", "program_for", false, false], [3, 4, 18, 18, "related-to", "program_for", false, false], [3, 4, 23, 23, "related-to", "program_for", false, false], [6, 6, 3, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "Arduino", "Integrated", "Development", "Environment", "(", "IDE", ")", "is", "a", "cross", "-platform", "application", "(", "Windows", ",", "macOS", "and", "Linux", ")", "written", "in", "the", "Java", "programming", "language", "."], "sentence-detokenized": "The Arduino Integrated Development Environment (IDE) is a cross-platform application (Windows, macOS and Linux) written in the Java programming language.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 34], [35, 46], [47, 48], [48, 51], [51, 52], [53, 55], [56, 57], [58, 63], [63, 72], [73, 84], [85, 86], [86, 93], [93, 94], [95, 100], [101, 104], [105, 110], [110, 111], [112, 119], [120, 122], [123, 126], [127, 131], [132, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-dev-33", "ner": [[3, 6, "algorithm"], [13, 14, "field"], [17, 18, "researcher"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 6, 13, 14, "opposite", "", false, false], [17, 18, 13, 14, "related-to", "works_with", false, false], [20, 21, 13, 14, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "study", "of", "neural", "networks", "came", "to", "a", "standstill", "after", "the", "publication", "of", "machine", "learning", "studies", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", "."], "sentence-detokenized": "The study of neural networks came to a standstill after the publication of machine learning studies by Marvin Minsky and Seymour Papert (1969).", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 28], [29, 33], [34, 36], [37, 38], [39, 49], [50, 55], [56, 59], [60, 71], [72, 74], [75, 82], [83, 91], [92, 99], [100, 102], [103, 109], [110, 116], [117, 120], [121, 128], [129, 135], [136, 137], [137, 141], [141, 142], [142, 143]]}
{"doc_key": "ai-dev-34", "ner": [[16, 17, "organisation"], [19, 19, "organisation"], [22, 24, "country"], [26, 29, "organisation"], [32, 32, "country"], [34, 35, "organisation"], [38, 38, "country"], [40, 40, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[26, 29, 22, 24, "general-affiliation", "", false, false], [34, 35, 32, 32, "general-affiliation", "", false, false], [40, 40, 38, 38, "general-affiliation", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Only", "a", "few", "non-Japanese", "companies", "managed", "to", "survive", "in", "this", "market", ",", "the", "main", "ones", "being", "Adept", "Technology", ",", "St\u00e4ubli", ",", "the", "Swedish", "-", "Swiss", "company", "ABB", "Asea", "Brown", "Boveri", ",", "the", "German", "company", "KUKA", "Robotics", "and", "the", "Italian", "company", "Comau", "."], "sentence-detokenized": "Only a few non-Japanese companies managed to survive in this market, the main ones being Adept Technology, St\u00e4ubli, the Swedish-Swiss company ABB Asea Brown Boveri, the German company KUKA Robotics and the Italian company Comau.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 23], [24, 33], [34, 41], [42, 44], [45, 52], [53, 55], [56, 60], [61, 67], [67, 68], [69, 72], [73, 77], [78, 82], [83, 88], [89, 94], [95, 105], [105, 106], [107, 114], [114, 115], [116, 119], [120, 127], [127, 128], [128, 133], [134, 141], [142, 145], [146, 150], [151, 156], [157, 163], [163, 164], [165, 168], [169, 175], [176, 183], [184, 188], [189, 197], [198, 201], [202, 205], [206, 213], [214, 221], [222, 227], [227, 228]]}
{"doc_key": "ai-dev-35", "ner": [[9, 10, "conference"], [15, 16, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 16, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Research", "activities", "include", "an", "annual", "scientific", "conference", ",", "the", "RuleML", "Symposium", ",", "also", "known", "as", "RuleML", "for", "short", "."], "sentence-detokenized": "Research activities include an annual scientific conference, the RuleML Symposium, also known as RuleML for short.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 30], [31, 37], [38, 48], [49, 59], [59, 60], [61, 64], [65, 71], [72, 81], [81, 82], [83, 87], [88, 93], [94, 96], [97, 103], [104, 107], [108, 113], [113, 114]]}
{"doc_key": "ai-dev-36", "ner": [[8, 9, "field"], [11, 12, "field"], [14, 14, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Concepts", "are", "used", "as", "formal", "tools", "or", "models", "in", "mathematics", ",", "computer", "science", ",", "databases", "and", "artificial", "intelligence", ",", "where", "they", "are", "sometimes", "referred", "to", "as", "classes", ",", "schemas", "or", "categories", "."], "sentence-detokenized": "Concepts are used as formal tools or models in mathematics, computer science, databases and artificial intelligence, where they are sometimes referred to as classes, schemas or categories.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 20], [21, 27], [28, 33], [34, 36], [37, 43], [44, 46], [47, 58], [58, 59], [60, 68], [69, 76], [76, 77], [78, 87], [88, 91], [92, 102], [103, 115], [115, 116], [117, 122], [123, 127], [128, 131], [132, 141], [142, 150], [151, 153], [154, 156], [157, 164], [164, 165], [166, 173], [174, 176], [177, 187], [187, 188]]}
{"doc_key": "ai-dev-37", "ner": [[7, 10, "organisation"], [13, 16, "organisation"], [19, 19, "organisation"], [20, 23, "organisation"], [27, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "the", "recipient", "of", "awards", "from", "the", "American", "Psychological", "Association", ",", "the", "National", "Academy", "of", "Sciences", ",", "the", "Royal", "Society", "for", "Cognitive", "Neuroscience", ",", "and", "the", "American", "Association", "of", "Humanists", "."], "sentence-detokenized": "He is the recipient of awards from the American Psychological Association, the National Academy of Sciences, the Royal Society for Cognitive Neuroscience, and the American Association of Humanists.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 19], [20, 22], [23, 29], [30, 34], [35, 38], [39, 47], [48, 61], [62, 73], [73, 74], [75, 78], [79, 87], [88, 95], [96, 98], [99, 107], [107, 108], [109, 112], [113, 118], [119, 126], [127, 130], [131, 140], [141, 153], [153, 154], [155, 158], [159, 162], [163, 171], [172, 183], [184, 186], [187, 196], [196, 197]]}
{"doc_key": "ai-dev-38", "ner": [[4, 5, "person"], [7, 8, "person"], [10, 11, "person"], [17, 18, "person"], [24, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[24, 30, 17, 18, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "film", ",", "starring", "Harrison", "Ford", ",", "Rutger", "Hauer", "and", "Sean", "Young", ",", "is", "loosely", "based", "on", "Philip", "K", ".", "Dick", "'s", "novel", "\"", "Do", "Androids", "Dream", "of", "Electric", "Sheep", "?", "\"", ".", "(", "1968", ")", "."], "sentence-detokenized": "The film, starring Harrison Ford, Rutger Hauer and Sean Young, is loosely based on Philip K. Dick's novel \"Do Androids Dream of Electric Sheep?\". (1968).", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 18], [19, 27], [28, 32], [32, 33], [34, 40], [41, 46], [47, 50], [51, 55], [56, 61], [61, 62], [63, 65], [66, 73], [74, 79], [80, 82], [83, 89], [90, 91], [91, 92], [93, 97], [97, 99], [100, 105], [106, 107], [107, 109], [110, 118], [119, 124], [125, 127], [128, 136], [137, 142], [142, 143], [143, 144], [144, 145], [146, 147], [147, 151], [151, 152], [152, 153]]}
{"doc_key": "ai-dev-39", "ner": [[0, 1, "task"], [3, 5, "algorithm"], [10, 12, "field"], [14, 15, "task"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 3, 5, "usage", "", false, false], [0, 1, 10, 12, "part-of", "task_part_of_field", false, false], [0, 1, 14, 15, "part-of", "task_part_of_field", false, false], [0, 1, 17, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Image", "segmentation", "using", "k-means", "clustering", "algorithms", "has", "long", "been", "used", "for", "pattern", "recognition", ",", "object", "detection", "and", "medical", "imaging", "."], "sentence-detokenized": "Image segmentation using k-means clustering algorithms has long been used for pattern recognition, object detection and medical imaging.", "token2charspan": [[0, 5], [6, 18], [19, 24], [25, 32], [33, 43], [44, 54], [55, 58], [59, 63], [64, 68], [69, 73], [74, 77], [78, 85], [86, 97], [97, 98], [99, 105], [106, 115], [116, 119], [120, 127], [128, 135], [135, 136]]}
{"doc_key": "ai-dev-40", "ner": [[14, 14, "algorithm"], [17, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Overall", "sampling", "from", "the", "truncated", "normal", "can", "be", "achieved", "using", "approximations", "of", "the", "normal", "CDF", "and", "the", "probit", "function", ",", "and", "there", "is", "a", "codertnorm", "(", ")", "/", "code", "function", "in", "R", "for", "generating", "truncated", "normal", "samples", "."], "sentence-detokenized": "Overall sampling from the truncated normal can be achieved using approximations of the normal CDF and the probit function, and there is a codertnorm()/code function in R for generating truncated normal samples.", "token2charspan": [[0, 7], [8, 16], [17, 21], [22, 25], [26, 35], [36, 42], [43, 46], [47, 49], [50, 58], [59, 64], [65, 79], [80, 82], [83, 86], [87, 93], [94, 97], [98, 101], [102, 105], [106, 112], [113, 121], [121, 122], [123, 126], [127, 132], [133, 135], [136, 137], [138, 148], [148, 149], [149, 150], [150, 151], [151, 155], [156, 164], [165, 167], [168, 169], [170, 173], [174, 184], [185, 194], [195, 201], [202, 209], [209, 210]]}
{"doc_key": "ai-dev-41", "ner": [[10, 10, "university"], [12, 12, "university"], [14, 15, "university"], [17, 18, "university"], [7, 20, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "also", "received", "honorary", "degrees", "from", "the", "Universities", "of", "Newcastle", ",", "Surrey", ",", "Tel", "Aviv", ",", "Simon", "Fraser", "and", "Troms\u00f8", "."], "sentence-detokenized": "He has also received honorary degrees from the Universities of Newcastle, Surrey, Tel Aviv, Simon Fraser and Troms\u00f8.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 20], [21, 29], [30, 37], [38, 42], [43, 46], [47, 59], [60, 62], [63, 72], [72, 73], [74, 80], [80, 81], [82, 85], [86, 90], [90, 91], [92, 97], [98, 104], [105, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-dev-42", "ner": [[0, 1, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "Java", "implementation", "that", "uses", "zero", "-", "based", "array", "indices", "with", "a", "convenience", "method", "to", "print", "a", "resolved", "sequence", "of", "operations", ":"], "sentence-detokenized": "A Java implementation that uses zero-based array indices with a convenience method to print a resolved sequence of operations:", "token2charspan": [[0, 1], [2, 6], [7, 21], [22, 26], [27, 31], [32, 36], [36, 37], [37, 42], [43, 48], [49, 56], [57, 61], [62, 63], [64, 75], [76, 82], [83, 85], [86, 91], [92, 93], [94, 102], [103, 111], [112, 114], [115, 125], [125, 126]]}
{"doc_key": "ai-dev-43", "ner": [[7, 7, "metrics"], [10, 12, "metrics"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 12, 7, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Such", "networks", "are", "usually", "trained", "under", "the", "crossentropy", "(", "or", "cross", "-", "tropy", ")", "regime", ",", "which", "provides", "a", "non-linear", "variant", "of", "multinomial", "logistic", "regression", "."], "sentence-detokenized": "Such networks are usually trained under the crossentropy (or cross-tropy) regime, which provides a non-linear variant of multinomial logistic regression.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 25], [26, 33], [34, 39], [40, 43], [44, 56], [57, 58], [58, 60], [61, 66], [66, 67], [67, 72], [72, 73], [74, 80], [80, 81], [82, 87], [88, 96], [97, 98], [99, 109], [110, 117], [118, 120], [121, 132], [133, 141], [142, 152], [152, 153]]}
{"doc_key": "ai-dev-44", "ner": [[3, 3, "misc"], [5, 12, "conference"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["ACL", "has", "a", "European", "(", "European", "Division", "of", "the", "European", "Computational", "Linguistics", "Association", ")", "."], "sentence-detokenized": "ACL has a European (European Division of the European Computational Linguistics Association).", "token2charspan": [[0, 3], [4, 7], [8, 9], [10, 18], [19, 20], [20, 28], [29, 37], [38, 40], [41, 44], [45, 53], [54, 67], [68, 79], [80, 91], [91, 92], [92, 93]]}
{"doc_key": "ai-dev-45", "ner": [[3, 4, "researcher"], [6, 8, "researcher"], [22, 22, "misc"], [24, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 22, 22, "role", "", false, false], [6, 8, 22, 22, "role", "", false, false], [22, 22, 24, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "professors", ",", "Hal", "Abelson", "and", "Gerald", "Jay", "Sussman", ",", "chose", "to", "remain", "neutral", "-", "their", "group", "was", "referred", "to", "variously", "as", "Switzerland", "and", "Project", "MAC", "for", "the", "next", "30", "years", "."], "sentence-detokenized": "Two professors, Hal Abelson and Gerald Jay Sussman, chose to remain neutral - their group was referred to variously as Switzerland and Project MAC for the next 30 years.", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 27], [28, 31], [32, 38], [39, 42], [43, 50], [50, 51], [52, 57], [58, 60], [61, 67], [68, 75], [76, 77], [78, 83], [84, 89], [90, 93], [94, 102], [103, 105], [106, 115], [116, 118], [119, 130], [131, 134], [135, 142], [143, 146], [147, 150], [151, 154], [155, 159], [160, 162], [163, 168], [168, 169]]}
{"doc_key": "ai-dev-46", "ner": [[2, 3, "misc"], [5, 5, "researcher"], [9, 16, "university"], [32, 32, "organisation"], [25, 31, "organisation"], [19, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 5, 5, "temporal", "", false, false], [5, 5, 32, 32, "physical", "", false, false], [5, 5, 32, 32, "role", "", false, false], [5, 5, 25, 31, "role", "", false, false], [25, 31, 9, 16, "part-of", "", false, false], [19, 21, 25, 31, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["After", "completing", "his", "PhD", ",", "Ghahramani", "moved", "to", "the", "University", "of", "Toronto", "in", "1995", ",", "where", "he", "worked", "with", "Geoffrey", "Hinton", "as", "a", "postdoctoral", "fellow", "in", "the", "artificial", "intelligence", "lab", "at", "the", "ITRC", "."], "sentence-detokenized": "After completing his PhD, Ghahramani moved to the University of Toronto in 1995, where he worked with Geoffrey Hinton as a postdoctoral fellow in the artificial intelligence lab at the ITRC.", "token2charspan": [[0, 5], [6, 16], [17, 20], [21, 24], [24, 25], [26, 36], [37, 42], [43, 45], [46, 49], [50, 60], [61, 63], [64, 71], [72, 74], [75, 79], [79, 80], [81, 86], [87, 89], [90, 96], [97, 101], [102, 110], [111, 117], [118, 120], [121, 122], [123, 135], [136, 142], [143, 145], [146, 149], [150, 160], [161, 173], [174, 177], [178, 180], [181, 184], [185, 189], [189, 190]]}
{"doc_key": "ai-dev-47", "ner": [[24, 24, "metrics"], [23, 26, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[23, 26, 24, 24, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Subsequent", "work", "focused", "on", "solving", "these", "problems", ",", "but", "it", "was", "only", "with", "the", "advent", "of", "the", "modern", "computer", "and", "the", "popularisation", "of", "maximum", "likelihood", "(", "MLE", ")", "parameterisation", "methods", "that", "research", "really", "took", "off", "."], "sentence-detokenized": "Subsequent work focused on solving these problems, but it was only with the advent of the modern computer and the popularisation of maximum likelihood (MLE) parameterisation methods that research really took off.", "token2charspan": [[0, 10], [11, 15], [16, 23], [24, 26], [27, 34], [35, 40], [41, 49], [49, 50], [51, 54], [55, 57], [58, 61], [62, 66], [67, 71], [72, 75], [76, 82], [83, 85], [86, 89], [90, 96], [97, 105], [106, 109], [110, 113], [114, 128], [129, 131], [132, 139], [140, 150], [151, 152], [152, 155], [155, 156], [157, 173], [174, 181], [182, 186], [187, 195], [196, 202], [203, 207], [208, 211], [211, 212]]}
{"doc_key": "ai-dev-48", "ner": [[5, 6, "person"], [9, 10, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "series", "was", "produced", "by", "David", "Fincher", "and", "starred", "Kevin", "Spacey", "."], "sentence-detokenized": "The series was produced by David Fincher and starred Kevin Spacey.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 26], [27, 32], [33, 40], [41, 44], [45, 52], [53, 58], [59, 65], [65, 66]]}
{"doc_key": "ai-dev-49", "ner": [[16, 16, "metrics"], [21, 21, "algorithm"], [24, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 21, 24, 30, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Due", "to", "computational", "power", "limitations", ",", "current", "in", "silico", "methods", "typically", "have", "to", "trade", "speed", "for", "accuracy", ";", "e.g.", "use", "fast", "protein", "docking", "methods", "instead", "of", "computationally", "expensive", "free", "energy", "calculations", "."], "sentence-detokenized": "Due to computational power limitations, current in silico methods typically have to trade speed for accuracy; e.g. use fast protein docking methods instead of computationally expensive free energy calculations.", "token2charspan": [[0, 3], [4, 6], [7, 20], [21, 26], [27, 38], [38, 39], [40, 47], [48, 50], [51, 57], [58, 65], [66, 75], [76, 80], [81, 83], [84, 89], [90, 95], [96, 99], [100, 108], [108, 109], [110, 114], [115, 118], [119, 123], [124, 131], [132, 139], [140, 147], [148, 155], [156, 158], [159, 174], [175, 184], [185, 189], [190, 196], [197, 209], [209, 210]]}
{"doc_key": "ai-dev-50", "ner": [[5, 7, "country"], [9, 9, "country"], [11, 11, "country"], [13, 13, "country"], [15, 15, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "had", "over", "30", "locations", "in", "the", "US", ",", "Canada", ",", "Mexico", ",", "Brazil", "and", "Argentina", "."], "sentence-detokenized": "He had over 30 locations in the US, Canada, Mexico, Brazil and Argentina.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 24], [25, 27], [28, 31], [32, 34], [34, 35], [36, 42], [42, 43], [44, 50], [50, 51], [52, 58], [59, 62], [63, 72], [72, 73]]}
{"doc_key": "ai-dev-51", "ner": [[5, 6, "field"], [11, 13, "product"], [15, 17, "algorithm"], [24, 25, "task"], [27, 28, "task"], [32, 33, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 13, 5, 6, "part-of", "", false, false], [11, 13, 15, 17, "usage", "", false, false], [24, 25, 5, 6, "part-of", "task_part_of_field", false, false], [24, 25, 32, 33, "related-to", "performs", false, false], [27, 28, 5, 6, "part-of", "task_part_of_field", false, false], [27, 28, 32, 33, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["An", "example", "of", "a", "typical", "computer", "vision", "computation", "contour", "for", "a", "face", "recognition", "system", "using", "k", "-", "NN", ",", "including", "the", "pre-processing", "steps", "of", "feature", "extraction", "and", "dimensionality", "reduction", "(", "typically", "implemented", "with", "OpenCV", ")", ":"], "sentence-detokenized": "An example of a typical computer vision computation contour for a face recognition system using k -NN, including the pre-processing steps of feature extraction and dimensionality reduction (typically implemented with OpenCV):", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 23], [24, 32], [33, 39], [40, 51], [52, 59], [60, 63], [64, 65], [66, 70], [71, 82], [83, 89], [90, 95], [96, 97], [98, 99], [99, 101], [101, 102], [103, 112], [113, 116], [117, 131], [132, 137], [138, 140], [141, 148], [149, 159], [160, 163], [164, 178], [179, 188], [189, 190], [190, 199], [200, 211], [212, 216], [217, 223], [223, 224], [224, 225]]}
{"doc_key": "ai-dev-52", "ner": [[9, 12, "algorithm"], [14, 14, "misc"], [16, 17, "misc"], [19, 19, "misc"], [23, 23, "programlang"], [25, 25, "product"], [29, 29, "algorithm"], [31, 32, "misc"], [34, 34, "misc"], [36, 36, "misc"], [38, 38, "misc"], [44, 44, "misc"], [46, 47, "misc"], [49, 50, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "has", "a", "rich", "set", "of", "features", ",", "libraries", "for", "constraint", "logic", "programming", ",", "multi-versioning", ",", "unit", "testing", ",", "GUI", ",", "interfacing", "with", "Java", ",", "ODBC", "and", "others", ",", "scripting", ",", "web", "server", ",", "SGML", ",", "RDF", ",", "RDFS", ",", "developer", "tools", "(", "including", "IDE", "with", "GUI", "silo", "and", "GUI", "profiler", ")", "and", "extensive", "documentation", "."], "sentence-detokenized": "It has a rich set of features, libraries for constraint logic programming, multi-versioning, unit testing, GUI, interfacing with Java, ODBC and others, scripting, web server, SGML, RDF, RDFS, developer tools (including IDE with GUI silo and GUI profiler) and extensive documentation.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 13], [14, 17], [18, 20], [21, 29], [29, 30], [31, 40], [41, 44], [45, 55], [56, 61], [62, 73], [73, 74], [75, 91], [91, 92], [93, 97], [98, 105], [105, 106], [107, 110], [110, 111], [112, 123], [124, 128], [129, 133], [133, 134], [135, 139], [140, 143], [144, 150], [150, 151], [152, 161], [161, 162], [163, 166], [167, 173], [173, 174], [175, 179], [179, 180], [181, 184], [184, 185], [186, 190], [190, 191], [192, 201], [202, 207], [208, 209], [209, 218], [219, 222], [223, 227], [228, 231], [232, 236], [237, 240], [241, 244], [245, 253], [253, 254], [255, 258], [259, 268], [269, 282], [282, 283]]}
{"doc_key": "ai-dev-53", "ner": [[0, 2, "field"], [4, 7, "field"], [10, 13, "misc"], [15, 17, "misc"], [19, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 13, 0, 2, "part-of", "", true, false], [10, 13, 4, 7, "part-of", "", false, false], [10, 13, 19, 22, "type-of", "", false, false], [15, 17, 0, 2, "part-of", "", false, false], [15, 17, 4, 7, "part-of", "", false, false], [15, 17, 19, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "computer", "vision", "and", "image", "processing", ",", "the", "concept", "of", "spatial", "representation", "of", "scale", "and", "Gaussian", "derivative", "operators", "is", "a", "canonical", "multidimensional", "representation", "."], "sentence-detokenized": "In computer vision and image processing, the concept of spatial representation of scale and Gaussian derivative operators is a canonical multidimensional representation.", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 22], [23, 28], [29, 39], [39, 40], [41, 44], [45, 52], [53, 55], [56, 63], [64, 78], [79, 81], [82, 87], [88, 91], [92, 100], [101, 111], [112, 121], [122, 124], [125, 126], [127, 136], [137, 153], [154, 168], [168, 169]]}
{"doc_key": "ai-dev-54", "ner": [[5, 10, "organisation"], [19, 23, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 10, 19, 23, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "also", "President", "of", "the", "Neural", "Information", "Processing", "Systems", "Foundation", ",", "a", "non-profit", "organisation", "that", "oversees", "the", "annual", "Neural", "Information", "Processing", "Systems", "Conference", "."], "sentence-detokenized": "He is also President of the Neural Information Processing Systems Foundation, a non-profit organisation that oversees the annual Neural Information Processing Systems Conference.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 20], [21, 23], [24, 27], [28, 34], [35, 46], [47, 57], [58, 65], [66, 76], [76, 77], [78, 79], [80, 90], [91, 103], [104, 108], [109, 117], [118, 121], [122, 128], [129, 135], [136, 147], [148, 158], [159, 166], [167, 177], [177, 178]]}
{"doc_key": "ai-dev-55", "ner": [[1, 2, "task"], [5, 9, "metrics"], [11, 14, "misc"], [16, 17, "task"], [19, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 5, 9, "usage", "", false, false], [5, 9, 11, 14, "type-of", "", false, false], [16, 17, 19, 22, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["For", "regression", "analysis", "problems", ",", "the", "error", "squared", "can", "be", "used", "as", "a", "loss", "function", ";", "for", "classification", ",", "cross", "-entropy", "can", "be", "used", "."], "sentence-detokenized": "For regression analysis problems, the error squared can be used as a loss function; for classification, cross-entropy can be used.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 32], [32, 33], [34, 37], [38, 43], [44, 51], [52, 55], [56, 58], [59, 63], [64, 66], [67, 68], [69, 73], [74, 82], [82, 83], [84, 87], [88, 102], [102, 103], [104, 109], [109, 117], [118, 121], [122, 124], [125, 129], [129, 130]]}
{"doc_key": "ai-dev-56", "ner": [[0, 0, "researcher"], [19, 22, "conference"], [24, 29, "conference"], [40, 41, "university"], [43, 43, "field"], [52, 56, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 19, 22, "role", "", false, false], [0, 0, 40, 41, "physical", "", false, false], [0, 0, 40, 41, "role", "", false, false], [0, 0, 52, 56, "role", "", false, false], [19, 22, 24, 29, "named", "same", false, false], [40, 41, 43, 43, "related-to", "subject_of_study_at", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Lafferty", "served", "in", "many", "prestigious", "positions", ",", "including", ":", "(", "1", ")", "Co-Chair", "and", "General", "Co-", "Chair", "of", "the", "Neural", "Information", "Processing", "Systems", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", ")", "Foundation", "Conference", "Program", ";", "2", ")", "Co-", "Director", "of", "CMU", "'s", "new", "PhD", "program", ";", "3", ")", "Associate", "Editor", "of", "the", "Journal", "of", "Machine", "Learning", "Research", "."], "sentence-detokenized": "Lafferty served in many prestigious positions, including: (1) Co-Chair and General Co-Chair of the Neural Information Processing Systems (Conference on Neural Information Processing Systems) Foundation Conference Program; 2) Co-Director of CMU's new PhD program; 3) Associate Editor of the Journal of Machine Learning Research.", "token2charspan": [[0, 8], [9, 15], [16, 18], [19, 23], [24, 35], [36, 45], [45, 46], [47, 56], [56, 57], [58, 59], [59, 60], [60, 61], [62, 70], [71, 74], [75, 82], [83, 86], [86, 91], [92, 94], [95, 98], [99, 105], [106, 117], [118, 128], [129, 136], [137, 138], [138, 148], [149, 151], [152, 158], [159, 170], [171, 181], [182, 189], [189, 190], [191, 201], [202, 212], [213, 220], [220, 221], [222, 223], [223, 224], [225, 228], [228, 236], [237, 239], [240, 243], [243, 245], [246, 249], [250, 253], [254, 261], [261, 262], [263, 264], [264, 265], [266, 275], [276, 282], [283, 285], [286, 289], [290, 297], [298, 300], [301, 308], [309, 317], [318, 326], [326, 327]]}
{"doc_key": "ai-dev-57", "ner": [[0, 1, "misc"], [5, 5, "algorithm"], [7, 7, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 0, 1, "type-of", "", false, false], [7, 7, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Convex", "algorithms", ",", "such", "as", "AdaBoost", "and", "LogitBoost", ",", "can", "get", "defeated", "by", "random", "noise", ",", "so", "they", "fail", "to", "learn", "basic", "and", "learnable", "combinations", "of", "weak", "hypothesis", "."], "sentence-detokenized": "Convex algorithms, such as AdaBoost and LogitBoost, can get defeated by random noise, so they fail to learn basic and learnable combinations of weak hypothesis.", "token2charspan": [[0, 6], [7, 17], [17, 18], [19, 23], [24, 26], [27, 35], [36, 39], [40, 50], [50, 51], [52, 55], [56, 59], [60, 68], [69, 71], [72, 78], [79, 84], [84, 85], [86, 88], [89, 93], [94, 98], [99, 101], [102, 107], [108, 113], [114, 117], [118, 127], [128, 140], [141, 143], [144, 148], [149, 159], [159, 160]]}
{"doc_key": "ai-dev-58", "ner": [[0, 0, "product"], [3, 7, "product"], [10, 19, "algorithm"], [20, 21, "algorithm"], [23, 27, "task"], [30, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 7, "type-of", "", false, false], [0, 0, 10, 19, "usage", "", false, false], [0, 0, 20, 21, "usage", "", false, false], [20, 21, 23, 27, "related-to", "used_for", true, false], [20, 21, 30, 33, "related-to", "used_for", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Apertium", "is", "a", "surface", "translation", "machine", "translation", "system", "that", "uses", "finite", "-", "state", "transformers", "for", "all", "its", "lexical", "transformations", "and", "embedded", "Markov", "models", "to", "label", "parts", "of", "words", "or", "to", "decode", "categories", "of", "words", "."], "sentence-detokenized": "Apertium is a surface translation machine translation system that uses finite-state transformers for all its lexical transformations and embedded Markov models to label parts of words or to decode categories of words.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 21], [22, 33], [34, 41], [42, 53], [54, 60], [61, 65], [66, 70], [71, 77], [77, 78], [78, 83], [84, 96], [97, 100], [101, 104], [105, 108], [109, 116], [117, 132], [133, 136], [137, 145], [146, 152], [153, 159], [160, 162], [163, 168], [169, 174], [175, 177], [178, 183], [184, 186], [187, 189], [190, 196], [197, 207], [208, 210], [211, 216], [216, 217]]}
{"doc_key": "ai-dev-59", "ner": [[0, 2, "misc"], [13, 14, "metrics"], [27, 28, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 13, 14, "related-to", "", true, false], [13, 14, 27, 28, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "natural", "gradient", "mathE", "f", "(", "x", ")", "/", "math", "corresponding", "to", "the", "Fisher", "infometric", "(", "a", "measure", "of", "the", "informational", "distance", "between", "probability", "distributions", "and", "the", "relative", "entropy", "curve", ")", "is", "now", "as", "follows"], "sentence-detokenized": "The natural gradient mathE f (x)/math corresponding to the Fisher infometric (a measure of the informational distance between probability distributions and the relative entropy curve) is now as follows", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 26], [27, 28], [29, 30], [30, 31], [31, 32], [32, 33], [33, 37], [38, 51], [52, 54], [55, 58], [59, 65], [66, 76], [77, 78], [78, 79], [80, 87], [88, 90], [91, 94], [95, 108], [109, 117], [118, 125], [126, 137], [138, 151], [152, 155], [156, 159], [160, 168], [169, 176], [177, 182], [182, 183], [184, 186], [187, 190], [191, 193], [194, 201]]}
{"doc_key": "ai-dev-60", "ner": [[0, 4, "programlang"], [9, 11, "product"], [13, 13, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 11, 0, 4, "origin", "", false, false], [13, 13, 0, 4, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "S", "programming", "language", "is", "inspired", "by", "the", "systems", "S'", "-", "PLUS", "and", "R."], "sentence-detokenized": "The S programming language is inspired by the systems S'-PLUS and R.", "token2charspan": [[0, 3], [4, 5], [6, 17], [18, 26], [27, 29], [30, 38], [39, 41], [42, 45], [46, 53], [54, 56], [56, 57], [57, 61], [62, 65], [66, 68]]}
{"doc_key": "ai-dev-61", "ner": [[5, 5, "product"], [10, 10, "product"], [12, 14, "product"], [18, 20, "researcher"], [22, 23, "researcher"], [25, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 10, 10, "named", "same", false, false], [12, 14, 10, 10, "origin", "derived_from", false, false], [12, 14, 18, 20, "origin", "", false, false], [12, 14, 22, 23, "origin", "", false, false], [12, 14, 25, 26, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "most", "influential", "application", "of", "Planner", "was", "a", "subset", "of", "Planner", "called", "Micro", "-", "Planner", ",", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "."], "sentence-detokenized": "The most influential application of Planner was a subset of Planner called Micro-Planner, implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd.", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 32], [33, 35], [36, 43], [44, 47], [48, 49], [50, 56], [57, 59], [60, 67], [68, 74], [75, 80], [80, 81], [81, 88], [88, 89], [90, 101], [102, 104], [105, 111], [112, 115], [116, 123], [123, 124], [125, 131], [132, 140], [141, 144], [145, 150], [151, 159], [159, 160]]}
{"doc_key": "ai-dev-62", "ner": [[4, 6, "country"], [8, 10, "researcher"], [20, 20, "misc"], [19, 26, "university"], [33, 34, "misc"], [45, 45, "misc"], [47, 51, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [[8, 10, 4, 6, "general-affiliation", "from_country", false, false], [19, 26, 20, 20, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "1779", ",", "the", "German", "-", "Danish", "scientist", "Christian", "Gottlieb", "Kratzenstein", "won", "first", "prize", "in", "a", "competition", "announced", "by", "the", "Russian", "Imperial", "Academy", "of", "Sciences", "and", "Arts", "for", "his", "models", "of", "the", "human", "vocal", "apparatus", ",", "with", "which", "he", "was", "able", "to", "produce", "five", "long", "vowels", "(", "in", "the", "international", "phonetic", "alphabet", ":"], "sentence-detokenized": "In 1779, the German-Danish scientist Christian Gottlieb Kratzenstein won first prize in a competition announced by the Russian Imperial Academy of Sciences and Arts for his models of the human vocal apparatus, with which he was able to produce five long vowels (in the international phonetic alphabet:", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 19], [19, 20], [20, 26], [27, 36], [37, 46], [47, 55], [56, 68], [69, 72], [73, 78], [79, 84], [85, 87], [88, 89], [90, 101], [102, 111], [112, 114], [115, 118], [119, 126], [127, 135], [136, 143], [144, 146], [147, 155], [156, 159], [160, 164], [165, 168], [169, 172], [173, 179], [180, 182], [183, 186], [187, 192], [193, 198], [199, 208], [208, 209], [210, 214], [215, 220], [221, 223], [224, 227], [228, 232], [233, 235], [236, 243], [244, 248], [249, 253], [254, 260], [261, 262], [262, 264], [265, 268], [269, 282], [283, 291], [292, 300], [300, 301]]}
{"doc_key": "ai-dev-63", "ner": [[3, 4, "product"], [6, 7, "misc"], [10, 15, "misc"], [31, 33, "misc"], [53, 54, "task"], [59, 60, "product"], [62, 62, "product"], [66, 67, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 4, 59, 60, "related-to", "supports_program", false, false], [3, 4, 62, 62, "related-to", "supports_program", false, false], [6, 7, 3, 4, "part-of", "", false, false], [10, 15, 3, 4, "part-of", "", false, false], [31, 33, 3, 4, "part-of", "", false, false], [53, 54, 3, 4, "part-of", "", false, false], [66, 67, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["New", "features", "in", "Office", "XP", "include", "smart", "labels", ",", "a", "menu", "-", "based", "search", "function", "that", "recognises", "different", "text", "styles", "in", "a", "document", "so", "users", "can", "perform", "additional", "tasks", ";", "a", "task", "pane", "interface", "that", "consolidates", "popular", "menu", "bar", "commands", "to", "the", "right", "of", "the", "screen", "for", "easy", ",", "quick", "access", ";", "new", "document", "collaboration", "capabilities", ",", "support", "for", "MSN", "Groups", "and", "SharePoint", ";", "and", "integrated", "handwriting", "recognition", "and", "speech", "recognition", "capabilities", "."], "sentence-detokenized": "New features in Office XP include smart labels, a menu-based search function that recognises different text styles in a document so users can perform additional tasks; a task pane interface that consolidates popular menu bar commands to the right of the screen for easy, quick access; new document collaboration capabilities, support for MSN Groups and SharePoint; and integrated handwriting recognition and speech recognition capabilities.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 22], [23, 25], [26, 33], [34, 39], [40, 46], [46, 47], [48, 49], [50, 54], [54, 55], [55, 60], [61, 67], [68, 76], [77, 81], [82, 92], [93, 102], [103, 107], [108, 114], [115, 117], [118, 119], [120, 128], [129, 131], [132, 137], [138, 141], [142, 149], [150, 160], [161, 166], [166, 167], [168, 169], [170, 174], [175, 179], [180, 189], [190, 194], [195, 207], [208, 215], [216, 220], [221, 224], [225, 233], [234, 236], [237, 240], [241, 246], [247, 249], [250, 253], [254, 260], [261, 264], [265, 269], [269, 270], [271, 276], [277, 283], [283, 284], [285, 288], [289, 297], [298, 311], [312, 324], [324, 325], [326, 333], [334, 337], [338, 341], [342, 348], [349, 352], [353, 363], [363, 364], [365, 368], [369, 379], [380, 391], [392, 403], [404, 407], [408, 414], [415, 426], [427, 439], [439, 440]]}
{"doc_key": "ai-dev-64", "ner": [[11, 12, "algorithm"], [13, 16, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 13, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "many", "applications", ",", "the", "units", "of", "these", "networks", "use", "a", "sigmoid", "function", "as", "the", "activation", "function", "."], "sentence-detokenized": "In many applications, the units of these networks use a sigmoid function as the activation function.", "token2charspan": [[0, 2], [3, 7], [8, 20], [20, 21], [22, 25], [26, 31], [32, 34], [35, 40], [41, 49], [50, 53], [54, 55], [56, 63], [64, 72], [73, 75], [76, 79], [80, 90], [91, 99], [99, 100]]}
{"doc_key": "ai-dev-65", "ner": [[3, 3, "researcher"], [12, 17, "organisation"], [29, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 12, 17, "role", "", false, false], [3, 3, 29, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2001", ",", "Mehler", "was", "elected", "an", "Honorary", "Foreign", "Fellow", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "and", "in", "2003", "he", "was", "elected", "a", "Fellow", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In 2001, Mehler was elected an Honorary Foreign Fellow of the American Academy of Arts and Sciences, and in 2003 he was elected a Fellow of the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 27], [28, 30], [31, 39], [40, 47], [48, 54], [55, 57], [58, 61], [62, 70], [71, 78], [79, 81], [82, 86], [87, 90], [91, 99], [99, 100], [101, 104], [105, 107], [108, 112], [113, 115], [116, 119], [120, 127], [128, 129], [130, 136], [137, 139], [140, 143], [144, 152], [153, 164], [165, 168], [169, 172], [173, 184], [185, 187], [188, 195], [195, 196]]}
{"doc_key": "ai-dev-66", "ner": [[3, 6, "task"], [8, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 6, 8, 10, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Extending", "this", "concept", "to", "non", "-binary", "classifications", "yields", "a", "confusion", "matrix", "."], "sentence-detokenized": "Extending this concept to non-binary classifications yields a confusion matrix.", "token2charspan": [[0, 9], [10, 14], [15, 22], [23, 25], [26, 29], [29, 36], [37, 52], [53, 59], [60, 61], [62, 71], [72, 78], [78, 79]]}
{"doc_key": "ai-dev-67", "ner": [[0, 2, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "maximum", "likelihood", "calculation", "provides", "an", "up", "-", "to", "-", "date", "estimate", "of", "the", "measurement", "noise", "variability", "."], "sentence-detokenized": "The maximum likelihood calculation provides an up-to-date estimate of the measurement noise variability.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 34], [35, 43], [44, 46], [47, 49], [49, 50], [50, 52], [52, 53], [53, 57], [58, 66], [67, 69], [70, 73], [74, 85], [86, 91], [92, 103], [103, 104]]}
{"doc_key": "ai-dev-68", "ner": [[0, 1, "field"], [4, 4, "algorithm"], [7, 7, "field"], [10, 11, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 7, 7, "usage", "", true, false], [4, 4, 10, 11, "related-to", "", true, false], [7, 7, 0, 1, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "learning", "is", "a", "perceptron", "algorithm", "for", "guided", "learning", "of", "binary", "classification", "."], "sentence-detokenized": "Machine learning is a perceptron algorithm for guided learning of binary classification.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 21], [22, 32], [33, 42], [43, 46], [47, 53], [54, 62], [63, 65], [66, 72], [73, 87], [87, 88]]}
{"doc_key": "ai-dev-69", "ner": [[7, 8, "field"], [10, 10, "field"], [13, 19, "conference"], [22, 26, "conference"], [29, 35, "conference"], [38, 42, "conference"], [45, 49, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 19, 7, 8, "topic", "", false, false], [13, 19, 10, 10, "topic", "", false, false], [22, 26, 7, 8, "topic", "", false, false], [22, 26, 10, 10, "topic", "", false, false], [29, 35, 7, 8, "topic", "", false, false], [29, 35, 10, 10, "topic", "", false, false], [38, 42, 7, 8, "topic", "", false, false], [38, 42, 10, 10, "topic", "", false, false], [45, 49, 7, 8, "topic", "", false, false], [45, 49, 10, 10, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["He", "has", "also", "chaired", "several", "conferences", "on", "machine", "learning", "and", "vision", ",", "including", "the", "Conference", "on", "Neural", "Information", "Processing", "Systems", ",", "the", "International", "Conference", "on", "Learning", "Representations", ",", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "the", "International", "Conference", "on", "Computer", "Vision", "and", "the", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "He has also chaired several conferences on machine learning and vision, including the Conference on Neural Information Processing Systems, the International Conference on Learning Representations, the Conference on Computer Vision and Pattern Recognition, the International Conference on Computer Vision and the European Conference on Computer Vision.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 27], [28, 39], [40, 42], [43, 50], [51, 59], [60, 63], [64, 70], [70, 71], [72, 81], [82, 85], [86, 96], [97, 99], [100, 106], [107, 118], [119, 129], [130, 137], [137, 138], [139, 142], [143, 156], [157, 167], [168, 170], [171, 179], [180, 195], [195, 196], [197, 200], [201, 211], [212, 214], [215, 223], [224, 230], [231, 234], [235, 242], [243, 254], [254, 255], [256, 259], [260, 273], [274, 284], [285, 287], [288, 296], [297, 303], [304, 307], [308, 311], [312, 320], [321, 331], [332, 334], [335, 343], [344, 350], [350, 351]]}
{"doc_key": "ai-dev-70", "ner": [[0, 2, "algorithm"], [9, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "concentration", "algorithm", "has", "also", "been", "used", "for", "the", "facial", "recognition", "system", "in", "the", "case", "of", "video", "sequences", "."], "sentence-detokenized": "The concentration algorithm has also been used for the facial recognition system in the case of video sequences.", "token2charspan": [[0, 3], [4, 17], [18, 27], [28, 31], [32, 36], [37, 41], [42, 46], [47, 50], [51, 54], [55, 61], [62, 73], [74, 80], [81, 83], [84, 87], [88, 92], [93, 95], [96, 101], [102, 111], [111, 112]]}
{"doc_key": "ai-dev-71", "ner": [[0, 2, "task"], [7, 7, "organisation"], [17, 17, "conference"], [22, 26, "academicjournal"], [29, 29, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[17, 17, 0, 2, "topic", "", false, false], [17, 17, 7, 7, "origin", "", false, false], [22, 26, 0, 2, "topic", "", false, false], [22, 26, 7, 7, "origin", "", true, false], [29, 29, 22, 26, "role", "edited_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Dissemination", "of", "information", "is", "also", "part", "of", "ELRA", "'s", "tasks", ",", "both", "through", "the", "organisation", "of", "the", "LREC", "conference", "and", "through", "the", "Language", "Resources", "and", "Evaluation", "Journal", "published", "by", "Springer", "."], "sentence-detokenized": "Dissemination of information is also part of ELRA's tasks, both through the organisation of the LREC conference and through the Language Resources and Evaluation Journal published by Springer.", "token2charspan": [[0, 13], [14, 16], [17, 28], [29, 31], [32, 36], [37, 41], [42, 44], [45, 49], [49, 51], [52, 57], [57, 58], [59, 63], [64, 71], [72, 75], [76, 88], [89, 91], [92, 95], [96, 100], [101, 111], [112, 115], [116, 123], [124, 127], [128, 136], [137, 146], [147, 150], [151, 161], [162, 169], [170, 179], [180, 182], [183, 191], [191, 192]]}
{"doc_key": "ai-dev-72", "ner": [[0, 10, "field"], [12, 14, "field"], [17, 19, "field"], [21, 24, "field"], [58, 59, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 10, 58, 59, "named", "", false, false], [17, 19, 0, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "the", "theory", "of", "linear", "time", "invariant", "(", "LTI", ")", "systems", ",", "in", "control", "theory", "and", "in", "digital", "signal", "processing", "or", "signal", "processing", ",", "the", "relationship", "between", "the", "input", "signal", ",", "math", "\\", "displaystyle", "x", "(", "t", ")", "/", "math", ",", "and", "the", "output", "signal", ",", "math", "\\", "displaystyle", "y", "(", "t", ")", "/", "math", ",", "of", "an", "LTI", "system", "is", "governed", "by", "a", "convolution", "operation", ":"], "sentence-detokenized": "In the theory of linear time invariant (LTI) systems, in control theory and in digital signal processing or signal processing, the relationship between the input signal, math\\ displaystyle x(t)/math, and the output signal, math\\ displaystyle y(t)/math, of an LTI system is governed by a convolution operation:", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 23], [24, 28], [29, 38], [39, 40], [40, 43], [43, 44], [45, 52], [52, 53], [54, 56], [57, 64], [65, 71], [72, 75], [76, 78], [79, 86], [87, 93], [94, 104], [105, 107], [108, 114], [115, 125], [125, 126], [127, 130], [131, 143], [144, 151], [152, 155], [156, 161], [162, 168], [168, 169], [170, 174], [174, 175], [176, 188], [189, 190], [190, 191], [191, 192], [192, 193], [193, 194], [194, 198], [198, 199], [200, 203], [204, 207], [208, 214], [215, 221], [221, 222], [223, 227], [227, 228], [229, 241], [242, 243], [243, 244], [244, 245], [245, 246], [246, 247], [247, 251], [251, 252], [253, 255], [256, 258], [259, 262], [263, 269], [270, 272], [273, 281], [282, 284], [285, 286], [287, 298], [299, 308], [308, 309]]}
{"doc_key": "ai-dev-73", "ner": [[15, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 25, "field"], [27, 30, "field"], [32, 33, "product"], [35, 36, "field"], [38, 38, "field"], [40, 41, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Because", "of", "its", "generality", ",", "it", "is", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "game", "theory", ",", "control", "theory", ",", "operation", "theory", ",", "information", "theory", ",", "simulation", "-", "based", "optimization", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Because of its generality, it is studied in many other disciplines, such as game theory, control theory, operation theory, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 25], [25, 26], [27, 29], [30, 32], [33, 40], [41, 43], [44, 48], [49, 54], [55, 66], [66, 67], [68, 72], [73, 75], [76, 80], [81, 87], [87, 88], [89, 96], [97, 103], [103, 104], [105, 114], [115, 121], [121, 122], [123, 134], [135, 141], [141, 142], [143, 153], [153, 154], [154, 159], [160, 172], [172, 173], [174, 185], [186, 193], [193, 194], [195, 200], [201, 213], [213, 214], [215, 225], [226, 229], [230, 237], [238, 248], [248, 249]]}
{"doc_key": "ai-dev-74", "ner": [[0, 2, "algorithm"], [12, 13, "field"], [24, 25, "algorithm"], [29, 30, "algorithm"], [33, 33, "algorithm"], [34, 36, "researcher"], [38, 39, "researcher"], [41, 43, "researcher"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[12, 13, 0, 2, "usage", "", true, false], [24, 25, 12, 13, "part-of", "", true, false], [29, 30, 12, 13, "part-of", "", true, false], [33, 33, 12, 13, "part-of", "", true, false]], "relations_mapping_to_source": [0, 2, 3, 4], "sentence": ["Stochastic", "gradient", "descent", "is", "a", "popular", "algorithm", "for", "training", "a", "variety", "of", "machine", "learning", "models", ",", "including", "(", "linear", ")", "support", "vector", "machines", ",", "logistic", "regression", "(", "see", "e.g.", "Vowpal", "Wabbit", ")", "and", "graphical", "models.Jenny", "Rose", "Finkel", ",", "Alex", "Kleeman", ",", "Christopher", "D.", "Manning", "(", "2008", ")", "."], "sentence-detokenized": "Stochastic gradient descent is a popular algorithm for training a variety of machine learning models, including (linear) support vector machines, logistic regression (see e.g. Vowpal Wabbit) and graphical models.Jenny Rose Finkel, Alex Kleeman, Christopher D. Manning (2008).", "token2charspan": [[0, 10], [11, 19], [20, 27], [28, 30], [31, 32], [33, 40], [41, 50], [51, 54], [55, 63], [64, 65], [66, 73], [74, 76], [77, 84], [85, 93], [94, 100], [100, 101], [102, 111], [112, 113], [113, 119], [119, 120], [121, 128], [129, 135], [136, 144], [144, 145], [146, 154], [155, 165], [166, 167], [167, 170], [171, 175], [176, 182], [183, 189], [189, 190], [191, 194], [195, 204], [205, 217], [218, 222], [223, 229], [229, 230], [231, 235], [236, 243], [243, 244], [245, 256], [257, 259], [260, 267], [268, 269], [269, 273], [273, 274], [274, 275]]}
{"doc_key": "ai-dev-75", "ner": [[8, 8, "organisation"], [12, 14, "product"], [18, 18, "country"], [21, 23, "university"], [24, 25, "location"], [27, 29, "university"], [30, 31, "location"], [33, 34, "university"], [35, 36, "location"], [38, 40, "university"], [41, 42, "location"], [44, 45, "university"], [46, 47, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 21, 23, "role", "donates_to", false, false], [8, 8, 27, 29, "role", "donates_to", false, false], [8, 8, 33, 34, "role", "donates_to", false, false], [8, 8, 38, 40, "role", "donates_to", false, false], [8, 8, 44, 45, "role", "donates_to", false, false], [12, 14, 8, 8, "origin", "donates", true, false], [21, 23, 24, 25, "physical", "", false, false], [24, 25, 18, 18, "physical", "", false, false], [27, 29, 30, 31, "physical", "", false, false], [30, 31, 18, 18, "physical", "", false, false], [33, 34, 35, 36, "physical", "", false, false], [35, 36, 18, 18, "physical", "", false, false], [38, 40, 41, 42, "physical", "", false, false], [41, 42, 18, 18, "physical", "", false, false], [44, 45, 46, 47, "physical", "", false, false], [46, 47, 18, 18, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "sentence": ["In", "August", "2011", ",", "it", "was", "announced", "that", "Hitachi", "will", "donate", "one", "electron", "microscope", "to", "each", "of", "five", "Indonesian", "universities", "(", "North", "Sumatra", "University", "in", "Medan", ",", "Indonesian", "Christian", "University", "in", "Jakarta", ",", "Padjadjaran", "University", "in", "Bandung", ",", "Jenderal", "Soedirman", "University", "in", "Purwokerto", "and", "Muhammadiyah", "University", "in", "Malang", ")", "."], "sentence-detokenized": "In August 2011, it was announced that Hitachi will donate one electron microscope to each of five Indonesian universities (North Sumatra University in Medan, Indonesian Christian University in Jakarta, Padjadjaran University in Bandung, Jenderal Soedirman University in Purwokerto and Muhammadiyah University in Malang).", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 18], [19, 22], [23, 32], [33, 37], [38, 45], [46, 50], [51, 57], [58, 61], [62, 70], [71, 81], [82, 84], [85, 89], [90, 92], [93, 97], [98, 108], [109, 121], [122, 123], [123, 128], [129, 136], [137, 147], [148, 150], [151, 156], [156, 157], [158, 168], [169, 178], [179, 189], [190, 192], [193, 200], [200, 201], [202, 213], [214, 224], [225, 227], [228, 235], [235, 236], [237, 245], [246, 255], [256, 266], [267, 269], [270, 280], [281, 284], [285, 297], [298, 308], [309, 311], [312, 318], [318, 319], [319, 320]]}
{"doc_key": "ai-dev-76", "ner": [[3, 4, "field"], [8, 9, "algorithm"], [11, 12, "algorithm"], [19, 20, "field"], [22, 26, "metrics"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Optimisation", "methods", "for", "exploratory", "operations", ",", "such", "as", "linear", "programming", "or", "dynamic", "programming", ",", "are", "often", "impractical", "for", "large", "software", "engineering", "problems", "because", "of", "their", "computational", "complexity", "."], "sentence-detokenized": "Optimisation methods for exploratory operations, such as linear programming or dynamic programming, are often impractical for large software engineering problems because of their computational complexity.", "token2charspan": [[0, 12], [13, 20], [21, 24], [25, 36], [37, 47], [47, 48], [49, 53], [54, 56], [57, 63], [64, 75], [76, 78], [79, 86], [87, 98], [98, 99], [100, 103], [104, 109], [110, 121], [122, 125], [126, 131], [132, 140], [141, 152], [153, 161], [162, 169], [170, 172], [173, 178], [179, 192], [193, 203], [203, 204]]}
{"doc_key": "ai-dev-77", "ner": [[0, 1, "metrics"], [6, 6, "metrics"], [10, 12, "metrics"], [17, 18, "metrics"], [20, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 6, 6, "compare", "", false, false], [0, 1, 10, 12, "compare", "", false, false], [17, 18, 10, 12, "part-of", "", false, false], [20, 21, 10, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sensitivity", "is", "not", "the", "same", "as", "accuracy", ",", "or", "the", "positive", "predictive", "value", "(", "the", "ratio", "of", "true", "positives", "to", "false", "positives", ")", ",", "which", "is", "the", "same", "as", "the", "test", "'s", "claim", "about", "the", "proportion", "of", "true", "positives", "in", "the", "test", "population", "."], "sentence-detokenized": "Sensitivity is not the same as accuracy, or the positive predictive value (the ratio of true positives to false positives), which is the same as the test's claim about the proportion of true positives in the test population.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 22], [23, 27], [28, 30], [31, 39], [39, 40], [41, 43], [44, 47], [48, 56], [57, 67], [68, 73], [74, 75], [75, 78], [79, 84], [85, 87], [88, 92], [93, 102], [103, 105], [106, 111], [112, 121], [121, 122], [122, 123], [124, 129], [130, 132], [133, 136], [137, 141], [142, 144], [145, 148], [149, 153], [153, 155], [156, 161], [162, 167], [168, 171], [172, 182], [183, 185], [186, 190], [191, 200], [201, 203], [204, 207], [208, 212], [213, 223], [223, 224]]}
{"doc_key": "ai-dev-78", "ner": [[0, 2, "person"], [8, 8, "product"], [11, 11, "person"], [28, 28, "person"], [36, 37, "person"], [48, 49, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6], "relations": [[8, 8, 0, 2, "artifact", "", false, false], [36, 37, 48, 49, "role", "convinces", false, false], [48, 49, 8, 8, "role", "producer", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Hampton", "Fancher", "'s", "scenario", "--", "not", "originally", "titled", "Android", "--", "see", "Sammon", ",", "pp.", "32", "and", "38", "for", "explanation", "--", "was", "adopted", "as", "an", "option", "in", "1977", ".", "Sammon", ",", "pp.", "23", "-", "30", ".", "Producer", "Michael", "Deeley", "took", "an", "interest", "in", "Fancher", "'s", "draft", "and", "persuaded", "director", "Ridley", "Scott", "to", "film", "it", "."], "sentence-detokenized": "Hampton Fancher's scenario -- not originally titled Android -- see Sammon, pp. 32 and 38 for explanation -- was adopted as an option in 1977. Sammon, pp. 23-30. Producer Michael Deeley took an interest in Fancher's draft and persuaded director Ridley Scott to film it.", "token2charspan": [[0, 7], [8, 15], [15, 17], [18, 26], [27, 29], [30, 33], [34, 44], [45, 51], [52, 59], [60, 62], [63, 66], [67, 73], [73, 74], [75, 78], [79, 81], [82, 85], [86, 88], [89, 92], [93, 104], [105, 107], [108, 111], [112, 119], [120, 122], [123, 125], [126, 132], [133, 135], [136, 140], [140, 141], [142, 148], [148, 149], [150, 153], [154, 156], [156, 157], [157, 159], [159, 160], [161, 169], [170, 177], [178, 184], [185, 189], [190, 192], [193, 201], [202, 204], [205, 212], [212, 214], [215, 220], [221, 224], [225, 234], [235, 243], [244, 250], [251, 256], [257, 259], [260, 264], [265, 267], [267, 268]]}
{"doc_key": "ai-dev-79", "ner": [[0, 1, "field"], [3, 4, "task"], [6, 7, "task"], [10, 12, "misc"], [14, 15, "field"], [17, 19, "task"], [21, 22, "task"], [24, 25, "field"], [28, 31, "task"], [33, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 4, 0, 1, "part-of", "", false, false], [6, 7, 0, 1, "part-of", "", false, false], [10, 12, 0, 1, "part-of", "", false, false], [14, 15, 0, 1, "part-of", "", false, false], [17, 19, 0, 1, "part-of", "", false, false], [21, 22, 0, 1, "part-of", "", false, false], [24, 25, 0, 1, "part-of", "", false, false], [28, 31, 0, 1, "part-of", "", false, false], [33, 33, 0, 1, "part-of", "", false, false], [35, 36, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Text", "analysis", "includes", "information", "retrieval", ",", "lexical", "analysis", "to", "explore", "word", "frequency", "distributions", ",", "pattern", "recognition", ",", "tagging", "/", "marking", ",", "information", "extraction", ",", "data", "mining", "techniques", "including", "link", "and", "association", "analysis", ",", "visualisation", "and", "predictive", "analysis", "."], "sentence-detokenized": "Text analysis includes information retrieval, lexical analysis to explore word frequency distributions, pattern recognition, tagging/marking, information extraction, data mining techniques including link and association analysis, visualisation and predictive analysis.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 34], [35, 44], [44, 45], [46, 53], [54, 62], [63, 65], [66, 73], [74, 78], [79, 88], [89, 102], [102, 103], [104, 111], [112, 123], [123, 124], [125, 132], [132, 133], [133, 140], [140, 141], [142, 153], [154, 164], [164, 165], [166, 170], [171, 177], [178, 188], [189, 198], [199, 203], [204, 207], [208, 219], [220, 228], [228, 229], [230, 243], [244, 247], [248, 258], [259, 267], [267, 268]]}
{"doc_key": "ai-dev-80", "ner": [[5, 5, "product"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Several", "of", "the", "measures", "use", "WordNet", ",", "a", "manually", "compiled", "lexical", "database", "of", "English", "words", "."], "sentence-detokenized": "Several of the measures use WordNet, a manually compiled lexical database of English words.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 23], [24, 27], [28, 35], [35, 36], [37, 38], [39, 47], [48, 56], [57, 64], [65, 73], [74, 76], [77, 84], [85, 90], [90, 91]]}
{"doc_key": "ai-dev-81", "ner": [[6, 6, "field"], [8, 9, "task"], [11, 16, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "system", "uses", "a", "combination", "of", "computational", ",", "information", "retrieval", "and", "knowledge", "representation", "techniques", "to", "find", "answers", "."], "sentence-detokenized": "The system uses a combination of computational, information retrieval and knowledge representation techniques to find answers.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 17], [18, 29], [30, 32], [33, 46], [46, 47], [48, 59], [60, 69], [70, 73], [74, 83], [84, 98], [99, 109], [110, 112], [113, 117], [118, 125], [125, 126]]}
{"doc_key": "ai-dev-82", "ner": [[6, 10, "metrics"], [13, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 10, 13, 18, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "measure", "of", "performance", ",", "the", "coefficient", "of", "uncertainty", "has", "the", "advantage", "over", "simple", "precision", "that", "it", "is", "not", "affected", "by", "the", "relative", "size", "of", "different", "classes", "."], "sentence-detokenized": "As a measure of performance, the coefficient of uncertainty has the advantage over simple precision that it is not affected by the relative size of different classes.", "token2charspan": [[0, 2], [3, 4], [5, 12], [13, 15], [16, 27], [27, 28], [29, 32], [33, 44], [45, 47], [48, 59], [60, 63], [64, 67], [68, 77], [78, 82], [83, 89], [90, 99], [100, 104], [105, 107], [108, 110], [111, 114], [115, 123], [124, 126], [127, 130], [131, 139], [140, 144], [145, 147], [148, 157], [158, 165], [165, 166]]}
{"doc_key": "ai-dev-83", "ner": [[10, 11, "algorithm"], [13, 14, "algorithm"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Researchers", "have", "tried", "a", "number", "of", "methods", ",", "such", "as", "optical", "flow", ",", "Kalman", "filtering", ",", "hidden", "Markov", "models", ",", "etc", "."], "sentence-detokenized": "Researchers have tried a number of methods, such as optical flow, Kalman filtering, hidden Markov models, etc.", "token2charspan": [[0, 11], [12, 16], [17, 22], [23, 24], [25, 31], [32, 34], [35, 42], [42, 43], [44, 48], [49, 51], [52, 59], [60, 64], [64, 65], [66, 72], [73, 82], [82, 83], [84, 90], [91, 97], [98, 104], [104, 105], [106, 109], [109, 110]]}
{"doc_key": "ai-dev-84", "ner": [[15, 18, "conference"], [32, 34, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "served", "as", "President", ",", "Vice", "-", "President", "and", "Secretary", "-", "Treasurer", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "and", "has", "been", "a", "member", "of", "the", "Board", "and", "Secretary", "of", "the", "Computing", "Research", "Association", "."], "sentence-detokenized": "He has served as President, Vice-President and Secretary-Treasurer of the Association for Computational Linguistics, and has been a member of the Board and Secretary of the Computing Research Association.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 26], [26, 27], [28, 32], [32, 33], [33, 42], [43, 46], [47, 56], [56, 57], [57, 66], [67, 69], [70, 73], [74, 85], [86, 89], [90, 103], [104, 115], [115, 116], [117, 120], [121, 124], [125, 129], [130, 131], [132, 138], [139, 141], [142, 145], [146, 151], [152, 155], [156, 165], [166, 168], [169, 172], [173, 182], [183, 191], [192, 203], [203, 204]]}
{"doc_key": "ai-dev-85", "ner": [[6, 6, "programlang"], [8, 8, "product"], [10, 10, "programlang"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 10, 10, "compare", "", false, false], [6, 6, 12, 13, "related-to", "supports", false, false], [8, 8, 10, 10, "compare", "", false, false], [8, 8, 12, 13, "related-to", "supports", false, false], [10, 10, 12, 13, "related-to", "supports", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Like", "other", "similar", "languages", "such", "as", "APL", "and", "MATLAB", ",", "R", "supports", "matrix", "arithmetic", "."], "sentence-detokenized": "Like other similar languages such as APL and MATLAB, R supports matrix arithmetic.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 28], [29, 33], [34, 36], [37, 40], [41, 44], [45, 51], [51, 52], [53, 54], [55, 63], [64, 70], [71, 81], [81, 82]]}
{"doc_key": "ai-dev-86", "ner": [[8, 9, "misc"], [12, 14, "organisation"], [18, 19, "researcher"], [20, 24, "university"], [28, 33, "misc"], [5, 5, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 12, 14, "physical", "", false, false], [8, 9, 28, 33, "temporal", "", false, false], [18, 19, 8, 9, "role", "arranges", false, false], [18, 19, 20, 24, "role", "works_for", false, false], [5, 5, 8, 9, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["On", "7", "June", "2014", ",", "Goostman", "won", "the", "Turing", "Test", "competition", "at", "the", "Royal", "Society", ",", "organised", "by", "Kevin", "Warwick", "from", "the", "University", "of", "Reading", "to", "mark", "the", "60th", "anniversary", "of", "Turing", "'s", "death", ",", "as", "33", "%", "of", "the", "judges", "were", "convinced", "that", "the", "robot", "was", "human", "."], "sentence-detokenized": "On 7 June 2014, Goostman won the Turing Test competition at the Royal Society, organised by Kevin Warwick from the University of Reading to mark the 60th anniversary of Turing's death, as 33% of the judges were convinced that the robot was human.", "token2charspan": [[0, 2], [3, 4], [5, 9], [10, 14], [14, 15], [16, 24], [25, 28], [29, 32], [33, 39], [40, 44], [45, 56], [57, 59], [60, 63], [64, 69], [70, 77], [77, 78], [79, 88], [89, 91], [92, 97], [98, 105], [106, 110], [111, 114], [115, 125], [126, 128], [129, 136], [137, 139], [140, 144], [145, 148], [149, 153], [154, 165], [166, 168], [169, 175], [175, 177], [178, 183], [183, 184], [185, 187], [188, 190], [190, 191], [192, 194], [195, 198], [199, 205], [206, 210], [211, 220], [221, 225], [226, 229], [230, 235], [236, 239], [240, 245], [245, 246]]}
{"doc_key": "ai-dev-87", "ner": [[0, 2, "product"], [5, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "collaborative", "robot", ",", "or", "cobot", ",", "is", "a", "robot", "that", "can", "interact", "safely", "and", "efficiently", "with", "human", "workers", "to", "perform", "simple", "industrial", "tasks", "."], "sentence-detokenized": "A collaborative robot, or cobot, is a robot that can interact safely and efficiently with human workers to perform simple industrial tasks.", "token2charspan": [[0, 1], [2, 15], [16, 21], [21, 22], [23, 25], [26, 31], [31, 32], [33, 35], [36, 37], [38, 43], [44, 48], [49, 52], [53, 61], [62, 68], [69, 72], [73, 84], [85, 89], [90, 95], [96, 103], [104, 106], [107, 114], [115, 121], [122, 132], [133, 138], [138, 139]]}
{"doc_key": "ai-dev-88", "ner": [[11, 12, "field"], [16, 17, "task"], [19, 20, "task"], [22, 23, "task"], [25, 26, "task"], [28, 29, "task"], [31, 32, "task"], [34, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[16, 17, 11, 12, "part-of", "task_part_of_field", false, false], [19, 20, 11, 12, "part-of", "task_part_of_field", false, false], [22, 23, 11, 12, "part-of", "task_part_of_field", false, false], [25, 26, 11, 12, "part-of", "task_part_of_field", false, false], [28, 29, 11, 12, "part-of", "task_part_of_field", false, false], [31, 32, 11, 12, "part-of", "task_part_of_field", false, false], [34, 35, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["This", "general", "framework", "has", "been", "applied", "to", "a", "wide", "variety", "of", "computer", "vision", "problems", ",", "including", "feature", "detection", ",", "feature", "classification", ",", "image", "segmentation", ",", "image", "matching", ",", "motion", "estimation", ",", "shape", "computation", "and", "object", "detection", "."], "sentence-detokenized": "This general framework has been applied to a wide variety of computer vision problems, including feature detection, feature classification, image segmentation, image matching, motion estimation, shape computation and object detection.", "token2charspan": [[0, 4], [5, 12], [13, 22], [23, 26], [27, 31], [32, 39], [40, 42], [43, 44], [45, 49], [50, 57], [58, 60], [61, 69], [70, 76], [77, 85], [85, 86], [87, 96], [97, 104], [105, 114], [114, 115], [116, 123], [124, 138], [138, 139], [140, 145], [146, 158], [158, 159], [160, 165], [166, 174], [174, 175], [176, 182], [183, 193], [193, 194], [195, 200], [201, 212], [213, 216], [217, 223], [224, 233], [233, 234]]}
{"doc_key": "ai-dev-89", "ner": [[11, 15, "task"], [16, 18, "algorithm"], [6, 7, "algorithm"], [28, 30, "algorithm"], [34, 35, "algorithm"], [39, 40, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 15, 16, 18, "part-of", "", false, false], [11, 15, 6, 7, "usage", "", false, false], [16, 18, 28, 30, "named", "same", false, false], [28, 30, 34, 35, "related-to", "", false, false], [28, 30, 39, 40, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "many", "practical", "applications", ",", "the", "maximum", "likelihood", "method", "is", "used", "to", "estimate", "the", "parameters", "of", "naive", "Bayesian", "models", ";", "in", "other", "words", ",", "one", "can", "work", "with", "a", "naive", "Bayesian", "model", "without", "accepting", "Bayesian", "likelihood", "or", "without", "using", "Bayesian", "methods", "."], "sentence-detokenized": "In many practical applications, the maximum likelihood method is used to estimate the parameters of naive Bayesian models; in other words, one can work with a naive Bayesian model without accepting Bayesian likelihood or without using Bayesian methods.", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 30], [30, 31], [32, 35], [36, 43], [44, 54], [55, 61], [62, 64], [65, 69], [70, 72], [73, 81], [82, 85], [86, 96], [97, 99], [100, 105], [106, 114], [115, 121], [121, 122], [123, 125], [126, 131], [132, 137], [137, 138], [139, 142], [143, 146], [147, 151], [152, 156], [157, 158], [159, 164], [165, 173], [174, 179], [180, 187], [188, 197], [198, 206], [207, 217], [218, 220], [221, 228], [229, 234], [235, 243], [244, 251], [251, 252]]}
{"doc_key": "ai-dev-90", "ner": [[2, 4, "researcher"], [6, 7, "misc"], [11, 15, "university"], [17, 19, "researcher"], [21, 22, "misc"], [24, 24, "university"], [26, 26, "university"], [30, 30, "misc"], [37, 39, "university"], [45, 48, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10], "relations": [[2, 4, 11, 15, "physical", "", false, false], [2, 4, 11, 15, "role", "", false, false], [2, 4, 17, 19, "social", "brothers", false, false], [6, 7, 2, 4, "named", "", false, false], [17, 19, 24, 24, "physical", "", false, false], [17, 19, 24, 24, "role", "", false, false], [17, 19, 26, 26, "physical", "", false, false], [17, 19, 26, 26, "role", "", false, false], [17, 19, 37, 39, "physical", "", false, false], [17, 19, 37, 39, "role", "", false, false], [21, 22, 17, 19, "named", "", false, false], [30, 30, 17, 19, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Brothers", "-", "Victor", "Gershevich", "Katz", ",", "American", "mathematician", ",", "professor", "at", "the", "Massachusetts", "Institute", "of", "Technology", ";", "Mikhail", "Gershevich", "Katz", ",", "Israeli", "mathematician", ",", "Harvard", "and", "Columbia", "University", "graduate", "(", "Ph.D.", ",", "1984", ")", ",", "professor", "at", "Bar-", "Ilan", "University", ",", "author", "of", "the", "monograph", "Mathematical", "Surveys", "and", "Monographs", ",", "vol", "."], "sentence-detokenized": "Brothers - Victor Gershevich Katz, American mathematician, professor at the Massachusetts Institute of Technology; Mikhail Gershevich Katz, Israeli mathematician, Harvard and Columbia University graduate (Ph.D. , 1984), professor at Bar-Ilan University, author of the monograph Mathematical Surveys and Monographs, vol.", "token2charspan": [[0, 8], [9, 10], [11, 17], [18, 28], [29, 33], [33, 34], [35, 43], [44, 57], [57, 58], [59, 68], [69, 71], [72, 75], [76, 89], [90, 99], [100, 102], [103, 113], [113, 114], [115, 122], [123, 133], [134, 138], [138, 139], [140, 147], [148, 161], [161, 162], [163, 170], [171, 174], [175, 183], [184, 194], [195, 203], [204, 205], [205, 210], [211, 212], [213, 217], [217, 218], [218, 219], [220, 229], [230, 232], [233, 237], [237, 241], [242, 252], [252, 253], [254, 260], [261, 263], [264, 267], [268, 277], [278, 290], [291, 298], [299, 302], [303, 313], [313, 314], [315, 318], [318, 319]]}
{"doc_key": "ai-dev-91", "ner": [[3, 4, "person"], [12, 13, "conference"], [17, 20, "organisation"], [21, 29, "location"], [33, 33, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 12, 13, "physical", "", false, false], [3, 4, 12, 13, "role", "", false, false], [3, 4, 17, 20, "role", "", false, false], [17, 20, 21, 29, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2000", ",", "Manuel", "Toharia", ",", "who", "was", "a", "speaker", "at", "previous", "university", "parties", "and", "director", "of", "the", "Pr\u00edncipe", "Felipe", "Museum", "in", "the", "city", "of", "Arts", "and", "Sciences", "in", "Valencia", ",", "suggested", "that", "Ragagageles", "expand", "and", "internationalise", "the", "event", "by", "bringing", "it", "to", "the", "famous", "museum", "."], "sentence-detokenized": "In 2000, Manuel Toharia, who was a speaker at previous university parties and director of the Pr\u00edncipe Felipe Museum in the city of Arts and Sciences in Valencia, suggested that Ragagageles expand and internationalise the event by bringing it to the famous museum.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 23], [23, 24], [25, 28], [29, 32], [33, 34], [35, 42], [43, 45], [46, 54], [55, 65], [66, 73], [74, 77], [78, 86], [87, 89], [90, 93], [94, 102], [103, 109], [110, 116], [117, 119], [120, 123], [124, 128], [129, 131], [132, 136], [137, 140], [141, 149], [150, 152], [153, 161], [161, 162], [163, 172], [173, 177], [178, 189], [190, 196], [197, 200], [201, 217], [218, 221], [222, 227], [228, 230], [231, 239], [240, 242], [243, 245], [246, 249], [250, 256], [257, 263], [263, 264]]}
{"doc_key": "ai-dev-92", "ner": [[4, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Within", "20", "minutes", ",", "the", "facial", "recognition", "system", "identifies", "personal", "data", ",", "including", "surname", ",", "ID", "and", "address", ",", "which", "are", "displayed", "on", "the", "street", "advertising", "screen", "."], "sentence-detokenized": "Within 20 minutes, the facial recognition system identifies personal data, including surname, ID and address, which are displayed on the street advertising screen.", "token2charspan": [[0, 6], [7, 9], [10, 17], [17, 18], [19, 22], [23, 29], [30, 41], [42, 48], [49, 59], [60, 68], [69, 73], [73, 74], [75, 84], [85, 92], [92, 93], [94, 96], [97, 100], [101, 108], [108, 109], [110, 115], [116, 119], [120, 129], [130, 132], [133, 136], [137, 143], [144, 155], [156, 162], [162, 163]]}
{"doc_key": "ai-dev-93", "ner": [[6, 7, "field"], [9, 9, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Recent", "research", "has", "increasingly", "focused", "on", "unsupervised", "learning", "and", "semi-random", "learning", "algorithms", "."], "sentence-detokenized": "Recent research has increasingly focused on unsupervised learning and semi-random learning algorithms.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 32], [33, 40], [41, 43], [44, 56], [57, 65], [66, 69], [70, 81], [82, 90], [91, 101], [101, 102]]}
{"doc_key": "ai-dev-94", "ner": [[4, 4, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Calculating", "this", "example", "using", "Python", "code", ":"], "sentence-detokenized": "Calculating this example using Python code:", "token2charspan": [[0, 11], [12, 16], [17, 24], [25, 30], [31, 37], [38, 42], [42, 43]]}
{"doc_key": "ai-dev-95", "ner": [[7, 8, "task"], [15, 16, "field"], [22, 25, "algorithm"], [19, 21, "algorithm"], [31, 33, "algorithm"], [38, 39, "researcher"], [41, 42, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[22, 25, 15, 16, "part-of", "", false, false], [22, 25, 31, 33, "type-of", "", false, false], [22, 25, 38, 39, "origin", "", false, false], [22, 25, 41, 42, "origin", "", false, false], [19, 21, 22, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Nowadays", ",", "however", ",", "many", "aspects", "of", "speech", "recognition", "have", "been", "taken", "over", "by", "a", "deep", "learning", "method", "called", "LSTM", "(", "Long", "short", "-", "term", "memory", ")", ",", "which", "is", "a", "recurrent", "neural", "network", "published", "in", "1997", "by", "Sepp", "Hochreiter", "&", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Nowadays, however, many aspects of speech recognition have been taken over by a deep learning method called LSTM (Long short-term memory), which is a recurrent neural network published in 1997 by Sepp Hochreiter & J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 8], [8, 9], [10, 17], [17, 18], [19, 23], [24, 31], [32, 34], [35, 41], [42, 53], [54, 58], [59, 63], [64, 69], [70, 74], [75, 77], [78, 79], [80, 84], [85, 93], [94, 100], [101, 107], [108, 112], [113, 114], [114, 118], [119, 124], [124, 125], [125, 129], [130, 136], [136, 137], [137, 138], [139, 144], [145, 147], [148, 149], [150, 159], [160, 166], [167, 174], [175, 184], [185, 187], [188, 192], [193, 195], [196, 200], [201, 211], [212, 213], [214, 220], [221, 232], [232, 233]]}
{"doc_key": "ai-dev-96", "ner": [[8, 8, "algorithm"], [17, 17, "algorithm"], [22, 22, "algorithm"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[8, 8, 22, 22, "named", "same", false, false], [17, 17, 22, 22, "compare", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "initial", "test", "results", "with", "noisy", "datasets", ",", "BrownBoost", "outperformed", "AdaBoost", "in", "generalization", "error", ";", "however", ",", "LogitBoost", "performed", "as", "well", "as", "BrownBoost", "."], "sentence-detokenized": "In initial test results with noisy datasets, BrownBoost outperformed AdaBoost in generalization error; however, LogitBoost performed as well as BrownBoost.", "token2charspan": [[0, 2], [3, 10], [11, 15], [16, 23], [24, 28], [29, 34], [35, 43], [43, 44], [45, 55], [56, 68], [69, 77], [78, 80], [81, 95], [96, 101], [101, 102], [103, 110], [110, 111], [112, 122], [123, 132], [133, 135], [136, 140], [141, 143], [144, 154], [154, 155]]}
{"doc_key": "ai-dev-97", "ner": [[0, 1, "algorithm"], [8, 10, "researcher"], [4, 7, "country"], [13, 15, "researcher"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 8, 10, "part-of", "", false, false], [8, 10, 4, 7, "physical", "", false, false], [19, 21, 13, 15, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Evolutionary", "programming", "was", "introduced", "in", "the", "US", "by", "Lawrence", "J.", "Fogel", ",", "while", "John", "Henry", "Holland", "called", "his", "method", "the", "genetic", "algorithm", "."], "sentence-detokenized": "Evolutionary programming was introduced in the US by Lawrence J. Fogel, while John Henry Holland called his method the genetic algorithm.", "token2charspan": [[0, 12], [13, 24], [25, 28], [29, 39], [40, 42], [43, 46], [47, 49], [50, 52], [53, 61], [62, 64], [65, 70], [70, 71], [72, 77], [78, 82], [83, 88], [89, 96], [97, 103], [104, 107], [108, 114], [115, 118], [119, 126], [127, 136], [136, 137]]}
{"doc_key": "ai-dev-98", "ner": [[2, 2, "researcher"], [4, 4, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 10, 11, "role", "", false, false], [2, 2, 13, 14, "role", "", false, false], [2, 2, 16, 17, "role", "", false, false], [2, 2, 19, 20, "role", "", false, false], [4, 4, 10, 11, "role", "", false, false], [4, 4, 13, 14, "role", "", false, false], [4, 4, 16, 17, "role", "", false, false], [4, 4, 19, 20, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Calculations", "by", "Doug", ",", "Alan", "and", "their", "colleagues", "(", "including", "Marvin", "Minsky", ",", "Allen", "Newell", ",", "Edward", "Feigenbaum", "and", "John", "McCarthy", ")", "showed", "that", "this", "would", "require", "between", "1000", "and", "3000", "man", "-", "years", ",", "far", "in", "excess", "of", "the", "typical", "academic", "project", "model", "."], "sentence-detokenized": "Calculations by Doug, Alan and their colleagues (including Marvin Minsky, Allen Newell, Edward Feigenbaum and John McCarthy) showed that this would require between 1000 and 3000 man-years, far in excess of the typical academic project model.", "token2charspan": [[0, 12], [13, 15], [16, 20], [20, 21], [22, 26], [27, 30], [31, 36], [37, 47], [48, 49], [49, 58], [59, 65], [66, 72], [72, 73], [74, 79], [80, 86], [86, 87], [88, 94], [95, 105], [106, 109], [110, 114], [115, 123], [123, 124], [125, 131], [132, 136], [137, 141], [142, 147], [148, 155], [156, 163], [164, 168], [169, 172], [173, 177], [178, 181], [181, 182], [182, 187], [187, 188], [189, 192], [193, 195], [196, 202], [203, 205], [206, 209], [210, 217], [218, 226], [227, 234], [235, 240], [240, 241]]}
{"doc_key": "ai-dev-99", "ner": [[4, 6, "metrics"], [9, 11, "metrics"], [14, 16, "metrics"], [18, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 9, 11, "part-of", "implemented_in", false, false], [14, 16, 18, 20, "part-of", "implemented_in", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Common", "criteria", "are", "the", "mean", "squared", "error", "criterion", "implemented", "in", "the", "MSECriterion", "and", "the", "cross", "-entropy", "criterion", "implemented", "in", "the", "NLLCriterion", "."], "sentence-detokenized": "Common criteria are the mean squared error criterion implemented in the MSECriterion and the cross-entropy criterion implemented in the NLLCriterion.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 23], [24, 28], [29, 36], [37, 42], [43, 52], [53, 64], [65, 67], [68, 71], [72, 84], [85, 88], [89, 92], [93, 98], [98, 106], [107, 116], [117, 128], [129, 131], [132, 135], [136, 148], [148, 149]]}
{"doc_key": "ai-dev-100", "ner": [[0, 0, "researcher"], [12, 12, "organisation"], [15, 28, "misc"], [33, 37, "conference"], [46, 47, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 12, 12, "role", "", false, false], [0, 0, 33, 37, "role", "", false, false], [0, 0, 46, 47, "role", "", false, false], [15, 28, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Zurada", "has", "served", "the", "engineering", "community", "for", "a", "long", "time", "as", "an", "IEEE", "volunteer", ":", "he", "was", "IEEE", "Vice", "President", "-", "Technical", "Activities", "(", "TAB", "Chair", ")", "in", "2014", ",", "President", "of", "the", "IEEE", "Computational", "Intelligence", "Society", "in", "2004", "-", "05", ",", "and", "a", "member", "of", "ADCOM", "in", "2009", "-", "14", ",", "2016", "-", "18", ",", "and", "previous", "years", "."], "sentence-detokenized": "Zurada has served the engineering community for a long time as an IEEE volunteer: he was IEEE Vice President-Technical Activities (TAB Chair) in 2014, President of the IEEE Computational Intelligence Society in 2004-05, and a member of ADCOM in 2009-14, 2016-18, and previous years.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 21], [22, 33], [34, 43], [44, 47], [48, 49], [50, 54], [55, 59], [60, 62], [63, 65], [66, 70], [71, 80], [80, 81], [82, 84], [85, 88], [89, 93], [94, 98], [99, 108], [108, 109], [109, 118], [119, 129], [130, 131], [131, 134], [135, 140], [140, 141], [142, 144], [145, 149], [149, 150], [151, 160], [161, 163], [164, 167], [168, 172], [173, 186], [187, 199], [200, 207], [208, 210], [211, 215], [215, 216], [216, 218], [218, 219], [220, 223], [224, 225], [226, 232], [233, 235], [236, 241], [242, 244], [245, 249], [249, 250], [250, 252], [252, 253], [254, 258], [258, 259], [259, 261], [261, 262], [263, 266], [267, 275], [276, 281], [281, 282]]}
{"doc_key": "ai-dev-101", "ner": [[3, 37, "field"], [6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 3, 37, "part-of", "", false, false], [9, 10, 3, 37, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "general", ",", "computational", "linguists", ",", "computer", "scientists", ",", "artificial", "intelligence", "experts", ",", "mathematicians", ",", "logicians", ",", "philosophers", ",", "cognitive", "scientists", ",", "cognitive", "psychologists", ",", "psycholinguists", ",", "anthropologists", "and", "neuroscientists", "are", "involved", "in", "the", "work", "of", "computational", "linguistics", "."], "sentence-detokenized": "In general, computational linguists, computer scientists, artificial intelligence experts, mathematicians, logicians, philosophers, cognitive scientists, cognitive psychologists, psycholinguists, anthropologists and neuroscientists are involved in the work of computational linguistics.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 25], [26, 35], [35, 36], [37, 45], [46, 56], [56, 57], [58, 68], [69, 81], [82, 89], [89, 90], [91, 105], [105, 106], [107, 116], [116, 117], [118, 130], [130, 131], [132, 141], [142, 152], [152, 153], [154, 163], [164, 177], [177, 178], [179, 194], [194, 195], [196, 211], [212, 215], [216, 231], [232, 235], [236, 244], [245, 247], [248, 251], [252, 256], [257, 259], [260, 273], [274, 285], [285, 286]]}
{"doc_key": "ai-dev-102", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "-", "term", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "correlations", "between", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and long-term short-term memory are often used to exploit correlations between frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [82, 83], [83, 87], [88, 93], [93, 94], [94, 98], [99, 105], [106, 109], [110, 115], [116, 120], [121, 123], [124, 131], [132, 144], [145, 152], [153, 159], [159, 160]]}
{"doc_key": "ai-dev-103", "ner": [[0, 0, "product"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Unimate", "was", "the", "first", "industrial", "robot", ","], "sentence-detokenized": "Unimate was the first industrial robot,", "token2charspan": [[0, 7], [8, 11], [12, 15], [16, 21], [22, 32], [33, 38], [38, 39]]}
{"doc_key": "ai-dev-104", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [11, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 11, 13, "win-defeat", "", false, false], [5, 6, 11, 13, "win-defeat", "", false, false], [8, 8, 11, 13, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Together", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "won", "the", "2018", "Turing", "Prize", "."], "sentence-detokenized": "Together with Geoffrey Hinton and Yann LeCun, Bengio won the 2018 Turing Prize.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 29], [30, 33], [34, 38], [39, 44], [44, 45], [46, 52], [53, 56], [57, 60], [61, 65], [66, 72], [73, 78], [78, 79]]}
{"doc_key": "ai-dev-105", "ner": [[6, 9, "country"], [21, 24, "misc"], [31, 31, "country"], [28, 30, "organisation"], [35, 36, "person"], [39, 40, "person"], [46, 50, "misc"], [52, 54, "country"], [59, 59, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[21, 24, 6, 9, "physical", "filmed_in", false, false], [35, 36, 28, 30, "role", "host", false, false], [39, 40, 28, 30, "role", "reporter", false, false], [46, 50, 6, 9, "physical", "filmed_in", false, false], [46, 50, 52, 54, "physical", "distributed_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "series", "were", "also", "filmed", "in", "the", "UK", ",", "targeting", "specific", "sectors", "of", "the", "global", "market", ",", "including", "two", "series", "of", "Robot", "Wars", "Extreme", "Warriors", "with", "contestants", "for", "TNN", "in", "the", "US", "(", "hosted", "by", "Mick", "Foley", "and", "reporter", "Rebecca", "Grant", ")", ",", "two", "series", "of", "Dutch", "Robot", "Wars", "for", "Dutch", "distribution", "in", "the", "Netherlands", "and", "one", "series", "for", "Germany", "."], "sentence-detokenized": "Other series were also filmed in the UK, targeting specific sectors of the global market, including two series of Robot Wars Extreme Warriors with contestants for TNN in the US (hosted by Mick Foley and reporter Rebecca Grant), two series of Dutch Robot Wars for Dutch distribution in the Netherlands and one series for Germany.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 22], [23, 29], [30, 32], [33, 36], [37, 39], [39, 40], [41, 50], [51, 59], [60, 67], [68, 70], [71, 74], [75, 81], [82, 88], [88, 89], [90, 99], [100, 103], [104, 110], [111, 113], [114, 119], [120, 124], [125, 132], [133, 141], [142, 146], [147, 158], [159, 162], [163, 166], [167, 169], [170, 173], [174, 176], [177, 178], [178, 184], [185, 187], [188, 192], [193, 198], [199, 202], [203, 211], [212, 219], [220, 225], [225, 226], [226, 227], [228, 231], [232, 238], [239, 241], [242, 247], [248, 253], [254, 258], [259, 262], [263, 268], [269, 281], [282, 284], [285, 288], [289, 300], [301, 304], [305, 308], [309, 315], [316, 319], [320, 327], [327, 328]]}
{"doc_key": "ai-dev-106", "ner": [[6, 6, "researcher"], [11, 11, "product"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 11, 11, "role", "", false, false], [28, 29, 11, 11, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "several", "years", "from", "1986", ",", "Miller", "led", "the", "development", "of", "WordNet", ",", "a", "large", "computer", "-", "readable", "electronic", "reference", "that", "can", "be", "used", "in", "applications", "such", "as", "search", "engines", "."], "sentence-detokenized": "For several years from 1986, Miller led the development of WordNet, a large computer-readable electronic reference that can be used in applications such as search engines.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 22], [23, 27], [27, 28], [29, 35], [36, 39], [40, 43], [44, 55], [56, 58], [59, 66], [66, 67], [68, 69], [70, 75], [76, 84], [84, 85], [85, 93], [94, 104], [105, 114], [115, 119], [120, 123], [124, 126], [127, 131], [132, 134], [135, 147], [148, 152], [153, 155], [156, 162], [163, 170], [170, 171]]}
{"doc_key": "ai-dev-107", "ner": [[3, 3, "algorithm"], [5, 10, "algorithm"], [13, 15, "researcher"], [18, 24, "organisation"], [28, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 13, 15, "origin", "", false, false], [3, 3, 28, 30, "win-defeat", "", false, false], [5, 10, 13, 15, "origin", "", false, false], [5, 10, 28, 30, "win-defeat", "", false, false], [13, 15, 18, 24, "physical", "", false, false], [13, 15, 18, 24, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Since", "2009", ",", "recursive", "and", "deep", "feed", "-", "forward", "neural", "networks", "developed", "by", "J\u00fcrgen", "Schmidhuber", "'s", "research", "team", "at", "the", "Swiss", "artificial", "intelligence", "laboratory", "IDSIA", "have", "won", "several", "international", "handwriting", "competitions", "."], "sentence-detokenized": "Since 2009, recursive and deep feed-forward neural networks developed by J\u00fcrgen Schmidhuber's research team at the Swiss artificial intelligence laboratory IDSIA have won several international handwriting competitions.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 21], [22, 25], [26, 30], [31, 35], [35, 36], [36, 43], [44, 50], [51, 59], [60, 69], [70, 72], [73, 79], [80, 91], [91, 93], [94, 102], [103, 107], [108, 110], [111, 114], [115, 120], [121, 131], [132, 144], [145, 155], [156, 161], [162, 166], [167, 170], [171, 178], [179, 192], [193, 204], [205, 217], [217, 218]]}
{"doc_key": "ai-dev-108", "ner": [[5, 6, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "software", "is", "implemented", "in", "C", "++", "and", "is", "packaged", "in", "Python", "."], "sentence-detokenized": "The software is implemented in C++ and is packaged in Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 30], [31, 32], [32, 34], [35, 38], [39, 41], [42, 50], [51, 53], [54, 60], [60, 61]]}
{"doc_key": "ai-dev-109", "ner": [[34, 38, "country"], [6, 7, "misc"], [11, 11, "misc"], [27, 27, "misc"], [30, 33, "misc"], [23, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 34, 38, "temporal", "", false, false], [11, 11, 6, 7, "artifact", "", false, false], [11, 11, 23, 23, "physical", "", false, false], [30, 33, 27, 27, "named", "", false, false], [30, 33, 23, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1857", ",", "a", "group", "of", "Dutch", "engineers", "began", "construction", "of", "Yotetsusho", ",", "a", "modern", ",", "Western", "-", "style", "foundry", "and", "shipyard", "in", "Nagasaki", ",", "near", "the", "Dutch", "settlement", "of", "Dejima", ",", "at", "the", "request", "of", "the", "Tokugawa", "shogunate", "."], "sentence-detokenized": "In 1857, a group of Dutch engineers began construction of Yotetsusho, a modern, Western-style foundry and shipyard in Nagasaki, near the Dutch settlement of Dejima, at the request of the Tokugawa shogunate.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 16], [17, 19], [20, 25], [26, 35], [36, 41], [42, 54], [55, 57], [58, 68], [68, 69], [70, 71], [72, 78], [78, 79], [80, 87], [87, 88], [88, 93], [94, 101], [102, 105], [106, 114], [115, 117], [118, 126], [126, 127], [128, 132], [133, 136], [137, 142], [143, 153], [154, 156], [157, 163], [163, 164], [165, 167], [168, 171], [172, 179], [180, 182], [183, 186], [187, 195], [196, 205], [205, 206]]}
{"doc_key": "ai-dev-110", "ner": [[10, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Let", "'s", "make", "it", "as", "precise", "as", "possible", "by", "measuring", "the", "mean", "squared", "error", "between", "math", "/", "math", "and", "math", "\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", "/", "math", ":", "we", "want", "math", "(", "y", "-\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", ")", "^", "2", "/", "math", "to", "be", "minimal", "for", "mathx", "_", "1", ",\\", "points", ",", "x", "_n", "/", "math", ",", "as", "well", "as", "for", "point", "s", "not", "in", "our", "sample", "."], "sentence-detokenized": "Let's make it as precise as possible by measuring the mean squared error between math / math and math\\ hat {f} (x; D) / math: we want math (y -\\ hat {f} (x; D)) ^ 2 / math to be minimal for mathx _ 1,\\ points, x _n / math, as well as for points not in our sample.", "token2charspan": [[0, 3], [3, 5], [6, 10], [11, 13], [14, 16], [17, 24], [25, 27], [28, 36], [37, 39], [40, 49], [50, 53], [54, 58], [59, 66], [67, 72], [73, 80], [81, 85], [86, 87], [88, 92], [93, 96], [97, 101], [101, 102], [103, 106], [107, 108], [108, 109], [109, 110], [111, 112], [112, 113], [113, 114], [115, 116], [116, 117], [118, 119], [120, 124], [124, 125], [126, 128], [129, 133], [134, 138], [139, 140], [140, 141], [142, 144], [145, 148], [149, 150], [150, 151], [151, 152], [153, 154], [154, 155], [155, 156], [157, 158], [158, 159], [159, 160], [161, 162], [163, 164], [165, 166], [167, 171], [172, 174], [175, 177], [178, 185], [186, 189], [190, 195], [196, 197], [198, 199], [199, 201], [202, 208], [208, 209], [210, 211], [212, 214], [215, 216], [217, 221], [221, 222], [223, 225], [226, 230], [231, 233], [234, 237], [238, 243], [243, 244], [245, 248], [249, 251], [252, 255], [256, 262], [262, 263]]}
{"doc_key": "ai-dev-111", "ner": [[3, 4, "researcher"], [12, 16, "organisation"], [24, 28, "product"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 12, 16, "role", "", false, false], [24, 28, 12, 16, "temporal", "", false, false], [24, 28, 36, 37, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "then", "sent", "Wydner", "an", "invitation", "to", "attend", "the", "annual", "meeting", "of", "the", "American", "Association", "of", "Translators", ",", "held", "the", "following", "October", ",", "where", "Weidner", "'s", "machine", "translation", "system", "was", "expected", "to", "be", "a", "breakthrough", "in", "machine", "translation", "."], "sentence-detokenized": "He then sent Wydner an invitation to attend the annual meeting of the American Association of Translators, held the following October, where Weidner's machine translation system was expected to be a breakthrough in machine translation.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 19], [20, 22], [23, 33], [34, 36], [37, 43], [44, 47], [48, 54], [55, 62], [63, 65], [66, 69], [70, 78], [79, 90], [91, 93], [94, 105], [105, 106], [107, 111], [112, 115], [116, 125], [126, 133], [133, 134], [135, 140], [141, 148], [148, 150], [151, 158], [159, 170], [171, 177], [178, 181], [182, 190], [191, 193], [194, 196], [197, 198], [199, 211], [212, 214], [215, 222], [223, 234], [234, 235]]}
{"doc_key": "ai-dev-112", "ner": [[0, 10, "conference"], [3, 8, "conference"], [12, 12, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 8, 0, 10, "named", "", false, false], [3, 8, 0, 10, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["At", "the", "2018", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "conference", ",", "Google", "researchers", "presented", "this", "work", "."], "sentence-detokenized": "At the 2018 Neural Information Processing Systems (NeurIPS) conference, Google researchers presented this work.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 30], [31, 41], [42, 49], [50, 51], [51, 58], [58, 59], [60, 70], [70, 71], [72, 78], [79, 90], [91, 100], [101, 105], [106, 110], [110, 111]]}
{"doc_key": "ai-dev-113", "ner": [[0, 4, "algorithm"], [10, 12, "algorithm"], [15, 18, "metrics"], [20, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 4, 10, 12, "usage", "", false, false], [10, 12, 15, 18, "related-to", "", true, false], [15, 18, 20, 22, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Baum", "-", "Welch", "algorithm", "uses", "the", "well", "-", "known", "EM", "algorithm", "to", "find", "a", "maximum", "likelihood", "estimate", "of", "the", "hidden", "Markov", "model", "parameters", "given", "the", "set", "of", "observed", "feature", "vectors", "."], "sentence-detokenized": "The Baum-Welch algorithm uses the well-known EM algorithm to find a maximum likelihood estimate of the hidden Markov model parameters given the set of observed feature vectors.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 14], [15, 24], [25, 29], [30, 33], [34, 38], [38, 39], [39, 44], [45, 47], [48, 57], [58, 60], [61, 65], [66, 67], [68, 75], [76, 86], [87, 95], [96, 98], [99, 102], [103, 109], [110, 116], [117, 122], [123, 133], [134, 139], [140, 143], [144, 147], [148, 150], [151, 159], [160, 167], [168, 175], [175, 176]]}
{"doc_key": "ai-dev-114", "ner": [[0, 9, "product"], [11, 11, "product"], [31, 32, "misc"], [37, 45, "product"], [51, 56, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[0, 9, 11, 11, "compare", "", false, false], [31, 32, 11, 11, "part-of", "", false, false], [37, 45, 11, 11, "part-of", "", false, false], [51, 56, 11, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": [")", "In", "addition", "to", "the", "taxonomic", "information", "contained", "in", "OpenCycis", ",", "ResearchCyc", "contains", "significantly", "more", "semantic", "knowledge", "(", "i.e.", "additional", "facts", "and", "rules", "of", "thumb", ")", "covering", "the", "concepts", "in", "its", "knowledge", "base", ";", "it", "also", "contains", "a", "large", "lexicon", ",", "English", "parsing", "and", "generation", "tools", ",", "and", "Java", "-", "based", "interfaces", "for", "editing", "and", "querying", "knowledge", "."], "sentence-detokenized": ") In addition to the taxonomic information contained in OpenCycis, ResearchCyc contains significantly more semantic knowledge (i.e. additional facts and rules of thumb) covering the concepts in its knowledge base; it also contains a large lexicon, English parsing and generation tools, and Java-based interfaces for editing and querying knowledge.", "token2charspan": [[0, 1], [2, 4], [5, 13], [14, 16], [17, 20], [21, 30], [31, 42], [43, 52], [53, 55], [56, 65], [65, 66], [67, 78], [79, 87], [88, 101], [102, 106], [107, 115], [116, 125], [126, 127], [127, 131], [132, 142], [143, 148], [149, 152], [153, 158], [159, 161], [162, 167], [167, 168], [169, 177], [178, 181], [182, 190], [191, 193], [194, 197], [198, 207], [208, 212], [212, 213], [214, 216], [217, 221], [222, 230], [231, 232], [233, 238], [239, 246], [246, 247], [248, 255], [256, 263], [264, 267], [268, 278], [279, 284], [284, 285], [286, 289], [290, 294], [294, 295], [295, 300], [301, 311], [312, 315], [316, 323], [324, 327], [328, 336], [337, 346], [346, 347]]}
{"doc_key": "ai-dev-115", "ner": [[0, 2, "algorithm"], [5, 6, "task"], [9, 11, "field"], [13, 14, "field"], [16, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 5, 6, "type-of", "", false, false], [5, 6, 9, 11, "part-of", "task_part_of_field", false, false], [5, 6, 13, 14, "part-of", "task_part_of_field", false, false], [5, 6, 16, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Hough", "transform", "is", "a", "feature", "extraction", "method", "used", "in", "image", "analysis", ",", "computer", "vision", "and", "digital", "image", "processing", "."], "sentence-detokenized": "The Hough transform is a feature extraction method used in image analysis, computer vision and digital image processing.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 22], [23, 24], [25, 32], [33, 43], [44, 50], [51, 55], [56, 58], [59, 64], [65, 73], [73, 74], [75, 83], [84, 90], [91, 94], [95, 102], [103, 108], [109, 119], [119, 120]]}
{"doc_key": "ai-dev-116", "ner": [[6, 6, "product"], [8, 12, "product"], [3, 3, "organisation"], [19, 19, "product"], [21, 22, "researcher"], [25, 26, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 6, 8, 12, "named", "", false, false], [6, 6, 3, 3, "artifact", "", false, false], [6, 6, 19, 19, "origin", "developed_from", false, false], [19, 19, 21, 22, "artifact", "", false, false], [25, 26, 3, 3, "role", "supported", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1978", ",", "Unimation", "developed", "the", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "robot", "with", "the", "support", "of", "Vicarm", "(", "Victor", "Scheinman", ")", "and", "General", "Motors", "."], "sentence-detokenized": "In 1978, Unimation developed the PUMA (Programmable Universal Machine for Assembly) robot with the support of Vicarm (Victor Scheinman) and General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 28], [29, 32], [33, 37], [38, 39], [39, 51], [52, 61], [62, 69], [70, 73], [74, 82], [82, 83], [84, 89], [90, 94], [95, 98], [99, 106], [107, 109], [110, 116], [117, 118], [118, 124], [125, 134], [134, 135], [136, 139], [140, 147], [148, 154], [154, 155]]}
{"doc_key": "ai-dev-117", "ner": [[0, 1, "algorithm"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 7, 8, "origin", "", false, false], [0, 1, 10, 11, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "LSTM", "was", "proposed", "in", "1997", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "The LSTM was proposed in 1997 by Sepp Hochreiter and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 21], [22, 24], [25, 29], [30, 32], [33, 37], [38, 48], [49, 52], [53, 59], [60, 71], [71, 72]]}
{"doc_key": "ai-dev-118", "ner": [[11, 12, "metrics"], [6, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "as", "a", "2", "\u00d7", "2", "contingency", "table", "or", "a", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated as a 2 \u00d7 2 contingency table or a confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [64, 66], [67, 68], [69, 78], [79, 85], [86, 88], [89, 96], [96, 97]]}
{"doc_key": "ai-dev-119", "ner": [[11, 11, "conference"], [13, 14, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "was", "also", "a", "major", "contributor", "to", "the", "creation", "of", "the", "ELRA", "and", "LREC", "conferences", "."], "sentence-detokenized": "He was also a major contributor to the creation of the ELRA and LREC conferences.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 13], [14, 19], [20, 31], [32, 34], [35, 38], [39, 47], [48, 50], [51, 54], [55, 59], [60, 63], [64, 68], [69, 80], [80, 81]]}
{"doc_key": "ai-dev-120", "ner": [[12, 26, "product"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "popular", "use", "of", "serial", "robots", "in", "today", "'s", "industry", "is", "the", "SCARA", "robot", ",", "which", "has", "four", "degrees", "of", "freedom", "and", "is", "called", "a", "SCARA", "robot", "."], "sentence-detokenized": "A popular use of serial robots in today's industry is the SCARA robot, which has four degrees of freedom and is called a SCARA robot.", "token2charspan": [[0, 1], [2, 9], [10, 13], [14, 16], [17, 23], [24, 30], [31, 33], [34, 39], [39, 41], [42, 50], [51, 53], [54, 57], [58, 63], [64, 69], [69, 70], [71, 76], [77, 80], [81, 85], [86, 93], [94, 96], [97, 104], [105, 108], [109, 111], [112, 118], [119, 120], [121, 126], [127, 132], [132, 133]]}
{"doc_key": "ai-dev-121", "ner": [[15, 22, "conference"], [14, 24, "conference"], [9, 12, "conference"], [41, 41, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 24, 15, 22, "named", "", false, false], [41, 41, 9, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "one", "of", "the", "founding", "members", "of", "the", "Association", "for", "Computational", "Linguistics", "'", "Special", "Interest", "Group", "on", "the", "Web", "as", "a", "Corpus", "(", "SIGWAC", ")", "and", "former", "Chair", "(", "2006-2008", ")", ",", "as", "well", "as", "one", "of", "the", "organisers", "of", "SENSEVAL", "."], "sentence-detokenized": "He was one of the founding members of the Association for Computational Linguistics' Special Interest Group on the Web as a Corpus (SIGWAC) and former Chair (2006-2008), as well as one of the organisers of SENSEVAL.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 13], [14, 17], [18, 26], [27, 34], [35, 37], [38, 41], [42, 53], [54, 57], [58, 71], [72, 83], [83, 84], [85, 92], [93, 101], [102, 107], [108, 110], [111, 114], [115, 118], [119, 121], [122, 123], [124, 130], [131, 132], [132, 138], [138, 139], [140, 143], [144, 150], [151, 156], [157, 158], [158, 167], [167, 168], [168, 169], [170, 172], [173, 177], [178, 180], [181, 184], [185, 187], [188, 191], [192, 202], [203, 205], [206, 214], [214, 215]]}
{"doc_key": "ai-dev-122", "ner": [[0, 0, "product"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["LinguaStream", "provides", "an", "extensive", "Java", "API", "as", "a", "platform", "."], "sentence-detokenized": "LinguaStream provides an extensive Java API as a platform.", "token2charspan": [[0, 12], [13, 21], [22, 24], [25, 34], [35, 39], [40, 43], [44, 46], [47, 48], [49, 57], [57, 58]]}
{"doc_key": "ai-dev-123", "ner": [[11, 11, "programlang"], [14, 16, "misc"], [10, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 10, 21, "type-of", "", false, false], [14, 16, 10, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "robot", "kit", "is", "Android", "-", "based", "and", "is", "programmed", "using", "Java", ",", "the", "Blocks", "programming", "interface", "or", "other", "Android", "programming", "systems", "."], "sentence-detokenized": "The robot kit is Android-based and is programmed using Java, the Blocks programming interface or other Android programming systems.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 16], [17, 24], [24, 25], [25, 30], [31, 34], [35, 37], [38, 48], [49, 54], [55, 59], [59, 60], [61, 64], [65, 71], [72, 83], [84, 93], [94, 96], [97, 102], [103, 110], [111, 122], [123, 130], [130, 131]]}
{"doc_key": "ai-dev-124", "ner": [[11, 18, "algorithm"], [15, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "method", "of", "defining", "a", "linked", "list", "determines", "whether", "to", "use", "depth", "-", "first", "or", "breadth", "-", "first", "search", "."], "sentence-detokenized": "The method of defining a linked list determines whether to use depth-first or breadth-first search.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 22], [23, 24], [25, 31], [32, 36], [37, 47], [48, 55], [56, 58], [59, 62], [63, 68], [68, 69], [69, 74], [75, 77], [78, 85], [85, 86], [86, 91], [92, 98], [98, 99]]}
{"doc_key": "ai-dev-125", "ner": [[21, 23, "task"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "areas", "can", "indicate", "the", "presence", "of", "objects", "or", "parts", "of", "objects", "in", "the", "image", "area", ",", "which", "can", "be", "used", "for", "object", "detection", "and", "/", "or", "object", "video", "tracking", "."], "sentence-detokenized": "These areas can indicate the presence of objects or parts of objects in the image area, which can be used for object detection and/or object video tracking.", "token2charspan": [[0, 5], [6, 11], [12, 15], [16, 24], [25, 28], [29, 37], [38, 40], [41, 48], [49, 51], [52, 57], [58, 60], [61, 68], [69, 71], [72, 75], [76, 81], [82, 86], [86, 87], [88, 93], [94, 97], [98, 100], [101, 105], [106, 109], [110, 116], [117, 126], [127, 130], [130, 131], [131, 133], [134, 140], [141, 146], [147, 155], [155, 156]]}
{"doc_key": "ai-dev-126", "ner": [[4, 5, "algorithm"], [7, 7, "product"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 4, 5, "type-of", "", false, false], [7, 7, 10, 10, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "a", "semantic", "network", "is", "WordNet", ",", "an", "English", "lexical", "database", "."], "sentence-detokenized": "An example of a semantic network is WordNet, an English lexical database.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 24], [25, 32], [33, 35], [36, 43], [43, 44], [45, 47], [48, 55], [56, 63], [64, 72], [72, 73]]}
{"doc_key": "ai-dev-127", "ner": [[0, 1, "task"], [6, 7, "field"], [9, 10, "field"], [20, 24, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 6, 7, "part-of", "", false, false], [0, 1, 9, 10, "named", "same", false, false], [0, 1, 9, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Speechreading", "is", "an", "interdisciplinary", "subfield", "of", "computer", "science", "and", "computer", "linguistics", "that", "develops", "methodologies", "and", "technologies", "that", "enable", "computers", "to", "identify", "and", "translate", "spoken", "language", "into", "text", "."], "sentence-detokenized": "Speechreading is an interdisciplinary subfield of computer science and computer linguistics that develops methodologies and technologies that enable computers to identify and translate spoken language into text.", "token2charspan": [[0, 13], [14, 16], [17, 19], [20, 37], [38, 46], [47, 49], [50, 58], [59, 66], [67, 70], [71, 79], [80, 91], [92, 96], [97, 105], [106, 119], [120, 123], [124, 136], [137, 141], [142, 148], [149, 158], [159, 161], [162, 170], [171, 174], [175, 184], [185, 191], [192, 200], [201, 205], [206, 210], [210, 211]]}
{"doc_key": "ai-dev-128", "ner": [[0, 1, "field"], [11, 12, "misc"], [17, 19, "field"], [20, 21, "task"], [23, 26, "task"], [46, 47, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 46, 47, "named", "same", false, false], [17, 19, 0, 1, "part-of", "subfield", false, false], [20, 21, 0, 1, "part-of", "", false, false], [20, 21, 17, 19, "part-of", "", false, false], [23, 26, 17, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Artificial", "intelligence", "has", "retained", "most", "of", "the", "attention", "in", "relation", "to", "applied", "ontology", "in", "subfields", "such", "as", "natural", "language", "processing", "by", "machine", "and", "knowledge", "representation", ",", "but", "ontology", "editors", "are", "often", "used", "in", "a", "wide", "range", "of", "domains", ",", "such", "as", "education", ",", "without", "contributing", "to", "artificial", "intelligence", "."], "sentence-detokenized": "Artificial intelligence has retained most of the attention in relation to applied ontology in subfields such as natural language processing by machine and knowledge representation, but ontology editors are often used in a wide range of domains, such as education, without contributing to artificial intelligence.", "token2charspan": [[0, 10], [11, 23], [24, 27], [28, 36], [37, 41], [42, 44], [45, 48], [49, 58], [59, 61], [62, 70], [71, 73], [74, 81], [82, 90], [91, 93], [94, 103], [104, 108], [109, 111], [112, 119], [120, 128], [129, 139], [140, 142], [143, 150], [151, 154], [155, 164], [165, 179], [179, 180], [181, 184], [185, 193], [194, 201], [202, 205], [206, 211], [212, 216], [217, 219], [220, 221], [222, 226], [227, 232], [233, 235], [236, 243], [243, 244], [245, 249], [250, 252], [253, 262], [262, 263], [264, 271], [272, 284], [285, 287], [288, 298], [299, 311], [311, 312]]}
{"doc_key": "ai-dev-129", "ner": [[7, 9, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 9, 12, 13, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["This", "update", "rule", "is", "in", "effect", "a", "stochastic", "gradient", "descent", "update", "of", "linear", "regression", "."], "sentence-detokenized": "This update rule is in effect a stochastic gradient descent update of linear regression.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 19], [20, 22], [23, 29], [30, 31], [32, 42], [43, 51], [52, 59], [60, 66], [67, 69], [70, 76], [77, 87], [87, 88]]}
{"doc_key": "ai-dev-130", "ner": [[6, 11, "organisation"], [14, 17, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "been", "elected", "to", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "the", "National", "Academy", "of", "Sciences", "and", "has", "received", "numerous", "awards", ":"], "sentence-detokenized": "He has been elected to the American Academy of Arts and Sciences and the National Academy of Sciences and has received numerous awards:", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 22], [23, 26], [27, 35], [36, 43], [44, 46], [47, 51], [52, 55], [56, 64], [65, 68], [69, 72], [73, 81], [82, 89], [90, 92], [93, 101], [102, 105], [106, 109], [110, 118], [119, 127], [128, 134], [134, 135]]}
{"doc_key": "ai-dev-131", "ner": [[5, 6, "organisation"], [12, 13, "person"], [15, 18, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 12, 13, "related-to", "written_about_by", false, false], [5, 6, 15, 18, "related-to", "written_about_by", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "recent", "thinking", "on", "Honda", "'s", "strategy", "was", "put", "forward", "by", "Gary", "Hamel", "and", "C.", "K", ".", "Prahalad", "in", "1989", "."], "sentence-detokenized": "The most recent thinking on Honda's strategy was put forward by Gary Hamel and C. K. Prahalad in 1989.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 24], [25, 27], [28, 33], [33, 35], [36, 44], [45, 48], [49, 52], [53, 60], [61, 63], [64, 68], [69, 74], [75, 78], [79, 81], [82, 83], [83, 84], [85, 93], [94, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-dev-132", "ner": [[1, 1, "metrics"], [4, 6, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 4, 6, "related-to", "calculates", true, false], [1, 1, 19, 19, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["While", "BLEU", "simply", "calculates", "the", "accuracy", "of", "an", "n-", "gram", "by", "adding", "an", "equal", "weight", "to", "each", "gram", ",", "NIST", "also", "calculates", "how", "informative", "a", "particular", "n-", "gram", "is", "."], "sentence-detokenized": "While BLEU simply calculates the accuracy of an n-gram by adding an equal weight to each gram, NIST also calculates how informative a particular n-gram is.", "token2charspan": [[0, 5], [6, 10], [11, 17], [18, 28], [29, 32], [33, 41], [42, 44], [45, 47], [48, 50], [50, 54], [55, 57], [58, 64], [65, 67], [68, 73], [74, 80], [81, 83], [84, 88], [89, 93], [93, 94], [95, 99], [100, 104], [105, 115], [116, 119], [120, 131], [132, 133], [134, 144], [145, 147], [147, 151], [152, 154], [154, 155]]}
{"doc_key": "ai-dev-133", "ner": [[3, 8, "misc"], [11, 12, "conference"], [9, 14, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 8, 11, 12, "temporal", "", false, false], [9, 14, 11, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "received", "the", "2019", "Lifetime", "Achievement", "Award", "from", "the", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "."], "sentence-detokenized": "He received the 2019 Lifetime Achievement Award from the Association for Computational Linguistics (ACL).", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 20], [21, 29], [30, 41], [42, 47], [48, 52], [53, 56], [57, 68], [69, 72], [73, 86], [87, 98], [99, 100], [100, 103], [103, 104], [104, 105]]}
{"doc_key": "ai-dev-134", "ner": [[0, 2, "researcher"], [8, 11, "organisation"], [6, 13, "organisation"], [20, 21, "conference"], [17, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 8, 11, "role", "", false, false], [0, 2, 20, 21, "role", "", false, false], [6, 13, 8, 11, "named", "", false, false], [17, 23, 20, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sycara", "is", "a", "member", "of", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", "and", "the", "American", "Association", "for", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Sycara is a member of the Institute of Electrical and Electronics Engineers (IEEE) and the American Association for Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 18], [19, 21], [22, 25], [26, 35], [36, 38], [39, 49], [50, 53], [54, 65], [66, 75], [76, 77], [77, 81], [81, 82], [83, 86], [87, 90], [91, 99], [100, 111], [112, 115], [116, 126], [127, 139], [140, 141], [141, 145], [145, 146], [146, 147]]}
{"doc_key": "ai-dev-135", "ner": [[10, 12, "misc"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "MATLAB", "code", "demonstrates", "a", "concrete", "solution", "to", "the", "system", "of", "non-linear", "equations", "presented", "in", "the", "previous", "section", "."], "sentence-detokenized": "The following MATLAB code demonstrates a concrete solution to the system of non-linear equations presented in the previous section.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 38], [39, 40], [41, 49], [50, 58], [59, 61], [62, 65], [66, 72], [73, 75], [76, 86], [87, 96], [97, 106], [107, 109], [110, 113], [114, 122], [123, 130], [130, 131]]}
{"doc_key": "ai-dev-136", "ner": [[4, 6, "product"], [14, 15, "field"], [37, 37, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 14, 15, "related-to", "trained_by", true, false], [4, 6, 37, 37, "related-to", "trained_by", true, false], [14, 15, 37, 37, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "many", "cases", ",", "pattern", "recognition", "systems", "are", "trained", "from", "labelled", "training", "data", "(", "supervised", "learning", ")", ",", "but", "if", "labelled", "data", "is", "not", "available", ",", "other", "algorithms", "can", "be", "used", "to", "detect", "previously", "unknown", "patterns", "(", "tutoring", ")", "."], "sentence-detokenized": "In many cases, pattern recognition systems are trained from labelled training data (supervised learning), but if labelled data is not available, other algorithms can be used to detect previously unknown patterns (tutoring).", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 22], [23, 34], [35, 42], [43, 46], [47, 54], [55, 59], [60, 68], [69, 77], [78, 82], [83, 84], [84, 94], [95, 103], [103, 104], [104, 105], [106, 109], [110, 112], [113, 121], [122, 126], [127, 129], [130, 133], [134, 143], [143, 144], [145, 150], [151, 161], [162, 165], [166, 168], [169, 173], [174, 176], [177, 183], [184, 194], [195, 202], [203, 211], [212, 213], [213, 221], [221, 222], [222, 223]]}
{"doc_key": "ai-dev-137", "ner": [[5, 8, "researcher"], [10, 13, "country"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 8, 10, 13, "physical", "", false, false], [5, 8, 23, 24, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "was", "first", "used", "by", "Lawrence", "J.", "Fogel", "in", "1960", "in", "the", "USA", "to", "use", "simulated", "evolution", "as", "a", "learning", "process", "to", "create", "artificial", "intelligence", "."], "sentence-detokenized": "It was first used by Lawrence J. Fogel in 1960 in the USA to use simulated evolution as a learning process to create artificial intelligence.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 17], [18, 20], [21, 29], [30, 32], [33, 38], [39, 41], [42, 46], [47, 49], [50, 53], [54, 57], [58, 60], [61, 64], [65, 74], [75, 84], [85, 87], [88, 89], [90, 98], [99, 106], [107, 109], [110, 116], [117, 127], [128, 140], [140, 141]]}
{"doc_key": "ai-dev-138", "ner": [[0, 1, "field"], [8, 9, "field"], [15, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 8, 9, "part-of", "", false, false], [15, 16, 8, 9, "part-of", "", false, false], [18, 19, 8, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Leverage", "learning", "is", "one", "of", "the", "three", "basic", "machine", "learning", "paradigms", ",", "in", "addition", "to", "supervised", "learning", "and", "unsupervised", "learning", "."], "sentence-detokenized": "Leverage learning is one of the three basic machine learning paradigms, in addition to supervised learning and unsupervised learning.", "token2charspan": [[0, 8], [9, 17], [18, 20], [21, 24], [25, 27], [28, 31], [32, 37], [38, 43], [44, 51], [52, 60], [61, 70], [70, 71], [72, 74], [75, 83], [84, 86], [87, 97], [98, 106], [107, 110], [111, 123], [124, 132], [132, 133]]}
{"doc_key": "ai-dev-139", "ner": [[4, 5, "field"], [12, 12, "programlang"], [29, 30, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 29, 30, "usage", "applies", false, false], [12, 12, 29, 30, "usage", "applies", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "such", "cases", ",", "cloud", "computing", "and", "the", "open", "source", "programming", "language", "R", "can", "help", "smaller", "banks", "to", "adopt", "risk", "analytics", "and", "support", "branch", "-", "level", "supervision", "by", "applying", "predictive", "analytics", "."], "sentence-detokenized": "In such cases, cloud computing and the open source programming language R can help smaller banks to adopt risk analytics and support branch-level supervision by applying predictive analytics.", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 20], [21, 30], [31, 34], [35, 38], [39, 43], [44, 50], [51, 62], [63, 71], [72, 73], [74, 77], [78, 82], [83, 90], [91, 96], [97, 99], [100, 105], [106, 110], [111, 120], [121, 124], [125, 132], [133, 139], [139, 140], [140, 145], [146, 157], [158, 160], [161, 169], [170, 180], [181, 190], [190, 191]]}
{"doc_key": "ai-dev-140", "ner": [[11, 12, "researcher"], [16, 16, "algorithm"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 20, 21, "named", "same", false, false], [16, 16, 11, 12, "origin", "proves_function", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["One", "of", "the", "first", "versions", "of", "the", "theory", "was", "proved", "by", "George", "Cybenko", "in", "1989", "for", "sigmoid", "activation", "functions", ".", "Cybenko", "G.", "(", "1989", ")", ",", "2", "(", "4", ")", ",", "303-314", "."], "sentence-detokenized": "One of the first versions of the theory was proved by George Cybenko in 1989 for sigmoid activation functions. Cybenko G. (1989), 2 (4), 303-314.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [17, 25], [26, 28], [29, 32], [33, 39], [40, 43], [44, 50], [51, 53], [54, 60], [61, 68], [69, 71], [72, 76], [77, 80], [81, 88], [89, 99], [100, 109], [109, 110], [111, 118], [119, 121], [122, 123], [123, 127], [127, 128], [128, 129], [130, 131], [132, 133], [133, 134], [134, 135], [135, 136], [137, 144], [144, 145]]}
{"doc_key": "ai-dev-141", "ner": [[5, 5, "algorithm"], [7, 9, "metrics"], [13, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 5, 5, "part-of", "", false, false], [13, 17, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "this", "process", ",", "called", "cross-validation", ",", "the", "MSE", "is", "often", "called", "the", "mean", "squared", "error", "of", "prediction", "and", "is", "calculated", "as", "follows", "."], "sentence-detokenized": "In this process, called cross-validation, the MSE is often called the mean squared error of prediction and is calculated as follows.", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 23], [24, 40], [40, 41], [42, 45], [46, 49], [50, 52], [53, 58], [59, 65], [66, 69], [70, 74], [75, 82], [83, 88], [89, 91], [92, 102], [103, 106], [107, 109], [110, 120], [121, 123], [124, 131], [131, 132]]}
{"doc_key": "ai-dev-142", "ner": [[3, 3, "task"], [4, 6, "task"], [5, 9, "task"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 4, 6, "compare", "", false, false], [4, 6, 18, 19, "part-of", "", false, false], [5, 9, 4, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["What", "generally", "distinguishes", "OMR", "from", "optical", "character", "recognition", "(", "OCR", ")", "is", "that", "it", "does", "not", "require", "sophisticated", "pattern", "recognition", "."], "sentence-detokenized": "What generally distinguishes OMR from optical character recognition (OCR) is that it does not require sophisticated pattern recognition.", "token2charspan": [[0, 4], [5, 14], [15, 28], [29, 32], [33, 37], [38, 45], [46, 55], [56, 67], [68, 69], [69, 72], [72, 73], [74, 76], [77, 81], [82, 84], [85, 89], [90, 93], [94, 101], [102, 115], [116, 123], [124, 135], [135, 136]]}
{"doc_key": "ai-dev-143", "ner": [[9, 10, "location"], [12, 12, "location"], [14, 14, "location"], [15, 18, "location"], [20, 21, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 14, 14, "physical", "", false, false], [15, 18, 12, 12, "physical", "", false, false], [20, 21, 12, 12, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2018", "and", "2019", ",", "the", "championships", "were", "held", "in", "Houston", "and", "Detroit", ",", "Michigan", "at", "the", "TCF", "Center", "and", "Ford", "Field", "."], "sentence-detokenized": "In 2018 and 2019, the championships were held in Houston and Detroit, Michigan at the TCF Center and Ford Field.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 16], [16, 17], [18, 21], [22, 35], [36, 40], [41, 45], [46, 48], [49, 56], [57, 60], [61, 68], [68, 69], [70, 78], [79, 81], [82, 85], [86, 89], [90, 96], [97, 100], [101, 105], [106, 111], [111, 112]]}
{"doc_key": "ai-dev-144", "ner": [[0, 0, "task"], [9, 10, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 0, "part-of", "", false, false], [12, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "treated", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multiclass", "classification", "."], "sentence-detokenized": "Classification can be treated as two separate problems - binary classification and multiclass classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 29], [30, 32], [33, 36], [37, 45], [46, 54], [55, 56], [57, 63], [64, 78], [79, 82], [83, 93], [94, 108], [108, 109]]}
{"doc_key": "ai-dev-145", "ner": [[4, 5, "product"], [8, 9, "product"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 4, 5, "type-of", "", false, false], [12, 13, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "examples", "of", "popular", "parallel", "robots", "are", "the", "Stewart", "platform", "and", "the", "Delta", "robot", "."], "sentence-detokenized": "Two examples of popular parallel robots are the Stewart platform and the Delta robot.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 23], [24, 32], [33, 39], [40, 43], [44, 47], [48, 55], [56, 64], [65, 68], [69, 72], [73, 78], [79, 84], [84, 85]]}
{"doc_key": "ai-dev-146", "ner": [[4, 9, "algorithm"], [21, 22, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 9, 21, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "Nevertheless", ",", "the", "ReLU", "activation", "function", ",", "which", "is", "not", "differentiable", "at", "0", ",", "has", "become", "quite", "popular", ",", "e.g.", "on", "AlexNet", ")", "."], "sentence-detokenized": "(Nevertheless, the ReLU activation function, which is not differentiable at 0, has become quite popular, e.g. on AlexNet).", "token2charspan": [[0, 1], [1, 13], [13, 14], [15, 18], [19, 23], [24, 34], [35, 43], [43, 44], [45, 50], [51, 53], [54, 57], [58, 72], [73, 75], [76, 77], [77, 78], [79, 82], [83, 89], [90, 95], [96, 103], [103, 104], [105, 109], [110, 112], [113, 120], [120, 121], [121, 122]]}
{"doc_key": "ai-dev-147", "ner": [[0, 2, "metrics"], [7, 11, "task"], [17, 17, "task"], [19, 20, "task"], [22, 23, "task"], [28, 30, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 28, 30, "named", "", true, false], [7, 11, 0, 2, "usage", "", true, false], [17, 17, 7, 11, "part-of", "", false, false], [19, 20, 7, 11, "part-of", "", false, false], [22, 23, 7, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["F", "-", "scores", "are", "often", "used", "in", "the", "field", "of", "information", "retrieval", "to", "measure", "the", "performance", "of", "search", ",", "document", "classification", "and", "query", "classification", ",", "which", "is", "why", "F_beta", "has", "found", "wide", "application", "."], "sentence-detokenized": "F-scores are often used in the field of information retrieval to measure the performance of search, document classification and query classification, which is why F_beta has found wide application.", "token2charspan": [[0, 1], [1, 2], [2, 8], [9, 12], [13, 18], [19, 23], [24, 26], [27, 30], [31, 36], [37, 39], [40, 51], [52, 61], [62, 64], [65, 72], [73, 76], [77, 88], [89, 91], [92, 98], [98, 99], [100, 108], [109, 123], [124, 127], [128, 133], [134, 148], [148, 149], [150, 155], [156, 158], [159, 162], [163, 169], [170, 173], [174, 179], [180, 184], [185, 196], [196, 197]]}
{"doc_key": "ai-dev-148", "ner": [[18, 18, "algorithm"], [17, 20, "algorithm"], [23, 24, "algorithm"], [26, 26, "algorithm"], [30, 31, "algorithm"], [33, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[17, 20, 18, 18, "named", "", false, false], [26, 26, 23, 24, "named", "", false, false], [33, 35, 30, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "is", "done", "by", "modelling", "the", "received", "signal", "and", "then", "using", "a", "statistical", "estimation", "method", "such", "as", "maximum", "likelihood", "(", "ML", ")", ",", "majority", "vote", "(", "MV", ")", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "to", "decide", "which", "target", "in", "the", "library", "best", "fits", "the", "model", "based", "on", "the", "received", "signal", "."], "sentence-detokenized": "This is done by modelling the received signal and then using a statistical estimation method such as maximum likelihood (ML), majority vote (MV) or maximum a posteriori (MAP) to decide which target in the library best fits the model based on the received signal.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 15], [16, 25], [26, 29], [30, 38], [39, 45], [46, 49], [50, 54], [55, 60], [61, 62], [63, 74], [75, 85], [86, 92], [93, 97], [98, 100], [101, 108], [109, 119], [120, 121], [121, 123], [123, 124], [124, 125], [126, 134], [135, 139], [140, 141], [141, 143], [143, 144], [145, 147], [148, 155], [156, 157], [158, 168], [169, 170], [170, 173], [173, 174], [175, 177], [178, 184], [185, 190], [191, 197], [198, 200], [201, 204], [205, 212], [213, 217], [218, 222], [223, 226], [227, 232], [233, 238], [239, 241], [242, 245], [246, 254], [255, 261], [261, 262]]}
{"doc_key": "ai-dev-149", "ner": [[0, 0, "researcher"], [3, 4, "misc"], [5, 5, "field"], [6, 12, "university"], [16, 18, "misc"], [19, 20, "field"], [21, 28, "university"], [29, 29, "misc"], [30, 34, "field"], [35, 38, "university"], [45, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 0, 6, 12, "physical", "", false, false], [0, 0, 6, 12, "role", "", false, false], [0, 0, 21, 28, "physical", "", false, false], [0, 0, 21, 28, "role", "", false, false], [0, 0, 35, 38, "physical", "", false, false], [0, 0, 35, 38, "role", "", false, false], [3, 4, 0, 0, "origin", "", false, false], [3, 4, 5, 5, "topic", "", false, false], [16, 18, 0, 0, "origin", "", false, false], [16, 18, 19, 20, "topic", "", false, false], [29, 29, 0, 0, "origin", "", false, false], [29, 29, 30, 34, "topic", "", false, false], [45, 53, 29, 29, "named", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Sowa", "received", "his", "B.A.", "in", "Mathematics", "from", "the", "Massachusetts", "Institute", "of", "Technology", "in", "1962", ",", "his", "M.Sc", ".", "in", "Applied", "Science", "from", "Harvard", "University", "in", "1966", ",", "and", "his", "Ph.D.", "in", "Computer", "Science", "from", "the", "Vrije", "Universiteit", "Brussel", "in", "1999", "for", "his", "doctoral", "thesis", "\"", "Knowledge", "Representation", ":", "Logical", ",", "Philosophical", "and", "Computational", "Foundations", "\"", "."], "sentence-detokenized": "Sowa received his B.A. in Mathematics from the Massachusetts Institute of Technology in 1962, his M.Sc. in Applied Science from Harvard University in 1966, and his Ph.D. in Computer Science from the Vrije Universiteit Brussel in 1999 for his doctoral thesis \"Knowledge Representation: Logical, Philosophical and Computational Foundations\".", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 22], [23, 25], [26, 37], [38, 42], [43, 46], [47, 60], [61, 70], [71, 73], [74, 84], [85, 87], [88, 92], [92, 93], [94, 97], [98, 102], [102, 103], [104, 106], [107, 114], [115, 122], [123, 127], [128, 135], [136, 146], [147, 149], [150, 154], [154, 155], [156, 159], [160, 163], [164, 169], [170, 172], [173, 181], [182, 189], [190, 194], [195, 198], [199, 204], [205, 217], [218, 225], [226, 228], [229, 233], [234, 237], [238, 241], [242, 250], [251, 257], [258, 259], [259, 268], [269, 283], [283, 284], [285, 292], [292, 293], [294, 307], [308, 311], [312, 325], [326, 337], [337, 338], [338, 339]]}
{"doc_key": "ai-dev-150", "ner": [[1, 2, "task"], [18, 18, "metrics"], [20, 21, "metrics"], [23, 24, "metrics"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[18, 18, 1, 2, "part-of", "", true, false], [20, 21, 1, 2, "part-of", "", true, false], [23, 24, 1, 2, "part-of", "", true, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Since", "paraphrase", "identification", "can", "be", "represented", "as", "a", "classification", "problem", ",", "most", "standard", "estimation", "methods", ",", "such", "as", "accuracy", ",", "f1", "score", "or", "ROC", "curve", ",", "work", "relatively", "well", "."], "sentence-detokenized": "Since paraphrase identification can be represented as a classification problem, most standard estimation methods, such as accuracy, f1 score or ROC curve, work relatively well.", "token2charspan": [[0, 5], [6, 16], [17, 31], [32, 35], [36, 38], [39, 50], [51, 53], [54, 55], [56, 70], [71, 78], [78, 79], [80, 84], [85, 93], [94, 104], [105, 112], [112, 113], [114, 118], [119, 121], [122, 130], [130, 131], [132, 134], [135, 140], [141, 143], [144, 147], [148, 153], [153, 154], [155, 159], [160, 170], [171, 175], [175, 176]]}
{"doc_key": "ai-dev-151", "ner": [[8, 10, "algorithm"], [26, 27, "algorithm"], [29, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 26, 27, "opposite", "not_suited_for", false, false], [8, 10, 29, 30, "opposite", "not_suited_for", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "makes", "it", "practical", "for", "the", "analysis", "and", "initial", "composition", "of", "large", "datasets", "(", "hundreds", "or", "thousands", "of", "taxa", ")", "where", "other", "analysis", "methods", "(", "e.g.", "maximum", "parsimony", ",", "maximum", "likelihood", ")", "may", "be", "computationally", "too", "complex", "."], "sentence-detokenized": "This makes it practical for the analysis and initial composition of large datasets (hundreds or thousands of taxa) where other analysis methods (e.g. maximum parsimony, maximum likelihood) may be computationally too complex.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 31], [32, 40], [41, 44], [45, 52], [53, 64], [65, 67], [68, 73], [74, 82], [83, 84], [84, 92], [93, 95], [96, 105], [106, 108], [109, 113], [113, 114], [115, 120], [121, 126], [127, 135], [136, 143], [144, 145], [145, 149], [150, 157], [158, 167], [167, 168], [169, 176], [177, 187], [187, 188], [189, 192], [193, 195], [196, 211], [212, 215], [216, 223], [223, 224]]}
{"doc_key": "ai-dev-152", "ner": [[3, 3, "programlang"], [5, 5, "programlang"], [9, 14, "organisation"], [11, 18, "organisation"], [22, 22, "programlang"], [19, 38, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 3, 22, 22, "named", "same", false, false], [11, 18, 9, 14, "named", "", false, false], [19, 38, 3, 3, "role", "submits", true, false], [19, 38, 5, 5, "role", "submits", true, false], [19, 38, 9, 14, "role", "submits_to", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Submission", "of", "the", "DAML", "+", "OIL", "language", "in", "2002", "to", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", "The", "work", "of", "the", "DAML", "contractors", "and", "the", "ad", "hoc", "joint", "European", "Union", "/", "United", "States", "Ad", "Hoc", "Markup", "Language", "Committee", "."], "sentence-detokenized": "Submission of the DAML + OIL language in 2002 to the World Wide Web Consortium (W3C) The work of the DAML contractors and the ad hoc joint European Union/United States Ad Hoc Markup Language Committee.", "token2charspan": [[0, 10], [11, 13], [14, 17], [18, 22], [23, 24], [25, 28], [29, 37], [38, 40], [41, 45], [46, 48], [49, 52], [53, 58], [59, 63], [64, 67], [68, 78], [79, 80], [80, 83], [83, 84], [85, 88], [89, 93], [94, 96], [97, 100], [101, 105], [106, 117], [118, 121], [122, 125], [126, 128], [129, 132], [133, 138], [139, 147], [148, 153], [153, 154], [154, 160], [161, 167], [168, 170], [171, 174], [175, 181], [182, 190], [191, 200], [200, 201]]}
{"doc_key": "ai-dev-153", "ner": [[4, 5, "misc"], [8, 9, "misc"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 4, 5, "part-of", "", true, false], [12, 13, 4, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "a", "non-linear", "normalisation", "is", "when", "the", "normalisation", "follows", "a", "sigmoid", "function", ",", "in", "which", "case", "the", "normalised", "image", "is", "calculated", "according", "to", "the", "equation"], "sentence-detokenized": "An example of a non-linear normalisation is when the normalisation follows a sigmoid function, in which case the normalised image is calculated according to the equation", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 26], [27, 40], [41, 43], [44, 48], [49, 52], [53, 66], [67, 74], [75, 76], [77, 84], [85, 93], [93, 94], [95, 97], [98, 103], [104, 108], [109, 112], [113, 123], [124, 129], [130, 132], [133, 143], [144, 153], [154, 156], [157, 160], [161, 169]]}
{"doc_key": "ai-dev-154", "ner": [[11, 11, "metrics"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 11, 16, 16, "related-to", "used_together", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "pointed", "out", "that", "to", "overcome", "this", "problem", ",", "accuracy", "is", "usually", "coupled", "with", "recall", "."], "sentence-detokenized": "It has been pointed out that to overcome this problem, accuracy is usually coupled with recall.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 23], [24, 28], [29, 31], [32, 40], [41, 45], [46, 53], [53, 54], [55, 63], [64, 66], [67, 74], [75, 82], [83, 87], [88, 94], [94, 95]]}
{"doc_key": "ai-dev-155", "ner": [[6, 8, "metrics"], [11, 13, "metrics"], [19, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 22, 11, 13, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "commonly", "used", "measures", "are", "the", "mean", "squared", "error", "and", "the", "average", "squared", "error", ",", "the", "latter", "being", "used", "for", "the", "Netflix", "Prize", "."], "sentence-detokenized": "The commonly used measures are the mean squared error and the average squared error, the latter being used for the Netflix Prize.", "token2charspan": [[0, 3], [4, 12], [13, 17], [18, 26], [27, 30], [31, 34], [35, 39], [40, 47], [48, 53], [54, 57], [58, 61], [62, 69], [70, 77], [78, 83], [83, 84], [85, 88], [89, 95], [96, 101], [102, 106], [107, 110], [111, 114], [115, 122], [123, 128], [128, 129]]}
{"doc_key": "ai-dev-156", "ner": [[4, 6, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "August", "2016", ",", "University", "College", "Hospital", "announced", "a", "research", "programme", "to", "develop", "an", "algorithm", "that", "can", "automatically", "distinguish", "between", "healthy", "and", "cancerous", "tissues", "in", "the", "head", "and", "neck", "regions", "."], "sentence-detokenized": "In August 2016, University College Hospital announced a research programme to develop an algorithm that can automatically distinguish between healthy and cancerous tissues in the head and neck regions.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 26], [27, 34], [35, 43], [44, 53], [54, 55], [56, 64], [65, 74], [75, 77], [78, 85], [86, 88], [89, 98], [99, 103], [104, 107], [108, 121], [122, 133], [134, 141], [142, 149], [150, 153], [154, 163], [164, 171], [172, 174], [175, 178], [179, 183], [184, 187], [188, 192], [193, 200], [200, 201]]}
{"doc_key": "ai-dev-157", "ner": [[15, 18, "organisation"], [21, 24, "organisation"], [27, 30, "organisation"], [33, 38, "organisation"], [41, 47, "organisation"], [51, 54, "organisation"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "influence", "of", "Posner", "'s", "theoretical", "and", "empirical", "contributions", "has", "been", "recognized", "through", "fellowships", "from", "the", "American", "Psychological", "Association", ",", "the", "Association", "for", "Psychological", "Science", ",", "the", "Society", "of", "Experimental", "Psychologists", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "The influence of Posner's theoretical and empirical contributions has been recognized through fellowships from the American Psychological Association, the Association for Psychological Science, the Society of Experimental Psychologists, the American Academy of Arts and Sciences, the American Association for the Advancement of Science, and the National Academy of Sciences.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 23], [23, 25], [26, 37], [38, 41], [42, 51], [52, 65], [66, 69], [70, 74], [75, 85], [86, 93], [94, 105], [106, 110], [111, 114], [115, 123], [124, 137], [138, 149], [149, 150], [151, 154], [155, 166], [167, 170], [171, 184], [185, 192], [192, 193], [194, 197], [198, 205], [206, 208], [209, 221], [222, 235], [235, 236], [237, 240], [241, 249], [250, 257], [258, 260], [261, 265], [266, 269], [270, 278], [278, 279], [280, 283], [284, 292], [293, 304], [305, 308], [309, 312], [313, 324], [325, 327], [328, 335], [335, 336], [337, 340], [341, 344], [345, 353], [354, 361], [362, 364], [365, 373], [373, 374]]}
{"doc_key": "ai-dev-158", "ner": [[2, 2, "product"], [7, 8, "field"], [12, 13, "task"], [17, 17, "task"], [19, 19, "task"], [22, 26, "task"], [29, 30, "field"], [32, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7, 8], "relations": [[2, 2, 7, 8, "usage", "", false, false], [12, 13, 7, 8, "part-of", "", false, false], [17, 17, 7, 8, "part-of", "", false, false], [19, 19, 17, 17, "named", "", false, false], [29, 30, 7, 8, "part-of", "", false, false], [32, 33, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 6, 7], "sentence": ["These", "intelligent", "chatbots", "use", "all", "kinds", "of", "artificial", "intelligence", ",", "such", "as", "image", "modelling", "and", "natural", "language", "understanding", "(", "NLU", ")", ",", "natural", "language", "generation", "(", "NLG", ")", ",", "machine", "learning", "and", "deep", "learning", "."], "sentence-detokenized": "These intelligent chatbots use all kinds of artificial intelligence, such as image modelling and natural language understanding (NLU), natural language generation (NLG), machine learning and deep learning.", "token2charspan": [[0, 5], [6, 17], [18, 26], [27, 30], [31, 34], [35, 40], [41, 43], [44, 54], [55, 67], [67, 68], [69, 73], [74, 76], [77, 82], [83, 92], [93, 96], [97, 104], [105, 113], [114, 127], [128, 129], [129, 132], [132, 133], [133, 134], [135, 142], [143, 151], [152, 162], [163, 164], [164, 167], [167, 168], [168, 169], [170, 177], [178, 186], [187, 190], [191, 195], [196, 204], [204, 205]]}
{"doc_key": "ai-dev-159", "ner": [[7, 7, "metrics"], [8, 11, "metrics"], [14, 14, "metrics"], [17, 24, "metrics"], [33, 33, "metrics"], [32, 35, "metrics"], [38, 45, "metrics"], [49, 51, "metrics"], [53, 53, "metrics"], [56, 62, "metrics"], [31, 72, "metrics"], [74, 74, "metrics"], [77, 84, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 11, 7, 7, "named", "", false, false], [14, 14, 7, 7, "named", "", false, false], [17, 24, 7, 7, "named", "", false, false], [32, 35, 33, 33, "named", "", false, false], [38, 45, 33, 33, "named", "", false, false], [53, 53, 49, 51, "named", "", false, false], [56, 62, 49, 51, "named", "", false, false], [74, 74, 31, 72, "named", "", false, false], [77, 84, 31, 72, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "ratios", "of", "the", "rows", "are", "the", "positive", "predictive", "value", "(", "PPV", ",", "aka", "precision", ")", "(", "TP", "/", "(", "TP", "+", "FP", ")", ")", ",", "with", "the", "addition", "of", "the", "VALE", "detection", "rate", "(", "FDR", ")", "(", "FP", "/", "(", "TP", "+", "FP", ")", ")", ";", "and", "the", "negative", "predictive", "value", "(", "NPV", ")", "(", "TN", "/", "(", "TN", "+", "FN", ")", ")", ",", "with", "the", "addition", "of", "the", "VALE", "exclusion", "rate", "(", "FOR", ")", "(", "FN", "/", "(", "TN", "+", "FN", ")", ")", "."], "sentence-detokenized": "The ratios of the rows are the positive predictive value (PPV, aka precision) (TP/(TP + FP)), with the addition of the VALE detection rate (FDR) (FP/(TP + FP)); and the negative predictive value (NPV) (TN/(TN + FN)), with the addition of the VALE exclusion rate (FOR) (FN/(TN + FN)).", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 17], [18, 22], [23, 26], [27, 30], [31, 39], [40, 50], [51, 56], [57, 58], [58, 61], [61, 62], [63, 66], [67, 76], [76, 77], [78, 79], [79, 81], [81, 82], [82, 83], [83, 85], [86, 87], [88, 90], [90, 91], [91, 92], [92, 93], [94, 98], [99, 102], [103, 111], [112, 114], [115, 118], [119, 123], [124, 133], [134, 138], [139, 140], [140, 143], [143, 144], [145, 146], [146, 148], [148, 149], [149, 150], [150, 152], [153, 154], [155, 157], [157, 158], [158, 159], [159, 160], [161, 164], [165, 168], [169, 177], [178, 188], [189, 194], [195, 196], [196, 199], [199, 200], [201, 202], [202, 204], [204, 205], [205, 206], [206, 208], [209, 210], [211, 213], [213, 214], [214, 215], [215, 216], [217, 221], [222, 225], [226, 234], [235, 237], [238, 241], [242, 246], [247, 256], [257, 261], [262, 263], [263, 266], [266, 267], [268, 269], [269, 271], [271, 272], [272, 273], [273, 275], [276, 277], [278, 280], [280, 281], [281, 282], [282, 283]]}
{"doc_key": "ai-dev-160", "ner": [[8, 8, "misc"], [14, 17, "algorithm"], [23, 23, "algorithm"], [21, 25, "algorithm"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[21, 25, 23, 23, "named", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["The", "information", "is", "a", "mixture", "of", "sitemaps", "and", "RSS", "and", "is", "generated", "using", "the", "Information", "Model", "(", "IM", ")", "and", "the", "Biomedical", "Resource", "Ontology", "(", "BRO", ")", "."], "sentence-detokenized": "The information is a mixture of sitemaps and RSS and is generated using the Information Model (IM) and the Biomedical Resource Ontology (BRO).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 20], [21, 28], [29, 31], [32, 40], [41, 44], [45, 48], [49, 52], [53, 55], [56, 65], [66, 71], [72, 75], [76, 87], [88, 93], [94, 95], [95, 97], [97, 98], [99, 102], [103, 106], [107, 117], [118, 126], [127, 135], [136, 137], [137, 140], [140, 141], [141, 142]]}
{"doc_key": "ai-dev-161", "ner": [[1, 2, "task"], [6, 9, "algorithm"], [11, 17, "algorithm"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 11, 17, "origin", "based_on", false, false], [11, 17, 6, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Recent", "text", "recognition", "is", "based", "on", "a", "recursive", "neural", "network", "(", "long", "-", "term", "short", "-", "term", "memory", ")", "and", "does", "not", "require", "a", "language", "model", "."], "sentence-detokenized": "Recent text recognition is based on a recursive neural network (long-term short-term memory) and does not require a language model.", "token2charspan": [[0, 6], [7, 11], [12, 23], [24, 26], [27, 32], [33, 35], [36, 37], [38, 47], [48, 54], [55, 62], [63, 64], [64, 68], [68, 69], [69, 73], [74, 79], [79, 80], [80, 84], [85, 91], [91, 92], [93, 96], [97, 101], [102, 105], [106, 113], [114, 115], [116, 124], [125, 130], [130, 131]]}
{"doc_key": "ai-dev-162", "ner": [[1, 2, "misc"], [4, 5, "metrics"], [8, 9, "algorithm"], [12, 13, "metrics"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 1, 2, "type-of", "", false, false], [8, 9, 4, 5, "related-to", "", true, false], [12, 13, 1, 2, "type-of", "", false, false], [16, 17, 12, 13, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Popular", "loss", "functions", "are", "hinge", "loss", "(", "for", "linear", "SVMs", ")", "and", "log", "loss", "(", "for", "logistic", "regression", ")", "."], "sentence-detokenized": "Popular loss functions are hinge loss (for linear SVMs) and log loss (for logistic regression).", "token2charspan": [[0, 7], [8, 12], [13, 22], [23, 26], [27, 32], [33, 37], [38, 39], [39, 42], [43, 49], [50, 54], [54, 55], [56, 59], [60, 63], [64, 68], [69, 70], [70, 73], [74, 82], [83, 93], [93, 94], [94, 95]]}
{"doc_key": "ai-dev-163", "ner": [[0, 0, "metrics"], [11, 15, "metrics"], [16, 18, "metrics"], [23, 24, "metrics"], [22, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 11, 15, "compare", "", false, false], [0, 0, 23, 24, "compare", "", false, false], [16, 18, 11, 15, "named", "", false, false], [22, 26, 23, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SSIM", "is", "designed", "to", "improve", "on", "traditional", "methods", "such", "as", "the", "signal", "-", "to", "-", "noise", "ratio", "(", "PSNR", ")", "and", "the", "mean", "square", "error", "(", "MSE", ")", "."], "sentence-detokenized": "SSIM is designed to improve on traditional methods such as the signal-to-noise ratio (PSNR) and the mean square error (MSE).", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 19], [20, 27], [28, 30], [31, 42], [43, 50], [51, 55], [56, 58], [59, 62], [63, 69], [69, 70], [70, 72], [72, 73], [73, 78], [79, 84], [85, 86], [86, 90], [90, 91], [92, 95], [96, 99], [100, 104], [105, 111], [112, 117], [118, 119], [119, 122], [122, 123], [123, 124]]}
{"doc_key": "ai-dev-164", "ner": [[8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "work", "has", "inspired", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "His work has inspired robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 21], [22, 30], [31, 42], [43, 47], [48, 50], [51, 57], [58, 64], [64, 65], [66, 70], [71, 78], [79, 82], [83, 87], [88, 94], [94, 95]]}
{"doc_key": "ai-dev-165", "ner": [[19, 20, "algorithm"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", ",", "impulse", "training", "is", "not", "differentiable", ",", "which", "rules", "out", "backpropagation", "-", "based", "training", "methods", "such", "as", "gradient", "descent", "."], "sentence-detokenized": "In addition, impulse training is not differentiable, which rules out backpropagation-based training methods such as gradient descent.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 20], [21, 29], [30, 32], [33, 36], [37, 51], [51, 52], [53, 58], [59, 64], [65, 68], [69, 84], [84, 85], [85, 90], [91, 99], [100, 107], [108, 112], [113, 115], [116, 124], [125, 132], [132, 133]]}
{"doc_key": "ai-dev-166", "ner": [[7, 9, "metrics"], [17, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 9, 17, 18, "related-to", "describes", false, false]], "relations_mapping_to_source": [0], "sentence": ["These", "relationships", "can", "be", "easily", "represented", "by", "a", "confusion", "matrix", ",", "which", "is", "a", "table", "describing", "the", "accuracy", "of", "the", "classification", "model", "."], "sentence-detokenized": "These relationships can be easily represented by a confusion matrix, which is a table describing the accuracy of the classification model.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 26], [27, 33], [34, 45], [46, 48], [49, 50], [51, 60], [61, 67], [67, 68], [69, 74], [75, 77], [78, 79], [80, 85], [86, 96], [97, 100], [101, 109], [110, 112], [113, 116], [117, 131], [132, 137], [137, 138]]}
{"doc_key": "ai-dev-167", "ner": [[0, 10, "conference"], [3, 8, "conference"], [12, 12, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 8, 0, 10, "named", "", false, false], [12, 12, 0, 10, "physical", "", false, false], [12, 12, 0, 10, "role", "", false, false], [12, 12, 0, 10, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["At", "the", "2018", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "conference", ",", "Google", "researchers", "presented", "work", "by"], "sentence-detokenized": "At the 2018 Neural Information Processing Systems (NeurIPS) conference, Google researchers presented work by", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 30], [31, 41], [42, 49], [50, 51], [51, 58], [58, 59], [60, 70], [70, 71], [72, 78], [79, 90], [91, 100], [101, 105], [106, 108]]}
{"doc_key": "ai-dev-168", "ner": [[2, 2, "university"], [12, 12, "product"], [19, 22, "misc"], [18, 18, "conference"], [27, 31, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 19, 22, "win-defeat", "", false, false], [19, 22, 18, 18, "temporal", "", false, false], [27, 31, 18, 18, "part-of", "", false, false], [27, 31, 18, 18, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "at", "Duke", "University", ",", "he", "worked", "on", "the", "automatic", "crossword", "solver", "PROVERB", ",", "which", "won", "the", "1999", "AAAI", "\"", "Outstanding", "Paper", "Award", "\"", "and", "participated", "in", "the", "American", "Crossword", "Puzzle", "Tournament", "."], "sentence-detokenized": "While at Duke University, he worked on the automatic crossword solver PROVERB, which won the 1999 AAAI \"Outstanding Paper Award\" and participated in the American Crossword Puzzle Tournament.", "token2charspan": [[0, 5], [6, 8], [9, 13], [14, 24], [24, 25], [26, 28], [29, 35], [36, 38], [39, 42], [43, 52], [53, 62], [63, 69], [70, 77], [77, 78], [79, 84], [85, 88], [89, 92], [93, 97], [98, 102], [103, 104], [104, 115], [116, 121], [122, 127], [127, 128], [129, 132], [133, 145], [146, 148], [149, 152], [153, 161], [162, 171], [172, 178], [179, 189], [189, 190]]}
{"doc_key": "ai-dev-169", "ner": [[2, 3, "location"], [5, 7, "location"], [13, 15, "country"], [17, 17, "country"], [19, 19, "country"], [21, 21, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 5, 7, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Headquartered", "in", "Rochester", "Hills", ",", "Michigan", ",", "the", "company", "has", "10", "regional", "offices", "in", "the", "US", ",", "Canada", ",", "Mexico", "and", "Brazil", "."], "sentence-detokenized": "Headquartered in Rochester Hills, Michigan, the company has 10 regional offices in the US, Canada, Mexico and Brazil.", "token2charspan": [[0, 13], [14, 16], [17, 26], [27, 32], [32, 33], [34, 42], [42, 43], [44, 47], [48, 55], [56, 59], [60, 62], [63, 71], [72, 79], [80, 82], [83, 86], [87, 89], [89, 90], [91, 97], [97, 98], [99, 105], [106, 109], [110, 116], [116, 117]]}
{"doc_key": "ai-dev-170", "ner": [[12, 12, "product"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "joins", "a", "collection", "of", "historically", "important", "robots", ",", "including", "the", "early", "Unimate", "and", "the", "Odetics", "Odex", "1", "."], "sentence-detokenized": "It joins a collection of historically important robots, including the early Unimate and the Odetics Odex 1.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 21], [22, 24], [25, 37], [38, 47], [48, 54], [54, 55], [56, 65], [66, 69], [70, 75], [76, 83], [84, 87], [88, 91], [92, 99], [100, 104], [105, 106], [106, 107]]}
{"doc_key": "ai-dev-171", "ner": [[6, 7, "researcher"], [10, 11, "organisation"], [13, 18, "researcher"], [21, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 7, 10, 11, "physical", "", false, false], [6, 7, 10, 11, "role", "", false, false], [13, 18, 10, 11, "physical", "", false, false], [13, 18, 10, 11, "role", "", false, false], [13, 18, 21, 27, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["This", "issue", "'s", "guest", "editor", "is", "David", "'s", "former", "colleague", "at", "NIST", ",", "Judah", "Levine", ",", "who", "is", "the", "most", "recent", "recipient", "of", "the", "I.I", ".", "Rab", "Award", "."], "sentence-detokenized": "This issue's guest editor is David's former colleague at NIST, Judah Levine, who is the most recent recipient of the I.I. Rab Award.", "token2charspan": [[0, 4], [5, 10], [10, 12], [13, 18], [19, 25], [26, 28], [29, 34], [34, 36], [37, 43], [44, 53], [54, 56], [57, 61], [61, 62], [63, 68], [69, 75], [75, 76], [77, 80], [81, 83], [84, 87], [88, 92], [93, 99], [100, 109], [110, 112], [113, 116], [117, 120], [120, 121], [122, 125], [126, 131], [131, 132]]}
{"doc_key": "ai-dev-172", "ner": [[12, 16, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "can", "be", "arranged", "in", "a", "2", "\u00d7", "2", "contingency", "table", "(", "confusion", "matrix", ")", "with", "the", "test", "result", "on", "the", "vertical", "axis", "and", "the", "actual", "condition", "on", "the", "horizontal", "axis", "."], "sentence-detokenized": "These can be arranged in a 2 \u00d7 2 contingency table (confusion matrix) with the test result on the vertical axis and the actual condition on the horizontal axis.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 21], [22, 24], [25, 26], [27, 28], [29, 30], [31, 32], [33, 44], [45, 50], [51, 52], [52, 61], [62, 68], [68, 69], [70, 74], [75, 78], [79, 83], [84, 90], [91, 93], [94, 97], [98, 106], [107, 111], [112, 115], [116, 119], [120, 126], [127, 136], [137, 139], [140, 143], [144, 154], [155, 159], [159, 160]]}
{"doc_key": "ai-dev-173", "ner": [[0, 4, "product"], [10, 10, "product"], [12, 12, "product"], [14, 15, "product"], [18, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 10, 10, "part-of", "", false, false], [0, 4, 12, 12, "part-of", "", false, false], [0, 4, 14, 15, "part-of", "", false, false], [0, 4, 18, 20, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Apple", "'s", "iOS", "operating", "system", ",", "which", "is", "used", "on", "iPhone", ",", "iPad", "and", "iPod", "Touch", ",", "uses", "VoiceOver", "speech", "synthesis", "."], "sentence-detokenized": "Apple's iOS operating system, which is used on iPhone, iPad and iPod Touch, uses VoiceOver speech synthesis.", "token2charspan": [[0, 5], [5, 7], [8, 11], [12, 21], [22, 28], [28, 29], [30, 35], [36, 38], [39, 43], [44, 46], [47, 53], [53, 54], [55, 59], [60, 63], [64, 68], [69, 74], [74, 75], [76, 80], [81, 90], [91, 97], [98, 107], [107, 108]]}
{"doc_key": "ai-dev-174", "ner": [[8, 10, "conference"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "the", "best", "system", "that", "entered", "MUC", "-", "7", "achieved", "an", "F-ratio", "of", "93.39", "%", ",", "while", "the", "human", "annotation", "scores", "were", "97.6", "%", "and", "96.95", "%", "respectively", "."], "sentence-detokenized": "For example, the best system that entered MUC-7 achieved an F-ratio of 93.39%, while the human annotation scores were 97.6% and 96.95% respectively.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 33], [34, 41], [42, 45], [45, 46], [46, 47], [48, 56], [57, 59], [60, 67], [68, 70], [71, 76], [76, 77], [77, 78], [79, 84], [85, 88], [89, 94], [95, 105], [106, 112], [113, 117], [118, 122], [122, 123], [124, 127], [128, 133], [133, 134], [135, 147], [147, 148]]}
{"doc_key": "ai-dev-175", "ner": [[11, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 15, 11, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "is", "done", "using", "standard", "neural", "network", "training", "algorithms", "such", "as", "stochastic", "gradient", "descent", "with", "backpropagation", "."], "sentence-detokenized": "This is done using standard neural network training algorithms such as stochastic gradient descent with backpropagation.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 18], [19, 27], [28, 34], [35, 42], [43, 51], [52, 62], [63, 67], [68, 70], [71, 81], [82, 90], [91, 98], [99, 103], [104, 119], [119, 120]]}
{"doc_key": "ai-dev-176", "ner": [[0, 4, "organisation"], [22, 24, "country"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 22, 24, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Rotten", "Tomatoes", "is", "in", "the", "top", "1000", "of", "the", "Alexa", "ranking", "of", "the", "website", ",", "which", "is", "around", "400th", "worldwide", "and", "150th", "in", "the", "US", "alone", "."], "sentence-detokenized": "Rotten Tomatoes is in the top 1000 of the Alexa ranking of the website, which is around 400th worldwide and 150th in the US alone.", "token2charspan": [[0, 6], [7, 15], [16, 18], [19, 21], [22, 25], [26, 29], [30, 34], [35, 37], [38, 41], [42, 47], [48, 55], [56, 58], [59, 62], [63, 70], [70, 71], [72, 77], [78, 80], [81, 87], [88, 93], [94, 103], [104, 107], [108, 113], [114, 116], [117, 120], [121, 123], [124, 129], [129, 130]]}
{"doc_key": "ai-dev-177", "ner": [[13, 17, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "general", ",", "all", "learning", "shows", "changes", "over", "time", ",", "but", "describes", "a", "sigmoid", "function", "that", "has", "a", "different", "appearance", "depending", "on", "the", "time", "scale", "of", "the", "observation", "."], "sentence-detokenized": "In general, all learning shows changes over time, but describes a sigmoid function that has a different appearance depending on the time scale of the observation.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 24], [25, 30], [31, 38], [39, 43], [44, 48], [48, 49], [50, 53], [54, 63], [64, 65], [66, 73], [74, 82], [83, 87], [88, 91], [92, 93], [94, 103], [104, 114], [115, 124], [125, 127], [128, 131], [132, 136], [137, 142], [143, 145], [146, 149], [150, 161], [161, 162]]}
{"doc_key": "ai-dev-178", "ner": [[0, 0, "metrics"], [6, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["SSD", "is", "also", "known", "as", "the", "average", "square", "error", "."], "sentence-detokenized": "SSD is also known as the average square error.", "token2charspan": [[0, 3], [4, 6], [7, 11], [12, 17], [18, 20], [21, 24], [25, 32], [33, 39], [40, 45], [45, 46]]}
{"doc_key": "ai-dev-179", "ner": [[0, 2, "algorithm"], [4, 5, "algorithm"], [7, 10, "algorithm"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 22, 23, "related-to", "can_be_related_to", true, false], [4, 5, 22, 23, "related-to", "can_be_related_to", true, false], [7, 10, 22, 23, "related-to", "can_be_related_to", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", ",", "neural", "networks", "or", "a", "naive", "Bayesian", "classifier", "can", "be", "used", "in", "combination", "with", "model", "quality", "metrics", "such", "as", "balanced", "accuracy", "."], "sentence-detokenized": "Decision tree learning, neural networks or a naive Bayesian classifier can be used in combination with model quality metrics such as balanced accuracy.", "token2charspan": [[0, 8], [9, 13], [14, 22], [22, 23], [24, 30], [31, 39], [40, 42], [43, 44], [45, 50], [51, 59], [60, 70], [71, 74], [75, 77], [78, 82], [83, 85], [86, 97], [98, 102], [103, 108], [109, 116], [117, 124], [125, 129], [130, 132], [133, 141], [142, 150], [150, 151]]}
{"doc_key": "ai-dev-180", "ner": [[0, 15, "conference"], [21, 25, "conference"], [26, 29, "misc"], [36, 39, "product"], [46, 49, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[26, 29, 21, 25, "origin", "", false, false], [26, 29, 21, 25, "temporal", "", false, false], [36, 39, 26, 29, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "is", "a", "past", "president", "(", "1979", ")", "and", "first", "member", "(", "2011", ")", "of", "ACL", ",", "a", "co-recipient", "of", "the", "1992", "Association", "for", "Computing", "Machinery", "Software", "Systems", "Award", "for", "his", "contributions", "to", "the", "development", "of", "the", "Interlisp", "programming", "system", ",", "and", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", "."], "sentence-detokenized": "He is a past president (1979) and first member (2011) of ACL, a co-recipient of the 1992 Association for Computing Machinery Software Systems Award for his contributions to the development of the Interlisp programming system, and a member of the Association for Computing Machinery.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 22], [23, 24], [24, 28], [28, 29], [30, 33], [34, 39], [40, 46], [47, 48], [48, 52], [52, 53], [54, 56], [57, 60], [60, 61], [62, 63], [64, 76], [77, 79], [80, 83], [84, 88], [89, 100], [101, 104], [105, 114], [115, 124], [125, 133], [134, 141], [142, 147], [148, 151], [152, 155], [156, 169], [170, 172], [173, 176], [177, 188], [189, 191], [192, 195], [196, 205], [206, 217], [218, 224], [224, 225], [226, 229], [230, 231], [232, 238], [239, 241], [242, 245], [246, 257], [258, 261], [262, 271], [272, 281], [281, 282]]}
{"doc_key": "ai-dev-181", "ner": [[7, 8, "researcher"], [10, 14, "researcher"], [3, 3, "researcher"], [0, 1, "researcher"], [26, 29, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 26, 29, "related-to", "", false, false], [10, 14, 26, 29, "related-to", "", false, false], [3, 3, 26, 29, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Cade", "Metz", "considers", "Bengio", ",", "along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "to", "be", "one", "of", "the", "three", "people", "most", "responsible", "for", "the", "development", "of", "deep", "learning", "in", "the", "1990s", "and", "2000s", "."], "sentence-detokenized": "Cade Metz considers Bengio, along with Geoffrey Hinton and Yann LeCun, to be one of the three people most responsible for the development of deep learning in the 1990s and 2000s.", "token2charspan": [[0, 4], [5, 9], [10, 19], [20, 26], [26, 27], [28, 33], [34, 38], [39, 47], [48, 54], [55, 58], [59, 63], [64, 69], [69, 70], [71, 73], [74, 76], [77, 80], [81, 83], [84, 87], [88, 93], [94, 100], [101, 105], [106, 117], [118, 121], [122, 125], [126, 137], [138, 140], [141, 145], [146, 154], [155, 157], [158, 161], [162, 167], [168, 171], [172, 177], [177, 178]]}
{"doc_key": "ai-dev-182", "ner": [[0, 2, "field"], [4, 5, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "information", "theory", "and", "computer", "science", ",", "code", "is", "usually", "thought", "of", "as", "an", "algorithm", "that", "represents", "symbols", "in", "some", "source", "character", ",", "encoded", "in", "strings", "that", "may", "be", "in", "some", "other", "target", "character", ",", "in", "an", "unambiguous", "way", "."], "sentence-detokenized": "In information theory and computer science, code is usually thought of as an algorithm that represents symbols in some source character, encoded in strings that may be in some other target character, in an unambiguous way.", "token2charspan": [[0, 2], [3, 14], [15, 21], [22, 25], [26, 34], [35, 42], [42, 43], [44, 48], [49, 51], [52, 59], [60, 67], [68, 70], [71, 73], [74, 76], [77, 86], [87, 91], [92, 102], [103, 110], [111, 113], [114, 118], [119, 125], [126, 135], [135, 136], [137, 144], [145, 147], [148, 155], [156, 160], [161, 164], [165, 167], [168, 170], [171, 175], [176, 181], [182, 188], [189, 198], [198, 199], [200, 202], [203, 205], [206, 217], [218, 221], [221, 222]]}
{"doc_key": "ai-dev-183", "ner": [[11, 11, "algorithm"], [9, 10, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 10, 11, 11, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "fairly", "simple", "non", "-linear", "function", ",", "such", "as", "a", "logistic", "function", ",", "also", "has", "an", "easily", "computable", "derivative", ",", "which", "can", "be", "important", "for", "calculating", "weight", "updates", "online", "."], "sentence-detokenized": "A fairly simple non-linear function, such as a logistic function, also has an easily computable derivative, which can be important for calculating weight updates online.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 19], [19, 26], [27, 35], [35, 36], [37, 41], [42, 44], [45, 46], [47, 55], [56, 64], [64, 65], [66, 70], [71, 74], [75, 77], [78, 84], [85, 95], [96, 106], [106, 107], [108, 113], [114, 117], [118, 120], [121, 130], [131, 134], [135, 146], [147, 153], [154, 161], [162, 168], [168, 169]]}
{"doc_key": "ai-dev-184", "ner": [[0, 0, "person"], [6, 6, "location"], [8, 8, "location"], [10, 12, "country"], [15, 15, "country"], [19, 20, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 6, "physical", "", false, false], [6, 6, 8, 8, "physical", "", false, false], [8, 8, 10, 12, "physical", "", false, false], [8, 8, 15, 15, "physical", "", false, false], [8, 8, 19, 20, "physical", "", false, false], [15, 15, 10, 12, "origin", "", false, false], [19, 20, 15, 15, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["\u010capek", "was", "born", "in", "1887", "in", "Hronov", ",", "Bohemia", "(", "Austria", "-", "Hungary", ",", "later", "Czechoslovakia", ",", "now", "the", "Czech", "Republic", ")", "."], "sentence-detokenized": "\u010capek was born in 1887 in Hronov, Bohemia (Austria-Hungary, later Czechoslovakia, now the Czech Republic).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 41], [42, 43], [43, 50], [50, 51], [51, 58], [58, 59], [60, 65], [66, 80], [80, 81], [82, 85], [86, 89], [90, 95], [96, 104], [104, 105], [105, 106]]}
{"doc_key": "ai-dev-185", "ner": [[5, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "special", "software", "can", "narrate", "RSS", "."], "sentence-detokenized": "Some special software can narrate RSS.", "token2charspan": [[0, 4], [5, 12], [13, 21], [22, 25], [26, 33], [34, 37], [37, 38]]}
{"doc_key": "ai-dev-186", "ner": [[7, 7, "task"], [10, 13, "task"], [18, 18, "task"], [20, 22, "task"], [29, 29, "task"], [32, 34, "task"], [39, 40, "task"], [43, 45, "product"], [47, 48, "product"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 7, 10, 13, "related-to", "", true, false], [7, 7, 18, 18, "related-to", "", true, false], [32, 34, 29, 29, "usage", "", true, false], [43, 45, 39, 40, "type-of", "", false, false], [47, 48, 39, 40, "type-of", "", false, false]], "relations_mapping_to_source": [0, 2, 3, 4, 5], "sentence": ["Aspects", "of", "the", "ontology", "editors", "include", ":", "visual", "navigation", "facilities", "in", "the", "knowledge", "model", ",", "inference", "engines", "and", "extraction", ";", "support", "for", "modules", ";", "import", "and", "export", "of", "foreign", "knowledge", "representation", "languages", "to", "match", "ontologies", ";", "and", "support", "for", "meta", "ontologies", "such", "as", "OWL", "-", "S", ",", "Dublin", "Core", ",", "etc", "."], "sentence-detokenized": "Aspects of the ontology editors include: visual navigation facilities in the knowledge model, inference engines and extraction; support for modules; import and export of foreign knowledge representation languages to match ontologies; and support for meta ontologies such as OWL-S, Dublin Core, etc.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 23], [24, 31], [32, 39], [39, 40], [41, 47], [48, 58], [59, 69], [70, 72], [73, 76], [77, 86], [87, 92], [92, 93], [94, 103], [104, 111], [112, 115], [116, 126], [126, 127], [128, 135], [136, 139], [140, 147], [147, 148], [149, 155], [156, 159], [160, 166], [167, 169], [170, 177], [178, 187], [188, 202], [203, 212], [213, 215], [216, 221], [222, 232], [232, 233], [234, 237], [238, 245], [246, 249], [250, 254], [255, 265], [266, 270], [271, 273], [274, 277], [277, 278], [278, 279], [279, 280], [281, 287], [288, 292], [292, 293], [294, 297], [297, 298]]}
{"doc_key": "ai-dev-187", "ner": [[0, 1, "organisation"], [6, 10, "misc"], [14, 17, "task"], [21, 21, "field"], [24, 24, "misc"], [26, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 10, 0, 1, "origin", "", false, false], [14, 17, 6, 10, "part-of", "", false, false], [21, 21, 6, 10, "part-of", "", false, false], [24, 24, 21, 21, "type-of", "", false, false], [26, 28, 21, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "FBI", "has", "also", "launched", "its", "next", "-", "generation", "identification", "programme", ",", "which", "includes", "facial", "recognition", "as", "well", "as", "more", "traditional", "biometrics", "such", "as", "fingerprints", "and", "iris", "scanning", "that", "can", "be", "used", "from", "both", "criminal", "and", "civil", "databases", "."], "sentence-detokenized": "The FBI has also launched its next-generation identification programme, which includes facial recognition as well as more traditional biometrics such as fingerprints and iris scanning that can be used from both criminal and civil databases.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 16], [17, 25], [26, 29], [30, 34], [34, 35], [35, 45], [46, 60], [61, 70], [70, 71], [72, 77], [78, 86], [87, 93], [94, 105], [106, 108], [109, 113], [114, 116], [117, 121], [122, 133], [134, 144], [145, 149], [150, 152], [153, 165], [166, 169], [170, 174], [175, 183], [184, 188], [189, 192], [193, 195], [196, 200], [201, 205], [206, 210], [211, 219], [220, 223], [224, 229], [230, 239], [239, 240]]}
{"doc_key": "ai-dev-188", "ner": [[5, 6, "person"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "the", "2016", "season", ",", "Samantha", "Ponder", "was", "added", "as", "presenter", ",", "replacing", "Molly", "McGrath", "."], "sentence-detokenized": "For the 2016 season, Samantha Ponder was added as presenter, replacing Molly McGrath.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 19], [19, 20], [21, 29], [30, 36], [37, 40], [41, 46], [47, 49], [50, 59], [59, 60], [61, 70], [71, 76], [77, 84], [84, 85]]}
{"doc_key": "ai-dev-189", "ner": [[3, 5, "algorithm"], [15, 19, "misc"], [21, 21, "misc"], [23, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "adversarial", "search", "algorithm", "commonly", "used", "to", "play", "two", "-", "player", "games", "(", "Tic", "-", "tac", "-", "toe", ",", "chess", ",", "Go", ",", "etc.", ")", "on", "a", "machine", "."], "sentence-detokenized": "This is an adversarial search algorithm commonly used to play two-player games (Tic-tac-toe, chess, Go, etc.) on a machine.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 29], [30, 39], [40, 48], [49, 53], [54, 56], [57, 61], [62, 65], [65, 66], [66, 72], [73, 78], [79, 80], [80, 83], [83, 84], [84, 87], [87, 88], [88, 91], [91, 92], [93, 98], [98, 99], [100, 102], [102, 103], [104, 108], [108, 109], [110, 112], [113, 114], [115, 122], [122, 123]]}
{"doc_key": "ai-dev-190", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [18, 19, "field"], [21, 22, "field"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "encompasses", "the", "fields", "of", "computer", "vision", "or", "machine", "vision", "and", "medical", "imaging", "and", "makes", "intensive", "use", "of", "pattern", "recognition", ",", "digital", "geometry", "and", "signal", "processing", "."], "sentence-detokenized": "It encompasses the fields of computer vision or machine vision and medical imaging and makes intensive use of pattern recognition, digital geometry and signal processing.", "token2charspan": [[0, 2], [3, 14], [15, 18], [19, 25], [26, 28], [29, 37], [38, 44], [45, 47], [48, 55], [56, 62], [63, 66], [67, 74], [75, 82], [83, 86], [87, 92], [93, 102], [103, 106], [107, 109], [110, 117], [118, 129], [129, 130], [131, 138], [139, 147], [148, 151], [152, 158], [159, 169], [169, 170]]}
{"doc_key": "ai-dev-191", "ner": [[0, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "in", "a", "facial", "recognition", "system", ",", "the", "input", "would", "be", "an", "image", "of", "a", "person", "'s", "face", "and", "the", "output", "would", "be", "that", "person", "'s", "name", "."], "sentence-detokenized": "For example, in a facial recognition system, the input would be an image of a person's face and the output would be that person's name.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 17], [18, 24], [25, 36], [37, 43], [43, 44], [45, 48], [49, 54], [55, 60], [61, 63], [64, 66], [67, 72], [73, 75], [76, 77], [78, 84], [84, 86], [87, 91], [92, 95], [96, 99], [100, 106], [107, 112], [113, 115], [116, 120], [121, 127], [127, 129], [130, 134], [134, 135]]}
{"doc_key": "ai-dev-192", "ner": [[0, 1, "organisation"], [23, 25, "product"], [4, 7, "product"]], "ner_mapping_to_source": [0, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Apple", "Inc", "has", "introduced", "Touch", "ID", ",", "the", "fingerprint", "-", "based", "system", "that", "is", "the", "successor", "to", "biometric", "authentication", ",", "on", "its", "flagship", "i", "Phone", "X", "."], "sentence-detokenized": "Apple Inc has introduced Touch ID, the fingerprint-based system that is the successor to biometric authentication, on its flagship iPhone X.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 24], [25, 30], [31, 33], [33, 34], [35, 38], [39, 50], [50, 51], [51, 56], [57, 63], [64, 68], [69, 71], [72, 75], [76, 85], [86, 88], [89, 98], [99, 113], [113, 114], [115, 117], [118, 121], [122, 130], [131, 132], [132, 137], [138, 139], [139, 140]]}
{"doc_key": "ai-dev-193", "ner": [[4, 7, "metrics"], [10, 11, "metrics"], [24, 27, "metrics"], [30, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Or", "a", "combination", "of", "an", "F", "-", "measure", "and", "an", "R-", "square", "estimated", "for", "the", "model", "'s", "raw", "output", "and", "target", ";", "or", "a", "cost", "/", "benefit", "matrix", "and", "a", "correlation", "coefficient", ",", "etc", "."], "sentence-detokenized": "Or a combination of an F-measure and an R-square estimated for the model's raw output and target; or a cost/benefit matrix and a correlation coefficient, etc.", "token2charspan": [[0, 2], [3, 4], [5, 16], [17, 19], [20, 22], [23, 24], [24, 25], [25, 32], [33, 36], [37, 39], [40, 42], [42, 48], [49, 58], [59, 62], [63, 66], [67, 72], [72, 74], [75, 78], [79, 85], [86, 89], [90, 96], [96, 97], [98, 100], [101, 102], [103, 107], [107, 108], [108, 115], [116, 122], [123, 126], [127, 128], [129, 140], [141, 152], [152, 153], [154, 157], [157, 158]]}
{"doc_key": "ai-dev-194", "ner": [[0, 7, "conference"], [8, 12, "location"], [14, 14, "location"], [17, 20, "location"], [21, 21, "location"], [23, 23, "country"], [31, 35, "location"], [39, 43, "location"], [38, 38, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 7, 8, 12, "physical", "", false, false], [0, 7, 17, 20, "physical", "", false, false], [0, 7, 31, 35, "physical", "", false, false], [0, 7, 39, 43, "physical", "", false, false], [8, 12, 14, 14, "physical", "", false, false], [17, 20, 21, 21, "physical", "", false, false], [21, 21, 23, 23, "physical", "", false, false], [31, 35, 38, 38, "physical", "", false, false], [39, 43, 38, 38, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "Campus", "Party", "has", "been", "held", "in", "Spain", "at", "the", "Colegio", "Miguel", "Hern\u00e1ndez", ",", "Ceulaj", "and", "the", "Benalm\u00e1dena", "sports", "arena", "in", "M\u00e1laga", ",", "Spain", ",", "and", "for", "the", "past", "15", "years", "at", "the", "Valencia", "Regional", "Fair", "and", "the", "Valencia", "City", "of", "Arts", "and", "Sciences", "."], "sentence-detokenized": "The Campus Party has been held in Spain at the Colegio Miguel Hern\u00e1ndez, Ceulaj and the Benalm\u00e1dena sports arena in M\u00e1laga, Spain, and for the past 15 years at the Valencia Regional Fair and the Valencia City of Arts and Sciences.", "token2charspan": [[0, 3], [4, 10], [11, 16], [17, 20], [21, 25], [26, 30], [31, 33], [34, 39], [40, 42], [43, 46], [47, 54], [55, 61], [62, 71], [71, 72], [73, 79], [80, 83], [84, 87], [88, 99], [100, 106], [107, 112], [113, 115], [116, 122], [122, 123], [124, 129], [129, 130], [131, 134], [135, 138], [139, 142], [143, 147], [148, 150], [151, 156], [157, 159], [160, 163], [164, 172], [173, 181], [182, 186], [187, 190], [191, 194], [195, 203], [204, 208], [209, 211], [212, 216], [217, 220], [221, 229], [229, 230]]}
{"doc_key": "ai-dev-195", "ner": [[0, 2, "product"], [15, 15, "programlang"], [18, 18, "product"], [20, 20, "product"], [24, 24, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 15, 0, 2, "general-affiliation", "", false, false], [18, 18, 15, 15, "part-of", "", false, false], [20, 20, 15, 15, "part-of", "", false, false], [24, 24, 0, 2, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["gnuplot", "can", "be", "used", "to", "plot", "data", "from", "a", "variety", "of", "programming", "languages", ",", "including", "Perl", "(", "via", "PDL", "and", "CPAN", "packages", ")", ",", "Python", "(", "via", ")", "."], "sentence-detokenized": "gnuplot can be used to plot data from a variety of programming languages, including Perl (via PDL and CPAN packages), Python (via).", "token2charspan": [[0, 7], [8, 11], [12, 14], [15, 19], [20, 22], [23, 27], [28, 32], [33, 37], [38, 39], [40, 47], [48, 50], [51, 62], [63, 72], [72, 73], [74, 83], [84, 88], [89, 90], [90, 93], [94, 97], [98, 101], [102, 106], [107, 115], [115, 116], [116, 117], [118, 124], [125, 126], [126, 129], [129, 130], [130, 131]]}
{"doc_key": "ai-dev-196", "ner": [[3, 7, "product"], [21, 21, "conference"], [23, 23, "conference"], [37, 37, "conference"], [39, 39, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 21, 3, 7, "topic", "", false, false], [23, 23, 3, 7, "topic", "", false, false], [37, 37, 3, 7, "topic", "", false, false], [39, 39, 3, 7, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "field", "of", "speech", "to", "speech", "dialogue", "systems", "is", "quite", "large", "and", "includes", "both", "research", "(", "with", "scientific", "conferences", "such", "as", "SIGdial", "and", "Interspeech", ")", "and", "a", "large", "industrial", "sector", "(", "with", "its", "own", "meetings", "such", "as", "SpeechTek", "and", "AVIOS", ")", "."], "sentence-detokenized": "The field of speech to speech dialogue systems is quite large and includes both research (with scientific conferences such as SIGdial and Interspeech) and a large industrial sector (with its own meetings such as SpeechTek and AVIOS).", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 22], [23, 29], [30, 38], [39, 46], [47, 49], [50, 55], [56, 61], [62, 65], [66, 74], [75, 79], [80, 88], [89, 90], [90, 94], [95, 105], [106, 117], [118, 122], [123, 125], [126, 133], [134, 137], [138, 149], [149, 150], [151, 154], [155, 156], [157, 162], [163, 173], [174, 180], [181, 182], [182, 186], [187, 190], [191, 194], [195, 203], [204, 208], [209, 211], [212, 221], [222, 225], [226, 231], [231, 232], [232, 233]]}
{"doc_key": "ai-dev-197", "ner": [[2, 4, "field"], [7, 8, "task"], [10, 12, "task"], [14, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 2, 4, "part-of", "task_part_of_field", false, false], [10, 12, 2, 4, "part-of", "task_part_of_field", false, false], [14, 16, 2, 4, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Problems", "with", "natural", "language", "processing", "often", "include", "speech", "recognition", ",", "natural", "language", "understanding", "and", "natural", "language", "generation", "."], "sentence-detokenized": "Problems with natural language processing often include speech recognition, natural language understanding and natural language generation.", "token2charspan": [[0, 8], [9, 13], [14, 21], [22, 30], [31, 41], [42, 47], [48, 55], [56, 62], [63, 74], [74, 75], [76, 83], [84, 92], [93, 106], [107, 110], [111, 118], [119, 127], [128, 138], [138, 139]]}
{"doc_key": "ai-dev-198", "ner": [[9, 9, "product"], [5, 8, "product"], [34, 36, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 5, 8, "part-of", "", false, false], [9, 9, 34, 36, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "such", "as", "the", "iOS", "operating", "system", "Siri", ",", "work", "on", "the", "basis", "of", "a", "similar", "pattern", "recognition", "technique", "as", "text", "-", "based", "systems", ",", "but", "in", "the", "former", "user", "input", "is", "via", "speech", "recognition", "."], "sentence-detokenized": "These systems, such as the iOS operating system Siri, work on the basis of a similar pattern recognition technique as text-based systems, but in the former user input is via speech recognition.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 22], [23, 26], [27, 30], [31, 40], [41, 47], [48, 52], [52, 53], [54, 58], [59, 61], [62, 65], [66, 71], [72, 74], [75, 76], [77, 84], [85, 92], [93, 104], [105, 114], [115, 117], [118, 122], [122, 123], [123, 128], [129, 136], [136, 137], [138, 141], [142, 144], [145, 148], [149, 155], [156, 160], [161, 166], [167, 169], [170, 173], [174, 180], [181, 192], [192, 193]]}
{"doc_key": "ai-dev-199", "ner": [[0, 7, "algorithm"], [16, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 7, 16, 17, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["More", "exotic", "goodness", "-", "of", "-", "fit", "functions", "that", "explore", "the", "granularity", "of", "the", "model", "include", "ROC", "curve", "area", "and", "rank", "measures", "."], "sentence-detokenized": "More exotic goodness-of-fit functions that explore the granularity of the model include ROC curve area and rank measures.", "token2charspan": [[0, 4], [5, 11], [12, 20], [20, 21], [21, 23], [23, 24], [24, 27], [28, 37], [38, 42], [43, 50], [51, 54], [55, 66], [67, 69], [70, 73], [74, 79], [80, 87], [88, 91], [92, 97], [98, 102], [103, 106], [107, 111], [112, 120], [120, 121]]}
{"doc_key": "ai-dev-200", "ner": [[2, 4, "product"], [7, 10, "researcher"], [16, 18, "product"], [24, 26, "organisation"], [23, 28, "organisation"], [38, 40, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 4, 7, 10, "origin", "", false, false], [7, 10, 24, 26, "role", "", false, false], [16, 18, 7, 10, "origin", "", false, false], [23, 28, 24, 26, "named", "", false, false], [38, 40, 24, 26, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "term", "Semantic", "Web", "was", "coined", "by", "Tim", "Berners", "-", "Lee", ",", "the", "inventor", "of", "the", "World", "Wide", "Web", "and", "director", "of", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "who", "oversees", "the", "development", "of", "the", "proposed", "Semantic", "Web", "standards", "."], "sentence-detokenized": "The term Semantic Web was coined by Tim Berners-Lee, the inventor of the World Wide Web and director of the World Wide Web Consortium (W3C), who oversees the development of the proposed Semantic Web standards.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 25], [26, 32], [33, 35], [36, 39], [40, 47], [47, 48], [48, 51], [51, 52], [53, 56], [57, 65], [66, 68], [69, 72], [73, 78], [79, 83], [84, 87], [88, 91], [92, 100], [101, 103], [104, 107], [108, 113], [114, 118], [119, 122], [123, 133], [134, 135], [135, 138], [138, 139], [139, 140], [141, 144], [145, 153], [154, 157], [158, 169], [170, 172], [173, 176], [177, 185], [186, 194], [195, 198], [199, 208], [208, 209]]}
{"doc_key": "ai-dev-201", "ner": [[0, 1, "task"], [5, 5, "task"], [12, 13, "product"], [16, 16, "product"], [15, 18, "product"], [21, 22, "product"], [29, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 12, 13, "opposite", "", false, false], [0, 1, 16, 16, "opposite", "", false, false], [0, 1, 21, 22, "opposite", "", false, false], [0, 1, 29, 30, "part-of", "", false, false], [5, 5, 0, 1, "named", "", false, false], [15, 18, 16, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Machine", "translation", ",", "sometimes", "abbreviated", "MT", "(", "not", "to", "be", "confused", "with", "computer-assisted", "translation", ",", "machine", "interpreting", "(", "MAHT", ")", "or", "interactive", "translation", ")", ",", "is", "a", "branch", "of", "computer", "linguistics", "that", "studies", "the", "use", "of", "software", "to", "translate", "text", "or", "speech", "from", "one", "language", "into", "another", "."], "sentence-detokenized": "Machine translation, sometimes abbreviated MT (not to be confused with computer-assisted translation, machine interpreting (MAHT) or interactive translation), is a branch of computer linguistics that studies the use of software to translate text or speech from one language into another.", "token2charspan": [[0, 7], [8, 19], [19, 20], [21, 30], [31, 42], [43, 45], [46, 47], [47, 50], [51, 53], [54, 56], [57, 65], [66, 70], [71, 88], [89, 100], [100, 101], [102, 109], [110, 122], [123, 124], [124, 128], [128, 129], [130, 132], [133, 144], [145, 156], [156, 157], [157, 158], [159, 161], [162, 163], [164, 170], [171, 173], [174, 182], [183, 194], [195, 199], [200, 207], [208, 211], [212, 215], [216, 218], [219, 227], [228, 230], [231, 240], [241, 245], [246, 248], [249, 255], [256, 260], [261, 264], [265, 273], [274, 278], [279, 286], [286, 287]]}
{"doc_key": "ai-dev-202", "ner": [[1, 4, "product"], [14, 17, "university"], [9, 10, "researcher"], [12, 13, "researcher"], [39, 43, "location"], [41, 41, "location"], [44, 52, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 4, 9, 10, "artifact", "", false, false], [1, 4, 12, 13, "artifact", "", false, false], [9, 10, 14, 17, "physical", "", false, false], [9, 10, 14, 17, "role", "", false, false], [12, 13, 14, 17, "physical", "", false, false], [12, 13, 14, 17, "role", "", false, false], [39, 43, 41, 41, "physical", "", false, false], [44, 52, 39, 43, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Early", "cross", "-language", "MT", "systems", "were", "also", "built", "by", "Roger", "Schank", "and", "Yorick", "Wilks", "at", "Stanford", "in", "the", "1970s", ";", "the", "former", "became", "the", "basis", "for", "a", "commercial", "money", "transfer", "system", ",", "and", "the", "latter", "'s", "code", "is", "preserved", "at", "the", "Boston", "Computer", "Museum", "as", "the", "first", "cross", "-", "language", "machine", "translation", "system", "."], "sentence-detokenized": "Early cross-language MT systems were also built by Roger Schank and Yorick Wilks at Stanford in the 1970s; the former became the basis for a commercial money transfer system, and the latter's code is preserved at the Boston Computer Museum as the first cross-language machine translation system.", "token2charspan": [[0, 5], [6, 11], [11, 20], [21, 23], [24, 31], [32, 36], [37, 41], [42, 47], [48, 50], [51, 56], [57, 63], [64, 67], [68, 74], [75, 80], [81, 83], [84, 92], [93, 95], [96, 99], [100, 105], [105, 106], [107, 110], [111, 117], [118, 124], [125, 128], [129, 134], [135, 138], [139, 140], [141, 151], [152, 157], [158, 166], [167, 173], [173, 174], [175, 178], [179, 182], [183, 189], [189, 191], [192, 196], [197, 199], [200, 209], [210, 212], [213, 216], [217, 223], [224, 232], [233, 239], [240, 242], [243, 246], [247, 252], [253, 258], [258, 259], [259, 267], [268, 275], [276, 287], [288, 294], [294, 295]]}
{"doc_key": "ai-dev-203", "ner": [[0, 1, "researcher"], [6, 10, "conference"], [7, 13, "conference"], [20, 24, "conference"], [26, 27, "conference"], [33, 36, "organisation"], [44, 44, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 6, 10, "role", "", false, false], [0, 1, 20, 24, "role", "", false, false], [0, 1, 33, 36, "role", "", false, false], [0, 1, 44, 44, "role", "", false, false], [7, 13, 6, 10, "named", "", false, false], [26, 27, 20, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sycara", "was", "Programme", "Chair", "of", "the", "Second", "International", "Semantic", "Web", "Conference", "(", "ISWC", "2003", ")", ";", "General", "Chair", "of", "the", "Second", "International", "Autonomous", "Agents", "Conference", "(", "Agents", "98", ")", ";", "Chair", "of", "the", "Agents", "Conference", "Steering", "Committee", "(", "1999-2001", ")", ";", "Chair", "of", "the", "AAAI", "Fellowship", "(", "1993-1999", ")", ";"], "sentence-detokenized": "Sycara was Programme Chair of the Second International Semantic Web Conference (ISWC 2003); General Chair of the Second International Autonomous Agents Conference (Agents 98); Chair of the Agents Conference Steering Committee (1999-2001); Chair of the AAAI Fellowship (1993-1999);", "token2charspan": [[0, 6], [7, 10], [11, 20], [21, 26], [27, 29], [30, 33], [34, 40], [41, 54], [55, 63], [64, 67], [68, 78], [79, 80], [80, 84], [85, 89], [89, 90], [90, 91], [92, 99], [100, 105], [106, 108], [109, 112], [113, 119], [120, 133], [134, 144], [145, 151], [152, 162], [163, 164], [164, 170], [171, 173], [173, 174], [174, 175], [176, 181], [182, 184], [185, 188], [189, 195], [196, 206], [207, 215], [216, 225], [226, 227], [227, 236], [236, 237], [237, 238], [239, 244], [245, 247], [248, 251], [252, 256], [257, 267], [268, 269], [269, 278], [278, 279], [279, 280]]}
{"doc_key": "ai-dev-204", "ner": [[11, 11, "conference"], [13, 16, "conference"], [18, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 16, 11, 11, "named", "", false, false], [18, 20, 11, 11, "part-of", "", false, false], [18, 20, 11, 11, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2016", ",", "he", "was", "selected", "as", "the", "recipient", "of", "the", "ACL", "(", "Association", "for", "Computational", "Linguistics", ")", "Lifetime", "Achievement", "Award", "."], "sentence-detokenized": "In 2016, he was selected as the recipient of the ACL (Association for Computational Linguistics) Lifetime Achievement Award.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 24], [25, 27], [28, 31], [32, 41], [42, 44], [45, 48], [49, 52], [53, 54], [54, 65], [66, 69], [70, 83], [84, 95], [95, 96], [97, 105], [106, 117], [118, 123], [123, 124]]}
{"doc_key": "ai-dev-205", "ner": [[0, 1, "researcher"], [3, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", ",", "Y", ".", "Bengio", ",", "P.", "Frasconi", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Sepp Hochreiter, Y. Bengio, P. Frasconi and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 15], [15, 16], [17, 18], [18, 19], [20, 26], [26, 27], [28, 30], [31, 39], [40, 43], [44, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-206", "ner": [[3, 3, "product"], [5, 7, "misc"], [9, 11, "programlang"], [19, 20, "product"], [32, 32, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 9, 11, "usage", "", false, false], [9, 11, 5, 7, "type-of", "", false, false], [9, 11, 19, 20, "related-to", "", false, false], [32, 32, 3, 3, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["For", "example", ",", "A.L.I.C.E.", "uses", "a", "markup", "language", "called", "AIML", ",", "which", "is", "specific", "to", "its", "function", "as", "a", "dialog", "system", "and", "has", "subsequently", "been", "adopted", "by", "several", "other", "so", "-", "called", "Alicebot", "developers", "."], "sentence-detokenized": "For example, A.L.I.C.E. uses a markup language called AIML, which is specific to its function as a dialog system and has subsequently been adopted by several other so-called Alicebot developers.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 23], [24, 28], [29, 30], [31, 37], [38, 46], [47, 53], [54, 58], [58, 59], [60, 65], [66, 68], [69, 77], [78, 80], [81, 84], [85, 93], [94, 96], [97, 98], [99, 105], [106, 112], [113, 116], [117, 120], [121, 133], [134, 138], [139, 146], [147, 149], [150, 157], [158, 163], [164, 166], [166, 167], [167, 173], [174, 182], [183, 193], [193, 194]]}
{"doc_key": "ai-dev-207", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2000", ",", "he", "was", "elected", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2000, he was elected a member of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [98, 99]]}
{"doc_key": "ai-dev-208", "ner": [[2, 2, "misc"], [0, 6, "misc"], [10, 16, "misc"], [23, 25, "algorithm"], [34, 35, "field"], [37, 38, "field"], [40, 41, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 2, 10, 16, "type-of", "", false, false], [2, 2, 34, 35, "related-to", "performs", true, false], [2, 2, 37, 38, "related-to", "performs", true, false], [2, 2, 40, 41, "related-to", "performs", true, false], [0, 6, 2, 2, "named", "", false, false], [23, 25, 10, 16, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Learning", "Classifier", "Systems", "(", "LCS", ")", "are", "a", "family", "of", "rule", "-", "based", "machine", "learning", "algorithms", "that", "combine", "a", "discovery", "component", ",", "usually", "a", "genetic", "algorithm", ",", "with", "a", "learning", "component", "that", "performs", "either", "supervised", "learning", ",", "reinforcement", "learning", "or", "unsupervised", "learning", "."], "sentence-detokenized": "Learning Classifier Systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, usually a genetic algorithm, with a learning component that performs either supervised learning, reinforcement learning or unsupervised learning.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 29], [29, 32], [32, 33], [34, 37], [38, 39], [40, 46], [47, 49], [50, 54], [54, 55], [55, 60], [61, 68], [69, 77], [78, 88], [89, 93], [94, 101], [102, 103], [104, 113], [114, 123], [123, 124], [125, 132], [133, 134], [135, 142], [143, 152], [152, 153], [154, 158], [159, 160], [161, 169], [170, 179], [180, 184], [185, 193], [194, 200], [201, 211], [212, 220], [220, 221], [222, 235], [236, 244], [245, 247], [248, 260], [261, 269], [269, 270]]}
{"doc_key": "ai-dev-209", "ner": [[16, 17, "algorithm"], [15, 19, "algorithm"], [29, 30, "algorithm"], [33, 35, "misc"], [44, 47, "algorithm"], [52, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[16, 17, 29, 30, "origin", "", false, false], [16, 17, 33, 35, "usage", "", false, false], [15, 19, 16, 17, "named", "", false, false], [44, 47, 33, 35, "type-of", "", false, false], [44, 47, 52, 55, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "unknown", "parameters", "of", "each", "vector", "\u03b2subk", "/", "sub", "are", "usually", "jointly", "estimated", "by", "a", "maximum", "a", "posteriori", "(", "MAP", ")", "estimate", ",", "which", "is", "an", "expansion", "of", "the", "maximum", "likelihood", ",", "using", "a", "regularization", "of", "the", "weights", "to", "avoid", "pathological", "solutions", "(", "usually", "a", "quadratic", "regularizing", "function", "equivalent", "to", "fitting", "a", "zero-mean", "Gaussian", "prior", "distribution", "to", "the", "weights", ",", "but", "other", "distributions", "are", "also", "possible", ")", "."], "sentence-detokenized": "The unknown parameters of each vector \u03b2subk/sub are usually jointly estimated by a maximum a posteriori (MAP) estimate, which is an expansion of the maximum likelihood, using a regularization of the weights to avoid pathological solutions (usually a quadratic regularizing function equivalent to fitting a zero-mean Gaussian prior distribution to the weights, but other distributions are also possible).", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 25], [26, 30], [31, 37], [38, 43], [43, 44], [44, 47], [48, 51], [52, 59], [60, 67], [68, 77], [78, 80], [81, 82], [83, 90], [91, 92], [93, 103], [104, 105], [105, 108], [108, 109], [110, 118], [118, 119], [120, 125], [126, 128], [129, 131], [132, 141], [142, 144], [145, 148], [149, 156], [157, 167], [167, 168], [169, 174], [175, 176], [177, 191], [192, 194], [195, 198], [199, 206], [207, 209], [210, 215], [216, 228], [229, 238], [239, 240], [240, 247], [248, 249], [250, 259], [260, 272], [273, 281], [282, 292], [293, 295], [296, 303], [304, 305], [306, 315], [316, 324], [325, 330], [331, 343], [344, 346], [347, 350], [351, 358], [358, 359], [360, 363], [364, 369], [370, 383], [384, 387], [388, 392], [393, 401], [401, 402], [402, 403]]}
{"doc_key": "ai-dev-210", "ner": [[9, 9, "researcher"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 9, 9, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "hierarchical", "structure", "of", "words", "is", "explicitly", "mapped", "in", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "The hierarchical structure of words is explicitly mapped in George Miller's Wordnet.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 29], [30, 35], [36, 38], [39, 49], [50, 56], [57, 59], [60, 66], [67, 73], [73, 75], [76, 83], [83, 84]]}
{"doc_key": "ai-dev-211", "ner": [[6, 13, "conference"], [16, 20, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 20, 6, 13, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Their", "capabilities", "are", "illustrated", "by", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", ",", "a", "benchmark", "for", "object", "classification", "and", "recognition", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "Their capabilities are illustrated by the ImageNet Large Scale Visual Recognition Challenge, a benchmark for object classification and recognition with millions of images and hundreds of object classes.", "token2charspan": [[0, 5], [6, 18], [19, 22], [23, 34], [35, 37], [38, 41], [42, 50], [51, 56], [57, 62], [63, 69], [70, 81], [82, 91], [91, 92], [93, 94], [95, 104], [105, 108], [109, 115], [116, 130], [131, 134], [135, 146], [147, 151], [152, 160], [161, 163], [164, 170], [171, 174], [175, 183], [184, 186], [187, 193], [194, 201], [201, 202]]}
{"doc_key": "ai-dev-212", "ner": [[0, 2, "misc"], [21, 21, "misc"], [24, 26, "person"], [31, 31, "misc"], [36, 37, "person"], [41, 43, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[21, 21, 0, 2, "general-affiliation", "", false, false], [31, 31, 0, 2, "general-affiliation", "", false, false], [31, 31, 24, 26, "artifact", "", false, false], [41, 43, 0, 2, "general-affiliation", "", false, false], [41, 43, 36, 37, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "science", "fiction", ",", "female", "robots", "are", "often", "portrayed", "as", "domestic", "servants", "and", "sex", "slaves", ",", "as", "seen", "in", "the", "film", "Westworld", ",", "by", "Paul", "J.", "Wilson", ".", "McAuley", "'s", "novel", "Fairyland", "(", "1995", ")", "and", "Lester", "del", "Rey's", "short", "story", "Helen", "O'", "Loy", "(", "1938", ")", ",", "and", "sometimes", "as", "warriors", ",", "killers", "or", "workers", "."], "sentence-detokenized": "In science fiction, female robots are often portrayed as domestic servants and sex slaves, as seen in the film Westworld, by Paul J. Wilson. McAuley's novel Fairyland (1995) and Lester del Rey's short story Helen O'Loy (1938), and sometimes as warriors, killers or workers.", "token2charspan": [[0, 2], [3, 10], [11, 18], [18, 19], [20, 26], [27, 33], [34, 37], [38, 43], [44, 53], [54, 56], [57, 65], [66, 74], [75, 78], [79, 82], [83, 89], [89, 90], [91, 93], [94, 98], [99, 101], [102, 105], [106, 110], [111, 120], [120, 121], [122, 124], [125, 129], [130, 132], [133, 139], [139, 140], [141, 148], [148, 150], [151, 156], [157, 166], [167, 168], [168, 172], [172, 173], [174, 177], [178, 184], [185, 188], [189, 194], [195, 200], [201, 206], [207, 212], [213, 215], [215, 218], [219, 220], [220, 224], [224, 225], [225, 226], [227, 230], [231, 240], [241, 243], [244, 252], [252, 253], [254, 261], [262, 264], [265, 272], [272, 273]]}
{"doc_key": "ai-dev-213", "ner": [[0, 1, "task"], [3, 4, "task"], [6, 7, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["answering", "questions", ",", "speech", "recognition", "and", "machine", "translation", "."], "sentence-detokenized": "answering questions, speech recognition and machine translation.", "token2charspan": [[0, 9], [10, 19], [19, 20], [21, 27], [28, 39], [40, 43], [44, 51], [52, 63], [63, 64]]}
{"doc_key": "ai-dev-214", "ner": [[5, 6, "researcher"], [7, 13, "organisation"], [15, 19, "location"], [20, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 7, 13, "role", "", false, false], [7, 13, 15, 19, "physical", "", false, false], [15, 19, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "his", "seminal", "work", ",", "Harry", "Blum", "of", "the", "Air", "Force", "Cambridge", "Research", "Laboratory", "at", "Hanscom", "Air", "Force", "Base", "in", "Bedford", ",", "Massachusetts", ",", "defined", "a", "mean", "axis", "shape", "for", "skeleton", "calculations", "using", "an", "intuitive", "model", "of", "fire", "propagation", "in", "a", "grass", "field", "where", "the", "field", "has", "a", "given", "shape", "."], "sentence-detokenized": "In his seminal work, Harry Blum of the Air Force Cambridge Research Laboratory at Hanscom Air Force Base in Bedford, Massachusetts, defined a mean axis shape for skeleton calculations using an intuitive model of fire propagation in a grass field where the field has a given shape.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 19], [19, 20], [21, 26], [27, 31], [32, 34], [35, 38], [39, 42], [43, 48], [49, 58], [59, 67], [68, 78], [79, 81], [82, 89], [90, 93], [94, 99], [100, 104], [105, 107], [108, 115], [115, 116], [117, 130], [130, 131], [132, 139], [140, 141], [142, 146], [147, 151], [152, 157], [158, 161], [162, 170], [171, 183], [184, 189], [190, 192], [193, 202], [203, 208], [209, 211], [212, 216], [217, 228], [229, 231], [232, 233], [234, 239], [240, 245], [246, 251], [252, 255], [256, 261], [262, 265], [266, 267], [268, 273], [274, 279], [279, 280]]}
{"doc_key": "ai-dev-215", "ner": [[14, 14, "algorithm"], [16, 16, "algorithm"], [0, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 0, 20, "compare", "", false, false], [16, 16, 0, 20, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "unlike", "boosting", "algorithms", "that", "analytically", "minimize", "the", "convex", "loss", "function", "(", "e.g.", "AdaBoost", "and", "LogitBoost", ")", ",", "Brown", "Boost", "solves", "a", "system", "of", "two", "equations", "and", "two", "unknowns", "using", "standard", "numerical", "methods", "."], "sentence-detokenized": "However, unlike boosting algorithms that analytically minimize the convex loss function (e.g. AdaBoost and LogitBoost), BrownBoost solves a system of two equations and two unknowns using standard numerical methods.", "token2charspan": [[0, 7], [7, 8], [9, 15], [16, 24], [25, 35], [36, 40], [41, 53], [54, 62], [63, 66], [67, 73], [74, 78], [79, 87], [88, 89], [89, 93], [94, 102], [103, 106], [107, 117], [117, 118], [118, 119], [120, 125], [125, 130], [131, 137], [138, 139], [140, 146], [147, 149], [150, 153], [154, 163], [164, 167], [168, 171], [172, 180], [181, 186], [187, 195], [196, 205], [206, 213], [213, 214]]}
{"doc_key": "ai-dev-216", "ner": [[11, 14, "misc"], [20, 24, "conference"], [26, 26, "conference"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[26, 26, 20, 24, "named", "", false, false]], "relations_mapping_to_source": [2], "sentence": ["Getoor", "is", "the", "recipient", "of", "several", "best", "paper", "awards", ",", "an", "NSF", "Career", "Achievement", "Award", "and", "is", "an", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "Fellow", "."], "sentence-detokenized": "Getoor is the recipient of several best paper awards, an NSF Career Achievement Award and is an Association for the Advancement of Artificial Intelligence (AAAI) Fellow.", "token2charspan": [[0, 6], [7, 9], [10, 13], [14, 23], [24, 26], [27, 34], [35, 39], [40, 45], [46, 52], [52, 53], [54, 56], [57, 60], [61, 67], [68, 79], [80, 85], [86, 89], [90, 92], [93, 95], [96, 107], [108, 111], [112, 115], [116, 127], [128, 130], [131, 141], [142, 154], [155, 156], [156, 160], [160, 161], [162, 168], [168, 169]]}
{"doc_key": "ai-dev-217", "ner": [[0, 1, "misc"], [6, 10, "misc"], [15, 16, "misc"], [21, 25, "misc"], [30, 34, "university"], [39, 47, "misc"], [52, 60, "misc"], [65, 78, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["ACM", "Fellow", "(", "2015", ")", "br", "Association", "for", "Computational", "Linguistics", "Fellow", "(", "2011", ")", "br", "AAAI", "Fellow", "(", "1994", ")", "br", "International", "Speech", "Communication", "Association", "Fellow", "(", "2011", ")", "br", "KTH", "Royal", "Institute", "of", "Technology", "(", "2007", ")", "br", "Columbia", "Engineering", "School", "Alumni", "Association", "Distinguished", "Faculty", "Teaching", "Award", "(", "2009", ")", "br", "IEEE", "James", "L.", "Flanagan", "Speech", "and", "Audio", "Processing", "Award", "(", "2011", ")", "br", "ISCA", "Medal", "for", "Scientific", "Achievement", "(", "2011", ")", "br", "ISCA", "Medal", "for", "Scientific", "Achievement", "(", "2011", ")"], "sentence-detokenized": "ACM Fellow (2015) br Association for Computational Linguistics Fellow (2011) br AAAI Fellow (1994) br International Speech Communication Association Fellow (2011) br KTH Royal Institute of Technology (2007) br Columbia Engineering School Alumni Association Distinguished Faculty Teaching Award (2009) br IEEE James L. Flanagan Speech and Audio Processing Award (2011) br ISCA Medal for Scientific Achievement (2011) br ISCA Medal for Scientific Achievement (2011)", "token2charspan": [[0, 3], [4, 10], [11, 12], [12, 16], [16, 17], [18, 20], [21, 32], [33, 36], [37, 50], [51, 62], [63, 69], [70, 71], [71, 75], [75, 76], [77, 79], [80, 84], [85, 91], [92, 93], [93, 97], [97, 98], [99, 101], [102, 115], [116, 122], [123, 136], [137, 148], [149, 155], [156, 157], [157, 161], [161, 162], [163, 165], [166, 169], [170, 175], [176, 185], [186, 188], [189, 199], [200, 201], [201, 205], [205, 206], [207, 209], [210, 218], [219, 230], [231, 237], [238, 244], [245, 256], [257, 270], [271, 278], [279, 287], [288, 293], [294, 295], [295, 299], [299, 300], [301, 303], [304, 308], [309, 314], [315, 317], [318, 326], [327, 333], [334, 337], [338, 343], [344, 354], [355, 360], [361, 362], [362, 366], [366, 367], [368, 370], [371, 375], [376, 381], [382, 385], [386, 396], [397, 408], [409, 410], [410, 414], [414, 415], [416, 418], [419, 423], [424, 429], [430, 433], [434, 444], [445, 456], [457, 458], [458, 462], [462, 463]]}
{"doc_key": "ai-dev-218", "ner": [[6, 6, "university"], [14, 17, "task"], [25, 26, "metrics"], [39, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[25, 26, 39, 40, "opposite", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["A", "disappointing", "result", "of", "the", "same", "Stanford", "study", "(", "and", "other", "attempts", "to", "improve", "name", "recognition", "in", "translation", ")", "is", "that", "in", "many", "cases", "the", "bilingual", "assessment", "subscores", "for", "translation", "are", "reduced", "as", "a", "result", "of", "the", "addition", "of", "name", "translation", "methods", "."], "sentence-detokenized": "A disappointing result of the same Stanford study (and other attempts to improve name recognition in translation) is that in many cases the bilingual assessment subscores for translation are reduced as a result of the addition of name translation methods.", "token2charspan": [[0, 1], [2, 15], [16, 22], [23, 25], [26, 29], [30, 34], [35, 43], [44, 49], [50, 51], [51, 54], [55, 60], [61, 69], [70, 72], [73, 80], [81, 85], [86, 97], [98, 100], [101, 112], [112, 113], [114, 116], [117, 121], [122, 124], [125, 129], [130, 135], [136, 139], [140, 149], [150, 160], [161, 170], [171, 174], [175, 186], [187, 190], [191, 198], [199, 201], [202, 203], [204, 210], [211, 213], [214, 217], [218, 226], [227, 229], [230, 234], [235, 246], [247, 254], [254, 255]]}
{"doc_key": "ai-dev-219", "ner": [[0, 0, "organisation"], [12, 14, "organisation"], [17, 23, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 12, 14, "role", "works_with", false, false], [0, 0, 17, 23, "role", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Medtronic", "will", "use", "the", "collected", "PM", "data", "and", "collaborate", "with", "researchers", "at", "Johns", "Hopkins", "Hospital", "and", "the", "University", "of", "Washington", "School", "of", "Medicine", "to", "help", "answer", "specific", "questions", "about", "heart", "disease", ",", "such", "as", "whether", "a", "weak", "heart", "causes", "arrhythmias", "or", "vice", "versa", "."], "sentence-detokenized": "Medtronic will use the collected PM data and collaborate with researchers at Johns Hopkins Hospital and the University of Washington School of Medicine to help answer specific questions about heart disease, such as whether a weak heart causes arrhythmias or vice versa.", "token2charspan": [[0, 9], [10, 14], [15, 18], [19, 22], [23, 32], [33, 35], [36, 40], [41, 44], [45, 56], [57, 61], [62, 73], [74, 76], [77, 82], [83, 90], [91, 99], [100, 103], [104, 107], [108, 118], [119, 121], [122, 132], [133, 139], [140, 142], [143, 151], [152, 154], [155, 159], [160, 166], [167, 175], [176, 185], [186, 191], [192, 197], [198, 205], [205, 206], [207, 211], [212, 214], [215, 222], [223, 224], [225, 229], [230, 235], [236, 242], [243, 254], [255, 257], [258, 262], [263, 268], [268, 269]]}
{"doc_key": "ai-dev-220", "ner": [[4, 4, "organisation"], [9, 10, "misc"], [11, 12, "person"], [14, 15, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 4, 4, "artifact", "made_by_studio", false, false], [11, 12, 9, 10, "role", "", false, false], [14, 15, 9, 10, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "was", "followed", "by", "Paramount", "'s", "first", "feature", "film", "Sangaree", "with", "Fernando", "Lamas", "and", "Arlene", "Dahle", "."], "sentence-detokenized": "This was followed by Paramount's first feature film Sangaree with Fernando Lamas and Arlene Dahle.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 20], [21, 30], [30, 32], [33, 38], [39, 46], [47, 51], [52, 60], [61, 65], [66, 74], [75, 80], [81, 84], [85, 91], [92, 97], [97, 98]]}
{"doc_key": "ai-dev-221", "ner": [[0, 0, "programlang"], [8, 10, "researcher"], [12, 13, "researcher"], [15, 16, "organisation"], [18, 19, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 10, "origin", "", false, false], [0, 0, 12, 13, "origin", "", false, false], [8, 10, 15, 16, "physical", "", false, false], [8, 10, 15, 16, "role", "", false, false], [12, 13, 18, 19, "physical", "", false, false], [12, 13, 18, 19, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["KRL", "is", "a", "knowledge", "representation", "language", "developed", "by", "Daniel", "G.", "Bobrow", "and", "Terry", "Winograd", "at", "Xerox", "PARC", "and", "Stanford", "University", ",", "respectively", "."], "sentence-detokenized": "KRL is a knowledge representation language developed by Daniel G. Bobrow and Terry Winograd at Xerox PARC and Stanford University, respectively.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 18], [19, 33], [34, 42], [43, 52], [53, 55], [56, 62], [63, 65], [66, 72], [73, 76], [77, 82], [83, 91], [92, 94], [95, 100], [101, 105], [106, 109], [110, 118], [119, 129], [129, 130], [131, 143], [143, 144]]}
{"doc_key": "ai-dev-222", "ner": [[0, 12, "conference"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [24, 27, "researcher"], [36, 37, "task"], [38, 41, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 12, 36, 37, "topic", "", true, false], [15, 16, 0, 12, "physical", "", false, false], [15, 16, 0, 12, "role", "", false, false], [15, 16, 0, 12, "temporal", "", false, false], [18, 19, 0, 12, "physical", "", false, false], [18, 19, 0, 12, "role", "", false, false], [18, 19, 0, 12, "temporal", "", false, false], [21, 22, 0, 12, "physical", "", false, false], [21, 22, 0, 12, "role", "", false, false], [21, 22, 0, 12, "temporal", "", false, false], [24, 27, 0, 12, "physical", "", false, false], [24, 27, 0, 12, "role", "", false, false], [24, 27, 0, 12, "temporal", "", false, false], [36, 37, 38, 41, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["At", "the", "IEEE", "Conference", "on", "\"", "Computer", "Vision", "and", "Pattern", "Recognition", "\"", "in", "2006", ",", "Qiang", "Zhu", ",", "Shai", "Avidan", ",", "Mei-Chen", "Yeh", "and", "Kwang", "-", "Ting", "Cheng", "presented", "an", "algorithm", "that", "can", "significantly", "speed", "up", "human", "recognition", "using", "HOG", "descriptor", "methods", "."], "sentence-detokenized": "At the IEEE Conference on \"Computer Vision and Pattern Recognition\" in 2006, Qiang Zhu, Shai Avidan, Mei-Chen Yeh and Kwang-Ting Cheng presented an algorithm that can significantly speed up human recognition using HOG descriptor methods.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 22], [23, 25], [26, 27], [27, 35], [36, 42], [43, 46], [47, 54], [55, 66], [66, 67], [68, 70], [71, 75], [75, 76], [77, 82], [83, 86], [86, 87], [88, 92], [93, 99], [99, 100], [101, 109], [110, 113], [114, 117], [118, 123], [123, 124], [124, 128], [129, 134], [135, 144], [145, 147], [148, 157], [158, 162], [163, 166], [167, 180], [181, 186], [187, 189], [190, 195], [196, 207], [208, 213], [214, 217], [218, 228], [229, 236], [236, 237]]}
{"doc_key": "ai-dev-223", "ner": [[0, 2, "researcher"], [6, 6, "conference"], [3, 11, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 6, "role", "", false, false], [0, 2, 3, 11, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hayes", "is", "a", "member", "of", "the", "AAAI", "and", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Hayes is a member of the AAAI and the Cognitive Science Society.", "token2charspan": [[0, 5], [6, 8], [9, 10], [11, 17], [18, 20], [21, 24], [25, 29], [30, 33], [34, 37], [38, 47], [48, 55], [56, 63], [63, 64]]}
{"doc_key": "ai-dev-224", "ner": [[0, 1, "misc"], [4, 5, "field"], [7, 8, "field"], [10, 11, "field"], [13, 13, "field"], [15, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 32, "field"], [38, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[0, 1, 4, 5, "part-of", "", false, false], [0, 1, 4, 5, "usage", "", false, false], [0, 1, 7, 8, "part-of", "", false, false], [0, 1, 7, 8, "usage", "", false, false], [0, 1, 10, 11, "part-of", "", false, false], [0, 1, 10, 11, "usage", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [0, 1, 13, 13, "usage", "", false, false], [0, 1, 15, 16, "part-of", "", false, false], [0, 1, 15, 16, "usage", "", false, false], [0, 1, 18, 19, "part-of", "", false, false], [0, 1, 18, 19, "usage", "", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 21, 22, "usage", "", false, false], [0, 1, 24, 24, "part-of", "", false, false], [0, 1, 24, 24, "usage", "", false, false], [0, 1, 26, 27, "part-of", "", false, false], [0, 1, 26, 27, "usage", "", false, false], [0, 1, 29, 29, "part-of", "", false, false], [0, 1, 29, 29, "usage", "", false, false], [0, 1, 31, 32, "part-of", "", false, false], [0, 1, 31, 32, "usage", "", false, false], [0, 1, 38, 39, "part-of", "", false, false], [0, 1, 38, 39, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "sentence": ["Time", "series", "are", "used", "in", "statistics", ",", "signal", "processing", ",", "pattern", "recognition", ",", "econometrics", ",", "mathematical", "finance", ",", "weather", "forecasting", ",", "earthquake", "prediction", ",", "electroencephalography", ",", "control", "engineering", ",", "astronomy", ",", "communications", "engineering", "and", "largely", "all", "fields", "of", "applied", "science", "and", "engineering", "involving", "time", "measurements", "."], "sentence-detokenized": "Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, earthquake prediction, electroencephalography, control engineering, astronomy, communications engineering and largely all fields of applied science and engineering involving time measurements.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 23], [24, 34], [34, 35], [36, 42], [43, 53], [53, 54], [55, 62], [63, 74], [74, 75], [76, 88], [88, 89], [90, 102], [103, 110], [110, 111], [112, 119], [120, 131], [131, 132], [133, 143], [144, 154], [154, 155], [156, 178], [178, 179], [180, 187], [188, 199], [199, 200], [201, 210], [210, 211], [212, 226], [227, 238], [239, 242], [243, 250], [251, 254], [255, 261], [262, 264], [265, 272], [273, 280], [281, 284], [285, 296], [297, 306], [307, 311], [312, 324], [324, 325]]}
{"doc_key": "ai-dev-225", "ner": [[14, 15, "metrics"], [36, 38, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "principle", ",", "an", "exact", "recovery", "in", "its", "feasible", "range", "can", "be", "solved", "with", "maximum", "likelihood", ",", "but", "this", "implies", "solving", "a", "bounded", "or", "regularized", "pruning", "problem", ",", "such", "as", "minimum", "bisection", ",", "which", "is", "usually", "NP", "-", "complete", "."], "sentence-detokenized": "In principle, an exact recovery in its feasible range can be solved with maximum likelihood, but this implies solving a bounded or regularized pruning problem, such as minimum bisection, which is usually NP-complete.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 16], [17, 22], [23, 31], [32, 34], [35, 38], [39, 47], [48, 53], [54, 57], [58, 60], [61, 67], [68, 72], [73, 80], [81, 91], [91, 92], [93, 96], [97, 101], [102, 109], [110, 117], [118, 119], [120, 127], [128, 130], [131, 142], [143, 150], [151, 158], [158, 159], [160, 164], [165, 167], [168, 175], [176, 185], [185, 186], [187, 192], [193, 195], [196, 203], [204, 206], [206, 207], [207, 215], [215, 216]]}
{"doc_key": "ai-dev-226", "ner": [[5, 6, "task"], [10, 13, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 13, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["in", "it", "s", "work", "on", "pedestrian", "detection", ",", "first", "described", "in", "the", "BMVC", "in", "2009", "."], "sentence-detokenized": "in its work on pedestrian detection, first described in the BMVC in 2009.", "token2charspan": [[0, 2], [3, 5], [5, 6], [7, 11], [12, 14], [15, 25], [26, 35], [35, 36], [37, 42], [43, 52], [53, 55], [56, 59], [60, 64], [65, 67], [68, 72], [72, 73]]}
{"doc_key": "ai-dev-227", "ner": [[15, 20, "conference"], [3, 3, "researcher"], [5, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 15, 20, "physical", "", false, false], [3, 3, 15, 20, "role", "", false, false], [3, 3, 5, 14, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2007", ",", "Terzopoulos", "received", "the", "IEEE", "PAMI", "Computer", "Vision", "Distinguished", "Researcher", "Award", "at", "the", "International", "Computer", "Vision", "Conference", "for", "his", "pioneering", "and", "sustained", "research", "in", "deformable", "models", "and", "their", "applications", "."], "sentence-detokenized": "In 2007, Terzopoulos received the IEEE PAMI Computer Vision Distinguished Researcher Award at the International Computer Vision Conference for his pioneering and sustained research in deformable models and their applications.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 29], [30, 33], [34, 38], [39, 43], [44, 52], [53, 59], [60, 73], [74, 84], [85, 90], [91, 93], [94, 97], [98, 111], [112, 120], [121, 127], [128, 138], [139, 142], [143, 146], [147, 157], [158, 161], [162, 171], [172, 180], [181, 183], [184, 194], [195, 201], [202, 205], [206, 211], [212, 224], [224, 225]]}
{"doc_key": "ai-dev-228", "ner": [[0, 0, "task"], [1, 1, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 1, 1, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cluster", "analysis", "involves", "assigning", "data", "points", "to", "clusters", "in", "such", "a", "way", "that", "elements", "belonging", "to", "the", "same", "cluster", "are", "as", "similar", "as", "possible", ",", "while", "elements", "belonging", "to", "different", "clusters", "are", "as", "different", "as", "possible", "."], "sentence-detokenized": "Cluster analysis involves assigning data points to clusters in such a way that elements belonging to the same cluster are as similar as possible, while elements belonging to different clusters are as different as possible.", "token2charspan": [[0, 7], [8, 16], [17, 25], [26, 35], [36, 40], [41, 47], [48, 50], [51, 59], [60, 62], [63, 67], [68, 69], [70, 73], [74, 78], [79, 87], [88, 97], [98, 100], [101, 104], [105, 109], [110, 117], [118, 121], [122, 124], [125, 132], [133, 135], [136, 144], [144, 145], [146, 151], [152, 160], [161, 170], [171, 173], [174, 183], [184, 192], [193, 196], [197, 199], [200, 209], [210, 212], [213, 221], [221, 222]]}
{"doc_key": "ai-dev-229", "ner": [[8, 9, "field"], [15, 16, "field"], [18, 19, "task"], [21, 22, "field"], [24, 26, "field"], [28, 28, "field"], [29, 29, "field"], [34, 35, "task"], [37, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 9, 15, 16, "named", "", false, false], [8, 9, 21, 22, "named", "", false, false], [8, 9, 28, 28, "named", "", false, false], [18, 19, 15, 16, "part-of", "task_part_of_field", false, false], [24, 26, 21, 22, "part-of", "", false, false], [29, 29, 28, 28, "part-of", "", false, false], [34, 35, 29, 29, "part-of", "", false, false], [37, 37, 29, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["(", "2005", ")", ",", "three", "different", "perspectives", "of", "text", "mining", "can", "be", "distinguished", ",", "namely", "text", "mining", "as", "information", "mining", ",", "text", "mining", "as", "text", "data", "mining", "and", "text", "mining", "as", "a", "process", "of", "Knowledge", "Discovery", "in", "Databases.Hotho", ",", "A.", ",", "N\u00fcrnberger", ",", "A.", "and", "Paa\u00df", ",", "G.", "(", "2005", ")", "."], "sentence-detokenized": "(2005), three different perspectives of text mining can be distinguished, namely text mining as information mining, text mining as text data mining and text mining as a process of Knowledge Discovery in Databases.Hotho, A., N\u00fcrnberger, A. and Paa\u00df, G. (2005).", "token2charspan": [[0, 1], [1, 5], [5, 6], [6, 7], [8, 13], [14, 23], [24, 36], [37, 39], [40, 44], [45, 51], [52, 55], [56, 58], [59, 72], [72, 73], [74, 80], [81, 85], [86, 92], [93, 95], [96, 107], [108, 114], [114, 115], [116, 120], [121, 127], [128, 130], [131, 135], [136, 140], [141, 147], [148, 151], [152, 156], [157, 163], [164, 166], [167, 168], [169, 176], [177, 179], [180, 189], [190, 199], [200, 202], [203, 218], [218, 219], [220, 222], [222, 223], [224, 234], [234, 235], [236, 238], [239, 242], [243, 247], [247, 248], [249, 251], [252, 253], [253, 257], [257, 258], [258, 259]]}
{"doc_key": "ai-dev-230", "ner": [[0, 2, "product"], [13, 20, "location"], [21, 22, "location"], [24, 24, "location"], [34, 36, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 13, 20, "related-to", "developed_for", false, false], [13, 20, 21, 22, "physical", "", false, false], [21, 22, 24, 24, "physical", "", false, false], [34, 36, 0, 2, "role", "buys", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Rancho", "Arm", "was", "developed", "as", "a", "robotic", "arm", "to", "assist", "disabled", "patients", "at", "the", "Rancho", "Los", "Amigos", "National", "Rehabilitation", "Center", "in", "Downey", ",", "California", ";", "this", "computer", "-", "controlled", "arm", "was", "purchased", "by", "Stanford", "University", "in", "1963", "."], "sentence-detokenized": "The Rancho Arm was developed as a robotic arm to assist disabled patients at the Rancho Los Amigos National Rehabilitation Center in Downey, California; this computer-controlled arm was purchased by Stanford University in 1963.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 18], [19, 28], [29, 31], [32, 33], [34, 41], [42, 45], [46, 48], [49, 55], [56, 64], [65, 73], [74, 76], [77, 80], [81, 87], [88, 91], [92, 98], [99, 107], [108, 122], [123, 129], [130, 132], [133, 139], [139, 140], [141, 151], [151, 152], [153, 157], [158, 166], [166, 167], [167, 177], [178, 181], [182, 185], [186, 195], [196, 198], [199, 207], [208, 218], [219, 221], [222, 226], [226, 227]]}
{"doc_key": "ai-dev-231", "ner": [[0, 1, "university"], [3, 3, "researcher"], [8, 12, "organisation"], [19, 22, "organisation"], [26, 27, "researcher"], [29, 31, "researcher"], [44, 44, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 0, 1, "physical", "", false, false], [3, 3, 0, 1, "role", "", false, false], [3, 3, 8, 12, "role", "founder", false, false], [3, 3, 19, 22, "role", "founder", false, false], [19, 22, 44, 44, "physical", "", false, false], [26, 27, 19, 22, "role", "founder", false, false], [29, 31, 19, 22, "role", "founder", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["At", "UCSD", ",", "Norman", "was", "the", "founder", "of", "the", "Institute", "for", "Cognitive", "Science", "and", "one", "of", "the", "organizers", "of", "the", "Cognitive", "Science", "Society", "(", "along", "with", "Roger", "Schank", ",", "Allan", "M.", "Collins", "and", "others", ")", ",", "which", "held", "it", "s", "first", "meeting", "on", "the", "UCSD", "campus", "in", "1979", "."], "sentence-detokenized": "At UCSD, Norman was the founder of the Institute for Cognitive Science and one of the organizers of the Cognitive Science Society (along with Roger Schank, Allan M. Collins and others), which held its first meeting on the UCSD campus in 1979.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 23], [24, 31], [32, 34], [35, 38], [39, 48], [49, 52], [53, 62], [63, 70], [71, 74], [75, 78], [79, 81], [82, 85], [86, 96], [97, 99], [100, 103], [104, 113], [114, 121], [122, 129], [130, 131], [131, 136], [137, 141], [142, 147], [148, 154], [154, 155], [156, 161], [162, 164], [165, 172], [173, 176], [177, 183], [183, 184], [184, 185], [186, 191], [192, 196], [197, 199], [199, 200], [201, 206], [207, 214], [215, 217], [218, 221], [222, 226], [227, 233], [234, 236], [237, 241], [241, 242]]}
{"doc_key": "ai-dev-232", "ner": [[7, 8, "product"], [10, 11, "product"], [13, 14, "product"], [16, 19, "product"], [21, 22, "product"], [24, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[21, 22, 16, 19, "type-of", "", false, false], [24, 29, 16, 19, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "commonly", "used", "robot", "configurations", "are", "articulated", "robots", ",", "SCARA", "robots", ",", "delta", "robots", "and", "robots", "with", "Cartesian", "coordinates", "(", "portal", "robots", "or", "x", "-", "y", "-", "z", "robots", ")", "."], "sentence-detokenized": "The most commonly used robot configurations are articulated robots, SCARA robots, delta robots and robots with Cartesian coordinates (portal robots or x-y-z robots).", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 28], [29, 43], [44, 47], [48, 59], [60, 66], [66, 67], [68, 73], [74, 80], [80, 81], [82, 87], [88, 94], [95, 98], [99, 105], [106, 110], [111, 120], [121, 132], [133, 134], [134, 140], [141, 147], [148, 150], [151, 152], [152, 153], [153, 154], [154, 155], [155, 156], [157, 163], [163, 164], [164, 165]]}
{"doc_key": "ai-dev-233", "ner": [[8, 8, "programlang"], [7, 10, "misc"], [15, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 10, 8, 8, "part-of", "", false, false], [15, 15, 7, 10, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Alternatively", ",", "it", "can", "be", "used", "directly", "with", "Perl", "Module", "TM", "(", "which", "also", "supports", "LTM", ")", "."], "sentence-detokenized": "Alternatively, it can be used directly with Perl Module TM (which also supports LTM).", "token2charspan": [[0, 13], [13, 14], [15, 17], [18, 21], [22, 24], [25, 29], [30, 38], [39, 43], [44, 48], [49, 55], [56, 58], [59, 60], [60, 65], [66, 70], [71, 79], [80, 83], [83, 84], [84, 85]]}
{"doc_key": "ai-dev-234", "ner": [[11, 12, "country"], [6, 9, "organisation"], [19, 19, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 9, 11, 12, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "won", "by", "a", "team", "from", "Newton", "Labs", "in", "the", "United", "States", "and", "the", "competition", "was", "shown", "on", "CNN", "."], "sentence-detokenized": "It was won by a team from Newton Labs in the United States and the competition was shown on CNN.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 13], [14, 15], [16, 20], [21, 25], [26, 32], [33, 37], [38, 40], [41, 44], [45, 51], [52, 58], [59, 62], [63, 66], [67, 78], [79, 82], [83, 88], [89, 91], [92, 95], [95, 96]]}
{"doc_key": "ai-dev-235", "ner": [[8, 12, "misc"], [16, 18, "person"], [20, 21, "person"], [23, 26, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 18, 8, 12, "role", "directs", false, false], [20, 21, 8, 12, "role", "acts_in", false, false], [23, 26, 8, 12, "role", "acts_in", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["On", "23", "June", "2008", ",", "the", "short", "film", "The", "Butler", "'s", "in", "Love", ",", "directed", "by", "David", "Arquette", "and", "starring", "Elizabeth", "Berkley", "and", "Thomas", "Jane", ",", "was", "released", "."], "sentence-detokenized": "On 23 June 2008, the short film The Butler's in Love, directed by David Arquette and starring Elizabeth Berkley and Thomas Jane, was released.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 15], [15, 16], [17, 20], [21, 26], [27, 31], [32, 35], [36, 42], [42, 44], [45, 47], [48, 52], [52, 53], [54, 62], [63, 65], [66, 71], [72, 80], [81, 84], [85, 93], [94, 103], [104, 111], [112, 115], [116, 122], [123, 127], [127, 128], [129, 132], [133, 141], [141, 142]]}
{"doc_key": "ai-dev-236", "ner": [[3, 4, "product"], [9, 11, "field"], [15, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 15, 15, "general-affiliation", "", false, false], [9, 11, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "Word", "Net", "is", "a", "resource", "containing", "a", "taxonomy", "of", "the", "meanings", "of", "English", "words", "."], "sentence-detokenized": "For example, WordNet is a resource containing a taxonomy of the meanings of English words.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [17, 20], [21, 23], [24, 25], [26, 34], [35, 45], [46, 47], [48, 56], [57, 59], [60, 63], [64, 72], [73, 75], [76, 83], [84, 89], [89, 90]]}
{"doc_key": "ai-dev-237", "ner": [[1, 3, "product"], [7, 7, "product"], [9, 9, "product"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 1, 3, "type-of", "", false, false], [7, 7, 14, 15, "related-to", "ability_to", false, false], [9, 9, 1, 3, "type-of", "", false, false], [9, 9, 14, 15, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Existing", "robotic", "humanoid", "systems", ",", "such", "as", "ASIMO", "and", "QRIO", ",", "use", "many", "motors", "for", "locomotion", "."], "sentence-detokenized": "Existing robotic humanoid systems, such as ASIMO and QRIO, use many motors for locomotion.", "token2charspan": [[0, 8], [9, 16], [17, 25], [26, 33], [33, 34], [35, 39], [40, 42], [43, 48], [49, 52], [53, 57], [57, 58], [59, 62], [63, 67], [68, 74], [75, 78], [79, 89], [89, 90]]}
{"doc_key": "ai-dev-238", "ner": [[0, 0, "metrics"], [5, 6, "metrics"], [8, 8, "metrics"], [10, 14, "misc"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 0, 0, "part-of", "", false, false], [8, 8, 0, 0, "part-of", "", false, false], [10, 14, 0, 0, "part-of", "", false, false], [16, 16, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LEPOR", "is", "designed", "with", "improved", "length", "penalty", ",", "precision", ",", "n-", "gram", "word", "order", "penalty", "and", "recall", "factors", "."], "sentence-detokenized": "LEPOR is designed with improved length penalty, precision, n-gram word order penalty and recall factors.", "token2charspan": [[0, 5], [6, 8], [9, 17], [18, 22], [23, 31], [32, 38], [39, 46], [46, 47], [48, 57], [57, 58], [59, 61], [61, 65], [66, 70], [71, 76], [77, 84], [85, 88], [89, 95], [96, 103], [103, 104]]}
{"doc_key": "ai-dev-239", "ner": [[4, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "based", "on", "the", "bilingual", "assessment", "methodology", ",", "but", "with", "some", "modifications", "."], "sentence-detokenized": "It is based on the bilingual assessment methodology, but with some modifications.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 14], [15, 18], [19, 28], [29, 39], [40, 51], [51, 52], [53, 56], [57, 61], [62, 66], [67, 80], [80, 81]]}
{"doc_key": "ai-dev-240", "ner": [[7, 8, "product"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "of", "an", "implementation", "in", "MATLAB", "/", "Octave", ":"], "sentence-detokenized": "This is an example of an implementation in MATLAB / Octave:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 24], [25, 39], [40, 42], [43, 49], [50, 51], [52, 58], [58, 59]]}
{"doc_key": "ai-dev-241", "ner": [[12, 12, "programlang"], [14, 14, "programlang"], [16, 16, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "designed", "to", "be", "used", "with", "multiple", "computer", "languages", ",", "including", "Python", ",", "Ruby", "and", "Scheme", "."], "sentence-detokenized": "It is designed to be used with multiple computer languages, including Python, Ruby and Scheme.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 20], [21, 25], [26, 30], [31, 39], [40, 48], [49, 58], [58, 59], [60, 69], [70, 76], [76, 77], [78, 82], [83, 86], [87, 93], [93, 94]]}
{"doc_key": "ai-dev-242", "ner": [[0, 0, "researcher"], [7, 7, "organisation"], [14, 14, "conference"], [19, 20, "academicjournal"], [25, 27, "organisation"], [31, 36, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 7, 7, "role", "", false, false], [0, 0, 14, 14, "role", "", false, false], [0, 0, 19, 20, "role", "", false, false], [0, 0, 25, 27, "role", "", false, false], [0, 0, 31, 36, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hayes", "has", "served", "as", "Secretary", "of", "the", "AISB", ",", "Chairman", "and", "Trustee", "of", "the", "IJCAI", ",", "Associate", "Editor", "of", "Artificial", "Intelligence", ",", "Governor", "of", "the", "Cognitive", "Science", "Society", "and", "President", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "."], "sentence-detokenized": "Hayes has served as Secretary of the AISB, Chairman and Trustee of the IJCAI, Associate Editor of Artificial Intelligence, Governor of the Cognitive Science Society and President of the American Association for Artificial Intelligence.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 32], [33, 36], [37, 41], [41, 42], [43, 51], [52, 55], [56, 63], [64, 66], [67, 70], [71, 76], [76, 77], [78, 87], [88, 94], [95, 97], [98, 108], [109, 121], [121, 122], [123, 131], [132, 134], [135, 138], [139, 148], [149, 156], [157, 164], [165, 168], [169, 178], [179, 181], [182, 185], [186, 194], [195, 206], [207, 210], [211, 221], [222, 234], [234, 235]]}
{"doc_key": "ai-dev-243", "ner": [[5, 15, "misc"], [19, 24, "misc"], [27, 29, "person"], [33, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[27, 29, 5, 15, "role", "directed_by", false, false], [27, 29, 19, 24, "role", "directed_by", false, false], [27, 29, 33, 37, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "of", "them", ",", "\"", "Now", "is", "the", "Time", "(", "to", "Put", "On", "Your", "Glasses", ")", "\"", "and", "\"", "Around", "is", "Around", "\"", ",", "were", "directed", "by", "Norman", "McLaren", "in", "1951", "for", "the", "National", "Film", "Board", "of", "Canada", "."], "sentence-detokenized": "Two of them, \"Now is the Time (to Put On Your Glasses)\" and \"Around is Around\", were directed by Norman McLaren in 1951 for the National Film Board of Canada.", "token2charspan": [[0, 3], [4, 6], [7, 11], [11, 12], [13, 14], [14, 17], [18, 20], [21, 24], [25, 29], [30, 31], [31, 33], [34, 37], [38, 40], [41, 45], [46, 53], [53, 54], [54, 55], [56, 59], [60, 61], [61, 67], [68, 70], [71, 77], [77, 78], [78, 79], [80, 84], [85, 93], [94, 96], [97, 103], [104, 111], [112, 114], [115, 119], [120, 123], [124, 127], [128, 136], [137, 141], [142, 147], [148, 150], [151, 157], [157, 158]]}
{"doc_key": "ai-dev-244", "ner": [[3, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "aim", "of", "the", "recommendation", "system", "is", "to", "predict", "the", "target", "user", "'s", "preference", "for", "a", "product", "."], "sentence-detokenized": "The aim of the recommendation system is to predict the target user's preference for a product.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 14], [15, 29], [30, 36], [37, 39], [40, 42], [43, 50], [51, 54], [55, 61], [62, 66], [66, 68], [69, 79], [80, 83], [84, 85], [86, 93], [93, 94]]}
{"doc_key": "ai-dev-245", "ner": [[2, 2, "algorithm"], [4, 4, "field"], [6, 6, "field"], [8, 9, "field"], [11, 13, "field"], [15, 15, "field"], [17, 18, "field"], [20, 20, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 2, 4, 4, "part-of", "", true, false], [2, 2, 6, 6, "part-of", "", true, false], [2, 2, 8, 9, "part-of", "", true, false], [2, 2, 11, 13, "part-of", "", true, false], [2, 2, 15, 15, "part-of", "", true, false], [2, 2, 17, 18, "part-of", "", true, false], [2, 2, 20, 20, "part-of", "", true, false], [2, 2, 22, 23, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Applications", "of", "convolution", "include", "probability", ",", "statistics", ",", "computer", "vision", ",", "natural", "language", "processing", ",", "image", "and", "signal", "processing", ",", "engineering", "and", "differential", "equations", "."], "sentence-detokenized": "Applications of convolution include probability, statistics, computer vision, natural language processing, image and signal processing, engineering and differential equations.", "token2charspan": [[0, 12], [13, 15], [16, 27], [28, 35], [36, 47], [47, 48], [49, 59], [59, 60], [61, 69], [70, 76], [76, 77], [78, 85], [86, 94], [95, 105], [105, 106], [107, 112], [113, 116], [117, 123], [124, 134], [134, 135], [136, 147], [148, 151], [152, 164], [165, 174], [174, 175]]}
{"doc_key": "ai-dev-246", "ner": [[0, 0, "field"], [3, 5, "task"], [7, 8, "task"], [10, 10, "task"], [11, 12, "task"], [14, 15, "task"], [18, 18, "task"], [20, 21, "task"], [23, 23, "task"], [26, 27, "task"], [29, 29, "field"], [31, 31, "field"], [33, 35, "field"], [37, 37, "field"], [39, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[0, 0, 3, 5, "part-of", "", true, false], [0, 0, 7, 8, "part-of", "", true, false], [0, 0, 10, 10, "part-of", "", true, false], [0, 0, 11, 12, "part-of", "", true, false], [0, 0, 14, 15, "part-of", "", true, false], [0, 0, 18, 18, "part-of", "", true, false], [0, 0, 20, 21, "part-of", "", true, false], [0, 0, 23, 23, "part-of", "", true, false], [0, 0, 26, 27, "part-of", "", true, false], [0, 0, 29, 29, "part-of", "", true, false], [0, 0, 31, 31, "part-of", "", true, false], [0, 0, 33, 35, "part-of", "", true, false], [0, 0, 37, 37, "part-of", "", true, false], [0, 0, 39, 39, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["DSP", "applications", "include", "audio", "signal", "processing", ",", "audio", "compression", ",", "digital", "image", "processing", ",", "video", "compression", ",", "speech", "processing", ",", "speech", "recognition", ",", "digital", "communications", ",", "digital", "synthesizers", ",", "radar", ",", "sonar", ",", "financial", "signal", "processing", ",", "seismology", "and", "biomedicine", "."], "sentence-detokenized": "DSP applications include audio signal processing, audio compression, digital image processing, video compression, speech processing, speech recognition, digital communications, digital synthesizers, radar, sonar, financial signal processing, seismology and biomedicine.", "token2charspan": [[0, 3], [4, 16], [17, 24], [25, 30], [31, 37], [38, 48], [48, 49], [50, 55], [56, 67], [67, 68], [69, 76], [77, 82], [83, 93], [93, 94], [95, 100], [101, 112], [112, 113], [114, 120], [121, 131], [131, 132], [133, 139], [140, 151], [151, 152], [153, 160], [161, 175], [175, 176], [177, 184], [185, 197], [197, 198], [199, 204], [204, 205], [206, 211], [211, 212], [213, 222], [223, 229], [230, 240], [240, 241], [242, 252], [253, 256], [257, 268], [268, 269]]}
{"doc_key": "ai-dev-247", "ner": [[13, 21, "misc"], [23, 30, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "February", "20", ",", "1912", "-", "August", "11", ",", "2011", ")", "was", "an", "inventor", "from", "the", "United", "States", "of", "America", ",", "best", "known", "for", "creating", "the", "first", "industrial", "robot", ",", "Unimate", "."], "sentence-detokenized": "(February 20, 1912 - August 11, 2011) was an inventor from the United States of America, best known for creating the first industrial robot, Unimate.", "token2charspan": [[0, 1], [1, 9], [10, 12], [12, 13], [14, 18], [19, 20], [21, 27], [28, 30], [30, 31], [32, 36], [36, 37], [38, 41], [42, 44], [45, 53], [54, 58], [59, 62], [63, 69], [70, 76], [77, 79], [80, 87], [87, 88], [89, 93], [94, 99], [100, 103], [104, 112], [113, 116], [117, 122], [123, 133], [134, 139], [139, 140], [141, 148], [148, 149]]}
{"doc_key": "ai-dev-248", "ner": [[2, 4, "researcher"], [6, 8, "researcher"], [10, 10, "researcher"], [18, 20, "algorithm"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 7], "relations": [[2, 4, 18, 20, "related-to", "writes_about", true, false], [6, 8, 18, 20, "related-to", "writes_about", true, false], [10, 10, 18, 20, "related-to", "writes_about", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Along", "with", "David", "E.", "Rumelhart", "and", "Ronald", "J.", "Williams", ",", "Hinton", "co-authored", "a", "widely", "cited", "1986", "article", "popularizing", "the", "backpropagation", "algorithm", ",", "published", "by", "his", "student", "Alex", "Krizhevsky", "{{", "cite", "web"], "sentence-detokenized": "Along with David E. Rumelhart and Ronald J. Williams, Hinton co-authored a widely cited 1986 article popularizing the backpropagation algorithm, published by his student Alex Krizhevsky {{cite web", "token2charspan": [[0, 5], [6, 10], [11, 16], [17, 19], [20, 29], [30, 33], [34, 40], [41, 43], [44, 52], [52, 53], [54, 60], [61, 72], [73, 74], [75, 81], [82, 87], [88, 92], [93, 100], [101, 113], [114, 117], [118, 133], [134, 143], [143, 144], [145, 154], [155, 157], [158, 161], [162, 169], [170, 174], [175, 185], [186, 188], [188, 192], [193, 196]]}
{"doc_key": "ai-dev-249", "ner": [[10, 11, "metrics"], [14, 16, "metrics"], [19, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "predicted", "value", "is", "consistently", "distributed", ",", "the", "root", "mean", "square", ",", "the", "mean", "squared", "error", "or", "the", "median", "of", "the", "absolute", "deviation", "can", "be", "used", "to", "summarise", "the", "errors", "."], "sentence-detokenized": "If the predicted value is consistently distributed, the root mean square, the mean squared error or the median of the absolute deviation can be used to summarise the errors.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 22], [23, 25], [26, 38], [39, 50], [50, 51], [52, 55], [56, 60], [61, 65], [66, 72], [72, 73], [74, 77], [78, 82], [83, 90], [91, 96], [97, 99], [100, 103], [104, 110], [111, 113], [114, 117], [118, 126], [127, 136], [137, 140], [141, 143], [144, 148], [149, 151], [152, 161], [162, 165], [166, 172], [172, 173]]}
{"doc_key": "ai-dev-250", "ner": [[0, 1, "algorithm"], [9, 10, "field"], [12, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 9, 10, "part-of", "", true, false], [0, 1, 12, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Conceptual", "clustering", "developed", "mainly", "in", "the", "1980s", "as", "a", "machine", "learning", "paradigm", "for", "unsupervised", "learning", "."], "sentence-detokenized": "Conceptual clustering developed mainly in the 1980s as a machine learning paradigm for unsupervised learning.", "token2charspan": [[0, 10], [11, 21], [22, 31], [32, 38], [39, 41], [42, 45], [46, 51], [52, 54], [55, 56], [57, 64], [65, 73], [74, 82], [83, 86], [87, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-dev-251", "ner": [[0, 4, "product"], [25, 29, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "machine", "translator", "is", "unable", "to", "recognise", "the", "pronouns", ",", "they", "may", "be", "mistakenly", "translated", "as", "ordinary", "pronouns", ",", "which", "is", "unlikely", "to", "affect", "the", "bilingual", "assessment", "of", "the", "translation", ",", "but", "will", "make", "the", "text", "less", "readable", "for", "humans", "."], "sentence-detokenized": "If the machine translator is unable to recognise the pronouns, they may be mistakenly translated as ordinary pronouns, which is unlikely to affect the bilingual assessment of the translation, but will make the text less readable for humans.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 25], [26, 28], [29, 35], [36, 38], [39, 48], [49, 52], [53, 61], [61, 62], [63, 67], [68, 71], [72, 74], [75, 85], [86, 96], [97, 99], [100, 108], [109, 117], [117, 118], [119, 124], [125, 127], [128, 136], [137, 139], [140, 146], [147, 150], [151, 160], [161, 171], [172, 174], [175, 178], [179, 190], [190, 191], [192, 195], [196, 200], [201, 205], [206, 209], [210, 214], [215, 219], [220, 228], [229, 232], [233, 239], [239, 240]]}
{"doc_key": "ai-dev-252", "ner": [[0, 1, "researcher"], [10, 11, "misc"], [12, 18, "conference"], [20, 22, "location"], [24, 24, "country"], [41, 42, "researcher"], [52, 52, "university"], [57, 58, "researcher"], [60, 61, "researcher"], [63, 64, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10], "relations": [[0, 1, 10, 11, "related-to", "writes_about", false, false], [0, 1, 12, 18, "temporal", "", true, false], [12, 18, 20, 22, "physical", "", false, false], [20, 22, 24, 24, "physical", "", false, false], [57, 58, 52, 52, "physical", "", false, false], [57, 58, 52, 52, "role", "", false, false], [60, 61, 52, 52, "physical", "", false, false], [60, 61, 52, 52, "role", "", false, false], [63, 64, 52, 52, "physical", "", false, false], [63, 64, 52, 52, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 6, 7, 8, 9, 10, 11], "sentence": ["Roger", "Schank", ",", "1969", ",", "A", "conceptual", "dependency", "parser", "for", "natural", "language", "Proceedings", "of", "the", "1969", "on", "Computational", "linguistics", ",", "S\u00e5ng", "-", "S\u00e4by", ",", "Sweden", ",", "pp", "1", "-", "3", ".", "This", "model", ",", "influenced", "in", "part", "by", "the", "work", "of", "Sydney", "Lamb", ",", "was", "widely", "used", "by", "Schank", "'s", "students", "at", "Yale", "University", ",", "such", "as", "Robert", "Wilensky", ",", "Wendy", "Lehnert", "and", "Janet", "Kolodner", "."], "sentence-detokenized": "Roger Schank, 1969, A conceptual dependency parser for natural language Proceedings of the 1969 on Computational linguistics, S\u00e5ng-S\u00e4by, Sweden, pp 1-3. This model, influenced in part by the work of Sydney Lamb, was widely used by Schank's students at Yale University, such as Robert Wilensky, Wendy Lehnert and Janet Kolodner.", "token2charspan": [[0, 5], [6, 12], [12, 13], [14, 18], [18, 19], [20, 21], [22, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 71], [72, 83], [84, 86], [87, 90], [91, 95], [96, 98], [99, 112], [113, 124], [124, 125], [126, 130], [130, 131], [131, 135], [135, 136], [137, 143], [143, 144], [145, 147], [148, 149], [149, 150], [150, 151], [151, 152], [153, 157], [158, 163], [163, 164], [165, 175], [176, 178], [179, 183], [184, 186], [187, 190], [191, 195], [196, 198], [199, 205], [206, 210], [210, 211], [212, 215], [216, 222], [223, 227], [228, 230], [231, 237], [237, 239], [240, 248], [249, 251], [252, 256], [257, 267], [267, 268], [269, 273], [274, 276], [277, 283], [284, 292], [292, 293], [294, 299], [300, 307], [308, 311], [312, 317], [318, 326], [326, 327]]}
{"doc_key": "ai-dev-253", "ner": [[0, 6, "algorithm"], [13, 15, "algorithm"], [16, 16, "metrics"]], "ner_mapping_to_source": [1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Improved", "Maximum", "Likelihood", "Method", "(", "IMLM", ")", "is", "a", "combination", "of", "two", "MLM", "(", "maximum", "likelihood", ")", "estimators", "."], "sentence-detokenized": "The Improved Maximum Likelihood Method (IMLM) is a combination of two MLM (maximum likelihood) estimators.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 31], [32, 38], [39, 40], [40, 44], [44, 45], [46, 48], [49, 50], [51, 62], [63, 65], [66, 69], [70, 73], [74, 75], [75, 82], [83, 93], [93, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-dev-254", "ner": [[22, 23, "metrics"], [26, 27, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[26, 27, 22, 23, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["These", "methods", "can", "also", "analyse", "the", "output", "of", "the", "programme", "and", "its", "usefulness", ",", "and", "may", "therefore", "include", "an", "analysis", "of", "its", "confusion", "matrix", "(", "or", "confusion", "table", ")", "."], "sentence-detokenized": "These methods can also analyse the output of the programme and its usefulness, and may therefore include an analysis of its confusion matrix (or confusion table).", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 22], [23, 30], [31, 34], [35, 41], [42, 44], [45, 48], [49, 58], [59, 62], [63, 66], [67, 77], [77, 78], [79, 82], [83, 86], [87, 96], [97, 104], [105, 107], [108, 116], [117, 119], [120, 123], [124, 133], [134, 140], [141, 142], [142, 144], [145, 154], [155, 160], [160, 161], [161, 162]]}
{"doc_key": "ai-dev-255", "ner": [[0, 0, "product"], [5, 6, "researcher"], [8, 9, "researcher"], [11, 13, "researcher"], [16, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 6, "origin", "", false, false], [0, 0, 8, 9, "origin", "", false, false], [0, 0, 11, 13, "origin", "", false, false], [0, 0, 16, 23, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SURF", "was", "first", "published", "by", "Herbert", "Bay", ",", "Tinne", "Tuytelaars", "and", "Luc", "Van", "Gool", "and", "presented", "at", "the", "2006", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "SURF was first published by Herbert Bay, Tinne Tuytelaars and Luc Van Gool and presented at the 2006 European Conference on Computer Vision.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 24], [25, 27], [28, 35], [36, 39], [39, 40], [41, 46], [47, 57], [58, 61], [62, 65], [66, 69], [70, 74], [75, 78], [79, 88], [89, 91], [92, 95], [96, 100], [101, 109], [110, 120], [121, 123], [124, 132], [133, 139], [139, 140]]}
{"doc_key": "ai-dev-256", "ner": [[0, 2, "task"], [6, 7, "field"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 6, 7, "part-of", "", false, false], [0, 2, 9, 10, "part-of", "", false, false], [0, 2, 12, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OCR", "is", "the", "research", "field", "of", "pattern", "recognition", ",", "artificial", "intelligence", "and", "computer", "vision", "."], "sentence-detokenized": "OCR is the research field of pattern recognition, artificial intelligence and computer vision.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 19], [20, 25], [26, 28], [29, 36], [37, 48], [48, 49], [50, 60], [61, 73], [74, 77], [78, 86], [87, 93], [93, 94]]}
{"doc_key": "ai-dev-257", "ner": [[3, 7, "metrics"], [11, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 15, 11, 13, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Continuing", "the", "example", "using", "the", "maximum", "likelihood", "estimator", ",", "the", "noise", "probability", "density", "function", "(", "pdf", ")", "for", "a", "single", "sample", "mathwn", "/", "math", "is", "as", "follows"], "sentence-detokenized": "Continuing the example using the maximum likelihood estimator, the noise probability density function (pdf) for a single sample mathwn/math is as follows", "token2charspan": [[0, 10], [11, 14], [15, 22], [23, 28], [29, 32], [33, 40], [41, 51], [52, 61], [61, 62], [63, 66], [67, 72], [73, 84], [85, 92], [93, 101], [102, 103], [103, 106], [106, 107], [108, 111], [112, 113], [114, 120], [121, 127], [128, 134], [134, 135], [135, 139], [140, 142], [143, 145], [146, 153]]}
{"doc_key": "ai-dev-258", "ner": [[0, 1, "field"], [4, 5, "task"], [7, 8, "task"], [10, 11, "task"], [13, 14, "task"], [16, 18, "task"], [20, 20, "task"], [22, 22, "task"], [24, 25, "task"], [27, 28, "task"], [30, 32, "task"], [34, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[4, 5, 0, 1, "part-of", "", false, false], [7, 8, 0, 1, "part-of", "", false, false], [10, 11, 0, 1, "part-of", "", false, false], [13, 14, 0, 1, "part-of", "", false, false], [16, 18, 0, 1, "part-of", "", false, false], [20, 20, 0, 1, "part-of", "", false, false], [22, 22, 0, 1, "part-of", "", false, false], [24, 25, 0, 1, "part-of", "", false, false], [27, 28, 0, 1, "part-of", "", false, false], [30, 32, 0, 1, "part-of", "", false, false], [34, 35, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Computer", "vision", "subdomains", "include", "scene", "reconstruction", ",", "event", "detection", ",", "video", "tracking", ",", "object", "detection", ",", "3D", "pose", "estimation", ",", "learning", ",", "indexing", ",", "motion", "estimation", ",", "visual", "servoing", ",", "3D", "scene", "modelling", "and", "image", "restoration", "."], "sentence-detokenized": "Computer vision subdomains include scene reconstruction, event detection, video tracking, object detection, 3D pose estimation, learning, indexing, motion estimation, visual servoing, 3D scene modelling and image restoration.", "token2charspan": [[0, 8], [9, 15], [16, 26], [27, 34], [35, 40], [41, 55], [55, 56], [57, 62], [63, 72], [72, 73], [74, 79], [80, 88], [88, 89], [90, 96], [97, 106], [106, 107], [108, 110], [111, 115], [116, 126], [126, 127], [128, 136], [136, 137], [138, 146], [146, 147], [148, 154], [155, 165], [165, 166], [167, 173], [174, 182], [182, 183], [184, 186], [187, 192], [193, 202], [203, 206], [207, 212], [213, 224], [224, 225]]}
{"doc_key": "ai-dev-259", "ner": [[10, 16, "conference"], [3, 3, "researcher"], [7, 9, "misc"], [18, 18, "conference"], [22, 22, "researcher"], [24, 24, "researcher"], [26, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 16, 18, 18, "named", "", false, false], [3, 3, 7, 9, "win-defeat", "", false, false], [3, 3, 26, 26, "related-to", "writes_about", true, false], [7, 9, 10, 16, "temporal", "", false, false], [22, 22, 7, 9, "win-defeat", "", false, true], [22, 22, 26, 26, "related-to", "writes_about", true, false], [24, 24, 7, 9, "win-defeat", "", false, true], [24, 24, 26, 26, "related-to", "writes_about", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["In", "2013", ",", "Terzopoulos", "was", "awarded", "the", "Helmholtz", "Prize", "at", "the", "International", "Conference", "on", "Computer", "Vision", "for", "his", "1987", "ICCV", "paper", "with", "Kass", "and", "Witkin", "on", "active", "contour", "models", "."], "sentence-detokenized": "In 2013, Terzopoulos was awarded the Helmholtz Prize at the International Conference on Computer Vision for his 1987 ICCV paper with Kass and Witkin on active contour models.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 24], [25, 32], [33, 36], [37, 46], [47, 52], [53, 55], [56, 59], [60, 73], [74, 84], [85, 87], [88, 96], [97, 103], [104, 107], [108, 111], [112, 116], [117, 121], [122, 127], [128, 132], [133, 137], [138, 141], [142, 148], [149, 151], [152, 158], [159, 166], [167, 173], [173, 174]]}
{"doc_key": "ai-dev-260", "ner": [[16, 17, "task"], [19, 21, "algorithm"], [23, 24, "algorithm"], [26, 28, "algorithm"], [30, 31, "algorithm"], [33, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[16, 17, 19, 21, "usage", "", true, false], [16, 17, 23, 24, "usage", "", true, false], [16, 17, 26, 28, "usage", "", true, false], [16, 17, 30, 31, "usage", "", true, false], [16, 17, 33, 34, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["If", "a", "regularization", "function", "There", "are", "many", "algorithms", "for", "solving", "such", "problems", ";", "popular", "ones", "for", "linear", "classification", "are", "stochastic", "gradient", "descent", ",", "gradient", "descent", ",", "L", "-", "BFGS", ",", "coordinate", "descent", "and", "Newton", "'s", "methods", "."], "sentence-detokenized": "If a regularization function There are many algorithms for solving such problems; popular ones for linear classification are stochastic gradient descent, gradient descent, L-BFGS, coordinate descent and Newton's methods.", "token2charspan": [[0, 2], [3, 4], [5, 19], [20, 28], [29, 34], [35, 38], [39, 43], [44, 54], [55, 58], [59, 66], [67, 71], [72, 80], [80, 81], [82, 89], [90, 94], [95, 98], [99, 105], [106, 120], [121, 124], [125, 135], [136, 144], [145, 152], [152, 153], [154, 162], [163, 170], [170, 171], [172, 173], [173, 174], [174, 178], [178, 179], [180, 190], [191, 198], [199, 202], [203, 209], [209, 211], [212, 219], [219, 220]]}
{"doc_key": "ai-dev-261", "ner": [[3, 6, "algorithm"], [0, 8, "algorithm"], [14, 15, "researcher"], [17, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 6, 14, 15, "origin", "", false, false], [0, 8, 3, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Long", "-", "term", "short", "-", "term", "memory", "(", "LSTM", ")", "networks", "were", "invented", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "in", "1997", "and", "set", "accuracy", "records", "in", "several", "application", "areas", "."], "sentence-detokenized": "Long-term short-term memory (LSTM) networks were invented by Sepp Hochreiter and J\u00fcrgen Schmidhuber in 1997 and set accuracy records in several application areas.", "token2charspan": [[0, 4], [4, 5], [5, 9], [10, 15], [15, 16], [16, 20], [21, 27], [28, 29], [29, 33], [33, 34], [35, 43], [44, 48], [49, 57], [58, 60], [61, 65], [66, 76], [77, 80], [81, 87], [88, 99], [100, 102], [103, 107], [108, 111], [112, 115], [116, 124], [125, 132], [133, 135], [136, 143], [144, 155], [156, 161], [161, 162]]}
{"doc_key": "ai-dev-262", "ner": [[0, 1, "product"], [4, 7, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 4, 7, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "TN", "was", "developed", "at", "Massachusetts", "General", "Hospital", "and", "tested", "in", "a", "number", "of", "scenarios", ",", "including", "smoking", "status", ",", "family", "history", "of", "coronary", "heart", "disease", "and", "identification", "of", "patients", "with", "sleep", "disorders", ","], "sentence-detokenized": "The TN was developed at Massachusetts General Hospital and tested in a number of scenarios, including smoking status, family history of coronary heart disease and identification of patients with sleep disorders,", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 20], [21, 23], [24, 37], [38, 45], [46, 54], [55, 58], [59, 65], [66, 68], [69, 70], [71, 77], [78, 80], [81, 90], [90, 91], [92, 101], [102, 109], [110, 116], [116, 117], [118, 124], [125, 132], [133, 135], [136, 144], [145, 150], [151, 158], [159, 162], [163, 177], [178, 180], [181, 189], [190, 194], [195, 200], [201, 210], [210, 211]]}
{"doc_key": "ai-dev-263", "ner": [[3, 3, "researcher"], [8, 8, "product"], [15, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 8, "role", "sells", false, false], [8, 8, 15, 17, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "delivered", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was delivered to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 75], [76, 78], [79, 86], [87, 93], [94, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-dev-264", "ner": [[0, 5, "conference"], [12, 13, "location"], [15, 15, "location"], [17, 19, "country"], [25, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 5, 12, 13, "physical", "", false, false], [12, 13, 15, 15, "physical", "", false, false], [15, 15, 17, 19, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Campus", "Party", "Europe", "took", "place", "from", "14", "-", "18", "April", "2010", "in", "Caja", "M\u00e1gicas", ",", "Madrid", ",", "Spain", ",", "with", "800", "participants", "from", "all", "27", "EU", "Member", "States", "."], "sentence-detokenized": "Campus Party Europe took place from 14-18 April 2010 in Caja M\u00e1gicas, Madrid, Spain, with 800 participants from all 27 EU Member States.", "token2charspan": [[0, 6], [7, 12], [13, 19], [20, 24], [25, 30], [31, 35], [36, 38], [38, 39], [39, 41], [42, 47], [48, 52], [53, 55], [56, 60], [61, 68], [68, 69], [70, 76], [76, 77], [78, 83], [83, 84], [85, 89], [90, 93], [94, 106], [107, 111], [112, 115], [116, 118], [119, 121], [122, 128], [129, 135], [135, 136]]}
{"doc_key": "ai-dev-265", "ner": [[7, 7, "organisation"], [9, 11, "organisation"], [16, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 19, 7, 7, "origin", "", false, false], [16, 19, 9, 11, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2016", ",", "a", "collaboration", "between", "DeepMind", "and", "Moorfields", "Eye", "Hospital", "was", "announced", "to", "develop", "AI", "applications", "for", "healthcare", "."], "sentence-detokenized": "In July 2016, a collaboration between DeepMind and Moorfields Eye Hospital was announced to develop AI applications for healthcare.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 15], [16, 29], [30, 37], [38, 46], [47, 50], [51, 61], [62, 65], [66, 74], [75, 78], [79, 88], [89, 91], [92, 99], [100, 102], [103, 115], [116, 119], [120, 130], [130, 131]]}
{"doc_key": "ai-dev-266", "ner": [[3, 4, "misc"], [12, 14, "university"], [16, 16, "university"], [18, 19, "university"], [21, 22, "university"], [24, 24, "university"], [26, 26, "university"], [28, 31, "university"], [33, 34, "university"], [36, 37, "university"], [39, 39, "university"], [42, 44, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[3, 4, 12, 14, "physical", "", false, false], [3, 4, 16, 16, "physical", "", false, false], [3, 4, 18, 19, "physical", "", false, false], [3, 4, 21, 22, "physical", "", false, false], [3, 4, 24, 24, "physical", "", false, false], [3, 4, 26, 26, "physical", "", false, false], [3, 4, 28, 31, "physical", "", false, false], [3, 4, 33, 34, "physical", "", false, false], [3, 4, 36, 37, "physical", "", false, false], [3, 4, 39, 39, "physical", "", false, false], [3, 4, 42, 44, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Finally", ",", "eleven", "PR2s", "were", "awarded", "to", "various", "institutions", ",", "including", "the", "University", "of", "Freiburg", ",", "Bosch", ",", "Georgia", "Tech", ",", "KU", "Leuven", ",", "MIT", ",", "Stanford", ",", "Munich", "University", "of", "Technology", ",", "UC", "Berkeley", ",", "U", "Penn", ",", "USC", "and", "the", "University", "of", "Tokyo", "."], "sentence-detokenized": "Finally, eleven PR2s were awarded to various institutions, including the University of Freiburg, Bosch, Georgia Tech, KU Leuven, MIT, Stanford, Munich University of Technology, UC Berkeley, U Penn, USC and the University of Tokyo.", "token2charspan": [[0, 7], [7, 8], [9, 15], [16, 20], [21, 25], [26, 33], [34, 36], [37, 44], [45, 57], [57, 58], [59, 68], [69, 72], [73, 83], [84, 86], [87, 95], [95, 96], [97, 102], [102, 103], [104, 111], [112, 116], [116, 117], [118, 120], [121, 127], [127, 128], [129, 132], [132, 133], [134, 142], [142, 143], [144, 150], [151, 161], [162, 164], [165, 175], [175, 176], [177, 179], [180, 188], [188, 189], [190, 191], [192, 196], [196, 197], [198, 201], [202, 205], [206, 209], [210, 220], [221, 223], [224, 229], [229, 230]]}
{"doc_key": "ai-dev-267", "ner": [[0, 0, "metrics"], [2, 2, "metrics"], [4, 4, "metrics"], [6, 6, "metrics"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 15, 17, "part-of", "", false, false], [2, 2, 15, 17, "part-of", "", false, false], [4, 4, 15, 17, "part-of", "", false, false], [6, 6, 15, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["TP", ",", "TN", ",", "FP", "and", "FN", "counts", "are", "usually", "kept", "in", "a", "table", "called", "a", "confusion", "matrix", "."], "sentence-detokenized": "TP, TN, FP and FN counts are usually kept in a table called a confusion matrix.", "token2charspan": [[0, 2], [2, 3], [4, 6], [6, 7], [8, 10], [11, 14], [15, 17], [18, 24], [25, 28], [29, 36], [37, 41], [42, 44], [45, 46], [47, 52], [53, 59], [60, 61], [62, 71], [72, 78], [78, 79]]}
{"doc_key": "ai-dev-268", "ner": [[0, 1, "metrics"], [3, 3, "metrics"], [5, 6, "metrics"], [8, 10, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Information", "value", ",", "crossentropy", ",", "mutual", "information", "and", "likelihood", "ratio", "are", "commonly", "used", "as", "features", "."], "sentence-detokenized": "Information value, crossentropy, mutual information and likelihood ratio are commonly used as features.", "token2charspan": [[0, 11], [12, 17], [17, 18], [19, 31], [31, 32], [33, 39], [40, 51], [52, 55], [56, 66], [67, 72], [73, 76], [77, 85], [86, 90], [91, 93], [94, 102], [102, 103]]}
{"doc_key": "ai-dev-269", "ner": [[12, 13, "task"], [15, 16, "task"], [18, 18, "task"], [20, 20, "task"], [22, 22, "task"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[24, 24, 22, 22, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "successfully", "applied", "to", "a", "wide", "range", "of", "problems", "including", "robot", "control", ",", "lift", "planning", ",", "telecoms", ",", "checkers", "and", "Go", "(", "AlphaGo", ")", "."], "sentence-detokenized": "It has been successfully applied to a wide range of problems including robot control, lift planning, telecoms, checkers and Go (AlphaGo).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 24], [25, 32], [33, 35], [36, 37], [38, 42], [43, 48], [49, 51], [52, 60], [61, 70], [71, 76], [77, 84], [84, 85], [86, 90], [91, 99], [99, 100], [101, 109], [109, 110], [111, 119], [120, 123], [124, 126], [127, 128], [128, 135], [135, 136], [136, 137]]}
{"doc_key": "ai-dev-270", "ner": [[12, 13, "misc"], [21, 25, "university"], [26, 26, "location"], [28, 28, "location"], [32, 35, "location"], [43, 46, "location"], [39, 39, "location"], [41, 41, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[12, 13, 21, 25, "physical", "", false, false], [21, 25, 26, 26, "physical", "", false, false], [26, 26, 28, 28, "physical", "", false, false], [32, 35, 43, 46, "physical", "", false, false], [43, 46, 39, 39, "physical", "", false, false], [39, 39, 41, 41, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "the", "inaugural", "year", "of", "the", "8th", "Mission", ",", "the", "Americas", "meeting", "was", "held", "on", "the", "campus", "of", "the", "Georgia", "Institute", "of", "Technology", "in", "Atlanta", ",", "Georgia", ",", "and", "the", "Asia", "/", "Pacific", "meeting", "was", "held", "in", "Beijing", ",", "China", ",", "at", "Beihang", "University", "Gymnasium", "."], "sentence-detokenized": "In 2018, the inaugural year of the 8th Mission, the Americas meeting was held on the campus of the Georgia Institute of Technology in Atlanta, Georgia, and the Asia/Pacific meeting was held in Beijing, China, at Beihang University Gymnasium.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 22], [23, 27], [28, 30], [31, 34], [35, 38], [39, 46], [46, 47], [48, 51], [52, 60], [61, 68], [69, 72], [73, 77], [78, 80], [81, 84], [85, 91], [92, 94], [95, 98], [99, 106], [107, 116], [117, 119], [120, 130], [131, 133], [134, 141], [141, 142], [143, 150], [150, 151], [152, 155], [156, 159], [160, 164], [164, 165], [165, 172], [173, 180], [181, 184], [185, 189], [190, 192], [193, 200], [200, 201], [202, 207], [207, 208], [209, 211], [212, 219], [220, 230], [231, 240], [240, 241]]}
{"doc_key": "ai-dev-271", "ner": [[0, 1, "field"], [6, 7, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "origin", "", false, false], [0, 1, 6, 7, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "is", "closely", "linked", "to", "pattern", "recognition", "and", "comes", "from", "artificial", "intelligence", "."], "sentence-detokenized": "Machine learning is closely linked to pattern recognition and comes from artificial intelligence.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 34], [35, 37], [38, 45], [46, 57], [58, 61], [62, 67], [68, 72], [73, 83], [84, 96], [96, 97]]}
{"doc_key": "ai-dev-272", "ner": [[16, 19, "product"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "device", "comes", "with", "3", "Java", "games", "that", "are", "controlled", "by", "the", "remote", "control", "and", "displayed", "on", "its", "LCD", "screen", "."], "sentence-detokenized": "The device comes with 3 Java games that are controlled by the remote control and displayed on its LCD screen.", "token2charspan": [[0, 3], [4, 10], [11, 16], [17, 21], [22, 23], [24, 28], [29, 34], [35, 39], [40, 43], [44, 54], [55, 57], [58, 61], [62, 68], [69, 76], [77, 80], [81, 90], [91, 93], [94, 97], [98, 101], [102, 108], [108, 109]]}
{"doc_key": "ai-dev-273", "ner": [[5, 14, "task"], [16, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 18, 5, 14, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "commercially", "successful", "but", "specialised", "computer", "vision", "-", "based", "technique", "for", "estimating", "articulated", "body", "pointers", "is", "optical", "motion", "tracking", "."], "sentence-detokenized": "A commercially successful but specialised computer vision-based technique for estimating articulated body pointers is optical motion tracking.", "token2charspan": [[0, 1], [2, 14], [15, 25], [26, 29], [30, 41], [42, 50], [51, 57], [57, 58], [58, 63], [64, 73], [74, 77], [78, 88], [89, 100], [101, 105], [106, 114], [115, 117], [118, 125], [126, 132], [133, 141], [141, 142]]}
{"doc_key": "ai-dev-274", "ner": [[0, 1, "organisation"], [6, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 6, 10, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "SMC", "is", "very", "similar", "to", "the", "more", "popular", "Jaccard", "index", "."], "sentence-detokenized": "The SMC is very similar to the more popular Jaccard index.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 15], [16, 23], [24, 26], [27, 30], [31, 35], [36, 43], [44, 51], [52, 57], [57, 58]]}
{"doc_key": "ai-dev-275", "ner": [[0, 0, "product"], [2, 6, "product"], [7, 9, "product"], [18, 19, "researcher"], [25, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 7, 9, "named", "", false, false], [0, 0, 18, 19, "artifact", "", false, false], [0, 0, 25, 25, "artifact", "", false, false], [2, 6, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "is", "the", "robotic", "arm", "of", "an", "industrial", "robot", "developed", "by", "Victor", "Scheinman", "at", "the", "pioneering", "robotics", "company", "Unimation", "."], "sentence-detokenized": "PUMA (Programmable Universal Machine for Assembly) is the robotic arm of an industrial robot developed by Victor Scheinman at the pioneering robotics company Unimation.", "token2charspan": [[0, 4], [5, 6], [6, 18], [19, 28], [29, 36], [37, 40], [41, 49], [49, 50], [51, 53], [54, 57], [58, 65], [66, 69], [70, 72], [73, 75], [76, 86], [87, 92], [93, 102], [103, 105], [106, 112], [113, 122], [123, 125], [126, 129], [130, 140], [141, 149], [150, 157], [158, 167], [167, 168]]}
{"doc_key": "ai-dev-276", "ner": [[4, 4, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "written", "in", "Python", "."], "sentence-detokenized": "It is written in Python.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 23], [23, 24]]}
{"doc_key": "ai-dev-277", "ner": [[0, 0, "misc"], [1, 2, "misc"], [12, 12, "field"], [14, 15, "field"], [23, 24, "field"], [26, 29, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 6, 7], "relations": [[0, 0, 1, 2, "related-to", "metric_for", true, false], [0, 0, 12, 12, "part-of", "", false, false], [0, 0, 14, 15, "part-of", "", false, false], [0, 0, 23, 24, "part-of", "", false, false], [0, 0, 26, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 5, 6], "sentence": ["Bandwidth", "in", "Hertz", "is", "a", "central", "concept", "in", "many", "fields", ",", "including", "electronics", ",", "information", "theory", ",", "digital", "communications", ",", "radio", "communications", ",", "signal", "processing", "and", "spectroscopy", ",", "and", "is", "one", "of", "the", "determinants", "of", "the", "throughput", "of", "a", "particular", "communication", "channel", "."], "sentence-detokenized": "Bandwidth in Hertz is a central concept in many fields, including electronics, information theory, digital communications, radio communications, signal processing and spectroscopy, and is one of the determinants of the throughput of a particular communication channel.", "token2charspan": [[0, 9], [10, 12], [13, 18], [19, 21], [22, 23], [24, 31], [32, 39], [40, 42], [43, 47], [48, 54], [54, 55], [56, 65], [66, 77], [77, 78], [79, 90], [91, 97], [97, 98], [99, 106], [107, 121], [121, 122], [123, 128], [129, 143], [143, 144], [145, 151], [152, 162], [163, 166], [167, 179], [179, 180], [181, 184], [185, 187], [188, 191], [192, 194], [195, 198], [199, 211], [212, 214], [215, 218], [219, 229], [230, 232], [233, 234], [235, 245], [246, 259], [260, 267], [267, 268]]}
{"doc_key": "ai-dev-278", "ner": [[8, 8, "algorithm"], [10, 10, "algorithm"], [17, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 17, 20, "part-of", "", false, false], [10, 10, 17, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["When", "convex", "loss", "is", "used", "(", "as", "in", "AdaBoost", ",", "LogitBoost", ",", "and", "all", "members", "of", "the", "AnyBoost", "family", "of", "algorithms", ")", ",", "an", "example", "with", "a", "higher", "margin", "will", "receive", "less", "(", "or", "equal", ")", "weight", "than", "an", "example", "with", "a", "lower", "margin", "."], "sentence-detokenized": "When convex loss is used (as in AdaBoost, LogitBoost, and all members of the AnyBoost family of algorithms), an example with a higher margin will receive less (or equal) weight than an example with a lower margin.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 19], [20, 24], [25, 26], [26, 28], [29, 31], [32, 40], [40, 41], [42, 52], [52, 53], [54, 57], [58, 61], [62, 69], [70, 72], [73, 76], [77, 85], [86, 92], [93, 95], [96, 106], [106, 107], [107, 108], [109, 111], [112, 119], [120, 124], [125, 126], [127, 133], [134, 140], [141, 145], [146, 153], [154, 158], [159, 160], [160, 162], [163, 168], [168, 169], [170, 176], [177, 181], [182, 184], [185, 192], [193, 197], [198, 199], [200, 205], [206, 212], [212, 213]]}
{"doc_key": "ai-dev-279", "ner": [[0, 0, "researcher"], [5, 6, "researcher"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sepp", "Hochreiter", "'s", "1991", "thesis", "Sepp", "Hochreiter", "."], "sentence-detokenized": "Sepp Hochreiter's 1991 thesis Sepp Hochreiter.", "token2charspan": [[0, 4], [5, 15], [15, 17], [18, 22], [23, 29], [30, 34], [35, 45], [45, 46]]}
{"doc_key": "ai-dev-280", "ner": [[5, 5, "algorithm"], [7, 7, "algorithm"], [14, 14, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"], [26, 28, "algorithm"], [31, 32, "algorithm"], [34, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[7, 7, 5, 5, "named", "", false, false], [17, 19, 26, 28, "related-to", "", true, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["Typical", "discriminative", "models", "include", "logistic", "regression", "(", "LR", ")", ",", "support", "vector", "machines", "(", "SVMs", ")", ",", "conditional", "random", "fields", "(", "CRFs", ")", "(", "defined", "over", "an", "undirected", "graph", ")", ",", "decision", "trees", ",", "neural", "networks", "and", "many", "others", "."], "sentence-detokenized": "Typical discriminative models include logistic regression (LR), support vector machines (SVMs), conditional random fields (CRFs) (defined over an undirected graph), decision trees, neural networks and many others.", "token2charspan": [[0, 7], [8, 22], [23, 29], [30, 37], [38, 46], [47, 57], [58, 59], [59, 61], [61, 62], [62, 63], [64, 71], [72, 78], [79, 87], [88, 89], [89, 93], [93, 94], [94, 95], [96, 107], [108, 114], [115, 121], [122, 123], [123, 127], [127, 128], [129, 130], [130, 137], [138, 142], [143, 145], [146, 156], [157, 162], [162, 163], [163, 164], [165, 173], [174, 179], [179, 180], [181, 187], [188, 196], [197, 200], [201, 205], [206, 212], [212, 213]]}
{"doc_key": "ai-dev-281", "ner": [[11, 15, "metrics"], [33, 36, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "then", "also", "possible", "to", "use", "these", "probabilities", "and", "estimate", "the", "root", "mean", "square", "error", "(", "or", "some", "similar", "measure", ")", "between", "the", "probabilities", "and", "the", "actual", "values", ",", "then", "combine", "this", "with", "a", "confusion", "matrix", "to", "create", "very", "efficient", "goodness", "-", "of", "-", "fit", "functions", "for", "logistic", "regression", "."], "sentence-detokenized": "It is then also possible to use these probabilities and estimate the root mean square error (or some similar measure) between the probabilities and the actual values, then combine this with a confusion matrix to create very efficient goodness-of-fit functions for logistic regression.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 15], [16, 24], [25, 27], [28, 31], [32, 37], [38, 51], [52, 55], [56, 64], [65, 68], [69, 73], [74, 78], [79, 85], [86, 91], [92, 93], [93, 95], [96, 100], [101, 108], [109, 116], [116, 117], [118, 125], [126, 129], [130, 143], [144, 147], [148, 151], [152, 158], [159, 165], [165, 166], [167, 171], [172, 179], [180, 184], [185, 189], [190, 191], [192, 201], [202, 208], [209, 211], [212, 218], [219, 223], [224, 233], [234, 242], [242, 243], [243, 245], [245, 246], [246, 249], [250, 259], [260, 263], [264, 272], [273, 283], [283, 284]]}
{"doc_key": "ai-dev-282", "ner": [[0, 0, "product"], [6, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VoiceOver", "was", "first", "introduced", "in", "2005", "in", "Mac", "OS", "X", "Tiger", "(", "10.4", ")", "."], "sentence-detokenized": "VoiceOver was first introduced in 2005 in Mac OS X Tiger (10.4).", "token2charspan": [[0, 9], [10, 13], [14, 19], [20, 30], [31, 33], [34, 38], [39, 41], [42, 45], [46, 48], [49, 50], [51, 56], [57, 58], [58, 62], [62, 63], [63, 64]]}
{"doc_key": "ai-dev-283", "ner": [[14, 17, "algorithm"], [21, 22, "misc"], [27, 30, "metrics"], [31, 35, "algorithm"], [63, 65, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 17, 21, 22, "related-to", "applied_to", false, false], [27, 30, 21, 22, "type-of", "", false, false], [27, 30, 31, 35, "related-to", "used_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "practice", ",", "machine", "-", "learning", "algorithms", "cope", "with", "this", "either", "by", "using", "a", "convex", "approximation", "of", "the", "0", "-", "1", "loss", "function", "(", "such", "as", "the", "loss", "of", "a", "hinge", "to", "a", "reference", "vector", "machine", ")", ",", "which", "is", "easier", "to", "optimise", ",", "or", "by", "making", "assumptions", "on", "the", "distribution", "mathP", "(", "x", ",", "y", ")", "/", "math", "(", "and", "thus", "terminating", "agnostic", "learning", "algorithms", ",", "for", "which", "the", "above", "result", "holds", ")", "."], "sentence-detokenized": "In practice, machine-learning algorithms cope with this either by using a convex approximation of the 0-1 loss function (such as the loss of a hinge to a reference vector machine), which is easier to optimise, or by making assumptions on the distribution mathP(x, y)/math (and thus terminating agnostic learning algorithms, for which the above result holds).", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 20], [20, 21], [21, 29], [30, 40], [41, 45], [46, 50], [51, 55], [56, 62], [63, 65], [66, 71], [72, 73], [74, 80], [81, 94], [95, 97], [98, 101], [102, 103], [103, 104], [104, 105], [106, 110], [111, 119], [120, 121], [121, 125], [126, 128], [129, 132], [133, 137], [138, 140], [141, 142], [143, 148], [149, 151], [152, 153], [154, 163], [164, 170], [171, 178], [178, 179], [179, 180], [181, 186], [187, 189], [190, 196], [197, 199], [200, 208], [208, 209], [210, 212], [213, 215], [216, 222], [223, 234], [235, 237], [238, 241], [242, 254], [255, 260], [260, 261], [261, 262], [262, 263], [264, 265], [265, 266], [266, 267], [267, 271], [272, 273], [273, 276], [277, 281], [282, 293], [294, 302], [303, 311], [312, 322], [322, 323], [324, 327], [328, 333], [334, 337], [338, 343], [344, 350], [351, 356], [356, 357], [357, 358]]}
{"doc_key": "ai-dev-284", "ner": [[0, 0, "misc"], [11, 14, "field"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 14, "usage", "", false, false], [0, 0, 19, 19, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Westworld", "(", "1973", ")", "was", "the", "first", "feature", "film", "to", "use", "digital", "image", "processing", "of", "photography", "to", "simulate", "the", "android", "point", "of", "view", "."], "sentence-detokenized": "Westworld (1973) was the first feature film to use digital image processing of photography to simulate the android point of view.", "token2charspan": [[0, 9], [10, 11], [11, 15], [15, 16], [17, 20], [21, 24], [25, 30], [31, 38], [39, 43], [44, 46], [47, 50], [51, 58], [59, 64], [65, 75], [76, 78], [79, 90], [91, 93], [94, 102], [103, 106], [107, 114], [115, 120], [121, 123], [124, 128], [128, 129]]}
{"doc_key": "ai-dev-285", "ner": [[6, 8, "task"], [10, 11, "task"], [13, 13, "task"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "now", "also", "commonly", "used", "in", "speech", "recognition", ",", "speech", "synthesis", ",", "diarisation", ",", "Xavier", "Anguera", "et", "al", "."], "sentence-detokenized": "It is now also commonly used in speech recognition, speech synthesis, diarisation, Xavier Anguera et al.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 14], [15, 23], [24, 28], [29, 31], [32, 38], [39, 50], [50, 51], [52, 58], [59, 68], [68, 69], [70, 81], [81, 82], [83, 89], [90, 97], [98, 100], [101, 103], [103, 104]]}
{"doc_key": "ai-dev-286", "ner": [[8, 13, "algorithm"], [18, 19, "algorithm"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 19, 8, 13, "type-of", "", false, false], [22, 24, 8, 13, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Here", ",", "math", "\\", "sigma", "/", "math", "is", "an", "element", "-", "based", "activation", "function", ",", "such", "as", "a", "sigmoid", "function", "or", "a", "rectified", "linear", "unit", "."], "sentence-detokenized": "Here, math\\ sigma/math is an element-based activation function, such as a sigmoid function or a rectified linear unit.", "token2charspan": [[0, 4], [4, 5], [6, 10], [10, 11], [12, 17], [17, 18], [18, 22], [23, 25], [26, 28], [29, 36], [36, 37], [37, 42], [43, 53], [54, 62], [62, 63], [64, 68], [69, 71], [72, 73], [74, 81], [82, 90], [91, 93], [94, 95], [96, 105], [106, 112], [113, 117], [117, 118]]}
{"doc_key": "ai-dev-287", "ner": [[7, 8, "algorithm"], [21, 21, "misc"], [23, 23, "misc"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "phonetics", "-", "based", "(", "i.e.", "all", "Hidden", "Markov", "Model", "-", "based", ")", "approaches", "required", "separate", "components", "and", "training", "for", "the", "pronunciation", ",", "acoustic", "and", "language", "models", "."], "sentence-detokenized": "Traditional phonetics-based (i.e. all Hidden Markov Model-based) approaches required separate components and training for the pronunciation, acoustic and language models.", "token2charspan": [[0, 11], [12, 21], [21, 22], [22, 27], [28, 29], [29, 33], [34, 37], [38, 44], [45, 51], [52, 57], [57, 58], [58, 63], [63, 64], [65, 75], [76, 84], [85, 93], [94, 104], [105, 108], [109, 117], [118, 121], [122, 125], [126, 139], [139, 140], [141, 149], [150, 153], [154, 162], [163, 169], [169, 170]]}
{"doc_key": "ai-dev-288", "ner": [[0, 3, "algorithm"], [6, 8, "field"], [10, 11, "field"], [12, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 12, 14, "related-to", "used_for", false, false], [6, 8, 0, 3, "usage", "", false, false], [10, 11, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Roberts", "cross", "operator", "is", "used", "in", "image", "processing", "and", "computer", "vision", "to", "detect", "edges", "."], "sentence-detokenized": "The Roberts cross operator is used in image processing and computer vision to detect edges.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 37], [38, 43], [44, 54], [55, 58], [59, 67], [68, 74], [75, 77], [78, 84], [85, 90], [90, 91]]}
{"doc_key": "ai-dev-289", "ner": [[0, 0, "metrics"], [2, 2, "metrics"], [24, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 24, 24, "opposite", "", false, false], [2, 2, 24, 24, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Sensitivity", "and", "specificity", "values", "do", "not", "depend", "on", "the", "percentage", "of", "positive", "cases", "in", "the", "population", "of", "interest", "(", "unlike", ",", "for", "example", ",", "precision", ")", "."], "sentence-detokenized": "Sensitivity and specificity values do not depend on the percentage of positive cases in the population of interest (unlike, for example, precision).", "token2charspan": [[0, 11], [12, 15], [16, 27], [28, 34], [35, 37], [38, 41], [42, 48], [49, 51], [52, 55], [56, 66], [67, 69], [70, 78], [79, 84], [85, 87], [88, 91], [92, 102], [103, 105], [106, 114], [115, 116], [116, 122], [122, 123], [124, 127], [128, 135], [135, 136], [137, 146], [146, 147], [147, 148]]}
{"doc_key": "ai-dev-290", "ner": [[2, 3, "algorithm"], [7, 17, "misc"], [9, 10, "researcher"], [12, 13, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 17, 2, 3, "topic", "", false, false], [7, 17, 9, 10, "artifact", "", false, false], [7, 17, 12, 13, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["However", ",", "perceptron", "models", "became", "very", "unpopular", "because", "of", "Marvin", "Minsky", "and", "Seymour", "Papert", "'s", "book", "\"", "Perceptrons", "\"", "published", "in", "1969", "."], "sentence-detokenized": "However, perceptron models became very unpopular because of Marvin Minsky and Seymour Papert's book \"Perceptrons\" published in 1969.", "token2charspan": [[0, 7], [7, 8], [9, 19], [20, 26], [27, 33], [34, 38], [39, 48], [49, 56], [57, 59], [60, 66], [67, 73], [74, 77], [78, 85], [86, 92], [92, 94], [95, 99], [100, 101], [101, 112], [112, 113], [114, 123], [124, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-dev-291", "ner": [[0, 4, "conference"], [7, 7, "organisation"], [3, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 3, 23, "topic", "", false, false], [7, 7, 0, 4, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "annual", "document", "summarization", "conferences", "organized", "by", "NIST", "have", "developed", "sophisticated", "evaluation", "criteria", "for", "techniques", "that", "take", "on", "the", "challenge", "of", "summarizing", "multiple", "documents", "."], "sentence-detokenized": "The annual document summarization conferences organized by NIST have developed sophisticated evaluation criteria for techniques that take on the challenge of summarizing multiple documents.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 33], [34, 45], [46, 55], [56, 58], [59, 63], [64, 68], [69, 78], [79, 92], [93, 103], [104, 112], [113, 116], [117, 127], [128, 132], [133, 137], [138, 140], [141, 144], [145, 154], [155, 157], [158, 169], [170, 178], [179, 188], [188, 189]]}
{"doc_key": "ai-dev-292", "ner": [[0, 2, "product"], [25, 27, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 25, 27, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "parallel", "manipulator", "is", "designed", "so", "that", "each", "chain", "is", "usually", "short", "and", "simple", "and", "can", "therefore", "be", "rigid", "against", "unwanted", "movement", ",", "compared", "to", "a", "series", "manipulator", "."], "sentence-detokenized": "The parallel manipulator is designed so that each chain is usually short and simple and can therefore be rigid against unwanted movement, compared to a series manipulator.", "token2charspan": [[0, 3], [4, 12], [13, 24], [25, 27], [28, 36], [37, 39], [40, 44], [45, 49], [50, 55], [56, 58], [59, 66], [67, 72], [73, 76], [77, 83], [84, 87], [88, 91], [92, 101], [102, 104], [105, 110], [111, 118], [119, 127], [128, 136], [136, 137], [138, 146], [147, 149], [150, 151], [152, 158], [159, 170], [170, 171]]}
{"doc_key": "ai-dev-293", "ner": [[26, 26, "misc"], [28, 30, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "the", "manipulator", "that", "makes", "the", "robot", "move", ",", "and", "the", "design", "of", "these", "systems", "can", "be", "categorised", "into", "several", "common", "types", ",", "such", "as", "SCARA", "and", "Cartesian", "coordinate", "robots", ",", "which", "use", "different", "coordinate", "systems", "to", "guide", "the", "machine", "'s", "arms", "."], "sentence-detokenized": "It is the manipulator that makes the robot move, and the design of these systems can be categorised into several common types, such as SCARA and Cartesian coordinate robots, which use different coordinate systems to guide the machine's arms.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 21], [22, 26], [27, 32], [33, 36], [37, 42], [43, 47], [47, 48], [49, 52], [53, 56], [57, 63], [64, 66], [67, 72], [73, 80], [81, 84], [85, 87], [88, 99], [100, 104], [105, 112], [113, 119], [120, 125], [125, 126], [127, 131], [132, 134], [135, 140], [141, 144], [145, 154], [155, 165], [166, 172], [172, 173], [174, 179], [180, 183], [184, 193], [194, 204], [205, 212], [213, 215], [216, 221], [222, 225], [226, 233], [233, 235], [236, 240], [240, 241]]}
{"doc_key": "ai-dev-294", "ner": [[0, 7, "country"], [11, 14, "organisation"], [17, 22, "organisation"], [25, 27, "organisation"], [30, 32, "organisation"], [36, 42, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 14, 0, 7, "physical", "", false, false], [17, 22, 0, 7, "physical", "", false, false], [25, 27, 0, 7, "physical", "", false, false], [30, 32, 0, 7, "physical", "", false, false], [36, 42, 0, 7, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "United", "States", ",", "he", "is", "a", "Fellow", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Linguistic", "Society", ",", "the", "American", "Philosophical", "Society", ",", "and", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In the United States, he is a Fellow of the National Academy of Sciences, the American Academy of Arts and Sciences, the American Linguistic Society, the American Philosophical Society, and the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 20], [20, 21], [22, 24], [25, 27], [28, 29], [30, 36], [37, 39], [40, 43], [44, 52], [53, 60], [61, 63], [64, 72], [72, 73], [74, 77], [78, 86], [87, 94], [95, 97], [98, 102], [103, 106], [107, 115], [115, 116], [117, 120], [121, 129], [130, 140], [141, 148], [148, 149], [150, 153], [154, 162], [163, 176], [177, 184], [184, 185], [186, 189], [190, 193], [194, 202], [203, 214], [215, 218], [219, 222], [223, 234], [235, 237], [238, 245], [245, 246]]}
{"doc_key": "ai-dev-295", "ner": [[7, 9, "algorithm"], [11, 14, "algorithm"], [18, 19, "algorithm"], [25, 26, "algorithm"], [31, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 9, 18, 19, "named", "", false, false], [11, 14, 7, 9, "named", "", false, false], [18, 19, 25, 26, "compare", "", false, false], [18, 19, 31, 32, "related-to", "performs", false, false], [25, 26, 31, 32, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["They", "gained", "prominence", "with", "the", "popularity", "of", "support", "vector", "machines", "(", "SVMs", ")", "in", "the", "1990s", ",", "when", "SVMs", "were", "found", "to", "be", "competitive", "with", "neural", "networks", "in", "tasks", "such", "as", "handwriting", "recognition", "."], "sentence-detokenized": "They gained prominence with the popularity of support vector machines (SVMs) in the 1990s, when SVMs were found to be competitive with neural networks in tasks such as handwriting recognition.", "token2charspan": [[0, 4], [5, 11], [12, 22], [23, 27], [28, 31], [32, 42], [43, 45], [46, 53], [54, 60], [61, 69], [70, 71], [71, 75], [75, 76], [77, 79], [80, 83], [84, 89], [89, 90], [91, 95], [96, 100], [101, 105], [106, 111], [112, 114], [115, 117], [118, 129], [130, 134], [135, 141], [142, 150], [151, 153], [154, 159], [160, 164], [165, 167], [168, 179], [180, 191], [191, 192]]}
{"doc_key": "ai-dev-296", "ner": [[2, 3, "misc"], [8, 9, "misc"], [13, 14, "algorithm"], [22, 23, "misc"], [27, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 8, 9, "usage", "", false, false], [2, 3, 22, 23, "usage", "", false, false], [8, 9, 13, 14, "origin", "result_of_algorithm", false, false], [22, 23, 27, 28, "origin", "result_of_algorithm", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "empirical", "whitening", "transformation", "is", "obtained", "by", "estimating", "the", "covariates", "(", "e.g.", "by", "maximum", "likelihood", ")", "and", "then", "constructing", "the", "corresponding", "estimated", "whitening", "matrix", "(", "e.g.", "by", "Choleski", "subtraction", ")", "."], "sentence-detokenized": "The empirical whitening transformation is obtained by estimating the covariates (e.g. by maximum likelihood) and then constructing the corresponding estimated whitening matrix (e.g. by Choleski subtraction).", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 38], [39, 41], [42, 50], [51, 53], [54, 64], [65, 68], [69, 79], [80, 81], [81, 85], [86, 88], [89, 96], [97, 107], [107, 108], [109, 112], [113, 117], [118, 130], [131, 134], [135, 148], [149, 158], [159, 168], [169, 175], [176, 177], [177, 181], [182, 184], [185, 193], [194, 205], [205, 206], [206, 207]]}
{"doc_key": "ai-dev-297", "ner": [[0, 0, "organisation"], [8, 9, "product"], [22, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 0, 0, "artifact", "", false, false], [22, 23, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["IAI", "is", "the", "world", "'s", "largest", "manufacturer", "of", "Cartesian", "robots", "and", "a", "recognised", "leader", "in", "low", "-", "cost", ",", "high", "-", "performance", "SCARA", "robots", "."], "sentence-detokenized": "IAI is the world's largest manufacturer of Cartesian robots and a recognised leader in low-cost, high-performance SCARA robots.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [16, 18], [19, 26], [27, 39], [40, 42], [43, 52], [53, 59], [60, 63], [64, 65], [66, 76], [77, 83], [84, 86], [87, 90], [90, 91], [91, 95], [95, 96], [97, 101], [101, 102], [102, 113], [114, 119], [120, 126], [126, 127]]}
{"doc_key": "ai-dev-298", "ner": [[7, 8, "field"], [10, 11, "field"], [13, 14, "field"], [16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 25, "field"], [27, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["Formal", "concept", "analysis", "has", "practical", "applications", "in", "data", "mining", ",", "text", "mining", ",", "machine", "learning", ",", "knowledge", "management", ",", "semantic", "web", ",", "software", "development", ",", "chemistry", "and", "biology", ",", "among", "others", "."], "sentence-detokenized": "Formal concept analysis has practical applications in data mining, text mining, machine learning, knowledge management, semantic web, software development, chemistry and biology, among others.", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 27], [28, 37], [38, 50], [51, 53], [54, 58], [59, 65], [65, 66], [67, 71], [72, 78], [78, 79], [80, 87], [88, 96], [96, 97], [98, 107], [108, 118], [118, 119], [120, 128], [129, 132], [132, 133], [134, 142], [143, 154], [154, 155], [156, 165], [166, 169], [170, 177], [177, 178], [179, 184], [185, 191], [191, 192]]}
{"doc_key": "ai-dev-299", "ner": [[0, 2, "field"], [4, 6, "field"], [10, 11, "field"], [17, 18, "field"], [29, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 17, 18, "part-of", "", false, false], [4, 6, 29, 30, "topic", "", false, false], [10, 11, 4, 6, "named", "", false, false], [17, 18, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", ",", "computational", "learning", "theory", "(", "or", "simply", "learning", "theory", ")", "is", "a", "subfield", "of", "artificial", "intelligence", "dedicated", "to", "the", "study", "of", "the", "design", "and", "analysis", "of", "machine", "learning", "algorithms", "."], "sentence-detokenized": "In computer science, computational learning theory (or simply learning theory) is a subfield of artificial intelligence dedicated to the study of the design and analysis of machine learning algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 34], [35, 43], [44, 50], [51, 52], [52, 54], [55, 61], [62, 70], [71, 77], [77, 78], [79, 81], [82, 83], [84, 92], [93, 95], [96, 106], [107, 119], [120, 129], [130, 132], [133, 136], [137, 142], [143, 145], [146, 149], [150, 156], [157, 160], [161, 169], [170, 172], [173, 180], [181, 189], [190, 200], [200, 201]]}
{"doc_key": "ai-dev-300", "ner": [[0, 3, "algorithm"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Cooperative", "filtering", "(", "CF", ")", "is", "a", "technique", "used", "by", "recommender", "systems", "."], "sentence-detokenized": "Cooperative filtering (CF) is a technique used by recommender systems.", "token2charspan": [[0, 11], [12, 21], [22, 23], [23, 25], [25, 26], [27, 29], [30, 31], [32, 41], [42, 46], [47, 49], [50, 61], [62, 69], [69, 70]]}
{"doc_key": "ai-dev-301", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "FALSE", "positive", "rate", "is", "the", "proportion", "of", "all", "negative", "results", "that", "still", "give", "a", "positive", "test", "result", ",", "i.e.", "the", "conditional", "probability", "of", "a", "positive", "test", "result", "if", "the", "event", "did", "not", "occur", "."], "sentence-detokenized": "The FALSE positive rate is the proportion of all negative results that still give a positive test result, i.e. the conditional probability of a positive test result if the event did not occur.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 23], [24, 26], [27, 30], [31, 41], [42, 44], [45, 48], [49, 57], [58, 65], [66, 70], [71, 76], [77, 81], [82, 83], [84, 92], [93, 97], [98, 104], [104, 105], [106, 110], [111, 114], [115, 126], [127, 138], [139, 141], [142, 143], [144, 152], [153, 157], [158, 164], [165, 167], [168, 171], [172, 177], [178, 181], [182, 185], [186, 191], [191, 192]]}
{"doc_key": "ai-dev-302", "ner": [[1, 15, "misc"], [37, 37, "metrics"], [41, 41, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 15, 37, 37, "topic", "", false, false], [1, 15, 41, 41, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "VLDB", "'", "8", ":", "Proceedings", "of", "the", "34th", "International", "Conference", "on", "Very", "Large", "Data", "Bases", ",", "pages", "422--433", ".", "showed", "that", "the", "given", "values", "of", "mathC", "/", "math", "and", "mathK", "/", "math", "generally", "imply", "relatively", "low", "accuracy", "for", "iteratively", "computed", "SimRank", "scores", "."], "sentence-detokenized": "In VLDB '8: Proceedings of the 34th International Conference on Very Large Data Bases, pages 422--433. showed that the given values of mathC/math and mathK/math generally imply relatively low accuracy for iteratively computed SimRank scores.", "token2charspan": [[0, 2], [3, 7], [8, 9], [9, 10], [10, 11], [12, 23], [24, 26], [27, 30], [31, 35], [36, 49], [50, 60], [61, 63], [64, 68], [69, 74], [75, 79], [80, 85], [85, 86], [87, 92], [93, 101], [101, 102], [103, 109], [110, 114], [115, 118], [119, 124], [125, 131], [132, 134], [135, 140], [140, 141], [141, 145], [146, 149], [150, 155], [155, 156], [156, 160], [161, 170], [171, 176], [177, 187], [188, 191], [192, 200], [201, 204], [205, 216], [217, 225], [226, 233], [234, 240], [240, 241]]}
{"doc_key": "ai-dev-303", "ner": [[5, 7, "misc"], [8, 8, "misc"], [15, 15, "person"], [17, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 5, 7, "general-affiliation", "", false, false], [8, 8, 15, 15, "artifact", "", false, false], [8, 8, 17, 19, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "June", "2015", ",", "the", "science", "fiction", "drama", "Sense8", ",", "written", "and", "produced", "by", "the", "Wachowskis", "and", "J.", "Michael", "Straczynski", "."], "sentence-detokenized": "In June 2015, the science fiction drama Sense8, written and produced by the Wachowskis and J. Michael Straczynski.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 25], [26, 33], [34, 39], [40, 46], [46, 47], [48, 55], [56, 59], [60, 68], [69, 71], [72, 75], [76, 86], [87, 90], [91, 93], [94, 101], [102, 113], [113, 114]]}
{"doc_key": "ai-dev-304", "ner": [[1, 1, "misc"], [6, 7, "product"], [23, 25, "misc"], [33, 33, "country"], [35, 35, "country"], [37, 37, "country"], [39, 39, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 1, 6, 7, "topic", "", false, false], [33, 33, 23, 25, "type-of", "", false, false], [35, 35, 23, 25, "type-of", "", false, false], [37, 37, 23, 25, "type-of", "", false, false], [39, 39, 23, 25, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Although", "Eurotra", "never", "delivered", "a", "functioning", "MT", "system", ",", "the", "project", "had", "a", "long", "-", "lasting", "impact", "on", "the", "emerging", "language", "industries", "in", "European", "Member", "States", ",", "particularly", "in", "the", "southern", "countries", "(", "Greece", ",", "Italy", ",", "Spain", "and", "Portugal", ")", "."], "sentence-detokenized": "Although Eurotra never delivered a functioning MT system, the project had a long-lasting impact on the emerging language industries in European Member States, particularly in the southern countries (Greece, Italy, Spain and Portugal).", "token2charspan": [[0, 8], [9, 16], [17, 22], [23, 32], [33, 34], [35, 46], [47, 49], [50, 56], [56, 57], [58, 61], [62, 69], [70, 73], [74, 75], [76, 80], [80, 81], [81, 88], [89, 95], [96, 98], [99, 102], [103, 111], [112, 120], [121, 131], [132, 134], [135, 143], [144, 150], [151, 157], [157, 158], [159, 171], [172, 174], [175, 178], [179, 187], [188, 197], [198, 199], [199, 205], [205, 206], [207, 212], [212, 213], [214, 219], [220, 223], [224, 232], [232, 233], [233, 234]]}
{"doc_key": "ai-dev-305", "ner": [[0, 0, "algorithm"], [5, 8, "task"], [16, 20, "task"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[5, 8, 0, 0, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Autocoding", "has", "been", "successfully", "applied", "to", "machine", "translation", "of", "human", "languages", ",", "commonly", "referred", "to", "as", "neural", "machine", "translation", "(", "NMT", ")", "."], "sentence-detokenized": "Autocoding has been successfully applied to machine translation of human languages, commonly referred to as neural machine translation (NMT).", "token2charspan": [[0, 10], [11, 14], [15, 19], [20, 32], [33, 40], [41, 43], [44, 51], [52, 63], [64, 66], [67, 72], [73, 82], [82, 83], [84, 92], [93, 101], [102, 104], [105, 107], [108, 114], [115, 122], [123, 134], [135, 136], [136, 139], [139, 140], [140, 141]]}
{"doc_key": "ai-dev-306", "ner": [[7, 9, "metrics"], [11, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Popular", "examples", "of", "probabilistic", "fitness", "functions", "include", "maximum", "likelihood", "estimation", "and", "soul", "loss", "."], "sentence-detokenized": "Popular examples of probabilistic fitness functions include maximum likelihood estimation and soul loss.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 33], [34, 41], [42, 51], [52, 59], [60, 67], [68, 78], [79, 89], [90, 93], [94, 98], [99, 103], [103, 104]]}
{"doc_key": "ai-dev-307", "ner": [[0, 1, "field"], [11, 14, "task"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 14, 0, 1, "part-of", "", false, false], [16, 17, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Data", "mining", "is", "a", "related", "field", "of", "research", "that", "focuses", "on", "exploratory", "analysis", "of", "data", "through", "unsupervised", "learning", "."], "sentence-detokenized": "Data mining is a related field of research that focuses on exploratory analysis of data through unsupervised learning.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 16], [17, 24], [25, 30], [31, 33], [34, 42], [43, 47], [48, 55], [56, 58], [59, 70], [71, 79], [80, 82], [83, 87], [88, 95], [96, 108], [109, 117], [117, 118]]}
{"doc_key": "ai-dev-308", "ner": [[0, 1, "algorithm"], [12, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 12, 14, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "filtering", "involves", "methods", "for", "matching", "people", "with", "similar", "interests", "and", "creating", "a", "recommendation", "system", "based", "on", "this", "."], "sentence-detokenized": "Collaborative filtering involves methods for matching people with similar interests and creating a recommendation system based on this.", "token2charspan": [[0, 13], [14, 23], [24, 32], [33, 40], [41, 44], [45, 53], [54, 60], [61, 65], [66, 73], [74, 83], [84, 87], [88, 96], [97, 98], [99, 113], [114, 120], [121, 126], [127, 129], [130, 134], [134, 135]]}
{"doc_key": "ai-dev-309", "ner": [[1, 6, "algorithm"], [14, 17, "product"]], "ner_mapping_to_source": [0, 2], "relations": [[14, 17, 1, 6, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Several", "WordNet", "-", "based", "word", "similarity", "algorithms", "are", "implemented", "in", "a", "Perl", "package", "called", "WordNet", ":", ":", "Similarity", "."], "sentence-detokenized": "Several WordNet-based word similarity algorithms are implemented in a Perl package called WordNet:: Similarity.", "token2charspan": [[0, 7], [8, 15], [15, 16], [16, 21], [22, 26], [27, 37], [38, 48], [49, 52], [53, 64], [65, 67], [68, 69], [70, 74], [75, 82], [83, 89], [90, 97], [97, 98], [98, 99], [100, 110], [110, 111]]}
{"doc_key": "ai-dev-310", "ner": [[6, 6, "conference"], [8, 8, "conference"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 8, 6, 6, "named", "", false, false], [11, 12, 6, 6, "temporal", "", false, false], [14, 15, 6, 6, "temporal", "", false, false], [17, 18, 6, 6, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "second", "paper", ",", "presented", "by", "CVPR", "(", "CVPR", ")", "2000", "Erik", "Miller", ",", "Nicholas", "Matsakis", "and", "Paul", "Viola", ",", "will", "also", "be", "discussed", "."], "sentence-detokenized": "The second paper, presented by CVPR (CVPR) 2000 Erik Miller, Nicholas Matsakis and Paul Viola, will also be discussed.", "token2charspan": [[0, 3], [4, 10], [11, 16], [16, 17], [18, 27], [28, 30], [31, 35], [36, 37], [37, 41], [41, 42], [43, 47], [48, 52], [53, 59], [59, 60], [61, 69], [70, 78], [79, 82], [83, 87], [88, 93], [93, 94], [95, 99], [100, 104], [105, 107], [108, 117], [117, 118]]}
{"doc_key": "ai-dev-311", "ner": [[0, 0, "algorithm"], [7, 8, "misc"], [15, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 15, 16, "compare", "", false, false], [15, 16, 7, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["QC", "is", "not", "evaluated", "against", "traditional", "modern", "clustering", "algorithms", ",", "with", "the", "exception", "of", "the", "Jaccard", "index", "."], "sentence-detokenized": "QC is not evaluated against traditional modern clustering algorithms, with the exception of the Jaccard index.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 19], [20, 27], [28, 39], [40, 46], [47, 57], [58, 68], [68, 69], [70, 74], [75, 78], [79, 88], [89, 91], [92, 95], [96, 103], [104, 109], [109, 110]]}
{"doc_key": "ai-dev-312", "ner": [[2, 7, "misc"], [8, 10, "misc"], [15, 16, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 2, 7, "physical", "", false, false], [8, 10, 15, 16, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "the", "VEX", "Robotics", "World", "Championship", ",", "a", "Parade", "of", "Nations", "will", "take", "place", "in", "Freedom", "Hall", ",", "with", "hundreds", "of", "students", "from", "more", "than", "30", "countries", "taking", "part", "."], "sentence-detokenized": "During the VEX Robotics World Championship, a Parade of Nations will take place in Freedom Hall, with hundreds of students from more than 30 countries taking part.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 23], [24, 29], [30, 42], [42, 43], [44, 45], [46, 52], [53, 55], [56, 63], [64, 68], [69, 73], [74, 79], [80, 82], [83, 90], [91, 95], [95, 96], [97, 101], [102, 110], [111, 113], [114, 122], [123, 127], [128, 132], [133, 137], [138, 140], [141, 150], [151, 157], [158, 162], [162, 163]]}
{"doc_key": "ai-dev-313", "ner": [[7, 8, "metrics"], [5, 10, "metrics"], [14, 15, "metrics"], [13, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 10, 7, 8, "named", "", false, false], [13, 17, 14, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Other", "measures", "of", "accuracy", "include", "single", "word", "error", "rate", "(", "SWER", ")", "and", "command", "success", "rate", "(", "CSR", ")", "."], "sentence-detokenized": "Other measures of accuracy include single word error rate (SWER) and command success rate (CSR).", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [27, 34], [35, 41], [42, 46], [47, 52], [53, 57], [58, 59], [59, 63], [63, 64], [65, 68], [69, 76], [77, 84], [85, 89], [90, 91], [91, 94], [94, 95], [95, 96]]}
{"doc_key": "ai-dev-314", "ner": [[8, 9, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "presented", "their", "method", "and", "results", "at", "the", "SIGGRAPH", "2000", "conference", "."], "sentence-detokenized": "They presented their method and results at the SIGGRAPH 2000 conference.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 27], [28, 31], [32, 39], [40, 42], [43, 46], [47, 55], [56, 60], [61, 71], [71, 72]]}
{"doc_key": "ai-dev-315", "ner": [[0, 2, "conference"], [7, 7, "misc"], [9, 13, "misc"], [17, 19, "conference"], [23, 29, "researcher"], [37, 38, "researcher"], [42, 44, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 7, 7, "origin", "", false, false], [7, 7, 17, 19, "physical", "", false, false], [7, 7, 17, 19, "temporal", "", false, false], [7, 7, 23, 29, "origin", "", false, false], [7, 7, 37, 38, "origin", "", false, false], [9, 13, 7, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "KDD", "conference", "grew", "out", "of", "the", "KDD", "(", "Knowledge", "Discovery", "and", "Data", "Mining", ")", "workshops", "at", "the", "AAAI", "conferences", ",", "initiated", "by", "Gregory", "I", ".", "Piatetsky", "-", "Shapiro", "in", "1989", ",", "1991", "and", "1993", ",", "and", "Usama", "Fayyad", "in", "1994", ".", "Machines", "|", "ACM", "."], "sentence-detokenized": "The KDD conference grew out of the KDD (Knowledge Discovery and Data Mining) workshops at the AAAI conferences, initiated by Gregory I. Piatetsky-Shapiro in 1989, 1991 and 1993, and Usama Fayyad in 1994. Machines | ACM.", "token2charspan": [[0, 3], [4, 7], [8, 18], [19, 23], [24, 27], [28, 30], [31, 34], [35, 38], [39, 40], [40, 49], [50, 59], [60, 63], [64, 68], [69, 75], [75, 76], [77, 86], [87, 89], [90, 93], [94, 98], [99, 110], [110, 111], [112, 121], [122, 124], [125, 132], [133, 134], [134, 135], [136, 145], [145, 146], [146, 153], [154, 156], [157, 161], [161, 162], [163, 167], [168, 171], [172, 176], [176, 177], [178, 181], [182, 187], [188, 194], [195, 197], [198, 202], [202, 203], [204, 212], [213, 214], [215, 218], [218, 219]]}
{"doc_key": "ai-dev-316", "ner": [[8, 9, "conference"], [6, 11, "conference"], [17, 20, "organisation"], [15, 22, "organisation"], [29, 30, "conference"], [32, 32, "conference"], [36, 42, "conference"], [44, 44, "conference"], [51, 53, "conference"], [55, 55, "conference"], [61, 64, "conference"], [66, 66, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[6, 11, 8, 9, "named", "", false, false], [15, 22, 17, 20, "named", "", false, false], [32, 32, 29, 30, "named", "", false, false], [44, 44, 36, 42, "named", "", false, false], [55, 55, 51, 53, "named", "", false, false], [66, 66, 61, 64, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["He", "is", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", "(", "ACM", ")", ",", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", ",", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", ",", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "the", "American", "Association", "for", "Advancement", "of", "Science", "(", "AAAS", ")", "and", "the", "Society", "for", "Optics", "and", "Photonics", "Technology", "(", "SPIE", ")", "."], "sentence-detokenized": "He is a member of the Association for Computing Machinery (ACM), the Institute of Electrical and Electronics Engineers (IEEE), the International Association for Pattern Recognition (IAPR), the Association for the Advancement of Artificial Intelligence (AAAI), the American Association for Advancement of Science (AAAS) and the Society for Optics and Photonics Technology (SPIE).", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 33], [34, 37], [38, 47], [48, 57], [58, 59], [59, 62], [62, 63], [63, 64], [65, 68], [69, 78], [79, 81], [82, 92], [93, 96], [97, 108], [109, 118], [119, 120], [120, 124], [124, 125], [125, 126], [127, 130], [131, 144], [145, 156], [157, 160], [161, 168], [169, 180], [181, 182], [182, 186], [186, 187], [187, 188], [189, 192], [193, 204], [205, 208], [209, 212], [213, 224], [225, 227], [228, 238], [239, 251], [252, 253], [253, 257], [257, 258], [258, 259], [260, 263], [264, 272], [273, 284], [285, 288], [289, 300], [301, 303], [304, 311], [312, 313], [313, 317], [317, 318], [319, 322], [323, 326], [327, 334], [335, 338], [339, 345], [346, 349], [350, 359], [360, 370], [371, 372], [372, 376], [376, 377], [377, 378]]}
{"doc_key": "ai-dev-317", "ner": [[0, 1, "field"], [3, 4, "field"], [16, 17, "field"], [30, 31, "field"], [49, 54, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 17, "named", "", false, false], [3, 4, 30, 31, "named", "", false, false], [30, 31, 49, 54, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "learning", "and", "data", "mining", "often", "use", "the", "same", "methods", "and", "overlap", "significantly", ",", "but", "while", "machine", "learning", "focuses", "on", "prediction", "based", "on", "known", "features", "learned", "from", "training", "data", ",", "data", "mining", "focuses", "on", "the", "discovery", "of", "(", "previously", ")", "unknown", "features", "in", "the", "data", "(", "this", "is", "the", "knowledge", "discovery", "analysis", "stage", "of", "databases", ")", "."], "sentence-detokenized": "Machine learning and data mining often use the same methods and overlap significantly, but while machine learning focuses on prediction based on known features learned from training data, data mining focuses on the discovery of (previously) unknown features in the data (this is the knowledge discovery analysis stage of databases).", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 25], [26, 32], [33, 38], [39, 42], [43, 46], [47, 51], [52, 59], [60, 63], [64, 71], [72, 85], [85, 86], [87, 90], [91, 96], [97, 104], [105, 113], [114, 121], [122, 124], [125, 135], [136, 141], [142, 144], [145, 150], [151, 159], [160, 167], [168, 172], [173, 181], [182, 186], [186, 187], [188, 192], [193, 199], [200, 207], [208, 210], [211, 214], [215, 224], [225, 227], [228, 229], [229, 239], [239, 240], [241, 248], [249, 257], [258, 260], [261, 264], [265, 269], [270, 271], [271, 275], [276, 278], [279, 282], [283, 292], [293, 302], [303, 311], [312, 317], [318, 320], [321, 330], [330, 331], [331, 332]]}
{"doc_key": "ai-dev-318", "ner": [[0, 0, "product"], [4, 4, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 4, "general-affiliation", "", false, false], [0, 0, 4, 4, "related-to", "runs_on", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Indy", "is", "written", "in", "Java", "and", "therefore", "works", "on", "most", "modern", "operating", "systems", "."], "sentence-detokenized": "Indy is written in Java and therefore works on most modern operating systems.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 23], [24, 27], [28, 37], [38, 43], [44, 46], [47, 51], [52, 58], [59, 68], [69, 76], [76, 77]]}
{"doc_key": "ai-dev-319", "ner": [[0, 0, "algorithm"], [6, 6, "algorithm"], [5, 9, "algorithm"], [14, 16, "algorithm"], [18, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 6, "type-of", "", true, false], [5, 9, 6, 6, "named", "", false, false], [14, 16, 6, 6, "type-of", "", true, false], [18, 18, 14, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["NMF", "is", "an", "example", "of", "non-negative", "quadratic", "programming", "(", "NQP", ")", ",", "as", "is", "support", "vector", "machine", "(", "SVM", ")", "."], "sentence-detokenized": "NMF is an example of non-negative quadratic programming (NQP), as is support vector machine (SVM).", "token2charspan": [[0, 3], [4, 6], [7, 9], [10, 17], [18, 20], [21, 33], [34, 43], [44, 55], [56, 57], [57, 60], [60, 61], [61, 62], [63, 65], [66, 68], [69, 76], [77, 83], [84, 91], [92, 93], [93, 96], [96, 97], [97, 98]]}
{"doc_key": "ai-dev-320", "ner": [[8, 9, "misc"], [12, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 12, 15, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["The", "method", "is", "based", "on", "the", "estimation", "of", "conditional", "probabilities", ",", "using", "a", "non-parametric", "maximum", "likelihood", "method", ",", "which", "leads", "to", "a"], "sentence-detokenized": "The method is based on the estimation of conditional probabilities, using a non-parametric maximum likelihood method, which leads to a", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 26], [27, 37], [38, 40], [41, 52], [53, 66], [66, 67], [68, 73], [74, 75], [76, 90], [91, 98], [99, 109], [110, 116], [116, 117], [118, 123], [124, 129], [130, 132], [133, 134]]}
{"doc_key": "ai-dev-321", "ner": [[7, 7, "algorithm"], [9, 11, "algorithm"], [13, 16, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "basic", "concepts", "of", "spectral", "estimation", "are", "autocorrelation", ",", "multivariate", "Fourier", "transform", ",", "root", "mean", "square", "error", "and", "entropy", "."], "sentence-detokenized": "The basic concepts of spectral estimation are autocorrelation, multivariate Fourier transform, root mean square error and entropy.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 21], [22, 30], [31, 41], [42, 45], [46, 61], [61, 62], [63, 75], [76, 83], [84, 93], [93, 94], [95, 99], [100, 104], [105, 111], [112, 117], [118, 121], [122, 129], [129, 130]]}
{"doc_key": "ai-dev-322", "ner": [[0, 1, "algorithm"], [9, 9, "field"], [11, 11, "algorithm"], [13, 15, "algorithm"], [17, 18, "task"], [20, 20, "field"], [22, 22, "field"], [24, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 1, 9, 9, "part-of", "", false, false], [0, 1, 11, 11, "part-of", "", false, false], [0, 1, 13, 15, "part-of", "", false, false], [0, 1, 17, 18, "part-of", "", false, false], [0, 1, 20, 20, "part-of", "", false, false], [0, 1, 22, 22, "part-of", "", false, false], [0, 1, 24, 25, "part-of", "", false, false], [0, 1, 27, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Kernel", "methods", "have", "a", "wide", "range", "of", "applications", "including", "geostatistics", ",", "kriging", ",", "inverse", "distance", "weighting", ",", "3D", "reconstruction", ",", "bioinformatics", ",", "chemoinformatics", ",", "information", "extraction", "and", "handwriting", "recognition", "."], "sentence-detokenized": "Kernel methods have a wide range of applications including geostatistics, kriging, inverse distance weighting, 3D reconstruction, bioinformatics, chemoinformatics, information extraction and handwriting recognition.", "token2charspan": [[0, 6], [7, 14], [15, 19], [20, 21], [22, 26], [27, 32], [33, 35], [36, 48], [49, 58], [59, 72], [72, 73], [74, 81], [81, 82], [83, 90], [91, 99], [100, 109], [109, 110], [111, 113], [114, 128], [128, 129], [130, 144], [144, 145], [146, 162], [162, 163], [164, 175], [176, 186], [187, 190], [191, 202], [203, 214], [214, 215]]}
{"doc_key": "ai-dev-323", "ner": [[16, 19, "product"], [15, 21, "product"], [25, 25, "organisation"], [26, 30, "product"], [32, 32, "product"], [36, 37, "product"], [39, 41, "product"], [43, 45, "product"], [47, 49, "product"], [53, 54, "product"], [56, 57, "product"], [62, 67, "product"], [71, 73, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[16, 19, 36, 37, "compare", "", false, false], [16, 19, 39, 41, "compare", "", false, false], [16, 19, 43, 45, "compare", "", false, false], [16, 19, 47, 49, "compare", "", false, false], [16, 19, 53, 54, "compare", "", false, false], [16, 19, 56, 57, "compare", "", false, false], [16, 19, 62, 67, "compare", "", false, false], [16, 19, 71, 73, "compare", "", false, false], [15, 21, 16, 19, "named", "", false, false], [26, 30, 25, 25, "artifact", "", false, false], [26, 30, 36, 37, "compare", "", false, false], [26, 30, 39, 41, "compare", "", false, false], [26, 30, 43, 45, "compare", "", false, false], [26, 30, 47, 49, "compare", "", false, false], [26, 30, 53, 54, "compare", "", false, false], [26, 30, 56, 57, "compare", "", false, false], [26, 30, 62, 67, "compare", "", false, false], [26, 30, 71, 73, "compare", "", false, false], [32, 32, 26, 30, "named", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "sentence": ["Robots", "can", "be", "autonomous", "or", "semi-autonomous", "and", "range", "from", "humanoids", ",", "such", "as", "the", "Honda", "Advanced", "Step", "in", "Innovative", "Mobility", "(", "ASIMO", ")", "and", "the", "TOSY", "TOSY", "Ping", "Pong", "Playing", "Robot", "(", "TOPIO", ")", ",", "to", "industrial", "robots", ",", "medical", "surgical", "robots", ",", "patient", "assistance", "robots", ",", "dog", "therapy", "robots", ",", "collectively", "programmed", "robot", "swarms", ",", "UAV", "drones", ",", "such", "as", "the", "General", "Atomics", "MQ", "-", "1", "Predator", ",", "and", "even", "microscopic", "nano", "robots", "."], "sentence-detokenized": "Robots can be autonomous or semi-autonomous and range from humanoids, such as the Honda Advanced Step in Innovative Mobility (ASIMO) and the TOSY TOSY Ping Pong Playing Robot (TOPIO), to industrial robots, medical surgical robots, patient assistance robots, dog therapy robots, collectively programmed robot swarms, UAV drones, such as the General Atomics MQ-1 Predator, and even microscopic nano robots.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 24], [25, 27], [28, 43], [44, 47], [48, 53], [54, 58], [59, 68], [68, 69], [70, 74], [75, 77], [78, 81], [82, 87], [88, 96], [97, 101], [102, 104], [105, 115], [116, 124], [125, 126], [126, 131], [131, 132], [133, 136], [137, 140], [141, 145], [146, 150], [151, 155], [156, 160], [161, 168], [169, 174], [175, 176], [176, 181], [181, 182], [182, 183], [184, 186], [187, 197], [198, 204], [204, 205], [206, 213], [214, 222], [223, 229], [229, 230], [231, 238], [239, 249], [250, 256], [256, 257], [258, 261], [262, 269], [270, 276], [276, 277], [278, 290], [291, 301], [302, 307], [308, 314], [314, 315], [316, 319], [320, 326], [326, 327], [328, 332], [333, 335], [336, 339], [340, 347], [348, 355], [356, 358], [358, 359], [359, 360], [361, 369], [369, 370], [371, 374], [375, 379], [380, 391], [392, 396], [397, 403], [403, 404]]}
{"doc_key": "ai-dev-324", "ner": [[0, 0, "product"], [2, 3, "product"], [19, 27, "university"], [8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 8, 9, "artifact", "", false, false], [0, 0, 11, 12, "artifact", "", false, false], [0, 0, 14, 15, "artifact", "", false, false], [0, 0, 17, 18, "artifact", "", false, false], [2, 3, 8, 9, "artifact", "", false, false], [2, 3, 11, 12, "artifact", "", false, false], [2, 3, 14, 15, "artifact", "", false, false], [2, 3, 17, 18, "artifact", "", false, false], [8, 9, 19, 27, "physical", "", false, false], [11, 12, 19, 27, "physical", "", false, false], [14, 15, 19, 27, "physical", "", false, false], [17, 18, 19, 27, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Freddy", "and", "Freddy", "II", "were", "robots", "built", "by", "Pat", "Ambler", ",", "Robin", "Popplestone", ",", "Austin", "Tate", "and", "Donald", "Mitchie", "at", "the", "University", "of", "Edinburgh", "'s", "School", "of", "Computing", ",", "capable", "of", "assembling", "wooden", "blocks", "in", "several", "hours", "."], "sentence-detokenized": "Freddy and Freddy II were robots built by Pat Ambler, Robin Popplestone, Austin Tate and Donald Mitchie at the University of Edinburgh's School of Computing, capable of assembling wooden blocks in several hours.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 20], [21, 25], [26, 32], [33, 38], [39, 41], [42, 45], [46, 52], [52, 53], [54, 59], [60, 71], [71, 72], [73, 79], [80, 84], [85, 88], [89, 95], [96, 103], [104, 106], [107, 110], [111, 121], [122, 124], [125, 134], [134, 136], [137, 143], [144, 146], [147, 156], [156, 157], [158, 165], [166, 168], [169, 179], [180, 186], [187, 193], [194, 196], [197, 204], [205, 210], [210, 211]]}
{"doc_key": "ai-dev-325", "ner": [[6, 6, "location"], [8, 8, "country"], [15, 18, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 8, 8, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "spent", "his", "childhood", "years", "in", "Paris", ",", "France", ",", "where", "his", "parents", "had", "emigrated", "from", "Lithuania", "in", "the", "early", "1920s", "."], "sentence-detokenized": "He spent his childhood years in Paris, France, where his parents had emigrated from Lithuania in the early 1920s.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 22], [23, 28], [29, 31], [32, 37], [37, 38], [39, 45], [45, 46], [47, 52], [53, 56], [57, 64], [65, 68], [69, 78], [79, 83], [84, 93], [94, 96], [97, 100], [101, 106], [107, 112], [112, 113]]}
{"doc_key": "ai-dev-326", "ner": [[2, 3, "researcher"], [4, 9, "misc"], [13, 17, "organisation"], [10, 12, "university"], [26, 32, "university"], [41, 43, "university"], [46, 49, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 3, 4, 9, "role", "", false, false], [2, 3, 10, 12, "physical", "", false, false], [2, 3, 26, 32, "role", "", false, false], [2, 3, 41, 43, "role", "", false, false], [2, 3, 46, 49, "role", "", false, false], [4, 9, 13, 17, "part-of", "", false, false], [13, 17, 10, 12, "part-of", "", false, false], [41, 43, 26, 32, "part-of", "", false, false], [46, 49, 26, 32, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Previously", ",", "Dr.", "Paulos", "Cooper-Siegel", "was", "an", "Associate", "Professor", "at", "Carnegie", "Mellon", "University", "'s", "School", "of", "Computer", "Science", ",", "where", "he", "was", "a", "faculty", "member", "of", "the", "Institute", "for", "Human", "-", "Computer", "Interaction", ",", "who", "was", "also", "a", "faculty", "member", "of", "the", "Robotics", "Institute", "and", "the", "Center", "for", "Entertainment", "Technology", "."], "sentence-detokenized": "Previously, Dr. Paulos Cooper-Siegel was an Associate Professor at Carnegie Mellon University's School of Computer Science, where he was a faculty member of the Institute for Human-Computer Interaction, who was also a faculty member of the Robotics Institute and the Center for Entertainment Technology.", "token2charspan": [[0, 10], [10, 11], [12, 15], [16, 22], [23, 36], [37, 40], [41, 43], [44, 53], [54, 63], [64, 66], [67, 75], [76, 82], [83, 93], [93, 95], [96, 102], [103, 105], [106, 114], [115, 122], [122, 123], [124, 129], [130, 132], [133, 136], [137, 138], [139, 146], [147, 153], [154, 156], [157, 160], [161, 170], [171, 174], [175, 180], [180, 181], [181, 189], [190, 201], [201, 202], [203, 206], [207, 210], [211, 215], [216, 217], [218, 225], [226, 232], [233, 235], [236, 239], [240, 248], [249, 258], [259, 262], [263, 266], [267, 273], [274, 277], [278, 291], [292, 302], [302, 303]]}
{"doc_key": "ai-dev-327", "ner": [[3, 4, "researcher"], [5, 7, "university"], [10, 11, "product"], [18, 22, "product"], [26, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 5, 7, "physical", "", false, false], [3, 4, 5, 7, "role", "", false, false], [10, 11, 3, 4, "artifact", "", false, false], [10, 11, 18, 22, "type-of", "", false, false], [10, 11, 26, 27, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1969", ",", "Victor", "Scheinman", "at", "Stanford", "University", "invented", "the", "Stanford", "Arm", ",", "an", "all", "-", "electric", ",", "6", "-", "axis", "articulated", "robot", "designed", "to", "enable", "arm", "movement", "."], "sentence-detokenized": "In 1969, Victor Scheinman at Stanford University invented the Stanford Arm, an all-electric, 6-axis articulated robot designed to enable arm movement.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 25], [26, 28], [29, 37], [38, 48], [49, 57], [58, 61], [62, 70], [71, 74], [74, 75], [76, 78], [79, 82], [82, 83], [83, 91], [91, 92], [93, 94], [94, 95], [95, 99], [100, 111], [112, 117], [118, 126], [127, 129], [130, 136], [137, 140], [141, 149], [149, 150]]}
{"doc_key": "ai-dev-328", "ner": [[5, 6, "product"], [16, 17, "field"], [19, 20, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 16, 17, "related-to", "", false, false], [5, 6, 19, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "creation", "and", "implementation", "of", "conversational", "robots", "is", "still", "an", "evolving", "field", ",", "strongly", "linked", "to", "artificial", "intelligence", "and", "machine", "learning", ",", "which", "means", "that", "the", "proposed", "solutions", ",", "while", "having", "obvious", "advantages", ",", "have", "some", "important", "limitations", "in", "terms", "of", "functionality", "and", "use", "cases", "."], "sentence-detokenized": "The creation and implementation of conversational robots is still an evolving field, strongly linked to artificial intelligence and machine learning, which means that the proposed solutions, while having obvious advantages, have some important limitations in terms of functionality and use cases.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 31], [32, 34], [35, 49], [50, 56], [57, 59], [60, 65], [66, 68], [69, 77], [78, 83], [83, 84], [85, 93], [94, 100], [101, 103], [104, 114], [115, 127], [128, 131], [132, 139], [140, 148], [148, 149], [150, 155], [156, 161], [162, 166], [167, 170], [171, 179], [180, 189], [189, 190], [191, 196], [197, 203], [204, 211], [212, 222], [222, 223], [224, 228], [229, 233], [234, 243], [244, 255], [256, 258], [259, 264], [265, 267], [268, 281], [282, 285], [286, 289], [290, 295], [295, 296]]}
{"doc_key": "ai-dev-329", "ner": [[0, 1, "university"], [4, 5, "product"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 0, 1, "part-of", "", true, false], [17, 18, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Carnegie", "Mellon", "University", "'s", "Sphinx", "toolkit", "is", "one", "place", "to", "start", "both", "learning", "about", "and", "experimenting", "with", "speech", "recognition", "."], "sentence-detokenized": "Carnegie Mellon University's Sphinx toolkit is one place to start both learning about and experimenting with speech recognition.", "token2charspan": [[0, 8], [9, 15], [16, 26], [26, 28], [29, 35], [36, 43], [44, 46], [47, 50], [51, 56], [57, 59], [60, 65], [66, 70], [71, 79], [80, 85], [86, 89], [90, 103], [104, 108], [109, 115], [116, 127], [127, 128]]}
{"doc_key": "ai-dev-330", "ner": [[2, 3, "misc"], [13, 19, "misc"], [21, 21, "misc"], [26, 26, "university"], [27, 28, "location"], [30, 32, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 13, 19, "temporal", "", false, false], [21, 21, 13, 19, "named", "", false, false], [21, 21, 27, 28, "physical", "", false, false], [26, 26, 21, 21, "role", "", false, false], [27, 28, 30, 32, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "official", "RoboCup", "competition", "was", "preceded", "(", "often", "unrecognised", ")", "by", "the", "first", "international", "micro", "-robot", "world", "championship", "football", "tournament", "(", "MIROSOT", ")", ",", "organised", "by", "KAIST", "in", "Taejon", ",", "Korea", ",", "in", "November", "1996", "."], "sentence-detokenized": "The official RoboCup competition was preceded (often unrecognised) by the first international micro-robot world championship football tournament (MIROSOT), organised by KAIST in Taejon, Korea, in November 1996.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 32], [33, 36], [37, 45], [46, 47], [47, 52], [53, 65], [65, 66], [67, 69], [70, 73], [74, 79], [80, 93], [94, 99], [99, 105], [106, 111], [112, 124], [125, 133], [134, 144], [145, 146], [146, 153], [153, 154], [154, 155], [156, 165], [166, 168], [169, 174], [175, 177], [178, 184], [184, 185], [186, 191], [191, 192], [193, 195], [196, 204], [205, 209], [209, 210]]}
{"doc_key": "ai-dev-331", "ner": [[5, 7, "metrics"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", "to", "the", "standard", "joi", "nt", "loss", "math", "(", "1-", "yf", "(", "x", ")", ")", "_", "+", "/", "math", "for", "labeled", "data", ",", "the", "loss", "function", "math", "(", "-", "1", "|", "f", "(", "x", ")", "|", ")", "_", "+", "/", "math", "is", "introduced", "for", "unlabeled", "data", ",", "letting", "mathy", "=", "operator", "name", "{", "sign", "}", "{", "f", "(", "x", ")", "}", "/", "math", "."], "sentence-detokenized": "In addition to the standard joint loss math (1-yf (x)) _ + / math for labeled data, the loss function math (-1 | f (x) |) _ + / math is introduced for unlabeled data, letting mathy = operator name {sign} {f (x)} / math.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 27], [28, 31], [31, 33], [34, 38], [39, 43], [44, 45], [45, 47], [47, 49], [50, 51], [51, 52], [52, 53], [53, 54], [55, 56], [57, 58], [59, 60], [61, 65], [66, 69], [70, 77], [78, 82], [82, 83], [84, 87], [88, 92], [93, 101], [102, 106], [107, 108], [108, 109], [109, 110], [111, 112], [113, 114], [115, 116], [116, 117], [117, 118], [119, 120], [120, 121], [122, 123], [124, 125], [126, 127], [128, 132], [133, 135], [136, 146], [147, 150], [151, 160], [161, 165], [165, 166], [167, 174], [175, 180], [181, 182], [183, 191], [192, 196], [197, 198], [198, 202], [202, 203], [204, 205], [205, 206], [207, 208], [208, 209], [209, 210], [210, 211], [212, 213], [214, 218], [218, 219]]}
{"doc_key": "ai-dev-332", "ner": [[0, 5, "misc"], [10, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 5, 10, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "particular", ",", "the", "RLS", "is", "designed", "to", "reduce", "the", "standard", "error", "of", "the", "mean", "squared", "error", "between", "the", "predicted", "values", "and", "the", "true", "signs", ",", "if", "regulated", "."], "sentence-detokenized": "In particular, the RLS is designed to reduce the standard error of the mean squared error between the predicted values and the true signs, if regulated.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 22], [23, 25], [26, 34], [35, 37], [38, 44], [45, 48], [49, 57], [58, 63], [64, 66], [67, 70], [71, 75], [76, 83], [84, 89], [90, 97], [98, 101], [102, 111], [112, 118], [119, 122], [123, 126], [127, 131], [132, 137], [137, 138], [139, 141], [142, 151], [151, 152]]}
{"doc_key": "ai-dev-333", "ner": [[5, 7, "algorithm"], [8, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 8, 11, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "essence", ",", "it", "combines", "maximum", "likelihood", "estimation", "with", "a", "regularisation", "procedure", "that", "favours", "simpler", "models", "over", "more", "complex", "ones", "."], "sentence-detokenized": "In essence, it combines maximum likelihood estimation with a regularisation procedure that favours simpler models over more complex ones.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 14], [15, 23], [24, 31], [32, 42], [43, 53], [54, 58], [59, 60], [61, 75], [76, 85], [86, 90], [91, 98], [99, 106], [107, 113], [114, 118], [119, 123], [124, 131], [132, 136], [136, 137]]}
{"doc_key": "ai-dev-334", "ner": [[0, 5, "metrics"], [11, 11, "metrics"], [13, 13, "metrics"], [16, 18, "misc"], [19, 25, "misc"], [38, 53, "algorithm"], [42, 52, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 11, 0, 5, "named", "", false, false], [13, 13, 0, 5, "named", "", false, false], [16, 18, 19, 25, "related-to", "", false, false], [16, 18, 38, 53, "related-to", "ratio", false, false], [38, 53, 42, 52, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "true", "-", "positive", "detection", "rate", "is", "also", "known", "as", "the", "sensitivity", ",", "recall", ",", "or", "probability", "of", "detection", "with", "respect", "to", "the", "mathematical", "discrimination", "threshold", ")", "on", "the", "y", "-axis", "of", "the", "probability", "of", "detection", "and", "the", "cumulative", "distribution", "of", "the", "probability", "of", "false", "alarm", "on", "the", "x-", "axis", "of", "the", "probability", "function", "."], "sentence-detokenized": "The true-positive detection rate is also known as the sensitivity, recall, or probability of detection with respect to the mathematical discrimination threshold) on the y-axis of the probability of detection and the cumulative distribution of the probability of false alarm on the x-axis of the probability function.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 17], [18, 27], [28, 32], [33, 35], [36, 40], [41, 46], [47, 49], [50, 53], [54, 65], [65, 66], [67, 73], [73, 74], [75, 77], [78, 89], [90, 92], [93, 102], [103, 107], [108, 115], [116, 118], [119, 122], [123, 135], [136, 150], [151, 160], [160, 161], [162, 164], [165, 168], [169, 170], [170, 175], [176, 178], [179, 182], [183, 194], [195, 197], [198, 207], [208, 211], [212, 215], [216, 226], [227, 239], [240, 242], [243, 246], [247, 258], [259, 261], [262, 267], [268, 273], [274, 276], [277, 280], [281, 283], [283, 287], [288, 290], [291, 294], [295, 306], [307, 315], [315, 316]]}
{"doc_key": "ai-dev-335", "ner": [[0, 1, "misc"], [3, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 0, 1, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "English", ",", "Word", "Net", "is", "an", "example", "of", "a", "semantic", "network", "."], "sentence-detokenized": "In English, WordNet is an example of a semantic network.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 16], [16, 19], [20, 22], [23, 25], [26, 33], [34, 36], [37, 38], [39, 47], [48, 55], [55, 56]]}
{"doc_key": "ai-dev-336", "ner": [[6, 8, "product"], [12, 14, "product"], [28, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[28, 28, 6, 8, "usage", "", false, false], [28, 28, 12, 14, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "use", "of", "long", "-", "term", "speech", "recognition", "software", "in", "combination", "with", "a", "word", "processor", "has", "been", "shown", "to", "be", "beneficial", "in", "strengthening", "short", "-", "term", "memory", "in", "AVM", "patients", "treated", "with", "resection", "."], "sentence-detokenized": "The use of long-term speech recognition software in combination with a word processor has been shown to be beneficial in strengthening short-term memory in AVM patients treated with resection.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 15], [15, 16], [16, 20], [21, 27], [28, 39], [40, 48], [49, 51], [52, 63], [64, 68], [69, 70], [71, 75], [76, 85], [86, 89], [90, 94], [95, 100], [101, 103], [104, 106], [107, 117], [118, 120], [121, 134], [135, 140], [140, 141], [141, 145], [146, 152], [153, 155], [156, 159], [160, 168], [169, 176], [177, 181], [182, 191], [191, 192]]}
{"doc_key": "ai-dev-337", "ner": [[7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "editors", "-", "in", "-", "chief", "were", "Ron", "Sun", ",", "Vasant", "Honavar", "and", "Gregg", "Oden", "(", "1999-2014", ")", "."], "sentence-detokenized": "The editors-in-chief were Ron Sun, Vasant Honavar and Gregg Oden (1999-2014).", "token2charspan": [[0, 3], [4, 11], [11, 12], [12, 14], [14, 15], [15, 20], [21, 25], [26, 29], [30, 33], [33, 34], [35, 41], [42, 49], [50, 53], [54, 59], [60, 64], [65, 66], [66, 75], [75, 76], [76, 77]]}
{"doc_key": "ai-dev-338", "ner": [[5, 7, "product"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 11, 12, "opposite", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Their", "\"", "parallel", "\"", "difference", "from", "series", "manipulators", "is", "that", "the", "end", "actuator", "(", "or", "\"", "arm", "\"", ")", "of", "this", "linkage", "(", "or", "\"", "hand", "\"", ")", "is", "directly", "connected", "to", "its", "base", "by", "means", "of", "several", "(", "usually", "three", "or", "six", ")", "separate", "and", "independent", "linkages", "operating", "simultaneously", "."], "sentence-detokenized": "Their \"parallel\" difference from series manipulators is that the end actuator (or \"arm\") of this linkage (or \"hand\") is directly connected to its base by means of several (usually three or six) separate and independent linkages operating simultaneously.", "token2charspan": [[0, 5], [6, 7], [7, 15], [15, 16], [17, 27], [28, 32], [33, 39], [40, 52], [53, 55], [56, 60], [61, 64], [65, 68], [69, 77], [78, 79], [79, 81], [82, 83], [83, 86], [86, 87], [87, 88], [89, 91], [92, 96], [97, 104], [105, 106], [106, 108], [109, 110], [110, 114], [114, 115], [115, 116], [117, 119], [120, 128], [129, 138], [139, 141], [142, 145], [146, 150], [151, 153], [154, 159], [160, 162], [163, 170], [171, 172], [172, 179], [180, 185], [186, 188], [189, 192], [192, 193], [194, 202], [203, 206], [207, 218], [219, 227], [228, 237], [238, 252], [252, 253]]}
{"doc_key": "ai-dev-339", "ner": [[5, 6, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 23, "researcher"], [25, 26, "researcher"], [28, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "thesis", "supervisor", "was", "Professor", "Cordell", "Green", ",", "and", "his", "thesis", "/", "oral", "committee", "included", "Professors", "Edward", "Feigenbaum", ",", "Joshua", "Lederberg", ",", "Paul", "Cohen", ",", "Allen", "Newell", ",", "Herbert", "Simon", ",", "."], "sentence-detokenized": "His thesis supervisor was Professor Cordell Green, and his thesis/oral committee included Professors Edward Feigenbaum, Joshua Lederberg, Paul Cohen, Allen Newell, Herbert Simon,.", "token2charspan": [[0, 3], [4, 10], [11, 21], [22, 25], [26, 35], [36, 43], [44, 49], [49, 50], [51, 54], [55, 58], [59, 65], [65, 66], [66, 70], [71, 80], [81, 89], [90, 100], [101, 107], [108, 118], [118, 119], [120, 126], [127, 136], [136, 137], [138, 142], [143, 148], [148, 149], [150, 155], [156, 162], [162, 163], [164, 171], [172, 177], [177, 178], [178, 179]]}
{"doc_key": "ai-dev-340", "ner": [[3, 5, "metrics"], [7, 9, "metrics"], [11, 13, "metrics"], [15, 17, "metrics"], [19, 21, "metrics"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "functions", "include", "mean", "squared", "error", ",", "mean", "squared", "error", ",", "mean", "absolute", "error", ",", "relative", "squared", "error", ",", "relative", "squared", "error", ",", "relative", "absolute", "error", "and", "others", "."], "sentence-detokenized": "Such functions include mean squared error, mean squared error, mean absolute error, relative squared error, relative squared error, relative absolute error and others.", "token2charspan": [[0, 4], [5, 14], [15, 22], [23, 27], [28, 35], [36, 41], [41, 42], [43, 47], [48, 55], [56, 61], [61, 62], [63, 67], [68, 76], [77, 82], [82, 83], [84, 92], [93, 100], [101, 106], [106, 107], [108, 116], [117, 124], [125, 130], [130, 131], [132, 140], [141, 149], [150, 155], [156, 159], [160, 166], [166, 167]]}
{"doc_key": "ai-dev-341", "ner": [[0, 2, "programlang"], [4, 4, "programlang"], [6, 6, "product"], [8, 8, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "Python", ",", "Java", "and", "MATLAB", "/", "OCTAVE", "bindings", "."], "sentence-detokenized": "There are Python, Java and MATLAB / OCTAVE bindings.", "token2charspan": [[0, 5], [6, 9], [10, 16], [16, 17], [18, 22], [23, 26], [27, 33], [34, 35], [36, 42], [43, 51], [51, 52]]}
{"doc_key": "ai-dev-342", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "MATLAB", "application", "can", "be", "found", "at", "."], "sentence-detokenized": "The MATLAB application can be found at.", "token2charspan": [[0, 3], [4, 10], [11, 22], [23, 26], [27, 29], [30, 35], [36, 38], [38, 39]]}
{"doc_key": "ai-dev-343", "ner": [[0, 1, "researcher"], [24, 25, "field"], [5, 6, "researcher"], [8, 9, "researcher"], [11, 12, "researcher"], [14, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[24, 25, 0, 1, "origin", "", false, false], [24, 25, 5, 6, "origin", "", false, false], [24, 25, 8, 9, "origin", "", false, false], [24, 25, 11, 12, "origin", "", false, false], [24, 25, 14, 21, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["John", "McCarthy", ",", "along", "with", "Alan", "Turing", ",", "Marvin", "Minsky", ",", "Allen", "Newell", "and", "Herbert", "A", ".", "Simon", ",", "one", "of", "the", "founders", "of", "artificial", "intelligence", "."], "sentence-detokenized": "John McCarthy, along with Alan Turing, Marvin Minsky, Allen Newell and Herbert A. Simon, one of the founders of artificial intelligence.", "token2charspan": [[0, 4], [5, 13], [13, 14], [15, 20], [21, 25], [26, 30], [31, 37], [37, 38], [39, 45], [46, 52], [52, 53], [54, 59], [60, 66], [67, 70], [71, 78], [79, 80], [80, 81], [82, 87], [87, 88], [89, 92], [93, 95], [96, 99], [100, 108], [109, 111], [112, 122], [123, 135], [135, 136]]}
{"doc_key": "ai-dev-344", "ner": [[10, 11, "product"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "parallel", "manipulator", "is", "a", "mechanical", "system", "that", "uses", "multiple", "sequential", "manipulators", "to", "support", "a", "single", "platform", "or", "end", "structure", "."], "sentence-detokenized": "A parallel manipulator is a mechanical system that uses multiple sequential manipulators to support a single platform or end structure.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 27], [28, 38], [39, 45], [46, 50], [51, 55], [56, 64], [65, 75], [76, 88], [89, 91], [92, 99], [100, 101], [102, 108], [109, 117], [118, 120], [121, 124], [125, 134], [134, 135]]}
{"doc_key": "ai-dev-345", "ner": [[0, 0, "product"], [3, 4, "task"], [6, 6, "product"], [8, 14, "product"], [25, 26, "misc"], [29, 29, "misc"], [32, 33, "misc"], [36, 41, "task"], [44, 47, "product"], [50, 51, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[6, 6, 0, 0, "part-of", "", false, false], [6, 6, 3, 4, "type-of", "", false, false], [8, 14, 6, 6, "named", "", false, false], [25, 26, 6, 6, "part-of", "", false, false], [29, 29, 6, 6, "part-of", "", false, false], [32, 33, 6, 6, "part-of", "", false, false], [36, 41, 6, 6, "part-of", "", false, false], [44, 47, 6, 6, "part-of", "", false, false], [50, 51, 6, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["GATE", "includes", "the", "information", "extraction", "system", "ANNIE", "(", "A", "Nearly", "-", "New", "Information", "Extraction", "System", ")", ",", "which", "is", "a", "set", "of", "modules", "consisting", "of", "a", "tokenizer", ",", "a", "gazetteer", ",", "a", "sentence", "splitter", ",", "a", "part", "-", "of", "-", "speech", "tagger", ",", "a", "named", "entity", "recognition", "transducer", "and", "a", "coreference", "tagger", "."], "sentence-detokenized": "GATE includes the information extraction system ANNIE (A Nearly-New Information Extraction System), which is a set of modules consisting of a tokenizer, a gazetteer, a sentence splitter, a part-of-speech tagger, a named entity recognition transducer and a coreference tagger.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 29], [30, 40], [41, 47], [48, 53], [54, 55], [55, 56], [57, 63], [63, 64], [64, 67], [68, 79], [80, 90], [91, 97], [97, 98], [98, 99], [100, 105], [106, 108], [109, 110], [111, 114], [115, 117], [118, 125], [126, 136], [137, 139], [140, 141], [142, 151], [151, 152], [153, 154], [155, 164], [164, 165], [166, 167], [168, 176], [177, 185], [185, 186], [187, 188], [189, 193], [193, 194], [194, 196], [196, 197], [197, 203], [204, 210], [210, 211], [212, 213], [214, 219], [220, 226], [227, 238], [239, 249], [250, 253], [254, 255], [256, 267], [268, 274], [274, 275]]}
{"doc_key": "ai-dev-346", "ner": [[3, 5, "university"], [9, 18, "country"], [22, 25, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "graduated", "from", "Moscow", "State", "University", "and", "left", "for", "the", "United", "States", "in", "November", "1978", ",", "thanks", "to", "the", "personal", "intervention", "of", "Senator", "Edward", "M.", "Kennedy", "."], "sentence-detokenized": "He graduated from Moscow State University and left for the United States in November 1978, thanks to the personal intervention of Senator Edward M. Kennedy.", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 24], [25, 30], [31, 41], [42, 45], [46, 50], [51, 54], [55, 58], [59, 65], [66, 72], [73, 75], [76, 84], [85, 89], [89, 90], [91, 97], [98, 100], [101, 104], [105, 113], [114, 126], [127, 129], [130, 137], [138, 144], [145, 147], [148, 155], [155, 156]]}
{"doc_key": "ai-dev-347", "ner": [[3, 6, "organisation"], [9, 13, "misc"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 6, 9, 13, "win-defeat", "", false, false], [9, 13, 18, 19, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2017", ",", "DeepMind", "'s", "AlphaGo", "team", "received", "the", "first", "IJCAI", "Marvin", "Minsky", "Medal", "for", "outstanding", "achievements", "in", "artificial", "intelligence", "."], "sentence-detokenized": "In 2017, DeepMind's AlphaGo team received the first IJCAI Marvin Minsky Medal for outstanding achievements in artificial intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 17], [17, 19], [20, 27], [28, 32], [33, 41], [42, 45], [46, 51], [52, 57], [58, 64], [65, 71], [72, 77], [78, 81], [82, 93], [94, 106], [107, 109], [110, 120], [121, 133], [133, 134]]}
{"doc_key": "ai-dev-348", "ner": [[4, 5, "misc"], [9, 9, "misc"], [10, 12, "misc"], [21, 22, "misc"], [24, 24, "misc"], [29, 31, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 9, 9, "related-to", "is_recorded_by", false, false], [9, 9, 10, 12, "cause-effect", "", false, false], [9, 9, 10, 12, "physical", "", false, false], [9, 9, 21, 22, "physical", "", false, false], [9, 9, 29, 31, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "ways", "in", "which", "anomalous", "propagation", "is", "recorded", "are", "tropospheric", "scattering", "by", "tropospheric", "irregularities", ",", "scattering", "by", "meteors", ",", "refraction", "in", "ionised", "regions", "and", "ionospheric", "layers", ",", "and", "reflection", "from", "the", "ionosphere", "."], "sentence-detokenized": "Other ways in which anomalous propagation is recorded are tropospheric scattering by tropospheric irregularities, scattering by meteors, refraction in ionised regions and ionospheric layers, and reflection from the ionosphere.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 19], [20, 29], [30, 41], [42, 44], [45, 53], [54, 57], [58, 70], [71, 81], [82, 84], [85, 97], [98, 112], [112, 113], [114, 124], [125, 127], [128, 135], [135, 136], [137, 147], [148, 150], [151, 158], [159, 166], [167, 170], [171, 182], [183, 189], [189, 190], [191, 194], [195, 205], [206, 210], [211, 214], [215, 225], [225, 226]]}
{"doc_key": "ai-dev-349", "ner": [[2, 2, "field"], [0, 4, "field"], [10, 10, "field"], [12, 13, "field"], [15, 16, "field"], [18, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 10, 10, "part-of", "", false, false], [2, 2, 12, 13, "part-of", "", false, false], [2, 2, 15, 16, "part-of", "", false, false], [2, 2, 18, 20, "part-of", "", false, false], [0, 4, 2, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Natural", "language", "processing", "(", "NLP", ")", "is", "a", "subfield", "of", "linguistics", ",", "computer", "science", ",", "information", "technology", "and", "artificial", "intelligence", "that", "deals", "with", "the", "interaction", "between", "computers", "and", "human", "(", "natural", ")", "languages", ",", "in", "particular", "how", "to", "program", "computers", "to", "process", "and", "analyse", "large", "amounts", "of", "natural", "language", "data", "."], "sentence-detokenized": "Natural language processing (NLP) is a subfield of linguistics, computer science, information technology and artificial intelligence that deals with the interaction between computers and human (natural) languages, in particular how to program computers to process and analyse large amounts of natural language data.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 29], [29, 32], [32, 33], [34, 36], [37, 38], [39, 47], [48, 50], [51, 62], [62, 63], [64, 72], [73, 80], [80, 81], [82, 93], [94, 104], [105, 108], [109, 119], [120, 132], [133, 137], [138, 143], [144, 148], [149, 152], [153, 164], [165, 172], [173, 182], [183, 186], [187, 192], [193, 194], [194, 201], [201, 202], [203, 212], [212, 213], [214, 216], [217, 227], [228, 231], [232, 234], [235, 242], [243, 252], [253, 255], [256, 263], [264, 267], [268, 275], [276, 281], [282, 289], [290, 292], [293, 300], [301, 309], [310, 314], [314, 315]]}
{"doc_key": "ai-dev-350", "ner": [[8, 9, "organisation"], [12, 13, "organisation"], [15, 16, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "active", "youth", "-", "led", "climate", "groups", "include", "Extinction", "Rebellion", ",", "the", "Sunrise", "Movement", ",", "SustainUS", "and", "others", ",", "which", "are", "active", "both", "internationally", "and", "locally", "."], "sentence-detokenized": "Other active youth-led climate groups include Extinction Rebellion, the Sunrise Movement, SustainUS and others, which are active both internationally and locally.", "token2charspan": [[0, 5], [6, 12], [13, 18], [18, 19], [19, 22], [23, 30], [31, 37], [38, 45], [46, 56], [57, 66], [66, 67], [68, 71], [72, 79], [80, 88], [88, 89], [90, 99], [100, 103], [104, 110], [110, 111], [112, 117], [118, 121], [122, 128], [129, 133], [134, 149], [150, 153], [154, 161], [161, 162]]}
