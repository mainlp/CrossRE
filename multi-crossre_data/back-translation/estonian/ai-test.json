{"doc_key": "ai-test-1", "ner": [[4, 6, "algorithm"], [8, 8, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "generative", "models", "include", "na\u00efve", "Bayes", "classifiers", ",", "Gaussian", "mixture", "models", ",", "variational", "autocoders", "and", "others", "."], "sentence-detokenized": "Typical generative models include na\u00efve Bayes classifiers, Gaussian mixture models, variational autocoders and others.", "token2charspan": [[0, 7], [8, 18], [19, 25], [26, 33], [34, 39], [40, 45], [46, 57], [57, 58], [59, 67], [68, 75], [76, 82], [82, 83], [84, 95], [96, 106], [107, 110], [111, 117], [117, 118]]}
{"doc_key": "ai-test-2", "ner": [[0, 0, "organisation"], [4, 4, "conference"], [6, 11, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "role", "", false, false], [6, 11, 4, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["ELRA", "organises", "a", "major", "LREC", "(", "International", "Language", "Resources", "and", "Evaluation", "Conference", ")", "every", "other", "year", "."], "sentence-detokenized": "ELRA organises a major LREC (International Language Resources and Evaluation Conference) every other year.", "token2charspan": [[0, 4], [5, 14], [15, 16], [17, 22], [23, 27], [28, 29], [29, 42], [43, 51], [52, 61], [62, 65], [66, 76], [77, 87], [87, 88], [89, 94], [95, 100], [101, 105], [105, 106]]}
{"doc_key": "ai-test-3", "ner": [[8, 12, "algorithm"], [13, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typically", ",", "the", "task", "is", "to", "derive", "a", "maximum", "likelihood", "estimate", "of", "the", "HMM", "parameters", "given", "the", "output", "sequences", "."], "sentence-detokenized": "Typically, the task is to derive a maximum likelihood estimate of the HMM parameters given the output sequences.", "token2charspan": [[0, 9], [9, 10], [11, 14], [15, 19], [20, 22], [23, 25], [26, 32], [33, 34], [35, 42], [43, 53], [54, 62], [63, 65], [66, 69], [70, 73], [74, 84], [85, 90], [91, 94], [95, 101], [102, 111], [111, 112]]}
{"doc_key": "ai-test-4", "ner": [[4, 8, "algorithm"], [9, 9, "algorithm"]], "ner_mapping_to_source": [1, 2], "relations": [[4, 8, 9, 9, "compare", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Unlike", "neural", "networks", "and", "support", "vector", "machines", ",", "the", "AdaBoost", "training", "process", "selects", "only", "those", "features", "that", "are", "known", "to", "improve", "the", "predictive", "power", "of", "the", "model", ",", "reducing", "the", "number", "of", "dimensions", "and", "potentially", "improving", "the", "execution", "time", ",", "as", "irrelevant", "features", "do", "not", "need", "to", "be", "computed", "."], "sentence-detokenized": "Unlike neural networks and support vector machines, the AdaBoost training process selects only those features that are known to improve the predictive power of the model, reducing the number of dimensions and potentially improving the execution time, as irrelevant features do not need to be computed.", "token2charspan": [[0, 6], [7, 13], [14, 22], [23, 26], [27, 34], [35, 41], [42, 50], [50, 51], [52, 55], [56, 64], [65, 73], [74, 81], [82, 89], [90, 94], [95, 100], [101, 109], [110, 114], [115, 118], [119, 124], [125, 127], [128, 135], [136, 139], [140, 150], [151, 156], [157, 159], [160, 163], [164, 169], [169, 170], [171, 179], [180, 183], [184, 190], [191, 193], [194, 204], [205, 208], [209, 220], [221, 230], [231, 234], [235, 244], [245, 249], [249, 250], [251, 253], [254, 264], [265, 273], [274, 276], [277, 280], [281, 285], [286, 288], [289, 291], [292, 300], [300, 301]]}
{"doc_key": "ai-test-5", "ner": [[0, 0, "misc"], [13, 13, "misc"], [11, 12, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 13, 13, "part-of", "", false, false], [13, 13, 11, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Troponymy", "is", "one", "of", "the", "possible", "associations", "between", "verbs", "in", "the", "Word", "Net", "semantic", "network", "."], "sentence-detokenized": "Troponymy is one of the possible associations between verbs in the WordNet semantic network.", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 19], [20, 23], [24, 32], [33, 45], [46, 53], [54, 59], [60, 62], [63, 66], [67, 71], [71, 74], [75, 83], [84, 91], [91, 92]]}
{"doc_key": "ai-test-6", "ner": [[7, 11, "task"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 11, 9, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "Framework", "Language", "is", "a", "technology", "used", "to", "represent", "artificial", "intelligence", "knowledge", "."], "sentence-detokenized": "A Framework Language is a technology used to represent artificial intelligence knowledge.", "token2charspan": [[0, 1], [2, 11], [12, 20], [21, 23], [24, 25], [26, 36], [37, 41], [42, 44], [45, 54], [55, 65], [66, 78], [79, 88], [88, 89]]}
{"doc_key": "ai-test-7", "ner": [[0, 0, "metrics"], [4, 7, "metrics"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 7, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "the", "bilingual", "evaluation", "survey", "in", "the", "way", "it", "calculates", "the", "brevity", "penalty", ",", "as", "small", "differences", "in", "translation", "length", "do", "not", "affect", "the", "overall", "score", "as", "much", "."], "sentence-detokenized": "NIST also differs from the bilingual evaluation survey in the way it calculates the brevity penalty, as small differences in translation length do not affect the overall score as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 26], [27, 36], [37, 47], [48, 54], [55, 57], [58, 61], [62, 65], [66, 68], [69, 79], [80, 83], [84, 91], [92, 99], [99, 100], [101, 103], [104, 109], [110, 121], [122, 124], [125, 136], [137, 143], [144, 146], [147, 150], [151, 157], [158, 161], [162, 169], [170, 175], [176, 178], [179, 183], [183, 184]]}
{"doc_key": "ai-test-8", "ner": [[14, 16, "algorithm"], [19, 21, "algorithm"], [31, 31, "field"], [40, 41, "algorithm"], [43, 45, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 16, 31, 31, "usage", "", false, false], [19, 21, 31, 31, "usage", "", false, false], [40, 41, 31, 31, "type-of", "", false, false], [43, 45, 31, 31, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "model", "is", "initially", "adapted", "to", "the", "training", "dataset", ",", "The", "model", "(", "e.g.", "a", "neural", "network", "or", "a", "naive", "Bayes", "classifier", ")", "is", "trained", "on", "the", "training", "dataset", "using", "a", "supervised", "learning", "method", ",", "such", "as", "optimization", "methods", "like", "gradient", "descent", "or", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The model is initially adapted to the training dataset, The model (e.g. a neural network or a naive Bayes classifier) is trained on the training dataset using a supervised learning method, such as optimization methods like gradient descent or stochastic gradient descent.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 22], [23, 30], [31, 33], [34, 37], [38, 46], [47, 54], [54, 55], [56, 59], [60, 65], [66, 67], [67, 71], [72, 73], [74, 80], [81, 88], [89, 91], [92, 93], [94, 99], [100, 105], [106, 116], [116, 117], [118, 120], [121, 128], [129, 131], [132, 135], [136, 144], [145, 152], [153, 158], [159, 160], [161, 171], [172, 180], [181, 187], [187, 188], [189, 193], [194, 196], [197, 209], [210, 217], [218, 222], [223, 231], [232, 239], [240, 242], [243, 253], [254, 262], [263, 270], [270, 271]]}
{"doc_key": "ai-test-9", "ner": [[0, 0, "product"], [8, 9, "task"], [11, 11, "task"], [13, 15, "task"], [17, 18, "task"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 0, "usage", "", true, false], [11, 11, 0, 0, "usage", "", true, false], [13, 15, 0, 0, "usage", "", true, false], [17, 18, 0, 0, "usage", "", true, false], [24, 26, 0, 0, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["FrameNet", "has", "been", "used", "in", "applications", "such", "as", "question", "answering", ",", "paraphrasing", ",", "textual", "inference", "recognition", "and", "information", "extraction", ",", "either", "directly", "or", "through", "semantic", "role", "labelling", "tools", "."], "sentence-detokenized": "FrameNet has been used in applications such as question answering, paraphrasing, textual inference recognition and information extraction, either directly or through semantic role labelling tools.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 22], [23, 25], [26, 38], [39, 43], [44, 46], [47, 55], [56, 65], [65, 66], [67, 79], [79, 80], [81, 88], [89, 98], [99, 110], [111, 114], [115, 126], [127, 137], [137, 138], [139, 145], [146, 154], [155, 157], [158, 165], [166, 174], [175, 179], [180, 189], [190, 195], [195, 196]]}
{"doc_key": "ai-test-10", "ner": [[5, 6, "field"], [11, 11, "misc"], [14, 14, "product"], [17, 17, "misc"], [20, 20, "product"], [23, 24, "field"], [27, 27, "product"], [30, 32, "misc"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [42, 43, "misc"], [46, 47, "product"], [49, 50, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[14, 14, 11, 11, "general-affiliation", "", false, false], [20, 20, 17, 17, "general-affiliation", "", false, false], [27, 27, 23, 24, "general-affiliation", "", false, false], [35, 35, 30, 32, "type-of", "", false, false], [37, 37, 30, 32, "type-of", "", false, false], [39, 39, 30, 32, "type-of", "", false, false], [46, 47, 42, 43, "general-affiliation", "", false, false], [49, 50, 42, 43, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["This", "includes", "programs", "such", "as", "data", "analysis", "and", "extraction", "tools", ",", "spreadsheets", "(", "e.g.", "Excel", ")", ",", "databases", "(", "e.g.", "Access", ")", ",", "statistical", "analysis", "(", "e.g.", "SAS", ")", ",", "generalised", "audit", "software", "(", "e.g.", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "business", "intelligence", "(", "e.g.", "Crystal", "Reports", "and", "Business", "Objects", ")", ",", "etc", "."], "sentence-detokenized": "This includes programs such as data analysis and extraction tools, spreadsheets (e.g. Excel), databases (e.g. Access), statistical analysis (e.g. SAS), generalised audit software (e.g. ACL, Arbutus, EAS), business intelligence (e.g. Crystal Reports and Business Objects), etc.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 27], [28, 30], [31, 35], [36, 44], [45, 48], [49, 59], [60, 65], [65, 66], [67, 79], [80, 81], [81, 85], [86, 91], [91, 92], [92, 93], [94, 103], [104, 105], [105, 109], [110, 116], [116, 117], [117, 118], [119, 130], [131, 139], [140, 141], [141, 145], [146, 149], [149, 150], [150, 151], [152, 163], [164, 169], [170, 178], [179, 180], [180, 184], [185, 188], [188, 189], [190, 197], [197, 198], [199, 202], [202, 203], [203, 204], [205, 213], [214, 226], [227, 228], [228, 232], [233, 240], [241, 248], [249, 252], [253, 261], [262, 269], [269, 270], [270, 271], [272, 275], [275, 276]]}
{"doc_key": "ai-test-11", "ner": [[0, 1, "organisation"], [5, 6, "researcher"], [12, 12, "organisation"], [15, 16, "product"], [21, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 6, "origin", "", false, false], [5, 6, 12, 12, "role", "", false, false], [15, 16, 21, 22, "type-of", "", false, false], [21, 22, 5, 6, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Rethink", "Robotics", "-", "founded", "by", "Rodney", "Brooks", ",", "who", "previously", "worked", "on", "iRobot", "-", "introduced", "Baxter", "in", "September", "2012", ",", "an", "industrial", "robot", "designed", "to", "safely", "interact", "with", "people", "working", "in", "the", "neighbourhood", "and", "programmable", "to", "perform", "simple", "tasks", "."], "sentence-detokenized": "Rethink Robotics - founded by Rodney Brooks, who previously worked on iRobot - introduced Baxter in September 2012, an industrial robot designed to safely interact with people working in the neighbourhood and programmable to perform simple tasks.", "token2charspan": [[0, 7], [8, 16], [17, 18], [19, 26], [27, 29], [30, 36], [37, 43], [43, 44], [45, 48], [49, 59], [60, 66], [67, 69], [70, 76], [77, 78], [79, 89], [90, 96], [97, 99], [100, 109], [110, 114], [114, 115], [116, 118], [119, 129], [130, 135], [136, 144], [145, 147], [148, 154], [155, 163], [164, 168], [169, 175], [176, 183], [184, 186], [187, 190], [191, 204], [205, 208], [209, 221], [222, 224], [225, 232], [233, 239], [240, 245], [245, 246]]}
{"doc_key": "ai-test-12", "ner": [[5, 6, "task"], [8, 9, "task"], [11, 14, "task"], [16, 17, "task"], [19, 20, "task"], [22, 23, "task"], [25, 27, "task"], [34, 35, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "text", "mining", "tasks", "include", "text", "categorisation", ",", "text", "grouping", ",", "concept", "/", "entity", "extraction", ",", "granular", "taxonomies", ",", "cognitive", "analysis", ",", "document", "summarisation", "and", "entity", "relationship", "modelling", "(", "i.e.", "learning", "the", "relationships", "between", "named", "entities", ")", "."], "sentence-detokenized": "Typical text mining tasks include text categorisation, text grouping, concept/entity extraction, granular taxonomies, cognitive analysis, document summarisation and entity relationship modelling (i.e. learning the relationships between named entities).", "token2charspan": [[0, 7], [8, 12], [13, 19], [20, 25], [26, 33], [34, 38], [39, 53], [53, 54], [55, 59], [60, 68], [68, 69], [70, 77], [77, 78], [78, 84], [85, 95], [95, 96], [97, 105], [106, 116], [116, 117], [118, 127], [128, 136], [136, 137], [138, 146], [147, 160], [161, 164], [165, 171], [172, 184], [185, 194], [195, 196], [196, 200], [201, 209], [210, 213], [214, 227], [228, 235], [236, 241], [242, 250], [250, 251], [251, 252]]}
{"doc_key": "ai-test-13", "ner": [[3, 3, "metrics"], [6, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nevertheless", ",", "the", "accuracy", ",", "or", "true", "negative", "rate", ",", "of", "such", "systems", "is", "reduced", "."], "sentence-detokenized": "Nevertheless, the accuracy, or true negative rate, of such systems is reduced.", "token2charspan": [[0, 12], [12, 13], [14, 17], [18, 26], [26, 27], [28, 30], [31, 35], [36, 44], [45, 49], [49, 50], [51, 53], [54, 58], [59, 66], [67, 69], [70, 77], [77, 78]]}
{"doc_key": "ai-test-14", "ner": [[4, 5, "task"], [11, 12, "misc"], [18, 19, "misc"], [31, 31, "product"], [33, 33, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 12, 4, 5, "temporal", "", false, false], [18, 19, 11, 12, "named", "", false, false], [31, 31, 11, 12, "usage", "", false, false], [33, 33, 11, 12, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "special", "case", "of", "keyword", "recognition", "is", "the", "recognition", "of", "a", "wake", "word", "(", "also", "known", "as", "a", "hot", "word", ")", ",", "which", "is", "used", "by", "personal", "digital", "assistants", "such", "as", "Alexa", "or", "Siri", "to", "wake", "up", "when", "their", "name", "is", "spoken", "."], "sentence-detokenized": "A special case of keyword recognition is the recognition of a wake word (also known as a hot word), which is used by personal digital assistants such as Alexa or Siri to wake up when their name is spoken.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 17], [18, 25], [26, 37], [38, 40], [41, 44], [45, 56], [57, 59], [60, 61], [62, 66], [67, 71], [72, 73], [73, 77], [78, 83], [84, 86], [87, 88], [89, 92], [93, 97], [97, 98], [98, 99], [100, 105], [106, 108], [109, 113], [114, 116], [117, 125], [126, 133], [134, 144], [145, 149], [150, 152], [153, 158], [159, 161], [162, 166], [167, 169], [170, 174], [175, 177], [178, 182], [183, 188], [189, 193], [194, 196], [197, 203], [203, 204]]}
{"doc_key": "ai-test-15", "ner": [[0, 0, "programlang"], [9, 9, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 0, 0, "part-of", "", false, false], [11, 11, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "is", "an", "open", "source", "programming", "language", "that", "combines", "Prolog", "and", "Java", "."], "sentence-detokenized": "Prova is an open source programming language that combines Prolog and Java.", "token2charspan": [[0, 5], [6, 8], [9, 11], [12, 16], [17, 23], [24, 35], [36, 44], [45, 49], [50, 58], [59, 65], [66, 69], [70, 74], [74, 75]]}
{"doc_key": "ai-test-16", "ner": [[6, 7, "organisation"], [3, 3, "organisation"], [13, 15, "product"], [16, 23, "country"], [46, 46, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[6, 7, 3, 3, "part-of", "", false, false], [6, 7, 3, 3, "role", "sells", false, false], [6, 7, 16, 23, "role", "sells_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1987", ",", "Toshiba", "'s", "subsidiary", "Tocibai", "Machine", "was", "accused", "of", "illegally", "selling", "CNC", "milling", "cutters", "to", "the", "Soviet", "Union", "for", "use", "in", "the", "manufacture", "of", "ultra", "-quiet", "submarine", "propellers", ",", "in", "violation", "of", "the", "CoCom", "agreement", ",", "an", "international", "embargo", "on", "certain", "countries", "imposed", "on", "COMECON", "countries", "."], "sentence-detokenized": "In 1987, Toshiba's subsidiary Tocibai Machine was accused of illegally selling CNC milling cutters to the Soviet Union for use in the manufacture of ultra-quiet submarine propellers, in violation of the CoCom agreement, an international embargo on certain countries imposed on COMECON countries.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [16, 18], [19, 29], [30, 37], [38, 45], [46, 49], [50, 57], [58, 60], [61, 70], [71, 78], [79, 82], [83, 90], [91, 98], [99, 101], [102, 105], [106, 112], [113, 118], [119, 122], [123, 126], [127, 129], [130, 133], [134, 145], [146, 148], [149, 154], [154, 160], [161, 170], [171, 181], [181, 182], [183, 185], [186, 195], [196, 198], [199, 202], [203, 208], [209, 218], [218, 219], [220, 222], [223, 236], [237, 244], [245, 247], [248, 255], [256, 265], [266, 273], [274, 276], [277, 284], [285, 294], [294, 295]]}
{"doc_key": "ai-test-17", "ner": [[7, 10, "product"], [21, 26, "location"]], "ner_mapping_to_source": [1, 2], "relations": [[7, 10, 21, 26, "physical", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Engelberger", "'s", "most", "famous", "contribution", ",", "the", "industrial", "robot", "arm", "Unimate", ",", "was", "one", "of", "the", "first", "to", "be", "inducted", "into", "the", "Robot", "Hall", "of", "Fame", "in", "2003", "."], "sentence-detokenized": "Engelberger's most famous contribution, the industrial robot arm Unimate, was one of the first to be inducted into the Robot Hall of Fame in 2003.", "token2charspan": [[0, 11], [11, 13], [14, 18], [19, 25], [26, 38], [38, 39], [40, 43], [44, 54], [55, 60], [61, 64], [65, 72], [72, 73], [74, 77], [78, 81], [82, 84], [85, 88], [89, 94], [95, 97], [98, 100], [101, 109], [110, 114], [115, 118], [119, 124], [125, 129], [130, 132], [133, 137], [138, 140], [141, 145], [145, 146]]}
{"doc_key": "ai-test-18", "ner": [[3, 3, "misc"], [8, 8, "misc"], [10, 11, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 8, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Initially", "controlled", "via", "static", "html", "web", "pages", "using", "CGI", ",", "Dalton", "'s", "work", "introduced", "a", "Java", "-", "based", "plug", "-", "in", "with", "limited", "success", "."], "sentence-detokenized": "Initially controlled via static html web pages using CGI, Dalton's work introduced a Java-based plug-in with limited success.", "token2charspan": [[0, 9], [10, 20], [21, 24], [25, 31], [32, 36], [37, 40], [41, 46], [47, 52], [53, 56], [56, 57], [58, 64], [64, 66], [67, 71], [72, 82], [83, 84], [85, 89], [89, 90], [90, 95], [96, 100], [100, 101], [101, 103], [104, 108], [109, 116], [117, 124], [124, 125]]}
{"doc_key": "ai-test-19", "ner": [[5, 6, "task"], [13, 13, "organisation"], [26, 26, "conference"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[5, 6, 13, 13, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "edition", "of", "the", "LMF", "specification", "since", "it", "has", "been", "ratified", "by", "ISO", "(", "this", "document", "became", "(", "in", "2015", ")", "the", "9th", "most", "cited", "LREC", "document", "at", "LREC", "conferences", ")", ":"], "sentence-detokenized": "The first edition of the LMF specification since it has been ratified by ISO (this document became (in 2015) the 9th most cited LREC document at LREC conferences):", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 20], [21, 24], [25, 28], [29, 42], [43, 48], [49, 51], [52, 55], [56, 60], [61, 69], [70, 72], [73, 76], [77, 78], [78, 82], [83, 91], [92, 98], [99, 100], [100, 102], [103, 107], [107, 108], [109, 112], [113, 116], [117, 121], [122, 127], [128, 132], [133, 141], [142, 144], [145, 149], [150, 161], [161, 162], [162, 163]]}
{"doc_key": "ai-test-20", "ner": [[0, 2, "metrics"], [15, 16, "metrics"], [17, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 16, 0, 2, "usage", "", false, false], [15, 16, 17, 21, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "confusion", "matrix", "or", "matching", "matrix", "is", "often", "used", "as", "a", "tool", "to", "validate", "the", "accuracy", "of", "the", "k", "-", "NN", "classification", "."], "sentence-detokenized": "The confusion matrix or matching matrix is often used as a tool to validate the accuracy of the k -NN classification.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 23], [24, 32], [33, 39], [40, 42], [43, 48], [49, 53], [54, 56], [57, 58], [59, 63], [64, 66], [67, 75], [76, 79], [80, 88], [89, 91], [92, 95], [96, 97], [98, 99], [99, 101], [102, 116], [116, 117]]}
{"doc_key": "ai-test-21", "ner": [[11, 11, "field"], [13, 14, "field"], [16, 17, "field"]], "ner_mapping_to_source": [1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Decision", "tree", "learning", "is", "one", "of", "the", "forecasting", "approaches", "used", "in", "statistics", ",", "data", "mining", "and", "machine", "learning", "."], "sentence-detokenized": "Decision tree learning is one of the forecasting approaches used in statistics, data mining and machine learning.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 48], [49, 59], [60, 64], [65, 67], [68, 78], [78, 79], [80, 84], [85, 91], [92, 95], [96, 103], [104, 112], [112, 113]]}
{"doc_key": "ai-test-22", "ner": [[6, 9, "misc"], [23, 25, "algorithm"], [27, 27, "algorithm"]], "ner_mapping_to_source": [0, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["During", "the", "run", "-time", ",", "the", "target", "prosody", "of", "the", "sentence", "is", "superimposed", "on", "these", "minimum", "units", "using", "signal", "processing", "techniques", "such", "as", "linear", "prediction", "coding", ",", "PSOLA"], "sentence-detokenized": "During the run-time, the target prosody of the sentence is superimposed on these minimum units using signal processing techniques such as linear prediction coding, PSOLA", "token2charspan": [[0, 6], [7, 10], [11, 14], [14, 19], [19, 20], [21, 24], [25, 31], [32, 39], [40, 42], [43, 46], [47, 55], [56, 58], [59, 71], [72, 74], [75, 80], [81, 88], [89, 94], [95, 100], [101, 107], [108, 118], [119, 129], [130, 134], [135, 137], [138, 144], [145, 155], [156, 162], [162, 163], [164, 169]]}
{"doc_key": "ai-test-23", "ner": [[3, 4, "field"], [6, 8, "field"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 3, 4, "usage", "", true, false], [17, 18, 6, 8, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "approach", "used", "artificial", "intelligence", "and", "machine", "learning", "to", "allow", "researchers", "to", "visually", "compare", "normal", "and", "thermal", "facial", "images", "."], "sentence-detokenized": "This approach used artificial intelligence and machine learning to allow researchers to visually compare normal and thermal facial images.", "token2charspan": [[0, 4], [5, 13], [14, 18], [19, 29], [30, 42], [43, 46], [47, 54], [55, 63], [64, 66], [67, 72], [73, 84], [85, 87], [88, 96], [97, 104], [105, 111], [112, 115], [116, 123], [124, 130], [131, 137], [137, 138]]}
{"doc_key": "ai-test-24", "ner": [[0, 2, "field"], [4, 5, "algorithm"], [10, 11, "task"], [15, 16, "misc"], [22, 23, "field"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 0, 2, "part-of", "", false, false], [4, 5, 10, 11, "topic", "", false, false], [10, 11, 15, 16, "origin", "", false, false], [22, 23, 0, 2, "part-of", "", false, false], [22, 23, 4, 5, "topic", "", false, false], [25, 26, 0, 2, "part-of", "", false, false], [25, 26, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "computer", "science", ",", "evolutionary", "computation", "is", "a", "family", "of", "global", "optimisation", "algorithms", "inspired", "by", "biological", "evolution", ",", "and", "a", "subfield", "of", "artificial", "intelligence", "and", "soft", "computing", "that", "studies", "these", "algorithms", "."], "sentence-detokenized": "In computer science, evolutionary computation is a family of global optimisation algorithms inspired by biological evolution, and a subfield of artificial intelligence and soft computing that studies these algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 33], [34, 45], [46, 48], [49, 50], [51, 57], [58, 60], [61, 67], [68, 80], [81, 91], [92, 100], [101, 103], [104, 114], [115, 124], [124, 125], [126, 129], [130, 131], [132, 140], [141, 143], [144, 154], [155, 167], [168, 171], [172, 176], [177, 186], [187, 191], [192, 199], [200, 205], [206, 216], [216, 217]]}
{"doc_key": "ai-test-25", "ner": [[8, 9, "metrics"], [13, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "a", "measure", "based", "on", "a", "confusion", "matrix", "can", "be", "combined", "with", "an", "estimated", "mean", "squared", "error", "between", "the", "raw", "outputs", "of", "the", "model", "and", "the", "actual", "values", "."], "sentence-detokenized": "For example, a measure based on a confusion matrix can be combined with an estimated mean squared error between the raw outputs of the model and the actual values.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 14], [15, 22], [23, 28], [29, 31], [32, 33], [34, 43], [44, 50], [51, 54], [55, 57], [58, 66], [67, 71], [72, 74], [75, 84], [85, 89], [90, 97], [98, 103], [104, 111], [112, 115], [116, 119], [120, 127], [128, 130], [131, 134], [135, 140], [141, 144], [145, 148], [149, 155], [156, 162], [162, 163]]}
{"doc_key": "ai-test-26", "ner": [[7, 8, "product"], [14, 14, "researcher"], [10, 11, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 14, 14, "origin", "", false, false], [7, 8, 10, 11, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Most", "of", "them", "are", "results", "of", "the", "word2vec", "model", "or", "word2vec", "variants", "developed", "by", "Mikolov", "et", "al", "."], "sentence-detokenized": "Most of them are results of the word2vec model or word2vec variants developed by Mikolov et al.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 16], [17, 24], [25, 27], [28, 31], [32, 40], [41, 46], [47, 49], [50, 58], [59, 67], [68, 77], [78, 80], [81, 88], [89, 91], [92, 94], [94, 95]]}
{"doc_key": "ai-test-27", "ner": [[8, 8, "conference"], [12, 15, "conference"], [11, 17, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 17, 12, 15, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "total", "of", "43", "publications", "were", "recognised", "by", "CVPR", "and", "the", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "during", "this", "period", "."], "sentence-detokenized": "A total of 43 publications were recognised by CVPR and the International Conference on Computer Vision (ICCV) during this period.", "token2charspan": [[0, 1], [2, 7], [8, 10], [11, 13], [14, 26], [27, 31], [32, 42], [43, 45], [46, 50], [51, 54], [55, 58], [59, 72], [73, 83], [84, 86], [87, 95], [96, 102], [103, 104], [104, 108], [108, 109], [110, 116], [117, 121], [122, 128], [128, 129]]}
{"doc_key": "ai-test-28", "ner": [[0, 0, "product"], [14, 15, "field"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 14, 15, "general-affiliation", "platform_for_education_about", false, false], [25, 26, 0, 0, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["AIBO", "has", "seen", "a", "lot", "of", "use", "as", "a", "low", "-", "cost", "platform", "for", "artificial", "intelligence", "in", "education", "and", "research", "because", "it", "integrates", "computing", ",", "computer", "vision", "and", "motion", "in", "a", "package", "that", "is", "significantly", "cheaper", "than", "conventional", "research", "robots", "."], "sentence-detokenized": "AIBO has seen a lot of use as a low-cost platform for artificial intelligence in education and research because it integrates computing, computer vision and motion in a package that is significantly cheaper than conventional research robots.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 15], [16, 19], [20, 22], [23, 26], [27, 29], [30, 31], [32, 35], [35, 36], [36, 40], [41, 49], [50, 53], [54, 64], [65, 77], [78, 80], [81, 90], [91, 94], [95, 103], [104, 111], [112, 114], [115, 125], [126, 135], [135, 136], [137, 145], [146, 152], [153, 156], [157, 163], [164, 166], [167, 168], [169, 176], [177, 181], [182, 184], [185, 198], [199, 206], [207, 211], [212, 224], [225, 233], [234, 240], [240, 241]]}
{"doc_key": "ai-test-29", "ner": [[0, 12, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "was", "the", "Programme", "Chair", "of", "the", "International", "Conference", "on", "Computer", "Vision", "2021", "."], "sentence-detokenized": "He was the Programme Chair of the International Conference on Computer Vision 2021.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 20], [21, 26], [27, 29], [30, 33], [34, 47], [48, 58], [59, 61], [62, 70], [71, 77], [78, 82], [82, 83]]}
{"doc_key": "ai-test-30", "ner": [[1, 1, "researcher"], [5, 6, "organisation"], [15, 16, "organisation"], [25, 26, "organisation"], [32, 37, "product"], [33, 39, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 1, 5, 6, "role", "", false, false], [1, 1, 15, 16, "role", "", true, false], [15, 16, 25, 26, "role", "develops_with", false, false], [32, 37, 15, 16, "artifact", "", false, false], [33, 39, 32, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["After", "Scheinman", "received", "a", "grant", "from", "Unimation", "to", "develop", "his", "projects", ",", "he", "sold", "them", "to", "Unimation", ",", "which", "further", "developed", "them", "with", "support", "from", "General", "Motors", "and", "later", "marketed", "them", "as", "a", "Programmable", "Universal", "Machine", "for", "Assembly", "(", "PUMA", ")", "."], "sentence-detokenized": "After Scheinman received a grant from Unimation to develop his projects, he sold them to Unimation, which further developed them with support from General Motors and later marketed them as a Programmable Universal Machine for Assembly (PUMA).", "token2charspan": [[0, 5], [6, 15], [16, 24], [25, 26], [27, 32], [33, 37], [38, 47], [48, 50], [51, 58], [59, 62], [63, 71], [71, 72], [73, 75], [76, 80], [81, 85], [86, 88], [89, 98], [98, 99], [100, 105], [106, 113], [114, 123], [124, 128], [129, 133], [134, 141], [142, 146], [147, 154], [155, 161], [162, 165], [166, 171], [172, 180], [181, 185], [186, 188], [189, 190], [191, 203], [204, 213], [214, 221], [222, 225], [226, 234], [235, 236], [236, 240], [240, 241], [241, 242]]}
{"doc_key": "ai-test-31", "ner": [[6, 7, "task"], [9, 11, "task"], [15, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 15, 6, 7, "general-affiliation", "works_with", false, false], [15, 15, 9, 11, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "overview", "of", "calibration", "methods", "for", "binary", "classification", "and", "multiclass", "classification", "tasks", "is", "given", "by", "Gebel", "(", "2009", ")", "."], "sentence-detokenized": "An overview of calibration methods for binary classification and multiclass classification tasks is given by Gebel (2009).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 34], [35, 38], [39, 45], [46, 60], [61, 64], [65, 75], [76, 90], [91, 96], [97, 99], [100, 105], [106, 108], [109, 114], [115, 116], [116, 120], [120, 121], [121, 122]]}
{"doc_key": "ai-test-32", "ner": [[6, 10, "task"], [13, 14, "task"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "works", "in", "areas", "such", "as", "optical", "character", "recognition", "(", "OCR", ")", ",", "speech", "synthesis", ",", "speech", "recognition", "technology", "and", "electronic", "keyboards", "."], "sentence-detokenized": "He works in areas such as optical character recognition (OCR), speech synthesis, speech recognition technology and electronic keyboards.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 17], [18, 22], [23, 25], [26, 33], [34, 43], [44, 55], [56, 57], [57, 60], [60, 61], [61, 62], [63, 69], [70, 79], [79, 80], [81, 87], [88, 99], [100, 110], [111, 114], [115, 125], [126, 135], [135, 136]]}
{"doc_key": "ai-test-33", "ner": [[7, 10, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "newer", "and", "more", "modern", "techniques", ",", "a", "Kald", "tool", "kit", "can", "be", "used", "."], "sentence-detokenized": "For newer and more modern techniques, a Kald tool kit can be used.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 18], [19, 25], [26, 36], [36, 37], [38, 39], [40, 44], [45, 49], [50, 53], [54, 57], [58, 60], [61, 65], [65, 66]]}
{"doc_key": "ai-test-34", "ner": [[0, 4, "researcher"], [8, 10, "organisation"], [16, 17, "organisation"], [23, 24, "organisation"], [30, 31, "researcher"], [32, 35, "organisation"], [42, 45, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 4, 8, 10, "role", "", false, false], [0, 4, 16, 17, "role", "", false, false], [0, 4, 23, 24, "role", "", false, false], [0, 4, 32, 35, "role", "", false, false], [0, 4, 42, 45, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Johnson", "-", "Laird", "is", "a", "Fellow", "of", "the", "American", "Philosophical", "Society", ",", "a", "Fellow", "of", "the", "Royal", "Society", ",", "a", "Fellow", "of", "the", "British", "Academy", ",", "a", "Fellow", "of", "the", "William", "James", "Association", "for", "Psychological", "Science", ",", "and", "a", "Fellow", "of", "the", "Society", "for", "Cognitive", "Science", "."], "sentence-detokenized": "Johnson-Laird is a Fellow of the American Philosophical Society, a Fellow of the Royal Society, a Fellow of the British Academy, a Fellow of the William James Association for Psychological Science, and a Fellow of the Society for Cognitive Science.", "token2charspan": [[0, 7], [7, 8], [8, 13], [14, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 41], [42, 55], [56, 63], [63, 64], [65, 66], [67, 73], [74, 76], [77, 80], [81, 86], [87, 94], [94, 95], [96, 97], [98, 104], [105, 107], [108, 111], [112, 119], [120, 127], [127, 128], [129, 130], [131, 137], [138, 140], [141, 144], [145, 152], [153, 158], [159, 170], [171, 174], [175, 188], [189, 196], [196, 197], [198, 201], [202, 203], [204, 210], [211, 213], [214, 217], [218, 225], [226, 229], [230, 239], [240, 247], [247, 248]]}
{"doc_key": "ai-test-35", "ner": [[0, 8, "conference"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 22, "algorithm"], [29, 29, "task"], [25, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 11, 0, 8, "physical", "", false, false], [10, 11, 0, 8, "temporal", "", false, false], [13, 14, 0, 8, "physical", "", false, false], [13, 14, 0, 8, "temporal", "", false, false], [16, 17, 0, 8, "physical", "", false, false], [16, 17, 0, 8, "temporal", "", false, false], [19, 22, 16, 17, "role", "extends", false, false], [29, 29, 16, 17, "role", "extends", false, false], [25, 31, 29, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["At", "the", "2010", "IEEE", "International", "Conference", "on", "Image", "Processing", ",", "Rui", "Hu", ",", "Mark", "Banard", "and", "John", "Collomosse", "extended", "the", "HOG", "descriptor", "for", "use", "in", "sketch", "-", "based", "image", "retrieval", "(", "SBIR", ")", "."], "sentence-detokenized": "At the 2010 IEEE International Conference on Image Processing, Rui Hu, Mark Banard and John Collomosse extended the HOG descriptor for use in sketch-based image retrieval (SBIR).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 30], [31, 41], [42, 44], [45, 50], [51, 61], [61, 62], [63, 66], [67, 69], [69, 70], [71, 75], [76, 82], [83, 86], [87, 91], [92, 102], [103, 111], [112, 115], [116, 119], [120, 130], [131, 134], [135, 138], [139, 141], [142, 148], [148, 149], [149, 154], [155, 160], [161, 170], [171, 172], [172, 176], [176, 177], [177, 178]]}
{"doc_key": "ai-test-36", "ner": [[0, 0, "metrics"], [6, 6, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["BLEU", "uses", "a", "modified", "form", "of", "accuracy", "to", "compare", "a", "translation", "candidate", "with", "several", "reference", "translators", "."], "sentence-detokenized": "BLEU uses a modified form of accuracy to compare a translation candidate with several reference translators.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 20], [21, 25], [26, 28], [29, 37], [38, 40], [41, 48], [49, 50], [51, 62], [63, 72], [73, 77], [78, 85], [86, 95], [96, 107], [107, 108]]}
{"doc_key": "ai-test-37", "ner": [[28, 29, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "the", "general", "base", "space", "math", "(", "Y", ",\\", "mathcal", "{", "B", "},\\", "nu", ")", "/", "math", "(", "i.e.", "the", "base", "space", "that", "is", "not", "countable", ")", ",", "relative", "entropy", "is", "usually", "considered", "."], "sentence-detokenized": "For the general base space math (Y,\\ mathcal {B},\\ nu) / math (i.e. the base space that is not countable), relative entropy is usually considered.", "token2charspan": [[0, 3], [4, 7], [8, 15], [16, 20], [21, 26], [27, 31], [32, 33], [33, 34], [34, 36], [37, 44], [45, 46], [46, 47], [47, 50], [51, 53], [53, 54], [55, 56], [57, 61], [62, 63], [63, 67], [68, 71], [72, 76], [77, 82], [83, 87], [88, 90], [91, 94], [95, 104], [104, 105], [105, 106], [107, 115], [116, 123], [124, 126], [127, 134], [135, 145], [145, 146]]}
{"doc_key": "ai-test-38", "ner": [[11, 11, "country"], [15, 15, "organisation"], [13, 17, "organisation"], [20, 21, "organisation"], [23, 26, "organisation"], [30, 32, "organisation"], [36, 41, "organisation"], [43, 43, "organisation"], [51, 51, "misc"], [52, 52, "misc"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 8, 9, 10, 11], "relations": [[15, 15, 11, 11, "physical", "", false, false], [13, 17, 15, 15, "named", "", false, false], [23, 26, 20, 21, "named", "", false, false], [43, 43, 36, 41, "named", "", false, false], [51, 51, 52, 52, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 3, 5, 6], "sentence": ["As", "of", "October", "2011", ",", "the", "already", "existing", "partnership", "between", "the", "United", "States", "National", "Park", "Service", "(", "NPS", ")", ",", "Historic", "Scotland", "(", "HS", ")", "in", "the", "UK", ",", "the", "World", "Monuments", "Fund", "and", "Mexico", "'s", "Instituto", "Nacional", "de", "Antropolog\u00eda", "y", "Historia", "(", "INAH", ")", "had", "been", "significantly", "expanded", ",", "the", "CyArk", "website", "."], "sentence-detokenized": "As of October 2011, the already existing partnership between the United States National Park Service (NPS), Historic Scotland (HS) in the UK, the World Monuments Fund and Mexico's Instituto Nacional de Antropolog\u00eda y Historia (INAH) had been significantly expanded, the CyArk website.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 18], [18, 19], [20, 23], [24, 31], [32, 40], [41, 52], [53, 60], [61, 64], [65, 71], [72, 78], [79, 87], [88, 92], [93, 100], [101, 102], [102, 105], [105, 106], [106, 107], [108, 116], [117, 125], [126, 127], [127, 129], [129, 130], [131, 133], [134, 137], [138, 140], [140, 141], [142, 145], [146, 151], [152, 161], [162, 166], [167, 170], [171, 177], [177, 179], [180, 189], [190, 198], [199, 201], [202, 214], [215, 216], [217, 225], [226, 227], [227, 231], [231, 232], [233, 236], [237, 241], [242, 255], [256, 264], [264, 265], [266, 269], [270, 275], [276, 283], [283, 284]]}
{"doc_key": "ai-test-39", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [11, 11, "product"], [13, 13, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 11, 11, "part-of", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [11, 11, 6, 7, "general-affiliation", "", false, false], [13, 13, 6, 7, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kernel", "SVM", "is", "available", "in", "many", "machine", "learning", "toolkits", ",", "including", "LIBSVM", ",", "MATLAB", "and", "others", "."], "sentence-detokenized": "Kernel SVM is available in many machine learning toolkits, including LIBSVM, MATLAB and others.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 23], [24, 26], [27, 31], [32, 39], [40, 48], [49, 57], [57, 58], [59, 68], [69, 75], [75, 76], [77, 83], [84, 87], [88, 94], [94, 95]]}
{"doc_key": "ai-test-40", "ner": [[2, 4, "misc"], [11, 14, "location"], [16, 16, "location"], [18, 18, "country"], [23, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 11, 14, "physical", "", false, false], [2, 4, 23, 26, "temporal", "", false, false], [11, 14, 16, 16, "physical", "", false, false], [16, 16, 18, 18, "physical", "", false, false], [23, 26, 11, 14, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "2009", "Loebner", "Awards", "competition", "took", "place", "on", "6", "September", "2009", "at", "the", "Brighton", "Centre", ",", "Brighton", ",", "UK", ",", "in", "conjunction", "with", "the", "Interspeech", "2009", "conference", "."], "sentence-detokenized": "The 2009 Loebner Awards competition took place on 6 September 2009 at the Brighton Centre, Brighton, UK, in conjunction with the Interspeech 2009 conference.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 23], [24, 35], [36, 40], [41, 46], [47, 49], [50, 51], [52, 61], [62, 66], [67, 69], [70, 73], [74, 82], [83, 89], [89, 90], [91, 99], [99, 100], [101, 103], [103, 104], [105, 107], [108, 119], [120, 124], [125, 128], [129, 140], [141, 145], [146, 156], [156, 157]]}
{"doc_key": "ai-test-41", "ner": [[2, 5, "product"], [8, 8, "product"], [14, 16, "product"], [17, 19, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[17, 19, 2, 5, "part-of", "", false, false], [17, 19, 8, 8, "part-of", "", false, false], [17, 19, 14, 16, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "humanoid", "robot", "QRIO", "is", "the", "successor", "to", "AIBO", "and", "uses", "the", "same", "basic", "R", "-", "CODE", "Aperios", "operating", "system", "."], "sentence-detokenized": "The humanoid robot QRIO is the successor to AIBO and uses the same basic R-CODE Aperios operating system.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 23], [24, 26], [27, 30], [31, 40], [41, 43], [44, 48], [49, 52], [53, 57], [58, 61], [62, 66], [67, 72], [73, 74], [74, 75], [75, 79], [80, 87], [88, 97], [98, 104], [104, 105]]}
{"doc_key": "ai-test-42", "ner": [[0, 2, "misc"], [6, 6, "algorithm"], [10, 11, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 0, 2, "cause-effect", "", true, false], [10, 11, 0, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "speech", "waveform", "is", "generated", "using", "HMMs", "based", "on", "the", "maximum", "likelihood", "criterion", "."], "sentence-detokenized": "The speech waveform is generated using HMMs based on the maximum likelihood criterion.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 22], [23, 32], [33, 38], [39, 43], [44, 49], [50, 52], [53, 56], [57, 64], [65, 75], [76, 85], [85, 86]]}
{"doc_key": "ai-test-43", "ner": [[0, 1, "product"], [5, 8, "task"], [10, 10, "task"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 5, 8, "type-of", "", false, false], [0, 1, 10, 10, "type-of", "", false, false], [0, 1, 16, 17, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "is", "a", "free", "multilingual", "statistical", "machine", "translation", "and", "neural", "machine", "translation", "service", "developed", "by", "Google", "that", "allows", "you", "to", "translate", "text", "and", "websites", "from", "one", "language", "into", "another", "."], "sentence-detokenized": "Google Translate is a free multilingual statistical machine translation and neural machine translation service developed by Google that allows you to translate text and websites from one language into another.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 39], [40, 51], [52, 59], [60, 71], [72, 75], [76, 82], [83, 90], [91, 102], [103, 110], [111, 120], [121, 123], [124, 130], [131, 135], [136, 142], [143, 146], [147, 149], [150, 159], [160, 164], [165, 168], [169, 177], [178, 182], [183, 186], [187, 195], [196, 200], [201, 208], [208, 209]]}
{"doc_key": "ai-test-44", "ner": [[4, 6, "field"], [8, 9, "field"], [11, 12, "field"], [14, 16, "field"], [20, 22, "task"], [24, 25, "task"], [27, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[20, 22, 4, 6, "part-of", "", false, true], [20, 22, 8, 9, "part-of", "", false, true], [20, 22, 11, 12, "part-of", "", false, true], [24, 25, 4, 6, "part-of", "", false, true], [24, 25, 8, 9, "part-of", "", false, true], [24, 25, 11, 12, "part-of", "", false, true], [27, 30, 4, 6, "part-of", "", false, true], [27, 30, 8, 9, "part-of", "", false, true], [27, 30, 11, 12, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Skeletons", "are", "widely", "used", "in", "computer", "vision", ",", "image", "analysis", ",", "pattern", "recognition", "and", "digital", "image", "processing", ",", "such", "as", "optical", "character", "recognition", ",", "fingerprint", "recognition", ",", "visual", "inspection", "or", "compression", "."], "sentence-detokenized": "Skeletons are widely used in computer vision, image analysis, pattern recognition and digital image processing, such as optical character recognition, fingerprint recognition, visual inspection or compression.", "token2charspan": [[0, 9], [10, 13], [14, 20], [21, 25], [26, 28], [29, 37], [38, 44], [44, 45], [46, 51], [52, 60], [60, 61], [62, 69], [70, 81], [82, 85], [86, 93], [94, 99], [100, 110], [110, 111], [112, 116], [117, 119], [120, 127], [128, 137], [138, 149], [149, 150], [151, 162], [163, 174], [174, 175], [176, 182], [183, 193], [194, 196], [197, 208], [208, 209]]}
{"doc_key": "ai-test-45", "ner": [[0, 8, "conference"], [9, 12, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 8, 9, 12, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "is", "an", "object", "classification", "and", "recognition", "benchmark", "that", "covers", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "The ImageNet Large Scale Visual Recognition Challenge is an object classification and recognition benchmark that covers millions of images and hundreds of object classes.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 24], [25, 31], [32, 43], [44, 53], [54, 56], [57, 59], [60, 66], [67, 81], [82, 85], [86, 97], [98, 107], [108, 112], [113, 119], [120, 128], [129, 131], [132, 138], [139, 142], [143, 151], [152, 154], [155, 161], [162, 169], [169, 170]]}
{"doc_key": "ai-test-46", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [15, 19, "misc"], [22, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 15, 19, "part-of", "", false, false], [0, 0, 22, 25, "part-of", "", false, false], [4, 5, 15, 19, "part-of", "", false, false], [4, 5, 22, 25, "part-of", "", false, false], [7, 8, 15, 19, "part-of", "", false, false], [7, 8, 22, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Bengio", ",", "along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "have", "been", "called", "by", "some", "the", "godfathers", "of", "artificial", "intelligence", "and", "the", "godfathers", "of", "deep", "learning", "."], "sentence-detokenized": "Bengio, along with Geoffrey Hinton and Yann LeCun, have been called by some the godfathers of artificial intelligence and the godfathers of deep learning.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 18], [19, 27], [28, 34], [35, 38], [39, 43], [44, 49], [49, 50], [51, 55], [56, 60], [61, 67], [68, 70], [71, 75], [76, 79], [80, 90], [91, 93], [94, 104], [105, 117], [118, 121], [122, 125], [126, 136], [137, 139], [140, 144], [145, 153], [153, 154]]}
{"doc_key": "ai-test-47", "ner": [[3, 3, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "an", "IEEE", "Life", "Fellow", "."], "sentence-detokenized": "He is an IEEE Life Fellow.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 13], [14, 18], [19, 25], [25, 26]]}
{"doc_key": "ai-test-48", "ner": [[0, 1, "organisation"], [14, 19, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 14, 19, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NSA", "Bethesda", "is", "responsible", "for", "the", "operational", "support", "of", "its", "main", "tenant", ",", "the", "Walter", "Reed", "National", "Military", "Medical", "Center", "."], "sentence-detokenized": "NSA Bethesda is responsible for the operational support of its main tenant, the Walter Reed National Military Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 31], [32, 35], [36, 47], [48, 55], [56, 58], [59, 62], [63, 67], [68, 74], [74, 75], [76, 79], [80, 86], [87, 91], [92, 100], [101, 109], [110, 117], [118, 124], [124, 125]]}
{"doc_key": "ai-test-49", "ner": [[6, 7, "field"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "three", "main", "learning", "paradigms", "are", "guided", "learning", ",", "unsupervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "The three main learning paradigms are guided learning, unsupervised learning and reinforcement learning.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 23], [24, 33], [34, 37], [38, 44], [45, 53], [53, 54], [55, 67], [68, 76], [77, 80], [81, 94], [95, 103], [103, 104]]}
{"doc_key": "ai-test-50", "ner": [[2, 2, "task"], [4, 6, "task"], [11, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Examples", "include", "control", ",", "planning", "and", "scheduling", ",", "the", "ability", "to", "answer", "diagnostic", "and", "consumer", "questions", ",", "handwriting", "recognition", ",", "natural", "language", "understanding", ",", "speech", "recognition", "and", "facial", "recognition", "."], "sentence-detokenized": "Examples include control, planning and scheduling, the ability to answer diagnostic and consumer questions, handwriting recognition, natural language understanding, speech recognition and facial recognition.", "token2charspan": [[0, 8], [9, 16], [17, 24], [24, 25], [26, 34], [35, 38], [39, 49], [49, 50], [51, 54], [55, 62], [63, 65], [66, 72], [73, 83], [84, 87], [88, 96], [97, 106], [106, 107], [108, 119], [120, 131], [131, 132], [133, 140], [141, 149], [150, 163], [163, 164], [165, 171], [172, 183], [184, 187], [188, 194], [195, 206], [206, 207]]}
{"doc_key": "ai-test-51", "ner": [[9, 15, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1991", "he", "was", "elected", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "1990", ",", "founding", "member", ")", "."], "sentence-detokenized": "In 1991 he was elected a member of the Association for the Advancement of Artificial Intelligence (1990, founding member).", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 22], [23, 24], [25, 31], [32, 34], [35, 38], [39, 50], [51, 54], [55, 58], [59, 70], [71, 73], [74, 84], [85, 97], [98, 99], [99, 103], [103, 104], [105, 113], [114, 120], [120, 121], [121, 122]]}
{"doc_key": "ai-test-52", "ner": [[12, 13, "misc"], [16, 17, "algorithm"], [29, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "if", "we", "formulate", "the", "problem", "as", "a", "solution", "to", "a", "Toeplitz", "matrix", "and", "use", "Levinson", "recursion", ",", "we", "can", "relatively", "quickly", "estimate", "a", "filter", "with", "the", "smallest", "mean", "square", "error", "."], "sentence-detokenized": "However, if we formulate the problem as a solution to a Toeplitz matrix and use Levinson recursion, we can relatively quickly estimate a filter with the smallest mean square error.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 14], [15, 24], [25, 28], [29, 36], [37, 39], [40, 41], [42, 50], [51, 53], [54, 55], [56, 64], [65, 71], [72, 75], [76, 79], [80, 88], [89, 98], [98, 99], [100, 102], [103, 106], [107, 117], [118, 125], [126, 134], [135, 136], [137, 143], [144, 148], [149, 152], [153, 161], [162, 166], [167, 173], [174, 179], [179, 180]]}
{"doc_key": "ai-test-53", "ner": [[5, 8, "conference"], [16, 19, "location"], [20, 20, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 8, 16, 19, "physical", "", false, false], [16, 19, 20, 20, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2011", ",", "the", "15th", "Campus", "Party", "Spain", "will", "take", "place", "in", "the", "city", "of", "Arts", "and", "Sciences", "of", "Valencia", "."], "sentence-detokenized": "In July 2011, the 15th Campus Party Spain will take place in the city of Arts and Sciences of Valencia.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 22], [23, 29], [30, 35], [36, 41], [42, 46], [47, 51], [52, 57], [58, 60], [61, 64], [65, 69], [70, 72], [73, 77], [78, 81], [82, 90], [91, 93], [94, 102], [102, 103]]}
{"doc_key": "ai-test-54", "ner": [[15, 15, "product"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Often", "this", "is", "generally", "only", "possible", "at", "the", "end", "of", "a", "complex", "game", "such", "as", "chess", "or", "go", ",", "as", "it", "is", "not", "possible", "to", "look", "ahead", "to", "the", "end", "of", "the", "game", ",", "except", "towards", "the", "end", ",", "and", "instead", "positions", "are", "given", "final", "values", "that", "indicate", "the", "probability", "that", "they", "will", "lead", "to", "a", "win", "for", "one", "player", "or", "another", "."], "sentence-detokenized": "Often this is generally only possible at the end of a complex game such as chess or go, as it is not possible to look ahead to the end of the game, except towards the end, and instead positions are given final values that indicate the probability that they will lead to a win for one player or another.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 23], [24, 28], [29, 37], [38, 40], [41, 44], [45, 48], [49, 51], [52, 53], [54, 61], [62, 66], [67, 71], [72, 74], [75, 80], [81, 83], [84, 86], [86, 87], [88, 90], [91, 93], [94, 96], [97, 100], [101, 109], [110, 112], [113, 117], [118, 123], [124, 126], [127, 130], [131, 134], [135, 137], [138, 141], [142, 146], [146, 147], [148, 154], [155, 162], [163, 166], [167, 170], [170, 171], [172, 175], [176, 183], [184, 193], [194, 197], [198, 203], [204, 209], [210, 216], [217, 221], [222, 230], [231, 234], [235, 246], [247, 251], [252, 256], [257, 261], [262, 266], [267, 269], [270, 271], [272, 275], [276, 279], [280, 283], [284, 290], [291, 293], [294, 301], [301, 302]]}
{"doc_key": "ai-test-55", "ner": [[4, 6, "algorithm"], [23, 24, "algorithm"], [30, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[4, 6, 23, 24, "compare", "", false, false], [4, 6, 30, 32, "compare", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["The", "difference", "between", "a", "multinomial", "logit", "model", "and", "many", "other", "methods", ",", "models", ",", "algorithms", ",", "etc.", "with", "the", "same", "basic", "apparatus", "(", "perceptron", "algorithm", ",", "support", "vector", "machines", ",", "linear", "discriminant", "analysis", ",", "etc.", ")", "."], "sentence-detokenized": "The difference between a multinomial logit model and many other methods, models, algorithms, etc. with the same basic apparatus (perceptron algorithm, support vector machines, linear discriminant analysis, etc.).", "token2charspan": [[0, 3], [4, 14], [15, 22], [23, 24], [25, 36], [37, 42], [43, 48], [49, 52], [53, 57], [58, 63], [64, 71], [71, 72], [73, 79], [79, 80], [81, 91], [91, 92], [93, 97], [98, 102], [103, 106], [107, 111], [112, 117], [118, 127], [128, 129], [129, 139], [140, 149], [149, 150], [151, 158], [159, 165], [166, 174], [174, 175], [176, 182], [183, 195], [196, 204], [204, 205], [206, 210], [210, 211], [211, 212]]}
{"doc_key": "ai-test-56", "ner": [[0, 3, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Association", "for", "Computational", "Linguistics", ",", "edited", "by"], "sentence-detokenized": "Association for Computational Linguistics, edited by", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [41, 42], [43, 49], [50, 52]]}
{"doc_key": "ai-test-57", "ner": [[3, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "a", "computerised", "face", "recognition", "system", ",", "each", "face", "is", "represented", "by", "a", "large", "number", "of", "pixel", "values", "."], "sentence-detokenized": "In a computerised face recognition system, each face is represented by a large number of pixel values.", "token2charspan": [[0, 2], [3, 4], [5, 17], [18, 22], [23, 34], [35, 41], [41, 42], [43, 47], [48, 52], [53, 55], [56, 67], [68, 70], [71, 72], [73, 78], [79, 85], [86, 88], [89, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-test-58", "ner": [[6, 9, "person"], [13, 16, "organisation"], [22, 23, "country"], [26, 26, "person"], [37, 39, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 9, 13, 16, "role", "", false, false], [6, 9, 22, 23, "physical", "", false, false], [26, 26, 37, 39, "origin", "", false, false], [26, 26, 37, 39, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2002", ",", "his", "son", ",", "Daniel", "Pearl", ",", "a", "journalist", "working", "for", "the", "Wall", "Street", "Journal", ",", "was", "kidnapped", "and", "murdered", "in", "Pakistan", ",", "leading", "Judea", "and", "other", "family", "members", "and", "friends", "to", "set", "up", "the", "Daniel", "Pearl", "Foundation", "."], "sentence-detokenized": "In 2002, his son, Daniel Pearl, a journalist working for the Wall Street Journal, was kidnapped and murdered in Pakistan, leading Judea and other family members and friends to set up the Daniel Pearl Foundation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [16, 17], [18, 24], [25, 30], [30, 31], [32, 33], [34, 44], [45, 52], [53, 56], [57, 60], [61, 65], [66, 72], [73, 80], [80, 81], [82, 85], [86, 95], [96, 99], [100, 108], [109, 111], [112, 120], [120, 121], [122, 129], [130, 135], [136, 139], [140, 145], [146, 152], [153, 160], [161, 164], [165, 172], [173, 175], [176, 179], [180, 182], [183, 186], [187, 193], [194, 199], [200, 210], [210, 211]]}
{"doc_key": "ai-test-59", "ner": [[6, 8, "organisation"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 18, 19, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["From", "the", "end", "of", "2006", ",", "Red", "Envelope", "Entertainment", "also", "started", "producing", "original", "content", "with", "filmmakers", "such", "as", "John", "Waters", "."], "sentence-detokenized": "From the end of 2006, Red Envelope Entertainment also started producing original content with filmmakers such as John Waters.", "token2charspan": [[0, 4], [5, 8], [9, 12], [13, 15], [16, 20], [20, 21], [22, 25], [26, 34], [35, 48], [49, 53], [54, 61], [62, 71], [72, 80], [81, 88], [89, 93], [94, 104], [105, 109], [110, 112], [113, 117], [118, 124], [124, 125]]}
{"doc_key": "ai-test-60", "ner": [[6, 10, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "building", "is", "now", "part", "of", "Beth", "Israel", "Deaconess", "Medical", "Center", "."], "sentence-detokenized": "The building is now part of Beth Israel Deaconess Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 32], [33, 39], [40, 49], [50, 57], [58, 64], [64, 65]]}
{"doc_key": "ai-test-61", "ner": [[16, 17, "field"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "common", "theme", "of", "this", "work", "is", "the", "adoption", "of", "a", "sign", "-", "theoretic", "perspective", "on", "artificial", "intelligence", "and", "knowledge", "representation", "."], "sentence-detokenized": "A common theme of this work is the adoption of a sign-theoretic perspective on artificial intelligence and knowledge representation.", "token2charspan": [[0, 1], [2, 8], [9, 14], [15, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 43], [44, 46], [47, 48], [49, 53], [53, 54], [54, 63], [64, 75], [76, 78], [79, 89], [90, 102], [103, 106], [107, 116], [117, 131], [131, 132]]}
{"doc_key": "ai-test-62", "ner": [[5, 9, "task"], [19, 20, "task"], [39, 40, "task"], [42, 43, "task"], [46, 48, "task"], [50, 50, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [[39, 40, 46, 48, "part-of", "", false, false], [42, 43, 46, 48, "part-of", "", false, false], [46, 48, 19, 20, "type-of", "", false, false], [50, 50, 46, 48, "named", "", false, false]], "relations_mapping_to_source": [4, 5, 6, 7], "sentence": ["For", "example", ",", "the", "term", "neural", "machine", "translation", "(", "NMT", ")", "emphasises", "the", "fact", "that", "deep", "learning", "-", "based", "machine", "translation", "approaches", "learn", "sequence", "-", "to", "-", "sequence", "conversions", "directly", ",", "avoiding", "the", "need", "for", "intermediate", "steps", "such", "as", "word", "alignment", "and", "language", "modelling", "used", "in", "statistical", "machine", "translation", "(", "SMT", ")", "."], "sentence-detokenized": "For example, the term neural machine translation (NMT) emphasises the fact that deep learning-based machine translation approaches learn sequence-to-sequence conversions directly, avoiding the need for intermediate steps such as word alignment and language modelling used in statistical machine translation (SMT).", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 36], [37, 48], [49, 50], [50, 53], [53, 54], [55, 65], [66, 69], [70, 74], [75, 79], [80, 84], [85, 93], [93, 94], [94, 99], [100, 107], [108, 119], [120, 130], [131, 136], [137, 145], [145, 146], [146, 148], [148, 149], [149, 157], [158, 169], [170, 178], [178, 179], [180, 188], [189, 192], [193, 197], [198, 201], [202, 214], [215, 220], [221, 225], [226, 228], [229, 233], [234, 243], [244, 247], [248, 256], [257, 266], [267, 271], [272, 274], [275, 286], [287, 294], [295, 306], [307, 308], [308, 311], [311, 312], [312, 313]]}
{"doc_key": "ai-test-63", "ner": [[6, 6, "field"], [11, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 6, 11, 12, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Most", "research", "in", "the", "field", "of", "WSD", "is", "carried", "out", "using", "Word", "Net", "as", "a", "reference", "term", "inventory", "."], "sentence-detokenized": "Most research in the field of WSD is carried out using WordNet as a reference term inventory.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 26], [27, 29], [30, 33], [34, 36], [37, 44], [45, 48], [49, 54], [55, 59], [59, 62], [63, 65], [66, 67], [68, 77], [78, 82], [83, 92], [92, 93]]}
{"doc_key": "ai-test-64", "ner": [[10, 11, "researcher"], [13, 14, "researcher"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Previous", "doctoral", "students", "and", "post-doctoral", "fellows", "in", "his", "group", "include", "Richard", "Zemel", "and", "Zoubin", "Ghahramani", "."], "sentence-detokenized": "Previous doctoral students and post-doctoral fellows in his group include Richard Zemel and Zoubin Ghahramani.", "token2charspan": [[0, 8], [9, 17], [18, 26], [27, 30], [31, 44], [45, 52], [53, 55], [56, 59], [60, 65], [66, 73], [74, 81], [82, 87], [88, 91], [92, 98], [99, 109], [109, 110]]}
{"doc_key": "ai-test-65", "ner": [[6, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Each", "prediction", "result", "or", "instance", "of", "the", "confusion", "matrix", "represents", "a", "point", "in", "the", "ROC", "space", "."], "sentence-detokenized": "Each prediction result or instance of the confusion matrix represents a point in the ROC space.", "token2charspan": [[0, 4], [5, 15], [16, 22], [23, 25], [26, 34], [35, 37], [38, 41], [42, 51], [52, 58], [59, 69], [70, 71], [72, 77], [78, 80], [81, 84], [85, 88], [89, 94], [94, 95]]}
{"doc_key": "ai-test-66", "ner": [[3, 3, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [17, 19, "product"], [20, 25, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 20, 25, "physical", "", false, false], [7, 8, 20, 25, "physical", "", false, false], [10, 11, 20, 25, "physical", "", false, false], [17, 19, 3, 3, "artifact", "", false, false], [17, 19, 7, 8, "artifact", "", false, false], [17, 19, 10, 11, "artifact", "", false, false], [17, 19, 20, 25, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "1997", ",", "Thrun", "and", "his", "colleagues", "Wolfram", "Burgard", "and", "Dieter", "Fox", "developed", "the", "world", "'s", "first", "robotic", "tour", "guide", "at", "the", "German", "Museum", "in", "Bonn", "(", "1997", ")", "."], "sentence-detokenized": "In 1997, Thrun and his colleagues Wolfram Burgard and Dieter Fox developed the world's first robotic tour guide at the German Museum in Bonn (1997).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 18], [19, 22], [23, 33], [34, 41], [42, 49], [50, 53], [54, 60], [61, 64], [65, 74], [75, 78], [79, 84], [84, 86], [87, 92], [93, 100], [101, 105], [106, 111], [112, 114], [115, 118], [119, 125], [126, 132], [133, 135], [136, 140], [141, 142], [142, 146], [146, 147], [147, 148]]}
{"doc_key": "ai-test-67", "ner": [[0, 1, "product"], [7, 7, "misc"], [22, 24, "field"], [26, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 0, 1, "part-of", "", false, false], [22, 24, 0, 1, "usage", "", false, false], [26, 27, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Word", "Net", "is", "a", "lexical", "database", "of", "semantic", "relationships", "between", "words", "in", "more", "than", "200", "languages", ".", "It", "is", "mainly", "used", "in", "natural", "language", "processing", "and", "artificial", "intelligence", "applications", "."], "sentence-detokenized": "WordNet is a lexical database of semantic relationships between words in more than 200 languages. It is mainly used in natural language processing and artificial intelligence applications.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 32], [33, 41], [42, 55], [56, 63], [64, 69], [70, 72], [73, 77], [78, 82], [83, 86], [87, 96], [96, 97], [98, 100], [101, 103], [104, 110], [111, 115], [116, 118], [119, 126], [127, 135], [136, 146], [147, 150], [151, 161], [162, 174], [175, 187], [187, 188]]}
{"doc_key": "ai-test-68", "ner": [[5, 7, "field"], [12, 15, "conference"], [18, 26, "conference"], [29, 29, "conference"], [32, 32, "conference"], [38, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 15, 5, 7, "topic", "", false, false], [12, 15, 38, 39, "topic", "", false, false], [18, 26, 5, 7, "topic", "", false, false], [18, 26, 38, 39, "topic", "", false, false], [29, 29, 5, 7, "topic", "", false, false], [29, 29, 38, 39, "topic", "", false, false], [32, 32, 5, 7, "topic", "", false, false], [32, 32, 38, 39, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Conferences", "in", "the", "field", "of", "natural", "language", "processing", ",", "such", "as", "the", "Association", "for", "Computational", "Linguistics", ",", "the", "North", "American", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "the", "EMNLP", "and", "the", "HLT", ",", "will", "include", "papers", "on", "speech", "processing", "."], "sentence-detokenized": "Conferences in the field of natural language processing, such as the Association for Computational Linguistics, the North American Chapter of the Association for Computational Linguistics, the EMNLP and the HLT, will include papers on speech processing.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 24], [25, 27], [28, 35], [36, 44], [45, 55], [55, 56], [57, 61], [62, 64], [65, 68], [69, 80], [81, 84], [85, 98], [99, 110], [110, 111], [112, 115], [116, 121], [122, 130], [131, 138], [139, 141], [142, 145], [146, 157], [158, 161], [162, 175], [176, 187], [187, 188], [189, 192], [193, 198], [199, 202], [203, 206], [207, 210], [210, 211], [212, 216], [217, 224], [225, 231], [232, 234], [235, 241], [242, 252], [252, 253]]}
{"doc_key": "ai-test-69", "ner": [[20, 22, "misc"], [32, 34, "misc"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "set", "of", "Java", "programs", "uses", "a", "lexicon", "to", "work", "through", "variations", "of", "biomedical", "texts", ",", "associating", "words", "by", "their", "parts", "of", "speech", ",", "which", "can", "be", "useful", "for", "web", "searches", "or", "electronic", "medical", "record", "searches", "."], "sentence-detokenized": "A set of Java programs uses a lexicon to work through variations of biomedical texts, associating words by their parts of speech, which can be useful for web searches or electronic medical record searches.", "token2charspan": [[0, 1], [2, 5], [6, 8], [9, 13], [14, 22], [23, 27], [28, 29], [30, 37], [38, 40], [41, 45], [46, 53], [54, 64], [65, 67], [68, 78], [79, 84], [84, 85], [86, 97], [98, 103], [104, 106], [107, 112], [113, 118], [119, 121], [122, 128], [128, 129], [130, 135], [136, 139], [140, 142], [143, 149], [150, 153], [154, 157], [158, 166], [167, 169], [170, 180], [181, 188], [189, 195], [196, 204], [204, 205]]}
{"doc_key": "ai-test-70", "ner": [[7, 7, "algorithm"], [9, 9, "algorithm"], [11, 11, "algorithm"], [13, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "many", "newer", "algorithms", "such", "as", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", "and", "others", "."], "sentence-detokenized": "There are many newer algorithms such as LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost and others.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 20], [21, 31], [32, 36], [37, 39], [40, 47], [47, 48], [49, 59], [59, 60], [61, 71], [71, 72], [73, 80], [80, 81], [82, 91], [92, 95], [96, 102], [102, 103]]}
{"doc_key": "ai-test-71", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "of", "a", "Python", "application", ":"], "sentence-detokenized": "This is an example of a Python application:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 23], [24, 30], [31, 42], [42, 43]]}
{"doc_key": "ai-test-72", "ner": [[0, 1, "organisation"], [2, 2, "product"], [7, 9, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 0, 1, "artifact", "made_by_company", false, false], [7, 9, 2, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Mattel", "'s", "Intellivision", "game", "console", "offered", "the", "Intellivoice", "Voice", "Synthesis", "module", "in", "1982", "."], "sentence-detokenized": "Mattel's Intellivision game console offered the Intellivoice Voice Synthesis module in 1982.", "token2charspan": [[0, 6], [6, 8], [9, 22], [23, 27], [28, 35], [36, 43], [44, 47], [48, 60], [61, 66], [67, 76], [77, 83], [84, 86], [87, 91], [91, 92]]}
{"doc_key": "ai-test-73", "ner": [[4, 5, "task"], [9, 16, "task"], [20, 20, "field"], [18, 19, "task"], [23, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 16, 4, 5, "part-of", "", false, false], [20, 20, 4, 5, "part-of", "", false, false], [18, 19, 4, 5, "part-of", "", false, false], [23, 28, 18, 19, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "also", "worked", "in", "machine", "translation", ",", "both", "in", "high", "-", "precision", "knowledge", "-", "based", "machine", "translation", "and", "statistical", "machine", "learning", "(", "e.g.", "generalised", "example", "-", "based", "machine", "translation", ")", "."], "sentence-detokenized": "He also worked in machine translation, both in high-precision knowledge-based machine translation and statistical machine learning (e.g. generalised example-based machine translation).", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 17], [18, 25], [26, 37], [37, 38], [39, 43], [44, 46], [47, 51], [51, 52], [52, 61], [62, 71], [71, 72], [72, 77], [78, 85], [86, 97], [98, 101], [102, 113], [114, 121], [122, 130], [131, 132], [132, 136], [137, 148], [149, 156], [156, 157], [157, 162], [163, 170], [171, 182], [182, 183], [183, 184]]}
{"doc_key": "ai-test-74", "ner": [[0, 1, "misc"], [7, 7, "misc"], [28, 29, "algorithm"], [31, 32, "field"], [34, 35, "field"], [37, 37, "field"], [39, 40, "field"], [42, 42, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 28, 29, "general-affiliation", "", false, false], [0, 1, 31, 32, "general-affiliation", "", false, false], [0, 1, 34, 35, "general-affiliation", "", false, false], [0, 1, 37, 37, "general-affiliation", "", false, false], [0, 1, 39, 40, "general-affiliation", "", false, false], [0, 1, 42, 42, "general-affiliation", "", false, false], [7, 7, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "commonly", "referred", "to", "as", "Mathematica", ")", "is", "a", "state", "-", "of", "-", "the", "-", "art", "technical", "computing", "system", "that", "spans", "most", "technical", "domains", "-", "including", "neural", "networks", ",", "machine", "learning", ",", "image", "processing", ",", "geometry", ",", "data", "science", ",", "visualization", "and", "more", "."], "sentence-detokenized": "Wolfram Mathematica (commonly referred to as Mathematica) is a state-of-the-art technical computing system that spans most technical domains - including neural networks, machine learning, image processing, geometry, data science, visualization and more.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 29], [30, 38], [39, 41], [42, 44], [45, 56], [56, 57], [58, 60], [61, 62], [63, 68], [68, 69], [69, 71], [71, 72], [72, 75], [75, 76], [76, 79], [80, 89], [90, 99], [100, 106], [107, 111], [112, 117], [118, 122], [123, 132], [133, 140], [141, 142], [143, 152], [153, 159], [160, 168], [168, 169], [170, 177], [178, 186], [186, 187], [188, 193], [194, 204], [204, 205], [206, 214], [214, 215], [216, 220], [221, 228], [228, 229], [230, 243], [244, 247], [248, 252], [252, 253]]}
{"doc_key": "ai-test-75", "ner": [[2, 5, "product"], [10, 12, "researcher"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 18, 2, 5, "type-of", "", false, false], [18, 18, 10, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "digitally", "controlled", "and", "programmed", "robot", "was", "invented", "by", "George", "Devol", "in", "1954", "and", "was", "eventually", "named", "Unimate", "."], "sentence-detokenized": "The first digitally controlled and programmed robot was invented by George Devol in 1954 and was eventually named Unimate.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 30], [31, 34], [35, 45], [46, 51], [52, 55], [56, 64], [65, 67], [68, 74], [75, 80], [81, 83], [84, 88], [89, 92], [93, 96], [97, 107], [108, 113], [114, 121], [121, 122]]}
{"doc_key": "ai-test-76", "ner": [[1, 1, "algorithm"], [3, 3, "algorithm"], [18, 18, "task"], [20, 21, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 3, 3, "compare", "", false, false], [3, 3, 18, 18, "general-affiliation", "", false, false], [3, 3, 20, 21, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Like", "DBNs", ",", "DBMs", "can", "learn", "complex", "and", "abstract", "internal", "representations", "of", "input", "data", "in", "tasks", "such", "as", "object", "or", "speech", "recognition", ",", "using", "limited", "labelled", "data", "to", "tune", "representations", "generated", "from", "large", "amounts", "of", "unlabelled", "sensory", "input", "data", "."], "sentence-detokenized": "Like DBNs, DBMs can learn complex and abstract internal representations of input data in tasks such as object or speech recognition, using limited labelled data to tune representations generated from large amounts of unlabelled sensory input data.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 15], [16, 19], [20, 25], [26, 33], [34, 37], [38, 46], [47, 55], [56, 71], [72, 74], [75, 80], [81, 85], [86, 88], [89, 94], [95, 99], [100, 102], [103, 109], [110, 112], [113, 119], [120, 131], [131, 132], [133, 138], [139, 146], [147, 155], [156, 160], [161, 163], [164, 168], [169, 184], [185, 194], [195, 199], [200, 205], [206, 213], [214, 216], [217, 227], [228, 235], [236, 241], [242, 246], [246, 247]]}
{"doc_key": "ai-test-77", "ner": [[6, 10, "task"], [14, 14, "conference"], [16, 16, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 6, 10, "topic", "", false, false], [16, 16, 6, 10, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "scientific", "conferences", "where", "work", "on", "vision", "-", "based", "activity", "recognition", "often", "appears", "are", "ICCV", "and", "CVPR", "."], "sentence-detokenized": "The scientific conferences where work on vision-based activity recognition often appears are ICCV and CVPR.", "token2charspan": [[0, 3], [4, 14], [15, 26], [27, 32], [33, 37], [38, 40], [41, 47], [47, 48], [48, 53], [54, 62], [63, 74], [75, 80], [81, 88], [89, 92], [93, 97], [98, 101], [102, 106], [106, 107]]}
{"doc_key": "ai-test-78", "ner": [[0, 3, "field"], [4, 5, "algorithm"], [7, 7, "algorithm"], [16, 17, "metrics"], [20, 21, "metrics"], [19, 34, "metrics"], [38, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 5, 0, 3, "part-of", "", false, false], [4, 5, 16, 17, "related-to", "finds", false, false], [4, 5, 20, 21, "related-to", "finds", false, false], [4, 5, 38, 39, "related-to", "", false, false], [7, 7, 4, 5, "named", "", false, false], [19, 34, 20, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "statistics", ",", "the", "Expectation", "Maximization", "(", "EM", ")", "algorithm", "is", "an", "iterative", "method", "for", "finding", "maximum", "likelihood", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "estimates", "of", "the", "parameters", "of", "statistical", "models", "when", "the", "model", "depends", "on", "unobserved", "latent", "variables", "."], "sentence-detokenized": "In statistics, the Expectation Maximization (EM) algorithm is an iterative method for finding maximum likelihood or maximum a posteriori (MAP) estimates of the parameters of statistical models when the model depends on unobserved latent variables.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 30], [31, 43], [44, 45], [45, 47], [47, 48], [49, 58], [59, 61], [62, 64], [65, 74], [75, 81], [82, 85], [86, 93], [94, 101], [102, 112], [113, 115], [116, 123], [124, 125], [126, 136], [137, 138], [138, 141], [141, 142], [143, 152], [153, 155], [156, 159], [160, 170], [171, 173], [174, 185], [186, 192], [193, 197], [198, 201], [202, 207], [208, 215], [216, 218], [219, 229], [230, 236], [237, 246], [246, 247]]}
{"doc_key": "ai-test-79", "ner": [[7, 11, "metrics"], [17, 17, "metrics"], [15, 19, "metrics"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[15, 19, 17, 17, "named", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Similarly", ",", "researchers", "sometimes", "report", "both", "a", "False", "Positive", "Rate", "(", "FPR", ")", "and", "a", "False", "Negative", "Rate", "(", "FNR", ")", "."], "sentence-detokenized": "Similarly, researchers sometimes report both a False Positive Rate (FPR) and a False Negative Rate (FNR).", "token2charspan": [[0, 9], [9, 10], [11, 22], [23, 32], [33, 39], [40, 44], [45, 46], [47, 52], [53, 61], [62, 66], [67, 68], [68, 71], [71, 72], [73, 76], [77, 78], [79, 84], [85, 93], [94, 98], [99, 100], [100, 103], [103, 104], [104, 105]]}
{"doc_key": "ai-test-80", "ner": [[6, 11, "metrics"], [13, 16, "field"], [19, 20, "metrics"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 16, 6, 11, "usage", "", false, false], [23, 24, 19, 20, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "concept", "is", "similar", "to", "the", "signal", "-", "to", "-", "noise", "ratio", "used", "in", "the", "natural", "sciences", "and", "the", "confusion", "matrix", "used", "in", "artificial", "intelligence", "."], "sentence-detokenized": "This concept is similar to the signal-to-noise ratio used in the natural sciences and the confusion matrix used in artificial intelligence.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 23], [24, 26], [27, 30], [31, 37], [37, 38], [38, 40], [40, 41], [41, 46], [47, 52], [53, 57], [58, 60], [61, 64], [65, 72], [73, 81], [82, 85], [86, 89], [90, 99], [100, 106], [107, 111], [112, 114], [115, 125], [126, 138], [138, 139]]}
{"doc_key": "ai-test-81", "ner": [[5, 6, "field"], [11, 12, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [33, 38, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 11, 12, "general-affiliation", "", false, false], [5, 6, 18, 19, "general-affiliation", "", false, false], [5, 6, 21, 22, "general-affiliation", "", false, false], [33, 38, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Code", "of", "Ethics", "for", "Human", "Enhancement", ",", "originally", "proposed", "by", "Steve", "Mann", "in", "2004", "and", "refined", "with", "Ray", "Kurzweil", "and", "Marvin", "Minsky", "in", "2013", ",", "was", "finally", "ratified", "on", "25", "June", "2017", "at", "the", "Toronto", "Virtual", "Reality", "Conference", "."], "sentence-detokenized": "The Code of Ethics for Human Enhancement, originally proposed by Steve Mann in 2004 and refined with Ray Kurzweil and Marvin Minsky in 2013, was finally ratified on 25 June 2017 at the Toronto Virtual Reality Conference.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 18], [19, 22], [23, 28], [29, 40], [40, 41], [42, 52], [53, 61], [62, 64], [65, 70], [71, 75], [76, 78], [79, 83], [84, 87], [88, 95], [96, 100], [101, 104], [105, 113], [114, 117], [118, 124], [125, 131], [132, 134], [135, 139], [139, 140], [141, 144], [145, 152], [153, 161], [162, 164], [165, 167], [168, 172], [173, 177], [178, 180], [181, 184], [185, 192], [193, 200], [201, 208], [209, 219], [219, 220]]}
{"doc_key": "ai-test-82", "ner": [[3, 5, "person"], [9, 13, "organisation"], [19, 20, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 9, 13, "role", "directed_for", false, false], [3, 5, 19, 20, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1913", ",", "Walter", "R.", "Booth", "directed", "10", "films", "for", "the", "UK", "cinema", "icon", ",", "probably", "in", "collaboration", "with", "Cecil", "Hepworth", "."], "sentence-detokenized": "In 1913, Walter R. Booth directed 10 films for the UK cinema icon, probably in collaboration with Cecil Hepworth.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 18], [19, 24], [25, 33], [34, 36], [37, 42], [43, 46], [47, 50], [51, 53], [54, 60], [61, 65], [65, 66], [67, 75], [76, 78], [79, 92], [93, 97], [98, 103], [104, 112], [112, 113]]}
{"doc_key": "ai-test-83", "ner": [[11, 11, "location"], [12, 13, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 11, 11, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "demonstrated", "their", "new", "robot", "at", "a", "trade", "fair", "at", "the", "Chicago", "Cow", "Palace", "in", "1961", "."], "sentence-detokenized": "They demonstrated their new robot at a trade fair at the Chicago Cow Palace in 1961.", "token2charspan": [[0, 4], [5, 17], [18, 23], [24, 27], [28, 33], [34, 36], [37, 38], [39, 44], [45, 49], [50, 52], [53, 56], [57, 64], [65, 68], [69, 75], [76, 78], [79, 83], [83, 84]]}
{"doc_key": "ai-test-84", "ner": [[6, 7, "task"], [10, 11, "field"], [15, 16, "field"]], "ner_mapping_to_source": [1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["While", "some", "chatbot", "applications", "use", "extensive", "word", "classification", "processes", ",", "natural", "language", "processors", "and", "sophisticated", "artificial", "intelligence", ",", "others", "simply", "search", "for", "generic", "keywords", "and", "generate", "answers", "using", "common", "phrases", "obtained", "from", "a", "linked", "library", "or", "database", "."], "sentence-detokenized": "While some chatbot applications use extensive word classification processes, natural language processors and sophisticated artificial intelligence, others simply search for generic keywords and generate answers using common phrases obtained from a linked library or database.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 31], [32, 35], [36, 45], [46, 50], [51, 65], [66, 75], [75, 76], [77, 84], [85, 93], [94, 104], [105, 108], [109, 122], [123, 133], [134, 146], [146, 147], [148, 154], [155, 161], [162, 168], [169, 172], [173, 180], [181, 189], [190, 193], [194, 202], [203, 210], [211, 216], [217, 223], [224, 231], [232, 240], [241, 245], [246, 247], [248, 254], [255, 262], [263, 265], [266, 274], [274, 275]]}
{"doc_key": "ai-test-85", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "WaveNet", "model", "proposed", "in", "2016", "achieves", "high", "performance", "in", "terms", "of", "call", "quality", "."], "sentence-detokenized": "The WaveNet model proposed in 2016 achieves high performance in terms of call quality.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 43], [44, 48], [49, 60], [61, 63], [64, 69], [70, 72], [73, 77], [78, 85], [85, 86]]}
{"doc_key": "ai-test-86", "ner": [[4, 4, "product"], [5, 7, "misc"], [9, 10, "misc"], [12, 13, "misc"], [15, 16, "misc"], [19, 21, "organisation"], [23, 23, "organisation"], [25, 26, "organisation"], [29, 29, "organisation"], [31, 34, "organisation"], [36, 36, "organisation"], [38, 38, "organisation"], [40, 42, "organisation"], [45, 45, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 4, 5, 7, "general-affiliation", "", false, false], [4, 4, 9, 10, "general-affiliation", "", false, false], [4, 4, 12, 13, "general-affiliation", "", false, false], [4, 4, 15, 16, "general-affiliation", "", false, false], [19, 21, 4, 4, "usage", "", false, false], [23, 23, 4, 4, "usage", "", false, false], [25, 26, 4, 4, "usage", "", false, false], [29, 29, 4, 4, "usage", "", false, false], [31, 34, 4, 4, "usage", "", false, false], [36, 36, 4, 4, "usage", "", false, false], [38, 38, 4, 4, "usage", "", false, false], [40, 42, 4, 4, "usage", "", false, false], [45, 45, 4, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organizations", "known", "to", "use", "ALE", "for", "emergency", "management", ",", "disaster", "relief", ",", "routine", "communications", "or", "emergency", "response", ":", "the", "American", "Red", "Cross", ",", "FEMA", ",", "disaster", "medical", "teams", ",", "NATO", ",", "Federal", "Bureau", "of", "Investigation", ",", "UN", ",", "AT&T", ",", "Civil", "Air", "Patrols", ",", "(", "ARES", ")", "."], "sentence-detokenized": "Organizations known to use ALE for emergency management, disaster relief, routine communications or emergency response: the American Red Cross, FEMA, disaster medical teams, NATO, Federal Bureau of Investigation, UN, AT&T, Civil Air Patrols, (ARES).", "token2charspan": [[0, 13], [14, 19], [20, 22], [23, 26], [27, 30], [31, 34], [35, 44], [45, 55], [55, 56], [57, 65], [66, 72], [72, 73], [74, 81], [82, 96], [97, 99], [100, 109], [110, 118], [118, 119], [120, 123], [124, 132], [133, 136], [137, 142], [142, 143], [144, 148], [148, 149], [150, 158], [159, 166], [167, 172], [172, 173], [174, 178], [178, 179], [180, 187], [188, 194], [195, 197], [198, 211], [211, 212], [213, 215], [215, 216], [217, 221], [221, 222], [223, 228], [229, 232], [233, 240], [240, 241], [242, 243], [243, 247], [247, 248], [248, 249]]}
{"doc_key": "ai-test-87", "ner": [[5, 7, "algorithm"], [16, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", ",", "for", "simplicity", ",", "the", "Kronecker", "delta", "is", "used", "(", "cf", ".", "the", "derivative", "of", "a", "sigmoid", "function", ",", "expressed", "by", "the", "function", "itself", ")", "."], "sentence-detokenized": "Here, for simplicity, the Kronecker delta is used (cf. the derivative of a sigmoid function, expressed by the function itself).", "token2charspan": [[0, 4], [4, 5], [6, 9], [10, 20], [20, 21], [22, 25], [26, 35], [36, 41], [42, 44], [45, 49], [50, 51], [51, 53], [53, 54], [55, 58], [59, 69], [70, 72], [73, 74], [75, 82], [83, 91], [91, 92], [93, 102], [103, 105], [106, 109], [110, 118], [119, 125], [125, 126], [126, 127]]}
{"doc_key": "ai-test-88", "ner": [[11, 12, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "theory", "is", "based", "on", "philosophical", "foundations", "and", "was", "established", "by", "Ray", "Solomonoff", "around", "1960", ".", "Samuel", "Rathmanner", "and", "Marcus", "Hutter", "."], "sentence-detokenized": "The theory is based on philosophical foundations and was established by Ray Solomonoff around 1960. Samuel Rathmanner and Marcus Hutter.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 36], [37, 48], [49, 52], [53, 56], [57, 68], [69, 71], [72, 75], [76, 86], [87, 93], [94, 98], [98, 99], [100, 106], [107, 117], [118, 121], [122, 128], [129, 135], [135, 136]]}
{"doc_key": "ai-test-89", "ner": [[0, 0, "product"], [8, 11, "misc"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 11, "type-of", "", false, false], [0, 0, 14, 15, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "a", "freely", "available", "database", "originally", "conceived", "as", "a", "semantic", "network", "based", "on", "psycholinguistic", "principles", ",", "has", "been", "extended", "to", "include", "definitions", "and", "is", "now", "also", "considered", "a", "dictionary", "."], "sentence-detokenized": "WordNet, a freely available database originally conceived as a semantic network based on psycholinguistic principles, has been extended to include definitions and is now also considered a dictionary.", "token2charspan": [[0, 7], [7, 8], [9, 10], [11, 17], [18, 27], [28, 36], [37, 47], [48, 57], [58, 60], [61, 62], [63, 71], [72, 79], [80, 85], [86, 88], [89, 105], [106, 116], [116, 117], [118, 121], [122, 126], [127, 135], [136, 138], [139, 146], [147, 158], [159, 162], [163, 165], [166, 169], [170, 174], [175, 185], [186, 187], [188, 198], [198, 199]]}
{"doc_key": "ai-test-90", "ner": [[2, 3, "field"], [15, 15, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 15, 2, 3, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Advances", "in", "computational", "imaging", "research", "have", "been", "reported", "in", "a", "number", "of", "places", ",", "including", "SIGGRAPH", "publications", "and", "."], "sentence-detokenized": "Advances in computational imaging research have been reported in a number of places, including SIGGRAPH publications and.", "token2charspan": [[0, 8], [9, 11], [12, 25], [26, 33], [34, 42], [43, 47], [48, 52], [53, 61], [62, 64], [65, 66], [67, 73], [74, 76], [77, 83], [83, 84], [85, 94], [95, 103], [104, 116], [117, 120], [120, 121]]}
{"doc_key": "ai-test-91", "ner": [[0, 0, "task"], [9, 10, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 0, "part-of", "", false, false], [12, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "treated", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multiclass", "classification", "."], "sentence-detokenized": "Classification can be treated as two separate problems - binary classification and multiclass classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 29], [30, 32], [33, 36], [37, 45], [46, 54], [55, 56], [57, 63], [64, 78], [79, 82], [83, 93], [94, 108], [108, 109]]}
{"doc_key": "ai-test-92", "ner": [[13, 13, "algorithm"], [18, 19, "algorithm"], [22, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 19, 13, 13, "type-of", "", false, false], [22, 22, 18, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Advanced", "gene", "discovery", "machines", "for", "both", "prokaryotic", "and", "eukaryotic", "genomes", "typically", "use", "sophisticated", "probabilistic", "models", ",", "such", "as", "hidden", "Markov", "models", "(", "HMMs", ")", ",", "to", "combine", "information", "from", "different", "signal", "and", "content", "measurements", "."], "sentence-detokenized": "Advanced gene discovery machines for both prokaryotic and eukaryotic genomes typically use sophisticated probabilistic models, such as hidden Markov models (HMMs), to combine information from different signal and content measurements.", "token2charspan": [[0, 8], [9, 13], [14, 23], [24, 32], [33, 36], [37, 41], [42, 53], [54, 57], [58, 68], [69, 76], [77, 86], [87, 90], [91, 104], [105, 118], [119, 125], [125, 126], [127, 131], [132, 134], [135, 141], [142, 148], [149, 155], [156, 157], [157, 161], [161, 162], [162, 163], [164, 166], [167, 174], [175, 186], [187, 191], [192, 201], [202, 208], [209, 212], [213, 220], [221, 233], [233, 234]]}
{"doc_key": "ai-test-93", "ner": [[0, 0, "misc"], [5, 6, "field"], [9, 10, "algorithm"], [13, 17, "algorithm"], [27, 28, "algorithm"]], "ner_mapping_to_source": [1, 2, 3, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Neuroevolution", "is", "a", "form", "of", "artificial", "intelligence", "that", "uses", "evolutionary", "algorithms", "to", "generate", "artificial", "neural", "networks", "(", "ANNs", ")", ",", "parameters", ",", "topology", "and", "rules", ".", "and", "evolutionary", "robotics", "."], "sentence-detokenized": "Neuroevolution is a form of artificial intelligence that uses evolutionary algorithms to generate artificial neural networks (ANNs), parameters, topology and rules. and evolutionary robotics.", "token2charspan": [[0, 14], [15, 17], [18, 19], [20, 24], [25, 27], [28, 38], [39, 51], [52, 56], [57, 61], [62, 74], [75, 85], [86, 88], [89, 97], [98, 108], [109, 115], [116, 124], [125, 126], [126, 130], [130, 131], [131, 132], [133, 143], [143, 144], [145, 153], [154, 157], [158, 163], [163, 164], [165, 168], [169, 181], [182, 190], [190, 191]]}
{"doc_key": "ai-test-94", "ner": [[1, 1, "organisation"], [6, 6, "metrics"], [9, 9, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 1, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "IBM", "proposed", "and", "implemented", "the", "BLEU", "system", ",", "Papinen", "et", "al", "."], "sentence-detokenized": "Since IBM proposed and implemented the BLEU system, Papinen et al.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 22], [23, 34], [35, 38], [39, 43], [44, 50], [50, 51], [52, 59], [60, 62], [63, 65], [65, 66]]}
{"doc_key": "ai-test-95", "ner": [[14, 18, "conference"], [20, 20, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 20, 14, 18, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2009", ",", "experts", "took", "part", "in", "a", "conference", "organised", "by", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "to", "discuss", "whether", "computers", "and", "robots", "could", "acquire", "autonomy", "and", "how", "much", "of", "a", "threat", "or", "threat", "these", "capabilities", "could", "pose", "."], "sentence-detokenized": "In 2009, experts took part in a conference organised by the Association for the Advancement of Artificial Intelligence (AAAI) to discuss whether computers and robots could acquire autonomy and how much of a threat or threat these capabilities could pose.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 21], [22, 26], [27, 29], [30, 31], [32, 42], [43, 52], [53, 55], [56, 59], [60, 71], [72, 75], [76, 79], [80, 91], [92, 94], [95, 105], [106, 118], [119, 120], [120, 124], [124, 125], [126, 128], [129, 136], [137, 144], [145, 154], [155, 158], [159, 165], [166, 171], [172, 179], [180, 188], [189, 192], [193, 196], [197, 201], [202, 204], [205, 206], [207, 213], [214, 216], [217, 223], [224, 229], [230, 242], [243, 248], [249, 253], [253, 254]]}
{"doc_key": "ai-test-96", "ner": [[26, 28, "researcher"], [30, 31, "researcher"], [33, 38, "task"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[33, 38, 26, 28, "artifact", "", false, false], [33, 38, 30, 31, "artifact", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["After", "boosting", ",", "a", "classifier", "constructed", "on", "the", "basis", "of", "200", "features", "can", "give", "a", "95", "%", "detection", "rate", "under", "^", "{", "-", "5", "}.", "/", "P", ".", "Viola", ",", "M.", "Jones", ",", "Robust", "Real", "-", "time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "After boosting, a classifier constructed on the basis of 200 features can give a 95% detection rate under ^ {-5}. / P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 17], [18, 28], [29, 40], [41, 43], [44, 47], [48, 53], [54, 56], [57, 60], [61, 69], [70, 73], [74, 78], [79, 80], [81, 83], [83, 84], [85, 94], [95, 99], [100, 105], [106, 107], [108, 109], [109, 110], [110, 111], [111, 113], [114, 115], [116, 117], [117, 118], [119, 124], [124, 125], [126, 128], [129, 134], [134, 135], [136, 142], [143, 147], [147, 148], [148, 152], [153, 159], [160, 169], [169, 170], [171, 175], [175, 176]]}
{"doc_key": "ai-test-97", "ner": [[9, 9, "organisation"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "website", "was", "originally", "Perl", "-", "based", ",", "but", "IMDb", "no", "longer", "discloses", "which", "software", "it", "uses", "for", "security", "reasons", "."], "sentence-detokenized": "The website was originally Perl-based, but IMDb no longer discloses which software it uses for security reasons.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 26], [27, 31], [31, 32], [32, 37], [37, 38], [39, 42], [43, 47], [48, 50], [51, 57], [58, 67], [68, 73], [74, 82], [83, 85], [86, 90], [91, 94], [95, 103], [104, 111], [111, 112]]}
{"doc_key": "ai-test-98", "ner": [[7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "start", "-", "up", "was", "founded", "by", "Demis", "Hassabis", ",", "Shane", "Legg", "and", "Mustafa", "Suleyman", "in", "2010", "."], "sentence-detokenized": "The start-up was founded by Demis Hassabis, Shane Legg and Mustafa Suleyman in 2010.", "token2charspan": [[0, 3], [4, 9], [9, 10], [10, 12], [13, 16], [17, 24], [25, 27], [28, 33], [34, 42], [42, 43], [44, 49], [50, 54], [55, 58], [59, 66], [67, 75], [76, 78], [79, 83], [83, 84]]}
{"doc_key": "ai-test-99", "ner": [[4, 5, "misc"], [8, 11, "metrics"], [26, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 4, 5, "type-of", "", false, false], [26, 27, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "very", "commonly", "used", "loss", "functions", "are", "the", "root", "mean", "square", "error", ",", "mathL", "(", "a", ")", "=", "a", "^", "2", "/", "math", ",", "and", "the", "absolute", "loss", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "/", "math", "."], "sentence-detokenized": "Two very commonly used loss functions are the root mean square error, mathL (a) = a ^ 2 / math, and the absolute loss, mathL (a) = | a | / math.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 27], [28, 37], [38, 41], [42, 45], [46, 50], [51, 55], [56, 62], [63, 68], [68, 69], [70, 75], [76, 77], [77, 78], [78, 79], [80, 81], [82, 83], [84, 85], [86, 87], [88, 89], [90, 94], [94, 95], [96, 99], [100, 103], [104, 112], [113, 117], [117, 118], [119, 124], [125, 126], [126, 127], [127, 128], [129, 130], [131, 132], [133, 134], [135, 136], [137, 138], [139, 143], [143, 144]]}
{"doc_key": "ai-test-100", "ner": [[3, 5, "algorithm"], [14, 15, "algorithm"], [12, 17, "algorithm"], [20, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 14, 15, "type-of", "example_of", false, false], [14, 15, 20, 22, "related-to", "", false, false], [12, 17, 14, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "soft", "-margin", "support", "vector", "machine", "described", "above", "is", "an", "example", "of", "an", "empirical", "risk", "minimisation", "(", "ERM", ")", "for", "joi", "nt", "loss", "."], "sentence-detokenized": "The soft-margin support vector machine described above is an example of an empirical risk minimisation (ERM) for joint loss.", "token2charspan": [[0, 3], [4, 8], [8, 15], [16, 23], [24, 30], [31, 38], [39, 48], [49, 54], [55, 57], [58, 60], [61, 68], [69, 71], [72, 74], [75, 84], [85, 89], [90, 102], [103, 104], [104, 107], [107, 108], [109, 112], [113, 116], [116, 118], [119, 123], [123, 124]]}
{"doc_key": "ai-test-101", "ner": [[8, 8, "task"], [10, 12, "task"], [21, 21, "organisation"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[10, 12, 8, 8, "type-of", "", false, false], [21, 21, 10, 12, "usage", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["A", "deep", "-", "learning", "-", "based", "approach", "to", "MT", ",", "neural", "machine", "translation", "has", "made", "rapid", "progress", "in", "recent", "years", "and", "Google", "has", "announced", "that", "its", "translation", "services", "now", "use", "this", "technology", "instead", "of", "previous", "statistical", "methods", "."], "sentence-detokenized": "A deep-learning-based approach to MT, neural machine translation has made rapid progress in recent years and Google has announced that its translation services now use this technology instead of previous statistical methods.", "token2charspan": [[0, 1], [2, 6], [6, 7], [7, 15], [15, 16], [16, 21], [22, 30], [31, 33], [34, 36], [36, 37], [38, 44], [45, 52], [53, 64], [65, 68], [69, 73], [74, 79], [80, 88], [89, 91], [92, 98], [99, 104], [105, 108], [109, 115], [116, 119], [120, 129], [130, 134], [135, 138], [139, 150], [151, 159], [160, 163], [164, 167], [168, 172], [173, 183], [184, 191], [192, 194], [195, 203], [204, 215], [216, 223], [223, 224]]}
{"doc_key": "ai-test-102", "ner": [[15, 15, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "usually", "gives", "a", "very", "large", "performance", "boost", "when", "working", "with", "large", "corpora", "such", "as", "WordNet", "."], "sentence-detokenized": "This usually gives a very large performance boost when working with large corpora such as WordNet.", "token2charspan": [[0, 4], [5, 12], [13, 18], [19, 20], [21, 25], [26, 31], [32, 43], [44, 49], [50, 54], [55, 62], [63, 67], [68, 73], [74, 81], [82, 86], [87, 89], [90, 97], [97, 98]]}
{"doc_key": "ai-test-103", "ner": [[0, 1, "task"], [4, 5, "field"], [17, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 17, 20, "part-of", "", false, false], [17, 20, 4, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Facial", "recognition", "is", "used", "in", "biometrics", ",", "often", "as", "part", "of", "(", "or", "in", "combination", "with", ")", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Facial recognition is used in biometrics, often as part of (or in combination with) a facial recognition system.", "token2charspan": [[0, 6], [7, 18], [19, 21], [22, 26], [27, 29], [30, 40], [40, 41], [42, 47], [48, 50], [51, 55], [56, 58], [59, 60], [60, 62], [63, 65], [66, 77], [78, 82], [82, 83], [84, 85], [86, 92], [93, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-104", "ner": [[2, 4, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["trained", "by", "maximum", "likelihood", "estimation", "."], "sentence-detokenized": "trained by maximum likelihood estimation.", "token2charspan": [[0, 7], [8, 10], [11, 18], [19, 29], [30, 40], [40, 41]]}
{"doc_key": "ai-test-105", "ner": [[2, 3, "country"], [5, 9, "organisation"], [13, 13, "location"], [15, 15, "country"], [17, 20, "organisation"], [21, 22, "country"], [27, 28, "organisation"], [33, 36, "organisation"], [37, 37, "country"], [48, 52, "organisation"], [53, 54, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[5, 9, 13, 13, "physical", "", false, false], [13, 13, 15, 15, "physical", "", false, false], [17, 20, 21, 22, "physical", "", false, false], [33, 36, 37, 37, "physical", "", false, false], [48, 52, 53, 54, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ltd", ".", "in", "Thailand", ";", "Komatsu", "(", "Shanghai", ")", "Ltd.", "in", "1996", "in", "Shanghai", ",", "China", ";", "Industrial", "Power", "Alliance", "Ltd.", "in", "Japan", ",", "a", "joint", "venture", "with", "Cummins", ",", "in", "1998", ";", "L&T-", "Komatsu", "Limited", "in", "India", "in", "1998", "(", "shares", "sold", "in", "2013", ")", ";", "and", "Komatsu", "Brasil", "International", "Ltda", ".", "Brazil", "in", "1998", "."], "sentence-detokenized": "Ltd. in Thailand; Komatsu (Shanghai) Ltd. in 1996 in Shanghai, China; Industrial Power Alliance Ltd. in Japan, a joint venture with Cummins, in 1998; L&T-Komatsu Limited in India in 1998 (shares sold in 2013); and Komatsu Brasil International Ltda. Brazil in 1998.", "token2charspan": [[0, 3], [3, 4], [5, 7], [8, 16], [16, 17], [18, 25], [26, 27], [27, 35], [35, 36], [37, 41], [42, 44], [45, 49], [50, 52], [53, 61], [61, 62], [63, 68], [68, 69], [70, 80], [81, 86], [87, 95], [96, 100], [101, 103], [104, 109], [109, 110], [111, 112], [113, 118], [119, 126], [127, 131], [132, 139], [139, 140], [141, 143], [144, 148], [148, 149], [150, 154], [154, 161], [162, 169], [170, 172], [173, 178], [179, 181], [182, 186], [187, 188], [188, 194], [195, 199], [200, 202], [203, 207], [207, 208], [208, 209], [210, 213], [214, 221], [222, 228], [229, 242], [243, 247], [247, 248], [249, 255], [256, 258], [259, 263], [263, 264]]}
{"doc_key": "ai-test-106", "ner": [[0, 1, "organisation"], [5, 9, "misc"], [14, 15, "person"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[14, 15, 0, 1, "physical", "", false, false], [14, 15, 5, 9, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "dgp", "also", "occasionally", "hosts", "artists", "-", "in", "-", "residence", "(", "e.g.", "Oscar", "winner", "Chris", "Landreth", "."], "sentence-detokenized": "The dgp also occasionally hosts artists-in-residence (e.g. Oscar winner Chris Landreth.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 25], [26, 31], [32, 39], [39, 40], [40, 42], [42, 43], [43, 52], [53, 54], [54, 58], [59, 64], [65, 71], [72, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-107", "ner": [[6, 8, "misc"], [10, 12, "misc"], [14, 17, "misc"], [21, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "currently", "four", "sub-competitions", "-", "RoboMaster", "Robotics", "Competition", ",", "RoboMaster", "Technical", "Challenge", ",", "ICRA", "RoboMaster", "AI", "Challenge", "and", "the", "new", "RoboMaster", "Youth", "Tournament", "."], "sentence-detokenized": "There are currently four sub-competitions - RoboMaster Robotics Competition, RoboMaster Technical Challenge, ICRA RoboMaster AI Challenge and the new RoboMaster Youth Tournament.", "token2charspan": [[0, 5], [6, 9], [10, 19], [20, 24], [25, 41], [42, 43], [44, 54], [55, 63], [64, 75], [75, 76], [77, 87], [88, 97], [98, 107], [107, 108], [109, 113], [114, 124], [125, 127], [128, 137], [138, 141], [142, 145], [146, 149], [150, 160], [161, 166], [167, 177], [177, 178]]}
{"doc_key": "ai-test-108", "ner": [[12, 17, "algorithm"], [21, 22, "algorithm"], [24, 25, "field"]], "ner_mapping_to_source": [1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["By", "the", "early", "2000s", ",", "the", "dominant", "speech", "processing", "strategy", "was", "moving", "away", "from", "the", "Hidden", "Markov", "Model", "towards", "more", "modern", "neural", "networks", "and", "deep", "learning", "."], "sentence-detokenized": "By the early 2000s, the dominant speech processing strategy was moving away from the Hidden Markov Model towards more modern neural networks and deep learning.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 18], [18, 19], [20, 23], [24, 32], [33, 39], [40, 50], [51, 59], [60, 63], [64, 70], [71, 75], [76, 80], [81, 84], [85, 91], [92, 98], [99, 104], [105, 112], [113, 117], [118, 124], [125, 131], [132, 140], [141, 144], [145, 149], [150, 158], [158, 159]]}
{"doc_key": "ai-test-109", "ner": [[3, 7, "misc"], [11, 13, "metrics"], [16, 18, "metrics"], [25, 27, "metrics"], [30, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 13, 16, 18, "related-to", "equal", false, false], [25, 27, 30, 32, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "equivalent", "expression", "for", "the", "binary", "target", "rate", "is", "that", "the", "TRUE", "positive", "rate", "and", "the", "FALSE", "positive", "rate", "are", "equal", "(", "and", "hence", "the", "FALSE", "negative", "rate", "and", "the", "TRUE", "negative", "rate", "are", "equal", ")", "for", "each", "sensitive", "attribute", "value", ":"], "sentence-detokenized": "Another equivalent expression for the binary target rate is that the TRUE positive rate and the FALSE positive rate are equal (and hence the FALSE negative rate and the TRUE negative rate are equal) for each sensitive attribute value:", "token2charspan": [[0, 7], [8, 18], [19, 29], [30, 33], [34, 37], [38, 44], [45, 51], [52, 56], [57, 59], [60, 64], [65, 68], [69, 73], [74, 82], [83, 87], [88, 91], [92, 95], [96, 101], [102, 110], [111, 115], [116, 119], [120, 125], [126, 127], [127, 130], [131, 136], [137, 140], [141, 146], [147, 155], [156, 160], [161, 164], [165, 168], [169, 173], [174, 182], [183, 187], [188, 191], [192, 197], [197, 198], [199, 202], [203, 207], [208, 217], [218, 227], [228, 233], [233, 234]]}
{"doc_key": "ai-test-110", "ner": [[0, 0, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["MATLAB", "function", ","], "sentence-detokenized": "MATLAB function,", "token2charspan": [[0, 6], [7, 15], [15, 16]]}
{"doc_key": "ai-test-111", "ner": [[0, 2, "product"], [7, 7, "misc"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 0, 2, "part-of", "", false, false], [15, 17, 0, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "articulated", "robot", "is", "a", "robot", "with", "rotating", "joints", "(", "e.g.", "a", "legged", "robot", "or", "an", "industrial", "robot", ")", "."], "sentence-detokenized": "An articulated robot is a robot with rotating joints (e.g. a legged robot or an industrial robot).", "token2charspan": [[0, 2], [3, 14], [15, 20], [21, 23], [24, 25], [26, 31], [32, 36], [37, 45], [46, 52], [53, 54], [54, 58], [59, 60], [61, 67], [68, 73], [74, 76], [77, 79], [80, 90], [91, 96], [96, 97], [97, 98]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [5, 6, "product"], [8, 9, "product"], [13, 15, "misc"], [19, 22, "product"], [29, 31, "misc"], [35, 35, "location"], [37, 37, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 13, 15, "general-affiliation", "nationality", false, false], [0, 0, 29, 31, "usage", "", false, false], [0, 0, 35, 35, "physical", "", false, false], [5, 6, 0, 0, "named", "", false, false], [8, 9, 0, 0, "named", "", false, false], [35, 35, 37, 37, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "also", "known", "as", "Pandora", "Media", "or", "Pandora", "Radio", ")", "is", "a", "US", "-", "based", "music", "streaming", "and", "automated", "recommendation", "service", "for", "Internet", "radio", ",", "powered", "by", "the", "Music", "Genome", "Project", "and", "headquartered", "in", "Oakland", ",", "California", "."], "sentence-detokenized": "Pandora (also known as Pandora Media or Pandora Radio) is a US-based music streaming and automated recommendation service for Internet radio, powered by the Music Genome Project and headquartered in Oakland, California.", "token2charspan": [[0, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 30], [31, 36], [37, 39], [40, 47], [48, 53], [53, 54], [55, 57], [58, 59], [60, 62], [62, 63], [63, 68], [69, 74], [75, 84], [85, 88], [89, 98], [99, 113], [114, 121], [122, 125], [126, 134], [135, 140], [140, 141], [142, 149], [150, 152], [153, 156], [157, 162], [163, 169], [170, 177], [178, 181], [182, 195], [196, 198], [199, 206], [206, 207], [208, 218], [218, 219]]}
{"doc_key": "ai-test-113", "ner": [[0, 15, "organisation"], [23, 25, "organisation"], [32, 33, "conference"], [46, 46, "conference"], [48, 48, "conference"], [50, 50, "conference"], [52, 52, "conference"], [54, 54, "conference"], [56, 56, "conference"], [58, 58, "conference"], [60, 60, "conference"], [62, 62, "conference"], [64, 64, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "Board", "of", "Directors", "of", "the", "International", "Society", "for", "Machine", "Learning", ",", "has", "been", "a", "member", "of", "the", "AAAI", "Executive", "Council", ",", "was", "Co-", "Chair", "of", "the", "ICML", "2011", "PC", ",", "and", "has", "been", "a", "senior", "PC", "member", "at", "conferences", "including", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "UAI", ",", "VLDB", ",", "WSDM", "and", "WWW", "."], "sentence-detokenized": "He is a member of the Board of Directors of the International Society for Machine Learning, has been a member of the AAAI Executive Council, was Co-Chair of the ICML 2011 PC, and has been a senior PC member at conferences including AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM and WWW.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 27], [28, 30], [31, 40], [41, 43], [44, 47], [48, 61], [62, 69], [70, 73], [74, 81], [82, 90], [90, 91], [92, 95], [96, 100], [101, 102], [103, 109], [110, 112], [113, 116], [117, 121], [122, 131], [132, 139], [139, 140], [141, 144], [145, 148], [148, 153], [154, 156], [157, 160], [161, 165], [166, 170], [171, 173], [173, 174], [175, 178], [179, 182], [183, 187], [188, 189], [190, 196], [197, 199], [200, 206], [207, 209], [210, 221], [222, 231], [232, 236], [236, 237], [238, 242], [242, 243], [244, 249], [249, 250], [251, 255], [255, 256], [257, 260], [260, 261], [262, 268], [268, 269], [270, 273], [273, 274], [275, 279], [279, 280], [281, 285], [286, 289], [290, 293], [293, 294]]}
{"doc_key": "ai-test-114", "ner": [[0, 2, "researcher"], [3, 10, "organisation"], [5, 12, "organisation"], [15, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 3, 10, "role", "", false, false], [5, 12, 3, 10, "named", "", false, false], [15, 20, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", "of", "the", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", "developed", "the", "Robocrane", ",", "in", "which", "the", "platform", "hangs", "from", "six", "cables", "instead", "of", "being", "supported", "by", "six", "towbars", "."], "sentence-detokenized": "James S. Albus of the National Institute of Standards and Technology (NIST) developed the Robocrane, in which the platform hangs from six cables instead of being supported by six towbars.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 17], [18, 21], [22, 30], [31, 40], [41, 43], [44, 53], [54, 57], [58, 68], [69, 70], [70, 74], [74, 75], [76, 85], [86, 89], [90, 99], [99, 100], [101, 103], [104, 109], [110, 113], [114, 122], [123, 128], [129, 133], [134, 137], [138, 144], [145, 152], [153, 155], [156, 161], [162, 171], [172, 174], [175, 178], [179, 186], [186, 187]]}
{"doc_key": "ai-test-115", "ner": [[3, 5, "algorithm"], [8, 9, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 3, 5, "type-of", "", false, false], [12, 13, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "class", "of", "direct", "search", "algorithms", "are", "various", "evolutionary", "algorithms", "such", "as", "genetic", "algorithms", "."], "sentence-detokenized": "Another class of direct search algorithms are various evolutionary algorithms such as genetic algorithms.", "token2charspan": [[0, 7], [8, 13], [14, 16], [17, 23], [24, 30], [31, 41], [42, 45], [46, 53], [54, 66], [67, 77], [78, 82], [83, 85], [86, 93], [94, 104], [104, 105]]}
{"doc_key": "ai-test-116", "ner": [[0, 0, "organisation"], [3, 3, "misc"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 0, 0, "named", "", false, false], [6, 7, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["KUKA", "is", "a", "German", "manufacturer", "of", "industrial", "robots", "and", "factory", "automation", "solutions", "."], "sentence-detokenized": "KUKA is a German manufacturer of industrial robots and factory automation solutions.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 16], [17, 29], [30, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 73], [74, 83], [83, 84]]}
{"doc_key": "ai-test-117", "ner": [[1, 1, "misc"], [6, 6, "person"], [9, 15, "misc"], [17, 17, "person"], [20, 20, "misc"], [22, 23, "person"], [25, 26, "misc"], [28, 29, "person"], [31, 33, "misc"], [35, 37, "person"], [39, 42, "misc"], [44, 45, "person"], [47, 50, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[6, 6, 1, 1, "usage", "", false, false], [9, 15, 6, 6, "artifact", "", false, false], [17, 17, 1, 1, "usage", "", false, false], [20, 20, 17, 17, "artifact", "", false, false], [22, 23, 1, 1, "usage", "", false, false], [25, 26, 22, 23, "artifact", "", false, false], [28, 29, 1, 1, "usage", "", false, false], [31, 33, 28, 29, "artifact", "", false, false], [35, 37, 1, 1, "usage", "", false, false], [39, 42, 35, 37, "artifact", "", false, false], [44, 45, 1, 1, "usage", "", false, false], [47, 50, 44, 45, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Other", "IMAX", "films", "from", "2016-2020", "include", "Zack", "Snyder", "'s", "Batman", "v", "Superman", ":", "Dawn", "of", "Justice", ",", "Clint", "Eastwood", "'s", "Sully", ",", "Damien", "Chazelle", "'s", "First", "Man", ",", "Patty", "Jenkins", "'", "Wonder", "Woman", "1984", ",", "Cary", "Joji", "Fukunaga", "'s", "No", "Time", "to", "Die", "and", "Joseph", "Kosinski", "'s", "Top", "Gun", ":", "Maverick", "."], "sentence-detokenized": "Other IMAX films from 2016-2020 include Zack Snyder's Batman v Superman: Dawn of Justice, Clint Eastwood's Sully, Damien Chazelle's First Man, Patty Jenkins' Wonder Woman 1984, Cary Joji Fukunaga's No Time to Die and Joseph Kosinski's Top Gun: Maverick.", "token2charspan": [[0, 5], [6, 10], [11, 16], [17, 21], [22, 31], [32, 39], [40, 44], [45, 51], [51, 53], [54, 60], [61, 62], [63, 71], [71, 72], [73, 77], [78, 80], [81, 88], [88, 89], [90, 95], [96, 104], [104, 106], [107, 112], [112, 113], [114, 120], [121, 129], [129, 131], [132, 137], [138, 141], [141, 142], [143, 148], [149, 156], [156, 157], [158, 164], [165, 170], [171, 175], [175, 176], [177, 181], [182, 186], [187, 195], [195, 197], [198, 200], [201, 205], [206, 208], [209, 212], [213, 216], [217, 223], [224, 232], [232, 234], [235, 238], [239, 242], [242, 243], [244, 252], [252, 253]]}
{"doc_key": "ai-test-118", "ner": [[3, 4, "misc"], [9, 12, "organisation"], [14, 16, "organisation"], [32, 35, "country"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[9, 12, 3, 4, "usage", "", false, false], [9, 12, 32, 35, "physical", "", false, false], [14, 16, 9, 12, "named", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Testing", "of", "the", "MICR", "E13B", "typeface", "was", "demonstrated", "to", "the", "American", "Bankers", "Association", "(", "ABA", ")", "in", "July", "1956", ",", "which", "adopted", "it", "in", "1958", "as", "the", "MICR", "standard", "for", "negotiable", "instruments", "in", "the", "United", "States", "."], "sentence-detokenized": "Testing of the MICR E13B typeface was demonstrated to the American Bankers Association (ABA) in July 1956, which adopted it in 1958 as the MICR standard for negotiable instruments in the United States.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 19], [20, 24], [25, 33], [34, 37], [38, 50], [51, 53], [54, 57], [58, 66], [67, 74], [75, 86], [87, 88], [88, 91], [91, 92], [93, 95], [96, 100], [101, 105], [105, 106], [107, 112], [113, 120], [121, 123], [124, 126], [127, 131], [132, 134], [135, 138], [139, 143], [144, 152], [153, 156], [157, 167], [168, 179], [180, 182], [183, 186], [187, 193], [194, 200], [200, 201]]}
{"doc_key": "ai-test-119", "ner": [[0, 2, "misc"], [19, 20, "field"], [23, 24, "field"], [27, 27, "field"], [29, 30, "field"], [32, 32, "field"], [34, 34, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[19, 20, 0, 2, "usage", "", false, false], [23, 24, 19, 20, "part-of", "", false, false], [27, 27, 0, 2, "usage", "", false, false], [29, 30, 0, 2, "usage", "", false, false], [32, 32, 0, 2, "usage", "", false, false], [34, 34, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Local", "search", "algorithms", "are", "widely", "applied", "to", "solve", "a", "wide", "range", "of", "difficult", "computational", "problems", ",", "including", "those", "in", "computer", "science", "(", "especially", "artificial", "intelligence", ")", ",", "mathematics", ",", "operations", "research", ",", "engineering", "and", "bioinformatics", "."], "sentence-detokenized": "Local search algorithms are widely applied to solve a wide range of difficult computational problems, including those in computer science (especially artificial intelligence), mathematics, operations research, engineering and bioinformatics.", "token2charspan": [[0, 5], [6, 12], [13, 23], [24, 27], [28, 34], [35, 42], [43, 45], [46, 51], [52, 53], [54, 58], [59, 64], [65, 67], [68, 77], [78, 91], [92, 100], [100, 101], [102, 111], [112, 117], [118, 120], [121, 129], [130, 137], [138, 139], [139, 149], [150, 160], [161, 173], [173, 174], [174, 175], [176, 187], [187, 188], [189, 199], [200, 208], [208, 209], [210, 221], [222, 225], [226, 240], [240, 241]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [8, 9, "location"], [11, 11, "country"], [15, 15, "country"], [23, 24, "algorithm"], [26, 26, "algorithm"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 8, 9, "physical", "", false, false], [0, 1, 15, 15, "general-affiliation", "nationality", false, false], [0, 1, 23, 24, "general-affiliation", "topic_of_study", false, false], [0, 1, 26, 26, "general-affiliation", "topic_of_study", false, false], [8, 9, 11, 11, "physical", "", false, false], [26, 26, 27, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "born", "September", "3", ",", "1947", "in", "Wallersdorf", ",", "Germany", ")", "is", "a", "German", "psychologist", "who", "has", "studied", "the", "use", "of", "bounded", "rationality", "and", "heuristics", "in", "decision", "making", "."], "sentence-detokenized": "Gerd Gigerenzer (born September 3, 1947 in Wallersdorf, Germany) is a German psychologist who has studied the use of bounded rationality and heuristics in decision making.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 21], [22, 31], [32, 33], [33, 34], [35, 39], [40, 42], [43, 54], [54, 55], [56, 63], [63, 64], [65, 67], [68, 69], [70, 76], [77, 89], [90, 93], [94, 97], [98, 105], [106, 109], [110, 113], [114, 116], [117, 124], [125, 136], [137, 140], [141, 151], [152, 154], [155, 163], [164, 170], [170, 171]]}
{"doc_key": "ai-test-121", "ner": [[4, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["in", "order", "to", "minimise", "the", "mean", "square", "error", "."], "sentence-detokenized": "in order to minimise the mean square error.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 20], [21, 24], [25, 29], [30, 36], [37, 42], [42, 43]]}
{"doc_key": "ai-test-122", "ner": [[13, 14, "misc"], [17, 18, "organisation"], [30, 32, "field"], [54, 55, "misc"], [67, 69, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 14, 17, 18, "origin", "", false, false], [54, 55, 67, 69, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "even", "an", "official", "language", "with", "a", "regulatory", "academy", ",", "such", "as", "standard", "French", "with", "the", "Acad\u00e9mie", "fran\u00e7aise", ",", "is", "classified", "(", "for", "example", ",", "in", "the", "field", "of", "natural", "language", "processing", ")", "as", "a", "natural", "language", "because", "its", "prescriptions", "do", "not", "make", "it", "a", "sufficiently", "constructed", "language", "to", "be", "classified", "as", "a", "constructed", "language", ",", "nor", "a", "sufficiently", "controlled", "language", "to", "be", "classified", "as", "a", "controlled", "natural", "language", "."], "sentence-detokenized": "However, even an official language with a regulatory academy, such as standard French with the Acad\u00e9mie fran\u00e7aise, is classified (for example, in the field of natural language processing) as a natural language because its prescriptions do not make it a sufficiently constructed language to be classified as a constructed language, nor a sufficiently controlled language to be classified as a controlled natural language.", "token2charspan": [[0, 7], [7, 8], [9, 13], [14, 16], [17, 25], [26, 34], [35, 39], [40, 41], [42, 52], [53, 60], [60, 61], [62, 66], [67, 69], [70, 78], [79, 85], [86, 90], [91, 94], [95, 103], [104, 113], [113, 114], [115, 117], [118, 128], [129, 130], [130, 133], [134, 141], [141, 142], [143, 145], [146, 149], [150, 155], [156, 158], [159, 166], [167, 175], [176, 186], [186, 187], [188, 190], [191, 192], [193, 200], [201, 209], [210, 217], [218, 221], [222, 235], [236, 238], [239, 242], [243, 247], [248, 250], [251, 252], [253, 265], [266, 277], [278, 286], [287, 289], [290, 292], [293, 303], [304, 306], [307, 308], [309, 320], [321, 329], [329, 330], [331, 334], [335, 336], [337, 349], [350, 360], [361, 369], [370, 372], [373, 375], [376, 386], [387, 389], [390, 391], [392, 402], [403, 410], [411, 419], [419, 420]]}
{"doc_key": "ai-test-123", "ner": [[13, 13, "metrics"], [16, 17, "metrics"], [19, 19, "metrics"], [36, 37, "metrics"], [39, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 19, 16, 17, "named", "", false, false], [39, 39, 36, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "a", "number", "of", "other", "metrics", ",", "the", "simplest", "of", "which", "is", "Accuracy", ",", "or", "Fraction", "Correct", "(", "FC", ")", ",", "which", "measures", "the", "proportion", "of", "all", "correctly", "categorised", "cases", ";", "it", "is", "complemented", "by", "Fraction", "Incorrect", "(", "FiC", ")", "."], "sentence-detokenized": "There are a number of other metrics, the simplest of which is Accuracy, or Fraction Correct (FC), which measures the proportion of all correctly categorised cases; it is complemented by Fraction Incorrect (FiC).", "token2charspan": [[0, 5], [6, 9], [10, 11], [12, 18], [19, 21], [22, 27], [28, 35], [35, 36], [37, 40], [41, 49], [50, 52], [53, 58], [59, 61], [62, 70], [70, 71], [72, 74], [75, 83], [84, 91], [92, 93], [93, 95], [95, 96], [96, 97], [98, 103], [104, 112], [113, 116], [117, 127], [128, 130], [131, 134], [135, 144], [145, 156], [157, 162], [162, 163], [164, 166], [167, 169], [170, 182], [183, 185], [186, 194], [195, 204], [205, 206], [206, 209], [209, 210], [210, 211]]}
{"doc_key": "ai-test-124", "ner": [[0, 0, "researcher"], [6, 10, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 10, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cardie", "became", "a", "member", "of", "the", "Association", "for", "Computational", "Linguistics", "in", "2016", "."], "sentence-detokenized": "Cardie became a member of the Association for Computational Linguistics in 2016.", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 22], [23, 25], [26, 29], [30, 41], [42, 45], [46, 59], [60, 71], [72, 74], [75, 79], [79, 80]]}
{"doc_key": "ai-test-125", "ner": [[12, 14, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Learning", "the", "parameters", "math", "\\", "theta", "/", "math", "is", "usually", "done", "by", "maximum", "likelihood", "learning", "for", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i", ";\\", "theta", ")", "/", "math", "."], "sentence-detokenized": "Learning the parameters math\\ theta / math is usually done by maximum likelihood learning for mathp (Y _ i | X _ i;\\ theta) / math.", "token2charspan": [[0, 8], [9, 12], [13, 23], [24, 28], [28, 29], [30, 35], [36, 37], [38, 42], [43, 45], [46, 53], [54, 58], [59, 61], [62, 69], [70, 80], [81, 89], [90, 93], [94, 99], [100, 101], [101, 102], [103, 104], [105, 106], [107, 108], [109, 110], [111, 112], [113, 114], [114, 116], [117, 122], [122, 123], [124, 125], [126, 130], [130, 131]]}
{"doc_key": "ai-test-126", "ner": [[0, 1, "task"], [3, 6, "algorithm"], [7, 8, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 0, 1, "usage", "", true, false], [7, 8, 3, 6, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cluster", "analysis", "and", "non-negative", "matrix", "factorisation", "for", "descriptive", "mining", "."], "sentence-detokenized": "Cluster analysis and non-negative matrix factorisation for descriptive mining.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 33], [34, 40], [41, 54], [55, 58], [59, 70], [71, 77], [77, 78]]}
{"doc_key": "ai-test-127", "ner": [[0, 3, "field"], [5, 6, "field"], [25, 27, "field"], [29, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[25, 27, 0, 3, "part-of", "", false, false], [25, 27, 5, 6, "part-of", "", false, false], [29, 30, 0, 3, "part-of", "", false, false], [29, 30, 5, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "computer", "science", "and", "computing", "that", "it", "enables", ",", "it", "has", "been", "a", "long", "-", "standing", "challenge", "to", "the", "ability", "of", "computers", "to", "do", "natural", "language", "processing", "and", "machine", "learning", "."], "sentence-detokenized": "In the computer science and computing that it enables, it has been a long-standing challenge to the ability of computers to do natural language processing and machine learning.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 23], [24, 27], [28, 37], [38, 42], [43, 45], [46, 53], [53, 54], [55, 57], [58, 61], [62, 66], [67, 68], [69, 73], [73, 74], [74, 82], [83, 92], [93, 95], [96, 99], [100, 107], [108, 110], [111, 120], [121, 123], [124, 126], [127, 134], [135, 143], [144, 154], [155, 158], [159, 166], [167, 175], [175, 176]]}
{"doc_key": "ai-test-128", "ner": [[3, 6, "algorithm"], [9, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 6, 9, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "The", "code", "for", "extracting", "Gabor", "features", "from", "images", "in", "MATLAB", "can", "be", "found", "at", "."], "sentence-detokenized": "(The code for extracting Gabor features from images in MATLAB can be found at.", "token2charspan": [[0, 1], [1, 4], [5, 9], [10, 13], [14, 24], [25, 30], [31, 39], [40, 44], [45, 51], [52, 54], [55, 61], [62, 65], [66, 68], [69, 74], [75, 77], [77, 78]]}
{"doc_key": "ai-test-129", "ner": [[5, 5, "misc"], [16, 17, "algorithm"], [21, 21, "task"], [23, 23, "task"], [25, 26, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 16, 17, "general-affiliation", "", false, false], [5, 5, 21, 21, "related-to", "solves_problem_of_type", false, false], [5, 5, 23, 23, "related-to", "solves_problem_of_type", false, false], [5, 5, 25, 26, "related-to", "solves_problem_of_type", false, false], [5, 5, 28, 29, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "design", "specifications", ",", "NeuralExpert", "focuses", "on", "the", "type", "of", "problem", "the", "user", "wants", "the", "neural", "network", "to", "solve", "(", "classification", ",", "prediction", ",", "feature", "approximation", "or", "clustering", "analysis", ")", "."], "sentence-detokenized": "In the design specifications, NeuralExpert focuses on the type of problem the user wants the neural network to solve (classification, prediction, feature approximation or clustering analysis).", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 28], [28, 29], [30, 42], [43, 50], [51, 53], [54, 57], [58, 62], [63, 65], [66, 73], [74, 77], [78, 82], [83, 88], [89, 92], [93, 99], [100, 107], [108, 110], [111, 116], [117, 118], [118, 132], [132, 133], [134, 144], [144, 145], [146, 153], [154, 167], [168, 170], [171, 181], [182, 190], [190, 191], [191, 192]]}
{"doc_key": "ai-test-130", "ner": [[2, 6, "misc"], [29, 31, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "size", "of", "the", "quantization", "step", "(", "\u0394", ")", "is", "small", "compared", "to", "the", "change", "in", "the", "quantizable", "signal", ",", "it", "is", "relatively", "easy", "to", "show", "that", "the", "mean", "squared", "error", "resulting", "from", "such", "rounding", "is", "approximately", "math", "\\", "Delta", "^", "2", "/", "12", "/", "math.math", ".", "math", "."], "sentence-detokenized": "If the size of the quantization step (\u0394) is small compared to the change in the quantizable signal, it is relatively easy to show that the mean squared error resulting from such rounding is approximately math\\ Delta ^ 2 / 12 / math.math. math.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 18], [19, 31], [32, 36], [37, 38], [38, 39], [39, 40], [41, 43], [44, 49], [50, 58], [59, 61], [62, 65], [66, 72], [73, 75], [76, 79], [80, 91], [92, 98], [98, 99], [100, 102], [103, 105], [106, 116], [117, 121], [122, 124], [125, 129], [130, 134], [135, 138], [139, 143], [144, 151], [152, 157], [158, 167], [168, 172], [173, 177], [178, 186], [187, 189], [190, 203], [204, 208], [208, 209], [210, 215], [216, 217], [218, 219], [220, 221], [222, 224], [225, 226], [227, 236], [236, 237], [238, 242], [242, 243]]}
{"doc_key": "ai-test-131", "ner": [[15, 15, "product"], [22, 25, "researcher"], [27, 28, "researcher"], [30, 42, "researcher"], [34, 44, "researcher"], [46, 48, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Compiling", "a", "rich", "lexicon", "with", "a", "suitable", "ontology", "requires", "considerable", "effort", ",", "for", "example", "the", "Wordnet", "lexicon", "required", "many", "human", "years", ".", "G.", "A", ".", "Miller", ",", "R.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Fellbaum", ".", "Gross", ",", "K", ".", "Miller", "."], "sentence-detokenized": "Compiling a rich lexicon with a suitable ontology requires considerable effort, for example the Wordnet lexicon required many human years. G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Beckwith, C. D. Fellbaum, D. Fellbaum. Gross, K. Miller.", "token2charspan": [[0, 9], [10, 11], [12, 16], [17, 24], [25, 29], [30, 31], [32, 40], [41, 49], [50, 58], [59, 71], [72, 78], [78, 79], [80, 83], [84, 91], [92, 95], [96, 103], [104, 111], [112, 120], [121, 125], [126, 131], [132, 137], [137, 138], [139, 141], [142, 143], [143, 144], [145, 151], [151, 152], [153, 155], [156, 164], [164, 165], [166, 168], [169, 171], [172, 180], [180, 181], [182, 184], [185, 193], [193, 194], [195, 197], [198, 200], [201, 209], [209, 210], [211, 213], [214, 222], [222, 223], [224, 229], [229, 230], [231, 232], [232, 233], [234, 240], [240, 241]]}
{"doc_key": "ai-test-132", "ner": [[0, 0, "organisation"], [21, 22, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[21, 22, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Kawasaki", "'s", "portfolio", "also", "includes", "retractable", "roofs", ",", "floors", "and", "other", "giant", "structures", ",", "such", "as", "the", "retractable", "surface", "of", "the", "Sapporo", "Dome", "."], "sentence-detokenized": "Kawasaki's portfolio also includes retractable roofs, floors and other giant structures, such as the retractable surface of the Sapporo Dome.", "token2charspan": [[0, 8], [8, 10], [11, 20], [21, 25], [26, 34], [35, 46], [47, 52], [52, 53], [54, 60], [61, 64], [65, 70], [71, 76], [77, 87], [87, 88], [89, 93], [94, 96], [97, 100], [101, 112], [113, 120], [121, 123], [124, 127], [128, 135], [136, 140], [140, 141]]}
{"doc_key": "ai-test-133", "ner": [[0, 1, "metrics"], [5, 7, "metrics"], [9, 11, "metrics"], [17, 18, "metrics"], [41, 41, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 17, 18, "related-to", "", false, false], [0, 1, 41, 41, "opposite", "alternative_to", false, false], [5, 7, 0, 1, "type-of", "", false, false], [9, 11, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kappa", "statistics", ",", "such", "as", "Fleiss", "'", "kappa", "and", "Cohen", "'s", "kappa", ",", "are", "methods", "for", "calculating", "inter-rater", "reliability", "based", "on", "different", "assumptions", "about", "marginal", "or", "prior", "distributions", ",", "and", "are", "increasingly", "being", "used", "as", "chance", "-", "corrected", "alternatives", "for", "estimating", "precision", "in", "other", "contexts", "."], "sentence-detokenized": "Kappa statistics, such as Fleiss' kappa and Cohen's kappa, are methods for calculating inter-rater reliability based on different assumptions about marginal or prior distributions, and are increasingly being used as chance-corrected alternatives for estimating precision in other contexts.", "token2charspan": [[0, 5], [6, 16], [16, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 39], [40, 43], [44, 49], [49, 51], [52, 57], [57, 58], [59, 62], [63, 70], [71, 74], [75, 86], [87, 98], [99, 110], [111, 116], [117, 119], [120, 129], [130, 141], [142, 147], [148, 156], [157, 159], [160, 165], [166, 179], [179, 180], [181, 184], [185, 188], [189, 201], [202, 207], [208, 212], [213, 215], [216, 222], [222, 223], [223, 232], [233, 245], [246, 249], [250, 260], [261, 270], [271, 273], [274, 279], [280, 288], [288, 289]]}
{"doc_key": "ai-test-134", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [18, 18, "researcher"], [27, 29, "algorithm"], [35, 35, "algorithm"], [31, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 18, 18, "role", "student_of", false, false], [7, 8, 18, 18, "role", "student_of", false, false], [10, 11, 18, 18, "role", "student_of", false, false], [13, 14, 18, 18, "role", "student_of", false, false], [35, 35, 4, 5, "origin", "", false, false], [35, 35, 7, 8, "origin", "", false, false], [35, 35, 10, 11, "origin", "", false, false], [35, 35, 13, 14, "origin", "", false, false], [35, 35, 18, 18, "origin", "", false, false], [35, 35, 27, 29, "type-of", "", false, false], [31, 37, 35, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Along", "with", "his", "students", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Graves", "and", "others", ",", "Schmidhuber", "published", "increasingly", "sophisticated", "versions", "of", "a", "type", "of", "recursive", "neural", "network", "called", "long", "short", "-", "term", "memory", "(", "LSTM", ")", "."], "sentence-detokenized": "Along with his students Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Graves and others, Schmidhuber published increasingly sophisticated versions of a type of recursive neural network called long short-term memory (LSTM).", "token2charspan": [[0, 5], [6, 10], [11, 14], [15, 23], [24, 28], [29, 39], [39, 40], [41, 46], [47, 51], [51, 52], [53, 57], [58, 65], [65, 66], [67, 71], [72, 78], [79, 82], [83, 89], [89, 90], [91, 102], [103, 112], [113, 125], [126, 139], [140, 148], [149, 151], [152, 153], [154, 158], [159, 161], [162, 171], [172, 178], [179, 186], [187, 193], [194, 198], [199, 204], [204, 205], [205, 209], [210, 216], [217, 218], [218, 222], [222, 223], [223, 224]]}
{"doc_key": "ai-test-135", "ner": [[4, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "The", "first", "Cobot", "KUKA", "LBR", "3", "is", "released", "."], "sentence-detokenized": "2004 - The first Cobot KUKA LBR 3 is released.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 16], [17, 22], [23, 27], [28, 31], [32, 33], [34, 36], [37, 45], [45, 46]]}
{"doc_key": "ai-test-136", "ner": [[11, 13, "algorithm"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Two", "superficial", "approaches", "used", "to", "train", "and", "then", "discriminate", "are", "the", "Naive", "Bayes", "classifier", "and", "decision", "trees", "."], "sentence-detokenized": "Two superficial approaches used to train and then discriminate are the Naive Bayes classifier and decision trees.", "token2charspan": [[0, 3], [4, 15], [16, 26], [27, 31], [32, 34], [35, 40], [41, 44], [45, 49], [50, 62], [63, 66], [67, 70], [71, 76], [77, 82], [83, 93], [94, 97], [98, 106], [107, 112], [112, 113]]}
{"doc_key": "ai-test-137", "ner": [[12, 13, "misc"], [0, 1, "person"], [3, 7, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 13, 0, 1, "origin", "", false, false], [12, 13, 3, 7, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Louis", "Daguerre", "and", "Henry", "Fox", "Talbot", "introduced", "the", "first", "practical", "forms", "of", "photography", "in", "January", "1839", "."], "sentence-detokenized": "Louis Daguerre and Henry Fox Talbot introduced the first practical forms of photography in January 1839.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 24], [25, 28], [29, 35], [36, 46], [47, 50], [51, 56], [57, 66], [67, 72], [73, 75], [76, 87], [88, 90], [91, 98], [99, 103], [103, 104]]}
{"doc_key": "ai-test-138", "ner": [[3, 4, "task"], [6, 7, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "speech", "synthesis", "with", "speech", "recognition", "enables", "communication", "with", "mobile", "devices", "via", "speech", "interfaces", "."], "sentence-detokenized": "For example, speech synthesis with speech recognition enables communication with mobile devices via speech interfaces.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 19], [20, 29], [30, 34], [35, 41], [42, 53], [54, 61], [62, 75], [76, 80], [81, 87], [88, 95], [96, 99], [100, 106], [107, 117], [117, 118]]}
{"doc_key": "ai-test-139", "ner": [[0, 0, "product"], [15, 15, "programlang"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 15, 15, "general-affiliation", "", false, false], [0, 0, 17, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Phidgets", "can", "be", "programmed", "using", "a", "wide", "range", "of", "software", "and", "programming", "languages", ",", "from", "Java", "to", "Microsoft", "Excel", "."], "sentence-detokenized": "Phidgets can be programmed using a wide range of software and programming languages, from Java to Microsoft Excel.", "token2charspan": [[0, 8], [9, 12], [13, 15], [16, 26], [27, 32], [33, 34], [35, 39], [40, 45], [46, 48], [49, 57], [58, 61], [62, 73], [74, 83], [83, 84], [85, 89], [90, 94], [95, 97], [98, 107], [108, 113], [113, 114]]}
{"doc_key": "ai-test-140", "ner": [[3, 8, "field"], [10, 14, "researcher"], [15, 17, "misc"], [21, 22, "field"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 8, 10, 14, "origin", "", false, false], [10, 14, 21, 22, "general-affiliation", "topic_of_study", false, false], [10, 14, 24, 25, "general-affiliation", "topic_of_study", false, false], [15, 17, 10, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "\"", "machine", "learning", "\"", "was", "coined", "in", "1959", "by", "Arthur", "Samuel", ",", "an", "American", "IBM", "employee", "and", "pioneer", "of", "computer", "games", "and", "artificial", "intelligence", "."], "sentence-detokenized": "The term \"machine learning\" was coined in 1959 by Arthur Samuel, an American IBM employee and pioneer of computer games and artificial intelligence.", "token2charspan": [[0, 3], [4, 8], [9, 10], [10, 17], [18, 26], [26, 27], [28, 31], [32, 38], [39, 41], [42, 46], [47, 49], [50, 56], [57, 63], [63, 64], [65, 67], [68, 76], [77, 80], [81, 89], [90, 93], [94, 101], [102, 104], [105, 113], [114, 119], [120, 123], [124, 134], [135, 147], [147, 148]]}
{"doc_key": "ai-test-141", "ner": [[10, 11, "misc"], [12, 13, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Fascinated", "by", "future", "technologies", "and", "their", "connection", "to", "art", ",", "Israeli", "poet", "David", "Avidan", "wanted", "to", "explore", "the", "use", "of", "computers", "to", "write", "literature", "."], "sentence-detokenized": "Fascinated by future technologies and their connection to art, Israeli poet David Avidan wanted to explore the use of computers to write literature.", "token2charspan": [[0, 10], [11, 13], [14, 20], [21, 33], [34, 37], [38, 43], [44, 54], [55, 57], [58, 61], [61, 62], [63, 70], [71, 75], [76, 81], [82, 88], [89, 95], [96, 98], [99, 106], [107, 110], [111, 114], [115, 117], [118, 127], [128, 130], [131, 136], [137, 147], [147, 148]]}
{"doc_key": "ai-test-142", "ner": [[4, 6, "misc"], [3, 3, "organisation"], [13, 13, "location"], [25, 29, "location"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[3, 3, 4, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2017", ",", "Oxbotica", "'s", "GATEway", "project", "tested", "seven", "autonomous", "bus", "routes", "in", "Greenwich", ",", "on", "a", "two", "-", "mile", "riverside", "road", "near", "London", "'s", "O2", "Arena", ",", "which", "is", "also", "used", "by", "pedestrians", "and", "cyclists", "."], "sentence-detokenized": "In 2017, Oxbotica's GATEway project tested seven autonomous bus routes in Greenwich, on a two-mile riverside road near London's O2 Arena, which is also used by pedestrians and cyclists.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 17], [17, 19], [20, 27], [28, 35], [36, 42], [43, 48], [49, 59], [60, 63], [64, 70], [71, 73], [74, 83], [83, 84], [85, 87], [88, 89], [90, 93], [93, 94], [94, 98], [99, 108], [109, 113], [114, 118], [119, 125], [125, 127], [128, 130], [131, 136], [136, 137], [138, 143], [144, 146], [147, 151], [152, 156], [157, 159], [160, 171], [172, 175], [176, 184], [184, 185]]}
{"doc_key": "ai-test-143", "ner": [[12, 15, "task"], [16, 18, "metrics"], [27, 29, "misc"], [32, 32, "metrics"], [30, 35, "metrics"], [37, 37, "metrics"], [39, 41, "metrics"], [44, 44, "metrics"], [46, 46, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9], "relations": [[16, 18, 27, 29, "related-to", "is_a", false, false], [16, 18, 32, 32, "usage", "", false, false], [32, 32, 46, 46, "named", "same", false, false], [30, 35, 44, 44, "opposite", "", false, false], [30, 35, 46, 46, "opposite", "", false, false], [37, 37, 30, 35, "named", "", false, false], [39, 41, 30, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 2, 4, 5, 6, 7, 8], "sentence": ["An", "unrelated", "but", "often", "used", "combination", "of", "the", "basic", "statistical", "indicators", "of", "information", "retrieval", "is", "the", "F", "-", "score", ",", "which", "is", "the", "(", "possibly", "weighted", ")", "harmonic", "mean", "of", "recall", "and", "precision", ",", "where", "recall", "=", "sensitivity", "=", "true", "positivity", "rate", ",", "but", "specificity", "and", "precision", "are", "completely", "different", "measures", "."], "sentence-detokenized": "An unrelated but often used combination of the basic statistical indicators of information retrieval is the F-score, which is the (possibly weighted) harmonic mean of recall and precision, where recall = sensitivity = true positivity rate, but specificity and precision are completely different measures.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 22], [23, 27], [28, 39], [40, 42], [43, 46], [47, 52], [53, 64], [65, 75], [76, 78], [79, 90], [91, 100], [101, 103], [104, 107], [108, 109], [109, 110], [110, 115], [115, 116], [117, 122], [123, 125], [126, 129], [130, 131], [131, 139], [140, 148], [148, 149], [150, 158], [159, 163], [164, 166], [167, 173], [174, 177], [178, 187], [187, 188], [189, 194], [195, 201], [202, 203], [204, 215], [216, 217], [218, 222], [223, 233], [234, 238], [238, 239], [240, 243], [244, 255], [256, 259], [260, 269], [270, 273], [274, 284], [285, 294], [295, 303], [303, 304]]}
{"doc_key": "ai-test-144", "ner": [[0, 1, "field"], [10, 10, "field"], [12, 12, "field"], [14, 14, "field"], [16, 17, "field"], [19, 20, "field"], [28, 29, "product"], [31, 34, "product"], [36, 37, "product"], [39, 40, "product"], [54, 56, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 10, "origin", "takes_inspiration_from", false, false], [0, 1, 12, 12, "origin", "takes_inspiration_from", false, false], [0, 1, 14, 14, "origin", "takes_inspiration_from", false, false], [0, 1, 16, 17, "origin", "takes_inspiration_from", false, false], [0, 1, 19, 20, "origin", "takes_inspiration_from", false, false], [28, 29, 0, 1, "origin", "", false, false], [31, 34, 0, 1, "origin", "", false, false], [36, 37, 0, 1, "origin", "", false, false], [39, 40, 0, 1, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Neuromorphic", "engineering", "is", "an", "interdisciplinary", "subject", "that", "draws", "inspiration", "from", "biology", ",", "physics", ",", "mathematics", ",", "computer", "science", "and", "electronics", "to", "design", "artificial", "neural", "systems", ",", "such", "as", "vision", "systems", ",", "head", "and", "eye", "systems", ",", "auditory", "processors", "and", "autonomous", "robots", ",", "whose", "physical", "architecture", "and", "design", "principles", "are", "based", "on", "the", "architecture", "of", "biological", "neural", "systems", "."], "sentence-detokenized": "Neuromorphic engineering is an interdisciplinary subject that draws inspiration from biology, physics, mathematics, computer science and electronics to design artificial neural systems, such as vision systems, head and eye systems, auditory processors and autonomous robots, whose physical architecture and design principles are based on the architecture of biological neural systems.", "token2charspan": [[0, 12], [13, 24], [25, 27], [28, 30], [31, 48], [49, 56], [57, 61], [62, 67], [68, 79], [80, 84], [85, 92], [92, 93], [94, 101], [101, 102], [103, 114], [114, 115], [116, 124], [125, 132], [133, 136], [137, 148], [149, 151], [152, 158], [159, 169], [170, 176], [177, 184], [184, 185], [186, 190], [191, 193], [194, 200], [201, 208], [208, 209], [210, 214], [215, 218], [219, 222], [223, 230], [230, 231], [232, 240], [241, 251], [252, 255], [256, 266], [267, 273], [273, 274], [275, 280], [281, 289], [290, 302], [303, 306], [307, 313], [314, 324], [325, 328], [329, 334], [335, 337], [338, 341], [342, 354], [355, 357], [358, 368], [369, 375], [376, 383], [383, 384]]}
{"doc_key": "ai-test-145", "ner": [[4, 6, "metrics"], [10, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 12, 4, 6, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["More", "specifically", ",", "the", "BIBO", "stability", "criterion", "requires", "that", "the", "ROC", "of", "the", "system", "contains", "a", "unit", "circle", "."], "sentence-detokenized": "More specifically, the BIBO stability criterion requires that the ROC of the system contains a unit circle.", "token2charspan": [[0, 4], [5, 17], [17, 18], [19, 22], [23, 27], [28, 37], [38, 47], [48, 56], [57, 61], [62, 65], [66, 69], [70, 72], [73, 76], [77, 83], [84, 92], [93, 94], [95, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-test-146", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "The", "program", "was", "rewritten", "in", "Java", "from", "1998", "."], "sentence-detokenized": "2 The program was rewritten in Java from 1998.", "token2charspan": [[0, 1], [2, 5], [6, 13], [14, 17], [18, 27], [28, 30], [31, 35], [36, 40], [41, 45], [45, 46]]}
{"doc_key": "ai-test-147", "ner": [[0, 0, "metrics"], [5, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 8, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MCC", "can", "be", "calculated", "directly", "from", "the", "confusion", "matrix", "using", "the", "formula", ":"], "sentence-detokenized": "MCC can be calculated directly from the confusion matrix using the formula:", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 21], [22, 30], [31, 35], [36, 39], [40, 49], [50, 56], [57, 62], [63, 66], [67, 74], [74, 75]]}
{"doc_key": "ai-test-148", "ner": [[7, 13, "organisation"], [18, 23, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 13, 18, 23, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "developed", "by", "a", "team", "from", "the", "MIT", "-", "IBM", "Watson", "AI", "Lab", "and", "first", "presented", "at", "the", "2018", "Learning", "Representations", "International", "Conference", "."], "sentence-detokenized": "It was developed by a team from the MIT-IBM Watson AI Lab and first presented at the 2018 Learning Representations International Conference.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 31], [32, 35], [36, 39], [39, 40], [40, 43], [44, 50], [51, 53], [54, 57], [58, 61], [62, 67], [68, 77], [78, 80], [81, 84], [85, 89], [90, 98], [99, 114], [115, 128], [129, 139], [139, 140]]}
{"doc_key": "ai-test-149", "ner": [[2, 5, "metrics"], [15, 16, "metrics"], [18, 20, "metrics"], [46, 46, "metrics"], [50, 53, "metrics"], [58, 58, "metrics"], [60, 60, "metrics"], [62, 64, "metrics"], [69, 70, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6, 7, 8, 9], "relations": [[15, 16, 46, 46, "type-of", "", false, false], [15, 16, 50, 53, "related-to", "collapses_to_identity", false, false], [18, 20, 50, 53, "related-to", "collapses_to_identity", false, false], [18, 20, 62, 64, "named", "same", false, false], [58, 58, 69, 70, "related-to", "collapses_to_identity", false, false], [60, 60, 69, 70, "related-to", "collapses_to_identity", false, false], [62, 64, 69, 70, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [0, 1, 3, 4, 5, 6, 7], "sentence": ["If", "the", "true", "frequencies", "of", "the", "two", "positive", "variables", "are", "equal", ",", "as", "expected", "for", "Fleiss", "kappa", "and", "F", "-", "score", ",", "i.e.", "the", "number", "of", "positive", "predictions", "corresponds", "to", "the", "number", "of", "positive", "classes", "in", "the", "dichotomous", "(", "two", "classes", ")", "case", ",", "the", "different", "kappa", "and", "correlation", "measures", "with", "Youden", "'s", "J", "will", "coincide", ",", "and", "recall", ",", "precision", "and", "F", "-", "score", "will", "be", "similarly", "identical", "in", "precision", "."], "sentence-detokenized": "If the true frequencies of the two positive variables are equal, as expected for Fleiss kappa and F-score, i.e. the number of positive predictions corresponds to the number of positive classes in the dichotomous (two classes) case, the different kappa and correlation measures with Youden's J will coincide, and recall, precision and F-score will be similarly identical in precision.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 23], [24, 26], [27, 30], [31, 34], [35, 43], [44, 53], [54, 57], [58, 63], [63, 64], [65, 67], [68, 76], [77, 80], [81, 87], [88, 93], [94, 97], [98, 99], [99, 100], [100, 105], [105, 106], [107, 111], [112, 115], [116, 122], [123, 125], [126, 134], [135, 146], [147, 158], [159, 161], [162, 165], [166, 172], [173, 175], [176, 184], [185, 192], [193, 195], [196, 199], [200, 211], [212, 213], [213, 216], [217, 224], [224, 225], [226, 230], [230, 231], [232, 235], [236, 245], [246, 251], [252, 255], [256, 267], [268, 276], [277, 281], [282, 288], [288, 290], [291, 292], [293, 297], [298, 306], [306, 307], [308, 311], [312, 318], [318, 319], [320, 329], [330, 333], [334, 335], [335, 336], [336, 341], [342, 346], [347, 349], [350, 359], [360, 369], [370, 372], [373, 382], [382, 383]]}
{"doc_key": "ai-test-150", "ner": [[15, 20, "misc"], [13, 17, "misc"], [21, 21, "conference"], [0, 5, "task"], [24, 24, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 20, 21, 21, "part-of", "", false, false], [15, 20, 21, 21, "physical", "", false, false], [15, 20, 21, 21, "temporal", "", false, false], [13, 17, 15, 20, "named", "", false, false], [0, 5, 15, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "first", "NLI", "joi", "nt", "exercise", "was", "held", "in", "the", "framework", "of", "the", "Building", "Educational", "Applications", "(", "BEA", ")", "workshop", "at", "NAACL", "2013", ".", "Tetreault", "et", "al", ",", "2013", "The", "competition", "resulted", "in", "29", "entries", "from", "teams", "around", "the", "world", ",", "24", "of", "which", "also", "published", "an", "article", "describing", "their", "systems", "and", "approaches", "."], "sentence-detokenized": "The first NLI joint exercise was held in the framework of the Building Educational Applications (BEA) workshop at NAACL 2013. Tetreault et al, 2013 The competition resulted in 29 entries from teams around the world, 24 of which also published an article describing their systems and approaches.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 17], [17, 19], [20, 28], [29, 32], [33, 37], [38, 40], [41, 44], [45, 54], [55, 57], [58, 61], [62, 70], [71, 82], [83, 95], [96, 97], [97, 100], [100, 101], [102, 110], [111, 113], [114, 119], [120, 124], [124, 125], [126, 135], [136, 138], [139, 141], [141, 142], [143, 147], [148, 151], [152, 163], [164, 172], [173, 175], [176, 178], [179, 186], [187, 191], [192, 197], [198, 204], [205, 208], [209, 214], [214, 215], [216, 218], [219, 221], [222, 227], [228, 232], [233, 242], [243, 245], [246, 253], [254, 264], [265, 270], [271, 278], [279, 282], [283, 293], [293, 294]]}
{"doc_key": "ai-test-151", "ner": [[0, 2, "algorithm"], [5, 8, "algorithm"], [14, 16, "misc"], [19, 21, "misc"], [36, 36, "misc"], [40, 41, "algorithm"], [32, 44, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 5, 8, "type-of", "", false, false], [0, 2, 14, 16, "related-to", "finds", false, false], [19, 21, 14, 16, "type-of", "", false, false], [32, 44, 40, 41, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Viterbi", "'s", "algorithm", "is", "a", "dynamic", "programming", "algorithm", "that", "finds", "the", "most", "likely", "sequence", "of", "hidden", "states", ",", "called", "Viterbi", "'s", "theorem", ",", "resulting", "in", "a", "sequence", "of", "observable", "events", ",", "especially", "in", "the", "context", "of", "Markov", "information", "sources", "and", "hidden", "Markov", "models", "(", "HMMs", ")", "."], "sentence-detokenized": "Viterbi's algorithm is a dynamic programming algorithm that finds the most likely sequence of hidden states, called Viterbi's theorem, resulting in a sequence of observable events, especially in the context of Markov information sources and hidden Markov models (HMMs).", "token2charspan": [[0, 7], [7, 9], [10, 19], [20, 22], [23, 24], [25, 32], [33, 44], [45, 54], [55, 59], [60, 65], [66, 69], [70, 74], [75, 81], [82, 90], [91, 93], [94, 100], [101, 107], [107, 108], [109, 115], [116, 123], [123, 125], [126, 133], [133, 134], [135, 144], [145, 147], [148, 149], [150, 158], [159, 161], [162, 172], [173, 179], [179, 180], [181, 191], [192, 194], [195, 198], [199, 206], [207, 209], [210, 216], [217, 228], [229, 236], [237, 240], [241, 247], [248, 254], [255, 261], [262, 263], [263, 267], [267, 268], [268, 269]]}
{"doc_key": "ai-test-152", "ner": [[0, 1, "field"], [3, 5, "algorithm"], [8, 10, "misc"], [12, 13, "algorithm"], [14, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 0, 1, "part-of", "", false, false], [3, 5, 8, 10, "general-affiliation", "", false, false], [3, 5, 12, 13, "related-to", "generalizes_from", false, false], [3, 5, 14, 16, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "statistics", ",", "multinomial", "logistic", "regression", "is", "a", "classification", "method", "that", "generalises", "logistic", "regression", "to", "multiclass", "classification", ",", "i.e.", "with", "more", "than", "two", "possible", "discrete", "outcomes", "."], "sentence-detokenized": "In statistics, multinomial logistic regression is a classification method that generalises logistic regression to multiclass classification, i.e. with more than two possible discrete outcomes.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 26], [27, 35], [36, 46], [47, 49], [50, 51], [52, 66], [67, 73], [74, 78], [79, 90], [91, 99], [100, 110], [111, 113], [114, 124], [125, 139], [139, 140], [141, 145], [146, 150], [151, 155], [156, 160], [161, 164], [165, 173], [174, 182], [183, 191], [191, 192]]}
{"doc_key": "ai-test-153", "ner": [[0, 2, "algorithm"], [9, 11, "field"], [13, 15, "field"], [18, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 9, 11, "part-of", "", false, false], [0, 2, 13, 15, "part-of", "", false, false], [18, 18, 0, 2, "usage", "", true, false], [20, 21, 0, 2, "usage", "", true, false], [23, 24, 0, 2, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hidden", "Markov", "Models", "are", "well", "known", "for", "their", "applications", "in", "reinforcement", "learning", "and", "temporal", "pattern", "recognition", "such", "as", "speech", ",", "handwriting", "recognition", ",", "gesture", "recognition", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Hidden Markov Models are well known for their applications in reinforcement learning and temporal pattern recognition such as speech, handwriting recognition, gesture recognition, Thad Starner, Alex Pentland.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 29], [30, 35], [36, 39], [40, 45], [46, 58], [59, 61], [62, 75], [76, 84], [85, 88], [89, 97], [98, 105], [106, 117], [118, 122], [123, 125], [126, 132], [132, 133], [134, 145], [146, 157], [157, 158], [159, 166], [167, 178], [178, 179], [180, 184], [185, 192], [192, 193], [194, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-test-154", "ner": [[8, 10, "misc"], [36, 40, "metrics"], [42, 44, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 42, 44, "named", "", false, false], [36, 40, 42, 44, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "essence", ",", "this", "means", "that", "if", "a", "word", "-", "gram", "has", "been", "seen", "more", "than", "k", "times", "during", "training", ",", "then", "the", "conditional", "probability", "of", "the", "word", ",", "given", "its", "history", ",", "is", "proportional", "to", "the", "maximum", "likelihood", "estimate", "of", "that", "word", "-", "gram", "."], "sentence-detokenized": "In essence, this means that if a word-gram has been seen more than k times during training, then the conditional probability of the word, given its history, is proportional to the maximum likelihood estimate of that word-gram.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 16], [17, 22], [23, 27], [28, 30], [31, 32], [33, 37], [37, 38], [38, 42], [43, 46], [47, 51], [52, 56], [57, 61], [62, 66], [67, 68], [69, 74], [75, 81], [82, 90], [90, 91], [92, 96], [97, 100], [101, 112], [113, 124], [125, 127], [128, 131], [132, 136], [136, 137], [138, 143], [144, 147], [148, 155], [155, 156], [157, 159], [160, 172], [173, 175], [176, 179], [180, 187], [188, 198], [199, 207], [208, 210], [211, 215], [216, 220], [220, 221], [221, 225], [225, 226]]}
{"doc_key": "ai-test-155", "ner": [[4, 7, "task"], [10, 11, "task"], [14, 16, "task"], [20, 22, "task"], [28, 33, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[28, 33, 20, 22, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "interested", "in", "the", "representation", "of", "knowledge", ",", "in", "commonsense", "reasoning", "and", "in", "natural", "language", "understanding", ",", "believing", "that", "deep", "language", "understanding", "can", "currently", "only", "be", "achieved", "by", "the", "significant", "manual", "development", "of", "semantically", "rich", "formalisms", "with", "statistical", "preferences", "."], "sentence-detokenized": "He is interested in the representation of knowledge, in commonsense reasoning and in natural language understanding, believing that deep language understanding can currently only be achieved by the significant manual development of semantically rich formalisms with statistical preferences.", "token2charspan": [[0, 2], [3, 5], [6, 16], [17, 19], [20, 23], [24, 38], [39, 41], [42, 51], [51, 52], [53, 55], [56, 67], [68, 77], [78, 81], [82, 84], [85, 92], [93, 101], [102, 115], [115, 116], [117, 126], [127, 131], [132, 136], [137, 145], [146, 159], [160, 163], [164, 173], [174, 178], [179, 181], [182, 190], [191, 193], [194, 197], [198, 209], [210, 216], [217, 228], [229, 231], [232, 244], [245, 249], [250, 260], [261, 265], [266, 277], [278, 289], [289, 290]]}
{"doc_key": "ai-test-156", "ner": [[0, 1, "programlang"], [3, 3, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["in", "JavaScript", ",", "Python", "or"], "sentence-detokenized": "in JavaScript, Python or", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 21], [22, 24]]}
{"doc_key": "ai-test-157", "ner": [[1, 2, "misc"], [5, 7, "misc"], [11, 11, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 5, 7, "part-of", "", false, false], [5, 7, 11, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Newcomb", "Awards", "are", "announced", "in", "AI", "Magazine", ",", "published", "by", "AAAI", "."], "sentence-detokenized": "The Newcomb Awards are announced in AI Magazine, published by AAAI.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 22], [23, 32], [33, 35], [36, 38], [39, 47], [47, 48], [49, 58], [59, 61], [62, 66], [66, 67]]}
{"doc_key": "ai-test-158", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "squared", "error", "on", "a", "test", "set", "of", "100", "is", "0.084", ",", "which", "is", "less", "than", "the", "unstandardised", "error", "."], "sentence-detokenized": "The mean squared error on a test set of 100 is 0.084, which is less than the unstandardised error.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 25], [26, 27], [28, 32], [33, 36], [37, 39], [40, 43], [44, 46], [47, 52], [52, 53], [54, 59], [60, 62], [63, 67], [68, 72], [73, 76], [77, 91], [92, 97], [97, 98]]}
{"doc_key": "ai-test-159", "ner": [[0, 2, "metrics"], [9, 11, "field"], [20, 23, "task"], [26, 27, "task"]], "ner_mapping_to_source": [0, 1, 3, 4], "relations": [[9, 11, 0, 2, "usage", "", false, false], [26, 27, 9, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 3], "sentence": ["F", "-", "scores", "have", "been", "widely", "used", "in", "the", "natural", "language", "processing", "literature", ",", "for", "example", "in", "the", "evaluation", "of", "name", "recognition", "(", "NER", ")", "and", "word", "segmentation", "."], "sentence-detokenized": "F-scores have been widely used in the natural language processing literature, for example in the evaluation of name recognition (NER) and word segmentation.", "token2charspan": [[0, 1], [1, 2], [2, 8], [9, 13], [14, 18], [19, 25], [26, 30], [31, 33], [34, 37], [38, 45], [46, 54], [55, 65], [66, 76], [76, 77], [78, 81], [82, 89], [90, 92], [93, 96], [97, 107], [108, 110], [111, 115], [116, 127], [128, 129], [129, 132], [132, 133], [134, 137], [138, 142], [143, 155], [155, 156]]}
{"doc_key": "ai-test-160", "ner": [[0, 0, "product"], [4, 7, "product"], [15, 16, "misc"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 15, 16, "related-to", "performs_task", false, false], [0, 0, 18, 19, "related-to", "performs_task", false, false], [4, 7, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Chatbots", "are", "typically", "used", "in", "dialogue", "systems", "for", "various", "purposes", ",", "including", "customer", "service", ",", "directing", "queries", "or", "collecting", "information", "."], "sentence-detokenized": "Chatbots are typically used in dialogue systems for various purposes, including customer service, directing queries or collecting information.", "token2charspan": [[0, 8], [9, 12], [13, 22], [23, 27], [28, 30], [31, 39], [40, 47], [48, 51], [52, 59], [60, 68], [68, 69], [70, 79], [80, 88], [89, 96], [96, 97], [98, 107], [108, 115], [116, 118], [119, 129], [130, 141], [141, 142]]}
{"doc_key": "ai-test-161", "ner": [[3, 9, "conference"], [13, 21, "conference"], [27, 37, "conference"], [43, 43, "conference"], [46, 49, "conference"], [51, 52, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 21, 3, 9, "named", "", false, false], [27, 37, 3, 9, "named", "", false, false], [43, 43, 27, 37, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Important", "journals", "are", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "later", "renamed", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "and", "since", "September", "2014", "renamed", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "-", "following", "the", "merger", "with", "ACM", ")", ",", "Computer", "Speech", "and", "Language", "and", "Speech", "Communication", "."], "sentence-detokenized": "Important journals are IEEE Transactions on Speech and Audio Processing (later renamed IEEE Transactions on Audio, Speech and Language Processing and since September 2014 renamed IEEE/ACM Transactions on Audio, Speech and Language Processing - following the merger with ACM), Computer Speech and Language and Speech Communication.", "token2charspan": [[0, 9], [10, 18], [19, 22], [23, 27], [28, 40], [41, 43], [44, 50], [51, 54], [55, 60], [61, 71], [72, 73], [73, 78], [79, 86], [87, 91], [92, 104], [105, 107], [108, 113], [113, 114], [115, 121], [122, 125], [126, 134], [135, 145], [146, 149], [150, 155], [156, 165], [166, 170], [171, 178], [179, 183], [183, 184], [184, 187], [188, 200], [201, 203], [204, 209], [209, 210], [211, 217], [218, 221], [222, 230], [231, 241], [242, 243], [244, 253], [254, 257], [258, 264], [265, 269], [270, 273], [273, 274], [274, 275], [276, 284], [285, 291], [292, 295], [296, 304], [305, 308], [309, 315], [316, 329], [329, 330]]}
{"doc_key": "ai-test-162", "ner": [[0, 1, "algorithm"], [4, 6, "task"], [7, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 0, 1, "usage", "", false, false], [4, 6, 7, 9, "part-of", "task_part_of_field", false, false], [4, 6, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["EM", "is", "often", "used", "to", "group", "data", "in", "machine", "learning", "and", "computer", "vision", "."], "sentence-detokenized": "EM is often used to group data in machine learning and computer vision.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 16], [17, 19], [20, 25], [26, 30], [31, 33], [34, 41], [42, 50], [51, 54], [55, 63], [64, 70], [70, 71]]}
{"doc_key": "ai-test-163", "ner": [[8, 17, "metrics"], [25, 28, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 17, 25, 28, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["While", "there", "is", "no", "perfect", "way", "to", "describe", "the", "matrix", "of", "TRUE", "and", "FALSE", "positive", "and", "negative", "mixed", "results", "with", "a", "single", "number", ",", "the", "Matthews", "correlation", "coefficient", "is", "generally", "considered", "one", "of", "the", "best", "such", "measures", "."], "sentence-detokenized": "While there is no perfect way to describe the matrix of TRUE and FALSE positive and negative mixed results with a single number, the Matthews correlation coefficient is generally considered one of the best such measures.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 17], [18, 25], [26, 29], [30, 32], [33, 41], [42, 45], [46, 52], [53, 55], [56, 60], [61, 64], [65, 70], [71, 79], [80, 83], [84, 92], [93, 98], [99, 106], [107, 111], [112, 113], [114, 120], [121, 127], [127, 128], [129, 132], [133, 141], [142, 153], [154, 165], [166, 168], [169, 178], [179, 189], [190, 193], [194, 196], [197, 200], [201, 205], [206, 210], [211, 219], [219, 220]]}
{"doc_key": "ai-test-164", "ner": [[12, 13, "field"], [29, 30, "field"], [33, 35, "field"], [39, 40, "algorithm"], [42, 43, "task"], [45, 46, "algorithm"], [51, 53, "algorithm"], [55, 56, "algorithm"], [62, 64, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[33, 35, 29, 30, "part-of", "subfield", false, false], [39, 40, 33, 35, "part-of", "", false, true], [42, 43, 33, 35, "part-of", "", false, true], [45, 46, 33, 35, "part-of", "", false, true], [51, 53, 33, 35, "part-of", "", false, true], [55, 56, 33, 35, "part-of", "", false, true], [62, 64, 33, 35, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "data", "sets", "have", "grown", "in", "size", "and", "complexity", ",", "direct", "practical", "data", "analysis", "has", "been", "complemented", "by", "indirect", ",", "automated", "data", "processing", ",", "aided", "by", "other", "discoveries", "in", "computer", "science", ",", "particularly", "in", "machine", "learning", ",", "such", "as", "neural", "networks", ",", "cluster", "analysis", ",", "genetic", "algorithms", "(", "1950s", ")", ",", "decision", "tree", "learning", "and", "decision", "rules", "(", "1960", "s", ")", "and", "support", "vector", "machines", "(", "1990", "s", ")", "."], "sentence-detokenized": "As data sets have grown in size and complexity, direct practical data analysis has been complemented by indirect, automated data processing, aided by other discoveries in computer science, particularly in machine learning, such as neural networks, cluster analysis, genetic algorithms (1950s), decision tree learning and decision rules (1960s) and support vector machines (1990s).", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 17], [18, 23], [24, 26], [27, 31], [32, 35], [36, 46], [46, 47], [48, 54], [55, 64], [65, 69], [70, 78], [79, 82], [83, 87], [88, 100], [101, 103], [104, 112], [112, 113], [114, 123], [124, 128], [129, 139], [139, 140], [141, 146], [147, 149], [150, 155], [156, 167], [168, 170], [171, 179], [180, 187], [187, 188], [189, 201], [202, 204], [205, 212], [213, 221], [221, 222], [223, 227], [228, 230], [231, 237], [238, 246], [246, 247], [248, 255], [256, 264], [264, 265], [266, 273], [274, 284], [285, 286], [286, 291], [291, 292], [292, 293], [294, 302], [303, 307], [308, 316], [317, 320], [321, 329], [330, 335], [336, 337], [337, 341], [341, 342], [342, 343], [344, 347], [348, 355], [356, 362], [363, 371], [372, 373], [373, 377], [377, 378], [378, 379], [379, 380]]}
{"doc_key": "ai-test-165", "ner": [[6, 6, "researcher"], [11, 14, "misc"], [20, 21, "researcher"], [23, 24, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 14, 6, 6, "artifact", "", false, false], [11, 14, 20, 21, "artifact", "", false, false], [11, 14, 23, 24, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "autumn", "of", "2005", ",", "Thrun", "published", "a", "textbook", ",", "Probabilistic", "Robotics", ",", "with", "his", "long", "-", "time", "colleagues", "Dieter", "Fox", "and", "Wolfram", "Burgard", "."], "sentence-detokenized": "In the autumn of 2005, Thrun published a textbook, Probabilistic Robotics, with his long-time colleagues Dieter Fox and Wolfram Burgard.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 21], [21, 22], [23, 28], [29, 38], [39, 40], [41, 49], [49, 50], [51, 64], [65, 73], [73, 74], [75, 79], [80, 83], [84, 88], [88, 89], [89, 93], [94, 104], [105, 111], [112, 115], [116, 119], [120, 127], [128, 135], [135, 136]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "and", "Pereiramath", "follows", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum and Pereiramath follows:", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 37], [38, 49], [50, 57], [57, 58]]}
{"doc_key": "ai-test-167", "ner": [[0, 1, "task"], [3, 3, "task"], [9, 10, "field"], [15, 16, "field"], [19, 20, "field"], [22, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 15, 16, "part-of", "task_part_of_field", false, false], [0, 1, 19, 20, "part-of", "task_part_of_field", false, false], [3, 3, 0, 1, "named", "", false, false], [15, 16, 9, 10, "part-of", "subfield", false, false], [19, 20, 9, 10, "part-of", "subfield", false, false], [22, 24, 19, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Question", "Answering", "(", "QA", ")", "is", "a", "field", "of", "computer", "science", "within", "the", "field", "of", "Information", "Retrieval", "and", "Natural", "Language", "Processing", "(", "NLP", ")", "that", "deals", "with", "the", "creation", "of", "systems", "that", "automatically", "answer", "questions", "asked", "by", "people", "in", "natural", "language", "."], "sentence-detokenized": "Question Answering (QA) is a field of computer science within the field of Information Retrieval and Natural Language Processing (NLP) that deals with the creation of systems that automatically answer questions asked by people in natural language.", "token2charspan": [[0, 8], [9, 18], [19, 20], [20, 22], [22, 23], [24, 26], [27, 28], [29, 34], [35, 37], [38, 46], [47, 54], [55, 61], [62, 65], [66, 71], [72, 74], [75, 86], [87, 96], [97, 100], [101, 108], [109, 117], [118, 128], [129, 130], [130, 133], [133, 134], [135, 139], [140, 145], [146, 150], [151, 154], [155, 163], [164, 166], [167, 174], [175, 179], [180, 193], [194, 200], [201, 210], [211, 216], [217, 219], [220, 226], [227, 229], [230, 237], [238, 246], [246, 247]]}
{"doc_key": "ai-test-168", "ner": [[9, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "the", "version", "of", "the", "metric", "used", "in", "NIST", "assessments", "prior", "to", "2009", "used", "the", "shortest", "comparative", "clause", "instead", "."], "sentence-detokenized": "However, the version of the metric used in NIST assessments prior to 2009 used the shortest comparative clause instead.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 20], [21, 23], [24, 27], [28, 34], [35, 39], [40, 42], [43, 47], [48, 59], [60, 65], [66, 68], [69, 73], [74, 78], [79, 82], [83, 91], [92, 103], [104, 110], [111, 118], [118, 119]]}
{"doc_key": "ai-test-169", "ner": [[5, 5, "person"], [13, 13, "organisation"], [14, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 14, 14, "related-to", "invests_in", false, false], [14, 14, 13, 13, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["On", "27", "August", "2018", ",", "Toyota", "announced", "a", "$", "500", "million", "investment", "in", "Uber", "autonomous", "cars", "."], "sentence-detokenized": "On 27 August 2018, Toyota announced a $500 million investment in Uber autonomous cars.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 17], [17, 18], [19, 25], [26, 35], [36, 37], [38, 39], [39, 42], [43, 50], [51, 61], [62, 64], [65, 69], [70, 80], [81, 85], [85, 86]]}
{"doc_key": "ai-test-170", "ner": [[5, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sample", "maximum", "is", "an", "estimator", "of", "the", "maximum", "likelihood", "of", "the", "population", "maximum", ",", "but", "as", "mentioned", "above", ",", "it", "is", "biased", "."], "sentence-detokenized": "The sample maximum is an estimator of the maximum likelihood of the population maximum, but as mentioned above, it is biased.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 21], [22, 24], [25, 34], [35, 37], [38, 41], [42, 49], [50, 60], [61, 63], [64, 67], [68, 78], [79, 86], [86, 87], [88, 91], [92, 94], [95, 104], [105, 110], [110, 111], [112, 114], [115, 117], [118, 124], [124, 125]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [4, 4, "misc"], [7, 7, "metrics"], [18, 20, "algorithm"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 4, 4, "related-to", "overcomes", false, false], [0, 0, 7, 7, "related-to", "increases", false, false], [4, 4, 18, 20, "opposite", "", false, false], [4, 4, 22, 24, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LSI", "helps", "to", "overcome", "synonymity", "by", "increasing", "recall", ",", "which", "is", "one", "of", "the", "most", "problematic", "limitations", "of", "Boolean", "keyword", "queries", "and", "vector", "space", "models", "."], "sentence-detokenized": "LSI helps to overcome synonymity by increasing recall, which is one of the most problematic limitations of Boolean keyword queries and vector space models.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 21], [22, 32], [33, 35], [36, 46], [47, 53], [53, 54], [55, 60], [61, 63], [64, 67], [68, 70], [71, 74], [75, 79], [80, 91], [92, 103], [104, 106], [107, 114], [115, 122], [123, 130], [131, 134], [135, 141], [142, 147], [148, 154], [154, 155]]}
{"doc_key": "ai-test-172", "ner": [[0, 1, "task"], [21, 21, "programlang"], [23, 23, "programlang"], [25, 25, "programlang"], [27, 28, "programlang"], [30, 30, "programlang"], [32, 32, "programlang"], [34, 34, "programlang"], [36, 36, "programlang"], [38, 38, "programlang"], [40, 40, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 21, 21, "general-affiliation", "", false, false], [0, 1, 23, 23, "general-affiliation", "", false, false], [0, 1, 25, 25, "general-affiliation", "", false, false], [0, 1, 27, 28, "general-affiliation", "", false, false], [0, 1, 30, 30, "general-affiliation", "", false, false], [0, 1, 32, 32, "general-affiliation", "", false, false], [0, 1, 34, 34, "general-affiliation", "", false, false], [0, 1, 36, 36, "general-affiliation", "", false, false], [0, 1, 38, 38, "general-affiliation", "", false, false], [0, 1, 40, 40, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Data", "collection", "applications", "are", "usually", "controlled", "by", "software", "programs", "developed", "using", "a", "variety", "of", "general", "-", "purpose", "programming", "languages", "such", "as", "assembly", ",", "BASIC", ",", "C", ",", "C", "++", ",", "C#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", ",", "etc."], "sentence-detokenized": "Data collection applications are usually controlled by software programs developed using a variety of general-purpose programming languages such as assembly, BASIC, C, C++, C#, Fortran, Java, LabVIEW, Lisp, Pascal, etc.", "token2charspan": [[0, 4], [5, 15], [16, 28], [29, 32], [33, 40], [41, 51], [52, 54], [55, 63], [64, 72], [73, 82], [83, 88], [89, 90], [91, 98], [99, 101], [102, 109], [109, 110], [110, 117], [118, 129], [130, 139], [140, 144], [145, 147], [148, 156], [156, 157], [158, 163], [163, 164], [165, 166], [166, 167], [168, 169], [169, 171], [171, 172], [173, 175], [175, 176], [177, 184], [184, 185], [186, 190], [190, 191], [192, 199], [199, 200], [201, 205], [205, 206], [207, 213], [213, 214], [215, 219]]}
{"doc_key": "ai-test-173", "ner": [[3, 3, "organisation"], [8, 10, "country"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2003", ",", "Honda", "published", "its", "Cog", "advertisement", "in", "the", "UK", "and", "online", "."], "sentence-detokenized": "In 2003, Honda published its Cog advertisement in the UK and online.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 24], [25, 28], [29, 32], [33, 46], [47, 49], [50, 53], [54, 56], [57, 60], [61, 67], [67, 68]]}
{"doc_key": "ai-test-174", "ner": [[0, 3, "conference"], [5, 7, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 5, 7, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Computational", "Linguistics", "Association", "defines", "computational", "linguistics", "as", ":"], "sentence-detokenized": "The Computational Linguistics Association defines computational linguistics as:", "token2charspan": [[0, 3], [4, 17], [18, 29], [30, 41], [42, 49], [50, 63], [64, 75], [76, 78], [78, 79]]}
{"doc_key": "ai-test-175", "ner": [[0, 2, "algorithm"], [9, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 12, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["Expectation", "maximization", "algorithms", "can", "be", "used", "to", "compute", "approximate", "maximum", "likelihood", "estimates", "of", "unknown", "state", "space", "parameters", "in", "the", "framework", "of", "minimum", "variance", "filters", "and", "smoothers", "."], "sentence-detokenized": "Expectation maximization algorithms can be used to compute approximate maximum likelihood estimates of unknown state space parameters in the framework of minimum variance filters and smoothers.", "token2charspan": [[0, 11], [12, 24], [25, 35], [36, 39], [40, 42], [43, 47], [48, 50], [51, 58], [59, 70], [71, 78], [79, 89], [90, 99], [100, 102], [103, 110], [111, 116], [117, 122], [123, 133], [134, 136], [137, 140], [141, 150], [151, 153], [154, 161], [162, 170], [171, 178], [179, 182], [183, 192], [192, 193]]}
{"doc_key": "ai-test-176", "ner": [[3, 3, "misc"], [5, 7, "person"], [9, 10, "person"], [12, 13, "person"], [16, 17, "misc"], [18, 19, "person"], [22, 23, "person"], [27, 27, "person"], [29, 30, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 7, 3, 3, "role", "actor_in", false, false], [9, 10, 3, 3, "role", "actor_in", false, false], [12, 13, 3, 3, "role", "actor_in", false, false], [18, 19, 16, 17, "role", "model_for", false, false], [27, 27, 29, 30, "social", "family", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Correspondents", "included", "former", "Baywatch", "actresses", "Donna", "D'", "Errico", ",", "Carmen", "Electra", "and", "Traci", "Bingham", ",", "former", "Playboy", "Playmate", "Heidi", "Mark", ",", "comedian", "Arj", "Barker", "and", "identical", "twins", "Randy", "and", "Jason", "Sklar", "."], "sentence-detokenized": "Correspondents included former Baywatch actresses Donna D'Errico, Carmen Electra and Traci Bingham, former Playboy Playmate Heidi Mark, comedian Arj Barker and identical twins Randy and Jason Sklar.", "token2charspan": [[0, 14], [15, 23], [24, 30], [31, 39], [40, 49], [50, 55], [56, 58], [58, 64], [64, 65], [66, 72], [73, 80], [81, 84], [85, 90], [91, 98], [98, 99], [100, 106], [107, 114], [115, 123], [124, 129], [130, 134], [134, 135], [136, 144], [145, 148], [149, 155], [156, 159], [160, 169], [170, 175], [176, 181], [182, 185], [186, 191], [192, 197], [197, 198]]}
{"doc_key": "ai-test-177", "ner": [[6, 7, "task"], [9, 9, "task"], [13, 15, "product"], [18, 19, "task"], [21, 21, "task"], [25, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 9, 6, 7, "named", "", false, false], [13, 15, 6, 7, "general-affiliation", "", false, false], [21, 21, 18, 19, "named", "", false, false], [25, 26, 18, 19, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "is", "typically", "used", "to", "generate", "speech", "recognition", "(", "ASR", ")", ",", "e.g.", "CMU", "Sphinx", "system", ",", "and", "speech", "synthesis", "(", "TTS", ")", ",", "e.g.", "Festival", "system", ",", "presentations", "."], "sentence-detokenized": "It is typically used to generate speech recognition (ASR), e.g. CMU Sphinx system, and speech synthesis (TTS), e.g. Festival system, presentations.", "token2charspan": [[0, 2], [3, 5], [6, 15], [16, 20], [21, 23], [24, 32], [33, 39], [40, 51], [52, 53], [53, 56], [56, 57], [57, 58], [59, 63], [64, 67], [68, 74], [75, 81], [81, 82], [83, 86], [87, 93], [94, 103], [104, 105], [105, 108], [108, 109], [109, 110], [111, 115], [116, 124], [125, 131], [131, 132], [133, 146], [146, 147]]}
{"doc_key": "ai-test-178", "ner": [[0, 0, "metrics"], [3, 4, "metrics"], [2, 6, "metrics"], [11, 11, "metrics"], [23, 23, "metrics"], [25, 25, "metrics"], [36, 39, "metrics"], [41, 43, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 7, 8], "relations": [[3, 4, 0, 0, "named", "", false, false], [2, 6, 3, 4, "named", "", false, false], [11, 11, 0, 0, "named", "", false, false], [25, 25, 23, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sensitivity", "or", "True", "Positivity", "Rate", "(", "TPR", ")", ",", "also", "called", "recall", ",", "is", "the", "proportion", "of", "people", "who", "test", "positive", "(", "TRUE", "Positive", ",", "TP", ")", "out", "of", "all", "people", "who", "actually", "test", "positive", "(", "Condition", "Positive", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "Sensitivity or True Positivity Rate (TPR), also called recall, is the proportion of people who test positive (TRUE Positive, TP) out of all people who actually test positive (Condition Positive, CP = TP + FN).", "token2charspan": [[0, 11], [12, 14], [15, 19], [20, 30], [31, 35], [36, 37], [37, 40], [40, 41], [41, 42], [43, 47], [48, 54], [55, 61], [61, 62], [63, 65], [66, 69], [70, 80], [81, 83], [84, 90], [91, 94], [95, 99], [100, 108], [109, 110], [110, 114], [115, 123], [123, 124], [125, 127], [127, 128], [129, 132], [133, 135], [136, 139], [140, 146], [147, 150], [151, 159], [160, 164], [165, 173], [174, 175], [175, 184], [185, 193], [193, 194], [195, 197], [198, 199], [200, 202], [203, 204], [205, 207], [207, 208], [208, 209]]}
{"doc_key": "ai-test-179", "ner": [[1, 2, "task"], [10, 10, "conference"], [12, 13, "conference"], [15, 15, "conference"], [17, 19, "conference"], [21, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6], "relations": [[10, 10, 1, 2, "topic", "", false, false], [12, 13, 1, 2, "topic", "", false, false], [15, 15, 1, 2, "topic", "", false, false], [17, 19, 1, 2, "topic", "", false, false], [21, 22, 1, 2, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4, 5], "sentence": ["Popular", "speech", "recognition", "conferences", "that", "take", "place", "every", "year", "are", "SpeechTEK", "and", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", "and", "IEEE", "ASRU", "."], "sentence-detokenized": "Popular speech recognition conferences that take place every year are SpeechTEK and SpeechTEK Europe, ICASSP, Interspeech/Eurospeech and IEEE ASRU.", "token2charspan": [[0, 7], [8, 14], [15, 26], [27, 38], [39, 43], [44, 48], [49, 54], [55, 60], [61, 65], [66, 69], [70, 79], [80, 83], [84, 93], [94, 100], [100, 101], [102, 108], [108, 109], [110, 121], [121, 122], [122, 132], [133, 136], [137, 141], [142, 146], [146, 147]]}
{"doc_key": "ai-test-180", "ner": [[0, 0, "researcher"], [3, 3, "researcher"], [17, 19, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 0, 0, "artifact", "", false, false], [22, 22, 3, 3, "artifact", "", false, false], [22, 22, 17, 19, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Devol", "collaborated", "with", "Engelberger", ",", "who", "served", "as", "the", "company", "'s", "president", ",", "to", "design", "and", "produce", "an", "industrial", "robot", "under", "the", "Unimate", "brand", "."], "sentence-detokenized": "Devol collaborated with Engelberger, who served as the company's president, to design and produce an industrial robot under the Unimate brand.", "token2charspan": [[0, 5], [6, 18], [19, 23], [24, 35], [35, 36], [37, 40], [41, 47], [48, 50], [51, 54], [55, 62], [62, 64], [65, 74], [74, 75], [76, 78], [79, 85], [86, 89], [90, 97], [98, 100], [101, 111], [112, 117], [118, 123], [124, 127], [128, 135], [136, 141], [141, 142]]}
{"doc_key": "ai-test-181", "ner": [[0, 2, "algorithm"], [5, 5, "algorithm"], [9, 14, "algorithm"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 9, 14, "general-affiliation", "", false, false], [5, 5, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "hidden", "Markov", "model", "(", "HMM", ")", "is", "a", "statistical", "Markov", "model", "in", "which", "the", "system", "being", "modelled", "is", "assumed", "to", "be", "a", "Markov", "process", "with", "unobserved", "(", "hidden", ")", "states", "."], "sentence-detokenized": "A hidden Markov model (HMM) is a statistical Markov model in which the system being modelled is assumed to be a Markov process with unobserved (hidden) states.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [22, 23], [23, 26], [26, 27], [28, 30], [31, 32], [33, 44], [45, 51], [52, 57], [58, 60], [61, 66], [67, 70], [71, 77], [78, 83], [84, 92], [93, 95], [96, 103], [104, 106], [107, 109], [110, 111], [112, 118], [119, 126], [127, 131], [132, 142], [143, 144], [144, 150], [150, 151], [152, 158], [158, 159]]}
{"doc_key": "ai-test-182", "ner": [[16, 18, "metrics"], [20, 20, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "feature", ",", "undesirable", "in", "many", "applications", ",", "has", "led", "researchers", "to", "use", "alternatives", "such", "as", "mean", "absolute", "error", "or", "median", "error", "."], "sentence-detokenized": "This feature, undesirable in many applications, has led researchers to use alternatives such as mean absolute error or median error.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 25], [26, 28], [29, 33], [34, 46], [46, 47], [48, 51], [52, 55], [56, 67], [68, 70], [71, 74], [75, 87], [88, 92], [93, 95], [96, 100], [101, 109], [110, 115], [116, 118], [119, 125], [126, 131], [131, 132]]}
{"doc_key": "ai-test-183", "ner": [[22, 24, "algorithm"], [29, 33, "field"], [36, 39, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 24, 29, 33, "part-of", "", false, false], [22, 24, 36, 39, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Such", "a", "sequence", "(", "which", "depends", "on", "the", "results", "of", "the", "exploration", "of", "the", "previous", "features", "at", "each", "stage", ")", "is", "called", "a", "decision", "tree", "and", "is", "applied", "in", "the", "field", "of", "machine", "learning", ",", "known", "as", "decision", "tree", "learning", "."], "sentence-detokenized": "Such a sequence (which depends on the results of the exploration of the previous features at each stage) is called a decision tree and is applied in the field of machine learning, known as decision tree learning.", "token2charspan": [[0, 4], [5, 6], [7, 15], [16, 17], [17, 22], [23, 30], [31, 33], [34, 37], [38, 45], [46, 48], [49, 52], [53, 64], [65, 67], [68, 71], [72, 80], [81, 89], [90, 92], [93, 97], [98, 103], [103, 104], [105, 107], [108, 114], [115, 116], [117, 125], [126, 130], [131, 134], [135, 137], [138, 145], [146, 148], [149, 152], [153, 158], [159, 161], [162, 169], [170, 178], [178, 179], [180, 185], [186, 188], [189, 197], [198, 202], [203, 211], [211, 212]]}
{"doc_key": "ai-test-184", "ner": [[1, 3, "task"], [5, 5, "algorithm"], [16, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 3, 5, 5, "compare", "", false, false], [16, 18, 5, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "with", "factor", "analysis", ",", "LCA", "can", "be", "used", "to", "classify", "a", "case", "according", "to", "its", "maximum", "likelihood", "of", "belonging", "to", "a", "class", "."], "sentence-detokenized": "As with factor analysis, LCA can be used to classify a case according to its maximum likelihood of belonging to a class.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 23], [23, 24], [25, 28], [29, 32], [33, 35], [36, 40], [41, 43], [44, 52], [53, 54], [55, 59], [60, 69], [70, 72], [73, 76], [77, 84], [85, 95], [96, 98], [99, 108], [109, 111], [112, 113], [114, 119], [119, 120]]}
{"doc_key": "ai-test-185", "ner": [[0, 2, "algorithm"], [7, 8, "metrics"], [6, 10, "metrics"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 7, 8, "usage", "", false, false], [7, 8, 12, 13, "related-to", "", false, false], [6, 10, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Supervised", "neural", "networks", "that", "use", "a", "mean", "squared", "error", "(", "MSE", ")", "cost", "function", "can", "use", "formal", "statistical", "methods", "to", "determine", "the", "reliability", "of", "the", "trained", "model", "."], "sentence-detokenized": "Supervised neural networks that use a mean squared error (MSE) cost function can use formal statistical methods to determine the reliability of the trained model.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 31], [32, 35], [36, 37], [38, 42], [43, 50], [51, 56], [57, 58], [58, 61], [61, 62], [63, 67], [68, 76], [77, 80], [81, 84], [85, 91], [92, 103], [104, 111], [112, 114], [115, 124], [125, 128], [129, 140], [141, 143], [144, 147], [148, 155], [156, 161], [161, 162]]}
{"doc_key": "ai-test-186", "ner": [[16, 18, "algorithm"], [20, 23, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 18, 20, 23, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "can", "be", "expressed", "directly", "as", "a", "linear", "program", ",", "but", "it", "is", "also", "equivalent", "to", "a", "Tihonov", "regularization", "with", "a", "hinge", "loss", "function", ",", "mathV", "(", "f", "(", "x", ")", ",", "y", ")", "=\\", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "math", ":"], "sentence-detokenized": "This can be expressed directly as a linear program, but it is also equivalent to a Tihonov regularization with a hinge loss function, mathV (f (x), y) =\\ max (0, 1 - yf (x)) / math:", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 21], [22, 30], [31, 33], [34, 35], [36, 42], [43, 50], [50, 51], [52, 55], [56, 58], [59, 61], [62, 66], [67, 77], [78, 80], [81, 82], [83, 90], [91, 105], [106, 110], [111, 112], [113, 118], [119, 123], [124, 132], [132, 133], [134, 139], [140, 141], [141, 142], [143, 144], [144, 145], [145, 146], [146, 147], [148, 149], [149, 150], [151, 153], [154, 157], [158, 159], [159, 160], [160, 161], [162, 163], [164, 165], [166, 168], [169, 170], [170, 171], [171, 172], [172, 173], [174, 175], [176, 180], [180, 181]]}
{"doc_key": "ai-test-187", "ner": [[14, 18, "product"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "technique", "was", "described", "in", "Breiman", "'s", "original", "work", "and", "has", "been", "implemented", "in", "the", "R", "package", "randomForest", "."], "sentence-detokenized": "The following technique was described in Breiman's original work and has been implemented in the R package randomForest.", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 27], [28, 37], [38, 40], [41, 48], [48, 50], [51, 59], [60, 64], [65, 68], [69, 72], [73, 77], [78, 89], [90, 92], [93, 96], [97, 98], [99, 106], [107, 119], [119, 120]]}
{"doc_key": "ai-test-188", "ner": [[8, 8, "metrics"], [38, 40, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "measures", "of", "image", "quality", ",", "such", "as", "PSNR", ",", "are", "usually", "performed", "on", "fixed", "-", "resolution", "images", "and", "do", "not", "take", "into", "account", "some", "aspects", "of", "the", "human", "visual", "system", ",", "such", "as", "changes", "in", "spatial", "resolution", "in", "the", "retina", "."], "sentence-detokenized": "Traditional measures of image quality, such as PSNR, are usually performed on fixed-resolution images and do not take into account some aspects of the human visual system, such as changes in spatial resolution in the retina.", "token2charspan": [[0, 11], [12, 20], [21, 23], [24, 29], [30, 37], [37, 38], [39, 43], [44, 46], [47, 51], [51, 52], [53, 56], [57, 64], [65, 74], [75, 77], [78, 83], [83, 84], [84, 94], [95, 101], [102, 105], [106, 108], [109, 112], [113, 117], [118, 122], [123, 130], [131, 135], [136, 143], [144, 146], [147, 150], [151, 156], [157, 163], [164, 170], [170, 171], [172, 176], [177, 179], [180, 187], [188, 190], [191, 198], [199, 209], [210, 212], [213, 216], [217, 223], [223, 224]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [10, 12, "person"], [16, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 19, "role", "", false, false], [3, 4, 16, 19, "role", "", false, false], [6, 7, 16, 19, "role", "", false, false], [16, 19, 10, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Dru", "and", "Macdonald", "Carey", "starred", "in", "Jack", "Broder", "'s", "colourful", "production", "of", "Hannah", "Lee", ",", "which", "premiered", "on", "19", "June", "1953", "."], "sentence-detokenized": "John Ireland, Joanne Dru and Macdonald Carey starred in Jack Broder's colourful production of Hannah Lee, which premiered on 19 June 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 55], [56, 60], [61, 67], [67, 69], [70, 79], [80, 90], [91, 93], [94, 100], [101, 104], [104, 105], [106, 111], [112, 121], [122, 124], [125, 127], [128, 132], [133, 137], [137, 138]]}
{"doc_key": "ai-test-190", "ner": [[4, 5, "task"], [9, 10, "field"], [16, 16, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 9, 10, "usage", "", false, false], [16, 16, 9, 10, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "process", "is", "called", "image", "registration", "and", "uses", "various", "computer", "vision", "techniques", ",", "mostly", "related", "to", "tracking", "."], "sentence-detokenized": "This process is called image registration and uses various computer vision techniques, mostly related to tracking.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 22], [23, 28], [29, 41], [42, 45], [46, 50], [51, 58], [59, 67], [68, 74], [75, 85], [85, 86], [87, 93], [94, 101], [102, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-test-191", "ner": [[19, 20, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Let", "'s", "now", "start", "to", "explain", "the", "different", "possible", "links", "between", "the", "predicted", "and", "the", "actual", "outcome", ":", "the", "confusion", "matrix", "."], "sentence-detokenized": "Let's now start to explain the different possible links between the predicted and the actual outcome: the confusion matrix.", "token2charspan": [[0, 3], [3, 5], [6, 9], [10, 15], [16, 18], [19, 26], [27, 30], [31, 40], [41, 49], [50, 55], [56, 63], [64, 67], [68, 77], [78, 81], [82, 85], [86, 92], [93, 100], [100, 101], [102, 105], [106, 115], [116, 122], [122, 123]]}
{"doc_key": "ai-test-192", "ner": [[0, 1, "product"], [2, 4, "misc"], [6, 6, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 2, 4, "part-of", "", false, false], [0, 1, 2, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "VOICEBOX", "speech", "processing", "toolkit", "for", "MATLAB", "implements", "the", "conversion", "and", "its", "inverse", "as", "follows", ":"], "sentence-detokenized": "The VOICEBOX speech processing toolkit for MATLAB implements the conversion and its inverse as follows:", "token2charspan": [[0, 3], [4, 12], [13, 19], [20, 30], [31, 38], [39, 42], [43, 49], [50, 60], [61, 64], [65, 75], [76, 79], [80, 83], [84, 91], [92, 94], [95, 102], [102, 103]]}
{"doc_key": "ai-test-193", "ner": [[0, 0, "programlang"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 9, "general-affiliation", "", false, false], [0, 0, 11, 12, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "is", "a", "logical", "programming", "language", "related", "to", "artificial", "intelligence", "and", "computer", "graphics", "."], "sentence-detokenized": "Prolog is a logical programming language related to artificial intelligence and computer graphics.", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 19], [20, 31], [32, 40], [41, 48], [49, 51], [52, 62], [63, 75], [76, 79], [80, 88], [89, 97], [97, 98]]}
{"doc_key": "ai-test-194", "ner": [[0, 0, "researcher"], [8, 9, "field"], [11, 11, "field"], [17, 20, "organisation"], [23, 26, "organisation"], [29, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 8, 9, "related-to", "works_with_topic", false, false], [0, 0, 11, 11, "related-to", "works_with_topic", false, false], [0, 0, 17, 20, "role", "", false, false], [0, 0, 23, 26, "role", "", false, false], [0, 0, 29, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "has", "received", "numerous", "awards", "for", "his", "contributions", "to", "neuroscience", "and", "psychology", ",", "including", "membership", "of", "the", "Royal", "Society", "of", "London", ",", "the", "Royal", "Society", "of", "Canada", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner has received numerous awards for his contributions to neuroscience and psychology, including membership of the Royal Society of London, the Royal Society of Canada and the National Academy of Sciences.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 28], [29, 35], [36, 39], [40, 43], [44, 57], [58, 60], [61, 73], [74, 77], [78, 88], [88, 89], [90, 99], [100, 110], [111, 113], [114, 117], [118, 123], [124, 131], [132, 134], [135, 141], [141, 142], [143, 146], [147, 152], [153, 160], [161, 163], [164, 170], [171, 174], [175, 178], [179, 187], [188, 195], [196, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-test-195", "ner": [[20, 21, "task"], [23, 24, "task"], [26, 27, "task"], [29, 32, "task"], [33, 33, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["By", "combining", "these", "operators", ",", "algorithms", "can", "be", "obtained", "for", "a", "wide", "range", "of", "image", "processing", "tasks", ",", "such", "as", "feature", "extraction", ",", "image", "segmentation", ",", "image", "sharpening", ",", "image", "filtering", "and", "image", "classification", "."], "sentence-detokenized": "By combining these operators, algorithms can be obtained for a wide range of image processing tasks, such as feature extraction, image segmentation, image sharpening, image filtering and image classification.", "token2charspan": [[0, 2], [3, 12], [13, 18], [19, 28], [28, 29], [30, 40], [41, 44], [45, 47], [48, 56], [57, 60], [61, 62], [63, 67], [68, 73], [74, 76], [77, 82], [83, 93], [94, 99], [99, 100], [101, 105], [106, 108], [109, 116], [117, 127], [127, 128], [129, 134], [135, 147], [147, 148], [149, 154], [155, 165], [165, 166], [167, 172], [173, 182], [183, 186], [187, 192], [193, 207], [207, 208]]}
{"doc_key": "ai-test-196", "ner": [[8, 11, "university"], [17, 19, "organisation"], [21, 22, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 22, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "2017", ",", "he", "has", "been", "Professor", "at", "the", "Coll\u00e8ge", "de", "France", "and", "since", "1989", "Director", "of", "INSERM", "Unit", "562", "(", "Cognitive", "Neuroimaging", ")", "."], "sentence-detokenized": "Since 2017, he has been Professor at the Coll\u00e8ge de France and since 1989 Director of INSERM Unit 562 (Cognitive Neuroimaging).", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 14], [15, 18], [19, 23], [24, 33], [34, 36], [37, 40], [41, 48], [49, 51], [52, 58], [59, 62], [63, 68], [69, 73], [74, 82], [83, 85], [86, 92], [93, 97], [98, 101], [102, 103], [103, 112], [113, 125], [125, 126], [126, 127]]}
{"doc_key": "ai-test-197", "ner": [[13, 15, "algorithm"], [17, 20, "algorithm"], [25, 25, "algorithm"], [27, 33, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[25, 25, 27, 33, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["There", "are", "a", "number", "of", "approaches", "to", "learning", "these", "embeddings", ",", "notably", "using", "Bayesian", "clustering", "frameworks", "or", "energy", "-", "based", "frameworks", ",", "and", "more", "recently", "TransE", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", "2013", ")", "."], "sentence-detokenized": "There are a number of approaches to learning these embeddings, notably using Bayesian clustering frameworks or energy-based frameworks, and more recently TransE (Conference on Neural Information Processing Systems 2013).", "token2charspan": [[0, 5], [6, 9], [10, 11], [12, 18], [19, 21], [22, 32], [33, 35], [36, 44], [45, 50], [51, 61], [61, 62], [63, 70], [71, 76], [77, 85], [86, 96], [97, 107], [108, 110], [111, 117], [117, 118], [118, 123], [124, 134], [134, 135], [136, 139], [140, 144], [145, 153], [154, 160], [161, 162], [162, 172], [173, 175], [176, 182], [183, 194], [195, 205], [206, 213], [214, 218], [218, 219], [219, 220]]}
{"doc_key": "ai-test-198", "ner": [[6, 7, "metrics"], [8, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 8, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "is", "an", "alternative", "to", "the", "Word", "Error", "Rate", "used", "in", "many", "countries", "."], "sentence-detokenized": "This is an alternative to the Word Error Rate used in many countries.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 25], [26, 29], [30, 34], [35, 40], [41, 45], [46, 50], [51, 53], [54, 58], [59, 68], [68, 69]]}
{"doc_key": "ai-test-199", "ner": [[0, 0, "algorithm"], [12, 13, "task"], [15, 16, "task"], [18, 19, "task"], [21, 23, "task"], [25, 28, "task"], [30, 31, "task"], [43, 43, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[12, 13, 0, 0, "usage", "", false, false], [15, 16, 0, 0, "usage", "", false, false], [18, 19, 0, 0, "usage", "", false, false], [21, 23, 0, 0, "usage", "", false, false], [25, 28, 0, 0, "usage", "", false, false], [30, 31, 0, 0, "usage", "", false, false], [43, 43, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["ANNs", "have", "been", "used", "in", "a", "wide", "range", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "desktop", "and", "video", "gaming", ",", "medical", "diagnosis", "and", "even", "activities", "traditionally", "considered", "reserved", "for", "humans", ",", "such", "as", "painting", "."], "sentence-detokenized": "ANNs have been used in a wide range of tasks, including computer vision, speech recognition, machine translation, social network filtering, desktop and video gaming, medical diagnosis and even activities traditionally considered reserved for humans, such as painting.", "token2charspan": [[0, 4], [5, 9], [10, 14], [15, 19], [20, 22], [23, 24], [25, 29], [30, 35], [36, 38], [39, 44], [44, 45], [46, 55], [56, 64], [65, 71], [71, 72], [73, 79], [80, 91], [91, 92], [93, 100], [101, 112], [112, 113], [114, 120], [121, 128], [129, 138], [138, 139], [140, 147], [148, 151], [152, 157], [158, 164], [164, 165], [166, 173], [174, 183], [184, 187], [188, 192], [193, 203], [204, 217], [218, 228], [229, 237], [238, 241], [242, 248], [248, 249], [250, 254], [255, 257], [258, 266], [266, 267]]}
{"doc_key": "ai-test-200", "ner": [[0, 4, "product"], [6, 6, "product"], [26, 28, "field"], [30, 30, "field"], [35, 35, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 26, 28, "related-to", "", false, false], [0, 4, 35, 35, "general-affiliation", "", false, false], [6, 6, 0, 4, "named", "", false, false], [30, 30, 26, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "is", "an", "open", "-", "source", "research", "platform", "and", "collection", "of", "voice", ",", "audio", ",", "speech", ",", "text", "and", "natural", "language", "processing", "(", "NLP", ")", "algorithms", "written", "in", "Java", ",", "arranged", "in", "a", "modular", "and", "extensible", "framework", "that", "seeks", "to", "facilitate", "the", "addition", "of", "new", "algorithms", "."], "sentence-detokenized": "The Modular Audio Recognition Framework (MARF) is an open-source research platform and collection of voice, audio, speech, text and natural language processing (NLP) algorithms written in Java, arranged in a modular and extensible framework that seeks to facilitate the addition of new algorithms.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 29], [30, 39], [40, 41], [41, 45], [45, 46], [47, 49], [50, 52], [53, 57], [57, 58], [58, 64], [65, 73], [74, 82], [83, 86], [87, 97], [98, 100], [101, 106], [106, 107], [108, 113], [113, 114], [115, 121], [121, 122], [123, 127], [128, 131], [132, 139], [140, 148], [149, 159], [160, 161], [161, 164], [164, 165], [166, 176], [177, 184], [185, 187], [188, 192], [192, 193], [194, 202], [203, 205], [206, 207], [208, 215], [216, 219], [220, 230], [231, 240], [241, 245], [246, 251], [252, 254], [255, 265], [266, 269], [270, 278], [279, 281], [282, 285], [286, 296], [296, 297]]}
{"doc_key": "ai-test-201", "ner": [[13, 15, "organisation"], [19, 19, "country"], [23, 25, "organisation"], [28, 29, "organisation"], [33, 34, "task"], [47, 50, "organisation"], [53, 54, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[23, 25, 19, 19, "physical", "", false, false], [23, 25, 33, 34, "usage", "", false, false], [23, 25, 47, 50, "named", "", false, false], [28, 29, 19, 19, "physical", "", false, false], [28, 29, 33, 34, "usage", "", false, false], [47, 50, 53, 54, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "a", "report", "by", "the", "civil", "liberties", "and", "civil", "rights", "organisation", "Big", "Brother", "Watch", "revealed", "that", "two", "UK", "police", "forces", ",", "South", "Wales", "Police", "and", "the", "Metropolitan", "Police", ",", "use", "live", "facial", "recognition", "at", "public", "events", "and", "in", "public", "spaces", ".", "In", "September", "2019", ",", "South", "Wales", "Police", "'s", "use", "of", "facial", "recognition", "was", "declared", "legal", "."], "sentence-detokenized": "In 2018, a report by the civil liberties and civil rights organisation Big Brother Watch revealed that two UK police forces, South Wales Police and the Metropolitan Police, use live facial recognition at public events and in public spaces. In September 2019, South Wales Police's use of facial recognition was declared legal.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 20], [21, 24], [25, 30], [31, 40], [41, 44], [45, 50], [51, 57], [58, 70], [71, 74], [75, 82], [83, 88], [89, 97], [98, 102], [103, 106], [107, 109], [110, 116], [117, 123], [123, 124], [125, 130], [131, 136], [137, 143], [144, 147], [148, 151], [152, 164], [165, 171], [171, 172], [173, 176], [177, 181], [182, 188], [189, 200], [201, 203], [204, 210], [211, 217], [218, 221], [222, 224], [225, 231], [232, 238], [238, 239], [240, 242], [243, 252], [253, 257], [257, 258], [259, 264], [265, 270], [271, 277], [277, 279], [280, 283], [284, 286], [287, 293], [294, 305], [306, 309], [310, 318], [319, 324], [324, 325]]}
{"doc_key": "ai-test-202", "ner": [[0, 0, "product"], [4, 5, "programlang"], [14, 15, "field"], [17, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 5, "general-affiliation", "", false, false], [0, 0, 14, 15, "related-to", "", false, false], [0, 0, 17, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "has", "been", "migrated", "to", "R", ",", "a", "freely", "available", "language", "and", "environment", "for", "statistical", "computing", "and", "graphics", "."], "sentence-detokenized": "ANIMAL has been migrated to R, a freely available language and environment for statistical computing and graphics.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 24], [25, 27], [28, 29], [29, 30], [31, 32], [33, 39], [40, 49], [50, 58], [59, 62], [63, 74], [75, 78], [79, 90], [91, 100], [101, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-test-203", "ner": [[3, 6, "algorithm"], [0, 10, "algorithm"], [16, 19, "algorithm"], [21, 23, "algorithm"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 16, 19, "opposite", "alternative to", false, false], [0, 10, 3, 6, "named", "", false, false], [21, 23, 16, 19, "named", "", false, false], [24, 26, 3, 6, "usage", "", false, false], [24, 26, 16, 19, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "time", "-", "homogeneous", "hidden", "Bernoulli", "model", "(", "TI", "-", "HBM", ")", "is", "an", "alternative", "to", "the", "hidden", "Markov", "model", "(", "HMM", ")", "for", "automatic", "speech", "recognition", "."], "sentence-detokenized": "The time-homogeneous hidden Bernoulli model (TI-HBM) is an alternative to the hidden Markov model (HMM) for automatic speech recognition.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 20], [21, 27], [28, 37], [38, 43], [44, 45], [45, 47], [47, 48], [48, 51], [51, 52], [53, 55], [56, 58], [59, 70], [71, 73], [74, 77], [78, 84], [85, 91], [92, 97], [98, 99], [99, 102], [102, 103], [104, 107], [108, 117], [118, 124], [125, 136], [136, 137]]}
{"doc_key": "ai-test-204", "ner": [[6, 7, "organisation"], [5, 5, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 5, 5, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "July", "2016", ",", "during", "SIGGRAPH", ",", "Nvidia", "demonstrated", "a", "new", "foveated", "rendering", "method", "that", "is", "claimed", "to", "be", "invisible", "to", "users", "."], "sentence-detokenized": "In July 2016, during SIGGRAPH, Nvidia demonstrated a new foveated rendering method that is claimed to be invisible to users.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 20], [21, 29], [29, 30], [31, 37], [38, 50], [51, 52], [53, 56], [57, 65], [66, 75], [76, 82], [83, 87], [88, 90], [91, 98], [99, 101], [102, 104], [105, 114], [115, 117], [118, 123], [123, 124]]}
{"doc_key": "ai-test-205", "ner": [[4, 15, "misc"], [10, 11, "researcher"], [19, 20, "researcher"], [22, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 15, 10, 11, "origin", "", false, false], [4, 15, 19, 20, "origin", "", false, false], [4, 15, 22, 22, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Both", "are", "based", "on", "the", "speech", "act", "theory", "developed", "by", "John", "Searle", "in", "the", "1960s", "and", "further", "developed", "by", "Terry", "Winograd", "and", "Flores", "in", "the", "1970s", "."], "sentence-detokenized": "Both are based on the speech act theory developed by John Searle in the 1960s and further developed by Terry Winograd and Flores in the 1970s.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 17], [18, 21], [22, 28], [29, 32], [33, 39], [40, 49], [50, 52], [53, 57], [58, 64], [65, 67], [68, 71], [72, 77], [78, 81], [82, 89], [90, 99], [100, 102], [103, 108], [109, 117], [118, 121], [122, 128], [129, 131], [132, 135], [136, 141], [141, 142]]}
{"doc_key": "ai-test-206", "ner": [[0, 3, "algorithm"], [21, 21, "researcher"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 21, 21, "related-to", "", false, false], [24, 24, 21, 21, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Neural", "network", "models", "of", "concept", "formation", "and", "knowledge", "structure", "have", "opened", "up", "powerful", "hierarchical", "models", "for", "organizing", "knowledge", ",", "such", "as", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "Neural network models of concept formation and knowledge structure have opened up powerful hierarchical models for organizing knowledge, such as George Miller's Wordnet.", "token2charspan": [[0, 6], [7, 14], [15, 21], [22, 24], [25, 32], [33, 42], [43, 46], [47, 56], [57, 66], [67, 71], [72, 78], [79, 81], [82, 90], [91, 103], [104, 110], [111, 114], [115, 125], [126, 135], [135, 136], [137, 141], [142, 144], [145, 151], [152, 158], [158, 160], [161, 168], [168, 169]]}
{"doc_key": "ai-test-207", "ner": [[0, 1, "algorithm"], [19, 20, "field"], [23, 25, "product"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 19, 20, "part-of", "", false, false], [0, 1, 28, 29, "part-of", "", false, false], [23, 25, 19, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Pattern", "matching", "has", "a", "wide", "range", "of", "applications", "and", "is", "used", ",", "for", "example", ",", "in", "the", "fields", "of", "facial", "recognition", "(", "see", "Facial", "Recognition", "System", ")", "and", "medical", "imaging", "."], "sentence-detokenized": "Pattern matching has a wide range of applications and is used, for example, in the fields of facial recognition (see Facial Recognition System) and medical imaging.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 22], [23, 27], [28, 33], [34, 36], [37, 49], [50, 53], [54, 56], [57, 61], [61, 62], [63, 66], [67, 74], [74, 75], [76, 78], [79, 82], [83, 89], [90, 92], [93, 99], [100, 111], [112, 113], [113, 116], [117, 123], [124, 135], [136, 142], [142, 143], [144, 147], [148, 155], [156, 163], [163, 164]]}
{"doc_key": "ai-test-208", "ner": [[10, 11, "researcher"], [13, 16, "researcher"], [17, 26, "organisation"], [28, 28, "organisation"], [35, 36, "algorithm"], [37, 51, "conference"], [39, 43, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 11, 17, 26, "role", "", false, false], [10, 11, 37, 51, "physical", "", false, false], [10, 11, 37, 51, "temporal", "", false, false], [10, 11, 39, 43, "physical", "", false, false], [13, 16, 17, 26, "role", "", false, false], [13, 16, 37, 51, "temporal", "", false, false], [28, 28, 17, 26, "named", "", false, false], [37, 51, 35, 36, "topic", "", false, false], [39, 43, 37, 51, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["However", ",", "it", "was", "not", "until", "2005", ",", "when", "researchers", "Navneet", "Dalal", "and", "Bill", "Triggs", "of", "the", "French", "National", "Institute", "for", "Research", "in", "Computer", "Science", "and", "Automation", "(", "INRIA", ")", "presented", "their", "further", "work", "on", "HOG", "descriptors", "at", "the", "CVPR", "(", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ")", ",", "that", "their", "use", "became", "widespread", "."], "sentence-detokenized": "However, it was not until 2005, when researchers Navneet Dalal and Bill Triggs of the French National Institute for Research in Computer Science and Automation (INRIA) presented their further work on HOG descriptors at the CVPR (Conference on Computer Vision and Pattern Recognition), that their use became widespread.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 15], [16, 19], [20, 25], [26, 30], [30, 31], [32, 36], [37, 48], [49, 56], [57, 62], [63, 66], [67, 71], [72, 78], [79, 81], [82, 85], [86, 92], [93, 101], [102, 111], [112, 115], [116, 124], [125, 127], [128, 136], [137, 144], [145, 148], [149, 159], [160, 161], [161, 166], [166, 167], [168, 177], [178, 183], [184, 191], [192, 196], [197, 199], [200, 203], [204, 215], [216, 218], [219, 222], [223, 227], [228, 229], [229, 239], [240, 242], [243, 251], [252, 258], [259, 262], [263, 270], [271, 282], [282, 283], [283, 284], [285, 289], [290, 295], [296, 299], [300, 306], [307, 317], [317, 318]]}
{"doc_key": "ai-test-209", "ner": [[0, 4, "university"], [16, 19, "organisation"], [21, 22, "organisation"], [29, 30, "field"], [36, 38, "researcher"], [40, 43, "researcher"], [45, 47, "researcher"], [49, 53, "organisation"], [57, 59, "organisation"], [64, 65, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[21, 22, 29, 30, "related-to", "", false, false], [36, 38, 21, 22, "physical", "", false, false], [36, 38, 21, 22, "role", "", false, false], [40, 43, 21, 22, "physical", "", false, false], [40, 43, 21, 22, "role", "", false, false], [45, 47, 21, 22, "physical", "", false, false], [45, 47, 21, 22, "role", "", false, false], [64, 65, 57, 59, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Prior", "to", "joining", "Penn", "'s", "faculty", "in", "2002", ",", "he", "spent", "ten", "years", "(", "1991-2001", ")", "at", "AT", "&T", "Labs", "and", "Bell", "Labs", ",", "including", "as", "head", "of", "the", "Artificial", "Intelligence", "Division", "with", "colleagues", "such", "as", "Michael", "L.", "Littman", ",", "David", "A", ".", "McAllester", "and", "Richard", "S.", "Sutton", ";", "the", "Secure", "Systems", "Research", "Division", ";", "and", "the", "Machine", "Learning", "Division", "with", "members", "such", "as", "Michael", "Collins", "and", "the", "Manager", ")", "."], "sentence-detokenized": "Prior to joining Penn's faculty in 2002, he spent ten years (1991-2001) at AT&T Labs and Bell Labs, including as head of the Artificial Intelligence Division with colleagues such as Michael L. Littman, David A. McAllester and Richard S. Sutton; the Secure Systems Research Division; and the Machine Learning Division with members such as Michael Collins and the Manager).", "token2charspan": [[0, 5], [6, 8], [9, 16], [17, 21], [21, 23], [24, 31], [32, 34], [35, 39], [39, 40], [41, 43], [44, 49], [50, 53], [54, 59], [60, 61], [61, 70], [70, 71], [72, 74], [75, 77], [77, 79], [80, 84], [85, 88], [89, 93], [94, 98], [98, 99], [100, 109], [110, 112], [113, 117], [118, 120], [121, 124], [125, 135], [136, 148], [149, 157], [158, 162], [163, 173], [174, 178], [179, 181], [182, 189], [190, 192], [193, 200], [200, 201], [202, 207], [208, 209], [209, 210], [211, 221], [222, 225], [226, 233], [234, 236], [237, 243], [243, 244], [245, 248], [249, 255], [256, 263], [264, 272], [273, 281], [281, 282], [283, 286], [287, 290], [291, 298], [299, 307], [308, 316], [317, 321], [322, 329], [330, 334], [335, 337], [338, 345], [346, 353], [354, 357], [358, 361], [362, 369], [369, 370], [370, 371]]}
{"doc_key": "ai-test-210", "ner": [[6, 8, "field"], [13, 14, "field"], [24, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 8, 13, 14, "compare", "", false, false], [24, 24, 13, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["If", "the", "data", "is", "unlabeled", ",", "supervised", "learning", "is", "not", "possible", "and", "an", "unsupervised", "learning", "approach", "is", "needed", ",", "which", "tries", "to", "find", "natural", "clustering", "groups", "and", "then", "map", "new", "data", "to", "these", "clusters", "."], "sentence-detokenized": "If the data is unlabeled, supervised learning is not possible and an unsupervised learning approach is needed, which tries to find natural clustering groups and then map new data to these clusters.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 24], [24, 25], [26, 36], [37, 45], [46, 48], [49, 52], [53, 61], [62, 65], [66, 68], [69, 81], [82, 90], [91, 99], [100, 102], [103, 109], [109, 110], [111, 116], [117, 122], [123, 125], [126, 130], [131, 138], [139, 149], [150, 156], [157, 160], [161, 165], [166, 169], [170, 173], [174, 178], [179, 181], [182, 187], [188, 196], [196, 197]]}
{"doc_key": "ai-test-211", "ner": [[3, 4, "field"], [15, 18, "organisation"], [25, 26, "field"], [28, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 15, 18, "origin", "", false, false], [3, 4, 25, 26, "part-of", "", false, false], [3, 4, 28, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "field", "of", "computer", "science", "developed", "in", "the", "1950s", "in", "academic", "institutions", "such", "as", "the", "MIT", "A.I", ".", "Lab", ",", "initially", "as", "a", "branch", "of", "artificial", "intelligence", "and", "robotics", "."], "sentence-detokenized": "This field of computer science developed in the 1950s in academic institutions such as the MIT A.I. Lab, initially as a branch of artificial intelligence and robotics.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 30], [31, 40], [41, 43], [44, 47], [48, 53], [54, 56], [57, 65], [66, 78], [79, 83], [84, 86], [87, 90], [91, 94], [95, 98], [98, 99], [100, 103], [103, 104], [105, 114], [115, 117], [118, 119], [120, 126], [127, 129], [130, 140], [141, 153], [154, 157], [158, 166], [166, 167]]}
{"doc_key": "ai-test-212", "ner": [[10, 11, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "can", "also", "be", "replaced", "by", "the", "following", "equation", "of", "logical", "loss", ":"], "sentence-detokenized": "It can also be replaced by the following equation of logical loss:", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 23], [24, 26], [27, 30], [31, 40], [41, 49], [50, 52], [53, 60], [61, 65], [65, 66]]}
{"doc_key": "ai-test-213", "ner": [[0, 3, "organisation"], [6, 9, "organisation"], [13, 17, "university"], [19, 19, "university"], [21, 22, "university"], [25, 27, "university"], [28, 30, "country"], [39, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 3, 39, 39, "related-to", "research_leader_in_field", false, false], [6, 9, 0, 3, "named", "", false, false], [6, 9, 39, 39, "related-to", "research_leader_in_field", false, false], [13, 17, 39, 39, "related-to", "research_leader_in_field", false, false], [19, 19, 39, 39, "related-to", "research_leader_in_field", false, false], [21, 22, 39, 39, "related-to", "research_leader_in_field", false, false], [25, 27, 28, 30, "physical", "", false, false], [25, 27, 39, 39, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "Shirley", "Ryan", "AbilityLab", "(", "formerly", "the", "Chicago", "Rehabilitation", "Institute", ")", ",", "the", "University", "of", "California", "at", "Berkeley", ",", "MIT", ",", "Stanford", "University", "and", "the", "University", "of", "Twente", "in", "the", "Netherlands", "are", "leading", "research", "institutions", "in", "the", "field", "of", "biomechatronics", "."], "sentence-detokenized": "The Shirley Ryan AbilityLab (formerly the Chicago Rehabilitation Institute), the University of California at Berkeley, MIT, Stanford University and the University of Twente in the Netherlands are leading research institutions in the field of biomechatronics.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 27], [28, 29], [29, 37], [38, 41], [42, 49], [50, 64], [65, 74], [74, 75], [75, 76], [77, 80], [81, 91], [92, 94], [95, 105], [106, 108], [109, 117], [117, 118], [119, 122], [122, 123], [124, 132], [133, 143], [144, 147], [148, 151], [152, 162], [163, 165], [166, 172], [173, 175], [176, 179], [180, 191], [192, 195], [196, 203], [204, 212], [213, 225], [226, 228], [229, 232], [233, 238], [239, 241], [242, 257], [257, 258]]}
{"doc_key": "ai-test-214", "ner": [[26, 33, "metrics"], [44, 45, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Given", "a", "set", "of", "predicted", "values", "and", "a", "corresponding", "set", "of", "X", "actual", "values", "for", "different", "time", "periods", ",", "a", "common", "estimation", "technique", "is", "to", "use", "the", "root", "mean", "square", "error", "of", "the", "predictions", ";", "other", "measures", "are", "also", "available", "(", "see", "Forecasting", "#", "Forecast", "accuracy", ")", "."], "sentence-detokenized": "Given a set of predicted values and a corresponding set of X actual values for different time periods, a common estimation technique is to use the root mean square error of the predictions; other measures are also available (see Forecasting # Forecast accuracy).", "token2charspan": [[0, 5], [6, 7], [8, 11], [12, 14], [15, 24], [25, 31], [32, 35], [36, 37], [38, 51], [52, 55], [56, 58], [59, 60], [61, 67], [68, 74], [75, 78], [79, 88], [89, 93], [94, 101], [101, 102], [103, 104], [105, 111], [112, 122], [123, 132], [133, 135], [136, 138], [139, 142], [143, 146], [147, 151], [152, 156], [157, 163], [164, 169], [170, 172], [173, 176], [177, 188], [188, 189], [190, 195], [196, 204], [205, 208], [209, 213], [214, 223], [224, 225], [225, 228], [229, 240], [241, 242], [243, 251], [252, 260], [260, 261], [261, 262]]}
{"doc_key": "ai-test-215", "ner": [[14, 14, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "measures", ",", "such", "as", "the", "proportion", "of", "correct", "predictions", "(", "also", "known", "as", "accuracy", ")", ",", "are", "not", "useful", "if", "the", "two", "classes", "are", "of", "very", "different", "sizes", "."], "sentence-detokenized": "Other measures, such as the proportion of correct predictions (also known as accuracy), are not useful if the two classes are of very different sizes.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 20], [21, 23], [24, 27], [28, 38], [39, 41], [42, 49], [50, 61], [62, 63], [63, 67], [68, 73], [74, 76], [77, 85], [85, 86], [86, 87], [88, 91], [92, 95], [96, 102], [103, 105], [106, 109], [110, 113], [114, 121], [122, 125], [126, 128], [129, 133], [134, 143], [144, 149], [149, 150]]}
{"doc_key": "ai-test-216", "ner": [[5, 5, "product"], [15, 20, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 15, 20, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "alpha", "version", "of", "OpenCV", "was", "released", "to", "the", "public", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "in", "2000", ",", "and", "five", "beta", "versions", "were", "released", "between", "2001", "and", "2005", "."], "sentence-detokenized": "The first alpha version of OpenCV was released to the public at the Conference on Computer Vision and Pattern Recognition in 2000, and five beta versions were released between 2001 and 2005.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [24, 26], [27, 33], [34, 37], [38, 46], [47, 49], [50, 53], [54, 60], [61, 63], [64, 67], [68, 78], [79, 81], [82, 90], [91, 97], [98, 101], [102, 109], [110, 121], [122, 124], [125, 129], [129, 130], [131, 134], [135, 139], [140, 144], [145, 153], [154, 158], [159, 167], [168, 175], [176, 180], [181, 184], [185, 189], [189, 190]]}
{"doc_key": "ai-test-217", "ner": [[23, 23, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Results", "are", "presented", "that", "give", "a", "correlation", "of", "up", "to", "0.964", "with", "the", "human", "estimate", "at", "the", "corpus", "level", ",", "compared", "to", "a", "BLEU", "result", "of", "0.817", "for", "the", "same", "dataset", "."], "sentence-detokenized": "Results are presented that give a correlation of up to 0.964 with the human estimate at the corpus level, compared to a BLEU result of 0.817 for the same dataset.", "token2charspan": [[0, 7], [8, 11], [12, 21], [22, 26], [27, 31], [32, 33], [34, 45], [46, 48], [49, 51], [52, 54], [55, 60], [61, 65], [66, 69], [70, 75], [76, 84], [85, 87], [88, 91], [92, 98], [99, 104], [104, 105], [106, 114], [115, 117], [118, 119], [120, 124], [125, 131], [132, 134], [135, 140], [141, 144], [145, 148], [149, 153], [154, 161], [161, 162]]}
{"doc_key": "ai-test-218", "ner": [[5, 6, "metrics"], [18, 18, "metrics"], [20, 22, "metrics"], [24, 27, "metrics"], [28, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 18, 18, "compare", "", false, false], [5, 6, 20, 22, "compare", "", false, false], [5, 6, 24, 27, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "early", "version", "of", "the", "VMAF", "is", "shown", "to", "outperform", "other", "image", "and", "video", "quality", "metrics", "such", "as", "SSIM", ",", "PSNR", "-", "HVS", "and", "VQM", "-", "VFD", "in", "terms", "of", "predictive", "accuracy", "compared", "to", "subjective", "assessments", "in", "three", "out", "of", "four", "datasets", "."], "sentence-detokenized": "The early version of the VMAF is shown to outperform other image and video quality metrics such as SSIM, PSNR -HVS and VQM-VFD in terms of predictive accuracy compared to subjective assessments in three out of four datasets.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 20], [21, 24], [25, 29], [30, 32], [33, 38], [39, 41], [42, 52], [53, 58], [59, 64], [65, 68], [69, 74], [75, 82], [83, 90], [91, 95], [96, 98], [99, 103], [103, 104], [105, 109], [110, 111], [111, 114], [115, 118], [119, 122], [122, 123], [123, 126], [127, 129], [130, 135], [136, 138], [139, 149], [150, 158], [159, 167], [168, 170], [171, 181], [182, 193], [194, 196], [197, 202], [203, 206], [207, 209], [210, 214], [215, 223], [223, 224]]}
{"doc_key": "ai-test-219", "ner": [[20, 21, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 21, 27, 28, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "example", ",", "the", "ambiguity", "of", "the", "word", "\"", "mouse", "\"", "(", "animal", "or", "device", ")", "is", "not", "relevant", "for", "machine", "translation", ",", "but", "is", "relevant", "for", "information", "retrieval", "."], "sentence-detokenized": "For example, the ambiguity of the word \"mouse\" (animal or device) is not relevant for machine translation, but is relevant for information retrieval.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 26], [27, 29], [30, 33], [34, 38], [39, 40], [40, 45], [45, 46], [47, 48], [48, 54], [55, 57], [58, 64], [64, 65], [66, 68], [69, 72], [73, 81], [82, 85], [86, 93], [94, 105], [105, 106], [107, 110], [111, 113], [114, 122], [123, 126], [127, 138], [139, 148], [148, 149]]}
{"doc_key": "ai-test-220", "ner": [[0, 1, "algorithm"], [9, 10, "field"], [11, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 1, "usage", "", false, false], [11, 13, 9, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Geometric", "warping", "was", "originally", "proposed", "in", "the", "field", "of", "computer", "vision", "to", "detect", "objects", "in", "2D", "and", "3D", ","], "sentence-detokenized": "Geometric warping was originally proposed in the field of computer vision to detect objects in 2D and 3D,", "token2charspan": [[0, 9], [10, 17], [18, 21], [22, 32], [33, 41], [42, 44], [45, 48], [49, 54], [55, 57], [58, 66], [67, 73], [74, 76], [77, 83], [84, 91], [92, 94], [95, 97], [98, 101], [102, 104], [104, 105]]}
{"doc_key": "ai-test-221", "ner": [[9, 10, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 15, 9, 10, "part-of", "subfield", false, false], [17, 18, 9, 10, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "is", "one", "of", "the", "three", "main", "categories", "of", "machine", "learning", ",", "along", "with", "supervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "It is one of the three main categories of machine learning, along with supervised learning and reinforcement learning.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 12], [13, 16], [17, 22], [23, 27], [28, 38], [39, 41], [42, 49], [50, 58], [58, 59], [60, 65], [66, 70], [71, 81], [82, 90], [91, 94], [95, 108], [109, 117], [117, 118]]}
{"doc_key": "ai-test-222", "ner": [[0, 1, "field"], [17, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 31, "field"], [33, 34, "field"], [36, 37, "field"], [39, 39, "field"], [41, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 1, 17, 17, "part-of", "subfield", false, false], [0, 1, 19, 20, "part-of", "subfield", false, false], [0, 1, 22, 23, "part-of", "subfield", false, false], [0, 1, 25, 26, "part-of", "subfield", false, false], [0, 1, 28, 31, "part-of", "subfield", false, false], [0, 1, 33, 34, "part-of", "subfield", false, false], [0, 1, 36, 37, "part-of", "subfield", false, false], [0, 1, 39, 39, "part-of", "subfield", false, false], [0, 1, 41, 42, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Reinforcement", "learning", ",", "because", "of", "its", "generality", ",", "is", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "games", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimization", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Reinforcement learning, because of its generality, is studied in many other disciplines, such as games, control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 13], [14, 22], [22, 23], [24, 31], [32, 34], [35, 38], [39, 49], [49, 50], [51, 53], [54, 61], [62, 64], [65, 69], [70, 75], [76, 87], [87, 88], [89, 93], [94, 96], [97, 102], [102, 103], [104, 111], [112, 118], [118, 119], [120, 130], [131, 139], [139, 140], [141, 152], [153, 159], [159, 160], [161, 171], [171, 172], [172, 177], [178, 190], [190, 191], [192, 203], [204, 211], [211, 212], [213, 218], [219, 231], [231, 232], [233, 243], [244, 247], [248, 255], [256, 266], [266, 267]]}
{"doc_key": "ai-test-223", "ner": [[0, 1, "field"], [6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "related-to", "", false, false], [0, 1, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pattern", "recognition", "is", "closely", "linked", "to", "artificial", "intelligence", "and", "machine", "learning", ","], "sentence-detokenized": "Pattern recognition is closely linked to artificial intelligence and machine learning,", "token2charspan": [[0, 7], [8, 19], [20, 22], [23, 30], [31, 37], [38, 40], [41, 51], [52, 64], [65, 68], [69, 76], [77, 85], [85, 86]]}
{"doc_key": "ai-test-224", "ner": [[13, 18, "field"], [15, 15, "field"], [26, 27, "task"], [29, 29, "task"], [31, 32, "task"], [34, 35, "algorithm"], [37, 39, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["Software", "is", "used", "to", "design", ",", "train", "and", "deploy", "neural", "network", "models", "(", "supervised", "and", "unsupervised", "learning", ")", "to", "perform", "a", "variety", "of", "tasks", "such", "as", "data", "mining", ",", "classification", ",", "feature", "approximation", ",", "multivariate", "regression", "and", "time", "series", "prediction", "."], "sentence-detokenized": "Software is used to design, train and deploy neural network models (supervised and unsupervised learning) to perform a variety of tasks such as data mining, classification, feature approximation, multivariate regression and time series prediction.", "token2charspan": [[0, 8], [9, 11], [12, 16], [17, 19], [20, 26], [26, 27], [28, 33], [34, 37], [38, 44], [45, 51], [52, 59], [60, 66], [67, 68], [68, 78], [79, 82], [83, 95], [96, 104], [104, 105], [106, 108], [109, 116], [117, 118], [119, 126], [127, 129], [130, 135], [136, 140], [141, 143], [144, 148], [149, 155], [155, 156], [157, 171], [171, 172], [173, 180], [181, 194], [194, 195], [196, 208], [209, 219], [220, 223], [224, 228], [229, 235], [236, 246], [246, 247]]}
{"doc_key": "ai-test-225", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2016", ",", "he", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2016, he was elected a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [98, 99]]}
{"doc_key": "ai-test-226", "ner": [[6, 9, "organisation"], [16, 21, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", "(", "since", "2005", ")", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "(", "since", "2009", ")", ","], "sentence-detokenized": "He is a member of the National Academy of Sciences (since 2005), the American Academy of Arts and Sciences (since 2009),", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 38], [39, 41], [42, 50], [51, 52], [52, 57], [58, 62], [62, 63], [63, 64], [65, 68], [69, 77], [78, 85], [86, 88], [89, 93], [94, 97], [98, 106], [107, 108], [108, 113], [114, 118], [118, 119], [119, 120]]}
{"doc_key": "ai-test-227", "ner": [[0, 5, "misc"], [9, 13, "product"], [16, 17, "country"], [19, 19, "country"], [24, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 13, 0, 5, "temporal", "", false, false], [9, 13, 16, 17, "physical", "", false, false], [9, 13, 19, 19, "physical", "", false, false], [9, 13, 24, 26, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "the", "1973", "Yom", "Kippur", "War", ",", "Soviet", "-supplied", "surface", "-", "to", "-", "air", "missile", "batteries", "in", "Egypt", "and", "Syria", "caused", "extensive", "damage", "to", "Israeli", "fighter", "aircraft", "."], "sentence-detokenized": "During the 1973 Yom Kippur War, Soviet-supplied surface-to-air missile batteries in Egypt and Syria caused extensive damage to Israeli fighter aircraft.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 26], [27, 30], [30, 31], [32, 38], [38, 47], [48, 55], [55, 56], [56, 58], [58, 59], [59, 62], [63, 70], [71, 80], [81, 83], [84, 89], [90, 93], [94, 99], [100, 106], [107, 116], [117, 123], [124, 126], [127, 134], [135, 142], [143, 151], [151, 152]]}
{"doc_key": "ai-test-228", "ner": [[10, 11, "product"], [15, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 16, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Another", "resource", "(", "free", "but", "copyright", "protected", ")", "is", "the", "HTK", "book", "(", "and", "accompanying", "HTK", "toolkit", ")", "."], "sentence-detokenized": "Another resource (free but copyright protected) is the HTK book (and accompanying HTK toolkit).", "token2charspan": [[0, 7], [8, 16], [17, 18], [18, 22], [23, 26], [27, 36], [37, 46], [46, 47], [48, 50], [51, 54], [55, 58], [59, 63], [64, 65], [65, 68], [69, 81], [82, 85], [86, 93], [93, 94], [94, 95]]}
{"doc_key": "ai-test-229", "ner": [[4, 6, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "was", "taken", "at", "the", "2004", "AAAI", "Spring", "Symposium", ",", "where", "linguists", ",", "computer", "scientists", "and", "other", "interested", "researchers", "coordinated", "their", "interests", "for", "the", "first", "time", "and", "proposed", "common", "tasks", "and", "reference", "datasets", "for", "the", "systematic", "computational", "study", "of", "affect", ",", "attraction", ",", "subjectivity", "and", "emotion", "in", "text", "."], "sentence-detokenized": "- was taken at the 2004 AAAI Spring Symposium, where linguists, computer scientists and other interested researchers coordinated their interests for the first time and proposed common tasks and reference datasets for the systematic computational study of affect, attraction, subjectivity and emotion in text.", "token2charspan": [[0, 1], [2, 5], [6, 11], [12, 14], [15, 18], [19, 23], [24, 28], [29, 35], [36, 45], [45, 46], [47, 52], [53, 62], [62, 63], [64, 72], [73, 83], [84, 87], [88, 93], [94, 104], [105, 116], [117, 128], [129, 134], [135, 144], [145, 148], [149, 152], [153, 158], [159, 163], [164, 167], [168, 176], [177, 183], [184, 189], [190, 193], [194, 203], [204, 212], [213, 216], [217, 220], [221, 231], [232, 245], [246, 251], [252, 254], [255, 261], [261, 262], [263, 273], [273, 274], [275, 287], [288, 291], [292, 299], [300, 302], [303, 307], [307, 308]]}
{"doc_key": "ai-test-230", "ner": [[12, 16, "task"], [26, 27, "task"], [29, 31, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "single", "grid", "can", "be", "analysed", "both", "in", "terms", "of", "content", "(", "at", "-", "a", "-glance", "observation", ")", "and", "structure", "(", "the", "main", "methods", "used", "are", "cluster", "analysis", ",", "principal", "component", "analysis", "and", "various", "structural", "indicators", "related", "to", "the", "complexity", "and", "scope", "of", "the", "estimates", ")", "."], "sentence-detokenized": "A single grid can be analysed both in terms of content (at-a-glance observation) and structure (the main methods used are cluster analysis, principal component analysis and various structural indicators related to the complexity and scope of the estimates).", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 17], [18, 20], [21, 29], [30, 34], [35, 37], [38, 43], [44, 46], [47, 54], [55, 56], [56, 58], [58, 59], [59, 60], [60, 67], [68, 79], [79, 80], [81, 84], [85, 94], [95, 96], [96, 99], [100, 104], [105, 112], [113, 117], [118, 121], [122, 129], [130, 138], [138, 139], [140, 149], [150, 159], [160, 168], [169, 172], [173, 180], [181, 191], [192, 202], [203, 210], [211, 213], [214, 217], [218, 228], [229, 232], [233, 238], [239, 241], [242, 245], [246, 255], [255, 256], [256, 257]]}
{"doc_key": "ai-test-231", "ner": [[3, 3, "organisation"], [10, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2018", ",", "Toyota", "was", "seen", "as", "lagging", "behind", "in", "self", "-", "driving", "cars", "and", "in", "need", "of", "innovation", "."], "sentence-detokenized": "In 2018, Toyota was seen as lagging behind in self-driving cars and in need of innovation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 24], [25, 27], [28, 35], [36, 42], [43, 45], [46, 50], [50, 51], [51, 58], [59, 63], [64, 67], [68, 70], [71, 75], [76, 78], [79, 89], [89, 90]]}
{"doc_key": "ai-test-232", "ner": [[39, 40, "misc"], [42, 43, "misc"], [45, 49, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "targets", "include", "natural", "objects", "such", "as", "the", "ground", ",", "the", "sea", ",", "precipitation", "(", "e.g.", "rain", ",", "snow", "or", "hail", ")", ",", "sandstorms", ",", "animals", "(", "especially", "birds", ")", ",", "atmospheric", "turbulence", "and", "other", "atmospheric", "effects", "such", "as", "ionospheric", "reflections", ",", "meteor", "trails", "and", "three", "-", "body", "scattering", "peaks", "."], "sentence-detokenized": "Such targets include natural objects such as the ground, the sea, precipitation (e.g. rain, snow or hail), sandstorms, animals (especially birds), atmospheric turbulence and other atmospheric effects such as ionospheric reflections, meteor trails and three-body scattering peaks.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 28], [29, 36], [37, 41], [42, 44], [45, 48], [49, 55], [55, 56], [57, 60], [61, 64], [64, 65], [66, 79], [80, 81], [81, 85], [86, 90], [90, 91], [92, 96], [97, 99], [100, 104], [104, 105], [105, 106], [107, 117], [117, 118], [119, 126], [127, 128], [128, 138], [139, 144], [144, 145], [145, 146], [147, 158], [159, 169], [170, 173], [174, 179], [180, 191], [192, 199], [200, 204], [205, 207], [208, 219], [220, 231], [231, 232], [233, 239], [240, 246], [247, 250], [251, 256], [256, 257], [257, 261], [262, 272], [273, 278], [278, 279]]}
{"doc_key": "ai-test-233", "ner": [[39, 40, "misc"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "terms", "of", "planning", "and", "control", ",", "an", "important", "difference", "between", "humanoids", "and", "other", "types", "of", "robots", "(", "e.g.", "industrial", "robots", ")", "is", "that", "the", "robot", "'s", "movements", "must", "be", "human", "-", "like", ",", "using", "leg", "movements", ",", "especially", "bipedal", "walking", "."], "sentence-detokenized": "In terms of planning and control, an important difference between humanoids and other types of robots (e.g. industrial robots) is that the robot's movements must be human-like, using leg movements, especially bipedal walking.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 20], [21, 24], [25, 32], [32, 33], [34, 36], [37, 46], [47, 57], [58, 65], [66, 75], [76, 79], [80, 85], [86, 91], [92, 94], [95, 101], [102, 103], [103, 107], [108, 118], [119, 125], [125, 126], [127, 129], [130, 134], [135, 138], [139, 144], [144, 146], [147, 156], [157, 161], [162, 164], [165, 170], [170, 171], [171, 175], [175, 176], [177, 182], [183, 186], [187, 196], [196, 197], [198, 208], [209, 216], [217, 224], [224, 225]]}
{"doc_key": "ai-test-234", "ner": [[0, 1, "algorithm"], [9, 12, "misc"], [14, 14, "metrics"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Gradient", "descent", "can", "take", "many", "iterations", "to", "compute", "a", "local", "minimum", "with", "the", "required", "accuracy", "if", "the", "curvature", "of", "a", "given", "function", "varies", "greatly", "in", "different", "directions", "."], "sentence-detokenized": "Gradient descent can take many iterations to compute a local minimum with the required accuracy if the curvature of a given function varies greatly in different directions.", "token2charspan": [[0, 8], [9, 16], [17, 20], [21, 25], [26, 30], [31, 41], [42, 44], [45, 52], [53, 54], [55, 60], [61, 68], [69, 73], [74, 77], [78, 86], [87, 95], [96, 98], [99, 102], [103, 112], [113, 115], [116, 117], [118, 123], [124, 132], [133, 139], [140, 147], [148, 150], [151, 160], [161, 171], [171, 172]]}
{"doc_key": "ai-test-235", "ner": [[0, 6, "misc"], [10, 10, "misc"], [16, 22, "conference"], [26, 26, "location"], [28, 30, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 6, 10, 10, "part-of", "", true, false], [16, 22, 26, 26, "physical", "", false, true], [26, 26, 28, 30, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "1997", "RoboCup", "2D", "Soccer", "Simulation", "League", "was", "the", "first", "RoboCup", "competition", "organised", "in", "conjunction", "with", "the", "International", "Joint", "Conference", "on", "Artificial", "Intelligence", ",", "held", "in", "Nagoya", ",", "Japan", ",", "from", "23", "to", "29", "August", "1997", "."], "sentence-detokenized": "The 1997 RoboCup 2D Soccer Simulation League was the first RoboCup competition organised in conjunction with the International Joint Conference on Artificial Intelligence, held in Nagoya, Japan, from 23 to 29 August 1997.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 19], [20, 26], [27, 37], [38, 44], [45, 48], [49, 52], [53, 58], [59, 66], [67, 78], [79, 88], [89, 91], [92, 103], [104, 108], [109, 112], [113, 126], [127, 132], [133, 143], [144, 146], [147, 157], [158, 170], [170, 171], [172, 176], [177, 179], [180, 186], [186, 187], [188, 193], [193, 194], [195, 199], [200, 202], [203, 205], [206, 208], [209, 215], [216, 220], [220, 221]]}
{"doc_key": "ai-test-236", "ner": [[15, 16, "product"]], "ner_mapping_to_source": [2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "options", "include", "a", "built", "-", "in", "Python", "environment", "and", "R", "console", ",", "and", "Rserve", "support", "."], "sentence-detokenized": "Other programming options include a built-in Python environment and R console, and Rserve support.", "token2charspan": [[0, 5], [6, 17], [18, 25], [26, 33], [34, 35], [36, 41], [41, 42], [42, 44], [45, 51], [52, 63], [64, 67], [68, 69], [70, 77], [77, 78], [79, 82], [83, 89], [90, 97], [97, 98]]}
{"doc_key": "ai-test-237", "ner": [[0, 1, "location"], [12, 13, "field"], [15, 15, "field"], [19, 20, "researcher"], [22, 23, "researcher"], [25, 26, "researcher"], [39, 40, "field"], [47, 48, "field"], [51, 52, "field"], [55, 59, "field"], [65, 68, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[19, 20, 15, 15, "related-to", "contributes_to_field", true, false], [22, 23, 15, 15, "related-to", "contributes_to_field", true, false], [25, 26, 15, 15, "related-to", "contributes_to_field", true, false], [51, 52, 47, 48, "part-of", "", false, false], [55, 59, 51, 52, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["From", "Bonn", ",", "he", "has", "made", "important", "contributions", "to", "the", "development", "of", "artificial", "intelligence", "and", "robotics", "(", "together", "with", "Wolfram", "Burgard", ",", "Dieter", "Fox", ",", "Sebastian", "Thrun", "among", "his", "students", ")", ",", "as", "well", "as", "to", "the", "development", "of", "software", "engineering", ",", "especially", "in", "the", "field", "of", "civil", "engineering", ",", "and", "information", "systems", ",", "especially", "in", "the", "geosciences", ".", "In", "2016", ",", "he", "won", "the", "AAAI", "Classic", "Paper", "Award", "2014", "."], "sentence-detokenized": "From Bonn, he has made important contributions to the development of artificial intelligence and robotics (together with Wolfram Burgard, Dieter Fox, Sebastian Thrun among his students), as well as to the development of software engineering, especially in the field of civil engineering, and information systems, especially in the geosciences. In 2016, he won the AAAI Classic Paper Award 2014.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 13], [14, 17], [18, 22], [23, 32], [33, 46], [47, 49], [50, 53], [54, 65], [66, 68], [69, 79], [80, 92], [93, 96], [97, 105], [106, 107], [107, 115], [116, 120], [121, 128], [129, 136], [136, 137], [138, 144], [145, 148], [148, 149], [150, 159], [160, 165], [166, 171], [172, 175], [176, 184], [184, 185], [185, 186], [187, 189], [190, 194], [195, 197], [198, 200], [201, 204], [205, 216], [217, 219], [220, 228], [229, 240], [240, 241], [242, 252], [253, 255], [256, 259], [260, 265], [266, 268], [269, 274], [275, 286], [286, 287], [288, 291], [292, 303], [304, 311], [311, 312], [313, 323], [324, 326], [327, 330], [331, 342], [342, 343], [344, 346], [347, 351], [351, 352], [353, 355], [356, 359], [360, 363], [364, 368], [369, 376], [377, 382], [383, 388], [389, 393], [393, 394]]}
{"doc_key": "ai-test-238", "ner": [[2, 6, "conference"], [17, 18, "location"], [20, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 6, 17, 18, "physical", "", false, false], [17, 18, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "first", "Campus", "Party", "in", "the", "US", "will", "take", "place", "on", "20", "-", "22", "August", "at", "the", "TCF", "Center", "in", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "The first Campus Party in the US will take place on 20-22 August at the TCF Center in Detroit, Michigan.", "token2charspan": [[0, 3], [4, 9], [10, 16], [17, 22], [23, 25], [26, 29], [30, 32], [33, 37], [38, 42], [43, 48], [49, 51], [52, 54], [54, 55], [55, 57], [58, 64], [65, 67], [68, 71], [72, 75], [76, 82], [83, 85], [86, 93], [93, 94], [95, 103], [103, 104]]}
{"doc_key": "ai-test-239", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [12, 13, "misc"], [22, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 12, 13, "win-defeat", "", false, false], [5, 6, 12, 13, "win-defeat", "", false, false], [8, 8, 12, 13, "win-defeat", "", false, false], [12, 13, 22, 25, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Together", "with", "Yann", "LeCun", "and", "Yoshua", "Bengio", ",", "Hinton", "won", "the", "2018", "Turing", "Prize", "for", "conceptual", "and", "technical", "breakthroughs", "that", "have", "made", "deep", "neural", "networks", "a", "critical", "component", "of", "computing", "."], "sentence-detokenized": "Together with Yann LeCun and Yoshua Bengio, Hinton won the 2018 Turing Prize for conceptual and technical breakthroughs that have made deep neural networks a critical component of computing.", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 24], [25, 28], [29, 35], [36, 42], [42, 43], [44, 50], [51, 54], [55, 58], [59, 63], [64, 70], [71, 76], [77, 80], [81, 91], [92, 95], [96, 105], [106, 119], [120, 124], [125, 129], [130, 134], [135, 139], [140, 146], [147, 155], [156, 157], [158, 166], [167, 176], [177, 179], [180, 189], [189, 190]]}
{"doc_key": "ai-test-240", "ner": [[0, 3, "product"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 10, 10, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Euler", "Math", "Toolbox", "uses", "a", "matrix", "language", "similar", "to", "MATLAB", ",", "which", "has", "been", "developed", "since", "the", "1970s", "."], "sentence-detokenized": "The Euler Math Toolbox uses a matrix language similar to MATLAB, which has been developed since the 1970s.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 22], [23, 27], [28, 29], [30, 36], [37, 45], [46, 53], [54, 56], [57, 63], [63, 64], [65, 70], [71, 74], [75, 79], [80, 89], [90, 95], [96, 99], [100, 105], [105, 106]]}
{"doc_key": "ai-test-241", "ner": [[7, 7, "programlang"], [9, 10, "programlang"], [12, 12, "programlang"], [14, 14, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "languages", "allow", "this", "portably", "(", "e.g.", "Scheme", ",", "Common", "Lisp", ",", "Perl", "or", "D", ")", "."], "sentence-detokenized": "Some languages allow this portably (e.g. Scheme, Common Lisp, Perl or D).", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 25], [26, 34], [35, 36], [36, 40], [41, 47], [47, 48], [49, 55], [56, 60], [60, 61], [62, 66], [67, 69], [70, 71], [71, 72], [72, 73]]}
{"doc_key": "ai-test-242", "ner": [[12, 12, "misc"], [3, 4, "researcher"], [6, 7, "researcher"], [25, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 12, 3, 4, "artifact", "", false, false], [12, 12, 6, 7, "artifact", "", false, false], [12, 12, 25, 27, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1969", ",", "Marvin", "Minsky", "and", "Seymour", "Papert", "'s", "famous", "book", "\"", "Perceptrons", "\"", "was", "published", ",", "showing", "that", "it", "is", "impossible", "to", "learn", "the", "XOR", "function", "for", "such", "classes", "of", "networks", "."], "sentence-detokenized": "In 1969, Marvin Minsky and Seymour Papert's famous book \"Perceptrons\" was published, showing that it is impossible to learn the XOR function for such classes of networks.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 22], [23, 26], [27, 34], [35, 41], [41, 43], [44, 50], [51, 55], [56, 57], [57, 68], [68, 69], [70, 73], [74, 83], [83, 84], [85, 92], [93, 97], [98, 100], [101, 103], [104, 114], [115, 117], [118, 123], [124, 127], [128, 131], [132, 140], [141, 144], [145, 149], [150, 157], [158, 160], [161, 169], [169, 170]]}
{"doc_key": "ai-test-243", "ner": [[4, 8, "misc"], [12, 12, "product"], [18, 21, "organisation"], [25, 30, "organisation"], [33, 38, "location"], [40, 40, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 21, 12, 12, "usage", "", false, false], [18, 21, 33, 38, "physical", "", false, false], [25, 30, 18, 21, "named", "", false, false], [33, 38, 40, 40, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "large", "number", "of", "Russian", "scientific", "and", "technical", "documents", "were", "translated", "using", "SYSTRAN", "under", "the", "auspices", "of", "the", "USAF", "Foreign", "Technology", "Division", "(", "later", "the", "National", "Air", "and", "Space", "Intelligence", "Center", ")", "at", "Wright", "-", "Patterson", "Air", "Force", "Base", ",", "Ohio", "."], "sentence-detokenized": "A large number of Russian scientific and technical documents were translated using SYSTRAN under the auspices of the USAF Foreign Technology Division (later the National Air and Space Intelligence Center) at Wright-Patterson Air Force Base, Ohio.", "token2charspan": [[0, 1], [2, 7], [8, 14], [15, 17], [18, 25], [26, 36], [37, 40], [41, 50], [51, 60], [61, 65], [66, 76], [77, 82], [83, 90], [91, 96], [97, 100], [101, 109], [110, 112], [113, 116], [117, 121], [122, 129], [130, 140], [141, 149], [150, 151], [151, 156], [157, 160], [161, 169], [170, 173], [174, 177], [178, 183], [184, 196], [197, 203], [203, 204], [205, 207], [208, 214], [214, 215], [215, 224], [225, 228], [229, 234], [235, 239], [239, 240], [241, 245], [245, 246]]}
{"doc_key": "ai-test-244", "ner": [[0, 2, "field"], [0, 5, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Semi-supervised", "learning", "falls", "between", "unsupervised", "learning", "(", "without", "labelled", "training", "data", ")", "and", "supervised", "learning", "(", "with", "fully", "labelled", "training", "data", ")", "."], "sentence-detokenized": "Semi-supervised learning falls between unsupervised learning (without labelled training data) and supervised learning (with fully labelled training data).", "token2charspan": [[0, 15], [16, 24], [25, 30], [31, 38], [39, 51], [52, 60], [61, 62], [62, 69], [70, 78], [79, 87], [88, 92], [92, 93], [94, 97], [98, 108], [109, 117], [118, 119], [119, 123], [124, 129], [130, 138], [139, 147], [148, 152], [152, 153], [153, 154]]}
{"doc_key": "ai-test-245", "ner": [[0, 4, "algorithm"], [9, 12, "algorithm"], [14, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 9, 12, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Ann", "-", "gram", "model", "is", "a", "type", "of", "probabilistic", "language", "model", "that", ",", "in", "the", "form", "of", "a", "Markov", "model", "of", "the", "(", "n", "-", "1", ")", "sequence", ",", "can", "efficiently", "predict", "the", "next", "element", "in", "that", "sequence", "."], "sentence-detokenized": "The Ann -gram model is a type of probabilistic language model that, in the form of a Markov model of the (n - 1) sequence, can efficiently predict the next element in that sequence.", "token2charspan": [[0, 3], [4, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 24], [25, 29], [30, 32], [33, 46], [47, 55], [56, 61], [62, 66], [66, 67], [68, 70], [71, 74], [75, 79], [80, 82], [83, 84], [85, 91], [92, 97], [98, 100], [101, 104], [105, 106], [106, 107], [108, 109], [110, 111], [111, 112], [113, 121], [121, 122], [123, 126], [127, 138], [139, 146], [147, 150], [151, 155], [156, 163], [164, 166], [167, 171], [172, 180], [180, 181]]}
{"doc_key": "ai-test-246", "ner": [[0, 2, "organisation"], [5, 5, "product"], [8, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 5, 5, "usage", "", false, false], [8, 15, 0, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Cleveland", "Clinic", "has", "used", "Cyc", "to", "develop", "a", "natural", "language", "query", "list", "of", "biomedical", "information", ",", "covering", "decades", "of", "information", "on", "heart", "and", "breast", "surgery", "."], "sentence-detokenized": "The Cleveland Clinic has used Cyc to develop a natural language query list of biomedical information, covering decades of information on heart and breast surgery.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 24], [25, 29], [30, 33], [34, 36], [37, 44], [45, 46], [47, 54], [55, 63], [64, 69], [70, 74], [75, 77], [78, 88], [89, 100], [100, 101], [102, 110], [111, 118], [119, 121], [122, 133], [134, 136], [137, 142], [143, 146], [147, 153], [154, 161], [161, 162]]}
{"doc_key": "ai-test-247", "ner": [[6, 7, "country"], [3, 9, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 3, 9, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "incident", "strained", "relations", "between", "the", "United", "States", "and", "Japan", "and", "led", "to", "the", "arrest", "and", "prosecution", "of", "two", "senior", "executives", "and", "the", "imposition", "of", "sanctions", "on", "the", "company", "by", "both", "countries", "."], "sentence-detokenized": "The incident strained relations between the United States and Japan and led to the arrest and prosecution of two senior executives and the imposition of sanctions on the company by both countries.", "token2charspan": [[0, 3], [4, 12], [13, 21], [22, 31], [32, 39], [40, 43], [44, 50], [51, 57], [58, 61], [62, 67], [68, 71], [72, 75], [76, 78], [79, 82], [83, 89], [90, 93], [94, 105], [106, 108], [109, 112], [113, 119], [120, 130], [131, 134], [135, 138], [139, 149], [150, 152], [153, 162], [163, 165], [166, 169], [170, 177], [178, 180], [181, 185], [186, 195], [195, 196]]}
{"doc_key": "ai-test-248", "ner": [[6, 8, "algorithm"], [4, 12, "field"], [18, 20, "misc"], [30, 30, "misc"], [33, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 8, 4, 12, "type-of", "", false, false], [18, 20, 4, 12, "part-of", "", true, false], [30, 30, 4, 12, "part-of", "", true, false], [33, 33, 4, 12, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["When", "modelling", "is", "done", "using", "an", "artificial", "neural", "network", "or", "other", "machine", "learning", ",", "parameter", "optimisation", "is", "called", "training", ",", "while", "optimisation", "of", "the", "hyperparameters", "of", "a", "model", "is", "called", "tuning", "and", "often", "cross-validation", "is", "used", "."], "sentence-detokenized": "When modelling is done using an artificial neural network or other machine learning, parameter optimisation is called training, while optimisation of the hyperparameters of a model is called tuning and often cross-validation is used.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 22], [23, 28], [29, 31], [32, 42], [43, 49], [50, 57], [58, 60], [61, 66], [67, 74], [75, 83], [83, 84], [85, 94], [95, 107], [108, 110], [111, 117], [118, 126], [126, 127], [128, 133], [134, 146], [147, 149], [150, 153], [154, 169], [170, 172], [173, 174], [175, 180], [181, 183], [184, 190], [191, 197], [198, 201], [202, 207], [208, 224], [225, 227], [228, 232], [232, 233]]}
{"doc_key": "ai-test-249", "ner": [[16, 18, "country"], [20, 20, "country"], [22, 22, "country"], [4, 6, "organisation"], [7, 7, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Following", "the", "acquisition", "of", "Rotten", "Tomatoes", "by", "Fandango", ",", "localised", "versions", "of", "the", "website", "were", "discontinued", "in", "the", "UK", ",", "India", "and", "Australia", "."], "sentence-detokenized": "Following the acquisition of Rotten Tomatoes by Fandango, localised versions of the website were discontinued in the UK, India and Australia.", "token2charspan": [[0, 9], [10, 13], [14, 25], [26, 28], [29, 35], [36, 44], [45, 47], [48, 56], [56, 57], [58, 67], [68, 76], [77, 79], [80, 83], [84, 91], [92, 96], [97, 109], [110, 112], [113, 116], [117, 119], [119, 120], [121, 126], [127, 130], [131, 140], [140, 141]]}
{"doc_key": "ai-test-250", "ner": [[13, 15, "metrics"], [23, 24, "task"]], "ner_mapping_to_source": [1, 2], "relations": [[13, 15, 23, 24, "related-to", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["The", "NER", "model", "is", "one", "of", "a", "number", "of", "methods", "used", "to", "determine", "the", "accuracy", "of", "live", "broadcasts", "and", "event", "subtitles", "produced", "using", "speech", "recognition", "."], "sentence-detokenized": "The NER model is one of a number of methods used to determine the accuracy of live broadcasts and event subtitles produced using speech recognition.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 20], [21, 23], [24, 25], [26, 32], [33, 35], [36, 43], [44, 48], [49, 51], [52, 61], [62, 65], [66, 74], [75, 77], [78, 82], [83, 93], [94, 97], [98, 103], [104, 113], [114, 122], [123, 128], [129, 135], [136, 147], [147, 148]]}
{"doc_key": "ai-test-251", "ner": [[0, 0, "researcher"], [5, 7, "university"], [10, 12, "university"], [13, 13, "location"], [16, 20, "university"], [23, 24, "university"], [25, 26, "location"], [30, 35, "university"], [36, 38, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 5, 7, "physical", "", false, false], [0, 0, 5, 7, "role", "", false, false], [0, 0, 10, 12, "physical", "", false, false], [0, 0, 10, 12, "role", "", false, false], [0, 0, 16, 20, "physical", "", false, false], [0, 0, 16, 20, "role", "", false, false], [0, 0, 23, 24, "physical", "", false, false], [0, 0, 23, 24, "role", "", false, false], [0, 0, 30, 35, "physical", "", false, false], [0, 0, 30, 35, "role", "", false, false], [10, 12, 13, 13, "physical", "", false, false], [16, 20, 25, 26, "physical", "", false, false], [23, 24, 25, 26, "physical", "", false, false], [30, 35, 36, 38, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Atran", "has", "taught", "at", "the", "University", "of", "Cambridge", ",", "the", "Hebrew", "University", "of", "Jerusalem", ",", "the", "\u00c9cole", "pratique", "des", "hautes", "\u00e9tudes", "and", "the", "\u00c9cole", "Polytechnique", "in", "Paris", ",", "and", "the", "John", "Jay", "College", "of", "Criminal", "Justice", "in", "New", "York", "."], "sentence-detokenized": "Atran has taught at the University of Cambridge, the Hebrew University of Jerusalem, the \u00c9cole pratique des hautes \u00e9tudes and the \u00c9cole Polytechnique in Paris, and the John Jay College of Criminal Justice in New York.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 23], [24, 34], [35, 37], [38, 47], [47, 48], [49, 52], [53, 59], [60, 70], [71, 73], [74, 83], [83, 84], [85, 88], [89, 94], [95, 103], [104, 107], [108, 114], [115, 121], [122, 125], [126, 129], [130, 135], [136, 149], [150, 152], [153, 158], [158, 159], [160, 163], [164, 167], [168, 172], [173, 176], [177, 184], [185, 187], [188, 196], [197, 204], [205, 207], [208, 211], [212, 216], [216, 217]]}
{"doc_key": "ai-test-252", "ner": [[0, 0, "product"], [4, 6, "task"], [11, 12, "researcher"], [13, 15, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 6, "origin", "", false, false], [0, 0, 4, 6, "related-to", "", false, false], [4, 6, 13, 15, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "was", "an", "early", "natural", "language", "understanding", "computer", "program", "developed", "by", "Terry", "Winograd", "at", "MIT", "in", "1968", "-", "1970", "."], "sentence-detokenized": "SHRDLU was an early natural language understanding computer program developed by Terry Winograd at MIT in 1968-1970.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 19], [20, 27], [28, 36], [37, 50], [51, 59], [60, 67], [68, 77], [78, 80], [81, 86], [87, 95], [96, 98], [99, 102], [103, 105], [106, 110], [110, 111], [111, 115], [115, 116]]}
{"doc_key": "ai-test-253", "ner": [[3, 4, "misc"], [5, 6, "field"], [9, 13, "university"], [15, 15, "location"], [17, 19, "country"], [24, 25, "university"], [28, 28, "misc"], [30, 34, "field"], [36, 38, "university"], [42, 43, "misc"], [44, 46, "field"], [49, 50, "misc"], [52, 58, "university"], [63, 64, "field"], [68, 69, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[3, 4, 5, 6, "topic", "", false, false], [3, 4, 9, 13, "origin", "", false, false], [9, 13, 15, 15, "physical", "", false, false], [9, 13, 24, 25, "role", "affiliated_with", false, false], [15, 15, 17, 19, "physical", "", false, false], [28, 28, 30, 34, "topic", "", false, false], [28, 28, 36, 38, "origin", "", false, false], [42, 43, 44, 46, "topic", "", false, false], [49, 50, 52, 58, "origin", "", false, false], [49, 50, 63, 64, "topic", "", false, false], [68, 69, 52, 58, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["He", "received", "his", "B.S.", "in", "electronic", "engineering", "from", "the", "B.M.S", ".", "College", "of", "Engineering", ",", "Bangalore", ",", "India", ",", "in", "1982", "while", "affiliated", "with", "Bangalore", "University", ",", "his", "M.S.", "in", "electrical", "and", "computer", "engineering", "in", "1984", "from", "Drexel", "University", ",", "and", "his", "M.S.", "in", "computer", "science", "in", "1989", "and", "Ph.D.", "in", "1990", "from", "the", "University", "of", "Wisconsin", "-", "Madison", ",", "where", "he", "studied", "artificial", "intelligence", "and", "worked", "with", "Leonard", "Uhr", "."], "sentence-detokenized": "He received his B.S. in electronic engineering from the B.M.S. College of Engineering, Bangalore, India, in 1982 while affiliated with Bangalore University, his M.S. in electrical and computer engineering in 1984 from Drexel University, and his M.S. in computer science in 1989 and Ph.D. in 1990 from the University of Wisconsin-Madison, where he studied artificial intelligence and worked with Leonard Uhr.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 20], [21, 23], [24, 34], [35, 46], [47, 51], [52, 55], [56, 61], [61, 62], [63, 70], [71, 73], [74, 85], [85, 86], [87, 96], [96, 97], [98, 103], [103, 104], [105, 107], [108, 112], [113, 118], [119, 129], [130, 134], [135, 144], [145, 155], [155, 156], [157, 160], [161, 165], [166, 168], [169, 179], [180, 183], [184, 192], [193, 204], [205, 207], [208, 212], [213, 217], [218, 224], [225, 235], [235, 236], [237, 240], [241, 244], [245, 249], [250, 252], [253, 261], [262, 269], [270, 272], [273, 277], [278, 281], [282, 287], [288, 290], [291, 295], [296, 300], [301, 304], [305, 315], [316, 318], [319, 328], [328, 329], [329, 336], [336, 337], [338, 343], [344, 346], [347, 354], [355, 365], [366, 378], [379, 382], [383, 389], [390, 394], [395, 402], [403, 406], [406, 407]]}
{"doc_key": "ai-test-254", "ner": [[9, 9, "metrics"], [7, 14, "metrics"], [19, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 14, 9, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Accuracy", "is", "usually", "measured", "in", "terms", "of", "word", "error", "rate", "(", "WER", ")", ",", "while", "speed", "is", "measured", "in", "real", "time", "."], "sentence-detokenized": "Accuracy is usually measured in terms of word error rate (WER), while speed is measured in real time.", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 28], [29, 31], [32, 37], [38, 40], [41, 45], [46, 51], [52, 56], [57, 58], [58, 61], [61, 62], [62, 63], [64, 69], [70, 75], [76, 78], [79, 87], [88, 90], [91, 95], [96, 100], [100, 101]]}
{"doc_key": "ai-test-255", "ner": [[3, 4, "researcher"], [8, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 8, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1971", ",", "Terry", "Winograd", "developed", "an", "early", "natural", "language", "processing", "engine", "that", "could", "interpret", "naturally", "written", "commands", "in", "a", "simple", "rule", "-", "driven", "environment", "."], "sentence-detokenized": "In 1971, Terry Winograd developed an early natural language processing engine that could interpret naturally written commands in a simple rule-driven environment.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 33], [34, 36], [37, 42], [43, 50], [51, 59], [60, 70], [71, 77], [78, 82], [83, 88], [89, 98], [99, 108], [109, 116], [117, 125], [126, 128], [129, 130], [131, 137], [138, 142], [142, 143], [143, 149], [150, 161], [161, 162]]}
{"doc_key": "ai-test-256", "ner": [[4, 5, "field"], [7, 8, "researcher"], [10, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 7, 8, "related-to", "", false, false], [4, 5, 10, 13, "related-to", "", false, false], [4, 5, 15, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "field", "of", "artificial", "intelligence", ",", "Marvin", "Minsky", ",", "Herbert", "A", ".", "Simon", "and", "Allen", "Newell", "."], "sentence-detokenized": "In the field of artificial intelligence, Marvin Minsky, Herbert A. Simon and Allen Newell.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 26], [27, 39], [39, 40], [41, 47], [48, 54], [54, 55], [56, 63], [64, 65], [65, 66], [67, 72], [73, 76], [77, 82], [83, 89], [89, 90]]}
{"doc_key": "ai-test-257", "ner": [[9, 10, "field"], [30, 31, "field"], [33, 34, "field"], [37, 38, "field"], [47, 50, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[30, 31, 9, 10, "origin", "", true, false], [30, 31, 9, 10, "part-of", "", false, false], [30, 31, 37, 38, "compare", "", false, false], [33, 34, 9, 10, "origin", "", true, false], [33, 34, 9, 10, "part-of", "", false, false], [33, 34, 37, 38, "compare", "", false, false], [37, 38, 9, 10, "origin", "", true, false], [37, 38, 9, 10, "part-of", "", false, false], [37, 38, 47, 50, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "the", "second", "half", "of", "the", "20th", "century", ",", "electrical", "engineering", "split", "into", "several", "disciplines", "specialising", "in", "the", "design", "and", "analysis", "of", "systems", "manipulating", "physical", "signals", ";", "for", "example", ",", "electronics", "engineering", "and", "computer", "engineering", ";", "while", "design", "engineering", "evolved", "to", "deal", "with", "the", "functional", "design", "of", "user", "-", "machine", "interfaces", "."], "sentence-detokenized": "In the second half of the 20th century, electrical engineering split into several disciplines specialising in the design and analysis of systems manipulating physical signals; for example, electronics engineering and computer engineering; while design engineering evolved to deal with the functional design of user-machine interfaces.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 21], [22, 25], [26, 30], [31, 38], [38, 39], [40, 50], [51, 62], [63, 68], [69, 73], [74, 81], [82, 93], [94, 106], [107, 109], [110, 113], [114, 120], [121, 124], [125, 133], [134, 136], [137, 144], [145, 157], [158, 166], [167, 174], [174, 175], [176, 179], [180, 187], [187, 188], [189, 200], [201, 212], [213, 216], [217, 225], [226, 237], [237, 238], [239, 244], [245, 251], [252, 263], [264, 271], [272, 274], [275, 279], [280, 284], [285, 288], [289, 299], [300, 306], [307, 309], [310, 314], [314, 315], [315, 322], [323, 333], [333, 334]]}
{"doc_key": "ai-test-258", "ner": [[6, 6, "metrics"], [8, 9, "metrics"], [11, 14, "metrics"], [45, 47, "metrics"], [54, 56, "metrics"], [60, 66, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 14, 8, 9, "named", "", false, false], [45, 47, 54, 56, "named", "", false, false], [54, 56, 60, 66, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Perhaps", "the", "simplest", "statistic", "is", "the", "accuracy", "or", "proportion", "correct", "(", "FC", ")", ",", "which", "measures", "the", "proportion", "of", "all", "correctly", "classified", "cases", ";", "it", "is", "the", "ratio", "of", "the", "number", "of", "correct", "classifications", "to", "the", "total", "number", "of", "correct", "or", "incorrect", "classifications", ":", "(", "TP", "+", "TN", ")", "/", "total", "population", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "Perhaps the simplest statistic is the accuracy or proportion correct (FC), which measures the proportion of all correctly classified cases; it is the ratio of the number of correct classifications to the total number of correct or incorrect classifications: (TP + TN) / total population = (TP + TN) / (TP + TN + FP + FN).", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 30], [31, 33], [34, 37], [38, 46], [47, 49], [50, 60], [61, 68], [69, 70], [70, 72], [72, 73], [73, 74], [75, 80], [81, 89], [90, 93], [94, 104], [105, 107], [108, 111], [112, 121], [122, 132], [133, 138], [138, 139], [140, 142], [143, 145], [146, 149], [150, 155], [156, 158], [159, 162], [163, 169], [170, 172], [173, 180], [181, 196], [197, 199], [200, 203], [204, 209], [210, 216], [217, 219], [220, 227], [228, 230], [231, 240], [241, 256], [256, 257], [258, 259], [259, 261], [262, 263], [264, 266], [266, 267], [268, 269], [270, 275], [276, 286], [287, 288], [289, 290], [290, 292], [293, 294], [295, 297], [297, 298], [299, 300], [301, 302], [302, 304], [305, 306], [307, 309], [310, 311], [312, 314], [315, 316], [317, 319], [319, 320], [320, 321]]}
{"doc_key": "ai-test-259", "ner": [[14, 23, "conference"], [26, 28, "conference"], [36, 36, "location"], [34, 35, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 23, 36, 36, "physical", "", false, false], [26, 28, 14, 23, "named", "", false, false], [34, 35, 14, 23, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "academic", "community", ",", "the", "main", "research", "forums", "started", "in", "1995", "with", "the", "first", "international", "conference", "on", "\"", "Data", "Mining", "and", "Knowledge", "Discovery", "\"", "(", "KDD", "-", "95", ")", ",", "sponsored", "by", "the", "AAAI", "in", "Montreal", "."], "sentence-detokenized": "In the academic community, the main research forums started in 1995 with the first international conference on \"Data Mining and Knowledge Discovery\" (KDD-95), sponsored by the AAAI in Montreal.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 25], [25, 26], [27, 30], [31, 35], [36, 44], [45, 51], [52, 59], [60, 62], [63, 67], [68, 72], [73, 76], [77, 82], [83, 96], [97, 107], [108, 110], [111, 112], [112, 116], [117, 123], [124, 127], [128, 137], [138, 147], [147, 148], [149, 150], [150, 153], [153, 154], [154, 156], [156, 157], [157, 158], [159, 168], [169, 171], [172, 175], [176, 180], [181, 183], [184, 192], [192, 193]]}
{"doc_key": "ai-test-260", "ner": [[9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "this", "approach", ",", "models", "are", "developed", "using", "various", "data", "mining", "and", "machine", "learning", "algorithms", "to", "predict", "users", "'", "ratings", "of", "unrated", "items", "."], "sentence-detokenized": "In this approach, models are developed using various data mining and machine learning algorithms to predict users' ratings of unrated items.", "token2charspan": [[0, 2], [3, 7], [8, 16], [16, 17], [18, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 57], [58, 64], [65, 68], [69, 76], [77, 85], [86, 96], [97, 99], [100, 107], [108, 113], [113, 114], [115, 122], [123, 125], [126, 133], [134, 139], [139, 140]]}
{"doc_key": "ai-test-261", "ner": [[18, 19, "algorithm"], [21, 24, "algorithm"], [25, 28, "misc"], [34, 36, "metrics"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[18, 19, 21, 24, "usage", "", false, false], [21, 24, 34, 36, "usage", "", false, false], [34, 36, 25, 28, "type-of", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["In", "the", "light", "of", "the", "foregoing", "discussion", ",", "we", "can", "see", "that", "the", "SVM", "technique", "is", "equivalent", "to", "empirical", "risk", "with", "Tihhonov", "regularization", ",", "where", "the", "loss", "function", "in", "this", "case", "is", "the", "loss", "of", "a", "soul", "."], "sentence-detokenized": "In the light of the foregoing discussion, we can see that the SVM technique is equivalent to empirical risk with Tihhonov regularization, where the loss function in this case is the loss of a soul.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 19], [20, 29], [30, 40], [40, 41], [42, 44], [45, 48], [49, 52], [53, 57], [58, 61], [62, 65], [66, 75], [76, 78], [79, 89], [90, 92], [93, 102], [103, 107], [108, 112], [113, 121], [122, 136], [136, 137], [138, 143], [144, 147], [148, 152], [153, 161], [162, 164], [165, 169], [170, 174], [175, 177], [178, 181], [182, 186], [187, 189], [190, 191], [192, 196], [196, 197]]}
{"doc_key": "ai-test-262", "ner": [[6, 7, "person"], [12, 13, "person"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "2015", "edition", "was", "hosted", "by", "Molly", "McGrath", ",", "with", "commentary", "by", "Chris", "Rose", "and", "former", "UFC", "fighter", "Kenny", "Florian", "."], "sentence-detokenized": "The 2015 edition was hosted by Molly McGrath, with commentary by Chris Rose and former UFC fighter Kenny Florian.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 27], [28, 30], [31, 36], [37, 44], [44, 45], [46, 50], [51, 61], [62, 64], [65, 70], [71, 75], [76, 79], [80, 86], [87, 90], [91, 98], [99, 104], [105, 112], [112, 113]]}
{"doc_key": "ai-test-263", "ner": [[4, 6, "product"], [10, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"], [19, 19, "researcher"], [22, 22, "researcher"], [32, 34, "task"], [36, 36, "product"], [38, 38, "researcher"], [43, 44, "task"], [46, 47, "researcher"], [51, 52, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12], "relations": [[4, 6, 10, 12, "origin", "", false, false], [4, 6, 14, 15, "origin", "", false, false], [4, 6, 17, 18, "origin", "", false, false], [4, 6, 19, 19, "origin", "", false, false], [14, 15, 38, 38, "named", "same", false, false], [17, 18, 22, 22, "named", "same", false, false], [32, 34, 36, 36, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 7], "sentence": ["A", "subset", "called", "the", "Micro", "-", "Planner", "was", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "Sussman", ",", "and", "Winograd", "in", "1971", ",", "and", "was", "used", "in", "Winograd", "'s", "natural", "language", "understanding", "program", "SHRDLU", ",", "Eugene", "Charniak", "'s", "work", "on", "story", "understanding", ",", "Thorne", "McCarty", "'s", "work", "on", "legal", "reasoning", ",", "and", "a", "few", "other", "projects", "."], "sentence-detokenized": "A subset called the Micro-Planner was implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd Sussman, and Winograd in 1971, and was used in Winograd's natural language understanding program SHRDLU, Eugene Charniak's work on story understanding, Thorne McCarty's work on legal reasoning, and a few other projects.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 19], [20, 25], [25, 26], [26, 33], [34, 37], [38, 49], [50, 52], [53, 59], [60, 63], [64, 71], [71, 72], [73, 79], [80, 88], [89, 92], [93, 98], [99, 107], [108, 115], [115, 116], [117, 120], [121, 129], [130, 132], [133, 137], [137, 138], [139, 142], [143, 146], [147, 151], [152, 154], [155, 163], [163, 165], [166, 173], [174, 182], [183, 196], [197, 204], [205, 211], [211, 212], [213, 219], [220, 228], [228, 230], [231, 235], [236, 238], [239, 244], [245, 258], [258, 259], [260, 266], [267, 274], [274, 276], [277, 281], [282, 284], [285, 290], [291, 300], [300, 301], [302, 305], [306, 307], [308, 311], [312, 317], [318, 326], [326, 327]]}
{"doc_key": "ai-test-264", "ner": [[0, 1, "product"], [4, 11, "product"], [15, 16, "task"], [18, 19, "task"], [21, 23, "task"], [25, 26, "task"], [28, 29, "task"], [32, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 11, 0, 1, "usage", "", true, false], [15, 16, 4, 11, "part-of", "", true, false], [18, 19, 4, 11, "part-of", "", true, false], [21, 23, 4, 11, "part-of", "", true, false], [25, 26, 4, 11, "part-of", "", true, false], [28, 29, 4, 11, "part-of", "", true, false], [32, 34, 4, 11, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Word", "Net", "has", "been", "used", "in", "information", "systems", "for", "a", "variety", "of", "purposes", ",", "including", "word", "disambiguation", ",", "information", "retrieval", ",", "automatic", "text", "classification", ",", "automatic", "summarisation", ",", "machine", "translation", "and", "even", "automatic", "crossword", "generation", "."], "sentence-detokenized": "WordNet has been used in information systems for a variety of purposes, including word disambiguation, information retrieval, automatic text classification, automatic summarisation, machine translation and even automatic crossword generation.", "token2charspan": [[0, 4], [4, 7], [8, 11], [12, 16], [17, 21], [22, 24], [25, 36], [37, 44], [45, 48], [49, 50], [51, 58], [59, 61], [62, 70], [70, 71], [72, 81], [82, 86], [87, 101], [101, 102], [103, 114], [115, 124], [124, 125], [126, 135], [136, 140], [141, 155], [155, 156], [157, 166], [167, 180], [180, 181], [182, 189], [190, 201], [202, 205], [206, 210], [211, 220], [221, 230], [231, 241], [241, 242]]}
{"doc_key": "ai-test-265", "ner": [[0, 0, "researcher"], [4, 4, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 4, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Keutzer", "was", "nominated", "for", "IEEE", "membership", "in", "1996", "."], "sentence-detokenized": "Keutzer was nominated for IEEE membership in 1996.", "token2charspan": [[0, 7], [8, 11], [12, 21], [22, 25], [26, 30], [31, 41], [42, 44], [45, 49], [49, 50]]}
{"doc_key": "ai-test-266", "ner": [[8, 10, "algorithm"], [54, 56, "misc"], [65, 67, "algorithm"], [69, 70, "algorithm"], [72, 73, "algorithm"], [76, 77, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[65, 67, 54, 56, "type-of", "", false, false], [69, 70, 54, 56, "type-of", "", false, false], [72, 73, 54, 56, "type-of", "", false, false], [76, 77, 54, 56, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "widely", "used", "type", "of", "composition", "is", "the", "nonlinear", "weighted", "sum", ",", "where", "math", "\\", "textstyle", "f", "(", "x", ")", "=", "K", "\\", "left", "(", "\\", "sum", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "\\", "right", ")", "/", "math", ",", "where", "math", "\\", "textstyle", "K", "/", "math", "(", "usually", "called", "the", "activation", "function", ")", "is", "some", "predefined", "function", ",", "such", "as", "a", "hyperbolic", "tangent", ",", "sigmoid", "function", ",", "softmax", "function", ",", "or", "rectification", "function", "."], "sentence-detokenized": "A widely used type of composition is the nonlinear weighted sum, where math\\ textstyle f (x) = K\\ left (\\ sum _ i w _ i g _ i (x)\\ right) / math, where math\\ textstyle K / math (usually called the activation function) is some predefined function, such as a hyperbolic tangent, sigmoid function, softmax function, or rectification function.", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 18], [19, 21], [22, 33], [34, 36], [37, 40], [41, 50], [51, 59], [60, 63], [63, 64], [65, 70], [71, 75], [75, 76], [77, 86], [87, 88], [89, 90], [90, 91], [91, 92], [93, 94], [95, 96], [96, 97], [98, 102], [103, 104], [104, 105], [106, 109], [110, 111], [112, 113], [114, 115], [116, 117], [118, 119], [120, 121], [122, 123], [124, 125], [126, 127], [127, 128], [128, 129], [129, 130], [131, 136], [136, 137], [138, 139], [140, 144], [144, 145], [146, 151], [152, 156], [156, 157], [158, 167], [168, 169], [170, 171], [172, 176], [177, 178], [178, 185], [186, 192], [193, 196], [197, 207], [208, 216], [216, 217], [218, 220], [221, 225], [226, 236], [237, 245], [245, 246], [247, 251], [252, 254], [255, 256], [257, 267], [268, 275], [275, 276], [277, 284], [285, 293], [293, 294], [295, 302], [303, 311], [311, 312], [313, 315], [316, 329], [330, 338], [338, 339]]}
{"doc_key": "ai-test-267", "ner": [[4, 4, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "film", "\"", "Westworld", "\"", ",", "female", "robots", "actually", "had", "sexual", "intercourse", "with", "human", "men", ",", "part", "of", "an", "imaginary", "holiday", "world", "where", "human", "customers", "paid", "to", "participate", "."], "sentence-detokenized": "In the film \"Westworld\", female robots actually had sexual intercourse with human men, part of an imaginary holiday world where human customers paid to participate.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 13], [13, 22], [22, 23], [23, 24], [25, 31], [32, 38], [39, 47], [48, 51], [52, 58], [59, 70], [71, 75], [76, 81], [82, 85], [85, 86], [87, 91], [92, 94], [95, 97], [98, 107], [108, 115], [116, 121], [122, 127], [128, 133], [134, 143], [144, 148], [149, 151], [152, 163], [163, 164]]}
{"doc_key": "ai-test-268", "ner": [[6, 9, "task"], [26, 31, "task"], [33, 34, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 9, 26, 31, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Usually", ",", "the", "process", "starts", "with", "the", "extraction", "of", "terminology", "and", "concepts", "or", "noun", "phrases", "from", "the", "plain", "text", ",", "using", "linguistic", "processing", "tools", "such", "as", "part", "-", "of", "-", "speech", "tagging", "and", "phrase", "splitting", "."], "sentence-detokenized": "Usually, the process starts with the extraction of terminology and concepts or noun phrases from the plain text, using linguistic processing tools such as part-of-speech tagging and phrase splitting.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 20], [21, 27], [28, 32], [33, 36], [37, 47], [48, 50], [51, 62], [63, 66], [67, 75], [76, 78], [79, 83], [84, 91], [92, 96], [97, 100], [101, 106], [107, 111], [111, 112], [113, 118], [119, 129], [130, 140], [141, 146], [147, 151], [152, 154], [155, 159], [159, 160], [160, 162], [162, 163], [163, 169], [170, 177], [178, 181], [182, 188], [189, 198], [198, 199]]}
{"doc_key": "ai-test-269", "ner": [[13, 14, "field"], [4, 19, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 19, 13, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "demonstrated", "its", "effectiveness", "on", "a", "number", "of", "problems", "of", "interest", "to", "the", "machine", "learning", "community", ",", "including", "handwriting", "recognition", "."], "sentence-detokenized": "They demonstrated its effectiveness on a number of problems of interest to the machine learning community, including handwriting recognition.", "token2charspan": [[0, 4], [5, 17], [18, 21], [22, 35], [36, 38], [39, 40], [41, 47], [48, 50], [51, 59], [60, 62], [63, 71], [72, 74], [75, 78], [79, 86], [87, 95], [96, 105], [105, 106], [107, 116], [117, 128], [129, 140], [140, 141]]}
{"doc_key": "ai-test-270", "ner": [[1, 2, "university"], [4, 4, "researcher"], [10, 11, "researcher"], [20, 20, "product"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 1, 2, "physical", "", false, false], [4, 4, 1, 2, "role", "", false, false], [20, 20, 10, 11, "origin", "", false, false], [20, 20, 17, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "at", "Stanford", ",", "Scheinman", "received", "a", "scholarship", "sponsored", "by", "George", "Devol", ",", "inventor", "of", "the", "first", "industrial", "robot", ",", "Unimate", "."], "sentence-detokenized": "While at Stanford, Scheinman received a scholarship sponsored by George Devol, inventor of the first industrial robot, Unimate.", "token2charspan": [[0, 5], [6, 8], [9, 17], [17, 18], [19, 28], [29, 37], [38, 39], [40, 51], [52, 61], [62, 64], [65, 71], [72, 77], [77, 78], [79, 87], [88, 90], [91, 94], [95, 100], [101, 111], [112, 117], [117, 118], [119, 126], [126, 127]]}
{"doc_key": "ai-test-271", "ner": [[4, 5, "task"], [10, 11, "metrics"], [9, 13, "metrics"], [22, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 10, 11, "usage", "", true, false], [9, 13, 10, 11, "named", "", false, false], [22, 24, 10, 11, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Although", "originally", "used", "for", "machine", "translation", "evaluation", ",", "the", "Bilingual", "Evaluation", "Platform", "(", "BLEU", ")", "has", "also", "been", "successfully", "used", "to", "evaluate", "paraphrase", "generation", "models", "."], "sentence-detokenized": "Although originally used for machine translation evaluation, the Bilingual Evaluation Platform (BLEU) has also been successfully used to evaluate paraphrase generation models.", "token2charspan": [[0, 8], [9, 19], [20, 24], [25, 28], [29, 36], [37, 48], [49, 59], [59, 60], [61, 64], [65, 74], [75, 85], [86, 94], [95, 96], [96, 100], [100, 101], [102, 105], [106, 110], [111, 115], [116, 128], [129, 133], [134, 136], [137, 145], [146, 156], [157, 167], [168, 174], [174, 175]]}
{"doc_key": "ai-test-272", "ner": [[0, 0, "organisation"], [6, 8, "organisation"], [10, 10, "organisation"], [14, 15, "product"], [16, 16, "country"], [18, 18, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 8, "role", "licenses_to", false, false], [0, 0, 10, 10, "role", "licenses_to", false, false], [6, 8, 16, 16, "physical", "", false, false], [10, 10, 18, 18, "physical", "", false, false], [14, 15, 6, 8, "artifact", "produces", false, false], [14, 15, 10, 10, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "later", "licensed", "its", "technology", "to", "Kawasaki", "Heavy", "Industries", "and", "GKN", ",", "which", "manufacture", "Unimation", "in", "Japan", "and", "England", "respectively", "."], "sentence-detokenized": "Unimation later licensed its technology to Kawasaki Heavy Industries and GKN, which manufacture Unimation in Japan and England respectively.", "token2charspan": [[0, 9], [10, 15], [16, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 57], [58, 68], [69, 72], [73, 76], [76, 77], [78, 83], [84, 95], [96, 105], [106, 108], [109, 114], [115, 118], [119, 126], [127, 139], [139, 140]]}
{"doc_key": "ai-test-273", "ner": [[19, 20, "conference"], [32, 34, "field"], [51, 54, "field"], [56, 56, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[32, 34, 51, 54, "compare", "", false, false], [56, 56, 51, 54, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Much", "of", "the", "confusion", "between", "these", "two", "research", "communities", "(", "which", "often", "have", "separate", "conferences", "and", "separate", "journals", ",", "ECML", "PKDD", "being", "a", "major", "exception", ")", "stems", "from", "their", "working", "principles", ":", "machine", "learning", "is", "usually", "judged", "on", "performance", "in", "terms", "of", "its", "ability", "to", "reproduce", "known", "knowledge", ",", "while", "knowledge", "discovery", "and", "data", "mining", "(", "KDD", ")", "is", "primarily", "concerned", "with", "the", "discovery", "of", "previously", "unknown", "knowledge", "."], "sentence-detokenized": "Much of the confusion between these two research communities (which often have separate conferences and separate journals, ECML PKDD being a major exception) stems from their working principles: machine learning is usually judged on performance in terms of its ability to reproduce known knowledge, while knowledge discovery and data mining (KDD) is primarily concerned with the discovery of previously unknown knowledge.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 29], [30, 35], [36, 39], [40, 48], [49, 60], [61, 62], [62, 67], [68, 73], [74, 78], [79, 87], [88, 99], [100, 103], [104, 112], [113, 121], [121, 122], [123, 127], [128, 132], [133, 138], [139, 140], [141, 146], [147, 156], [156, 157], [158, 163], [164, 168], [169, 174], [175, 182], [183, 193], [193, 194], [195, 202], [203, 211], [212, 214], [215, 222], [223, 229], [230, 232], [233, 244], [245, 247], [248, 253], [254, 256], [257, 260], [261, 268], [269, 271], [272, 281], [282, 287], [288, 297], [297, 298], [299, 304], [305, 314], [315, 324], [325, 328], [329, 333], [334, 340], [341, 342], [342, 345], [345, 346], [347, 349], [350, 359], [360, 369], [370, 374], [375, 378], [379, 388], [389, 391], [392, 402], [403, 410], [411, 420], [420, 421]]}
{"doc_key": "ai-test-274", "ner": [[0, 1, "algorithm"], [9, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 9, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Hidden", "Markov", "models", "are", "the", "basis", "of", "most", "modern", "automatic", "speech", "recognition", "systems", "."], "sentence-detokenized": "Hidden Markov models are the basis of most modern automatic speech recognition systems.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 28], [29, 34], [35, 37], [38, 42], [43, 49], [50, 59], [60, 66], [67, 78], [79, 86], [86, 87]]}
{"doc_key": "ai-test-275", "ner": [[2, 2, "location"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": [",", "a", "Bangalore", ",", "India", "-", "based", "company", "specialising", "in", "online", "address", "recognition", "software", "."], "sentence-detokenized": ", a Bangalore, India-based company specialising in online address recognition software.", "token2charspan": [[0, 1], [2, 3], [4, 13], [13, 14], [15, 20], [20, 21], [21, 26], [27, 34], [35, 47], [48, 50], [51, 57], [58, 65], [66, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-276", "ner": [[23, 25, "misc"], [49, 49, "metrics"], [51, 53, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[49, 49, 51, 53, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Do", "repeated", "translations", "converge", "on", "the", "same", "expression", "in", "both", "languages", "?", "I.e.", "does", "the", "translation", "method", "indicate", "stationarity", "or", "does", "it", "give", "a", "canonical", "form", "?", "Does", "the", "translation", "become", "stationary", "without", "losing", "the", "original", "meaning", "?", "This", "measure", "has", "been", "criticised", "for", "not", "correlating", "well", "with", "the", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "score", "."], "sentence-detokenized": "Do repeated translations converge on the same expression in both languages? I.e. does the translation method indicate stationarity or does it give a canonical form? Does the translation become stationary without losing the original meaning? This measure has been criticised for not correlating well with the BLEU (BiLingual Evaluation Understudy) score.", "token2charspan": [[0, 2], [3, 11], [12, 24], [25, 33], [34, 36], [37, 40], [41, 45], [46, 56], [57, 59], [60, 64], [65, 74], [74, 75], [76, 80], [81, 85], [86, 89], [90, 101], [102, 108], [109, 117], [118, 130], [131, 133], [134, 138], [139, 141], [142, 146], [147, 148], [149, 158], [159, 163], [163, 164], [165, 169], [170, 173], [174, 185], [186, 192], [193, 203], [204, 211], [212, 218], [219, 222], [223, 231], [232, 239], [239, 240], [241, 245], [246, 253], [254, 257], [258, 262], [263, 273], [274, 277], [278, 281], [282, 293], [294, 298], [299, 303], [304, 307], [308, 312], [313, 314], [314, 323], [324, 334], [335, 345], [345, 346], [347, 352], [352, 353]]}
{"doc_key": "ai-test-277", "ner": [[0, 10, "organisation"], [14, 18, "organisation"], [12, 13, "university"], [20, 20, "university"], [23, 24, "field"], [26, 31, "organisation"], [35, 37, "organisation"], [47, 50, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[14, 18, 12, 13, "part-of", "", false, false], [20, 20, 23, 24, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "is", "a", "Fellow", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", ",", "Stanford", "University", "Center", "for", "Advanced", "Behavioral", "Research", ",", "MIT", "Center", "for", "Cognitive", "Science", ",", "Canadian", "Institute", "of", "Advanced", "Cognitive", "Science", ",", "and", "the", "Canadian", "Psychological", "Association", ",", "and", "was", "elected", "a", "Fellow", "of", "the", "Royal", "Society", "of", "Canada", "in", "1998", "."], "sentence-detokenized": "He is a Fellow of the American Association for Artificial Intelligence, Stanford University Center for Advanced Behavioral Research, MIT Center for Cognitive Science, Canadian Institute of Advanced Cognitive Science, and the Canadian Psychological Association, and was elected a Fellow of the Royal Society of Canada in 1998.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 42], [43, 46], [47, 57], [58, 70], [70, 71], [72, 80], [81, 91], [92, 98], [99, 102], [103, 111], [112, 122], [123, 131], [131, 132], [133, 136], [137, 143], [144, 147], [148, 157], [158, 165], [165, 166], [167, 175], [176, 185], [186, 188], [189, 197], [198, 207], [208, 215], [215, 216], [217, 220], [221, 224], [225, 233], [234, 247], [248, 259], [259, 260], [261, 264], [265, 268], [269, 276], [277, 278], [279, 285], [286, 288], [289, 292], [293, 298], [299, 306], [307, 309], [310, 316], [317, 319], [320, 324], [324, 325]]}
{"doc_key": "ai-test-278", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 12, "researcher"], [14, 18, "misc"], [21, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 14, 18, "part-of", "", false, false], [0, 0, 21, 24, "part-of", "", false, false], [4, 5, 14, 18, "part-of", "", false, false], [4, 5, 21, 24, "part-of", "", false, false], [7, 12, 14, 18, "part-of", "", false, false], [7, 12, 21, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", "-", "along", "with", "Yoshua", "Bengio", "and", "Yann", "LeCun", "-", "are", "called", "by", "some", "the", "godfathers", "of", "artificial", "intelligence", "and", "the", "godfathers", "of", "deep", "learning", "."], "sentence-detokenized": "Hinton - along with Yoshua Bengio and Yann LeCun - are called by some the godfathers of artificial intelligence and the godfathers of deep learning.", "token2charspan": [[0, 6], [7, 8], [9, 14], [15, 19], [20, 26], [27, 33], [34, 37], [38, 42], [43, 48], [49, 50], [51, 54], [55, 61], [62, 64], [65, 69], [70, 73], [74, 84], [85, 87], [88, 98], [99, 111], [112, 115], [116, 119], [120, 130], [131, 133], [134, 138], [139, 147], [147, 148]]}
{"doc_key": "ai-test-279", "ner": [[0, 2, "product"], [19, 19, "misc"], [21, 22, "misc"], [23, 23, "product"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 19, 19, "related-to", "", false, false], [0, 2, 21, 22, "related-to", "", false, false], [19, 19, 23, 23, "named", "same", false, false], [28, 29, 23, 23, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["eSpeak", ",", "an", "open", "source", "lightweight", "speech", "project", "with", "its", "own", "approach", "to", "synthesis", ",", "has", "been", "experimenting", "with", "Mandarin", "and", "Cantonese", ".", "eSpeak", "has", "been", "used", "by", "Google", "Translate", "since", "May", "20102010", "."], "sentence-detokenized": "eSpeak, an open source lightweight speech project with its own approach to synthesis, has been experimenting with Mandarin and Cantonese. eSpeak has been used by Google Translate since May 20102010.", "token2charspan": [[0, 6], [6, 7], [8, 10], [11, 15], [16, 22], [23, 34], [35, 41], [42, 49], [50, 54], [55, 58], [59, 62], [63, 71], [72, 74], [75, 84], [84, 85], [86, 89], [90, 94], [95, 108], [109, 113], [114, 122], [123, 126], [127, 136], [136, 137], [138, 144], [145, 148], [149, 153], [154, 158], [159, 161], [162, 168], [169, 178], [179, 184], [185, 188], [189, 197], [197, 198]]}
{"doc_key": "ai-test-280", "ner": [[5, 7, "product"], [13, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 13, 15, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Also", "released", "in", "1982", ",", "Software", "Automatic", "Mouth", "was", "the", "first", "commercial", "software", "voice", "synthesis", "program", "."], "sentence-detokenized": "Also released in 1982, Software Automatic Mouth was the first commercial software voice synthesis program.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 21], [21, 22], [23, 31], [32, 41], [42, 47], [48, 51], [52, 55], [56, 61], [62, 72], [73, 81], [82, 87], [88, 97], [98, 105], [105, 106]]}
{"doc_key": "ai-test-281", "ner": [[4, 6, "metrics"], [8, 8, "metrics"], [13, 13, "metrics"], [15, 15, "metrics"], [18, 25, "metrics"], [31, 33, "metrics"], [32, 32, "metrics"], [35, 45, "metrics"], [48, 50, "metrics"], [49, 52, "metrics"], [57, 57, "metrics"], [59, 59, "metrics"], [62, 69, "metrics"], [75, 77, "metrics"], [79, 79, "metrics"], [82, 89, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[8, 8, 4, 6, "named", "", false, false], [13, 13, 4, 6, "named", "", false, false], [15, 15, 4, 6, "named", "", false, false], [18, 25, 4, 6, "named", "", false, false], [32, 32, 31, 33, "named", "", false, false], [35, 45, 31, 33, "named", "", false, false], [49, 52, 48, 50, "named", "", false, false], [57, 57, 48, 50, "named", "", false, false], [59, 59, 48, 50, "named", "", false, false], [62, 69, 48, 50, "named", "", false, false], [79, 79, 75, 77, "named", "", false, false], [82, 89, 75, 77, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["The", "column", "ratios", "are", "TRUE", "Positive", "Rate", "(", "TPR", ",", "also", "known", "as", "Sensitivity", "or", "recall", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "with", "the", "addition", "of", "FALSE", "Negative", "Rate", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ";", "and", "TRUE", "Negative", "Rate", "(", "TNR", ",", "also", "known", "as", "Specificity", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", ",", "with", "the", "addition", "of", "FALSE", "Positive", "Rate", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "The column ratios are TRUE Positive Rate (TPR, also known as Sensitivity or recall) (TP / (TP + FN)), with the addition of FALSE Negative Rate (FNR) (FN / (TP + FN)); and TRUE Negative Rate (TNR, also known as Specificity, SPC) (TN / (TN + FP)), with the addition of FALSE Positive Rate (FPR) (FP / (TN + FP)).", "token2charspan": [[0, 3], [4, 10], [11, 17], [18, 21], [22, 26], [27, 35], [36, 40], [41, 42], [42, 45], [45, 46], [47, 51], [52, 57], [58, 60], [61, 72], [73, 75], [76, 82], [82, 83], [84, 85], [85, 87], [88, 89], [90, 91], [91, 93], [94, 95], [96, 98], [98, 99], [99, 100], [100, 101], [102, 106], [107, 110], [111, 119], [120, 122], [123, 128], [129, 137], [138, 142], [143, 144], [144, 147], [147, 148], [149, 150], [150, 152], [153, 154], [155, 156], [156, 158], [159, 160], [161, 163], [163, 164], [164, 165], [165, 166], [167, 170], [171, 175], [176, 184], [185, 189], [190, 191], [191, 194], [194, 195], [196, 200], [201, 206], [207, 209], [210, 221], [221, 222], [223, 226], [226, 227], [228, 229], [229, 231], [232, 233], [234, 235], [235, 237], [238, 239], [240, 242], [242, 243], [243, 244], [244, 245], [246, 250], [251, 254], [255, 263], [264, 266], [267, 272], [273, 281], [282, 286], [287, 288], [288, 291], [291, 292], [293, 294], [294, 296], [297, 298], [299, 300], [300, 302], [303, 304], [305, 307], [307, 308], [308, 309], [309, 310]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 2, "person"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 17, 17, "role", "working_with", false, false], [2, 2, 17, 17, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "and", "Weber", "also", "collaborated", "on", "a", "number", "of", "other", "robots", ",", "and", "their", "experience", "working", "with", "Kismet", "."], "sentence-detokenized": "Edsinger and Weber also collaborated on a number of other robots, and their experience working with Kismet.", "token2charspan": [[0, 8], [9, 12], [13, 18], [19, 23], [24, 36], [37, 39], [40, 41], [42, 48], [49, 51], [52, 57], [58, 64], [64, 65], [66, 69], [70, 75], [76, 86], [87, 94], [95, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-test-283", "ner": [[12, 12, "programlang"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["R", "functions", "are", "also", "available", "in", "several", "scripting", "languages", ",", "such", "as", "Python", "."], "sentence-detokenized": "R functions are also available in several scripting languages, such as Python.", "token2charspan": [[0, 1], [2, 11], [12, 15], [16, 20], [21, 30], [31, 33], [34, 41], [42, 51], [52, 61], [61, 62], [63, 67], [68, 70], [71, 77], [77, 78]]}
{"doc_key": "ai-test-284", "ner": [[0, 0, "programlang"], [11, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 13, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "was", "one", "of", "the", "first", "robot", "languages", "and", "was", "used", "in", "Unimate", "robots", "."], "sentence-detokenized": "VAL was one of the first robot languages and was used in Unimate robots.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 18], [19, 24], [25, 30], [31, 40], [41, 44], [45, 48], [49, 53], [54, 56], [57, 64], [65, 71], [71, 72]]}
{"doc_key": "ai-test-285", "ner": [[9, 16, "conference"], [11, 20, "conference"], [21, 21, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 16, 21, 21, "physical", "", false, false], [11, 20, 9, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["They", "first", "presented", "their", "database", "as", "a", "poster", "at", "the", "2009", "Computer", "Vision", "and", "Pattern", "Recognition", "Conference", "(", "CVPR", ")", "in", "Florida", "."], "sentence-detokenized": "They first presented their database as a poster at the 2009 Computer Vision and Pattern Recognition Conference (CVPR) in Florida.", "token2charspan": [[0, 4], [5, 10], [11, 20], [21, 26], [27, 35], [36, 38], [39, 40], [41, 47], [48, 50], [51, 54], [55, 59], [60, 68], [69, 75], [76, 79], [80, 87], [88, 99], [100, 110], [111, 112], [112, 116], [116, 117], [118, 120], [121, 128], [128, 129]]}
{"doc_key": "ai-test-286", "ner": [[0, 1, "misc"], [6, 7, "task"], [9, 10, "field"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 7, 0, 1, "type-of", "", false, false], [9, 10, 0, 1, "type-of", "", false, false], [12, 13, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Categorisation", "tasks", "without", "labels", "are", "called", "unsupervised", "classification", ",", "unsupervised", "learning", ",", "cluster", "analysis", "."], "sentence-detokenized": "Categorisation tasks without labels are called unsupervised classification, unsupervised learning, cluster analysis.", "token2charspan": [[0, 14], [15, 20], [21, 28], [29, 35], [36, 39], [40, 46], [47, 59], [60, 74], [74, 75], [76, 88], [89, 97], [97, 98], [99, 106], [107, 115], [115, 116]]}
{"doc_key": "ai-test-287", "ner": [[2, 3, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "includes", "object", "recognition", ",", "recognition", "and", "finding", "of", "people", "and", "further", "emotion", "recognition", "."], "sentence-detokenized": "This includes object recognition, recognition and finding of people and further emotion recognition.", "token2charspan": [[0, 4], [5, 13], [14, 20], [21, 32], [32, 33], [34, 45], [46, 49], [50, 57], [58, 60], [61, 67], [68, 71], [72, 79], [80, 87], [88, 99], [99, 100]]}
{"doc_key": "ai-test-288", "ner": [[6, 6, "misc"], [8, 8, "misc"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "process", "is", "complex", "and", "involves", "coding", "and", "remembering", "or", "recalling", "."], "sentence-detokenized": "The process is complex and involves coding and remembering or recalling.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 26], [27, 35], [36, 42], [43, 46], [47, 58], [59, 61], [62, 71], [71, 72]]}
{"doc_key": "ai-test-289", "ner": [[10, 11, "product"], [13, 18, "product"], [32, 33, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 13, 18, "named", "", false, false], [10, 11, 32, 33, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "also", "known", "as", "parallel", "robots", "or", "generalised", "Stewart", "platforms", "(", "in", "a", "Stewart", "platform", ",", "the", "actuators", "are", "both", "on", "the", "base", "and", "on", "the", "platform", ")", ",", "are", "articulated", "robots", "that", "use", "similar", "mechanisms", "to", "move", "either", "the", "base", "robot", "or", "one", "or", "more", "manipulator", "arms", "."], "sentence-detokenized": "These systems, also known as parallel robots or generalised Stewart platforms (in a Stewart platform, the actuators are both on the base and on the platform), are articulated robots that use similar mechanisms to move either the base robot or one or more manipulator arms.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 25], [26, 28], [29, 37], [38, 44], [45, 47], [48, 59], [60, 67], [68, 77], [78, 79], [79, 81], [82, 83], [84, 91], [92, 100], [100, 101], [102, 105], [106, 115], [116, 119], [120, 124], [125, 127], [128, 131], [132, 136], [137, 140], [141, 143], [144, 147], [148, 156], [156, 157], [157, 158], [159, 162], [163, 174], [175, 181], [182, 186], [187, 190], [191, 198], [199, 209], [210, 212], [213, 217], [218, 224], [225, 228], [229, 233], [234, 239], [240, 242], [243, 246], [247, 249], [250, 254], [255, 266], [267, 271], [271, 272]]}
{"doc_key": "ai-test-290", "ner": [[0, 1, "field"], [4, 5, "field"], [11, 13, "field"], [20, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 5, "part-of", "subfield", false, false], [0, 1, 11, 13, "compare", "", false, false], [11, 13, 20, 21, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "learning", "as", "a", "systems", "engineering", "discipline", "can", "be", "considered", "separately", "from", "computer", "vision", ",", "which", "is", "a", "form", "of", "computer", "science", "."], "sentence-detokenized": "Machine learning as a systems engineering discipline can be considered separately from computer vision, which is a form of computer science.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 21], [22, 29], [30, 41], [42, 52], [53, 56], [57, 59], [60, 70], [71, 81], [82, 86], [87, 95], [96, 102], [102, 103], [104, 109], [110, 112], [113, 114], [115, 119], [120, 122], [123, 131], [132, 139], [139, 140]]}
{"doc_key": "ai-test-291", "ner": [[4, 5, "algorithm"], [9, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 9, 11, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "activation", "function", "of", "LSTM", "gates", "is", "often", "a", "logistic", "sigmoid", "function", "."], "sentence-detokenized": "The activation function of LSTM gates is often a logistic sigmoid function.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 26], [27, 31], [32, 37], [38, 40], [41, 46], [47, 48], [49, 57], [58, 65], [66, 74], [74, 75]]}
{"doc_key": "ai-test-292", "ner": [[5, 6, "metrics"], [20, 24, "metrics"], [23, 26, "metrics"], [35, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 20, 24, "named", "", false, false], [5, 6, 35, 36, "named", "", false, false], [23, 26, 20, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "other", "words", ",", "the", "sample", "mean", "is", "a", "(", "necessarily", "unique", ")", "efficient", "estimator", ",", "and", "therefore", "also", "an", "unbiased", "estimator", "with", "minimum", "variation", "(", "MVUE", ")", ",", "in", "addition", "to", "being", "a", "maximum", "likelihood", "estimator", "."], "sentence-detokenized": "In other words, the sample mean is a (necessarily unique) efficient estimator, and therefore also an unbiased estimator with minimum variation (MVUE), in addition to being a maximum likelihood estimator.", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 19], [20, 26], [27, 31], [32, 34], [35, 36], [37, 38], [38, 49], [50, 56], [56, 57], [58, 67], [68, 77], [77, 78], [79, 82], [83, 92], [93, 97], [98, 100], [101, 109], [110, 119], [120, 124], [125, 132], [133, 142], [143, 144], [144, 148], [148, 149], [149, 150], [151, 153], [154, 162], [163, 165], [166, 171], [172, 173], [174, 181], [182, 192], [193, 202], [202, 203]]}
{"doc_key": "ai-test-293", "ner": [[2, 3, "academicjournal"], [6, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [22, 22, "product"], [23, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 22, 22, "topic", "", false, false], [2, 3, 23, 26, "topic", "", false, false], [6, 8, 2, 3, "role", "", false, false], [10, 11, 2, 3, "role", "", false, false], [13, 14, 2, 3, "role", "", false, false], [22, 22, 23, 26, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["A", "2001", "Scientific", "American", "article", "by", "Berners", "-", "Lee", ",", "James", "Hendler", "and", "Ora", "Lassila", "described", "the", "expected", "evolution", "of", "the", "existing", "web", "into", "a", "semantic", "web", "."], "sentence-detokenized": "A 2001 Scientific American article by Berners-Lee, James Hendler and Ora Lassila described the expected evolution of the existing web into a semantic web.", "token2charspan": [[0, 1], [2, 6], [7, 17], [18, 26], [27, 34], [35, 37], [38, 45], [45, 46], [46, 49], [49, 50], [51, 56], [57, 64], [65, 68], [69, 72], [73, 80], [81, 90], [91, 94], [95, 103], [104, 113], [114, 116], [117, 120], [121, 129], [130, 133], [134, 138], [139, 140], [141, 149], [150, 153], [153, 154]]}
{"doc_key": "ai-test-294", "ner": [[0, 1, "misc"], [12, 13, "person"], [15, 15, "person"], [25, 25, "person"], [37, 37, "person"], [44, 45, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 13, 0, 1, "role", "actor_in_work", false, false], [15, 15, 12, 13, "named", "", false, false], [15, 15, 12, 13, "origin", "", false, false], [25, 25, 15, 15, "part-of", "", false, false], [44, 45, 15, 15, "role", "auditioned_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Blade", "Runner", "used", "a", "number", "of", "then", "lesser", "-", "known", "actors", ":", "Sean", "Young", "plays", "Rachael", ",", "an", "experimental", "replicant", "implanted", "with", "the", "memories", "of", "Tyrell", "'s", "niece", ",", "which", "makes", "her", "believe", "she", "is", "human", ";", "Sammon", ",", "pp", "92", "-", "93", ".", "Nina", "Axelrod", "auditioned", "for", "the", "role", "."], "sentence-detokenized": "Blade Runner used a number of then lesser-known actors: Sean Young plays Rachael, an experimental replicant implanted with the memories of Tyrell's niece, which makes her believe she is human; Sammon, pp 92-93. Nina Axelrod auditioned for the role.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 19], [20, 26], [27, 29], [30, 34], [35, 41], [41, 42], [42, 47], [48, 54], [54, 55], [56, 60], [61, 66], [67, 72], [73, 80], [80, 81], [82, 84], [85, 97], [98, 107], [108, 117], [118, 122], [123, 126], [127, 135], [136, 138], [139, 145], [145, 147], [148, 153], [153, 154], [155, 160], [161, 166], [167, 170], [171, 178], [179, 182], [183, 185], [186, 191], [191, 192], [193, 199], [199, 200], [201, 203], [204, 206], [206, 207], [207, 209], [209, 210], [211, 215], [216, 223], [224, 234], [235, 238], [239, 242], [243, 247], [247, 248]]}
{"doc_key": "ai-test-295", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [13, 17, "university"], [23, 25, "product"], [22, 27, "product"], [45, 45, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 13, 17, "physical", "", false, false], [3, 4, 13, 17, "physical", "", false, false], [6, 7, 13, 17, "physical", "", false, false], [9, 10, 13, 17, "physical", "", false, false], [13, 17, 45, 45, "physical", "", true, false], [23, 25, 13, 17, "temporal", "", false, false], [22, 27, 13, 17, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Gerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "and", "Terry", "Winograd", "visited", "the", "University", "of", "Edinburgh", "in", "1971", ",", "spreading", "the", "news", "about", "Micro", "-", "Planner", "and", "SHRDLU", "and", "questioning", "the", "single", "proof", "approach", "of", "the", "resolution", ",", "which", "had", "been", "the", "mainstay", "of", "the", "Edinburgh", "logicians", "."], "sentence-detokenized": "Gerry Sussman, Eugene Charniak, Seymour Papert and Terry Winograd visited the University of Edinburgh in 1971, spreading the news about Micro-Planner and SHRDLU and questioning the single proof approach of the resolution, which had been the mainstay of the Edinburgh logicians.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 21], [22, 30], [30, 31], [32, 39], [40, 46], [47, 50], [51, 56], [57, 65], [66, 73], [74, 77], [78, 88], [89, 91], [92, 101], [102, 104], [105, 109], [109, 110], [111, 120], [121, 124], [125, 129], [130, 135], [136, 141], [141, 142], [142, 149], [150, 153], [154, 160], [161, 164], [165, 176], [177, 180], [181, 187], [188, 193], [194, 202], [203, 205], [206, 209], [210, 220], [220, 221], [222, 227], [228, 231], [232, 236], [237, 240], [241, 249], [250, 252], [253, 256], [257, 266], [267, 276], [276, 277]]}
{"doc_key": "ai-test-296", "ner": [[11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Walter", "'s", "work", "has", "inspired", "subsequent", "generations", "of", "roboticists", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "Walter's work has inspired subsequent generations of roboticists such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 6], [6, 8], [9, 13], [14, 17], [18, 26], [27, 37], [38, 49], [50, 52], [53, 64], [65, 69], [70, 72], [73, 79], [80, 86], [86, 87], [88, 92], [93, 100], [101, 104], [105, 109], [110, 116], [116, 117]]}
{"doc_key": "ai-test-297", "ner": [[7, 7, "algorithm"], [18, 19, "researcher"], [9, 17, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 18, 19, "origin", "", false, false], [7, 7, 9, 17, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Later", ",", "a", "similar", "GPU", "-", "based", "CNN", "won", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "2012", "by", "Alex", "Krizhevsky", "et", "al", "."], "sentence-detokenized": "Later, a similar GPU-based CNN won the ImageNet Large Scale Visual Recognition Challenge 2012 by Alex Krizhevsky et al.", "token2charspan": [[0, 5], [5, 6], [7, 8], [9, 16], [17, 20], [20, 21], [21, 26], [27, 30], [31, 34], [35, 38], [39, 47], [48, 53], [54, 59], [60, 66], [67, 78], [79, 88], [89, 93], [94, 96], [97, 101], [102, 112], [113, 115], [116, 118], [118, 119]]}
{"doc_key": "ai-test-298", "ner": [[1, 2, "misc"], [10, 12, "metrics"], [15, 16, "metrics"], [21, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 12, 1, 2, "type-of", "", false, false], [15, 16, 1, 2, "type-of", "", false, false], [15, 16, 21, 21, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "loss", "functions", "commonly", "used", "for", "probabilistic", "classification", "are", "the", "log", "-", "loss", "and", "the", "Brier", "score", "between", "the", "predicted", "and", "true", "probability", "distributions", "."], "sentence-detokenized": "The loss functions commonly used for probabilistic classification are the log-loss and the Brier score between the predicted and true probability distributions.", "token2charspan": [[0, 3], [4, 8], [9, 18], [19, 27], [28, 32], [33, 36], [37, 50], [51, 65], [66, 69], [70, 73], [74, 77], [77, 78], [78, 82], [83, 86], [87, 90], [91, 96], [97, 102], [103, 110], [111, 114], [115, 124], [125, 128], [129, 133], [134, 145], [146, 159], [159, 160]]}
{"doc_key": "ai-test-299", "ner": [[4, 4, "organisation"], [18, 18, "field"], [9, 10, "organisation"], [14, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 18, 18, "general-affiliation", "field_of_study", false, false], [4, 4, 14, 16, "part-of", "", false, false], [9, 10, 4, 4, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "May", "2016", ",", "NtechLab", "was", "officially", "accepted", "by", "NIST", "as", "one", "of", "three", "Russian", "companies", "to", "test", "biometric", "technology", "."], "sentence-detokenized": "In May 2016, NtechLab was officially accepted by NIST as one of three Russian companies to test biometric technology.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [13, 21], [22, 25], [26, 36], [37, 45], [46, 48], [49, 53], [54, 56], [57, 60], [61, 63], [64, 69], [70, 77], [78, 87], [88, 90], [91, 95], [96, 105], [106, 116], [116, 117]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "floating", "-", "point", "numbers", "only", "have", "a", "certain", "mathematical", "precision", "."], "sentence-detokenized": "However, floating-point numbers only have a certain mathematical precision.", "token2charspan": [[0, 7], [7, 8], [9, 17], [17, 18], [18, 23], [24, 31], [32, 36], [37, 41], [42, 43], [44, 51], [52, 64], [65, 74], [74, 75]]}
{"doc_key": "ai-test-301", "ner": [[5, 5, "organisation"], [11, 18, "conference"], [14, 20, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 11, 18, "role", "contributes_to", false, false], [14, 20, 11, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "2015", ",", "many", "of", "SenseTime", "'s", "papers", "were", "accepted", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "During 2015, many of SenseTime's papers were accepted at the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 6], [7, 11], [11, 12], [13, 17], [18, 20], [21, 30], [30, 32], [33, 39], [40, 44], [45, 53], [54, 56], [57, 60], [61, 71], [72, 74], [75, 83], [84, 90], [91, 94], [95, 102], [103, 114], [115, 116], [116, 120], [120, 121], [121, 122]]}
{"doc_key": "ai-test-302", "ner": [[9, 11, "task"], [13, 13, "task"], [15, 16, "task"], [18, 21, "task"], [23, 24, "field"], [26, 28, "misc"], [30, 36, "conference"], [44, 46, "misc"], [48, 49, "conference"], [66, 68, "misc"], [70, 70, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[9, 11, 23, 24, "part-of", "task_part_of_field", false, false], [13, 13, 9, 11, "named", "", false, false], [15, 16, 23, 24, "part-of", "task_part_of_field", false, false], [18, 21, 15, 16, "named", "", false, false], [26, 28, 30, 36, "temporal", "", false, false], [44, 46, 48, 49, "temporal", "", false, false], [66, 68, 70, 70, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["He", "contributed", "to", "the", "development", "of", "optimal", "algorithms", "for", "Structure", "From", "Motion", "(", "SFM", "or", "Visual", "SLAM", ",", "Simultaneous", "Localization", "and", "Mapping", ",", "in", "robotics", ";", "Best", "Paper", "Award", "at", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "1998", ")", ",", "characterizing", "its", "ambiguity", "(", "David", "Marr", "Prize", "at", "ICCV", "1999", ")", ",", "as", "well", "as", "characterizing", "the", "detectability", "and", "traceability", "of", "visual", "-intuitive", "sensor", "fusion", "(", "Best", "Paper", "Award", "at", "Robotics", "2015", ")", "."], "sentence-detokenized": "He contributed to the development of optimal algorithms for Structure From Motion (SFM or Visual SLAM, Simultaneous Localization and Mapping, in robotics; Best Paper Award at Conference on Computer Vision and Pattern Recognition 1998), characterizing its ambiguity (David Marr Prize at ICCV 1999), as well as characterizing the detectability and traceability of visual-intuitive sensor fusion (Best Paper Award at Robotics 2015).", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 21], [22, 33], [34, 36], [37, 44], [45, 55], [56, 59], [60, 69], [70, 74], [75, 81], [82, 83], [83, 86], [87, 89], [90, 96], [97, 101], [101, 102], [103, 115], [116, 128], [129, 132], [133, 140], [140, 141], [142, 144], [145, 153], [153, 154], [155, 159], [160, 165], [166, 171], [172, 174], [175, 185], [186, 188], [189, 197], [198, 204], [205, 208], [209, 216], [217, 228], [229, 233], [233, 234], [234, 235], [236, 250], [251, 254], [255, 264], [265, 266], [266, 271], [272, 276], [277, 282], [283, 285], [286, 290], [291, 295], [295, 296], [296, 297], [298, 300], [301, 305], [306, 308], [309, 323], [324, 327], [328, 341], [342, 345], [346, 358], [359, 361], [362, 368], [368, 378], [379, 385], [386, 392], [393, 394], [394, 398], [399, 404], [405, 410], [411, 413], [414, 422], [423, 427], [427, 428], [428, 429]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 44], [45, 48], [49, 52], [53, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-304", "ner": [[0, 1, "task"], [6, 8, "field"], [10, 11, "field"], [13, 14, "field"], [18, 19, "task"], [17, 21, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 6, 8, "part-of", "task_part_of_field", false, false], [0, 1, 10, 11, "part-of", "task_part_of_field", false, false], [0, 1, 13, 14, "part-of", "task_part_of_field", false, false], [0, 1, 18, 19, "part-of", "", false, false], [0, 1, 17, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Edge", "detection", "is", "a", "fundamental", "tool", "in", "image", "processing", ",", "machine", "vision", "and", "computer", "vision", ",", "especially", "for", "feature", "recognition", "and", "retrieval", "."], "sentence-detokenized": "Edge detection is a fundamental tool in image processing, machine vision and computer vision, especially for feature recognition and retrieval.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 19], [20, 31], [32, 36], [37, 39], [40, 45], [46, 56], [56, 57], [58, 65], [66, 72], [73, 76], [77, 85], [86, 92], [92, 93], [94, 104], [105, 108], [109, 116], [117, 128], [129, 132], [133, 142], [142, 143]]}
{"doc_key": "ai-test-305", "ner": [[6, 7, "misc"], [23, 24, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "example", "of", "this", "is", "the", "outdoor", "temperature", "(", "mathtemp", "/", "math", ")", ",", "which", "in", "this", "application", "can", "be", "stored", "to", "several", "decimal", "places", "(", "depending", "on", "the", "measuring", "device", ")", "."], "sentence-detokenized": "An example of this is the outdoor temperature (mathtemp/math), which in this application can be stored to several decimal places (depending on the measuring device).", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 18], [19, 21], [22, 25], [26, 33], [34, 45], [46, 47], [47, 55], [55, 56], [56, 60], [60, 61], [61, 62], [63, 68], [69, 71], [72, 76], [77, 88], [89, 92], [93, 95], [96, 102], [103, 105], [106, 113], [114, 121], [122, 128], [129, 130], [130, 139], [140, 142], [143, 146], [147, 156], [157, 163], [163, 164], [164, 165]]}
{"doc_key": "ai-test-306", "ner": [[2, 3, "person"], [5, 6, "person"], [8, 9, "person"], [18, 19, "person"], [21, 21, "misc"], [25, 25, "misc"], [27, 28, "person"], [30, 30, "organisation"], [33, 34, "person"], [36, 36, "organisation"], [38, 40, "person"], [41, 41, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[27, 28, 21, 21, "part-of", "", false, false], [27, 28, 25, 25, "role", "", false, false], [33, 34, 30, 30, "role", "", false, false], [38, 40, 36, 36, "role", "youtuber", false, false], [41, 41, 38, 40, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Returning", "judges", "Fon", "Davis", ",", "Jessica", "Chobot", "and", "Leland", "Melvin", ",", "as", "well", "as", "celebrity", "guest", "judges", "actor", "Clark", "Gregg", ",", "MythBusters", "host", "and", "former", "Battlebots", "builder", "Adam", "Savage", ",", "NFL", "tight", "end", "Vernon", "Davis", "and", "YouTube", "star", "Michael", "Stevens", "aka", "Vsauce", "."], "sentence-detokenized": "Returning judges Fon Davis, Jessica Chobot and Leland Melvin, as well as celebrity guest judges actor Clark Gregg, MythBusters host and former Battlebots builder Adam Savage, NFL tight end Vernon Davis and YouTube star Michael Stevens aka Vsauce.", "token2charspan": [[0, 9], [10, 16], [17, 20], [21, 26], [26, 27], [28, 35], [36, 42], [43, 46], [47, 53], [54, 60], [60, 61], [62, 64], [65, 69], [70, 72], [73, 82], [83, 88], [89, 95], [96, 101], [102, 107], [108, 113], [113, 114], [115, 126], [127, 131], [132, 135], [136, 142], [143, 153], [154, 161], [162, 166], [167, 173], [173, 174], [175, 178], [179, 184], [185, 188], [189, 195], [196, 201], [202, 205], [206, 213], [214, 218], [219, 226], [227, 234], [235, 238], [239, 245], [245, 246]]}
{"doc_key": "ai-test-307", "ner": [[15, 16, "algorithm"], [19, 21, "algorithm"], [17, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 16, 17, 25, "part-of", "", false, false], [19, 21, 17, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "these", "methods", "have", "never", "been", "able", "to", "overcome", "the", "inhomogeneous", "internal", "craft", "of", "Gaussian", "Mixture", "Model", "/", "Hidden", "Markov", "Model", "(", "GMM", "-", "HMM", ")", "technology", ",", "which", "is", "based", "on", "discriminatively", "trained", "speech", "generating", "models", "."], "sentence-detokenized": "However, these methods have never been able to overcome the inhomogeneous internal craft of Gaussian Mixture Model/Hidden Markov Model (GMM-HMM) technology, which is based on discriminatively trained speech generating models.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 22], [23, 27], [28, 33], [34, 38], [39, 43], [44, 46], [47, 55], [56, 59], [60, 73], [74, 82], [83, 88], [89, 91], [92, 100], [101, 108], [109, 114], [114, 115], [115, 121], [122, 128], [129, 134], [135, 136], [136, 139], [139, 140], [140, 143], [143, 144], [145, 155], [155, 156], [157, 162], [163, 165], [166, 171], [172, 174], [175, 191], [192, 199], [200, 206], [207, 217], [218, 224], [224, 225]]}
{"doc_key": "ai-test-308", "ner": [[4, 4, "product"], [6, 7, "programlang"], [9, 9, "programlang"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Software", "packages", "such", "as", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", "and", "SciPy", "provide", "convenient", "ways", "to", "implement", "these", "different", "methods", "."], "sentence-detokenized": "Software packages such as MATLAB, GNU Octave, Scilab and SciPy provide convenient ways to implement these different methods.", "token2charspan": [[0, 8], [9, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 37], [38, 44], [44, 45], [46, 52], [53, 56], [57, 62], [63, 70], [71, 81], [82, 86], [87, 89], [90, 99], [100, 105], [106, 115], [116, 123], [123, 124]]}
{"doc_key": "ai-test-309", "ner": [[1, 2, "algorithm"], [0, 4, "algorithm"], [14, 15, "researcher"], [16, 18, "university"], [20, 21, "researcher"], [22, 26, "organisation"], [28, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7], "relations": [[1, 2, 14, 15, "origin", "", false, false], [1, 2, 20, 21, "origin", "", false, false], [0, 4, 1, 2, "named", "", false, false], [14, 15, 16, 18, "physical", "", false, false], [14, 15, 16, 18, "role", "", false, false], [20, 21, 22, 26, "physical", "", false, false], [20, 21, 22, 26, "role", "", false, false], [28, 30, 22, 26, "named", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Linear", "Prediction", "Coding", "(", "LPC", ")", "is", "a", "speech", "processing", "algorithm", "first", "proposed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", "."], "sentence-detokenized": "Linear Prediction Coding (LPC) is a speech processing algorithm first proposed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [31, 33], [34, 35], [36, 42], [43, 53], [54, 63], [64, 69], [70, 78], [79, 81], [82, 90], [91, 98], [99, 101], [102, 108], [109, 119], [120, 123], [124, 129], [130, 135], [136, 138], [139, 145], [146, 155], [156, 159], [160, 169], [170, 171], [171, 174], [174, 175], [176, 178], [179, 183], [183, 184]]}
{"doc_key": "ai-test-310", "ner": [[18, 26, "conference"], [20, 28, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 28, 18, 26, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2006", ",", "on", "the", "occasion", "of", "the", "algorithm", "'s", "25th", "anniversary", ",", "a", "workshop", "was", "organised", "at", "the", "International", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "to", "summarise", "the", "latest", "contributions", "and", "variations", "of", "the", "original", "algorithm", ",", "mainly", "aimed", "at", "improving", "the", "speed", ",", "reliability", "and", "accuracy", "of", "the", "algorithm", "and", "reducing", "the", "dependence", "on", "user", "-", "defined", "constants", "."], "sentence-detokenized": "In 2006, on the occasion of the algorithm's 25th anniversary, a workshop was organised at the International Conference on Computer Vision and Pattern Recognition (CVPR) to summarise the latest contributions and variations of the original algorithm, mainly aimed at improving the speed, reliability and accuracy of the algorithm and reducing the dependence on user-defined constants.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 24], [25, 27], [28, 31], [32, 41], [41, 43], [44, 48], [49, 60], [60, 61], [62, 63], [64, 72], [73, 76], [77, 86], [87, 89], [90, 93], [94, 107], [108, 118], [119, 121], [122, 130], [131, 137], [138, 141], [142, 149], [150, 161], [162, 163], [163, 167], [167, 168], [169, 171], [172, 181], [182, 185], [186, 192], [193, 206], [207, 210], [211, 221], [222, 224], [225, 228], [229, 237], [238, 247], [247, 248], [249, 255], [256, 261], [262, 264], [265, 274], [275, 278], [279, 284], [284, 285], [286, 297], [298, 301], [302, 310], [311, 313], [314, 317], [318, 327], [328, 331], [332, 340], [341, 344], [345, 355], [356, 358], [359, 363], [363, 364], [364, 371], [372, 381], [381, 382]]}
{"doc_key": "ai-test-311", "ner": [[3, 5, "university"], [8, 11, "organisation"], [13, 15, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Members", "visited", "the", "University", "of", "Debrecen", ",", "the", "Hungarian", "Academy", "of", "Sciences", ",", "E\u00f6tv\u00f6s", "Lor\u00e1nd", "University", ",", "etc", "."], "sentence-detokenized": "Members visited the University of Debrecen, the Hungarian Academy of Sciences, E\u00f6tv\u00f6s Lor\u00e1nd University, etc.", "token2charspan": [[0, 7], [8, 15], [16, 19], [20, 30], [31, 33], [34, 42], [42, 43], [44, 47], [48, 57], [58, 65], [66, 68], [69, 77], [77, 78], [79, 85], [86, 92], [93, 103], [103, 104], [105, 108], [108, 109]]}
{"doc_key": "ai-test-312", "ner": [[2, 2, "algorithm"], [15, 17, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 15, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "extend", "SVM", "to", "cases", "where", "the", "data", "are", "not", "linearly", "separable", ",", "we", "introduce", "a", "loss", "function", ","], "sentence-detokenized": "To extend SVM to cases where the data are not linearly separable, we introduce a loss function,", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 16], [17, 22], [23, 28], [29, 32], [33, 37], [38, 41], [42, 45], [46, 54], [55, 64], [64, 65], [66, 68], [69, 78], [79, 80], [81, 85], [86, 94], [94, 95]]}
{"doc_key": "ai-test-313", "ner": [[0, 0, "programlang"], [9, 10, "researcher"], [12, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 9, 10, "origin", "", false, false], [0, 0, 12, 13, "origin", "", false, false], [0, 0, 15, 16, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Logo", "is", "a", "programming", "language", "developed", "in", "1967", "by", "Wally", "Feurzeig", ",", "Seymour", "Papert", "and", "Cynthia", "Solomon", "."], "sentence-detokenized": "Logo is a programming language developed in 1967 by Wally Feurzeig, Seymour Papert and Cynthia Solomon.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 21], [22, 30], [31, 40], [41, 43], [44, 48], [49, 51], [52, 57], [58, 66], [66, 67], [68, 75], [76, 82], [83, 86], [87, 94], [95, 102], [102, 103]]}
{"doc_key": "ai-test-314", "ner": [[0, 3, "organisation"], [6, 11, "organisation"], [12, 15, "location"], [17, 17, "location"], [19, 19, "location"], [25, 28, "product"], [36, 40, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 6, 11, "role", "works_for", false, false], [6, 11, 12, 15, "physical", "", false, false], [12, 15, 17, 17, "physical", "", false, false], [17, 17, 19, 19, "physical", "", false, false], [25, 28, 0, 3, "origin", "", false, false], [36, 40, 25, 28, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Eyring", "'s", "research", "institute", "was", "the", "US", "Air", "Force", "Missile", "Directorate", "at", "Hill", "Air", "Force", "Base", "near", "Ogden", ",", "Utah", ",", "to", "produce", "the", "top-secret", "Intelligent", "Systems", "Technology", "Software", ",", "which", "was", "later", "the", "basis", "of", "Reagan", "'s", "Star", "Wars", "programme", "."], "sentence-detokenized": "Eyring's research institute was the US Air Force Missile Directorate at Hill Air Force Base near Ogden, Utah, to produce the top-secret Intelligent Systems Technology Software, which was later the basis of Reagan's Star Wars programme.", "token2charspan": [[0, 6], [6, 8], [9, 17], [18, 27], [28, 31], [32, 35], [36, 38], [39, 42], [43, 48], [49, 56], [57, 68], [69, 71], [72, 76], [77, 80], [81, 86], [87, 91], [92, 96], [97, 102], [102, 103], [104, 108], [108, 109], [110, 112], [113, 120], [121, 124], [125, 135], [136, 147], [148, 155], [156, 166], [167, 175], [175, 176], [177, 182], [183, 186], [187, 192], [193, 196], [197, 202], [203, 205], [206, 212], [212, 214], [215, 219], [220, 224], [225, 234], [234, 235]]}
{"doc_key": "ai-test-315", "ner": [[12, 13, "field"], [24, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Over", "the", "decades", ",", "he", "has", "explored", "and", "developed", "new", "areas", "of", "computer", "science", ",", "from", "compilers", ",", "programming", "languages", "and", "systems", "architecture", "to", "John", "F", ".", "Sowa", "and", "John", "Zachman", "(", "1992", ")", "."], "sentence-detokenized": "Over the decades, he has explored and developed new areas of computer science, from compilers, programming languages and systems architecture to John F. Sowa and John Zachman (1992).", "token2charspan": [[0, 4], [5, 8], [9, 16], [16, 17], [18, 20], [21, 24], [25, 33], [34, 37], [38, 47], [48, 51], [52, 57], [58, 60], [61, 69], [70, 77], [77, 78], [79, 83], [84, 93], [93, 94], [95, 106], [107, 116], [117, 120], [121, 128], [129, 141], [142, 144], [145, 149], [150, 151], [151, 152], [153, 157], [158, 161], [162, 166], [167, 174], [175, 176], [176, 180], [180, 181], [181, 182]]}
{"doc_key": "ai-test-316", "ner": [[0, 2, "algorithm"], [8, 12, "algorithm"], [14, 17, "algorithm"], [19, 21, "field"], [23, 24, "field"], [27, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 12, 0, 2, "named", "", false, false], [14, 17, 0, 2, "named", "", false, false], [19, 21, 0, 2, "usage", "", false, false], [23, 24, 0, 2, "usage", "", false, false], [27, 30, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Sobel", "operator", ",", "sometimes", "referred", "to", "as", "the", "Sobel", "-", "Feldman", "operator", "or", "Sobel", "filter", ",", "is", "used", "in", "image", "processing", "and", "computer", "vision", ",", "particularly", "in", "edge", "detection", "algorithms", ",", "where", "it", "creates", "an", "image", "that", "emphasises", "edges", "."], "sentence-detokenized": "The Sobel operator, sometimes referred to as the Sobel-Feldman operator or Sobel filter, is used in image processing and computer vision, particularly in edge detection algorithms, where it creates an image that emphasises edges.", "token2charspan": [[0, 3], [4, 9], [10, 18], [18, 19], [20, 29], [30, 38], [39, 41], [42, 44], [45, 48], [49, 54], [54, 55], [55, 62], [63, 71], [72, 74], [75, 80], [81, 87], [87, 88], [89, 91], [92, 96], [97, 99], [100, 105], [106, 116], [117, 120], [121, 129], [130, 136], [136, 137], [138, 150], [151, 153], [154, 158], [159, 168], [169, 179], [179, 180], [181, 186], [187, 189], [190, 197], [198, 200], [201, 206], [207, 211], [212, 222], [223, 228], [228, 229]]}
{"doc_key": "ai-test-317", "ner": [[0, 0, "algorithm"], [3, 3, "field"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 3, 3, "compare", "", false, false], [0, 0, 3, 3, "type-of", "", false, false], [0, 0, 12, 12, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["LDA", "is", "a", "supervised", "learning", "algorithm", "that", "uses", "data", "tags", ",", "while", "PCA", "is", "a", "learning", "algorithm", "that", "ignores", "tags", "."], "sentence-detokenized": "LDA is a supervised learning algorithm that uses data tags, while PCA is a learning algorithm that ignores tags.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 19], [20, 28], [29, 38], [39, 43], [44, 48], [49, 53], [54, 58], [58, 59], [60, 65], [66, 69], [70, 72], [73, 74], [75, 83], [84, 93], [94, 98], [99, 106], [107, 111], [111, 112]]}
{"doc_key": "ai-test-318", "ner": [[5, 5, "algorithm"], [7, 9, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "linear", "classification", "algorithms", "are", "Winnow", ",", "support", "vector", "machine", "and", "logistic", "regression", "."], "sentence-detokenized": "Other linear classification algorithms are Winnow, support vector machine and logistic regression.", "token2charspan": [[0, 5], [6, 12], [13, 27], [28, 38], [39, 42], [43, 49], [49, 50], [51, 58], [59, 65], [66, 73], [74, 77], [78, 86], [87, 97], [97, 98]]}
{"doc_key": "ai-test-319", "ner": [[0, 1, "product"], [5, 6, "programlang"], [16, 18, "product"], [20, 20, "programlang"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 6, "general-affiliation", "", true, false], [0, 1, 16, 18, "general-affiliation", "", true, false], [0, 1, 20, 20, "general-affiliation", "", true, false], [0, 1, 22, 22, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "VTK", "consists", "of", "a", "C", "++", "class", "library", "and", "several", "interpreted", "interface", "layers", ",", "including", "Tcl", "/", "Tk", ",", "Java", "and", "Python", "."], "sentence-detokenized": "The VTK consists of a C++ class library and several interpreted interface layers, including Tcl/Tk, Java and Python.", "token2charspan": [[0, 3], [4, 7], [8, 16], [17, 19], [20, 21], [22, 23], [23, 25], [26, 31], [32, 39], [40, 43], [44, 51], [52, 63], [64, 73], [74, 80], [80, 81], [82, 91], [92, 95], [95, 96], [96, 98], [98, 99], [100, 104], [105, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-test-320", "ner": [[7, 9, "task"], [16, 18, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Text", "produced", "by", "processing", "spontaneous", "speech", "using", "automatic", "speech", "recognition", "and", "printed", "or", "handwritten", "text", "using", "optical", "character", "recognition", "also", "contains", "processing", "noise", "."], "sentence-detokenized": "Text produced by processing spontaneous speech using automatic speech recognition and printed or handwritten text using optical character recognition also contains processing noise.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 27], [28, 39], [40, 46], [47, 52], [53, 62], [63, 69], [70, 81], [82, 85], [86, 93], [94, 96], [97, 108], [109, 113], [114, 119], [120, 127], [128, 137], [138, 149], [150, 154], [155, 163], [164, 174], [175, 180], [180, 181]]}
{"doc_key": "ai-test-321", "ner": [[0, 2, "researcher"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 12, 12, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "is", "the", "author", "of", "several", "books", "and", "led", "the", "development", "of", "WordNet", ",", "an", "online", "database", "for", "word", "linking", "using", "computer", "programs", "."], "sentence-detokenized": "Miller is the author of several books and led the development of WordNet, an online database for word linking using computer programs.", "token2charspan": [[0, 6], [7, 9], [10, 13], [14, 20], [21, 23], [24, 31], [32, 37], [38, 41], [42, 45], [46, 49], [50, 61], [62, 64], [65, 72], [72, 73], [74, 76], [77, 83], [84, 92], [93, 96], [97, 101], [102, 109], [110, 115], [116, 124], [125, 133], [133, 134]]}
{"doc_key": "ai-test-322", "ner": [[1, 1, "field"], [5, 7, "organisation"], [8, 10, "country"], [12, 13, "person"], [15, 17, "person"], [19, 20, "person"], [22, 23, "person"], [24, 26, "country"], [28, 31, "location"], [33, 34, "misc"], [35, 36, "person"], [38, 39, "person"], [40, 41, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[5, 7, 8, 10, "physical", "", false, false], [12, 13, 24, 26, "physical", "", false, false], [15, 17, 24, 26, "physical", "", false, false], [19, 20, 24, 26, "physical", "", false, false], [22, 23, 24, 26, "physical", "", false, false], [28, 31, 1, 1, "general-affiliation", "", false, false], [28, 31, 35, 36, "artifact", "", false, false], [33, 34, 35, 36, "named", "", false, false], [38, 39, 40, 41, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Contemporary", "automatons", "are", "represented", "by", "Cabaret", "Mechanical", "Theatre", "in", "the", "UK", ",", "Dug", "North", "and", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", ",", "Joe", "Jones", "in", "the", "USA", ",", "Le", "D\u00e9fenseur", "du", "Temps", "by", "French", "artist", "Jacques", "Monestier", "and", "Fran\u00e7ois", "Junod", "in", "Switzerland", "."], "sentence-detokenized": "Contemporary automatons are represented by Cabaret Mechanical Theatre in the UK, Dug North and Chomick + Meder, Arthur Ganson, Joe Jones in the USA, Le D\u00e9fenseur du Temps by French artist Jacques Monestier and Fran\u00e7ois Junod in Switzerland.", "token2charspan": [[0, 12], [13, 23], [24, 27], [28, 39], [40, 42], [43, 50], [51, 61], [62, 69], [70, 72], [73, 76], [77, 79], [79, 80], [81, 84], [85, 90], [91, 94], [95, 102], [103, 104], [105, 110], [110, 111], [112, 118], [119, 125], [125, 126], [127, 130], [131, 136], [137, 139], [140, 143], [144, 147], [147, 148], [149, 151], [152, 161], [162, 164], [165, 170], [171, 173], [174, 180], [181, 187], [188, 195], [196, 205], [206, 209], [210, 218], [219, 224], [225, 227], [228, 239], [239, 240]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 21, 21, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "includes", "standard", "codefor", "/", "code", "and", "codewhile", "/", "code", "loops", ",", "but", "(", "as", "in", "other", "similar", "applications", "such", "as", "R", ")", ",", "the", "use", "of", "vectorized", "notation", "is", "recommended", "and", "is", "often", "faster", "to", "execute", "."], "sentence-detokenized": "MATLAB includes standard codefor/code and codewhile/code loops, but (as in other similar applications such as R), the use of vectorized notation is recommended and is often faster to execute.", "token2charspan": [[0, 6], [7, 15], [16, 24], [25, 32], [32, 33], [33, 37], [38, 41], [42, 51], [51, 52], [52, 56], [57, 62], [62, 63], [64, 67], [68, 69], [69, 71], [72, 74], [75, 80], [81, 88], [89, 101], [102, 106], [107, 109], [110, 111], [111, 112], [112, 113], [114, 117], [118, 121], [122, 124], [125, 135], [136, 144], [145, 147], [148, 159], [160, 163], [164, 166], [167, 172], [173, 179], [180, 182], [183, 190], [190, 191]]}
{"doc_key": "ai-test-324", "ner": [[3, 3, "researcher"], [9, 12, "conference"], [16, 19, "field"], [20, 25, "misc"], [28, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 20, 25, "win-defeat", "", false, false], [3, 3, 28, 37, "win-defeat", "", false, false], [20, 25, 9, 12, "temporal", "", false, false], [20, 25, 16, 19, "topic", "", false, false], [28, 37, 9, 12, "temporal", "", false, false], [28, 37, 16, 19, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2007", ",", "Pausch", "received", "two", "awards", "from", "the", "Association", "for", "Computing", "Machinery", "for", "his", "achievements", "in", "computer", "science", "education", ".", "Karl", "Karlstrom", "Outstanding", "Educator", "Award", "and", "the", "ACM", "SIGCSE", "Award", "for", "Outstanding", "Contribution", "to", "Computer", "Science", "Education", "."], "sentence-detokenized": "In 2007, Pausch received two awards from the Association for Computing Machinery for his achievements in computer science education. Karl Karlstrom Outstanding Educator Award and the ACM SIGCSE Award for Outstanding Contribution to Computer Science Education.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 24], [25, 28], [29, 35], [36, 40], [41, 44], [45, 56], [57, 60], [61, 70], [71, 80], [81, 84], [85, 88], [89, 101], [102, 104], [105, 113], [114, 121], [122, 131], [131, 132], [133, 137], [138, 147], [148, 159], [160, 168], [169, 174], [175, 178], [179, 182], [183, 186], [187, 193], [194, 199], [200, 203], [204, 215], [216, 228], [229, 231], [232, 240], [241, 248], [249, 258], [258, 259]]}
{"doc_key": "ai-test-325", "ner": [[3, 3, "person"], [8, 8, "product"], [9, 12, "product"], [15, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 8, 8, "role", "sells", false, false], [8, 8, 9, 12, "general-affiliation", "", false, false], [8, 8, 15, 17, "physical", "shipped_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "delivered", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was delivered to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 75], [76, 78], [79, 86], [87, 93], [94, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-test-326", "ner": [[0, 1, "algorithm"], [5, 7, "field"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 0, 1, "usage", "", false, false], [11, 12, 5, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Semantic", "networks", "are", "used", "in", "natural", "language", "processing", "applications", "such", "as", "semantic", "analysis", "."], "sentence-detokenized": "Semantic networks are used in natural language processing applications such as semantic analysis.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 26], [27, 29], [30, 37], [38, 46], [47, 57], [58, 70], [71, 75], [76, 78], [79, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-test-327", "ner": [[4, 5, "field"], [7, 8, "field"], [10, 11, "task"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 8, 4, 5, "usage", "", false, false], [10, 11, 4, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Some", "successful", "applications", "of", "deep", "learning", "are", "computer", "vision", "and", "speech", "recognition", ".", "Honglak", "Lee", ",", "Roger", "Grosse", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y", ".", "Ng", "."], "sentence-detokenized": "Some successful applications of deep learning are computer vision and speech recognition. Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 4], [5, 15], [16, 28], [29, 31], [32, 36], [37, 45], [46, 49], [50, 58], [59, 65], [66, 69], [70, 76], [77, 88], [88, 89], [90, 97], [98, 101], [101, 102], [103, 108], [109, 115], [115, 116], [117, 123], [124, 133], [133, 134], [135, 141], [142, 143], [143, 144], [145, 147], [147, 148]]}
{"doc_key": "ai-test-328", "ner": [[0, 10, "product"], [16, 16, "misc"], [19, 22, "misc"], [25, 25, "product"], [28, 30, "task"], [32, 33, "task"], [35, 36, "task"], [38, 40, "field"], [42, 44, "task"], [46, 47, "field"], [49, 50, "task"], [52, 53, "task"], [55, 56, "task"], [58, 58, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[0, 10, 16, 16, "physical", "travels_to", false, false], [0, 10, 19, 22, "physical", "travels_to", false, false], [25, 25, 0, 10, "part-of", "", false, false], [25, 25, 0, 10, "role", "maintains", false, false], [25, 25, 28, 30, "related-to", "has_ability_to", false, false], [25, 25, 32, 33, "related-to", "has_ability_to", false, false], [25, 25, 35, 36, "related-to", "has_ability_to", false, false], [25, 25, 38, 40, "related-to", "has_ability_to", false, false], [25, 25, 42, 44, "related-to", "has_ability_to", false, false], [25, 25, 46, 47, "related-to", "has_ability_to", false, false], [25, 25, 49, 50, "related-to", "has_ability_to", false, false], [25, 25, 52, 53, "related-to", "has_ability_to", false, false], [25, 25, 55, 56, "related-to", "has_ability_to", false, false], [25, 25, 58, 58, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["In", "addition", "to", "servicing", "the", "systems", "of", "the", "spacecraft", "Discovery", "One", "during", "its", "interplanetary", "mission", "to", "Jupiter", "(", "or", "Saturn", "in", "the", "novel", ")", ",", "HAL", "is", "capable", "of", "speech", "synthesis", ",", "speech", "recognition", ",", "facial", "recognition", ",", "natural", "language", "processing", ",", "lip", "-", "reading", ",", "art", "appreciation", ",", "affective", "computing", ",", "automatic", "thinking", ",", "spacecraft", "piloting", "and", "chess", "."], "sentence-detokenized": "In addition to servicing the systems of the spacecraft Discovery One during its interplanetary mission to Jupiter (or Saturn in the novel), HAL is capable of speech synthesis, speech recognition, facial recognition, natural language processing, lip-reading, art appreciation, affective computing, automatic thinking, spacecraft piloting and chess.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 24], [25, 28], [29, 36], [37, 39], [40, 43], [44, 54], [55, 64], [65, 68], [69, 75], [76, 79], [80, 94], [95, 102], [103, 105], [106, 113], [114, 115], [115, 117], [118, 124], [125, 127], [128, 131], [132, 137], [137, 138], [138, 139], [140, 143], [144, 146], [147, 154], [155, 157], [158, 164], [165, 174], [174, 175], [176, 182], [183, 194], [194, 195], [196, 202], [203, 214], [214, 215], [216, 223], [224, 232], [233, 243], [243, 244], [245, 248], [248, 249], [249, 256], [256, 257], [258, 261], [262, 274], [274, 275], [276, 285], [286, 295], [295, 296], [297, 306], [307, 315], [315, 316], [317, 327], [328, 336], [337, 340], [341, 346], [346, 347]]}
{"doc_key": "ai-test-329", "ner": [[0, 1, "researcher"], [3, 4, "country"], [5, 8, "country"], [14, 15, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 3, 4, "physical", "", false, false], [0, 1, 5, 8, "physical", "", false, false], [0, 1, 14, 15, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dr", "Julesz", "emigrated", "from", "Hungary", "to", "the", "United", "States", "after", "the", "invasion", "of", "the", "Soviet", "Union", "in", "1956", "."], "sentence-detokenized": "Dr Julesz emigrated from Hungary to the United States after the invasion of the Soviet Union in 1956.", "token2charspan": [[0, 2], [3, 9], [10, 19], [20, 24], [25, 32], [33, 35], [36, 39], [40, 46], [47, 53], [54, 59], [60, 63], [64, 72], [73, 75], [76, 79], [80, 86], [87, 92], [93, 95], [96, 100], [100, 101]]}
{"doc_key": "ai-test-330", "ner": [[0, 0, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sigmoid", "activation", "functions", "use", "a", "second", "nonlinearity", "for", "large", "inputs", ":", "math", "\\", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+\\", "exp", "(", "-", "v", "_", "i", ")", ")", "^", "{", "-1", "}", "/", "math", "."], "sentence-detokenized": "Sigmoid activation functions use a second nonlinearity for large inputs: math\\ phi (v _ i) = (1 +\\ exp (-v _ i)) ^ {-1} / math.", "token2charspan": [[0, 7], [8, 18], [19, 28], [29, 32], [33, 34], [35, 41], [42, 54], [55, 58], [59, 64], [65, 71], [71, 72], [73, 77], [77, 78], [79, 82], [83, 84], [84, 85], [86, 87], [88, 89], [89, 90], [91, 92], [93, 94], [94, 95], [96, 98], [99, 102], [103, 104], [104, 105], [105, 106], [107, 108], [109, 110], [110, 111], [111, 112], [113, 114], [115, 116], [116, 118], [118, 119], [120, 121], [122, 126], [126, 127]]}
{"doc_key": "ai-test-331", "ner": [[10, 12, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "probabilities", "are", "used", "to", "determine", "the", "target", "using", "the", "maximum", "likelihood", "decision", "."], "sentence-detokenized": "These probabilities are used to determine the target using the maximum likelihood decision.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 28], [29, 31], [32, 41], [42, 45], [46, 52], [53, 58], [59, 62], [63, 70], [71, 81], [82, 90], [90, 91]]}
{"doc_key": "ai-test-332", "ner": [[6, 8, "university"], [14, 16, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1984", "he", "moved", "to", "the", "University", "of", "Konstanz", "and", "in", "1990", "to", "the", "University", "of", "Salzburg", "."], "sentence-detokenized": "In 1984 he moved to the University of Konstanz and in 1990 to the University of Salzburg.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 16], [17, 19], [20, 23], [24, 34], [35, 37], [38, 46], [47, 50], [51, 53], [54, 58], [59, 61], [62, 65], [66, 76], [77, 79], [80, 88], [88, 89]]}
{"doc_key": "ai-test-333", "ner": [[4, 4, "metrics"], [15, 17, "metrics"], [19, 21, "metrics"], [23, 23, "metrics"], [25, 26, "metrics"], [28, 30, "metrics"], [33, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 17, 4, 4, "origin", "based_on", false, false], [19, 21, 4, 4, "origin", "based_on", false, false], [23, 23, 4, 4, "origin", "based_on", false, false], [25, 26, 4, 4, "origin", "based_on", false, false], [28, 30, 4, 4, "origin", "based_on", false, false], [33, 36, 4, 4, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Some", "of", "the", "popular", "confusion", "matrix", "-", "based", "goodness", "-", "of", "-", "fit", "functions", "are", "sensitivity", "/", "specificity", ",", "recall", "/", "accuracy", ",", "F-measure", ",", "Jaccard", "similarity", ",", "Matthews", "correlation", "coefficient", "and", "a", "cost", "/", "profit", "matrix", "that", "combines", "the", "costs", "and", "profits", "assigned", "to", "4", "different", "types", "of", "classification", "."], "sentence-detokenized": "Some of the popular confusion matrix-based goodness-of-fit functions are sensitivity/specificity, recall/accuracy, F-measure, Jaccard similarity, Matthews correlation coefficient and a cost/profit matrix that combines the costs and profits assigned to 4 different types of classification.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 19], [20, 29], [30, 36], [36, 37], [37, 42], [43, 51], [51, 52], [52, 54], [54, 55], [55, 58], [59, 68], [69, 72], [73, 84], [84, 85], [85, 96], [96, 97], [98, 104], [104, 105], [105, 113], [113, 114], [115, 124], [124, 125], [126, 133], [134, 144], [144, 145], [146, 154], [155, 166], [167, 178], [179, 182], [183, 184], [185, 189], [189, 190], [190, 196], [197, 203], [204, 208], [209, 217], [218, 221], [222, 227], [228, 231], [232, 239], [240, 248], [249, 251], [252, 253], [254, 263], [264, 269], [270, 272], [273, 287], [287, 288]]}
{"doc_key": "ai-test-334", "ner": [[7, 7, "product"], [9, 9, "product"], [11, 11, "product"], [13, 13, "product"], [15, 16, "programlang"], [27, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[27, 29, 7, 7, "part-of", "", false, false], [27, 29, 9, 9, "part-of", "", false, false], [27, 29, 11, 11, "part-of", "", false, false], [27, 29, 13, 13, "part-of", "", false, false], [27, 29, 15, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Common", "numerical", "programming", "environments", ",", "such", "as", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", "and", "R-", "language", ",", "provide", "some", "simpler", "methods", "of", "feature", "extraction", "(", "e.g.", "principal", "component", "analysis", ")", "using", "built", "-", "in", "commands", "."], "sentence-detokenized": "Common numerical programming environments, such as MATLAB, SciLab, NumPy, Sklearn and R-language, provide some simpler methods of feature extraction (e.g. principal component analysis) using built-in commands.", "token2charspan": [[0, 6], [7, 16], [17, 28], [29, 41], [41, 42], [43, 47], [48, 50], [51, 57], [57, 58], [59, 65], [65, 66], [67, 72], [72, 73], [74, 81], [82, 85], [86, 88], [88, 96], [96, 97], [98, 105], [106, 110], [111, 118], [119, 126], [127, 129], [130, 137], [138, 148], [149, 150], [150, 154], [155, 164], [165, 174], [175, 183], [183, 184], [185, 190], [191, 196], [196, 197], [197, 199], [200, 208], [208, 209]]}
{"doc_key": "ai-test-335", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Industrial", "robots", "have", "been", "deployed", "to", "collaborate", "with", "humans", "to", "perform", "industrial", "production", "tasks", "."], "sentence-detokenized": "Industrial robots have been deployed to collaborate with humans to perform industrial production tasks.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 27], [28, 36], [37, 39], [40, 51], [52, 56], [57, 63], [64, 66], [67, 74], [75, 85], [86, 96], [97, 102], [102, 103]]}
{"doc_key": "ai-test-336", "ner": [[5, 6, "field"], [8, 11, "researcher"], [20, 22, "field"], [24, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 20, 22, "related-to", "", false, false], [5, 6, 24, 25, "related-to", "", false, false], [5, 6, 27, 28, "related-to", "", false, false], [8, 11, 5, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "first", "published", "work", "on", "CGs", ",", "John", "F", ".", "Sowa", "applied", "them", "to", "a", "wide", "range", "of", "topics", "in", "artificial", "intelligence", ",", "computer", "science", "and", "cognitive", "science", "."], "sentence-detokenized": "In the first published work on CGs, John F. Sowa applied them to a wide range of topics in artificial intelligence, computer science and cognitive science.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [23, 27], [28, 30], [31, 34], [34, 35], [36, 40], [41, 42], [42, 43], [44, 48], [49, 56], [57, 61], [62, 64], [65, 66], [67, 71], [72, 77], [78, 80], [81, 87], [88, 90], [91, 101], [102, 114], [114, 115], [116, 124], [125, 132], [133, 136], [137, 146], [147, 154], [154, 155]]}
{"doc_key": "ai-test-337", "ner": [[0, 0, "metrics"], [4, 4, "metrics"], [10, 11, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "BLEU", "in", "the", "calculation", "of", "the", "brevity", "penalty", ",", "as", "small", "differences", "in", "translation", "length", "do", "not", "affect", "the", "overall", "result", "as", "much", "."], "sentence-detokenized": "NIST also differs from BLEU in the calculation of the brevity penalty, as small differences in translation length do not affect the overall result as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 46], [47, 49], [50, 53], [54, 61], [62, 69], [69, 70], [71, 73], [74, 79], [80, 91], [92, 94], [95, 106], [107, 113], [114, 116], [117, 120], [121, 127], [128, 131], [132, 139], [140, 146], [147, 149], [150, 154], [154, 155]]}
{"doc_key": "ai-test-338", "ner": [[0, 5, "misc"], [13, 13, "conference"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 5, 13, 13, "temporal", "", false, false], [0, 5, 16, 17, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "IJCAI", "Award", "for", "Research", "Excellence", "is", "a", "bi-annual", "award", "given", "at", "the", "IJCAI", "conference", "to", "artificial", "intelligence", "researchers", "in", "recognition", "of", "their", "career", "excellence", "."], "sentence-detokenized": "The IJCAI Award for Research Excellence is a bi-annual award given at the IJCAI conference to artificial intelligence researchers in recognition of their career excellence.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 19], [20, 28], [29, 39], [40, 42], [43, 44], [45, 54], [55, 60], [61, 66], [67, 69], [70, 73], [74, 79], [80, 90], [91, 93], [94, 104], [105, 117], [118, 129], [130, 132], [133, 144], [145, 147], [148, 153], [154, 160], [161, 171], [171, 172]]}
{"doc_key": "ai-test-339", "ner": [[0, 0, "researcher"], [4, 4, "conference"], [17, 24, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "role", "", false, false], [0, 0, 17, 24, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lenat", "was", "one", "of", "AAAI", "'s", "original", "fellows", "and", "is", "the", "only", "person", "to", "have", "served", "on", "both", "the", "Microsoft", "and", "Apple", "Scientific", "Advisory", "Boards", "."], "sentence-detokenized": "Lenat was one of AAAI's original fellows and is the only person to have served on both the Microsoft and Apple Scientific Advisory Boards.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 16], [17, 21], [21, 23], [24, 32], [33, 40], [41, 44], [45, 47], [48, 51], [52, 56], [57, 63], [64, 66], [67, 71], [72, 78], [79, 81], [82, 86], [87, 90], [91, 100], [101, 104], [105, 110], [111, 121], [122, 130], [131, 137], [137, 138]]}
{"doc_key": "ai-test-340", "ner": [[0, 0, "algorithm"], [5, 6, "misc"], [9, 11, "metrics"], [18, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 6, "related-to", "minimise", false, false], [9, 11, 5, 6, "type-of", "", false, false], [18, 18, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autocoders", "are", "trained", "to", "minimise", "reconstruction", "errors", "(", "e.g.", "mean", "square", "error", ")", ",", "often", "referred", "to", "as", "losses", ":"], "sentence-detokenized": "Autocoders are trained to minimise reconstruction errors (e.g. mean square error), often referred to as losses:", "token2charspan": [[0, 10], [11, 14], [15, 22], [23, 25], [26, 34], [35, 49], [50, 56], [57, 58], [58, 62], [63, 67], [68, 74], [75, 80], [80, 81], [81, 82], [83, 88], [89, 97], [98, 100], [101, 103], [104, 110], [110, 111]]}
{"doc_key": "ai-test-341", "ner": [[30, 32, "misc"], [27, 36, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[27, 36, 30, 32, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "alternative", "to", "the", "use", "of", "definitions", "is", "to", "take", "into", "account", "the", "overall", "relatedness", "of", "word", "meanings", "and", "calculate", "the", "similarity", "of", "each", "word", "meaning", "pair", "from", "a", "given", "lexical", "knowledge", "base", ",", "such", "as", "WordNet", "."], "sentence-detokenized": "An alternative to the use of definitions is to take into account the overall relatedness of word meanings and calculate the similarity of each word meaning pair from a given lexical knowledge base, such as WordNet.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 21], [22, 25], [26, 28], [29, 40], [41, 43], [44, 46], [47, 51], [52, 56], [57, 64], [65, 68], [69, 76], [77, 88], [89, 91], [92, 96], [97, 105], [106, 109], [110, 119], [120, 123], [124, 134], [135, 137], [138, 142], [143, 147], [148, 155], [156, 160], [161, 165], [166, 167], [168, 173], [174, 181], [182, 191], [192, 196], [196, 197], [198, 202], [203, 205], [206, 213], [213, 214]]}
{"doc_key": "ai-test-342", "ner": [[0, 4, "algorithm"], [9, 11, "researcher"], [15, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 9, 11, "origin", "", false, false], [9, 11, 15, 17, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD", "-", "Lambda", "is", "a", "learning", "algorithm", "invented", "by", "Richard", "S.", "Sutton", ",", "based", "on", "Arthur", "Samuel", "'s", "earlier", "work", "on", "learning", "temporal", "differences", "."], "sentence-detokenized": "TD-Lambda is a learning algorithm invented by Richard S. Sutton, based on Arthur Samuel's earlier work on learning temporal differences.", "token2charspan": [[0, 2], [2, 3], [3, 9], [10, 12], [13, 14], [15, 23], [24, 33], [34, 42], [43, 45], [46, 53], [54, 56], [57, 63], [63, 64], [65, 70], [71, 73], [74, 80], [81, 87], [87, 89], [90, 97], [98, 102], [103, 105], [106, 114], [115, 123], [124, 135], [135, 136]]}
{"doc_key": "ai-test-343", "ner": [[22, 23, "field"], [25, 25, "field"], [0, 1, "task"], [7, 8, "task"], [6, 10, "task"], [16, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 22, 23, "part-of", "task_part_of_field", false, false], [0, 1, 25, 25, "part-of", "task_part_of_field", false, false], [7, 8, 0, 1, "named", "", false, false], [6, 10, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Hierarchical", "clustering", "(", "also", "known", "as", "hierarchical", "cluster", "analysis", "or", "HCA", ")", "is", "a", "method", "of", "cluster", "analysis", "in", "the", "field", "of", "data", "mining", "and", "statistics", "that", "aims", "to", "create", "a", "hierarchy", "of", "clusters", "."], "sentence-detokenized": "Hierarchical clustering (also known as hierarchical cluster analysis or HCA) is a method of cluster analysis in the field of data mining and statistics that aims to create a hierarchy of clusters.", "token2charspan": [[0, 12], [13, 23], [24, 25], [25, 29], [30, 35], [36, 38], [39, 51], [52, 59], [60, 68], [69, 71], [72, 75], [75, 76], [77, 79], [80, 81], [82, 88], [89, 91], [92, 99], [100, 108], [109, 111], [112, 115], [116, 121], [122, 124], [125, 129], [130, 136], [137, 140], [141, 151], [152, 156], [157, 161], [162, 164], [165, 171], [172, 173], [174, 183], [184, 186], [187, 195], [195, 196]]}
{"doc_key": "ai-test-344", "ner": [[3, 3, "algorithm"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "concept", "of", "deconvolution", "is", "widely", "used", "in", "signal", "processing", "and", "image", "processing", "techniques", "."], "sentence-detokenized": "The concept of deconvolution is widely used in signal processing and image processing techniques.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 28], [29, 31], [32, 38], [39, 43], [44, 46], [47, 53], [54, 64], [65, 68], [69, 74], [75, 85], [86, 96], [96, 97]]}
{"doc_key": "ai-test-345", "ner": [[0, 1, "algorithm"], [20, 21, "misc"], [25, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 20, 21, "related-to", "enhances", false, false], [0, 1, 20, 21, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cognitive", "maps", "serve", "to", "construct", "and", "accumulate", "spatial", "knowledge", ",", "allowing", "the", "mind", "'s", "eye", "to", "visualise", "images", "to", "reduce", "cognitive", "load", ",", "improve", "information", "retention", "and", "learning", "."], "sentence-detokenized": "Cognitive maps serve to construct and accumulate spatial knowledge, allowing the mind's eye to visualise images to reduce cognitive load, improve information retention and learning.", "token2charspan": [[0, 9], [10, 14], [15, 20], [21, 23], [24, 33], [34, 37], [38, 48], [49, 56], [57, 66], [66, 67], [68, 76], [77, 80], [81, 85], [85, 87], [88, 91], [92, 94], [95, 104], [105, 111], [112, 114], [115, 121], [122, 131], [132, 136], [136, 137], [138, 145], [146, 157], [158, 167], [168, 171], [172, 180], [180, 181]]}
{"doc_key": "ai-test-346", "ner": [[9, 9, "programlang"], [11, 12, "programlang"], [14, 14, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": [",", "which", "usually", "provide", "links", "to", "languages", "such", "as", "Python", ",", "C", "++", ",", "Java", ")", "."], "sentence-detokenized": ", which usually provide links to languages such as Python, C++, Java).", "token2charspan": [[0, 1], [2, 7], [8, 15], [16, 23], [24, 29], [30, 32], [33, 42], [43, 47], [48, 50], [51, 57], [57, 58], [59, 60], [60, 62], [62, 63], [64, 68], [68, 69], [69, 70]]}
{"doc_key": "ai-test-347", "ner": [[0, 5, "product"], [16, 18, "task"], [23, 24, "task"], [28, 33, "task"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "Voice", "User", "Interface", "(", "VUI", ")", "enables", "human", "-", "to", "-", "computer", "interaction", ",", "using", "speech", "recognition", "to", "understand", "spoken", "phrases", "and", "answer", "questions", ",", "and", "typically", "text", "-", "to", "-", "speech", "to", "provide", "a", "response", "."], "sentence-detokenized": "A Voice User Interface (VUI) enables human-to-computer interaction, using speech recognition to understand spoken phrases and answer questions, and typically text-to-speech to provide a response.", "token2charspan": [[0, 1], [2, 7], [8, 12], [13, 22], [23, 24], [24, 27], [27, 28], [29, 36], [37, 42], [42, 43], [43, 45], [45, 46], [46, 54], [55, 66], [66, 67], [68, 73], [74, 80], [81, 92], [93, 95], [96, 106], [107, 113], [114, 121], [122, 125], [126, 132], [133, 142], [142, 143], [144, 147], [148, 157], [158, 162], [162, 163], [163, 165], [165, 166], [166, 172], [173, 175], [176, 183], [184, 185], [186, 194], [194, 195]]}
{"doc_key": "ai-test-348", "ner": [[0, 0, "programlang"], [3, 10, "misc"], [12, 15, "researcher"], [16, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4], "relations": [[0, 0, 3, 10, "general-affiliation", "is_a", false, false], [0, 0, 12, 15, "origin", "", false, false], [12, 15, 16, 18, "role", "", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["Jess", "is", "a", "rules", "engine", "for", "the", "Java", "platform", ",", "developed", "by", "Ernest", "Friedman", "-", "Hill", "of", "Sandia", "National", "."], "sentence-detokenized": "Jess is a rules engine for the Java platform, developed by Ernest Friedman-Hill of Sandia National.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 15], [16, 22], [23, 26], [27, 30], [31, 35], [36, 44], [44, 45], [46, 55], [56, 58], [59, 65], [66, 74], [74, 75], [75, 79], [80, 82], [83, 89], [90, 98], [98, 99]]}
{"doc_key": "ai-test-349", "ner": [[1, 4, "algorithm"], [13, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 4, 13, 13, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "multilayer", "perceptrons", "with", "a", "hidden", "layer", ",", "more", "sophisticated", "algorithms", "such", "as", "backpropagation", "must", "be", "used", "."], "sentence-detokenized": "For multilayer perceptrons with a hidden layer, more sophisticated algorithms such as backpropagation must be used.", "token2charspan": [[0, 3], [4, 14], [15, 26], [27, 31], [32, 33], [34, 40], [41, 46], [46, 47], [48, 52], [53, 66], [67, 77], [78, 82], [83, 85], [86, 101], [102, 106], [107, 109], [110, 114], [114, 115]]}
{"doc_key": "ai-test-350", "ner": [[0, 1, "product"], [3, 6, "product"], [10, 18, "algorithm"], [22, 23, "field"], [27, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 0, 1, "part-of", "", false, false], [3, 6, 10, 18, "usage", "", false, true], [10, 18, 22, 23, "related-to", "performs", false, false], [27, 32, 22, 23, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Google", "Translate", "'s", "neural", "machine", "translation", "system", "uses", "a", "large", "end", "-", "to", "-", "end", "artificial", "neural", "network", "that", "tries", "to", "perform", "deep", "learning", ",", "in", "particular", "long", "short", "-", "term", "memory", "networks", "."], "sentence-detokenized": "Google Translate's neural machine translation system uses a large end-to-end artificial neural network that tries to perform deep learning, in particular long short-term memory networks.", "token2charspan": [[0, 6], [7, 16], [16, 18], [19, 25], [26, 33], [34, 45], [46, 52], [53, 57], [58, 59], [60, 65], [66, 69], [69, 70], [70, 72], [72, 73], [73, 76], [77, 87], [88, 94], [95, 102], [103, 107], [108, 113], [114, 116], [117, 124], [125, 129], [130, 138], [138, 139], [140, 142], [143, 153], [154, 158], [159, 164], [164, 165], [165, 169], [170, 176], [177, 185], [185, 186]]}
{"doc_key": "ai-test-351", "ner": [[11, 11, "researcher"], [13, 13, "researcher"], [15, 15, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 23, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Various", "methods", "were", "developed", "in", "the", "1980s", "and", "early", "1990s", "by", "Werbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Pearlmutter", "and", "others", "."], "sentence-detokenized": "Various methods were developed in the 1980s and early 1990s by Werbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Pearlmutter and others.", "token2charspan": [[0, 7], [8, 15], [16, 20], [21, 30], [31, 33], [34, 37], [38, 43], [44, 47], [48, 53], [54, 59], [60, 62], [63, 69], [69, 70], [71, 79], [79, 80], [81, 89], [89, 90], [91, 97], [98, 109], [109, 110], [111, 115], [116, 126], [126, 127], [128, 139], [140, 143], [144, 150], [150, 151]]}
{"doc_key": "ai-test-352", "ner": [[1, 1, "organisation"], [2, 3, "organisation"], [7, 9, "organisation"], [16, 17, "task"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 7, 9, "role", "licenses_from", false, false], [2, 3, 1, 1, "named", "", false, false], [15, 15, 1, 1, "origin", "", false, false], [15, 15, 16, 17, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["|", "Apple", "Apple", "Inc", "originally", "licensed", "software", "from", "Nuance", "to", "provide", "its", "digital", "assistant", "with", "Siri", "speech", "recognition", "capabilities", "."], "sentence-detokenized": "| Apple Apple Inc originally licensed software from Nuance to provide its digital assistant with Siri speech recognition capabilities.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 17], [18, 28], [29, 37], [38, 46], [47, 51], [52, 58], [59, 61], [62, 69], [70, 73], [74, 81], [82, 91], [92, 96], [97, 101], [102, 108], [109, 120], [121, 133], [133, 134]]}
{"doc_key": "ai-test-353", "ner": [[0, 0, "organisation"], [3, 4, "misc"], [7, 8, "person"], [12, 13, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 4, "role", "releases_movies_in_genre", false, false], [7, 8, 0, 0, "role", "directs_for", false, false], [12, 13, 0, 0, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "released", "several", "3D", "westerns", "produced", "by", "Sam", "Katzman", "and", "directed", "by", "William", "Castle", "."], "sentence-detokenized": "Columbia released several 3D westerns produced by Sam Katzman and directed by William Castle.", "token2charspan": [[0, 8], [9, 17], [18, 25], [26, 28], [29, 37], [38, 46], [47, 49], [50, 53], [54, 61], [62, 65], [66, 74], [75, 77], [78, 85], [86, 92], [92, 93]]}
{"doc_key": "ai-test-354", "ner": [[6, 7, "field"], [9, 9, "field"], [11, 11, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "includes", "expertise", "and", "research", "in", "computer", "science", ",", "linguistics", "and", "computing", "."], "sentence-detokenized": "This includes expertise and research in computer science, linguistics and computing.", "token2charspan": [[0, 4], [5, 13], [14, 23], [24, 27], [28, 36], [37, 39], [40, 48], [49, 56], [56, 57], [58, 69], [70, 73], [74, 83], [83, 84]]}
{"doc_key": "ai-test-355", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", "is", "an", "example", "of", "R-", "code", ":"], "sentence-detokenized": "Here is an example of R-code:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 24], [24, 28], [28, 29]]}
{"doc_key": "ai-test-356", "ner": [[0, 2, "metrics"], [9, 9, "metrics"], [8, 12, "metrics"], [16, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[0, 2, 9, 9, "part-of", "plotted_into", false, false], [8, 12, 9, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["The", "ROC", "curve", "is", "generated", "by", "comparing", "the", "True", "Positive", "Rate", "(", "TPR", ")", "and", "the", "False", "Positive", "Rate", "(", "FPR", ")", "at", "different", "threshold", "values", "."], "sentence-detokenized": "The ROC curve is generated by comparing the True Positive Rate (TPR) and the False Positive Rate (FPR) at different threshold values.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 26], [27, 29], [30, 39], [40, 43], [44, 48], [49, 57], [58, 62], [63, 64], [64, 67], [67, 68], [69, 72], [73, 76], [77, 82], [83, 91], [92, 96], [97, 98], [98, 101], [101, 102], [103, 105], [106, 115], [116, 125], [126, 132], [132, 133]]}
{"doc_key": "ai-test-357", "ner": [[1, 4, "field"], [5, 6, "researcher"], [8, 9, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 1, 4, "related-to", "researches_field", false, false], [8, 9, 1, 4, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["After", "machine", "learning", "studies", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", ",", "research", "stalled", ","], "sentence-detokenized": "After machine learning studies by Marvin Minsky and Seymour Papert (1969), research stalled,", "token2charspan": [[0, 5], [6, 13], [14, 22], [23, 30], [31, 33], [34, 40], [41, 47], [48, 51], [52, 59], [60, 66], [67, 68], [68, 72], [72, 73], [73, 74], [75, 83], [84, 91], [91, 92]]}
{"doc_key": "ai-test-358", "ner": [[9, 10, "programlang"], [12, 14, "product"], [16, 17, "programlang"], [19, 19, "product"], [21, 21, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "environments", "used", "to", "build", "DAQ", "applications", "include", "Ladder", "Logic", ",", "Visual", "C", "++", ",", "Visual", "Basic", ",", "LabVIEW", "and", "MATLAB", "."], "sentence-detokenized": "Other programming environments used to build DAQ applications include Ladder Logic, Visual C++, Visual Basic, LabVIEW and MATLAB.", "token2charspan": [[0, 5], [6, 17], [18, 30], [31, 35], [36, 38], [39, 44], [45, 48], [49, 61], [62, 69], [70, 76], [77, 82], [82, 83], [84, 90], [91, 92], [92, 94], [94, 95], [96, 102], [103, 108], [108, 109], [110, 117], [118, 121], [122, 128], [128, 129]]}
{"doc_key": "ai-test-359", "ner": [[9, 15, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "method", "is", "designed", "to", "solve", "some", "of", "the", "problems", "associated", "with", "the", "popular", "BLEU", "metric", "and", "to", "achieve", "a", "good", "correlation", "with", "a", "person", "'s", "rating", "at", "the", "sentence", "or", "segment", "level", "."], "sentence-detokenized": "The method is designed to solve some of the problems associated with the popular BLEU metric and to achieve a good correlation with a person's rating at the sentence or segment level.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 22], [23, 25], [26, 31], [32, 36], [37, 39], [40, 43], [44, 52], [53, 63], [64, 68], [69, 72], [73, 80], [81, 85], [86, 92], [93, 96], [97, 99], [100, 107], [108, 109], [110, 114], [115, 126], [127, 131], [132, 133], [134, 140], [140, 142], [143, 149], [150, 152], [153, 156], [157, 165], [166, 168], [169, 176], [177, 182], [182, 183]]}
{"doc_key": "ai-test-360", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "-", "term", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "the", "semantic", "relationships", "between", "successive", "video", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and long-term short-term memory are often used to exploit the semantic relationships between successive video frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [82, 83], [83, 87], [88, 93], [93, 94], [94, 98], [99, 105], [106, 109], [110, 115], [116, 120], [121, 123], [124, 131], [132, 135], [136, 144], [145, 158], [159, 166], [167, 177], [178, 183], [184, 190], [190, 191]]}
{"doc_key": "ai-test-361", "ner": [[4, 8, "product"], [14, 20, "product"], [38, 40, "product"]], "ner_mapping_to_source": [1, 2, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "mass", "production", ",", "printed", "circuit", "boards", "(", "PCBs", ")", "are", "almost", "exclusively", "produced", "by", "pick", "-", "and", "-", "place", "robots", ",", "usually", "SCARA", "manipulators", ",", "which", "remove", "tiny", "electronic", "components", "from", "strips", "or", "trays", "and", "place", "them", "on", "PCBs", "with", "high", "precision", "."], "sentence-detokenized": "In mass production, printed circuit boards (PCBs) are almost exclusively produced by pick-and-place robots, usually SCARA manipulators, which remove tiny electronic components from strips or trays and place them on PCBs with high precision.", "token2charspan": [[0, 2], [3, 7], [8, 18], [18, 19], [20, 27], [28, 35], [36, 42], [43, 44], [44, 48], [48, 49], [50, 53], [54, 60], [61, 72], [73, 81], [82, 84], [85, 89], [89, 90], [90, 93], [93, 94], [94, 99], [100, 106], [106, 107], [108, 115], [116, 121], [122, 134], [134, 135], [136, 141], [142, 148], [149, 153], [154, 164], [165, 175], [176, 180], [181, 187], [188, 190], [191, 196], [197, 200], [201, 206], [207, 211], [212, 214], [215, 219], [220, 224], [225, 229], [230, 239], [239, 240]]}
{"doc_key": "ai-test-362", "ner": [[4, 5, "field"], [15, 15, "algorithm"], [22, 23, "researcher"], [25, 26, "researcher"], [28, 31, "researcher"], [36, 37, "algorithm"], [38, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 15, 4, 5, "part-of", "", false, false], [15, 15, 22, 23, "origin", "", false, false], [15, 15, 25, 26, "origin", "", false, false], [15, 15, 28, 31, "origin", "", false, false], [15, 15, 36, 37, "type-of", "", false, false], [36, 37, 38, 40, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "the", "context", "of", "machine", "learning", ",", "where", "it", "is", "most", "widely", "applied", "today", ",", "LDA", "was", "independently", "rediscovered", "in", "2003", "by", "David", "Blei", ",", "Andrew", "Ng", "and", "Michael", "I", ".", "Jordan", "and", "presented", "as", "a", "graphical", "model", "for", "topic", "discovery", "."], "sentence-detokenized": "In the context of machine learning, where it is most widely applied today, LDA was independently rediscovered in 2003 by David Blei, Andrew Ng and Michael I. Jordan and presented as a graphical model for topic discovery.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 25], [26, 34], [34, 35], [36, 41], [42, 44], [45, 47], [48, 52], [53, 59], [60, 67], [68, 73], [73, 74], [75, 78], [79, 82], [83, 96], [97, 109], [110, 112], [113, 117], [118, 120], [121, 126], [127, 131], [131, 132], [133, 139], [140, 142], [143, 146], [147, 154], [155, 156], [156, 157], [158, 164], [165, 168], [169, 178], [179, 181], [182, 183], [184, 193], [194, 199], [200, 203], [204, 209], [210, 219], [219, 220]]}
{"doc_key": "ai-test-363", "ner": [[2, 2, "task"], [7, 7, "misc"], [9, 9, "metrics"], [11, 11, "metrics"], [13, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 7, 7, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["Eight", "na\u00efve", "WSI", "test", "scores", "for", "different", "tauopathies", "measured", "recall", ",", "accuracy", "and", "F1", "-", "score", "of", "0.92", ",", "0.72", "and", "0.81", ",", "respectively", "."], "sentence-detokenized": "Eight na\u00efve WSI test scores for different tauopathies measured recall, accuracy and F1-score of 0.92, 0.72 and 0.81, respectively.", "token2charspan": [[0, 5], [6, 11], [12, 15], [16, 20], [21, 27], [28, 31], [32, 41], [42, 53], [54, 62], [63, 69], [69, 70], [71, 79], [80, 83], [84, 86], [86, 87], [87, 92], [93, 95], [96, 100], [100, 101], [102, 106], [107, 110], [111, 115], [115, 116], [117, 129], [129, 130]]}
{"doc_key": "ai-test-364", "ner": [[6, 7, "field"], [16, 17, "task"]], "ner_mapping_to_source": [1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Advanced", "AR", "technologies", "(", "e.g.", "adding", "computer", "vision", ",", "adding", "AR", "cameras", "to", "the", "smartphone", "and", "object", "recognition", ")", "transform", "information", "about", "the", "real", "world", "around", "the", "user", "into", "interactive", "and", "digitally", "manipulable", "information", "."], "sentence-detokenized": "Advanced AR technologies (e.g. adding computer vision, adding AR cameras to the smartphone and object recognition) transform information about the real world around the user into interactive and digitally manipulable information.", "token2charspan": [[0, 8], [9, 11], [12, 24], [25, 26], [26, 30], [31, 37], [38, 46], [47, 53], [53, 54], [55, 61], [62, 64], [65, 72], [73, 75], [76, 79], [80, 90], [91, 94], [95, 101], [102, 113], [113, 114], [115, 124], [125, 136], [137, 142], [143, 146], [147, 151], [152, 157], [158, 164], [165, 168], [169, 173], [174, 178], [179, 190], [191, 194], [195, 204], [205, 216], [217, 228], [228, 229]]}
{"doc_key": "ai-test-365", "ner": [[3, 3, "researcher"], [5, 5, "organisation"], [12, 14, "field"], [23, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 5, 5, "role", "forms_company", false, false], [5, 5, 12, 14, "related-to", "works_with", false, false], [5, 5, 23, 25, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2014", ",", "Schmidhuber", "founded", "Nnaisense", "to", "work", "on", "commercial", "applications", "of", "artificial", "intelligence", "in", "areas", "such", "as", "finance", ",", "heavy", "industry", "and", "self", "-", "driving", "cars", "."], "sentence-detokenized": "In 2014, Schmidhuber founded Nnaisense to work on commercial applications of artificial intelligence in areas such as finance, heavy industry and self-driving cars.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 28], [29, 38], [39, 41], [42, 46], [47, 49], [50, 60], [61, 73], [74, 76], [77, 87], [88, 100], [101, 103], [104, 109], [110, 114], [115, 117], [118, 125], [125, 126], [127, 132], [133, 141], [142, 145], [146, 150], [150, 151], [151, 158], [159, 163], [163, 164]]}
{"doc_key": "ai-test-366", "ner": [[27, 31, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Not", "only", "does", "this", "change", "the", "performance", "of", "all", "subsequent", "tests", "on", "the", "retained", "explanatory", "model", ",", "but", "it", "can", "also", "lead", "to", "outliers", "and", "change", "the", "mean", "squared", "error", "of", "the", "estimate", "."], "sentence-detokenized": "Not only does this change the performance of all subsequent tests on the retained explanatory model, but it can also lead to outliers and change the mean squared error of the estimate.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 18], [19, 25], [26, 29], [30, 41], [42, 44], [45, 48], [49, 59], [60, 65], [66, 68], [69, 72], [73, 81], [82, 93], [94, 99], [99, 100], [101, 104], [105, 107], [108, 111], [112, 116], [117, 121], [122, 124], [125, 133], [134, 137], [138, 144], [145, 148], [149, 153], [154, 161], [162, 167], [168, 170], [171, 174], [175, 183], [183, 184]]}
{"doc_key": "ai-test-367", "ner": [[0, 0, "misc"], [7, 8, "task"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Bigrams", "are", "used", "in", "the", "most", "successful", "speech", "recognition", "language", "models", "."], "sentence-detokenized": "Bigrams are used in the most successful speech recognition language models.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 19], [20, 23], [24, 28], [29, 39], [40, 46], [47, 58], [59, 67], [68, 74], [74, 75]]}
{"doc_key": "ai-test-368", "ner": [[3, 6, "field"], [13, 15, "misc"], [21, 23, "misc"], [9, 12, "organisation"], [34, 36, "misc"], [29, 32, "organisation"], [46, 48, "misc"], [42, 45, "organisation"], [58, 60, "misc"], [54, 57, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[13, 15, 3, 6, "topic", "", false, false], [21, 23, 9, 12, "origin", "", false, false], [34, 36, 29, 32, "origin", "", false, false], [46, 48, 42, 45, "origin", "", false, false], [58, 60, 54, 57, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["His", "research", "in", "cognitive", "psychology", "has", "been", "awarded", "the", "American", "Psychological", "Association", "'s", "Early", "Career", "Award", "(", "1984", ")", "and", "the", "Boyd", "McCandless", "Prize", "(", "1986", ")", ",", "the", "National", "Academy", "of", "Sciences", "'", "Troland", "Research", "Award", "(", "1993", ")", ",", "the", "Royal", "British", "Institute", "'s", "Henry", "Dale", "Prize", "(", "2004", ")", "and", "the", "Cognitive", "Neuroscience", "Society", "'s", "George", "Miller", "Prize", "(", "2010", ")", "."], "sentence-detokenized": "His research in cognitive psychology has been awarded the American Psychological Association's Early Career Award (1984) and the Boyd McCandless Prize (1986), the National Academy of Sciences' Troland Research Award (1993), the Royal British Institute's Henry Dale Prize (2004) and the Cognitive Neuroscience Society's George Miller Prize (2010).", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 25], [26, 36], [37, 40], [41, 45], [46, 53], [54, 57], [58, 66], [67, 80], [81, 92], [92, 94], [95, 100], [101, 107], [108, 113], [114, 115], [115, 119], [119, 120], [121, 124], [125, 128], [129, 133], [134, 144], [145, 150], [151, 152], [152, 156], [156, 157], [157, 158], [159, 162], [163, 171], [172, 179], [180, 182], [183, 191], [191, 192], [193, 200], [201, 209], [210, 215], [216, 217], [217, 221], [221, 222], [222, 223], [224, 227], [228, 233], [234, 241], [242, 251], [251, 253], [254, 259], [260, 264], [265, 270], [271, 272], [272, 276], [276, 277], [278, 281], [282, 285], [286, 295], [296, 308], [309, 316], [316, 318], [319, 325], [326, 332], [333, 338], [339, 340], [340, 344], [344, 345], [345, 346]]}
{"doc_key": "ai-test-369", "ner": [[0, 0, "misc"], [4, 4, "researcher"], [6, 6, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [18, 20, "task"], [23, 26, "researcher"], [28, 32, "researcher"], [33, 34, "task"], [36, 36, "misc"]], "ner_mapping_to_source": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[0, 0, 4, 4, "origin", "", false, false], [0, 0, 6, 6, "origin", "", false, false], [0, 0, 18, 20, "related-to", "used_for", false, false], [13, 14, 0, 0, "usage", "", false, false], [13, 14, 23, 26, "named", "same", false, false], [16, 17, 0, 0, "usage", "", false, false], [16, 17, 28, 32, "named", "same", false, false], [33, 34, 36, 36, "usage", "", false, false]], "relations_mapping_to_source": [2, 3, 4, 7, 8, 9, 10, 11], "sentence": ["Peculiarity", "(", "developed", "by", "Sirovich", "and", "Kirby", "(", "1987", ")", "and", "used", "by", "Matthew", "Turk", "and", "Alex", "Pentland", "for", "face", "classification", ")", ".", "Turk", ",", "Matthew", "A", "and", "Pentland", ",", "Alex", "P", ".", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "Peculiarity (developed by Sirovich and Kirby (1987) and used by Matthew Turk and Alex Pentland for face classification). Turk, Matthew A and Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 11], [12, 13], [13, 22], [23, 25], [26, 34], [35, 38], [39, 44], [45, 46], [46, 50], [50, 51], [52, 55], [56, 60], [61, 63], [64, 71], [72, 76], [77, 80], [81, 85], [86, 94], [95, 98], [99, 103], [104, 118], [118, 119], [119, 120], [121, 125], [125, 126], [127, 134], [135, 136], [137, 140], [141, 149], [149, 150], [151, 155], [156, 157], [157, 158], [159, 163], [164, 175], [176, 181], [182, 192], [192, 193]]}
{"doc_key": "ai-test-370", "ner": [[6, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "lexical", "dictionary", ",", "such", "as", "WordNet", ",", "can", "then", "be", "used", "to", "understand", "the", "context", "."], "sentence-detokenized": "A lexical dictionary, such as WordNet, can then be used to understand the context.", "token2charspan": [[0, 1], [2, 9], [10, 20], [20, 21], [22, 26], [27, 29], [30, 37], [37, 38], [39, 42], [43, 47], [48, 50], [51, 55], [56, 58], [59, 69], [70, 73], [74, 81], [81, 82]]}
{"doc_key": "ai-test-371", "ner": [[0, 0, "misc"], [8, 8, "misc"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 8, "part-of", "", false, false], [8, 8, 15, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hyponymy", "is", "the", "most", "commonly", "coded", "association", "between", "synsets", "used", "in", "lexical", "databases", "such", "as", "WordNet", "."], "sentence-detokenized": "Hyponymy is the most commonly coded association between synsets used in lexical databases such as WordNet.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 20], [21, 29], [30, 35], [36, 47], [48, 55], [56, 63], [64, 68], [69, 71], [72, 79], [80, 89], [90, 94], [95, 97], [98, 105], [105, 106]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [7, 8, "programlang"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 7, 8, "general-affiliation", "", false, false], [0, 0, 10, 10, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "provides", "open", "-", "source", "libraries", "in", "C", "++", "and", "Java", ",", "but", "many", "customers", "rely", "on", "community", "-", "developed", "libraries", ",", "such", "as", "libraries", "that", "include", "built", "-", "in", "facilities", "(", "array", "-", "type", ")", "for", "retrieving", "data", "from", "DAP", "servers", "."], "sentence-detokenized": "OPeNDAP provides open-source libraries in C++ and Java, but many customers rely on community-developed libraries, such as libraries that include built-in facilities (array-type) for retrieving data from DAP servers.", "token2charspan": [[0, 7], [8, 16], [17, 21], [21, 22], [22, 28], [29, 38], [39, 41], [42, 43], [43, 45], [46, 49], [50, 54], [54, 55], [56, 59], [60, 64], [65, 74], [75, 79], [80, 82], [83, 92], [92, 93], [93, 102], [103, 112], [112, 113], [114, 118], [119, 121], [122, 131], [132, 136], [137, 144], [145, 150], [150, 151], [151, 153], [154, 164], [165, 166], [166, 171], [171, 172], [172, 176], [176, 177], [178, 181], [182, 192], [193, 197], [198, 202], [203, 206], [207, 214], [214, 215]]}
{"doc_key": "ai-test-373", "ner": [[4, 5, "misc"], [7, 7, "product"], [28, 30, "misc"], [41, 41, "organisation"], [42, 42, "product"], [45, 49, "product"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 7], "relations": [[28, 30, 7, 7, "part-of", "", false, false], [42, 42, 41, 41, "artifact", "", false, false]], "relations_mapping_to_source": [2, 3], "sentence": ["On", "this", "page", ",", "Samurai", "Damashii", "exaggerated", "Senkousha", "as", "a", "crystallization", "of", "four", "thousand", "years", "of", "Chinese", "scientific", "knowledge", ",", "commented", "on", "its", "crude", "design", "(", "e.g.", ",", "the", "Chinese", "cannon", "at", "its", "foot", ")", ",", "and", "juxtaposed", "its", "image", "between", "Honda", "ASIMO", "and", "Sony", "QRIO", "SDR", "-", "3", "X", "images", "for", "comparison", "."], "sentence-detokenized": "On this page, Samurai Damashii exaggerated Senkousha as a crystallization of four thousand years of Chinese scientific knowledge, commented on its crude design (e.g., the Chinese cannon at its foot), and juxtaposed its image between Honda ASIMO and Sony QRIO SDR-3X images for comparison.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 21], [22, 30], [31, 42], [43, 52], [53, 55], [56, 57], [58, 73], [74, 76], [77, 81], [82, 90], [91, 96], [97, 99], [100, 107], [108, 118], [119, 128], [128, 129], [130, 139], [140, 142], [143, 146], [147, 152], [153, 159], [160, 161], [161, 165], [165, 166], [167, 170], [171, 178], [179, 185], [186, 188], [189, 192], [193, 197], [197, 198], [198, 199], [200, 203], [204, 214], [215, 218], [219, 224], [225, 232], [233, 238], [239, 244], [245, 248], [249, 253], [254, 258], [259, 262], [262, 263], [263, 264], [264, 265], [266, 272], [273, 276], [277, 287], [287, 288]]}
{"doc_key": "ai-test-374", "ner": [[8, 9, "algorithm"], [20, 20, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 20, 20, "part-of", "includes_functionality_of", false, false], [8, 9, 22, 22, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "also", "many", "programming", "libraries", "that", "include", "neural", "network", "functionality", "and", "can", "be", "used", "in", "customised", "applications", "(", "e.g.", "TensorFlow", ",", "Theano", ",", "etc.", ")", "."], "sentence-detokenized": "There are also many programming libraries that include neural network functionality and can be used in customised applications (e.g. TensorFlow, Theano, etc.).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 19], [20, 31], [32, 41], [42, 46], [47, 54], [55, 61], [62, 69], [70, 83], [84, 87], [88, 91], [92, 94], [95, 99], [100, 102], [103, 113], [114, 126], [127, 128], [128, 132], [133, 143], [143, 144], [145, 151], [151, 152], [153, 157], [157, 158], [158, 159]]}
{"doc_key": "ai-test-375", "ner": [[0, 9, "conference"], [12, 12, "organisation"], [15, 21, "conference"], [23, 23, "conference"], [25, 25, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", ",", "the", "IEEE", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "IAPR", "and", "SPIE", "."], "sentence-detokenized": "He is a member of the Association for Computing Machinery, the IEEE, the American Association for the Advancement of Science, IAPR and SPIE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 33], [34, 37], [38, 47], [48, 57], [57, 58], [59, 62], [63, 67], [67, 68], [69, 72], [73, 81], [82, 93], [94, 97], [98, 101], [102, 113], [114, 116], [117, 124], [124, 125], [126, 130], [131, 134], [135, 139], [139, 140]]}
{"doc_key": "ai-test-376", "ner": [[5, 7, "organisation"], [11, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 11, 12, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "test", "carried", "out", "by", "the", "RET", "in", "2011", "to", "install", "facial", "recognition", "cameras", "on", "trams", "ensured", "that", "people", "who", "were", "banned", "from", "using", "the", "city", "'s", "trams", "did", "not", "sneak", "on", "."], "sentence-detokenized": "A test carried out by the RET in 2011 to install facial recognition cameras on trams ensured that people who were banned from using the city's trams did not sneak on.", "token2charspan": [[0, 1], [2, 6], [7, 14], [15, 18], [19, 21], [22, 25], [26, 29], [30, 32], [33, 37], [38, 40], [41, 48], [49, 55], [56, 67], [68, 75], [76, 78], [79, 84], [85, 92], [93, 97], [98, 104], [105, 108], [109, 113], [114, 120], [121, 125], [126, 131], [132, 135], [136, 140], [140, 142], [143, 148], [149, 152], [153, 156], [157, 162], [163, 165], [165, 166]]}
{"doc_key": "ai-test-377", "ner": [[2, 4, "person"], [18, 19, "person"], [21, 22, "person"], [26, 27, "person"], [29, 30, "person"], [32, 33, "person"], [35, 36, "person"], [38, 39, "person"], [41, 42, "person"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [], "relations_mapping_to_source": [], "sentence": ["Adapted", "from", "Cole", "Porter", "'s", "popular", "Broadway", "musical", ",", "the", "film", "starred", "MGM", "'s", "Song", "Festival", "team", "of", "Howard", "Keel", "and", "Kathryn", "Grayson", ",", "supported", "by", "Ann", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Van", ",", "James", "Whitmore", ",", "Kurt", "Kasznar", "and", "Tommy", "Rall", "."], "sentence-detokenized": "Adapted from Cole Porter's popular Broadway musical, the film starred MGM's Song Festival team of Howard Keel and Kathryn Grayson, supported by Ann Miller, Keenan Wynn, Bobby Van, James Whitmore, Kurt Kasznar and Tommy Rall.", "token2charspan": [[0, 7], [8, 12], [13, 17], [18, 24], [24, 26], [27, 34], [35, 43], [44, 51], [51, 52], [53, 56], [57, 61], [62, 69], [70, 73], [73, 75], [76, 80], [81, 89], [90, 94], [95, 97], [98, 104], [105, 109], [110, 113], [114, 121], [122, 129], [129, 130], [131, 140], [141, 143], [144, 147], [148, 154], [154, 155], [156, 162], [163, 167], [167, 168], [169, 174], [175, 178], [178, 179], [180, 185], [186, 194], [194, 195], [196, 200], [201, 208], [209, 212], [213, 218], [219, 223], [223, 224]]}
{"doc_key": "ai-test-378", "ner": [[17, 20, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "applications", "should", "simplify", "call", "flows", ",", "minimise", "prompts", ",", "eliminate", "unnecessary", "repetition", "and", "enable", "a", "sophisticated", "mixed-initiative", "dialogue", "system", "that", "allows", "callers", "to", "enter", "multiple", "pieces", "of", "information", "in", "a", "single", "utterance", "and", "in", "any", "order", "or", "combination", "."], "sentence-detokenized": "Such applications should simplify call flows, minimise prompts, eliminate unnecessary repetition and enable a sophisticated mixed-initiative dialogue system that allows callers to enter multiple pieces of information in a single utterance and in any order or combination.", "token2charspan": [[0, 4], [5, 17], [18, 24], [25, 33], [34, 38], [39, 44], [44, 45], [46, 54], [55, 62], [62, 63], [64, 73], [74, 85], [86, 96], [97, 100], [101, 107], [108, 109], [110, 123], [124, 140], [141, 149], [150, 156], [157, 161], [162, 168], [169, 176], [177, 179], [180, 185], [186, 194], [195, 201], [202, 204], [205, 216], [217, 219], [220, 221], [222, 228], [229, 238], [239, 242], [243, 245], [246, 249], [250, 255], [256, 258], [259, 270], [270, 271]]}
{"doc_key": "ai-test-379", "ner": [[3, 4, "algorithm"], [7, 9, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 9, 3, 4, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Thus", ",", "traditional", "gradient", "descent", "(", "or", "stochastic", "gradient", "descent", ")", "methods", "can", "be", "adapted", ",", "where", "instead", "of", "stepping", "in", "the", "direction", "of", "the", "gradient", "of", "a", "function", ",", "one", "steps", "in", "the", "direction", "of", "a", "vector", "chosen", "from", "among", "the", "subgradients", "of", "the", "function", "."], "sentence-detokenized": "Thus, traditional gradient descent (or stochastic gradient descent) methods can be adapted, where instead of stepping in the direction of the gradient of a function, one steps in the direction of a vector chosen from among the subgradients of the function.", "token2charspan": [[0, 4], [4, 5], [6, 17], [18, 26], [27, 34], [35, 36], [36, 38], [39, 49], [50, 58], [59, 66], [66, 67], [68, 75], [76, 79], [80, 82], [83, 90], [90, 91], [92, 97], [98, 105], [106, 108], [109, 117], [118, 120], [121, 124], [125, 134], [135, 137], [138, 141], [142, 150], [151, 153], [154, 155], [156, 164], [164, 165], [166, 169], [170, 175], [176, 178], [179, 182], [183, 192], [193, 195], [196, 197], [198, 204], [205, 211], [212, 216], [217, 222], [223, 226], [227, 239], [240, 242], [243, 246], [247, 255], [255, 256]]}
{"doc_key": "ai-test-380", "ner": [[10, 13, "metrics"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Assuming", "that", "the", "distortion", "is", "measured", "in", "terms", "of", "the", "root", "mean", "square", "error", ",", "the", "distortion", "D", "is", "given", "by", ":"], "sentence-detokenized": "Assuming that the distortion is measured in terms of the root mean square error, the distortion D is given by:", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 28], [29, 31], [32, 40], [41, 43], [44, 49], [50, 52], [53, 56], [57, 61], [62, 66], [67, 73], [74, 79], [79, 80], [81, 84], [85, 95], [96, 97], [98, 100], [101, 106], [107, 109], [109, 110]]}
{"doc_key": "ai-test-381", "ner": [[0, 0, "algorithm"], [4, 6, "field"], [22, 23, "task"], [25, 26, "task"], [31, 32, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[0, 0, 4, 6, "part-of", "", false, false], [22, 23, 0, 0, "part-of", "", false, false], [25, 26, 0, 0, "part-of", "", false, false], [31, 32, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4], "sentence": ["MLPs", "were", "a", "popular", "machine", "-", "learning", "solution", "in", "the", "1980s", ",", "finding", "applications", "in", "a", "variety", "of", "fields", ",", "such", "as", "speech", "recognition", ",", "image", "recognition", "and", "machine", "learning", ",", "neural", "networks", "."], "sentence-detokenized": "MLPs were a popular machine-learning solution in the 1980s, finding applications in a variety of fields, such as speech recognition, image recognition and machine learning, neural networks.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 19], [20, 27], [27, 28], [28, 36], [37, 45], [46, 48], [49, 52], [53, 58], [58, 59], [60, 67], [68, 80], [81, 83], [84, 85], [86, 93], [94, 96], [97, 103], [103, 104], [105, 109], [110, 112], [113, 119], [120, 131], [131, 132], [133, 138], [139, 150], [151, 154], [155, 162], [163, 171], [171, 172], [173, 179], [180, 188], [188, 189]]}
{"doc_key": "ai-test-382", "ner": [[0, 0, "researcher"], [3, 5, "misc"], [6, 9, "university"], [15, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 9, "physical", "", false, false], [0, 0, 6, 9, "role", "", false, false], [3, 5, 0, 0, "origin", "", false, false], [15, 17, 0, 0, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "received", "his", "PhD", "from", "the", "University", "of", "Toronto", "in", "1979", "under", "the", "supervision", "of", "C.", "Raymond", "Perrault", ","], "sentence-detokenized": "Allen received his PhD from the University of Toronto in 1979 under the supervision of C. Raymond Perrault,", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 22], [23, 27], [28, 31], [32, 42], [43, 45], [46, 53], [54, 56], [57, 61], [62, 67], [68, 71], [72, 83], [84, 86], [87, 89], [90, 97], [98, 106], [106, 107]]}
{"doc_key": "ai-test-383", "ner": [[0, 0, "product"], [4, 7, "field"], [10, 10, "product"], [12, 12, "product"], [14, 14, "product"], [24, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6], "relations": [[0, 0, 4, 7, "related-to", "supports", false, false], [10, 10, 4, 7, "type-of", "", true, false], [12, 12, 4, 7, "type-of", "", true, false], [14, 14, 4, 7, "type-of", "", true, false], [24, 27, 4, 7, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5], "sentence": ["OpenCV", "supports", "some", "models", "from", "deep", "learning", "frameworks", "such", "as", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "after", "conversion", "to", "an", "ONNX", "model", ")", "and", "Caffe", "according", "to", "a", "defined", "list", "of", "supported", "layers", "."], "sentence-detokenized": "OpenCV supports some models from deep learning frameworks such as TensorFlow, Torch, PyTorch (after conversion to an ONNX model) and Caffe according to a defined list of supported layers.", "token2charspan": [[0, 6], [7, 15], [16, 20], [21, 27], [28, 32], [33, 37], [38, 46], [47, 57], [58, 62], [63, 65], [66, 76], [76, 77], [78, 83], [83, 84], [85, 92], [93, 94], [94, 99], [100, 110], [111, 113], [114, 116], [117, 121], [122, 127], [127, 128], [129, 132], [133, 138], [139, 148], [149, 151], [152, 153], [154, 161], [162, 166], [167, 169], [170, 179], [180, 186], [186, 187]]}
{"doc_key": "ai-test-384", "ner": [[2, 2, "researcher"], [10, 12, "organisation"], [9, 14, "organisation"], [23, 28, "organisation"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 10, 12, "role", "", false, false], [2, 2, 23, 28, "role", "", false, false], [2, 2, 21, 22, "related-to", "lectures_in", false, false], [9, 14, 10, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Previously", ",", "Christensen", "was", "a", "founding", "member", "of", "the", "European", "Robotics", "Research", "Network", "(", "EURON", ")", "and", "a", "Distinguished", "Lecturer", "in", "Robotics", "at", "the", "IEEE", "Robotics", "and", "Automation", "Society", "."], "sentence-detokenized": "Previously, Christensen was a founding member of the European Robotics Research Network (EURON) and a Distinguished Lecturer in Robotics at the IEEE Robotics and Automation Society.", "token2charspan": [[0, 10], [10, 11], [12, 23], [24, 27], [28, 29], [30, 38], [39, 45], [46, 48], [49, 52], [53, 61], [62, 70], [71, 79], [80, 87], [88, 89], [89, 94], [94, 95], [96, 99], [100, 101], [102, 115], [116, 124], [125, 127], [128, 136], [137, 139], [140, 143], [144, 148], [149, 157], [158, 161], [162, 172], [173, 180], [180, 181]]}
{"doc_key": "ai-test-385", "ner": [[6, 9, "field"], [10, 12, "university"], [13, 14, "location"], [17, 22, "country"], [25, 27, "misc"], [28, 28, "field"], [34, 36, "organisation"], [31, 31, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 12, 13, 14, "physical", "", false, false], [13, 14, 17, 22, "physical", "", false, false], [25, 27, 28, 28, "topic", "", false, false], [34, 36, 31, 31, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "obtained", "a", "master", "'s", "degree", "in", "mathematics", "from", "the", "Samarkand", "State", "University", "in", "Samarkand", ",", "the", "Soviet", "Socialist", "Republic", "of", "Uzbekistan", "in", "1958", "and", "a", "doctorate", "in", "statistics", "from", "the", "Moscow", "Institute", "of", "Control", "Sciences", "in", "1964", "."], "sentence-detokenized": "He obtained a master's degree in mathematics from the Samarkand State University in Samarkand, the Soviet Socialist Republic of Uzbekistan in 1958 and a doctorate in statistics from the Moscow Institute of Control Sciences in 1964.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 20], [20, 22], [23, 29], [30, 32], [33, 44], [45, 49], [50, 53], [54, 63], [64, 69], [70, 80], [81, 83], [84, 93], [93, 94], [95, 98], [99, 105], [106, 115], [116, 124], [125, 127], [128, 138], [139, 141], [142, 146], [147, 150], [151, 152], [153, 162], [163, 165], [166, 176], [177, 181], [182, 185], [186, 192], [193, 202], [203, 205], [206, 213], [214, 222], [223, 225], [226, 230], [230, 231]]}
{"doc_key": "ai-test-386", "ner": [[4, 5, "organisation"], [10, 12, "product"], [34, 35, "field"], [33, 39, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 34, 35, "usage", "", false, false], [4, 5, 33, 39, "usage", "", false, false], [10, 12, 4, 5, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Increasingly", ",", "however", ",", "Cycorp", "'s", "work", "involves", "giving", "the", "Cyc", "system", "the", "ability", "to", "communicate", "with", "end-users", "in", "a", "natural", "language", ",", "and", "to", "contribute", "to", "a", "continuous", "process", "of", "knowledge", "formation", "through", "machine", "learning", "and", "natural", "language", "understanding", "."], "sentence-detokenized": "Increasingly, however, Cycorp's work involves giving the Cyc system the ability to communicate with end-users in a natural language, and to contribute to a continuous process of knowledge formation through machine learning and natural language understanding.", "token2charspan": [[0, 12], [12, 13], [14, 21], [21, 22], [23, 29], [29, 31], [32, 36], [37, 45], [46, 52], [53, 56], [57, 60], [61, 67], [68, 71], [72, 79], [80, 82], [83, 94], [95, 99], [100, 109], [110, 112], [113, 114], [115, 122], [123, 131], [131, 132], [133, 136], [137, 139], [140, 150], [151, 153], [154, 155], [156, 166], [167, 174], [175, 177], [178, 187], [188, 197], [198, 205], [206, 213], [214, 222], [223, 226], [227, 234], [235, 243], [244, 257], [257, 258]]}
{"doc_key": "ai-test-387", "ner": [[53, 53, "metrics"], [55, 55, "metrics"], [57, 57, "metrics"], [59, 60, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "when", "searching", "for", "the", "most", "suitable", "classifier", "for", "a", "problem", ",", "the", "training", "dataset", "is", "used", "to", "train", "candidate", "algorithms", ",", "the", "validation", "dataset", "is", "used", "to", "compare", "their", "performance", "and", "decide", "which", "one", "to", "take", ",", "and", "finally", "the", "test", "dataset", "is", "used", "to", "obtain", "performance", "metrics", "such", "as", "accuracy", ",", "sensitivity", ",", "specificity", ",", "F-", "measure", ",", "etc", "."], "sentence-detokenized": "For example, when searching for the most suitable classifier for a problem, the training dataset is used to train candidate algorithms, the validation dataset is used to compare their performance and decide which one to take, and finally the test dataset is used to obtain performance metrics such as accuracy, sensitivity, specificity, F-measure, etc.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [18, 27], [28, 31], [32, 35], [36, 40], [41, 49], [50, 60], [61, 64], [65, 66], [67, 74], [74, 75], [76, 79], [80, 88], [89, 96], [97, 99], [100, 104], [105, 107], [108, 113], [114, 123], [124, 134], [134, 135], [136, 139], [140, 150], [151, 158], [159, 161], [162, 166], [167, 169], [170, 177], [178, 183], [184, 195], [196, 199], [200, 206], [207, 212], [213, 216], [217, 219], [220, 224], [224, 225], [226, 229], [230, 237], [238, 241], [242, 246], [247, 254], [255, 257], [258, 262], [263, 265], [266, 272], [273, 284], [285, 292], [293, 297], [298, 300], [301, 309], [309, 310], [311, 322], [322, 323], [324, 335], [335, 336], [337, 339], [339, 346], [346, 347], [348, 351], [351, 352]]}
{"doc_key": "ai-test-388", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "average", "square", "error", "is", "0.15", "."], "sentence-detokenized": "The average square error is 0.15.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 24], [25, 27], [28, 32], [32, 33]]}
{"doc_key": "ai-test-389", "ner": [[6, 11, "misc"], [4, 4, "organisation"], [14, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 6, 11, "role", "", false, false], [14, 14, 6, 11, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1979", ",", "the", "IEEE", "held", "a", "Micromouse", "competition", ",", "which", "was", "featured", "in", "Spectrum", "magazine", "."], "sentence-detokenized": "In 1979, the IEEE held a Micromouse competition, which was featured in Spectrum magazine.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 22], [23, 24], [25, 35], [36, 47], [47, 48], [49, 54], [55, 58], [59, 67], [68, 70], [71, 79], [80, 88], [88, 89]]}
{"doc_key": "ai-test-390", "ner": [[0, 2, "algorithm"], [12, 14, "task"], [16, 17, "task"], [19, 20, "task"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Gabor", "space", "is", "very", "useful", "in", "image", "processing", "applications", "such", "as", "optical", "character", "recognition", ",", "iris", "recognition", "and", "fingerprint", "recognition", "."], "sentence-detokenized": "The Gabor space is very useful in image processing applications such as optical character recognition, iris recognition and fingerprint recognition.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 18], [19, 23], [24, 30], [31, 33], [34, 39], [40, 50], [51, 63], [64, 68], [69, 71], [72, 79], [80, 89], [90, 101], [101, 102], [103, 107], [108, 119], [120, 123], [124, 135], [136, 147], [147, 148]]}
{"doc_key": "ai-test-391", "ner": [[7, 7, "programlang"], [6, 9, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", "via", "high", "-", "level", "interfaces", "to", "Java", "and", "Tcl", "."], "sentence-detokenized": "or via high-level interfaces to Java and Tcl.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [12, 17], [18, 28], [29, 31], [32, 36], [37, 40], [41, 44], [44, 45]]}
{"doc_key": "ai-test-392", "ner": [[21, 22, "field"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Recent", "studies", "have", "shown", "that", "kernel", "-", "based", "methods", ",", "such", "as", "support", "vector", "machines", ",", "have", "proven", "to", "work", "better", "under", "supervision", "."], "sentence-detokenized": "Recent studies have shown that kernel-based methods, such as support vector machines, have proven to work better under supervision.", "token2charspan": [[0, 6], [7, 14], [15, 19], [20, 25], [26, 30], [31, 37], [37, 38], [38, 43], [44, 51], [51, 52], [53, 57], [58, 60], [61, 68], [69, 75], [76, 84], [84, 85], [86, 90], [91, 97], [98, 100], [101, 105], [106, 112], [113, 118], [119, 130], [130, 131]]}
{"doc_key": "ai-test-393", "ner": [[6, 6, "misc"], [21, 21, "researcher"], [23, 23, "researcher"], [30, 31, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 21, 30, 31, "usage", "", false, false], [23, 23, 30, 31, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "analysis", "of", "the", "relationship", "between", "ozone", "and", "temperature", "is", "given", "below", "to", "illustrate", "the", "principles", "of", "fractionation", "(", "data", "from", "Rousseeuw", "and", "Leroy", "(", "1986", ")", ",", "analysis", "done", "in", "R", ")", "."], "sentence-detokenized": "An analysis of the relationship between ozone and temperature is given below to illustrate the principles of fractionation (data from Rousseeuw and Leroy (1986), analysis done in R).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 31], [32, 39], [40, 45], [46, 49], [50, 61], [62, 64], [65, 70], [71, 76], [77, 79], [80, 90], [91, 94], [95, 105], [106, 108], [109, 122], [123, 124], [124, 128], [129, 133], [134, 143], [144, 147], [148, 153], [154, 155], [155, 159], [159, 160], [160, 161], [162, 170], [171, 175], [176, 178], [179, 180], [180, 181], [181, 182]]}
{"doc_key": "ai-test-394", "ner": [[0, 1, "organisation"], [17, 18, "product"], [20, 22, "product"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[17, 18, 0, 1, "artifact", "", false, false], [20, 22, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["Denso", "Wave", "is", "a", "subsidiary", "manufacturing", "automatic", "identification", "products", "(", "barcode", "readers", "and", "related", "products", ")", ",", "industrial", "robots", "and", "programmable", "logic", "controllers", "."], "sentence-detokenized": "Denso Wave is a subsidiary manufacturing automatic identification products (barcode readers and related products), industrial robots and programmable logic controllers.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 15], [16, 26], [27, 40], [41, 50], [51, 65], [66, 74], [75, 76], [76, 83], [84, 91], [92, 95], [96, 103], [104, 112], [112, 113], [113, 114], [115, 125], [126, 132], [133, 136], [137, 149], [150, 155], [156, 167], [167, 168]]}
{"doc_key": "ai-test-395", "ner": [[1, 5, "metrics"], [8, 10, "metrics"], [22, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 5, 22, 22, "compare", "", false, false], [8, 10, 1, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["While", "the", "bilingual", "evaluation", "sub", "-award", "simply", "calculates", "the", "accuracy", "of", "the", "n-", "grams", "by", "adding", "an", "equal", "weight", "to", "each", ",", "NIST", "also", "calculates", "how", "informative", "a", "particular", "n-", "gram", "is", "."], "sentence-detokenized": "While the bilingual evaluation sub-award simply calculates the accuracy of the n-grams by adding an equal weight to each, NIST also calculates how informative a particular n-gram is.", "token2charspan": [[0, 5], [6, 9], [10, 19], [20, 30], [31, 34], [34, 40], [41, 47], [48, 58], [59, 62], [63, 71], [72, 74], [75, 78], [79, 81], [81, 86], [87, 89], [90, 96], [97, 99], [100, 105], [106, 112], [113, 115], [116, 120], [120, 121], [122, 126], [127, 131], [132, 142], [143, 146], [147, 158], [159, 160], [161, 171], [172, 174], [174, 178], [179, 181], [181, 182]]}
{"doc_key": "ai-test-396", "ner": [[11, 11, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "particular", ",", "they", "are", "used", "in", "tree", "likelihood", "calculations", "(", "Bayesian", "and", "maximum", "likelihood", "methods", "for", "tree", "estimation", ")", "and", "are", "used", "to", "estimate", "the", "evolutionary", "distance", "between", "sequences", "based", "on", "observed", "differences", "between", "sequences", "."], "sentence-detokenized": "In particular, they are used in tree likelihood calculations (Bayesian and maximum likelihood methods for tree estimation) and are used to estimate the evolutionary distance between sequences based on observed differences between sequences.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 19], [20, 23], [24, 28], [29, 31], [32, 36], [37, 47], [48, 60], [61, 62], [62, 70], [71, 74], [75, 82], [83, 93], [94, 101], [102, 105], [106, 110], [111, 121], [121, 122], [123, 126], [127, 130], [131, 135], [136, 138], [139, 147], [148, 151], [152, 164], [165, 173], [174, 181], [182, 191], [192, 197], [198, 200], [201, 209], [210, 221], [222, 229], [230, 239], [239, 240]]}
{"doc_key": "ai-test-397", "ner": [[1, 3, "conference"], [19, 20, "misc"], [22, 22, "misc"], [40, 46, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 19, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Audio", "Engineering", "Society", "recommends", "a", "48", "kHz", "sampling", "rate", "for", "most", "applications", ",", "but", "recognises", "44.1", "kHz", "for", "Compact", "Disc", "(", "CD", ")", "and", "other", "consumer", "applications", ",", "32", "kHz", "for", "transmission", "-", "related", "applications", ",", "and", "96", "kHz", "for", "higher", "bandwidth", "or", "relaxed", "anti-aliasing", "filters", "."], "sentence-detokenized": "The Audio Engineering Society recommends a 48 kHz sampling rate for most applications, but recognises 44.1 kHz for Compact Disc (CD) and other consumer applications, 32 kHz for transmission-related applications, and 96 kHz for higher bandwidth or relaxed anti-aliasing filters.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 29], [30, 40], [41, 42], [43, 45], [46, 49], [50, 58], [59, 63], [64, 67], [68, 72], [73, 85], [85, 86], [87, 90], [91, 101], [102, 106], [107, 110], [111, 114], [115, 122], [123, 127], [128, 129], [129, 131], [131, 132], [133, 136], [137, 142], [143, 151], [152, 164], [164, 165], [166, 168], [169, 172], [173, 176], [177, 189], [189, 190], [190, 197], [198, 210], [210, 211], [212, 215], [216, 218], [219, 222], [223, 226], [227, 233], [234, 243], [244, 246], [247, 254], [255, 268], [269, 276], [276, 277]]}
{"doc_key": "ai-test-398", "ner": [[5, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Resources", "have", "been", "made", "for", "Word", "Net", "on", "the", "affectivity", "of", "words", "and", "concepts", "{", "{", "cite", "journal"], "sentence-detokenized": "Resources have been made for WordNet on the affectivity of words and concepts {{cite journal", "token2charspan": [[0, 9], [10, 14], [15, 19], [20, 24], [25, 28], [29, 33], [33, 36], [37, 39], [40, 43], [44, 55], [56, 58], [59, 64], [65, 68], [69, 77], [78, 79], [79, 80], [80, 84], [85, 92]]}
{"doc_key": "ai-test-399", "ner": [[0, 7, "misc"], [24, 25, "person"], [31, 36, "person"], [41, 43, "person"], [47, 50, "organisation"], [70, 72, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[31, 36, 41, 43, "role", "acts_in", false, false], [47, 50, 41, 43, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "a", "reddish", "-", "green", "anaglyph", ",", "the", "audience", "was", "presented", "with", "three", "reels", "of", "tests", ",", "which", "included", "scenes", "from", "the", "countryside", ",", "Marie", "Doro", "rehearsal", "footage", ",", "part", "of", "John", "B", ".", "Mason", ",", "who", "played", "several", "excerpts", "from", "Jim", "the", "Penman", "(", "a", "film", "Famous", "Players", "-", "Lasky", "released", "the", "same", "year", ",", "but", "not", "in", "3D", ")", ",", "oriental", "dancers", ",", "and", "a", "reel", "of", "footage", "of", "Niagara", "Falls", "."], "sentence-detokenized": "In a reddish-green anaglyph, the audience was presented with three reels of tests, which included scenes from the countryside, Marie Doro rehearsal footage, part of John B. Mason, who played several excerpts from Jim the Penman (a film Famous Players-Lasky released the same year, but not in 3D), oriental dancers, and a reel of footage of Niagara Falls.", "token2charspan": [[0, 2], [3, 4], [5, 12], [12, 13], [13, 18], [19, 27], [27, 28], [29, 32], [33, 41], [42, 45], [46, 55], [56, 60], [61, 66], [67, 72], [73, 75], [76, 81], [81, 82], [83, 88], [89, 97], [98, 104], [105, 109], [110, 113], [114, 125], [125, 126], [127, 132], [133, 137], [138, 147], [148, 155], [155, 156], [157, 161], [162, 164], [165, 169], [170, 171], [171, 172], [173, 178], [178, 179], [180, 183], [184, 190], [191, 198], [199, 207], [208, 212], [213, 216], [217, 220], [221, 227], [228, 229], [229, 230], [231, 235], [236, 242], [243, 250], [250, 251], [251, 256], [257, 265], [266, 269], [270, 274], [275, 279], [279, 280], [281, 284], [285, 288], [289, 291], [292, 294], [294, 295], [295, 296], [297, 305], [306, 313], [313, 314], [315, 318], [319, 320], [321, 325], [326, 328], [329, 336], [337, 339], [340, 347], [348, 353], [353, 354]]}
{"doc_key": "ai-test-400", "ner": [[8, 11, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "concrete", "way", "to", "implement", "the", "maximum", "likelihood", "assessment", "of", "this", "problem", "."], "sentence-detokenized": "This is a concrete way to implement the maximum likelihood assessment of this problem.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 18], [19, 22], [23, 25], [26, 35], [36, 39], [40, 47], [48, 58], [59, 69], [70, 72], [73, 77], [78, 85], [85, 86]]}
{"doc_key": "ai-test-401", "ner": [[0, 4, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["crawler", "-", "compatible", "web", "servers", ",", "and", "integrates", "sitemap", "and", "RSS", "-", "feed", "functionality", "into", "a", "decentralised", "mechanism", "that", "allows", "computational", "biologists", "and", "bioinformaticians", "to", "publicly", "communicate", "and", "retrieve", "metadata", "about", "biomedical", "resources", "."], "sentence-detokenized": "crawler-compatible web servers, and integrates sitemap and RSS-feed functionality into a decentralised mechanism that allows computational biologists and bioinformaticians to publicly communicate and retrieve metadata about biomedical resources.", "token2charspan": [[0, 7], [7, 8], [8, 18], [19, 22], [23, 30], [30, 31], [32, 35], [36, 46], [47, 54], [55, 58], [59, 62], [62, 63], [63, 67], [68, 81], [82, 86], [87, 88], [89, 102], [103, 112], [113, 117], [118, 124], [125, 138], [139, 149], [150, 153], [154, 171], [172, 174], [175, 183], [184, 195], [196, 199], [200, 208], [209, 217], [218, 223], [224, 234], [235, 244], [244, 245]]}
{"doc_key": "ai-test-402", "ner": [[4, 12, "misc"], [15, 20, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "covered", "by", "the", "American", "National", "Standards", "Institute", "/", "NISO", "standard", "Z39.50", "and", "the", "International", "Organization", "for", "Standardization", "standard", "23950", "."], "sentence-detokenized": "It is covered by the American National Standards Institute/NISO standard Z39.50 and the International Organization for Standardization standard 23950.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 20], [21, 29], [30, 38], [39, 48], [49, 58], [58, 59], [59, 63], [64, 72], [73, 79], [80, 83], [84, 87], [88, 101], [102, 114], [115, 118], [119, 134], [135, 143], [144, 149], [149, 150]]}
{"doc_key": "ai-test-403", "ner": [[17, 19, "misc"], [22, 22, "metrics"], [27, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "encoder", "and", "decoder", "are", "trained", "to", "take", "a", "phrase", "and", "reproduce", "the", "corresponding", "paraphrase", "from", "a", "single", "hot", "distribution", ",", "minimizing", "perplexity", ",", "using", "a", "simple", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The encoder and decoder are trained to take a phrase and reproduce the corresponding paraphrase from a single hot distribution, minimizing perplexity, using a simple stochastic gradient descent.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 27], [28, 35], [36, 38], [39, 43], [44, 45], [46, 52], [53, 56], [57, 66], [67, 70], [71, 84], [85, 95], [96, 100], [101, 102], [103, 109], [110, 113], [114, 126], [126, 127], [128, 138], [139, 149], [149, 150], [151, 156], [157, 158], [159, 165], [166, 176], [177, 185], [186, 193], [193, 194]]}
{"doc_key": "ai-test-404", "ner": [[8, 10, "task"], [12, 16, "task"], [26, 30, "task"], [32, 38, "task"], [40, 45, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "typical", "applications", "of", "pattern", "recognition", "techniques", "are", "automatic", "speech", "recognition", ",", "text", "classification", "into", "multiple", "categories", "(", "e.g.", "spam", "/", "non", "-spam", "messages", ")", ",", "handwriting", "recognition", "on", "mail", "envelopes", ",", "automatic", "recognition", "of", "people", "'s", "facial", "features", "or", "extraction", "of", "handwriting", "from", "medical", "forms", "."], "sentence-detokenized": "Other typical applications of pattern recognition techniques are automatic speech recognition, text classification into multiple categories (e.g. spam/non-spam messages), handwriting recognition on mail envelopes, automatic recognition of people's facial features or extraction of handwriting from medical forms.", "token2charspan": [[0, 5], [6, 13], [14, 26], [27, 29], [30, 37], [38, 49], [50, 60], [61, 64], [65, 74], [75, 81], [82, 93], [93, 94], [95, 99], [100, 114], [115, 119], [120, 128], [129, 139], [140, 141], [141, 145], [146, 150], [150, 151], [151, 154], [154, 159], [160, 168], [168, 169], [169, 170], [171, 182], [183, 194], [195, 197], [198, 202], [203, 212], [212, 213], [214, 223], [224, 235], [236, 238], [239, 245], [245, 247], [248, 254], [255, 263], [264, 266], [267, 277], [278, 280], [281, 292], [293, 297], [298, 305], [306, 311], [311, 312]]}
{"doc_key": "ai-test-405", "ner": [[0, 2, "algorithm"], [14, 15, "field"], [17, 18, "task"], [20, 21, "task"], [23, 25, "task"], [27, 30, "task"], [33, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 15, 0, 2, "usage", "", false, false], [17, 18, 0, 2, "usage", "", false, false], [20, 21, 0, 2, "usage", "", false, false], [23, 25, 0, 2, "usage", "", false, false], [27, 30, 0, 2, "usage", "", false, false], [33, 34, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Artificial", "neural", "networks", "have", "been", "used", "for", "a", "wide", "range", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "desktop", "and", "video", "gaming", ",", "and", "medical", "diagnosis", "."], "sentence-detokenized": "Artificial neural networks have been used for a wide range of tasks, including computer vision, speech recognition, machine translation, social network filtering, desktop and video gaming, and medical diagnosis.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 31], [32, 36], [37, 41], [42, 45], [46, 47], [48, 52], [53, 58], [59, 61], [62, 67], [67, 68], [69, 78], [79, 87], [88, 94], [94, 95], [96, 102], [103, 114], [114, 115], [116, 123], [124, 135], [135, 136], [137, 143], [144, 151], [152, 161], [161, 162], [163, 170], [171, 174], [175, 180], [181, 187], [187, 188], [189, 192], [193, 200], [201, 210], [210, 211]]}
{"doc_key": "ai-test-406", "ner": [[3, 4, "organisation"], [5, 5, "product"], [17, 17, "product"], [20, 20, "organisation"], [21, 22, "product"], [24, 24, "product"], [26, 28, "product"], [30, 30, "product"], [32, 32, "programlang"], [40, 42, "field"], [45, 45, "product"], [50, 50, "algorithm"], [52, 52, "algorithm"], [54, 54, "algorithm"], [58, 58, "product"], [65, 66, "task"], [71, 72, "algorithm"], [76, 76, "product"], [78, 78, "product"], [80, 82, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "relations": [[5, 5, 3, 4, "origin", "", false, false], [5, 5, 17, 17, "named", "same", false, false], [5, 5, 45, 45, "named", "same", false, false], [32, 32, 40, 42, "related-to", "used_for", false, false], [50, 50, 32, 32, "part-of", "", true, false], [50, 50, 45, 45, "origin", "", true, false], [52, 52, 32, 32, "part-of", "", true, false], [52, 52, 45, 45, "origin", "", true, false], [54, 54, 32, 32, "part-of", "", true, false], [54, 54, 45, 45, "origin", "", true, false], [58, 58, 65, 66, "related-to", "used_for", false, false], [71, 72, 58, 58, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["For", "example", ",", "Salford", "Systems", "CART", "(", "which", "licensed", "the", "proprietary", "code", "of", "the", "original", "authors", "of", "CART", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "an", "open", "source", "software", "environment", "for", "statistical", "computing", "that", "includes", "several", "CART", "applications", "such", "as", "the", "rpart", ",", "party", "and", "randomForest", "packages", ")", ",", "Weka", "(", "a", "free", "and", "open", "source", "data", "mining", "package", "that", "includes", "several", "decision", "tree", "algorithms", ")", ",", "Orange", ",", "KNIME", ",", "Microsoft", "SQL", "Server", "programming", "language", ")", "."], "sentence-detokenized": "For example, Salford Systems CART (which licensed the proprietary code of the original authors of CART), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (an open source software environment for statistical computing that includes several CART applications such as the rpart, party and randomForest packages), Weka (a free and open source data mining package that includes several decision tree algorithms), Orange, KNIME, Microsoft SQL Server programming language).", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 20], [21, 28], [29, 33], [34, 35], [35, 40], [41, 49], [50, 53], [54, 65], [66, 70], [71, 73], [74, 77], [78, 86], [87, 94], [95, 97], [98, 102], [102, 103], [103, 104], [105, 108], [109, 113], [114, 121], [121, 122], [123, 133], [133, 134], [135, 138], [139, 149], [150, 155], [155, 156], [157, 163], [163, 164], [165, 166], [167, 168], [168, 170], [171, 175], [176, 182], [183, 191], [192, 203], [204, 207], [208, 219], [220, 229], [230, 234], [235, 243], [244, 251], [252, 256], [257, 269], [270, 274], [275, 277], [278, 281], [282, 287], [287, 288], [289, 294], [295, 298], [299, 311], [312, 320], [320, 321], [321, 322], [323, 327], [328, 329], [329, 330], [331, 335], [336, 339], [340, 344], [345, 351], [352, 356], [357, 363], [364, 371], [372, 376], [377, 385], [386, 393], [394, 402], [403, 407], [408, 418], [418, 419], [419, 420], [421, 427], [427, 428], [429, 434], [434, 435], [436, 445], [446, 449], [450, 456], [457, 468], [469, 477], [477, 478], [478, 479]]}
{"doc_key": "ai-test-407", "ner": [[1, 2, "algorithm"], [0, 4, "algorithm"], [10, 11, "researcher"], [12, 14, "university"], [16, 17, "researcher"], [18, 22, "organisation"], [24, 26, "organisation"], [34, 36, "researcher"], [38, 40, "researcher"], [42, 45, "organisation"], [56, 61, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[1, 2, 10, 11, "origin", "", false, false], [1, 2, 16, 17, "origin", "", false, false], [1, 2, 34, 36, "origin", "", false, false], [1, 2, 38, 40, "origin", "", false, false], [0, 4, 1, 2, "named", "", false, false], [10, 11, 12, 14, "physical", "", false, false], [10, 11, 12, 14, "role", "", false, false], [16, 17, 18, 22, "physical", "", false, false], [16, 17, 18, 22, "role", "", false, false], [24, 26, 18, 22, "named", "", false, false], [34, 36, 42, 45, "physical", "", false, false], [34, 36, 42, 45, "role", "", false, false], [38, 40, 42, 45, "physical", "", false, false], [38, 40, 42, 45, "role", "", false, false], [56, 61, 1, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Linear", "Predictive", "Coding", "(", "LPC", ")", "was", "first", "developed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", ",", "and", "then", "further", "developed", "by", "Bishnu", "S.", "Atal", "and", "Manfred", "R.", "Schroeder", "of", "Bell", "Labs", "in", "the", "early", "to", "mid-1970s", ",", "becoming", "the", "basis", "for", "the", "first", "DSP", "chips", "for", "speech", "synthesizers", "in", "the", "late", "1970s", "."], "sentence-detokenized": "Linear Predictive Coding (LPC) was first developed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966, and then further developed by Bishnu S. Atal and Manfred R. Schroeder of Bell Labs in the early to mid-1970s, becoming the basis for the first DSP chips for speech synthesizers in the late 1970s.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [31, 34], [35, 40], [41, 50], [51, 53], [54, 62], [63, 70], [71, 73], [74, 80], [81, 91], [92, 95], [96, 101], [102, 107], [108, 110], [111, 117], [118, 127], [128, 131], [132, 141], [142, 143], [143, 146], [146, 147], [148, 150], [151, 155], [155, 156], [157, 160], [161, 165], [166, 173], [174, 183], [184, 186], [187, 193], [194, 196], [197, 201], [202, 205], [206, 213], [214, 216], [217, 226], [227, 229], [230, 234], [235, 239], [240, 242], [243, 246], [247, 252], [253, 255], [256, 265], [265, 266], [267, 275], [276, 279], [280, 285], [286, 289], [290, 293], [294, 299], [300, 303], [304, 309], [310, 313], [314, 320], [321, 333], [334, 336], [337, 340], [341, 345], [346, 351], [351, 352]]}
{"doc_key": "ai-test-408", "ner": [[0, 3, "metrics"], [8, 8, "metrics"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 0, 3, "part-of", "", false, false], [10, 10, 0, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "F", "-", "score", "is", "a", "combination", "of", "accuracy", "and", "recall", ",", "giving", "a", "single", "result", "."], "sentence-detokenized": "The F-score is a combination of accuracy and recall, giving a single result.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 16], [17, 28], [29, 31], [32, 40], [41, 44], [45, 51], [51, 52], [53, 59], [60, 61], [62, 68], [69, 75], [75, 76]]}
{"doc_key": "ai-test-409", "ner": [[0, 1, "field"], [8, 11, "task"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 0, 1, "part-of", "task_part_of_field", false, false], [16, 17, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Image", "analysis", "tasks", "can", "be", "as", "simple", "as", "barcode", "d", "tag", "reading", "or", "as", "complex", "as", "facial", "recognition", "."], "sentence-detokenized": "Image analysis tasks can be as simple as barcode d tag reading or as complex as facial recognition.", "token2charspan": [[0, 5], [6, 14], [15, 20], [21, 24], [25, 27], [28, 30], [31, 37], [38, 40], [41, 48], [49, 50], [51, 54], [55, 62], [63, 65], [66, 68], [69, 76], [77, 79], [80, 86], [87, 98], [98, 99]]}
{"doc_key": "ai-test-410", "ner": [[5, 7, "algorithm"], [25, 26, "algorithm"], [34, 36, "algorithm"], [39, 39, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[34, 36, 25, 26, "type-of", "", false, false], [39, 39, 34, 36, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "special", "case", "of", "linear", "support", "vector", "machines", "can", "be", "solved", "more", "efficiently", "by", "the", "same", "type", "of", "algorithms", "that", "optimise", "its", "close", "cousin", ",", "logistic", "regression", ";", "this", "class", "of", "algorithms", "also", "includes", "stochastic", "gradient", "descent", "(", "e.g.", "PEGASOS", ")", "."], "sentence-detokenized": "The special case of linear support vector machines can be solved more efficiently by the same type of algorithms that optimise its close cousin, logistic regression; this class of algorithms also includes stochastic gradient descent (e.g. PEGASOS).", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 19], [20, 26], [27, 34], [35, 41], [42, 50], [51, 54], [55, 57], [58, 64], [65, 69], [70, 81], [82, 84], [85, 88], [89, 93], [94, 98], [99, 101], [102, 112], [113, 117], [118, 126], [127, 130], [131, 136], [137, 143], [143, 144], [145, 153], [154, 164], [164, 165], [166, 170], [171, 176], [177, 179], [180, 190], [191, 195], [196, 204], [205, 215], [216, 224], [225, 232], [233, 234], [234, 238], [239, 246], [246, 247], [247, 248]]}
{"doc_key": "ai-test-411", "ner": [[1, 1, "product"], [0, 4, "product"], [22, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 0, 4, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["When", "Siri", "on", "iOS", "is", "asked", "if", "you", "have", "a", "pet", ",", "one", "of", "the", "answers", "is", "\"", "I", "used", "to", "have", "an", "AIBO", "\"", "."], "sentence-detokenized": "When Siri on iOS is asked if you have a pet, one of the answers is \"I used to have an AIBO\".", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 16], [17, 19], [20, 25], [26, 28], [29, 32], [33, 37], [38, 39], [40, 43], [43, 44], [45, 48], [49, 51], [52, 55], [56, 63], [64, 66], [67, 68], [68, 69], [70, 74], [75, 77], [78, 82], [83, 85], [86, 90], [90, 91], [91, 92]]}
{"doc_key": "ai-test-412", "ner": [[0, 3, "task"], [5, 8, "metrics"], [10, 10, "metrics"], [12, 12, "metrics"], [13, 15, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 8, 0, 3, "part-of", "", false, false], [10, 10, 5, 8, "named", "", false, false], [12, 12, 0, 3, "part-of", "", false, false], [13, 15, 12, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "data", "warehouse", ",", "positive", "predictive", "value", "is", "called", "accuracy", "and", "sensitivity", "is", "called", "recall", "."], "sentence-detokenized": "In the data warehouse, positive predictive value is called accuracy and sensitivity is called recall.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 21], [21, 22], [23, 31], [32, 42], [43, 48], [49, 51], [52, 58], [59, 67], [68, 71], [72, 83], [84, 86], [87, 93], [94, 100], [100, 101]]}
{"doc_key": "ai-test-413", "ner": [[9, 10, "field"], [12, 12, "task"], [14, 14, "task"], [16, 17, "task"], [31, 32, "task"], [34, 35, "task"], [37, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 12, 9, 10, "part-of", "task_part_of_field", false, false], [14, 14, 9, 10, "part-of", "task_part_of_field", false, false], [16, 17, 9, 10, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["His", "research", "focused", "in", "particular", "on", "areas", "such", "as", "text", "mining", "(", "extraction", ",", "categorisation", ",", "novelty", "detection", ")", "and", "new", "theoretical", "frameworks", "such", "as", "unified", "utility", "theory", ",", "which", "combines", "information", "retrieval", ",", "automatic", "summarisation", ",", "free", "-", "text", "question", "answering", "and", "related", "tasks", "."], "sentence-detokenized": "His research focused in particular on areas such as text mining (extraction, categorisation, novelty detection) and new theoretical frameworks such as unified utility theory, which combines information retrieval, automatic summarisation, free-text question answering and related tasks.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 23], [24, 34], [35, 37], [38, 43], [44, 48], [49, 51], [52, 56], [57, 63], [64, 65], [65, 75], [75, 76], [77, 91], [91, 92], [93, 100], [101, 110], [110, 111], [112, 115], [116, 119], [120, 131], [132, 142], [143, 147], [148, 150], [151, 158], [159, 166], [167, 173], [173, 174], [175, 180], [181, 189], [190, 201], [202, 211], [211, 212], [213, 222], [223, 236], [236, 237], [238, 242], [242, 243], [243, 247], [248, 256], [257, 266], [267, 270], [271, 278], [279, 284], [284, 285]]}
{"doc_key": "ai-test-414", "ner": [[3, 4, "product"], [16, 17, "misc"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Delta", "robots", "have", "rotary", "actuators", "mounted", "on", "the", "base", ",", "which", "move", "a", "light", ",", "rigid", "parallel", "arm", "."], "sentence-detokenized": "Delta robots have rotary actuators mounted on the base, which move a light, rigid parallel arm.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 24], [25, 34], [35, 42], [43, 45], [46, 49], [50, 54], [54, 55], [56, 61], [62, 66], [67, 68], [69, 74], [74, 75], [76, 81], [82, 90], [91, 94], [94, 95]]}
{"doc_key": "ai-test-415", "ner": [[8, 12, "metrics"], [6, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "as", "a", "2", "\u00d7", "2", "contingency", "table", "or", "a", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated as a 2 \u00d7 2 contingency table or a confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [64, 66], [67, 68], [69, 78], [79, 85], [86, 88], [89, 96], [96, 97]]}
{"doc_key": "ai-test-416", "ner": [[4, 5, "field"], [31, 32, "task"], [38, 39, "task"], [44, 46, "task"], [48, 50, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[31, 32, 4, 5, "part-of", "task_part_of_field", false, false], [38, 39, 4, 5, "part-of", "task_part_of_field", false, false], [44, 46, 4, 5, "part-of", "task_part_of_field", false, false], [48, 50, 4, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "actual", "task", "of", "data", "mining", "is", "the", "semi-automated", "or", "automated", "analysis", "of", "large", "amounts", "of", "data", "to", "extract", "unknown", "patterns", "of", "interest", ",", "such", "as", "groups", "of", "data", "records", "(", "cluster", "analysis", ")", ",", "unusual", "records", "(", "anomaly", "detection", ")", "and", "dependencies", "(", "association", "rule", "mining", ",", "sequential", "pattern", "mining", ")", "."], "sentence-detokenized": "The actual task of data mining is the semi-automated or automated analysis of large amounts of data to extract unknown patterns of interest, such as groups of data records (cluster analysis), unusual records (anomaly detection) and dependencies (association rule mining, sequential pattern mining).", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 18], [19, 23], [24, 30], [31, 33], [34, 37], [38, 52], [53, 55], [56, 65], [66, 74], [75, 77], [78, 83], [84, 91], [92, 94], [95, 99], [100, 102], [103, 110], [111, 118], [119, 127], [128, 130], [131, 139], [139, 140], [141, 145], [146, 148], [149, 155], [156, 158], [159, 163], [164, 171], [172, 173], [173, 180], [181, 189], [189, 190], [190, 191], [192, 199], [200, 207], [208, 209], [209, 216], [217, 226], [226, 227], [228, 231], [232, 244], [245, 246], [246, 257], [258, 262], [263, 269], [269, 270], [271, 281], [282, 289], [290, 296], [296, 297], [297, 298]]}
{"doc_key": "ai-test-417", "ner": [[2, 3, "product"], [5, 6, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 5, 6, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "the", "recommendation", "system", ",", "sentiment", "analysis", "has", "proved", "to", "be", "a", "valuable", "technique", "."], "sentence-detokenized": "For the recommendation system, sentiment analysis has proved to be a valuable technique.", "token2charspan": [[0, 3], [4, 7], [8, 22], [23, 29], [29, 30], [31, 40], [41, 49], [50, 53], [54, 60], [61, 63], [64, 66], [67, 68], [69, 77], [78, 87], [87, 88]]}
{"doc_key": "ai-test-418", "ner": [[2, 3, "misc"], [11, 12, "product"], [32, 32, "organisation"], [35, 36, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 11, 12, "usage", "", false, false], [32, 32, 35, 36, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Coincidentally", ",", "the", "Germans", "had", "chosen", "the", "wrong", "frequency", "for", "the", "Wotan", "system", ";", "it", "was", "operating", "on", "45", "MHz", ",", "which", "happened", "to", "be", "the", "frequency", "of", "the", "powerful", "but", "non-operational", "BBC", "transmitter", "at", "Alexandra", "Palace", "."], "sentence-detokenized": "Coincidentally, the Germans had chosen the wrong frequency for the Wotan system; it was operating on 45 MHz, which happened to be the frequency of the powerful but non-operational BBC transmitter at Alexandra Palace.", "token2charspan": [[0, 14], [14, 15], [16, 19], [20, 27], [28, 31], [32, 38], [39, 42], [43, 48], [49, 58], [59, 62], [63, 66], [67, 72], [73, 79], [79, 80], [81, 83], [84, 87], [88, 97], [98, 100], [101, 103], [104, 107], [107, 108], [109, 114], [115, 123], [124, 126], [127, 129], [130, 133], [134, 143], [144, 146], [147, 150], [151, 159], [160, 163], [164, 179], [180, 183], [184, 195], [196, 198], [199, 208], [209, 215], [215, 216]]}
{"doc_key": "ai-test-419", "ner": [[8, 12, "metrics"], [6, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "as", "a", "2", "\u00d7", "2", "contingency", "table", "or", "a", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated as a 2 \u00d7 2 contingency table or a confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [64, 66], [67, 68], [69, 78], [79, 85], [86, 88], [89, 96], [96, 97]]}
{"doc_key": "ai-test-420", "ner": [[0, 3, "misc"], [8, 8, "misc"], [12, 12, "product"], [14, 14, "product"], [16, 18, "product"], [25, 26, "misc"], [33, 37, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 12, 8, 8, "usage", "", false, false], [14, 14, 8, 8, "usage", "", false, false], [16, 18, 14, 14, "named", "", false, false], [25, 26, 8, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "Semantic", "Web", "applications", "and", "in", "relatively", "popular", "RDF", "applications", "such", "as", "RSS", "and", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "resources", "are", "usually", "represented", "by", "URIs", ",", "which", "intentionally", "represent", "actual", "data", "on", "the", "World", "Wide", "Web", "and", "can", "be", "used", "to", "access", "that", "data", "."], "sentence-detokenized": "In Semantic Web applications and in relatively popular RDF applications such as RSS and FOAF (Friend a Friend), resources are usually represented by URIs, which intentionally represent actual data on the World Wide Web and can be used to access that data.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 28], [29, 32], [33, 35], [36, 46], [47, 54], [55, 58], [59, 71], [72, 76], [77, 79], [80, 83], [84, 87], [88, 92], [93, 94], [94, 100], [101, 102], [103, 109], [109, 110], [110, 111], [112, 121], [122, 125], [126, 133], [134, 145], [146, 148], [149, 153], [153, 154], [155, 160], [161, 174], [175, 184], [185, 191], [192, 196], [197, 199], [200, 203], [204, 209], [210, 214], [215, 218], [219, 222], [223, 226], [227, 229], [230, 234], [235, 237], [238, 244], [245, 249], [250, 254], [254, 255]]}
{"doc_key": "ai-test-421", "ner": [[0, 7, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "has", "researched", "this", "topic", "extensively", "."], "sentence-detokenized": "The Association for the Advancement of Artificial Intelligence has researched this topic extensively.", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 35], [36, 38], [39, 49], [50, 62], [63, 66], [67, 77], [78, 82], [83, 88], [89, 100], [100, 101]]}
{"doc_key": "ai-test-422", "ner": [[0, 9, "product"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 19, 0, 9, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Apple", "'s", "Macintosh", "speech", "system", ",", "which", "was", "born", "out", "of", "curiosity", ",", "has", "evolved", "into", "the", "fully", "supported", "PlainTalk", "programme", "for", "people", "with", "visual", "impairments", "."], "sentence-detokenized": "Apple's Macintosh speech system, which was born out of curiosity, has evolved into the fully supported PlainTalk programme for people with visual impairments.", "token2charspan": [[0, 5], [5, 7], [8, 17], [18, 24], [25, 31], [31, 32], [33, 38], [39, 42], [43, 47], [48, 51], [52, 54], [55, 64], [64, 65], [66, 69], [70, 77], [78, 82], [83, 86], [87, 92], [93, 102], [103, 112], [113, 122], [123, 126], [127, 133], [134, 138], [139, 145], [146, 157], [157, 158]]}
{"doc_key": "ai-test-423", "ner": [[5, 5, "field"], [7, 8, "task"], [10, 11, "task"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 5, 5, "part-of", "task_part_of_field", false, false], [10, 11, 5, 5, "part-of", "task_part_of_field", false, false], [13, 14, 5, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Other", "uses", "of", "ontologies", "in", "NLP", "include", "information", "retrieval", ",", "information", "extraction", "and", "automatic", "summarisation", "."], "sentence-detokenized": "Other uses of ontologies in NLP include information retrieval, information extraction and automatic summarisation.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 24], [25, 27], [28, 31], [32, 39], [40, 51], [52, 61], [61, 62], [63, 74], [75, 85], [86, 89], [90, 99], [100, 113], [113, 114]]}
{"doc_key": "ai-test-424", "ner": [[7, 15, "organisation"], [18, 22, "organisation"], [25, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "institute", "has", "worked", "closely", "with", "the", "Janelia", "Farm", "Campus", "of", "the", "Howard", "Hughes", "Medical", "Institute", ",", "the", "Allen", "Institute", "for", "Brain", "Science", "and", "the", "National", "Institutes", "of", "Health", "to", "develop", "better", "methods", "for", "reconstructing", "neuronal", "architectures", "."], "sentence-detokenized": "The institute has worked closely with the Janelia Farm Campus of the Howard Hughes Medical Institute, the Allen Institute for Brain Science and the National Institutes of Health to develop better methods for reconstructing neuronal architectures.", "token2charspan": [[0, 3], [4, 13], [14, 17], [18, 24], [25, 32], [33, 37], [38, 41], [42, 49], [50, 54], [55, 61], [62, 64], [65, 68], [69, 75], [76, 82], [83, 90], [91, 100], [100, 101], [102, 105], [106, 111], [112, 121], [122, 125], [126, 131], [132, 139], [140, 143], [144, 147], [148, 156], [157, 167], [168, 170], [171, 177], [178, 180], [181, 188], [189, 195], [196, 203], [204, 207], [208, 222], [223, 231], [232, 245], [245, 246]]}
{"doc_key": "ai-test-425", "ner": [[0, 0, "organisation"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 0, 0, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Google", "recently", "announced", "that", "Google", "Translate", "translates", "around", "1", "million", "books", "in", "one", "day", "(", "2012", ")", "."], "sentence-detokenized": "Google recently announced that Google Translate translates around 1 million books in one day (2012).", "token2charspan": [[0, 6], [7, 15], [16, 25], [26, 30], [31, 37], [38, 47], [48, 58], [59, 65], [66, 67], [68, 75], [76, 81], [82, 84], [85, 88], [89, 92], [93, 94], [94, 98], [98, 99], [99, 100]]}
{"doc_key": "ai-test-426", "ner": [[14, 14, "country"], [17, 17, "country"], [19, 19, "country"], [21, 21, "country"], [23, 23, "country"], [25, 26, "country"], [38, 39, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Events", "are", "held", "all", "over", "the", "world", ",", "and", "are", "most", "popular", "in", "the", "UK", ",", "the", "US", ",", "Japan", ",", "Singapore", ",", "India", "and", "South", "Korea", ",", "and", "are", "becoming", "increasingly", "popular", "in", "sub-continental", "countries", "such", "as", "Sri", "Lanka", "."], "sentence-detokenized": "Events are held all over the world, and are most popular in the UK, the US, Japan, Singapore, India and South Korea, and are becoming increasingly popular in sub-continental countries such as Sri Lanka.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 24], [25, 28], [29, 34], [34, 35], [36, 39], [40, 43], [44, 48], [49, 56], [57, 59], [60, 63], [64, 66], [66, 67], [68, 71], [72, 74], [74, 75], [76, 81], [81, 82], [83, 92], [92, 93], [94, 99], [100, 103], [104, 109], [110, 115], [115, 116], [117, 120], [121, 124], [125, 133], [134, 146], [147, 154], [155, 157], [158, 173], [174, 183], [184, 188], [189, 191], [192, 195], [196, 201], [201, 202]]}
{"doc_key": "ai-test-427", "ner": [[5, 6, "programlang"], [12, 12, "programlang"], [14, 14, "programlang"], [16, 17, "programlang"], [10, 19, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "packages", "are", "mainly", "developed", "in", "R", ",", "with", "occasional", "use", "in", "Java", ",", "C", ",", "C", "++", "and", "Fortran", "."], "sentence-detokenized": "These packages are mainly developed in R, with occasional use in Java, C, C++ and Fortran.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 25], [26, 35], [36, 38], [39, 40], [40, 41], [42, 46], [47, 57], [58, 61], [62, 64], [65, 69], [69, 70], [71, 72], [72, 73], [74, 75], [75, 77], [78, 81], [82, 89], [89, 90]]}
{"doc_key": "ai-test-428", "ner": [[2, 7, "conference"], [3, 9, "conference"], [12, 12, "researcher"], [14, 14, "researcher"], [15, 19, "researcher"], [21, 22, "algorithm"], [27, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 9, 2, 7, "named", "", false, false], [12, 12, 2, 7, "physical", "", false, false], [12, 12, 2, 7, "role", "", false, false], [12, 12, 15, 19, "role", "teams_up_with", false, false], [12, 12, 21, 22, "usage", "", false, false], [14, 14, 2, 7, "physical", "", false, false], [14, 14, 2, 7, "role", "", false, false], [14, 14, 15, 19, "role", "teams_up_with", false, false], [14, 14, 21, 22, "usage", "", false, false], [15, 19, 2, 7, "physical", "", false, false], [15, 19, 2, 7, "role", "", false, false], [15, 19, 21, 22, "usage", "", false, false], [21, 22, 27, 32, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["At", "the", "2006", "European", "Conference", "on", "Computer", "Vision", "(", "ECCV", ")", ",", "Dalal", "and", "Triggs", "collaborated", "with", "Cordelia", "Schmid", "to", "apply", "HOG", "detectors", "to", "the", "problem", "of", "human", "detection", "in", "film", "and", "video", "."], "sentence-detokenized": "At the 2006 European Conference on Computer Vision (ECCV), Dalal and Triggs collaborated with Cordelia Schmid to apply HOG detectors to the problem of human detection in film and video.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 20], [21, 31], [32, 34], [35, 43], [44, 50], [51, 52], [52, 56], [56, 57], [57, 58], [59, 64], [65, 68], [69, 75], [76, 88], [89, 93], [94, 102], [103, 109], [110, 112], [113, 118], [119, 122], [123, 132], [133, 135], [136, 139], [140, 147], [148, 150], [151, 156], [157, 166], [167, 169], [170, 174], [175, 178], [179, 184], [184, 185]]}
{"doc_key": "ai-test-429", "ner": [[3, 3, "metrics"], [5, 7, "metrics"], [11, 13, "task"], [21, 25, "metrics"], [31, 31, "metrics"], [34, 36, "metrics"], [38, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7], "relations": [[3, 3, 11, 13, "related-to", "measured_with", false, false], [5, 7, 11, 13, "related-to", "measured_with", false, false], [38, 38, 34, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 5], "sentence": ["In", "addition", "to", "sensitivity", "and", "specificity", ",", "the", "performance", "of", "a", "binary", "classification", "test", "can", "also", "be", "measured", "in", "terms", "of", "positive", "predictive", "value", "(", "PPV", ")", ",", "also", "known", "as", "accuracy", ",", "and", "negative", "predictive", "value", "(", "NPV", ")", "."], "sentence-detokenized": "In addition to sensitivity and specificity, the performance of a binary classification test can also be measured in terms of positive predictive value (PPV), also known as accuracy, and negative predictive value (NPV).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 42], [42, 43], [44, 47], [48, 59], [60, 62], [63, 64], [65, 71], [72, 86], [87, 91], [92, 95], [96, 100], [101, 103], [104, 112], [113, 115], [116, 121], [122, 124], [125, 133], [134, 144], [145, 150], [151, 152], [152, 155], [155, 156], [156, 157], [158, 162], [163, 168], [169, 171], [172, 180], [180, 181], [182, 185], [186, 194], [195, 205], [206, 211], [212, 213], [213, 216], [216, 217], [217, 218]]}
{"doc_key": "ai-test-430", "ner": [[15, 17, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "models", "can", "give", "partial", "credit", "for", "overlapping", "matches", "(", "for", "example", ",", "using", "the", "Jaccard", "index", "criterion", "."], "sentence-detokenized": "Such models can give partial credit for overlapping matches (for example, using the Jaccard index criterion.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 28], [29, 35], [36, 39], [40, 51], [52, 59], [60, 61], [61, 64], [65, 72], [72, 73], [74, 79], [80, 83], [84, 91], [92, 97], [98, 107], [107, 108]]}
{"doc_key": "ai-test-431", "ner": [[13, 19, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", ",", "it", "illustrates", "the", "philosophical", "problems", "and", "possible", "misunderstandings", "of", "using", "maximum", "likelihood", "estimators", "and", "likelihood", "functions", "in", "single", "-", "sample", "estimation", "."], "sentence-detokenized": "In addition, it illustrates the philosophical problems and possible misunderstandings of using maximum likelihood estimators and likelihood functions in single-sample estimation.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 15], [16, 27], [28, 31], [32, 45], [46, 54], [55, 58], [59, 67], [68, 85], [86, 88], [89, 94], [95, 102], [103, 113], [114, 124], [125, 128], [129, 139], [140, 149], [150, 152], [153, 159], [159, 160], [160, 166], [167, 177], [177, 178]]}
