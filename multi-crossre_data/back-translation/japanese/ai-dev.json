{"doc_key": "ai-dev-1", "ner": [[2, 3, "metrics"], [8, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 2, 3, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Here", ",", "accuracy", "is", "measured", "in", "terms", "of", "error", "rate", "and", "is", "defined", "as", "follows", "."], "sentence-detokenized": "Here, accuracy is measured in terms of error rate and is defined as follows.", "token2charspan": [[0, 4], [4, 5], [6, 14], [15, 17], [18, 26], [27, 29], [30, 35], [36, 38], [39, 44], [45, 49], [50, 53], [54, 56], [57, 64], [65, 67], [68, 75], [75, 76]]}
{"doc_key": "ai-dev-2", "ner": [[4, 4, "algorithm"], [11, 12, "misc"], [16, 17, "algorithm"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 11, 12, "type-of", "", false, false], [4, 4, 16, 17, "related-to", "", false, false], [4, 4, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "this", "regard", ",", "SVM", "is", "closely", "related", "to", "other", "basic", "classification", "algorithms", "such", "as", "regularised", "least", "squares", "logistic", "regression", "."], "sentence-detokenized": "In this regard, SVM is closely related to other basic classification algorithms such as regularised least squares logistic regression.", "token2charspan": [[0, 2], [3, 7], [8, 14], [14, 15], [16, 19], [20, 22], [23, 30], [31, 38], [39, 41], [42, 47], [48, 53], [54, 68], [69, 79], [80, 84], [85, 87], [88, 99], [100, 105], [106, 113], [114, 122], [123, 133], [133, 134]]}
{"doc_key": "ai-dev-3", "ner": [[3, 14, "person"], [2, 18, "person"]], "ner_mapping_to_source": [1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Brion", "James", "plays", "Leon", "Kowalski", ",", "a", "fight", "-", "and", "-", "work", "replicant", ",", "and", "Joanna", "Cassidy", "plays", "Zola", ",", "an", "assassination", "replicant", "."], "sentence-detokenized": "Brion James plays Leon Kowalski, a fight-and-work replicant, and Joanna Cassidy plays Zola, an assassination replicant.", "token2charspan": [[0, 5], [6, 11], [12, 17], [18, 22], [23, 31], [31, 32], [33, 34], [35, 40], [40, 41], [41, 44], [44, 45], [45, 49], [50, 59], [59, 60], [61, 64], [65, 71], [72, 79], [80, 85], [86, 90], [90, 91], [92, 94], [95, 108], [109, 118], [118, 119]]}
{"doc_key": "ai-dev-4", "ner": [[19, 23, "product"], [17, 18, "organisation"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "first", "photographs", ",", "scanned", ",", "stored", "and", "reproduced", "in", "digital", "pixels", ",", "were", "displayed", "on", "the", "NIST", "Standards", "Eastern", "Automatic", "Computer", "(", "SEAC", ")", "."], "sentence-detokenized": "The first photographs, scanned, stored and reproduced in digital pixels, were displayed on the NIST Standards Eastern Automatic Computer (SEAC).", "token2charspan": [[0, 3], [4, 9], [10, 21], [21, 22], [23, 30], [30, 31], [32, 38], [39, 42], [43, 53], [54, 56], [57, 64], [65, 71], [71, 72], [73, 77], [78, 87], [88, 90], [91, 94], [95, 99], [100, 109], [110, 117], [118, 127], [128, 136], [137, 138], [138, 142], [142, 143], [143, 144]]}
{"doc_key": "ai-dev-5", "ner": [[0, 6, "task"], [10, 10, "task"], [8, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 6, 10, 10, "part-of", "", false, false], [0, 6, 8, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Segmenting", "text", "into", "topics", "or", "discrete", "turns", "can", "significantly", "improve", "information", "retrieval", "and", "speech", "recognition", "(", "by", "indexing", "/", "recognising", "documents", "more", "accurately", "or", "giving", "the", "result", "of", "a", "specific", "part", "of", "the", "document", "corresponding", "to", "a", "query", ")", "."], "sentence-detokenized": "Segmenting text into topics or discrete turns can significantly improve information retrieval and speech recognition (by indexing/recognising documents more accurately or giving the result of a specific part of the document corresponding to a query).", "token2charspan": [[0, 10], [11, 15], [16, 20], [21, 27], [28, 30], [31, 39], [40, 45], [46, 49], [50, 63], [64, 71], [72, 83], [84, 93], [94, 97], [98, 104], [105, 116], [117, 118], [118, 120], [121, 129], [129, 130], [130, 141], [142, 151], [152, 156], [157, 167], [168, 170], [171, 177], [178, 181], [182, 188], [189, 191], [192, 193], [194, 202], [203, 207], [208, 210], [211, 214], [215, 223], [224, 237], [238, 240], [241, 242], [243, 248], [248, 249], [249, 250]]}
{"doc_key": "ai-dev-6", "ner": [[27, 28, "conference"], [23, 25, "university"], [32, 33, "researcher"], [35, 36, "researcher"], [38, 39, "researcher"], [41, 42, "researcher"], [44, 45, "researcher"], [46, 47, "researcher"], [49, 51, "researcher"], [53, 54, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[27, 28, 23, 25, "physical", "", false, false], [32, 33, 27, 28, "physical", "", false, false], [32, 33, 27, 28, "role", "", false, false], [32, 33, 27, 28, "temporal", "", false, false], [35, 36, 27, 28, "physical", "", false, false], [35, 36, 27, 28, "role", "", false, false], [35, 36, 27, 28, "temporal", "", false, false], [38, 39, 27, 28, "physical", "", false, false], [38, 39, 27, 28, "role", "", false, false], [38, 39, 27, 28, "temporal", "", false, false], [41, 42, 27, 28, "physical", "", false, false], [41, 42, 27, 28, "role", "", false, false], [41, 42, 27, 28, "temporal", "", false, false], [44, 45, 27, 28, "physical", "", false, false], [44, 45, 27, 28, "role", "", false, false], [44, 45, 27, 28, "temporal", "", false, false], [46, 47, 27, 28, "physical", "", false, false], [46, 47, 27, 28, "role", "", false, false], [46, 47, 27, 28, "temporal", "", false, false], [49, 51, 27, 28, "physical", "", false, false], [49, 51, 27, 28, "role", "", false, false], [49, 51, 27, 28, "temporal", "", false, false], [53, 54, 27, 28, "physical", "", false, false], [53, 54, 27, 28, "role", "", false, false], [53, 54, 27, 28, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "sentence": ["In", "1999", ",", "he", "organised", "such", "a", "symposium", "at", "Indiana", "University", ",", "and", "in", "April", "2000", ",", "he", "organised", "a", "major", "symposium", "at", "Stanford", "University", "entitled", "'", "Spiritual", "Robots", "'", ",", "with", "Ray", "Kurzweil", ",", "Hans", "Moravec", ",", "Kevin", "Kelly", ",", "Ralph", "Markle", ",", "Bill", "Joy", "Frank", "Drake", ",", "John", "Henry", "Holland", "and", "John", "Koza", "moderated", "a", "panel", "comprising", "."], "sentence-detokenized": "In 1999, he organised such a symposium at Indiana University, and in April 2000, he organised a major symposium at Stanford University entitled 'Spiritual Robots', with Ray Kurzweil, Hans Moravec, Kevin Kelly, Ralph Markle, Bill Joy Frank Drake, John Henry Holland and John Koza moderated a panel comprising.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 21], [22, 26], [27, 28], [29, 38], [39, 41], [42, 49], [50, 60], [60, 61], [62, 65], [66, 68], [69, 74], [75, 79], [79, 80], [81, 83], [84, 93], [94, 95], [96, 101], [102, 111], [112, 114], [115, 123], [124, 134], [135, 143], [144, 145], [145, 154], [155, 161], [161, 162], [162, 163], [164, 168], [169, 172], [173, 181], [181, 182], [183, 187], [188, 195], [195, 196], [197, 202], [203, 208], [208, 209], [210, 215], [216, 222], [222, 223], [224, 228], [229, 232], [233, 238], [239, 244], [244, 245], [246, 250], [251, 256], [257, 264], [265, 268], [269, 273], [274, 278], [279, 288], [289, 290], [291, 296], [297, 307], [307, 308]]}
{"doc_key": "ai-dev-7", "ner": [[0, 2, "metrics"], [21, 23, "metrics"]], "ner_mapping_to_source": [4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["p", "is", "the", "number", "of", "correct", "positive", "results", "divided", "by", "the", "number", "of", "all", "positive", "results", "returned", "by", "the", "classifier", "and", "r", "is", "the", "number", "of", "correct", "positive", "results", "divided", "by", "the", "number", "of", "all", "relevant", "samples", "(", "all", "samples", "to", "be", "identified", "as", "positive", ")", "."], "sentence-detokenized": "p is the number of correct positive results divided by the number of all positive results returned by the classifier and r is the number of correct positive results divided by the number of all relevant samples (all samples to be identified as positive).", "token2charspan": [[0, 1], [2, 4], [5, 8], [9, 15], [16, 18], [19, 26], [27, 35], [36, 43], [44, 51], [52, 54], [55, 58], [59, 65], [66, 68], [69, 72], [73, 81], [82, 89], [90, 98], [99, 101], [102, 105], [106, 116], [117, 120], [121, 122], [123, 125], [126, 129], [130, 136], [137, 139], [140, 147], [148, 156], [157, 164], [165, 172], [173, 175], [176, 179], [180, 186], [187, 189], [190, 193], [194, 202], [203, 210], [211, 212], [212, 215], [216, 223], [224, 226], [227, 229], [230, 240], [241, 243], [244, 252], [252, 253], [253, 254]]}
{"doc_key": "ai-dev-8", "ner": [[8, 12, "product"], [13, 19, "person"], [15, 16, "misc"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[8, 12, 13, 19, "win-defeat", "", false, false], [8, 12, 15, 16, "win-defeat", "", true, false], [13, 19, 15, 16, "win-defeat", "lose", true, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["A", "prime", "example", "of", "this", "would", "be", "the", "development", "of", "AlphaGo", ",", "which", "defeated", "the", "world", "Go", "champion", "Lee", "Sedol", "."], "sentence-detokenized": "A prime example of this would be the development of AlphaGo, which defeated the world Go champion Lee Sedol.", "token2charspan": [[0, 1], [2, 7], [8, 15], [16, 18], [19, 23], [24, 29], [30, 32], [33, 36], [37, 48], [49, 51], [52, 59], [59, 60], [61, 66], [67, 75], [76, 79], [80, 85], [86, 88], [89, 97], [98, 101], [102, 107], [107, 108]]}
{"doc_key": "ai-dev-9", "ner": [[0, 1, "product"], [12, 16, "misc"], [5, 6, "misc"], [9, 11, "product"]], "ner_mapping_to_source": [2, 3, 4, 5], "relations": [[0, 1, 12, 16, "related-to", "", false, false], [0, 1, 5, 6, "usage", "", false, false], [0, 1, 9, 11, "usage", "", false, false]], "relations_mapping_to_source": [2, 3, 4], "sentence": ["Unsupervised", "disambiguation", "systems", "use", "pre-trained", "word", "embedding", "models", "and", "Word", "Net", "to", "select", "the", "best", "word", "sense", "using", "similarity", "between", "word", "senses", "within", "a", "fixed", "context", "window", "."], "sentence-detokenized": "Unsupervised disambiguation systems use pre-trained word embedding models and WordNet to select the best word sense using similarity between word senses within a fixed context window.", "token2charspan": [[0, 12], [13, 27], [28, 35], [36, 39], [40, 51], [52, 56], [57, 66], [67, 73], [74, 77], [78, 82], [82, 85], [86, 88], [89, 95], [96, 99], [100, 104], [105, 109], [110, 115], [116, 121], [122, 132], [133, 140], [141, 145], [146, 152], [153, 159], [160, 161], [162, 167], [168, 175], [176, 182], [182, 183]]}
{"doc_key": "ai-dev-10", "ner": [[3, 3, "field"], [0, 0, "field"], [2, 2, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 3, 3, "part-of", "", false, false], [2, 2, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Supervised", "and", "unsupervised", "machine", "learning", "has", "been", "used", "to", "automatically", "derive", "such", "rules", "."], "sentence-detokenized": "Supervised and unsupervised machine learning has been used to automatically derive such rules.", "token2charspan": [[0, 10], [11, 14], [15, 27], [28, 35], [36, 44], [45, 48], [49, 53], [54, 58], [59, 61], [62, 75], [76, 82], [83, 87], [88, 93], [93, 94]]}
{"doc_key": "ai-dev-11", "ner": [[3, 3, "researcher"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1969", ",", "Scheinman", "invented", "the", "Stanford", "Arm", "."], "sentence-detokenized": "In 1969, Scheinman invented the Stanford Arm.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 27], [28, 31], [32, 40], [41, 44], [44, 45]]}
{"doc_key": "ai-dev-12", "ner": [[0, 2, "metrics"], [11, 15, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Log", "losses", "are", "differentiable", ",", "so", "the", "model", "can", "be", "optimised", "using", "gradient", "-", "based", "methods", "."], "sentence-detokenized": "Log losses are differentiable, so the model can be optimised using gradient-based methods.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 29], [29, 30], [31, 33], [34, 37], [38, 43], [44, 47], [48, 50], [51, 60], [61, 66], [67, 75], [75, 76], [76, 81], [82, 89], [89, 90]]}
{"doc_key": "ai-dev-13", "ner": [[0, 2, "field"], [4, 6, "algorithm"], [8, 14, "algorithm"], [10, 15, "algorithm"], [19, 19, "field"], [31, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6], "relations": [[4, 6, 19, 19, "part-of", "", false, false], [8, 14, 4, 6, "named", "", false, false], [10, 15, 4, 6, "named", "", false, false], [19, 19, 0, 2, "part-of", "subfield", false, false], [31, 32, 19, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5], "sentence": ["In", "machine", "learning", ",", "support", "vector", "machines", "(", "SVMs", ",", "also", "known", "as", "support", "vector", "networks", ")", "are", "supervised", "learning", "models", "with", "learning", "algorithms", "that", "analyse", "data", "used", "for", "classification", "and", "regression", "analysis", "."], "sentence-detokenized": "In machine learning, support vector machines (SVMs, also known as support vector networks) are supervised learning models with learning algorithms that analyse data used for classification and regression analysis.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 28], [29, 35], [36, 44], [45, 46], [46, 50], [50, 51], [52, 56], [57, 62], [63, 65], [66, 73], [74, 80], [81, 89], [89, 90], [91, 94], [95, 105], [106, 114], [115, 121], [122, 126], [127, 135], [136, 146], [147, 151], [152, 159], [160, 164], [165, 169], [170, 173], [174, 188], [189, 192], [193, 203], [204, 212], [212, 213]]}
{"doc_key": "ai-dev-14", "ner": [[14, 19, "task"], [22, 22, "metrics"], [24, 24, "metrics"], [26, 26, "researcher"], [28, 28, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "number", "of", "revised", "and", "improved", "methods", "have", "been", "proposed", "as", "automatic", "indicators", "for", "machine", "translation", "(", "MT", ")", "evaluation", ",", "including", "TER", ",", "METEOR", "and", "Banerjee", "and", "Lavie", ",", "(", "2005", ")", "."], "sentence-detokenized": "A number of revised and improved methods have been proposed as automatic indicators for machine translation (MT) evaluation, including TER, METEOR and Banerjee and Lavie, (2005).", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 19], [20, 23], [24, 32], [33, 40], [41, 45], [46, 50], [51, 59], [60, 62], [63, 72], [73, 83], [84, 87], [88, 95], [96, 107], [108, 109], [109, 111], [111, 112], [113, 123], [123, 124], [125, 134], [135, 138], [138, 139], [140, 146], [147, 150], [151, 159], [160, 163], [164, 169], [169, 170], [171, 172], [172, 176], [176, 177], [177, 178]]}
{"doc_key": "ai-dev-15", "ner": [[2, 6, "misc"], [9, 9, "organisation"], [12, 12, "organisation"], [16, 16, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 6, 12, 12, "origin", "", false, false], [12, 12, 9, 9, "part-of", "", false, false], [16, 16, 12, 12, "role", "", false, false], [19, 20, 12, 12, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "contains", "a", "high", "-", "level", "ontology", "developed", "by", "IEEE", "working", "group", "P1600.1", "(", "drafted", "by", "Ian", "Niles", "and", "Adam", "Pease", ")", "."], "sentence-detokenized": "It contains a high-level ontology developed by IEEE working group P1600.1 (drafted by Ian Niles and Adam Pease).", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 18], [18, 19], [19, 24], [25, 33], [34, 43], [44, 46], [47, 51], [52, 59], [60, 65], [66, 73], [74, 75], [75, 82], [83, 85], [86, 89], [90, 95], [96, 99], [100, 104], [105, 110], [110, 111], [111, 112]]}
{"doc_key": "ai-dev-16", "ner": [[1, 3, "misc"], [29, 30, "algorithm"], [34, 34, "algorithm"], [25, 40, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[29, 30, 1, 3, "part-of", "", true, false], [34, 34, 1, 3, "part-of", "", true, false], [25, 40, 34, 34, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["As", "cryo", "-electron", "tomography", "can", "only", "acquire", "a", "limited", "number", "of", "projections", "to", "avoid", "hardware", "limitations", "and", "damage", "to", "biological", "samples", ",", "it", "can", "be", "used", "in", "conjunction", "with", "compressed", "sensing", "techniques", "and", "regularisation", "functions", "(", "e.g.", "Huber", "loss", ")", "to", "improve", "the", "reconstruction", "for", "better", "interpretation", "."], "sentence-detokenized": "As cryo-electron tomography can only acquire a limited number of projections to avoid hardware limitations and damage to biological samples, it can be used in conjunction with compressed sensing techniques and regularisation functions (e.g. Huber loss) to improve the reconstruction for better interpretation.", "token2charspan": [[0, 2], [3, 7], [7, 16], [17, 27], [28, 31], [32, 36], [37, 44], [45, 46], [47, 54], [55, 61], [62, 64], [65, 76], [77, 79], [80, 85], [86, 94], [95, 106], [107, 110], [111, 117], [118, 120], [121, 131], [132, 139], [139, 140], [141, 143], [144, 147], [148, 150], [151, 155], [156, 158], [159, 170], [171, 175], [176, 186], [187, 194], [195, 205], [206, 209], [210, 224], [225, 234], [235, 236], [236, 240], [241, 246], [247, 251], [251, 252], [253, 255], [256, 263], [264, 267], [268, 282], [283, 286], [287, 293], [294, 308], [308, 309]]}
{"doc_key": "ai-dev-17", "ner": [[5, 5, "misc"], [1, 3, "programlang"], [10, 11, "algorithm"], [13, 14, "algorithm"], [8, 19, "algorithm"], [22, 25, "product"], [26, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 5, 1, 3, "part-of", "", false, false], [10, 11, 5, 5, "type-of", "", false, false], [13, 14, 5, 5, "type-of", "", false, false], [8, 19, 5, 5, "type-of", "", false, false], [22, 25, 1, 3, "general-affiliation", "", true, false], [22, 25, 1, 3, "part-of", "", true, false], [26, 28, 22, 25, "role", "publishes", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Implementations", "in", "R", "of", "several", "whitening", "methods", ",", "such", "as", "ZCA", "whitening", ",", "PCA", "whitening", "and", "CCA", "whitening", ",", "are", "available", "in", "the", "whitening", "R", "package", "published", "in", "CRAN", "."], "sentence-detokenized": "Implementations in R of several whitening methods, such as ZCA whitening, PCA whitening and CCA whitening, are available in the whitening R package published in CRAN.", "token2charspan": [[0, 15], [16, 18], [19, 20], [21, 23], [24, 31], [32, 41], [42, 49], [49, 50], [51, 55], [56, 58], [59, 62], [63, 72], [72, 73], [74, 77], [78, 87], [88, 91], [92, 95], [96, 105], [105, 106], [107, 110], [111, 120], [121, 123], [124, 127], [128, 137], [138, 139], [140, 147], [148, 157], [158, 160], [161, 165], [165, 166]]}
{"doc_key": "ai-dev-18", "ner": [[32, 32, "product"], [34, 34, "product"], [36, 36, "product"], [38, 39, "product"], [41, 42, "programlang"]], "ner_mapping_to_source": [2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Today", ",", "the", "field", "has", "become", "even", "more", "challenging", "and", "complex", "with", "the", "addition", "of", "circuit", ",", "system", "and", "signal", "analysis", "and", "design", "languages", "and", "software", ",", "from", "MATLAB", "and", "Simulink", "to", "NumPy", ",", "VHDL", ",", "PSpice", ",", "Verilog", "and", "even", "assembly", "language", "."], "sentence-detokenized": "Today, the field has become even more challenging and complex with the addition of circuit, system and signal analysis and design languages and software, from MATLAB and Simulink to NumPy, VHDL, PSpice, Verilog and even assembly language.", "token2charspan": [[0, 5], [5, 6], [7, 10], [11, 16], [17, 20], [21, 27], [28, 32], [33, 37], [38, 49], [50, 53], [54, 61], [62, 66], [67, 70], [71, 79], [80, 82], [83, 90], [90, 91], [92, 98], [99, 102], [103, 109], [110, 118], [119, 122], [123, 129], [130, 139], [140, 143], [144, 152], [152, 153], [154, 158], [159, 165], [166, 169], [170, 178], [179, 181], [182, 187], [187, 188], [189, 193], [193, 194], [195, 201], [201, 202], [203, 210], [211, 214], [215, 219], [220, 228], [229, 237], [237, 238]]}
{"doc_key": "ai-dev-19", "ner": [[7, 8, "person"], [13, 14, "person"], [18, 22, "organisation"], [23, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[18, 22, 13, 14, "origin", "", false, false], [23, 24, 18, 22, "artifact", "builds", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "company", "was", "established", "in", "1937", "by", "Kiichiro", "Toyoda", ",", "spun", "off", "from", "Sakichi", "Toyoda", "'s", "company", ",", "Toyoda", "Automatic", "Loom", ",", "to", "make", "cars", "."], "sentence-detokenized": "The company was established in 1937 by Kiichiro Toyoda, spun off from Sakichi Toyoda's company, Toyoda Automatic Loom, to make cars.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 27], [28, 30], [31, 35], [36, 38], [39, 47], [48, 54], [54, 55], [56, 60], [61, 64], [65, 69], [70, 77], [78, 84], [84, 86], [87, 94], [94, 95], [96, 102], [103, 112], [113, 117], [117, 118], [119, 121], [122, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-dev-20", "ner": [[0, 6, "field"], [36, 36, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[36, 36, 0, 6, "origin", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Unsupervised", "learning", ",", "on", "the", "other", "hand", ",", "assumes", "unlabelled", "training", "data", ",", "attempts", "to", "find", "patterns", "inherent", "in", "the", "data", "and", "uses", "them", "to", "determine", "the", "correct", "output", "values", "for", "a", "new", "data", "instance", ".", "Semi-supervised", "learning", "uses", "a", "combination", "of", "labelled", "and", "unlabelled", "data", "(", "usually", "a", "combination", "of", "a", "small", "number", "of", "labelled", "data", "and", "a", "large", "amount", "of", "unlabelled", "data", ")", "."], "sentence-detokenized": "Unsupervised learning, on the other hand, assumes unlabelled training data, attempts to find patterns inherent in the data and uses them to determine the correct output values for a new data instance. Semi-supervised learning uses a combination of labelled and unlabelled data (usually a combination of a small number of labelled data and a large amount of unlabelled data).", "token2charspan": [[0, 12], [13, 21], [21, 22], [23, 25], [26, 29], [30, 35], [36, 40], [40, 41], [42, 49], [50, 60], [61, 69], [70, 74], [74, 75], [76, 84], [85, 87], [88, 92], [93, 101], [102, 110], [111, 113], [114, 117], [118, 122], [123, 126], [127, 131], [132, 136], [137, 139], [140, 149], [150, 153], [154, 161], [162, 168], [169, 175], [176, 179], [180, 181], [182, 185], [186, 190], [191, 199], [199, 200], [201, 216], [217, 225], [226, 230], [231, 232], [233, 244], [245, 247], [248, 256], [257, 260], [261, 271], [272, 276], [277, 278], [278, 285], [286, 287], [288, 299], [300, 302], [303, 304], [305, 310], [311, 317], [318, 320], [321, 329], [330, 334], [335, 338], [339, 340], [341, 346], [347, 353], [354, 356], [357, 367], [368, 372], [372, 373], [373, 374]]}
{"doc_key": "ai-dev-21", "ner": [[13, 13, "organisation"], [17, 17, "organisation"], [20, 24, "product"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[17, 17, 20, 24, "artifact", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["While", "some", "of", "these", "humanoid", "robots", "are", "practical", ",", "others", ",", "such", "as", "Sony", "'s", "QRIO", "and", "Wow", "Wee", "'s", "RoboSapien", ",", "are", "designed", "for", "entertainment", "purposes", "."], "sentence-detokenized": "While some of these humanoid robots are practical, others, such as Sony's QRIO and Wow Wee's RoboSapien, are designed for entertainment purposes.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 19], [20, 28], [29, 35], [36, 39], [40, 49], [49, 50], [51, 57], [57, 58], [59, 63], [64, 66], [67, 71], [71, 73], [74, 78], [79, 82], [83, 86], [87, 90], [90, 92], [93, 103], [103, 104], [105, 108], [109, 117], [118, 121], [122, 135], [136, 144], [144, 145]]}
{"doc_key": "ai-dev-22", "ner": [[0, 0, "researcher"], [6, 10, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 10, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Weber", "became", "a", "Fellow", "of", "the", "Society", "for", "Artificial", "Intelligence", "in", "1991", "."], "sentence-detokenized": "Weber became a Fellow of the Society for Artificial Intelligence in 1991.", "token2charspan": [[0, 5], [6, 12], [13, 14], [15, 21], [22, 24], [25, 28], [29, 36], [37, 40], [41, 51], [52, 64], [65, 67], [68, 72], [72, 73]]}
{"doc_key": "ai-dev-23", "ner": [[9, 9, "field"], [12, 12, "field"], [21, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 24, 9, 9, "part-of", "task_part_of_field", false, false], [21, 24, 12, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "company", "was", "developing", "high", "-", "level", "ontologies", "for", "data", "mining", "and", "database", "technologies", ",", "and", "more", "specifically", "for", "intelligence", "and", "automatic", "natural", "language", "understanding", "."], "sentence-detokenized": "The company was developing high-level ontologies for data mining and database technologies, and more specifically for intelligence and automatic natural language understanding.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 26], [27, 31], [31, 32], [32, 37], [38, 48], [49, 52], [53, 57], [58, 64], [65, 68], [69, 77], [78, 90], [90, 91], [92, 95], [96, 100], [101, 113], [114, 117], [118, 130], [131, 134], [135, 144], [145, 152], [153, 161], [162, 175], [175, 176]]}
{"doc_key": "ai-dev-24", "ner": [[23, 25, "misc"], [29, 32, "misc"], [34, 35, "misc"], [26, 26, "country"], [38, 38, "organisation"], [41, 41, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[23, 25, 26, 26, "physical", "", false, false], [29, 32, 26, 26, "physical", "", false, false], [34, 35, 26, 26, "physical", "", false, false], [38, 38, 41, 41, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["However", ",", "the", "last", "few", "years", "have", "seen", "the", "emergence", "of", "various", "e-services", "and", "related", "initiatives", "in", "developing", "countries", ",", "such", "as", "the", "Nenmadi", "project", "in", "India", ",", "the", "MCA21", "Mission", "Mode", "project", ",", "Digital", "India", "and", "the", "e-Government", "Authority", "of", "Pakistan", "."], "sentence-detokenized": "However, the last few years have seen the emergence of various e-services and related initiatives in developing countries, such as the Nenmadi project in India, the MCA21 Mission Mode project, Digital India and the e-Government Authority of Pakistan.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 17], [18, 21], [22, 27], [28, 32], [33, 37], [38, 41], [42, 51], [52, 54], [55, 62], [63, 73], [74, 77], [78, 85], [86, 97], [98, 100], [101, 111], [112, 121], [121, 122], [123, 127], [128, 130], [131, 134], [135, 142], [143, 150], [151, 153], [154, 159], [159, 160], [161, 164], [165, 170], [171, 178], [179, 183], [184, 191], [191, 192], [193, 200], [201, 206], [207, 210], [211, 214], [215, 227], [228, 237], [238, 240], [241, 249], [249, 250]]}
{"doc_key": "ai-dev-25", "ner": [[0, 1, "misc"], [2, 3, "field"], [5, 5, "field"], [11, 13, "university"], [14, 23, "university"], [28, 28, "misc"], [32, 34, "field"], [30, 31, "misc"], [35, 35, "university"], [38, 41, "university"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 2, 3, "topic", "", false, false], [0, 1, 5, 5, "topic", "", false, false], [28, 28, 32, 34, "topic", "", false, false], [28, 28, 35, 35, "origin", "", false, false], [30, 31, 35, 35, "origin", "", false, false], [35, 35, 38, 41, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 5, 6, 7, 8], "sentence": ["D.", "in", "radio", "physics", "and", "electronics", "from", "Rajabazar", "Science", "College", ",", "University", "of", "Calcutta", ",", "as", "a", "student", "of", "the", "Indian", "Statistical", "Institute", "in", "1979", ",", "and", "a", "PhD", "and", "diploma", "in", "electrical", "engineering", "from", "Imperial", "College", ",", "University", "of", "London", "in", "1982", "."], "sentence-detokenized": "D. in radio physics and electronics from Rajabazar Science College, University of Calcutta, as a student of the Indian Statistical Institute in 1979, and a PhD and diploma in electrical engineering from Imperial College, University of London in 1982.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 19], [20, 23], [24, 35], [36, 40], [41, 50], [51, 58], [59, 66], [66, 67], [68, 78], [79, 81], [82, 90], [90, 91], [92, 94], [95, 96], [97, 104], [105, 107], [108, 111], [112, 118], [119, 130], [131, 140], [141, 143], [144, 148], [148, 149], [150, 153], [154, 155], [156, 159], [160, 163], [164, 171], [172, 174], [175, 185], [186, 197], [198, 202], [203, 211], [212, 219], [219, 220], [221, 231], [232, 234], [235, 241], [242, 244], [245, 249], [249, 250]]}
{"doc_key": "ai-dev-26", "ner": [[0, 1, "location"], [14, 16, "misc"], [23, 23, "misc"], [25, 27, "person"], [13, 30, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 16, 0, 1, "temporal", "", false, false], [23, 23, 0, 1, "temporal", "", false, false], [25, 27, 23, 23, "role", "actor_in", false, false], [13, 30, 23, 23, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Expo", "II", "announced", "the", "world", "premieres", "of", "previously", "unseen", "films", "in", "3D", ",", "including", "The", "Diamond", "Wizard", "and", "Universal", "'s", "short", "film", "Hawaiian", "Nights", "with", "Mamie", "Van", "Doren", "and", "Pinky", "Lee", "."], "sentence-detokenized": "Expo II announced the world premieres of previously unseen films in 3D, including The Diamond Wizard and Universal's short film Hawaiian Nights with Mamie Van Doren and Pinky Lee.", "token2charspan": [[0, 4], [5, 7], [8, 17], [18, 21], [22, 27], [28, 37], [38, 40], [41, 51], [52, 58], [59, 64], [65, 67], [68, 70], [70, 71], [72, 81], [82, 85], [86, 93], [94, 100], [101, 104], [105, 114], [114, 116], [117, 122], [123, 127], [128, 136], [137, 143], [144, 148], [149, 154], [155, 158], [159, 164], [165, 168], [169, 174], [175, 178], [178, 179]]}
{"doc_key": "ai-dev-27", "ner": [[7, 9, "researcher"], [16, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 9, 16, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "maximum", "sub-array", "problem", "was", "proposed", "by", "Ulf", "Grenander", "in", "1977", "as", "a", "simplified", "model", "for", "maximum", "likelihood", "estimation", "of", "patterns", "in", "digital", "images", "."], "sentence-detokenized": "The maximum sub-array problem was proposed by Ulf Grenander in 1977 as a simplified model for maximum likelihood estimation of patterns in digital images.", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 29], [30, 33], [34, 42], [43, 45], [46, 49], [50, 59], [60, 62], [63, 67], [68, 70], [71, 72], [73, 83], [84, 89], [90, 93], [94, 101], [102, 112], [113, 123], [124, 126], [127, 135], [136, 138], [139, 146], [147, 153], [153, 154]]}
{"doc_key": "ai-dev-28", "ner": [[0, 2, "product"], [4, 5, "product"], [7, 9, "product"], [12, 12, "product"], [14, 16, "product"], [18, 22, "product"], [28, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[28, 28, 0, 2, "part-of", "", false, false], [28, 28, 4, 5, "part-of", "", false, false], [28, 28, 7, 9, "part-of", "", false, false], [28, 28, 12, 12, "part-of", "", false, false], [28, 28, 14, 16, "part-of", "", false, false], [28, 28, 18, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "iPhone", "4S", ",", "iPad", "3", ",", "iPad", "Mini", "1G", ",", "iPad", "Air", ",", "iPad", "Pro", "1G", "and", "iPod", "Touch", "5", "G", "and", "later", "have", "the", "more", "advanced", "Siri", "voice", "assistant", "."], "sentence-detokenized": "The iPhone 4S, iPad 3, iPad Mini 1G, iPad Air, iPad Pro 1G and iPod Touch 5G and later have the more advanced Siri voice assistant.", "token2charspan": [[0, 3], [4, 10], [11, 13], [13, 14], [15, 19], [20, 21], [21, 22], [23, 27], [28, 32], [33, 35], [35, 36], [37, 41], [42, 45], [45, 46], [47, 51], [52, 55], [56, 58], [59, 62], [63, 67], [68, 73], [74, 75], [75, 76], [77, 80], [81, 86], [87, 91], [92, 95], [96, 100], [101, 109], [110, 114], [115, 120], [121, 130], [130, 131]]}
{"doc_key": "ai-dev-29", "ner": [[9, 12, "metrics"], [14, 17, "metrics"], [35, 40, "metrics"], [45, 50, "metrics"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[9, 12, 35, 40, "named", "", false, false], [14, 17, 9, 12, "named", "", false, false], [35, 40, 45, 50, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["It", "is", "easy", "to", "verify", "that", "logistic", "loss", "and", "binary", "cross", "-entropy", "loss", "(", "Log", "loss", ")", "are", "in", "fact", "the", "same", "(", "up", "to", "a", "multiplication", "constant", "math", "frac", "{", "1", "}", ")", ".", "{", "Cross", "-", "entropy", "loss", "is", "closely", "related", "to", "the", "Kullback", "-", "Leibler", "divergence", "between", "the", "empirical", "and", "predictive", "distributions", "."], "sentence-detokenized": "It is easy to verify that logistic loss and binary cross-entropy loss (Log loss) are in fact the same (up to a multiplication constant math frac {1}). {Cross-entropy loss is closely related to the Kullback-Leibler divergence between the empirical and predictive distributions.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 13], [14, 20], [21, 25], [26, 34], [35, 39], [40, 43], [44, 50], [51, 56], [56, 64], [65, 69], [70, 71], [71, 74], [75, 79], [79, 80], [81, 84], [85, 87], [88, 92], [93, 96], [97, 101], [102, 103], [103, 105], [106, 108], [109, 110], [111, 125], [126, 134], [135, 139], [140, 144], [145, 146], [146, 147], [147, 148], [148, 149], [149, 150], [151, 152], [152, 157], [157, 158], [158, 165], [166, 170], [171, 173], [174, 181], [182, 189], [190, 192], [193, 196], [197, 205], [205, 206], [206, 213], [214, 224], [225, 232], [233, 236], [237, 246], [247, 250], [251, 261], [262, 275], [275, 276]]}
{"doc_key": "ai-dev-30", "ner": [[0, 2, "algorithm"], [11, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "EM", "algorithm", "is", "used", "to", "find", "the", "(", "local", ")", "maximum", "likelihood", "parameters", "of", "a", "statistical", "model", "when", "the", "equations", "can", "not", "be", "solved", "directly", "."], "sentence-detokenized": "The EM algorithm is used to find the (local) maximum likelihood parameters of a statistical model when the equations cannot be solved directly.", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 19], [20, 24], [25, 27], [28, 32], [33, 36], [37, 38], [38, 43], [43, 44], [45, 52], [53, 63], [64, 74], [75, 77], [78, 79], [80, 91], [92, 97], [98, 102], [103, 106], [107, 116], [117, 120], [120, 123], [124, 126], [127, 133], [134, 142], [142, 143]]}
{"doc_key": "ai-dev-31", "ner": [[7, 8, "task"], [11, 15, "task"], [19, 20, "task"], [22, 23, "task"], [27, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "research", "provided", "the", "basis", "for", "modern", "speech", "synthesis", "technology", ",", "reading", "machines", "for", "the", "blind", ",", "research", "into", "speech", "perception", "and", "speech", "recognition", ",", "and", "the", "development", "of", "a", "motor", "theory", "of", "speech", "perception", "."], "sentence-detokenized": "This research provided the basis for modern speech synthesis technology, reading machines for the blind, research into speech perception and speech recognition, and the development of a motor theory of speech perception.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 26], [27, 32], [33, 36], [37, 43], [44, 50], [51, 60], [61, 71], [71, 72], [73, 80], [81, 89], [90, 93], [94, 97], [98, 103], [103, 104], [105, 113], [114, 118], [119, 125], [126, 136], [137, 140], [141, 147], [148, 159], [159, 160], [161, 164], [165, 168], [169, 180], [181, 183], [184, 185], [186, 191], [192, 198], [199, 201], [202, 208], [209, 219], [219, 220]]}
{"doc_key": "ai-dev-32", "ner": [[0, 1, "product"], [2, 6, "misc"], [8, 20, "misc"], [14, 14, "product"], [16, 16, "product"], [18, 18, "product"], [21, 24, "programlang"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Arduino", "Integrated", "Development", "Environment", "(", "IDE", ")", "is", "a", "cross", "-platform", "(", "for", "Windows", ",", "macOS", "and", "Linux", ")", "application", "written", "in", "the", "Java", "programming", "language", "."], "sentence-detokenized": "The Arduino Integrated Development Environment (IDE) is a cross-platform (for Windows, macOS and Linux) application written in the Java programming language.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 34], [35, 46], [47, 48], [48, 51], [51, 52], [53, 55], [56, 57], [58, 63], [63, 72], [73, 74], [74, 77], [78, 85], [85, 86], [87, 92], [93, 96], [97, 102], [102, 103], [104, 115], [116, 123], [124, 126], [127, 130], [131, 135], [136, 147], [148, 156], [156, 157]]}
{"doc_key": "ai-dev-33", "ner": [[0, 1, "algorithm"], [8, 9, "field"], [12, 12, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 8, 9, "opposite", "", false, false], [12, 12, 8, 9, "related-to", "works_with", false, false], [15, 16, 8, 9, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Neural", "network", "research", "stagnated", "after", "the", "publication", "of", "machine", "learning", "research", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", "."], "sentence-detokenized": "Neural network research stagnated after the publication of machine learning research by Marvin Minsky and Seymour Papert (1969).", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 33], [34, 39], [40, 43], [44, 55], [56, 58], [59, 66], [67, 75], [76, 84], [85, 87], [88, 94], [95, 101], [102, 105], [106, 113], [114, 120], [121, 122], [122, 126], [126, 127], [127, 128]]}
{"doc_key": "ai-dev-34", "ner": [[18, 19, "organisation"], [21, 21, "organisation"], [27, 27, "country"], [23, 26, "organisation"], [34, 34, "country"], [31, 33, "organisation"], [36, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 8], "relations": [[23, 26, 27, 27, "general-affiliation", "", false, false], [31, 33, 34, 34, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["In", "the", "end", ",", "only", "a", "few", "non-Japanese", "companies", "managed", "to", "survive", "in", "this", "market", ".", "They", "include", "Adept", "Technology", ",", "St\u00e4ubli", ",", "ABB", "Asea", "Braunboberri", "from", "Sweden", "and", "Switzerland", ",", "KUKA", "Robotics", "from", "Germany", "and", "Comau", "from", "Italy", "."], "sentence-detokenized": "In the end, only a few non-Japanese companies managed to survive in this market. They include Adept Technology, St\u00e4ubli, ABB Asea Braunboberri from Sweden and Switzerland, KUKA Robotics from Germany and Comau from Italy.", "token2charspan": [[0, 2], [3, 6], [7, 10], [10, 11], [12, 16], [17, 18], [19, 22], [23, 35], [36, 45], [46, 53], [54, 56], [57, 64], [65, 67], [68, 72], [73, 79], [79, 80], [81, 85], [86, 93], [94, 99], [100, 110], [110, 111], [112, 119], [119, 120], [121, 124], [125, 129], [130, 142], [143, 147], [148, 154], [155, 158], [159, 170], [170, 171], [172, 176], [177, 185], [186, 190], [191, 198], [199, 202], [203, 208], [209, 213], [214, 219], [219, 220]]}
{"doc_key": "ai-dev-35", "ner": [[9, 11, "conference"], [13, 18, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 18, 9, 11, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Research", "activities", "include", "an", "annual", "research", "meeting", ",", "the", "Rules", "ML", "Symposium", "(", "also", "known", "as", "Rules", "ML", "for", "short", ")", "."], "sentence-detokenized": "Research activities include an annual research meeting, the Rules ML Symposium (also known as Rules ML for short).", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 30], [31, 37], [38, 46], [47, 54], [54, 55], [56, 59], [60, 65], [66, 68], [69, 78], [79, 80], [80, 84], [85, 90], [91, 93], [94, 99], [100, 102], [103, 106], [107, 112], [112, 113], [113, 114]]}
{"doc_key": "ai-dev-36", "ner": [[12, 12, "field"], [14, 15, "field"], [17, 17, "field"], [9, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Concepts", "are", "used", "as", "formal", "tools", "and", "models", "in", "fields", "such", "as", "mathematics", ",", "computer", "science", ",", "databases", "and", "artificial", "intelligence", ",", "and", "are", "sometimes", "referred", "to", "as", "classes", ",", "schemas", "or", "categories", "."], "sentence-detokenized": "Concepts are used as formal tools and models in fields such as mathematics, computer science, databases and artificial intelligence, and are sometimes referred to as classes, schemas or categories.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 20], [21, 27], [28, 33], [34, 37], [38, 44], [45, 47], [48, 54], [55, 59], [60, 62], [63, 74], [74, 75], [76, 84], [85, 92], [92, 93], [94, 103], [104, 107], [108, 118], [119, 131], [131, 132], [133, 136], [137, 140], [141, 150], [151, 159], [160, 162], [163, 165], [166, 173], [173, 174], [175, 182], [183, 185], [186, 196], [196, 197]]}
{"doc_key": "ai-dev-37", "ner": [[6, 8, "organisation"], [11, 14, "organisation"], [17, 17, "organisation"], [19, 21, "organisation"], [24, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "received", "awards", "from", "the", "American", "Psychological", "Association", ",", "the", "National", "Academy", "of", "Sciences", ",", "the", "Royal", "and", "Cognitive", "Neuroscience", "Society", "and", "the", "American", "Humanist", "Association", "."], "sentence-detokenized": "He has received awards from the American Psychological Association, the National Academy of Sciences, the Royal and Cognitive Neuroscience Society and the American Humanist Association.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 22], [23, 27], [28, 31], [32, 40], [41, 54], [55, 66], [66, 67], [68, 71], [72, 80], [81, 88], [89, 91], [92, 100], [100, 101], [102, 105], [106, 111], [112, 115], [116, 125], [126, 138], [139, 146], [147, 150], [151, 154], [155, 163], [164, 172], [173, 184], [184, 185]]}
{"doc_key": "ai-dev-38", "ner": [[1, 11, "person"], [4, 5, "person"], [7, 10, "person"], [16, 17, "person"], [21, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 26, 16, 17, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Starring", "Harrison", "Ford", ",", "Rutger", "Hauer", "and", "Sean", "Young", ",", "the", "film", "is", "loosely", "based", "on", "Philip", "K", "Dick", "'s", "novel", "Do", "Androids", "Dream", "of", "Electric", "Sheep", "(", "1968", ")", "."], "sentence-detokenized": "Starring Harrison Ford, Rutger Hauer and Sean Young, the film is loosely based on Philip K Dick's novel Do Androids Dream of Electric Sheep (1968).", "token2charspan": [[0, 8], [9, 17], [18, 22], [22, 23], [24, 30], [31, 36], [37, 40], [41, 45], [46, 51], [51, 52], [53, 56], [57, 61], [62, 64], [65, 72], [73, 78], [79, 81], [82, 88], [89, 90], [91, 95], [95, 97], [98, 103], [104, 106], [107, 115], [116, 121], [122, 124], [125, 133], [134, 139], [140, 141], [141, 145], [145, 146], [146, 147]]}
{"doc_key": "ai-dev-39", "ner": [[0, 1, "task"], [4, 7, "algorithm"], [12, 13, "field"], [15, 16, "task"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 4, 7, "usage", "", false, false], [0, 1, 12, 13, "part-of", "task_part_of_field", false, false], [0, 1, 15, 16, "part-of", "task_part_of_field", false, false], [0, 1, 18, 19, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Image", "segmentation", "using", "the", "k-means", "clustering", "algorithm", "has", "long", "been", "used", "for", "pattern", "recognition", ",", "object", "detection", "and", "medical", "imaging", "."], "sentence-detokenized": "Image segmentation using the k-means clustering algorithm has long been used for pattern recognition, object detection and medical imaging.", "token2charspan": [[0, 5], [6, 18], [19, 24], [25, 28], [29, 36], [37, 47], [48, 57], [58, 61], [62, 66], [67, 71], [72, 76], [77, 80], [81, 88], [89, 100], [100, 101], [102, 108], [109, 118], [119, 122], [123, 130], [131, 138], [138, 139]]}
{"doc_key": "ai-dev-40", "ner": [[13, 14, "algorithm"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["General", "sampling", "from", "truncated", "normal", "form", "can", "be", "achieved", "using", "normal", "CDF", "and", "probit", "function", "approximations", ",", "and", "R", "has", "a", "function", "codertnorm", "(", ")", "/", "code", "that", "generates", "samples", "of", "truncated", "normal", "form", "."], "sentence-detokenized": "General sampling from truncated normal form can be achieved using normal CDF and probit function approximations, and R has a function codertnorm () / code that generates samples of truncated normal form.", "token2charspan": [[0, 7], [8, 16], [17, 21], [22, 31], [32, 38], [39, 43], [44, 47], [48, 50], [51, 59], [60, 65], [66, 72], [73, 76], [77, 80], [81, 87], [88, 96], [97, 111], [111, 112], [113, 116], [117, 118], [119, 122], [123, 124], [125, 133], [134, 144], [145, 146], [146, 147], [148, 149], [150, 154], [155, 159], [160, 169], [170, 177], [178, 180], [181, 190], [191, 197], [198, 202], [202, 203]]}
{"doc_key": "ai-dev-41", "ner": [[11, 11, "university"], [13, 13, "university"], [15, 16, "university"], [18, 19, "university"], [21, 21, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "also", "been", "awarded", "honorary", "doctorates", "from", "the", "Universities", "of", "Newcastle", ",", "Surrey", ",", "Tel", "Aviv", ",", "Simon", "Fraser", "and", "Troms\u00f8", "."], "sentence-detokenized": "He has also been awarded honorary doctorates from the Universities of Newcastle, Surrey, Tel Aviv, Simon Fraser and Troms\u00f8.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 24], [25, 33], [34, 44], [45, 49], [50, 53], [54, 66], [67, 69], [70, 79], [79, 80], [81, 87], [87, 88], [89, 92], [93, 97], [97, 98], [99, 104], [105, 111], [112, 115], [116, 122], [122, 123]]}
{"doc_key": "ai-dev-42", "ner": [[0, 0, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Java", "implementation", "using", "zero", "-", "based", "array", "indexes", "and", "a", "convenience", "method", "to", "display", "the", "order", "of", "operations", "resolved", "."], "sentence-detokenized": "Java implementation using zero-based array indexes and a convenience method to display the order of operations resolved.", "token2charspan": [[0, 4], [5, 19], [20, 25], [26, 30], [30, 31], [31, 36], [37, 42], [43, 50], [51, 54], [55, 56], [57, 68], [69, 75], [76, 78], [79, 86], [87, 90], [91, 96], [97, 99], [100, 110], [111, 119], [119, 120]]}
{"doc_key": "ai-dev-43", "ner": [[8, 8, "metrics"], [7, 12, "metrics"], [21, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 12, 8, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Such", "networks", "are", "typically", "trained", "in", "a", "cross", "-entropy", "(", "or", "cross", "-entropy", ")", "regime", ",", "giving", "a", "non-linear", "variant", "of", "multinomial", "logistic", "regression", "."], "sentence-detokenized": "Such networks are typically trained in a cross-entropy (or cross-entropy) regime, giving a non-linear variant of multinomial logistic regression.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 27], [28, 35], [36, 38], [39, 40], [41, 46], [46, 54], [55, 56], [56, 58], [59, 64], [64, 72], [72, 73], [74, 80], [80, 81], [82, 88], [89, 90], [91, 101], [102, 109], [110, 112], [113, 124], [125, 133], [134, 144], [144, 145]]}
{"doc_key": "ai-dev-44", "ner": [[4, 4, "misc"], [6, 13, "conference"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "ACL", "has", "a", "European", "(", "European", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ")", "."], "sentence-detokenized": "The ACL has a European (European Chapter of the Association for Computational Linguistics).", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 13], [14, 22], [23, 24], [24, 32], [33, 40], [41, 43], [44, 47], [48, 59], [60, 63], [64, 77], [78, 89], [89, 90], [90, 91]]}
{"doc_key": "ai-dev-45", "ner": [[3, 3, "researcher"], [6, 8, "researcher"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Two", "professors", ",", "Hal", "Abelson", "and", "Gerald", "Jay", "Sussman", ",", "chose", "a", "neutral", "position", "."], "sentence-detokenized": "Two professors, Hal Abelson and Gerald Jay Sussman, chose a neutral position.", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 27], [28, 31], [32, 38], [39, 42], [43, 50], [50, 51], [52, 57], [58, 59], [60, 67], [68, 76], [76, 77]]}
{"doc_key": "ai-dev-46", "ner": [[0, 3, "misc"], [14, 17, "university"], [21, 23, "organisation"], [9, 13, "organisation"], [30, 31, "researcher"]], "ner_mapping_to_source": [0, 2, 3, 4, 5], "relations": [[9, 13, 14, 17, "part-of", "", false, false], [30, 31, 9, 13, "role", "", false, false]], "relations_mapping_to_source": [4, 5], "sentence": ["After", "completing", "his", "PhD", ",", "he", "moved", "to", "the", "Artificial", "Intelligence", "Laboratory", "at", "the", "University", "of", "Toronto", "in", "1995", "as", "an", "ITRC", "Postdoctoral", "Research", "Fellow", ",", "where", "he", "collaborated", "with", "Geoffrey", "Hinton", "."], "sentence-detokenized": "After completing his PhD, he moved to the Artificial Intelligence Laboratory at the University of Toronto in 1995 as an ITRC Postdoctoral Research Fellow, where he collaborated with Geoffrey Hinton.", "token2charspan": [[0, 5], [6, 16], [17, 20], [21, 24], [24, 25], [26, 28], [29, 34], [35, 37], [38, 41], [42, 52], [53, 65], [66, 76], [77, 79], [80, 83], [84, 94], [95, 97], [98, 105], [106, 108], [109, 113], [114, 116], [117, 119], [120, 124], [125, 137], [138, 146], [147, 153], [153, 154], [155, 160], [161, 163], [164, 176], [177, 181], [182, 190], [191, 197], [197, 198]]}
{"doc_key": "ai-dev-47", "ner": [[24, 27, "metrics"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Subsequently", ",", "research", "was", "conducted", "to", "solve", "these", "problems", ",", "but", "it", "was", "not", "until", "the", "advent", "of", "modern", "computers", "and", "the", "popularisation", "of", "maximum", "likelihood", "(", "MLE", ")", "parameterisation", "techniques", "that", "research", "began", "in", "earnest", "."], "sentence-detokenized": "Subsequently, research was conducted to solve these problems, but it was not until the advent of modern computers and the popularisation of maximum likelihood (MLE) parameterisation techniques that research began in earnest.", "token2charspan": [[0, 12], [12, 13], [14, 22], [23, 26], [27, 36], [37, 39], [40, 45], [46, 51], [52, 60], [60, 61], [62, 65], [66, 68], [69, 72], [73, 76], [77, 82], [83, 86], [87, 93], [94, 96], [97, 103], [104, 113], [114, 117], [118, 121], [122, 136], [137, 139], [140, 147], [148, 158], [159, 160], [160, 163], [163, 164], [165, 181], [182, 192], [193, 197], [198, 206], [207, 212], [213, 215], [216, 223], [223, 224]]}
{"doc_key": "ai-dev-48", "ner": [[4, 6, "person"], [8, 10, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "series", "was", "produced", "by", "David", "Fincher", "and", "starred", "Kevin", "Spacey", "."], "sentence-detokenized": "The series was produced by David Fincher and starred Kevin Spacey.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 26], [27, 32], [33, 40], [41, 44], [45, 52], [53, 58], [59, 65], [65, 66]]}
{"doc_key": "ai-dev-49", "ner": [[0, 11, "algorithm"], [14, 16, "algorithm"]], "ner_mapping_to_source": [1, 2], "relations": [[0, 11, 14, 16, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "example", "is", "the", "use", "of", "fast", "protein", "docking", "methods", "instead", "of", "computationally", "expensive", "free", "energy", "calculations", "."], "sentence-detokenized": "An example is the use of fast protein docking methods instead of computationally expensive free energy calculations.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 17], [18, 21], [22, 24], [25, 29], [30, 37], [38, 45], [46, 53], [54, 61], [62, 64], [65, 80], [81, 90], [91, 95], [96, 102], [103, 115], [115, 116]]}
{"doc_key": "ai-dev-50", "ner": [[8, 8, "country"], [10, 10, "country"], [12, 12, "country"], [14, 14, "country"], [16, 16, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "had", "more", "than", "30", "shops", "in", "the", "USA", ",", "Canada", ",", "Mexico", ",", "Brazil", "and", "Argentina", "."], "sentence-detokenized": "It had more than 30 shops in the USA, Canada, Mexico, Brazil and Argentina.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 19], [20, 25], [26, 28], [29, 32], [33, 36], [36, 37], [38, 44], [44, 45], [46, 52], [52, 53], [54, 60], [61, 64], [65, 74], [74, 75]]}
{"doc_key": "ai-dev-51", "ner": [[4, 5, "field"], [15, 17, "product"], [10, 14, "algorithm"], [20, 20, "task"], [23, 24, "task"], [30, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[15, 17, 4, 5, "part-of", "", false, false], [15, 17, 10, 14, "usage", "", false, false], [20, 20, 4, 5, "part-of", "task_part_of_field", false, false], [20, 20, 30, 30, "related-to", "performs", false, false], [23, 24, 4, 5, "part-of", "task_part_of_field", false, false], [23, 24, 30, 30, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Example", "of", "a", "typical", "computer", "vision", "computation", "pipeline", "in", "a", "k", "-", "NN", "-", "based", "face", "recognition", "system", ",", "including", "feature", "extraction", "and", "dimensionality", "reduction", "pre-processing", "(", "typically", "implemented", "in", "OpenCV", ")", "."], "sentence-detokenized": "Example of a typical computer vision computation pipeline in a k -NN-based face recognition system, including feature extraction and dimensionality reduction pre-processing (typically implemented in OpenCV).", "token2charspan": [[0, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 36], [37, 48], [49, 57], [58, 60], [61, 62], [63, 64], [65, 66], [66, 68], [68, 69], [69, 74], [75, 79], [80, 91], [92, 98], [98, 99], [100, 109], [110, 117], [118, 128], [129, 132], [133, 147], [148, 157], [158, 172], [173, 174], [174, 183], [184, 195], [196, 198], [199, 205], [205, 206], [206, 207]]}
{"doc_key": "ai-dev-52", "ner": [[5, 7, "algorithm"], [9, 9, "misc"], [11, 12, "misc"], [14, 14, "misc"], [24, 25, "algorithm"], [27, 28, "misc"], [30, 30, "misc"], [34, 34, "misc"], [45, 45, "misc"], [39, 39, "misc"], [42, 44, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 6, 7, 8, 10, 11, 12, 13], "relations": [], "relations_mapping_to_source": [], "sentence": ["Rich", "functionality", ",", "libraries", "for", "constraint", "logic", "programming", ",", "multi-threading", ",", "unit", "tests", ",", "GUI", ",", "interfaces", "to", "Java", ",", "ODBC", ",", "etc.", ",", "literate", "programming", ",", "web", "server", ",", "SGML", ",", "RDF", ",", "RDFS", ",", "developer", "tools", "(", "GUI", "debugger", "and", "GUI", "profiler", "in", "IDE", ")", ",", "with", "extensive", "documentation", "."], "sentence-detokenized": "Rich functionality, libraries for constraint logic programming, multi-threading, unit tests, GUI, interfaces to Java, ODBC, etc., literate programming, web server, SGML, RDF, RDFS, developer tools (GUI debugger and GUI profiler in IDE), with extensive documentation.", "token2charspan": [[0, 4], [5, 18], [18, 19], [20, 29], [30, 33], [34, 44], [45, 50], [51, 62], [62, 63], [64, 79], [79, 80], [81, 85], [86, 91], [91, 92], [93, 96], [96, 97], [98, 108], [109, 111], [112, 116], [116, 117], [118, 122], [122, 123], [124, 128], [128, 129], [130, 138], [139, 150], [150, 151], [152, 155], [156, 162], [162, 163], [164, 168], [168, 169], [170, 173], [173, 174], [175, 179], [179, 180], [181, 190], [191, 196], [197, 198], [198, 201], [202, 210], [211, 214], [215, 218], [219, 227], [228, 230], [231, 234], [234, 235], [235, 236], [237, 241], [242, 251], [252, 265], [265, 266]]}
{"doc_key": "ai-dev-53", "ner": [[0, 1, "field"], [4, 4, "field"], [9, 13, "misc"], [15, 17, "misc"], [18, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 13, 0, 1, "part-of", "", true, false], [9, 13, 4, 4, "part-of", "", false, false], [9, 13, 18, 24, "type-of", "", false, false], [15, 17, 0, 1, "part-of", "", false, false], [15, 17, 4, 4, "part-of", "", false, false], [15, 17, 18, 24, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "computer", "vision", "and", "image", "processing", ",", "the", "concept", "of", "scale", "-", "space", "representation", "and", "Gaussian", "differential", "operators", "are", "treated", "as", "canonical", "multi", "-scale", "representations", "."], "sentence-detokenized": "In computer vision and image processing, the concept of scale-space representation and Gaussian differential operators are treated as canonical multi-scale representations.", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 22], [23, 28], [29, 39], [39, 40], [41, 44], [45, 52], [53, 55], [56, 61], [61, 62], [62, 67], [68, 82], [83, 86], [87, 95], [96, 108], [109, 118], [119, 122], [123, 130], [131, 133], [134, 143], [144, 149], [149, 155], [156, 171], [171, 172]]}
{"doc_key": "ai-dev-54", "ner": [[8, 18, "organisation"], [25, 26, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 18, 25, 26, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "also", "the", "President", "of", "the", "NPO", "Association", "for", "the", "Promotion", "of", "Neural", "Information", "Processing", "Systems", ",", "which", "oversees", "the", "annual", "Neural", "Information", "Processing", "Systems", "Conference", "."], "sentence-detokenized": "He is also the President of the NPO Association for the Promotion of Neural Information Processing Systems, which oversees the annual Neural Information Processing Systems Conference.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 14], [15, 24], [25, 27], [28, 31], [32, 35], [36, 47], [48, 51], [52, 55], [56, 65], [66, 68], [69, 75], [76, 87], [88, 98], [99, 106], [106, 107], [108, 113], [114, 122], [123, 126], [127, 133], [134, 140], [141, 152], [153, 163], [164, 171], [172, 182], [182, 183]]}
{"doc_key": "ai-dev-55", "ner": [[11, 13, "task"], [0, 2, "metrics"], [5, 10, "misc"], [19, 19, "task"], [16, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 13, 0, 2, "usage", "", false, false], [0, 2, 5, 10, "type-of", "", false, false], [19, 19, 16, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "squared", "error", "can", "be", "used", "as", "the", "loss", "function", "in", "regression", "analysis", "problems", "and", "the", "cross", "-entropy", "in", "classification", "problems", "."], "sentence-detokenized": "The squared error can be used as the loss function in regression analysis problems and the cross-entropy in classification problems.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 21], [22, 24], [25, 29], [30, 32], [33, 36], [37, 41], [42, 50], [51, 53], [54, 64], [65, 73], [74, 82], [83, 86], [87, 90], [91, 96], [96, 104], [105, 107], [108, 122], [123, 131], [131, 132]]}
{"doc_key": "ai-dev-56", "ner": [[0, 1, "researcher"], [22, 25, "conference"], [37, 43, "field"], [51, 68, "conference"]], "ner_mapping_to_source": [0, 2, 4, 5], "relations": [[0, 1, 51, 68, "role", "", false, false]], "relations_mapping_to_source": [3], "sentence": ["Rafferty", "has", "held", "a", "number", "of", "prestigious", "positions", ",", "including", ":", "1", ")", "programme", "co-chair", "and", "general", "co-chair", "of", "the", "Conference", "on", "Neural", "Information", "Processing", "Systems", "Foundation", "conference", ";", "2", ")", "co-director", "of", "CMU", "'s", "new", "Machine", "Learning", "PhD", "Co-", "Director", "of", "the", "programme", ";", "3", ")", "Associate", "Editor", "of", "the", "Journal", "of", "Machine", "Learning", "Research", ";", "and", "4", ")", "Associate", "Editor", "of", "the", "Journal", "of", "Machine", "Learning", "Research", "."], "sentence-detokenized": "Rafferty has held a number of prestigious positions, including: 1) programme co-chair and general co-chair of the Conference on Neural Information Processing Systems Foundation conference; 2) co-director of CMU's new Machine Learning PhD Co-Director of the programme; 3) Associate Editor of the Journal of Machine Learning Research; and 4) Associate Editor of the Journal of Machine Learning Research.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 19], [20, 26], [27, 29], [30, 41], [42, 51], [51, 52], [53, 62], [62, 63], [64, 65], [65, 66], [67, 76], [77, 85], [86, 89], [90, 97], [98, 106], [107, 109], [110, 113], [114, 124], [125, 127], [128, 134], [135, 146], [147, 157], [158, 165], [166, 176], [177, 187], [187, 188], [189, 190], [190, 191], [192, 203], [204, 206], [207, 210], [210, 212], [213, 216], [217, 224], [225, 233], [234, 237], [238, 241], [241, 249], [250, 252], [253, 256], [257, 266], [266, 267], [268, 269], [269, 270], [271, 280], [281, 287], [288, 290], [291, 294], [295, 302], [303, 305], [306, 313], [314, 322], [323, 331], [331, 332], [333, 336], [337, 338], [338, 339], [340, 349], [350, 356], [357, 359], [360, 363], [364, 371], [372, 374], [375, 382], [383, 391], [392, 400], [400, 401]]}
{"doc_key": "ai-dev-57", "ner": [[0, 1, "misc"], [6, 7, "algorithm"]], "ner_mapping_to_source": [0, 2], "relations": [[6, 7, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Convex", "algorithms", "such", "as", "AdaBoost", "and", "LogitBoost", "are", "defeated", "by", "random", "noise", "and", "can", "not", "learn", "basic", ",", "trainable", "combinations", "of", "weak", "hypotheses", "."], "sentence-detokenized": "Convex algorithms such as AdaBoost and LogitBoost are defeated by random noise and cannot learn basic, trainable combinations of weak hypotheses.", "token2charspan": [[0, 6], [7, 17], [18, 22], [23, 25], [26, 34], [35, 38], [39, 49], [50, 53], [54, 62], [63, 65], [66, 72], [73, 78], [79, 82], [83, 86], [86, 89], [90, 95], [96, 101], [101, 102], [103, 112], [113, 125], [126, 128], [129, 133], [134, 144], [144, 145]]}
{"doc_key": "ai-dev-58", "ner": [[2, 8, "product"], [11, 18, "algorithm"], [19, 21, "algorithm"], [23, 28, "task"], [30, 32, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[19, 21, 23, 28, "related-to", "used_for", true, false], [19, 21, 30, 32, "related-to", "used_for", true, false]], "relations_mapping_to_source": [3, 4], "sentence": ["Apertium", "is", "a", "shallow", "transfer", "machine", "translation", "system", "that", "uses", "a", "finite", "state", "transducer", "for", "lexical", "transformation", "and", "a", "hidden", "Markov", "model", "for", "part", "-", "of", "-", "speech", "tagging", "and", "word", "category", "disambiguation", "."], "sentence-detokenized": "Apertium is a shallow transfer machine translation system that uses a finite state transducer for lexical transformation and a hidden Markov model for part-of-speech tagging and word category disambiguation.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 21], [22, 30], [31, 38], [39, 50], [51, 57], [58, 62], [63, 67], [68, 69], [70, 76], [77, 82], [83, 93], [94, 97], [98, 105], [106, 120], [121, 124], [125, 126], [127, 133], [134, 140], [141, 146], [147, 150], [151, 155], [155, 156], [156, 158], [158, 159], [159, 165], [166, 173], [174, 177], [178, 182], [183, 191], [192, 206], [206, 207]]}
{"doc_key": "ai-dev-59", "ner": [[0, 3, "misc"], [14, 16, "metrics"], [27, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 14, 16, "related-to", "", true, false], [14, 16, 27, 29, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "natural", "gradient", "of", "mathE", "f", "(", "x", ")", "/", "math", "conforms", "to", "the", "Fisher", "information", "metric", "(", "information", "distance", "measure", "between", "probability", "distributions", ",", "the", "curvature", "of", "relative", "entropy", ")", "and", "is"], "sentence-detokenized": "The natural gradient of mathE f (x) / math conforms to the Fisher information metric (information distance measure between probability distributions, the curvature of relative entropy) and is", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 23], [24, 29], [30, 31], [32, 33], [33, 34], [34, 35], [36, 37], [38, 42], [43, 51], [52, 54], [55, 58], [59, 65], [66, 77], [78, 84], [85, 86], [86, 97], [98, 106], [107, 114], [115, 122], [123, 134], [135, 148], [148, 149], [150, 153], [154, 163], [164, 166], [167, 175], [176, 183], [183, 184], [185, 188], [189, 191]]}
{"doc_key": "ai-dev-60", "ner": [[0, 3, "programlang"], [7, 7, "product"], [12, 12, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 0, 3, "origin", "", false, false], [12, 12, 0, 3, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "programming", "language", "S", "inspired", "the", "systems", "S", "'", "-", "PLUS", "and", "R."], "sentence-detokenized": "The programming language S inspired the systems S '-PLUS and R.", "token2charspan": [[0, 3], [4, 15], [16, 24], [25, 26], [27, 35], [36, 39], [40, 47], [48, 49], [50, 51], [51, 52], [52, 56], [57, 60], [61, 63]]}
{"doc_key": "ai-dev-61", "ner": [[8, 9, "product"], [9, 13, "product"], [17, 19, "researcher"], [21, 22, "researcher"], [24, 25, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[9, 13, 8, 9, "origin", "derived_from", false, false], [9, 13, 17, 19, "origin", "", false, false], [9, 13, 21, 22, "origin", "", false, false], [9, 13, 24, 25, "origin", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4], "sentence": ["The", "most", "influential", "Planner", "implementation", "was", "a", "subset", "of", "Planner", "called", "Micro", "-", "Planner", ",", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "."], "sentence-detokenized": "The most influential Planner implementation was a subset of Planner called Micro-Planner, implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd.", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 28], [29, 43], [44, 47], [48, 49], [50, 56], [57, 59], [60, 67], [68, 74], [75, 80], [80, 81], [81, 88], [88, 89], [90, 101], [102, 104], [105, 111], [112, 115], [116, 123], [123, 124], [125, 131], [132, 140], [141, 144], [145, 150], [151, 159], [159, 160]]}
{"doc_key": "ai-dev-62", "ner": [[6, 6, "country"], [8, 10, "researcher"], [20, 20, "misc"], [18, 28, "university"], [33, 35, "misc"], [38, 39, "misc"], [42, 44, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [[8, 10, 6, 6, "general-affiliation", "from_country", false, false], [18, 28, 20, 20, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "1779", ",", "the", "German", "and", "Danish", "scientist", "Christian", "Gottlieb", "Kratzenstein", "won", "first", "prize", "in", "a", "contest", "presented", "by", "the", "Russian", "Imperial", "Academy", "of", "Sciences", "and", "Arts", "for", "a", "model", "of", "the", "human", "vocal", "tract", "that", "could", "produce", "five", "long", "tones", "(", "International", "Phonetic", "Alphabet", "notation", ")", "."], "sentence-detokenized": "In 1779, the German and Danish scientist Christian Gottlieb Kratzenstein won first prize in a contest presented by the Russian Imperial Academy of Sciences and Arts for a model of the human vocal tract that could produce five long tones (International Phonetic Alphabet notation).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 19], [20, 23], [24, 30], [31, 40], [41, 50], [51, 59], [60, 72], [73, 76], [77, 82], [83, 88], [89, 91], [92, 93], [94, 101], [102, 111], [112, 114], [115, 118], [119, 126], [127, 135], [136, 143], [144, 146], [147, 155], [156, 159], [160, 164], [165, 168], [169, 170], [171, 176], [177, 179], [180, 183], [184, 189], [190, 195], [196, 201], [202, 206], [207, 212], [213, 220], [221, 225], [226, 230], [231, 236], [237, 238], [238, 251], [252, 260], [261, 269], [270, 278], [278, 279], [279, 280]]}
{"doc_key": "ai-dev-63", "ner": [[3, 5, "product"], [6, 9, "misc"], [10, 15, "misc"], [31, 34, "misc"], [52, 53, "task"], [58, 58, "product"], [61, 63, "product"], [65, 65, "task"], [67, 68, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 5, 58, 58, "related-to", "supports_program", false, false], [3, 5, 61, 63, "related-to", "supports_program", false, false], [6, 9, 3, 5, "part-of", "", false, false], [10, 15, 3, 5, "part-of", "", false, false], [31, 34, 3, 5, "part-of", "", false, false], [52, 53, 3, 5, "part-of", "", false, false], [65, 65, 3, 5, "part-of", "", false, false], [67, 68, 3, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["New", "features", "in", "Office", "XP", "include", "Smart", "Tags", ",", "a", "selection", "-", "based", "search", "facility", "that", "recognises", "different", "types", "of", "text", "in", "documents", "so", "that", "users", "can", "perform", "additional", "actions", ";", "Task", "Pane", ",", "which", "consolidates", "popular", "menu", "bar", "commands", "on", "the", "right", "side", "of", "the", "screen", "for", "quick", "access", ";", "new", "document", "collaboration", "features", ",", "support", "for", "MSN", "Groups", "and", "SharePoint", ",", "and", "integrated", "handwriting", "and", "speech", "recognition", "."], "sentence-detokenized": "New features in Office XP include Smart Tags, a selection-based search facility that recognises different types of text in documents so that users can perform additional actions; Task Pane, which consolidates popular menu bar commands on the right side of the screen for quick access; new document collaboration features, support for MSN Groups and SharePoint, and integrated handwriting and speech recognition.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 22], [23, 25], [26, 33], [34, 39], [40, 44], [44, 45], [46, 47], [48, 57], [57, 58], [58, 63], [64, 70], [71, 79], [80, 84], [85, 95], [96, 105], [106, 111], [112, 114], [115, 119], [120, 122], [123, 132], [133, 135], [136, 140], [141, 146], [147, 150], [151, 158], [159, 169], [170, 177], [177, 178], [179, 183], [184, 188], [188, 189], [190, 195], [196, 208], [209, 216], [217, 221], [222, 225], [226, 234], [235, 237], [238, 241], [242, 247], [248, 252], [253, 255], [256, 259], [260, 266], [267, 270], [271, 276], [277, 283], [283, 284], [285, 288], [289, 297], [298, 311], [312, 320], [320, 321], [322, 329], [330, 333], [334, 337], [338, 344], [345, 348], [349, 359], [359, 360], [361, 364], [365, 375], [376, 387], [388, 391], [392, 398], [399, 410], [410, 411]]}
{"doc_key": "ai-dev-64", "ner": [[8, 11, "algorithm"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 11, 12, 13, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "many", "applications", ",", "units", "in", "these", "networks", "apply", "sigmoidal", "functions", "as", "activation", "functions", "."], "sentence-detokenized": "In many applications, units in these networks apply sigmoidal functions as activation functions.", "token2charspan": [[0, 2], [3, 7], [8, 20], [20, 21], [22, 27], [28, 30], [31, 36], [37, 45], [46, 51], [52, 61], [62, 71], [72, 74], [75, 85], [86, 95], [95, 96]]}
{"doc_key": "ai-dev-65", "ner": [[12, 17, "organisation"], [25, 31, "organisation"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2001", ",", "he", "was", "elected", "a", "Foreign", "Honorary", "Member", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "in", "2003", "a", "Fellow", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In 2001, he was elected a Foreign Honorary Member of the American Academy of Arts and Sciences and in 2003 a Fellow of the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 33], [34, 42], [43, 49], [50, 52], [53, 56], [57, 65], [66, 73], [74, 76], [77, 81], [82, 85], [86, 94], [95, 98], [99, 101], [102, 106], [107, 108], [109, 115], [116, 118], [119, 122], [123, 131], [132, 143], [144, 147], [148, 151], [152, 163], [164, 166], [167, 174], [174, 175]]}
{"doc_key": "ai-dev-66", "ner": [[3, 6, "task"], [7, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 6, 7, 10, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Extending", "this", "concept", "to", "non", "-binary", "classification", "yields", "a", "confusion", "matrix", "."], "sentence-detokenized": "Extending this concept to non-binary classification yields a confusion matrix.", "token2charspan": [[0, 9], [10, 14], [15, 22], [23, 25], [26, 29], [29, 36], [37, 51], [52, 58], [59, 60], [61, 70], [71, 77], [77, 78]]}
{"doc_key": "ai-dev-67", "ner": [[9, 10, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Updated", "measurement", "noise", "variance", "estimates", "can", "be", "obtained", "from", "maximum", "likelihood", "calculations"], "sentence-detokenized": "Updated measurement noise variance estimates can be obtained from maximum likelihood calculations", "token2charspan": [[0, 7], [8, 19], [20, 25], [26, 34], [35, 44], [45, 48], [49, 51], [52, 60], [61, 65], [66, 73], [74, 84], [85, 97]]}
{"doc_key": "ai-dev-68", "ner": [[0, 5, "field"], [10, 12, "field"], [13, 14, "task"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[10, 12, 0, 5, "type-of", "", true, false]], "relations_mapping_to_source": [2], "sentence": ["In", "machine", "learning", ",", "the", "perceptron", "is", "an", "algorithm", "for", "supervised", "learning", "of", "binary", "classification", "."], "sentence-detokenized": "In machine learning, the perceptron is an algorithm for supervised learning of binary classification.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 24], [25, 35], [36, 38], [39, 41], [42, 51], [52, 55], [56, 66], [67, 75], [76, 78], [79, 85], [86, 100], [100, 101]]}
{"doc_key": "ai-dev-69", "ner": [[51, 52, "field"], [54, 54, "field"], [0, 22, "conference"], [24, 28, "conference"], [30, 36, "conference"], [38, 42, "conference"], [44, 50, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 22, 51, 52, "topic", "", false, false], [0, 22, 54, 54, "topic", "", false, false], [24, 28, 51, 52, "topic", "", false, false], [24, 28, 54, 54, "topic", "", false, false], [30, 36, 51, 52, "topic", "", false, false], [30, 36, 54, 54, "topic", "", false, false], [38, 42, 51, 52, "topic", "", false, false], [38, 42, 54, 54, "topic", "", false, false], [44, 50, 51, 52, "topic", "", false, false], [44, 50, 54, 54, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["He", "has", "also", "served", "as", "an", "area", "chair", "for", "several", "machine", "learning", "and", "vision", "conferences", ",", "including", "Conference", "on", "Neural", "Information", "Processing", "Systems", ",", "International", "Conference", "on", "Learning", "Representations", ",", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "International", "Conference", "on", "Computer", "Vision", ",", "European", "Conference", "on", "Computer", "Vision", "and", "other", "machine", "learning", "and", "vision", "conferences", "as", "area", "chairs", "."], "sentence-detokenized": "He has also served as an area chair for several machine learning and vision conferences, including Conference on Neural Information Processing Systems, International Conference on Learning Representations, Conference on Computer Vision and Pattern Recognition, International Conference on Computer Vision, European Conference on Computer Vision and other machine learning and vision conferences as area chairs.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 21], [22, 24], [25, 29], [30, 35], [36, 39], [40, 47], [48, 55], [56, 64], [65, 68], [69, 75], [76, 87], [87, 88], [89, 98], [99, 109], [110, 112], [113, 119], [120, 131], [132, 142], [143, 150], [150, 151], [152, 165], [166, 176], [177, 179], [180, 188], [189, 204], [204, 205], [206, 216], [217, 219], [220, 228], [229, 235], [236, 239], [240, 247], [248, 259], [259, 260], [261, 274], [275, 285], [286, 288], [289, 297], [298, 304], [304, 305], [306, 314], [315, 325], [326, 328], [329, 337], [338, 344], [345, 348], [349, 354], [355, 362], [363, 371], [372, 375], [376, 382], [383, 394], [395, 397], [398, 402], [403, 409], [409, 410]]}
{"doc_key": "ai-dev-70", "ner": [[0, 2, "algorithm"], [4, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 10, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "contraction", "algorithm", "has", "also", "been", "used", "in", "face", "recognition", "systems", "within", "video", "sequences", "."], "sentence-detokenized": "The contraction algorithm has also been used in face recognition systems within video sequences.", "token2charspan": [[0, 3], [4, 15], [16, 25], [26, 29], [30, 34], [35, 39], [40, 44], [45, 47], [48, 52], [53, 64], [65, 72], [73, 79], [80, 85], [86, 95], [95, 96]]}
{"doc_key": "ai-dev-71", "ner": [[1, 3, "task"], [5, 9, "organisation"], [15, 15, "conference"], [11, 24, "academicjournal"], [27, 27, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 15, 1, 3, "topic", "", false, false], [15, 15, 5, 9, "origin", "", false, false], [11, 24, 1, 3, "topic", "", false, false], [11, 24, 5, 9, "origin", "", true, false], [27, 27, 11, 24, "role", "edited_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Dissemination", "of", "information", "is", "also", "part", "of", "ELRA", "'s", "mission", ",", "through", "the", "organisation", "of", "LREC", "conferences", "and", "through", "the", "Language", "Resources", "and", "Evaluation", "Journal", "edited", "by", "Springer", "."], "sentence-detokenized": "Dissemination of information is also part of ELRA's mission, through the organisation of LREC conferences and through the Language Resources and Evaluation Journal edited by Springer.", "token2charspan": [[0, 13], [14, 16], [17, 28], [29, 31], [32, 36], [37, 41], [42, 44], [45, 49], [49, 51], [52, 59], [59, 60], [61, 68], [69, 72], [73, 85], [86, 88], [89, 93], [94, 105], [106, 109], [110, 117], [118, 121], [122, 130], [131, 140], [141, 144], [145, 155], [156, 163], [164, 170], [171, 173], [174, 182], [182, 183]]}
{"doc_key": "ai-dev-72", "ner": [[0, 8, "field"], [11, 12, "field"], [14, 15, "field"], [16, 19, "field"], [48, 51, "field"], [55, 55, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 8, 48, 51, "named", "", false, false], [14, 15, 0, 8, "named", "", false, false], [55, 55, 11, 12, "part-of", "", true, false], [55, 55, 14, 15, "part-of", "", true, false], [55, 55, 48, 51, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "linear", "time", "-", "invariant", "(", "LTI", ")", "systems", "theory", ",", "control", "theory", ",", "digital", "signal", "processing", "or", "signal", "processing", ",", "the", "relationship", "between", "the", "input", "signal", "math", "displaystyle", "x", "(", "t", ")", "/", "math", "and", "the", "output", "signal", "math", "displaystyle", "y", "(", "t", ")", "/", "math", "of", "an", "LTI", "system", "is", "governed", "by", "the", "convolution", "operation", "Convolution", "operations", "govern", "the", "relationship", "between", "the", "input", "signal", "math", "displaystyle", "x", "(", "t", ")", "/", "math", "and", "the", "output", "signal", "math", "displaystyle", "y", "(", "t", ")", "/", "math", "."], "sentence-detokenized": "In linear time-invariant (LTI) systems theory, control theory, digital signal processing or signal processing, the relationship between the input signal math displaystyle x (t) / math and the output signal math displaystyle y (t) / math of an LTI system is governed by the convolution operation Convolution operations govern the relationship between the input signal math displaystyle x (t) / math and the output signal math displaystyle y (t) / math.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [15, 24], [25, 26], [26, 29], [29, 30], [31, 38], [39, 45], [45, 46], [47, 54], [55, 61], [61, 62], [63, 70], [71, 77], [78, 88], [89, 91], [92, 98], [99, 109], [109, 110], [111, 114], [115, 127], [128, 135], [136, 139], [140, 145], [146, 152], [153, 157], [158, 170], [171, 172], [173, 174], [174, 175], [175, 176], [177, 178], [179, 183], [184, 187], [188, 191], [192, 198], [199, 205], [206, 210], [211, 223], [224, 225], [226, 227], [227, 228], [228, 229], [230, 231], [232, 236], [237, 239], [240, 242], [243, 246], [247, 253], [254, 256], [257, 265], [266, 268], [269, 272], [273, 284], [285, 294], [295, 306], [307, 317], [318, 324], [325, 328], [329, 341], [342, 349], [350, 353], [354, 359], [360, 366], [367, 371], [372, 384], [385, 386], [387, 388], [388, 389], [389, 390], [391, 392], [393, 397], [398, 401], [402, 405], [406, 412], [413, 419], [420, 424], [425, 437], [438, 439], [440, 441], [441, 442], [442, 443], [444, 445], [446, 450], [450, 451]]}
{"doc_key": "ai-dev-73", "ner": [[18, 19, "field"], [21, 22, "field"], [24, 25, "field"], [27, 28, "field"], [30, 33, "field"], [35, 36, "product"], [38, 39, "field"], [41, 41, "field"], [43, 43, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Due", "to", "its", "generality", ",", "it", "is", "also", "a", "field", "of", "study", "in", "many", "other", "disciplines", ",", "including", "game", "theory", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimisation", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Due to its generality, it is also a field of study in many other disciplines, including game theory, control theory, operations research, information theory, simulation-based optimisation, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 21], [21, 22], [23, 25], [26, 28], [29, 33], [34, 35], [36, 41], [42, 44], [45, 50], [51, 53], [54, 58], [59, 64], [65, 76], [76, 77], [78, 87], [88, 92], [93, 99], [99, 100], [101, 108], [109, 115], [115, 116], [117, 127], [128, 136], [136, 137], [138, 149], [150, 156], [156, 157], [158, 168], [168, 169], [169, 174], [175, 187], [187, 188], [189, 200], [201, 208], [208, 209], [210, 215], [216, 228], [228, 229], [230, 240], [241, 244], [245, 252], [253, 263], [263, 264]]}
{"doc_key": "ai-dev-74", "ner": [[0, 3, "algorithm"], [13, 14, "field"], [25, 26, "algorithm"], [33, 34, "algorithm"], [16, 41, "researcher"], [43, 44, "researcher"], [46, 48, "researcher"]], "ner_mapping_to_source": [0, 1, 3, 4, 6, 7, 8], "relations": [[13, 14, 0, 3, "usage", "", true, false], [25, 26, 13, 14, "part-of", "", true, false], [33, 34, 13, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["Stochastic", "gradient", "descent", "is", "a", "commonly", "used", "algorithm", "for", "training", "various", "models", "in", "machine", "learning", ",", "such", "as", "(", "linear", ")", "support", "vector", "machines", ",", "logistic", "regression", "(", "see", ",", "for", "example", ",", "Vowpal", "Wabbit", ")", "and", "graphical", "models", "Jenny", "Rose", "Finkel", ",", "Alex", "Kleeman", ",", "Christopher", "D.", "Manning", "(", "2008", ")", "."], "sentence-detokenized": "Stochastic gradient descent is a commonly used algorithm for training various models in machine learning, such as (linear) support vector machines, logistic regression (see, for example, Vowpal Wabbit) and graphical models Jenny Rose Finkel, Alex Kleeman, Christopher D. Manning (2008).", "token2charspan": [[0, 10], [11, 19], [20, 27], [28, 30], [31, 32], [33, 41], [42, 46], [47, 56], [57, 60], [61, 69], [70, 77], [78, 84], [85, 87], [88, 95], [96, 104], [104, 105], [106, 110], [111, 113], [114, 115], [115, 121], [121, 122], [123, 130], [131, 137], [138, 146], [146, 147], [148, 156], [157, 167], [168, 169], [169, 172], [172, 173], [174, 177], [178, 185], [185, 186], [187, 193], [194, 200], [200, 201], [202, 205], [206, 215], [216, 222], [223, 228], [229, 233], [234, 240], [240, 241], [242, 246], [247, 254], [254, 255], [256, 267], [268, 270], [271, 278], [279, 280], [280, 284], [284, 285], [285, 286]]}
{"doc_key": "ai-dev-75", "ner": [[4, 4, "organisation"], [10, 12, "product"], [15, 16, "country"], [19, 22, "university"], [23, 24, "location"], [26, 29, "university"], [30, 30, "location"], [32, 34, "university"], [35, 35, "location"], [37, 40, "university"], [41, 41, "location"], [43, 46, "university"], [46, 46, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[4, 4, 19, 22, "role", "donates_to", false, false], [4, 4, 26, 29, "role", "donates_to", false, false], [4, 4, 32, 34, "role", "donates_to", false, false], [4, 4, 37, 40, "role", "donates_to", false, false], [4, 4, 43, 46, "role", "donates_to", false, false], [10, 12, 4, 4, "origin", "donates", true, false], [19, 22, 23, 24, "physical", "", false, false], [23, 24, 15, 16, "physical", "", false, false], [26, 29, 30, 30, "physical", "", false, false], [30, 30, 15, 16, "physical", "", false, false], [32, 34, 35, 35, "physical", "", false, false], [35, 35, 15, 16, "physical", "", false, false], [37, 40, 41, 41, "physical", "", false, false], [41, 41, 15, 16, "physical", "", false, false], [43, 46, 46, 46, "physical", "", false, false], [46, 46, 15, 16, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "sentence": ["In", "August", "2011", ",", "Hitachi", "announced", "that", "it", "would", "donate", "electron", "microscopes", "to", "each", "of", "five", "Indonesian", "universities", "(", "University", "of", "North", "Sumatra", "in", "Medan", ",", "Indonesian", "Christian", "University", "in", "Jakarta", ",", "Padjadjaran", "University", "in", "Bandung", ",", "Genderal", "Sudirman", "University", "in", "Purwokerto", "and", "Muhammadiyah", "University", "in", "Malang", ")", "."], "sentence-detokenized": "In August 2011, Hitachi announced that it would donate electron microscopes to each of five Indonesian universities (University of North Sumatra in Medan, Indonesian Christian University in Jakarta, Padjadjaran University in Bandung, Genderal Sudirman University in Purwokerto and Muhammadiyah University in Malang). ", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 23], [24, 33], [34, 38], [39, 41], [42, 47], [48, 54], [55, 63], [64, 75], [76, 78], [79, 83], [84, 86], [87, 91], [92, 102], [103, 115], [116, 117], [117, 127], [128, 130], [131, 136], [137, 144], [145, 147], [148, 153], [153, 154], [155, 165], [166, 175], [176, 186], [187, 189], [190, 197], [197, 198], [199, 210], [211, 221], [222, 224], [225, 232], [232, 233], [234, 242], [243, 251], [252, 262], [263, 265], [266, 276], [277, 280], [281, 293], [294, 304], [305, 307], [308, 314], [314, 315], [315, 316]]}
{"doc_key": "ai-dev-76", "ner": [[2, 3, "field"], [0, 1, "field"], [6, 6, "algorithm"], [8, 10, "algorithm"], [18, 19, "field"], [21, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 0, 1, "part-of", "", false, false], [2, 3, 18, 19, "related-to", "", true, false], [2, 3, 21, 25, "related-to", "", true, false], [6, 6, 2, 3, "type-of", "", false, false], [8, 10, 2, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Operations", "research", "optimisation", "techniques", "such", "as", "linear", "and", "dynamic", "programming", "are", "often", "not", "practical", "for", "large", "-", "scale", "software", "engineering", "problems", "because", "they", "are", "computationally", "expensive", "."], "sentence-detokenized": "Operations research optimisation techniques such as linear and dynamic programming are often not practical for large-scale software engineering problems because they are computationally expensive.", "token2charspan": [[0, 10], [11, 19], [20, 32], [33, 43], [44, 48], [49, 51], [52, 58], [59, 62], [63, 70], [71, 82], [83, 86], [87, 92], [93, 96], [97, 106], [107, 110], [111, 116], [116, 117], [117, 122], [123, 131], [132, 143], [144, 152], [153, 160], [161, 165], [166, 169], [170, 185], [186, 195], [195, 196]]}
{"doc_key": "ai-dev-77", "ner": [[0, 0, "metrics"], [5, 7, "metrics"], [11, 13, "metrics"], [20, 21, "metrics"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[0, 0, 5, 7, "compare", "", false, false], [11, 13, 5, 7, "part-of", "", false, false], [20, 21, 5, 7, "part-of", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Sensitivity", "differs", "from", "accuracy", "and", "positive", "predictive", "value", "(", "the", "ratio", "of", "true", "positives", "to", "the", "sum", "of", "true", "and", "false", "positives", ")", ",", "which", "describes", "the", "proportion", "of", "actual", "positives", "in", "the", "population", "being", "tested", "and", "is", "the", "same", "as", "that", "related", "to", "the", "content", "of", "the", "test", "."], "sentence-detokenized": "Sensitivity differs from accuracy and positive predictive value (the ratio of true positives to the sum of true and false positives), which describes the proportion of actual positives in the population being tested and is the same as that related to the content of the test.", "token2charspan": [[0, 11], [12, 19], [20, 24], [25, 33], [34, 37], [38, 46], [47, 57], [58, 63], [64, 65], [65, 68], [69, 74], [75, 77], [78, 82], [83, 92], [93, 95], [96, 99], [100, 103], [104, 106], [107, 111], [112, 115], [116, 121], [122, 131], [131, 132], [132, 133], [134, 139], [140, 149], [150, 153], [154, 164], [165, 167], [168, 174], [175, 184], [185, 187], [188, 191], [192, 202], [203, 208], [209, 215], [216, 219], [220, 222], [223, 226], [227, 231], [232, 234], [235, 239], [240, 247], [248, 250], [251, 254], [255, 262], [263, 265], [266, 269], [270, 274], [274, 275]]}
{"doc_key": "ai-dev-78", "ner": [[5, 6, "person"], [10, 12, "product"], [15, 15, "person"], [30, 30, "person"], [37, 39, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 12, 5, 6, "artifact", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["The", "screenplay", "was", "written", "by", "Hampton", "Fancher", "!", "Not", "originally", "titled", "The", "Androids", "-", "see", "Sammon", ",", "pp.", "32", "and", "38", "for", "explanation", "-", "it", "was", "optioned", "in", "1977", ";", "Sammon", ",", "pp.", "23", "-", "30", "Producer", "Michael", "DeLay", "became", "interested", "in", "Fancher", "'s", "draft", "and", "persuaded", "him", "to", "make", "the", "film", "."], "sentence-detokenized": "The screenplay was written by Hampton Fancher! Not originally titled The Androids - see Sammon, pp. 32 and 38 for explanation - it was optioned in 1977; Sammon, pp. 23-30 Producer Michael DeLay became interested in Fancher's draft and persuaded him to make the film.", "token2charspan": [[0, 3], [4, 14], [15, 18], [19, 26], [27, 29], [30, 37], [38, 45], [45, 46], [47, 50], [51, 61], [62, 68], [69, 72], [73, 81], [82, 83], [84, 87], [88, 94], [94, 95], [96, 99], [100, 102], [103, 106], [107, 109], [110, 113], [114, 125], [126, 127], [128, 130], [131, 134], [135, 143], [144, 146], [147, 151], [151, 152], [153, 159], [159, 160], [161, 164], [165, 167], [167, 168], [168, 170], [171, 179], [180, 187], [188, 193], [194, 200], [201, 211], [212, 214], [215, 222], [222, 224], [225, 230], [231, 234], [235, 244], [245, 248], [249, 251], [252, 256], [257, 260], [261, 265], [265, 266]]}
{"doc_key": "ai-dev-79", "ner": [[0, 0, "field"], [3, 4, "task"], [6, 8, "task"], [9, 11, "misc"], [18, 19, "field"], [21, 23, "task"], [25, 26, "task"], [13, 14, "field"], [16, 31, "task"], [33, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 4, 0, 0, "part-of", "", false, false], [6, 8, 0, 0, "part-of", "", false, false], [9, 11, 0, 0, "part-of", "", false, false], [18, 19, 0, 0, "part-of", "", false, false], [21, 23, 0, 0, "part-of", "", false, false], [25, 26, 0, 0, "part-of", "", false, false], [13, 14, 0, 0, "part-of", "", false, false], [16, 31, 0, 0, "part-of", "", false, false], [33, 33, 0, 0, "part-of", "", false, false], [35, 36, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Text", "analysis", "includes", "information", "retrieval", ",", "lexical", "analysis", "for", "word", "frequency", "distribution", ",", "data", "mining", "techniques", "such", "as", "pattern", "recognition", ",", "tagging", "and", "annotation", ",", "information", "extraction", ",", "link", "and", "association", "analysis", ",", "visualisation", "and", "predictive", "analysis", "."], "sentence-detokenized": "Text analysis includes information retrieval, lexical analysis for word frequency distribution, data mining techniques such as pattern recognition, tagging and annotation, information extraction, link and association analysis, visualisation and predictive analysis.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 34], [35, 44], [44, 45], [46, 53], [54, 62], [63, 66], [67, 71], [72, 81], [82, 94], [94, 95], [96, 100], [101, 107], [108, 118], [119, 123], [124, 126], [127, 134], [135, 146], [146, 147], [148, 155], [156, 159], [160, 170], [170, 171], [172, 183], [184, 194], [194, 195], [196, 200], [201, 204], [205, 216], [217, 225], [225, 226], [227, 240], [241, 244], [245, 255], [256, 264], [264, 265]]}
{"doc_key": "ai-dev-80", "ner": [[11, 12, "misc"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "metrics", "use", "WordNet", ",", "a", "manually", "constructed", "lexical", "database", "of", "English", "words", "."], "sentence-detokenized": "Some metrics use WordNet, a manually constructed lexical database of English words.", "token2charspan": [[0, 4], [5, 12], [13, 16], [17, 24], [24, 25], [26, 27], [28, 36], [37, 48], [49, 56], [57, 65], [66, 68], [69, 76], [77, 82], [82, 83]]}
{"doc_key": "ai-dev-81", "ner": [[6, 7, "field"], [9, 10, "task"], [3, 16, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "system", "combines", "techniques", "such", "as", "computational", "linguistics", ",", "information", "retrieval", "and", "knowledge", "representation", "to", "find", "answers", "."], "sentence-detokenized": "The system combines techniques such as computational linguistics, information retrieval and knowledge representation to find answers.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 30], [31, 35], [36, 38], [39, 52], [53, 64], [64, 65], [66, 77], [78, 87], [88, 91], [92, 101], [102, 116], [117, 119], [120, 124], [125, 132], [132, 133]]}
{"doc_key": "ai-dev-82", "ner": [[5, 6, "metrics"], [12, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 12, 13, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "performance", "measure", ",", "uncertainty", "coefficients", "have", "the", "advantage", "over", "simple", "precision", "in", "that", "they", "are", "not", "affected", "by", "the", "relative", "sizes", "of", "different", "classes", "."], "sentence-detokenized": "As a performance measure, uncertainty coefficients have the advantage over simple precision in that they are not affected by the relative sizes of different classes.", "token2charspan": [[0, 2], [3, 4], [5, 16], [17, 24], [24, 25], [26, 37], [38, 50], [51, 55], [56, 59], [60, 69], [70, 74], [75, 81], [82, 91], [92, 94], [95, 99], [100, 104], [105, 108], [109, 112], [113, 121], [122, 124], [125, 128], [129, 137], [138, 143], [144, 146], [147, 156], [157, 164], [164, 165]]}
{"doc_key": "ai-dev-83", "ner": [[7, 8, "algorithm"], [10, 11, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Researchers", "have", "tried", "various", "methods", ",", "including", "optical", "flow", ",", "Kalman", "filtering", "and", "hidden", "Markov", "models", "."], "sentence-detokenized": "Researchers have tried various methods, including optical flow, Kalman filtering and hidden Markov models.", "token2charspan": [[0, 11], [12, 16], [17, 22], [23, 30], [31, 38], [38, 39], [40, 49], [50, 57], [58, 62], [62, 63], [64, 70], [71, 80], [81, 84], [85, 91], [92, 98], [99, 105], [105, 106]]}
{"doc_key": "ai-dev-84", "ner": [[15, 18, "conference"], [28, 30, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "served", "as", "President", ",", "Vice", "-", "President", "and", "Secretary", "/", "Treasurer", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "is", "a", "Board", "Member", "and", "Secretary", "of", "the", "Computing", "Research", "Association", "."], "sentence-detokenized": "He has served as President, Vice-President and Secretary/Treasurer of the Association for Computational Linguistics and is a Board Member and Secretary of the Computing Research Association.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 26], [26, 27], [28, 32], [32, 33], [33, 42], [43, 46], [47, 56], [56, 57], [57, 66], [67, 69], [70, 73], [74, 85], [86, 89], [90, 103], [104, 115], [116, 119], [120, 122], [123, 124], [125, 130], [131, 137], [138, 141], [142, 151], [152, 154], [155, 158], [159, 168], [169, 177], [178, 189], [189, 190]]}
{"doc_key": "ai-dev-85", "ner": [[5, 5, "programlang"], [3, 7, "product"], [9, 9, "programlang"], [10, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 9, 9, "compare", "", false, false], [5, 5, 10, 12, "related-to", "supports", false, false], [3, 7, 9, 9, "compare", "", false, false], [3, 7, 10, 12, "related-to", "supports", false, false], [9, 9, 10, 12, "related-to", "supports", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Like", "similar", "languages", "such", "as", "APL", "and", "MATLAB", ",", "R", "supports", "matrix", "operations", "."], "sentence-detokenized": "Like similar languages such as APL and MATLAB, R supports matrix operations.", "token2charspan": [[0, 4], [5, 12], [13, 22], [23, 27], [28, 30], [31, 34], [35, 38], [39, 45], [45, 46], [47, 48], [49, 57], [58, 64], [65, 75], [75, 76]]}
{"doc_key": "ai-dev-86", "ner": [[7, 9, "misc"], [6, 13, "organisation"], [16, 20, "researcher"], [22, 24, "university"], [26, 32, "misc"], [48, 48, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 9, 6, 13, "physical", "", false, false], [7, 9, 26, 32, "temporal", "", false, false], [16, 20, 7, 9, "role", "arranges", false, false], [16, 20, 22, 24, "role", "works_for", false, false], [48, 48, 7, 9, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["On", "7", "June", "2014", ",", "at", "the", "Turing", "Test", "competition", "at", "the", "Royal", "Society", ",", "organised", "by", "Kevin", "Warwick", "of", "the", "University", "of", "Reading", "to", "mark", "the", "60th", "anniversary", "of", "Turing", "'s", "death", ",", "33", "%", "of", "the", "judges", "were", "convinced", "that", "the", "bot", "was", "human", ",", "and", "Guthman", "won", "."], "sentence-detokenized": "On 7 June 2014, at the Turing Test competition at the Royal Society, organised by Kevin Warwick of the University of Reading to mark the 60th anniversary of Turing's death, 33% of the judges were convinced that the bot was human, and Guthman won.", "token2charspan": [[0, 2], [3, 4], [5, 9], [10, 14], [14, 15], [16, 18], [19, 22], [23, 29], [30, 34], [35, 46], [47, 49], [50, 53], [54, 59], [60, 67], [67, 68], [69, 78], [79, 81], [82, 87], [88, 95], [96, 98], [99, 102], [103, 113], [114, 116], [117, 124], [125, 127], [128, 132], [133, 136], [137, 141], [142, 153], [154, 156], [157, 163], [163, 165], [166, 171], [171, 172], [173, 175], [175, 176], [177, 179], [180, 183], [184, 190], [191, 195], [196, 205], [206, 210], [211, 214], [215, 218], [219, 222], [223, 228], [228, 229], [230, 233], [234, 241], [242, 245], [245, 246]]}
{"doc_key": "ai-dev-87", "ner": [[1, 1, "product"], [0, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 5, 1, 1, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "robots", "(", "cobots", ")", "are", "robots", "that", "can", "safely", "and", "effectively", "interact", "with", "human", "workers", "when", "performing", "simple", "industrial", "tasks", "."], "sentence-detokenized": "Collaborative robots (cobots) are robots that can safely and effectively interact with human workers when performing simple industrial tasks.", "token2charspan": [[0, 13], [14, 20], [21, 22], [22, 28], [28, 29], [30, 33], [34, 40], [41, 45], [46, 49], [50, 56], [57, 60], [61, 72], [73, 81], [82, 86], [87, 92], [93, 100], [101, 105], [106, 116], [117, 123], [124, 134], [135, 140], [140, 141]]}
{"doc_key": "ai-dev-88", "ner": [[13, 14, "field"], [17, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "task"], [29, 30, "task"], [32, 34, "task"], [16, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[17, 18, 13, 14, "part-of", "task_part_of_field", false, false], [20, 21, 13, 14, "part-of", "task_part_of_field", false, false], [23, 24, 13, 14, "part-of", "task_part_of_field", false, false], [26, 27, 13, 14, "part-of", "task_part_of_field", false, false], [29, 30, 13, 14, "part-of", "task_part_of_field", false, false], [32, 34, 13, 14, "part-of", "task_part_of_field", false, false], [16, 37, 13, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["This", "overall", "framework", "has", "been", "applied", "to", "a", "great", "variety", "of", "problems", "in", "computer", "vision", ",", "including", "feature", "detection", ",", "feature", "classification", ",", "image", "segmentation", ",", "image", "matching", ",", "motion", "estimation", ",", "shape", "cue", "computation", "and", "object", "recognition", "."], "sentence-detokenized": "This overall framework has been applied to a great variety of problems in computer vision, including feature detection, feature classification, image segmentation, image matching, motion estimation, shape cue computation and object recognition.", "token2charspan": [[0, 4], [5, 12], [13, 22], [23, 26], [27, 31], [32, 39], [40, 42], [43, 44], [45, 50], [51, 58], [59, 61], [62, 70], [71, 73], [74, 82], [83, 89], [89, 90], [91, 100], [101, 108], [109, 118], [118, 119], [120, 127], [128, 142], [142, 143], [144, 149], [150, 162], [162, 163], [164, 169], [170, 178], [178, 179], [180, 186], [187, 197], [197, 198], [199, 204], [205, 208], [209, 220], [221, 224], [225, 231], [232, 243], [243, 244]]}
{"doc_key": "ai-dev-89", "ner": [[5, 7, "task"], [8, 10, "algorithm"], [11, 15, "algorithm"], [28, 30, "algorithm"], [33, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 4, 5], "relations": [[5, 7, 8, 10, "part-of", "", false, false], [5, 7, 11, 15, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "many", "practical", "applications", ",", "parameter", "estimation", "for", "na\u00efve", "Bayesian", "models", "uses", "the", "maximum", "likelihood", "method", ".", "In", "other", "words", ",", "na\u00efve", "Bayesian", "models", "can", "be", "handled", "without", "accepting", "Bayesian", "probabilities", "and", "without", "using", "Bayesian", "methods", "."], "sentence-detokenized": "In many practical applications, parameter estimation for na\u00efve Bayesian models uses the maximum likelihood method. In other words, na\u00efve Bayesian models can be handled without accepting Bayesian probabilities and without using Bayesian methods.", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 30], [30, 31], [32, 41], [42, 52], [53, 56], [57, 62], [63, 71], [72, 78], [79, 83], [84, 87], [88, 95], [96, 106], [107, 113], [113, 114], [115, 117], [118, 123], [124, 129], [129, 130], [131, 136], [137, 145], [146, 152], [153, 156], [157, 159], [160, 167], [168, 175], [176, 185], [186, 194], [195, 208], [209, 212], [213, 220], [221, 226], [227, 235], [236, 243], [243, 244]]}
{"doc_key": "ai-dev-90", "ner": [[2, 4, "researcher"], [6, 7, "misc"], [12, 15, "university"], [17, 62, "researcher"], [21, 63, "misc"], [26, 27, "university"], [36, 39, "university"], [42, 45, "misc"], [47, 51, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 8, 9, 10], "relations": [[2, 4, 12, 15, "physical", "", false, false], [2, 4, 12, 15, "role", "", false, false], [2, 4, 17, 62, "social", "brothers", false, false], [6, 7, 2, 4, "named", "", false, false], [17, 62, 26, 27, "physical", "", false, false], [17, 62, 26, 27, "role", "", false, false], [17, 62, 36, 39, "physical", "", false, false], [17, 62, 36, 39, "role", "", false, false], [21, 63, 17, 62, "named", "", false, false], [42, 45, 17, 62, "artifact", "", false, false], [42, 45, 47, 51, "part-of", "part", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 8, 9, 10, 12, 13], "sentence": ["Siblings", "-", "Victor", "Gershevich", "Katz", ",", "American", "mathematician", ",", "professor", "at", "the", "Massachusetts", "Institute", "of", "Technology", ";", "Mikhail", "Gershevich", "Katz", ",", "Israeli", "mathematician", ",", "graduate", "of", "Harvard", "and", "Columbia", "University", "(", "PhD", "1984", ")", ",", "professor", "at", "Bar-", "Ilan", "University", ",", "monograph", "Systolic", "Geometry", "and", "Topology", "(", "Math", ".", "Servais", "and", "Monographs", ",", "vol", ".", "1994", ")", ",", "Mikhail", "Gershevich", "Katz", ",", "Israeli", "mathematician", "."], "sentence-detokenized": "Siblings - Victor Gershevich Katz, American mathematician, professor at the Massachusetts Institute of Technology; Mikhail Gershevich Katz, Israeli mathematician, graduate of Harvard and Columbia University (PhD 1984), professor at Bar-Ilan University, monograph Systolic Geometry and Topology (Math. Servais and Monographs, vol. 1994), Mikhail Gershevich Katz, Israeli mathematician.", "token2charspan": [[0, 8], [9, 10], [11, 17], [18, 28], [29, 33], [33, 34], [35, 43], [44, 57], [57, 58], [59, 68], [69, 71], [72, 75], [76, 89], [90, 99], [100, 102], [103, 113], [113, 114], [115, 122], [123, 133], [134, 138], [138, 139], [140, 147], [148, 161], [161, 162], [163, 171], [172, 174], [175, 182], [183, 186], [187, 195], [196, 206], [207, 208], [208, 211], [212, 216], [216, 217], [217, 218], [219, 228], [229, 231], [232, 236], [236, 240], [241, 251], [251, 252], [253, 262], [263, 271], [272, 280], [281, 284], [285, 293], [294, 295], [295, 299], [299, 300], [301, 308], [309, 312], [313, 323], [323, 324], [325, 328], [328, 329], [330, 334], [334, 335], [335, 336], [337, 344], [345, 355], [356, 360], [360, 361], [362, 369], [370, 383], [383, 384]]}
{"doc_key": "ai-dev-91", "ner": [[3, 6, "person"], [10, 12, "conference"], [16, 20, "organisation"], [21, 28, "location"], [32, 33, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 10, 12, "physical", "", false, false], [3, 6, 10, 12, "role", "", false, false], [3, 6, 16, 20, "role", "", false, false], [16, 20, 21, 28, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2000", ",", "Manuel", "Tojaria", ",", "a", "speaker", "at", "previous", "Campus", "Parties", "and", "director", "of", "the", "Museo", "de", "Ciencia", "Principe", "Felipe", "in", "Valencia", "'s", "City", "of", "Arts", "and", "Sciences", ",", "suggested", "to", "La", "Gajelles", "that", "the", "event", "be", "expanded", "and", "internationalised", ",", "and", "the", "venue", "moved", "to", "this", "famous", "museum", "."], "sentence-detokenized": "In 2000, Manuel Tojaria, a speaker at previous Campus Parties and director of the Museo de Ciencia Principe Felipe in Valencia's City of Arts and Sciences, suggested to La Gajelles that the event be expanded and internationalised, and the venue moved to this famous museum.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 23], [23, 24], [25, 26], [27, 34], [35, 37], [38, 46], [47, 53], [54, 61], [62, 65], [66, 74], [75, 77], [78, 81], [82, 87], [88, 90], [91, 98], [99, 107], [108, 114], [115, 117], [118, 126], [126, 128], [129, 133], [134, 136], [137, 141], [142, 145], [146, 154], [154, 155], [156, 165], [166, 168], [169, 171], [172, 180], [181, 185], [186, 189], [190, 195], [196, 198], [199, 207], [208, 211], [212, 229], [229, 230], [231, 234], [235, 238], [239, 244], [245, 250], [251, 253], [254, 258], [259, 265], [266, 272], [272, 273]]}
{"doc_key": "ai-dev-92", "ner": [[0, 3, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "facial", "recognition", "system", "identifies", "personal", "details", "such", "as", "first", "name", ",", "last", "name", ",", "ID", "number", "and", "address", "within", "20", "minutes", ",", "which", "are", "then", "displayed", "on", "advertising", "screens", "on", "the", "street", "."], "sentence-detokenized": "A facial recognition system identifies personal details such as first name, last name, ID number and address within 20 minutes, which are then displayed on advertising screens on the street.", "token2charspan": [[0, 1], [2, 8], [9, 20], [21, 27], [28, 38], [39, 47], [48, 55], [56, 60], [61, 63], [64, 69], [70, 74], [74, 75], [76, 80], [81, 85], [85, 86], [87, 89], [90, 96], [97, 100], [101, 108], [109, 115], [116, 118], [119, 126], [126, 127], [128, 133], [134, 137], [138, 142], [143, 152], [153, 155], [156, 167], [168, 175], [176, 178], [179, 182], [183, 189], [189, 190]]}
{"doc_key": "ai-dev-93", "ner": [[5, 5, "field"], [7, 8, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Recent", "research", "has", "focused", "on", "unsupervised", "and", "semi-supervised", "learning", "algorithms", "."], "sentence-detokenized": "Recent research has focused on unsupervised and semi-supervised learning algorithms.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 27], [28, 30], [31, 43], [44, 47], [48, 63], [64, 72], [73, 83], [83, 84]]}
{"doc_key": "ai-dev-94", "ner": [[5, 5, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Computation", "of", "this", "example", "by", "Python", "code", "."], "sentence-detokenized": "Computation of this example by Python code.", "token2charspan": [[0, 11], [12, 14], [15, 19], [20, 27], [28, 30], [31, 37], [38, 42], [42, 43]]}
{"doc_key": "ai-dev-95", "ner": [[3, 8, "task"], [13, 14, "field"], [20, 21, "algorithm"], [17, 19, "algorithm"], [23, 28, "algorithm"], [32, 33, "researcher"], [35, 37, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[20, 21, 13, 14, "part-of", "", false, false], [20, 21, 23, 28, "type-of", "", false, false], [20, 21, 32, 33, "origin", "", false, false], [20, 21, 35, 37, "origin", "", false, false], [17, 19, 20, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["However", ",", "much", "of", "speech", "recognition", "has", "now", "been", "taken", "over", "by", "a", "deep", "learning", "method", "called", "LSTM", "(", "Long", "Short", "Memory", ":", "recurrent", "neural", "network", ")", ",", "which", "was", "introduced", "by", "Sepp", "Hochreiter", "&", "J\u00fcrgen", "Schmidhuber", "in", "1997", "."], "sentence-detokenized": "However, much of speech recognition has now been taken over by a deep learning method called LSTM (Long Short Memory: recurrent neural network), which was introduced by Sepp Hochreiter & J\u00fcrgen Schmidhuber in 1997.", "token2charspan": [[0, 7], [7, 8], [9, 13], [14, 16], [17, 23], [24, 35], [36, 39], [40, 43], [44, 48], [49, 54], [55, 59], [60, 62], [63, 64], [65, 69], [70, 78], [79, 85], [86, 92], [93, 97], [98, 99], [99, 103], [104, 109], [110, 116], [116, 117], [118, 127], [128, 134], [135, 142], [142, 143], [143, 144], [145, 150], [151, 154], [155, 165], [166, 168], [169, 173], [174, 184], [185, 186], [187, 193], [194, 205], [206, 208], [209, 213], [213, 214]]}
{"doc_key": "ai-dev-96", "ner": [[15, 15, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [2, 3], "relations": [[15, 15, 19, 20, "compare", "", false, false]], "relations_mapping_to_source": [2], "sentence": ["Preliminary", "experiments", "on", "noisy", "datasets", "showed", "that", "BrownBoost", "outperformed", "AdaBoost", "'s", "generalisation", "error", ",", "while", "LogitBoost", "performed", "as", "well", "as", "BrownBoost", "."], "sentence-detokenized": "Preliminary experiments on noisy datasets showed that BrownBoost outperformed AdaBoost's generalisation error, while LogitBoost performed as well as BrownBoost.", "token2charspan": [[0, 11], [12, 23], [24, 26], [27, 32], [33, 41], [42, 48], [49, 53], [54, 64], [65, 77], [78, 86], [86, 88], [89, 103], [104, 109], [109, 110], [111, 116], [117, 127], [128, 137], [138, 140], [141, 145], [146, 148], [149, 159], [159, 160]]}
{"doc_key": "ai-dev-97", "ner": [[0, 2, "algorithm"], [5, 9, "researcher"], [10, 10, "country"], [13, 15, "researcher"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 5, 9, "part-of", "", false, false], [5, 9, 10, 10, "physical", "", false, false], [19, 21, 13, 15, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Evolutionary", "programming", "was", "introduced", "by", "Lawrence", "J.", "Vogel", "in", "the", "USA", ",", "and", "John", "Henry", "Holland", "called", "his", "method", "a", "genetic", "algorithm", "."], "sentence-detokenized": "Evolutionary programming was introduced by Lawrence J. Vogel in the USA, and John Henry Holland called his method a genetic algorithm.", "token2charspan": [[0, 12], [13, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 54], [55, 60], [61, 63], [64, 67], [68, 71], [71, 72], [73, 76], [77, 81], [82, 87], [88, 95], [96, 102], [103, 106], [107, 113], [114, 115], [116, 123], [124, 133], [133, 134]]}
{"doc_key": "ai-dev-98", "ner": [[3, 3, "researcher"], [5, 6, "researcher"], [10, 11, "researcher"], [14, 14, "researcher"], [16, 17, "researcher"], [9, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 3, 10, 11, "role", "", false, false], [3, 3, 14, 14, "role", "", false, false], [3, 3, 16, 17, "role", "", false, false], [3, 3, 9, 20, "role", "", false, false], [5, 6, 10, 11, "role", "", false, false], [5, 6, 14, 14, "role", "", false, false], [5, 6, 16, 17, "role", "", false, false], [5, 6, 9, 20, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Background", "calculations", "by", "Doug", ",", "Alan", "and", "colleagues", "(", "including", "Marvin", "Minsky", ",", "Allen", "Newell", ",", "Edward", "Feigenbaum", "and", "John", "McCarthy", ")", "indicated", "that", "the", "effort", "would", "require", "1000-3000", "man", "-", "years", "of", "effort", ",", "well", "beyond", "the", "usual", "academic", "project", "model", ".", "They", "were", "."], "sentence-detokenized": "Background calculations by Doug, Alan and colleagues (including Marvin Minsky, Allen Newell, Edward Feigenbaum and John McCarthy) indicated that the effort would require 1000-3000 man-years of effort, well beyond the usual academic project model. They were.", "token2charspan": [[0, 10], [11, 23], [24, 26], [27, 31], [31, 32], [33, 37], [38, 41], [42, 52], [53, 54], [54, 63], [64, 70], [71, 77], [77, 78], [79, 84], [85, 91], [91, 92], [93, 99], [100, 110], [111, 114], [115, 119], [120, 128], [128, 129], [130, 139], [140, 144], [145, 148], [149, 155], [156, 161], [162, 169], [170, 179], [180, 183], [183, 184], [184, 189], [190, 192], [193, 199], [199, 200], [201, 205], [206, 212], [213, 216], [217, 222], [223, 231], [232, 239], [240, 245], [245, 246], [247, 251], [252, 256], [256, 257]]}
{"doc_key": "ai-dev-99", "ner": [[4, 10, "metrics"], [11, 13, "metrics"], [14, 16, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 10, 11, 13, "part-of", "implemented_in", false, false], [14, 16, 20, 20, "part-of", "implemented_in", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Common", "criteria", "include", "the", "Mean", "Squared", "Error", "criterion", "implemented", "in", "the", "MSECriterion", "and", "the", "cross", "-entropy", "criterion", "implemented", "in", "the", "NLLCriterion", "."], "sentence-detokenized": "Common criteria include the Mean Squared Error criterion implemented in the MSECriterion and the cross-entropy criterion implemented in the NLLCriterion.", "token2charspan": [[0, 6], [7, 15], [16, 23], [24, 27], [28, 32], [33, 40], [41, 46], [47, 56], [57, 68], [69, 71], [72, 75], [76, 88], [89, 92], [93, 96], [97, 102], [102, 110], [111, 120], [121, 132], [133, 135], [136, 139], [140, 152], [152, 153]]}
{"doc_key": "ai-dev-100", "ner": [[0, 1, "researcher"], [47, 47, "organisation"], [2, 12, "misc"], [14, 21, "conference"], [36, 43, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 47, 47, "role", "", false, false], [0, 1, 14, 21, "role", "", false, false], [0, 1, 36, 43, "role", "", false, false], [2, 12, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Zurada", "was", "IEEE", "Vice-President", "-", "Technical", "Activities", "(", "TAB", "Chair", ")", "in", "2014", ",", "President", "of", "the", "IEEE", "Computational", "Intelligence", "Society", "in", "2004", "-", "05", ",", "2009", "-", "14", ",", "2016", "-", "18", "and", "it", "Previously", "an", "ADCOM", "member", ",", "he", "has", "been", "a", "long", "-", "standing", "IEEE", "volunteer", "for", "technical", "professionals", "."], "sentence-detokenized": "Zurada was IEEE Vice-President-Technical Activities (TAB Chair) in 2014, President of the IEEE Computational Intelligence Society in 2004-05, 2009-14, 2016-18 and it Previously an ADCOM member, he has been a long-standing IEEE volunteer for technical professionals.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 30], [30, 31], [31, 40], [41, 51], [52, 53], [53, 56], [57, 62], [62, 63], [64, 66], [67, 71], [71, 72], [73, 82], [83, 85], [86, 89], [90, 94], [95, 108], [109, 121], [122, 129], [130, 132], [133, 137], [137, 138], [138, 140], [140, 141], [142, 146], [146, 147], [147, 149], [149, 150], [151, 155], [155, 156], [156, 158], [159, 162], [163, 165], [166, 176], [177, 179], [180, 185], [186, 192], [192, 193], [194, 196], [197, 200], [201, 205], [206, 207], [208, 212], [212, 213], [213, 221], [222, 226], [227, 236], [237, 240], [241, 250], [251, 264], [264, 265]]}
{"doc_key": "ai-dev-101", "ner": [[3, 4, "field"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 3, 4, "part-of", "", false, false], [11, 12, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "general", ",", "computational", "linguistics", "involves", "linguists", ",", "computer", "science", "and", "artificial", "intelligence", "specialists", ",", "mathematicians", ",", "logicians", ",", "philosophers", ",", "cognitive", "scientists", ",", "cognitive", "psychologists", ",", "psycholinguists", ",", "anthropologists", "and", "neuroscientists", "."], "sentence-detokenized": "In general, computational linguistics involves linguists, computer science and artificial intelligence specialists, mathematicians, logicians, philosophers, cognitive scientists, cognitive psychologists, psycholinguists, anthropologists and neuroscientists.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 25], [26, 37], [38, 46], [47, 56], [56, 57], [58, 66], [67, 74], [75, 78], [79, 89], [90, 102], [103, 114], [114, 115], [116, 130], [130, 131], [132, 141], [141, 142], [143, 155], [155, 156], [157, 166], [167, 177], [177, 178], [179, 188], [189, 202], [202, 203], [204, 219], [219, 220], [221, 236], [237, 240], [241, 256], [256, 257]]}
{"doc_key": "ai-dev-102", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [0, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "-", "term", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "correlations", "between", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and long-term short-term memory are often used to exploit correlations between frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [82, 83], [83, 87], [88, 93], [93, 94], [94, 98], [99, 105], [106, 109], [110, 115], [116, 120], [121, 123], [124, 131], [132, 144], [145, 152], [153, 159], [159, 160]]}
{"doc_key": "ai-dev-103", "ner": [[0, 2, "product"], [4, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 4, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "'", "Unimate", "'", "was", "the", "first", "industrial", "robot", "."], "sentence-detokenized": "The 'Unimate' was the first industrial robot.", "token2charspan": [[0, 3], [4, 5], [5, 12], [12, 13], [14, 17], [18, 21], [22, 27], [28, 38], [39, 44], [44, 45]]}
{"doc_key": "ai-dev-104", "ner": [[0, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [11, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 11, 14, "win-defeat", "", false, false], [5, 6, 11, 14, "win-defeat", "", false, false], [8, 8, 11, 14, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Together", "with", "Geoffrey", "Hinton", "and", "Jan", "Lukun", ",", "Bengio", "was", "awarded", "the", "2018", "Turing", "Award", "."], "sentence-detokenized": "Together with Geoffrey Hinton and Jan Lukun, Bengio was awarded the 2018 Turing Award.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 29], [30, 33], [34, 37], [38, 43], [43, 44], [45, 51], [52, 55], [56, 63], [64, 67], [68, 72], [73, 79], [80, 85], [85, 86]]}
{"doc_key": "ai-dev-105", "ner": [[50, 50, "country"], [6, 9, "misc"], [11, 14, "country"], [15, 16, "organisation"], [20, 21, "person"], [25, 26, "person"], [32, 35, "misc"], [40, 40, "country"], [45, 45, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[6, 9, 50, 50, "physical", "filmed_in", false, false], [20, 21, 15, 16, "role", "host", false, false], [25, 26, 15, 16, "role", "reporter", false, false], [32, 35, 50, 50, "physical", "filmed_in", false, false], [32, 35, 40, 40, "physical", "distributed_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "series", "included", "two", "series", "of", "Robot", "Wars", "Extreme", "Warriors", "against", "American", "competitors", "on", "the", "TNN", "network", "(", "hosted", "by", "Mick", "Foley", "and", "pit", "reporter", "Rebecca", "Grant", ")", ",", "two", "series", "of", "Dutch", "Robot", "Wars", "to", "be", "shown", "in", "the", "Netherlands", "and", "one", "series", "for", "Germany", ",", "were", "filmed", "at", "UK", "venues", "for", "specific", "sectors", "of", "the", "global", "market", "."], "sentence-detokenized": "Other series included two series of Robot Wars Extreme Warriors against American competitors on the TNN network (hosted by Mick Foley and pit reporter Rebecca Grant), two series of Dutch Robot Wars to be shown in the Netherlands and one series for Germany, were filmed at UK venues for specific sectors of the global market.", "token2charspan": [[0, 5], [6, 12], [13, 21], [22, 25], [26, 32], [33, 35], [36, 41], [42, 46], [47, 54], [55, 63], [64, 71], [72, 80], [81, 92], [93, 95], [96, 99], [100, 103], [104, 111], [112, 113], [113, 119], [120, 122], [123, 127], [128, 133], [134, 137], [138, 141], [142, 150], [151, 158], [159, 164], [164, 165], [165, 166], [167, 170], [171, 177], [178, 180], [181, 186], [187, 192], [193, 197], [198, 200], [201, 203], [204, 209], [210, 212], [213, 216], [217, 228], [229, 232], [233, 236], [237, 243], [244, 247], [248, 255], [255, 256], [257, 261], [262, 268], [269, 271], [272, 274], [275, 281], [282, 285], [286, 294], [295, 302], [303, 305], [306, 309], [310, 316], [317, 323], [323, 324]]}
{"doc_key": "ai-dev-106", "ner": [[10, 11, "product"], [28, 29, "product"]], "ner_mapping_to_source": [1, 2], "relations": [[28, 29, 10, 11, "usage", "", true, false]], "relations_mapping_to_source": [1], "sentence": ["For", "many", "years", "from", "1986", ",", "he", "led", "the", "development", "of", "WordNet", ",", "a", "large", "computer", "-", "readable", "electronic", "reference", "that", "could", "be", "used", "for", "applications", "such", "as", "search", "engines", "."], "sentence-detokenized": "For many years from 1986, he led the development of WordNet, a large computer-readable electronic reference that could be used for applications such as search engines.", "token2charspan": [[0, 3], [4, 8], [9, 14], [15, 19], [20, 24], [24, 25], [26, 28], [29, 32], [33, 36], [37, 48], [49, 51], [52, 59], [59, 60], [61, 62], [63, 68], [69, 77], [77, 78], [78, 86], [87, 97], [98, 107], [108, 112], [113, 118], [119, 121], [122, 126], [127, 130], [131, 143], [144, 148], [149, 151], [152, 158], [159, 166], [166, 167]]}
{"doc_key": "ai-dev-107", "ner": [[5, 8, "algorithm"], [11, 13, "researcher"], [16, 21, "organisation"], [22, 27, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[5, 8, 11, 13, "origin", "", false, false], [5, 8, 22, 27, "win-defeat", "", false, false], [11, 13, 16, 21, "physical", "", false, false], [11, 13, 16, 21, "role", "", false, false]], "relations_mapping_to_source": [2, 3, 4, 5], "sentence": ["Since", "2009", ",", "recurrent", "and", "deep", "feedforward", "neural", "networks", "developed", "by", "J\u00fcrgen", "Schmidhuber", "'s", "research", "group", "at", "the", "Swiss", "AI", "Lab", "IDSIA", "have", "won", "several", "international", "handwriting", "competitions", "..."], "sentence-detokenized": "Since 2009, recurrent and deep feedforward neural networks developed by J\u00fcrgen Schmidhuber's research group at the Swiss AI Lab IDSIA have won several international handwriting competitions...", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 21], [22, 25], [26, 30], [31, 42], [43, 49], [50, 58], [59, 68], [69, 71], [72, 78], [79, 90], [90, 92], [93, 101], [102, 107], [108, 110], [111, 114], [115, 120], [121, 123], [124, 127], [128, 133], [134, 138], [139, 142], [143, 150], [151, 164], [165, 176], [177, 189], [189, 192]]}
{"doc_key": "ai-dev-108", "ner": [[4, 6, "programlang"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "software", "is", "implemented", "in", "C", "++", "and", "wrapped", "for", "Python", "."], "sentence-detokenized": "The software is implemented in C++ and wrapped for Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 30], [31, 32], [32, 34], [35, 38], [39, 46], [47, 50], [51, 57], [57, 58]]}
{"doc_key": "ai-dev-109", "ner": [[5, 9, "country"], [11, 16, "misc"], [17, 30, "misc"], [35, 38, "misc"], [32, 33, "misc"], [39, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[17, 30, 5, 9, "temporal", "", false, false], [17, 30, 11, 16, "artifact", "", false, false], [17, 30, 39, 39, "physical", "", false, false], [32, 33, 35, 38, "named", "", false, false], [32, 33, 39, 39, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1857", ",", "at", "the", "request", "of", "the", "Tokugawa", "Shogunate", ",", "Dutch", "engineers", "began", "work", "on", "the", "construction", "of", "a", "modern", "Western", "-", "style", "foundry", "and", "shipyard", ",", "the", "Nagasaki", "Yotetsujo", ",", "near", "Dejima", ",", "the", "Dutch", "settlement", "in", "Nagasaki", "."], "sentence-detokenized": "In 1857, at the request of the Tokugawa Shogunate, Dutch engineers began work on the construction of a modern Western-style foundry and shipyard, the Nagasaki Yotetsujo, near Dejima, the Dutch settlement in Nagasaki.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 39], [40, 49], [49, 50], [51, 56], [57, 66], [67, 72], [73, 77], [78, 80], [81, 84], [85, 97], [98, 100], [101, 102], [103, 109], [110, 117], [117, 118], [118, 123], [124, 131], [132, 135], [136, 144], [144, 145], [146, 149], [150, 158], [159, 168], [168, 169], [170, 174], [175, 181], [181, 182], [183, 186], [187, 192], [193, 203], [204, 206], [207, 215], [215, 216]]}
{"doc_key": "ai-dev-110", "ner": [[10, 12, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["We", "will", "be", "as", "accurate", "as", "possible", "by", "measuring", "the", "mean", "squared", "error", "between", "mathx", "/", "math", "and", "math", "hat", "{", "f", "}", "(", "x", ";", "D", ")", "/", "math", ":", "we", "want", "math", "(", "y", "-", "hat", "{", "f", "}", "(", "x", ";", "D", ")", ")", ".", "mathx", "_", "1", ",\\", "dots", ",", "x", "_n", "/", "math", "and", "points", "outside", "the", "sample", ".", "Both", "require", "^", "2", "/", "math", "to", "be", "minimal", "."], "sentence-detokenized": "We will be as accurate as possible by measuring the mean squared error between mathx / math and math hat {f} (x; D) / math: we want math (y -hat {f} (x; D)). mathx _ 1,\\ dots, x _n / math and points outside the sample. Both require ^ 2 / math to be minimal.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 13], [14, 22], [23, 25], [26, 34], [35, 37], [38, 47], [48, 51], [52, 56], [57, 64], [65, 70], [71, 78], [79, 84], [85, 86], [87, 91], [92, 95], [96, 100], [101, 104], [105, 106], [106, 107], [107, 108], [109, 110], [110, 111], [111, 112], [113, 114], [114, 115], [116, 117], [118, 122], [122, 123], [124, 126], [127, 131], [132, 136], [137, 138], [138, 139], [140, 141], [141, 144], [145, 146], [146, 147], [147, 148], [149, 150], [150, 151], [151, 152], [153, 154], [154, 155], [155, 156], [156, 157], [158, 163], [164, 165], [166, 167], [167, 169], [170, 174], [174, 175], [176, 177], [178, 180], [181, 182], [183, 187], [188, 191], [192, 198], [199, 206], [207, 210], [211, 217], [217, 218], [219, 223], [224, 231], [232, 233], [234, 235], [236, 237], [238, 242], [243, 245], [246, 248], [249, 256], [256, 257]]}
{"doc_key": "ai-dev-111", "ner": [[4, 5, "researcher"], [13, 15, "organisation"], [19, 24, "product"], [29, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 13, 15, "role", "", false, false], [19, 24, 13, 15, "temporal", "", false, false], [19, 24, 29, 30, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "following", "October", ",", "Widener", "was", "invited", "to", "the", "annual", "meeting", "of", "the", "American", "Translators", "Association", ",", "where", "the", "Widener", "Machine", "Translation", "System", "was", "heralded", "as", "a", "breakthrough", "in", "machine", "translation", "."], "sentence-detokenized": "The following October, Widener was invited to the annual meeting of the American Translators Association, where the Widener Machine Translation System was heralded as a breakthrough in machine translation.", "token2charspan": [[0, 3], [4, 13], [14, 21], [21, 22], [23, 30], [31, 34], [35, 42], [43, 45], [46, 49], [50, 56], [57, 64], [65, 67], [68, 71], [72, 80], [81, 92], [93, 104], [104, 105], [106, 111], [112, 115], [116, 123], [124, 131], [132, 143], [144, 150], [151, 154], [155, 163], [164, 166], [167, 168], [169, 181], [182, 184], [185, 192], [193, 204], [204, 205]]}
{"doc_key": "ai-dev-112", "ner": [[0, 2, "conference"], [3, 8, "conference"], [13, 13, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 8, 0, 2, "named", "", false, false], [3, 8, 0, 2, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["2018", "Conference", "on", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", ",", "presented", "by", "Google", "researchers", "."], "sentence-detokenized": "2018 Conference on Neural Information Processing Systems (NeurIPS), presented by Google researchers.", "token2charspan": [[0, 4], [5, 15], [16, 18], [19, 25], [26, 37], [38, 48], [49, 56], [57, 58], [58, 65], [65, 66], [66, 67], [68, 77], [78, 80], [81, 87], [88, 99], [99, 100]]}
{"doc_key": "ai-dev-113", "ner": [[0, 4, "algorithm"], [5, 12, "algorithm"], [13, 18, "metrics"], [22, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 4, 5, 12, "usage", "", false, false], [5, 12, 13, 18, "related-to", "", true, false], [13, 18, 22, 23, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Baum", "-", "Welch", "algorithm", "uses", "the", "well", "-", "known", "EM", "algorithm", "to", "find", "maximum", "likelihood", "estimates", "of", "the", "parameters", "of", "the", "hidden", "Markov", "model", "given", "a", "set", "of", "observed", "feature", "vectors", "."], "sentence-detokenized": "The Baum-Welch algorithm uses the well-known EM algorithm to find maximum likelihood estimates of the parameters of the hidden Markov model given a set of observed feature vectors.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 14], [15, 24], [25, 29], [30, 33], [34, 38], [38, 39], [39, 44], [45, 47], [48, 57], [58, 60], [61, 65], [66, 73], [74, 84], [85, 94], [95, 97], [98, 101], [102, 112], [113, 115], [116, 119], [120, 126], [127, 133], [134, 139], [140, 145], [146, 147], [148, 151], [152, 154], [155, 163], [164, 171], [172, 179], [179, 180]]}
{"doc_key": "ai-dev-114", "ner": [[7, 8, "product"], [28, 30, "misc"], [36, 43, "product"], [33, 55, "product"]], "ner_mapping_to_source": [0, 2, 3, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", "to", "the", "taxonomic", "information", "contained", "in", "OpenCyc", ",", "ResearchCyc", "contains", "substantial", "semantic", "knowledge", "(", "i.e.", "additional", "facts", "and", "rules", "of", "thumb", ")", "about", "the", "concepts", "in", "the", "knowledge", "base", ".", "It", "also", "includes", "an", "extensive", "dictionary", ",", "English", "parsing", "and", "generation", "tools", ",", "and", "a", "Java", "-", "based", "interface", "for", "knowledge", "editing", "and", "querying", "."], "sentence-detokenized": "In addition to the taxonomic information contained in OpenCyc, ResearchCyc contains substantial semantic knowledge (i.e. additional facts and rules of thumb) about the concepts in the knowledge base. It also includes an extensive dictionary, English parsing and generation tools, and a Java-based interface for knowledge editing and querying.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 28], [29, 40], [41, 50], [51, 53], [54, 61], [61, 62], [63, 74], [75, 83], [84, 95], [96, 104], [105, 114], [115, 116], [116, 120], [121, 131], [132, 137], [138, 141], [142, 147], [148, 150], [151, 156], [156, 157], [158, 163], [164, 167], [168, 176], [177, 179], [180, 183], [184, 193], [194, 198], [198, 199], [200, 202], [203, 207], [208, 216], [217, 219], [220, 229], [230, 240], [240, 241], [242, 249], [250, 257], [258, 261], [262, 272], [273, 278], [278, 279], [280, 283], [284, 285], [286, 290], [290, 291], [291, 296], [297, 306], [307, 310], [311, 320], [321, 328], [329, 332], [333, 341], [341, 342]]}
{"doc_key": "ai-dev-115", "ner": [[0, 3, "algorithm"], [4, 7, "task"], [10, 11, "field"], [13, 14, "field"], [16, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 4, 7, "type-of", "", false, false], [4, 7, 10, 11, "part-of", "task_part_of_field", false, false], [4, 7, 13, 14, "part-of", "task_part_of_field", false, false], [4, 7, 16, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Hough", "transform", "is", "a", "feature", "extraction", "technique", "used", "in", "image", "analysis", ",", "computer", "vision", "and", "digital", "image", "processing", "."], "sentence-detokenized": "The Hough transform is a feature extraction technique used in image analysis, computer vision and digital image processing.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 22], [23, 24], [25, 32], [33, 43], [44, 53], [54, 58], [59, 61], [62, 67], [68, 76], [76, 77], [78, 86], [87, 93], [94, 97], [98, 105], [106, 111], [112, 122], [122, 123]]}
{"doc_key": "ai-dev-116", "ner": [[6, 12, "product"], [3, 3, "organisation"], [16, 21, "product"], [17, 17, "researcher"], [23, 25, "organisation"]], "ner_mapping_to_source": [0, 2, 3, 4, 5], "relations": [[6, 12, 3, 3, "artifact", "", false, false], [6, 12, 16, 21, "origin", "developed_from", false, false], [16, 21, 17, 17, "artifact", "", false, false], [23, 25, 3, 3, "role", "supported", false, false]], "relations_mapping_to_source": [1, 2, 3, 4], "sentence": ["In", "1978", ",", "Unimation", "developed", "the", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "robot", "from", "Victor", "Scheinman", "(", "Vicarm", ")", "with", "support", "from", "General", "Motors", "."], "sentence-detokenized": "In 1978, Unimation developed the PUMA (Programmable Universal Machine for Assembly) robot from Victor Scheinman (Vicarm) with support from General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 28], [29, 32], [33, 37], [38, 39], [39, 51], [52, 61], [62, 69], [70, 73], [74, 82], [82, 83], [84, 89], [90, 94], [95, 101], [102, 111], [112, 113], [113, 119], [119, 120], [121, 125], [126, 133], [134, 138], [139, 146], [147, 153], [153, 154]]}
{"doc_key": "ai-dev-117", "ner": [[0, 0, "algorithm"], [4, 4, "researcher"], [7, 9, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "origin", "", false, false], [0, 0, 7, 9, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["LSTM", "was", "proposed", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "in", "1997", "."], "sentence-detokenized": "LSTM was proposed by Sepp Hochreiter and J\u00fcrgen Schmidhuber in 1997.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 20], [21, 25], [26, 36], [37, 40], [41, 47], [48, 59], [60, 62], [63, 67], [67, 68]]}
{"doc_key": "ai-dev-118", "ner": [[11, 12, "metrics"], [14, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "in", "a", "2", "x", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", "."], "sentence-detokenized": "The four results can be formulated in a 2 x 2 contingency table or confusion matrix as follows.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [64, 66], [67, 76], [77, 83], [84, 86], [87, 94], [94, 95]]}
{"doc_key": "ai-dev-119", "ner": [[9, 10, "conference"], [13, 14, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "also", "made", "many", "contributions", "to", "the", "establishment", "of", "ELRA", "and", "to", "LREC", "conferences", "."], "sentence-detokenized": "He has also made many contributions to the establishment of ELRA and to LREC conferences.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 21], [22, 35], [36, 38], [39, 42], [43, 56], [57, 59], [60, 64], [65, 68], [69, 71], [72, 76], [77, 88], [88, 89]]}
{"doc_key": "ai-dev-120", "ner": [[22, 23, "misc"], [25, 28, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[25, 28, 22, 23, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "typical", "application", "for", "serial", "robots", "in", "industry", "today", "is", "four", "-", "degree", "-", "of", "-", "freedom", "pick", "-", "and", "-", "place", "assembly", "robots", ",", "known", "as", "SCARA", "robots", "."], "sentence-detokenized": "A typical application for serial robots in industry today is four-degree-of-freedom pick-and-place assembly robots, known as SCARA robots.", "token2charspan": [[0, 1], [2, 9], [10, 21], [22, 25], [26, 32], [33, 39], [40, 42], [43, 51], [52, 57], [58, 60], [61, 65], [65, 66], [66, 72], [72, 73], [73, 75], [75, 76], [76, 83], [84, 88], [88, 89], [89, 92], [92, 93], [93, 98], [99, 107], [108, 114], [114, 115], [116, 121], [122, 124], [125, 130], [131, 137], [137, 138]]}
{"doc_key": "ai-dev-121", "ner": [[14, 19, "conference"], [13, 23, "conference"], [24, 31, "conference"], [35, 38, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 23, 14, 19, "named", "", false, false], [35, 38, 24, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["One", "of", "the", "founding", "members", "and", "former", "chair", "(", "2006-2008", ")", "of", "the", "Special", "Interest", "Group", "on", "Web", "as", "Corpus", "(", "SIGWAC", ")", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "and", "a", "founding", "organiser", "of", "SENSEVAL", ".", "He", "is", "also", "one", "of", "the", "founding", "organisers", "of", "SENSEVAL", "."], "sentence-detokenized": "One of the founding members and former chair (2006-2008) of the Special Interest Group on Web as Corpus (SIGWAC) of the Association for Computational Linguistics, and a founding organiser of SENSEVAL. He is also one of the founding organisers of SENSEVAL.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 19], [20, 27], [28, 31], [32, 38], [39, 44], [45, 46], [46, 55], [55, 56], [57, 59], [60, 63], [64, 71], [72, 80], [81, 86], [87, 89], [90, 93], [94, 96], [97, 103], [104, 105], [105, 111], [111, 112], [113, 115], [116, 119], [120, 131], [132, 135], [136, 149], [150, 161], [161, 162], [163, 166], [167, 168], [169, 177], [178, 187], [188, 190], [191, 199], [199, 200], [201, 203], [204, 206], [207, 211], [212, 215], [216, 218], [219, 222], [223, 231], [232, 242], [243, 245], [246, 254], [254, 255]]}
{"doc_key": "ai-dev-122", "ner": [[4, 4, "product"], [8, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 4, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "platform", ",", "LinguaStream", "offers", "a", "rich", "Java", "API", "."], "sentence-detokenized": "As a platform, LinguaStream offers a rich Java API.", "token2charspan": [[0, 2], [3, 4], [5, 13], [13, 14], [15, 27], [28, 34], [35, 36], [37, 41], [42, 46], [47, 50], [50, 51]]}
{"doc_key": "ai-dev-123", "ner": [[19, 24, "misc"], [9, 14, "product"]], "ner_mapping_to_source": [1, 2], "relations": [[19, 24, 9, 14, "type-of", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["The", "robot", "kit", "is", "Android", "-", "based", "and", "is", "programmed", "using", "the", "Android", "programming", "system", ",", "including", "Java", "and", "the", "'", "Blocks", "'", "programming", "interface", "."], "sentence-detokenized": "The robot kit is Android-based and is programmed using the Android programming system, including Java and the 'Blocks' programming interface.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 16], [17, 24], [24, 25], [25, 30], [31, 34], [35, 37], [38, 48], [49, 54], [55, 58], [59, 66], [67, 78], [79, 85], [85, 86], [87, 96], [97, 101], [102, 105], [106, 109], [110, 111], [111, 117], [117, 118], [119, 130], [131, 140], [140, 141]]}
{"doc_key": "ai-dev-124", "ner": [[9, 11, "algorithm"], [13, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "method", "of", "defining", "the", "linked", "list", "specifies", "whether", "depth", "-", "first", "or", "width", "-", "first", "search", "should", "be", "used", "."], "sentence-detokenized": "The method of defining the linked list specifies whether depth-first or width-first search should be used.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 22], [23, 26], [27, 33], [34, 38], [39, 48], [49, 56], [57, 62], [62, 63], [63, 68], [69, 71], [72, 77], [77, 78], [78, 83], [84, 90], [91, 97], [98, 100], [101, 105], [105, 106]]}
{"doc_key": "ai-dev-125", "ner": [[19, 19, "task"], [16, 24, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "areas", "indicate", "the", "presence", "of", "objects", "or", "parts", "of", "objects", "in", "the", "image", "and", "have", "potential", "applications", "in", "object", "recognition", "and", "object", "image", "tracking", "."], "sentence-detokenized": "These areas indicate the presence of objects or parts of objects in the image and have potential applications in object recognition and object image tracking.", "token2charspan": [[0, 5], [6, 11], [12, 20], [21, 24], [25, 33], [34, 36], [37, 44], [45, 47], [48, 53], [54, 56], [57, 64], [65, 67], [68, 71], [72, 77], [78, 81], [82, 86], [87, 96], [97, 109], [110, 112], [113, 119], [120, 131], [132, 135], [136, 142], [143, 148], [149, 157], [157, 158]]}
{"doc_key": "ai-dev-126", "ner": [[4, 5, "algorithm"], [6, 7, "product"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 4, 5, "type-of", "", false, false], [6, 7, 10, 10, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "a", "semantic", "network", "is", "WordNet", ",", "an", "English", "lexical", "database", "."], "sentence-detokenized": "An example of a semantic network is WordNet, an English lexical database.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 24], [25, 32], [33, 35], [36, 43], [43, 44], [45, 47], [48, 55], [56, 63], [64, 72], [72, 73]]}
{"doc_key": "ai-dev-127", "ner": [[0, 3, "task"], [7, 7, "field"], [10, 12, "field"], [18, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 7, 7, "part-of", "", false, false], [0, 3, 10, 12, "named", "same", false, false], [0, 3, 10, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Speech", "recognition", "is", "an", "interdisciplinary", "subfield", "of", "computer", "science", "and", "computational", "linguistics", "that", "develops", "methodologies", "and", "techniques", "for", "the", "computer", "recognition", "and", "conversion", "of", "spoken", "language", "into", "text", "."], "sentence-detokenized": "Speech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methodologies and techniques for the computer recognition and conversion of spoken language into text.", "token2charspan": [[0, 6], [7, 18], [19, 21], [22, 24], [25, 42], [43, 51], [52, 54], [55, 63], [64, 71], [72, 75], [76, 89], [90, 101], [102, 106], [107, 115], [116, 129], [130, 133], [134, 144], [145, 148], [149, 152], [153, 161], [162, 173], [174, 177], [178, 188], [189, 191], [192, 198], [199, 207], [208, 212], [213, 217], [217, 218]]}
{"doc_key": "ai-dev-128", "ner": [[0, 1, "field"], [8, 11, "misc"], [13, 18, "field"], [21, 22, "task"], [40, 43, "field"]], "ner_mapping_to_source": [0, 1, 2, 4, 5], "relations": [[0, 1, 40, 43, "named", "same", false, false], [13, 18, 0, 1, "part-of", "subfield", false, false], [21, 22, 13, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 4], "sentence": ["Artificial", "intelligence", "has", "received", "most", "attention", "in", "the", "field", "of", "applied", "ontologies", ",", "such", "as", "natural", "language", "processing", "in", "machines", "and", "knowledge", "representation", ",", "but", "ontology", "editors", "are", "often", "used", "in", "various", "fields", ",", "such", "as", "education", ",", "without", "aiming", "to", "contribute", "to", "AI", "."], "sentence-detokenized": "Artificial intelligence has received most attention in the field of applied ontologies, such as natural language processing in machines and knowledge representation, but ontology editors are often used in various fields, such as education, without aiming to contribute to AI.", "token2charspan": [[0, 10], [11, 23], [24, 27], [28, 36], [37, 41], [42, 51], [52, 54], [55, 58], [59, 64], [65, 67], [68, 75], [76, 86], [86, 87], [88, 92], [93, 95], [96, 103], [104, 112], [113, 123], [124, 126], [127, 135], [136, 139], [140, 149], [150, 164], [164, 165], [166, 169], [170, 178], [179, 186], [187, 190], [191, 196], [197, 201], [202, 204], [205, 212], [213, 219], [219, 220], [221, 225], [226, 228], [229, 238], [238, 239], [240, 247], [248, 254], [255, 257], [258, 268], [269, 271], [272, 274], [274, 275]]}
{"doc_key": "ai-dev-129", "ner": [[6, 8, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 11, 12, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["This", "update", "rule", "is", "actually", "a", "stochastic", "gradient", "descent", "update", "of", "linear", "regression", "."], "sentence-detokenized": "This update rule is actually a stochastic gradient descent update of linear regression.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 19], [20, 28], [29, 30], [31, 41], [42, 50], [51, 58], [59, 65], [66, 68], [69, 75], [76, 86], [86, 87]]}
{"doc_key": "ai-dev-130", "ner": [[6, 11, "organisation"], [14, 17, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "has", "been", "elected", "to", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "the", "National", "Academy", "of", "Sciences", "and", "has", "received", "a", "series", "of", "awards", "."], "sentence-detokenized": "She has been elected to the American Academy of Arts and Sciences and the National Academy of Sciences and has received a series of awards.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 20], [21, 23], [24, 27], [28, 36], [37, 44], [45, 47], [48, 52], [53, 56], [57, 65], [66, 69], [70, 73], [74, 82], [83, 90], [91, 93], [94, 102], [103, 106], [107, 110], [111, 119], [120, 121], [122, 128], [129, 131], [132, 138], [138, 139]]}
{"doc_key": "ai-dev-131", "ner": [[11, 11, "person"], [14, 17, "person"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "most", "recent", "thinking", "on", "Honda", "'s", "strategy", "was", "proposed", "by", "Gary", "Hamel", "and", "C", "K", "Prahalad", "in", "1989", "."], "sentence-detokenized": "The most recent thinking on Honda's strategy was proposed by Gary Hamel and C K Prahalad in 1989.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 24], [25, 27], [28, 33], [33, 35], [36, 44], [45, 48], [49, 57], [58, 60], [61, 65], [66, 71], [72, 75], [76, 77], [78, 79], [80, 88], [89, 91], [92, 96], [96, 97]]}
{"doc_key": "ai-dev-132", "ner": [[0, 1, "metrics"], [5, 6, "metrics"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 5, 6, "related-to", "calculates", true, false], [0, 1, 16, 16, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Whereas", "BLEU", "simply", "calculates", "the", "accuracy", "of", "n-", "grams", "and", "adds", "equal", "weights", "to", "each", ",", "NIST", "also", "calculates", "how", "informative", "a", "particular", "n-", "gram", "is", "."], "sentence-detokenized": "Whereas BLEU simply calculates the accuracy of n-grams and adds equal weights to each, NIST also calculates how informative a particular n-gram is.", "token2charspan": [[0, 7], [8, 12], [13, 19], [20, 30], [31, 34], [35, 43], [44, 46], [47, 49], [49, 54], [55, 58], [59, 63], [64, 69], [70, 77], [78, 80], [81, 85], [85, 86], [87, 91], [92, 96], [97, 107], [108, 111], [112, 123], [124, 125], [126, 136], [137, 139], [139, 143], [144, 146], [146, 147]]}
{"doc_key": "ai-dev-133", "ner": [[0, 5, "misc"], [8, 9, "conference"], [6, 11, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 5, 8, 9, "temporal", "", false, false], [6, 11, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lifetime", "Achievement", "Award", "2019", "from", "the", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "."], "sentence-detokenized": "Lifetime Achievement Award 2019 from the Association for Computational Linguistics (ACL).", "token2charspan": [[0, 8], [9, 20], [21, 26], [27, 31], [32, 36], [37, 40], [41, 52], [53, 56], [57, 70], [71, 82], [83, 84], [84, 87], [87, 88], [88, 89]]}
{"doc_key": "ai-dev-134", "ner": [[0, 0, "researcher"], [6, 13, "organisation"], [1, 23, "conference"]], "ner_mapping_to_source": [0, 2, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sykara", "is", "a", "member", "of", "the", "Institute", "of", "Electrical", "and", "Electronic", "Engineers", "(", "IEEE", ")", "and", "the", "American", "Association", "for", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Sykara is a member of the Institute of Electrical and Electronic Engineers (IEEE) and the American Association for Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 18], [19, 21], [22, 25], [26, 35], [36, 38], [39, 49], [50, 53], [54, 64], [65, 74], [75, 76], [76, 80], [80, 81], [82, 85], [86, 89], [90, 98], [99, 110], [111, 114], [115, 125], [126, 138], [139, 140], [140, 144], [144, 145], [145, 146]]}
{"doc_key": "ai-dev-135", "ner": [[2, 3, "product"], [11, 14, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 11, 14, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "following", "MATLAB", "code", "shows", "a", "specific", "solution", "method", "for", "solving", "the", "non-linear", "simultaneous", "equations", "presented", "in", "the", "previous", "section", ".", "See", "also", "."], "sentence-detokenized": "The following MATLAB code shows a specific solution method for solving the non-linear simultaneous equations presented in the previous section. See also.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 31], [32, 33], [34, 42], [43, 51], [52, 58], [59, 62], [63, 70], [71, 74], [75, 85], [86, 98], [99, 108], [109, 118], [119, 121], [122, 125], [126, 134], [135, 142], [142, 143], [144, 147], [148, 152], [152, 153]]}
{"doc_key": "ai-dev-136", "ner": [[0, 4, "product"], [11, 12, "field"], [33, 34, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 11, 12, "related-to", "trained_by", true, false], [0, 4, 33, 34, "related-to", "trained_by", true, false], [11, 12, 33, 34, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Pattern", "recognition", "systems", "are", "often", "trained", "from", "labelled", "training", "data", "(", "supervised", "learning", ")", ",", "but", "in", "the", "absence", "of", "labelled", "data", ",", "other", "algorithms", "can", "be", "used", "to", "discover", "unknown", "patterns", "(", "unsupervised", "learning", ")", "."], "sentence-detokenized": "Pattern recognition systems are often trained from labelled training data (supervised learning), but in the absence of labelled data, other algorithms can be used to discover unknown patterns (unsupervised learning).", "token2charspan": [[0, 7], [8, 19], [20, 27], [28, 31], [32, 37], [38, 45], [46, 50], [51, 59], [60, 68], [69, 73], [74, 75], [75, 85], [86, 94], [94, 95], [95, 96], [97, 100], [101, 103], [104, 107], [108, 115], [116, 118], [119, 127], [128, 132], [132, 133], [134, 139], [140, 150], [151, 154], [155, 157], [158, 162], [163, 165], [166, 174], [175, 182], [183, 191], [192, 193], [193, 205], [206, 214], [214, 215], [215, 216]]}
{"doc_key": "ai-dev-137", "ner": [[10, 14, "researcher"], [15, 16, "country"], [26, 28, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 14, 15, 16, "physical", "", false, false], [10, 14, 26, 28, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "is", "believed", "that", "pseudo", "-evolution", "was", "first", "used", "by", "Lawrence", "J.", "Vogel", "in", "the", "USA", "in", "1960", "as", "a", "learning", "process", "for", "the", "purpose", "of", "generating", "artificial", "intelligence", "."], "sentence-detokenized": "It is believed that pseudo-evolution was first used by Lawrence J. Vogel in the USA in 1960 as a learning process for the purpose of generating artificial intelligence.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 19], [20, 26], [26, 36], [37, 40], [41, 46], [47, 51], [52, 54], [55, 63], [64, 66], [67, 72], [73, 75], [76, 79], [80, 83], [84, 86], [87, 91], [92, 94], [95, 96], [97, 105], [106, 113], [114, 117], [118, 121], [122, 129], [130, 132], [133, 143], [144, 154], [155, 167], [167, 168]]}
{"doc_key": "ai-dev-138", "ner": [[0, 2, "field"], [10, 11, "field"], [15, 15, "field"], [12, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 10, 11, "part-of", "", false, false], [15, 15, 10, 11, "part-of", "", false, false], [12, 18, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Reinforcement", "learning", "is", "one", "of", "the", "three", "basic", "paradigms", "of", "machine", "learning", ",", "along", "with", "supervised", "and", "unsupervised", "learning", "."], "sentence-detokenized": "Reinforcement learning is one of the three basic paradigms of machine learning, along with supervised and unsupervised learning.", "token2charspan": [[0, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 42], [43, 48], [49, 58], [59, 61], [62, 69], [70, 78], [78, 79], [80, 85], [86, 90], [91, 101], [102, 105], [106, 118], [119, 127], [127, 128]]}
{"doc_key": "ai-dev-139", "ner": [[13, 13, "programlang"], [24, 26, "field"]], "ner_mapping_to_source": [1, 2], "relations": [[13, 13, 24, 26, "usage", "applies", false, false]], "relations_mapping_to_source": [1], "sentence": ["In", "such", "cases", ",", "cloud", "computing", "and", "the", "open", "-", "source", "programming", "language", "R", "can", "help", "small", "and", "medium-sized", "banks", "introduce", "risk", "analysis", ",", "apply", "predictive", "analytics", "and", "support", "branch", "-", "level", "monitoring", "."], "sentence-detokenized": "In such cases, cloud computing and the open-source programming language R can help small and medium-sized banks introduce risk analysis, apply predictive analytics and support branch-level monitoring.", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 20], [21, 30], [31, 34], [35, 38], [39, 43], [43, 44], [44, 50], [51, 62], [63, 71], [72, 73], [74, 77], [78, 82], [83, 88], [89, 92], [93, 105], [106, 111], [112, 121], [122, 126], [127, 135], [135, 136], [137, 142], [143, 153], [154, 163], [164, 167], [168, 175], [176, 182], [182, 183], [183, 188], [189, 199], [199, 200]]}
{"doc_key": "ai-dev-140", "ner": [[12, 13, "researcher"], [19, 20, "algorithm"], [22, 23, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 13, 22, 23, "named", "same", false, false], [19, 20, 12, 13, "origin", "proves_function", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["One", "of", "the", "first", "versions", "of", "this", "theorem", "was", "proved", "by", "George", "Cybenko", "in", "1989", "for", "activation", "functions", "of", "sigmoidal", "functions", ";", "Cybenko", "G.", "(", "1989", ")", ",", "2", "(", "4", ")", ",", "303-314", "."], "sentence-detokenized": "One of the first versions of this theorem was proved by George Cybenko in 1989 for activation functions of sigmoidal functions; Cybenko G. (1989), 2 (4), 303-314.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [17, 25], [26, 28], [29, 33], [34, 41], [42, 45], [46, 52], [53, 55], [56, 62], [63, 70], [71, 73], [74, 78], [79, 82], [83, 93], [94, 103], [104, 106], [107, 116], [117, 126], [126, 127], [128, 135], [136, 138], [139, 140], [140, 144], [144, 145], [145, 146], [147, 148], [149, 150], [150, 151], [151, 152], [152, 153], [154, 161], [161, 162]]}
{"doc_key": "ai-dev-141", "ner": [[0, 7, "algorithm"], [8, 15, "metrics"], [16, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 15, 0, 7, "part-of", "", false, false], [16, 18, 8, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "this", "process", ",", "called", "cross-validation", ",", "the", "MSE", "is", "often", "referred", "to", "as", "the", "mean", "squared", "prediction", "error", "and", "is", "calculated", "as", "follows", "."], "sentence-detokenized": "In this process, called cross-validation, the MSE is often referred to as the mean squared prediction error and is calculated as follows.", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 23], [24, 40], [40, 41], [42, 45], [46, 49], [50, 52], [53, 58], [59, 67], [68, 70], [71, 73], [74, 77], [78, 82], [83, 90], [91, 101], [102, 107], [108, 111], [112, 114], [115, 125], [126, 128], [129, 136], [136, 137]]}
{"doc_key": "ai-dev-142", "ner": [[0, 1, "task"], [6, 6, "task"], [5, 13, "task"], [19, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 6, 6, "compare", "", false, false], [6, 6, 19, 21, "part-of", "", false, false], [5, 13, 6, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OMR", "is", "generally", "distinguished", "from", "optical", "character", "recognition", "(", "OCR", ")", "in", "that", "it", "does", "not", "require", "a", "complex", "pattern", "recognition", "engine", "."], "sentence-detokenized": "OMR is generally distinguished from optical character recognition (OCR) in that it does not require a complex pattern recognition engine.", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 30], [31, 35], [36, 43], [44, 53], [54, 65], [66, 67], [67, 70], [70, 71], [72, 74], [75, 79], [80, 82], [83, 87], [88, 91], [92, 99], [100, 101], [102, 109], [110, 117], [118, 129], [130, 136], [136, 137]]}
{"doc_key": "ai-dev-143", "ner": [[20, 21, "location"], [11, 11, "location"], [10, 16, "location"]], "ner_mapping_to_source": [2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2018", "and", "2019", ",", "the", "Championship", "was", "held", "at", "the", "TCF", "Centre", "and", "Ford", "Field", "in", "Houston", "and", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "In 2018 and 2019, the Championship was held at the TCF Centre and Ford Field in Houston and Detroit, Michigan.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 16], [16, 17], [18, 21], [22, 34], [35, 38], [39, 43], [44, 46], [47, 50], [51, 54], [55, 61], [62, 65], [66, 70], [71, 76], [77, 79], [80, 87], [88, 91], [92, 99], [99, 100], [101, 109], [109, 110]]}
{"doc_key": "ai-dev-144", "ner": [[0, 9, "task"], [8, 13, "task"]], "ner_mapping_to_source": [0, 2], "relations": [[8, 13, 0, 9, "part-of", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Classification", "can", "be", "considered", "as", "two", "separate", "issues", ":", "binary", "classification", "and", "multivalued", "classification", "."], "sentence-detokenized": "Classification can be considered as two separate issues: binary classification and multivalued classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 48], [49, 55], [55, 56], [57, 63], [64, 78], [79, 82], [83, 94], [95, 109], [109, 110]]}
{"doc_key": "ai-dev-145", "ner": [[0, 4, "product"], [5, 12, "product"]], "ner_mapping_to_source": [0, 2], "relations": [[5, 12, 0, 4, "type-of", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Typical", "examples", "of", "parallel", "robots", "are", "the", "Stewart", "platform", "and", "the", "Delta", "robot", "."], "sentence-detokenized": "Typical examples of parallel robots are the Stewart platform and the Delta robot.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 28], [29, 35], [36, 39], [40, 43], [44, 51], [52, 60], [61, 64], [65, 68], [69, 74], [75, 80], [80, 81]]}
{"doc_key": "ai-dev-146", "ner": [[3, 7, "algorithm"], [15, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 7, 15, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "Nevertheless", ",", "ReLU", "activation", "functions", "that", "are", "non-differentiable", "at", "0", "are", "quite", "widespread", ",", "e.g.", "on", "AlexNet", ".", ")"], "sentence-detokenized": "(Nevertheless, ReLU activation functions that are non-differentiable at 0 are quite widespread, e.g. on AlexNet.)", "token2charspan": [[0, 1], [1, 13], [13, 14], [15, 19], [20, 30], [31, 40], [41, 45], [46, 49], [50, 68], [69, 71], [72, 73], [74, 77], [78, 83], [84, 94], [94, 95], [96, 100], [101, 103], [104, 111], [111, 112], [112, 113]]}
{"doc_key": "ai-dev-147", "ner": [[0, 2, "metrics"], [9, 12, "task"], [17, 17, "task"], [19, 20, "task"], [22, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 12, 0, 2, "usage", "", true, false], [17, 17, 9, 12, "part-of", "", false, false], [19, 20, 9, 12, "part-of", "", false, false], [22, 23, 9, 12, "part-of", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4], "sentence": ["F", "-", "scores", "are", "commonly", "used", "in", "the", "field", "of", "information", "retrieval", "to", "measure", "the", "performance", "of", "retrieval", ",", "document", "classification", "and", "query", "classification", "."], "sentence-detokenized": "F-scores are commonly used in the field of information retrieval to measure the performance of retrieval, document classification and query classification.", "token2charspan": [[0, 1], [1, 2], [2, 8], [9, 12], [13, 21], [22, 26], [27, 29], [30, 33], [34, 39], [40, 42], [43, 54], [55, 64], [65, 67], [68, 75], [76, 79], [80, 91], [92, 94], [95, 104], [104, 105], [106, 114], [115, 129], [130, 133], [134, 139], [140, 154], [154, 155]]}
{"doc_key": "ai-dev-148", "ner": [[16, 16, "algorithm"], [18, 18, "algorithm"], [21, 24, "algorithm"], [13, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 3, 5], "relations": [[18, 18, 16, 16, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "is", "done", "by", "modelling", "the", "received", "signal", "and", "using", "statistical", "estimation", "methods", "such", "as", "maximum", "likelihood", "(", "ML", ")", ",", "majority", "voting", "(", "MV", ")", "and", "maximum", "a", "posteriori", "(", "MAP", ")", "to", "determine", "which", "targets", "in", "the", "library", "best", "fit", "the", "model", "built", "using", "the", "received", "signal", "."], "sentence-detokenized": "This is done by modelling the received signal and using statistical estimation methods such as maximum likelihood (ML), majority voting (MV) and maximum a posteriori (MAP) to determine which targets in the library best fit the model built using the received signal.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 15], [16, 25], [26, 29], [30, 38], [39, 45], [46, 49], [50, 55], [56, 67], [68, 78], [79, 86], [87, 91], [92, 94], [95, 102], [103, 113], [114, 115], [115, 117], [117, 118], [118, 119], [120, 128], [129, 135], [136, 137], [137, 139], [139, 140], [141, 144], [145, 152], [153, 154], [155, 165], [166, 167], [167, 170], [170, 171], [172, 174], [175, 184], [185, 190], [191, 198], [199, 201], [202, 205], [206, 213], [214, 218], [219, 222], [223, 226], [227, 232], [233, 238], [239, 244], [245, 248], [249, 257], [258, 264], [264, 265]]}
{"doc_key": "ai-dev-149", "ner": [[0, 4, "misc"], [5, 7, "field"], [8, 13, "university"], [16, 26, "misc"], [18, 18, "field"], [21, 21, "university"], [27, 28, "misc"], [28, 32, "field"], [33, 33, "university"], [43, 87, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 4, 5, 7, "topic", "", false, false], [16, 26, 18, 18, "topic", "", false, false], [27, 28, 28, 32, "topic", "", false, false], [43, 87, 27, 28, "named", "", true, false]], "relations_mapping_to_source": [7, 9, 11, 12], "sentence": ["He", "received", "a", "BSc", "in", "mathematics", "from", "the", "Massachusetts", "Institute", "of", "Technology", "in", "1962", ",", "an", "MSc", "in", "applied", "science", "from", "Harvard", "University", "in", "1966", "and", "a", "PhD", "in", "computer", "science", "from", "the", "Free", "University", "of", "Brussels", "in", "1999", "with", "a", "thesis", "entitled", "Knowledge", "Representation", "In", "1999", ",", "he", "received", "a", "PhD", "from", "the", "Free", "University", "of", "Brussels", "entitled", "Knowledge", "Representation", ":", "logical", ",", "Philosophical", "and", "Computational", "Foundations", "'", ",", "and", "a", "PhD", "from", "the", "Free", "University", "of", "Brussels", "in", "1999", "with", "a", "thesis", "entitled", "'", "Knowledge", "Representation", "."], "sentence-detokenized": "He received a BSc in mathematics from the Massachusetts Institute of Technology in 1962, an MSc in applied science from Harvard University in 1966 and a PhD in computer science from the Free University of Brussels in 1999 with a thesis entitled Knowledge Representation In 1999, he received a PhD from the Free University of Brussels entitled Knowledge Representation: logical, Philosophical and Computational Foundations', and a PhD from the Free University of Brussels in 1999 with a thesis entitled 'Knowledge Representation.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 17], [18, 20], [21, 32], [33, 37], [38, 41], [42, 55], [56, 65], [66, 68], [69, 79], [80, 82], [83, 87], [87, 88], [89, 91], [92, 95], [96, 98], [99, 106], [107, 114], [115, 119], [120, 127], [128, 138], [139, 141], [142, 146], [147, 150], [151, 152], [153, 156], [157, 159], [160, 168], [169, 176], [177, 181], [182, 185], [186, 190], [191, 201], [202, 204], [205, 213], [214, 216], [217, 221], [222, 226], [227, 228], [229, 235], [236, 244], [245, 254], [255, 269], [270, 272], [273, 277], [277, 278], [279, 281], [282, 290], [291, 292], [293, 296], [297, 301], [302, 305], [306, 310], [311, 321], [322, 324], [325, 333], [334, 342], [343, 352], [353, 367], [367, 368], [369, 376], [376, 377], [378, 391], [392, 395], [396, 409], [410, 421], [421, 422], [422, 423], [424, 427], [428, 429], [430, 433], [434, 438], [439, 442], [443, 447], [448, 458], [459, 461], [462, 470], [471, 473], [474, 478], [479, 483], [484, 485], [486, 492], [493, 501], [502, 503], [503, 512], [513, 527], [527, 528]]}
{"doc_key": "ai-dev-150", "ner": [[2, 2, "task"], [7, 7, "task"], [15, 15, "metrics"], [17, 18, "metrics"], [13, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 7, 7, "general-affiliation", "", false, false], [15, 15, 2, 2, "part-of", "", true, false], [17, 18, 2, 2, "part-of", "", true, false], [13, 21, 2, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["As", "paraphrase", "recognition", "is", "treated", "as", "a", "classification", "problem", ",", "standard", "evaluation", "metrics", "such", "as", "accuracy", ",", "f1-", "score", "and", "ROC", "curves", "perform", "relatively", "well", "."], "sentence-detokenized": "As paraphrase recognition is treated as a classification problem, standard evaluation metrics such as accuracy, f1-score and ROC curves perform relatively well.", "token2charspan": [[0, 2], [3, 13], [14, 25], [26, 28], [29, 36], [37, 39], [40, 41], [42, 56], [57, 64], [64, 65], [66, 74], [75, 85], [86, 93], [94, 98], [99, 101], [102, 110], [110, 111], [112, 115], [115, 120], [121, 124], [125, 128], [129, 135], [136, 143], [144, 154], [155, 159], [159, 160]]}
{"doc_key": "ai-dev-151", "ner": [[16, 17, "algorithm"], [25, 28, "algorithm"], [24, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 17, 25, 28, "opposite", "not_suited_for", false, false], [16, 17, 24, 32, "opposite", "not_suited_for", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "makes", "it", "practical", "for", "analysing", "large", "datasets", "(", "hundreds", "or", "thousands", "of", "taxa", ")", "and", "for", "bootstrapping", "where", "other", "means", "of", "analysis", "(", "e.g.", "maximum", "-", "weight", "parsimony", ",", "maximum", "likelihood", "methods", ")", "can", "not", "keep", "up", "with", "the", "calculations", "."], "sentence-detokenized": "This makes it practical for analysing large datasets (hundreds or thousands of taxa) and for bootstrapping where other means of analysis (e.g. maximum-weight parsimony, maximum likelihood methods) cannot keep up with the calculations.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 37], [38, 43], [44, 52], [53, 54], [54, 62], [63, 65], [66, 75], [76, 78], [79, 83], [83, 84], [85, 88], [89, 92], [93, 106], [107, 112], [113, 118], [119, 124], [125, 127], [128, 136], [137, 138], [138, 142], [143, 150], [150, 151], [151, 157], [158, 167], [167, 168], [169, 176], [177, 187], [188, 195], [195, 196], [197, 200], [200, 203], [204, 208], [209, 211], [212, 216], [217, 220], [221, 233], [233, 234]]}
{"doc_key": "ai-dev-152", "ner": [[5, 5, "programlang"], [7, 8, "programlang"], [13, 13, "organisation"], [10, 18, "organisation"], [23, 23, "programlang"], [27, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 23, 23, "named", "same", false, false], [10, 18, 13, 13, "named", "", false, false], [27, 37, 5, 5, "role", "submits", true, false], [27, 37, 7, 8, "role", "submits", true, false], [27, 37, 13, 13, "role", "submits_to", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "2002", "submission", "of", "the", "DAML", "+", "OIL", "language", "to", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", "was", "work", "undertaken", "by", "the", "DAML", "contractor", "and", "the", "European", "Union", "/", "US", "Ad", "Hoc", "Joint", "Committee", "on", "Markup", "Languages", "."], "sentence-detokenized": "The 2002 submission of the DAML + OIL language to the World Wide Web Consortium (W3C) was work undertaken by the DAML contractor and the European Union/US Ad Hoc Joint Committee on Markup Languages.", "token2charspan": [[0, 3], [4, 8], [9, 19], [20, 22], [23, 26], [27, 31], [32, 33], [34, 37], [38, 46], [47, 49], [50, 53], [54, 59], [60, 64], [65, 68], [69, 79], [80, 81], [81, 84], [84, 85], [86, 89], [90, 94], [95, 105], [106, 108], [109, 112], [113, 117], [118, 128], [129, 132], [133, 136], [137, 145], [146, 151], [151, 152], [152, 154], [155, 157], [158, 161], [162, 167], [168, 177], [178, 180], [181, 187], [188, 197], [197, 198]]}
{"doc_key": "ai-dev-153", "ner": [[2, 5, "misc"], [7, 8, "misc"], [6, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 2, 5, "part-of", "", true, false], [6, 17, 2, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "non-linear", "normalisation", "is", "when", "the", "normalisation", "follows", "a", "sigmoid", "function", ",", "in", "which", "case", "the", "normalised", "image", "is", "calculated", "according", "to", "Eq."], "sentence-detokenized": "An example of non-linear normalisation is when the normalisation follows a sigmoid function, in which case the normalised image is calculated according to Eq.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 24], [25, 38], [39, 41], [42, 46], [47, 50], [51, 64], [65, 72], [73, 74], [75, 82], [83, 91], [91, 92], [93, 95], [96, 101], [102, 106], [107, 110], [111, 121], [122, 127], [128, 130], [131, 141], [142, 151], [152, 154], [155, 158]]}
{"doc_key": "ai-dev-154", "ner": [[9, 10, "metrics"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 10, 13, 14, "related-to", "used_together", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "address", "this", "issue", ",", "it", "is", "noted", "that", "accuracy", "is", "usually", "paired", "with", "recall"], "sentence-detokenized": "To address this issue, it is noted that accuracy is usually paired with recall", "token2charspan": [[0, 2], [3, 10], [11, 15], [16, 21], [21, 22], [23, 25], [26, 28], [29, 34], [35, 39], [40, 48], [49, 51], [52, 59], [60, 66], [67, 71], [72, 78]]}
{"doc_key": "ai-dev-155", "ner": [[5, 6, "metrics"], [9, 13, "metrics"], [17, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 24, 9, 13, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Commonly", "used", "indicators", "are", "the", "mean", "squared", "error", "and", "root", "mean", "square", ",", "the", "latter", "of", "which", "has", "also", "been", "used", "in", "the", "Netflix", "Prize", "."], "sentence-detokenized": "Commonly used indicators are the mean squared error and root mean square, the latter of which has also been used in the Netflix Prize.", "token2charspan": [[0, 8], [9, 13], [14, 24], [25, 28], [29, 32], [33, 37], [38, 45], [46, 51], [52, 55], [56, 60], [61, 65], [66, 72], [72, 73], [74, 77], [78, 84], [85, 87], [88, 93], [94, 97], [98, 102], [103, 107], [108, 112], [113, 115], [116, 119], [120, 127], [128, 133], [133, 134]]}
{"doc_key": "ai-dev-156", "ner": [[7, 10, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "August", "2016", ",", "a", "research", "programme", "with", "University", "College", "Hospital", "was", "announced", "to", "develop", "an", "algorithm", "that", "can", "automatically", "distinguish", "between", "healthy", "head", "and", "neck", "tissue", "and", "cancer", "."], "sentence-detokenized": "In August 2016, a research programme with University College Hospital was announced to develop an algorithm that can automatically distinguish between healthy head and neck tissue and cancer.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 17], [18, 26], [27, 36], [37, 41], [42, 52], [53, 60], [61, 69], [70, 73], [74, 83], [84, 86], [87, 94], [95, 97], [98, 107], [108, 112], [113, 116], [117, 130], [131, 142], [143, 150], [151, 158], [159, 163], [164, 167], [168, 172], [173, 179], [180, 183], [184, 190], [190, 191]]}
{"doc_key": "ai-dev-157", "ner": [[0, 0, "researcher"], [16, 18, "organisation"], [21, 24, "organisation"], [26, 30, "organisation"], [32, 38, "organisation"], [40, 47, "organisation"], [50, 53, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 16, 18, "role", "", false, false], [0, 0, 21, 24, "role", "", false, false], [0, 0, 26, 30, "role", "", false, false], [0, 0, 32, 38, "role", "", false, false], [0, 0, 40, 47, "role", "", false, false], [0, 0, 50, 53, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Posner", "'s", "theoretical", "and", "empirical", "contributions", "have", "been", "recognised", "for", "their", "impact", "through", "fellowships", "with", "the", "American", "Psychological", "Association", ",", "the", "Association", "for", "Psychological", "Science", ",", "the", "Society", "of", "Experimental", "Psychologists", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Posner's theoretical and empirical contributions have been recognised for their impact through fellowships with the American Psychological Association, the Association for Psychological Science, the Society of Experimental Psychologists, the American Academy of Arts and Sciences, the American Association for the Advancement of Science and the National Academy of Sciences.", "token2charspan": [[0, 6], [6, 8], [9, 20], [21, 24], [25, 34], [35, 48], [49, 53], [54, 58], [59, 69], [70, 73], [74, 79], [80, 86], [87, 94], [95, 106], [107, 111], [112, 115], [116, 124], [125, 138], [139, 150], [150, 151], [152, 155], [156, 167], [168, 171], [172, 185], [186, 193], [193, 194], [195, 198], [199, 206], [207, 209], [210, 222], [223, 236], [236, 237], [238, 241], [242, 250], [251, 258], [259, 261], [262, 266], [267, 270], [271, 279], [279, 280], [281, 284], [285, 293], [294, 305], [306, 309], [310, 313], [314, 325], [326, 328], [329, 336], [337, 340], [341, 344], [345, 353], [354, 361], [362, 364], [365, 373], [373, 374]]}
{"doc_key": "ai-dev-158", "ner": [[1, 2, "product"], [3, 8, "field"], [11, 11, "task"], [16, 16, "task"], [14, 18, "task"], [21, 25, "task"], [28, 29, "field"], [10, 32, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7, 8], "relations": [[1, 2, 3, 8, "usage", "", false, false], [11, 11, 3, 8, "part-of", "", false, false], [16, 16, 3, 8, "part-of", "", false, false], [14, 18, 16, 16, "named", "", false, false], [28, 29, 3, 8, "part-of", "", false, false], [10, 32, 3, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 6, 7], "sentence": ["These", "intelligent", "chatbots", "utilise", "all", "kinds", "of", "artificial", "intelligence", ",", "including", "image", "moderation", ",", "natural", "language", "understanding", "(", "NLU", ")", ",", "natural", "language", "generation", "(", "NLG", ")", ",", "machine", "learning", "and", "deep", "learning", "."], "sentence-detokenized": "These intelligent chatbots utilise all kinds of artificial intelligence, including image moderation, natural language understanding (NLU), natural language generation (NLG), machine learning and deep learning.", "token2charspan": [[0, 5], [6, 17], [18, 26], [27, 34], [35, 38], [39, 44], [45, 47], [48, 58], [59, 71], [71, 72], [73, 82], [83, 88], [89, 99], [99, 100], [101, 108], [109, 117], [118, 131], [132, 133], [133, 136], [136, 137], [137, 138], [139, 146], [147, 155], [156, 166], [167, 168], [168, 171], [171, 172], [172, 173], [174, 181], [182, 190], [191, 194], [195, 199], [200, 208], [208, 209]]}
{"doc_key": "ai-dev-159", "ner": [[5, 9, "metrics"], [12, 12, "metrics"], [15, 20, "metrics"], [26, 30, "metrics"], [33, 40, "metrics"], [43, 47, "metrics"], [50, 59, "metrics"], [61, 63, "metrics"], [65, 65, "metrics"], [68, 75, "metrics"]], "ner_mapping_to_source": [1, 2, 3, 5, 6, 8, 9, 10, 11, 12], "relations": [[65, 65, 61, 63, "named", "", false, false], [68, 75, 61, 63, "named", "", false, false]], "relations_mapping_to_source": [7, 8], "sentence": ["The", "row", "ratios", "are", "the", "positive", "predictive", "value", "(", "PPV", ",", "aka", "accuracy", ")", "(", "TP", "/", "(", "TP", "+", "FP", ")", ")", "and", "its", "complementary", "false", "discovery", "rate", "(", "FDR", ")", "(", "FP", "/", "(", "TP", "+", "FP", ")", ")", "and", "the", "negative", "predictive", "value", "(", "NPV", ")", "(", "TN", "/", "(", "TN", "+", "FN", ")", ")", "and", "its", "complementary", "false", "leakage", "rate", "(", "FOR", ")", "(", "FN", "/", "(", "TN", "+", "FN", ")", ")", "."], "sentence-detokenized": "The row ratios are the positive predictive value (PPV, aka accuracy) (TP / (TP + FP)) and its complementary false discovery rate (FDR) (FP / (TP + FP)) and the negative predictive value (NPV) (TN / (TN + FN)) and its complementary false leakage rate (FOR) (FN / (TN + FN)).", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 18], [19, 22], [23, 31], [32, 42], [43, 48], [49, 50], [50, 53], [53, 54], [55, 58], [59, 67], [67, 68], [69, 70], [70, 72], [73, 74], [75, 76], [76, 78], [79, 80], [81, 83], [83, 84], [84, 85], [86, 89], [90, 93], [94, 107], [108, 113], [114, 123], [124, 128], [129, 130], [130, 133], [133, 134], [135, 136], [136, 138], [139, 140], [141, 142], [142, 144], [145, 146], [147, 149], [149, 150], [150, 151], [152, 155], [156, 159], [160, 168], [169, 179], [180, 185], [186, 187], [187, 190], [190, 191], [192, 193], [193, 195], [196, 197], [198, 199], [199, 201], [202, 203], [204, 206], [206, 207], [207, 208], [209, 212], [213, 216], [217, 230], [231, 236], [237, 244], [245, 249], [250, 251], [251, 254], [254, 255], [256, 257], [257, 259], [260, 261], [262, 263], [263, 265], [266, 267], [268, 270], [270, 271], [271, 272], [272, 273]]}
{"doc_key": "ai-dev-160", "ner": [[19, 22, "misc"], [7, 7, "algorithm"], [6, 9, "algorithm"], [14, 14, "algorithm"], [12, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 9, 7, 7, "named", "", false, false], [12, 18, 14, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "information", "is", "created", "using", "the", "Information", "Model", "(", "IM", ")", "and", "Biomedical", "Resource", "Ontology", "(", "BRO", ")", "by", "merging", "sitemaps", "and", "RSS", "."], "sentence-detokenized": "The information is created using the Information Model (IM) and Biomedical Resource Ontology (BRO) by merging sitemaps and RSS.", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 26], [27, 32], [33, 36], [37, 48], [49, 54], [55, 56], [56, 58], [58, 59], [60, 63], [64, 74], [75, 83], [84, 92], [93, 94], [94, 97], [97, 98], [99, 101], [102, 109], [110, 118], [119, 122], [123, 126], [126, 127]]}
{"doc_key": "ai-dev-161", "ner": [[1, 2, "task"], [6, 8, "algorithm"], [10, 16, "algorithm"], [19, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 10, 16, "origin", "based_on", false, false], [10, 16, 6, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Modern", "text", "recognition", "is", "based", "on", "recurrent", "neural", "networks", "(", "long", "-", "term", "short", "-", "term", "memory", ")", "and", "does", "not", "require", "a", "language", "model", "."], "sentence-detokenized": "Modern text recognition is based on recurrent neural networks (long-term short-term memory) and does not require a language model.", "token2charspan": [[0, 6], [7, 11], [12, 23], [24, 26], [27, 32], [33, 35], [36, 45], [46, 52], [53, 61], [62, 63], [63, 67], [67, 68], [68, 72], [73, 78], [78, 79], [79, 83], [84, 90], [90, 91], [92, 95], [96, 100], [101, 104], [105, 112], [113, 114], [115, 123], [124, 129], [129, 130]]}
{"doc_key": "ai-dev-162", "ner": [[1, 1, "misc"], [4, 5, "metrics"], [7, 9, "algorithm"], [12, 13, "metrics"], [15, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 1, 1, "type-of", "", false, false], [7, 9, 4, 5, "related-to", "", true, false], [12, 13, 1, 1, "type-of", "", false, false], [15, 17, 12, 13, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Common", "loss", "functions", "include", "hinge", "loss", "(", "for", "linear", "SVM", ")", "and", "log", "loss", "(", "for", "logistic", "regression", ")", "."], "sentence-detokenized": "Common loss functions include hinge loss (for linear SVM) and log loss (for logistic regression).", "token2charspan": [[0, 6], [7, 11], [12, 21], [22, 29], [30, 35], [36, 40], [41, 42], [42, 45], [46, 52], [53, 56], [56, 57], [58, 61], [62, 65], [66, 70], [71, 72], [72, 75], [76, 84], [85, 95], [95, 96], [96, 97]]}
{"doc_key": "ai-dev-163", "ner": [[0, 1, "metrics"], [10, 15, "metrics"], [16, 18, "metrics"], [22, 23, "metrics"], [21, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 10, 15, "compare", "", false, false], [0, 1, 22, 23, "compare", "", false, false], [16, 18, 10, 15, "named", "", false, false], [21, 25, 22, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SSIM", "is", "designed", "to", "improve", "on", "traditional", "methods", "such", "as", "peak", "signal", "-", "to", "-", "noise", "ratio", "(", "PSNR", ")", "and", "mean", "squared", "error", "(", "MSE", ")", "."], "sentence-detokenized": "SSIM is designed to improve on traditional methods such as peak signal-to-noise ratio (PSNR) and mean squared error (MSE).", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 19], [20, 27], [28, 30], [31, 42], [43, 50], [51, 55], [56, 58], [59, 63], [64, 70], [70, 71], [71, 73], [73, 74], [74, 79], [80, 85], [86, 87], [87, 91], [91, 92], [93, 96], [97, 101], [102, 109], [110, 115], [116, 117], [117, 120], [120, 121], [121, 122]]}
{"doc_key": "ai-dev-164", "ner": [[10, 11, "researcher"], [13, 14, "researcher"], [9, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "work", "influenced", "subsequent", "generations", "of", "robotics", "researchers", ",", "including", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "His work influenced subsequent generations of robotics researchers, including Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 3], [4, 8], [9, 19], [20, 30], [31, 42], [43, 45], [46, 54], [55, 66], [66, 67], [68, 77], [78, 84], [85, 91], [91, 92], [93, 97], [98, 105], [106, 109], [110, 114], [115, 121], [121, 122]]}
{"doc_key": "ai-dev-165", "ner": [[16, 19, "algorithm"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Furthermore", ",", "learning", "of", "pulses", "is", "not", "differentiable", "and", "back", "-", "propagation", "-", "based", "learning", "methods", "such", "as", "gradient", "descent", "can", "not", "be", "used", "."], "sentence-detokenized": "Furthermore, learning of pulses is not differentiable and back-propagation-based learning methods such as gradient descent cannot be used.", "token2charspan": [[0, 11], [11, 12], [13, 21], [22, 24], [25, 31], [32, 34], [35, 38], [39, 53], [54, 57], [58, 62], [62, 63], [63, 74], [74, 75], [75, 80], [81, 89], [90, 97], [98, 102], [103, 105], [106, 114], [115, 122], [123, 126], [126, 129], [130, 132], [133, 137], [137, 138]]}
{"doc_key": "ai-dev-166", "ner": [[8, 8, "metrics"], [18, 18, "task"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "relationship", "can", "be", "easily", "expressed", "in", "a", "confusion", "matrix", ",", "a", "table", "representing", "the", "accuracy", "of", "the", "classification", "model", "."], "sentence-detokenized": "This relationship can be easily expressed in a confusion matrix, a table representing the accuracy of the classification model.", "token2charspan": [[0, 4], [5, 17], [18, 21], [22, 24], [25, 31], [32, 41], [42, 44], [45, 46], [47, 56], [57, 63], [63, 64], [65, 66], [67, 72], [73, 85], [86, 89], [90, 98], [99, 101], [102, 105], [106, 120], [121, 126], [126, 127]]}
{"doc_key": "ai-dev-167", "ner": [[7, 9, "conference"], [10, 15, "conference"], [3, 3, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 15, 7, 9, "named", "", false, false], [3, 3, 7, 9, "physical", "", false, false], [3, 3, 7, 9, "role", "", false, false], [3, 3, 7, 9, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Work", "presented", "by", "Google", "researchers", "at", "the", "2018", "Conference", "on", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "."], "sentence-detokenized": "Work presented by Google researchers at the 2018 Conference on Neural Information Processing Systems (NeurIPS).", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 24], [25, 36], [37, 39], [40, 43], [44, 48], [49, 59], [60, 62], [63, 69], [70, 81], [82, 92], [93, 100], [101, 102], [102, 109], [109, 110], [110, 111]]}
{"doc_key": "ai-dev-168", "ner": [[2, 2, "university"], [6, 14, "product"], [15, 20, "misc"], [21, 23, "conference"], [26, 32, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 14, 15, 20, "win-defeat", "", false, false], [15, 20, 21, 23, "temporal", "", false, false], [26, 32, 21, 23, "part-of", "", false, false], [26, 32, 21, 23, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "at", "Duke", "University", ",", "he", "worked", "on", "the", "automatic", "crossword", "solver", "PROVERB", ",", "which", "won", "the", "Outstanding", "Paper", "Award", "from", "the", "AAAI", "in", "1999", "and", "competed", "in", "the", "US", "Crossword", "Puzzle", "Tournament", "."], "sentence-detokenized": "While at Duke University, he worked on the automatic crossword solver PROVERB, which won the Outstanding Paper Award from the AAAI in 1999 and competed in the US Crossword Puzzle Tournament.", "token2charspan": [[0, 5], [6, 8], [9, 13], [14, 24], [24, 25], [26, 28], [29, 35], [36, 38], [39, 42], [43, 52], [53, 62], [63, 69], [70, 77], [77, 78], [79, 84], [85, 88], [89, 92], [93, 104], [105, 110], [111, 116], [117, 121], [122, 125], [126, 130], [131, 133], [134, 138], [139, 142], [143, 151], [152, 154], [155, 158], [159, 161], [162, 171], [172, 178], [179, 189], [189, 190]]}
{"doc_key": "ai-dev-169", "ner": [[4, 5, "location"], [6, 7, "location"], [16, 16, "country"], [18, 18, "country"], [20, 20, "country"], [22, 22, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 6, 7, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "is", "headquartered", "in", "Rochester", "Hills", ",", "Michigan", ",", "and", "has", "10", "regional", "offices", "in", "the", "USA", ",", "Canada", ",", "Mexico", "and", "Brazil", "."], "sentence-detokenized": "It is headquartered in Rochester Hills, Michigan, and has 10 regional offices in the USA, Canada, Mexico and Brazil.", "token2charspan": [[0, 2], [3, 5], [6, 19], [20, 22], [23, 32], [33, 38], [38, 39], [40, 48], [48, 49], [50, 53], [54, 57], [58, 60], [61, 69], [70, 77], [78, 80], [81, 84], [85, 88], [88, 89], [90, 96], [96, 97], [98, 104], [105, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-dev-170", "ner": [[12, 12, "product"], [9, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "joins", "a", "collection", "of", "historically", "significant", "robots", ",", "including", "the", "early", "Unimate", "and", "Odetics", "Odex", "1", "."], "sentence-detokenized": "It joins a collection of historically significant robots, including the early Unimate and Odetics Odex 1.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 21], [22, 24], [25, 37], [38, 49], [50, 56], [56, 57], [58, 67], [68, 71], [72, 77], [78, 85], [86, 89], [90, 97], [98, 102], [103, 104], [104, 105]]}
{"doc_key": "ai-dev-171", "ner": [[14, 15, "organisation"], [7, 52, "researcher"], [19, 69, "misc"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[7, 52, 14, 15, "physical", "", false, false], [7, 52, 14, 15, "role", "", false, false], [7, 52, 19, 69, "win-defeat", "", false, false]], "relations_mapping_to_source": [2, 3, 4], "sentence": ["The", "guest", "editor", "for", "this", "issue", "is", "Judah", "Levine", ",", "David", "'s", "former", "colleague", "at", "NIST", "and", "a", "recent", "recipient", "of", "the", "I", ".", "I", ".", "Rabi", "Award", "The", "I", ".", "I", ".", "Rabi", "Award", "is", "given", "to", "a", "person", "who", "has", "demonstrated", "a", "commitment", "to", "the", "cause", "of", "the", "I", ".", "I", ".", "Rabi", "Award", "and", "has", "been", "awarded", "the", "I", ".", "I", ".", "Rabi", "Prize", "for", "his", "work", "."], "sentence-detokenized": "The guest editor for this issue is Judah Levine, David's former colleague at NIST and a recent recipient of the I. I. Rabi Award The I. I. Rabi Award is given to a person who has demonstrated a commitment to the cause of the I. I. Rabi Award and has been awarded the I. I. Rabi Prize for his work.", "token2charspan": [[0, 3], [4, 9], [10, 16], [17, 20], [21, 25], [26, 31], [32, 34], [35, 40], [41, 47], [47, 48], [49, 54], [54, 56], [57, 63], [64, 73], [74, 76], [77, 81], [82, 85], [86, 87], [88, 94], [95, 104], [105, 107], [108, 111], [112, 113], [113, 114], [115, 116], [116, 117], [118, 122], [123, 128], [129, 132], [133, 134], [134, 135], [136, 137], [137, 138], [139, 143], [144, 149], [150, 152], [153, 158], [159, 161], [162, 163], [164, 170], [171, 174], [175, 178], [179, 191], [192, 193], [194, 204], [205, 207], [208, 211], [212, 217], [218, 220], [221, 224], [225, 226], [226, 227], [228, 229], [229, 230], [231, 235], [236, 241], [242, 245], [246, 249], [250, 254], [255, 262], [263, 266], [267, 268], [268, 269], [270, 271], [271, 272], [273, 277], [278, 283], [284, 287], [288, 291], [292, 296], [296, 297]]}
{"doc_key": "ai-dev-172", "ner": [[11, 19, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "made", "into", "a", "2", "\u00d7", "2", "contingency", "table", "(", "confusion", "matrix", ")", ",", "where", "the", "test", "results", "are", "conventionally", "taken", "on", "the", "vertical", "axis", "and", "the", "actual", "situation", "on", "the", "horizontal", "axis", "."], "sentence-detokenized": "This is made into a 2\u00d72 contingency table (confusion matrix), where the test results are conventionally taken on the vertical axis and the actual situation on the horizontal axis.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 17], [18, 19], [20, 21], [21, 22], [22, 23], [24, 35], [36, 41], [42, 43], [43, 52], [53, 59], [59, 60], [60, 61], [62, 67], [68, 71], [72, 76], [77, 84], [85, 88], [89, 103], [104, 109], [110, 112], [113, 116], [117, 125], [126, 130], [131, 134], [135, 138], [139, 145], [146, 155], [156, 158], [159, 162], [163, 173], [174, 178], [178, 179]]}
{"doc_key": "ai-dev-173", "ner": [[0, 6, "product"], [7, 7, "product"], [9, 9, "product"], [11, 12, "product"], [13, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 6, 7, 7, "part-of", "", false, false], [0, 6, 9, 9, "part-of", "", false, false], [0, 6, 11, 12, "part-of", "", false, false], [0, 6, 13, 21, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Apple", "'s", "iOS", "operating", "system", "on", "the", "iPhone", ",", "iPad", "and", "iPod", "Touch", "uses", "VoiceOver", ",", "a", "text", "-", "to", "-", "speech", "accessibility", "system", "."], "sentence-detokenized": "Apple's iOS operating system on the iPhone, iPad and iPod Touch uses VoiceOver, a text-to-speech accessibility system.", "token2charspan": [[0, 5], [5, 7], [8, 11], [12, 21], [22, 28], [29, 31], [32, 35], [36, 42], [42, 43], [44, 48], [49, 52], [53, 57], [58, 63], [64, 68], [69, 78], [78, 79], [80, 81], [82, 86], [86, 87], [87, 89], [89, 90], [90, 96], [97, 110], [111, 117], [117, 118]]}
{"doc_key": "ai-dev-174", "ner": [[0, 11, "conference"], [12, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "the", "best", "system", "entering", "the", "MUC", "-", "7", "was", "F-", "measure", "with", "93.39", "%", ",", "compared", "to", "97.6", "%", "and", "96.95", "%", "for", "human", "annotators", "."], "sentence-detokenized": "For example, the best system entering the MUC-7 was F-measure with 93.39%, compared to 97.6% and 96.95% for human annotators.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 37], [38, 41], [42, 45], [45, 46], [46, 47], [48, 51], [52, 54], [54, 61], [62, 66], [67, 72], [72, 73], [73, 74], [75, 83], [84, 86], [87, 91], [91, 92], [93, 96], [97, 102], [102, 103], [104, 107], [108, 113], [114, 124], [124, 125]]}
{"doc_key": "ai-dev-175", "ner": [[9, 14, "algorithm"], [0, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 15, 9, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "is", "done", "using", "standard", "neural", "net", "learning", "algorithms", "such", "as", "stochastic", "gradient", "descent", "with", "backpropagation", "."], "sentence-detokenized": "This is done using standard neural net learning algorithms such as stochastic gradient descent with backpropagation.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 18], [19, 27], [28, 34], [35, 38], [39, 47], [48, 58], [59, 63], [64, 66], [67, 77], [78, 86], [87, 94], [95, 99], [100, 115], [115, 116]]}
{"doc_key": "ai-dev-176", "ner": [[0, 1, "organisation"], [21, 25, "product"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Rotten", "Tomatoes", "is", "a", "Top", "1000", "site", ",", "ranked", "approximately", "400th", "in", "the", "world", "and", "150th", "in", "the", "US", "alone", ",", "according", "to", "website", "ranker", "Alexa", "."], "sentence-detokenized": "Rotten Tomatoes is a Top 1000 site, ranked approximately 400th in the world and 150th in the US alone, according to website ranker Alexa.", "token2charspan": [[0, 6], [7, 15], [16, 18], [19, 20], [21, 24], [25, 29], [30, 34], [34, 35], [36, 42], [43, 56], [57, 62], [63, 65], [66, 69], [70, 75], [76, 79], [80, 85], [86, 88], [89, 92], [93, 95], [96, 101], [101, 102], [103, 112], [113, 115], [116, 123], [124, 130], [131, 136], [136, 137]]}
{"doc_key": "ai-dev-177", "ner": [[7, 9, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "general", ",", "all", "learning", "describes", "a", "sigmoid", "function", "that", "exhibits", "gradual", "changes", "over", "time", ",", "but", "which", "shows", "different", "aspects", "depending", "on", "the", "time", "scale", "of", "the", "observation", "."], "sentence-detokenized": "In general, all learning describes a sigmoid function that exhibits gradual changes over time, but which shows different aspects depending on the time scale of the observation.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 24], [25, 34], [35, 36], [37, 44], [45, 53], [54, 58], [59, 67], [68, 75], [76, 83], [84, 88], [89, 93], [93, 94], [95, 98], [99, 104], [105, 110], [111, 120], [121, 128], [129, 138], [139, 141], [142, 145], [146, 150], [151, 156], [157, 159], [160, 163], [164, 175], [175, 176]]}
{"doc_key": "ai-dev-178", "ner": [[0, 1, "metrics"], [2, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 2, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["SSD", "is", "also", "referred", "to", "as", "the", "mean", "squared", "error", "."], "sentence-detokenized": "SSD is also referred to as the mean squared error.", "token2charspan": [[0, 3], [4, 6], [7, 11], [12, 20], [21, 23], [24, 26], [27, 30], [31, 35], [36, 43], [44, 49], [49, 50]]}
{"doc_key": "ai-dev-179", "ner": [[0, 2, "algorithm"], [4, 5, "algorithm"], [7, 11, "algorithm"], [21, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 21, 24, "related-to", "can_be_related_to", true, false], [4, 5, 21, 24, "related-to", "can_be_related_to", true, false], [7, 11, 21, 24, "related-to", "can_be_related_to", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", ",", "neural", "networks", ",", "na\u00efve", "Bayes", "classifiers", ",", "etc.", "can", "be", "used", "in", "combination", "with", "model", "quality", "indicators", "such", "as", "balance", "accuracy", "."], "sentence-detokenized": "Decision tree learning, neural networks, na\u00efve Bayes classifiers, etc. can be used in combination with model quality indicators such as balance accuracy.", "token2charspan": [[0, 8], [9, 13], [14, 22], [22, 23], [24, 30], [31, 39], [39, 40], [41, 46], [47, 52], [53, 64], [64, 65], [66, 70], [71, 74], [75, 77], [78, 82], [83, 85], [86, 97], [98, 102], [103, 108], [109, 116], [117, 127], [128, 132], [133, 135], [136, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-dev-180", "ner": [[13, 13, "conference"], [18, 22, "conference"], [23, 26, "misc"], [30, 32, "product"], [19, 20, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[23, 26, 18, 22, "origin", "", false, false], [23, 26, 18, 22, "temporal", "", false, false], [30, 32, 23, 26, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Past", "President", "(", "1979", ")", "and", "first", "Fellow", "(", "2011", ")", "of", "the", "ACL", ",", "co-winner", "of", "the", "1992", "Association", "for", "Computing", "Machinery", "Software", "Systems", "Award", "for", "contributions", "to", "the", "programming", "system", "Interlisp", ",", "Fellow", ".", "He", "is", "."], "sentence-detokenized": "Past President (1979) and first Fellow (2011) of the ACL, co-winner of the 1992 Association for Computing Machinery Software Systems Award for contributions to the programming system Interlisp, Fellow. He is.", "token2charspan": [[0, 4], [5, 14], [15, 16], [16, 20], [20, 21], [22, 25], [26, 31], [32, 38], [39, 40], [40, 44], [44, 45], [46, 48], [49, 52], [53, 56], [56, 57], [58, 67], [68, 70], [71, 74], [75, 79], [80, 91], [92, 95], [96, 105], [106, 115], [116, 124], [125, 132], [133, 138], [139, 142], [143, 156], [157, 159], [160, 163], [164, 175], [176, 182], [183, 192], [192, 193], [194, 200], [200, 201], [202, 204], [205, 207], [207, 208]]}
{"doc_key": "ai-dev-181", "ner": [[8, 9, "researcher"], [6, 12, "researcher"], [4, 4, "researcher"], [0, 3, "researcher"], [24, 29, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 9, 24, 29, "related-to", "", false, false], [6, 12, 24, 29, "related-to", "", false, false], [4, 4, 24, 29, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Cade", "Metz", "believes", "that", "Bengio", ",", "along", "with", "Jeffrey", "Hinton", "and", "Jan", "Lukun", ",", "were", "among", "the", "three", "people", "who", "contributed", "most", "to", "the", "progress", "of", "deep", "learning", "in", "the", "1990s", "and", "2000s", "."], "sentence-detokenized": "Cade Metz believes that Bengio, along with Jeffrey Hinton and Jan Lukun, were among the three people who contributed most to the progress of deep learning in the 1990s and 2000s.", "token2charspan": [[0, 4], [5, 9], [10, 18], [19, 23], [24, 30], [30, 31], [32, 37], [38, 42], [43, 50], [51, 57], [58, 61], [62, 65], [66, 71], [71, 72], [73, 77], [78, 83], [84, 87], [88, 93], [94, 100], [101, 104], [105, 116], [117, 121], [122, 124], [125, 128], [129, 137], [138, 140], [141, 145], [146, 154], [155, 157], [158, 161], [162, 167], [168, 171], [172, 177], [177, 178]]}
{"doc_key": "ai-dev-182", "ner": [[0, 1, "field"], [4, 5, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "information", "theory", "and", "computer", "science", ",", "a", "code", "is", "usually", "considered", "to", "be", "an", "algorithm", "that", "uniquely", "represents", "a", "symbol", "in", "one", "source", "alphabet", "with", "an", "encoded", "string", "that", "could", "be", "in", "another", "target", "alphabet", "."], "sentence-detokenized": "In information theory and computer science, a code is usually considered to be an algorithm that uniquely represents a symbol in one source alphabet with an encoded string that could be in another target alphabet.", "token2charspan": [[0, 2], [3, 14], [15, 21], [22, 25], [26, 34], [35, 42], [42, 43], [44, 45], [46, 50], [51, 53], [54, 61], [62, 72], [73, 75], [76, 78], [79, 81], [82, 91], [92, 96], [97, 105], [106, 116], [117, 118], [119, 125], [126, 128], [129, 132], [133, 139], [140, 148], [149, 153], [154, 156], [157, 164], [165, 171], [172, 176], [177, 182], [183, 185], [186, 188], [189, 196], [197, 203], [204, 212], [212, 213]]}
{"doc_key": "ai-dev-183", "ner": [[0, 1, "algorithm"], [2, 8, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 8, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sigmoidal", "functions", "such", "as", "logistic", "functions", ",", "which", "are", "fairly", "simple", "non-linear", "functions", ",", "can", "be", "important", "when", "calculating", "weight", "updates", "in", "networks", ",", "as", "derivatives", "are", "also", "easily", "calculated", "."], "sentence-detokenized": "Sigmoidal functions such as logistic functions, which are fairly simple non-linear functions, can be important when calculating weight updates in networks, as derivatives are also easily calculated.", "token2charspan": [[0, 9], [10, 19], [20, 24], [25, 27], [28, 36], [37, 46], [46, 47], [48, 53], [54, 57], [58, 64], [65, 71], [72, 82], [83, 92], [92, 93], [94, 97], [98, 100], [101, 110], [111, 115], [116, 127], [128, 134], [135, 142], [143, 145], [146, 154], [154, 155], [156, 158], [159, 170], [171, 174], [175, 179], [180, 186], [187, 197], [197, 198]]}
{"doc_key": "ai-dev-184", "ner": [[0, 1, "person"], [5, 6, "location"], [8, 8, "location"], [10, 12, "country"], [15, 15, "country"], [17, 19, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 5, 6, "physical", "", false, false], [5, 6, 8, 8, "physical", "", false, false], [8, 8, 10, 12, "physical", "", false, false], [8, 8, 15, 15, "physical", "", false, false], [8, 8, 17, 19, "physical", "", false, false], [15, 15, 10, 12, "origin", "", false, false], [17, 19, 15, 15, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["\u010capek", "was", "born", "in", "1887", "in", "Hronov", ",", "Bohemia", "(", "Austria", "-", "Hungary", ",", "later", "Czechoslovakia", ",", "now", "Czech", "Republic", ")", "."], "sentence-detokenized": "\u010capek was born in 1887 in Hronov, Bohemia (Austria-Hungary, later Czechoslovakia, now Czech Republic).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 41], [42, 43], [43, 50], [50, 51], [51, 58], [58, 59], [60, 65], [66, 80], [80, 81], [82, 85], [86, 91], [92, 100], [100, 101], [101, 102]]}
{"doc_key": "ai-dev-185", "ner": [[4, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "specialised", "software", "can", "narrate", "RSS", "."], "sentence-detokenized": "Some specialised software can narrate RSS.", "token2charspan": [[0, 4], [5, 16], [17, 25], [26, 29], [30, 37], [38, 41], [41, 42]]}
{"doc_key": "ai-dev-186", "ner": [[6, 7, "task"], [9, 11, "task"], [15, 15, "task"], [18, 18, "task"], [13, 20, "task"], [28, 29, "task"], [31, 33, "task"], [37, 39, "task"], [46, 46, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 9], "relations": [[6, 7, 9, 11, "related-to", "", true, false], [6, 7, 15, 15, "related-to", "", true, false], [6, 7, 18, 18, "related-to", "", true, false], [31, 33, 28, 29, "usage", "", true, false], [46, 46, 37, 39, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5], "sentence": ["Features", "of", "the", "ontology", "editor", "include", "visual", "navigation", "within", "the", "knowledge", "model", ",", "support", "for", "inference", "engines", ",", "extractions", "and", "modules", ",", "import", "and", "export", "of", "foreign", "language", "knowledge", "representation", "languages", "for", "ontology", "collation", ",", "and", "support", "for", "meta", "-ontologies", "such", "as", "OWL", "-", "S", "and", "Dublin", "Core", "."], "sentence-detokenized": "Features of the ontology editor include visual navigation within the knowledge model, support for inference engines, extractions and modules, import and export of foreign language knowledge representation languages for ontology collation, and support for meta-ontologies such as OWL-S and Dublin Core.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 24], [25, 31], [32, 39], [40, 46], [47, 57], [58, 64], [65, 68], [69, 78], [79, 84], [84, 85], [86, 93], [94, 97], [98, 107], [108, 115], [115, 116], [117, 128], [129, 132], [133, 140], [140, 141], [142, 148], [149, 152], [153, 159], [160, 162], [163, 170], [171, 179], [180, 189], [190, 204], [205, 214], [215, 218], [219, 227], [228, 237], [237, 238], [239, 242], [243, 250], [251, 254], [255, 259], [259, 270], [271, 275], [276, 278], [279, 282], [282, 283], [283, 284], [285, 288], [289, 295], [296, 300], [300, 301]]}
{"doc_key": "ai-dev-187", "ner": [[0, 1, "organisation"], [6, 11, "misc"], [12, 17, "task"], [19, 19, "field"], [20, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[6, 11, 0, 1, "origin", "", false, false], [12, 17, 6, 11, "part-of", "", false, false], [19, 19, 6, 11, "part-of", "", false, false], [20, 27, 19, 19, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4], "sentence": ["The", "FBI", "has", "also", "instituted", "a", "next", "-", "generation", "ID", "programme", "that", "includes", "facial", "recognition", "in", "addition", "to", "traditional", "biometrics", "such", "as", "fingerprints", "and", "iris", "scans", ",", "which", "can", "be", "drawn", "from", "both", "criminal", "and", "civil", "databases", "."], "sentence-detokenized": "The FBI has also instituted a next-generation ID programme that includes facial recognition in addition to traditional biometrics such as fingerprints and iris scans, which can be drawn from both criminal and civil databases.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 16], [17, 27], [28, 29], [30, 34], [34, 35], [35, 45], [46, 48], [49, 58], [59, 63], [64, 72], [73, 79], [80, 91], [92, 94], [95, 103], [104, 106], [107, 118], [119, 129], [130, 134], [135, 137], [138, 150], [151, 154], [155, 159], [160, 165], [165, 166], [167, 172], [173, 176], [177, 179], [180, 185], [186, 190], [191, 195], [196, 204], [205, 208], [209, 214], [215, 224], [224, 225]]}
{"doc_key": "ai-dev-188", "ner": [[5, 6, "person"], [7, 10, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "the", "2016", "season", ",", "Samantha", "Ponder", "replaced", "Molly", "McGrath", "as", "presenter", "."], "sentence-detokenized": "For the 2016 season, Samantha Ponder replaced Molly McGrath as presenter.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 19], [19, 20], [21, 29], [30, 36], [37, 45], [46, 51], [52, 59], [60, 62], [63, 72], [72, 73]]}
{"doc_key": "ai-dev-189", "ner": [[0, 2, "algorithm"], [16, 19, "misc"], [21, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Adversarial", "search", "algorithms", "are", "commonly", "used", "in", "machine", "learning", "of", "two", "-", "player", "games", "(", "e.g.", "three", "-", "way", "parallels", ",", "chess", ",", "Go", ")", "."], "sentence-detokenized": "Adversarial search algorithms are commonly used in machine learning of two-player games (e.g. three-way parallels, chess, Go).", "token2charspan": [[0, 11], [12, 18], [19, 29], [30, 33], [34, 42], [43, 47], [48, 50], [51, 58], [59, 67], [68, 70], [71, 74], [74, 75], [75, 81], [82, 87], [88, 89], [89, 93], [94, 99], [99, 100], [100, 103], [104, 113], [113, 114], [115, 120], [120, 121], [122, 124], [124, 125], [125, 126]]}
{"doc_key": "ai-dev-190", "ner": [[7, 7, "field"], [10, 11, "field"], [3, 15, "field"], [22, 23, "field"], [25, 26, "field"], [19, 29, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "involved", "in", "areas", "such", "as", "computer", "vision", ",", "machine", "vision", "and", "medical", "image", "processing", ",", "and", "makes", "extensive", "use", "of", "pattern", "recognition", ",", "digital", "geometry", "and", "signal", "processing", "."], "sentence-detokenized": "It is involved in areas such as computer vision, machine vision and medical image processing, and makes extensive use of pattern recognition, digital geometry and signal processing.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 23], [24, 28], [29, 31], [32, 40], [41, 47], [47, 48], [49, 56], [57, 63], [64, 67], [68, 75], [76, 81], [82, 92], [92, 93], [94, 97], [98, 103], [104, 113], [114, 117], [118, 120], [121, 128], [129, 140], [140, 141], [142, 149], [150, 158], [159, 162], [163, 169], [170, 180], [180, 181]]}
{"doc_key": "ai-dev-191", "ner": [[0, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "in", "a", "face", "recognition", "system", ",", "the", "input", "is", "a", "photograph", "of", "a", "person", "'s", "face", "and", "the", "output", "label", "is", "the", "person", "'s", "name", "."], "sentence-detokenized": "For example, in a face recognition system, the input is a photograph of a person's face and the output label is the person's name.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 17], [18, 22], [23, 34], [35, 41], [41, 42], [43, 46], [47, 52], [53, 55], [56, 57], [58, 68], [69, 71], [72, 73], [74, 80], [80, 82], [83, 87], [88, 91], [92, 95], [96, 102], [103, 108], [109, 111], [112, 115], [116, 122], [122, 124], [125, 129], [129, 130]]}
{"doc_key": "ai-dev-192", "ner": [[0, 1, "organisation"], [2, 5, "product"], [6, 12, "product"], [15, 19, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 2, 5, "artifact", "", false, false], [2, 5, 6, 12, "part-of", "", false, false], [6, 12, 2, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Apple", "Inc.", "introduced", "Face", "ID", "on", "its", "flagship", "i", "Phone", "X", "as", "a", "biometric", "successor", "to", "Touch", "ID", ",", "which", "uses", "fingerprints", "."], "sentence-detokenized": "Apple Inc. introduced Face ID on its flagship iPhone X as a biometric successor to Touch ID, which uses fingerprints.", "token2charspan": [[0, 5], [6, 10], [11, 21], [22, 26], [27, 29], [30, 32], [33, 36], [37, 45], [46, 47], [47, 52], [53, 54], [55, 57], [58, 59], [60, 69], [70, 79], [80, 82], [83, 88], [89, 91], [91, 92], [93, 98], [99, 103], [104, 116], [116, 117]]}
{"doc_key": "ai-dev-193", "ner": [[9, 17, "metrics"], [24, 33, "metrics"]], "ner_mapping_to_source": [1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Alternatively", ",", "one", "could", "combine", "the", "F", "-", "measure", "with", "the", "raw", "model", "outputs", "and", "the", "R-", "squared", "evaluated", "for", "the", "target", ",", "or", "combine", "the", "cost", "/", "gain", "matrix", "with", "the", "correlation", "coefficient", "."], "sentence-detokenized": "Alternatively, one could combine the F-measure with the raw model outputs and the R-squared evaluated for the target, or combine the cost/gain matrix with the correlation coefficient.", "token2charspan": [[0, 13], [13, 14], [15, 18], [19, 24], [25, 32], [33, 36], [37, 38], [38, 39], [39, 46], [47, 51], [52, 55], [56, 59], [60, 65], [66, 73], [74, 77], [78, 81], [82, 84], [84, 91], [92, 101], [102, 105], [106, 109], [110, 116], [116, 117], [118, 120], [121, 128], [129, 132], [133, 137], [137, 138], [138, 142], [143, 149], [150, 154], [155, 158], [159, 170], [171, 182], [182, 183]]}
{"doc_key": "ai-dev-194", "ner": [[0, 7, "conference"], [20, 22, "location"], [24, 25, "location"], [15, 27, "location"], [28, 28, "location"], [30, 30, "country"], [38, 38, "location"], [41, 45, "location"], [37, 37, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 7, 20, 22, "physical", "", false, false], [0, 7, 15, 27, "physical", "", false, false], [0, 7, 38, 38, "physical", "", false, false], [0, 7, 41, 45, "physical", "", false, false], [20, 22, 24, 25, "physical", "", false, false], [15, 27, 28, 28, "physical", "", false, false], [28, 28, 30, 30, "physical", "", false, false], [38, 38, 37, 37, "physical", "", false, false], [41, 45, 37, 37, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "Spanish", "edition", "of", "Campus", "Party", "has", "been", "held", "for", "the", "past", "15", "years", "at", "the", "Municipal", "Sport", "Arena", "in", "Colegio", "Miguel", "Hern\u00e1ndez", ",", "Ceulaj", "and", "Benalm\u00e1dena", "in", "M\u00e1laga", ",", "Spain", ",", "and", "in", "Valencia", "at", "the", "Valencia", "County", "Municipality", "and", "City", "of", "Arts", "and", "Sciences", ".", "The", "event", "was", "held", "in", "Valencia", "at", "the", "Valencia", "County", "Municipality", "and", "City", "of", "Arts", "and", "Sciences", "."], "sentence-detokenized": "The Spanish edition of Campus Party has been held for the past 15 years at the Municipal Sport Arena in Colegio Miguel Hern\u00e1ndez, Ceulaj and Benalm\u00e1dena in M\u00e1laga, Spain, and in Valencia at the Valencia County Municipality and City of Arts and Sciences. The event was held in Valencia at the Valencia County Municipality and City of Arts and Sciences.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 22], [23, 29], [30, 35], [36, 39], [40, 44], [45, 49], [50, 53], [54, 57], [58, 62], [63, 65], [66, 71], [72, 74], [75, 78], [79, 88], [89, 94], [95, 100], [101, 103], [104, 111], [112, 118], [119, 128], [128, 129], [130, 136], [137, 140], [141, 152], [153, 155], [156, 162], [162, 163], [164, 169], [169, 170], [171, 174], [175, 177], [178, 186], [187, 189], [190, 193], [194, 202], [203, 209], [210, 222], [223, 226], [227, 231], [232, 234], [235, 239], [240, 243], [244, 252], [252, 253], [254, 257], [258, 263], [264, 267], [268, 272], [273, 275], [276, 284], [285, 287], [288, 291], [292, 300], [301, 307], [308, 320], [321, 324], [325, 329], [330, 332], [333, 337], [338, 341], [342, 350], [350, 351]]}
{"doc_key": "ai-dev-195", "ner": [[0, 0, "product"], [11, 11, "programlang"], [15, 15, "product"], [17, 17, "product"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 11, 0, 0, "general-affiliation", "", false, false], [15, 15, 11, 11, "part-of", "", false, false], [17, 17, 11, 11, "part-of", "", false, false], [21, 21, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["gnuplot", "can", "graph", "data", "from", "a", "variety", "of", "programming", "languages", ",", "Perl", "(", "via", "the", "PDL", "and", "CPAN", "packages", ")", "and", "Python", "(", "via"], "sentence-detokenized": "gnuplot can graph data from a variety of programming languages, Perl (via the PDL and CPAN packages) and Python (via", "token2charspan": [[0, 7], [8, 11], [12, 17], [18, 22], [23, 27], [28, 29], [30, 37], [38, 40], [41, 52], [53, 62], [62, 63], [64, 68], [69, 70], [70, 73], [74, 77], [78, 81], [82, 85], [86, 90], [91, 99], [99, 100], [101, 104], [105, 111], [112, 113], [113, 116]]}
{"doc_key": "ai-dev-196", "ner": [[2, 6, "product"], [18, 22, "conference"], [34, 38, "conference"]], "ner_mapping_to_source": [0, 2, 4], "relations": [[18, 22, 2, 6, "topic", "", false, false], [34, 38, 2, 6, "topic", "", false, false]], "relations_mapping_to_source": [1, 3], "sentence": ["The", "field", "of", "spoken", "dialogue", "systems", "is", "very", "large", "and", "includes", "both", "research", "(", "covered", "by", "scientific", "conferences", "such", "as", "SIGdial", "and", "Interspeech", ")", "and", "a", "large", "industry", "sector", "(", "with", "its", "own", "conferences", "such", "as", "SpeechTek", "and", "AVIOS", ")", "."], "sentence-detokenized": "The field of spoken dialogue systems is very large and includes both research (covered by scientific conferences such as SIGdial and Interspeech) and a large industry sector (with its own conferences such as SpeechTek and AVIOS).", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 28], [29, 36], [37, 39], [40, 44], [45, 50], [51, 54], [55, 63], [64, 68], [69, 77], [78, 79], [79, 86], [87, 89], [90, 100], [101, 112], [113, 117], [118, 120], [121, 128], [129, 132], [133, 144], [144, 145], [146, 149], [150, 151], [152, 157], [158, 166], [167, 173], [174, 175], [175, 179], [180, 183], [184, 187], [188, 199], [200, 204], [205, 207], [208, 217], [218, 221], [222, 227], [227, 228], [228, 229]]}
{"doc_key": "ai-dev-197", "ner": [[0, 3, "field"], [8, 9, "task"], [11, 13, "task"], [5, 17, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 0, 3, "part-of", "task_part_of_field", false, false], [11, 13, 0, 3, "part-of", "task_part_of_field", false, false], [5, 17, 0, 3, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "natural", "language", "processing", ",", "tasks", "such", "as", "speech", "recognition", ",", "natural", "language", "understanding", "and", "natural", "language", "generation", "are", "frequent", "."], "sentence-detokenized": "In natural language processing, tasks such as speech recognition, natural language understanding and natural language generation are frequent.", "token2charspan": [[0, 2], [3, 10], [11, 19], [20, 30], [30, 31], [32, 37], [38, 42], [43, 45], [46, 52], [53, 64], [64, 65], [66, 73], [74, 82], [83, 96], [97, 100], [101, 108], [109, 117], [118, 128], [129, 132], [133, 141], [141, 142]]}
{"doc_key": "ai-dev-198", "ner": [[5, 7, "product"], [25, 26, "task"]], "ner_mapping_to_source": [0, 2], "relations": [[5, 7, 25, 26, "usage", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["These", "systems", ",", "such", "as", "Siri", "in", "iOS", ",", "work", "with", "pattern", "recognition", "technology", "similar", "to", "text", "-", "based", "systems", ",", "but", "the", "former", "uses", "speech", "recognition", "to", "provide", "input", "from", "the", "user", "."], "sentence-detokenized": "These systems, such as Siri in iOS, work with pattern recognition technology similar to text-based systems, but the former uses speech recognition to provide input from the user.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 22], [23, 27], [28, 30], [31, 34], [34, 35], [36, 40], [41, 45], [46, 53], [54, 65], [66, 76], [77, 84], [85, 87], [88, 92], [92, 93], [93, 98], [99, 106], [106, 107], [108, 111], [112, 115], [116, 122], [123, 127], [128, 134], [135, 146], [147, 149], [150, 157], [158, 163], [164, 168], [169, 172], [173, 177], [177, 178]]}
{"doc_key": "ai-dev-199", "ner": [[1, 2, "algorithm"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 15, 17, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["More", "exotic", "fitness", "functions", "that", "pursue", "the", "granularity", "of", "the", "model", "include", "the", "area", "under", "the", "ROC", "curve", "and", "the", "rank", "scale", "."], "sentence-detokenized": "More exotic fitness functions that pursue the granularity of the model include the area under the ROC curve and the rank scale.", "token2charspan": [[0, 4], [5, 11], [12, 19], [20, 29], [30, 34], [35, 41], [42, 45], [46, 57], [58, 60], [61, 64], [65, 70], [71, 78], [79, 82], [83, 87], [88, 93], [94, 97], [98, 101], [102, 107], [108, 111], [112, 115], [116, 120], [121, 126], [126, 127]]}
{"doc_key": "ai-dev-200", "ner": [[1, 4, "product"], [7, 10, "researcher"], [14, 17, "product"], [24, 25, "organisation"], [27, 30, "organisation"], [34, 38, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 4, 7, 10, "origin", "", false, false], [7, 10, 24, 25, "role", "", false, false], [14, 17, 7, 10, "origin", "", false, false], [27, 30, 24, 25, "named", "", false, false], [34, 38, 24, 25, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "term", "Semantic", "Web", "was", "coined", "by", "Tim", "Berners", "-", "Lee", ",", "inventor", "of", "the", "World", "Wide", "Web", "and", "director", "of", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "which", "oversees", "the", "development", "of", "proposed", "Semantic", "Web", "standards", "."], "sentence-detokenized": "The term Semantic Web was coined by Tim Berners-Lee, inventor of the World Wide Web and director of the World Wide Web Consortium (W3C), which oversees the development of proposed Semantic Web standards.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 25], [26, 32], [33, 35], [36, 39], [40, 47], [47, 48], [48, 51], [51, 52], [53, 61], [62, 64], [65, 68], [69, 74], [75, 79], [80, 83], [84, 87], [88, 96], [97, 99], [100, 103], [104, 109], [110, 114], [115, 118], [119, 129], [130, 131], [131, 134], [134, 135], [135, 136], [137, 142], [143, 151], [152, 155], [156, 167], [168, 170], [171, 179], [180, 188], [189, 192], [193, 202], [202, 203]]}
{"doc_key": "ai-dev-201", "ner": [[0, 1, "task"], [6, 6, "task"], [8, 13, "product"], [21, 21, "product"], [26, 33, "field"]], "ner_mapping_to_source": [0, 1, 4, 5, 6], "relations": [[0, 1, 21, 21, "opposite", "", false, false], [0, 1, 26, 33, "part-of", "", false, false], [6, 6, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [2, 3, 4], "sentence": ["Machine", "translation", ",", "sometimes", "abbreviated", "as", "MT", "(", "computer", "-", "aided", "translation", ",", "MAHT", ",", "not", "to", "be", "confused", "with", "interactive", "translation", ")", ",", "is", "a", "computational", "linguistics", "It", "is", "a", "sub-discipline", "of", "linguistics", "."], "sentence-detokenized": "Machine translation, sometimes abbreviated as MT (computer-aided translation, MAHT, not to be confused with interactive translation), is a computational linguistics It is a sub-discipline of linguistics.", "token2charspan": [[0, 7], [8, 19], [19, 20], [21, 30], [31, 42], [43, 45], [46, 48], [49, 50], [50, 58], [58, 59], [59, 64], [65, 76], [76, 77], [78, 82], [82, 83], [84, 87], [88, 90], [91, 93], [94, 102], [103, 107], [108, 119], [120, 131], [131, 132], [132, 133], [134, 136], [137, 138], [139, 152], [153, 164], [165, 167], [168, 170], [171, 172], [173, 187], [188, 190], [191, 202], [202, 203]]}
{"doc_key": "ai-dev-202", "ner": [[2, 4, "product"], [14, 14, "university"], [8, 8, "researcher"], [11, 13, "researcher"], [42, 42, "location"], [45, 45, "location"], [45, 55, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 4, 8, 8, "artifact", "", false, false], [2, 4, 11, 13, "artifact", "", false, false], [8, 8, 14, 14, "physical", "", false, false], [8, 8, 14, 14, "role", "", false, false], [11, 13, 14, 14, "physical", "", false, false], [11, 13, 14, 14, "role", "", false, false], [42, 42, 45, 45, "physical", "", false, false], [45, 55, 42, 42, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["An", "early", "interlanguage", "MT", "system", "was", "built", "by", "Roger", "Schank", "and", "Yorick", "Wilks", "at", "Stanford", "University", "in", "the", "1970s", ",", "the", "former", "becoming", "the", "basis", "for", "a", "commercial", "system", "for", "fund", "transfer", ",", "and", "the", "latter", "'s", "code", "is", "preserved", "in", "the", "Computer", "Museum", "in", "Boston", "as", "the", "first", "interlanguage", "machine", "translation", "system", ".", "The", "system", "is", "preserved", "in", "the", "Computer", "Museum", "in", "Boston", "as", "the", "first", "interlanguage", "machine", "translation", "system", "."], "sentence-detokenized": "An early interlanguage MT system was built by Roger Schank and Yorick Wilks at Stanford University in the 1970s, the former becoming the basis for a commercial system for fund transfer, and the latter's code is preserved in the Computer Museum in Boston as the first interlanguage machine translation system. The system is preserved in the Computer Museum in Boston as the first interlanguage machine translation system.", "token2charspan": [[0, 2], [3, 8], [9, 22], [23, 25], [26, 32], [33, 36], [37, 42], [43, 45], [46, 51], [52, 58], [59, 62], [63, 69], [70, 75], [76, 78], [79, 87], [88, 98], [99, 101], [102, 105], [106, 111], [111, 112], [113, 116], [117, 123], [124, 132], [133, 136], [137, 142], [143, 146], [147, 148], [149, 159], [160, 166], [167, 170], [171, 175], [176, 184], [184, 185], [186, 189], [190, 193], [194, 200], [200, 202], [203, 207], [208, 210], [211, 220], [221, 223], [224, 227], [228, 236], [237, 243], [244, 246], [247, 253], [254, 256], [257, 260], [261, 266], [267, 280], [281, 288], [289, 300], [301, 307], [307, 308], [309, 312], [313, 319], [320, 322], [323, 332], [333, 335], [336, 339], [340, 348], [349, 355], [356, 358], [359, 365], [366, 368], [369, 372], [373, 378], [379, 392], [393, 400], [401, 412], [413, 419], [419, 420]]}
{"doc_key": "ai-dev-203", "ner": [[0, 1, "researcher"], [7, 13, "conference"], [20, 25, "conference"], [27, 28, "conference"], [33, 37, "organisation"], [45, 45, "conference"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6], "relations": [[0, 1, 20, 25, "role", "", false, false], [0, 1, 33, 37, "role", "", false, false], [0, 1, 45, 45, "role", "", false, false], [27, 28, 20, 25, "named", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 5], "sentence": ["Sycara", "was", "programme", "chair", "of", "the", "2nd", "International", "Semantic", "Web", "Conference", "(", "ISWC", "2003", ")", ",", "general", "chair", "of", "the", "2nd", "International", "Conference", "on", "Autonomous", "Agents", "(", "Agents", "98", ")", ",", "chair", "of", "the", "Agents", "Conference", "Steering", "Committee", "(", "1999-2001", ")", "and", "chair", "of", "the", "AAAI", "scholarship", "committee", "(", "1993-1999", ")", "."], "sentence-detokenized": "Sycara was programme chair of the 2nd International Semantic Web Conference (ISWC 2003), general chair of the 2nd International Conference on Autonomous Agents (Agents 98), chair of the Agents Conference Steering Committee (1999-2001) and chair of the AAAI scholarship committee (1993-1999).", "token2charspan": [[0, 6], [7, 10], [11, 20], [21, 26], [27, 29], [30, 33], [34, 37], [38, 51], [52, 60], [61, 64], [65, 75], [76, 77], [77, 81], [82, 86], [86, 87], [87, 88], [89, 96], [97, 102], [103, 105], [106, 109], [110, 113], [114, 127], [128, 138], [139, 141], [142, 152], [153, 159], [160, 161], [161, 167], [168, 170], [170, 171], [171, 172], [173, 178], [179, 181], [182, 185], [186, 192], [193, 203], [204, 212], [213, 222], [223, 224], [224, 233], [233, 234], [235, 238], [239, 244], [245, 247], [248, 251], [252, 256], [257, 268], [269, 278], [279, 280], [280, 289], [289, 290], [290, 291]]}
{"doc_key": "ai-dev-204", "ner": [[13, 18, "conference"], [15, 16, "conference"], [7, 9, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 16, 13, 18, "named", "", false, false], [7, 9, 13, 18, "part-of", "", false, false], [7, 9, 13, 18, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2016", ",", "she", "was", "named", "a", "Lifetime", "Achievement", "Award", "winner", "by", "the", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "."], "sentence-detokenized": "In 2016, she was named a Lifetime Achievement Award winner by the Association for Computational Linguistics (ACL).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 22], [23, 24], [25, 33], [34, 45], [46, 51], [52, 58], [59, 61], [62, 65], [66, 77], [78, 81], [82, 95], [96, 107], [108, 109], [109, 112], [112, 113], [113, 114]]}
{"doc_key": "ai-dev-205", "ner": [[0, 1, "researcher"], [3, 5, "researcher"], [7, 8, "researcher"], [11, 12, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", ",", "Y", ".", "Bengio", ",", "P.", "Frasconi", ",", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Sepp Hochreiter, Y. Bengio, P. Frasconi, and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 15], [15, 16], [17, 18], [18, 19], [20, 26], [26, 27], [28, 30], [31, 39], [39, 40], [41, 44], [45, 51], [52, 63], [63, 64]]}
{"doc_key": "ai-dev-206", "ner": [[3, 3, "product"], [7, 11, "misc"], [6, 6, "programlang"], [18, 22, "product"], [32, 32, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 6, 6, "usage", "", false, false], [6, 6, 7, 11, "type-of", "", false, false], [6, 6, 18, 22, "related-to", "", false, false], [32, 32, 3, 3, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["For", "example", ",", "A.L.I.C.E.", "uses", "the", "AIML", "markup", "language", ",", "which", "is", "specifically", "designed", "to", "function", "as", "a", "dialogue", "system", "and", "has", "since", "been", "variously", "adopted", "by", "developers", "of", "so", "-", "called", "Alicebots", "."], "sentence-detokenized": "For example, A.L.I.C.E. uses the AIML markup language, which is specifically designed to function as a dialogue system and has since been variously adopted by developers of so-called Alicebots.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 23], [24, 28], [29, 32], [33, 37], [38, 44], [45, 53], [53, 54], [55, 60], [61, 63], [64, 76], [77, 85], [86, 88], [89, 97], [98, 100], [101, 102], [103, 111], [112, 118], [119, 122], [123, 126], [127, 132], [133, 137], [138, 147], [148, 155], [156, 158], [159, 169], [170, 172], [173, 175], [175, 176], [176, 182], [183, 192], [192, 193]]}
{"doc_key": "ai-dev-207", "ner": [[10, 13, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2000", ",", "he", "was", "elected", "a", "Fellow", "of", "the", "Society", "for", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2000, he was elected a Fellow of the Society for Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 47], [48, 51], [52, 62], [63, 75], [75, 76]]}
{"doc_key": "ai-dev-208", "ner": [[2, 3, "misc"], [0, 8, "misc"], [9, 17, "misc"], [25, 26, "algorithm"], [34, 34, "field"], [36, 36, "field"], [38, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 3, 9, 17, "type-of", "", false, false], [2, 3, 34, 34, "related-to", "performs", true, false], [2, 3, 36, 36, "related-to", "performs", true, false], [2, 3, 38, 39, "related-to", "performs", true, false], [0, 8, 2, 3, "named", "", false, false], [25, 26, 9, 17, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["A", "learning", "classifier", "system", "(", "LCS", ")", "is", "a", "type", "of", "rule", "-", "based", "machine", "learning", "algorithm", "that", "combines", "a", "discovery", "component", "(", "usually", "a", "genetic", "algorithm", ")", "with", "a", "learning", "component", "(", "either", "supervised", ",", "reinforcement", "or", "unsupervised", "learning", ")", "."], "sentence-detokenized": "A learning classifier system (LCS) is a type of rule-based machine learning algorithm that combines a discovery component (usually a genetic algorithm) with a learning component (either supervised, reinforcement or unsupervised learning).", "token2charspan": [[0, 1], [2, 10], [11, 21], [22, 28], [29, 30], [30, 33], [33, 34], [35, 37], [38, 39], [40, 44], [45, 47], [48, 52], [52, 53], [53, 58], [59, 66], [67, 75], [76, 85], [86, 90], [91, 99], [100, 101], [102, 111], [112, 121], [122, 123], [123, 130], [131, 132], [133, 140], [141, 150], [150, 151], [152, 156], [157, 158], [159, 167], [168, 177], [178, 179], [179, 185], [186, 196], [196, 197], [198, 211], [212, 214], [215, 227], [228, 236], [236, 237], [237, 238]]}
{"doc_key": "ai-dev-209", "ner": [[14, 18, "algorithm"], [28, 30, "algorithm"], [39, 41, "algorithm"], [44, 52, "misc"]], "ner_mapping_to_source": [1, 2, 4, 5], "relations": [[39, 41, 44, 52, "compare", "", false, false]], "relations_mapping_to_source": [4], "sentence": ["The", "unknown", "parameters", "of", "each", "vector", "\u03b2subk", "/", "sub", "are", "usually", "jointly", "estimated", "by", "maximum", "a", "posteriori", "(", "MAP", ")", "estimation", ".", "This", "is", "an", "extension", "of", "the", "maximum", "likelihood", "method", "using", "regularisation", "of", "the", "weights", "(", "usually", "a", "squared", "regularisation", "function", ",", "which", "corresponds", "to", "placing", "a", "zero-mean", "Gaussian", "prior", "on", "the", "weights", ",", "but", "other", "distributions", "are", "also", "possible", ")", "to", "prevent", "pathological", "solutions", "."], "sentence-detokenized": "The unknown parameters of each vector \u03b2subk / sub are usually jointly estimated by maximum a posteriori (MAP) estimation. This is an extension of the maximum likelihood method using regularisation of the weights (usually a squared regularisation function, which corresponds to placing a zero-mean Gaussian prior on the weights, but other distributions are also possible) to prevent pathological solutions.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 25], [26, 30], [31, 37], [38, 43], [44, 45], [46, 49], [50, 53], [54, 61], [62, 69], [70, 79], [80, 82], [83, 90], [91, 92], [93, 103], [104, 105], [105, 108], [108, 109], [110, 120], [120, 121], [122, 126], [127, 129], [130, 132], [133, 142], [143, 145], [146, 149], [150, 157], [158, 168], [169, 175], [176, 181], [182, 196], [197, 199], [200, 203], [204, 211], [212, 213], [213, 220], [221, 222], [223, 230], [231, 245], [246, 254], [254, 255], [256, 261], [262, 273], [274, 276], [277, 284], [285, 286], [287, 296], [297, 305], [306, 311], [312, 314], [315, 318], [319, 326], [326, 327], [328, 331], [332, 337], [338, 351], [352, 355], [356, 360], [361, 369], [369, 370], [371, 373], [374, 381], [382, 394], [395, 404], [404, 405]]}
{"doc_key": "ai-dev-210", "ner": [[9, 9, "researcher"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 9, 9, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "hierarchical", "structure", "of", "words", "is", "explicitly", "mapped", "in", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "The hierarchical structure of words is explicitly mapped in George Miller's Wordnet.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 29], [30, 35], [36, 38], [39, 49], [50, 56], [57, 59], [60, 66], [67, 73], [73, 75], [76, 83], [83, 84]]}
{"doc_key": "ai-dev-211", "ner": [[0, 2, "conference"], [4, 8, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 8, 0, 2, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "is", "a", "benchmark", "for", "object", "classification", "and", "detection", "consisting", "of", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "It is a benchmark for object classification and detection consisting of millions of images and hundreds of object classes.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 17], [18, 21], [22, 28], [29, 43], [44, 47], [48, 57], [58, 68], [69, 71], [72, 80], [81, 83], [84, 90], [91, 94], [95, 103], [104, 106], [107, 113], [114, 121], [121, 122]]}
{"doc_key": "ai-dev-212", "ner": [[0, 4, "misc"], [9, 9, "misc"], [11, 12, "person"], [16, 16, "misc"], [27, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[9, 9, 0, 4, "general-affiliation", "", false, false], [16, 16, 0, 4, "general-affiliation", "", false, false], [16, 16, 11, 12, "artifact", "", false, false], [27, 29, 0, 4, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "science", "fiction", ",", "as", "seen", "in", "the", "film", "Westworld", ",", "Paul", "J.", "McCauley", "'s", "novel", "Fairyland", "(", "1995", ")", "and", "Lester", "Del", "Rey", "'s", "short", "story", "Helen", "O'", "Roy", "(", "1938", ")", ",", "robots", "in", "female", "form", "are", "often", "produced", "for", "use", "as", "domestic", "helpers", "and", "sex", "slaves", ",", "and", "sometimes", "used", "as", "warriors", ",", "killers", "and", "labourers", "."], "sentence-detokenized": "In science fiction, as seen in the film Westworld, Paul J. McCauley's novel Fairyland (1995) and Lester Del Rey's short story Helen O'Roy (1938), robots in female form are often produced for use as domestic helpers and sex slaves, and sometimes used as warriors, killers and labourers.", "token2charspan": [[0, 2], [3, 10], [11, 18], [18, 19], [20, 22], [23, 27], [28, 30], [31, 34], [35, 39], [40, 49], [49, 50], [51, 55], [56, 58], [59, 67], [67, 69], [70, 75], [76, 85], [86, 87], [87, 91], [91, 92], [93, 96], [97, 103], [104, 107], [108, 111], [111, 113], [114, 119], [120, 125], [126, 131], [132, 134], [134, 137], [138, 139], [139, 143], [143, 144], [144, 145], [146, 152], [153, 155], [156, 162], [163, 167], [168, 171], [172, 177], [178, 186], [187, 190], [191, 194], [195, 197], [198, 206], [207, 214], [215, 218], [219, 222], [223, 229], [229, 230], [231, 234], [235, 244], [245, 249], [250, 252], [253, 261], [261, 262], [263, 270], [271, 274], [275, 284], [284, 285]]}
{"doc_key": "ai-dev-213", "ner": [[0, 1, "task"], [3, 4, "task"], [6, 7, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Question", "answering", ",", "speech", "recognition", "and", "machine", "translation", "."], "sentence-detokenized": "Question answering, speech recognition and machine translation.", "token2charspan": [[0, 8], [9, 18], [18, 19], [20, 26], [27, 38], [39, 42], [43, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-214", "ner": [[5, 8, "researcher"], [9, 13, "organisation"], [14, 17, "location"], [19, 19, "location"], [20, 21, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 8, 9, 13, "role", "", false, false], [9, 13, 14, 17, "physical", "", false, false], [14, 17, 19, 19, "physical", "", false, false], [19, 19, 20, 21, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "his", "seminal", "paper", ",", "Harry", "Blum", "of", "the", "Air", "Force", "Cambridge", "Laboratory", "at", "Hanscom", "Air", "Force", "Base", ",", "Bedford", ",", "Massachusetts", ",", "uses", "an", "intuitive", "model", "of", "fire", "propagation", "in", "grasslands", "to", "define", "an", "inner", "axis", "for", "calculating", "the", "skeleton", "of", "a", "shape", "in", "a", "field", "with", "a", "given", "shape", "."], "sentence-detokenized": "In his seminal paper, Harry Blum of the Air Force Cambridge Laboratory at Hanscom Air Force Base, Bedford, Massachusetts, uses an intuitive model of fire propagation in grasslands to define an inner axis for calculating the skeleton of a shape in a field with a given shape.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 20], [20, 21], [22, 27], [28, 32], [33, 35], [36, 39], [40, 43], [44, 49], [50, 59], [60, 70], [71, 73], [74, 81], [82, 85], [86, 91], [92, 96], [96, 97], [98, 105], [105, 106], [107, 120], [120, 121], [122, 126], [127, 129], [130, 139], [140, 145], [146, 148], [149, 153], [154, 165], [166, 168], [169, 179], [180, 182], [183, 189], [190, 192], [193, 198], [199, 203], [204, 207], [208, 219], [220, 223], [224, 232], [233, 235], [236, 237], [238, 243], [244, 246], [247, 248], [249, 254], [255, 259], [260, 261], [262, 267], [268, 273], [273, 274]]}
{"doc_key": "ai-dev-215", "ner": [[6, 10, "algorithm"], [20, 21, "algorithm"]], "ner_mapping_to_source": [1, 2], "relations": [[6, 10, 20, 21, "compare", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["However", ",", "unlike", "boosting", "algorithms", "(", "such", "as", "AdaBoost", "and", "LogitBoost", ")", ",", "which", "analytically", "minimise", "convex", "loss", "functions", ",", "Brown", "Boost", "solves", "systems", "of", "two", "equations", "and", "two", "unknowns", "using", "standard", "numerical", "methods", "."], "sentence-detokenized": "However, unlike boosting algorithms (such as AdaBoost and LogitBoost), which analytically minimise convex loss functions, BrownBoost solves systems of two equations and two unknowns using standard numerical methods.", "token2charspan": [[0, 7], [7, 8], [9, 15], [16, 24], [25, 35], [36, 37], [37, 41], [42, 44], [45, 53], [54, 57], [58, 68], [68, 69], [69, 70], [71, 76], [77, 89], [90, 98], [99, 105], [106, 110], [111, 120], [120, 121], [122, 127], [127, 132], [133, 139], [140, 147], [148, 150], [151, 154], [155, 164], [165, 168], [169, 172], [173, 181], [182, 187], [188, 196], [197, 206], [207, 214], [214, 215]]}
{"doc_key": "ai-dev-216", "ner": [[0, 2, "researcher"], [8, 10, "misc"], [17, 22, "conference"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[0, 2, 8, 10, "win-defeat", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Getoor", "has", "received", "several", "best", "paper", "awards", ",", "NSF", "Career", "Awards", "and", "is", "a", "Fellow", "of", "the", "Association", "for", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Getoor has received several best paper awards, NSF Career Awards and is a Fellow of the Association for Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 27], [28, 32], [33, 38], [39, 45], [45, 46], [47, 50], [51, 57], [58, 64], [65, 68], [69, 71], [72, 73], [74, 80], [81, 83], [84, 87], [88, 99], [100, 103], [104, 114], [115, 127], [128, 129], [129, 133], [133, 134], [134, 135]]}
{"doc_key": "ai-dev-217", "ner": [[0, 1, "misc"], [11, 12, "misc"], [17, 18, "misc"], [26, 29, "misc"], [39, 40, "misc"], [34, 38, "university"], [48, 56, "misc"], [61, 71, "misc"], [74, 78, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["ACM", "Fellow", "(", "2015", ")", "br", "Fellow", "of", "the", "Association", "for", "Computational", "Linguistics", "(", "2011", ")", "br", "AAAI", "Fellow", "(", "1994", ")", "br", "Fellow", "of", "the", "International", "Speech", "Communication", "Association", "(", "2011", ")", "br", "Royal", "Institute", "of", "Technology", "KTH", "Honorary", "Doctorate", "(", "Hedersdoktor", ")", "(", "2007", ")", "br", "Columbia", "Engineering", "School", "Alumni", "Association", "Distinguished", "Faculty", "Teaching", "award", "(", "2009", ")", "br", "IEEE", "James", "L.", "Flanagan", "Speech", "and", "Audio", "Processing", "Award", "(", "2011", ")", "br", "ISCA", "Medal", "for", "Scientific", "Achievement", "(", "2011", ")", "."], "sentence-detokenized": "ACM Fellow (2015)br Fellow of the Association for Computational Linguistics (2011)br AAAI Fellow (1994)br Fellow of the International Speech Communication Association (2011)br Royal Institute of Technology KTH Honorary Doctorate (Hedersdoktor) (2007)br Columbia Engineering School Alumni Association Distinguished Faculty Teaching award (2009)br IEEE James L. Flanagan Speech and Audio Processing Award (2011) br ISCA Medal for Scientific Achievement (2011).", "token2charspan": [[0, 3], [4, 10], [11, 12], [12, 16], [16, 17], [17, 19], [20, 26], [27, 29], [30, 33], [34, 45], [46, 49], [50, 63], [64, 75], [76, 77], [77, 81], [81, 82], [82, 84], [85, 89], [90, 96], [97, 98], [98, 102], [102, 103], [103, 105], [106, 112], [113, 115], [116, 119], [120, 133], [134, 140], [141, 154], [155, 166], [167, 168], [168, 172], [172, 173], [173, 175], [176, 181], [182, 191], [192, 194], [195, 205], [206, 209], [210, 218], [219, 228], [229, 230], [230, 242], [242, 243], [244, 245], [245, 249], [249, 250], [250, 252], [253, 261], [262, 273], [274, 280], [281, 287], [288, 299], [300, 313], [314, 321], [322, 330], [331, 336], [337, 338], [338, 342], [342, 343], [343, 345], [346, 350], [351, 356], [357, 359], [360, 368], [369, 375], [376, 379], [380, 385], [386, 396], [397, 402], [403, 404], [404, 408], [408, 409], [410, 412], [413, 417], [418, 423], [424, 427], [428, 438], [439, 450], [451, 452], [452, 456], [456, 457], [457, 458]]}
{"doc_key": "ai-dev-218", "ner": [[6, 6, "university"], [13, 17, "task"], [37, 43, "metrics"], [31, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[37, 43, 31, 34, "opposite", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["A", "frustrating", "result", "of", "the", "same", "Stanford", "study", "(", "and", "other", "attempts", "to", "improve", "name", "-", "recognition", "translation", ")", "is", "that", ",", "in", "many", "cases", ",", "the", "inclusion", "of", "methods", "for", "translation", "of", "named", "entities", "reduces", "the", "assignment", "score", "of", "the", "bilingual", "evaluation", "for", "the", "translation", "."], "sentence-detokenized": "A frustrating result of the same Stanford study (and other attempts to improve name-recognition translation) is that, in many cases, the inclusion of methods for translation of named entities reduces the assignment score of the bilingual evaluation for the translation.", "token2charspan": [[0, 1], [2, 13], [14, 20], [21, 23], [24, 27], [28, 32], [33, 41], [42, 47], [48, 49], [49, 52], [53, 58], [59, 67], [68, 70], [71, 78], [79, 83], [83, 84], [84, 95], [96, 107], [107, 108], [109, 111], [112, 116], [116, 117], [118, 120], [121, 125], [126, 131], [131, 132], [133, 136], [137, 146], [147, 149], [150, 157], [158, 161], [162, 173], [174, 176], [177, 182], [183, 191], [192, 199], [200, 203], [204, 214], [215, 220], [221, 223], [224, 227], [228, 237], [238, 248], [249, 252], [253, 256], [257, 268], [268, 269]]}
{"doc_key": "ai-dev-219", "ner": [[5, 8, "organisation"], [12, 13, "organisation"], [16, 21, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 8, 12, 13, "role", "works_with", false, false], [5, 8, 16, 21, "role", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Using", "the", "PM", "data", "collected", ",", "Medtronic", "is", "working", "with", "researchers", "at", "Johns", "Hopkins", "Hospital", "and", "Washington", "University", "School", "of", "Medicine", "to", "answer", "specific", "questions", "about", "heart", "disease", ",", "such", "as", "whether", "a", "weak", "heart", "causes", "arrhythmias", "or", "vice", "versa", "."], "sentence-detokenized": "Using the PM data collected, Medtronic is working with researchers at Johns Hopkins Hospital and Washington University School of Medicine to answer specific questions about heart disease, such as whether a weak heart causes arrhythmias or vice versa.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 17], [18, 27], [27, 28], [29, 38], [39, 41], [42, 49], [50, 54], [55, 66], [67, 69], [70, 75], [76, 83], [84, 92], [93, 96], [97, 107], [108, 118], [119, 125], [126, 128], [129, 137], [138, 140], [141, 147], [148, 156], [157, 166], [167, 172], [173, 178], [179, 186], [186, 187], [188, 192], [193, 195], [196, 203], [204, 205], [206, 210], [211, 216], [217, 223], [224, 235], [236, 238], [239, 243], [244, 249], [249, 250]]}
{"doc_key": "ai-dev-220", "ner": [[2, 3, "organisation"], [8, 18, "misc"], [14, 17, "person"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[8, 18, 2, 3, "artifact", "made_by_studio", false, false], [14, 17, 8, 18, "role", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["Later", ",", "Paramount", "'s", "first", "feature", "film", ",", "Sangaree", ",", "starring", "Fernando", "Llamas", "and", "Arlene", "Dahl", ",", "was", "released", "."], "sentence-detokenized": "Later, Paramount's first feature film, Sangaree, starring Fernando Llamas and Arlene Dahl, was released.", "token2charspan": [[0, 5], [5, 6], [7, 16], [16, 18], [19, 24], [25, 32], [33, 37], [37, 38], [39, 47], [47, 48], [49, 57], [58, 66], [67, 73], [74, 77], [78, 84], [85, 89], [89, 90], [91, 94], [95, 103], [103, 104]]}
{"doc_key": "ai-dev-221", "ner": [[0, 1, "programlang"], [9, 9, "researcher"], [12, 13, "researcher"], [16, 16, "organisation"], [14, 20, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 9, 9, "origin", "", false, false], [0, 1, 12, 13, "origin", "", false, false], [9, 9, 16, 16, "physical", "", false, false], [9, 9, 16, 16, "role", "", false, false], [12, 13, 14, 20, "physical", "", false, false], [12, 13, 14, 20, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["KRL", "is", "a", "knowledge", "representation", "language", "developed", "by", "Daniel", "G.", "Bobrow", "and", "Terry", "Winograd", "while", "at", "Xerox", "PARC", "and", "Stanford", "University", "respectively", "."], "sentence-detokenized": "KRL is a knowledge representation language developed by Daniel G. Bobrow and Terry Winograd while at Xerox PARC and Stanford University respectively.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 18], [19, 33], [34, 42], [43, 52], [53, 55], [56, 62], [63, 65], [66, 72], [73, 76], [77, 82], [83, 91], [92, 97], [98, 100], [101, 106], [107, 111], [112, 115], [116, 124], [125, 135], [136, 148], [148, 149]]}
{"doc_key": "ai-dev-222", "ner": [[3, 10, "conference"], [12, 12, "researcher"], [13, 15, "researcher"], [16, 18, "researcher"], [19, 26, "researcher"], [7, 7, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6], "relations": [[12, 12, 3, 10, "physical", "", false, false], [12, 12, 3, 10, "role", "", false, false], [12, 12, 3, 10, "temporal", "", false, false], [13, 15, 3, 10, "physical", "", false, false], [13, 15, 3, 10, "role", "", false, false], [13, 15, 3, 10, "temporal", "", false, false], [16, 18, 3, 10, "physical", "", false, false], [16, 18, 3, 10, "role", "", false, false], [16, 18, 3, 10, "temporal", "", false, false], [19, 26, 3, 10, "physical", "", false, false], [19, 26, 3, 10, "role", "", false, false], [19, 26, 3, 10, "temporal", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["At", "the", "2006", "IEEE", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "Qiang", "Zhu", ",", "Shai", "Avidan", ",", "Mei-Chen", "Yeh", "and", "Kwang", "-", "Ting", "Cheng", "presented", "an", "algorithm", "that", "significantly", "speeds", "up", "human", "detection", "with", "HOG", "descriptors", "."], "sentence-detokenized": "At the 2006 IEEE Conference on Computer Vision and Pattern Recognition, Qiang Zhu, Shai Avidan, Mei-Chen Yeh and Kwang-Ting Cheng presented an algorithm that significantly speeds up human detection with HOG descriptors.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 27], [28, 30], [31, 39], [40, 46], [47, 50], [51, 58], [59, 70], [70, 71], [72, 77], [78, 81], [81, 82], [83, 87], [88, 94], [94, 95], [96, 104], [105, 108], [109, 112], [113, 118], [118, 119], [119, 123], [124, 129], [130, 139], [140, 142], [143, 152], [153, 157], [158, 171], [172, 178], [179, 181], [182, 187], [188, 197], [198, 202], [203, 206], [207, 218], [218, 219]]}
{"doc_key": "ai-dev-223", "ner": [[0, 0, "researcher"], [10, 12, "organisation"]], "ner_mapping_to_source": [0, 2], "relations": [[0, 0, 10, 12, "role", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Hayes", "is", "a", "Charter", "Fellow", "of", "the", "AAAI", "and", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Hayes is a Charter Fellow of the AAAI and the Cognitive Science Society.", "token2charspan": [[0, 5], [6, 8], [9, 10], [11, 18], [19, 25], [26, 28], [29, 32], [33, 37], [38, 41], [42, 45], [46, 55], [56, 63], [64, 71], [71, 72]]}
{"doc_key": "ai-dev-224", "ner": [[0, 2, "misc"], [5, 5, "field"], [7, 8, "field"], [10, 11, "field"], [13, 13, "field"], [15, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 25, "field"], [27, 28, "field"], [30, 30, "field"], [32, 34, "field"], [39, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[0, 2, 5, 5, "part-of", "", false, false], [0, 2, 5, 5, "usage", "", false, false], [0, 2, 7, 8, "part-of", "", false, false], [0, 2, 7, 8, "usage", "", false, false], [0, 2, 10, 11, "part-of", "", false, false], [0, 2, 10, 11, "usage", "", false, false], [0, 2, 13, 13, "part-of", "", false, false], [0, 2, 13, 13, "usage", "", false, false], [0, 2, 15, 16, "part-of", "", false, false], [0, 2, 15, 16, "usage", "", false, false], [0, 2, 18, 19, "part-of", "", false, false], [0, 2, 18, 19, "usage", "", false, false], [0, 2, 21, 22, "part-of", "", false, false], [0, 2, 21, 22, "usage", "", false, false], [0, 2, 24, 25, "part-of", "", false, false], [0, 2, 24, 25, "usage", "", false, false], [0, 2, 27, 28, "part-of", "", false, false], [0, 2, 27, 28, "usage", "", false, false], [0, 2, 30, 30, "part-of", "", false, false], [0, 2, 30, 30, "usage", "", false, false], [0, 2, 32, 34, "part-of", "", false, false], [0, 2, 32, 34, "usage", "", false, false], [0, 2, 39, 40, "part-of", "", false, false], [0, 2, 39, 40, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "sentence": ["Time", "series", "are", "used", "in", "statistics", ",", "signal", "processing", ",", "pattern", "recognition", ",", "econometrics", ",", "mathematical", "finance", ",", "weather", "forecasting", ",", "earthquake", "prediction", ",", "EEG", "measurements", ",", "control", "engineering", ",", "astronomy", ",", "communications", "engineering", "and", "all", "other", "areas", "of", "applied", "science", "and", "engineering", "that", "involve", "time", "measurement", "."], "sentence-detokenized": "Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, earthquake prediction, EEG measurements, control engineering, astronomy, communications engineering and all other areas of applied science and engineering that involve time measurement.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 23], [24, 34], [34, 35], [36, 42], [43, 53], [53, 54], [55, 62], [63, 74], [74, 75], [76, 88], [88, 89], [90, 102], [103, 110], [110, 111], [112, 119], [120, 131], [131, 132], [133, 143], [144, 154], [154, 155], [156, 159], [160, 172], [172, 173], [174, 181], [182, 193], [193, 194], [195, 204], [204, 205], [206, 220], [221, 232], [233, 236], [237, 240], [241, 246], [247, 252], [253, 255], [256, 263], [264, 271], [272, 275], [276, 287], [288, 292], [293, 300], [301, 305], [306, 317], [317, 318]]}
{"doc_key": "ai-dev-225", "ner": [[18, 22, "metrics"], [43, 45, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Exact", "restoration", "can", ",", "in", "principle", ",", "be", "solved", "to", "the", "extent", "that", "it", "is", "feasible", "to", "do", "so", "using", "maximum", "likelihood", "methods", ",", "which", "is", "equivalent", "to", "solving", "constrained", "or", "regularised", "cut", "problems", ",", "such", "as", "minimum", "bisection", ",", "which", "are", "generally", "NP", "-", "complete", "."], "sentence-detokenized": "Exact restoration can, in principle, be solved to the extent that it is feasible to do so using maximum likelihood methods, which is equivalent to solving constrained or regularised cut problems, such as minimum bisection, which are generally NP-complete.", "token2charspan": [[0, 5], [6, 17], [18, 21], [21, 22], [23, 25], [26, 35], [35, 36], [37, 39], [40, 46], [47, 49], [50, 53], [54, 60], [61, 65], [66, 68], [69, 71], [72, 80], [81, 83], [84, 86], [87, 89], [90, 95], [96, 103], [104, 114], [115, 122], [122, 123], [124, 129], [130, 132], [133, 143], [144, 146], [147, 154], [155, 166], [167, 169], [170, 181], [182, 185], [186, 194], [194, 195], [196, 200], [201, 203], [204, 211], [212, 221], [221, 222], [223, 228], [229, 232], [233, 242], [243, 245], [245, 246], [246, 254], [254, 255]]}
{"doc_key": "ai-dev-226", "ner": [[0, 6, "task"], [7, 11, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 11, 0, 6, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["is", "the", "result", "of", "pedestrian", "detection", "research", "presented", "at", "the", "BMVC", "in", "2009", "."], "sentence-detokenized": "is the result of pedestrian detection research presented at the BMVC in 2009.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 27], [28, 37], [38, 46], [47, 56], [57, 59], [60, 63], [64, 68], [69, 71], [72, 76], [76, 77]]}
{"doc_key": "ai-dev-227", "ner": [[3, 7, "conference"], [9, 11, "researcher"], [12, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 11, 3, 7, "physical", "", false, false], [9, 11, 3, 7, "role", "", false, false], [9, 11, 12, 19, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["At", "the", "2007", "International", "Conference", "on", "Computer", "Vision", ",", "Terzopoulos", "received", "the", "first", "IEEE", "PAMI", "Computer", "Vision", "Distinguished", "Researcher", "Award", "."], "sentence-detokenized": "At the 2007 International Conference on Computer Vision, Terzopoulos received the first IEEE PAMI Computer Vision Distinguished Researcher Award.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 25], [26, 36], [37, 39], [40, 48], [49, 55], [55, 56], [57, 68], [69, 77], [78, 81], [82, 87], [88, 92], [93, 97], [98, 106], [107, 113], [114, 127], [128, 138], [139, 144], [144, 145]]}
{"doc_key": "ai-dev-228", "ner": [[0, 5, "task"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "cluster", "analysis", "or", "cluster", "analysis", ",", "data", "points", "are", "assigned", "to", "clusters", "so", "that", "items", "belonging", "to", "the", "same", "cluster", "are", "as", "similar", "as", "possible", "and", "items", "belonging", "to", "different", "clusters", "are", "as", "dissimilar", "as", "possible", "."], "sentence-detokenized": "In cluster analysis or cluster analysis, data points are assigned to clusters so that items belonging to the same cluster are as similar as possible and items belonging to different clusters are as dissimilar as possible.", "token2charspan": [[0, 2], [3, 10], [11, 19], [20, 22], [23, 30], [31, 39], [39, 40], [41, 45], [46, 52], [53, 56], [57, 65], [66, 68], [69, 77], [78, 80], [81, 85], [86, 91], [92, 101], [102, 104], [105, 108], [109, 113], [114, 121], [122, 125], [126, 128], [129, 136], [137, 139], [140, 148], [149, 152], [153, 158], [159, 168], [169, 171], [172, 181], [182, 190], [191, 194], [195, 197], [198, 208], [209, 211], [212, 220], [220, 221]]}
{"doc_key": "ai-dev-229", "ner": [[11, 12, "field"], [17, 18, "task"], [20, 21, "field"], [22, 25, "field"], [27, 28, "field"], [30, 31, "field"], [33, 35, "task"], [36, 36, "misc"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6, 7, 8], "relations": [[11, 12, 20, 21, "named", "", false, false], [11, 12, 27, 28, "named", "", false, false], [22, 25, 20, 21, "part-of", "", false, false], [30, 31, 27, 28, "part-of", "", false, false], [33, 35, 30, 31, "part-of", "", false, false], [36, 36, 30, 31, "part-of", "", false, false]], "relations_mapping_to_source": [1, 2, 4, 5, 6, 7], "sentence": ["(", "2005", ")", "We", "can", "differ", "between", "three", "different", "perspectives", "of", "text", "mining", ":", "text", "mining", "as", "information", "extraction", ",", "text", "mining", "as", "text", "data", "mining", "and", "text", "mining", "as", "data", "mining", "(", "knowledge", "discovery", "in", "databases", ")", "process", ".", "Hotho", ",", "A.", ",", "N\u00fcrnberger", ",", "A.", "and", "Paa\u00df", ",", "G.", "(", "2005", ")", "."], "sentence-detokenized": "(2005) We can differ between three different perspectives of text mining: text mining as information extraction, text mining as text data mining and text mining as data mining (knowledge discovery in databases) process .Hotho, A., N\u00fcrnberger, A. and Paa\u00df, G. (2005).", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 9], [10, 13], [14, 20], [21, 28], [29, 34], [35, 44], [45, 57], [58, 60], [61, 65], [66, 72], [72, 73], [74, 78], [79, 85], [86, 88], [89, 100], [101, 111], [111, 112], [113, 117], [118, 124], [125, 127], [128, 132], [133, 137], [138, 144], [145, 148], [149, 153], [154, 160], [161, 163], [164, 168], [169, 175], [176, 177], [177, 186], [187, 196], [197, 199], [200, 209], [209, 210], [211, 218], [219, 220], [220, 225], [225, 226], [227, 229], [229, 230], [231, 241], [241, 242], [243, 245], [246, 249], [250, 254], [254, 255], [256, 258], [259, 260], [260, 264], [264, 265], [265, 266]]}
{"doc_key": "ai-dev-230", "ner": [[0, 2, "product"], [10, 14, "location"], [17, 17, "location"], [18, 19, "location"], [35, 35, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 10, 14, "related-to", "developed_for", false, false], [10, 14, 17, 17, "physical", "", false, false], [17, 17, 18, 19, "physical", "", false, false], [35, 35, 0, 2, "role", "buys", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Rancho", "Arm", "is", "a", "robotic", "arm", "developed", "at", "the", "Rancho", "Los", "Amigos", "National", "Rehabilitation", "Centre", "in", "Dorney", ",", "California", ",", "to", "help", "patients", "with", "disabilities", ";", "this", "computer", "-", "controlled", "arm", "was", "purchased", "by", "Stanford", "University", "in", "1963", "."], "sentence-detokenized": "The Rancho Arm is a robotic arm developed at the Rancho Los Amigos National Rehabilitation Centre in Dorney, California, to help patients with disabilities; this computer-controlled arm was purchased by Stanford University in 1963.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 17], [18, 19], [20, 27], [28, 31], [32, 41], [42, 44], [45, 48], [49, 55], [56, 59], [60, 66], [67, 75], [76, 90], [91, 97], [98, 100], [101, 107], [107, 108], [109, 119], [119, 120], [121, 123], [124, 128], [129, 137], [138, 142], [143, 155], [155, 156], [157, 161], [162, 170], [170, 171], [171, 181], [182, 185], [186, 189], [190, 199], [200, 202], [203, 211], [212, 222], [223, 225], [226, 230], [230, 231]]}
{"doc_key": "ai-dev-231", "ner": [[0, 1, "university"], [3, 3, "researcher"], [9, 12, "organisation"], [20, 22, "organisation"], [25, 26, "researcher"], [24, 35, "researcher"], [43, 43, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 0, 1, "physical", "", false, false], [3, 3, 0, 1, "role", "", false, false], [3, 3, 9, 12, "role", "founder", false, false], [3, 3, 20, 22, "role", "founder", false, false], [20, 22, 43, 43, "physical", "", false, false], [25, 26, 20, 22, "role", "founder", false, false], [24, 35, 20, 22, "role", "founder", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["At", "UCSD", ",", "Norman", "was", "a", "founder", "of", "the", "Institute", "for", "Cognitive", "Science", "and", "one", "of", "the", "organisers", "of", "the", "Cognitive", "Science", "Society", "(", "with", "Roger", "Shank", ",", "Alan", "M.", "Collins", "and", "others", ")", ",", "which", "held", "it", "s", "first", "meeting", "on", "the", "UCSD", "campus", "in", "1979", "."], "sentence-detokenized": "At UCSD, Norman was a founder of the Institute for Cognitive Science and one of the organisers of the Cognitive Science Society (with Roger Shank, Alan M. Collins and others), which held its first meeting on the UCSD campus in 1979.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 21], [22, 29], [30, 32], [33, 36], [37, 46], [47, 50], [51, 60], [61, 68], [69, 72], [73, 76], [77, 79], [80, 83], [84, 94], [95, 97], [98, 101], [102, 111], [112, 119], [120, 127], [128, 129], [129, 133], [134, 139], [140, 145], [145, 146], [147, 151], [152, 154], [155, 162], [163, 166], [167, 173], [173, 174], [174, 175], [176, 181], [182, 186], [187, 189], [189, 190], [191, 196], [197, 204], [205, 207], [208, 211], [212, 216], [217, 223], [224, 226], [227, 231], [231, 232]]}
{"doc_key": "ai-dev-232", "ner": [[0, 1, "product"], [3, 4, "product"], [6, 7, "product"], [9, 11, "product"], [16, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[16, 23, 9, 11, "type-of", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Articulated", "robots", ",", "SCARA", "robots", ",", "delta", "robots", "and", "Cartesian", "co-ordinate", "robots", "(", "gantry", "robots", "and", "X", "-", "Y", "-", "Z", "robots", ")", "are", "commonly", "used", "."], "sentence-detokenized": "Articulated robots, SCARA robots, delta robots and Cartesian co-ordinate robots (gantry robots and X-Y-Z robots) are commonly used.", "token2charspan": [[0, 11], [12, 18], [18, 19], [20, 25], [26, 32], [32, 33], [34, 39], [40, 46], [47, 50], [51, 60], [61, 72], [73, 79], [80, 81], [81, 87], [88, 94], [95, 98], [99, 100], [100, 101], [101, 102], [102, 103], [103, 104], [105, 111], [111, 112], [113, 116], [117, 125], [126, 130], [130, 131]]}
{"doc_key": "ai-dev-233", "ner": [[8, 8, "programlang"], [9, 10, "misc"], [12, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 8, 8, "part-of", "", false, false], [12, 14, 9, 10, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "can", "also", "be", "used", "directly", "with", "the", "Perl", "module", "TM", "(", "LTM", "is", "also", "supported", ")", "."], "sentence-detokenized": "It can also be used directly with the Perl module TM (LTM is also supported).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 19], [20, 28], [29, 33], [34, 37], [38, 42], [43, 49], [50, 52], [53, 54], [54, 57], [58, 60], [61, 65], [66, 75], [75, 76], [76, 77]]}
{"doc_key": "ai-dev-234", "ner": [[11, 14, "country"], [6, 10, "organisation"], [15, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 10, 11, 14, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "was", "won", "by", "a", "team", "from", "Newton", "Labs", "in", "the", "USA", ",", "which", "was", "broadcast", "on", "CNN", "."], "sentence-detokenized": "This was won by a team from Newton Labs in the USA, which was broadcast on CNN.", "token2charspan": [[0, 4], [5, 8], [9, 12], [13, 15], [16, 17], [18, 22], [23, 27], [28, 34], [35, 39], [40, 42], [43, 46], [47, 50], [50, 51], [52, 57], [58, 61], [62, 71], [72, 74], [75, 78], [78, 79]]}
{"doc_key": "ai-dev-235", "ner": [[0, 6, "misc"], [10, 12, "person"], [15, 16, "person"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 12, 0, 6, "role", "directs", false, false], [15, 16, 0, 6, "role", "acts_in", false, false], [18, 19, 0, 6, "role", "acts_in", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Butler", "'s", "in", "Love", ",", "a", "short", "film", "directed", "by", "David", "Arquette", "and", "starring", "Elizabeth", "Berkeley", "and", "Thomas", "Jane", ",", "was", "released", "on", "23", "June", "2008", "."], "sentence-detokenized": "The Butler's in Love, a short film directed by David Arquette and starring Elizabeth Berkeley and Thomas Jane, was released on 23 June 2008.", "token2charspan": [[0, 3], [4, 10], [10, 12], [13, 15], [16, 20], [20, 21], [22, 23], [24, 29], [30, 34], [35, 43], [44, 46], [47, 52], [53, 61], [62, 65], [66, 74], [75, 84], [85, 93], [94, 97], [98, 104], [105, 109], [109, 110], [111, 114], [115, 123], [124, 126], [127, 129], [130, 134], [135, 139], [139, 140]]}
{"doc_key": "ai-dev-236", "ner": [[3, 6, "product"], [9, 11, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 3, 6, "part-of", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["For", "example", ",", "Word", "Net", "is", "a", "resource", "containing", "a", "taxonomy", "of", "the", "meanings", "of", "English", "words", "as", "elements", "."], "sentence-detokenized": "For example, WordNet is a resource containing a taxonomy of the meanings of English words as elements.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [17, 20], [21, 23], [24, 25], [26, 34], [35, 45], [46, 47], [48, 56], [57, 59], [60, 63], [64, 72], [73, 75], [76, 83], [84, 89], [90, 92], [93, 101], [101, 102]]}
{"doc_key": "ai-dev-237", "ner": [[1, 3, "product"], [5, 9, "product"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[5, 9, 1, 3, "type-of", "", false, false], [5, 9, 15, 16, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [2, 3], "sentence": ["Existing", "humanoid", "robot", "systems", ",", "such", "as", "ASIMO", "and", "QRIO", ",", "use", "many", "motors", "to", "achieve", "locomotion", "."], "sentence-detokenized": "Existing humanoid robot systems, such as ASIMO and QRIO, use many motors to achieve locomotion.", "token2charspan": [[0, 8], [9, 17], [18, 23], [24, 31], [31, 32], [33, 37], [38, 40], [41, 46], [47, 50], [51, 55], [55, 56], [57, 60], [61, 65], [66, 72], [73, 75], [76, 83], [84, 94], [94, 95]]}
{"doc_key": "ai-dev-238", "ner": [[0, 1, "metrics"], [5, 6, "metrics"], [8, 8, "metrics"], [10, 14, "misc"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 0, 1, "part-of", "", false, false], [8, 8, 0, 1, "part-of", "", false, false], [10, 14, 0, 1, "part-of", "", false, false], [16, 16, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LEPOR", "is", "designed", "with", "enhanced", "length", "penalty", ",", "precision", ",", "n-", "gram", "word", "order", "penalty", "and", "recall", "."], "sentence-detokenized": "LEPOR is designed with enhanced length penalty, precision, n-gram word order penalty and recall.", "token2charspan": [[0, 5], [6, 8], [9, 17], [18, 22], [23, 31], [32, 38], [39, 46], [46, 47], [48, 57], [57, 58], [59, 61], [61, 65], [66, 70], [71, 76], [77, 84], [85, 88], [89, 95], [95, 96]]}
{"doc_key": "ai-dev-239", "ner": [[0, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "based", "on", "the", "Bilingual", "Evaluation", "Index", ",", "but", "with", "slight", "modifications", "."], "sentence-detokenized": "It is based on the Bilingual Evaluation Index, but with slight modifications.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 14], [15, 18], [19, 28], [29, 39], [40, 45], [45, 46], [47, 50], [51, 55], [56, 62], [63, 76], [76, 77]]}
{"doc_key": "ai-dev-240", "ner": [[3, 3, "product"], [5, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Example", "implementation", "in", "MATLAB", "/", "Octave", "."], "sentence-detokenized": "Example implementation in MATLAB / Octave.", "token2charspan": [[0, 7], [8, 22], [23, 25], [26, 32], [33, 34], [35, 41], [41, 42]]}
{"doc_key": "ai-dev-241", "ner": [[13, 13, "programlang"], [15, 15, "programlang"], [12, 17, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "intended", "for", "use", "with", "a", "variety", "of", "computer", "languages", ",", "including", "Python", ",", "Ruby", "and", "Scheme", "."], "sentence-detokenized": "It is intended for use with a variety of computer languages, including Python, Ruby and Scheme.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 18], [19, 22], [23, 27], [28, 29], [30, 37], [38, 40], [41, 49], [50, 59], [59, 60], [61, 70], [71, 77], [77, 78], [79, 83], [84, 87], [88, 94], [94, 95]]}
{"doc_key": "ai-dev-242", "ner": [[0, 1, "researcher"], [5, 5, "organisation"], [11, 11, "conference"], [16, 17, "academicjournal"], [22, 24, "organisation"], [26, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 5, 5, "role", "", false, false], [0, 1, 11, 11, "role", "", false, false], [0, 1, 16, 17, "role", "", false, false], [0, 1, 22, 24, "role", "", false, false], [0, 1, 26, 33, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hayes", "is", "secretary", "of", "the", "AISB", ",", "president", "and", "trustee", "of", "IJCAI", ",", "deputy", "editor", "of", "Artificial", "Intelligence", ",", "governor", "of", "the", "Cognitive", "Science", "Society", "and", "president", "of", "the", "American", "Society", "for", "Artificial", "Intelligence", "."], "sentence-detokenized": "Hayes is secretary of the AISB, president and trustee of IJCAI, deputy editor of Artificial Intelligence, governor of the Cognitive Science Society and president of the American Society for Artificial Intelligence.", "token2charspan": [[0, 5], [6, 8], [9, 18], [19, 21], [22, 25], [26, 30], [30, 31], [32, 41], [42, 45], [46, 53], [54, 56], [57, 62], [62, 63], [64, 70], [71, 77], [78, 80], [81, 91], [92, 104], [104, 105], [106, 114], [115, 117], [118, 121], [122, 131], [132, 139], [140, 147], [148, 151], [152, 161], [162, 164], [165, 168], [169, 177], [178, 185], [186, 189], [190, 200], [201, 213], [213, 214]]}
{"doc_key": "ai-dev-243", "ner": [[5, 15, "misc"], [18, 21, "misc"], [23, 25, "person"], [26, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 25, 5, 15, "role", "directed_by", false, false], [23, 25, 18, 21, "role", "directed_by", false, false], [23, 25, 26, 33, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "of", "these", "films", ",", "Now", "is", "the", "Time", "(", "to", "Put", "On", "Your", "Glasses", ")", "and", "Around", "is", "Around", ",", "were", "directed", "by", "Norman", "McLaren", "for", "the", "National", "Film", "Board", "of", "Canada", "in", "1951", "."], "sentence-detokenized": "Two of these films, Now is the Time (to Put On Your Glasses) and Around is Around, were directed by Norman McLaren for the National Film Board of Canada in 1951.", "token2charspan": [[0, 3], [4, 6], [7, 12], [13, 18], [18, 19], [20, 23], [24, 26], [27, 30], [31, 35], [36, 37], [37, 39], [40, 43], [44, 46], [47, 51], [52, 59], [59, 60], [61, 64], [65, 71], [72, 74], [75, 81], [81, 82], [83, 87], [88, 96], [97, 99], [100, 106], [107, 114], [115, 118], [119, 122], [123, 131], [132, 136], [137, 142], [143, 145], [146, 152], [153, 155], [156, 160], [160, 161]]}
{"doc_key": "ai-dev-244", "ner": [[0, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "recommender", "system", "aims", "to", "predict", "the", "target", "user", "'s", "preferences", "for", "items", "."], "sentence-detokenized": "The recommender system aims to predict the target user's preferences for items.", "token2charspan": [[0, 3], [4, 15], [16, 22], [23, 27], [28, 30], [31, 38], [39, 42], [43, 49], [50, 54], [54, 56], [57, 68], [69, 72], [73, 78], [78, 79]]}
{"doc_key": "ai-dev-245", "ner": [[0, 0, "algorithm"], [4, 5, "field"], [7, 7, "field"], [9, 10, "field"], [12, 14, "field"], [16, 16, "field"], [18, 19, "field"], [21, 21, "field"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 5, "part-of", "", true, false], [0, 0, 7, 7, "part-of", "", true, false], [0, 0, 9, 10, "part-of", "", true, false], [0, 0, 12, 14, "part-of", "", true, false], [0, 0, 16, 16, "part-of", "", true, false], [0, 0, 18, 19, "part-of", "", true, false], [0, 0, 21, 21, "part-of", "", true, false], [0, 0, 23, 24, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Convolution", "has", "applications", "in", "probability", "theory", ",", "statistics", ",", "computer", "vision", ",", "natural", "language", "processing", ",", "image", "and", "signal", "processing", ",", "engineering", "and", "differential", "equations", "."], "sentence-detokenized": "Convolution has applications in probability theory, statistics, computer vision, natural language processing, image and signal processing, engineering and differential equations.", "token2charspan": [[0, 11], [12, 15], [16, 28], [29, 31], [32, 43], [44, 50], [50, 51], [52, 62], [62, 63], [64, 72], [73, 79], [79, 80], [81, 88], [89, 97], [98, 108], [108, 109], [110, 115], [116, 119], [120, 126], [127, 137], [137, 138], [139, 150], [151, 154], [155, 167], [168, 177], [177, 178]]}
{"doc_key": "ai-dev-246", "ner": [[1, 3, "field"], [4, 6, "task"], [8, 9, "task"], [11, 11, "task"], [12, 12, "task"], [13, 13, "task"], [15, 16, "task"], [19, 19, "task"], [21, 22, "task"], [24, 24, "task"], [27, 28, "task"], [30, 30, "field"], [32, 32, "field"], [34, 36, "field"], [38, 38, "field"], [40, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[1, 3, 4, 6, "part-of", "", true, false], [1, 3, 8, 9, "part-of", "", true, false], [1, 3, 11, 11, "part-of", "", true, false], [1, 3, 12, 12, "part-of", "", true, false], [1, 3, 13, 13, "part-of", "", true, false], [1, 3, 15, 16, "part-of", "", true, false], [1, 3, 19, 19, "part-of", "", true, false], [1, 3, 21, 22, "part-of", "", true, false], [1, 3, 24, 24, "part-of", "", true, false], [1, 3, 27, 28, "part-of", "", true, false], [1, 3, 30, 30, "part-of", "", true, false], [1, 3, 32, 32, "part-of", "", true, false], [1, 3, 34, 36, "part-of", "", true, false], [1, 3, 38, 38, "part-of", "", true, false], [1, 3, 40, 40, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Applications", "of", "DSP", "include", "audio", "signal", "processing", ",", "speech", "compression", ",", "digital", "image", "processing", ",", "video", "compression", ",", "speech", "processing", ",", "speech", "recognition", ",", "digital", "communications", ",", "digital", "synthesis", ",", "radar", ",", "sonar", ",", "financial", "signal", "processing", ",", "seismology", "and", "biomedicine", "."], "sentence-detokenized": "Applications of DSP include audio signal processing, speech compression, digital image processing, video compression, speech processing, speech recognition, digital communications, digital synthesis, radar, sonar, financial signal processing, seismology and biomedicine.", "token2charspan": [[0, 12], [13, 15], [16, 19], [20, 27], [28, 33], [34, 40], [41, 51], [51, 52], [53, 59], [60, 71], [71, 72], [73, 80], [81, 86], [87, 97], [97, 98], [99, 104], [105, 116], [116, 117], [118, 124], [125, 135], [135, 136], [137, 143], [144, 155], [155, 156], [157, 164], [165, 179], [179, 180], [181, 188], [189, 198], [198, 199], [200, 205], [205, 206], [207, 212], [212, 213], [214, 223], [224, 230], [231, 241], [241, 242], [243, 253], [254, 257], [258, 269], [269, 270]]}
{"doc_key": "ai-dev-247", "ner": [[11, 12, "misc"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "20", "February", "1912", "-", "11", "August", "2011", ")", "was", "an", "American", "inventor", ",", "best", "known", "for", "creating", "the", "Unimate", ",", "the", "first", "industrial", "robot", "."], "sentence-detokenized": "(20 February 1912 - 11 August 2011) was an American inventor, best known for creating the Unimate, the first industrial robot.", "token2charspan": [[0, 1], [1, 3], [4, 12], [13, 17], [18, 19], [20, 22], [23, 29], [30, 34], [34, 35], [36, 39], [40, 42], [43, 51], [52, 60], [60, 61], [62, 66], [67, 72], [73, 76], [77, 85], [86, 89], [90, 97], [97, 98], [99, 102], [103, 108], [109, 119], [120, 125], [125, 126]]}
{"doc_key": "ai-dev-248", "ner": [[18, 20, "researcher"], [22, 26, "researcher"], [8, 10, "algorithm"], [11, 14, "algorithm"], [29, 30, "task"], [35, 36, "algorithm"], [34, 39, "researcher"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7], "relations": [[18, 20, 8, 10, "related-to", "writes_about", true, false], [22, 26, 8, 10, "related-to", "writes_about", true, false], [8, 10, 11, 14, "related-to", "", true, false], [29, 30, 35, 36, "related-to", "", true, false], [34, 39, 35, 36, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 3, 4, 5], "sentence": ["In", "a", "paper", "published", "in", "1986", "generalising", "the", "backpropagation", "algorithm", "for", "training", "multilayer", "neural", "nets", ",", "co-authored", "with", "David", "E.", "Rumelhart", "and", "Ronald", "J.", "Williams", ",", "a", "milestone", "in", "image", "recognition", ",", "his", "student", "Alex", "Alex", "Net", "designed", "by", "Krizhevsky", "{{", "cite", "web"], "sentence-detokenized": "In a paper published in 1986 generalising the backpropagation algorithm for training multilayer neural nets, co-authored with David E. Rumelhart and Ronald J. Williams, a milestone in image recognition, his student Alex AlexNet designed by Krizhevsky {{cite web", "token2charspan": [[0, 2], [3, 4], [5, 10], [11, 20], [21, 23], [24, 28], [29, 41], [42, 45], [46, 61], [62, 71], [72, 75], [76, 84], [85, 95], [96, 102], [103, 107], [107, 108], [109, 120], [121, 125], [126, 131], [132, 134], [135, 144], [145, 148], [149, 155], [156, 158], [159, 167], [167, 168], [169, 170], [171, 180], [181, 183], [184, 189], [190, 201], [201, 202], [203, 206], [207, 214], [215, 219], [220, 224], [224, 227], [228, 236], [237, 239], [240, 250], [251, 253], [253, 257], [258, 261]]}
{"doc_key": "ai-dev-249", "ner": [[9, 11, "metrics"], [13, 16, "metrics"], [18, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "predicted", "values", "are", "continuously", "distributed", ",", "the", "mean", "square", "error", ",", "root", "mean", "square", "error", "and", "central", "absolute", "deviation", "may", "be", "used", "to", "summarise", "the", "error", "."], "sentence-detokenized": "If the predicted values are continuously distributed, the mean square error, root mean square error and central absolute deviation may be used to summarise the error.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 23], [24, 27], [28, 40], [41, 52], [52, 53], [54, 57], [58, 62], [63, 69], [70, 75], [75, 76], [77, 81], [82, 86], [87, 93], [94, 99], [100, 103], [104, 111], [112, 120], [121, 130], [131, 134], [135, 137], [138, 142], [143, 145], [146, 155], [156, 159], [160, 165], [165, 166]]}
{"doc_key": "ai-dev-250", "ner": [[0, 1, "algorithm"], [9, 10, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 9, 10, "part-of", "", true, false], [0, 1, 13, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Conceptual", "clustering", "developed", "mainly", "in", "the", "1980s", "as", "a", "machine", "learning", "paradigm", "for", "unsupervised", "learning", "."], "sentence-detokenized": "Conceptual clustering developed mainly in the 1980s as a machine learning paradigm for unsupervised learning.", "token2charspan": [[0, 10], [11, 21], [22, 31], [32, 38], [39, 41], [42, 45], [46, 51], [52, 54], [55, 56], [57, 64], [65, 73], [74, 82], [83, 86], [87, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-dev-251", "ner": [[10, 15, "product"], [30, 36, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "a", "named", "entity", "can", "not", "be", "recognised", "by", "the", "machine", "translator", ",", "it", "may", "be", "incorrectly", "translated", "as", "a", "common", "noun", ".", "This", "would", "most", "likely", "not", "affect", "the", "pronominality", "of", "the", "translation", "'s", "bilingual", "evaluation", ",", "but", "would", "change", "the", "human", "readability", "of", "the", "text", "."], "sentence-detokenized": "If a named entity cannot be recognised by the machine translator, it may be incorrectly translated as a common noun. This would most likely not affect the pronominality of the translation's bilingual evaluation, but would change the human readability of the text.", "token2charspan": [[0, 2], [3, 4], [5, 10], [11, 17], [18, 21], [21, 24], [25, 27], [28, 38], [39, 41], [42, 45], [46, 53], [54, 64], [64, 65], [66, 68], [69, 72], [73, 75], [76, 87], [88, 98], [99, 101], [102, 103], [104, 110], [111, 115], [115, 116], [117, 121], [122, 127], [128, 132], [133, 139], [140, 143], [144, 150], [151, 154], [155, 168], [169, 171], [172, 175], [176, 187], [187, 189], [190, 199], [200, 210], [210, 211], [212, 215], [216, 221], [222, 228], [229, 232], [233, 238], [239, 250], [251, 253], [254, 257], [258, 262], [262, 263]]}
{"doc_key": "ai-dev-252", "ner": [[0, 1, "researcher"], [10, 11, "misc"], [12, 17, "conference"], [19, 21, "location"], [23, 23, "country"], [36, 38, "researcher"], [48, 48, "university"], [51, 52, "researcher"], [54, 55, "researcher"], [57, 58, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10], "relations": [[0, 1, 10, 11, "related-to", "writes_about", false, false], [0, 1, 12, 17, "temporal", "", true, false], [12, 17, 19, 21, "physical", "", false, false], [19, 21, 23, 23, "physical", "", false, false], [51, 52, 48, 48, "physical", "", false, false], [51, 52, 48, 48, "role", "", false, false], [54, 55, 48, 48, "physical", "", false, false], [54, 55, 48, 48, "role", "", false, false], [57, 58, 48, 48, "physical", "", false, false], [57, 58, 48, 48, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 6, 7, 8, 9, 10, 11], "sentence": ["Roger", "Schank", ",", "1969", ",", "A", "conceptual", "dependency", "parser", "for", "natural", "language", "Proceedings", "of", "1969", "on", "Computational", "linguistics", ",", "S\u00e5ng", "-", "S\u00e4by", ",", "Sweden", ",", "pages", "1-", "3", "This", "model", "was", "partly", "influenced", "by", "the", "work", "of", "Sydney", "Lamb", "and", "was", "widely", "used", "by", "Schank", "'s", "students", "at", "Yale", "University", ",", "Robert", "Wilensky", ",", "Wendy", "Lehnert", ",", "Janet", "Kolodner", "and", "others", "."], "sentence-detokenized": "Roger Schank, 1969, A conceptual dependency parser for natural language Proceedings of 1969 on Computational linguistics, S\u00e5ng-S\u00e4by, Sweden, pages 1-3 This model was partly influenced by the work of Sydney Lamb and was widely used by Schank's students at Yale University, Robert Wilensky, Wendy Lehnert, Janet Kolodner and others.", "token2charspan": [[0, 5], [6, 12], [12, 13], [14, 18], [18, 19], [20, 21], [22, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 71], [72, 83], [84, 86], [87, 91], [92, 94], [95, 108], [109, 120], [120, 121], [122, 126], [126, 127], [127, 131], [131, 132], [133, 139], [139, 140], [141, 146], [147, 149], [149, 150], [151, 155], [156, 161], [162, 165], [166, 172], [173, 183], [184, 186], [187, 190], [191, 195], [196, 198], [199, 205], [206, 210], [211, 214], [215, 218], [219, 225], [226, 230], [231, 233], [234, 240], [240, 242], [243, 251], [252, 254], [255, 259], [260, 270], [270, 271], [272, 278], [279, 287], [287, 288], [289, 294], [295, 302], [302, 303], [304, 309], [310, 318], [319, 322], [323, 329], [329, 330]]}
{"doc_key": "ai-dev-253", "ner": [[3, 6, "algorithm"], [10, 10, "algorithm"], [12, 13, "metrics"]], "ner_mapping_to_source": [1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "improved", "maximum", "likelihood", "method", "(", "IMLM", ")", "combines", "two", "MLM", "(", "maximum", "likelihood", ")", "estimators", "."], "sentence-detokenized": "The improved maximum likelihood method (IMLM) combines two MLM (maximum likelihood) estimators.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 31], [32, 38], [39, 40], [40, 44], [44, 45], [46, 54], [55, 58], [59, 62], [63, 64], [64, 71], [72, 82], [82, 83], [84, 94], [94, 95]]}
{"doc_key": "ai-dev-254", "ner": [[21, 22, "metrics"], [15, 26, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 26, 21, 22, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["These", "methods", "may", "also", "analyse", "the", "programme", "'s", "outputs", "and", "their", "usefulness", ",", "and", "therefore", "may", "include", "an", "analysis", "of", "its", "confusion", "matrix", "(", "or", "confusion", "table", ")", "."], "sentence-detokenized": "These methods may also analyse the programme's outputs and their usefulness, and therefore may include an analysis of its confusion matrix (or confusion table).", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 22], [23, 30], [31, 34], [35, 44], [44, 46], [47, 54], [55, 58], [59, 64], [65, 75], [75, 76], [77, 80], [81, 90], [91, 94], [95, 102], [103, 105], [106, 114], [115, 117], [118, 121], [122, 131], [132, 138], [139, 140], [140, 142], [143, 152], [153, 158], [158, 159], [159, 160]]}
{"doc_key": "ai-dev-255", "ner": [[0, 1, "product"], [5, 6, "researcher"], [8, 9, "researcher"], [11, 13, "researcher"], [18, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 6, "origin", "", false, false], [0, 1, 8, 9, "origin", "", false, false], [0, 1, 11, 13, "origin", "", false, false], [0, 1, 18, 23, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SURF", "was", "first", "presented", "by", "Herbert", "Bay", ",", "Tinne", "Tuytelaars", "and", "Luc", "Van", "Gool", "and", "presented", "at", "the", "2006", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "SURF was first presented by Herbert Bay, Tinne Tuytelaars and Luc Van Gool and presented at the 2006 European Conference on Computer Vision.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 24], [25, 27], [28, 35], [36, 39], [39, 40], [41, 46], [47, 57], [58, 61], [62, 65], [66, 69], [70, 74], [75, 78], [79, 88], [89, 91], [92, 95], [96, 100], [101, 109], [110, 120], [121, 123], [124, 132], [133, 139], [139, 140]]}
{"doc_key": "ai-dev-256", "ner": [[0, 0, "task"], [6, 7, "field"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 7, "part-of", "", false, false], [0, 0, 9, 10, "part-of", "", false, false], [0, 0, 12, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OCR", "is", "a", "research", "area", "in", "pattern", "recognition", ",", "artificial", "intelligence", "and", "computer", "vision", "."], "sentence-detokenized": "OCR is a research area in pattern recognition, artificial intelligence and computer vision.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 17], [18, 22], [23, 25], [26, 33], [34, 45], [45, 46], [47, 57], [58, 70], [71, 74], [75, 83], [84, 90], [90, 91]]}
{"doc_key": "ai-dev-257", "ner": [[4, 7, "metrics"], [10, 16, "algorithm"], [14, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 10, 16, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Continuing", "the", "example", "with", "the", "maximum", "likelihood", "estimator", ",", "the", "probability", "density", "function", "(", "pdf", ")", "of", "the", "noise", "for", "one", "sample", "mathwn", "/", "math", "is"], "sentence-detokenized": "Continuing the example with the maximum likelihood estimator, the probability density function (pdf) of the noise for one sample mathwn / math is", "token2charspan": [[0, 10], [11, 14], [15, 22], [23, 27], [28, 31], [32, 39], [40, 50], [51, 60], [60, 61], [62, 65], [66, 77], [78, 85], [86, 94], [95, 96], [96, 99], [99, 100], [101, 103], [104, 107], [108, 113], [114, 117], [118, 121], [122, 128], [129, 135], [136, 137], [138, 142], [143, 145]]}
{"doc_key": "ai-dev-258", "ner": [[0, 1, "field"], [4, 5, "task"], [7, 8, "task"], [10, 11, "task"], [13, 14, "task"], [16, 18, "task"], [20, 20, "task"], [22, 22, "task"], [24, 25, "task"], [27, 28, "task"], [30, 32, "task"], [34, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[4, 5, 0, 1, "part-of", "", false, false], [7, 8, 0, 1, "part-of", "", false, false], [10, 11, 0, 1, "part-of", "", false, false], [13, 14, 0, 1, "part-of", "", false, false], [16, 18, 0, 1, "part-of", "", false, false], [20, 20, 0, 1, "part-of", "", false, false], [22, 22, 0, 1, "part-of", "", false, false], [24, 25, 0, 1, "part-of", "", false, false], [27, 28, 0, 1, "part-of", "", false, false], [30, 32, 0, 1, "part-of", "", false, false], [34, 35, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Computer", "vision", "sub-domains", "include", "scene", "reconstruction", ",", "event", "detection", ",", "video", "tracking", ",", "object", "recognition", ",", "3D", "pose", "estimation", ",", "learning", ",", "indexing", ",", "motion", "estimation", ",", "visual", "servoing", ",", "3D", "scene", "modelling", "and", "image", "restoration", "."], "sentence-detokenized": "Computer vision sub-domains include scene reconstruction, event detection, video tracking, object recognition, 3D pose estimation, learning, indexing, motion estimation, visual servoing, 3D scene modelling and image restoration.", "token2charspan": [[0, 8], [9, 15], [16, 27], [28, 35], [36, 41], [42, 56], [56, 57], [58, 63], [64, 73], [73, 74], [75, 80], [81, 89], [89, 90], [91, 97], [98, 109], [109, 110], [111, 113], [114, 118], [119, 129], [129, 130], [131, 139], [139, 140], [141, 149], [149, 150], [151, 157], [158, 168], [168, 169], [170, 176], [177, 185], [185, 186], [187, 189], [190, 195], [196, 205], [206, 209], [210, 215], [216, 227], [227, 228]]}
{"doc_key": "ai-dev-259", "ner": [[5, 8, "conference"], [10, 10, "researcher"], [13, 17, "misc"], [18, 33, "conference"], [25, 32, "researcher"], [21, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6], "relations": [[5, 8, 18, 33, "named", "", false, false], [10, 10, 13, 17, "win-defeat", "", false, false], [10, 10, 21, 22, "related-to", "writes_about", true, false], [13, 17, 5, 8, "temporal", "", false, false], [25, 32, 13, 17, "win-defeat", "", false, true], [25, 32, 21, 22, "related-to", "writes_about", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 6, 7], "sentence": ["In", "2013", ",", "at", "the", "International", "Computer", "Vision", "Conference", ",", "Terzopoulos", "was", "awarded", "the", "Helmholtz", "Prize", "for", "an", "ICCV", "paper", "on", "active", "contour", "modelling", ",", "which", "he", "presented", "with", "Kass", "and", "Witkin", "in", "1987", "."], "sentence-detokenized": "In 2013, at the International Computer Vision Conference, Terzopoulos was awarded the Helmholtz Prize for an ICCV paper on active contour modelling, which he presented with Kass and Witkin in 1987.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 29], [30, 38], [39, 45], [46, 56], [56, 57], [58, 69], [70, 73], [74, 81], [82, 85], [86, 95], [96, 101], [102, 105], [106, 108], [109, 113], [114, 119], [120, 122], [123, 129], [130, 137], [138, 147], [147, 148], [149, 154], [155, 157], [158, 167], [168, 172], [173, 177], [178, 181], [182, 188], [189, 191], [192, 196], [196, 197]]}
{"doc_key": "ai-dev-260", "ner": [[18, 20, "task"], [21, 23, "algorithm"], [25, 27, "algorithm"], [29, 30, "algorithm"], [32, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 3, 4, 5], "relations": [[18, 20, 21, 23, "usage", "", true, false], [18, 20, 25, 27, "usage", "", true, false], [18, 20, 29, 30, "usage", "", true, false], [18, 20, 32, 33, "usage", "", true, false]], "relations_mapping_to_source": [0, 2, 3, 4], "sentence": ["For", "regularisation", "functions", "There", "are", "many", "algorithms", "for", "solving", "such", "problems", ",", "but", "the", "most", "commonly", "used", "in", "linear", "classification", "are", "Stochastic", "gradient", "descent", ",", "L", "-", "BFGS", ",", "coordinate", "descent", "and", "Newton", "'s", "method", "."], "sentence-detokenized": "For regularisation functions There are many algorithms for solving such problems, but the most commonly used in linear classification are Stochastic gradient descent, L-BFGS, coordinate descent and Newton's method.", "token2charspan": [[0, 3], [4, 18], [19, 28], [29, 34], [35, 38], [39, 43], [44, 54], [55, 58], [59, 66], [67, 71], [72, 80], [80, 81], [82, 85], [86, 89], [90, 94], [95, 103], [104, 108], [109, 111], [112, 118], [119, 133], [134, 137], [138, 148], [149, 157], [158, 165], [165, 166], [167, 168], [168, 169], [169, 173], [173, 174], [175, 185], [186, 193], [194, 197], [198, 204], [204, 206], [207, 213], [213, 214]]}
{"doc_key": "ai-dev-261", "ner": [[13, 14, "algorithm"], [10, 12, "algorithm"], [2, 2, "researcher"], [5, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 14, 2, 2, "origin", "", false, false], [10, 12, 13, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Invented", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "in", "1997", ",", "LSTM", "(", "Long", "Short", "Memory", ")", "networks", "have", "set", "accuracy", "records", "in", "several", "application", "areas", "."], "sentence-detokenized": "Invented by Sepp Hochreiter and J\u00fcrgen Schmidhuber in 1997, LSTM (Long Short Memory) networks have set accuracy records in several application areas.", "token2charspan": [[0, 8], [9, 11], [12, 16], [17, 27], [28, 31], [32, 38], [39, 50], [51, 53], [54, 58], [58, 59], [60, 64], [65, 66], [66, 70], [71, 76], [77, 83], [83, 84], [85, 93], [94, 98], [99, 102], [103, 111], [112, 119], [120, 122], [123, 130], [131, 142], [143, 148], [148, 149]]}
{"doc_key": "ai-dev-262", "ner": [[0, 1, "product"], [4, 5, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 4, 5, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["TN", "was", "developed", "at", "Massachusetts", "General", "Hospital", "and", "tested", "in", "several", "scenarios", ",", "including", "smoking", "status", ",", "extracting", "family", "history", "of", "coronary", "artery", "disease", "and", "identifying", "patients", "with", "sleep", "disturbances", "."], "sentence-detokenized": "TN was developed at Massachusetts General Hospital and tested in several scenarios, including smoking status, extracting family history of coronary artery disease and identifying patients with sleep disturbances.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 33], [34, 41], [42, 50], [51, 54], [55, 61], [62, 64], [65, 72], [73, 82], [82, 83], [84, 93], [94, 101], [102, 108], [108, 109], [110, 120], [121, 127], [128, 135], [136, 138], [139, 147], [148, 154], [155, 162], [163, 166], [167, 178], [179, 187], [188, 192], [193, 198], [199, 211], [211, 212]]}
{"doc_key": "ai-dev-263", "ner": [[8, 10, "researcher"], [14, 18, "organisation"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "first", "Unimate", "robot", ",", "sold", "privately", "by", "Mr", "Debord", "in", "1960", ",", "was", "shipped", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "The first Unimate robot, sold privately by Mr Debord in 1960, was shipped to General Motors in 1961.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 23], [23, 24], [25, 29], [30, 39], [40, 42], [43, 45], [46, 52], [53, 55], [56, 60], [60, 61], [62, 65], [66, 73], [74, 76], [77, 84], [85, 91], [92, 94], [95, 99], [99, 100]]}
{"doc_key": "ai-dev-264", "ner": [[21, 26, "conference"], [27, 29, "location"], [32, 32, "country"], [18, 20, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4], "relations": [[21, 26, 27, 29, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["From", "14", "-", "18", "April", "2010", ",", "800", "participants", "from", "each", "of", "the", "27", "Member", "States", "of", "the", "European", "Union", "took", "part", "in", "Campus", "Party", "Europe", "at", "Caja", "M\u00e1gica", "in", "Madrid", ",", "Spain", "."], "sentence-detokenized": "From 14-18 April 2010, 800 participants from each of the 27 Member States of the European Union took part in Campus Party Europe at Caja M\u00e1gica in Madrid, Spain.", "token2charspan": [[0, 4], [5, 7], [7, 8], [8, 10], [11, 16], [17, 21], [21, 22], [23, 26], [27, 39], [40, 44], [45, 49], [50, 52], [53, 56], [57, 59], [60, 66], [67, 73], [74, 76], [77, 80], [81, 89], [90, 95], [96, 100], [101, 105], [106, 108], [109, 115], [116, 121], [122, 128], [129, 131], [132, 136], [137, 143], [144, 146], [147, 153], [153, 154], [155, 160], [160, 161]]}
{"doc_key": "ai-dev-265", "ner": [[9, 12, "organisation"], [15, 19, "misc"]], "ner_mapping_to_source": [1, 2], "relations": [[15, 19, 9, 12, "origin", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["In", "July", "2016", ",", "a", "collaboration", "between", "DeepMind", "and", "Moorfields", "Eye", "Hospital", "was", "announced", "to", "develop", "AI", "applications", "for", "healthcare", "."], "sentence-detokenized": "In July 2016, a collaboration between DeepMind and Moorfields Eye Hospital was announced to develop AI applications for healthcare.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 15], [16, 29], [30, 37], [38, 46], [47, 50], [51, 61], [62, 65], [66, 74], [75, 78], [79, 88], [89, 91], [92, 99], [100, 102], [103, 115], [116, 119], [120, 130], [130, 131]]}
{"doc_key": "ai-dev-266", "ner": [[0, 3, "misc"], [11, 11, "university"], [13, 13, "university"], [15, 16, "university"], [18, 19, "university"], [21, 21, "university"], [23, 23, "university"], [25, 28, "university"], [30, 31, "university"], [33, 34, "university"], [36, 36, "university"], [7, 39, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[0, 3, 11, 11, "physical", "", false, false], [0, 3, 13, 13, "physical", "", false, false], [0, 3, 15, 16, "physical", "", false, false], [0, 3, 18, 19, "physical", "", false, false], [0, 3, 21, 21, "physical", "", false, false], [0, 3, 23, 23, "physical", "", false, false], [0, 3, 25, 28, "physical", "", false, false], [0, 3, 30, 31, "physical", "", false, false], [0, 3, 33, 34, "physical", "", false, false], [0, 3, 36, 36, "physical", "", false, false], [0, 3, 7, 39, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["PR2s", "were", "awarded", "to", "11", "institutions", ",", "including", "the", "University", "of", "Freiburg", ",", "Bosch", ",", "Georgia", "Tech", ",", "KU", "Leuven", ",", "MIT", ",", "Stanford", ",", "Technical", "University", "of", "Munich", ",", "UC", "Berkeley", ",", "U", "Penn", ",", "USC", "and", "Tokyo", "University", "."], "sentence-detokenized": "PR2s were awarded to 11 institutions, including the University of Freiburg, Bosch, Georgia Tech, KU Leuven, MIT, Stanford, Technical University of Munich, UC Berkeley, U Penn, USC and Tokyo University.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 20], [21, 23], [24, 36], [36, 37], [38, 47], [48, 51], [52, 62], [63, 65], [66, 74], [74, 75], [76, 81], [81, 82], [83, 90], [91, 95], [95, 96], [97, 99], [100, 106], [106, 107], [108, 111], [111, 112], [113, 121], [121, 122], [123, 132], [133, 143], [144, 146], [147, 153], [153, 154], [155, 157], [158, 166], [166, 167], [168, 169], [170, 174], [174, 175], [176, 179], [180, 183], [184, 189], [190, 200], [200, 201]]}
{"doc_key": "ai-dev-267", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [7, 8, "metrics"], [9, 10, "metrics"], [18, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 18, 19, "part-of", "", false, false], [5, 5, 18, 19, "part-of", "", false, false], [7, 8, 18, 19, "part-of", "", false, false], [9, 10, 18, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "counts", "of", "TPs", ",", "TNs", ",", "FPs", "and", "FNs", "are", "usually", "managed", "in", "a", "table", "called", "the", "confusion", "matrix", "."], "sentence-detokenized": "The counts of TPs, TNs, FPs and FNs are usually managed in a table called the confusion matrix.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 17], [17, 18], [19, 22], [22, 23], [24, 27], [28, 31], [32, 35], [36, 39], [40, 47], [48, 55], [56, 58], [59, 60], [61, 66], [67, 73], [74, 77], [78, 87], [88, 94], [94, 95]]}
{"doc_key": "ai-dev-268", "ner": [[4, 5, "metrics"], [7, 8, "metrics"], [10, 12, "metrics"], [3, 15, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Commonly", "used", "features", "include", "information", "gain", ",", "cross", "-entropy", ",", "mutual", "information", "content", "and", "odds", "ratio", "."], "sentence-detokenized": "Commonly used features include information gain, cross-entropy, mutual information content and odds ratio.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 30], [31, 42], [43, 47], [47, 48], [49, 54], [54, 62], [62, 63], [64, 70], [71, 82], [83, 90], [91, 94], [95, 99], [100, 105], [105, 106]]}
{"doc_key": "ai-dev-269", "ner": [[12, 13, "task"], [16, 16, "task"], [18, 18, "task"], [20, 20, "task"], [22, 22, "task"], [11, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 24, 22, 22, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "successfully", "applied", "to", "a", "variety", "of", "problems", ",", "including", "robot", "control", ",", "elevator", "scheduling", ",", "telecommunications", ",", "checkers", "and", "Go", "(", "AlphaGo", ")", "."], "sentence-detokenized": "It has been successfully applied to a variety of problems, including robot control, elevator scheduling, telecommunications, checkers and Go (AlphaGo).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 24], [25, 32], [33, 35], [36, 37], [38, 45], [46, 48], [49, 57], [57, 58], [59, 68], [69, 74], [75, 82], [82, 83], [84, 92], [93, 103], [103, 104], [105, 123], [123, 124], [125, 133], [134, 137], [138, 140], [141, 142], [142, 149], [149, 150], [150, 151]]}
{"doc_key": "ai-dev-270", "ner": [[11, 12, "misc"], [17, 20, "university"], [23, 23, "location"], [24, 25, "location"], [29, 33, "location"], [34, 38, "location"], [39, 39, "location"], [40, 41, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 17, 20, "physical", "", false, false], [17, 20, 23, 23, "physical", "", false, false], [23, 23, 24, 25, "physical", "", false, false], [29, 33, 34, 38, "physical", "", false, false], [34, 38, 39, 39, "physical", "", false, false], [39, 39, 40, 41, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "the", "first", "year", "of", "Mission", "8", ",", "the", "US", "venue", "was", "held", "at", "the", "Georgia", "Institute", "of", "Technology", "campus", "in", "Atlanta", ",", "Georgia", ",", "and", "the", "Asia", "/", "Pacific", "venue", "at", "the", "Beifang", "University", "Gymnasium", "in", "Beijing", ",", "China", "."], "sentence-detokenized": "In 2018, the first year of Mission 8, the US venue was held at the Georgia Institute of Technology campus in Atlanta, Georgia, and the Asia/Pacific venue at the Beifang University Gymnasium in Beijing, China.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 18], [19, 23], [24, 26], [27, 34], [35, 36], [36, 37], [38, 41], [42, 44], [45, 50], [51, 54], [55, 59], [60, 62], [63, 66], [67, 74], [75, 84], [85, 87], [88, 98], [99, 105], [106, 108], [109, 116], [116, 117], [118, 125], [125, 126], [127, 130], [131, 134], [135, 139], [139, 140], [140, 147], [148, 153], [154, 156], [157, 160], [161, 168], [169, 179], [180, 189], [190, 192], [193, 200], [200, 201], [202, 207], [207, 208]]}
{"doc_key": "ai-dev-271", "ner": [[0, 2, "field"], [6, 7, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 7, "origin", "", false, false], [0, 2, 6, 7, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "is", "strongly", "associated", "with", "pattern", "recognition", "and", "has", "its", "origins", "in", "artificial", "intelligence", "."], "sentence-detokenized": "Machine learning is strongly associated with pattern recognition and has its origins in artificial intelligence.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 28], [29, 39], [40, 44], [45, 52], [53, 64], [65, 68], [69, 72], [73, 76], [77, 84], [85, 87], [88, 98], [99, 111], [111, 112]]}
{"doc_key": "ai-dev-272", "ner": [[0, 7, "programlang"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "comes", "with", "three", "Java", "games", "that", "are", "controlled", "by", "remote", "control", "and", "displayed", "on", "the", "LCD", "screen", "."], "sentence-detokenized": "It comes with three Java games that are controlled by remote control and displayed on the LCD screen.", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 19], [20, 24], [25, 30], [31, 35], [36, 39], [40, 50], [51, 53], [54, 60], [61, 68], [69, 72], [73, 82], [83, 85], [86, 89], [90, 93], [94, 100], [100, 101]]}
{"doc_key": "ai-dev-273", "ner": [[5, 16, "task"], [17, 20, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 20, 5, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "commercially", "successful", "but", "specialised", "computer", "vision", "-", "based", "technique", "for", "estimating", "the", "posture", "of", "articulated", "bodies", "is", "optical", "motion", "capture", "."], "sentence-detokenized": "A commercially successful but specialised computer vision-based technique for estimating the posture of articulated bodies is optical motion capture.", "token2charspan": [[0, 1], [2, 14], [15, 25], [26, 29], [30, 41], [42, 50], [51, 57], [57, 58], [58, 63], [64, 73], [74, 77], [78, 88], [89, 92], [93, 100], [101, 103], [104, 115], [116, 122], [123, 125], [126, 133], [134, 140], [141, 148], [148, 149]]}
{"doc_key": "ai-dev-274", "ner": [[0, 2, "organisation"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 10, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "SMC", "is", "very", "similar", "to", "the", "more", "common", "Jaccard", "index", "."], "sentence-detokenized": "The SMC is very similar to the more common Jaccard index.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 15], [16, 23], [24, 26], [27, 30], [31, 35], [36, 42], [43, 50], [51, 56], [56, 57]]}
{"doc_key": "ai-dev-275", "ner": [[0, 6, "product"], [20, 23, "researcher"], [24, 28, "organisation"]], "ner_mapping_to_source": [1, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ",", "programmable", "universal", "manipulation", "arm", ")", "is", "an", "industrial", "robot", "robotic", "arm", "developed", "by", "Victor", "Scheinman", "of", "Unimation", ",", "a", "pioneer", "in", "robotics", "."], "sentence-detokenized": "PUMA (Programmable Universal Machine for Assembly, programmable universal manipulation arm) is an industrial robot robotic arm developed by Victor Scheinman of Unimation, a pioneer in robotics.", "token2charspan": [[0, 4], [5, 6], [6, 18], [19, 28], [29, 36], [37, 40], [41, 49], [49, 50], [51, 63], [64, 73], [74, 86], [87, 90], [90, 91], [92, 94], [95, 97], [98, 108], [109, 114], [115, 122], [123, 126], [127, 136], [137, 139], [140, 146], [147, 156], [157, 159], [160, 169], [169, 170], [171, 172], [173, 180], [181, 183], [184, 192], [192, 193]]}
{"doc_key": "ai-dev-276", "ner": [[3, 4, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "written", "in", "Python", "."], "sentence-detokenized": "It is written in Python.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 23], [23, 24]]}
{"doc_key": "ai-dev-277", "ner": [[2, 4, "misc"], [12, 12, "field"], [14, 15, "field"], [17, 17, "field"], [19, 19, "field"], [22, 23, "field"], [25, 25, "field"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["Bandwidth", "in", "Hertz", "is", "a", "central", "concept", "in", "many", "fields", ",", "including", "electronics", ",", "information", "theory", ",", "digital", "and", "wireless", "communications", ",", "signal", "processing", "and", "spectroscopy", ",", "and", "is", "one", "of", "the", "factors", "determining", "the", "capacity", "of", "a", "given", "communication", "channel", "."], "sentence-detokenized": "Bandwidth in Hertz is a central concept in many fields, including electronics, information theory, digital and wireless communications, signal processing and spectroscopy, and is one of the factors determining the capacity of a given communication channel.", "token2charspan": [[0, 9], [10, 12], [13, 18], [19, 21], [22, 23], [24, 31], [32, 39], [40, 42], [43, 47], [48, 54], [54, 55], [56, 65], [66, 77], [77, 78], [79, 90], [91, 97], [97, 98], [99, 106], [107, 110], [111, 119], [120, 134], [134, 135], [136, 142], [143, 153], [154, 157], [158, 170], [170, 171], [172, 175], [176, 178], [179, 182], [183, 185], [186, 189], [190, 197], [198, 209], [210, 213], [214, 222], [223, 225], [226, 227], [228, 233], [234, 247], [248, 255], [255, 256]]}
{"doc_key": "ai-dev-278", "ner": [[8, 8, "algorithm"], [10, 11, "algorithm"], [16, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 16, 19, "part-of", "", false, false], [10, 11, 16, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["When", "convex", "loss", "is", "used", "(", "as", "in", "AdaBoost", ",", "LogitBoost", "and", "all", "members", "of", "the", "AnyBoost", "family", "of", "algorithms", ")", ",", "examples", "with", "higher", "margins", "will", "receive", "less", "(", "or", "the", "same", ")", "weighting", "than", "those", "with", "lower", "margins", "."], "sentence-detokenized": "When convex loss is used (as in AdaBoost, LogitBoost and all members of the AnyBoost family of algorithms), examples with higher margins will receive less (or the same) weighting than those with lower margins.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 19], [20, 24], [25, 26], [26, 28], [29, 31], [32, 40], [40, 41], [42, 52], [53, 56], [57, 60], [61, 68], [69, 71], [72, 75], [76, 84], [85, 91], [92, 94], [95, 105], [105, 106], [106, 107], [108, 116], [117, 121], [122, 128], [129, 136], [137, 141], [142, 149], [150, 154], [155, 156], [156, 158], [159, 162], [163, 167], [167, 168], [169, 178], [179, 183], [184, 189], [190, 194], [195, 200], [201, 208], [208, 209]]}
{"doc_key": "ai-dev-279", "ner": [[0, 1, "researcher"], [7, 8, "researcher"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sepp", "Hochreiter", "'s", "graduation", "thesis", "in", "1991", "Sepp", "Hochreiter", "."], "sentence-detokenized": "Sepp Hochreiter's graduation thesis in 1991 Sepp Hochreiter.", "token2charspan": [[0, 4], [5, 15], [15, 17], [18, 28], [29, 35], [36, 38], [39, 43], [44, 48], [49, 59], [59, 60]]}
{"doc_key": "ai-dev-280", "ner": [[4, 7, "algorithm"], [14, 14, "algorithm"], [18, 18, "algorithm"], [17, 21, "algorithm"], [26, 28, "algorithm"], [31, 32, "algorithm"]], "ner_mapping_to_source": [1, 3, 4, 5, 6, 7], "relations": [[18, 18, 26, 28, "related-to", "", true, false], [17, 21, 18, 18, "named", "", false, false]], "relations_mapping_to_source": [2, 3], "sentence": ["Typical", "discriminant", "models", "include", "logistic", "regression", "(", "LR", ")", ",", "support", "vector", "machines", "(", "SVM", ")", ",", "conditional", "random", "fields", "(", "CRF", ")", "(", "specified", "on", "an", "undirected", "graph", ")", ",", "decision", "trees", "and", "neural", "networks", "."], "sentence-detokenized": "Typical discriminant models include logistic regression (LR), support vector machines (SVM), conditional random fields (CRF) (specified on an undirected graph), decision trees and neural networks.", "token2charspan": [[0, 7], [8, 20], [21, 27], [28, 35], [36, 44], [45, 55], [56, 57], [57, 59], [59, 60], [60, 61], [62, 69], [70, 76], [77, 85], [86, 87], [87, 90], [90, 91], [91, 92], [93, 104], [105, 111], [112, 118], [119, 120], [120, 123], [123, 124], [125, 126], [126, 135], [136, 138], [139, 141], [142, 152], [153, 158], [158, 159], [159, 160], [161, 169], [170, 175], [176, 179], [180, 186], [187, 195], [195, 196]]}
{"doc_key": "ai-dev-281", "ner": [[11, 13, "metrics"], [28, 33, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "then", "possible", "to", "use", "this", "probability", "to", "evaluate", "the", "mean", "squared", "error", "(", "or", "similar", "measure", ")", "between", "the", "probability", "and", "the", "actual", "value", ",", "and", "combine", "this", "with", "a", "confusion", "matrix", "to", "create", "a", "very", "efficient", "fitness", "function", "for", "logistic", "regression", "."], "sentence-detokenized": "It is then possible to use this probability to evaluate the mean squared error (or similar measure) between the probability and the actual value, and combine this with a confusion matrix to create a very efficient fitness function for logistic regression.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 19], [20, 22], [23, 26], [27, 31], [32, 43], [44, 46], [47, 55], [56, 59], [60, 64], [65, 72], [73, 78], [79, 80], [80, 82], [83, 90], [91, 98], [98, 99], [100, 107], [108, 111], [112, 123], [124, 127], [128, 131], [132, 138], [139, 144], [144, 145], [146, 149], [150, 157], [158, 162], [163, 167], [168, 169], [170, 179], [180, 186], [187, 189], [190, 196], [197, 198], [199, 203], [204, 213], [214, 221], [222, 230], [231, 234], [235, 243], [244, 254], [254, 255]]}
{"doc_key": "ai-dev-282", "ner": [[0, 0, "product"], [5, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VoiceOver", "was", "first", "implemented", "in", "Mac", "OS", "X", "Tiger", "(", "10.4", ")", "in", "2005", "."], "sentence-detokenized": "VoiceOver was first implemented in Mac OS X Tiger (10.4) in 2005.", "token2charspan": [[0, 9], [10, 13], [14, 19], [20, 31], [32, 34], [35, 38], [39, 41], [42, 43], [44, 49], [50, 51], [51, 55], [55, 56], [57, 59], [60, 64], [64, 65]]}
{"doc_key": "ai-dev-283", "ner": [[11, 13, "algorithm"], [18, 19, "misc"], [9, 36, "metrics"], [25, 31, "algorithm"], [54, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 13, 18, 19, "related-to", "applied_to", false, false], [9, 36, 18, 19, "type-of", "", false, false], [9, 36, 25, 31, "related-to", "used_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "practice", ",", "machine", "learning", "algorithms", "have", "responded", "by", "either", "adopting", "convex", "approximations", "of", "the", "0", "-", "1", "loss", "function", "(", "e.g.", "hinge", "loss", "in", "support", "vector", "machines", ")", ",", "which", "are", "easier", "to", "optimise", ",", "or", "by", "imposing", "assumptions", "on", "the", "distribution", "mathP", "(", "x", ",", "y", ")", "/", "math", "(", "thus", "quitting", "agnostic", "learning", "algorithms", "where", "the", "above", "results", "apply", ")", ".", "(", "i.e.", "the", "above", "results", "apply", ")", "."], "sentence-detokenized": "In practice, machine learning algorithms have responded by either adopting convex approximations of the 0-1 loss function (e.g. hinge loss in support vector machines), which are easier to optimise, or by imposing assumptions on the distribution mathP (x, y) / math (thus quitting agnostic learning algorithms where the above results apply). (i.e. the above results apply).", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 20], [21, 29], [30, 40], [41, 45], [46, 55], [56, 58], [59, 65], [66, 74], [75, 81], [82, 96], [97, 99], [100, 103], [104, 105], [105, 106], [106, 107], [108, 112], [113, 121], [122, 123], [123, 127], [128, 133], [134, 138], [139, 141], [142, 149], [150, 156], [157, 165], [165, 166], [166, 167], [168, 173], [174, 177], [178, 184], [185, 187], [188, 196], [196, 197], [198, 200], [201, 203], [204, 212], [213, 224], [225, 227], [228, 231], [232, 244], [245, 250], [251, 252], [252, 253], [253, 254], [255, 256], [256, 257], [258, 259], [260, 264], [265, 266], [266, 270], [271, 279], [280, 288], [289, 297], [298, 308], [309, 314], [315, 318], [319, 324], [325, 332], [333, 338], [338, 339], [339, 340], [341, 342], [342, 346], [347, 350], [351, 356], [357, 364], [365, 370], [370, 371], [371, 372]]}
{"doc_key": "ai-dev-284", "ner": [[0, 0, "misc"], [11, 14, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 11, 14, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Westworld", "(", "1973", ")", "was", "the", "first", "feature", "film", "to", "use", "digital", "image", "processing", "on", "photographs", "to", "simulate", "an", "android", "perspective", "."], "sentence-detokenized": "Westworld (1973) was the first feature film to use digital image processing on photographs to simulate an android perspective.", "token2charspan": [[0, 9], [10, 11], [11, 15], [15, 16], [17, 20], [21, 24], [25, 30], [31, 38], [39, 43], [44, 46], [47, 50], [51, 58], [59, 64], [65, 75], [76, 78], [79, 90], [91, 93], [94, 102], [103, 105], [106, 113], [114, 125], [125, 126]]}
{"doc_key": "ai-dev-285", "ner": [[6, 7, "task"], [9, 10, "task"], [12, 13, "task"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "now", "often", "used", "for", "speech", "recognition", ",", "speech", "synthesis", ",", "diary", "writing", ",", "Xavier", "Anguera", "et", "al", "."], "sentence-detokenized": "It is now often used for speech recognition, speech synthesis, diary writing, Xavier Anguera et al.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 15], [16, 20], [21, 24], [25, 31], [32, 43], [43, 44], [45, 51], [52, 61], [61, 62], [63, 68], [69, 76], [76, 77], [78, 84], [85, 92], [93, 95], [96, 98], [98, 99]]}
{"doc_key": "ai-dev-286", "ner": [[6, 12, "algorithm"], [17, 17, "algorithm"], [13, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 17, 6, 12, "type-of", "", false, false], [13, 23, 6, 12, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["where", "math", "\u03c3", "/", "math", "is", "the", "activation", "function", "of", "an", "elemental", "unit", ",", "such", "as", "a", "sigmoid", "function", "or", "a", "rectified", "linear", "unit", "."], "sentence-detokenized": "where math \u03c3 / math is the activation function of an elemental unit, such as a sigmoid function or a rectified linear unit.", "token2charspan": [[0, 5], [6, 10], [11, 12], [13, 14], [15, 19], [20, 22], [23, 26], [27, 37], [38, 46], [47, 49], [50, 52], [53, 62], [63, 67], [67, 68], [69, 73], [74, 76], [77, 78], [79, 86], [87, 95], [96, 98], [99, 100], [101, 110], [111, 117], [118, 122], [122, 123]]}
{"doc_key": "ai-dev-287", "ner": [[5, 5, "algorithm"], [13, 13, "misc"], [16, 17, "misc"], [14, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "speech", "-", "based", "(", "hidden", "Markov", "model", "-", "based", ")", "approaches", "require", "pronunciation", "models", ",", "acoustic", "models", "and", "language", "models", "to", "be", "constructed", "and", "trained", "separately", "."], "sentence-detokenized": "Traditional speech-based (hidden Markov model-based) approaches require pronunciation models, acoustic models and language models to be constructed and trained separately.", "token2charspan": [[0, 11], [12, 18], [18, 19], [19, 24], [25, 26], [26, 32], [33, 39], [40, 45], [45, 46], [46, 51], [51, 52], [53, 63], [64, 71], [72, 85], [86, 92], [92, 93], [94, 102], [103, 109], [110, 113], [114, 122], [123, 129], [130, 132], [133, 135], [136, 147], [148, 151], [152, 159], [160, 170], [170, 171]]}
{"doc_key": "ai-dev-288", "ner": [[0, 2, "algorithm"], [9, 9, "field"], [12, 13, "field"], [6, 8, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 6, 8, "related-to", "used_for", false, false], [9, 9, 0, 2, "usage", "", false, false], [12, 13, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Roberts", "cross", "operators", "are", "used", "for", "edge", "detection", "in", "image", "processing", "and", "computer", "vision", "."], "sentence-detokenized": "Roberts cross operators are used for edge detection in image processing and computer vision.", "token2charspan": [[0, 7], [8, 13], [14, 23], [24, 27], [28, 32], [33, 36], [37, 41], [42, 51], [52, 54], [55, 60], [61, 71], [72, 75], [76, 84], [85, 91], [91, 92]]}
{"doc_key": "ai-dev-289", "ner": [[2, 2, "metrics"], [18, 24, "metrics"]], "ner_mapping_to_source": [1, 2], "relations": [[2, 2, 18, 24, "opposite", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Sensitivity", "and", "specificity", "values", "are", "independent", "of", "the", "proportion", "of", "positive", "cases", "in", "the", "target", "population", "(", "as", "opposed", "to", ",", "for", "example", ",", "accuracy", ")", "."], "sentence-detokenized": "Sensitivity and specificity values are independent of the proportion of positive cases in the target population (as opposed to, for example, accuracy).", "token2charspan": [[0, 11], [12, 15], [16, 27], [28, 34], [35, 38], [39, 50], [51, 53], [54, 57], [58, 68], [69, 71], [72, 80], [81, 86], [87, 89], [90, 93], [94, 100], [101, 111], [112, 113], [113, 115], [116, 123], [124, 126], [126, 127], [128, 131], [132, 139], [139, 140], [141, 149], [149, 150], [150, 151]]}
{"doc_key": "ai-dev-290", "ner": [[3, 7, "algorithm"], [19, 19, "misc"], [13, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[19, 19, 3, 7, "topic", "", false, false], [19, 19, 13, 14, "artifact", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["However", ",", "the", "perceptron", "model", "was", "brought", "into", "great", "disrepute", "by", "Minsky", "and", "Papert", "'s", "1969", "book", ",", "The", "Perceptron", "."], "sentence-detokenized": "However, the perceptron model was brought into great disrepute by Minsky and Papert's 1969 book, The Perceptron.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 23], [24, 29], [30, 33], [34, 41], [42, 46], [47, 52], [53, 62], [63, 65], [66, 72], [73, 76], [77, 83], [83, 85], [86, 90], [91, 95], [95, 96], [97, 100], [101, 111], [111, 112]]}
{"doc_key": "ai-dev-291", "ner": [[3, 5, "conference"], [0, 1, "organisation"], [16, 20, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 16, 20, "topic", "", false, false], [0, 1, 3, 5, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["NIST", "'s", "annual", "Document", "Understanding", "Conference", "develops", "high", "-", "level", "evaluation", "criteria", "for", "techniques", "that", "challenge", "the", "summarisation", "of", "multiple", "documents", "."], "sentence-detokenized": "NIST's annual Document Understanding Conference develops high-level evaluation criteria for techniques that challenge the summarisation of multiple documents.", "token2charspan": [[0, 4], [4, 6], [7, 13], [14, 22], [23, 36], [37, 47], [48, 56], [57, 61], [61, 62], [62, 67], [68, 78], [79, 87], [88, 91], [92, 102], [103, 107], [108, 117], [118, 121], [122, 135], [136, 138], [139, 147], [148, 157], [157, 158]]}
{"doc_key": "ai-dev-292", "ner": [[0, 2, "product"], [19, 20, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 19, 20, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Parallel", "manipulators", "are", "designed", "to", "be", "shorter", ",", "simpler", "and", "more", "rigid", "against", "unwanted", "movement", "in", "each", "chain", "than", "serial", "manipulators", "."], "sentence-detokenized": "Parallel manipulators are designed to be shorter, simpler and more rigid against unwanted movement in each chain than serial manipulators.", "token2charspan": [[0, 8], [9, 21], [22, 25], [26, 34], [35, 37], [38, 40], [41, 48], [48, 49], [50, 57], [58, 61], [62, 66], [67, 72], [73, 80], [81, 89], [90, 98], [99, 101], [102, 106], [107, 112], [113, 117], [118, 124], [125, 137], [137, 138]]}
{"doc_key": "ai-dev-293", "ner": [[15, 15, "misc"], [17, 17, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Manipulators", "move", "the", "robot", ",", "but", "their", "designs", "fall", "into", "general", "types", ",", "such", "as", "scalar", "and", "Cartesian", "co-ordinate", "types", ",", "which", "direct", "the", "arms", "of", "the", "machine", "in", "different", "co-ordinate", "systems", "."], "sentence-detokenized": "Manipulators move the robot, but their designs fall into general types, such as scalar and Cartesian co-ordinate types, which direct the arms of the machine in different co-ordinate systems.", "token2charspan": [[0, 12], [13, 17], [18, 21], [22, 27], [27, 28], [29, 32], [33, 38], [39, 46], [47, 51], [52, 56], [57, 64], [65, 70], [70, 71], [72, 76], [77, 79], [80, 86], [87, 90], [91, 100], [101, 112], [113, 118], [118, 119], [120, 125], [126, 132], [133, 136], [137, 141], [142, 144], [145, 148], [149, 156], [157, 159], [160, 169], [170, 181], [182, 189], [189, 190]]}
{"doc_key": "ai-dev-294", "ner": [[10, 13, "organisation"], [16, 23, "organisation"], [24, 40, "organisation"], [25, 33, "organisation"], [34, 39, "organisation"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "USA", ",", "he", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Philological", "Association", ",", "the", "American", "Philosophical", "Society", "and", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In the USA, he is a member of the National Academy of Sciences, the American Academy of Arts and Sciences, the American Philological Association, the American Philosophical Society and the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 6], [7, 10], [10, 11], [12, 14], [15, 17], [18, 19], [20, 26], [27, 29], [30, 33], [34, 42], [43, 50], [51, 53], [54, 62], [62, 63], [64, 67], [68, 76], [77, 84], [85, 87], [88, 92], [93, 96], [97, 105], [105, 106], [107, 110], [111, 119], [120, 132], [133, 144], [144, 145], [146, 149], [150, 158], [159, 172], [173, 180], [181, 184], [185, 188], [189, 197], [198, 209], [210, 213], [214, 217], [218, 229], [230, 232], [233, 240], [240, 241]]}
{"doc_key": "ai-dev-295", "ner": [[0, 8, "algorithm"], [22, 25, "algorithm"], [26, 30, "task"]], "ner_mapping_to_source": [1, 3, 4], "relations": [[22, 25, 26, 30, "related-to", "performs", false, false]], "relations_mapping_to_source": [4], "sentence": ["Support", "Vector", "Machines", "(", "SVMs", ")", "came", "into", "the", "limelight", "in", "the", "1990s", "when", "they", "became", "popular", "and", "were", "found", "to", "compete", "with", "neural", "networks", "in", "tasks", "such", "as", "handwriting", "recognition", "."], "sentence-detokenized": "Support Vector Machines (SVMs) came into the limelight in the 1990s when they became popular and were found to compete with neural networks in tasks such as handwriting recognition.", "token2charspan": [[0, 7], [8, 14], [15, 23], [24, 25], [25, 29], [29, 30], [31, 35], [36, 40], [41, 44], [45, 54], [55, 57], [58, 61], [62, 67], [68, 72], [73, 77], [78, 84], [85, 92], [93, 96], [97, 101], [102, 107], [108, 110], [111, 118], [119, 123], [124, 130], [131, 139], [140, 142], [143, 148], [149, 153], [154, 156], [157, 168], [169, 180], [180, 181]]}
{"doc_key": "ai-dev-296", "ner": [[2, 4, "misc"], [9, 9, "misc"], [12, 14, "algorithm"], [22, 23, "misc"], [26, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 9, 9, "usage", "", false, false], [2, 4, 22, 23, "usage", "", false, false], [9, 9, 12, 14, "origin", "result_of_algorithm", false, false], [22, 23, 26, 27, "origin", "result_of_algorithm", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "empirical", "whitening", "transformation", "is", "obtained", "by", "estimating", "the", "covariances", "(", "e.g.", "maximum", "likelihood", "method", ")", "and", "then", "constructing", "the", "corresponding", "estimated", "whitening", "matrix", "(", "e.g.", "Cholesky", "decomposition", ")", "."], "sentence-detokenized": "The empirical whitening transformation is obtained by estimating the covariances (e.g. maximum likelihood method) and then constructing the corresponding estimated whitening matrix (e.g. Cholesky decomposition).", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 38], [39, 41], [42, 50], [51, 53], [54, 64], [65, 68], [69, 80], [81, 82], [82, 86], [87, 94], [95, 105], [106, 112], [112, 113], [114, 117], [118, 122], [123, 135], [136, 139], [140, 153], [154, 163], [164, 173], [174, 180], [181, 182], [182, 186], [187, 195], [196, 209], [209, 210], [210, 211]]}
{"doc_key": "ai-dev-297", "ner": [[0, 2, "organisation"], [8, 9, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 0, 2, "artifact", "", false, false], [23, 23, 0, 2, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["IAI", "is", "the", "world", "'s", "largest", "manufacturer", "of", "Cartesian", "co-ordinate", "robots", "and", "an", "established", "leader", "in", "low", "-", "cost", ",", "high", "-", "performance", "SCARA", "robots", "."], "sentence-detokenized": "IAI is the world's largest manufacturer of Cartesian co-ordinate robots and an established leader in low-cost, high-performance SCARA robots.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [16, 18], [19, 26], [27, 39], [40, 42], [43, 52], [53, 64], [65, 71], [72, 75], [76, 78], [79, 90], [91, 97], [98, 100], [101, 104], [104, 105], [105, 109], [109, 110], [111, 115], [115, 116], [116, 127], [128, 133], [134, 140], [140, 141]]}
{"doc_key": "ai-dev-298", "ner": [[7, 8, "field"], [10, 11, "field"], [13, 14, "field"], [16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 25, "field"], [27, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["Formal", "concept", "analysis", "has", "practical", "applications", "in", "data", "mining", ",", "text", "mining", ",", "machine", "learning", ",", "knowledge", "management", ",", "semantic", "web", ",", "software", "development", ",", "chemistry", "and", "biology", "."], "sentence-detokenized": "Formal concept analysis has practical applications in data mining, text mining, machine learning, knowledge management, semantic web, software development, chemistry and biology.", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 27], [28, 37], [38, 50], [51, 53], [54, 58], [59, 65], [65, 66], [67, 71], [72, 78], [78, 79], [80, 87], [88, 96], [96, 97], [98, 107], [108, 118], [118, 119], [120, 128], [129, 132], [132, 133], [134, 142], [143, 154], [154, 155], [156, 165], [166, 169], [170, 177], [177, 178]]}
{"doc_key": "ai-dev-299", "ner": [[0, 2, "field"], [4, 6, "field"], [10, 11, "field"], [16, 19, "field"], [26, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 16, 19, "part-of", "", false, false], [4, 6, 26, 27, "topic", "", false, false], [10, 11, 4, 6, "named", "", false, false], [16, 19, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", ",", "computational", "learning", "theory", "(", "or", "simply", "learning", "theory", ")", "is", "a", "subfield", "of", "artificial", "intelligence", "that", "studies", "the", "design", "and", "analysis", "of", "machine", "learning", "algorithms", "."], "sentence-detokenized": "In computer science, computational learning theory (or simply learning theory) is a subfield of artificial intelligence that studies the design and analysis of machine learning algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 34], [35, 43], [44, 50], [51, 52], [52, 54], [55, 61], [62, 70], [71, 77], [77, 78], [79, 81], [82, 83], [84, 92], [93, 95], [96, 106], [107, 119], [120, 124], [125, 132], [133, 136], [137, 143], [144, 147], [148, 156], [157, 159], [160, 167], [168, 176], [177, 187], [187, 188]]}
{"doc_key": "ai-dev-300", "ner": [[0, 5, "algorithm"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Collaborative", "filtering", "(", "CF", ")", "is", "a", "technique", "used", "in", "recommender", "systems", "."], "sentence-detokenized": "Collaborative filtering (CF) is a technique used in recommender systems.", "token2charspan": [[0, 13], [14, 23], [24, 25], [25, 27], [27, 28], [29, 31], [32, 33], [34, 43], [44, 48], [49, 51], [52, 63], [64, 71], [71, 72]]}
{"doc_key": "ai-dev-301", "ner": [[0, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "false", "positive", "rate", "is", "the", "proportion", "of", "all", "negatives", "that", "result", "in", "a", "positive", "test", "result", ",", "i.e.", "the", "conditional", "probability", "of", "a", "positive", "test", "result", "given", "an", "event", "that", "did", "not", "exist", "."], "sentence-detokenized": "The false positive rate is the proportion of all negatives that result in a positive test result, i.e. the conditional probability of a positive test result given an event that did not exist.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 23], [24, 26], [27, 30], [31, 41], [42, 44], [45, 48], [49, 58], [59, 63], [64, 70], [71, 73], [74, 75], [76, 84], [85, 89], [90, 96], [96, 97], [98, 102], [103, 106], [107, 118], [119, 130], [131, 133], [134, 135], [136, 144], [145, 149], [150, 156], [157, 162], [163, 165], [166, 171], [172, 176], [177, 180], [181, 184], [185, 190], [190, 191]]}
{"doc_key": "ai-dev-302", "ner": [[0, 15, "misc"], [58, 62, "metrics"], [37, 63, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 15, 58, 62, "topic", "", false, false], [0, 15, 37, 63, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "VLDB", "'", "8", ":", "Proceedings", "of", "the", "34th", "International", "Conference", "on", "Very", "Large", "Data", "Bases", ",", "pages", "422--433", ",", "the", "values", "given", "for", "mathC", "/", "math", "and", "mathK", "/", "math", "were", "generally", "used", "to", "calculate", "iteratively", "SimRank", "scores", ",", "and", "that", "the", "values", "given", "for", "mathC", "/", "math", "and", "mathK", "/", "math", "generally", "imply", "a", "relatively", "low", "accuracy", "of", "the", "iteratively", "calculated", "SimRank", "scores", "."], "sentence-detokenized": "In VLDB '8: Proceedings of the 34th International Conference on Very Large Data Bases, pages 422--433, the values given for mathC / math and mathK / math were generally used to calculate iteratively SimRank scores, and that the values given for mathC / math and mathK / math generally imply a relatively low accuracy of the iteratively calculated SimRank scores.", "token2charspan": [[0, 2], [3, 7], [8, 9], [9, 10], [10, 11], [12, 23], [24, 26], [27, 30], [31, 35], [36, 49], [50, 60], [61, 63], [64, 68], [69, 74], [75, 79], [80, 85], [85, 86], [87, 92], [93, 101], [101, 102], [103, 106], [107, 113], [114, 119], [120, 123], [124, 129], [130, 131], [132, 136], [137, 140], [141, 146], [147, 148], [149, 153], [154, 158], [159, 168], [169, 173], [174, 176], [177, 186], [187, 198], [199, 206], [207, 213], [213, 214], [215, 218], [219, 223], [224, 227], [228, 234], [235, 240], [241, 244], [245, 250], [251, 252], [253, 257], [258, 261], [262, 267], [268, 269], [270, 274], [275, 284], [285, 290], [291, 292], [293, 303], [304, 307], [308, 316], [317, 319], [320, 323], [324, 335], [336, 346], [347, 354], [355, 361], [361, 362]]}
{"doc_key": "ai-dev-303", "ner": [[0, 4, "misc"], [5, 7, "misc"], [18, 18, "person"], [21, 23, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 7, 0, 4, "general-affiliation", "", false, false], [5, 7, 18, 18, "artifact", "", false, false], [5, 7, 21, 23, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "sci", "-", "fi", "drama", "Sense8", ",", "which", "debuted", "in", "June", "2015", ",", "is", "written", "and", "produced", "by", "The", "Wachowskis", "and", "J", "Michael", "Straczynski", "."], "sentence-detokenized": "The sci-fi drama Sense8, which debuted in June 2015, is written and produced by The Wachowskis and J Michael Straczynski.", "token2charspan": [[0, 3], [4, 7], [7, 8], [8, 10], [11, 16], [17, 23], [23, 24], [25, 30], [31, 38], [39, 41], [42, 46], [47, 51], [51, 52], [53, 55], [56, 63], [64, 67], [68, 76], [77, 79], [80, 83], [84, 94], [95, 98], [99, 100], [101, 108], [109, 120], [120, 121]]}
{"doc_key": "ai-dev-304", "ner": [[1, 1, "misc"], [6, 7, "product"], [25, 27, "misc"], [35, 35, "country"], [37, 37, "country"], [39, 39, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 1, 6, 7, "topic", "", false, false], [35, 35, 25, 27, "type-of", "", false, false], [37, 37, 25, 27, "type-of", "", false, false], [39, 39, 25, 27, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Although", "Eurotra", "never", "provided", "a", "practical", "MT", "system", ",", "the", "project", "had", "a", "significant", "long", "-", "term", "impact", "on", "the", "emerging", "language", "industries", "of", "the", "European", "Member", "States", ",", "particularly", "in", "the", "southern", "countries", "of", "Greece", ",", "Italy", ",", "Spain", "and", "Portugal", "."], "sentence-detokenized": "Although Eurotra never provided a practical MT system, the project had a significant long-term impact on the emerging language industries of the European Member States, particularly in the southern countries of Greece, Italy, Spain and Portugal.", "token2charspan": [[0, 8], [9, 16], [17, 22], [23, 31], [32, 33], [34, 43], [44, 46], [47, 53], [53, 54], [55, 58], [59, 66], [67, 70], [71, 72], [73, 84], [85, 89], [89, 90], [90, 94], [95, 101], [102, 104], [105, 108], [109, 117], [118, 126], [127, 137], [138, 140], [141, 144], [145, 153], [154, 160], [161, 167], [167, 168], [169, 181], [182, 184], [185, 188], [189, 197], [198, 207], [208, 210], [211, 217], [217, 218], [219, 224], [224, 225], [226, 231], [232, 235], [236, 244], [244, 245]]}
{"doc_key": "ai-dev-305", "ner": [[0, 0, "algorithm"], [6, 8, "task"], [13, 20, "task"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[6, 8, 0, 0, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Autoencoders", "have", "been", "successfully", "applied", "to", "machine", "translation", "of", "human", "language", ",", "usually", "referred", "to", "as", "neural", "machine", "translation", "(", "NMT", ")", "."], "sentence-detokenized": "Autoencoders have been successfully applied to machine translation of human language, usually referred to as neural machine translation (NMT).", "token2charspan": [[0, 12], [13, 17], [18, 22], [23, 35], [36, 43], [44, 46], [47, 54], [55, 66], [67, 69], [70, 75], [76, 84], [84, 85], [86, 93], [94, 102], [103, 105], [106, 108], [109, 115], [116, 123], [124, 135], [136, 137], [137, 140], [140, 141], [141, 142]]}
{"doc_key": "ai-dev-306", "ner": [[9, 10, "metrics"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "examples", "of", "probability", "-", "based", "fitness", "functions", "include", "maximum", "likelihood", "estimation", "and", "hinge", "loss", "."], "sentence-detokenized": "Typical examples of probability-based fitness functions include maximum likelihood estimation and hinge loss.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 31], [31, 32], [32, 37], [38, 45], [46, 55], [56, 63], [64, 71], [72, 82], [83, 93], [94, 97], [98, 103], [104, 108], [108, 109]]}
{"doc_key": "ai-dev-307", "ner": [[0, 1, "field"], [7, 11, "task"], [12, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 11, 0, 1, "part-of", "", false, false], [12, 14, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Data", "mining", "is", "a", "related", "field", "that", "focuses", "on", "exploratory", "data", "analysis", "through", "unsupervised", "learning", "."], "sentence-detokenized": "Data mining is a related field that focuses on exploratory data analysis through unsupervised learning.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 16], [17, 24], [25, 30], [31, 35], [36, 43], [44, 46], [47, 58], [59, 63], [64, 72], [73, 80], [81, 93], [94, 102], [102, 103]]}
{"doc_key": "ai-dev-308", "ner": [[0, 2, "algorithm"], [12, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 12, 15, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "filtering", "is", "a", "technique", "that", "matches", "people", "with", "similar", "interests", "and", "builds", "a", "recommendation", "system", "on", "this", "basis", "."], "sentence-detokenized": "Collaborative filtering is a technique that matches people with similar interests and builds a recommendation system on this basis.", "token2charspan": [[0, 13], [14, 23], [24, 26], [27, 28], [29, 38], [39, 43], [44, 51], [52, 58], [59, 63], [64, 71], [72, 81], [82, 85], [86, 92], [93, 94], [95, 109], [110, 116], [117, 119], [120, 124], [125, 130], [130, 131]]}
{"doc_key": "ai-dev-309", "ner": [[3, 10, "algorithm"], [14, 14, "programlang"], [16, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 20, 3, 10, "type-of", "", false, false], [16, 20, 14, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "number", "of", "word", "similarity", "algorithms", "based", "on", "Word", "Net", "are", "implemented", "in", "a", "Perl", "package", "called", "WordNet", ":", ":", "Similarity", "."], "sentence-detokenized": "A number of word similarity algorithms based on WordNet are implemented in a Perl package called WordNet:: Similarity.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 16], [17, 27], [28, 38], [39, 44], [45, 47], [48, 52], [52, 55], [56, 59], [60, 71], [72, 74], [75, 76], [77, 81], [82, 89], [90, 96], [97, 104], [104, 105], [105, 106], [107, 117], [117, 118]]}
{"doc_key": "ai-dev-310", "ner": [[16, 18, "conference"], [7, 8, "researcher"], [10, 11, "researcher"], [13, 15, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "also", "covers", "the", "paper", "presented", "by", "Erik", "Miller", ",", "Nicholas", "Matsakis", "and", "Paul", "Viola", "at", "CVPR", "(", "CVPR", ")", "2000", "."], "sentence-detokenized": "It also covers the paper presented by Erik Miller, Nicholas Matsakis and Paul Viola at CVPR (CVPR) 2000.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 18], [19, 24], [25, 34], [35, 37], [38, 42], [43, 49], [49, 50], [51, 59], [60, 68], [69, 72], [73, 77], [78, 83], [84, 86], [87, 91], [92, 93], [93, 97], [97, 98], [99, 103], [103, 104]]}
{"doc_key": "ai-dev-311", "ner": [[0, 1, "algorithm"], [2, 19, "misc"], [20, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 20, 21, "compare", "", false, false], [20, 21, 2, 19, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["QC", "has", "not", "been", "compared", "with", "previous", "state", "-", "of", "-", "the", "-", "art", "clustering", "algorithms", ",", "except", "for", "the", "Jaccard", "indicator", "."], "sentence-detokenized": "QC has not been compared with previous state-of-the-art clustering algorithms, except for the Jaccard indicator.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 15], [16, 24], [25, 29], [30, 38], [39, 44], [44, 45], [45, 47], [47, 48], [48, 51], [51, 52], [52, 55], [56, 66], [67, 77], [77, 78], [79, 85], [86, 89], [90, 93], [94, 101], [102, 111], [111, 112]]}
{"doc_key": "ai-dev-312", "ner": [[0, 5, "misc"], [13, 17, "misc"], [7, 11, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 17, 0, 5, "physical", "", false, false], [13, 17, 7, 11, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "the", "VEX", "Robotics", "World", "Congress", ",", "Freedom", "Hall", "will", "host", "a", "'", "Parade", "of", "Nations", "'", "with", "hundreds", "of", "students", "from", "over", "30", "countries", "."], "sentence-detokenized": "During the VEX Robotics World Congress, Freedom Hall will host a 'Parade of Nations' with hundreds of students from over 30 countries.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 23], [24, 29], [30, 38], [38, 39], [40, 47], [48, 52], [53, 57], [58, 62], [63, 64], [65, 66], [66, 72], [73, 75], [76, 83], [83, 84], [85, 89], [90, 98], [99, 101], [102, 110], [111, 115], [116, 120], [121, 123], [124, 133], [133, 134]]}
{"doc_key": "ai-dev-313", "ner": [[8, 8, "metrics"], [5, 10, "metrics"], [16, 17, "metrics"], [13, 13, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 10, 8, 8, "named", "", false, false], [13, 13, 16, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Other", "indicators", "of", "accuracy", "include", "SWER", "(", "Single", "Word", "Error", "Rate", ")", "and", "CSR", "(", "Command", "Success", "Rate", ")", "."], "sentence-detokenized": "Other indicators of accuracy include SWER (Single Word Error Rate) and CSR (Command Success Rate).", "token2charspan": [[0, 5], [6, 16], [17, 19], [20, 28], [29, 36], [37, 41], [42, 43], [43, 49], [50, 54], [55, 60], [61, 65], [65, 66], [67, 70], [71, 74], [75, 76], [76, 83], [84, 91], [92, 96], [96, 97], [97, 98]]}
{"doc_key": "ai-dev-314", "ner": [[6, 8, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "presented", "their", "methods", "and", "results", "at", "SIGGRAPH", "2000", "."], "sentence-detokenized": "They presented their methods and results at SIGGRAPH 2000.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 28], [29, 32], [33, 40], [41, 43], [44, 52], [53, 57], [57, 58]]}
{"doc_key": "ai-dev-315", "ner": [[0, 5, "conference"], [7, 11, "misc"], [6, 37, "misc"], [12, 16, "conference"], [19, 31, "researcher"], [32, 34, "researcher"], [56, 58, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 5, 7, 11, "origin", "", false, false], [7, 11, 12, 16, "physical", "", false, false], [7, 11, 12, 16, "temporal", "", false, false], [7, 11, 19, 31, "origin", "", false, false], [7, 11, 32, 34, "origin", "", false, false], [6, 37, 7, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "KDD", "conference", "evolved", "from", "the", "Knowledge", "Discovery", "and", "Data", "(", "KDD", ")", "at", "the", "AAAI", "conference", "initiated", "by", "Gregory", "I", ".", "Piatetsky", "-", "Shapiro", "in", "1989", ",", "1991", "and", "1993", "and", "Usama", "Fayyad", "in", "1994", ".", "Mining", ")", "workshop", "at", "the", "AAAI", "conference", ",", "initiated", "by", "Gregory", "I", ".", "Piatetsky", "-", "Shapiro", "in", "1994", ".", "Machinery", "|", "ACM", "."], "sentence-detokenized": "The KDD conference evolved from the Knowledge Discovery and Data (KDD) at the AAAI conference initiated by Gregory I. Piatetsky-Shapiro in 1989, 1991 and 1993 and Usama Fayyad in 1994. Mining) workshop at the AAAI conference, initiated by Gregory I. Piatetsky-Shapiro in 1994. Machinery | ACM.", "token2charspan": [[0, 3], [4, 7], [8, 18], [19, 26], [27, 31], [32, 35], [36, 45], [46, 55], [56, 59], [60, 64], [65, 66], [66, 69], [69, 70], [71, 73], [74, 77], [78, 82], [83, 93], [94, 103], [104, 106], [107, 114], [115, 116], [116, 117], [118, 127], [127, 128], [128, 135], [136, 138], [139, 143], [143, 144], [145, 149], [150, 153], [154, 158], [159, 162], [163, 168], [169, 175], [176, 178], [179, 183], [183, 184], [185, 191], [191, 192], [193, 201], [202, 204], [205, 208], [209, 213], [214, 224], [224, 225], [226, 235], [236, 238], [239, 246], [247, 248], [248, 249], [250, 259], [259, 260], [260, 267], [268, 270], [271, 275], [275, 276], [277, 286], [287, 288], [289, 292], [292, 293]]}
{"doc_key": "ai-dev-316", "ner": [[8, 9, "conference"], [7, 11, "conference"], [15, 22, "organisation"], [26, 32, "conference"], [36, 41, "conference"], [51, 51, "conference"], [45, 53, "conference"], [59, 60, "conference"], [57, 62, "conference"]], "ner_mapping_to_source": [0, 1, 3, 5, 7, 8, 9, 10, 11], "relations": [[7, 11, 8, 9, "named", "", false, false], [45, 53, 51, 51, "named", "", false, false], [57, 62, 59, 60, "named", "", false, false]], "relations_mapping_to_source": [0, 4, 5], "sentence": ["He", "is", "an", "elected", "Fellow", "of", "the", "American", "Computer", "Society", "(", "ACM", ")", ",", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", ",", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", ",", "the", "Association", "for", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "(", "AAAS", ")", "and", "the", "Society", "for", "Photonic", "Technologies", "(", "SPIE", ")", "."], "sentence-detokenized": "He is an elected Fellow of the American Computer Society (ACM), the Institute of Electrical and Electronics Engineers (IEEE), the International Association for Pattern Recognition (IAPR), the Association for Artificial Intelligence (AAAI), the American Association for the Advancement of Science (AAAS) and the Society for Photonic Technologies (SPIE).", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 16], [17, 23], [24, 26], [27, 30], [31, 39], [40, 48], [49, 56], [57, 58], [58, 61], [61, 62], [62, 63], [64, 67], [68, 77], [78, 80], [81, 91], [92, 95], [96, 107], [108, 117], [118, 119], [119, 123], [123, 124], [124, 125], [126, 129], [130, 143], [144, 155], [156, 159], [160, 167], [168, 179], [180, 181], [181, 185], [185, 186], [186, 187], [188, 191], [192, 203], [204, 207], [208, 218], [219, 231], [232, 233], [233, 237], [237, 238], [238, 239], [240, 243], [244, 252], [253, 264], [265, 268], [269, 272], [273, 284], [285, 287], [288, 295], [296, 297], [297, 301], [301, 302], [303, 306], [307, 310], [311, 318], [319, 322], [323, 331], [332, 344], [345, 346], [346, 350], [350, 351], [351, 352]]}
{"doc_key": "ai-dev-317", "ner": [[0, 0, "field"], [3, 4, "field"], [16, 20, "field"], [31, 32, "field"], [50, 53, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 16, 20, "named", "", false, false], [3, 4, 31, 32, "named", "", false, false], [31, 32, 50, 53, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "learning", "and", "data", "mining", "often", "use", "the", "same", "methods", "and", "overlap", "significantly", ",", "but", "whereas", "machine", "learning", "focuses", "on", "making", "predictions", "based", "on", "known", "properties", "learned", "from", "training", "data", ",", "data", "mining", "focuses", "on", "discovering", "(", "previously", ")", "unknown", "properties", "in", "the", "data", "(", "this", "is", "analytical", "step", "of", "knowledge", "discovery", "in", "databases", ")", "."], "sentence-detokenized": "Machine learning and data mining often use the same methods and overlap significantly, but whereas machine learning focuses on making predictions based on known properties learned from training data, data mining focuses on discovering (previously) unknown properties in the data (this is analytical step of knowledge discovery in databases).", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 25], [26, 32], [33, 38], [39, 42], [43, 46], [47, 51], [52, 59], [60, 63], [64, 71], [72, 85], [85, 86], [87, 90], [91, 98], [99, 106], [107, 115], [116, 123], [124, 126], [127, 133], [134, 145], [146, 151], [152, 154], [155, 160], [161, 171], [172, 179], [180, 184], [185, 193], [194, 198], [198, 199], [200, 204], [205, 211], [212, 219], [220, 222], [223, 234], [235, 236], [236, 246], [246, 247], [248, 255], [256, 266], [267, 269], [270, 273], [274, 278], [279, 280], [280, 284], [285, 287], [288, 298], [299, 303], [304, 306], [307, 316], [317, 326], [327, 329], [330, 339], [339, 340], [340, 341]]}
{"doc_key": "ai-dev-318", "ner": [[4, 6, "programlang"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Indy", "is", "written", "in", "Java", "and", "runs", "on", "most", "modern", "operating", "systems", "."], "sentence-detokenized": "The Indy is written in Java and runs on most modern operating systems.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 19], [20, 22], [23, 27], [28, 31], [32, 36], [37, 39], [40, 44], [45, 51], [52, 61], [62, 69], [69, 70]]}
{"doc_key": "ai-dev-319", "ner": [[0, 0, "algorithm"], [13, 18, "algorithm"], [7, 11, "algorithm"]], "ner_mapping_to_source": [0, 2, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["NMF", ",", "like", "support", "vector", "machines", "(", "SVMs", ")", ",", "is", "a", "type", "of", "non-negative", "quadratic", "programming", "(", "NQP", ")", "."], "sentence-detokenized": "NMF, like support vector machines (SVMs), is a type of non-negative quadratic programming (NQP).", "token2charspan": [[0, 3], [3, 4], [5, 9], [10, 17], [18, 24], [25, 33], [34, 35], [35, 39], [39, 40], [40, 41], [42, 44], [45, 46], [47, 51], [52, 54], [55, 67], [68, 77], [78, 89], [90, 91], [91, 94], [94, 95], [95, 96]]}
{"doc_key": "ai-dev-320", "ner": [[2, 4, "misc"], [5, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 4, 5, 10, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["This", "method", "estimates", "conditional", "probabilities", "using", "a", "non-parametric", "maximum", "likelihood", "method", ",", "which", "allows"], "sentence-detokenized": "This method estimates conditional probabilities using a non-parametric maximum likelihood method, which allows", "token2charspan": [[0, 4], [5, 11], [12, 21], [22, 33], [34, 47], [48, 53], [54, 55], [56, 70], [71, 78], [79, 89], [90, 96], [96, 97], [98, 103], [104, 110]]}
{"doc_key": "ai-dev-321", "ner": [[7, 7, "algorithm"], [9, 11, "algorithm"], [13, 15, "metrics"], [6, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Basic", "concepts", "involved", "in", "spectral", "estimation", "include", "autocorrelation", ",", "multidimensional", "Fourier", "transform", ",", "mean", "square", "error", "and", "entropy", "."], "sentence-detokenized": "Basic concepts involved in spectral estimation include autocorrelation, multidimensional Fourier transform, mean square error and entropy.", "token2charspan": [[0, 5], [6, 14], [15, 23], [24, 26], [27, 35], [36, 46], [47, 54], [55, 70], [70, 71], [72, 88], [89, 96], [97, 106], [106, 107], [108, 112], [113, 119], [120, 125], [126, 129], [130, 137], [137, 138]]}
{"doc_key": "ai-dev-322", "ner": [[0, 3, "algorithm"], [10, 10, "field"], [12, 12, "algorithm"], [14, 16, "algorithm"], [18, 19, "task"], [21, 21, "field"], [23, 23, "field"], [25, 26, "task"], [9, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 3, 10, 10, "part-of", "", false, false], [0, 3, 12, 12, "part-of", "", false, false], [0, 3, 14, 16, "part-of", "", false, false], [0, 3, 18, 19, "part-of", "", false, false], [0, 3, 21, 21, "part-of", "", false, false], [0, 3, 23, 23, "part-of", "", false, false], [0, 3, 25, 26, "part-of", "", false, false], [0, 3, 9, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Kernel", "methods", "have", "a", "wide", "range", "of", "applications", ",", "including", "geostatistics", ",", "kriging", ",", "inverse", "distance", "weighting", ",", "3D", "reconstruction", ",", "bioinformatics", ",", "cheminformatics", ",", "information", "extraction", "and", "handwriting", "recognition", "."], "sentence-detokenized": "Kernel methods have a wide range of applications, including geostatistics, kriging, inverse distance weighting, 3D reconstruction, bioinformatics, cheminformatics, information extraction and handwriting recognition.", "token2charspan": [[0, 6], [7, 14], [15, 19], [20, 21], [22, 26], [27, 32], [33, 35], [36, 48], [48, 49], [50, 59], [60, 73], [73, 74], [75, 82], [82, 83], [84, 91], [92, 100], [101, 110], [110, 111], [112, 114], [115, 129], [129, 130], [131, 145], [145, 146], [147, 162], [162, 163], [164, 175], [176, 186], [187, 190], [191, 202], [203, 214], [214, 215]]}
{"doc_key": "ai-dev-323", "ner": [[15, 15, "product"], [14, 20, "product"], [26, 29, "product"], [9, 31, "product"], [34, 34, "product"], [37, 38, "product"], [41, 43, "product"], [45, 47, "product"], [49, 52, "product"], [54, 56, "product"], [57, 65, "product"], [69, 72, "product"]], "ner_mapping_to_source": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[15, 15, 34, 34, "compare", "", false, false], [15, 15, 37, 38, "compare", "", false, false], [15, 15, 41, 43, "compare", "", false, false], [15, 15, 45, 47, "compare", "", false, false], [15, 15, 49, 52, "compare", "", false, false], [15, 15, 54, 56, "compare", "", false, false], [15, 15, 57, 65, "compare", "", false, false], [15, 15, 69, 72, "compare", "", false, false], [14, 20, 15, 15, "named", "", false, false], [26, 29, 34, 34, "compare", "", false, false], [26, 29, 37, 38, "compare", "", false, false], [26, 29, 41, 43, "compare", "", false, false], [26, 29, 45, 47, "compare", "", false, false], [26, 29, 49, 52, "compare", "", false, false], [26, 29, 54, 56, "compare", "", false, false], [26, 29, 57, 65, "compare", "", false, false], [26, 29, 69, 72, "compare", "", false, false], [9, 31, 26, 29, "named", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19], "sentence": ["Robots", "can", "be", "autonomous", "or", "semi-autonomous", ",", "ranging", "from", "humanoids", "such", "as", "Honda", "'s", "Advanced", "Step", "in", "Innovative", "Mobility", "(", "ASIMO", ")", "and", "TOSY", "'s", "TOSY", "Ping", "Pong", "Playing", "Robot", "(", "TOPIO", ")", "to", "industrial", "robots", ",", "medical", "surgery", "robots", ",", "patient", "assistance", "robots", ",", "dog", "therapy", "robots", ",", "group", "-programmed", "swarm", "robots", ",", "unmanned", "aerial", "vehicles", "such", "as", "the", "General", "Atomics", "MQ", "-", "1", "Predator", ",", "and", "even", "microscopic", "nano", "-", "robots", "."], "sentence-detokenized": "Robots can be autonomous or semi-autonomous, ranging from humanoids such as Honda's Advanced Step in Innovative Mobility (ASIMO) and TOSY's TOSY Ping Pong Playing Robot (TOPIO) to industrial robots, medical surgery robots, patient assistance robots, dog therapy robots, group-programmed swarm robots, unmanned aerial vehicles such as the General Atomics MQ-1 Predator, and even microscopic nano-robots.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 24], [25, 27], [28, 43], [43, 44], [45, 52], [53, 57], [58, 67], [68, 72], [73, 75], [76, 81], [81, 83], [84, 92], [93, 97], [98, 100], [101, 111], [112, 120], [121, 122], [122, 127], [127, 128], [129, 132], [133, 137], [137, 139], [140, 144], [145, 149], [150, 154], [155, 162], [163, 168], [169, 170], [170, 175], [175, 176], [177, 179], [180, 190], [191, 197], [197, 198], [199, 206], [207, 214], [215, 221], [221, 222], [223, 230], [231, 241], [242, 248], [248, 249], [250, 253], [254, 261], [262, 268], [268, 269], [270, 275], [275, 286], [287, 292], [293, 299], [299, 300], [301, 309], [310, 316], [317, 325], [326, 330], [331, 333], [334, 337], [338, 345], [346, 353], [354, 356], [356, 357], [357, 358], [359, 367], [367, 368], [369, 372], [373, 377], [378, 389], [390, 394], [394, 395], [395, 401], [401, 402]]}
{"doc_key": "ai-dev-324", "ner": [[2, 2, "product"], [19, 29, "university"], [8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [[2, 2, 8, 9, "artifact", "", false, false], [2, 2, 11, 12, "artifact", "", false, false], [2, 2, 14, 15, "artifact", "", false, false], [2, 2, 17, 18, "artifact", "", false, false], [8, 9, 19, 29, "physical", "", false, false], [11, 12, 19, 29, "physical", "", false, false], [14, 15, 19, 29, "physical", "", false, false], [17, 18, 19, 29, "physical", "", false, false]], "relations_mapping_to_source": [4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Freddy", "and", "Freddy", "II", "are", "robots", "built", "by", "Pat", "Ambler", ",", "Robin", "Popplestone", ",", "Austin", "Tait", "and", "Donald", "Michie", "at", "the", "University", "of", "Edinburgh", "'s", "School", "of", "Informatics", ",", "which", "can", "assemble", "wooden", "blocks", "in", "a", "matter", "of", "hours", "."], "sentence-detokenized": "Freddy and Freddy II are robots built by Pat Ambler, Robin Popplestone, Austin Tait and Donald Michie at the University of Edinburgh's School of Informatics, which can assemble wooden blocks in a matter of hours.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 20], [21, 24], [25, 31], [32, 37], [38, 40], [41, 44], [45, 51], [51, 52], [53, 58], [59, 70], [70, 71], [72, 78], [79, 83], [84, 87], [88, 94], [95, 101], [102, 104], [105, 108], [109, 119], [120, 122], [123, 132], [132, 134], [135, 141], [142, 144], [145, 156], [156, 157], [158, 163], [164, 167], [168, 176], [177, 183], [184, 190], [191, 193], [194, 195], [196, 202], [203, 205], [206, 211], [211, 212]]}
{"doc_key": "ai-dev-325", "ner": [[0, 5, "location"], [6, 10, "country"], [16, 18, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 5, 6, 10, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["She", "spent", "her", "childhood", "in", "Paris", ",", "France", ",", "with", "her", "parents", ",", "who", "emigrated", "from", "Lithuania", "in", "the", "early", "1920s", "."], "sentence-detokenized": "She spent her childhood in Paris, France, with her parents, who emigrated from Lithuania in the early 1920s.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 23], [24, 26], [27, 32], [32, 33], [34, 40], [40, 41], [42, 46], [47, 50], [51, 58], [58, 59], [60, 63], [64, 73], [74, 78], [79, 88], [89, 91], [92, 95], [96, 101], [102, 107], [107, 108]]}
{"doc_key": "ai-dev-326", "ner": [[0, 5, "misc"], [6, 10, "organisation"], [11, 20, "university"], [21, 25, "university"], [30, 30, "university"], [27, 36, "university"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [[0, 5, 6, 10, "part-of", "", false, false], [6, 10, 11, 20, "part-of", "", false, false], [30, 30, 21, 25, "part-of", "", false, false], [27, 36, 21, 25, "part-of", "", false, false]], "relations_mapping_to_source": [5, 6, 7, 8], "sentence": ["Cooper", "Siegel", "Associate", "Professor", "in", "the", "Department", "of", "Computer", "Science", "at", "Carnegie", "Mellon", "University", ",", "before", "becoming", "a", "professor", "at", "the", "Human", "-", "Computer", "Interaction", "Institute", "and", "teaching", "at", "the", "Robotics", "Institute", "and", "the", "Entertainment", "Technology", "Centre", "."], "sentence-detokenized": "Cooper Siegel Associate Professor in the Department of Computer Science at Carnegie Mellon University, before becoming a professor at the Human-Computer Interaction Institute and teaching at the Robotics Institute and the Entertainment Technology Centre.", "token2charspan": [[0, 6], [7, 13], [14, 23], [24, 33], [34, 36], [37, 40], [41, 51], [52, 54], [55, 63], [64, 71], [72, 74], [75, 83], [84, 90], [91, 101], [101, 102], [103, 109], [110, 118], [119, 120], [121, 130], [131, 133], [134, 137], [138, 143], [143, 144], [144, 152], [153, 164], [165, 174], [175, 178], [179, 187], [188, 190], [191, 194], [195, 203], [204, 213], [214, 217], [218, 221], [222, 235], [236, 246], [247, 253], [253, 254]]}
{"doc_key": "ai-dev-327", "ner": [[3, 5, "researcher"], [6, 6, "university"], [10, 13, "product"], [18, 22, "product"], [25, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 6, 6, "physical", "", false, false], [3, 5, 6, 6, "role", "", false, false], [10, 13, 3, 5, "artifact", "", false, false], [10, 13, 18, 22, "type-of", "", false, false], [10, 13, 25, 27, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1969", ",", "Victor", "Scheinman", "of", "Stanford", "University", "invented", "the", "Stanford", "Arm", ",", "an", "all", "-", "electric", ",", "six", "-", "axis", "articulated", "robot", "designed", "to", "enable", "arm", "solutions", "."], "sentence-detokenized": "In 1969, Victor Scheinman of Stanford University invented the Stanford Arm, an all-electric, six-axis articulated robot designed to enable arm solutions.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 25], [26, 28], [29, 37], [38, 48], [49, 57], [58, 61], [62, 70], [71, 74], [74, 75], [76, 78], [79, 82], [82, 83], [83, 91], [91, 92], [93, 96], [96, 97], [97, 101], [102, 113], [114, 119], [120, 128], [129, 131], [132, 138], [139, 142], [143, 152], [152, 153]]}
{"doc_key": "ai-dev-328", "ner": [[5, 5, "product"], [15, 15, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 15, 15, "related-to", "", false, false], [5, 5, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "creation", "and", "implementation", "of", "chatbots", "is", "still", "a", "developing", "field", ",", "largely", "related", "to", "artificial", "intelligence", "and", "machine", "learning", ".", "Therefore", ",", "while", "the", "solutions", "offered", "have", "obvious", "advantages", ",", "they", "also", "have", "some", "important", "limitations", "in", "terms", "of", "functionality", "and", "use", "cases", "."], "sentence-detokenized": "The creation and implementation of chatbots is still a developing field, largely related to artificial intelligence and machine learning. Therefore, while the solutions offered have obvious advantages, they also have some important limitations in terms of functionality and use cases.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 31], [32, 34], [35, 43], [44, 46], [47, 52], [53, 54], [55, 65], [66, 71], [71, 72], [73, 80], [81, 88], [89, 91], [92, 102], [103, 115], [116, 119], [120, 127], [128, 136], [136, 137], [138, 147], [147, 148], [149, 154], [155, 158], [159, 168], [169, 176], [177, 181], [182, 189], [190, 200], [200, 201], [202, 206], [207, 211], [212, 216], [217, 221], [222, 231], [232, 243], [244, 246], [247, 252], [253, 255], [256, 269], [270, 273], [274, 277], [278, 283], [283, 284]]}
{"doc_key": "ai-dev-329", "ner": [[6, 7, "university"], [10, 12, "product"], [22, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 12, 6, 7, "part-of", "", true, false], [22, 23, 10, 12, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "for", "freely", "available", "resources", ",", "Carnegie", "Mellon", "University", "'s", "Sphinx", "toolkit", "is", "one", "place", "to", "start", "learning", "about", "and", "experimenting", "with", "speech", "recognition", "."], "sentence-detokenized": "As for freely available resources, Carnegie Mellon University's Sphinx toolkit is one place to start learning about and experimenting with speech recognition.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 23], [24, 33], [33, 34], [35, 43], [44, 50], [51, 61], [61, 63], [64, 70], [71, 78], [79, 81], [82, 85], [86, 91], [92, 94], [95, 100], [101, 109], [110, 115], [116, 119], [120, 133], [134, 138], [139, 145], [146, 157], [157, 158]]}
{"doc_key": "ai-dev-330", "ner": [[1, 5, "misc"], [15, 18, "misc"], [13, 23, "misc"], [24, 26, "university"], [27, 27, "location"], [28, 32, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 5, 15, 18, "temporal", "", false, false], [13, 23, 15, 18, "named", "", false, false], [13, 23, 27, 27, "physical", "", false, false], [24, 26, 13, 23, "role", "", false, false], [27, 27, 28, 32, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "official", "RoboCup", "competition", "was", "preceded", "(", "often", "unacknowledged", ")", "by", "the", "first", "International", "Micro", "Robot", "World", "Cup", "Football", "Tournament", "(", "MIROSOT", ")", "organised", "by", "KAIST", "in", "Daejeon", ",", "South", "Korea", ",", "in", "November", "1996", "."], "sentence-detokenized": "The official RoboCup competition was preceded (often unacknowledged) by the first International Micro Robot World Cup Football Tournament (MIROSOT) organised by KAIST in Daejeon, South Korea, in November 1996.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 32], [33, 36], [37, 45], [46, 47], [47, 52], [53, 67], [67, 68], [69, 71], [72, 75], [76, 81], [82, 95], [96, 101], [102, 107], [108, 113], [114, 117], [118, 126], [127, 137], [138, 139], [139, 146], [146, 147], [148, 157], [158, 160], [161, 166], [167, 169], [170, 177], [177, 178], [179, 184], [185, 190], [190, 191], [192, 194], [195, 203], [204, 208], [208, 209]]}
{"doc_key": "ai-dev-331", "ner": [[5, 6, "metrics"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", "to", "the", "standard", "hinge", "loss", "math", "(", "1-", "yf", "(", "x", ")", ")", ",", "the", "loss", "function", "math", "(", "-", "1", "|", "f", "(", "x", ")", ")", "_", "+", "/", "math", "for", "labelled", "data", "is", "introduced", "for", "unlabelled", "data", "by", "mathy", "=\\", "operatorname", "{", "sign", "}.", "{", "f", "(", "x", ")", "}", "/", "math", "."], "sentence-detokenized": "In addition to the standard hinge loss math (1-yf (x)), the loss function math (-1 | f (x))_ + / math for labelled data is introduced for unlabelled data by mathy =\\ operatorname {sign}. {f (x)} / math.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 27], [28, 33], [34, 38], [39, 43], [44, 45], [45, 47], [47, 49], [50, 51], [51, 52], [52, 53], [53, 54], [54, 55], [56, 59], [60, 64], [65, 73], [74, 78], [79, 80], [80, 81], [81, 82], [83, 84], [85, 86], [87, 88], [88, 89], [89, 90], [90, 91], [91, 92], [93, 94], [95, 96], [97, 101], [102, 105], [106, 114], [115, 119], [120, 122], [123, 133], [134, 137], [138, 148], [149, 153], [154, 156], [157, 162], [163, 165], [166, 178], [179, 180], [180, 184], [184, 186], [187, 188], [188, 189], [190, 191], [191, 192], [192, 193], [193, 194], [195, 196], [197, 201], [201, 202]]}
{"doc_key": "ai-dev-332", "ner": [[3, 4, "misc"], [8, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 8, 11, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "particular", ",", "RLS", "is", "designed", "to", "minimise", "the", "mean", "squared", "error", "between", "predictions", "and", "true", "labels", ",", "subject", "to", "regularisation", "."], "sentence-detokenized": "In particular, RLS is designed to minimise the mean squared error between predictions and true labels, subject to regularisation.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 21], [22, 30], [31, 33], [34, 42], [43, 46], [47, 51], [52, 59], [60, 65], [66, 73], [74, 85], [86, 89], [90, 94], [95, 101], [101, 102], [103, 110], [111, 113], [114, 128], [128, 129]]}
{"doc_key": "ai-dev-333", "ner": [[0, 3, "algorithm"], [8, 9, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 8, 9, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "combines", "maximum", "likelihood", "estimation", "with", "a", "regularisation", "procedure", "that", "favours", "simple", "models", "over", "more", "complex", "ones", "."], "sentence-detokenized": "It combines maximum likelihood estimation with a regularisation procedure that favours simple models over more complex ones.", "token2charspan": [[0, 2], [3, 11], [12, 19], [20, 30], [31, 41], [42, 46], [47, 48], [49, 63], [64, 73], [74, 78], [79, 86], [87, 93], [94, 100], [101, 105], [106, 110], [111, 118], [119, 123], [123, 124]]}
{"doc_key": "ai-dev-334", "ner": [[1, 5, "metrics"], [11, 11, "metrics"], [13, 14, "metrics"], [6, 17, "misc"], [19, 24, "misc"], [25, 28, "algorithm"], [35, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 11, 1, 5, "named", "", false, false], [13, 14, 1, 5, "named", "", false, false], [6, 17, 19, 24, "related-to", "", false, false], [6, 17, 25, 28, "related-to", "ratio", false, false], [25, 28, 35, 37, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["(", "The", "true", "positive", "rate", "is", "also", "referred", "to", "as", "the", "sensitivity", ",", "repeatability", "or", "probability", "of", "detection", "maths", "against", "the", "identification", "threshold", "of", "the", "cumulative", "distribution", "function", "of", "detection", "probability", "on", "the", "Y-axis", "and", "false", "alarm", "probability", "on", "the", "X", "-", "axis", ".", ")"], "sentence-detokenized": "(The true positive rate is also referred to as the sensitivity, repeatability or probability of detection maths against the identification threshold of the cumulative distribution function of detection probability on the Y-axis and false alarm probability on the X-axis.)", "token2charspan": [[0, 1], [1, 4], [5, 9], [10, 18], [19, 23], [24, 26], [27, 31], [32, 40], [41, 43], [44, 46], [47, 50], [51, 62], [62, 63], [64, 77], [78, 80], [81, 92], [93, 95], [96, 105], [106, 111], [112, 119], [120, 123], [124, 138], [139, 148], [149, 151], [152, 155], [156, 166], [167, 179], [180, 188], [189, 191], [192, 201], [202, 213], [214, 216], [217, 220], [221, 227], [228, 231], [232, 237], [238, 243], [244, 255], [256, 258], [259, 262], [263, 264], [264, 265], [265, 269], [269, 270], [270, 271]]}
{"doc_key": "ai-dev-335", "ner": [[0, 1, "misc"], [3, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 6, 0, 1, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "English", ",", "Word", "Net", "is", "an", "example", "of", "a", "semantic", "network", "."], "sentence-detokenized": "In English, WordNet is an example of a semantic network.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 16], [16, 19], [20, 22], [23, 25], [26, 33], [34, 36], [37, 38], [39, 47], [48, 55], [55, 56]]}
{"doc_key": "ai-dev-336", "ner": [[5, 8, "product"], [9, 13, "product"], [26, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[26, 29, 5, 8, "usage", "", false, false], [26, 29, 9, 13, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Long", "-", "term", "use", "of", "speech", "recognition", "software", "in", "conjunction", "with", "a", "word", "processor", "was", "shown", "to", "be", "effective", "in", "short", "-", "term", "memory", "re-enforcement", "in", "patients", "with", "brain", "AVMs", "undergoing", "resection", "."], "sentence-detokenized": "Long-term use of speech recognition software in conjunction with a word processor was shown to be effective in short-term memory re-enforcement in patients with brain AVMs undergoing resection.", "token2charspan": [[0, 4], [4, 5], [5, 9], [10, 13], [14, 16], [17, 23], [24, 35], [36, 44], [45, 47], [48, 59], [60, 64], [65, 66], [67, 71], [72, 81], [82, 85], [86, 91], [92, 94], [95, 97], [98, 107], [108, 110], [111, 116], [116, 117], [117, 121], [122, 128], [129, 143], [144, 146], [147, 155], [156, 160], [161, 166], [167, 171], [172, 182], [183, 192], [192, 193]]}
{"doc_key": "ai-dev-337", "ner": [[7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Founding", "editors", "-", "in", "-", "chief", "were", "Ron", "Sun", ",", "Vasant", "Honavar", "and", "Greg", "Oden", "(", "1999-2014", ")", "."], "sentence-detokenized": "Founding editors-in-chief were Ron Sun, Vasant Honavar and Greg Oden (1999-2014).", "token2charspan": [[0, 8], [9, 16], [16, 17], [17, 19], [19, 20], [20, 25], [26, 30], [31, 34], [35, 38], [38, 39], [40, 46], [47, 54], [55, 58], [59, 63], [64, 68], [69, 70], [70, 79], [79, 80], [80, 81]]}
{"doc_key": "ai-dev-338", "ner": [[0, 4, "product"], [14, 14, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 14, 14, "opposite", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "contrast", "to", "serial", "manipulators", ",", "its", "'", "parallel", "'", "feature", "is", "that", "the", "end-effectors", "(", "or", "'", "arms", "'", ")", "of", "this", "linkage", "are", "directly", "connected", "to", "its", "base", "by", "a", "number", "(", "usually", "three", "to", "six", ")", "of", "independent", "links", "working", "simultaneously", "."], "sentence-detokenized": "In contrast to serial manipulators, its 'parallel' feature is that the end-effectors (or 'arms') of this linkage are directly connected to its base by a number (usually three to six) of independent links working simultaneously.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 21], [22, 34], [34, 35], [36, 39], [40, 41], [41, 49], [49, 50], [51, 58], [59, 61], [62, 66], [67, 70], [71, 84], [85, 86], [86, 88], [89, 90], [90, 94], [94, 95], [95, 96], [97, 99], [100, 104], [105, 112], [113, 116], [117, 125], [126, 135], [136, 138], [139, 142], [143, 147], [148, 150], [151, 152], [153, 159], [160, 161], [161, 168], [169, 174], [175, 177], [178, 181], [181, 182], [183, 185], [186, 197], [198, 203], [204, 211], [212, 226], [226, 227]]}
{"doc_key": "ai-dev-339", "ner": [[4, 6, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [24, 25, "researcher"], [27, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "dissertation", "supervisor", "is", "Professor", "Cordell", "Green", "and", "the", "dissertation", "and", "oral", "committee", "includes", "Professors", "Edward", "Feigenbaum", ",", "Joshua", "Lederberg", ",", "Paul", "Cohen", ",", "Allen", "Newell", "and", "Herbert", "Simon", "."], "sentence-detokenized": "The dissertation supervisor is Professor Cordell Green and the dissertation and oral committee includes Professors Edward Feigenbaum, Joshua Lederberg, Paul Cohen, Allen Newell and Herbert Simon.", "token2charspan": [[0, 3], [4, 16], [17, 27], [28, 30], [31, 40], [41, 48], [49, 54], [55, 58], [59, 62], [63, 75], [76, 79], [80, 84], [85, 94], [95, 103], [104, 114], [115, 121], [122, 132], [132, 133], [134, 140], [141, 150], [150, 151], [152, 156], [157, 162], [162, 163], [164, 169], [170, 176], [177, 180], [181, 188], [189, 194], [194, 195]]}
{"doc_key": "ai-dev-340", "ner": [[3, 5, "metrics"], [7, 10, "metrics"], [12, 14, "metrics"], [16, 18, "metrics"], [20, 23, "metrics"], [2, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "functions", "include", "mean", "squared", "error", ",", "root", "mean", "squared", "error", ",", "mean", "absolute", "error", ",", "relative", "squared", "error", ",", "root", "relative", "squared", "error", "and", "relative", "absolute", "error", "."], "sentence-detokenized": "Such functions include mean squared error, root mean squared error, mean absolute error, relative squared error, root relative squared error and relative absolute error.", "token2charspan": [[0, 4], [5, 14], [15, 22], [23, 27], [28, 35], [36, 41], [41, 42], [43, 47], [48, 52], [53, 60], [61, 66], [66, 67], [68, 72], [73, 81], [82, 87], [87, 88], [89, 97], [98, 105], [106, 111], [111, 112], [113, 117], [118, 126], [127, 134], [135, 140], [141, 144], [145, 153], [154, 162], [163, 168], [168, 169]]}
{"doc_key": "ai-dev-341", "ner": [[4, 4, "programlang"], [6, 6, "programlang"], [8, 8, "product"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "bindings", "in", "Python", ",", "Java", "and", "MATLAB", "/", "OCTAVE", "."], "sentence-detokenized": "There are bindings in Python, Java and MATLAB / OCTAVE.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 21], [22, 28], [28, 29], [30, 34], [35, 38], [39, 45], [46, 47], [48, 54], [54, 55]]}
{"doc_key": "ai-dev-342", "ner": [[2, 3, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "implementation", "in", "MATLAB", "can", "be", "found", "here", "."], "sentence-detokenized": "An implementation in MATLAB can be found here.", "token2charspan": [[0, 2], [3, 17], [18, 20], [21, 27], [28, 31], [32, 34], [35, 40], [41, 45], [45, 46]]}
{"doc_key": "ai-dev-343", "ner": [[0, 2, "researcher"], [8, 9, "field"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [11, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 2, "origin", "", false, false], [8, 9, 13, 14, "origin", "", false, false], [8, 9, 16, 17, "origin", "", false, false], [8, 9, 19, 20, "origin", "", false, false], [8, 9, 11, 25, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["John", "McCarthy", "was", "one", "of", "the", "founders", "of", "artificial", "intelligence", ",", "along", "with", "Alan", "Turing", ",", "Marvin", "Minsky", ",", "Allen", "Newell", "and", "Herbert", "A", ".", "Simon", "."], "sentence-detokenized": "John McCarthy was one of the founders of artificial intelligence, along with Alan Turing, Marvin Minsky, Allen Newell and Herbert A. Simon.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 21], [22, 24], [25, 28], [29, 37], [38, 40], [41, 51], [52, 64], [64, 65], [66, 71], [72, 76], [77, 81], [82, 88], [88, 89], [90, 96], [97, 103], [103, 104], [105, 110], [111, 117], [118, 121], [122, 129], [130, 131], [131, 132], [133, 138], [138, 139]]}
{"doc_key": "ai-dev-344", "ner": [[8, 9, "product"], [10, 15, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Parallel", "manipulators", "are", "mechanical", "systems", "in", "which", "several", "serial", "manipulators", "support", "a", "single", "platform", "(", "end-effector", ")", "."], "sentence-detokenized": "Parallel manipulators are mechanical systems in which several serial manipulators support a single platform (end-effector).", "token2charspan": [[0, 8], [9, 21], [22, 25], [26, 36], [37, 44], [45, 47], [48, 53], [54, 61], [62, 68], [69, 81], [82, 89], [90, 91], [92, 98], [99, 107], [108, 109], [109, 121], [121, 122], [122, 123]]}
{"doc_key": "ai-dev-345", "ner": [[0, 1, "product"], [5, 7, "task"], [9, 20, "product"], [11, 14, "product"], [29, 29, "misc"], [32, 32, "misc"], [35, 36, "misc"], [39, 44, "task"], [47, 50, "product"], [53, 54, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[9, 20, 0, 1, "part-of", "", false, false], [9, 20, 5, 7, "type-of", "", false, false], [11, 14, 9, 20, "named", "", false, false], [29, 29, 9, 20, "part-of", "", false, false], [32, 32, 9, 20, "part-of", "", false, false], [35, 36, 9, 20, "part-of", "", false, false], [39, 44, 9, 20, "part-of", "", false, false], [47, 50, 9, 20, "part-of", "", false, false], [53, 54, 9, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["GATE", "is", "equipped", "with", "an", "information", "extraction", "system", "called", "ANNIE", "(", "A", "Nearly", "-", "New", "Information", "Extraction", "System", ")", ",", "which", "is", "a", "group", "of", "modules", "consisting", "of", "a", "tokeniser", ",", "a", "gazetteer", ",", "a", "clause", "segmenter", ",", "a", "part", "-", "of", "-", "speech", "tagger", ",", "a", "unique", "expression", "recognition", "converter", "and", "a", "coreference", "tagger", ".", "The", "system", "consists", "of", "a", "tokeniser", ",", "gazetteer", ",", "clause", "segmenter", ",", "part", "-", "of", "-", "speech", "tagger", ",", "unique", "expression", "recognition", "transformer", "and", "coreference", "tagger", "."], "sentence-detokenized": "GATE is equipped with an information extraction system called ANNIE (A Nearly-New Information Extraction System), which is a group of modules consisting of a tokeniser, a gazetteer, a clause segmenter, a part-of-speech tagger, a unique expression recognition converter and a coreference tagger. The system consists of a tokeniser, gazetteer, clause segmenter, part-of-speech tagger, unique expression recognition transformer and coreference tagger.", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 21], [22, 24], [25, 36], [37, 47], [48, 54], [55, 61], [62, 67], [68, 69], [69, 70], [71, 77], [77, 78], [78, 81], [82, 93], [94, 104], [105, 111], [111, 112], [112, 113], [114, 119], [120, 122], [123, 124], [125, 130], [131, 133], [134, 141], [142, 152], [153, 155], [156, 157], [158, 167], [167, 168], [169, 170], [171, 180], [180, 181], [182, 183], [184, 190], [191, 200], [200, 201], [202, 203], [204, 208], [208, 209], [209, 211], [211, 212], [212, 218], [219, 225], [225, 226], [227, 228], [229, 235], [236, 246], [247, 258], [259, 268], [269, 272], [273, 274], [275, 286], [287, 293], [293, 294], [295, 298], [299, 305], [306, 314], [315, 317], [318, 319], [320, 329], [329, 330], [331, 340], [340, 341], [342, 348], [349, 358], [358, 359], [360, 364], [364, 365], [365, 367], [367, 368], [368, 374], [375, 381], [381, 382], [383, 389], [390, 400], [401, 412], [413, 424], [425, 428], [429, 440], [441, 447], [447, 448]]}
{"doc_key": "ai-dev-346", "ner": [[2, 5, "university"], [7, 11, "country"], [18, 21, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "graduated", "from", "Moscow", "State", "University", "and", "came", "to", "the", "USA", "in", "November", "1978", "through", "the", "mediation", "of", "Senator", "Edward", "M.", "Kennedy", "."], "sentence-detokenized": "He graduated from Moscow State University and came to the USA in November 1978 through the mediation of Senator Edward M. Kennedy.", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 24], [25, 30], [31, 41], [42, 45], [46, 50], [51, 53], [54, 57], [58, 61], [62, 64], [65, 73], [74, 78], [79, 86], [87, 90], [91, 100], [101, 103], [104, 111], [112, 118], [119, 121], [122, 129], [129, 130]]}
{"doc_key": "ai-dev-347", "ner": [[4, 6, "organisation"], [9, 15, "misc"], [19, 19, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 9, 15, "win-defeat", "", false, false], [9, 15, 19, 19, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2017", ",", "the", "DeepMind", "AlphaGo", "team", "was", "awarded", "the", "first", "IJCAI", "Marvin", "Minsky", "Medal", "for", "outstanding", "achievement", "in", "AI", "."], "sentence-detokenized": "In 2017, the DeepMind AlphaGo team was awarded the first IJCAI Marvin Minsky Medal for outstanding achievement in AI.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 21], [22, 29], [30, 34], [35, 38], [39, 46], [47, 50], [51, 56], [57, 62], [63, 69], [70, 76], [77, 82], [83, 86], [87, 98], [99, 110], [111, 113], [114, 116], [116, 117]]}
{"doc_key": "ai-dev-348", "ner": [[1, 4, "misc"], [7, 7, "misc"], [11, 12, "misc"], [27, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 5], "relations": [[1, 4, 7, 7, "related-to", "is_recorded_by", false, false], [7, 7, 11, 12, "cause-effect", "", false, false], [7, 7, 11, 12, "physical", "", false, false], [7, 7, 27, 29, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4], "sentence": ["Other", "anomalous", "propagation", "may", "be", "recorded", "as", "troposcatters", "causing", "turbulence", "in", "the", "troposphere", ",", "scattering", "by", "meteors", ",", "refraction", "in", "ionospheric", "regions", "and", "layers", ",", "and", "reflections", "from", "the", "ionosphere", "."], "sentence-detokenized": "Other anomalous propagation may be recorded as troposcatters causing turbulence in the troposphere, scattering by meteors, refraction in ionospheric regions and layers, and reflections from the ionosphere.", "token2charspan": [[0, 5], [6, 15], [16, 27], [28, 31], [32, 34], [35, 43], [44, 46], [47, 60], [61, 68], [69, 79], [80, 82], [83, 86], [87, 98], [98, 99], [100, 110], [111, 113], [114, 121], [121, 122], [123, 133], [134, 136], [137, 148], [149, 156], [157, 160], [161, 167], [167, 168], [169, 172], [173, 184], [185, 189], [190, 193], [194, 204], [204, 205]]}
{"doc_key": "ai-dev-349", "ner": [[1, 2, "field"], [0, 6, "field"], [10, 10, "field"], [12, 13, "field"], [15, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 2, 10, 10, "part-of", "", false, false], [1, 2, 12, 13, "part-of", "", false, false], [1, 2, 15, 16, "part-of", "", false, false], [1, 2, 18, 19, "part-of", "", false, false], [0, 6, 1, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Natural", "language", "processing", "(", "NLP", ")", "is", "a", "subfield", "of", "linguistics", ",", "computer", "science", ",", "information", "engineering", "and", "artificial", "intelligence", "concerned", "with", "the", "interaction", "between", "computers", "and", "human", "(", "natural", ")", "language", ",", "in", "particular", "the", "way", "computers", "are", "programmed", "to", "process", "and", "analyse", "large", "amounts", "of", "natural", "language", "data", "."], "sentence-detokenized": "Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering and artificial intelligence concerned with the interaction between computers and human (natural) language, in particular the way computers are programmed to process and analyse large amounts of natural language data.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 29], [29, 32], [32, 33], [34, 36], [37, 38], [39, 47], [48, 50], [51, 62], [62, 63], [64, 72], [73, 80], [80, 81], [82, 93], [94, 105], [106, 109], [110, 120], [121, 133], [134, 143], [144, 148], [149, 152], [153, 164], [165, 172], [173, 182], [183, 186], [187, 192], [193, 194], [194, 201], [201, 202], [203, 211], [211, 212], [213, 215], [216, 226], [227, 230], [231, 234], [235, 244], [245, 248], [249, 259], [260, 262], [263, 270], [271, 274], [275, 282], [283, 288], [289, 296], [297, 299], [300, 307], [308, 316], [317, 321], [321, 322]]}
{"doc_key": "ai-dev-350", "ner": [[9, 10, "organisation"], [12, 13, "organisation"], [15, 16, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "youth", "-", "led", "climate", "change", "groups", "such", "as", "Extinction", "Rebellion", ",", "Sunrise", "Movement", ",", "SustainUS", "and", "the", "are", "active", "at", "transnational", "and", "local", "levels", "."], "sentence-detokenized": "Other youth-led climate change groups such as Extinction Rebellion, Sunrise Movement, SustainUS and the are active at transnational and local levels.", "token2charspan": [[0, 5], [6, 11], [11, 12], [12, 15], [16, 23], [24, 30], [31, 37], [38, 42], [43, 45], [46, 56], [57, 66], [66, 67], [68, 75], [76, 84], [84, 85], [86, 95], [96, 99], [100, 103], [104, 107], [108, 114], [115, 117], [118, 131], [132, 135], [136, 141], [142, 148], [148, 149]]}
