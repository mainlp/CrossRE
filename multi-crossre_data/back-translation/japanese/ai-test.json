{"doc_key": "ai-test-1", "ner": [[5, 7, "algorithm"], [9, 10, "algorithm"], [13, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "generative", "modelling", "approaches", "include", "na\u00efve", "Bayes", "classifiers", ",", "Gaussian", "mixture", "models", "and", "variational", "autoencoders", "."], "sentence-detokenized": "Typical generative modelling approaches include na\u00efve Bayes classifiers, Gaussian mixture models and variational autoencoders.", "token2charspan": [[0, 7], [8, 18], [19, 28], [29, 39], [40, 47], [48, 53], [54, 59], [60, 71], [71, 72], [73, 81], [82, 89], [90, 96], [97, 100], [101, 112], [113, 125], [125, 126]]}
{"doc_key": "ai-test-2", "ner": [[0, 2, "organisation"], [10, 19, "conference"], [3, 4, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 10, 19, "role", "", false, false], [3, 4, 10, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Finally", ",", "ELRA", "organises", "a", "major", "conference", ",", "the", "International", "Language", "Resources", "and", "Evaluation", "Conference", "(", "LREC", ")", ",", "every", "two", "years", "."], "sentence-detokenized": "Finally, ELRA organises a major conference, the International Language Resources and Evaluation Conference (LREC), every two years.", "token2charspan": [[0, 7], [7, 8], [9, 13], [14, 23], [24, 25], [26, 31], [32, 42], [42, 43], [44, 47], [48, 61], [62, 70], [71, 80], [81, 84], [85, 95], [96, 106], [107, 108], [108, 112], [112, 113], [113, 114], [115, 120], [121, 124], [125, 130], [130, 131]]}
{"doc_key": "ai-test-3", "ner": [[5, 10, "algorithm"], [11, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "challenge", "is", "usually", "to", "derive", "maximum", "likelihood", "estimates", "of", "the", "parameters", "of", "the", "HMM", ",", "given", "the", "output", "sequence", "."], "sentence-detokenized": "The challenge is usually to derive maximum likelihood estimates of the parameters of the HMM, given the output sequence.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 24], [25, 27], [28, 34], [35, 42], [43, 53], [54, 63], [64, 66], [67, 70], [71, 81], [82, 84], [85, 88], [89, 92], [92, 93], [94, 99], [100, 103], [104, 110], [111, 119], [119, 120]]}
{"doc_key": "ai-test-4", "ner": [[4, 8, "algorithm"], [12, 12, "algorithm"]], "ner_mapping_to_source": [1, 2], "relations": [[4, 8, 12, 12, "compare", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Unlike", "neural", "networks", "and", "support", "vector", "machines", ",", "the", "training", "process", "in", "AdaBoost", "only", "selects", "features", "that", "are", "known", "to", "improve", "the", "predictive", "power", "of", "the", "model", ",", "thus", "reducing", "dimensionality", "and", "potentially", "improving", "runtime", "as", "irrelevant", "features", "do", "not", "need", "to", "be", "calculated", "."], "sentence-detokenized": "Unlike neural networks and support vector machines, the training process in AdaBoost only selects features that are known to improve the predictive power of the model, thus reducing dimensionality and potentially improving runtime as irrelevant features do not need to be calculated.", "token2charspan": [[0, 6], [7, 13], [14, 22], [23, 26], [27, 34], [35, 41], [42, 50], [50, 51], [52, 55], [56, 64], [65, 72], [73, 75], [76, 84], [85, 89], [90, 97], [98, 106], [107, 111], [112, 115], [116, 121], [122, 124], [125, 132], [133, 136], [137, 147], [148, 153], [154, 156], [157, 160], [161, 166], [166, 167], [168, 172], [173, 181], [182, 196], [197, 200], [201, 212], [213, 222], [223, 230], [231, 233], [234, 244], [245, 253], [254, 256], [257, 260], [261, 265], [266, 268], [269, 271], [272, 282], [282, 283]]}
{"doc_key": "ai-test-5", "ner": [[0, 1, "misc"], [8, 14, "misc"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 8, 14, "part-of", "", false, false], [8, 14, 15, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Tropony", "is", "one", "of", "the", "possible", "relations", "between", "verbs", "in", "the", "semantic", "network", "of", "the", "Word", "Net", "database", "."], "sentence-detokenized": "Tropony is one of the possible relations between verbs in the semantic network of the WordNet database.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 17], [18, 21], [22, 30], [31, 40], [41, 48], [49, 54], [55, 57], [58, 61], [62, 70], [71, 78], [79, 81], [82, 85], [86, 90], [90, 93], [94, 102], [102, 103]]}
{"doc_key": "ai-test-6", "ner": [[6, 9, "task"], [10, 11, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 9, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Frame", "languages", "are", "a", "technique", "used", "for", "knowledge", "representation", "in", "artificial", "intelligence", "."], "sentence-detokenized": "Frame languages are a technique used for knowledge representation in artificial intelligence.", "token2charspan": [[0, 5], [6, 15], [16, 19], [20, 21], [22, 31], [32, 36], [37, 40], [41, 50], [51, 65], [66, 68], [69, 79], [80, 92], [92, 93]]}
{"doc_key": "ai-test-7", "ner": [[0, 1, "metrics"], [2, 9, "metrics"], [13, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 2, 9, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "the", "Bilingual", "Evaluation", "understudy", "in", "the", "way", "it", "calculates", "the", "brevity", "penalty", ",", "in", "that", "small", "variations", "in", "the", "length", "of", "the", "translation", "do", "not", "affect", "the", "overall", "score", "as", "much", "."], "sentence-detokenized": "NIST also differs from the Bilingual Evaluation understudy in the way it calculates the brevity penalty, in that small variations in the length of the translation do not affect the overall score as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 26], [27, 36], [37, 47], [48, 58], [59, 61], [62, 65], [66, 69], [70, 72], [73, 83], [84, 87], [88, 95], [96, 103], [103, 104], [105, 107], [108, 112], [113, 118], [119, 129], [130, 132], [133, 136], [137, 143], [144, 146], [147, 150], [151, 162], [163, 165], [166, 169], [170, 176], [177, 180], [181, 188], [189, 194], [195, 197], [198, 202], [202, 203]]}
{"doc_key": "ai-test-8", "ner": [[6, 8, "algorithm"], [19, 20, "field"], [28, 29, "algorithm"], [31, 33, "algorithm"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[6, 8, 19, 20, "usage", "", false, false], [28, 29, 19, 20, "type-of", "", false, false], [31, 33, 19, 20, "type-of", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Models", "(", "e.g.", "neural", "nets", "or", "na\u00efve", "Bayes", "classifiers", ")", "are", "initially", "fitted", "to", "the", "training", "data", "set", "using", "supervised", "learning", "methods", ",", "e.g.", "optimisation", "methods", "such", "as", "gradient", "descent", "or", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "Models (e.g. neural nets or na\u00efve Bayes classifiers) are initially fitted to the training data set using supervised learning methods, e.g. optimisation methods such as gradient descent or stochastic gradient descent.", "token2charspan": [[0, 6], [7, 8], [8, 12], [13, 19], [20, 24], [25, 27], [28, 33], [34, 39], [40, 51], [51, 52], [53, 56], [57, 66], [67, 73], [74, 76], [77, 80], [81, 89], [90, 94], [95, 98], [99, 104], [105, 115], [116, 124], [125, 132], [132, 133], [134, 138], [139, 151], [152, 159], [160, 164], [165, 167], [168, 176], [177, 184], [185, 187], [188, 198], [199, 207], [208, 215], [215, 216]]}
{"doc_key": "ai-test-9", "ner": [[0, 2, "product"], [15, 16, "task"], [20, 22, "task"], [12, 25, "task"], [7, 9, "task"]], "ner_mapping_to_source": [0, 1, 3, 4, 5], "relations": [[15, 16, 0, 2, "usage", "", true, false], [20, 22, 0, 2, "usage", "", true, false], [12, 25, 0, 2, "usage", "", true, false], [7, 9, 0, 2, "usage", "", true, false]], "relations_mapping_to_source": [0, 2, 3, 4], "sentence": ["Frame", "Net", "is", "used", "by", "direct", "or", "semantic", "role", "labelling", "tools", "for", "applications", "such", "as", "question", "answering", ",", "paraphrasing", ",", "textual", "implication", "recognition", "and", "information", "extraction", "."], "sentence-detokenized": "FrameNet is used by direct or semantic role labelling tools for applications such as question answering, paraphrasing, textual implication recognition and information extraction.", "token2charspan": [[0, 5], [5, 8], [9, 11], [12, 16], [17, 19], [20, 26], [27, 29], [30, 38], [39, 43], [44, 53], [54, 59], [60, 63], [64, 76], [77, 81], [82, 84], [85, 93], [94, 103], [103, 104], [105, 117], [117, 118], [119, 126], [127, 138], [139, 150], [151, 154], [155, 166], [167, 177], [177, 178]]}
{"doc_key": "ai-test-10", "ner": [[2, 3, "field"], [8, 8, "misc"], [10, 11, "product"], [14, 14, "misc"], [16, 17, "product"], [20, 21, "field"], [23, 24, "product"], [27, 29, "misc"], [32, 32, "product"], [34, 34, "product"], [31, 36, "product"], [39, 40, "misc"], [43, 43, "product"], [45, 52, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[10, 11, 8, 8, "general-affiliation", "", false, false], [16, 17, 14, 14, "general-affiliation", "", false, false], [23, 24, 20, 21, "general-affiliation", "", false, false], [32, 32, 27, 29, "type-of", "", false, false], [34, 34, 27, 29, "type-of", "", false, false], [31, 36, 27, 29, "type-of", "", false, false], [43, 43, 39, 40, "general-affiliation", "", false, false], [45, 52, 39, 40, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["This", "includes", "data", "analysis", "and", "extraction", "tools", ",", "spreadsheets", "(", "e.g.", "Excel", ")", ",", "databases", "(", "e.g.", "Access", ")", ",", "statistical", "analysis", "(", "e.g.", "SAS", ")", ",", "generic", "auditing", "software", "(", "e.g.", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "business", "intelligence", "(", "Crystal", "Reports", ",", "Business", "Objects", ",", "etc.", ")", "and", "other", "programmes", "."], "sentence-detokenized": "This includes data analysis and extraction tools, spreadsheets (e.g. Excel), databases (e.g. Access), statistical analysis (e.g. SAS), generic auditing software (e.g. ACL, Arbutus, EAS), business intelligence (Crystal Reports, Business Objects, etc.) and other programmes.", "token2charspan": [[0, 4], [5, 13], [14, 18], [19, 27], [28, 31], [32, 42], [43, 48], [48, 49], [50, 62], [63, 64], [64, 68], [69, 74], [74, 75], [75, 76], [77, 86], [87, 88], [88, 92], [93, 99], [99, 100], [100, 101], [102, 113], [114, 122], [123, 124], [124, 128], [129, 132], [132, 133], [133, 134], [135, 142], [143, 151], [152, 160], [161, 162], [162, 166], [167, 170], [170, 171], [172, 179], [179, 180], [181, 184], [184, 185], [185, 186], [187, 195], [196, 208], [209, 210], [210, 217], [218, 225], [225, 226], [227, 235], [236, 243], [243, 244], [245, 249], [249, 250], [251, 254], [255, 260], [261, 271], [271, 272]]}
{"doc_key": "ai-test-11", "ner": [[0, 1, "organisation"], [4, 6, "researcher"], [8, 10, "organisation"], [12, 14, "product"], [23, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 4, 6, "origin", "", false, false], [4, 6, 8, 10, "role", "", false, false], [12, 14, 23, 27, "type-of", "", false, false], [23, 27, 4, 6, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Rethink", "Robotics", ",", "founded", "by", "Rodney", "Brooks", ",", "formerly", "of", "iRobot", ",", "launched", "Baxter", "in", "September", "2012", ".", "The", "robot", "is", "designed", "as", "a", "programmable", "industrial", "robot", "that", "can", "safely", "interact", "with", "adjacent", "human", "workers", "to", "perform", "simple", "tasks", "."], "sentence-detokenized": "Rethink Robotics, founded by Rodney Brooks, formerly of iRobot, launched Baxter in September 2012. The robot is designed as a programmable industrial robot that can safely interact with adjacent human workers to perform simple tasks.", "token2charspan": [[0, 7], [8, 16], [16, 17], [18, 25], [26, 28], [29, 35], [36, 42], [42, 43], [44, 52], [53, 55], [56, 62], [62, 63], [64, 72], [73, 79], [80, 82], [83, 92], [93, 97], [97, 98], [99, 102], [103, 108], [109, 111], [112, 120], [121, 123], [124, 125], [126, 138], [139, 149], [150, 155], [156, 160], [161, 164], [165, 171], [172, 180], [181, 185], [186, 194], [195, 200], [201, 208], [209, 211], [212, 219], [220, 226], [227, 232], [232, 233]]}
{"doc_key": "ai-test-12", "ner": [[1, 2, "field"], [5, 6, "task"], [8, 9, "task"], [11, 14, "task"], [16, 20, "task"], [22, 23, "task"], [25, 26, "task"], [28, 30, "task"], [36, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 6, 1, 2, "part-of", "task_part_of_field", false, false], [8, 9, 1, 2, "part-of", "task_part_of_field", false, false], [11, 14, 1, 2, "part-of", "task_part_of_field", false, false], [16, 20, 1, 2, "part-of", "task_part_of_field", false, false], [22, 23, 1, 2, "part-of", "task_part_of_field", false, false], [25, 26, 1, 2, "part-of", "task_part_of_field", false, false], [28, 30, 1, 2, "part-of", "task_part_of_field", false, false], [36, 38, 1, 2, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Typical", "text", "mining", "tasks", "include", "text", "classification", ",", "text", "clustering", ",", "concept", "/", "entity", "extraction", ",", "creating", "fine", "-", "grained", "taxonomies", ",", "sentiment", "analysis", ",", "document", "summarisation", "and", "entity", "relationship", "modelling", "(", "i.e.", "learning", "relationships", "between", "named", "entity", "recognitions", ")", "."], "sentence-detokenized": "Typical text mining tasks include text classification, text clustering, concept/entity extraction, creating fine-grained taxonomies, sentiment analysis, document summarisation and entity relationship modelling (i.e. learning relationships between named entity recognitions).", "token2charspan": [[0, 7], [8, 12], [13, 19], [20, 25], [26, 33], [34, 38], [39, 53], [53, 54], [55, 59], [60, 70], [70, 71], [72, 79], [79, 80], [80, 86], [87, 97], [97, 98], [99, 107], [108, 112], [112, 113], [113, 120], [121, 131], [131, 132], [133, 142], [143, 151], [151, 152], [153, 161], [162, 175], [176, 179], [180, 186], [187, 199], [200, 209], [210, 211], [211, 215], [216, 224], [225, 238], [239, 246], [247, 252], [253, 259], [260, 272], [272, 273], [273, 274]]}
{"doc_key": "ai-test-13", "ner": [[5, 6, "metrics"], [12, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "stemming", "reduces", "the", "accuracy", "of", "such", "systems", ",", "i.e.", "the", "true", "negative", "rate", "."], "sentence-detokenized": "However, stemming reduces the accuracy of such systems, i.e. the true negative rate.", "token2charspan": [[0, 7], [7, 8], [9, 17], [18, 25], [26, 29], [30, 38], [39, 41], [42, 46], [47, 54], [54, 55], [56, 60], [61, 64], [65, 69], [70, 78], [79, 83], [83, 84]]}
{"doc_key": "ai-test-14", "ner": [[4, 6, "task"], [7, 7, "misc"], [9, 12, "misc"], [21, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[7, 7, 4, 6, "temporal", "", false, false], [9, 12, 7, 7, "named", "", false, false], [21, 25, 7, 7, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 3], "sentence": ["A", "special", "example", "of", "keyword", "detection", "is", "wakeword", "(", "also", "known", "as", "hotword", ")", "detection", ",", "where", "a", "personal", "digital", "assistant", "such", "as", "Alexa", "or", "Siri", "wakes", "up", "when", "you", "speak", "your", "name", "."], "sentence-detokenized": "A special example of keyword detection is wakeword (also known as hotword) detection, where a personal digital assistant such as Alexa or Siri wakes up when you speak your name.", "token2charspan": [[0, 1], [2, 9], [10, 17], [18, 20], [21, 28], [29, 38], [39, 41], [42, 50], [51, 52], [52, 56], [57, 62], [63, 65], [66, 73], [73, 74], [75, 84], [84, 85], [86, 91], [92, 93], [94, 102], [103, 110], [111, 120], [121, 125], [126, 128], [129, 134], [135, 137], [138, 142], [143, 148], [149, 151], [152, 156], [157, 160], [161, 166], [167, 171], [172, 176], [176, 177]]}
{"doc_key": "ai-test-15", "ner": [[0, 0, "programlang"], [8, 11, "programlang"]], "ner_mapping_to_source": [0, 2], "relations": [[8, 11, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Prova", "is", "an", "open", "source", "programming", "language", "that", "combines", "Prolog", "and", "Java", "."], "sentence-detokenized": "Prova is an open source programming language that combines Prolog and Java.", "token2charspan": [[0, 5], [6, 8], [9, 11], [12, 16], [17, 23], [24, 35], [36, 44], [45, 49], [50, 58], [59, 65], [66, 69], [70, 74], [74, 75]]}
{"doc_key": "ai-test-16", "ner": [[5, 6, "organisation"], [3, 3, "organisation"], [12, 14, "product"], [16, 20, "country"], [32, 33, "organisation"], [42, 42, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 6, 3, 3, "part-of", "", false, false], [5, 6, 3, 3, "role", "sells", false, false], [5, 6, 16, 20, "role", "sells_to", false, false], [32, 33, 42, 42, "opposite", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "1987", ",", "Toshiba", "subsidiary", "Tofui", "Machinery", "was", "accused", "of", "illegally", "selling", "CNC", "milling", "machines", "to", "the", "Soviet", "Union", "for", "the", "production", "of", "extremely", "quiet", "submarine", "propellers", ",", "in", "violation", "of", "the", "CoCom", "Agreement", ",", "an", "international", "embargo", "on", "certain", "countries", "to", "COMECON", "countries", "."], "sentence-detokenized": "In 1987, Toshiba subsidiary Tofui Machinery was accused of illegally selling CNC milling machines to the Soviet Union for the production of extremely quiet submarine propellers, in violation of the CoCom Agreement, an international embargo on certain countries to COMECON countries.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 27], [28, 33], [34, 43], [44, 47], [48, 55], [56, 58], [59, 68], [69, 76], [77, 80], [81, 88], [89, 97], [98, 100], [101, 104], [105, 111], [112, 117], [118, 121], [122, 125], [126, 136], [137, 139], [140, 149], [150, 155], [156, 165], [166, 176], [176, 177], [178, 180], [181, 190], [191, 193], [194, 197], [198, 203], [204, 213], [213, 214], [215, 217], [218, 231], [232, 239], [240, 242], [243, 250], [251, 260], [261, 263], [264, 271], [272, 281], [281, 282]]}
{"doc_key": "ai-test-17", "ner": [[0, 0, "researcher"], [7, 12, "product"], [15, 20, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 12, 0, 0, "artifact", "", false, false], [7, 12, 15, 20, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Engelberger", "'s", "most", "famous", "co-invention", ",", "the", "industrial", "robot", "arm", "Unimate", ",", "was", "inducted", "into", "the", "Robotics", "Hall", "of", "Fame", "in", "2003", "."], "sentence-detokenized": "Engelberger's most famous co-invention, the industrial robot arm Unimate, was inducted into the Robotics Hall of Fame in 2003.", "token2charspan": [[0, 11], [11, 13], [14, 18], [19, 25], [26, 38], [38, 39], [40, 43], [44, 54], [55, 60], [61, 64], [65, 72], [72, 73], [74, 77], [78, 86], [87, 91], [92, 95], [96, 104], [105, 109], [110, 112], [113, 117], [118, 120], [121, 125], [125, 126]]}
{"doc_key": "ai-test-18", "ner": [[3, 4, "misc"], [7, 8, "misc"], [10, 11, "person"], [22, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 7, 8, "usage", "", false, false], [10, 11, 22, 25, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Initially", "controlled", "by", "static", "HTML", "web", "pages", "using", "CGI", ",", "Dalton", "'s", "research", "led", "to", "the", "introduction", "of", "a", "Java", "-", "based", "augmented", "reality", "interface", "with", "limited", "success", "."], "sentence-detokenized": "Initially controlled by static HTML web pages using CGI, Dalton's research led to the introduction of a Java-based augmented reality interface with limited success.", "token2charspan": [[0, 9], [10, 20], [21, 23], [24, 30], [31, 35], [36, 39], [40, 45], [46, 51], [52, 55], [55, 56], [57, 63], [63, 65], [66, 74], [75, 78], [79, 81], [82, 85], [86, 98], [99, 101], [102, 103], [104, 108], [108, 109], [109, 114], [115, 124], [125, 132], [133, 142], [143, 147], [148, 155], [156, 163], [163, 164]]}
{"doc_key": "ai-test-19", "ner": [[2, 5, "task"], [8, 8, "organisation"], [24, 24, "conference"], [28, 28, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 5, 8, 8, "origin", "", false, false], [24, 24, 28, 28, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["First", "publication", "on", "the", "LMF", "specification", "ratified", "by", "ISO", "(", "this", "paper", "became", "(", "in", "2015", ")", "the", "ninth", "most", "cited", "paper", "within", "the", "LREC", "conference", "from", "an", "LREC", "paper", ")", "."], "sentence-detokenized": "First publication on the LMF specification ratified by ISO (this paper became (in 2015) the ninth most cited paper within the LREC conference from an LREC paper).", "token2charspan": [[0, 5], [6, 17], [18, 20], [21, 24], [25, 28], [29, 42], [43, 51], [52, 54], [55, 58], [59, 60], [60, 64], [65, 70], [71, 77], [78, 79], [79, 81], [82, 86], [86, 87], [88, 91], [92, 97], [98, 102], [103, 108], [109, 114], [115, 121], [122, 125], [126, 130], [131, 141], [142, 146], [147, 149], [150, 154], [155, 160], [160, 161], [161, 162]]}
{"doc_key": "ai-test-20", "ner": [[0, 0, "metrics"], [11, 13, "metrics"], [13, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 13, 0, 0, "usage", "", false, false], [11, 13, 13, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Confusion", "and", "matching", "matrices", "are", "often", "used", "as", "tools", "to", "verify", "the", "accuracy", "of", "k", "-", "NN", "classification", "."], "sentence-detokenized": "Confusion and matching matrices are often used as tools to verify the accuracy of k -NN classification.", "token2charspan": [[0, 9], [10, 13], [14, 22], [23, 31], [32, 35], [36, 41], [42, 46], [47, 49], [50, 55], [56, 58], [59, 65], [66, 69], [70, 78], [79, 81], [82, 83], [84, 85], [85, 87], [88, 102], [102, 103]]}
{"doc_key": "ai-test-21", "ner": [[0, 1, "algorithm"], [12, 12, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 12, "part-of", "", false, false], [0, 1, 14, 15, "part-of", "", false, false], [0, 1, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", "is", "one", "of", "the", "predictive", "modelling", "approaches", "used", "in", "statistics", ",", "data", "mining", "and", "machine", "learning", "."], "sentence-detokenized": "Decision tree learning is one of the predictive modelling approaches used in statistics, data mining and machine learning.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 47], [48, 57], [58, 68], [69, 73], [74, 76], [77, 87], [87, 88], [89, 93], [94, 100], [101, 104], [105, 112], [113, 121], [121, 122]]}
{"doc_key": "ai-test-22", "ner": [[11, 13, "misc"], [16, 17, "field"], [19, 23, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 13, 16, 17, "related-to", "", true, false], [19, 23, 16, 17, "type-of", "", false, false], [25, 25, 16, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["At", "runtime", ",", "these", "smallest", "units", "are", "overlaid", "with", "the", "desired", "prosody", "of", "the", "sentence", "by", "signal", "processing", "techniques", "such", "as", "linear", "predictive", "coding", ",", "PSOLA"], "sentence-detokenized": "At runtime, these smallest units are overlaid with the desired prosody of the sentence by signal processing techniques such as linear predictive coding, PSOLA", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 17], [18, 26], [27, 32], [33, 36], [37, 45], [46, 50], [51, 54], [55, 62], [63, 70], [71, 73], [74, 77], [78, 86], [87, 89], [90, 96], [97, 107], [108, 118], [119, 123], [124, 126], [127, 133], [134, 144], [145, 151], [151, 152], [153, 158]]}
{"doc_key": "ai-test-23", "ner": [[3, 3, "field"], [6, 8, "field"], [12, 15, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 15, 3, 3, "usage", "", true, false], [12, 15, 6, 8, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "method", "uses", "artificial", "intelligence", "and", "machine", "learning", "to", "visibly", "compare", "conventional", "and", "thermal", "facial", "images", "."], "sentence-detokenized": "The method uses artificial intelligence and machine learning to visibly compare conventional and thermal facial images.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 26], [27, 39], [40, 43], [44, 51], [52, 60], [61, 63], [64, 71], [72, 79], [80, 92], [93, 96], [97, 104], [105, 111], [112, 118], [118, 119]]}
{"doc_key": "ai-test-24", "ner": [[0, 2, "field"], [4, 7, "algorithm"], [12, 15, "task"], [16, 17, "misc"], [24, 24, "field"], [27, 29, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 7, 0, 2, "part-of", "", false, false], [4, 7, 12, 15, "topic", "", false, false], [12, 15, 16, 17, "origin", "", false, false], [24, 24, 0, 2, "part-of", "", false, false], [24, 24, 4, 7, "topic", "", false, false], [27, 29, 0, 2, "part-of", "", false, false], [27, 29, 4, 7, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "computer", "science", ",", "evolutionary", "computation", "is", "a", "set", "of", "algorithms", "for", "global", "optimisation", "inspired", "by", "biological", "evolution", ",", "and", "is", "a", "subfield", "of", "artificial", "intelligence", "and", "soft", "computing", "that", "studies", "these", "algorithms", "."], "sentence-detokenized": "In computer science, evolutionary computation is a set of algorithms for global optimisation inspired by biological evolution, and is a subfield of artificial intelligence and soft computing that studies these algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 33], [34, 45], [46, 48], [49, 50], [51, 54], [55, 57], [58, 68], [69, 72], [73, 79], [80, 92], [93, 101], [102, 104], [105, 115], [116, 125], [125, 126], [127, 130], [131, 133], [134, 135], [136, 144], [145, 147], [148, 158], [159, 171], [172, 175], [176, 180], [181, 190], [191, 195], [196, 203], [204, 209], [210, 220], [220, 221]]}
{"doc_key": "ai-test-25", "ner": [[0, 9, "metrics"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "some", "measure", "based", "on", "the", "confusion", "matrix", "can", "be", "combined", "with", "the", "mean", "squared", "error", "evaluated", "between", "the", "raw", "model", "output", "and", "the", "actual", "values", "."], "sentence-detokenized": "For example, some measure based on the confusion matrix can be combined with the mean squared error evaluated between the raw model output and the actual values.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [18, 25], [26, 31], [32, 34], [35, 38], [39, 48], [49, 55], [56, 59], [60, 62], [63, 71], [72, 76], [77, 80], [81, 85], [86, 93], [94, 99], [100, 109], [110, 117], [118, 121], [122, 125], [126, 131], [132, 138], [139, 142], [143, 146], [147, 153], [154, 160], [160, 161]]}
{"doc_key": "ai-test-26", "ner": [[8, 9, "product"], [12, 12, "researcher"], [18, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 12, 12, "origin", "", false, false], [8, 9, 18, 19, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Most", "of", "the", "results", "are", "due", "to", "the", "word2vec", "model", "developed", "by", "Mikolov", "et", "al", ".", "or", "variants", "of", "word2vec", "."], "sentence-detokenized": "Most of the results are due to the word2vec model developed by Mikolov et al. or variants of word2vec.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 19], [20, 23], [24, 27], [28, 30], [31, 34], [35, 43], [44, 49], [50, 59], [60, 62], [63, 70], [71, 73], [74, 76], [76, 77], [78, 80], [81, 89], [90, 92], [93, 101], [101, 102]]}
{"doc_key": "ai-test-27", "ner": [[16, 22, "conference"]], "ner_mapping_to_source": [2], "relations": [], "relations_mapping_to_source": [], "sentence": ["During", "this", "period", ",", "a", "total", "of", "43", "papers", "were", "evaluated", "at", "the", "CVPR", "and", "the", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "."], "sentence-detokenized": "During this period, a total of 43 papers were evaluated at the CVPR and the International Conference on Computer Vision (ICCV).", "token2charspan": [[0, 6], [7, 11], [12, 18], [18, 19], [20, 21], [22, 27], [28, 30], [31, 33], [34, 40], [41, 45], [46, 55], [56, 58], [59, 62], [63, 67], [68, 71], [72, 75], [76, 89], [90, 100], [101, 103], [104, 112], [113, 119], [120, 121], [121, 125], [125, 126], [126, 127]]}
{"doc_key": "ai-test-28", "ner": [[0, 1, "product"], [11, 12, "field"], [20, 21, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 11, 12, "general-affiliation", "platform_for_education_about", false, false], [20, 21, 0, 1, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["AIBO", "is", "often", "used", "as", "an", "education", "and", "research", "platform", "for", "artificial", "intelligence", ",", "as", "it", "integrates", "a", "computer", ",", "computer", "vision", "and", "articulator", "and", "is", "much", "cheaper", "than", "traditional", "research", "robots", "."], "sentence-detokenized": "AIBO is often used as an education and research platform for artificial intelligence, as it integrates a computer, computer vision and articulator and is much cheaper than traditional research robots.", "token2charspan": [[0, 4], [5, 7], [8, 13], [14, 18], [19, 21], [22, 24], [25, 34], [35, 38], [39, 47], [48, 56], [57, 60], [61, 71], [72, 84], [84, 85], [86, 88], [89, 91], [92, 102], [103, 104], [105, 113], [113, 114], [115, 123], [124, 130], [131, 134], [135, 146], [147, 150], [151, 153], [154, 158], [159, 166], [167, 171], [172, 183], [184, 192], [193, 199], [199, 200]]}
{"doc_key": "ai-test-29", "ner": [[6, 11, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "was", "programme", "chair", "of", "the", "International", "Conference", "on", "Computer", "Vision", "2021", "."], "sentence-detokenized": "He was programme chair of the International Conference on Computer Vision 2021.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 22], [23, 25], [26, 29], [30, 43], [44, 54], [55, 57], [58, 66], [67, 73], [74, 78], [78, 79]]}
{"doc_key": "ai-test-30", "ner": [[0, 0, "researcher"], [5, 5, "organisation"], [7, 11, "organisation"], [20, 22, "organisation"], [35, 37, "product"], [31, 34, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 5, 5, "role", "", false, false], [0, 0, 7, 11, "role", "", true, false], [7, 11, 20, 22, "role", "develops_with", false, false], [35, 37, 7, 11, "artifact", "", false, false], [31, 34, 35, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Scheinman", "received", "a", "fellowship", "from", "Unimation", "and", "sold", "the", "design", "to", "Unimation", ",", "which", "further", "developed", "it", "with", "the", "support", "of", "General", "Motors", "and", "later", "introduced", "it", "to", "the", "market", "as", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", ",", "which", "was", "later", "introduced", "to", "the", "market", "as", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "."], "sentence-detokenized": "Scheinman received a fellowship from Unimation and sold the design to Unimation, which further developed it with the support of General Motors and later introduced it to the market as PUMA (Programmable Universal Machine for Assembly), which was later introduced to the market as PUMA (Programmable Universal Machine for Assembly).", "token2charspan": [[0, 9], [10, 18], [19, 20], [21, 31], [32, 36], [37, 46], [47, 50], [51, 55], [56, 59], [60, 66], [67, 69], [70, 79], [79, 80], [81, 86], [87, 94], [95, 104], [105, 107], [108, 112], [113, 116], [117, 124], [125, 127], [128, 135], [136, 142], [143, 146], [147, 152], [153, 163], [164, 166], [167, 169], [170, 173], [174, 180], [181, 183], [184, 188], [189, 190], [190, 202], [203, 212], [213, 220], [221, 224], [225, 233], [233, 234], [234, 235], [236, 241], [242, 245], [246, 251], [252, 262], [263, 265], [266, 269], [270, 276], [277, 279], [280, 284], [285, 286], [286, 298], [299, 308], [309, 316], [317, 320], [321, 329], [329, 330], [330, 331]]}
{"doc_key": "ai-test-31", "ner": [[6, 6, "task"], [8, 12, "task"], [15, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 15, 6, 6, "general-affiliation", "works_with", false, false], [15, 15, 8, 12, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "overview", "of", "calibration", "methods", "for", "binary", "and", "multi-class", "classification", "classification", "tasks", "is", "given", "by", "Gebel", "(", "2009", ")", "."], "sentence-detokenized": "An overview of calibration methods for binary and multi-class classification classification tasks is given by Gebel (2009).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 34], [35, 38], [39, 45], [46, 49], [50, 61], [62, 76], [77, 91], [92, 97], [98, 100], [101, 106], [107, 109], [110, 115], [116, 117], [117, 121], [121, 122], [122, 123]]}
{"doc_key": "ai-test-32", "ner": [[8, 8, "task"], [7, 11, "task"], [14, 15, "task"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 11, 8, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "involved", "in", "the", "fields", "of", "optical", "character", "recognition", "(", "OCR", ")", ",", "speech", "synthesis", ",", "speech", "recognition", "technology", "and", "electronic", "keyboard", "instruments", "."], "sentence-detokenized": "He is involved in the fields of optical character recognition (OCR), speech synthesis, speech recognition technology and electronic keyboard instruments.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 21], [22, 28], [29, 31], [32, 39], [40, 49], [50, 61], [62, 63], [63, 66], [66, 67], [67, 68], [69, 75], [76, 85], [85, 86], [87, 93], [94, 105], [106, 116], [117, 120], [121, 131], [132, 140], [141, 152], [152, 153]]}
{"doc_key": "ai-test-33", "ner": [[13, 14, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "newer", ",", "state", "-", "of", "-", "the", "-", "art", "technology", ",", "the", "Kaldi", "toolkit", "can", "be", "used", "."], "sentence-detokenized": "For newer, state-of-the-art technology, the Kaldi toolkit can be used.", "token2charspan": [[0, 3], [4, 9], [9, 10], [11, 16], [16, 17], [17, 19], [19, 20], [20, 23], [23, 24], [24, 27], [28, 38], [38, 39], [40, 43], [44, 49], [50, 57], [58, 61], [62, 64], [65, 69], [69, 70]]}
{"doc_key": "ai-test-34", "ner": [[0, 5, "organisation"], [11, 11, "organisation"], [16, 17, "organisation"], [19, 23, "researcher"], [24, 27, "organisation"], [32, 34, "organisation"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Fellow", "of", "the", "American", "Philosophical", "Society", ",", "Fellow", "of", "the", "Royal", "Society", ",", "Fellow", "of", "the", "British", "Academy", ",", "William", "James", "Fellow", "of", "the", "Association", "for", "Psychological", "Science", ",", "Fellow", "of", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Fellow of the American Philosophical Society, Fellow of the Royal Society, Fellow of the British Academy, William James Fellow of the Association for Psychological Science, Fellow of the Cognitive Science Society.", "token2charspan": [[0, 6], [7, 9], [10, 13], [14, 22], [23, 36], [37, 44], [44, 45], [46, 52], [53, 55], [56, 59], [60, 65], [66, 73], [73, 74], [75, 81], [82, 84], [85, 88], [89, 96], [97, 104], [104, 105], [106, 113], [114, 119], [120, 126], [127, 129], [130, 133], [134, 145], [146, 149], [150, 163], [164, 171], [171, 172], [173, 179], [180, 182], [183, 186], [187, 196], [197, 204], [205, 212], [212, 213]]}
{"doc_key": "ai-test-35", "ner": [[3, 8, "conference"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 22, "algorithm"], [25, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6], "relations": [[10, 11, 3, 8, "physical", "", false, false], [10, 11, 3, 8, "temporal", "", false, false], [13, 14, 3, 8, "physical", "", false, false], [13, 14, 3, 8, "temporal", "", false, false], [16, 17, 3, 8, "physical", "", false, false], [16, 17, 3, 8, "temporal", "", false, false], [19, 22, 16, 17, "role", "extends", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["At", "the", "2010", "IEEE", "International", "Conference", "on", "Image", "Processing", ",", "Rui", "Hu", ",", "Mark", "Banard", "and", "John", "Collomosse", "extended", "the", "HOG", "descriptor", "for", "use", "in", "sketch", "-", "based", "image", "retrieval", "(", "SBIR", ")", "."], "sentence-detokenized": "At the 2010 IEEE International Conference on Image Processing, Rui Hu, Mark Banard and John Collomosse extended the HOG descriptor for use in sketch-based image retrieval (SBIR).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 30], [31, 41], [42, 44], [45, 50], [51, 61], [61, 62], [63, 66], [67, 69], [69, 70], [71, 75], [76, 82], [83, 86], [87, 91], [92, 102], [103, 111], [112, 115], [116, 119], [120, 130], [131, 134], [135, 138], [139, 141], [142, 148], [148, 149], [149, 154], [155, 160], [161, 170], [171, 172], [172, 176], [176, 177], [177, 178]]}
{"doc_key": "ai-test-36", "ner": [[0, 1, "metrics"], [15, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 15, 16, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["BLEU", "is", "used", "to", "compare", "candidate", "translations", "with", "multiple", "reference", "translations", "in", "a", "form", "of", "improved", "accuracy", "."], "sentence-detokenized": "BLEU is used to compare candidate translations with multiple reference translations in a form of improved accuracy.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 15], [16, 23], [24, 33], [34, 46], [47, 51], [52, 60], [61, 70], [71, 83], [84, 86], [87, 88], [89, 93], [94, 96], [97, 105], [106, 114], [114, 115]]}
{"doc_key": "ai-test-37", "ner": [[27, 29, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "a", "general", "basis", "space", "math", "(", "Y", ",\\", "mathcal", "{", "B", "},\\", "nu", ")", "/", "math", "(", "i.e.", "a", "non-countable", "basis", "space", ")", ",", "one", "generally", "considers", "relative", "entropy", "."], "sentence-detokenized": "For a general basis space math (Y,\\ mathcal {B},\\ nu) / math (i.e. a non-countable basis space), one generally considers relative entropy.", "token2charspan": [[0, 3], [4, 5], [6, 13], [14, 19], [20, 25], [26, 30], [31, 32], [32, 33], [33, 35], [36, 43], [44, 45], [45, 46], [46, 49], [50, 52], [52, 53], [54, 55], [56, 60], [61, 62], [62, 66], [67, 68], [69, 82], [83, 88], [89, 94], [94, 95], [95, 96], [97, 100], [101, 110], [111, 120], [121, 129], [130, 137], [137, 138]]}
{"doc_key": "ai-test-38", "ner": [[9, 9, "country"], [11, 11, "organisation"], [10, 14, "organisation"], [18, 18, "organisation"], [20, 23, "organisation"], [27, 29, "organisation"], [42, 42, "country"], [32, 35, "organisation"], [36, 41, "organisation"], [49, 49, "misc"], [50, 50, "misc"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[11, 11, 9, 9, "physical", "", false, false], [10, 14, 11, 11, "named", "", false, false], [20, 23, 18, 18, "named", "", false, false], [32, 35, 42, 42, "physical", "", false, false], [36, 41, 32, 35, "named", "", false, false], [49, 49, 50, 50, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 3, 4, 5, 6], "sentence": ["As", "of", "October", "2011", ",", "the", "partnerships", "with", "the", "US", "National", "Park", "Service", "(", "NPS", ")", ",", "Historic", "Scotland", "(", "HS", ")", "in", "the", "UK", ",", "the", "World", "Monuments", "Fund", "and", "the", "National", "Institute", "of", "Anthropology", "and", "History", "(", "INAH", ")", "in", "Mexico", "have", "been", "significantly", "expanded", "and", "the", "CyArk", "website"], "sentence-detokenized": "As of October 2011, the partnerships with the US National Park Service (NPS), Historic Scotland (HS) in the UK, the World Monuments Fund and the National Institute of Anthropology and History (INAH) in Mexico have been significantly expanded and the CyArk website", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 18], [18, 19], [20, 23], [24, 36], [37, 41], [42, 45], [46, 48], [49, 57], [58, 62], [63, 70], [71, 72], [72, 75], [75, 76], [76, 77], [78, 86], [87, 95], [96, 97], [97, 99], [99, 100], [101, 103], [104, 107], [108, 110], [110, 111], [112, 115], [116, 121], [122, 131], [132, 136], [137, 140], [141, 144], [145, 153], [154, 163], [164, 166], [167, 179], [180, 183], [184, 191], [192, 193], [193, 197], [197, 198], [199, 201], [202, 208], [209, 213], [214, 218], [219, 232], [233, 241], [242, 245], [246, 249], [250, 255], [256, 263]]}
{"doc_key": "ai-test-39", "ner": [[0, 2, "algorithm"], [6, 7, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Kernel", "SVMs", "are", "available", "in", "many", "machine", "learning", "toolkits", ",", "such", "as", "LIBSVM", "and", "MATLAB", "."], "sentence-detokenized": "Kernel SVMs are available in many machine learning toolkits, such as LIBSVM and MATLAB.", "token2charspan": [[0, 6], [7, 11], [12, 15], [16, 25], [26, 28], [29, 33], [34, 41], [42, 50], [51, 59], [59, 60], [61, 65], [66, 68], [69, 75], [76, 79], [80, 86], [86, 87]]}
{"doc_key": "ai-test-40", "ner": [[2, 7, "misc"], [12, 14, "location"], [16, 16, "location"], [18, 20, "country"], [23, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 7, 12, 14, "physical", "", false, false], [2, 7, 23, 24, "temporal", "", false, false], [12, 14, 16, 16, "physical", "", false, false], [16, 16, 18, 20, "physical", "", false, false], [23, 24, 12, 14, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "2009", "Loebner", "Prize", "Competition", "was", "held", "on", "6", "September", "2009", "at", "the", "Brighton", "Centre", ",", "Brighton", ",", "UK", ",", "in", "conjunction", "with", "Interspeech", "2009", "."], "sentence-detokenized": "The 2009 Loebner Prize Competition was held on 6 September 2009 at the Brighton Centre, Brighton, UK, in conjunction with Interspeech 2009.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 34], [35, 38], [39, 43], [44, 46], [47, 48], [49, 58], [59, 63], [64, 66], [67, 70], [71, 79], [80, 86], [86, 87], [88, 96], [96, 97], [98, 100], [100, 101], [102, 104], [105, 116], [117, 121], [122, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-test-41", "ner": [[2, 3, "product"], [9, 10, "product"], [17, 19, "product"], [20, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[20, 22, 2, 3, "part-of", "", false, false], [20, 22, 9, 10, "part-of", "", false, false], [20, 22, 17, 19, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "humanoid", "robot", "QRIO", ",", "developed", "as", "a", "successor", "to", "AIBO", ",", "is", "based", "on", "the", "same", "R", "-", "CODE", "Aperios", "operating", "system", "."], "sentence-detokenized": "The humanoid robot QRIO, developed as a successor to AIBO, is based on the same R-CODE Aperios operating system.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 23], [23, 24], [25, 34], [35, 37], [38, 39], [40, 49], [50, 52], [53, 57], [57, 58], [59, 61], [62, 67], [68, 70], [71, 74], [75, 79], [80, 81], [81, 82], [82, 86], [87, 94], [95, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-42", "ner": [[0, 3, "misc"], [7, 7, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 0, 3, "cause-effect", "", true, false], [12, 13, 0, 3, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "speech", "waveform", "is", "generated", "from", "the", "HMM", "itself", "based", "on", "the", "maximum", "likelihood", "criterion", "."], "sentence-detokenized": "The speech waveform is generated from the HMM itself based on the maximum likelihood criterion.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 22], [23, 32], [33, 37], [38, 41], [42, 45], [46, 52], [53, 58], [59, 61], [62, 65], [66, 73], [74, 84], [85, 94], [94, 95]]}
{"doc_key": "ai-test-43", "ner": [[0, 3, "product"], [5, 6, "task"], [8, 10, "task"], [12, 15, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 5, 6, "type-of", "", false, false], [0, 3, 8, 10, "type-of", "", false, false], [0, 3, 12, 15, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "is", "a", "free", "multilingual", "statistical", "and", "neural", "machine", "translation", "service", "developed", "by", "Google", "to", "translate", "text", "and", "websites", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Google Translate is a free multilingual statistical and neural machine translation service developed by Google to translate text and websites from one language to another.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 39], [40, 51], [52, 55], [56, 62], [63, 70], [71, 82], [83, 90], [91, 100], [101, 103], [104, 110], [111, 113], [114, 123], [124, 128], [129, 132], [133, 141], [142, 146], [147, 150], [151, 159], [160, 162], [163, 170], [170, 171]]}
{"doc_key": "ai-test-44", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [14, 16, "field"], [21, 23, "task"], [25, 26, "task"], [17, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[21, 23, 5, 6, "part-of", "", false, true], [21, 23, 8, 9, "part-of", "", false, true], [21, 23, 11, 12, "part-of", "", false, true], [25, 26, 5, 6, "part-of", "", false, true], [25, 26, 8, 9, "part-of", "", false, true], [25, 26, 11, 12, "part-of", "", false, true], [17, 31, 5, 6, "part-of", "", false, true], [17, 31, 8, 9, "part-of", "", false, true], [17, 31, 11, 12, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Skeletons", "are", "widely", "used", "in", "computer", "vision", ",", "image", "analysis", ",", "pattern", "recognition", "and", "digital", "image", "processing", "for", "purposes", "such", "as", "optical", "character", "recognition", ",", "fingerprint", "recognition", ",", "visual", "inspection", "and", "compression", "."], "sentence-detokenized": "Skeletons are widely used in computer vision, image analysis, pattern recognition and digital image processing for purposes such as optical character recognition, fingerprint recognition, visual inspection and compression.", "token2charspan": [[0, 9], [10, 13], [14, 20], [21, 25], [26, 28], [29, 37], [38, 44], [44, 45], [46, 51], [52, 60], [60, 61], [62, 69], [70, 81], [82, 85], [86, 93], [94, 99], [100, 110], [111, 114], [115, 123], [124, 128], [129, 131], [132, 139], [140, 149], [150, 161], [161, 162], [163, 174], [175, 186], [186, 187], [188, 194], [195, 205], [206, 209], [210, 221], [221, 222]]}
{"doc_key": "ai-test-45", "ner": [[0, 8, "conference"], [10, 14, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 8, 10, 14, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "is", "a", "benchmark", "for", "object", "classification", "and", "detection", ",", "consisting", "of", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "The ImageNet Large Scale Visual Recognition Challenge is a benchmark for object classification and detection, consisting of millions of images and hundreds of object classes.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 24], [25, 31], [32, 43], [44, 53], [54, 56], [57, 58], [59, 68], [69, 72], [73, 79], [80, 94], [95, 98], [99, 108], [108, 109], [110, 120], [121, 123], [124, 132], [133, 135], [136, 142], [143, 146], [147, 155], [156, 158], [159, 165], [166, 173], [173, 174]]}
{"doc_key": "ai-test-46", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [2, 10, "researcher"], [18, 18, "misc"], [11, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 18, 18, "part-of", "", false, false], [0, 0, 11, 24, "part-of", "", false, false], [4, 5, 18, 18, "part-of", "", false, false], [4, 5, 11, 24, "part-of", "", false, false], [2, 10, 18, 18, "part-of", "", false, false], [2, 10, 11, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Bengio", ",", "along", "with", "Jeffrey", "Hinton", "and", "Jan", "Lukun", ",", "is", "sometimes", "referred", "to", "as", "the", "Godfather", "of", "AI", "and", "the", "Godfather", "of", "Deep", "Learning", "."], "sentence-detokenized": "Bengio, along with Jeffrey Hinton and Jan Lukun, is sometimes referred to as the Godfather of AI and the Godfather of Deep Learning.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 18], [19, 26], [27, 33], [34, 37], [38, 41], [42, 47], [47, 48], [49, 51], [52, 61], [62, 70], [71, 73], [74, 76], [77, 80], [81, 90], [91, 93], [94, 96], [97, 100], [101, 104], [105, 114], [115, 117], [118, 122], [123, 131], [131, 132]]}
{"doc_key": "ai-test-47", "ner": [[7, 7, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "Life", "Fellow", "of", "the", "IEEE", "."], "sentence-detokenized": "He is a Life Fellow of the IEEE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 19], [20, 22], [23, 26], [27, 31], [31, 32]]}
{"doc_key": "ai-test-48", "ner": [[0, 2, "organisation"], [14, 19, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 14, 19, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NSA", "Bethesda", "is", "responsible", "for", "base", "operational", "support", "to", "its", "main", "tenant", ",", "the", "Walter", "Reed", "National", "Military", "Medical", "Centre", "."], "sentence-detokenized": "NSA Bethesda is responsible for base operational support to its main tenant, the Walter Reed National Military Medical Centre.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 31], [32, 36], [37, 48], [49, 56], [57, 59], [60, 63], [64, 68], [69, 75], [75, 76], [77, 80], [81, 87], [88, 92], [93, 101], [102, 110], [111, 118], [119, 125], [125, 126]]}
{"doc_key": "ai-test-49", "ner": [[7, 8, "field"], [10, 11, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "three", "main", "learning", "paradigms", ":", "supervised", "learning", ",", "unsupervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "There are three main learning paradigms: supervised learning, unsupervised learning and reinforcement learning.", "token2charspan": [[0, 5], [6, 9], [10, 15], [16, 20], [21, 29], [30, 39], [39, 40], [41, 51], [52, 60], [60, 61], [62, 74], [75, 83], [84, 87], [88, 101], [102, 110], [110, 111]]}
{"doc_key": "ai-test-50", "ner": [[2, 2, "task"], [4, 6, "task"], [8, 15, "task"], [18, 18, "task"], [20, 22, "task"], [24, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Examples", "include", "control", ",", "planning", ",", "scheduling", ",", "diagnostics", "and", "the", "ability", "to", "answer", "consumer", "questions", ",", "handwriting", "recognition", ",", "natural", "language", "understanding", ",", "speech", "recognition", "and", "facial", "recognition", "."], "sentence-detokenized": "Examples include control, planning, scheduling, diagnostics and the ability to answer consumer questions, handwriting recognition, natural language understanding, speech recognition and facial recognition.", "token2charspan": [[0, 8], [9, 16], [17, 24], [24, 25], [26, 34], [34, 35], [36, 46], [46, 47], [48, 59], [60, 63], [64, 67], [68, 75], [76, 78], [79, 85], [86, 94], [95, 104], [104, 105], [106, 117], [118, 129], [129, 130], [131, 138], [139, 147], [148, 161], [161, 162], [163, 169], [170, 181], [182, 185], [186, 192], [193, 204], [204, 205]]}
{"doc_key": "ai-test-51", "ner": [[10, 13, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1991", ",", "he", "was", "elected", "a", "Fellow", "of", "the", "Society", "for", "Artificial", "Intelligence", "(", "1990", ",", "Founding", "Fellow", ")", "."], "sentence-detokenized": "In 1991, he was elected a Fellow of the Society for Artificial Intelligence (1990, Founding Fellow).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 47], [48, 51], [52, 62], [63, 75], [76, 77], [77, 81], [81, 82], [83, 91], [92, 98], [98, 99], [99, 100]]}
{"doc_key": "ai-test-52", "ner": [[10, 12, "misc"], [14, 18, "algorithm"], [22, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "by", "formulating", "the", "problem", "as", "a", "solution", "to", "the", "Toeplitz", "matrix", "and", "using", "Levinson", "recursion", ",", "a", "filter", "with", "as", "small", "a", "mean", "squared", "error", "as", "possible", "can", "be", "estimated", "relatively", "quickly", "."], "sentence-detokenized": "However, by formulating the problem as a solution to the Toeplitz matrix and using Levinson recursion, a filter with as small a mean squared error as possible can be estimated relatively quickly.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 23], [24, 27], [28, 35], [36, 38], [39, 40], [41, 49], [50, 52], [53, 56], [57, 65], [66, 72], [73, 76], [77, 82], [83, 91], [92, 101], [101, 102], [103, 104], [105, 111], [112, 116], [117, 119], [120, 125], [126, 127], [128, 132], [133, 140], [141, 146], [147, 149], [150, 158], [159, 162], [163, 165], [166, 175], [176, 186], [187, 194], [194, 195]]}
{"doc_key": "ai-test-53", "ner": [[5, 12, "conference"], [13, 19, "location"], [20, 20, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 12, 13, 19, "physical", "", false, false], [13, 19, 20, 20, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2011", ",", "the", "15th", "Campus", "Party", "Spain", "will", "take", "place", "in", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", "."], "sentence-detokenized": "In July 2011, the 15th Campus Party Spain will take place in the City of Arts and Sciences in Valencia.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 22], [23, 29], [30, 35], [36, 41], [42, 46], [47, 51], [52, 57], [58, 60], [61, 64], [65, 69], [70, 72], [73, 77], [78, 81], [82, 90], [91, 93], [94, 102], [102, 103]]}
{"doc_key": "ai-test-54", "ner": [[19, 19, "product"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "many", "cases", ",", "this", "is", "generally", "only", "possible", "at", "the", "end", "of", "complex", "games", "such", "as", "chess", "or", "Go", ".", "This", "is", "because", "it", "is", "computationally", "impossible", "to", "look", "ahead", "to", "the", "completion", "of", "the", "game", ",", "except", "towards", "the", "end", ",", "and", "instead", "a", "finite", "value", "is", "given", "to", "the", "position", "as", "an", "estimate", "of", "the", "degree", "to", "which", "one", "believes", "it", "will", "bring", "victory", "to", "one", "player", "or", "another", "."], "sentence-detokenized": "In many cases, this is generally only possible at the end of complex games such as chess or Go. This is because it is computationally impossible to look ahead to the completion of the game, except towards the end, and instead a finite value is given to the position as an estimate of the degree to which one believes it will bring victory to one player or another.", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 19], [20, 22], [23, 32], [33, 37], [38, 46], [47, 49], [50, 53], [54, 57], [58, 60], [61, 68], [69, 74], [75, 79], [80, 82], [83, 88], [89, 91], [92, 94], [94, 95], [96, 100], [101, 103], [104, 111], [112, 114], [115, 117], [118, 133], [134, 144], [145, 147], [148, 152], [153, 158], [159, 161], [162, 165], [166, 176], [177, 179], [180, 183], [184, 188], [188, 189], [190, 196], [197, 204], [205, 208], [209, 212], [212, 213], [214, 217], [218, 225], [226, 227], [228, 234], [235, 240], [241, 243], [244, 249], [250, 252], [253, 256], [257, 265], [266, 268], [269, 271], [272, 280], [281, 283], [284, 287], [288, 294], [295, 297], [298, 303], [304, 307], [308, 316], [317, 319], [320, 324], [325, 330], [331, 338], [339, 341], [342, 345], [346, 352], [353, 355], [356, 363], [363, 364]]}
{"doc_key": "ai-test-55", "ner": [[3, 3, "algorithm"], [18, 19, "algorithm"], [25, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[3, 3, 18, 19, "compare", "", false, false], [3, 3, 25, 29, "compare", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["Differences", "between", "the", "multinomial", "logit", "model", "and", "many", "other", "methods", ",", "models", ",", "algorithms", ",", "etc.", "(", "e.g.", "perceptron", "algorithms", ",", "support", "vector", "machines", ",", "linear", "discriminant", "analysis", ")", "that", "have", "the", "same", "basic", "setup", "."], "sentence-detokenized": "Differences between the multinomial logit model and many other methods, models, algorithms, etc. (e.g. perceptron algorithms, support vector machines, linear discriminant analysis) that have the same basic setup.", "token2charspan": [[0, 11], [12, 19], [20, 23], [24, 35], [36, 41], [42, 47], [48, 51], [52, 56], [57, 62], [63, 70], [70, 71], [72, 78], [78, 79], [80, 90], [90, 91], [92, 96], [97, 98], [98, 102], [103, 113], [114, 124], [124, 125], [126, 133], [134, 140], [141, 149], [149, 150], [151, 157], [158, 170], [171, 179], [179, 180], [181, 185], [186, 190], [191, 194], [195, 199], [200, 205], [206, 211], [211, 212]]}
{"doc_key": "ai-test-56", "ner": [[3, 6, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Published", "by", "the", "Association", "for", "Computational", "Linguistics"], "sentence-detokenized": "Published by the Association for Computational Linguistics", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 28], [29, 32], [33, 46], [47, 58]]}
{"doc_key": "ai-test-57", "ner": [[2, 3, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "computerised", "face", "recognition", ",", "each", "face", "is", "represented", "by", "a", "number", "of", "pixel", "values", "."], "sentence-detokenized": "In computerised face recognition, each face is represented by a number of pixel values.", "token2charspan": [[0, 2], [3, 15], [16, 20], [21, 32], [32, 33], [34, 38], [39, 43], [44, 46], [47, 58], [59, 61], [62, 63], [64, 70], [71, 73], [74, 79], [80, 86], [86, 87]]}
{"doc_key": "ai-test-58", "ner": [[5, 6, "person"], [10, 16, "organisation"], [21, 21, "country"], [24, 26, "person"], [31, 36, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 10, 16, "role", "", false, false], [5, 6, 21, 21, "physical", "", false, false], [24, 26, 31, 36, "origin", "", false, false], [24, 26, 31, 36, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2002", ",", "her", "son", "Daniel", "Pearl", ",", "a", "reporter", "for", "The", "Wall", "Street", "Journal", ",", "was", "abducted", "and", "murdered", "in", "Pakistan", ",", "leading", "Judea", "and", "other", "family", "members", "and", "friends", "to", "establish", "the", "Daniel", "Pearl", "Foundation", "."], "sentence-detokenized": "In 2002, her son Daniel Pearl, a reporter for The Wall Street Journal, was abducted and murdered in Pakistan, leading Judea and other family members and friends to establish the Daniel Pearl Foundation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 23], [24, 29], [29, 30], [31, 32], [33, 41], [42, 45], [46, 49], [50, 54], [55, 61], [62, 69], [69, 70], [71, 74], [75, 83], [84, 87], [88, 96], [97, 99], [100, 108], [108, 109], [110, 117], [118, 123], [124, 127], [128, 133], [134, 140], [141, 148], [149, 152], [153, 160], [161, 163], [164, 173], [174, 177], [178, 184], [185, 190], [191, 201], [201, 202]]}
{"doc_key": "ai-test-59", "ner": [[7, 9, "organisation"], [17, 21, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 9, 17, 21, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "of", "the", "end", "of", "2006", ",", "Red", "Envelope", "Entertainment", "has", "expanded", "into", "original", "content", "production", "with", "filmmakers", "such", "as", "John", "Waters", "."], "sentence-detokenized": "As of the end of 2006, Red Envelope Entertainment has expanded into original content production with filmmakers such as John Waters.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 13], [14, 16], [17, 21], [21, 22], [23, 26], [27, 35], [36, 49], [50, 53], [54, 62], [63, 67], [68, 76], [77, 84], [85, 95], [96, 100], [101, 111], [112, 116], [117, 119], [120, 124], [125, 131], [131, 132]]}
{"doc_key": "ai-test-60", "ner": [[6, 11, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "building", "is", "now", "part", "of", "the", "Beth", "Israel", "Deaconess", "Medical", "Centre", "."], "sentence-detokenized": "The building is now part of the Beth Israel Deaconess Medical Centre.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 31], [32, 36], [37, 43], [44, 53], [54, 61], [62, 68], [68, 69]]}
{"doc_key": "ai-test-61", "ner": [[19, 19, "field"], [22, 22, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "common", "theme", "in", "this", "work", "is", "the", "incorporation", "of", "a", "sign", "-", "theoretic", "perspective", "into", "the", "problems", "of", "artificial", "intelligence", "and", "knowledge", "representation", "."], "sentence-detokenized": "A common theme in this work is the incorporation of a sign-theoretic perspective into the problems of artificial intelligence and knowledge representation.", "token2charspan": [[0, 1], [2, 8], [9, 14], [15, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 48], [49, 51], [52, 53], [54, 58], [58, 59], [59, 68], [69, 80], [81, 85], [86, 89], [90, 98], [99, 101], [102, 112], [113, 125], [126, 129], [130, 139], [140, 154], [154, 155]]}
{"doc_key": "ai-test-62", "ner": [[0, 3, "task"], [5, 9, "task"], [19, 19, "task"], [48, 48, "task"], [46, 52, "task"], [39, 43, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6], "relations": [[0, 3, 19, 19, "type-of", "", false, false], [5, 9, 0, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 3], "sentence": ["For", "example", ",", "the", "term", "neural", "machine", "translation", "(", "NMT", ")", "emphasises", "the", "fact", "that", "deep", "learning", "-", "based", "machine", "translation", "approaches", "learn", "sequence", "-", "to", "-", "sequence", "transformations", "directly", ",", "eliminating", "the", "need", "for", "intermediate", "steps", "used", "in", "statistical", "machine", "translation", "(", "SMT", ")", ",", "such", "as", "word", "alignment", "and", "language", "modelling", "."], "sentence-detokenized": "For example, the term neural machine translation (NMT) emphasises the fact that deep learning-based machine translation approaches learn sequence-to-sequence transformations directly, eliminating the need for intermediate steps used in statistical machine translation (SMT), such as word alignment and language modelling.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 36], [37, 48], [49, 50], [50, 53], [53, 54], [55, 65], [66, 69], [70, 74], [75, 79], [80, 84], [85, 93], [93, 94], [94, 99], [100, 107], [108, 119], [120, 130], [131, 136], [137, 145], [145, 146], [146, 148], [148, 149], [149, 157], [158, 173], [174, 182], [182, 183], [184, 195], [196, 199], [200, 204], [205, 208], [209, 221], [222, 227], [228, 232], [233, 235], [236, 247], [248, 255], [256, 267], [268, 269], [269, 272], [272, 273], [273, 274], [275, 279], [280, 282], [283, 287], [288, 297], [298, 301], [302, 310], [311, 320], [320, 321]]}
{"doc_key": "ai-test-63", "ner": [[3, 4, "field"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 12, 13, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "the", "field", "of", "WSD", ",", "most", "research", "has", "been", "conducted", "using", "Word", "Net", "as", "a", "reference", "glossary", "."], "sentence-detokenized": "In the field of WSD, most research has been conducted using WordNet as a reference glossary.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 19], [19, 20], [21, 25], [26, 34], [35, 38], [39, 43], [44, 53], [54, 59], [60, 64], [64, 67], [68, 70], [71, 72], [73, 82], [83, 91], [91, 92]]}
{"doc_key": "ai-test-64", "ner": [[1, 2, "misc"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 1, 2, "general-affiliation", "", false, true], [14, 15, 1, 2, "general-affiliation", "", false, true]], "relations_mapping_to_source": [0, 1], "sentence": ["Prominent", "former", "PhD", "students", "and", "post-doctoral", "researchers", "in", "his", "group", "include", "Richard", "Zemel", "and", "Zubin", "Ghahramani", "."], "sentence-detokenized": "Prominent former PhD students and post-doctoral researchers in his group include Richard Zemel and Zubin Ghahramani.", "token2charspan": [[0, 9], [10, 16], [17, 20], [21, 29], [30, 33], [34, 47], [48, 59], [60, 62], [63, 66], [67, 72], [73, 80], [81, 88], [89, 94], [95, 98], [99, 104], [105, 115], [115, 116]]}
{"doc_key": "ai-test-65", "ner": [[7, 7, "metrics"], [15, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 7, 15, 15, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Each", "prediction", "result", "or", "instance", "of", "the", "confusion", "matrix", "represents", "a", "single", "point", "in", "the", "ROC", "space", "."], "sentence-detokenized": "Each prediction result or instance of the confusion matrix represents a single point in the ROC space.", "token2charspan": [[0, 4], [5, 15], [16, 22], [23, 25], [26, 34], [35, 37], [38, 41], [42, 51], [52, 58], [59, 69], [70, 71], [72, 78], [79, 84], [85, 87], [88, 91], [92, 95], [96, 101], [101, 102]]}
{"doc_key": "ai-test-66", "ner": [[13, 13, "researcher"], [0, 11, "researcher"], [19, 22, "product"], [24, 26, "location"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[13, 13, 24, 26, "physical", "", false, false], [0, 11, 24, 26, "physical", "", false, false], [19, 22, 13, 13, "artifact", "", false, false], [19, 22, 0, 11, "artifact", "", false, false], [19, 22, 24, 26, "physical", "", false, false]], "relations_mapping_to_source": [0, 2, 3, 5, 6], "sentence": ["In", "1997", ",", "together", "with", "his", "colleagues", "Wolfram", "Baggard", "and", "Dieter", "Fox", ",", "Thrun", "developed", "the", "world", "'s", "first", "robotic", "tour", "guide", "at", "the", "Deutsches", "Museum", "Bonn", "(", "1997", ")", "."], "sentence-detokenized": "In 1997, together with his colleagues Wolfram Baggard and Dieter Fox, Thrun developed the world's first robotic tour guide at the Deutsches Museum Bonn (1997).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 17], [18, 22], [23, 26], [27, 37], [38, 45], [46, 53], [54, 57], [58, 64], [65, 68], [68, 69], [70, 75], [76, 85], [86, 89], [90, 95], [95, 97], [98, 103], [104, 111], [112, 116], [117, 122], [123, 125], [126, 129], [130, 139], [140, 146], [147, 151], [152, 153], [153, 157], [157, 158], [158, 159]]}
{"doc_key": "ai-test-67", "ner": [[0, 2, "product"], [7, 9, "misc"], [20, 21, "field"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 9, 0, 2, "part-of", "", false, false], [20, 21, 0, 2, "usage", "", false, false], [24, 25, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Word", "Net", "is", "a", "lexical", "database", "of", "semantic", "relations", "between", "words", "in", "over", "200", "languages", ",", "used", "primarily", "in", "automated", "natural", "language", "processing", "and", "artificial", "intelligence", "applications", "."], "sentence-detokenized": "WordNet is a lexical database of semantic relations between words in over 200 languages, used primarily in automated natural language processing and artificial intelligence applications.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 32], [33, 41], [42, 51], [52, 59], [60, 65], [66, 68], [69, 73], [74, 77], [78, 87], [87, 88], [89, 93], [94, 103], [104, 106], [107, 116], [117, 124], [125, 133], [134, 144], [145, 148], [149, 159], [160, 172], [173, 185], [185, 186]]}
{"doc_key": "ai-test-68", "ner": [[4, 7, "field"], [12, 25, "conference"], [27, 27, "conference"], [9, 31, "conference"], [32, 39, "field"]], "ner_mapping_to_source": [0, 2, 3, 4, 5], "relations": [[12, 25, 4, 7, "topic", "", false, false], [12, 25, 32, 39, "topic", "", false, false], [27, 27, 4, 7, "topic", "", false, false], [27, 27, 32, 39, "topic", "", false, false], [9, 31, 4, 7, "topic", "", false, false], [9, 31, 32, 39, "topic", "", false, false]], "relations_mapping_to_source": [2, 3, 4, 5, 6, 7], "sentence": ["Conferences", "in", "the", "field", "of", "natural", "language", "processing", ",", "such", "as", "the", "Association", "for", "Computational", "Linguistics", ",", "North", "American", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "EMNLP", "and", "HLT", ",", "are", "Papers", "on", "speech", "processing", "are", "beginning", "to", "appear", "."], "sentence-detokenized": "Conferences in the field of natural language processing, such as the Association for Computational Linguistics, North American Chapter of the Association for Computational Linguistics, EMNLP and HLT, are Papers on speech processing are beginning to appear.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 24], [25, 27], [28, 35], [36, 44], [45, 55], [55, 56], [57, 61], [62, 64], [65, 68], [69, 80], [81, 84], [85, 98], [99, 110], [110, 111], [112, 117], [118, 126], [127, 134], [135, 137], [138, 141], [142, 153], [154, 157], [158, 171], [172, 183], [183, 184], [185, 190], [191, 194], [195, 198], [198, 199], [200, 203], [204, 210], [211, 213], [214, 220], [221, 231], [232, 235], [236, 245], [246, 248], [249, 255], [255, 256]]}
{"doc_key": "ai-test-69", "ner": [[8, 10, "misc"]], "ner_mapping_to_source": [2], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "vocabulary", "is", "useful", "for", "web", "searches", "and", "electronic", "medical", "record", "searches", "."], "sentence-detokenized": "This vocabulary is useful for web searches and electronic medical record searches.", "token2charspan": [[0, 4], [5, 15], [16, 18], [19, 25], [26, 29], [30, 33], [34, 42], [43, 46], [47, 57], [58, 65], [66, 72], [73, 81], [81, 82]]}
{"doc_key": "ai-test-70", "ner": [[9, 9, "algorithm"], [11, 11, "algorithm"], [13, 13, "algorithm"], [15, 15, "algorithm"], [17, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "days", ",", "there", "are", "many", "algorithms", "such", "as", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", ",", ",", ",", ",", "etc", "."], "sentence-detokenized": "These days, there are many algorithms such as LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost,,,, etc.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 17], [18, 21], [22, 26], [27, 37], [38, 42], [43, 45], [46, 53], [53, 54], [55, 65], [65, 66], [67, 77], [77, 78], [79, 86], [86, 87], [88, 97], [97, 98], [98, 99], [99, 100], [100, 101], [102, 105], [105, 106]]}
{"doc_key": "ai-test-71", "ner": [[2, 3, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Example", "implementation", "in", "Python", "."], "sentence-detokenized": "Example implementation in Python.", "token2charspan": [[0, 7], [8, 22], [23, 25], [26, 32], [32, 33]]}
{"doc_key": "ai-test-72", "ner": [[5, 5, "organisation"], [0, 10, "task"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Intellivision", "game", "console", "from", "Mattel", "offered", "the", "Intellivoice", "speech", "synthesis", "module", "in", "1982", "."], "sentence-detokenized": "The Intellivision game console from Mattel offered the Intellivoice speech synthesis module in 1982.", "token2charspan": [[0, 3], [4, 17], [18, 22], [23, 30], [31, 35], [36, 42], [43, 50], [51, 54], [55, 67], [68, 74], [75, 84], [85, 91], [92, 94], [95, 99], [99, 100]]}
{"doc_key": "ai-test-73", "ner": [[0, 6, "task"], [7, 11, "task"], [15, 16, "field"], [17, 19, "task"], [21, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 11, 0, 6, "part-of", "", false, false], [15, 16, 0, 6, "part-of", "", false, false], [17, 19, 0, 6, "part-of", "", false, false], [21, 26, 17, 19, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["They", "also", "worked", "on", "machine", "translation", "for", "highly", "accurate", "knowledge", "-", "based", "MT", "and", "machine", "learning", "for", "statistical", "machine", "translation", "(", "e.g.", "generalised", "example", "-", "based", "MT", ")", "."], "sentence-detokenized": "They also worked on machine translation for highly accurate knowledge-based MT and machine learning for statistical machine translation (e.g. generalised example-based MT).", "token2charspan": [[0, 4], [5, 9], [10, 16], [17, 19], [20, 27], [28, 39], [40, 43], [44, 50], [51, 59], [60, 69], [69, 70], [70, 75], [76, 78], [79, 82], [83, 90], [91, 99], [100, 103], [104, 115], [116, 123], [124, 135], [136, 137], [137, 141], [142, 153], [154, 161], [161, 162], [162, 167], [168, 170], [170, 171], [171, 172]]}
{"doc_key": "ai-test-74", "ner": [[0, 1, "misc"], [6, 7, "misc"], [28, 29, "algorithm"], [31, 32, "field"], [34, 35, "field"], [37, 37, "field"], [39, 40, "field"], [43, 43, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 28, 29, "general-affiliation", "", false, false], [0, 1, 31, 32, "general-affiliation", "", false, false], [0, 1, 34, 35, "general-affiliation", "", false, false], [0, 1, 37, 37, "general-affiliation", "", false, false], [0, 1, 39, 40, "general-affiliation", "", false, false], [0, 1, 43, 43, "general-affiliation", "", false, false], [6, 7, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "usually", "referred", "to", "as", "Mathematica", ")", "is", "a", "state", "-", "of", "-", "the", "-", "art", "technical", "computing", "system", "that", "covers", "most", "technical", "areas", "such", "as", "neural", "networks", ",", "machine", "learning", ",", "image", "processing", ",", "geometry", ",", "data", "science", ",", "and", "visualisation", "."], "sentence-detokenized": "Wolfram Mathematica (usually referred to as Mathematica) is a state-of-the-art technical computing system that covers most technical areas such as neural networks, machine learning, image processing, geometry, data science, and visualisation.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 28], [29, 37], [38, 40], [41, 43], [44, 55], [55, 56], [57, 59], [60, 61], [62, 67], [67, 68], [68, 70], [70, 71], [71, 74], [74, 75], [75, 78], [79, 88], [89, 98], [99, 105], [106, 110], [111, 117], [118, 122], [123, 132], [133, 138], [139, 143], [144, 146], [147, 153], [154, 162], [162, 163], [164, 171], [172, 180], [180, 181], [182, 187], [188, 198], [198, 199], [200, 208], [208, 209], [210, 214], [215, 222], [222, 223], [224, 227], [228, 241], [241, 242]]}
{"doc_key": "ai-test-75", "ner": [[2, 7, "product"], [9, 12, "researcher"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 19, 2, 7, "type-of", "", false, false], [19, 19, 9, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "digitally", "operated", "and", "programmable", "robot", "was", "invented", "by", "George", "Debor", "in", "1954", "and", "was", "eventually", "called", "'", "Unimate", "'", "."], "sentence-detokenized": "The first digitally operated and programmable robot was invented by George Debor in 1954 and was eventually called 'Unimate'.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 28], [29, 32], [33, 45], [46, 51], [52, 55], [56, 64], [65, 67], [68, 74], [75, 80], [81, 83], [84, 88], [89, 92], [93, 96], [97, 107], [108, 114], [115, 116], [116, 123], [123, 124], [124, 125]]}
{"doc_key": "ai-test-76", "ner": [[0, 1, "algorithm"], [3, 4, "algorithm"], [25, 25, "task"], [22, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 3, 4, "compare", "", false, false], [3, 4, 25, 25, "general-affiliation", "", false, false], [3, 4, 22, 29, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Like", "DBNs", ",", "DBMs", "can", "use", "a", "limited", "amount", "of", "labelled", "data", "to", "learn", "complex", ",", "abstract", "internal", "representations", "of", "inputs", "in", "tasks", "such", "as", "object", "recognition", "and", "speech", "recognition", ",", "fine", "-", "tuning", "representations", "built", "using", "large", "amounts", "of", "unlabelled", "sensory", "input", "data", "."], "sentence-detokenized": "Like DBNs, DBMs can use a limited amount of labelled data to learn complex, abstract internal representations of inputs in tasks such as object recognition and speech recognition, fine-tuning representations built using large amounts of unlabelled sensory input data.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 15], [16, 19], [20, 23], [24, 25], [26, 33], [34, 40], [41, 43], [44, 52], [53, 57], [58, 60], [61, 66], [67, 74], [74, 75], [76, 84], [85, 93], [94, 109], [110, 112], [113, 119], [120, 122], [123, 128], [129, 133], [134, 136], [137, 143], [144, 155], [156, 159], [160, 166], [167, 178], [178, 179], [180, 184], [184, 185], [185, 191], [192, 207], [208, 213], [214, 219], [220, 225], [226, 233], [234, 236], [237, 247], [248, 255], [256, 261], [262, 266], [266, 267]]}
{"doc_key": "ai-test-77", "ner": [[2, 9, "task"], [16, 16, "conference"]], "ner_mapping_to_source": [0, 2], "relations": [[16, 16, 2, 9, "topic", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Conferences", "where", "research", "on", "vision", "-", "based", "activity", "recognition", "is", "often", "conducted", "are", "the", "ICCV", "and", "CVPR", "."], "sentence-detokenized": "Conferences where research on vision-based activity recognition is often conducted are the ICCV and CVPR.", "token2charspan": [[0, 11], [12, 17], [18, 26], [27, 29], [30, 36], [36, 37], [37, 42], [43, 51], [52, 63], [64, 66], [67, 72], [73, 82], [83, 86], [87, 90], [91, 95], [96, 99], [100, 104], [104, 105]]}
{"doc_key": "ai-test-78", "ner": [[0, 1, "field"], [4, 11, "algorithm"], [17, 17, "metrics"], [15, 27, "metrics"], [39, 39, "misc"]], "ner_mapping_to_source": [0, 2, 3, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "statistics", ",", "the", "expectation", "-maximisation", "(", "EM", ")", "algorithm", "is", "an", "iterative", "method", "for", "obtaining", "maximum", "likelihood", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "estimates", "of", "the", "parameters", "of", "a", "statistical", "model", "where", "the", "model", "depends", "on", "unobserved", "latent", "variables", "."], "sentence-detokenized": "In statistics, the expectation-maximisation (EM) algorithm is an iterative method for obtaining maximum likelihood or maximum a posteriori (MAP) estimates of the parameters of a statistical model where the model depends on unobserved latent variables.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 30], [30, 43], [44, 45], [45, 47], [47, 48], [49, 58], [59, 61], [62, 64], [65, 74], [75, 81], [82, 85], [86, 95], [96, 103], [104, 114], [115, 117], [118, 125], [126, 127], [128, 138], [139, 140], [140, 143], [143, 144], [145, 154], [155, 157], [158, 161], [162, 172], [173, 175], [176, 177], [178, 189], [190, 195], [196, 201], [202, 205], [206, 211], [212, 219], [220, 222], [223, 233], [234, 240], [241, 250], [250, 251]]}
{"doc_key": "ai-test-79", "ner": [[10, 10, "metrics"], [15, 15, "metrics"], [13, 17, "metrics"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[13, 17, 15, 15, "named", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Similarly", ",", "investigators", "may", "also", "report", "false", "positive", "rates", "(", "FPR", ")", "and", "false", "negative", "rates", "(", "FNR", ")", "."], "sentence-detokenized": "Similarly, investigators may also report false positive rates (FPR) and false negative rates (FNR).", "token2charspan": [[0, 9], [9, 10], [11, 24], [25, 28], [29, 33], [34, 40], [41, 46], [47, 55], [56, 61], [62, 63], [63, 66], [66, 67], [68, 71], [72, 77], [78, 86], [87, 92], [93, 94], [94, 97], [97, 98], [98, 99]]}
{"doc_key": "ai-test-80", "ner": [[6, 10, "metrics"], [12, 14, "field"], [17, 18, "metrics"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 14, 6, 10, "usage", "", false, false], [21, 22, 17, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "concept", "is", "similar", "to", "the", "signal", "-", "to", "-", "noise", "ratio", "used", "in", "science", "and", "the", "confusion", "matrix", "used", "in", "artificial", "intelligence", "."], "sentence-detokenized": "The concept is similar to the signal-to-noise ratio used in science and the confusion matrix used in artificial intelligence.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 25], [26, 29], [30, 36], [36, 37], [37, 39], [39, 40], [40, 45], [46, 51], [52, 56], [57, 59], [60, 67], [68, 71], [72, 75], [76, 85], [86, 92], [93, 97], [98, 100], [101, 111], [112, 124], [124, 125]]}
{"doc_key": "ai-test-81", "ner": [[5, 6, "field"], [9, 11, "researcher"], [17, 17, "researcher"], [20, 22, "researcher"], [29, 34, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 9, 11, "general-affiliation", "", false, false], [5, 6, 17, 17, "general-affiliation", "", false, false], [5, 6, 20, 22, "general-affiliation", "", false, false], [29, 34, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Code", "of", "Ethics", "on", "Human", "Augmentation", ",", "introduced", "by", "Steve", "Mann", "in", "2004", "and", "refined", "by", "Ray", "Kurzweil", "and", "Marvin", "Minsky", "in", "2013", ",", "was", "finally", "ratified", "at", "the", "Virtual", "Reality", "Toronto", "conference", "on", "25", "June", "2017", ".", "It", "was", "ratified", "by", "."], "sentence-detokenized": "The Code of Ethics on Human Augmentation, introduced by Steve Mann in 2004 and refined by Ray Kurzweil and Marvin Minsky in 2013, was finally ratified at the Virtual Reality Toronto conference on 25 June 2017. It was ratified by.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 18], [19, 21], [22, 27], [28, 40], [40, 41], [42, 52], [53, 55], [56, 61], [62, 66], [67, 69], [70, 74], [75, 78], [79, 86], [87, 89], [90, 93], [94, 102], [103, 106], [107, 113], [114, 120], [121, 123], [124, 128], [128, 129], [130, 133], [134, 141], [142, 150], [151, 153], [154, 157], [158, 165], [166, 173], [174, 181], [182, 192], [193, 195], [196, 198], [199, 203], [204, 208], [208, 209], [210, 212], [213, 216], [217, 225], [226, 228], [228, 229]]}
{"doc_key": "ai-test-82", "ner": [[3, 5, "person"], [12, 16, "organisation"], [18, 20, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 12, 16, "role", "directed_for", false, false], [3, 5, 18, 20, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1913", ",", "Walter", "R.", "Booth", "directed", "ten", "films", "for", "the", "British", "Kinoplastikon", "company", ",", "apparently", "in", "collaboration", "with", "Cecil", "Hepworth", "."], "sentence-detokenized": "In 1913, Walter R. Booth directed ten films for the British Kinoplastikon company, apparently in collaboration with Cecil Hepworth.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 18], [19, 24], [25, 33], [34, 37], [38, 43], [44, 47], [48, 51], [52, 59], [60, 73], [74, 81], [81, 82], [83, 93], [94, 96], [97, 110], [111, 115], [116, 121], [122, 130], [130, 131]]}
{"doc_key": "ai-test-83", "ner": [[8, 11, "location"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1961", ",", "at", "a", "trade", "fair", "at", "the", "Cow", "Palace", "in", "Chicago", ",", "they", "presented", "a", "new", "robot", "."], "sentence-detokenized": "In 1961, at a trade fair at the Cow Palace in Chicago, they presented a new robot.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 13], [14, 19], [20, 24], [25, 27], [28, 31], [32, 35], [36, 42], [43, 45], [46, 53], [53, 54], [55, 59], [60, 69], [70, 71], [72, 75], [76, 81], [81, 82]]}
{"doc_key": "ai-test-84", "ner": [[0, 1, "product"], [5, 6, "task"], [9, 10, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 5, 6, "usage", "", false, false], [0, 1, 9, 10, "usage", "", false, false], [0, 1, 14, 15, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Some", "chatbot", "applications", "use", "extensive", "word", "classification", "processes", ",", "natural", "language", "processors", "and", "advanced", "artificial", "intelligence", ",", "while", "others", "simply", "scan", "for", "common", "keywords", "and", "generate", "responses", "using", "common", "phrases", "taken", "from", "relevant", "libraries", "and", "databases", "There", "are", "."], "sentence-detokenized": "Some chatbot applications use extensive word classification processes, natural language processors and advanced artificial intelligence, while others simply scan for common keywords and generate responses using common phrases taken from relevant libraries and databases There are.", "token2charspan": [[0, 4], [5, 12], [13, 25], [26, 29], [30, 39], [40, 44], [45, 59], [60, 69], [69, 70], [71, 78], [79, 87], [88, 98], [99, 102], [103, 111], [112, 122], [123, 135], [135, 136], [137, 142], [143, 149], [150, 156], [157, 161], [162, 165], [166, 172], [173, 181], [182, 185], [186, 194], [195, 204], [205, 210], [211, 217], [218, 225], [226, 231], [232, 236], [237, 245], [246, 255], [256, 259], [260, 269], [270, 275], [276, 279], [279, 280]]}
{"doc_key": "ai-test-85", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "WaveNet", "model", "proposed", "in", "2016", "achieves", "excellent", "performance", "with", "regard", "to", "speech", "quality", "."], "sentence-detokenized": "The WaveNet model proposed in 2016 achieves excellent performance with regard to speech quality.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 43], [44, 53], [54, 65], [66, 70], [71, 77], [78, 80], [81, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-test-86", "ner": [[3, 5, "product"], [6, 7, "misc"], [9, 10, "misc"], [12, 13, "misc"], [15, 16, "misc"], [19, 20, "organisation"], [22, 22, "organisation"], [24, 27, "organisation"], [29, 29, "organisation"], [31, 34, "organisation"], [36, 36, "organisation"], [38, 38, "organisation"], [40, 42, "organisation"], [18, 45, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[3, 5, 6, 7, "general-affiliation", "", false, false], [3, 5, 9, 10, "general-affiliation", "", false, false], [3, 5, 12, 13, "general-affiliation", "", false, false], [3, 5, 15, 16, "general-affiliation", "", false, false], [19, 20, 3, 5, "usage", "", false, false], [22, 22, 3, 5, "usage", "", false, false], [24, 27, 3, 5, "usage", "", false, false], [29, 29, 3, 5, "usage", "", false, false], [31, 34, 3, 5, "usage", "", false, false], [36, 36, 3, 5, "usage", "", false, false], [38, 38, 3, 5, "usage", "", false, false], [40, 42, 3, 5, "usage", "", false, false], [18, 45, 3, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organisations", "known", "to", "use", "ALEs", "for", "emergency", "management", ",", "disaster", "relief", ",", "conventional", "communications", "and", "catastrophic", "response", ".", "American", "Red", "Cross", ",", "FEMA", ",", "Disaster", "Medical", "Assistance", "Team", ",", "NATO", ",", "Federal", "Bureau", "of", "Investigation", ",", "UN", ",", "AT&T", ",", "Civil", "Air", "Patrol", ",", "(", "ARES", ")", "."], "sentence-detokenized": "Organisations known to use ALEs for emergency management, disaster relief, conventional communications and catastrophic response. American Red Cross, FEMA, Disaster Medical Assistance Team, NATO, Federal Bureau of Investigation, UN, AT&T, Civil Air Patrol, (ARES).", "token2charspan": [[0, 13], [14, 19], [20, 22], [23, 26], [27, 31], [32, 35], [36, 45], [46, 56], [56, 57], [58, 66], [67, 73], [73, 74], [75, 87], [88, 102], [103, 106], [107, 119], [120, 128], [128, 129], [130, 138], [139, 142], [143, 148], [148, 149], [150, 154], [154, 155], [156, 164], [165, 172], [173, 183], [184, 188], [188, 189], [190, 194], [194, 195], [196, 203], [204, 210], [211, 213], [214, 227], [227, 228], [229, 231], [231, 232], [233, 237], [237, 238], [239, 244], [245, 248], [249, 255], [255, 256], [257, 258], [258, 262], [262, 263], [263, 264]]}
{"doc_key": "ai-test-87", "ner": [[0, 3, "algorithm"], [11, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Kronecker", "delta", "is", "used", "here", "for", "simplicity", "(", "see", "Derivatives", "of", "sigmoidal", "functions", "are", "expressed", "in", "terms", "of", "the", "function", "itself", ")", "."], "sentence-detokenized": "The Kronecker delta is used here for simplicity (see Derivatives of sigmoidal functions are expressed in terms of the function itself).", "token2charspan": [[0, 3], [4, 13], [14, 19], [20, 22], [23, 27], [28, 32], [33, 36], [37, 47], [48, 49], [49, 52], [53, 64], [65, 67], [68, 77], [78, 87], [88, 91], [92, 101], [102, 104], [105, 110], [111, 113], [114, 117], [118, 126], [127, 133], [133, 134], [134, 135]]}
{"doc_key": "ai-test-88", "ner": [[11, 12, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "theory", "is", "based", "on", "philosophical", "foundations", "and", "was", "founded", "by", "Ray", "Solomonoff", "around", "1960", ".", "Samuel", "Rathmaner", "and", "Markus", "Hutter", "."], "sentence-detokenized": "The theory is based on philosophical foundations and was founded by Ray Solomonoff around 1960. Samuel Rathmaner and Markus Hutter.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 36], [37, 48], [49, 52], [53, 56], [57, 64], [65, 67], [68, 71], [72, 82], [83, 89], [90, 94], [94, 95], [96, 102], [103, 112], [113, 116], [117, 123], [124, 130], [130, 131]]}
{"doc_key": "ai-test-89", "ner": [[0, 2, "product"], [8, 10, "misc"], [12, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 8, 10, "type-of", "", false, false], [0, 2, 12, 14, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Word", "Net", "is", "a", "database", "originally", "designed", "as", "a", "semantic", "network", "based", "on", "psycholinguistic", "principles", ",", "which", "has", "been", "extended", "by", "the", "addition", "of", "definitions", "and", "is", "now", "also", "positioned", "as", "a", "dictionary", "."], "sentence-detokenized": "WordNet is a database originally designed as a semantic network based on psycholinguistic principles, which has been extended by the addition of definitions and is now also positioned as a dictionary.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 12], [13, 21], [22, 32], [33, 41], [42, 44], [45, 46], [47, 55], [56, 63], [64, 69], [70, 72], [73, 89], [90, 100], [100, 101], [102, 107], [108, 111], [112, 116], [117, 125], [126, 128], [129, 132], [133, 141], [142, 144], [145, 156], [157, 160], [161, 163], [164, 167], [168, 172], [173, 183], [184, 186], [187, 188], [189, 199], [199, 200]]}
{"doc_key": "ai-test-90", "ner": [[1, 4, "field"], [12, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 1, 4, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Advances", "in", "computational", "imaging", "research", "are", "presented", "in", "several", "fora", ",", "including", "SIGGRAPH", "publications", "and", "conferences", "."], "sentence-detokenized": "Advances in computational imaging research are presented in several fora, including SIGGRAPH publications and conferences.", "token2charspan": [[0, 8], [9, 11], [12, 25], [26, 33], [34, 42], [43, 46], [47, 56], [57, 59], [60, 67], [68, 72], [72, 73], [74, 83], [84, 92], [93, 105], [106, 109], [110, 121], [121, 122]]}
{"doc_key": "ai-test-91", "ner": [[0, 9, "task"], [8, 13, "task"]], "ner_mapping_to_source": [0, 2], "relations": [[8, 13, 0, 9, "part-of", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Classification", "can", "be", "considered", "as", "two", "separate", "issues", ":", "binary", "classification", "and", "multivalued", "classification", "."], "sentence-detokenized": "Classification can be considered as two separate issues: binary classification and multivalued classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 48], [49, 55], [55, 56], [57, 63], [64, 78], [79, 82], [83, 94], [95, 109], [109, 110]]}
{"doc_key": "ai-test-92", "ner": [[11, 11, "algorithm"], [16, 18, "algorithm"], [14, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 18, 11, 11, "type-of", "", false, false], [14, 23, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Advanced", "gene", "detectors", "for", "prokaryotic", "and", "eukaryotic", "genomes", "typically", "use", "complex", "probabilistic", "models", ",", "such", "as", "hidden", "Markov", "models", "(", "HMMs", ")", ",", "to", "combine", "information", "from", "a", "variety", "of", "different", "signals", "and", "content", "measurements", "."], "sentence-detokenized": "Advanced gene detectors for prokaryotic and eukaryotic genomes typically use complex probabilistic models, such as hidden Markov models (HMMs), to combine information from a variety of different signals and content measurements.", "token2charspan": [[0, 8], [9, 13], [14, 23], [24, 27], [28, 39], [40, 43], [44, 54], [55, 62], [63, 72], [73, 76], [77, 84], [85, 98], [99, 105], [105, 106], [107, 111], [112, 114], [115, 121], [122, 128], [129, 135], [136, 137], [137, 141], [141, 142], [142, 143], [144, 146], [147, 154], [155, 166], [167, 171], [172, 173], [174, 181], [182, 184], [185, 194], [195, 202], [203, 206], [207, 214], [215, 227], [227, 228]]}
{"doc_key": "ai-test-93", "ner": [[0, 4, "misc"], [6, 6, "field"], [8, 11, "algorithm"], [5, 5, "algorithm"], [13, 17, "algorithm"], [26, 27, "algorithm"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [[13, 17, 5, 5, "named", "", false, false]], "relations_mapping_to_source": [4], "sentence": ["Neuroevolution", "is", "a", "type", "of", "artificial", "intelligence", "that", "uses", "evolutionary", "algorithms", "to", "generate", "artificial", "neural", "networks", "(", "ANNs", ")", ",", "parameters", ",", "topologies", ",", "rules", "and", "evolutionary", "robotics", "."], "sentence-detokenized": "Neuroevolution is a type of artificial intelligence that uses evolutionary algorithms to generate artificial neural networks (ANNs), parameters, topologies, rules and evolutionary robotics.", "token2charspan": [[0, 14], [15, 17], [18, 19], [20, 24], [25, 27], [28, 38], [39, 51], [52, 56], [57, 61], [62, 74], [75, 85], [86, 88], [89, 97], [98, 108], [109, 115], [116, 124], [125, 126], [126, 130], [130, 131], [131, 132], [133, 143], [143, 144], [145, 155], [155, 156], [157, 162], [163, 166], [167, 179], [180, 188], [188, 189]]}
{"doc_key": "ai-test-94", "ner": [[1, 1, "organisation"], [6, 6, "metrics"], [9, 9, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 1, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "IBM", "proposed", "and", "realised", "the", "BLEU", "system", ",", "Papineni", "et", "al", "."], "sentence-detokenized": "Since IBM proposed and realised the BLEU system, Papineni et al.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 22], [23, 31], [32, 35], [36, 40], [41, 47], [47, 48], [49, 57], [58, 60], [61, 63], [63, 64]]}
{"doc_key": "ai-test-95", "ner": [[12, 12, "conference"], [8, 17, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 17, 12, 12, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2009", ",", "a", "conference", "organised", "by", "the", "Association", "for", "Artificial", "Intelligence", "(", "AAAI", ")", "was", "held", "where", "experts", "discussed", "the", "possibility", "of", "computers", "and", "robots", "gaining", "autonomy", "and", "the", "extent", "to", "which", "this", "capability", "poses", "a", "threat", "or", "danger", "."], "sentence-detokenized": "In 2009, a conference organised by the Association for Artificial Intelligence (AAAI) was held where experts discussed the possibility of computers and robots gaining autonomy and the extent to which this capability poses a threat or danger.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 21], [22, 31], [32, 34], [35, 38], [39, 50], [51, 54], [55, 65], [66, 78], [79, 80], [80, 84], [84, 85], [86, 89], [90, 94], [95, 100], [101, 108], [109, 118], [119, 122], [123, 134], [135, 137], [138, 147], [148, 151], [152, 158], [159, 166], [167, 175], [176, 179], [180, 183], [184, 190], [191, 193], [194, 199], [200, 204], [205, 215], [216, 221], [222, 223], [224, 230], [231, 233], [234, 240], [240, 241]]}
{"doc_key": "ai-test-96", "ner": [[24, 25, "researcher"], [27, 28, "researcher"], [30, 35, "task"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[30, 35, 24, 25, "artifact", "", false, false], [30, 35, 27, 28, "artifact", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["After", "boosting", ",", "a", "classifier", "consisting", "of", "200", "features", "can", "achieve", "a", "detection", "rate", "of", "95", "%", "under", "^", "{", "-", "5", "}", "/", "P.", "Viola", ",", "M.", "Jones", ",", "Robust", "Real", "-", "time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "After boosting, a classifier consisting of 200 features can achieve a detection rate of 95% under ^ {-5} / P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 17], [18, 28], [29, 39], [40, 42], [43, 46], [47, 55], [56, 59], [60, 67], [68, 69], [70, 79], [80, 84], [85, 87], [88, 90], [90, 91], [92, 97], [98, 99], [100, 101], [101, 102], [102, 103], [103, 104], [105, 106], [107, 109], [110, 115], [115, 116], [117, 119], [120, 125], [125, 126], [127, 133], [134, 138], [138, 139], [139, 143], [144, 150], [151, 160], [160, 161], [162, 166], [166, 167]]}
{"doc_key": "ai-test-97", "ner": [[9, 9, "organisation"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "website", "was", "originally", "Perl", "-", "based", ",", "but", "IMDb", "no", "longer", "publishes", "which", "software", "it", "uses", "for", "security", "reasons", "."], "sentence-detokenized": "The website was originally Perl-based, but IMDb no longer publishes which software it uses for security reasons.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 26], [27, 31], [31, 32], [32, 37], [37, 38], [39, 42], [43, 47], [48, 50], [51, 57], [58, 67], [68, 73], [74, 82], [83, 85], [86, 90], [91, 94], [95, 103], [104, 111], [111, 112]]}
{"doc_key": "ai-test-98", "ner": [[10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "start", "-", "up", "company", "was", "founded", "in", "2010", "by", "Demis", "Hassabis", ",", "Shane", "Legg", "and", "Mustafa", "Suleyman", "."], "sentence-detokenized": "The start-up company was founded in 2010 by Demis Hassabis, Shane Legg and Mustafa Suleyman.", "token2charspan": [[0, 3], [4, 9], [9, 10], [10, 12], [13, 20], [21, 24], [25, 32], [33, 35], [36, 40], [41, 43], [44, 49], [50, 58], [58, 59], [60, 65], [66, 70], [71, 74], [75, 82], [83, 91], [91, 92]]}
{"doc_key": "ai-test-99", "ner": [[4, 4, "misc"], [8, 10, "metrics"], [25, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 4, 4, "type-of", "", false, false], [25, 26, 4, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "very", "commonly", "used", "loss", "functions", "are", "the", "mean", "squared", "error", ",", "mathL", "(", "a", ")", "=", "a", "^", "2", "/", "math", ",", "and", "the", "absolute", "loss", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "/", "math", "."], "sentence-detokenized": "Two very commonly used loss functions are the mean squared error, mathL (a) = a ^ 2 / math, and the absolute loss, mathL (a) = | a | / math.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 27], [28, 37], [38, 41], [42, 45], [46, 50], [51, 58], [59, 64], [64, 65], [66, 71], [72, 73], [73, 74], [74, 75], [76, 77], [78, 79], [80, 81], [82, 83], [84, 85], [86, 90], [90, 91], [92, 95], [96, 99], [100, 108], [109, 113], [113, 114], [115, 120], [121, 122], [122, 123], [123, 124], [125, 126], [127, 128], [129, 130], [131, 132], [133, 134], [135, 139], [139, 140]]}
{"doc_key": "ai-test-100", "ner": [[0, 9, "algorithm"], [12, 18, "algorithm"], [19, 20, "metrics"]], "ner_mapping_to_source": [0, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "soft", "merge", "support", "vector", "machine", "described", "above", "is", "an", "example", "of", "empirical", "risk", "minimisation", "(", "ERM", ")", "for", "hinge", "loss", "."], "sentence-detokenized": "The soft merge support vector machine described above is an example of empirical risk minimisation (ERM) for hinge loss.", "token2charspan": [[0, 3], [4, 8], [9, 14], [15, 22], [23, 29], [30, 37], [38, 47], [48, 53], [54, 56], [57, 59], [60, 67], [68, 70], [71, 80], [81, 85], [86, 98], [99, 100], [100, 103], [103, 104], [105, 108], [109, 114], [115, 119], [119, 120]]}
{"doc_key": "ai-test-101", "ner": [[5, 6, "field"], [8, 11, "task"], [0, 16, "task"], [19, 20, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 16, 5, 6, "origin", "", false, false], [0, 16, 8, 11, "type-of", "", false, false], [19, 20, 0, 16, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Neural", "machine", "translation", ",", "a", "deep", "learning", "approach", "to", "MT", ",", "has", "progressed", "rapidly", "in", "recent", "years", ",", "and", "Google", "has", "announced", "that", "it", "will", "replace", "traditional", "statistical", "methods", "in", "its", "translation", "services", "."], "sentence-detokenized": "Neural machine translation, a deep learning approach to MT, has progressed rapidly in recent years, and Google has announced that it will replace traditional statistical methods in its translation services.", "token2charspan": [[0, 6], [7, 14], [15, 26], [26, 27], [28, 29], [30, 34], [35, 43], [44, 52], [53, 55], [56, 58], [58, 59], [60, 63], [64, 74], [75, 82], [83, 85], [86, 92], [93, 98], [98, 99], [100, 103], [104, 110], [111, 114], [115, 124], [125, 129], [130, 132], [133, 137], [138, 145], [146, 157], [158, 169], [170, 177], [178, 180], [181, 184], [185, 196], [197, 205], [205, 206]]}
{"doc_key": "ai-test-102", "ner": [[0, 16, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "tends", "to", "lead", "to", "very", "significant", "performance", "gains", "when", "dealing", "with", "large", "corpora", "such", "as", "WordNet", "."], "sentence-detokenized": "This tends to lead to very significant performance gains when dealing with large corpora such as WordNet.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 18], [19, 21], [22, 26], [27, 38], [39, 50], [51, 56], [57, 61], [62, 69], [70, 74], [75, 80], [81, 88], [89, 93], [94, 96], [97, 104], [104, 105]]}
{"doc_key": "ai-test-103", "ner": [[0, 2, "task"], [19, 20, "field"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 7, "part-of", "", false, false], [6, 7, 19, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Face", "detection", "is", "often", "used", "as", "part", "of", "(", "or", "together", "with", ")", "face", "recognition", "systems", "in", "the", "field", "of", "biometrics", "."], "sentence-detokenized": "Face detection is often used as part of (or together with) face recognition systems in the field of biometrics.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 23], [24, 28], [29, 31], [32, 36], [37, 39], [40, 41], [41, 43], [44, 52], [53, 57], [57, 58], [59, 63], [64, 75], [76, 83], [84, 86], [87, 90], [91, 96], [97, 99], [100, 110], [110, 111]]}
{"doc_key": "ai-test-104", "ner": [[3, 5, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["were", "trained", "by", "maximum", "likelihood", "estimation", "."], "sentence-detokenized": "were trained by maximum likelihood estimation.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 23], [24, 34], [35, 45], [45, 46]]}
{"doc_key": "ai-test-105", "ner": [[0, 1, "country"], [4, 9, "organisation"], [10, 10, "location"], [12, 13, "country"], [19, 21, "organisation"], [28, 30, "country"], [25, 25, "organisation"], [32, 36, "organisation"], [37, 38, "country"], [49, 54, "organisation"], [46, 47, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[4, 9, 10, 10, "physical", "", false, false], [10, 10, 12, 13, "physical", "", false, false], [19, 21, 28, 30, "physical", "", false, false], [32, 36, 37, 38, "physical", "", false, false], [49, 54, 46, 47, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ltd.", "in", "1996", ",", "Komatsu", "(", "Shanghai", ")", "Ltd.", "in", "Shanghai", ",", "China", "in", "1996", ",", "Industrial", "Power", "Alliance", "Corporation", ",", "a", "joint", "venture", "with", "Cummins", "Corporation", "of", "Japan", "in", "1998", ",", "L&T", "-", "Komatsu", "Limited", "in", "India", "in", "1998", "(", "sold", "in", "2013", ")", "and", "Brazil", "in", "1998", ".", "Komatsu", "Brasil", "International", "Ltda", "."], "sentence-detokenized": "Ltd. in 1996, Komatsu (Shanghai) Ltd. in Shanghai, China in 1996, Industrial Power Alliance Corporation, a joint venture with Cummins Corporation of Japan in 1998, L&T-Komatsu Limited in India in 1998 (sold in 2013) and Brazil in 1998. Komatsu Brasil International Ltda.", "token2charspan": [[0, 4], [5, 7], [8, 12], [12, 13], [14, 21], [22, 23], [23, 31], [31, 32], [33, 37], [38, 40], [41, 49], [49, 50], [51, 56], [57, 59], [60, 64], [64, 65], [66, 76], [77, 82], [83, 91], [92, 103], [103, 104], [105, 106], [107, 112], [113, 120], [121, 125], [126, 133], [134, 145], [146, 148], [149, 154], [155, 157], [158, 162], [162, 163], [164, 167], [167, 168], [168, 175], [176, 183], [184, 186], [187, 192], [193, 195], [196, 200], [201, 202], [202, 206], [207, 209], [210, 214], [214, 215], [216, 219], [220, 226], [227, 229], [230, 234], [234, 235], [236, 243], [244, 250], [251, 264], [265, 269], [269, 270]]}
{"doc_key": "ai-test-106", "ner": [[1, 7, "misc"], [10, 10, "misc"], [8, 15, "person"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[8, 15, 1, 7, "general-affiliation", "", false, false], [8, 15, 10, 10, "win-defeat", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["It", "has", "also", "hosted", "artists", "-in", "-", "residence", ",", "including", "Academy", "Award", "-", "winner", "Chris", "Landreth", "."], "sentence-detokenized": "It has also hosted artists-in-residence, including Academy Award-winner Chris Landreth.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 26], [26, 29], [29, 30], [30, 39], [39, 40], [41, 50], [51, 58], [59, 64], [64, 65], [65, 71], [72, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-107", "ner": [[7, 9, "misc"], [12, 14, "misc"], [17, 22, "misc"], [24, 32, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "currently", "four", "sub-competitions", ":", "the", "RoboMaster", "Robotics", "Competition", ",", "the", "RoboMaster", "Technical", "Challenge", ",", "the", "ICRA", "RoboMaster", "AI", "Challenge", "and", "the", "new", "RoboMaster", "Youth", "Tournament", ".", "The", "RoboMaster", "Youth", "Tournament", "is", "being", "organised", "."], "sentence-detokenized": "There are currently four sub-competitions: the RoboMaster Robotics Competition, the RoboMaster Technical Challenge, the ICRA RoboMaster AI Challenge and the new RoboMaster Youth Tournament. The RoboMaster Youth Tournament is being organised.", "token2charspan": [[0, 5], [6, 9], [10, 19], [20, 24], [25, 41], [41, 42], [43, 46], [47, 57], [58, 66], [67, 78], [78, 79], [80, 83], [84, 94], [95, 104], [105, 114], [114, 115], [116, 119], [120, 124], [125, 135], [136, 138], [139, 148], [149, 152], [153, 156], [157, 160], [161, 171], [172, 177], [178, 188], [188, 189], [190, 193], [194, 204], [205, 210], [211, 221], [222, 224], [225, 230], [231, 240], [240, 241]]}
{"doc_key": "ai-test-108", "ner": [[5, 7, "field"], [13, 16, "algorithm"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[5, 7, 22, 23, "usage", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["In", "the", "early", "2000s", ",", "mainstream", "speech", "processing", "began", "to", "move", "away", "from", "hidden", "Markov", "models", "towards", "more", "modern", "neural", "networks", "and", "deep", "learning", "."], "sentence-detokenized": "In the early 2000s, mainstream speech processing began to move away from hidden Markov models towards more modern neural networks and deep learning.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 18], [18, 19], [20, 30], [31, 37], [38, 48], [49, 54], [55, 57], [58, 62], [63, 67], [68, 72], [73, 79], [80, 86], [87, 93], [94, 101], [102, 106], [107, 113], [114, 120], [121, 129], [130, 133], [134, 138], [139, 147], [147, 148]]}
{"doc_key": "ai-test-109", "ner": [[7, 13, "misc"], [14, 15, "metrics"], [17, 20, "metrics"], [26, 27, "metrics"], [29, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 15, 17, 20, "related-to", "equal", false, false], [26, 27, 29, 32, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "equivalent", "expression", "is", "that", "in", "the", "case", "of", "binary", "target", "rates", ",", "the", "true", "positive", "and", "false", "positive", "rates", "are", "equal", "(", "and", "therefore", "the", "false", "negative", "and", "true", "negative", "rates", "are", "equal", ")", "for", "every", "value", "of", "the", "sensitive", "characteristic", "."], "sentence-detokenized": "Another equivalent expression is that in the case of binary target rates, the true positive and false positive rates are equal (and therefore the false negative and true negative rates are equal) for every value of the sensitive characteristic.", "token2charspan": [[0, 7], [8, 18], [19, 29], [30, 32], [33, 37], [38, 40], [41, 44], [45, 49], [50, 52], [53, 59], [60, 66], [67, 72], [72, 73], [74, 77], [78, 82], [83, 91], [92, 95], [96, 101], [102, 110], [111, 116], [117, 120], [121, 126], [127, 128], [128, 131], [132, 141], [142, 145], [146, 151], [152, 160], [161, 164], [165, 169], [170, 178], [179, 184], [185, 188], [189, 194], [194, 195], [196, 199], [200, 205], [206, 211], [212, 214], [215, 218], [219, 228], [229, 243], [243, 244]]}
{"doc_key": "ai-test-110", "ner": [[0, 0, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["MATLAB", "functions", "."], "sentence-detokenized": "MATLAB functions.", "token2charspan": [[0, 6], [7, 16], [16, 17]]}
{"doc_key": "ai-test-111", "ner": [[0, 2, "product"], [5, 6, "misc"], [8, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 0, 2, "part-of", "", false, false], [8, 13, 0, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Articulated", "robots", "are", "robots", "with", "rotating", "joints", "(", "e.g.", "legged", "robots", "and", "industrial", "robots", ")", "."], "sentence-detokenized": "Articulated robots are robots with rotating joints (e.g. legged robots and industrial robots).", "token2charspan": [[0, 11], [12, 18], [19, 22], [23, 29], [30, 34], [35, 43], [44, 50], [51, 52], [52, 56], [57, 63], [64, 70], [71, 74], [75, 85], [86, 92], [92, 93], [93, 94]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [2, 3, "product"], [5, 8, "product"], [13, 21, "product"], [24, 29, "misc"], [37, 39, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7], "relations": [[0, 0, 24, 29, "usage", "", false, false], [0, 0, 37, 39, "physical", "", false, false], [2, 3, 0, 0, "named", "", false, false], [5, 8, 0, 0, "named", "", false, false], [37, 39, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "Pandora", "Media", "or", "Pandora", "Radio", ")", "is", "an", "internet", "radio", "service", "providing", "music", "streaming", "and", "automated", "recommender", "systems", "in", "the", "USA", ",", "operated", "by", "the", "Music", "Genome", "Project", "and", "headquartered", "in", "It", "is", "headquartered", "in", "Oakland", ",", "California", "."], "sentence-detokenized": "Pandora (Pandora Media or Pandora Radio) is an internet radio service providing music streaming and automated recommender systems in the USA, operated by the Music Genome Project and headquartered in It is headquartered in Oakland, California.", "token2charspan": [[0, 7], [8, 9], [9, 16], [17, 22], [23, 25], [26, 33], [34, 39], [39, 40], [41, 43], [44, 46], [47, 55], [56, 61], [62, 69], [70, 79], [80, 85], [86, 95], [96, 99], [100, 109], [110, 121], [122, 129], [130, 132], [133, 136], [137, 140], [140, 141], [142, 150], [151, 153], [154, 157], [158, 163], [164, 170], [171, 178], [179, 182], [183, 196], [197, 199], [200, 202], [203, 205], [206, 219], [220, 222], [223, 230], [230, 231], [232, 242], [242, 243]]}
{"doc_key": "ai-test-113", "ner": [[7, 8, "organisation"], [0, 13, "organisation"], [18, 19, "conference"], [28, 28, "conference"], [30, 30, "conference"], [32, 32, "conference"], [34, 34, "conference"], [36, 36, "conference"], [38, 38, "conference"], [40, 40, "conference"], [42, 42, "conference"], [44, 44, "conference"], [25, 46, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["Board", "member", "of", "the", "International", "Association", "for", "Machine", "Learning", ",", "board", "member", "of", "AAAI", ",", "PC", "co-chair", "of", "ICML", "2011", ",", "senior", "PC", "member", "at", "conferences", "such", "as", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "UAI", ",", "VLDB", ",", "WSDM", "and", "WWW", "."], "sentence-detokenized": "Board member of the International Association for Machine Learning, board member of AAAI, PC co-chair of ICML 2011, senior PC member at conferences such as AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM and WWW.", "token2charspan": [[0, 5], [6, 12], [13, 15], [16, 19], [20, 33], [34, 45], [46, 49], [50, 57], [58, 66], [66, 67], [68, 73], [74, 80], [81, 83], [84, 88], [88, 89], [90, 92], [93, 101], [102, 104], [105, 109], [110, 114], [114, 115], [116, 122], [123, 125], [126, 132], [133, 135], [136, 147], [148, 152], [153, 155], [156, 160], [160, 161], [162, 166], [166, 167], [168, 173], [173, 174], [175, 179], [179, 180], [181, 184], [184, 185], [186, 192], [192, 193], [194, 197], [197, 198], [199, 203], [203, 204], [205, 209], [210, 213], [214, 217], [217, 218]]}
{"doc_key": "ai-test-114", "ner": [[4, 9, "researcher"], [13, 14, "organisation"], [10, 20, "organisation"], [0, 1, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 9, 13, 14, "role", "", false, false], [10, 20, 13, 14, "named", "", false, false], [0, 1, 4, 9, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Robocrane", ",", "developed", "by", "James", "S.", "Albus", "of", "the", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", ",", "uses", "six", "cables", "to", "hang", "the", "platform", "instead", "of", "supporting", "it", "with", "six", "jacks", "."], "sentence-detokenized": "The Robocrane, developed by James S. Albus of the National Institute of Standards and Technology (NIST), uses six cables to hang the platform instead of supporting it with six jacks.", "token2charspan": [[0, 3], [4, 13], [13, 14], [15, 24], [25, 27], [28, 33], [34, 36], [37, 42], [43, 45], [46, 49], [50, 58], [59, 68], [69, 71], [72, 81], [82, 85], [86, 96], [97, 98], [98, 102], [102, 103], [103, 104], [105, 109], [110, 113], [114, 120], [121, 123], [124, 128], [129, 132], [133, 141], [142, 149], [150, 152], [153, 163], [164, 166], [167, 171], [172, 175], [176, 181], [181, 182]]}
{"doc_key": "ai-test-115", "ner": [[3, 5, "algorithm"], [9, 9, "algorithm"], [14, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 3, 5, "type-of", "", false, false], [14, 14, 9, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "class", "of", "direct", "search", "algorithms", "is", "the", "various", "evolutionary", "algorithms", ",", "such", "as", "genetic", "algorithms", "."], "sentence-detokenized": "Another class of direct search algorithms is the various evolutionary algorithms, such as genetic algorithms.", "token2charspan": [[0, 7], [8, 13], [14, 16], [17, 23], [24, 30], [31, 41], [42, 44], [45, 48], [49, 56], [57, 69], [70, 80], [80, 81], [82, 86], [87, 89], [90, 97], [98, 108], [108, 109]]}
{"doc_key": "ai-test-116", "ner": [[0, 0, "organisation"], [1, 5, "misc"], [8, 8, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 5, 0, 0, "named", "", false, false], [8, 8, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["KUKA", "is", "a", "German", "manufacturer", "of", "solutions", "for", "industrial", "robotics", "and", "factory", "automation", "."], "sentence-detokenized": "KUKA is a German manufacturer of solutions for industrial robotics and factory automation.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 16], [17, 29], [30, 32], [33, 42], [43, 46], [47, 57], [58, 66], [67, 70], [71, 78], [79, 89], [89, 90]]}
{"doc_key": "ai-test-117", "ner": [[4, 4, "misc"], [11, 12, "person"], [14, 20, "misc"], [22, 23, "person"], [25, 25, "misc"], [27, 28, "person"], [30, 31, "misc"], [33, 34, "person"], [38, 40, "misc"], [44, 47, "person"], [48, 51, "misc"], [53, 55, "person"], [35, 59, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[11, 12, 4, 4, "usage", "", false, false], [14, 20, 11, 12, "artifact", "", false, false], [22, 23, 4, 4, "usage", "", false, false], [25, 25, 22, 23, "artifact", "", false, false], [27, 28, 4, 4, "usage", "", false, false], [30, 31, 27, 28, "artifact", "", false, false], [33, 34, 4, 4, "usage", "", false, false], [38, 40, 33, 34, "artifact", "", false, false], [44, 47, 4, 4, "usage", "", false, false], [48, 51, 44, 47, "artifact", "", false, false], [53, 55, 4, 4, "usage", "", false, false], [35, 59, 53, 55, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Other", "films", "shot", "with", "IMAX", "cameras", "between", "2016", "and", "2020", "were", "Zack", "Snyder", "'s", "Batman", "v", "Superman", ":", "Dawn", "of", "Justice", ",", "Clint", "Eastwood", "'s", "Sully", ",", "Damian", "Chazelle", "'s", "First", "Man", ",", "Patty", "Jenkins", "It", "was", "director", "Wonder", "Woman", "1984", ",", "directed", "by", "Cary", "Joji", "Fukunaga", "'s", "No", "Time", "-", "Die", "and", "Joseph", "Kosinski", "'s", "Top", "Gun", ".", "Maverick", "\"", "."], "sentence-detokenized": "Other films shot with IMAX cameras between 2016 and 2020 were Zack Snyder's Batman v Superman: Dawn of Justice, Clint Eastwood's Sully, Damian Chazelle's First Man, Patty Jenkins It was director Wonder Woman 1984, directed by Cary Joji Fukunaga's No Time - Die and Joseph Kosinski's Top Gun. Maverick\".", "token2charspan": [[0, 5], [6, 11], [12, 16], [17, 21], [22, 26], [27, 34], [35, 42], [43, 47], [48, 51], [52, 56], [57, 61], [62, 66], [67, 73], [73, 75], [76, 82], [83, 84], [85, 93], [93, 94], [95, 99], [100, 102], [103, 110], [110, 111], [112, 117], [118, 126], [126, 128], [129, 134], [134, 135], [136, 142], [143, 151], [151, 153], [154, 159], [160, 163], [163, 164], [165, 170], [171, 178], [179, 181], [182, 185], [186, 194], [195, 201], [202, 207], [208, 212], [212, 213], [214, 222], [223, 225], [226, 230], [231, 235], [236, 244], [244, 246], [247, 249], [250, 254], [255, 256], [257, 260], [261, 264], [265, 271], [272, 280], [280, 282], [283, 286], [287, 290], [290, 291], [292, 300], [300, 301], [301, 302]]}
{"doc_key": "ai-test-118", "ner": [[8, 9, "misc"], [18, 19, "organisation"], [15, 15, "organisation"], [27, 27, "misc"], [33, 35, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 9, 27, 27, "named", "", false, false], [18, 19, 8, 9, "usage", "", false, false], [18, 19, 33, 35, "physical", "", false, false], [15, 15, 18, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "July", "1956", ",", "a", "prototype", "of", "the", "MICR", "E13B", "font", "was", "presented", "to", "the", "ABA", "(", "American", "Bankers", "Association", ")", ",", "which", "adopted", "it", "as", "the", "MICR", "standard", "for", "negotiable", "documents", "in", "the", "USA", "in", "1958", "."], "sentence-detokenized": "In July 1956, a prototype of the MICR E13B font was presented to the ABA (American Bankers Association), which adopted it as the MICR standard for negotiable documents in the USA in 1958.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 15], [16, 25], [26, 28], [29, 32], [33, 37], [38, 42], [43, 47], [48, 51], [52, 61], [62, 64], [65, 68], [69, 72], [73, 74], [74, 82], [83, 90], [91, 102], [102, 103], [103, 104], [105, 110], [111, 118], [119, 121], [122, 124], [125, 128], [129, 133], [134, 142], [143, 146], [147, 157], [158, 167], [168, 170], [171, 174], [175, 178], [179, 181], [182, 186], [186, 187]]}
{"doc_key": "ai-test-119", "ner": [[0, 2, "misc"], [18, 19, "field"], [22, 23, "field"], [26, 26, "field"], [28, 29, "field"], [31, 32, "field"], [33, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[18, 19, 0, 2, "usage", "", false, false], [22, 23, 18, 19, "part-of", "", false, false], [26, 26, 0, 2, "usage", "", false, false], [28, 29, 0, 2, "usage", "", false, false], [31, 32, 0, 2, "usage", "", false, false], [33, 33, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Local", "search", "algorithms", "have", "been", "widely", "applied", "to", "a", "number", "of", "challenging", "computational", "problems", ",", "including", "problems", "in", "computer", "science", "(", "especially", "artificial", "intelligence", ")", ",", "mathematics", ",", "operations", "research", ",", "engineering", "and", "bioinformatics", "."], "sentence-detokenized": "Local search algorithms have been widely applied to a number of challenging computational problems, including problems in computer science (especially artificial intelligence), mathematics, operations research, engineering and bioinformatics.", "token2charspan": [[0, 5], [6, 12], [13, 23], [24, 28], [29, 33], [34, 40], [41, 48], [49, 51], [52, 53], [54, 60], [61, 63], [64, 75], [76, 89], [90, 98], [98, 99], [100, 109], [110, 118], [119, 121], [122, 130], [131, 138], [139, 140], [140, 150], [151, 161], [162, 174], [174, 175], [175, 176], [177, 188], [188, 189], [190, 200], [201, 209], [209, 210], [211, 222], [223, 226], [227, 241], [241, 242]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [8, 8, "location"], [9, 10, "country"], [14, 14, "country"], [18, 19, "algorithm"], [23, 25, "algorithm"], [26, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 8, 8, "physical", "", false, false], [0, 1, 14, 14, "general-affiliation", "nationality", false, false], [0, 1, 18, 19, "general-affiliation", "topic_of_study", false, false], [0, 1, 23, 25, "general-affiliation", "topic_of_study", false, false], [8, 8, 9, 10, "physical", "", false, false], [23, 25, 26, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "born", "3", "September", "1947", ",", "Walsdorf", ",", "Germany", ")", "is", "a", "German", "psychologist", "who", "studies", "bounded", "rationality", "and", "the", "use", "of", "heuristics", "in", "decision", "-", "making", "."], "sentence-detokenized": "Gerd Gigerenzer (born 3 September 1947, Walsdorf, Germany) is a German psychologist who studies bounded rationality and the use of heuristics in decision-making.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 21], [22, 23], [24, 33], [34, 38], [38, 39], [40, 48], [48, 49], [50, 57], [57, 58], [59, 61], [62, 63], [64, 70], [71, 83], [84, 87], [88, 95], [96, 103], [104, 115], [116, 119], [120, 123], [124, 127], [128, 130], [131, 141], [142, 144], [145, 153], [153, 154], [154, 160], [160, 161]]}
{"doc_key": "ai-test-121", "ner": [[0, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["and", "minimise", "the", "mean", "squared", "error", "."], "sentence-detokenized": "and minimise the mean squared error.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 21], [22, 29], [30, 35], [35, 36]]}
{"doc_key": "ai-test-122", "ner": [[9, 12, "misc"], [14, 16, "organisation"], [38, 48, "field"], [34, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[9, 12, 14, 16, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["However", ",", "even", "official", "languages", "with", "regulating", "societies", ",", "such", "as", "standard", "French", "with", "the", "Acad\u00e9mie", "Fran\u00e7aise", ",", "are", "not", "so", "constitutive", "as", "to", "be", "classified", "as", "constitutive", "languages", "or", "so", "controlled", "as", "controlled", "natural", "languages", "(", "e.g.", "in", "the", "field", "of", "natural", "language", "processing", ")", ",", "due", "to", "their", "prescriptive", "points", ".", "The", "term", "'", "natural", "language", "'", "is", "used", "in", "the", "following", "way", "."], "sentence-detokenized": "However, even official languages with regulating societies, such as standard French with the Acad\u00e9mie Fran\u00e7aise, are not so constitutive as to be classified as constitutive languages or so controlled as controlled natural languages (e.g. in the field of natural language processing), due to their prescriptive points. The term 'natural language' is used in the following way.", "token2charspan": [[0, 7], [7, 8], [9, 13], [14, 22], [23, 32], [33, 37], [38, 48], [49, 58], [58, 59], [60, 64], [65, 67], [68, 76], [77, 83], [84, 88], [89, 92], [93, 101], [102, 111], [111, 112], [113, 116], [117, 120], [121, 123], [124, 136], [137, 139], [140, 142], [143, 145], [146, 156], [157, 159], [160, 172], [173, 182], [183, 185], [186, 188], [189, 199], [200, 202], [203, 213], [214, 221], [222, 231], [232, 233], [233, 237], [238, 240], [241, 244], [245, 250], [251, 253], [254, 261], [262, 270], [271, 281], [281, 282], [282, 283], [284, 287], [288, 290], [291, 296], [297, 309], [310, 316], [316, 317], [318, 321], [322, 326], [327, 328], [328, 335], [336, 344], [344, 345], [346, 348], [349, 353], [354, 356], [357, 360], [361, 370], [371, 374], [374, 375]]}
{"doc_key": "ai-test-123", "ner": [[0, 1, "metrics"]], "ner_mapping_to_source": [2], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "indicator", "measures", "the", "percentage", "of", "all", "instances", "that", "are", "correctly", "classified", "."], "sentence-detokenized": "This indicator measures the percentage of all instances that are correctly classified.", "token2charspan": [[0, 4], [5, 14], [15, 23], [24, 27], [28, 38], [39, 41], [42, 45], [46, 55], [56, 60], [61, 64], [65, 74], [75, 85], [85, 86]]}
{"doc_key": "ai-test-124", "ner": [[0, 0, "researcher"], [6, 10, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 10, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cardy", "became", "a", "Fellow", "of", "the", "Association", "for", "Computational", "Linguistics", "in", "2016", "."], "sentence-detokenized": "Cardy became a Fellow of the Association for Computational Linguistics in 2016.", "token2charspan": [[0, 5], [6, 12], [13, 14], [15, 21], [22, 24], [25, 28], [29, 40], [41, 44], [45, 58], [59, 70], [71, 73], [74, 78], [78, 79]]}
{"doc_key": "ai-test-125", "ner": [[4, 10, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Parameter", "learning", "is", "usually", "done", "by", "maximum", "likelihood", "learning", "of", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i", ";\\", "theta", ")", "/", "math", "."], "sentence-detokenized": "Parameter learning is usually done by maximum likelihood learning of mathp (Y _ i | X _ i;\\ theta) / math.", "token2charspan": [[0, 9], [10, 18], [19, 21], [22, 29], [30, 34], [35, 37], [38, 45], [46, 56], [57, 65], [66, 68], [69, 74], [75, 76], [76, 77], [78, 79], [80, 81], [82, 83], [84, 85], [86, 87], [88, 89], [89, 91], [92, 97], [97, 98], [99, 100], [101, 105], [105, 106]]}
{"doc_key": "ai-test-126", "ner": [[6, 7, "task"], [0, 5, "algorithm"], [9, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 6, 7, "usage", "", true, false], [9, 10, 0, 5, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Non", "-negative", "matrix", "factor", "methods", "for", "cluster", "analysis", "and", "descriptive", "mining", "."], "sentence-detokenized": "Non-negative matrix factor methods for cluster analysis and descriptive mining.", "token2charspan": [[0, 3], [3, 12], [13, 19], [20, 26], [27, 34], [35, 38], [39, 46], [47, 55], [56, 59], [60, 71], [72, 78], [78, 79]]}
{"doc_key": "ai-test-127", "ner": [[0, 1, "field"], [5, 7, "field"], [12, 13, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 13, 0, 1, "part-of", "", false, false], [12, 13, 5, 7, "part-of", "", false, false], [16, 17, 0, 1, "part-of", "", false, false], [16, 17, 5, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", "and", "the", "information", "technologies", "that", "enable", "it", ",", "improving", "natural", "language", "processing", "and", "machine", "learning", "capabilities", "in", "computers", "is", "a", "long", "-", "term", "challenge", "."], "sentence-detokenized": "In computer science and the information technologies that enable it, improving natural language processing and machine learning capabilities in computers is a long-term challenge.", "token2charspan": [[0, 2], [3, 11], [12, 19], [20, 23], [24, 27], [28, 39], [40, 52], [53, 57], [58, 64], [65, 67], [67, 68], [69, 78], [79, 86], [87, 95], [96, 106], [107, 110], [111, 118], [119, 127], [128, 140], [141, 143], [144, 153], [154, 156], [157, 158], [159, 163], [163, 164], [164, 168], [169, 178], [178, 179]]}
{"doc_key": "ai-test-128", "ner": [[2, 12, "algorithm"], [0, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 12, 0, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "For", "code", "for", "Gabor", "feature", "extraction", "from", "images", "in", "MATLAB", ",", "see", "."], "sentence-detokenized": "(For code for Gabor feature extraction from images in MATLAB, see.", "token2charspan": [[0, 1], [1, 4], [5, 9], [10, 13], [14, 19], [20, 27], [28, 38], [39, 43], [44, 50], [51, 53], [54, 60], [60, 61], [62, 65], [65, 66]]}
{"doc_key": "ai-test-129", "ner": [[0, 0, "misc"], [13, 14, "algorithm"], [18, 18, "task"], [20, 20, "task"], [22, 23, "task"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 13, 14, "general-affiliation", "", false, false], [0, 0, 18, 18, "related-to", "solves_problem_of_type", false, false], [0, 0, 20, 20, "related-to", "solves_problem_of_type", false, false], [0, 0, 22, 23, "related-to", "solves_problem_of_type", false, false], [0, 0, 25, 26, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["NeuralExpert", "determines", "design", "specifications", "around", "the", "type", "of", "problem", "the", "user", "wants", "the", "neural", "network", "to", "solve", "(", "classification", ",", "prediction", ",", "function", "approximation", ",", "cluster", "analysis", ")", "."], "sentence-detokenized": "NeuralExpert determines design specifications around the type of problem the user wants the neural network to solve (classification, prediction, function approximation, cluster analysis).", "token2charspan": [[0, 12], [13, 23], [24, 30], [31, 45], [46, 52], [53, 56], [57, 61], [62, 64], [65, 72], [73, 76], [77, 81], [82, 87], [88, 91], [92, 98], [99, 106], [107, 109], [110, 115], [116, 117], [117, 131], [131, 132], [133, 143], [143, 144], [145, 153], [154, 167], [167, 168], [169, 176], [177, 185], [185, 186], [186, 187]]}
{"doc_key": "ai-test-130", "ner": [[0, 4, "misc"], [28, 30, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "quantisation", "step", "size", "(", "\u0394", ")", "is", "small", "relative", "to", "the", "variation", "in", "the", "signal", "being", "quantised", ",", "it", "is", "relatively", "easy", "to", "show", "that", "the", "mean", "squared", "error", "resulting", "from", "such", "a", "rounding", "operation", "is", "approximately", "math", "Delta", "^", "2", "/", "12", "/", "math.math", "."], "sentence-detokenized": "If the quantisation step size (\u0394) is small relative to the variation in the signal being quantised, it is relatively easy to show that the mean squared error resulting from such a rounding operation is approximately math Delta ^ 2 / 12 / math.math.", "token2charspan": [[0, 2], [3, 6], [7, 19], [20, 24], [25, 29], [30, 31], [31, 32], [32, 33], [34, 36], [37, 42], [43, 51], [52, 54], [55, 58], [59, 68], [69, 71], [72, 75], [76, 82], [83, 88], [89, 98], [98, 99], [100, 102], [103, 105], [106, 116], [117, 121], [122, 124], [125, 129], [130, 134], [135, 138], [139, 143], [144, 151], [152, 157], [158, 167], [168, 172], [173, 177], [178, 179], [180, 188], [189, 198], [199, 201], [202, 215], [216, 220], [221, 226], [227, 228], [229, 230], [231, 232], [233, 235], [236, 237], [238, 247], [247, 248]]}
{"doc_key": "ai-test-131", "ner": [[19, 19, "product"], [28, 31, "researcher"], [33, 34, "researcher"], [36, 38, "researcher"], [40, 41, "researcher"], [43, 45, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Building", "a", "rich", "vocabulary", "with", "an", "appropriate", "ontology", "required", "a", "great", "deal", "of", "effort", ",", "for", "example", ",", "the", "Wordnet", "vocabulary", "took", "many", "man", "-", "years", "of", "work", "G.", "A", ".", "Miller", ",", "R.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Gross", ",", "K", ".", "Miller", "."], "sentence-detokenized": "Building a rich vocabulary with an appropriate ontology required a great deal of effort, for example, the Wordnet vocabulary took many man-years of work G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 8], [9, 10], [11, 15], [16, 26], [27, 31], [32, 34], [35, 46], [47, 55], [56, 64], [65, 66], [67, 72], [73, 77], [78, 80], [81, 87], [87, 88], [89, 92], [93, 100], [100, 101], [102, 105], [106, 113], [114, 124], [125, 129], [130, 134], [135, 138], [138, 139], [139, 144], [145, 147], [148, 152], [153, 155], [156, 157], [157, 158], [159, 165], [165, 166], [167, 169], [170, 178], [178, 179], [180, 182], [183, 185], [186, 194], [194, 195], [196, 198], [199, 204], [204, 205], [206, 207], [207, 208], [209, 215], [215, 216]]}
{"doc_key": "ai-test-132", "ner": [[0, 1, "organisation"], [21, 24, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[21, 24, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Kawasaki", "'s", "portfolio", "also", "includes", "giant", "structures", "such", "as", "retractable", "roofs", "and", "floors", ",", "of", "which", "the", "retractable", "surface", "of", "the", "Sapporo", "Dome", "is", "an", "example", "."], "sentence-detokenized": "Kawasaki's portfolio also includes giant structures such as retractable roofs and floors, of which the retractable surface of the Sapporo Dome is an example.", "token2charspan": [[0, 8], [8, 10], [11, 20], [21, 25], [26, 34], [35, 40], [41, 51], [52, 56], [57, 59], [60, 71], [72, 77], [78, 81], [82, 88], [88, 89], [90, 92], [93, 98], [99, 102], [103, 114], [115, 122], [123, 125], [126, 129], [130, 137], [138, 142], [143, 145], [146, 148], [149, 156], [156, 157]]}
{"doc_key": "ai-test-133", "ner": [[0, 1, "metrics"], [5, 5, "metrics"], [3, 13, "metrics"], [16, 18, "metrics"], [42, 43, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 18, "related-to", "", false, false], [0, 1, 42, 43, "opposite", "alternative_to", false, false], [5, 5, 0, 1, "type-of", "", false, false], [3, 13, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kappa", "statistics", ",", "such", "as", "Fleiss", "'", "Kappa", "and", "Cohen", "'s", "Kappa", ",", "are", "methods", "for", "calculating", "inter-rater", "reliability", "based", "on", "different", "assumptions", "about", "marginal", "and", "prior", "distributions", ",", "and", "are", "often", "used", "in", "other", "contexts", "as", "a", "correction", "for", "chance", "instead", "of", "accuracy", "."], "sentence-detokenized": "Kappa statistics, such as Fleiss' Kappa and Cohen's Kappa, are methods for calculating inter-rater reliability based on different assumptions about marginal and prior distributions, and are often used in other contexts as a correction for chance instead of accuracy.", "token2charspan": [[0, 5], [6, 16], [16, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 39], [40, 43], [44, 49], [49, 51], [52, 57], [57, 58], [59, 62], [63, 70], [71, 74], [75, 86], [87, 98], [99, 110], [111, 116], [117, 119], [120, 129], [130, 141], [142, 147], [148, 156], [157, 160], [161, 166], [167, 180], [180, 181], [182, 185], [186, 189], [190, 195], [196, 200], [201, 203], [204, 209], [210, 218], [219, 221], [222, 223], [224, 234], [235, 238], [239, 245], [246, 253], [254, 256], [257, 265], [265, 266]]}
{"doc_key": "ai-test-134", "ner": [[6, 7, "researcher"], [9, 10, "researcher"], [12, 13, "researcher"], [15, 16, "researcher"], [0, 0, "researcher"], [21, 23, "algorithm"], [24, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 7], "relations": [[6, 7, 0, 0, "role", "student_of", false, false], [9, 10, 0, 0, "role", "student_of", false, false], [12, 13, 0, 0, "role", "student_of", false, false], [15, 16, 0, 0, "role", "student_of", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Schmidhuber", ",", "together", "with", "his", "students", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", "and", "Alex", "Graves", ",", "published", "increasingly", "sophisticated", "recurrent", "neural", "networks", "called", "long", "-", "term", "short", "-", "term", "memory", "(", "LSTM", ")", "."], "sentence-detokenized": "Schmidhuber, together with his students Sepp Hochreiter, Felix Gers, Fred Cummins and Alex Graves, published increasingly sophisticated recurrent neural networks called long-term short-term memory (LSTM).", "token2charspan": [[0, 11], [11, 12], [13, 21], [22, 26], [27, 30], [31, 39], [40, 44], [45, 55], [55, 56], [57, 62], [63, 67], [67, 68], [69, 73], [74, 81], [82, 85], [86, 90], [91, 97], [97, 98], [99, 108], [109, 121], [122, 135], [136, 145], [146, 152], [153, 161], [162, 168], [169, 173], [173, 174], [174, 178], [179, 184], [184, 185], [185, 189], [190, 196], [197, 198], [198, 202], [202, 203], [203, 204]]}
{"doc_key": "ai-test-135", "ner": [[5, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "Launch", "of", "the", "first", "Cobot", "KUKA", "LBR", "3", "."], "sentence-detokenized": "2004 - Launch of the first Cobot KUKA LBR 3.", "token2charspan": [[0, 4], [5, 6], [7, 13], [14, 16], [17, 20], [21, 26], [27, 32], [33, 37], [38, 41], [42, 43], [43, 44]]}
{"doc_key": "ai-test-136", "ner": [[9, 11, "algorithm"], [8, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Two", "approaches", "to", "learning", "for", "disambiguation", "are", "used", ":", "na\u00efve", "Bayes", "classifiers", "and", "decision", "trees", "."], "sentence-detokenized": "Two approaches to learning for disambiguation are used: na\u00efve Bayes classifiers and decision trees.", "token2charspan": [[0, 3], [4, 14], [15, 17], [18, 26], [27, 30], [31, 45], [46, 49], [50, 54], [54, 55], [56, 61], [62, 67], [68, 79], [80, 83], [84, 92], [93, 98], [98, 99]]}
{"doc_key": "ai-test-137", "ner": [[4, 5, "misc"], [12, 12, "person"], [15, 17, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 12, 12, "origin", "", false, false], [4, 5, 15, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "practical", "form", "of", "photography", "was", "introduced", "in", "January", "1839", "by", "Louis", "Daguerre", "and", "Henry", "Fox", "Talbot", "."], "sentence-detokenized": "The first practical form of photography was introduced in January 1839 by Louis Daguerre and Henry Fox Talbot.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 24], [25, 27], [28, 39], [40, 43], [44, 54], [55, 57], [58, 65], [66, 70], [71, 73], [74, 79], [80, 88], [89, 92], [93, 98], [99, 102], [103, 109], [109, 110]]}
{"doc_key": "ai-test-138", "ner": [[3, 3, "task"], [6, 11, "task"], [19, 20, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 19, 20, "part-of", "task_part_of_field", false, false], [6, 11, 19, 20, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "speech", "synthesis", "and", "speech", "recognition", "can", "be", "combined", "to", "enable", "interaction", "with", "mobile", "devices", "via", "a", "language", "processing", "interface", "."], "sentence-detokenized": "For example, speech synthesis and speech recognition can be combined to enable interaction with mobile devices via a language processing interface.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 19], [20, 29], [30, 33], [34, 40], [41, 52], [53, 56], [57, 59], [60, 68], [69, 71], [72, 78], [79, 90], [91, 95], [96, 102], [103, 110], [111, 114], [115, 116], [117, 125], [126, 136], [137, 146], [146, 147]]}
{"doc_key": "ai-test-139", "ner": [[0, 2, "product"], [16, 17, "product"]], "ner_mapping_to_source": [0, 2], "relations": [[0, 2, 16, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Fidget", "can", "be", "programmed", "using", "a", "variety", "of", "software", "and", "programming", "languages", ",", "from", "Java", "to", "Microsoft", "Excel", "."], "sentence-detokenized": "Fidget can be programmed using a variety of software and programming languages, from Java to Microsoft Excel.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 24], [25, 30], [31, 32], [33, 40], [41, 43], [44, 52], [53, 56], [57, 68], [69, 78], [78, 79], [80, 84], [85, 89], [90, 92], [93, 102], [103, 108], [108, 109]]}
{"doc_key": "ai-test-140", "ner": [[1, 4, "field"], [9, 15, "researcher"], [24, 28, "misc"], [18, 18, "field"], [21, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 4, 9, 15, "origin", "", false, false], [9, 15, 18, 18, "general-affiliation", "topic_of_study", false, false], [9, 15, 21, 23, "general-affiliation", "topic_of_study", false, false], [24, 28, 9, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "machine", "learning", "was", "coined", "in", "1959", "by", "Arthur", "Samuel", ",", "a", "pioneer", "in", "the", "field", "of", "computer", "games", "and", "artificial", "intelligence", "at", "IBM", "Corporation", "in", "the", "USA", "."], "sentence-detokenized": "The term machine learning was coined in 1959 by Arthur Samuel, a pioneer in the field of computer games and artificial intelligence at IBM Corporation in the USA.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 25], [26, 29], [30, 36], [37, 39], [40, 44], [45, 47], [48, 54], [55, 61], [61, 62], [63, 64], [65, 72], [73, 75], [76, 79], [80, 85], [86, 88], [89, 97], [98, 103], [104, 107], [108, 118], [119, 131], [132, 134], [135, 138], [139, 150], [151, 153], [154, 157], [158, 161], [161, 162]]}
{"doc_key": "ai-test-141", "ner": [[0, 1, "misc"], [2, 3, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Israeli", "poet", "David", "Avidan", "was", "fascinated", "by", "the", "relationship", "between", "future", "technology", "and", "art", ",", "and", "wanted", "to", "use", "computers", "to", "write", "literature", "."], "sentence-detokenized": "Israeli poet David Avidan was fascinated by the relationship between future technology and art, and wanted to use computers to write literature.", "token2charspan": [[0, 7], [8, 12], [13, 18], [19, 25], [26, 29], [30, 40], [41, 43], [44, 47], [48, 60], [61, 68], [69, 75], [76, 86], [87, 90], [91, 94], [94, 95], [96, 99], [100, 106], [107, 109], [110, 113], [114, 123], [124, 126], [127, 132], [133, 143], [143, 144]]}
{"doc_key": "ai-test-142", "ner": [[2, 8, "misc"], [10, 10, "organisation"], [17, 17, "location"], [26, 30, "location"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[10, 10, 2, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2017", ",", "as", "part", "of", "the", "GATEway", "project", ",", "Oxbotica", "trialled", "seven", "autonomous", "shuttle", "buses", "in", "Greenwich", ",", "navigating", "a", "two", "-", "mile", "riverside", "path", "near", "The", "O2", "Arena", "in", "London", "on", "a", "route", "used", "by", "pedestrians", "and", "cyclists", "alike", "."], "sentence-detokenized": "In 2017, as part of the GATEway project, Oxbotica trialled seven autonomous shuttle buses in Greenwich, navigating a two-mile riverside path near The O2 Arena in London on a route used by pedestrians and cyclists alike.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 16], [17, 19], [20, 23], [24, 31], [32, 39], [39, 40], [41, 49], [50, 58], [59, 64], [65, 75], [76, 83], [84, 89], [90, 92], [93, 102], [102, 103], [104, 114], [115, 116], [117, 120], [120, 121], [121, 125], [126, 135], [136, 140], [141, 145], [146, 149], [150, 152], [153, 158], [159, 161], [162, 168], [169, 171], [172, 173], [174, 179], [180, 184], [185, 187], [188, 199], [200, 203], [204, 212], [213, 218], [218, 219]]}
{"doc_key": "ai-test-143", "ner": [[10, 10, "task"], [14, 20, "metrics"], [25, 27, "misc"], [28, 28, "metrics"], [31, 31, "metrics"], [34, 34, "metrics"], [36, 36, "metrics"], [38, 40, "metrics"], [43, 44, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[14, 20, 25, 27, "related-to", "is_a", false, false], [14, 20, 28, 28, "usage", "", false, false], [14, 20, 31, 31, "usage", "", false, false], [28, 28, 34, 34, "named", "same", false, false], [34, 34, 43, 44, "opposite", "", false, false], [36, 36, 34, 34, "named", "", false, false], [38, 40, 34, 34, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 7, 8], "sentence": ["An", "unrelated", "but", "often", "used", "combination", "of", "basic", "statistics", "for", "information", "retrieval", "is", "the", "F", "-", "score", ",", "which", "is", "the", "(", "presumably", "weighted", ")", "harmonic", "mean", "of", "recovery", "rate", "and", "accuracy", ".", "Recovery", "rate", "=", "sensitivity", "=", "true", "positive", "rate", ",", "but", "specificity", "and", "precision", "are", "completely", "different", "measures", "."], "sentence-detokenized": "An unrelated but often used combination of basic statistics for information retrieval is the F-score, which is the (presumably weighted) harmonic mean of recovery rate and accuracy. Recovery rate = sensitivity = true positive rate, but specificity and precision are completely different measures.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 22], [23, 27], [28, 39], [40, 42], [43, 48], [49, 59], [60, 63], [64, 75], [76, 85], [86, 88], [89, 92], [93, 94], [94, 95], [95, 100], [100, 101], [102, 107], [108, 110], [111, 114], [115, 116], [116, 126], [127, 135], [135, 136], [137, 145], [146, 150], [151, 153], [154, 162], [163, 167], [168, 171], [172, 180], [180, 181], [182, 190], [191, 195], [196, 197], [198, 209], [210, 211], [212, 216], [217, 225], [226, 230], [230, 231], [232, 235], [236, 247], [248, 251], [252, 261], [262, 265], [266, 276], [277, 286], [287, 295], [295, 296]]}
{"doc_key": "ai-test-144", "ner": [[0, 1, "field"], [7, 7, "field"], [9, 9, "field"], [11, 12, "field"], [14, 16, "field"], [22, 23, "product"], [25, 28, "product"], [30, 31, "product"], [20, 35, "product"], [5, 51, "product"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 7, 7, "origin", "takes_inspiration_from", false, false], [0, 1, 9, 9, "origin", "takes_inspiration_from", false, false], [0, 1, 11, 12, "origin", "takes_inspiration_from", false, false], [0, 1, 14, 16, "origin", "takes_inspiration_from", false, false], [22, 23, 0, 1, "origin", "", false, false], [25, 28, 0, 1, "origin", "", false, false], [30, 31, 0, 1, "origin", "", false, false], [20, 35, 0, 1, "origin", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Neuromorphic", "engineering", "draws", "inspiration", "from", "biology", ",", "physics", ",", "mathematics", ",", "computer", "science", "and", "electronics", "to", "design", "artificial", "neural", "systems", "such", "as", "visual", "systems", ",", "head", "-", "eye", "systems", ",", "auditory", "processors", "and", "autonomous", "robots", "whose", "physical", "architecture", "and", "design", "principles", "are", "It", "is", "an", "interdisciplinary", "subject", "that", "is", "based", "on", "the", "design", "of"], "sentence-detokenized": "Neuromorphic engineering draws inspiration from biology, physics, mathematics, computer science and electronics to design artificial neural systems such as visual systems, head-eye systems, auditory processors and autonomous robots whose physical architecture and design principles are It is an interdisciplinary subject that is based on the design of", "token2charspan": [[0, 12], [13, 24], [25, 30], [31, 42], [43, 47], [48, 55], [55, 56], [57, 64], [64, 65], [66, 77], [77, 78], [79, 87], [88, 95], [96, 99], [100, 111], [112, 114], [115, 121], [122, 132], [133, 139], [140, 147], [148, 152], [153, 155], [156, 162], [163, 170], [170, 171], [172, 176], [176, 177], [177, 180], [181, 188], [188, 189], [190, 198], [199, 209], [210, 213], [214, 224], [225, 231], [232, 237], [238, 246], [247, 259], [260, 263], [264, 270], [271, 281], [282, 285], [286, 288], [289, 291], [292, 294], [295, 312], [313, 320], [321, 325], [326, 328], [329, 334], [335, 337], [338, 341], [342, 348], [349, 351]]}
{"doc_key": "ai-test-145", "ner": [[3, 5, "metrics"], [9, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 3, 5, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Specifically", ",", "the", "BIBO", "stability", "criterion", "requires", "that", "the", "ROC", "of", "the", "system", "includes", "a", "unit", "circle", "."], "sentence-detokenized": "Specifically, the BIBO stability criterion requires that the ROC of the system includes a unit circle.", "token2charspan": [[0, 12], [12, 13], [14, 17], [18, 22], [23, 32], [33, 42], [43, 51], [52, 56], [57, 60], [61, 64], [65, 67], [68, 71], [72, 78], [79, 87], [88, 89], [90, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-test-146", "ner": [[7, 7, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "The", "programme", "has", "been", "rewritten", "in", "Java", "since", "1998", "."], "sentence-detokenized": "2 The programme has been rewritten in Java since 1998.", "token2charspan": [[0, 1], [2, 5], [6, 15], [16, 19], [20, 24], [25, 34], [35, 37], [38, 42], [43, 48], [49, 53], [53, 54]]}
{"doc_key": "ai-test-147", "ner": [[0, 3, "metrics"], [7, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 7, 9, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "MCC", "can", "be", "calculated", "directly", "from", "the", "confusion", "matrix", "using", "the", "formula"], "sentence-detokenized": "The MCC can be calculated directly from the confusion matrix using the formula", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 25], [26, 34], [35, 39], [40, 43], [44, 53], [54, 60], [61, 66], [67, 70], [71, 78]]}
{"doc_key": "ai-test-148", "ner": [[3, 8, "organisation"], [14, 20, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 8, 14, 20, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Developed", "by", "the", "MIT", "-", "IBM", "Watson", "AI", "Lab", "team", "and", "first", "presented", "at", "the", "2018", "International", "Conference", "on", "Learning", "Representations", "."], "sentence-detokenized": "Developed by the MIT-IBM Watson AI Lab team and first presented at the 2018 International Conference on Learning Representations.", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 20], [20, 21], [21, 24], [25, 31], [32, 34], [35, 38], [39, 43], [44, 47], [48, 53], [54, 63], [64, 66], [67, 70], [71, 75], [76, 89], [90, 100], [101, 103], [104, 112], [113, 128], [128, 129]]}
{"doc_key": "ai-test-149", "ner": [[0, 4, "metrics"], [15, 15, "metrics"], [18, 20, "metrics"], [49, 49, "metrics"], [53, 56, "metrics"], [61, 61, "metrics"], [63, 63, "metrics"], [65, 68, "metrics"], [72, 72, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9], "relations": [[15, 15, 53, 56, "related-to", "collapses_to_identity", false, false], [18, 20, 49, 49, "type-of", "", false, false], [18, 20, 53, 56, "related-to", "collapses_to_identity", false, false], [18, 20, 65, 68, "named", "same", false, false], [61, 61, 72, 72, "related-to", "collapses_to_identity", false, false], [63, 63, 72, 72, "related-to", "collapses_to_identity", false, false], [65, 68, 72, 72, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "sentence": ["If", "the", "TRUE", "prevalence", "of", "two", "positive", "variables", "is", "equal", ",", "as", "assumed", "for", "the", "Fleiss", "kappa", "and", "F", "-", "score", ",", "i.e.", "the", "number", "of", "positive", "predictions", "matches", "the", "number", "of", "positive", "classes", "in", "the", "dichotomous", "(", "two", "-", "class", ")", "case", ",", "then", "the", "different", "kappa", "and", "correlation", "measures", "collapse", "to", "Youden", "'s", "J", "and", "identity", ",", "and", "the", "repeatability", ",", "precision", "and", "F", "-", "score", "are", "likewise", "identical", "to", "accuracy", "."], "sentence-detokenized": "If the TRUE prevalence of two positive variables is equal, as assumed for the Fleiss kappa and F-score, i.e. the number of positive predictions matches the number of positive classes in the dichotomous (two-class) case, then the different kappa and correlation measures collapse to Youden's J and identity, and the repeatability, precision and F-score are likewise identical to accuracy.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 22], [23, 25], [26, 29], [30, 38], [39, 48], [49, 51], [52, 57], [57, 58], [59, 61], [62, 69], [70, 73], [74, 77], [78, 84], [85, 90], [91, 94], [95, 96], [96, 97], [97, 102], [102, 103], [104, 108], [109, 112], [113, 119], [120, 122], [123, 131], [132, 143], [144, 151], [152, 155], [156, 162], [163, 165], [166, 174], [175, 182], [183, 185], [186, 189], [190, 201], [202, 203], [203, 206], [206, 207], [207, 212], [212, 213], [214, 218], [218, 219], [220, 224], [225, 228], [229, 238], [239, 244], [245, 248], [249, 260], [261, 269], [270, 278], [279, 281], [282, 288], [288, 290], [291, 292], [293, 296], [297, 305], [305, 306], [307, 310], [311, 314], [315, 328], [328, 329], [330, 339], [340, 343], [344, 345], [345, 346], [346, 351], [352, 355], [356, 364], [365, 374], [375, 377], [378, 386], [386, 387]]}
{"doc_key": "ai-test-150", "ner": [[12, 12, "misc"], [9, 16, "misc"], [18, 18, "conference"], [2, 5, "task"], [21, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 18, 18, "part-of", "", false, false], [12, 12, 18, 18, "physical", "", false, false], [12, 12, 18, 18, "temporal", "", false, false], [9, 16, 12, 12, "named", "", false, false], [2, 5, 12, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "first", "NLI", "sharing", "task", "was", "held", "at", "the", "Building", "Educational", "Applications", "workshop", "(", "BEA", ")", "of", "the", "NAACL", "2013", ";", "Tetreault", "et", "al", ",", "2013", "The", "competition", "attracted", "29", "entries", "from", "teams", "around", "the", "world", ".", "24", "of", "these", "teams", "also", "presented", "papers", "describing", "their", "systems", "and", "approaches", "."], "sentence-detokenized": "The first NLI sharing task was held at the Building Educational Applications workshop (BEA) of the NAACL 2013; Tetreault et al, 2013 The competition attracted 29 entries from teams around the world. 24 of these teams also presented papers describing their systems and approaches.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 21], [22, 26], [27, 30], [31, 35], [36, 38], [39, 42], [43, 51], [52, 63], [64, 76], [77, 85], [86, 87], [87, 90], [90, 91], [92, 94], [95, 98], [99, 104], [105, 109], [109, 110], [111, 120], [121, 123], [124, 126], [126, 127], [128, 132], [133, 136], [137, 148], [149, 158], [159, 161], [162, 169], [170, 174], [175, 180], [181, 187], [188, 191], [192, 197], [197, 198], [199, 201], [202, 204], [205, 210], [211, 216], [217, 221], [222, 231], [232, 238], [239, 249], [250, 255], [256, 263], [264, 267], [268, 278], [278, 279]]}
{"doc_key": "ai-test-151", "ner": [[0, 2, "algorithm"], [5, 7, "algorithm"], [31, 31, "misc"], [36, 42, "misc"], [14, 14, "misc"], [18, 19, "algorithm"], [21, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 5, 7, "type-of", "", false, false], [0, 2, 31, 31, "related-to", "finds", false, false], [36, 42, 31, 31, "type-of", "", false, false], [21, 24, 18, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Viterbi", "algorithm", "is", "a", "dynamic", "programming", "method", ",", "particularly", "in", "the", "context", "of", "Markov", "sources", "and", "hidden", "Markov", "models", "(", "HMMs", ")", ",", "that", "seeks", "the", "most", "likely", "sequence", "of", "hidden", "states", ",", "called", "the", "Viterbi", "path", ",", "that", "results", "in", "a", "sequence", "of", "observed", "events", "."], "sentence-detokenized": "The Viterbi algorithm is a dynamic programming method, particularly in the context of Markov sources and hidden Markov models (HMMs), that seeks the most likely sequence of hidden states, called the Viterbi path, that results in a sequence of observed events.", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 24], [25, 26], [27, 34], [35, 46], [47, 53], [53, 54], [55, 67], [68, 70], [71, 74], [75, 82], [83, 85], [86, 92], [93, 100], [101, 104], [105, 111], [112, 118], [119, 125], [126, 127], [127, 131], [131, 132], [132, 133], [134, 138], [139, 144], [145, 148], [149, 153], [154, 160], [161, 169], [170, 172], [173, 179], [180, 186], [186, 187], [188, 194], [195, 198], [199, 206], [207, 211], [211, 212], [213, 217], [218, 225], [226, 228], [229, 230], [231, 239], [240, 242], [243, 251], [252, 258], [258, 259]]}
{"doc_key": "ai-test-152", "ner": [[0, 1, "field"], [3, 7, "algorithm"], [8, 19, "misc"], [11, 13, "algorithm"], [14, 17, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 7, 0, 1, "part-of", "", false, false], [3, 7, 8, 19, "general-affiliation", "", false, false], [3, 7, 11, 13, "related-to", "generalizes_from", false, false], [3, 7, 14, 17, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "statistics", ",", "multinomial", "logistic", "regression", "is", "a", "taxonomy", "that", "generalises", "logistic", "regression", "to", "a", "multi", "-class", "classification", ",", "i.e.", "one", "with", "more", "than", "two", "possible", "discrete", "outcomes", "."], "sentence-detokenized": "In statistics, multinomial logistic regression is a taxonomy that generalises logistic regression to a multi-class classification, i.e. one with more than two possible discrete outcomes.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 26], [27, 35], [36, 46], [47, 49], [50, 51], [52, 60], [61, 65], [66, 77], [78, 86], [87, 97], [98, 100], [101, 102], [103, 108], [108, 114], [115, 129], [129, 130], [131, 135], [136, 139], [140, 144], [145, 149], [150, 154], [155, 158], [159, 167], [168, 176], [177, 185], [185, 186]]}
{"doc_key": "ai-test-153", "ner": [[0, 2, "algorithm"], [9, 9, "field"], [12, 14, "field"], [17, 17, "task"], [15, 22, "task"], [24, 25, "researcher"], [27, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6, 7], "relations": [[0, 2, 9, 9, "part-of", "", false, false], [0, 2, 12, 14, "part-of", "", false, false], [17, 17, 0, 2, "usage", "", true, false], [15, 22, 0, 2, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 4], "sentence": ["Hidden", "Markov", "models", "are", "known", "for", "their", "applications", "in", "reinforcement", "learning", "and", "temporal", "pattern", "recognition", "such", "as", "speech", ",", "handwriting", "and", "gesture", "recognition", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Hidden Markov models are known for their applications in reinforcement learning and temporal pattern recognition such as speech, handwriting and gesture recognition, Thad Starner, Alex Pentland.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 30], [31, 34], [35, 40], [41, 53], [54, 56], [57, 70], [71, 79], [80, 83], [84, 92], [93, 100], [101, 112], [113, 117], [118, 120], [121, 127], [127, 128], [129, 140], [141, 144], [145, 152], [153, 164], [164, 165], [166, 170], [171, 178], [178, 179], [180, 184], [185, 193], [193, 194]]}
{"doc_key": "ai-test-154", "ner": [[26, 30, "metrics"], [33, 34, "misc"]], "ner_mapping_to_source": [1, 2], "relations": [[26, 30, 33, 34, "related-to", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["This", "means", "that", "if", "a", "word", "occurs", "more", "than", "k", "times", "during", "training", ",", "the", "conditional", "probability", "obtained", "from", "the", "word", "'s", "history", "is", "proportional", "to", "the", "maximum", "likelihood", "estimate", "of", "its", "n", "-", "gram", "."], "sentence-detokenized": "This means that if a word occurs more than k times during training, the conditional probability obtained from the word's history is proportional to the maximum likelihood estimate of its n -gram.", "token2charspan": [[0, 4], [5, 10], [11, 15], [16, 18], [19, 20], [21, 25], [26, 32], [33, 37], [38, 42], [43, 44], [45, 50], [51, 57], [58, 66], [66, 67], [68, 71], [72, 83], [84, 95], [96, 104], [105, 109], [110, 113], [114, 118], [118, 120], [121, 128], [129, 131], [132, 144], [145, 147], [148, 151], [152, 159], [160, 170], [171, 179], [180, 182], [183, 186], [187, 188], [189, 190], [190, 194], [194, 195]]}
{"doc_key": "ai-test-155", "ner": [[4, 5, "task"], [7, 8, "task"], [10, 12, "task"], [17, 19, "task"], [22, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[22, 29, 17, 19, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "interested", "in", "knowledge", "representation", ",", "commonsense", "reasoning", "and", "natural", "language", "understanding", ",", "and", "believes", "that", "deep", "language", "understanding", "can", "currently", "only", "be", "achieved", "through", "significant", "manual", "engineering", "of", "semantically", "rich", "formalisms", "coupled", "with", "statistical", "preferences", "."], "sentence-detokenized": "He is interested in knowledge representation, commonsense reasoning and natural language understanding, and believes that deep language understanding can currently only be achieved through significant manual engineering of semantically rich formalisms coupled with statistical preferences.", "token2charspan": [[0, 2], [3, 5], [6, 16], [17, 19], [20, 29], [30, 44], [44, 45], [46, 57], [58, 67], [68, 71], [72, 79], [80, 88], [89, 102], [102, 103], [104, 107], [108, 116], [117, 121], [122, 126], [127, 135], [136, 149], [150, 153], [154, 163], [164, 168], [169, 171], [172, 180], [181, 188], [189, 200], [201, 207], [208, 219], [220, 222], [223, 235], [236, 240], [241, 251], [252, 259], [260, 264], [265, 276], [277, 288], [288, 289]]}
{"doc_key": "ai-test-156", "ner": [[0, 0, "programlang"], [2, 2, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["JavaScript", ",", "Python", "or"], "sentence-detokenized": "JavaScript, Python or", "token2charspan": [[0, 10], [10, 11], [12, 18], [19, 21]]}
{"doc_key": "ai-test-157", "ner": [[0, 2, "misc"], [6, 7, "misc"], [10, 11, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 7, "part-of", "", false, false], [6, 7, 10, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Newcomb", "Awards", "are", "announced", "in", "AI", "Magazine", ",", "published", "by", "AAAI", "."], "sentence-detokenized": "The Newcomb Awards are announced in AI Magazine, published by AAAI.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 22], [23, 32], [33, 35], [36, 38], [39, 47], [47, 48], [49, 58], [59, 61], [62, 66], [66, 67]]}
{"doc_key": "ai-test-158", "ner": [[0, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "squared", "error", "on", "the", "test", "set", "of", "100", "exemplars", "is", "0.084", ",", "which", "is", "smaller", "than", "the", "denormalised", "error", "."], "sentence-detokenized": "The mean squared error on the test set of 100 exemplars is 0.084, which is smaller than the denormalised error.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 25], [26, 29], [30, 34], [35, 38], [39, 41], [42, 45], [46, 55], [56, 58], [59, 64], [64, 65], [66, 71], [72, 74], [75, 82], [83, 87], [88, 91], [92, 104], [105, 110], [110, 111]]}
{"doc_key": "ai-test-159", "ner": [[0, 3, "metrics"], [8, 10, "field"], [16, 20, "task"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 3, 4], "relations": [[8, 10, 0, 3, "usage", "", false, false], [23, 24, 8, 10, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 3], "sentence": ["F", "-", "scores", "are", "widely", "used", "in", "the", "natural", "language", "processing", "literature", ",", "such", "as", "in", "Named", "Entity", "Recognition", "(", "NER", ")", "and", "word", "segmentation", "evaluation", "."], "sentence-detokenized": "F-scores are widely used in the natural language processing literature, such as in Named Entity Recognition (NER) and word segmentation evaluation.", "token2charspan": [[0, 1], [1, 2], [2, 8], [9, 12], [13, 19], [20, 24], [25, 27], [28, 31], [32, 39], [40, 48], [49, 59], [60, 70], [70, 71], [72, 76], [77, 79], [80, 82], [83, 88], [89, 95], [96, 107], [108, 109], [109, 112], [112, 113], [114, 117], [118, 122], [123, 135], [136, 146], [146, 147]]}
{"doc_key": "ai-test-160", "ner": [[0, 1, "product"], [5, 7, "product"], [15, 16, "misc"], [18, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 15, 16, "related-to", "performs_task", false, false], [0, 1, 18, 18, "related-to", "performs_task", false, false], [5, 7, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Chatbots", "are", "commonly", "used", "in", "dialogue", "systems", "for", "various", "purposes", "such", "as", "customer", "service", ",", "request", "routing", "and", "information", "gathering", "."], "sentence-detokenized": "Chatbots are commonly used in dialogue systems for various purposes such as customer service, request routing and information gathering.", "token2charspan": [[0, 8], [9, 12], [13, 21], [22, 26], [27, 29], [30, 38], [39, 46], [47, 50], [51, 58], [59, 67], [68, 72], [73, 75], [76, 84], [85, 92], [92, 93], [94, 101], [102, 109], [110, 113], [114, 125], [126, 135], [135, 136]]}
{"doc_key": "ai-test-161", "ner": [[3, 9, "conference"], [12, 21, "conference"], [26, 36, "conference"], [43, 43, "conference"], [47, 50, "conference"], [53, 53, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 21, 3, 9, "named", "", false, false], [26, 36, 3, 9, "named", "", false, false], [43, 43, 26, 36, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Important", "journals", "include", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "later", "renamed", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "and", "since", "September", "2014", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "-", "renamed", "after", "the", "merger", "with", "ACM", "Publishing", ")", ",", "Computer", "Speech", "and", "Language", "and", "Speech", "Communication", "."], "sentence-detokenized": "Important journals include IEEE Transactions on Speech and Audio Processing (later renamed IEEE Transactions on Audio, Speech and Language Processing and since September 2014 IEEE / ACM Transactions on Audio, Speech and Language Processing - renamed after the merger with ACM Publishing), Computer Speech and Language and Speech Communication.", "token2charspan": [[0, 9], [10, 18], [19, 26], [27, 31], [32, 44], [45, 47], [48, 54], [55, 58], [59, 64], [65, 75], [76, 77], [77, 82], [83, 90], [91, 95], [96, 108], [109, 111], [112, 117], [117, 118], [119, 125], [126, 129], [130, 138], [139, 149], [150, 153], [154, 159], [160, 169], [170, 174], [175, 179], [180, 181], [182, 185], [186, 198], [199, 201], [202, 207], [207, 208], [209, 215], [216, 219], [220, 228], [229, 239], [240, 241], [242, 249], [250, 255], [256, 259], [260, 266], [267, 271], [272, 275], [276, 286], [286, 287], [287, 288], [289, 297], [298, 304], [305, 308], [309, 317], [318, 321], [322, 328], [329, 342], [342, 343]]}
{"doc_key": "ai-test-162", "ner": [[0, 1, "algorithm"], [5, 7, "task"], [8, 8, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 7, 0, 1, "usage", "", false, false], [5, 7, 8, 8, "part-of", "task_part_of_field", false, false], [5, 7, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["EM", "is", "often", "used", "for", "data", "clustering", "in", "machine", "learning", "and", "computer", "vision", "."], "sentence-detokenized": "EM is often used for data clustering in machine learning and computer vision.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 16], [17, 20], [21, 25], [26, 36], [37, 39], [40, 47], [48, 56], [57, 60], [61, 69], [70, 76], [76, 77]]}
{"doc_key": "ai-test-163", "ner": [[12, 15, "metrics"], [20, 23, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 15, 20, 23, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["Although", "there", "is", "no", "perfect", "way", "to", "express", "a", "true", "-", "false", "confusion", "matrix", "in", "a", "single", "number", ",", "the", "Matthews", "correlation", "coefficient", "is", "generally", "considered", "the", "best", "such", "measure", "."], "sentence-detokenized": "Although there is no perfect way to express a true-false confusion matrix in a single number, the Matthews correlation coefficient is generally considered the best such measure.", "token2charspan": [[0, 8], [9, 14], [15, 17], [18, 20], [21, 28], [29, 32], [33, 35], [36, 43], [44, 45], [46, 50], [50, 51], [51, 56], [57, 66], [67, 73], [74, 76], [77, 78], [79, 85], [86, 92], [92, 93], [94, 97], [98, 106], [107, 118], [119, 130], [131, 133], [134, 143], [144, 154], [155, 158], [159, 163], [164, 168], [169, 176], [176, 177]]}
{"doc_key": "ai-test-164", "ner": [[13, 17, "field"], [21, 24, "field"], [67, 68, "field"], [26, 27, "algorithm"], [29, 30, "task"], [32, 33, "algorithm"], [38, 39, "algorithm"], [42, 43, "algorithm"], [48, 50, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[67, 68, 21, 24, "part-of", "subfield", false, false], [26, 27, 67, 68, "part-of", "", false, true], [29, 30, 67, 68, "part-of", "", false, true], [32, 33, 67, 68, "part-of", "", false, true], [38, 39, 67, 68, "part-of", "", false, true], [42, 43, 67, 68, "part-of", "", false, true], [48, 50, 67, 68, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "data", "sets", "became", "larger", "and", "more", "complex", ",", "direct", "hands", "-", "on", "data", "analysis", "was", "augmented", "by", "other", "discoveries", "in", "computer", "science", ",", "in", "particular", "neural", "networks", ",", "cluster", "analysis", ",", "genetic", "algorithms", "(", "1950s", ")", ",", "decision", "tree", "learning", "and", "decision", "rules", "(", "1960s", ")", ",", "support", "vector", "machines", "(", "1990", "s", ")", "It", "was", "indirectly", "augmented", "by", "automatic", "data", "processing", "with", "the", "help", "of", "machine", "learning", "disciplines", "such", "as"], "sentence-detokenized": "As data sets became larger and more complex, direct hands-on data analysis was augmented by other discoveries in computer science, in particular neural networks, cluster analysis, genetic algorithms (1950s), decision tree learning and decision rules (1960s), support vector machines (1990s) It was indirectly augmented by automatic data processing with the help of machine learning disciplines such as", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 19], [20, 26], [27, 30], [31, 35], [36, 43], [43, 44], [45, 51], [52, 57], [57, 58], [58, 60], [61, 65], [66, 74], [75, 78], [79, 88], [89, 91], [92, 97], [98, 109], [110, 112], [113, 121], [122, 129], [129, 130], [131, 133], [134, 144], [145, 151], [152, 160], [160, 161], [162, 169], [170, 178], [178, 179], [180, 187], [188, 198], [199, 200], [200, 205], [205, 206], [206, 207], [208, 216], [217, 221], [222, 230], [231, 234], [235, 243], [244, 249], [250, 251], [251, 256], [256, 257], [257, 258], [259, 266], [267, 273], [274, 282], [283, 284], [284, 288], [288, 289], [289, 290], [291, 293], [294, 297], [298, 308], [309, 318], [319, 321], [322, 331], [332, 336], [337, 347], [348, 352], [353, 356], [357, 361], [362, 364], [365, 372], [373, 381], [382, 393], [394, 398], [399, 401]]}
{"doc_key": "ai-test-165", "ner": [[4, 4, "researcher"], [21, 24, "misc"], [13, 14, "researcher"], [6, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 24, 4, 4, "artifact", "", false, false], [21, 24, 13, 14, "artifact", "", false, false], [21, 24, 6, 17, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "autumn", "2005", ",", "Slan", ",", "together", "with", "his", "long", "-", "time", "collaborators", "Dieter", "Fox", "and", "Wolfram", "Baggard", ",", "published", "a", "textbook", "entitled", "Probabilistic", "Robotics", "."], "sentence-detokenized": "In autumn 2005, Slan, together with his long-time collaborators Dieter Fox and Wolfram Baggard, published a textbook entitled Probabilistic Robotics.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 20], [20, 21], [22, 30], [31, 35], [36, 39], [40, 44], [44, 45], [45, 49], [50, 63], [64, 70], [71, 74], [75, 78], [79, 86], [87, 94], [94, 95], [96, 105], [106, 107], [108, 116], [117, 125], [126, 139], [140, 148], [148, 149]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "and", "Pereiramath", "are", "listed", "below", "."], "sentence-detokenized": "John D. Lafferty, Andrew McCallum and Pereiramath are listed below.", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 37], [38, 49], [50, 53], [54, 60], [61, 66], [66, 67]]}
{"doc_key": "ai-test-167", "ner": [[0, 6, "task"], [8, 12, "field"], [15, 15, "field"], [20, 20, "field"], [18, 22, "field"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[15, 15, 8, 12, "part-of", "subfield", false, false], [20, 20, 8, 12, "part-of", "subfield", false, false], [18, 22, 20, 20, "named", "", false, false]], "relations_mapping_to_source": [3, 4, 5], "sentence": ["Question", "answering", "(", "QA", ")", "is", "a", "branch", "of", "computer", "science", "in", "the", "field", "of", "information", "retrieval", "and", "natural", "language", "processing", "(", "NLP", ")", ",", "concerned", "with", "building", "systems", "that", "automatically", "answer", "questions", "posed", "by", "humans", "in", "natural", "language", "."], "sentence-detokenized": "Question answering (QA) is a branch of computer science in the field of information retrieval and natural language processing (NLP), concerned with building systems that automatically answer questions posed by humans in natural language.", "token2charspan": [[0, 8], [9, 18], [19, 20], [20, 22], [22, 23], [24, 26], [27, 28], [29, 35], [36, 38], [39, 47], [48, 55], [56, 58], [59, 62], [63, 68], [69, 71], [72, 83], [84, 93], [94, 97], [98, 105], [106, 114], [115, 125], [126, 127], [127, 130], [130, 131], [131, 132], [133, 142], [143, 147], [148, 156], [157, 164], [165, 169], [170, 183], [184, 190], [191, 200], [201, 206], [207, 209], [210, 216], [217, 219], [220, 227], [228, 236], [236, 237]]}
{"doc_key": "ai-test-168", "ner": [[3, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "in", "NIST", "assessments", "prior", "to", "2009", ",", "the", "shortest", "reference", "sentence", "was", "used", "instead", "."], "sentence-detokenized": "However, in NIST assessments prior to 2009, the shortest reference sentence was used instead.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 16], [17, 28], [29, 34], [35, 37], [38, 42], [42, 43], [44, 47], [48, 56], [57, 66], [67, 75], [76, 79], [80, 84], [85, 92], [92, 93]]}
{"doc_key": "ai-test-169", "ner": [[15, 15, "product"]], "ner_mapping_to_source": [2], "relations": [], "relations_mapping_to_source": [], "sentence": ["On", "27", "August", "2018", ",", "Toyota", "announced", "a", "USD", "500", "million", "investment", "in", "Uber", "'s", "autonomous", "vehicles", "."], "sentence-detokenized": "On 27 August 2018, Toyota announced a USD 500 million investment in Uber's autonomous vehicles.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 17], [17, 18], [19, 25], [26, 35], [36, 37], [38, 41], [42, 45], [46, 53], [54, 64], [65, 67], [68, 72], [72, 74], [75, 85], [86, 94], [94, 95]]}
{"doc_key": "ai-test-170", "ner": [[4, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sample", "maximum", "is", "the", "maximum", "likelihood", "estimate", "of", "the", "population", "maximum", ",", "but", "it", "is", "biased", "as", "discussed", "above", "."], "sentence-detokenized": "The sample maximum is the maximum likelihood estimate of the population maximum, but it is biased as discussed above.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 21], [22, 25], [26, 33], [34, 44], [45, 53], [54, 56], [57, 60], [61, 71], [72, 79], [79, 80], [81, 84], [85, 87], [88, 90], [91, 97], [98, 100], [101, 110], [111, 116], [116, 117]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [3, 4, "misc"], [5, 11, "metrics"], [16, 16, "algorithm"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 4, "related-to", "overcomes", false, false], [0, 0, 5, 11, "related-to", "increases", false, false], [3, 4, 16, 16, "opposite", "", false, false], [3, 4, 20, 21, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LSI", "can", "help", "overcome", "synonyms", "by", "increasing", "recall", ",", "one", "of", "the", "most", "problematic", "constraints", "in", "Boolean", "keyword", "queries", "and", "vector", "space", "models", "."], "sentence-detokenized": "LSI can help overcome synonyms by increasing recall, one of the most problematic constraints in Boolean keyword queries and vector space models.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 21], [22, 30], [31, 33], [34, 44], [45, 51], [51, 52], [53, 56], [57, 59], [60, 63], [64, 68], [69, 80], [81, 92], [93, 95], [96, 103], [104, 111], [112, 119], [120, 123], [124, 130], [131, 136], [137, 143], [143, 144]]}
{"doc_key": "ai-test-172", "ner": [[0, 1, "task"], [24, 24, "programlang"], [26, 26, "programlang"], [28, 29, "programlang"], [32, 32, "programlang"], [35, 35, "programlang"], [37, 37, "programlang"], [39, 39, "programlang"], [41, 41, "programlang"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 1, 24, 24, "general-affiliation", "", false, false], [0, 1, 26, 26, "general-affiliation", "", false, false], [0, 1, 28, 29, "general-affiliation", "", false, false], [0, 1, 32, 32, "general-affiliation", "", false, false], [0, 1, 35, 35, "general-affiliation", "", false, false], [0, 1, 37, 37, "general-affiliation", "", false, false], [0, 1, 39, 39, "general-affiliation", "", false, false], [0, 1, 41, 41, "general-affiliation", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Data", "collection", "applications", "are", "usually", "controlled", "by", "software", "programmes", "developed", "using", "a", "variety", "of", "general", "-", "purpose", "programming", "languages", ",", "such", "as", "Assembly", ",", "BASIC", ",", "C", ",", "C", "+", "+", ",", "C", "#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", "and", "Pascal", "."], "sentence-detokenized": "Data collection applications are usually controlled by software programmes developed using a variety of general-purpose programming languages, such as Assembly, BASIC, C, C + +, C #, Fortran, Java, LabVIEW, Lisp and Pascal.", "token2charspan": [[0, 4], [5, 15], [16, 28], [29, 32], [33, 40], [41, 51], [52, 54], [55, 63], [64, 74], [75, 84], [85, 90], [91, 92], [93, 100], [101, 103], [104, 111], [111, 112], [112, 119], [120, 131], [132, 141], [141, 142], [143, 147], [148, 150], [151, 159], [159, 160], [161, 166], [166, 167], [168, 169], [169, 170], [171, 172], [173, 174], [175, 176], [176, 177], [178, 179], [180, 181], [181, 182], [183, 190], [190, 191], [192, 196], [196, 197], [198, 205], [205, 206], [207, 211], [212, 215], [216, 222], [222, 223]]}
{"doc_key": "ai-test-173", "ner": [[3, 3, "organisation"], [9, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2003", ",", "Honda", "released", "an", "advertisement", "for", "the", "Cog", "in", "the", "UK", "and", "on", "the", "internet", "."], "sentence-detokenized": "In 2003, Honda released an advertisement for the Cog in the UK and on the internet.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 26], [27, 40], [41, 44], [45, 48], [49, 52], [53, 55], [56, 59], [60, 62], [63, 66], [67, 69], [70, 73], [74, 82], [82, 83]]}
{"doc_key": "ai-test-174", "ner": [[5, 6, "conference"], [3, 11, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 3, 11, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["According", "to", "the", "Computational", "Linguistics", "Society", "'s", "definition", ",", "computational", "linguistics", "is"], "sentence-detokenized": "According to the Computational Linguistics Society's definition, computational linguistics is", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 30], [31, 42], [43, 50], [50, 52], [53, 63], [63, 64], [65, 78], [79, 90], [91, 93]]}
{"doc_key": "ai-test-175", "ner": [[0, 2, "algorithm"], [6, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 6, 12, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "expectation", "-maximisation", "algorithm", "allows", "the", "calculation", "of", "approximate", "maximum", "likelihood", "estimates", "of", "unknown", "state", "-", "space", "parameters", "in", "the", "minimum", "variance", "filter", "and", "smoothing", "."], "sentence-detokenized": "The expectation-maximisation algorithm allows the calculation of approximate maximum likelihood estimates of unknown state-space parameters in the minimum variance filter and smoothing.", "token2charspan": [[0, 3], [4, 15], [15, 28], [29, 38], [39, 45], [46, 49], [50, 61], [62, 64], [65, 76], [77, 84], [85, 95], [96, 105], [106, 108], [109, 116], [117, 122], [122, 123], [123, 128], [129, 139], [140, 142], [143, 146], [147, 154], [155, 163], [164, 170], [171, 174], [175, 184], [184, 185]]}
{"doc_key": "ai-test-176", "ner": [[2, 3, "misc"], [5, 6, "person"], [8, 9, "person"], [11, 12, "person"], [14, 16, "misc"], [17, 18, "person"], [21, 22, "person"], [28, 29, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 8], "relations": [[5, 6, 2, 3, "role", "actor_in", false, false], [8, 9, 2, 3, "role", "actor_in", false, false], [11, 12, 2, 3, "role", "actor_in", false, false], [17, 18, 14, 16, "role", "model_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Correspondents", "included", "former", "Baywatch", "actresses", "Donna", "DeRico", ",", "Carmen", "Electra", "and", "Tracy", "Bingham", ",", "former", "Playboy", "Playmate", "Heidi", "Mark", ",", "comedian", "Arj", "Barker", "and", "identical", "twins", "Randy", "and", "Jason", "Sklar", "."], "sentence-detokenized": "Correspondents included former Baywatch actresses Donna DeRico, Carmen Electra and Tracy Bingham, former Playboy Playmate Heidi Mark, comedian Arj Barker and identical twins Randy and Jason Sklar.", "token2charspan": [[0, 14], [15, 23], [24, 30], [31, 39], [40, 49], [50, 55], [56, 62], [62, 63], [64, 70], [71, 78], [79, 82], [83, 88], [89, 96], [96, 97], [98, 104], [105, 112], [113, 121], [122, 127], [128, 132], [132, 133], [134, 142], [143, 146], [147, 153], [154, 157], [158, 167], [168, 173], [174, 179], [180, 183], [184, 189], [190, 195], [195, 196]]}
{"doc_key": "ai-test-177", "ner": [[11, 15, "task"], [17, 19, "product"], [23, 24, "task"], [24, 26, "task"], [32, 32, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[24, 26, 23, 24, "named", "", false, false], [32, 32, 23, 24, "general-affiliation", "", false, false]], "relations_mapping_to_source": [2, 3], "sentence": ["It", "is", "often", "used", "to", "generate", "expressions", "for", "speech", "recognition", "(", "ASR", ")", ",", "such", "as", "the", "CMU", "Sphinx", "system", ",", "and", "for", "speech", "synthesis", "(", "TTS", ")", ",", "such", "as", "the", "Festival", "system", "."], "sentence-detokenized": "It is often used to generate expressions for speech recognition (ASR), such as the CMU Sphinx system, and for speech synthesis (TTS), such as the Festival system.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 16], [17, 19], [20, 28], [29, 40], [41, 44], [45, 51], [52, 63], [64, 65], [65, 68], [68, 69], [69, 70], [71, 75], [76, 78], [79, 82], [83, 86], [87, 93], [94, 100], [100, 101], [102, 105], [106, 109], [110, 116], [117, 126], [127, 128], [128, 131], [131, 132], [132, 133], [134, 138], [139, 141], [142, 145], [146, 154], [155, 161], [161, 162]]}
{"doc_key": "ai-test-178", "ner": [[0, 0, "metrics"], [2, 6, "metrics"], [9, 13, "metrics"], [22, 23, "metrics"], [25, 25, "metrics"], [39, 40, "metrics"], [42, 42, "metrics"], [44, 46, "metrics"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6, 7, 8], "relations": [[9, 13, 0, 0, "named", "", false, false], [25, 25, 22, 23, "named", "", false, false], [42, 42, 39, 40, "named", "", false, false], [44, 46, 39, 40, "named", "", false, false]], "relations_mapping_to_source": [2, 3, 4, 5], "sentence": ["Sensitivity", "or", "True", "Positive", "Rate", "(", "TPR", ")", ",", "also", "called", "recall", ",", "is", "the", "proportion", "of", "people", "who", "test", "positive", "(", "TRUE", "Positive", ",", "TP", ")", "out", "of", "the", "total", "number", "of", "people", "who", "are", "actually", "positive", "(", "Condition", "Positive", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "Sensitivity or True Positive Rate (TPR), also called recall, is the proportion of people who test positive (TRUE Positive, TP) out of the total number of people who are actually positive (Condition Positive, CP = TP + FN).", "token2charspan": [[0, 11], [12, 14], [15, 19], [20, 28], [29, 33], [34, 35], [35, 38], [38, 39], [39, 40], [41, 45], [46, 52], [53, 59], [59, 60], [61, 63], [64, 67], [68, 78], [79, 81], [82, 88], [89, 92], [93, 97], [98, 106], [107, 108], [108, 112], [113, 121], [121, 122], [123, 125], [125, 126], [127, 130], [131, 133], [134, 137], [138, 143], [144, 150], [151, 153], [154, 160], [161, 164], [165, 168], [169, 177], [178, 186], [187, 188], [188, 197], [198, 206], [206, 207], [208, 210], [211, 212], [213, 215], [216, 217], [218, 220], [220, 221], [221, 222]]}
{"doc_key": "ai-test-179", "ner": [[0, 3, "task"], [9, 10, "conference"], [12, 12, "conference"], [14, 14, "conference"], [16, 17, "conference"], [5, 23, "conference"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6], "relations": [[9, 10, 0, 3, "topic", "", false, false], [12, 12, 0, 3, "topic", "", false, false], [14, 14, 0, 3, "topic", "", false, false], [16, 17, 0, 3, "topic", "", false, false], [5, 23, 0, 3, "topic", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5], "sentence": ["Speech", "recognition", "-", "related", "conferences", "such", "as", "SpeechTEK", ",", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", "and", "IEEE", "ASRU", "are", "held", "every", "one", "to", "two", "years", "and", "have", "gained", "popularity", "."], "sentence-detokenized": "Speech recognition-related conferences such as SpeechTEK, SpeechTEK Europe, ICASSP, Interspeech / Eurospeech and IEEE ASRU are held every one to two years and have gained popularity.", "token2charspan": [[0, 6], [7, 18], [18, 19], [19, 26], [27, 38], [39, 43], [44, 46], [47, 56], [56, 57], [58, 67], [68, 74], [74, 75], [76, 82], [82, 83], [84, 95], [96, 97], [98, 108], [109, 112], [113, 117], [118, 122], [123, 126], [127, 131], [132, 137], [138, 141], [142, 144], [145, 148], [149, 154], [155, 158], [159, 163], [164, 170], [171, 181], [181, 182]]}
{"doc_key": "ai-test-180", "ner": [[0, 8, "researcher"], [4, 6, "researcher"], [13, 14, "product"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 19, 0, 8, "artifact", "", false, false], [19, 19, 4, 6, "artifact", "", false, false], [19, 19, 13, 14, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Deborg", ",", "together", "with", "Engelberger", ",", "who", "was", "president", ",", "designed", "and", "produced", "industrial", "robots", "under", "the", "brand", "name", "Unimate", "."], "sentence-detokenized": "Deborg, together with Engelberger, who was president, designed and produced industrial robots under the brand name Unimate.", "token2charspan": [[0, 6], [6, 7], [8, 16], [17, 21], [22, 33], [33, 34], [35, 38], [39, 42], [43, 52], [52, 53], [54, 62], [63, 66], [67, 75], [76, 86], [87, 93], [94, 99], [100, 103], [104, 109], [110, 114], [115, 122], [122, 123]]}
{"doc_key": "ai-test-181", "ner": [[0, 6, "algorithm"], [7, 10, "algorithm"], [11, 20, "algorithm"]], "ner_mapping_to_source": [1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Hidden", "Markov", "Models", "(", "HMMs", ")", "are", "statistical", "Markov", "models", "that", "assume", "that", "the", "system", "being", "modelled", "is", "a", "Markov", "process", "with", "unobserved", "(", "hidden", ")", "states", "."], "sentence-detokenized": "Hidden Markov Models (HMMs) are statistical Markov models that assume that the system being modelled is a Markov process with unobserved (hidden) states.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 22], [22, 26], [26, 27], [28, 31], [32, 43], [44, 50], [51, 57], [58, 62], [63, 69], [70, 74], [75, 78], [79, 85], [86, 91], [92, 100], [101, 103], [104, 105], [106, 112], [113, 120], [121, 125], [126, 136], [137, 138], [138, 144], [144, 145], [146, 152], [152, 153]]}
{"doc_key": "ai-test-182", "ner": [[19, 22, "metrics"], [23, 23, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "property", "is", "undesirable", "in", "many", "applications", ",", "leading", "researchers", "to", "use", "alternative", "measures", "such", "as", "those", "based", "on", "mean", "absolute", "error", "or", "median", "."], "sentence-detokenized": "This property is undesirable in many applications, leading researchers to use alternative measures such as those based on mean absolute error or median.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 28], [29, 31], [32, 36], [37, 49], [49, 50], [51, 58], [59, 70], [71, 73], [74, 77], [78, 89], [90, 98], [99, 103], [104, 106], [107, 112], [113, 118], [119, 121], [122, 126], [127, 135], [136, 141], [142, 144], [145, 151], [151, 152]]}
{"doc_key": "ai-test-183", "ner": [[17, 20, "algorithm"], [28, 28, "field"], [31, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 20, 28, 28, "part-of", "", false, false], [17, 20, 31, 34, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Such", "an", "ordering", "(", "where", "each", "stage", "depends", "on", "the", "findings", "of", "the", "previous", "attribute", ")", "is", "called", "a", "decision", "tree", "and", "is", "applied", "in", "the", "field", "of", "machine", "learning", ",", "called", "decision", "tree", "learning", "."], "sentence-detokenized": "Such an ordering (where each stage depends on the findings of the previous attribute) is called a decision tree and is applied in the field of machine learning, called decision tree learning.", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 18], [18, 23], [24, 28], [29, 34], [35, 42], [43, 45], [46, 49], [50, 58], [59, 61], [62, 65], [66, 74], [75, 84], [84, 85], [86, 88], [89, 95], [96, 97], [98, 106], [107, 111], [112, 115], [116, 118], [119, 126], [127, 129], [130, 133], [134, 139], [140, 142], [143, 150], [151, 159], [159, 160], [161, 167], [168, 176], [177, 181], [182, 190], [190, 191]]}
{"doc_key": "ai-test-184", "ner": [[0, 2, "task"], [4, 4, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 4, 4, "compare", "", false, false], [14, 15, 4, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Like", "factor", "analysis", ",", "LCA", "can", "also", "be", "used", "to", "classify", "cases", "according", "to", "maximum", "likelihood", "class", "membership", "."], "sentence-detokenized": "Like factor analysis, LCA can also be used to classify cases according to maximum likelihood class membership.", "token2charspan": [[0, 4], [5, 11], [12, 20], [20, 21], [22, 25], [26, 29], [30, 34], [35, 37], [38, 42], [43, 45], [46, 54], [55, 60], [61, 70], [71, 73], [74, 81], [82, 92], [93, 98], [99, 109], [109, 110]]}
{"doc_key": "ai-test-185", "ner": [[0, 4, "algorithm"], [6, 7, "metrics"], [5, 9, "metrics"], [11, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 4, 6, 7, "usage", "", false, false], [6, 7, 11, 13, "related-to", "", false, false], [5, 9, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Supervised", "neural", "networks", "that", "use", "mean", "squared", "error", "(", "MSE", ")", "cost", "functions", "can", "use", "formal", "statistical", "methods", "to", "determine", "the", "reliability", "of", "the", "trained", "model", "."], "sentence-detokenized": "Supervised neural networks that use mean squared error (MSE) cost functions can use formal statistical methods to determine the reliability of the trained model.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 31], [32, 35], [36, 40], [41, 48], [49, 54], [55, 56], [56, 59], [59, 60], [61, 65], [66, 75], [76, 79], [80, 83], [84, 90], [91, 102], [103, 110], [111, 113], [114, 123], [124, 127], [128, 139], [140, 142], [143, 146], [147, 154], [155, 160], [160, 161]]}
{"doc_key": "ai-test-186", "ner": [[15, 17, "algorithm"], [18, 21, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 17, 18, 21, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "can", "be", "expressed", "directly", "as", "a", "linear", "programme", ",", "but", "is", "equivalent", "to", "the", "Tikhonov", "regularisation", "by", "the", "hinge", "loss", "function", ",", "mathV", "(", "f", "(", "x", ")", ",", "y", ")", "=\\", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "math", ":"], "sentence-detokenized": "This can be expressed directly as a linear programme, but is equivalent to the Tikhonov regularisation by the hinge loss function, mathV (f (x), y) =\\ max (0, 1 - yf (x)) / math:", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 21], [22, 30], [31, 33], [34, 35], [36, 42], [43, 52], [52, 53], [54, 57], [58, 60], [61, 71], [72, 74], [75, 78], [79, 87], [88, 102], [103, 105], [106, 109], [110, 115], [116, 120], [121, 129], [129, 130], [131, 136], [137, 138], [138, 139], [140, 141], [141, 142], [142, 143], [143, 144], [145, 146], [146, 147], [148, 150], [151, 154], [155, 156], [156, 157], [157, 158], [159, 160], [161, 162], [163, 165], [166, 167], [167, 168], [168, 169], [169, 170], [171, 172], [173, 177], [177, 178]]}
{"doc_key": "ai-test-187", "ner": [[13, 16, "product"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "method", "is", "described", "in", "Breiman", "'s", "original", "paper", "and", "implemented", "in", "the", "R", "package", "randomForest", "."], "sentence-detokenized": "The following method is described in Breiman's original paper and implemented in the R package randomForest.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 23], [24, 33], [34, 36], [37, 44], [44, 46], [47, 55], [56, 61], [62, 65], [66, 77], [78, 80], [81, 84], [85, 86], [87, 94], [95, 107], [107, 108]]}
{"doc_key": "ai-test-188", "ner": [[5, 7, "metrics"], [38, 39, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "image", "quality", "measures", ",", "such", "as", "PSNR", ",", "are", "typically", "performed", "on", "fixed", "-", "resolution", "images", "and", "do", "not", "take", "into", "account", "some", "aspects", "of", "the", "human", "visual", "system", ",", "such", "as", "changes", "in", "spatial", "resolution", "across", "the", "retina", "."], "sentence-detokenized": "Traditional image quality measures, such as PSNR, are typically performed on fixed-resolution images and do not take into account some aspects of the human visual system, such as changes in spatial resolution across the retina.", "token2charspan": [[0, 11], [12, 17], [18, 25], [26, 34], [34, 35], [36, 40], [41, 43], [44, 48], [48, 49], [50, 53], [54, 63], [64, 73], [74, 76], [77, 82], [82, 83], [83, 93], [94, 100], [101, 104], [105, 107], [108, 111], [112, 116], [117, 121], [122, 129], [130, 134], [135, 142], [143, 145], [146, 149], [150, 155], [156, 162], [163, 169], [169, 170], [171, 175], [176, 178], [179, 186], [187, 189], [190, 197], [198, 208], [209, 215], [216, 219], [220, 226], [226, 227]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [10, 12, "person"], [16, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 19, "role", "", false, false], [3, 4, 16, 19, "role", "", false, false], [6, 7, 16, 19, "role", "", false, false], [16, 19, 10, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Drue", "and", "Macdonald", "Carey", "star", "in", "Jack", "Broder", "'s", "colour", "production", "of", "Hannah", "Lee", ",", "which", "premiered", "on", "19", "June", "1953", "."], "sentence-detokenized": "John Ireland, Joanne Drue and Macdonald Carey star in Jack Broder's colour production of Hannah Lee, which premiered on 19 June 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 25], [26, 29], [30, 39], [40, 45], [46, 50], [51, 53], [54, 58], [59, 65], [65, 67], [68, 74], [75, 85], [86, 88], [89, 95], [96, 99], [99, 100], [101, 106], [107, 116], [117, 119], [120, 122], [123, 127], [128, 132], [132, 133]]}
{"doc_key": "ai-test-190", "ner": [[3, 5, "task"], [8, 10, "field"], [14, 16, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 8, 10, "usage", "", false, false], [14, 16, 8, 10, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "process", "is", "called", "image", "registration", "and", "uses", "various", "computer", "vision", "techniques", ",", "mainly", "related", "to", "tracking", "."], "sentence-detokenized": "The process is called image registration and uses various computer vision techniques, mainly related to tracking.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 21], [22, 27], [28, 40], [41, 44], [45, 49], [50, 57], [58, 66], [67, 73], [74, 84], [84, 85], [86, 92], [93, 100], [101, 103], [104, 112], [112, 113]]}
{"doc_key": "ai-test-191", "ner": [[14, 16, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["We", "now", "begin", "to", "explain", "the", "various", "possible", "relationships", "between", "predicted", "and", "actual", "outcomes", ".", "Confusion", "matrices"], "sentence-detokenized": "We now begin to explain the various possible relationships between predicted and actual outcomes. Confusion matrices", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 23], [24, 27], [28, 35], [36, 44], [45, 58], [59, 66], [67, 76], [77, 80], [81, 87], [88, 96], [96, 97], [98, 107], [108, 116]]}
{"doc_key": "ai-test-192", "ner": [[0, 1, "product"], [1, 5, "misc"], [6, 6, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 1, 5, "part-of", "", false, false], [0, 1, 1, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "VOICEBOX", "speech", "processing", "toolbox", "for", "MATLAB", "implements", "transformations", "and", "vice", "versa", "."], "sentence-detokenized": "The VOICEBOX speech processing toolbox for MATLAB implements transformations and vice versa.", "token2charspan": [[0, 3], [4, 12], [13, 19], [20, 30], [31, 38], [39, 42], [43, 49], [50, 60], [61, 76], [77, 80], [81, 85], [86, 91], [91, 92]]}
{"doc_key": "ai-test-193", "ner": [[0, 0, "programlang"], [8, 8, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 8, "general-affiliation", "", false, false], [0, 0, 11, 12, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "is", "a", "logic", "programming", "language", "relevant", "to", "artificial", "intelligence", "and", "computational", "linguistics", "."], "sentence-detokenized": "Prolog is a logic programming language relevant to artificial intelligence and computational linguistics.", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 17], [18, 29], [30, 38], [39, 47], [48, 50], [51, 61], [62, 74], [75, 78], [79, 92], [93, 104], [104, 105]]}
{"doc_key": "ai-test-194", "ner": [[0, 0, "researcher"], [9, 9, "field"], [11, 11, "field"], [19, 20, "organisation"], [23, 26, "organisation"], [29, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 9, 9, "related-to", "works_with_topic", false, false], [0, 0, 11, 11, "related-to", "works_with_topic", false, false], [0, 0, 19, 20, "role", "", false, false], [0, 0, 23, 26, "role", "", false, false], [0, 0, 29, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "has", "received", "numerous", "awards", "for", "his", "contributions", "to", "neuroscience", "and", "psychology", ",", "including", "membership", "of", "the", "Royal", "Society", "of", "London", ",", "the", "Royal", "Society", "of", "Canada", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner has received numerous awards for his contributions to neuroscience and psychology, including membership of the Royal Society of London, the Royal Society of Canada and the National Academy of Sciences.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 28], [29, 35], [36, 39], [40, 43], [44, 57], [58, 60], [61, 73], [74, 77], [78, 88], [88, 89], [90, 99], [100, 110], [111, 113], [114, 117], [118, 123], [124, 131], [132, 134], [135, 141], [141, 142], [143, 146], [147, 152], [153, 160], [161, 163], [164, 170], [171, 174], [175, 178], [179, 187], [188, 195], [196, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-test-195", "ner": [[10, 11, "field"], [16, 17, "task"], [19, 20, "task"], [22, 23, "task"], [25, 26, "task"], [14, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[16, 17, 10, 11, "part-of", "task_part_of_field", false, false], [19, 20, 10, 11, "part-of", "task_part_of_field", false, false], [22, 23, 10, 11, "part-of", "task_part_of_field", false, false], [25, 26, 10, 11, "part-of", "task_part_of_field", false, false], [14, 28, 10, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["These", "operators", "can", "be", "combined", "to", "obtain", "algorithms", "for", "many", "image", "processing", "tasks", ",", "such", "as", "feature", "extraction", ",", "image", "segmentation", ",", "image", "sharpening", ",", "image", "filtering", "and", "classification", "."], "sentence-detokenized": "These operators can be combined to obtain algorithms for many image processing tasks, such as feature extraction, image segmentation, image sharpening, image filtering and classification.", "token2charspan": [[0, 5], [6, 15], [16, 19], [20, 22], [23, 31], [32, 34], [35, 41], [42, 52], [53, 56], [57, 61], [62, 67], [68, 78], [79, 84], [84, 85], [86, 90], [91, 93], [94, 101], [102, 112], [112, 113], [114, 119], [120, 132], [132, 133], [134, 139], [140, 150], [150, 151], [152, 157], [158, 167], [168, 171], [172, 186], [186, 187]]}
{"doc_key": "ai-test-196", "ner": [[1, 4, "university"], [12, 14, "organisation"], [16, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 17, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Professor", ",", "Coll\u00e8ge", "de", "France", ",", "as", "of", "2017", ";", "director", "of", "INSERM", "Unit", "562", "(", "Cognitive", "Neuroimaging", ")", "since", "1989", "."], "sentence-detokenized": "Professor, Coll\u00e8ge de France, as of 2017; director of INSERM Unit 562 (Cognitive Neuroimaging) since 1989.", "token2charspan": [[0, 9], [9, 10], [11, 18], [19, 21], [22, 28], [28, 29], [30, 32], [33, 35], [36, 40], [40, 41], [42, 50], [51, 53], [54, 60], [61, 65], [66, 69], [70, 71], [71, 80], [81, 93], [93, 94], [95, 100], [101, 105], [105, 106]]}
{"doc_key": "ai-test-197", "ner": [[17, 20, "algorithm"], [24, 24, "algorithm"], [28, 32, "conference"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[24, 24, 28, 32, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["There", "are", "a", "number", "of", "approaches", "to", "learning", "these", "embeddings", ",", "notably", "using", "Bayesian", "clustering", "frameworks", ",", "energy", "-", "based", "frameworks", "and", "more", "recently", "TransE", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", "2013", ")", "They", "include", "."], "sentence-detokenized": "There are a number of approaches to learning these embeddings, notably using Bayesian clustering frameworks, energy-based frameworks and more recently TransE (Conference on Neural Information Processing Systems 2013) They include.", "token2charspan": [[0, 5], [6, 9], [10, 11], [12, 18], [19, 21], [22, 32], [33, 35], [36, 44], [45, 50], [51, 61], [61, 62], [63, 70], [71, 76], [77, 85], [86, 96], [97, 107], [107, 108], [109, 115], [115, 116], [116, 121], [122, 132], [133, 136], [137, 141], [142, 150], [151, 157], [158, 159], [159, 169], [170, 172], [173, 179], [180, 191], [192, 202], [203, 210], [211, 215], [215, 216], [217, 221], [222, 229], [229, 230]]}
{"doc_key": "ai-test-198", "ner": [[6, 8, "metrics"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "an", "alternative", "to", "the", "Word", "Error", "Rate", "used", "in", "some", "countries", "."], "sentence-detokenized": "It is an alternative to the Word Error Rate used in some countries.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 20], [21, 23], [24, 27], [28, 32], [33, 38], [39, 43], [44, 48], [49, 51], [52, 56], [57, 66], [66, 67]]}
{"doc_key": "ai-test-199", "ner": [[0, 1, "algorithm"], [10, 11, "task"], [13, 14, "task"], [16, 17, "task"], [19, 21, "task"], [23, 27, "task"], [29, 31, "task"], [41, 42, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 11, 0, 1, "usage", "", false, false], [13, 14, 0, 1, "usage", "", false, false], [16, 17, 0, 1, "usage", "", false, false], [19, 21, 0, 1, "usage", "", false, false], [23, 27, 0, 1, "usage", "", false, false], [29, 31, 0, 1, "usage", "", false, false], [41, 42, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["ANNs", "are", "used", "for", "a", "variety", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "playing", "board", "and", "video", "games", ",", "medical", "diagnostics", "and", "even", "activities", "traditionally", "considered", "only", "humanly", "possible", ",", "such", "as", "painting", "."], "sentence-detokenized": "ANNs are used for a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games, medical diagnostics and even activities traditionally considered only humanly possible, such as painting.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 17], [18, 19], [20, 27], [28, 30], [31, 36], [36, 37], [38, 47], [48, 56], [57, 63], [63, 64], [65, 71], [72, 83], [83, 84], [85, 92], [93, 104], [104, 105], [106, 112], [113, 120], [121, 130], [130, 131], [132, 139], [140, 145], [146, 149], [150, 155], [156, 161], [161, 162], [163, 170], [171, 182], [183, 186], [187, 191], [192, 202], [203, 216], [217, 227], [228, 232], [233, 240], [241, 249], [249, 250], [251, 255], [256, 258], [259, 267], [267, 268]]}
{"doc_key": "ai-test-200", "ner": [[3, 8, "product"], [0, 2, "product"], [27, 27, "field"], [25, 29, "field"], [33, 35, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 8, 27, 27, "related-to", "", false, false], [3, 8, 33, 35, "general-affiliation", "", false, false], [0, 2, 3, 8, "named", "", false, false], [25, 29, 27, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["MARF", "(", "Modular", "Audio", "Recognition", "Framework", ")", "is", "an", "open", "source", "research", "platform", "and", "a", "collection", "of", "speech", ",", "sound", ",", "speech", ",", "text", "and", "natural", "language", "processing", "(", "NLP", ")", "algorithms", "written", "in", "Java", "that", "attempts", "to", "facilitate", "the", "addition", "of", "new", "algorithms", ".", "It", "is", "arranged", "in", "a", "modular", ",", "extensible", "framework", "that", "attempts", "to", "facilitate", "the", "addition", "of", "new", "algorithms", "."], "sentence-detokenized": "MARF (Modular Audio Recognition Framework) is an open source research platform and a collection of speech, sound, speech, text and natural language processing (NLP) algorithms written in Java that attempts to facilitate the addition of new algorithms. It is arranged in a modular, extensible framework that attempts to facilitate the addition of new algorithms.", "token2charspan": [[0, 4], [5, 6], [6, 13], [14, 19], [20, 31], [32, 41], [41, 42], [43, 45], [46, 48], [49, 53], [54, 60], [61, 69], [70, 78], [79, 82], [83, 84], [85, 95], [96, 98], [99, 105], [105, 106], [107, 112], [112, 113], [114, 120], [120, 121], [122, 126], [127, 130], [131, 138], [139, 147], [148, 158], [159, 160], [160, 163], [163, 164], [165, 175], [176, 183], [184, 186], [187, 191], [192, 196], [197, 205], [206, 208], [209, 219], [220, 223], [224, 232], [233, 235], [236, 239], [240, 250], [250, 251], [252, 254], [255, 257], [258, 266], [267, 269], [270, 271], [272, 279], [279, 280], [281, 291], [292, 301], [302, 306], [307, 315], [316, 318], [319, 329], [330, 333], [334, 342], [343, 345], [346, 349], [350, 360], [360, 361]]}
{"doc_key": "ai-test-201", "ner": [[12, 14, "organisation"], [17, 18, "country"], [22, 23, "organisation"], [26, 27, "organisation"], [32, 34, "task"], [47, 50, "organisation"], [52, 54, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[22, 23, 17, 18, "physical", "", false, false], [22, 23, 32, 34, "usage", "", false, false], [22, 23, 47, 50, "named", "", false, false], [26, 27, 17, 18, "physical", "", false, false], [26, 27, 32, 34, "usage", "", false, false], [47, 50, 52, 54, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "a", "report", "by", "civil", "liberties", "and", "rights", "campaign", "group", "Big", "Brother", "Watch", "revealed", "that", "two", "UK", "police", "forces", ",", "South", "Wales", "Police", "and", "Metropolitan", "Police", ",", "were", "using", "live", "facial", "recognition", "at", "public", "events", "and", "in", "public", "spaces", ",", "and", "in", "September", "2019", ",", "South", "Wales", "Police", "'s", "use", "of", "facial", "recognition", "was", "declared", "legal", "."], "sentence-detokenized": "In 2018, a report by civil liberties and rights campaign group Big Brother Watch revealed that two UK police forces, South Wales Police and Metropolitan Police, were using live facial recognition at public events and in public spaces, and in September 2019, South Wales Police's use of facial recognition was declared legal.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 20], [21, 26], [27, 36], [37, 40], [41, 47], [48, 56], [57, 62], [63, 66], [67, 74], [75, 80], [81, 89], [90, 94], [95, 98], [99, 101], [102, 108], [109, 115], [115, 116], [117, 122], [123, 128], [129, 135], [136, 139], [140, 152], [153, 159], [159, 160], [161, 165], [166, 171], [172, 176], [177, 183], [184, 195], [196, 198], [199, 205], [206, 212], [213, 216], [217, 219], [220, 226], [227, 233], [233, 234], [235, 238], [239, 241], [242, 251], [252, 256], [256, 257], [258, 263], [264, 269], [270, 276], [276, 278], [279, 282], [283, 285], [286, 292], [293, 304], [305, 308], [309, 317], [318, 323], [323, 324]]}
{"doc_key": "ai-test-202", "ner": [[0, 0, "product"], [4, 5, "programlang"], [14, 14, "field"], [17, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 5, "general-affiliation", "", false, false], [0, 0, 14, 14, "related-to", "", false, false], [0, 0, 17, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "has", "been", "ported", "to", "R", ",", "a", "freely", "available", "language", "and", "environment", "for", "statistical", "computing", "and", "graphics", "."], "sentence-detokenized": "ANIMAL has been ported to R, a freely available language and environment for statistical computing and graphics.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 22], [23, 25], [26, 27], [27, 28], [29, 30], [31, 37], [38, 47], [48, 56], [57, 60], [61, 72], [73, 76], [77, 88], [89, 98], [99, 102], [103, 111], [111, 112]]}
{"doc_key": "ai-test-203", "ner": [[4, 4, "algorithm"], [0, 12, "algorithm"], [16, 20, "algorithm"], [23, 25, "task"]], "ner_mapping_to_source": [0, 1, 3, 4], "relations": [[0, 12, 4, 4, "named", "", false, false], [23, 25, 4, 4, "usage", "", false, false]], "relations_mapping_to_source": [1, 3], "sentence": ["The", "Time", "Asynchronous", "Hidden", "Bernoulli", "Model", "(", "TI", "-", "HBM", ")", "is", "an", "alternative", "to", "the", "Hidden", "Markov", "Model", "(", "HMM", ")", "for", "automatic", "speech", "recognition", "."], "sentence-detokenized": "The Time Asynchronous Hidden Bernoulli Model (TI-HBM) is an alternative to the Hidden Markov Model (HMM) for automatic speech recognition.", "token2charspan": [[0, 3], [4, 8], [9, 21], [22, 28], [29, 38], [39, 44], [45, 46], [46, 48], [48, 49], [49, 52], [52, 53], [54, 56], [57, 59], [60, 71], [72, 74], [75, 78], [79, 85], [86, 92], [93, 98], [99, 100], [100, 103], [103, 104], [105, 108], [109, 118], [119, 125], [126, 137], [137, 138]]}
{"doc_key": "ai-test-204", "ner": [[4, 4, "organisation"], [13, 16, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 13, 16, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "July", "2016", ",", "Nvidia", "demonstrated", "a", "new", "method", "of", "foveated", "rendering", "at", "SIGGRAPH", ",", "which", "it", "claimed", "was", "invisible", "to", "users", "."], "sentence-detokenized": "In July 2016, Nvidia demonstrated a new method of foveated rendering at SIGGRAPH, which it claimed was invisible to users.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 20], [21, 33], [34, 35], [36, 39], [40, 46], [47, 49], [50, 58], [59, 68], [69, 71], [72, 80], [80, 81], [82, 87], [88, 90], [91, 98], [99, 102], [103, 112], [113, 115], [116, 121], [121, 122]]}
{"doc_key": "ai-test-205", "ner": [[1, 5, "misc"], [8, 11, "researcher"], [20, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[1, 5, 8, 11, "origin", "", false, false], [1, 5, 20, 20, "origin", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["Both", "rely", "on", "speech", "act", "theory", ",", "developed", "by", "John", "Searle", "in", "the", "1960s", "and", "reinforced", "by", "Terry", "Winograd", "and", "Flores", "in", "the", "1970s", "."], "sentence-detokenized": "Both rely on speech act theory, developed by John Searle in the 1960s and reinforced by Terry Winograd and Flores in the 1970s.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 19], [20, 23], [24, 30], [30, 31], [32, 41], [42, 44], [45, 49], [50, 56], [57, 59], [60, 63], [64, 69], [70, 73], [74, 84], [85, 87], [88, 93], [94, 102], [103, 106], [107, 113], [114, 116], [117, 120], [121, 126], [126, 127]]}
{"doc_key": "ai-test-206", "ner": [[0, 3, "algorithm"], [23, 23, "researcher"], [21, 26, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 23, 23, "related-to", "", false, false], [21, 26, 23, 23, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Neural", "network", "models", "of", "concept", "formation", "and", "the", "structure", "of", "knowledge", "have", "opened", "up", "powerful", "hierarchical", "models", "of", "knowledge", "organisation", ",", "such", "as", "George", "Miller", "'s", "WordNet", "."], "sentence-detokenized": "Neural network models of concept formation and the structure of knowledge have opened up powerful hierarchical models of knowledge organisation, such as George Miller's WordNet.", "token2charspan": [[0, 6], [7, 14], [15, 21], [22, 24], [25, 32], [33, 42], [43, 46], [47, 50], [51, 60], [61, 63], [64, 73], [74, 78], [79, 85], [86, 88], [89, 97], [98, 110], [111, 117], [118, 120], [121, 130], [131, 143], [143, 144], [145, 149], [150, 152], [153, 159], [160, 166], [166, 168], [169, 176], [176, 177]]}
{"doc_key": "ai-test-207", "ner": [[0, 1, "algorithm"], [15, 16, "field"], [18, 21, "product"], [2, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 15, 16, "part-of", "", false, false], [0, 1, 2, 26, "part-of", "", false, false], [18, 21, 15, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Template", "matching", "has", "a", "wide", "range", "of", "applications", "and", "is", "used", "in", "areas", "such", "as", "face", "recognition", "(", "see", "face", "recognition", "systems", ")", "and", "medical", "image", "processing", "."], "sentence-detokenized": "Template matching has a wide range of applications and is used in areas such as face recognition (see face recognition systems) and medical image processing.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 23], [24, 28], [29, 34], [35, 37], [38, 50], [51, 54], [55, 57], [58, 62], [63, 65], [66, 71], [72, 76], [77, 79], [80, 84], [85, 96], [97, 98], [98, 101], [102, 106], [107, 118], [119, 126], [126, 127], [128, 131], [132, 139], [140, 145], [146, 156], [156, 157]]}
{"doc_key": "ai-test-208", "ner": [[10, 11, "researcher"], [13, 14, "researcher"], [19, 25, "organisation"], [21, 27, "organisation"], [34, 36, "algorithm"], [42, 44, "conference"], [37, 46, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 11, 19, 25, "role", "", false, false], [10, 11, 42, 44, "physical", "", false, false], [10, 11, 42, 44, "temporal", "", false, false], [10, 11, 37, 46, "physical", "", false, false], [13, 14, 19, 25, "role", "", false, false], [13, 14, 42, 44, "temporal", "", false, false], [21, 27, 19, 25, "named", "", false, false], [42, 44, 34, 36, "topic", "", false, false], [37, 46, 42, 44, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["However", ",", "widespread", "use", "only", "started", "in", "2005", ",", "when", "Navneet", "Dalal", "and", "Bill", "Triggs", ",", "researchers", "at", "the", "French", "National", "Institute", "for", "Computer", "Science", "Automation", "(", "INRIA", ")", ",", "presented", "supplementary", "work", "on", "HOG", "descriptors", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", ".", "It", "was", "."], "sentence-detokenized": "However, widespread use only started in 2005, when Navneet Dalal and Bill Triggs, researchers at the French National Institute for Computer Science Automation (INRIA), presented supplementary work on HOG descriptors at the Conference on Computer Vision and Pattern Recognition (CVPR). It was.", "token2charspan": [[0, 7], [7, 8], [9, 19], [20, 23], [24, 28], [29, 36], [37, 39], [40, 44], [44, 45], [46, 50], [51, 58], [59, 64], [65, 68], [69, 73], [74, 80], [80, 81], [82, 93], [94, 96], [97, 100], [101, 107], [108, 116], [117, 126], [127, 130], [131, 139], [140, 147], [148, 158], [159, 160], [160, 165], [165, 166], [166, 167], [168, 177], [178, 191], [192, 196], [197, 199], [200, 203], [204, 215], [216, 218], [219, 222], [223, 233], [234, 236], [237, 245], [246, 252], [253, 256], [257, 264], [265, 276], [277, 278], [278, 282], [282, 283], [283, 284], [285, 287], [288, 291], [291, 292]]}
{"doc_key": "ai-test-209", "ner": [[6, 9, "university"], [20, 22, "organisation"], [25, 28, "organisation"], [46, 46, "field"], [32, 34, "researcher"], [36, 39, "researcher"], [29, 45, "researcher"], [49, 52, "organisation"], [60, 64, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[25, 28, 46, 46, "related-to", "", false, false], [32, 34, 25, 28, "physical", "", false, false], [32, 34, 25, 28, "role", "", false, false], [36, 39, 25, 28, "physical", "", false, false], [36, 39, 25, 28, "role", "", false, false], [29, 45, 25, 28, "physical", "", false, false], [29, 45, 25, 28, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Before", "becoming", "a", "professor", "at", "the", "University", "of", "Pennsylvania", "in", "2002", ",", "he", "spent", "10", "years", "(", "1991-2001", ")", "at", "AT", "&", "T", "Laboratories", "and", "Bell", "Labs", ",", "with", "colleagues", "such", "as", "Michael", "L.", "Littman", ",", "David", "A", ".", "McAllester", "and", "Richard", "S.", "Sutton", "in", "the", "AI", "Department", ",", "Secure", "Systems", "Research", "Division", ",", "and", "spent", "time", "as", "head", "of", "the", "Machine", "Learning", "Division", "with", "members", "such", "as", "Michael", "Collins", "and", "Reader", ")", "."], "sentence-detokenized": "Before becoming a professor at the University of Pennsylvania in 2002, he spent 10 years (1991-2001) at AT & T Laboratories and Bell Labs, with colleagues such as Michael L. Littman, David A. McAllester and Richard S. Sutton in the AI Department, Secure Systems Research Division, and spent time as head of the Machine Learning Division with members such as Michael Collins and Reader).", "token2charspan": [[0, 6], [7, 15], [16, 17], [18, 27], [28, 30], [31, 34], [35, 45], [46, 48], [49, 61], [62, 64], [65, 69], [69, 70], [71, 73], [74, 79], [80, 82], [83, 88], [89, 90], [90, 99], [99, 100], [101, 103], [104, 106], [107, 108], [109, 110], [111, 123], [124, 127], [128, 132], [133, 137], [137, 138], [139, 143], [144, 154], [155, 159], [160, 162], [163, 170], [171, 173], [174, 181], [181, 182], [183, 188], [189, 190], [190, 191], [192, 202], [203, 206], [207, 214], [215, 217], [218, 224], [225, 227], [228, 231], [232, 234], [235, 245], [245, 246], [247, 253], [254, 261], [262, 270], [271, 279], [279, 280], [281, 284], [285, 290], [291, 295], [296, 298], [299, 303], [304, 306], [307, 310], [311, 318], [319, 327], [328, 336], [337, 341], [342, 349], [350, 354], [355, 357], [358, 365], [366, 373], [374, 377], [378, 384], [384, 385], [385, 386]]}
{"doc_key": "ai-test-210", "ner": [[6, 9, "field"], [12, 13, "field"], [16, 20, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 9, 12, 13, "compare", "", false, false], [16, 20, 12, 13, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["If", "the", "data", "are", "unlabelled", ",", "supervised", "learning", "is", "not", "possible", "and", "unsupervised", "learning", "requires", "natural", "cluster", "analysis", ",", "grouping", "and", "attempts", "to", "map", "new", "data", "to", "these", "groups", "."], "sentence-detokenized": "If the data are unlabelled, supervised learning is not possible and unsupervised learning requires natural cluster analysis, grouping and attempts to map new data to these groups.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 15], [16, 26], [26, 27], [28, 38], [39, 47], [48, 50], [51, 54], [55, 63], [64, 67], [68, 80], [81, 89], [90, 98], [99, 106], [107, 114], [115, 123], [123, 124], [125, 133], [134, 137], [138, 146], [147, 149], [150, 153], [154, 157], [158, 162], [163, 165], [166, 171], [172, 178], [178, 179]]}
{"doc_key": "ai-test-211", "ner": [[0, 5, "field"], [13, 19, "organisation"], [27, 27, "field"], [30, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 5, 13, 19, "origin", "", false, false], [0, 5, 27, 27, "part-of", "", false, false], [0, 5, 30, 30, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "branch", "of", "computer", "science", "that", "developed", "in", "the", "1950s", "at", "academic", "institutions", "such", "as", "the", "MIT", "A.I", ".", "Lab", ",", "and", "was", "originally", "a", "branch", "of", "artificial", "intelligence", "and", "robotics", "."], "sentence-detokenized": "A branch of computer science that developed in the 1950s at academic institutions such as the MIT A.I. Lab, and was originally a branch of artificial intelligence and robotics.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 20], [21, 28], [29, 33], [34, 43], [44, 46], [47, 50], [51, 56], [57, 59], [60, 68], [69, 81], [82, 86], [87, 89], [90, 93], [94, 97], [98, 101], [101, 102], [103, 106], [106, 107], [108, 111], [112, 115], [116, 126], [127, 128], [129, 135], [136, 138], [139, 149], [150, 162], [163, 166], [167, 175], [175, 176]]}
{"doc_key": "ai-test-212", "ner": [[8, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "can", "also", "be", "replaced", "by", "the", "following", "Log", "loss", "formula", "."], "sentence-detokenized": "It can also be replaced by the following Log loss formula.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 23], [24, 26], [27, 30], [31, 40], [41, 44], [45, 49], [50, 57], [57, 58]]}
{"doc_key": "ai-test-213", "ner": [[0, 4, "organisation"], [6, 10, "organisation"], [14, 18, "university"], [20, 20, "university"], [22, 23, "university"], [26, 34, "university"], [30, 32, "country"], [38, 38, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 4, 38, 38, "related-to", "research_leader_in_field", false, false], [6, 10, 0, 4, "named", "", false, false], [6, 10, 38, 38, "related-to", "research_leader_in_field", false, false], [14, 18, 38, 38, "related-to", "research_leader_in_field", false, false], [20, 20, 38, 38, "related-to", "research_leader_in_field", false, false], [22, 23, 38, 38, "related-to", "research_leader_in_field", false, false], [26, 34, 30, 32, "physical", "", false, false], [26, 34, 38, 38, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "Shirley", "Ryan", "Ability", "Lab", "(", "formerly", "the", "Chicago", "Rehabilitation", "Institute", ")", ",", "the", "University", "of", "California", ",", "Berkeley", ",", "MIT", ",", "Stanford", "University", "and", "the", "University", "of", "Twente", "in", "the", "Netherlands", "are", "among", "the", "research", "leaders", "in", "biomechatronics", "."], "sentence-detokenized": "The Shirley Ryan Ability Lab (formerly the Chicago Rehabilitation Institute), the University of California, Berkeley, MIT, Stanford University and the University of Twente in the Netherlands are among the research leaders in biomechatronics.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 24], [25, 28], [29, 30], [30, 38], [39, 42], [43, 50], [51, 65], [66, 75], [75, 76], [76, 77], [78, 81], [82, 92], [93, 95], [96, 106], [106, 107], [108, 116], [116, 117], [118, 121], [121, 122], [123, 131], [132, 142], [143, 146], [147, 150], [151, 161], [162, 164], [165, 171], [172, 174], [175, 178], [179, 190], [191, 194], [195, 200], [201, 204], [205, 213], [214, 221], [222, 224], [225, 240], [240, 241]]}
{"doc_key": "ai-test-214", "ner": [[27, 31, "metrics"], [44, 44, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Given", "a", "set", "of", "predicted", "values", "of", "X", "over", "various", "time", "periods", "and", "a", "corresponding", "set", "of", "actual", "values", ",", "a", "common", "evaluation", "technique", "is", "to", "use", "the", "mean", "squared", "forecast", "error", ".", "Other", "measures", "can", "also", "be", "used", "(", "see", "Forecasting", "#", "Forecasting", "accuracy", ")", "."], "sentence-detokenized": "Given a set of predicted values of X over various time periods and a corresponding set of actual values, a common evaluation technique is to use the mean squared forecast error. Other measures can also be used (see Forecasting # Forecasting accuracy).", "token2charspan": [[0, 5], [6, 7], [8, 11], [12, 14], [15, 24], [25, 31], [32, 34], [35, 36], [37, 41], [42, 49], [50, 54], [55, 62], [63, 66], [67, 68], [69, 82], [83, 86], [87, 89], [90, 96], [97, 103], [103, 104], [105, 106], [107, 113], [114, 124], [125, 134], [135, 137], [138, 140], [141, 144], [145, 148], [149, 153], [154, 161], [162, 170], [171, 176], [176, 177], [178, 183], [184, 192], [193, 196], [197, 201], [202, 204], [205, 209], [210, 211], [211, 214], [215, 226], [227, 228], [229, 240], [241, 249], [249, 250], [250, 251]]}
{"doc_key": "ai-test-215", "ner": [[2, 14, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "indicators", ",", "such", "as", "the", "percentage", "of", "correct", "predictions", "(", "also", "known", "as", "accuracy", ")", ",", "are", "not", "useful", "when", "the", "sizes", "of", "the", "two", "classes", "differ", "significantly", "."], "sentence-detokenized": "Other indicators, such as the percentage of correct predictions (also known as accuracy), are not useful when the sizes of the two classes differ significantly.", "token2charspan": [[0, 5], [6, 16], [16, 17], [18, 22], [23, 25], [26, 29], [30, 40], [41, 43], [44, 51], [52, 63], [64, 65], [65, 69], [70, 75], [76, 78], [79, 87], [87, 88], [88, 89], [90, 93], [94, 97], [98, 104], [105, 109], [110, 113], [114, 119], [120, 122], [123, 126], [127, 130], [131, 138], [139, 145], [146, 159], [159, 160]]}
{"doc_key": "ai-test-216", "ner": [[5, 9, "product"], [11, 17, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 9, 11, 17, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "alpha", "version", "of", "OpenCV", "was", "released", "at", "a", "conference", "on", "computer", "vision", "and", "pattern", "recognition", "in", "2000", ",", "with", "five", "beta", "versions", "released", "between", "2001", "and", "2005", "."], "sentence-detokenized": "The first alpha version of OpenCV was released at a conference on computer vision and pattern recognition in 2000, with five beta versions released between 2001 and 2005.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [24, 26], [27, 33], [34, 37], [38, 46], [47, 49], [50, 51], [52, 62], [63, 65], [66, 74], [75, 81], [82, 85], [86, 93], [94, 105], [106, 108], [109, 113], [113, 114], [115, 119], [120, 124], [125, 129], [130, 138], [139, 147], [148, 155], [156, 160], [161, 164], [165, 169], [169, 170]]}
{"doc_key": "ai-test-217", "ner": [[21, 22, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "results", "showed", "a", "correlation", "of", "up", "to", "0.964", "with", "human", "judgements", "at", "the", "corpus", "level", ",", "compared", "to", "0.817", "for", "BLEU", "on", "the", "same", "dataset", "."], "sentence-detokenized": "The results showed a correlation of up to 0.964 with human judgements at the corpus level, compared to 0.817 for BLEU on the same dataset.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 20], [21, 32], [33, 35], [36, 38], [39, 41], [42, 47], [48, 52], [53, 58], [59, 69], [70, 72], [73, 76], [77, 83], [84, 89], [89, 90], [91, 99], [100, 102], [103, 108], [109, 112], [113, 117], [118, 120], [121, 124], [125, 129], [130, 137], [137, 138]]}
{"doc_key": "ai-test-218", "ner": [[3, 3, "metrics"], [17, 17, "metrics"], [19, 21, "metrics"], [15, 26, "metrics"], [27, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 17, 17, "compare", "", false, false], [3, 3, 19, 21, "compare", "", false, false], [3, 3, 15, 26, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Initial", "versions", "of", "VMAF", "have", "been", "shown", "to", "outperform", "other", "image", "and", "video", "quality", "metrics", "such", "as", "SSIM", ",", "PSNR", "-", "HVS", "and", "VQM", "-", "VFD", "in", "terms", "of", "predictive", "accuracy", "when", "compared", "to", "subjective", "ratings", "in", "three", "of", "the", "four", "data", "sets", "."], "sentence-detokenized": "Initial versions of VMAF have been shown to outperform other image and video quality metrics such as SSIM, PSNR -HVS and VQM-VFD in terms of predictive accuracy when compared to subjective ratings in three of the four data sets.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 24], [25, 29], [30, 34], [35, 40], [41, 43], [44, 54], [55, 60], [61, 66], [67, 70], [71, 76], [77, 84], [85, 92], [93, 97], [98, 100], [101, 105], [105, 106], [107, 111], [112, 113], [113, 116], [117, 120], [121, 124], [124, 125], [125, 128], [129, 131], [132, 137], [138, 140], [141, 151], [152, 160], [161, 165], [166, 174], [175, 177], [178, 188], [189, 196], [197, 199], [200, 205], [206, 208], [209, 212], [213, 217], [218, 222], [223, 227], [227, 228]]}
{"doc_key": "ai-test-219", "ner": [[18, 19, "task"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 25, 26, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "example", ",", "the", "ambiguity", "of", "'", "mouse", "'", "(", "animal", "or", "device", ")", "is", "not", "relevant", "for", "machine", "translation", ",", "but", "is", "relevant", "for", "information", "retrieval", "."], "sentence-detokenized": "For example, the ambiguity of 'mouse' (animal or device) is not relevant for machine translation, but is relevant for information retrieval.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 26], [27, 29], [30, 31], [31, 36], [36, 37], [38, 39], [39, 45], [46, 48], [49, 55], [55, 56], [57, 59], [60, 63], [64, 72], [73, 76], [77, 84], [85, 96], [96, 97], [98, 101], [102, 104], [105, 113], [114, 117], [118, 129], [130, 139], [139, 140]]}
{"doc_key": "ai-test-220", "ner": [[0, 2, "algorithm"], [6, 8, "field"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 8, 0, 2, "usage", "", false, false], [12, 13, 6, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Geometric", "hashing", "was", "originally", "proposed", "in", "computer", "vision", "for", "2D", "and", "3D", "object", "recognition", "."], "sentence-detokenized": "Geometric hashing was originally proposed in computer vision for 2D and 3D object recognition.", "token2charspan": [[0, 9], [10, 17], [18, 21], [22, 32], [33, 41], [42, 44], [45, 53], [54, 60], [61, 64], [65, 67], [68, 71], [72, 74], [75, 81], [82, 93], [93, 94]]}
{"doc_key": "ai-test-221", "ner": [[17, 17, "field"], [2, 3, "field"], [0, 6, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 17, 17, "part-of", "subfield", false, false], [0, 6, 17, 17, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Along", "with", "supervised", "learning", "and", "reinforcement", "learning", ",", "it", "forms", "one", "of", "the", "three", "main", "categories", "of", "machine", "learning", "."], "sentence-detokenized": "Along with supervised learning and reinforcement learning, it forms one of the three main categories of machine learning.", "token2charspan": [[0, 5], [6, 10], [11, 21], [22, 30], [31, 34], [35, 48], [49, 57], [57, 58], [59, 61], [62, 67], [68, 71], [72, 74], [75, 78], [79, 84], [85, 89], [90, 100], [101, 103], [104, 111], [112, 120], [120, 121]]}
{"doc_key": "ai-test-222", "ner": [[5, 6, "field"], [17, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 30, "field"], [32, 33, "field"], [35, 36, "field"], [38, 38, "field"], [40, 40, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[5, 6, 17, 17, "part-of", "subfield", false, false], [5, 6, 19, 20, "part-of", "subfield", false, false], [5, 6, 22, 23, "part-of", "subfield", false, false], [5, 6, 25, 26, "part-of", "subfield", false, false], [5, 6, 28, 30, "part-of", "subfield", false, false], [5, 6, 32, 33, "part-of", "subfield", false, false], [5, 6, 35, 36, "part-of", "subfield", false, false], [5, 6, 38, 38, "part-of", "subfield", false, false], [5, 6, 40, 40, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Due", "to", "its", "generality", ",", "reinforcement", "learning", "has", "also", "been", "studied", "in", "many", "other", "fields", ",", "including", "games", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "optimisation", "by", "simulation", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Due to its generality, reinforcement learning has also been studied in many other fields, including games, control theory, operations research, information theory, optimisation by simulation, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 21], [21, 22], [23, 36], [37, 45], [46, 49], [50, 54], [55, 59], [60, 67], [68, 70], [71, 75], [76, 81], [82, 88], [88, 89], [90, 99], [100, 105], [105, 106], [107, 114], [115, 121], [121, 122], [123, 133], [134, 142], [142, 143], [144, 155], [156, 162], [162, 163], [164, 176], [177, 179], [180, 190], [190, 191], [192, 203], [204, 211], [211, 212], [213, 218], [219, 231], [231, 232], [233, 243], [244, 247], [248, 255], [256, 266], [266, 267]]}
{"doc_key": "ai-test-223", "ner": [[0, 2, "field"], [6, 6, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 6, "related-to", "", false, false], [0, 2, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pattern", "recognition", "is", "closely", "related", "to", "artificial", "intelligence", "and", "machine", "learning", "."], "sentence-detokenized": "Pattern recognition is closely related to artificial intelligence and machine learning.", "token2charspan": [[0, 7], [8, 19], [20, 22], [23, 30], [31, 38], [39, 41], [42, 52], [53, 65], [66, 69], [70, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-224", "ner": [[7, 8, "algorithm"], [10, 10, "field"], [12, 13, "field"], [24, 25, "task"], [27, 27, "task"], [29, 30, "task"], [32, 33, "algorithm"], [23, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[7, 8, 10, 10, "related-to", "", false, false], [7, 8, 12, 13, "related-to", "", false, false], [24, 25, 7, 8, "usage", "", true, false], [27, 27, 7, 8, "usage", "", true, false], [29, 30, 7, 8, "usage", "", true, false], [32, 33, 7, 8, "usage", "", true, false], [23, 37, 7, 8, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Used", "to", "design", ",", "train", "and", "deploy", "neural", "network", "(", "supervised", "and", "unsupervised", "learning", ")", "models", "to", "perform", "a", "variety", "of", "tasks", ",", "including", "data", "mining", ",", "classification", ",", "function", "approximation", ",", "multivariate", "regression", "and", "time", "series", "prediction", "."], "sentence-detokenized": "Used to design, train and deploy neural network (supervised and unsupervised learning) models to perform a variety of tasks, including data mining, classification, function approximation, multivariate regression and time series prediction.", "token2charspan": [[0, 4], [5, 7], [8, 14], [14, 15], [16, 21], [22, 25], [26, 32], [33, 39], [40, 47], [48, 49], [49, 59], [60, 63], [64, 76], [77, 85], [85, 86], [87, 93], [94, 96], [97, 104], [105, 106], [107, 114], [115, 117], [118, 123], [123, 124], [125, 134], [135, 139], [140, 146], [146, 147], [148, 162], [162, 163], [164, 172], [173, 186], [186, 187], [188, 200], [201, 211], [212, 215], [216, 220], [221, 227], [228, 238], [238, 239]]}
{"doc_key": "ai-test-225", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2016", ",", "he", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2016, he was elected a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [98, 99]]}
{"doc_key": "ai-test-226", "ner": [[6, 9, "organisation"], [16, 21, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", "(", "since", "2005", ")", "and", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "(", "since", "2009", ")", "."], "sentence-detokenized": "He is a member of the National Academy of Sciences (since 2005) and the American Academy of Arts and Sciences (since 2009).", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 38], [39, 41], [42, 50], [51, 52], [52, 57], [58, 62], [62, 63], [64, 67], [68, 71], [72, 80], [81, 88], [89, 91], [92, 96], [97, 100], [101, 109], [110, 111], [111, 116], [117, 121], [121, 122], [122, 123]]}
{"doc_key": "ai-test-227", "ner": [[3, 6, "misc"], [8, 13, "product"], [23, 23, "country"], [28, 29, "misc"]], "ner_mapping_to_source": [0, 1, 3, 4], "relations": [[8, 13, 3, 6, "temporal", "", false, false], [8, 13, 23, 23, "physical", "", false, false], [8, 13, 28, 29, "opposite", "", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["During", "the", "1973", "Russo", "-", "Japanese", "War", ",", "surface", "-", "to", "-", "air", "missile", "batteries", "deployed", "by", "the", "Soviet", "Union", "in", "Egypt", "and", "Syria", "caused", "significant", "damage", "to", "Israeli", "fighters", "."], "sentence-detokenized": "During the 1973 Russo-Japanese War, surface-to-air missile batteries deployed by the Soviet Union in Egypt and Syria caused significant damage to Israeli fighters.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 21], [21, 22], [22, 30], [31, 34], [34, 35], [36, 43], [43, 44], [44, 46], [46, 47], [47, 50], [51, 58], [59, 68], [69, 77], [78, 80], [81, 84], [85, 91], [92, 97], [98, 100], [101, 106], [107, 110], [111, 116], [117, 123], [124, 135], [136, 142], [143, 145], [146, 153], [154, 162], [162, 163]]}
{"doc_key": "ai-test-228", "ner": [[9, 10, "product"], [14, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 15, 9, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Another", "resource", "(", "free", "but", "copyrighted", ")", "is", "the", "HTK", "book", "(", "and", "accompanying", "HTK", "toolkit", ")", "."], "sentence-detokenized": "Another resource (free but copyrighted) is the HTK book (and accompanying HTK toolkit).", "token2charspan": [[0, 7], [8, 16], [17, 18], [18, 22], [23, 26], [27, 38], [38, 39], [40, 42], [43, 46], [47, 50], [51, 55], [56, 57], [57, 60], [61, 73], [74, 77], [78, 85], [85, 86], [86, 87]]}
{"doc_key": "ai-test-229", "ner": [[19, 20, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "was", "the", "first", "time", "that", "linguists", ",", "computer", "scientists", "and", "other", "researchers", "had", "united", "their", "interests", "at", "the", "2004", "AAAI", "Spring", "Symposium", "to", "propose", "a", "shared", "task", "and", "benchmark", "dataset", "for", "systematic", "computational", "research", "on", "emotions", ",", "appeals", ",", "subjectivity", "and", "sentiment", "in", "text", "."], "sentence-detokenized": "- was the first time that linguists, computer scientists and other researchers had united their interests at the 2004 AAAI Spring Symposium to propose a shared task and benchmark dataset for systematic computational research on emotions, appeals, subjectivity and sentiment in text.", "token2charspan": [[0, 1], [2, 5], [6, 9], [10, 15], [16, 20], [21, 25], [26, 35], [35, 36], [37, 45], [46, 56], [57, 60], [61, 66], [67, 78], [79, 82], [83, 89], [90, 95], [96, 105], [106, 108], [109, 112], [113, 117], [118, 122], [123, 129], [130, 139], [140, 142], [143, 150], [151, 152], [153, 159], [160, 164], [165, 168], [169, 178], [179, 186], [187, 190], [191, 201], [202, 215], [216, 224], [225, 227], [228, 236], [236, 237], [238, 245], [245, 246], [247, 259], [260, 263], [264, 273], [274, 276], [277, 281], [281, 282]]}
{"doc_key": "ai-test-230", "ner": [[10, 10, "task"], [15, 16, "task"], [18, 21, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "single", "grid", "can", "be", "analysed", "for", "both", "content", "(", "visual", ")", "and", "structure", "(", "cluster", "analysis", ",", "principal", "component", "analysis", "and", "various", "structural", "indicators", "of", "assessment", "complexity", "and", "scope", "being", "the", "main", "methods", ")", "."], "sentence-detokenized": "A single grid can be analysed for both content (visual) and structure (cluster analysis, principal component analysis and various structural indicators of assessment complexity and scope being the main methods).", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 17], [18, 20], [21, 29], [30, 33], [34, 38], [39, 46], [47, 48], [48, 54], [54, 55], [56, 59], [60, 69], [70, 71], [71, 78], [79, 87], [87, 88], [89, 98], [99, 108], [109, 117], [118, 121], [122, 129], [130, 140], [141, 151], [152, 154], [155, 165], [166, 176], [177, 180], [181, 186], [187, 192], [193, 196], [197, 201], [202, 209], [209, 210], [210, 211]]}
{"doc_key": "ai-test-231", "ner": [[8, 15, "product"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2018", ",", "Toyota", "was", "assessed", "as", "being", "behind", "the", "curve", "in", "self", "-", "driving", "vehicles", "and", "in", "need", "of", "innovation", "."], "sentence-detokenized": "In 2018, Toyota was assessed as being behind the curve in self-driving vehicles and in need of innovation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 28], [29, 31], [32, 37], [38, 44], [45, 48], [49, 54], [55, 57], [58, 62], [62, 63], [63, 70], [71, 79], [80, 83], [84, 86], [87, 91], [92, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-test-232", "ner": [[41, 42, "misc"], [44, 45, "misc"], [39, 51, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "targets", "include", "natural", "objects", "such", "as", "the", "ground", ",", "oceans", ",", "precipitation", "(", "rain", ",", "snow", ",", "hail", ",", "etc.", ")", ",", "sandstorms", ",", "animals", "(", "especially", "birds", ")", "and", "atmospheric", "turbulence", ",", "as", "well", "as", "atmospheric", "effects", "such", "as", "ionospheric", "reflections", ",", "meteor", "trails", "and", "three", "-", "body", "scattering", "spikes", "."], "sentence-detokenized": "Such targets include natural objects such as the ground, oceans, precipitation (rain, snow, hail, etc.), sandstorms, animals (especially birds) and atmospheric turbulence, as well as atmospheric effects such as ionospheric reflections, meteor trails and three-body scattering spikes.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 28], [29, 36], [37, 41], [42, 44], [45, 48], [49, 55], [55, 56], [57, 63], [63, 64], [65, 78], [79, 80], [80, 84], [84, 85], [86, 90], [90, 91], [92, 96], [96, 97], [98, 102], [102, 103], [103, 104], [105, 115], [115, 116], [117, 124], [125, 126], [126, 136], [137, 142], [142, 143], [144, 147], [148, 159], [160, 170], [170, 171], [172, 174], [175, 179], [180, 182], [183, 194], [195, 202], [203, 207], [208, 210], [211, 222], [223, 234], [234, 235], [236, 242], [243, 249], [250, 253], [254, 259], [259, 260], [260, 264], [265, 275], [276, 282], [282, 283]]}
{"doc_key": "ai-test-233", "ner": [[17, 17, "product"], [35, 36, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "planning", "and", "control", ",", "the", "essential", "difference", "between", "humanoids", "and", "other", "types", "of", "robots", "(", "e.g.", "industrial", "robots", ")", "is", "the", "requirement", "for", "human", "-", "like", "movements", "using", "leg", "-", "type", "locomotion", ",", "especially", "bipedal", "locomotion", "."], "sentence-detokenized": "In planning and control, the essential difference between humanoids and other types of robots (e.g. industrial robots) is the requirement for human-like movements using leg-type locomotion, especially bipedal locomotion.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 23], [23, 24], [25, 28], [29, 38], [39, 49], [50, 57], [58, 67], [68, 71], [72, 77], [78, 83], [84, 86], [87, 93], [94, 95], [95, 99], [100, 110], [111, 117], [117, 118], [119, 121], [122, 125], [126, 137], [138, 141], [142, 147], [147, 148], [148, 152], [153, 162], [163, 168], [169, 172], [172, 173], [173, 177], [178, 188], [188, 189], [190, 200], [201, 208], [209, 219], [219, 220]]}
{"doc_key": "ai-test-234", "ner": [[0, 1, "algorithm"], [9, 11, "misc"], [12, 16, "metrics"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Gradient", "descent", "methods", "may", "require", "many", "iterations", "to", "calculate", "local", "minima", "with", "the", "required", "accuracy", "when", "the", "curvature", "in", "different", "directions", "is", "very", "different", "for", "a", "given", "function", "."], "sentence-detokenized": "Gradient descent methods may require many iterations to calculate local minima with the required accuracy when the curvature in different directions is very different for a given function.", "token2charspan": [[0, 8], [9, 16], [17, 24], [25, 28], [29, 36], [37, 41], [42, 52], [53, 55], [56, 65], [66, 71], [72, 78], [79, 83], [84, 87], [88, 96], [97, 105], [106, 110], [111, 114], [115, 124], [125, 127], [128, 137], [138, 148], [149, 151], [152, 156], [157, 166], [167, 170], [171, 172], [173, 178], [179, 187], [187, 188]]}
{"doc_key": "ai-test-235", "ner": [[0, 28, "misc"], [12, 12, "misc"], [12, 21, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 28, 12, 12, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["The", "RoboCup", "2D", "Football", "Simulation", "League", "was", "the", "first", "event", "of", "the", "RoboCup", "international", "joint", "conference", "on", "artificial", "intelligence", ",", "held", "in", "Nagoya", "from", "23", "-", "29", "August", "1997", "."], "sentence-detokenized": "The RoboCup 2D Football Simulation League was the first event of the RoboCup international joint conference on artificial intelligence, held in Nagoya from 23-29 August 1997.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 23], [24, 34], [35, 41], [42, 45], [46, 49], [50, 55], [56, 61], [62, 64], [65, 68], [69, 76], [77, 90], [91, 96], [97, 107], [108, 110], [111, 121], [122, 134], [134, 135], [136, 140], [141, 143], [144, 150], [151, 155], [156, 158], [158, 159], [159, 161], [162, 168], [169, 173], [173, 174]]}
{"doc_key": "ai-test-236", "ner": [[6, 6, "programlang"], [9, 9, "programlang"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "options", "include", "an", "embedded", "Python", "environment", ",", "R", "console", "and", "Rserve", "support", "."], "sentence-detokenized": "Other programming options include an embedded Python environment, R console and Rserve support.", "token2charspan": [[0, 5], [6, 17], [18, 25], [26, 33], [34, 36], [37, 45], [46, 52], [53, 64], [64, 65], [66, 67], [68, 75], [76, 79], [80, 86], [87, 94], [94, 95]]}
{"doc_key": "ai-test-237", "ner": [[24, 26, "location"], [6, 6, "field"], [9, 9, "field"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 20, "researcher"], [27, 29, "field"], [30, 31, "field"], [4, 35, "field"], [38, 44, "field"], [45, 49, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[12, 13, 9, 9, "related-to", "contributes_to_field", true, false], [15, 16, 9, 9, "related-to", "contributes_to_field", true, false], [18, 20, 9, 9, "related-to", "contributes_to_field", true, false], [4, 35, 30, 31, "part-of", "", false, false], [38, 44, 4, 35, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Fundamental", "contributions", "to", "the", "development", "of", "artificial", "intelligence", "and", "robotics", "(", "with", "Wolfram", "Burgard", ",", "Dieter", "Fox", "and", "Sebastian", "Thrun", "as", "disciples", ")", "from", "Bonn", ",", "especially", "software", "engineering", "in", "civil", "engineering", ",", "and", "information", "systems", ",", "especially", "in", "earth", "sciences", ".", "was", "awarded", "the", "AAAI", "Classic", "Paper", "award", "in", "2016.2014", "."], "sentence-detokenized": "Fundamental contributions to the development of artificial intelligence and robotics (with Wolfram Burgard, Dieter Fox and Sebastian Thrun as disciples) from Bonn, especially software engineering in civil engineering, and information systems, especially in earth sciences. was awarded the AAAI Classic Paper award in 2016.2014.", "token2charspan": [[0, 11], [12, 25], [26, 28], [29, 32], [33, 44], [45, 47], [48, 58], [59, 71], [72, 75], [76, 84], [85, 86], [86, 90], [91, 98], [99, 106], [106, 107], [108, 114], [115, 118], [119, 122], [123, 132], [133, 138], [139, 141], [142, 151], [151, 152], [153, 157], [158, 162], [162, 163], [164, 174], [175, 183], [184, 195], [196, 198], [199, 204], [205, 216], [216, 217], [218, 221], [222, 233], [234, 241], [241, 242], [243, 253], [254, 256], [257, 262], [263, 271], [271, 272], [273, 276], [277, 284], [285, 288], [289, 293], [294, 301], [302, 307], [308, 313], [314, 316], [317, 326], [326, 327]]}
{"doc_key": "ai-test-238", "ner": [[2, 10, "conference"], [11, 14, "location"], [15, 15, "location"], [17, 19, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 10, 11, 14, "physical", "", false, false], [11, 14, 15, 15, "physical", "", false, false], [15, 15, 17, 19, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "first", "USA", "version", "of", "Campus", "Party", "will", "be", "held", "at", "the", "TCF", "Centre", "in", "Detroit", ",", "Michigan", ",", "from", "20", "-", "22", "August", "."], "sentence-detokenized": "The first USA version of Campus Party will be held at the TCF Centre in Detroit, Michigan, from 20-22 August.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 21], [22, 24], [25, 31], [32, 37], [38, 42], [43, 45], [46, 50], [51, 53], [54, 57], [58, 61], [62, 68], [69, 71], [72, 79], [79, 80], [81, 89], [89, 90], [91, 95], [96, 98], [98, 99], [99, 101], [102, 108], [108, 109]]}
{"doc_key": "ai-test-239", "ner": [[4, 5, "researcher"], [2, 8, "researcher"], [0, 0, "researcher"], [10, 15, "misc"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 10, 15, "win-defeat", "", false, false], [2, 8, 10, 15, "win-defeat", "", false, false], [0, 0, 10, 15, "win-defeat", "", false, false], [10, 15, 23, 25, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Hinton", ",", "along", "with", "Yann", "LeCun", "and", "Yoshua", "Bengio", ",", "received", "the", "2018", "Turing", "Award", "for", "conceptual", "and", "engineering", "breakthroughs", "that", "have", "made", "deep", "neural", "networks", "a", "key", "component", "of", "computing", "."], "sentence-detokenized": "Hinton, along with Yann LeCun and Yoshua Bengio, received the 2018 Turing Award for conceptual and engineering breakthroughs that have made deep neural networks a key component of computing.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 18], [19, 23], [24, 29], [30, 33], [34, 40], [41, 47], [47, 48], [49, 57], [58, 61], [62, 66], [67, 73], [74, 79], [80, 83], [84, 94], [95, 98], [99, 110], [111, 124], [125, 129], [130, 134], [135, 139], [140, 144], [145, 151], [152, 160], [161, 162], [163, 166], [167, 176], [177, 179], [180, 189], [189, 190]]}
{"doc_key": "ai-test-240", "ner": [[0, 3, "product"], [9, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 9, 14, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Euler", "Math", "Toolbox", "uses", "a", "matrix", "language", "similar", "to", "MATLAB", ",", "which", "has", "been", "under", "development", "since", "the", "1970s", "."], "sentence-detokenized": "The Euler Math Toolbox uses a matrix language similar to MATLAB, which has been under development since the 1970s.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 22], [23, 27], [28, 29], [30, 36], [37, 45], [46, 53], [54, 56], [57, 63], [63, 64], [65, 70], [71, 74], [75, 79], [80, 85], [86, 97], [98, 103], [104, 107], [108, 113], [113, 114]]}
{"doc_key": "ai-test-241", "ner": [[6, 6, "programlang"], [8, 9, "programlang"], [11, 11, "programlang"], [5, 13, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "languages", "are", "portable", "(", "e.g.", "Scheme", ",", "Common", "Lisp", ",", "Perl", ",", "D", ")", "."], "sentence-detokenized": "Some languages are portable (e.g. Scheme, Common Lisp, Perl, D).", "token2charspan": [[0, 4], [5, 14], [15, 18], [19, 27], [28, 29], [29, 33], [34, 40], [40, 41], [42, 48], [49, 53], [53, 54], [55, 59], [59, 60], [61, 62], [62, 63], [63, 64]]}
{"doc_key": "ai-test-242", "ner": [[6, 6, "misc"], [10, 10, "researcher"], [23, 25, "misc"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[6, 6, 10, 10, "artifact", "", false, false], [6, 6, 23, 25, "topic", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "1969", ",", "the", "famous", "book", "Perceptron", "by", "Minsky", "and", "Papert", "showed", "that", "it", "is", "impossible", "for", "these", "classes", "of", "networks", "to", "learn", "the", "XOR", "function", "."], "sentence-detokenized": "In 1969, the famous book Perceptron by Minsky and Papert showed that it is impossible for these classes of networks to learn the XOR function.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 19], [20, 24], [25, 35], [36, 38], [39, 45], [46, 49], [50, 56], [57, 63], [64, 68], [69, 71], [72, 74], [75, 85], [86, 89], [90, 95], [96, 103], [104, 106], [107, 115], [116, 118], [119, 124], [125, 128], [129, 132], [133, 141], [141, 142]]}
{"doc_key": "ai-test-243", "ner": [[4, 8, "misc"], [10, 14, "product"], [18, 21, "organisation"], [25, 28, "organisation"], [30, 36, "location"], [38, 38, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 21, 10, 14, "usage", "", false, false], [18, 21, 30, 36, "physical", "", false, false], [25, 28, 18, 21, "named", "", false, false], [30, 36, 38, 38, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "large", "volume", "of", "Russian", "scientific", "and", "technical", "documents", "were", "translated", "using", "SYSTRAN", "under", "the", "auspices", "of", "the", "USAF", "Foreign", "Technology", "Division", "(", "later", "the", "National", "Aerospace", "Information", "Centre", ")", "at", "Wright", "-", "Patterson", "Air", "Force", "Base", ",", "Ohio", "."], "sentence-detokenized": "A large volume of Russian scientific and technical documents were translated using SYSTRAN under the auspices of the USAF Foreign Technology Division (later the National Aerospace Information Centre) at Wright-Patterson Air Force Base, Ohio.", "token2charspan": [[0, 1], [2, 7], [8, 14], [15, 17], [18, 25], [26, 36], [37, 40], [41, 50], [51, 60], [61, 65], [66, 76], [77, 82], [83, 90], [91, 96], [97, 100], [101, 109], [110, 112], [113, 116], [117, 121], [122, 129], [130, 140], [141, 149], [150, 151], [151, 156], [157, 160], [161, 169], [170, 179], [180, 191], [192, 198], [198, 199], [200, 202], [203, 209], [209, 210], [210, 219], [220, 223], [224, 229], [230, 234], [234, 235], [236, 240], [240, 241]]}
{"doc_key": "ai-test-244", "ner": [[0, 1, "field"], [4, 5, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Semi-supervised", "learning", "lies", "between", "unsupervised", "learning", "(", "without", "labelled", "training", "data", ")", "and", "supervised", "learning", "(", "with", "fully", "labelled", "training", "data", ")", "."], "sentence-detokenized": "Semi-supervised learning lies between unsupervised learning (without labelled training data) and supervised learning (with fully labelled training data).", "token2charspan": [[0, 15], [16, 24], [25, 29], [30, 37], [38, 50], [51, 59], [60, 61], [61, 68], [69, 77], [78, 86], [87, 91], [91, 92], [93, 96], [97, 107], [108, 116], [117, 118], [118, 122], [123, 128], [129, 137], [138, 146], [147, 151], [151, 152], [152, 153]]}
{"doc_key": "ai-test-245", "ner": [[0, 5, "algorithm"], [6, 11, "algorithm"], [22, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 5, 6, 11, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "-", "gram", "models", "are", "a", "type", "of", "probabilistic", "language", "model", "that", "efficiently", "predict", "the", "next", "item", "in", "such", "a", "sequence", "in", "the", "form", "of", "a", "(", "n", "-", "1", ")", "-order", "Markov", "model", "."], "sentence-detokenized": "An-gram models are a type of probabilistic language model that efficiently predict the next item in such a sequence in the form of a (n - 1)-order Markov model.", "token2charspan": [[0, 2], [2, 3], [3, 7], [8, 14], [15, 18], [19, 20], [21, 25], [26, 28], [29, 42], [43, 51], [52, 57], [58, 62], [63, 74], [75, 82], [83, 86], [87, 91], [92, 96], [97, 99], [100, 104], [105, 106], [107, 115], [116, 118], [119, 122], [123, 127], [128, 130], [131, 132], [133, 134], [134, 135], [136, 137], [138, 139], [139, 140], [140, 146], [147, 153], [154, 159], [159, 160]]}
{"doc_key": "ai-test-246", "ner": [[0, 3, "organisation"], [4, 6, "product"], [9, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 4, 6, "usage", "", false, false], [9, 15, 0, 3, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Cleveland", "Clinic", "has", "used", "Cyc", "to", "develop", "a", "natural", "language", "query", "interface", "for", "biomedical", "information", ",", "including", "information", "on", "decades", "of", "cardiothoracic", "surgery", "."], "sentence-detokenized": "The Cleveland Clinic has used Cyc to develop a natural language query interface for biomedical information, including information on decades of cardiothoracic surgery.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 24], [25, 29], [30, 33], [34, 36], [37, 44], [45, 46], [47, 54], [55, 63], [64, 69], [70, 79], [80, 83], [84, 94], [95, 106], [106, 107], [108, 117], [118, 129], [130, 132], [133, 140], [141, 143], [144, 158], [159, 166], [166, 167]]}
{"doc_key": "ai-test-247", "ner": [[2, 7, "country"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "incident", "strained", "relations", "between", "the", "two", "countries", ",", "leading", "to", "the", "arrest", "and", "prosecution", "of", "two", "senior", "officials", "and", "the", "imposition", "of", "sanctions", "by", "both", "countries", "."], "sentence-detokenized": "The incident strained relations between the two countries, leading to the arrest and prosecution of two senior officials and the imposition of sanctions by both countries.", "token2charspan": [[0, 3], [4, 12], [13, 21], [22, 31], [32, 39], [40, 43], [44, 47], [48, 57], [57, 58], [59, 66], [67, 69], [70, 73], [74, 80], [81, 84], [85, 96], [97, 99], [100, 103], [104, 110], [111, 120], [121, 124], [125, 128], [129, 139], [140, 142], [143, 152], [153, 155], [156, 160], [161, 170], [170, 171]]}
{"doc_key": "ai-test-248", "ner": [[8, 8, "algorithm"], [3, 4, "field"], [16, 16, "misc"], [15, 29, "misc"], [32, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 8, 3, 4, "type-of", "", false, false], [16, 16, 3, 4, "part-of", "", true, false], [15, 29, 3, 4, "part-of", "", true, false], [32, 33, 3, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["When", "modelling", "with", "machine", "learning", ",", "such", "as", "artificial", "neural", "networks", ",", "parameter", "optimisation", "is", "called", "training", "and", "optimisation", "of", "the", "hyper", "-", "parameters", "of", "the", "model", "is", "called", "tuning", ",", "often", "using", "cross-validation", "."], "sentence-detokenized": "When modelling with machine learning, such as artificial neural networks, parameter optimisation is called training and optimisation of the hyper-parameters of the model is called tuning, often using cross-validation.", "token2charspan": [[0, 4], [5, 14], [15, 19], [20, 27], [28, 36], [36, 37], [38, 42], [43, 45], [46, 56], [57, 63], [64, 72], [72, 73], [74, 83], [84, 96], [97, 99], [100, 106], [107, 115], [116, 119], [120, 132], [133, 135], [136, 139], [140, 145], [145, 146], [146, 156], [157, 159], [160, 163], [164, 169], [170, 172], [173, 179], [180, 186], [186, 187], [188, 193], [194, 199], [200, 216], [216, 217]]}
{"doc_key": "ai-test-249", "ner": [[4, 4, "country"], [6, 6, "country"], [8, 8, "country"], [14, 16, "organisation"], [18, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 16, 18, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Localised", "versions", "in", "the", "UK", ",", "India", "and", "Australia", "were", "discontinued", "following", "the", "acquisition", "of", "Rotten", "Tomatoes", "by", "Fandango", "."], "sentence-detokenized": "Localised versions in the UK, India and Australia were discontinued following the acquisition of Rotten Tomatoes by Fandango.", "token2charspan": [[0, 9], [10, 18], [19, 21], [22, 25], [26, 28], [28, 29], [30, 35], [36, 39], [40, 49], [50, 54], [55, 67], [68, 77], [78, 81], [82, 93], [94, 96], [97, 103], [104, 112], [113, 115], [116, 124], [124, 125]]}
{"doc_key": "ai-test-250", "ner": [[0, 3, "task"], [13, 14, "metrics"], [17, 21, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 13, 14, "related-to", "", false, false], [13, 14, 17, 21, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "NER", "model", "is", "one", "of", "a", "number", "of", "methods", "for", "determining", "the", "accuracy", "of", "live", "subtitles", "produced", "using", "speech", "recognition", "for", "television", "broadcasts", "and", "events", "."], "sentence-detokenized": "The NER model is one of a number of methods for determining the accuracy of live subtitles produced using speech recognition for television broadcasts and events.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 20], [21, 23], [24, 25], [26, 32], [33, 35], [36, 43], [44, 47], [48, 59], [60, 63], [64, 72], [73, 75], [76, 80], [81, 90], [91, 99], [100, 105], [106, 112], [113, 124], [125, 128], [129, 139], [140, 150], [151, 154], [155, 161], [161, 162]]}
{"doc_key": "ai-test-251", "ner": [[0, 0, "researcher"], [4, 5, "university"], [8, 13, "university"], [11, 11, "location"], [15, 17, "university"], [21, 21, "university"], [22, 23, "location"], [26, 32, "university"], [33, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 5, "physical", "", false, false], [0, 0, 4, 5, "role", "", false, false], [0, 0, 8, 13, "physical", "", false, false], [0, 0, 8, 13, "role", "", false, false], [0, 0, 15, 17, "physical", "", false, false], [0, 0, 15, 17, "role", "", false, false], [0, 0, 21, 21, "physical", "", false, false], [0, 0, 21, 21, "role", "", false, false], [0, 0, 26, 32, "physical", "", false, false], [0, 0, 26, 32, "role", "", false, false], [8, 13, 11, 11, "physical", "", false, false], [15, 17, 22, 23, "physical", "", false, false], [21, 21, 22, 23, "physical", "", false, false], [26, 32, 33, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Atran", "has", "taught", "at", "Cambridge", "University", ",", "the", "Hebrew", "University", "of", "Jerusalem", ",", "the", "\u00c9cole", "pratique", "des", "hautes", "\u00e9tudes", "and", "\u00c9cole", "Polytechnique", "in", "Paris", "and", "the", "John", "Jay", "College", "of", "Criminal", "Justice", "in", "New", "York", "."], "sentence-detokenized": "Atran has taught at Cambridge University, the Hebrew University of Jerusalem, the \u00c9cole pratique des hautes \u00e9tudes and \u00c9cole Polytechnique in Paris and the John Jay College of Criminal Justice in New York.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 40], [40, 41], [42, 45], [46, 52], [53, 63], [64, 66], [67, 76], [76, 77], [78, 81], [82, 87], [88, 96], [97, 100], [101, 107], [108, 114], [115, 118], [119, 124], [125, 138], [139, 141], [142, 147], [148, 151], [152, 155], [156, 160], [161, 164], [165, 172], [173, 175], [176, 184], [185, 192], [193, 195], [196, 199], [200, 204], [204, 205]]}
{"doc_key": "ai-test-252", "ner": [[0, 2, "product"], [4, 6, "task"], [10, 13, "researcher"], [14, 14, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 4, 6, "origin", "", false, false], [0, 2, 4, 6, "related-to", "", false, false], [4, 6, 14, 14, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "was", "an", "early", "natural", "language", "understanding", "computer", "programme", "developed", "by", "Terry", "Winograd", "at", "MIT", "between", "1968", "and", "1970", "."], "sentence-detokenized": "SHRDLU was an early natural language understanding computer programme developed by Terry Winograd at MIT between 1968 and 1970.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 19], [20, 27], [28, 36], [37, 50], [51, 59], [60, 69], [70, 79], [80, 82], [83, 88], [89, 97], [98, 100], [101, 104], [105, 112], [113, 117], [118, 121], [122, 126], [126, 127]]}
{"doc_key": "ai-test-253", "ner": [[0, 5, "misc"], [6, 7, "field"], [8, 11, "university"], [15, 15, "country"], [13, 22, "university"], [25, 25, "misc"], [25, 32, "field"], [33, 35, "university"], [38, 40, "misc"], [41, 44, "field"], [45, 50, "university"], [61, 65, "field"], [67, 68, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14], "relations": [[0, 5, 6, 7, "topic", "", false, false], [0, 5, 8, 11, "origin", "", false, false], [8, 11, 13, 22, "role", "affiliated_with", false, false], [25, 25, 25, 32, "topic", "", false, false], [25, 25, 33, 35, "origin", "", false, false], [38, 40, 41, 44, "topic", "", false, false], [67, 68, 45, 50, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 3, 5, 6, 7, 10], "sentence": ["He", "received", "his", "B.Tech", ".", "in", "Electronics", "from", "B.M.S.", "Institute", "of", "Technology", ",", "Bangalore", ",", "India", "(", "affiliated", "to", "Bangalore", "University", ")", "in", "1982", ",", "M.Tech", ".", "in", "Electrical", "and", "Computer", "Engineering", "from", "Drexel", "University", "in", "1984", ",", "M.Sc", ".", "in", "Computer", "Science", "from", "the", "University", "of", "Wisconsin", "-", "Madison", "in", "1989", "and", "Ph", ".", "D.", "in", "1990", ",", "respectively", ",", "studying", "Artificial", "Intelligence", "and", "working", "with", "Leonard", "Earle", "."], "sentence-detokenized": "He received his B.Tech. in Electronics from B.M.S. Institute of Technology, Bangalore, India (affiliated to Bangalore University) in 1982, M.Tech. in Electrical and Computer Engineering from Drexel University in 1984, M.Sc. in Computer Science from the University of Wisconsin-Madison in 1989 and Ph. D. in 1990, respectively, studying Artificial Intelligence and working with Leonard Earle.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 22], [22, 23], [24, 26], [27, 38], [39, 43], [44, 50], [51, 60], [61, 63], [64, 74], [74, 75], [76, 85], [85, 86], [87, 92], [93, 94], [94, 104], [105, 107], [108, 117], [118, 128], [128, 129], [130, 132], [133, 137], [137, 138], [139, 145], [145, 146], [147, 149], [150, 160], [161, 164], [165, 173], [174, 185], [186, 190], [191, 197], [198, 208], [209, 211], [212, 216], [216, 217], [218, 222], [222, 223], [224, 226], [227, 235], [236, 243], [244, 248], [249, 252], [253, 263], [264, 266], [267, 276], [276, 277], [277, 284], [285, 287], [288, 292], [293, 296], [297, 299], [299, 300], [301, 303], [304, 306], [307, 311], [311, 312], [313, 325], [325, 326], [327, 335], [336, 346], [347, 359], [360, 363], [364, 371], [372, 376], [377, 384], [385, 390], [390, 391]]}
{"doc_key": "ai-test-254", "ner": [[7, 11, "metrics"], [3, 25, "metrics"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Accuracy", "is", "usually", "assessed", "in", "terms", "of", "word", "error", "rate", "(", "WER", ")", ",", "while", "speed", "is", "assessed", "in", "terms", "of", "a", "real", "-", "time", "factor", "."], "sentence-detokenized": "Accuracy is usually assessed in terms of word error rate (WER), while speed is assessed in terms of a real-time factor.", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 28], [29, 31], [32, 37], [38, 40], [41, 45], [46, 51], [52, 56], [57, 58], [58, 61], [61, 62], [62, 63], [64, 69], [70, 75], [76, 78], [79, 87], [88, 90], [91, 96], [97, 99], [100, 101], [102, 106], [106, 107], [107, 111], [112, 118], [118, 119]]}
{"doc_key": "ai-test-255", "ner": [[3, 4, "researcher"], [5, 12, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 5, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1971", ",", "Terry", "Winograd", "developed", "an", "early", "natural", "language", "processing", "engine", "that", "could", "interpret", "commands", "written", "in", "natural", "language", "using", "simple", "rules", "."], "sentence-detokenized": "In 1971, Terry Winograd developed an early natural language processing engine that could interpret commands written in natural language using simple rules.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 33], [34, 36], [37, 42], [43, 50], [51, 59], [60, 70], [71, 77], [78, 82], [83, 88], [89, 98], [99, 107], [108, 115], [116, 118], [119, 126], [127, 135], [136, 141], [142, 148], [149, 154], [154, 155]]}
{"doc_key": "ai-test-256", "ner": [[13, 14, "field"], [0, 1, "researcher"], [3, 6, "researcher"], [8, 9, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 14, 0, 1, "related-to", "", false, false], [13, 14, 3, 6, "related-to", "", false, false], [13, 14, 8, 9, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Marvin", "Minsky", ",", "Herbert", "A", ".", "Simon", "and", "Allen", "Newell", "are", "prominent", "in", "artificial", "intelligence", "."], "sentence-detokenized": "Marvin Minsky, Herbert A. Simon and Allen Newell are prominent in artificial intelligence.", "token2charspan": [[0, 6], [7, 13], [13, 14], [15, 22], [23, 24], [24, 25], [26, 31], [32, 35], [36, 41], [42, 48], [49, 52], [53, 62], [63, 65], [66, 76], [77, 89], [89, 90]]}
{"doc_key": "ai-test-257", "ner": [[9, 10, "field"], [13, 13, "field"], [15, 18, "field"], [33, 36, "field"], [43, 46, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 13, 9, 10, "origin", "", true, false], [13, 13, 9, 10, "part-of", "", false, false], [13, 13, 33, 36, "compare", "", false, false], [15, 18, 9, 10, "origin", "", true, false], [15, 18, 9, 10, "part-of", "", false, false], [15, 18, 33, 36, "compare", "", false, false], [33, 36, 9, 10, "origin", "", true, false], [33, 36, 9, 10, "part-of", "", false, false], [33, 36, 43, 46, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "the", "second", "half", "of", "the", "20th", "century", ",", "electrical", "engineering", "separated", "into", "electronics", "and", "computer", "engineering", ",", "which", "specialise", "in", "the", "design", "and", "analysis", "of", "systems", "that", "handle", "physical", "signals", ",", "and", "design", "engineering", ",", "which", "deals", "with", "the", "functional", "design", "of", "user", "-", "machine", "interfaces", "."], "sentence-detokenized": "In the second half of the 20th century, electrical engineering separated into electronics and computer engineering, which specialise in the design and analysis of systems that handle physical signals, and design engineering, which deals with the functional design of user-machine interfaces.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 21], [22, 25], [26, 30], [31, 38], [38, 39], [40, 50], [51, 62], [63, 72], [73, 77], [78, 89], [90, 93], [94, 102], [103, 114], [114, 115], [116, 121], [122, 132], [133, 135], [136, 139], [140, 146], [147, 150], [151, 159], [160, 162], [163, 170], [171, 175], [176, 182], [183, 191], [192, 199], [199, 200], [201, 204], [205, 211], [212, 223], [223, 224], [225, 230], [231, 236], [237, 241], [242, 245], [246, 256], [257, 263], [264, 266], [267, 271], [271, 272], [272, 279], [280, 290], [290, 291]]}
{"doc_key": "ai-test-258", "ner": [[30, 32, "metrics"], [39, 41, "metrics"], [45, 51, "metrics"]], "ner_mapping_to_source": [3, 4, 5], "relations": [[30, 32, 39, 41, "named", "", false, false], [39, 41, 45, 51, "part-of", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["It", "measures", "the", "proportion", "of", "all", "correctly", "classified", "instances", "and", "is", "the", "ratio", "of", "the", "number", "of", "correct", "classifications", "to", "the", "total", "number", "of", "correct", "or", "incorrect", "classifications", ":", "(", "TP", "+", "TN", ")", "/", "total", "population", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "It measures the proportion of all correctly classified instances and is the ratio of the number of correct classifications to the total number of correct or incorrect classifications: (TP + TN) / total population = (TP + TN) / (TP + TN + FP + FN).", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 26], [27, 29], [30, 33], [34, 43], [44, 54], [55, 64], [65, 68], [69, 71], [72, 75], [76, 81], [82, 84], [85, 88], [89, 95], [96, 98], [99, 106], [107, 122], [123, 125], [126, 129], [130, 135], [136, 142], [143, 145], [146, 153], [154, 156], [157, 166], [167, 182], [182, 183], [184, 185], [185, 187], [188, 189], [190, 192], [192, 193], [194, 195], [196, 201], [202, 212], [213, 214], [215, 216], [216, 218], [219, 220], [221, 223], [223, 224], [225, 226], [227, 228], [228, 230], [231, 232], [233, 235], [236, 237], [238, 240], [241, 242], [243, 245], [245, 246], [246, 247]]}
{"doc_key": "ai-test-259", "ner": [[4, 10, "conference"], [11, 15, "conference"], [25, 26, "location"], [21, 21, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 10, 25, 26, "physical", "", false, false], [11, 15, 4, 10, "named", "", false, false], [21, 21, 4, 10, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "academia", ",", "the", "first", "international", "conference", "Data", "Mining", "and", "Knowledge", "Discovery", "(", "KDD", "-", "95", ")", ",", "organised", "by", "the", "AAAI", ",", "started", "in", "Montreal", "in", "1995", "and", "became", "a", "major", "research", "forum", "."], "sentence-detokenized": "In academia, the first international conference Data Mining and Knowledge Discovery (KDD-95), organised by the AAAI, started in Montreal in 1995 and became a major research forum.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 16], [17, 22], [23, 36], [37, 47], [48, 52], [53, 59], [60, 63], [64, 73], [74, 83], [84, 85], [85, 88], [88, 89], [89, 91], [91, 92], [92, 93], [94, 103], [104, 106], [107, 110], [111, 115], [115, 116], [117, 124], [125, 127], [128, 136], [137, 139], [140, 144], [145, 148], [149, 155], [156, 157], [158, 163], [164, 172], [173, 178], [178, 179]]}
{"doc_key": "ai-test-260", "ner": [[4, 4, "field"], [7, 8, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "approach", "uses", "various", "data", "mining", "and", "machine", "learning", "algorithms", "to", "develop", "models", "that", "predict", "user", "ratings", "for", "unrated", "items", "."], "sentence-detokenized": "This approach uses various data mining and machine learning algorithms to develop models that predict user ratings for unrated items.", "token2charspan": [[0, 4], [5, 13], [14, 18], [19, 26], [27, 31], [32, 38], [39, 42], [43, 50], [51, 59], [60, 70], [71, 73], [74, 81], [82, 88], [89, 93], [94, 101], [102, 106], [107, 114], [115, 118], [119, 126], [127, 132], [132, 133]]}
{"doc_key": "ai-test-261", "ner": [[6, 8, "algorithm"], [11, 12, "algorithm"], [13, 17, "algorithm"], [21, 21, "misc"], [25, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 8, 11, 12, "related-to", "equivalent", false, false], [11, 12, 13, 17, "usage", "", false, false], [13, 17, 25, 26, "usage", "", false, false], [25, 26, 21, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "above", "considerations", "suggest", "that", "the", "SVM", "technique", "is", "equivalent", "to", "empirical", "risk", "using", "Tikhonov", "regularisation", ",", "in", "which", "case", "the", "loss", "function", "is", "the", "hinge", "loss"], "sentence-detokenized": "The above considerations suggest that the SVM technique is equivalent to empirical risk using Tikhonov regularisation, in which case the loss function is the hinge loss", "token2charspan": [[0, 3], [4, 9], [10, 24], [25, 32], [33, 37], [38, 41], [42, 45], [46, 55], [56, 58], [59, 69], [70, 72], [73, 82], [83, 87], [88, 93], [94, 102], [103, 117], [117, 118], [119, 121], [122, 127], [128, 132], [133, 136], [137, 141], [142, 150], [151, 153], [154, 157], [158, 163], [164, 168]]}
{"doc_key": "ai-test-262", "ner": [[6, 9, "person"], [10, 10, "person"], [13, 14, "organisation"], [16, 17, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 17, 13, 14, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "2015", "edition", "was", "hosted", "by", "Molly", "McGrath", ",", "with", "Chris", "Rose", "and", "former", "UFC", "fighter", "Kenny", "Florian", "as", "commentators", "."], "sentence-detokenized": "The 2015 edition was hosted by Molly McGrath, with Chris Rose and former UFC fighter Kenny Florian as commentators.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 27], [28, 30], [31, 36], [37, 44], [44, 45], [46, 50], [51, 56], [57, 61], [62, 65], [66, 72], [73, 76], [77, 84], [85, 90], [91, 98], [99, 101], [102, 114], [114, 115]]}
{"doc_key": "ai-test-263", "ner": [[2, 6, "product"], [9, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [18, 18, "researcher"], [21, 21, "researcher"], [29, 31, "task"], [33, 33, "product"], [37, 37, "researcher"], [41, 43, "task"], [45, 45, "researcher"], [49, 51, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12], "relations": [[2, 6, 9, 11, "origin", "", false, false], [2, 6, 13, 14, "origin", "", false, false], [2, 6, 16, 17, "origin", "", false, false], [2, 6, 18, 18, "origin", "", false, false], [13, 14, 37, 37, "named", "same", false, false], [16, 17, 21, 21, "named", "same", false, false], [29, 31, 33, 33, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 7], "sentence": ["A", "subset", "called", "Micro", "-", "Planner", "was", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "Sussman", ",", "and", "Winograd", "1971", ",", "and", "used", "in", "Winograd", "'s", "natural", "language", "understanding", "programme", "SHRDLU", "and", "used", "in", "Eugene", "Charniak", "'s", "work", "on", "narrative", "understanding", ",", "Thorne", "McCarty", "'s", "work", "on", "legal", "reasoning", "and", "several", "other", "projects", "."], "sentence-detokenized": "A subset called Micro-Planner was implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd Sussman, and Winograd 1971, and used in Winograd's natural language understanding programme SHRDLU and used in Eugene Charniak's work on narrative understanding, Thorne McCarty's work on legal reasoning and several other projects.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [21, 22], [22, 29], [30, 33], [34, 45], [46, 48], [49, 55], [56, 59], [60, 67], [67, 68], [69, 75], [76, 84], [85, 88], [89, 94], [95, 103], [104, 111], [111, 112], [113, 116], [117, 125], [126, 130], [130, 131], [132, 135], [136, 140], [141, 143], [144, 152], [152, 154], [155, 162], [163, 171], [172, 185], [186, 195], [196, 202], [203, 206], [207, 211], [212, 214], [215, 221], [222, 230], [230, 232], [233, 237], [238, 240], [241, 250], [251, 264], [264, 265], [266, 272], [273, 280], [280, 282], [283, 287], [288, 290], [291, 296], [297, 306], [307, 310], [311, 318], [319, 324], [325, 333], [333, 334]]}
{"doc_key": "ai-test-264", "ner": [[0, 5, "product"], [10, 14, "product"], [15, 16, "task"], [18, 19, "task"], [22, 23, "task"], [25, 26, "task"], [28, 30, "task"], [32, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 14, 0, 5, "usage", "", true, false], [15, 16, 10, 14, "part-of", "", true, false], [18, 19, 10, 14, "part-of", "", true, false], [22, 23, 10, 14, "part-of", "", true, false], [25, 26, 10, 14, "part-of", "", true, false], [28, 30, 10, 14, "part-of", "", true, false], [32, 35, 10, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Word", "Net", "is", "used", "for", "a", "variety", "of", "purposes", "in", "information", "systems", ",", "including", "word", "sense", "disambiguation", ",", "information", "retrieval", ",", "automatic", "sentence", "classification", ",", "automatic", "summarisation", ",", "machine", "translation", "and", "even", "automatic", "crossword", "puzzle", "generation", "."], "sentence-detokenized": "WordNet is used for a variety of purposes in information systems, including word sense disambiguation, information retrieval, automatic sentence classification, automatic summarisation, machine translation and even automatic crossword puzzle generation.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 15], [16, 19], [20, 21], [22, 29], [30, 32], [33, 41], [42, 44], [45, 56], [57, 64], [64, 65], [66, 75], [76, 80], [81, 86], [87, 101], [101, 102], [103, 114], [115, 124], [124, 125], [126, 135], [136, 144], [145, 159], [159, 160], [161, 170], [171, 184], [184, 185], [186, 193], [194, 205], [206, 209], [210, 214], [215, 224], [225, 234], [235, 241], [242, 252], [252, 253]]}
{"doc_key": "ai-test-265", "ner": [[4, 4, "researcher"], [7, 7, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 7, 7, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1996", ",", "he", "was", "appointed", "an", "IEEE", "Fellow", "."], "sentence-detokenized": "In 1996, he was appointed an IEEE Fellow.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 25], [26, 28], [29, 33], [34, 40], [40, 41]]}
{"doc_key": "ai-test-266", "ner": [[6, 12, "algorithm"], [53, 54, "misc"], [63, 64, "algorithm"], [66, 67, "algorithm"], [69, 70, "algorithm"], [72, 73, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[63, 64, 53, 54, "type-of", "", false, false], [66, 67, 53, 54, "type-of", "", false, false], [69, 70, 53, 54, "type-of", "", false, false], [72, 73, 53, 54, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "widely", "used", "type", "of", "composition", "is", "the", "non-linear", "weighted", "sum", ",", "mathine", "textstyle", "f", "(", "x", ")", "=", "K", "\\", "left", "(", "\\", "sum", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "\\", "right", ")", "/", "math", ",", "where", "mathine", "textstyle", "K", "/", "math", "(", "commonly", "referred", "to", "as", "activate", "function", ")", "is", "some", "predefined", "function", ",", "such", "as", "hyperbolic", "tangent", ",", "sigmoid", "function", ",", "softmax", "function", "or", "rectifier", "function", ".", "where", "mathine", "textstyle", "K", "is", "a", "predefined", "function", ",", "such", "as", "activated", "tangent", ",", "sigmoid", "function", ",", "softmax", "function", "or", "rectifier", "function", "."], "sentence-detokenized": "A widely used type of composition is the non-linear weighted sum, mathine textstyle f (x) = K\\ left (\\ sum _ i w _ i g _ i (x)\\ right) / math, where mathine textstyle K / math (commonly referred to as activate function) is some predefined function, such as hyperbolic tangent, sigmoid function, softmax function or rectifier function. where mathine textstyle K is a predefined function, such as activated tangent, sigmoid function, softmax function or rectifier function.", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 18], [19, 21], [22, 33], [34, 36], [37, 40], [41, 51], [52, 60], [61, 64], [64, 65], [66, 73], [74, 83], [84, 85], [86, 87], [87, 88], [88, 89], [90, 91], [92, 93], [93, 94], [95, 99], [100, 101], [101, 102], [103, 106], [107, 108], [109, 110], [111, 112], [113, 114], [115, 116], [117, 118], [119, 120], [121, 122], [123, 124], [124, 125], [125, 126], [126, 127], [128, 133], [133, 134], [135, 136], [137, 141], [141, 142], [143, 148], [149, 156], [157, 166], [167, 168], [169, 170], [171, 175], [176, 177], [177, 185], [186, 194], [195, 197], [198, 200], [201, 209], [210, 218], [218, 219], [220, 222], [223, 227], [228, 238], [239, 247], [247, 248], [249, 253], [254, 256], [257, 267], [268, 275], [275, 276], [277, 284], [285, 293], [293, 294], [295, 302], [303, 311], [312, 314], [315, 324], [325, 333], [333, 334], [335, 340], [341, 348], [349, 358], [359, 360], [361, 363], [364, 365], [366, 376], [377, 385], [385, 386], [387, 391], [392, 394], [395, 404], [405, 412], [412, 413], [414, 421], [422, 430], [430, 431], [432, 439], [440, 448], [449, 451], [452, 461], [462, 470], [470, 471]]}
{"doc_key": "ai-test-267", "ner": [[3, 3, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "film", "Westworld", ",", "female", "robots", "actually", "had", "intercourse", "with", "human", "men", ",", "creating", "a", "vacation", "world", "in", "which", "human", "customers", "paid", "to", "participate", "."], "sentence-detokenized": "In the film Westworld, female robots actually had intercourse with human men, creating a vacation world in which human customers paid to participate.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 21], [21, 22], [23, 29], [30, 36], [37, 45], [46, 49], [50, 61], [62, 66], [67, 72], [73, 76], [76, 77], [78, 86], [87, 88], [89, 97], [98, 103], [104, 106], [107, 112], [113, 118], [119, 128], [129, 133], [134, 136], [137, 148], [148, 149]]}
{"doc_key": "ai-test-268", "ner": [[5, 13, "task"], [22, 27, "task"], [20, 30, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 13, 22, 27, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "generally", "begins", "with", "the", "extraction", "of", "terms", ",", "concepts", "and", "noun", "phrases", "from", "plain", "text", "using", "linguistic", "processing", "systems", "such", "as", "part", "-", "of", "-", "speech", "tagging", "and", "phrase", "chunking", "."], "sentence-detokenized": "It generally begins with the extraction of terms, concepts and noun phrases from plain text using linguistic processing systems such as part-of-speech tagging and phrase chunking.", "token2charspan": [[0, 2], [3, 12], [13, 19], [20, 24], [25, 28], [29, 39], [40, 42], [43, 48], [48, 49], [50, 58], [59, 62], [63, 67], [68, 75], [76, 80], [81, 86], [87, 91], [92, 97], [98, 108], [109, 119], [120, 127], [128, 132], [133, 135], [136, 140], [140, 141], [141, 143], [143, 144], [144, 150], [151, 158], [159, 162], [163, 169], [170, 178], [178, 179]]}
{"doc_key": "ai-test-269", "ner": [[14, 15, "field"], [18, 21, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 21, 14, 15, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "demonstrated", "its", "performance", "on", "a", "number", "of", "problems", "of", "interest", "in", "the", "machine", "learning", "community", ",", "such", "as", "handwriting", "recognition", "."], "sentence-detokenized": "It has demonstrated its performance on a number of problems of interest in the machine learning community, such as handwriting recognition.", "token2charspan": [[0, 2], [3, 6], [7, 19], [20, 23], [24, 35], [36, 38], [39, 40], [41, 47], [48, 50], [51, 59], [60, 62], [63, 71], [72, 74], [75, 78], [79, 86], [87, 95], [96, 105], [105, 106], [107, 111], [112, 114], [115, 126], [127, 138], [138, 139]]}
{"doc_key": "ai-test-270", "ner": [[2, 3, "university"], [5, 5, "researcher"], [10, 12, "researcher"], [21, 21, "product"], [18, 19, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 5, 2, 3, "physical", "", false, false], [5, 5, 2, 3, "role", "", false, false], [21, 21, 10, 12, "origin", "", false, false], [21, 21, 18, 19, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "at", "Stanford", "University", ",", "Scheinman", "won", "a", "fellowship", "sponsored", "by", "George", "DeVol", ",", "inventor", "of", "the", "first", "industrial", "robot", ",", "Unimate", "."], "sentence-detokenized": "While at Stanford University, Scheinman won a fellowship sponsored by George DeVol, inventor of the first industrial robot, Unimate.", "token2charspan": [[0, 5], [6, 8], [9, 17], [18, 28], [28, 29], [30, 39], [40, 43], [44, 45], [46, 56], [57, 66], [67, 69], [70, 76], [77, 82], [82, 83], [84, 92], [93, 95], [96, 99], [100, 105], [106, 116], [117, 122], [122, 123], [124, 131], [131, 132]]}
{"doc_key": "ai-test-271", "ner": [[3, 5, "task"], [12, 12, "metrics"], [8, 11, "metrics"], [20, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 12, 12, "usage", "", true, false], [8, 11, 12, 12, "named", "", false, false], [20, 24, 12, 12, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Originally", "used", "to", "evaluate", "machine", "translation", ",", "the", "BLEU", "(", "Bilingual", "Evaluation", "understudy", ")", "has", "also", "been", "used", "successfully", "to", "evaluate", "paraphrase", "representation", "generation", "models", "."], "sentence-detokenized": "Originally used to evaluate machine translation, the BLEU (Bilingual Evaluation understudy) has also been used successfully to evaluate paraphrase representation generation models.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 27], [28, 35], [36, 47], [47, 48], [49, 52], [53, 57], [58, 59], [59, 68], [69, 79], [80, 90], [90, 91], [92, 95], [96, 100], [101, 105], [106, 110], [111, 123], [124, 126], [127, 135], [136, 146], [147, 161], [162, 172], [173, 179], [179, 180]]}
{"doc_key": "ai-test-272", "ner": [[0, 2, "organisation"], [11, 13, "organisation"], [14, 16, "product"], [20, 20, "country"]], "ner_mapping_to_source": [0, 2, 3, 5], "relations": [[0, 2, 11, 13, "role", "licenses_to", false, false], [11, 13, 20, 20, "physical", "", false, false], [14, 16, 11, 13, "artifact", "produces", false, false]], "relations_mapping_to_source": [1, 3, 5], "sentence": ["Unimation", "has", "since", "licensed", "the", "technology", "to", "Kawasaki", "Heavy", "Industries", "and", "GKN", ",", "which", "produce", "Unimate", "in", "Japan", "and", "the", "UK", "respectively", "."], "sentence-detokenized": "Unimation has since licensed the technology to Kawasaki Heavy Industries and GKN, which produce Unimate in Japan and the UK respectively.", "token2charspan": [[0, 9], [10, 13], [14, 19], [20, 28], [29, 32], [33, 43], [44, 46], [47, 55], [56, 61], [62, 72], [73, 76], [77, 80], [80, 81], [82, 87], [88, 95], [96, 103], [104, 106], [107, 112], [113, 116], [117, 120], [121, 123], [124, 136], [136, 137]]}
{"doc_key": "ai-test-273", "ner": [[13, 18, "conference"], [35, 36, "field"], [56, 56, "field"], [55, 63, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[35, 36, 56, 56, "compare", "", false, false], [55, 63, 56, 56, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Much", "of", "the", "confusion", "between", "the", "two", "research", "communities", "(", "with", "the", "exception", "of", "ECML", "PKDD", ",", "which", "is", "often", "a", "separate", "conference", "or", "journal", ")", "stems", "from", "the", "fundamental", "assumptions", "they", "address", ".", "In", "machine", "learning", ",", "performance", "is", "usually", "assessed", "with", "respect", "to", "the", "ability", "to", "reproduce", "known", "knowledge", ",", "whereas", "in", "knowledge", "discovery", "and", "data", "mining", "(", "KDD", ")", ",", "the", "key", "task", "is", "to", "discover", "previously", "unknown", "knowledge", "."], "sentence-detokenized": "Much of the confusion between the two research communities (with the exception of ECML PKDD, which is often a separate conference or journal) stems from the fundamental assumptions they address. In machine learning, performance is usually assessed with respect to the ability to reproduce known knowledge, whereas in knowledge discovery and data mining (KDD), the key task is to discover previously unknown knowledge.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 29], [30, 33], [34, 37], [38, 46], [47, 58], [59, 60], [60, 64], [65, 68], [69, 78], [79, 81], [82, 86], [87, 91], [91, 92], [93, 98], [99, 101], [102, 107], [108, 109], [110, 118], [119, 129], [130, 132], [133, 140], [140, 141], [142, 147], [148, 152], [153, 156], [157, 168], [169, 180], [181, 185], [186, 193], [193, 194], [195, 197], [198, 205], [206, 214], [214, 215], [216, 227], [228, 230], [231, 238], [239, 247], [248, 252], [253, 260], [261, 263], [264, 267], [268, 275], [276, 278], [279, 288], [289, 294], [295, 304], [304, 305], [306, 313], [314, 316], [317, 326], [327, 336], [337, 340], [341, 345], [346, 352], [353, 354], [354, 357], [357, 358], [358, 359], [360, 363], [364, 367], [368, 372], [373, 375], [376, 378], [379, 387], [388, 398], [399, 406], [407, 416], [416, 417]]}
{"doc_key": "ai-test-274", "ner": [[0, 2, "algorithm"], [9, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Hidden", "Markov", "models", "form", "the", "basis", "of", "most", "modern", "automatic", "speech", "recognition", "systems", "."], "sentence-detokenized": "Hidden Markov models form the basis of most modern automatic speech recognition systems.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 25], [26, 29], [30, 35], [36, 38], [39, 43], [44, 50], [51, 60], [61, 67], [68, 79], [80, 87], [87, 88]]}
{"doc_key": "ai-test-275", "ner": [[0, 2, "location"], [3, 6, "country"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 3, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["is", "a", "Bangalore", ",", "India", "-", "based", "company", "specialising", "in", "online", "handwriting", "recognition", "software", "."], "sentence-detokenized": "is a Bangalore, India-based company specialising in online handwriting recognition software.", "token2charspan": [[0, 2], [3, 4], [5, 14], [14, 15], [16, 21], [21, 22], [22, 27], [28, 35], [36, 48], [49, 51], [52, 58], [59, 70], [71, 82], [83, 91], [91, 92]]}
{"doc_key": "ai-test-276", "ner": [[23, 26, "misc"], [50, 50, "metrics"], [52, 54, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[50, 50, 52, 54, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Does", "repeated", "translation", "converge", "to", "a", "single", "representation", "in", "both", "languages", "?", "In", "other", "words", ",", "does", "the", "translation", "method", "exhibit", "stationarity", "or", "produce", "a", "normal", "form", "?", "Does", "the", "translation", "become", "stationary", "without", "losing", "the", "original", "meaning", "?", "This", "indicator", "has", "been", "criticised", "for", "not", "correlating", "well", "with", "the", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "score", "."], "sentence-detokenized": "Does repeated translation converge to a single representation in both languages? In other words, does the translation method exhibit stationarity or produce a normal form? Does the translation become stationary without losing the original meaning? This indicator has been criticised for not correlating well with the BLEU (BiLingual Evaluation Understudy) score.", "token2charspan": [[0, 4], [5, 13], [14, 25], [26, 34], [35, 37], [38, 39], [40, 46], [47, 61], [62, 64], [65, 69], [70, 79], [79, 80], [81, 83], [84, 89], [90, 95], [95, 96], [97, 101], [102, 105], [106, 117], [118, 124], [125, 132], [133, 145], [146, 148], [149, 156], [157, 158], [159, 165], [166, 170], [170, 171], [172, 176], [177, 180], [181, 192], [193, 199], [200, 210], [211, 218], [219, 225], [226, 229], [230, 238], [239, 246], [246, 247], [248, 252], [253, 262], [263, 266], [267, 271], [272, 282], [283, 286], [287, 290], [291, 302], [303, 307], [308, 312], [313, 316], [317, 321], [322, 323], [323, 332], [333, 343], [344, 354], [354, 355], [356, 361], [361, 362]]}
{"doc_key": "ai-test-277", "ner": [[5, 9, "organisation"], [12, 20, "organisation"], [21, 22, "university"], [25, 25, "university"], [27, 29, "field"], [31, 36, "organisation"], [39, 41, "organisation"], [50, 54, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[12, 20, 21, 22, "part-of", "", false, false], [25, 25, 27, 29, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "holds", "fellowships", "from", "the", "American", "Association", "for", "Artificial", "Intelligence", ",", "the", "Centre", "for", "Advanced", "Study", "in", "the", "Behavioural", "Sciences", "at", "Stanford", "University", ",", "the", "MIT", "Centre", "for", "Cognitive", "Science", ",", "the", "Canadian", "Institute", "for", "Advanced", "Study", "and", "the", "Canadian", "Psychological", "Association", ",", "and", "was", "elected", "a", "fellow", "of", "the", "Royal", "Society", "of", "Canada", "in", "1998", "."], "sentence-detokenized": "He holds fellowships from the American Association for Artificial Intelligence, the Centre for Advanced Study in the Behavioural Sciences at Stanford University, the MIT Centre for Cognitive Science, the Canadian Institute for Advanced Study and the Canadian Psychological Association, and was elected a fellow of the Royal Society of Canada in 1998.", "token2charspan": [[0, 2], [3, 8], [9, 20], [21, 25], [26, 29], [30, 38], [39, 50], [51, 54], [55, 65], [66, 78], [78, 79], [80, 83], [84, 90], [91, 94], [95, 103], [104, 109], [110, 112], [113, 116], [117, 128], [129, 137], [138, 140], [141, 149], [150, 160], [160, 161], [162, 165], [166, 169], [170, 176], [177, 180], [181, 190], [191, 198], [198, 199], [200, 203], [204, 212], [213, 222], [223, 226], [227, 235], [236, 241], [242, 245], [246, 249], [250, 258], [259, 272], [273, 284], [284, 285], [286, 289], [290, 293], [294, 301], [302, 303], [304, 310], [311, 313], [314, 317], [318, 323], [324, 331], [332, 334], [335, 341], [342, 344], [345, 349], [349, 350]]}
{"doc_key": "ai-test-278", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [18, 21, "misc"], [10, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 18, 21, "part-of", "", false, false], [0, 0, 10, 26, "part-of", "", false, false], [4, 5, 18, 21, "part-of", "", false, false], [4, 5, 10, 26, "part-of", "", false, false], [7, 8, 18, 21, "part-of", "", false, false], [7, 8, 10, 26, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", ",", "together", "with", "Joshua", "Bengio", "and", "Jan", "Lukun", ",", "is", "also", "known", "as", "the", "'", "Godfather", "of", "AI", "'", "and", "the", "'", "Godfather", "of", "Deep", "Learning", "'", "."], "sentence-detokenized": "Hinton, together with Joshua Bengio and Jan Lukun, is also known as the 'Godfather of AI' and the 'Godfather of Deep Learning'.", "token2charspan": [[0, 6], [6, 7], [8, 16], [17, 21], [22, 28], [29, 35], [36, 39], [40, 43], [44, 49], [49, 50], [51, 53], [54, 58], [59, 64], [65, 67], [68, 71], [72, 73], [73, 82], [83, 85], [86, 88], [88, 89], [90, 93], [94, 97], [98, 99], [99, 108], [109, 111], [112, 116], [117, 125], [125, 126], [126, 127]]}
{"doc_key": "ai-test-279", "ner": [[17, 17, "misc"], [19, 19, "misc"], [7, 8, "product"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[17, 17, 7, 8, "named", "same", false, false]], "relations_mapping_to_source": [2], "sentence": ["The", "lightweight", "open", "-", "source", "speech", "project", "eSpeak", "has", "its", "own", "synthesis", "method", "and", "has", "experimented", "with", "Mandarin", "and", "Cantonese", "."], "sentence-detokenized": "The lightweight open-source speech project eSpeak has its own synthesis method and has experimented with Mandarin and Cantonese.", "token2charspan": [[0, 3], [4, 15], [16, 20], [20, 21], [21, 27], [28, 34], [35, 42], [43, 49], [50, 53], [54, 57], [58, 61], [62, 71], [72, 78], [79, 82], [83, 86], [87, 99], [100, 104], [105, 113], [114, 117], [118, 127], [127, 128]]}
{"doc_key": "ai-test-280", "ner": [[3, 5, "product"], [19, 20, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 5, 19, 20, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "addition", ",", "Software", "Automatic", "Speech", ",", "launched", "in", "1982", ",", "was", "the", "first", "commercial", "all", "-", "software", "speech", "synthesis", "programme", "."], "sentence-detokenized": "In addition, Software Automatic Speech, launched in 1982, was the first commercial all-software speech synthesis programme.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 21], [22, 31], [32, 38], [38, 39], [40, 48], [49, 51], [52, 56], [56, 57], [58, 61], [62, 65], [66, 71], [72, 82], [83, 86], [86, 87], [87, 95], [96, 102], [103, 112], [113, 122], [122, 123]]}
{"doc_key": "ai-test-281", "ner": [[5, 7, "metrics"], [9, 9, "metrics"], [12, 12, "metrics"], [14, 14, "metrics"], [17, 24, "metrics"], [29, 32, "metrics"], [35, 42, "metrics"], [44, 46, "metrics"], [48, 48, "metrics"], [53, 53, "metrics"], [56, 62, "metrics"], [66, 68, "metrics"], [70, 70, "metrics"], [73, 80, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15], "relations": [[9, 9, 5, 7, "named", "", false, false], [12, 12, 5, 7, "named", "", false, false], [14, 14, 5, 7, "named", "", false, false], [17, 24, 5, 7, "named", "", false, false], [48, 48, 44, 46, "named", "", false, false], [53, 53, 44, 46, "named", "", false, false], [56, 62, 44, 46, "named", "", false, false], [70, 70, 66, 68, "named", "", false, false], [73, 80, 66, 68, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 6, 8, 9, 10, 11], "sentence": ["The", "column", "ratios", "are", ":", "true", "positive", "rate", "(", "TPR", ",", "aka", "sensitivity", "or", "reproducibility", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "and", "complement", "false", "negative", "rate", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ",", "true", "negative", "rate", "(", "TNR", ",", "aka", "specificity", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", "and", "complement", "false", "positive", "rate", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "The column ratios are: true positive rate (TPR, aka sensitivity or reproducibility) (TP / (TP + FN)), and complement false negative rate (FNR) (FN / (TP + FN)), true negative rate (TNR, aka specificity, SPC) (TN / (TN + FP)) and complement false positive rate (FPR) (FP / (TN + FP)).", "token2charspan": [[0, 3], [4, 10], [11, 17], [18, 21], [21, 22], [23, 27], [28, 36], [37, 41], [42, 43], [43, 46], [46, 47], [48, 51], [52, 63], [64, 66], [67, 82], [82, 83], [84, 85], [85, 87], [88, 89], [90, 91], [91, 93], [94, 95], [96, 98], [98, 99], [99, 100], [100, 101], [102, 105], [106, 116], [117, 122], [123, 131], [132, 136], [137, 138], [138, 141], [141, 142], [143, 144], [144, 146], [147, 148], [149, 150], [150, 152], [153, 154], [155, 157], [157, 158], [158, 159], [159, 160], [161, 165], [166, 174], [175, 179], [180, 181], [181, 184], [184, 185], [186, 189], [190, 201], [201, 202], [203, 206], [206, 207], [208, 209], [209, 211], [212, 213], [214, 215], [215, 217], [218, 219], [220, 222], [222, 223], [223, 224], [225, 228], [229, 239], [240, 245], [246, 254], [255, 259], [260, 261], [261, 264], [264, 265], [266, 267], [267, 269], [270, 271], [272, 273], [273, 275], [276, 277], [278, 280], [280, 281], [281, 282], [282, 283]]}
{"doc_key": "ai-test-282", "ner": [[2, 2, "person"], [3, 17, "product"]], "ner_mapping_to_source": [1, 2], "relations": [[2, 2, 3, 17, "role", "working_with", false, false]], "relations_mapping_to_source": [1], "sentence": ["Edzinger", "and", "Weber", "have", "also", "collaborated", "on", "a", "number", "of", "other", "robots", ",", "having", "developed", "Kismet", ",", "Abot"], "sentence-detokenized": "Edzinger and Weber have also collaborated on a number of other robots, having developed Kismet, Abot", "token2charspan": [[0, 8], [9, 12], [13, 18], [19, 23], [24, 28], [29, 41], [42, 44], [45, 46], [47, 53], [54, 56], [57, 62], [63, 69], [69, 70], [71, 77], [78, 87], [88, 94], [94, 95], [96, 100]]}
{"doc_key": "ai-test-283", "ner": [[0, 2, "programlang"], [9, 11, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 11, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["R", "functions", "can", "also", "be", "accessed", "from", "scripting", "languages", "such", "as", "Python", "."], "sentence-detokenized": "R functions can also be accessed from scripting languages such as Python.", "token2charspan": [[0, 1], [2, 11], [12, 15], [16, 20], [21, 23], [24, 32], [33, 37], [38, 47], [48, 57], [58, 62], [63, 65], [66, 72], [72, 73]]}
{"doc_key": "ai-test-284", "ner": [[0, 0, "programlang"], [11, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 14, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "was", "one", "of", "the", "first", "robotics", "languages", "and", "was", "used", "for", "the", "Unimate", "robot", "."], "sentence-detokenized": "VAL was one of the first robotics languages and was used for the Unimate robot.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 18], [19, 24], [25, 33], [34, 43], [44, 47], [48, 51], [52, 56], [57, 60], [61, 64], [65, 72], [73, 78], [78, 79]]}
{"doc_key": "ai-test-285", "ner": [[14, 20, "conference"], [16, 25, "conference"], [26, 26, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 20, 26, 26, "physical", "", false, false], [16, 25, 14, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["They", "presented", "the", "database", "for", "the", "first", "time", "in", "a", "poster", "presentation", "at", "the", "2009", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "in", "Florida", "."], "sentence-detokenized": "They presented the database for the first time in a poster presentation at the 2009 Conference on Computer Vision and Pattern Recognition (CVPR) in Florida.", "token2charspan": [[0, 4], [5, 14], [15, 18], [19, 27], [28, 31], [32, 35], [36, 41], [42, 46], [47, 49], [50, 51], [52, 58], [59, 71], [72, 74], [75, 78], [79, 83], [84, 94], [95, 97], [98, 106], [107, 113], [114, 117], [118, 125], [126, 137], [138, 139], [139, 143], [143, 144], [145, 147], [148, 155], [155, 156]]}
{"doc_key": "ai-test-286", "ner": [[0, 2, "misc"], [11, 12, "task"], [14, 15, "field"], [8, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 12, 0, 2, "type-of", "", false, false], [14, 15, 0, 2, "type-of", "", false, false], [8, 20, 0, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Classification", "tasks", "where", "labels", "are", "not", "supplied", "are", "referred", "to", "as", "unsupervised", "classification", ",", "unsupervised", "learning", ",", "cluster", "analysis", ",", "etc", "."], "sentence-detokenized": "Classification tasks where labels are not supplied are referred to as unsupervised classification, unsupervised learning, cluster analysis, etc.", "token2charspan": [[0, 14], [15, 20], [21, 26], [27, 33], [34, 37], [38, 41], [42, 50], [51, 54], [55, 63], [64, 66], [67, 69], [70, 82], [83, 97], [97, 98], [99, 111], [112, 120], [120, 121], [122, 129], [130, 138], [138, 139], [140, 143], [143, 144]]}
{"doc_key": "ai-test-287", "ner": [[0, 1, "task"], [9, 13, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Object", "recognition", ",", "human", "recognition", "and", "localisation", ",", "as", "well", "as", "emotional", "recognition", "are", "required", "."], "sentence-detokenized": "Object recognition, human recognition and localisation, as well as emotional recognition are required.", "token2charspan": [[0, 6], [7, 18], [18, 19], [20, 25], [26, 37], [38, 41], [42, 54], [54, 55], [56, 58], [59, 63], [64, 66], [67, 76], [77, 88], [89, 92], [93, 101], [101, 102]]}
{"doc_key": "ai-test-288", "ner": [[6, 6, "misc"], [8, 8, "misc"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "process", "is", "complex", "and", "involves", "encoding", "and", "recall", "or", "retrieval", "."], "sentence-detokenized": "The process is complex and involves encoding and recall or retrieval.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 26], [27, 35], [36, 44], [45, 48], [49, 55], [56, 58], [59, 68], [68, 69]]}
{"doc_key": "ai-test-289", "ner": [[11, 12, "product"], [41, 41, "product"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Also", "known", "as", "parallel", "robots", "or", "general", "Stewart", "platforms", "(", "in", "Stewart", "platforms", ",", "actuators", "are", "paired", "on", "both", "the", "base", "and", "the", "platform", ")", ",", "using", "a", "similar", "mechanism", "to", "move", "the", "base", "robot", "and", "one", "or", "more", "manipulator", "arms", "Articulated", "robots", "."], "sentence-detokenized": "Also known as parallel robots or general Stewart platforms (in Stewart platforms, actuators are paired on both the base and the platform), using a similar mechanism to move the base robot and one or more manipulator arms Articulated robots.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 29], [30, 32], [33, 40], [41, 48], [49, 58], [59, 60], [60, 62], [63, 70], [71, 80], [80, 81], [82, 91], [92, 95], [96, 102], [103, 105], [106, 110], [111, 114], [115, 119], [120, 123], [124, 127], [128, 136], [136, 137], [137, 138], [139, 144], [145, 146], [147, 154], [155, 164], [165, 167], [168, 172], [173, 176], [177, 181], [182, 187], [188, 191], [192, 195], [196, 198], [199, 203], [204, 215], [216, 220], [221, 232], [233, 239], [239, 240]]}
{"doc_key": "ai-test-290", "ner": [[0, 16, "field"], [2, 5, "field"], [8, 13, "field"], [17, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 16, 2, 5, "part-of", "subfield", false, false], [0, 16, 8, 13, "compare", "", false, false], [8, 13, 17, 17, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "vision", "as", "systems", "engineering", "is", "distinct", "from", "computer", "vision", ",", "which", "is", "a", "branch", "of", "computer", "science", "."], "sentence-detokenized": "Machine vision as systems engineering is distinct from computer vision, which is a branch of computer science.", "token2charspan": [[0, 7], [8, 14], [15, 17], [18, 25], [26, 37], [38, 40], [41, 49], [50, 54], [55, 63], [64, 70], [70, 71], [72, 77], [78, 80], [81, 82], [83, 89], [90, 92], [93, 101], [102, 109], [109, 110]]}
{"doc_key": "ai-test-291", "ner": [[4, 7, "algorithm"], [10, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 7, 10, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "activation", "function", "of", "an", "LSTM", "gate", "is", "often", "a", "logistic", "sigmoid", "function", "."], "sentence-detokenized": "The activation function of an LSTM gate is often a logistic sigmoid function.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 26], [27, 29], [30, 34], [35, 39], [40, 42], [43, 48], [49, 50], [51, 59], [60, 67], [68, 76], [76, 77]]}
{"doc_key": "ai-test-292", "ner": [[5, 8, "metrics"], [23, 36, "metrics"], [24, 28, "metrics"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[5, 8, 24, 28, "named", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["In", "other", "words", ",", "the", "sample", "mean", "is", "an", "efficient", "(", "not", "necessarily", "unique", ")", "estimator", ",", "and", "in", "addition", "to", "being", "a", "maximum", "likelihood", "estimator", ",", "it", "is", "also", "a", "minimum", "variance", "unbiased", "estimator", "(", "MVUE", ")", "."], "sentence-detokenized": "In other words, the sample mean is an efficient (not necessarily unique) estimator, and in addition to being a maximum likelihood estimator, it is also a minimum variance unbiased estimator (MVUE).", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 19], [20, 26], [27, 31], [32, 34], [35, 37], [38, 47], [48, 49], [49, 52], [53, 64], [65, 71], [71, 72], [73, 82], [82, 83], [84, 87], [88, 90], [91, 99], [100, 102], [103, 108], [109, 110], [111, 118], [119, 129], [130, 139], [139, 140], [141, 143], [144, 146], [147, 151], [152, 153], [154, 161], [162, 170], [171, 179], [180, 189], [190, 191], [191, 195], [195, 196], [196, 197]]}
{"doc_key": "ai-test-293", "ner": [[2, 5, "academicjournal"], [6, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [19, 20, "product"], [22, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 5, 19, 20, "topic", "", false, false], [2, 5, 22, 27, "topic", "", false, false], [6, 8, 2, 5, "role", "", false, false], [10, 11, 2, 5, "role", "", false, false], [13, 14, 2, 5, "role", "", false, false], [19, 20, 22, 27, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["A", "2001", "Scientific", "American", "article", "by", "Berners", "-", "Lee", ",", "James", "Hendler", "and", "Ola", "Lassila", "states", "that", "the", "existing", "web", "is", "expected", "to", "evolve", "into", "a", "semantic", "web", "."], "sentence-detokenized": "A 2001 Scientific American article by Berners-Lee, James Hendler and Ola Lassila states that the existing web is expected to evolve into a semantic web.", "token2charspan": [[0, 1], [2, 6], [7, 17], [18, 26], [27, 34], [35, 37], [38, 45], [45, 46], [46, 49], [49, 50], [51, 56], [57, 64], [65, 68], [69, 72], [73, 80], [81, 87], [88, 92], [93, 96], [97, 105], [106, 109], [110, 112], [113, 121], [122, 124], [125, 131], [132, 136], [137, 138], [139, 147], [148, 151], [151, 152]]}
{"doc_key": "ai-test-294", "ner": [[0, 3, "misc"], [15, 17, "person"], [44, 44, "person"]], "ner_mapping_to_source": [0, 2, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Blade", "Runner", "featured", "a", "number", "of", "actors", "who", "were", "little", "known", "at", "the", "time", ".", "Rachel", ",", "an", "experimental", "replicant", "who", "has", "been", "implanted", "with", "the", "memories", "of", "Tyrell", "'s", "niece", "and", "believes", "herself", "to", "be", "human", ",", "is", "played", "by", "Sean", "Young", "(", "Sammon", ",", "pp.", "92", "-", "93", "Nina", "Axelrod", "auditioned", "for", "the", "role", "."], "sentence-detokenized": "Blade Runner featured a number of actors who were little known at the time. Rachel, an experimental replicant who has been implanted with the memories of Tyrell's niece and believes herself to be human, is played by Sean Young (Sammon, pp. 92-93 Nina Axelrod auditioned for the role.", "token2charspan": [[0, 5], [6, 12], [13, 21], [22, 23], [24, 30], [31, 33], [34, 40], [41, 44], [45, 49], [50, 56], [57, 62], [63, 65], [66, 69], [70, 74], [74, 75], [76, 82], [82, 83], [84, 86], [87, 99], [100, 109], [110, 113], [114, 117], [118, 122], [123, 132], [133, 137], [138, 141], [142, 150], [151, 153], [154, 160], [160, 162], [163, 168], [169, 172], [173, 181], [182, 189], [190, 192], [193, 195], [196, 201], [201, 202], [203, 205], [206, 212], [213, 215], [216, 220], [221, 226], [227, 228], [228, 234], [234, 235], [236, 239], [240, 242], [242, 243], [243, 245], [246, 250], [251, 258], [259, 269], [270, 273], [274, 277], [278, 282], [282, 283]]}
{"doc_key": "ai-test-295", "ner": [[3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [12, 13, "researcher"], [15, 19, "university"], [22, 27, "product"], [42, 42, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7], "relations": [[3, 4, 15, 19, "physical", "", false, false], [6, 7, 15, 19, "physical", "", false, false], [9, 10, 15, 19, "physical", "", false, false], [12, 13, 15, 19, "physical", "", false, false], [15, 19, 42, 42, "physical", "", true, false], [22, 27, 15, 19, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 6], "sentence": ["In", "1971", ",", "Gary", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "and", "Terry", "Winograd", "visited", "the", "University", "of", "Edinburgh", "to", "inform", "them", "about", "the", "microplanner", "and", "the", "SHRDLU", ",", "and", "to", "question", "the", "solution", "uniform", "proof", "procedure", "approach", "that", "had", "dominated", "the", "Edinburgh", "Logic", "Society", "."], "sentence-detokenized": "In 1971, Gary Sussman, Eugene Charniak, Seymour Papert and Terry Winograd visited the University of Edinburgh to inform them about the microplanner and the SHRDLU, and to question the solution uniform proof procedure approach that had dominated the Edinburgh Logic Society.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 13], [14, 21], [21, 22], [23, 29], [30, 38], [38, 39], [40, 47], [48, 54], [55, 58], [59, 64], [65, 73], [74, 81], [82, 85], [86, 96], [97, 99], [100, 109], [110, 112], [113, 119], [120, 124], [125, 130], [131, 134], [135, 147], [148, 151], [152, 155], [156, 162], [162, 163], [164, 167], [168, 170], [171, 179], [180, 183], [184, 192], [193, 200], [201, 206], [207, 216], [217, 225], [226, 230], [231, 234], [235, 244], [245, 248], [249, 258], [259, 264], [265, 272], [272, 273]]}
{"doc_key": "ai-test-296", "ner": [[7, 7, "field"], [11, 12, "researcher"], [14, 15, "researcher"], [10, 18, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Walter", "'s", "work", "influenced", "subsequent", "generations", "of", "robotics", "researchers", ",", "including", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "Walter's work influenced subsequent generations of robotics researchers, including Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 6], [6, 8], [9, 13], [14, 24], [25, 35], [36, 47], [48, 50], [51, 59], [60, 71], [71, 72], [73, 82], [83, 89], [90, 96], [96, 97], [98, 102], [103, 110], [111, 114], [115, 119], [120, 126], [126, 127]]}
{"doc_key": "ai-test-297", "ner": [[5, 6, "algorithm"], [7, 12, "researcher"], [13, 21, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 7, 12, "origin", "", false, false], [5, 6, 13, 21, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "similar", "GPU", "-", "based", "CNN", "by", "Alex", "Krizhevsky", "et", "al", ".", "subsequently", "won", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "2012", "."], "sentence-detokenized": "A similar GPU-based CNN by Alex Krizhevsky et al. subsequently won the ImageNet Large Scale Visual Recognition Challenge 2012.", "token2charspan": [[0, 1], [2, 9], [10, 13], [13, 14], [14, 19], [20, 23], [24, 26], [27, 31], [32, 42], [43, 45], [46, 48], [48, 49], [50, 62], [63, 66], [67, 70], [71, 79], [80, 85], [86, 91], [92, 98], [99, 110], [111, 120], [121, 125], [125, 126]]}
{"doc_key": "ai-test-298", "ner": [[0, 0, "misc"], [12, 13, "metrics"], [18, 20, "misc"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[12, 13, 0, 0, "type-of", "", false, false], [12, 13, 18, 20, "related-to", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["Loss", "functions", "commonly", "used", "for", "probabilistic", "classification", "include", "log", "-", "loss", "and", "Brier", "scores", "between", "the", "predicted", "and", "true", "probability", "distributions", "."], "sentence-detokenized": "Loss functions commonly used for probabilistic classification include log-loss and Brier scores between the predicted and true probability distributions.", "token2charspan": [[0, 4], [5, 14], [15, 23], [24, 28], [29, 32], [33, 46], [47, 61], [62, 69], [70, 73], [73, 74], [74, 78], [79, 82], [83, 88], [89, 95], [96, 103], [104, 107], [108, 117], [118, 121], [122, 126], [127, 138], [139, 152], [152, 153]]}
{"doc_key": "ai-test-299", "ner": [[4, 5, "organisation"], [16, 18, "field"], [19, 19, "organisation"], [8, 9, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 16, 18, "general-affiliation", "field_of_study", false, false], [4, 5, 8, 9, "part-of", "", false, false], [19, 19, 4, 5, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "May", "2016", ",", "NtechLab", "was", "one", "of", "three", "Russian", "companies", "to", "pass", "official", "testing", "of", "biometric", "technology", "by", "NIST", "."], "sentence-detokenized": "In May 2016, NtechLab was one of three Russian companies to pass official testing of biometric technology by NIST.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [13, 21], [22, 25], [26, 29], [30, 32], [33, 38], [39, 46], [47, 56], [57, 59], [60, 64], [65, 73], [74, 81], [82, 84], [85, 94], [95, 105], [106, 108], [109, 113], [113, 114]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "floating", "-", "point", "numbers", "have", "only", "a", "certain", "degree", "of", "mathematical", "precision", "."], "sentence-detokenized": "However, floating-point numbers have only a certain degree of mathematical precision.", "token2charspan": [[0, 7], [7, 8], [9, 17], [17, 18], [18, 23], [24, 31], [32, 36], [37, 41], [42, 43], [44, 51], [52, 58], [59, 61], [62, 74], [75, 84], [84, 85]]}
{"doc_key": "ai-test-301", "ner": [[16, 20, "conference"], [12, 18, "conference"]], "ner_mapping_to_source": [1, 2], "relations": [[12, 18, 16, 20, "named", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["During", "2015", ",", "a", "number", "of", "SenseTime", "papers", "were", "accepted", "to", "the", "CVPR", "(", "Computer", "Vision", "and", "Pattern", "Recognition", ")", "conference", "."], "sentence-detokenized": "During 2015, a number of SenseTime papers were accepted to the CVPR (Computer Vision and Pattern Recognition) conference.", "token2charspan": [[0, 6], [7, 11], [11, 12], [13, 14], [15, 21], [22, 24], [25, 34], [35, 41], [42, 46], [47, 55], [56, 58], [59, 62], [63, 67], [68, 69], [69, 77], [78, 84], [85, 88], [89, 96], [97, 108], [108, 109], [110, 120], [120, 121]]}
{"doc_key": "ai-test-302", "ner": [[0, 1, "task"], [2, 4, "task"], [7, 8, "task"], [10, 13, "task"], [16, 16, "field"], [18, 20, "misc"], [22, 28, "conference"], [41, 43, "misc"], [45, 49, "conference"], [63, 65, "misc"], [67, 67, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 16, 16, "part-of", "task_part_of_field", false, false], [2, 4, 0, 1, "named", "", false, false], [7, 8, 16, 16, "part-of", "task_part_of_field", false, false], [10, 13, 7, 8, "named", "", false, false], [18, 20, 22, 28, "temporal", "", false, false], [41, 43, 45, 49, "temporal", "", false, false], [63, 65, 67, 67, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Structure", "From", "Motion", "(", "SFM", ",", "or", "Visual", "SLAM", ",", "simultaneous", "localisation", "and", "mapping", ",", "in", "Robotics", ";", "Best", "Paper", "Award", "at", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "1998", ")", ",", "co-developed", "an", "optimal", "algorithm", "to", "characterise", "its", "ambiguity", "(", "David", "Marr", "Prize", "at", "ICCV", "1999", ")", ",", "and", "also", "characterised", "the", "discriminability", "and", "observability", "of", "visual", "-", "inertial", "sensor", "fusion", "(", "Best", "Paper", "Award", "at", "Robotics", "2015", ")", "."], "sentence-detokenized": "Structure From Motion (SFM, or Visual SLAM, simultaneous localisation and mapping, in Robotics; Best Paper Award at Conference on Computer Vision and Pattern Recognition 1998), co-developed an optimal algorithm to characterise its ambiguity (David Marr Prize at ICCV 1999), and also characterised the discriminability and observability of visual-inertial sensor fusion (Best Paper Award at Robotics 2015 ).", "token2charspan": [[0, 9], [10, 14], [15, 21], [22, 23], [23, 26], [26, 27], [28, 30], [31, 37], [38, 42], [42, 43], [44, 56], [57, 69], [70, 73], [74, 81], [81, 82], [83, 85], [86, 94], [94, 95], [96, 100], [101, 106], [107, 112], [113, 115], [116, 126], [127, 129], [130, 138], [139, 145], [146, 149], [150, 157], [158, 169], [170, 174], [174, 175], [175, 176], [177, 189], [190, 192], [193, 200], [201, 210], [211, 213], [214, 226], [227, 230], [231, 240], [241, 242], [242, 247], [248, 252], [253, 258], [259, 261], [262, 266], [267, 271], [271, 272], [272, 273], [274, 277], [278, 282], [283, 296], [297, 300], [301, 317], [318, 321], [322, 335], [336, 338], [339, 345], [345, 346], [346, 354], [355, 361], [362, 368], [369, 370], [370, 374], [375, 380], [381, 386], [387, 389], [390, 398], [399, 403], [404, 405], [405, 406]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Association", "for", "the", "Promotion", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Association for the Promotion of Artificial Intelligence.", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 44], [45, 48], [49, 52], [53, 62], [63, 65], [66, 76], [77, 89], [89, 90]]}
{"doc_key": "ai-test-304", "ner": [[0, 2, "task"], [7, 8, "field"], [10, 11, "field"], [13, 14, "field"], [21, 21, "task"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 7, 8, "part-of", "task_part_of_field", false, false], [0, 2, 10, 11, "part-of", "task_part_of_field", false, false], [0, 2, 13, 14, "part-of", "task_part_of_field", false, false], [0, 2, 21, 21, "part-of", "", false, false], [0, 2, 24, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Edge", "detection", "is", "a", "fundamental", "tool", "in", "image", "processing", ",", "machine", "vision", "and", "computer", "vision", ",", "especially", "in", "the", "fields", "of", "feature", "detection", "and", "feature", "extraction", "."], "sentence-detokenized": "Edge detection is a fundamental tool in image processing, machine vision and computer vision, especially in the fields of feature detection and feature extraction.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 19], [20, 31], [32, 36], [37, 39], [40, 45], [46, 56], [56, 57], [58, 65], [66, 72], [73, 76], [77, 85], [86, 92], [92, 93], [94, 104], [105, 107], [108, 111], [112, 118], [119, 121], [122, 129], [130, 139], [140, 143], [144, 151], [152, 162], [162, 163]]}
{"doc_key": "ai-test-305", "ner": [[0, 7, "misc"], [15, 23, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "variables", "such", "as", "outdoor", "temperature", "(", "mathtemp", "/", "math", ")", "may", "be", "recorded", "to", "a", "few", "decimal", "places", "of", "precision", "in", "some", "applications", "(", "depending", "on", "the", "sensing", "device", ")", "."], "sentence-detokenized": "For example, variables such as outdoor temperature (mathtemp / math) may be recorded to a few decimal places of precision in some applications (depending on the sensing device).", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 22], [23, 27], [28, 30], [31, 38], [39, 50], [51, 52], [52, 60], [61, 62], [63, 67], [67, 68], [69, 72], [73, 75], [76, 84], [85, 87], [88, 89], [90, 93], [94, 101], [102, 108], [109, 111], [112, 121], [122, 124], [125, 129], [130, 142], [143, 144], [144, 153], [154, 156], [157, 160], [161, 168], [169, 175], [175, 176], [176, 177]]}
{"doc_key": "ai-test-306", "ner": [[0, 1, "person"], [3, 5, "person"], [6, 7, "person"], [14, 15, "person"], [17, 17, "misc"], [20, 21, "misc"], [23, 24, "person"], [26, 26, "organisation"], [29, 30, "person"], [32, 32, "organisation"], [34, 35, "person"], [37, 38, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[23, 24, 17, 17, "part-of", "", false, false], [23, 24, 20, 21, "role", "", false, false], [29, 30, 26, 26, "role", "", false, false], [34, 35, 32, 32, "role", "youtuber", false, false], [37, 38, 34, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Von", "Davis", ",", "Jessica", "Chobot", "and", "Leland", "Melvin", "return", "as", "judges", ",", "plus", "actor", "Clark", "Gregg", ",", "MythBusters", "host", "and", "former", "Battlebots", "builder", "Adam", "Savage", ",", "NFL", "tight", "end", "Vernon", "Davis", "and", "YouTube", "star", "Michael", "Stevens", "a.k.a", "Vsauce", "as", "celebrity", "guest", "judges", "."], "sentence-detokenized": "Von Davis, Jessica Chobot and Leland Melvin return as judges, plus actor Clark Gregg, MythBusters host and former Battlebots builder Adam Savage, NFL tight end Vernon Davis and YouTube star Michael Stevens a.k.a Vsauce as celebrity guest judges.", "token2charspan": [[0, 3], [4, 9], [9, 10], [11, 18], [19, 25], [26, 29], [30, 36], [37, 43], [44, 50], [51, 53], [54, 60], [60, 61], [62, 66], [67, 72], [73, 78], [79, 84], [84, 85], [86, 97], [98, 102], [103, 106], [107, 113], [114, 124], [125, 132], [133, 137], [138, 144], [144, 145], [146, 149], [150, 155], [156, 159], [160, 166], [167, 172], [173, 176], [177, 184], [185, 189], [190, 197], [198, 205], [206, 211], [212, 218], [219, 221], [222, 231], [232, 237], [238, 244], [244, 245]]}
{"doc_key": "ai-test-307", "ner": [[10, 11, "algorithm"], [15, 16, "algorithm"], [12, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 12, 20, "part-of", "", false, false], [15, 16, 12, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "these", "methods", "did", "not", "beat", "non-uniform", "internal", "handcrafted", "Gaussian", "mixture", "model", "/", "hidden", "Markov", "model", "(", "GMM", "-", "HMM", ")", "techniques", "based", "on", "discriminatively", "trained", "generative", "models", "of", "speech", "."], "sentence-detokenized": "However, these methods did not beat non-uniform internal handcrafted Gaussian mixture model/hidden Markov model (GMM-HMM) techniques based on discriminatively trained generative models of speech.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 22], [23, 26], [27, 30], [31, 35], [36, 47], [48, 56], [57, 68], [69, 77], [78, 85], [86, 91], [91, 92], [92, 98], [99, 105], [106, 111], [112, 113], [113, 116], [116, 117], [117, 120], [120, 121], [122, 132], [133, 138], [139, 141], [142, 158], [159, 166], [167, 177], [178, 184], [185, 187], [188, 194], [194, 195]]}
{"doc_key": "ai-test-308", "ner": [[4, 4, "product"], [6, 7, "programlang"], [9, 9, "programlang"], [2, 11, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Software", "packages", "such", "as", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", "and", "SciPy", "provide", "convenient", "ways", "to", "apply", "these", "different", "methods", "."], "sentence-detokenized": "Software packages such as MATLAB, GNU Octave, Scilab and SciPy provide convenient ways to apply these different methods.", "token2charspan": [[0, 8], [9, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 37], [38, 44], [44, 45], [46, 52], [53, 56], [57, 62], [63, 70], [71, 81], [82, 86], [87, 89], [90, 95], [96, 101], [102, 111], [112, 119], [119, 120]]}
{"doc_key": "ai-test-309", "ner": [[0, 7, "algorithm"], [8, 9, "task"], [18, 20, "researcher"], [21, 22, "university"], [24, 25, "researcher"], [29, 30, "organisation"], [27, 28, "organisation"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [[18, 20, 21, 22, "physical", "", false, false], [18, 20, 21, 22, "role", "", false, false], [24, 25, 29, 30, "physical", "", false, false], [24, 25, 29, 30, "role", "", false, false], [27, 28, 29, 30, "named", "", false, false]], "relations_mapping_to_source": [4, 5, 6, 7, 8], "sentence": ["Linear", "Predictive", "Coding", "(", "LPC", ")", ",", "a", "speech", "processing", "algorithm", ",", "was", "first", "proposed", "in", "1966", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "."], "sentence-detokenized": "Linear Predictive Coding (LPC), a speech processing algorithm, was first proposed in 1966 by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT).", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [30, 31], [32, 33], [34, 40], [41, 51], [52, 61], [61, 62], [63, 66], [67, 72], [73, 81], [82, 84], [85, 89], [90, 92], [93, 101], [102, 109], [110, 112], [113, 119], [120, 130], [131, 134], [135, 140], [141, 146], [147, 149], [150, 156], [157, 166], [167, 170], [171, 180], [181, 182], [182, 185], [185, 186], [186, 187]]}
{"doc_key": "ai-test-310", "ner": [[18, 19, "conference"], [20, 31, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 31, 18, 19, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2006", ",", "to", "celebrate", "the", "25th", "anniversary", "of", "the", "algorithm", ",", "a", "workshop", "was", "held", "at", "the", "International", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "to", "discuss", "the", "speed", "of", "the", "algorithm", ",", "the", "robustness", "and", "accuracy", "of", "the", "estimated", "solution", "and", "the", "reduced", "reliance", "on", "user-", "defined", "constants", ",", "as", "well", "as", "the", "latest", "Contributions", "and", "variations", "were", "summarised", "."], "sentence-detokenized": "In 2006, to celebrate the 25th anniversary of the algorithm, a workshop was held at the International Conference on Computer Vision and Pattern Recognition (CVPR) to discuss the speed of the algorithm, the robustness and accuracy of the estimated solution and the reduced reliance on user-defined constants, as well as the latest Contributions and variations were summarised.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 21], [22, 25], [26, 30], [31, 42], [43, 45], [46, 49], [50, 59], [59, 60], [61, 62], [63, 71], [72, 75], [76, 80], [81, 83], [84, 87], [88, 101], [102, 112], [113, 115], [116, 124], [125, 131], [132, 135], [136, 143], [144, 155], [156, 157], [157, 161], [161, 162], [163, 165], [166, 173], [174, 177], [178, 183], [184, 186], [187, 190], [191, 200], [200, 201], [202, 205], [206, 216], [217, 220], [221, 229], [230, 232], [233, 236], [237, 246], [247, 255], [256, 259], [260, 263], [264, 271], [272, 280], [281, 283], [284, 289], [289, 296], [297, 306], [306, 307], [308, 310], [311, 315], [316, 318], [319, 322], [323, 329], [330, 343], [344, 347], [348, 358], [359, 363], [364, 374], [374, 375]]}
{"doc_key": "ai-test-311", "ner": [[0, 6, "university"], [8, 11, "organisation"], [13, 14, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Members", "went", "to", "the", "University", "of", "Debrecen", ",", "Hungarian", "Academy", "of", "Sciences", "and", "E\u00f6tv\u00f6s", "Lor\u00e1nd", "University", "."], "sentence-detokenized": "Members went to the University of Debrecen, Hungarian Academy of Sciences and E\u00f6tv\u00f6s Lor\u00e1nd University.", "token2charspan": [[0, 7], [8, 12], [13, 15], [16, 19], [20, 30], [31, 33], [34, 42], [42, 43], [44, 53], [54, 61], [62, 64], [65, 73], [74, 77], [78, 84], [85, 91], [92, 102], [102, 103]]}
{"doc_key": "ai-test-312", "ner": [[5, 6, "algorithm"], [1, 4, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 1, 4, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Introduce", "a", "loss", "function", "to", "extend", "SVM", "when", "data", "are", "not", "linearly", "separable", "."], "sentence-detokenized": "Introduce a loss function to extend SVM when data are not linearly separable.", "token2charspan": [[0, 9], [10, 11], [12, 16], [17, 25], [26, 28], [29, 35], [36, 39], [40, 44], [45, 49], [50, 53], [54, 57], [58, 66], [67, 76], [76, 77]]}
{"doc_key": "ai-test-313", "ner": [[0, 2, "programlang"], [8, 9, "researcher"], [11, 12, "researcher"], [14, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 8, 9, "origin", "", false, false], [0, 2, 11, 12, "origin", "", false, false], [0, 2, 14, 16, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Logo", "is", "an", "educational", "programming", "language", "designed", "by", "Wally", "Feurzeig", ",", "Seymour", "Papert", "and", "Cynthia", "Solomon", "in", "1967", "."], "sentence-detokenized": "Logo is an educational programming language designed by Wally Feurzeig, Seymour Papert and Cynthia Solomon in 1967.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 34], [35, 43], [44, 52], [53, 55], [56, 61], [62, 70], [70, 71], [72, 79], [80, 86], [87, 90], [91, 98], [99, 106], [107, 109], [110, 114], [114, 115]]}
{"doc_key": "ai-test-314", "ner": [[0, 1, "organisation"], [5, 9, "organisation"], [10, 14, "location"], [15, 16, "location"], [17, 20, "location"], [24, 29, "product"], [34, 41, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 5, 9, "role", "works_for", false, false], [5, 9, 10, 14, "physical", "", false, false], [10, 14, 15, 16, "physical", "", false, false], [15, 16, 17, 20, "physical", "", false, false], [24, 29, 0, 1, "origin", "", false, false], [34, 41, 24, 29, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Eiling", "Labs", "worked", "with", "the", "US", "Air", "Force", "Missile", "Command", "at", "Hill", "Air", "Force", "Base", "near", "Ogden", ",", "Utah", ",", "to", "produce", "the", "'", "intelligent", "systems", "technology", "software", "'", "that", "later", "formed", "the", "basis", "of", "Reagan", "'s", "Star", "Wars", "programme", ",", "in", "the", "highest", "military", "secrecy", "."], "sentence-detokenized": "Eiling Labs worked with the US Air Force Missile Command at Hill Air Force Base near Ogden, Utah, to produce the 'intelligent systems technology software' that later formed the basis of Reagan's Star Wars programme, in the highest military secrecy.", "token2charspan": [[0, 6], [7, 11], [12, 18], [19, 23], [24, 27], [28, 30], [31, 34], [35, 40], [41, 48], [49, 56], [57, 59], [60, 64], [65, 68], [69, 74], [75, 79], [80, 84], [85, 90], [90, 91], [92, 96], [96, 97], [98, 100], [101, 108], [109, 112], [113, 114], [114, 125], [126, 133], [134, 144], [145, 153], [153, 154], [155, 159], [160, 165], [166, 172], [173, 176], [177, 182], [183, 185], [186, 192], [192, 194], [195, 199], [200, 204], [205, 214], [214, 215], [216, 218], [219, 222], [223, 230], [231, 239], [240, 247], [247, 248]]}
{"doc_key": "ai-test-315", "ner": [[21, 22, "field"], [3, 6, "researcher"], [8, 9, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "decades", ",", "John", "F", ".", "Sowa", "and", "John", "Zachman", "(", "1992", ")", "have", "been", "researching", "and", "developing", "new", "areas", "of", "computer", "science", ",", "including", "compilers", ",", "programming", "languages", "and", "system", "architectures", "."], "sentence-detokenized": "For decades, John F. Sowa and John Zachman (1992) have been researching and developing new areas of computer science, including compilers, programming languages and system architectures.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [18, 19], [19, 20], [21, 25], [26, 29], [30, 34], [35, 42], [43, 44], [44, 48], [48, 49], [50, 54], [55, 59], [60, 71], [72, 75], [76, 86], [87, 90], [91, 96], [97, 99], [100, 108], [109, 116], [116, 117], [118, 127], [128, 137], [137, 138], [139, 150], [151, 160], [161, 164], [165, 171], [172, 185], [185, 186]]}
{"doc_key": "ai-test-316", "ner": [[0, 1, "algorithm"], [5, 8, "algorithm"], [3, 13, "algorithm"], [16, 16, "field"], [19, 20, "field"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 8, 0, 1, "named", "", false, false], [3, 13, 0, 1, "named", "", false, false], [16, 16, 0, 1, "usage", "", false, false], [19, 20, 0, 1, "usage", "", false, false], [25, 26, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Sobel", "operators", ",", "also", "called", "Sobel", "-", "Feldman", "operators", "or", "Sobel", "filters", ",", "are", "used", "in", "image", "processing", "and", "computer", "vision", ",", "particularly", "in", "edge", "detection", "algorithms", ",", "to", "create", "edge", "-", "enhanced", "images", "."], "sentence-detokenized": "Sobel operators, also called Sobel-Feldman operators or Sobel filters, are used in image processing and computer vision, particularly in edge detection algorithms, to create edge-enhanced images.", "token2charspan": [[0, 5], [6, 15], [15, 16], [17, 21], [22, 28], [29, 34], [34, 35], [35, 42], [43, 52], [53, 55], [56, 61], [62, 69], [69, 70], [71, 74], [75, 79], [80, 82], [83, 88], [89, 99], [100, 103], [104, 112], [113, 119], [119, 120], [121, 133], [134, 136], [137, 141], [142, 151], [152, 162], [162, 163], [164, 166], [167, 173], [174, 178], [178, 179], [179, 187], [188, 194], [194, 195]]}
{"doc_key": "ai-test-317", "ner": [[3, 13, "field"], [14, 14, "algorithm"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["LDA", "is", "a", "supervised", "learning", "algorithm", "that", "uses", "labels", "in", "the", "data", ",", "while", "PCA", "is", "a", "learning", "algorithm", "that", "ignores", "labels", "."], "sentence-detokenized": "LDA is a supervised learning algorithm that uses labels in the data, while PCA is a learning algorithm that ignores labels.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 19], [20, 28], [29, 38], [39, 43], [44, 48], [49, 55], [56, 58], [59, 62], [63, 67], [67, 68], [69, 74], [75, 78], [79, 81], [82, 83], [84, 92], [93, 102], [103, 107], [108, 115], [116, 122], [122, 123]]}
{"doc_key": "ai-test-318", "ner": [[5, 5, "algorithm"], [7, 9, "algorithm"], [4, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "linear", "classification", "algorithms", "include", "Winnow", ",", "support", "vector", "machines", "and", "logistic", "regression", "."], "sentence-detokenized": "Other linear classification algorithms include Winnow, support vector machines and logistic regression.", "token2charspan": [[0, 5], [6, 12], [13, 27], [28, 38], [39, 46], [47, 53], [53, 54], [55, 62], [63, 69], [70, 78], [79, 82], [83, 91], [92, 102], [102, 103]]}
{"doc_key": "ai-test-319", "ner": [[0, 0, "product"], [4, 5, "programlang"], [15, 17, "product"], [19, 19, "programlang"], [13, 21, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 4, 5, "general-affiliation", "", true, false], [0, 0, 15, 17, "general-affiliation", "", true, false], [0, 0, 19, 19, "general-affiliation", "", true, false], [0, 0, 13, 21, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["VTK", "consists", "of", "a", "C", "++", "class", "library", "and", "several", "interpreted", "interface", "layers", ",", "including", "Tcl", "/", "Tk", ",", "Java", "and", "Python", "."], "sentence-detokenized": "VTK consists of a C++ class library and several interpreted interface layers, including Tcl / Tk, Java and Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 17], [18, 19], [19, 21], [22, 27], [28, 35], [36, 39], [40, 47], [48, 59], [60, 69], [70, 76], [76, 77], [78, 87], [88, 91], [92, 93], [94, 96], [96, 97], [98, 102], [103, 106], [107, 113], [113, 114]]}
{"doc_key": "ai-test-320", "ner": [[3, 8, "task"], [15, 19, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Text", "processed", "from", "spontaneous", "speech", "by", "automatic", "speech", "recognition", "or", "from", "printed", "or", "handwritten", "text", "by", "optical", "character", "recognition", "also", "contains", "processing", "noise", "."], "sentence-detokenized": "Text processed from spontaneous speech by automatic speech recognition or from printed or handwritten text by optical character recognition also contains processing noise.", "token2charspan": [[0, 4], [5, 14], [15, 19], [20, 31], [32, 38], [39, 41], [42, 51], [52, 58], [59, 70], [71, 73], [74, 78], [79, 86], [87, 89], [90, 101], [102, 106], [107, 109], [110, 117], [118, 127], [128, 139], [140, 144], [145, 153], [154, 164], [165, 170], [170, 171]]}
{"doc_key": "ai-test-321", "ner": [[0, 0, "researcher"], [8, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 8, 9, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "wrote", "several", "books", "and", "led", "the", "development", "of", "WordNet", ",", "an", "online", "word", "-", "linkage", "database", "for", "use", "in", "computer", "programmes", "."], "sentence-detokenized": "Miller wrote several books and led the development of WordNet, an online word-linkage database for use in computer programmes.", "token2charspan": [[0, 6], [7, 12], [13, 20], [21, 26], [27, 30], [31, 34], [35, 38], [39, 50], [51, 53], [54, 61], [61, 62], [63, 65], [66, 72], [73, 77], [77, 78], [78, 85], [86, 94], [95, 98], [99, 102], [103, 105], [106, 114], [115, 125], [125, 126]]}
{"doc_key": "ai-test-322", "ner": [[1, 4, "field"], [5, 9, "organisation"], [10, 10, "country"], [12, 12, "person"], [15, 17, "person"], [19, 20, "person"], [22, 25, "person"], [26, 26, "country"], [28, 32, "location"], [36, 36, "misc"], [33, 35, "person"], [38, 40, "person"], [41, 42, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[5, 9, 10, 10, "physical", "", false, false], [12, 12, 26, 26, "physical", "", false, false], [15, 17, 26, 26, "physical", "", false, false], [19, 20, 26, 26, "physical", "", false, false], [22, 25, 26, 26, "physical", "", false, false], [28, 32, 1, 4, "general-affiliation", "", false, false], [28, 32, 33, 35, "artifact", "", false, false], [36, 36, 33, 35, "named", "", false, false], [38, 40, 41, 42, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Contemporary", "automata", "are", "represented", "by", "Cabaret", "Mechanical", "Theatre", "in", "the", "UK", ",", "Dug", "North", "and", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", "and", "Joe", "Jones", "in", "the", "USA", ",", "Le", "D\u00e9fenseur", "du", "Temps", "by", "Jacques", "Monestier", "in", "France", "and", "Fran\u00e7ois", "Junod", "from", "Switzerland", "are", "represented", "."], "sentence-detokenized": "Contemporary automata are represented by Cabaret Mechanical Theatre in the UK, Dug North and Chomick + Meder, Arthur Ganson and Joe Jones in the USA, Le D\u00e9fenseur du Temps by Jacques Monestier in France and Fran\u00e7ois Junod from Switzerland are represented.", "token2charspan": [[0, 12], [13, 21], [22, 25], [26, 37], [38, 40], [41, 48], [49, 59], [60, 67], [68, 70], [71, 74], [75, 77], [77, 78], [79, 82], [83, 88], [89, 92], [93, 100], [101, 102], [103, 108], [108, 109], [110, 116], [117, 123], [124, 127], [128, 131], [132, 137], [138, 140], [141, 144], [145, 148], [148, 149], [150, 152], [153, 162], [163, 165], [166, 171], [172, 174], [175, 182], [183, 192], [193, 195], [196, 202], [203, 206], [207, 215], [216, 221], [222, 226], [227, 238], [239, 242], [243, 254], [254, 255]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [18, 20, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 18, 20, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "has", "standard", "codefor", "/", "code", "and", "codewhile", "/", "code", "loops", ",", "but", "(", "like", "other", "similar", "applications", "such", "as", "R", ")", "it", "is", "recommended", "to", "use", "vectorised", "notation", ",", "which", "is", "often", "faster", "to", "execute", "."], "sentence-detokenized": "MATLAB has standard codefor / code and codewhile / code loops, but (like other similar applications such as R) it is recommended to use vectorised notation, which is often faster to execute.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 27], [28, 29], [30, 34], [35, 38], [39, 48], [49, 50], [51, 55], [56, 61], [61, 62], [63, 66], [67, 68], [68, 72], [73, 78], [79, 86], [87, 99], [100, 104], [105, 107], [108, 109], [109, 110], [111, 113], [114, 116], [117, 128], [129, 131], [132, 135], [136, 146], [147, 155], [155, 156], [157, 162], [163, 165], [166, 171], [172, 178], [179, 181], [182, 189], [189, 190]]}
{"doc_key": "ai-test-324", "ner": [[0, 4, "researcher"], [5, 10, "conference"], [14, 17, "field"], [19, 27, "misc"], [32, 41, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 19, 27, "win-defeat", "", false, false], [0, 4, 32, 41, "win-defeat", "", false, false], [19, 27, 5, 10, "temporal", "", false, false], [19, 27, 14, 17, "topic", "", false, false], [32, 41, 5, 10, "temporal", "", false, false], [32, 41, 14, 17, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pausch", "received", "two", "awards", "from", "the", "Association", "for", "Computing", "Machinery", "in", "2007", "for", "his", "achievements", "in", "computer", "education", ":", "the", "'", "Karl", "V", ".", "Karlstrom", "Outstanding", "Educator", "Award", "'", "and", "the", "'", "ACM", "SIGCSE", "Award", "for", "Outstanding", "Contributions", "to", "Computer", "Science", "Education", "'", "from", "the", "Association", "for", "Computing", "Machinery", "."], "sentence-detokenized": "Pausch received two awards from the Association for Computing Machinery in 2007 for his achievements in computer education: the 'Karl V. Karlstrom Outstanding Educator Award' and the 'ACM SIGCSE Award for Outstanding Contributions to Computer Science Education' from the Association for Computing Machinery.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 26], [27, 31], [32, 35], [36, 47], [48, 51], [52, 61], [62, 71], [72, 74], [75, 79], [80, 83], [84, 87], [88, 100], [101, 103], [104, 112], [113, 122], [122, 123], [124, 127], [128, 129], [129, 133], [134, 135], [135, 136], [137, 146], [147, 158], [159, 167], [168, 173], [173, 174], [175, 178], [179, 182], [183, 184], [184, 187], [188, 194], [195, 200], [201, 204], [205, 216], [217, 230], [231, 233], [234, 242], [243, 250], [251, 260], [260, 261], [262, 266], [267, 270], [271, 282], [283, 286], [287, 296], [297, 306], [306, 307]]}
{"doc_key": "ai-test-325", "ner": [[3, 4, "person"], [8, 10, "product"], [15, 17, "organisation"]], "ner_mapping_to_source": [0, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1960", ",", "Mr", "Debord", "personally", "sold", "the", "first", "Unimate", "robot", "and", "shipped", "it", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, Mr Debord personally sold the first Unimate robot and shipped it to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 18], [19, 29], [30, 34], [35, 38], [39, 44], [45, 52], [53, 58], [59, 62], [63, 70], [71, 73], [74, 76], [77, 84], [85, 91], [92, 94], [95, 99], [99, 100]]}
{"doc_key": "ai-test-326", "ner": [[0, 2, "algorithm"], [5, 7, "field"], [9, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 12, 0, 2, "usage", "", false, false], [9, 12, 5, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Semantic", "networks", "are", "used", "in", "natural", "language", "processing", "applications", "such", "as", "semantic", "analysis", "."], "sentence-detokenized": "Semantic networks are used in natural language processing applications such as semantic analysis.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 26], [27, 29], [30, 37], [38, 46], [47, 57], [58, 70], [71, 75], [76, 78], [79, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-test-327", "ner": [[3, 5, "field"], [6, 6, "field"], [9, 10, "task"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 24, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[6, 6, 3, 5, "usage", "", false, false], [9, 10, 3, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Successful", "examples", "of", "deep", "learning", "include", "computer", "vision", "and", "speech", "recognition", ".", "Hongluck", "Lee", ",", "Roger", "Grosse", ",", "Rajesh", "Ranganath", "and", "Andrew", "Y", ".", "Ng", "."], "sentence-detokenized": "Successful examples of deep learning include computer vision and speech recognition. Hongluck Lee, Roger Grosse, Rajesh Ranganath and Andrew Y. Ng.", "token2charspan": [[0, 10], [11, 19], [20, 22], [23, 27], [28, 36], [37, 44], [45, 53], [54, 60], [61, 64], [65, 71], [72, 83], [83, 84], [85, 93], [94, 97], [97, 98], [99, 104], [105, 111], [111, 112], [113, 119], [120, 129], [130, 133], [134, 140], [141, 142], [142, 143], [144, 146], [146, 147]]}
{"doc_key": "ai-test-328", "ner": [[4, 8, "product"], [14, 14, "misc"], [17, 17, "misc"], [23, 25, "product"], [29, 30, "task"], [32, 33, "task"], [35, 36, "task"], [38, 40, "field"], [42, 43, "task"], [45, 46, "field"], [48, 49, "task"], [51, 52, "task"], [54, 55, "task"], [27, 57, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 8, 14, 14, "physical", "travels_to", false, false], [4, 8, 17, 17, "physical", "travels_to", false, false], [23, 25, 4, 8, "part-of", "", false, false], [23, 25, 4, 8, "role", "maintains", false, false], [23, 25, 29, 30, "related-to", "has_ability_to", false, false], [23, 25, 32, 33, "related-to", "has_ability_to", false, false], [23, 25, 35, 36, "related-to", "has_ability_to", false, false], [23, 25, 38, 40, "related-to", "has_ability_to", false, false], [23, 25, 42, 43, "related-to", "has_ability_to", false, false], [23, 25, 45, 46, "related-to", "has_ability_to", false, false], [23, 25, 48, 49, "related-to", "has_ability_to", false, false], [23, 25, 51, 52, "related-to", "has_ability_to", false, false], [23, 25, 54, 55, "related-to", "has_ability_to", false, false], [23, 25, 27, 57, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["In", "addition", "to", "maintaining", "the", "Discovery", "One", "spacecraft", "systems", "during", "the", "interplanetary", "mission", "to", "Jupiter", "(", "or", "Saturn", "in", "the", "novel", ")", ",", "HAL", "has", "the", "ability", "to", "perform", "speech", "synthesis", ",", "voice", "recognition", ",", "facial", "recognition", ",", "natural", "language", "processing", ",", "lip", "reading", ",", "art", "appreciation", ",", "emotional", "computing", ",", "automatic", "reasoning", ",", "spacecraft", "piloting", "and", "chess", "."], "sentence-detokenized": "In addition to maintaining the Discovery One spacecraft systems during the interplanetary mission to Jupiter (or Saturn in the novel), HAL has the ability to perform speech synthesis, voice recognition, facial recognition, natural language processing, lip reading, art appreciation, emotional computing, automatic reasoning, spacecraft piloting and chess.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 40], [41, 44], [45, 55], [56, 63], [64, 70], [71, 74], [75, 89], [90, 97], [98, 100], [101, 108], [109, 110], [110, 112], [113, 119], [120, 122], [123, 126], [127, 132], [132, 133], [133, 134], [135, 138], [139, 142], [143, 146], [147, 154], [155, 157], [158, 165], [166, 172], [173, 182], [182, 183], [184, 189], [190, 201], [201, 202], [203, 209], [210, 221], [221, 222], [223, 230], [231, 239], [240, 250], [250, 251], [252, 255], [256, 263], [263, 264], [265, 268], [269, 281], [281, 282], [283, 292], [293, 302], [302, 303], [304, 313], [314, 323], [323, 324], [325, 335], [336, 344], [345, 348], [349, 354], [354, 355]]}
{"doc_key": "ai-test-329", "ner": [[0, 1, "researcher"], [1, 9, "country"], [12, 15, "country"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[0, 1, 1, 9, "physical", "", false, false], [0, 1, 12, 15, "cause-effect", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["Dr", "Jules", "emigrated", "from", "Hungary", "to", "the", "USA", "following", "the", "invasion", "of", "the", "Soviet", "Union", "in", "1956", "."], "sentence-detokenized": "Dr Jules emigrated from Hungary to the USA following the invasion of the Soviet Union in 1956.", "token2charspan": [[0, 2], [3, 8], [9, 18], [19, 23], [24, 31], [32, 34], [35, 38], [39, 42], [43, 52], [53, 56], [57, 65], [66, 68], [69, 72], [73, 79], [80, 85], [86, 88], [89, 93], [93, 94]]}
{"doc_key": "ai-test-330", "ner": [[0, 2, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sigmoid", "function", "activation", "function", "uses", "a", "second", "nonlinearity", "for", "large", "inputs", ":", "math", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+\\", "exp", "(", "-", "v", "_", "i", ")", ")", "^", "{", "-1", "}", "/", "math", "."], "sentence-detokenized": "The sigmoid function activation function uses a second nonlinearity for large inputs: math phi (v _ i) = (1 +\\ exp (-v _ i))^ {-1} / math.", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 31], [32, 40], [41, 45], [46, 47], [48, 54], [55, 67], [68, 71], [72, 77], [78, 84], [84, 85], [86, 90], [91, 94], [95, 96], [96, 97], [98, 99], [100, 101], [101, 102], [103, 104], [105, 106], [106, 107], [108, 110], [111, 114], [115, 116], [116, 117], [117, 118], [119, 120], [121, 122], [122, 123], [123, 124], [124, 125], [126, 127], [127, 129], [129, 130], [131, 132], [133, 137], [137, 138]]}
{"doc_key": "ai-test-331", "ner": [[6, 11, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Based", "on", "this", "probability", ",", "the", "maximum", "likelihood", "decision", "is", "used", "to", "determine", "what", "the", "target", "is", "."], "sentence-detokenized": "Based on this probability, the maximum likelihood decision is used to determine what the target is.", "token2charspan": [[0, 5], [6, 8], [9, 13], [14, 25], [25, 26], [27, 30], [31, 38], [39, 49], [50, 58], [59, 61], [62, 66], [67, 69], [70, 79], [80, 84], [85, 88], [89, 95], [96, 98], [98, 99]]}
{"doc_key": "ai-test-332", "ner": [[2, 4, "university"], [0, 10, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Moved", "to", "Konstanz", "University", "in", "1984", "and", "to", "Salzburg", "University", "in", "1990", "."], "sentence-detokenized": "Moved to Konstanz University in 1984 and to Salzburg University in 1990.", "token2charspan": [[0, 5], [6, 8], [9, 17], [18, 28], [29, 31], [32, 36], [37, 40], [41, 43], [44, 52], [53, 63], [64, 66], [67, 71], [71, 72]]}
{"doc_key": "ai-test-333", "ner": [[4, 7, "metrics"], [8, 10, "metrics"], [12, 14, "metrics"], [16, 16, "metrics"], [18, 19, "metrics"], [21, 23, "metrics"], [25, 28, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[8, 10, 4, 7, "origin", "based_on", false, false], [12, 14, 4, 7, "origin", "based_on", false, false], [16, 16, 4, 7, "origin", "based_on", false, false], [18, 19, 4, 7, "origin", "based_on", false, false], [21, 23, 4, 7, "origin", "based_on", false, false], [25, 28, 4, 7, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Typical", "fitness", "functions", "based", "on", "confusion", "matrices", "include", "sensitivity", "/", "specificity", ",", "repeatability", "/", "precision", ",", "F-measure", ",", "Jaccard", "similarity", ",", "Matthews", "correlation", "coefficient", "and", "cost", "/", "gain", "matrices", "that", "combine", "the", "costs", "and", "gains", "assigned", "to", "the", "four", "categories", "."], "sentence-detokenized": "Typical fitness functions based on confusion matrices include sensitivity/specificity, repeatability/precision, F-measure, Jaccard similarity, Matthews correlation coefficient and cost/gain matrices that combine the costs and gains assigned to the four categories.", "token2charspan": [[0, 7], [8, 15], [16, 25], [26, 31], [32, 34], [35, 44], [45, 53], [54, 61], [62, 73], [73, 74], [74, 85], [85, 86], [87, 100], [100, 101], [101, 110], [110, 111], [112, 121], [121, 122], [123, 130], [131, 141], [141, 142], [143, 151], [152, 163], [164, 175], [176, 179], [180, 184], [184, 185], [185, 189], [190, 198], [199, 203], [204, 211], [212, 215], [216, 221], [222, 225], [226, 231], [232, 240], [241, 243], [244, 247], [248, 252], [253, 263], [263, 264]]}
{"doc_key": "ai-test-334", "ner": [[6, 6, "product"], [8, 8, "product"], [10, 10, "product"], [12, 12, "product"], [4, 17, "programlang"], [23, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[23, 29, 6, 6, "part-of", "", false, false], [23, 29, 8, 8, "part-of", "", false, false], [23, 29, 10, 10, "part-of", "", false, false], [23, 29, 12, 12, "part-of", "", false, false], [23, 29, 4, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Common", "numerical", "programming", "environments", "such", "as", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", "and", "the", "R", "language", "provide", "simpler", "feature", "extraction", "techniques", "(", "such", "as", "principal", "component", "analysis", ")", "with", "built", "-", "in", "commands", "."], "sentence-detokenized": "Common numerical programming environments such as MATLAB, SciLab, NumPy, Sklearn and the R language provide simpler feature extraction techniques (such as principal component analysis) with built-in commands.", "token2charspan": [[0, 6], [7, 16], [17, 28], [29, 41], [42, 46], [47, 49], [50, 56], [56, 57], [58, 64], [64, 65], [66, 71], [71, 72], [73, 80], [81, 84], [85, 88], [89, 90], [91, 99], [100, 107], [108, 115], [116, 123], [124, 134], [135, 145], [146, 147], [147, 151], [152, 154], [155, 164], [165, 174], [175, 183], [183, 184], [185, 189], [190, 195], [195, 196], [196, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-test-335", "ner": [[0, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Industrial", "robots", "are", "introduced", "to", "work", "with", "humans", "to", "perform", "industrial", "production", "tasks", "."], "sentence-detokenized": "Industrial robots are introduced to work with humans to perform industrial production tasks.", "token2charspan": [[0, 10], [11, 17], [18, 21], [22, 32], [33, 35], [36, 40], [41, 45], [46, 52], [53, 55], [56, 63], [64, 74], [75, 85], [86, 91], [91, 92]]}
{"doc_key": "ai-test-336", "ner": [[13, 13, "field"], [0, 6, "researcher"], [22, 23, "field"], [25, 26, "field"], [15, 29, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 13, 22, 23, "related-to", "", false, false], [13, 13, 25, 26, "related-to", "", false, false], [13, 13, 15, 29, "related-to", "", false, false], [0, 6, 13, 13, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "F", ".", "Sowa", ",", "in", "his", "first", "paper", "on", "CG", ",", "applied", "CG", "to", "a", "wide", "range", "of", "fields", ",", "including", "artificial", "intelligence", ",", "computer", "science", "and", "cognitive", "science", "."], "sentence-detokenized": "John F. Sowa, in his first paper on CG, applied CG to a wide range of fields, including artificial intelligence, computer science and cognitive science.", "token2charspan": [[0, 4], [5, 6], [6, 7], [8, 12], [12, 13], [14, 16], [17, 20], [21, 26], [27, 32], [33, 35], [36, 38], [38, 39], [40, 47], [48, 50], [51, 53], [54, 55], [56, 60], [61, 66], [67, 69], [70, 76], [76, 77], [78, 87], [88, 98], [99, 111], [111, 112], [113, 121], [122, 129], [130, 133], [134, 143], [144, 151], [151, 152]]}
{"doc_key": "ai-test-337", "ner": [[0, 0, "metrics"], [2, 6, "metrics"], [10, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 2, 6, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "BLEU", "in", "the", "way", "it", "calculates", "the", "conciseness", "penalty", ",", "in", "that", "some", "variation", "in", "translation", "length", "does", "not", "affect", "the", "overall", "score", "as", "much", "."], "sentence-detokenized": "NIST also differs from BLEU in the way it calculates the conciseness penalty, in that some variation in translation length does not affect the overall score as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 38], [39, 41], [42, 52], [53, 56], [57, 68], [69, 76], [76, 77], [78, 80], [81, 85], [86, 90], [91, 100], [101, 103], [104, 115], [116, 122], [123, 127], [128, 131], [132, 138], [139, 142], [143, 150], [151, 156], [157, 159], [160, 164], [164, 165]]}
{"doc_key": "ai-test-338", "ner": [[0, 5, "misc"], [13, 13, "conference"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 5, 13, 13, "temporal", "", false, false], [0, 5, 23, 24, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "IJCAI", "Award", "for", "Research", "Excellence", "is", "awarded", "twice", "a", "year", "at", "the", "IJCAI", "conference", "to", "recognise", "the", "outstanding", "achievements", "of", "researchers", "in", "artificial", "intelligence", "."], "sentence-detokenized": "The IJCAI Award for Research Excellence is awarded twice a year at the IJCAI conference to recognise the outstanding achievements of researchers in artificial intelligence.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 19], [20, 28], [29, 39], [40, 42], [43, 50], [51, 56], [57, 58], [59, 63], [64, 66], [67, 70], [71, 76], [77, 87], [88, 90], [91, 100], [101, 104], [105, 116], [117, 129], [130, 132], [133, 144], [145, 147], [148, 158], [159, 171], [171, 172]]}
{"doc_key": "ai-test-339", "ner": [[0, 1, "researcher"], [9, 9, "conference"], [18, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 9, 9, "role", "", false, false], [0, 1, 18, 28, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lennart", "was", "one", "of", "the", "first", "Fellows", "of", "the", "AAAI", "and", "is", "the", "only", "person", "who", "is", "a", "member", "of", "the", "Scientific", "Advisory", "Boards", "of", "both", "Microsoft", "and", "Apple", "."], "sentence-detokenized": "Lennart was one of the first Fellows of the AAAI and is the only person who is a member of the Scientific Advisory Boards of both Microsoft and Apple.", "token2charspan": [[0, 7], [8, 11], [12, 15], [16, 18], [19, 22], [23, 28], [29, 36], [37, 39], [40, 43], [44, 48], [49, 52], [53, 55], [56, 59], [60, 64], [65, 71], [72, 75], [76, 78], [79, 80], [81, 87], [88, 90], [91, 94], [95, 105], [106, 114], [115, 121], [122, 124], [125, 129], [130, 139], [140, 143], [144, 149], [149, 150]]}
{"doc_key": "ai-test-340", "ner": [[0, 0, "algorithm"], [5, 6, "misc"], [8, 11, "metrics"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 6, "related-to", "minimise", false, false], [8, 11, 5, 6, "type-of", "", false, false], [14, 15, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autoencoders", "are", "trained", "to", "minimise", "reconstruction", "errors", "(", "e.g.", "mean", "squared", "errors", ")", ",", "called", "losses", "."], "sentence-detokenized": "Autoencoders are trained to minimise reconstruction errors (e.g. mean squared errors), called losses.", "token2charspan": [[0, 12], [13, 16], [17, 24], [25, 27], [28, 36], [37, 51], [52, 58], [59, 60], [60, 64], [65, 69], [70, 77], [78, 84], [84, 85], [85, 86], [87, 93], [94, 100], [100, 101]]}
{"doc_key": "ai-test-341", "ner": [[21, 27, "misc"], [30, 31, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[30, 31, 21, 27, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "alternative", "to", "using", "definitions", "is", "to", "consider", "general", "word", "sense", "associations", "and", "calculate", "the", "similarity", "of", "each", "word", "sense", "pair", "based", "on", "a", "given", "lexical", "knowledge", "base", ",", "such", "as", "WordNet", "."], "sentence-detokenized": "An alternative to using definitions is to consider general word sense associations and calculate the similarity of each word sense pair based on a given lexical knowledge base, such as WordNet.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 23], [24, 35], [36, 38], [39, 41], [42, 50], [51, 58], [59, 63], [64, 69], [70, 82], [83, 86], [87, 96], [97, 100], [101, 111], [112, 114], [115, 119], [120, 124], [125, 130], [131, 135], [136, 141], [142, 144], [145, 146], [147, 152], [153, 160], [161, 170], [171, 175], [175, 176], [177, 181], [182, 184], [185, 192], [192, 193]]}
{"doc_key": "ai-test-342", "ner": [[0, 4, "algorithm"], [8, 11, "researcher"], [18, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 8, 11, "origin", "", false, false], [8, 11, 18, 20, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD", "-", "Lambda", "is", "a", "learning", "algorithm", "devised", "by", "Richard", "S.", "Sutton", ",", "based", "on", "early", "work", "by", "Arthur", "Samuel", "on", "temporal", "difference", "learning", "."], "sentence-detokenized": "TD-Lambda is a learning algorithm devised by Richard S. Sutton, based on early work by Arthur Samuel on temporal difference learning.", "token2charspan": [[0, 2], [2, 3], [3, 9], [10, 12], [13, 14], [15, 23], [24, 33], [34, 41], [42, 44], [45, 52], [53, 55], [56, 62], [62, 63], [64, 69], [70, 72], [73, 78], [79, 83], [84, 86], [87, 93], [94, 100], [101, 103], [104, 112], [113, 123], [124, 132], [132, 133]]}
{"doc_key": "ai-test-343", "ner": [[0, 1, "field"], [4, 4, "field"], [6, 7, "task"], [9, 19, "task"], [20, 21, "task"]], "ner_mapping_to_source": [0, 1, 2, 4, 5], "relations": [[6, 7, 0, 1, "part-of", "task_part_of_field", false, false], [6, 7, 4, 4, "part-of", "task_part_of_field", false, false], [9, 19, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 3], "sentence": ["In", "data", "mining", "and", "statistics", ",", "hierarchical", "clustering", "(", "also", "known", "as", "hierarchical", "cluster", "analysis", "or", "HCA", ")", "is", "a", "cluster", "analysis", "technique", "that", "attempts", "to", "build", "a", "hierarchical", "structure", "of", "clusters", "."], "sentence-detokenized": "In data mining and statistics, hierarchical clustering (also known as hierarchical cluster analysis or HCA) is a cluster analysis technique that attempts to build a hierarchical structure of clusters.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 18], [19, 29], [29, 30], [31, 43], [44, 54], [55, 56], [56, 60], [61, 66], [67, 69], [70, 82], [83, 90], [91, 99], [100, 102], [103, 106], [106, 107], [108, 110], [111, 112], [113, 120], [121, 129], [130, 139], [140, 144], [145, 153], [154, 156], [157, 162], [163, 164], [165, 177], [178, 187], [188, 190], [191, 199], [199, 200]]}
{"doc_key": "ai-test-344", "ner": [[2, 3, "algorithm"], [8, 8, "field"], [10, 11, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 8, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "concept", "of", "deconvolution", "is", "widely", "used", "in", "signal", "and", "image", "processing", "techniques", "."], "sentence-detokenized": "The concept of deconvolution is widely used in signal and image processing techniques.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 28], [29, 31], [32, 38], [39, 43], [44, 46], [47, 53], [54, 57], [58, 63], [64, 74], [75, 85], [85, 86]]}
{"doc_key": "ai-test-345", "ner": [[0, 1, "algorithm"], [17, 19, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 17, 19, "related-to", "enhances", false, false], [0, 1, 17, 19, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cognitive", "maps", "help", "build", "and", "store", "spatial", "knowledge", "and", "visualise", "images", "with", "the", "mind", "'s", "eye", ",", "reducing", "cognitive", "load", "and", "facilitating", "information", "recall", "and", "learning", "."], "sentence-detokenized": "Cognitive maps help build and store spatial knowledge and visualise images with the mind's eye, reducing cognitive load and facilitating information recall and learning.", "token2charspan": [[0, 9], [10, 14], [15, 19], [20, 25], [26, 29], [30, 35], [36, 43], [44, 53], [54, 57], [58, 67], [68, 74], [75, 79], [80, 83], [84, 88], [88, 90], [91, 94], [94, 95], [96, 104], [105, 114], [115, 119], [120, 123], [124, 136], [137, 148], [149, 155], [156, 159], [160, 168], [168, 169]]}
{"doc_key": "ai-test-346", "ner": [[11, 11, "programlang"], [8, 16, "programlang"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "It", "is", "common", "to", "provide", "bindings", "to", "languages", "such", "as", "Python", ",", "C", "++", "and", "Java", ")", "."], "sentence-detokenized": "(It is common to provide bindings to languages such as Python, C++ and Java).", "token2charspan": [[0, 1], [1, 3], [4, 6], [7, 13], [14, 16], [17, 24], [25, 33], [34, 36], [37, 46], [47, 51], [52, 54], [55, 61], [61, 62], [63, 64], [64, 66], [67, 70], [71, 75], [75, 76], [76, 77]]}
{"doc_key": "ai-test-347", "ner": [[0, 2, "product"], [3, 4, "product"], [16, 17, "task"], [18, 23, "task"], [27, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 16, 17, "usage", "", false, false], [0, 2, 18, 23, "usage", "", false, false], [0, 2, 27, 30, "usage", "", false, false], [3, 4, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Voice", "User", "Interfaces", "(", "VUIs", ")", "enable", "spoken", "dialogue", "between", "humans", "and", "computers", "by", "using", "speech", "recognition", "to", "understand", "spoken", "commands", "and", "question", "responses", ",", "usually", "by", "converting", "text", "to", "speech", "and", "playing", "back", "the", "response", "."], "sentence-detokenized": "Voice User Interfaces (VUIs) enable spoken dialogue between humans and computers by using speech recognition to understand spoken commands and question responses, usually by converting text to speech and playing back the response.", "token2charspan": [[0, 5], [6, 10], [11, 21], [22, 23], [23, 27], [27, 28], [29, 35], [36, 42], [43, 51], [52, 59], [60, 66], [67, 70], [71, 80], [81, 83], [84, 89], [90, 96], [97, 108], [109, 111], [112, 122], [123, 129], [130, 138], [139, 142], [143, 151], [152, 161], [161, 162], [163, 170], [171, 173], [174, 184], [185, 189], [190, 192], [193, 199], [200, 203], [204, 211], [212, 216], [217, 220], [221, 229], [229, 230]]}
{"doc_key": "ai-test-348", "ner": [[3, 5, "misc"], [7, 7, "programlang"], [10, 15, "researcher"], [16, 17, "organisation"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[10, 15, 16, 17, "role", "", false, false]], "relations_mapping_to_source": [3], "sentence": ["Jess", "is", "a", "rules", "engine", "for", "the", "Java", "platform", "developed", "by", "Ernest", "Friedman", "-", "Hill", "of", "Sandia", "National", "."], "sentence-detokenized": "Jess is a rules engine for the Java platform developed by Ernest Friedman-Hill of Sandia National.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 15], [16, 22], [23, 26], [27, 30], [31, 35], [36, 44], [45, 54], [55, 57], [58, 64], [65, 73], [73, 74], [74, 78], [79, 81], [82, 88], [89, 97], [97, 98]]}
{"doc_key": "ai-test-349", "ner": [[0, 3, "algorithm"], [12, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 12, 14, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "multi-layer", "perceptrons", "where", "hidden", "layers", "are", "present", ",", "more", "advanced", "algorithms", "such", "as", "backpropagation", "need", "to", "be", "used", "."], "sentence-detokenized": "For multi-layer perceptrons where hidden layers are present, more advanced algorithms such as backpropagation need to be used.", "token2charspan": [[0, 3], [4, 15], [16, 27], [28, 33], [34, 40], [41, 47], [48, 51], [52, 59], [59, 60], [61, 65], [66, 74], [75, 85], [86, 90], [91, 93], [94, 109], [110, 114], [115, 117], [118, 120], [121, 125], [125, 126]]}
{"doc_key": "ai-test-350", "ner": [[0, 0, "product"], [3, 6, "product"], [10, 18, "algorithm"], [22, 23, "field"], [28, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 0, 0, "part-of", "", false, false], [3, 6, 10, 18, "usage", "", false, true], [10, 18, 22, 23, "related-to", "performs", false, false], [28, 35, 22, 23, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Google", "Translate", "'s", "neural", "machine", "translation", "system", "uses", "a", "large", "end", "-", "to", "-", "end", "artificial", "neural", "network", "that", "attempts", "to", "perform", "deep", "learning", ",", "in", "particular", "a", "long", "-", "term", "short", "-", "term", "memory", "network", "."], "sentence-detokenized": "Google Translate's neural machine translation system uses a large end-to-end artificial neural network that attempts to perform deep learning, in particular a long-term short-term memory network.", "token2charspan": [[0, 6], [7, 16], [16, 18], [19, 25], [26, 33], [34, 45], [46, 52], [53, 57], [58, 59], [60, 65], [66, 69], [69, 70], [70, 72], [72, 73], [73, 76], [77, 87], [88, 94], [95, 102], [103, 107], [108, 116], [117, 119], [120, 127], [128, 132], [133, 141], [141, 142], [143, 145], [146, 156], [157, 158], [159, 163], [163, 164], [164, 168], [169, 174], [174, 175], [175, 179], [180, 186], [187, 194], [194, 195]]}
{"doc_key": "ai-test-351", "ner": [[8, 8, "researcher"], [10, 10, "researcher"], [12, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"], [20, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Various", "methods", "for", "this", "purpose", "were", "developed", "by", "Werbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", "and", "Pearlmutter", "in", "the", "1980s", "and", "early", "1990s", "."], "sentence-detokenized": "Various methods for this purpose were developed by Werbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter and Pearlmutter in the 1980s and early 1990s.", "token2charspan": [[0, 7], [8, 15], [16, 19], [20, 24], [25, 32], [33, 37], [38, 47], [48, 50], [51, 57], [57, 58], [59, 67], [67, 68], [69, 77], [77, 78], [79, 85], [86, 97], [97, 98], [99, 103], [104, 114], [115, 118], [119, 130], [131, 133], [134, 137], [138, 143], [144, 147], [148, 153], [154, 159], [159, 160]]}
{"doc_key": "ai-test-352", "ner": [[1, 1, "organisation"], [2, 3, "organisation"], [8, 11, "organisation"], [15, 17, "task"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 8, 11, "role", "licenses_from", false, false], [2, 3, 1, 1, "named", "", false, false], [12, 12, 1, 1, "origin", "", false, false], [12, 12, 15, 17, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["|", "Apple", "Apple", "Inc.", "originally", "licensed", "software", "from", "Nuance", "to", "give", "its", "Siri", "digital", "assistant", "speech", "recognition", "capabilities", "."], "sentence-detokenized": "| Apple Apple Inc. originally licensed software from Nuance to give its Siri digital assistant speech recognition capabilities.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 18], [19, 29], [30, 38], [39, 47], [48, 52], [53, 59], [60, 62], [63, 67], [68, 71], [72, 76], [77, 84], [85, 94], [95, 101], [102, 113], [114, 126], [126, 127]]}
{"doc_key": "ai-test-353", "ner": [[0, 0, "organisation"], [2, 4, "misc"], [6, 8, "person"], [10, 13, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 2, 4, "role", "releases_movies_in_genre", false, false], [6, 8, 0, 0, "role", "directs_for", false, false], [10, 13, 0, 0, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "released", "several", "3D", "westerns", "produced", "by", "Sam", "Katzman", "and", "directed", "by", "William", "Castle", "."], "sentence-detokenized": "Columbia released several 3D westerns produced by Sam Katzman and directed by William Castle.", "token2charspan": [[0, 8], [9, 17], [18, 25], [26, 28], [29, 37], [38, 46], [47, 49], [50, 53], [54, 61], [62, 65], [66, 74], [75, 77], [78, 85], [86, 92], [92, 93]]}
{"doc_key": "ai-test-354", "ner": [[9, 10, "field"], [12, 12, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "incorporates", "knowledge", "and", "research", "from", "the", "fields", "of", "computer", "science", ",", "linguistics", "and", "computer", "engineering", "."], "sentence-detokenized": "It incorporates knowledge and research from the fields of computer science, linguistics and computer engineering.", "token2charspan": [[0, 2], [3, 15], [16, 25], [26, 29], [30, 38], [39, 43], [44, 47], [48, 54], [55, 57], [58, 66], [67, 74], [74, 75], [76, 87], [88, 91], [92, 100], [101, 112], [112, 113]]}
{"doc_key": "ai-test-355", "ner": [[0, 7, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "is", "an", "example", "of", "an", "R", "code", "."], "sentence-detokenized": "The following is an example of an R code.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 19], [20, 27], [28, 30], [31, 33], [34, 35], [36, 40], [40, 41]]}
{"doc_key": "ai-test-356", "ner": [[0, 2, "metrics"], [11, 11, "metrics"], [14, 18, "metrics"]], "ner_mapping_to_source": [0, 2, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["ROC", "curves", "are", "produced", "by", "plotting", "the", "true", "positive", "rate", "(", "TPR", ")", "and", "false", "positive", "rate", "(", "FPR", ")", "at", "various", "threshold", "settings", "."], "sentence-detokenized": "ROC curves are produced by plotting the true positive rate (TPR) and false positive rate (FPR) at various threshold settings.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 26], [27, 35], [36, 39], [40, 44], [45, 53], [54, 58], [59, 60], [60, 63], [63, 64], [65, 68], [69, 74], [75, 83], [84, 88], [89, 90], [90, 93], [93, 94], [95, 97], [98, 105], [106, 115], [116, 124], [124, 125]]}
{"doc_key": "ai-test-357", "ner": [[0, 3, "field"], [6, 6, "researcher"], [9, 10, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 0, 3, "related-to", "researches_field", false, false], [9, 10, 0, 3, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["After", "the", "machine", "learning", "work", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", ",", "research", "stagnated", "."], "sentence-detokenized": "After the machine learning work by Marvin Minsky and Seymour Papert (1969), research stagnated.", "token2charspan": [[0, 5], [6, 9], [10, 17], [18, 26], [27, 31], [32, 34], [35, 41], [42, 48], [49, 52], [53, 60], [61, 67], [68, 69], [69, 73], [73, 74], [74, 75], [76, 84], [85, 94], [94, 95]]}
{"doc_key": "ai-test-358", "ner": [[23, 23, "task"], [5, 6, "programlang"], [8, 10, "product"], [13, 14, "programlang"], [16, 17, "product"], [3, 19, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[23, 23, 5, 6, "related-to", "used_to_build", false, false], [23, 23, 8, 10, "related-to", "used_to_build", false, false], [23, 23, 13, 14, "related-to", "used_to_build", false, false], [23, 23, 16, 17, "related-to", "used_to_build", false, false], [23, 23, 3, 19, "related-to", "used_to_build", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "programming", "environments", "such", "as", "Ladder", "Logic", ",", "Visual", "C", "+", "+", ",", "Visual", "Basic", ",", "LabVIEW", "and", "MATLAB", "are", "used", "to", "build", "DAQ", "applications", "."], "sentence-detokenized": "Other programming environments such as Ladder Logic, Visual C + +, Visual Basic, LabVIEW and MATLAB are used to build DAQ applications.", "token2charspan": [[0, 5], [6, 17], [18, 30], [31, 35], [36, 38], [39, 45], [46, 51], [51, 52], [53, 59], [60, 61], [62, 63], [64, 65], [65, 66], [67, 73], [74, 79], [79, 80], [81, 88], [89, 92], [93, 99], [100, 103], [104, 108], [109, 111], [112, 117], [118, 121], [122, 134], [134, 135]]}
{"doc_key": "ai-test-359", "ner": [[11, 12, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "indicator", "was", "designed", "to", "correct", "problems", "with", "the", "more", "common", "BLEU", "indicator", "and", "to", "obtain", "a", "good", "correlation", "with", "human", "judgements", "at", "the", "sentence", "or", "segment", "level", "."], "sentence-detokenized": "This indicator was designed to correct problems with the more common BLEU indicator and to obtain a good correlation with human judgements at the sentence or segment level.", "token2charspan": [[0, 4], [5, 14], [15, 18], [19, 27], [28, 30], [31, 38], [39, 47], [48, 52], [53, 56], [57, 61], [62, 68], [69, 73], [74, 83], [84, 87], [88, 90], [91, 97], [98, 99], [100, 104], [105, 116], [117, 121], [122, 127], [128, 138], [139, 141], [142, 145], [146, 154], [155, 157], [158, 165], [166, 171], [171, 172]]}
{"doc_key": "ai-test-360", "ner": [[12, 14, "algorithm"], [16, 18, "algorithm"], [9, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["To", "exploit", "semantic", "correlations", "between", "consecutive", "video", "frames", ",", "techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "-", "term", "short", "-", "term", "memory", "are", "often", "employed", "."], "sentence-detokenized": "To exploit semantic correlations between consecutive video frames, techniques such as dynamic Markov networks, convolutional neural networks and long-term short-term memory are often employed.", "token2charspan": [[0, 2], [3, 10], [11, 19], [20, 32], [33, 40], [41, 52], [53, 58], [59, 65], [65, 66], [67, 77], [78, 82], [83, 85], [86, 93], [94, 100], [101, 109], [109, 110], [111, 124], [125, 131], [132, 140], [141, 144], [145, 149], [149, 150], [150, 154], [155, 160], [160, 161], [161, 165], [166, 172], [173, 176], [177, 182], [183, 191], [191, 192]]}
{"doc_key": "ai-test-361", "ner": [[4, 4, "product"], [5, 7, "product"], [8, 13, "product"], [15, 15, "product"], [32, 35, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 8, 13, "artifact", "", false, false], [4, 4, 32, 35, "named", "", false, false], [5, 7, 4, 4, "named", "", false, false], [15, 15, 8, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Most", "mass", "production", "of", "printed", "circuit", "boards", "involves", "pick", "-", "and", "-", "place", "robots", "(", "SCARA", "manipulators", ")", "that", "remove", "small", "electronic", "components", "from", "strips", "or", "trays", "and", "precisely", "fit", "them", "onto", "the", "printed", "circuit", "board", "."], "sentence-detokenized": "Most mass production of printed circuit boards involves pick-and-place robots (SCARA manipulators) that remove small electronic components from strips or trays and precisely fit them onto the printed circuit board.", "token2charspan": [[0, 4], [5, 9], [10, 20], [21, 23], [24, 31], [32, 39], [40, 46], [47, 55], [56, 60], [60, 61], [61, 64], [64, 65], [65, 70], [71, 77], [78, 79], [79, 84], [85, 97], [97, 98], [99, 103], [104, 110], [111, 116], [117, 127], [128, 138], [139, 143], [144, 150], [151, 153], [154, 159], [160, 163], [164, 173], [174, 177], [178, 182], [183, 187], [188, 191], [192, 199], [200, 207], [208, 213], [213, 214]]}
{"doc_key": "ai-test-362", "ner": [[6, 7, "field"], [0, 2, "algorithm"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 23, "researcher"], [25, 29, "algorithm"], [30, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 6, 7, "part-of", "", false, false], [0, 2, 13, 14, "origin", "", false, false], [0, 2, 16, 17, "origin", "", false, false], [0, 2, 19, 23, "origin", "", false, false], [0, 2, 25, 29, "type-of", "", false, false], [25, 29, 30, 31, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["LDA", "is", "the", "most", "widely", "applied", "machine", "learning", "today", ",", "originally", "rediscovered", "by", "David", "Blei", ",", "Andrew", "Ng", "and", "Michael", "I", ".", "Jordan", "in", "2003", "as", "a", "graphical", "model", "for", "topic", "exploration", "."], "sentence-detokenized": "LDA is the most widely applied machine learning today, originally rediscovered by David Blei, Andrew Ng and Michael I. Jordan in 2003 as a graphical model for topic exploration.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 15], [16, 22], [23, 30], [31, 38], [39, 47], [48, 53], [53, 54], [55, 65], [66, 78], [79, 81], [82, 87], [88, 92], [92, 93], [94, 100], [101, 103], [104, 107], [108, 115], [116, 117], [117, 118], [119, 125], [126, 128], [129, 133], [134, 136], [137, 138], [139, 148], [149, 154], [155, 158], [159, 164], [165, 176], [176, 177]]}
{"doc_key": "ai-test-363", "ner": [[5, 6, "task"], [8, 8, "misc"], [17, 17, "metrics"], [19, 19, "metrics"], [21, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 8, 8, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "performance", "of", "eight", "na\u00efve", "WSIs", "for", "various", "tauopathies", "on", "the", "test", "data", "was", "measured", ",", "with", "repeatability", ",", "accuracy", "and", "F1", "scores", "of", "0.92", ",", "0.72", "and", "0.81", ",", "respectively", "."], "sentence-detokenized": "The performance of eight na\u00efve WSIs for various tauopathies on the test data was measured, with repeatability, accuracy and F1 scores of 0.92, 0.72 and 0.81, respectively.", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 24], [25, 30], [31, 35], [36, 39], [40, 47], [48, 59], [60, 62], [63, 66], [67, 71], [72, 76], [77, 80], [81, 89], [89, 90], [91, 95], [96, 109], [109, 110], [111, 119], [120, 123], [124, 126], [127, 133], [134, 136], [137, 141], [141, 142], [143, 147], [148, 151], [152, 156], [156, 157], [158, 170], [170, 171]]}
{"doc_key": "ai-test-364", "ner": [[1, 1, "field"], [8, 10, "field"], [12, 12, "field"], [4, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 12, 12, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Advanced", "AR", "technologies", "(", "such", "as", "the", "addition", "of", "computer", "vision", ",", "AR", "cameras", "on", "smartphones", ",", "object", "recognition", ",", "etc.", ")", "will", "allow", "real", "-world", "information", "around", "the", "user", "to", "be", "interactively", "and", "digitally", "manipulated", "."], "sentence-detokenized": "Advanced AR technologies (such as the addition of computer vision, AR cameras on smartphones, object recognition, etc.) will allow real-world information around the user to be interactively and digitally manipulated.", "token2charspan": [[0, 8], [9, 11], [12, 24], [25, 26], [26, 30], [31, 33], [34, 37], [38, 46], [47, 49], [50, 58], [59, 65], [65, 66], [67, 69], [70, 77], [78, 80], [81, 92], [92, 93], [94, 100], [101, 112], [112, 113], [114, 118], [118, 119], [120, 124], [125, 130], [131, 135], [135, 141], [142, 153], [154, 160], [161, 164], [165, 169], [170, 172], [173, 175], [176, 189], [190, 193], [194, 203], [204, 215], [215, 216]]}
{"doc_key": "ai-test-365", "ner": [[3, 3, "researcher"], [4, 7, "organisation"], [14, 16, "field"], [25, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 4, 7, "role", "forms_company", false, false], [4, 7, 14, 16, "related-to", "works_with", false, false], [4, 7, 25, 27, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2014", ",", "Schmidhuber", "founded", "Nisense", ",", "a", "company", "working", "on", "commercial", "applications", "of", "artificial", "intelligence", "in", "areas", "such", "as", "finance", ",", "heavy", "industry", "and", "self", "-", "driving", "cars", "."], "sentence-detokenized": "In 2014, Schmidhuber founded Nisense, a company working on commercial applications of artificial intelligence in areas such as finance, heavy industry and self-driving cars.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 28], [29, 36], [36, 37], [38, 39], [40, 47], [48, 55], [56, 58], [59, 69], [70, 82], [83, 85], [86, 96], [97, 109], [110, 112], [113, 118], [119, 123], [124, 126], [127, 134], [134, 135], [136, 141], [142, 150], [151, 154], [155, 159], [159, 160], [160, 167], [168, 172], [172, 173]]}
{"doc_key": "ai-test-366", "ner": [[6, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "can", "lead", "to", "bias", "and", "mean", "squared", "errors", "in", "estimation", "as", "well", "as", "altering", "the", "performance", "of", "all", "subsequent", "tests", "on", "the", "retained", "explanatory", "model", "."], "sentence-detokenized": "This can lead to bias and mean squared errors in estimation as well as altering the performance of all subsequent tests on the retained explanatory model.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 21], [22, 25], [26, 30], [31, 38], [39, 45], [46, 48], [49, 59], [60, 62], [63, 67], [68, 70], [71, 79], [80, 83], [84, 95], [96, 98], [99, 102], [103, 113], [114, 119], [120, 122], [123, 126], [127, 135], [136, 147], [148, 153], [153, 154]]}
{"doc_key": "ai-test-367", "ner": [[0, 3, "misc"], [6, 6, "algorithm"], [9, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 0, 3, "usage", "", false, false], [6, 6, 9, 10, "topic", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Bigrams", "are", "used", "in", "many", "successful", "language", "models", "for", "speech", "recognition", "."], "sentence-detokenized": "Bigrams are used in many successful language models for speech recognition.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 19], [20, 24], [25, 35], [36, 44], [45, 51], [52, 55], [56, 62], [63, 74], [74, 75]]}
{"doc_key": "ai-test-368", "ner": [[4, 5, "field"], [11, 14, "misc"], [24, 26, "misc"], [16, 18, "organisation"], [32, 35, "misc"], [36, 40, "organisation"], [46, 48, "misc"], [54, 61, "misc"], [58, 61, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 8, 9], "relations": [[11, 14, 4, 5, "topic", "", false, false], [24, 26, 16, 18, "origin", "", false, false], [32, 35, 36, 40, "origin", "", false, false], [54, 61, 58, 61, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4], "sentence": ["For", "his", "work", "in", "cognitive", "psychology", ",", "he", "has", "received", "the", "Early", "Career", "Award", "from", "the", "American", "Psychological", "Association", "(", "1984", ")", ",", "the", "Boyd", "McCandless", "Award", "(", "1986", ")", ",", "the", "Troland", "Research", "Award", "from", "the", "National", "Academy", "of", "Sciences", "(", "1993", ")", ",", "the", "Henry", "Dale", "Prize", "(", "2004", ")", "and", "the", "George", "Miller", "Award", "from", "the", "Cognitive", "Neuroscience", "Society", "(", "2010", ")", "."], "sentence-detokenized": "For his work in cognitive psychology, he has received the Early Career Award from the American Psychological Association (1984), the Boyd McCandless Award (1986), the Troland Research Award from the National Academy of Sciences (1993), the Henry Dale Prize (2004) and the George Miller Award from the Cognitive Neuroscience Society (2010).", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 15], [16, 25], [26, 36], [36, 37], [38, 40], [41, 44], [45, 53], [54, 57], [58, 63], [64, 70], [71, 76], [77, 81], [82, 85], [86, 94], [95, 108], [109, 120], [121, 122], [122, 126], [126, 127], [127, 128], [129, 132], [133, 137], [138, 148], [149, 154], [155, 156], [156, 160], [160, 161], [161, 162], [163, 166], [167, 174], [175, 183], [184, 189], [190, 194], [195, 198], [199, 207], [208, 215], [216, 218], [219, 227], [228, 229], [229, 233], [233, 234], [234, 235], [236, 239], [240, 245], [246, 250], [251, 256], [257, 258], [258, 262], [262, 263], [264, 267], [268, 271], [272, 278], [279, 285], [286, 291], [292, 296], [297, 300], [301, 310], [311, 323], [324, 331], [332, 333], [333, 337], [337, 338], [338, 339]]}
{"doc_key": "ai-test-369", "ner": [[0, 0, "misc"], [3, 7, "misc"], [8, 9, "product"], [14, 14, "researcher"], [16, 16, "researcher"], [26, 26, "researcher"], [23, 25, "task"], [32, 35, "researcher"], [29, 41, "researcher"], [42, 43, "task"], [45, 45, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11], "relations": [[0, 0, 3, 7, "named", "", false, false], [0, 0, 45, 45, "named", "", false, false], [3, 7, 14, 14, "origin", "", false, false], [3, 7, 16, 16, "origin", "", false, false], [3, 7, 23, 25, "related-to", "used_for", false, false], [8, 9, 3, 7, "usage", "", false, false], [8, 9, 42, 43, "named", "", false, false], [26, 26, 3, 7, "usage", "", false, false], [26, 26, 32, 35, "named", "same", false, false], [42, 43, 45, 45, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 11], "sentence": ["Eigenfaces", "(", "a", "method", "for", "using", "eigenfaces", "in", "face", "recognition", "systems", "was", "developed", "by", "Sirovich", "and", "Kirby", "(", "1987", ")", "and", "used", "for", "face", "classification", "by", "Matthew", "Turk", "and", "Alex", "Pentland", ";", "Turk", ",", "Matthew", "A", "and", "Pentland", ",", "Alex", "P", ".", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "Eigenfaces (a method for using eigenfaces in face recognition systems was developed by Sirovich and Kirby (1987) and used for face classification by Matthew Turk and Alex Pentland; Turk, Matthew A and Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 10], [11, 12], [12, 13], [14, 20], [21, 24], [25, 30], [31, 41], [42, 44], [45, 49], [50, 61], [62, 69], [70, 73], [74, 83], [84, 86], [87, 95], [96, 99], [100, 105], [106, 107], [107, 111], [111, 112], [113, 116], [117, 121], [122, 125], [126, 130], [131, 145], [146, 148], [149, 156], [157, 161], [162, 165], [166, 170], [171, 179], [179, 180], [181, 185], [185, 186], [187, 194], [195, 196], [197, 200], [201, 209], [209, 210], [211, 215], [216, 217], [217, 218], [219, 223], [224, 235], [236, 241], [242, 252], [252, 253]]}
{"doc_key": "ai-test-370", "ner": [[3, 11, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "context", "can", "then", "be", "understood", "using", "lexical", "dictionaries", "such", "as", "WordNet", "."], "sentence-detokenized": "The context can then be understood using lexical dictionaries such as WordNet.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 20], [21, 23], [24, 34], [35, 40], [41, 48], [49, 61], [62, 66], [67, 69], [70, 77], [77, 78]]}
{"doc_key": "ai-test-371", "ner": [[0, 0, "misc"], [8, 8, "misc"], [13, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 8, "part-of", "", false, false], [8, 8, 13, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hyponymy", "is", "the", "most", "frequently", "encoded", "relationship", "between", "synsets", "used", "in", "lexical", "databases", "such", "as", "WordNet", "."], "sentence-detokenized": "Hyponymy is the most frequently encoded relationship between synsets used in lexical databases such as WordNet.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 20], [21, 31], [32, 39], [40, 52], [53, 60], [61, 68], [69, 73], [74, 76], [77, 84], [85, 94], [95, 99], [100, 102], [103, 110], [110, 111]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [6, 7, "programlang"], [9, 9, "programlang"], [39, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 7, "general-affiliation", "", false, false], [0, 0, 9, 9, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "provides", "open", "source", "libraries", "in", "C", "++", "and", "Java", ",", "but", "many", "clients", "rely", "on", "community", "-", "developed", "libraries", ",", "such", "as", "a", "library", "that", "incorporates", "the", "ability", "to", "retrieve", "data", "(", "in", "array", "format", ")", "from", "the", "DAP", "server", "."], "sentence-detokenized": "OPeNDAP provides open source libraries in C++ and Java, but many clients rely on community-developed libraries, such as a library that incorporates the ability to retrieve data (in array format) from the DAP server.", "token2charspan": [[0, 7], [8, 16], [17, 21], [22, 28], [29, 38], [39, 41], [42, 43], [43, 45], [46, 49], [50, 54], [54, 55], [56, 59], [60, 64], [65, 72], [73, 77], [78, 80], [81, 90], [90, 91], [91, 100], [101, 110], [110, 111], [112, 116], [117, 119], [120, 121], [122, 129], [130, 134], [135, 147], [148, 151], [152, 159], [160, 162], [163, 171], [172, 176], [177, 178], [178, 180], [181, 186], [187, 193], [193, 194], [195, 199], [200, 203], [204, 207], [208, 214], [214, 215]]}
{"doc_key": "ai-test-373", "ner": [[4, 5, "product"], [13, 13, "country"], [23, 25, "misc"], [44, 48, "product"]], "ner_mapping_to_source": [1, 2, 3, 7], "relations": [[4, 5, 13, 13, "artifact", "", false, false], [23, 25, 4, 5, "part-of", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["The", "page", "exaggerated", "the", "Senkosha", "as", "the", "product", "of", "four", "thousand", "years", "of", "Chinese", "scientific", "knowledge", ",", "commented", "on", "its", "crude", "design", ",", "including", "a", "cannon", "in", "the", "crotch", ",", "and", "placed", "images", "of", "it", "alongside", "images", "of", "Honda", "'s", "ASIMO", "and", "Sony", "'s", "QRIO", "SDR", "-", "3", "X", "."], "sentence-detokenized": "The page exaggerated the Senkosha as the product of four thousand years of Chinese scientific knowledge, commented on its crude design, including a cannon in the crotch, and placed images of it alongside images of Honda's ASIMO and Sony's QRIO SDR-3X.", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 24], [25, 33], [34, 36], [37, 40], [41, 48], [49, 51], [52, 56], [57, 65], [66, 71], [72, 74], [75, 82], [83, 93], [94, 103], [103, 104], [105, 114], [115, 117], [118, 121], [122, 127], [128, 134], [134, 135], [136, 145], [146, 147], [148, 154], [155, 157], [158, 161], [162, 168], [168, 169], [170, 173], [174, 180], [181, 187], [188, 190], [191, 193], [194, 203], [204, 210], [211, 213], [214, 219], [219, 221], [222, 227], [228, 231], [232, 236], [236, 238], [239, 243], [244, 247], [247, 248], [248, 249], [249, 250], [250, 251]]}
{"doc_key": "ai-test-374", "ner": [[10, 12, "algorithm"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 12, 21, 21, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["There", "are", "also", "a", "number", "of", "programming", "libraries", "that", "have", "neural", "network", "functionality", "and", "are", "available", "in", "custom", "implementations", "(", "e.g.", "TensorFlow", ",", "Theano", ")", "."], "sentence-detokenized": "There are also a number of programming libraries that have neural network functionality and are available in custom implementations (e.g. TensorFlow, Theano).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 16], [17, 23], [24, 26], [27, 38], [39, 48], [49, 53], [54, 58], [59, 65], [66, 73], [74, 87], [88, 91], [92, 95], [96, 105], [106, 108], [109, 115], [116, 131], [132, 133], [133, 137], [138, 148], [148, 149], [150, 156], [156, 157], [157, 158]]}
{"doc_key": "ai-test-375", "ner": [[6, 9, "conference"], [11, 11, "organisation"], [14, 19, "conference"], [21, 21, "conference"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", ",", "IEEE", ",", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "IAPR", "and", "SPIE", "."], "sentence-detokenized": "He is a member of the Association for Computing Machinery, IEEE, American Association for the Advancement of Science, IAPR and SPIE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 33], [34, 37], [38, 47], [48, 57], [57, 58], [59, 63], [63, 64], [65, 73], [74, 85], [86, 89], [90, 93], [94, 105], [106, 108], [109, 116], [116, 117], [118, 122], [123, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-test-376", "ner": [[4, 5, "organisation"], [7, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 7, 13, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "experiment", "conducted", "by", "RET", "in", "2011", "with", "facial", "recognition", "system", "cameras", "on", "trams", "ensured", "that", "people", "who", "were", "banned", "from", "trams", "did", "not", "sneak", "on", "anyway", "."], "sentence-detokenized": "An experiment conducted by RET in 2011 with facial recognition system cameras on trams ensured that people who were banned from trams did not sneak on anyway.", "token2charspan": [[0, 2], [3, 13], [14, 23], [24, 26], [27, 30], [31, 33], [34, 38], [39, 43], [44, 50], [51, 62], [63, 69], [70, 77], [78, 80], [81, 86], [87, 94], [95, 99], [100, 106], [107, 110], [111, 115], [116, 122], [123, 127], [128, 133], [134, 137], [138, 141], [142, 147], [148, 150], [151, 157], [157, 158]]}
{"doc_key": "ai-test-377", "ner": [[4, 6, "person"], [9, 9, "organisation"], [16, 16, "person"], [19, 22, "person"], [23, 24, "person"], [26, 27, "person"], [29, 30, "person"], [32, 33, "person"], [35, 36, "person"], [38, 40, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[4, 6, 9, 9, "role", "works_for", false, false], [16, 16, 9, 9, "role", "works_for", false, false], [19, 22, 9, 9, "role", "works_for", false, false], [23, 24, 9, 9, "role", "works_for", false, false], [26, 27, 9, 9, "role", "works_for", false, false], [29, 30, 9, 9, "role", "works_for", false, false], [32, 33, 9, 9, "role", "works_for", false, false], [35, 36, 9, 9, "role", "works_for", false, false], [38, 40, 9, 9, "role", "works_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "film", "adaptation", "of", "Cole", "Porter", "'s", "popular", "Broadway", "musical", "stars", "the", "MGM", "diva", "duo", "of", "Howard", "Keel", "and", "Kathryn", "Grayson", ",", "with", "Anne", "Miller", ",", "Keenan", "Wynne", ",", "Bobby", "Van", ",", "James", "Whitmore", ",", "Kurt", "Kazner", "and", "Tommy", "Lall", "in", "supporting", "roles", "."], "sentence-detokenized": "The film adaptation of Cole Porter's popular Broadway musical stars the MGM diva duo of Howard Keel and Kathryn Grayson, with Anne Miller, Keenan Wynne, Bobby Van, James Whitmore, Kurt Kazner and Tommy Lall in supporting roles.", "token2charspan": [[0, 3], [4, 8], [9, 19], [20, 22], [23, 27], [28, 34], [34, 36], [37, 44], [45, 53], [54, 61], [62, 67], [68, 71], [72, 75], [76, 80], [81, 84], [85, 87], [88, 94], [95, 99], [100, 103], [104, 111], [112, 119], [119, 120], [121, 125], [126, 130], [131, 137], [137, 138], [139, 145], [146, 151], [151, 152], [153, 158], [159, 162], [162, 163], [164, 169], [170, 178], [178, 179], [180, 184], [185, 191], [192, 195], [196, 201], [202, 206], [207, 209], [210, 220], [221, 226], [226, 227]]}
{"doc_key": "ai-test-378", "ner": [[17, 20, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "applications", "need", "to", "streamline", "call", "flows", ",", "minimise", "prompting", ",", "eliminate", "unnecessary", "repetition", "and", "enable", "elaborate", "mixed", "-initiative", "dialogue", "systems", "(", "where", "callers", "can", "enter", "multiple", "pieces", "of", "information", "in", "a", "single", "utterance", ",", "in", "any", "order", "or", "combination", ")", "."], "sentence-detokenized": "Such applications need to streamline call flows, minimise prompting, eliminate unnecessary repetition and enable elaborate mixed-initiative dialogue systems (where callers can enter multiple pieces of information in a single utterance, in any order or combination).", "token2charspan": [[0, 4], [5, 17], [18, 22], [23, 25], [26, 36], [37, 41], [42, 47], [47, 48], [49, 57], [58, 67], [67, 68], [69, 78], [79, 90], [91, 101], [102, 105], [106, 112], [113, 122], [123, 128], [128, 139], [140, 148], [149, 156], [157, 158], [158, 163], [164, 171], [172, 175], [176, 181], [182, 190], [191, 197], [198, 200], [201, 212], [213, 215], [216, 217], [218, 224], [225, 234], [234, 235], [236, 238], [239, 242], [243, 248], [249, 251], [252, 263], [263, 264], [264, 265]]}
{"doc_key": "ai-test-379", "ner": [[3, 4, "algorithm"], [7, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 11, 3, 4, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Therefore", ",", "conventional", "gradient", "descent", "(", "or", "stochastic", "gradient", "descent", ")", "methods", "can", "be", "applied", ",", "stepping", "in", "the", "direction", "of", "the", "vector", "selected", "from", "the", "subgradient", "of", "the", "function", ",", "rather", "than", "stepping", "in", "the", "direction", "of", "the", "gradient", "of", "the", "function", "."], "sentence-detokenized": "Therefore, conventional gradient descent (or stochastic gradient descent) methods can be applied, stepping in the direction of the vector selected from the subgradient of the function, rather than stepping in the direction of the gradient of the function.", "token2charspan": [[0, 9], [9, 10], [11, 23], [24, 32], [33, 40], [41, 42], [42, 44], [45, 55], [56, 64], [65, 72], [72, 73], [74, 81], [82, 85], [86, 88], [89, 96], [96, 97], [98, 106], [107, 109], [110, 113], [114, 123], [124, 126], [127, 130], [131, 137], [138, 146], [147, 151], [152, 155], [156, 167], [168, 170], [171, 174], [175, 183], [183, 184], [185, 191], [192, 196], [197, 205], [206, 208], [209, 212], [213, 222], [223, 225], [226, 229], [230, 238], [239, 241], [242, 245], [246, 254], [254, 255]]}
{"doc_key": "ai-test-380", "ner": [[6, 10, "metrics"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Assuming", "that", "distortion", "is", "measured", "in", "terms", "of", "mean", "squared", "error", ",", "the", "distortion", "D", ",", "is", "given", "by"], "sentence-detokenized": "Assuming that distortion is measured in terms of mean squared error, the distortion D, is given by", "token2charspan": [[0, 8], [9, 13], [14, 24], [25, 27], [28, 36], [37, 39], [40, 45], [46, 48], [49, 53], [54, 61], [62, 67], [67, 68], [69, 72], [73, 83], [84, 85], [85, 86], [87, 89], [90, 95], [96, 98]]}
{"doc_key": "ai-test-381", "ner": [[0, 2, "field"], [18, 19, "task"], [21, 22, "task"], [24, 25, "task"], [15, 29, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "machine", "learning", "solution", "that", "became", "popular", "in", "the", "1980s", "and", "has", "applications", "in", "areas", "as", "diverse", "as", "speech", "recognition", ",", "image", "recognition", ",", "machine", "translation", "software", "and", "neural", "networks", "."], "sentence-detokenized": "A machine learning solution that became popular in the 1980s and has applications in areas as diverse as speech recognition, image recognition, machine translation software and neural networks.", "token2charspan": [[0, 1], [2, 9], [10, 18], [19, 27], [28, 32], [33, 39], [40, 47], [48, 50], [51, 54], [55, 60], [61, 64], [65, 68], [69, 81], [82, 84], [85, 90], [91, 93], [94, 101], [102, 104], [105, 111], [112, 123], [123, 124], [125, 130], [131, 142], [142, 143], [144, 151], [152, 163], [164, 172], [173, 176], [177, 183], [184, 192], [192, 193]]}
{"doc_key": "ai-test-382", "ner": [[0, 0, "misc"], [3, 6, "university"], [12, 14, "researcher"]], "ner_mapping_to_source": [1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["D.", "at", "the", "University", "of", "Toronto", "in", "1979", "under", "the", "supervision", "of", "C.", "Raymond", "Perrault", "."], "sentence-detokenized": "D. at the University of Toronto in 1979 under the supervision of C. Raymond Perrault.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 20], [21, 23], [24, 31], [32, 34], [35, 39], [40, 45], [46, 49], [50, 61], [62, 64], [65, 67], [68, 75], [76, 84], [84, 85]]}
{"doc_key": "ai-test-383", "ner": [[0, 0, "product"], [5, 7, "field"], [10, 10, "product"], [12, 12, "product"], [14, 14, "product"], [19, 19, "product"], [8, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 5, 7, "related-to", "supports", false, false], [10, 10, 5, 7, "type-of", "", true, false], [12, 12, 5, 7, "type-of", "", true, false], [14, 14, 5, 7, "type-of", "", true, false], [14, 14, 19, 19, "related-to", "converting_to", true, false], [8, 27, 5, 7, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["OpenCV", "supports", "several", "models", "from", "deep", "learning", "frameworks", "such", "as", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "after", "conversion", "to", "ONNX", "models", ")", "and", "Caffe", ",", "according", "to", "the", "definition", "of", "supported", "layers", "."], "sentence-detokenized": "OpenCV supports several models from deep learning frameworks such as TensorFlow, Torch, PyTorch (after conversion to ONNX models) and Caffe, according to the definition of supported layers.", "token2charspan": [[0, 6], [7, 15], [16, 23], [24, 30], [31, 35], [36, 40], [41, 49], [50, 60], [61, 65], [66, 68], [69, 79], [79, 80], [81, 86], [86, 87], [88, 95], [96, 97], [97, 102], [103, 113], [114, 116], [117, 121], [122, 128], [128, 129], [130, 133], [134, 139], [139, 140], [141, 150], [151, 153], [154, 157], [158, 168], [169, 171], [172, 181], [182, 188], [188, 189]]}
{"doc_key": "ai-test-384", "ner": [[0, 3, "researcher"], [9, 11, "organisation"], [8, 13, "organisation"], [19, 23, "organisation"], [16, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 9, 11, "role", "", false, false], [0, 3, 19, 23, "role", "", false, false], [0, 3, 16, 27, "related-to", "lectures_in", false, false], [8, 13, 9, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "is", "also", "the", "founding", "Chairman", "of", "the", "European", "Robotics", "Research", "Network", "(", "EURON", ")", "and", "has", "been", "an", "IEEE", "Robotics", "and", "Automation", "Society", "Distinguished", "Lecturer", "in", "Robotics", "."], "sentence-detokenized": "He is also the founding Chairman of the European Robotics Research Network (EURON) and has been an IEEE Robotics and Automation Society Distinguished Lecturer in Robotics.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 14], [15, 23], [24, 32], [33, 35], [36, 39], [40, 48], [49, 57], [58, 66], [67, 74], [75, 76], [76, 81], [81, 82], [83, 86], [87, 90], [91, 95], [96, 98], [99, 103], [104, 112], [113, 116], [117, 127], [128, 135], [136, 149], [150, 158], [159, 161], [162, 170], [170, 171]]}
{"doc_key": "ai-test-385", "ner": [[7, 9, "field"], [10, 11, "university"], [13, 13, "location"], [14, 20, "country"], [0, 25, "misc"], [26, 27, "field"], [28, 33, "organisation"], [34, 35, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 11, 13, 13, "physical", "", false, false], [13, 13, 14, 20, "physical", "", false, false], [0, 25, 26, 27, "topic", "", false, false], [28, 33, 34, 35, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "received", "a", "master", "'s", "degree", "in", "mathematics", "from", "Samarkand", "State", "University", "(", "Samarkand", ",", "Socialist", "Republic", "of", "Uzbekistan", ")", "in", "1958", "and", "a", "PhD", "in", "statistics", "from", "the", "Institute", "of", "Control", "Science", "in", "Moscow", "in", "1964", "."], "sentence-detokenized": "He received a master's degree in mathematics from Samarkand State University (Samarkand, Socialist Republic of Uzbekistan) in 1958 and a PhD in statistics from the Institute of Control Science in Moscow in 1964.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 20], [20, 22], [23, 29], [30, 32], [33, 44], [45, 49], [50, 59], [60, 65], [66, 76], [77, 78], [78, 87], [87, 88], [89, 98], [99, 107], [108, 110], [111, 121], [121, 122], [123, 125], [126, 130], [131, 134], [135, 136], [137, 140], [141, 143], [144, 154], [155, 159], [160, 163], [164, 173], [174, 176], [177, 184], [185, 192], [193, 195], [196, 202], [203, 205], [206, 210], [210, 211]]}
{"doc_key": "ai-test-386", "ner": [[2, 2, "organisation"], [8, 10, "product"], [25, 25, "field"], [24, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 25, 25, "usage", "", false, false], [2, 2, 24, 30, "usage", "", false, false], [8, 10, 2, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["However", ",", "Cycorp", "is", "increasingly", "working", "to", "enable", "Cyc", "systems", "to", "communicate", "with", "end-users", "in", "natural", "language", "and", "to", "support", "ongoing", "knowledge", "formation", "processes", "through", "machine", "learning", "and", "natural", "language", "understanding", "."], "sentence-detokenized": "However, Cycorp is increasingly working to enable Cyc systems to communicate with end-users in natural language and to support ongoing knowledge formation processes through machine learning and natural language understanding.", "token2charspan": [[0, 7], [7, 8], [9, 15], [16, 18], [19, 31], [32, 39], [40, 42], [43, 49], [50, 53], [54, 61], [62, 64], [65, 76], [77, 81], [82, 91], [92, 94], [95, 102], [103, 111], [112, 115], [116, 118], [119, 126], [127, 134], [135, 144], [145, 154], [155, 164], [165, 172], [173, 180], [181, 189], [190, 193], [194, 201], [202, 210], [211, 224], [224, 225]]}
{"doc_key": "ai-test-387", "ner": [[42, 42, "metrics"], [44, 44, "metrics"], [46, 46, "metrics"], [40, 49, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "when", "seeking", "the", "best", "classifier", "for", "a", "problem", ",", "candidate", "algorithms", "are", "trained", "on", "a", "training", "dataset", ",", "their", "performance", "is", "compared", "on", "a", "validation", "dataset", "to", "decide", "which", "one", "to", "take", ",", "and", "finally", "performance", "characteristics", "such", "as", "accuracy", ",", "sensitivity", ",", "specificity", "and", "F-", "measure", "are", "obtained", "on", "a", "test", "dataset", "."], "sentence-detokenized": "For example, when seeking the best classifier for a problem, candidate algorithms are trained on a training dataset, their performance is compared on a validation dataset to decide which one to take, and finally performance characteristics such as accuracy, sensitivity, specificity and F-measure are obtained on a test dataset.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [18, 25], [26, 29], [30, 34], [35, 45], [46, 49], [50, 51], [52, 59], [59, 60], [61, 70], [71, 81], [82, 85], [86, 93], [94, 96], [97, 98], [99, 107], [108, 115], [115, 116], [117, 122], [123, 134], [135, 137], [138, 146], [147, 149], [150, 151], [152, 162], [163, 170], [171, 173], [174, 180], [181, 186], [187, 190], [191, 193], [194, 198], [198, 199], [200, 203], [204, 211], [212, 223], [224, 239], [240, 244], [245, 247], [248, 256], [256, 257], [258, 269], [269, 270], [271, 282], [283, 286], [287, 289], [289, 296], [297, 300], [301, 309], [310, 312], [313, 314], [315, 319], [320, 327], [327, 328]]}
{"doc_key": "ai-test-388", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "squared", "error", "is", "0.15", "."], "sentence-detokenized": "The mean squared error is 0.15.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 25], [26, 30], [30, 31]]}
{"doc_key": "ai-test-389", "ner": [[7, 10, "misc"], [14, 14, "misc"]], "ner_mapping_to_source": [0, 2], "relations": [[14, 14, 7, 10, "topic", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["In", "1979", ",", "an", "IEEE", "-", "sponsored", "micromouse", "competition", "was", "organised", "and", "published", "in", "Spectrum", "."], "sentence-detokenized": "In 1979, an IEEE-sponsored micromouse competition was organised and published in Spectrum.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 16], [16, 17], [17, 26], [27, 37], [38, 49], [50, 53], [54, 63], [64, 67], [68, 77], [78, 80], [81, 89], [89, 90]]}
{"doc_key": "ai-test-390", "ner": [[0, 3, "algorithm"], [7, 9, "field"], [12, 14, "task"], [16, 17, "task"], [10, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 7, 9, "part-of", "", false, false], [12, 14, 7, 9, "part-of", "task_part_of_field", false, false], [16, 17, 7, 9, "part-of", "task_part_of_field", false, false], [10, 20, 7, 9, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Gabor", "space", "is", "very", "useful", "for", "image", "processing", "applications", "such", "as", "optical", "character", "recognition", ",", "iris", "recognition", "and", "fingerprint", "recognition", "."], "sentence-detokenized": "The Gabor space is very useful for image processing applications such as optical character recognition, iris recognition and fingerprint recognition.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 18], [19, 23], [24, 30], [31, 34], [35, 40], [41, 51], [52, 64], [65, 69], [70, 72], [73, 80], [81, 90], [91, 102], [102, 103], [104, 108], [109, 120], [121, 124], [125, 136], [137, 148], [148, 149]]}
{"doc_key": "ai-test-391", "ner": [[9, 9, "programlang"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Or", "through", "high", "-", "level", "interfaces", "in", "Java", "or", "Tcl", "."], "sentence-detokenized": "Or through high-level interfaces in Java or Tcl.", "token2charspan": [[0, 2], [3, 10], [11, 15], [15, 16], [16, 21], [22, 32], [33, 35], [36, 40], [41, 43], [44, 47], [47, 48]]}
{"doc_key": "ai-test-392", "ner": [[17, 17, "field"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Recent", "research", "has", "shown", "that", "kernel", "-", "based", "methods", "such", "as", "support", "vector", "machines", "perform", "well", "with", "supervision", "."], "sentence-detokenized": "Recent research has shown that kernel-based methods such as support vector machines perform well with supervision.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 25], [26, 30], [31, 37], [37, 38], [38, 43], [44, 51], [52, 56], [57, 59], [60, 67], [68, 74], [75, 83], [84, 91], [92, 96], [97, 101], [102, 113], [113, 114]]}
{"doc_key": "ai-test-393", "ner": [[23, 23, "researcher"], [25, 25, "researcher"], [33, 33, "programlang"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[23, 23, 33, 33, "usage", "", false, false], [25, 25, 33, 33, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["To", "illustrate", "the", "basic", "principles", "of", "bagging", ",", "an", "analysis", "of", "the", "relationship", "between", "ozone", "and", "temperature", "is", "presented", "below", "(", "data", "from", "Rousseeuw", "and", "Leroy", "(", "1986", ")", ",", "analysis", "performed", "in", "R", ")", "."], "sentence-detokenized": "To illustrate the basic principles of bagging, an analysis of the relationship between ozone and temperature is presented below (data from Rousseeuw and Leroy (1986), analysis performed in R).", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 23], [24, 34], [35, 37], [38, 45], [45, 46], [47, 49], [50, 58], [59, 61], [62, 65], [66, 78], [79, 86], [87, 92], [93, 96], [97, 108], [109, 111], [112, 121], [122, 127], [128, 129], [129, 133], [134, 138], [139, 148], [149, 152], [153, 158], [159, 160], [160, 164], [164, 165], [165, 166], [167, 175], [176, 185], [186, 188], [189, 190], [190, 191], [191, 192]]}
{"doc_key": "ai-test-394", "ner": [[0, 1, "organisation"], [11, 11, "product"], [18, 18, "product"], [21, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 0, 1, "artifact", "", false, false], [18, 18, 0, 1, "artifact", "", false, false], [21, 23, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Denso", "Wave", "is", "a", "subsidiary", "that", "produces", "automatic", "identification", "products", "(", "barcode", "readers", "and", "related", "products", ")", ",", "industrial", "robots", "and", "programmable", "logic", "controllers", "."], "sentence-detokenized": "Denso Wave is a subsidiary that produces automatic identification products (barcode readers and related products), industrial robots and programmable logic controllers.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 15], [16, 26], [27, 31], [32, 40], [41, 50], [51, 65], [66, 74], [75, 76], [76, 83], [84, 91], [92, 95], [96, 103], [104, 112], [112, 113], [113, 114], [115, 125], [126, 132], [133, 136], [137, 149], [150, 155], [156, 167], [167, 168]]}
{"doc_key": "ai-test-395", "ner": [[0, 4, "metrics"], [8, 10, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 19, 19, "compare", "", false, false], [8, 10, 0, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Whereas", "the", "Bilingual", "Evaluation", "understudy", "simply", "calculates", "the", "accuracy", "of", "the", "n-grams", "and", "gives", "each", "an", "equal", "weighting", ",", "NIST", "also", "calculates", "how", "informative", "a", "particular", "n-", "gram", "is", "."], "sentence-detokenized": "Whereas the Bilingual Evaluation understudy simply calculates the accuracy of the n-grams and gives each an equal weighting, NIST also calculates how informative a particular n-gram is.", "token2charspan": [[0, 7], [8, 11], [12, 21], [22, 32], [33, 43], [44, 50], [51, 61], [62, 65], [66, 74], [75, 77], [78, 81], [82, 89], [90, 93], [94, 99], [100, 104], [105, 107], [108, 113], [114, 123], [123, 124], [125, 129], [130, 134], [135, 145], [146, 149], [150, 161], [162, 163], [164, 174], [175, 177], [177, 181], [182, 184], [184, 185]]}
{"doc_key": "ai-test-396", "ner": [[11, 11, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "particular", ",", "it", "is", "used", "to", "calculate", "tree", "likelihoods", "(", "Bayesian", "and", "maximum", "likelihood", "methods", ")", "and", "to", "estimate", "evolutionary", "distances", "between", "sequences", "from", "differences", "between", "sequences", "."], "sentence-detokenized": "In particular, it is used to calculate tree likelihoods (Bayesian and maximum likelihood methods) and to estimate evolutionary distances between sequences from differences between sequences.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 17], [18, 20], [21, 25], [26, 28], [29, 38], [39, 43], [44, 55], [56, 57], [57, 65], [66, 69], [70, 77], [78, 88], [89, 96], [96, 97], [98, 101], [102, 104], [105, 113], [114, 126], [127, 136], [137, 144], [145, 154], [155, 159], [160, 171], [172, 179], [180, 189], [189, 190]]}
{"doc_key": "ai-test-397", "ner": [[0, 3, "conference"], [21, 21, "misc"], [36, 38, "misc"]], "ner_mapping_to_source": [0, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Audio", "Engineering", "Society", "recommends", "48", "kHz", "for", "most", "applications", ",", "but", "44.1", "kHz", "is", "acceptable", "for", "consumer", "applications", "such", "as", "CDs", ",", "32", "kHz", "for", "transmission", "-", "related", "applications", "and", "96", "kHz", "for", "widebanding", "and", "anti-aliasing", "filter", "relaxation", "."], "sentence-detokenized": "The Audio Engineering Society recommends 48 kHz for most applications, but 44.1 kHz is acceptable for consumer applications such as CDs, 32 kHz for transmission-related applications and 96 kHz for widebanding and anti-aliasing filter relaxation.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 29], [30, 40], [41, 43], [44, 47], [48, 51], [52, 56], [57, 69], [69, 70], [71, 74], [75, 79], [80, 83], [84, 86], [87, 97], [98, 101], [102, 110], [111, 123], [124, 128], [129, 131], [132, 135], [135, 136], [137, 139], [140, 143], [144, 147], [148, 160], [160, 161], [161, 168], [169, 181], [182, 185], [186, 188], [189, 192], [193, 196], [197, 208], [209, 212], [213, 226], [227, 233], [234, 244], [244, 245]]}
{"doc_key": "ai-test-398", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Resources", "on", "word", "and", "concept", "affectivity", "are", "available", "on", "WordNet", "{{", "cite", "journal"], "sentence-detokenized": "Resources on word and concept affectivity are available on WordNet{{cite journal", "token2charspan": [[0, 9], [10, 12], [13, 17], [18, 21], [22, 29], [30, 41], [42, 45], [46, 55], [56, 58], [59, 66], [66, 68], [68, 72], [73, 80]]}
{"doc_key": "ai-test-399", "ner": [[0, 4, "misc"], [10, 12, "person"], [14, 17, "person"], [22, 24, "person"], [30, 33, "organisation"], [44, 47, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 17, 22, 24, "role", "acts_in", false, false], [30, 33, 22, 24, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Red", "and", "green", "anaglyphs", "of", "countryside", ",", "test", "shots", "of", "Marie", "D'", "Oro", ",", "John", "B", ".", "Mason", "performing", "some", "passages", "from", "Jim", "the", "Penman", "(", "a", "film", "released", "by", "Famous", "Players", "Lasky", "that", "year", ",", "not", "in", "3D", ")", ",", "Oriental", "Dancers", ",", "Niagara", "Falls", ".", "A", "video", "reel", "and", "other", "footage", "was", "test", "-", "screened", "over", "three", "reels", "."], "sentence-detokenized": "Red and green anaglyphs of countryside, test shots of Marie D'Oro, John B. Mason performing some passages from Jim the Penman (a film released by Famous Players Lasky that year, not in 3D), Oriental Dancers, Niagara Falls. A video reel and other footage was test-screened over three reels.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 23], [24, 26], [27, 38], [38, 39], [40, 44], [45, 50], [51, 53], [54, 59], [60, 62], [62, 65], [65, 66], [67, 71], [72, 73], [73, 74], [75, 80], [81, 91], [92, 96], [97, 105], [106, 110], [111, 114], [115, 118], [119, 125], [126, 127], [127, 128], [129, 133], [134, 142], [143, 145], [146, 152], [153, 160], [161, 166], [167, 171], [172, 176], [176, 177], [178, 181], [182, 184], [185, 187], [187, 188], [188, 189], [190, 198], [199, 206], [206, 207], [208, 215], [216, 221], [221, 222], [223, 224], [225, 230], [231, 235], [236, 239], [240, 245], [246, 253], [254, 257], [258, 262], [262, 263], [263, 271], [272, 276], [277, 282], [283, 288], [288, 289]]}
{"doc_key": "ai-test-400", "ner": [[7, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "special", "way", "of", "implementing", "maximum", "likelihood", "estimation", "for", "this", "problem", "."], "sentence-detokenized": "This is a special way of implementing maximum likelihood estimation for this problem.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 17], [18, 21], [22, 24], [25, 37], [38, 45], [46, 56], [57, 67], [68, 71], [72, 76], [77, 84], [84, 85]]}
{"doc_key": "ai-test-401", "ner": [[0, 4, "product"], [8, 8, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "crawler-friendly", "web", "server", "that", "integrates", "sitemap", "and", "RSS", "feed", "functionality", ",", "a", "decentralised", "mechanism", "for", "computational", "biologists", "and", "bioinformaticians", "to", "openly", "disseminate", "and", "retrieve", "metadata", "about", "biomedical", "resources", "."], "sentence-detokenized": "A crawler-friendly web server that integrates sitemap and RSS feed functionality, a decentralised mechanism for computational biologists and bioinformaticians to openly disseminate and retrieve metadata about biomedical resources.", "token2charspan": [[0, 1], [2, 18], [19, 22], [23, 29], [30, 34], [35, 45], [46, 53], [54, 57], [58, 61], [62, 66], [67, 80], [80, 81], [82, 83], [84, 97], [98, 107], [108, 111], [112, 125], [126, 136], [137, 140], [141, 158], [159, 161], [162, 168], [169, 180], [181, 184], [185, 193], [194, 202], [203, 208], [209, 219], [220, 229], [229, 230]]}
{"doc_key": "ai-test-402", "ner": [[2, 9, "misc"], [11, 16, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Covered", "by", "American", "National", "Standards", "Institute", "/", "NISO", "Standard", "Z39.50", "and", "International", "Organisation", "for", "Standardisation", "Standard", "23950", "."], "sentence-detokenized": "Covered by American National Standards Institute/NISO Standard Z39.50 and International Organisation for Standardisation Standard 23950.", "token2charspan": [[0, 7], [8, 10], [11, 19], [20, 28], [29, 38], [39, 48], [48, 49], [49, 53], [54, 62], [63, 69], [70, 73], [74, 87], [88, 100], [101, 104], [105, 120], [121, 129], [130, 135], [135, 136]]}
{"doc_key": "ai-test-403", "ner": [[11, 17, "misc"], [21, 22, "metrics"], [22, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Encoders", "and", "decoders", "are", "trained", "to", "take", "a", "phrase", "and", "reproduce", "the", "one", "-", "shot", "distribution", "of", "the", "corresponding", "paraphrase", "by", "minimising", "perplexity", "using", "a", "simple", "stochastic", "gradient", "descent", "method", "."], "sentence-detokenized": "Encoders and decoders are trained to take a phrase and reproduce the one-shot distribution of the corresponding paraphrase by minimising perplexity using a simple stochastic gradient descent method.", "token2charspan": [[0, 8], [9, 12], [13, 21], [22, 25], [26, 33], [34, 36], [37, 41], [42, 43], [44, 50], [51, 54], [55, 64], [65, 68], [69, 72], [72, 73], [73, 77], [78, 90], [91, 93], [94, 97], [98, 111], [112, 122], [123, 125], [126, 136], [137, 147], [148, 153], [154, 155], [156, 162], [163, 173], [174, 182], [183, 190], [191, 197], [197, 198]]}
{"doc_key": "ai-test-404", "ner": [[3, 5, "field"], [6, 8, "task"], [10, 15, "task"], [25, 30, "task"], [32, 37, "task"], [39, 46, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 8, 3, 5, "part-of", "task_part_of_field", false, false], [10, 15, 3, 5, "part-of", "task_part_of_field", false, false], [25, 30, 3, 5, "part-of", "task_part_of_field", false, false], [32, 37, 3, 5, "part-of", "task_part_of_field", false, false], [39, 46, 3, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Typical", "applications", "of", "pattern", "recognition", "include", "automatic", "speech", "recognition", ",", "classification", "of", "text", "into", "multiple", "categories", "(", "e.g.", "spam", "/", "non", "-spam", "mail", ")", ",", "handwritten", "text", "recognition", "on", "postal", "envelopes", ",", "automatic", "recognition", "of", "human", "facial", "images", "and", "extraction", "of", "handwritten", "text", "images", "from", "medical", "forms", "."], "sentence-detokenized": "Typical applications of pattern recognition include automatic speech recognition, classification of text into multiple categories (e.g. spam/non-spam mail), handwritten text recognition on postal envelopes, automatic recognition of human facial images and extraction of handwritten text images from medical forms.", "token2charspan": [[0, 7], [8, 20], [21, 23], [24, 31], [32, 43], [44, 51], [52, 61], [62, 68], [69, 80], [80, 81], [82, 96], [97, 99], [100, 104], [105, 109], [110, 118], [119, 129], [130, 131], [131, 135], [136, 140], [140, 141], [141, 144], [144, 149], [150, 154], [154, 155], [155, 156], [157, 168], [169, 173], [174, 185], [186, 188], [189, 195], [196, 205], [205, 206], [207, 216], [217, 228], [229, 231], [232, 237], [238, 244], [245, 251], [252, 255], [256, 266], [267, 269], [270, 281], [282, 286], [287, 293], [294, 298], [299, 306], [307, 312], [312, 313]]}
{"doc_key": "ai-test-405", "ner": [[0, 3, "algorithm"], [12, 13, "field"], [15, 16, "task"], [18, 19, "task"], [21, 23, "task"], [25, 29, "task"], [11, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 13, 0, 3, "usage", "", false, false], [15, 16, 0, 3, "usage", "", false, false], [18, 19, 0, 3, "usage", "", false, false], [21, 23, 0, 3, "usage", "", false, false], [25, 29, 0, 3, "usage", "", false, false], [11, 32, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Artificial", "neural", "networks", "are", "used", "for", "a", "variety", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "board", "and", "video", "game", "playing", "and", "medical", "diagnosis", "."], "sentence-detokenized": "Artificial neural networks are used for a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, board and video game playing and medical diagnosis.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 30], [31, 35], [36, 39], [40, 41], [42, 49], [50, 52], [53, 58], [58, 59], [60, 69], [70, 78], [79, 85], [85, 86], [87, 93], [94, 105], [105, 106], [107, 114], [115, 126], [126, 127], [128, 134], [135, 142], [143, 152], [152, 153], [154, 159], [160, 163], [164, 169], [170, 174], [175, 182], [183, 186], [187, 194], [195, 204], [204, 205]]}
{"doc_key": "ai-test-406", "ner": [[0, 4, "organisation"], [5, 5, "product"], [13, 13, "product"], [17, 17, "organisation"], [18, 19, "product"], [21, 21, "product"], [23, 25, "product"], [27, 27, "product"], [29, 29, "programlang"], [34, 35, "field"], [41, 41, "product"], [45, 45, "algorithm"], [47, 47, "algorithm"], [49, 49, "algorithm"], [53, 53, "product"], [65, 66, "algorithm"], [70, 70, "product"], [72, 72, "product"], [74, 76, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19], "relations": [[5, 5, 0, 4, "origin", "", false, false], [5, 5, 13, 13, "named", "same", false, false], [5, 5, 41, 41, "named", "same", false, false], [29, 29, 34, 35, "related-to", "used_for", false, false], [45, 45, 29, 29, "part-of", "", true, false], [45, 45, 41, 41, "origin", "", true, false], [47, 47, 29, 29, "part-of", "", true, false], [47, 47, 41, 41, "origin", "", true, false], [49, 49, 29, 29, "part-of", "", true, false], [49, 49, 41, 41, "origin", "", true, false], [65, 66, 53, 53, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11], "sentence": ["For", "example", ",", "Salford", "Systems", "CART", "(", "licensed", "proprietary", "code", "from", "the", "original", "CART", "authors", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "an", "open", "source", "statistical", "computing", "software", "environment", ",", "including", "multiple", "CART", "implementations", "such", "as", "rpart", ",", "party", "and", "randomForest", "packages", ")", ",", "Weka", "(", "free", "and", "open", "source", "data", "mining", "suite", ",", "including", "numerous", "decision", "tree", "algorithms", ")", ",", "Orange", ",", "KNIME", "and", "Microsoft", "SQL", "Server", "programming", "language", ")", ",", "among", "others", "."], "sentence-detokenized": "For example, Salford Systems CART (licensed proprietary code from the original CART authors), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (an open source statistical computing software environment, including multiple CART implementations such as rpart, party and randomForest packages), Weka (free and open source data mining suite, including numerous decision tree algorithms), Orange, KNIME and Microsoft SQL Server programming language), among others.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 20], [21, 28], [29, 33], [34, 35], [35, 43], [44, 55], [56, 60], [61, 65], [66, 69], [70, 78], [79, 83], [84, 91], [91, 92], [92, 93], [94, 97], [98, 102], [103, 110], [110, 111], [112, 122], [122, 123], [124, 127], [128, 138], [139, 144], [144, 145], [146, 152], [152, 153], [154, 155], [156, 157], [157, 159], [160, 164], [165, 171], [172, 183], [184, 193], [194, 202], [203, 214], [214, 215], [216, 225], [226, 234], [235, 239], [240, 255], [256, 260], [261, 263], [264, 269], [269, 270], [271, 276], [277, 280], [281, 293], [294, 302], [302, 303], [303, 304], [305, 309], [310, 311], [311, 315], [316, 319], [320, 324], [325, 331], [332, 336], [337, 343], [344, 349], [349, 350], [351, 360], [361, 369], [370, 378], [379, 383], [384, 394], [394, 395], [395, 396], [397, 403], [403, 404], [405, 410], [411, 414], [415, 424], [425, 428], [429, 435], [436, 447], [448, 456], [456, 457], [457, 458], [459, 464], [465, 471], [471, 472]]}
{"doc_key": "ai-test-407", "ner": [[0, 8, "algorithm"], [9, 11, "researcher"], [12, 13, "university"], [15, 17, "researcher"], [20, 21, "organisation"], [18, 19, "organisation"], [32, 33, "researcher"], [36, 39, "researcher"], [40, 43, "organisation"], [56, 61, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[9, 11, 12, 13, "physical", "", false, false], [9, 11, 12, 13, "role", "", false, false], [15, 17, 20, 21, "physical", "", false, false], [15, 17, 20, 21, "role", "", false, false], [18, 19, 20, 21, "named", "", false, false], [32, 33, 40, 43, "physical", "", false, false], [32, 33, 40, 43, "role", "", false, false], [36, 39, 40, 43, "physical", "", false, false], [36, 39, 40, 43, "role", "", false, false]], "relations_mapping_to_source": [5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Linear", "Predictive", "Coding", "(", "LPC", ")", "was", "developed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", ",", "and", "further", "developed", "by", "Bishnu", "S.", "Atal", "and", "Manfred", "R.", "Schroeder", "of", "Bell", "Labs", "in", "the", "early", "to", "mid", "1970s", "and", "It", "was", "the", "basis", "for", "the", "first", "speech", "synthesis", "DSP", "chips", "in", "the", "late", "1970s", "."], "sentence-detokenized": "Linear Predictive Coding (LPC) was developed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966, and further developed by Bishnu S. Atal and Manfred R. Schroeder of Bell Labs in the early to mid 1970s and It was the basis for the first speech synthesis DSP chips in the late 1970s.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [31, 34], [35, 44], [45, 47], [48, 56], [57, 64], [65, 67], [68, 74], [75, 85], [86, 89], [90, 95], [96, 101], [102, 104], [105, 111], [112, 121], [122, 125], [126, 135], [136, 137], [137, 140], [140, 141], [142, 144], [145, 149], [149, 150], [151, 154], [155, 162], [163, 172], [173, 175], [176, 182], [183, 185], [186, 190], [191, 194], [195, 202], [203, 205], [206, 215], [216, 218], [219, 223], [224, 228], [229, 231], [232, 235], [236, 241], [242, 244], [245, 248], [249, 254], [255, 258], [259, 261], [262, 265], [266, 269], [270, 275], [276, 279], [280, 283], [284, 289], [290, 296], [297, 306], [307, 310], [311, 316], [317, 319], [320, 323], [324, 328], [329, 334], [334, 335]]}
{"doc_key": "ai-test-408", "ner": [[0, 3, "metrics"], [7, 9, "metrics"]], "ner_mapping_to_source": [0, 2], "relations": [[7, 9, 0, 3, "part-of", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["The", "F", "-", "score", "combines", "accuracy", "and", "recall", "into", "a", "single", "score", "."], "sentence-detokenized": "The F-score combines accuracy and recall into a single score.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 20], [21, 29], [30, 33], [34, 40], [41, 45], [46, 47], [48, 54], [55, 60], [60, 61]]}
{"doc_key": "ai-test-409", "ner": [[0, 4, "field"], [10, 15, "task"], [19, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 15, 0, 4, "part-of", "task_part_of_field", false, false], [19, 23, 0, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Image", "analysis", "can", "range", "from", "simple", "tasks", ",", "such", "as", "reading", "barcode", "tags", ",", "to", "more", "sophisticated", "ones", ",", "such", "as", "facial", "recognition", "systems", "."], "sentence-detokenized": "Image analysis can range from simple tasks, such as reading barcode tags, to more sophisticated ones, such as facial recognition systems.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 24], [25, 29], [30, 36], [37, 42], [42, 43], [44, 48], [49, 51], [52, 59], [60, 67], [68, 72], [72, 73], [74, 76], [77, 81], [82, 95], [96, 100], [100, 101], [102, 106], [107, 109], [110, 116], [117, 128], [129, 136], [136, 137]]}
{"doc_key": "ai-test-410", "ner": [[5, 7, "algorithm"], [25, 26, "algorithm"], [33, 35, "algorithm"], [38, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[33, 35, 25, 26, "type-of", "", false, false], [38, 38, 33, 35, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "special", "case", "of", "linear", "support", "vector", "machines", "can", "be", "solved", "more", "efficiently", "with", "the", "same", "kind", "of", "algorithms", "that", "optimise", "its", "close", "relative", ",", "logistic", "regression", ".", "This", "class", "of", "algorithms", "includes", "Stochastic", "gradient", "descent", "(", "e.g.", "PEGASOS", ")", "."], "sentence-detokenized": "The special case of linear support vector machines can be solved more efficiently with the same kind of algorithms that optimise its close relative, logistic regression. This class of algorithms includes Stochastic gradient descent (e.g. PEGASOS).", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 19], [20, 26], [27, 34], [35, 41], [42, 50], [51, 54], [55, 57], [58, 64], [65, 69], [70, 81], [82, 86], [87, 90], [91, 95], [96, 100], [101, 103], [104, 114], [115, 119], [120, 128], [129, 132], [133, 138], [139, 147], [147, 148], [149, 157], [158, 168], [168, 169], [170, 174], [175, 180], [181, 183], [184, 194], [195, 203], [204, 214], [215, 223], [224, 231], [232, 233], [233, 237], [238, 245], [245, 246], [246, 247]]}
{"doc_key": "ai-test-411", "ner": [[3, 5, "product"], [6, 6, "product"], [15, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 6, 6, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["If", "you", "ask", "Siri", "on", "an", "iOS", "device", "whether", "she", "has", "a", "pet", ",", "she", "will", "reply", "that", "she", "used", "to", "have", "an", "AIBO", "."], "sentence-detokenized": "If you ask Siri on an iOS device whether she has a pet, she will reply that she used to have an AIBO.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 15], [16, 18], [19, 21], [22, 25], [26, 32], [33, 40], [41, 44], [45, 48], [49, 50], [51, 54], [54, 55], [56, 59], [60, 64], [65, 70], [71, 75], [76, 79], [80, 84], [85, 87], [88, 92], [93, 95], [96, 100], [100, 101]]}
{"doc_key": "ai-test-412", "ner": [[0, 2, "task"], [4, 6, "metrics"], [8, 8, "metrics"], [10, 11, "metrics"], [12, 13, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 0, 2, "part-of", "", false, false], [8, 8, 4, 6, "named", "", false, false], [10, 11, 0, 2, "part-of", "", false, false], [12, 13, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "information", "retrieval", ",", "positive", "predictions", "are", "called", "precision", "and", "sensitivity", "is", "called", "recall", "."], "sentence-detokenized": "In information retrieval, positive predictions are called precision and sensitivity is called recall.", "token2charspan": [[0, 2], [3, 14], [15, 24], [24, 25], [26, 34], [35, 46], [47, 50], [51, 57], [58, 67], [68, 71], [72, 83], [84, 86], [87, 93], [94, 100], [100, 101]]}
{"doc_key": "ai-test-413", "ner": [[10, 11, "field"], [13, 13, "task"], [15, 15, "task"], [17, 20, "task"], [26, 27, "task"], [29, 30, "task"], [32, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 13, 10, 11, "part-of", "task_part_of_field", false, false], [15, 15, 10, 11, "part-of", "task_part_of_field", false, false], [17, 20, 10, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "particular", ",", "his", "research", "focuses", "on", "areas", "such", "as", "text", "mining", "(", "extraction", ",", "classification", ",", "novelty", "detection", ")", "and", "new", "theoretical", "frameworks", "such", "as", "information", "retrieval", ",", "automatic", "summarisation", ",", "free", "-", "form", "question", "answering", "and", "utility", "-", "based", "unification", "theories", "bridging", "related", "tasks", "."], "sentence-detokenized": "In particular, his research focuses on areas such as text mining (extraction, classification, novelty detection) and new theoretical frameworks such as information retrieval, automatic summarisation, free-form question answering and utility-based unification theories bridging related tasks.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 27], [28, 35], [36, 38], [39, 44], [45, 49], [50, 52], [53, 57], [58, 64], [65, 66], [66, 76], [76, 77], [78, 92], [92, 93], [94, 101], [102, 111], [111, 112], [113, 116], [117, 120], [121, 132], [133, 143], [144, 148], [149, 151], [152, 163], [164, 173], [173, 174], [175, 184], [185, 198], [198, 199], [200, 204], [204, 205], [205, 209], [210, 218], [219, 228], [229, 232], [233, 240], [240, 241], [241, 246], [247, 258], [259, 267], [268, 276], [277, 284], [285, 290], [290, 291]]}
{"doc_key": "ai-test-414", "ner": [[0, 0, "product"], [7, 9, "product"], [10, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 0, 0, "part-of", "", false, false], [10, 18, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Delta", "robots", "have", "a", "base", "-", "mounted", "rotary", "actuator", "that", "moves", "a", "light", ",", "rigid", "parallelogram", "-", "shaped", "arm", "."], "sentence-detokenized": "Delta robots have a base-mounted rotary actuator that moves a light, rigid parallelogram-shaped arm.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 19], [20, 24], [24, 25], [25, 32], [33, 39], [40, 48], [49, 53], [54, 59], [60, 61], [62, 67], [67, 68], [69, 74], [75, 88], [88, 89], [89, 95], [96, 99], [99, 100]]}
{"doc_key": "ai-test-415", "ner": [[8, 12, "metrics"], [14, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", "."], "sentence-detokenized": "The four results can be formulated in a 2 \u00d7 2 contingency table or confusion matrix as follows.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [64, 66], [67, 76], [77, 83], [84, 86], [87, 94], [94, 95]]}
{"doc_key": "ai-test-416", "ner": [[2, 3, "field"], [30, 31, "task"], [37, 40, "task"], [43, 45, "task"], [47, 49, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[30, 31, 2, 3, "part-of", "task_part_of_field", false, false], [37, 40, 2, 3, "part-of", "task_part_of_field", false, false], [43, 45, 2, 3, "part-of", "task_part_of_field", false, false], [47, 49, 2, 3, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "actual", "data", "mining", "task", "is", "the", "semi-automatic", "or", "automatic", "analysis", "of", "large", "amounts", "of", "data", "to", "extract", "unknown", "and", "interesting", "patterns", ",", "such", "as", "groups", "of", "data", "records", "(", "cluster", "analysis", ")", ",", "anomalous", "records", "(", "anomaly", "detection", ")", "and", "dependencies", "(", "association", "rule", "mining", ",", "sequential", "pattern", "mining", ")", "."], "sentence-detokenized": "The actual data mining task is the semi-automatic or automatic analysis of large amounts of data to extract unknown and interesting patterns, such as groups of data records (cluster analysis), anomalous records (anomaly detection) and dependencies (association rule mining, sequential pattern mining).", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 22], [23, 27], [28, 30], [31, 34], [35, 49], [50, 52], [53, 62], [63, 71], [72, 74], [75, 80], [81, 88], [89, 91], [92, 96], [97, 99], [100, 107], [108, 115], [116, 119], [120, 131], [132, 140], [140, 141], [142, 146], [147, 149], [150, 156], [157, 159], [160, 164], [165, 172], [173, 174], [174, 181], [182, 190], [190, 191], [191, 192], [193, 202], [203, 210], [211, 212], [212, 219], [220, 229], [229, 230], [231, 234], [235, 247], [248, 249], [249, 260], [261, 265], [266, 272], [272, 273], [274, 284], [285, 292], [293, 299], [299, 300], [300, 301]]}
{"doc_key": "ai-test-417", "ner": [[10, 11, "product"], [0, 1, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sentiment", "analysis", "has", "proven", "to", "be", "a", "useful", "technique", "for", "recommendation", "systems", "."], "sentence-detokenized": "Sentiment analysis has proven to be a useful technique for recommendation systems.", "token2charspan": [[0, 9], [10, 18], [19, 22], [23, 29], [30, 32], [33, 35], [36, 37], [38, 44], [45, 54], [55, 58], [59, 73], [74, 81], [81, 82]]}
{"doc_key": "ai-test-418", "ner": [[6, 9, "misc"], [10, 12, "product"], [21, 22, "organisation"], [28, 30, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 9, 10, 12, "usage", "", false, false], [21, 22, 28, 30, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Coincidentally", ",", "the", "frequency", "chosen", "by", "the", "Germans", "for", "the", "Votan", "system", "was", "45", "MHz", ",", "just", "the", "frequency", "of", "the", "BBC", "'s", "powerful", "but", "dormant", "television", "transmitter", "at", "Alexandra", "Palace", "."], "sentence-detokenized": "Coincidentally, the frequency chosen by the Germans for the Votan system was 45 MHz, just the frequency of the BBC's powerful but dormant television transmitter at Alexandra Palace.", "token2charspan": [[0, 14], [14, 15], [16, 19], [20, 29], [30, 36], [37, 39], [40, 43], [44, 51], [52, 55], [56, 59], [60, 65], [66, 72], [73, 76], [77, 79], [80, 83], [83, 84], [85, 89], [90, 93], [94, 103], [104, 106], [107, 110], [111, 114], [114, 116], [117, 125], [126, 129], [130, 137], [138, 148], [149, 160], [161, 163], [164, 173], [174, 180], [180, 181]]}
{"doc_key": "ai-test-419", "ner": [[8, 12, "metrics"], [14, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", "."], "sentence-detokenized": "The four results can be formulated in a 2 \u00d7 2 contingency table or confusion matrix as follows.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [64, 66], [67, 76], [77, 83], [84, 86], [87, 94], [94, 95]]}
{"doc_key": "ai-test-420", "ner": [[1, 2, "misc"], [8, 9, "misc"], [15, 15, "product"], [18, 19, "product"], [27, 28, "misc"], [33, 36, "product"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6], "relations": [[15, 15, 8, 9, "usage", "", false, false], [18, 19, 15, 15, "named", "", false, false], [27, 28, 8, 9, "part-of", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["In", "Semantic", "Web", "applications", "and", "relatively", "common", "applications", "of", "RDF", ",", "such", "as", "RSS", "and", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "resources", "are", "deliberately", "represented", "by", "URIs", "that", "indicate", "actual", "data", "on", "the", "World", "Wide", "Web", "and", "can", "be", "used", "to", "access", "them", "This", "tends", "to", "be", "the", "case", "."], "sentence-detokenized": "In Semantic Web applications and relatively common applications of RDF, such as RSS and FOAF (Friend a Friend), resources are deliberately represented by URIs that indicate actual data on the World Wide Web and can be used to access them This tends to be the case.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 28], [29, 32], [33, 43], [44, 50], [51, 63], [64, 66], [67, 70], [70, 71], [72, 76], [77, 79], [80, 83], [84, 87], [88, 92], [93, 94], [94, 100], [101, 102], [103, 109], [109, 110], [110, 111], [112, 121], [122, 125], [126, 138], [139, 150], [151, 153], [154, 158], [159, 163], [164, 172], [173, 179], [180, 184], [185, 187], [188, 191], [192, 197], [198, 202], [203, 206], [207, 210], [211, 214], [215, 217], [218, 222], [223, 225], [226, 232], [233, 237], [238, 242], [243, 248], [249, 251], [252, 254], [255, 258], [259, 263], [263, 264]]}
{"doc_key": "ai-test-421", "ner": [[0, 4, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Artificial", "Intelligence", "Society", "is", "researching", "this", "topic", "in", "depth", "."], "sentence-detokenized": "The Artificial Intelligence Society is researching this topic in depth.", "token2charspan": [[0, 3], [4, 14], [15, 27], [28, 35], [36, 38], [39, 50], [51, 55], [56, 61], [62, 64], [65, 70], [70, 71]]}
{"doc_key": "ai-test-422", "ner": [[7, 10, "product"], [14, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 14, 7, 10, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["What", "started", "as", "a", "curiosity", ",", "the", "Apple", "Macintosh", "speech", "system", "has", "evolved", "into", "PlainTalk", ",", "a", "full", "support", "programme", "for", "the", "visually", "impaired", "."], "sentence-detokenized": "What started as a curiosity, the Apple Macintosh speech system has evolved into PlainTalk, a full support programme for the visually impaired.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 17], [18, 27], [27, 28], [29, 32], [33, 38], [39, 48], [49, 55], [56, 62], [63, 66], [67, 74], [75, 79], [80, 89], [89, 90], [91, 92], [93, 97], [98, 105], [106, 115], [116, 119], [120, 123], [124, 132], [133, 141], [141, 142]]}
{"doc_key": "ai-test-423", "ner": [[6, 8, "field"], [0, 10, "task"], [12, 13, "task"], [5, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 10, 6, 8, "part-of", "task_part_of_field", false, false], [12, 13, 6, 8, "part-of", "task_part_of_field", false, false], [5, 16, 6, 8, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Other", "uses", "of", "ontologies", "in", "natural", "language", "processing", "include", "information", "retrieval", ",", "information", "extraction", "and", "automatic", "summarisation", "."], "sentence-detokenized": "Other uses of ontologies in natural language processing include information retrieval, information extraction and automatic summarisation.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 24], [25, 27], [28, 35], [36, 44], [45, 55], [56, 63], [64, 75], [76, 85], [85, 86], [87, 98], [99, 109], [110, 113], [114, 123], [124, 137], [137, 138]]}
{"doc_key": "ai-test-424", "ner": [[7, 15, "organisation"], [18, 22, "organisation"], [25, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "institute", "is", "working", "closely", "with", "the", "Janelia", "Farm", "Campus", "of", "the", "Howard", "Hughes", "Medical", "Institute", ",", "the", "Allen", "Institute", "for", "Brain", "Science", "and", "the", "US", "National", "Institutes", "of", "Health", "to", "develop", "superior", "methods", "to", "reconstruct", "neuronal", "structures", "."], "sentence-detokenized": "The institute is working closely with the Janelia Farm Campus of the Howard Hughes Medical Institute, the Allen Institute for Brain Science and the US National Institutes of Health to develop superior methods to reconstruct neuronal structures.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 24], [25, 32], [33, 37], [38, 41], [42, 49], [50, 54], [55, 61], [62, 64], [65, 68], [69, 75], [76, 82], [83, 90], [91, 100], [100, 101], [102, 105], [106, 111], [112, 121], [122, 125], [126, 131], [132, 139], [140, 143], [144, 147], [148, 150], [151, 159], [160, 170], [171, 173], [174, 180], [181, 183], [184, 191], [192, 200], [201, 208], [209, 211], [212, 223], [224, 232], [233, 243], [243, 244]]}
{"doc_key": "ai-test-425", "ner": [[2, 2, "organisation"], [5, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 2, 2, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Recently", ",", "Google", "announced", "that", "Google", "Translate", "translates", "enough", "text", "to", "fill", "approximately", "one", "million", "books", "a", "day", "(", "2012", ")", "."], "sentence-detokenized": "Recently, Google announced that Google Translate translates enough text to fill approximately one million books a day (2012).", "token2charspan": [[0, 8], [8, 9], [10, 16], [17, 26], [27, 31], [32, 38], [39, 48], [49, 59], [60, 66], [67, 71], [72, 74], [75, 79], [80, 93], [94, 97], [98, 105], [106, 111], [112, 113], [114, 117], [118, 119], [119, 123], [123, 124], [124, 125]]}
{"doc_key": "ai-test-426", "ner": [[16, 16, "country"], [18, 18, "country"], [20, 20, "country"], [22, 22, "country"], [24, 24, "country"], [26, 27, "country"], [39, 43, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Events", "are", "held", "in", "many", "parts", "of", "the", "world", ",", "and", "are", "most", "popular", "in", "the", "UK", ",", "USA", ",", "Japan", ",", "Singapore", ",", "India", "and", "South", "Korea", ",", "and", "are", "becoming", "increasingly", "popular", "in", "countries", "on", "the", "subcontinent", ",", "such", "as", "Sri", "Lanka", "."], "sentence-detokenized": "Events are held in many parts of the world, and are most popular in the UK, USA, Japan, Singapore, India and South Korea, and are becoming increasingly popular in countries on the subcontinent, such as Sri Lanka.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 18], [19, 23], [24, 29], [30, 32], [33, 36], [37, 42], [42, 43], [44, 47], [48, 51], [52, 56], [57, 64], [65, 67], [68, 71], [72, 74], [74, 75], [76, 79], [79, 80], [81, 86], [86, 87], [88, 97], [97, 98], [99, 104], [105, 108], [109, 114], [115, 120], [120, 121], [122, 125], [126, 129], [130, 138], [139, 151], [152, 159], [160, 162], [163, 172], [173, 175], [176, 179], [180, 192], [192, 193], [194, 198], [199, 201], [202, 205], [206, 211], [211, 212]]}
{"doc_key": "ai-test-427", "ner": [[6, 6, "programlang"], [10, 10, "programlang"], [12, 12, "programlang"], [14, 15, "programlang"], [3, 17, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "packages", "are", "developed", "mainly", "in", "R", ",", "sometimes", "in", "Java", ",", "C", ",", "C", "++", "and", "Fortran", "."], "sentence-detokenized": "These packages are developed mainly in R, sometimes in Java, C, C++ and Fortran.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 28], [29, 35], [36, 38], [39, 40], [40, 41], [42, 51], [52, 54], [55, 59], [59, 60], [61, 62], [62, 63], [64, 65], [65, 67], [68, 71], [72, 79], [79, 80]]}
{"doc_key": "ai-test-428", "ner": [[4, 6, "conference"], [5, 11, "conference"], [16, 18, "researcher"], [20, 22, "researcher"], [25, 27, "algorithm"], [31, 37, "task"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6], "relations": [[5, 11, 4, 6, "named", "", false, false], [16, 18, 4, 6, "physical", "", false, false], [16, 18, 4, 6, "role", "", false, false], [16, 18, 20, 22, "role", "teams_up_with", false, false], [16, 18, 25, 27, "usage", "", false, false], [20, 22, 4, 6, "physical", "", false, false], [20, 22, 4, 6, "role", "", false, false], [20, 22, 25, 27, "usage", "", false, false], [25, 27, 31, 37, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["As", "part", "of", "the", "2006", "European", "Conference", "on", "Computer", "Vision", "(", "ECCV", ")", ",", "Dalal", "and", "Triggs", ",", "in", "collaboration", "with", "Cordelia", "Schmid", ",", "applied", "the", "HOG", "detector", "to", "the", "problem", "of", "person", "detection", "in", "film", "and", "video", "."], "sentence-detokenized": "As part of the 2006 European Conference on Computer Vision (ECCV), Dalal and Triggs, in collaboration with Cordelia Schmid, applied the HOG detector to the problem of person detection in film and video.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 19], [20, 28], [29, 39], [40, 42], [43, 51], [52, 58], [59, 60], [60, 64], [64, 65], [65, 66], [67, 72], [73, 76], [77, 83], [83, 84], [85, 87], [88, 101], [102, 106], [107, 115], [116, 122], [122, 123], [124, 131], [132, 135], [136, 139], [140, 148], [149, 151], [152, 155], [156, 163], [164, 166], [167, 173], [174, 183], [184, 186], [187, 191], [192, 195], [196, 201], [201, 202]]}
{"doc_key": "ai-test-429", "ner": [[15, 17, "metrics"], [4, 5, "task"], [20, 24, "metrics"], [28, 28, "metrics"], [31, 35, "metrics"]], "ner_mapping_to_source": [1, 2, 4, 5, 7], "relations": [[15, 17, 4, 5, "related-to", "measured_with", false, false]], "relations_mapping_to_source": [1], "sentence": ["The", "performance", "of", "a", "binary", "classification", "test", "can", "be", "measured", "in", "terms", "of", "sensitivity", "and", "specificity", ",", "as", "well", "as", "positive", "predictive", "value", "(", "PPV", ")", ",", "aka", "accuracy", ",", "and", "negative", "predictive", "value", "(", "NPV", ")", "."], "sentence-detokenized": "The performance of a binary classification test can be measured in terms of sensitivity and specificity, as well as positive predictive value (PPV), aka accuracy, and negative predictive value (NPV).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 20], [21, 27], [28, 42], [43, 47], [48, 51], [52, 54], [55, 63], [64, 66], [67, 72], [73, 75], [76, 87], [88, 91], [92, 103], [103, 104], [105, 107], [108, 112], [113, 115], [116, 124], [125, 135], [136, 141], [142, 143], [143, 146], [146, 147], [147, 148], [149, 152], [153, 161], [161, 162], [163, 166], [167, 175], [176, 186], [187, 192], [193, 194], [194, 197], [197, 198], [198, 199]]}
{"doc_key": "ai-test-430", "ner": [[11, 14, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "models", "allow", "for", "partial", "assessment", "of", "overlapping", "matches", "(", "e.g.", "using", "Jaccard", "index", "criteria", ")", "."], "sentence-detokenized": "Such models allow for partial assessment of overlapping matches (e.g. using Jaccard index criteria).", "token2charspan": [[0, 4], [5, 11], [12, 17], [18, 21], [22, 29], [30, 40], [41, 43], [44, 55], [56, 63], [64, 65], [65, 69], [70, 75], [76, 83], [84, 89], [90, 98], [98, 99], [99, 100]]}
{"doc_key": "ai-test-431", "ner": [[24, 30, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Furthermore", ",", "in", "the", "case", "of", "single", "-", "sample", "based", "estimation", ",", "it", "illustrates", "the", "potential", "for", "philosophical", "problems", "and", "misunderstandings", "in", "the", "use", "of", "maximum", "likelihood", "estimators", "and", "likelihood", "functions", "."], "sentence-detokenized": "Furthermore, in the case of single-sample based estimation, it illustrates the potential for philosophical problems and misunderstandings in the use of maximum likelihood estimators and likelihood functions.", "token2charspan": [[0, 11], [11, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 34], [34, 35], [35, 41], [42, 47], [48, 58], [58, 59], [60, 62], [63, 74], [75, 78], [79, 88], [89, 92], [93, 106], [107, 115], [116, 119], [120, 137], [138, 140], [141, 144], [145, 148], [149, 151], [152, 159], [160, 170], [171, 181], [182, 185], [186, 196], [197, 206], [206, 207]]}
