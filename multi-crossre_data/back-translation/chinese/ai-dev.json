{"doc_key": "ai-dev-1", "ner": [[2, 3, "metrics"], [7, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 11, 2, 3, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Here", ",", "accuracy", "is", "measured", "by", "the", "error", "rate", ",", "which", "is", "defined", "as", "."], "sentence-detokenized": "Here, accuracy is measured by the error rate, which is defined as.", "token2charspan": [[0, 4], [4, 5], [6, 14], [15, 17], [18, 26], [27, 29], [30, 33], [34, 39], [40, 44], [44, 45], [46, 51], [52, 54], [55, 62], [63, 65], [65, 66]]}
{"doc_key": "ai-dev-2", "ner": [[4, 5, "algorithm"], [11, 12, "misc"], [15, 17, "algorithm"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 11, 12, "type-of", "", false, false], [4, 5, 15, 17, "related-to", "", false, false], [4, 5, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["From", "this", "perspective", ",", "SVM", "is", "closely", "related", "to", "other", "basic", "classification", "algorithms", "such", "as", "regularised", "least", "squares", "logistic", "regression", "."], "sentence-detokenized": "From this perspective, SVM is closely related to other basic classification algorithms such as regularised least squares logistic regression.", "token2charspan": [[0, 4], [5, 9], [10, 21], [21, 22], [23, 26], [27, 29], [30, 37], [38, 45], [46, 48], [49, 54], [55, 60], [61, 75], [76, 86], [87, 91], [92, 94], [95, 106], [107, 112], [113, 120], [121, 129], [130, 140], [140, 141]]}
{"doc_key": "ai-dev-3", "ner": [[0, 1, "person"], [3, 4, "person"], [13, 14, "person"], [16, 16, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 0, 1, "named", "actor_plays_character", false, false], [3, 4, 0, 1, "origin", "actor_plays_character", false, false], [16, 16, 13, 14, "named", "actor_plays_character", false, false], [16, 16, 13, 14, "origin", "actor_plays_character", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Brion", "James", "as", "Leon", "Kowalski", ",", "a", "fighting", "and", "labouring", "replicant", ",", "and", "Joanna", "Cassidy", "as", "Zhora", ",", "an", "assassin", "replicant", "."], "sentence-detokenized": "Brion James as Leon Kowalski, a fighting and labouring replicant, and Joanna Cassidy as Zhora, an assassin replicant.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 19], [20, 28], [28, 29], [30, 31], [32, 40], [41, 44], [45, 54], [55, 64], [64, 65], [66, 69], [70, 76], [77, 84], [85, 87], [88, 93], [93, 94], [95, 97], [98, 106], [107, 116], [116, 117]]}
{"doc_key": "ai-dev-4", "ner": [[18, 21, "product"], [23, 23, "product"], [16, 16, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 21, 16, 16, "physical", "", false, false], [23, 23, 18, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "image", "to", "be", "scanned", ",", "stored", "and", "recreated", "in", "digital", "pixels", "is", "displayed", "on", "NIST", "'s", "Eastern", "Standards", "Automated", "Computer", "(", "SEAC", ")", "."], "sentence-detokenized": "The first image to be scanned, stored and recreated in digital pixels is displayed on NIST's Eastern Standards Automated Computer (SEAC).", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 18], [19, 21], [22, 29], [29, 30], [31, 37], [38, 41], [42, 51], [52, 54], [55, 62], [63, 69], [70, 72], [73, 82], [83, 85], [86, 90], [90, 92], [93, 100], [101, 110], [111, 120], [121, 129], [130, 131], [131, 135], [135, 136], [136, 137]]}
{"doc_key": "ai-dev-5", "ner": [[0, 6, "task"], [20, 21, "task"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 6, 20, 21, "part-of", "", false, false], [0, 6, 23, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Segmenting", "text", "into", "topics", "or", "discourse", "turns", "may", "be", "useful", "in", "some", "natural", "processing", "tasks", ":", "it", "can", "greatly", "improve", "information", "retrieval", "or", "speech", "recognition", "(", "by", "indexing", "/", "recognising", "documents", "more", "precisely", ",", "or", "by", "using", "as", "a", "result", "a", "specific", "part", "of", "a", "document", "that", "corresponds", "to", "a", "query", ")", "."], "sentence-detokenized": "Segmenting text into topics or discourse turns may be useful in some natural processing tasks: it can greatly improve information retrieval or speech recognition (by indexing/recognising documents more precisely, or by using as a result a specific part of a document that corresponds to a query).", "token2charspan": [[0, 10], [11, 15], [16, 20], [21, 27], [28, 30], [31, 40], [41, 46], [47, 50], [51, 53], [54, 60], [61, 63], [64, 68], [69, 76], [77, 87], [88, 93], [93, 94], [95, 97], [98, 101], [102, 109], [110, 117], [118, 129], [130, 139], [140, 142], [143, 149], [150, 161], [162, 163], [163, 165], [166, 174], [174, 175], [175, 186], [187, 196], [197, 201], [202, 211], [211, 212], [213, 215], [216, 218], [219, 224], [225, 227], [228, 229], [230, 236], [237, 238], [239, 247], [248, 252], [253, 255], [256, 257], [258, 266], [267, 271], [272, 283], [284, 286], [287, 288], [289, 294], [294, 295], [295, 296]]}
{"doc_key": "ai-dev-6", "ner": [[1, 2, "university"], [25, 26, "conference"], [21, 22, "university"], [34, 37, "researcher"], [39, 40, "researcher"], [43, 43, "researcher"], [45, 46, "researcher"], [48, 49, "researcher"], [51, 52, "researcher"], [54, 56, "researcher"], [58, 59, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[25, 26, 21, 22, "physical", "", false, false], [34, 37, 25, 26, "physical", "", false, false], [34, 37, 25, 26, "role", "", false, false], [34, 37, 25, 26, "temporal", "", false, false], [39, 40, 25, 26, "physical", "", false, false], [39, 40, 25, 26, "role", "", false, false], [39, 40, 25, 26, "temporal", "", false, false], [43, 43, 25, 26, "physical", "", false, false], [43, 43, 25, 26, "role", "", false, false], [43, 43, 25, 26, "temporal", "", false, false], [45, 46, 25, 26, "physical", "", false, false], [45, 46, 25, 26, "role", "", false, false], [45, 46, 25, 26, "temporal", "", false, false], [48, 49, 25, 26, "physical", "", false, false], [48, 49, 25, 26, "role", "", false, false], [48, 49, 25, 26, "temporal", "", false, false], [51, 52, 25, 26, "physical", "", false, false], [51, 52, 25, 26, "role", "", false, false], [51, 52, 25, 26, "temporal", "", false, false], [54, 56, 25, 26, "physical", "", false, false], [54, 56, 25, 26, "role", "", false, false], [54, 56, 25, 26, "temporal", "", false, false], [58, 59, 25, 26, "physical", "", false, false], [58, 59, 25, 26, "role", "", false, false], [58, 59, 25, 26, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "sentence": ["At", "Indiana", "University", "in", "1999", "he", "organised", "such", "a", "symposium", ",", "and", "in", "April", "2000", "he", "organised", "a", "larger", "symposium", "at", "Stanford", "University", "entitled", "'", "Mental", "Robots", "'", ",", "where", "he", "chaired", "a", "panel", "consisting", "of", "Ray", "Kurzweil", ",", "Hans", "Moravec", ",", "Kevin", "Kelly", ",", "Ralph", "Merkle", ",", "Bill", "Joy", ",", "Frank", "Drake", ",", "John", "Henry", "Holland", "and", "John", "Cozza", "The", "group", "consisting", "of", "."], "sentence-detokenized": "At Indiana University in 1999 he organised such a symposium, and in April 2000 he organised a larger symposium at Stanford University entitled 'Mental Robots', where he chaired a panel consisting of Ray Kurzweil, Hans Moravec, Kevin Kelly, Ralph Merkle, Bill Joy, Frank Drake, John Henry Holland and John Cozza The group consisting of.", "token2charspan": [[0, 2], [3, 10], [11, 21], [22, 24], [25, 29], [30, 32], [33, 42], [43, 47], [48, 49], [50, 59], [59, 60], [61, 64], [65, 67], [68, 73], [74, 78], [79, 81], [82, 91], [92, 93], [94, 100], [101, 110], [111, 113], [114, 122], [123, 133], [134, 142], [143, 144], [144, 150], [151, 157], [157, 158], [158, 159], [160, 165], [166, 168], [169, 176], [177, 178], [179, 184], [185, 195], [196, 198], [199, 202], [203, 211], [211, 212], [213, 217], [218, 225], [225, 226], [227, 232], [233, 238], [238, 239], [240, 245], [246, 252], [252, 253], [254, 258], [259, 262], [262, 263], [264, 269], [270, 275], [275, 276], [277, 281], [282, 287], [288, 295], [296, 299], [300, 304], [305, 310], [311, 314], [315, 320], [321, 331], [332, 334], [334, 335]]}
{"doc_key": "ai-dev-7", "ner": [[8, 8, "metrics"], [9, 9, "metrics"], [11, 11, "metrics"], [12, 12, "metrics"], [17, 29, "metrics"], [39, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 8, 17, 29, "named", "", false, false], [9, 9, 8, 8, "named", "", false, false], [11, 11, 39, 39, "named", "", false, false], [12, 12, 11, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "calculates", "the", "score", "by", "considering", "both", "the", "precision", "p", "and", "recall", "r", "of", "the", "test", ":", "p", "is", "the", "number", "of", "correct", "positive", "results", "divided", "by", "the", "number", "of", "all", "positive", "results", "returned", "by", "the", "classifier", ",", "and", "r", "is", "the", "number", "of", "correct", "positive", "results", "divided", "by", "the", "number", "of", "all", "relevant", "samples", "(", "all", "samples", "that", "should", "have", "been", "identified", "as", "positive", ")", "."], "sentence-detokenized": "It calculates the score by considering both the precision p and recall r of the test: p is the number of correct positive results divided by the number of all positive results returned by the classifier, and r is the number of correct positive results divided by the number of all relevant samples (all samples that should have been identified as positive).", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 23], [24, 26], [27, 38], [39, 43], [44, 47], [48, 57], [58, 59], [60, 63], [64, 70], [71, 72], [73, 75], [76, 79], [80, 84], [84, 85], [86, 87], [88, 90], [91, 94], [95, 101], [102, 104], [105, 112], [113, 121], [122, 129], [130, 137], [138, 140], [141, 144], [145, 151], [152, 154], [155, 158], [159, 167], [168, 175], [176, 184], [185, 187], [188, 191], [192, 202], [202, 203], [204, 207], [208, 209], [210, 212], [213, 216], [217, 223], [224, 226], [227, 234], [235, 243], [244, 251], [252, 259], [260, 262], [263, 266], [267, 273], [274, 276], [277, 280], [281, 289], [290, 297], [298, 299], [299, 302], [303, 310], [311, 315], [316, 322], [323, 327], [328, 332], [333, 343], [344, 346], [347, 355], [355, 356], [356, 357]]}
{"doc_key": "ai-dev-8", "ner": [[1, 2, "organisation"], [20, 21, "product"], [29, 32, "person"], [36, 36, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 20, 21, "artifact", "", false, false], [20, 21, 29, 32, "win-defeat", "", false, false], [20, 21, 36, 36, "win-defeat", "", true, false], [29, 32, 36, 36, "win-defeat", "lose", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "Google", "'s", "acquisition", ",", "the", "company", "has", "made", "a", "number", "of", "significant", "achievements", ",", "perhaps", "most", "notably", "the", "creation", "of", "AlphaGo", ",", "the", "program", "that", "defeated", "world", "champion", "Lee", "Sedol", "in", "a", "complex", "game", "of", "Go", "."], "sentence-detokenized": "Since Google's acquisition, the company has made a number of significant achievements, perhaps most notably the creation of AlphaGo, the program that defeated world champion Lee Sedol in a complex game of Go.", "token2charspan": [[0, 5], [6, 12], [12, 14], [15, 26], [26, 27], [28, 31], [32, 39], [40, 43], [44, 48], [49, 50], [51, 57], [58, 60], [61, 72], [73, 85], [85, 86], [87, 94], [95, 99], [100, 107], [108, 111], [112, 120], [121, 123], [124, 131], [131, 132], [133, 136], [137, 144], [145, 149], [150, 158], [159, 164], [165, 173], [174, 177], [178, 183], [184, 186], [187, 188], [189, 196], [197, 201], [202, 204], [205, 207], [207, 208]]}
{"doc_key": "ai-dev-9", "ner": [[16, 16, "misc"], [28, 28, "field"], [32, 34, "product"], [51, 51, "misc"], [55, 56, "misc"], [59, 59, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[16, 16, 28, 28, "part-of", "", false, false], [16, 16, 55, 56, "named", "same", false, false], [32, 34, 51, 51, "related-to", "", false, false], [32, 34, 55, 56, "usage", "", false, false], [32, 34, 59, 59, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "representation", "of", "words", "considering", "their", "context", "through", "a", "dense", "vector", "of", "fixed", "size", "(", "word", "embeddings", ")", "has", "become", "one", "of", "the", "most", "fundamental", "modules", "in", "several", "NLP", "systems", ".", "An", "unsupervised", "disambiguation", "system", "uses", "similarities", "between", "word", "senses", "in", "a", "fixed", "context", "window", "to", "select", "the", "most", "appropriate", "word", "sense", "using", "a", "pre-trained", "word", "embedding", "model", "and", "WordNet", "."], "sentence-detokenized": "The representation of words considering their context through a dense vector of fixed size (word embeddings) has become one of the most fundamental modules in several NLP systems. An unsupervised disambiguation system uses similarities between word senses in a fixed context window to select the most appropriate word sense using a pre-trained word embedding model and WordNet.", "token2charspan": [[0, 3], [4, 18], [19, 21], [22, 27], [28, 39], [40, 45], [46, 53], [54, 61], [62, 63], [64, 69], [70, 76], [77, 79], [80, 85], [86, 90], [91, 92], [92, 96], [97, 107], [107, 108], [109, 112], [113, 119], [120, 123], [124, 126], [127, 130], [131, 135], [136, 147], [148, 155], [156, 158], [159, 166], [167, 170], [171, 178], [178, 179], [180, 182], [183, 195], [196, 210], [211, 217], [218, 222], [223, 235], [236, 243], [244, 248], [249, 255], [256, 258], [259, 260], [261, 266], [267, 274], [275, 281], [282, 284], [285, 291], [292, 295], [296, 300], [301, 312], [313, 317], [318, 323], [324, 329], [330, 331], [332, 343], [344, 348], [349, 358], [359, 364], [365, 368], [369, 376], [376, 377]]}
{"doc_key": "ai-dev-10", "ner": [[0, 1, "field"], [5, 5, "field"], [7, 8, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 0, 1, "part-of", "", false, false], [7, 8, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "techniques", ",", "both", "supervised", "and", "unsupervised", "learning", ",", "are", "used", "to", "automatically", "induce", "such", "rules", "."], "sentence-detokenized": "Machine learning techniques, both supervised and unsupervised learning, are used to automatically induce such rules.", "token2charspan": [[0, 7], [8, 16], [17, 27], [27, 28], [29, 33], [34, 44], [45, 48], [49, 61], [62, 70], [70, 71], [72, 75], [76, 80], [81, 83], [84, 97], [98, 104], [105, 109], [110, 115], [115, 116]]}
{"doc_key": "ai-dev-11", "ner": [[3, 3, "researcher"], [5, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1969", ",", "Scheinman", "invented", "the", "Stanford", "arm", "."], "sentence-detokenized": "In 1969, Scheinman invented the Stanford arm.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 27], [28, 31], [32, 40], [41, 44], [44, 45]]}
{"doc_key": "ai-dev-12", "ner": [[1, 2, "metrics"], [6, 9, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Since", "logarithmic", "losses", "are", "divisible", ",", "gradient", "-", "based", "methods", "can", "be", "used", "to", "optimise", "the", "model", "."], "sentence-detokenized": "Since logarithmic losses are divisible, gradient-based methods can be used to optimise the model.", "token2charspan": [[0, 5], [6, 17], [18, 24], [25, 28], [29, 38], [38, 39], [40, 48], [48, 49], [49, 54], [55, 62], [63, 66], [67, 69], [70, 74], [75, 77], [78, 86], [87, 90], [91, 96], [96, 97]]}
{"doc_key": "ai-dev-13", "ner": [[1, 2, "field"], [4, 6, "algorithm"], [8, 8, "algorithm"], [11, 13, "algorithm"], [16, 17, "field"], [29, 29, "task"], [31, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 6, 16, 17, "part-of", "", false, false], [8, 8, 4, 6, "named", "", false, false], [11, 13, 4, 6, "named", "", false, false], [16, 17, 1, 2, "part-of", "subfield", false, false], [29, 29, 16, 17, "part-of", "", false, false], [31, 32, 16, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "machine", "learning", ",", "support", "vector", "machines", "(", "SVMs", ",", "also", "support", "vector", "networks", ")", "are", "supervised", "learning", "models", "with", "learning", "algorithms", "that", "are", "used", "to", "analyse", "data", "for", "classification", "and", "regression", "analysis", "."], "sentence-detokenized": "In machine learning, support vector machines (SVMs, also support vector networks) are supervised learning models with learning algorithms that are used to analyse data for classification and regression analysis.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 28], [29, 35], [36, 44], [45, 46], [46, 50], [50, 51], [52, 56], [57, 64], [65, 71], [72, 80], [80, 81], [82, 85], [86, 96], [97, 105], [106, 112], [113, 117], [118, 126], [127, 137], [138, 142], [143, 146], [147, 151], [152, 154], [155, 162], [163, 167], [168, 171], [172, 186], [187, 190], [191, 201], [202, 210], [210, 211]]}
{"doc_key": "ai-dev-14", "ner": [[5, 6, "task"], [8, 8, "task"], [25, 25, "metrics"], [27, 27, "metrics"], [29, 29, "researcher"], [31, 31, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 8, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "an", "automatic", "measure", "for", "machine", "translation", "(", "MT", ")", "evaluation", ",", "many", "other", "methods", "have", "been", "proposed", "for", "modification", "or", "improvement", ",", "such", "as", "TER", ",", "METEOR", ",", "Banerjee", "and", "Lavie", "(", "2005", ")", "."], "sentence-detokenized": "As an automatic measure for machine translation (MT) evaluation, many other methods have been proposed for modification or improvement, such as TER, METEOR, Banerjee and Lavie (2005).", "token2charspan": [[0, 2], [3, 5], [6, 15], [16, 23], [24, 27], [28, 35], [36, 47], [48, 49], [49, 51], [51, 52], [53, 63], [63, 64], [65, 69], [70, 75], [76, 83], [84, 88], [89, 93], [94, 102], [103, 106], [107, 119], [120, 122], [123, 134], [134, 135], [136, 140], [141, 143], [144, 147], [147, 148], [149, 155], [155, 156], [157, 165], [166, 169], [170, 175], [176, 177], [177, 181], [181, 182], [182, 183]]}
{"doc_key": "ai-dev-15", "ner": [[3, 5, "misc"], [9, 9, "organisation"], [12, 12, "organisation"], [17, 18, "researcher"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 12, 12, "origin", "", false, false], [12, 12, 9, 9, "part-of", "", false, false], [17, 18, 12, 12, "role", "", false, false], [20, 21, 12, 12, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "includes", "an", "upper", "layer", "ontology", ",", "created", "by", "IEEE", "Working", "Group", "P1600.1", "(", "originally", "created", "by", "Ian", "Niles", "and", "Adam", "Pease", ")", "."], "sentence-detokenized": "It includes an upper layer ontology, created by IEEE Working Group P1600.1 (originally created by Ian Niles and Adam Pease).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 20], [21, 26], [27, 35], [35, 36], [37, 44], [45, 47], [48, 52], [53, 60], [61, 66], [67, 74], [75, 76], [76, 86], [87, 94], [95, 97], [98, 101], [102, 107], [108, 111], [112, 116], [117, 122], [122, 123], [123, 124]]}
{"doc_key": "ai-dev-16", "ner": [[1, 5, "misc"], [23, 25, "algorithm"], [27, 28, "algorithm"], [31, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 25, 1, 5, "part-of", "", true, false], [27, 28, 1, 5, "part-of", "", true, false], [31, 33, 27, 28, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "cryo-electron", "tomography", ",", "where", "the", "number", "of", "projections", "acquired", "is", "limited", "due", "to", "hardware", "limitations", ",", "it", "can", "be", "used", "together", "with", "compressed", "sensing", "techniques", "or", "regularisation", "functions", "such", "as", "Huber", "loss", "to", "improve", "the", "reconstruction", "and", "obtain", "a", "better", "interpretation", "in", "order", "to", "avoid", "damage", "to", "the", "biological", "specimen", "."], "sentence-detokenized": "In cryo-electron tomography, where the number of projections acquired is limited due to hardware limitations, it can be used together with compressed sensing techniques or regularisation functions such as Huber loss to improve the reconstruction and obtain a better interpretation in order to avoid damage to the biological specimen.", "token2charspan": [[0, 2], [3, 16], [17, 27], [27, 28], [29, 34], [35, 38], [39, 45], [46, 48], [49, 60], [61, 69], [70, 72], [73, 80], [81, 84], [85, 87], [88, 96], [97, 108], [108, 109], [110, 112], [113, 116], [117, 119], [120, 124], [125, 133], [134, 138], [139, 149], [150, 157], [158, 168], [169, 171], [172, 186], [187, 196], [197, 201], [202, 204], [205, 210], [211, 215], [216, 218], [219, 226], [227, 230], [231, 245], [246, 249], [250, 256], [257, 258], [259, 265], [266, 280], [281, 283], [284, 289], [290, 292], [293, 298], [299, 305], [306, 308], [309, 312], [313, 323], [324, 332], [332, 333]]}
{"doc_key": "ai-dev-17", "ner": [[3, 3, "misc"], [17, 19, "algorithm"], [21, 24, "algorithm"], [26, 27, "algorithm"], [9, 11, "product"], [14, 14, "product"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6], "relations": [[17, 19, 3, 3, "type-of", "", false, false], [21, 24, 3, 3, "type-of", "", false, false], [26, 27, 3, 3, "type-of", "", false, false], [14, 14, 9, 11, "role", "publishes", false, false]], "relations_mapping_to_source": [1, 2, 3, 6], "sentence": ["Several", "implementations", "of", "whitening", "procedures", "are", "available", "in", "the", "whitening", "R", "package", "published", "on", "CRAN", ",", "including", "ZCA", "-", "whitening", "and", "PCA", "whitening", ",", "and", "also", "CCA", "whitening", "."], "sentence-detokenized": "Several implementations of whitening procedures are available in the whitening R package published on CRAN, including ZCA-whitening and PCA whitening, and also CCA whitening.", "token2charspan": [[0, 7], [8, 23], [24, 26], [27, 36], [37, 47], [48, 51], [52, 61], [62, 64], [65, 68], [69, 78], [79, 80], [81, 88], [89, 98], [99, 101], [102, 106], [106, 107], [108, 117], [118, 121], [121, 122], [122, 131], [132, 135], [136, 139], [140, 149], [149, 150], [151, 154], [155, 159], [160, 163], [164, 173], [173, 174]]}
{"doc_key": "ai-dev-18", "ner": [[17, 17, "product"], [19, 19, "product"], [21, 21, "product"], [23, 23, "product"], [25, 25, "product"], [27, 27, "product"], [13, 31, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[17, 17, 21, 21, "compare", "", false, false], [17, 17, 23, 23, "compare", "", false, false], [17, 17, 25, 25, "compare", "", false, false], [17, 17, 27, 27, "compare", "", false, false], [17, 17, 13, 31, "compare", "", false, false], [19, 19, 21, 21, "compare", "", false, false], [19, 19, 23, 23, "compare", "", false, false], [19, 19, 25, 25, "compare", "", false, false], [19, 19, 27, 27, "compare", "", false, false], [19, 19, 13, 31, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Today", "the", "field", "has", "become", "even", "more", "daunting", "and", "complex", "with", "the", "addition", "of", "languages", "ranging", "from", "MATLAB", "and", "Simulink", "to", "NumPy", ",", "VHDL", ",", "PSpice", ",", "Verilog", "and", "even", "assembly", "language", "."], "sentence-detokenized": "Today the field has become even more daunting and complex with the addition of languages ranging from MATLAB and Simulink to NumPy, VHDL, PSpice, Verilog and even assembly language.", "token2charspan": [[0, 5], [6, 9], [10, 15], [16, 19], [20, 26], [27, 31], [32, 36], [37, 45], [46, 49], [50, 57], [58, 62], [63, 66], [67, 75], [76, 78], [79, 88], [89, 96], [97, 101], [102, 108], [109, 112], [113, 121], [122, 124], [125, 130], [130, 131], [132, 136], [136, 137], [138, 144], [144, 145], [146, 153], [154, 157], [158, 162], [163, 171], [172, 180], [180, 181]]}
{"doc_key": "ai-dev-19", "ner": [[6, 6, "person"], [15, 20, "person"], [25, 25, "organisation"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[25, 25, 15, 20, "origin", "", false, false], [23, 23, 25, 25, "artifact", "builds", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "company", "was", "founded", "by", "Kiichiro", "Toyoda", "in", "1937", "as", "a", "spin", "-", "off", "from", "Toyota", "Satoshi", ",", "the", "company", "that", "created", "the", "car", "Toyota", "Industries", "."], "sentence-detokenized": "The company was founded by Kiichiro Toyoda in 1937 as a spin-off from Toyota Satoshi, the company that created the car Toyota Industries.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 26], [27, 35], [36, 42], [43, 45], [46, 50], [51, 53], [54, 55], [56, 60], [60, 61], [61, 64], [65, 69], [70, 76], [77, 84], [84, 85], [86, 89], [90, 97], [98, 102], [103, 110], [111, 114], [115, 118], [119, 125], [126, 136], [136, 137]]}
{"doc_key": "ai-dev-20", "ner": [[0, 1, "field"], [51, 52, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[51, 52, 0, 1, "origin", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Unsupervised", "learning", ",", "on", "the", "other", "hand", ",", "assumes", "that", "the", "training", "data", "is", "not", "hand", "-", "labelled", "and", "attempts", "to", "find", "inherent", "patterns", "in", "the", "data", "that", "can", "then", "be", "used", "to", "determine", "the", "correct", "output", "values", "for", "new", "data", "instances", ".", "A", "recently", "explored", "combination", "of", "the", "two", "is", "semi-supervised", "learning", ",", "which", "uses", "a", "combination", "of", "labelled", "and", "unlabelled", "data", "(", "usually", "a", "small", "set", "of", "labelled", "data", "combined", "with", "a", "large", "amount", "of", "unlabelled", "data", ")", "."], "sentence-detokenized": "Unsupervised learning, on the other hand, assumes that the training data is not hand-labelled and attempts to find inherent patterns in the data that can then be used to determine the correct output values for new data instances. A recently explored combination of the two is semi-supervised learning, which uses a combination of labelled and unlabelled data (usually a small set of labelled data combined with a large amount of unlabelled data).", "token2charspan": [[0, 12], [13, 21], [21, 22], [23, 25], [26, 29], [30, 35], [36, 40], [40, 41], [42, 49], [50, 54], [55, 58], [59, 67], [68, 72], [73, 75], [76, 79], [80, 84], [84, 85], [85, 93], [94, 97], [98, 106], [107, 109], [110, 114], [115, 123], [124, 132], [133, 135], [136, 139], [140, 144], [145, 149], [150, 153], [154, 158], [159, 161], [162, 166], [167, 169], [170, 179], [180, 183], [184, 191], [192, 198], [199, 205], [206, 209], [210, 213], [214, 218], [219, 228], [228, 229], [230, 231], [232, 240], [241, 249], [250, 261], [262, 264], [265, 268], [269, 272], [273, 275], [276, 291], [292, 300], [300, 301], [302, 307], [308, 312], [313, 314], [315, 326], [327, 329], [330, 338], [339, 342], [343, 353], [354, 358], [359, 360], [360, 367], [368, 369], [370, 375], [376, 379], [380, 382], [383, 391], [392, 396], [397, 405], [406, 410], [411, 412], [413, 418], [419, 425], [426, 428], [429, 439], [440, 444], [444, 445], [445, 446]]}
{"doc_key": "ai-dev-21", "ner": [[23, 23, "organisation"], [25, 25, "product"], [27, 28, "organisation"], [30, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[25, 25, 23, 23, "artifact", "", false, false], [27, 28, 30, 30, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["While", "these", "humanoid", "robots", "are", "used", "for", "utilitarian", "purposes", ",", "there", "are", "also", "some", "humanoid", "robots", "intended", "for", "entertainment", "purposes", ",", "such", "as", "Sony", "'s", "QRIO", "and", "Wow", "Wee", "'s", "RoboSapien", "."], "sentence-detokenized": "While these humanoid robots are used for utilitarian purposes, there are also some humanoid robots intended for entertainment purposes, such as Sony's QRIO and Wow Wee's RoboSapien.", "token2charspan": [[0, 5], [6, 11], [12, 20], [21, 27], [28, 31], [32, 36], [37, 40], [41, 52], [53, 61], [61, 62], [63, 68], [69, 72], [73, 77], [78, 82], [83, 91], [92, 98], [99, 107], [108, 111], [112, 125], [126, 134], [134, 135], [136, 140], [141, 143], [144, 148], [148, 150], [151, 155], [156, 159], [160, 163], [164, 167], [167, 169], [170, 180], [180, 181]]}
{"doc_key": "ai-dev-22", "ner": [[0, 0, "researcher"], [5, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 12, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Weber", "became", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "in", "1991", "."], "sentence-detokenized": "Weber became a Fellow of the Association for the Advancement of Artificial Intelligence in 1991.", "token2charspan": [[0, 5], [6, 12], [13, 14], [15, 21], [22, 24], [25, 28], [29, 40], [41, 44], [45, 48], [49, 60], [61, 63], [64, 74], [75, 87], [88, 90], [91, 95], [95, 96]]}
{"doc_key": "ai-dev-23", "ner": [[6, 7, "field"], [9, 9, "field"], [20, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 23, 6, 7, "part-of", "task_part_of_field", false, false], [20, 23, 9, 9, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["At", "this", "company", "he", "is", "developing", "data", "mining", "and", "database", "technologies", ",", "and", "more", "specifically", "advanced", "ontologies", "for", "intelligent", "and", "automated", "natural", "language", "understanding", "."], "sentence-detokenized": "At this company he is developing data mining and database technologies, and more specifically advanced ontologies for intelligent and automated natural language understanding.", "token2charspan": [[0, 2], [3, 7], [8, 15], [16, 18], [19, 21], [22, 32], [33, 37], [38, 44], [45, 48], [49, 57], [58, 70], [70, 71], [72, 75], [76, 80], [81, 93], [94, 102], [103, 113], [114, 117], [118, 129], [130, 133], [134, 143], [144, 151], [152, 160], [161, 174], [174, 175]]}
{"doc_key": "ai-dev-24", "ner": [[24, 26, "misc"], [28, 32, "misc"], [34, 35, "misc"], [36, 37, "country"], [40, 45, "organisation"], [43, 43, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[24, 26, 36, 37, "physical", "", false, false], [28, 32, 36, 37, "physical", "", false, false], [34, 35, 36, 37, "physical", "", false, false], [40, 45, 43, 43, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["However", ",", "in", "the", "last", "few", "years", "one", "can", "see", "the", "emergence", "of", "different", "e-services", "and", "related", "initiatives", "in", "developing", "countries", ",", "such", "as", "the", "Nemmadi", "project", ",", "the", "MCA21", "mission", "model", "project", "or", "Digital", "India", "in", "India", ",", "the", "e-Government", "Bureau", "in", "Pakistan", ",", "etc", "."], "sentence-detokenized": "However, in the last few years one can see the emergence of different e-services and related initiatives in developing countries, such as the Nemmadi project, the MCA21 mission model project or Digital India in India, the e-Government Bureau in Pakistan, etc.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 15], [16, 20], [21, 24], [25, 30], [31, 34], [35, 38], [39, 42], [43, 46], [47, 56], [57, 59], [60, 69], [70, 80], [81, 84], [85, 92], [93, 104], [105, 107], [108, 118], [119, 128], [128, 129], [130, 134], [135, 137], [138, 141], [142, 149], [150, 157], [157, 158], [159, 162], [163, 168], [169, 176], [177, 182], [183, 190], [191, 193], [194, 201], [202, 207], [208, 210], [211, 216], [216, 217], [218, 221], [222, 234], [235, 241], [242, 244], [245, 253], [253, 254], [255, 258], [258, 259]]}
{"doc_key": "ai-dev-25", "ner": [[3, 3, "misc"], [5, 6, "field"], [8, 8, "field"], [19, 22, "university"], [25, 28, "university"], [13, 16, "university"], [34, 34, "misc"], [36, 37, "field"], [40, 43, "misc"], [44, 45, "university"], [47, 49, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 3, 5, 6, "topic", "", false, false], [3, 3, 8, 8, "topic", "", false, false], [3, 3, 19, 22, "origin", "", false, false], [19, 22, 25, 28, "part-of", "", false, false], [13, 16, 19, 22, "part-of", "", false, false], [34, 34, 36, 37, "topic", "", false, false], [34, 34, 44, 45, "origin", "", false, false], [40, 43, 44, 45, "origin", "", false, false], [44, 45, 47, 49, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["He", "obtained", "his", "PhD", "in", "radio", "physics", "and", "electronics", "as", "a", "student", "of", "the", "Indian", "Statistical", "Institute", "at", "the", "Rajabazar", "School", "of", "Science", "campus", "of", "the", "University", "of", "Calcutta", "in", "1979", ",", "and", "a", "PhD", "in", "electrical", "engineering", "and", "an", "Imperial", "College", "Diploma", "from", "Imperial", "College", ",", "University", "of", "London", "in", "1982", "."], "sentence-detokenized": "He obtained his PhD in radio physics and electronics as a student of the Indian Statistical Institute at the Rajabazar School of Science campus of the University of Calcutta in 1979, and a PhD in electrical engineering and an Imperial College Diploma from Imperial College, University of London in 1982.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 19], [20, 22], [23, 28], [29, 36], [37, 40], [41, 52], [53, 55], [56, 57], [58, 65], [66, 68], [69, 72], [73, 79], [80, 91], [92, 101], [102, 104], [105, 108], [109, 118], [119, 125], [126, 128], [129, 136], [137, 143], [144, 146], [147, 150], [151, 161], [162, 164], [165, 173], [174, 176], [177, 181], [181, 182], [183, 186], [187, 188], [189, 192], [193, 195], [196, 206], [207, 218], [219, 222], [223, 225], [226, 234], [235, 242], [243, 250], [251, 255], [256, 264], [265, 272], [272, 273], [274, 284], [285, 287], [288, 294], [295, 297], [298, 302], [302, 303]]}
{"doc_key": "ai-dev-26", "ner": [[0, 2, "location"], [20, 22, "misc"], [35, 36, "misc"], [28, 30, "person"], [31, 33, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[20, 22, 0, 2, "temporal", "", false, false], [35, 36, 0, 2, "temporal", "", false, false], [28, 30, 35, 36, "role", "actor_in", false, false], [31, 33, 35, 36, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "second", "Expo", "was", "announced", "as", "the", "world", "premiere", "location", "for", "several", "films", "never", "before", "seen", "in", "3D", ",", "including", "The", "Diamond", "Elves", "and", "Universal", "'s", "short", "film", "Mamie", "Van", "Doren", "and", "Pinky", "Lee", "'s", "Hawaiian", "Nights", "."], "sentence-detokenized": "The second Expo was announced as the world premiere location for several films never before seen in 3D, including The Diamond Elves and Universal's short film Mamie Van Doren and Pinky Lee's Hawaiian Nights.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 19], [20, 29], [30, 32], [33, 36], [37, 42], [43, 51], [52, 60], [61, 64], [65, 72], [73, 78], [79, 84], [85, 91], [92, 96], [97, 99], [100, 102], [102, 103], [104, 113], [114, 117], [118, 125], [126, 131], [132, 135], [136, 145], [145, 147], [148, 153], [154, 158], [159, 164], [165, 168], [169, 174], [175, 178], [179, 184], [185, 188], [188, 190], [191, 199], [200, 206], [206, 207]]}
{"doc_key": "ai-dev-27", "ner": [[7, 9, "researcher"], [16, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 9, 16, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "maximum", "subarray", "problem", "was", "introduced", "by", "Ulf", "Grenander", "in", "1977", "as", "a", "simplified", "model", "for", "maximum", "likelihood", "estimation", "of", "patterns", "in", "digitised", "images", "."], "sentence-detokenized": "The maximum subarray problem was introduced by Ulf Grenander in 1977 as a simplified model for maximum likelihood estimation of patterns in digitised images.", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 28], [29, 32], [33, 43], [44, 46], [47, 50], [51, 60], [61, 63], [64, 68], [69, 71], [72, 73], [74, 84], [85, 90], [91, 94], [95, 102], [103, 113], [114, 124], [125, 127], [128, 136], [137, 139], [140, 149], [150, 156], [156, 157]]}
{"doc_key": "ai-dev-28", "ner": [[0, 2, "product"], [4, 5, "product"], [7, 9, "product"], [12, 12, "product"], [14, 16, "product"], [18, 21, "product"], [27, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[27, 27, 0, 2, "part-of", "", false, false], [27, 27, 4, 5, "part-of", "", false, false], [27, 27, 7, 9, "part-of", "", false, false], [27, 27, 12, 12, "part-of", "", false, false], [27, 27, 14, 16, "part-of", "", false, false], [27, 27, 18, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "iPhone", "4S", ",", "iPad", "3", ",", "iPad", "Mini", "1G", ",", "iPad", "Air", ",", "iPad", "Pro", "1G", ",", "iPod", "Touch", "5", "G", "and", "onwards", "are", "equipped", "with", "Siri", ",", "a", "more", "advanced", "voice", "assistant", "."], "sentence-detokenized": "The iPhone 4S, iPad 3, iPad Mini 1G, iPad Air, iPad Pro 1G, iPod Touch 5G and onwards are equipped with Siri, a more advanced voice assistant.", "token2charspan": [[0, 3], [4, 10], [11, 13], [13, 14], [15, 19], [20, 21], [21, 22], [23, 27], [28, 32], [33, 35], [35, 36], [37, 41], [42, 45], [45, 46], [47, 51], [52, 55], [56, 58], [58, 59], [60, 64], [65, 70], [71, 72], [72, 73], [74, 77], [78, 85], [86, 89], [90, 98], [99, 103], [104, 108], [108, 109], [110, 111], [112, 116], [117, 125], [126, 131], [132, 141], [141, 142]]}
{"doc_key": "ai-dev-29", "ner": [[7, 8, "metrics"], [11, 14, "metrics"], [16, 17, "metrics"], [58, 61, "metrics"], [66, 71, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 14, 58, 61, "named", "", false, false], [16, 17, 11, 14, "named", "", false, false], [58, 61, 66, 71, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["It", "is", "easy", "to", "check", "that", "the", "logistic", "loss", "and", "the", "binary", "cross", "-entropy", "loss", "(", "Log", "loss", ")", "are", "actually", "the", "same", "(", "at", "most", "a", "multiplicative", "constant", "math", "/", "frac", "{", "1", "}", "{", "log", "(", "2", ")", "}", "/", "math", ")", ".", "{", "1", "}", "log", "(", "2", ")", "}", "/", "math", ")", ".", "The", "cross", "-entropy", "loss", "is", "closely", "related", "to", "the", "Kullback", "-", "Leibler", "divergence", "between", "the", "empirical", "and", "predictive", "distributions", "."], "sentence-detokenized": "It is easy to check that the logistic loss and the binary cross-entropy loss (Log loss) are actually the same (at most a multiplicative constant math/ frac {1} { log (2)} / math). {1} log (2)} / math) . The cross-entropy loss is closely related to the Kullback-Leibler divergence between the empirical and predictive distributions.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 13], [14, 19], [20, 24], [25, 28], [29, 37], [38, 42], [43, 46], [47, 50], [51, 57], [58, 63], [63, 71], [72, 76], [77, 78], [78, 81], [82, 86], [86, 87], [88, 91], [92, 100], [101, 104], [105, 109], [110, 111], [111, 113], [114, 118], [119, 120], [121, 135], [136, 144], [145, 149], [149, 150], [151, 155], [156, 157], [157, 158], [158, 159], [160, 161], [162, 165], [166, 167], [167, 168], [168, 169], [169, 170], [171, 172], [173, 177], [177, 178], [178, 179], [180, 181], [181, 182], [182, 183], [184, 187], [188, 189], [189, 190], [190, 191], [191, 192], [193, 194], [195, 199], [199, 200], [201, 202], [203, 206], [207, 212], [212, 220], [221, 225], [226, 228], [229, 236], [237, 244], [245, 247], [248, 251], [252, 260], [260, 261], [261, 268], [269, 279], [280, 287], [288, 291], [292, 301], [302, 305], [306, 316], [317, 330], [330, 331]]}
{"doc_key": "ai-dev-30", "ner": [[11, 13, "algorithm"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[22, 23, 11, 13, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "cases", "where", "the", "equations", "can", "not", "be", "solved", "directly", ",", "the", "EM", "algorithm", "is", "used", "to", "find", "the", "(", "local", ")", "maximum", "likelihood", "parameter", "of", "the", "statistical", "model", "."], "sentence-detokenized": "In cases where the equations cannot be solved directly, the EM algorithm is used to find the (local) maximum likelihood parameter of the statistical model.", "token2charspan": [[0, 2], [3, 8], [9, 14], [15, 18], [19, 28], [29, 32], [32, 35], [36, 38], [39, 45], [46, 54], [54, 55], [56, 59], [60, 62], [63, 72], [73, 75], [76, 80], [81, 83], [84, 88], [89, 92], [93, 94], [94, 99], [99, 100], [101, 108], [109, 119], [120, 129], [130, 132], [133, 136], [137, 148], [149, 154], [154, 155]]}
{"doc_key": "ai-dev-31", "ner": [[11, 12, "task"], [15, 16, "task"], [18, 19, "task"], [21, 22, "task"], [28, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "research", "has", "been", "the", "basis", "for", "the", "development", "of", "modern", "speech", "synthesis", "technology", ",", "blind", "readers", ",", "speech", "perception", "and", "speech", "recognition", "research", "and", "the", "development", "of", "speech", "perception", "motion", "theory", "."], "sentence-detokenized": "This research has been the basis for the development of modern speech synthesis technology, blind readers, speech perception and speech recognition research and the development of speech perception motion theory.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 22], [23, 26], [27, 32], [33, 36], [37, 40], [41, 52], [53, 55], [56, 62], [63, 69], [70, 79], [80, 90], [90, 91], [92, 97], [98, 105], [105, 106], [107, 113], [114, 124], [125, 128], [129, 135], [136, 147], [148, 156], [157, 160], [161, 164], [165, 176], [177, 179], [180, 186], [187, 197], [198, 204], [205, 211], [211, 212]]}
{"doc_key": "ai-dev-32", "ner": [[0, 1, "product"], [2, 4, "misc"], [6, 6, "misc"], [10, 12, "misc"], [15, 15, "product"], [17, 17, "product"], [19, 19, "product"], [27, 27, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 4, 0, 1, "origin", "", false, false], [2, 4, 10, 12, "type-of", "", false, false], [2, 4, 15, 15, "related-to", "program_for", false, false], [2, 4, 17, 17, "related-to", "program_for", false, false], [2, 4, 19, 19, "related-to", "program_for", false, false], [2, 4, 27, 27, "related-to", "program_for", false, false], [6, 6, 2, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "Arduino", "Integrated", "Development", "Environment", "(", "IDE", ")", "is", "a", "cross", "-platform", "application", "(", "for", "Windows", ",", "macOS", "and", "Linux", ")", ",", "written", "in", "the", "programming", "language", "Java", "."], "sentence-detokenized": "The Arduino Integrated Development Environment (IDE) is a cross-platform application (for Windows, macOS and Linux), written in the programming language Java.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 34], [35, 46], [47, 48], [48, 51], [51, 52], [53, 55], [56, 57], [58, 63], [63, 72], [73, 84], [85, 86], [86, 89], [90, 97], [97, 98], [99, 104], [105, 108], [109, 114], [114, 115], [115, 116], [117, 124], [125, 127], [128, 131], [132, 143], [144, 152], [153, 157], [157, 158]]}
{"doc_key": "ai-dev-33", "ner": [[17, 18, "algorithm"], [4, 5, "field"], [8, 9, "researcher"], [11, 12, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[17, 18, 4, 5, "opposite", "", false, false], [8, 9, 4, 5, "related-to", "works_with", false, false], [11, 12, 4, 5, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["After", "the", "publication", "of", "machine", "learning", "research", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", ",", "neural", "network", "research", "stagnated", "."], "sentence-detokenized": "After the publication of machine learning research by Marvin Minsky and Seymour Papert (1969), neural network research stagnated.", "token2charspan": [[0, 5], [6, 9], [10, 21], [22, 24], [25, 32], [33, 41], [42, 50], [51, 53], [54, 60], [61, 67], [68, 71], [72, 79], [80, 86], [87, 88], [88, 92], [92, 93], [93, 94], [95, 101], [102, 109], [110, 118], [119, 128], [128, 129]]}
{"doc_key": "ai-dev-34", "ner": [[19, 20, "organisation"], [22, 22, "organisation"], [25, 28, "country"], [29, 32, "organisation"], [35, 35, "country"], [37, 38, "organisation"], [41, 41, "country"], [43, 43, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[29, 32, 25, 28, "general-affiliation", "", false, false], [37, 38, 35, 35, "general-affiliation", "", false, false], [43, 43, 41, 41, "general-affiliation", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Only", "a", "few", "non-Japanese", "companies", "were", "eventually", "able", "to", "survive", "in", "this", "market", ",", "the", "main", "ones", "being", ":", "Adept", "Technology", ",", "St\u00e4ubli", ",", "the", "Swedish", "-", "Swiss", "company", "ABB", "Asea", "Brown", "Boveri", ",", "the", "German", "company", "KUKA", "Robotics", "and", "the", "Italian", "company", "Comau", "."], "sentence-detokenized": "Only a few non-Japanese companies were eventually able to survive in this market, the main ones being: Adept Technology, St\u00e4ubli, the Swedish-Swiss company ABB Asea Brown Boveri, the German company KUKA Robotics and the Italian company Comau.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 23], [24, 33], [34, 38], [39, 49], [50, 54], [55, 57], [58, 65], [66, 68], [69, 73], [74, 80], [80, 81], [82, 85], [86, 90], [91, 95], [96, 101], [101, 102], [103, 108], [109, 119], [119, 120], [121, 128], [128, 129], [130, 133], [134, 141], [141, 142], [142, 147], [148, 155], [156, 159], [160, 164], [165, 170], [171, 177], [177, 178], [179, 182], [183, 189], [190, 197], [198, 202], [203, 211], [212, 215], [216, 219], [220, 227], [228, 235], [236, 241], [241, 242]]}
{"doc_key": "ai-dev-35", "ner": [[9, 11, "conference"], [16, 17, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 17, 9, 11, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "research", "activities", "include", "an", "annual", "research", "conference", ",", "the", "RuleML", "Workshop", ",", "also", "known", "as", "RuleML", "for", "short", "."], "sentence-detokenized": "The research activities include an annual research conference, the RuleML Workshop, also known as RuleML for short.", "token2charspan": [[0, 3], [4, 12], [13, 23], [24, 31], [32, 34], [35, 41], [42, 50], [51, 61], [61, 62], [63, 66], [67, 73], [74, 82], [82, 83], [84, 88], [89, 94], [95, 97], [98, 104], [105, 108], [109, 114], [114, 115]]}
{"doc_key": "ai-dev-36", "ner": [[9, 9, "field"], [11, 12, "field"], [14, 14, "field"], [16, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Concepts", "are", "used", "as", "formal", "tools", "or", "models", "in", "mathematics", ",", "computer", "science", ",", "databases", "and", "artificial", "intelligence", ",", "and", "they", "are", "sometimes", "referred", "to", "as", "classes", ",", "patterns", "or", "categories", "."], "sentence-detokenized": "Concepts are used as formal tools or models in mathematics, computer science, databases and artificial intelligence, and they are sometimes referred to as classes, patterns or categories.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 20], [21, 27], [28, 33], [34, 36], [37, 43], [44, 46], [47, 58], [58, 59], [60, 68], [69, 76], [76, 77], [78, 87], [88, 91], [92, 102], [103, 115], [115, 116], [117, 120], [121, 125], [126, 129], [130, 139], [140, 148], [149, 151], [152, 154], [155, 162], [162, 163], [164, 172], [173, 175], [176, 186], [186, 187]]}
{"doc_key": "ai-dev-37", "ner": [[6, 8, "organisation"], [10, 14, "organisation"], [16, 17, "organisation"], [19, 21, "organisation"], [23, 26, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "received", "awards", "from", "the", "American", "Psychological", "Association", ",", "the", "National", "Academy", "of", "Sciences", ",", "the", "Royal", ",", "Cognitive", "Neuroscience", "Society", "and", "the", "American", "Humanist", "Association", "."], "sentence-detokenized": "He has received awards from the American Psychological Association, the National Academy of Sciences, the Royal, Cognitive Neuroscience Society and the American Humanist Association.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 22], [23, 27], [28, 31], [32, 40], [41, 54], [55, 66], [66, 67], [68, 71], [72, 80], [81, 88], [89, 91], [92, 100], [100, 101], [102, 105], [106, 111], [111, 112], [113, 122], [123, 135], [136, 143], [144, 147], [148, 151], [152, 160], [161, 169], [170, 181], [181, 182]]}
{"doc_key": "ai-dev-38", "ner": [[1, 2, "person"], [4, 5, "person"], [7, 8, "person"], [16, 19, "person"], [22, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[22, 27, 16, 19, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Starring", "Harrison", "Ford", ",", "Rutger", "Hauer", "and", "Sean", "Young", ",", "the", "film", "is", "loosely", "based", "on", "Philip", "K", ".", "Dick", "'s", "novel", "Do", "Androids", "Dream", "of", "Electric", "Sheep", "(", "1968", ")", "."], "sentence-detokenized": "Starring Harrison Ford, Rutger Hauer and Sean Young, the film is loosely based on Philip K. Dick's novel Do Androids Dream of Electric Sheep (1968).", "token2charspan": [[0, 8], [9, 17], [18, 22], [22, 23], [24, 30], [31, 36], [37, 40], [41, 45], [46, 51], [51, 52], [53, 56], [57, 61], [62, 64], [65, 72], [73, 78], [79, 81], [82, 88], [89, 90], [90, 91], [92, 96], [96, 98], [99, 104], [105, 107], [108, 116], [117, 122], [123, 125], [126, 134], [135, 140], [141, 142], [142, 146], [146, 147], [147, 148]]}
{"doc_key": "ai-dev-39", "ner": [[0, 1, "task"], [3, 6, "algorithm"], [12, 13, "field"], [15, 16, "task"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 3, 6, "usage", "", false, false], [0, 1, 12, 13, "part-of", "task_part_of_field", false, false], [0, 1, 15, 16, "part-of", "task_part_of_field", false, false], [0, 1, 18, 19, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Image", "segmentation", "using", "the", "k-means", "clustering", "algorithm", "has", "long", "been", "used", "in", "pattern", "recognition", ",", "object", "detection", "and", "medical", "imaging", "."], "sentence-detokenized": "Image segmentation using the k-means clustering algorithm has long been used in pattern recognition, object detection and medical imaging.", "token2charspan": [[0, 5], [6, 18], [19, 24], [25, 28], [29, 36], [37, 47], [48, 57], [58, 61], [62, 66], [67, 71], [72, 76], [77, 79], [80, 87], [88, 99], [99, 100], [101, 107], [108, 117], [118, 121], [122, 129], [130, 137], [137, 138]]}
{"doc_key": "ai-dev-40", "ner": [[15, 15, "algorithm"], [17, 18, "algorithm"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["General", "sampling", "from", "a", "truncated", "normal", "line", "can", "be", "achieved", "using", "approximations", "to", "the", "normal", "CDF", "and", "probit", "functions", ",", "and", "R", "has", "a", "function", "codertnorm", "(", ")", "/", "code", "that", "generates", "samples", "of", "the", "truncated", "normal", "line", "."], "sentence-detokenized": "General sampling from a truncated normal line can be achieved using approximations to the normal CDF and probit functions, and R has a function codertnorm () / code that generates samples of the truncated normal line.", "token2charspan": [[0, 7], [8, 16], [17, 21], [22, 23], [24, 33], [34, 40], [41, 45], [46, 49], [50, 52], [53, 61], [62, 67], [68, 82], [83, 85], [86, 89], [90, 96], [97, 100], [101, 104], [105, 111], [112, 121], [121, 122], [123, 126], [127, 128], [129, 132], [133, 134], [135, 143], [144, 154], [155, 156], [156, 157], [158, 159], [160, 164], [165, 169], [170, 179], [180, 187], [188, 190], [191, 194], [195, 204], [205, 211], [212, 216], [216, 217]]}
{"doc_key": "ai-dev-41", "ner": [[6, 7, "university"], [9, 12, "university"], [14, 16, "university"], [18, 20, "university"], [22, 23, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "also", "holds", "honorary", "doctorates", "from", "Newcastle", "University", ",", "the", "University", "of", "Surrey", ",", "Tel", "Aviv", "University", ",", "Simon", "Fraser", "University", "and", "Troms\u00f8", "University", "."], "sentence-detokenized": "He also holds honorary doctorates from Newcastle University, the University of Surrey, Tel Aviv University, Simon Fraser University and Troms\u00f8 University.", "token2charspan": [[0, 2], [3, 7], [8, 13], [14, 22], [23, 33], [34, 38], [39, 48], [49, 59], [59, 60], [61, 64], [65, 75], [76, 78], [79, 85], [85, 86], [87, 90], [91, 95], [96, 106], [106, 107], [108, 113], [114, 120], [121, 131], [132, 135], [136, 142], [143, 153], [153, 154]]}
{"doc_key": "ai-dev-42", "ner": [[1, 1, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "Java", "implementation", "using", "zero", "-", "based", "array", "indexing", ",", "and", "a", "handy", "method", "for", "printing", "the", "order", "of", "resolved", "operations", "."], "sentence-detokenized": "A Java implementation using zero-based array indexing, and a handy method for printing the order of resolved operations.", "token2charspan": [[0, 1], [2, 6], [7, 21], [22, 27], [28, 32], [32, 33], [33, 38], [39, 44], [45, 53], [53, 54], [55, 58], [59, 60], [61, 66], [67, 73], [74, 77], [78, 86], [87, 90], [91, 96], [97, 99], [100, 108], [109, 119], [119, 120]]}
{"doc_key": "ai-dev-43", "ner": [[7, 8, "metrics"], [11, 12, "metrics"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Such", "networks", "are", "usually", "trained", "in", "the", "cross", "-entropy", "(", "or", "cross", "-entropy", ")", "regime", ",", "giving", "a", "non-linear", "multinomial", "logistic", "regression", "variant", "."], "sentence-detokenized": "Such networks are usually trained in the cross-entropy (or cross-entropy) regime, giving a non-linear multinomial logistic regression variant.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 25], [26, 33], [34, 36], [37, 40], [41, 46], [46, 54], [55, 56], [56, 58], [59, 64], [64, 72], [72, 73], [74, 80], [80, 81], [82, 88], [89, 90], [91, 101], [102, 113], [114, 122], [123, 133], [134, 141], [141, 142]]}
{"doc_key": "ai-dev-44", "ner": [[0, 1, "conference"], [4, 4, "misc"], [6, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ACL", "has", "a", "European", "(", "European", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ")", "."], "sentence-detokenized": "The ACL has a European (European Chapter of the Association for Computational Linguistics).", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 13], [14, 22], [23, 24], [24, 32], [33, 40], [41, 43], [44, 47], [48, 59], [60, 63], [64, 77], [78, 89], [89, 90], [90, 91]]}
{"doc_key": "ai-dev-45", "ner": [[3, 4, "researcher"], [6, 8, "researcher"], [28, 28, "misc"], [27, 31, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 28, 28, "role", "", false, false], [6, 8, 28, 28, "role", "", false, false], [28, 28, 27, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "professors", ",", "Hal", "Ibbetson", "and", "Gerald", "Jay", "Sussman", ",", "chose", "to", "remain", "neutral", "-", "and", "for", "the", "next", "30", "years", "their", "group", "was", "variously", "known", "as", "the", "Swiss", "and", "MAC", "projects", "."], "sentence-detokenized": "Two professors, Hal Ibbetson and Gerald Jay Sussman, chose to remain neutral - and for the next 30 years their group was variously known as the Swiss and MAC projects.", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 28], [29, 32], [33, 39], [40, 43], [44, 51], [51, 52], [53, 58], [59, 61], [62, 68], [69, 76], [77, 78], [79, 82], [83, 86], [87, 90], [91, 95], [96, 98], [99, 104], [105, 110], [111, 116], [117, 120], [121, 130], [131, 136], [137, 139], [140, 143], [144, 149], [150, 153], [154, 157], [158, 166], [166, 167]]}
{"doc_key": "ai-dev-46", "ner": [[2, 2, "misc"], [4, 4, "researcher"], [7, 10, "university"], [15, 15, "organisation"], [19, 22, "organisation"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 4, 4, "temporal", "", false, false], [4, 4, 15, 15, "physical", "", false, false], [4, 4, 15, 15, "role", "", false, false], [4, 4, 19, 22, "role", "", false, false], [19, 22, 7, 10, "part-of", "", false, false], [26, 27, 19, 22, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["After", "his", "PhD", ",", "Ghahramani", "moved", "to", "the", "University", "of", "Toronto", "in", "1995", "as", "an", "ITRC", "postdoctoral", "researcher", "in", "the", "Artificial", "Intelligence", "Lab", ",", "working", "with", "Geoffrey", "Hinton", "."], "sentence-detokenized": "After his PhD, Ghahramani moved to the University of Toronto in 1995 as an ITRC postdoctoral researcher in the Artificial Intelligence Lab, working with Geoffrey Hinton.", "token2charspan": [[0, 5], [6, 9], [10, 13], [13, 14], [15, 25], [26, 31], [32, 34], [35, 38], [39, 49], [50, 52], [53, 60], [61, 63], [64, 68], [69, 71], [72, 74], [75, 79], [80, 92], [93, 103], [104, 106], [107, 110], [111, 121], [122, 134], [135, 138], [138, 139], [140, 147], [148, 152], [153, 161], [162, 168], [168, 169]]}
{"doc_key": "ai-dev-47", "ner": [[22, 23, "metrics"], [25, 25, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[25, 25, 22, 23, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Subsequent", "work", "focused", "on", "solving", "these", "problems", ",", "but", "it", "was", "not", "until", "the", "advent", "of", "modern", "computers", "and", "the", "spread", "of", "maximum", "likelihood", "(", "MLE", ")", "parameterisation", "techniques", "that", "research", "really", "took", "off", "."], "sentence-detokenized": "Subsequent work focused on solving these problems, but it was not until the advent of modern computers and the spread of maximum likelihood (MLE) parameterisation techniques that research really took off.", "token2charspan": [[0, 10], [11, 15], [16, 23], [24, 26], [27, 34], [35, 40], [41, 49], [49, 50], [51, 54], [55, 57], [58, 61], [62, 65], [66, 71], [72, 75], [76, 82], [83, 85], [86, 92], [93, 102], [103, 106], [107, 110], [111, 117], [118, 120], [121, 128], [129, 139], [140, 141], [141, 144], [144, 145], [146, 162], [163, 173], [174, 178], [179, 187], [188, 194], [195, 199], [200, 203], [203, 204]]}
{"doc_key": "ai-dev-48", "ner": [[5, 6, "person"], [9, 10, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "play", "is", "produced", "by", "David", "Fincher", "and", "stars", "Kevin", "Spacey", "."], "sentence-detokenized": "The play is produced by David Fincher and stars Kevin Spacey.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 20], [21, 23], [24, 29], [30, 37], [38, 41], [42, 47], [48, 53], [54, 60], [60, 61]]}
{"doc_key": "ai-dev-49", "ner": [[10, 10, "metrics"], [22, 23, "algorithm"], [29, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 23, 29, 31, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Current", "in", "silico", "methods", "often", "have", "to", "trade", "speed", "for", "accuracy", "due", "to", "computational", "capacity", "limitations", ";", "for", "example", ",", "using", "fast", "protein", "docking", "methods", "rather", "than", "computationally", "expensive", "free", "energy", "calculations", "."], "sentence-detokenized": "Current in silico methods often have to trade speed for accuracy due to computational capacity limitations; for example, using fast protein docking methods rather than computationally expensive free energy calculations.", "token2charspan": [[0, 7], [8, 10], [11, 17], [18, 25], [26, 31], [32, 36], [37, 39], [40, 45], [46, 51], [52, 55], [56, 64], [65, 68], [69, 71], [72, 85], [86, 94], [95, 106], [106, 107], [108, 111], [112, 119], [119, 120], [121, 126], [127, 131], [132, 139], [140, 147], [148, 155], [156, 162], [163, 167], [168, 183], [184, 193], [194, 198], [199, 205], [206, 218], [218, 219]]}
{"doc_key": "ai-dev-50", "ner": [[7, 9, "country"], [11, 11, "country"], [13, 13, "country"], [15, 15, "country"], [17, 17, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "has", "more", "than", "30", "locations", "in", "the", "United", "States", ",", "Canada", ",", "Mexico", ",", "Brazil", "and", "Argentina", "."], "sentence-detokenized": "It has more than 30 locations in the United States, Canada, Mexico, Brazil and Argentina.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 19], [20, 29], [30, 32], [33, 36], [37, 43], [44, 50], [50, 51], [52, 58], [58, 59], [60, 66], [66, 67], [68, 74], [75, 78], [79, 88], [88, 89]]}
{"doc_key": "ai-dev-51", "ner": [[5, 6, "field"], [10, 13, "product"], [15, 16, "algorithm"], [19, 20, "task"], [22, 23, "task"], [30, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 13, 5, 6, "part-of", "", false, false], [10, 13, 15, 16, "usage", "", false, false], [19, 20, 5, 6, "part-of", "task_part_of_field", false, false], [19, 20, 30, 30, "related-to", "performs", false, false], [22, 23, 5, 6, "part-of", "task_part_of_field", false, false], [22, 23, 30, 30, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["An", "example", "of", "a", "typical", "computer", "vision", "computational", "pipeline", "for", "a", "facial", "recognition", "system", "using", "k", "-NN", ",", "including", "feature", "extraction", "and", "dimensionality", "reduction", "pre-processing", "steps", "(", "usually", "implemented", "with", "OpenCV", ")", "."], "sentence-detokenized": "An example of a typical computer vision computational pipeline for a facial recognition system using k-NN, including feature extraction and dimensionality reduction pre-processing steps (usually implemented with OpenCV).", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 23], [24, 32], [33, 39], [40, 53], [54, 62], [63, 66], [67, 68], [69, 75], [76, 87], [88, 94], [95, 100], [101, 102], [102, 105], [105, 106], [107, 116], [117, 124], [125, 135], [136, 139], [140, 154], [155, 164], [165, 179], [180, 185], [186, 187], [187, 194], [195, 206], [207, 211], [212, 218], [218, 219], [219, 220]]}
{"doc_key": "ai-dev-52", "ner": [[8, 10, "algorithm"], [13, 13, "misc"], [15, 16, "misc"], [18, 18, "misc"], [22, 22, "programlang"], [24, 24, "product"], [28, 29, "algorithm"], [31, 32, "misc"], [34, 34, "misc"], [38, 38, "misc"], [44, 44, "misc"], [46, 47, "misc"], [49, 50, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "has", "a", "rich", "set", "of", "features", ",", "constraint", "logic", "programming", "libraries", ",", "multi-threading", ",", "unit", "testing", ",", "GUI", ",", "interfaces", "with", "Java", ",", "ODBC", "and", "others", ",", "literate", "programming", ",", "web", "server", ",", "SGML", ",", "RDF", ",", "RDFS", ",", "developer", "tools", "(", "including", "IDE", "with", "GUI", "debugger", "and", "GUI", "profiler", ")", "and", "extensive", "documentation", "."], "sentence-detokenized": "It has a rich set of features, constraint logic programming libraries, multi-threading, unit testing, GUI, interfaces with Java, ODBC and others, literate programming, web server, SGML, RDF, RDFS, developer tools (including IDE with GUI debugger and GUI profiler) and extensive documentation.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 13], [14, 17], [18, 20], [21, 29], [29, 30], [31, 41], [42, 47], [48, 59], [60, 69], [69, 70], [71, 86], [86, 87], [88, 92], [93, 100], [100, 101], [102, 105], [105, 106], [107, 117], [118, 122], [123, 127], [127, 128], [129, 133], [134, 137], [138, 144], [144, 145], [146, 154], [155, 166], [166, 167], [168, 171], [172, 178], [178, 179], [180, 184], [184, 185], [186, 189], [189, 190], [191, 195], [195, 196], [197, 206], [207, 212], [213, 214], [214, 223], [224, 227], [228, 232], [233, 236], [237, 245], [246, 249], [250, 253], [254, 262], [262, 263], [264, 267], [268, 277], [278, 291], [291, 292]]}
{"doc_key": "ai-dev-53", "ner": [[1, 2, "field"], [4, 5, "field"], [10, 13, "misc"], [15, 17, "misc"], [22, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 13, 1, 2, "part-of", "", true, false], [10, 13, 4, 5, "part-of", "", false, false], [10, 13, 22, 25, "type-of", "", false, false], [15, 17, 1, 2, "part-of", "", false, false], [15, 17, 4, 5, "part-of", "", false, false], [15, 17, 22, 25, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "computer", "vision", "and", "image", "processing", ",", "the", "concept", "of", "scale", "-", "space", "representation", "and", "Gaussian", "derivative", "operators", "is", "used", "as", "a", "typical", "multi", "-scale", "representation", "."], "sentence-detokenized": "In computer vision and image processing, the concept of scale-space representation and Gaussian derivative operators is used as a typical multi-scale representation.", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 22], [23, 28], [29, 39], [39, 40], [41, 44], [45, 52], [53, 55], [56, 61], [61, 62], [62, 67], [68, 82], [83, 86], [87, 95], [96, 106], [107, 116], [117, 119], [120, 124], [125, 127], [128, 129], [130, 137], [138, 143], [143, 149], [150, 164], [164, 165]]}
{"doc_key": "ai-dev-54", "ner": [[5, 10, "organisation"], [23, 30, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 10, 23, 30, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "also", "Chairman", "of", "the", "Neural", "Information", "Processing", "Systems", "Foundation", ",", "a", "not", "-", "for", "-", "profit", "organisation", "that", "oversees", "the", "annual", "meeting", "of", "the", "Neural", "Information", "Processing", "Systems", "Conference", "."], "sentence-detokenized": "He is also Chairman of the Neural Information Processing Systems Foundation, a not-for-profit organisation that oversees the annual meeting of the Neural Information Processing Systems Conference.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 19], [20, 22], [23, 26], [27, 33], [34, 45], [46, 56], [57, 64], [65, 75], [75, 76], [77, 78], [79, 82], [82, 83], [83, 86], [86, 87], [87, 93], [94, 106], [107, 111], [112, 120], [121, 124], [125, 131], [132, 139], [140, 142], [143, 146], [147, 153], [154, 165], [166, 176], [177, 184], [185, 195], [195, 196]]}
{"doc_key": "ai-dev-55", "ner": [[1, 2, "task"], [5, 6, "metrics"], [11, 15, "misc"], [17, 17, "task"], [19, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 5, 6, "usage", "", false, false], [5, 6, 11, 15, "type-of", "", false, false], [17, 17, 19, 20, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["For", "regression", "analysis", "problems", ",", "squared", "error", "can", "be", "used", "as", "the", "loss", "function", ",", "and", "for", "classification", ",", "cross", "entropy", "can", "be", "used", "."], "sentence-detokenized": "For regression analysis problems, squared error can be used as the loss function, and for classification, cross entropy can be used.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 32], [32, 33], [34, 41], [42, 47], [48, 51], [52, 54], [55, 59], [60, 62], [63, 66], [67, 71], [72, 80], [80, 81], [82, 85], [86, 89], [90, 104], [104, 105], [106, 111], [112, 119], [120, 123], [124, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-dev-56", "ner": [[0, 0, "researcher"], [26, 26, "conference"], [19, 24, "conference"], [36, 36, "university"], [39, 43, "field"], [51, 55, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 26, 26, "role", "", false, false], [0, 0, 36, 36, "physical", "", false, false], [0, 0, 36, 36, "role", "", false, false], [0, 0, 51, 55, "role", "", false, false], [26, 26, 19, 24, "named", "same", false, false], [36, 36, 39, 43, "related-to", "subject_of_study_at", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Rafferty", "has", "held", "many", "prestigious", "positions", ",", "including", "1", ")", "Program", "Co-", "Chair", "and", "General", "Co-", "Chair", "of", "the", "Conference", "on", "Neural", "Information", "Processing", "Systems", "(", "CNIPS", ")", "Foundation", "Conference", ";", "2", ")", "Co", "-Director", "of", "CMU", "'s", "new", "PhD", "program", "in", "Machine", "Learning", ";", "3", ")", "Associate", "Editor", "of", "the", "Journal", "of", "Machine", "Learning", "Research"], "sentence-detokenized": "Rafferty has held many prestigious positions, including 1) Program Co-Chair and General Co-Chair of the Conference on Neural Information Processing Systems (CNIPS) Foundation Conference; 2) Co-Director of CMU's new PhD program in Machine Learning; 3) Associate Editor of the Journal of Machine Learning Research", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 22], [23, 34], [35, 44], [44, 45], [46, 55], [56, 57], [57, 58], [59, 66], [67, 70], [70, 75], [76, 79], [80, 87], [88, 91], [91, 96], [97, 99], [100, 103], [104, 114], [115, 117], [118, 124], [125, 136], [137, 147], [148, 155], [156, 157], [157, 162], [162, 163], [164, 174], [175, 185], [185, 186], [187, 188], [188, 189], [190, 192], [192, 201], [202, 204], [205, 208], [208, 210], [211, 214], [215, 218], [219, 226], [227, 229], [230, 237], [238, 246], [246, 247], [248, 249], [249, 250], [251, 260], [261, 267], [268, 270], [271, 274], [275, 282], [283, 285], [286, 293], [294, 302], [303, 311]]}
{"doc_key": "ai-dev-57", "ner": [[0, 1, "misc"], [5, 5, "algorithm"], [7, 7, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 0, 1, "type-of", "", false, false], [7, 7, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Convex", "algorithms", ",", "such", "as", "AdaBoost", "and", "LogitBoost", ",", "can", "be", "defeated", "by", "random", "noise", "so", "that", "they", "can", "not", "learn", "basic", "and", "learnable", "combinations", "of", "weak", "hypotheses", "."], "sentence-detokenized": "Convex algorithms, such as AdaBoost and LogitBoost, can be defeated by random noise so that they cannot learn basic and learnable combinations of weak hypotheses.", "token2charspan": [[0, 6], [7, 17], [17, 18], [19, 23], [24, 26], [27, 35], [36, 39], [40, 50], [50, 51], [52, 55], [56, 58], [59, 67], [68, 70], [71, 77], [78, 83], [84, 86], [87, 91], [92, 96], [97, 100], [100, 103], [104, 109], [110, 115], [116, 119], [120, 129], [130, 142], [143, 145], [146, 150], [151, 161], [161, 162]]}
{"doc_key": "ai-dev-58", "ner": [[0, 0, "product"], [3, 7, "product"], [10, 13, "algorithm"], [20, 21, "algorithm"], [24, 25, "task"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 7, "type-of", "", false, false], [0, 0, 10, 13, "usage", "", false, false], [0, 0, 20, 21, "usage", "", false, false], [20, 21, 24, 25, "related-to", "used_for", true, false], [20, 21, 27, 29, "related-to", "used_for", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Apertium", "is", "a", "shallow", "transformation", "machine", "translation", "system", "that", "uses", "a", "finite", "state", "converter", "for", "all", "lexical", "transformations", "and", "a", "hidden", "Markov", "model", "for", "discourse", "tagging", "or", "word", "class", "disambiguation", "."], "sentence-detokenized": "Apertium is a shallow transformation machine translation system that uses a finite state converter for all lexical transformations and a hidden Markov model for discourse tagging or word class disambiguation.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 21], [22, 36], [37, 44], [45, 56], [57, 63], [64, 68], [69, 73], [74, 75], [76, 82], [83, 88], [89, 98], [99, 102], [103, 106], [107, 114], [115, 130], [131, 134], [135, 136], [137, 143], [144, 150], [151, 156], [157, 160], [161, 170], [171, 178], [179, 181], [182, 186], [187, 192], [193, 207], [207, 208]]}
{"doc_key": "ai-dev-59", "ner": [[0, 2, "misc"], [15, 17, "metrics"], [31, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 15, 17, "related-to", "", true, false], [15, 17, 31, 32, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "natural", "gradient", "of", "mathE", "f", "(", "x", ")", "/", "math", ",", "consistent", "with", "the", "Fisher", "information", "metric", "(", "a", "measure", "of", "information", "distance", "between", "probability", "distributions", "and", "the", "curvature", "of", "relative", "entropy", ")", ",", "now", "reads"], "sentence-detokenized": "The natural gradient of mathE f (x) / math, consistent with the Fisher information metric (a measure of information distance between probability distributions and the curvature of relative entropy), now reads", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 23], [24, 29], [30, 31], [32, 33], [33, 34], [34, 35], [36, 37], [38, 42], [42, 43], [44, 54], [55, 59], [60, 63], [64, 70], [71, 82], [83, 89], [90, 91], [91, 92], [93, 100], [101, 103], [104, 115], [116, 124], [125, 132], [133, 144], [145, 158], [159, 162], [163, 166], [167, 176], [177, 179], [180, 188], [189, 196], [196, 197], [197, 198], [199, 202], [203, 208]]}
{"doc_key": "ai-dev-60", "ner": [[0, 3, "programlang"], [7, 10, "product"], [12, 12, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 10, 0, 3, "origin", "", false, false], [12, 12, 0, 3, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "S", "programming", "language", "inspired", "the", "system", "'s", "S'", "-", "PLUS", "and", "R."], "sentence-detokenized": "The S programming language inspired the system's S'-PLUS and R.", "token2charspan": [[0, 3], [4, 5], [6, 17], [18, 26], [27, 35], [36, 39], [40, 46], [46, 48], [49, 51], [51, 52], [52, 56], [57, 60], [61, 63]]}
{"doc_key": "ai-dev-61", "ner": [[5, 5, "product"], [10, 10, "product"], [13, 15, "product"], [19, 21, "researcher"], [23, 24, "researcher"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 10, 10, "named", "same", false, false], [13, 15, 10, 10, "origin", "derived_from", false, false], [13, 15, 19, 21, "origin", "", false, false], [13, 15, 23, 24, "origin", "", false, false], [13, 15, 26, 27, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "most", "influential", "implementation", "of", "Planner", "is", "a", "subset", "of", "Planner", ",", "called", "Micro", "-", "Planner", ",", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "."], "sentence-detokenized": "The most influential implementation of Planner is a subset of Planner, called Micro-Planner, implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd.", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 35], [36, 38], [39, 46], [47, 49], [50, 51], [52, 58], [59, 61], [62, 69], [69, 70], [71, 77], [78, 83], [83, 84], [84, 91], [91, 92], [93, 104], [105, 107], [108, 114], [115, 118], [119, 126], [126, 127], [128, 134], [135, 143], [144, 147], [148, 153], [154, 162], [162, 163]]}
{"doc_key": "ai-dev-62", "ner": [[4, 6, "country"], [8, 10, "researcher"], [20, 20, "misc"], [19, 26, "university"], [36, 37, "misc"], [43, 43, "misc"], [48, 50, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [[8, 10, 4, 6, "general-affiliation", "from_country", false, false], [19, 26, 20, 20, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "1779", ",", "the", "German", "-", "Danish", "scientist", "Christian", "Gottlieb", "Kratzenstein", "won", "first", "prize", "in", "a", "competition", "announced", "by", "the", "Russian", "Imperial", "Academy", "of", "Sciences", "and", "Arts", "for", "his", "construction", "of", "a", "model", "of", "the", "human", "vocal", "tract", "that", "could", "produce", "five", "long", "vowels", "(", "represented", "by", "the", "International", "Phonetic", "Alphabet", "symbol", ")", "."], "sentence-detokenized": "In 1779, the German-Danish scientist Christian Gottlieb Kratzenstein won first prize in a competition announced by the Russian Imperial Academy of Sciences and Arts for his construction of a model of the human vocal tract that could produce five long vowels (represented by the International Phonetic Alphabet symbol).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 19], [19, 20], [20, 26], [27, 36], [37, 46], [47, 55], [56, 68], [69, 72], [73, 78], [79, 84], [85, 87], [88, 89], [90, 101], [102, 111], [112, 114], [115, 118], [119, 126], [127, 135], [136, 143], [144, 146], [147, 155], [156, 159], [160, 164], [165, 168], [169, 172], [173, 185], [186, 188], [189, 190], [191, 196], [197, 199], [200, 203], [204, 209], [210, 215], [216, 221], [222, 226], [227, 232], [233, 240], [241, 245], [246, 250], [251, 257], [258, 259], [259, 270], [271, 273], [274, 277], [278, 291], [292, 300], [301, 309], [310, 316], [316, 317], [317, 318]]}
{"doc_key": "ai-dev-63", "ner": [[3, 4, "product"], [6, 7, "misc"], [10, 14, "misc"], [32, 36, "misc"], [55, 56, "task"], [61, 62, "product"], [64, 66, "product"], [68, 69, "task"], [71, 72, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 4, 61, 62, "related-to", "supports_program", false, false], [3, 4, 64, 66, "related-to", "supports_program", false, false], [6, 7, 3, 4, "part-of", "", false, false], [10, 14, 3, 4, "part-of", "", false, false], [32, 36, 3, 4, "part-of", "", false, false], [55, 56, 3, 4, "part-of", "", false, false], [68, 69, 3, 4, "part-of", "", false, false], [71, 72, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["New", "features", "in", "Office", "XP", "include", "Smart", "Tags", ",", "a", "selection", "-", "based", "search", "feature", "that", "identifies", "different", "types", "of", "text", "in", "a", "document", "so", "that", "users", "can", "perform", "additional", "actions", ";", "a", "task", "pane", "interface", "that", "consolidates", "frequently", "used", "menu", "bar", "commands", "on", "the", "right", "side", "of", "the", "screen", "for", "quick", "access", ";", "new", "document", "collaboration", "features", "with", "support", "for", "MSN", "Groups", "and", "SharePoint", ";", "and", "integrated", "handwriting", "recognition", "and", "voice", "recognition", "features", "."], "sentence-detokenized": "New features in Office XP include Smart Tags, a selection-based search feature that identifies different types of text in a document so that users can perform additional actions; a task pane interface that consolidates frequently used menu bar commands on the right side of the screen for quick access; new document collaboration features with support for MSN Groups and SharePoint; and integrated handwriting recognition and voice recognition features.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 22], [23, 25], [26, 33], [34, 39], [40, 44], [44, 45], [46, 47], [48, 57], [57, 58], [58, 63], [64, 70], [71, 78], [79, 83], [84, 94], [95, 104], [105, 110], [111, 113], [114, 118], [119, 121], [122, 123], [124, 132], [133, 135], [136, 140], [141, 146], [147, 150], [151, 158], [159, 169], [170, 177], [177, 178], [179, 180], [181, 185], [186, 190], [191, 200], [201, 205], [206, 218], [219, 229], [230, 234], [235, 239], [240, 243], [244, 252], [253, 255], [256, 259], [260, 265], [266, 270], [271, 273], [274, 277], [278, 284], [285, 288], [289, 294], [295, 301], [301, 302], [303, 306], [307, 315], [316, 329], [330, 338], [339, 343], [344, 351], [352, 355], [356, 359], [360, 366], [367, 370], [371, 381], [381, 382], [383, 386], [387, 397], [398, 409], [410, 421], [422, 425], [426, 431], [432, 443], [444, 452], [452, 453]]}
{"doc_key": "ai-dev-64", "ner": [[11, 12, "algorithm"], [14, 16, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 14, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "many", "applications", ",", "the", "cells", "of", "these", "networks", "apply", "a", "sigmoid", "function", "as", "the", "activation", "function", "."], "sentence-detokenized": "In many applications, the cells of these networks apply a sigmoid function as the activation function.", "token2charspan": [[0, 2], [3, 7], [8, 20], [20, 21], [22, 25], [26, 31], [32, 34], [35, 40], [41, 49], [50, 55], [56, 57], [58, 65], [66, 74], [75, 77], [78, 81], [82, 92], [93, 101], [101, 102]]}
{"doc_key": "ai-dev-65", "ner": [[2, 2, "researcher"], [10, 16, "organisation"], [26, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 10, 16, "role", "", false, false], [2, 2, 26, 33, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2001", "Mailer", "was", "elected", "an", "Honorary", "Foreign", "Member", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "in", "2003", "he", "was", "elected", "a", "Fellow", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In 2001 Mailer was elected an Honorary Foreign Member of the American Academy of Arts and Sciences and in 2003 he was elected a Fellow of the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 18], [19, 26], [27, 29], [30, 38], [39, 46], [47, 53], [54, 56], [57, 60], [61, 69], [70, 77], [78, 80], [81, 85], [86, 89], [90, 98], [99, 102], [103, 105], [106, 110], [111, 113], [114, 117], [118, 125], [126, 127], [128, 134], [135, 137], [138, 141], [142, 150], [151, 162], [163, 166], [167, 170], [171, 182], [183, 185], [186, 193], [193, 194]]}
{"doc_key": "ai-dev-66", "ner": [[4, 6, "task"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 9, 10, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Extending", "this", "concept", "to", "non", "-binary", "classifications", "yields", "the", "confusion", "matrix", "."], "sentence-detokenized": "Extending this concept to non-binary classifications yields the confusion matrix.", "token2charspan": [[0, 9], [10, 14], [15, 22], [23, 25], [26, 29], [29, 36], [37, 52], [53, 59], [60, 63], [64, 73], [74, 80], [80, 81]]}
{"doc_key": "ai-dev-67", "ner": [[11, 12, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "latest", "measurement", "noise", "variance", "estimates", "can", "be", "obtained", "from", "the", "maximum", "likelihood", "calculation"], "sentence-detokenized": "The latest measurement noise variance estimates can be obtained from the maximum likelihood calculation", "token2charspan": [[0, 3], [4, 10], [11, 22], [23, 28], [29, 37], [38, 47], [48, 51], [52, 54], [55, 63], [64, 68], [69, 72], [73, 80], [81, 91], [92, 103]]}
{"doc_key": "ai-dev-68", "ner": [[1, 2, "field"], [4, 6, "algorithm"], [12, 13, "field"], [10, 11, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 12, 13, "usage", "", true, false], [4, 6, 10, 11, "related-to", "", true, false], [12, 13, 1, 2, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "machine", "learning", ",", "a", "perceptron", "is", "an", "algorithm", "for", "binary", "classification", "supervised", "learning", "."], "sentence-detokenized": "In machine learning, a perceptron is an algorithm for binary classification supervised learning.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 22], [23, 33], [34, 36], [37, 39], [40, 49], [50, 53], [54, 60], [61, 75], [76, 86], [87, 95], [95, 96]]}
{"doc_key": "ai-dev-69", "ner": [[9, 10, "field"], [12, 12, "field"], [16, 22, "conference"], [25, 29, "conference"], [31, 38, "conference"], [40, 45, "conference"], [48, 52, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[16, 22, 9, 10, "topic", "", false, false], [16, 22, 12, 12, "topic", "", false, false], [25, 29, 9, 10, "topic", "", false, false], [25, 29, 12, 12, "topic", "", false, false], [31, 38, 9, 10, "topic", "", false, false], [31, 38, 12, 12, "topic", "", false, false], [40, 45, 9, 10, "topic", "", false, false], [40, 45, 12, 12, "topic", "", false, false], [48, 52, 9, 10, "topic", "", false, false], [48, 52, 12, 12, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["She", "has", "also", "served", "as", "regional", "chair", "of", "several", "machine", "learning", "and", "vision", "conferences", ",", "including", "the", "Conference", "on", "Neural", "Information", "Processing", "Systems", ",", "the", "International", "Conference", "on", "Learning", "Representation", ",", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "the", "International", "Conference", "on", "Computer", "Vision", "and", "the", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "She has also served as regional chair of several machine learning and vision conferences, including the Conference on Neural Information Processing Systems, the International Conference on Learning Representation, the Conference on Computer Vision and Pattern Recognition, the International Conference on Computer Vision and the European Conference on Computer Vision.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 19], [20, 22], [23, 31], [32, 37], [38, 40], [41, 48], [49, 56], [57, 65], [66, 69], [70, 76], [77, 88], [88, 89], [90, 99], [100, 103], [104, 114], [115, 117], [118, 124], [125, 136], [137, 147], [148, 155], [155, 156], [157, 160], [161, 174], [175, 185], [186, 188], [189, 197], [198, 212], [212, 213], [214, 217], [218, 228], [229, 231], [232, 240], [241, 247], [248, 251], [252, 259], [260, 271], [271, 272], [273, 276], [277, 290], [291, 301], [302, 304], [305, 313], [314, 320], [321, 324], [325, 328], [329, 337], [338, 348], [349, 351], [352, 360], [361, 367], [367, 368]]}
{"doc_key": "ai-dev-70", "ner": [[0, 1, "algorithm"], [6, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Concentration", "algorithms", "are", "also", "used", "for", "facial", "recognition", "systems", "in", "video", "sequences", "."], "sentence-detokenized": "Concentration algorithms are also used for facial recognition systems in video sequences.", "token2charspan": [[0, 13], [14, 24], [25, 28], [29, 33], [34, 38], [39, 42], [43, 49], [50, 61], [62, 69], [70, 72], [73, 78], [79, 88], [88, 89]]}
{"doc_key": "ai-dev-71", "ner": [[0, 2, "task"], [6, 6, "organisation"], [17, 17, "conference"], [21, 25, "academicjournal"], [29, 29, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[17, 17, 0, 2, "topic", "", false, false], [17, 17, 6, 6, "origin", "", false, false], [21, 25, 0, 2, "topic", "", false, false], [21, 25, 6, 6, "origin", "", true, false], [29, 29, 21, 25, "role", "edited_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Information", "dissemination", "is", "also", "part", "of", "ELRA", "'s", "mission", ",", "which", "is", "achieved", "through", "the", "organisation", "of", "LREC", "conferences", "and", "the", "Language", "Resources", "and", "Assessment", "Journal", ",", "edited", "by", "Springer", "."], "sentence-detokenized": "Information dissemination is also part of ELRA's mission, which is achieved through the organisation of LREC conferences and the Language Resources and Assessment Journal, edited by Springer.", "token2charspan": [[0, 11], [12, 25], [26, 28], [29, 33], [34, 38], [39, 41], [42, 46], [46, 48], [49, 56], [56, 57], [58, 63], [64, 66], [67, 75], [76, 83], [84, 87], [88, 100], [101, 103], [104, 108], [109, 120], [121, 124], [125, 128], [129, 137], [138, 147], [148, 151], [152, 162], [163, 170], [170, 171], [172, 178], [179, 181], [182, 190], [190, 191]]}
{"doc_key": "ai-dev-72", "ner": [[1, 9, "field"], [11, 12, "field"], [14, 16, "field"], [18, 19, "field"], [50, 53, "field"], [57, 57, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 9, 50, 53, "named", "", false, false], [14, 16, 1, 9, "named", "", false, false], [57, 57, 11, 12, "part-of", "", true, false], [57, 57, 14, 16, "part-of", "", true, false], [57, 57, 50, 53, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "linear", "time", "-", "invariant", "(", "LTI", ")", "systems", "theory", ",", "control", "theory", "and", "digital", "signal", "processing", "or", "signal", "processing", ",", "the", "relationship", "between", "the", "input", "signal", "math", "\\", "displaystyle", "x", "(", "t", ")", "/", "math", "and", "the", "output", "signal", "math", "\\", "displaystyle", "y", "(", "t", ")", "/", "math", "of", "an", "LTI", "system", "is", "governed", "by", "the", "convolution", "operation", "."], "sentence-detokenized": "In linear time-invariant (LTI) systems theory, control theory and digital signal processing or signal processing, the relationship between the input signal math\\ displaystyle x (t) / math and the output signal math\\ displaystyle y (t) / math of an LTI system is governed by the convolution operation.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [15, 24], [25, 26], [26, 29], [29, 30], [31, 38], [39, 45], [45, 46], [47, 54], [55, 61], [62, 65], [66, 73], [74, 80], [81, 91], [92, 94], [95, 101], [102, 112], [112, 113], [114, 117], [118, 130], [131, 138], [139, 142], [143, 148], [149, 155], [156, 160], [160, 161], [162, 174], [175, 176], [177, 178], [178, 179], [179, 180], [181, 182], [183, 187], [188, 191], [192, 195], [196, 202], [203, 209], [210, 214], [214, 215], [216, 228], [229, 230], [231, 232], [232, 233], [233, 234], [235, 236], [237, 241], [242, 244], [245, 247], [248, 251], [252, 258], [259, 261], [262, 270], [271, 273], [274, 277], [278, 289], [290, 299], [299, 300]]}
{"doc_key": "ai-dev-73", "ner": [[15, 16, "field"], [18, 18, "field"], [20, 21, "field"], [23, 24, "field"], [26, 29, "field"], [31, 32, "product"], [34, 35, "field"], [37, 37, "field"], [39, 40, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Due", "to", "its", "generality", ",", "the", "field", "is", "studied", "in", "many", "other", "disciplines", "such", "as", "game", "theory", ",", "cybernetics", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimisation", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Due to its generality, the field is studied in many other disciplines such as game theory, cybernetics, operations research, information theory, simulation-based optimisation, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 21], [21, 22], [23, 26], [27, 32], [33, 35], [36, 43], [44, 46], [47, 51], [52, 57], [58, 69], [70, 74], [75, 77], [78, 82], [83, 89], [89, 90], [91, 102], [102, 103], [104, 114], [115, 123], [123, 124], [125, 136], [137, 143], [143, 144], [145, 155], [155, 156], [156, 161], [162, 174], [174, 175], [176, 187], [188, 195], [195, 196], [197, 202], [203, 215], [215, 216], [217, 227], [228, 231], [232, 239], [240, 250], [250, 251]]}
{"doc_key": "ai-dev-74", "ner": [[0, 2, "algorithm"], [14, 15, "field"], [21, 22, "algorithm"], [25, 26, "algorithm"], [32, 33, "algorithm"], [37, 37, "algorithm"], [38, 42, "researcher"], [44, 45, "researcher"], [47, 49, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[14, 15, 0, 2, "usage", "", true, false], [21, 22, 14, 15, "part-of", "", true, false], [25, 26, 14, 15, "part-of", "", true, false], [32, 33, 14, 15, "part-of", "", true, false], [37, 37, 14, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Stochastic", "gradient", "descent", "is", "a", "popular", "algorithm", "for", "training", "a", "variety", "of", "models", "in", "machine", "learning", ",", "including", "(", "linear", ")", "support", "vector", "machines", ",", "logistic", "regression", "(", "see", ",", "e.g.", ",", "Vowpal", "Wabbit", ")", ",", "and", "graphical", "models", ".", "jenny", "Rose", "Finkel", ",", "Alex", "Kleeman", ",", "Christopher", "D.", "Manning", "(", "2008", ")", "."], "sentence-detokenized": "Stochastic gradient descent is a popular algorithm for training a variety of models in machine learning, including (linear) support vector machines, logistic regression (see, e.g., Vowpal Wabbit), and graphical models. jenny Rose Finkel, Alex Kleeman, Christopher D. Manning (2008).", "token2charspan": [[0, 10], [11, 19], [20, 27], [28, 30], [31, 32], [33, 40], [41, 50], [51, 54], [55, 63], [64, 65], [66, 73], [74, 76], [77, 83], [84, 86], [87, 94], [95, 103], [103, 104], [105, 114], [115, 116], [116, 122], [122, 123], [124, 131], [132, 138], [139, 147], [147, 148], [149, 157], [158, 168], [169, 170], [170, 173], [173, 174], [175, 179], [179, 180], [181, 187], [188, 194], [194, 195], [195, 196], [197, 200], [201, 210], [211, 217], [217, 218], [219, 224], [225, 229], [230, 236], [236, 237], [238, 242], [243, 250], [250, 251], [252, 263], [264, 266], [267, 274], [275, 276], [276, 280], [280, 281], [281, 282]]}
{"doc_key": "ai-dev-75", "ner": [[4, 4, "organisation"], [11, 12, "product"], [19, 19, "country"], [21, 24, "university"], [26, 26, "location"], [28, 30, "university"], [32, 32, "location"], [34, 35, "university"], [37, 37, "location"], [39, 41, "university"], [43, 43, "location"], [45, 46, "university"], [48, 48, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[4, 4, 21, 24, "role", "donates_to", false, false], [4, 4, 28, 30, "role", "donates_to", false, false], [4, 4, 34, 35, "role", "donates_to", false, false], [4, 4, 39, 41, "role", "donates_to", false, false], [4, 4, 45, 46, "role", "donates_to", false, false], [11, 12, 4, 4, "origin", "donates", true, false], [21, 24, 26, 26, "physical", "", false, false], [26, 26, 19, 19, "physical", "", false, false], [28, 30, 32, 32, "physical", "", false, false], [32, 32, 19, 19, "physical", "", false, false], [34, 35, 37, 37, "physical", "", false, false], [37, 37, 19, 19, "physical", "", false, false], [39, 41, 43, 43, "physical", "", false, false], [43, 43, 19, 19, "physical", "", false, false], [45, 46, 48, 48, "physical", "", false, false], [48, 48, 19, 19, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "sentence": ["In", "August", "2011", ",", "Hitachi", "announced", "that", "it", "would", "donate", "an", "electron", "microscope", "to", "each", "of", "five", "universities", "in", "Indonesia", "(", "University", "of", "North", "Sumatra", "in", "Medan", ",", "Indonesian", "Christian", "University", "in", "Jakarta", ",", "Pajajaran", "University", "in", "Bandung", ",", "Jendra", "Sudirman", "University", "in", "Pwoctu", "and", "Muhammad", "University", "in", "Malang", ")", "."], "sentence-detokenized": "In August 2011, Hitachi announced that it would donate an electron microscope to each of five universities in Indonesia (University of North Sumatra in Medan, Indonesian Christian University in Jakarta, Pajajaran University in Bandung, Jendra Sudirman University in Pwoctu and Muhammad University in Malang).", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 23], [24, 33], [34, 38], [39, 41], [42, 47], [48, 54], [55, 57], [58, 66], [67, 77], [78, 80], [81, 85], [86, 88], [89, 93], [94, 106], [107, 109], [110, 119], [120, 121], [121, 131], [132, 134], [135, 140], [141, 148], [149, 151], [152, 157], [157, 158], [159, 169], [170, 179], [180, 190], [191, 193], [194, 201], [201, 202], [203, 212], [213, 223], [224, 226], [227, 234], [234, 235], [236, 242], [243, 251], [252, 262], [263, 265], [266, 272], [273, 276], [277, 285], [286, 296], [297, 299], [300, 306], [306, 307], [307, 308]]}
{"doc_key": "ai-dev-76", "ner": [[0, 0, "field"], [2, 4, "field"], [8, 9, "algorithm"], [11, 14, "algorithm"], [21, 22, "field"], [27, 28, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 2, 4, "part-of", "", false, false], [0, 0, 21, 22, "related-to", "", true, false], [0, 0, 27, 28, "related-to", "", true, false], [8, 9, 0, 0, "type-of", "", false, false], [11, 14, 0, 0, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Optimisation", "techniques", "in", "operations", "research", ",", "such", "as", "linear", "programming", "or", "dynamic", "programming", ",", "are", "often", "impractical", "for", "large", "-", "scale", "software", "engineering", "problems", "due", "to", "their", "computational", "complexity", "."], "sentence-detokenized": "Optimisation techniques in operations research, such as linear programming or dynamic programming, are often impractical for large-scale software engineering problems due to their computational complexity.", "token2charspan": [[0, 12], [13, 23], [24, 26], [27, 37], [38, 46], [46, 47], [48, 52], [53, 55], [56, 62], [63, 74], [75, 77], [78, 85], [86, 97], [97, 98], [99, 102], [103, 108], [109, 120], [121, 124], [125, 130], [130, 131], [131, 136], [137, 145], [146, 157], [158, 166], [167, 170], [171, 173], [174, 179], [180, 193], [194, 204], [204, 205]]}
{"doc_key": "ai-dev-77", "ner": [[0, 1, "metrics"], [4, 4, "metrics"], [6, 8, "metrics"], [13, 14, "metrics"], [16, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 4, 4, "compare", "", false, false], [0, 1, 6, 8, "compare", "", false, false], [13, 14, 6, 8, "part-of", "", false, false], [16, 18, 6, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sensitivity", "is", "different", "from", "precision", "or", "positive", "predictive", "value", "(", "the", "ratio", "of", "true", "positives", "to", "true", "false", "positives", ")", ",", "which", "is", "both", "a", "statement", "about", "the", "proportion", "of", "actual", "positives", "in", "the", "population", "being", "tested", "and", "a", "statement", "about", "the", "test", "."], "sentence-detokenized": "Sensitivity is different from precision or positive predictive value (the ratio of true positives to true false positives), which is both a statement about the proportion of actual positives in the population being tested and a statement about the test.", "token2charspan": [[0, 11], [12, 14], [15, 24], [25, 29], [30, 39], [40, 42], [43, 51], [52, 62], [63, 68], [69, 70], [70, 73], [74, 79], [80, 82], [83, 87], [88, 97], [98, 100], [101, 105], [106, 111], [112, 121], [121, 122], [122, 123], [124, 129], [130, 132], [133, 137], [138, 139], [140, 149], [150, 155], [156, 159], [160, 170], [171, 173], [174, 180], [181, 190], [191, 193], [194, 197], [198, 208], [209, 214], [215, 221], [222, 225], [226, 227], [228, 237], [238, 243], [244, 247], [248, 252], [252, 253]]}
{"doc_key": "ai-dev-78", "ner": [[0, 1, "person"], [9, 9, "product"], [11, 11, "person"], [12, 27, "person"], [34, 36, "person"], [39, 39, "person"], [45, 47, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 39, 39, "named", "same", false, false], [9, 9, 0, 1, "artifact", "", false, false], [34, 36, 45, 47, "role", "convinces", false, false], [45, 47, 9, 9, "role", "producer", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Hampton", "Fancher", "'s", "screenplay", "!", "--", "not", "initially", "titled", "Andr\u00e9", "--", "see", "Sammon", ",", "pp.", "32", "and", "38", "for", "an", "explanation", "--", "was", "optioned", "in", "1977", ".", "sammon", ",", "pp.", "23", "-", "30", "Producer", "Michael", "Deeley", "was", "interested", "in", "Fancher", "'s", "draft", "and", "persuaded", "director", "Ridley", "Scott", "to", "take", "it", "on", "."], "sentence-detokenized": "Hampton Fancher's screenplay! -- not initially titled Andr\u00e9 -- see Sammon, pp. 32 and 38 for an explanation -- was optioned in 1977. sammon, pp. 23-30 Producer Michael Deeley was interested in Fancher's draft and persuaded director Ridley Scott to take it on.", "token2charspan": [[0, 7], [8, 15], [15, 17], [18, 28], [28, 29], [30, 32], [33, 36], [37, 46], [47, 53], [54, 59], [60, 62], [63, 66], [67, 73], [73, 74], [75, 78], [79, 81], [82, 85], [86, 88], [89, 92], [93, 95], [96, 107], [108, 110], [111, 114], [115, 123], [124, 126], [127, 131], [131, 132], [133, 139], [139, 140], [141, 144], [145, 147], [147, 148], [148, 150], [151, 159], [160, 167], [168, 174], [175, 178], [179, 189], [190, 192], [193, 200], [200, 202], [203, 208], [209, 212], [213, 222], [223, 231], [232, 238], [239, 244], [245, 247], [248, 252], [253, 255], [256, 258], [258, 259]]}
{"doc_key": "ai-dev-79", "ner": [[0, 1, "field"], [3, 4, "task"], [6, 8, "task"], [10, 12, "misc"], [14, 15, "field"], [17, 19, "task"], [21, 22, "task"], [24, 25, "field"], [28, 31, "task"], [33, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 4, 0, 1, "part-of", "", false, false], [6, 8, 0, 1, "part-of", "", false, false], [10, 12, 0, 1, "part-of", "", false, false], [14, 15, 0, 1, "part-of", "", false, false], [17, 19, 0, 1, "part-of", "", false, false], [21, 22, 0, 1, "part-of", "", false, false], [24, 25, 0, 1, "part-of", "", false, false], [28, 31, 0, 1, "part-of", "", false, false], [33, 33, 0, 1, "part-of", "", false, false], [35, 36, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Text", "analysis", "involves", "information", "retrieval", ",", "lexical", "analysis", "to", "study", "word", "frequency", "distribution", ",", "pattern", "recognition", ",", "tagging", "/", "annotation", ",", "information", "extraction", ",", "data", "mining", "techniques", "including", "linkage", "and", "association", "analysis", ",", "visualisation", "and", "predictive", "analysis", "."], "sentence-detokenized": "Text analysis involves information retrieval, lexical analysis to study word frequency distribution, pattern recognition, tagging/annotation, information extraction, data mining techniques including linkage and association analysis, visualisation and predictive analysis.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 34], [35, 44], [44, 45], [46, 53], [54, 62], [63, 65], [66, 71], [72, 76], [77, 86], [87, 99], [99, 100], [101, 108], [109, 120], [120, 121], [122, 129], [129, 130], [130, 140], [140, 141], [142, 153], [154, 164], [164, 165], [166, 170], [171, 177], [178, 188], [189, 198], [199, 206], [207, 210], [211, 222], [223, 231], [231, 232], [233, 246], [247, 250], [251, 261], [262, 270], [270, 271]]}
{"doc_key": "ai-dev-80", "ner": [[5, 5, "product"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 16, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["There", "are", "several", "indicators", "using", "WordNet", ",", "which", "is", "a", "manually", "constructed", "lexical", "database", "of", "English", "words", "."], "sentence-detokenized": "There are several indicators using WordNet, which is a manually constructed lexical database of English words.", "token2charspan": [[0, 5], [6, 9], [10, 17], [18, 28], [29, 34], [35, 42], [42, 43], [44, 49], [50, 52], [53, 54], [55, 63], [64, 75], [76, 83], [84, 92], [93, 95], [96, 103], [104, 109], [109, 110]]}
{"doc_key": "ai-dev-81", "ner": [[8, 9, "field"], [11, 12, "task"], [14, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "system", "uses", "a", "combination", "of", "techniques", "from", "computational", "linguistics", ",", "information", "retrieval", "and", "knowledge", "representation", "to", "find", "answers", "."], "sentence-detokenized": "The system uses a combination of techniques from computational linguistics, information retrieval and knowledge representation to find answers.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 17], [18, 29], [30, 32], [33, 43], [44, 48], [49, 62], [63, 74], [74, 75], [76, 87], [88, 97], [98, 101], [102, 111], [112, 126], [127, 129], [130, 134], [135, 142], [142, 143]]}
{"doc_key": "ai-dev-82", "ner": [[6, 7, "metrics"], [12, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 12, 12, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "performance", "indicator", ",", "the", "uncertainty", "factor", "has", "advantages", "over", "simple", "accuracy", "because", "it", "is", "independent", "of", "the", "relative", "size", "of", "the", "different", "categories", "."], "sentence-detokenized": "As a performance indicator, the uncertainty factor has advantages over simple accuracy because it is independent of the relative size of the different categories.", "token2charspan": [[0, 2], [3, 4], [5, 16], [17, 26], [26, 27], [28, 31], [32, 43], [44, 50], [51, 54], [55, 65], [66, 70], [71, 77], [78, 86], [87, 94], [95, 97], [98, 100], [101, 112], [113, 115], [116, 119], [120, 128], [129, 133], [134, 136], [137, 140], [141, 150], [151, 161], [161, 162]]}
{"doc_key": "ai-dev-83", "ner": [[5, 8, "algorithm"], [10, 11, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Researchers", "have", "tried", "many", "methods", "such", "as", "optical", "flow", ",", "Kalman", "filtering", ",", "Hidden", "Markov", "Models", ",", "etc", "."], "sentence-detokenized": "Researchers have tried many methods such as optical flow, Kalman filtering, Hidden Markov Models, etc.", "token2charspan": [[0, 11], [12, 16], [17, 22], [23, 27], [28, 35], [36, 40], [41, 43], [44, 51], [52, 56], [56, 57], [58, 64], [65, 74], [74, 75], [76, 82], [83, 89], [90, 96], [96, 97], [98, 101], [101, 102]]}
{"doc_key": "ai-dev-84", "ner": [[16, 20, "conference"], [39, 43, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "has", "held", "the", "positions", "of", "President", ",", "Vice", "-", "President", "and", "Secretary", "-", "Treasurer", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "and", "is", "a", "member", "of", "the", "Board", "of", "Directors", "and", "Secretary", "of", "the", "Board", "of", "Directors", "of", "the", "Association", "for", "Computational", "Studies", "."], "sentence-detokenized": "She has held the positions of President, Vice-President and Secretary-Treasurer of the Association for Computational Linguistics, and is a member of the Board of Directors and Secretary of the Board of Directors of the Association for Computational Studies.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 16], [17, 26], [27, 29], [30, 39], [39, 40], [41, 45], [45, 46], [46, 55], [56, 59], [60, 69], [69, 70], [70, 79], [80, 82], [83, 86], [87, 98], [99, 102], [103, 116], [117, 128], [128, 129], [130, 133], [134, 136], [137, 138], [139, 145], [146, 148], [149, 152], [153, 158], [159, 161], [162, 171], [172, 175], [176, 185], [186, 188], [189, 192], [193, 198], [199, 201], [202, 211], [212, 214], [215, 218], [219, 230], [231, 234], [235, 248], [249, 256], [256, 257]]}
{"doc_key": "ai-dev-85", "ner": [[7, 7, "programlang"], [9, 9, "product"], [11, 11, "programlang"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 11, 11, "compare", "", false, false], [7, 7, 13, 14, "related-to", "supports", false, false], [9, 9, 11, 11, "compare", "", false, false], [9, 9, 13, 14, "related-to", "supports", false, false], [11, 11, 13, 14, "related-to", "supports", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["As", "with", "other", "similar", "languages", "such", "as", "APL", "and", "MATLAB", ",", "R", "supports", "matrix", "operations", "."], "sentence-detokenized": "As with other similar languages such as APL and MATLAB, R supports matrix operations.", "token2charspan": [[0, 2], [3, 7], [8, 13], [14, 21], [22, 31], [32, 36], [37, 39], [40, 43], [44, 47], [48, 54], [54, 55], [56, 57], [58, 66], [67, 73], [74, 84], [84, 85]]}
{"doc_key": "ai-dev-86", "ner": [[8, 9, "misc"], [19, 21, "organisation"], [13, 14, "researcher"], [16, 17, "university"], [24, 31, "misc"], [5, 5, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 19, 21, "physical", "", false, false], [8, 9, 24, 31, "temporal", "", false, false], [13, 14, 8, 9, "role", "arranges", false, false], [13, 14, 16, 17, "role", "works_for", false, false], [5, 5, 8, 9, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["On", "7", "June", "2014", ",", "Gustman", "won", "the", "Turing", "Test", "competition", "organised", "by", "Kevin", "Warwick", "of", "Reading", "University", "at", "the", "Royal", "Society", "to", "mark", "the", "60th", "anniversary", "of", "Turing", "'s", "death", "after", "33", "%", "of", "the", "judges", "were", "convinced", "that", "the", "robot", "was", "human", "."], "sentence-detokenized": "On 7 June 2014, Gustman won the Turing Test competition organised by Kevin Warwick of Reading University at the Royal Society to mark the 60th anniversary of Turing's death after 33% of the judges were convinced that the robot was human.", "token2charspan": [[0, 2], [3, 4], [5, 9], [10, 14], [14, 15], [16, 23], [24, 27], [28, 31], [32, 38], [39, 43], [44, 55], [56, 65], [66, 68], [69, 74], [75, 82], [83, 85], [86, 93], [94, 104], [105, 107], [108, 111], [112, 117], [118, 125], [126, 128], [129, 133], [134, 137], [138, 142], [143, 154], [155, 157], [158, 164], [164, 166], [167, 172], [173, 178], [179, 181], [181, 182], [183, 185], [186, 189], [190, 196], [197, 201], [202, 211], [212, 216], [217, 220], [221, 226], [227, 230], [231, 236], [236, 237]]}
{"doc_key": "ai-dev-87", "ner": [[0, 2, "product"], [4, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "collaborative", "robot", "or", "cobot", "is", "a", "robot", "that", "can", "interact", "safely", "and", "effectively", "with", "human", "workers", "while", "performing", "simple", "industrial", "tasks", "."], "sentence-detokenized": "A collaborative robot or cobot is a robot that can interact safely and effectively with human workers while performing simple industrial tasks.", "token2charspan": [[0, 1], [2, 15], [16, 21], [22, 24], [25, 30], [31, 33], [34, 35], [36, 41], [42, 46], [47, 50], [51, 59], [60, 66], [67, 70], [71, 82], [83, 87], [88, 93], [94, 101], [102, 107], [108, 118], [119, 125], [126, 136], [137, 142], [142, 143]]}
{"doc_key": "ai-dev-88", "ner": [[13, 14, "field"], [17, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "task"], [29, 30, "task"], [32, 35, "task"], [37, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[17, 18, 13, 14, "part-of", "task_part_of_field", false, false], [20, 21, 13, 14, "part-of", "task_part_of_field", false, false], [23, 24, 13, 14, "part-of", "task_part_of_field", false, false], [26, 27, 13, 14, "part-of", "task_part_of_field", false, false], [29, 30, 13, 14, "part-of", "task_part_of_field", false, false], [32, 35, 13, 14, "part-of", "task_part_of_field", false, false], [37, 38, 13, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["This", "general", "framework", "has", "been", "applied", "to", "a", "large", "number", "of", "problems", "in", "computer", "vision", ",", "including", "feature", "detection", ",", "feature", "classification", ",", "image", "segmentation", ",", "image", "matching", ",", "motion", "estimation", ",", "computation", "of", "shape", "cues", "and", "object", "recognition", "."], "sentence-detokenized": "This general framework has been applied to a large number of problems in computer vision, including feature detection, feature classification, image segmentation, image matching, motion estimation, computation of shape cues and object recognition.", "token2charspan": [[0, 4], [5, 12], [13, 22], [23, 26], [27, 31], [32, 39], [40, 42], [43, 44], [45, 50], [51, 57], [58, 60], [61, 69], [70, 72], [73, 81], [82, 88], [88, 89], [90, 99], [100, 107], [108, 117], [117, 118], [119, 126], [127, 141], [141, 142], [143, 148], [149, 161], [161, 162], [163, 168], [169, 177], [177, 178], [179, 185], [186, 196], [196, 197], [198, 209], [210, 212], [213, 218], [219, 223], [224, 227], [228, 234], [235, 246], [246, 247]]}
{"doc_key": "ai-dev-89", "ner": [[6, 12, "task"], [10, 11, "algorithm"], [14, 17, "algorithm"], [27, 28, "algorithm"], [32, 33, "algorithm"], [37, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 12, 10, 11, "part-of", "", false, false], [6, 12, 14, 17, "usage", "", false, false], [10, 11, 27, 28, "named", "same", false, false], [27, 28, 32, 33, "related-to", "", false, false], [27, 28, 37, 38, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "many", "practical", "applications", ",", "the", "parameters", "of", "naive", "Bayesian", "models", "are", "estimated", "using", "the", "maximum", "likelihood", "method", ";", "in", "other", "words", ",", "one", "can", "use", "a", "naive", "Bayesian", "model", "without", "accepting", "Bayesian", "probabilities", "or", "using", "any", "Bayesian", "methods", "."], "sentence-detokenized": "In many practical applications, the parameters of naive Bayesian models are estimated using the maximum likelihood method; in other words, one can use a naive Bayesian model without accepting Bayesian probabilities or using any Bayesian methods.", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 30], [30, 31], [32, 35], [36, 46], [47, 49], [50, 55], [56, 64], [65, 71], [72, 75], [76, 85], [86, 91], [92, 95], [96, 103], [104, 114], [115, 121], [121, 122], [123, 125], [126, 131], [132, 137], [137, 138], [139, 142], [143, 146], [147, 150], [151, 152], [153, 158], [159, 167], [168, 173], [174, 181], [182, 191], [192, 200], [201, 214], [215, 217], [218, 223], [224, 227], [228, 236], [237, 244], [244, 245]]}
{"doc_key": "ai-dev-90", "ner": [[2, 2, "researcher"], [6, 7, "misc"], [10, 11, "university"], [3, 15, "researcher"], [17, 18, "misc"], [22, 22, "university"], [24, 25, "university"], [27, 27, "misc"], [32, 37, "university"], [44, 47, "misc"], [50, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[2, 2, 10, 11, "physical", "", false, false], [2, 2, 10, 11, "role", "", false, false], [2, 2, 3, 15, "social", "brothers", false, false], [6, 7, 2, 2, "named", "", false, false], [3, 15, 22, 22, "physical", "", false, false], [3, 15, 22, 22, "role", "", false, false], [3, 15, 24, 25, "physical", "", false, false], [3, 15, 24, 25, "role", "", false, false], [3, 15, 32, 37, "physical", "", false, false], [3, 15, 32, 37, "role", "", false, false], [17, 18, 3, 15, "named", "", false, false], [27, 27, 3, 15, "origin", "", false, false], [44, 47, 3, 15, "artifact", "", false, false], [44, 47, 50, 53, "part-of", "part", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Brothers", "-", "Victor", "Geshevich", "Katz", ",", "American", "mathematician", ",", "Professor", "at", "MIT", ";", "Mikhail", "Geshevich", "Katz", ",", "Israeli", "mathematician", ",", "graduate", "of", "Harvard", "and", "Columbia", "Universities", "(", "PhD", ",", "1984", ")", ",", "Professor", "at", "Bar", "-", "Ilan", "University", ",", "author", "of", "the", "monograph", "\"", "Contraction", "Geometry", "and", "Topology", "\"", "(", "Mathematical", "Surveys", "and", "Monographs", ",", "vol", ".", "2", ")", "."], "sentence-detokenized": "Brothers - Victor Geshevich Katz, American mathematician, Professor at MIT; Mikhail Geshevich Katz, Israeli mathematician, graduate of Harvard and Columbia Universities (PhD, 1984), Professor at Bar-Ilan University, author of the monograph \"Contraction Geometry and Topology\" (Mathematical Surveys and Monographs, vol. 2).", "token2charspan": [[0, 8], [9, 10], [11, 17], [18, 27], [28, 32], [32, 33], [34, 42], [43, 56], [56, 57], [58, 67], [68, 70], [71, 74], [74, 75], [76, 83], [84, 93], [94, 98], [98, 99], [100, 107], [108, 121], [121, 122], [123, 131], [132, 134], [135, 142], [143, 146], [147, 155], [156, 168], [169, 170], [170, 173], [173, 174], [175, 179], [179, 180], [180, 181], [182, 191], [192, 194], [195, 198], [198, 199], [199, 203], [204, 214], [214, 215], [216, 222], [223, 225], [226, 229], [230, 239], [240, 241], [241, 252], [253, 261], [262, 265], [266, 274], [274, 275], [276, 277], [277, 289], [290, 297], [298, 301], [302, 312], [312, 313], [314, 317], [317, 318], [319, 320], [320, 321], [321, 322]]}
{"doc_key": "ai-dev-91", "ner": [[3, 4, "person"], [9, 10, "conference"], [14, 18, "organisation"], [20, 26, "location"], [31, 31, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 9, 10, "physical", "", false, false], [3, 4, 9, 10, "role", "", false, false], [3, 4, 14, 18, "role", "", false, false], [14, 18, 20, 26, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2000", ",", "Manuel", "Toharia", ",", "speaker", "at", "previous", "campus", "gatherings", "and", "director", "of", "the", "Pr\u00edncipe", "Felipe", "Science", "Museum", "in", "the", "Valencian", "City", "of", "Arts", "and", "Sciences", ",", "suggested", "that", "the", "Ragageles", "expand", "the", "event", "and", "make", "it", "more", "international", "by", "moving", "it", "to", "the", "prestigious", "museum", "."], "sentence-detokenized": "In 2000, Manuel Toharia, speaker at previous campus gatherings and director of the Pr\u00edncipe Felipe Science Museum in the Valencian City of Arts and Sciences, suggested that the Ragageles expand the event and make it more international by moving it to the prestigious museum.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 23], [23, 24], [25, 32], [33, 35], [36, 44], [45, 51], [52, 62], [63, 66], [67, 75], [76, 78], [79, 82], [83, 91], [92, 98], [99, 106], [107, 113], [114, 116], [117, 120], [121, 130], [131, 135], [136, 138], [139, 143], [144, 147], [148, 156], [156, 157], [158, 167], [168, 172], [173, 176], [177, 186], [187, 193], [194, 197], [198, 203], [204, 207], [208, 212], [213, 215], [216, 220], [221, 234], [235, 237], [238, 244], [245, 247], [248, 250], [251, 254], [255, 266], [267, 273], [273, 274]]}
{"doc_key": "ai-dev-92", "ner": [[4, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Within", "20", "minutes", ",", "the", "facial", "recognition", "system", "identifies", "personal", "information", ",", "including", "surname", ",", "ID", "number", "and", "address", ",", "which", "is", "displayed", "on", "advertising", "screens", "in", "the", "street", "."], "sentence-detokenized": "Within 20 minutes, the facial recognition system identifies personal information, including surname, ID number and address, which is displayed on advertising screens in the street.", "token2charspan": [[0, 6], [7, 9], [10, 17], [17, 18], [19, 22], [23, 29], [30, 41], [42, 48], [49, 59], [60, 68], [69, 80], [80, 81], [82, 91], [92, 99], [99, 100], [101, 103], [104, 110], [111, 114], [115, 122], [122, 123], [124, 129], [130, 132], [133, 142], [143, 145], [146, 157], [158, 165], [166, 168], [169, 172], [173, 179], [179, 180]]}
{"doc_key": "ai-dev-93", "ner": [[6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Recent", "research", "has", "increasingly", "focused", "on", "unsupervised", "learning", "and", "semi-supervised", "learning", "algorithms", "."], "sentence-detokenized": "Recent research has increasingly focused on unsupervised learning and semi-supervised learning algorithms.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 32], [33, 40], [41, 43], [44, 56], [57, 65], [66, 69], [70, 85], [86, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-dev-94", "ner": [[1, 1, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Use", "Python", "code", "to", "calculate", "this", "example", "."], "sentence-detokenized": "Use Python code to calculate this example.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 18], [19, 28], [29, 33], [34, 41], [41, 42]]}
{"doc_key": "ai-dev-95", "ner": [[7, 8, "task"], [14, 15, "field"], [18, 22, "algorithm"], [24, 24, "algorithm"], [28, 30, "algorithm"], [33, 34, "researcher"], [36, 37, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[18, 22, 14, 15, "part-of", "", false, false], [18, 22, 28, 30, "type-of", "", false, false], [18, 22, 33, 34, "origin", "", false, false], [18, 22, 36, 37, "origin", "", false, false], [24, 24, 18, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Today", ",", "however", ",", "many", "aspects", "of", "speech", "recognition", "have", "been", "replaced", "by", "a", "deep", "learning", "method", "called", "long", "short", "-", "term", "memory", "(", "LSTM", ")", ",", "a", "recurrent", "neural", "network", "published", "by", "Sepp", "Hochreiter", "&", "J\u00fcrgen", "Schmidhuber", "in", "1997", "."], "sentence-detokenized": "Today, however, many aspects of speech recognition have been replaced by a deep learning method called long short-term memory (LSTM), a recurrent neural network published by Sepp Hochreiter & J\u00fcrgen Schmidhuber in 1997.", "token2charspan": [[0, 5], [5, 6], [7, 14], [14, 15], [16, 20], [21, 28], [29, 31], [32, 38], [39, 50], [51, 55], [56, 60], [61, 69], [70, 72], [73, 74], [75, 79], [80, 88], [89, 95], [96, 102], [103, 107], [108, 113], [113, 114], [114, 118], [119, 125], [126, 127], [127, 131], [131, 132], [132, 133], [134, 135], [136, 145], [146, 152], [153, 160], [161, 170], [171, 173], [174, 178], [179, 189], [190, 191], [192, 198], [199, 210], [211, 213], [214, 218], [218, 219]]}
{"doc_key": "ai-dev-96", "ner": [[8, 8, "algorithm"], [10, 10, "algorithm"], [19, 19, "algorithm"], [24, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 10, 10, "compare", "", false, false], [8, 8, 24, 24, "named", "same", false, false], [19, 19, 24, 24, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "preliminary", "experimental", "results", "with", "noisy", "datasets", ",", "BrownBoost", "outperformed", "AdaBoost", "in", "terms", "of", "generalisation", "error", ";", "however", ",", "LogitBoost", "performed", "as", "well", "as", "BrownBoost", "."], "sentence-detokenized": "In preliminary experimental results with noisy datasets, BrownBoost outperformed AdaBoost in terms of generalisation error; however, LogitBoost performed as well as BrownBoost.", "token2charspan": [[0, 2], [3, 14], [15, 27], [28, 35], [36, 40], [41, 46], [47, 55], [55, 56], [57, 67], [68, 80], [81, 89], [90, 92], [93, 98], [99, 101], [102, 116], [117, 122], [122, 123], [124, 131], [131, 132], [133, 143], [144, 153], [154, 156], [157, 161], [162, 164], [165, 175], [175, 176]]}
{"doc_key": "ai-dev-97", "ner": [[0, 2, "algorithm"], [5, 7, "researcher"], [8, 10, "country"], [13, 15, "researcher"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 5, 7, "part-of", "", false, false], [5, 7, 8, 10, "physical", "", false, false], [19, 21, 13, 15, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Evolutionary", "programming", "was", "introduced", "by", "Lawrence", "J.", "Fogel", "in", "the", "USA", ",", "and", "John", "Henry", "Holland", "calls", "his", "method", "a", "genetic", "algorithm", "."], "sentence-detokenized": "Evolutionary programming was introduced by Lawrence J. Fogel in the USA, and John Henry Holland calls his method a genetic algorithm.", "token2charspan": [[0, 12], [13, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 54], [55, 60], [61, 63], [64, 67], [68, 71], [71, 72], [73, 76], [77, 81], [82, 87], [88, 95], [96, 101], [102, 105], [106, 112], [113, 114], [115, 122], [123, 132], [132, 133]]}
{"doc_key": "ai-dev-98", "ner": [[4, 4, "researcher"], [6, 6, "researcher"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 4, 12, 13, "role", "", false, false], [4, 4, 15, 16, "role", "", false, false], [4, 4, 18, 19, "role", "", false, false], [4, 4, 21, 22, "role", "", false, false], [6, 6, 12, 13, "role", "", false, false], [6, 6, 15, 16, "role", "", false, false], [6, 6, 18, 19, "role", "", false, false], [6, 6, 21, 22, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Post", "hoc", "calculations", "by", "Doug", ",", "Alan", "and", "their", "colleagues", "(", "including", "Marvin", "Minsky", ",", "Alan", "Newell", ",", "Edward", "Feigenbaum", "and", "John", "McCarthy", ")", "suggest", "that", "the", "work", "would", "have", "required", "between", "1,000", "and", "3,000", "person", "-", "years", "of", "effort", ",", "well", "beyond", "the", "standard", "academic", "project", "model", "."], "sentence-detokenized": "Post hoc calculations by Doug, Alan and their colleagues (including Marvin Minsky, Alan Newell, Edward Feigenbaum and John McCarthy) suggest that the work would have required between 1,000 and 3,000 person-years of effort, well beyond the standard academic project model.", "token2charspan": [[0, 4], [5, 8], [9, 21], [22, 24], [25, 29], [29, 30], [31, 35], [36, 39], [40, 45], [46, 56], [57, 58], [58, 67], [68, 74], [75, 81], [81, 82], [83, 87], [88, 94], [94, 95], [96, 102], [103, 113], [114, 117], [118, 122], [123, 131], [131, 132], [133, 140], [141, 145], [146, 149], [150, 154], [155, 160], [161, 165], [166, 174], [175, 182], [183, 188], [189, 192], [193, 198], [199, 205], [205, 206], [206, 211], [212, 214], [215, 221], [221, 222], [223, 227], [228, 234], [235, 238], [239, 247], [248, 256], [257, 264], [265, 270], [270, 271]]}
{"doc_key": "ai-dev-99", "ner": [[4, 6, "metrics"], [13, 15, "metrics"], [10, 18, "metrics"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[13, 15, 10, 18, "part-of", "implemented_in", false, false]], "relations_mapping_to_source": [1], "sentence": ["Common", "criteria", "are", "the", "mean", "squared", "error", "criterion", "implemented", "in", "MSECriterion", "and", "the", "cross", "entropy", "criterion", "implemented", "in", "NLLCriterion", "."], "sentence-detokenized": "Common criteria are the mean squared error criterion implemented in MSECriterion and the cross entropy criterion implemented in NLLCriterion.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 23], [24, 28], [29, 36], [37, 42], [43, 52], [53, 64], [65, 67], [68, 80], [81, 84], [85, 88], [89, 94], [95, 102], [103, 112], [113, 124], [125, 127], [128, 140], [140, 141]]}
{"doc_key": "ai-dev-100", "ner": [[0, 1, "researcher"], [11, 11, "organisation"], [15, 26, "misc"], [31, 35, "conference"], [46, 46, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 11, 11, "role", "", false, false], [0, 1, 31, 35, "role", "", false, false], [0, 1, 46, 46, "role", "", false, false], [15, 26, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Zurada", "has", "served", "the", "engineering", "profession", "as", "a", "long", "-", "time", "IEEE", "volunteer", ":", "as", "IEEE", "Vice", "President", "-", "Technical", "Activities", "(", "TAB", "Chair", ")", "in", "2014", ",", "as", "Chair", "of", "the", "IEEE", "Computational", "Intelligence", "Society", "from", "2004", "-", "05", ",", "and", "as", "a", "member", "of", "ADCOM", "from", "2009", "-", "14", ",", "2016", "-", "18", "and", "earlier", "years", "."], "sentence-detokenized": "Zurada has served the engineering profession as a long-time IEEE volunteer: as IEEE Vice President - Technical Activities (TAB Chair) in 2014, as Chair of the IEEE Computational Intelligence Society from 2004-05, and as a member of ADCOM from 2009-14, 2016-18 and earlier years.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 21], [22, 33], [34, 44], [45, 47], [48, 49], [50, 54], [54, 55], [55, 59], [60, 64], [65, 74], [74, 75], [76, 78], [79, 83], [84, 88], [89, 98], [99, 100], [101, 110], [111, 121], [122, 123], [123, 126], [127, 132], [132, 133], [134, 136], [137, 141], [141, 142], [143, 145], [146, 151], [152, 154], [155, 158], [159, 163], [164, 177], [178, 190], [191, 198], [199, 203], [204, 208], [208, 209], [209, 211], [211, 212], [213, 216], [217, 219], [220, 221], [222, 228], [229, 231], [232, 237], [238, 242], [243, 247], [247, 248], [248, 250], [250, 251], [252, 256], [256, 257], [257, 259], [260, 263], [264, 271], [272, 277], [277, 278]]}
{"doc_key": "ai-dev-101", "ner": [[3, 4, "field"], [12, 13, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 13, 3, 4, "part-of", "", false, false], [15, 16, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "general", ",", "computational", "linguistics", "draws", "on", "the", "participation", "of", "linguists", ",", "computer", "science", ",", "artificial", "intelligence", "specialists", ",", "mathematicians", ",", "logicians", ",", "philosophers", ",", "cognitive", "scientists", ",", "cognitive", "psychologists", ",", "psycholinguists", ",", "anthropologists", "and", "neuroscientists", ",", "among", "others", "."], "sentence-detokenized": "In general, computational linguistics draws on the participation of linguists, computer science, artificial intelligence specialists, mathematicians, logicians, philosophers, cognitive scientists, cognitive psychologists, psycholinguists, anthropologists and neuroscientists, among others.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 25], [26, 37], [38, 43], [44, 46], [47, 50], [51, 64], [65, 67], [68, 77], [77, 78], [79, 87], [88, 95], [95, 96], [97, 107], [108, 120], [121, 132], [132, 133], [134, 148], [148, 149], [150, 159], [159, 160], [161, 173], [173, 174], [175, 184], [185, 195], [195, 196], [197, 206], [207, 220], [220, 221], [222, 237], [237, 238], [239, 254], [255, 258], [259, 274], [274, 275], [276, 281], [282, 288], [288, 289]]}
{"doc_key": "ai-dev-102", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "and", "short", "term", "memory", "are", "often", "used", "to", "exploit", "inter", "-", "frame", "correlations", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and long and short term memory are often used to exploit inter-frame correlations.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [83, 86], [87, 92], [93, 97], [98, 104], [105, 108], [109, 114], [115, 119], [120, 122], [123, 130], [131, 136], [136, 137], [137, 142], [143, 155], [155, 156]]}
{"doc_key": "ai-dev-103", "ner": [[0, 2, "product"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Unimate", "is", "the", "first", "industrial", "robot", "."], "sentence-detokenized": "Unimate is the first industrial robot.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 20], [21, 31], [32, 37], [37, 38]]}
{"doc_key": "ai-dev-104", "ner": [[2, 3, "researcher"], [5, 7, "researcher"], [0, 0, "researcher"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 13, 14, "win-defeat", "", false, false], [5, 7, 13, 14, "win-defeat", "", false, false], [0, 0, 13, 14, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Bengeo", "joins", "Geoffrey", "Hinton", "and", "Jan", "Le", "Coon", "as", "winners", "of", "the", "2018", "Turing", "Award", "."], "sentence-detokenized": "Bengeo joins Geoffrey Hinton and Jan Le Coon as winners of the 2018 Turing Award.", "token2charspan": [[0, 6], [7, 12], [13, 21], [22, 28], [29, 32], [33, 36], [37, 39], [40, 44], [45, 47], [48, 55], [56, 58], [59, 62], [63, 67], [68, 74], [75, 80], [80, 81]]}
{"doc_key": "ai-dev-105", "ner": [[5, 6, "country"], [19, 20, "misc"], [26, 26, "country"], [22, 24, "organisation"], [31, 32, "person"], [34, 35, "person"], [44, 46, "misc"], [50, 51, "country"], [56, 56, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[19, 20, 5, 6, "physical", "filmed_in", false, false], [31, 32, 22, 24, "role", "host", false, false], [34, 35, 22, 24, "role", "reporter", false, false], [44, 46, 5, 6, "physical", "filmed_in", false, false], [44, 46, 50, 51, "physical", "distributed_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Further", "series", "were", "filmed", "in", "the", "UK", "for", "specific", "areas", "of", "the", "global", "market", ",", "including", "two", "Robot", "Wars", "Extreme", "Warriors", "for", "the", "TNN", "network", "featuring", "US", "competitors", "(", "hosted", "by", "Mick", "Foley", "with", "Rebecca", "Grant", "as", "on", "-", "set", "reporter", ")", ",", "two", "Dutch", "Robot", "Wars", "for", "distribution", "in", "the", "Netherlands", "and", "a", "series", "for", "Germany", "."], "sentence-detokenized": "Further series were filmed in the UK for specific areas of the global market, including two Robot Wars Extreme Warriors for the TNN network featuring US competitors (hosted by Mick Foley with Rebecca Grant as on-set reporter), two Dutch Robot Wars for distribution in the Netherlands and a series for Germany.", "token2charspan": [[0, 7], [8, 14], [15, 19], [20, 26], [27, 29], [30, 33], [34, 36], [37, 40], [41, 49], [50, 55], [56, 58], [59, 62], [63, 69], [70, 76], [76, 77], [78, 87], [88, 91], [92, 97], [98, 102], [103, 110], [111, 119], [120, 123], [124, 127], [128, 131], [132, 139], [140, 149], [150, 152], [153, 164], [165, 166], [166, 172], [173, 175], [176, 180], [181, 186], [187, 191], [192, 199], [200, 205], [206, 208], [209, 211], [211, 212], [212, 215], [216, 224], [224, 225], [225, 226], [227, 230], [231, 236], [237, 242], [243, 247], [248, 251], [252, 264], [265, 267], [268, 271], [272, 283], [284, 287], [288, 289], [290, 296], [297, 300], [301, 308], [308, 309]]}
{"doc_key": "ai-dev-106", "ner": [[8, 8, "researcher"], [13, 13, "product"], [30, 31, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 13, 13, "role", "", false, false], [30, 31, 13, 13, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "many", "years", ",", "beginning", "in", "1986", ",", "Miller", "directed", "the", "development", "of", "WordNet", ",", "a", "large", "computer", "-", "readable", "electronic", "reference", "that", "could", "be", "used", "for", "applications", "such", "as", "search", "engines", "."], "sentence-detokenized": "For many years, beginning in 1986, Miller directed the development of WordNet, a large computer-readable electronic reference that could be used for applications such as search engines.", "token2charspan": [[0, 3], [4, 8], [9, 14], [14, 15], [16, 25], [26, 28], [29, 33], [33, 34], [35, 41], [42, 50], [51, 54], [55, 66], [67, 69], [70, 77], [77, 78], [79, 80], [81, 86], [87, 95], [95, 96], [96, 104], [105, 115], [116, 125], [126, 130], [131, 136], [137, 139], [140, 144], [145, 148], [149, 161], [162, 166], [167, 169], [170, 176], [177, 184], [184, 185]]}
{"doc_key": "ai-dev-107", "ner": [[3, 3, "algorithm"], [7, 12, "algorithm"], [15, 16, "researcher"], [21, 26, "organisation"], [30, 32, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 15, 16, "origin", "", false, false], [3, 3, 30, 32, "win-defeat", "", false, false], [7, 12, 15, 16, "origin", "", false, false], [7, 12, 30, 32, "win-defeat", "", false, false], [15, 16, 21, 26, "physical", "", false, false], [15, 16, 21, 26, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Since", "2009", ",", "recurrent", "neural", "networks", "and", "deep", "feed", "-", "forward", "neural", "networks", "developed", "by", "J\u00fcrgen", "Schmidhuber", "'s", "research", "group", "at", "the", "Swiss", "artificial", "intelligence", "laboratory", "IDSIA", "have", "won", "several", "international", "handwriting", "competitions", "."], "sentence-detokenized": "Since 2009, recurrent neural networks and deep feed-forward neural networks developed by J\u00fcrgen Schmidhuber's research group at the Swiss artificial intelligence laboratory IDSIA have won several international handwriting competitions.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 21], [22, 28], [29, 37], [38, 41], [42, 46], [47, 51], [51, 52], [52, 59], [60, 66], [67, 75], [76, 85], [86, 88], [89, 95], [96, 107], [107, 109], [110, 118], [119, 124], [125, 127], [128, 131], [132, 137], [138, 148], [149, 161], [162, 172], [173, 178], [179, 183], [184, 187], [188, 195], [196, 209], [210, 221], [222, 234], [234, 235]]}
{"doc_key": "ai-dev-108", "ner": [[5, 7, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "software", "is", "implemented", "in", "C", "+", "+", "and", "wrapped", "for", "Python", "."], "sentence-detokenized": "The software is implemented in C + + and wrapped for Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 30], [31, 32], [33, 34], [35, 36], [37, 40], [41, 48], [49, 52], [53, 59], [59, 60]]}
{"doc_key": "ai-dev-109", "ner": [[6, 9, "country"], [14, 15, "misc"], [19, 19, "misc"], [34, 36, "misc"], [37, 38, "misc"], [20, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[19, 19, 6, 9, "temporal", "", false, false], [19, 19, 14, 15, "artifact", "", false, false], [19, 19, 20, 39, "physical", "", false, false], [37, 38, 34, 36, "named", "", false, false], [37, 38, 20, 39, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1857", ",", "at", "the", "request", "of", "the", "Tokugawa", "Shogunate", ",", "a", "group", "of", "Dutch", "engineers", "began", "work", "at", "Yotetsusho", "Nagasaki", ",", "a", "modern", ",", "Western", "-", "style", "foundry", "and", "shipyard", "located", "near", "the", "Dutch", "settlement", "of", "Dejima", "in", "Nagasaki", "."], "sentence-detokenized": "In 1857, at the request of the Tokugawa Shogunate, a group of Dutch engineers began work at Yotetsusho Nagasaki, a modern, Western-style foundry and shipyard located near the Dutch settlement of Dejima in Nagasaki.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 39], [40, 49], [49, 50], [51, 52], [53, 58], [59, 61], [62, 67], [68, 77], [78, 83], [84, 88], [89, 91], [92, 102], [103, 111], [111, 112], [113, 114], [115, 121], [121, 122], [123, 130], [130, 131], [131, 136], [137, 144], [145, 148], [149, 157], [158, 165], [166, 170], [171, 174], [175, 180], [181, 191], [192, 194], [195, 201], [202, 204], [205, 213], [213, 214]]}
{"doc_key": "ai-dev-110", "ner": [[10, 12, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["We", "make", "this", "as", "accurate", "as", "possible", "by", "measuring", "the", "mean", "squared", "error", "between", "mathy", "/", "math", "and", "math", "hat", "{", "f", "}", "(", "x", ";", "D", ")", "/", "math", ":", "we", "want", "math", "(", "y", "-", "hat", "{", "f", "}", "(", "x", ";", "D", ")", ")", "^", "2", "/", "math", "to", "be", "the", "smallest", ",", "both", "for", "mathx", "_", "1", ",\\", "dots", ",", "x", "_n", "/", "math", "and", "for", "points", "outside", "our", "sample", "."], "sentence-detokenized": "We make this as accurate as possible by measuring the mean squared error between mathy / math and math hat {f} (x; D) / math: we want math (y - hat {f} (x; D))^ 2 / math to be the smallest, both for mathx _ 1,\\ dots, x _n / math and for points outside our sample.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 15], [16, 24], [25, 27], [28, 36], [37, 39], [40, 49], [50, 53], [54, 58], [59, 66], [67, 72], [73, 80], [81, 86], [87, 88], [89, 93], [94, 97], [98, 102], [103, 106], [107, 108], [108, 109], [109, 110], [111, 112], [112, 113], [113, 114], [115, 116], [116, 117], [118, 119], [120, 124], [124, 125], [126, 128], [129, 133], [134, 138], [139, 140], [140, 141], [142, 143], [144, 147], [148, 149], [149, 150], [150, 151], [152, 153], [153, 154], [154, 155], [156, 157], [157, 158], [158, 159], [159, 160], [161, 162], [163, 164], [165, 169], [170, 172], [173, 175], [176, 179], [180, 188], [188, 189], [190, 194], [195, 198], [199, 204], [205, 206], [207, 208], [208, 210], [211, 215], [215, 216], [217, 218], [219, 221], [222, 223], [224, 228], [229, 232], [233, 236], [237, 243], [244, 251], [252, 255], [256, 262], [262, 263]]}
{"doc_key": "ai-dev-111", "ner": [[2, 7, "researcher"], [13, 17, "organisation"], [22, 26, "product"], [34, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 7, 13, 17, "role", "", false, false], [22, 26, 13, 17, "temporal", "", false, false], [22, 26, 34, 35, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "then", "extended", "an", "invitation", "to", "Widener", "to", "attend", "the", "annual", "meeting", "of", "the", "American", "Translators", "Association", "the", "following", "October", ",", "where", "the", "Widener", "Machine", "Translation", "System", "was", "hailed", "as", "a", "promising", "breakthrough", "in", "machine", "translation", "."], "sentence-detokenized": "He then extended an invitation to Widener to attend the annual meeting of the American Translators Association the following October, where the Widener Machine Translation System was hailed as a promising breakthrough in machine translation.", "token2charspan": [[0, 2], [3, 7], [8, 16], [17, 19], [20, 30], [31, 33], [34, 41], [42, 44], [45, 51], [52, 55], [56, 62], [63, 70], [71, 73], [74, 77], [78, 86], [87, 98], [99, 110], [111, 114], [115, 124], [125, 132], [132, 133], [134, 139], [140, 143], [144, 151], [152, 159], [160, 171], [172, 178], [179, 182], [183, 189], [190, 192], [193, 194], [195, 204], [205, 217], [218, 220], [221, 228], [229, 240], [240, 241]]}
{"doc_key": "ai-dev-112", "ner": [[11, 15, "conference"], [17, 17, "conference"], [7, 7, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 17, 11, 15, "named", "", false, false], [17, 17, 11, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "work", "was", "presented", "by", "researchers", "from", "Google", "at", "the", "2018", "Neural", "Information", "Processing", "Systems", "Conference", "(", "NeurIPS", ")", "."], "sentence-detokenized": "The work was presented by researchers from Google at the 2018 Neural Information Processing Systems Conference (NeurIPS).", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 22], [23, 25], [26, 37], [38, 42], [43, 49], [50, 52], [53, 56], [57, 61], [62, 68], [69, 80], [81, 91], [92, 99], [100, 110], [111, 112], [112, 119], [119, 120], [120, 121]]}
{"doc_key": "ai-dev-113", "ner": [[0, 4, "algorithm"], [6, 10, "algorithm"], [14, 17, "metrics"], [18, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 4, 6, 10, "usage", "", false, false], [6, 10, 14, 17, "related-to", "", true, false], [14, 17, 18, 21, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Baum", "-", "Welch", "algorithm", "uses", "the", "well", "known", "EM", "algorithm", "to", "find", "the", "maximum", "likelihood", "estimate", "of", "the", "Hidden", "Markov", "Model", "parameters", "given", "a", "set", "of", "observed", "eigenvectors", "."], "sentence-detokenized": "The Baum-Welch algorithm uses the well known EM algorithm to find the maximum likelihood estimate of the Hidden Markov Model parameters given a set of observed eigenvectors.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 14], [15, 24], [25, 29], [30, 33], [34, 38], [39, 44], [45, 47], [48, 57], [58, 60], [61, 65], [66, 69], [70, 77], [78, 88], [89, 97], [98, 100], [101, 104], [105, 111], [112, 118], [119, 124], [125, 135], [136, 141], [142, 143], [144, 147], [148, 150], [151, 159], [160, 172], [172, 173]]}
{"doc_key": "ai-dev-114", "ner": [[8, 8, "product"], [10, 10, "product"], [29, 30, "misc"], [36, 43, "product"], [47, 49, "programlang"], [50, 54, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 8, 10, 10, "compare", "", false, false], [29, 30, 10, 10, "part-of", "", false, false], [36, 43, 10, 10, "part-of", "", false, false], [50, 54, 10, 10, "part-of", "", false, false], [50, 54, 47, 49, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "addition", "to", "the", "taxonomic", "information", "contained", "in", "OpenCyc", ",", "ResearchCyc", "includes", "more", "semantic", "knowledge", "(", "i.e.", "additional", "facts", "and", "rules", "of", "thumb", ")", "involving", "the", "concepts", "in", "its", "knowledge", "base", ";", "it", "also", "includes", "a", "large", "dictionary", ",", "English", "parsing", "and", "generation", "tools", ",", "and", "a", "Java", "-", "based", "knowledge", "editing", "and", "query", "interface", "."], "sentence-detokenized": "In addition to the taxonomic information contained in OpenCyc, ResearchCyc includes more semantic knowledge (i.e. additional facts and rules of thumb) involving the concepts in its knowledge base; it also includes a large dictionary, English parsing and generation tools, and a Java-based knowledge editing and query interface.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 28], [29, 40], [41, 50], [51, 53], [54, 61], [61, 62], [63, 74], [75, 83], [84, 88], [89, 97], [98, 107], [108, 109], [109, 113], [114, 124], [125, 130], [131, 134], [135, 140], [141, 143], [144, 149], [149, 150], [151, 160], [161, 164], [165, 173], [174, 176], [177, 180], [181, 190], [191, 195], [195, 196], [197, 199], [200, 204], [205, 213], [214, 215], [216, 221], [222, 232], [232, 233], [234, 241], [242, 249], [250, 253], [254, 264], [265, 270], [270, 271], [272, 275], [276, 277], [278, 282], [282, 283], [283, 288], [289, 298], [299, 306], [307, 310], [311, 316], [317, 326], [326, 327]]}
{"doc_key": "ai-dev-115", "ner": [[0, 3, "algorithm"], [5, 6, "task"], [10, 11, "field"], [13, 14, "field"], [16, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 5, 6, "type-of", "", false, false], [5, 6, 10, 11, "part-of", "task_part_of_field", false, false], [5, 6, 13, 14, "part-of", "task_part_of_field", false, false], [5, 6, 16, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Hough", "transform", "is", "a", "feature", "extraction", "technique", "used", "in", "image", "analysis", ",", "computer", "vision", "and", "digital", "image", "processing", "."], "sentence-detokenized": "The Hough transform is a feature extraction technique used in image analysis, computer vision and digital image processing.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 22], [23, 24], [25, 32], [33, 43], [44, 53], [54, 58], [59, 61], [62, 67], [68, 76], [76, 77], [78, 86], [87, 93], [94, 97], [98, 105], [106, 111], [112, 122], [122, 123]]}
{"doc_key": "ai-dev-116", "ner": [[13, 13, "product"], [15, 19, "product"], [10, 10, "organisation"], [23, 23, "product"], [25, 26, "researcher"], [7, 8, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 13, 15, 19, "named", "", false, false], [13, 13, 10, 10, "artifact", "", false, false], [13, 13, 23, 23, "origin", "developed_from", false, false], [23, 23, 25, 26, "artifact", "", false, false], [7, 8, 10, 10, "role", "supported", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1978", ",", "with", "the", "support", "of", "General", "Motors", ",", "Unimation", "developed", "the", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "robot", "from", "Vicarm", "(", "Victor", "Scheinman", ")", "."], "sentence-detokenized": "In 1978, with the support of General Motors, Unimation developed the PUMA (Programmable Universal Machine for Assembly) robot from Vicarm (Victor Scheinman).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 13], [14, 17], [18, 25], [26, 28], [29, 36], [37, 43], [43, 44], [45, 54], [55, 64], [65, 68], [69, 73], [74, 75], [75, 87], [88, 97], [98, 105], [106, 109], [110, 118], [118, 119], [120, 125], [126, 130], [131, 137], [138, 139], [139, 145], [146, 155], [155, 156], [156, 157]]}
{"doc_key": "ai-dev-117", "ner": [[0, 2, "algorithm"], [5, 6, "researcher"], [8, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 5, 6, "origin", "", false, false], [0, 2, 8, 11, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "LSTM", "was", "proposed", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "in", "1997", "."], "sentence-detokenized": "The LSTM was proposed by Sepp Hochreiter and J\u00fcrgen Schmidhuber in 1997.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 21], [22, 24], [25, 29], [30, 40], [41, 44], [45, 51], [52, 63], [64, 66], [67, 71], [71, 72]]}
{"doc_key": "ai-dev-118", "ner": [[13, 14, "metrics"], [16, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "four", "results", "can", "be", "expressed", "in", "terms", "of", "a", "2", "x", "2", "contingency", "table", "or", "confusion", "matrix", ",", "as", "follows", "."], "sentence-detokenized": "These four results can be expressed in terms of a 2 x 2 contingency table or confusion matrix, as follows.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 22], [23, 25], [26, 35], [36, 38], [39, 44], [45, 47], [48, 49], [50, 51], [52, 53], [54, 55], [56, 67], [68, 73], [74, 76], [77, 86], [87, 93], [93, 94], [95, 97], [98, 105], [105, 106]]}
{"doc_key": "ai-dev-119", "ner": [[9, 9, "conference"], [11, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "also", "contributed", "much", "through", "the", "establishment", "of", "the", "ELRA", "and", "LREC", "conferences", "."], "sentence-detokenized": "He also contributed much through the establishment of the ELRA and LREC conferences.", "token2charspan": [[0, 2], [3, 7], [8, 19], [20, 24], [25, 32], [33, 36], [37, 50], [51, 53], [54, 57], [58, 62], [63, 66], [67, 71], [72, 83], [83, 84]]}
{"doc_key": "ai-dev-120", "ner": [[16, 17, "misc"], [21, 23, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[21, 23, 16, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "popular", "application", "of", "serial", "robots", "in", "industry", "today", "is", "the", "pick", "-", "and", "-", "place", "assembly", "robot", ",", "known", "as", "a", "SCARA", "robot", ",", "which", "has", "four", "degrees", "of", "freedom", "."], "sentence-detokenized": "A popular application of serial robots in industry today is the pick-and-place assembly robot, known as a SCARA robot, which has four degrees of freedom.", "token2charspan": [[0, 1], [2, 9], [10, 21], [22, 24], [25, 31], [32, 38], [39, 41], [42, 50], [51, 56], [57, 59], [60, 63], [64, 68], [68, 69], [69, 72], [72, 73], [73, 78], [79, 87], [88, 93], [93, 94], [95, 100], [101, 103], [104, 105], [106, 111], [112, 117], [117, 118], [119, 124], [125, 128], [129, 133], [134, 141], [142, 144], [145, 152], [152, 153]]}
{"doc_key": "ai-dev-121", "ner": [[10, 18, "conference"], [20, 20, "conference"], [23, 27, "conference"], [37, 38, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[20, 20, 10, 18, "named", "", false, false], [37, 38, 23, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "is", "a", "founding", "member", "and", "former", "chair", "of", "the", "Special", "Interest", "Group", "on", "the", "Web", "as", "a", "Corpus", "(", "SIGWAC", ")", "of", "the", "Association", "for", "Computational", "Linguistics", "(", "2006-2008", ")", "and", "one", "of", "the", "founding", "organisers", "of", "SENSEVAL", "."], "sentence-detokenized": "He is a founding member and former chair of the Special Interest Group on the Web as a Corpus (SIGWAC) of the Association for Computational Linguistics (2006-2008) and one of the founding organisers of SENSEVAL.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 16], [17, 23], [24, 27], [28, 34], [35, 40], [41, 43], [44, 47], [48, 55], [56, 64], [65, 70], [71, 73], [74, 77], [78, 81], [82, 84], [85, 86], [87, 93], [94, 95], [95, 101], [101, 102], [103, 105], [106, 109], [110, 121], [122, 125], [126, 139], [140, 151], [152, 153], [153, 162], [162, 163], [164, 167], [168, 171], [172, 174], [175, 178], [179, 187], [188, 198], [199, 201], [202, 210], [210, 211]]}
{"doc_key": "ai-dev-122", "ner": [[4, 4, "product"], [8, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 4, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "platform", ",", "LinguaStream", "offers", "an", "extensive", "Java", "API", "."], "sentence-detokenized": "As a platform, LinguaStream offers an extensive Java API.", "token2charspan": [[0, 2], [3, 4], [5, 13], [13, 14], [15, 27], [28, 34], [35, 37], [38, 47], [48, 52], [53, 56], [56, 57]]}
{"doc_key": "ai-dev-123", "ner": [[11, 11, "programlang"], [13, 16, "misc"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 19, 21, "type-of", "", false, false], [13, 16, 19, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "robot", "kit", "is", "based", "on", "Android", "and", "is", "programmed", "using", "Java", ",", "the", "Blocks", "programming", "interface", "or", "other", "Android", "programming", "systems", "."], "sentence-detokenized": "The robot kit is based on Android and is programmed using Java, the Blocks programming interface or other Android programming systems.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 16], [17, 22], [23, 25], [26, 33], [34, 37], [38, 40], [41, 51], [52, 57], [58, 62], [62, 63], [64, 67], [68, 74], [75, 86], [87, 96], [97, 99], [100, 105], [106, 113], [114, 125], [126, 133], [133, 134]]}
{"doc_key": "ai-dev-124", "ner": [[11, 14, "algorithm"], [16, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "method", "for", "defining", "a", "linked", "table", "specifies", "the", "use", "of", "depth", "-", "first", "search", "or", "breadth", "-", "first", "search", "."], "sentence-detokenized": "The method for defining a linked table specifies the use of depth-first search or breadth-first search.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 25], [26, 32], [33, 38], [39, 48], [49, 52], [53, 56], [57, 59], [60, 65], [65, 66], [66, 71], [72, 78], [79, 81], [82, 89], [89, 90], [90, 95], [96, 102], [102, 103]]}
{"doc_key": "ai-dev-125", "ner": [[20, 21, "task"], [25, 27, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "areas", "may", "signal", "the", "presence", "of", "objects", "or", "parts", "of", "objects", "in", "the", "image", "field", "and", "are", "suitable", "for", "object", "recognition", "and", "/", "or", "object", "video", "tracking", "."], "sentence-detokenized": "These areas may signal the presence of objects or parts of objects in the image field and are suitable for object recognition and/or object video tracking.", "token2charspan": [[0, 5], [6, 11], [12, 15], [16, 22], [23, 26], [27, 35], [36, 38], [39, 46], [47, 49], [50, 55], [56, 58], [59, 66], [67, 69], [70, 73], [74, 79], [80, 85], [86, 89], [90, 93], [94, 102], [103, 106], [107, 113], [114, 125], [126, 129], [129, 130], [130, 132], [133, 139], [140, 145], [146, 154], [154, 155]]}
{"doc_key": "ai-dev-126", "ner": [[4, 5, "algorithm"], [7, 7, "product"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 4, 5, "type-of", "", false, false], [7, 7, 14, 15, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "a", "semantic", "network", "is", "WordNet", ",", "a", "vocabulary", "database", "for", "the", "English", "language", "."], "sentence-detokenized": "An example of a semantic network is WordNet, a vocabulary database for the English language.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 24], [25, 32], [33, 35], [36, 43], [43, 44], [45, 46], [47, 57], [58, 66], [67, 70], [71, 74], [75, 82], [83, 91], [91, 92]]}
{"doc_key": "ai-dev-127", "ner": [[0, 1, "task"], [7, 8, "field"], [10, 11, "field"], [21, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 7, 8, "part-of", "", false, false], [0, 1, 10, 11, "named", "same", false, false], [0, 1, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Speech", "recognition", "is", "an", "interdisciplinary", "subfield", "of", "computer", "science", "and", "computational", "linguistics", "that", "develops", "methods", "and", "techniques", "that", "enable", "computers", "to", "recognise", "and", "translate", "spoken", "language", "into", "text", "."], "sentence-detokenized": "Speech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methods and techniques that enable computers to recognise and translate spoken language into text.", "token2charspan": [[0, 6], [7, 18], [19, 21], [22, 24], [25, 42], [43, 51], [52, 54], [55, 63], [64, 71], [72, 75], [76, 89], [90, 101], [102, 106], [107, 115], [116, 123], [124, 127], [128, 138], [139, 143], [144, 150], [151, 160], [161, 163], [164, 173], [174, 177], [178, 187], [188, 194], [195, 203], [204, 208], [209, 213], [213, 214]]}
{"doc_key": "ai-dev-128", "ner": [[0, 1, "field"], [9, 11, "misc"], [17, 19, "field"], [15, 15, "task"], [21, 22, "task"], [45, 46, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 45, 46, "named", "same", false, false], [17, 19, 0, 1, "part-of", "subfield", false, false], [15, 15, 0, 1, "part-of", "", false, false], [15, 15, 17, 19, "part-of", "", false, false], [21, 22, 17, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Artificial", "intelligence", "retains", "the", "most", "attention", "in", "terms", "of", "applied", "ontologies", "in", "subfields", "such", "as", "machine", "and", "natural", "language", "processing", "within", "knowledge", "representation", ",", "but", "ontology", "editing", "is", "often", "used", "in", "a", "range", "of", "areas", "such", "as", "education", "and", "is", "not", "intended", "to", "contribute", "to", "artificial", "intelligence", "."], "sentence-detokenized": "Artificial intelligence retains the most attention in terms of applied ontologies in subfields such as machine and natural language processing within knowledge representation, but ontology editing is often used in a range of areas such as education and is not intended to contribute to artificial intelligence.", "token2charspan": [[0, 10], [11, 23], [24, 31], [32, 35], [36, 40], [41, 50], [51, 53], [54, 59], [60, 62], [63, 70], [71, 81], [82, 84], [85, 94], [95, 99], [100, 102], [103, 110], [111, 114], [115, 122], [123, 131], [132, 142], [143, 149], [150, 159], [160, 174], [174, 175], [176, 179], [180, 188], [189, 196], [197, 199], [200, 205], [206, 210], [211, 213], [214, 215], [216, 221], [222, 224], [225, 230], [231, 235], [236, 238], [239, 248], [249, 252], [253, 255], [256, 259], [260, 268], [269, 271], [272, 282], [283, 285], [286, 296], [297, 309], [309, 310]]}
{"doc_key": "ai-dev-129", "ner": [[6, 8, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 11, 12, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["This", "update", "rule", "is", "effectively", "a", "stochastic", "gradient", "descent", "update", "of", "linear", "regression", "."], "sentence-detokenized": "This update rule is effectively a stochastic gradient descent update of linear regression.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 19], [20, 31], [32, 33], [34, 44], [45, 53], [54, 61], [62, 68], [69, 71], [72, 78], [79, 89], [89, 90]]}
{"doc_key": "ai-dev-130", "ner": [[4, 10, "organisation"], [12, 20, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "was", "elected", "to", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "the", "National", "Academy", "of", "Sciences", ",", "and", "has", "received", "a", "number", "of", "awards", "."], "sentence-detokenized": "He was elected to the American Academy of Arts and Sciences and the National Academy of Sciences, and has received a number of awards.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 21], [22, 30], [31, 38], [39, 41], [42, 46], [47, 50], [51, 59], [60, 63], [64, 67], [68, 76], [77, 84], [85, 87], [88, 96], [96, 97], [98, 101], [102, 105], [106, 114], [115, 116], [117, 123], [124, 126], [127, 133], [133, 134]]}
{"doc_key": "ai-dev-131", "ner": [[6, 7, "organisation"], [13, 14, "person"], [16, 21, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 13, 14, "related-to", "written_about_by", false, false], [6, 7, 16, 21, "related-to", "written_about_by", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "latest", "school", "of", "thought", "on", "Honda", "'s", "strategy", "was", "put", "forward", "by", "Gary", "Hamel", "and", "C.", "K", ".", "Prahalad", "in", "1989", "."], "sentence-detokenized": "The latest school of thought on Honda's strategy was put forward by Gary Hamel and C. K. Prahalad in 1989.", "token2charspan": [[0, 3], [4, 10], [11, 17], [18, 20], [21, 28], [29, 31], [32, 37], [37, 39], [40, 48], [49, 52], [53, 56], [57, 64], [65, 67], [68, 72], [73, 78], [79, 82], [83, 85], [86, 87], [87, 88], [89, 97], [98, 100], [101, 105], [105, 106]]}
{"doc_key": "ai-dev-132", "ner": [[0, 0, "metrics"], [4, 4, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "related-to", "calculates", true, false], [0, 0, 20, 20, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["BLEU", "simply", "calculates", "the", "accuracy", "of", "the", "n-", "grams", "by", "adding", "the", "same", "weight", "to", "each", "n-", "gram", ",", "whereas", "NIST", "also", "calculates", "how", "informative", "a", "particular", "n-", "gram", "is", "."], "sentence-detokenized": "BLEU simply calculates the accuracy of the n-grams by adding the same weight to each n-gram, whereas NIST also calculates how informative a particular n-gram is.", "token2charspan": [[0, 4], [5, 11], [12, 22], [23, 26], [27, 35], [36, 38], [39, 42], [43, 45], [45, 50], [51, 53], [54, 60], [61, 64], [65, 69], [70, 76], [77, 79], [80, 84], [85, 87], [87, 91], [91, 92], [93, 100], [101, 105], [106, 110], [111, 121], [122, 125], [126, 137], [138, 139], [140, 150], [151, 153], [153, 157], [158, 160], [160, 161]]}
{"doc_key": "ai-dev-133", "ner": [[3, 7, "misc"], [10, 13, "conference"], [11, 15, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 7, 10, 13, "temporal", "", false, false], [11, 15, 10, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "awarded", "the", "2019", "Lifetime", "Achievement", "Award", "from", "the", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "."], "sentence-detokenized": "He was awarded the 2019 Lifetime Achievement Award from the Association for Computational Linguistics (ACL).", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 18], [19, 23], [24, 32], [33, 44], [45, 50], [51, 55], [56, 59], [60, 71], [72, 75], [76, 89], [90, 101], [102, 103], [103, 106], [106, 107], [107, 108]]}
{"doc_key": "ai-dev-134", "ner": [[0, 0, "researcher"], [8, 11, "organisation"], [13, 13, "organisation"], [19, 24, "conference"], [21, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 11, "role", "", false, false], [0, 0, 19, 24, "role", "", false, false], [13, 13, 8, 11, "named", "", false, false], [21, 26, 19, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sycara", "is", "a", "member", "of", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", "and", "a", "member", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Sycara is a member of the Institute of Electrical and Electronics Engineers (IEEE) and a member of the American Association for Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 18], [19, 21], [22, 25], [26, 35], [36, 38], [39, 49], [50, 53], [54, 65], [66, 75], [76, 77], [77, 81], [81, 82], [83, 86], [87, 88], [89, 95], [96, 98], [99, 102], [103, 111], [112, 123], [124, 127], [128, 138], [139, 151], [152, 153], [153, 157], [157, 158], [158, 159]]}
{"doc_key": "ai-dev-135", "ner": [[2, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "MATLAB", "code", "demonstrates", "a", "specific", "solution", "to", "the", "system", "of", "non-linear", "equations", "presented", "in", "the", "previous", "section", ".", "See", "also"], "sentence-detokenized": "The following MATLAB code demonstrates a specific solution to the system of non-linear equations presented in the previous section. See also", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 38], [39, 40], [41, 49], [50, 58], [59, 61], [62, 65], [66, 72], [73, 75], [76, 86], [87, 96], [97, 106], [107, 109], [110, 113], [114, 122], [123, 130], [130, 131], [132, 135], [136, 140]]}
{"doc_key": "ai-dev-136", "ner": [[4, 7, "product"], [14, 14, "field"], [15, 38, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 7, 14, 14, "related-to", "trained_by", true, false], [4, 7, 15, 38, "related-to", "trained_by", true, false], [14, 14, 15, 38, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "many", "cases", ",", "pattern", "recognition", "systems", "are", "trained", "on", "labelled", "training", "data", "(", "supervised", "learning", ")", ",", "but", "when", "no", "labelled", "data", "is", "available", ",", "other", "algorithms", "can", "be", "used", "to", "discover", "previously", "unknown", "patterns", "(", "unsupervised", "learning", ")", "."], "sentence-detokenized": "In many cases, pattern recognition systems are trained on labelled training data (supervised learning), but when no labelled data is available, other algorithms can be used to discover previously unknown patterns (unsupervised learning).", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 22], [23, 34], [35, 42], [43, 46], [47, 54], [55, 57], [58, 66], [67, 75], [76, 80], [81, 82], [82, 92], [93, 101], [101, 102], [102, 103], [104, 107], [108, 112], [113, 115], [116, 124], [125, 129], [130, 132], [133, 142], [142, 143], [144, 149], [150, 160], [161, 164], [165, 167], [168, 172], [173, 175], [176, 184], [185, 195], [196, 203], [204, 212], [213, 214], [214, 226], [227, 235], [235, 236], [236, 237]]}
{"doc_key": "ai-dev-137", "ner": [[8, 10, "researcher"], [11, 14, "country"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 11, 14, "physical", "", false, false], [8, 10, 24, 25, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "approach", "was", "first", "used", "in", "1960", "by", "Lawrence", "J.", "Fogel", "in", "the", "USA", "to", "simulate", "evolution", "as", "a", "learning", "process", "aimed", "at", "generating", "artificial", "intelligence", "."], "sentence-detokenized": "This approach was first used in 1960 by Lawrence J. Fogel in the USA to simulate evolution as a learning process aimed at generating artificial intelligence.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 23], [24, 28], [29, 31], [32, 36], [37, 39], [40, 48], [49, 51], [52, 57], [58, 60], [61, 64], [65, 68], [69, 71], [72, 80], [81, 90], [91, 93], [94, 95], [96, 104], [105, 112], [113, 118], [119, 121], [122, 132], [133, 143], [144, 156], [156, 157]]}
{"doc_key": "ai-dev-138", "ner": [[0, 2, "field"], [8, 9, "field"], [13, 13, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 8, 9, "part-of", "", false, false], [13, 13, 8, 9, "part-of", "", false, false], [15, 16, 8, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Reinforcement", "learning", "is", "one", "of", "the", "three", "basic", "machine", "learning", "paradigms", ",", "alongside", "supervised", "and", "unsupervised", "learning", "."], "sentence-detokenized": "Reinforcement learning is one of the three basic machine learning paradigms, alongside supervised and unsupervised learning.", "token2charspan": [[0, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 42], [43, 48], [49, 56], [57, 65], [66, 75], [75, 76], [77, 86], [87, 97], [98, 101], [102, 114], [115, 123], [123, 124]]}
{"doc_key": "ai-dev-139", "ner": [[4, 5, "field"], [12, 12, "programlang"], [28, 29, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 28, 29, "usage", "applies", false, false], [12, 12, 28, 29, "usage", "applies", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "this", "context", ",", "cloud", "computing", "and", "the", "open", "source", "programming", "language", "R", "can", "help", "small", "banks", "adopt", "risk", "analytics", "and", "support", "monitoring", "at", "branch", "level", "by", "applying", "predictive", "analytics", "."], "sentence-detokenized": "In this context, cloud computing and the open source programming language R can help small banks adopt risk analytics and support monitoring at branch level by applying predictive analytics.", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 22], [23, 32], [33, 36], [37, 40], [41, 45], [46, 52], [53, 64], [65, 73], [74, 75], [76, 79], [80, 84], [85, 90], [91, 96], [97, 102], [103, 107], [108, 117], [118, 121], [122, 129], [130, 140], [141, 143], [144, 150], [151, 156], [157, 159], [160, 168], [169, 179], [180, 189], [189, 190]]}
{"doc_key": "ai-dev-140", "ner": [[11, 12, "researcher"], [16, 18, "algorithm"], [22, 23, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 22, 23, "named", "same", false, false], [16, 18, 11, 12, "origin", "proves_function", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["One", "of", "the", "earliest", "versions", "of", "this", "theorem", "was", "proved", "by", "George", "Cybenko", "in", "1989", "for", "the", "sigmoid", "function", "activation", "function", ".", "cybenko", "G.", "(", "1989", ")", ",", "2", "(", "4", ")", ",", "303-314", "."], "sentence-detokenized": "One of the earliest versions of this theorem was proved by George Cybenko in 1989 for the sigmoid function activation function. cybenko G. (1989), 2(4), 303-314.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 19], [20, 28], [29, 31], [32, 36], [37, 44], [45, 48], [49, 55], [56, 58], [59, 65], [66, 73], [74, 76], [77, 81], [82, 85], [86, 89], [90, 97], [98, 106], [107, 117], [118, 126], [126, 127], [128, 135], [136, 138], [139, 140], [140, 144], [144, 145], [145, 146], [147, 148], [148, 149], [149, 150], [150, 151], [151, 152], [153, 160], [160, 161]]}
{"doc_key": "ai-dev-141", "ner": [[7, 7, "algorithm"], [10, 11, "metrics"], [16, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 7, 7, "part-of", "", false, false], [16, 24, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "this", "process", ",", "also", "known", "as", "cross-validation", ",", "the", "MSE", "is", "commonly", "referred", "to", "as", "the", "square", "of", "the", "mean", "forecast", "error", "and", "is", "calculated", "as"], "sentence-detokenized": "In this process, also known as cross-validation, the MSE is commonly referred to as the square of the mean forecast error and is calculated as", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 21], [22, 27], [28, 30], [31, 47], [47, 48], [49, 52], [53, 56], [57, 59], [60, 68], [69, 77], [78, 80], [81, 83], [84, 87], [88, 94], [95, 97], [98, 101], [102, 106], [107, 115], [116, 121], [122, 125], [126, 128], [129, 139], [140, 142]]}
{"doc_key": "ai-dev-142", "ner": [[0, 1, "task"], [5, 7, "task"], [9, 9, "task"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 5, 7, "compare", "", false, false], [5, 7, 18, 19, "part-of", "", false, false], [9, 9, 5, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OMR", "is", "often", "distinguished", "from", "optical", "character", "recognition", "(", "OCR", ")", "because", "it", "does", "not", "require", "a", "sophisticated", "pattern", "recognition", "engine", "."], "sentence-detokenized": "OMR is often distinguished from optical character recognition (OCR) because it does not require a sophisticated pattern recognition engine.", "token2charspan": [[0, 3], [4, 6], [7, 12], [13, 26], [27, 31], [32, 39], [40, 49], [50, 61], [62, 63], [63, 66], [66, 67], [68, 75], [76, 78], [79, 83], [84, 87], [88, 95], [96, 97], [98, 111], [112, 119], [120, 131], [132, 138], [138, 139]]}
{"doc_key": "ai-dev-143", "ner": [[18, 18, "location"], [20, 20, "location"], [22, 22, "location"], [11, 13, "location"], [15, 17, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[20, 20, 22, 22, "physical", "", false, false], [11, 13, 20, 20, "physical", "", false, false], [15, 17, 20, 20, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2018", "and", "2019", ",", "the", "championships", "will", "be", "held", "at", "the", "TCF", "Center", "and", "Ford", "Field", "in", "Houston", "and", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "In 2018 and 2019, the championships will be held at the TCF Center and Ford Field in Houston and Detroit, Michigan.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 16], [16, 17], [18, 21], [22, 35], [36, 40], [41, 43], [44, 48], [49, 51], [52, 55], [56, 59], [60, 66], [67, 70], [71, 75], [76, 81], [82, 84], [85, 92], [93, 96], [97, 104], [104, 105], [106, 114], [114, 115]]}
{"doc_key": "ai-dev-144", "ner": [[0, 0, "task"], [10, 11, "task"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 0, 0, "part-of", "", false, false], [13, 14, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "thought", "of", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multi-level", "classification", "."], "sentence-detokenized": "Classification can be thought of as two separate problems - binary classification and multi-level classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 29], [30, 32], [33, 35], [36, 39], [40, 48], [49, 57], [58, 59], [60, 66], [67, 81], [82, 85], [86, 97], [98, 112], [112, 113]]}
{"doc_key": "ai-dev-145", "ner": [[4, 5, "product"], [8, 9, "product"], [11, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 4, 5, "type-of", "", false, false], [11, 13, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "examples", "of", "popular", "parallel", "robots", "are", "the", "Stewart", "platform", "and", "the", "Delta", "robot", "."], "sentence-detokenized": "Two examples of popular parallel robots are the Stewart platform and the Delta robot.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 23], [24, 32], [33, 39], [40, 43], [44, 47], [48, 55], [56, 64], [65, 68], [69, 72], [73, 78], [79, 84], [84, 85]]}
{"doc_key": "ai-dev-146", "ner": [[3, 5, "algorithm"], [21, 21, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 5, 21, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "However", ",", "ReLU", "activation", "functions", ",", "which", "are", "indistinguishable", "at", "0", ",", "have", "become", "quite", "popular", ",", "for", "example", "in", "AlexNet", ".", ")"], "sentence-detokenized": "(However, ReLU activation functions, which are indistinguishable at 0, have become quite popular, for example in AlexNet.)", "token2charspan": [[0, 1], [1, 8], [8, 9], [10, 14], [15, 25], [26, 35], [35, 36], [37, 42], [43, 46], [47, 64], [65, 67], [68, 69], [69, 70], [71, 75], [76, 82], [83, 88], [89, 96], [96, 97], [98, 101], [102, 109], [110, 112], [113, 120], [120, 121], [121, 122]]}
{"doc_key": "ai-dev-147", "ner": [[0, 4, "metrics"], [11, 13, "task"], [18, 18, "task"], [20, 21, "task"], [23, 27, "task"], [30, 30, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 4, 30, 30, "named", "", true, false], [11, 13, 0, 4, "usage", "", true, false], [18, 18, 11, 13, "part-of", "", false, false], [20, 21, 11, 13, "part-of", "", false, false], [23, 27, 11, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "F", "-", "score", "is", "often", "used", "in", "the", "field", "of", "information", "retrieval", "to", "measure", "the", "performance", "of", "search", ",", "document", "classification", "and", "query", "classification", ".", "As", "a", "result", ",", "F_beta", "is", "seen", "as", "widely", "used", "."], "sentence-detokenized": "The F-score is often used in the field of information retrieval to measure the performance of search, document classification and query classification. As a result, F_beta is seen as widely used.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 20], [21, 25], [26, 28], [29, 32], [33, 38], [39, 41], [42, 53], [54, 63], [64, 66], [67, 74], [75, 78], [79, 90], [91, 93], [94, 100], [100, 101], [102, 110], [111, 125], [126, 129], [130, 135], [136, 150], [150, 151], [152, 154], [155, 156], [157, 163], [163, 164], [165, 171], [172, 174], [175, 179], [180, 182], [183, 189], [190, 194], [194, 195]]}
{"doc_key": "ai-dev-148", "ner": [[16, 17, "algorithm"], [19, 19, "algorithm"], [22, 23, "algorithm"], [25, 25, "algorithm"], [28, 30, "algorithm"], [32, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[19, 19, 16, 17, "named", "", false, false], [25, 25, 22, 23, "named", "", false, false], [32, 32, 28, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "is", "done", "by", "modelling", "the", "received", "signal", "and", "then", "using", "statistical", "estimation", "methods", "such", "as", "Maximum", "Likelihood", "(", "ML", ")", ",", "Majority", "Voting", "(", "MV", ")", "or", "Maximum", "A", "Posteriori", "(", "MAP", ")", "to", "determine", "which", "target", "in", "the", "library", "best", "fits", "the", "model", "built", "using", "the", "received", "signal", "."], "sentence-detokenized": "This is done by modelling the received signal and then using statistical estimation methods such as Maximum Likelihood (ML), Majority Voting (MV) or Maximum A Posteriori (MAP) to determine which target in the library best fits the model built using the received signal.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 15], [16, 25], [26, 29], [30, 38], [39, 45], [46, 49], [50, 54], [55, 60], [61, 72], [73, 83], [84, 91], [92, 96], [97, 99], [100, 107], [108, 118], [119, 120], [120, 122], [122, 123], [123, 124], [125, 133], [134, 140], [141, 142], [142, 144], [144, 145], [146, 148], [149, 156], [157, 158], [159, 169], [170, 171], [171, 174], [174, 175], [176, 178], [179, 188], [189, 194], [195, 201], [202, 204], [205, 208], [209, 216], [217, 221], [222, 226], [227, 230], [231, 236], [237, 242], [243, 248], [249, 252], [253, 261], [262, 268], [268, 269]]}
{"doc_key": "ai-dev-149", "ner": [[0, 0, "researcher"], [2, 4, "misc"], [5, 5, "field"], [7, 8, "university"], [11, 13, "misc"], [14, 14, "field"], [16, 17, "university"], [22, 23, "misc"], [24, 68, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 10], "relations": [[0, 0, 7, 8, "physical", "", false, false], [0, 0, 7, 8, "role", "", false, false], [0, 0, 16, 17, "physical", "", false, false], [0, 0, 16, 17, "role", "", false, false], [2, 4, 0, 0, "origin", "", false, false], [2, 4, 5, 5, "topic", "", false, false], [11, 13, 0, 0, "origin", "", false, false], [11, 13, 14, 14, "topic", "", false, false], [22, 23, 0, 0, "origin", "", false, false], [24, 68, 22, 23, "named", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 6, 7, 8, 9, 10, 12], "sentence": ["Sowa", "received", "a", "BSc", "in", "mathematics", "from", "MIT", "in", "1962", ",", "an", "MSc", "in", "applications", "from", "Harvard", "University", "in", "1966", "and", "a", "PhD", "in", "computer", "science", "from", "the", "Free", "University", "of", "Brussels", "in", "1999", "with", "a", "thesis", "on", "knowledge", "representation", ".", "1999", "saw", "him", "receive", "a", "PhD", "in", "computer", "science", "from", "the", "Free", "University", "of", "Brussels", "with", "a", "thesis", "on", "knowledge", "representation", ":", "logic", ",", "philosophy", "and", "computational", "Foundations", "\"", "."], "sentence-detokenized": "Sowa received a BSc in mathematics from MIT in 1962, an MSc in applications from Harvard University in 1966 and a PhD in computer science from the Free University of Brussels in 1999 with a thesis on knowledge representation. 1999 saw him receive a PhD in computer science from the Free University of Brussels with a thesis on knowledge representation: logic, philosophy and computational Foundations\".", "token2charspan": [[0, 4], [5, 13], [14, 15], [16, 19], [20, 22], [23, 34], [35, 39], [40, 43], [44, 46], [47, 51], [51, 52], [53, 55], [56, 59], [60, 62], [63, 75], [76, 80], [81, 88], [89, 99], [100, 102], [103, 107], [108, 111], [112, 113], [114, 117], [118, 120], [121, 129], [130, 137], [138, 142], [143, 146], [147, 151], [152, 162], [163, 165], [166, 174], [175, 177], [178, 182], [183, 187], [188, 189], [190, 196], [197, 199], [200, 209], [210, 224], [224, 225], [226, 230], [231, 234], [235, 238], [239, 246], [247, 248], [249, 252], [253, 255], [256, 264], [265, 272], [273, 277], [278, 281], [282, 286], [287, 297], [298, 300], [301, 309], [310, 314], [315, 316], [317, 323], [324, 326], [327, 336], [337, 351], [351, 352], [353, 358], [358, 359], [360, 370], [371, 374], [375, 388], [389, 400], [400, 401], [401, 402]]}
{"doc_key": "ai-dev-150", "ner": [[1, 2, "task"], [9, 9, "task"], [19, 19, "metrics"], [21, 22, "metrics"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 9, 9, "general-affiliation", "", false, false], [19, 19, 1, 2, "part-of", "", true, false], [21, 22, 1, 2, "part-of", "", true, false], [24, 25, 1, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["As", "paraphrase", "recognition", "can", "be", "set", "up", "as", "a", "classification", "problem", ",", "most", "standard", "evaluation", "metrics", ",", "such", "as", "accuracy", ",", "f1", "scores", "or", "ROC", "curves", ",", "do", "relatively", "well", "."], "sentence-detokenized": "As paraphrase recognition can be set up as a classification problem, most standard evaluation metrics, such as accuracy, f1 scores or ROC curves, do relatively well.", "token2charspan": [[0, 2], [3, 13], [14, 25], [26, 29], [30, 32], [33, 36], [37, 39], [40, 42], [43, 44], [45, 59], [60, 67], [67, 68], [69, 73], [74, 82], [83, 93], [94, 101], [101, 102], [103, 107], [108, 110], [111, 119], [119, 120], [121, 123], [124, 130], [131, 133], [134, 137], [138, 144], [144, 145], [146, 148], [149, 159], [160, 164], [164, 165]]}
{"doc_key": "ai-dev-151", "ner": [[16, 16, "algorithm"], [26, 27, "algorithm"], [29, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 16, 26, 27, "opposite", "not_suited_for", false, false], [16, 16, 29, 30, "opposite", "not_suited_for", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "makes", "it", "practical", "for", "analysing", "large", "datasets", "(", "hundreds", "or", "thousands", "of", "taxa", ")", "and", "bootstrapping", ",", "for", "which", "other", "means", "of", "analysis", "(", "e.g.", "maximum", "analysis", ",", "maximum", "likelihood", ")", "may", "be", "computationally", "difficult", "to", "achieve", "."], "sentence-detokenized": "This makes it practical for analysing large datasets (hundreds or thousands of taxa) and bootstrapping, for which other means of analysis (e.g. maximum analysis, maximum likelihood) may be computationally difficult to achieve.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 37], [38, 43], [44, 52], [53, 54], [54, 62], [63, 65], [66, 75], [76, 78], [79, 83], [83, 84], [85, 88], [89, 102], [102, 103], [104, 107], [108, 113], [114, 119], [120, 125], [126, 128], [129, 137], [138, 139], [139, 143], [144, 151], [152, 160], [160, 161], [162, 169], [170, 180], [180, 181], [182, 185], [186, 188], [189, 204], [205, 214], [215, 217], [218, 225], [225, 226]]}
{"doc_key": "ai-dev-152", "ner": [[0, 3, "programlang"], [8, 12, "organisation"], [14, 14, "organisation"], [24, 24, "programlang"], [27, 37, "organisation"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[14, 14, 8, 12, "named", "", false, false], [27, 37, 0, 3, "role", "submits", true, false], [27, 37, 8, 12, "role", "submits_to", true, false]], "relations_mapping_to_source": [1, 3, 4], "sentence": ["The", "DAML", "+", "OIL", "language", ",", "submitted", "to", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", "in", "2002", ",", "is", "the", "work", "of", "the", "DAML", "contractor", "and", "the", "Ad", "Hoc", "Joint", "EU", "/", "US", "Committee", "on", "Markup", "Languages", "."], "sentence-detokenized": "The DAML+OIL language, submitted to the World Wide Web Consortium (W3C) in 2002, is the work of the DAML contractor and the Ad Hoc Joint EU/US Committee on Markup Languages.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 12], [13, 21], [21, 22], [23, 32], [33, 35], [36, 39], [40, 45], [46, 50], [51, 54], [55, 65], [66, 67], [67, 70], [70, 71], [72, 74], [75, 79], [79, 80], [81, 83], [84, 87], [88, 92], [93, 95], [96, 99], [100, 104], [105, 115], [116, 119], [120, 123], [124, 126], [127, 130], [131, 136], [137, 139], [139, 140], [140, 142], [143, 152], [153, 155], [156, 162], [163, 172], [172, 173]]}
{"doc_key": "ai-dev-153", "ner": [[2, 4, "misc"], [8, 8, "misc"], [11, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 2, 4, "part-of", "", true, false], [11, 14, 2, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "nonlinear", "normalization", "is", "when", "the", "normalization", "follows", "a", "sigmoid", "function", ",", "in", "which", "case", "the", "normalized", "image", "is", "calculated", "according", "to", "the", "formula"], "sentence-detokenized": "An example of nonlinear normalization is when the normalization follows a sigmoid function, in which case the normalized image is calculated according to the formula", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 23], [24, 37], [38, 40], [41, 45], [46, 49], [50, 63], [64, 71], [72, 73], [74, 81], [82, 90], [90, 91], [92, 94], [95, 100], [101, 105], [106, 109], [110, 120], [121, 126], [127, 129], [130, 140], [141, 150], [151, 153], [154, 157], [158, 165]]}
{"doc_key": "ai-dev-154", "ner": [[9, 10, "metrics"], [14, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 10, 14, 14, "related-to", "used_together", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "noted", "that", "to", "overcome", "this", "problem", ",", "precision", "is", "usually", "combined", "with", "recall", "."], "sentence-detokenized": "It was noted that to overcome this problem, precision is usually combined with recall.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 17], [18, 20], [21, 29], [30, 34], [35, 42], [42, 43], [44, 53], [54, 56], [57, 64], [65, 73], [74, 78], [79, 85], [85, 86]]}
{"doc_key": "ai-dev-155", "ner": [[4, 6, "metrics"], [8, 13, "metrics"], [20, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 23, 8, 13, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Commonly", "used", "metrics", "are", "mean", "squared", "error", "and", "mean", "square", "root", "error", ",", "the", "latter", "of", "which", "has", "been", "used", "in", "the", "Netflix", "awards", "."], "sentence-detokenized": "Commonly used metrics are mean squared error and mean square root error, the latter of which has been used in the Netflix awards.", "token2charspan": [[0, 8], [9, 13], [14, 21], [22, 25], [26, 30], [31, 38], [39, 44], [45, 48], [49, 53], [54, 60], [61, 65], [66, 71], [71, 72], [73, 76], [77, 83], [84, 86], [87, 92], [93, 96], [97, 101], [102, 106], [107, 109], [110, 113], [114, 121], [122, 128], [128, 129]]}
{"doc_key": "ai-dev-156", "ner": [[12, 16, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "August", "2016", ",", "a", "research", "programme", "was", "announced", "in", "collaboration", "with", "University", "College", "Hospital", "with", "the", "aim", "of", "developing", "an", "algorithm", "that", "can", "automatically", "distinguish", "between", "healthy", "and", "cancerous", "tissue", "in", "the", "head", "and", "neck", "."], "sentence-detokenized": "In August 2016, a research programme was announced in collaboration with University College Hospital with the aim of developing an algorithm that can automatically distinguish between healthy and cancerous tissue in the head and neck.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 17], [18, 26], [27, 36], [37, 40], [41, 50], [51, 53], [54, 67], [68, 72], [73, 83], [84, 91], [92, 100], [101, 105], [106, 109], [110, 113], [114, 116], [117, 127], [128, 130], [131, 140], [141, 145], [146, 149], [150, 163], [164, 175], [176, 183], [184, 191], [192, 195], [196, 205], [206, 212], [213, 215], [216, 219], [220, 224], [225, 228], [229, 233], [233, 234]]}
{"doc_key": "ai-dev-157", "ner": [[3, 3, "researcher"], [16, 18, "organisation"], [20, 24, "organisation"], [26, 30, "organisation"], [32, 38, "organisation"], [41, 47, "organisation"], [49, 53, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 16, 18, "role", "", false, false], [3, 3, 20, 24, "role", "", false, false], [3, 3, 26, 30, "role", "", false, false], [3, 3, 32, 38, "role", "", false, false], [3, 3, 41, 47, "role", "", false, false], [3, 3, 49, 53, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "impact", "of", "Posner", "'s", "theoretical", "and", "empirical", "contributions", "has", "been", "recognised", "through", "fellowships", "from", "the", "American", "Psychological", "Association", ",", "the", "Association", "for", "Psychological", "Science", ",", "the", "Society", "of", "Experimental", "Psychologists", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "The impact of Posner's theoretical and empirical contributions has been recognised through fellowships from the American Psychological Association, the Association for Psychological Science, the Society of Experimental Psychologists, the American Academy of Arts and Sciences, the American Association for the Advancement of Science and the National Academy of Sciences.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 20], [20, 22], [23, 34], [35, 38], [39, 48], [49, 62], [63, 66], [67, 71], [72, 82], [83, 90], [91, 102], [103, 107], [108, 111], [112, 120], [121, 134], [135, 146], [146, 147], [148, 151], [152, 163], [164, 167], [168, 181], [182, 189], [189, 190], [191, 194], [195, 202], [203, 205], [206, 218], [219, 232], [232, 233], [234, 237], [238, 246], [247, 254], [255, 257], [258, 262], [263, 266], [267, 275], [275, 276], [277, 280], [281, 289], [290, 301], [302, 305], [306, 309], [310, 321], [322, 324], [325, 332], [333, 336], [337, 340], [341, 349], [350, 357], [358, 360], [361, 369], [369, 370]]}
{"doc_key": "ai-dev-158", "ner": [[2, 5, "product"], [7, 8, "field"], [11, 12, "task"], [14, 16, "task"], [18, 18, "task"], [21, 23, "task"], [25, 25, "task"], [28, 29, "field"], [31, 32, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 5, 7, 8, "usage", "", false, false], [11, 12, 7, 8, "part-of", "", false, false], [14, 16, 7, 8, "part-of", "", false, false], [18, 18, 14, 16, "named", "", false, false], [21, 23, 7, 8, "part-of", "", false, false], [25, 25, 21, 23, "named", "", false, false], [28, 29, 7, 8, "part-of", "", false, false], [31, 32, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["These", "intelligent", "chatbots", "make", "use", "of", "various", "artificial", "intelligence", "such", "as", "image", "modulation", "and", "natural", "language", "understanding", "(", "NLU", ")", ",", "natural", "language", "generation", "(", "NLG", ")", ",", "machine", "learning", "and", "deep", "learning", "."], "sentence-detokenized": "These intelligent chatbots make use of various artificial intelligence such as image modulation and natural language understanding (NLU), natural language generation (NLG), machine learning and deep learning.", "token2charspan": [[0, 5], [6, 17], [18, 26], [27, 31], [32, 35], [36, 38], [39, 46], [47, 57], [58, 70], [71, 75], [76, 78], [79, 84], [85, 95], [96, 99], [100, 107], [108, 116], [117, 130], [131, 132], [132, 135], [135, 136], [136, 137], [138, 145], [146, 154], [155, 165], [166, 167], [167, 170], [170, 171], [171, 172], [173, 180], [181, 189], [190, 193], [194, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-dev-159", "ner": [[4, 6, "metrics"], [8, 8, "metrics"], [13, 13, "metrics"], [16, 22, "metrics"], [27, 29, "metrics"], [31, 31, "metrics"], [34, 41, "metrics"], [44, 46, "metrics"], [48, 48, "metrics"], [51, 58, "metrics"], [29, 64, "metrics"], [66, 66, "metrics"], [69, 76, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 4, 6, "named", "", false, false], [13, 13, 4, 6, "named", "", false, false], [16, 22, 4, 6, "named", "", false, false], [31, 31, 27, 29, "named", "", false, false], [34, 41, 27, 29, "named", "", false, false], [48, 48, 44, 46, "named", "", false, false], [51, 58, 44, 46, "named", "", false, false], [66, 66, 29, 64, "named", "", false, false], [69, 76, 29, 64, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "line", "ratios", "are", "positive", "predictive", "value", "(", "PPV", ",", "also", "known", "as", "precision", ")", "(", "TP", "/", "(", "TP", "+", "FP", ")", ")", ",", "supplemented", "by", "false", "discovery", "rate", "(", "FDR", ")", "(", "FP", "/", "(", "TP", "+", "FP", ")", ")", ";", "and", "negative", "predictive", "value", "(", "NPV", ")", "(", "TN", "/", "(", "TN", "+", "FN", ")", ")", ",", "supplemented", "by", "false", "omission", "rate", "(", "FOR", ")", "(", "FN", "/", "(", "TN", "+", "FN", ")", ")", "."], "sentence-detokenized": "The line ratios are positive predictive value (PPV, also known as precision) (TP/(TP+FP)), supplemented by false discovery rate (FDR) (FP/(TP+FP)); and negative predictive value (NPV) (TN/(TN+FN)), supplemented by false omission rate (FOR) (FN/(TN+FN)).", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 19], [20, 28], [29, 39], [40, 45], [46, 47], [47, 50], [50, 51], [52, 56], [57, 62], [63, 65], [66, 75], [75, 76], [77, 78], [78, 80], [80, 81], [81, 82], [82, 84], [84, 85], [85, 87], [87, 88], [88, 89], [89, 90], [91, 103], [104, 106], [107, 112], [113, 122], [123, 127], [128, 129], [129, 132], [132, 133], [134, 135], [135, 137], [137, 138], [138, 139], [139, 141], [141, 142], [142, 144], [144, 145], [145, 146], [146, 147], [148, 151], [152, 160], [161, 171], [172, 177], [178, 179], [179, 182], [182, 183], [184, 185], [185, 187], [187, 188], [188, 189], [189, 191], [191, 192], [192, 194], [194, 195], [195, 196], [196, 197], [198, 210], [211, 213], [214, 219], [220, 228], [229, 233], [234, 235], [235, 238], [238, 239], [240, 241], [241, 243], [243, 244], [244, 245], [245, 247], [247, 248], [248, 250], [250, 251], [251, 252], [252, 253]]}
{"doc_key": "ai-dev-160", "ner": [[8, 8, "misc"], [13, 15, "algorithm"], [17, 17, "algorithm"], [21, 23, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[17, 17, 13, 15, "named", "", false, false], [25, 25, 21, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "information", "is", "a", "mixture", "of", "sitemap", "and", "RSS", "and", "is", "created", "using", "the", "Information", "Model", "(", "IM", ")", "and", "the", "Biomedical", "Resource", "Ontology", "(", "BRO", ")", "."], "sentence-detokenized": "The information is a mixture of sitemap and RSS and is created using the Information Model (IM) and the Biomedical Resource Ontology (BRO).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 20], [21, 28], [29, 31], [32, 39], [40, 43], [44, 47], [48, 51], [52, 54], [55, 62], [63, 68], [69, 72], [73, 84], [85, 90], [91, 92], [92, 94], [94, 95], [96, 99], [100, 103], [104, 114], [115, 123], [124, 132], [133, 134], [134, 137], [137, 138], [138, 139]]}
{"doc_key": "ai-dev-161", "ner": [[1, 2, "task"], [6, 8, "algorithm"], [10, 15, "algorithm"], [21, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 10, 15, "origin", "based_on", false, false], [10, 15, 6, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Recent", "text", "recognition", "is", "based", "on", "recurrent", "neural", "networks", "(", "long", "and", "short", "-", "term", "memory", ")", "and", "does", "not", "require", "a", "language", "model", "."], "sentence-detokenized": "Recent text recognition is based on recurrent neural networks (long and short-term memory) and does not require a language model.", "token2charspan": [[0, 6], [7, 11], [12, 23], [24, 26], [27, 32], [33, 35], [36, 45], [46, 52], [53, 61], [62, 63], [63, 67], [68, 71], [72, 77], [77, 78], [78, 82], [83, 89], [89, 90], [91, 94], [95, 99], [100, 103], [104, 111], [112, 113], [114, 122], [123, 128], [128, 129]]}
{"doc_key": "ai-dev-162", "ner": [[1, 2, "misc"], [4, 5, "metrics"], [8, 9, "algorithm"], [12, 13, "metrics"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 1, 2, "type-of", "", false, false], [8, 9, 4, 5, "related-to", "", true, false], [12, 13, 1, 2, "type-of", "", false, false], [16, 17, 12, 13, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Popular", "loss", "functions", "include", "hinge", "loss", "(", "for", "linear", "SVM", ")", "and", "logarithmic", "loss", "(", "for", "logistic", "regression", ")", "."], "sentence-detokenized": "Popular loss functions include hinge loss (for linear SVM) and logarithmic loss (for logistic regression).", "token2charspan": [[0, 7], [8, 12], [13, 22], [23, 30], [31, 36], [37, 41], [42, 43], [43, 46], [47, 53], [54, 57], [57, 58], [59, 62], [63, 74], [75, 79], [80, 81], [81, 84], [85, 93], [94, 104], [104, 105], [105, 106]]}
{"doc_key": "ai-dev-163", "ner": [[0, 0, "metrics"], [9, 13, "metrics"], [15, 15, "metrics"], [18, 20, "metrics"], [22, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 9, 13, "compare", "", false, false], [0, 0, 18, 20, "compare", "", false, false], [15, 15, 9, 13, "named", "", false, false], [22, 22, 18, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SSIM", "aims", "to", "improve", "on", "traditional", "methods", "such", "as", "Peak", "Signal", "to", "Noise", "Ratio", "(", "PSNR", ")", "and", "Mean", "Squared", "Error", "(", "MSE", ")", "."], "sentence-detokenized": "SSIM aims to improve on traditional methods such as Peak Signal to Noise Ratio (PSNR) and Mean Squared Error (MSE).", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 20], [21, 23], [24, 35], [36, 43], [44, 48], [49, 51], [52, 56], [57, 63], [64, 66], [67, 72], [73, 78], [79, 80], [80, 84], [84, 85], [86, 89], [90, 94], [95, 102], [103, 108], [109, 110], [110, 113], [113, 114], [114, 115]]}
{"doc_key": "ai-dev-164", "ner": [[10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "work", "inspired", "subsequent", "generations", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "His work inspired subsequent generations of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 28], [29, 40], [41, 43], [44, 52], [53, 64], [65, 69], [70, 72], [73, 79], [80, 86], [86, 87], [88, 92], [93, 100], [101, 104], [105, 109], [110, 116], [116, 117]]}
{"doc_key": "ai-dev-165", "ner": [[7, 9, "algorithm"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 16, 7, 9, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["Further", "impulse", "training", "is", "non-separable", ",", "eliminating", "back", "-", "propagation", "based", "training", "methods", "such", "as", "gradient", "descent", "."], "sentence-detokenized": "Further impulse training is non-separable, eliminating back-propagation based training methods such as gradient descent.", "token2charspan": [[0, 7], [8, 15], [16, 24], [25, 27], [28, 41], [41, 42], [43, 54], [55, 59], [59, 60], [60, 71], [72, 77], [78, 86], [87, 94], [95, 99], [100, 102], [103, 111], [112, 119], [119, 120]]}
{"doc_key": "ai-dev-166", "ner": [[7, 9, "metrics"], [15, 16, "metrics"], [18, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 15, 16, "related-to", "describes", false, false], [15, 16, 18, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "relationship", "can", "easily", "be", "represented", "by", "a", "confusion", "matrix", ",", "a", "table", "describing", "the", "accuracy", "of", "the", "classification", "model", "."], "sentence-detokenized": "This relationship can easily be represented by a confusion matrix, a table describing the accuracy of the classification model.", "token2charspan": [[0, 4], [5, 17], [18, 21], [22, 28], [29, 31], [32, 43], [44, 46], [47, 48], [49, 58], [59, 65], [65, 66], [67, 68], [69, 74], [75, 85], [86, 89], [90, 98], [99, 101], [102, 105], [106, 120], [121, 126], [126, 127]]}
{"doc_key": "ai-dev-167", "ner": [[3, 7, "conference"], [9, 9, "conference"], [14, 14, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 3, 7, "named", "", false, false], [14, 14, 3, 7, "physical", "", false, false], [14, 14, 3, 7, "role", "", false, false], [14, 14, 3, 7, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["At", "the", "2018", "Neural", "Information", "Processing", "Systems", "Conference", "(", "NeurIPS", ")", ",", "researchers", "from", "Google", "presented", "this", "work"], "sentence-detokenized": "At the 2018 Neural Information Processing Systems Conference (NeurIPS), researchers from Google presented this work", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 30], [31, 41], [42, 49], [50, 60], [61, 62], [62, 69], [69, 70], [70, 71], [72, 83], [84, 88], [89, 95], [96, 105], [106, 110], [111, 115]]}
{"doc_key": "ai-dev-168", "ner": [[1, 5, "university"], [10, 10, "product"], [22, 24, "misc"], [20, 20, "conference"], [14, 34, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 10, 22, 24, "win-defeat", "", false, false], [22, 24, 20, 20, "temporal", "", false, false], [14, 34, 20, 20, "part-of", "", false, false], [14, 34, 20, 20, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "his", "time", "at", "Duke", "University", ",", "he", "worked", "on", "PROVERB", ",", "an", "automated", "crossword", "writer", ",", "which", "won", "the", "AAAI", "'s", "Distinguished", "Dissertation", "Award", "in", "1999", "and", "was", "entered", "into", "the", "American", "Crossword", "Championship", "."], "sentence-detokenized": "During his time at Duke University, he worked on PROVERB, an automated crossword writer, which won the AAAI's Distinguished Dissertation Award in 1999 and was entered into the American Crossword Championship.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 18], [19, 23], [24, 34], [34, 35], [36, 38], [39, 45], [46, 48], [49, 56], [56, 57], [58, 60], [61, 70], [71, 80], [81, 87], [87, 88], [89, 94], [95, 98], [99, 102], [103, 107], [107, 109], [110, 123], [124, 136], [137, 142], [143, 145], [146, 150], [151, 154], [155, 158], [159, 166], [167, 171], [172, 175], [176, 184], [185, 194], [195, 207], [207, 208]]}
{"doc_key": "ai-dev-169", "ner": [[5, 6, "location"], [8, 8, "location"], [15, 16, "country"], [18, 18, "country"], [20, 20, "country"], [22, 22, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 6, 8, 8, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "company", "is", "headquartered", "in", "Rochester", "Hills", ",", "Michigan", "and", "has", "10", "regional", "offices", "in", "the", "USA", ",", "Canada", ",", "Mexico", "and", "Brazil", "."], "sentence-detokenized": "The company is headquartered in Rochester Hills, Michigan and has 10 regional offices in the USA, Canada, Mexico and Brazil.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 28], [29, 31], [32, 41], [42, 47], [47, 48], [49, 57], [58, 61], [62, 65], [66, 68], [69, 77], [78, 85], [86, 88], [89, 92], [93, 96], [96, 97], [98, 104], [104, 105], [106, 112], [113, 116], [117, 123], [123, 124]]}
{"doc_key": "ai-dev-170", "ner": [[12, 12, "product"], [14, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "joins", "a", "range", "of", "historically", "significant", "robots", ",", "including", "the", "early", "Unimate", "and", "Odetics", "Odex", "1", "."], "sentence-detokenized": "It joins a range of historically significant robots, including the early Unimate and Odetics Odex 1.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 16], [17, 19], [20, 32], [33, 44], [45, 51], [51, 52], [53, 62], [63, 66], [67, 72], [73, 80], [81, 84], [85, 92], [93, 97], [98, 99], [99, 100]]}
{"doc_key": "ai-dev-171", "ner": [[11, 12, "researcher"], [16, 16, "organisation"], [8, 9, "researcher"], [21, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 12, 16, 16, "physical", "", false, false], [11, 12, 16, 16, "role", "", false, false], [8, 9, 16, 16, "physical", "", false, false], [8, 9, 16, 16, "role", "", false, false], [8, 9, 21, 29, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "guest", "editor", "for", "that", "issue", "will", "be", "Judah", "Levine", ",", "David", "'s", "former", "colleague", "at", "NIST", "and", "the", "latest", "recipient", "of", "the", "I.I", ".", "Rabi", "Award", ".", "Rabi", "Award", "."], "sentence-detokenized": "The guest editor for that issue will be Judah Levine, David's former colleague at NIST and the latest recipient of the I.I. Rabi Award. Rabi Award.", "token2charspan": [[0, 3], [4, 9], [10, 16], [17, 20], [21, 25], [26, 31], [32, 36], [37, 39], [40, 45], [46, 52], [52, 53], [54, 59], [59, 61], [62, 68], [69, 78], [79, 81], [82, 86], [87, 90], [91, 94], [95, 101], [102, 111], [112, 114], [115, 118], [119, 122], [122, 123], [124, 128], [129, 134], [134, 135], [136, 140], [141, 146], [146, 147]]}
{"doc_key": "ai-dev-172", "ner": [[14, 15, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "can", "be", "arranged", "in", "a", "2", "x", "2", "table", "of", "contingency", "rates", "(", "confusion", "matrix", ")", ",", "traditionally", "with", "the", "test", "results", "on", "the", "vertical", "axis", "and", "the", "actual", "situation", "on", "the", "horizontal", "axis", "."], "sentence-detokenized": "These can be arranged in a 2 x 2 table of contingency rates (confusion matrix), traditionally with the test results on the vertical axis and the actual situation on the horizontal axis.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 21], [22, 24], [25, 26], [27, 28], [29, 30], [31, 32], [33, 38], [39, 41], [42, 53], [54, 59], [60, 61], [61, 70], [71, 77], [77, 78], [78, 79], [80, 93], [94, 98], [99, 102], [103, 107], [108, 115], [116, 118], [119, 122], [123, 131], [132, 136], [137, 140], [141, 144], [145, 151], [152, 161], [162, 164], [165, 168], [169, 179], [180, 184], [184, 185]]}
{"doc_key": "ai-dev-173", "ner": [[1, 4, "product"], [8, 8, "product"], [10, 10, "product"], [12, 13, "product"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 4, 8, 8, "part-of", "", false, false], [1, 4, 10, 10, "part-of", "", false, false], [1, 4, 12, 13, "part-of", "", false, false], [1, 4, 15, 17, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Apple", "iOS", "operating", "system", "used", "on", "the", "iPhone", ",", "iPad", "and", "iPod", "Touch", "uses", "VoiceOver", "speech", "synthesis", "assistance", "."], "sentence-detokenized": "The Apple iOS operating system used on the iPhone, iPad and iPod Touch uses VoiceOver speech synthesis assistance.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 23], [24, 30], [31, 35], [36, 38], [39, 42], [43, 49], [49, 50], [51, 55], [56, 59], [60, 64], [65, 70], [71, 75], [76, 85], [86, 92], [93, 102], [103, 113], [113, 114]]}
{"doc_key": "ai-dev-174", "ner": [[8, 12, "conference"], [13, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "the", "best", "system", "to", "enter", "MUC", "-", "7", "had", "an", "F", "-", "value", "of", "93.39", "%", ",", "compared", "to", "97.6", "%", "and", "96.95", "%", "for", "human", "annotators", "."], "sentence-detokenized": "For example, the best system to enter MUC-7 had an F-value of 93.39%, compared to 97.6% and 96.95% for human annotators.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 31], [32, 37], [38, 41], [41, 42], [42, 43], [44, 47], [48, 50], [51, 52], [52, 53], [53, 58], [59, 61], [62, 67], [67, 68], [68, 69], [70, 78], [79, 81], [82, 86], [86, 87], [88, 91], [92, 97], [97, 98], [99, 102], [103, 108], [109, 119], [119, 120]]}
{"doc_key": "ai-dev-175", "ner": [[12, 14, "algorithm"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 17, 12, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "is", "done", "using", "standard", "neural", "net", "training", "algorithms", ",", "such", "as", "stochastic", "gradient", "descent", "with", "back", "propagation", "."], "sentence-detokenized": "This is done using standard neural net training algorithms, such as stochastic gradient descent with back propagation.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 18], [19, 27], [28, 34], [35, 38], [39, 47], [48, 58], [58, 59], [60, 64], [65, 67], [68, 78], [79, 87], [88, 95], [96, 100], [101, 105], [106, 117], [117, 118]]}
{"doc_key": "ai-dev-176", "ner": [[6, 7, "organisation"], [27, 28, "country"], [4, 4, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 27, 28, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["According", "to", "website", "ranker", "Alexa", ",", "Rotten", "Tomatoes", "is", "a", "top", "1000", "website", ",", "ranking", "around", "400th", "in", "the", "world", "and", "only", "in", "the", "top", "150", "in", "the", "US", "."], "sentence-detokenized": "According to website ranker Alexa, Rotten Tomatoes is a top 1000 website, ranking around 400th in the world and only in the top 150 in the US.", "token2charspan": [[0, 9], [10, 12], [13, 20], [21, 27], [28, 33], [33, 34], [35, 41], [42, 50], [51, 53], [54, 55], [56, 59], [60, 64], [65, 72], [72, 73], [74, 81], [82, 88], [89, 94], [95, 97], [98, 101], [102, 107], [108, 111], [112, 116], [117, 119], [120, 123], [124, 127], [128, 131], [132, 134], [135, 138], [139, 141], [141, 142]]}
{"doc_key": "ai-dev-177", "ner": [[17, 19, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "general", ",", "all", "learning", "shows", "incremental", "changes", "over", "time", ",", "but", "the", "description", "is", "of", "a", "Sigmoid", "function", "that", "behaves", "differently", "depending", "on", "the", "time", "scale", "of", "the", "observation", "."], "sentence-detokenized": "In general, all learning shows incremental changes over time, but the description is of a Sigmoid function that behaves differently depending on the time scale of the observation.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 24], [25, 30], [31, 42], [43, 50], [51, 55], [56, 60], [60, 61], [62, 65], [66, 69], [70, 81], [82, 84], [85, 87], [88, 89], [90, 97], [98, 106], [107, 111], [112, 119], [120, 131], [132, 141], [142, 144], [145, 148], [149, 153], [154, 159], [160, 162], [163, 166], [167, 178], [178, 179]]}
{"doc_key": "ai-dev-178", "ner": [[0, 0, "metrics"], [5, 7, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["SSD", "is", "also", "known", "as", "mean", "squared", "error", "."], "sentence-detokenized": "SSD is also known as mean squared error.", "token2charspan": [[0, 3], [4, 6], [7, 11], [12, 17], [18, 20], [21, 25], [26, 33], [34, 39], [39, 40]]}
{"doc_key": "ai-dev-179", "ner": [[0, 2, "algorithm"], [4, 5, "algorithm"], [7, 9, "algorithm"], [23, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 23, 24, "related-to", "can_be_related_to", true, false], [4, 5, 23, 24, "related-to", "can_be_related_to", true, false], [7, 9, 23, 24, "related-to", "can_be_related_to", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", ",", "neural", "networks", "or", "naive", "Bayesian", "classifiers", "can", "be", "used", "in", "conjunction", "with", "measures", "of", "model", "quality", ",", "such", "as", "balance", "accuracy", "."], "sentence-detokenized": "Decision tree learning, neural networks or naive Bayesian classifiers can be used in conjunction with measures of model quality, such as balance accuracy.", "token2charspan": [[0, 8], [9, 13], [14, 22], [22, 23], [24, 30], [31, 39], [40, 42], [43, 48], [49, 57], [58, 69], [70, 73], [74, 76], [77, 81], [82, 84], [85, 96], [97, 101], [102, 110], [111, 113], [114, 119], [120, 127], [127, 128], [129, 133], [134, 136], [137, 144], [145, 153], [153, 154]]}
{"doc_key": "ai-dev-180", "ner": [[15, 16, "conference"], [22, 26, "conference"], [21, 29, "misc"], [34, 40, "product"], [43, 47, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 29, 22, 26, "origin", "", false, false], [21, 29, 22, 26, "temporal", "", false, false], [34, 40, 21, 29, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "is", "a", "past", "president", "(", "1979", ")", "and", "inaugural", "fellow", "(", "2011", ")", "of", "the", "ACL", ",", "a", "co-recipient", "of", "the", "1992", "Association", "for", "Computing", "Machinery", "Software", "Systems", "Award", "for", "his", "contributions", "to", "the", "Interlisp", "programming", "system", ",", "and", "a", "fellow", "of", "the", "Association", "for", "Computing", "Machinery", "."], "sentence-detokenized": "He is a past president (1979) and inaugural fellow (2011) of the ACL, a co-recipient of the 1992 Association for Computing Machinery Software Systems Award for his contributions to the Interlisp programming system, and a fellow of the Association for Computing Machinery.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 22], [23, 24], [24, 28], [28, 29], [30, 33], [34, 43], [44, 50], [51, 52], [52, 56], [56, 57], [58, 60], [61, 64], [65, 68], [68, 69], [70, 71], [72, 84], [85, 87], [88, 91], [92, 96], [97, 108], [109, 112], [113, 122], [123, 132], [133, 141], [142, 149], [150, 155], [156, 159], [160, 163], [164, 177], [178, 180], [181, 184], [185, 194], [195, 206], [207, 213], [213, 214], [215, 218], [219, 220], [221, 227], [228, 230], [231, 234], [235, 246], [247, 250], [251, 260], [261, 270], [270, 271]]}
{"doc_key": "ai-dev-181", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [1, 9, "researcher"], [12, 13, "researcher"], [26, 29, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 26, 29, "related-to", "", false, false], [5, 6, 26, 29, "related-to", "", false, false], [1, 9, 26, 29, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "is", "considered", "by", "Cade", "Metz", "to", "be", "one", "of", "the", "three", "people", "most", "responsible", "for", "the", "development", "of", "deep", "learning", "in", "the", "1990s", "and", "2000s", "."], "sentence-detokenized": "Along with Geoffrey Hinton and Yann LeCun, Bengio is considered by Cade Metz to be one of the three people most responsible for the development of deep learning in the 1990s and 2000s.", "token2charspan": [[0, 5], [6, 10], [11, 19], [20, 26], [27, 30], [31, 35], [36, 41], [41, 42], [43, 49], [50, 52], [53, 63], [64, 66], [67, 71], [72, 76], [77, 79], [80, 82], [83, 86], [87, 89], [90, 93], [94, 99], [100, 106], [107, 111], [112, 123], [124, 127], [128, 131], [132, 143], [144, 146], [147, 151], [152, 160], [161, 163], [164, 167], [168, 173], [174, 177], [178, 183], [183, 184]]}
{"doc_key": "ai-dev-182", "ner": [[1, 2, "field"], [4, 5, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "information", "theory", "and", "computer", "science", ",", "encoding", "is", "often", "considered", "to", "be", "an", "algorithm", "that", "uniquely", "represents", "symbols", "from", "a", "certain", "source", "alphabet", "through", "encoded", "strings", "that", "may", "be", "other", "target", "alphabets", "."], "sentence-detokenized": "In information theory and computer science, encoding is often considered to be an algorithm that uniquely represents symbols from a certain source alphabet through encoded strings that may be other target alphabets.", "token2charspan": [[0, 2], [3, 14], [15, 21], [22, 25], [26, 34], [35, 42], [42, 43], [44, 52], [53, 55], [56, 61], [62, 72], [73, 75], [76, 78], [79, 81], [82, 91], [92, 96], [97, 105], [106, 116], [117, 124], [125, 129], [130, 131], [132, 139], [140, 146], [147, 155], [156, 163], [164, 171], [172, 179], [180, 184], [185, 188], [189, 191], [192, 197], [198, 204], [205, 214], [214, 215]]}
{"doc_key": "ai-dev-183", "ner": [[5, 5, "algorithm"], [9, 10, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 10, 5, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "fairly", "simple", "non", "-linear", "function", "such", "as", "a", "logistic", "function", "also", "has", "an", "easily", "computable", "derivative", ",", "which", "may", "be", "important", "when", "calculating", "weight", "updates", "in", "a", "network", "."], "sentence-detokenized": "A fairly simple non-linear function such as a logistic function also has an easily computable derivative, which may be important when calculating weight updates in a network.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 19], [19, 26], [27, 35], [36, 40], [41, 43], [44, 45], [46, 54], [55, 63], [64, 68], [69, 72], [73, 75], [76, 82], [83, 93], [94, 104], [104, 105], [106, 111], [112, 115], [116, 118], [119, 128], [129, 133], [134, 145], [146, 152], [153, 160], [161, 163], [164, 165], [166, 173], [173, 174]]}
{"doc_key": "ai-dev-184", "ner": [[6, 6, "location"], [8, 8, "location"], [10, 12, "country"], [15, 15, "country"], [18, 20, "country"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[6, 6, 8, 8, "physical", "", false, false], [8, 8, 10, 12, "physical", "", false, false], [8, 8, 15, 15, "physical", "", false, false], [8, 8, 18, 20, "physical", "", false, false], [15, 15, 10, 12, "origin", "", false, false], [18, 20, 15, 15, "origin", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6], "sentence": ["Chapke", "was", "born", "in", "1887", "in", "Hronov", ",", "Bohemia", "(", "Austria", "-", "Hungary", ",", "later", "Czechoslovakia", ",", "now", "the", "Czech", "Republic", ")", "."], "sentence-detokenized": "Chapke was born in 1887 in Hronov, Bohemia (Austria-Hungary, later Czechoslovakia, now the Czech Republic).", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 18], [19, 23], [24, 26], [27, 33], [33, 34], [35, 42], [43, 44], [44, 51], [51, 52], [52, 59], [59, 60], [61, 66], [67, 81], [81, 82], [83, 86], [87, 90], [91, 96], [97, 105], [105, 106], [106, 107]]}
{"doc_key": "ai-dev-185", "ner": [[7, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "specialised", "software", "is", "available", "to", "narrate", "RSS", "."], "sentence-detokenized": "Some specialised software is available to narrate RSS.", "token2charspan": [[0, 4], [5, 16], [17, 25], [26, 28], [29, 38], [39, 41], [42, 49], [50, 53], [53, 54]]}
{"doc_key": "ai-dev-186", "ner": [[6, 7, "task"], [15, 17, "task"], [10, 10, "task"], [13, 13, "task"], [19, 21, "task"], [28, 29, "task"], [32, 33, "task"], [37, 39, "task"], [42, 44, "product"], [46, 47, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[6, 7, 15, 17, "related-to", "", true, false], [6, 7, 10, 10, "related-to", "", true, false], [6, 7, 13, 13, "related-to", "", true, false], [32, 33, 28, 29, "usage", "", true, false], [42, 44, 37, 39, "type-of", "", false, false], [46, 47, 37, 39, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Aspects", "of", "ontology", "editing", "include", ":", "visual", "navigation", "possibilities", ",", "inference", "engines", "and", "extraction", "within", "the", "knowledge", "model", ";", "support", "for", "modules", ";", "import", "and", "export", "of", "foreign", "knowledge", "representation", "languages", "for", "ontology", "matching", ";", "and", "support", "for", "meta", "-ontologies", "such", "as", "OWL", "-", "S", ",", "Dublin", "Core", ",", "etc", "."], "sentence-detokenized": "Aspects of ontology editing include: visual navigation possibilities, inference engines and extraction within the knowledge model; support for modules; import and export of foreign knowledge representation languages for ontology matching; and support for meta-ontologies such as OWL-S, Dublin Core, etc.", "token2charspan": [[0, 7], [8, 10], [11, 19], [20, 27], [28, 35], [35, 36], [37, 43], [44, 54], [55, 68], [68, 69], [70, 79], [80, 87], [88, 91], [92, 102], [103, 109], [110, 113], [114, 123], [124, 129], [129, 130], [131, 138], [139, 142], [143, 150], [150, 151], [152, 158], [159, 162], [163, 169], [170, 172], [173, 180], [181, 190], [191, 205], [206, 215], [216, 219], [220, 228], [229, 237], [237, 238], [239, 242], [243, 250], [251, 254], [255, 259], [259, 270], [271, 275], [276, 278], [279, 282], [282, 283], [283, 284], [284, 285], [286, 292], [293, 297], [297, 298], [299, 302], [302, 303]]}
{"doc_key": "ai-dev-187", "ner": [[0, 1, "organisation"], [6, 9, "misc"], [13, 14, "task"], [21, 22, "field"], [25, 25, "misc"], [27, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 9, 0, 1, "origin", "", false, false], [13, 14, 6, 9, "part-of", "", false, false], [21, 22, 6, 9, "part-of", "", false, false], [25, 25, 21, 22, "type-of", "", false, false], [27, 29, 21, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "FBI", "has", "also", "developed", "its", "Next", "Generation", "Identification", "program", ",", "which", "includes", "face", "recognition", ",", "as", "well", "as", "more", "traditional", "biometric", "technologies", "such", "as", "fingerprint", "and", "iris", "scans", "that", "can", "be", "pulled", "from", "criminal", "and", "civil", "databases", "."], "sentence-detokenized": "The FBI has also developed its Next Generation Identification program, which includes face recognition, as well as more traditional biometric technologies such as fingerprint and iris scans that can be pulled from criminal and civil databases.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 16], [17, 26], [27, 30], [31, 35], [36, 46], [47, 61], [62, 69], [69, 70], [71, 76], [77, 85], [86, 90], [91, 102], [102, 103], [104, 106], [107, 111], [112, 114], [115, 119], [120, 131], [132, 141], [142, 154], [155, 159], [160, 162], [163, 174], [175, 178], [179, 183], [184, 189], [190, 194], [195, 198], [199, 201], [202, 208], [209, 213], [214, 222], [223, 226], [227, 232], [233, 242], [242, 243]]}
{"doc_key": "ai-dev-188", "ner": [[5, 6, "person"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["During", "the", "2016", "season", ",", "Samantha", "Pond", "was", "added", "as", "host", ",", "replacing", "Molly", "McGrath", "."], "sentence-detokenized": "During the 2016 season, Samantha Pond was added as host, replacing Molly McGrath.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 22], [22, 23], [24, 32], [33, 37], [38, 41], [42, 47], [48, 50], [51, 55], [55, 56], [57, 66], [67, 72], [73, 80], [80, 81]]}
{"doc_key": "ai-dev-189", "ner": [[3, 5, "algorithm"], [16, 20, "misc"], [22, 22, "misc"], [24, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "an", "adversarial", "search", "algorithm", "commonly", "used", "in", "machine", "versus", "two", "-", "player", "games", "(", "tic", "-", "tac", "-", "toe", ",", "chess", ",", "Go", ",", "etc.", ")", "."], "sentence-detokenized": "It is an adversarial search algorithm commonly used in machine versus two-player games (tic-tac-toe, chess, Go, etc.).", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 20], [21, 27], [28, 37], [38, 46], [47, 51], [52, 54], [55, 62], [63, 69], [70, 73], [73, 74], [74, 80], [81, 86], [87, 88], [88, 91], [91, 92], [92, 95], [95, 96], [96, 99], [99, 100], [101, 106], [106, 107], [108, 110], [110, 111], [112, 116], [116, 117], [117, 118]]}
{"doc_key": "ai-dev-190", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [18, 19, "field"], [21, 22, "field"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "covers", "the", "fields", "of", "computer", "vision", "or", "machine", "vision", "and", "medical", "imaging", "and", "makes", "extensive", "use", "of", "pattern", "recognition", ",", "digital", "geometry", "and", "signal", "processing", "."], "sentence-detokenized": "It covers the fields of computer vision or machine vision and medical imaging and makes extensive use of pattern recognition, digital geometry and signal processing.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 20], [21, 23], [24, 32], [33, 39], [40, 42], [43, 50], [51, 57], [58, 61], [62, 69], [70, 77], [78, 81], [82, 87], [88, 97], [98, 101], [102, 104], [105, 112], [113, 124], [124, 125], [126, 133], [134, 142], [143, 146], [147, 153], [154, 164], [164, 165]]}
{"doc_key": "ai-dev-191", "ner": [[5, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "in", "a", "facial", "recognition", "system", ",", "a", "photograph", "of", "a", "person", "'s", "face", "would", "be", "the", "input", ",", "and", "the", "output", "would", "be", "labelled", "with", "the", "person", "'s", "name", "."], "sentence-detokenized": "For example, in a facial recognition system, a photograph of a person's face would be the input, and the output would be labelled with the person's name.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 17], [18, 24], [25, 36], [37, 43], [43, 44], [45, 46], [47, 57], [58, 60], [61, 62], [63, 69], [69, 71], [72, 76], [77, 82], [83, 85], [86, 89], [90, 95], [95, 96], [97, 100], [101, 104], [105, 111], [112, 117], [118, 120], [121, 129], [130, 134], [135, 138], [139, 145], [145, 147], [148, 152], [152, 153]]}
{"doc_key": "ai-dev-192", "ner": [[0, 1, "organisation"], [3, 4, "product"], [8, 10, "product"], [21, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 3, 4, "artifact", "", false, false], [3, 4, 8, 10, "part-of", "", false, false], [8, 10, 3, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Apple", "has", "introduced", "Face", "ID", "on", "its", "flagship", "i", "Phone", "X", "as", "a", "biometric", "authentication", "successor", "to", "the", "fingerprint", "-", "based", "Touch", "ID", "system", "."], "sentence-detokenized": "Apple has introduced Face ID on its flagship iPhone X as a biometric authentication successor to the fingerprint-based Touch ID system.", "token2charspan": [[0, 5], [6, 9], [10, 20], [21, 25], [26, 28], [29, 31], [32, 35], [36, 44], [45, 46], [46, 51], [52, 53], [54, 56], [57, 58], [59, 68], [69, 83], [84, 93], [94, 96], [97, 100], [101, 112], [112, 113], [113, 118], [119, 124], [125, 127], [128, 134], [134, 135]]}
{"doc_key": "ai-dev-193", "ner": [[2, 5, "metrics"], [9, 10, "metrics"], [23, 27, "metrics"], [31, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Either", "the", "F", "-", "value", "is", "combined", "with", "an", "R-", "square", "assessed", "for", "the", "original", "model", "output", "and", "the", "target", ";", "or", "the", "cost", "/", "benefit", "matrix", "is", "combined", "with", "a", "correlation", "coefficient", ",", "etc", "."], "sentence-detokenized": "Either the F-value is combined with an R-square assessed for the original model output and the target; or the cost/benefit matrix is combined with a correlation coefficient, etc.", "token2charspan": [[0, 6], [7, 10], [11, 12], [12, 13], [13, 18], [19, 21], [22, 30], [31, 35], [36, 38], [39, 41], [41, 47], [48, 56], [57, 60], [61, 64], [65, 73], [74, 79], [80, 86], [87, 90], [91, 94], [95, 101], [101, 102], [103, 105], [106, 109], [110, 114], [114, 115], [115, 122], [123, 129], [130, 132], [133, 141], [142, 146], [147, 148], [149, 160], [161, 172], [172, 173], [174, 177], [177, 178]]}
{"doc_key": "ai-dev-194", "ner": [[6, 12, "conference"], [18, 20, "location"], [22, 22, "location"], [24, 26, "location"], [28, 28, "location"], [30, 30, "country"], [36, 37, "location"], [40, 44, "location"], [46, 46, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[6, 12, 18, 20, "physical", "", false, false], [6, 12, 24, 26, "physical", "", false, false], [6, 12, 36, 37, "physical", "", false, false], [6, 12, 40, 44, "physical", "", false, false], [18, 20, 22, 22, "physical", "", false, false], [24, 26, 28, 28, "physical", "", false, false], [28, 28, 30, 30, "physical", "", false, false], [36, 37, 46, 46, "physical", "", false, false], [40, 44, 46, 46, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["For", "the", "past", "15", "years", ",", "the", "Spanish", "version", "of", "the", "School", "Party", "has", "been", "held", "at", "the", "Colegio", "Miguel", "Hern\u00e1ndez", ",", "Ceulaj", "and", "Benalm\u00e1dena", "Municipal", "Stadiums", "in", "Malaga", ",", "Spain", ";", "and", "at", "the", "Valencia", "County", "Fair", "and", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", "."], "sentence-detokenized": "For the past 15 years, the Spanish version of the School Party has been held at the Colegio Miguel Hern\u00e1ndez, Ceulaj and Benalm\u00e1dena Municipal Stadiums in Malaga, Spain; and at the Valencia County Fair and the City of Arts and Sciences in Valencia.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 15], [16, 21], [21, 22], [23, 26], [27, 34], [35, 42], [43, 45], [46, 49], [50, 56], [57, 62], [63, 66], [67, 71], [72, 76], [77, 79], [80, 83], [84, 91], [92, 98], [99, 108], [108, 109], [110, 116], [117, 120], [121, 132], [133, 142], [143, 151], [152, 154], [155, 161], [161, 162], [163, 168], [168, 169], [170, 173], [174, 176], [177, 180], [181, 189], [190, 196], [197, 201], [202, 205], [206, 209], [210, 214], [215, 217], [218, 222], [223, 226], [227, 235], [236, 238], [239, 247], [247, 248]]}
{"doc_key": "ai-dev-195", "ner": [[0, 5, "product"], [12, 12, "programlang"], [16, 16, "product"], [18, 18, "product"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 0, 5, "general-affiliation", "", false, false], [16, 16, 12, 12, "part-of", "", false, false], [18, 18, 12, 12, "part-of", "", false, false], [22, 22, 0, 5, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["gnuplot", "can", "plot", "data", "in", "a", "variety", "of", "programming", "languages", ",", "including", "Perl", "(", "via", "the", "PDL", "and", "CPAN", "packages", ")", ",", "Python", "(", "via", ")", "."], "sentence-detokenized": "gnuplot can plot data in a variety of programming languages, including Perl (via the PDL and CPAN packages), Python (via).", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 21], [22, 24], [25, 26], [27, 34], [35, 37], [38, 49], [50, 59], [59, 60], [61, 70], [71, 75], [76, 77], [77, 80], [81, 84], [85, 88], [89, 92], [93, 97], [98, 106], [106, 107], [107, 108], [109, 115], [116, 117], [117, 120], [120, 121], [121, 122]]}
{"doc_key": "ai-dev-196", "ner": [[2, 6, "product"], [20, 20, "conference"], [22, 22, "conference"], [36, 36, "conference"], [38, 38, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[20, 20, 2, 6, "topic", "", false, false], [22, 22, 2, 6, "topic", "", false, false], [36, 36, 2, 6, "topic", "", false, false], [38, 38, 2, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "field", "of", "spoken", "dialogue", "systems", "is", "quite", "large", "and", "includes", "both", "research", "(", "featured", "at", "scientific", "conferences", "such", "as", "SIGdial", "and", "Interspeech", ")", "and", "a", "large", "industrial", "sector", "(", "with", "its", "own", "conferences", "such", "as", "SpeechTek", "and", "AVIOS", ")", "."], "sentence-detokenized": "The field of spoken dialogue systems is quite large and includes both research (featured at scientific conferences such as SIGdial and Interspeech) and a large industrial sector (with its own conferences such as SpeechTek and AVIOS).", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 28], [29, 36], [37, 39], [40, 45], [46, 51], [52, 55], [56, 64], [65, 69], [70, 78], [79, 80], [80, 88], [89, 91], [92, 102], [103, 114], [115, 119], [120, 122], [123, 130], [131, 134], [135, 146], [146, 147], [148, 151], [152, 153], [154, 159], [160, 170], [171, 177], [178, 179], [179, 183], [184, 187], [188, 191], [192, 203], [204, 208], [209, 211], [212, 221], [222, 225], [226, 231], [231, 232], [232, 233]]}
{"doc_key": "ai-dev-197", "ner": [[3, 5, "field"], [8, 9, "task"], [11, 13, "task"], [15, 17, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 3, 5, "part-of", "task_part_of_field", false, false], [11, 13, 3, 5, "part-of", "task_part_of_field", false, false], [15, 17, 3, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "challenges", "of", "natural", "language", "processing", "often", "involve", "speech", "recognition", ",", "natural", "language", "understanding", "and", "natural", "language", "generation", "."], "sentence-detokenized": "The challenges of natural language processing often involve speech recognition, natural language understanding and natural language generation.", "token2charspan": [[0, 3], [4, 14], [15, 17], [18, 25], [26, 34], [35, 45], [46, 51], [52, 59], [60, 66], [67, 78], [78, 79], [80, 87], [88, 96], [97, 110], [111, 114], [115, 122], [123, 131], [132, 142], [142, 143]]}
{"doc_key": "ai-dev-198", "ner": [[5, 5, "product"], [7, 10, "product"], [38, 39, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 7, 10, "part-of", "", false, false], [5, 5, 38, 39, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "such", "as", "Siri", "for", "the", "iOS", "operating", "system", ",", "use", "similar", "pattern", "recognition", "technology", "to", "text", "-", "based", "systems", ",", "but", "in", "the", "case", "of", "the", "former", ",", "the", "user", "'s", "input", "is", "made", "through", "speech", "recognition", "."], "sentence-detokenized": "These systems, such as Siri for the iOS operating system, use similar pattern recognition technology to text-based systems, but in the case of the former, the user's input is made through speech recognition.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 22], [23, 27], [28, 31], [32, 35], [36, 39], [40, 49], [50, 56], [56, 57], [58, 61], [62, 69], [70, 77], [78, 89], [90, 100], [101, 103], [104, 108], [108, 109], [109, 114], [115, 122], [122, 123], [124, 127], [128, 130], [131, 134], [135, 139], [140, 142], [143, 146], [147, 153], [153, 154], [155, 158], [159, 163], [163, 165], [166, 171], [172, 174], [175, 179], [180, 187], [188, 194], [195, 206], [206, 207]]}
{"doc_key": "ai-dev-199", "ner": [[2, 4, "algorithm"], [17, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 4, 17, 19, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["More", "exotic", "fitness", "functions", "for", "exploring", "the", "granularity", "of", "the", "model", "include", "area", "and", "rank", "measurements", "under", "the", "ROC", "curve", "."], "sentence-detokenized": "More exotic fitness functions for exploring the granularity of the model include area and rank measurements under the ROC curve.", "token2charspan": [[0, 4], [5, 11], [12, 19], [20, 29], [30, 33], [34, 43], [44, 47], [48, 59], [60, 62], [63, 66], [67, 72], [73, 80], [81, 85], [86, 89], [90, 94], [95, 107], [108, 113], [114, 117], [118, 121], [122, 127], [127, 128]]}
{"doc_key": "ai-dev-200", "ner": [[2, 37, "product"], [7, 12, "researcher"], [16, 18, "product"], [22, 25, "organisation"], [28, 31, "organisation"], [38, 39, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 37, 7, 12, "origin", "", false, false], [7, 12, 22, 25, "role", "", false, false], [16, 18, 7, 12, "origin", "", false, false], [28, 31, 22, 25, "named", "", false, false], [38, 39, 22, 25, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "term", "Semantic", "Web", "was", "coined", "by", "Tim", "Berners", "-", "Lee", ",", "the", "inventor", "of", "the", "World", "Wide", "Web", "and", "director", "of", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "which", "oversees", "the", "development", "of", "proposed", "Semantic", "Web", "standards", "."], "sentence-detokenized": "The term Semantic Web was coined by Tim Berners-Lee, the inventor of the World Wide Web and director of the World Wide Web Consortium (W3C), which oversees the development of proposed Semantic Web standards.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 25], [26, 32], [33, 35], [36, 39], [40, 47], [47, 48], [48, 51], [51, 52], [53, 56], [57, 65], [66, 68], [69, 72], [73, 78], [79, 83], [84, 87], [88, 91], [92, 100], [101, 103], [104, 107], [108, 113], [114, 118], [119, 122], [123, 133], [134, 135], [135, 138], [138, 139], [139, 140], [141, 146], [147, 155], [156, 159], [160, 171], [172, 174], [175, 183], [184, 192], [193, 196], [197, 206], [206, 207]]}
{"doc_key": "ai-dev-201", "ner": [[0, 1, "task"], [8, 8, "task"], [15, 16, "product"], [18, 22, "product"], [24, 24, "product"], [27, 28, "product"], [35, 36, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 15, 16, "opposite", "", false, false], [0, 1, 18, 22, "opposite", "", false, false], [0, 1, 27, 28, "opposite", "", false, false], [0, 1, 35, 36, "part-of", "", false, false], [8, 8, 0, 1, "named", "", false, false], [24, 24, 18, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Machine", "translation", ",", "sometimes", "referred", "to", "simply", "as", "MT", "(", "not", "to", "be", "confused", "with", "computer-assisted", "translation", ",", "machine", "-", "assisted", "human", "translation", "(", "MAHT", ")", "or", "interactive", "translation", ")", ",", "is", "a", "subfield", "of", "computational", "linguistics", "that", "studies", "the", "use", "of", "software", "to", "translate", "text", "or", "speech", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Machine translation, sometimes referred to simply as MT (not to be confused with computer-assisted translation, machine-assisted human translation (MAHT) or interactive translation), is a subfield of computational linguistics that studies the use of software to translate text or speech from one language to another.", "token2charspan": [[0, 7], [8, 19], [19, 20], [21, 30], [31, 39], [40, 42], [43, 49], [50, 52], [53, 55], [56, 57], [57, 60], [61, 63], [64, 66], [67, 75], [76, 80], [81, 98], [99, 110], [110, 111], [112, 119], [119, 120], [120, 128], [129, 134], [135, 146], [147, 148], [148, 152], [152, 153], [154, 156], [157, 168], [169, 180], [180, 181], [181, 182], [183, 185], [186, 187], [188, 196], [197, 199], [200, 213], [214, 225], [226, 230], [231, 238], [239, 242], [243, 246], [247, 249], [250, 258], [259, 261], [262, 271], [272, 276], [277, 279], [280, 286], [287, 291], [292, 295], [296, 304], [305, 307], [308, 315], [315, 316]]}
{"doc_key": "ai-dev-202", "ner": [[1, 4, "product"], [14, 14, "university"], [8, 9, "researcher"], [11, 12, "researcher"], [42, 44, "location"], [45, 45, "location"], [1, 52, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 4, 8, 9, "artifact", "", false, false], [1, 4, 11, 12, "artifact", "", false, false], [8, 9, 14, 14, "physical", "", false, false], [8, 9, 14, 14, "role", "", false, false], [11, 12, 14, 14, "physical", "", false, false], [11, 12, 14, 14, "role", "", false, false], [42, 44, 45, 45, "physical", "", false, false], [1, 52, 42, 44, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Early", "interlingual", "MT", "systems", "were", "also", "built", "by", "Roger", "Schank", "and", "Yorick", "Wilks", "at", "Stanford", "in", "the", "1970s", ";", "the", "former", "became", "the", "basis", "for", "a", "commercial", "system", "for", "fund", "transfer", ",", "and", "the", "code", "for", "the", "latter", "is", "kept", "at", "the", "Computer", "Museum", "in", "Boston", "as", "the", "first", "interlingual", "machine", "translation", "system", "."], "sentence-detokenized": "Early interlingual MT systems were also built by Roger Schank and Yorick Wilks at Stanford in the 1970s; the former became the basis for a commercial system for fund transfer, and the code for the latter is kept at the Computer Museum in Boston as the first interlingual machine translation system.", "token2charspan": [[0, 5], [6, 18], [19, 21], [22, 29], [30, 34], [35, 39], [40, 45], [46, 48], [49, 54], [55, 61], [62, 65], [66, 72], [73, 78], [79, 81], [82, 90], [91, 93], [94, 97], [98, 103], [103, 104], [105, 108], [109, 115], [116, 122], [123, 126], [127, 132], [133, 136], [137, 138], [139, 149], [150, 156], [157, 160], [161, 165], [166, 174], [174, 175], [176, 179], [180, 183], [184, 188], [189, 192], [193, 196], [197, 203], [204, 206], [207, 211], [212, 214], [215, 218], [219, 227], [228, 234], [235, 237], [238, 244], [245, 247], [248, 251], [252, 257], [258, 270], [271, 278], [279, 290], [291, 297], [297, 298]]}
{"doc_key": "ai-dev-203", "ner": [[0, 0, "researcher"], [7, 11, "conference"], [13, 14, "conference"], [20, 26, "conference"], [28, 39, "conference"], [33, 40, "organisation"], [49, 50, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 7, 11, "role", "", false, false], [0, 0, 20, 26, "role", "", false, false], [0, 0, 33, 40, "role", "", false, false], [0, 0, 49, 50, "role", "", false, false], [13, 14, 7, 11, "named", "", false, false], [28, 39, 20, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sycara", "served", "as", "Program", "Chair", "of", "the", "Second", "International", "Semantic", "Web", "Conference", "(", "ISWC", "2003", ")", ";", "General", "Chair", "of", "the", "Second", "International", "Conference", "on", "Autonomous", "Agents", "(", "Agents", "98", ")", ";", "Chair", "of", "the", "Steering", "Committee", "of", "the", "Agents", "Conference", "(", "1999-2001", ")", ";", "and", "Fellowship", "Chair", "of", "the", "AAAI", "(", "1993-1999", ")", "."], "sentence-detokenized": "Sycara served as Program Chair of the Second International Semantic Web Conference (ISWC 2003); General Chair of the Second International Conference on Autonomous Agents (Agents 98); Chair of the Steering Committee of the Agents Conference (1999-2001); and Fellowship Chair of the AAAI (1993-1999).", "token2charspan": [[0, 6], [7, 13], [14, 16], [17, 24], [25, 30], [31, 33], [34, 37], [38, 44], [45, 58], [59, 67], [68, 71], [72, 82], [83, 84], [84, 88], [89, 93], [93, 94], [94, 95], [96, 103], [104, 109], [110, 112], [113, 116], [117, 123], [124, 137], [138, 148], [149, 151], [152, 162], [163, 169], [170, 171], [171, 177], [178, 180], [180, 181], [181, 182], [183, 188], [189, 191], [192, 195], [196, 204], [205, 214], [215, 217], [218, 221], [222, 228], [229, 239], [240, 241], [241, 250], [250, 251], [251, 252], [253, 256], [257, 267], [268, 273], [274, 276], [277, 280], [281, 285], [286, 287], [287, 296], [296, 297], [297, 298]]}
{"doc_key": "ai-dev-204", "ner": [[11, 11, "conference"], [13, 16, "conference"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 16, 11, 11, "named", "", false, false], [18, 19, 11, 11, "part-of", "", false, false], [18, 19, 11, 11, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2016", ",", "she", "was", "selected", "as", "the", "recipient", "of", "the", "ACL", "(", "Association", "for", "Computational", "Linguistics", ")", "Lifetime", "Achievement", "Award", "."], "sentence-detokenized": "In 2016, she was selected as the recipient of the ACL (Association for Computational Linguistics) Lifetime Achievement Award.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 25], [26, 28], [29, 32], [33, 42], [43, 45], [46, 49], [50, 53], [54, 55], [55, 66], [67, 70], [71, 84], [85, 96], [96, 97], [98, 106], [107, 118], [119, 124], [124, 125]]}
{"doc_key": "ai-dev-205", "ner": [[0, 1, "researcher"], [3, 5, "researcher"], [7, 8, "researcher"], [11, 12, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", ",", "Y", ".", "Bengio", ",", "P.", "Frasconi", ",", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Sepp Hochreiter, Y. Bengio, P. Frasconi, and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 15], [15, 16], [17, 18], [18, 19], [20, 26], [26, 27], [28, 30], [31, 39], [39, 40], [41, 44], [45, 51], [52, 63], [63, 64]]}
{"doc_key": "ai-dev-206", "ner": [[3, 3, "product"], [6, 7, "misc"], [9, 12, "programlang"], [18, 21, "product"], [26, 34, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 9, 12, "usage", "", false, false], [9, 12, 6, 7, "type-of", "", false, false], [9, 12, 18, 21, "related-to", "", false, false], [26, 34, 3, 3, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["For", "example", ",", "A.L.I.C.E.", "uses", "a", "markup", "language", "called", "AIML", ",", "which", "is", "specific", "to", "it", "as", "a", "dialogue", "system", "and", "has", "since", "been", "adopted", "by", "the", "developers", "of", "various", "other", "so", "-", "called", "Alicebots", "."], "sentence-detokenized": "For example, A.L.I.C.E. uses a markup language called AIML, which is specific to it as a dialogue system and has since been adopted by the developers of various other so-called Alicebots.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 23], [24, 28], [29, 30], [31, 37], [38, 46], [47, 53], [54, 58], [58, 59], [60, 65], [66, 68], [69, 77], [78, 80], [81, 83], [84, 86], [87, 88], [89, 97], [98, 104], [105, 108], [109, 112], [113, 118], [119, 123], [124, 131], [132, 134], [135, 138], [139, 149], [150, 152], [153, 160], [161, 166], [167, 169], [169, 170], [170, 176], [177, 186], [186, 187]]}
{"doc_key": "ai-dev-207", "ner": [[9, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2000", "she", "was", "elected", "as", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2000 she was elected as a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 15], [16, 23], [24, 26], [27, 28], [29, 35], [36, 38], [39, 42], [43, 54], [55, 58], [59, 62], [63, 74], [75, 77], [78, 88], [89, 101], [101, 102]]}
{"doc_key": "ai-dev-208", "ner": [[0, 3, "misc"], [5, 5, "misc"], [11, 17, "misc"], [24, 26, "algorithm"], [34, 34, "field"], [36, 36, "field"], [38, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 11, 17, "type-of", "", false, false], [0, 3, 34, 34, "related-to", "performs", true, false], [0, 3, 36, 36, "related-to", "performs", true, false], [0, 3, 38, 39, "related-to", "performs", true, false], [5, 5, 0, 3, "named", "", false, false], [24, 26, 11, 17, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["A", "Learning", "Classifier", "System", "(", "LCS", ")", "is", "a", "series", "of", "rule", "-", "based", "machine", "learning", "algorithms", "that", "combine", "a", "discovery", "component", "(", "usually", "a", "genetic", "algorithm", ")", "with", "a", "learning", "component", "to", "perform", "supervised", ",", "reinforcement", "or", "unsupervised", "learning", "."], "sentence-detokenized": "A Learning Classifier System (LCS) is a series of rule-based machine learning algorithms that combine a discovery component (usually a genetic algorithm) with a learning component to perform supervised, reinforcement or unsupervised learning.", "token2charspan": [[0, 1], [2, 10], [11, 21], [22, 28], [29, 30], [30, 33], [33, 34], [35, 37], [38, 39], [40, 46], [47, 49], [50, 54], [54, 55], [55, 60], [61, 68], [69, 77], [78, 88], [89, 93], [94, 101], [102, 103], [104, 113], [114, 123], [124, 125], [125, 132], [133, 134], [135, 142], [143, 152], [152, 153], [154, 158], [159, 160], [161, 169], [170, 179], [180, 182], [183, 190], [191, 201], [201, 202], [203, 216], [217, 219], [220, 232], [233, 241], [241, 242]]}
{"doc_key": "ai-dev-209", "ner": [[14, 17, "algorithm"], [19, 19, "algorithm"], [25, 26, "algorithm"], [40, 42, "algorithm"], [47, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 4, 5], "relations": [[14, 17, 25, 26, "origin", "", false, false], [19, 19, 14, 17, "named", "", false, false], [40, 42, 47, 53, "compare", "", false, false]], "relations_mapping_to_source": [0, 2, 4], "sentence": ["The", "unknown", "parameters", "in", "each", "vector", "\u03b2subk", "/", "sub", "are", "usually", "estimated", "jointly", "by", "maximum", "a", "posteriori", "estimation", "(", "MAP", ")", ",", "an", "extension", "of", "maximum", "likelihood", "that", "uses", "regularisation", "of", "the", "weights", "to", "prevent", "pathological", "solutions", "(", "usually", "a", "squared", "regularisation", "function", ",", "equivalent", "to", "placing", "a", "Gaussian", "prior", "distribution", "with", "zero", "mean", "on", "the", "weights", ",", "but", "other", "distributions", "are", "also", "possible", ")", "."], "sentence-detokenized": "The unknown parameters in each vector \u03b2subk / sub are usually estimated jointly by maximum a posteriori estimation (MAP), an extension of maximum likelihood that uses regularisation of the weights to prevent pathological solutions (usually a squared regularisation function, equivalent to placing a Gaussian prior distribution with zero mean on the weights, but other distributions are also possible).", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 25], [26, 30], [31, 37], [38, 43], [44, 45], [46, 49], [50, 53], [54, 61], [62, 71], [72, 79], [80, 82], [83, 90], [91, 92], [93, 103], [104, 114], [115, 116], [116, 119], [119, 120], [120, 121], [122, 124], [125, 134], [135, 137], [138, 145], [146, 156], [157, 161], [162, 166], [167, 181], [182, 184], [185, 188], [189, 196], [197, 199], [200, 207], [208, 220], [221, 230], [231, 232], [232, 239], [240, 241], [242, 249], [250, 264], [265, 273], [273, 274], [275, 285], [286, 288], [289, 296], [297, 298], [299, 307], [308, 313], [314, 326], [327, 331], [332, 336], [337, 341], [342, 344], [345, 348], [349, 356], [356, 357], [358, 361], [362, 367], [368, 381], [382, 385], [386, 390], [391, 399], [399, 400], [400, 401]]}
{"doc_key": "ai-dev-210", "ner": [[1, 2, "researcher"], [4, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 1, 2, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "George", "Miller", "'s", "Wordnet", ",", "the", "hierarchical", "structure", "of", "words", "has", "been", "explicitly", "mapped", "out", "."], "sentence-detokenized": "In George Miller's Wordnet, the hierarchical structure of words has been explicitly mapped out.", "token2charspan": [[0, 2], [3, 9], [10, 16], [16, 18], [19, 26], [26, 27], [28, 31], [32, 44], [45, 54], [55, 57], [58, 63], [64, 67], [68, 72], [73, 83], [84, 90], [91, 94], [94, 95]]}
{"doc_key": "ai-dev-211", "ner": [[0, 6, "conference"], [14, 17, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 17, 0, 6, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "illustrates", "their", "capabilities", ";", "a", "benchmark", "for", "object", "classification", "and", "detection", ",", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "The ImageNet Large Scale Visual Recognition Challenge illustrates their capabilities; a benchmark for object classification and detection, with millions of images and hundreds of object classes.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 24], [25, 31], [32, 43], [44, 53], [54, 65], [66, 71], [72, 84], [84, 85], [86, 87], [88, 97], [98, 101], [102, 108], [109, 123], [124, 127], [128, 137], [137, 138], [139, 143], [144, 152], [153, 155], [156, 162], [163, 166], [167, 175], [176, 178], [179, 185], [186, 193], [193, 194]]}
{"doc_key": "ai-dev-212", "ner": [[1, 2, "misc"], [24, 24, "misc"], [26, 28, "person"], [31, 31, "misc"], [36, 38, "person"], [41, 43, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[24, 24, 1, 2, "general-affiliation", "", false, false], [31, 31, 1, 2, "general-affiliation", "", false, false], [31, 31, 26, 28, "artifact", "", false, false], [41, 43, 1, 2, "general-affiliation", "", false, false], [41, 43, 36, 38, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "science", "fiction", ",", "female", "-", "looking", "robots", "are", "often", "produced", "for", "use", "as", "domestic", "servants", "and", "sex", "slaves", ",", "as", "in", "the", "film", "Westworld", ",", "Paul", "J.", "McCauley", "'s", "novel", "Wonderland", "(", "1995", ")", "and", "Lester", "del", "Rey's", "short", "story", "Helen", "O'", "Roy", "(", "1938", ")", ",", "and", "sometimes", "as", "warriors", ",", "killers", "or", "labourers", "."], "sentence-detokenized": "In science fiction, female-looking robots are often produced for use as domestic servants and sex slaves, as in the film Westworld, Paul J. McCauley's novel Wonderland (1995) and Lester del Rey's short story Helen O'Roy (1938), and sometimes as warriors, killers or labourers.", "token2charspan": [[0, 2], [3, 10], [11, 18], [18, 19], [20, 26], [26, 27], [27, 34], [35, 41], [42, 45], [46, 51], [52, 60], [61, 64], [65, 68], [69, 71], [72, 80], [81, 89], [90, 93], [94, 97], [98, 104], [104, 105], [106, 108], [109, 111], [112, 115], [116, 120], [121, 130], [130, 131], [132, 136], [137, 139], [140, 148], [148, 150], [151, 156], [157, 167], [168, 169], [169, 173], [173, 174], [175, 178], [179, 185], [186, 189], [190, 195], [196, 201], [202, 207], [208, 213], [214, 216], [216, 219], [220, 221], [221, 225], [225, 226], [226, 227], [228, 231], [232, 241], [242, 244], [245, 253], [253, 254], [255, 262], [263, 265], [266, 275], [275, 276]]}
{"doc_key": "ai-dev-213", "ner": [[0, 1, "task"], [3, 4, "task"], [6, 7, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Question", "answering", ",", "speech", "recognition", "and", "machine", "translation", "."], "sentence-detokenized": "Question answering, speech recognition and machine translation.", "token2charspan": [[0, 8], [9, 18], [18, 19], [20, 26], [27, 38], [39, 42], [43, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-214", "ner": [[5, 6, "researcher"], [8, 13, "organisation"], [15, 19, "location"], [20, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 8, 13, "role", "", false, false], [8, 13, 15, 19, "physical", "", false, false], [15, 19, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "his", "seminal", "paper", ",", "Harry", "Blum", "of", "the", "Air", "Force", "Cambridge", "Research", "Laboratory", "at", "Hanscom", "Air", "Force", "Base", "in", "Bedford", ",", "Massachusetts", ",", "defined", "a", "medial", "axis", "for", "calculating", "the", "shape", "skeleton", "using", "an", "intuitive", "model", "of", "fire", "propagation", "on", "a", "grassland", ",", "where", "the", "grassland", "has", "the", "form", "of", "a", "given", "shape", "."], "sentence-detokenized": "In his seminal paper, Harry Blum of the Air Force Cambridge Research Laboratory at Hanscom Air Force Base in Bedford, Massachusetts, defined a medial axis for calculating the shape skeleton using an intuitive model of fire propagation on a grassland, where the grassland has the form of a given shape.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 20], [20, 21], [22, 27], [28, 32], [33, 35], [36, 39], [40, 43], [44, 49], [50, 59], [60, 68], [69, 79], [80, 82], [83, 90], [91, 94], [95, 100], [101, 105], [106, 108], [109, 116], [116, 117], [118, 131], [131, 132], [133, 140], [141, 142], [143, 149], [150, 154], [155, 158], [159, 170], [171, 174], [175, 180], [181, 189], [190, 195], [196, 198], [199, 208], [209, 214], [215, 217], [218, 222], [223, 234], [235, 237], [238, 239], [240, 249], [249, 250], [251, 256], [257, 260], [261, 270], [271, 274], [275, 278], [279, 283], [284, 286], [287, 288], [289, 294], [295, 300], [300, 301]]}
{"doc_key": "ai-dev-215", "ner": [[16, 16, "algorithm"], [18, 18, "algorithm"], [20, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 16, 20, 20, "compare", "", false, false], [18, 18, 20, 20, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "in", "contrast", "to", "boosting", "algorithms", "that", "analytically", "minimise", "convex", "loss", "functions", ",", "such", "as", "AdaBoost", "and", "LogitBoost", ",", "BrownBoost", "uses", "standard", "numerical", "methods", "to", "solve", "a", "system", "consisting", "of", "two", "equations", "and", "two", "unknowns", "."], "sentence-detokenized": "However, in contrast to boosting algorithms that analytically minimise convex loss functions, such as AdaBoost and LogitBoost, BrownBoost uses standard numerical methods to solve a system consisting of two equations and two unknowns.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 20], [21, 23], [24, 32], [33, 43], [44, 48], [49, 61], [62, 70], [71, 77], [78, 82], [83, 92], [92, 93], [94, 98], [99, 101], [102, 110], [111, 114], [115, 125], [125, 126], [127, 137], [138, 142], [143, 151], [152, 161], [162, 169], [170, 172], [173, 178], [179, 180], [181, 187], [188, 198], [199, 201], [202, 205], [206, 215], [216, 219], [220, 223], [224, 232], [232, 233]]}
{"doc_key": "ai-dev-216", "ner": [[0, 0, "researcher"], [7, 10, "misc"], [19, 24, "conference"], [18, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 10, "win-defeat", "", false, false], [0, 0, 19, 24, "role", "", false, false], [18, 26, 19, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Gertol", "holds", "several", "best", "paper", "awards", ",", "an", "NSF", "career", "award", ",", "and", "is", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Gertol holds several best paper awards, an NSF career award, and is a member of the Association for the Advancement of Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 12], [13, 20], [21, 25], [26, 31], [32, 38], [38, 39], [40, 42], [43, 46], [47, 53], [54, 59], [59, 60], [61, 64], [65, 67], [68, 69], [70, 76], [77, 79], [80, 83], [84, 95], [96, 99], [100, 103], [104, 115], [116, 118], [119, 129], [130, 142], [143, 144], [144, 148], [148, 149], [149, 150]]}
{"doc_key": "ai-dev-217", "ner": [[0, 3, "misc"], [10, 11, "misc"], [16, 17, "misc"], [22, 27, "misc"], [32, 33, "misc"], [38, 41, "university"], [46, 53, "misc"], [58, 67, "misc"], [72, 78, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["ACM", "Fellow", "(", "2015", ")", "br", "Fellow", ",", "Association", "for", "Computational", "Linguistics", "(", "2011", ")", "br", "AAAI", "Fellow", "(", "1994", ")", "br", "Fellow", ",", "International", "Speech", "Communication", "Association", "(", "2011", ")", "br", "Honorary", "Doctorate", "(", "Hedersdoktor", ")", ",", "Royal", "Institute", "of", "Technology", "(", "2007", ")", "br", "Columbia", "Engineering", "Alumni", "Association", "Distinguished", "Faculty", "Teaching", "Award", "(", "2009", ")", "br", "IEEE", "James", "L.", "Flanagan", "Award", "for", "Speech", "and", "Audio", "Processing", "(", "2011", ")", "br", "ISCA", "Medal", "for", "Scientific", "Achievement", "(", "2011", ")"], "sentence-detokenized": "ACM Fellow (2015) br Fellow, Association for Computational Linguistics (2011) br AAAI Fellow (1994) br Fellow, International Speech Communication Association (2011) br Honorary Doctorate (Hedersdoktor), Royal Institute of Technology (2007) br Columbia Engineering Alumni Association Distinguished Faculty Teaching Award (2009) br IEEE James L. Flanagan Award for Speech and Audio Processing (2011)br ISCA Medal for Scientific Achievement (2011)", "token2charspan": [[0, 3], [4, 10], [11, 12], [12, 16], [16, 17], [18, 20], [21, 27], [27, 28], [29, 40], [41, 44], [45, 58], [59, 70], [71, 72], [72, 76], [76, 77], [78, 80], [81, 85], [86, 92], [93, 94], [94, 98], [98, 99], [100, 102], [103, 109], [109, 110], [111, 124], [125, 131], [132, 145], [146, 157], [158, 159], [159, 163], [163, 164], [165, 167], [168, 176], [177, 186], [187, 188], [188, 200], [200, 201], [201, 202], [203, 208], [209, 218], [219, 221], [222, 232], [233, 234], [234, 238], [238, 239], [240, 242], [243, 251], [252, 263], [264, 270], [271, 282], [283, 296], [297, 304], [305, 313], [314, 319], [320, 321], [321, 325], [325, 326], [327, 329], [330, 334], [335, 340], [341, 343], [344, 352], [353, 358], [359, 362], [363, 369], [370, 373], [374, 379], [380, 390], [391, 392], [392, 396], [396, 397], [397, 399], [400, 404], [405, 410], [411, 414], [415, 425], [426, 437], [438, 439], [439, 443], [443, 444]]}
{"doc_key": "ai-dev-218", "ner": [[6, 6, "university"], [14, 16, "task"], [26, 32, "metrics"], [39, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[26, 32, 39, 41, "opposite", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["A", "frustrating", "result", "of", "the", "same", "Stanford", "study", "(", "and", "other", "attempts", "to", "improve", "named", "recognition", "translations", ")", "is", "that", "very", "often", "the", "decline", "in", "translation", "stand", "-", "in", "scores", "for", "bilingual", "assessments", "will", "lead", "to", "the", "inclusion", "of", "named", "entity", "translations", "."], "sentence-detokenized": "A frustrating result of the same Stanford study (and other attempts to improve named recognition translations) is that very often the decline in translation stand-in scores for bilingual assessments will lead to the inclusion of named entity translations.", "token2charspan": [[0, 1], [2, 13], [14, 20], [21, 23], [24, 27], [28, 32], [33, 41], [42, 47], [48, 49], [49, 52], [53, 58], [59, 67], [68, 70], [71, 78], [79, 84], [85, 96], [97, 109], [109, 110], [111, 113], [114, 118], [119, 123], [124, 129], [130, 133], [134, 141], [142, 144], [145, 156], [157, 162], [162, 163], [163, 165], [166, 172], [173, 176], [177, 186], [187, 198], [199, 203], [204, 208], [209, 211], [212, 215], [216, 225], [226, 228], [229, 234], [235, 241], [242, 254], [254, 255]]}
{"doc_key": "ai-dev-219", "ner": [[0, 0, "organisation"], [11, 14, "organisation"], [16, 22, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 14, "role", "works_with", false, false], [0, 0, 16, 22, "role", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Medtronic", "is", "using", "the", "PM", "data", "collected", "and", "collaborating", "with", "researchers", "at", "Johns", "Hopkins", "Hospital", "and", "the", "University", "of", "Washington", "School", "of", "Medicine", "to", "help", "answer", "specific", "questions", "about", "heart", "disease", ",", "such", "as", "whether", "a", "weak", "heart", "can", "lead", "to", "arrhythmias", "or", "vice", "versa", "."], "sentence-detokenized": "Medtronic is using the PM data collected and collaborating with researchers at Johns Hopkins Hospital and the University of Washington School of Medicine to help answer specific questions about heart disease, such as whether a weak heart can lead to arrhythmias or vice versa.", "token2charspan": [[0, 9], [10, 12], [13, 18], [19, 22], [23, 25], [26, 30], [31, 40], [41, 44], [45, 58], [59, 63], [64, 75], [76, 78], [79, 84], [85, 92], [93, 101], [102, 105], [106, 109], [110, 120], [121, 123], [124, 134], [135, 141], [142, 144], [145, 153], [154, 156], [157, 161], [162, 168], [169, 177], [178, 187], [188, 193], [194, 199], [200, 207], [207, 208], [209, 213], [214, 216], [217, 224], [225, 226], [227, 231], [232, 237], [238, 241], [242, 246], [247, 249], [250, 261], [262, 264], [265, 269], [270, 275], [275, 276]]}
{"doc_key": "ai-dev-220", "ner": [[4, 5, "organisation"], [9, 9, "misc"], [12, 13, "person"], [15, 16, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 4, 5, "artifact", "made_by_studio", false, false], [12, 13, 9, 9, "role", "", false, false], [15, 16, 9, 9, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "was", "followed", "by", "Paramount", "'s", "first", "film", ",", "Sangari", ",", "with", "Fernando", "Lamas", "and", "Arlene", "Dahl", "."], "sentence-detokenized": "This was followed by Paramount's first film, Sangari, with Fernando Lamas and Arlene Dahl.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 20], [21, 30], [30, 32], [33, 38], [39, 43], [43, 44], [45, 52], [52, 53], [54, 58], [59, 67], [68, 73], [74, 77], [78, 84], [85, 89], [89, 90]]}
{"doc_key": "ai-dev-221", "ner": [[0, 0, "programlang"], [9, 11, "researcher"], [13, 14, "researcher"], [17, 18, "organisation"], [20, 21, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 9, 11, "origin", "", false, false], [0, 0, 13, 14, "origin", "", false, false], [9, 11, 17, 18, "physical", "", false, false], [9, 11, 17, 18, "role", "", false, false], [13, 14, 20, 21, "physical", "", false, false], [13, 14, 20, 21, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["KRL", "is", "a", "knowledge", "representation", "language", ",", "developed", "by", "Daniel", "G.", "Bobrow", "and", "Terry", "Winograd", "while", "at", "Xerox", "PARC", "and", "Stanford", "University", "respectively", "."], "sentence-detokenized": "KRL is a knowledge representation language, developed by Daniel G. Bobrow and Terry Winograd while at Xerox PARC and Stanford University respectively.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 18], [19, 33], [34, 42], [42, 43], [44, 53], [54, 56], [57, 63], [64, 66], [67, 73], [74, 77], [78, 83], [84, 92], [93, 98], [99, 101], [102, 107], [108, 112], [113, 116], [117, 125], [126, 136], [137, 149], [149, 150]]}
{"doc_key": "ai-dev-222", "ner": [[3, 10, "conference"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 24, "researcher"], [31, 32, "task"], [34, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 10, 31, 32, "topic", "", true, false], [12, 13, 3, 10, "physical", "", false, false], [12, 13, 3, 10, "role", "", false, false], [12, 13, 3, 10, "temporal", "", false, false], [15, 16, 3, 10, "physical", "", false, false], [15, 16, 3, 10, "role", "", false, false], [15, 16, 3, 10, "temporal", "", false, false], [18, 19, 3, 10, "physical", "", false, false], [18, 19, 3, 10, "role", "", false, false], [18, 19, 3, 10, "temporal", "", false, false], [21, 24, 3, 10, "physical", "", false, false], [21, 24, 3, 10, "role", "", false, false], [21, 24, 3, 10, "temporal", "", false, false], [31, 32, 34, 37, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["At", "the", "2006", "IEEE", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "Qiang", "Zhu", ",", "Shai", "Avidan", ",", "Mei-Chen", "Yeh", "and", "Kwang", "-", "Ting", "Cheng", "presented", "an", "algorithm", "that", "greatly", "accelerates", "human", "detection", "using", "the", "HOG", "descriptor", "method", "."], "sentence-detokenized": "At the 2006 IEEE Conference on Computer Vision and Pattern Recognition, Qiang Zhu, Shai Avidan, Mei-Chen Yeh and Kwang-Ting Cheng presented an algorithm that greatly accelerates human detection using the HOG descriptor method.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 27], [28, 30], [31, 39], [40, 46], [47, 50], [51, 58], [59, 70], [70, 71], [72, 77], [78, 81], [81, 82], [83, 87], [88, 94], [94, 95], [96, 104], [105, 108], [109, 112], [113, 118], [118, 119], [119, 123], [124, 129], [130, 139], [140, 142], [143, 152], [153, 157], [158, 165], [166, 177], [178, 183], [184, 193], [194, 199], [200, 203], [204, 207], [208, 218], [219, 225], [225, 226]]}
{"doc_key": "ai-dev-223", "ner": [[0, 0, "researcher"], [6, 7, "conference"], [9, 13, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 7, "role", "", false, false], [0, 0, 9, 13, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hayes", "is", "a", "charter", "member", "of", "the", "AAAI", "and", "the", "Association", "for", "Cognitive", "Science", "."], "sentence-detokenized": "Hayes is a charter member of the AAAI and the Association for Cognitive Science.", "token2charspan": [[0, 5], [6, 8], [9, 10], [11, 18], [19, 25], [26, 28], [29, 32], [33, 37], [38, 41], [42, 45], [46, 57], [58, 61], [62, 71], [72, 79], [79, 80]]}
{"doc_key": "ai-dev-224", "ner": [[0, 1, "misc"], [5, 5, "field"], [7, 8, "field"], [10, 11, "field"], [13, 13, "field"], [15, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 32, "field"], [38, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[0, 1, 5, 5, "part-of", "", false, false], [0, 1, 5, 5, "usage", "", false, false], [0, 1, 7, 8, "part-of", "", false, false], [0, 1, 7, 8, "usage", "", false, false], [0, 1, 10, 11, "part-of", "", false, false], [0, 1, 10, 11, "usage", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [0, 1, 13, 13, "usage", "", false, false], [0, 1, 15, 16, "part-of", "", false, false], [0, 1, 15, 16, "usage", "", false, false], [0, 1, 18, 19, "part-of", "", false, false], [0, 1, 18, 19, "usage", "", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 21, 22, "usage", "", false, false], [0, 1, 24, 24, "part-of", "", false, false], [0, 1, 24, 24, "usage", "", false, false], [0, 1, 26, 27, "part-of", "", false, false], [0, 1, 26, 27, "usage", "", false, false], [0, 1, 29, 29, "part-of", "", false, false], [0, 1, 29, 29, "usage", "", false, false], [0, 1, 31, 32, "part-of", "", false, false], [0, 1, 31, 32, "usage", "", false, false], [0, 1, 38, 39, "part-of", "", false, false], [0, 1, 38, 39, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "sentence": ["Time", "series", "are", "used", "in", "statistics", ",", "signal", "processing", ",", "pattern", "recognition", ",", "econometrics", ",", "mathematical", "finance", ",", "weather", "forecasting", ",", "earthquake", "prediction", ",", "electroencephalography", ",", "control", "engineering", ",", "astronomy", ",", "communications", "engineering", ",", "and", "any", "area", "of", "applied", "science", "and", "engineering", "that", "involves", "time", "measurement", "."], "sentence-detokenized": "Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, earthquake prediction, electroencephalography, control engineering, astronomy, communications engineering, and any area of applied science and engineering that involves time measurement.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 23], [24, 34], [34, 35], [36, 42], [43, 53], [53, 54], [55, 62], [63, 74], [74, 75], [76, 88], [88, 89], [90, 102], [103, 110], [110, 111], [112, 119], [120, 131], [131, 132], [133, 143], [144, 154], [154, 155], [156, 178], [178, 179], [180, 187], [188, 199], [199, 200], [201, 210], [210, 211], [212, 226], [227, 238], [238, 239], [240, 243], [244, 247], [248, 252], [253, 255], [256, 263], [264, 271], [272, 275], [276, 287], [288, 292], [293, 301], [302, 306], [307, 318], [318, 319]]}
{"doc_key": "ai-dev-225", "ner": [[9, 18, "metrics"], [38, 40, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "principle", ",", "exact", "recovery", "can", "be", "solved", "by", "the", "maximum", "likelihood", "method", "to", "the", "extent", "that", "it", "is", "feasible", ",", "but", "this", "is", "equivalent", "to", "solving", "a", "restricted", "or", "normalised", "cut", "problem", ",", "such", "as", "the", "usually", "NP", "-", "complete", "minimum", "partition", "."], "sentence-detokenized": "In principle, exact recovery can be solved by the maximum likelihood method to the extent that it is feasible, but this is equivalent to solving a restricted or normalised cut problem, such as the usually NP-complete minimum partition.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 19], [20, 28], [29, 32], [33, 35], [36, 42], [43, 45], [46, 49], [50, 57], [58, 68], [69, 75], [76, 78], [79, 82], [83, 89], [90, 94], [95, 97], [98, 100], [101, 109], [109, 110], [111, 114], [115, 119], [120, 122], [123, 133], [134, 136], [137, 144], [145, 146], [147, 157], [158, 160], [161, 171], [172, 175], [176, 183], [183, 184], [185, 189], [190, 192], [193, 196], [197, 204], [205, 207], [207, 208], [208, 216], [217, 224], [225, 234], [234, 235]]}
{"doc_key": "ai-dev-226", "ner": [[12, 13, "task"], [5, 5, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 12, 13, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "was", "first", "described", "at", "BMVC", "in", "2009", "in", "their", "work", "on", "pedestrian", "detection", "."], "sentence-detokenized": "This was first described at BMVC in 2009 in their work on pedestrian detection.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 24], [25, 27], [28, 32], [33, 35], [36, 40], [41, 43], [44, 49], [50, 54], [55, 57], [58, 68], [69, 78], [78, 79]]}
{"doc_key": "ai-dev-227", "ner": [[4, 9, "conference"], [11, 11, "researcher"], [14, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 4, 9, "physical", "", false, false], [11, 11, 4, 9, "role", "", false, false], [11, 11, 14, 25, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2007", ",", "at", "the", "International", "Conference", "on", "Computer", "Vision", ",", "Terzopoulos", "was", "awarded", "the", "inaugural", "IEEE", "PAMI", "Distinguished", "Researcher", "Award", "in", "Computer", "Vision", "for", "his", "pioneering", "and", "continuing", "research", "in", "deformable", "models", "and", "their", "applications", "."], "sentence-detokenized": "In 2007, at the International Conference on Computer Vision, Terzopoulos was awarded the inaugural IEEE PAMI Distinguished Researcher Award in Computer Vision for his pioneering and continuing research in deformable models and their applications.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 29], [30, 40], [41, 43], [44, 52], [53, 59], [59, 60], [61, 72], [73, 76], [77, 84], [85, 88], [89, 98], [99, 103], [104, 108], [109, 122], [123, 133], [134, 139], [140, 142], [143, 151], [152, 158], [159, 162], [163, 166], [167, 177], [178, 181], [182, 192], [193, 201], [202, 204], [205, 215], [216, 222], [223, 226], [227, 232], [233, 245], [245, 246]]}
{"doc_key": "ai-dev-228", "ner": [[0, 1, "task"], [3, 4, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 3, 4, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cluster", "analysis", "or", "cluster", "analysis", "involves", "assigning", "data", "points", "to", "clusters", "so", "that", "items", "in", "the", "same", "cluster", "are", "as", "similar", "as", "possible", "and", "items", "belonging", "to", "different", "clusters", "are", "as", "dissimilar", "as", "possible", "."], "sentence-detokenized": "Cluster analysis or cluster analysis involves assigning data points to clusters so that items in the same cluster are as similar as possible and items belonging to different clusters are as dissimilar as possible.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 36], [37, 45], [46, 55], [56, 60], [61, 67], [68, 70], [71, 79], [80, 82], [83, 87], [88, 93], [94, 96], [97, 100], [101, 105], [106, 113], [114, 117], [118, 120], [121, 128], [129, 131], [132, 140], [141, 144], [145, 150], [151, 160], [161, 163], [164, 173], [174, 182], [183, 186], [187, 189], [190, 200], [201, 203], [204, 212], [212, 213]]}
{"doc_key": "ai-dev-229", "ner": [[7, 8, "field"], [16, 16, "field"], [18, 19, "task"], [15, 15, "field"], [25, 26, "field"], [28, 29, "field"], [32, 33, "field"], [35, 36, "task"], [38, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 8, 16, 16, "named", "", false, false], [7, 8, 15, 15, "named", "", false, false], [7, 8, 28, 29, "named", "", false, false], [18, 19, 16, 16, "part-of", "task_part_of_field", false, false], [25, 26, 15, 15, "part-of", "", false, false], [32, 33, 28, 29, "part-of", "", false, false], [35, 36, 32, 33, "part-of", "", false, false], [38, 38, 32, 33, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["(", "2005", ")", "We", "can", "look", "at", "text", "mining", "from", "three", "different", "perspectives", ",", "i.e.", "text", "mining", "as", "information", "extraction", ",", "text", "mining", "as", "text", "data", "mining", "and", "text", "mining", "as", "a", "data", "mining", "(", "knowledge", "discovery", "in", "databases", ")", "process", ".", "hotho", ",", "A.", ",", "N\u00fcrnberger", ",", "A.", "and", "Paa\u00df", ",", "G.", "(", "2005", ")", "."], "sentence-detokenized": "(2005) We can look at text mining from three different perspectives, i.e. text mining as information extraction, text mining as text data mining and text mining as a data mining (knowledge discovery in databases) process. hotho, A., N\u00fcrnberger, A. and Paa\u00df, G. (2005).", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 9], [10, 13], [14, 18], [19, 21], [22, 26], [27, 33], [34, 38], [39, 44], [45, 54], [55, 67], [67, 68], [69, 73], [74, 78], [79, 85], [86, 88], [89, 100], [101, 111], [111, 112], [113, 117], [118, 124], [125, 127], [128, 132], [133, 137], [138, 144], [145, 148], [149, 153], [154, 160], [161, 163], [164, 165], [166, 170], [171, 177], [178, 179], [179, 188], [189, 198], [199, 201], [202, 211], [211, 212], [213, 220], [220, 221], [222, 227], [227, 228], [229, 231], [231, 232], [233, 243], [243, 244], [245, 247], [248, 251], [252, 256], [256, 257], [258, 260], [261, 262], [262, 266], [266, 267], [267, 268]]}
{"doc_key": "ai-dev-230", "ner": [[0, 2, "product"], [14, 21, "location"], [22, 22, "location"], [24, 24, "location"], [34, 35, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 14, 21, "related-to", "developed_for", false, false], [14, 21, 22, 22, "physical", "", false, false], [22, 22, 24, 24, "physical", "", false, false], [34, 35, 0, 2, "role", "buys", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Rancho", "arm", "was", "developed", "as", "a", "robotic", "arm", "to", "help", "disabled", "patients", "at", "the", "Rancho", "Los", "Amigos", "National", "Rehabilitation", "Centre", "in", "Downey", ",", "California", ";", "the", "computer", "-", "controlled", "arm", "was", "bought", "by", "Stanford", "University", "in", "1963", "."], "sentence-detokenized": "The Rancho arm was developed as a robotic arm to help disabled patients at the Rancho Los Amigos National Rehabilitation Centre in Downey, California; the computer-controlled arm was bought by Stanford University in 1963.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 18], [19, 28], [29, 31], [32, 33], [34, 41], [42, 45], [46, 48], [49, 53], [54, 62], [63, 71], [72, 74], [75, 78], [79, 85], [86, 89], [90, 96], [97, 105], [106, 120], [121, 127], [128, 130], [131, 137], [137, 138], [139, 149], [149, 150], [151, 154], [155, 163], [163, 164], [164, 174], [175, 178], [179, 182], [183, 189], [190, 192], [193, 201], [202, 212], [213, 215], [216, 220], [220, 221]]}
{"doc_key": "ai-dev-231", "ner": [[1, 1, "university"], [3, 3, "researcher"], [10, 14, "organisation"], [33, 36, "organisation"], [23, 24, "researcher"], [26, 28, "researcher"], [44, 44, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 1, 1, "physical", "", false, false], [3, 3, 1, 1, "role", "", false, false], [3, 3, 10, 14, "role", "founder", false, false], [3, 3, 33, 36, "role", "founder", false, false], [33, 36, 44, 44, "physical", "", false, false], [23, 24, 33, 36, "role", "founder", false, false], [26, 28, 33, 36, "role", "founder", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["At", "UCLA", ",", "Norman", "was", "one", "of", "the", "founders", "of", "the", "Institute", "of", "Cognitive", "Science", "and", "one", "of", "the", "organizers", "(", "along", "with", "Roger", "Schenck", ",", "Alan", "M.", "Collins", "and", "others", ")", "of", "the", "Cognitive", "Science", "Society", ",", "which", "held", "its", "first", "meeting", "at", "UCLA", "in", "1979", "."], "sentence-detokenized": "At UCLA, Norman was one of the founders of the Institute of Cognitive Science and one of the organizers (along with Roger Schenck, Alan M. Collins and others) of the Cognitive Science Society, which held its first meeting at UCLA in 1979.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 23], [24, 26], [27, 30], [31, 39], [40, 42], [43, 46], [47, 56], [57, 59], [60, 69], [70, 77], [78, 81], [82, 85], [86, 88], [89, 92], [93, 103], [104, 105], [105, 110], [111, 115], [116, 121], [122, 129], [129, 130], [131, 135], [136, 138], [139, 146], [147, 150], [151, 157], [157, 158], [159, 161], [162, 165], [166, 175], [176, 183], [184, 191], [191, 192], [193, 198], [199, 203], [204, 207], [208, 213], [214, 221], [222, 224], [225, 229], [230, 232], [233, 237], [237, 238]]}
{"doc_key": "ai-dev-232", "ner": [[6, 7, "product"], [9, 10, "product"], [12, 13, "product"], [15, 19, "product"], [22, 22, "product"], [24, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[22, 22, 15, 19, "type-of", "", false, false], [24, 29, 15, 19, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "common", "robot", "configurations", "are", "articulated", "robots", ",", "SCARA", "robots", ",", "triangular", "robots", "and", "right", "-", "angle", "co-ordinate", "robots", ",", "(", "gantry", "or", "X", "-", "Y", "-", "Z", "robots", ")", "."], "sentence-detokenized": "The most common robot configurations are articulated robots, SCARA robots, triangular robots and right-angle co-ordinate robots, (gantry or X-Y-Z robots).", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 21], [22, 36], [37, 40], [41, 52], [53, 59], [59, 60], [61, 66], [67, 73], [73, 74], [75, 85], [86, 92], [93, 96], [97, 102], [102, 103], [103, 108], [109, 120], [121, 127], [127, 128], [129, 130], [130, 136], [137, 139], [140, 141], [141, 142], [142, 143], [143, 144], [144, 145], [146, 152], [152, 153], [153, 154]]}
{"doc_key": "ai-dev-233", "ner": [[7, 7, "programlang"], [8, 9, "misc"], [15, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 7, 7, "part-of", "", false, false], [15, 15, 8, 9, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Alternatively", ",", "it", "is", "possible", "to", "use", "Perl", "Module", "TM", "directly", "(", "it", "also", "supports", "LTM", ")", "."], "sentence-detokenized": "Alternatively, it is possible to use Perl Module TM directly (it also supports LTM).", "token2charspan": [[0, 13], [13, 14], [15, 17], [18, 20], [21, 29], [30, 32], [33, 36], [37, 41], [42, 48], [49, 51], [52, 60], [61, 62], [62, 64], [65, 69], [70, 78], [79, 82], [82, 83], [83, 84]]}
{"doc_key": "ai-dev-234", "ner": [[1, 1, "country"], [4, 5, "organisation"], [13, 14, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 1, 1, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "American", "team", "from", "Newton", "Labs", "won", "the", "competition", ",", "which", "was", "broadcast", "on", "CNN", "."], "sentence-detokenized": "An American team from Newton Labs won the competition, which was broadcast on CNN.", "token2charspan": [[0, 2], [3, 11], [12, 16], [17, 21], [22, 28], [29, 33], [34, 37], [38, 41], [42, 53], [53, 54], [55, 60], [61, 64], [65, 74], [75, 77], [78, 81], [81, 82]]}
{"doc_key": "ai-dev-235", "ner": [[16, 20, "misc"], [2, 3, "person"], [6, 7, "person"], [9, 12, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 16, 20, "role", "directs", false, false], [6, 7, 16, 20, "role", "acts_in", false, false], [9, 12, 16, 20, "role", "acts_in", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Directed", "by", "David", "Arquette", "and", "starring", "Elizabeth", "Berkeley", "and", "Thomas", "Jane", ",", "the", "short", "film", "\"", "The", "Love", "of", "a", "Housekeeper", "\"", "was", "released", "on", "23", "June", "2008", "."], "sentence-detokenized": "Directed by David Arquette and starring Elizabeth Berkeley and Thomas Jane, the short film \"The Love of a Housekeeper\" was released on 23 June 2008.", "token2charspan": [[0, 8], [9, 11], [12, 17], [18, 26], [27, 30], [31, 39], [40, 49], [50, 58], [59, 62], [63, 69], [70, 74], [74, 75], [76, 79], [80, 85], [86, 90], [91, 92], [92, 95], [96, 100], [101, 103], [104, 105], [106, 117], [117, 118], [119, 122], [123, 131], [132, 134], [135, 137], [138, 142], [143, 147], [147, 148]]}
{"doc_key": "ai-dev-236", "ner": [[3, 4, "product"], [10, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 10, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["For", "example", ",", "Word", "Net", "is", "a", "resource", "that", "includes", "taxonomies", "whose", "elements", "are", "the", "meanings", "of", "English", "words", "."], "sentence-detokenized": "For example, WordNet is a resource that includes taxonomies whose elements are the meanings of English words.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [17, 20], [21, 23], [24, 25], [26, 34], [35, 39], [40, 48], [49, 59], [60, 65], [66, 74], [75, 78], [79, 82], [83, 91], [92, 94], [95, 102], [103, 108], [108, 109]]}
{"doc_key": "ai-dev-237", "ner": [[1, 3, "product"], [6, 6, "product"], [8, 8, "product"], [14, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 1, 3, "type-of", "", false, false], [6, 6, 14, 14, "related-to", "ability_to", false, false], [8, 8, 1, 3, "type-of", "", false, false], [8, 8, 14, 14, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Existing", "humanoid", "robotic", "systems", "such", "as", "ASIMO", "and", "QRIO", "use", "many", "motors", "to", "achieve", "movement", "."], "sentence-detokenized": "Existing humanoid robotic systems such as ASIMO and QRIO use many motors to achieve movement.", "token2charspan": [[0, 8], [9, 17], [18, 25], [26, 33], [34, 38], [39, 41], [42, 47], [48, 51], [52, 56], [57, 60], [61, 65], [66, 72], [73, 75], [76, 83], [84, 92], [92, 93]]}
{"doc_key": "ai-dev-238", "ner": [[0, 1, "metrics"], [5, 6, "metrics"], [8, 8, "metrics"], [10, 14, "misc"], [16, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 0, 1, "part-of", "", false, false], [8, 8, 0, 1, "part-of", "", false, false], [10, 14, 0, 1, "part-of", "", false, false], [16, 18, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LEPOR", "is", "designed", "with", "enhanced", "length", "penalties", ",", "precision", ",", "n-", "gram", "word", "order", "penalties", "and", "recall", "in", "mind", "."], "sentence-detokenized": "LEPOR is designed with enhanced length penalties, precision, n-gram word order penalties and recall in mind.", "token2charspan": [[0, 5], [6, 8], [9, 17], [18, 22], [23, 31], [32, 38], [39, 48], [48, 49], [50, 59], [59, 60], [61, 63], [63, 67], [68, 72], [73, 78], [79, 88], [89, 92], [93, 99], [100, 102], [103, 107], [107, 108]]}
{"doc_key": "ai-dev-239", "ner": [[2, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "a", "research", "indicator", "based", "on", "bilingual", "evaluation", ",", "but", "with", "some", "changes", "."], "sentence-detokenized": "It is a research indicator based on bilingual evaluation, but with some changes.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 16], [17, 26], [27, 32], [33, 35], [36, 45], [46, 56], [56, 57], [58, 61], [62, 66], [67, 71], [72, 79], [79, 80]]}
{"doc_key": "ai-dev-240", "ner": [[8, 10, "product"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "of", "an", "implementation", "in", "MATLAB", "/", "Octave", "."], "sentence-detokenized": "This is an example of an implementation in MATLAB/Octave.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 24], [25, 39], [40, 42], [43, 49], [49, 50], [50, 56], [56, 57]]}
{"doc_key": "ai-dev-241", "ner": [[13, 13, "programlang"], [15, 15, "programlang"], [17, 17, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "designed", "to", "be", "used", "by", "a", "number", "of", "computer", "languages", "including", "Python", ",", "Ruby", "and", "Scheme", "."], "sentence-detokenized": "It is designed to be used by a number of computer languages including Python, Ruby and Scheme.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 20], [21, 25], [26, 28], [29, 30], [31, 37], [38, 40], [41, 49], [50, 59], [60, 69], [70, 76], [76, 77], [78, 82], [83, 86], [87, 93], [93, 94]]}
{"doc_key": "ai-dev-242", "ner": [[0, 0, "researcher"], [6, 7, "organisation"], [14, 14, "conference"], [18, 20, "academicjournal"], [24, 27, "organisation"], [31, 36, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 7, "role", "", false, false], [0, 0, 14, 14, "role", "", false, false], [0, 0, 18, 20, "role", "", false, false], [0, 0, 24, 27, "role", "", false, false], [0, 0, 31, 36, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hayes", "has", "served", "as", "Secretary", "of", "the", "AISB", ",", "President", "and", "Trustee", "of", "the", "IJCAI", ",", "Associate", "Editor", "of", "Artificial", "Intelligence", ",", "Trustee", "of", "the", "Cognitive", "Science", "Society", "and", "President", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "."], "sentence-detokenized": "Hayes has served as Secretary of the AISB, President and Trustee of the IJCAI, Associate Editor of Artificial Intelligence, Trustee of the Cognitive Science Society and President of the American Association for Artificial Intelligence.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 32], [33, 36], [37, 41], [41, 42], [43, 52], [53, 56], [57, 64], [65, 67], [68, 71], [72, 77], [77, 78], [79, 88], [89, 95], [96, 98], [99, 109], [110, 122], [122, 123], [124, 131], [132, 134], [135, 138], [139, 148], [149, 156], [157, 164], [165, 168], [169, 178], [179, 181], [182, 185], [186, 194], [195, 206], [207, 210], [211, 221], [222, 234], [234, 235]]}
{"doc_key": "ai-dev-243", "ner": [[5, 13, "misc"], [15, 19, "misc"], [22, 23, "person"], [25, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 23, 5, 13, "role", "directed_by", false, false], [22, 23, 15, 19, "role", "directed_by", false, false], [22, 23, 25, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "of", "these", "productions", ",", "Now", "Is", "the", "Time", "(", "Putting", "on", "Glasses", ")", "and", "Left", "and", "Right", ",", "were", "directed", "by", "Norman", "McLaren", "for", "the", "National", "Film", "Board", "of", "Canada", "in", "1951", "."], "sentence-detokenized": "Two of these productions, Now Is the Time (Putting on Glasses) and Left and Right, were directed by Norman McLaren for the National Film Board of Canada in 1951.", "token2charspan": [[0, 3], [4, 6], [7, 12], [13, 24], [24, 25], [26, 29], [30, 32], [33, 36], [37, 41], [42, 43], [43, 50], [51, 53], [54, 61], [61, 62], [63, 66], [67, 71], [72, 75], [76, 81], [81, 82], [83, 87], [88, 96], [97, 99], [100, 106], [107, 114], [115, 118], [119, 122], [123, 131], [132, 136], [137, 142], [143, 145], [146, 152], [153, 155], [156, 160], [160, 161]]}
{"doc_key": "ai-dev-244", "ner": [[3, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "purpose", "of", "a", "recommendation", "system", "is", "to", "predict", "the", "target", "user", "'s", "preference", "for", "a", "particular", "item", "."], "sentence-detokenized": "The purpose of a recommendation system is to predict the target user's preference for a particular item.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 16], [17, 31], [32, 38], [39, 41], [42, 44], [45, 52], [53, 56], [57, 63], [64, 68], [68, 70], [71, 81], [82, 85], [86, 87], [88, 98], [99, 103], [103, 104]]}
{"doc_key": "ai-dev-245", "ner": [[1, 2, "algorithm"], [4, 4, "field"], [6, 6, "field"], [8, 9, "field"], [11, 13, "field"], [15, 16, "field"], [18, 19, "field"], [21, 21, "field"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[1, 2, 4, 4, "part-of", "", true, false], [1, 2, 6, 6, "part-of", "", true, false], [1, 2, 8, 9, "part-of", "", true, false], [1, 2, 11, 13, "part-of", "", true, false], [1, 2, 15, 16, "part-of", "", true, false], [1, 2, 18, 19, "part-of", "", true, false], [1, 2, 21, 21, "part-of", "", true, false], [1, 2, 23, 24, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Applications", "of", "convolution", "include", "probability", ",", "statistics", ",", "computer", "vision", ",", "natural", "language", "processing", ",", "image", "processing", "and", "signal", "processing", ",", "engineering", "and", "differential", "equations", "."], "sentence-detokenized": "Applications of convolution include probability, statistics, computer vision, natural language processing, image processing and signal processing, engineering and differential equations.", "token2charspan": [[0, 12], [13, 15], [16, 27], [28, 35], [36, 47], [47, 48], [49, 59], [59, 60], [61, 69], [70, 76], [76, 77], [78, 85], [86, 94], [95, 105], [105, 106], [107, 112], [113, 123], [124, 127], [128, 134], [135, 145], [145, 146], [147, 158], [159, 162], [163, 175], [176, 185], [185, 186]]}
{"doc_key": "ai-dev-246", "ner": [[2, 2, "field"], [4, 6, "task"], [8, 9, "task"], [11, 13, "task"], [15, 16, "task"], [18, 19, "task"], [21, 22, "task"], [27, 28, "task"], [30, 30, "field"], [32, 32, "field"], [34, 36, "field"], [38, 38, "field"], [40, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15], "relations": [[2, 2, 4, 6, "part-of", "", true, false], [2, 2, 8, 9, "part-of", "", true, false], [2, 2, 11, 13, "part-of", "", true, false], [2, 2, 15, 16, "part-of", "", true, false], [2, 2, 18, 19, "part-of", "", true, false], [2, 2, 21, 22, "part-of", "", true, false], [2, 2, 27, 28, "part-of", "", true, false], [2, 2, 30, 30, "part-of", "", true, false], [2, 2, 32, 32, "part-of", "", true, false], [2, 2, 34, 36, "part-of", "", true, false], [2, 2, 38, 38, "part-of", "", true, false], [2, 2, 40, 40, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14], "sentence": ["Applications", "for", "DSP", "include", "audio", "signal", "processing", ",", "audio", "compression", ",", "digital", "image", "processing", ",", "video", "compression", ",", "speech", "processing", ",", "speech", "recognition", ",", "digital", "communications", ",", "digital", "synthesizers", ",", "radar", ",", "sonar", ",", "financial", "signal", "processing", ",", "seismology", "and", "biomedicine", "."], "sentence-detokenized": "Applications for DSP include audio signal processing, audio compression, digital image processing, video compression, speech processing, speech recognition, digital communications, digital synthesizers, radar, sonar, financial signal processing, seismology and biomedicine.", "token2charspan": [[0, 12], [13, 16], [17, 20], [21, 28], [29, 34], [35, 41], [42, 52], [52, 53], [54, 59], [60, 71], [71, 72], [73, 80], [81, 86], [87, 97], [97, 98], [99, 104], [105, 116], [116, 117], [118, 124], [125, 135], [135, 136], [137, 143], [144, 155], [155, 156], [157, 164], [165, 179], [179, 180], [181, 188], [189, 201], [201, 202], [203, 208], [208, 209], [210, 215], [215, 216], [217, 226], [227, 233], [234, 244], [244, 245], [246, 256], [257, 260], [261, 272], [272, 273]]}
{"doc_key": "ai-dev-247", "ner": [[11, 12, "misc"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "20", "February", "1912", "-", "11", "August", "2011", ")", "was", "an", "American", "inventor", ",", "best", "known", "for", "creating", "the", "first", "industrial", "robot", ",", "the", "Unimate", "."], "sentence-detokenized": "(20 February 1912 - 11 August 2011) was an American inventor, best known for creating the first industrial robot, the Unimate.", "token2charspan": [[0, 1], [1, 3], [4, 12], [13, 17], [18, 19], [20, 22], [23, 29], [30, 34], [34, 35], [36, 39], [40, 42], [43, 51], [52, 60], [60, 61], [62, 66], [67, 72], [73, 76], [77, 85], [86, 89], [90, 95], [96, 106], [107, 112], [112, 113], [114, 117], [118, 125], [125, 126]]}
{"doc_key": "ai-dev-248", "ner": [[5, 7, "researcher"], [9, 11, "researcher"], [0, 0, "researcher"], [22, 25, "algorithm"], [27, 29, "algorithm"], [43, 44, "task"], [37, 39, "algorithm"], [34, 35, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[5, 7, 22, 25, "related-to", "writes_about", true, false], [9, 11, 22, 25, "related-to", "writes_about", true, false], [0, 0, 22, 25, "related-to", "writes_about", true, false], [22, 25, 27, 29, "related-to", "", true, false], [43, 44, 37, 39, "related-to", "", true, false], [34, 35, 37, 39, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", ",", "in", "collaboration", "with", "David", "E.", "Rumelhart", "and", "Ronald", "J.", "Williams", ",", "published", "a", "highly", "cited", "paper", "in", "1986", "that", "popularized", "the", "backpropagation", "algorithm", "for", "training", "multilayer", "neural", "networks", ",", "and", "his", "student", "Alex", "Krizhevsky", "designed", "AlexNet", ",", "a", "dramatic", "landmark", "in", "image", "recognition", "{", "{", "cite", "web"], "sentence-detokenized": "Hinton, in collaboration with David E. Rumelhart and Ronald J. Williams, published a highly cited paper in 1986 that popularized the backpropagation algorithm for training multilayer neural networks, and his student Alex Krizhevsky designed AlexNet, a dramatic landmark in image recognition {{ cite web", "token2charspan": [[0, 6], [6, 7], [8, 10], [11, 24], [25, 29], [30, 35], [36, 38], [39, 48], [49, 52], [53, 59], [60, 62], [63, 71], [71, 72], [73, 82], [83, 84], [85, 91], [92, 97], [98, 103], [104, 106], [107, 111], [112, 116], [117, 128], [129, 132], [133, 148], [149, 158], [159, 162], [163, 171], [172, 182], [183, 189], [190, 198], [198, 199], [200, 203], [204, 207], [208, 215], [216, 220], [221, 231], [232, 240], [241, 248], [248, 249], [250, 251], [252, 260], [261, 269], [270, 272], [273, 278], [279, 290], [291, 292], [292, 293], [294, 298], [299, 302]]}
{"doc_key": "ai-dev-249", "ner": [[17, 19, "metrics"], [21, 24, "metrics"], [26, 28, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "values", "being", "predicted", "are", "continuously", "distributed", ",", "the", "error", "can", "be", "summarised", "in", "terms", "of", "mean", "squared", "error", ",", "mean", "square", "root", "error", "or", "median", "absolute", "deviation", "."], "sentence-detokenized": "When the values being predicted are continuously distributed, the error can be summarised in terms of mean squared error, mean square root error or median absolute deviation.", "token2charspan": [[0, 4], [5, 8], [9, 15], [16, 21], [22, 31], [32, 35], [36, 48], [49, 60], [60, 61], [62, 65], [66, 71], [72, 75], [76, 78], [79, 89], [90, 92], [93, 98], [99, 101], [102, 106], [107, 114], [115, 120], [120, 121], [122, 126], [127, 133], [134, 138], [139, 144], [145, 147], [148, 154], [155, 163], [164, 173], [173, 174]]}
{"doc_key": "ai-dev-250", "ner": [[0, 2, "algorithm"], [12, 13, "field"], [10, 11, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 12, 13, "part-of", "", true, false], [0, 2, 10, 11, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Conceptual", "clustering", "was", "developed", "mainly", "in", "the", "1980s", "as", "an", "unsupervised", "learning", "machine", "learning", "paradigm", "."], "sentence-detokenized": "Conceptual clustering was developed mainly in the 1980s as an unsupervised learning machine learning paradigm.", "token2charspan": [[0, 10], [11, 21], [22, 25], [26, 35], [36, 42], [43, 45], [46, 49], [50, 55], [56, 58], [59, 61], [62, 74], [75, 83], [84, 91], [92, 100], [101, 109], [109, 110]]}
{"doc_key": "ai-dev-251", "ner": [[7, 8, "product"], [26, 30, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "named", "entities", "are", "not", "recognised", "by", "machine", "translation", ",", "they", "may", "be", "incorrectly", "translated", "into", "common", "nouns", ",", "which", "is", "likely", "not", "to", "affect", "the", "bilingual", "assessment", "stand", "-", "in", "'s", "evaluation", "of", "the", "translation", ",", "but", "will", "alter", "the", "human", "readability", "of", "the", "text", "."], "sentence-detokenized": "If named entities are not recognised by machine translation, they may be incorrectly translated into common nouns, which is likely not to affect the bilingual assessment stand-in's evaluation of the translation, but will alter the human readability of the text.", "token2charspan": [[0, 2], [3, 8], [9, 17], [18, 21], [22, 25], [26, 36], [37, 39], [40, 47], [48, 59], [59, 60], [61, 65], [66, 69], [70, 72], [73, 84], [85, 95], [96, 100], [101, 107], [108, 113], [113, 114], [115, 120], [121, 123], [124, 130], [131, 134], [135, 137], [138, 144], [145, 148], [149, 158], [159, 169], [170, 175], [175, 176], [176, 178], [178, 180], [181, 191], [192, 194], [195, 198], [199, 210], [210, 211], [212, 215], [216, 220], [221, 226], [227, 230], [231, 236], [237, 248], [249, 251], [252, 255], [256, 260], [260, 261]]}
{"doc_key": "ai-dev-252", "ner": [[0, 1, "researcher"], [10, 11, "misc"], [12, 18, "conference"], [20, 22, "location"], [24, 24, "country"], [39, 42, "researcher"], [46, 46, "researcher"], [50, 50, "university"], [54, 55, "researcher"], [57, 58, "researcher"], [60, 61, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 11, "related-to", "writes_about", false, false], [0, 1, 12, 18, "temporal", "", true, false], [12, 18, 20, 22, "physical", "", false, false], [20, 22, 24, 24, "physical", "", false, false], [46, 46, 50, 50, "physical", "", false, false], [46, 46, 50, 50, "role", "", false, false], [54, 55, 50, 50, "physical", "", false, false], [54, 55, 50, 50, "role", "", false, false], [57, 58, 50, 50, "physical", "", false, false], [57, 58, 50, 50, "role", "", false, false], [60, 61, 50, 50, "physical", "", false, false], [60, 61, 50, 50, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Roger", "Schank", ",", "1969", ",", "A", "conceptual", "dependency", "parser", "for", "natural", "language", "Proceedings", "of", "the", "1969", "on", "Computational", "linguistics", ",", "S\u00e5ng", "-", "S\u00e4by", ",", "Sweden", ",", "pages", "1-", "3", "This", "model", ",", "influenced", "in", "part", "by", "the", "work", "of", "Sydney", "Lamb", ",", "was", "widely", "used", "by", "Schank", "'s", "students", "at", "Yale", ",", "such", "as", "Robert", "Wilensky", ",", "Wendy", "Lehnert", "and", "Janet", "Kolodner", "."], "sentence-detokenized": "Roger Schank, 1969, A conceptual dependency parser for natural language Proceedings of the 1969 on Computational linguistics, S\u00e5ng-S\u00e4by, Sweden, pages 1-3 This model, influenced in part by the work of Sydney Lamb, was widely used by Schank's students at Yale, such as Robert Wilensky, Wendy Lehnert and Janet Kolodner.", "token2charspan": [[0, 5], [6, 12], [12, 13], [14, 18], [18, 19], [20, 21], [22, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 71], [72, 83], [84, 86], [87, 90], [91, 95], [96, 98], [99, 112], [113, 124], [124, 125], [126, 130], [130, 131], [131, 135], [135, 136], [137, 143], [143, 144], [145, 150], [151, 153], [153, 154], [155, 159], [160, 165], [165, 166], [167, 177], [178, 180], [181, 185], [186, 188], [189, 192], [193, 197], [198, 200], [201, 207], [208, 212], [212, 213], [214, 217], [218, 224], [225, 229], [230, 232], [233, 239], [239, 241], [242, 250], [251, 253], [254, 258], [258, 259], [260, 264], [265, 267], [268, 274], [275, 283], [283, 284], [285, 290], [291, 298], [299, 302], [303, 308], [309, 317], [317, 318]]}
{"doc_key": "ai-dev-253", "ner": [[2, 4, "algorithm"], [6, 9, "algorithm"], [13, 13, "algorithm"], [15, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 9, 2, 4, "named", "", false, false], [13, 13, 2, 4, "named", "", false, false], [15, 16, 2, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Improved", "Maximum", "Likelihood", "Method", "(", "IMLM", ")", "is", "a", "combination", "of", "two", "MLM", "(", "maximum", "likelihood", ")", "estimators", "."], "sentence-detokenized": "The Improved Maximum Likelihood Method (IMLM) is a combination of two MLM (maximum likelihood) estimators.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 31], [32, 38], [39, 40], [40, 44], [44, 45], [46, 48], [49, 50], [51, 62], [63, 65], [66, 69], [70, 73], [74, 75], [75, 82], [83, 93], [93, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-dev-254", "ner": [[22, 23, "metrics"], [26, 27, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[26, 27, 22, 23, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["These", "methods", "can", "also", "analyse", "the", "output", "of", "a", "program", "and", "its", "usefulness", ",", "and", "may", "therefore", "involve", "the", "analysis", "of", "its", "obfuscation", "matrix", "(", "or", "obfuscation", "table", ")", "."], "sentence-detokenized": "These methods can also analyse the output of a program and its usefulness, and may therefore involve the analysis of its obfuscation matrix (or obfuscation table).", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 22], [23, 30], [31, 34], [35, 41], [42, 44], [45, 46], [47, 54], [55, 58], [59, 62], [63, 73], [73, 74], [75, 78], [79, 82], [83, 92], [93, 100], [101, 104], [105, 113], [114, 116], [117, 120], [121, 132], [133, 139], [140, 141], [141, 143], [144, 155], [156, 161], [161, 162], [162, 163]]}
{"doc_key": "ai-dev-255", "ner": [[0, 4, "product"], [5, 6, "researcher"], [8, 9, "researcher"], [11, 13, "researcher"], [17, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 5, 6, "origin", "", false, false], [0, 4, 8, 9, "origin", "", false, false], [0, 4, 11, 13, "origin", "", false, false], [0, 4, 17, 22, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SURF", "was", "first", "published", "by", "Herbert", "Bay", ",", "Tinne", "Tuytelaars", "and", "Luc", "Van", "Gool", "and", "presented", "at", "the", "European", "Computer", "Vision", "Conference", "2006", "."], "sentence-detokenized": "SURF was first published by Herbert Bay, Tinne Tuytelaars and Luc Van Gool and presented at the European Computer Vision Conference 2006.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 24], [25, 27], [28, 35], [36, 39], [39, 40], [41, 46], [47, 57], [58, 61], [62, 65], [66, 69], [70, 74], [75, 78], [79, 88], [89, 91], [92, 95], [96, 104], [105, 113], [114, 120], [121, 131], [132, 136], [136, 137]]}
{"doc_key": "ai-dev-256", "ner": [[0, 0, "task"], [7, 8, "field"], [10, 11, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 8, "part-of", "", false, false], [0, 0, 10, 11, "part-of", "", false, false], [0, 0, 13, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OCR", "is", "an", "area", "of", "research", "in", "pattern", "recognition", ",", "artificial", "intelligence", "and", "computer", "vision", "."], "sentence-detokenized": "OCR is an area of research in pattern recognition, artificial intelligence and computer vision.", "token2charspan": [[0, 3], [4, 6], [7, 9], [10, 14], [15, 17], [18, 26], [27, 29], [30, 37], [38, 49], [49, 50], [51, 61], [62, 74], [75, 78], [79, 87], [88, 94], [94, 95]]}
{"doc_key": "ai-dev-257", "ner": [[6, 9, "metrics"], [12, 14, "algorithm"], [16, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 18, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Continuing", "with", "the", "example", "of", "using", "the", "maximum", "likelihood", "estimator", ",", "the", "probability", "density", "function", "(", "pdf", ")", "of", "the", "noise", "of", "a", "sample", "mathwn", "/", "math", "is"], "sentence-detokenized": "Continuing with the example of using the maximum likelihood estimator, the probability density function (pdf) of the noise of a sample mathwn/math is", "token2charspan": [[0, 10], [11, 15], [16, 19], [20, 27], [28, 30], [31, 36], [37, 40], [41, 48], [49, 59], [60, 69], [69, 70], [71, 74], [75, 86], [87, 94], [95, 103], [104, 105], [105, 108], [108, 109], [110, 112], [113, 116], [117, 122], [123, 125], [126, 127], [128, 134], [135, 141], [141, 142], [142, 146], [147, 149]]}
{"doc_key": "ai-dev-258", "ner": [[2, 3, "field"], [5, 6, "task"], [8, 9, "task"], [11, 12, "task"], [14, 15, "task"], [17, 19, "task"], [21, 21, "task"], [23, 23, "task"], [25, 26, "task"], [28, 29, "task"], [31, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[5, 6, 2, 3, "part-of", "", false, false], [8, 9, 2, 3, "part-of", "", false, false], [11, 12, 2, 3, "part-of", "", false, false], [14, 15, 2, 3, "part-of", "", false, false], [17, 19, 2, 3, "part-of", "", false, false], [21, 21, 2, 3, "part-of", "", false, false], [23, 23, 2, 3, "part-of", "", false, false], [25, 26, 2, 3, "part-of", "", false, false], [28, 29, 2, 3, "part-of", "", false, false], [31, 33, 2, 3, "part-of", "", false, false], [35, 36, 2, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Subfields", "of", "computer", "vision", "include", "scene", "reconstruction", ",", "event", "detection", ",", "video", "tracking", ",", "object", "recognition", ",", "3D", "pose", "estimation", ",", "learning", ",", "indexing", ",", "motion", "estimation", ",", "visual", "servoing", ",", "3D", "scene", "modelling", "and", "image", "restoration", "."], "sentence-detokenized": "Subfields of computer vision include scene reconstruction, event detection, video tracking, object recognition, 3D pose estimation, learning, indexing, motion estimation, visual servoing, 3D scene modelling and image restoration.", "token2charspan": [[0, 9], [10, 12], [13, 21], [22, 28], [29, 36], [37, 42], [43, 57], [57, 58], [59, 64], [65, 74], [74, 75], [76, 81], [82, 90], [90, 91], [92, 98], [99, 110], [110, 111], [112, 114], [115, 119], [120, 130], [130, 131], [132, 140], [140, 141], [142, 150], [150, 151], [152, 158], [159, 169], [169, 170], [171, 177], [178, 186], [186, 187], [188, 190], [191, 196], [197, 206], [207, 210], [211, 216], [217, 228], [228, 229]]}
{"doc_key": "ai-dev-259", "ner": [[4, 9, "conference"], [11, 12, "researcher"], [14, 16, "misc"], [19, 20, "conference"], [27, 27, "researcher"], [29, 29, "researcher"], [23, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 9, 19, 20, "named", "", false, false], [11, 12, 14, 16, "win-defeat", "", false, false], [11, 12, 23, 24, "related-to", "writes_about", true, false], [14, 16, 4, 9, "temporal", "", false, false], [27, 27, 14, 16, "win-defeat", "", false, true], [27, 27, 23, 24, "related-to", "writes_about", true, false], [29, 29, 14, 16, "win-defeat", "", false, true], [29, 29, 23, 24, "related-to", "writes_about", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["In", "2013", ",", "at", "the", "International", "Conference", "on", "Computer", "Vision", ",", "Terzopoulos", "was", "awarded", "the", "Helmholtz", "Prize", "for", "his", "1987", "ICCV", "paper", "on", "active", "contour", "models", "with", "Kass", "and", "Witkin", "."], "sentence-detokenized": "In 2013, at the International Conference on Computer Vision, Terzopoulos was awarded the Helmholtz Prize for his 1987 ICCV paper on active contour models with Kass and Witkin.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 29], [30, 40], [41, 43], [44, 52], [53, 59], [59, 60], [61, 72], [73, 76], [77, 84], [85, 88], [89, 98], [99, 104], [105, 108], [109, 112], [113, 117], [118, 122], [123, 128], [129, 131], [132, 138], [139, 146], [147, 153], [154, 158], [159, 163], [164, 167], [168, 174], [174, 175]]}
{"doc_key": "ai-dev-260", "ner": [[14, 15, "task"], [17, 19, "algorithm"], [21, 22, "algorithm"], [24, 26, "algorithm"], [28, 29, "algorithm"], [31, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 15, 17, 19, "usage", "", true, false], [14, 15, 21, 22, "usage", "", true, false], [14, 15, 24, 26, "usage", "", true, false], [14, 15, 28, 29, "usage", "", true, false], [14, 15, 31, 32, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Many", "algorithms", "exist", "to", "solve", "such", "problems", "if", "regularisation", "functions", ";", "popular", "algorithms", "for", "linear", "classification", "include", "stochastic", "gradient", "descent", ")", "gradient", "descent", ",", "L", "-", "BFGS", ",", "coordinate", "descent", "and", "Newton", "'s", "method", "."], "sentence-detokenized": "Many algorithms exist to solve such problems if regularisation functions; popular algorithms for linear classification include stochastic gradient descent) gradient descent, L-BFGS, coordinate descent and Newton's method.", "token2charspan": [[0, 4], [5, 15], [16, 21], [22, 24], [25, 30], [31, 35], [36, 44], [45, 47], [48, 62], [63, 72], [72, 73], [74, 81], [82, 92], [93, 96], [97, 103], [104, 118], [119, 126], [127, 137], [138, 146], [147, 154], [154, 155], [156, 164], [165, 172], [172, 173], [174, 175], [175, 176], [176, 180], [180, 181], [182, 192], [193, 200], [201, 204], [205, 211], [211, 213], [214, 220], [220, 221]]}
{"doc_key": "ai-dev-261", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 11, 12, "origin", "", false, false], [5, 5, 0, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Long", "Short", "Term", "Memory", "(", "LSTM", ")", "networks", "were", "invented", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "in", "1997", "and", "have", "set", "accuracy", "records", "in", "a", "number", "of", "application", "areas", "."], "sentence-detokenized": "Long Short Term Memory (LSTM) networks were invented by Sepp Hochreiter and J\u00fcrgen Schmidhuber in 1997 and have set accuracy records in a number of application areas.", "token2charspan": [[0, 4], [5, 10], [11, 15], [16, 22], [23, 24], [24, 28], [28, 29], [30, 38], [39, 43], [44, 52], [53, 55], [56, 60], [61, 71], [72, 75], [76, 82], [83, 94], [95, 97], [98, 102], [103, 106], [107, 111], [112, 115], [116, 124], [125, 132], [133, 135], [136, 137], [138, 144], [145, 147], [148, 159], [160, 165], [165, 166]]}
{"doc_key": "ai-dev-262", "ner": [[0, 0, "product"], [5, 6, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["TN", "was", "developed", "at", "Massachusetts", "General", "Hospital", "and", "tested", "in", "a", "variety", "of", "situations", ",", "including", "extraction", "of", "smoking", "status", ",", "family", "history", "of", "coronary", "artery", "disease", ",", "and", "identification", "of", "patients", "with", "sleep", "disorders", "."], "sentence-detokenized": "TN was developed at Massachusetts General Hospital and tested in a variety of situations, including extraction of smoking status, family history of coronary artery disease, and identification of patients with sleep disorders.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 33], [34, 41], [42, 50], [51, 54], [55, 61], [62, 64], [65, 66], [67, 74], [75, 77], [78, 88], [88, 89], [90, 99], [100, 110], [111, 113], [114, 121], [122, 128], [128, 129], [130, 136], [137, 144], [145, 147], [148, 156], [157, 163], [164, 171], [171, 172], [173, 176], [177, 191], [192, 194], [195, 203], [204, 208], [209, 214], [215, 224], [224, 225]]}
{"doc_key": "ai-dev-263", "ner": [[3, 4, "researcher"], [9, 10, "product"], [16, 19, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 9, 10, "role", "sells", false, false], [9, 10, 16, 19, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1960", ",", "De", "Waal", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "shipped", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, De Waal personally sold the first Unimate robot, which was shipped to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 16], [17, 27], [28, 32], [33, 36], [37, 42], [43, 50], [51, 56], [56, 57], [58, 63], [64, 67], [68, 75], [76, 78], [79, 86], [87, 93], [94, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-dev-264", "ner": [[1, 4, "conference"], [7, 8, "location"], [10, 10, "location"], [12, 12, "country"], [30, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 4, 7, 8, "physical", "", false, false], [7, 8, 10, 10, "physical", "", false, false], [10, 10, 12, 12, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "European", "Campus", "Party", "was", "held", "in", "Caja", "M\u00e1gica", ",", "Madrid", ",", "Spain", ",", "from", "14", "to", "18", "April", "2010", ",", "with", "800", "participants", "from", "the", "27", "member", "states", "of", "the", "European", "Union", "."], "sentence-detokenized": "The European Campus Party was held in Caja M\u00e1gica, Madrid, Spain, from 14 to 18 April 2010, with 800 participants from the 27 member states of the European Union.", "token2charspan": [[0, 3], [4, 12], [13, 19], [20, 25], [26, 29], [30, 34], [35, 37], [38, 42], [43, 49], [49, 50], [51, 57], [57, 58], [59, 64], [64, 65], [66, 70], [71, 73], [74, 76], [77, 79], [80, 85], [86, 90], [90, 91], [92, 96], [97, 100], [101, 113], [114, 118], [119, 122], [123, 125], [126, 132], [133, 139], [140, 142], [143, 146], [147, 155], [156, 161], [161, 162]]}
{"doc_key": "ai-dev-265", "ner": [[4, 4, "organisation"], [6, 8, "organisation"], [14, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 17, 4, 4, "origin", "", false, false], [14, 17, 6, 8, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2016", ",", "DeepMind", "and", "Moorfields", "Eye", "Hospital", "announced", "a", "collaboration", "to", "develop", "AI", "applications", "for", "healthcare", "."], "sentence-detokenized": "In July 2016, DeepMind and Moorfields Eye Hospital announced a collaboration to develop AI applications for healthcare.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 22], [23, 26], [27, 37], [38, 41], [42, 50], [51, 60], [61, 62], [63, 76], [77, 79], [80, 87], [88, 90], [91, 103], [104, 107], [108, 118], [118, 119]]}
{"doc_key": "ai-dev-266", "ner": [[2, 5, "misc"], [10, 13, "university"], [15, 15, "university"], [17, 20, "university"], [22, 23, "university"], [25, 25, "university"], [27, 28, "university"], [30, 33, "university"], [35, 36, "university"], [38, 38, "university"], [40, 40, "university"], [42, 45, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[2, 5, 10, 13, "physical", "", false, false], [2, 5, 15, 15, "physical", "", false, false], [2, 5, 17, 20, "physical", "", false, false], [2, 5, 22, 23, "physical", "", false, false], [2, 5, 25, 25, "physical", "", false, false], [2, 5, 27, 28, "physical", "", false, false], [2, 5, 30, 33, "physical", "", false, false], [2, 5, 35, 36, "physical", "", false, false], [2, 5, 38, 38, "physical", "", false, false], [2, 5, 40, 40, "physical", "", false, false], [2, 5, 42, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["They", "eventually", "awarded", "11", "PR2s", "to", "various", "institutions", ",", "including", "the", "University", "of", "Freiburg", ",", "Bosch", ",", "Georgia", "Institute", "of", "Technology", ",", "KU", "Leuven", ",", "MIT", ",", "Stanford", "University", ",", "Technical", "University", "of", "Munich", ",", "UC", "Berkeley", ",", "Penn", ",", "USC", "and", "the", "University", "of", "Tokyo", "."], "sentence-detokenized": "They eventually awarded 11 PR2s to various institutions, including the University of Freiburg, Bosch, Georgia Institute of Technology, KU Leuven, MIT, Stanford University, Technical University of Munich, UC Berkeley, Penn, USC and the University of Tokyo.", "token2charspan": [[0, 4], [5, 15], [16, 23], [24, 26], [27, 31], [32, 34], [35, 42], [43, 55], [55, 56], [57, 66], [67, 70], [71, 81], [82, 84], [85, 93], [93, 94], [95, 100], [100, 101], [102, 109], [110, 119], [120, 122], [123, 133], [133, 134], [135, 137], [138, 144], [144, 145], [146, 149], [149, 150], [151, 159], [160, 170], [170, 171], [172, 181], [182, 192], [193, 195], [196, 202], [202, 203], [204, 206], [207, 215], [215, 216], [217, 221], [221, 222], [223, 226], [227, 230], [231, 234], [235, 245], [246, 248], [249, 254], [254, 255]]}
{"doc_key": "ai-dev-267", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [7, 7, "metrics"], [9, 10, "metrics"], [18, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 18, 20, "part-of", "", false, false], [5, 5, 18, 20, "part-of", "", false, false], [7, 7, 18, 20, "part-of", "", false, false], [9, 10, 18, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "counts", "for", "TP", ",", "TN", ",", "FP", "and", "FN", "are", "usually", "kept", "on", "a", "table", "known", "as", "the", "confusion", "matrix", "."], "sentence-detokenized": "The counts for TP, TN, FP and FN are usually kept on a table known as the confusion matrix.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 17], [17, 18], [19, 21], [21, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 44], [45, 49], [50, 52], [53, 54], [55, 60], [61, 66], [67, 69], [70, 73], [74, 83], [84, 90], [90, 91]]}
{"doc_key": "ai-dev-268", "ner": [[5, 6, "metrics"], [8, 9, "metrics"], [11, 12, "metrics"], [14, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["As", "a", "feature", "set", ",", "information", "gain", ",", "cross", "entropy", ",", "mutual", "information", "and", "odds", "ratios", "are", "usually", "used", "."], "sentence-detokenized": "As a feature set, information gain, cross entropy, mutual information and odds ratios are usually used.", "token2charspan": [[0, 2], [3, 4], [5, 12], [13, 16], [16, 17], [18, 29], [30, 34], [34, 35], [36, 41], [42, 49], [49, 50], [51, 57], [58, 69], [70, 73], [74, 78], [79, 85], [86, 89], [90, 97], [98, 102], [102, 103]]}
{"doc_key": "ai-dev-269", "ner": [[12, 13, "task"], [15, 16, "task"], [18, 18, "task"], [20, 20, "task"], [22, 22, "task"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[24, 24, 22, 22, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "successfully", "applied", "to", "a", "variety", "of", "problems", ",", "including", "robot", "control", ",", "lift", "scheduling", ",", "telecommunications", ",", "checkers", "and", "Go", "(", "AlphaGo", ")", "."], "sentence-detokenized": "It has been successfully applied to a variety of problems, including robot control, lift scheduling, telecommunications, checkers and Go (AlphaGo).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 24], [25, 32], [33, 35], [36, 37], [38, 45], [46, 48], [49, 57], [57, 58], [59, 68], [69, 74], [75, 82], [82, 83], [84, 88], [89, 99], [99, 100], [101, 119], [119, 120], [121, 129], [130, 133], [134, 136], [137, 138], [138, 145], [145, 146], [146, 147]]}
{"doc_key": "ai-dev-270", "ner": [[11, 13, "misc"], [17, 20, "university"], [23, 23, "location"], [24, 25, "location"], [28, 32, "location"], [35, 41, "location"], [43, 43, "location"], [45, 45, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 13, 17, 20, "physical", "", false, false], [17, 20, 23, 23, "physical", "", false, false], [23, 23, 24, 25, "physical", "", false, false], [28, 32, 35, 41, "physical", "", false, false], [35, 41, 43, 43, "physical", "", false, false], [43, 43, 45, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["2018", "is", "the", "first", "year", "of", "Mission", "8", ",", "with", "the", "US", "venue", "taking", "place", "at", "the", "Georgia", "Institute", "of", "Technology", "campus", "in", "Atlanta", ",", "Georgia", ",", "and", "the", "Asia", "/", "Pacific", "venue", "at", "the", "Beijing", "University", "of", "Aeronautics", "and", "Astronautics", "stadium", "in", "Beijing", ",", "China", "."], "sentence-detokenized": "2018 is the first year of Mission 8, with the US venue taking place at the Georgia Institute of Technology campus in Atlanta, Georgia, and the Asia/Pacific venue at the Beijing University of Aeronautics and Astronautics stadium in Beijing, China.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 17], [18, 22], [23, 25], [26, 33], [34, 35], [35, 36], [37, 41], [42, 45], [46, 48], [49, 54], [55, 61], [62, 67], [68, 70], [71, 74], [75, 82], [83, 92], [93, 95], [96, 106], [107, 113], [114, 116], [117, 124], [124, 125], [126, 133], [133, 134], [135, 138], [139, 142], [143, 147], [147, 148], [148, 155], [156, 161], [162, 164], [165, 168], [169, 176], [177, 187], [188, 190], [191, 202], [203, 206], [207, 219], [220, 227], [228, 230], [231, 238], [238, 239], [240, 245], [245, 246]]}
{"doc_key": "ai-dev-271", "ner": [[0, 2, "field"], [6, 7, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 7, "origin", "", false, false], [0, 2, 6, 7, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "is", "closely", "related", "to", "pattern", "recognition", "and", "stems", "from", "artificial", "intelligence", "."], "sentence-detokenized": "Machine learning is closely related to pattern recognition and stems from artificial intelligence.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 35], [36, 38], [39, 46], [47, 58], [59, 62], [63, 68], [69, 73], [74, 84], [85, 97], [97, 98]]}
{"doc_key": "ai-dev-272", "ner": [[4, 4, "programlang"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "comes", "with", "3", "Java", "games", ",", "controlled", "with", "a", "remote", "control", "and", "displayed", "on", "its", "LCD", "screen", "."], "sentence-detokenized": "It comes with 3 Java games, controlled with a remote control and displayed on its LCD screen.", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 15], [16, 20], [21, 26], [26, 27], [28, 38], [39, 43], [44, 45], [46, 52], [53, 60], [61, 64], [65, 74], [75, 77], [78, 81], [82, 85], [86, 92], [92, 93]]}
{"doc_key": "ai-dev-273", "ner": [[5, 14, "task"], [16, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 18, 5, 14, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "commercially", "successful", "but", "specialised", "computer", "vision", "-", "based", "technique", "for", "articulated", "body", "pose", "estimation", "is", "optical", "motion", "capture", "."], "sentence-detokenized": "A commercially successful but specialised computer vision-based technique for articulated body pose estimation is optical motion capture.", "token2charspan": [[0, 1], [2, 14], [15, 25], [26, 29], [30, 41], [42, 50], [51, 57], [57, 58], [58, 63], [64, 73], [74, 77], [78, 89], [90, 94], [95, 99], [100, 110], [111, 113], [114, 121], [122, 128], [129, 136], [136, 137]]}
{"doc_key": "ai-dev-274", "ner": [[1, 2, "organisation"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 9, 10, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "SMC", "is", "very", "similar", "to", "the", "more", "popular", "Jaccard", "index", "."], "sentence-detokenized": "The SMC is very similar to the more popular Jaccard index.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 15], [16, 23], [24, 26], [27, 30], [31, 35], [36, 43], [44, 51], [52, 57], [57, 58]]}
{"doc_key": "ai-dev-275", "ner": [[0, 0, "product"], [2, 6, "product"], [9, 12, "product"], [21, 22, "researcher"], [23, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 9, 12, "named", "", false, false], [0, 0, 21, 22, "artifact", "", false, false], [0, 0, 23, 28, "artifact", "", false, false], [2, 6, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ",", "or", "Programmable", "Universal", "Manipulator", "Arm", ")", "is", "an", "industrial", "robot", "arm", "developed", "by", "Victor", "Scheinman", "of", "the", "pioneering", "robotics", "company", "Unimation", "."], "sentence-detokenized": "PUMA (Programmable Universal Machine for Assembly, or Programmable Universal Manipulator Arm) is an industrial robot arm developed by Victor Scheinman of the pioneering robotics company Unimation.", "token2charspan": [[0, 4], [5, 6], [6, 18], [19, 28], [29, 36], [37, 40], [41, 49], [49, 50], [51, 53], [54, 66], [67, 76], [77, 88], [89, 92], [92, 93], [94, 96], [97, 99], [100, 110], [111, 116], [117, 120], [121, 130], [131, 133], [134, 140], [141, 150], [151, 153], [154, 157], [158, 168], [169, 177], [178, 185], [186, 195], [195, 196]]}
{"doc_key": "ai-dev-276", "ner": [[4, 4, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "written", "in", "Python", "."], "sentence-detokenized": "It is written in Python.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 23], [23, 24]]}
{"doc_key": "ai-dev-277", "ner": [[0, 0, "misc"], [2, 4, "misc"], [12, 12, "field"], [14, 15, "field"], [23, 24, "field"], [26, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 6, 7], "relations": [[0, 0, 2, 4, "related-to", "metric_for", true, false], [0, 0, 12, 12, "part-of", "", false, false], [0, 0, 14, 15, "part-of", "", false, false], [0, 0, 23, 24, "part-of", "", false, false], [0, 0, 26, 26, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 5, 6], "sentence": ["Bandwidth", "in", "Hertz", "is", "a", "central", "concept", "in", "many", "fields", ",", "including", "electronics", ",", "information", "theory", ",", "digital", "communications", ",", "radio", "communications", ",", "signal", "processing", "and", "spectroscopy", ",", "and", "is", "one", "of", "the", "factors", "that", "determine", "the", "capacity", "of", "a", "particular", "communication", "channel", "."], "sentence-detokenized": "Bandwidth in Hertz is a central concept in many fields, including electronics, information theory, digital communications, radio communications, signal processing and spectroscopy, and is one of the factors that determine the capacity of a particular communication channel.", "token2charspan": [[0, 9], [10, 12], [13, 18], [19, 21], [22, 23], [24, 31], [32, 39], [40, 42], [43, 47], [48, 54], [54, 55], [56, 65], [66, 77], [77, 78], [79, 90], [91, 97], [97, 98], [99, 106], [107, 121], [121, 122], [123, 128], [129, 143], [143, 144], [145, 151], [152, 162], [163, 166], [167, 179], [179, 180], [181, 184], [185, 187], [188, 191], [192, 194], [195, 198], [199, 206], [207, 211], [212, 221], [222, 225], [226, 234], [235, 237], [238, 239], [240, 250], [251, 264], [265, 272], [272, 273]]}
{"doc_key": "ai-dev-278", "ner": [[12, 12, "algorithm"], [14, 14, "algorithm"], [11, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 12, 11, 19, "part-of", "", false, false], [14, 14, 11, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["If", "convex", "losses", "are", "utilised", "(", "as", "in", "all", "members", "of", "the", "AdaBoost", ",", "LogitBoost", "and", "AnyBoost", "family", "of", "algorithms", ")", ",", "then", "examples", "with", "higher", "margins", "will", "receive", "less", "(", "or", "equal", ")", "weights", "than", "examples", "with", "lower", "margins", "."], "sentence-detokenized": "If convex losses are utilised (as in all members of the AdaBoost, LogitBoost and AnyBoost family of algorithms), then examples with higher margins will receive less (or equal) weights than examples with lower margins.", "token2charspan": [[0, 2], [3, 9], [10, 16], [17, 20], [21, 29], [30, 31], [31, 33], [34, 36], [37, 40], [41, 48], [49, 51], [52, 55], [56, 64], [64, 65], [66, 76], [77, 80], [81, 89], [90, 96], [97, 99], [100, 110], [110, 111], [111, 112], [113, 117], [118, 126], [127, 131], [132, 138], [139, 146], [147, 151], [152, 159], [160, 164], [165, 166], [166, 168], [169, 174], [174, 175], [176, 183], [184, 188], [189, 197], [198, 202], [203, 208], [209, 216], [216, 217]]}
{"doc_key": "ai-dev-279", "ner": [[0, 5, "researcher"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", "1991", "thesis", "Sepp", "Hochreiter", "."], "sentence-detokenized": "Sepp Hochreiter 1991 thesis Sepp Hochreiter.", "token2charspan": [[0, 4], [5, 15], [16, 20], [21, 27], [28, 32], [33, 43], [43, 44]]}
{"doc_key": "ai-dev-280", "ner": [[4, 5, "algorithm"], [7, 7, "algorithm"], [10, 11, "algorithm"], [14, 14, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"], [25, 27, "algorithm"], [30, 31, "algorithm"], [33, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 7, 4, 5, "named", "", false, false], [14, 14, 10, 11, "named", "", false, false], [17, 19, 25, 27, "related-to", "", true, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Typical", "discriminatory", "models", "include", "logistic", "regression", "(", "LR", ")", ",", "support", "vector", "machines", "(", "SVM", ")", ",", "conditional", "random", "fields", "(", "CRF", ")", "(", "specified", "on", "undirected", "graphs", ")", ",", "decision", "trees", ",", "neural", "networks", ",", "and", "many", "others", "."], "sentence-detokenized": "Typical discriminatory models include logistic regression (LR), support vector machines (SVM), conditional random fields (CRF) (specified on undirected graphs), decision trees, neural networks, and many others.", "token2charspan": [[0, 7], [8, 22], [23, 29], [30, 37], [38, 46], [47, 57], [58, 59], [59, 61], [61, 62], [62, 63], [64, 71], [72, 78], [79, 87], [88, 89], [89, 92], [92, 93], [93, 94], [95, 106], [107, 113], [114, 120], [121, 122], [122, 125], [125, 126], [127, 128], [128, 137], [138, 140], [141, 151], [152, 158], [158, 159], [159, 160], [161, 169], [170, 175], [175, 176], [177, 183], [184, 192], [192, 193], [194, 197], [198, 202], [203, 209], [209, 210]]}
{"doc_key": "ai-dev-281", "ner": [[12, 14, "metrics"], [34, 36, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Then", "it", "is", "also", "possible", "to", "use", "these", "probabilities", ",", "evaluate", "the", "mean", "squared", "error", "(", "or", "other", "similar", "measure", ")", "between", "the", "probabilities", "and", "the", "actual", "values", ",", "and", "then", "combine", "this", "with", "the", "confusion", "matrix", "to", "create", "very", "efficient", "fitness", "functions", "for", "logistic", "regression", "."], "sentence-detokenized": "Then it is also possible to use these probabilities, evaluate the mean squared error (or other similar measure) between the probabilities and the actual values, and then combine this with the confusion matrix to create very efficient fitness functions for logistic regression.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 15], [16, 24], [25, 27], [28, 31], [32, 37], [38, 51], [51, 52], [53, 61], [62, 65], [66, 70], [71, 78], [79, 84], [85, 86], [86, 88], [89, 94], [95, 102], [103, 110], [110, 111], [112, 119], [120, 123], [124, 137], [138, 141], [142, 145], [146, 152], [153, 159], [159, 160], [161, 164], [165, 169], [170, 177], [178, 182], [183, 187], [188, 191], [192, 201], [202, 208], [209, 211], [212, 218], [219, 223], [224, 233], [234, 241], [242, 251], [252, 255], [256, 264], [265, 275], [275, 276]]}
{"doc_key": "ai-dev-282", "ner": [[0, 0, "product"], [4, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VoiceOver", "first", "appeared", "in", "Mac", "OS", "X", "Tiger", "(", "10.4", ")", "in", "2005", "."], "sentence-detokenized": "VoiceOver first appeared in Mac OS X Tiger (10.4) in 2005.", "token2charspan": [[0, 9], [10, 15], [16, 24], [25, 27], [28, 31], [32, 34], [35, 36], [37, 42], [43, 44], [44, 48], [48, 49], [50, 52], [53, 57], [57, 58]]}
{"doc_key": "ai-dev-283", "ner": [[11, 14, "algorithm"], [18, 19, "misc"], [22, 23, "metrics"], [25, 27, "algorithm"], [57, 60, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 14, 18, 19, "related-to", "applied_to", false, false], [22, 23, 18, 19, "type-of", "", false, false], [22, 23, 25, 27, "related-to", "used_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "practice", ",", "machine", "learning", "algorithms", "respond", "either", "by", "employing", "a", "convex", "approximation", "to", "the", "0", "-", "1", "loss", "function", "(", "e.g.", "hinge", "loss", "for", "support", "vector", "machines", ")", ",", "which", "is", "easier", "to", "optimise", ",", "or", "by", "imposing", "assumptions", "on", "the", "distribution", "mathP", "(", "x", ",", "y", ")", "/", "math", "(", "thus", "no", "longer", "being", "the", "agnostic", "learning", "algorithm", "to", "which", "the", "above", "results", "apply", ")", "."], "sentence-detokenized": "In practice, machine learning algorithms respond either by employing a convex approximation to the 0-1 loss function (e.g. hinge loss for support vector machines), which is easier to optimise, or by imposing assumptions on the distribution mathP(x, y)/math (thus no longer being the agnostic learning algorithm to which the above results apply).", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 20], [21, 29], [30, 40], [41, 48], [49, 55], [56, 58], [59, 68], [69, 70], [71, 77], [78, 91], [92, 94], [95, 98], [99, 100], [100, 101], [101, 102], [103, 107], [108, 116], [117, 118], [118, 122], [123, 128], [129, 133], [134, 137], [138, 145], [146, 152], [153, 161], [161, 162], [162, 163], [164, 169], [170, 172], [173, 179], [180, 182], [183, 191], [191, 192], [193, 195], [196, 198], [199, 207], [208, 219], [220, 222], [223, 226], [227, 239], [240, 245], [245, 246], [246, 247], [247, 248], [249, 250], [250, 251], [251, 252], [252, 256], [257, 258], [258, 262], [263, 265], [266, 272], [273, 278], [279, 282], [283, 291], [292, 300], [301, 310], [311, 313], [314, 319], [320, 323], [324, 329], [330, 337], [338, 343], [343, 344], [344, 345]]}
{"doc_key": "ai-dev-284", "ner": [[0, 0, "misc"], [10, 13, "field"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 13, "usage", "", false, false], [0, 0, 20, 20, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Westworld", "(", "1973", ")", "was", "the", "first", "film", "to", "use", "digital", "image", "processing", "techniques", "to", "simulate", "the", "perspective", "of", "a", "robot", "."], "sentence-detokenized": "Westworld (1973) was the first film to use digital image processing techniques to simulate the perspective of a robot.", "token2charspan": [[0, 9], [10, 11], [11, 15], [15, 16], [17, 20], [21, 24], [25, 30], [31, 35], [36, 38], [39, 42], [43, 50], [51, 56], [57, 67], [68, 78], [79, 81], [82, 90], [91, 94], [95, 106], [107, 109], [110, 111], [112, 117], [117, 118]]}
{"doc_key": "ai-dev-285", "ner": [[7, 8, "task"], [10, 11, "task"], [13, 13, "task"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "now", "also", "commonly", "used", "for", "speech", "recognition", ",", "speech", "synthesis", ",", "diarisation", ",", "Xavier", "Anguera", "and", "others", "."], "sentence-detokenized": "It is now also commonly used for speech recognition, speech synthesis, diarisation, Xavier Anguera and others.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 14], [15, 23], [24, 28], [29, 32], [33, 39], [40, 51], [51, 52], [53, 59], [60, 69], [69, 70], [71, 82], [82, 83], [84, 90], [91, 98], [99, 102], [103, 109], [109, 110]]}
{"doc_key": "ai-dev-286", "ner": [[9, 13, "algorithm"], [18, 19, "algorithm"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 19, 9, 13, "type-of", "", false, false], [22, 24, 9, 13, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Here", ",", "math", "/", "sigma", "/", "math", "is", "an", "element", "-", "wise", "activation", "function", ",", "such", "as", "a", "sigmoid", "function", "or", "a", "rectified", "linear", "unit", "."], "sentence-detokenized": "Here, math/sigma/math is an element-wise activation function, such as a sigmoid function or a rectified linear unit.", "token2charspan": [[0, 4], [4, 5], [6, 10], [10, 11], [11, 16], [16, 17], [17, 21], [22, 24], [25, 27], [28, 35], [35, 36], [36, 40], [41, 51], [52, 60], [60, 61], [62, 66], [67, 69], [70, 71], [72, 79], [80, 88], [89, 91], [92, 93], [94, 103], [104, 110], [111, 115], [115, 116]]}
{"doc_key": "ai-dev-287", "ner": [[11, 13, "algorithm"], [21, 21, "misc"], [23, 23, "misc"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "speech", "-", "based", "approaches", "(", "i.e.", "all", "models", "based", "on", "Hidden", "Markov", "Models", ")", "require", "separate", "components", "and", "training", "for", "articulation", ",", "acoustic", "and", "language", "models", "."], "sentence-detokenized": "Traditional speech-based approaches (i.e. all models based on Hidden Markov Models) require separate components and training for articulation, acoustic and language models.", "token2charspan": [[0, 11], [12, 18], [18, 19], [19, 24], [25, 35], [36, 37], [37, 41], [42, 45], [46, 52], [53, 58], [59, 61], [62, 68], [69, 75], [76, 82], [82, 83], [84, 91], [92, 100], [101, 111], [112, 115], [116, 124], [125, 128], [129, 141], [141, 142], [143, 151], [152, 155], [156, 164], [165, 171], [171, 172]]}
{"doc_key": "ai-dev-288", "ner": [[0, 4, "algorithm"], [7, 8, "field"], [10, 12, "field"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 4, 13, 14, "related-to", "used_for", false, false], [7, 8, 0, 4, "usage", "", false, false], [10, 12, 0, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Roberts", "Cross", "operator", "is", "used", "in", "image", "processing", "and", "computer", "vision", "for", "edge", "detection", "."], "sentence-detokenized": "The Roberts Cross operator is used in image processing and computer vision for edge detection.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 37], [38, 43], [44, 54], [55, 58], [59, 67], [68, 74], [75, 78], [79, 83], [84, 93], [93, 94]]}
{"doc_key": "ai-dev-289", "ner": [[3, 3, "metrics"], [0, 0, "metrics"], [26, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 26, 26, "opposite", "", false, false], [0, 0, 26, 26, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "values", "for", "sensitivity", "and", "specificity", "are", "independent", "of", "the", "percentage", "of", "positive", "cases", "in", "the", "population", "of", "interest", "(", "relative", "to", ",", "for", "example", ",", "precision", ")", "."], "sentence-detokenized": "The values for sensitivity and specificity are independent of the percentage of positive cases in the population of interest (relative to, for example, precision).", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 26], [27, 30], [31, 42], [43, 46], [47, 58], [59, 61], [62, 65], [66, 76], [77, 79], [80, 88], [89, 94], [95, 97], [98, 101], [102, 112], [113, 115], [116, 124], [125, 126], [126, 134], [135, 137], [137, 138], [139, 142], [143, 150], [150, 151], [152, 161], [161, 162], [162, 163]]}
{"doc_key": "ai-dev-290", "ner": [[2, 4, "algorithm"], [19, 19, "misc"], [8, 13, "researcher"], [15, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 19, 2, 4, "topic", "", false, false], [19, 19, 8, 13, "artifact", "", false, false], [19, 19, 15, 15, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["However", ",", "the", "perceptron", "model", "became", "very", "unpopular", "with", "the", "publication", "of", "Marvin", "Minsky", "and", "Seymour", "Papert", "'s", "book", "Perceptron", "in", "1969", "."], "sentence-detokenized": "However, the perceptron model became very unpopular with the publication of Marvin Minsky and Seymour Papert's book Perceptron in 1969.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 23], [24, 29], [30, 36], [37, 41], [42, 51], [52, 56], [57, 60], [61, 72], [73, 75], [76, 82], [83, 89], [90, 93], [94, 101], [102, 108], [108, 110], [111, 115], [116, 126], [127, 129], [130, 134], [134, 135]]}
{"doc_key": "ai-dev-291", "ner": [[2, 4, "conference"], [8, 8, "organisation"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 4, 23, 24, "topic", "", false, false], [8, 8, 2, 4, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "annual", "Document", "Understanding", "Conference", ",", "organized", "by", "NIST", ",", "has", "developed", "sophisticated", "evaluation", "criteria", "for", "technologies", "that", "take", "on", "the", "challenge", "of", "multi-document", "summarization", "."], "sentence-detokenized": "The annual Document Understanding Conference, organized by NIST, has developed sophisticated evaluation criteria for technologies that take on the challenge of multi-document summarization.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 33], [34, 44], [44, 45], [46, 55], [56, 58], [59, 63], [63, 64], [65, 68], [69, 78], [79, 92], [93, 103], [104, 112], [113, 116], [117, 129], [130, 134], [135, 139], [140, 142], [143, 146], [147, 156], [157, 159], [160, 174], [175, 188], [188, 189]]}
{"doc_key": "ai-dev-292", "ner": [[6, 8, "product"], [0, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 0, 4, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "contrast", "to", "tandem", "manipulators", ",", "parallel", "manipulators", "are", "designed", "so", "that", "each", "chain", "is", "usually", "short", "and", "simple", "and", "can", "therefore", "be", "somewhat", "rigid", "for", "unwanted", "movements", "."], "sentence-detokenized": "In contrast to tandem manipulators, parallel manipulators are designed so that each chain is usually short and simple and can therefore be somewhat rigid for unwanted movements.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 21], [22, 34], [34, 35], [36, 44], [45, 57], [58, 61], [62, 70], [71, 73], [74, 78], [79, 83], [84, 89], [90, 92], [93, 100], [101, 106], [107, 110], [111, 117], [118, 121], [122, 125], [126, 135], [136, 138], [139, 147], [148, 153], [154, 157], [158, 166], [167, 176], [176, 177]]}
{"doc_key": "ai-dev-293", "ner": [[25, 25, "misc"], [27, 30, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "robot", "is", "something", "that", "makes", "a", "robot", "move", ".", "The", "design", "of", "these", "systems", "can", "be", "divided", "into", "several", "common", "types", ",", "such", "as", "SCARA", "and", "soft", "axis", "co-ordinate", "robots", ",", "which", "use", "different", "co-ordinate", "systems", "to", "command", "the", "machine", "'s", "arm", "."], "sentence-detokenized": "A robot is something that makes a robot move. The design of these systems can be divided into several common types, such as SCARA and soft axis co-ordinate robots, which use different co-ordinate systems to command the machine's arm.", "token2charspan": [[0, 1], [2, 7], [8, 10], [11, 20], [21, 25], [26, 31], [32, 33], [34, 39], [40, 44], [44, 45], [46, 49], [50, 56], [57, 59], [60, 65], [66, 73], [74, 77], [78, 80], [81, 88], [89, 93], [94, 101], [102, 108], [109, 114], [114, 115], [116, 120], [121, 123], [124, 129], [130, 133], [134, 138], [139, 143], [144, 155], [156, 162], [162, 163], [164, 169], [170, 173], [174, 183], [184, 195], [196, 203], [204, 206], [207, 214], [215, 218], [219, 226], [226, 228], [229, 232], [232, 233]]}
{"doc_key": "ai-dev-294", "ner": [[1, 2, "country"], [8, 12, "organisation"], [14, 20, "organisation"], [23, 26, "organisation"], [29, 31, "organisation"], [33, 40, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 12, 1, 2, "physical", "", false, false], [14, 20, 1, 2, "physical", "", false, false], [23, 26, 1, 2, "physical", "", false, false], [29, 31, 1, 2, "physical", "", false, false], [33, 40, 1, 2, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "USA", "he", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Academy", "of", "Linguistics", ",", "the", "American", "Philosophical", "Society", "and", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In the USA he is a member of the National Academy of Sciences, the American Academy of Arts and Sciences, the American Academy of Linguistics, the American Philosophical Society and the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 13], [14, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 41], [42, 49], [50, 52], [53, 61], [61, 62], [63, 66], [67, 75], [76, 83], [84, 86], [87, 91], [92, 95], [96, 104], [104, 105], [106, 109], [110, 118], [119, 126], [127, 129], [130, 141], [141, 142], [143, 146], [147, 155], [156, 169], [170, 177], [178, 181], [182, 185], [186, 194], [195, 206], [207, 210], [211, 214], [215, 226], [227, 229], [230, 237], [237, 238]]}
{"doc_key": "ai-dev-295", "ner": [[8, 10, "algorithm"], [12, 14, "algorithm"], [19, 19, "algorithm"], [25, 26, "algorithm"], [31, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 10, 19, 19, "named", "", false, false], [12, 14, 8, 10, "named", "", false, false], [19, 19, 25, 26, "compare", "", false, false], [19, 19, 31, 32, "related-to", "performs", false, false], [25, 26, 31, 32, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["They", "made", "a", "splash", "with", "the", "popularity", "of", "support", "vector", "machines", "(", "SVMs", ")", "in", "the", "1990s", ",", "when", "SVMs", "were", "found", "to", "compete", "with", "neural", "networks", "on", "tasks", "such", "as", "handwriting", "recognition", "."], "sentence-detokenized": "They made a splash with the popularity of support vector machines (SVMs) in the 1990s, when SVMs were found to compete with neural networks on tasks such as handwriting recognition.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 18], [19, 23], [24, 27], [28, 38], [39, 41], [42, 49], [50, 56], [57, 65], [66, 67], [67, 71], [71, 72], [73, 75], [76, 79], [80, 85], [85, 86], [87, 91], [92, 96], [97, 101], [102, 107], [108, 110], [111, 118], [119, 123], [124, 130], [131, 139], [140, 142], [143, 148], [149, 153], [154, 156], [157, 168], [169, 180], [180, 181]]}
{"doc_key": "ai-dev-296", "ner": [[2, 3, "misc"], [10, 10, "misc"], [14, 17, "algorithm"], [25, 26, "misc"], [30, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 10, 10, "usage", "", false, false], [2, 3, 25, 26, "usage", "", false, false], [10, 10, 14, 17, "origin", "result_of_algorithm", false, false], [25, 26, 30, 31, "origin", "result_of_algorithm", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["An", "empirical", "whitening", "transformation", "can", "be", "obtained", "by", "estimating", "the", "covariance", "(", "e.g.", "by", "the", "maximum", "likelihood", "method", ")", "and", "subsequently", "constructing", "the", "corresponding", "estimated", "whitening", "matrix", "(", "e.g.", "by", "Cholesky", "decomposition", ")", "."], "sentence-detokenized": "An empirical whitening transformation can be obtained by estimating the covariance (e.g. by the maximum likelihood method) and subsequently constructing the corresponding estimated whitening matrix (e.g. by Cholesky decomposition).", "token2charspan": [[0, 2], [3, 12], [13, 22], [23, 37], [38, 41], [42, 44], [45, 53], [54, 56], [57, 67], [68, 71], [72, 82], [83, 84], [84, 88], [89, 91], [92, 95], [96, 103], [104, 114], [115, 121], [121, 122], [123, 126], [127, 139], [140, 152], [153, 156], [157, 170], [171, 180], [181, 190], [191, 197], [198, 199], [199, 203], [204, 206], [207, 215], [216, 229], [229, 230], [230, 231]]}
{"doc_key": "ai-dev-297", "ner": [[0, 2, "organisation"], [8, 10, "product"], [21, 22, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 0, 2, "artifact", "", false, false], [21, 22, 0, 2, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["IAI", "is", "the", "world", "'s", "largest", "manufacturer", "of", "Cartesian", "Coordinate", "Robots", "and", "the", "established", "leader", "in", "low", "cost", ",", "high", "performance", "SCARA", "robots", "."], "sentence-detokenized": "IAI is the world's largest manufacturer of Cartesian Coordinate Robots and the established leader in low cost, high performance SCARA robots.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [16, 18], [19, 26], [27, 39], [40, 42], [43, 52], [53, 63], [64, 70], [71, 74], [75, 78], [79, 90], [91, 97], [98, 100], [101, 104], [105, 109], [109, 110], [111, 115], [116, 127], [128, 133], [134, 140], [140, 141]]}
{"doc_key": "ai-dev-298", "ner": [[9, 10, "field"], [12, 13, "field"], [15, 16, "field"], [18, 19, "field"], [21, 23, "field"], [25, 26, "field"], [28, 28, "field"], [30, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["Formal", "concept", "analysis", "has", "practical", "applications", "in", "areas", "including", "data", "mining", ",", "text", "mining", ",", "machine", "learning", ",", "knowledge", "management", ",", "the", "Semantic", "Web", ",", "software", "development", ",", "chemistry", "and", "biology", "."], "sentence-detokenized": "Formal concept analysis has practical applications in areas including data mining, text mining, machine learning, knowledge management, the Semantic Web, software development, chemistry and biology.", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 27], [28, 37], [38, 50], [51, 53], [54, 59], [60, 69], [70, 74], [75, 81], [81, 82], [83, 87], [88, 94], [94, 95], [96, 103], [104, 112], [112, 113], [114, 123], [124, 134], [134, 135], [136, 139], [140, 148], [149, 152], [152, 153], [154, 162], [163, 174], [174, 175], [176, 185], [186, 189], [190, 197], [197, 198]]}
{"doc_key": "ai-dev-299", "ner": [[1, 2, "field"], [4, 6, "field"], [10, 11, "field"], [17, 18, "field"], [26, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 17, 18, "part-of", "", false, false], [4, 6, 26, 27, "topic", "", false, false], [10, 11, 4, 6, "named", "", false, false], [17, 18, 1, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", ",", "computational", "learning", "theory", "(", "or", "just", "learning", "theory", ")", "is", "a", "subfield", "of", "artificial", "intelligence", "devoted", "to", "the", "design", "and", "analysis", "of", "machine", "learning", "algorithms", "."], "sentence-detokenized": "In computer science, computational learning theory (or just learning theory) is a subfield of artificial intelligence devoted to the design and analysis of machine learning algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 34], [35, 43], [44, 50], [51, 52], [52, 54], [55, 59], [60, 68], [69, 75], [75, 76], [77, 79], [80, 81], [82, 90], [91, 93], [94, 104], [105, 117], [118, 125], [126, 128], [129, 132], [133, 139], [140, 143], [144, 152], [153, 155], [156, 163], [164, 172], [173, 183], [183, 184]]}
{"doc_key": "ai-dev-300", "ner": [[0, 1, "algorithm"], [3, 3, "algorithm"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 0, 1, "named", "", false, false], [10, 10, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Collaborative", "filtering", "(", "CF", ")", "is", "a", "technique", "used", "by", "recommender", "systems", "."], "sentence-detokenized": "Collaborative filtering (CF) is a technique used by recommender systems.", "token2charspan": [[0, 13], [14, 23], [24, 25], [25, 27], [27, 28], [29, 31], [32, 33], [34, 43], [44, 48], [49, 51], [52, 63], [64, 71], [71, 72]]}
{"doc_key": "ai-dev-301", "ner": [[0, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "false", "positive", "rate", "is", "the", "proportion", "of", "all", "negative", "results", "that", "still", "produce", "a", "positive", "result", ",", "i.e.", "the", "conditional", "probability", "of", "a", "positive", "test", "result", "in", "the", "presence", "of", "an", "event", "that", "is", "not", "present", "."], "sentence-detokenized": "The false positive rate is the proportion of all negative results that still produce a positive result, i.e. the conditional probability of a positive test result in the presence of an event that is not present.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 23], [24, 26], [27, 30], [31, 41], [42, 44], [45, 48], [49, 57], [58, 65], [66, 70], [71, 76], [77, 84], [85, 86], [87, 95], [96, 102], [102, 103], [104, 108], [109, 112], [113, 124], [125, 136], [137, 139], [140, 141], [142, 150], [151, 155], [156, 162], [163, 165], [166, 169], [170, 178], [179, 181], [182, 184], [185, 190], [191, 195], [196, 198], [199, 202], [203, 210], [210, 211]]}
{"doc_key": "ai-dev-302", "ner": [[1, 14, "misc"], [35, 36, "metrics"], [39, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 14, 35, 36, "topic", "", false, false], [1, 14, 39, 39, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "VLDB", "'", "8", ":", "Proceedings", "of", "the", "34th", "International", "Conference", "on", "Very", "Large", "Databases", ",", "pp.", "422--433", ".", "shows", "that", "given", "values", "of", "mathC", "/", "math", "and", "mathK", "/", "math", "usually", "imply", "relatively", "low", "accuracy", "of", "iteratively", "calculated", "SimRank", "scores", "."], "sentence-detokenized": "In VLDB '8: Proceedings of the 34th International Conference on Very Large Databases, pp. 422--433. shows that given values of mathC / math and mathK / math usually imply relatively low accuracy of iteratively calculated SimRank scores.", "token2charspan": [[0, 2], [3, 7], [8, 9], [9, 10], [10, 11], [12, 23], [24, 26], [27, 30], [31, 35], [36, 49], [50, 60], [61, 63], [64, 68], [69, 74], [75, 84], [84, 85], [86, 89], [90, 98], [98, 99], [100, 105], [106, 110], [111, 116], [117, 123], [124, 126], [127, 132], [133, 134], [135, 139], [140, 143], [144, 149], [150, 151], [152, 156], [157, 164], [165, 170], [171, 181], [182, 185], [186, 194], [195, 197], [198, 209], [210, 220], [221, 228], [229, 235], [235, 236]]}
{"doc_key": "ai-dev-303", "ner": [[0, 3, "misc"], [4, 4, "misc"], [13, 14, "person"], [16, 18, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 0, 3, "general-affiliation", "", false, false], [4, 4, 13, 14, "artifact", "", false, false], [4, 4, 16, 18, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "science", "fiction", "drama", "Sense8", "debuted", "in", "June", "2015", ",", "written", "and", "produced", "by", "Wachowski", "and", "J.", "Michael", "Straczynski", "."], "sentence-detokenized": "The science fiction drama Sense8 debuted in June 2015, written and produced by Wachowski and J. Michael Straczynski.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 25], [26, 32], [33, 40], [41, 43], [44, 48], [49, 53], [53, 54], [55, 62], [63, 66], [67, 75], [76, 78], [79, 88], [89, 92], [93, 95], [96, 103], [104, 115], [115, 116]]}
{"doc_key": "ai-dev-304", "ner": [[1, 1, "misc"], [7, 8, "product"], [26, 28, "misc"], [36, 36, "country"], [38, 38, "country"], [40, 40, "country"], [42, 42, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 1, 7, 8, "topic", "", false, false], [36, 36, 26, 28, "type-of", "", false, false], [38, 38, 26, 28, "type-of", "", false, false], [40, 40, 26, 28, "type-of", "", false, false], [42, 42, 26, 28, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Although", "Eurotra", "has", "never", "delivered", "a", "usable", "MT", "system", ",", "the", "project", "has", "had", "a", "profound", "long", "-", "term", "impact", "on", "the", "emerging", "language", "industry", "in", "European", "member", "states", ",", "particularly", "in", "southern", "countries", "such", "as", "Greece", ",", "Italy", ",", "Spain", "and", "Portugal", "."], "sentence-detokenized": "Although Eurotra has never delivered a usable MT system, the project has had a profound long-term impact on the emerging language industry in European member states, particularly in southern countries such as Greece, Italy, Spain and Portugal.", "token2charspan": [[0, 8], [9, 16], [17, 20], [21, 26], [27, 36], [37, 38], [39, 45], [46, 48], [49, 55], [55, 56], [57, 60], [61, 68], [69, 72], [73, 76], [77, 78], [79, 87], [88, 92], [92, 93], [93, 97], [98, 104], [105, 107], [108, 111], [112, 120], [121, 129], [130, 138], [139, 141], [142, 150], [151, 157], [158, 164], [164, 165], [166, 178], [179, 181], [182, 190], [191, 200], [201, 205], [206, 208], [209, 215], [215, 216], [217, 222], [222, 223], [224, 229], [230, 233], [234, 242], [242, 243]]}
{"doc_key": "ai-dev-305", "ner": [[0, 0, "algorithm"], [6, 7, "task"], [18, 20, "task"], [22, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 7, 0, 0, "usage", "", true, false], [18, 20, 6, 7, "named", "", false, false], [22, 22, 18, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autoencoders", "have", "been", "successfully", "applied", "to", "machine", "translation", "of", "human", "languages", ",", "which", "is", "often", "referred", "to", "as", "neural", "machine", "translation", "(", "NMT", ")", "."], "sentence-detokenized": "Autoencoders have been successfully applied to machine translation of human languages, which is often referred to as neural machine translation (NMT).", "token2charspan": [[0, 12], [13, 17], [18, 22], [23, 35], [36, 43], [44, 46], [47, 54], [55, 66], [67, 69], [70, 75], [76, 85], [85, 86], [87, 92], [93, 95], [96, 101], [102, 110], [111, 113], [114, 116], [117, 123], [124, 131], [132, 143], [144, 145], [145, 148], [148, 149], [149, 150]]}
{"doc_key": "ai-dev-306", "ner": [[9, 11, "metrics"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Popular", "examples", "of", "probability", "-", "based", "fitness", "functions", "include", "maximum", "likelihood", "estimation", "and", "hinge", "loss", "."], "sentence-detokenized": "Popular examples of probability-based fitness functions include maximum likelihood estimation and hinge loss.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 31], [31, 32], [32, 37], [38, 45], [46, 55], [56, 63], [64, 71], [72, 82], [83, 93], [94, 97], [98, 103], [104, 108], [108, 109]]}
{"doc_key": "ai-dev-307", "ner": [[0, 1, "field"], [11, 13, "task"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 13, 0, 1, "part-of", "", false, false], [15, 16, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Data", "mining", "is", "a", "related", "area", "of", "research", "that", "focuses", "on", "exploratory", "data", "analysis", "through", "unsupervised", "learning", "."], "sentence-detokenized": "Data mining is a related area of research that focuses on exploratory data analysis through unsupervised learning.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 16], [17, 24], [25, 29], [30, 32], [33, 41], [42, 46], [47, 54], [55, 57], [58, 69], [70, 74], [75, 83], [84, 91], [92, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-dev-308", "ner": [[0, 1, "algorithm"], [13, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 13, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "filtering", "consists", "of", "techniques", "for", "matching", "people", "with", "similar", "interests", "and", "building", "recommendation", "systems", "based", "on", "them", "."], "sentence-detokenized": "Collaborative filtering consists of techniques for matching people with similar interests and building recommendation systems based on them.", "token2charspan": [[0, 13], [14, 23], [24, 32], [33, 35], [36, 46], [47, 50], [51, 59], [60, 66], [67, 71], [72, 79], [80, 89], [90, 93], [94, 102], [103, 117], [118, 125], [126, 131], [132, 134], [135, 139], [139, 140]]}
{"doc_key": "ai-dev-309", "ner": [[1, 7, "algorithm"], [11, 11, "programlang"], [14, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 16, 1, 7, "type-of", "", false, false], [14, 16, 11, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Some", "WordNet", "-", "based", "lexical", "similarity", "algorithms", "are", "implemented", "in", "a", "Perl", "package", "called", "WordNet", "::", "Similarity", "."], "sentence-detokenized": "Some WordNet-based lexical similarity algorithms are implemented in a Perl package called WordNet::Similarity.", "token2charspan": [[0, 4], [5, 12], [12, 13], [13, 18], [19, 26], [27, 37], [38, 48], [49, 52], [53, 64], [65, 67], [68, 69], [70, 74], [75, 82], [83, 89], [90, 97], [97, 99], [99, 109], [109, 110]]}
{"doc_key": "ai-dev-310", "ner": [[13, 13, "conference"], [15, 16, "conference"], [4, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 16, 13, 13, "named", "", false, false], [4, 5, 13, 13, "temporal", "", false, false], [7, 8, 13, 13, "temporal", "", false, false], [10, 11, 13, 13, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Another", "paper", "presented", "by", "Erik", "Miller", ",", "Nicholas", "Matsakis", "and", "Paul", "Viola", "at", "CVPR", "(", "CVPR", "2000", ")", "will", "also", "be", "discussed", "."], "sentence-detokenized": "Another paper presented by Erik Miller, Nicholas Matsakis and Paul Viola at CVPR (CVPR 2000) will also be discussed.", "token2charspan": [[0, 7], [8, 13], [14, 23], [24, 26], [27, 31], [32, 38], [38, 39], [40, 48], [49, 57], [58, 61], [62, 66], [67, 72], [73, 75], [76, 80], [81, 82], [82, 86], [87, 91], [91, 92], [93, 97], [98, 102], [103, 105], [106, 115], [115, 116]]}
{"doc_key": "ai-dev-311", "ner": [[8, 8, "algorithm"], [16, 17, "misc"], [4, 6, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 4, 6, "compare", "", false, false], [4, 6, 16, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["With", "the", "exception", "of", "the", "Jaccard", "index", ",", "QC", "has", "not", "been", "evaluated", "against", "traditional", "modern", "clustering", "algorithms", "."], "sentence-detokenized": "With the exception of the Jaccard index, QC has not been evaluated against traditional modern clustering algorithms.", "token2charspan": [[0, 4], [5, 8], [9, 18], [19, 21], [22, 25], [26, 33], [34, 39], [39, 40], [41, 43], [44, 47], [48, 51], [52, 56], [57, 66], [67, 74], [75, 86], [87, 93], [94, 104], [105, 115], [115, 116]]}
{"doc_key": "ai-dev-312", "ner": [[2, 5, "misc"], [8, 11, "misc"], [13, 15, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 2, 5, "physical", "", false, false], [8, 11, 13, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "the", "VEX", "Robotics", "World", "Championships", ",", "a", "national", "parade", "was", "held", "in", "the", "Freedom", "Hall", ",", "which", "included", "hundreds", "of", "students", "from", "more", "than", "30", "countries", "."], "sentence-detokenized": "During the VEX Robotics World Championships, a national parade was held in the Freedom Hall, which included hundreds of students from more than 30 countries.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 23], [24, 29], [30, 43], [43, 44], [45, 46], [47, 55], [56, 62], [63, 66], [67, 71], [72, 74], [75, 78], [79, 86], [87, 91], [91, 92], [93, 98], [99, 107], [108, 116], [117, 119], [120, 128], [129, 133], [134, 138], [139, 143], [144, 146], [147, 156], [156, 157]]}
{"doc_key": "ai-dev-313", "ner": [[6, 9, "metrics"], [11, 11, "metrics"], [15, 17, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 6, 9, "named", "", false, false], [19, 19, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Other", "measures", "of", "accuracy", "include", "the", "Single", "Word", "Error", "Rate", "(", "SWER", ")", "and", "the", "Command", "Success", "Rate", "(", "CSR", ")", "."], "sentence-detokenized": "Other measures of accuracy include the Single Word Error Rate (SWER) and the Command Success Rate (CSR).", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [27, 34], [35, 38], [39, 45], [46, 50], [51, 56], [57, 61], [62, 63], [63, 67], [67, 68], [69, 72], [73, 76], [77, 84], [85, 92], [93, 97], [98, 99], [99, 102], [102, 103], [103, 104]]}
{"doc_key": "ai-dev-314", "ner": [[7, 8, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "presented", "their", "methods", "and", "results", "at", "SIGGRAPH", "2000", "."], "sentence-detokenized": "They presented their methods and results at SIGGRAPH 2000.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 28], [29, 32], [33, 40], [41, 43], [44, 52], [53, 57], [57, 58]]}
{"doc_key": "ai-dev-315", "ner": [[0, 2, "conference"], [7, 7, "misc"], [9, 13, "misc"], [18, 19, "conference"], [25, 31, "researcher"], [39, 40, "researcher"], [44, 45, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 7, 7, "origin", "", false, false], [7, 7, 18, 19, "physical", "", false, false], [7, 7, 18, 19, "temporal", "", false, false], [7, 7, 25, 31, "origin", "", false, false], [7, 7, 39, 40, "origin", "", false, false], [9, 13, 7, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "KDD", "conference", "grew", "out", "of", "the", "KDD", "(", "Knowledge", "Discovery", "and", "Data", "Mining", ")", "workshops", "at", "the", "AAAI", "conferences", ",", "which", "were", "initiated", "by", "Gregory", "I", ".", "Piatetsky", "-", "Shapiro", "in", "1989", ",", "1991", "and", "1993", "and", "by", "Usama", "Fayyad", "in", "1994", ".", "Mechanics", "\uff5cACM", "."], "sentence-detokenized": "The KDD conference grew out of the KDD (Knowledge Discovery and Data Mining) workshops at the AAAI conferences, which were initiated by Gregory I. Piatetsky-Shapiro in 1989, 1991 and 1993 and by Usama Fayyad in 1994. Mechanics\uff5cACM.", "token2charspan": [[0, 3], [4, 7], [8, 18], [19, 23], [24, 27], [28, 30], [31, 34], [35, 38], [39, 40], [40, 49], [50, 59], [60, 63], [64, 68], [69, 75], [75, 76], [77, 86], [87, 89], [90, 93], [94, 98], [99, 110], [110, 111], [112, 117], [118, 122], [123, 132], [133, 135], [136, 143], [144, 145], [145, 146], [147, 156], [156, 157], [157, 164], [165, 167], [168, 172], [172, 173], [174, 178], [179, 182], [183, 187], [188, 191], [192, 194], [195, 200], [201, 207], [208, 210], [211, 215], [215, 216], [217, 226], [226, 230], [230, 231]]}
{"doc_key": "ai-dev-316", "ner": [[10, 11, "conference"], [13, 13, "conference"], [19, 22, "organisation"], [24, 24, "organisation"], [28, 32, "conference"], [34, 34, "conference"], [42, 44, "conference"], [46, 46, "conference"], [50, 66, "conference"], [58, 58, "conference"], [62, 69, "conference"], [71, 71, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[13, 13, 10, 11, "named", "", false, false], [24, 24, 19, 22, "named", "", false, false], [34, 34, 28, 32, "named", "", false, false], [46, 46, 42, 44, "named", "", false, false], [58, 58, 50, 66, "named", "", false, false], [71, 71, 62, 69, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["He", "has", "been", "elected", "to", "membership", "of", "the", "Association", "for", "Computing", "Machinery", "(", "ACM", ")", ",", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", ",", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", ",", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "(", "AAAS", ")", "and", "the", "Society", "for", "the", "Science", "of", "Optics", "and", "Photonics", "(", "SPIE", ")", "."], "sentence-detokenized": "He has been elected to membership of the Association for Computing Machinery (ACM), the Institute of Electrical and Electronics Engineers (IEEE), the International Association for Pattern Recognition (IAPR), the Association for the Advancement of Artificial Intelligence (AAAI), the American Association for the Advancement of Science (AAAS) and the Society for the Science of Optics and Photonics (SPIE).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 22], [23, 33], [34, 36], [37, 40], [41, 52], [53, 56], [57, 66], [67, 76], [77, 78], [78, 81], [81, 82], [82, 83], [84, 87], [88, 97], [98, 100], [101, 111], [112, 115], [116, 127], [128, 137], [138, 139], [139, 143], [143, 144], [144, 145], [146, 149], [150, 163], [164, 175], [176, 179], [180, 187], [188, 199], [200, 201], [201, 205], [205, 206], [206, 207], [208, 211], [212, 223], [224, 227], [228, 231], [232, 243], [244, 246], [247, 257], [258, 270], [271, 272], [272, 276], [276, 277], [277, 278], [279, 282], [283, 291], [292, 303], [304, 307], [308, 311], [312, 323], [324, 326], [327, 334], [335, 336], [336, 340], [340, 341], [342, 345], [346, 349], [350, 357], [358, 361], [362, 365], [366, 373], [374, 376], [377, 383], [384, 387], [388, 397], [398, 399], [399, 403], [403, 404], [404, 405]]}
{"doc_key": "ai-dev-317", "ner": [[0, 1, "field"], [3, 4, "field"], [16, 17, "field"], [32, 33, "field"], [52, 55, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 17, "named", "", false, false], [3, 4, 32, 33, "named", "", false, false], [32, 33, 52, 55, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "learning", "and", "data", "mining", "often", "use", "the", "same", "methods", "and", "have", "significant", "overlap", ",", "but", "machine", "learning", "focuses", "on", "prediction", ",", "based", "on", "known", "attributes", "learned", "from", "training", "data", ",", "while", "data", "mining", "focuses", "on", "discovering", "(", "previously", ")", "unknown", "attributes", "in", "the", "data", "(", "this", "is", "the", "analytical", "step", "of", "knowledge", "discovery", "in", "databases", ")", "."], "sentence-detokenized": "Machine learning and data mining often use the same methods and have significant overlap, but machine learning focuses on prediction, based on known attributes learned from training data, while data mining focuses on discovering (previously) unknown attributes in the data (this is the analytical step of knowledge discovery in databases).", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 25], [26, 32], [33, 38], [39, 42], [43, 46], [47, 51], [52, 59], [60, 63], [64, 68], [69, 80], [81, 88], [88, 89], [90, 93], [94, 101], [102, 110], [111, 118], [119, 121], [122, 132], [132, 133], [134, 139], [140, 142], [143, 148], [149, 159], [160, 167], [168, 172], [173, 181], [182, 186], [186, 187], [188, 193], [194, 198], [199, 205], [206, 213], [214, 216], [217, 228], [229, 230], [230, 240], [240, 241], [242, 249], [250, 260], [261, 263], [264, 267], [268, 272], [273, 274], [274, 278], [279, 281], [282, 285], [286, 296], [297, 301], [302, 304], [305, 314], [315, 324], [325, 327], [328, 337], [337, 338], [338, 339]]}
{"doc_key": "ai-dev-318", "ner": [[0, 0, "product"], [4, 4, "programlang"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "general-affiliation", "", false, false], [0, 0, 4, 4, "related-to", "runs_on", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Indy", "is", "written", "in", "Java", "and", "can", "therefore", "run", "on", "most", "modern", "operating", "systems", "."], "sentence-detokenized": "Indy is written in Java and can therefore run on most modern operating systems.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 23], [24, 27], [28, 31], [32, 41], [42, 45], [46, 48], [49, 53], [54, 60], [61, 70], [71, 78], [78, 79]]}
{"doc_key": "ai-dev-319", "ner": [[0, 1, "algorithm"], [5, 7, "algorithm"], [9, 9, "algorithm"], [14, 16, "algorithm"], [18, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 7, "type-of", "", true, false], [9, 9, 5, 7, "named", "", false, false], [14, 16, 5, 7, "type-of", "", true, false], [18, 18, 14, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["NMF", "is", "an", "instance", "of", "non-negative", "quadratic", "programming", "(", "NQP", ")", ",", "just", "like", "support", "vector", "machines", "(", "SVMs", ")", "."], "sentence-detokenized": "NMF is an instance of non-negative quadratic programming (NQP), just like support vector machines (SVMs).", "token2charspan": [[0, 3], [4, 6], [7, 9], [10, 18], [19, 21], [22, 34], [35, 44], [45, 56], [57, 58], [58, 61], [61, 62], [62, 63], [64, 68], [69, 73], [74, 81], [82, 88], [89, 97], [98, 99], [99, 103], [103, 104], [104, 105]]}
{"doc_key": "ai-dev-320", "ner": [[6, 7, "misc"], [10, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 10, 11, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["The", "method", "is", "based", "on", "estimating", "conditional", "probabilities", "using", "a", "non-parametric", "maximum", "likelihood", "method", ",", "which", "would", "result", "in"], "sentence-detokenized": "The method is based on estimating conditional probabilities using a non-parametric maximum likelihood method, which would result in", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 33], [34, 45], [46, 59], [60, 65], [66, 67], [68, 82], [83, 90], [91, 101], [102, 108], [108, 109], [110, 115], [116, 121], [122, 128], [129, 131]]}
{"doc_key": "ai-dev-321", "ner": [[8, 8, "algorithm"], [10, 12, "algorithm"], [14, 16, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "basic", "concepts", "involved", "in", "spectral", "estimation", "include", "autocorrelation", ",", "multidimensional", "Fourier", "transform", ",", "mean", "square", "error", "and", "entropy", "."], "sentence-detokenized": "The basic concepts involved in spectral estimation include autocorrelation, multidimensional Fourier transform, mean square error and entropy.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 27], [28, 30], [31, 39], [40, 50], [51, 58], [59, 74], [74, 75], [76, 92], [93, 100], [101, 110], [110, 111], [112, 116], [117, 123], [124, 129], [130, 133], [134, 141], [141, 142]]}
{"doc_key": "ai-dev-322", "ner": [[4, 6, "algorithm"], [10, 10, "field"], [12, 12, "algorithm"], [14, 16, "algorithm"], [18, 19, "task"], [21, 21, "field"], [23, 23, "field"], [25, 26, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[4, 6, 10, 10, "part-of", "", false, false], [4, 6, 12, 12, "part-of", "", false, false], [4, 6, 14, 16, "part-of", "", false, false], [4, 6, 18, 19, "part-of", "", false, false], [4, 6, 21, 21, "part-of", "", false, false], [4, 6, 23, 23, "part-of", "", false, false], [4, 6, 25, 26, "part-of", "", false, false], [4, 6, 28, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "application", "areas", "of", "kernel", "methods", "are", "diverse", "and", "include", "geostatistics", ",", "kriging", ",", "inverse", "distance", "weighting", ",", "3D", "reconstruction", ",", "bioinformatics", ",", "chemoinformatics", ",", "information", "extraction", "and", "handwriting", "recognition", "."], "sentence-detokenized": "The application areas of kernel methods are diverse and include geostatistics, kriging, inverse distance weighting, 3D reconstruction, bioinformatics, chemoinformatics, information extraction and handwriting recognition.", "token2charspan": [[0, 3], [4, 15], [16, 21], [22, 24], [25, 31], [32, 39], [40, 43], [44, 51], [52, 55], [56, 63], [64, 77], [77, 78], [79, 86], [86, 87], [88, 95], [96, 104], [105, 114], [114, 115], [116, 118], [119, 133], [133, 134], [135, 149], [149, 150], [151, 167], [167, 168], [169, 180], [181, 191], [192, 195], [196, 207], [208, 219], [219, 220]]}
{"doc_key": "ai-dev-323", "ner": [[9, 9, "organisation"], [11, 15, "product"], [17, 17, "product"], [20, 27, "product"], [29, 29, "product"], [32, 33, "product"], [35, 37, "product"], [39, 41, "product"], [43, 45, "product"], [49, 50, "product"], [52, 64, "product"], [55, 61, "product"], [65, 66, "product"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[11, 15, 9, 9, "artifact", "", false, false], [11, 15, 32, 33, "compare", "", false, false], [11, 15, 35, 37, "compare", "", false, false], [11, 15, 39, 41, "compare", "", false, false], [11, 15, 43, 45, "compare", "", false, false], [11, 15, 49, 50, "compare", "", false, false], [11, 15, 52, 64, "compare", "", false, false], [11, 15, 55, 61, "compare", "", false, false], [11, 15, 65, 66, "compare", "", false, false], [17, 17, 11, 15, "named", "", false, false], [20, 27, 32, 33, "compare", "", false, false], [20, 27, 35, 37, "compare", "", false, false], [20, 27, 39, 41, "compare", "", false, false], [20, 27, 43, 45, "compare", "", false, false], [20, 27, 49, 50, "compare", "", false, false], [20, 27, 52, 64, "compare", "", false, false], [20, 27, 55, 61, "compare", "", false, false], [20, 27, 65, 66, "compare", "", false, false], [29, 29, 20, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19], "sentence": ["Robots", "can", "be", "autonomous", "or", "semi-autonomous", "and", "range", "from", "Honda", "'s", "Advanced", "Steps", "for", "Innovative", "Mobility", "(", "ASIMO", ")", "and", "TOSY", "'s", "TOSY", "ping", "-", "pong", "playing", "robot", "(", "TOPIO", ")", "to", "industrial", "robots", ",", "medical", "operating", "robots", ",", "patient", "assistance", "robots", ",", "dog", "therapy", "robots", ",", "collectively", "programmed", "swarm", "robots", ",", "drones", "such", "as", "General", "Atomics", "'", "MQ", "-", "1", "Predator", ",", "and", "even", "miniature", "nanobots", "."], "sentence-detokenized": "Robots can be autonomous or semi-autonomous and range from Honda's Advanced Steps for Innovative Mobility (ASIMO) and TOSY's TOSY ping-pong playing robot (TOPIO) to industrial robots, medical operating robots, patient assistance robots, dog therapy robots, collectively programmed swarm robots, drones such as General Atomics' MQ-1 Predator, and even miniature nanobots.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 24], [25, 27], [28, 43], [44, 47], [48, 53], [54, 58], [59, 64], [64, 66], [67, 75], [76, 81], [82, 85], [86, 96], [97, 105], [106, 107], [107, 112], [112, 113], [114, 117], [118, 122], [122, 124], [125, 129], [130, 134], [134, 135], [135, 139], [140, 147], [148, 153], [154, 155], [155, 160], [160, 161], [162, 164], [165, 175], [176, 182], [182, 183], [184, 191], [192, 201], [202, 208], [208, 209], [210, 217], [218, 228], [229, 235], [235, 236], [237, 240], [241, 248], [249, 255], [255, 256], [257, 269], [270, 280], [281, 286], [287, 293], [293, 294], [295, 301], [302, 306], [307, 309], [310, 317], [318, 325], [325, 326], [327, 329], [329, 330], [330, 331], [332, 340], [340, 341], [342, 345], [346, 350], [351, 360], [361, 369], [369, 370]]}
{"doc_key": "ai-dev-324", "ner": [[0, 0, "product"], [2, 3, "product"], [20, 27, "university"], [8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 8, 9, "artifact", "", false, false], [0, 0, 11, 12, "artifact", "", false, false], [0, 0, 14, 15, "artifact", "", false, false], [0, 0, 17, 18, "artifact", "", false, false], [2, 3, 8, 9, "artifact", "", false, false], [2, 3, 11, 12, "artifact", "", false, false], [2, 3, 14, 15, "artifact", "", false, false], [2, 3, 17, 18, "artifact", "", false, false], [8, 9, 20, 27, "physical", "", false, false], [11, 12, 20, 27, "physical", "", false, false], [14, 15, 20, 27, "physical", "", false, false], [17, 18, 20, 27, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Freddy", "and", "Freddy", "II", "are", "robots", "built", "by", "Pat", "Ambler", ",", "Robin", "Popstone", ",", "Austin", "Tate", "and", "Donald", "Mitch", "at", "the", "School", "of", "Informatics", ",", "University", "of", "Edinburgh", ",", "capable", "of", "assembling", "wooden", "blocks", "in", "a", "matter", "of", "hours", "."], "sentence-detokenized": "Freddy and Freddy II are robots built by Pat Ambler, Robin Popstone, Austin Tate and Donald Mitch at the School of Informatics, University of Edinburgh, capable of assembling wooden blocks in a matter of hours.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 20], [21, 24], [25, 31], [32, 37], [38, 40], [41, 44], [45, 51], [51, 52], [53, 58], [59, 67], [67, 68], [69, 75], [76, 80], [81, 84], [85, 91], [92, 97], [98, 100], [101, 104], [105, 111], [112, 114], [115, 126], [126, 127], [128, 138], [139, 141], [142, 151], [151, 152], [153, 160], [161, 163], [164, 174], [175, 181], [182, 188], [189, 191], [192, 193], [194, 200], [201, 203], [204, 209], [209, 210]]}
{"doc_key": "ai-dev-325", "ner": [[5, 7, "country"], [14, 15, "country"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "childhood", "was", "spent", "in", "Paris", ",", "France", ",", "where", "his", "parents", "emigrated", "from", "Lithuania", "in", "the", "early", "1920s", "."], "sentence-detokenized": "His childhood was spent in Paris, France, where his parents emigrated from Lithuania in the early 1920s.", "token2charspan": [[0, 3], [4, 13], [14, 17], [18, 23], [24, 26], [27, 32], [32, 33], [34, 40], [40, 41], [42, 47], [48, 51], [52, 59], [60, 69], [70, 74], [75, 84], [85, 87], [88, 91], [92, 97], [98, 103], [103, 104]]}
{"doc_key": "ai-dev-326", "ner": [[2, 3, "researcher"], [5, 9, "misc"], [10, 15, "organisation"], [16, 21, "university"], [28, 32, "university"], [33, 44, "university"], [46, 49, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 3, 5, 9, "role", "", false, false], [2, 3, 16, 21, "physical", "", false, false], [2, 3, 28, 32, "role", "", false, false], [2, 3, 33, 44, "role", "", false, false], [2, 3, 46, 49, "role", "", false, false], [5, 9, 10, 15, "part-of", "", false, false], [10, 15, 16, 21, "part-of", "", false, false], [33, 44, 28, 32, "part-of", "", false, false], [46, 49, 28, 32, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Previously", ",", "Dr.", "Paulos", "held", "the", "Cooper-", "Siegel", "Associate", "Professorship", "in", "the", "School", "of", "Computer", "Science", "at", "Carnegie", "Mellon", "University", ",", "where", "he", "was", "a", "faculty", "member", "of", "the", "Human", "-", "Computer", "Interaction", "Institute", "and", "served", "as", "a", "concierge", "faculty", "member", "in", "the", "Robotics", "Institute", "and", "the", "Entertainment", "Technology", "Center", "."], "sentence-detokenized": "Previously, Dr. Paulos held the Cooper-Siegel Associate Professorship in the School of Computer Science at Carnegie Mellon University, where he was a faculty member of the Human-Computer Interaction Institute and served as a concierge faculty member in the Robotics Institute and the Entertainment Technology Center.", "token2charspan": [[0, 10], [10, 11], [12, 15], [16, 22], [23, 27], [28, 31], [32, 39], [39, 45], [46, 55], [56, 69], [70, 72], [73, 76], [77, 83], [84, 86], [87, 95], [96, 103], [104, 106], [107, 115], [116, 122], [123, 133], [133, 134], [135, 140], [141, 143], [144, 147], [148, 149], [150, 157], [158, 164], [165, 167], [168, 171], [172, 177], [177, 178], [178, 186], [187, 198], [199, 208], [209, 212], [213, 219], [220, 222], [223, 224], [225, 234], [235, 242], [243, 249], [250, 252], [253, 256], [257, 265], [266, 275], [276, 279], [280, 283], [284, 297], [298, 308], [309, 315], [315, 316]]}
{"doc_key": "ai-dev-327", "ner": [[3, 4, "researcher"], [6, 7, "university"], [9, 11, "product"], [17, 23, "product"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 6, 7, "physical", "", false, false], [3, 4, 6, 7, "role", "", false, false], [9, 11, 3, 4, "artifact", "", false, false], [9, 11, 17, 23, "type-of", "", false, false], [9, 11, 25, 26, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1969", ",", "Victor", "Scheinman", "of", "Stanford", "University", "invented", "the", "Stanford", "Arm", ",", "an", "all", "-", "electric", "6", "-", "axis", "articulated", "robot", "designed", "to", "allow", "arm", "solutions", "."], "sentence-detokenized": "In 1969, Victor Scheinman of Stanford University invented the Stanford Arm, an all-electric 6-axis articulated robot designed to allow arm solutions.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 25], [26, 28], [29, 37], [38, 48], [49, 57], [58, 61], [62, 70], [71, 74], [74, 75], [76, 78], [79, 82], [82, 83], [83, 91], [92, 93], [93, 94], [94, 98], [99, 110], [111, 116], [117, 125], [126, 128], [129, 134], [135, 138], [139, 148], [148, 149]]}
{"doc_key": "ai-dev-328", "ner": [[5, 6, "product"], [17, 18, "field"], [20, 21, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 17, 18, "related-to", "", false, false], [5, 6, 20, 21, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "creation", "and", "implementation", "of", "chatbots", "is", "still", "a", "developing", "area", ",", "with", "a", "strong", "relationship", "to", "artificial", "intelligence", "and", "machine", "learning", ",", "so", "the", "solutions", "on", "offer", ",", "while", "having", "obvious", "advantages", ",", "have", "some", "important", "limitations", "in", "terms", "of", "functionality", "and", "use", "cases", "."], "sentence-detokenized": "The creation and implementation of chatbots is still a developing area, with a strong relationship to artificial intelligence and machine learning, so the solutions on offer, while having obvious advantages, have some important limitations in terms of functionality and use cases.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 31], [32, 34], [35, 43], [44, 46], [47, 52], [53, 54], [55, 65], [66, 70], [70, 71], [72, 76], [77, 78], [79, 85], [86, 98], [99, 101], [102, 112], [113, 125], [126, 129], [130, 137], [138, 146], [146, 147], [148, 150], [151, 154], [155, 164], [165, 167], [168, 173], [173, 174], [175, 180], [181, 187], [188, 195], [196, 206], [206, 207], [208, 212], [213, 217], [218, 227], [228, 239], [240, 242], [243, 248], [249, 251], [252, 265], [266, 269], [270, 273], [274, 279], [279, 280]]}
{"doc_key": "ai-dev-329", "ner": [[7, 9, "university"], [11, 13, "product"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 13, 7, 9, "part-of", "", true, false], [19, 20, 11, 13, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "terms", "of", "freely", "available", "resources", ",", "Carnegie", "Mellon", "University", "'s", "Sphinx", "toolkit", "is", "a", "starting", "point", "for", "learning", "speech", "recognition", "and", "starting", "to", "experiment", "."], "sentence-detokenized": "In terms of freely available resources, Carnegie Mellon University's Sphinx toolkit is a starting point for learning speech recognition and starting to experiment.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 18], [19, 28], [29, 38], [38, 39], [40, 48], [49, 55], [56, 66], [66, 68], [69, 75], [76, 83], [84, 86], [87, 88], [89, 97], [98, 103], [104, 107], [108, 116], [117, 123], [124, 135], [136, 139], [140, 148], [149, 151], [152, 162], [162, 163]]}
{"doc_key": "ai-dev-330", "ner": [[2, 4, "misc"], [13, 19, "misc"], [8, 21, "misc"], [26, 26, "university"], [31, 32, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[2, 4, 13, 19, "temporal", "", false, false], [8, 21, 13, 19, "named", "", false, false], [26, 26, 8, 21, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 3], "sentence": ["The", "official", "RoboCup", "competition", "was", "preceded", "by", "the", "(", "usually", "unrecognised", ")", "first", "International", "Micro", "Robot", "World", "Cup", "Soccer", "Tournament", "(", "MIROSOT", ")", ",", "organised", "by", "KAIST", "in", "Tae", "Sung", ",", "South", "Korea", ",", "in", "November", "1996", "."], "sentence-detokenized": "The official RoboCup competition was preceded by the (usually unrecognised) first International Micro Robot World Cup Soccer Tournament (MIROSOT), organised by KAIST in Tae Sung, South Korea, in November 1996.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 32], [33, 36], [37, 45], [46, 48], [49, 52], [53, 54], [54, 61], [62, 74], [74, 75], [76, 81], [82, 95], [96, 101], [102, 107], [108, 113], [114, 117], [118, 124], [125, 135], [136, 137], [137, 144], [144, 145], [145, 146], [147, 156], [157, 159], [160, 165], [166, 168], [169, 172], [173, 177], [177, 178], [179, 184], [185, 190], [190, 191], [192, 194], [195, 203], [204, 208], [208, 209]]}
{"doc_key": "ai-dev-331", "ner": [[5, 6, "metrics"], [23, 24, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", "to", "the", "standard", "hinge", "loss", "maths", "(", "1-", "yf", "(", "x", ")", ")", "_", "+", "/", "maths", ",", "there", "is", "a", "loss", "function", "math", "(", "-", "1", "|", "f", "(", "x", ")", "|", ")", "_", "+", "/", "maths", "that", "is", "introduced", "for", "unlabeled", "data", "by", "letting", "mathy", "=\\operatorname", "{", "sign", "}", "/", "maths", "{", "f", "(", "x", ")", "}", "/", "math", "."], "sentence-detokenized": "In addition to the standard hinge loss maths (1-yf (x))_ + / maths, there is a loss function math (-1 | f (x) |)_ + / maths that is introduced for unlabeled data by letting mathy =\\operatorname {sign} / maths {f (x)} / math.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 27], [28, 33], [34, 38], [39, 44], [45, 46], [46, 48], [48, 50], [51, 52], [52, 53], [53, 54], [54, 55], [55, 56], [57, 58], [59, 60], [61, 66], [66, 67], [68, 73], [74, 76], [77, 78], [79, 83], [84, 92], [93, 97], [98, 99], [99, 100], [100, 101], [102, 103], [104, 105], [106, 107], [107, 108], [108, 109], [110, 111], [111, 112], [112, 113], [114, 115], [116, 117], [118, 123], [124, 128], [129, 131], [132, 142], [143, 146], [147, 156], [157, 161], [162, 164], [165, 172], [173, 178], [179, 193], [194, 195], [195, 199], [199, 200], [201, 202], [203, 208], [209, 210], [210, 211], [212, 213], [213, 214], [214, 215], [215, 216], [217, 218], [219, 223], [223, 224]]}
{"doc_key": "ai-dev-332", "ner": [[4, 4, "misc"], [10, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 10, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "particular", ",", "the", "RLS", "was", "designed", "to", "minimise", "the", "mean", "squared", "error", "between", "the", "predicted", "and", "true", "labels", ",", "but", "in", "line", "with", "regularisation", "."], "sentence-detokenized": "In particular, the RLS was designed to minimise the mean squared error between the predicted and true labels, but in line with regularisation.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 22], [23, 26], [27, 35], [36, 38], [39, 47], [48, 51], [52, 56], [57, 64], [65, 70], [71, 78], [79, 82], [83, 92], [93, 96], [97, 101], [102, 108], [108, 109], [110, 113], [114, 116], [117, 121], [122, 126], [127, 141], [141, 142]]}
{"doc_key": "ai-dev-333", "ner": [[4, 6, "algorithm"], [8, 10, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 8, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Essentially", ",", "this", "combines", "maximum", "likelihood", "estimation", "and", "regularisation", "procedures", "in", "favour", "of", "simpler", "models", "rather", "than", "more", "complex", "ones", "."], "sentence-detokenized": "Essentially, this combines maximum likelihood estimation and regularisation procedures in favour of simpler models rather than more complex ones.", "token2charspan": [[0, 11], [11, 12], [13, 17], [18, 26], [27, 34], [35, 45], [46, 56], [57, 60], [61, 75], [76, 86], [87, 89], [90, 96], [97, 99], [100, 107], [108, 114], [115, 121], [122, 126], [127, 131], [132, 139], [140, 144], [144, 145]]}
{"doc_key": "ai-dev-334", "ner": [[20, 20, "metrics"], [30, 30, "metrics"], [32, 32, "metrics"], [34, 36, "misc"], [42, 46, "misc"], [12, 14, "algorithm"], [17, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[30, 30, 20, 20, "named", "", false, false], [32, 32, 20, 20, "named", "", false, false], [34, 36, 42, 46, "related-to", "", false, false], [34, 36, 12, 14, "related-to", "ratio", false, false], [12, 14, 17, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["(", "The", "probability", "of", "detection", "on", "the", "y", "-axis", "compared", "to", "the", "cumulative", "distribution", "function", "of", "the", "probability", "of", "false", "positives", "on", "the", "x-", "axis", "is", "also", "referred", "to", "as", "sensitivity", ",", "recall", "or", "probability", "of", "detection", ",", "i.e.", "the", "probability", "of", "detection", "against", "a", "discrimination", "threshold", ")", "."], "sentence-detokenized": "(The probability of detection on the y-axis compared to the cumulative distribution function of the probability of false positives on the x-axis is also referred to as sensitivity, recall or probability of detection, i.e. the probability of detection against a discrimination threshold).", "token2charspan": [[0, 1], [1, 4], [5, 16], [17, 19], [20, 29], [30, 32], [33, 36], [37, 38], [38, 43], [44, 52], [53, 55], [56, 59], [60, 70], [71, 83], [84, 92], [93, 95], [96, 99], [100, 111], [112, 114], [115, 120], [121, 130], [131, 133], [134, 137], [138, 140], [140, 144], [145, 147], [148, 152], [153, 161], [162, 164], [165, 167], [168, 179], [179, 180], [181, 187], [188, 190], [191, 202], [203, 205], [206, 215], [215, 216], [217, 221], [222, 225], [226, 237], [238, 240], [241, 250], [251, 258], [259, 260], [261, 275], [276, 285], [285, 286], [286, 287]]}
{"doc_key": "ai-dev-335", "ner": [[1, 1, "misc"], [3, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 1, 1, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "English", ",", "Word", "Net", "is", "an", "example", "of", "a", "semantic", "network", "."], "sentence-detokenized": "In English, WordNet is an example of a semantic network.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 16], [16, 19], [20, 22], [23, 25], [26, 33], [34, 36], [37, 38], [39, 47], [48, 55], [55, 56]]}
{"doc_key": "ai-dev-336", "ner": [[5, 10, "product"], [11, 18, "product"], [29, 33, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[29, 33, 5, 10, "usage", "", false, false], [29, 33, 11, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Long", "-", "term", "use", "of", "speech", "recognition", "software", "in", "combination", "with", "a", "word", "processor", "has", "been", "shown", "to", "be", "beneficial", "for", "short", "-", "term", "memory", "recovery", "in", "patients", "with", "AVM", "in", "the", "brain", "who", "have", "undergone", "resection", "therapy", "."], "sentence-detokenized": "Long-term use of speech recognition software in combination with a word processor has been shown to be beneficial for short-term memory recovery in patients with AVM in the brain who have undergone resection therapy.", "token2charspan": [[0, 4], [4, 5], [5, 9], [10, 13], [14, 16], [17, 23], [24, 35], [36, 44], [45, 47], [48, 59], [60, 64], [65, 66], [67, 71], [72, 81], [82, 85], [86, 90], [91, 96], [97, 99], [100, 102], [103, 113], [114, 117], [118, 123], [123, 124], [124, 128], [129, 135], [136, 144], [145, 147], [148, 156], [157, 161], [162, 165], [166, 168], [169, 172], [173, 178], [179, 182], [183, 187], [188, 197], [198, 207], [208, 215], [215, 216]]}
{"doc_key": "ai-dev-337", "ner": [[8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Its", "founding", "editors", "-", "in", "-", "chief", "were", "Ron", "Sun", ",", "Vasant", "Honavar", "and", "Gregg", "Oden", "(", "from", "1999", "to", "2014", ")", "."], "sentence-detokenized": "Its founding editors-in-chief were Ron Sun, Vasant Honavar and Gregg Oden (from 1999 to 2014).", "token2charspan": [[0, 3], [4, 12], [13, 20], [20, 21], [21, 23], [23, 24], [24, 29], [30, 34], [35, 38], [39, 42], [42, 43], [44, 50], [51, 58], [59, 62], [63, 68], [69, 73], [74, 75], [75, 79], [80, 84], [85, 87], [88, 92], [92, 93], [93, 94]]}
{"doc_key": "ai-dev-338", "ner": [[2, 4, "product"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 4, 14, 15, "opposite", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "contrast", "to", "serial", "manipulators", ",", "their", "\"", "parallel", "\"", "difference", "is", "that", "the", "end", "effector", "(", "or", "\"", "hand", "\"", ")", "of", "this", "linkage", "(", "or", "\"", "arm", "\"", ")", "is", "attached", "directly", "to", "it", "s", "base", "by", "a", "number", "(", "usually", "three", "or", "six", ")", "of", "independent", "linkages", "working", "simultaneously", "."], "sentence-detokenized": "In contrast to serial manipulators, their \"parallel\" difference is that the end effector (or \"hand\") of this linkage (or \"arm\") is attached directly to its base by a number (usually three or six) of independent linkages working simultaneously.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 21], [22, 34], [34, 35], [36, 41], [42, 43], [43, 51], [51, 52], [53, 63], [64, 66], [67, 71], [72, 75], [76, 79], [80, 88], [89, 90], [90, 92], [93, 94], [94, 98], [98, 99], [99, 100], [101, 103], [104, 108], [109, 116], [117, 118], [118, 120], [121, 122], [122, 125], [125, 126], [126, 127], [128, 130], [131, 139], [140, 148], [149, 151], [152, 154], [154, 155], [156, 160], [161, 163], [164, 165], [166, 172], [173, 174], [174, 181], [182, 187], [188, 190], [191, 194], [194, 195], [196, 198], [199, 210], [211, 219], [220, 227], [228, 242], [242, 243]]}
{"doc_key": "ai-dev-339", "ner": [[5, 6, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [24, 25, "researcher"], [28, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "thesis", "supervisor", "was", "Professor", "Cordell", "Green", "and", "his", "thesis", "/", "oral", "committee", "included", "Professors", "Edward", "Feigenbaum", ",", "Joshua", "Lederberg", ",", "Paul", "Cohen", ",", "Allen", "Newell", ",", "Herbert", "Simon", "Herbert", "Simon", "and", "other", "professors", "."], "sentence-detokenized": "His thesis supervisor was Professor Cordell Green and his thesis/oral committee included Professors Edward Feigenbaum, Joshua Lederberg, Paul Cohen, Allen Newell, Herbert Simon Herbert Simon and other professors.", "token2charspan": [[0, 3], [4, 10], [11, 21], [22, 25], [26, 35], [36, 43], [44, 49], [50, 53], [54, 57], [58, 64], [64, 65], [65, 69], [70, 79], [80, 88], [89, 99], [100, 106], [107, 117], [117, 118], [119, 125], [126, 135], [135, 136], [137, 141], [142, 147], [147, 148], [149, 154], [155, 161], [161, 162], [163, 170], [171, 176], [177, 184], [185, 190], [191, 194], [195, 200], [201, 211], [211, 212]]}
{"doc_key": "ai-dev-340", "ner": [[3, 5, "metrics"], [7, 8, "metrics"], [12, 14, "metrics"], [16, 18, "metrics"], [9, 23, "metrics"], [25, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "functions", "include", "mean", "squared", "error", ",", "mean", "square", "root", "error", ",", "mean", "absolute", "error", ",", "relative", "squared", "error", ",", "relative", "square", "root", "error", ",", "relative", "absolute", "error", ",", "and", "others", "."], "sentence-detokenized": "Such functions include mean squared error, mean square root error, mean absolute error, relative squared error, relative square root error, relative absolute error, and others.", "token2charspan": [[0, 4], [5, 14], [15, 22], [23, 27], [28, 35], [36, 41], [41, 42], [43, 47], [48, 54], [55, 59], [60, 65], [65, 66], [67, 71], [72, 80], [81, 86], [86, 87], [88, 96], [97, 104], [105, 110], [110, 111], [112, 120], [121, 127], [128, 132], [133, 138], [138, 139], [140, 148], [149, 157], [158, 163], [163, 164], [165, 168], [169, 175], [175, 176]]}
{"doc_key": "ai-dev-341", "ner": [[0, 4, "programlang"], [6, 6, "programlang"], [8, 10, "programlang"]], "ner_mapping_to_source": [0, 1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "bundles", "for", "Python", ",", "Java", "and", "MATLAB", "/", "OCTAVE", "."], "sentence-detokenized": "There are bundles for Python, Java and MATLAB/OCTAVE.", "token2charspan": [[0, 5], [6, 9], [10, 17], [18, 21], [22, 28], [28, 29], [30, 34], [35, 38], [39, 45], [45, 46], [46, 52], [52, 53]]}
{"doc_key": "ai-dev-342", "ner": [[3, 3, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "implementation", "in", "MATLAB", "can", "be", "found", "at", "the", "following", "website"], "sentence-detokenized": "The implementation in MATLAB can be found at the following website", "token2charspan": [[0, 3], [4, 18], [19, 21], [22, 28], [29, 32], [33, 35], [36, 41], [42, 44], [45, 48], [49, 58], [59, 66]]}
{"doc_key": "ai-dev-343", "ner": [[0, 1, "researcher"], [9, 10, "field"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 19, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 10, 0, 1, "origin", "", false, false], [9, 10, 13, 14, "origin", "", false, false], [9, 10, 16, 17, "origin", "", false, false], [9, 10, 19, 19, "origin", "", false, false], [9, 10, 22, 25, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["John", "McCarthy", "is", "one", "of", "the", "founding", "fathers", "of", "artificial", "intelligence", ",", "alongside", "Alan", "Turing", ",", "Marvin", "Minsky", ",", "Alan", "Newell", "and", "Herbert", "A", ".", "Simon", "."], "sentence-detokenized": "John McCarthy is one of the founding fathers of artificial intelligence, alongside Alan Turing, Marvin Minsky, Alan Newell and Herbert A. Simon.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 23], [24, 27], [28, 36], [37, 44], [45, 47], [48, 58], [59, 71], [71, 72], [73, 82], [83, 87], [88, 94], [94, 95], [96, 102], [103, 109], [109, 110], [111, 115], [116, 122], [123, 126], [127, 134], [135, 136], [136, 137], [138, 143], [143, 144]]}
{"doc_key": "ai-dev-344", "ner": [[10, 11, "product"], [18, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "parallel", "manipulator", "is", "a", "mechanical", "system", "that", "uses", "several", "serial", "manipulators", "to", "support", "a", "platform", ",", "or", "end-effector", "."], "sentence-detokenized": "A parallel manipulator is a mechanical system that uses several serial manipulators to support a platform, or end-effector.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 27], [28, 38], [39, 45], [46, 50], [51, 55], [56, 63], [64, 70], [71, 83], [84, 86], [87, 94], [95, 96], [97, 105], [105, 106], [107, 109], [110, 122], [122, 123]]}
{"doc_key": "ai-dev-345", "ner": [[0, 0, "product"], [3, 5, "task"], [8, 8, "product"], [11, 14, "product"], [25, 26, "misc"], [28, 29, "misc"], [31, 33, "misc"], [35, 36, "task"], [38, 41, "product"], [43, 44, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[8, 8, 0, 0, "part-of", "", false, false], [8, 8, 3, 5, "type-of", "", false, false], [11, 14, 8, 8, "named", "", false, false], [25, 26, 8, 8, "part-of", "", false, false], [28, 29, 8, 8, "part-of", "", false, false], [31, 33, 8, 8, "part-of", "", false, false], [35, 36, 8, 8, "part-of", "", false, false], [38, 41, 8, 8, "part-of", "", false, false], [43, 44, 8, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["GATE", "includes", "an", "information", "extraction", "system", "known", "as", "ANNIE", "(", "Nearly", "New", "Information", "Extraction", "System", ")", ",", "which", "is", "a", "set", "of", "modules", "consisting", "of", "a", "tagger", ",", "a", "gazetteer", ",", "a", "sentence", "segmenter", ",", "discourse", "tags", ",", "named", "entity", "recognition", "converters", "and", "coreference", "tags", "."], "sentence-detokenized": "GATE includes an information extraction system known as ANNIE (Nearly New Information Extraction System), which is a set of modules consisting of a tagger, a gazetteer, a sentence segmenter, discourse tags, named entity recognition converters and coreference tags.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 28], [29, 39], [40, 46], [47, 52], [53, 55], [56, 61], [62, 63], [63, 69], [70, 73], [74, 85], [86, 96], [97, 103], [103, 104], [104, 105], [106, 111], [112, 114], [115, 116], [117, 120], [121, 123], [124, 131], [132, 142], [143, 145], [146, 147], [148, 154], [154, 155], [156, 157], [158, 167], [167, 168], [169, 170], [171, 179], [180, 189], [189, 190], [191, 200], [201, 205], [205, 206], [207, 212], [213, 219], [220, 231], [232, 242], [243, 246], [247, 258], [259, 263], [263, 264]]}
{"doc_key": "ai-dev-346", "ner": [[3, 5, "university"], [23, 25, "country"], [16, 18, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "graduated", "from", "Moscow", "State", "University", "and", "in", "November", "1978", ",", "following", "the", "personal", "intervention", "of", "Senator", "Edward", "Kennedy", ",", "he", "went", "to", "the", "United", "States", "."], "sentence-detokenized": "He graduated from Moscow State University and in November 1978, following the personal intervention of Senator Edward Kennedy, he went to the United States.", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 24], [25, 30], [31, 41], [42, 45], [46, 48], [49, 57], [58, 62], [62, 63], [64, 73], [74, 77], [78, 86], [87, 99], [100, 102], [103, 110], [111, 117], [118, 125], [125, 126], [127, 129], [130, 134], [135, 137], [138, 141], [142, 148], [149, 155], [155, 156]]}
{"doc_key": "ai-dev-347", "ner": [[3, 7, "organisation"], [10, 15, "misc"], [19, 20, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 7, 10, 15, "win-defeat", "", false, false], [10, 15, 19, 20, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2017", ",", "the", "DeepMind", "AlphaGo", "team", "was", "awarded", "the", "inaugural", "IJCAI", "Marvin", "Minsky", "Medal", "for", "Outstanding", "Achievement", "in", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2017, the DeepMind AlphaGo team was awarded the inaugural IJCAI Marvin Minsky Medal for Outstanding Achievement in Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 21], [22, 29], [30, 34], [35, 38], [39, 46], [47, 50], [51, 60], [61, 66], [67, 73], [74, 80], [81, 86], [87, 90], [91, 102], [103, 114], [115, 117], [118, 128], [129, 141], [141, 142]]}
{"doc_key": "ai-dev-348", "ner": [[4, 5, "misc"], [12, 12, "misc"], [7, 11, "misc"], [21, 23, "misc"], [33, 33, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[4, 5, 12, 12, "related-to", "is_recorded_by", false, false], [12, 12, 7, 11, "cause-effect", "", false, false], [12, 12, 7, 11, "physical", "", false, false], [12, 12, 21, 23, "physical", "", false, false], [12, 12, 33, 33, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "ways", "of", "recording", "anomalous", "propagation", "are", "tropospheric", "irregularities", "caused", "by", "tropospheric", "scatterers", ",", "scattering", "caused", "by", "meteors", ",", "refraction", "in", "the", "ionised", "zone", "and", "in", "the", "ionosphere", ",", "and", "reflection", "from", "the", "ionosphere", "."], "sentence-detokenized": "Other ways of recording anomalous propagation are tropospheric irregularities caused by tropospheric scatterers, scattering caused by meteors, refraction in the ionised zone and in the ionosphere, and reflection from the ionosphere.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 23], [24, 33], [34, 45], [46, 49], [50, 62], [63, 77], [78, 84], [85, 87], [88, 100], [101, 111], [111, 112], [113, 123], [124, 130], [131, 133], [134, 141], [141, 142], [143, 153], [154, 156], [157, 160], [161, 168], [169, 173], [174, 177], [178, 180], [181, 184], [185, 195], [195, 196], [197, 200], [201, 211], [212, 216], [217, 220], [221, 231], [231, 232]]}
{"doc_key": "ai-dev-349", "ner": [[0, 2, "field"], [4, 4, "field"], [10, 10, "field"], [12, 13, "field"], [15, 16, "field"], [18, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 10, 10, "part-of", "", false, false], [0, 2, 12, 13, "part-of", "", false, false], [0, 2, 15, 16, "part-of", "", false, false], [0, 2, 18, 20, "part-of", "", false, false], [4, 4, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Natural", "Language", "Processing", "(", "NLP", ")", "is", "a", "subfield", "of", "linguistics", ",", "computer", "science", ",", "information", "engineering", "and", "artificial", "intelligence", "that", "deals", "with", "the", "interaction", "between", "computers", "and", "human", "(", "natural", ")", "language", ",", "and", "in", "particular", "how", "to", "program", "computers", "to", "process", "and", "analyse", "large", "amounts", "of", "natural", "language", "data", "."], "sentence-detokenized": "Natural Language Processing (NLP) is a subfield of linguistics, computer science, information engineering and artificial intelligence that deals with the interaction between computers and human (natural) language, and in particular how to program computers to process and analyse large amounts of natural language data.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 29], [29, 32], [32, 33], [34, 36], [37, 38], [39, 47], [48, 50], [51, 62], [62, 63], [64, 72], [73, 80], [80, 81], [82, 93], [94, 105], [106, 109], [110, 120], [121, 133], [134, 138], [139, 144], [145, 149], [150, 153], [154, 165], [166, 173], [174, 183], [184, 187], [188, 193], [194, 195], [195, 202], [202, 203], [204, 212], [212, 213], [214, 217], [218, 220], [221, 231], [232, 235], [236, 238], [239, 246], [247, 256], [257, 259], [260, 267], [268, 271], [272, 279], [280, 285], [286, 293], [294, 296], [297, 304], [305, 313], [314, 318], [318, 319]]}
{"doc_key": "ai-dev-350", "ner": [[9, 10, "organisation"], [12, 14, "organisation"], [16, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "active", "youth", "-", "led", "climate", "groups", "include", "the", "Extinction", "Rebellion", ",", "the", "Sunrise", "Movement", ",", "Sustainable", "America", ",", "and", "others", "working", "at", "the", "transnational", "and", "local", "levels", "."], "sentence-detokenized": "Other active youth-led climate groups include the Extinction Rebellion, the Sunrise Movement, Sustainable America, and others working at the transnational and local levels.", "token2charspan": [[0, 5], [6, 12], [13, 18], [18, 19], [19, 22], [23, 30], [31, 37], [38, 45], [46, 49], [50, 60], [61, 70], [70, 71], [72, 75], [76, 83], [84, 92], [92, 93], [94, 105], [106, 113], [113, 114], [115, 118], [119, 125], [126, 133], [134, 136], [137, 140], [141, 154], [155, 158], [159, 164], [165, 171], [171, 172]]}
