{"doc_key": "ai-test-1", "ner": [[5, 7, "algorithm"], [9, 10, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "generative", "model", "approaches", "include", "naive", "Bayesian", "classifiers", ",", "Gaussian", "mixture", "models", ",", "variational", "autoencoders", "and", "others", "."], "sentence-detokenized": "Typical generative model approaches include naive Bayesian classifiers, Gaussian mixture models, variational autoencoders and others.", "token2charspan": [[0, 7], [8, 18], [19, 24], [25, 35], [36, 43], [44, 49], [50, 58], [59, 70], [70, 71], [72, 80], [81, 88], [89, 95], [95, 96], [97, 108], [109, 121], [122, 125], [126, 132], [132, 133]]}
{"doc_key": "ai-test-2", "ner": [[6, 6, "organisation"], [12, 12, "conference"], [15, 20, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 12, 12, "role", "", false, false], [15, 20, 12, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Finally", ",", "every", "other", "year", ",", "ELRA", "organises", "a", "major", "conference", ",", "LREC", ",", "the", "International", "Language", "Resources", "and", "Evaluation", "Conference", "."], "sentence-detokenized": "Finally, every other year, ELRA organises a major conference, LREC, the International Language Resources and Evaluation Conference.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 20], [21, 25], [25, 26], [27, 31], [32, 41], [42, 43], [44, 49], [50, 60], [60, 61], [62, 66], [66, 67], [68, 71], [72, 85], [86, 94], [95, 104], [105, 108], [109, 119], [120, 130], [130, 131]]}
{"doc_key": "ai-test-3", "ner": [[7, 11, "algorithm"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "task", "is", "usually", "to", "derive", "a", "maximum", "likelihood", "estimate", "of", "the", "HMM", "parameters", "for", "a", "given", "output", "sequence", "."], "sentence-detokenized": "The task is usually to derive a maximum likelihood estimate of the HMM parameters for a given output sequence.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 19], [20, 22], [23, 29], [30, 31], [32, 39], [40, 50], [51, 59], [60, 62], [63, 66], [67, 70], [71, 81], [82, 85], [86, 87], [88, 93], [94, 100], [101, 109], [109, 110]]}
{"doc_key": "ai-test-4", "ner": [[4, 6, "algorithm"], [8, 9, "algorithm"]], "ner_mapping_to_source": [1, 2], "relations": [[4, 6, 8, 9, "compare", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Unlike", "neural", "networks", "and", "support", "vector", "machines", ",", "AdaBoost", "'s", "training", "process", "selects", "only", "those", "features", "that", "are", "known", "to", "improve", "the", "predictive", "power", "of", "the", "model", ",", "reducing", "dimensionality", "and", "potentially", "improving", "execution", "time", ",", "as", "irrelevant", "features", "do", "not", "need", "to", "be", "computed", "."], "sentence-detokenized": "Unlike neural networks and support vector machines, AdaBoost's training process selects only those features that are known to improve the predictive power of the model, reducing dimensionality and potentially improving execution time, as irrelevant features do not need to be computed.", "token2charspan": [[0, 6], [7, 13], [14, 22], [23, 26], [27, 34], [35, 41], [42, 50], [50, 51], [52, 60], [60, 62], [63, 71], [72, 79], [80, 87], [88, 92], [93, 98], [99, 107], [108, 112], [113, 116], [117, 122], [123, 125], [126, 133], [134, 137], [138, 148], [149, 154], [155, 157], [158, 161], [162, 167], [167, 168], [169, 177], [178, 192], [193, 196], [197, 208], [209, 218], [219, 228], [229, 233], [233, 234], [235, 237], [238, 248], [249, 257], [258, 260], [261, 264], [265, 269], [270, 272], [273, 275], [276, 284], [284, 285]]}
{"doc_key": "ai-test-5", "ner": [[0, 0, "misc"], [11, 13, "misc"], [14, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 13, "part-of", "", false, false], [11, 13, 14, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Tokens", "are", "one", "of", "the", "possible", "relations", "between", "verbs", "in", "the", "semantic", "network", "of", "the", "Word", "Net", "database", "."], "sentence-detokenized": "Tokens are one of the possible relations between verbs in the semantic network of the WordNet database.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 17], [18, 21], [22, 30], [31, 40], [41, 48], [49, 54], [55, 57], [58, 61], [62, 70], [71, 78], [79, 81], [82, 85], [86, 90], [90, 93], [94, 102], [102, 103]]}
{"doc_key": "ai-test-6", "ner": [[8, 10, "task"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 10, 12, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "framework", "language", "is", "a", "technique", "for", "the", "representation", "of", "knowledge", "in", "artificial", "intelligence", "."], "sentence-detokenized": "A framework language is a technique for the representation of knowledge in artificial intelligence.", "token2charspan": [[0, 1], [2, 11], [12, 20], [21, 23], [24, 25], [26, 35], [36, 39], [40, 43], [44, 58], [59, 61], [62, 71], [72, 74], [75, 85], [86, 98], [98, 99]]}
{"doc_key": "ai-test-7", "ner": [[0, 0, "metrics"], [4, 7, "metrics"], [9, 11, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 7, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "Bilingual", "evaluation", "understudy", "in", "calculating", "the", "simplicity", "penalty", ",", "as", "small", "changes", "in", "translation", "length", "have", "little", "effect", "on", "the", "total", "score", "."], "sentence-detokenized": "NIST also differs from Bilingual evaluation understudy in calculating the simplicity penalty, as small changes in translation length have little effect on the total score.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 32], [33, 43], [44, 54], [55, 57], [58, 69], [70, 73], [74, 84], [85, 92], [92, 93], [94, 96], [97, 102], [103, 110], [111, 113], [114, 125], [126, 132], [133, 137], [138, 144], [145, 151], [152, 154], [155, 158], [159, 164], [165, 170], [170, 171]]}
{"doc_key": "ai-test-8", "ner": [[21, 22, "algorithm"], [24, 27, "algorithm"], [30, 31, "field"], [38, 39, "algorithm"], [41, 43, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 22, 30, 31, "usage", "", false, false], [24, 27, 30, 31, "usage", "", false, false], [38, 39, 30, 31, "type-of", "", false, false], [41, 43, 30, 31, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "model", "is", "initially", "fitted", "on", "a", "training", "dataset", "and", "the", "model", "is", "trained", "on", "the", "training", "dataset", "(", "e.g.", "a", "neural", "net", "or", "a", "naive", "Bayesian", "classifier", ")", "using", "supervised", "learning", "methods", "such", "as", "optimization", "methods", "using", "gradient", "descent", "or", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The model is initially fitted on a training dataset and the model is trained on the training dataset (e.g. a neural net or a naive Bayesian classifier) using supervised learning methods such as optimization methods using gradient descent or stochastic gradient descent.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 22], [23, 29], [30, 32], [33, 34], [35, 43], [44, 51], [52, 55], [56, 59], [60, 65], [66, 68], [69, 76], [77, 79], [80, 83], [84, 92], [93, 100], [101, 102], [102, 106], [107, 108], [109, 115], [116, 119], [120, 122], [123, 124], [125, 130], [131, 139], [140, 150], [150, 151], [152, 157], [158, 168], [169, 177], [178, 185], [186, 190], [191, 193], [194, 206], [207, 214], [215, 220], [221, 229], [230, 237], [238, 240], [241, 251], [252, 260], [261, 268], [268, 269]]}
{"doc_key": "ai-test-9", "ner": [[0, 0, "product"], [8, 9, "task"], [11, 11, "task"], [13, 16, "task"], [18, 19, "task"], [26, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 0, "usage", "", true, false], [11, 11, 0, 0, "usage", "", true, false], [13, 16, 0, 0, "usage", "", true, false], [18, 19, 0, 0, "usage", "", true, false], [26, 27, 0, 0, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["FrameNet", "has", "been", "used", "in", "applications", "such", "as", "question", "answering", ",", "paraphrasing", ",", "identifying", "concatenation", "of", "text", "and", "information", "extraction", ",", "either", "directly", "or", "through", "semantic", "role", "labelling", "tools", "."], "sentence-detokenized": "FrameNet has been used in applications such as question answering, paraphrasing, identifying concatenation of text and information extraction, either directly or through semantic role labelling tools.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 22], [23, 25], [26, 38], [39, 43], [44, 46], [47, 55], [56, 65], [65, 66], [67, 79], [79, 80], [81, 92], [93, 106], [107, 109], [110, 114], [115, 118], [119, 130], [131, 141], [141, 142], [143, 149], [150, 158], [159, 161], [162, 169], [170, 178], [179, 183], [184, 193], [194, 199], [199, 200]]}
{"doc_key": "ai-test-10", "ner": [[6, 7, "field"], [12, 12, "misc"], [15, 15, "product"], [18, 18, "misc"], [21, 21, "product"], [24, 25, "field"], [28, 28, "product"], [31, 34, "misc"], [37, 37, "product"], [39, 39, "product"], [41, 41, "product"], [44, 45, "misc"], [48, 49, "product"], [51, 52, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[15, 15, 12, 12, "general-affiliation", "", false, false], [21, 21, 18, 18, "general-affiliation", "", false, false], [28, 28, 24, 25, "general-affiliation", "", false, false], [37, 37, 31, 34, "type-of", "", false, false], [39, 39, 31, 34, "type-of", "", false, false], [41, 41, 31, 34, "type-of", "", false, false], [48, 49, 44, 45, "general-affiliation", "", false, false], [51, 52, 44, 45, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["This", "will", "include", "programs", "such", "as", "data", "analysis", "and", "extraction", "tools", ",", "spreadsheets", "(", "e.g.", "Excel", ")", ",", "databases", "(", "e.g.", "Access", ")", ",", "statistical", "analysis", "(", "e.g.", "SAS", ")", ",", "general", "purpose", "auditing", "software", "(", "e.g.", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "business", "intelligence", "(", "e.g.", "Crystal", "Reports", "and", "Business", "Objects", ")", ",", "etc", "."], "sentence-detokenized": "This will include programs such as data analysis and extraction tools, spreadsheets (e.g. Excel), databases (e.g. Access), statistical analysis (e.g. SAS), general purpose auditing software (e.g. ACL, Arbutus, EAS), business intelligence (e.g. Crystal Reports and Business Objects), etc.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 26], [27, 31], [32, 34], [35, 39], [40, 48], [49, 52], [53, 63], [64, 69], [69, 70], [71, 83], [84, 85], [85, 89], [90, 95], [95, 96], [96, 97], [98, 107], [108, 109], [109, 113], [114, 120], [120, 121], [121, 122], [123, 134], [135, 143], [144, 145], [145, 149], [150, 153], [153, 154], [154, 155], [156, 163], [164, 171], [172, 180], [181, 189], [190, 191], [191, 195], [196, 199], [199, 200], [201, 208], [208, 209], [210, 213], [213, 214], [214, 215], [216, 224], [225, 237], [238, 239], [239, 243], [244, 251], [252, 259], [260, 263], [264, 272], [273, 280], [280, 281], [281, 282], [283, 286], [286, 287]]}
{"doc_key": "ai-test-11", "ner": [[0, 1, "organisation"], [5, 6, "researcher"], [10, 10, "organisation"], [13, 14, "product"], [20, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 6, "origin", "", false, false], [5, 6, 10, 10, "role", "", false, false], [13, 14, 20, 21, "type-of", "", false, false], [20, 21, 5, 6, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Rethink", "Robotics", "-", "founded", "by", "Rodney", "Brooks", ",", "formerly", "of", "iRobot", "-", "launched", "Baxter", "in", "September", "2012", ";", "as", "an", "industrial", "robot", "designed", "to", "interact", "safely", "with", "neighbouring", "human", "workers", "and", "can", "be", "programmed", "to", "perform", "simple", "tasks", "."], "sentence-detokenized": "Rethink Robotics - founded by Rodney Brooks, formerly of iRobot - launched Baxter in September 2012; as an industrial robot designed to interact safely with neighbouring human workers and can be programmed to perform simple tasks.", "token2charspan": [[0, 7], [8, 16], [17, 18], [19, 26], [27, 29], [30, 36], [37, 43], [43, 44], [45, 53], [54, 56], [57, 63], [64, 65], [66, 74], [75, 81], [82, 84], [85, 94], [95, 99], [99, 100], [101, 103], [104, 106], [107, 117], [118, 123], [124, 132], [133, 135], [136, 144], [145, 151], [152, 156], [157, 169], [170, 175], [176, 183], [184, 187], [188, 191], [192, 194], [195, 205], [206, 208], [209, 216], [217, 223], [224, 229], [229, 230]]}
{"doc_key": "ai-test-12", "ner": [[1, 2, "field"], [5, 6, "task"], [8, 9, "task"], [11, 14, "task"], [18, 19, "task"], [21, 22, "task"], [24, 25, "task"], [27, 29, "task"], [36, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 6, 1, 2, "part-of", "task_part_of_field", false, false], [8, 9, 1, 2, "part-of", "task_part_of_field", false, false], [11, 14, 1, 2, "part-of", "task_part_of_field", false, false], [18, 19, 1, 2, "part-of", "task_part_of_field", false, false], [21, 22, 1, 2, "part-of", "task_part_of_field", false, false], [24, 25, 1, 2, "part-of", "task_part_of_field", false, false], [27, 29, 1, 2, "part-of", "task_part_of_field", false, false], [36, 38, 1, 2, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Typical", "text", "mining", "tasks", "include", "text", "classification", ",", "text", "clustering", ",", "concept", "/", "entity", "extraction", ",", "refinement", "of", "taxonomy", "generation", ",", "sentiment", "analysis", ",", "document", "summarisation", "and", "entity", "relationship", "modelling", "(", "i.e.", "learning", "the", "relationships", "between", "named", "entity", "recognition", ")", "."], "sentence-detokenized": "Typical text mining tasks include text classification, text clustering, concept/entity extraction, refinement of taxonomy generation, sentiment analysis, document summarisation and entity relationship modelling (i.e. learning the relationships between named entity recognition).", "token2charspan": [[0, 7], [8, 12], [13, 19], [20, 25], [26, 33], [34, 38], [39, 53], [53, 54], [55, 59], [60, 70], [70, 71], [72, 79], [79, 80], [80, 86], [87, 97], [97, 98], [99, 109], [110, 112], [113, 121], [122, 132], [132, 133], [134, 143], [144, 152], [152, 153], [154, 162], [163, 176], [177, 180], [181, 187], [188, 200], [201, 210], [211, 212], [212, 216], [217, 225], [226, 229], [230, 243], [244, 251], [252, 257], [258, 264], [265, 276], [276, 277], [277, 278]]}
{"doc_key": "ai-test-13", "ner": [[10, 10, "metrics"], [13, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "for", "such", "a", "system", ",", "stemming", "reduces", "the", "accuracy", ",", "or", "true", "negation", "rate", "."], "sentence-detokenized": "However, for such a system, stemming reduces the accuracy, or true negation rate.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 17], [18, 19], [20, 26], [26, 27], [28, 36], [37, 44], [45, 48], [49, 57], [57, 58], [59, 61], [62, 66], [67, 75], [76, 80], [80, 81]]}
{"doc_key": "ai-test-14", "ner": [[4, 5, "task"], [7, 8, "misc"], [12, 13, "misc"], [25, 25, "product"], [27, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 4, 5, "temporal", "", false, false], [12, 13, 7, 8, "named", "", false, false], [25, 25, 7, 8, "usage", "", false, false], [27, 27, 7, 8, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "special", "case", "of", "keyword", "discovery", "is", "wake", "word", "(", "also", "called", "hot", "word", ")", "detection", ",", "used", "by", "personal", "digital", "assistants", "(", "such", "as", "Alexa", "or", "Siri", ")", "that", "wake", "up", "when", "their", "name", "is", "spoken", "."], "sentence-detokenized": "A special case of keyword discovery is wake word (also called hot word) detection, used by personal digital assistants (such as Alexa or Siri) that wake up when their name is spoken.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 17], [18, 25], [26, 35], [36, 38], [39, 43], [44, 48], [49, 50], [50, 54], [55, 61], [62, 65], [66, 70], [70, 71], [72, 81], [81, 82], [83, 87], [88, 90], [91, 99], [100, 107], [108, 118], [119, 120], [120, 124], [125, 127], [128, 133], [134, 136], [137, 141], [141, 142], [143, 147], [148, 152], [153, 155], [156, 160], [161, 166], [167, 171], [172, 174], [175, 181], [181, 182]]}
{"doc_key": "ai-test-15", "ner": [[0, 0, "programlang"], [9, 9, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 0, 0, "part-of", "", false, false], [11, 11, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "is", "an", "open", "source", "programming", "language", "that", "combines", "Prolog", "with", "Java", "."], "sentence-detokenized": "Prova is an open source programming language that combines Prolog with Java.", "token2charspan": [[0, 5], [6, 8], [9, 11], [12, 16], [17, 23], [24, 35], [36, 44], [45, 49], [50, 58], [59, 65], [66, 70], [71, 75], [75, 76]]}
{"doc_key": "ai-test-16", "ner": [[3, 4, "organisation"], [9, 10, "organisation"], [17, 19, "product"], [29, 33, "country"], [37, 37, "organisation"], [48, 48, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 9, 10, "part-of", "", false, false], [3, 4, 9, 10, "role", "sells", false, false], [3, 4, 29, 33, "role", "sells_to", false, false], [37, 37, 48, 48, "opposite", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "1987", ",", "Tocibai", "Machine", ",", "a", "subsidiary", "of", "Toshiba", "Corporation", ",", "was", "accused", "of", "illegally", "selling", "CNC", "milling", "cutters", "for", "the", "production", "of", "very", "quiet", "submarine", "propellers", "to", "the", "Soviet", "Union", ",", "in", "violation", "of", "the", "CoCom", "agreement", ",", "an", "international", "embargo", "imposed", "on", "certain", "countries", "against", "COMECON", "countries", "."], "sentence-detokenized": "In 1987, Tocibai Machine, a subsidiary of Toshiba Corporation, was accused of illegally selling CNC milling cutters for the production of very quiet submarine propellers to the Soviet Union, in violation of the CoCom agreement, an international embargo imposed on certain countries against COMECON countries.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 24], [24, 25], [26, 27], [28, 38], [39, 41], [42, 49], [50, 61], [61, 62], [63, 66], [67, 74], [75, 77], [78, 87], [88, 95], [96, 99], [100, 107], [108, 115], [116, 119], [120, 123], [124, 134], [135, 137], [138, 142], [143, 148], [149, 158], [159, 169], [170, 172], [173, 176], [177, 183], [184, 189], [189, 190], [191, 193], [194, 203], [204, 206], [207, 210], [211, 216], [217, 226], [226, 227], [228, 230], [231, 244], [245, 252], [253, 260], [261, 263], [264, 271], [272, 281], [282, 289], [290, 297], [298, 307], [307, 308]]}
{"doc_key": "ai-test-17", "ner": [[0, 0, "researcher"], [6, 10, "product"], [19, 23, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 10, 0, 0, "artifact", "", false, false], [6, 10, 19, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Engelberg", "'s", "most", "famous", "co-invention", ",", "the", "Unimate", "industrial", "robot", "arm", ",", "was", "one", "of", "the", "first", "inductees", "into", "the", "Robotics", "Hall", "of", "Fame", "in", "2003", "."], "sentence-detokenized": "Engelberg's most famous co-invention, the Unimate industrial robot arm, was one of the first inductees into the Robotics Hall of Fame in 2003.", "token2charspan": [[0, 9], [9, 11], [12, 16], [17, 23], [24, 36], [36, 37], [38, 41], [42, 49], [50, 60], [61, 66], [67, 70], [70, 71], [72, 75], [76, 79], [80, 82], [83, 86], [87, 92], [93, 102], [103, 107], [108, 111], [112, 120], [121, 125], [126, 128], [129, 133], [134, 136], [137, 141], [141, 142]]}
{"doc_key": "ai-test-18", "ner": [[7, 8, "misc"], [11, 13, "misc"], [0, 1, "person"], [20, 21, "field"], [17, 19, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 11, 13, "usage", "", false, false], [0, 1, 20, 21, "role", "", false, false], [20, 21, 17, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dalton", "'s", "work", "was", "initially", "controlled", "through", "static", "HTML", "pages", "using", "CGI", ",", "and", "he", "introduced", "a", "Java", "-", "based", "augmented", "reality", "interface", "with", "limited", "success", "."], "sentence-detokenized": "Dalton's work was initially controlled through static HTML pages using CGI, and he introduced a Java-based augmented reality interface with limited success.", "token2charspan": [[0, 6], [6, 8], [9, 13], [14, 17], [18, 27], [28, 38], [39, 46], [47, 53], [54, 58], [59, 64], [65, 70], [71, 74], [74, 75], [76, 79], [80, 82], [83, 93], [94, 95], [96, 100], [100, 101], [101, 106], [107, 116], [117, 124], [125, 134], [135, 139], [140, 147], [148, 155], [155, 156]]}
{"doc_key": "ai-test-19", "ner": [[6, 8, "task"], [15, 15, "organisation"], [31, 31, "conference"], [24, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 8, 15, 15, "origin", "", false, false], [31, 31, 24, 24, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "is", "the", "first", "publication", "on", "the", "LMF", "specification", "as", "it", "has", "been", "approved", "by", "ISO", "(", "this", "paper", "became", "the", "ninth", "most", "cited", "LREC", "paper", "within", "the", "(", "2015", ")", "LREC", "conference", ")", "."], "sentence-detokenized": "This is the first publication on the LMF specification as it has been approved by ISO (this paper became the ninth most cited LREC paper within the (2015) LREC conference).", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 17], [18, 29], [30, 32], [33, 36], [37, 40], [41, 54], [55, 57], [58, 60], [61, 64], [65, 69], [70, 78], [79, 81], [82, 85], [86, 87], [87, 91], [92, 97], [98, 104], [105, 108], [109, 114], [115, 119], [120, 125], [126, 130], [131, 136], [137, 143], [144, 147], [148, 149], [149, 153], [153, 154], [155, 159], [160, 170], [170, 171], [171, 172]]}
{"doc_key": "ai-test-20", "ner": [[0, 2, "metrics"], [15, 15, "metrics"], [17, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 15, 0, 2, "usage", "", false, false], [15, 15, 17, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "confusion", "matrix", "or", "matching", "matrix", "is", "often", "used", "as", "a", "tool", "to", "verify", "the", "accuracy", "of", "k", "-", "NN", "classification", "."], "sentence-detokenized": "The confusion matrix or matching matrix is often used as a tool to verify the accuracy of k-NN classification.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 23], [24, 32], [33, 39], [40, 42], [43, 48], [49, 53], [54, 56], [57, 58], [59, 63], [64, 66], [67, 73], [74, 77], [78, 86], [87, 89], [90, 91], [91, 92], [92, 94], [95, 109], [109, 110]]}
{"doc_key": "ai-test-21", "ner": [[0, 1, "algorithm"], [12, 12, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 12, "part-of", "", false, false], [0, 1, 14, 15, "part-of", "", false, false], [0, 1, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", "is", "one", "of", "the", "predictive", "modelling", "methods", "used", "in", "statistics", ",", "data", "mining", "and", "machine", "learning", "."], "sentence-detokenized": "Decision tree learning is one of the predictive modelling methods used in statistics, data mining and machine learning.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 47], [48, 57], [58, 65], [66, 70], [71, 73], [74, 84], [84, 85], [86, 90], [91, 97], [98, 101], [102, 109], [110, 118], [118, 119]]}
{"doc_key": "ai-test-22", "ner": [[5, 7, "misc"], [16, 17, "field"], [21, 23, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 7, 16, 17, "related-to", "", true, false], [21, 23, 16, 17, "type-of", "", false, false], [25, 25, 16, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["At", "runtime", ",", "the", "target", "notes", "of", "the", "sentence", "are", "superimposed", "on", "these", "minimal", "units", "by", "signal", "processing", "techniques", "such", "as", "linear", "predictive", "coding", ",", "PSOLA", "."], "sentence-detokenized": "At runtime, the target notes of the sentence are superimposed on these minimal units by signal processing techniques such as linear predictive coding, PSOLA.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 22], [23, 28], [29, 31], [32, 35], [36, 44], [45, 48], [49, 61], [62, 64], [65, 70], [71, 78], [79, 84], [85, 87], [88, 94], [95, 105], [106, 116], [117, 121], [122, 124], [125, 131], [132, 142], [143, 149], [149, 150], [151, 156], [156, 157]]}
{"doc_key": "ai-test-23", "ner": [[3, 4, "field"], [6, 11, "field"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 3, 4, "usage", "", true, false], [17, 18, 6, 11, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "approach", "uses", "artificial", "intelligence", "and", "machine", "learning", "to", "enable", "researchers", "to", "visually", "compare", "conventional", "and", "thermal", "facial", "images", "."], "sentence-detokenized": "This approach uses artificial intelligence and machine learning to enable researchers to visually compare conventional and thermal facial images.", "token2charspan": [[0, 4], [5, 13], [14, 18], [19, 29], [30, 42], [43, 46], [47, 54], [55, 63], [64, 66], [67, 73], [74, 85], [86, 88], [89, 97], [98, 105], [106, 118], [119, 122], [123, 130], [131, 137], [138, 144], [144, 145]]}
{"doc_key": "ai-test-24", "ner": [[1, 2, "field"], [4, 5, "algorithm"], [10, 11, "task"], [15, 16, "misc"], [20, 21, "field"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 1, 2, "part-of", "", false, false], [4, 5, 10, 11, "topic", "", false, false], [10, 11, 15, 16, "origin", "", false, false], [20, 21, 1, 2, "part-of", "", false, false], [20, 21, 4, 5, "topic", "", false, false], [23, 24, 1, 2, "part-of", "", false, false], [23, 24, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "computer", "science", ",", "evolutionary", "computing", "is", "the", "family", "of", "global", "optimisation", "algorithms", "inspired", "by", "biological", "evolution", ",", "and", "the", "artificial", "intelligence", "and", "soft", "computing", "subfields", "that", "study", "them", "."], "sentence-detokenized": "In computer science, evolutionary computing is the family of global optimisation algorithms inspired by biological evolution, and the artificial intelligence and soft computing subfields that study them.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 33], [34, 43], [44, 46], [47, 50], [51, 57], [58, 60], [61, 67], [68, 80], [81, 91], [92, 100], [101, 103], [104, 114], [115, 124], [124, 125], [126, 129], [130, 133], [134, 144], [145, 157], [158, 161], [162, 166], [167, 176], [177, 186], [187, 191], [192, 197], [198, 202], [202, 203]]}
{"doc_key": "ai-test-25", "ner": [[10, 11, "metrics"], [14, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "we", "can", "combine", "some", "measures", "based", "on", "confusion", "matrices", "with", "the", "mean", "squared", "error", "assessed", "between", "the", "original", "model", "output", "and", "the", "actual", "values", "."], "sentence-detokenized": "For example, we can combine some measures based on confusion matrices with the mean squared error assessed between the original model output and the actual values.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 19], [20, 27], [28, 32], [33, 41], [42, 47], [48, 50], [51, 60], [61, 69], [70, 74], [75, 78], [79, 83], [84, 91], [92, 97], [98, 106], [107, 114], [115, 118], [119, 127], [128, 133], [134, 140], [141, 144], [145, 148], [149, 155], [156, 162], [162, 163]]}
{"doc_key": "ai-test-26", "ner": [[6, 7, "product"], [15, 15, "researcher"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 15, 15, "origin", "", false, false], [6, 7, 12, 12, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Most", "are", "the", "result", "of", "the", "word2vec", "model", "or", "a", "variant", "of", "word2vec", "developed", "by", "Mikolov", "et", "al", "."], "sentence-detokenized": "Most are the result of the word2vec model or a variant of word2vec developed by Mikolov et al.", "token2charspan": [[0, 4], [5, 8], [9, 12], [13, 19], [20, 22], [23, 26], [27, 35], [36, 41], [42, 44], [45, 46], [47, 54], [55, 57], [58, 66], [67, 76], [77, 79], [80, 87], [88, 90], [91, 93], [93, 94]]}
{"doc_key": "ai-test-27", "ner": [[14, 14, "conference"], [16, 21, "conference"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 23, 16, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "during", "this", "time", "that", "a", "total", "of", "43", "papers", "were", "recognised", "by", "CVPR", "and", "the", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "."], "sentence-detokenized": "It was during this time that a total of 43 papers were recognised by CVPR and the International Conference on Computer Vision (ICCV).", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 23], [24, 28], [29, 30], [31, 36], [37, 39], [40, 42], [43, 49], [50, 54], [55, 65], [66, 68], [69, 73], [74, 77], [78, 81], [82, 95], [96, 106], [107, 109], [110, 118], [119, 125], [126, 127], [127, 131], [131, 132], [132, 133]]}
{"doc_key": "ai-test-28", "ner": [[0, 0, "product"], [10, 10, "field"], [19, 20, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 10, "general-affiliation", "platform_for_education_about", false, false], [19, 20, 0, 0, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["AIBO", "has", "been", "widely", "used", "as", "an", "inexpensive", "platform", "for", "AI", "education", "and", "research", "as", "it", "integrates", "computers", ",", "computer", "vision", "and", "articulators", "in", "a", "much", "cheaper", "package", "than", "traditional", "research", "robots", "."], "sentence-detokenized": "AIBO has been widely used as an inexpensive platform for AI education and research as it integrates computers, computer vision and articulators in a much cheaper package than traditional research robots.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 20], [21, 25], [26, 28], [29, 31], [32, 43], [44, 52], [53, 56], [57, 59], [60, 69], [70, 73], [74, 82], [83, 85], [86, 88], [89, 99], [100, 109], [109, 110], [111, 119], [120, 126], [127, 130], [131, 143], [144, 146], [147, 148], [149, 153], [154, 161], [162, 169], [170, 174], [175, 186], [187, 195], [196, 202], [202, 203]]}
{"doc_key": "ai-test-29", "ner": [[6, 13, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "served", "as", "the", "program", "chair", "for", "the", "2021", "International", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "She served as the program chair for the 2021 International Conference on Computer Vision.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 17], [18, 25], [26, 31], [32, 35], [36, 39], [40, 44], [45, 58], [59, 69], [70, 72], [73, 81], [82, 88], [88, 89]]}
{"doc_key": "ai-test-30", "ner": [[11, 11, "researcher"], [5, 5, "organisation"], [15, 15, "organisation"], [25, 27, "organisation"], [33, 37, "product"], [39, 39, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 5, 5, "role", "", false, false], [11, 11, 15, 15, "role", "", true, false], [15, 15, 25, 27, "role", "develops_with", false, false], [33, 37, 15, 15, "artifact", "", false, false], [39, 39, 33, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["After", "receiving", "a", "scholarship", "from", "Unimation", "to", "develop", "his", "designs", ",", "Scheinman", "sold", "them", "to", "Unimation", ",", "who", "further", "developed", "them", "with", "the", "support", "of", "General", "Motors", "and", "later", "marketed", "them", "as", "a", "programmable", "universal", "machine", "for", "assembly", "(", "PUMA", ")", "."], "sentence-detokenized": "After receiving a scholarship from Unimation to develop his designs, Scheinman sold them to Unimation, who further developed them with the support of General Motors and later marketed them as a programmable universal machine for assembly (PUMA).", "token2charspan": [[0, 5], [6, 15], [16, 17], [18, 29], [30, 34], [35, 44], [45, 47], [48, 55], [56, 59], [60, 67], [67, 68], [69, 78], [79, 83], [84, 88], [89, 91], [92, 101], [101, 102], [103, 106], [107, 114], [115, 124], [125, 129], [130, 134], [135, 138], [139, 146], [147, 149], [150, 157], [158, 164], [165, 168], [169, 174], [175, 183], [184, 188], [189, 191], [192, 193], [194, 206], [207, 216], [217, 224], [225, 228], [229, 237], [238, 239], [239, 243], [243, 244], [244, 245]]}
{"doc_key": "ai-test-31", "ner": [[11, 11, "task"], [13, 15, "task"], [0, 0, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 11, "general-affiliation", "works_with", false, false], [0, 0, 13, 15, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Gebel", "(", "2009", ")", "provides", "an", "overview", "of", "calibration", "methods", "for", "binary", "and", "multiclass", "classification", "tasks"], "sentence-detokenized": "Gebel (2009) provides an overview of calibration methods for binary and multiclass classification tasks", "token2charspan": [[0, 5], [6, 7], [7, 11], [11, 12], [13, 21], [22, 24], [25, 33], [34, 36], [37, 48], [49, 56], [57, 60], [61, 67], [68, 71], [72, 82], [83, 97], [98, 103]]}
{"doc_key": "ai-test-32", "ner": [[7, 9, "task"], [11, 11, "task"], [14, 15, "task"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "involved", "in", "areas", "such", "as", "optical", "character", "recognition", "(", "OCR", ")", ",", "speech", "synthesis", ",", "speech", "recognition", "technology", "and", "electronic", "keyboard", "instrumentation", "."], "sentence-detokenized": "He is involved in areas such as optical character recognition (OCR), speech synthesis, speech recognition technology and electronic keyboard instrumentation.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 23], [24, 28], [29, 31], [32, 39], [40, 49], [50, 61], [62, 63], [63, 66], [66, 67], [67, 68], [69, 75], [76, 85], [85, 86], [87, 93], [94, 105], [106, 116], [117, 120], [121, 131], [132, 140], [141, 156], [156, 157]]}
{"doc_key": "ai-test-33", "ner": [[18, 20, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "more", "up", "-", "to", "-", "date", "and", "state", "-", "of", "-", "the", "-", "art", "technology", ",", "the", "Kaldi", "Toolbox", "is", "available", "."], "sentence-detokenized": "For more up-to-date and state-of-the-art technology, the Kaldi Toolbox is available.", "token2charspan": [[0, 3], [4, 8], [9, 11], [11, 12], [12, 14], [14, 15], [15, 19], [20, 23], [24, 29], [29, 30], [30, 32], [32, 33], [33, 36], [36, 37], [37, 40], [41, 51], [51, 52], [53, 56], [57, 62], [63, 70], [71, 73], [74, 83], [83, 84]]}
{"doc_key": "ai-test-34", "ner": [[0, 0, "researcher"], [6, 9, "organisation"], [14, 16, "organisation"], [20, 23, "organisation"], [26, 27, "researcher"], [30, 34, "organisation"], [40, 43, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 6, 9, "role", "", false, false], [0, 0, 14, 16, "role", "", false, false], [0, 0, 20, 23, "role", "", false, false], [0, 0, 30, 34, "role", "", false, false], [0, 0, 40, 43, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Johnson", "Laird", "is", "a", "Fellow", "of", "the", "American", "Philosophical", "Society", ",", "a", "Fellow", "of", "the", "Royal", "Society", ",", "a", "Fellow", "of", "the", "British", "Academy", ",", "a", "William", "James", "Fellow", "of", "the", "Association", "for", "Psychological", "Science", ",", "and", "a", "Fellow", "of", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Johnson Laird is a Fellow of the American Philosophical Society, a Fellow of the Royal Society, a Fellow of the British Academy, a William James Fellow of the Association for Psychological Science, and a Fellow of the Cognitive Science Society.", "token2charspan": [[0, 7], [8, 13], [14, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 41], [42, 55], [56, 63], [63, 64], [65, 66], [67, 73], [74, 76], [77, 80], [81, 86], [87, 94], [94, 95], [96, 97], [98, 104], [105, 107], [108, 111], [112, 119], [120, 127], [127, 128], [129, 130], [131, 138], [139, 144], [145, 151], [152, 154], [155, 158], [159, 170], [171, 174], [175, 188], [189, 196], [196, 197], [198, 201], [202, 203], [204, 210], [211, 213], [214, 217], [218, 227], [228, 235], [236, 243], [243, 244]]}
{"doc_key": "ai-test-35", "ner": [[3, 8, "conference"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [20, 21, "algorithm"], [23, 27, "task"], [29, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 11, 3, 8, "physical", "", false, false], [10, 11, 3, 8, "temporal", "", false, false], [13, 14, 3, 8, "physical", "", false, false], [13, 14, 3, 8, "temporal", "", false, false], [16, 17, 3, 8, "physical", "", false, false], [16, 17, 3, 8, "temporal", "", false, false], [20, 21, 16, 17, "role", "extends", false, false], [23, 27, 16, 17, "role", "extends", false, false], [29, 29, 23, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["At", "the", "2010", "IEEE", "International", "Conference", "on", "Image", "Processing", ",", "Rui", "Hu", ",", "Mark", "Banard", "and", "John", "Collomosse", "extended", "the", "HOG", "descriptor", "for", "sketch", "-", "based", "image", "retrieval", "(", "SBIR", ")", "."], "sentence-detokenized": "At the 2010 IEEE International Conference on Image Processing, Rui Hu, Mark Banard and John Collomosse extended the HOG descriptor for sketch-based image retrieval (SBIR).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 30], [31, 41], [42, 44], [45, 50], [51, 61], [61, 62], [63, 66], [67, 69], [69, 70], [71, 75], [76, 82], [83, 86], [87, 91], [92, 102], [103, 111], [112, 115], [116, 119], [120, 130], [131, 134], [135, 141], [141, 142], [142, 147], [148, 153], [154, 163], [164, 165], [165, 169], [169, 170], [170, 171]]}
{"doc_key": "ai-test-36", "ner": [[0, 0, "metrics"], [6, 7, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 7, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["BLEU", "uses", "a", "modified", "form", "of", "precision", "to", "compare", "a", "candidate", "translation", "with", "multiple", "reference", "translations", "."], "sentence-detokenized": "BLEU uses a modified form of precision to compare a candidate translation with multiple reference translations.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 20], [21, 25], [26, 28], [29, 38], [39, 41], [42, 49], [50, 51], [52, 61], [62, 73], [74, 78], [79, 87], [88, 97], [98, 110], [110, 111]]}
{"doc_key": "ai-test-37", "ner": [[31, 32, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "the", "case", "of", "the", "general", "base", "space", "math", "(", "Y", ",\\", "mathcal", "{", "B", "},\\", "nu", ")", "/", "math", "(", "i.e.", "an", "uncountable", "base", "space", ")", ",", "one", "usually", "considers", "relative", "entropy", "."], "sentence-detokenized": "For the case of the general base space math (Y,\\ mathcal {B},\\ nu) / math (i.e. an uncountable base space), one usually considers relative entropy.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 15], [16, 19], [20, 27], [28, 32], [33, 38], [39, 43], [44, 45], [45, 46], [46, 48], [49, 56], [57, 58], [58, 59], [59, 62], [63, 65], [65, 66], [67, 68], [69, 73], [74, 75], [75, 79], [80, 82], [83, 94], [95, 99], [100, 105], [105, 106], [106, 107], [108, 111], [112, 119], [120, 129], [130, 138], [139, 146], [146, 147]]}
{"doc_key": "ai-test-38", "ner": [[11, 11, "country"], [12, 14, "organisation"], [16, 16, "organisation"], [19, 20, "organisation"], [22, 22, "organisation"], [25, 28, "organisation"], [41, 43, "country"], [31, 36, "organisation"], [38, 38, "organisation"], [48, 48, "misc"], [49, 49, "misc"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[12, 14, 11, 11, "physical", "", false, false], [16, 16, 12, 14, "named", "", false, false], [22, 22, 19, 20, "named", "", false, false], [31, 36, 41, 43, "physical", "", false, false], [38, 38, 31, 36, "named", "", false, false], [48, 48, 49, 49, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 3, 4, 5, 6], "sentence": ["As", "of", "October", "2011", ",", "the", "already", "existing", "partnerships", "with", "the", "US", "National", "Park", "Service", "(", "NPS", ")", ",", "Historic", "Scotland", "(", "HS", ")", ",", "the", "World", "Monuments", "Fund", "and", "the", "National", "Institute", "of", "Anthropology", "and", "History", "(", "INAH", ")", "of", "Mexico", "have", "been", "greatly", "expanded", ",", ",", "CyArk", "website"], "sentence-detokenized": "As of October 2011, the already existing partnerships with the US National Park Service (NPS), Historic Scotland (HS), the World Monuments Fund and the National Institute of Anthropology and History (INAH) of Mexico have been greatly expanded,, CyArk website", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 18], [18, 19], [20, 23], [24, 31], [32, 40], [41, 53], [54, 58], [59, 62], [63, 65], [66, 74], [75, 79], [80, 87], [88, 89], [89, 92], [92, 93], [93, 94], [95, 103], [104, 112], [113, 114], [114, 116], [116, 117], [117, 118], [119, 122], [123, 128], [129, 138], [139, 143], [144, 147], [148, 151], [152, 160], [161, 170], [171, 173], [174, 186], [187, 190], [191, 198], [199, 200], [200, 204], [204, 205], [206, 208], [209, 215], [216, 220], [221, 225], [226, 233], [234, 242], [242, 243], [243, 244], [245, 250], [251, 258]]}
{"doc_key": "ai-test-39", "ner": [[0, 3, "algorithm"], [6, 7, "field"], [11, 11, "product"], [13, 13, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 11, 11, "part-of", "", false, false], [0, 3, 13, 13, "part-of", "", false, false], [11, 11, 6, 7, "general-affiliation", "", false, false], [13, 13, 6, 7, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kernel", "SVMs", "are", "available", "in", "many", "machine", "learning", "toolkits", ",", "including", "LIBSVM", ",", "MATLAB", "and", "others", "."], "sentence-detokenized": "Kernel SVMs are available in many machine learning toolkits, including LIBSVM, MATLAB and others.", "token2charspan": [[0, 6], [7, 11], [12, 15], [16, 25], [26, 28], [29, 33], [34, 41], [42, 50], [51, 59], [59, 60], [61, 70], [71, 77], [77, 78], [79, 85], [86, 89], [90, 96], [96, 97]]}
{"doc_key": "ai-test-40", "ner": [[0, 3, "misc"], [12, 15, "location"], [13, 13, "location"], [16, 18, "country"], [21, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 12, 15, "physical", "", false, false], [0, 3, 21, 24, "temporal", "", false, false], [12, 15, 13, 13, "physical", "", false, false], [13, 13, 16, 18, "physical", "", false, false], [21, 24, 12, 15, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Loebner", "Prize", "Competition", "2009", "took", "place", "on", "6", "September", "2009", "at", "the", "Brighton", "Centre", "in", "the", "UK", "in", "conjunction", "with", "the", "Interspeech", "2009", "conference", "."], "sentence-detokenized": "The Loebner Prize Competition 2009 took place on 6 September 2009 at the Brighton Centre in the UK in conjunction with the Interspeech 2009 conference.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 29], [30, 34], [35, 39], [40, 45], [46, 48], [49, 50], [51, 60], [61, 65], [66, 68], [69, 72], [73, 81], [82, 88], [89, 91], [92, 95], [96, 98], [99, 101], [102, 113], [114, 118], [119, 122], [123, 134], [135, 139], [140, 150], [150, 151]]}
{"doc_key": "ai-test-41", "ner": [[2, 3, "product"], [10, 10, "product"], [16, 18, "product"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 21, 2, 3, "part-of", "", false, false], [19, 21, 10, 10, "part-of", "", false, false], [19, 21, 16, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "humanoid", "QRIO", "robot", "is", "designed", "as", "a", "successor", "to", "AIBO", "and", "runs", "the", "same", "basic", "R", "-", "CODE", "Aperios", "operating", "system", "."], "sentence-detokenized": "The humanoid QRIO robot is designed as a successor to AIBO and runs the same basic R-CODE Aperios operating system.", "token2charspan": [[0, 3], [4, 12], [13, 17], [18, 23], [24, 26], [27, 35], [36, 38], [39, 40], [41, 50], [51, 53], [54, 58], [59, 62], [63, 67], [68, 71], [72, 76], [77, 82], [83, 84], [84, 85], [85, 89], [90, 97], [98, 107], [108, 114], [114, 115]]}
{"doc_key": "ai-test-42", "ner": [[0, 3, "misc"], [7, 7, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 0, 3, "cause-effect", "", true, false], [12, 13, 0, 3, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "speech", "waveforms", "are", "generated", "by", "the", "HMMs", "themselves", "according", "to", "the", "maximum", "likelihood", "criterion", "."], "sentence-detokenized": "The speech waveforms are generated by the HMMs themselves according to the maximum likelihood criterion.", "token2charspan": [[0, 3], [4, 10], [11, 20], [21, 24], [25, 34], [35, 37], [38, 41], [42, 46], [47, 57], [58, 67], [68, 70], [71, 74], [75, 82], [83, 93], [94, 103], [103, 104]]}
{"doc_key": "ai-test-43", "ner": [[0, 1, "product"], [5, 8, "task"], [10, 12, "task"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 5, 8, "type-of", "", false, false], [0, 1, 10, 12, "type-of", "", false, false], [0, 1, 16, 17, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "is", "a", "free", "multilingual", "statistical", "machine", "translation", "and", "neural", "machine", "translation", "service", "developed", "by", "Google", "that", "translates", "text", "and", "websites", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Google Translate is a free multilingual statistical machine translation and neural machine translation service developed by Google that translates text and websites from one language to another.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 39], [40, 51], [52, 59], [60, 71], [72, 75], [76, 82], [83, 90], [91, 102], [103, 110], [111, 120], [121, 123], [124, 130], [131, 135], [136, 146], [147, 151], [152, 155], [156, 164], [165, 169], [170, 173], [174, 182], [183, 185], [186, 193], [193, 194]]}
{"doc_key": "ai-test-44", "ner": [[6, 7, "field"], [9, 10, "field"], [12, 13, "field"], [15, 17, "field"], [22, 24, "task"], [26, 27, "task"], [20, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[22, 24, 6, 7, "part-of", "", false, true], [22, 24, 9, 10, "part-of", "", false, true], [22, 24, 12, 13, "part-of", "", false, true], [26, 27, 6, 7, "part-of", "", false, true], [26, 27, 9, 10, "part-of", "", false, true], [26, 27, 12, 13, "part-of", "", false, true], [20, 32, 6, 7, "part-of", "", false, true], [20, 32, 9, 10, "part-of", "", false, true], [20, 32, 12, 13, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "skeleton", "is", "widely", "used", "in", "computer", "vision", ",", "image", "analysis", ",", "pattern", "recognition", "and", "digital", "image", "processing", "for", "purposes", "such", "as", "optical", "character", "recognition", ",", "fingerprint", "recognition", ",", "visual", "inspection", "or", "compression", "."], "sentence-detokenized": "The skeleton is widely used in computer vision, image analysis, pattern recognition and digital image processing for purposes such as optical character recognition, fingerprint recognition, visual inspection or compression.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 22], [23, 27], [28, 30], [31, 39], [40, 46], [46, 47], [48, 53], [54, 62], [62, 63], [64, 71], [72, 83], [84, 87], [88, 95], [96, 101], [102, 112], [113, 116], [117, 125], [126, 130], [131, 133], [134, 141], [142, 151], [152, 163], [163, 164], [165, 176], [177, 188], [188, 189], [190, 196], [197, 207], [208, 210], [211, 222], [222, 223]]}
{"doc_key": "ai-test-45", "ner": [[0, 6, "conference"], [11, 14, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 6, 11, 14, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "is", "a", "benchmark", "for", "object", "classification", "and", "detection", ",", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "The ImageNet Large Scale Visual Recognition Challenge is a benchmark for object classification and detection, with millions of images and hundreds of object classes.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 24], [25, 31], [32, 43], [44, 53], [54, 56], [57, 58], [59, 68], [69, 72], [73, 79], [80, 94], [95, 98], [99, 108], [108, 109], [110, 114], [115, 123], [124, 126], [127, 133], [134, 137], [138, 146], [147, 149], [150, 156], [157, 164], [164, 165]]}
{"doc_key": "ai-test-46", "ner": [[8, 9, "researcher"], [2, 3, "researcher"], [5, 6, "researcher"], [15, 18, "misc"], [21, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 9, 15, 18, "part-of", "", false, false], [8, 9, 21, 24, "part-of", "", false, false], [2, 3, 15, 18, "part-of", "", false, false], [2, 3, 21, 24, "part-of", "", false, false], [5, 6, 15, 18, "part-of", "", false, false], [5, 6, 21, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "is", "known", "by", "some", "as", "the", "godfather", "of", "artificial", "intelligence", "and", "the", "godfather", "of", "deep", "learning", "."], "sentence-detokenized": "Along with Geoffrey Hinton and Yann LeCun, Bengio is known by some as the godfather of artificial intelligence and the godfather of deep learning.", "token2charspan": [[0, 5], [6, 10], [11, 19], [20, 26], [27, 30], [31, 35], [36, 41], [41, 42], [43, 49], [50, 52], [53, 58], [59, 61], [62, 66], [67, 69], [70, 73], [74, 83], [84, 86], [87, 97], [98, 110], [111, 114], [115, 118], [119, 128], [129, 131], [132, 136], [137, 145], [145, 146]]}
{"doc_key": "ai-test-47", "ner": [[6, 7, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "life", "member", "of", "the", "IEEE", "."], "sentence-detokenized": "He is a life member of the IEEE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 19], [20, 22], [23, 26], [27, 31], [31, 32]]}
{"doc_key": "ai-test-48", "ner": [[0, 1, "organisation"], [5, 19, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 5, 19, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Bethesda", "NSA", "is", "responsible", "for", "providing", "base", "operational", "support", "to", "its", "main", "tenant", ",", "Walter", "Reed", "National", "Military", "Medical", "Center", "."], "sentence-detokenized": "Bethesda NSA is responsible for providing base operational support to its main tenant, Walter Reed National Military Medical Center.", "token2charspan": [[0, 8], [9, 12], [13, 15], [16, 27], [28, 31], [32, 41], [42, 46], [47, 58], [59, 66], [67, 69], [70, 73], [74, 78], [79, 85], [85, 86], [87, 93], [94, 98], [99, 107], [108, 116], [117, 124], [125, 131], [131, 132]]}
{"doc_key": "ai-test-49", "ner": [[6, 7, "field"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "three", "main", "learning", "paradigms", "are", "supervised", "learning", ",", "unsupervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "The three main learning paradigms are supervised learning, unsupervised learning and reinforcement learning.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 23], [24, 33], [34, 37], [38, 48], [49, 57], [57, 58], [59, 71], [72, 80], [81, 84], [85, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-test-50", "ner": [[2, 2, "task"], [4, 6, "task"], [11, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Examples", "include", "control", ",", "planning", "and", "scheduling", ",", "the", "ability", "to", "answer", "diagnostic", "and", "consumer", "questions", ",", "handwriting", "recognition", ",", "natural", "language", "understanding", ",", "speech", "recognition", "and", "facial", "recognition", "."], "sentence-detokenized": "Examples include control, planning and scheduling, the ability to answer diagnostic and consumer questions, handwriting recognition, natural language understanding, speech recognition and facial recognition.", "token2charspan": [[0, 8], [9, 16], [17, 24], [24, 25], [26, 34], [35, 38], [39, 49], [49, 50], [51, 54], [55, 62], [63, 65], [66, 72], [73, 83], [84, 87], [88, 96], [97, 106], [106, 107], [108, 119], [120, 131], [131, 132], [133, 140], [141, 149], [150, 163], [163, 164], [165, 171], [172, 183], [184, 187], [188, 194], [195, 206], [206, 207]]}
{"doc_key": "ai-test-51", "ner": [[8, 15, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1991", "he", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "founding", "Fellow", ",", "1990", ")", "."], "sentence-detokenized": "In 1991 he was elected a Fellow of the Association for the Advancement of Artificial Intelligence (founding Fellow, 1990).", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 22], [23, 24], [25, 31], [32, 34], [35, 38], [39, 50], [51, 54], [55, 58], [59, 70], [71, 73], [74, 84], [85, 97], [98, 99], [99, 107], [108, 114], [114, 115], [116, 120], [120, 121], [121, 122]]}
{"doc_key": "ai-test-52", "ner": [[10, 12, "misc"], [15, 16, "algorithm"], [25, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "by", "formulating", "the", "problem", "as", "a", "solution", "to", "the", "Toplitz", "matrix", "and", "using", "Levinson", "recursion", ",", "we", "can", "estimate", "a", "filter", "with", "minimum", "mean", "square", "error", "relatively", "quickly", "."], "sentence-detokenized": "However, by formulating the problem as a solution to the Toplitz matrix and using Levinson recursion, we can estimate a filter with minimum mean square error relatively quickly.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 23], [24, 27], [28, 35], [36, 38], [39, 40], [41, 49], [50, 52], [53, 56], [57, 64], [65, 71], [72, 75], [76, 81], [82, 90], [91, 100], [100, 101], [102, 104], [105, 108], [109, 117], [118, 119], [120, 126], [127, 131], [132, 139], [140, 144], [145, 151], [152, 157], [158, 168], [169, 176], [176, 177]]}
{"doc_key": "ai-test-53", "ner": [[5, 11, "conference"], [16, 22, "location"], [23, 23, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 11, 16, 22, "physical", "", false, false], [16, 22, 23, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2011", ",", "the", "15th", "edition", "of", "the", "Spanish", "School", "Party", "will", "take", "place", "at", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", "."], "sentence-detokenized": "In July 2011, the 15th edition of the Spanish School Party will take place at the City of Arts and Sciences in Valencia.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 22], [23, 30], [31, 33], [34, 37], [38, 45], [46, 52], [53, 58], [59, 63], [64, 68], [69, 74], [75, 77], [78, 81], [82, 86], [87, 89], [90, 94], [95, 98], [99, 107], [108, 110], [111, 119], [119, 120]]}
{"doc_key": "ai-test-54", "ner": [[16, 16, "product"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typically", ",", "this", "is", "usually", "only", "possible", "in", "the", "final", "stages", "of", "complex", "games", "such", "as", "chess", "or", "go", ",", "as", "it", "is", "not", "computationally", "feasible", "to", "look", "ahead", "to", "the", "completion", "of", "the", "game", "except", "near", "the", "end", ";", "instead", ",", "positions", "are", "given", "a", "limited", "value", "as", "an", "estimate", "of", "the", "degree", "of", "belief", "that", "they", "will", "lead", "to", "a", "win", "for", "one", "side", "or", "the", "other", "."], "sentence-detokenized": "Typically, this is usually only possible in the final stages of complex games such as chess or go, as it is not computationally feasible to look ahead to the completion of the game except near the end; instead, positions are given a limited value as an estimate of the degree of belief that they will lead to a win for one side or the other.", "token2charspan": [[0, 9], [9, 10], [11, 15], [16, 18], [19, 26], [27, 31], [32, 40], [41, 43], [44, 47], [48, 53], [54, 60], [61, 63], [64, 71], [72, 77], [78, 82], [83, 85], [86, 91], [92, 94], [95, 97], [97, 98], [99, 101], [102, 104], [105, 107], [108, 111], [112, 127], [128, 136], [137, 139], [140, 144], [145, 150], [151, 153], [154, 157], [158, 168], [169, 171], [172, 175], [176, 180], [181, 187], [188, 192], [193, 196], [197, 200], [200, 201], [202, 209], [209, 210], [211, 220], [221, 224], [225, 230], [231, 232], [233, 240], [241, 246], [247, 249], [250, 252], [253, 261], [262, 264], [265, 268], [269, 275], [276, 278], [279, 285], [286, 290], [291, 295], [296, 300], [301, 305], [306, 308], [309, 310], [311, 314], [315, 318], [319, 322], [323, 327], [328, 330], [331, 334], [335, 340], [340, 341]]}
{"doc_key": "ai-test-55", "ner": [[3, 6, "algorithm"], [23, 24, "algorithm"], [26, 27, "algorithm"], [30, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 6, 23, 24, "compare", "", false, false], [3, 6, 26, 27, "compare", "", false, false], [3, 6, 30, 32, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "difference", "between", "the", "polynomial", "logit", "model", "and", "numerous", "other", "methods", ",", "models", ",", "algorithms", ",", "etc.", "with", "the", "same", "basic", "setup", "(", "perceptron", "algorithms", ",", "support", "vector", "machines", ",", "linear", "discriminant", "analysis", ",", "etc.", ")", "."], "sentence-detokenized": "The difference between the polynomial logit model and numerous other methods, models, algorithms, etc. with the same basic setup (perceptron algorithms, support vector machines, linear discriminant analysis, etc.).", "token2charspan": [[0, 3], [4, 14], [15, 22], [23, 26], [27, 37], [38, 43], [44, 49], [50, 53], [54, 62], [63, 68], [69, 76], [76, 77], [78, 84], [84, 85], [86, 96], [96, 97], [98, 102], [103, 107], [108, 111], [112, 116], [117, 122], [123, 128], [129, 130], [130, 140], [141, 151], [151, 152], [153, 160], [161, 167], [168, 176], [176, 177], [178, 184], [185, 197], [198, 206], [206, 207], [208, 212], [212, 213], [213, 214]]}
{"doc_key": "ai-test-56", "ner": [[0, 3, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Association", "for", "Computational", "Linguistics", ",", "published", "by"], "sentence-detokenized": "Association for Computational Linguistics, published by", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [41, 42], [43, 52], [53, 55]]}
{"doc_key": "ai-test-57", "ner": [[2, 4, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "computerised", "facial", "recognition", "systems", ",", "each", "face", "is", "represented", "by", "a", "large", "number", "of", "pixel", "values", "."], "sentence-detokenized": "In computerised facial recognition systems, each face is represented by a large number of pixel values.", "token2charspan": [[0, 2], [3, 15], [16, 22], [23, 34], [35, 42], [42, 43], [44, 48], [49, 53], [54, 56], [57, 68], [69, 71], [72, 73], [74, 79], [80, 86], [87, 89], [90, 95], [96, 102], [102, 103]]}
{"doc_key": "ai-test-58", "ner": [[8, 9, "person"], [16, 18, "organisation"], [21, 23, "country"], [34, 34, "person"], [29, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 9, 16, 18, "role", "", false, false], [8, 9, 21, 23, "physical", "", false, false], [34, 34, 29, 33, "origin", "", false, false], [34, 34, 29, 33, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "kidnapping", "and", "murder", "of", "his", "son", ",", "Daniel", "Pearl", ",", "a", "journalist", "working", "for", "the", "Wall", "Street", "Journal", ",", "in", "Pakistan", "in", "2002", "led", "to", "the", "creation", "of", "the", "Daniel", "Pearl", "Foundation", "by", "Judea", "and", "other", "family", "members", "and", "friends", "."], "sentence-detokenized": "The kidnapping and murder of his son, Daniel Pearl, a journalist working for the Wall Street Journal, in Pakistan in 2002 led to the creation of the Daniel Pearl Foundation by Judea and other family members and friends.", "token2charspan": [[0, 3], [4, 14], [15, 18], [19, 25], [26, 28], [29, 32], [33, 36], [36, 37], [38, 44], [45, 50], [50, 51], [52, 53], [54, 64], [65, 72], [73, 76], [77, 80], [81, 85], [86, 92], [93, 100], [100, 101], [102, 104], [105, 113], [114, 116], [117, 121], [122, 125], [126, 128], [129, 132], [133, 141], [142, 144], [145, 148], [149, 155], [156, 161], [162, 172], [173, 175], [176, 181], [182, 185], [186, 191], [192, 198], [199, 206], [207, 210], [211, 218], [218, 219]]}
{"doc_key": "ai-test-59", "ner": [[6, 8, "organisation"], [20, 21, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 20, 21, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["By", "the", "end", "of", "2006", ",", "Red", "Packet", "Entertainment", "had", "also", "expanded", "into", "producing", "original", "content", "with", "filmmakers", "such", "as", "John", "Waters", "."], "sentence-detokenized": "By the end of 2006, Red Packet Entertainment had also expanded into producing original content with filmmakers such as John Waters.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 13], [14, 18], [18, 19], [20, 23], [24, 30], [31, 44], [45, 48], [49, 53], [54, 62], [63, 67], [68, 77], [78, 86], [87, 94], [95, 99], [100, 110], [111, 115], [116, 118], [119, 123], [124, 130], [130, 131]]}
{"doc_key": "ai-test-60", "ner": [[6, 11, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "building", "is", "now", "part", "of", "the", "Beth", "Israel", "Deaconess", "Medical", "Centre", "."], "sentence-detokenized": "The building is now part of the Beth Israel Deaconess Medical Centre.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 31], [32, 36], [37, 43], [44, 53], [54, 61], [62, 68], [68, 69]]}
{"doc_key": "ai-test-61", "ner": [[19, 20, "field"], [22, 23, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "common", "theme", "in", "this", "work", "is", "the", "adoption", "of", "a", "symbolic", "-", "theoretic", "perspective", "on", "the", "issue", "of", "artificial", "intelligence", "and", "knowledge", "representation", "."], "sentence-detokenized": "A common theme in this work is the adoption of a symbolic-theoretic perspective on the issue of artificial intelligence and knowledge representation.", "token2charspan": [[0, 1], [2, 8], [9, 14], [15, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 43], [44, 46], [47, 48], [49, 57], [57, 58], [58, 67], [68, 79], [80, 82], [83, 86], [87, 92], [93, 95], [96, 106], [107, 119], [120, 123], [124, 133], [134, 148], [148, 149]]}
{"doc_key": "ai-test-62", "ner": [[5, 7, "task"], [9, 9, "task"], [19, 20, "task"], [39, 40, "task"], [42, 43, "task"], [46, 48, "task"], [50, 50, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 7, 19, 20, "type-of", "", false, false], [5, 7, 46, 48, "compare", "", false, false], [5, 7, 46, 48, "opposite", "", false, false], [9, 9, 5, 7, "named", "", false, false], [39, 40, 46, 48, "part-of", "", false, false], [42, 43, 46, 48, "part-of", "", false, false], [46, 48, 19, 20, "type-of", "", false, false], [50, 50, 46, 48, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["For", "example", ",", "the", "term", "Neural", "Machine", "Translation", "(", "NMT", ")", "highlights", "the", "fact", "that", "deep", "learning", "-", "based", "machine", "translation", "methods", "learn", "sequence", "-", "to", "-", "sequence", "conversions", "directly", ",", "avoiding", "the", "need", "for", "intermediate", "steps", "such", "as", "word", "alignment", "and", "language", "modelling", "used", "in", "Statistical", "Machine", "Translation", "(", "SMT", ")", "."], "sentence-detokenized": "For example, the term Neural Machine Translation (NMT) highlights the fact that deep learning-based machine translation methods learn sequence-to-sequence conversions directly, avoiding the need for intermediate steps such as word alignment and language modelling used in Statistical Machine Translation (SMT).", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 36], [37, 48], [49, 50], [50, 53], [53, 54], [55, 65], [66, 69], [70, 74], [75, 79], [80, 84], [85, 93], [93, 94], [94, 99], [100, 107], [108, 119], [120, 127], [128, 133], [134, 142], [142, 143], [143, 145], [145, 146], [146, 154], [155, 166], [167, 175], [175, 176], [177, 185], [186, 189], [190, 194], [195, 198], [199, 211], [212, 217], [218, 222], [223, 225], [226, 230], [231, 240], [241, 244], [245, 253], [254, 263], [264, 268], [269, 271], [272, 283], [284, 291], [292, 303], [304, 305], [305, 308], [308, 309], [309, 310]]}
{"doc_key": "ai-test-63", "ner": [[8, 8, "field"], [14, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 8, 14, 15, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Most", "of", "the", "research", "in", "the", "field", "of", "WSD", "has", "been", "conducted", "by", "using", "Word", "Net", "as", "a", "reference", "list", "of", "meanings", "."], "sentence-detokenized": "Most of the research in the field of WSD has been conducted by using WordNet as a reference list of meanings.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 20], [21, 23], [24, 27], [28, 33], [34, 36], [37, 40], [41, 44], [45, 49], [50, 59], [60, 62], [63, 68], [69, 73], [73, 76], [77, 79], [80, 81], [82, 91], [92, 96], [97, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-test-64", "ner": [[11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Notable", "former", "PhD", "students", "and", "postdoctoral", "researchers", "in", "his", "group", "include", "Richard", "Zemel", "and", "Zubin", "Gahlamani", "."], "sentence-detokenized": "Notable former PhD students and postdoctoral researchers in his group include Richard Zemel and Zubin Gahlamani.", "token2charspan": [[0, 7], [8, 14], [15, 18], [19, 27], [28, 31], [32, 44], [45, 56], [57, 59], [60, 63], [64, 69], [70, 77], [78, 85], [86, 91], [92, 95], [96, 101], [102, 111], [111, 112]]}
{"doc_key": "ai-test-65", "ner": [[7, 8, "metrics"], [14, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 14, 14, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Each", "instance", "of", "the", "prediction", "result", "or", "confusion", "matrix", "represents", "a", "point", "in", "the", "ROC", "space", "."], "sentence-detokenized": "Each instance of the prediction result or confusion matrix represents a point in the ROC space.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 31], [32, 38], [39, 41], [42, 51], [52, 58], [59, 69], [70, 71], [72, 77], [78, 80], [81, 84], [85, 88], [89, 94], [94, 95]]}
{"doc_key": "ai-test-66", "ner": [[2, 2, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [16, 17, "product"], [19, 23, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 19, 23, "physical", "", false, false], [6, 7, 19, 23, "physical", "", false, false], [9, 10, 19, 23, "physical", "", false, false], [16, 17, 2, 2, "artifact", "", false, false], [16, 17, 6, 7, "artifact", "", false, false], [16, 17, 9, 10, "artifact", "", false, false], [16, 17, 19, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "1997", "Thrun", "and", "his", "colleagues", "Wolfram", "Burgard", "and", "Dieter", "Fox", "developed", "the", "world", "'s", "first", "robot", "guide", "at", "the", "German", "Museum", "in", "Bonn", "(", "1997", ")", "."], "sentence-detokenized": "In 1997 Thrun and his colleagues Wolfram Burgard and Dieter Fox developed the world's first robot guide at the German Museum in Bonn (1997).", "token2charspan": [[0, 2], [3, 7], [8, 13], [14, 17], [18, 21], [22, 32], [33, 40], [41, 48], [49, 52], [53, 59], [60, 63], [64, 73], [74, 77], [78, 83], [83, 85], [86, 91], [92, 97], [98, 103], [104, 106], [107, 110], [111, 117], [118, 124], [125, 127], [128, 132], [133, 134], [134, 138], [138, 139], [139, 140]]}
{"doc_key": "ai-test-67", "ner": [[0, 3, "product"], [7, 7, "misc"], [23, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 0, 3, "part-of", "", false, false], [23, 25, 0, 3, "usage", "", false, false], [27, 28, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Word", "Net", "is", "a", "lexical", "database", "of", "semantic", "relationships", "between", "words", "in", "over", "200", "languages", ".", "It", "s", "main", "use", "is", "for", "automated", "natural", "language", "processing", "and", "artificial", "intelligence", "applications", "."], "sentence-detokenized": "WordNet is a lexical database of semantic relationships between words in over 200 languages. Its main use is for automated natural language processing and artificial intelligence applications.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 32], [33, 41], [42, 55], [56, 63], [64, 69], [70, 72], [73, 77], [78, 81], [82, 91], [91, 92], [93, 95], [95, 96], [97, 101], [102, 105], [106, 108], [109, 112], [113, 122], [123, 130], [131, 139], [140, 150], [151, 154], [155, 165], [166, 178], [179, 191], [191, 192]]}
{"doc_key": "ai-test-68", "ner": [[5, 7, "field"], [11, 15, "conference"], [17, 26, "conference"], [28, 28, "conference"], [30, 30, "conference"], [38, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 15, 5, 7, "topic", "", false, false], [11, 15, 38, 39, "topic", "", false, false], [17, 26, 5, 7, "topic", "", false, false], [17, 26, 38, 39, "topic", "", false, false], [28, 28, 5, 7, "topic", "", false, false], [28, 28, 38, 39, "topic", "", false, false], [30, 30, 5, 7, "topic", "", false, false], [30, 30, 38, 39, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Conferences", "in", "the", "field", "of", "natural", "language", "processing", ",", "such", "as", "the", "Association", "for", "Computational", "Linguistics", ",", "the", "North", "American", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "EMNLP", "and", "HLT", ",", "are", "beginning", "to", "include", "papers", "on", "speech", "processing", "."], "sentence-detokenized": "Conferences in the field of natural language processing, such as the Association for Computational Linguistics, the North American Chapter of the Association for Computational Linguistics, EMNLP and HLT, are beginning to include papers on speech processing.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 24], [25, 27], [28, 35], [36, 44], [45, 55], [55, 56], [57, 61], [62, 64], [65, 68], [69, 80], [81, 84], [85, 98], [99, 110], [110, 111], [112, 115], [116, 121], [122, 130], [131, 138], [139, 141], [142, 145], [146, 157], [158, 161], [162, 175], [176, 187], [187, 188], [189, 194], [195, 198], [199, 202], [202, 203], [204, 207], [208, 217], [218, 220], [221, 228], [229, 235], [236, 238], [239, 245], [246, 256], [256, 257]]}
{"doc_key": "ai-test-69", "ner": [[3, 3, "programlang"], [20, 20, "misc"], [31, 33, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "group", "of", "Java", "programs", "use", "the", "dictionary", "to", "process", "variations", "in", "biomedical", "texts", "by", "linking", "words", "by", "their", "semantic", "parts", ",", "which", "is", "useful", "for", "web", "searches", "or", "searches", "through", "electronic", "medical", "records", "."], "sentence-detokenized": "A group of Java programs use the dictionary to process variations in biomedical texts by linking words by their semantic parts, which is useful for web searches or searches through electronic medical records.", "token2charspan": [[0, 1], [2, 7], [8, 10], [11, 15], [16, 24], [25, 28], [29, 32], [33, 43], [44, 46], [47, 54], [55, 65], [66, 68], [69, 79], [80, 85], [86, 88], [89, 96], [97, 102], [103, 105], [106, 111], [112, 120], [121, 126], [126, 127], [128, 133], [134, 136], [137, 143], [144, 147], [148, 151], [152, 160], [161, 163], [164, 172], [173, 180], [181, 191], [192, 199], [200, 207], [207, 208]]}
{"doc_key": "ai-test-70", "ner": [[8, 8, "algorithm"], [10, 10, "algorithm"], [12, 12, "algorithm"], [14, 14, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "many", "more", "recent", "algorithms", "such", "as", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", ",", ",", "etc", "."], "sentence-detokenized": "There are many more recent algorithms such as LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost,, etc.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 19], [20, 26], [27, 37], [38, 42], [43, 45], [46, 53], [53, 54], [55, 65], [65, 66], [67, 77], [77, 78], [79, 86], [86, 87], [88, 97], [97, 98], [98, 99], [100, 103], [103, 104]]}
{"doc_key": "ai-test-71", "ner": [[8, 8, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "of", "an", "implementation", "in", "Python", "."], "sentence-detokenized": "This is an example of an implementation in Python.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 24], [25, 39], [40, 42], [43, 49], [49, 50]]}
{"doc_key": "ai-test-72", "ner": [[0, 0, "organisation"], [2, 2, "product"], [7, 9, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 0, 0, "artifact", "made_by_company", false, false], [7, 9, 2, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Mattel", "'s", "Intellivision", "game", "console", "offered", "the", "Intellivoice", "speech", "synthesis", "module", "in", "1982", "."], "sentence-detokenized": "Mattel's Intellivision game console offered the Intellivoice speech synthesis module in 1982.", "token2charspan": [[0, 6], [6, 8], [9, 22], [23, 27], [28, 35], [36, 43], [44, 47], [48, 60], [61, 67], [68, 77], [78, 84], [85, 87], [88, 92], [92, 93]]}
{"doc_key": "ai-test-73", "ner": [[4, 5, "task"], [8, 14, "task"], [16, 17, "field"], [19, 21, "task"], [24, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 14, 4, 5, "part-of", "", false, false], [16, 17, 4, 5, "part-of", "", false, false], [19, 21, 4, 5, "part-of", "", false, false], [24, 28, 19, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "also", "works", "on", "machine", "translation", ",", "including", "high", "-", "accuracy", "knowledge", "-", "based", "MT", "and", "machine", "learning", "for", "statistical", "machine", "translation", "(", "e.g.", "generalised", "example", "-", "based", "MT", ")", "."], "sentence-detokenized": "He also works on machine translation, including high-accuracy knowledge-based MT and machine learning for statistical machine translation (e.g. generalised example-based MT).", "token2charspan": [[0, 2], [3, 7], [8, 13], [14, 16], [17, 24], [25, 36], [36, 37], [38, 47], [48, 52], [52, 53], [53, 61], [62, 71], [71, 72], [72, 77], [78, 80], [81, 84], [85, 92], [93, 101], [102, 105], [106, 117], [118, 125], [126, 137], [138, 139], [139, 143], [144, 155], [156, 163], [163, 164], [164, 169], [170, 172], [172, 173], [173, 174]]}
{"doc_key": "ai-test-74", "ner": [[0, 1, "misc"], [6, 6, "misc"], [20, 21, "algorithm"], [23, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 32, "field"], [34, 36, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 20, 21, "general-affiliation", "", false, false], [0, 1, 23, 24, "general-affiliation", "", false, false], [0, 1, 26, 27, "general-affiliation", "", false, false], [0, 1, 29, 29, "general-affiliation", "", false, false], [0, 1, 31, 32, "general-affiliation", "", false, false], [0, 1, 34, 36, "general-affiliation", "", false, false], [6, 6, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "commonly", "known", "as", "Mathematica", ")", "is", "a", "modern", "technical", "computing", "system", "that", "spans", "most", "technical", "areas", "-including", "neural", "networks", ",", "machine", "learning", ",", "image", "processing", ",", "geometry", ",", "data", "science", ",", "visualization", ",", "and", "others", "."], "sentence-detokenized": "Wolfram Mathematica (commonly known as Mathematica) is a modern technical computing system that spans most technical areas-including neural networks, machine learning, image processing, geometry, data science, visualization, and others.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 29], [30, 35], [36, 38], [39, 50], [50, 51], [52, 54], [55, 56], [57, 63], [64, 73], [74, 83], [84, 90], [91, 95], [96, 101], [102, 106], [107, 116], [117, 122], [122, 132], [133, 139], [140, 148], [148, 149], [150, 157], [158, 166], [166, 167], [168, 173], [174, 184], [184, 185], [186, 194], [194, 195], [196, 200], [201, 208], [208, 209], [210, 223], [223, 224], [225, 228], [229, 235], [235, 236]]}
{"doc_key": "ai-test-75", "ner": [[2, 7, "product"], [12, 14, "researcher"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 21, 2, 7, "type-of", "", false, false], [21, 21, 12, 14, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "digitally", "operated", "and", "programmable", "robot", "was", "invented", "in", "1954", "by", "Georges", "de", "Waal", "and", "eventually", "became", "known", "as", "the", "Unimate", "."], "sentence-detokenized": "The first digitally operated and programmable robot was invented in 1954 by Georges de Waal and eventually became known as the Unimate.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 28], [29, 32], [33, 45], [46, 51], [52, 55], [56, 64], [65, 67], [68, 72], [73, 75], [76, 83], [84, 86], [87, 91], [92, 95], [96, 106], [107, 113], [114, 119], [120, 122], [123, 126], [127, 134], [134, 135]]}
{"doc_key": "ai-test-76", "ner": [[1, 1, "algorithm"], [3, 3, "algorithm"], [17, 18, "task"], [20, 21, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 3, 3, "compare", "", false, false], [3, 3, 17, 18, "general-affiliation", "", false, false], [3, 3, 20, 21, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Like", "DBNs", ",", "DBMs", "can", "learn", "complex", "and", "abstract", "internal", "representations", "of", "inputs", "in", "tasks", "such", "as", "object", "recognition", "or", "speech", "recognition", ",", "using", "limited", ",", "labelled", "data", "to", "fine", "-", "tune", "representations", "built", "using", "large", "amounts", "of", "unlabelled", "sensory", "input", "data", "."], "sentence-detokenized": "Like DBNs, DBMs can learn complex and abstract internal representations of inputs in tasks such as object recognition or speech recognition, using limited, labelled data to fine-tune representations built using large amounts of unlabelled sensory input data.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 15], [16, 19], [20, 25], [26, 33], [34, 37], [38, 46], [47, 55], [56, 71], [72, 74], [75, 81], [82, 84], [85, 90], [91, 95], [96, 98], [99, 105], [106, 117], [118, 120], [121, 127], [128, 139], [139, 140], [141, 146], [147, 154], [154, 155], [156, 164], [165, 169], [170, 172], [173, 177], [177, 178], [178, 182], [183, 198], [199, 204], [205, 210], [211, 216], [217, 224], [225, 227], [228, 238], [239, 246], [247, 252], [253, 257], [257, 258]]}
{"doc_key": "ai-test-77", "ner": [[3, 7, "task"], [13, 13, "conference"], [15, 15, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 13, 3, 7, "topic", "", false, false], [15, 15, 3, 7, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Scientific", "conferences", "where", "vision", "-", "based", "activity", "recognition", "work", "is", "frequently", "seen", "are", "ICCV", "and", "CVPR", "."], "sentence-detokenized": "Scientific conferences where vision-based activity recognition work is frequently seen are ICCV and CVPR.", "token2charspan": [[0, 10], [11, 22], [23, 28], [29, 35], [35, 36], [36, 41], [42, 50], [51, 62], [63, 67], [68, 70], [71, 81], [82, 86], [87, 90], [91, 95], [96, 99], [100, 104], [104, 105]]}
{"doc_key": "ai-test-78", "ner": [[1, 1, "field"], [4, 5, "algorithm"], [7, 7, "algorithm"], [16, 17, "metrics"], [19, 21, "metrics"], [23, 23, "metrics"], [38, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 5, 1, 1, "part-of", "", false, false], [4, 5, 16, 17, "related-to", "finds", false, false], [4, 5, 19, 21, "related-to", "finds", false, false], [4, 5, 38, 39, "related-to", "", false, false], [7, 7, 4, 5, "named", "", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "statistics", ",", "the", "expectation", "maximisation", "(", "EM", ")", "algorithm", "is", "an", "iterative", "method", "for", "finding", "maximum", "likelihood", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "estimates", "of", "parameters", "in", "a", "statistical", "model", "where", "the", "model", "depends", "on", "unobserved", "latent", "variables", "."], "sentence-detokenized": "In statistics, the expectation maximisation (EM) algorithm is an iterative method for finding maximum likelihood or maximum a posteriori (MAP) estimates of parameters in a statistical model where the model depends on unobserved latent variables.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 30], [31, 43], [44, 45], [45, 47], [47, 48], [49, 58], [59, 61], [62, 64], [65, 74], [75, 81], [82, 85], [86, 93], [94, 101], [102, 112], [113, 115], [116, 123], [124, 125], [126, 136], [137, 138], [138, 141], [141, 142], [143, 152], [153, 155], [156, 166], [167, 169], [170, 171], [172, 183], [184, 189], [190, 195], [196, 199], [200, 205], [206, 213], [214, 216], [217, 227], [228, 234], [235, 244], [244, 245]]}
{"doc_key": "ai-test-79", "ner": [[5, 7, "metrics"], [9, 13, "metrics"], [14, 16, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 13, 5, 7, "named", "", false, false], [18, 18, 14, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Similarly", ",", "investigators", "sometimes", "report", "false", "positive", "rates", "(", "FPR", ")", "as", "well", "as", "false", "negative", "rates", "(", "FNR", ")", "."], "sentence-detokenized": "Similarly, investigators sometimes report false positive rates (FPR) as well as false negative rates (FNR).", "token2charspan": [[0, 9], [9, 10], [11, 24], [25, 34], [35, 41], [42, 47], [48, 56], [57, 62], [63, 64], [64, 67], [67, 68], [69, 71], [72, 76], [77, 79], [80, 85], [86, 94], [95, 100], [101, 102], [102, 105], [105, 106], [106, 107]]}
{"doc_key": "ai-test-80", "ner": [[6, 12, "metrics"], [14, 14, "field"], [17, 18, "metrics"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 14, 6, 12, "usage", "", false, false], [21, 22, 17, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "concept", "is", "similar", "to", "the", "signal", "-", "to", "-", "noise", "ratio", "used", "in", "science", "and", "the", "confusion", "matrix", "used", "in", "artificial", "intelligence", "."], "sentence-detokenized": "This concept is similar to the signal-to-noise ratio used in science and the confusion matrix used in artificial intelligence.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 23], [24, 26], [27, 30], [31, 37], [37, 38], [38, 40], [40, 41], [41, 46], [47, 52], [53, 57], [58, 60], [61, 68], [69, 72], [73, 76], [77, 86], [87, 93], [94, 98], [99, 101], [102, 112], [113, 125], [125, 126]]}
{"doc_key": "ai-test-81", "ner": [[5, 7, "field"], [11, 11, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [31, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 7, 11, 11, "general-affiliation", "", false, false], [5, 7, 18, 19, "general-affiliation", "", false, false], [5, 7, 21, 22, "general-affiliation", "", false, false], [31, 37, 5, 7, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Code", "of", "Ethics", "for", "Human", "Augmentation", "was", "originally", "proposed", "by", "Steve", "Mann", "in", "2004", "and", "refined", "with", "Ray", "Kurzweil", "and", "Marvin", "Minsky", "in", "2013", ",", "and", "was", "finally", "approved", "at", "the", "Virtual", "Reality", "Conference", "in", "Toronto", "on", "25", "June", "2017", "."], "sentence-detokenized": "The Code of Ethics for Human Augmentation was originally proposed by Steve Mann in 2004 and refined with Ray Kurzweil and Marvin Minsky in 2013, and was finally approved at the Virtual Reality Conference in Toronto on 25 June 2017.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 18], [19, 22], [23, 28], [29, 41], [42, 45], [46, 56], [57, 65], [66, 68], [69, 74], [75, 79], [80, 82], [83, 87], [88, 91], [92, 99], [100, 104], [105, 108], [109, 117], [118, 121], [122, 128], [129, 135], [136, 138], [139, 143], [143, 144], [145, 148], [149, 152], [153, 160], [161, 169], [170, 172], [173, 176], [177, 184], [185, 192], [193, 203], [204, 206], [207, 214], [215, 217], [218, 220], [221, 225], [226, 230], [230, 231]]}
{"doc_key": "ai-test-82", "ner": [[2, 4, "person"], [9, 12, "organisation"], [16, 17, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 4, 9, 12, "role", "directed_for", false, false], [2, 4, 16, 17, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1913", "Walter", "R", "Booth", "directed", "ten", "films", "for", "the", "British", "Kinoplastikon", "company", ",", "presumably", "with", "Cecil", "Hepworth", "."], "sentence-detokenized": "In 1913 Walter R Booth directed ten films for the British Kinoplastikon company, presumably with Cecil Hepworth.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 16], [17, 22], [23, 31], [32, 35], [36, 41], [42, 45], [46, 49], [50, 57], [58, 71], [72, 79], [79, 80], [81, 91], [92, 96], [97, 102], [103, 111], [111, 112]]}
{"doc_key": "ai-test-83", "ner": [[16, 16, "location"], [12, 15, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 15, 16, 16, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1961", "they", "launched", "their", "new", "robot", "at", "a", "trade", "show", "at", "the", "Cow", "Palace", "in", "Chicago", "."], "sentence-detokenized": "In 1961 they launched their new robot at a trade show at the Cow Palace in Chicago.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 21], [22, 27], [28, 31], [32, 37], [38, 40], [41, 42], [43, 48], [49, 53], [54, 56], [57, 60], [61, 64], [65, 71], [72, 74], [75, 82], [82, 83]]}
{"doc_key": "ai-test-84", "ner": [[1, 1, "product"], [5, 6, "task"], [9, 11, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 5, 6, "usage", "", false, false], [1, 1, 9, 11, "usage", "", false, false], [1, 1, 15, 16, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Some", "chatbot", "applications", "use", "extensive", "word", "classification", "processes", ",", "natural", "language", "processing", "processors", "and", "sophisticated", "artificial", "intelligence", ",", "while", "others", "simply", "scan", "for", "general", "keywords", "and", "generate", "responses", "using", "common", "phrases", "obtained", "from", "relevant", "libraries", "or", "databases", "."], "sentence-detokenized": "Some chatbot applications use extensive word classification processes, natural language processing processors and sophisticated artificial intelligence, while others simply scan for general keywords and generate responses using common phrases obtained from relevant libraries or databases.", "token2charspan": [[0, 4], [5, 12], [13, 25], [26, 29], [30, 39], [40, 44], [45, 59], [60, 69], [69, 70], [71, 78], [79, 87], [88, 98], [99, 109], [110, 113], [114, 127], [128, 138], [139, 151], [151, 152], [153, 158], [159, 165], [166, 172], [173, 177], [178, 181], [182, 189], [190, 198], [199, 202], [203, 211], [212, 221], [222, 227], [228, 234], [235, 242], [243, 251], [252, 256], [257, 265], [266, 275], [276, 278], [279, 288], [288, 289]]}
{"doc_key": "ai-test-85", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "WaveNet", "model", "proposed", "in", "2016", "achieved", "good", "performance", "in", "terms", "of", "speech", "quality", "."], "sentence-detokenized": "The WaveNet model proposed in 2016 achieved good performance in terms of speech quality.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 43], [44, 48], [49, 60], [61, 63], [64, 69], [70, 72], [73, 79], [80, 87], [87, 88]]}
{"doc_key": "ai-test-86", "ner": [[4, 4, "product"], [6, 7, "misc"], [9, 10, "misc"], [12, 13, "misc"], [15, 17, "misc"], [19, 21, "organisation"], [23, 23, "organisation"], [25, 28, "organisation"], [30, 30, "organisation"], [32, 32, "organisation"], [34, 34, "organisation"], [36, 38, "organisation"], [40, 42, "organisation"], [44, 44, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 4, 6, 7, "general-affiliation", "", false, false], [4, 4, 9, 10, "general-affiliation", "", false, false], [4, 4, 12, 13, "general-affiliation", "", false, false], [4, 4, 15, 17, "general-affiliation", "", false, false], [19, 21, 4, 4, "usage", "", false, false], [23, 23, 4, 4, "usage", "", false, false], [25, 28, 4, 4, "usage", "", false, false], [30, 30, 4, 4, "usage", "", false, false], [32, 32, 4, 4, "usage", "", false, false], [34, 34, 4, 4, "usage", "", false, false], [36, 38, 4, 4, "usage", "", false, false], [40, 42, 4, 4, "usage", "", false, false], [44, 44, 4, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organisations", "known", "to", "use", "ALE", "for", "emergency", "management", ",", "disaster", "relief", ",", "general", "communications", "or", "special", "situation", "response", ".", "American", "Red", "Cross", ",", "FEMA", ",", "Disaster", "Medical", "Assistance", "Team", ",", "NATO", ",", "FBI", ",", "UN", ",", "AT", "&", "T", ",", "Civil", "Air", "Patrol", "(", "ARES", ")", "."], "sentence-detokenized": "Organisations known to use ALE for emergency management, disaster relief, general communications or special situation response. American Red Cross, FEMA, Disaster Medical Assistance Team, NATO, FBI, UN, AT & T, Civil Air Patrol (ARES).", "token2charspan": [[0, 13], [14, 19], [20, 22], [23, 26], [27, 30], [31, 34], [35, 44], [45, 55], [55, 56], [57, 65], [66, 72], [72, 73], [74, 81], [82, 96], [97, 99], [100, 107], [108, 117], [118, 126], [126, 127], [128, 136], [137, 140], [141, 146], [146, 147], [148, 152], [152, 153], [154, 162], [163, 170], [171, 181], [182, 186], [186, 187], [188, 192], [192, 193], [194, 197], [197, 198], [199, 201], [201, 202], [203, 205], [206, 207], [208, 209], [209, 210], [211, 216], [217, 220], [221, 227], [228, 229], [229, 233], [233, 234], [234, 235]]}
{"doc_key": "ai-test-87", "ner": [[6, 7, "algorithm"], [15, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", ",", "for", "simplicity", ",", "the", "Kronecker", "delta", "(", "let", "'s", "say", "the", "derivative", "of", "the", "sigma", "function", ",", "expressed", "through", "the", "function", "itself", ")", "is", "used", "."], "sentence-detokenized": "Here, for simplicity, the Kronecker delta (let's say the derivative of the sigma function, expressed through the function itself) is used.", "token2charspan": [[0, 4], [4, 5], [6, 9], [10, 20], [20, 21], [22, 25], [26, 35], [36, 41], [42, 43], [43, 46], [46, 48], [49, 52], [53, 56], [57, 67], [68, 70], [71, 74], [75, 80], [81, 89], [89, 90], [91, 100], [101, 108], [109, 112], [113, 121], [122, 128], [128, 129], [130, 132], [133, 137], [137, 138]]}
{"doc_key": "ai-test-88", "ner": [[13, 15, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "theory", "is", "based", "on", "a", "philosophical", "foundation", "and", "was", "founded", "around", "1960", "by", "Ray", "Solomonov.", "Samuel", "Lasmana", "and", "Marcus", "Hut", "."], "sentence-detokenized": "The theory is based on a philosophical foundation and was founded around 1960 by Ray Solomonov. Samuel Lasmana and Marcus Hut.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 24], [25, 38], [39, 49], [50, 53], [54, 57], [58, 65], [66, 72], [73, 77], [78, 80], [81, 84], [85, 95], [96, 102], [103, 110], [111, 114], [115, 121], [122, 125], [125, 126]]}
{"doc_key": "ai-test-89", "ner": [[0, 1, "product"], [11, 12, "misc"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 11, 12, "type-of", "", false, false], [0, 1, 15, 16, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Word", "Net", "is", "a", "freely", "available", "database", "originally", "designed", "as", "a", "semantic", "network", "based", "on", "psycholinguistic", "principles", ",", "expanded", "by", "the", "addition", "of", "definitions", ",", "and", "now", "also", "considered", "as", "a", "dictionary", "."], "sentence-detokenized": "WordNet is a freely available database originally designed as a semantic network based on psycholinguistic principles, expanded by the addition of definitions, and now also considered as a dictionary.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 12], [13, 19], [20, 29], [30, 38], [39, 49], [50, 58], [59, 61], [62, 63], [64, 72], [73, 80], [81, 86], [87, 89], [90, 106], [107, 117], [117, 118], [119, 127], [128, 130], [131, 134], [135, 143], [144, 146], [147, 158], [158, 159], [160, 163], [164, 167], [168, 172], [173, 183], [184, 186], [187, 188], [189, 199], [199, 200]]}
{"doc_key": "ai-test-90", "ner": [[5, 6, "field"], [15, 15, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 15, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Advances", "in", "the", "field", "of", "computational", "imaging", "research", "are", "presented", "in", "several", "places", ",", "including", "SIGGRAPH", "publications", "and", "."], "sentence-detokenized": "Advances in the field of computational imaging research are presented in several places, including SIGGRAPH publications and.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 21], [22, 24], [25, 38], [39, 46], [47, 55], [56, 59], [60, 69], [70, 72], [73, 80], [81, 87], [87, 88], [89, 98], [99, 107], [108, 120], [121, 124], [124, 125]]}
{"doc_key": "ai-test-91", "ner": [[0, 0, "task"], [10, 11, "task"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 0, 0, "part-of", "", false, false], [13, 14, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "thought", "of", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multi-level", "classification", "."], "sentence-detokenized": "Classification can be thought of as two separate problems - binary classification and multi-level classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 29], [30, 32], [33, 35], [36, 39], [40, 48], [49, 57], [58, 59], [60, 66], [67, 81], [82, 85], [86, 97], [98, 112], [112, 113]]}
{"doc_key": "ai-test-92", "ner": [[13, 16, "algorithm"], [19, 19, "algorithm"]], "ner_mapping_to_source": [1, 2], "relations": [[19, 19, 13, 16, "named", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Advanced", "gene", "finders", "for", "prokaryotic", "and", "eukaryotic", "genomes", "often", "use", "complex", "probabilistic", "models", "such", "as", "Hidden", "Markov", "Models", "(", "HMM", ")", "to", "combine", "information", "from", "a", "variety", "of", "different", "signal", "and", "content", "measures", "."], "sentence-detokenized": "Advanced gene finders for prokaryotic and eukaryotic genomes often use complex probabilistic models such as Hidden Markov Models (HMM) to combine information from a variety of different signal and content measures.", "token2charspan": [[0, 8], [9, 13], [14, 21], [22, 25], [26, 37], [38, 41], [42, 52], [53, 60], [61, 66], [67, 70], [71, 78], [79, 92], [93, 99], [100, 104], [105, 107], [108, 114], [115, 121], [122, 128], [129, 130], [130, 133], [133, 134], [135, 137], [138, 145], [146, 157], [158, 162], [163, 164], [165, 172], [173, 175], [176, 185], [186, 192], [193, 196], [197, 204], [205, 213], [213, 214]]}
{"doc_key": "ai-test-93", "ner": [[0, 0, "misc"], [3, 3, "misc"], [9, 10, "field"], [13, 14, "algorithm"], [21, 21, "algorithm"], [31, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6], "relations": [[0, 0, 9, 10, "part-of", "", false, false], [0, 0, 13, 14, "usage", "", false, false], [3, 3, 0, 0, "named", "", false, false], [31, 32, 0, 0, "origin", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 5], "sentence": ["Neuroevolution", ",", "or", "neuroevolution", ",", "is", "a", "form", "of", "artificial", "intelligence", "that", "uses", "evolutionary", "algorithms", "to", "generate", "artificial", "neural", "networks", "(", "ANNs", ")", ",", "parameters", ",", "topologies", "and", "rules", ".", "and", "evolutionary", "robotics", "."], "sentence-detokenized": "Neuroevolution, or neuroevolution, is a form of artificial intelligence that uses evolutionary algorithms to generate artificial neural networks (ANNs), parameters, topologies and rules. and evolutionary robotics.", "token2charspan": [[0, 14], [14, 15], [16, 18], [19, 33], [33, 34], [35, 37], [38, 39], [40, 44], [45, 47], [48, 58], [59, 71], [72, 76], [77, 81], [82, 94], [95, 105], [106, 108], [109, 117], [118, 128], [129, 135], [136, 144], [145, 146], [146, 150], [150, 151], [151, 152], [153, 163], [163, 164], [165, 175], [176, 179], [180, 185], [185, 186], [187, 190], [191, 203], [204, 212], [212, 213]]}
{"doc_key": "ai-test-94", "ner": [[1, 1, "organisation"], [6, 6, "metrics"], [9, 9, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 1, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "IBM", "proposed", "and", "implemented", "the", "BLEU", "system", ",", "Papineni", "et", "al", "."], "sentence-detokenized": "As IBM proposed and implemented the BLEU system, Papineni et al.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 19], [20, 31], [32, 35], [36, 40], [41, 47], [47, 48], [49, 57], [58, 60], [61, 63], [63, 64]]}
{"doc_key": "ai-test-95", "ner": [[11, 16, "conference"], [10, 20, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 20, 11, 16, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2009", ",", "experts", "attended", "a", "conference", "hosted", "by", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "to", "discuss", "whether", "computers", "and", "robots", "might", "gain", "any", "autonomy", ",", "and", "how", "much", "of", "a", "threat", "or", "hazard", "these", "capabilities", "might", "pose", "."], "sentence-detokenized": "In 2009, experts attended a conference hosted by the Association for the Advancement of Artificial Intelligence (AAAI) to discuss whether computers and robots might gain any autonomy, and how much of a threat or hazard these capabilities might pose.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 25], [26, 27], [28, 38], [39, 45], [46, 48], [49, 52], [53, 64], [65, 68], [69, 72], [73, 84], [85, 87], [88, 98], [99, 111], [112, 113], [113, 117], [117, 118], [119, 121], [122, 129], [130, 137], [138, 147], [148, 151], [152, 158], [159, 164], [165, 169], [170, 173], [174, 182], [182, 183], [184, 187], [188, 191], [192, 196], [197, 199], [200, 201], [202, 208], [209, 211], [212, 218], [219, 224], [225, 237], [238, 243], [244, 248], [248, 249]]}
{"doc_key": "ai-test-96", "ner": [[29, 31, "researcher"], [33, 34, "researcher"], [36, 41, "task"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[36, 41, 29, 31, "artifact", "", false, false], [36, 41, 33, 34, "artifact", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["After", "boosting", ",", "a", "classifier", "constructed", "from", "200", "features", "can", "achieve", "a", "95", "%", "detection", "rate", "at", "^", "{", "-", "5", "}", "/", "math", "FALSE", "positive", "rate", ".", "/", "P", ".", "Viola", ",", "M.", "Jones", ",", "Robust", "Real", "-", "time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "After boosting, a classifier constructed from 200 features can achieve a 95% detection rate at ^ {-5} / math FALSE positive rate. / P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 17], [18, 28], [29, 40], [41, 45], [46, 49], [50, 58], [59, 62], [63, 70], [71, 72], [73, 75], [75, 76], [77, 86], [87, 91], [92, 94], [95, 96], [97, 98], [98, 99], [99, 100], [100, 101], [102, 103], [104, 108], [109, 114], [115, 123], [124, 128], [128, 129], [130, 131], [132, 133], [133, 134], [135, 140], [140, 141], [142, 144], [145, 150], [150, 151], [152, 158], [159, 163], [163, 164], [164, 168], [169, 175], [176, 185], [185, 186], [187, 191], [191, 192]]}
{"doc_key": "ai-test-97", "ner": [[6, 6, "programlang"], [12, 12, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "site", "was", "originally", "based", "on", "Perl", ",", "but", "for", "security", "reasons", "IMDb", "no", "longer", "discloses", "the", "software", "it", "uses", "."], "sentence-detokenized": "The site was originally based on Perl, but for security reasons IMDb no longer discloses the software it uses.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 23], [24, 29], [30, 32], [33, 37], [37, 38], [39, 42], [43, 46], [47, 55], [56, 63], [64, 68], [69, 71], [72, 78], [79, 88], [89, 92], [93, 101], [102, 104], [105, 109], [109, 110]]}
{"doc_key": "ai-test-98", "ner": [[6, 8, "researcher"], [10, 11, "researcher"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "startup", "was", "founded", "in", "2010", "by", "Demis", "Hassabis", ",", "Shane", "Leger", "and", "Mustafa", "Suleiman", "."], "sentence-detokenized": "The startup was founded in 2010 by Demis Hassabis, Shane Leger and Mustafa Suleiman.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 26], [27, 31], [32, 34], [35, 40], [41, 49], [49, 50], [51, 56], [57, 62], [63, 66], [67, 74], [75, 83], [83, 84]]}
{"doc_key": "ai-test-99", "ner": [[3, 4, "misc"], [6, 8, "metrics"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 8, 3, 4, "type-of", "", false, false], [22, 23, 3, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "very", "common", "loss", "functions", "are", "mean", "squared", "error", ",", "mathL", "(", "a", ")", "=", "a", "^", "2", "/", "math", ",", "and", "absolute", "loss", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "/", "math", "."], "sentence-detokenized": "Two very common loss functions are mean squared error, mathL (a) = a ^ 2 / math, and absolute loss, mathL (a) = | a | / math.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 20], [21, 30], [31, 34], [35, 39], [40, 47], [48, 53], [53, 54], [55, 60], [61, 62], [62, 63], [63, 64], [65, 66], [67, 68], [69, 70], [71, 72], [73, 74], [75, 79], [79, 80], [81, 84], [85, 93], [94, 98], [98, 99], [100, 105], [106, 107], [107, 108], [108, 109], [110, 111], [112, 113], [114, 115], [116, 117], [118, 119], [120, 124], [124, 125]]}
{"doc_key": "ai-test-100", "ner": [[3, 4, "algorithm"], [12, 14, "algorithm"], [16, 18, "algorithm"], [19, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 12, 14, "type-of", "example_of", false, false], [12, 14, 19, 20, "related-to", "", false, false], [16, 18, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "soft", "edge", "support", "vector", "machine", "described", "above", "is", "an", "example", "of", "empirical", "risk", "minimisation", "(", "ERM", ")", "for", "hinge", "loss", "."], "sentence-detokenized": "The soft edge support vector machine described above is an example of empirical risk minimisation (ERM) for hinge loss.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 21], [22, 28], [29, 36], [37, 46], [47, 52], [53, 55], [56, 58], [59, 66], [67, 69], [70, 79], [80, 84], [85, 97], [98, 99], [99, 102], [102, 103], [104, 107], [108, 113], [114, 118], [118, 119]]}
{"doc_key": "ai-test-101", "ner": [[1, 4, "field"], [7, 7, "task"], [9, 11, "task"], [20, 20, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 11, 1, 4, "origin", "", false, false], [9, 11, 7, 7, "type-of", "", false, false], [20, 20, 9, 11, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "deep", "learning", "-", "based", "approach", "to", "MT", ",", "neural", "machine", "translation", "has", "made", "rapid", "progress", "in", "recent", "years", "and", "Google", "has", "announced", "that", "its", "translation", "service", "is", "now", "using", "this", "technique", "rather", "than", "the", "previous", "statistical", "approach", "."], "sentence-detokenized": "A deep learning-based approach to MT, neural machine translation has made rapid progress in recent years and Google has announced that its translation service is now using this technique rather than the previous statistical approach.", "token2charspan": [[0, 1], [2, 6], [7, 15], [15, 16], [16, 21], [22, 30], [31, 33], [34, 36], [36, 37], [38, 44], [45, 52], [53, 64], [65, 68], [69, 73], [74, 79], [80, 88], [89, 91], [92, 98], [99, 104], [105, 108], [109, 115], [116, 119], [120, 129], [130, 134], [135, 138], [139, 150], [151, 158], [159, 161], [162, 165], [166, 171], [172, 176], [177, 186], [187, 193], [194, 198], [199, 202], [203, 211], [212, 223], [224, 232], [232, 233]]}
{"doc_key": "ai-test-102", "ner": [[15, 15, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "tends", "to", "yield", "very", "large", "performance", "gains", "when", "working", "with", "large", "corpora", "such", "as", "WordNet", "."], "sentence-detokenized": "This tends to yield very large performance gains when working with large corpora such as WordNet.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 19], [20, 24], [25, 30], [31, 42], [43, 48], [49, 53], [54, 61], [62, 66], [67, 72], [73, 80], [81, 85], [86, 88], [89, 96], [96, 97]]}
{"doc_key": "ai-test-103", "ner": [[0, 1, "task"], [5, 5, "field"], [17, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 17, 20, "part-of", "", false, false], [17, 20, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Face", "detection", "is", "used", "in", "biometrics", ",", "often", "as", "part", "of", "(", "or", "in", "conjunction", "with", ")", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Face detection is used in biometrics, often as part of (or in conjunction with) a facial recognition system.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 22], [23, 25], [26, 36], [36, 37], [38, 43], [44, 46], [47, 51], [52, 54], [55, 56], [56, 58], [59, 61], [62, 73], [74, 78], [78, 79], [80, 81], [82, 88], [89, 100], [101, 107], [107, 108]]}
{"doc_key": "ai-test-104", "ner": [[2, 4, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Training", "by", "maximum", "likelihood", "estimation", "."], "sentence-detokenized": "Training by maximum likelihood estimation.", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 30], [31, 41], [41, 42]]}
{"doc_key": "ai-test-105", "ner": [[6, 13, "organisation"], [16, 17, "country"], [20, 23, "organisation"], [27, 28, "country"], [35, 35, "organisation"], [37, 41, "organisation"], [44, 46, "country"], [56, 60, "organisation"], [4, 4, "country"]], "ner_mapping_to_source": [1, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[20, 23, 27, 28, "physical", "", false, false], [37, 41, 44, 46, "physical", "", false, false], [56, 60, 4, 4, "physical", "", false, false]], "relations_mapping_to_source": [2, 3, 4], "sentence": ["Ltd.", ",", "located", "in", "Thailand", ";", "Komatsu", "(", "Shanghai", ")", "Ltd.", ",", "located", "in", "Shanghai", ",", "China", "in", "1996", ";", "Industrial", "Power", "Alliance", "Ltd.", ",", "located", "in", "Japan", "in", "1998", "as", "a", "joint", "venture", "with", "Cummins", ";", "L", "&", "T-", "Komatsu", "Ltd.", ",", "located", "in", "India", "in", "1998", "(", "shares", "sold", "in", "2013", ")", ";", "and", "Komatsu", "Brazil", "International", "Ltd", ".", "."], "sentence-detokenized": "Ltd., located in Thailand; Komatsu (Shanghai) Ltd., located in Shanghai, China in 1996; Industrial Power Alliance Ltd., located in Japan in 1998 as a joint venture with Cummins; L & T-Komatsu Ltd., located in India in 1998 (shares sold in 2013); and Komatsu Brazil International Ltd. .", "token2charspan": [[0, 4], [4, 5], [6, 13], [14, 16], [17, 25], [25, 26], [27, 34], [35, 36], [36, 44], [44, 45], [46, 50], [50, 51], [52, 59], [60, 62], [63, 71], [71, 72], [73, 78], [79, 81], [82, 86], [86, 87], [88, 98], [99, 104], [105, 113], [114, 118], [118, 119], [120, 127], [128, 130], [131, 136], [137, 139], [140, 144], [145, 147], [148, 149], [150, 155], [156, 163], [164, 168], [169, 176], [176, 177], [178, 179], [180, 181], [182, 184], [184, 191], [192, 196], [196, 197], [198, 205], [206, 208], [209, 214], [215, 217], [218, 222], [223, 224], [224, 230], [231, 235], [236, 238], [239, 243], [243, 244], [244, 245], [246, 249], [250, 257], [258, 264], [265, 278], [279, 282], [282, 283], [284, 285]]}
{"doc_key": "ai-test-106", "ner": [[1, 1, "organisation"], [5, 7, "misc"], [11, 12, "misc"], [14, 15, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 15, 1, 1, "physical", "", false, false], [14, 15, 5, 7, "general-affiliation", "", false, false], [14, 15, 11, 12, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "dgp", "also", "sometimes", "hosts", "artists", "in", "residence", "(", "such", "as", "Academy", "Award", "winner", "Chris", "Landreth", ")", "."], "sentence-detokenized": "The dgp also sometimes hosts artists in residence (such as Academy Award winner Chris Landreth).", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 22], [23, 28], [29, 36], [37, 39], [40, 49], [50, 51], [51, 55], [56, 58], [59, 66], [67, 72], [73, 79], [80, 85], [86, 94], [94, 95], [95, 96]]}
{"doc_key": "ai-test-107", "ner": [[6, 9, "misc"], [12, 14, "misc"], [17, 24, "misc"], [26, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "currently", "comprises", "four", "sub-competitions", "-", "the", "RoboMaster", "Robotics", "Competition", ",", "the", "RoboMaster", "Technology", "Challenge", ",", "the", "ICRA", "RoboMaster", "Artificial", "Intelligence", "Challenge", ",", "and", "the", "new", "RoboMaster", "Youth", "Championship", "."], "sentence-detokenized": "It currently comprises four sub-competitions - the RoboMaster Robotics Competition, the RoboMaster Technology Challenge, the ICRA RoboMaster Artificial Intelligence Challenge, and the new RoboMaster Youth Championship.", "token2charspan": [[0, 2], [3, 12], [13, 22], [23, 27], [28, 44], [45, 46], [47, 50], [51, 61], [62, 70], [71, 82], [82, 83], [84, 87], [88, 98], [99, 109], [110, 119], [119, 120], [121, 124], [125, 129], [130, 140], [141, 151], [152, 164], [165, 174], [174, 175], [176, 179], [180, 183], [184, 187], [188, 198], [199, 204], [205, 217], [217, 218]]}
{"doc_key": "ai-test-108", "ner": [[9, 10, "field"], [15, 19, "algorithm"], [23, 24, "algorithm"], [26, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 23, 24, "usage", "", false, false], [9, 10, 26, 27, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["By", "the", "beginning", "of", "the", "21st", "century", ",", "mainstream", "speech", "processing", "strategies", "began", "to", "move", "away", "from", "Hidden", "Markov", "Models", "to", "more", "modern", "neural", "networks", "and", "deep", "learning", "."], "sentence-detokenized": "By the beginning of the 21st century, mainstream speech processing strategies began to move away from Hidden Markov Models to more modern neural networks and deep learning.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 23], [24, 28], [29, 36], [36, 37], [38, 48], [49, 55], [56, 66], [67, 77], [78, 83], [84, 86], [87, 91], [92, 96], [97, 101], [102, 108], [109, 115], [116, 122], [123, 125], [126, 130], [131, 137], [138, 144], [145, 153], [154, 157], [158, 162], [163, 171], [171, 172]]}
{"doc_key": "ai-test-109", "ner": [[5, 6, "misc"], [22, 23, "metrics"], [25, 27, "metrics"], [34, 35, "metrics"], [37, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[22, 23, 25, 27, "related-to", "equal", false, false], [34, 35, 37, 39, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "the", "case", "of", "binary", "target", "rates", ",", "another", "equivalent", "expression", "is", "that", "for", "each", "value", "of", "a", "sensitive", "feature", ",", "the", "true", "positive", "and", "false", "positive", "rates", "are", "equal", "(", "and", "therefore", "the", "false", "negative", "and", "true", "negative", "rates", "are", "also", "equal", ")", "."], "sentence-detokenized": "In the case of binary target rates, another equivalent expression is that for each value of a sensitive feature, the true positive and false positive rates are equal (and therefore the false negative and true negative rates are also equal).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 21], [22, 28], [29, 34], [34, 35], [36, 43], [44, 54], [55, 65], [66, 68], [69, 73], [74, 77], [78, 82], [83, 88], [89, 91], [92, 93], [94, 103], [104, 111], [111, 112], [113, 116], [117, 121], [122, 130], [131, 134], [135, 140], [141, 149], [150, 155], [156, 159], [160, 165], [166, 167], [167, 170], [171, 180], [181, 184], [185, 190], [191, 199], [200, 203], [204, 208], [209, 217], [218, 223], [224, 227], [228, 232], [233, 238], [238, 239], [239, 240]]}
{"doc_key": "ai-test-110", "ner": [[1, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["of", "MATLAB", "functions", "."], "sentence-detokenized": "of MATLAB functions.", "token2charspan": [[0, 2], [3, 9], [10, 19], [19, 20]]}
{"doc_key": "ai-test-111", "ner": [[0, 2, "product"], [7, 10, "misc"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 10, 0, 2, "part-of", "", false, false], [16, 17, 0, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "articulated", "robot", "is", "a", "robot", "with", "rotating", "joints", "(", "e.g.", "a", "legged", "robot", "or", "an", "industrial", "robot", ")", "."], "sentence-detokenized": "An articulated robot is a robot with rotating joints (e.g. a legged robot or an industrial robot).", "token2charspan": [[0, 2], [3, 14], [15, 20], [21, 23], [24, 25], [26, 31], [32, 36], [37, 45], [46, 52], [53, 54], [54, 58], [59, 60], [61, 67], [68, 73], [74, 76], [77, 79], [80, 90], [91, 96], [96, 97], [97, 98]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [5, 6, "product"], [8, 9, "product"], [13, 13, "misc"], [17, 18, "product"], [24, 27, "misc"], [31, 31, "location"], [33, 33, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 13, 13, "general-affiliation", "nationality", false, false], [0, 0, 24, 27, "usage", "", false, false], [0, 0, 31, 31, "physical", "", false, false], [5, 6, 0, 0, "named", "", false, false], [8, 9, 0, 0, "named", "", false, false], [31, 31, 33, 33, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "also", "known", "as", "Pandora", "Media", "or", "Pandora", "Radio", ")", "is", "an", "American", "music", "streaming", "and", "auto-suggestion", "system", "Internet", "radio", "service", "powered", "by", "the", "Music", "Genome", "Project", "and", "based", "in", "Oakland", ",", "California", "."], "sentence-detokenized": "Pandora (also known as Pandora Media or Pandora Radio) is an American music streaming and auto-suggestion system Internet radio service powered by the Music Genome Project and based in Oakland, California.", "token2charspan": [[0, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 30], [31, 36], [37, 39], [40, 47], [48, 53], [53, 54], [55, 57], [58, 60], [61, 69], [70, 75], [76, 85], [86, 89], [90, 105], [106, 112], [113, 121], [122, 127], [128, 135], [136, 143], [144, 146], [147, 150], [151, 156], [157, 163], [164, 171], [172, 175], [176, 181], [182, 184], [185, 192], [192, 193], [194, 204], [204, 205]]}
{"doc_key": "ai-test-113", "ner": [[10, 15, "organisation"], [22, 25, "organisation"], [32, 33, "conference"], [44, 44, "conference"], [46, 46, "conference"], [48, 48, "conference"], [50, 50, "conference"], [52, 52, "conference"], [54, 54, "conference"], [56, 56, "conference"], [58, 58, "conference"], [60, 60, "conference"], [63, 63, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "member", "of", "the", "Board", "of", "Directors", "of", "the", "International", "Society", "for", "Machine", "Learning", ",", "has", "been", "a", "member", "of", "the", "AAAI", "Executive", "Committee", ",", "was", "PC", "Co-", "Chair", "of", "ICML", "2011", ",", "and", "has", "served", "as", "a", "senior", "PC", "member", "of", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "UAI", ",", "VLDB", ",", "WSDM", ",", "and", "WWW", "conferences", "."], "sentence-detokenized": "She is a member of the Board of Directors of the International Society for Machine Learning, has been a member of the AAAI Executive Committee, was PC Co-Chair of ICML 2011, and has served as a senior PC member of AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM, and WWW conferences.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 15], [16, 18], [19, 22], [23, 28], [29, 31], [32, 41], [42, 44], [45, 48], [49, 62], [63, 70], [71, 74], [75, 82], [83, 91], [91, 92], [93, 96], [97, 101], [102, 103], [104, 110], [111, 113], [114, 117], [118, 122], [123, 132], [133, 142], [142, 143], [144, 147], [148, 150], [151, 154], [154, 159], [160, 162], [163, 167], [168, 172], [172, 173], [174, 177], [178, 181], [182, 188], [189, 191], [192, 193], [194, 200], [201, 203], [204, 210], [211, 213], [214, 218], [218, 219], [220, 224], [224, 225], [226, 231], [231, 232], [233, 237], [237, 238], [239, 242], [242, 243], [244, 250], [250, 251], [252, 255], [255, 256], [257, 261], [261, 262], [263, 267], [267, 268], [269, 272], [273, 276], [277, 288], [288, 289]]}
{"doc_key": "ai-test-114", "ner": [[0, 2, "researcher"], [4, 10, "organisation"], [12, 14, "organisation"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 4, 10, "role", "", false, false], [12, 14, 4, 10, "named", "", false, false], [16, 16, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", "of", "the", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", "has", "developed", "Robocrane", ",", "a", "platform", "suspended", "from", "six", "cables", "rather", "than", "supported", "by", "six", "jacks", "."], "sentence-detokenized": "James S. Albus of the National Institute of Standards and Technology (NIST) has developed Robocrane, a platform suspended from six cables rather than supported by six jacks.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 17], [18, 21], [22, 30], [31, 40], [41, 43], [44, 53], [54, 57], [58, 68], [69, 70], [70, 74], [74, 75], [76, 79], [80, 89], [90, 99], [99, 100], [101, 102], [103, 111], [112, 121], [122, 126], [127, 130], [131, 137], [138, 144], [145, 149], [150, 159], [160, 162], [163, 166], [167, 172], [172, 173]]}
{"doc_key": "ai-test-115", "ner": [[3, 5, "algorithm"], [8, 9, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 3, 5, "type-of", "", false, false], [13, 14, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "class", "of", "direct", "search", "algorithms", "are", "various", "evolutionary", "algorithms", ",", "such", "as", "genetic", "algorithms", "."], "sentence-detokenized": "Another class of direct search algorithms are various evolutionary algorithms, such as genetic algorithms.", "token2charspan": [[0, 7], [8, 13], [14, 16], [17, 23], [24, 30], [31, 41], [42, 45], [46, 53], [54, 66], [67, 77], [77, 78], [79, 83], [84, 86], [87, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-test-116", "ner": [[0, 1, "organisation"], [3, 4, "misc"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 0, 1, "named", "", false, false], [6, 7, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["KUKA", "is", "a", "German", "manufacturer", "of", "industrial", "robots", "and", "factory", "automation", "solutions", "."], "sentence-detokenized": "KUKA is a German manufacturer of industrial robots and factory automation solutions.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 16], [17, 29], [30, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 73], [74, 83], [83, 84]]}
{"doc_key": "ai-test-117", "ner": [[4, 4, "misc"], [11, 12, "person"], [14, 20, "misc"], [22, 23, "person"], [25, 25, "misc"], [27, 28, "person"], [30, 31, "misc"], [33, 34, "person"], [36, 38, "misc"], [40, 42, "person"], [44, 47, "misc"], [49, 50, "person"], [53, 58, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[11, 12, 4, 4, "usage", "", false, false], [14, 20, 11, 12, "artifact", "", false, false], [22, 23, 4, 4, "usage", "", false, false], [25, 25, 22, 23, "artifact", "", false, false], [27, 28, 4, 4, "usage", "", false, false], [30, 31, 27, 28, "artifact", "", false, false], [33, 34, 4, 4, "usage", "", false, false], [36, 38, 33, 34, "artifact", "", false, false], [40, 42, 4, 4, "usage", "", false, false], [44, 47, 40, 42, "artifact", "", false, false], [49, 50, 4, 4, "usage", "", false, false], [53, 58, 49, 50, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Other", "films", "shot", "with", "IMAX", "cameras", "between", "2016", "and", "2020", "are", "Zack", "Snyder", "'s", "Batman", "v", "Superman", ":", "Dawn", "of", "Justice", ",", "Clint", "Eastwood", "'s", "Sully", ",", "Damien", "Chazelle", "'s", "First", "Man", ",", "Patty", "Jenkins", "'", "Wonder", "Woman", "1984", ",", "Cary", "Yogi", "Fukunaga", "'s", "No", "Time", "to", "Die", "and", "Joseph", "Kosinski", "'s", "The", "Greatest", "The", "High", "Roller", ".", "maverick", "."], "sentence-detokenized": "Other films shot with IMAX cameras between 2016 and 2020 are Zack Snyder's Batman v Superman: Dawn of Justice, Clint Eastwood's Sully, Damien Chazelle's First Man, Patty Jenkins' Wonder Woman 1984, Cary Yogi Fukunaga's No Time to Die and Joseph Kosinski's The Greatest The High Roller. maverick.", "token2charspan": [[0, 5], [6, 11], [12, 16], [17, 21], [22, 26], [27, 34], [35, 42], [43, 47], [48, 51], [52, 56], [57, 60], [61, 65], [66, 72], [72, 74], [75, 81], [82, 83], [84, 92], [92, 93], [94, 98], [99, 101], [102, 109], [109, 110], [111, 116], [117, 125], [125, 127], [128, 133], [133, 134], [135, 141], [142, 150], [150, 152], [153, 158], [159, 162], [162, 163], [164, 169], [170, 177], [177, 178], [179, 185], [186, 191], [192, 196], [196, 197], [198, 202], [203, 207], [208, 216], [216, 218], [219, 221], [222, 226], [227, 229], [230, 233], [234, 237], [238, 244], [245, 253], [253, 255], [256, 259], [260, 268], [269, 272], [273, 277], [278, 284], [284, 285], [286, 294], [294, 295]]}
{"doc_key": "ai-test-118", "ner": [[7, 8, "misc"], [14, 16, "organisation"], [18, 18, "organisation"], [7, 26, "misc"], [31, 34, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 7, 26, "named", "", false, false], [14, 16, 7, 8, "usage", "", false, false], [14, 16, 31, 34, "physical", "", false, false], [18, 18, 14, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "July", "1956", ",", "a", "trial", "of", "MICR", "E13B", "type", "was", "shown", "to", "the", "American", "Bankers", "Association", "(", "ABA", ")", ",", "which", "adopted", "it", "as", "the", "MICR", "standard", "for", "negotiable", "documents", "in", "the", "United", "States", "in", "1958", "."], "sentence-detokenized": "In July 1956, a trial of MICR E13B type was shown to the American Bankers Association (ABA), which adopted it as the MICR standard for negotiable documents in the United States in 1958.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 15], [16, 21], [22, 24], [25, 29], [30, 34], [35, 39], [40, 43], [44, 49], [50, 52], [53, 56], [57, 65], [66, 73], [74, 85], [86, 87], [87, 90], [90, 91], [91, 92], [93, 98], [99, 106], [107, 109], [110, 112], [113, 116], [117, 121], [122, 130], [131, 134], [135, 145], [146, 155], [156, 158], [159, 162], [163, 169], [170, 176], [177, 179], [180, 184], [184, 185]]}
{"doc_key": "ai-test-119", "ner": [[0, 2, "misc"], [15, 16, "field"], [19, 20, "field"], [23, 23, "field"], [25, 26, "field"], [28, 28, "field"], [30, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 16, 0, 2, "usage", "", false, false], [19, 20, 15, 16, "part-of", "", false, false], [23, 23, 0, 2, "usage", "", false, false], [25, 26, 0, 2, "usage", "", false, false], [28, 28, 0, 2, "usage", "", false, false], [30, 30, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Local", "search", "algorithms", "are", "widely", "used", "in", "many", "difficult", "computational", "problems", ",", "including", "those", "in", "computer", "science", "(", "especially", "artificial", "intelligence", ")", ",", "mathematics", ",", "operations", "research", ",", "engineering", "and", "bioinformatics", "."], "sentence-detokenized": "Local search algorithms are widely used in many difficult computational problems, including those in computer science (especially artificial intelligence), mathematics, operations research, engineering and bioinformatics.", "token2charspan": [[0, 5], [6, 12], [13, 23], [24, 27], [28, 34], [35, 39], [40, 42], [43, 47], [48, 57], [58, 71], [72, 80], [80, 81], [82, 91], [92, 97], [98, 100], [101, 109], [110, 117], [118, 119], [119, 129], [130, 140], [141, 153], [153, 154], [154, 155], [156, 167], [167, 168], [169, 179], [180, 188], [188, 189], [190, 201], [202, 205], [206, 220], [220, 221]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [8, 8, "location"], [10, 10, "country"], [14, 14, "country"], [22, 23, "algorithm"], [25, 25, "algorithm"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 8, 8, "physical", "", false, false], [0, 1, 14, 14, "general-affiliation", "nationality", false, false], [0, 1, 22, 23, "general-affiliation", "topic_of_study", false, false], [0, 1, 25, 25, "general-affiliation", "topic_of_study", false, false], [8, 8, 10, 10, "physical", "", false, false], [25, 25, 27, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "born", "3", "September", "1947", "in", "Wallersdorf", ",", "Germany", ")", "is", "a", "German", "psychologist", "who", "has", "studied", "the", "use", "of", "bounded", "rationality", "and", "heuristics", "in", "decision", "-", "making", "."], "sentence-detokenized": "Gerd Gigerenzer (born 3 September 1947 in Wallersdorf, Germany) is a German psychologist who has studied the use of bounded rationality and heuristics in decision-making.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 21], [22, 23], [24, 33], [34, 38], [39, 41], [42, 53], [53, 54], [55, 62], [62, 63], [64, 66], [67, 68], [69, 75], [76, 88], [89, 92], [93, 96], [97, 104], [105, 108], [109, 112], [113, 115], [116, 123], [124, 135], [136, 139], [140, 150], [151, 153], [154, 162], [162, 163], [163, 169], [169, 170]]}
{"doc_key": "ai-test-121", "ner": [[3, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["to", "minimise", "the", "mean", "squared", "error", "."], "sentence-detokenized": "to minimise the mean squared error.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 20], [21, 28], [29, 34], [34, 35]]}
{"doc_key": "ai-test-122", "ner": [[14, 15, "misc"], [17, 20, "organisation"], [34, 36, "field"], [53, 54, "misc"], [58, 60, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 15, 17, 20, "origin", "", false, false], [53, 54, 58, 60, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "even", "the", "official", "language", "with", "a", "supervisory", "institute", ",", "such", "as", "the", "standard", "French", "with", "the", "Institut", "de", "France", ",", "is", "classified", "as", "a", "natural", "language", "(", "e.g.", "in", "the", "field", "of", "natural", "language", "processing", ")", "because", "its", "prescriptive", "point", "does", "not", "make", "it", "sufficient", "to", "be", "classified", "either", "as", "a", "constructed", "language", "or", "as", "a", "controlled", "natural", "language", "."], "sentence-detokenized": "However, even the official language with a supervisory institute, such as the standard French with the Institut de France, is classified as a natural language (e.g. in the field of natural language processing) because its prescriptive point does not make it sufficient to be classified either as a constructed language or as a controlled natural language.", "token2charspan": [[0, 7], [7, 8], [9, 13], [14, 17], [18, 26], [27, 35], [36, 40], [41, 42], [43, 54], [55, 64], [64, 65], [66, 70], [71, 73], [74, 77], [78, 86], [87, 93], [94, 98], [99, 102], [103, 111], [112, 114], [115, 121], [121, 122], [123, 125], [126, 136], [137, 139], [140, 141], [142, 149], [150, 158], [159, 160], [160, 164], [165, 167], [168, 171], [172, 177], [178, 180], [181, 188], [189, 197], [198, 208], [208, 209], [210, 217], [218, 221], [222, 234], [235, 240], [241, 245], [246, 249], [250, 254], [255, 257], [258, 268], [269, 271], [272, 274], [275, 285], [286, 292], [293, 295], [296, 297], [298, 309], [310, 318], [319, 321], [322, 324], [325, 326], [327, 337], [338, 345], [346, 354], [354, 355]]}
{"doc_key": "ai-test-123", "ner": [[8, 8, "metrics"], [10, 10, "metrics"], [12, 12, "metrics"], [30, 30, "metrics"], [32, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 10, 10, "named", "", false, false], [32, 32, 30, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "other", "metrics", ",", "the", "simplest", "being", "accuracy", "or", "correctness", "(", "FC", ")", ",", "which", "measures", "the", "fraction", "of", "all", "instances", "that", "are", "correctly", "categorised", ";", "complementing", "this", "is", "incorrectness", "(", "FiC", ")", "."], "sentence-detokenized": "There are other metrics, the simplest being accuracy or correctness (FC), which measures the fraction of all instances that are correctly categorised; complementing this is incorrectness (FiC).", "token2charspan": [[0, 5], [6, 9], [10, 15], [16, 23], [23, 24], [25, 28], [29, 37], [38, 43], [44, 52], [53, 55], [56, 67], [68, 69], [69, 71], [71, 72], [72, 73], [74, 79], [80, 88], [89, 92], [93, 101], [102, 104], [105, 108], [109, 118], [119, 123], [124, 127], [128, 137], [138, 149], [149, 150], [151, 164], [165, 169], [170, 172], [173, 186], [187, 188], [188, 191], [191, 192], [192, 193]]}
{"doc_key": "ai-test-124", "ner": [[0, 0, "researcher"], [5, 9, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 9, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cadi", "became", "a", "Fellow", "of", "the", "Association", "for", "Computational", "Linguistics", "in", "2016", "."], "sentence-detokenized": "Cadi became a Fellow of the Association for Computational Linguistics in 2016.", "token2charspan": [[0, 4], [5, 11], [12, 13], [14, 20], [21, 23], [24, 27], [28, 39], [40, 43], [44, 57], [58, 69], [70, 72], [73, 77], [77, 78]]}
{"doc_key": "ai-test-125", "ner": [[12, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Learning", "the", "parameter", "math", "/", "theta", "/", "math", "is", "usually", "done", "by", "maximum", "likelihood", "learning", "of", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i;/", "theta", ")", "/math", "."], "sentence-detokenized": "Learning the parameter math/theta/math is usually done by maximum likelihood learning of mathp(Y _ i | X _ i;/theta)/math.", "token2charspan": [[0, 8], [9, 12], [13, 22], [23, 27], [27, 28], [28, 33], [33, 34], [34, 38], [39, 41], [42, 49], [50, 54], [55, 57], [58, 65], [66, 76], [77, 85], [86, 88], [89, 94], [94, 95], [95, 96], [97, 98], [99, 100], [101, 102], [103, 104], [105, 106], [107, 110], [110, 115], [115, 116], [116, 121], [121, 122]]}
{"doc_key": "ai-test-126", "ner": [[0, 1, "task"], [4, 6, "algorithm"], [8, 9, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 0, 1, "usage", "", true, false], [8, 9, 4, 6, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cluster", "analysis", ",", "and", "non-negative", "matrix", "decomposition", "for", "descriptive", "mining", "."], "sentence-detokenized": "Cluster analysis, and non-negative matrix decomposition for descriptive mining.", "token2charspan": [[0, 7], [8, 16], [16, 17], [18, 21], [22, 34], [35, 41], [42, 55], [56, 59], [60, 71], [72, 78], [78, 79]]}
{"doc_key": "ai-test-127", "ner": [[20, 21, "field"], [19, 25, "field"], [4, 6, "field"], [8, 9, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 20, 21, "part-of", "", false, false], [4, 6, 19, 25, "part-of", "", false, false], [8, 9, 20, 21, "part-of", "", false, false], [8, 9, 19, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "ability", "to", "perform", "natural", "language", "processing", "and", "machine", "learning", "in", "computers", "has", "been", "a", "long", "-", "standing", "challenge", "in", "computer", "science", "and", "the", "information", "technology", "it", "enables", "."], "sentence-detokenized": "The ability to perform natural language processing and machine learning in computers has been a long-standing challenge in computer science and the information technology it enables.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 30], [31, 39], [40, 50], [51, 54], [55, 62], [63, 71], [72, 74], [75, 84], [85, 88], [89, 93], [94, 95], [96, 100], [100, 101], [101, 109], [110, 119], [120, 122], [123, 131], [132, 139], [140, 143], [144, 147], [148, 159], [160, 170], [171, 173], [174, 181], [181, 182]]}
{"doc_key": "ai-test-128", "ner": [[3, 6, "algorithm"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 6, 10, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "The", "code", "for", "extracting", "Gabor", "features", "from", "images", "in", "MATLAB", "can", "be", "found", "at"], "sentence-detokenized": "(The code for extracting Gabor features from images in MATLAB can be found at", "token2charspan": [[0, 1], [1, 4], [5, 9], [10, 13], [14, 24], [25, 30], [31, 39], [40, 44], [45, 51], [52, 54], [55, 61], [62, 65], [66, 68], [69, 74], [75, 77]]}
{"doc_key": "ai-test-129", "ner": [[0, 1, "misc"], [11, 14, "algorithm"], [17, 17, "task"], [19, 19, "task"], [21, 22, "task"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 11, 14, "general-affiliation", "", false, false], [0, 1, 17, 17, "related-to", "solves_problem_of_type", false, false], [0, 1, 19, 19, "related-to", "solves_problem_of_type", false, false], [0, 1, 21, 22, "related-to", "solves_problem_of_type", false, false], [0, 1, 24, 25, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["NeuralExpert", "is", "designed", "around", "the", "type", "of", "problem", "the", "user", "wants", "the", "neural", "network", "to", "solve", "(", "classification", ",", "prediction", ",", "function", "approximation", "or", "cluster", "analysis", ")", "."], "sentence-detokenized": "NeuralExpert is designed around the type of problem the user wants the neural network to solve (classification, prediction, function approximation or cluster analysis).", "token2charspan": [[0, 12], [13, 15], [16, 24], [25, 31], [32, 35], [36, 40], [41, 43], [44, 51], [52, 55], [56, 60], [61, 66], [67, 70], [71, 77], [78, 85], [86, 88], [89, 94], [95, 96], [96, 110], [110, 111], [112, 122], [122, 123], [124, 132], [133, 146], [147, 149], [150, 157], [158, 166], [166, 167], [167, 168]]}
{"doc_key": "ai-test-130", "ner": [[2, 3, "misc"], [27, 29, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "quantization", "step", "(", "\u0394", ")", "is", "small", "relative", "to", "the", "change", "in", "the", "signal", "being", "quantized", ",", "it", "is", "relatively", "simple", "to", "show", "that", "the", "mean", "squared", "error", "resulting", "from", "this", "rounding", "operation", "will", "be", "approximately", "math", "\\", "Delta", "^", "2", "/", "12", "/", "math.math", "."], "sentence-detokenized": "When the quantization step (\u0394) is small relative to the change in the signal being quantized, it is relatively simple to show that the mean squared error resulting from this rounding operation will be approximately math\\ Delta ^ 2 / 12 / math.math.", "token2charspan": [[0, 4], [5, 8], [9, 21], [22, 26], [27, 28], [28, 29], [29, 30], [31, 33], [34, 39], [40, 48], [49, 51], [52, 55], [56, 62], [63, 65], [66, 69], [70, 76], [77, 82], [83, 92], [92, 93], [94, 96], [97, 99], [100, 110], [111, 117], [118, 120], [121, 125], [126, 130], [131, 134], [135, 139], [140, 147], [148, 153], [154, 163], [164, 168], [169, 173], [174, 182], [183, 192], [193, 197], [198, 200], [201, 214], [215, 219], [219, 220], [221, 226], [227, 228], [229, 230], [231, 232], [233, 235], [236, 237], [238, 247], [247, 248]]}
{"doc_key": "ai-test-131", "ner": [[17, 17, "product"], [26, 30, "researcher"], [32, 33, "researcher"], [35, 37, "researcher"], [39, 40, "researcher"], [42, 44, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Building", "rich", "thesauri", "with", "suitable", "ontologies", "requires", "a", "great", "deal", "of", "effort", ";", "for", "example", ",", "the", "Wordnet", "thesaurus", "required", "many", "human", "years", "of", "effort", ".", "g", ".", "A", ".", "Miller", ",", "R.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Gross", ",", "K", ".", "Miller", "."], "sentence-detokenized": "Building rich thesauri with suitable ontologies requires a great deal of effort; for example, the Wordnet thesaurus required many human years of effort. g. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 27], [28, 36], [37, 47], [48, 56], [57, 58], [59, 64], [65, 69], [70, 72], [73, 79], [79, 80], [81, 84], [85, 92], [92, 93], [94, 97], [98, 105], [106, 115], [116, 124], [125, 129], [130, 135], [136, 141], [142, 144], [145, 151], [151, 152], [153, 154], [154, 155], [156, 157], [157, 158], [159, 165], [165, 166], [167, 169], [170, 178], [178, 179], [180, 182], [183, 185], [186, 194], [194, 195], [196, 198], [199, 204], [204, 205], [206, 207], [207, 208], [209, 215], [215, 216]]}
{"doc_key": "ai-test-132", "ner": [[0, 0, "organisation"], [20, 21, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 21, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Kawasaki", "'s", "portfolio", "also", "includes", "retractable", "roofs", ",", "floors", "and", "other", "giant", "structures", ",", "an", "example", "of", "which", "is", "the", "Sapporo", "Dome", "'", "retractable", "surface", "."], "sentence-detokenized": "Kawasaki's portfolio also includes retractable roofs, floors and other giant structures, an example of which is the Sapporo Dome' retractable surface.", "token2charspan": [[0, 8], [8, 10], [11, 20], [21, 25], [26, 34], [35, 46], [47, 52], [52, 53], [54, 60], [61, 64], [65, 70], [71, 76], [77, 87], [87, 88], [89, 91], [92, 99], [100, 102], [103, 108], [109, 111], [112, 115], [116, 123], [124, 128], [128, 129], [130, 141], [142, 149], [149, 150]]}
{"doc_key": "ai-test-133", "ner": [[0, 1, "metrics"], [5, 7, "metrics"], [9, 11, "metrics"], [17, 18, "metrics"], [43, 43, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 17, 18, "related-to", "", false, false], [0, 1, 43, 43, "opposite", "alternative_to", false, false], [5, 7, 0, 1, "type-of", "", false, false], [9, 11, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kappa", "statistics", ",", "such", "as", "Fleiss", "'", "kappa", "and", "Cohen", "'s", "kappa", ",", "are", "methods", "of", "calculating", "inter-rater", "reliability", "based", "on", "different", "assumptions", "about", "marginal", "or", "prior", "distributions", ",", "and", "are", "increasingly", "used", "in", "other", "contexts", "as", "an", "alternative", "to", "chance", "-", "corrected", "accuracy", "."], "sentence-detokenized": "Kappa statistics, such as Fleiss' kappa and Cohen's kappa, are methods of calculating inter-rater reliability based on different assumptions about marginal or prior distributions, and are increasingly used in other contexts as an alternative to chance-corrected accuracy.", "token2charspan": [[0, 5], [6, 16], [16, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 39], [40, 43], [44, 49], [49, 51], [52, 57], [57, 58], [59, 62], [63, 70], [71, 73], [74, 85], [86, 97], [98, 109], [110, 115], [116, 118], [119, 128], [129, 140], [141, 146], [147, 155], [156, 158], [159, 164], [165, 178], [178, 179], [180, 183], [184, 187], [188, 200], [201, 205], [206, 208], [209, 214], [215, 223], [224, 226], [227, 229], [230, 241], [242, 244], [245, 251], [251, 252], [252, 261], [262, 270], [270, 271]]}
{"doc_key": "ai-test-134", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [18, 19, "researcher"], [22, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 18, 19, "role", "student_of", false, false], [7, 8, 18, 19, "role", "student_of", false, false], [10, 11, 18, 19, "role", "student_of", false, false], [13, 14, 18, 19, "role", "student_of", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Together", "with", "his", "students", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Graves", "and", "others", ",", "Schmidt", "Huber", "has", "published", "an", "increasingly", "A", "more", "complex", "version", "."], "sentence-detokenized": "Together with his students Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Graves and others, Schmidt Huber has published an increasingly A more complex version.", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 26], [27, 31], [32, 42], [42, 43], [44, 49], [50, 54], [54, 55], [56, 60], [61, 68], [68, 69], [70, 74], [75, 81], [82, 85], [86, 92], [92, 93], [94, 101], [102, 107], [108, 111], [112, 121], [122, 124], [125, 137], [138, 139], [140, 144], [145, 152], [153, 160], [160, 161]]}
{"doc_key": "ai-test-135", "ner": [[4, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "The", "first", "Cobot", "KUKA", "LBR", "3", "is", "launched", "."], "sentence-detokenized": "2004 - The first Cobot KUKA LBR 3 is launched.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 16], [17, 22], [23, 27], [28, 31], [32, 33], [34, 36], [37, 45], [45, 46]]}
{"doc_key": "ai-test-136", "ner": [[10, 13, "algorithm"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Two", "superficial", "methods", "used", "to", "train", "and", "then", "disambiguate", "are", "the", "Naive", "Bayes", "classifier", "and", "the", "decision", "tree", "."], "sentence-detokenized": "Two superficial methods used to train and then disambiguate are the Naive Bayes classifier and the decision tree.", "token2charspan": [[0, 3], [4, 15], [16, 23], [24, 28], [29, 31], [32, 37], [38, 41], [42, 46], [47, 59], [60, 63], [64, 67], [68, 73], [74, 79], [80, 90], [91, 94], [95, 98], [99, 107], [108, 112], [112, 113]]}
{"doc_key": "ai-test-137", "ner": [[5, 6, "misc"], [9, 10, "person"], [11, 14, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 9, 10, "origin", "", false, false], [5, 6, 11, 14, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "practical", "forms", "of", "photography", "were", "introduced", "by", "Louis", "Daguerre", "and", "Henry", "Fox", "Talbot", "in", "January", "1839", "."], "sentence-detokenized": "The first practical forms of photography were introduced by Louis Daguerre and Henry Fox Talbot in January 1839.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 25], [26, 28], [29, 40], [41, 45], [46, 56], [57, 59], [60, 65], [66, 74], [75, 78], [79, 84], [85, 88], [89, 95], [96, 98], [99, 106], [107, 111], [111, 112]]}
{"doc_key": "ai-test-138", "ner": [[3, 4, "task"], [7, 8, "task"], [19, 20, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 19, 20, "part-of", "task_part_of_field", false, false], [7, 8, 19, 20, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "speech", "synthesis", "combined", "with", "speech", "recognition", "can", "be", "used", "to", "interact", "with", "mobile", "devices", "through", "a", "language", "processing", "interface", "."], "sentence-detokenized": "For example, speech synthesis combined with speech recognition can be used to interact with mobile devices through a language processing interface.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 19], [20, 29], [30, 38], [39, 43], [44, 50], [51, 62], [63, 66], [67, 69], [70, 74], [75, 77], [78, 86], [87, 91], [92, 98], [99, 106], [107, 114], [115, 116], [117, 125], [126, 136], [137, 146], [146, 147]]}
{"doc_key": "ai-test-139", "ner": [[0, 0, "product"], [14, 14, "programlang"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 14, 14, "general-affiliation", "", false, false], [0, 0, 16, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Phidgets", "can", "be", "programmed", "using", "a", "variety", "of", "software", "and", "programming", "languages", ",", "from", "Java", "to", "Microsoft", "Excel", "."], "sentence-detokenized": "Phidgets can be programmed using a variety of software and programming languages, from Java to Microsoft Excel.", "token2charspan": [[0, 8], [9, 12], [13, 15], [16, 26], [27, 32], [33, 34], [35, 42], [43, 45], [46, 54], [55, 58], [59, 70], [71, 80], [80, 81], [82, 86], [87, 91], [92, 94], [95, 104], [105, 110], [110, 111]]}
{"doc_key": "ai-test-140", "ner": [[2, 4, "field"], [9, 12, "researcher"], [13, 16, "misc"], [24, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 9, 12, "origin", "", false, false], [9, 12, 24, 25, "general-affiliation", "topic_of_study", false, false], [9, 12, 27, 28, "general-affiliation", "topic_of_study", false, false], [13, 16, 9, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "machine", "learning", "was", "coined", "in", "1959", "by", "Arthur", "Samuel", ",", "an", "American", "employee", "of", "IBM", "and", "a", "pioneer", "in", "the", "field", "of", "computer", "games", "and", "artificial", "intelligence", "."], "sentence-detokenized": "The term machine learning was coined in 1959 by Arthur Samuel, an American employee of IBM and a pioneer in the field of computer games and artificial intelligence.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 25], [26, 29], [30, 36], [37, 39], [40, 44], [45, 47], [48, 54], [55, 61], [61, 62], [63, 65], [66, 74], [75, 83], [84, 86], [87, 90], [91, 94], [95, 96], [97, 104], [105, 107], [108, 111], [112, 117], [118, 120], [121, 129], [130, 135], [136, 139], [140, 150], [151, 163], [163, 164]]}
{"doc_key": "ai-test-141", "ner": [[12, 13, "misc"], [14, 14, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 14, 12, 13, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Fascinated", "by", "the", "future", "of", "technology", "and", "its", "relationship", "to", "art", ",", "Israeli", "poet", "David", "Avidan", "wants", "to", "explore", "the", "use", "of", "computers", "for", "literary", "creation", "."], "sentence-detokenized": "Fascinated by the future of technology and its relationship to art, Israeli poet David Avidan wants to explore the use of computers for literary creation.", "token2charspan": [[0, 10], [11, 13], [14, 17], [18, 24], [25, 27], [28, 38], [39, 42], [43, 46], [47, 59], [60, 62], [63, 66], [66, 67], [68, 75], [76, 80], [81, 86], [87, 93], [94, 99], [100, 102], [103, 110], [111, 114], [115, 118], [119, 121], [122, 131], [132, 135], [136, 144], [145, 153], [153, 154]]}
{"doc_key": "ai-test-142", "ner": [[5, 6, "misc"], [8, 8, "organisation"], [17, 17, "location"], [26, 27, "location"], [28, 29, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 8, 5, 6, "part-of", "", false, false], [28, 29, 26, 27, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "part", "of", "the", "2017", "GATEway", "project", ",", "Oxbotica", "trialled", "seven", "self", "-", "driving", "shuttle", "buses", "in", "Greenwich", "on", "a", "two", "-", "mile", "riverside", "path", "near", "London", "'s", "O2", "Arena", ",", "which", "is", "also", "used", "by", "pedestrians", "and", "cyclists", "."], "sentence-detokenized": "As part of the 2017 GATEway project, Oxbotica trialled seven self-driving shuttle buses in Greenwich on a two-mile riverside path near London's O2 Arena, which is also used by pedestrians and cyclists.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 19], [20, 27], [28, 35], [35, 36], [37, 45], [46, 54], [55, 60], [61, 65], [65, 66], [66, 73], [74, 81], [82, 87], [88, 90], [91, 100], [101, 103], [104, 105], [106, 109], [109, 110], [110, 114], [115, 124], [125, 129], [130, 134], [135, 141], [141, 143], [144, 146], [147, 152], [152, 153], [154, 159], [160, 162], [163, 167], [168, 172], [173, 175], [176, 187], [188, 191], [192, 200], [200, 201]]}
{"doc_key": "ai-test-143", "ner": [[10, 11, "task"], [14, 16, "metrics"], [21, 22, "misc"], [28, 33, "metrics"], [35, 35, "metrics"], [37, 39, "metrics"], [42, 42, "metrics"], [30, 44, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 5, 6, 7, 8, 9], "relations": [[14, 16, 21, 22, "related-to", "is_a", false, false], [28, 33, 42, 42, "opposite", "", false, false], [28, 33, 30, 44, "opposite", "", false, false], [35, 35, 28, 33, "named", "", false, false], [37, 39, 28, 33, "named", "", false, false]], "relations_mapping_to_source": [0, 5, 6, 7, 8], "sentence": ["An", "unrelated", "but", "commonly", "used", "combination", "of", "basic", "statistics", "for", "information", "retrieval", "is", "the", "F", "-", "score", ",", "which", "is", "the", "harmonic", "mean", "(", "possibly", "weighted", ")", "of", "recall", "and", "precision", ",", "where", "recall", "=", "sensitivity", "=", "true", "positive", "rate", ",", "but", "specificity", "and", "precision", "are", "completely", "different", "measures", "."], "sentence-detokenized": "An unrelated but commonly used combination of basic statistics for information retrieval is the F-score, which is the harmonic mean (possibly weighted) of recall and precision, where recall = sensitivity = true positive rate, but specificity and precision are completely different measures.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 25], [26, 30], [31, 42], [43, 45], [46, 51], [52, 62], [63, 66], [67, 78], [79, 88], [89, 91], [92, 95], [96, 97], [97, 98], [98, 103], [103, 104], [105, 110], [111, 113], [114, 117], [118, 126], [127, 131], [132, 133], [133, 141], [142, 150], [150, 151], [152, 154], [155, 161], [162, 165], [166, 175], [175, 176], [177, 182], [183, 189], [190, 191], [192, 203], [204, 205], [206, 210], [211, 219], [220, 224], [224, 225], [226, 229], [230, 241], [242, 245], [246, 255], [256, 259], [260, 270], [271, 280], [281, 289], [289, 290]]}
{"doc_key": "ai-test-144", "ner": [[0, 3, "field"], [10, 10, "field"], [12, 12, "field"], [14, 14, "field"], [16, 17, "field"], [19, 20, "field"], [28, 29, "product"], [31, 34, "product"], [36, 37, "product"], [39, 40, "product"], [50, 52, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 3, 10, 10, "origin", "takes_inspiration_from", false, false], [0, 3, 12, 12, "origin", "takes_inspiration_from", false, false], [0, 3, 14, 14, "origin", "takes_inspiration_from", false, false], [0, 3, 16, 17, "origin", "takes_inspiration_from", false, false], [0, 3, 19, 20, "origin", "takes_inspiration_from", false, false], [28, 29, 0, 3, "origin", "", false, false], [31, 34, 0, 3, "origin", "", false, false], [36, 37, 0, 3, "origin", "", false, false], [39, 40, 0, 3, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Neuromorphic", "engineering", "is", "an", "interdisciplinary", "discipline", "that", "draws", "inspiration", "from", "biology", ",", "physics", ",", "mathematics", ",", "computer", "science", "and", "electrical", "engineering", "to", "design", "artificial", "neural", "systems", "such", "as", "vision", "systems", ",", "head", "-", "eye", "systems", ",", "auditory", "processors", "and", "autonomous", "robots", "whose", "physical", "structures", "and", "design", "principles", "are", "based", "on", "biological", "neural", "systems", "."], "sentence-detokenized": "Neuromorphic engineering is an interdisciplinary discipline that draws inspiration from biology, physics, mathematics, computer science and electrical engineering to design artificial neural systems such as vision systems, head-eye systems, auditory processors and autonomous robots whose physical structures and design principles are based on biological neural systems.", "token2charspan": [[0, 12], [13, 24], [25, 27], [28, 30], [31, 48], [49, 59], [60, 64], [65, 70], [71, 82], [83, 87], [88, 95], [95, 96], [97, 104], [104, 105], [106, 117], [117, 118], [119, 127], [128, 135], [136, 139], [140, 150], [151, 162], [163, 165], [166, 172], [173, 183], [184, 190], [191, 198], [199, 203], [204, 206], [207, 213], [214, 221], [221, 222], [223, 227], [227, 228], [228, 231], [232, 239], [239, 240], [241, 249], [250, 260], [261, 264], [265, 275], [276, 282], [283, 288], [289, 297], [298, 308], [309, 312], [313, 319], [320, 330], [331, 334], [335, 340], [341, 343], [344, 354], [355, 361], [362, 369], [369, 370]]}
{"doc_key": "ai-test-145", "ner": [[2, 5, "metrics"], [9, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 9, 2, 5, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Specifically", ",", "the", "BIBO", "stability", "guidelines", "require", "that", "the", "ROC", "of", "the", "system", "includes", "the", "unit", "circle", "."], "sentence-detokenized": "Specifically, the BIBO stability guidelines require that the ROC of the system includes the unit circle.", "token2charspan": [[0, 12], [12, 13], [14, 17], [18, 22], [23, 32], [33, 43], [44, 51], [52, 56], [57, 60], [61, 64], [65, 67], [68, 71], [72, 78], [79, 87], [88, 91], [92, 96], [97, 103], [103, 104]]}
{"doc_key": "ai-test-146", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "The", "program", "was", "rewritten", "in", "Java", "starting", "in", "1998", "."], "sentence-detokenized": "2 The program was rewritten in Java starting in 1998.", "token2charspan": [[0, 1], [2, 5], [6, 13], [14, 17], [18, 27], [28, 30], [31, 35], [36, 44], [45, 47], [48, 52], [52, 53]]}
{"doc_key": "ai-test-147", "ner": [[1, 1, "metrics"], [7, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 7, 9, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "MCC", "can", "be", "calculated", "directly", "from", "the", "confusion", "matrix", "using", "the", "formula"], "sentence-detokenized": "The MCC can be calculated directly from the confusion matrix using the formula", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 25], [26, 34], [35, 39], [40, 43], [44, 53], [54, 60], [61, 66], [67, 70], [71, 78]]}
{"doc_key": "ai-test-148", "ner": [[7, 14, "organisation"], [21, 25, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 14, 21, 25, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "developed", "by", "a", "team", "at", "the", "MIT", "-", "IBM", "Watson", "Artificial", "Intelligence", "Lab", "and", "first", "presented", "at", "the", "2018", "International", "Conference", "on", "Learning", "Representations", "."], "sentence-detokenized": "It was developed by a team at the MIT-IBM Watson Artificial Intelligence Lab and first presented at the 2018 International Conference on Learning Representations.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 29], [30, 33], [34, 37], [37, 38], [38, 41], [42, 48], [49, 59], [60, 72], [73, 76], [77, 80], [81, 86], [87, 96], [97, 99], [100, 103], [104, 108], [109, 122], [123, 133], [134, 136], [137, 145], [146, 161], [161, 162]]}
{"doc_key": "ai-test-149", "ner": [[2, 5, "metrics"], [15, 16, "metrics"], [46, 46, "metrics"], [48, 48, "metrics"], [56, 58, "metrics"], [59, 59, "metrics"], [61, 61, "metrics"], [18, 66, "metrics"], [71, 71, "metrics"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8, 9], "relations": [[15, 16, 46, 46, "type-of", "", false, false], [15, 16, 56, 58, "related-to", "collapses_to_identity", false, false], [59, 59, 71, 71, "related-to", "collapses_to_identity", false, false], [61, 61, 71, 71, "related-to", "collapses_to_identity", false, false], [18, 66, 71, 71, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [0, 1, 5, 6, 7], "sentence": ["When", "the", "true", "prevalence", "of", "the", "two", "positive", "variables", "are", "equal", "as", "assumed", "by", "the", "Fleiss", "kappa", "and", "F", "-", "score", ",", "i.e.", "the", "number", "of", "positive", "predictions", "matches", "the", "number", "of", "positive", "categories", "in", "the", "dichotomous", "(", "two", "-", "category", ")", "case", ",", "the", "different", "kappa", "and", "correlation", "measures", "collapse", "in", "the", "same", "way", "as", "Youden", "'s", "J.", "Recall", ",", "precision", "and", "F", "-", "score", "are", "likewise", "the", "same", "as", "accuracy", "."], "sentence-detokenized": "When the true prevalence of the two positive variables are equal as assumed by the Fleiss kappa and F-score, i.e. the number of positive predictions matches the number of positive categories in the dichotomous (two-category) case, the different kappa and correlation measures collapse in the same way as Youden's J. Recall, precision and F-score are likewise the same as accuracy.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 24], [25, 27], [28, 31], [32, 35], [36, 44], [45, 54], [55, 58], [59, 64], [65, 67], [68, 75], [76, 78], [79, 82], [83, 89], [90, 95], [96, 99], [100, 101], [101, 102], [102, 107], [107, 108], [109, 113], [114, 117], [118, 124], [125, 127], [128, 136], [137, 148], [149, 156], [157, 160], [161, 167], [168, 170], [171, 179], [180, 190], [191, 193], [194, 197], [198, 209], [210, 211], [211, 214], [214, 215], [215, 223], [223, 224], [225, 229], [229, 230], [231, 234], [235, 244], [245, 250], [251, 254], [255, 266], [267, 275], [276, 284], [285, 287], [288, 291], [292, 296], [297, 300], [301, 303], [304, 310], [310, 312], [313, 315], [316, 322], [322, 323], [324, 333], [334, 337], [338, 339], [339, 340], [340, 345], [346, 349], [350, 358], [359, 362], [363, 367], [368, 370], [371, 379], [379, 380]]}
{"doc_key": "ai-test-150", "ner": [[2, 5, "misc"], [7, 7, "misc"], [0, 0, "conference"], [13, 16, "task"], [17, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 5, 0, 0, "part-of", "", false, false], [2, 5, 0, 0, "physical", "", false, false], [2, 5, 0, 0, "temporal", "", false, false], [7, 7, 2, 5, "named", "", false, false], [13, 16, 2, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["NAACL", "'s", "Building", "Educational", "Applications", "Workshop", "(", "BEA", ")", "2013", "hosted", "the", "inaugural", "NLI", "Shared", "Task", ".", "tetreault", "et", "al", ".", "2013", "The", "competition", "generated", "29", "participating", "teams", "from", "around", "the", "world", ",", "24", "of", "which", "also", "published", "a", "paper", "describing", "their", "systems", "and", "methods", "."], "sentence-detokenized": "NAACL's Building Educational Applications Workshop (BEA) 2013 hosted the inaugural NLI Shared Task. tetreault et al. 2013 The competition generated 29 participating teams from around the world, 24 of which also published a paper describing their systems and methods.", "token2charspan": [[0, 5], [5, 7], [8, 16], [17, 28], [29, 41], [42, 50], [51, 52], [52, 55], [55, 56], [57, 61], [62, 68], [69, 72], [73, 82], [83, 86], [87, 93], [94, 98], [98, 99], [100, 109], [110, 112], [113, 115], [115, 116], [117, 121], [122, 125], [126, 137], [138, 147], [148, 150], [151, 164], [165, 170], [171, 175], [176, 182], [183, 186], [187, 192], [192, 193], [194, 196], [197, 199], [200, 205], [206, 210], [211, 220], [221, 222], [223, 228], [229, 239], [240, 245], [246, 253], [254, 257], [258, 265], [265, 266]]}
{"doc_key": "ai-test-151", "ner": [[0, 2, "algorithm"], [5, 7, "algorithm"], [15, 16, "misc"], [27, 28, "misc"], [35, 35, "misc"], [39, 40, "algorithm"], [43, 43, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 5, 7, "type-of", "", false, false], [0, 2, 15, 16, "related-to", "finds", false, false], [27, 28, 15, 16, "type-of", "", false, false], [43, 43, 39, 40, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Viterbi", "algorithm", "is", "a", "dynamic", "programming", "algorithm", "for", "finding", "the", "most", "likely", "sequence", "of", "hidden", "states", "leading", "to", "an", "observed", "sequence", "of", "events", ",", "called", "a", "Viterbi", "path", ",", "especially", "in", "the", "context", "of", "Markovian", "information", "sources", "and", "Hidden", "Markov", "Models", "(", "HMM", ")", "."], "sentence-detokenized": "The Viterbi algorithm is a dynamic programming algorithm for finding the most likely sequence of hidden states leading to an observed sequence of events, called a Viterbi path, especially in the context of Markovian information sources and Hidden Markov Models (HMM).", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 24], [25, 26], [27, 34], [35, 46], [47, 56], [57, 60], [61, 68], [69, 72], [73, 77], [78, 84], [85, 93], [94, 96], [97, 103], [104, 110], [111, 118], [119, 121], [122, 124], [125, 133], [134, 142], [143, 145], [146, 152], [152, 153], [154, 160], [161, 162], [163, 170], [171, 175], [175, 176], [177, 187], [188, 190], [191, 194], [195, 202], [203, 205], [206, 215], [216, 227], [228, 235], [236, 239], [240, 246], [247, 253], [254, 260], [261, 262], [262, 265], [265, 266], [266, 267]]}
{"doc_key": "ai-test-152", "ner": [[1, 1, "field"], [3, 5, "algorithm"], [8, 9, "misc"], [12, 13, "algorithm"], [16, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 1, 1, "part-of", "", false, false], [3, 5, 8, 9, "general-affiliation", "", false, false], [3, 5, 12, 13, "related-to", "generalizes_from", false, false], [3, 5, 16, 18, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "statistics", ",", "polynomial", "logistic", "regression", "is", "a", "classification", "method", "that", "generalises", "logistic", "regression", "to", "a", "multi", "-class", "classification", ",", "i.e.", "there", "are", "more", "than", "two", "possible", "discrete", "outcomes", "."], "sentence-detokenized": "In statistics, polynomial logistic regression is a classification method that generalises logistic regression to a multi-class classification, i.e. there are more than two possible discrete outcomes.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 25], [26, 34], [35, 45], [46, 48], [49, 50], [51, 65], [66, 72], [73, 77], [78, 89], [90, 98], [99, 109], [110, 112], [113, 114], [115, 120], [120, 126], [127, 141], [141, 142], [143, 147], [148, 153], [154, 157], [158, 162], [163, 167], [168, 171], [172, 180], [181, 189], [190, 198], [198, 199]]}
{"doc_key": "ai-test-153", "ner": [[0, 5, "algorithm"], [10, 11, "field"], [13, 15, "field"], [19, 19, "task"], [21, 22, "task"], [24, 25, "task"], [27, 28, "researcher"], [30, 31, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 5, 10, 11, "part-of", "", false, false], [0, 5, 13, 15, "part-of", "", false, false], [19, 19, 0, 5, "usage", "", true, false], [21, 22, 0, 5, "usage", "", true, false], [24, 25, 0, 5, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hidden", "Markov", "models", "are", "well", "known", "for", "their", "applications", "in", "reinforcement", "learning", "and", "temporal", "pattern", "recognition", ",", "such", "as", "speech", ",", "handwriting", "recognition", ",", "gesture", "recognition", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Hidden Markov models are well known for their applications in reinforcement learning and temporal pattern recognition, such as speech, handwriting recognition, gesture recognition, Thad Starner, Alex Pentland.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 29], [30, 35], [36, 39], [40, 45], [46, 58], [59, 61], [62, 75], [76, 84], [85, 88], [89, 97], [98, 105], [106, 117], [117, 118], [119, 123], [124, 126], [127, 133], [133, 134], [135, 146], [147, 158], [158, 159], [160, 167], [168, 179], [179, 180], [181, 185], [186, 193], [193, 194], [195, 199], [200, 208], [208, 209]]}
{"doc_key": "ai-test-154", "ner": [[10, 12, "misc"], [35, 38, "metrics"], [40, 42, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 12, 40, 42, "named", "", false, false], [35, 38, 40, 42, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "essence", ",", "this", "means", "that", "if", "more", "than", "k", "turn", "-", "grams", "have", "been", "seen", "in", "training", ",", "then", "the", "conditional", "probability", "of", "a", "word", ",", "given", "its", "history", ",", "is", "proportional", "to", "the", "maximum", "likelihood", "estimate", "for", "that", "n", "-", "gram", "."], "sentence-detokenized": "In essence, this means that if more than k turn-grams have been seen in training, then the conditional probability of a word, given its history, is proportional to the maximum likelihood estimate for that n-gram.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 16], [17, 22], [23, 27], [28, 30], [31, 35], [36, 40], [41, 42], [43, 47], [47, 48], [48, 53], [54, 58], [59, 63], [64, 68], [69, 71], [72, 80], [80, 81], [82, 86], [87, 90], [91, 102], [103, 114], [115, 117], [118, 119], [120, 124], [124, 125], [126, 131], [132, 135], [136, 143], [143, 144], [145, 147], [148, 160], [161, 163], [164, 167], [168, 175], [176, 186], [187, 195], [196, 199], [200, 204], [205, 206], [206, 207], [207, 211], [211, 212]]}
{"doc_key": "ai-test-155", "ner": [[4, 5, "task"], [7, 10, "task"], [12, 14, "task"], [19, 22, "task"], [32, 34, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[32, 34, 19, 22, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "interested", "in", "knowledge", "representation", ",", "common", "-", "sense", "reasoning", "and", "natural", "language", "understanding", ",", "and", "believes", "that", "deep", "language", "understanding", "can", "currently", "only", "be", "achieved", "through", "a", "large", "number", "of", "hand", "-", "designed", "semantically", "rich", "formalisms", ",", "coupled", "with", "statistical", "preferences", "."], "sentence-detokenized": "He is interested in knowledge representation, common-sense reasoning and natural language understanding, and believes that deep language understanding can currently only be achieved through a large number of hand-designed semantically rich formalisms, coupled with statistical preferences.", "token2charspan": [[0, 2], [3, 5], [6, 16], [17, 19], [20, 29], [30, 44], [44, 45], [46, 52], [52, 53], [53, 58], [59, 68], [69, 72], [73, 80], [81, 89], [90, 103], [103, 104], [105, 108], [109, 117], [118, 122], [123, 127], [128, 136], [137, 150], [151, 154], [155, 164], [165, 169], [170, 172], [173, 181], [182, 189], [190, 191], [192, 197], [198, 204], [205, 207], [208, 212], [212, 213], [213, 221], [222, 234], [235, 239], [240, 250], [250, 251], [252, 259], [260, 264], [265, 276], [277, 288], [288, 289]]}
{"doc_key": "ai-test-156", "ner": [[1, 1, "programlang"], [3, 3, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "JavaScript", ",", "Python", "or"], "sentence-detokenized": "In JavaScript, Python or", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 21], [22, 24]]}
{"doc_key": "ai-test-157", "ner": [[0, 2, "misc"], [7, 8, "misc"], [11, 11, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 7, 8, "part-of", "", false, false], [7, 8, 11, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Newcomb", "Award", "was", "announced", "in", "the", "AI", "Journal", "published", "by", "AAAI", "."], "sentence-detokenized": "The Newcomb Award was announced in the AI Journal published by AAAI.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 21], [22, 31], [32, 34], [35, 38], [39, 41], [42, 49], [50, 59], [60, 62], [63, 67], [67, 68]]}
{"doc_key": "ai-test-158", "ner": [[9, 11, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["On", "a", "test", "set", "of", "100", "samples", ",", "the", "mean", "squared", "error", "was", "0.084", ",", "which", "is", "smaller", "than", "the", "un", "-", "normalised", "error", "."], "sentence-detokenized": "On a test set of 100 samples, the mean squared error was 0.084, which is smaller than the un-normalised error.", "token2charspan": [[0, 2], [3, 4], [5, 9], [10, 13], [14, 16], [17, 20], [21, 28], [28, 29], [30, 33], [34, 38], [39, 46], [47, 52], [53, 56], [57, 62], [62, 63], [64, 69], [70, 72], [73, 80], [81, 85], [86, 89], [90, 92], [92, 93], [93, 103], [104, 109], [109, 110]]}
{"doc_key": "ai-test-159", "ner": [[0, 3, "metrics"], [10, 12, "field"], [21, 23, "task"], [25, 25, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 12, 0, 3, "usage", "", false, false], [21, 23, 10, 12, "part-of", "task_part_of_field", false, false], [25, 25, 21, 23, "named", "", false, false], [28, 29, 10, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "F", "-", "score", "has", "been", "used", "extensively", "in", "the", "natural", "language", "processing", "literature", ",", "for", "example", "in", "the", "evaluation", "of", "named", "entity", "recognition", "(", "NER", ")", "and", "word", "segmentation", "."], "sentence-detokenized": "The F-score has been used extensively in the natural language processing literature, for example in the evaluation of named entity recognition (NER) and word segmentation.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 15], [16, 20], [21, 25], [26, 37], [38, 40], [41, 44], [45, 52], [53, 61], [62, 72], [73, 83], [83, 84], [85, 88], [89, 96], [97, 99], [100, 103], [104, 114], [115, 117], [118, 123], [124, 130], [131, 142], [143, 144], [144, 147], [147, 148], [149, 152], [153, 157], [158, 170], [170, 171]]}
{"doc_key": "ai-test-160", "ner": [[0, 1, "product"], [5, 8, "product"], [17, 18, "misc"], [22, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 17, 18, "related-to", "performs_task", false, false], [0, 1, 22, 23, "related-to", "performs_task", false, false], [5, 8, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Chatbots", "are", "often", "used", "in", "dialogue", "systems", "for", "a", "variety", "of", "purposes", ",", "including", "customer", "service", ",", "request", "routing", ",", "or", "for", "information", "gathering", "."], "sentence-detokenized": "Chatbots are often used in dialogue systems for a variety of purposes, including customer service, request routing, or for information gathering.", "token2charspan": [[0, 8], [9, 12], [13, 18], [19, 23], [24, 26], [27, 35], [36, 43], [44, 47], [48, 49], [50, 57], [58, 60], [61, 69], [69, 70], [71, 80], [81, 89], [90, 97], [97, 98], [99, 106], [107, 114], [114, 115], [116, 118], [119, 122], [123, 134], [135, 144], [144, 145]]}
{"doc_key": "ai-test-161", "ner": [[3, 9, "conference"], [13, 22, "conference"], [28, 38, "conference"], [43, 43, "conference"], [47, 50, "conference"], [52, 53, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 22, 3, 9, "named", "", false, false], [28, 38, 3, 9, "named", "", false, false], [43, 43, 28, 38, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Important", "journals", "include", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "later", "renamed", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "and", ",", "since", "September", "2014", ",", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "-", "after", "merging", "with", "ACM", "publications", ")", ",", "Computer", "Speech", "and", "Language", "and", "Speech", "Communication", "."], "sentence-detokenized": "Important journals include IEEE Transactions on Speech and Audio Processing (later renamed IEEE Transactions on Audio, Speech and Language Processing and, since September 2014, IEEE / ACM Transactions on Audio, Speech and Language Processing - after merging with ACM publications), Computer Speech and Language and Speech Communication.", "token2charspan": [[0, 9], [10, 18], [19, 26], [27, 31], [32, 44], [45, 47], [48, 54], [55, 58], [59, 64], [65, 75], [76, 77], [77, 82], [83, 90], [91, 95], [96, 108], [109, 111], [112, 117], [117, 118], [119, 125], [126, 129], [130, 138], [139, 149], [150, 153], [153, 154], [155, 160], [161, 170], [171, 175], [175, 176], [177, 181], [182, 183], [184, 187], [188, 200], [201, 203], [204, 209], [209, 210], [211, 217], [218, 221], [222, 230], [231, 241], [242, 243], [244, 249], [250, 257], [258, 262], [263, 266], [267, 279], [279, 280], [280, 281], [282, 290], [291, 297], [298, 301], [302, 310], [311, 314], [315, 321], [322, 335], [335, 336]]}
{"doc_key": "ai-test-162", "ner": [[0, 1, "algorithm"], [5, 6, "task"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 0, 1, "usage", "", false, false], [5, 6, 8, 9, "part-of", "task_part_of_field", false, false], [5, 6, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["EM", "is", "often", "used", "for", "data", "clustering", "in", "machine", "learning", "and", "computer", "vision", "."], "sentence-detokenized": "EM is often used for data clustering in machine learning and computer vision.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 16], [17, 20], [21, 25], [26, 36], [37, 39], [40, 47], [48, 56], [57, 60], [61, 69], [70, 76], [76, 77]]}
{"doc_key": "ai-test-163", "ner": [[9, 11, "metrics"], [23, 26, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 23, 26, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["While", "there", "is", "no", "perfect", "way", "to", "describe", "the", "confusion", "matrix", "of", "TRUE", "and", "FALSE", "positives", "and", "negatives", "in", "one", "number", ",", "the", "Matthews", "correlation", "coefficient", "is", "generally", "considered", "to", "be", "one", "of", "the", "best", "such", "measures", "."], "sentence-detokenized": "While there is no perfect way to describe the confusion matrix of TRUE and FALSE positives and negatives in one number, the Matthews correlation coefficient is generally considered to be one of the best such measures.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 17], [18, 25], [26, 29], [30, 32], [33, 41], [42, 45], [46, 55], [56, 62], [63, 65], [66, 70], [71, 74], [75, 80], [81, 90], [91, 94], [95, 104], [105, 107], [108, 111], [112, 118], [118, 119], [120, 123], [124, 132], [133, 144], [145, 156], [157, 159], [160, 169], [170, 180], [181, 183], [184, 186], [187, 190], [191, 193], [194, 197], [198, 202], [203, 207], [208, 216], [216, 217]]}
{"doc_key": "ai-test-164", "ner": [[15, 16, "field"], [31, 33, "field"], [40, 41, "field"], [45, 46, "algorithm"], [48, 49, "task"], [51, 54, "algorithm"], [57, 59, "algorithm"], [61, 62, "algorithm"], [68, 70, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[40, 41, 31, 33, "part-of", "subfield", false, false], [45, 46, 40, 41, "part-of", "", false, true], [48, 49, 40, 41, "part-of", "", false, true], [51, 54, 40, 41, "part-of", "", false, true], [57, 59, 40, 41, "part-of", "", false, true], [61, 62, 40, 41, "part-of", "", false, true], [68, 70, 40, 41, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "the", "size", "and", "complexity", "of", "data", "sets", "have", "increased", ",", "direct", "hands", "-", "on", "data", "analysis", "has", "been", "complemented", "by", "indirect", ",", "automated", "data", "processing", ",", "aided", "by", "other", "discoveries", "in", "computer", "science", ",", "particularly", "in", "the", "field", "of", "machine", "learning", ",", "such", "as", "neural", "networks", ",", "cluster", "analysis", ",", "genetic", "algorithms", "(", "1950s", ")", ",", "decision", "tree", "learning", "and", "decision", "rules", "(", "1960s", ")", ",", "and", "support", "vector", "machines", "(", "1990", "s", ")", "."], "sentence-detokenized": "As the size and complexity of data sets have increased, direct hands-on data analysis has been complemented by indirect, automated data processing, aided by other discoveries in computer science, particularly in the field of machine learning, such as neural networks, cluster analysis, genetic algorithms (1950s), decision tree learning and decision rules (1960s), and support vector machines (1990s).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 15], [16, 26], [27, 29], [30, 34], [35, 39], [40, 44], [45, 54], [54, 55], [56, 62], [63, 68], [68, 69], [69, 71], [72, 76], [77, 85], [86, 89], [90, 94], [95, 107], [108, 110], [111, 119], [119, 120], [121, 130], [131, 135], [136, 146], [146, 147], [148, 153], [154, 156], [157, 162], [163, 174], [175, 177], [178, 186], [187, 194], [194, 195], [196, 208], [209, 211], [212, 215], [216, 221], [222, 224], [225, 232], [233, 241], [241, 242], [243, 247], [248, 250], [251, 257], [258, 266], [266, 267], [268, 275], [276, 284], [284, 285], [286, 293], [294, 304], [305, 306], [306, 311], [311, 312], [312, 313], [314, 322], [323, 327], [328, 336], [337, 340], [341, 349], [350, 355], [356, 357], [357, 362], [362, 363], [363, 364], [365, 368], [369, 376], [377, 383], [384, 392], [393, 394], [394, 398], [398, 399], [399, 400], [400, 401]]}
{"doc_key": "ai-test-165", "ner": [[6, 6, "researcher"], [22, 23, "misc"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 23, 6, 6, "artifact", "", false, false], [22, 23, 16, 17, "artifact", "", false, false], [22, 23, 19, 20, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "autumn", "of", "2005", ",", "Thrun", "published", "a", "textbook", "with", "his", "long", "-", "time", "collaborators", "Dieter", "Fox", "and", "Wolfram", "Burgard", "entitled", "Probabilistic", "Robotics", "."], "sentence-detokenized": "In the autumn of 2005, Thrun published a textbook with his long-time collaborators Dieter Fox and Wolfram Burgard entitled Probabilistic Robotics.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 21], [21, 22], [23, 28], [29, 38], [39, 40], [41, 49], [50, 54], [55, 58], [59, 63], [63, 64], [64, 68], [69, 82], [83, 89], [90, 93], [94, 97], [98, 105], [106, 113], [114, 122], [123, 136], [137, 145], [145, 146]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 9, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "and", "Pereiramath", "as", "follows", "."], "sentence-detokenized": "John D. Lafferty, Andrew McCallum and Pereiramath as follows.", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 37], [38, 49], [50, 52], [53, 60], [60, 61]]}
{"doc_key": "ai-test-167", "ner": [[0, 1, "task"], [3, 3, "task"], [7, 10, "field"], [14, 15, "field"], [17, 19, "field"], [21, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 14, 15, "part-of", "task_part_of_field", false, false], [0, 1, 17, 19, "part-of", "task_part_of_field", false, false], [3, 3, 0, 1, "named", "", false, false], [14, 15, 7, 10, "part-of", "subfield", false, false], [17, 19, 7, 10, "part-of", "subfield", false, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Question", "Answering", "(", "QA", ")", "is", "a", "computer", "science", "discipline", "in", "the", "field", "of", "information", "retrieval", "and", "Natural", "Language", "Processing", "(", "NLP", ")", ",", "which", "is", "concerned", "with", "building", "systems", "that", "automatically", "answer", "questions", "posed", "by", "humans", "in", "natural", "language", "."], "sentence-detokenized": "Question Answering (QA) is a computer science discipline in the field of information retrieval and Natural Language Processing (NLP), which is concerned with building systems that automatically answer questions posed by humans in natural language.", "token2charspan": [[0, 8], [9, 18], [19, 20], [20, 22], [22, 23], [24, 26], [27, 28], [29, 37], [38, 45], [46, 56], [57, 59], [60, 63], [64, 69], [70, 72], [73, 84], [85, 94], [95, 98], [99, 106], [107, 115], [116, 126], [127, 128], [128, 131], [131, 132], [132, 133], [134, 139], [140, 142], [143, 152], [153, 157], [158, 166], [167, 174], [175, 179], [180, 193], [194, 200], [201, 210], [211, 216], [217, 219], [220, 226], [227, 229], [230, 237], [238, 246], [246, 247]]}
{"doc_key": "ai-test-168", "ner": [[11, 11, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "in", "the", "version", "of", "the", "indicator", "used", "in", "the", "NIST", "assessment", "prior", "to", "2009", ",", "the", "shortest", "reference", "sentence", "was", "used", "."], "sentence-detokenized": "However, in the version of the indicator used in the NIST assessment prior to 2009, the shortest reference sentence was used.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 40], [41, 45], [46, 48], [49, 52], [53, 57], [58, 68], [69, 74], [75, 77], [78, 82], [82, 83], [84, 87], [88, 96], [97, 106], [107, 115], [116, 119], [120, 124], [124, 125]]}
{"doc_key": "ai-test-169", "ner": [[5, 5, "person"], [13, 13, "organisation"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 15, 17, "related-to", "invests_in", false, false], [15, 17, 13, 13, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["On", "27", "August", "2018", ",", "Toyota", "announced", "a", "$", "500", "million", "investment", "in", "Uber", "'s", "self", "-", "driving", "cars", "."], "sentence-detokenized": "On 27 August 2018, Toyota announced a $500 million investment in Uber's self-driving cars.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 17], [17, 18], [19, 25], [26, 35], [36, 37], [38, 39], [39, 42], [43, 50], [51, 61], [62, 64], [65, 69], [69, 71], [72, 76], [76, 77], [77, 84], [85, 89], [89, 90]]}
{"doc_key": "ai-test-170", "ner": [[5, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sample", "maximum", "is", "a", "maximum", "likelihood", "estimate", "of", "the", "population", "maximum", ",", "but", ",", "as", "noted", "above", ",", "it", "is", "biased", "."], "sentence-detokenized": "The sample maximum is a maximum likelihood estimate of the population maximum, but, as noted above, it is biased.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 21], [22, 23], [24, 31], [32, 42], [43, 51], [52, 54], [55, 58], [59, 69], [70, 77], [77, 78], [79, 82], [82, 83], [84, 86], [87, 92], [93, 98], [98, 99], [100, 102], [103, 105], [106, 112], [112, 113]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [4, 4, "misc"], [7, 7, "metrics"], [16, 18, "algorithm"], [20, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 4, 4, "related-to", "overcomes", false, false], [0, 0, 7, 7, "related-to", "increases", false, false], [4, 4, 16, 18, "opposite", "", false, false], [4, 4, 20, 22, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LSI", "helps", "to", "overcome", "synonyms", "by", "increasing", "recall", ",", "one", "of", "the", "most", "problematic", "limitations", "of", "Boolean", "keyword", "queries", "and", "vector", "space", "models", "."], "sentence-detokenized": "LSI helps to overcome synonyms by increasing recall, one of the most problematic limitations of Boolean keyword queries and vector space models.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 21], [22, 30], [31, 33], [34, 44], [45, 51], [51, 52], [53, 56], [57, 59], [60, 63], [64, 68], [69, 80], [81, 92], [93, 95], [96, 103], [104, 111], [112, 119], [120, 123], [124, 130], [131, 136], [137, 143], [143, 144]]}
{"doc_key": "ai-test-172", "ner": [[0, 1, "task"], [17, 17, "programlang"], [19, 19, "programlang"], [21, 21, "programlang"], [24, 25, "programlang"], [27, 28, "programlang"], [30, 30, "programlang"], [32, 32, "programlang"], [34, 34, "programlang"], [36, 36, "programlang"], [38, 38, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 17, 17, "general-affiliation", "", false, false], [0, 1, 19, 19, "general-affiliation", "", false, false], [0, 1, 21, 21, "general-affiliation", "", false, false], [0, 1, 24, 25, "general-affiliation", "", false, false], [0, 1, 27, 28, "general-affiliation", "", false, false], [0, 1, 30, 30, "general-affiliation", "", false, false], [0, 1, 32, 32, "general-affiliation", "", false, false], [0, 1, 34, 34, "general-affiliation", "", false, false], [0, 1, 36, 36, "general-affiliation", "", false, false], [0, 1, 38, 38, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Data", "acquisition", "applications", "are", "usually", "controlled", "by", "software", "programs", "developed", "using", "various", "common", "programming", "languages", "such", "as", "Assembly", ",", "BASIC", ",", "C", ",", "C", "+", "+", ",", "C", "#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", ",", "etc."], "sentence-detokenized": "Data acquisition applications are usually controlled by software programs developed using various common programming languages such as Assembly, BASIC, C, C + +, C #, Fortran, Java, LabVIEW, Lisp, Pascal, etc.", "token2charspan": [[0, 4], [5, 16], [17, 29], [30, 33], [34, 41], [42, 52], [53, 55], [56, 64], [65, 73], [74, 83], [84, 89], [90, 97], [98, 104], [105, 116], [117, 126], [127, 131], [132, 134], [135, 143], [143, 144], [145, 150], [150, 151], [152, 153], [153, 154], [155, 156], [157, 158], [159, 160], [160, 161], [162, 163], [164, 165], [165, 166], [167, 174], [174, 175], [176, 180], [180, 181], [182, 189], [189, 190], [191, 195], [195, 196], [197, 203], [203, 204], [205, 209]]}
{"doc_key": "ai-test-173", "ner": [[3, 3, "organisation"], [6, 6, "product"], [9, 10, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 3, 3, "artifact", "", false, false], [6, 6, 9, 10, "physical", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2003", ",", "Honda", "launched", "its", "Cog", "advert", "in", "the", "UK", "and", "on", "the", "Internet", "."], "sentence-detokenized": "In 2003, Honda launched its Cog advert in the UK and on the Internet.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 27], [28, 31], [32, 38], [39, 41], [42, 45], [46, 48], [49, 52], [53, 55], [56, 59], [60, 68], [68, 69]]}
{"doc_key": "ai-test-174", "ner": [[1, 4, "conference"], [6, 8, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 4, 6, 8, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Association", "for", "Computational", "Linguistics", "defines", "computational", "linguistics", "as", "."], "sentence-detokenized": "The Association for Computational Linguistics defines computational linguistics as.", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 33], [34, 45], [46, 53], [54, 67], [68, 79], [80, 82], [82, 83]]}
{"doc_key": "ai-test-175", "ner": [[0, 3, "algorithm"], [10, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 10, 14, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "expectation", "maximisation", "algorithm", "can", "be", "used", "to", "calculate", "approximate", "maximum", "likelihood", "estimates", "of", "the", "unknown", "state", "space", "parameters", "within", "the", "minimum", "variance", "filter", "and", "smoother", "."], "sentence-detokenized": "An expectation maximisation algorithm can be used to calculate approximate maximum likelihood estimates of the unknown state space parameters within the minimum variance filter and smoother.", "token2charspan": [[0, 2], [3, 14], [15, 27], [28, 37], [38, 41], [42, 44], [45, 49], [50, 52], [53, 62], [63, 74], [75, 82], [83, 93], [94, 103], [104, 106], [107, 110], [111, 118], [119, 124], [125, 130], [131, 141], [142, 148], [149, 152], [153, 160], [161, 169], [170, 176], [177, 180], [181, 189], [189, 190]]}
{"doc_key": "ai-test-176", "ner": [[3, 3, "misc"], [6, 7, "person"], [5, 10, "person"], [12, 13, "person"], [16, 17, "misc"], [18, 19, "person"], [22, 23, "person"], [28, 28, "person"], [30, 31, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[6, 7, 3, 3, "role", "actor_in", false, false], [5, 10, 3, 3, "role", "actor_in", false, false], [12, 13, 3, 3, "role", "actor_in", false, false], [18, 19, 16, 17, "role", "model_for", false, false], [28, 28, 30, 31, "social", "family", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Correspondents", "include", "former", "Baywatch", "actresses", "Donna", "D'", "Errico", ",", "Carmen", "Electra", "and", "Traci", "Bingham", ",", "former", "Playboy", "playmate", "Heidi", "Mark", ",", "comedian", "Arj", "Barker", ")", "and", "identical", "twins", "Randy", "and", "Jason", "Scola", "."], "sentence-detokenized": "Correspondents include former Baywatch actresses Donna D'Errico, Carmen Electra and Traci Bingham, former Playboy playmate Heidi Mark, comedian Arj Barker) and identical twins Randy and Jason Scola.", "token2charspan": [[0, 14], [15, 22], [23, 29], [30, 38], [39, 48], [49, 54], [55, 57], [57, 63], [63, 64], [65, 71], [72, 79], [80, 83], [84, 89], [90, 97], [97, 98], [99, 105], [106, 113], [114, 122], [123, 128], [129, 133], [133, 134], [135, 143], [144, 147], [148, 154], [154, 155], [156, 159], [160, 169], [170, 175], [176, 181], [182, 185], [186, 191], [192, 197], [197, 198]]}
{"doc_key": "ai-test-177", "ner": [[8, 9, "task"], [11, 11, "task"], [16, 18, "product"], [22, 23, "task"], [25, 25, "task"], [19, 32, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 8, 9, "named", "", false, false], [16, 18, 8, 9, "general-affiliation", "", false, false], [25, 25, 22, 23, "named", "", false, false], [19, 32, 22, 23, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "is", "typically", "used", "to", "generate", "representations", "for", "speech", "recognition", "(", "ASR", ")", ",", "such", "as", "the", "CMU", "Sphinx", "system", ",", "and", "speech", "synthesis", "(", "TTS", ")", ",", "such", "as", "the", "Festival", "system", "."], "sentence-detokenized": "It is typically used to generate representations for speech recognition (ASR), such as the CMU Sphinx system, and speech synthesis (TTS), such as the Festival system.", "token2charspan": [[0, 2], [3, 5], [6, 15], [16, 20], [21, 23], [24, 32], [33, 48], [49, 52], [53, 59], [60, 71], [72, 73], [73, 76], [76, 77], [77, 78], [79, 83], [84, 86], [87, 90], [91, 94], [95, 101], [102, 108], [108, 109], [110, 113], [114, 120], [121, 130], [131, 132], [132, 135], [135, 136], [136, 137], [138, 142], [143, 145], [146, 149], [150, 158], [159, 165], [165, 166]]}
{"doc_key": "ai-test-178", "ner": [[0, 1, "metrics"], [3, 5, "metrics"], [7, 7, "metrics"], [14, 18, "metrics"], [26, 27, "metrics"], [29, 29, "metrics"], [40, 41, "metrics"], [43, 43, "metrics"], [45, 47, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 5, 0, 1, "named", "", false, false], [7, 7, 3, 5, "named", "", false, false], [14, 18, 0, 1, "named", "", false, false], [29, 29, 26, 27, "named", "", false, false], [43, 43, 40, 41, "named", "", false, false], [45, 47, 40, 41, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "sensitivity", "or", "true", "positive", "rate", "(", "TPR", ")", ",", "also", "known", "as", "the", "recall", "rate", ",", "is", "the", "proportion", "of", "those", "who", "test", "positive", "(", "true", "positives", ",", "TP", ")", "out", "of", "all", "those", "who", "are", "actually", "positive", "(", "conditional", "positives", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "The sensitivity or true positive rate (TPR), also known as the recall rate, is the proportion of those who test positive (true positives, TP) out of all those who are actually positive (conditional positives, CP = TP + FN).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 23], [24, 32], [33, 37], [38, 39], [39, 42], [42, 43], [43, 44], [45, 49], [50, 55], [56, 58], [59, 62], [63, 69], [70, 74], [74, 75], [76, 78], [79, 82], [83, 93], [94, 96], [97, 102], [103, 106], [107, 111], [112, 120], [121, 122], [122, 126], [127, 136], [136, 137], [138, 140], [140, 141], [142, 145], [146, 148], [149, 152], [153, 158], [159, 162], [163, 166], [167, 175], [176, 184], [185, 186], [186, 197], [198, 207], [207, 208], [209, 211], [212, 213], [214, 216], [217, 218], [219, 221], [221, 222], [222, 223]]}
{"doc_key": "ai-test-179", "ner": [[1, 2, "task"], [9, 9, "conference"], [11, 12, "conference"], [14, 14, "conference"], [16, 16, "conference"], [18, 18, "conference"], [20, 21, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 9, 1, 2, "topic", "", false, false], [11, 12, 1, 2, "topic", "", false, false], [14, 14, 1, 2, "topic", "", false, false], [16, 16, 1, 2, "topic", "", false, false], [18, 18, 1, 2, "topic", "", false, false], [20, 21, 1, 2, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Popular", "speech", "recognition", "conferences", "held", "annually", "or", "biennially", "include", "SpeechTEK", "and", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", "and", "IEEE", "ASRU", "."], "sentence-detokenized": "Popular speech recognition conferences held annually or biennially include SpeechTEK and SpeechTEK Europe, ICASSP, Interspeech / Eurospeech and IEEE ASRU.", "token2charspan": [[0, 7], [8, 14], [15, 26], [27, 38], [39, 43], [44, 52], [53, 55], [56, 66], [67, 74], [75, 84], [85, 88], [89, 98], [99, 105], [105, 106], [107, 113], [113, 114], [115, 126], [127, 128], [129, 139], [140, 143], [144, 148], [149, 153], [153, 154]]}
{"doc_key": "ai-test-180", "ner": [[12, 13, "researcher"], [3, 5, "researcher"], [17, 18, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 12, 13, "artifact", "", false, false], [23, 23, 3, 5, "artifact", "", false, false], [23, 23, 17, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "collaboration", "with", "Engelberg", ",", "who", "is", "president", "of", "the", "company", ",", "De", "Waal", "designs", "and", "produces", "industrial", "robots", "under", "the", "brand", "name", "Unimate", "."], "sentence-detokenized": "In collaboration with Engelberg, who is president of the company, De Waal designs and produces industrial robots under the brand name Unimate.", "token2charspan": [[0, 2], [3, 16], [17, 21], [22, 31], [31, 32], [33, 36], [37, 39], [40, 49], [50, 52], [53, 56], [57, 64], [64, 65], [66, 68], [69, 73], [74, 81], [82, 85], [86, 94], [95, 105], [106, 112], [113, 118], [119, 122], [123, 128], [129, 133], [134, 141], [141, 142]]}
{"doc_key": "ai-test-181", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [9, 11, "algorithm"], [23, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 9, 11, "general-affiliation", "", false, false], [5, 5, 0, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "Hidden", "Markov", "Model", "(", "HMM", ")", "is", "a", "statistical", "Markov", "model", "in", "which", "the", "system", "being", "modelled", "is", "assumed", "to", "be", "a", "Markov", "process", "with", "an", "unobserved", "(", "hidden", ")", "state", "."], "sentence-detokenized": "A Hidden Markov Model (HMM) is a statistical Markov model in which the system being modelled is assumed to be a Markov process with an unobserved (hidden) state.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [22, 23], [23, 26], [26, 27], [28, 30], [31, 32], [33, 44], [45, 51], [52, 57], [58, 60], [61, 66], [67, 70], [71, 77], [78, 83], [84, 92], [93, 95], [96, 103], [104, 106], [107, 109], [110, 111], [112, 118], [119, 126], [127, 131], [132, 134], [135, 145], [146, 147], [147, 153], [153, 154], [155, 160], [160, 161]]}
{"doc_key": "ai-test-182", "ner": [[16, 18, "metrics"], [23, 23, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "property", "is", "undesirable", "in", "many", "applications", ",", "leading", "researchers", "to", "use", "alternative", "methods", "such", "as", "mean", "absolute", "error", "or", "median", "-", "based", "methods", "."], "sentence-detokenized": "This property is undesirable in many applications, leading researchers to use alternative methods such as mean absolute error or median-based methods.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 28], [29, 31], [32, 36], [37, 49], [49, 50], [51, 58], [59, 70], [71, 73], [74, 77], [78, 89], [90, 97], [98, 102], [103, 105], [106, 110], [111, 119], [120, 125], [126, 128], [129, 135], [135, 136], [136, 141], [142, 149], [149, 150]]}
{"doc_key": "ai-test-183", "ner": [[18, 19, "algorithm"], [27, 28, "field"], [31, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 19, 27, 28, "part-of", "", false, false], [18, 19, 31, 33, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Such", "a", "sequence", "(", "depending", "on", "the", "findings", "of", "each", "stage", "on", "previous", "attributes", ")", "is", "called", "a", "decision", "tree", "and", "is", "applied", "to", "the", "field", "of", "machine", "learning", "known", "as", "decision", "tree", "learning", "."], "sentence-detokenized": "Such a sequence (depending on the findings of each stage on previous attributes) is called a decision tree and is applied to the field of machine learning known as decision tree learning.", "token2charspan": [[0, 4], [5, 6], [7, 15], [16, 17], [17, 26], [27, 29], [30, 33], [34, 42], [43, 45], [46, 50], [51, 56], [57, 59], [60, 68], [69, 79], [79, 80], [81, 83], [84, 90], [91, 92], [93, 101], [102, 106], [107, 110], [111, 113], [114, 121], [122, 124], [125, 128], [129, 134], [135, 137], [138, 145], [146, 154], [155, 160], [161, 163], [164, 172], [173, 177], [178, 186], [186, 187]]}
{"doc_key": "ai-test-184", "ner": [[2, 3, "task"], [5, 7, "algorithm"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 5, 7, "compare", "", false, false], [15, 16, 5, 7, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "with", "factor", "analysis", ",", "LCA", "can", "be", "used", "to", "classify", "cases", "according", "to", "their", "most", "likely", "category", "members", "."], "sentence-detokenized": "As with factor analysis, LCA can be used to classify cases according to their most likely category members.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 23], [23, 24], [25, 28], [29, 32], [33, 35], [36, 40], [41, 43], [44, 52], [53, 58], [59, 68], [69, 71], [72, 77], [78, 82], [83, 89], [90, 98], [99, 106], [106, 107]]}
{"doc_key": "ai-test-185", "ner": [[0, 2, "algorithm"], [4, 6, "metrics"], [8, 8, "metrics"], [10, 11, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 4, 6, "usage", "", false, false], [4, 6, 10, 11, "related-to", "", false, false], [8, 8, 4, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Supervised", "neural", "networks", "using", "mean", "squared", "error", "(", "MSE", ")", "cost", "functions", "can", "use", "formal", "statistical", "methods", "to", "determine", "the", "plausibility", "of", "the", "training", "model", "."], "sentence-detokenized": "Supervised neural networks using mean squared error (MSE) cost functions can use formal statistical methods to determine the plausibility of the training model.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 32], [33, 37], [38, 45], [46, 51], [52, 53], [53, 56], [56, 57], [58, 62], [63, 72], [73, 76], [77, 80], [81, 87], [88, 99], [100, 107], [108, 110], [111, 120], [121, 124], [125, 137], [138, 140], [141, 144], [145, 153], [154, 159], [159, 160]]}
{"doc_key": "ai-test-186", "ner": [[16, 17, "algorithm"], [20, 22, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 17, 20, 22, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "can", "be", "expressed", "directly", "as", "a", "linear", "program", ",", "but", "it", "is", "also", "equivalent", "to", "Tikhonov", "regularization", "with", "a", "hinge", "loss", "function", ",", "mathV", "(", "f", "(", "x", ")", ",", "y", ")", "=", "\\", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "math", ":"], "sentence-detokenized": "This can be expressed directly as a linear program, but it is also equivalent to Tikhonov regularization with a hinge loss function, mathV (f (x), y) = \\ max (0, 1 - yf (x))/ math:", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 21], [22, 30], [31, 33], [34, 35], [36, 42], [43, 50], [50, 51], [52, 55], [56, 58], [59, 61], [62, 66], [67, 77], [78, 80], [81, 89], [90, 104], [105, 109], [110, 111], [112, 117], [118, 122], [123, 131], [131, 132], [133, 138], [139, 140], [140, 141], [142, 143], [143, 144], [144, 145], [145, 146], [147, 148], [148, 149], [150, 151], [152, 153], [154, 157], [158, 159], [159, 160], [160, 161], [162, 163], [164, 165], [166, 168], [169, 170], [170, 171], [171, 172], [172, 173], [173, 174], [175, 179], [179, 180]]}
{"doc_key": "ai-test-187", "ner": [[6, 6, "researcher"], [13, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "techniques", "are", "described", "in", "Breiman", "'s", "original", "paper", "and", "implemented", "in", "the", "R", "package", "randomForest", "."], "sentence-detokenized": "The following techniques are described in Breiman's original paper and implemented in the R package randomForest.", "token2charspan": [[0, 3], [4, 13], [14, 24], [25, 28], [29, 38], [39, 41], [42, 49], [49, 51], [52, 60], [61, 66], [67, 70], [71, 82], [83, 85], [86, 89], [90, 91], [92, 99], [100, 112], [112, 113]]}
{"doc_key": "ai-test-188", "ner": [[9, 9, "metrics"], [41, 41, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "methods", "of", "measuring", "image", "quality", ",", "such", "as", "PSNR", ",", "are", "usually", "performed", "on", "fixed", "-", "resolution", "images", "and", "do", "not", "take", "into", "account", "certain", "aspects", "of", "the", "human", "visual", "system", ",", "such", "as", "variations", "in", "spatial", "resolution", "across", "the", "retina", "."], "sentence-detokenized": "Traditional methods of measuring image quality, such as PSNR, are usually performed on fixed-resolution images and do not take into account certain aspects of the human visual system, such as variations in spatial resolution across the retina.", "token2charspan": [[0, 11], [12, 19], [20, 22], [23, 32], [33, 38], [39, 46], [46, 47], [48, 52], [53, 55], [56, 60], [60, 61], [62, 65], [66, 73], [74, 83], [84, 86], [87, 92], [92, 93], [93, 103], [104, 110], [111, 114], [115, 117], [118, 121], [122, 126], [127, 131], [132, 139], [140, 147], [148, 155], [156, 158], [159, 162], [163, 168], [169, 175], [176, 182], [182, 183], [184, 188], [189, 191], [192, 202], [203, 205], [206, 213], [214, 224], [225, 231], [232, 235], [236, 242], [242, 243]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [10, 12, "person"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 17, "role", "", false, false], [3, 4, 16, 17, "role", "", false, false], [6, 7, 16, 17, "role", "", false, false], [16, 17, 10, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Drew", "and", "Macdonald", "Carey", "starred", "in", "Jack", "Broad", "'s", "colourful", "production", "of", "Hannah", "Lee", ",", "which", "premiered", "on", "19", "June", "1953", "."], "sentence-detokenized": "John Ireland, Joanne Drew and Macdonald Carey starred in Jack Broad's colourful production of Hannah Lee, which premiered on 19 June 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 25], [26, 29], [30, 39], [40, 45], [46, 53], [54, 56], [57, 61], [62, 67], [67, 69], [70, 79], [80, 90], [91, 93], [94, 100], [101, 104], [104, 105], [106, 111], [112, 121], [122, 124], [125, 127], [128, 132], [133, 137], [137, 138]]}
{"doc_key": "ai-test-190", "ner": [[5, 6, "task"], [12, 13, "field"], [16, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 12, 13, "usage", "", false, false], [16, 18, 12, 13, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "process", "is", "known", "as", "image", "registration", "and", "uses", "different", "methods", "of", "computer", "vision", ",", "mostly", "related", "to", "tracking", "."], "sentence-detokenized": "This process is known as image registration and uses different methods of computer vision, mostly related to tracking.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 21], [22, 24], [25, 30], [31, 43], [44, 47], [48, 52], [53, 62], [63, 70], [71, 73], [74, 82], [83, 89], [89, 90], [91, 97], [98, 105], [106, 108], [109, 117], [117, 118]]}
{"doc_key": "ai-test-191", "ner": [[15, 17, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Let", "us", "now", "begin", "to", "explain", "the", "different", "possible", "relationships", "between", "predictions", "and", "actual", "results", ".", "Confusion", "matrix"], "sentence-detokenized": "Let us now begin to explain the different possible relationships between predictions and actual results. Confusion matrix", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [17, 19], [20, 27], [28, 31], [32, 41], [42, 50], [51, 64], [65, 72], [73, 84], [85, 88], [89, 95], [96, 103], [103, 104], [105, 114], [115, 121]]}
{"doc_key": "ai-test-192", "ner": [[2, 2, "product"], [3, 5, "misc"], [0, 0, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 3, 5, "part-of", "", false, false], [2, 2, 3, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["MATLAB", "'s", "VOICEBOX", "speech", "processing", "toolbox", "implements", "this", "conversion", "and", "its", "inverse", "."], "sentence-detokenized": "MATLAB's VOICEBOX speech processing toolbox implements this conversion and its inverse.", "token2charspan": [[0, 6], [6, 8], [9, 17], [18, 24], [25, 35], [36, 43], [44, 54], [55, 59], [60, 70], [71, 74], [75, 78], [79, 86], [86, 87]]}
{"doc_key": "ai-test-193", "ner": [[0, 0, "programlang"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 9, "general-affiliation", "", false, false], [0, 0, 11, 12, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "is", "a", "logic", "programming", "language", "related", "to", "artificial", "intelligence", "and", "computational", "linguistics", "."], "sentence-detokenized": "Prolog is a logic programming language related to artificial intelligence and computational linguistics.", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 17], [18, 29], [30, 38], [39, 46], [47, 49], [50, 60], [61, 73], [74, 77], [78, 91], [92, 103], [103, 104]]}
{"doc_key": "ai-test-194", "ner": [[0, 0, "researcher"], [9, 9, "field"], [11, 11, "field"], [16, 20, "organisation"], [22, 26, "organisation"], [28, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 9, 9, "related-to", "works_with_topic", false, false], [0, 0, 11, 11, "related-to", "works_with_topic", false, false], [0, 0, 16, 20, "role", "", false, false], [0, 0, 22, 26, "role", "", false, false], [0, 0, 28, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "has", "received", "many", "awards", "for", "his", "contributions", "to", "neuroscience", "and", "psychology", ",", "including", "membership", "of", "the", "Royal", "Society", "of", "London", ",", "the", "Royal", "Society", "of", "Canada", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner has received many awards for his contributions to neuroscience and psychology, including membership of the Royal Society of London, the Royal Society of Canada and the National Academy of Sciences.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 24], [25, 31], [32, 35], [36, 39], [40, 53], [54, 56], [57, 69], [70, 73], [74, 84], [84, 85], [86, 95], [96, 106], [107, 109], [110, 113], [114, 119], [120, 127], [128, 130], [131, 137], [137, 138], [139, 142], [143, 148], [149, 156], [157, 159], [160, 166], [167, 170], [171, 174], [175, 183], [184, 191], [192, 194], [195, 203], [203, 204]]}
{"doc_key": "ai-test-195", "ner": [[11, 12, "field"], [17, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "task"], [29, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[17, 18, 11, 12, "part-of", "task_part_of_field", false, false], [20, 21, 11, 12, "part-of", "task_part_of_field", false, false], [23, 24, 11, 12, "part-of", "task_part_of_field", false, false], [26, 27, 11, 12, "part-of", "task_part_of_field", false, false], [29, 29, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["By", "combining", "these", "operators", ",", "algorithms", "can", "be", "obtained", "for", "many", "image", "processing", "tasks", ",", "such", "as", "feature", "extraction", ",", "image", "segmentation", ",", "image", "sharpening", ",", "image", "filtering", "and", "classification", "."], "sentence-detokenized": "By combining these operators, algorithms can be obtained for many image processing tasks, such as feature extraction, image segmentation, image sharpening, image filtering and classification.", "token2charspan": [[0, 2], [3, 12], [13, 18], [19, 28], [28, 29], [30, 40], [41, 44], [45, 47], [48, 56], [57, 60], [61, 65], [66, 71], [72, 82], [83, 88], [88, 89], [90, 94], [95, 97], [98, 105], [106, 116], [116, 117], [118, 123], [124, 136], [136, 137], [138, 143], [144, 154], [154, 155], [156, 161], [162, 171], [172, 175], [176, 190], [190, 191]]}
{"doc_key": "ai-test-196", "ner": [[8, 12, "university"], [23, 26, "organisation"], [27, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[27, 28, 23, 26, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "of", "2017", ",", "he", "is", "a", "professor", "at", "the", "Coll\u00e8ge", "de", "France", "and", ",", "since", "1989", ",", "he", "is", "director", "of", "the", "INSERM", "562", "unit", "on", "cognitive", "neuroimaging", "."], "sentence-detokenized": "As of 2017, he is a professor at the Coll\u00e8ge de France and, since 1989, he is director of the INSERM 562 unit on cognitive neuroimaging.", "token2charspan": [[0, 2], [3, 5], [6, 10], [10, 11], [12, 14], [15, 17], [18, 19], [20, 29], [30, 32], [33, 36], [37, 44], [45, 47], [48, 54], [55, 58], [58, 59], [60, 65], [66, 70], [70, 71], [72, 74], [75, 77], [78, 86], [87, 89], [90, 93], [94, 100], [101, 104], [105, 109], [110, 112], [113, 122], [123, 135], [135, 136]]}
{"doc_key": "ai-test-197", "ner": [[14, 17, "algorithm"], [19, 23, "algorithm"], [28, 28, "algorithm"], [30, 36, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[28, 28, 30, 36, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["There", "are", "a", "number", "of", "ways", "to", "learn", "these", "embeddings", ",", "in", "particular", "using", "a", "Bayesian", "clustering", "framework", "or", "an", "energy", "-", "based", "framework", ",", "and", "more", "recently", "TransE", "(", "2013", "Conference", "on", "Neural", "Information", "Processing", "Systems", ")", "."], "sentence-detokenized": "There are a number of ways to learn these embeddings, in particular using a Bayesian clustering framework or an energy-based framework, and more recently TransE (2013 Conference on Neural Information Processing Systems).", "token2charspan": [[0, 5], [6, 9], [10, 11], [12, 18], [19, 21], [22, 26], [27, 29], [30, 35], [36, 41], [42, 52], [52, 53], [54, 56], [57, 67], [68, 73], [74, 75], [76, 84], [85, 95], [96, 105], [106, 108], [109, 111], [112, 118], [118, 119], [119, 124], [125, 134], [134, 135], [136, 139], [140, 144], [145, 153], [154, 160], [161, 162], [162, 166], [167, 177], [178, 180], [181, 187], [188, 199], [200, 210], [211, 218], [218, 219], [219, 220]]}
{"doc_key": "ai-test-198", "ner": [[6, 10, "metrics"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "an", "alternative", "to", "the", "Word", "Error", "Rate", "(", "WER", ")", "used", "in", "several", "countries", "."], "sentence-detokenized": "It is an alternative to the Word Error Rate (WER) used in several countries.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 20], [21, 23], [24, 27], [28, 32], [33, 38], [39, 43], [44, 45], [45, 48], [48, 49], [50, 54], [55, 57], [58, 65], [66, 75], [75, 76]]}
{"doc_key": "ai-test-199", "ner": [[0, 0, "algorithm"], [11, 12, "task"], [14, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 28, "task"], [30, 31, "task"], [44, 44, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 0, 0, "usage", "", false, false], [14, 15, 0, 0, "usage", "", false, false], [17, 18, 0, 0, "usage", "", false, false], [20, 22, 0, 0, "usage", "", false, false], [24, 28, 0, 0, "usage", "", false, false], [30, 31, 0, 0, "usage", "", false, false], [44, 44, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["ANNs", "have", "been", "used", "for", "a", "variety", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "playing", "board", "and", "video", "games", ",", "medical", "diagnosis", ",", "and", "even", "for", "activities", "traditionally", "considered", "exclusively", "human", ",", "such", "as", "painting", "."], "sentence-detokenized": "ANNs have been used for a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games, medical diagnosis, and even for activities traditionally considered exclusively human, such as painting.", "token2charspan": [[0, 4], [5, 9], [10, 14], [15, 19], [20, 23], [24, 25], [26, 33], [34, 36], [37, 42], [42, 43], [44, 53], [54, 62], [63, 69], [69, 70], [71, 77], [78, 89], [89, 90], [91, 98], [99, 110], [110, 111], [112, 118], [119, 126], [127, 136], [136, 137], [138, 145], [146, 151], [152, 155], [156, 161], [162, 167], [167, 168], [169, 176], [177, 186], [186, 187], [188, 191], [192, 196], [197, 200], [201, 211], [212, 225], [226, 236], [237, 248], [249, 254], [254, 255], [256, 260], [261, 263], [264, 272], [272, 273]]}
{"doc_key": "ai-test-200", "ner": [[0, 4, "product"], [6, 6, "product"], [26, 28, "field"], [30, 30, "field"], [35, 35, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 26, 28, "related-to", "", false, false], [0, 4, 35, 35, "general-affiliation", "", false, false], [6, 6, 0, 4, "named", "", false, false], [30, 30, 26, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "is", "an", "open", "source", "research", "platform", "and", "a", "collection", "of", "speech", ",", "voice", ",", "speech", ",", "text", "and", "natural", "language", "processing", "(", "NLP", ")", "algorithms", "written", "in", "Java", ",", "arranged", "as", "a", "modular", "and", "extensible", "framework", "that", "attempts", "to", "facilitate", "the", "inclusion", "of", "new", "algorithms", "."], "sentence-detokenized": "The Modular Audio Recognition Framework (MARF) is an open source research platform and a collection of speech, voice, speech, text and natural language processing (NLP) algorithms written in Java, arranged as a modular and extensible framework that attempts to facilitate the inclusion of new algorithms.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 29], [30, 39], [40, 41], [41, 45], [45, 46], [47, 49], [50, 52], [53, 57], [58, 64], [65, 73], [74, 82], [83, 86], [87, 88], [89, 99], [100, 102], [103, 109], [109, 110], [111, 116], [116, 117], [118, 124], [124, 125], [126, 130], [131, 134], [135, 142], [143, 151], [152, 162], [163, 164], [164, 167], [167, 168], [169, 179], [180, 187], [188, 190], [191, 195], [195, 196], [197, 205], [206, 208], [209, 210], [211, 218], [219, 222], [223, 233], [234, 243], [244, 248], [249, 257], [258, 260], [261, 271], [272, 275], [276, 285], [286, 288], [289, 292], [293, 303], [303, 304]]}
{"doc_key": "ai-test-201", "ner": [[12, 14, "organisation"], [18, 18, "country"], [23, 25, "organisation"], [27, 29, "organisation"], [35, 36, "task"], [56, 60, "organisation"], [53, 55, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[23, 25, 18, 18, "physical", "", false, false], [23, 25, 35, 36, "usage", "", false, false], [23, 25, 56, 60, "named", "", false, false], [27, 29, 18, 18, "physical", "", false, false], [27, 29, 35, 36, "usage", "", false, false], [56, 60, 53, 55, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "a", "report", "by", "civil", "liberties", "and", "rights", "campaign", "group", "Big", "Brother", "Watch", "revealed", "that", "two", "UK", "police", "forces", ",", "the", "South", "Wales", "Police", "and", "the", "Metropolitan", "Police", ",", "use", "real", "-", "time", "facial", "recognition", "at", "public", "events", "and", "in", "public", "places", ",", "and", "in", "September", "2019", ",", "the", "use", "of", "facial", "recognition", "by", "the", "South", "Wales", "Police", "was", "ruled", "to", "be", "legal", "."], "sentence-detokenized": "In 2018, a report by civil liberties and rights campaign group Big Brother Watch revealed that two UK police forces, the South Wales Police and the Metropolitan Police, use real-time facial recognition at public events and in public places, and in September 2019, the use of facial recognition by the South Wales Police was ruled to be legal.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 20], [21, 26], [27, 36], [37, 40], [41, 47], [48, 56], [57, 62], [63, 66], [67, 74], [75, 80], [81, 89], [90, 94], [95, 98], [99, 101], [102, 108], [109, 115], [115, 116], [117, 120], [121, 126], [127, 132], [133, 139], [140, 143], [144, 147], [148, 160], [161, 167], [167, 168], [169, 172], [173, 177], [177, 178], [178, 182], [183, 189], [190, 201], [202, 204], [205, 211], [212, 218], [219, 222], [223, 225], [226, 232], [233, 239], [239, 240], [241, 244], [245, 247], [248, 257], [258, 262], [262, 263], [264, 267], [268, 271], [272, 274], [275, 281], [282, 293], [294, 296], [297, 300], [301, 306], [307, 312], [313, 319], [320, 323], [324, 329], [330, 332], [333, 335], [336, 341], [341, 342]]}
{"doc_key": "ai-test-202", "ner": [[0, 0, "product"], [5, 5, "programlang"], [13, 14, "field"], [16, 16, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 5, "general-affiliation", "", false, false], [0, 0, 13, 14, "related-to", "", false, false], [0, 0, 16, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "has", "been", "ported", "to", "R", ",", "a", "free", "language", "and", "environment", "for", "statistical", "computing", "and", "graphics", "."], "sentence-detokenized": "ANIMAL has been ported to R, a free language and environment for statistical computing and graphics.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 22], [23, 25], [26, 27], [27, 28], [29, 30], [31, 35], [36, 44], [45, 48], [49, 60], [61, 64], [65, 76], [77, 86], [87, 90], [91, 99], [99, 100]]}
{"doc_key": "ai-test-203", "ner": [[0, 5, "algorithm"], [7, 9, "algorithm"], [16, 18, "algorithm"], [20, 20, "algorithm"], [23, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 5, 16, 18, "opposite", "alternative to", false, false], [7, 9, 0, 5, "named", "", false, false], [20, 20, 16, 18, "named", "", false, false], [23, 25, 0, 5, "usage", "", false, false], [23, 25, 16, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "temporally", "homogeneous", "implicit", "Bernoulli", "model", "(", "TI", "-", "HBM", ")", "is", "an", "alternative", "to", "the", "implicit", "Markov", "model", "(", "HMM", ")", "in", "automatic", "speech", "recognition", "."], "sentence-detokenized": "The temporally homogeneous implicit Bernoulli model (TI-HBM) is an alternative to the implicit Markov model (HMM) in automatic speech recognition.", "token2charspan": [[0, 3], [4, 14], [15, 26], [27, 35], [36, 45], [46, 51], [52, 53], [53, 55], [55, 56], [56, 59], [59, 60], [61, 63], [64, 66], [67, 78], [79, 81], [82, 85], [86, 94], [95, 101], [102, 107], [108, 109], [109, 112], [112, 113], [114, 116], [117, 126], [127, 133], [134, 145], [145, 146]]}
{"doc_key": "ai-test-204", "ner": [[4, 4, "organisation"], [20, 20, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 20, 20, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "July", "2016", ",", "Nvidia", "demonstrated", "a", "new", "method", "of", "rendering", "depressions", "that", "it", "claims", "is", "invisible", "to", "users", "during", "SIGGRAPH", "."], "sentence-detokenized": "In July 2016, Nvidia demonstrated a new method of rendering depressions that it claims is invisible to users during SIGGRAPH.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 20], [21, 33], [34, 35], [36, 39], [40, 46], [47, 49], [50, 59], [60, 71], [72, 76], [77, 79], [80, 86], [87, 89], [90, 99], [100, 102], [103, 108], [109, 115], [116, 124], [124, 125]]}
{"doc_key": "ai-test-205", "ner": [[3, 6, "misc"], [9, 10, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 6, 9, 10, "origin", "", false, false], [3, 6, 17, 18, "origin", "", false, false], [3, 6, 20, 21, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Both", "rely", "on", "the", "speech", "act", "theory", "developed", "by", "John", "Searle", "in", "the", "1960s", "and", "reinforced", "by", "Terry", "Winograd", "and", "Flores", "in", "the", "1970s", "."], "sentence-detokenized": "Both rely on the speech act theory developed by John Searle in the 1960s and reinforced by Terry Winograd and Flores in the 1970s.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 16], [17, 23], [24, 27], [28, 34], [35, 44], [45, 47], [48, 52], [53, 59], [60, 62], [63, 66], [67, 72], [73, 76], [77, 87], [88, 90], [91, 96], [97, 105], [106, 109], [110, 116], [117, 119], [120, 123], [124, 129], [129, 130]]}
{"doc_key": "ai-test-206", "ner": [[0, 14, "algorithm"], [20, 21, "researcher"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 14, 20, 21, "related-to", "", false, false], [23, 23, 20, 21, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Neural", "network", "models", "of", "concept", "formation", "and", "knowledge", "structure", "open", "up", "powerful", "hierarchical", "models", "for", "knowledge", "organisation", ",", "such", "as", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "Neural network models of concept formation and knowledge structure open up powerful hierarchical models for knowledge organisation, such as George Miller's Wordnet.", "token2charspan": [[0, 6], [7, 14], [15, 21], [22, 24], [25, 32], [33, 42], [43, 46], [47, 56], [57, 66], [67, 71], [72, 74], [75, 83], [84, 96], [97, 103], [104, 107], [108, 117], [118, 130], [130, 131], [132, 136], [137, 139], [140, 146], [147, 153], [153, 155], [156, 163], [163, 164]]}
{"doc_key": "ai-test-207", "ner": [[0, 1, "algorithm"], [14, 15, "field"], [18, 20, "product"], [23, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 14, 15, "part-of", "", false, false], [0, 1, 23, 25, "part-of", "", false, false], [18, 20, 14, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Template", "matching", "has", "a", "variety", "of", "applications", "and", "is", "used", "in", "areas", "such", "as", "face", "recognition", "(", "see", "Face", "Recognition", "Systems", ")", "and", "medical", "image", "processing", "."], "sentence-detokenized": "Template matching has a variety of applications and is used in areas such as face recognition (see Face Recognition Systems) and medical image processing.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 23], [24, 31], [32, 34], [35, 47], [48, 51], [52, 54], [55, 59], [60, 62], [63, 68], [69, 73], [74, 76], [77, 81], [82, 93], [94, 95], [95, 98], [99, 103], [104, 115], [116, 123], [123, 124], [125, 128], [129, 136], [137, 142], [143, 153], [153, 154]]}
{"doc_key": "ai-test-208", "ner": [[10, 11, "researcher"], [13, 15, "researcher"], [16, 24, "organisation"], [26, 26, "organisation"], [33, 34, "algorithm"], [37, 43, "conference"], [45, 45, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 11, 16, 24, "role", "", false, false], [10, 11, 37, 43, "physical", "", false, false], [10, 11, 37, 43, "temporal", "", false, false], [10, 11, 45, 45, "physical", "", false, false], [13, 15, 16, 24, "role", "", false, false], [13, 15, 37, 43, "temporal", "", false, false], [26, 26, 16, 24, "named", "", false, false], [37, 43, 33, 34, "topic", "", false, false], [45, 45, 37, 43, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["However", ",", "it", "was", "not", "until", "2005", ",", "when", "researchers", "Navneet", "Dalal", "and", "Bill", "Triggs", "from", "the", "French", "National", "Institute", "for", "Computer", "Science", "and", "Automation", "(", "INRIA", ")", "presented", "their", "complementary", "work", "on", "HOG", "descriptors", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", ",", "that", "it", "became", "widely", "available", "."], "sentence-detokenized": "However, it was not until 2005, when researchers Navneet Dalal and Bill Triggs from the French National Institute for Computer Science and Automation (INRIA) presented their complementary work on HOG descriptors at the Conference on Computer Vision and Pattern Recognition (CVPR), that it became widely available.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 15], [16, 19], [20, 25], [26, 30], [30, 31], [32, 36], [37, 48], [49, 56], [57, 62], [63, 66], [67, 71], [72, 78], [79, 83], [84, 87], [88, 94], [95, 103], [104, 113], [114, 117], [118, 126], [127, 134], [135, 138], [139, 149], [150, 151], [151, 156], [156, 157], [158, 167], [168, 173], [174, 187], [188, 192], [193, 195], [196, 199], [200, 211], [212, 214], [215, 218], [219, 229], [230, 232], [233, 241], [242, 248], [249, 252], [253, 260], [261, 272], [273, 274], [274, 278], [278, 279], [279, 280], [281, 285], [286, 288], [289, 295], [296, 302], [303, 312], [312, 313]]}
{"doc_key": "ai-test-209", "ner": [[4, 4, "university"], [17, 20, "organisation"], [22, 23, "organisation"], [30, 32, "field"], [36, 38, "researcher"], [40, 43, "researcher"], [45, 47, "researcher"], [50, 54, "organisation"], [58, 60, "organisation"], [63, 64, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[22, 23, 30, 32, "related-to", "", false, false], [36, 38, 22, 23, "physical", "", false, false], [36, 38, 22, 23, "role", "", false, false], [40, 43, 22, 23, "physical", "", false, false], [40, 43, 22, 23, "role", "", false, false], [45, 47, 22, 23, "physical", "", false, false], [45, 47, 22, 23, "role", "", false, false], [63, 64, 58, 60, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Prior", "to", "joining", "the", "Penn", "faculty", "in", "2002", ",", "he", "spent", "ten", "years", "(", "1991-2001", ")", "at", "AT", "&", "T", "Laboratories", "and", "Bell", "Labs", ",", "including", "as", "head", "of", "the", "Artificial", "Intelligence", "Department", ",", "with", "colleagues", "Michael", "L.", "Littman", ",", "David", "A", ".", "McAllester", "and", "Richard", "S.", "Sutton", ";", "the", "Security", "Systems", "Research", "(", "department", ";", "and", "the", "Machine", "Learning", "department", ",", "with", "Michael", "Collins", "and", "leadership", ")", "."], "sentence-detokenized": "Prior to joining the Penn faculty in 2002, he spent ten years (1991-2001) at AT & T Laboratories and Bell Labs, including as head of the Artificial Intelligence Department, with colleagues Michael L. Littman, David A. McAllester and Richard S. Sutton; the Security Systems Research (department; and the Machine Learning department, with Michael Collins and leadership).", "token2charspan": [[0, 5], [6, 8], [9, 16], [17, 20], [21, 25], [26, 33], [34, 36], [37, 41], [41, 42], [43, 45], [46, 51], [52, 55], [56, 61], [62, 63], [63, 72], [72, 73], [74, 76], [77, 79], [80, 81], [82, 83], [84, 96], [97, 100], [101, 105], [106, 110], [110, 111], [112, 121], [122, 124], [125, 129], [130, 132], [133, 136], [137, 147], [148, 160], [161, 171], [171, 172], [173, 177], [178, 188], [189, 196], [197, 199], [200, 207], [207, 208], [209, 214], [215, 216], [216, 217], [218, 228], [229, 232], [233, 240], [241, 243], [244, 250], [250, 251], [252, 255], [256, 264], [265, 272], [273, 281], [282, 283], [283, 293], [293, 294], [295, 298], [299, 302], [303, 310], [311, 319], [320, 330], [330, 331], [332, 336], [337, 344], [345, 352], [353, 356], [357, 367], [367, 368], [368, 369]]}
{"doc_key": "ai-test-210", "ner": [[0, 1, "field"], [12, 13, "field"], [24, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 12, 13, "compare", "", false, false], [24, 24, 12, 13, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Supervised", "learning", "is", "not", "possible", "when", "the", "data", "is", "unlabelled", ",", "and", "unsupervised", "learning", "methods", "are", "needed", "to", "try", "to", "find", "natural", "clusters", "to", "analyse", "and", "then", "map", "the", "new", "data", "to", "these", "formed", "clusters", "."], "sentence-detokenized": "Supervised learning is not possible when the data is unlabelled, and unsupervised learning methods are needed to try to find natural clusters to analyse and then map the new data to these formed clusters.", "token2charspan": [[0, 10], [11, 19], [20, 22], [23, 26], [27, 35], [36, 40], [41, 44], [45, 49], [50, 52], [53, 63], [63, 64], [65, 68], [69, 81], [82, 90], [91, 98], [99, 102], [103, 109], [110, 112], [113, 116], [117, 119], [120, 124], [125, 132], [133, 141], [142, 144], [145, 152], [153, 156], [157, 161], [162, 165], [166, 169], [170, 173], [174, 178], [179, 181], [182, 187], [188, 194], [195, 203], [203, 204]]}
{"doc_key": "ai-test-211", "ner": [[3, 5, "field"], [15, 19, "organisation"], [26, 27, "field"], [29, 29, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 15, 19, "origin", "", false, false], [3, 5, 26, 27, "part-of", "", false, false], [3, 5, 29, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "field", "of", "computer", "science", "was", "developed", "in", "the", "1950s", "at", "academic", "institutions", "such", "as", "the", "MIT", "Artificial", "Intelligence", "Laboratory", ",", "initially", "as", "a", "branch", "of", "artificial", "intelligence", "and", "robotics", "."], "sentence-detokenized": "This field of computer science was developed in the 1950s at academic institutions such as the MIT Artificial Intelligence Laboratory, initially as a branch of artificial intelligence and robotics.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 30], [31, 34], [35, 44], [45, 47], [48, 51], [52, 57], [58, 60], [61, 69], [70, 82], [83, 87], [88, 90], [91, 94], [95, 98], [99, 109], [110, 122], [123, 133], [133, 134], [135, 144], [145, 147], [148, 149], [150, 156], [157, 159], [160, 170], [171, 183], [184, 187], [188, 196], [196, 197]]}
{"doc_key": "ai-test-212", "ner": [[2, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "log", "loss", "equation", "can", "also", "be", "used", "instead", "."], "sentence-detokenized": "The following log loss equation can also be used instead.", "token2charspan": [[0, 3], [4, 13], [14, 17], [18, 22], [23, 31], [32, 35], [36, 40], [41, 43], [44, 48], [49, 56], [56, 57]]}
{"doc_key": "ai-test-213", "ner": [[0, 4, "organisation"], [7, 11, "organisation"], [14, 19, "university"], [21, 21, "university"], [23, 24, "university"], [27, 29, "university"], [30, 32, "country"], [36, 37, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 4, 36, 37, "related-to", "research_leader_in_field", false, false], [7, 11, 0, 4, "named", "", false, false], [7, 11, 36, 37, "related-to", "research_leader_in_field", false, false], [14, 19, 36, 37, "related-to", "research_leader_in_field", false, false], [21, 21, 36, 37, "related-to", "research_leader_in_field", false, false], [23, 24, 36, 37, "related-to", "research_leader_in_field", false, false], [27, 29, 30, 32, "physical", "", false, false], [27, 29, 36, 37, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "Shirley", "Ryan", "Ability", "Lab", "(", "formerly", "the", "Rehabilitation", "Institute", "of", "Chicago", ")", ",", "the", "University", "of", "California", "at", "Berkeley", ",", "MIT", ",", "Stanford", "University", "and", "the", "University", "of", "Twente", "in", "the", "Netherlands", "are", "research", "leaders", "in", "biomechatronics", "."], "sentence-detokenized": "The Shirley Ryan Ability Lab (formerly the Rehabilitation Institute of Chicago), the University of California at Berkeley, MIT, Stanford University and the University of Twente in the Netherlands are research leaders in biomechatronics.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 24], [25, 28], [29, 30], [30, 38], [39, 42], [43, 57], [58, 67], [68, 70], [71, 78], [78, 79], [79, 80], [81, 84], [85, 95], [96, 98], [99, 109], [110, 112], [113, 121], [121, 122], [123, 126], [126, 127], [128, 136], [137, 147], [148, 151], [152, 155], [156, 166], [167, 169], [170, 176], [177, 179], [180, 183], [184, 195], [196, 199], [200, 208], [209, 216], [217, 219], [220, 235], [235, 236]]}
{"doc_key": "ai-test-214", "ner": [[27, 33, "metrics"], [42, 45, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Given", "a", "set", "of", "forecast", "values", "and", "a", "corresponding", "set", "of", "actual", "values", "of", "X", "over", "different", "time", "periods", ",", "a", "common", "evaluation", "technique", "is", "to", "use", "the", "square", "of", "the", "average", "forecast", "error", ";", "other", "measures", "are", "also", "available", "(", "see", "Forecasting", "#", "Forecasting", "accuracy", ")", "."], "sentence-detokenized": "Given a set of forecast values and a corresponding set of actual values of X over different time periods, a common evaluation technique is to use the square of the average forecast error; other measures are also available (see Forecasting#Forecasting accuracy).", "token2charspan": [[0, 5], [6, 7], [8, 11], [12, 14], [15, 23], [24, 30], [31, 34], [35, 36], [37, 50], [51, 54], [55, 57], [58, 64], [65, 71], [72, 74], [75, 76], [77, 81], [82, 91], [92, 96], [97, 104], [104, 105], [106, 107], [108, 114], [115, 125], [126, 135], [136, 138], [139, 141], [142, 145], [146, 149], [150, 156], [157, 159], [160, 163], [164, 171], [172, 180], [181, 186], [186, 187], [188, 193], [194, 202], [203, 206], [207, 211], [212, 221], [222, 223], [223, 226], [227, 238], [238, 239], [239, 250], [251, 259], [259, 260], [260, 261]]}
{"doc_key": "ai-test-215", "ner": [[14, 14, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "measures", ",", "such", "as", "the", "proportion", "of", "correct", "predictions", "(", "also", "known", "as", "accuracy", ")", ",", "are", "not", "useful", "where", "the", "two", "categories", "are", "of", "very", "different", "sizes", "."], "sentence-detokenized": "Other measures, such as the proportion of correct predictions (also known as accuracy), are not useful where the two categories are of very different sizes.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 20], [21, 23], [24, 27], [28, 38], [39, 41], [42, 49], [50, 61], [62, 63], [63, 67], [68, 73], [74, 76], [77, 85], [85, 86], [86, 87], [88, 91], [92, 95], [96, 102], [103, 108], [109, 112], [113, 116], [117, 127], [128, 131], [132, 134], [135, 139], [140, 149], [150, 155], [155, 156]]}
{"doc_key": "ai-test-216", "ner": [[5, 5, "product"], [13, 17, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 13, 17, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "alpha", "version", "of", "OpenCV", "was", "released", "to", "the", "public", "at", "the", "Computer", "Vision", "and", "Pattern", "Recognition", "Conference", "in", "2000", ",", "and", "five", "beta", "versions", "were", "released", "between", "2001", "and", "2005", "."], "sentence-detokenized": "The first alpha version of OpenCV was released to the public at the Computer Vision and Pattern Recognition Conference in 2000, and five beta versions were released between 2001 and 2005.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [24, 26], [27, 33], [34, 37], [38, 46], [47, 49], [50, 53], [54, 60], [61, 63], [64, 67], [68, 76], [77, 83], [84, 87], [88, 95], [96, 107], [108, 118], [119, 121], [122, 126], [126, 127], [128, 131], [132, 136], [137, 141], [142, 150], [151, 155], [156, 164], [165, 172], [173, 177], [178, 181], [182, 186], [186, 187]]}
{"doc_key": "ai-test-217", "ner": [[19, 19, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "results", "show", "a", "high", "correlation", "of", "0.964", "with", "human", "judgement", "at", "corpus", "level", ",", "compared", "to", "0.817", "for", "BLEU", "on", "the", "same", "dataset", "."], "sentence-detokenized": "The results show a high correlation of 0.964 with human judgement at corpus level, compared to 0.817 for BLEU on the same dataset.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 18], [19, 23], [24, 35], [36, 38], [39, 44], [45, 49], [50, 55], [56, 65], [66, 68], [69, 75], [76, 81], [81, 82], [83, 91], [92, 94], [95, 100], [101, 104], [105, 109], [110, 112], [113, 116], [117, 121], [122, 129], [129, 130]]}
{"doc_key": "ai-test-218", "ner": [[3, 4, "metrics"], [18, 18, "metrics"], [20, 22, "metrics"], [24, 26, "metrics"], [27, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 18, 18, "compare", "", false, false], [3, 4, 20, 22, "compare", "", false, false], [3, 4, 24, 26, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Earlier", "versions", "of", "the", "VMAF", "have", "been", "shown", "to", "outperform", "other", "image", "and", "video", "quality", "metrics", "such", "as", "SSIM", ",", "PSNR", "-", "HVS", "and", "VQM", "-", "VFD", "in", "terms", "of", "predictive", "accuracy", "compared", "to", "subjective", "evaluations", "on", "three", "of", "the", "four", "datasets", "."], "sentence-detokenized": "Earlier versions of the VMAF have been shown to outperform other image and video quality metrics such as SSIM, PSNR-HVS and VQM-VFD in terms of predictive accuracy compared to subjective evaluations on three of the four datasets.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 23], [24, 28], [29, 33], [34, 38], [39, 44], [45, 47], [48, 58], [59, 64], [65, 70], [71, 74], [75, 80], [81, 88], [89, 96], [97, 101], [102, 104], [105, 109], [109, 110], [111, 115], [115, 116], [116, 119], [120, 123], [124, 127], [127, 128], [128, 131], [132, 134], [135, 140], [141, 143], [144, 154], [155, 163], [164, 172], [173, 175], [176, 186], [187, 198], [199, 201], [202, 207], [208, 210], [211, 214], [215, 219], [220, 228], [228, 229]]}
{"doc_key": "ai-test-219", "ner": [[18, 19, "task"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 25, 26, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "example", ",", "the", "ambiguity", "of", "\"", "mouse", "\"", "(", "animal", "or", "device", ")", "is", "not", "important", "in", "machine", "translation", ",", "but", "is", "important", "in", "information", "retrieval", "."], "sentence-detokenized": "For example, the ambiguity of \"mouse\" (animal or device) is not important in machine translation, but is important in information retrieval.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 26], [27, 29], [30, 31], [31, 36], [36, 37], [38, 39], [39, 45], [46, 48], [49, 55], [55, 56], [57, 59], [60, 63], [64, 73], [74, 76], [77, 84], [85, 96], [96, 97], [98, 101], [102, 104], [105, 114], [115, 117], [118, 129], [130, 139], [139, 140]]}
{"doc_key": "ai-test-220", "ner": [[0, 2, "algorithm"], [5, 7, "field"], [9, 11, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 0, 2, "usage", "", false, false], [9, 11, 5, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Geometric", "hashing", "was", "originally", "proposed", "in", "computer", "vision", "for", "object", "recognition", "in", "2D", "and", "3D", "."], "sentence-detokenized": "Geometric hashing was originally proposed in computer vision for object recognition in 2D and 3D.", "token2charspan": [[0, 9], [10, 17], [18, 21], [22, 32], [33, 41], [42, 44], [45, 53], [54, 60], [61, 64], [65, 71], [72, 83], [84, 86], [87, 89], [90, 93], [94, 96], [96, 97]]}
{"doc_key": "ai-test-221", "ner": [[17, 18, "field"], [2, 3, "field"], [0, 6, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 17, 18, "part-of", "subfield", false, false], [0, 6, 17, 18, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Together", "with", "supervised", "learning", "and", "reinforcement", "learning", ",", "it", "forms", "one", "of", "the", "three", "main", "categories", "of", "machine", "learning", "."], "sentence-detokenized": "Together with supervised learning and reinforcement learning, it forms one of the three main categories of machine learning.", "token2charspan": [[0, 8], [9, 13], [14, 24], [25, 33], [34, 37], [38, 51], [52, 60], [60, 61], [62, 64], [65, 70], [71, 74], [75, 77], [78, 81], [82, 87], [88, 92], [93, 103], [104, 106], [107, 114], [115, 123], [123, 124]]}
{"doc_key": "ai-test-222", "ner": [[0, 10, "field"], [16, 16, "field"], [18, 18, "field"], [20, 21, "field"], [23, 24, "field"], [26, 29, "field"], [31, 32, "field"], [34, 35, "field"], [37, 37, "field"], [39, 40, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 10, 16, 16, "part-of", "subfield", false, false], [0, 10, 18, 18, "part-of", "subfield", false, false], [0, 10, 20, 21, "part-of", "subfield", false, false], [0, 10, 23, 24, "part-of", "subfield", false, false], [0, 10, 26, 29, "part-of", "subfield", false, false], [0, 10, 31, 32, "part-of", "subfield", false, false], [0, 10, 34, 35, "part-of", "subfield", false, false], [0, 10, 37, 37, "part-of", "subfield", false, false], [0, 10, 39, 40, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Reinforcement", "learning", "has", "been", "studied", "in", "many", "other", "disciplines", "due", "to", "its", "generality", ",", "such", "as", "games", ",", "cybernetics", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimisation", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Reinforcement learning has been studied in many other disciplines due to its generality, such as games, cybernetics, operations research, information theory, simulation-based optimisation, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 13], [14, 22], [23, 26], [27, 31], [32, 39], [40, 42], [43, 47], [48, 53], [54, 65], [66, 69], [70, 72], [73, 76], [77, 87], [87, 88], [89, 93], [94, 96], [97, 102], [102, 103], [104, 115], [115, 116], [117, 127], [128, 136], [136, 137], [138, 149], [150, 156], [156, 157], [158, 168], [168, 169], [169, 174], [175, 187], [187, 188], [189, 200], [201, 208], [208, 209], [210, 215], [216, 228], [228, 229], [230, 240], [241, 244], [245, 252], [253, 263], [263, 264]]}
{"doc_key": "ai-test-223", "ner": [[0, 2, "field"], [6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 7, "related-to", "", false, false], [0, 2, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pattern", "recognition", "is", "closely", "related", "to", "artificial", "intelligence", "and", "machine", "learning", "."], "sentence-detokenized": "Pattern recognition is closely related to artificial intelligence and machine learning.", "token2charspan": [[0, 7], [8, 19], [20, 22], [23, 30], [31, 38], [39, 41], [42, 52], [53, 65], [66, 69], [70, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-224", "ner": [[10, 11, "algorithm"], [13, 13, "field"], [15, 16, "field"], [27, 28, "task"], [30, 30, "task"], [32, 33, "task"], [35, 36, "algorithm"], [38, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 11, 13, 13, "related-to", "", false, false], [10, 11, 15, 16, "related-to", "", false, false], [27, 28, 10, 11, "usage", "", true, false], [30, 30, 10, 11, "usage", "", true, false], [32, 33, 10, 11, "usage", "", true, false], [35, 36, 10, 11, "usage", "", true, false], [38, 40, 10, 11, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "software", "is", "used", "to", "design", ",", "train", "and", "deploy", "neural", "network", "(", "supervised", "and", "unsupervised", "learning", ")", "models", "to", "perform", "a", "variety", "of", "tasks", "such", "as", "data", "mining", ",", "classification", ",", "function", "approximation", ",", "multivariate", "regression", "and", "time", "series", "prediction", "."], "sentence-detokenized": "The software is used to design, train and deploy neural network (supervised and unsupervised learning) models to perform a variety of tasks such as data mining, classification, function approximation, multivariate regression and time series prediction.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 20], [21, 23], [24, 30], [30, 31], [32, 37], [38, 41], [42, 48], [49, 55], [56, 63], [64, 65], [65, 75], [76, 79], [80, 92], [93, 101], [101, 102], [103, 109], [110, 112], [113, 120], [121, 122], [123, 130], [131, 133], [134, 139], [140, 144], [145, 147], [148, 152], [153, 159], [159, 160], [161, 175], [175, 176], [177, 185], [186, 199], [199, 200], [201, 213], [214, 224], [225, 228], [229, 233], [234, 240], [241, 251], [251, 252]]}
{"doc_key": "ai-test-225", "ner": [[10, 17, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2016", ",", "he", "was", "elected", "as", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2016, he was elected as a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 28], [29, 35], [36, 38], [39, 42], [43, 54], [55, 58], [59, 62], [63, 74], [75, 77], [78, 88], [89, 101], [101, 102]]}
{"doc_key": "ai-test-226", "ner": [[5, 9, "organisation"], [15, 21, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", "(", "since", "2005", ")", "and", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "(", "since", "2009", ")", "."], "sentence-detokenized": "She is a member of the National Academy of Sciences (since 2005) and the American Academy of Arts and Sciences (since 2009).", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 15], [16, 18], [19, 22], [23, 31], [32, 39], [40, 42], [43, 51], [52, 53], [53, 58], [59, 63], [63, 64], [65, 68], [69, 72], [73, 81], [82, 89], [90, 92], [93, 97], [98, 101], [102, 110], [111, 112], [112, 117], [118, 122], [122, 123], [123, 124]]}
{"doc_key": "ai-test-227", "ner": [[1, 5, "misc"], [8, 13, "product"], [17, 17, "country"], [19, 20, "country"], [24, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 13, 1, 5, "temporal", "", false, false], [8, 13, 17, 17, "physical", "", false, false], [8, 13, 19, 20, "physical", "", false, false], [8, 13, 24, 26, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "the", "1973", "Yom", "Kippur", "War", ",", "Soviet", "surface", "-", "to", "-", "air", "missile", "batteries", "supplied", "in", "Egypt", "and", "Syria", "caused", "serious", "damage", "to", "Israeli", "fighter", "jets", "."], "sentence-detokenized": "During the 1973 Yom Kippur War, Soviet surface-to-air missile batteries supplied in Egypt and Syria caused serious damage to Israeli fighter jets.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 26], [27, 30], [30, 31], [32, 38], [39, 46], [46, 47], [47, 49], [49, 50], [50, 53], [54, 61], [62, 71], [72, 80], [81, 83], [84, 89], [90, 93], [94, 99], [100, 106], [107, 114], [115, 121], [122, 124], [125, 132], [133, 140], [141, 145], [145, 146]]}
{"doc_key": "ai-test-228", "ner": [[9, 10, "product"], [15, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 16, 9, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Another", "resource", "(", "free", "but", "copyrighted", ")", "is", "the", "HTK", "book", "(", "and", "the", "accompanying", "HTK", "toolkit", ")", "."], "sentence-detokenized": "Another resource (free but copyrighted) is the HTK book (and the accompanying HTK toolkit).", "token2charspan": [[0, 7], [8, 16], [17, 18], [18, 22], [23, 26], [27, 38], [38, 39], [40, 42], [43, 46], [47, 50], [51, 55], [56, 57], [57, 60], [61, 64], [65, 77], [78, 81], [82, 89], [89, 90], [90, 91]]}
{"doc_key": "ai-test-229", "ner": [[0, 4, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "At", "the", "2004", "AAAI", "Spring", "Symposium", ",", "linguists", ",", "computer", "scientists", "and", "other", "interested", "researchers", "united", "their", "interests", "for", "the", "first", "time", "and", "proposed", "shared", "tasks", "and", "benchmark", "datasets", "for", "the", "systematic", "computational", "study", "of", "emotion", ",", "attractiveness", ",", "subjectivity", "and", "sentiment", "in", "text", "."], "sentence-detokenized": "- At the 2004 AAAI Spring Symposium, linguists, computer scientists and other interested researchers united their interests for the first time and proposed shared tasks and benchmark datasets for the systematic computational study of emotion, attractiveness, subjectivity and sentiment in text.", "token2charspan": [[0, 1], [2, 4], [5, 8], [9, 13], [14, 18], [19, 25], [26, 35], [35, 36], [37, 46], [46, 47], [48, 56], [57, 67], [68, 71], [72, 77], [78, 88], [89, 100], [101, 107], [108, 113], [114, 123], [124, 127], [128, 131], [132, 137], [138, 142], [143, 146], [147, 155], [156, 162], [163, 168], [169, 172], [173, 182], [183, 191], [192, 195], [196, 199], [200, 210], [211, 224], [225, 230], [231, 233], [234, 241], [241, 242], [243, 257], [257, 258], [259, 271], [272, 275], [276, 285], [286, 288], [289, 293], [293, 294]]}
{"doc_key": "ai-test-230", "ner": [[9, 10, "task"], [15, 16, "task"], [18, 20, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "single", "grid", "can", "be", "analysed", "for", "content", "(", "eyeball", "inspection", ")", "and", "structure", "(", "cluster", "analysis", ",", "principal", "component", "analysis", "and", "various", "structural", "indices", "related", "to", "the", "complexity", "and", "range", "of", "ratings", "are", "the", "main", "techniques", "used", ")", "."], "sentence-detokenized": "A single grid can be analysed for content (eyeball inspection) and structure (cluster analysis, principal component analysis and various structural indices related to the complexity and range of ratings are the main techniques used).", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 17], [18, 20], [21, 29], [30, 33], [34, 41], [42, 43], [43, 50], [51, 61], [61, 62], [63, 66], [67, 76], [77, 78], [78, 85], [86, 94], [94, 95], [96, 105], [106, 115], [116, 124], [125, 128], [129, 136], [137, 147], [148, 155], [156, 163], [164, 166], [167, 170], [171, 181], [182, 185], [186, 191], [192, 194], [195, 202], [203, 206], [207, 210], [211, 215], [216, 226], [227, 231], [231, 232], [232, 233]]}
{"doc_key": "ai-test-231", "ner": [[3, 7, "organisation"], [11, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2018", ",", "Toyota", "was", "seen", "to", "be", "lagging", "behind", "in", "self", "-", "driving", "cars", "and", "in", "need", "of", "innovation", "."], "sentence-detokenized": "In 2018, Toyota was seen to be lagging behind in self-driving cars and in need of innovation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 24], [25, 27], [28, 30], [31, 38], [39, 45], [46, 48], [49, 53], [53, 54], [54, 61], [62, 66], [67, 70], [71, 73], [74, 78], [79, 81], [82, 92], [92, 93]]}
{"doc_key": "ai-test-232", "ner": [[40, 41, "misc"], [43, 44, "misc"], [46, 50, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "targets", "include", "natural", "objects", "such", "as", "the", "ground", ",", "the", "ocean", ",", "precipitation", "(", "e.g.", "rain", ",", "snow", "or", "hail", ")", ",", "dust", "storms", ",", "animals", "(", "especially", "birds", ")", ",", "atmospheric", "turbulence", "and", "other", "atmospheric", "effects", "such", "as", "ionospheric", "reflections", ",", "meteor", "trails", "and", "three", "-", "body", "scattering", "spikes", "."], "sentence-detokenized": "These targets include natural objects such as the ground, the ocean, precipitation (e.g. rain, snow or hail), dust storms, animals (especially birds), atmospheric turbulence and other atmospheric effects such as ionospheric reflections, meteor trails and three-body scattering spikes.", "token2charspan": [[0, 5], [6, 13], [14, 21], [22, 29], [30, 37], [38, 42], [43, 45], [46, 49], [50, 56], [56, 57], [58, 61], [62, 67], [67, 68], [69, 82], [83, 84], [84, 88], [89, 93], [93, 94], [95, 99], [100, 102], [103, 107], [107, 108], [108, 109], [110, 114], [115, 121], [121, 122], [123, 130], [131, 132], [132, 142], [143, 148], [148, 149], [149, 150], [151, 162], [163, 173], [174, 177], [178, 183], [184, 195], [196, 203], [204, 208], [209, 211], [212, 223], [224, 235], [235, 236], [237, 243], [244, 250], [251, 254], [255, 260], [260, 261], [261, 265], [266, 276], [277, 283], [283, 284]]}
{"doc_key": "ai-test-233", "ner": [[20, 25, "product"], [38, 39, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "terms", "of", "planning", "and", "control", ",", "the", "essential", "difference", "between", "humanoid", "robots", "and", "other", "types", "of", "robot", "(", "e.g.", "industrial", "robots", ")", "is", "that", "the", "robot", "must", "move", "like", "a", "human", ",", "using", "leg", "movements", ",", "especially", "bipedal", "gait", "."], "sentence-detokenized": "In terms of planning and control, the essential difference between humanoid robots and other types of robot (e.g. industrial robots) is that the robot must move like a human, using leg movements, especially bipedal gait.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 20], [21, 24], [25, 32], [32, 33], [34, 37], [38, 47], [48, 58], [59, 66], [67, 75], [76, 82], [83, 86], [87, 92], [93, 98], [99, 101], [102, 107], [108, 109], [109, 113], [114, 124], [125, 131], [131, 132], [133, 135], [136, 140], [141, 144], [145, 150], [151, 155], [156, 160], [161, 165], [166, 167], [168, 173], [173, 174], [175, 180], [181, 184], [185, 194], [194, 195], [196, 206], [207, 214], [215, 219], [219, 220]]}
{"doc_key": "ai-test-234", "ner": [[14, 17, "algorithm"], [25, 26, "misc"], [27, 30, "metrics"], [2, 4, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "curvature", "of", "a", "given", "function", "is", "very", "different", "in", "different", "directions", ",", "the", "gradient", "descent", "method", "may", "require", "several", "iterations", "to", "calculate", "a", "local", "minimum", "with", "the", "required", "accuracy", "."], "sentence-detokenized": "If the curvature of a given function is very different in different directions, the gradient descent method may require several iterations to calculate a local minimum with the required accuracy.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 21], [22, 27], [28, 36], [37, 39], [40, 44], [45, 54], [55, 57], [58, 67], [68, 78], [78, 79], [80, 83], [84, 92], [93, 100], [101, 107], [108, 111], [112, 119], [120, 127], [128, 138], [139, 141], [142, 151], [152, 153], [154, 159], [160, 167], [168, 172], [173, 176], [177, 185], [186, 194], [194, 195]]}
{"doc_key": "ai-test-235", "ner": [[0, 6, "misc"], [10, 10, "misc"], [17, 22, "conference"], [25, 25, "location"], [27, 27, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 6, 10, 10, "part-of", "", true, false], [17, 22, 25, 25, "physical", "", false, true], [25, 25, 27, 27, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "1997", "RoboCup", "2D", "football", "simulation", "league", "was", "the", "first", "RoboCup", "competition", "promoted", "in", "conjunction", "with", "the", "International", "Joint", "Conference", "on", "Artificial", "Intelligence", "held", "in", "Nagoya", ",", "Japan", ",", "from", "23", "to", "29", "August", "1997", "."], "sentence-detokenized": "The 1997 RoboCup 2D football simulation league was the first RoboCup competition promoted in conjunction with the International Joint Conference on Artificial Intelligence held in Nagoya, Japan, from 23 to 29 August 1997.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 19], [20, 28], [29, 39], [40, 46], [47, 50], [51, 54], [55, 60], [61, 68], [69, 80], [81, 89], [90, 92], [93, 104], [105, 109], [110, 113], [114, 127], [128, 133], [134, 144], [145, 147], [148, 158], [159, 171], [172, 176], [177, 179], [180, 186], [186, 187], [188, 193], [193, 194], [195, 199], [200, 202], [203, 205], [206, 208], [209, 215], [216, 220], [220, 221]]}
{"doc_key": "ai-test-236", "ner": [[6, 6, "programlang"], [13, 13, "programlang"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "options", "include", "an", "embedded", "Python", "environment", ",", "as", "well", "as", "an", "R", "console", "and", "support", "for", "Rserve", "."], "sentence-detokenized": "Other programming options include an embedded Python environment, as well as an R console and support for Rserve.", "token2charspan": [[0, 5], [6, 17], [18, 25], [26, 33], [34, 36], [37, 45], [46, 52], [53, 64], [64, 65], [66, 68], [69, 73], [74, 76], [77, 79], [80, 81], [82, 89], [90, 93], [94, 101], [102, 105], [106, 112], [112, 113]]}
{"doc_key": "ai-test-237", "ner": [[1, 1, "location"], [7, 8, "field"], [10, 10, "field"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [30, 31, "field"], [35, 36, "field"], [40, 41, "field"], [45, 47, "field"], [50, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[15, 16, 10, 10, "related-to", "contributes_to_field", true, false], [18, 19, 10, 10, "related-to", "contributes_to_field", true, false], [21, 22, 10, 10, "related-to", "contributes_to_field", true, false], [40, 41, 35, 36, "part-of", "", false, false], [45, 47, 40, 41, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "Bonn", "he", "made", "fundamental", "contributions", "to", "artificial", "intelligence", "and", "robotics", "(", "among", "his", "students", "Wolfram", "Burgard", ",", "Dieter", "Fox", ",", "Sebastian", "Thrun", ")", ",", "and", "to", "the", "development", "of", "software", "engineering", ",", "especially", "in", "civil", "engineering", ",", "and", "of", "information", "systems", ",", "especially", "in", "earth", "sciences", ".", "Winner", "of", "the", "AAAI", "Classic", "Paper", "Award", "2016.2014", "."], "sentence-detokenized": "In Bonn he made fundamental contributions to artificial intelligence and robotics (among his students Wolfram Burgard, Dieter Fox, Sebastian Thrun), and to the development of software engineering, especially in civil engineering, and of information systems, especially in earth sciences. Winner of the AAAI Classic Paper Award 2016.2014.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 15], [16, 27], [28, 41], [42, 44], [45, 55], [56, 68], [69, 72], [73, 81], [82, 83], [83, 88], [89, 92], [93, 101], [102, 109], [110, 117], [117, 118], [119, 125], [126, 129], [129, 130], [131, 140], [141, 146], [146, 147], [147, 148], [149, 152], [153, 155], [156, 159], [160, 171], [172, 174], [175, 183], [184, 195], [195, 196], [197, 207], [208, 210], [211, 216], [217, 228], [228, 229], [230, 233], [234, 236], [237, 248], [249, 256], [256, 257], [258, 268], [269, 271], [272, 277], [278, 286], [286, 287], [288, 294], [295, 297], [298, 301], [302, 306], [307, 314], [315, 320], [321, 326], [327, 336], [336, 337]]}
{"doc_key": "ai-test-238", "ner": [[2, 4, "conference"], [14, 17, "location"], [18, 18, "location"], [20, 20, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 4, 14, 17, "physical", "", false, false], [14, 17, 18, 18, "physical", "", false, false], [18, 18, 20, 20, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "first", "American", "Campus", "Party", "will", "take", "place", "from", "20", "to", "22", "August", "at", "the", "TCF", "Center", "in", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "The first American Campus Party will take place from 20 to 22 August at the TCF Center in Detroit, Michigan.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 25], [26, 31], [32, 36], [37, 41], [42, 47], [48, 52], [53, 55], [56, 58], [59, 61], [62, 68], [69, 71], [72, 75], [76, 79], [80, 86], [87, 89], [90, 97], [97, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-test-239", "ner": [[10, 12, "researcher"], [14, 17, "researcher"], [0, 1, "researcher"], [3, 6, "misc"], [26, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 12, 3, 6, "win-defeat", "", false, false], [14, 17, 3, 6, "win-defeat", "", false, false], [0, 1, 3, 6, "win-defeat", "", false, false], [3, 6, 26, 29, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Hinton", "was", "awarded", "the", "2018", "Turing", "Award", ",", "along", "with", "Jan", "Le", "Coon", "and", "Joshua", "Bengeo", ",", "for", "their", "conceptual", "and", "engineering", "breakthroughs", "that", "have", "made", "deep", "neural", "networks", "an", "essential", "part", "of", "computing", "."], "sentence-detokenized": "Hinton was awarded the 2018 Turing Award, along with Jan Le Coon and Joshua Bengeo, for their conceptual and engineering breakthroughs that have made deep neural networks an essential part of computing.", "token2charspan": [[0, 6], [7, 10], [11, 18], [19, 22], [23, 27], [28, 34], [35, 40], [40, 41], [42, 47], [48, 52], [53, 56], [57, 59], [60, 64], [65, 68], [69, 75], [76, 82], [82, 83], [84, 87], [88, 93], [94, 104], [105, 108], [109, 120], [121, 134], [135, 139], [140, 144], [145, 149], [150, 154], [155, 161], [162, 170], [171, 173], [174, 183], [184, 188], [189, 191], [192, 201], [201, 202]]}
{"doc_key": "ai-test-240", "ner": [[0, 3, "product"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 10, 10, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Eulerian", "Mathematics", "Toolbox", "uses", "a", "matrix", "language", "similar", "to", "MATLAB", ",", "a", "system", "that", "has", "been", "in", "development", "since", "the", "1970s", "."], "sentence-detokenized": "The Eulerian Mathematics Toolbox uses a matrix language similar to MATLAB, a system that has been in development since the 1970s.", "token2charspan": [[0, 3], [4, 12], [13, 24], [25, 32], [33, 37], [38, 39], [40, 46], [47, 55], [56, 63], [64, 66], [67, 73], [73, 74], [75, 76], [77, 83], [84, 88], [89, 92], [93, 97], [98, 100], [101, 112], [113, 118], [119, 122], [123, 128], [128, 129]]}
{"doc_key": "ai-test-241", "ner": [[7, 7, "programlang"], [9, 10, "programlang"], [12, 12, "programlang"], [14, 14, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "languages", "make", "it", "portable", "(", "e.g.", "Scheme", ",", "Common", "Lisp", ",", "Perl", "or", "D", ")", "."], "sentence-detokenized": "Some languages make it portable (e.g. Scheme, Common Lisp, Perl or D).", "token2charspan": [[0, 4], [5, 14], [15, 19], [20, 22], [23, 31], [32, 33], [33, 37], [38, 44], [44, 45], [46, 52], [53, 57], [57, 58], [59, 63], [64, 66], [67, 68], [68, 69], [69, 70]]}
{"doc_key": "ai-test-242", "ner": [[14, 14, "misc"], [7, 8, "researcher"], [10, 11, "researcher"], [28, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 14, 7, 8, "artifact", "", false, false], [14, 14, 10, 11, "artifact", "", false, false], [14, 14, 28, 30, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1969", ",", "a", "famous", "book", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", ",", "entitled", "Perceptron", ",", "showed", "that", "it", "was", "impossible", "for", "these", "classes", "of", "networks", "to", "learn", "the", "XOR", "function", "."], "sentence-detokenized": "In 1969, a famous book by Marvin Minsky and Seymour Papert, entitled Perceptron, showed that it was impossible for these classes of networks to learn the XOR function.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 22], [23, 25], [26, 32], [33, 39], [40, 43], [44, 51], [52, 58], [58, 59], [60, 68], [69, 79], [79, 80], [81, 87], [88, 92], [93, 95], [96, 99], [100, 110], [111, 114], [115, 120], [121, 128], [129, 131], [132, 140], [141, 143], [144, 149], [150, 153], [154, 157], [158, 166], [166, 167]]}
{"doc_key": "ai-test-243", "ner": [[4, 9, "misc"], [12, 12, "product"], [18, 23, "organisation"], [26, 30, "organisation"], [33, 38, "location"], [40, 40, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 23, 12, 12, "usage", "", false, false], [18, 23, 33, 38, "physical", "", false, false], [26, 30, 18, 23, "named", "", false, false], [33, 38, 40, 40, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "large", "number", "of", "Russian", "scientific", "and", "technical", "documents", "were", "translated", "using", "SYSTRAN", "under", "the", "auspices", "of", "the", "US", "Air", "Force", "Foreign", "Technology", "Division", "(", "later", "the", "National", "Aerospace", "Intelligence", "Center", ")", "at", "Wright", "-", "Patterson", "Air", "Force", "Base", ",", "Ohio", "."], "sentence-detokenized": "A large number of Russian scientific and technical documents were translated using SYSTRAN under the auspices of the US Air Force Foreign Technology Division (later the National Aerospace Intelligence Center) at Wright-Patterson Air Force Base, Ohio.", "token2charspan": [[0, 1], [2, 7], [8, 14], [15, 17], [18, 25], [26, 36], [37, 40], [41, 50], [51, 60], [61, 65], [66, 76], [77, 82], [83, 90], [91, 96], [97, 100], [101, 109], [110, 112], [113, 116], [117, 119], [120, 123], [124, 129], [130, 137], [138, 148], [149, 157], [158, 159], [159, 164], [165, 168], [169, 177], [178, 187], [188, 200], [201, 207], [207, 208], [209, 211], [212, 218], [218, 219], [219, 228], [229, 232], [233, 238], [239, 243], [243, 244], [245, 249], [249, 250]]}
{"doc_key": "ai-test-244", "ner": [[0, 2, "field"], [5, 8, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Semi-supervised", "learning", "is", "somewhere", "between", "unsupervised", "learning", "(", "training", "data", "without", "any", "labelling", ")", "and", "supervised", "learning", "(", "training", "data", "with", "full", "labelling", ")", "."], "sentence-detokenized": "Semi-supervised learning is somewhere between unsupervised learning (training data without any labelling) and supervised learning (training data with full labelling).", "token2charspan": [[0, 15], [16, 24], [25, 27], [28, 37], [38, 45], [46, 58], [59, 67], [68, 69], [69, 77], [78, 82], [83, 90], [91, 94], [95, 104], [104, 105], [106, 109], [110, 120], [121, 129], [130, 131], [131, 139], [140, 144], [145, 149], [150, 154], [155, 164], [164, 165], [165, 166]]}
{"doc_key": "ai-test-245", "ner": [[0, 2, "algorithm"], [5, 7, "algorithm"], [27, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 5, 7, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Ann-gram", "model", "is", "a", "probabilistic", "linguistic", "model", "for", "predicting", "the", "next", "item", "in", "such", "a", "sequence", "and", "takes", "the", "form", "of", "an", "(", "n-1", ")", "-order", "Markov", "model", ".", "Effective", "."], "sentence-detokenized": "The Ann-gram model is a probabilistic linguistic model for predicting the next item in such a sequence and takes the form of an (n-1)-order Markov model. Effective.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 21], [22, 23], [24, 37], [38, 48], [49, 54], [55, 58], [59, 69], [70, 73], [74, 78], [79, 83], [84, 86], [87, 91], [92, 93], [94, 102], [103, 106], [107, 112], [113, 116], [117, 121], [122, 124], [125, 127], [128, 129], [129, 132], [132, 133], [133, 139], [140, 146], [147, 152], [152, 153], [154, 163], [163, 164]]}
{"doc_key": "ai-test-246", "ner": [[0, 2, "organisation"], [4, 5, "product"], [8, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 4, 5, "usage", "", false, false], [8, 14, 0, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Cleveland", "Clinic", "used", "Cyc", "to", "develop", "a", "natural", "language", "query", "interface", "for", "biomedical", "information", "across", "decades", "of", "cardiothoracic", "surgical", "information", "."], "sentence-detokenized": "The Cleveland Clinic used Cyc to develop a natural language query interface for biomedical information across decades of cardiothoracic surgical information.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 29], [30, 32], [33, 40], [41, 42], [43, 50], [51, 59], [60, 65], [66, 75], [76, 79], [80, 90], [91, 102], [103, 109], [110, 117], [118, 120], [121, 135], [136, 144], [145, 156], [156, 157]]}
{"doc_key": "ai-test-247", "ner": [[5, 7, "country"], [9, 9, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 9, 9, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "incident", "strained", "relations", "between", "the", "United", "States", "and", "Japan", "and", "led", "to", "the", "arrest", "and", "prosecution", "of", "two", "senior", "executives", "and", "the", "imposition", "of", "sanctions", "on", "the", "company", "by", "both", "countries", "."], "sentence-detokenized": "The incident strained relations between the United States and Japan and led to the arrest and prosecution of two senior executives and the imposition of sanctions on the company by both countries.", "token2charspan": [[0, 3], [4, 12], [13, 21], [22, 31], [32, 39], [40, 43], [44, 50], [51, 57], [58, 61], [62, 67], [68, 71], [72, 75], [76, 78], [79, 82], [83, 89], [90, 93], [94, 105], [106, 108], [109, 112], [113, 119], [120, 130], [131, 134], [135, 138], [139, 149], [150, 152], [153, 162], [163, 165], [166, 169], [170, 177], [178, 180], [181, 185], [186, 195], [195, 196]]}
{"doc_key": "ai-test-248", "ner": [[5, 7, "algorithm"], [10, 14, "field"], [19, 19, "misc"], [29, 29, "misc"], [33, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 7, 10, 14, "type-of", "", false, false], [19, 19, 10, 14, "part-of", "", true, false], [29, 29, 10, 14, "part-of", "", true, false], [33, 33, 10, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["If", "modelling", "is", "done", "by", "artificial", "neural", "networks", "or", "other", "machine", "learning", ",", "the", "optimisation", "of", "parameters", "is", "called", "training", ",", "while", "the", "optimisation", "of", "model", "hyperparameters", "is", "called", "tuning", "and", "often", "uses", "cross-validation", "."], "sentence-detokenized": "If modelling is done by artificial neural networks or other machine learning, the optimisation of parameters is called training, while the optimisation of model hyperparameters is called tuning and often uses cross-validation.", "token2charspan": [[0, 2], [3, 12], [13, 15], [16, 20], [21, 23], [24, 34], [35, 41], [42, 50], [51, 53], [54, 59], [60, 67], [68, 76], [76, 77], [78, 81], [82, 94], [95, 97], [98, 108], [109, 111], [112, 118], [119, 127], [127, 128], [129, 134], [135, 138], [139, 151], [152, 154], [155, 160], [161, 176], [177, 179], [180, 186], [187, 193], [194, 197], [198, 203], [204, 208], [209, 225], [225, 226]]}
{"doc_key": "ai-test-249", "ner": [[6, 7, "country"], [9, 9, "country"], [11, 12, "country"], [19, 20, "organisation"], [15, 16, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 20, 15, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Localised", "versions", "of", "the", "site", "in", "the", "UK", ",", "India", "and", "Australia", "were", "discontinued", "following", "Fandango", "'s", "acquisition", "of", "Rotten", "Tomatoes", "."], "sentence-detokenized": "Localised versions of the site in the UK, India and Australia were discontinued following Fandango's acquisition of Rotten Tomatoes.", "token2charspan": [[0, 9], [10, 18], [19, 21], [22, 25], [26, 30], [31, 33], [34, 37], [38, 40], [40, 41], [42, 47], [48, 51], [52, 61], [62, 66], [67, 79], [80, 89], [90, 98], [98, 100], [101, 112], [113, 115], [116, 122], [123, 131], [131, 132]]}
{"doc_key": "ai-test-250", "ner": [[1, 1, "task"], [11, 12, "metrics"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 11, 12, "related-to", "", false, false], [11, 12, 17, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "NER", "model", "is", "one", "of", "several", "methods", "for", "determining", "the", "accuracy", "of", "live", "captions", "produced", "using", "speech", "recognition", "in", "television", "broadcasts", "and", "events", "."], "sentence-detokenized": "The NER model is one of several methods for determining the accuracy of live captions produced using speech recognition in television broadcasts and events.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 20], [21, 23], [24, 31], [32, 39], [40, 43], [44, 55], [56, 59], [60, 68], [69, 71], [72, 76], [77, 85], [86, 94], [95, 100], [101, 107], [108, 119], [120, 122], [123, 133], [134, 144], [145, 148], [149, 155], [155, 156]]}
{"doc_key": "ai-test-251", "ner": [[0, 0, "researcher"], [3, 5, "university"], [8, 9, "university"], [11, 11, "location"], [13, 17, "university"], [18, 20, "university"], [21, 21, "location"], [24, 31, "university"], [32, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 3, 5, "physical", "", false, false], [0, 0, 3, 5, "role", "", false, false], [0, 0, 8, 9, "physical", "", false, false], [0, 0, 8, 9, "role", "", false, false], [0, 0, 13, 17, "physical", "", false, false], [0, 0, 13, 17, "role", "", false, false], [0, 0, 18, 20, "physical", "", false, false], [0, 0, 18, 20, "role", "", false, false], [0, 0, 24, 31, "physical", "", false, false], [0, 0, 24, 31, "role", "", false, false], [8, 9, 11, 11, "physical", "", false, false], [13, 17, 21, 21, "physical", "", false, false], [18, 20, 21, 21, "physical", "", false, false], [24, 31, 32, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Atran", "has", "taught", "at", "Cambridge", "University", ",", "the", "Hebrew", "University", "in", "Jerusalem", ",", "the", "Ecole", "Normale", "Sup\u00e9rieure", "and", "Ecole", "Polytechnique", "in", "Paris", ",", "and", "the", "John", "Jay", "College", "of", "Criminal", "Justice", "in", "New", "York", "City", "."], "sentence-detokenized": "Atran has taught at Cambridge University, the Hebrew University in Jerusalem, the Ecole Normale Sup\u00e9rieure and Ecole Polytechnique in Paris, and the John Jay College of Criminal Justice in New York City.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 40], [40, 41], [42, 45], [46, 52], [53, 63], [64, 66], [67, 76], [76, 77], [78, 81], [82, 87], [88, 95], [96, 106], [107, 110], [111, 116], [117, 130], [131, 133], [134, 139], [139, 140], [141, 144], [145, 148], [149, 153], [154, 157], [158, 165], [166, 168], [169, 177], [178, 185], [186, 188], [189, 192], [193, 197], [198, 202], [202, 203]]}
{"doc_key": "ai-test-252", "ner": [[0, 0, "product"], [7, 9, "task"], [13, 14, "researcher"], [16, 16, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 9, "origin", "", false, false], [0, 0, 7, 9, "related-to", "", false, false], [7, 9, 16, 16, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "was", "an", "early", "computer", "program", "for", "natural", "language", "understanding", ",", "developed", "by", "Terry", "Winograd", "at", "MIT", "from", "1968", "-", "1970", "."], "sentence-detokenized": "SHRDLU was an early computer program for natural language understanding, developed by Terry Winograd at MIT from 1968-1970.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 19], [20, 28], [29, 36], [37, 40], [41, 48], [49, 57], [58, 71], [71, 72], [73, 82], [83, 85], [86, 91], [92, 100], [101, 103], [104, 107], [108, 112], [113, 117], [117, 118], [118, 122], [122, 123]]}
{"doc_key": "ai-test-253", "ner": [[7, 8, "field"], [10, 14, "university"], [16, 16, "location"], [18, 20, "country"], [28, 29, "university"], [33, 35, "misc"], [36, 40, "field"], [41, 42, "university"], [48, 51, "misc"], [54, 56, "field"], [52, 53, "misc"], [57, 63, "university"], [72, 73, "field"], [77, 78, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[10, 14, 16, 16, "physical", "", false, false], [10, 14, 28, 29, "role", "affiliated_with", false, false], [16, 16, 18, 20, "physical", "", false, false], [33, 35, 36, 40, "topic", "", false, false], [33, 35, 41, 42, "origin", "", false, false], [48, 51, 54, 56, "topic", "", false, false], [52, 53, 57, 63, "origin", "", false, false], [52, 53, 72, 73, "topic", "", false, false], [77, 78, 57, 63, "physical", "", false, false]], "relations_mapping_to_source": [2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["He", "received", "his", "Bachelor", "'s", "degree", "in", "electrical", "engineering", "from", "B.M.S", ".", "College", "of", "Engineering", ",", "Bangalore", ",", "India", ",", "in", "1982", ",", "which", "was", "then", "part", "of", "Bangalore", "University", ",", "his", "Master", "'s", "degree", "in", "electrical", "and", "computer", "engineering", "from", "Drexel", "University", "in", "1984", ",", "and", "his", "Master", "'s", "degree", "and", "PhD", "in", "computer", "science", "from", "the", "University", "of", "Wisconsin", "-", "Madison", "in", "1989", "and", "1990", "respectively", ",", "where", "he", "studied", "artificial", "intelligence", "and", "worked", "with", "Leonard", "Uhr", "."], "sentence-detokenized": "He received his Bachelor's degree in electrical engineering from B.M.S. College of Engineering, Bangalore, India, in 1982, which was then part of Bangalore University, his Master's degree in electrical and computer engineering from Drexel University in 1984, and his Master's degree and PhD in computer science from the University of Wisconsin-Madison in 1989 and 1990 respectively, where he studied artificial intelligence and worked with Leonard Uhr.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 24], [24, 26], [27, 33], [34, 36], [37, 47], [48, 59], [60, 64], [65, 70], [70, 71], [72, 79], [80, 82], [83, 94], [94, 95], [96, 105], [105, 106], [107, 112], [112, 113], [114, 116], [117, 121], [121, 122], [123, 128], [129, 132], [133, 137], [138, 142], [143, 145], [146, 155], [156, 166], [166, 167], [168, 171], [172, 178], [178, 180], [181, 187], [188, 190], [191, 201], [202, 205], [206, 214], [215, 226], [227, 231], [232, 238], [239, 249], [250, 252], [253, 257], [257, 258], [259, 262], [263, 266], [267, 273], [273, 275], [276, 282], [283, 286], [287, 290], [291, 293], [294, 302], [303, 310], [311, 315], [316, 319], [320, 330], [331, 333], [334, 343], [343, 344], [344, 351], [352, 354], [355, 359], [360, 363], [364, 368], [369, 381], [381, 382], [383, 388], [389, 391], [392, 399], [400, 410], [411, 423], [424, 427], [428, 434], [435, 439], [440, 447], [448, 451], [451, 452]]}
{"doc_key": "ai-test-254", "ner": [[7, 9, "metrics"], [11, 11, "metrics"], [21, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Accuracy", "is", "usually", "rated", "in", "terms", "of", "word", "error", "rate", "(", "WER", ")", ",", "while", "speed", "is", "measured", "in", "terms", "of", "the", "actual", "time", "factor", "."], "sentence-detokenized": "Accuracy is usually rated in terms of word error rate (WER), while speed is measured in terms of the actual time factor.", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 25], [26, 28], [29, 34], [35, 37], [38, 42], [43, 48], [49, 53], [54, 55], [55, 58], [58, 59], [59, 60], [61, 66], [67, 72], [73, 75], [76, 84], [85, 87], [88, 93], [94, 96], [97, 100], [101, 107], [108, 112], [113, 119], [119, 120]]}
{"doc_key": "ai-test-255", "ner": [[3, 4, "researcher"], [8, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 8, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1971", ",", "Terry", "Winograd", "developed", "an", "early", "natural", "language", "processing", "engine", "capable", "of", "interpreting", "naturally", "written", "commands", "in", "a", "simple", "rule", "-", "managed", "environment", "."], "sentence-detokenized": "In 1971, Terry Winograd developed an early natural language processing engine capable of interpreting naturally written commands in a simple rule-managed environment.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 33], [34, 36], [37, 42], [43, 50], [51, 59], [60, 70], [71, 77], [78, 85], [86, 88], [89, 101], [102, 111], [112, 119], [120, 128], [129, 131], [132, 133], [134, 140], [141, 145], [145, 146], [146, 153], [154, 165], [165, 166]]}
{"doc_key": "ai-test-256", "ner": [[3, 4, "field"], [6, 7, "researcher"], [9, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 6, 7, "related-to", "", false, false], [3, 4, 9, 12, "related-to", "", false, false], [3, 4, 14, 15, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "terms", "of", "artificial", "intelligence", ",", "Marvin", "Minsky", ",", "Herbert", "A", ".", "Simon", "and", "Alan", "Newell", "are", "all", "prominent", "."], "sentence-detokenized": "In terms of artificial intelligence, Marvin Minsky, Herbert A. Simon and Alan Newell are all prominent.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 22], [23, 35], [35, 36], [37, 43], [44, 50], [50, 51], [52, 59], [60, 61], [61, 62], [63, 68], [69, 72], [73, 77], [78, 84], [85, 88], [89, 92], [93, 102], [102, 103]]}
{"doc_key": "ai-test-257", "ner": [[9, 10, "field"], [29, 30, "field"], [32, 33, "field"], [39, 40, "field"], [49, 52, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[29, 30, 9, 10, "origin", "", true, false], [29, 30, 9, 10, "part-of", "", false, false], [29, 30, 39, 40, "compare", "", false, false], [32, 33, 9, 10, "origin", "", true, false], [32, 33, 9, 10, "part-of", "", false, false], [32, 33, 39, 40, "compare", "", false, false], [39, 40, 9, 10, "origin", "", true, false], [39, 40, 9, 10, "part-of", "", false, false], [39, 40, 49, 52, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "the", "second", "half", "of", "the", "20th", "century", ",", "electrical", "engineering", "itself", "separated", "into", "several", "disciplines", "specialising", "in", "the", "design", "and", "analysis", "of", "systems", "that", "manipulate", "physical", "signals", ";", "electrical", "engineering", "and", "computer", "engineering", ",", "for", "example", ";", "and", "design", "engineering", "developed", "to", "deal", "with", "the", "functional", "design", "of", "user", "-", "machine", "interfaces", "."], "sentence-detokenized": "In the second half of the 20th century, electrical engineering itself separated into several disciplines specialising in the design and analysis of systems that manipulate physical signals; electrical engineering and computer engineering, for example; and design engineering developed to deal with the functional design of user-machine interfaces.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 21], [22, 25], [26, 30], [31, 38], [38, 39], [40, 50], [51, 62], [63, 69], [70, 79], [80, 84], [85, 92], [93, 104], [105, 117], [118, 120], [121, 124], [125, 131], [132, 135], [136, 144], [145, 147], [148, 155], [156, 160], [161, 171], [172, 180], [181, 188], [188, 189], [190, 200], [201, 212], [213, 216], [217, 225], [226, 237], [237, 238], [239, 242], [243, 250], [250, 251], [252, 255], [256, 262], [263, 274], [275, 284], [285, 287], [288, 292], [293, 297], [298, 301], [302, 312], [313, 319], [320, 322], [323, 327], [327, 328], [328, 335], [336, 346], [346, 347]]}
{"doc_key": "ai-test-258", "ner": [[5, 5, "metrics"], [7, 7, "metrics"], [9, 9, "metrics"], [45, 47, "metrics"], [54, 56, "metrics"], [60, 66, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 9, 7, 7, "named", "", false, false], [45, 47, 54, 56, "named", "", false, false], [54, 56, 60, 66, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Perhaps", "the", "simplest", "statistic", "is", "accuracy", "or", "correctness", "(", "FC", ")", ",", "which", "measures", "the", "fraction", "of", "all", "instances", "that", "are", "correctly", "classified", ";", "it", "is", "the", "ratio", "of", "the", "number", "of", "correct", "classifications", "to", "the", "total", "number", "of", "correct", "or", "incorrect", "classifications", ":", "(", "TP", "+", "TN", ")", "/", "total", "population", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "Perhaps the simplest statistic is accuracy or correctness (FC), which measures the fraction of all instances that are correctly classified; it is the ratio of the number of correct classifications to the total number of correct or incorrect classifications: (TP + TN)/total population = (TP + TN)/(TP + TN + FP + FN).", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 30], [31, 33], [34, 42], [43, 45], [46, 57], [58, 59], [59, 61], [61, 62], [62, 63], [64, 69], [70, 78], [79, 82], [83, 91], [92, 94], [95, 98], [99, 108], [109, 113], [114, 117], [118, 127], [128, 138], [138, 139], [140, 142], [143, 145], [146, 149], [150, 155], [156, 158], [159, 162], [163, 169], [170, 172], [173, 180], [181, 196], [197, 199], [200, 203], [204, 209], [210, 216], [217, 219], [220, 227], [228, 230], [231, 240], [241, 256], [256, 257], [258, 259], [259, 261], [262, 263], [264, 266], [266, 267], [267, 268], [268, 273], [274, 284], [285, 286], [287, 288], [288, 290], [291, 292], [293, 295], [295, 296], [296, 297], [297, 298], [298, 300], [301, 302], [303, 305], [306, 307], [308, 310], [311, 312], [313, 315], [315, 316], [316, 317]]}
{"doc_key": "ai-test-259", "ner": [[12, 20, "conference"], [22, 24, "conference"], [28, 30, "location"], [33, 34, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 20, 28, 30, "physical", "", false, false], [22, 24, 12, 20, "named", "", false, false], [33, 34, 12, 20, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "academia", ",", "the", "main", "research", "forum", "began", "in", "1995", "when", "the", "first", "international", "conference", "on", "data", "mining", "and", "knowledge", "discovery", "(", "KDD", "-", "95", ")", "began", "in", "Montreal", "under", "the", "auspices", "of", "the", "AAAI", "."], "sentence-detokenized": "In academia, the main research forum began in 1995 when the first international conference on data mining and knowledge discovery (KDD-95) began in Montreal under the auspices of the AAAI.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 16], [17, 21], [22, 30], [31, 36], [37, 42], [43, 45], [46, 50], [51, 55], [56, 59], [60, 65], [66, 79], [80, 90], [91, 93], [94, 98], [99, 105], [106, 109], [110, 119], [120, 129], [130, 131], [131, 134], [134, 135], [135, 137], [137, 138], [139, 144], [145, 147], [148, 156], [157, 162], [163, 166], [167, 175], [176, 178], [179, 182], [183, 187], [187, 188]]}
{"doc_key": "ai-test-260", "ner": [[5, 6, "field"], [8, 9, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "this", "approach", ",", "different", "data", "mining", ",", "machine", "learning", "algorithms", "are", "used", "to", "develop", "models", "to", "predict", "user", "ratings", "of", "unrated", "items", "."], "sentence-detokenized": "In this approach, different data mining, machine learning algorithms are used to develop models to predict user ratings of unrated items.", "token2charspan": [[0, 2], [3, 7], [8, 16], [16, 17], [18, 27], [28, 32], [33, 39], [39, 40], [41, 48], [49, 57], [58, 68], [69, 72], [73, 77], [78, 80], [81, 88], [89, 95], [96, 98], [99, 106], [107, 111], [112, 119], [120, 122], [123, 130], [131, 136], [136, 137]]}
{"doc_key": "ai-test-261", "ner": [[10, 10, "algorithm"], [15, 16, "algorithm"], [18, 21, "algorithm"], [25, 26, "misc"], [29, 30, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 10, 15, 16, "related-to", "equivalent", false, false], [15, 16, 18, 21, "usage", "", false, false], [18, 21, 29, 30, "usage", "", false, false], [29, 30, 25, 26, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Based", "on", "the", "above", "discussion", ",", "we", "see", "that", "the", "SVM", "technique", "is", "equivalent", "to", "empirical", "risk", "with", "Tikhonov", "regularization", ",", "in", "which", "case", "the", "loss", "function", "is", "the", "hinge", "loss"], "sentence-detokenized": "Based on the above discussion, we see that the SVM technique is equivalent to empirical risk with Tikhonov regularization, in which case the loss function is the hinge loss", "token2charspan": [[0, 5], [6, 8], [9, 12], [13, 18], [19, 29], [29, 30], [31, 33], [34, 37], [38, 42], [43, 46], [47, 50], [51, 60], [61, 63], [64, 74], [75, 77], [78, 87], [88, 92], [93, 97], [98, 106], [107, 121], [121, 122], [123, 125], [126, 131], [132, 136], [137, 140], [141, 145], [146, 154], [155, 157], [158, 161], [162, 167], [168, 172]]}
{"doc_key": "ai-test-262", "ner": [[6, 7, "person"], [9, 10, "person"], [13, 13, "organisation"], [15, 16, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 16, 13, 13, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "2015", "edition", "was", "hosted", "by", "Molly", "McGrath", "with", "Chris", "Rose", "and", "former", "UFC", "fighter", "Kenny", "Florian", "as", "commentators", "."], "sentence-detokenized": "The 2015 edition was hosted by Molly McGrath with Chris Rose and former UFC fighter Kenny Florian as commentators.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 27], [28, 30], [31, 36], [37, 44], [45, 49], [50, 55], [56, 60], [61, 64], [65, 71], [72, 75], [76, 83], [84, 89], [90, 97], [98, 100], [101, 113], [113, 114]]}
{"doc_key": "ai-test-263", "ner": [[3, 6, "product"], [9, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [18, 18, "researcher"], [21, 21, "researcher"], [28, 28, "researcher"], [30, 32, "task"], [34, 34, "product"], [36, 37, "researcher"], [41, 42, "task"], [44, 45, "researcher"], [49, 50, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[3, 6, 9, 11, "origin", "", false, false], [3, 6, 13, 14, "origin", "", false, false], [3, 6, 16, 17, "origin", "", false, false], [3, 6, 18, 18, "origin", "", false, false], [13, 14, 36, 37, "named", "same", false, false], [16, 17, 21, 21, "named", "same", false, false], [16, 17, 28, 28, "named", "same", false, false], [30, 32, 34, 34, "related-to", "", false, false], [34, 34, 28, 28, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["A", "subset", "called", "Micro", "-", "Planner", "was", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "Sussman", ",", "and", "Winograd", "1971", ",", "and", "was", "used", "in", "Winograd", "'s", "natural", "language", "understanding", "program", "SHRDLU", ",", "Eugene", "Charniak", "'s", "work", "on", "story", "comprehension", ",", "Thorne", "McCarty", "'s", "work", "on", "legal", "reasoning", ",", "and", "several", "other", "projects", "."], "sentence-detokenized": "A subset called Micro-Planner was implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd Sussman, and Winograd 1971, and was used in Winograd's natural language understanding program SHRDLU, Eugene Charniak's work on story comprehension, Thorne McCarty's work on legal reasoning, and several other projects.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [21, 22], [22, 29], [30, 33], [34, 45], [46, 48], [49, 55], [56, 59], [60, 67], [67, 68], [69, 75], [76, 84], [85, 88], [89, 94], [95, 103], [104, 111], [111, 112], [113, 116], [117, 125], [126, 130], [130, 131], [132, 135], [136, 139], [140, 144], [145, 147], [148, 156], [156, 158], [159, 166], [167, 175], [176, 189], [190, 197], [198, 204], [204, 205], [206, 212], [213, 221], [221, 223], [224, 228], [229, 231], [232, 237], [238, 251], [251, 252], [253, 259], [260, 267], [267, 269], [270, 274], [275, 277], [278, 283], [284, 293], [293, 294], [295, 298], [299, 306], [307, 312], [313, 321], [321, 322]]}
{"doc_key": "ai-test-264", "ner": [[0, 1, "product"], [11, 12, "product"], [15, 17, "task"], [19, 20, "task"], [22, 24, "task"], [26, 27, "task"], [29, 31, "task"], [33, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 0, 1, "usage", "", true, false], [15, 17, 11, 12, "part-of", "", true, false], [19, 20, 11, 12, "part-of", "", true, false], [22, 24, 11, 12, "part-of", "", true, false], [26, 27, 11, 12, "part-of", "", true, false], [29, 31, 11, 12, "part-of", "", true, false], [33, 36, 11, 12, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Word", "Net", "has", "been", "used", "for", "a", "variety", "of", "purposes", "in", "information", "systems", ",", "including", "word", "sense", "disambiguation", ",", "information", "retrieval", ",", "automatic", "text", "classification", ",", "automatic", "summarisation", ",", "machine", "translation", "and", "even", "automatic", "word", "puzzle", "generation", "."], "sentence-detokenized": "WordNet has been used for a variety of purposes in information systems, including word sense disambiguation, information retrieval, automatic text classification, automatic summarisation, machine translation and even automatic word puzzle generation.", "token2charspan": [[0, 4], [4, 7], [8, 11], [12, 16], [17, 21], [22, 25], [26, 27], [28, 35], [36, 38], [39, 47], [48, 50], [51, 62], [63, 70], [70, 71], [72, 81], [82, 86], [87, 92], [93, 107], [107, 108], [109, 120], [121, 130], [130, 131], [132, 141], [142, 146], [147, 161], [161, 162], [163, 172], [173, 186], [186, 187], [188, 195], [196, 207], [208, 211], [212, 216], [217, 226], [227, 231], [232, 238], [239, 249], [249, 250]]}
{"doc_key": "ai-test-265", "ner": [[2, 3, "researcher"], [8, 14, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 8, 14, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1996", "Keutzer", "was", "appointed", "a", "Fellow", "of", "the", "Institute", "of", "Electrical", "and", "Electronic", "Engineers", "."], "sentence-detokenized": "In 1996 Keutzer was appointed a Fellow of the Institute of Electrical and Electronic Engineers.", "token2charspan": [[0, 2], [3, 7], [8, 15], [16, 19], [20, 29], [30, 31], [32, 38], [39, 41], [42, 45], [46, 55], [56, 58], [59, 69], [70, 73], [74, 84], [85, 94], [94, 95]]}
{"doc_key": "ai-test-266", "ner": [[7, 9, "algorithm"], [53, 55, "misc"], [64, 65, "algorithm"], [67, 68, "algorithm"], [70, 71, "algorithm"], [73, 74, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[64, 65, 53, 55, "type-of", "", false, false], [67, 68, 53, 55, "type-of", "", false, false], [70, 71, 53, 55, "type-of", "", false, false], [73, 74, 53, 55, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "widely", "used", "composition", "type", "is", "the", "non-linear", "weighted", "sum", ",", "where", "math", "\\", "textstyle", "f", "(", "x", ")", "=", "K", "\\", "left", "(", "\\", "sum", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "\\", "right", ")", "/", "math", ",", "where", "math", "\\", "textstyle", "K", "/", "math", "(", "often", "called", "the", "activation", "function", ")", "is", "some", "predefined", "function", "such", "as", "a", "hyperbolic", "tangent", ",", "sigmoid", "functions", ",", "softmax", "functions", "or", "rectifier", "functions", "."], "sentence-detokenized": "A widely used composition type is the non-linear weighted sum, where math\\ textstyle f (x) = K\\ left (\\ sum _ i w _ i g _ i (x)\\ right) / math, where math\\ textstyle K / math (often called the activation function) is some predefined function such as a hyperbolic tangent, sigmoid functions, softmax functions or rectifier functions.", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 25], [26, 30], [31, 33], [34, 37], [38, 48], [49, 57], [58, 61], [61, 62], [63, 68], [69, 73], [73, 74], [75, 84], [85, 86], [87, 88], [88, 89], [89, 90], [91, 92], [93, 94], [94, 95], [96, 100], [101, 102], [102, 103], [104, 107], [108, 109], [110, 111], [112, 113], [114, 115], [116, 117], [118, 119], [120, 121], [122, 123], [124, 125], [125, 126], [126, 127], [127, 128], [129, 134], [134, 135], [136, 137], [138, 142], [142, 143], [144, 149], [150, 154], [154, 155], [156, 165], [166, 167], [168, 169], [170, 174], [175, 176], [176, 181], [182, 188], [189, 192], [193, 203], [204, 212], [212, 213], [214, 216], [217, 221], [222, 232], [233, 241], [242, 246], [247, 249], [250, 251], [252, 262], [263, 270], [270, 271], [272, 279], [280, 289], [289, 290], [291, 298], [299, 308], [309, 311], [312, 321], [322, 331], [331, 332]]}
{"doc_key": "ai-test-267", "ner": [[3, 3, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "film", "Westworld", ",", "female", "robots", "actually", "have", "sex", "with", "human", "men", "as", "part", "of", "a", "fake", "holiday", "world", "that", "human", "customers", "pay", "to", "attend", "."], "sentence-detokenized": "In the film Westworld, female robots actually have sex with human men as part of a fake holiday world that human customers pay to attend.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 21], [21, 22], [23, 29], [30, 36], [37, 45], [46, 50], [51, 54], [55, 59], [60, 65], [66, 69], [70, 72], [73, 77], [78, 80], [81, 82], [83, 87], [88, 95], [96, 101], [102, 106], [107, 112], [113, 122], [123, 126], [127, 129], [130, 136], [136, 137]]}
{"doc_key": "ai-test-268", "ner": [[6, 7, "task"], [25, 30, "task"], [32, 33, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 25, 30, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Typically", ",", "the", "process", "begins", "with", "term", "extraction", "and", "the", "use", "of", "linguistic", "processors", "for", "concepts", "or", "noun", "phrases", "from", "plain", "text", ",", "such", "as", "part", "-", "of", "-", "speech", "tagging", "and", "phrase", "chunking", "."], "sentence-detokenized": "Typically, the process begins with term extraction and the use of linguistic processors for concepts or noun phrases from plain text, such as part-of-speech tagging and phrase chunking.", "token2charspan": [[0, 9], [9, 10], [11, 14], [15, 22], [23, 29], [30, 34], [35, 39], [40, 50], [51, 54], [55, 58], [59, 62], [63, 65], [66, 76], [77, 87], [88, 91], [92, 100], [101, 103], [104, 108], [109, 116], [117, 121], [122, 127], [128, 132], [132, 133], [134, 138], [139, 141], [142, 146], [146, 147], [147, 149], [149, 150], [150, 156], [157, 164], [165, 168], [169, 175], [176, 184], [184, 185]]}
{"doc_key": "ai-test-269", "ner": [[13, 14, "field"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 13, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "demonstrated", "their", "performance", "on", "a", "number", "of", "problems", "of", "interest", "to", "the", "machine", "learning", "community", ",", "including", "handwriting", "recognition", "."], "sentence-detokenized": "They demonstrated their performance on a number of problems of interest to the machine learning community, including handwriting recognition.", "token2charspan": [[0, 4], [5, 17], [18, 23], [24, 35], [36, 38], [39, 40], [41, 47], [48, 50], [51, 59], [60, 62], [63, 71], [72, 74], [75, 78], [79, 86], [87, 95], [96, 105], [105, 106], [107, 116], [117, 128], [129, 140], [140, 141]]}
{"doc_key": "ai-test-270", "ner": [[3, 5, "university"], [7, 8, "researcher"], [14, 17, "researcher"], [19, 26, "product"], [22, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 3, 5, "physical", "", false, false], [7, 8, 3, 5, "role", "", false, false], [19, 26, 14, 17, "origin", "", false, false], [19, 26, 22, 25, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "his", "studies", "at", "Stanford", "University", ",", "Scheinman", "was", "awarded", "a", "scholarship", "sponsored", "by", "George", "DeVore", ",", "the", "inventor", "of", "the", "first", "industrial", "robot", ",", "the", "Unimate", "."], "sentence-detokenized": "During his studies at Stanford University, Scheinman was awarded a scholarship sponsored by George DeVore, the inventor of the first industrial robot, the Unimate.", "token2charspan": [[0, 6], [7, 10], [11, 18], [19, 21], [22, 30], [31, 41], [41, 42], [43, 52], [53, 56], [57, 64], [65, 66], [67, 78], [79, 88], [89, 91], [92, 98], [99, 105], [105, 106], [107, 110], [111, 119], [120, 122], [123, 126], [127, 132], [133, 143], [144, 149], [149, 150], [151, 154], [155, 162], [162, 163]]}
{"doc_key": "ai-test-271", "ner": [[5, 6, "task"], [8, 10, "metrics"], [8, 15, "metrics"], [21, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 8, 10, "usage", "", true, false], [8, 15, 8, 10, "named", "", false, false], [21, 23, 8, 10, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Although", "originally", "used", "to", "evaluate", "machine", "translation", ",", "Bilingual", "Evaluation", "Understudy", "(", "BLEU", ")", "has", "also", "been", "successfully", "used", "to", "evaluate", "transcription", "generation", "models", "."], "sentence-detokenized": "Although originally used to evaluate machine translation, Bilingual Evaluation Understudy (BLEU) has also been successfully used to evaluate transcription generation models.", "token2charspan": [[0, 8], [9, 19], [20, 24], [25, 27], [28, 36], [37, 44], [45, 56], [56, 57], [58, 67], [68, 78], [79, 89], [90, 91], [91, 95], [95, 96], [97, 100], [101, 105], [106, 110], [111, 123], [124, 128], [129, 131], [132, 140], [141, 154], [155, 165], [166, 172], [172, 173]]}
{"doc_key": "ai-test-272", "ner": [[0, 0, "organisation"], [6, 8, "organisation"], [10, 10, "organisation"], [13, 13, "product"], [15, 15, "country"], [17, 18, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 8, "role", "licenses_to", false, false], [0, 0, 10, 10, "role", "licenses_to", false, false], [6, 8, 15, 15, "physical", "", false, false], [10, 10, 17, 18, "physical", "", false, false], [13, 13, 6, 8, "artifact", "produces", false, false], [13, 13, 10, 10, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "later", "licensed", "its", "technology", "to", "Kawasaki", "Heavy", "Industries", "and", "GKN", "to", "build", "Unimates", "in", "Japan", "and", "the", "UK", "respectively", "."], "sentence-detokenized": "Unimation later licensed its technology to Kawasaki Heavy Industries and GKN to build Unimates in Japan and the UK respectively.", "token2charspan": [[0, 9], [10, 15], [16, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 57], [58, 68], [69, 72], [73, 76], [77, 79], [80, 85], [86, 94], [95, 97], [98, 103], [104, 107], [108, 111], [112, 114], [115, 127], [127, 128]]}
{"doc_key": "ai-test-273", "ner": [[20, 21, "conference"], [37, 38, "field"], [56, 60, "field"], [62, 62, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[37, 38, 56, 60, "compare", "", false, false], [62, 62, 56, 60, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Much", "of", "the", "confusion", "between", "these", "two", "research", "groups", "(", "which", "often", "have", "separate", "conferences", "and", "separate", "journals", ",", "with", "ECML", "PKDD", "being", "a", "major", "exception", ")", "stems", "from", "the", "underlying", "assumptions", "of", "their", "work", ":", "in", "machine", "learning", ",", "performance", "is", "usually", "evaluated", "in", "terms", "of", "the", "ability", "to", "replicate", "known", "knowledge", ",", "whereas", "in", "knowledge", "discovery", "and", "data", "mining", "(", "KDD", ")", ",", "the", "key", "task", "is", "to", "discover", "previously", "unknown", "knowledge", "."], "sentence-detokenized": "Much of the confusion between these two research groups (which often have separate conferences and separate journals, with ECML PKDD being a major exception) stems from the underlying assumptions of their work: in machine learning, performance is usually evaluated in terms of the ability to replicate known knowledge, whereas in knowledge discovery and data mining (KDD), the key task is to discover previously unknown knowledge.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 29], [30, 35], [36, 39], [40, 48], [49, 55], [56, 57], [57, 62], [63, 68], [69, 73], [74, 82], [83, 94], [95, 98], [99, 107], [108, 116], [116, 117], [118, 122], [123, 127], [128, 132], [133, 138], [139, 140], [141, 146], [147, 156], [156, 157], [158, 163], [164, 168], [169, 172], [173, 183], [184, 195], [196, 198], [199, 204], [205, 209], [209, 210], [211, 213], [214, 221], [222, 230], [230, 231], [232, 243], [244, 246], [247, 254], [255, 264], [265, 267], [268, 273], [274, 276], [277, 280], [281, 288], [289, 291], [292, 301], [302, 307], [308, 317], [317, 318], [319, 326], [327, 329], [330, 339], [340, 349], [350, 353], [354, 358], [359, 365], [366, 367], [367, 370], [370, 371], [371, 372], [373, 376], [377, 380], [381, 385], [386, 388], [389, 391], [392, 400], [401, 411], [412, 419], [420, 429], [429, 430]]}
{"doc_key": "ai-test-274", "ner": [[0, 1, "algorithm"], [9, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 9, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Hidden", "Markov", "models", "are", "the", "basis", "for", "most", "modern", "automatic", "speech", "recognition", "systems", "."], "sentence-detokenized": "Hidden Markov models are the basis for most modern automatic speech recognition systems.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 28], [29, 34], [35, 38], [39, 43], [44, 50], [51, 60], [61, 67], [68, 79], [80, 87], [87, 88]]}
{"doc_key": "ai-test-275", "ner": [[3, 3, "location"], [12, 13, "task"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "Bangalore", ",", "India", "-", "based", "company", "specialising", "in", "online", "handwriting", "recognition", "software", "."], "sentence-detokenized": "This is a Bangalore, India-based company specialising in online handwriting recognition software.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 19], [19, 20], [21, 26], [26, 27], [27, 32], [33, 40], [41, 53], [54, 56], [57, 63], [64, 75], [76, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-test-276", "ner": [[26, 27, "misc"], [51, 51, "metrics"], [53, 55, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[51, 51, 53, 55, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Does", "the", "translation", "of", "repetition", "converge", "on", "a", "single", "expression", "in", "both", "languages", "?", "That", "is", ",", "does", "the", "translation", "method", "show", "stationarity", "or", "produce", "a", "typical", "form", "?", "Does", "the", "translation", "become", "fixed", "without", "losing", "its", "original", "meaning", "?", "This", "indicator", "has", "been", "criticised", "for", "not", "correlating", "well", "with", "the", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "scores", "."], "sentence-detokenized": "Does the translation of repetition converge on a single expression in both languages? That is, does the translation method show stationarity or produce a typical form? Does the translation become fixed without losing its original meaning? This indicator has been criticised for not correlating well with the BLEU (BiLingual Evaluation Understudy) scores.", "token2charspan": [[0, 4], [5, 8], [9, 20], [21, 23], [24, 34], [35, 43], [44, 46], [47, 48], [49, 55], [56, 66], [67, 69], [70, 74], [75, 84], [84, 85], [86, 90], [91, 93], [93, 94], [95, 99], [100, 103], [104, 115], [116, 122], [123, 127], [128, 140], [141, 143], [144, 151], [152, 153], [154, 161], [162, 166], [166, 167], [168, 172], [173, 176], [177, 188], [189, 195], [196, 201], [202, 209], [210, 216], [217, 220], [221, 229], [230, 237], [237, 238], [239, 243], [244, 253], [254, 257], [258, 262], [263, 273], [274, 277], [278, 281], [282, 293], [294, 298], [299, 303], [304, 307], [308, 312], [313, 314], [314, 323], [324, 334], [335, 345], [345, 346], [347, 353], [353, 354]]}
{"doc_key": "ai-test-277", "ner": [[4, 9, "organisation"], [11, 18, "organisation"], [19, 21, "university"], [28, 29, "university"], [26, 27, "field"], [31, 36, "organisation"], [2, 41, "organisation"], [48, 52, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 18, 19, 21, "part-of", "", false, false], [28, 29, 26, 27, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "holds", "fellowships", "from", "the", "American", "Association", "for", "Artificial", "Intelligence", ",", "the", "Centre", "for", "Advanced", "Study", "in", "Behavioural", "Science", "at", "Stanford", "University", ",", "the", "Centre", "for", "Cognitive", "Science", "at", "MIT", ",", "the", "Canadian", "Institute", "for", "Advanced", "Research", ",", "the", "Canadian", "Psychological", "Association", "and", "was", "elected", "a", "Fellow", "of", "the", "Royal", "Society", "of", "Canada", "in", "1998", "."], "sentence-detokenized": "He holds fellowships from the American Association for Artificial Intelligence, the Centre for Advanced Study in Behavioural Science at Stanford University, the Centre for Cognitive Science at MIT, the Canadian Institute for Advanced Research, the Canadian Psychological Association and was elected a Fellow of the Royal Society of Canada in 1998.", "token2charspan": [[0, 2], [3, 8], [9, 20], [21, 25], [26, 29], [30, 38], [39, 50], [51, 54], [55, 65], [66, 78], [78, 79], [80, 83], [84, 90], [91, 94], [95, 103], [104, 109], [110, 112], [113, 124], [125, 132], [133, 135], [136, 144], [145, 155], [155, 156], [157, 160], [161, 167], [168, 171], [172, 181], [182, 189], [190, 192], [193, 196], [196, 197], [198, 201], [202, 210], [211, 220], [221, 224], [225, 233], [234, 242], [242, 243], [244, 247], [248, 256], [257, 270], [271, 282], [283, 286], [287, 290], [291, 298], [299, 300], [301, 307], [308, 310], [311, 314], [315, 320], [321, 328], [329, 331], [332, 338], [339, 341], [342, 346], [346, 347]]}
{"doc_key": "ai-test-278", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [16, 18, "misc"], [21, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 16, 18, "part-of", "", false, false], [0, 0, 21, 24, "part-of", "", false, false], [4, 5, 16, 18, "part-of", "", false, false], [4, 5, 21, 24, "part-of", "", false, false], [7, 8, 16, 18, "part-of", "", false, false], [7, 8, 21, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", "-", "along", "with", "Yoshua", "Bengio", "and", "Yann", "LeCun", "-", "is", "known", "by", "some", "as", "the", "godfather", "of", "AI", "and", "the", "godfather", "of", "deep", "learning", "."], "sentence-detokenized": "Hinton - along with Yoshua Bengio and Yann LeCun - is known by some as the godfather of AI and the godfather of deep learning.", "token2charspan": [[0, 6], [7, 8], [9, 14], [15, 19], [20, 26], [27, 33], [34, 37], [38, 42], [43, 48], [49, 50], [51, 53], [54, 59], [60, 62], [63, 67], [68, 70], [71, 74], [75, 84], [85, 87], [88, 90], [91, 94], [95, 98], [99, 108], [109, 111], [112, 116], [117, 125], [125, 126]]}
{"doc_key": "ai-test-279", "ner": [[6, 6, "product"], [19, 19, "misc"], [21, 22, "misc"], [23, 25, "product"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 19, 19, "related-to", "", false, false], [6, 6, 21, 22, "related-to", "", false, false], [19, 19, 23, 25, "named", "same", false, false], [28, 29, 23, 25, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "lightweight", "open", "source", "speech", "project", "eSpeak", "has", "its", "own", "synthesis", "method", ",", "which", "it", "has", "experimented", "with", "for", "Mandarin", "and", "Cantonese", ".", "eSpeak", "has", "been", "used", "by", "Google", "Translate", "since", "May", "2010", "."], "sentence-detokenized": "The lightweight open source speech project eSpeak has its own synthesis method, which it has experimented with for Mandarin and Cantonese. eSpeak has been used by Google Translate since May 2010.", "token2charspan": [[0, 3], [4, 15], [16, 20], [21, 27], [28, 34], [35, 42], [43, 49], [50, 53], [54, 57], [58, 61], [62, 71], [72, 78], [78, 79], [80, 85], [86, 88], [89, 92], [93, 105], [106, 110], [111, 114], [115, 123], [124, 127], [128, 137], [137, 138], [139, 145], [146, 149], [150, 154], [155, 159], [160, 162], [163, 169], [170, 179], [180, 185], [186, 189], [190, 194], [194, 195]]}
{"doc_key": "ai-test-280", "ner": [[0, 2, "product"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 17, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Software", "Automated", "Mouth", ",", "also", "released", "in", "1982", ",", "was", "the", "first", "commercially", "available", "full", "software", "speech", "synthesis", "program", "."], "sentence-detokenized": "Software Automated Mouth, also released in 1982, was the first commercially available full software speech synthesis program.", "token2charspan": [[0, 8], [9, 18], [19, 24], [24, 25], [26, 30], [31, 39], [40, 42], [43, 47], [47, 48], [49, 52], [53, 56], [57, 62], [63, 75], [76, 85], [86, 90], [91, 99], [100, 106], [107, 116], [117, 124], [124, 125]]}
{"doc_key": "ai-test-281", "ner": [[7, 9, "metrics"], [11, 11, "metrics"], [16, 16, "metrics"], [18, 18, "metrics"], [21, 27, "metrics"], [36, 36, "metrics"], [39, 46, "metrics"], [50, 52, "metrics"], [54, 54, "metrics"], [59, 59, "metrics"], [61, 61, "metrics"], [64, 71, "metrics"], [32, 77, "metrics"], [79, 79, "metrics"], [82, 89, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[11, 11, 7, 9, "named", "", false, false], [16, 16, 7, 9, "named", "", false, false], [18, 18, 7, 9, "named", "", false, false], [21, 27, 7, 9, "named", "", false, false], [54, 54, 50, 52, "named", "", false, false], [59, 59, 50, 52, "named", "", false, false], [61, 61, 50, 52, "named", "", false, false], [64, 71, 50, 52, "named", "", false, false], [79, 79, 32, 77, "named", "", false, false], [82, 89, 32, 77, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 6, 7, 8, 9, 10, 11], "sentence": ["The", "rates", "in", "this", "column", "are", "the", "true", "positive", "rate", "(", "TPR", ",", "also", "known", "as", "sensitivity", "or", "recall", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "the", "supplementary", "false", "negative", "rate", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ";", "and", "the", "true", "negative", "rate", "(", "TNR", ",", "also", "known", "as", "specificity", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", ",", "the", "supplementary", "false", "positive", "rate", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "The rates in this column are the true positive rate (TPR, also known as sensitivity or recall) (TP/(TP+FN)), the supplementary false negative rate (FNR) (FN/(TP+FN)); and the true negative rate (TNR, also known as specificity, SPC) (TN/(TN+FP)), the supplementary false positive rate (FPR) (FP/(TN+FP)).", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 17], [18, 24], [25, 28], [29, 32], [33, 37], [38, 46], [47, 51], [52, 53], [53, 56], [56, 57], [58, 62], [63, 68], [69, 71], [72, 83], [84, 86], [87, 93], [93, 94], [95, 96], [96, 98], [98, 99], [99, 100], [100, 102], [102, 103], [103, 105], [105, 106], [106, 107], [107, 108], [109, 112], [113, 126], [127, 132], [133, 141], [142, 146], [147, 148], [148, 151], [151, 152], [153, 154], [154, 156], [156, 157], [157, 158], [158, 160], [160, 161], [161, 163], [163, 164], [164, 165], [165, 166], [167, 170], [171, 174], [175, 179], [180, 188], [189, 193], [194, 195], [195, 198], [198, 199], [200, 204], [205, 210], [211, 213], [214, 225], [225, 226], [227, 230], [230, 231], [232, 233], [233, 235], [235, 236], [236, 237], [237, 239], [239, 240], [240, 242], [242, 243], [243, 244], [244, 245], [246, 249], [250, 263], [264, 269], [270, 278], [279, 283], [284, 285], [285, 288], [288, 289], [290, 291], [291, 293], [293, 294], [294, 295], [295, 297], [297, 298], [298, 300], [300, 301], [301, 302], [302, 303]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 3, "person"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 17, 17, "role", "working_with", false, false], [2, 3, 17, 17, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Eisinger", "and", "Weber", "have", "also", "worked", "together", "on", "many", "other", "robots", ",", "as", "has", "their", "experience", "with", "Kismet", "."], "sentence-detokenized": "Eisinger and Weber have also worked together on many other robots, as has their experience with Kismet.", "token2charspan": [[0, 8], [9, 12], [13, 18], [19, 23], [24, 28], [29, 35], [36, 44], [45, 47], [48, 52], [53, 58], [59, 65], [65, 66], [67, 69], [70, 73], [74, 79], [80, 90], [91, 95], [96, 102], [102, 103]]}
{"doc_key": "ai-test-283", "ner": [[0, 3, "programlang"], [16, 18, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 16, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "functionality", "of", "R", "can", "be", "obtained", "from", "a", "number", "of", "scripting", "languages", ",", "such", "as", "Python", ",", "which", "can", "also", "be", "used", "."], "sentence-detokenized": "The functionality of R can be obtained from a number of scripting languages, such as Python, which can also be used.", "token2charspan": [[0, 3], [4, 17], [18, 20], [21, 22], [23, 26], [27, 29], [30, 38], [39, 43], [44, 45], [46, 52], [53, 55], [56, 65], [66, 75], [75, 76], [77, 81], [82, 84], [85, 91], [91, 92], [93, 98], [99, 102], [103, 107], [108, 110], [111, 115], [115, 116]]}
{"doc_key": "ai-test-284", "ner": [[0, 1, "programlang"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 0, 1, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "was", "one", "of", "the", "first", "robotics", "languages", "and", "was", "used", "for", "Unimate", "robots", "."], "sentence-detokenized": "VAL was one of the first robotics languages and was used for Unimate robots.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 18], [19, 24], [25, 33], [34, 43], [44, 47], [48, 51], [52, 56], [57, 60], [61, 68], [69, 75], [75, 76]]}
{"doc_key": "ai-test-285", "ner": [[13, 19, "conference"], [21, 21, "conference"], [23, 24, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 19, 23, 24, "physical", "", false, false], [21, 21, 13, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["They", "presented", "their", "database", "for", "the", "first", "time", "in", "poster", "form", "at", "the", "2009", "Computer", "Vision", "and", "Pattern", "Recognition", "Conference", "(", "CVPR", ")", "in", "Florida", "."], "sentence-detokenized": "They presented their database for the first time in poster form at the 2009 Computer Vision and Pattern Recognition Conference (CVPR) in Florida.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 29], [30, 33], [34, 37], [38, 43], [44, 48], [49, 51], [52, 58], [59, 63], [64, 66], [67, 70], [71, 75], [76, 84], [85, 91], [92, 95], [96, 103], [104, 115], [116, 126], [127, 128], [128, 132], [132, 133], [134, 136], [137, 144], [144, 145]]}
{"doc_key": "ai-test-286", "ner": [[0, 3, "misc"], [10, 11, "task"], [13, 14, "field"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 11, 0, 3, "type-of", "", false, false], [13, 14, 0, 3, "type-of", "", false, false], [17, 18, 0, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Classification", "tasks", "that", "do", "not", "provide", "labels", "are", "known", "as", "unsupervised", "classification", ",", "unsupervised", "learning", ",", "and", "cluster", "analysis", "."], "sentence-detokenized": "Classification tasks that do not provide labels are known as unsupervised classification, unsupervised learning, and cluster analysis.", "token2charspan": [[0, 14], [15, 20], [21, 25], [26, 28], [29, 32], [33, 40], [41, 47], [48, 51], [52, 57], [58, 60], [61, 73], [74, 88], [88, 89], [90, 102], [103, 111], [111, 112], [113, 116], [117, 124], [125, 133], [133, 134]]}
{"doc_key": "ai-test-287", "ner": [[4, 5, "task"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "needs", "to", "perform", "object", "recognition", ",", "identify", "and", "locate", "humans", "and", "furthermore", "perform", "emotion", "recognition", "."], "sentence-detokenized": "It needs to perform object recognition, identify and locate humans and furthermore perform emotion recognition.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 19], [20, 26], [27, 38], [38, 39], [40, 48], [49, 52], [53, 59], [60, 66], [67, 70], [71, 82], [83, 90], [91, 98], [99, 110], [110, 111]]}
{"doc_key": "ai-test-288", "ner": [[6, 6, "misc"], [8, 8, "misc"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "process", "is", "complex", "and", "involves", "coding", "and", "recall", "or", "retrieval", "."], "sentence-detokenized": "The process is complex and involves coding and recall or retrieval.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 26], [27, 35], [36, 42], [43, 46], [47, 53], [54, 56], [57, 66], [66, 67]]}
{"doc_key": "ai-test-289", "ner": [[7, 9, "product"], [7, 7, "product"], [29, 30, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 7, 7, "named", "", false, false], [7, 9, 29, 30, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Also", "known", "as", "parallel", "robots", ",", "or", "Stewart", "platforms", "in", "the", "broad", "sense", "(", "in", "which", "actuators", "are", "paired", "on", "the", "base", "and", "platform", ")", ",", "these", "systems", "are", "articulated", "robots", "that", "use", "a", "similar", "mechanism", "to", "move", "the", "robot", "on", "its", "base", ",", "or", "one", "or", "more", "manipulator", "arms", "."], "sentence-detokenized": "Also known as parallel robots, or Stewart platforms in the broad sense (in which actuators are paired on the base and platform), these systems are articulated robots that use a similar mechanism to move the robot on its base, or one or more manipulator arms.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 29], [29, 30], [31, 33], [34, 41], [42, 51], [52, 54], [55, 58], [59, 64], [65, 70], [71, 72], [72, 74], [75, 80], [81, 90], [91, 94], [95, 101], [102, 104], [105, 108], [109, 113], [114, 117], [118, 126], [126, 127], [127, 128], [129, 134], [135, 142], [143, 146], [147, 158], [159, 165], [166, 170], [171, 174], [175, 176], [177, 184], [185, 194], [195, 197], [198, 202], [203, 206], [207, 212], [213, 215], [216, 219], [220, 224], [224, 225], [226, 228], [229, 232], [233, 235], [236, 240], [241, 252], [253, 257], [257, 258]]}
{"doc_key": "ai-test-290", "ner": [[0, 1, "field"], [4, 5, "field"], [13, 14, "field"], [20, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 5, "part-of", "subfield", false, false], [0, 1, 13, 14, "compare", "", false, false], [13, 14, 20, 21, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "vision", "as", "a", "systems", "engineering", "discipline", "can", "be", "seen", "as", "distinct", "from", "computer", "vision", "and", "as", "a", "form", "of", "computer", "science", "."], "sentence-detokenized": "Machine vision as a systems engineering discipline can be seen as distinct from computer vision and as a form of computer science.", "token2charspan": [[0, 7], [8, 14], [15, 17], [18, 19], [20, 27], [28, 39], [40, 50], [51, 54], [55, 57], [58, 62], [63, 65], [66, 74], [75, 79], [80, 88], [89, 95], [96, 99], [100, 102], [103, 104], [105, 109], [110, 112], [113, 121], [122, 129], [129, 130]]}
{"doc_key": "ai-test-291", "ner": [[4, 5, "algorithm"], [9, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 9, 11, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "activation", "function", "for", "LSTM", "gates", "is", "usually", "a", "logistic", "sigmoid", "function", "."], "sentence-detokenized": "The activation function for LSTM gates is usually a logistic sigmoid function.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 27], [28, 32], [33, 38], [39, 41], [42, 49], [50, 51], [52, 60], [61, 68], [69, 77], [77, 78]]}
{"doc_key": "ai-test-292", "ner": [[5, 8, "metrics"], [18, 21, "metrics"], [23, 23, "metrics"], [31, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 8, 18, 21, "named", "", false, false], [5, 8, 31, 33, "named", "", false, false], [23, 23, 18, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "other", "words", ",", "the", "sample", "mean", "is", "the", "(", "necessarily", "unique", ")", "valid", "estimate", "and", "therefore", "the", "minimum", "variance", "unbiased", "estimate", "(", "MVUE", ")", ",", "in", "addition", "to", "being", "the", "maximum", "likelihood", "estimate", "."], "sentence-detokenized": "In other words, the sample mean is the (necessarily unique) valid estimate and therefore the minimum variance unbiased estimate (MVUE), in addition to being the maximum likelihood estimate.", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 19], [20, 26], [27, 31], [32, 34], [35, 38], [39, 40], [40, 51], [52, 58], [58, 59], [60, 65], [66, 74], [75, 78], [79, 88], [89, 92], [93, 100], [101, 109], [110, 118], [119, 127], [128, 129], [129, 133], [133, 134], [134, 135], [136, 138], [139, 147], [148, 150], [151, 156], [157, 160], [161, 168], [169, 179], [180, 188], [188, 189]]}
{"doc_key": "ai-test-293", "ner": [[26, 27, "academicjournal"], [14, 16, "researcher"], [18, 19, "researcher"], [21, 24, "researcher"], [6, 6, "product"], [8, 11, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[26, 27, 6, 6, "topic", "", false, false], [26, 27, 8, 11, "topic", "", false, false], [14, 16, 26, 27, "role", "", false, false], [18, 19, 26, 27, "role", "", false, false], [21, 24, 26, 27, "role", "", false, false], [6, 6, 8, 11, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "expected", "evolution", "of", "the", "existing", "web", "to", "the", "Semantic", "Web", "is", "described", "by", "Berners", "-", "Lee", ",", "James", "Hendler", "and", "Ola", "Lassila", "in", "their", "2001", "Scientific", "American", "article", "."], "sentence-detokenized": "The expected evolution of the existing web to the Semantic Web is described by Berners-Lee, James Hendler and Ola Lassila in their 2001 Scientific American article.", "token2charspan": [[0, 3], [4, 12], [13, 22], [23, 25], [26, 29], [30, 38], [39, 42], [43, 45], [46, 49], [50, 58], [59, 62], [63, 65], [66, 75], [76, 78], [79, 86], [86, 87], [87, 90], [90, 91], [92, 97], [98, 105], [106, 109], [110, 113], [114, 121], [122, 124], [125, 130], [131, 135], [136, 146], [147, 155], [156, 163], [163, 164]]}
{"doc_key": "ai-test-294", "ner": [[0, 1, "misc"], [14, 15, "person"], [17, 17, "person"], [27, 28, "person"], [38, 38, "person"], [44, 44, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 15, 0, 1, "role", "actor_in_work", false, false], [17, 17, 14, 15, "named", "", false, false], [17, 17, 14, 15, "origin", "", false, false], [27, 28, 17, 17, "part-of", "", false, false], [44, 44, 17, 17, "role", "auditioned_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Blade", "Runner", "uses", "some", "of", "the", "lesser", "-", "known", "actors", "of", "the", "time", ".", "Sean", "Young", "played", "Rachael", ",", "an", "experimental", "replicant", "whose", "memory", "was", "implanted", "in", "Tyr", "'s", "niece", "to", "convince", "her", "that", "she", "was", "human", ";", "Salmon", ",", "pp.", "92", "-", "93", "Nina", "Axelrod", "auditioned", "for", "the", "role", "."], "sentence-detokenized": "Blade Runner uses some of the lesser-known actors of the time. Sean Young played Rachael, an experimental replicant whose memory was implanted in Tyr's niece to convince her that she was human; Salmon, pp. 92-93 Nina Axelrod auditioned for the role.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 22], [23, 25], [26, 29], [30, 36], [36, 37], [37, 42], [43, 49], [50, 52], [53, 56], [57, 61], [61, 62], [63, 67], [68, 73], [74, 80], [81, 88], [88, 89], [90, 92], [93, 105], [106, 115], [116, 121], [122, 128], [129, 132], [133, 142], [143, 145], [146, 149], [149, 151], [152, 157], [158, 160], [161, 169], [170, 173], [174, 178], [179, 182], [183, 186], [187, 192], [192, 193], [194, 200], [200, 201], [202, 205], [206, 208], [208, 209], [209, 211], [212, 216], [217, 224], [225, 235], [236, 239], [240, 243], [244, 248], [248, 249]]}
{"doc_key": "ai-test-295", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [12, 15, "university"], [23, 25, "product"], [27, 27, "product"], [49, 49, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 12, 15, "physical", "", false, false], [3, 4, 12, 15, "physical", "", false, false], [6, 7, 12, 15, "physical", "", false, false], [9, 10, 12, 15, "physical", "", false, false], [12, 15, 49, 49, "physical", "", true, false], [23, 25, 12, 15, "temporal", "", false, false], [27, 27, 12, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Gerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "and", "Terry", "Winograd", "visited", "the", "University", "of", "Edinburgh", "in", "1971", "to", "spread", "the", "word", "about", "Micro", "-", "Planner", "and", "SHRDLU", "and", "to", "express", "doubts", "about", "the", "unified", "proof", "-", "of", "-", "procedure", "approach", "to", "resolution", "that", "had", "been", "the", "backbone", "of", "Edinburgh", "logicians", "."], "sentence-detokenized": "Gerry Sussman, Eugene Charniak, Seymour Papert and Terry Winograd visited the University of Edinburgh in 1971 to spread the word about Micro-Planner and SHRDLU and to express doubts about the unified proof-of-procedure approach to resolution that had been the backbone of Edinburgh logicians.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 21], [22, 30], [30, 31], [32, 39], [40, 46], [47, 50], [51, 56], [57, 65], [66, 73], [74, 77], [78, 88], [89, 91], [92, 101], [102, 104], [105, 109], [110, 112], [113, 119], [120, 123], [124, 128], [129, 134], [135, 140], [140, 141], [141, 148], [149, 152], [153, 159], [160, 163], [164, 166], [167, 174], [175, 181], [182, 187], [188, 191], [192, 199], [200, 205], [205, 206], [206, 208], [208, 209], [209, 218], [219, 227], [228, 230], [231, 241], [242, 246], [247, 250], [251, 255], [256, 259], [260, 268], [269, 271], [272, 281], [282, 291], [291, 292]]}
{"doc_key": "ai-test-296", "ner": [[0, 0, "researcher"], [7, 7, "field"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 12, 13, "role", "inspires", false, false], [0, 0, 15, 16, "role", "inspires", false, false], [0, 0, 18, 19, "role", "inspires", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Walter", "'s", "work", "inspired", "subsequent", "generations", "of", "robotics", "researchers", ",", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "Walter's work inspired subsequent generations of robotics researchers, such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 6], [6, 8], [9, 13], [14, 22], [23, 33], [34, 45], [46, 48], [49, 57], [58, 69], [69, 70], [71, 75], [76, 78], [79, 85], [86, 92], [92, 93], [94, 98], [99, 106], [107, 110], [111, 115], [116, 122], [122, 123]]}
{"doc_key": "ai-test-297", "ner": [[5, 5, "algorithm"], [7, 8, "researcher"], [15, 21, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 7, 8, "origin", "", false, false], [5, 5, 15, 21, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "similar", "GPU", "-", "based", "CNN", "by", "Alex", "Krizhevsky", "et", "al", ".", "subsequently", "won", "the", "2012", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "."], "sentence-detokenized": "A similar GPU-based CNN by Alex Krizhevsky et al. subsequently won the 2012 ImageNet Large Scale Visual Recognition Challenge.", "token2charspan": [[0, 1], [2, 9], [10, 13], [13, 14], [14, 19], [20, 23], [24, 26], [27, 31], [32, 42], [43, 45], [46, 48], [48, 49], [50, 62], [63, 66], [67, 70], [71, 75], [76, 84], [85, 90], [91, 96], [97, 103], [104, 115], [116, 125], [125, 126]]}
{"doc_key": "ai-test-298", "ner": [[2, 3, "misc"], [8, 9, "metrics"], [11, 12, "metrics"], [16, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 2, 3, "type-of", "", false, false], [11, 12, 2, 3, "type-of", "", false, false], [11, 12, 16, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Commonly", "used", "loss", "functions", "for", "probability", "classification", "include", "logarithmic", "loss", "and", "Brier", "scores", "between", "predicted", "and", "true", "probability", "distributions", "."], "sentence-detokenized": "Commonly used loss functions for probability classification include logarithmic loss and Brier scores between predicted and true probability distributions.", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 28], [29, 32], [33, 44], [45, 59], [60, 67], [68, 79], [80, 84], [85, 88], [89, 94], [95, 101], [102, 109], [110, 119], [120, 123], [124, 128], [129, 140], [141, 154], [154, 155]]}
{"doc_key": "ai-test-299", "ner": [[4, 5, "organisation"], [13, 13, "field"], [16, 16, "organisation"], [19, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 13, 13, "general-affiliation", "field_of_study", false, false], [4, 5, 19, 20, "part-of", "", false, false], [16, 16, 4, 5, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "May", "2016", ",", "NtechLab", "was", "accepted", "as", "an", "official", "test", "subject", "for", "biometric", "technology", "by", "NIST", "among", "three", "Russian", "companies", "."], "sentence-detokenized": "In May 2016, NtechLab was accepted as an official test subject for biometric technology by NIST among three Russian companies.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [13, 21], [22, 25], [26, 34], [35, 37], [38, 40], [41, 49], [50, 54], [55, 62], [63, 66], [67, 76], [77, 87], [88, 90], [91, 95], [96, 101], [102, 107], [108, 115], [116, 125], [125, 126]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "floating", "point", "numbers", "only", "have", "a", "certain", "mathematical", "precision", "."], "sentence-detokenized": "However, floating point numbers only have a certain mathematical precision.", "token2charspan": [[0, 7], [7, 8], [9, 17], [18, 23], [24, 31], [32, 36], [37, 41], [42, 43], [44, 51], [52, 64], [65, 74], [74, 75]]}
{"doc_key": "ai-test-301", "ner": [[5, 5, "organisation"], [11, 17, "conference"], [19, 19, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 11, 17, "role", "contributes_to", false, false], [19, 19, 11, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "2015", ",", "many", "of", "SenseTime", "'s", "papers", "were", "accepted", "at", "the", "Computer", "Vision", "and", "Pattern", "Recognition", "Conference", "(", "CVPR", ")", "."], "sentence-detokenized": "During 2015, many of SenseTime's papers were accepted at the Computer Vision and Pattern Recognition Conference (CVPR).", "token2charspan": [[0, 6], [7, 11], [11, 12], [13, 17], [18, 20], [21, 30], [30, 32], [33, 39], [40, 44], [45, 53], [54, 56], [57, 60], [61, 69], [70, 76], [77, 80], [81, 88], [89, 100], [101, 111], [112, 113], [113, 117], [117, 118], [118, 119]]}
{"doc_key": "ai-test-302", "ner": [[7, 9, "task"], [11, 11, "task"], [14, 15, "task"], [17, 20, "task"], [23, 23, "field"], [25, 27, "misc"], [30, 36, "conference"], [43, 45, "misc"], [47, 48, "conference"], [66, 69, "misc"], [70, 70, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[7, 9, 23, 23, "part-of", "task_part_of_field", false, false], [11, 11, 7, 9, "named", "", false, false], [14, 15, 23, 23, "part-of", "task_part_of_field", false, false], [17, 20, 14, 15, "named", "", false, false], [25, 27, 30, 36, "temporal", "", false, false], [43, 45, 47, 48, "temporal", "", false, false], [66, 69, 70, 70, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["He", "co", "-developed", "the", "best", "algorithm", "for", "structure", "from", "motion", "(", "SFM", ",", "or", "visual", "SLAM", ",", "simultaneous", "localisation", "and", "mapping", ",", "in", "robotics", ";", "Best", "Paper", "Award", ",", "1998", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ")", ",", "described", "its", "ambiguity", "(", "David", "Marr", "Award", ",", "ICCV", "1999", ")", ",", "and", "also", "described", "the", "recognisability", "and", "observability", "of", "vision", "-", "inertial", "sensor", "fusion", "(", "2015", "Best", "Paper", "Award", "in", "Robotics", ")", "."], "sentence-detokenized": "He co-developed the best algorithm for structure from motion (SFM, or visual SLAM, simultaneous localisation and mapping, in robotics; Best Paper Award, 1998 Conference on Computer Vision and Pattern Recognition), described its ambiguity (David Marr Award, ICCV 1999), and also described the recognisability and observability of vision-inertial sensor fusion (2015 Best Paper Award in Robotics).", "token2charspan": [[0, 2], [3, 5], [5, 15], [16, 19], [20, 24], [25, 34], [35, 38], [39, 48], [49, 53], [54, 60], [61, 62], [62, 65], [65, 66], [67, 69], [70, 76], [77, 81], [81, 82], [83, 95], [96, 108], [109, 112], [113, 120], [120, 121], [122, 124], [125, 133], [133, 134], [135, 139], [140, 145], [146, 151], [151, 152], [153, 157], [158, 168], [169, 171], [172, 180], [181, 187], [188, 191], [192, 199], [200, 211], [211, 212], [212, 213], [214, 223], [224, 227], [228, 237], [238, 239], [239, 244], [245, 249], [250, 255], [255, 256], [257, 261], [262, 266], [266, 267], [267, 268], [269, 272], [273, 277], [278, 287], [288, 291], [292, 307], [308, 311], [312, 325], [326, 328], [329, 335], [335, 336], [336, 344], [345, 351], [352, 358], [359, 360], [360, 364], [365, 369], [370, 375], [376, 381], [382, 384], [385, 393], [393, 394], [394, 395]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 44], [45, 48], [49, 52], [53, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-304", "ner": [[0, 1, "task"], [7, 8, "field"], [10, 11, "field"], [13, 14, "field"], [21, 22, "task"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 7, 8, "part-of", "task_part_of_field", false, false], [0, 1, 10, 11, "part-of", "task_part_of_field", false, false], [0, 1, 13, 14, "part-of", "task_part_of_field", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 24, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Edge", "detection", "is", "a", "fundamental", "tool", "in", "image", "processing", ",", "machine", "vision", "and", "computer", "vision", ",", "especially", "in", "the", "field", "of", "feature", "detection", "and", "feature", "extraction", "."], "sentence-detokenized": "Edge detection is a fundamental tool in image processing, machine vision and computer vision, especially in the field of feature detection and feature extraction.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 19], [20, 31], [32, 36], [37, 39], [40, 45], [46, 56], [56, 57], [58, 65], [66, 72], [73, 76], [77, 85], [86, 92], [92, 93], [94, 104], [105, 107], [108, 111], [112, 117], [118, 120], [121, 128], [129, 138], [139, 142], [143, 150], [151, 161], [161, 162]]}
{"doc_key": "ai-test-305", "ner": [[9, 10, "misc"], [27, 31, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "example", "of", "this", "is", "a", "variable", "such", "as", "external", "temperature", "(", "mathtemp", "/", "math", ")", ",", "which", "in", "a", "particular", "application", "may", "be", "recorded", "to", "a", "few", "decimal", "places", "of", "precision", "(", "depending", "on", "the", "sensing", "device", ")", "."], "sentence-detokenized": "An example of this is a variable such as external temperature (mathtemp / math), which in a particular application may be recorded to a few decimal places of precision (depending on the sensing device).", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 18], [19, 21], [22, 23], [24, 32], [33, 37], [38, 40], [41, 49], [50, 61], [62, 63], [63, 71], [72, 73], [74, 78], [78, 79], [79, 80], [81, 86], [87, 89], [90, 91], [92, 102], [103, 114], [115, 118], [119, 121], [122, 130], [131, 133], [134, 135], [136, 139], [140, 147], [148, 154], [155, 157], [158, 167], [168, 169], [169, 178], [179, 181], [182, 185], [186, 193], [194, 200], [200, 201], [201, 202]]}
{"doc_key": "ai-test-306", "ner": [[2, 4, "person"], [6, 7, "person"], [9, 10, "person"], [19, 20, "person"], [22, 22, "misc"], [26, 26, "misc"], [28, 29, "person"], [31, 31, "organisation"], [33, 34, "person"], [36, 36, "organisation"], [38, 39, "person"], [42, 42, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[28, 29, 22, 22, "part-of", "", false, false], [28, 29, 26, 26, "role", "", false, false], [33, 34, 31, 31, "role", "", false, false], [38, 39, 36, 36, "role", "youtuber", false, false], [42, 42, 38, 39, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Returning", "judges", "are", "Fon", "Davis", ",", "Jessica", "Chobot", "and", "Leland", "Melvin", ",", "as", "well", "as", "celebrity", "guest", "judges", "actor", "Clark", "Gregg", ",", "Mythbusters", "host", "and", "former", "Battlebots", "builder", "Adam", "Savage", ",", "NFL", "linebacker", "Vernon", "Davis", "and", "YouTube", "star", "Michael", "Stevens", ",", "aka", "Vsauce", "."], "sentence-detokenized": "Returning judges are Fon Davis, Jessica Chobot and Leland Melvin, as well as celebrity guest judges actor Clark Gregg, Mythbusters host and former Battlebots builder Adam Savage, NFL linebacker Vernon Davis and YouTube star Michael Stevens, aka Vsauce.", "token2charspan": [[0, 9], [10, 16], [17, 20], [21, 24], [25, 30], [30, 31], [32, 39], [40, 46], [47, 50], [51, 57], [58, 64], [64, 65], [66, 68], [69, 73], [74, 76], [77, 86], [87, 92], [93, 99], [100, 105], [106, 111], [112, 117], [117, 118], [119, 130], [131, 135], [136, 139], [140, 146], [147, 157], [158, 165], [166, 170], [171, 177], [177, 178], [179, 182], [183, 193], [194, 200], [201, 206], [207, 210], [211, 218], [219, 223], [224, 231], [232, 239], [239, 240], [241, 244], [245, 251], [251, 252]]}
{"doc_key": "ai-test-307", "ner": [[12, 13, "algorithm"], [16, 18, "algorithm"], [14, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 13, 14, 24, "part-of", "", false, false], [16, 18, 14, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "these", "methods", "never", "win", "over", "non-uniform", "internally", "hand", "-", "crafted", "Gaussian", "Hybrid", "Model", "/", "Hidden", "Markov", "Model", "(", "GMM", "-", "HMM", ")", "techniques", "based", "on", "speech", "generative", "models", ",", "which", "are", "trained", "discriminatively", "."], "sentence-detokenized": "However, these methods never win over non-uniform internally hand-crafted Gaussian Hybrid Model/Hidden Markov Model (GMM-HMM) techniques based on speech generative models, which are trained discriminatively.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 22], [23, 28], [29, 32], [33, 37], [38, 49], [50, 60], [61, 65], [65, 66], [66, 73], [74, 82], [83, 89], [90, 95], [95, 96], [96, 102], [103, 109], [110, 115], [116, 117], [117, 120], [120, 121], [121, 124], [124, 125], [126, 136], [137, 142], [143, 145], [146, 152], [153, 163], [164, 170], [170, 171], [172, 177], [178, 181], [182, 189], [190, 206], [206, 207]]}
{"doc_key": "ai-test-308", "ner": [[3, 3, "product"], [5, 6, "programlang"], [8, 8, "programlang"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Packages", "such", "as", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", "and", "SciPy", "facilitate", "the", "application", "of", "these", "different", "methods", "."], "sentence-detokenized": "Packages such as MATLAB, GNU Octave, Scilab and SciPy facilitate the application of these different methods.", "token2charspan": [[0, 8], [9, 13], [14, 16], [17, 23], [23, 24], [25, 28], [29, 35], [35, 36], [37, 43], [44, 47], [48, 53], [54, 64], [65, 68], [69, 80], [81, 83], [84, 89], [90, 99], [100, 107], [107, 108]]}
{"doc_key": "ai-test-309", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [8, 9, "task"], [14, 15, "researcher"], [17, 18, "university"], [20, 21, "researcher"], [23, 27, "organisation"], [29, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 8, 9, "related-to", "", false, false], [0, 2, 14, 15, "origin", "", false, false], [0, 2, 20, 21, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [14, 15, 17, 18, "physical", "", false, false], [14, 15, 17, 18, "role", "", false, false], [20, 21, 23, 27, "physical", "", false, false], [20, 21, 23, 27, "role", "", false, false], [29, 29, 23, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Linear", "Predictive", "Coding", "(", "LPC", ")", "is", "a", "speech", "processing", "algorithm", "first", "proposed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "Corporation", "(", "NTT", ")", "in", "1966", "."], "sentence-detokenized": "Linear Predictive Coding (LPC) is a speech processing algorithm first proposed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone Corporation (NTT) in 1966.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [31, 33], [34, 35], [36, 42], [43, 53], [54, 63], [64, 69], [70, 78], [79, 81], [82, 90], [91, 98], [99, 101], [102, 108], [109, 119], [120, 123], [124, 129], [130, 135], [136, 138], [139, 145], [146, 155], [156, 159], [160, 169], [170, 181], [182, 183], [183, 186], [186, 187], [188, 190], [191, 195], [195, 196]]}
{"doc_key": "ai-test-310", "ner": [[18, 25, "conference"], [27, 29, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[27, 29, 18, 25, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2006", ",", "to", "mark", "the", "25th", "anniversary", "of", "the", "algorithm", ",", "a", "workshop", "was", "organised", "at", "the", "International", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "to", "summarise", "the", "latest", "contributions", "and", "changes", "to", "the", "original", "algorithm", ",", "primarily", "to", "improve", "the", "speed", "of", "the", "algorithm", ",", "the", "robustness", "and", "accuracy", "of", "the", "estimation", "solution", ",", "and", "to", "reduce", "the", "reliance", "on", "user", "-", "defined", "constants", "."], "sentence-detokenized": "In 2006, to mark the 25th anniversary of the algorithm, a workshop was organised at the International Conference on Computer Vision and Pattern Recognition (CVPR) to summarise the latest contributions and changes to the original algorithm, primarily to improve the speed of the algorithm, the robustness and accuracy of the estimation solution, and to reduce the reliance on user-defined constants.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 16], [17, 20], [21, 25], [26, 37], [38, 40], [41, 44], [45, 54], [54, 55], [56, 57], [58, 66], [67, 70], [71, 80], [81, 83], [84, 87], [88, 101], [102, 112], [113, 115], [116, 124], [125, 131], [132, 135], [136, 143], [144, 155], [156, 157], [157, 161], [161, 162], [163, 165], [166, 175], [176, 179], [180, 186], [187, 200], [201, 204], [205, 212], [213, 215], [216, 219], [220, 228], [229, 238], [238, 239], [240, 249], [250, 252], [253, 260], [261, 264], [265, 270], [271, 273], [274, 277], [278, 287], [287, 288], [289, 292], [293, 303], [304, 307], [308, 316], [317, 319], [320, 323], [324, 334], [335, 343], [343, 344], [345, 348], [349, 351], [352, 358], [359, 362], [363, 371], [372, 374], [375, 379], [379, 380], [380, 387], [388, 397], [397, 398]]}
{"doc_key": "ai-test-311", "ner": [[3, 6, "university"], [8, 12, "organisation"], [14, 16, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Members", "went", "to", "the", "University", "of", "Debrecen", ",", "the", "Hungarian", "Academy", "of", "Sciences", ",", "E\u00f6tv\u00f6s", "Lor\u00e1nd", "University", ",", "etc", "."], "sentence-detokenized": "Members went to the University of Debrecen, the Hungarian Academy of Sciences, E\u00f6tv\u00f6s Lor\u00e1nd University, etc.", "token2charspan": [[0, 7], [8, 12], [13, 15], [16, 19], [20, 30], [31, 33], [34, 42], [42, 43], [44, 47], [48, 57], [58, 65], [66, 68], [69, 77], [77, 78], [79, 85], [86, 92], [93, 103], [103, 104], [105, 108], [108, 109]]}
{"doc_key": "ai-test-312", "ner": [[2, 3, "algorithm"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "extend", "the", "SVM", "to", "the", "case", "where", "the", "data", "is", "not", "linearly", "separable", ",", "we", "introduce", "a", "loss", "function", "."], "sentence-detokenized": "To extend the SVM to the case where the data is not linearly separable, we introduce a loss function.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 17], [18, 20], [21, 24], [25, 29], [30, 35], [36, 39], [40, 44], [45, 47], [48, 51], [52, 60], [61, 70], [70, 71], [72, 74], [75, 84], [85, 86], [87, 91], [92, 100], [100, 101]]}
{"doc_key": "ai-test-313", "ner": [[0, 0, "programlang"], [8, 9, "researcher"], [11, 12, "researcher"], [14, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 8, 9, "origin", "", false, false], [0, 0, 11, 12, "origin", "", false, false], [0, 0, 14, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Logo", "is", "an", "educational", "programming", "language", "designed", "by", "Wally", "Feurzeig", ",", "Seymour", "Papert", "and", "Cynthia", "Solomon", "in", "1967", "."], "sentence-detokenized": "Logo is an educational programming language designed by Wally Feurzeig, Seymour Papert and Cynthia Solomon in 1967.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 34], [35, 43], [44, 52], [53, 55], [56, 61], [62, 70], [70, 71], [72, 79], [80, 86], [87, 90], [91, 98], [99, 106], [107, 109], [110, 114], [114, 115]]}
{"doc_key": "ai-test-314", "ner": [[0, 2, "organisation"], [22, 23, "organisation"], [26, 29, "location"], [31, 31, "location"], [32, 37, "location"], [15, 21, "product"], [44, 48, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 22, 23, "role", "works_for", false, false], [22, 23, 26, 29, "physical", "", false, false], [26, 29, 31, 31, "physical", "", false, false], [31, 31, 32, 37, "physical", "", false, false], [15, 21, 0, 2, "origin", "", false, false], [44, 48, 15, 21, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "Eyring", "Institute", "was", "instrumental", "in", "the", "production", ",", "under", "top", "military", "secrecy", ",", "of", "the", "Intelligent", "Systems", "Technology", "software", "for", "the", "USAF", "Missile", "Agency", "at", "Hill", "Air", "Force", "Base", "near", "Ogden", ",", "Utah", ",", "which", "was", "the", "basis", "for", "what", "was", "later", "named", "the", "Reagan", "Star", "Wars", "program", "."], "sentence-detokenized": "The Eyring Institute was instrumental in the production, under top military secrecy, of the Intelligent Systems Technology software for the USAF Missile Agency at Hill Air Force Base near Ogden, Utah, which was the basis for what was later named the Reagan Star Wars program.", "token2charspan": [[0, 3], [4, 10], [11, 20], [21, 24], [25, 37], [38, 40], [41, 44], [45, 55], [55, 56], [57, 62], [63, 66], [67, 75], [76, 83], [83, 84], [85, 87], [88, 91], [92, 103], [104, 111], [112, 122], [123, 131], [132, 135], [136, 139], [140, 144], [145, 152], [153, 159], [160, 162], [163, 167], [168, 171], [172, 177], [178, 182], [183, 187], [188, 193], [193, 194], [195, 199], [199, 200], [201, 206], [207, 210], [211, 214], [215, 220], [221, 224], [225, 229], [230, 233], [234, 239], [240, 245], [246, 249], [250, 256], [257, 261], [262, 266], [267, 274], [274, 275]]}
{"doc_key": "ai-test-315", "ner": [[10, 11, "field"], [21, 24, "researcher"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "decades", "he", "has", "researched", "and", "developed", "emerging", "areas", "of", "computer", "science", ",", "from", "compilers", ",", "programming", "languages", "and", "systems", "architecture", "John", "F", ".", "Sowa", "and", "John", "Zachman", "(", "1992", ")", "."], "sentence-detokenized": "For decades he has researched and developed emerging areas of computer science, from compilers, programming languages and systems architecture John F. Sowa and John Zachman (1992).", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 18], [19, 29], [30, 33], [34, 43], [44, 52], [53, 58], [59, 61], [62, 70], [71, 78], [78, 79], [80, 84], [85, 94], [94, 95], [96, 107], [108, 117], [118, 121], [122, 129], [130, 142], [143, 147], [148, 149], [149, 150], [151, 155], [156, 159], [160, 164], [165, 172], [173, 174], [174, 178], [178, 179], [179, 180]]}
{"doc_key": "ai-test-316", "ner": [[0, 2, "algorithm"], [9, 12, "algorithm"], [13, 15, "algorithm"], [20, 21, "field"], [23, 24, "field"], [28, 32, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 12, 0, 2, "named", "", false, false], [13, 15, 0, 2, "named", "", false, false], [20, 21, 0, 2, "usage", "", false, false], [23, 24, 0, 2, "usage", "", false, false], [28, 32, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Sobel", "operator", ",", "sometimes", "referred", "to", "as", "the", "Sobel", "-", "Feldman", "operator", "or", "Sobel", "filter", ",", "is", "used", "in", "image", "processing", "and", "computer", "vision", ",", "particularly", "in", "edge", "detection", "algorithms", ",", "where", "it", "creates", "an", "image", "with", "an", "emphasis", "on", "edges", "."], "sentence-detokenized": "The Sobel operator, sometimes referred to as the Sobel-Feldman operator or Sobel filter, is used in image processing and computer vision, particularly in edge detection algorithms, where it creates an image with an emphasis on edges.", "token2charspan": [[0, 3], [4, 9], [10, 18], [18, 19], [20, 29], [30, 38], [39, 41], [42, 44], [45, 48], [49, 54], [54, 55], [55, 62], [63, 71], [72, 74], [75, 80], [81, 87], [87, 88], [89, 91], [92, 96], [97, 99], [100, 105], [106, 116], [117, 120], [121, 129], [130, 136], [136, 137], [138, 150], [151, 153], [154, 158], [159, 168], [169, 179], [179, 180], [181, 186], [187, 189], [190, 197], [198, 200], [201, 206], [207, 211], [212, 214], [215, 223], [224, 226], [227, 232], [232, 233]]}
{"doc_key": "ai-test-317", "ner": [[0, 1, "algorithm"], [3, 7, "field"], [17, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 3, 7, "compare", "", false, false], [0, 1, 3, 7, "type-of", "", false, false], [0, 1, 17, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["LDA", "is", "a", "supervised", "learning", "algorithm", "that", "makes", "use", "of", "the", "labels", "of", "the", "data", ",", "while", "PCA", "is", "a", "learning", "algorithm", "that", "ignores", "the", "labels", "."], "sentence-detokenized": "LDA is a supervised learning algorithm that makes use of the labels of the data, while PCA is a learning algorithm that ignores the labels.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 19], [20, 28], [29, 38], [39, 43], [44, 49], [50, 53], [54, 56], [57, 60], [61, 67], [68, 70], [71, 74], [75, 79], [79, 80], [81, 86], [87, 90], [91, 93], [94, 95], [96, 104], [105, 114], [115, 119], [120, 127], [128, 131], [132, 138], [138, 139]]}
{"doc_key": "ai-test-318", "ner": [[5, 5, "algorithm"], [7, 8, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "linear", "classification", "algorithms", "include", "Winnow", ",", "support", "vector", "machines", "and", "logistic", "regression", "."], "sentence-detokenized": "Other linear classification algorithms include Winnow, support vector machines and logistic regression.", "token2charspan": [[0, 5], [6, 12], [13, 27], [28, 38], [39, 46], [47, 53], [53, 54], [55, 62], [63, 69], [70, 78], [79, 82], [83, 91], [92, 102], [102, 103]]}
{"doc_key": "ai-test-319", "ner": [[0, 0, "product"], [4, 6, "programlang"], [16, 18, "product"], [20, 20, "programlang"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 4, 6, "general-affiliation", "", true, false], [0, 0, 16, 18, "general-affiliation", "", true, false], [0, 0, 20, 20, "general-affiliation", "", true, false], [0, 0, 22, 22, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["VTK", "consists", "of", "a", "C", "+", "+", "class", "library", "and", "several", "interpreted", "interface", "layers", ",", "including", "Tcl", "/", "Tk", ",", "Java", "and", "Python", "."], "sentence-detokenized": "VTK consists of a C + + class library and several interpreted interface layers, including Tcl / Tk, Java and Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 17], [18, 19], [20, 21], [22, 23], [24, 29], [30, 37], [38, 41], [42, 49], [50, 61], [62, 71], [72, 78], [78, 79], [80, 89], [90, 93], [94, 95], [96, 98], [98, 99], [100, 104], [105, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-test-320", "ner": [[9, 11, "task"], [14, 26, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", ",", "the", "processing", "of", "spontaneous", "speech", "using", "automatic", "speech", "recognition", "and", "the", "processing", "of", "text", "produced", "by", "printed", "or", "handwritten", "text", "using", "optical", "character", "recognition", "also", "contains", "processing", "noise", "."], "sentence-detokenized": "In addition, the processing of spontaneous speech using automatic speech recognition and the processing of text produced by printed or handwritten text using optical character recognition also contains processing noise.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 16], [17, 27], [28, 30], [31, 42], [43, 49], [50, 55], [56, 65], [66, 72], [73, 84], [85, 88], [89, 92], [93, 103], [104, 106], [107, 111], [112, 120], [121, 123], [124, 131], [132, 134], [135, 146], [147, 151], [152, 157], [158, 165], [166, 175], [176, 187], [188, 192], [193, 201], [202, 212], [213, 218], [218, 219]]}
{"doc_key": "ai-test-321", "ner": [[0, 0, "researcher"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 9, 9, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "wrote", "several", "books", "and", "directed", "the", "development", "of", "WordNet", ",", "an", "online", "database", "of", "word", "links", "that", "can", "be", "used", "by", "computer", "programs", "."], "sentence-detokenized": "Miller wrote several books and directed the development of WordNet, an online database of word links that can be used by computer programs.", "token2charspan": [[0, 6], [7, 12], [13, 20], [21, 26], [27, 30], [31, 39], [40, 43], [44, 55], [56, 58], [59, 66], [66, 67], [68, 70], [71, 77], [78, 86], [87, 89], [90, 94], [95, 100], [101, 105], [106, 109], [110, 112], [113, 117], [118, 120], [121, 129], [130, 138], [138, 139]]}
{"doc_key": "ai-test-322", "ner": [[1, 2, "field"], [6, 9, "organisation"], [10, 11, "country"], [13, 14, "person"], [16, 18, "person"], [23, 24, "person"], [26, 27, "person"], [20, 21, "country"], [29, 32, "location"], [34, 35, "misc"], [36, 37, "person"], [39, 40, "person"], [41, 42, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[6, 9, 10, 11, "physical", "", false, false], [13, 14, 20, 21, "physical", "", false, false], [16, 18, 20, 21, "physical", "", false, false], [23, 24, 20, 21, "physical", "", false, false], [26, 27, 20, 21, "physical", "", false, false], [29, 32, 1, 2, "general-affiliation", "", false, false], [29, 32, 36, 37, "artifact", "", false, false], [34, 35, 36, 37, "named", "", false, false], [39, 40, 41, 42, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Contemporary", "automata", "are", "represented", "by", "the", "Cabaret", "Mechanical", "Theatre", "in", "the", "UK", ",", "Dug", "North", "and", "Chomick", "+", "Meder", "in", "the", "US", ",", "Arthur", "Ganson", ",", "Joe", "Jones", ",", "Le", "D\u00e9fenseur", "du", "Temps", "by", "French", "artist", "Jacques", "Monestier", "and", "Fran\u00e7ois", "Junod", "in", "Switzerland", "."], "sentence-detokenized": "Contemporary automata are represented by the Cabaret Mechanical Theatre in the UK, Dug North and Chomick + Meder in the US, Arthur Ganson, Joe Jones, Le D\u00e9fenseur du Temps by French artist Jacques Monestier and Fran\u00e7ois Junod in Switzerland.", "token2charspan": [[0, 12], [13, 21], [22, 25], [26, 37], [38, 40], [41, 44], [45, 52], [53, 63], [64, 71], [72, 74], [75, 78], [79, 81], [81, 82], [83, 86], [87, 92], [93, 96], [97, 104], [105, 106], [107, 112], [113, 115], [116, 119], [120, 122], [122, 123], [124, 130], [131, 137], [137, 138], [139, 142], [143, 148], [148, 149], [150, 152], [153, 162], [163, 165], [166, 171], [172, 174], [175, 181], [182, 188], [189, 196], [197, 206], [207, 210], [211, 219], [220, 225], [226, 228], [229, 240], [240, 241]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [23, 23, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 23, 23, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "does", "include", "the", "standard", "codefor", "/", "code", "and", "codewhile", "/", "code", "loops", ",", "but", "(", "as", "with", "other", "similar", "applications", "such", "as", "R", ")", "the", "use", "of", "vector", "notation", "is", "encouraged", "and", "is", "often", "faster", "to", "execute", "."], "sentence-detokenized": "MATLAB does include the standard codefor/code and codewhile/code loops, but (as with other similar applications such as R) the use of vector notation is encouraged and is often faster to execute.", "token2charspan": [[0, 6], [7, 11], [12, 19], [20, 23], [24, 32], [33, 40], [40, 41], [41, 45], [46, 49], [50, 59], [59, 60], [60, 64], [65, 70], [70, 71], [72, 75], [76, 77], [77, 79], [80, 84], [85, 90], [91, 98], [99, 111], [112, 116], [117, 119], [120, 121], [121, 122], [123, 126], [127, 130], [131, 133], [134, 140], [141, 149], [150, 152], [153, 163], [164, 167], [168, 170], [171, 176], [177, 183], [184, 186], [187, 194], [194, 195]]}
{"doc_key": "ai-test-324", "ner": [[3, 3, "researcher"], [7, 12, "conference"], [17, 18, "field"], [20, 27, "misc"], [29, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 20, 27, "win-defeat", "", false, false], [3, 3, 29, 39, "win-defeat", "", false, false], [20, 27, 7, 12, "temporal", "", false, false], [20, 27, 17, 18, "topic", "", false, false], [29, 39, 7, 12, "temporal", "", false, false], [29, 39, 17, 18, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2007", ",", "Pausch", "received", "two", "awards", "from", "the", "Association", "for", "Computing", "Machinery", "for", "his", "achievements", "in", "computing", "education", ":", "the", "Carl", "V.", "Carlstrom", "Award", "for", "Outstanding", "Educator", "and", "the", "ACM", "SIGCSE", "Award", "for", "Outstanding", "Contribution", "to", "Computer", "Science", "Education", "."], "sentence-detokenized": "In 2007, Pausch received two awards from the Association for Computing Machinery for his achievements in computing education: the Carl V. Carlstrom Award for Outstanding Educator and the ACM SIGCSE Award for Outstanding Contribution to Computer Science Education.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 24], [25, 28], [29, 35], [36, 40], [41, 44], [45, 56], [57, 60], [61, 70], [71, 80], [81, 84], [85, 88], [89, 101], [102, 104], [105, 114], [115, 124], [124, 125], [126, 129], [130, 134], [135, 137], [138, 147], [148, 153], [154, 157], [158, 169], [170, 178], [179, 182], [183, 186], [187, 190], [191, 197], [198, 203], [204, 207], [208, 219], [220, 232], [233, 235], [236, 244], [245, 252], [253, 262], [262, 263]]}
{"doc_key": "ai-test-325", "ner": [[3, 4, "person"], [9, 9, "product"], [10, 10, "product"], [16, 19, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 9, 9, "role", "sells", false, false], [9, 9, 10, 10, "general-affiliation", "", false, false], [9, 9, 16, 19, "physical", "shipped_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1960", ",", "De", "Waal", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "shipped", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, De Waal personally sold the first Unimate robot, which was shipped to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 16], [17, 27], [28, 32], [33, 36], [37, 42], [43, 50], [51, 56], [56, 57], [58, 63], [64, 67], [68, 75], [76, 78], [79, 86], [87, 93], [94, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-test-326", "ner": [[0, 2, "algorithm"], [6, 8, "field"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 13, 0, 2, "usage", "", false, false], [12, 13, 6, 8, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Semantic", "Web", "is", "used", "in", "natural", "language", "processing", "applications", "such", "as", "semantic", "parsing", "."], "sentence-detokenized": "The Semantic Web is used in natural language processing applications such as semantic parsing.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 19], [20, 24], [25, 27], [28, 35], [36, 44], [45, 55], [56, 68], [69, 73], [74, 76], [77, 85], [86, 93], [93, 94]]}
{"doc_key": "ai-test-327", "ner": [[6, 7, "field"], [9, 10, "field"], [12, 13, "task"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [24, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 10, 6, 7, "usage", "", false, false], [12, 13, 6, 7, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Some", "of", "the", "successful", "applications", "of", "deep", "learning", "are", "computer", "vision", "and", "speech", "recognition", ".", "Hongle", "Li", ",", "Roger", "Gross", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y", ".", "Wu", "."], "sentence-detokenized": "Some of the successful applications of deep learning are computer vision and speech recognition. Hongle Li, Roger Gross, Rajesh Ranganath, Andrew Y. Wu.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 22], [23, 35], [36, 38], [39, 43], [44, 52], [53, 56], [57, 65], [66, 72], [73, 76], [77, 83], [84, 95], [95, 96], [97, 103], [104, 106], [106, 107], [108, 113], [114, 119], [119, 120], [121, 127], [128, 137], [137, 138], [139, 145], [146, 147], [147, 148], [149, 151], [151, 152]]}
{"doc_key": "ai-test-328", "ner": [[4, 9, "product"], [13, 13, "misc"], [17, 17, "misc"], [20, 20, "product"], [24, 25, "task"], [27, 28, "task"], [30, 31, "task"], [33, 35, "field"], [37, 38, "task"], [40, 41, "field"], [43, 44, "task"], [46, 47, "task"], [49, 50, "task"], [52, 53, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 9, 13, 13, "physical", "travels_to", false, false], [4, 9, 17, 17, "physical", "travels_to", false, false], [20, 20, 4, 9, "part-of", "", false, false], [20, 20, 4, 9, "role", "maintains", false, false], [20, 20, 24, 25, "related-to", "has_ability_to", false, false], [20, 20, 27, 28, "related-to", "has_ability_to", false, false], [20, 20, 30, 31, "related-to", "has_ability_to", false, false], [20, 20, 33, 35, "related-to", "has_ability_to", false, false], [20, 20, 37, 38, "related-to", "has_ability_to", false, false], [20, 20, 40, 41, "related-to", "has_ability_to", false, false], [20, 20, 43, 44, "related-to", "has_ability_to", false, false], [20, 20, 46, 47, "related-to", "has_ability_to", false, false], [20, 20, 49, 50, "related-to", "has_ability_to", false, false], [20, 20, 52, 53, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["In", "addition", "to", "maintaining", "the", "Discovery", "One", "spacecraft", "system", "during", "interplanetary", "missions", "to", "Jupiter", "(", "or", "fictional", "Saturn", ")", ",", "HAL", "is", "capable", "of", "speech", "synthesis", ",", "speech", "recognition", ",", "facial", "recognition", ",", "natural", "language", "processing", ",", "lip", "reading", ",", "art", "appreciation", ",", "affective", "computing", ",", "automated", "reasoning", ",", "spacecraft", "piloting", "and", "chess", "playing", "."], "sentence-detokenized": "In addition to maintaining the Discovery One spacecraft system during interplanetary missions to Jupiter (or fictional Saturn), HAL is capable of speech synthesis, speech recognition, facial recognition, natural language processing, lip reading, art appreciation, affective computing, automated reasoning, spacecraft piloting and chess playing.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 40], [41, 44], [45, 55], [56, 62], [63, 69], [70, 84], [85, 93], [94, 96], [97, 104], [105, 106], [106, 108], [109, 118], [119, 125], [125, 126], [126, 127], [128, 131], [132, 134], [135, 142], [143, 145], [146, 152], [153, 162], [162, 163], [164, 170], [171, 182], [182, 183], [184, 190], [191, 202], [202, 203], [204, 211], [212, 220], [221, 231], [231, 232], [233, 236], [237, 244], [244, 245], [246, 249], [250, 262], [262, 263], [264, 273], [274, 283], [283, 284], [285, 294], [295, 304], [304, 305], [306, 316], [317, 325], [326, 329], [330, 335], [336, 343], [343, 344]]}
{"doc_key": "ai-test-329", "ner": [[0, 2, "researcher"], [5, 5, "country"], [7, 9, "country"], [12, 12, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 5, "physical", "", false, false], [0, 2, 7, 9, "physical", "", false, false], [0, 2, 12, 12, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dr", ".", "Ulysses", "emigrated", "from", "Hungary", "to", "the", "United", "States", "after", "the", "Soviet", "invasion", "in", "1956", "."], "sentence-detokenized": "Dr. Ulysses emigrated from Hungary to the United States after the Soviet invasion in 1956.", "token2charspan": [[0, 2], [2, 3], [4, 11], [12, 21], [22, 26], [27, 34], [35, 37], [38, 41], [42, 48], [49, 55], [56, 61], [62, 65], [66, 72], [73, 81], [82, 84], [85, 89], [89, 90]]}
{"doc_key": "ai-test-330", "ner": [[0, 2, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sigma", "function", "activation", "function", "uses", "a", "second", "nonlinearity", "for", "large", "inputs", ":", "math", "\\", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+", "exp", "(", "-", "v", "_", "i", ")", ")", "^", "{", "-1", "}", "/", "math", "."], "sentence-detokenized": "The sigma function activation function uses a second nonlinearity for large inputs: math\\ phi (v _ i) = (1 + exp (-v _ i))^ {-1} / math.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 29], [30, 38], [39, 43], [44, 45], [46, 52], [53, 65], [66, 69], [70, 75], [76, 82], [82, 83], [84, 88], [88, 89], [90, 93], [94, 95], [95, 96], [97, 98], [99, 100], [100, 101], [102, 103], [104, 105], [105, 106], [107, 108], [109, 112], [113, 114], [114, 115], [115, 116], [117, 118], [119, 120], [120, 121], [121, 122], [122, 123], [124, 125], [125, 127], [127, 128], [129, 130], [131, 135], [135, 136]]}
{"doc_key": "ai-test-331", "ner": [[13, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "probabilities", "are", "used", "to", "determine", "what", "the", "goal", "is", ",", "using", "the", "maximum", "likelihood", "decision", "."], "sentence-detokenized": "These probabilities are used to determine what the goal is, using the maximum likelihood decision.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 28], [29, 31], [32, 41], [42, 46], [47, 50], [51, 55], [56, 58], [58, 59], [60, 65], [66, 69], [70, 77], [78, 88], [89, 97], [97, 98]]}
{"doc_key": "ai-test-332", "ner": [[5, 8, "university"], [13, 16, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1984", "he", "transferred", "to", "the", "University", "of", "Konstanz", "and", "in", "1990", "to", "the", "University", "of", "Salzburg", "."], "sentence-detokenized": "In 1984 he transferred to the University of Konstanz and in 1990 to the University of Salzburg.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 22], [23, 25], [26, 29], [30, 40], [41, 43], [44, 52], [53, 56], [57, 59], [60, 64], [65, 67], [68, 71], [72, 82], [83, 85], [86, 94], [94, 95]]}
{"doc_key": "ai-test-333", "ner": [[6, 7, "metrics"], [9, 11, "metrics"], [13, 15, "metrics"], [17, 17, "metrics"], [19, 20, "metrics"], [22, 24, "metrics"], [27, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 11, 6, 7, "origin", "based_on", false, false], [13, 15, 6, 7, "origin", "based_on", false, false], [17, 17, 6, 7, "origin", "based_on", false, false], [19, 20, 6, 7, "origin", "based_on", false, false], [22, 24, 6, 7, "origin", "based_on", false, false], [27, 31, 6, 7, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Some", "popular", "fitness", "functions", "based", "on", "confusion", "matrices", "include", "sensitivity", "/", "specificity", ",", "recall", "/", "precision", ",", "F-measure", ",", "Jaccard", "similarity", ",", "Matthews", "correlation", "coefficient", ",", "and", "a", "cost", "/", "benefit", "matrix", ",", "which", "combines", "the", "costs", "and", "benefits", "assigned", "to", "four", "different", "types", "of", "classifications", "."], "sentence-detokenized": "Some popular fitness functions based on confusion matrices include sensitivity/specificity, recall/precision, F-measure, Jaccard similarity, Matthews correlation coefficient, and a cost/benefit matrix, which combines the costs and benefits assigned to four different types of classifications.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 30], [31, 36], [37, 39], [40, 49], [50, 58], [59, 66], [67, 78], [78, 79], [79, 90], [90, 91], [92, 98], [98, 99], [99, 108], [108, 109], [110, 119], [119, 120], [121, 128], [129, 139], [139, 140], [141, 149], [150, 161], [162, 173], [173, 174], [175, 178], [179, 180], [181, 185], [185, 186], [186, 193], [194, 200], [200, 201], [202, 207], [208, 216], [217, 220], [221, 226], [227, 230], [231, 239], [240, 248], [249, 251], [252, 256], [257, 266], [267, 272], [273, 275], [276, 291], [291, 292]]}
{"doc_key": "ai-test-334", "ner": [[6, 6, "product"], [8, 8, "product"], [10, 10, "product"], [12, 12, "product"], [14, 14, "programlang"], [24, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[24, 27, 6, 6, "part-of", "", false, false], [24, 27, 8, 8, "part-of", "", false, false], [24, 27, 10, 10, "part-of", "", false, false], [24, 27, 12, 12, "part-of", "", false, false], [24, 27, 14, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Common", "numerical", "programming", "environments", "such", "as", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", "and", "R", "provide", "some", "of", "the", "simpler", "feature", "extraction", "techniques", "(", "e.g.", "principal", "component", "analysis", ")", "through", "built", "-", "in", "commands", "."], "sentence-detokenized": "Common numerical programming environments such as MATLAB, SciLab, NumPy, Sklearn and R provide some of the simpler feature extraction techniques (e.g. principal component analysis) through built-in commands.", "token2charspan": [[0, 6], [7, 16], [17, 28], [29, 41], [42, 46], [47, 49], [50, 56], [56, 57], [58, 64], [64, 65], [66, 71], [71, 72], [73, 80], [81, 84], [85, 86], [87, 94], [95, 99], [100, 102], [103, 106], [107, 114], [115, 122], [123, 133], [134, 144], [145, 146], [146, 150], [151, 160], [161, 170], [171, 179], [179, 180], [181, 188], [189, 194], [194, 195], [195, 197], [198, 206], [206, 207]]}
{"doc_key": "ai-test-335", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Industrial", "robots", "have", "been", "implemented", "to", "work", "with", "humans", "to", "perform", "industrial", "manufacturing", "tasks", "."], "sentence-detokenized": "Industrial robots have been implemented to work with humans to perform industrial manufacturing tasks.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 27], [28, 39], [40, 42], [43, 47], [48, 52], [53, 59], [60, 62], [63, 70], [71, 81], [82, 95], [96, 101], [101, 102]]}
{"doc_key": "ai-test-336", "ner": [[6, 6, "field"], [8, 12, "researcher"], [21, 22, "field"], [24, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 21, 22, "related-to", "", false, false], [6, 6, 24, 25, "related-to", "", false, false], [6, 6, 27, 28, "related-to", "", false, false], [8, 12, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "first", "published", "paper", "on", "CG", ",", "John", "F", ".", "Sowa", "applied", "it", "to", "a", "wide", "range", "of", "topics", "in", "artificial", "intelligence", ",", "computer", "science", "and", "cognitive", "science", "."], "sentence-detokenized": "In the first published paper on CG, John F. Sowa applied it to a wide range of topics in artificial intelligence, computer science and cognitive science.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [23, 28], [29, 31], [32, 34], [34, 35], [36, 40], [41, 42], [42, 43], [44, 48], [49, 56], [57, 59], [60, 62], [63, 64], [65, 69], [70, 75], [76, 78], [79, 85], [86, 88], [89, 99], [100, 112], [112, 113], [114, 122], [123, 130], [131, 134], [135, 144], [145, 152], [152, 153]]}
{"doc_key": "ai-test-337", "ner": [[0, 0, "metrics"], [4, 5, "metrics"], [7, 9, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 5, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "BLEU", "in", "calculating", "the", "simplicity", "penalty", ",", "as", "small", "changes", "in", "translation", "length", "have", "little", "effect", "on", "the", "total", "score", "."], "sentence-detokenized": "NIST also differs from BLEU in calculating the simplicity penalty, as small changes in translation length have little effect on the total score.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 27], [28, 30], [31, 42], [43, 46], [47, 57], [58, 65], [65, 66], [67, 69], [70, 75], [76, 83], [84, 86], [87, 98], [99, 105], [106, 110], [111, 117], [118, 124], [125, 127], [128, 131], [132, 137], [138, 143], [143, 144]]}
{"doc_key": "ai-test-338", "ner": [[1, 3, "misc"], [12, 12, "conference"], [15, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 3, 12, 12, "temporal", "", false, false], [1, 3, 15, 15, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "IJCAI", "Research", "Excellence", "Award", "is", "a", "biennial", "award", "presented", "at", "the", "IJCAI", "Conference", "to", "AI", "researchers", "in", "recognition", "of", "career", "excellence", "."], "sentence-detokenized": "The IJCAI Research Excellence Award is a biennial award presented at the IJCAI Conference to AI researchers in recognition of career excellence.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 29], [30, 35], [36, 38], [39, 40], [41, 49], [50, 55], [56, 65], [66, 68], [69, 72], [73, 78], [79, 89], [90, 92], [93, 95], [96, 107], [108, 110], [111, 122], [123, 125], [126, 132], [133, 143], [143, 144]]}
{"doc_key": "ai-test-339", "ner": [[4, 5, "conference"], [15, 25, "organisation"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Reinert", "was", "one", "of", "AAAI", "'s", "original", "fellows", "and", "is", "the", "only", "person", "to", "have", "served", "on", "the", "scientific", "advisory", "boards", "of", "both", "Microsoft", "and", "Apple", "."], "sentence-detokenized": "Reinert was one of AAAI's original fellows and is the only person to have served on the scientific advisory boards of both Microsoft and Apple.", "token2charspan": [[0, 7], [8, 11], [12, 15], [16, 18], [19, 23], [23, 25], [26, 34], [35, 42], [43, 46], [47, 49], [50, 53], [54, 58], [59, 65], [66, 68], [69, 73], [74, 80], [81, 83], [84, 87], [88, 98], [99, 107], [108, 114], [115, 117], [118, 122], [123, 132], [133, 136], [137, 142], [142, 143]]}
{"doc_key": "ai-test-340", "ner": [[0, 0, "algorithm"], [5, 6, "misc"], [9, 11, "metrics"], [18, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 6, "related-to", "minimise", false, false], [9, 11, 5, 6, "type-of", "", false, false], [18, 18, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autoencoders", "are", "trained", "to", "minimise", "reconstruction", "errors", "(", "e.g.", "mean", "squared", "error", ")", ",", "often", "referred", "to", "as", "losses", "."], "sentence-detokenized": "Autoencoders are trained to minimise reconstruction errors (e.g. mean squared error), often referred to as losses.", "token2charspan": [[0, 12], [13, 16], [17, 24], [25, 27], [28, 36], [37, 51], [52, 58], [59, 60], [60, 64], [65, 69], [70, 77], [78, 83], [83, 84], [84, 85], [86, 91], [92, 100], [101, 103], [104, 106], [107, 113], [113, 114]]}
{"doc_key": "ai-test-341", "ner": [[26, 26, "misc"], [27, 31, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[27, 31, 26, 26, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "alternative", "approach", "to", "using", "definitions", "is", "to", "consider", "general", "word", "sense", "relatedness", "and", "calculate", "the", "similarity", "of", "each", "word", "sense", "pair", "based", "on", "a", "given", "lexical", "knowledge", "base", "(", "e.g.", "WordNet", ")", "."], "sentence-detokenized": "An alternative approach to using definitions is to consider general word sense relatedness and calculate the similarity of each word sense pair based on a given lexical knowledge base (e.g. WordNet).", "token2charspan": [[0, 2], [3, 14], [15, 23], [24, 26], [27, 32], [33, 44], [45, 47], [48, 50], [51, 59], [60, 67], [68, 72], [73, 78], [79, 90], [91, 94], [95, 104], [105, 108], [109, 119], [120, 122], [123, 127], [128, 132], [133, 138], [139, 143], [144, 149], [150, 152], [153, 154], [155, 160], [161, 168], [169, 178], [179, 183], [184, 185], [185, 189], [190, 197], [197, 198], [198, 199]]}
{"doc_key": "ai-test-342", "ner": [[0, 3, "algorithm"], [9, 11, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 9, 11, "origin", "", false, false], [9, 11, 14, 15, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD", "-", "Lambda", "is", "a", "learning", "algorithm", "invented", "by", "Richard", "S.", "Sutton", "based", "on", "Arthur", "Samuel", "'s", "earlier", "work", "on", "time", "difference", "learning", "."], "sentence-detokenized": "TD-Lambda is a learning algorithm invented by Richard S. Sutton based on Arthur Samuel's earlier work on time difference learning.", "token2charspan": [[0, 2], [2, 3], [3, 9], [10, 12], [13, 14], [15, 23], [24, 33], [34, 42], [43, 45], [46, 53], [54, 56], [57, 63], [64, 69], [70, 72], [73, 79], [80, 86], [86, 88], [89, 96], [97, 101], [102, 104], [105, 109], [110, 120], [121, 129], [129, 130]]}
{"doc_key": "ai-test-343", "ner": [[1, 2, "field"], [4, 4, "field"], [6, 7, "task"], [12, 14, "task"], [16, 16, "task"], [22, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 7, 1, 2, "part-of", "task_part_of_field", false, false], [6, 7, 4, 4, "part-of", "task_part_of_field", false, false], [12, 14, 6, 7, "named", "", false, false], [16, 16, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "data", "mining", "and", "statistics", ",", "hierarchical", "clustering", "(", "also", "known", "as", "hierarchical", "cluster", "analysis", "or", "HCA", ")", "is", "a", "method", "of", "cluster", "analysis", "that", "aims", "to", "create", "a", "hierarchy", "of", "clusters", "."], "sentence-detokenized": "In data mining and statistics, hierarchical clustering (also known as hierarchical cluster analysis or HCA) is a method of cluster analysis that aims to create a hierarchy of clusters.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 18], [19, 29], [29, 30], [31, 43], [44, 54], [55, 56], [56, 60], [61, 66], [67, 69], [70, 82], [83, 90], [91, 99], [100, 102], [103, 106], [106, 107], [108, 110], [111, 112], [113, 119], [120, 122], [123, 130], [131, 139], [140, 144], [145, 149], [150, 152], [153, 159], [160, 161], [162, 171], [172, 174], [175, 183], [183, 184]]}
{"doc_key": "ai-test-344", "ner": [[3, 4, "algorithm"], [10, 11, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "concept", "of", "deconvolution", "is", "widely", "used", "in", "techniques", "for", "signal", "processing", "and", "image", "processing", "."], "sentence-detokenized": "The concept of deconvolution is widely used in techniques for signal processing and image processing.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 28], [29, 31], [32, 38], [39, 43], [44, 46], [47, 57], [58, 61], [62, 68], [69, 79], [80, 83], [84, 89], [90, 100], [100, 101]]}
{"doc_key": "ai-test-345", "ner": [[0, 1, "algorithm"], [21, 22, "misc"], [26, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 21, 22, "related-to", "enhances", false, false], [0, 1, 21, 22, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cognitive", "maps", "serve", "the", "construction", "and", "accumulation", "of", "spatial", "knowledge", ",", "allowing", "the", "mind", "'s", "eye", "to", "visualise", "images", "to", "reduce", "cognitive", "load", "and", "enhance", "information", "recall", "and", "learning", "."], "sentence-detokenized": "Cognitive maps serve the construction and accumulation of spatial knowledge, allowing the mind's eye to visualise images to reduce cognitive load and enhance information recall and learning.", "token2charspan": [[0, 9], [10, 14], [15, 20], [21, 24], [25, 37], [38, 41], [42, 54], [55, 57], [58, 65], [66, 75], [75, 76], [77, 85], [86, 89], [90, 94], [94, 96], [97, 100], [101, 103], [104, 113], [114, 120], [121, 123], [124, 130], [131, 140], [141, 145], [146, 149], [150, 157], [158, 169], [170, 176], [177, 180], [181, 189], [189, 190]]}
{"doc_key": "ai-test-346", "ner": [[8, 8, "programlang"], [10, 12, "programlang"], [6, 16, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "usually", "offering", "bindings", "to", "languages", "such", "as", "Python", ",", "C", "+", "+", ",", "Java", ",", "etc.", ")", "."], "sentence-detokenized": "(usually offering bindings to languages such as Python, C + +, Java, etc.).", "token2charspan": [[0, 1], [1, 8], [9, 17], [18, 26], [27, 29], [30, 39], [40, 44], [45, 47], [48, 54], [54, 55], [56, 57], [58, 59], [60, 61], [61, 62], [63, 67], [67, 68], [69, 73], [73, 74], [74, 75]]}
{"doc_key": "ai-test-347", "ner": [[0, 0, "product"], [4, 4, "product"], [14, 15, "task"], [21, 22, "task"], [30, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 14, 15, "usage", "", false, false], [0, 0, 21, 22, "usage", "", false, false], [0, 0, 30, 34, "usage", "", false, false], [4, 4, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Voice", "User", "Interfaces", "(", "VUIs", ")", "enable", "spoken", "human", "-", "computer", "interaction", ",", "using", "speech", "recognition", "to", "understand", "spoken", "commands", "and", "question", "responses", ",", "and", "often", "play", "back", "responses", "using", "text", "-", "to", "-", "speech", "."], "sentence-detokenized": "Voice User Interfaces (VUIs) enable spoken human-computer interaction, using speech recognition to understand spoken commands and question responses, and often play back responses using text-to-speech.", "token2charspan": [[0, 5], [6, 10], [11, 21], [22, 23], [23, 27], [27, 28], [29, 35], [36, 42], [43, 48], [48, 49], [49, 57], [58, 69], [69, 70], [71, 76], [77, 83], [84, 95], [96, 98], [99, 109], [110, 116], [117, 125], [126, 129], [130, 138], [139, 148], [148, 149], [150, 153], [154, 159], [160, 164], [165, 169], [170, 179], [180, 185], [186, 190], [190, 191], [191, 193], [193, 194], [194, 200], [200, 201]]}
{"doc_key": "ai-test-348", "ner": [[0, 0, "programlang"], [3, 4, "misc"], [7, 7, "programlang"], [12, 15, "researcher"], [17, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 4, "general-affiliation", "is_a", false, false], [0, 0, 7, 7, "general-affiliation", "made_with", false, false], [0, 0, 12, 15, "origin", "", false, false], [12, 15, 17, 18, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Jess", "is", "a", "rules", "engine", "for", "the", "Java", "platform", ",", "developed", "by", "Ernest", "Friedman", "-", "Hill", "of", "Sandia", "National", "."], "sentence-detokenized": "Jess is a rules engine for the Java platform, developed by Ernest Friedman-Hill of Sandia National.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 15], [16, 22], [23, 26], [27, 30], [31, 35], [36, 44], [44, 45], [46, 55], [56, 58], [59, 65], [66, 74], [74, 75], [75, 79], [80, 82], [83, 89], [90, 98], [98, 99]]}
{"doc_key": "ai-test-349", "ner": [[1, 2, "algorithm"], [14, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 14, 16, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "multi-layer", "perceptrons", "where", "hidden", "layers", "are", "present", ",", "more", "complex", "algorithms", "such", "as", "back", "-", "propagation", "must", "be", "used", "."], "sentence-detokenized": "For multi-layer perceptrons where hidden layers are present, more complex algorithms such as back-propagation must be used.", "token2charspan": [[0, 3], [4, 15], [16, 27], [28, 33], [34, 40], [41, 47], [48, 51], [52, 59], [59, 60], [61, 65], [66, 73], [74, 84], [85, 89], [90, 92], [93, 97], [97, 98], [98, 109], [110, 114], [115, 117], [118, 122], [122, 123]]}
{"doc_key": "ai-test-350", "ner": [[0, 1, "product"], [3, 6, "product"], [10, 18, "algorithm"], [23, 24, "field"], [27, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 0, 1, "part-of", "", false, false], [3, 6, 10, 18, "usage", "", false, true], [10, 18, 23, 24, "related-to", "performs", false, false], [27, 33, 23, 24, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Google", "Translate", "'s", "neural", "machine", "translation", "system", "uses", "a", "large", "end", "-", "to", "-", "end", "artificial", "neural", "network", "in", "an", "attempt", "to", "perform", "deep", "learning", ",", "specifically", "long", "and", "short", "-", "term", "memory", "networks", "."], "sentence-detokenized": "Google Translate's neural machine translation system uses a large end-to-end artificial neural network in an attempt to perform deep learning, specifically long and short-term memory networks.", "token2charspan": [[0, 6], [7, 16], [16, 18], [19, 25], [26, 33], [34, 45], [46, 52], [53, 57], [58, 59], [60, 65], [66, 69], [69, 70], [70, 72], [72, 73], [73, 76], [77, 87], [88, 94], [95, 102], [103, 105], [106, 108], [109, 116], [117, 119], [120, 127], [128, 132], [133, 141], [141, 142], [143, 155], [156, 160], [161, 164], [165, 170], [170, 171], [171, 175], [176, 182], [183, 191], [191, 192]]}
{"doc_key": "ai-test-351", "ner": [[7, 7, "researcher"], [9, 9, "researcher"], [11, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "1980s", "and", "early", "1990s", ",", "Werbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Pearlmutter", "and", "others", "developed", "various", "methods", "to", "achieve", "this", "goal", "."], "sentence-detokenized": "In the 1980s and early 1990s, Werbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Pearlmutter and others developed various methods to achieve this goal.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 16], [17, 22], [23, 28], [28, 29], [30, 36], [36, 37], [38, 46], [46, 47], [48, 56], [56, 57], [58, 64], [65, 76], [76, 77], [78, 82], [83, 93], [93, 94], [95, 106], [107, 110], [111, 117], [118, 127], [128, 135], [136, 143], [144, 146], [147, 154], [155, 159], [160, 164], [164, 165]]}
{"doc_key": "ai-test-352", "ner": [[0, 0, "organisation"], [1, 1, "organisation"], [6, 6, "organisation"], [9, 10, "task"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 6, "role", "licenses_from", false, false], [1, 1, 0, 0, "named", "", false, false], [15, 15, 0, 0, "origin", "", false, false], [15, 15, 9, 10, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["|", "Apple", "originally", "licensed", "software", "from", "Nuance", "to", "provide", "voice", "recognition", "for", "its", "digital", "assistant", "Siri", "."], "sentence-detokenized": "| Apple originally licensed software from Nuance to provide voice recognition for its digital assistant Siri.", "token2charspan": [[0, 1], [2, 7], [8, 18], [19, 27], [28, 36], [37, 41], [42, 48], [49, 51], [52, 59], [60, 65], [66, 77], [78, 81], [82, 85], [86, 93], [94, 103], [104, 108], [108, 109]]}
{"doc_key": "ai-test-353", "ner": [[0, 0, "organisation"], [3, 4, "misc"], [7, 8, "person"], [12, 13, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 4, "role", "releases_movies_in_genre", false, false], [7, 8, 0, 0, "role", "directs_for", false, false], [12, 13, 0, 0, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "released", "several", "3D", "westerns", "produced", "by", "Sam", "Katzman", "and", "directed", "by", "William", "Castle", "."], "sentence-detokenized": "Columbia released several 3D westerns produced by Sam Katzman and directed by William Castle.", "token2charspan": [[0, 8], [9, 17], [18, 25], [26, 28], [29, 37], [38, 46], [47, 49], [50, 53], [54, 61], [62, 65], [66, 74], [75, 77], [78, 85], [86, 92], [92, 93]]}
{"doc_key": "ai-test-354", "ner": [[9, 10, "field"], [12, 12, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "incorporates", "knowledge", "and", "research", "from", "the", "fields", "of", "computer", "science", ",", "linguistics", "and", "computer", "engineering", "."], "sentence-detokenized": "It incorporates knowledge and research from the fields of computer science, linguistics and computer engineering.", "token2charspan": [[0, 2], [3, 15], [16, 25], [26, 29], [30, 38], [39, 43], [44, 47], [48, 54], [55, 57], [58, 66], [67, 74], [74, 75], [76, 87], [88, 91], [92, 100], [101, 112], [112, 113]]}
{"doc_key": "ai-test-355", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Below", "is", "an", "example", "of", "an", "R", "code", "."], "sentence-detokenized": "Below is an example of an R code.", "token2charspan": [[0, 5], [6, 8], [9, 11], [12, 19], [20, 22], [23, 25], [26, 27], [28, 32], [32, 33]]}
{"doc_key": "ai-test-356", "ner": [[0, 4, "metrics"], [8, 10, "metrics"], [12, 12, "metrics"], [16, 18, "metrics"], [20, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 8, 10, "part-of", "plotted_into", false, false], [0, 4, 16, 18, "part-of", "plotted_into", false, false], [12, 12, 8, 10, "named", "", false, false], [20, 22, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "ROC", "curves", "are", "obtained", "by", "plotting", "the", "true", "positive", "rate", "(", "TPR", ")", "against", "the", "false", "positive", "rate", "(", "FPR", ")", "at", "different", "threshold", "settings", "."], "sentence-detokenized": "The ROC curves are obtained by plotting the true positive rate (TPR) against the false positive rate (FPR) at different threshold settings.", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 18], [19, 27], [28, 30], [31, 39], [40, 43], [44, 48], [49, 57], [58, 62], [63, 64], [64, 67], [67, 68], [69, 76], [77, 80], [81, 86], [87, 95], [96, 100], [101, 102], [102, 105], [105, 106], [107, 109], [110, 119], [120, 129], [130, 138], [138, 139]]}
{"doc_key": "ai-test-357", "ner": [[4, 5, "field"], [8, 9, "researcher"], [11, 12, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 4, 5, "related-to", "researches_field", false, false], [11, 12, 4, 5, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Research", "stagnated", "after", "the", "machine", "learning", "research", "of", "Marvin", "Minsky", "and", "Seymour", "Papert", "."], "sentence-detokenized": "Research stagnated after the machine learning research of Marvin Minsky and Seymour Papert.", "token2charspan": [[0, 8], [9, 18], [19, 24], [25, 28], [29, 36], [37, 45], [46, 54], [55, 57], [58, 64], [65, 71], [72, 75], [76, 83], [84, 90], [90, 91]]}
{"doc_key": "ai-test-358", "ner": [[6, 6, "task"], [9, 10, "programlang"], [12, 15, "product"], [17, 18, "programlang"], [20, 20, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 6, 9, 10, "related-to", "used_to_build", false, false], [6, 6, 12, 15, "related-to", "used_to_build", false, false], [6, 6, 17, 18, "related-to", "used_to_build", false, false], [6, 6, 20, 20, "related-to", "used_to_build", false, false], [6, 6, 22, 22, "related-to", "used_to_build", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "programming", "environments", "used", "to", "build", "DAQ", "applications", "include", "Ladder", "Logic", ",", "Visual", "C", "+", "+", ",", "Visual", "Basic", ",", "LabVIEW", "and", "MATLAB", "."], "sentence-detokenized": "Other programming environments used to build DAQ applications include Ladder Logic, Visual C + +, Visual Basic, LabVIEW and MATLAB.", "token2charspan": [[0, 5], [6, 17], [18, 30], [31, 35], [36, 38], [39, 44], [45, 48], [49, 61], [62, 69], [70, 76], [77, 82], [82, 83], [84, 90], [91, 92], [93, 94], [95, 96], [96, 97], [98, 104], [105, 110], [110, 111], [112, 119], [120, 123], [124, 130], [130, 131]]}
{"doc_key": "ai-test-359", "ner": [[14, 17, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "metric", "is", "designed", "to", "address", "some", "of", "the", "issues", "in", "the", "more", "popular", "BLEU", "metrics", "and", "to", "correlate", "well", "with", "human", "judgement", "at", "the", "sentence", "or", "segment", "level", "."], "sentence-detokenized": "The metric is designed to address some of the issues in the more popular BLEU metrics and to correlate well with human judgement at the sentence or segment level.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 22], [23, 25], [26, 33], [34, 38], [39, 41], [42, 45], [46, 52], [53, 55], [56, 59], [60, 64], [65, 72], [73, 77], [78, 85], [86, 89], [90, 92], [93, 102], [103, 107], [108, 112], [113, 118], [119, 128], [129, 131], [132, 135], [136, 144], [145, 147], [148, 155], [156, 161], [161, 162]]}
{"doc_key": "ai-test-360", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "and", "short", "term", "memory", "are", "often", "used", "to", "exploit", "the", "semantic", "associations", "between", "successive", "video", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and long and short term memory are often used to exploit the semantic associations between successive video frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [83, 86], [87, 92], [93, 97], [98, 104], [105, 108], [109, 114], [115, 119], [120, 122], [123, 130], [131, 134], [135, 143], [144, 156], [157, 164], [165, 175], [176, 181], [182, 188], [188, 189]]}
{"doc_key": "ai-test-361", "ner": [[3, 5, "product"], [7, 9, "product"], [14, 19, "product"], [23, 23, "product"], [41, 42, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 14, 19, "artifact", "", false, false], [3, 5, 41, 42, "named", "", false, false], [7, 9, 3, 5, "named", "", false, false], [23, 23, 14, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Mass", "-", "produced", "printed", "circuit", "boards", "(", "PCBs", ")", "are", "manufactured", "almost", "exclusively", "by", "pick", "-", "and", "-", "place", "robots", ",", "often", "using", "SCARA", "manipulators", ",", "which", "remove", "tiny", "electronic", "components", "from", "strips", "or", "trays", "and", "place", "them", "very", "precisely", "onto", "the", "PCBs", "."], "sentence-detokenized": "Mass-produced printed circuit boards (PCBs) are manufactured almost exclusively by pick-and-place robots, often using SCARA manipulators, which remove tiny electronic components from strips or trays and place them very precisely onto the PCBs.", "token2charspan": [[0, 4], [4, 5], [5, 13], [14, 21], [22, 29], [30, 36], [37, 38], [38, 42], [42, 43], [44, 47], [48, 60], [61, 67], [68, 79], [80, 82], [83, 87], [87, 88], [88, 91], [91, 92], [92, 97], [98, 104], [104, 105], [106, 111], [112, 117], [118, 123], [124, 136], [136, 137], [138, 143], [144, 150], [151, 155], [156, 166], [167, 177], [178, 182], [183, 189], [190, 192], [193, 198], [199, 202], [203, 208], [209, 213], [214, 218], [219, 228], [229, 233], [234, 237], [238, 242], [242, 243]]}
{"doc_key": "ai-test-362", "ner": [[4, 5, "field"], [15, 16, "algorithm"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 29, "researcher"], [36, 37, "algorithm"], [39, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 16, 4, 5, "part-of", "", false, false], [15, 16, 20, 21, "origin", "", false, false], [15, 16, 23, 24, "origin", "", false, false], [15, 16, 26, 29, "origin", "", false, false], [15, 16, 36, 37, "type-of", "", false, false], [36, 37, 39, 40, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "the", "context", "of", "machine", "learning", ",", "where", "it", "is", "most", "widely", "used", "today", ",", "LDA", "was", "independently", "rediscovered", "by", "David", "Blei", ",", "Andrew", "Ng", "and", "Michael", "I", ".", "Jordan", "in", "2003", "and", "presented", "as", "a", "graphical", "model", "for", "topic", "discovery", "."], "sentence-detokenized": "In the context of machine learning, where it is most widely used today, LDA was independently rediscovered by David Blei, Andrew Ng and Michael I. Jordan in 2003 and presented as a graphical model for topic discovery.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 25], [26, 34], [34, 35], [36, 41], [42, 44], [45, 47], [48, 52], [53, 59], [60, 64], [65, 70], [70, 71], [72, 75], [76, 79], [80, 93], [94, 106], [107, 109], [110, 115], [116, 120], [120, 121], [122, 128], [129, 131], [132, 135], [136, 143], [144, 145], [145, 146], [147, 153], [154, 156], [157, 161], [162, 165], [166, 175], [176, 178], [179, 180], [181, 190], [191, 196], [197, 200], [201, 206], [207, 216], [216, 217]]}
{"doc_key": "ai-test-363", "ner": [[5, 5, "task"], [8, 9, "misc"], [14, 14, "metrics"], [16, 16, "metrics"], [18, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 5, 8, 9, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["Test", "data", "from", "eight", "naive", "WSIs", "for", "different", "tauopathies", "were", "measured", ",", "resulting", "in", "recall", ",", "precision", "and", "F1", "scores", "of", "0.92", ",", "0.72", "and", "0.81", "respectively", "."], "sentence-detokenized": "Test data from eight naive WSIs for different tauopathies were measured, resulting in recall, precision and F1 scores of 0.92, 0.72 and 0.81 respectively.", "token2charspan": [[0, 4], [5, 9], [10, 14], [15, 20], [21, 26], [27, 31], [32, 35], [36, 45], [46, 57], [58, 62], [63, 71], [71, 72], [73, 82], [83, 85], [86, 92], [92, 93], [94, 103], [104, 107], [108, 110], [111, 117], [118, 120], [121, 125], [125, 126], [127, 131], [132, 135], [136, 140], [141, 153], [153, 154]]}
{"doc_key": "ai-test-364", "ner": [[5, 5, "field"], [12, 13, "field"], [18, 18, "field"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 18, 18, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["With", "the", "help", "of", "advanced", "AR", "technologies", "(", "e.g.", "the", "addition", "of", "computer", "vision", ",", "the", "incorporation", "of", "AR", "cameras", "into", "smartphones", "and", "object", "recognition", ")", ",", "information", "about", "the", "real", "world", "around", "the", "user", "becomes", "interactive", "and", "digitally", "manipulated", "."], "sentence-detokenized": "With the help of advanced AR technologies (e.g. the addition of computer vision, the incorporation of AR cameras into smartphones and object recognition), information about the real world around the user becomes interactive and digitally manipulated.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 25], [26, 28], [29, 41], [42, 43], [43, 47], [48, 51], [52, 60], [61, 63], [64, 72], [73, 79], [79, 80], [81, 84], [85, 98], [99, 101], [102, 104], [105, 112], [113, 117], [118, 129], [130, 133], [134, 140], [141, 152], [152, 153], [153, 154], [155, 166], [167, 172], [173, 176], [177, 181], [182, 187], [188, 194], [195, 198], [199, 203], [204, 211], [212, 223], [224, 227], [228, 237], [238, 249], [249, 250]]}
{"doc_key": "ai-test-365", "ner": [[3, 3, "researcher"], [8, 8, "organisation"], [16, 18, "field"], [27, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 8, 8, "role", "forms_company", false, false], [8, 8, 16, 18, "related-to", "works_with", false, false], [8, 8, 27, 29, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2014", ",", "Schmidhuber", "founded", "a", "company", ",", "Nnaisense", ",", "to", "work", "on", "commercial", "applications", "of", "artificial", "intelligence", "in", "areas", "such", "as", "finance", ",", "heavy", "industry", "and", "self", "-", "driving", "cars", "."], "sentence-detokenized": "In 2014, Schmidhuber founded a company, Nnaisense, to work on commercial applications of artificial intelligence in areas such as finance, heavy industry and self-driving cars.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 28], [29, 30], [31, 38], [38, 39], [40, 49], [49, 50], [51, 53], [54, 58], [59, 61], [62, 72], [73, 85], [86, 88], [89, 99], [100, 112], [113, 115], [116, 121], [122, 126], [127, 129], [130, 137], [137, 138], [139, 144], [145, 153], [154, 157], [158, 162], [162, 163], [163, 170], [171, 175], [175, 176]]}
{"doc_key": "ai-test-366", "ner": [[25, 29, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Not", "only", "does", "this", "alter", "the", "performance", "of", "all", "subsequent", "tests", "of", "the", "retained", "explanatory", "model", ",", "it", "may", "also", "introduce", "bias", "and", "alter", "the", "mean", "squared", "error", "of", "the", "estimates", "."], "sentence-detokenized": "Not only does this alter the performance of all subsequent tests of the retained explanatory model, it may also introduce bias and alter the mean squared error of the estimates.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 18], [19, 24], [25, 28], [29, 40], [41, 43], [44, 47], [48, 58], [59, 64], [65, 67], [68, 71], [72, 80], [81, 92], [93, 98], [98, 99], [100, 102], [103, 106], [107, 111], [112, 121], [122, 126], [127, 130], [131, 136], [137, 140], [141, 145], [146, 153], [154, 159], [160, 162], [163, 166], [167, 176], [176, 177]]}
{"doc_key": "ai-test-367", "ner": [[0, 2, "misc"], [9, 9, "algorithm"], [7, 8, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 0, 2, "usage", "", false, false], [9, 9, 7, 8, "topic", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Large", "words", "are", "used", "in", "most", "successful", "speech", "recognition", "language", "models", "."], "sentence-detokenized": "Large words are used in most successful speech recognition language models.", "token2charspan": [[0, 5], [6, 11], [12, 15], [16, 20], [21, 23], [24, 28], [29, 39], [40, 46], [47, 58], [59, 67], [68, 74], [74, 75]]}
{"doc_key": "ai-test-368", "ner": [[3, 6, "field"], [10, 12, "misc"], [17, 20, "misc"], [25, 28, "organisation"], [31, 33, "misc"], [35, 39, "organisation"], [45, 47, "misc"], [49, 51, "organisation"], [57, 59, "misc"], [61, 64, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[10, 12, 3, 6, "topic", "", false, false], [17, 20, 25, 28, "origin", "", false, false], [31, 33, 35, 39, "origin", "", false, false], [45, 47, 49, 51, "origin", "", false, false], [57, 59, 61, 64, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["His", "research", "in", "cognitive", "psychology", "has", "been", "recognized", "with", "the", "Early", "Career", "Award", "(", "1984", ")", "and", "the", "Boyd", "McCandless", "Award", "(", "1986", ")", "from", "the", "American", "Psychological", "Association", ",", "the", "Troran", "Research", "Award", "from", "the", "National", "Academy", "of", "Sciences", "(", "1993", ")", ",", "the", "Henry", "Dyer", "Award", "from", "the", "Royal", "Society", "(", "2004", ")", "and", "the", "George", "Miller", "Award", "from", "the", "Cognitive", "Neuroscience", "Society", "(", "2010", ")", "."], "sentence-detokenized": "His research in cognitive psychology has been recognized with the Early Career Award (1984) and the Boyd McCandless Award (1986) from the American Psychological Association, the Troran Research Award from the National Academy of Sciences (1993), the Henry Dyer Award from the Royal Society (2004) and the George Miller Award from the Cognitive Neuroscience Society (2010).", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 25], [26, 36], [37, 40], [41, 45], [46, 56], [57, 61], [62, 65], [66, 71], [72, 78], [79, 84], [85, 86], [86, 90], [90, 91], [92, 95], [96, 99], [100, 104], [105, 115], [116, 121], [122, 123], [123, 127], [127, 128], [129, 133], [134, 137], [138, 146], [147, 160], [161, 172], [172, 173], [174, 177], [178, 184], [185, 193], [194, 199], [200, 204], [205, 208], [209, 217], [218, 225], [226, 228], [229, 237], [238, 239], [239, 243], [243, 244], [244, 245], [246, 249], [250, 255], [256, 260], [261, 266], [267, 271], [272, 275], [276, 281], [282, 289], [290, 291], [291, 295], [295, 296], [297, 300], [301, 304], [305, 311], [312, 318], [319, 324], [325, 329], [330, 333], [334, 343], [344, 356], [357, 364], [365, 366], [366, 370], [370, 371], [371, 372]]}
{"doc_key": "ai-test-369", "ner": [[0, 0, "misc"], [5, 5, "misc"], [7, 10, "product"], [13, 13, "researcher"], [15, 15, "researcher"], [22, 23, "researcher"], [25, 26, "researcher"], [28, 29, "task"], [31, 34, "researcher"], [36, 40, "researcher"], [41, 42, "task"], [44, 44, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[0, 0, 5, 5, "named", "", false, false], [0, 0, 44, 44, "named", "", false, false], [5, 5, 13, 13, "origin", "", false, false], [5, 5, 15, 15, "origin", "", false, false], [5, 5, 28, 29, "related-to", "used_for", false, false], [7, 10, 5, 5, "usage", "", false, false], [7, 10, 41, 42, "named", "", false, false], [22, 23, 5, 5, "usage", "", false, false], [22, 23, 31, 34, "named", "same", false, false], [25, 26, 5, 5, "usage", "", false, false], [25, 26, 36, 40, "named", "same", false, false], [41, 42, 44, 44, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Eigenfaces", "(", "The", "use", "of", "eigenfaces", "for", "facial", "recognition", "systems", "was", "developed", "by", "Sirovich", "and", "Kirby", "(", "1987", ")", "and", "used", "by", "Matthew", "Turk", "and", "Alex", "Pentland", "for", "facial", "classification", ".", "Turk", ",", "Matthew", "A", "and", "Pentland", ",", "Alex", "P", ".", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "Eigenfaces (The use of eigenfaces for facial recognition systems was developed by Sirovich and Kirby (1987) and used by Matthew Turk and Alex Pentland for facial classification. Turk, Matthew A and Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 10], [11, 12], [12, 15], [16, 19], [20, 22], [23, 33], [34, 37], [38, 44], [45, 56], [57, 64], [65, 68], [69, 78], [79, 81], [82, 90], [91, 94], [95, 100], [101, 102], [102, 106], [106, 107], [108, 111], [112, 116], [117, 119], [120, 127], [128, 132], [133, 136], [137, 141], [142, 150], [151, 154], [155, 161], [162, 176], [176, 177], [178, 182], [182, 183], [184, 191], [192, 193], [194, 197], [198, 206], [206, 207], [208, 212], [213, 214], [214, 215], [216, 220], [221, 232], [233, 238], [239, 249], [249, 250]]}
{"doc_key": "ai-test-370", "ner": [[5, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "lexical", "dictionary", "such", "as", "Word", "Net", "can", "then", "be", "used", "to", "understand", "the", "context", "."], "sentence-detokenized": "A lexical dictionary such as WordNet can then be used to understand the context.", "token2charspan": [[0, 1], [2, 9], [10, 20], [21, 25], [26, 28], [29, 33], [33, 36], [37, 40], [41, 45], [46, 48], [49, 53], [54, 56], [57, 67], [68, 71], [72, 79], [79, 80]]}
{"doc_key": "ai-test-371", "ner": [[0, 0, "misc"], [8, 8, "misc"], [10, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 8, "part-of", "", false, false], [8, 8, 10, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Synonyms", "are", "the", "most", "frequently", "encoded", "relationships", "between", "synonyms", "used", "in", "thesauri", "(", "e.g.", "WordNet", ")", "."], "sentence-detokenized": "Synonyms are the most frequently encoded relationships between synonyms used in thesauri (e.g. WordNet).", "token2charspan": [[0, 8], [9, 12], [13, 16], [17, 21], [22, 32], [33, 40], [41, 54], [55, 62], [63, 71], [72, 76], [77, 79], [80, 88], [89, 90], [90, 94], [95, 102], [102, 103], [103, 104]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [6, 7, "programlang"], [9, 9, "programlang"], [37, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 7, "general-affiliation", "", false, false], [0, 0, 9, 9, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "offers", "open", "source", "libraries", "in", "C", "++", "and", "Java", ",", "but", "many", "customers", "rely", "on", "community", "-", "developed", "libraries", "such", "as", "libraries", "that", "include", "embedded", "functionality", "for", "retrieving", "(", "array", "-", "style", ")", "data", "from", "the", "DAP", "server", "."], "sentence-detokenized": "OPeNDAP offers open source libraries in C++ and Java, but many customers rely on community-developed libraries such as libraries that include embedded functionality for retrieving (array-style) data from the DAP server.", "token2charspan": [[0, 7], [8, 14], [15, 19], [20, 26], [27, 36], [37, 39], [40, 41], [41, 43], [44, 47], [48, 52], [52, 53], [54, 57], [58, 62], [63, 72], [73, 77], [78, 80], [81, 90], [90, 91], [91, 100], [101, 110], [111, 115], [116, 118], [119, 128], [129, 133], [134, 141], [142, 150], [151, 164], [165, 168], [169, 179], [180, 181], [181, 186], [186, 187], [187, 192], [192, 193], [194, 198], [199, 203], [204, 207], [208, 211], [212, 218], [218, 219]]}
{"doc_key": "ai-test-373", "ner": [[4, 5, "misc"], [8, 8, "product"], [16, 16, "country"], [29, 31, "misc"], [44, 44, "organisation"], [46, 46, "product"], [48, 48, "organisation"], [50, 54, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 16, 16, "opposite", "", false, false], [8, 8, 16, 16, "artifact", "", false, false], [29, 31, 8, 8, "part-of", "", false, false], [46, 46, 44, 44, "artifact", "", false, false], [50, 54, 48, 48, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "that", "page", ",", "Samurai", "Damashii", "exaggerates", "the", "Senkousha", "as", "the", "culmination", "of", "4,000", "years", "of", "Chinese", "scientific", "knowledge", ",", "comments", "on", "its", "crude", "design", "(", "such", "as", "the", "Chinese", "cannon", "on", "its", "hip", ")", ",", "and", "juxtaposes", "it", "s", "image", "against", "images", "of", "Honda", "'s", "ASIMO", "and", "Sony", "'s", "QRIO", "SDR", "-", "3", "X", "."], "sentence-detokenized": "In that page, Samurai Damashii exaggerates the Senkousha as the culmination of 4,000 years of Chinese scientific knowledge, comments on its crude design (such as the Chinese cannon on its hip), and juxtaposes its image against images of Honda's ASIMO and Sony's QRIO SDR-3X.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 21], [22, 30], [31, 42], [43, 46], [47, 56], [57, 59], [60, 63], [64, 75], [76, 78], [79, 84], [85, 90], [91, 93], [94, 101], [102, 112], [113, 122], [122, 123], [124, 132], [133, 135], [136, 139], [140, 145], [146, 152], [153, 154], [154, 158], [159, 161], [162, 165], [166, 173], [174, 180], [181, 183], [184, 187], [188, 191], [191, 192], [192, 193], [194, 197], [198, 208], [209, 211], [211, 212], [213, 218], [219, 226], [227, 233], [234, 236], [237, 242], [242, 244], [245, 250], [251, 254], [255, 259], [259, 261], [262, 266], [267, 270], [270, 271], [271, 272], [272, 273], [273, 274]]}
{"doc_key": "ai-test-374", "ner": [[7, 8, "algorithm"], [15, 15, "product"], [17, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 15, 15, "part-of", "includes_functionality_of", false, false], [7, 8, 17, 19, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "also", "many", "programming", "libraries", "containing", "neural", "network", "functionality", "for", "custom", "implementations", "(", "e.g.", "TensorFlow", ",", "Theano", ",", "etc.", ")", "."], "sentence-detokenized": "There are also many programming libraries containing neural network functionality for custom implementations (e.g. TensorFlow, Theano, etc.).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 19], [20, 31], [32, 41], [42, 52], [53, 59], [60, 67], [68, 81], [82, 85], [86, 92], [93, 108], [109, 110], [110, 114], [115, 125], [125, 126], [127, 133], [133, 134], [135, 139], [139, 140], [140, 141]]}
{"doc_key": "ai-test-375", "ner": [[5, 6, "conference"], [8, 8, "organisation"], [10, 16, "conference"], [18, 18, "conference"], [20, 20, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "ACM", ",", "IEEE", ",", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "IAPR", "and", "SPIE", "."], "sentence-detokenized": "He is a member of the ACM, IEEE, American Association for the Advancement of Science, IAPR and SPIE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 25], [25, 26], [27, 31], [31, 32], [33, 41], [42, 53], [54, 57], [58, 61], [62, 73], [74, 76], [77, 84], [84, 85], [86, 90], [91, 94], [95, 99], [99, 100]]}
{"doc_key": "ai-test-376", "ner": [[3, 4, "organisation"], [8, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 8, 10, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2011", ",", "RET", "'s", "trial", "of", "installing", "facial", "recognition", "system", "cameras", "on", "trams", "ensured", "that", "people", "who", "were", "barred", "from", "entering", "the", "city", "'s", "trams", "did", "not", "sneak", "onto", "them", "anyway", "."], "sentence-detokenized": "In 2011, RET's trial of installing facial recognition system cameras on trams ensured that people who were barred from entering the city's trams did not sneak onto them anyway.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [12, 14], [15, 20], [21, 23], [24, 34], [35, 41], [42, 53], [54, 60], [61, 68], [69, 71], [72, 77], [78, 85], [86, 90], [91, 97], [98, 101], [102, 106], [107, 113], [114, 118], [119, 127], [128, 131], [132, 136], [136, 138], [139, 144], [145, 148], [149, 152], [153, 158], [159, 163], [164, 168], [169, 175], [175, 176]]}
{"doc_key": "ai-test-377", "ner": [[6, 7, "person"], [8, 8, "organisation"], [15, 16, "person"], [10, 19, "person"], [23, 25, "person"], [27, 28, "person"], [30, 31, "person"], [33, 34, "person"], [36, 37, "person"], [39, 40, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[6, 7, 8, 8, "role", "works_for", false, false], [15, 16, 8, 8, "role", "works_for", false, false], [10, 19, 8, 8, "role", "works_for", false, false], [23, 25, 8, 8, "role", "works_for", false, false], [27, 28, 8, 8, "role", "works_for", false, false], [30, 31, 8, 8, "role", "works_for", false, false], [33, 34, 8, 8, "role", "works_for", false, false], [36, 37, 8, 8, "role", "works_for", false, false], [39, 40, 8, 8, "role", "works_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "film", "adaptation", "of", "the", "popular", "Cole", "Porter", "Broadway", "musical", "stars", "MGM", "'s", "singing", "duo", "Howard", "Keel", "and", "Kathryn", "Grayson", "and", "is", "supported", "by", "Ann", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Pham", ",", "James", "Whitmore", ",", "Kurt", "Casniar", "and", "Tommy", "Rall", "."], "sentence-detokenized": "The film adaptation of the popular Cole Porter Broadway musical stars MGM's singing duo Howard Keel and Kathryn Grayson and is supported by Ann Miller, Keenan Wynn, Bobby Pham, James Whitmore, Kurt Casniar and Tommy Rall.", "token2charspan": [[0, 3], [4, 8], [9, 19], [20, 22], [23, 26], [27, 34], [35, 39], [40, 46], [47, 55], [56, 63], [64, 69], [70, 73], [73, 75], [76, 83], [84, 87], [88, 94], [95, 99], [100, 103], [104, 111], [112, 119], [120, 123], [124, 126], [127, 136], [137, 139], [140, 143], [144, 150], [150, 151], [152, 158], [159, 163], [163, 164], [165, 170], [171, 175], [175, 176], [177, 182], [183, 191], [191, 192], [193, 197], [198, 205], [206, 209], [210, 215], [216, 220], [220, 221]]}
{"doc_key": "ai-test-378", "ner": [[20, 25, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "applications", "should", "simplify", "the", "call", "flow", ",", "minimise", "prompts", ",", "eliminate", "unnecessary", "repetition", "and", "allow", "for", "well", "-", "designed", "hybrid", "initiative", "dialogue", "systems", "that", "allow", "callers", "to", "enter", "several", "pieces", "of", "information", "in", "any", "order", "or", "combination", "in", "a", "single", "discourse", "."], "sentence-detokenized": "Such applications should simplify the call flow, minimise prompts, eliminate unnecessary repetition and allow for well-designed hybrid initiative dialogue systems that allow callers to enter several pieces of information in any order or combination in a single discourse.", "token2charspan": [[0, 4], [5, 17], [18, 24], [25, 33], [34, 37], [38, 42], [43, 47], [47, 48], [49, 57], [58, 65], [65, 66], [67, 76], [77, 88], [89, 99], [100, 103], [104, 109], [110, 113], [114, 118], [118, 119], [119, 127], [128, 134], [135, 145], [146, 154], [155, 162], [163, 167], [168, 173], [174, 181], [182, 184], [185, 190], [191, 198], [199, 205], [206, 208], [209, 220], [221, 223], [224, 227], [228, 233], [234, 236], [237, 248], [249, 251], [252, 253], [254, 260], [261, 270], [270, 271]]}
{"doc_key": "ai-test-379", "ner": [[4, 6, "algorithm"], [9, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 4, 6, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Thus", ",", "the", "traditional", "gradient", "descent", "method", "(", "or", "stochastic", "gradient", "descent", ")", "can", "be", "adapted", "by", "taking", "a", "step", "in", "the", "direction", "of", "the", "gradient", "of", "the", "function", "and", "a", "step", "in", "the", "direction", "of", "selecting", "a", "vector", "from", "the", "subgradients", "of", "the", "function", "."], "sentence-detokenized": "Thus, the traditional gradient descent method (or stochastic gradient descent) can be adapted by taking a step in the direction of the gradient of the function and a step in the direction of selecting a vector from the subgradients of the function.", "token2charspan": [[0, 4], [4, 5], [6, 9], [10, 21], [22, 30], [31, 38], [39, 45], [46, 47], [47, 49], [50, 60], [61, 69], [70, 77], [77, 78], [79, 82], [83, 85], [86, 93], [94, 96], [97, 103], [104, 105], [106, 110], [111, 113], [114, 117], [118, 127], [128, 130], [131, 134], [135, 143], [144, 146], [147, 150], [151, 159], [160, 163], [164, 165], [166, 170], [171, 173], [174, 177], [178, 187], [188, 190], [191, 200], [201, 202], [203, 209], [210, 214], [215, 218], [219, 231], [232, 234], [235, 238], [239, 247], [247, 248]]}
{"doc_key": "ai-test-380", "ner": [[11, 13, "metrics"], [19, 19, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "it", "is", "assumed", "that", "the", "distortion", "is", "measured", "by", "the", "mean", "squared", "error", ",", "then", "the", "distortion", ",", "D", ",", "is", "given", "by", "the", "following", "equation"], "sentence-detokenized": "If it is assumed that the distortion is measured by the mean squared error, then the distortion, D, is given by the following equation", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 16], [17, 21], [22, 25], [26, 36], [37, 39], [40, 48], [49, 51], [52, 55], [56, 60], [61, 68], [69, 74], [74, 75], [76, 80], [81, 84], [85, 95], [95, 96], [97, 98], [98, 99], [100, 102], [103, 108], [109, 111], [112, 115], [116, 125], [126, 134]]}
{"doc_key": "ai-test-381", "ner": [[0, 0, "algorithm"], [3, 4, "field"], [17, 18, "task"], [20, 21, "task"], [23, 24, "task"], [14, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 4, "part-of", "", false, false], [17, 18, 0, 0, "part-of", "", false, false], [20, 21, 0, 0, "part-of", "", false, false], [23, 24, 0, 0, "part-of", "", false, false], [14, 29, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["MLPs", "were", "popular", "machine", "learning", "solutions", "in", "the", "1980s", "and", "found", "applications", "in", "areas", "as", "diverse", "as", "speech", "recognition", ",", "image", "recognition", "and", "machine", "translation", "software", ",", "and", "neural", "networks", "."], "sentence-detokenized": "MLPs were popular machine learning solutions in the 1980s and found applications in areas as diverse as speech recognition, image recognition and machine translation software, and neural networks.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 25], [26, 34], [35, 44], [45, 47], [48, 51], [52, 57], [58, 61], [62, 67], [68, 80], [81, 83], [84, 89], [90, 92], [93, 100], [101, 103], [104, 110], [111, 122], [122, 123], [124, 129], [130, 141], [142, 145], [146, 153], [154, 165], [166, 174], [174, 175], [176, 179], [180, 186], [187, 195], [195, 196]]}
{"doc_key": "ai-test-382", "ner": [[0, 0, "researcher"], [3, 3, "misc"], [5, 8, "university"], [15, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 8, "physical", "", false, false], [0, 0, 5, 8, "role", "", false, false], [3, 3, 0, 0, "origin", "", false, false], [15, 17, 0, 0, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "received", "his", "PhD", "from", "the", "University", "of", "Toronto", "in", "1979", "under", "the", "supervision", "of", "C.", "Raymond", "Perrault", "."], "sentence-detokenized": "Allen received his PhD from the University of Toronto in 1979 under the supervision of C. Raymond Perrault.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 22], [23, 27], [28, 31], [32, 42], [43, 45], [46, 53], [54, 56], [57, 61], [62, 67], [68, 71], [72, 83], [84, 86], [87, 89], [90, 97], [98, 106], [106, 107]]}
{"doc_key": "ai-test-383", "ner": [[0, 0, "product"], [7, 9, "field"], [12, 12, "product"], [14, 14, "product"], [16, 16, "product"], [21, 21, "product"], [25, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 7, 9, "related-to", "supports", false, false], [12, 12, 7, 9, "type-of", "", true, false], [14, 14, 7, 9, "type-of", "", true, false], [16, 16, 7, 9, "type-of", "", true, false], [16, 16, 21, 21, "related-to", "converting_to", true, false], [25, 25, 7, 9, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["OpenCV", "supports", "a", "number", "of", "models", "from", "deep", "learning", "frameworks", "such", "as", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "after", "conversion", "to", "ONNX", "models", ")", "and", "Caffe", ",", "based", "on", "a", "defined", "list", "of", "supported", "layers", "."], "sentence-detokenized": "OpenCV supports a number of models from deep learning frameworks such as TensorFlow, Torch, PyTorch (after conversion to ONNX models) and Caffe, based on a defined list of supported layers.", "token2charspan": [[0, 6], [7, 15], [16, 17], [18, 24], [25, 27], [28, 34], [35, 39], [40, 44], [45, 53], [54, 64], [65, 69], [70, 72], [73, 83], [83, 84], [85, 90], [90, 91], [92, 99], [100, 101], [101, 106], [107, 117], [118, 120], [121, 125], [126, 132], [132, 133], [134, 137], [138, 143], [143, 144], [145, 150], [151, 153], [154, 155], [156, 163], [164, 168], [169, 171], [172, 181], [182, 188], [188, 189]]}
{"doc_key": "ai-test-384", "ner": [[2, 2, "researcher"], [8, 12, "organisation"], [14, 14, "organisation"], [23, 28, "organisation"], [20, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 8, 12, "role", "", false, false], [2, 2, 23, 28, "role", "", false, false], [2, 2, 20, 22, "related-to", "lectures_in", false, false], [14, 14, 8, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Previously", ",", "Christensen", "was", "the", "founding", "president", "of", "the", "European", "Robotics", "Research", "Network", "(", "EURON", ")", "and", "a", "Distinguished", "Lecturer", "in", "Robotics", "at", "the", "IEEE", "Robotics", "and", "Automation", "Society", "."], "sentence-detokenized": "Previously, Christensen was the founding president of the European Robotics Research Network (EURON) and a Distinguished Lecturer in Robotics at the IEEE Robotics and Automation Society.", "token2charspan": [[0, 10], [10, 11], [12, 23], [24, 27], [28, 31], [32, 40], [41, 50], [51, 53], [54, 57], [58, 66], [67, 75], [76, 84], [85, 92], [93, 94], [94, 99], [99, 100], [101, 104], [105, 106], [107, 120], [121, 129], [130, 132], [133, 141], [142, 144], [145, 148], [149, 153], [154, 162], [163, 166], [167, 177], [178, 185], [185, 186]]}
{"doc_key": "ai-test-385", "ner": [[3, 7, "field"], [10, 12, "university"], [13, 19, "country"], [22, 22, "misc"], [23, 24, "field"], [26, 30, "organisation"], [31, 32, "location"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7], "relations": [[22, 22, 23, 24, "topic", "", false, false], [26, 30, 31, 32, "physical", "", false, false]], "relations_mapping_to_source": [2, 3], "sentence": ["He", "received", "his", "master", "'s", "degree", "in", "mathematics", "from", "Samarkand", "State", "University", "in", "the", "Uzbek", "Soviet", "Socialist", "Republic", "in", "1958", "and", "his", "doctorate", "in", "statistics", "from", "the", "Institute", "of", "Control", "Sciences", "in", "Moscow", "in", "1964", "."], "sentence-detokenized": "He received his master's degree in mathematics from Samarkand State University in the Uzbek Soviet Socialist Republic in 1958 and his doctorate in statistics from the Institute of Control Sciences in Moscow in 1964.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 22], [22, 24], [25, 31], [32, 34], [35, 46], [47, 51], [52, 61], [62, 67], [68, 78], [79, 81], [82, 85], [86, 91], [92, 98], [99, 108], [109, 117], [118, 120], [121, 125], [126, 129], [130, 133], [134, 143], [144, 146], [147, 157], [158, 162], [163, 166], [167, 176], [177, 179], [180, 187], [188, 196], [197, 199], [200, 206], [207, 209], [210, 214], [214, 215]]}
{"doc_key": "ai-test-386", "ner": [[2, 10, "product"], [31, 32, "field"], [34, 36, "task"]], "ner_mapping_to_source": [1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "Cycorp", "'s", "work", "increasingly", "involves", "giving", "Cycorp", "systems", "the", "ability", "to", "communicate", "with", "end", "users", "in", "natural", "language", "and", "to", "assist", "in", "the", "ongoing", "process", "of", "knowledge", "formation", "through", "machine", "learning", "and", "natural", "language", "understanding", "."], "sentence-detokenized": "However, Cycorp's work increasingly involves giving Cycorp systems the ability to communicate with end users in natural language and to assist in the ongoing process of knowledge formation through machine learning and natural language understanding.", "token2charspan": [[0, 7], [7, 8], [9, 15], [15, 17], [18, 22], [23, 35], [36, 44], [45, 51], [52, 58], [59, 66], [67, 70], [71, 78], [79, 81], [82, 93], [94, 98], [99, 102], [103, 108], [109, 111], [112, 119], [120, 128], [129, 132], [133, 135], [136, 142], [143, 145], [146, 149], [150, 157], [158, 165], [166, 168], [169, 178], [179, 188], [189, 196], [197, 204], [205, 213], [214, 217], [218, 225], [226, 234], [235, 248], [248, 249]]}
{"doc_key": "ai-test-387", "ner": [[53, 53, "metrics"], [55, 55, "metrics"], [57, 57, "metrics"], [59, 63, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "if", "seeking", "the", "most", "suitable", "classifier", "for", "a", "problem", ",", "the", "training", "dataset", "is", "used", "to", "train", "candidate", "algorithms", ",", "the", "validation", "dataset", "is", "used", "to", "compare", "their", "performance", "and", "decide", "which", "one", "to", "adopt", ",", "and", "finally", ",", "the", "test", "dataset", "is", "used", "to", "obtain", "performance", "characteristics", "such", "as", "accuracy", ",", "sensitivity", ",", "specificity", ",", "F", "-", "value", ",", "etc", "."], "sentence-detokenized": "For example, if seeking the most suitable classifier for a problem, the training dataset is used to train candidate algorithms, the validation dataset is used to compare their performance and decide which one to adopt, and finally, the test dataset is used to obtain performance characteristics such as accuracy, sensitivity, specificity, F-value, etc.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 23], [24, 27], [28, 32], [33, 41], [42, 52], [53, 56], [57, 58], [59, 66], [66, 67], [68, 71], [72, 80], [81, 88], [89, 91], [92, 96], [97, 99], [100, 105], [106, 115], [116, 126], [126, 127], [128, 131], [132, 142], [143, 150], [151, 153], [154, 158], [159, 161], [162, 169], [170, 175], [176, 187], [188, 191], [192, 198], [199, 204], [205, 208], [209, 211], [212, 217], [217, 218], [219, 222], [223, 230], [230, 231], [232, 235], [236, 240], [241, 248], [249, 251], [252, 256], [257, 259], [260, 266], [267, 278], [279, 294], [295, 299], [300, 302], [303, 311], [311, 312], [313, 324], [324, 325], [326, 337], [337, 338], [339, 340], [340, 341], [341, 346], [346, 347], [348, 351], [351, 352]]}
{"doc_key": "ai-test-388", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "squared", "error", "is", "0.15", "."], "sentence-detokenized": "The mean squared error is 0.15.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 25], [26, 30], [30, 31]]}
{"doc_key": "ai-test-389", "ner": [[7, 8, "misc"], [4, 4, "organisation"], [13, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 7, 8, "role", "", false, false], [13, 13, 7, 8, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1979", ",", "the", "IEEE", "organised", "a", "Micromouse", "competition", ",", "as", "shown", "in", "Spectrum", "."], "sentence-detokenized": "In 1979, the IEEE organised a Micromouse competition, as shown in Spectrum.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 27], [28, 29], [30, 40], [41, 52], [52, 53], [54, 56], [57, 62], [63, 65], [66, 74], [74, 75]]}
{"doc_key": "ai-test-390", "ner": [[0, 2, "algorithm"], [5, 6, "field"], [10, 12, "task"], [14, 15, "task"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 5, 6, "part-of", "", false, false], [10, 12, 5, 6, "part-of", "task_part_of_field", false, false], [14, 15, 5, 6, "part-of", "task_part_of_field", false, false], [17, 18, 5, 6, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Gabor", "spaces", "are", "useful", "in", "image", "processing", "applications", "such", "as", "optical", "character", "recognition", ",", "iris", "recognition", "and", "fingerprint", "recognition", "."], "sentence-detokenized": "Gabor spaces are useful in image processing applications such as optical character recognition, iris recognition and fingerprint recognition.", "token2charspan": [[0, 5], [6, 12], [13, 16], [17, 23], [24, 26], [27, 32], [33, 43], [44, 56], [57, 61], [62, 64], [65, 72], [73, 82], [83, 94], [94, 95], [96, 100], [101, 112], [113, 116], [117, 128], [129, 140], [140, 141]]}
{"doc_key": "ai-test-391", "ner": [[5, 5, "programlang"], [7, 7, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", "through", "advanced", "interfaces", "with", "Java", "and", "Tcl", "."], "sentence-detokenized": "or through advanced interfaces with Java and Tcl.", "token2charspan": [[0, 2], [3, 10], [11, 19], [20, 30], [31, 35], [36, 40], [41, 44], [45, 48], [48, 49]]}
{"doc_key": "ai-test-392", "ner": [[11, 12, "algorithm"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 21, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "recent", "research", ",", "kernel", "-", "based", "methods", ",", "such", "as", "support", "vector", "machines", ",", "have", "shown", "excellent", "performance", "in", "the", "supervised", "case", "."], "sentence-detokenized": "In recent research, kernel-based methods, such as support vector machines, have shown excellent performance in the supervised case.", "token2charspan": [[0, 2], [3, 9], [10, 18], [18, 19], [20, 26], [26, 27], [27, 32], [33, 40], [40, 41], [42, 46], [47, 49], [50, 57], [58, 64], [65, 73], [73, 74], [75, 79], [80, 85], [86, 95], [96, 107], [108, 110], [111, 114], [115, 125], [126, 130], [130, 131]]}
{"doc_key": "ai-test-393", "ner": [[15, 15, "misc"], [23, 23, "researcher"], [25, 25, "researcher"], [33, 33, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 33, 33, "usage", "", false, false], [25, 25, 33, 33, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["To", "illustrate", "the", "basic", "principles", "of", "bagging", ",", "the", "following", "analysis", "of", "the", "relationship", "between", "ozone", "and", "temperature", "is", "presented", "(", "data", "from", "Rousseeuw", "and", "Leroy", "(", "1986", ")", ",", "analysis", "done", "in", "R", ")", "."], "sentence-detokenized": "To illustrate the basic principles of bagging, the following analysis of the relationship between ozone and temperature is presented (data from Rousseeuw and Leroy (1986), analysis done in R).", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 23], [24, 34], [35, 37], [38, 45], [45, 46], [47, 50], [51, 60], [61, 69], [70, 72], [73, 76], [77, 89], [90, 97], [98, 103], [104, 107], [108, 119], [120, 122], [123, 132], [133, 134], [134, 138], [139, 143], [144, 153], [154, 157], [158, 163], [164, 165], [165, 169], [169, 170], [170, 171], [172, 180], [181, 185], [186, 188], [189, 190], [190, 191], [191, 192]]}
{"doc_key": "ai-test-394", "ner": [[0, 2, "organisation"], [11, 11, "product"], [18, 19, "product"], [21, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 0, 2, "artifact", "", false, false], [18, 19, 0, 2, "artifact", "", false, false], [21, 23, 0, 2, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Denso", "Wave", "is", "a", "subsidiary", "that", "manufactures", "automatic", "identification", "products", "(", "barcode", "readers", "and", "related", "products", ")", ",", "industrial", "robots", "and", "programmable", "logic", "controllers", "."], "sentence-detokenized": "Denso Wave is a subsidiary that manufactures automatic identification products (barcode readers and related products), industrial robots and programmable logic controllers.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 15], [16, 26], [27, 31], [32, 44], [45, 54], [55, 69], [70, 78], [79, 80], [80, 87], [88, 95], [96, 99], [100, 107], [108, 116], [116, 117], [117, 118], [119, 129], [130, 136], [137, 140], [141, 153], [154, 159], [160, 171], [171, 172]]}
{"doc_key": "ai-test-395", "ner": [[0, 2, "metrics"], [6, 6, "metrics"], [21, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 21, 21, "compare", "", false, false], [6, 6, 0, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Bilingual", "evaluation", "understudy", "simply", "calculates", "the", "accuracy", "of", "the", "n-gram", "by", "adding", "the", "same", "weight", "to", "each", "n-", "gram", ",", "whereas", "NIST", "also", "calculates", "how", "informative", "a", "particular", "n-", "gram", "is", "."], "sentence-detokenized": "Bilingual evaluation understudy simply calculates the accuracy of the n-gram by adding the same weight to each n-gram, whereas NIST also calculates how informative a particular n-gram is.", "token2charspan": [[0, 9], [10, 20], [21, 31], [32, 38], [39, 49], [50, 53], [54, 62], [63, 65], [66, 69], [70, 76], [77, 79], [80, 86], [87, 90], [91, 95], [96, 102], [103, 105], [106, 110], [111, 113], [113, 117], [117, 118], [119, 126], [127, 131], [132, 136], [137, 147], [148, 151], [152, 163], [164, 165], [166, 176], [177, 179], [179, 183], [184, 186], [186, 187]]}
{"doc_key": "ai-test-396", "ner": [[14, 14, "algorithm"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "particular", ",", "they", "are", "used", "in", "the", "calculation", "of", "tree", "likelihoods", "(", "in", "Bayesian", "and", "maximum", "likelihood", "approaches", "to", "tree", "estimation", ")", ",", "and", "they", "are", "used", "to", "estimate", "evolutionary", "distances", "between", "sequences", "from", "observed", "differences", "between", "sequences", "."], "sentence-detokenized": "In particular, they are used in the calculation of tree likelihoods (in Bayesian and maximum likelihood approaches to tree estimation), and they are used to estimate evolutionary distances between sequences from observed differences between sequences.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 19], [20, 23], [24, 28], [29, 31], [32, 35], [36, 47], [48, 50], [51, 55], [56, 67], [68, 69], [69, 71], [72, 80], [81, 84], [85, 92], [93, 103], [104, 114], [115, 117], [118, 122], [123, 133], [133, 134], [134, 135], [136, 139], [140, 144], [145, 148], [149, 153], [154, 156], [157, 165], [166, 178], [179, 188], [189, 196], [197, 206], [207, 211], [212, 220], [221, 232], [233, 240], [241, 250], [250, 251]]}
{"doc_key": "ai-test-397", "ner": [[0, 3, "conference"], [20, 21, "misc"], [23, 23, "misc"], [46, 47, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 20, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Audio", "Engineering", "Society", "recommends", "a", "sample", "rate", "of", "48", "kHz", "for", "most", "applications", ",", "but", "recognises", "44.1", "kHz", "for", "compact", "discs", "(", "CDs", ")", "and", "other", "consumer", "uses", ",", "32", "kHz", "for", "transmission", "-", "related", "applications", ",", "and", "96", "kHz", "for", "higher", "bandwidths", "or", "relaxed", "anti-alias", "filter", "intake", "."], "sentence-detokenized": "The Audio Engineering Society recommends a sample rate of 48kHz for most applications, but recognises 44.1kHz for compact discs (CDs) and other consumer uses, 32kHz for transmission-related applications, and 96kHz for higher bandwidths or relaxed anti-alias filter intake.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 29], [30, 40], [41, 42], [43, 49], [50, 54], [55, 57], [58, 60], [60, 63], [64, 67], [68, 72], [73, 85], [85, 86], [87, 90], [91, 101], [102, 106], [106, 109], [110, 113], [114, 121], [122, 127], [128, 129], [129, 132], [132, 133], [134, 137], [138, 143], [144, 152], [153, 157], [157, 158], [159, 161], [161, 164], [165, 168], [169, 181], [181, 182], [182, 189], [190, 202], [202, 203], [204, 207], [208, 210], [210, 213], [214, 217], [218, 224], [225, 235], [236, 238], [239, 246], [247, 257], [258, 264], [265, 271], [271, 272]]}
{"doc_key": "ai-test-398", "ner": [[10, 10, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Affective", "resources", "for", "words", "and", "concepts", "have", "been", "created", "for", "WordNet", "{", "{", "cite", "journal"], "sentence-detokenized": "Affective resources for words and concepts have been created for WordNet {{cite journal", "token2charspan": [[0, 9], [10, 19], [20, 23], [24, 29], [30, 33], [34, 42], [43, 47], [48, 52], [53, 60], [61, 64], [65, 72], [73, 74], [74, 75], [75, 79], [80, 87]]}
{"doc_key": "ai-test-399", "ner": [[1, 4, "misc"], [21, 22, "person"], [26, 29, "person"], [33, 34, "person"], [36, 44, "organisation"], [61, 62, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[26, 29, 33, 34, "role", "acts_in", false, false], [36, 44, 33, 34, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "red", "and", "green", "anamorphic", ",", "the", "audience", "is", "treated", "to", "three", "test", "reels", "featuring", "rural", "scenes", ",", "test", "footage", "of", "Mary", "Dorough", ",", "clips", "of", "John", "B", ".", "Mason", "playing", "passages", "from", "Penman", "Jim", "(", "Famous", "Players", "-", "Lasky", "'s", "film", "released", "that", "year", ",", "but", "not", "in", "3D", ")", ",", "Oriental", "dancers", ",", "and", "a", "reel", "of", "footage", "from", "Niagara", "Falls", "."], "sentence-detokenized": "In red and green anamorphic, the audience is treated to three test reels featuring rural scenes, test footage of Mary Dorough, clips of John B. Mason playing passages from Penman Jim (Famous Players-Lasky's film released that year, but not in 3D), Oriental dancers, and a reel of footage from Niagara Falls.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 16], [17, 27], [27, 28], [29, 32], [33, 41], [42, 44], [45, 52], [53, 55], [56, 61], [62, 66], [67, 72], [73, 82], [83, 88], [89, 95], [95, 96], [97, 101], [102, 109], [110, 112], [113, 117], [118, 125], [125, 126], [127, 132], [133, 135], [136, 140], [141, 142], [142, 143], [144, 149], [150, 157], [158, 166], [167, 171], [172, 178], [179, 182], [183, 184], [184, 190], [191, 198], [198, 199], [199, 204], [204, 206], [207, 211], [212, 220], [221, 225], [226, 230], [230, 231], [232, 235], [236, 239], [240, 242], [243, 245], [245, 246], [246, 247], [248, 256], [257, 264], [264, 265], [266, 269], [270, 271], [272, 276], [277, 279], [280, 287], [288, 292], [293, 300], [301, 306], [306, 307]]}
{"doc_key": "ai-test-400", "ner": [[7, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "particular", "way", "of", "implementing", "maximum", "likelihood", "estimation", "for", "this", "problem", "."], "sentence-detokenized": "This is a particular way of implementing maximum likelihood estimation for this problem.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 20], [21, 24], [25, 27], [28, 40], [41, 48], [49, 59], [60, 70], [71, 74], [75, 79], [80, 87], [87, 88]]}
{"doc_key": "ai-test-401", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "integrates", "the", "functionality", "of", "sitemaps", "and", "RSS", "feeds", "into", "a", "decentralised", "mechanism", "for", "computational", "biologists", "and", "bioinformaticians", "to", "publicly", "broadcast", "and", "retrieve", "metadata", "about", "biomedical", "resources", "."], "sentence-detokenized": "It integrates the functionality of sitemaps and RSS feeds into a decentralised mechanism for computational biologists and bioinformaticians to publicly broadcast and retrieve metadata about biomedical resources.", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 31], [32, 34], [35, 43], [44, 47], [48, 51], [52, 57], [58, 62], [63, 64], [65, 78], [79, 88], [89, 92], [93, 106], [107, 117], [118, 121], [122, 139], [140, 142], [143, 151], [152, 161], [162, 165], [166, 174], [175, 183], [184, 189], [190, 200], [201, 210], [210, 211]]}
{"doc_key": "ai-test-402", "ner": [[4, 11, "misc"], [13, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "covered", "by", "American", "National", "Standards", "Institute", "/", "NISO", "Standard", "Z39.50", "and", "International", "Organization", "for", "Standardization", "Standard", "23950", "."], "sentence-detokenized": "It is covered by American National Standards Institute/NISO Standard Z39.50 and International Organization for Standardization Standard 23950.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 25], [26, 34], [35, 44], [45, 54], [54, 55], [55, 59], [60, 68], [69, 75], [76, 79], [80, 93], [94, 106], [107, 110], [111, 126], [127, 135], [136, 141], [141, 142]]}
{"doc_key": "ai-test-403", "ner": [[24, 27, "misc"], [8, 8, "metrics"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "encoder", "and", "decoder", "are", "trained", "to", "minimise", "perplexity", "by", "using", "a", "simple", "stochastic", "gradient", "descent", "method", "to", "obtain", "a", "phrase", "and", "reproduce", "the", "monothermal", "distribution", "of", "the", "corresponding", "paraphrase", "."], "sentence-detokenized": "The encoder and decoder are trained to minimise perplexity by using a simple stochastic gradient descent method to obtain a phrase and reproduce the monothermal distribution of the corresponding paraphrase.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 27], [28, 35], [36, 38], [39, 47], [48, 58], [59, 61], [62, 67], [68, 69], [70, 76], [77, 87], [88, 96], [97, 104], [105, 111], [112, 114], [115, 121], [122, 123], [124, 130], [131, 134], [135, 144], [145, 148], [149, 160], [161, 173], [174, 176], [177, 180], [181, 194], [195, 205], [205, 206]]}
{"doc_key": "ai-test-404", "ner": [[4, 5, "field"], [8, 10, "task"], [13, 17, "task"], [27, 31, "task"], [33, 37, "task"], [40, 46, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 10, 4, 5, "part-of", "task_part_of_field", false, false], [13, 17, 4, 5, "part-of", "task_part_of_field", false, false], [27, 31, 4, 5, "part-of", "task_part_of_field", false, false], [33, 37, 4, 5, "part-of", "task_part_of_field", false, false], [40, 46, 4, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "typical", "applications", "of", "pattern", "recognition", "technology", "are", "automatic", "speech", "recognition", ",", "the", "classification", "of", "text", "into", "categories", "(", "e.g.", "spam", "/", "non", "-", "spam", ")", ",", "handwriting", "recognition", "on", "postal", "envelopes", ",", "automatic", "recognition", "of", "face", "images", "or", "the", "extraction", "of", "handwritten", "images", "from", "medical", "forms", "."], "sentence-detokenized": "Other typical applications of pattern recognition technology are automatic speech recognition, the classification of text into categories (e.g. spam/non-spam), handwriting recognition on postal envelopes, automatic recognition of face images or the extraction of handwritten images from medical forms.", "token2charspan": [[0, 5], [6, 13], [14, 26], [27, 29], [30, 37], [38, 49], [50, 60], [61, 64], [65, 74], [75, 81], [82, 93], [93, 94], [95, 98], [99, 113], [114, 116], [117, 121], [122, 126], [127, 137], [138, 139], [139, 143], [144, 148], [148, 149], [149, 152], [152, 153], [153, 157], [157, 158], [158, 159], [160, 171], [172, 183], [184, 186], [187, 193], [194, 203], [203, 204], [205, 214], [215, 226], [227, 229], [230, 234], [235, 241], [242, 244], [245, 248], [249, 259], [260, 262], [263, 274], [275, 281], [282, 286], [287, 294], [295, 300], [300, 301]]}
{"doc_key": "ai-test-405", "ner": [[0, 2, "algorithm"], [13, 14, "field"], [16, 17, "task"], [19, 20, "task"], [22, 24, "task"], [26, 30, "task"], [33, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 14, 0, 2, "usage", "", false, false], [16, 17, 0, 2, "usage", "", false, false], [19, 20, 0, 2, "usage", "", false, false], [22, 24, 0, 2, "usage", "", false, false], [26, 30, 0, 2, "usage", "", false, false], [33, 34, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Artificial", "neural", "networks", "have", "been", "used", "for", "a", "variety", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "playing", "board", "and", "video", "games", ",", "and", "medical", "diagnosis", "."], "sentence-detokenized": "Artificial neural networks have been used for a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games, and medical diagnosis.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 31], [32, 36], [37, 41], [42, 45], [46, 47], [48, 55], [56, 58], [59, 64], [64, 65], [66, 75], [76, 84], [85, 91], [91, 92], [93, 99], [100, 111], [111, 112], [113, 120], [121, 132], [132, 133], [134, 140], [141, 148], [149, 158], [158, 159], [160, 167], [168, 173], [174, 177], [178, 183], [184, 189], [189, 190], [191, 194], [195, 202], [203, 212], [212, 213]]}
{"doc_key": "ai-test-406", "ner": [[2, 3, "organisation"], [4, 4, "product"], [12, 12, "product"], [16, 16, "organisation"], [17, 18, "product"], [20, 20, "product"], [22, 24, "product"], [26, 26, "product"], [28, 28, "programlang"], [36, 37, "field"], [41, 41, "product"], [46, 46, "algorithm"], [48, 48, "algorithm"], [50, 50, "algorithm"], [54, 54, "product"], [61, 62, "task"], [66, 67, "algorithm"], [71, 71, "product"], [73, 73, "product"], [75, 77, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "relations": [[4, 4, 2, 3, "origin", "", false, false], [4, 4, 12, 12, "named", "same", false, false], [4, 4, 41, 41, "named", "same", false, false], [28, 28, 36, 37, "related-to", "used_for", false, false], [46, 46, 28, 28, "part-of", "", true, false], [46, 46, 41, 41, "origin", "", true, false], [48, 48, 28, 28, "part-of", "", true, false], [48, 48, 41, 41, "origin", "", true, false], [50, 50, 28, 28, "part-of", "", true, false], [50, 50, 41, 41, "origin", "", true, false], [54, 54, 61, 62, "related-to", "used_for", false, false], [66, 67, 54, 54, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Examples", "include", "Salford", "Systems", "CART", "(", "proprietary", "code", "licensed", "from", "the", "original", "CART", "authors", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "an", "open", "source", "software", "environment", "for", "statistical", "computing", "which", "includes", "several", "CART", "implementations", "such", "as", "the", "rpart", ",", "party", "and", "randomForest", "packages", ")", ",", "Weka", "(", "a", "free", "and", "open", "source", "data", "mining", "suite", "containing", "many", "decision", "tree", "algorithms", ")", ",", "Orange", ",", "KNIME", ",", "Microsoft", "SQL", "Server", "programming", "language", ")", "."], "sentence-detokenized": "Examples include Salford Systems CART (proprietary code licensed from the original CART authors), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (an open source software environment for statistical computing which includes several CART implementations such as the rpart, party and randomForest packages), Weka (a free and open source data mining suite containing many decision tree algorithms), Orange, KNIME, Microsoft SQL Server programming language).", "token2charspan": [[0, 8], [9, 16], [17, 24], [25, 32], [33, 37], [38, 39], [39, 50], [51, 55], [56, 64], [65, 69], [70, 73], [74, 82], [83, 87], [88, 95], [95, 96], [96, 97], [98, 101], [102, 106], [107, 114], [114, 115], [116, 126], [126, 127], [128, 131], [132, 142], [143, 148], [148, 149], [150, 156], [156, 157], [158, 159], [160, 161], [161, 163], [164, 168], [169, 175], [176, 184], [185, 196], [197, 200], [201, 212], [213, 222], [223, 228], [229, 237], [238, 245], [246, 250], [251, 266], [267, 271], [272, 274], [275, 278], [279, 284], [284, 285], [286, 291], [292, 295], [296, 308], [309, 317], [317, 318], [318, 319], [320, 324], [325, 326], [326, 327], [328, 332], [333, 336], [337, 341], [342, 348], [349, 353], [354, 360], [361, 366], [367, 377], [378, 382], [383, 391], [392, 396], [397, 407], [407, 408], [408, 409], [410, 416], [416, 417], [418, 423], [423, 424], [425, 434], [435, 438], [439, 445], [446, 457], [458, 466], [466, 467], [467, 468]]}
{"doc_key": "ai-test-407", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [10, 11, "researcher"], [13, 14, "university"], [16, 17, "researcher"], [19, 22, "organisation"], [24, 24, "organisation"], [33, 35, "researcher"], [37, 39, "researcher"], [41, 42, "organisation"], [61, 64, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 10, 11, "origin", "", false, false], [0, 2, 16, 17, "origin", "", false, false], [0, 2, 33, 35, "origin", "", false, false], [0, 2, 37, 39, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [10, 11, 13, 14, "physical", "", false, false], [10, 11, 13, 14, "role", "", false, false], [16, 17, 19, 22, "physical", "", false, false], [16, 17, 19, 22, "role", "", false, false], [24, 24, 19, 22, "named", "", false, false], [33, 35, 41, 42, "physical", "", false, false], [33, 35, 41, 42, "role", "", false, false], [37, 39, 41, 42, "physical", "", false, false], [37, 39, 41, 42, "role", "", false, false], [61, 64, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", "was", "first", "developed", "by", "Fumitada", "Itakura", "at", "Nagoya", "University", "and", "Shuzo", "Saito", "at", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", ",", "then", "further", "developed", "by", "Bishnu", "S.", "Atal", "and", "Manfred", "R.", "Schroeder", "at", "Bell", "Labs", "in", "the", "early", "to", "mid-1970s", ",", "and", "in", "the", "the", "late", "1970s", "became", "the", "basis", "for", "the", "first", "speech", "synthesiser", "DSP", "chip", "."], "sentence-detokenized": "Linear predictive coding (LPC) was first developed by Fumitada Itakura at Nagoya University and Shuzo Saito at Nippon Telegraph and Telephone (NTT) in 1966, then further developed by Bishnu S. Atal and Manfred R. Schroeder at Bell Labs in the early to mid-1970s, and in the the late 1970s became the basis for the first speech synthesiser DSP chip.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [31, 34], [35, 40], [41, 50], [51, 53], [54, 62], [63, 70], [71, 73], [74, 80], [81, 91], [92, 95], [96, 101], [102, 107], [108, 110], [111, 117], [118, 127], [128, 131], [132, 141], [142, 143], [143, 146], [146, 147], [148, 150], [151, 155], [155, 156], [157, 161], [162, 169], [170, 179], [180, 182], [183, 189], [190, 192], [193, 197], [198, 201], [202, 209], [210, 212], [213, 222], [223, 225], [226, 230], [231, 235], [236, 238], [239, 242], [243, 248], [249, 251], [252, 261], [261, 262], [263, 266], [267, 269], [270, 273], [274, 277], [278, 282], [283, 288], [289, 295], [296, 299], [300, 305], [306, 309], [310, 313], [314, 319], [320, 326], [327, 338], [339, 342], [343, 347], [347, 348]]}
{"doc_key": "ai-test-408", "ner": [[0, 3, "metrics"], [8, 8, "metrics"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 0, 3, "part-of", "", false, false], [10, 10, 0, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "F", "-", "score", "is", "a", "combination", "of", "precision", "and", "recall", ",", "providing", "a", "single", "score", "."], "sentence-detokenized": "The F-score is a combination of precision and recall, providing a single score.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 16], [17, 28], [29, 31], [32, 41], [42, 45], [46, 52], [52, 53], [54, 63], [64, 65], [66, 72], [73, 78], [78, 79]]}
{"doc_key": "ai-test-409", "ner": [[0, 1, "field"], [8, 11, "task"], [16, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 0, 1, "part-of", "task_part_of_field", false, false], [16, 18, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Image", "analysis", "tasks", "can", "be", "as", "simple", "as", "reading", "barcode", "d", "tags", "or", "as", "complex", "as", "facial", "recognition", "systems", "."], "sentence-detokenized": "Image analysis tasks can be as simple as reading barcode d tags or as complex as facial recognition systems.", "token2charspan": [[0, 5], [6, 14], [15, 20], [21, 24], [25, 27], [28, 30], [31, 37], [38, 40], [41, 48], [49, 56], [57, 58], [59, 63], [64, 66], [67, 69], [70, 77], [78, 80], [81, 87], [88, 99], [100, 107], [107, 108]]}
{"doc_key": "ai-test-410", "ner": [[5, 7, "algorithm"], [22, 23, "algorithm"], [28, 30, "algorithm"], [33, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[28, 30, 22, 23, "type-of", "", false, false], [33, 33, 28, 30, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "special", "case", "of", "linear", "support", "vector", "machines", "can", "be", "solved", "more", "efficiently", "by", "similar", "algorithms", "to", "optimise", "their", "close", "cousin", ",", "logistic", "regression", ";", "such", "algorithms", "include", "stochastic", "gradient", "descent", "(", "e.g.", "PEGASOS", ")", "."], "sentence-detokenized": "The special case of linear support vector machines can be solved more efficiently by similar algorithms to optimise their close cousin, logistic regression; such algorithms include stochastic gradient descent (e.g. PEGASOS).", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 19], [20, 26], [27, 34], [35, 41], [42, 50], [51, 54], [55, 57], [58, 64], [65, 69], [70, 81], [82, 84], [85, 92], [93, 103], [104, 106], [107, 115], [116, 121], [122, 127], [128, 134], [134, 135], [136, 144], [145, 155], [155, 156], [157, 161], [162, 172], [173, 180], [181, 191], [192, 200], [201, 208], [209, 210], [210, 214], [215, 222], [222, 223], [223, 224]]}
{"doc_key": "ai-test-411", "ner": [[1, 1, "product"], [3, 3, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 3, 3, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["When", "Siri", "on", "iOS", "devices", "is", "asked", "if", "you", "have", "a", "pet", ",", "one", "of", "the", "responses", "is", "I", "once", "had", "an", "AIBO", "."], "sentence-detokenized": "When Siri on iOS devices is asked if you have a pet, one of the responses is I once had an AIBO.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 16], [17, 24], [25, 27], [28, 33], [34, 36], [37, 40], [41, 45], [46, 47], [48, 51], [51, 52], [53, 56], [57, 59], [60, 63], [64, 73], [74, 76], [77, 78], [79, 83], [84, 87], [88, 90], [91, 95], [95, 96]]}
{"doc_key": "ai-test-412", "ner": [[1, 2, "task"], [4, 7, "metrics"], [11, 11, "metrics"], [13, 13, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 7, 1, 2, "part-of", "", false, false], [11, 11, 4, 7, "named", "", false, false], [13, 13, 1, 2, "part-of", "", false, false], [18, 18, 13, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "information", "retrieval", ",", "positive", "predictive", "values", "are", "referred", "to", "as", "precision", "and", "sensitivities", "are", "referred", "to", "as", "recall", "."], "sentence-detokenized": "In information retrieval, positive predictive values are referred to as precision and sensitivities are referred to as recall.", "token2charspan": [[0, 2], [3, 14], [15, 24], [24, 25], [26, 34], [35, 45], [46, 52], [53, 56], [57, 65], [66, 68], [69, 71], [72, 81], [82, 85], [86, 99], [100, 103], [104, 112], [113, 115], [116, 118], [119, 125], [125, 126]]}
{"doc_key": "ai-test-413", "ner": [[10, 11, "field"], [13, 13, "task"], [15, 15, "task"], [17, 18, "task"], [33, 34, "task"], [36, 37, "task"], [39, 42, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 13, 10, 11, "part-of", "task_part_of_field", false, false], [15, 15, 10, 11, "part-of", "task_part_of_field", false, false], [17, 18, 10, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "particular", ",", "his", "research", "focuses", "on", "areas", "such", "as", "text", "mining", "(", "extraction", ",", "classification", ",", "novelty", "detection", ")", "and", "new", "theoretical", "frameworks", "such", "as", "a", "unified", "utility", "-", "based", "theory", "linking", "information", "retrieval", ",", "automatic", "summarisation", ",", "free", "-", "text", "answering", "and", "related", "tasks", "."], "sentence-detokenized": "In particular, his research focuses on areas such as text mining (extraction, classification, novelty detection) and new theoretical frameworks such as a unified utility-based theory linking information retrieval, automatic summarisation, free-text answering and related tasks.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 27], [28, 35], [36, 38], [39, 44], [45, 49], [50, 52], [53, 57], [58, 64], [65, 66], [66, 76], [76, 77], [78, 92], [92, 93], [94, 101], [102, 111], [111, 112], [113, 116], [117, 120], [121, 132], [133, 143], [144, 148], [149, 151], [152, 153], [154, 161], [162, 169], [169, 170], [170, 175], [176, 182], [183, 190], [191, 202], [203, 212], [212, 213], [214, 223], [224, 237], [237, 238], [239, 243], [243, 244], [244, 248], [249, 258], [259, 262], [263, 270], [271, 276], [276, 277]]}
{"doc_key": "ai-test-414", "ner": [[1, 2, "product"], [5, 6, "product"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 1, 2, "part-of", "", false, false], [17, 18, 1, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Delta", "robot", "has", "a", "rotating", "drive", "mounted", "on", "a", "base", "that", "moves", "a", "light", "and", "stiff", "parallelogram", "arm", "."], "sentence-detokenized": "The Delta robot has a rotating drive mounted on a base that moves a light and stiff parallelogram arm.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 19], [20, 21], [22, 30], [31, 36], [37, 44], [45, 47], [48, 49], [50, 54], [55, 59], [60, 65], [66, 67], [68, 73], [74, 77], [78, 83], [84, 97], [98, 101], [101, 102]]}
{"doc_key": "ai-test-415", "ner": [[10, 14, "metrics"], [16, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "four", "results", "can", "be", "expressed", "in", "terms", "of", "a", "2", "x", "2", "contingency", "table", "or", "confusion", "matrix", ",", "as", "follows", "."], "sentence-detokenized": "These four results can be expressed in terms of a 2 x 2 contingency table or confusion matrix, as follows.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 22], [23, 25], [26, 35], [36, 38], [39, 44], [45, 47], [48, 49], [50, 51], [52, 53], [54, 55], [56, 67], [68, 73], [74, 76], [77, 86], [87, 93], [93, 94], [95, 97], [98, 105], [105, 106]]}
{"doc_key": "ai-test-416", "ner": [[2, 3, "field"], [30, 31, "task"], [37, 38, "task"], [43, 45, "task"], [47, 49, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[30, 31, 2, 3, "part-of", "task_part_of_field", false, false], [37, 38, 2, 3, "part-of", "task_part_of_field", false, false], [43, 45, 2, 3, "part-of", "task_part_of_field", false, false], [47, 49, 2, 3, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "actual", "data", "mining", "task", "is", "the", "semi-automatic", "or", "automatic", "analysis", "of", "large", "amounts", "of", "data", "to", "extract", "unknown", "and", "interesting", "patterns", ",", "such", "as", "clusters", "of", "data", "records", "(", "cluster", "analysis", ")", ",", "anomalous", "records", "(", "anomaly", "detection", ")", "and", "dependencies", "(", "association", "rule", "mining", ",", "sequential", "pattern", "mining", ")", "."], "sentence-detokenized": "The actual data mining task is the semi-automatic or automatic analysis of large amounts of data to extract unknown and interesting patterns, such as clusters of data records (cluster analysis), anomalous records (anomaly detection) and dependencies (association rule mining, sequential pattern mining).", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 22], [23, 27], [28, 30], [31, 34], [35, 49], [50, 52], [53, 62], [63, 71], [72, 74], [75, 80], [81, 88], [89, 91], [92, 96], [97, 99], [100, 107], [108, 115], [116, 119], [120, 131], [132, 140], [140, 141], [142, 146], [147, 149], [150, 158], [159, 161], [162, 166], [167, 174], [175, 176], [176, 183], [184, 192], [192, 193], [193, 194], [195, 204], [205, 212], [213, 214], [214, 221], [222, 231], [231, 232], [233, 236], [237, 249], [250, 251], [251, 262], [263, 267], [268, 274], [274, 275], [276, 286], [287, 294], [295, 301], [301, 302], [302, 303]]}
{"doc_key": "ai-test-417", "ner": [[11, 12, "product"], [0, 2, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sentiment", "analysis", "has", "proven", "to", "be", "a", "valuable", "technique", "for", "a", "recommendation", "system", "."], "sentence-detokenized": "Sentiment analysis has proven to be a valuable technique for a recommendation system.", "token2charspan": [[0, 9], [10, 18], [19, 22], [23, 29], [30, 32], [33, 35], [36, 37], [38, 46], [47, 56], [57, 60], [61, 62], [63, 77], [78, 84], [84, 85]]}
{"doc_key": "ai-test-418", "ner": [[5, 5, "misc"], [12, 12, "product"], [34, 34, "organisation"], [38, 39, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 12, 12, "usage", "", false, false], [34, 34, 38, 39, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "it", "happens", ",", "the", "Germans", "chose", "the", "operating", "frequency", "of", "the", "Wotan", "system", "very", "badly", ";", "it", "operates", "on", "45", "MHz", ",", "which", "happens", "to", "be", "the", "frequency", "of", "the", "powerful", "but", "dormant", "BBC", "television", "transmitter", "at", "Alexandra", "Palace", "."], "sentence-detokenized": "As it happens, the Germans chose the operating frequency of the Wotan system very badly; it operates on 45 MHz, which happens to be the frequency of the powerful but dormant BBC television transmitter at Alexandra Palace.", "token2charspan": [[0, 2], [3, 5], [6, 13], [13, 14], [15, 18], [19, 26], [27, 32], [33, 36], [37, 46], [47, 56], [57, 59], [60, 63], [64, 69], [70, 76], [77, 81], [82, 87], [87, 88], [89, 91], [92, 100], [101, 103], [104, 106], [107, 110], [110, 111], [112, 117], [118, 125], [126, 128], [129, 131], [132, 135], [136, 145], [146, 148], [149, 152], [153, 161], [162, 165], [166, 173], [174, 177], [178, 188], [189, 200], [201, 203], [204, 213], [214, 220], [220, 221]]}
{"doc_key": "ai-test-419", "ner": [[10, 14, "metrics"], [16, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "four", "results", "can", "be", "expressed", "in", "terms", "of", "a", "2", "x", "2", "contingency", "table", "or", "confusion", "matrix", ",", "as", "follows", "."], "sentence-detokenized": "These four results can be expressed in terms of a 2 x 2 contingency table or confusion matrix, as follows.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 22], [23, 25], [26, 35], [36, 38], [39, 44], [45, 47], [48, 49], [50, 51], [52, 53], [54, 55], [56, 67], [68, 73], [74, 76], [77, 86], [87, 93], [93, 94], [95, 97], [98, 105], [105, 106]]}
{"doc_key": "ai-test-420", "ner": [[1, 3, "misc"], [9, 9, "misc"], [13, 13, "product"], [15, 15, "product"], [17, 19, "product"], [27, 27, "misc"], [42, 45, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 13, 9, 9, "usage", "", false, false], [15, 15, 9, 9, "usage", "", false, false], [17, 19, 15, 15, "named", "", false, false], [27, 27, 9, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "Semantic", "Web", "applications", ",", "and", "in", "relatively", "popular", "RDF", "applications", "such", "as", "RSS", "and", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "resources", "are", "often", "represented", "by", "URIs", "that", "are", "intentionally", "represented", "and", "can", "be", "used", "to", "access", "the", "actual", "data", "on", "the", "World", "Wide", "Web", "."], "sentence-detokenized": "In Semantic Web applications, and in relatively popular RDF applications such as RSS and FOAF (Friend a Friend), resources are often represented by URIs that are intentionally represented and can be used to access the actual data on the World Wide Web.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 28], [28, 29], [30, 33], [34, 36], [37, 47], [48, 55], [56, 59], [60, 72], [73, 77], [78, 80], [81, 84], [85, 88], [89, 93], [94, 95], [95, 101], [102, 103], [104, 110], [110, 111], [111, 112], [113, 122], [123, 126], [127, 132], [133, 144], [145, 147], [148, 152], [153, 157], [158, 161], [162, 175], [176, 187], [188, 191], [192, 195], [196, 198], [199, 203], [204, 206], [207, 213], [214, 217], [218, 224], [225, 229], [230, 232], [233, 236], [237, 242], [243, 247], [248, 251], [251, 252]]}
{"doc_key": "ai-test-421", "ner": [[0, 10, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "has", "conducted", "an", "in", "-", "depth", "study", "of", "this", "topic"], "sentence-detokenized": "The Association for the Advancement of Artificial Intelligence has conducted an in-depth study of this topic", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 35], [36, 38], [39, 49], [50, 62], [63, 66], [67, 76], [77, 79], [80, 82], [82, 83], [83, 88], [89, 94], [95, 97], [98, 102], [103, 108]]}
{"doc_key": "ai-test-422", "ner": [[5, 11, "product"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 20, 5, 11, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Starting", "as", "a", "curiosity", ",", "the", "voice", "system", "of", "the", "Apple", "Macintosh", "has", "evolved", "into", "a", "fully", "supported", "program", ",", "PlainTalk", ",", "for", "people", "with", "vision", "problems", "."], "sentence-detokenized": "Starting as a curiosity, the voice system of the Apple Macintosh has evolved into a fully supported program, PlainTalk, for people with vision problems.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 23], [23, 24], [25, 28], [29, 34], [35, 41], [42, 44], [45, 48], [49, 54], [55, 64], [65, 68], [69, 76], [77, 81], [82, 83], [84, 89], [90, 99], [100, 107], [107, 108], [109, 118], [118, 119], [120, 123], [124, 130], [131, 135], [136, 142], [143, 151], [151, 152]]}
{"doc_key": "ai-test-423", "ner": [[7, 7, "field"], [9, 10, "task"], [12, 13, "task"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 7, 7, "part-of", "task_part_of_field", false, false], [12, 13, 7, 7, "part-of", "task_part_of_field", false, false], [15, 16, 7, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Other", "areas", "of", "use", "for", "ontologies", "in", "NLP", "include", "information", "retrieval", ",", "information", "extraction", "and", "automatic", "summarisation", "."], "sentence-detokenized": "Other areas of use for ontologies in NLP include information retrieval, information extraction and automatic summarisation.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 18], [19, 22], [23, 33], [34, 36], [37, 40], [41, 48], [49, 60], [61, 70], [70, 71], [72, 83], [84, 94], [95, 98], [99, 108], [109, 122], [122, 123]]}
{"doc_key": "ai-test-424", "ner": [[5, 14, "organisation"], [16, 21, "organisation"], [24, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Institute", "works", "closely", "with", "the", "Janelia", "Farm", "Campus", "of", "the", "Howard", "Hughes", "Medical", "Institute", ",", "the", "Allen", "Institute", "for", "Brain", "Science", "and", "the", "National", "Institutes", "of", "Health", "to", "develop", "better", "ways", "of", "reconstructing", "neuronal", "architecture", "."], "sentence-detokenized": "The Institute works closely with the Janelia Farm Campus of the Howard Hughes Medical Institute, the Allen Institute for Brain Science and the National Institutes of Health to develop better ways of reconstructing neuronal architecture.", "token2charspan": [[0, 3], [4, 13], [14, 19], [20, 27], [28, 32], [33, 36], [37, 44], [45, 49], [50, 56], [57, 59], [60, 63], [64, 70], [71, 77], [78, 85], [86, 95], [95, 96], [97, 100], [101, 106], [107, 116], [117, 120], [121, 126], [127, 134], [135, 138], [139, 142], [143, 151], [152, 162], [163, 165], [166, 172], [173, 175], [176, 183], [184, 190], [191, 195], [196, 198], [199, 213], [214, 222], [223, 235], [235, 236]]}
{"doc_key": "ai-test-425", "ner": [[2, 2, "organisation"], [5, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 2, 2, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Recently", ",", "Google", "announced", "that", "Google", "Translate", "translates", "approximately", "enough", "text", "to", "fill", "a", "million", "books", "in", "a", "single", "day", "(", "2012", ")", "."], "sentence-detokenized": "Recently, Google announced that Google Translate translates approximately enough text to fill a million books in a single day (2012).", "token2charspan": [[0, 8], [8, 9], [10, 16], [17, 26], [27, 31], [32, 38], [39, 48], [49, 59], [60, 73], [74, 80], [81, 85], [86, 88], [89, 93], [94, 95], [96, 103], [104, 109], [110, 112], [113, 114], [115, 121], [122, 125], [126, 127], [127, 131], [131, 132], [132, 133]]}
{"doc_key": "ai-test-426", "ner": [[12, 13, "country"], [15, 15, "country"], [17, 17, "country"], [19, 19, "country"], [21, 21, "country"], [23, 25, "country"], [35, 36, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Events", "are", "held", "all", "over", "the", "world", "and", "are", "most", "popular", "in", "the", "UK", ",", "USA", ",", "Japan", ",", "Singapore", ",", "India", ",", "Korea", "and", "are", "starting", "to", "gain", "popularity", "in", "subcontinental", "countries", "such", "as", "Sri", "Lanka", "."], "sentence-detokenized": "Events are held all over the world and are most popular in the UK, USA, Japan, Singapore, India, Korea and are starting to gain popularity in subcontinental countries such as Sri Lanka.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 24], [25, 28], [29, 34], [35, 38], [39, 42], [43, 47], [48, 55], [56, 58], [59, 62], [63, 65], [65, 66], [67, 70], [70, 71], [72, 77], [77, 78], [79, 88], [88, 89], [90, 95], [95, 96], [97, 102], [103, 106], [107, 110], [111, 119], [120, 122], [123, 127], [128, 138], [139, 141], [142, 156], [157, 166], [167, 171], [172, 174], [175, 178], [179, 184], [184, 185]]}
{"doc_key": "ai-test-427", "ner": [[6, 6, "programlang"], [12, 12, "programlang"], [14, 14, "programlang"], [16, 17, "programlang"], [19, 19, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "packages", "are", "mainly", "developed", "in", "R", ",", "but", "sometimes", "also", "in", "Java", ",", "C", ",", "C", "++", "and", "Fortran", "."], "sentence-detokenized": "These packages are mainly developed in R, but sometimes also in Java, C, C++ and Fortran.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 25], [26, 35], [36, 38], [39, 40], [40, 41], [42, 45], [46, 55], [56, 60], [61, 63], [64, 68], [68, 69], [70, 71], [71, 72], [73, 74], [74, 76], [77, 80], [81, 88], [88, 89]]}
{"doc_key": "ai-test-428", "ner": [[4, 8, "conference"], [10, 12, "conference"], [14, 14, "researcher"], [16, 16, "researcher"], [17, 21, "researcher"], [23, 25, "algorithm"], [30, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 12, 4, 8, "named", "", false, false], [14, 14, 4, 8, "physical", "", false, false], [14, 14, 4, 8, "role", "", false, false], [14, 14, 17, 21, "role", "teams_up_with", false, false], [14, 14, 23, 25, "usage", "", false, false], [16, 16, 4, 8, "physical", "", false, false], [16, 16, 4, 8, "role", "", false, false], [16, 16, 17, 21, "role", "teams_up_with", false, false], [16, 16, 23, 25, "usage", "", false, false], [17, 21, 4, 8, "physical", "", false, false], [17, 21, 4, 8, "role", "", false, false], [17, 21, 23, 25, "usage", "", false, false], [23, 25, 30, 35, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["As", "part", "of", "the", "European", "Conference", "on", "Computer", "Vision", "(", "ECCV", ")", "2006", ",", "Dalal", "and", "Triggs", "collaborated", "with", "Cordelia", "Schmid", "to", "apply", "the", "HOG", "detector", "to", "the", "problem", "of", "human", "detection", "in", "film", "and", "video", "."], "sentence-detokenized": "As part of the European Conference on Computer Vision (ECCV) 2006, Dalal and Triggs collaborated with Cordelia Schmid to apply the HOG detector to the problem of human detection in film and video.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 23], [24, 34], [35, 37], [38, 46], [47, 53], [54, 55], [55, 59], [59, 60], [61, 65], [65, 66], [67, 72], [73, 76], [77, 83], [84, 96], [97, 101], [102, 110], [111, 117], [118, 120], [121, 126], [127, 130], [131, 134], [135, 143], [144, 146], [147, 150], [151, 158], [159, 161], [162, 167], [168, 177], [178, 180], [181, 185], [186, 189], [190, 195], [195, 196]]}
{"doc_key": "ai-test-429", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [12, 12, "task"], [20, 22, "metrics"], [24, 24, "metrics"], [30, 30, "metrics"], [33, 35, "metrics"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 3, 12, 12, "related-to", "measured_with", false, false], [5, 5, 12, 12, "related-to", "measured_with", false, false], [20, 22, 12, 12, "related-to", "measured_with", false, false], [24, 24, 20, 22, "named", "", false, false], [30, 30, 20, 22, "named", "", false, false], [37, 37, 33, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "addition", "to", "sensitivity", "and", "specificity", ",", "the", "performance", "of", "a", "binary", "classification", "test", "can", "be", "measured", "in", "terms", "of", "positive", "predictive", "value", "(", "PPV", ")", "(", "also", "known", "as", "precision", ")", "and", "negative", "predictive", "value", "(", "NPV", ")", "."], "sentence-detokenized": "In addition to sensitivity and specificity, the performance of a binary classification test can be measured in terms of positive predictive value (PPV) (also known as precision) and negative predictive value (NPV).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 42], [42, 43], [44, 47], [48, 59], [60, 62], [63, 64], [65, 71], [72, 86], [87, 91], [92, 95], [96, 98], [99, 107], [108, 110], [111, 116], [117, 119], [120, 128], [129, 139], [140, 145], [146, 147], [147, 150], [150, 151], [152, 153], [153, 157], [158, 163], [164, 166], [167, 176], [176, 177], [178, 181], [182, 190], [191, 201], [202, 207], [208, 209], [209, 212], [212, 213], [213, 214]]}
{"doc_key": "ai-test-430", "ner": [[13, 15, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "models", "can", "give", "partial", "rewards", "for", "overlapping", "matches", "(", "e.g.", "using", "the", "Jaccard", "index", "criterion", "."], "sentence-detokenized": "Such models can give partial rewards for overlapping matches (e.g. using the Jaccard index criterion.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 28], [29, 36], [37, 40], [41, 52], [53, 60], [61, 62], [62, 66], [67, 72], [73, 76], [77, 84], [85, 90], [91, 100], [100, 101]]}
{"doc_key": "ai-test-431", "ner": [[22, 27, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Furthermore", ",", "in", "the", "case", "of", "single", "sample", "-", "based", "estimation", ",", "it", "demonstrates", "the", "philosophical", "issues", "and", "possible", "misunderstandings", "when", "using", "maximum", "likelihood", "estimators", "and", "likelihood", "functions", "."], "sentence-detokenized": "Furthermore, in the case of single sample-based estimation, it demonstrates the philosophical issues and possible misunderstandings when using maximum likelihood estimators and likelihood functions.", "token2charspan": [[0, 11], [11, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 34], [35, 41], [41, 42], [42, 47], [48, 58], [58, 59], [60, 62], [63, 75], [76, 79], [80, 93], [94, 100], [101, 104], [105, 113], [114, 131], [132, 136], [137, 142], [143, 150], [151, 161], [162, 172], [173, 176], [177, 187], [188, 197], [197, 198]]}
