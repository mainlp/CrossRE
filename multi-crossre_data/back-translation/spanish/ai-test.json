{"doc_key": "ai-test-1", "ner": [[5, 7, "algorithm"], [9, 10, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "generative", "modelling", "approaches", "include", "naive", "Bayes", "classifiers", ",", "Gaussian", "mixture", "models", ",", "variational", "autoencoders", "and", "others", "."], "sentence-detokenized": "Typical generative modelling approaches include naive Bayes classifiers, Gaussian mixture models, variational autoencoders and others.", "token2charspan": [[0, 7], [8, 18], [19, 28], [29, 39], [40, 47], [48, 53], [54, 59], [60, 71], [71, 72], [73, 81], [82, 89], [90, 96], [96, 97], [98, 109], [110, 122], [123, 126], [127, 133], [133, 134]]}
{"doc_key": "ai-test-2", "ner": [[6, 6, "organisation"], [10, 10, "conference"], [14, 20, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 10, 10, "role", "", false, false], [14, 20, 10, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Finally", ",", "every", "two", "years", ",", "ELRA", "organises", "a", "major", "LREC", "conference", ",", "the", "International", "Conference", "on", "Language", "Resources", "and", "Evaluation", "."], "sentence-detokenized": "Finally, every two years, ELRA organises a major LREC conference, the International Conference on Language Resources and Evaluation.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 18], [19, 24], [24, 25], [26, 30], [31, 40], [41, 42], [43, 48], [49, 53], [54, 64], [64, 65], [66, 69], [70, 83], [84, 94], [95, 97], [98, 106], [107, 116], [117, 120], [121, 131], [131, 132]]}
{"doc_key": "ai-test-3", "ner": [[7, 11, "algorithm"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "task", "is", "typically", "to", "derive", "the", "maximum", "likelihood", "estimate", "of", "the", "HMM", "parameters", "given", "the", "output", "sequences", "."], "sentence-detokenized": "The task is typically to derive the maximum likelihood estimate of the HMM parameters given the output sequences.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 21], [22, 24], [25, 31], [32, 35], [36, 43], [44, 54], [55, 63], [64, 66], [67, 70], [71, 74], [75, 85], [86, 91], [92, 95], [96, 102], [103, 112], [112, 113]]}
{"doc_key": "ai-test-4", "ner": [[1, 1, "algorithm"], [4, 6, "algorithm"], [9, 9, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 9, 9, "compare", "", false, false], [4, 6, 9, 9, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Unlike", "neural", "networks", "and", "support", "vector", "machines", ",", "the", "AdaBoost", "training", "process", "selects", "only", "those", "features", "that", "are", "known", "to", "improve", "the", "predictive", "power", "of", "the", "model", ",", "reducing", "dimensionality", "and", "potentially", "improving", "runtime", ",", "as", "irrelevant", "features", "do", "not", "need", "to", "be", "computed", "."], "sentence-detokenized": "Unlike neural networks and support vector machines, the AdaBoost training process selects only those features that are known to improve the predictive power of the model, reducing dimensionality and potentially improving runtime, as irrelevant features do not need to be computed.", "token2charspan": [[0, 6], [7, 13], [14, 22], [23, 26], [27, 34], [35, 41], [42, 50], [50, 51], [52, 55], [56, 64], [65, 73], [74, 81], [82, 89], [90, 94], [95, 100], [101, 109], [110, 114], [115, 118], [119, 124], [125, 127], [128, 135], [136, 139], [140, 150], [151, 156], [157, 159], [160, 163], [164, 169], [169, 170], [171, 179], [180, 194], [195, 198], [199, 210], [211, 220], [221, 228], [228, 229], [230, 232], [233, 243], [244, 252], [253, 255], [256, 259], [260, 264], [265, 267], [268, 270], [271, 279], [279, 280]]}
{"doc_key": "ai-test-5", "ner": [[0, 0, "misc"], [11, 13, "misc"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 13, "part-of", "", false, false], [11, 13, 15, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Troponymy", "is", "one", "of", "the", "possible", "relations", "between", "verbs", "in", "the", "semantic", "network", "of", "the", "Word", "Net", "database", "."], "sentence-detokenized": "Troponymy is one of the possible relations between verbs in the semantic network of the WordNet database.", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 19], [20, 23], [24, 32], [33, 42], [43, 50], [51, 56], [57, 59], [60, 63], [64, 72], [73, 80], [81, 83], [84, 87], [88, 92], [92, 95], [96, 104], [104, 105]]}
{"doc_key": "ai-test-6", "ner": [[8, 9, "task"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 11, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "frame", "language", "is", "a", "technology", "used", "for", "knowledge", "representation", "in", "artificial", "intelligence", "."], "sentence-detokenized": "A frame language is a technology used for knowledge representation in artificial intelligence.", "token2charspan": [[0, 1], [2, 7], [8, 16], [17, 19], [20, 21], [22, 32], [33, 37], [38, 41], [42, 51], [52, 66], [67, 69], [70, 80], [81, 93], [93, 94]]}
{"doc_key": "ai-test-7", "ner": [[0, 0, "metrics"], [5, 6, "metrics"], [12, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 5, 6, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "the", "bilingual", "assessment", "in", "its", "calculation", "of", "the", "brevity", "penalty", "in", "that", "small", "variations", "in", "translation", "length", "do", "not", "affect", "the", "overall", "score", "as", "much", "."], "sentence-detokenized": "NIST also differs from the bilingual assessment in its calculation of the brevity penalty in that small variations in translation length do not affect the overall score as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 26], [27, 36], [37, 47], [48, 50], [51, 54], [55, 66], [67, 69], [70, 73], [74, 81], [82, 89], [90, 92], [93, 97], [98, 103], [104, 114], [115, 117], [118, 129], [130, 136], [137, 139], [140, 143], [144, 150], [151, 154], [155, 162], [163, 168], [169, 171], [172, 176], [176, 177]]}
{"doc_key": "ai-test-8", "ner": [[5, 6, "algorithm"], [9, 11, "algorithm"], [22, 26, "field"], [32, 33, "algorithm"], [35, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 22, 26, "usage", "", false, false], [9, 11, 22, 26, "usage", "", false, false], [32, 33, 22, 26, "type-of", "", false, false], [35, 37, 22, 26, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "model", "(", "e.g.", "a", "neural", "network", "or", "a", "naive", "Bayes", "classifier", ")", "is", "trained", "on", "the", "training", "data", "set", "using", "a", "supervised", "learning", "method", ",", "e.g.", "using", "optimisation", "methods", "such", "as", "gradient", "descent", "or", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The model (e.g. a neural network or a naive Bayes classifier) is trained on the training data set using a supervised learning method, e.g. using optimisation methods such as gradient descent or stochastic gradient descent.", "token2charspan": [[0, 3], [4, 9], [10, 11], [11, 15], [16, 17], [18, 24], [25, 32], [33, 35], [36, 37], [38, 43], [44, 49], [50, 60], [60, 61], [62, 64], [65, 72], [73, 75], [76, 79], [80, 88], [89, 93], [94, 97], [98, 103], [104, 105], [106, 116], [117, 125], [126, 132], [132, 133], [134, 138], [139, 144], [145, 157], [158, 165], [166, 170], [171, 173], [174, 182], [183, 190], [191, 193], [194, 204], [205, 213], [214, 221], [221, 222]]}
{"doc_key": "ai-test-9", "ner": [[0, 2, "product"], [8, 9, "task"], [11, 11, "task"], [13, 15, "task"], [17, 18, "task"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 2, "usage", "", true, false], [11, 11, 0, 2, "usage", "", true, false], [13, 15, 0, 2, "usage", "", true, false], [17, 18, 0, 2, "usage", "", true, false], [24, 26, 0, 2, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["FrameNet", "has", "been", "used", "in", "applications", "such", "as", "question", "answering", ",", "paraphrasing", ",", "textual", "linkage", "recognition", "and", "information", "extraction", ",", "either", "directly", "or", "through", "semantic", "role", "labelling", "tools", "."], "sentence-detokenized": "FrameNet has been used in applications such as question answering, paraphrasing, textual linkage recognition and information extraction, either directly or through semantic role labelling tools.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 22], [23, 25], [26, 38], [39, 43], [44, 46], [47, 55], [56, 65], [65, 66], [67, 79], [79, 80], [81, 88], [89, 96], [97, 108], [109, 112], [113, 124], [125, 135], [135, 136], [137, 143], [144, 152], [153, 155], [156, 163], [164, 172], [173, 177], [178, 187], [188, 193], [193, 194]]}
{"doc_key": "ai-test-10", "ner": [[6, 9, "field"], [12, 14, "misc"], [15, 15, "product"], [19, 19, "misc"], [21, 21, "product"], [24, 27, "field"], [28, 28, "product"], [31, 33, "misc"], [36, 36, "product"], [38, 38, "product"], [40, 40, "product"], [43, 46, "misc"], [47, 48, "product"], [50, 51, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[15, 15, 12, 14, "general-affiliation", "", false, false], [21, 21, 19, 19, "general-affiliation", "", false, false], [28, 28, 24, 27, "general-affiliation", "", false, false], [36, 36, 31, 33, "type-of", "", false, false], [38, 38, 31, 33, "type-of", "", false, false], [40, 40, 31, 33, "type-of", "", false, false], [47, 48, 43, 46, "general-affiliation", "", false, false], [50, 51, 43, 46, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["This", "would", "include", "software", "such", "as", "data", "mining", "and", "analysis", "tools", ",", "spreadsheets", "(", "e.g.", "Excel", ")", ",", "databases", "(", "e.g.", "Access", ")", ",", "statistical", "analysis", "(", "e.g.", "SAS", ")", ",", "generalised", "auditing", "software", "(", "e.g.", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "business", "intelligence", "(", "e.g.", "Crystal", "Reports", "and", "Business", "Objects", ")", ",", "etc", "."], "sentence-detokenized": "This would include software such as data mining and analysis tools, spreadsheets (e.g. Excel), databases (e.g. Access), statistical analysis (e.g. SAS), generalised auditing software (e.g. ACL, Arbutus, EAS), business intelligence (e.g. Crystal Reports and Business Objects), etc.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 27], [28, 32], [33, 35], [36, 40], [41, 47], [48, 51], [52, 60], [61, 66], [66, 67], [68, 80], [81, 82], [82, 86], [87, 92], [92, 93], [93, 94], [95, 104], [105, 106], [106, 110], [111, 117], [117, 118], [118, 119], [120, 131], [132, 140], [141, 142], [142, 146], [147, 150], [150, 151], [151, 152], [153, 164], [165, 173], [174, 182], [183, 184], [184, 188], [189, 192], [192, 193], [194, 201], [201, 202], [203, 206], [206, 207], [207, 208], [209, 217], [218, 230], [231, 232], [232, 236], [237, 244], [245, 252], [253, 256], [257, 265], [266, 273], [273, 274], [274, 275], [276, 279], [279, 280]]}
{"doc_key": "ai-test-11", "ner": [[0, 1, "organisation"], [5, 6, "researcher"], [13, 13, "product"], [19, 20, "product"]], "ner_mapping_to_source": [0, 1, 3, 4], "relations": [[0, 1, 5, 6, "origin", "", false, false], [13, 13, 19, 20, "type-of", "", false, false], [19, 20, 5, 6, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["Rethink", "Robotics", "-", "founded", "by", "Rodney", "Brooks", ",", "formerly", "of", "iRobot", "-", "introduced", "Baxter", "in", "September", "2012", "as", "an", "industrial", "robot", "designed", "to", "interact", "safely", "with", "nearby", "human", "workers", ",", "and", "be", "programmable", "to", "perform", "simple", "tasks", "."], "sentence-detokenized": "Rethink Robotics - founded by Rodney Brooks, formerly of iRobot - introduced Baxter in September 2012 as an industrial robot designed to interact safely with nearby human workers, and be programmable to perform simple tasks.", "token2charspan": [[0, 7], [8, 16], [17, 18], [19, 26], [27, 29], [30, 36], [37, 43], [43, 44], [45, 53], [54, 56], [57, 63], [64, 65], [66, 76], [77, 83], [84, 86], [87, 96], [97, 101], [102, 104], [105, 107], [108, 118], [119, 124], [125, 133], [134, 136], [137, 145], [146, 152], [153, 157], [158, 164], [165, 170], [171, 178], [178, 179], [180, 183], [184, 186], [187, 199], [200, 202], [203, 210], [211, 217], [218, 223], [223, 224]]}
{"doc_key": "ai-test-12", "ner": [[1, 2, "field"], [5, 6, "task"], [8, 9, "task"], [11, 14, "task"], [16, 19, "task"], [21, 22, "task"], [24, 25, "task"], [27, 29, "task"], [35, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 6, 1, 2, "part-of", "task_part_of_field", false, false], [8, 9, 1, 2, "part-of", "task_part_of_field", false, false], [11, 14, 1, 2, "part-of", "task_part_of_field", false, false], [16, 19, 1, 2, "part-of", "task_part_of_field", false, false], [21, 22, 1, 2, "part-of", "task_part_of_field", false, false], [24, 25, 1, 2, "part-of", "task_part_of_field", false, false], [27, 29, 1, 2, "part-of", "task_part_of_field", false, false], [35, 37, 1, 2, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Typical", "text", "mining", "tasks", "include", "text", "categorisation", ",", "text", "clustering", ",", "concept", "/", "entity", "extraction", ",", "production", "of", "granular", "taxonomies", ",", "sentiment", "analysis", ",", "document", "summarisation", "and", "entity", "relationship", "modelling", "(", "i.e.", "learning", "relationships", "between", "named", "entity", "recognition", ")", "."], "sentence-detokenized": "Typical text mining tasks include text categorisation, text clustering, concept/entity extraction, production of granular taxonomies, sentiment analysis, document summarisation and entity relationship modelling (i.e. learning relationships between named entity recognition).", "token2charspan": [[0, 7], [8, 12], [13, 19], [20, 25], [26, 33], [34, 38], [39, 53], [53, 54], [55, 59], [60, 70], [70, 71], [72, 79], [79, 80], [80, 86], [87, 97], [97, 98], [99, 109], [110, 112], [113, 121], [122, 132], [132, 133], [134, 143], [144, 152], [152, 153], [154, 162], [163, 176], [177, 180], [181, 187], [188, 200], [201, 210], [211, 212], [212, 216], [217, 225], [226, 239], [240, 247], [248, 253], [254, 260], [261, 272], [272, 273], [273, 274]]}
{"doc_key": "ai-test-13", "ner": [[5, 5, "metrics"], [8, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "stemming", "reduces", "the", "accuracy", ",", "or", "true", "negative", "rate", ",", "in", "these", "systems", "."], "sentence-detokenized": "However, stemming reduces the accuracy, or true negative rate, in these systems.", "token2charspan": [[0, 7], [7, 8], [9, 17], [18, 25], [26, 29], [30, 38], [38, 39], [40, 42], [43, 47], [48, 56], [57, 61], [61, 62], [63, 65], [66, 71], [72, 79], [79, 80]]}
{"doc_key": "ai-test-14", "ner": [[4, 5, "task"], [10, 13, "misc"], [17, 18, "misc"], [27, 27, "product"], [29, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 13, 4, 5, "temporal", "", false, false], [17, 18, 10, 13, "named", "", false, false], [27, 27, 10, 13, "usage", "", false, false], [29, 29, 10, 13, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "special", "case", "of", "keyword", "detection", "is", "the", "detection", "of", "wake", "-", "up", "words", "(", "also", "called", "hot", "word", ")", "used", "by", "personal", "digital", "assistants", "such", "as", "Alexa", "or", "Siri", "to", "wake", "up", "when", "their", "name", "is", "spoken", "."], "sentence-detokenized": "A special case of keyword detection is the detection of wake-up words (also called hot word) used by personal digital assistants such as Alexa or Siri to wake up when their name is spoken.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 17], [18, 25], [26, 35], [36, 38], [39, 42], [43, 52], [53, 55], [56, 60], [60, 61], [61, 63], [64, 69], [70, 71], [71, 75], [76, 82], [83, 86], [87, 91], [91, 92], [93, 97], [98, 100], [101, 109], [110, 117], [118, 128], [129, 133], [134, 136], [137, 142], [143, 145], [146, 150], [151, 153], [154, 158], [159, 161], [162, 166], [167, 172], [173, 177], [178, 180], [181, 187], [187, 188]]}
{"doc_key": "ai-test-15", "ner": [[0, 2, "programlang"], [9, 9, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 0, 2, "part-of", "", false, false], [11, 11, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "is", "an", "open", "source", "programming", "language", "that", "combines", "Prolog", "with", "Java", "."], "sentence-detokenized": "Prova is an open source programming language that combines Prolog with Java.", "token2charspan": [[0, 5], [6, 8], [9, 11], [12, 16], [17, 23], [24, 35], [36, 44], [45, 49], [50, 58], [59, 65], [66, 70], [71, 75], [75, 76]]}
{"doc_key": "ai-test-16", "ner": [[3, 4, "organisation"], [9, 9, "organisation"], [16, 18, "product"], [28, 31, "country"], [34, 34, "organisation"], [44, 44, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 9, 9, "part-of", "", false, false], [3, 4, 9, 9, "role", "sells", false, false], [3, 4, 28, 31, "role", "sells_to", false, false], [34, 34, 44, 44, "opposite", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "1987", ",", "Tocibai", "Machine", ",", "a", "subsidiary", "of", "Toshiba", ",", "was", "accused", "of", "illegally", "selling", "CNC", "milling", "machines", "used", "to", "manufacture", "very", "quiet", "submarine", "propellers", "to", "the", "Soviet", "Union", "in", "violation", "of", "the", "CoCom", "agreement", ",", "an", "international", "embargo", "on", "certain", "countries", "to", "COMECON", "countries", "."], "sentence-detokenized": "In 1987, Tocibai Machine, a subsidiary of Toshiba, was accused of illegally selling CNC milling machines used to manufacture very quiet submarine propellers to the Soviet Union in violation of the CoCom agreement, an international embargo on certain countries to COMECON countries.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 24], [24, 25], [26, 27], [28, 38], [39, 41], [42, 49], [49, 50], [51, 54], [55, 62], [63, 65], [66, 75], [76, 83], [84, 87], [88, 95], [96, 104], [105, 109], [110, 112], [113, 124], [125, 129], [130, 135], [136, 145], [146, 156], [157, 159], [160, 163], [164, 170], [171, 176], [177, 179], [180, 189], [190, 192], [193, 196], [197, 202], [203, 212], [212, 213], [214, 216], [217, 230], [231, 238], [239, 241], [242, 249], [250, 259], [260, 262], [263, 270], [271, 280], [280, 281]]}
{"doc_key": "ai-test-17", "ner": [[0, 0, "researcher"], [7, 10, "product"], [20, 23, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 10, 0, 0, "artifact", "", false, false], [7, 10, 20, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Engelberger", "'s", "most", "famous", "invention", ",", "the", "Unimate", "industrial", "robot", "arm", ",", "was", "one", "of", "the", "first", "inductees", "into", "the", "Robot", "Hall", "of", "Fame", "in", "2003", "."], "sentence-detokenized": "Engelberger's most famous invention, the Unimate industrial robot arm, was one of the first inductees into the Robot Hall of Fame in 2003.", "token2charspan": [[0, 11], [11, 13], [14, 18], [19, 25], [26, 35], [35, 36], [37, 40], [41, 48], [49, 59], [60, 65], [66, 69], [69, 70], [71, 74], [75, 78], [79, 81], [82, 85], [86, 91], [92, 101], [102, 106], [107, 110], [111, 116], [117, 121], [122, 124], [125, 129], [130, 132], [133, 137], [137, 138]]}
{"doc_key": "ai-test-18", "ner": [[4, 5, "misc"], [9, 9, "misc"], [11, 11, "person"], [19, 20, "field"], [16, 18, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 9, 9, "usage", "", false, false], [11, 11, 19, 20, "role", "", false, false], [19, 20, 16, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Although", "initially", "controlled", "by", "static", "html", "web", "pages", "using", "CGI", ",", "Dalton", "'s", "work", "introduced", "a", "Java", "-", "based", "augmented", "reality", "interface", "that", "met", "with", "limited", "success", "."], "sentence-detokenized": "Although initially controlled by static html web pages using CGI, Dalton's work introduced a Java-based augmented reality interface that met with limited success.", "token2charspan": [[0, 8], [9, 18], [19, 29], [30, 32], [33, 39], [40, 44], [45, 48], [49, 54], [55, 60], [61, 64], [64, 65], [66, 72], [72, 74], [75, 79], [80, 90], [91, 92], [93, 97], [97, 98], [98, 103], [104, 113], [114, 121], [122, 131], [132, 136], [137, 140], [141, 145], [146, 153], [154, 161], [161, 162]]}
{"doc_key": "ai-test-19", "ner": [[5, 7, "task"], [10, 10, "organisation"], [29, 29, "conference"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[5, 7, 10, 10, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "publication", "on", "the", "LMF", "specification", "as", "ratified", "by", "ISO", "(", "this", "article", "became", "(", "in", "2015", ")", "the", "ninth", "most", "cited", "article", "within", "the", "LREC", "conferences", "of", "LREC", "articles", ")", ":"], "sentence-detokenized": "The first publication on the LMF specification as ratified by ISO (this article became (in 2015) the ninth most cited article within the LREC conferences of LREC articles):", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 24], [25, 28], [29, 32], [33, 46], [47, 49], [50, 58], [59, 61], [62, 65], [66, 67], [67, 71], [72, 79], [80, 86], [87, 88], [88, 90], [91, 95], [95, 96], [97, 100], [101, 106], [107, 111], [112, 117], [118, 125], [126, 132], [133, 136], [137, 141], [142, 153], [154, 156], [157, 161], [162, 170], [170, 171], [171, 172]]}
{"doc_key": "ai-test-20", "ner": [[1, 2, "metrics"], [15, 17, "metrics"], [18, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 17, 1, 2, "usage", "", false, false], [15, 17, 18, 21, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "confusion", "matrix", "or", "coincidence", "matrix", "is", "often", "used", "as", "a", "tool", "to", "validate", "the", "accuracy", "of", "the", "k", "-", "NN", "classification", "."], "sentence-detokenized": "A confusion matrix or coincidence matrix is often used as a tool to validate the accuracy of the k -NN classification.", "token2charspan": [[0, 1], [2, 11], [12, 18], [19, 21], [22, 33], [34, 40], [41, 43], [44, 49], [50, 54], [55, 57], [58, 59], [60, 64], [65, 67], [68, 76], [77, 80], [81, 89], [90, 92], [93, 96], [97, 98], [99, 100], [100, 102], [103, 117], [117, 118]]}
{"doc_key": "ai-test-21", "ner": [[0, 1, "algorithm"], [12, 12, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 12, "part-of", "", false, false], [0, 1, 14, 15, "part-of", "", false, false], [0, 1, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", "is", "one", "of", "the", "predictive", "modelling", "approaches", "used", "in", "statistics", ",", "data", "mining", "and", "machine", "learning", "."], "sentence-detokenized": "Decision tree learning is one of the predictive modelling approaches used in statistics, data mining and machine learning.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 47], [48, 57], [58, 68], [69, 73], [74, 76], [77, 87], [87, 88], [89, 93], [94, 100], [101, 104], [105, 112], [113, 121], [121, 122]]}
{"doc_key": "ai-test-22", "ner": [[5, 5, "misc"], [18, 22, "field"], [23, 25, "algorithm"], [27, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 18, 22, "related-to", "", true, false], [23, 25, 18, 22, "type-of", "", false, false], [27, 27, 18, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["At", "runtime", ",", "the", "target", "prosody", "of", "a", "sentence", "is", "superimposed", "on", "these", "minimal", "units", "by", "means", "of", "signal", "processing", "techniques", "such", "as", "linear", "predictive", "coding", ",", "PSOLA"], "sentence-detokenized": "At runtime, the target prosody of a sentence is superimposed on these minimal units by means of signal processing techniques such as linear predictive coding, PSOLA", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 22], [23, 30], [31, 33], [34, 35], [36, 44], [45, 47], [48, 60], [61, 63], [64, 69], [70, 77], [78, 83], [84, 86], [87, 92], [93, 95], [96, 102], [103, 113], [114, 124], [125, 129], [130, 132], [133, 139], [140, 150], [151, 157], [157, 158], [159, 164]]}
{"doc_key": "ai-test-23", "ner": [[3, 4, "field"], [6, 9, "field"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 3, 4, "usage", "", true, false], [17, 18, 6, 9, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "approach", "uses", "artificial", "intelligence", "and", "machine", "learning", "to", "allow", "researchers", "to", "visibly", "compare", "conventional", "and", "thermal", "facial", "images", "."], "sentence-detokenized": "This approach uses artificial intelligence and machine learning to allow researchers to visibly compare conventional and thermal facial images.", "token2charspan": [[0, 4], [5, 13], [14, 18], [19, 29], [30, 42], [43, 46], [47, 54], [55, 63], [64, 66], [67, 72], [73, 84], [85, 87], [88, 95], [96, 103], [104, 116], [117, 120], [121, 128], [129, 135], [136, 142], [142, 143]]}
{"doc_key": "ai-test-24", "ner": [[1, 2, "field"], [4, 5, "algorithm"], [12, 13, "task"], [16, 17, "misc"], [23, 24, "field"], [26, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 1, 2, "part-of", "", false, false], [4, 5, 12, 13, "topic", "", false, false], [12, 13, 16, 17, "origin", "", false, false], [23, 24, 1, 2, "part-of", "", false, false], [23, 24, 4, 5, "topic", "", false, false], [26, 27, 1, 2, "part-of", "", false, false], [26, 27, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "computer", "science", ",", "evolutionary", "computation", "is", "a", "family", "of", "algorithms", "for", "global", "optimisation", "inspired", "by", "biological", "evolution", ",", "and", "the", "subfield", "of", "artificial", "intelligence", "and", "soft", "computing", "that", "studies", "these", "algorithms", "."], "sentence-detokenized": "In computer science, evolutionary computation is a family of algorithms for global optimisation inspired by biological evolution, and the subfield of artificial intelligence and soft computing that studies these algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 33], [34, 45], [46, 48], [49, 50], [51, 57], [58, 60], [61, 71], [72, 75], [76, 82], [83, 95], [96, 104], [105, 107], [108, 118], [119, 128], [128, 129], [130, 133], [134, 137], [138, 146], [147, 149], [150, 160], [161, 173], [174, 177], [178, 182], [183, 192], [193, 197], [198, 205], [206, 211], [212, 222], [222, 223]]}
{"doc_key": "ai-test-25", "ner": [[8, 9, "metrics"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "some", "measure", "based", "on", "the", "confusion", "matrix", "can", "be", "combined", "with", "the", "mean", "squared", "error", "evaluated", "between", "the", "raw", "model", "results", "and", "the", "actual", "values", "."], "sentence-detokenized": "For example, some measure based on the confusion matrix can be combined with the mean squared error evaluated between the raw model results and the actual values.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [18, 25], [26, 31], [32, 34], [35, 38], [39, 48], [49, 55], [56, 59], [60, 62], [63, 71], [72, 76], [77, 80], [81, 85], [86, 93], [94, 99], [100, 109], [110, 117], [118, 121], [122, 125], [126, 131], [132, 139], [140, 143], [144, 147], [148, 154], [155, 161], [161, 162]]}
{"doc_key": "ai-test-26", "ner": [[8, 8, "product"], [11, 11, "researcher"], [7, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 11, 11, "origin", "", false, false], [8, 8, 7, 18, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Most", "of", "them", "are", "results", "of", "the", "word2vec", "model", "developed", "by", "Mikolov", "et", "al", ".", "or", "variants", "of", "word2vec", "."], "sentence-detokenized": "Most of them are results of the word2vec model developed by Mikolov et al. or variants of word2vec.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 16], [17, 24], [25, 27], [28, 31], [32, 40], [41, 46], [47, 56], [57, 59], [60, 67], [68, 70], [71, 73], [73, 74], [75, 77], [78, 86], [87, 89], [90, 98], [98, 99]]}
{"doc_key": "ai-test-27", "ner": [[13, 13, "conference"], [16, 20, "conference"], [22, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 22, 16, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["During", "this", "time", ",", "a", "total", "of", "43", "publications", "were", "recognised", "by", "the", "CVPR", "and", "the", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "."], "sentence-detokenized": "During this time, a total of 43 publications were recognised by the CVPR and the International Conference on Computer Vision (ICCV).", "token2charspan": [[0, 6], [7, 11], [12, 16], [16, 17], [18, 19], [20, 25], [26, 28], [29, 31], [32, 44], [45, 49], [50, 60], [61, 63], [64, 67], [68, 72], [73, 76], [77, 80], [81, 94], [95, 105], [106, 108], [109, 117], [118, 124], [125, 126], [126, 130], [130, 131], [131, 132]]}
{"doc_key": "ai-test-28", "ner": [[0, 0, "product"], [10, 11, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 11, "general-affiliation", "platform_for_education_about", false, false], [22, 23, 0, 0, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["AIBO", "has", "been", "widely", "used", "as", "an", "inexpensive", "platform", "for", "artificial", "intelligence", "education", "and", "research", ",", "because", "it", "integrates", "a", "computer", ",", "computer", "vision", "and", "articulators", "in", "a", "much", "cheaper", "package", "than", "conventional", "research", "robots", "."], "sentence-detokenized": "AIBO has been widely used as an inexpensive platform for artificial intelligence education and research, because it integrates a computer, computer vision and articulators in a much cheaper package than conventional research robots.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 20], [21, 25], [26, 28], [29, 31], [32, 43], [44, 52], [53, 56], [57, 67], [68, 80], [81, 90], [91, 94], [95, 103], [103, 104], [105, 112], [113, 115], [116, 126], [127, 128], [129, 137], [137, 138], [139, 147], [148, 154], [155, 158], [159, 171], [172, 174], [175, 176], [177, 181], [182, 189], [190, 197], [198, 202], [203, 215], [216, 224], [225, 231], [231, 232]]}
{"doc_key": "ai-test-29", "ner": [[7, 11, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "has", "been", "programme", "chair", "of", "the", "International", "Computer", "Vision", "Conference", "2021", "."], "sentence-detokenized": "She has been programme chair of the International Computer Vision Conference 2021.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 22], [23, 28], [29, 31], [32, 35], [36, 49], [50, 58], [59, 65], [66, 76], [77, 81], [81, 82]]}
{"doc_key": "ai-test-30", "ner": [[0, 0, "researcher"], [7, 7, "organisation"], [16, 16, "organisation"], [26, 27, "organisation"], [34, 38, "product"], [40, 40, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 7, 7, "role", "", false, false], [0, 0, 16, 16, "role", "", true, false], [16, 16, 26, 27, "role", "develops_with", false, false], [34, 38, 16, 16, "artifact", "", false, false], [40, 40, 34, 38, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Scheinman", ",", "after", "receiving", "a", "grant", "from", "Unimation", "to", "develop", "his", "designs", ",", "sold", "them", "to", "Unimation", ",", "which", "further", "developed", "them", "with", "the", "support", "of", "General", "Motors", "and", "later", "marketed", "them", "as", "the", "Programmable", "Universal", "Machine", "for", "Assembly", "(", "PUMA", ")", "."], "sentence-detokenized": "Scheinman, after receiving a grant from Unimation to develop his designs, sold them to Unimation, which further developed them with the support of General Motors and later marketed them as the Programmable Universal Machine for Assembly (PUMA).", "token2charspan": [[0, 9], [9, 10], [11, 16], [17, 26], [27, 28], [29, 34], [35, 39], [40, 49], [50, 52], [53, 60], [61, 64], [65, 72], [72, 73], [74, 78], [79, 83], [84, 86], [87, 96], [96, 97], [98, 103], [104, 111], [112, 121], [122, 126], [127, 131], [132, 135], [136, 143], [144, 146], [147, 154], [155, 161], [162, 165], [166, 171], [172, 180], [181, 185], [186, 188], [189, 192], [193, 205], [206, 215], [216, 223], [224, 227], [228, 236], [237, 238], [238, 242], [242, 243], [243, 244]]}
{"doc_key": "ai-test-31", "ner": [[11, 11, "task"], [13, 15, "task"], [0, 0, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 11, "general-affiliation", "works_with", false, false], [0, 0, 13, 15, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Gebel", "(", "2009", ")", "provides", "an", "overview", "of", "calibration", "methods", "for", "binary", "and", "multi-class", "classification", "tasks", "."], "sentence-detokenized": "Gebel (2009) provides an overview of calibration methods for binary and multi-class classification tasks.", "token2charspan": [[0, 5], [6, 7], [7, 11], [11, 12], [13, 21], [22, 24], [25, 33], [34, 36], [37, 48], [49, 56], [57, 60], [61, 67], [68, 71], [72, 83], [84, 98], [99, 104], [104, 105]]}
{"doc_key": "ai-test-32", "ner": [[7, 9, "task"], [11, 11, "task"], [14, 15, "task"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "is", "involved", "in", "fields", "such", "as", "optical", "character", "recognition", "(", "OCR", ")", ",", "speech", "synthesis", ",", "speech", "recognition", "technology", "and", "electronic", "keyboard", "instruments", "."], "sentence-detokenized": "It is involved in fields such as optical character recognition (OCR), speech synthesis, speech recognition technology and electronic keyboard instruments.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 24], [25, 29], [30, 32], [33, 40], [41, 50], [51, 62], [63, 64], [64, 67], [67, 68], [68, 69], [70, 76], [77, 86], [86, 87], [88, 94], [95, 106], [107, 117], [118, 121], [122, 132], [133, 141], [142, 153], [153, 154]]}
{"doc_key": "ai-test-33", "ner": [[11, 12, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "the", "latest", "and", "most", "cutting", "-", "edge", "techniques", ",", "the", "Kaldi", "toolkit", "can", "be", "used", "."], "sentence-detokenized": "For the latest and most cutting-edge techniques, the Kaldi toolkit can be used.", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 18], [19, 23], [24, 31], [31, 32], [32, 36], [37, 47], [47, 48], [49, 52], [53, 58], [59, 66], [67, 70], [71, 73], [74, 78], [78, 79]]}
{"doc_key": "ai-test-34", "ner": [[0, 4, "researcher"], [8, 10, "organisation"], [13, 14, "organisation"], [17, 18, "organisation"], [21, 22, "researcher"], [26, 29, "organisation"], [32, 34, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 4, 8, 10, "role", "", false, false], [0, 4, 13, 14, "role", "", false, false], [0, 4, 17, 18, "role", "", false, false], [0, 4, 26, 29, "role", "", false, false], [0, 4, 32, 34, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Johnson", "-", "Laird", "is", "a", "member", "of", "the", "American", "Philosophical", "Society", ",", "the", "Royal", "Society", ",", "the", "British", "Academy", ",", "the", "William", "James", "Fellow", "of", "the", "Association", "for", "Psychological", "Science", "and", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Johnson-Laird is a member of the American Philosophical Society, the Royal Society, the British Academy, the William James Fellow of the Association for Psychological Science and the Cognitive Science Society.", "token2charspan": [[0, 7], [7, 8], [8, 13], [14, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 41], [42, 55], [56, 63], [63, 64], [65, 68], [69, 74], [75, 82], [82, 83], [84, 87], [88, 95], [96, 103], [103, 104], [105, 108], [109, 116], [117, 122], [123, 129], [130, 132], [133, 136], [137, 148], [149, 152], [153, 166], [167, 174], [175, 178], [179, 182], [183, 192], [193, 200], [201, 208], [208, 209]]}
{"doc_key": "ai-test-35", "ner": [[3, 8, "conference"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [20, 21, "algorithm"], [25, 29, "task"], [31, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 11, 3, 8, "physical", "", false, false], [10, 11, 3, 8, "temporal", "", false, false], [13, 14, 3, 8, "physical", "", false, false], [13, 14, 3, 8, "temporal", "", false, false], [16, 17, 3, 8, "physical", "", false, false], [16, 17, 3, 8, "temporal", "", false, false], [20, 21, 16, 17, "role", "extends", false, false], [25, 29, 16, 17, "role", "extends", false, false], [31, 31, 25, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["At", "the", "2010", "IEEE", "International", "Conference", "on", "Image", "Processing", ",", "Rui", "Hu", ",", "Mark", "Banard", "and", "John", "Collomosse", "extended", "the", "HOG", "descriptor", "for", "use", "in", "sketch", "-", "based", "image", "retrieval", "(", "SBIR", ")", "."], "sentence-detokenized": "At the 2010 IEEE International Conference on Image Processing, Rui Hu, Mark Banard and John Collomosse extended the HOG descriptor for use in sketch-based image retrieval (SBIR).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 30], [31, 41], [42, 44], [45, 50], [51, 61], [61, 62], [63, 66], [67, 69], [69, 70], [71, 75], [76, 82], [83, 86], [87, 91], [92, 102], [103, 111], [112, 115], [116, 119], [120, 130], [131, 134], [135, 138], [139, 141], [142, 148], [148, 149], [149, 154], [155, 160], [161, 170], [171, 172], [172, 176], [176, 177], [177, 178]]}
{"doc_key": "ai-test-36", "ner": [[0, 0, "metrics"], [6, 6, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["BLEU", "uses", "a", "modified", "form", "of", "precision", "to", "compare", "a", "candidate", "translation", "with", "multiple", "reference", "translations", "."], "sentence-detokenized": "BLEU uses a modified form of precision to compare a candidate translation with multiple reference translations.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 20], [21, 25], [26, 28], [29, 38], [39, 41], [42, 49], [50, 51], [52, 61], [62, 73], [74, 78], [79, 87], [88, 97], [98, 110], [110, 111]]}
{"doc_key": "ai-test-37", "ner": [[32, 33, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "the", "case", "of", "a", "general", "base", "space", "math", "(", "Y", ",", "mathcal", "{", "B}", ",", "nu", ")", "/", "math", "(", "i.e.", "a", "base", "space", "which", "is", "not", "countable", ")", ",", "the", "relative", "entropy", "is", "usually", "considered", "."], "sentence-detokenized": "For the case of a general base space math(Y,mathcal {B},nu) / math (i.e. a base space which is not countable), the relative entropy is usually considered.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 15], [16, 17], [18, 25], [26, 30], [31, 36], [37, 41], [41, 42], [42, 43], [43, 44], [44, 51], [52, 53], [53, 55], [55, 56], [56, 58], [58, 59], [60, 61], [62, 66], [67, 68], [68, 72], [73, 74], [75, 79], [80, 85], [86, 91], [92, 94], [95, 98], [99, 108], [108, 109], [109, 110], [111, 114], [115, 123], [124, 131], [132, 134], [135, 142], [143, 153], [153, 154]]}
{"doc_key": "ai-test-38", "ner": [[8, 8, "country"], [9, 11, "organisation"], [13, 13, "organisation"], [17, 18, "country"], [19, 20, "organisation"], [22, 22, "organisation"], [26, 28, "organisation"], [30, 30, "country"], [32, 37, "organisation"], [39, 39, "organisation"], [46, 46, "misc"], [47, 47, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[9, 11, 8, 8, "physical", "", false, false], [13, 13, 9, 11, "named", "", false, false], [19, 20, 17, 18, "physical", "", false, false], [22, 22, 19, 20, "named", "", false, false], [32, 37, 30, 30, "physical", "", false, false], [39, 39, 32, 37, "named", "", false, false], [46, 46, 47, 47, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["By", "October", "2011", ",", "existing", "partnerships", "with", "the", "US", "National", "Park", "Service", "(", "NPS", ")", ",", "the", "UK", "'s", "Historic", "Scotland", "(", "HS", ")", ",", "the", "World", "Monuments", "Fund", "and", "Mexico", "'s", "National", "Institute", "of", "Anthropology", "and", "History", "(", "INAH", ")", "had", "expanded", "considerably", ",", ",", "CyArk", "website"], "sentence-detokenized": "By October 2011, existing partnerships with the US National Park Service (NPS), the UK's Historic Scotland (HS), the World Monuments Fund and Mexico's National Institute of Anthropology and History (INAH) had expanded considerably,, CyArk website", "token2charspan": [[0, 2], [3, 10], [11, 15], [15, 16], [17, 25], [26, 38], [39, 43], [44, 47], [48, 50], [51, 59], [60, 64], [65, 72], [73, 74], [74, 77], [77, 78], [78, 79], [80, 83], [84, 86], [86, 88], [89, 97], [98, 106], [107, 108], [108, 110], [110, 111], [111, 112], [113, 116], [117, 122], [123, 132], [133, 137], [138, 141], [142, 148], [148, 150], [151, 159], [160, 169], [170, 172], [173, 185], [186, 189], [190, 197], [198, 199], [199, 203], [203, 204], [205, 208], [209, 217], [218, 230], [230, 231], [231, 232], [233, 238], [239, 246]]}
{"doc_key": "ai-test-39", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [12, 12, "product"], [14, 14, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 12, "part-of", "", false, false], [0, 1, 14, 14, "part-of", "", false, false], [12, 12, 6, 7, "general-affiliation", "", false, false], [14, 14, 6, 7, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kernel", "SVMs", "are", "available", "in", "many", "machine", "learning", "toolkits", ",", "such", "as", "LIBSVM", ",", "MATLAB", "and", "others", "."], "sentence-detokenized": "Kernel SVMs are available in many machine learning toolkits, such as LIBSVM, MATLAB and others.", "token2charspan": [[0, 6], [7, 11], [12, 15], [16, 25], [26, 28], [29, 33], [34, 41], [42, 50], [51, 59], [59, 60], [61, 65], [66, 68], [69, 75], [75, 76], [77, 83], [84, 87], [88, 94], [94, 95]]}
{"doc_key": "ai-test-40", "ner": [[0, 4, "misc"], [13, 14, "location"], [16, 16, "location"], [17, 20, "country"], [24, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 13, 14, "physical", "", false, false], [0, 4, 24, 26, "temporal", "", false, false], [13, 14, 16, 16, "physical", "", false, false], [16, 16, 17, 20, "physical", "", false, false], [24, 26, 13, 14, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "2009", "Loebner", "Prize", "competition", "was", "held", "on", "6", "September", "2009", "at", "the", "Brighton", "Centre", ",", "Brighton", ",", "UK", ",", "in", "conjunction", "with", "the", "Interspeech", "2009", "conference", "."], "sentence-detokenized": "The 2009 Loebner Prize competition was held on 6 September 2009 at the Brighton Centre, Brighton, UK, in conjunction with the Interspeech 2009 conference.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 34], [35, 38], [39, 43], [44, 46], [47, 48], [49, 58], [59, 63], [64, 66], [67, 70], [71, 79], [80, 86], [86, 87], [88, 96], [96, 97], [98, 100], [100, 101], [102, 104], [105, 116], [117, 121], [122, 125], [126, 137], [138, 142], [143, 153], [153, 154]]}
{"doc_key": "ai-test-41", "ner": [[0, 3, "product"], [10, 10, "product"], [16, 18, "product"], [19, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 22, 0, 3, "part-of", "", false, false], [19, 22, 10, 10, "part-of", "", false, false], [19, 22, 16, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "humanoid", "robot", "QRIO", "was", "designed", "as", "a", "successor", "to", "AIBO", ",", "and", "runs", "the", "same", "R", "-", "CODE", "Aperios", "base", "operating", "system", "."], "sentence-detokenized": "The humanoid robot QRIO was designed as a successor to AIBO, and runs the same R-CODE Aperios base operating system.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 23], [24, 27], [28, 36], [37, 39], [40, 41], [42, 51], [52, 54], [55, 59], [59, 60], [61, 64], [65, 69], [70, 73], [74, 78], [79, 80], [80, 81], [81, 85], [86, 93], [94, 98], [99, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-test-42", "ner": [[0, 1, "misc"], [5, 10, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 10, 0, 1, "cause-effect", "", true, false], [11, 12, 0, 1, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Speech", "waveforms", "are", "generated", "from", "the", "HMMs", "themselves", "based", "on", "the", "maximum", "likelihood", "criterion", "."], "sentence-detokenized": "Speech waveforms are generated from the HMMs themselves based on the maximum likelihood criterion.", "token2charspan": [[0, 6], [7, 16], [17, 20], [21, 30], [31, 35], [36, 39], [40, 44], [45, 55], [56, 61], [62, 64], [65, 68], [69, 76], [77, 87], [88, 97], [97, 98]]}
{"doc_key": "ai-test-43", "ner": [[0, 1, "product"], [5, 10, "task"], [8, 8, "task"], [14, 14, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 5, 10, "type-of", "", false, false], [0, 1, 8, 8, "type-of", "", false, false], [0, 1, 14, 14, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "is", "a", "free", "multilingual", "statistical", "and", "neural", "machine", "translation", "service", "developed", "by", "Google", "to", "translate", "texts", "and", "websites", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Google Translate is a free multilingual statistical and neural machine translation service developed by Google to translate texts and websites from one language to another.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 39], [40, 51], [52, 55], [56, 62], [63, 70], [71, 82], [83, 90], [91, 100], [101, 103], [104, 110], [111, 113], [114, 123], [124, 129], [130, 133], [134, 142], [143, 147], [148, 151], [152, 160], [161, 163], [164, 171], [171, 172]]}
{"doc_key": "ai-test-44", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [14, 16, "field"], [21, 23, "task"], [25, 26, "task"], [28, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[21, 23, 5, 6, "part-of", "", false, true], [21, 23, 8, 9, "part-of", "", false, true], [21, 23, 11, 12, "part-of", "", false, true], [25, 26, 5, 6, "part-of", "", false, true], [25, 26, 8, 9, "part-of", "", false, true], [25, 26, 11, 12, "part-of", "", false, true], [28, 31, 5, 6, "part-of", "", false, true], [28, 31, 8, 9, "part-of", "", false, true], [28, 31, 11, 12, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Skeletons", "are", "widely", "used", "in", "computer", "vision", ",", "image", "analysis", ",", "pattern", "recognition", "and", "digital", "image", "processing", "for", "purposes", "such", "as", "optical", "character", "recognition", ",", "fingerprint", "recognition", ",", "visual", "inspection", "or", "compression", "."], "sentence-detokenized": "Skeletons are widely used in computer vision, image analysis, pattern recognition and digital image processing for purposes such as optical character recognition, fingerprint recognition, visual inspection or compression.", "token2charspan": [[0, 9], [10, 13], [14, 20], [21, 25], [26, 28], [29, 37], [38, 44], [44, 45], [46, 51], [52, 60], [60, 61], [62, 69], [70, 81], [82, 85], [86, 93], [94, 99], [100, 110], [111, 114], [115, 123], [124, 128], [129, 131], [132, 139], [140, 149], [150, 161], [161, 162], [163, 174], [175, 186], [186, 187], [188, 194], [195, 205], [206, 208], [209, 220], [220, 221]]}
{"doc_key": "ai-test-45", "ner": [[0, 7, "conference"], [12, 15, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 7, 12, 15, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["ImageNet", "'s", "large", "-", "scale", "visual", "recognition", "challenge", "is", "a", "benchmark", "in", "object", "classification", "and", "detection", ",", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "ImageNet's large-scale visual recognition challenge is a benchmark in object classification and detection, with millions of images and hundreds of object classes.", "token2charspan": [[0, 8], [8, 10], [11, 16], [16, 17], [17, 22], [23, 29], [30, 41], [42, 51], [52, 54], [55, 56], [57, 66], [67, 69], [70, 76], [77, 91], [92, 95], [96, 105], [105, 106], [107, 111], [112, 120], [121, 123], [124, 130], [131, 134], [135, 143], [144, 146], [147, 153], [154, 161], [161, 162]]}
{"doc_key": "ai-test-46", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 11, "researcher"], [16, 18, "misc"], [20, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 16, 18, "part-of", "", false, false], [0, 0, 20, 23, "part-of", "", false, false], [4, 5, 16, 18, "part-of", "", false, false], [4, 5, 20, 23, "part-of", "", false, false], [7, 11, 16, 18, "part-of", "", false, false], [7, 11, 20, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Bengio", ",", "along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "are", "known", "to", "some", "as", "the", "Fathers", "of", "AI", "and", "Godfathers", "of", "Deep", "Learning", "."], "sentence-detokenized": "Bengio, along with Geoffrey Hinton and Yann LeCun, are known to some as the Fathers of AI and Godfathers of Deep Learning.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 18], [19, 27], [28, 34], [35, 38], [39, 43], [44, 49], [49, 50], [51, 54], [55, 60], [61, 63], [64, 68], [69, 71], [72, 75], [76, 83], [84, 86], [87, 89], [90, 93], [94, 104], [105, 107], [108, 112], [113, 121], [121, 122]]}
{"doc_key": "ai-test-47", "ner": [[5, 7, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "life", "member", "of", "the", "IEEE", "."], "sentence-detokenized": "He is a life member of the IEEE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 19], [20, 22], [23, 26], [27, 31], [31, 32]]}
{"doc_key": "ai-test-48", "ner": [[0, 1, "organisation"], [13, 18, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 13, 18, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Bethesda", "NSA", "is", "responsible", "for", "base", "operational", "support", "for", "its", "main", "tenant", ",", "Walter", "Reed", "National", "Military", "Medical", "Center", "."], "sentence-detokenized": "Bethesda NSA is responsible for base operational support for its main tenant, Walter Reed National Military Medical Center.", "token2charspan": [[0, 8], [9, 12], [13, 15], [16, 27], [28, 31], [32, 36], [37, 48], [49, 56], [57, 60], [61, 64], [65, 69], [70, 76], [76, 77], [78, 84], [85, 89], [90, 98], [99, 107], [108, 115], [116, 122], [122, 123]]}
{"doc_key": "ai-test-49", "ner": [[6, 7, "field"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "three", "main", "learning", "paradigms", "are", "supervised", "learning", ",", "unsupervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "The three main learning paradigms are supervised learning, unsupervised learning and reinforcement learning.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 23], [24, 33], [34, 37], [38, 48], [49, 57], [57, 58], [59, 71], [72, 80], [81, 84], [85, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-test-50", "ner": [[2, 2, "task"], [4, 6, "task"], [11, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Examples", "include", "monitoring", ",", "planning", "and", "scheduling", ",", "the", "ability", "to", "answer", "diagnostic", "and", "consumer", "questions", ",", "handwriting", "recognition", ",", "natural", "language", "understanding", ",", "speech", "recognition", "and", "facial", "recognition", "."], "sentence-detokenized": "Examples include monitoring, planning and scheduling, the ability to answer diagnostic and consumer questions, handwriting recognition, natural language understanding, speech recognition and facial recognition.", "token2charspan": [[0, 8], [9, 16], [17, 27], [27, 28], [29, 37], [38, 41], [42, 52], [52, 53], [54, 57], [58, 65], [66, 68], [69, 75], [76, 86], [87, 90], [91, 99], [100, 109], [109, 110], [111, 122], [123, 134], [134, 135], [136, 143], [144, 152], [153, 166], [166, 167], [168, 174], [175, 186], [187, 190], [191, 197], [198, 209], [209, 210]]}
{"doc_key": "ai-test-51", "ner": [[8, 14, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1991", "he", "was", "elected", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "1990", ",", "founding", "member", ")", "."], "sentence-detokenized": "In 1991 he was elected member of the Association for the Advancement of Artificial Intelligence (1990, founding member).", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 22], [23, 29], [30, 32], [33, 36], [37, 48], [49, 52], [53, 56], [57, 68], [69, 71], [72, 82], [83, 95], [96, 97], [97, 101], [101, 102], [103, 111], [112, 118], [118, 119], [119, 120]]}
{"doc_key": "ai-test-52", "ner": [[11, 12, "misc"], [15, 16, "algorithm"], [29, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "by", "formulating", "the", "problem", "as", "the", "solution", "of", "a", "Toeplitz", "matrix", "and", "using", "Levinson", "recursion", ",", "we", "can", "relatively", "quickly", "estimate", "a", "filter", "with", "the", "smallest", "possible", "mean", "square", "error", "."], "sentence-detokenized": "However, by formulating the problem as the solution of a Toeplitz matrix and using Levinson recursion, we can relatively quickly estimate a filter with the smallest possible mean square error.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 23], [24, 27], [28, 35], [36, 38], [39, 42], [43, 51], [52, 54], [55, 56], [57, 65], [66, 72], [73, 76], [77, 82], [83, 91], [92, 101], [101, 102], [103, 105], [106, 109], [110, 120], [121, 128], [129, 137], [138, 139], [140, 146], [147, 151], [152, 155], [156, 164], [165, 173], [174, 178], [179, 185], [186, 191], [191, 192]]}
{"doc_key": "ai-test-53", "ner": [[5, 10, "conference"], [16, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 10, 16, 20, "physical", "", false, false], [16, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2011", ",", "the", "15th", "edition", "of", "Campus", "Party", "Espa\u00f1a", "will", "be", "held", "in", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", "."], "sentence-detokenized": "In July 2011, the 15th edition of Campus Party Espa\u00f1a will be held in the City of Arts and Sciences in Valencia.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 22], [23, 30], [31, 33], [34, 40], [41, 46], [47, 53], [54, 58], [59, 61], [62, 66], [67, 69], [70, 73], [74, 78], [79, 81], [82, 86], [87, 90], [91, 99], [100, 102], [103, 111], [111, 112]]}
{"doc_key": "ai-test-54", "ner": [[14, 14, "product"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Often", ",", "this", "is", "only", "possible", "at", "the", "end", "of", "complicated", "games", "such", "as", "chess", "or", "go", ",", "as", "it", "is", "not", "computationally", "feasible", "to", "look", "ahead", "to", "the", "end", "of", "the", "game", ",", "except", "towards", "the", "end", ",", "and", "instead", ",", "positions", "are", "given", "finite", "values", "as", "estimates", "of", "the", "degree", "of", "belief", "that", "they", "will", "lead", "to", "a", "win", "for", "one", "player", "or", "the", "other", "."], "sentence-detokenized": "Often, this is only possible at the end of complicated games such as chess or go, as it is not computationally feasible to look ahead to the end of the game, except towards the end, and instead, positions are given finite values as estimates of the degree of belief that they will lead to a win for one player or the other.", "token2charspan": [[0, 5], [5, 6], [7, 11], [12, 14], [15, 19], [20, 28], [29, 31], [32, 35], [36, 39], [40, 42], [43, 54], [55, 60], [61, 65], [66, 68], [69, 74], [75, 77], [78, 80], [80, 81], [82, 84], [85, 87], [88, 90], [91, 94], [95, 110], [111, 119], [120, 122], [123, 127], [128, 133], [134, 136], [137, 140], [141, 144], [145, 147], [148, 151], [152, 156], [156, 157], [158, 164], [165, 172], [173, 176], [177, 180], [180, 181], [182, 185], [186, 193], [193, 194], [195, 204], [205, 208], [209, 214], [215, 221], [222, 228], [229, 231], [232, 241], [242, 244], [245, 248], [249, 255], [256, 258], [259, 265], [266, 270], [271, 275], [276, 280], [281, 285], [286, 288], [289, 290], [291, 294], [295, 298], [299, 302], [303, 309], [310, 312], [313, 316], [317, 322], [322, 323]]}
{"doc_key": "ai-test-55", "ner": [[4, 53, "algorithm"], [26, 27, "algorithm"], [29, 30, "algorithm"], [33, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 53, 26, 27, "compare", "", false, false], [4, 53, 29, 30, "compare", "", false, false], [4, 53, 33, 35, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "difference", "between", "the", "multinomial", "logit", "model", "and", "many", "other", "methods", ",", "models", ",", "algorithms", ",", "etc.", "with", "the", "same", "basic", "set", "-", "up", "(", "the", "perceptron", "algorithm", ",", "support", "vector", "machines", ",", "linear", "discriminant", "analysis", ",", "etc.", ")", "is", "that", "the", "multinomial", "logit", "model", "is", "not", "the", "same", "as", "the", "multinomial", "logit", "model", "."], "sentence-detokenized": "The difference between the multinomial logit model and many other methods, models, algorithms, etc. with the same basic set-up (the perceptron algorithm, support vector machines, linear discriminant analysis, etc.) is that the multinomial logit model is not the same as the multinomial logit model.", "token2charspan": [[0, 3], [4, 14], [15, 22], [23, 26], [27, 38], [39, 44], [45, 50], [51, 54], [55, 59], [60, 65], [66, 73], [73, 74], [75, 81], [81, 82], [83, 93], [93, 94], [95, 99], [100, 104], [105, 108], [109, 113], [114, 119], [120, 123], [123, 124], [124, 126], [127, 128], [128, 131], [132, 142], [143, 152], [152, 153], [154, 161], [162, 168], [169, 177], [177, 178], [179, 185], [186, 198], [199, 207], [207, 208], [209, 213], [213, 214], [215, 217], [218, 222], [223, 226], [227, 238], [239, 244], [245, 250], [251, 253], [254, 257], [258, 261], [262, 266], [267, 269], [270, 273], [274, 285], [286, 291], [292, 297], [297, 298]]}
{"doc_key": "ai-test-56", "ner": [[0, 3, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Association", "for", "Computational", "Linguistics", ",", "published", "by"], "sentence-detokenized": "Association for Computational Linguistics, published by", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [41, 42], [43, 52], [53, 55]]}
{"doc_key": "ai-test-57", "ner": [[3, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "computerised", "face", "recognition", "system", ",", "each", "face", "is", "represented", "by", "a", "large", "number", "of", "pixel", "values", "."], "sentence-detokenized": "In the computerised face recognition system, each face is represented by a large number of pixel values.", "token2charspan": [[0, 2], [3, 6], [7, 19], [20, 24], [25, 36], [37, 43], [43, 44], [45, 49], [50, 54], [55, 57], [58, 69], [70, 72], [73, 74], [75, 80], [81, 87], [88, 90], [91, 96], [97, 103], [103, 104]]}
{"doc_key": "ai-test-58", "ner": [[6, 7, "person"], [14, 16, "organisation"], [23, 23, "country"], [26, 26, "person"], [36, 38, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 7, 14, 16, "role", "", false, false], [6, 7, 23, 23, "physical", "", false, false], [26, 26, 36, 38, "origin", "", false, false], [26, 26, 36, 38, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2002", ",", "his", "son", ",", "Daniel", "Pearl", ",", "a", "journalist", "working", "for", "the", "Wall", "Street", "Journal", ",", "was", "kidnapped", "and", "murdered", "in", "Pakistan", ",", "prompting", "Judea", "and", "other", "family", "members", "and", "friends", "to", "create", "the", "Daniel", "Pearl", "Foundation", "."], "sentence-detokenized": "In 2002, his son, Daniel Pearl, a journalist working for the Wall Street Journal, was kidnapped and murdered in Pakistan, prompting Judea and other family members and friends to create the Daniel Pearl Foundation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [16, 17], [18, 24], [25, 30], [30, 31], [32, 33], [34, 44], [45, 52], [53, 56], [57, 60], [61, 65], [66, 72], [73, 80], [80, 81], [82, 85], [86, 95], [96, 99], [100, 108], [109, 111], [112, 120], [120, 121], [122, 131], [132, 137], [138, 141], [142, 147], [148, 154], [155, 162], [163, 166], [167, 174], [175, 177], [178, 184], [185, 188], [189, 195], [196, 201], [202, 212], [212, 213]]}
{"doc_key": "ai-test-59", "ner": [[4, 6, "organisation"], [17, 18, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 17, 18, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "late", "2006", ",", "Red", "Envelope", "Entertainment", "also", "expanded", "into", "original", "content", "production", "with", "filmmakers", "such", "as", "John", "Waters", "."], "sentence-detokenized": "In late 2006, Red Envelope Entertainment also expanded into original content production with filmmakers such as John Waters.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 26], [27, 40], [41, 45], [46, 54], [55, 59], [60, 68], [69, 76], [77, 87], [88, 92], [93, 103], [104, 108], [109, 111], [112, 116], [117, 123], [123, 124]]}
{"doc_key": "ai-test-60", "ner": [[6, 10, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "building", "is", "now", "part", "of", "Beth", "Israel", "Deaconess", "Medical", "Center", "."], "sentence-detokenized": "The building is now part of Beth Israel Deaconess Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 32], [33, 39], [40, 49], [50, 57], [58, 64], [64, 65]]}
{"doc_key": "ai-test-61", "ner": [[18, 19, "field"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "common", "theme", "of", "this", "work", "is", "the", "adoption", "of", "a", "sign", "-", "theoretic", "perspective", "on", "issues", "of", "artificial", "intelligence", "and", "knowledge", "representation", "."], "sentence-detokenized": "A common theme of this work is the adoption of a sign-theoretic perspective on issues of artificial intelligence and knowledge representation.", "token2charspan": [[0, 1], [2, 8], [9, 14], [15, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 43], [44, 46], [47, 48], [49, 53], [53, 54], [54, 63], [64, 75], [76, 78], [79, 85], [86, 88], [89, 99], [100, 112], [113, 116], [117, 126], [127, 141], [141, 142]]}
{"doc_key": "ai-test-62", "ner": [[5, 7, "task"], [9, 9, "task"], [19, 20, "task"], [39, 40, "task"], [42, 43, "task"], [48, 50, "task"], [52, 52, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 7, 19, 20, "type-of", "", false, false], [5, 7, 48, 50, "compare", "", false, false], [5, 7, 48, 50, "opposite", "", false, false], [9, 9, 5, 7, "named", "", false, false], [39, 40, 48, 50, "part-of", "", false, false], [42, 43, 48, 50, "part-of", "", false, false], [48, 50, 19, 20, "type-of", "", false, false], [52, 52, 48, 50, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["For", "example", ",", "the", "term", "neural", "machine", "translation", "(", "NMT", ")", "emphasises", "the", "fact", "that", "deep", "learning", "-", "based", "machine", "translation", "approaches", "learn", "sequence", "-", "to", "-", "sequence", "transformations", "directly", ",", "obviating", "the", "need", "for", "intermediate", "steps", "such", "as", "word", "alignment", "and", "language", "modelling", "that", "were", "used", "in", "statistical", "machine", "translation", "(", "SMT", ")", "."], "sentence-detokenized": "For example, the term neural machine translation (NMT) emphasises the fact that deep learning-based machine translation approaches learn sequence-to-sequence transformations directly, obviating the need for intermediate steps such as word alignment and language modelling that were used in statistical machine translation (SMT).", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 36], [37, 48], [49, 50], [50, 53], [53, 54], [55, 65], [66, 69], [70, 74], [75, 79], [80, 84], [85, 93], [93, 94], [94, 99], [100, 107], [108, 119], [120, 130], [131, 136], [137, 145], [145, 146], [146, 148], [148, 149], [149, 157], [158, 173], [174, 182], [182, 183], [184, 193], [194, 197], [198, 202], [203, 206], [207, 219], [220, 225], [226, 230], [231, 233], [234, 238], [239, 248], [249, 252], [253, 261], [262, 271], [272, 276], [277, 281], [282, 286], [287, 289], [290, 301], [302, 309], [310, 321], [322, 323], [323, 326], [326, 327], [327, 328]]}
{"doc_key": "ai-test-63", "ner": [[8, 8, "field"], [13, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 8, 13, 14, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Most", "of", "the", "research", "in", "the", "field", "of", "WSD", "is", "carried", "out", "using", "Word", "Net", "as", "a", "reference", "sense", "inventory", "for", "."], "sentence-detokenized": "Most of the research in the field of WSD is carried out using WordNet as a reference sense inventory for.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 20], [21, 23], [24, 27], [28, 33], [34, 36], [37, 40], [41, 43], [44, 51], [52, 55], [56, 61], [62, 66], [66, 69], [70, 72], [73, 74], [75, 84], [85, 90], [91, 100], [101, 104], [104, 105]]}
{"doc_key": "ai-test-64", "ner": [[1, 1, "misc"], [10, 11, "researcher"], [13, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 1, 1, "general-affiliation", "", false, true], [13, 14, 1, 1, "general-affiliation", "", false, true]], "relations_mapping_to_source": [0, 1], "sentence": ["Former", "PhD", "students", "and", "postdoctoral", "researchers", "in", "his", "group", "include", "Richard", "Zemel", "and", "Zoubin", "Ghahramani", "."], "sentence-detokenized": "Former PhD students and postdoctoral researchers in his group include Richard Zemel and Zoubin Ghahramani.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 23], [24, 36], [37, 48], [49, 51], [52, 55], [56, 61], [62, 69], [70, 77], [78, 83], [84, 87], [88, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-test-65", "ner": [[7, 8, "metrics"], [14, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 14, 14, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Each", "prediction", "result", "or", "instance", "of", "a", "confusion", "matrix", "represents", "a", "point", "in", "the", "ROC", "space", "."], "sentence-detokenized": "Each prediction result or instance of a confusion matrix represents a point in the ROC space.", "token2charspan": [[0, 4], [5, 15], [16, 22], [23, 25], [26, 34], [35, 37], [38, 39], [40, 49], [50, 56], [57, 67], [68, 69], [70, 75], [76, 78], [79, 82], [83, 86], [87, 92], [92, 93]]}
{"doc_key": "ai-test-66", "ner": [[2, 2, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [16, 18, "product"], [21, 23, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 21, 23, "physical", "", false, false], [6, 7, 21, 23, "physical", "", false, false], [9, 10, 21, 23, "physical", "", false, false], [16, 18, 2, 2, "artifact", "", false, false], [16, 18, 6, 7, "artifact", "", false, false], [16, 18, 9, 10, "artifact", "", false, false], [16, 18, 21, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "1997", "Thrun", "and", "his", "colleagues", "Wolfram", "Burgard", "and", "Dieter", "Fox", "developed", "the", "world", "'s", "first", "robotic", "tour", "guide", "at", "the", "Deutsches", "Museum", "Bonn", "(", "1997", ")", "."], "sentence-detokenized": "In 1997 Thrun and his colleagues Wolfram Burgard and Dieter Fox developed the world's first robotic tour guide at the Deutsches Museum Bonn (1997).", "token2charspan": [[0, 2], [3, 7], [8, 13], [14, 17], [18, 21], [22, 32], [33, 40], [41, 48], [49, 52], [53, 59], [60, 63], [64, 73], [74, 77], [78, 83], [83, 85], [86, 91], [92, 99], [100, 104], [105, 110], [111, 113], [114, 117], [118, 127], [128, 134], [135, 139], [140, 141], [141, 145], [145, 146], [146, 147]]}
{"doc_key": "ai-test-67", "ner": [[0, 1, "product"], [7, 7, "misc"], [24, 26, "field"], [28, 29, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 0, 1, "part-of", "", false, false], [24, 26, 0, 1, "usage", "", false, false], [28, 29, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Word", "Net", "is", "a", "lexical", "database", "of", "semantic", "relations", "between", "words", "in", "more", "than", "200", "languages", ".", "It", "s", "main", "use", "is", "in", "automatic", "natural", "language", "processing", "and", "artificial", "intelligence", "applications", "."], "sentence-detokenized": "WordNet is a lexical database of semantic relations between words in more than 200 languages. Its main use is in automatic natural language processing and artificial intelligence applications.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 32], [33, 41], [42, 51], [52, 59], [60, 65], [66, 68], [69, 73], [74, 78], [79, 82], [83, 92], [92, 93], [94, 96], [96, 97], [98, 102], [103, 106], [107, 109], [110, 112], [113, 122], [123, 130], [131, 139], [140, 150], [151, 154], [155, 165], [166, 178], [179, 191], [191, 192]]}
{"doc_key": "ai-test-68", "ner": [[5, 7, "field"], [11, 15, "conference"], [18, 26, "conference"], [28, 29, "conference"], [32, 32, "conference"], [40, 41, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 15, 5, 7, "topic", "", false, false], [11, 15, 40, 41, "topic", "", false, false], [18, 26, 5, 7, "topic", "", false, false], [18, 26, 40, 41, "topic", "", false, false], [28, 29, 5, 7, "topic", "", false, false], [28, 29, 40, 41, "topic", "", false, false], [32, 32, 5, 7, "topic", "", false, false], [32, 32, 40, 41, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Conferences", "in", "the", "field", "of", "natural", "language", "processing", ",", "such", "as", "the", "Association", "for", "Computational", "Linguistics", ",", "the", "North", "American", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "the", "EMNLP", "and", "the", "HLT", ",", "are", "beginning", "to", "include", "papers", "on", "speech", "processing", "."], "sentence-detokenized": "Conferences in the field of natural language processing, such as the Association for Computational Linguistics, the North American Chapter of the Association for Computational Linguistics, the EMNLP and the HLT, are beginning to include papers on speech processing.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 24], [25, 27], [28, 35], [36, 44], [45, 55], [55, 56], [57, 61], [62, 64], [65, 68], [69, 80], [81, 84], [85, 98], [99, 110], [110, 111], [112, 115], [116, 121], [122, 130], [131, 138], [139, 141], [142, 145], [146, 157], [158, 161], [162, 175], [176, 187], [187, 188], [189, 192], [193, 198], [199, 202], [203, 206], [207, 210], [210, 211], [212, 215], [216, 225], [226, 228], [229, 236], [237, 243], [244, 246], [247, 253], [254, 264], [264, 265]]}
{"doc_key": "ai-test-69", "ner": [[3, 3, "programlang"], [20, 22, "misc"], [34, 36, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "set", "of", "Java", "programs", "uses", "the", "lexicon", "to", "work", "through", "variations", "of", "biomedical", "texts", "by", "linking", "words", "by", "their", "parts", "of", "speech", ",", "which", "can", "be", "useful", "in", "web", "searches", "or", "in", "an", "electronic", "medical", "record", "."], "sentence-detokenized": "A set of Java programs uses the lexicon to work through variations of biomedical texts by linking words by their parts of speech, which can be useful in web searches or in an electronic medical record.", "token2charspan": [[0, 1], [2, 5], [6, 8], [9, 13], [14, 22], [23, 27], [28, 31], [32, 39], [40, 42], [43, 47], [48, 55], [56, 66], [67, 69], [70, 80], [81, 86], [87, 89], [90, 97], [98, 103], [104, 106], [107, 112], [113, 118], [119, 121], [122, 128], [128, 129], [130, 135], [136, 139], [140, 142], [143, 149], [150, 152], [153, 156], [157, 165], [166, 168], [169, 171], [172, 174], [175, 185], [186, 193], [194, 200], [200, 201]]}
{"doc_key": "ai-test-70", "ner": [[8, 8, "algorithm"], [10, 10, "algorithm"], [12, 12, "algorithm"], [14, 14, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "many", "newer", "algorithms", ",", "such", "as", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", ",", "and", "others", "."], "sentence-detokenized": "There are many newer algorithms, such as LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost, and others.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 20], [21, 31], [31, 32], [33, 37], [38, 40], [41, 48], [48, 49], [50, 60], [60, 61], [62, 72], [72, 73], [74, 81], [81, 82], [83, 92], [92, 93], [94, 97], [98, 104], [104, 105]]}
{"doc_key": "ai-test-71", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "implementation", "in", "Python", ":"], "sentence-detokenized": "This is an example implementation in Python:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 33], [34, 36], [37, 43], [43, 44]]}
{"doc_key": "ai-test-72", "ner": [[1, 1, "organisation"], [2, 2, "product"], [8, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 1, 1, "artifact", "made_by_company", false, false], [8, 10, 2, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Mattel", "Intellivision", "video", "game", "console", "offered", "the", "Intellivoice", "speech", "synthesis", "module", "in", "1982", "."], "sentence-detokenized": "The Mattel Intellivision video game console offered the Intellivoice speech synthesis module in 1982.", "token2charspan": [[0, 3], [4, 10], [11, 24], [25, 30], [31, 35], [36, 43], [44, 51], [52, 55], [56, 68], [69, 75], [76, 85], [86, 92], [93, 95], [96, 100], [100, 101]]}
{"doc_key": "ai-test-73", "ner": [[5, 6, "task"], [10, 17, "task"], [20, 21, "field"], [23, 25, "task"], [29, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 17, 5, 6, "part-of", "", false, false], [20, 21, 5, 6, "part-of", "", false, false], [23, 25, 5, 6, "part-of", "", false, false], [29, 34, 23, 25, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "has", "also", "worked", "in", "machine", "translation", ",", "both", "in", "high", "-", "precision", "knowledge", "-", "based", "machine", "translation", "and", "in", "machine", "learning", "for", "statistical", "machine", "translation", "(", "such", "as", "generalised", "example", "-", "based", "machine", "translation", ")", "."], "sentence-detokenized": "He has also worked in machine translation, both in high-precision knowledge-based machine translation and in machine learning for statistical machine translation (such as generalised example-based machine translation).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 21], [22, 29], [30, 41], [41, 42], [43, 47], [48, 50], [51, 55], [55, 56], [56, 65], [66, 75], [75, 76], [76, 81], [82, 89], [90, 101], [102, 105], [106, 108], [109, 116], [117, 125], [126, 129], [130, 141], [142, 149], [150, 161], [162, 163], [163, 167], [168, 170], [171, 182], [183, 190], [190, 191], [191, 196], [197, 204], [205, 216], [216, 217], [217, 218]]}
{"doc_key": "ai-test-74", "ner": [[0, 1, "misc"], [5, 5, "misc"], [19, 20, "algorithm"], [22, 23, "field"], [25, 26, "field"], [28, 28, "field"], [30, 31, "field"], [33, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 19, 20, "general-affiliation", "", false, false], [0, 1, 22, 23, "general-affiliation", "", false, false], [0, 1, 25, 26, "general-affiliation", "", false, false], [0, 1, 28, 28, "general-affiliation", "", false, false], [0, 1, 30, 31, "general-affiliation", "", false, false], [0, 1, 33, 33, "general-affiliation", "", false, false], [5, 5, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "usually", "called", "Mathematica", ")", "is", "a", "modern", "technical", "computing", "system", "that", "spans", "most", "technical", "areas", "-including", "neural", "networks", ",", "machine", "learning", ",", "image", "processing", ",", "geometry", ",", "data", "science", ",", "visualizations", ",", "and", "others", "."], "sentence-detokenized": "Wolfram Mathematica (usually called Mathematica) is a modern technical computing system that spans most technical areas-including neural networks, machine learning, image processing, geometry, data science, visualizations, and others.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 28], [29, 35], [36, 47], [47, 48], [49, 51], [52, 53], [54, 60], [61, 70], [71, 80], [81, 87], [88, 92], [93, 98], [99, 103], [104, 113], [114, 119], [119, 129], [130, 136], [137, 145], [145, 146], [147, 154], [155, 163], [163, 164], [165, 170], [171, 181], [181, 182], [183, 191], [191, 192], [193, 197], [198, 205], [205, 206], [207, 221], [221, 222], [223, 226], [227, 233], [233, 234]]}
{"doc_key": "ai-test-75", "ner": [[2, 6, "product"], [10, 11, "researcher"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 18, 2, 6, "type-of", "", false, false], [18, 18, 10, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "digitally", "operated", ",", "programmable", "robot", "was", "invented", "by", "George", "Devol", "in", "1954", "and", "was", "eventually", "named", "Unimate", "."], "sentence-detokenized": "The first digitally operated, programmable robot was invented by George Devol in 1954 and was eventually named Unimate.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 28], [28, 29], [30, 42], [43, 48], [49, 52], [53, 61], [62, 64], [65, 71], [72, 77], [78, 80], [81, 85], [86, 89], [90, 93], [94, 104], [105, 110], [111, 118], [118, 119]]}
{"doc_key": "ai-test-76", "ner": [[1, 1, "algorithm"], [3, 3, "algorithm"], [17, 18, "task"], [20, 21, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 3, 3, "compare", "", false, false], [3, 3, 17, 18, "general-affiliation", "", false, false], [3, 3, 20, 21, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Like", "DBNs", ",", "DBMs", "can", "learn", "complex", "and", "abstract", "internal", "representations", "of", "input", "in", "tasks", "such", "as", "object", "recognition", "or", "speech", "recognition", ",", "using", "limited", ",", "labelled", "data", "to", "refine", "representations", "constructed", "from", "a", "large", "set", "of", "unlabelled", "sensory", "input", "data", "."], "sentence-detokenized": "Like DBNs, DBMs can learn complex and abstract internal representations of input in tasks such as object recognition or speech recognition, using limited, labelled data to refine representations constructed from a large set of unlabelled sensory input data.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 15], [16, 19], [20, 25], [26, 33], [34, 37], [38, 46], [47, 55], [56, 71], [72, 74], [75, 80], [81, 83], [84, 89], [90, 94], [95, 97], [98, 104], [105, 116], [117, 119], [120, 126], [127, 138], [138, 139], [140, 145], [146, 153], [153, 154], [155, 163], [164, 168], [169, 171], [172, 178], [179, 194], [195, 206], [207, 211], [212, 213], [214, 219], [220, 223], [224, 226], [227, 237], [238, 245], [246, 251], [252, 256], [256, 257]]}
{"doc_key": "ai-test-77", "ner": [[4, 8, "task"], [13, 13, "conference"], [15, 15, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 13, 4, 8, "topic", "", false, false], [15, 15, 4, 8, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "scientific", "conferences", "where", "vision", "-", "based", "activity", "recognition", "papers", "usually", "appear", "are", "ICCV", "and", "CVPR", "."], "sentence-detokenized": "The scientific conferences where vision-based activity recognition papers usually appear are ICCV and CVPR.", "token2charspan": [[0, 3], [4, 14], [15, 26], [27, 32], [33, 39], [39, 40], [40, 45], [46, 54], [55, 66], [67, 73], [74, 81], [82, 88], [89, 92], [93, 97], [98, 101], [102, 106], [106, 107]]}
{"doc_key": "ai-test-78", "ner": [[1, 1, "field"], [4, 5, "algorithm"], [7, 7, "algorithm"], [16, 17, "metrics"], [19, 21, "metrics"], [23, 23, "metrics"], [38, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 5, 1, 1, "part-of", "", false, false], [4, 5, 16, 17, "related-to", "finds", false, false], [4, 5, 19, 21, "related-to", "finds", false, false], [4, 5, 38, 38, "related-to", "", false, false], [7, 7, 4, 5, "named", "", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "statistics", ",", "an", "expectation", "maximisation", "(", "EM", ")", "algorithm", "is", "an", "iterative", "method", "for", "finding", "maximum", "likelihood", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "estimates", "of", "parameters", "in", "statistical", "models", ",", "where", "the", "model", "depends", "on", "unobserved", "latent", "variables", "."], "sentence-detokenized": "In statistics, an expectation maximisation (EM) algorithm is an iterative method for finding maximum likelihood or maximum a posteriori (MAP) estimates of parameters in statistical models, where the model depends on unobserved latent variables.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 17], [18, 29], [30, 42], [43, 44], [44, 46], [46, 47], [48, 57], [58, 60], [61, 63], [64, 73], [74, 80], [81, 84], [85, 92], [93, 100], [101, 111], [112, 114], [115, 122], [123, 124], [125, 135], [136, 137], [137, 140], [140, 141], [142, 151], [152, 154], [155, 165], [166, 168], [169, 180], [181, 187], [187, 188], [189, 194], [195, 198], [199, 204], [205, 212], [213, 215], [216, 226], [227, 233], [234, 243], [243, 244]]}
{"doc_key": "ai-test-79", "ner": [[7, 7, "metrics"], [10, 13, "metrics"], [16, 18, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 13, 7, 7, "named", "", false, false], [20, 20, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Similarly", ",", "researchers", "sometimes", "report", "the", "false", "positive", "rate", "(", "FPR", ")", "as", "well", "as", "the", "false", "negative", "rate", "(", "FNR", ")", "."], "sentence-detokenized": "Similarly, researchers sometimes report the false positive rate (FPR) as well as the false negative rate (FNR).", "token2charspan": [[0, 9], [9, 10], [11, 22], [23, 32], [33, 39], [40, 43], [44, 49], [50, 58], [59, 63], [64, 65], [65, 68], [68, 69], [70, 72], [73, 77], [78, 80], [81, 84], [85, 90], [91, 99], [100, 104], [105, 106], [106, 109], [109, 110], [110, 111]]}
{"doc_key": "ai-test-80", "ner": [[6, 11, "metrics"], [14, 14, "field"], [17, 18, "metrics"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 14, 6, 11, "usage", "", false, false], [21, 22, 17, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "concept", "is", "similar", "to", "the", "signal", "-", "to", "-", "noise", "ratio", "used", "in", "science", "and", "the", "confusion", "matrix", "used", "in", "artificial", "intelligence", "."], "sentence-detokenized": "The concept is similar to the signal-to-noise ratio used in science and the confusion matrix used in artificial intelligence.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 25], [26, 29], [30, 36], [36, 37], [37, 39], [39, 40], [40, 45], [46, 51], [52, 56], [57, 59], [60, 67], [68, 71], [72, 75], [76, 85], [86, 92], [93, 97], [98, 100], [101, 111], [112, 124], [124, 125]]}
{"doc_key": "ai-test-81", "ner": [[5, 6, "field"], [13, 14, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [33, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 13, 14, "general-affiliation", "", false, false], [5, 6, 20, 21, "general-affiliation", "", false, false], [5, 6, 23, 24, "general-affiliation", "", false, false], [33, 37, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Code", "of", "Ethics", "on", "Human", "Augmentation", ",", "which", "was", "originally", "presented", "by", "Steve", "Mann", "in", "2004", "and", "refined", "with", "Ray", "Kurzweil", "and", "Marvin", "Minsky", "in", "2013", ",", "was", "finally", "ratified", "at", "the", "Virtual", "Reality", "conference", "in", "Toronto", "on", "25", "June", "2017", "."], "sentence-detokenized": "The Code of Ethics on Human Augmentation, which was originally presented by Steve Mann in 2004 and refined with Ray Kurzweil and Marvin Minsky in 2013, was finally ratified at the Virtual Reality conference in Toronto on 25 June 2017.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 18], [19, 21], [22, 27], [28, 40], [40, 41], [42, 47], [48, 51], [52, 62], [63, 72], [73, 75], [76, 81], [82, 86], [87, 89], [90, 94], [95, 98], [99, 106], [107, 111], [112, 115], [116, 124], [125, 128], [129, 135], [136, 142], [143, 145], [146, 150], [150, 151], [152, 155], [156, 163], [164, 172], [173, 175], [176, 179], [180, 187], [188, 195], [196, 206], [207, 209], [210, 217], [218, 220], [221, 223], [224, 228], [229, 233], [233, 234]]}
{"doc_key": "ai-test-82", "ner": [[3, 5, "person"], [11, 12, "organisation"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 11, 12, "role", "directed_for", false, false], [3, 5, 18, 19, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1913", ",", "Walter", "R.", "Booth", "directed", "10", "films", "for", "the", "UK", "Kinoplastikon", ",", "presumably", "in", "collaboration", "with", "Cecil", "Hepworth", "."], "sentence-detokenized": "In 1913, Walter R. Booth directed 10 films for the UK Kinoplastikon, presumably in collaboration with Cecil Hepworth.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 18], [19, 24], [25, 33], [34, 36], [37, 42], [43, 46], [47, 50], [51, 53], [54, 67], [67, 68], [69, 79], [80, 82], [83, 96], [97, 101], [102, 107], [108, 116], [116, 117]]}
{"doc_key": "ai-test-83", "ner": [[16, 16, "location"], [13, 14, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 16, 16, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "unveiled", "their", "new", "robot", "in", "1961", "at", "a", "trade", "show", "at", "the", "Cow", "Palace", "in", "Chicago", "."], "sentence-detokenized": "They unveiled their new robot in 1961 at a trade show at the Cow Palace in Chicago.", "token2charspan": [[0, 4], [5, 13], [14, 19], [20, 23], [24, 29], [30, 32], [33, 37], [38, 40], [41, 42], [43, 48], [49, 53], [54, 56], [57, 60], [61, 64], [65, 71], [72, 74], [75, 82], [82, 83]]}
{"doc_key": "ai-test-84", "ner": [[2, 2, "product"], [6, 7, "task"], [10, 11, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 6, 7, "usage", "", false, false], [2, 2, 10, 11, "usage", "", false, false], [2, 2, 15, 16, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["While", "some", "chatbot", "applications", "use", "extensive", "word", "classification", "processes", ",", "natural", "language", "processors", "and", "sophisticated", "artificial", "intelligence", ",", "others", "simply", "search", "for", "general", "keywords", "and", "generate", "responses", "using", "common", "phrases", "obtained", "from", "an", "associated", "library", "or", "database", "."], "sentence-detokenized": "While some chatbot applications use extensive word classification processes, natural language processors and sophisticated artificial intelligence, others simply search for general keywords and generate responses using common phrases obtained from an associated library or database.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 31], [32, 35], [36, 45], [46, 50], [51, 65], [66, 75], [75, 76], [77, 84], [85, 93], [94, 104], [105, 108], [109, 122], [123, 133], [134, 146], [146, 147], [148, 154], [155, 161], [162, 168], [169, 172], [173, 180], [181, 189], [190, 193], [194, 202], [203, 212], [213, 218], [219, 225], [226, 233], [234, 242], [243, 247], [248, 250], [251, 261], [262, 269], [270, 272], [273, 281], [281, 282]]}
{"doc_key": "ai-test-85", "ner": [[1, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "WaveNet", "model", "proposed", "in", "2016", "achieves", "high", "speech", "quality", "performance", "."], "sentence-detokenized": "The WaveNet model proposed in 2016 achieves high speech quality performance.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 43], [44, 48], [49, 55], [56, 63], [64, 75], [75, 76]]}
{"doc_key": "ai-test-86", "ner": [[4, 4, "product"], [6, 7, "misc"], [9, 10, "misc"], [12, 13, "misc"], [15, 18, "misc"], [20, 22, "organisation"], [24, 24, "organisation"], [26, 29, "organisation"], [31, 31, "organisation"], [33, 36, "organisation"], [38, 39, "organisation"], [41, 41, "organisation"], [43, 45, "organisation"], [48, 48, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 4, 6, 7, "general-affiliation", "", false, false], [4, 4, 9, 10, "general-affiliation", "", false, false], [4, 4, 12, 13, "general-affiliation", "", false, false], [4, 4, 15, 18, "general-affiliation", "", false, false], [20, 22, 4, 4, "usage", "", false, false], [24, 24, 4, 4, "usage", "", false, false], [26, 29, 4, 4, "usage", "", false, false], [31, 31, 4, 4, "usage", "", false, false], [33, 36, 4, 4, "usage", "", false, false], [38, 39, 4, 4, "usage", "", false, false], [41, 41, 4, 4, "usage", "", false, false], [43, 45, 4, 4, "usage", "", false, false], [48, 48, 4, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organisations", "known", "to", "use", "ALE", "for", "emergency", "management", ",", "disaster", "relief", ",", "routine", "communication", "or", "response", "in", "extraordinary", "situations", ":", "American", "Red", "Cross", ",", "FEMA", ",", "Disaster", "Medical", "Assistance", "Teams", ",", "NATO", ",", "Federal", "Bureau", "of", "Investigation", ",", "United", "Nations", ",", "AT&T", ",", "Civil", "Air", "Patrol", ",", "(", "ARES", ")", "."], "sentence-detokenized": "Organisations known to use ALE for emergency management, disaster relief, routine communication or response in extraordinary situations: American Red Cross, FEMA, Disaster Medical Assistance Teams, NATO, Federal Bureau of Investigation, United Nations, AT&T, Civil Air Patrol, (ARES).", "token2charspan": [[0, 13], [14, 19], [20, 22], [23, 26], [27, 30], [31, 34], [35, 44], [45, 55], [55, 56], [57, 65], [66, 72], [72, 73], [74, 81], [82, 95], [96, 98], [99, 107], [108, 110], [111, 124], [125, 135], [135, 136], [137, 145], [146, 149], [150, 155], [155, 156], [157, 161], [161, 162], [163, 171], [172, 179], [180, 190], [191, 196], [196, 197], [198, 202], [202, 203], [204, 211], [212, 218], [219, 221], [222, 235], [235, 236], [237, 243], [244, 251], [251, 252], [253, 257], [257, 258], [259, 264], [265, 268], [269, 275], [275, 276], [277, 278], [278, 282], [282, 283], [283, 284]]}
{"doc_key": "ai-test-87", "ner": [[5, 6, "algorithm"], [17, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "this", "case", ",", "the", "Kronecker", "delta", "is", "used", "for", "simplicity", "(", "see", "the", "derivative", "of", "a", "sigmoid", "function", ",", "which", "is", "expressed", "by", "the", "function", "itself", ")", "."], "sentence-detokenized": "In this case, the Kronecker delta is used for simplicity (see the derivative of a sigmoid function, which is expressed by the function itself).", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 27], [28, 33], [34, 36], [37, 41], [42, 45], [46, 56], [57, 58], [58, 61], [62, 65], [66, 76], [77, 79], [80, 81], [82, 89], [90, 98], [98, 99], [100, 105], [106, 108], [109, 118], [119, 121], [122, 125], [126, 134], [135, 141], [141, 142], [142, 143]]}
{"doc_key": "ai-test-88", "ner": [[12, 13, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "theory", "is", "based", "on", "philosophical", "foundations", ",", "and", "was", "founded", "by", "Ray", "Solomonoff", "around", "1960", ".", "Samuel", "Rathmanner", "and", "Marcus", "Hutter", "."], "sentence-detokenized": "The theory is based on philosophical foundations, and was founded by Ray Solomonoff around 1960. Samuel Rathmanner and Marcus Hutter.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 36], [37, 48], [48, 49], [50, 53], [54, 57], [58, 65], [66, 68], [69, 72], [73, 83], [84, 90], [91, 95], [95, 96], [97, 103], [104, 114], [115, 118], [119, 125], [126, 132], [132, 133]]}
{"doc_key": "ai-test-89", "ner": [[0, 0, "product"], [9, 10, "misc"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 9, 10, "type-of", "", false, false], [0, 0, 13, 14, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "an", "open-access", "database", "originally", "conceived", "as", "a", "semantic", "network", "based", "on", "psycholinguistic", "principles", ",", "was", "expanded", "by", "adding", "definitions", "and", "is", "now", "also", "considered", "a", "dictionary", "."], "sentence-detokenized": "WordNet, an open-access database originally conceived as a semantic network based on psycholinguistic principles, was expanded by adding definitions and is now also considered a dictionary.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 23], [24, 32], [33, 43], [44, 53], [54, 56], [57, 58], [59, 67], [68, 75], [76, 81], [82, 84], [85, 101], [102, 112], [112, 113], [114, 117], [118, 126], [127, 129], [130, 136], [137, 148], [149, 152], [153, 155], [156, 159], [160, 164], [165, 175], [176, 177], [178, 188], [188, 189]]}
{"doc_key": "ai-test-90", "ner": [[5, 6, "field"], [17, 17, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 17, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Developments", "in", "the", "field", "of", "computational", "imaging", "research", "are", "presented", "in", "several", "places", ",", "such", "as", "the", "SIGGRAPH", "publications", "and", "the", "."], "sentence-detokenized": "Developments in the field of computational imaging research are presented in several places, such as the SIGGRAPH publications and the.", "token2charspan": [[0, 12], [13, 15], [16, 19], [20, 25], [26, 28], [29, 42], [43, 50], [51, 59], [60, 63], [64, 73], [74, 76], [77, 84], [85, 91], [91, 92], [93, 97], [98, 100], [101, 104], [105, 113], [114, 126], [127, 130], [131, 134], [134, 135]]}
{"doc_key": "ai-test-91", "ner": [[0, 0, "task"], [9, 10, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 0, "part-of", "", false, false], [12, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "considered", "as", "two", "distinct", "problems", ":", "binary", "classification", "and", "multi-class", "classification", "."], "sentence-detokenized": "Classification can be considered as two distinct problems: binary classification and multi-class classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 48], [49, 57], [57, 58], [59, 65], [66, 80], [81, 84], [85, 96], [97, 111], [111, 112]]}
{"doc_key": "ai-test-92", "ner": [[14, 14, "algorithm"], [19, 20, "algorithm"], [23, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 20, 14, 14, "type-of", "", false, false], [23, 23, 19, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Advanced", "gene", "finders", ",", "for", "both", "prokaryotic", "and", "eukaryotic", "genomes", ",", "often", "use", "complex", "probabilistic", "models", ",", "such", "as", "Hidden", "Markov", "Models", "(", "HMMs", ")", ",", "to", "combine", "information", "from", "a", "range", "of", "different", "signal", "and", "content", "measurements", "."], "sentence-detokenized": "Advanced gene finders, for both prokaryotic and eukaryotic genomes, often use complex probabilistic models, such as Hidden Markov Models (HMMs), to combine information from a range of different signal and content measurements.", "token2charspan": [[0, 8], [9, 13], [14, 21], [21, 22], [23, 26], [27, 31], [32, 43], [44, 47], [48, 58], [59, 66], [66, 67], [68, 73], [74, 77], [78, 85], [86, 99], [100, 106], [106, 107], [108, 112], [113, 115], [116, 122], [123, 129], [130, 136], [137, 138], [138, 142], [142, 143], [143, 144], [145, 147], [148, 155], [156, 167], [168, 172], [173, 174], [175, 180], [181, 183], [184, 193], [194, 200], [201, 204], [205, 212], [213, 225], [225, 226]]}
{"doc_key": "ai-test-93", "ner": [[0, 0, "misc"], [3, 3, "misc"], [9, 10, "field"], [13, 14, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"], [31, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 9, 10, "part-of", "", false, false], [0, 0, 13, 14, "usage", "", false, false], [3, 3, 0, 0, "named", "", false, false], [17, 19, 0, 0, "origin", "", true, false], [21, 21, 17, 19, "named", "", false, false], [31, 32, 0, 0, "origin", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Neuroevolution", ",", "or", "neuro-evolution", ",", "is", "a", "form", "of", "artificial", "intelligence", "that", "uses", "evolutionary", "algorithms", "to", "generate", "artificial", "neural", "networks", "(", "ANNs", ")", ",", "parameters", ",", "topology", "and", "rules", ".", "and", "evolutionary", "robotics", "."], "sentence-detokenized": "Neuroevolution, or neuro-evolution, is a form of artificial intelligence that uses evolutionary algorithms to generate artificial neural networks (ANNs), parameters, topology and rules. and evolutionary robotics.", "token2charspan": [[0, 14], [14, 15], [16, 18], [19, 34], [34, 35], [36, 38], [39, 40], [41, 45], [46, 48], [49, 59], [60, 72], [73, 77], [78, 82], [83, 95], [96, 106], [107, 109], [110, 118], [119, 129], [130, 136], [137, 145], [146, 147], [147, 151], [151, 152], [152, 153], [154, 164], [164, 165], [166, 174], [175, 178], [179, 184], [184, 185], [186, 189], [190, 202], [203, 211], [211, 212]]}
{"doc_key": "ai-test-94", "ner": [[1, 1, "organisation"], [6, 6, "metrics"], [8, 8, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 1, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "IBM", "proposed", "and", "realised", "the", "BLEU", "system", "Papineni", "et", "al", "."], "sentence-detokenized": "Since IBM proposed and realised the BLEU system Papineni et al.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 22], [23, 31], [32, 35], [36, 40], [41, 47], [48, 56], [57, 59], [60, 62], [62, 63]]}
{"doc_key": "ai-test-95", "ner": [[10, 16, "conference"], [18, 18, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 18, 10, 16, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2009", ",", "experts", "attended", "a", "conference", "organised", "by", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "to", "discuss", "whether", "computers", "and", "robots", "could", "acquire", "some", "kind", "of", "autonomy", ",", "and", "to", "what", "extent", "these", "capabilities", "could", "pose", "a", "threat", "or", "danger", "."], "sentence-detokenized": "In 2009, experts attended a conference organised by the Association for the Advancement of Artificial Intelligence (AAAI) to discuss whether computers and robots could acquire some kind of autonomy, and to what extent these capabilities could pose a threat or danger.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 25], [26, 27], [28, 38], [39, 48], [49, 51], [52, 55], [56, 67], [68, 71], [72, 75], [76, 87], [88, 90], [91, 101], [102, 114], [115, 116], [116, 120], [120, 121], [122, 124], [125, 132], [133, 140], [141, 150], [151, 154], [155, 161], [162, 167], [168, 175], [176, 180], [181, 185], [186, 188], [189, 197], [197, 198], [199, 202], [203, 205], [206, 210], [211, 217], [218, 223], [224, 236], [237, 242], [243, 247], [248, 249], [250, 256], [257, 259], [260, 266], [266, 267]]}
{"doc_key": "ai-test-96", "ner": [[30, 32, "researcher"], [34, 35, "researcher"], [37, 42, "task"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[37, 42, 30, 32, "artifact", "", false, false], [37, 42, 34, 35, "artifact", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["After", "boosting", ",", "a", "classifier", "constructed", "from", "200", "features", "could", "produce", "a", "95", "%", "detection", "rate", "with", "a", "positive", "rate", "^", "{", "-", "5", "}", "/", "math", "FALSE", ".", "/", "P", ".", "Viola", ",", "M.", "Jones", ",", "Robust", "Real", "-", "time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "After boosting, a classifier constructed from 200 features could produce a 95% detection rate with a positive rate ^ {-5} / math FALSE. / P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 17], [18, 28], [29, 40], [41, 45], [46, 49], [50, 58], [59, 64], [65, 72], [73, 74], [75, 77], [77, 78], [79, 88], [89, 93], [94, 98], [99, 100], [101, 109], [110, 114], [115, 116], [117, 118], [118, 119], [119, 120], [120, 121], [122, 123], [124, 128], [129, 134], [134, 135], [136, 137], [138, 139], [139, 140], [141, 146], [146, 147], [148, 150], [151, 156], [156, 157], [158, 164], [165, 169], [169, 170], [170, 174], [175, 181], [182, 191], [191, 192], [193, 197], [197, 198]]}
{"doc_key": "ai-test-97", "ner": [[6, 6, "programlang"], [9, 9, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "website", "was", "originally", "based", "on", "Perl", ",", "but", "IMDb", "no", "longer", "discloses", "which", "software", "it", "uses", "for", "security", "reasons", "."], "sentence-detokenized": "The website was originally based on Perl, but IMDb no longer discloses which software it uses for security reasons.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 26], [27, 32], [33, 35], [36, 40], [40, 41], [42, 45], [46, 50], [51, 53], [54, 60], [61, 70], [71, 76], [77, 85], [86, 88], [89, 93], [94, 97], [98, 106], [107, 114], [114, 115]]}
{"doc_key": "ai-test-98", "ner": [[5, 6, "researcher"], [8, 9, "researcher"], [11, 12, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "company", "was", "founded", "by", "Demis", "Hassabis", ",", "Shane", "Legg", "and", "Mustafa", "Suleyman", "in", "2010", "."], "sentence-detokenized": "The company was founded by Demis Hassabis, Shane Legg and Mustafa Suleyman in 2010.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 26], [27, 32], [33, 41], [41, 42], [43, 48], [49, 53], [54, 57], [58, 65], [66, 74], [75, 77], [78, 82], [82, 83]]}
{"doc_key": "ai-test-99", "ner": [[3, 4, "misc"], [7, 9, "metrics"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 3, 4, "type-of", "", false, false], [24, 25, 3, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "widely", "used", "loss", "functions", "are", "the", "mean", "square", "error", ",", "mathL", "(", "a", ")", "=", "a", "^", "2", "/", "math", ",", "and", "the", "absolute", "loss", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "/", "math", "."], "sentence-detokenized": "Two widely used loss functions are the mean square error, mathL (a) = a ^ 2 / math, and the absolute loss, mathL (a) = | a | / math.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 20], [21, 30], [31, 34], [35, 38], [39, 43], [44, 50], [51, 56], [56, 57], [58, 63], [64, 65], [65, 66], [66, 67], [68, 69], [70, 71], [72, 73], [74, 75], [76, 77], [78, 82], [82, 83], [84, 87], [88, 91], [92, 100], [101, 105], [105, 106], [107, 112], [113, 114], [114, 115], [115, 116], [117, 118], [119, 120], [121, 122], [123, 124], [125, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-test-100", "ner": [[0, 5, "algorithm"], [12, 14, "algorithm"], [16, 16, "algorithm"], [19, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 5, 12, 14, "type-of", "example_of", false, false], [12, 14, 19, 20, "related-to", "", false, false], [16, 16, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "soft", "margin", "support", "vector", "machine", "described", "above", "is", "an", "example", "of", "empirical", "risk", "minimisation", "(", "ERM", ")", "for", "hinge", "loss", "."], "sentence-detokenized": "The soft margin support vector machine described above is an example of empirical risk minimisation (ERM) for hinge loss.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 23], [24, 30], [31, 38], [39, 48], [49, 54], [55, 57], [58, 60], [61, 68], [69, 71], [72, 81], [82, 86], [87, 99], [100, 101], [101, 104], [104, 105], [106, 109], [110, 115], [116, 120], [120, 121]]}
{"doc_key": "ai-test-101", "ner": [[5, 9, "field"], [9, 9, "task"], [0, 2, "task"], [19, 19, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 9, "origin", "", false, false], [0, 2, 9, 9, "type-of", "", false, false], [19, 19, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Neural", "machine", "translation", ",", "a", "deep", "learning", "approach", "to", "MT", ",", "has", "progressed", "rapidly", "in", "recent", "years", ",", "and", "Google", "has", "announced", "that", "its", "translation", "services", "now", "use", "this", "technology", "instead", "of", "its", "previous", "statistical", "methods", "."], "sentence-detokenized": "Neural machine translation, a deep learning approach to MT, has progressed rapidly in recent years, and Google has announced that its translation services now use this technology instead of its previous statistical methods.", "token2charspan": [[0, 6], [7, 14], [15, 26], [26, 27], [28, 29], [30, 34], [35, 43], [44, 52], [53, 55], [56, 58], [58, 59], [60, 63], [64, 74], [75, 82], [83, 85], [86, 92], [93, 98], [98, 99], [100, 103], [104, 110], [111, 114], [115, 124], [125, 129], [130, 133], [134, 145], [146, 154], [155, 158], [159, 162], [163, 167], [168, 178], [179, 186], [187, 189], [190, 193], [194, 202], [203, 214], [215, 222], [222, 223]]}
{"doc_key": "ai-test-102", "ner": [[15, 15, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "tends", "to", "produce", "very", "large", "performance", "gains", "when", "working", "with", "large", "corpora", "such", "as", "WordNet", "."], "sentence-detokenized": "This tends to produce very large performance gains when working with large corpora such as WordNet.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 21], [22, 26], [27, 32], [33, 44], [45, 50], [51, 55], [56, 63], [64, 68], [69, 74], [75, 82], [83, 87], [88, 90], [91, 98], [98, 99]]}
{"doc_key": "ai-test-103", "ner": [[0, 1, "task"], [5, 5, "field"], [18, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 18, 20, "part-of", "", false, false], [18, 20, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Face", "detection", "is", "used", "in", "biometrics", ",", "often", "as", "part", "of", "(", "or", "in", "conjunction", "with", ")", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Face detection is used in biometrics, often as part of (or in conjunction with) a facial recognition system.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 22], [23, 25], [26, 36], [36, 37], [38, 43], [44, 46], [47, 51], [52, 54], [55, 56], [56, 58], [59, 61], [62, 73], [74, 78], [78, 79], [80, 81], [82, 88], [89, 100], [101, 107], [107, 108]]}
{"doc_key": "ai-test-104", "ner": [[2, 4, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["trained", "by", "maximum", "likelihood", "estimation", "."], "sentence-detokenized": "trained by maximum likelihood estimation.", "token2charspan": [[0, 7], [8, 10], [11, 18], [19, 29], [30, 40], [40, 41]]}
{"doc_key": "ai-test-105", "ner": [[3, 3, "country"], [5, 9, "organisation"], [13, 13, "location"], [15, 15, "country"], [17, 20, "organisation"], [22, 22, "country"], [28, 28, "organisation"], [33, 35, "organisation"], [37, 37, "country"], [48, 51, "organisation"], [53, 53, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[5, 9, 13, 13, "physical", "", false, false], [13, 13, 15, 15, "physical", "", false, false], [17, 20, 22, 22, "physical", "", false, false], [33, 35, 37, 37, "physical", "", false, false], [48, 51, 53, 53, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ltd", ".", "in", "Thailand", ";", "Komatsu", "(", "Shanghai", ")", "Ltd.", "in", "1996", "in", "Shanghai", ",", "China", ";", "Industrial", "Power", "Alliance", "Ltd.", "in", "Japan", ",", "a", "joint", "venture", "with", "Cummins", ",", "in", "1998", ";", "L&T-", "Komatsu", "Limited", "in", "India", "in", "1998", "(", "shares", "sold", "in", "2013", ")", ";", "and", "Komatsu", "Brasil", "International", "Ltda.", "in", "Brazil", "in", "1998", "."], "sentence-detokenized": "Ltd. in Thailand; Komatsu (Shanghai) Ltd. in 1996 in Shanghai, China; Industrial Power Alliance Ltd. in Japan, a joint venture with Cummins, in 1998; L&T-Komatsu Limited in India in 1998 (shares sold in 2013); and Komatsu Brasil International Ltda. in Brazil in 1998.", "token2charspan": [[0, 3], [3, 4], [5, 7], [8, 16], [16, 17], [18, 25], [26, 27], [27, 35], [35, 36], [37, 41], [42, 44], [45, 49], [50, 52], [53, 61], [61, 62], [63, 68], [68, 69], [70, 80], [81, 86], [87, 95], [96, 100], [101, 103], [104, 109], [109, 110], [111, 112], [113, 118], [119, 126], [127, 131], [132, 139], [139, 140], [141, 143], [144, 148], [148, 149], [150, 154], [154, 161], [162, 169], [170, 172], [173, 178], [179, 181], [182, 186], [187, 188], [188, 194], [195, 199], [200, 202], [203, 207], [207, 208], [208, 209], [210, 213], [214, 221], [222, 228], [229, 242], [243, 248], [249, 251], [252, 258], [259, 261], [262, 266], [266, 267]]}
{"doc_key": "ai-test-106", "ner": [[0, 1, "organisation"], [5, 7, "misc"], [10, 10, "misc"], [12, 13, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 13, 0, 1, "physical", "", false, false], [12, 13, 5, 7, "general-affiliation", "", false, false], [12, 13, 10, 10, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "dgp", "also", "occasionally", "hosts", "artists", "in", "residence", "(", "e.g.", "Oscar", "winner", "Chris", "Landreth", ")", "."], "sentence-detokenized": "The dgp also occasionally hosts artists in residence (e.g. Oscar winner Chris Landreth).", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 25], [26, 31], [32, 39], [40, 42], [43, 52], [53, 54], [54, 58], [59, 64], [65, 71], [72, 77], [78, 86], [86, 87], [87, 88]]}
{"doc_key": "ai-test-107", "ner": [[7, 9, "misc"], [12, 14, "misc"], [17, 20, "misc"], [24, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "currently", "includes", "four", "sub-competitions", ":", "the", "RoboMaster", "robotics", "competition", ",", "the", "RoboMaster", "technical", "challenge", ",", "the", "ICRA", "RoboMaster", "AI", "challenge", "and", "the", "new", "RoboMaster", "youth", "tournament", "."], "sentence-detokenized": "It currently includes four sub-competitions: the RoboMaster robotics competition, the RoboMaster technical challenge, the ICRA RoboMaster AI challenge and the new RoboMaster youth tournament.", "token2charspan": [[0, 2], [3, 12], [13, 21], [22, 26], [27, 43], [43, 44], [45, 48], [49, 59], [60, 68], [69, 80], [80, 81], [82, 85], [86, 96], [97, 106], [107, 116], [116, 117], [118, 121], [122, 126], [127, 137], [138, 140], [141, 150], [151, 154], [155, 158], [159, 162], [163, 173], [174, 179], [180, 190], [190, 191]]}
{"doc_key": "ai-test-108", "ner": [[7, 8, "field"], [16, 18, "algorithm"], [27, 28, "algorithm"], [30, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 27, 28, "usage", "", false, false], [7, 8, 30, 31, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "the", "early", "2000s", ",", "the", "dominant", "speech", "processing", "strategy", "began", "to", "move", "away", "from", "the", "Hidden", "Markov", "model", "towards", "state", "-", "of", "-", "the", "-", "art", "neural", "networks", "and", "deep", "learning", "."], "sentence-detokenized": "In the early 2000s, the dominant speech processing strategy began to move away from the Hidden Markov model towards state-of-the-art neural networks and deep learning.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 18], [18, 19], [20, 23], [24, 32], [33, 39], [40, 50], [51, 59], [60, 65], [66, 68], [69, 73], [74, 78], [79, 83], [84, 87], [88, 94], [95, 101], [102, 107], [108, 115], [116, 121], [121, 122], [122, 124], [124, 125], [125, 128], [128, 129], [129, 132], [133, 139], [140, 148], [149, 152], [153, 157], [158, 166], [166, 167]]}
{"doc_key": "ai-test-109", "ner": [[9, 11, "misc"], [16, 17, "metrics"], [21, 22, "metrics"], [30, 32, "metrics"], [35, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 17, 21, 22, "related-to", "equal", false, false], [30, 32, 35, 37, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "equivalent", "expression", ",", "in", "the", "case", "of", "a", "binary", "target", "rate", ",", "is", "that", "the", "TRUE", "positive", "rate", "and", "the", "FALSE", "positive", "rate", "are", "equal", "(", "and", "therefore", "the", "FALSE", "negative", "rate", "and", "the", "TRUE", "negative", "rate", "are", "equal", ")", "for", "each", "value", "of", "the", "sensitive", "characteristics", ":"], "sentence-detokenized": "Another equivalent expression, in the case of a binary target rate, is that the TRUE positive rate and the FALSE positive rate are equal (and therefore the FALSE negative rate and the TRUE negative rate are equal) for each value of the sensitive characteristics:", "token2charspan": [[0, 7], [8, 18], [19, 29], [29, 30], [31, 33], [34, 37], [38, 42], [43, 45], [46, 47], [48, 54], [55, 61], [62, 66], [66, 67], [68, 70], [71, 75], [76, 79], [80, 84], [85, 93], [94, 98], [99, 102], [103, 106], [107, 112], [113, 121], [122, 126], [127, 130], [131, 136], [137, 138], [138, 141], [142, 151], [152, 155], [156, 161], [162, 170], [171, 175], [176, 179], [180, 183], [184, 188], [189, 197], [198, 202], [203, 206], [207, 212], [212, 213], [214, 217], [218, 222], [223, 228], [229, 231], [232, 235], [236, 245], [246, 261], [261, 262]]}
{"doc_key": "ai-test-110", "ner": [[1, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "MATLAB", "function", ","], "sentence-detokenized": "The MATLAB function,", "token2charspan": [[0, 3], [4, 10], [11, 19], [19, 20]]}
{"doc_key": "ai-test-111", "ner": [[1, 2, "product"], [7, 7, "misc"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 1, 2, "part-of", "", false, false], [16, 17, 1, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "articulated", "robot", "is", "a", "robot", "with", "rotating", "joints", "(", "e.g.", "a", "legged", "robot", "or", "an", "industrial", "robot", ")", "."], "sentence-detokenized": "An articulated robot is a robot with rotating joints (e.g. a legged robot or an industrial robot).", "token2charspan": [[0, 2], [3, 14], [15, 20], [21, 23], [24, 25], [26, 31], [32, 36], [37, 45], [46, 52], [53, 54], [54, 58], [59, 60], [61, 67], [68, 73], [74, 76], [77, 79], [80, 90], [91, 96], [96, 97], [97, 98]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [5, 6, "product"], [8, 9, "product"], [13, 13, "misc"], [20, 23, "product"], [26, 28, "misc"], [32, 32, "location"], [34, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 13, 13, "general-affiliation", "nationality", false, false], [0, 0, 26, 28, "usage", "", false, false], [0, 0, 32, 32, "physical", "", false, false], [5, 6, 0, 0, "named", "", false, false], [8, 9, 0, 0, "named", "", false, false], [32, 32, 34, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "also", "known", "as", "Pandora", "Media", "or", "Pandora", "Radio", ")", "is", "an", "American", "music", "streaming", "Internet", "radio", "service", "and", "automated", "recommendation", "system", "powered", "by", "the", "Music", "Genome", "Project", "and", "based", "in", "Oakland", ",", "California", "."], "sentence-detokenized": "Pandora (also known as Pandora Media or Pandora Radio) is an American music streaming Internet radio service and automated recommendation system powered by the Music Genome Project and based in Oakland, California.", "token2charspan": [[0, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 30], [31, 36], [37, 39], [40, 47], [48, 53], [53, 54], [55, 57], [58, 60], [61, 69], [70, 75], [76, 85], [86, 94], [95, 100], [101, 108], [109, 112], [113, 122], [123, 137], [138, 144], [145, 152], [153, 155], [156, 159], [160, 165], [166, 172], [173, 180], [181, 184], [185, 190], [191, 193], [194, 201], [201, 202], [203, 213], [213, 214]]}
{"doc_key": "ai-test-113", "ner": [[7, 11, "organisation"], [17, 20, "organisation"], [26, 27, "conference"], [41, 41, "conference"], [43, 43, "conference"], [45, 45, "conference"], [47, 47, "conference"], [49, 49, "conference"], [51, 51, "conference"], [53, 53, "conference"], [55, 55, "conference"], [57, 57, "conference"], [59, 59, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "board", "member", "of", "the", "International", "Society", "for", "Machine", "Learning", ",", "has", "served", "on", "the", "executive", "council", "of", "AAAI", ",", "was", "co-chair", "of", "the", "ICML", "2011", "PC", ",", "and", "has", "been", "a", "senior", "PC", "member", "of", "conferences", "such", "as", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "IAU", ",", "VLDB", ",", "WSDM", "and", "WWW", "."], "sentence-detokenized": "She is a board member of the International Society for Machine Learning, has served on the executive council of AAAI, was co-chair of the ICML 2011 PC, and has been a senior PC member of conferences such as AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, IAU, VLDB, WSDM and WWW.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 14], [15, 21], [22, 24], [25, 28], [29, 42], [43, 50], [51, 54], [55, 62], [63, 71], [71, 72], [73, 76], [77, 83], [84, 86], [87, 90], [91, 100], [101, 108], [109, 111], [112, 116], [116, 117], [118, 121], [122, 130], [131, 133], [134, 137], [138, 142], [143, 147], [148, 150], [150, 151], [152, 155], [156, 159], [160, 164], [165, 166], [167, 173], [174, 176], [177, 183], [184, 186], [187, 198], [199, 203], [204, 206], [207, 211], [211, 212], [213, 217], [217, 218], [219, 224], [224, 225], [226, 230], [230, 231], [232, 235], [235, 236], [237, 243], [243, 244], [245, 248], [248, 249], [250, 254], [254, 255], [256, 260], [261, 264], [265, 268], [268, 269]]}
{"doc_key": "ai-test-114", "ner": [[0, 2, "researcher"], [5, 10, "organisation"], [12, 12, "organisation"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 10, "role", "", false, false], [12, 12, 5, 10, "named", "", false, false], [16, 16, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", "of", "the", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", "developed", "the", "Robocrane", ",", "in", "which", "the", "platform", "hangs", "from", "six", "cables", "instead", "of", "being", "supported", "by", "six", "jacks", "."], "sentence-detokenized": "James S. Albus of the National Institute of Standards and Technology (NIST) developed the Robocrane, in which the platform hangs from six cables instead of being supported by six jacks.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 17], [18, 21], [22, 30], [31, 40], [41, 43], [44, 53], [54, 57], [58, 68], [69, 70], [70, 74], [74, 75], [76, 85], [86, 89], [90, 99], [99, 100], [101, 103], [104, 109], [110, 113], [114, 122], [123, 128], [129, 133], [134, 137], [138, 144], [145, 152], [153, 155], [156, 161], [162, 171], [172, 174], [175, 178], [179, 184], [184, 185]]}
{"doc_key": "ai-test-115", "ner": [[3, 5, "algorithm"], [9, 12, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 12, 3, 5, "type-of", "", false, false], [13, 14, 9, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "class", "of", "direct", "search", "algorithms", "are", "the", "various", "evolutionary", "algorithms", ",", "e.g.", "genetic", "algorithms", "."], "sentence-detokenized": "Another class of direct search algorithms are the various evolutionary algorithms, e.g. genetic algorithms.", "token2charspan": [[0, 7], [8, 13], [14, 16], [17, 23], [24, 30], [31, 41], [42, 45], [46, 49], [50, 57], [58, 70], [71, 81], [81, 82], [83, 87], [88, 95], [96, 106], [106, 107]]}
{"doc_key": "ai-test-116", "ner": [[0, 1, "organisation"], [3, 4, "misc"], [6, 6, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 0, 1, "named", "", false, false], [6, 6, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["KUKA", "is", "a", "German", "manufacturer", "of", "industrial", "robots", "and", "factory", "automation", "solutions", "."], "sentence-detokenized": "KUKA is a German manufacturer of industrial robots and factory automation solutions.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 16], [17, 29], [30, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 73], [74, 83], [83, 84]]}
{"doc_key": "ai-test-117", "ner": [[9, 9, "misc"], [12, 14, "person"], [15, 21, "misc"], [23, 24, "person"], [26, 26, "misc"], [28, 29, "person"], [31, 32, "misc"], [34, 39, "person"], [37, 39, "misc"], [41, 43, "person"], [45, 48, "misc"], [51, 52, "person"], [54, 60, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[12, 14, 9, 9, "usage", "", false, false], [15, 21, 12, 14, "artifact", "", false, false], [23, 24, 9, 9, "usage", "", false, false], [26, 26, 23, 24, "artifact", "", false, false], [28, 29, 9, 9, "usage", "", false, false], [31, 32, 28, 29, "artifact", "", false, false], [34, 39, 9, 9, "usage", "", false, false], [37, 39, 34, 39, "artifact", "", false, false], [41, 43, 9, 9, "usage", "", false, false], [45, 48, 41, 43, "artifact", "", false, false], [51, 52, 9, 9, "usage", "", false, false], [54, 60, 51, 52, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Other", "films", "between", "2016", "and", "2020", "that", "captured", "with", "IMAX", "cameras", "were", "Zack", "Snyder", "'s", "Batman", "v", "Superman", ":", "Dawn", "of", "Justice", ",", "Clint", "Eastwood", "'s", "Sully", ",", "Damien", "Chazelle", "'s", "First", "Man", ",", "Patty", "Jenkins", "'", "Wonder", "Woman", "1984", ",", "Cary", "Joji", "Fukunaga", "'s", "No", "Time", "to", "Die", ",", "and", "Joseph", "Kosinski", "'s", "Top", "Gun", ":", "Joseph", "Kosinski", "'s", "Maverick", "."], "sentence-detokenized": "Other films between 2016 and 2020 that captured with IMAX cameras were Zack Snyder's Batman v Superman: Dawn of Justice, Clint Eastwood's Sully, Damien Chazelle's First Man, Patty Jenkins' Wonder Woman 1984, Cary Joji Fukunaga's No Time to Die, and Joseph Kosinski's Top Gun: Joseph Kosinski's Maverick.", "token2charspan": [[0, 5], [6, 11], [12, 19], [20, 24], [25, 28], [29, 33], [34, 38], [39, 47], [48, 52], [53, 57], [58, 65], [66, 70], [71, 75], [76, 82], [82, 84], [85, 91], [92, 93], [94, 102], [102, 103], [104, 108], [109, 111], [112, 119], [119, 120], [121, 126], [127, 135], [135, 137], [138, 143], [143, 144], [145, 151], [152, 160], [160, 162], [163, 168], [169, 172], [172, 173], [174, 179], [180, 187], [187, 188], [189, 195], [196, 201], [202, 206], [206, 207], [208, 212], [213, 217], [218, 226], [226, 228], [229, 231], [232, 236], [237, 239], [240, 243], [243, 244], [245, 248], [249, 255], [256, 264], [264, 266], [267, 270], [271, 274], [274, 275], [276, 282], [283, 291], [291, 293], [294, 302], [302, 303]]}
{"doc_key": "ai-test-118", "ner": [[4, 5, "misc"], [11, 13, "organisation"], [15, 15, "organisation"], [28, 28, "misc"], [35, 36, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 28, 28, "named", "", false, false], [11, 13, 4, 5, "usage", "", false, false], [11, 13, 35, 36, "physical", "", false, false], [15, 15, 11, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "proof", "of", "the", "MICR", "E13B", "typeface", "was", "shown", "to", "the", "American", "Bankers", "Association", "(", "ABA", ")", "in", "July", "1956", ",", "which", "adopted", "it", "in", "1958", "as", "the", "MICR", "standard", "for", "negotiable", "documents", "in", "the", "United", "States", "."], "sentence-detokenized": "The proof of the MICR E13B typeface was shown to the American Bankers Association (ABA) in July 1956, which adopted it in 1958 as the MICR standard for negotiable documents in the United States.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 16], [17, 21], [22, 26], [27, 35], [36, 39], [40, 45], [46, 48], [49, 52], [53, 61], [62, 69], [70, 81], [82, 83], [83, 86], [86, 87], [88, 90], [91, 95], [96, 100], [100, 101], [102, 107], [108, 115], [116, 118], [119, 121], [122, 126], [127, 129], [130, 133], [134, 138], [139, 147], [148, 151], [152, 162], [163, 172], [173, 175], [176, 179], [180, 186], [187, 193], [193, 194]]}
{"doc_key": "ai-test-119", "ner": [[0, 2, "misc"], [15, 16, "field"], [19, 20, "field"], [23, 23, "field"], [25, 26, "field"], [28, 28, "field"], [30, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 16, 0, 2, "usage", "", false, false], [19, 20, 15, 16, "part-of", "", false, false], [23, 23, 0, 2, "usage", "", false, false], [25, 26, 0, 2, "usage", "", false, false], [28, 28, 0, 2, "usage", "", false, false], [30, 30, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Local", "search", "algorithms", "are", "widely", "applied", "to", "numerous", "difficult", "computational", "problems", ",", "including", "problems", "in", "computer", "science", "(", "particularly", "artificial", "intelligence", ")", ",", "mathematics", ",", "operations", "research", ",", "engineering", "and", "bioinformatics", "."], "sentence-detokenized": "Local search algorithms are widely applied to numerous difficult computational problems, including problems in computer science (particularly artificial intelligence), mathematics, operations research, engineering and bioinformatics.", "token2charspan": [[0, 5], [6, 12], [13, 23], [24, 27], [28, 34], [35, 42], [43, 45], [46, 54], [55, 64], [65, 78], [79, 87], [87, 88], [89, 98], [99, 107], [108, 110], [111, 119], [120, 127], [128, 129], [129, 141], [142, 152], [153, 165], [165, 166], [166, 167], [168, 179], [179, 180], [181, 191], [192, 200], [200, 201], [202, 213], [214, 217], [218, 232], [232, 233]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [8, 8, "location"], [10, 10, "country"], [14, 14, "country"], [22, 23, "algorithm"], [25, 25, "algorithm"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 8, 8, "physical", "", false, false], [0, 1, 14, 14, "general-affiliation", "nationality", false, false], [0, 1, 22, 23, "general-affiliation", "topic_of_study", false, false], [0, 1, 25, 25, "general-affiliation", "topic_of_study", false, false], [8, 8, 10, 10, "physical", "", false, false], [25, 25, 27, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "born", "3", "September", "1947", "in", "Wallersdorf", ",", "Germany", ")", "is", "a", "German", "psychologist", "who", "has", "studied", "the", "use", "of", "bounded", "rationality", "and", "heuristics", "in", "decision", "-", "making", "."], "sentence-detokenized": "Gerd Gigerenzer (born 3 September 1947 in Wallersdorf, Germany) is a German psychologist who has studied the use of bounded rationality and heuristics in decision-making.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 21], [22, 23], [24, 33], [34, 38], [39, 41], [42, 53], [53, 54], [55, 62], [62, 63], [64, 66], [67, 68], [69, 75], [76, 88], [89, 92], [93, 96], [97, 104], [105, 108], [109, 112], [113, 115], [116, 123], [124, 135], [136, 139], [140, 150], [151, 153], [154, 162], [162, 163], [163, 169], [169, 170]]}
{"doc_key": "ai-test-121", "ner": [[3, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["to", "minimise", "the", "mean", "square", "error", "."], "sentence-detokenized": "to minimise the mean square error.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 20], [21, 27], [28, 33], [33, 34]]}
{"doc_key": "ai-test-122", "ner": [[12, 13, "misc"], [16, 17, "organisation"], [31, 33, "field"], [51, 52, "misc"], [62, 64, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 13, 16, 17, "origin", "", false, false], [51, 52, 62, 64, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["But", "even", "an", "official", "language", "with", "a", "regulatory", "academy", ",", "such", "as", "Standard", "French", "with", "the", "Acad\u00e9mie", "fran\u00e7aise", ",", "is", "classified", "as", "a", "natural", "language", "(", "e.g.", "in", "the", "field", "of", "natural", "language", "processing", ")", ",", "since", "its", "prescriptive", "points", "do", "not", "make", "it", "sufficiently", "constructed", "to", "be", "classified", "as", "a", "constructed", "language", ",", "nor", "sufficiently", "controlled", "to", "be", "classified", "as", "a", "controlled", "natural", "language", "."], "sentence-detokenized": "But even an official language with a regulatory academy, such as Standard French with the Acad\u00e9mie fran\u00e7aise, is classified as a natural language (e.g. in the field of natural language processing), since its prescriptive points do not make it sufficiently constructed to be classified as a constructed language, nor sufficiently controlled to be classified as a controlled natural language.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 20], [21, 29], [30, 34], [35, 36], [37, 47], [48, 55], [55, 56], [57, 61], [62, 64], [65, 73], [74, 80], [81, 85], [86, 89], [90, 98], [99, 108], [108, 109], [110, 112], [113, 123], [124, 126], [127, 128], [129, 136], [137, 145], [146, 147], [147, 151], [152, 154], [155, 158], [159, 164], [165, 167], [168, 175], [176, 184], [185, 195], [195, 196], [196, 197], [198, 203], [204, 207], [208, 220], [221, 227], [228, 230], [231, 234], [235, 239], [240, 242], [243, 255], [256, 267], [268, 270], [271, 273], [274, 284], [285, 287], [288, 289], [290, 301], [302, 310], [310, 311], [312, 315], [316, 328], [329, 339], [340, 342], [343, 345], [346, 356], [357, 359], [360, 361], [362, 372], [373, 380], [381, 389], [389, 390]]}
{"doc_key": "ai-test-123", "ner": [[10, 10, "metrics"], [12, 13, "metrics"], [15, 15, "metrics"], [33, 34, "metrics"], [36, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 15, 12, 13, "named", "", false, false], [36, 36, 33, 34, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "other", "metrics", ",", "the", "simplest", "of", "which", "is", "accuracy", "or", "Fraction", "Correct", "(", "FC", ")", ",", "which", "measures", "the", "fraction", "of", "all", "instances", "that", "are", "correctly", "classified", ";", "the", "complement", "is", "Fraction", "Incorrect", "(", "FiC", ")", "."], "sentence-detokenized": "There are other metrics, the simplest of which is accuracy or Fraction Correct (FC), which measures the fraction of all instances that are correctly classified; the complement is Fraction Incorrect (FiC).", "token2charspan": [[0, 5], [6, 9], [10, 15], [16, 23], [23, 24], [25, 28], [29, 37], [38, 40], [41, 46], [47, 49], [50, 58], [59, 61], [62, 70], [71, 78], [79, 80], [80, 82], [82, 83], [83, 84], [85, 90], [91, 99], [100, 103], [104, 112], [113, 115], [116, 119], [120, 129], [130, 134], [135, 138], [139, 148], [149, 159], [159, 160], [161, 164], [165, 175], [176, 178], [179, 187], [188, 197], [198, 199], [199, 202], [202, 203], [203, 204]]}
{"doc_key": "ai-test-124", "ner": [[0, 0, "researcher"], [6, 9, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 9, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cardie", "became", "a", "member", "of", "the", "Association", "for", "Computational", "Linguistics", "in", "2016", "."], "sentence-detokenized": "Cardie became a member of the Association for Computational Linguistics in 2016.", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 22], [23, 25], [26, 29], [30, 41], [42, 45], [46, 59], [60, 71], [72, 74], [75, 79], [79, 80]]}
{"doc_key": "ai-test-125", "ner": [[13, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "learning", "of", "the", "parameters", "math", "theta", "/", "math", "is", "usually", "done", "by", "maximum", "likelihood", "learning", "for", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i", ";\\", "theta", ")", "/", "math", "."], "sentence-detokenized": "The learning of the parameters math theta / math is usually done by maximum likelihood learning for mathp (Y _ i | X _ i;\\ theta) / math.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 19], [20, 30], [31, 35], [36, 41], [42, 43], [44, 48], [49, 51], [52, 59], [60, 64], [65, 67], [68, 75], [76, 86], [87, 95], [96, 99], [100, 105], [106, 107], [107, 108], [109, 110], [111, 112], [113, 114], [115, 116], [117, 118], [119, 120], [120, 122], [123, 128], [128, 129], [130, 131], [132, 136], [136, 137]]}
{"doc_key": "ai-test-126", "ner": [[0, 1, "task"], [3, 6, "algorithm"], [8, 9, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 0, 1, "usage", "", true, false], [8, 9, 3, 6, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cluster", "analysis", "and", "factorisation", "of", "non-negative", "matrices", "for", "descriptive", "mining", "."], "sentence-detokenized": "Cluster analysis and factorisation of non-negative matrices for descriptive mining.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 34], [35, 37], [38, 50], [51, 59], [60, 63], [64, 75], [76, 82], [82, 83]]}
{"doc_key": "ai-test-127", "ner": [[1, 2, "field"], [5, 6, "field"], [14, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 16, 1, 2, "part-of", "", false, false], [14, 16, 5, 6, "part-of", "", false, false], [18, 19, 1, 2, "part-of", "", false, false], [18, 19, 5, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", "and", "enabling", "information", "technology", ",", "the", "ability", "in", "computers", "to", "do", "natural", "language", "processing", "and", "machine", "learning", "has", "been", "a", "long", "-", "term", "challenge", "."], "sentence-detokenized": "In computer science and enabling information technology, the ability in computers to do natural language processing and machine learning has been a long-term challenge.", "token2charspan": [[0, 2], [3, 11], [12, 19], [20, 23], [24, 32], [33, 44], [45, 55], [55, 56], [57, 60], [61, 68], [69, 71], [72, 81], [82, 84], [85, 87], [88, 95], [96, 104], [105, 115], [116, 119], [120, 127], [128, 136], [137, 140], [141, 145], [146, 147], [148, 152], [152, 153], [153, 157], [158, 167], [167, 168]]}
{"doc_key": "ai-test-128", "ner": [[4, 7, "algorithm"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 7, 10, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "The", "code", "for", "extracting", "Gabor", "features", "from", "images", "in", "MATLAB", "can", "be", "found", "at"], "sentence-detokenized": "(The code for extracting Gabor features from images in MATLAB can be found at", "token2charspan": [[0, 1], [1, 4], [5, 9], [10, 13], [14, 24], [25, 30], [31, 39], [40, 44], [45, 51], [52, 54], [55, 61], [62, 65], [66, 68], [69, 74], [75, 77]]}
{"doc_key": "ai-test-129", "ner": [[0, 0, "misc"], [14, 15, "algorithm"], [19, 19, "task"], [21, 21, "task"], [23, 24, "task"], [26, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 14, 15, "general-affiliation", "", false, false], [0, 0, 19, 19, "related-to", "solves_problem_of_type", false, false], [0, 0, 21, 21, "related-to", "solves_problem_of_type", false, false], [0, 0, 23, 24, "related-to", "solves_problem_of_type", false, false], [0, 0, 26, 27, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["NeuralExpert", "focuses", "the", "design", "specifications", "around", "the", "type", "of", "problem", "the", "user", "wants", "the", "neural", "network", "to", "solve", "(", "Classification", ",", "Prediction", ",", "Function", "Approximation", "or", "Cluster", "Analysis", ")", "."], "sentence-detokenized": "NeuralExpert focuses the design specifications around the type of problem the user wants the neural network to solve (Classification, Prediction, Function Approximation or Cluster Analysis).", "token2charspan": [[0, 12], [13, 20], [21, 24], [25, 31], [32, 46], [47, 53], [54, 57], [58, 62], [63, 65], [66, 73], [74, 77], [78, 82], [83, 88], [89, 92], [93, 99], [100, 107], [108, 110], [111, 116], [117, 118], [118, 132], [132, 133], [134, 144], [144, 145], [146, 154], [155, 168], [169, 171], [172, 179], [180, 188], [188, 189], [189, 190]]}
{"doc_key": "ai-test-130", "ner": [[2, 6, "misc"], [30, 32, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "size", "of", "the", "quantization", "step", "(", "\u0394", ")", "is", "small", "relative", "to", "the", "variation", "of", "the", "signal", "being", "quantified", ",", "it", "is", "relatively", "straightforward", "to", "show", "that", "the", "mean", "square", "error", "produced", "by", "such", "a", "rounding", "operation", "will", "be", "approximately", "math", "\\", "Delta", "^", "2", "/", "12", "/", "math.math"], "sentence-detokenized": "When the size of the quantization step (\u0394) is small relative to the variation of the signal being quantified, it is relatively straightforward to show that the mean square error produced by such a rounding operation will be approximately math\\ Delta ^ 2 / 12 / math.math", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 20], [21, 33], [34, 38], [39, 40], [40, 41], [41, 42], [43, 45], [46, 51], [52, 60], [61, 63], [64, 67], [68, 77], [78, 80], [81, 84], [85, 91], [92, 97], [98, 108], [108, 109], [110, 112], [113, 115], [116, 126], [127, 142], [143, 145], [146, 150], [151, 155], [156, 159], [160, 164], [165, 171], [172, 177], [178, 186], [187, 189], [190, 194], [195, 196], [197, 205], [206, 215], [216, 220], [221, 223], [224, 237], [238, 242], [242, 243], [244, 249], [250, 251], [252, 253], [254, 255], [256, 258], [259, 260], [261, 270]]}
{"doc_key": "ai-test-131", "ner": [[14, 14, "product"], [25, 28, "researcher"], [30, 31, "researcher"], [33, 35, "researcher"], [37, 38, "researcher"], [40, 42, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Building", "a", "rich", "lexicon", "with", "an", "appropriate", "ontology", "requires", "significant", "effort", ",", "e.g.", ",", "Wordnet", "'s", "lexicon", "required", "many", "person", "-", "years", "of", "effort", ".", "G.", "A", ".", "Miller", ",", "R.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Gross", ",", "K", ".", "Miller", "."], "sentence-detokenized": "Building a rich lexicon with an appropriate ontology requires significant effort, e.g., Wordnet's lexicon required many person-years of effort. G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 8], [9, 10], [11, 15], [16, 23], [24, 28], [29, 31], [32, 43], [44, 52], [53, 61], [62, 73], [74, 80], [80, 81], [82, 86], [86, 87], [88, 95], [95, 97], [98, 105], [106, 114], [115, 119], [120, 126], [126, 127], [127, 132], [133, 135], [136, 142], [142, 143], [144, 146], [147, 148], [148, 149], [150, 156], [156, 157], [158, 160], [161, 169], [169, 170], [171, 173], [174, 176], [177, 185], [185, 186], [187, 189], [190, 195], [195, 196], [197, 198], [198, 199], [200, 206], [206, 207]]}
{"doc_key": "ai-test-132", "ner": [[0, 0, "organisation"], [15, 16, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 16, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Kawasaki", "'s", "portfolio", "also", "includes", "roofs", ",", "floors", "and", "other", "giant", "retractable", "structures", ";", "the", "Sapporo", "Dome", "retractable", "surface", "is", "one", "example", "."], "sentence-detokenized": "Kawasaki's portfolio also includes roofs, floors and other giant retractable structures; the Sapporo Dome retractable surface is one example.", "token2charspan": [[0, 8], [8, 10], [11, 20], [21, 25], [26, 34], [35, 40], [40, 41], [42, 48], [49, 52], [53, 58], [59, 64], [65, 76], [77, 87], [87, 88], [89, 92], [93, 100], [101, 105], [106, 117], [118, 125], [126, 128], [129, 132], [133, 140], [140, 141]]}
{"doc_key": "ai-test-133", "ner": [[0, 1, "metrics"], [5, 7, "metrics"], [9, 11, "metrics"], [17, 18, "metrics"], [39, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 17, 18, "related-to", "", false, false], [0, 1, 39, 39, "opposite", "alternative_to", false, false], [5, 7, 0, 1, "type-of", "", false, false], [9, 11, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kappa", "statistics", ",", "such", "as", "Fleiss", "'", "kappa", "and", "Cohen", "'s", "kappa", ",", "are", "methods", "for", "calculating", "inter-rater", "reliability", "based", "on", "different", "assumptions", "about", "marginal", "or", "prior", "distributions", ",", "and", "are", "increasingly", "used", "as", "alternatives", "to", "chance", "-", "corrected", "precision", "in", "other", "contexts", "."], "sentence-detokenized": "Kappa statistics, such as Fleiss' kappa and Cohen's kappa, are methods for calculating inter-rater reliability based on different assumptions about marginal or prior distributions, and are increasingly used as alternatives to chance-corrected precision in other contexts.", "token2charspan": [[0, 5], [6, 16], [16, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 39], [40, 43], [44, 49], [49, 51], [52, 57], [57, 58], [59, 62], [63, 70], [71, 74], [75, 86], [87, 98], [99, 110], [111, 116], [117, 119], [120, 129], [130, 141], [142, 147], [148, 156], [157, 159], [160, 165], [166, 179], [179, 180], [181, 184], [185, 188], [189, 201], [202, 206], [207, 209], [210, 222], [223, 225], [226, 232], [232, 233], [233, 242], [243, 252], [253, 255], [256, 261], [262, 270], [270, 271]]}
{"doc_key": "ai-test-134", "ner": [[3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [12, 13, "researcher"], [17, 17, "researcher"], [26, 28, "algorithm"], [33, 33, "algorithm"], [35, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 4, 17, 17, "role", "student_of", false, false], [6, 7, 17, 17, "role", "student_of", false, false], [9, 10, 17, 17, "role", "student_of", false, false], [12, 13, 17, 17, "role", "student_of", false, false], [33, 33, 3, 4, "origin", "", false, false], [33, 33, 6, 7, "origin", "", false, false], [33, 33, 9, 10, "origin", "", false, false], [33, 33, 12, 13, "origin", "", false, false], [33, 33, 17, 17, "origin", "", false, false], [33, 33, 26, 28, "type-of", "", false, false], [35, 35, 33, 33, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["With", "his", "students", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Graves", "and", "others", ",", "Schmidhuber", "published", "increasingly", "sophisticated", "versions", "of", "a", "type", "of", "recurrent", "neural", "network", "called", "short", "-", "term", "memory", "(", "LSTM", ")", "."], "sentence-detokenized": "With his students Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Graves and others, Schmidhuber published increasingly sophisticated versions of a type of recurrent neural network called short-term memory (LSTM).", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 22], [23, 33], [33, 34], [35, 40], [41, 45], [45, 46], [47, 51], [52, 59], [59, 60], [61, 65], [66, 72], [73, 76], [77, 83], [83, 84], [85, 96], [97, 106], [107, 119], [120, 133], [134, 142], [143, 145], [146, 147], [148, 152], [153, 155], [156, 165], [166, 172], [173, 180], [181, 187], [188, 193], [193, 194], [194, 198], [199, 205], [206, 207], [207, 211], [211, 212], [212, 213]]}
{"doc_key": "ai-test-135", "ner": [[4, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "The", "first", "Cobot", "KUKA", "LBR", "3", "is", "launched", "."], "sentence-detokenized": "2004 - The first Cobot KUKA LBR 3 is launched.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 16], [17, 22], [23, 27], [28, 31], [32, 33], [34, 36], [37, 45], [45, 46]]}
{"doc_key": "ai-test-136", "ner": [[10, 13, "algorithm"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Two", "superficial", "approaches", "used", "to", "train", "and", "then", "disambiguate", "are", "the", "Naive", "Bayes", "classifier", "and", "decision", "trees", "."], "sentence-detokenized": "Two superficial approaches used to train and then disambiguate are the Naive Bayes classifier and decision trees.", "token2charspan": [[0, 3], [4, 15], [16, 26], [27, 31], [32, 34], [35, 40], [41, 44], [45, 49], [50, 62], [63, 66], [67, 70], [71, 76], [77, 82], [83, 93], [94, 97], [98, 106], [107, 112], [112, 113]]}
{"doc_key": "ai-test-137", "ner": [[5, 5, "misc"], [12, 13, "person"], [15, 17, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 12, 13, "origin", "", false, false], [5, 5, 15, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "practical", "forms", "of", "photography", "were", "introduced", "in", "January", "1839", "by", "Louis", "Daguerre", "and", "Henry", "Fox", "Talbot", "."], "sentence-detokenized": "The first practical forms of photography were introduced in January 1839 by Louis Daguerre and Henry Fox Talbot.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 25], [26, 28], [29, 40], [41, 45], [46, 56], [57, 59], [60, 67], [68, 72], [73, 75], [76, 81], [82, 90], [91, 94], [95, 100], [101, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-138", "ner": [[3, 4, "task"], [8, 9, "task"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 17, 18, "part-of", "task_part_of_field", false, false], [8, 9, 17, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "speech", "synthesis", ",", "combined", "with", "speech", "recognition", ",", "allows", "interaction", "with", "mobile", "devices", "through", "language", "processing", "interfaces", "."], "sentence-detokenized": "For example, speech synthesis, combined with speech recognition, allows interaction with mobile devices through language processing interfaces.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 19], [20, 29], [29, 30], [31, 39], [40, 44], [45, 51], [52, 63], [63, 64], [65, 71], [72, 83], [84, 88], [89, 95], [96, 103], [104, 111], [112, 120], [121, 131], [132, 142], [142, 143]]}
{"doc_key": "ai-test-139", "ner": [[0, 0, "product"], [14, 14, "programlang"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 14, 14, "general-affiliation", "", false, false], [0, 0, 16, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Phidgets", "can", "be", "programmed", "with", "a", "variety", "of", "programs", "and", "programming", "languages", ",", "from", "Java", "to", "Microsoft", "Excel", "."], "sentence-detokenized": "Phidgets can be programmed with a variety of programs and programming languages, from Java to Microsoft Excel.", "token2charspan": [[0, 8], [9, 12], [13, 15], [16, 26], [27, 31], [32, 33], [34, 41], [42, 44], [45, 53], [54, 57], [58, 69], [70, 79], [79, 80], [81, 85], [86, 90], [91, 93], [94, 103], [104, 109], [109, 110]]}
{"doc_key": "ai-test-140", "ner": [[2, 3, "field"], [9, 10, "researcher"], [13, 15, "misc"], [23, 24, "field"], [26, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 10, "origin", "", false, false], [9, 10, 23, 24, "general-affiliation", "topic_of_study", false, false], [9, 10, 26, 27, "general-affiliation", "topic_of_study", false, false], [13, 15, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "machine", "learning", "was", "coined", "in", "1959", "by", "Arthur", "Samuel", ",", "an", "American", "at", "IBM", "and", "a", "pioneer", "in", "the", "field", "of", "computer", "games", "and", "artificial", "intelligence", "."], "sentence-detokenized": "The term machine learning was coined in 1959 by Arthur Samuel, an American at IBM and a pioneer in the field of computer games and artificial intelligence.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 25], [26, 29], [30, 36], [37, 39], [40, 44], [45, 47], [48, 54], [55, 61], [61, 62], [63, 65], [66, 74], [75, 77], [78, 81], [82, 85], [86, 87], [88, 95], [96, 98], [99, 102], [103, 108], [109, 111], [112, 120], [121, 126], [127, 130], [131, 141], [142, 154], [154, 155]]}
{"doc_key": "ai-test-141", "ner": [[0, 1, "misc"], [2, 3, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Israeli", "poet", "David", "Avidan", ",", "fascinated", "by", "the", "technologies", "of", "the", "future", "and", "their", "relationship", "to", "art", ",", "wanted", "to", "explore", "the", "use", "of", "computers", "for", "writing", "literature", "."], "sentence-detokenized": "Israeli poet David Avidan, fascinated by the technologies of the future and their relationship to art, wanted to explore the use of computers for writing literature.", "token2charspan": [[0, 7], [8, 12], [13, 18], [19, 25], [25, 26], [27, 37], [38, 40], [41, 44], [45, 57], [58, 60], [61, 64], [65, 71], [72, 75], [76, 81], [82, 94], [95, 97], [98, 101], [101, 102], [103, 109], [110, 112], [113, 120], [121, 124], [125, 128], [129, 131], [132, 141], [142, 145], [146, 153], [154, 164], [164, 165]]}
{"doc_key": "ai-test-142", "ner": [[4, 5, "misc"], [9, 9, "organisation"], [15, 15, "location"], [25, 25, "location"], [27, 31, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 4, 5, "part-of", "", false, false], [27, 31, 25, 25, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "part", "of", "the", "GATEway", "project", "in", "2017", ",", "Oxbotica", "tested", "seven", "autonomous", "buses", "in", "Greenwich", ",", "navigating", "a", "three", "-", "kilometre", "riverside", "path", "near", "London", "'s", "The", "O2", "Arena", "on", "a", "route", "also", "used", "by", "pedestrians", "and", "cyclists", "."], "sentence-detokenized": "As part of the GATEway project in 2017, Oxbotica tested seven autonomous buses in Greenwich, navigating a three-kilometre riverside path near London's The O2 Arena on a route also used by pedestrians and cyclists.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 22], [23, 30], [31, 33], [34, 38], [38, 39], [40, 48], [49, 55], [56, 61], [62, 72], [73, 78], [79, 81], [82, 91], [91, 92], [93, 103], [104, 105], [106, 111], [111, 112], [112, 121], [122, 131], [132, 136], [137, 141], [142, 148], [148, 150], [151, 154], [155, 157], [158, 163], [164, 166], [167, 168], [169, 174], [175, 179], [180, 184], [185, 187], [188, 199], [200, 203], [204, 212], [212, 213]]}
{"doc_key": "ai-test-143", "ner": [[10, 11, "task"], [14, 16, "metrics"], [21, 26, "misc"], [28, 28, "metrics"], [30, 30, "metrics"], [33, 33, "metrics"], [35, 35, "metrics"], [37, 39, "metrics"], [42, 42, "metrics"], [44, 44, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[14, 16, 21, 26, "related-to", "is_a", false, false], [14, 16, 28, 28, "usage", "", false, false], [14, 16, 30, 30, "usage", "", false, false], [28, 28, 33, 33, "named", "same", false, false], [30, 30, 44, 44, "named", "same", false, false], [33, 33, 42, 42, "opposite", "", false, false], [33, 33, 44, 44, "opposite", "", false, false], [35, 35, 33, 33, "named", "", false, false], [37, 39, 33, 33, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["An", "unrelated", "but", "commonly", "used", "combination", "of", "basic", "statistics", "of", "information", "retrieval", "is", "the", "F", "-", "score", ",", "which", "is", "a", "harmonic", "(", "possibly", "weighted", ")", "average", "of", "recall", "and", "precision", ",", "where", "recall", "=", "sensitivity", "=", "true", "positive", "rate", ",", "but", "specificity", "and", "precision", "are", "entirely", "different", "measures", "."], "sentence-detokenized": "An unrelated but commonly used combination of basic statistics of information retrieval is the F-score, which is a harmonic (possibly weighted) average of recall and precision, where recall = sensitivity = true positive rate, but specificity and precision are entirely different measures.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 25], [26, 30], [31, 42], [43, 45], [46, 51], [52, 62], [63, 65], [66, 77], [78, 87], [88, 90], [91, 94], [95, 96], [96, 97], [97, 102], [102, 103], [104, 109], [110, 112], [113, 114], [115, 123], [124, 125], [125, 133], [134, 142], [142, 143], [144, 151], [152, 154], [155, 161], [162, 165], [166, 175], [175, 176], [177, 182], [183, 189], [190, 191], [192, 203], [204, 205], [206, 210], [211, 219], [220, 224], [224, 225], [226, 229], [230, 241], [242, 245], [246, 255], [256, 259], [260, 268], [269, 278], [279, 287], [287, 288]]}
{"doc_key": "ai-test-144", "ner": [[0, 1, "field"], [9, 9, "field"], [11, 11, "field"], [13, 13, "field"], [15, 16, "field"], [18, 19, "field"], [28, 29, "product"], [31, 34, "product"], [36, 37, "product"], [39, 40, "product"], [53, 55, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 9, 9, "origin", "takes_inspiration_from", false, false], [0, 1, 11, 11, "origin", "takes_inspiration_from", false, false], [0, 1, 13, 13, "origin", "takes_inspiration_from", false, false], [0, 1, 15, 16, "origin", "takes_inspiration_from", false, false], [0, 1, 18, 19, "origin", "takes_inspiration_from", false, false], [28, 29, 0, 1, "origin", "", false, false], [31, 34, 0, 1, "origin", "", false, false], [36, 37, 0, 1, "origin", "", false, false], [39, 40, 0, 1, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Neuromorphic", "engineering", "is", "an", "interdisciplinary", "subject", "that", "draws", "on", "biology", ",", "physics", ",", "mathematics", ",", "computer", "science", "and", "electronic", "engineering", "to", "design", "artificial", "neural", "systems", ",", "such", "as", "vision", "systems", ",", "head", "-", "eye", "systems", ",", "auditory", "processors", "and", "autonomous", "robots", ",", "whose", "physical", "architecture", "and", "design", "principles", "are", "based", "on", "those", "of", "biological", "nervous", "systems", "."], "sentence-detokenized": "Neuromorphic engineering is an interdisciplinary subject that draws on biology, physics, mathematics, computer science and electronic engineering to design artificial neural systems, such as vision systems, head-eye systems, auditory processors and autonomous robots, whose physical architecture and design principles are based on those of biological nervous systems.", "token2charspan": [[0, 12], [13, 24], [25, 27], [28, 30], [31, 48], [49, 56], [57, 61], [62, 67], [68, 70], [71, 78], [78, 79], [80, 87], [87, 88], [89, 100], [100, 101], [102, 110], [111, 118], [119, 122], [123, 133], [134, 145], [146, 148], [149, 155], [156, 166], [167, 173], [174, 181], [181, 182], [183, 187], [188, 190], [191, 197], [198, 205], [205, 206], [207, 211], [211, 212], [212, 215], [216, 223], [223, 224], [225, 233], [234, 244], [245, 248], [249, 259], [260, 266], [266, 267], [268, 273], [274, 282], [283, 295], [296, 299], [300, 306], [307, 317], [318, 321], [322, 327], [328, 330], [331, 336], [337, 339], [340, 350], [351, 358], [359, 366], [366, 367]]}
{"doc_key": "ai-test-145", "ner": [[4, 6, "metrics"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 10, 4, 6, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "particular", ",", "the", "BIBO", "stability", "criterion", "requires", "that", "the", "ROC", "of", "the", "system", "includes", "the", "unit", "circle", "."], "sentence-detokenized": "In particular, the BIBO stability criterion requires that the ROC of the system includes the unit circle.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 23], [24, 33], [34, 43], [44, 52], [53, 57], [58, 61], [62, 65], [66, 68], [69, 72], [73, 79], [80, 88], [89, 92], [93, 97], [98, 104], [104, 105]]}
{"doc_key": "ai-test-146", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "The", "programme", "was", "rewritten", "in", "Java", "as", "of", "1998", "."], "sentence-detokenized": "2 The programme was rewritten in Java as of 1998.", "token2charspan": [[0, 1], [2, 5], [6, 15], [16, 19], [20, 29], [30, 32], [33, 37], [38, 40], [41, 43], [44, 48], [48, 49]]}
{"doc_key": "ai-test-147", "ner": [[1, 1, "metrics"], [8, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 8, 9, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "MCC", "can", "be", "calculated", "directly", "from", "the", "confusion", "matrix", "using", "the", "formula", ":"], "sentence-detokenized": "The MCC can be calculated directly from the confusion matrix using the formula:", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 25], [26, 34], [35, 39], [40, 43], [44, 53], [54, 60], [61, 66], [67, 70], [71, 78], [78, 79]]}
{"doc_key": "ai-test-148", "ner": [[8, 13, "organisation"], [19, 24, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 13, 19, 24, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "developed", "by", "a", "team", "at", "the", "MIT", "-", "IBM", "Watson", "AI", "Lab", "and", "first", "presented", "at", "the", "2018", "International", "Conference", "on", "Learning", "Representations", "."], "sentence-detokenized": "It was developed by a team at the MIT-IBM Watson AI Lab and first presented at the 2018 International Conference on Learning Representations.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 29], [30, 33], [34, 37], [37, 38], [38, 41], [42, 48], [49, 51], [52, 55], [56, 59], [60, 65], [66, 75], [76, 78], [79, 82], [83, 87], [88, 101], [102, 112], [113, 115], [116, 124], [125, 140], [140, 141]]}
{"doc_key": "ai-test-149", "ner": [[2, 3, "metrics"], [16, 17, "metrics"], [19, 21, "metrics"], [47, 47, "metrics"], [49, 49, "metrics"], [55, 57, "metrics"], [60, 60, "metrics"], [62, 62, "metrics"], [64, 66, "metrics"], [71, 71, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[16, 17, 47, 47, "type-of", "", false, false], [16, 17, 55, 57, "related-to", "collapses_to_identity", false, false], [19, 21, 49, 49, "type-of", "", false, false], [19, 21, 55, 57, "related-to", "collapses_to_identity", false, false], [19, 21, 64, 66, "named", "same", false, false], [60, 60, 71, 71, "related-to", "collapses_to_identity", false, false], [62, 62, 71, 71, "related-to", "collapses_to_identity", false, false], [64, 66, 71, 71, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["When", "the", "TRUE", "prevalences", "of", "the", "two", "positive", "variables", "are", "equal", ",", "as", "assumed", "in", "the", "Fleiss", "kappa", "and", "F", "-", "score", ",", "i.e.", "the", "number", "of", "positive", "predictions", "matches", "the", "number", "of", "positive", "classes", "in", "the", "dichotomous", "(", "two", "-", "class", ")", "case", ",", "the", "different", "kappa", "and", "correlation", "measures", "collapse", "to", "identity", "with", "Youden", "'s", "J", ",", "and", "recall", ",", "precision", "and", "F", "-", "score", "are", "equally", "identical", "with", "accuracy", "."], "sentence-detokenized": "When the TRUE prevalences of the two positive variables are equal, as assumed in the Fleiss kappa and F-score, i.e. the number of positive predictions matches the number of positive classes in the dichotomous (two-class) case, the different kappa and correlation measures collapse to identity with Youden's J, and recall, precision and F-score are equally identical with accuracy.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 25], [26, 28], [29, 32], [33, 36], [37, 45], [46, 55], [56, 59], [60, 65], [65, 66], [67, 69], [70, 77], [78, 80], [81, 84], [85, 91], [92, 97], [98, 101], [102, 103], [103, 104], [104, 109], [109, 110], [111, 115], [116, 119], [120, 126], [127, 129], [130, 138], [139, 150], [151, 158], [159, 162], [163, 169], [170, 172], [173, 181], [182, 189], [190, 192], [193, 196], [197, 208], [209, 210], [210, 213], [213, 214], [214, 219], [219, 220], [221, 225], [225, 226], [227, 230], [231, 240], [241, 246], [247, 250], [251, 262], [263, 271], [272, 280], [281, 283], [284, 292], [293, 297], [298, 304], [304, 306], [307, 308], [308, 309], [310, 313], [314, 320], [320, 321], [322, 331], [332, 335], [336, 337], [337, 338], [338, 343], [344, 347], [348, 355], [356, 365], [366, 370], [371, 379], [379, 380]]}
{"doc_key": "ai-test-150", "ner": [[3, 9, "misc"], [7, 7, "misc"], [2, 2, "conference"], [13, 16, "task"], [17, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 9, 2, 2, "part-of", "", false, false], [3, 9, 2, 2, "physical", "", false, false], [3, 9, 2, 2, "temporal", "", false, false], [7, 7, 3, 9, "named", "", false, false], [13, 16, 3, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "2013", "NAACL", "Building", "Educational", "Applications", "(", "BEA", ")", "workshop", "hosted", "the", "inaugural", "NLI", "shared", "task", ".", "Tetreault", "et", "al", ",", "2013", "The", "competition", "resulted", "in", "29", "entries", "from", "teams", "around", "the", "world", ",", "24", "of", "which", "also", "published", "a", "paper", "describing", "their", "systems", "and", "approaches", "."], "sentence-detokenized": "The 2013 NAACL Building Educational Applications (BEA) workshop hosted the inaugural NLI shared task. Tetreault et al, 2013 The competition resulted in 29 entries from teams around the world, 24 of which also published a paper describing their systems and approaches.", "token2charspan": [[0, 3], [4, 8], [9, 14], [15, 23], [24, 35], [36, 48], [49, 50], [50, 53], [53, 54], [55, 63], [64, 70], [71, 74], [75, 84], [85, 88], [89, 95], [96, 100], [100, 101], [102, 111], [112, 114], [115, 117], [117, 118], [119, 123], [124, 127], [128, 139], [140, 148], [149, 151], [152, 154], [155, 162], [163, 167], [168, 173], [174, 180], [181, 184], [185, 190], [190, 191], [192, 194], [195, 197], [198, 203], [204, 208], [209, 218], [219, 220], [221, 226], [227, 237], [238, 243], [244, 251], [252, 255], [256, 266], [266, 267]]}
{"doc_key": "ai-test-151", "ner": [[0, 2, "algorithm"], [5, 7, "algorithm"], [15, 16, "misc"], [20, 21, "misc"], [37, 38, "misc"], [41, 42, "algorithm"], [45, 45, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 5, 7, "type-of", "", false, false], [0, 2, 15, 16, "related-to", "finds", false, false], [20, 21, 15, 16, "type-of", "", false, false], [45, 45, 41, 42, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Viterbi", "algorithm", "is", "a", "dynamic", "programming", "algorithm", "for", "finding", "the", "most", "probable", "sequence", "of", "hidden", "states", ",", "called", "the", "Viterbi", "path", ",", "which", "results", "in", "a", "sequence", "of", "observed", "events", ",", "especially", "in", "the", "context", "of", "Markov", "information", "sources", "and", "Hidden", "Markov", "Models", "(", "HMMs", ")", "."], "sentence-detokenized": "The Viterbi algorithm is a dynamic programming algorithm for finding the most probable sequence of hidden states, called the Viterbi path, which results in a sequence of observed events, especially in the context of Markov information sources and Hidden Markov Models (HMMs).", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 24], [25, 26], [27, 34], [35, 46], [47, 56], [57, 60], [61, 68], [69, 72], [73, 77], [78, 86], [87, 95], [96, 98], [99, 105], [106, 112], [112, 113], [114, 120], [121, 124], [125, 132], [133, 137], [137, 138], [139, 144], [145, 152], [153, 155], [156, 157], [158, 166], [167, 169], [170, 178], [179, 185], [185, 186], [187, 197], [198, 200], [201, 204], [205, 212], [213, 215], [216, 222], [223, 234], [235, 242], [243, 246], [247, 253], [254, 260], [261, 267], [268, 269], [269, 273], [273, 274], [274, 275]]}
{"doc_key": "ai-test-152", "ner": [[1, 1, "field"], [3, 5, "algorithm"], [8, 9, "misc"], [12, 13, "algorithm"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 1, 1, "part-of", "", false, false], [3, 5, 8, 9, "general-affiliation", "", false, false], [3, 5, 12, 13, "related-to", "generalizes_from", false, false], [3, 5, 15, 16, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "statistics", ",", "multinomial", "logistic", "regression", "is", "a", "classification", "method", "that", "generalises", "logistic", "regression", "to", "multiclass", "classification", ",", "i.e.", "with", "more", "than", "two", "possible", "discrete", "outcomes", "."], "sentence-detokenized": "In statistics, multinomial logistic regression is a classification method that generalises logistic regression to multiclass classification, i.e. with more than two possible discrete outcomes.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 26], [27, 35], [36, 46], [47, 49], [50, 51], [52, 66], [67, 73], [74, 78], [79, 90], [91, 99], [100, 110], [111, 113], [114, 124], [125, 139], [139, 140], [141, 145], [146, 150], [151, 155], [156, 160], [161, 164], [165, 173], [174, 182], [183, 191], [191, 192]]}
{"doc_key": "ai-test-153", "ner": [[0, 2, "algorithm"], [9, 10, "field"], [12, 14, "field"], [17, 17, "task"], [20, 20, "task"], [22, 23, "task"], [25, 26, "researcher"], [28, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 9, 10, "part-of", "", false, false], [0, 2, 12, 14, "part-of", "", false, false], [17, 17, 0, 2, "usage", "", true, false], [20, 20, 0, 2, "usage", "", true, false], [22, 23, 0, 2, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hidden", "Markov", "models", "are", "known", "for", "their", "applications", "to", "reinforcement", "learning", "and", "temporal", "pattern", "recognition", "such", "as", "speech", ",", "handwriting", "recognition", ",", "gesture", "recognition", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Hidden Markov models are known for their applications to reinforcement learning and temporal pattern recognition such as speech, handwriting recognition, gesture recognition, Thad Starner, Alex Pentland.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 30], [31, 34], [35, 40], [41, 53], [54, 56], [57, 70], [71, 79], [80, 83], [84, 92], [93, 100], [101, 112], [113, 117], [118, 120], [121, 127], [127, 128], [129, 140], [141, 152], [152, 153], [154, 161], [162, 173], [173, 174], [175, 179], [180, 187], [187, 188], [189, 193], [194, 202], [202, 203]]}
{"doc_key": "ai-test-154", "ner": [[6, 9, "misc"], [32, 34, "metrics"], [37, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 9, 37, 37, "named", "", false, false], [32, 34, 37, 37, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Essentially", ",", "this", "means", "that", "if", "the", "programme", "has", "been", "seen", "more", "than", "k", "times", "in", "training", ",", "the", "conditional", "probability", "of", "a", "word", "given", "it", "s", "history", "is", "proportional", "to", "the", "maximum", "likelihood", "estimate", "of", "that", "programme", "."], "sentence-detokenized": "Essentially, this means that if the programme has been seen more than k times in training, the conditional probability of a word given its history is proportional to the maximum likelihood estimate of that programme.", "token2charspan": [[0, 11], [11, 12], [13, 17], [18, 23], [24, 28], [29, 31], [32, 35], [36, 45], [46, 49], [50, 54], [55, 59], [60, 64], [65, 69], [70, 71], [72, 77], [78, 80], [81, 89], [89, 90], [91, 94], [95, 106], [107, 118], [119, 121], [122, 123], [124, 128], [129, 134], [135, 137], [137, 138], [139, 146], [147, 149], [150, 162], [163, 165], [166, 169], [170, 177], [178, 188], [189, 197], [198, 200], [201, 205], [206, 215], [215, 216]]}
{"doc_key": "ai-test-155", "ner": [[4, 5, "task"], [7, 8, "task"], [10, 12, "task"], [17, 19, "task"], [27, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[27, 28, 17, 19, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "interested", "in", "knowledge", "representation", ",", "commonsense", "reasoning", "and", "natural", "language", "understanding", ",", "and", "believes", "that", "deep", "language", "understanding", "can", "currently", "only", "be", "achieved", "through", "significant", "manual", "engineering", "of", "semantically", "rich", "formalisms", ",", "coupled", "with", "statistical", "preferences", "."], "sentence-detokenized": "He is interested in knowledge representation, commonsense reasoning and natural language understanding, and believes that deep language understanding can currently only be achieved through significant manual engineering of semantically rich formalisms, coupled with statistical preferences.", "token2charspan": [[0, 2], [3, 5], [6, 16], [17, 19], [20, 29], [30, 44], [44, 45], [46, 57], [58, 67], [68, 71], [72, 79], [80, 88], [89, 102], [102, 103], [104, 107], [108, 116], [117, 121], [122, 126], [127, 135], [136, 149], [150, 153], [154, 163], [164, 168], [169, 171], [172, 180], [181, 188], [189, 200], [201, 207], [208, 219], [220, 222], [223, 235], [236, 240], [241, 251], [251, 252], [253, 260], [261, 265], [266, 277], [278, 289], [289, 290]]}
{"doc_key": "ai-test-156", "ner": [[1, 1, "programlang"], [3, 3, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "JavaScript", ",", "Python", "or"], "sentence-detokenized": "In JavaScript, Python or", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 21], [22, 24]]}
{"doc_key": "ai-test-157", "ner": [[1, 2, "misc"], [7, 8, "misc"], [11, 11, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 7, 8, "part-of", "", false, false], [7, 8, 11, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Newcomb", "Awards", "are", "announced", "in", "the", "AI", "Magazine", "published", "by", "AAAI", "."], "sentence-detokenized": "The Newcomb Awards are announced in the AI Magazine published by AAAI.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 22], [23, 32], [33, 35], [36, 39], [40, 42], [43, 51], [52, 61], [62, 64], [65, 69], [69, 70]]}
{"doc_key": "ai-test-158", "ner": [[1, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "root", "mean", "square", "error", "on", "a", "test", "set", "of", "100", "specimens", "is", "0.084", ",", "which", "is", "smaller", "than", "the", "unstandardised", "error", "."], "sentence-detokenized": "The root mean square error on a test set of 100 specimens is 0.084, which is smaller than the unstandardised error.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 20], [21, 26], [27, 29], [30, 31], [32, 36], [37, 40], [41, 43], [44, 47], [48, 57], [58, 60], [61, 66], [66, 67], [68, 73], [74, 76], [77, 84], [85, 89], [90, 93], [94, 108], [109, 114], [114, 115]]}
{"doc_key": "ai-test-159", "ner": [[1, 3, "metrics"], [10, 12, "field"], [20, 22, "task"], [24, 24, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 12, 1, 3, "usage", "", false, false], [20, 22, 10, 12, "part-of", "task_part_of_field", false, false], [24, 24, 20, 22, "named", "", false, false], [27, 28, 10, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "F", "-", "score", "has", "been", "widely", "used", "in", "the", "natural", "language", "processing", "literature", ",", "such", "as", "the", "evaluation", "of", "named", "entity", "recognition", "(", "NER", ")", "and", "word", "segmentation", "."], "sentence-detokenized": "The F-score has been widely used in the natural language processing literature, such as the evaluation of named entity recognition (NER) and word segmentation.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 15], [16, 20], [21, 27], [28, 32], [33, 35], [36, 39], [40, 47], [48, 56], [57, 67], [68, 78], [78, 79], [80, 84], [85, 87], [88, 91], [92, 102], [103, 105], [106, 111], [112, 118], [119, 130], [131, 132], [132, 135], [135, 136], [137, 140], [141, 145], [146, 158], [158, 159]]}
{"doc_key": "ai-test-160", "ner": [[0, 0, "product"], [5, 7, "product"], [18, 19, "misc"], [21, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 18, 19, "related-to", "performs_task", false, false], [0, 0, 21, 22, "related-to", "performs_task", false, false], [5, 7, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Chatbots", "are", "typically", "used", "in", "dialogue", "systems", "for", "a", "variety", "of", "purposes", ",", "such", "as", "customer", "support", ",", "routing", "requests", "or", "gathering", "information", "."], "sentence-detokenized": "Chatbots are typically used in dialogue systems for a variety of purposes, such as customer support, routing requests or gathering information.", "token2charspan": [[0, 8], [9, 12], [13, 22], [23, 27], [28, 30], [31, 39], [40, 47], [48, 51], [52, 53], [54, 61], [62, 64], [65, 73], [73, 74], [75, 79], [80, 82], [83, 91], [92, 99], [99, 100], [101, 108], [109, 117], [118, 120], [121, 130], [131, 142], [142, 143]]}
{"doc_key": "ai-test-161", "ner": [[6, 12, "conference"], [16, 24, "conference"], [31, 40, "conference"], [46, 46, "conference"], [50, 53, "conference"], [55, 56, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[16, 24, 6, 12, "named", "", false, false], [31, 40, 6, 12, "named", "", false, false], [46, 46, 31, 40, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Among", "the", "most", "important", "journals", "are", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "later", "renamed", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "and", ",", "since", "September", "2014", ",", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", ",", "after", "merging", "with", "an", "ACM", "publication", ")", ",", "Computer", "Speech", "and", "Language", "and", "Speech", "Communication", "."], "sentence-detokenized": "Among the most important journals are IEEE Transactions on Speech and Audio Processing (later renamed IEEE Transactions on Audio, Speech and Language Processing and, since September 2014, IEEE/ACM Transactions on Audio, Speech and Language, after merging with an ACM publication), Computer Speech and Language and Speech Communication.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 24], [25, 33], [34, 37], [38, 42], [43, 55], [56, 58], [59, 65], [66, 69], [70, 75], [76, 86], [87, 88], [88, 93], [94, 101], [102, 106], [107, 119], [120, 122], [123, 128], [128, 129], [130, 136], [137, 140], [141, 149], [150, 160], [161, 164], [164, 165], [166, 171], [172, 181], [182, 186], [186, 187], [188, 192], [192, 193], [193, 196], [197, 209], [210, 212], [213, 218], [218, 219], [220, 226], [227, 230], [231, 239], [239, 240], [241, 246], [247, 254], [255, 259], [260, 262], [263, 266], [267, 278], [278, 279], [279, 280], [281, 289], [290, 296], [297, 300], [301, 309], [310, 313], [314, 320], [321, 334], [334, 335]]}
{"doc_key": "ai-test-162", "ner": [[0, 0, "algorithm"], [5, 6, "task"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 0, 0, "usage", "", false, false], [5, 6, 8, 9, "part-of", "task_part_of_field", false, false], [5, 6, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["EM", "is", "frequently", "used", "for", "data", "clustering", "in", "machine", "learning", "and", "computer", "vision", "."], "sentence-detokenized": "EM is frequently used for data clustering in machine learning and computer vision.", "token2charspan": [[0, 2], [3, 5], [6, 16], [17, 21], [22, 25], [26, 30], [31, 41], [42, 44], [45, 52], [53, 61], [62, 65], [66, 74], [75, 81], [81, 82]]}
{"doc_key": "ai-test-163", "ner": [[9, 11, "metrics"], [24, 27, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 24, 27, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["Although", "there", "is", "no", "perfect", "way", "to", "describe", "the", "confusion", "matrix", "of", "TRUE", "and", "FALSE", "positives", "and", "negatives", "with", "a", "single", "number", ",", "the", "Matthews", "correlation", "coefficient", "is", "generally", "considered", "to", "be", "one", "of", "the", "best", "such", "measures", "."], "sentence-detokenized": "Although there is no perfect way to describe the confusion matrix of TRUE and FALSE positives and negatives with a single number, the Matthews correlation coefficient is generally considered to be one of the best such measures.", "token2charspan": [[0, 8], [9, 14], [15, 17], [18, 20], [21, 28], [29, 32], [33, 35], [36, 44], [45, 48], [49, 58], [59, 65], [66, 68], [69, 73], [74, 77], [78, 83], [84, 93], [94, 97], [98, 107], [108, 112], [113, 114], [115, 121], [122, 128], [128, 129], [130, 133], [134, 142], [143, 154], [155, 166], [167, 169], [170, 179], [180, 190], [191, 193], [194, 196], [197, 200], [201, 203], [204, 207], [208, 212], [213, 217], [218, 226], [226, 227]]}
{"doc_key": "ai-test-164", "ner": [[13, 16, "field"], [30, 31, "field"], [38, 39, "field"], [43, 44, "algorithm"], [46, 47, "task"], [49, 50, "algorithm"], [55, 57, "algorithm"], [59, 60, "algorithm"], [66, 68, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[38, 39, 30, 31, "part-of", "subfield", false, false], [43, 44, 38, 39, "part-of", "", false, true], [46, 47, 38, 39, "part-of", "", false, true], [49, 50, 38, 39, "part-of", "", false, true], [55, 57, 38, 39, "part-of", "", false, true], [59, 60, 38, 39, "part-of", "", false, true], [66, 68, 38, 39, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "data", "sets", "have", "grown", "in", "size", "and", "complexity", ",", "direct", "and", "practical", "data", "analysis", "has", "been", "augmented", "by", "indirect", "and", "automated", "data", "processing", ",", "aided", "by", "other", "discoveries", "in", "computer", "science", ",", "especially", "in", "the", "field", "of", "machine", "learning", ",", "such", "as", "neural", "networks", ",", "cluster", "analysis", ",", "genetic", "algorithms", "(", "1950s", ")", ",", "decision", "tree", "learning", "and", "decision", "rules", "(", "1960s", ")", ",", "and", "support", "vector", "machines", "(", "1990", "s", ")", "."], "sentence-detokenized": "As data sets have grown in size and complexity, direct and practical data analysis has been augmented by indirect and automated data processing, aided by other discoveries in computer science, especially in the field of machine learning, such as neural networks, cluster analysis, genetic algorithms (1950s), decision tree learning and decision rules (1960s), and support vector machines (1990s).", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 17], [18, 23], [24, 26], [27, 31], [32, 35], [36, 46], [46, 47], [48, 54], [55, 58], [59, 68], [69, 73], [74, 82], [83, 86], [87, 91], [92, 101], [102, 104], [105, 113], [114, 117], [118, 127], [128, 132], [133, 143], [143, 144], [145, 150], [151, 153], [154, 159], [160, 171], [172, 174], [175, 183], [184, 191], [191, 192], [193, 203], [204, 206], [207, 210], [211, 216], [217, 219], [220, 227], [228, 236], [236, 237], [238, 242], [243, 245], [246, 252], [253, 261], [261, 262], [263, 270], [271, 279], [279, 280], [281, 288], [289, 299], [300, 301], [301, 306], [306, 307], [307, 308], [309, 317], [318, 322], [323, 331], [332, 335], [336, 344], [345, 350], [351, 352], [352, 357], [357, 358], [358, 359], [360, 363], [364, 371], [372, 378], [379, 387], [388, 389], [389, 393], [393, 394], [394, 395], [395, 396]]}
{"doc_key": "ai-test-165", "ner": [[4, 4, "researcher"], [9, 10, "misc"], [18, 19, "researcher"], [21, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 4, 4, "artifact", "", false, false], [9, 10, 18, 19, "artifact", "", false, false], [9, 10, 21, 22, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "autumn", "2005", ",", "Thrun", "published", "a", "textbook", "entitled", "Probabilistic", "Robotics", "together", "with", "his", "long", "-", "time", "collaborators", "Dieter", "Fox", "and", "Wolfram", "Burgard", "."], "sentence-detokenized": "In autumn 2005, Thrun published a textbook entitled Probabilistic Robotics together with his long-time collaborators Dieter Fox and Wolfram Burgard.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 21], [22, 31], [32, 33], [34, 42], [43, 51], [52, 65], [66, 74], [75, 83], [84, 88], [89, 92], [93, 97], [97, 98], [98, 102], [103, 116], [117, 123], [124, 127], [128, 131], [132, 139], [140, 147], [147, 148]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "and", "Pereiramath", "as", "follows", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum and Pereiramath as follows:", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 37], [38, 49], [50, 52], [53, 60], [60, 61]]}
{"doc_key": "ai-test-167", "ner": [[0, 1, "task"], [3, 3, "task"], [14, 15, "field"], [17, 19, "field"], [21, 21, "field"]], "ner_mapping_to_source": [0, 1, 3, 4, 5], "relations": [[0, 1, 14, 15, "part-of", "task_part_of_field", false, false], [0, 1, 17, 19, "part-of", "task_part_of_field", false, false], [3, 3, 0, 1, "named", "", false, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 5], "sentence": ["Question", "answering", "(", "QA", ")", "is", "a", "computer", "science", "discipline", "within", "the", "fields", "of", "information", "retrieval", "and", "natural", "language", "processing", "(", "NLP", ")", ",", "which", "is", "concerned", "with", "building", "systems", "that", "automatically", "answer", "questions", "posed", "by", "humans", "in", "natural", "language", "."], "sentence-detokenized": "Question answering (QA) is a computer science discipline within the fields of information retrieval and natural language processing (NLP), which is concerned with building systems that automatically answer questions posed by humans in natural language.", "token2charspan": [[0, 8], [9, 18], [19, 20], [20, 22], [22, 23], [24, 26], [27, 28], [29, 37], [38, 45], [46, 56], [57, 63], [64, 67], [68, 74], [75, 77], [78, 89], [90, 99], [100, 103], [104, 111], [112, 120], [121, 131], [132, 133], [133, 136], [136, 137], [137, 138], [139, 144], [145, 147], [148, 157], [158, 162], [163, 171], [172, 179], [180, 184], [185, 198], [199, 205], [206, 215], [216, 221], [222, 224], [225, 231], [232, 234], [235, 242], [243, 251], [251, 252]]}
{"doc_key": "ai-test-168", "ner": [[10, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "in", "the", "version", "of", "the", "metric", "used", "by", "NIST", "assessments", "prior", "to", "2009", ",", "the", "shorter", "reference", "phrase", "was", "used", "."], "sentence-detokenized": "However, in the version of the metric used by NIST assessments prior to 2009, the shorter reference phrase was used.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 37], [38, 42], [43, 45], [46, 50], [51, 62], [63, 68], [69, 71], [72, 76], [76, 77], [78, 81], [82, 89], [90, 99], [100, 106], [107, 110], [111, 115], [115, 116]]}
{"doc_key": "ai-test-169", "ner": [[5, 5, "person"], [13, 13, "organisation"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 15, 15, "related-to", "invests_in", false, false], [15, 15, 13, 13, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["On", "27", "August", "2018", ",", "Toyota", "announced", "a", "$", "500", "million", "investment", "in", "Uber", "'s", "autonomous", "cars", "."], "sentence-detokenized": "On 27 August 2018, Toyota announced a $500 million investment in Uber's autonomous cars.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 17], [17, 18], [19, 25], [26, 35], [36, 37], [38, 39], [39, 42], [43, 50], [51, 61], [62, 64], [65, 69], [69, 71], [72, 82], [83, 87], [87, 88]]}
{"doc_key": "ai-test-170", "ner": [[5, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sample", "maximum", "is", "the", "maximum", "likelihood", "estimator", "for", "the", "population", "maximum", ",", "but", ",", "as", "discussed", "above", ",", "it", "is", "biased", "."], "sentence-detokenized": "The sample maximum is the maximum likelihood estimator for the population maximum, but, as discussed above, it is biased.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 21], [22, 25], [26, 33], [34, 44], [45, 54], [55, 58], [59, 62], [63, 73], [74, 81], [81, 82], [83, 86], [86, 87], [88, 90], [91, 100], [101, 106], [106, 107], [108, 110], [111, 113], [114, 120], [120, 121]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [3, 3, "misc"], [6, 6, "metrics"], [15, 17, "algorithm"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 3, "related-to", "overcomes", false, false], [0, 0, 6, 6, "related-to", "increases", false, false], [3, 3, 15, 17, "opposite", "", false, false], [3, 3, 19, 21, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LSI", "helps", "overcome", "synonymy", "by", "increasing", "recall", ",", "one", "of", "the", "most", "problematic", "limitations", "of", "Boolean", "keyword", "queries", "and", "vector", "space", "models", "."], "sentence-detokenized": "LSI helps overcome synonymy by increasing recall, one of the most problematic limitations of Boolean keyword queries and vector space models.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 27], [28, 30], [31, 41], [42, 48], [48, 49], [50, 53], [54, 56], [57, 60], [61, 65], [66, 77], [78, 89], [90, 92], [93, 100], [101, 108], [109, 116], [117, 120], [121, 127], [128, 133], [134, 140], [140, 141]]}
{"doc_key": "ai-test-172", "ner": [[0, 1, "task"], [21, 21, "programlang"], [23, 23, "programlang"], [25, 25, "programlang"], [27, 28, "programlang"], [30, 30, "programlang"], [32, 32, "programlang"], [34, 34, "programlang"], [36, 36, "programlang"], [38, 38, "programlang"], [40, 40, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 21, 21, "general-affiliation", "", false, false], [0, 1, 23, 23, "general-affiliation", "", false, false], [0, 1, 25, 25, "general-affiliation", "", false, false], [0, 1, 27, 28, "general-affiliation", "", false, false], [0, 1, 30, 30, "general-affiliation", "", false, false], [0, 1, 32, 32, "general-affiliation", "", false, false], [0, 1, 34, 34, "general-affiliation", "", false, false], [0, 1, 36, 36, "general-affiliation", "", false, false], [0, 1, 38, 38, "general-affiliation", "", false, false], [0, 1, 40, 40, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Data", "acquisition", "applications", "are", "typically", "controlled", "by", "software", "programmes", "developed", "in", "a", "variety", "of", "general", "purpose", "programming", "languages", ",", "such", "as", "Assembly", ",", "BASIC", ",", "C", ",", "C", "+", ",", "C#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", ",", "etc."], "sentence-detokenized": "Data acquisition applications are typically controlled by software programmes developed in a variety of general purpose programming languages, such as Assembly, BASIC, C, C+, C#, Fortran, Java, LabVIEW, Lisp, Pascal, etc.", "token2charspan": [[0, 4], [5, 16], [17, 29], [30, 33], [34, 43], [44, 54], [55, 57], [58, 66], [67, 77], [78, 87], [88, 90], [91, 92], [93, 100], [101, 103], [104, 111], [112, 119], [120, 131], [132, 141], [141, 142], [143, 147], [148, 150], [151, 159], [159, 160], [161, 166], [166, 167], [168, 169], [169, 170], [171, 172], [172, 173], [173, 174], [175, 177], [177, 178], [179, 186], [186, 187], [188, 192], [192, 193], [194, 201], [201, 202], [203, 207], [207, 208], [209, 215], [215, 216], [217, 221]]}
{"doc_key": "ai-test-173", "ner": [[3, 3, "organisation"], [6, 6, "product"], [10, 10, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 3, 3, "artifact", "", false, false], [6, 6, 10, 10, "physical", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2003", ",", "Honda", "launched", "its", "Cog", "advertisement", "in", "the", "UK", "and", "on", "the", "Internet", "."], "sentence-detokenized": "In 2003, Honda launched its Cog advertisement in the UK and on the Internet.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 27], [28, 31], [32, 45], [46, 48], [49, 52], [53, 55], [56, 59], [60, 62], [63, 66], [67, 75], [75, 76]]}
{"doc_key": "ai-test-174", "ner": [[1, 4, "conference"], [6, 7, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 4, 6, 7, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Association", "for", "Computational", "Linguistics", "defines", "computational", "linguistics", "as", ":"], "sentence-detokenized": "The Association for Computational Linguistics defines computational linguistics as:", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 33], [34, 45], [46, 53], [54, 67], [68, 79], [80, 82], [82, 83]]}
{"doc_key": "ai-test-175", "ner": [[0, 2, "algorithm"], [9, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 11, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["Expectation", "maximisation", "algorithms", "can", "be", "used", "to", "compute", "approximate", "maximum", "likelihood", "estimates", "of", "the", "unknown", "state", "space", "parameters", "within", "filters", "and", "minimum", "variance", "smoothers", "."], "sentence-detokenized": "Expectation maximisation algorithms can be used to compute approximate maximum likelihood estimates of the unknown state space parameters within filters and minimum variance smoothers.", "token2charspan": [[0, 11], [12, 24], [25, 35], [36, 39], [40, 42], [43, 47], [48, 50], [51, 58], [59, 70], [71, 78], [79, 89], [90, 99], [100, 102], [103, 106], [107, 114], [115, 120], [121, 126], [127, 137], [138, 144], [145, 152], [153, 156], [157, 164], [165, 173], [174, 183], [183, 184]]}
{"doc_key": "ai-test-176", "ner": [[3, 3, "misc"], [5, 7, "person"], [9, 10, "person"], [12, 13, "person"], [16, 17, "misc"], [18, 19, "person"], [22, 23, "person"], [27, 27, "person"], [29, 30, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 7, 3, 3, "role", "actor_in", false, false], [9, 10, 3, 3, "role", "actor_in", false, false], [12, 13, 3, 3, "role", "actor_in", false, false], [18, 19, 16, 17, "role", "model_for", false, false], [27, 27, 29, 30, "social", "family", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Correspondents", "included", "former", "Baywatch", "actresses", "Donna", "D'", "Errico", ",", "Carmen", "Electra", "and", "Traci", "Bingham", ",", "former", "Playboy", "Playmate", "Heidi", "Mark", ",", "comedian", "Arj", "Barker", "and", "identical", "twins", "Randy", "and", "Jason", "Sklar", "."], "sentence-detokenized": "Correspondents included former Baywatch actresses Donna D'Errico, Carmen Electra and Traci Bingham, former Playboy Playmate Heidi Mark, comedian Arj Barker and identical twins Randy and Jason Sklar.", "token2charspan": [[0, 14], [15, 23], [24, 30], [31, 39], [40, 49], [50, 55], [56, 58], [58, 64], [64, 65], [66, 72], [73, 80], [81, 84], [85, 90], [91, 98], [98, 99], [100, 106], [107, 114], [115, 123], [124, 129], [130, 134], [134, 135], [136, 144], [145, 148], [149, 155], [156, 159], [160, 169], [170, 175], [176, 181], [182, 185], [186, 191], [192, 197], [197, 198]]}
{"doc_key": "ai-test-177", "ner": [[8, 9, "task"], [11, 11, "task"], [16, 18, "product"], [21, 22, "task"], [24, 27, "task"], [29, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 8, 9, "named", "", false, false], [16, 18, 8, 9, "general-affiliation", "", false, false], [24, 27, 21, 22, "named", "", false, false], [29, 30, 21, 22, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "is", "commonly", "used", "to", "generate", "representations", "for", "speech", "recognition", "(", "ASR", ")", ",", "e.g.", "the", "CMU", "Sphinx", "system", ",", "and", "speech", "synthesis", "(", "TTS", ")", ",", "e.g.", "the", "Festival", "system", "."], "sentence-detokenized": "It is commonly used to generate representations for speech recognition (ASR), e.g. the CMU Sphinx system, and speech synthesis (TTS), e.g. the Festival system.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 19], [20, 22], [23, 31], [32, 47], [48, 51], [52, 58], [59, 70], [71, 72], [72, 75], [75, 76], [76, 77], [78, 82], [83, 86], [87, 90], [91, 97], [98, 104], [104, 105], [106, 109], [110, 116], [117, 126], [127, 128], [128, 131], [131, 132], [132, 133], [134, 138], [139, 142], [143, 151], [152, 158], [158, 159]]}
{"doc_key": "ai-test-178", "ner": [[0, 1, "metrics"], [3, 5, "metrics"], [7, 7, "metrics"], [13, 13, "metrics"], [28, 28, "metrics"], [30, 30, "metrics"], [41, 42, "metrics"], [44, 44, "metrics"], [46, 48, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 5, 0, 1, "named", "", false, false], [7, 7, 3, 5, "named", "", false, false], [13, 13, 0, 1, "named", "", false, false], [30, 30, 28, 28, "named", "", false, false], [44, 44, 41, 42, "named", "", false, false], [46, 48, 41, 42, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "sensitivity", "or", "True", "Positive", "Rate", "(", "TPR", ")", ",", "also", "known", "as", "recall", ",", "is", "the", "proportion", "of", "people", "who", "test", "positive", "and", "are", "positive", "(", "True", "Positive", ",", "TP", ")", "out", "of", "all", "people", "who", "are", "actually", "positive", "(", "Condition", "Positive", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "The sensitivity or True Positive Rate (TPR), also known as recall, is the proportion of people who test positive and are positive (True Positive, TP) out of all people who are actually positive (Condition Positive, CP = TP + FN).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 23], [24, 32], [33, 37], [38, 39], [39, 42], [42, 43], [43, 44], [45, 49], [50, 55], [56, 58], [59, 65], [65, 66], [67, 69], [70, 73], [74, 84], [85, 87], [88, 94], [95, 98], [99, 103], [104, 112], [113, 116], [117, 120], [121, 129], [130, 131], [131, 135], [136, 144], [144, 145], [146, 148], [148, 149], [150, 153], [154, 156], [157, 160], [161, 167], [168, 171], [172, 175], [176, 184], [185, 193], [194, 195], [195, 204], [205, 213], [213, 214], [215, 217], [218, 219], [220, 222], [223, 224], [225, 227], [227, 228], [228, 229]]}
{"doc_key": "ai-test-179", "ner": [[4, 5, "task"], [13, 13, "conference"], [15, 16, "conference"], [18, 18, "conference"], [20, 20, "conference"], [22, 22, "conference"], [24, 25, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 13, 4, 5, "topic", "", false, false], [15, 16, 4, 5, "topic", "", false, false], [18, 18, 4, 5, "topic", "", false, false], [20, 20, 4, 5, "topic", "", false, false], [22, 22, 4, 5, "topic", "", false, false], [24, 25, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Among", "the", "most", "popular", "speech", "recognition", "conferences", "held", "every", "year", "or", "two", "are", "SpeechTEK", "and", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", "and", "IEEE", "ASRU", "."], "sentence-detokenized": "Among the most popular speech recognition conferences held every year or two are SpeechTEK and SpeechTEK Europe, ICASSP, Interspeech / Eurospeech and IEEE ASRU.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 22], [23, 29], [30, 41], [42, 53], [54, 58], [59, 64], [65, 69], [70, 72], [73, 76], [77, 80], [81, 90], [91, 94], [95, 104], [105, 111], [111, 112], [113, 119], [119, 120], [121, 132], [133, 134], [135, 145], [146, 149], [150, 154], [155, 159], [159, 160]]}
{"doc_key": "ai-test-180", "ner": [[0, 0, "researcher"], [3, 3, "researcher"], [17, 18, "product"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 21, 0, 0, "artifact", "", false, false], [21, 21, 3, 3, "artifact", "", false, false], [21, 21, 17, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Devol", "collaborated", "with", "Engelberger", ",", "who", "was", "president", "of", "the", "company", ",", "to", "design", "and", "produce", "an", "industrial", "robot", "under", "the", "Unimate", "brand", "."], "sentence-detokenized": "Devol collaborated with Engelberger, who was president of the company, to design and produce an industrial robot under the Unimate brand.", "token2charspan": [[0, 5], [6, 18], [19, 23], [24, 35], [35, 36], [37, 40], [41, 44], [45, 54], [55, 57], [58, 61], [62, 69], [69, 70], [71, 73], [74, 80], [81, 84], [85, 92], [93, 95], [96, 106], [107, 112], [113, 118], [119, 122], [123, 130], [131, 136], [136, 137]]}
{"doc_key": "ai-test-181", "ner": [[1, 3, "algorithm"], [5, 7, "algorithm"], [9, 11, "algorithm"], [22, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 3, 9, 11, "general-affiliation", "", false, false], [5, 7, 1, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "hidden", "Markov", "model", "(", "HMM", ")", "is", "a", "statistical", "Markov", "model", "in", "which", "the", "modelled", "system", "is", "assumed", "to", "be", "a", "Markov", "process", "with", "unobserved", "(", "hidden", ")", "states", "."], "sentence-detokenized": "A hidden Markov model (HMM) is a statistical Markov model in which the modelled system is assumed to be a Markov process with unobserved (hidden) states.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [22, 23], [23, 26], [26, 27], [28, 30], [31, 32], [33, 44], [45, 51], [52, 57], [58, 60], [61, 66], [67, 70], [71, 79], [80, 86], [87, 89], [90, 97], [98, 100], [101, 103], [104, 105], [106, 112], [113, 120], [121, 125], [126, 136], [137, 138], [138, 144], [144, 145], [146, 152], [152, 153]]}
{"doc_key": "ai-test-182", "ner": [[16, 18, "metrics"], [25, 25, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "property", ",", "undesirable", "in", "many", "applications", ",", "has", "led", "researchers", "to", "use", "alternatives", "such", "as", "mean", "absolute", "error", ",", "or", "those", "based", "on", "the", "median", "."], "sentence-detokenized": "This property, undesirable in many applications, has led researchers to use alternatives such as mean absolute error, or those based on the median.", "token2charspan": [[0, 4], [5, 13], [13, 14], [15, 26], [27, 29], [30, 34], [35, 47], [47, 48], [49, 52], [53, 56], [57, 68], [69, 71], [72, 75], [76, 88], [89, 93], [94, 96], [97, 101], [102, 110], [111, 116], [116, 117], [118, 120], [121, 126], [127, 132], [133, 135], [136, 139], [140, 146], [146, 147]]}
{"doc_key": "ai-test-183", "ner": [[23, 24, "algorithm"], [32, 33, "field"], [36, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 24, 32, 33, "part-of", "", false, false], [23, 24, 36, 38, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Such", "a", "sequence", "(", "which", "depends", "on", "the", "outcome", "of", "the", "investigation", "of", "the", "previous", "attributes", "at", "each", "stage", ")", "is", "called", "a", "decision", "tree", "and", "is", "applied", "in", "the", "field", "of", "machine", "learning", "known", "as", "decision", "tree", "learning", "."], "sentence-detokenized": "Such a sequence (which depends on the outcome of the investigation of the previous attributes at each stage) is called a decision tree and is applied in the field of machine learning known as decision tree learning.", "token2charspan": [[0, 4], [5, 6], [7, 15], [16, 17], [17, 22], [23, 30], [31, 33], [34, 37], [38, 45], [46, 48], [49, 52], [53, 66], [67, 69], [70, 73], [74, 82], [83, 93], [94, 96], [97, 101], [102, 107], [107, 108], [109, 111], [112, 118], [119, 120], [121, 129], [130, 134], [135, 138], [139, 141], [142, 149], [150, 152], [153, 156], [157, 162], [163, 165], [166, 173], [174, 182], [183, 188], [189, 191], [192, 200], [201, 205], [206, 214], [214, 215]]}
{"doc_key": "ai-test-184", "ner": [[2, 3, "task"], [5, 5, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 5, 5, "compare", "", false, false], [19, 20, 5, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "in", "factor", "analysis", ",", "LCA", "can", "also", "be", "used", "to", "classify", "cases", "according", "to", "their", "membership", "of", "a", "maximum", "likelihood", "class", "."], "sentence-detokenized": "As in factor analysis, LCA can also be used to classify cases according to their membership of a maximum likelihood class.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 21], [21, 22], [23, 26], [27, 30], [31, 35], [36, 38], [39, 43], [44, 46], [47, 55], [56, 61], [62, 71], [72, 74], [75, 80], [81, 91], [92, 94], [95, 96], [97, 104], [105, 115], [116, 121], [121, 122]]}
{"doc_key": "ai-test-185", "ner": [[0, 2, "algorithm"], [5, 7, "metrics"], [9, 9, "metrics"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 7, "usage", "", false, false], [5, 7, 11, 12, "related-to", "", false, false], [9, 9, 5, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Supervised", "neural", "networks", "using", "a", "mean", "square", "error", "(", "MSE", ")", "cost", "function", "can", "use", "formal", "statistical", "methods", "to", "determine", "the", "confidence", "of", "the", "trained", "model", "."], "sentence-detokenized": "Supervised neural networks using a mean square error (MSE) cost function can use formal statistical methods to determine the confidence of the trained model.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 32], [33, 34], [35, 39], [40, 46], [47, 52], [53, 54], [54, 57], [57, 58], [59, 63], [64, 72], [73, 76], [77, 80], [81, 87], [88, 99], [100, 107], [108, 110], [111, 120], [121, 124], [125, 135], [136, 138], [139, 142], [143, 150], [151, 156], [156, 157]]}
{"doc_key": "ai-test-186", "ner": [[16, 17, "algorithm"], [20, 22, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 17, 20, 22, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "can", "be", "expressed", "directly", "as", "a", "linear", "programme", ",", "but", "is", "also", "equivalent", "to", "the", "Tikhonov", "regularisation", "with", "the", "hinge", "loss", "function", ",", "mathV", "(", "f", "(", "x", ")", ",", "y", ")", "=", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "math", ":"], "sentence-detokenized": "This can be expressed directly as a linear programme, but is also equivalent to the Tikhonov regularisation with the hinge loss function, mathV (f (x), y) = max (0, 1 - yf (x)) / math:", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 21], [22, 30], [31, 33], [34, 35], [36, 42], [43, 52], [52, 53], [54, 57], [58, 60], [61, 65], [66, 76], [77, 79], [80, 83], [84, 92], [93, 107], [108, 112], [113, 116], [117, 122], [123, 127], [128, 136], [136, 137], [138, 143], [144, 145], [145, 146], [147, 148], [148, 149], [149, 150], [150, 151], [152, 153], [153, 154], [155, 156], [157, 160], [161, 162], [162, 163], [163, 164], [165, 166], [167, 168], [169, 171], [172, 173], [173, 174], [174, 175], [175, 176], [177, 178], [179, 183], [183, 184]]}
{"doc_key": "ai-test-187", "ner": [[15, 17, "product"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "technique", "is", "described", "in", "Breiman", "'s", "original", "paper", "and", "is", "implemented", "in", "the", "R", "package", "randomForest", "."], "sentence-detokenized": "The following technique is described in Breiman's original paper and is implemented in the R package randomForest.", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 26], [27, 36], [37, 39], [40, 47], [47, 49], [50, 58], [59, 64], [65, 68], [69, 71], [72, 83], [84, 86], [87, 90], [91, 92], [93, 100], [101, 113], [113, 114]]}
{"doc_key": "ai-test-188", "ner": [[8, 8, "metrics"], [39, 40, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "measures", "of", "image", "quality", ",", "such", "as", "PSNR", ",", "are", "usually", "performed", "with", "fixed", "resolution", "images", "and", "do", "not", "take", "into", "account", "some", "aspects", "of", "the", "human", "visual", "system", ",", "such", "as", "the", "change", "of", "spatial", "resolution", "in", "the", "retina", "."], "sentence-detokenized": "Traditional measures of image quality, such as PSNR, are usually performed with fixed resolution images and do not take into account some aspects of the human visual system, such as the change of spatial resolution in the retina.", "token2charspan": [[0, 11], [12, 20], [21, 23], [24, 29], [30, 37], [37, 38], [39, 43], [44, 46], [47, 51], [51, 52], [53, 56], [57, 64], [65, 74], [75, 79], [80, 85], [86, 96], [97, 103], [104, 107], [108, 110], [111, 114], [115, 119], [120, 124], [125, 132], [133, 137], [138, 145], [146, 148], [149, 152], [153, 158], [159, 165], [166, 172], [172, 173], [174, 178], [179, 181], [182, 185], [186, 192], [193, 195], [196, 203], [204, 214], [215, 217], [218, 221], [222, 228], [228, 229]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [10, 12, "person"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 15, 16, "role", "", false, false], [3, 4, 15, 16, "role", "", false, false], [6, 7, 15, 16, "role", "", false, false], [15, 16, 10, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Dru", "and", "Macdonald", "Carey", "starred", "in", "Jack", "Broder", "'s", "colour", "production", "Hannah", "Lee", ",", "released", "on", "19", "June", "1953", "."], "sentence-detokenized": "John Ireland, Joanne Dru and Macdonald Carey starred in Jack Broder's colour production Hannah Lee, released on 19 June 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 55], [56, 60], [61, 67], [67, 69], [70, 76], [77, 87], [88, 94], [95, 98], [98, 99], [100, 108], [109, 111], [112, 114], [115, 119], [120, 124], [124, 125]]}
{"doc_key": "ai-test-190", "ner": [[4, 5, "task"], [10, 11, "field"], [17, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 10, 11, "usage", "", false, false], [17, 17, 10, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "process", "is", "called", "image", "registration", ",", "and", "uses", "different", "computer", "vision", "methods", ",", "mostly", "related", "to", "tracking", "."], "sentence-detokenized": "This process is called image registration, and uses different computer vision methods, mostly related to tracking.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 22], [23, 28], [29, 41], [41, 42], [43, 46], [47, 51], [52, 61], [62, 70], [71, 77], [78, 85], [85, 86], [87, 93], [94, 101], [102, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-test-191", "ner": [[17, 18, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Let", "us", "now", "begin", "to", "explain", "the", "different", "possible", "relationships", "between", "the", "expected", "and", "actual", "outcome", ":", "Confusion", "matrix", "."], "sentence-detokenized": "Let us now begin to explain the different possible relationships between the expected and actual outcome: Confusion matrix.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [17, 19], [20, 27], [28, 31], [32, 41], [42, 50], [51, 64], [65, 72], [73, 76], [77, 85], [86, 89], [90, 96], [97, 104], [104, 105], [106, 115], [116, 122], [122, 123]]}
{"doc_key": "ai-test-192", "ner": [[1, 1, "product"], [2, 4, "misc"], [6, 6, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 2, 4, "part-of", "", false, false], [1, 1, 2, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "VOICEBOX", "speech", "processing", "toolbox", "for", "MATLAB", "implements", "the", "conversion", "and", "its", "inverse", "as", ":"], "sentence-detokenized": "The VOICEBOX speech processing toolbox for MATLAB implements the conversion and its inverse as:", "token2charspan": [[0, 3], [4, 12], [13, 19], [20, 30], [31, 38], [39, 42], [43, 49], [50, 60], [61, 64], [65, 75], [76, 79], [80, 83], [84, 91], [92, 94], [94, 95]]}
{"doc_key": "ai-test-193", "ner": [[0, 0, "programlang"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 9, "general-affiliation", "", false, false], [0, 0, 11, 12, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "is", "a", "logic", "programming", "language", "associated", "with", "artificial", "intelligence", "and", "computational", "linguistics", "."], "sentence-detokenized": "Prolog is a logic programming language associated with artificial intelligence and computational linguistics.", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 17], [18, 29], [30, 38], [39, 49], [50, 54], [55, 65], [66, 78], [79, 82], [83, 96], [97, 108], [108, 109]]}
{"doc_key": "ai-test-194", "ner": [[0, 0, "researcher"], [9, 9, "field"], [11, 11, "field"], [17, 20, "organisation"], [23, 26, "organisation"], [29, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 9, 9, "related-to", "works_with_topic", false, false], [0, 0, 11, 11, "related-to", "works_with_topic", false, false], [0, 0, 17, 20, "role", "", false, false], [0, 0, 23, 26, "role", "", false, false], [0, 0, 29, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "has", "received", "numerous", "awards", "for", "his", "contributions", "to", "neuroscience", "and", "psychology", ",", "including", "membership", "in", "the", "Royal", "Society", "of", "London", ",", "the", "Royal", "Society", "of", "Canada", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner has received numerous awards for his contributions to neuroscience and psychology, including membership in the Royal Society of London, the Royal Society of Canada and the National Academy of Sciences.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 28], [29, 35], [36, 39], [40, 43], [44, 57], [58, 60], [61, 73], [74, 77], [78, 88], [88, 89], [90, 99], [100, 110], [111, 113], [114, 117], [118, 123], [124, 131], [132, 134], [135, 141], [141, 142], [143, 146], [147, 152], [153, 160], [161, 163], [164, 170], [171, 174], [175, 178], [179, 187], [188, 195], [196, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-test-195", "ner": [[11, 16, "field"], [17, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "task"], [29, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[17, 18, 11, 16, "part-of", "task_part_of_field", false, false], [20, 21, 11, 16, "part-of", "task_part_of_field", false, false], [23, 24, 11, 16, "part-of", "task_part_of_field", false, false], [26, 27, 11, 16, "part-of", "task_part_of_field", false, false], [29, 29, 11, 16, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["By", "combining", "these", "operators", ",", "algorithms", "can", "be", "obtained", "for", "many", "image", "processing", "tasks", ",", "such", "as", "feature", "extraction", ",", "image", "segmentation", ",", "image", "refinement", ",", "image", "filtering", "and", "classification", "."], "sentence-detokenized": "By combining these operators, algorithms can be obtained for many image processing tasks, such as feature extraction, image segmentation, image refinement, image filtering and classification.", "token2charspan": [[0, 2], [3, 12], [13, 18], [19, 28], [28, 29], [30, 40], [41, 44], [45, 47], [48, 56], [57, 60], [61, 65], [66, 71], [72, 82], [83, 88], [88, 89], [90, 94], [95, 97], [98, 105], [106, 116], [116, 117], [118, 123], [124, 136], [136, 137], [138, 143], [144, 154], [154, 155], [156, 161], [162, 171], [172, 175], [176, 190], [190, 191]]}
{"doc_key": "ai-test-196", "ner": [[10, 12, "university"], [20, 22, "organisation"], [24, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[24, 25, 20, 22, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "2017", ",", "he", "has", "been", "a", "professor", "at", "the", "Coll\u00e8ge", "de", "France", "and", ",", "since", "1989", ",", "director", "of", "INSERM", "Unit", "562", ",", "Cognitive", "Neuroimaging", "."], "sentence-detokenized": "Since 2017, he has been a professor at the Coll\u00e8ge de France and, since 1989, director of INSERM Unit 562, Cognitive Neuroimaging.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 14], [15, 18], [19, 23], [24, 25], [26, 35], [36, 38], [39, 42], [43, 50], [51, 53], [54, 60], [61, 64], [64, 65], [66, 71], [72, 76], [76, 77], [78, 86], [87, 89], [90, 96], [97, 101], [102, 105], [105, 106], [107, 116], [117, 129], [129, 130]]}
{"doc_key": "ai-test-197", "ner": [[12, 14, "algorithm"], [16, 19, "algorithm"], [25, 25, "algorithm"], [27, 33, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[25, 25, 27, 33, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["There", "are", "many", "approaches", "to", "learning", "these", "embeddings", ",", "in", "particular", "using", "Bayesian", "clustering", "frameworks", "or", "energy", "-", "based", "frameworks", ",", "and", "most", "recently", ",", "TransE", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", "2013", ")", "."], "sentence-detokenized": "There are many approaches to learning these embeddings, in particular using Bayesian clustering frameworks or energy-based frameworks, and most recently, TransE (Conference on Neural Information Processing Systems 2013).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 25], [26, 28], [29, 37], [38, 43], [44, 54], [54, 55], [56, 58], [59, 69], [70, 75], [76, 84], [85, 95], [96, 106], [107, 109], [110, 116], [116, 117], [117, 122], [123, 133], [133, 134], [135, 138], [139, 143], [144, 152], [152, 153], [154, 160], [161, 162], [162, 172], [173, 175], [176, 182], [183, 194], [195, 205], [206, 213], [214, 218], [218, 219], [219, 220]]}
{"doc_key": "ai-test-198", "ner": [[6, 8, "metrics"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "an", "alternative", "to", "the", "Word", "Error", "Rate", "used", "in", "several", "countries", "."], "sentence-detokenized": "It is an alternative to the Word Error Rate used in several countries.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 20], [21, 23], [24, 27], [28, 32], [33, 38], [39, 43], [44, 48], [49, 51], [52, 59], [60, 69], [69, 70]]}
{"doc_key": "ai-test-199", "ner": [[0, 0, "algorithm"], [12, 13, "task"], [15, 16, "task"], [18, 19, "task"], [21, 23, "task"], [25, 28, "task"], [30, 31, "task"], [44, 44, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[12, 13, 0, 0, "usage", "", false, false], [15, 16, 0, 0, "usage", "", false, false], [18, 19, 0, 0, "usage", "", false, false], [21, 23, 0, 0, "usage", "", false, false], [25, 28, 0, 0, "usage", "", false, false], [30, 31, 0, 0, "usage", "", false, false], [44, 44, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["ANNs", "have", "been", "used", "in", "a", "variety", "of", "tasks", ",", "such", "as", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "board", "and", "video", "games", ",", "medical", "diagnostics", "and", "even", "in", "activities", "traditionally", "considered", "reserved", "for", "humans", ",", "such", "as", "painting", "."], "sentence-detokenized": "ANNs have been used in a variety of tasks, such as computer vision, speech recognition, machine translation, social network filtering, board and video games, medical diagnostics and even in activities traditionally considered reserved for humans, such as painting.", "token2charspan": [[0, 4], [5, 9], [10, 14], [15, 19], [20, 22], [23, 24], [25, 32], [33, 35], [36, 41], [41, 42], [43, 47], [48, 50], [51, 59], [60, 66], [66, 67], [68, 74], [75, 86], [86, 87], [88, 95], [96, 107], [107, 108], [109, 115], [116, 123], [124, 133], [133, 134], [135, 140], [141, 144], [145, 150], [151, 156], [156, 157], [158, 165], [166, 177], [178, 181], [182, 186], [187, 189], [190, 200], [201, 214], [215, 225], [226, 234], [235, 238], [239, 245], [245, 246], [247, 251], [252, 254], [255, 263], [263, 264]]}
{"doc_key": "ai-test-200", "ner": [[0, 3, "product"], [5, 5, "product"], [25, 27, "field"], [29, 29, "field"], [34, 34, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 25, 27, "related-to", "", false, false], [0, 3, 34, 34, "general-affiliation", "", false, false], [5, 5, 0, 3, "named", "", false, false], [29, 29, 25, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "is", "an", "open", "source", "research", "platform", "and", "a", "collection", "of", "speech", ",", "sound", ",", "speech", ",", "text", "and", "natural", "language", "processing", "(", "NLP", ")", "algorithms", "written", "in", "Java", "and", "organised", "in", "a", "modular", "and", "extensible", "framework", "that", "aims", "to", "facilitate", "the", "addition", "of", "new", "algorithms", "."], "sentence-detokenized": "Modular Audio Recognition Framework (MARF) is an open source research platform and a collection of speech, sound, speech, text and natural language processing (NLP) algorithms written in Java and organised in a modular and extensible framework that aims to facilitate the addition of new algorithms.", "token2charspan": [[0, 7], [8, 13], [14, 25], [26, 35], [36, 37], [37, 41], [41, 42], [43, 45], [46, 48], [49, 53], [54, 60], [61, 69], [70, 78], [79, 82], [83, 84], [85, 95], [96, 98], [99, 105], [105, 106], [107, 112], [112, 113], [114, 120], [120, 121], [122, 126], [127, 130], [131, 138], [139, 147], [148, 158], [159, 160], [160, 163], [163, 164], [165, 175], [176, 183], [184, 186], [187, 191], [192, 195], [196, 205], [206, 208], [209, 210], [211, 218], [219, 222], [223, 233], [234, 243], [244, 248], [249, 253], [254, 256], [257, 267], [268, 271], [272, 280], [281, 283], [284, 287], [288, 298], [298, 299]]}
{"doc_key": "ai-test-201", "ner": [[13, 15, "organisation"], [19, 19, "country"], [23, 25, "organisation"], [28, 29, "organisation"], [34, 35, "task"], [48, 51, "organisation"], [54, 55, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[23, 25, 19, 19, "physical", "", false, false], [23, 25, 34, 35, "usage", "", false, false], [23, 25, 48, 51, "named", "", false, false], [28, 29, 19, 19, "physical", "", false, false], [28, 29, 34, 35, "usage", "", false, false], [48, 51, 54, 55, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "a", "report", "by", "civil", "rights", "and", "civil", "liberties", "campaigning", "organisation", "Big", "Brother", "Watch", "revealed", "that", "two", "UK", "police", "forces", ",", "South", "Wales", "Police", "and", "the", "Metropolitan", "Police", ",", "were", "using", "live", "facial", "recognition", "at", "public", "events", "and", "in", "public", "spaces", ",", "in", "September", "2019", ",", "South", "Wales", "Police", "'s", "use", "of", "facial", "recognition", "was", "declared", "legal", "."], "sentence-detokenized": "In 2018, a report by civil rights and civil liberties campaigning organisation Big Brother Watch revealed that two UK police forces, South Wales Police and the Metropolitan Police, were using live facial recognition at public events and in public spaces, in September 2019, South Wales Police's use of facial recognition was declared legal.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 20], [21, 26], [27, 33], [34, 37], [38, 43], [44, 53], [54, 65], [66, 78], [79, 82], [83, 90], [91, 96], [97, 105], [106, 110], [111, 114], [115, 117], [118, 124], [125, 131], [131, 132], [133, 138], [139, 144], [145, 151], [152, 155], [156, 159], [160, 172], [173, 179], [179, 180], [181, 185], [186, 191], [192, 196], [197, 203], [204, 215], [216, 218], [219, 225], [226, 232], [233, 236], [237, 239], [240, 246], [247, 253], [253, 254], [255, 257], [258, 267], [268, 272], [272, 273], [274, 279], [280, 285], [286, 292], [292, 294], [295, 298], [299, 301], [302, 308], [309, 320], [321, 324], [325, 333], [334, 339], [339, 340]]}
{"doc_key": "ai-test-202", "ner": [[0, 0, "product"], [5, 5, "programlang"], [14, 15, "field"], [17, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 5, "general-affiliation", "", false, false], [0, 0, 14, 15, "related-to", "", false, false], [0, 0, 17, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "has", "been", "ported", "to", "R", ",", "a", "freely", "available", "language", "and", "environment", "for", "statistical", "computing", "and", "graphics", "."], "sentence-detokenized": "ANIMAL has been ported to R, a freely available language and environment for statistical computing and graphics.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 22], [23, 25], [26, 27], [27, 28], [29, 30], [31, 37], [38, 47], [48, 56], [57, 60], [61, 72], [73, 76], [77, 88], [89, 98], [99, 102], [103, 111], [111, 112]]}
{"doc_key": "ai-test-203", "ner": [[0, 4, "algorithm"], [6, 8, "algorithm"], [15, 17, "algorithm"], [19, 19, "algorithm"], [22, 24, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 15, 17, "opposite", "alternative to", false, false], [6, 8, 0, 4, "named", "", false, false], [19, 19, 15, 17, "named", "", false, false], [22, 24, 0, 4, "usage", "", false, false], [22, 24, 15, 17, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Time", "Hidden", "Bernoulli", "Model", "(", "TI", "-", "HBM", ")", "is", "an", "alternative", "to", "the", "Hidden", "Markov", "Model", "(", "HMM", ")", "for", "automatic", "speech", "recognition", "."], "sentence-detokenized": "The Time Hidden Bernoulli Model (TI-HBM) is an alternative to the Hidden Markov Model (HMM) for automatic speech recognition.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 25], [26, 31], [32, 33], [33, 35], [35, 36], [36, 39], [39, 40], [41, 43], [44, 46], [47, 58], [59, 61], [62, 65], [66, 72], [73, 79], [80, 85], [86, 87], [87, 90], [90, 91], [92, 95], [96, 105], [106, 112], [113, 124], [124, 125]]}
{"doc_key": "ai-test-204", "ner": [[4, 4, "organisation"], [12, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 12, 12, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "July", "2016", ",", "Nvidia", "demonstrated", "a", "new", "foveated", "rendering", "method", "during", "SIGGRAPH", "that", "claimed", "to", "be", "invisible", "to", "users", "."], "sentence-detokenized": "In July 2016, Nvidia demonstrated a new foveated rendering method during SIGGRAPH that claimed to be invisible to users.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 20], [21, 33], [34, 35], [36, 39], [40, 48], [49, 58], [59, 65], [66, 72], [73, 81], [82, 86], [87, 94], [95, 97], [98, 100], [101, 110], [111, 113], [114, 119], [119, 120]]}
{"doc_key": "ai-test-205", "ner": [[4, 7, "misc"], [10, 11, "researcher"], [18, 19, "researcher"], [21, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 7, 10, 11, "origin", "", false, false], [4, 7, 18, 19, "origin", "", false, false], [4, 7, 21, 21, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Both", "are", "based", "on", "the", "speech", "act", "theory", "developed", "by", "John", "Searle", "in", "the", "1960s", "and", "improved", "by", "Terry", "Winograd", "and", "Flores", "in", "the", "1970s", "."], "sentence-detokenized": "Both are based on the speech act theory developed by John Searle in the 1960s and improved by Terry Winograd and Flores in the 1970s.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 17], [18, 21], [22, 28], [29, 32], [33, 39], [40, 49], [50, 52], [53, 57], [58, 64], [65, 67], [68, 71], [72, 77], [78, 81], [82, 90], [91, 93], [94, 99], [100, 108], [109, 112], [113, 119], [120, 122], [123, 126], [127, 132], [132, 133]]}
{"doc_key": "ai-test-206", "ner": [[0, 2, "algorithm"], [21, 22, "researcher"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 21, 22, "related-to", "", false, false], [24, 24, 21, 22, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Neural", "network", "models", "of", "concept", "formation", "and", "knowledge", "structure", "have", "opened", "up", "powerful", "hierarchical", "models", "of", "knowledge", "organisation", ",", "such", "as", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "Neural network models of concept formation and knowledge structure have opened up powerful hierarchical models of knowledge organisation, such as George Miller's Wordnet.", "token2charspan": [[0, 6], [7, 14], [15, 21], [22, 24], [25, 32], [33, 42], [43, 46], [47, 56], [57, 66], [67, 71], [72, 78], [79, 81], [82, 90], [91, 103], [104, 110], [111, 113], [114, 123], [124, 136], [136, 137], [138, 142], [143, 145], [146, 152], [153, 159], [159, 161], [162, 169], [169, 170]]}
{"doc_key": "ai-test-207", "ner": [[0, 1, "algorithm"], [12, 13, "field"], [16, 18, "product"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 13, "part-of", "", false, false], [0, 1, 21, 23, "part-of", "", false, false], [16, 18, 12, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Template", "matching", "has", "various", "applications", "and", "is", "used", "in", "fields", "such", "as", "face", "recognition", "(", "see", "face", "recognition", "system", ")", "and", "medical", "image", "processing", "."], "sentence-detokenized": "Template matching has various applications and is used in fields such as face recognition (see face recognition system) and medical image processing.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 29], [30, 42], [43, 46], [47, 49], [50, 54], [55, 57], [58, 64], [65, 69], [70, 72], [73, 77], [78, 89], [90, 91], [91, 94], [95, 99], [100, 111], [112, 118], [118, 119], [120, 123], [124, 131], [132, 137], [138, 148], [148, 149]]}
{"doc_key": "ai-test-208", "ner": [[12, 13, "researcher"], [15, 16, "researcher"], [21, 30, "organisation"], [32, 32, "organisation"], [40, 41, "algorithm"], [44, 50, "conference"], [52, 52, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 13, 21, 30, "role", "", false, false], [12, 13, 44, 50, "physical", "", false, false], [12, 13, 44, 50, "temporal", "", false, false], [12, 13, 52, 52, "physical", "", false, false], [15, 16, 21, 30, "role", "", false, false], [15, 16, 44, 50, "temporal", "", false, false], [32, 32, 21, 30, "named", "", false, false], [44, 50, 40, 41, "topic", "", false, false], [52, 52, 44, 50, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["However", ",", "their", "use", "did", "not", "become", "widespread", "until", "2005", ",", "when", "Navneet", "Dalal", "and", "Bill", "Triggs", ",", "researchers", "at", "the", "French", "National", "Institute", "for", "Research", "in", "Computer", "Science", "and", "Automation", "(", "INRIA", ")", ",", "presented", "their", "complementary", "work", "on", "HOG", "descriptors", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "However, their use did not become widespread until 2005, when Navneet Dalal and Bill Triggs, researchers at the French National Institute for Research in Computer Science and Automation (INRIA), presented their complementary work on HOG descriptors at the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 18], [19, 22], [23, 26], [27, 33], [34, 44], [45, 50], [51, 55], [55, 56], [57, 61], [62, 69], [70, 75], [76, 79], [80, 84], [85, 91], [91, 92], [93, 104], [105, 107], [108, 111], [112, 118], [119, 127], [128, 137], [138, 141], [142, 150], [151, 153], [154, 162], [163, 170], [171, 174], [175, 185], [186, 187], [187, 192], [192, 193], [193, 194], [195, 204], [205, 210], [211, 224], [225, 229], [230, 232], [233, 236], [237, 248], [249, 251], [252, 255], [256, 266], [267, 269], [270, 278], [279, 285], [286, 289], [290, 297], [298, 309], [310, 311], [311, 315], [315, 316], [316, 317]]}
{"doc_key": "ai-test-209", "ner": [[3, 3, "university"], [16, 17, "organisation"], [19, 20, "organisation"], [27, 27, "field"], [33, 35, "researcher"], [37, 39, "researcher"], [41, 43, "researcher"], [47, 50, "organisation"], [53, 57, "organisation"], [62, 63, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[19, 20, 27, 27, "related-to", "", false, false], [33, 35, 19, 20, "physical", "", false, false], [33, 35, 19, 20, "role", "", false, false], [37, 39, 19, 20, "physical", "", false, false], [37, 39, 19, 20, "role", "", false, false], [41, 43, 19, 20, "physical", "", false, false], [41, 43, 19, 20, "role", "", false, false], [62, 63, 53, 57, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Before", "joining", "the", "Pennsylvania", "faculty", "in", "2002", ",", "he", "spent", "a", "decade", "(", "1991-2001", ")", "at", "AT&T", "Labs", "and", "Bell", "Labs", ",", "including", "as", "head", "of", "the", "AI", "department", "with", "colleagues", "such", "as", "Michael", "L.", "Littman", ",", "David", "A.", "McAllester", "and", "Richard", "S.", "Sutton", ";", "of", "the", "secure", "systems", "research", "department", ";", "and", "of", "the", "machine", "learning", "department", "with", "members", "such", "as", "Michael", "Collins", "and", "the", "leader", ")", "."], "sentence-detokenized": "Before joining the Pennsylvania faculty in 2002, he spent a decade (1991-2001) at AT&T Labs and Bell Labs, including as head of the AI department with colleagues such as Michael L. Littman, David A. McAllester and Richard S. Sutton; of the secure systems research department; and of the machine learning department with members such as Michael Collins and the leader).", "token2charspan": [[0, 6], [7, 14], [15, 18], [19, 31], [32, 39], [40, 42], [43, 47], [47, 48], [49, 51], [52, 57], [58, 59], [60, 66], [67, 68], [68, 77], [77, 78], [79, 81], [82, 86], [87, 91], [92, 95], [96, 100], [101, 105], [105, 106], [107, 116], [117, 119], [120, 124], [125, 127], [128, 131], [132, 134], [135, 145], [146, 150], [151, 161], [162, 166], [167, 169], [170, 177], [178, 180], [181, 188], [188, 189], [190, 195], [196, 198], [199, 209], [210, 213], [214, 221], [222, 224], [225, 231], [231, 232], [233, 235], [236, 239], [240, 246], [247, 254], [255, 263], [264, 274], [274, 275], [276, 279], [280, 282], [283, 286], [287, 294], [295, 303], [304, 314], [315, 319], [320, 327], [328, 332], [333, 335], [336, 343], [344, 351], [352, 355], [356, 359], [360, 366], [366, 367], [367, 368]]}
{"doc_key": "ai-test-210", "ner": [[6, 7, "field"], [14, 15, "field"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 14, 15, "compare", "", false, false], [24, 25, 14, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["When", "data", "are", "not", "labelled", ",", "supervised", "learning", "is", "not", "possible", ",", "and", "an", "unsupervised", "learning", "approach", "is", "required", "that", "attempts", "to", "find", "natural", "cluster", "analyses", "to", "groups", ",", "and", "then", "assign", "the", "new", "data", "to", "these", "formed", "groups", "."], "sentence-detokenized": "When data are not labelled, supervised learning is not possible, and an unsupervised learning approach is required that attempts to find natural cluster analyses to groups, and then assign the new data to these formed groups.", "token2charspan": [[0, 4], [5, 9], [10, 13], [14, 17], [18, 26], [26, 27], [28, 38], [39, 47], [48, 50], [51, 54], [55, 63], [63, 64], [65, 68], [69, 71], [72, 84], [85, 93], [94, 102], [103, 105], [106, 114], [115, 119], [120, 128], [129, 131], [132, 136], [137, 144], [145, 152], [153, 161], [162, 164], [165, 171], [171, 172], [173, 176], [177, 181], [182, 188], [189, 192], [193, 196], [197, 201], [202, 204], [205, 210], [211, 217], [218, 224], [224, 225]]}
{"doc_key": "ai-test-211", "ner": [[3, 4, "field"], [15, 19, "organisation"], [26, 27, "field"], [29, 29, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 15, 19, "origin", "", false, false], [3, 4, 26, 27, "part-of", "", false, false], [3, 4, 29, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "field", "of", "computer", "science", "was", "developed", "in", "the", "1950s", "at", "academic", "institutions", "such", "as", "MIT", "'s", "Artificial", "Intelligence", "Laboratory", ",", "originally", "as", "a", "branch", "of", "artificial", "intelligence", "and", "robotics", "."], "sentence-detokenized": "This field of computer science was developed in the 1950s at academic institutions such as MIT's Artificial Intelligence Laboratory, originally as a branch of artificial intelligence and robotics.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 30], [31, 34], [35, 44], [45, 47], [48, 51], [52, 57], [58, 60], [61, 69], [70, 82], [83, 87], [88, 90], [91, 94], [94, 96], [97, 107], [108, 120], [121, 131], [131, 132], [133, 143], [144, 146], [147, 148], [149, 155], [156, 158], [159, 169], [170, 182], [183, 186], [187, 195], [195, 196]]}
{"doc_key": "ai-test-212", "ner": [[7, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "could", "also", "be", "replaced", "by", "the", "logistic", "loss", "equation", "below", ":"], "sentence-detokenized": "It could also be replaced by the logistic loss equation below:", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 16], [17, 25], [26, 28], [29, 32], [33, 41], [42, 46], [47, 55], [56, 61], [61, 62]]}
{"doc_key": "ai-test-213", "ner": [[0, 3, "organisation"], [7, 10, "organisation"], [14, 18, "university"], [20, 20, "university"], [22, 23, "university"], [25, 28, "university"], [31, 31, "country"], [36, 36, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 3, 36, 36, "related-to", "research_leader_in_field", false, false], [7, 10, 0, 3, "named", "", false, false], [7, 10, 36, 36, "related-to", "research_leader_in_field", false, false], [14, 18, 36, 36, "related-to", "research_leader_in_field", false, false], [20, 20, 36, 36, "related-to", "research_leader_in_field", false, false], [22, 23, 36, 36, "related-to", "research_leader_in_field", false, false], [25, 28, 31, 31, "physical", "", false, false], [25, 28, 36, 36, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Shirley", "Ryan", "'s", "AbilityLab", "(", "formerly", "the", "Rehabilitation", "Institute", "of", "Chicago", ")", ",", "the", "University", "of", "California", "at", "Berkeley", ",", "MIT", ",", "Stanford", "University", "and", "the", "University", "of", "Twente", "in", "the", "Netherlands", "are", "the", "leaders", "in", "biomechatronics", "research", "."], "sentence-detokenized": "Shirley Ryan's AbilityLab (formerly the Rehabilitation Institute of Chicago), the University of California at Berkeley, MIT, Stanford University and the University of Twente in the Netherlands are the leaders in biomechatronics research.", "token2charspan": [[0, 7], [8, 12], [12, 14], [15, 25], [26, 27], [27, 35], [36, 39], [40, 54], [55, 64], [65, 67], [68, 75], [75, 76], [76, 77], [78, 81], [82, 92], [93, 95], [96, 106], [107, 109], [110, 118], [118, 119], [120, 123], [123, 124], [125, 133], [134, 144], [145, 148], [149, 152], [153, 163], [164, 166], [167, 173], [174, 176], [177, 180], [181, 192], [193, 196], [197, 200], [201, 208], [209, 211], [212, 227], [228, 236], [236, 237]]}
{"doc_key": "ai-test-214", "ner": [[28, 31, "metrics"], [42, 43, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Given", "a", "set", "of", "predicted", "values", "and", "a", "corresponding", "set", "of", "actual", "values", "of", "X", "for", "various", "time", "periods", ",", "a", "common", "evaluation", "technique", "is", "to", "use", "the", "mean", "squared", "prediction", "error", ";", "other", "measures", "are", "also", "available", "(", "see", "forecasting", "#", "forecasting", "accuracy", ")", "."], "sentence-detokenized": "Given a set of predicted values and a corresponding set of actual values of X for various time periods, a common evaluation technique is to use the mean squared prediction error; other measures are also available (see forecasting # forecasting accuracy).", "token2charspan": [[0, 5], [6, 7], [8, 11], [12, 14], [15, 24], [25, 31], [32, 35], [36, 37], [38, 51], [52, 55], [56, 58], [59, 65], [66, 72], [73, 75], [76, 77], [78, 81], [82, 89], [90, 94], [95, 102], [102, 103], [104, 105], [106, 112], [113, 123], [124, 133], [134, 136], [137, 139], [140, 143], [144, 147], [148, 152], [153, 160], [161, 171], [172, 177], [177, 178], [179, 184], [185, 193], [194, 197], [198, 202], [203, 212], [213, 214], [214, 217], [218, 229], [230, 231], [232, 243], [244, 252], [252, 253], [253, 254]]}
{"doc_key": "ai-test-215", "ner": [[13, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "measures", ",", "such", "as", "the", "proportion", "of", "correct", "predictions", "(", "also", "called", "accuracy", ")", ",", "are", "not", "useful", "when", "the", "two", "classes", "are", "of", "very", "different", "sizes", "."], "sentence-detokenized": "Other measures, such as the proportion of correct predictions (also called accuracy), are not useful when the two classes are of very different sizes.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 20], [21, 23], [24, 27], [28, 38], [39, 41], [42, 49], [50, 61], [62, 63], [63, 67], [68, 74], [75, 83], [83, 84], [84, 85], [86, 89], [90, 93], [94, 100], [101, 105], [106, 109], [110, 113], [114, 121], [122, 125], [126, 128], [129, 133], [134, 143], [144, 149], [149, 150]]}
{"doc_key": "ai-test-216", "ner": [[5, 5, "product"], [11, 15, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 11, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "alpha", "version", "of", "OpenCV", "was", "made", "public", "at", "the", "Computer", "Vision", "and", "Pattern", "Recognition", "Conference", "in", "2000", ",", "and", "five", "betas", "were", "released", "between", "2001", "and", "2005", "."], "sentence-detokenized": "The first alpha version of OpenCV was made public at the Computer Vision and Pattern Recognition Conference in 2000, and five betas were released between 2001 and 2005.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [24, 26], [27, 33], [34, 37], [38, 42], [43, 49], [50, 52], [53, 56], [57, 65], [66, 72], [73, 76], [77, 84], [85, 96], [97, 107], [108, 110], [111, 115], [115, 116], [117, 120], [121, 125], [126, 131], [132, 136], [137, 145], [146, 153], [154, 158], [159, 162], [163, 167], [167, 168]]}
{"doc_key": "ai-test-217", "ner": [[22, 22, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Results", "have", "been", "presented", "that", "give", "a", "correlation", "of", "up", "to", "0.964", "with", "human", "judgement", "at", "the", "corpus", "level", ",", "compared", "to", "BLEU", "'s", "achievement", "of", "0.817", "on", "the", "same", "dataset", "."], "sentence-detokenized": "Results have been presented that give a correlation of up to 0.964 with human judgement at the corpus level, compared to BLEU's achievement of 0.817 on the same dataset.", "token2charspan": [[0, 7], [8, 12], [13, 17], [18, 27], [28, 32], [33, 37], [38, 39], [40, 51], [52, 54], [55, 57], [58, 60], [61, 66], [67, 71], [72, 77], [78, 87], [88, 90], [91, 94], [95, 101], [102, 107], [107, 108], [109, 117], [118, 120], [121, 125], [125, 127], [128, 139], [140, 142], [143, 148], [149, 151], [152, 155], [156, 160], [161, 168], [168, 169]]}
{"doc_key": "ai-test-218", "ner": [[4, 7, "metrics"], [18, 18, "metrics"], [20, 22, "metrics"], [24, 26, "metrics"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 7, 18, 18, "compare", "", false, false], [4, 7, 20, 22, "compare", "", false, false], [4, 7, 24, 26, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "first", "version", "of", "VMAF", "has", "been", "shown", "to", "outperform", "other", "image", "and", "video", "quality", "metrics", "such", "as", "SSIM", ",", "PSNR", "-", "HVS", "and", "VQM", "-", "VFD", "in", "three", "out", "of", "four", "datasets", "in", "terms", "of", "prediction", "accuracy", ",", "when", "compared", "to", "subjective", "ratings", "."], "sentence-detokenized": "A first version of VMAF has been shown to outperform other image and video quality metrics such as SSIM, PSNR-HVS and VQM-VFD in three out of four datasets in terms of prediction accuracy, when compared to subjective ratings.", "token2charspan": [[0, 1], [2, 7], [8, 15], [16, 18], [19, 23], [24, 27], [28, 32], [33, 38], [39, 41], [42, 52], [53, 58], [59, 64], [65, 68], [69, 74], [75, 82], [83, 90], [91, 95], [96, 98], [99, 103], [103, 104], [105, 109], [109, 110], [110, 113], [114, 117], [118, 121], [121, 122], [122, 125], [126, 128], [129, 134], [135, 138], [139, 141], [142, 146], [147, 155], [156, 158], [159, 164], [165, 167], [168, 178], [179, 187], [187, 188], [189, 193], [194, 202], [203, 205], [206, 216], [217, 224], [224, 225]]}
{"doc_key": "ai-test-219", "ner": [[18, 19, "task"], [26, 27, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 26, 27, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "example", ",", "the", "ambiguity", "of", "\"", "mouse", "\"", "(", "animal", "or", "device", ")", "is", "not", "relevant", "in", "machine", "translation", ",", "but", "it", "is", "relevant", "in", "information", "retrieval", "."], "sentence-detokenized": "For example, the ambiguity of \"mouse\" (animal or device) is not relevant in machine translation, but it is relevant in information retrieval.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 26], [27, 29], [30, 31], [31, 36], [36, 37], [38, 39], [39, 45], [46, 48], [49, 55], [55, 56], [57, 59], [60, 63], [64, 72], [73, 75], [76, 83], [84, 95], [95, 96], [97, 100], [101, 103], [104, 106], [107, 115], [116, 118], [119, 130], [131, 140], [140, 141]]}
{"doc_key": "ai-test-220", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 1, "usage", "", false, false], [12, 13, 6, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Geometric", "hashing", "was", "originally", "proposed", "in", "computer", "vision", "for", "2D", "and", "3D", "object", "recognition", ","], "sentence-detokenized": "Geometric hashing was originally proposed in computer vision for 2D and 3D object recognition,", "token2charspan": [[0, 9], [10, 17], [18, 21], [22, 32], [33, 41], [42, 44], [45, 53], [54, 60], [61, 64], [65, 67], [68, 71], [72, 74], [75, 81], [82, 93], [93, 94]]}
{"doc_key": "ai-test-221", "ner": [[9, 10, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 15, 9, 10, "part-of", "subfield", false, false], [17, 18, 9, 10, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "forms", "one", "of", "the", "three", "main", "categories", "of", "machine", "learning", ",", "along", "with", "supervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "It forms one of the three main categories of machine learning, along with supervised learning and reinforcement learning.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 15], [16, 19], [20, 25], [26, 30], [31, 41], [42, 44], [45, 52], [53, 61], [61, 62], [63, 68], [69, 73], [74, 84], [85, 93], [94, 97], [98, 111], [112, 120], [120, 121]]}
{"doc_key": "ai-test-222", "ner": [[0, 1, "field"], [17, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 31, "field"], [33, 34, "field"], [36, 37, "field"], [39, 39, "field"], [41, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 1, 17, 17, "part-of", "subfield", false, false], [0, 1, 19, 20, "part-of", "subfield", false, false], [0, 1, 22, 23, "part-of", "subfield", false, false], [0, 1, 25, 26, "part-of", "subfield", false, false], [0, 1, 28, 31, "part-of", "subfield", false, false], [0, 1, 33, 34, "part-of", "subfield", false, false], [0, 1, 36, 37, "part-of", "subfield", false, false], [0, 1, 39, 39, "part-of", "subfield", false, false], [0, 1, 41, 42, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Reinforcement", "learning", ",", "due", "to", "its", "generality", ",", "is", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "games", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimisation", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Reinforcement learning, due to its generality, is studied in many other disciplines, such as games, control theory, operations research, information theory, simulation-based optimisation, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 13], [14, 22], [22, 23], [24, 27], [28, 30], [31, 34], [35, 45], [45, 46], [47, 49], [50, 57], [58, 60], [61, 65], [66, 71], [72, 83], [83, 84], [85, 89], [90, 92], [93, 98], [98, 99], [100, 107], [108, 114], [114, 115], [116, 126], [127, 135], [135, 136], [137, 148], [149, 155], [155, 156], [157, 167], [167, 168], [168, 173], [174, 186], [186, 187], [188, 199], [200, 207], [207, 208], [209, 214], [215, 227], [227, 228], [229, 239], [240, 243], [244, 251], [252, 262], [262, 263]]}
{"doc_key": "ai-test-223", "ner": [[0, 1, "field"], [6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "related-to", "", false, false], [0, 1, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pattern", "recognition", "is", "closely", "related", "to", "artificial", "intelligence", "and", "machine", "learning", ","], "sentence-detokenized": "Pattern recognition is closely related to artificial intelligence and machine learning,", "token2charspan": [[0, 7], [8, 19], [20, 22], [23, 30], [31, 38], [39, 41], [42, 52], [53, 65], [66, 69], [70, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-224", "ner": [[10, 11, "algorithm"], [14, 15, "field"], [17, 18, "field"], [29, 30, "task"], [32, 32, "task"], [34, 35, "task"], [37, 38, "algorithm"], [40, 42, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 11, 14, 15, "related-to", "", false, false], [10, 11, 17, 18, "related-to", "", false, false], [29, 30, 10, 11, "usage", "", true, false], [32, 32, 10, 11, "usage", "", true, false], [34, 35, 10, 11, "usage", "", true, false], [37, 38, 10, 11, "usage", "", true, false], [40, 42, 10, 11, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "software", "is", "used", "to", "design", ",", "train", "and", "deploy", "neural", "network", "models", "(", "supervised", "learning", "and", "unsupervised", "learning", ")", "to", "perform", "a", "wide", "variety", "of", "tasks", "such", "as", "data", "mining", ",", "classification", ",", "function", "approximation", ",", "multivariate", "regression", "and", "time", "series", "prediction", "."], "sentence-detokenized": "The software is used to design, train and deploy neural network models (supervised learning and unsupervised learning) to perform a wide variety of tasks such as data mining, classification, function approximation, multivariate regression and time series prediction.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 20], [21, 23], [24, 30], [30, 31], [32, 37], [38, 41], [42, 48], [49, 55], [56, 63], [64, 70], [71, 72], [72, 82], [83, 91], [92, 95], [96, 108], [109, 117], [117, 118], [119, 121], [122, 129], [130, 131], [132, 136], [137, 144], [145, 147], [148, 153], [154, 158], [159, 161], [162, 166], [167, 173], [173, 174], [175, 189], [189, 190], [191, 199], [200, 213], [213, 214], [215, 227], [228, 238], [239, 242], [243, 247], [248, 254], [255, 265], [265, 266]]}
{"doc_key": "ai-test-225", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2016", ",", "he", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2016, he was elected a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [98, 99]]}
{"doc_key": "ai-test-226", "ner": [[6, 9, "organisation"], [15, 21, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", "(", "since", "2005", ")", "and", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "(", "since", "2009", ")", ","], "sentence-detokenized": "He is a member of the National Academy of Sciences (since 2005) and the American Academy of Arts and Sciences (since 2009),", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 38], [39, 41], [42, 50], [51, 52], [52, 57], [58, 62], [62, 63], [64, 67], [68, 71], [72, 80], [81, 88], [89, 91], [92, 96], [97, 100], [101, 109], [110, 111], [111, 116], [117, 121], [121, 122], [122, 123]]}
{"doc_key": "ai-test-227", "ner": [[3, 5, "misc"], [9, 14, "product"], [17, 17, "country"], [19, 19, "country"], [24, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 14, 3, 5, "temporal", "", false, false], [9, 14, 17, 17, "physical", "", false, false], [9, 14, 19, 19, "physical", "", false, false], [9, 14, 24, 26, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "the", "1973", "Yom", "Kippur", "War", ",", "Soviet", "-supplied", "surface", "-", "to", "-", "air", "missile", "batteries", "in", "Egypt", "and", "Syria", "caused", "severe", "damage", "to", "Israeli", "fighter", "aircraft", "."], "sentence-detokenized": "During the 1973 Yom Kippur War, Soviet-supplied surface-to-air missile batteries in Egypt and Syria caused severe damage to Israeli fighter aircraft.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 26], [27, 30], [30, 31], [32, 38], [38, 47], [48, 55], [55, 56], [56, 58], [58, 59], [59, 62], [63, 70], [71, 80], [81, 83], [84, 89], [90, 93], [94, 99], [100, 106], [107, 113], [114, 120], [121, 123], [124, 131], [132, 139], [140, 148], [148, 149]]}
{"doc_key": "ai-test-228", "ner": [[9, 10, "product"], [15, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 16, 9, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Another", "(", "free", "but", "copyrighted", ")", "resource", "is", "the", "HTK", "book", "(", "and", "the", "accompanying", "HTK", "toolkit", ")", "."], "sentence-detokenized": "Another (free but copyrighted) resource is the HTK book (and the accompanying HTK toolkit).", "token2charspan": [[0, 7], [8, 9], [9, 13], [14, 17], [18, 29], [29, 30], [31, 39], [40, 42], [43, 46], [47, 50], [51, 55], [56, 57], [57, 60], [61, 64], [65, 77], [78, 81], [82, 89], [89, 90], [90, 91]]}
{"doc_key": "ai-test-229", "ner": [[5, 6, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "were", "taken", "at", "the", "2004", "AAAI", "Spring", "Symposium", ",", "where", "linguists", ",", "computer", "scientists", "and", "other", "interested", "researchers", "aligned", "their", "interests", "for", "the", "first", "time", "and", "proposed", "shared", "tasks", "and", "reference", "datasets", "for", "systematic", "computational", "research", "on", "affect", ",", "attractiveness", ",", "subjectivity", "and", "sentiment", "in", "text", "."], "sentence-detokenized": "- were taken at the 2004 AAAI Spring Symposium, where linguists, computer scientists and other interested researchers aligned their interests for the first time and proposed shared tasks and reference datasets for systematic computational research on affect, attractiveness, subjectivity and sentiment in text.", "token2charspan": [[0, 1], [2, 6], [7, 12], [13, 15], [16, 19], [20, 24], [25, 29], [30, 36], [37, 46], [46, 47], [48, 53], [54, 63], [63, 64], [65, 73], [74, 84], [85, 88], [89, 94], [95, 105], [106, 117], [118, 125], [126, 131], [132, 141], [142, 145], [146, 149], [150, 155], [156, 160], [161, 164], [165, 173], [174, 180], [181, 186], [187, 190], [191, 200], [201, 209], [210, 213], [214, 224], [225, 238], [239, 247], [248, 250], [251, 257], [257, 258], [259, 273], [273, 274], [275, 287], [288, 291], [292, 301], [302, 304], [305, 309], [309, 310]]}
{"doc_key": "ai-test-230", "ner": [[12, 13, "task"], [23, 24, "task"], [26, 28, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "same", "grid", "can", "be", "analysed", "both", "in", "terms", "of", "content", "(", "visual", "inspection", ")", "and", "structure", "(", "the", "main", "techniques", "used", "are", "cluster", "analysis", ",", "principal", "component", "analysis", "and", "a", "series", "of", "structural", "indices", "related", "to", "the", "complexity", "and", "scope", "of", "the", "ratings", ")", "."], "sentence-detokenized": "The same grid can be analysed both in terms of content (visual inspection) and structure (the main techniques used are cluster analysis, principal component analysis and a series of structural indices related to the complexity and scope of the ratings).", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 17], [18, 20], [21, 29], [30, 34], [35, 37], [38, 43], [44, 46], [47, 54], [55, 56], [56, 62], [63, 73], [73, 74], [75, 78], [79, 88], [89, 90], [90, 93], [94, 98], [99, 109], [110, 114], [115, 118], [119, 126], [127, 135], [135, 136], [137, 146], [147, 156], [157, 165], [166, 169], [170, 171], [172, 178], [179, 181], [182, 192], [193, 200], [201, 208], [209, 211], [212, 215], [216, 226], [227, 230], [231, 236], [237, 239], [240, 243], [244, 251], [251, 252], [252, 253]]}
{"doc_key": "ai-test-231", "ner": [[3, 3, "organisation"], [11, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2018", ",", "Toyota", "was", "seen", "as", "lagging", "behind", "in", "the", "self", "-", "driving", "car", "and", "needing", "to", "innovate", "."], "sentence-detokenized": "In 2018, Toyota was seen as lagging behind in the self-driving car and needing to innovate.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 24], [25, 27], [28, 35], [36, 42], [43, 45], [46, 49], [50, 54], [54, 55], [55, 62], [63, 66], [67, 70], [71, 78], [79, 81], [82, 90], [90, 91]]}
{"doc_key": "ai-test-232", "ner": [[40, 41, "misc"], [43, 44, "misc"], [46, 49, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "targets", "include", "natural", "objects", "such", "as", "the", "ground", ",", "the", "sea", ",", "precipitation", "(", "such", "as", "rain", ",", "snow", "or", "hail", ")", ",", "sandstorms", ",", "animals", "(", "especially", "birds", ")", ",", "atmospheric", "turbulence", "and", "other", "atmospheric", "effects", "such", "as", "ionospheric", "reflections", ",", "meteor", "trails", "and", "three", "-", "body", "scattering", "."], "sentence-detokenized": "These targets include natural objects such as the ground, the sea, precipitation (such as rain, snow or hail), sandstorms, animals (especially birds), atmospheric turbulence and other atmospheric effects such as ionospheric reflections, meteor trails and three-body scattering.", "token2charspan": [[0, 5], [6, 13], [14, 21], [22, 29], [30, 37], [38, 42], [43, 45], [46, 49], [50, 56], [56, 57], [58, 61], [62, 65], [65, 66], [67, 80], [81, 82], [82, 86], [87, 89], [90, 94], [94, 95], [96, 100], [101, 103], [104, 108], [108, 109], [109, 110], [111, 121], [121, 122], [123, 130], [131, 132], [132, 142], [143, 148], [148, 149], [149, 150], [151, 162], [163, 173], [174, 177], [178, 183], [184, 195], [196, 203], [204, 208], [209, 211], [212, 223], [224, 235], [235, 236], [237, 243], [244, 250], [251, 254], [255, 260], [260, 261], [261, 265], [266, 276], [276, 277]]}
{"doc_key": "ai-test-233", "ner": [[18, 18, "product"], [38, 39, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "planning", "and", "control", ",", "the", "essential", "difference", "between", "humanoids", "and", "other", "types", "of", "robots", "(", "such", "as", "industrial", "robots", ")", "is", "that", "the", "robot", "'s", "movement", "must", "be", "human", "-", "like", ",", "using", "legged", "locomotion", ",", "especially", "bipedal", "walking", "."], "sentence-detokenized": "In planning and control, the essential difference between humanoids and other types of robots (such as industrial robots) is that the robot's movement must be human-like, using legged locomotion, especially bipedal walking.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 23], [23, 24], [25, 28], [29, 38], [39, 49], [50, 57], [58, 67], [68, 71], [72, 77], [78, 83], [84, 86], [87, 93], [94, 95], [95, 99], [100, 102], [103, 113], [114, 120], [120, 121], [122, 124], [125, 129], [130, 133], [134, 139], [139, 141], [142, 150], [151, 155], [156, 158], [159, 164], [164, 165], [165, 169], [169, 170], [171, 176], [177, 183], [184, 194], [194, 195], [196, 206], [207, 214], [215, 222], [222, 223]]}
{"doc_key": "ai-test-234", "ner": [[0, 1, "algorithm"], [9, 10, "misc"], [14, 14, "metrics"], [18, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Gradient", "descent", "can", "take", "many", "iterations", "to", "compute", "a", "local", "minimum", "with", "the", "required", "accuracy", ",", "if", "the", "curvature", "in", "different", "directions", "is", "very", "different", "for", "the", "given", "function", "."], "sentence-detokenized": "Gradient descent can take many iterations to compute a local minimum with the required accuracy, if the curvature in different directions is very different for the given function.", "token2charspan": [[0, 8], [9, 16], [17, 20], [21, 25], [26, 30], [31, 41], [42, 44], [45, 52], [53, 54], [55, 60], [61, 68], [69, 73], [74, 77], [78, 86], [87, 95], [95, 96], [97, 99], [100, 103], [104, 113], [114, 116], [117, 126], [127, 137], [138, 140], [141, 145], [146, 155], [156, 159], [160, 163], [164, 169], [170, 178], [178, 179]]}
{"doc_key": "ai-test-235", "ner": [[1, 6, "misc"], [10, 10, "misc"], [17, 22, "conference"], [25, 25, "location"], [27, 27, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 6, 10, 10, "part-of", "", true, false], [17, 22, 25, 25, "physical", "", false, true], [25, 25, 27, 27, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "1997", "RoboCup", "2D", "Soccer", "Simulation", "League", "was", "the", "first", "RoboCup", "competition", "promoted", "in", "conjunction", "with", "the", "International", "Joint", "Conference", "on", "Artificial", "Intelligence", "held", "in", "Nagoya", ",", "Japan", ",", "23", "-", "29", "August", "1997", "."], "sentence-detokenized": "The 1997 RoboCup 2D Soccer Simulation League was the first RoboCup competition promoted in conjunction with the International Joint Conference on Artificial Intelligence held in Nagoya, Japan, 23-29 August 1997.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 19], [20, 26], [27, 37], [38, 44], [45, 48], [49, 52], [53, 58], [59, 66], [67, 78], [79, 87], [88, 90], [91, 102], [103, 107], [108, 111], [112, 125], [126, 131], [132, 142], [143, 145], [146, 156], [157, 169], [170, 174], [175, 177], [178, 184], [184, 185], [186, 191], [191, 192], [193, 195], [195, 196], [196, 198], [199, 205], [206, 210], [210, 211]]}
{"doc_key": "ai-test-236", "ner": [[6, 6, "programlang"], [10, 10, "programlang"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "options", "include", "an", "integrated", "Python", "environment", "and", "an", "R", "console", ",", "as", "well", "as", "support", "for", "Rserve", "."], "sentence-detokenized": "Other programming options include an integrated Python environment and an R console, as well as support for Rserve.", "token2charspan": [[0, 5], [6, 17], [18, 25], [26, 33], [34, 36], [37, 47], [48, 54], [55, 66], [67, 70], [71, 73], [74, 75], [76, 83], [83, 84], [85, 87], [88, 92], [93, 95], [96, 103], [104, 107], [108, 114], [114, 115]]}
{"doc_key": "ai-test-237", "ner": [[1, 1, "location"], [7, 8, "field"], [10, 10, "field"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [31, 32, "field"], [37, 38, "field"], [41, 42, "field"], [48, 49, "field"], [53, 56, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[13, 14, 10, 10, "related-to", "contributes_to_field", true, false], [16, 17, 10, 10, "related-to", "contributes_to_field", true, false], [19, 20, 10, 10, "related-to", "contributes_to_field", true, false], [41, 42, 37, 38, "part-of", "", false, false], [48, 49, 41, 42, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Since", "Bonn", "he", "has", "contributed", "mainly", "to", "artificial", "intelligence", "and", "robotics", "(", "with", "Wolfram", "Burgard", ",", "Dieter", "Fox", ",", "Sebastian", "Thrun", "among", "his", "students", ")", ",", "and", "to", "the", "development", "of", "software", "engineering", ",", "in", "particular", "in", "civil", "engineering", ",", "and", "information", "systems", ",", "in", "particular", "in", "the", "geosciences", ".", "He", "won", "the", "AAAI", "Classic", "Paper", "Award", "2016.2014", "."], "sentence-detokenized": "Since Bonn he has contributed mainly to artificial intelligence and robotics (with Wolfram Burgard, Dieter Fox, Sebastian Thrun among his students), and to the development of software engineering, in particular in civil engineering, and information systems, in particular in the geosciences. He won the AAAI Classic Paper Award 2016.2014.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 17], [18, 29], [30, 36], [37, 39], [40, 50], [51, 63], [64, 67], [68, 76], [77, 78], [78, 82], [83, 90], [91, 98], [98, 99], [100, 106], [107, 110], [110, 111], [112, 121], [122, 127], [128, 133], [134, 137], [138, 146], [146, 147], [147, 148], [149, 152], [153, 155], [156, 159], [160, 171], [172, 174], [175, 183], [184, 195], [195, 196], [197, 199], [200, 210], [211, 213], [214, 219], [220, 231], [231, 232], [233, 236], [237, 248], [249, 256], [256, 257], [258, 260], [261, 271], [272, 274], [275, 278], [279, 290], [290, 291], [292, 294], [295, 298], [299, 302], [303, 307], [308, 315], [316, 321], [322, 327], [328, 337], [337, 338]]}
{"doc_key": "ai-test-238", "ner": [[2, 10, "conference"], [17, 19, "location"], [21, 21, "location"], [23, 23, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 10, 17, 19, "physical", "", false, false], [17, 19, 21, 21, "physical", "", false, false], [21, 21, 23, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "first", "US", "edition", "of", "the", "Campus", "Party", "will", "take", "place", "from", "20", "to", "22", "August", "at", "the", "TCF", "Center", "in", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "The first US edition of the Campus Party will take place from 20 to 22 August at the TCF Center in Detroit, Michigan.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 20], [21, 23], [24, 27], [28, 34], [35, 40], [41, 45], [46, 50], [51, 56], [57, 61], [62, 64], [65, 67], [68, 70], [71, 77], [78, 80], [81, 84], [85, 88], [89, 95], [96, 98], [99, 106], [106, 107], [108, 116], [116, 117]]}
{"doc_key": "ai-test-239", "ner": [[2, 3, "researcher"], [6, 7, "researcher"], [9, 9, "researcher"], [13, 14, "misc"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 13, 14, "win-defeat", "", false, false], [6, 7, 13, 14, "win-defeat", "", false, false], [9, 9, 13, 14, "win-defeat", "", false, false], [13, 14, 23, 25, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Along", "with", "Yann", "LeCun", ",", "and", "Yoshua", "Bengio", ",", "Hinton", "won", "the", "2018", "Turing", "Award", "for", "conceptual", "and", "engineering", "advances", "that", "have", "made", "deep", "neural", "networks", "a", "critical", "component", "of", "computing", "."], "sentence-detokenized": "Along with Yann LeCun, and Yoshua Bengio, Hinton won the 2018 Turing Award for conceptual and engineering advances that have made deep neural networks a critical component of computing.", "token2charspan": [[0, 5], [6, 10], [11, 15], [16, 21], [21, 22], [23, 26], [27, 33], [34, 40], [40, 41], [42, 48], [49, 52], [53, 56], [57, 61], [62, 68], [69, 74], [75, 78], [79, 89], [90, 93], [94, 105], [106, 114], [115, 119], [120, 124], [125, 129], [130, 134], [135, 141], [142, 150], [151, 152], [153, 161], [162, 171], [172, 174], [175, 184], [184, 185]]}
{"doc_key": "ai-test-240", "ner": [[0, 2, "product"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 9, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Euler", "Math", "Toolbox", "uses", "a", "matrix", "language", "similar", "to", "MATLAB", ",", "a", "system", "that", "had", "been", "in", "development", "since", "the", "1970s", "."], "sentence-detokenized": "Euler Math Toolbox uses a matrix language similar to MATLAB, a system that had been in development since the 1970s.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 23], [24, 25], [26, 32], [33, 41], [42, 49], [50, 52], [53, 59], [59, 60], [61, 62], [63, 69], [70, 74], [75, 78], [79, 83], [84, 86], [87, 98], [99, 104], [105, 108], [109, 114], [114, 115]]}
{"doc_key": "ai-test-241", "ner": [[11, 11, "programlang"], [13, 14, "programlang"], [16, 16, "programlang"], [18, 18, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "languages", "make", "this", "possible", "in", "a", "portable", "form", "(", "e.g.", "Scheme", ",", "Common", "Lisp", ",", "Perl", "or", "D", ")", "."], "sentence-detokenized": "Some languages make this possible in a portable form (e.g. Scheme, Common Lisp, Perl or D).", "token2charspan": [[0, 4], [5, 14], [15, 19], [20, 24], [25, 33], [34, 36], [37, 38], [39, 47], [48, 52], [53, 54], [54, 58], [59, 65], [65, 66], [67, 73], [74, 78], [78, 79], [80, 84], [85, 87], [88, 89], [89, 90], [90, 91]]}
{"doc_key": "ai-test-242", "ner": [[7, 7, "misc"], [9, 10, "researcher"], [12, 13, "researcher"], [27, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 9, 10, "artifact", "", false, false], [7, 7, 12, 13, "artifact", "", false, false], [7, 7, 27, 28, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1969", ",", "a", "famous", "book", "entitled", "Perceptrons", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "showed", "that", "it", "was", "impossible", "for", "these", "kinds", "of", "networks", "to", "learn", "an", "XOR", "function", "."], "sentence-detokenized": "In 1969, a famous book entitled Perceptrons by Marvin Minsky and Seymour Papert showed that it was impossible for these kinds of networks to learn an XOR function.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 22], [23, 31], [32, 43], [44, 46], [47, 53], [54, 60], [61, 64], [65, 72], [73, 79], [80, 86], [87, 91], [92, 94], [95, 98], [99, 109], [110, 113], [114, 119], [120, 125], [126, 128], [129, 137], [138, 140], [141, 146], [147, 149], [150, 153], [154, 162], [162, 163]]}
{"doc_key": "ai-test-243", "ner": [[4, 8, "misc"], [12, 13, "product"], [18, 21, "organisation"], [25, 30, "organisation"], [33, 38, "location"], [40, 40, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 21, 12, 13, "usage", "", false, false], [18, 21, 33, 38, "physical", "", false, false], [25, 30, 18, 21, "named", "", false, false], [33, 38, 40, 40, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "large", "number", "of", "Russian", "scientific", "and", "technical", "documents", "were", "translated", "with", "SYSTRAN", "under", "the", "auspices", "of", "the", "USAF", "Foreign", "Technology", "Division", "(", "later", "the", "National", "Air", "and", "Space", "Intelligence", "Center", ")", "at", "Wright", "-", "Patterson", "Air", "Force", "Base", ",", "Ohio", "."], "sentence-detokenized": "A large number of Russian scientific and technical documents were translated with SYSTRAN under the auspices of the USAF Foreign Technology Division (later the National Air and Space Intelligence Center) at Wright-Patterson Air Force Base, Ohio.", "token2charspan": [[0, 1], [2, 7], [8, 14], [15, 17], [18, 25], [26, 36], [37, 40], [41, 50], [51, 60], [61, 65], [66, 76], [77, 81], [82, 89], [90, 95], [96, 99], [100, 108], [109, 111], [112, 115], [116, 120], [121, 128], [129, 139], [140, 148], [149, 150], [150, 155], [156, 159], [160, 168], [169, 172], [173, 176], [177, 182], [183, 195], [196, 202], [202, 203], [204, 206], [207, 213], [213, 214], [214, 223], [224, 227], [228, 233], [234, 238], [238, 239], [240, 244], [244, 245]]}
{"doc_key": "ai-test-244", "ner": [[0, 1, "field"], [4, 5, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Semi-supervised", "learning", "lies", "between", "unsupervised", "learning", "(", "without", "labelled", "training", "data", ")", "and", "supervised", "learning", "(", "with", "fully", "labelled", "training", "data", ")", "."], "sentence-detokenized": "Semi-supervised learning lies between unsupervised learning (without labelled training data) and supervised learning (with fully labelled training data).", "token2charspan": [[0, 15], [16, 24], [25, 29], [30, 37], [38, 50], [51, 59], [60, 61], [61, 68], [69, 77], [78, 86], [87, 91], [91, 92], [93, 96], [97, 107], [108, 116], [117, 118], [118, 122], [123, 128], [129, 137], [138, 146], [147, 151], [151, 152], [152, 153]]}
{"doc_key": "ai-test-245", "ner": [[0, 4, "algorithm"], [9, 11, "algorithm"], [33, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 9, 11, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Ann", "-", "gram", "model", "is", "a", "type", "of", "probabilistic", "linguistic", "model", "for", "predicting", "the", "next", "element", "of", "such", "a", "sequence", "in", "the", "form", "of", "an", "efficient", "(", "n", "-", "1", ")", "-order", "Markov", "model", "."], "sentence-detokenized": "The Ann -gram model is a type of probabilistic linguistic model for predicting the next element of such a sequence in the form of an efficient (n - 1)-order Markov model.", "token2charspan": [[0, 3], [4, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 24], [25, 29], [30, 32], [33, 46], [47, 57], [58, 63], [64, 67], [68, 78], [79, 82], [83, 87], [88, 95], [96, 98], [99, 103], [104, 105], [106, 114], [115, 117], [118, 121], [122, 126], [127, 129], [130, 132], [133, 142], [143, 144], [144, 145], [146, 147], [148, 149], [149, 150], [150, 156], [157, 163], [164, 169], [169, 170]]}
{"doc_key": "ai-test-246", "ner": [[1, 2, "organisation"], [5, 5, "product"], [9, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 5, 5, "usage", "", false, false], [9, 15, 1, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Cleveland", "Clinic", "has", "used", "Cyc", "to", "develop", "a", "natural", "language", "query", "interface", "for", "biomedical", "information", ",", "spanning", "decades", "of", "information", "on", "cardiothoracic", "surgeries", "."], "sentence-detokenized": "The Cleveland Clinic has used Cyc to develop a natural language query interface for biomedical information, spanning decades of information on cardiothoracic surgeries.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 24], [25, 29], [30, 33], [34, 36], [37, 44], [45, 46], [47, 54], [55, 63], [64, 69], [70, 79], [80, 83], [84, 94], [95, 106], [106, 107], [108, 116], [117, 124], [125, 127], [128, 139], [140, 142], [143, 157], [158, 167], [167, 168]]}
{"doc_key": "ai-test-247", "ner": [[6, 6, "country"], [8, 12, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 6, 8, 12, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "incident", "strained", "relations", "between", "the", "US", "and", "Japan", ",", "leading", "to", "the", "arrest", "and", "prosecution", "of", "two", "senior", "executives", "and", "the", "imposition", "of", "sanctions", "on", "the", "company", "by", "both", "countries", "."], "sentence-detokenized": "The incident strained relations between the US and Japan, leading to the arrest and prosecution of two senior executives and the imposition of sanctions on the company by both countries.", "token2charspan": [[0, 3], [4, 12], [13, 21], [22, 31], [32, 39], [40, 43], [44, 46], [47, 50], [51, 56], [56, 57], [58, 65], [66, 68], [69, 72], [73, 79], [80, 83], [84, 95], [96, 98], [99, 102], [103, 109], [110, 120], [121, 124], [125, 128], [129, 139], [140, 142], [143, 152], [153, 155], [156, 159], [160, 167], [168, 170], [171, 175], [176, 185], [185, 186]]}
{"doc_key": "ai-test-248", "ner": [[7, 9, "algorithm"], [12, 13, "field"], [22, 22, "misc"], [35, 35, "misc"], [39, 39, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 9, 12, 13, "type-of", "", false, false], [22, 22, 12, 13, "part-of", "", true, false], [35, 35, 12, 13, "part-of", "", true, false], [39, 39, 12, 13, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["If", "the", "modelling", "is", "done", "using", "an", "artificial", "neural", "network", "or", "other", "machine", "learning", ",", "the", "optimisation", "of", "the", "parameters", "is", "called", "training", ",", "while", "the", "optimisation", "of", "the", "hyperparameters", "of", "the", "model", "is", "called", "tuning", "and", "usually", "uses", "cross-validation", "."], "sentence-detokenized": "If the modelling is done using an artificial neural network or other machine learning, the optimisation of the parameters is called training, while the optimisation of the hyperparameters of the model is called tuning and usually uses cross-validation.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 24], [25, 30], [31, 33], [34, 44], [45, 51], [52, 59], [60, 62], [63, 68], [69, 76], [77, 85], [85, 86], [87, 90], [91, 103], [104, 106], [107, 110], [111, 121], [122, 124], [125, 131], [132, 140], [140, 141], [142, 147], [148, 151], [152, 164], [165, 167], [168, 171], [172, 187], [188, 190], [191, 194], [195, 200], [201, 203], [204, 210], [211, 217], [218, 221], [222, 229], [230, 234], [235, 251], [251, 252]]}
{"doc_key": "ai-test-249", "ner": [[8, 8, "country"], [10, 10, "country"], [12, 12, "country"], [20, 21, "organisation"], [16, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[20, 21, 16, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Localised", "versions", "of", "the", "site", "available", "in", "the", "UK", ",", "India", "and", "Australia", "were", "discontinued", "following", "Fandango", "'s", "acquisition", "of", "Rotten", "Tomatoes", "."], "sentence-detokenized": "Localised versions of the site available in the UK, India and Australia were discontinued following Fandango's acquisition of Rotten Tomatoes.", "token2charspan": [[0, 9], [10, 18], [19, 21], [22, 25], [26, 30], [31, 40], [41, 43], [44, 47], [48, 50], [50, 51], [52, 57], [58, 61], [62, 71], [72, 76], [77, 89], [90, 99], [100, 108], [108, 110], [111, 122], [123, 125], [126, 132], [133, 141], [141, 142]]}
{"doc_key": "ai-test-250", "ner": [[1, 1, "task"], [11, 11, "metrics"], [22, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 11, 11, "related-to", "", false, false], [11, 11, 22, 23, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "NER", "model", "is", "one", "of", "the", "methods", "for", "determining", "the", "accuracy", "of", "live", "subtitles", "in", "television", "broadcasts", "and", "events", "produced", "by", "speech", "recognition", "."], "sentence-detokenized": "The NER model is one of the methods for determining the accuracy of live subtitles in television broadcasts and events produced by speech recognition.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 20], [21, 23], [24, 27], [28, 35], [36, 39], [40, 51], [52, 55], [56, 64], [65, 67], [68, 72], [73, 82], [83, 85], [86, 96], [97, 107], [108, 111], [112, 118], [119, 127], [128, 130], [131, 137], [138, 149], [149, 150]]}
{"doc_key": "ai-test-251", "ner": [[0, 0, "researcher"], [4, 5, "university"], [8, 9, "university"], [11, 11, "location"], [14, 18, "university"], [21, 22, "university"], [24, 24, "location"], [28, 33, "university"], [35, 36, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 5, "physical", "", false, false], [0, 0, 4, 5, "role", "", false, false], [0, 0, 8, 9, "physical", "", false, false], [0, 0, 8, 9, "role", "", false, false], [0, 0, 14, 18, "physical", "", false, false], [0, 0, 14, 18, "role", "", false, false], [0, 0, 21, 22, "physical", "", false, false], [0, 0, 21, 22, "role", "", false, false], [0, 0, 28, 33, "physical", "", false, false], [0, 0, 28, 33, "role", "", false, false], [8, 9, 11, 11, "physical", "", false, false], [14, 18, 24, 24, "physical", "", false, false], [21, 22, 24, 24, "physical", "", false, false], [28, 33, 35, 36, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Atran", "has", "taught", "at", "Cambridge", "University", ",", "the", "Hebrew", "University", "of", "Jerusalem", ",", "the", "\u00c9cole", "pratique", "des", "hautes", "\u00e9tudes", "and", "the", "\u00c9cole", "Polytechnique", "in", "Paris", ",", "and", "the", "John", "Jay", "College", "of", "Criminal", "Justice", "in", "New", "York", "."], "sentence-detokenized": "Atran has taught at Cambridge University, the Hebrew University of Jerusalem, the \u00c9cole pratique des hautes \u00e9tudes and the \u00c9cole Polytechnique in Paris, and the John Jay College of Criminal Justice in New York.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 40], [40, 41], [42, 45], [46, 52], [53, 63], [64, 66], [67, 76], [76, 77], [78, 81], [82, 87], [88, 96], [97, 100], [101, 107], [108, 114], [115, 118], [119, 122], [123, 128], [129, 142], [143, 145], [146, 151], [151, 152], [153, 156], [157, 160], [161, 165], [166, 169], [170, 177], [178, 180], [181, 189], [190, 197], [198, 200], [201, 204], [205, 209], [209, 210]]}
{"doc_key": "ai-test-252", "ner": [[0, 1, "product"], [6, 8, "task"], [12, 13, "researcher"], [15, 15, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 6, 8, "origin", "", false, false], [0, 1, 6, 8, "related-to", "", false, false], [6, 8, 15, 15, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "was", "one", "of", "the", "first", "natural", "language", "understanding", "software", "developed", "by", "Terry", "Winograd", "at", "MIT", "in", "1968", "-", "1970", "."], "sentence-detokenized": "SHRDLU was one of the first natural language understanding software developed by Terry Winograd at MIT in 1968-1970.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 17], [18, 21], [22, 27], [28, 35], [36, 44], [45, 58], [59, 67], [68, 77], [78, 80], [81, 86], [87, 95], [96, 98], [99, 102], [103, 105], [106, 110], [110, 111], [111, 115], [115, 116]]}
{"doc_key": "ai-test-253", "ner": [[3, 3, "misc"], [6, 8, "field"], [9, 13, "university"], [15, 15, "location"], [17, 17, "country"], [25, 26, "university"], [29, 30, "misc"], [32, 36, "field"], [40, 44, "university"], [45, 46, "misc"], [48, 49, "field"], [54, 56, "misc"], [63, 67, "university"], [72, 73, "field"], [77, 78, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[3, 3, 6, 8, "topic", "", false, false], [3, 3, 9, 13, "origin", "", false, false], [9, 13, 15, 15, "physical", "", false, false], [9, 13, 25, 26, "role", "affiliated_with", false, false], [15, 15, 17, 17, "physical", "", false, false], [29, 30, 32, 36, "topic", "", false, false], [29, 30, 40, 44, "origin", "", false, false], [45, 46, 48, 49, "topic", "", false, false], [54, 56, 63, 67, "origin", "", false, false], [54, 56, 72, 73, "topic", "", false, false], [77, 78, 63, 67, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["He", "received", "a", "B.S.", "degree", "in", "electrical", "engineering", "from", "B.M.S", ".", "College", "of", "Engineering", ",", "Bangalore", ",", "India", ",", "in", "1982", ",", "while", "affiliated", "with", "Bangalore", "University", ",", "an", "M.S.", "degree", "in", "electrical", "engineering", "and", "computer", "science", "in", "1984", "from", "Drexel", "University", ",", "and", "an", "M.S.", "degree", "in", "computer", "science", "in", "1989", "and", "a", "Ph.D.", "degree", "in", "1990", ",", "respectively", ",", "from", "the", "University", "of", "Wisconsin", "-", "Madison", ",", "where", "he", "studied", "Artificial", "Intelligence", "and", "worked", "with", "Leonard", "Uhr", "."], "sentence-detokenized": "He received a B.S. degree in electrical engineering from B.M.S. College of Engineering, Bangalore, India, in 1982, while affiliated with Bangalore University, an M.S. degree in electrical engineering and computer science in 1984 from Drexel University, and an M.S. degree in computer science in 1989 and a Ph.D. degree in 1990, respectively, from the University of Wisconsin-Madison, where he studied Artificial Intelligence and worked with Leonard Uhr.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 18], [19, 25], [26, 28], [29, 39], [40, 51], [52, 56], [57, 62], [62, 63], [64, 71], [72, 74], [75, 86], [86, 87], [88, 97], [97, 98], [99, 104], [104, 105], [106, 108], [109, 113], [113, 114], [115, 120], [121, 131], [132, 136], [137, 146], [147, 157], [157, 158], [159, 161], [162, 166], [167, 173], [174, 176], [177, 187], [188, 199], [200, 203], [204, 212], [213, 220], [221, 223], [224, 228], [229, 233], [234, 240], [241, 251], [251, 252], [253, 256], [257, 259], [260, 264], [265, 271], [272, 274], [275, 283], [284, 291], [292, 294], [295, 299], [300, 303], [304, 305], [306, 311], [312, 318], [319, 321], [322, 326], [326, 327], [328, 340], [340, 341], [342, 346], [347, 350], [351, 361], [362, 364], [365, 374], [374, 375], [375, 382], [382, 383], [384, 389], [390, 392], [393, 400], [401, 411], [412, 424], [425, 428], [429, 435], [436, 440], [441, 448], [449, 452], [452, 453]]}
{"doc_key": "ai-test-254", "ner": [[6, 8, "metrics"], [10, 10, "metrics"], [19, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Accuracy", "is", "usually", "measured", "by", "the", "word", "error", "rate", "(", "WER", ")", ",", "while", "speed", "is", "measured", "by", "the", "real", "time", "factor", "."], "sentence-detokenized": "Accuracy is usually measured by the word error rate (WER), while speed is measured by the real time factor.", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 28], [29, 31], [32, 35], [36, 40], [41, 46], [47, 51], [52, 53], [53, 56], [56, 57], [57, 58], [59, 64], [65, 70], [71, 73], [74, 82], [83, 85], [86, 89], [90, 94], [95, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-test-255", "ner": [[3, 4, "researcher"], [8, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 8, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1971", ",", "Terry", "Winograd", "developed", "the", "first", "natural", "language", "processing", "engine", "capable", "of", "interpreting", "naturally", "typed", "commands", "in", "a", "simple", "rule", "-", "driven", "environment", "."], "sentence-detokenized": "In 1971, Terry Winograd developed the first natural language processing engine capable of interpreting naturally typed commands in a simple rule-driven environment.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 33], [34, 37], [38, 43], [44, 51], [52, 60], [61, 71], [72, 78], [79, 86], [87, 89], [90, 102], [103, 112], [113, 118], [119, 127], [128, 130], [131, 132], [133, 139], [140, 144], [144, 145], [145, 151], [152, 163], [163, 164]]}
{"doc_key": "ai-test-256", "ner": [[1, 2, "field"], [4, 5, "researcher"], [7, 10, "researcher"], [12, 13, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 4, 5, "related-to", "", false, false], [1, 2, 7, 10, "related-to", "", false, false], [1, 2, 12, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "artificial", "intelligence", ",", "Marvin", "Minsky", ",", "Herbert", "A", ".", "Simon", "and", "Allen", "Newell", "stand", "out", "."], "sentence-detokenized": "In artificial intelligence, Marvin Minsky, Herbert A. Simon and Allen Newell stand out.", "token2charspan": [[0, 2], [3, 13], [14, 26], [26, 27], [28, 34], [35, 41], [41, 42], [43, 50], [51, 52], [52, 53], [54, 59], [60, 63], [64, 69], [70, 76], [77, 82], [83, 86], [86, 87]]}
{"doc_key": "ai-test-257", "ner": [[9, 10, "field"], [30, 31, "field"], [33, 34, "field"], [40, 41, "field"], [50, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[30, 31, 9, 10, "origin", "", true, false], [30, 31, 9, 10, "part-of", "", false, false], [30, 31, 40, 41, "compare", "", false, false], [33, 34, 9, 10, "origin", "", true, false], [33, 34, 9, 10, "part-of", "", false, false], [33, 34, 40, 41, "compare", "", false, false], [40, 41, 9, 10, "origin", "", true, false], [40, 41, 9, 10, "part-of", "", false, false], [40, 41, 50, 53, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "the", "second", "half", "of", "the", "20th", "century", ",", "electrical", "engineering", "itself", "split", "into", "several", "disciplines", ",", "specialising", "in", "the", "design", "and", "analysis", "of", "systems", "that", "manipulate", "physical", "signals", ";", "electronic", "engineering", "and", "computer", "engineering", ",", "for", "example", ",", "while", "design", "engineering", "developed", "to", "deal", "with", "the", "functional", "design", "of", "user", "-", "machine", "interfaces", "."], "sentence-detokenized": "In the second half of the 20th century, electrical engineering itself split into several disciplines, specialising in the design and analysis of systems that manipulate physical signals; electronic engineering and computer engineering, for example, while design engineering developed to deal with the functional design of user-machine interfaces.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 21], [22, 25], [26, 30], [31, 38], [38, 39], [40, 50], [51, 62], [63, 69], [70, 75], [76, 80], [81, 88], [89, 100], [100, 101], [102, 114], [115, 117], [118, 121], [122, 128], [129, 132], [133, 141], [142, 144], [145, 152], [153, 157], [158, 168], [169, 177], [178, 185], [185, 186], [187, 197], [198, 209], [210, 213], [214, 222], [223, 234], [234, 235], [236, 239], [240, 247], [247, 248], [249, 254], [255, 261], [262, 273], [274, 283], [284, 286], [287, 291], [292, 296], [297, 300], [301, 311], [312, 318], [319, 321], [322, 326], [326, 327], [327, 334], [335, 345], [345, 346]]}
{"doc_key": "ai-test-258", "ner": [[6, 6, "metrics"], [8, 9, "metrics"], [11, 11, "metrics"], [48, 49, "metrics"], [56, 58, "metrics"], [62, 68, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 8, 9, "named", "", false, false], [48, 49, 56, 58, "named", "", false, false], [56, 58, 62, 68, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Perhaps", "the", "simplest", "statistic", "is", "the", "accuracy", "or", "Correct", "Fraction", "(", "CF", ")", ",", "which", "measures", "the", "fraction", "of", "all", "instances", "that", "are", "correctly", "classified", ";", "it", "is", "the", "ratio", "of", "the", "number", "of", "correct", "classifications", "to", "the", "total", "number", "of", "correct", "or", "incorrect", "classifications", ":", "(", "TP", "+", "TN", ")", "/", "Total", "population", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "Perhaps the simplest statistic is the accuracy or Correct Fraction (CF), which measures the fraction of all instances that are correctly classified; it is the ratio of the number of correct classifications to the total number of correct or incorrect classifications: (TP + TN) / Total population = (TP + TN) / (TP + TN + FP + FN).", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 30], [31, 33], [34, 37], [38, 46], [47, 49], [50, 57], [58, 66], [67, 68], [68, 70], [70, 71], [71, 72], [73, 78], [79, 87], [88, 91], [92, 100], [101, 103], [104, 107], [108, 117], [118, 122], [123, 126], [127, 136], [137, 147], [147, 148], [149, 151], [152, 154], [155, 158], [159, 164], [165, 167], [168, 171], [172, 178], [179, 181], [182, 189], [190, 205], [206, 208], [209, 212], [213, 218], [219, 225], [226, 228], [229, 236], [237, 239], [240, 249], [250, 265], [265, 266], [267, 268], [268, 270], [271, 272], [273, 275], [275, 276], [277, 278], [279, 284], [285, 295], [296, 297], [298, 299], [299, 301], [302, 303], [304, 306], [306, 307], [308, 309], [310, 311], [311, 313], [314, 315], [316, 318], [319, 320], [321, 323], [324, 325], [326, 328], [328, 329], [329, 330]]}
{"doc_key": "ai-test-259", "ner": [[15, 23, "conference"], [25, 27, "conference"], [32, 32, "location"], [37, 38, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 23, 32, 32, "physical", "", false, false], [25, 27, 15, 23, "named", "", false, false], [37, 38, 15, 23, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "academic", "community", ",", "the", "main", "research", "forums", "started", "in", "1995", ",", "when", "the", "First", "International", "Conference", "on", "Data", "Mining", "and", "Knowledge", "Discovery", "(", "KDD", "-", "95", ")", "was", "launched", "in", "Montreal", "under", "the", "sponsorship", "of", "the", "AAAI", "."], "sentence-detokenized": "In the academic community, the main research forums started in 1995, when the First International Conference on Data Mining and Knowledge Discovery (KDD-95) was launched in Montreal under the sponsorship of the AAAI.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 25], [25, 26], [27, 30], [31, 35], [36, 44], [45, 51], [52, 59], [60, 62], [63, 67], [67, 68], [69, 73], [74, 77], [78, 83], [84, 97], [98, 108], [109, 111], [112, 116], [117, 123], [124, 127], [128, 137], [138, 147], [148, 149], [149, 152], [152, 153], [153, 155], [155, 156], [157, 160], [161, 169], [170, 172], [173, 181], [182, 187], [188, 191], [192, 203], [204, 206], [207, 210], [211, 215], [215, 216]]}
{"doc_key": "ai-test-260", "ner": [[9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "this", "approach", ",", "models", "are", "developed", "using", "different", "data", "mining", "and", "machine", "learning", "algorithms", "to", "predict", "user", "ratings", "of", "unrated", "items", "."], "sentence-detokenized": "In this approach, models are developed using different data mining and machine learning algorithms to predict user ratings of unrated items.", "token2charspan": [[0, 2], [3, 7], [8, 16], [16, 17], [18, 24], [25, 28], [29, 38], [39, 44], [45, 54], [55, 59], [60, 66], [67, 70], [71, 78], [79, 87], [88, 98], [99, 101], [102, 109], [110, 114], [115, 122], [123, 125], [126, 133], [134, 139], [139, 140]]}
{"doc_key": "ai-test-261", "ner": [[11, 11, "algorithm"], [17, 18, "algorithm"], [20, 21, "algorithm"], [28, 29, "misc"], [32, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 11, 17, 18, "related-to", "equivalent", false, false], [17, 18, 20, 21, "usage", "", false, false], [20, 21, 32, 33, "usage", "", false, false], [32, 33, 28, 29, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "light", "of", "the", "above", "discussion", ",", "we", "see", "that", "the", "SVM", "technique", "is", "equivalent", "to", "the", "empirical", "risk", "with", "Tikhonov", "regularisation", ",", "where", "in", "this", "case", "the", "loss", "function", "is", "the", "hinge", "loss", "."], "sentence-detokenized": "In light of the above discussion, we see that the SVM technique is equivalent to the empirical risk with Tikhonov regularisation, where in this case the loss function is the hinge loss.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 15], [16, 21], [22, 32], [32, 33], [34, 36], [37, 40], [41, 45], [46, 49], [50, 53], [54, 63], [64, 66], [67, 77], [78, 80], [81, 84], [85, 94], [95, 99], [100, 104], [105, 113], [114, 128], [128, 129], [130, 135], [136, 138], [139, 143], [144, 148], [149, 152], [153, 157], [158, 166], [167, 169], [170, 173], [174, 179], [180, 184], [184, 185]]}
{"doc_key": "ai-test-262", "ner": [[6, 7, "person"], [10, 11, "person"], [14, 14, "organisation"], [16, 17, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 17, 14, 14, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "2015", "edition", "was", "hosted", "by", "Molly", "McGrath", ",", "with", "Chris", "Rose", "and", "former", "UFC", "fighter", "Kenny", "Florian", "as", "commentators", "."], "sentence-detokenized": "The 2015 edition was hosted by Molly McGrath, with Chris Rose and former UFC fighter Kenny Florian as commentators.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 27], [28, 30], [31, 36], [37, 44], [44, 45], [46, 50], [51, 56], [57, 61], [62, 65], [66, 72], [73, 76], [77, 84], [85, 90], [91, 98], [99, 101], [102, 114], [114, 115]]}
{"doc_key": "ai-test-263", "ner": [[3, 5, "product"], [9, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [18, 18, "researcher"], [21, 21, "researcher"], [29, 31, "task"], [33, 33, "product"], [35, 36, "researcher"], [38, 39, "task"], [42, 42, "researcher"], [47, 48, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12], "relations": [[3, 5, 9, 11, "origin", "", false, false], [3, 5, 13, 14, "origin", "", false, false], [3, 5, 16, 17, "origin", "", false, false], [3, 5, 18, 18, "origin", "", false, false], [13, 14, 35, 36, "named", "same", false, false], [16, 17, 21, 21, "named", "same", false, false], [29, 31, 33, 33, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 7], "sentence": ["A", "subset", "called", "Micro", "-", "Planner", "was", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "Sussman", ",", "and", "Winograd", "1971", "and", "was", "used", "in", "Winograd", "'s", "natural", "language", "understanding", "programme", "SHRDLU", ",", "Eugene", "Charniak", "'s", "story", "understanding", "work", ",", "Thorne", "McCarty", "'s", "work", "on", "legal", "reasoning", ",", "and", "some", "other", "projects", "."], "sentence-detokenized": "A subset called Micro-Planner was implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd Sussman, and Winograd 1971 and was used in Winograd's natural language understanding programme SHRDLU, Eugene Charniak's story understanding work, Thorne McCarty's work on legal reasoning, and some other projects.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [21, 22], [22, 29], [30, 33], [34, 45], [46, 48], [49, 55], [56, 59], [60, 67], [67, 68], [69, 75], [76, 84], [85, 88], [89, 94], [95, 103], [104, 111], [111, 112], [113, 116], [117, 125], [126, 130], [131, 134], [135, 138], [139, 143], [144, 146], [147, 155], [155, 157], [158, 165], [166, 174], [175, 188], [189, 198], [199, 205], [205, 206], [207, 213], [214, 222], [222, 224], [225, 230], [231, 244], [245, 249], [249, 250], [251, 257], [258, 265], [265, 267], [268, 272], [273, 275], [276, 281], [282, 291], [291, 292], [293, 296], [297, 301], [302, 307], [308, 316], [316, 317]]}
{"doc_key": "ai-test-264", "ner": [[0, 1, "product"], [11, 12, "product"], [16, 18, "task"], [20, 21, "task"], [23, 25, "task"], [27, 28, "task"], [30, 31, "task"], [34, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 0, 1, "usage", "", true, false], [16, 18, 11, 12, "part-of", "", true, false], [20, 21, 11, 12, "part-of", "", true, false], [23, 25, 11, 12, "part-of", "", true, false], [27, 28, 11, 12, "part-of", "", true, false], [30, 31, 11, 12, "part-of", "", true, false], [34, 36, 11, 12, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Word", "Net", "has", "been", "used", "for", "a", "variety", "of", "purposes", "in", "information", "systems", ",", "such", "as", "word", "sense", "disambiguation", ",", "information", "retrieval", ",", "automatic", "text", "classification", ",", "automatic", "summarisation", ",", "automatic", "translation", "and", "even", "automatic", "crossword", "generation", "."], "sentence-detokenized": "WordNet has been used for a variety of purposes in information systems, such as word sense disambiguation, information retrieval, automatic text classification, automatic summarisation, automatic translation and even automatic crossword generation.", "token2charspan": [[0, 4], [4, 7], [8, 11], [12, 16], [17, 21], [22, 25], [26, 27], [28, 35], [36, 38], [39, 47], [48, 50], [51, 62], [63, 70], [70, 71], [72, 76], [77, 79], [80, 84], [85, 90], [91, 105], [105, 106], [107, 118], [119, 128], [128, 129], [130, 139], [140, 144], [145, 159], [159, 160], [161, 170], [171, 184], [184, 185], [186, 195], [196, 207], [208, 211], [212, 216], [217, 226], [227, 236], [237, 247], [247, 248]]}
{"doc_key": "ai-test-265", "ner": [[0, 0, "researcher"], [7, 7, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 7, 7, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Keutzer", "was", "appointed", "a", "Fellow", "of", "the", "IEEE", "in", "1996", "."], "sentence-detokenized": "Keutzer was appointed a Fellow of the IEEE in 1996.", "token2charspan": [[0, 7], [8, 11], [12, 21], [22, 23], [24, 30], [31, 33], [34, 37], [38, 42], [43, 45], [46, 50], [50, 51]]}
{"doc_key": "ai-test-266", "ner": [[8, 10, "algorithm"], [51, 52, "misc"], [62, 63, "algorithm"], [66, 67, "algorithm"], [70, 71, "algorithm"], [75, 76, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[62, 63, 51, 52, "type-of", "", false, false], [66, 67, 51, 52, "type-of", "", false, false], [70, 71, 51, 52, "type-of", "", false, false], [75, 76, 51, 52, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "widely", "used", "type", "of", "composition", "is", "the", "non-linear", "weighted", "sum", ",", "where", "math", "\\", "textstyle", "f", "(", "x", ")", "=", "left", "K", "(", "sum", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "/", "math", ",", "where", "math", "\\", "textstyle", "K", "/", "math", "(", "commonly", "known", "as", "the", "activation", "function", ")", "is", "some", "predefined", "function", ",", "such", "as", "the", "hyperbolic", "tangent", ",", "the", "sigmoid", "function", ",", "the", "softmax", "function", ",", "or", "the", "rectifier", "function", "."], "sentence-detokenized": "A widely used type of composition is the non-linear weighted sum, where math\\ textstyle f (x) = left K (sum _ i w _ i g _ i (x)/math, where math\\ textstyle K /math (commonly known as the activation function) is some predefined function, such as the hyperbolic tangent, the sigmoid function, the softmax function, or the rectifier function.", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 18], [19, 21], [22, 33], [34, 36], [37, 40], [41, 51], [52, 60], [61, 64], [64, 65], [66, 71], [72, 76], [76, 77], [78, 87], [88, 89], [90, 91], [91, 92], [92, 93], [94, 95], [96, 100], [101, 102], [103, 104], [104, 107], [108, 109], [110, 111], [112, 113], [114, 115], [116, 117], [118, 119], [120, 121], [122, 123], [124, 125], [125, 126], [126, 127], [127, 128], [128, 132], [132, 133], [134, 139], [140, 144], [144, 145], [146, 155], [156, 157], [158, 159], [159, 163], [164, 165], [165, 173], [174, 179], [180, 182], [183, 186], [187, 197], [198, 206], [206, 207], [208, 210], [211, 215], [216, 226], [227, 235], [235, 236], [237, 241], [242, 244], [245, 248], [249, 259], [260, 267], [267, 268], [269, 272], [273, 280], [281, 289], [289, 290], [291, 294], [295, 302], [303, 311], [311, 312], [313, 315], [316, 319], [320, 329], [330, 338], [338, 339]]}
{"doc_key": "ai-test-267", "ner": [[3, 3, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "film", "Westworld", ",", "female", "robots", "had", "sex", "with", "human", "men", "as", "part", "of", "the", "imaginary", "holiday", "world", "that", "human", "customers", "paid", "for", "."], "sentence-detokenized": "In the film Westworld, female robots had sex with human men as part of the imaginary holiday world that human customers paid for.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 21], [21, 22], [23, 29], [30, 36], [37, 40], [41, 44], [45, 49], [50, 55], [56, 59], [60, 62], [63, 67], [68, 70], [71, 74], [75, 84], [85, 92], [93, 98], [99, 103], [104, 109], [110, 119], [120, 124], [125, 128], [128, 129]]}
{"doc_key": "ai-test-268", "ner": [[7, 9, "task"], [24, 29, "task"], [31, 32, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 24, 29, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Typically", ",", "the", "process", "begins", "with", "the", "extraction", "of", "terminology", "and", "concepts", "or", "noun", "phrases", "from", "plain", "text", ",", "using", "linguistic", "processors", "such", "as", "part", "-", "of", "-", "speech", "tagging", "and", "sentence", "fragmentation", "."], "sentence-detokenized": "Typically, the process begins with the extraction of terminology and concepts or noun phrases from plain text, using linguistic processors such as part-of-speech tagging and sentence fragmentation.", "token2charspan": [[0, 9], [9, 10], [11, 14], [15, 22], [23, 29], [30, 34], [35, 38], [39, 49], [50, 52], [53, 64], [65, 68], [69, 77], [78, 80], [81, 85], [86, 93], [94, 98], [99, 104], [105, 109], [109, 110], [111, 116], [117, 127], [128, 138], [139, 143], [144, 146], [147, 151], [151, 152], [152, 154], [154, 155], [155, 161], [162, 169], [170, 173], [174, 182], [183, 196], [196, 197]]}
{"doc_key": "ai-test-269", "ner": [[12, 13, "field"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 18, 12, 13, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "demonstrated", "performance", "on", "a", "range", "of", "problems", "of", "interest", "to", "the", "machine", "learning", "community", ",", "including", "handwriting", "recognition", "."], "sentence-detokenized": "They demonstrated performance on a range of problems of interest to the machine learning community, including handwriting recognition.", "token2charspan": [[0, 4], [5, 17], [18, 29], [30, 32], [33, 34], [35, 40], [41, 43], [44, 52], [53, 55], [56, 64], [65, 67], [68, 71], [72, 79], [80, 88], [89, 98], [98, 99], [100, 109], [110, 121], [122, 133], [133, 134]]}
{"doc_key": "ai-test-270", "ner": [[3, 3, "university"], [5, 5, "researcher"], [11, 12, "researcher"], [18, 18, "product"], [22, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 5, 3, 3, "physical", "", false, false], [5, 5, 3, 3, "role", "", false, false], [18, 18, 11, 12, "origin", "", false, false], [18, 18, 22, 23, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "studying", "at", "Stanford", ",", "Scheinman", "won", "a", "scholarship", "sponsored", "by", "George", "Devol", ",", "the", "inventor", "of", "the", "Unimate", ",", "the", "first", "industrial", "robot", "."], "sentence-detokenized": "While studying at Stanford, Scheinman won a scholarship sponsored by George Devol, the inventor of the Unimate, the first industrial robot.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [26, 27], [28, 37], [38, 41], [42, 43], [44, 55], [56, 65], [66, 68], [69, 75], [76, 81], [81, 82], [83, 86], [87, 95], [96, 98], [99, 102], [103, 110], [110, 111], [112, 115], [116, 121], [122, 132], [133, 138], [138, 139]]}
{"doc_key": "ai-test-271", "ner": [[5, 6, "task"], [9, 11, "metrics"], [13, 13, "metrics"], [21, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 9, 11, "usage", "", true, false], [13, 13, 9, 11, "named", "", false, false], [21, 23, 9, 11, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Although", "originally", "used", "to", "evaluate", "machine", "translations", ",", "the", "bilingual", "evaluation", "study", "(", "BLEU", ")", "has", "been", "successfully", "used", "to", "evaluate", "paraphrase", "generation", "models", "as", "well", "."], "sentence-detokenized": "Although originally used to evaluate machine translations, the bilingual evaluation study (BLEU) has been successfully used to evaluate paraphrase generation models as well.", "token2charspan": [[0, 8], [9, 19], [20, 24], [25, 27], [28, 36], [37, 44], [45, 57], [57, 58], [59, 62], [63, 72], [73, 83], [84, 89], [90, 91], [91, 95], [95, 96], [97, 100], [101, 105], [106, 118], [119, 123], [124, 126], [127, 135], [136, 146], [147, 157], [158, 164], [165, 167], [168, 172], [172, 173]]}
{"doc_key": "ai-test-272", "ner": [[0, 0, "organisation"], [6, 8, "organisation"], [10, 10, "organisation"], [14, 14, "product"], [16, 16, "country"], [18, 18, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 8, "role", "licenses_to", false, false], [0, 0, 10, 10, "role", "licenses_to", false, false], [6, 8, 16, 16, "physical", "", false, false], [10, 10, 18, 18, "physical", "", false, false], [14, 14, 6, 8, "artifact", "produces", false, false], [14, 14, 10, 10, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "subsequently", "licensed", "its", "technology", "to", "Kawasaki", "Heavy", "Industries", "and", "GKN", ",", "which", "manufactured", "Unimates", "in", "Japan", "and", "England", ",", "respectively", "."], "sentence-detokenized": "Unimation subsequently licensed its technology to Kawasaki Heavy Industries and GKN, which manufactured Unimates in Japan and England, respectively.", "token2charspan": [[0, 9], [10, 22], [23, 31], [32, 35], [36, 46], [47, 49], [50, 58], [59, 64], [65, 75], [76, 79], [80, 83], [83, 84], [85, 90], [91, 103], [104, 112], [113, 115], [116, 121], [122, 125], [126, 133], [133, 134], [135, 147], [147, 148]]}
{"doc_key": "ai-test-273", "ner": [[18, 19, "conference"], [36, 37, "field"], [55, 59, "field"], [61, 61, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[36, 37, 55, 59, "compare", "", false, false], [61, 61, 55, 59, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Much", "of", "the", "confusion", "between", "these", "two", "research", "communities", "(", "which", "often", "have", "separate", "conferences", "and", "journals", ",", "ECML", "PKDD", "being", "an", "important", "exception", ")", "stems", "from", "the", "basic", "assumptions", "under", "which", "they", "work", ":", "in", "machine", "learning", ",", "performance", "is", "usually", "evaluated", "with", "respect", "to", "the", "ability", "to", "reproduce", "known", "knowledge", ",", "while", "in", "knowledge", "discovery", "and", "data", "mining", "(", "KDD", ")", "the", "key", "task", "is", "the", "discovery", "of", "previously", "unknown", "knowledge", "."], "sentence-detokenized": "Much of the confusion between these two research communities (which often have separate conferences and journals, ECML PKDD being an important exception) stems from the basic assumptions under which they work: in machine learning, performance is usually evaluated with respect to the ability to reproduce known knowledge, while in knowledge discovery and data mining (KDD) the key task is the discovery of previously unknown knowledge.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 29], [30, 35], [36, 39], [40, 48], [49, 60], [61, 62], [62, 67], [68, 73], [74, 78], [79, 87], [88, 99], [100, 103], [104, 112], [112, 113], [114, 118], [119, 123], [124, 129], [130, 132], [133, 142], [143, 152], [152, 153], [154, 159], [160, 164], [165, 168], [169, 174], [175, 186], [187, 192], [193, 198], [199, 203], [204, 208], [208, 209], [210, 212], [213, 220], [221, 229], [229, 230], [231, 242], [243, 245], [246, 253], [254, 263], [264, 268], [269, 276], [277, 279], [280, 283], [284, 291], [292, 294], [295, 304], [305, 310], [311, 320], [320, 321], [322, 327], [328, 330], [331, 340], [341, 350], [351, 354], [355, 359], [360, 366], [367, 368], [368, 371], [371, 372], [373, 376], [377, 380], [381, 385], [386, 388], [389, 392], [393, 402], [403, 405], [406, 416], [417, 424], [425, 434], [434, 435]]}
{"doc_key": "ai-test-274", "ner": [[0, 1, "algorithm"], [9, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 9, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Hidden", "Markov", "models", "are", "the", "basis", "of", "most", "modern", "automatic", "speech", "recognition", "systems", "."], "sentence-detokenized": "Hidden Markov models are the basis of most modern automatic speech recognition systems.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 28], [29, 34], [35, 37], [38, 42], [43, 49], [50, 59], [60, 66], [67, 78], [79, 86], [86, 87]]}
{"doc_key": "ai-test-275", "ner": [[1, 1, "location"], [2, 5, "country"], [11, 11, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 2, 5, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["a", "Bangalore", ",", "India", "-", "based", "company", "specialising", "in", "online", "handwriting", "recognition", "software", "."], "sentence-detokenized": "a Bangalore, India-based company specialising in online handwriting recognition software.", "token2charspan": [[0, 1], [2, 11], [11, 12], [13, 18], [18, 19], [19, 24], [25, 32], [33, 45], [46, 48], [49, 55], [56, 67], [68, 79], [80, 88], [88, 89]]}
{"doc_key": "ai-test-276", "ner": [[26, 27, "misc"], [50, 50, "metrics"], [52, 54, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[50, 50, 52, 54, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Do", "the", "repeated", "translations", "become", "a", "single", "expression", "in", "both", "languages", "?", "That", "is", ",", "does", "the", "translation", "method", "show", "stationarity", "or", "does", "it", "produce", "a", "canonical", "form", "?", "Does", "the", "translation", "become", "stationary", "without", "losing", "the", "original", "meaning", "?", "This", "metric", "has", "been", "criticised", "for", "not", "correlating", "well", "with", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "scores", "."], "sentence-detokenized": "Do the repeated translations become a single expression in both languages? That is, does the translation method show stationarity or does it produce a canonical form? Does the translation become stationary without losing the original meaning? This metric has been criticised for not correlating well with BLEU (BiLingual Evaluation Understudy) scores.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 28], [29, 35], [36, 37], [38, 44], [45, 55], [56, 58], [59, 63], [64, 73], [73, 74], [75, 79], [80, 82], [82, 83], [84, 88], [89, 92], [93, 104], [105, 111], [112, 116], [117, 129], [130, 132], [133, 137], [138, 140], [141, 148], [149, 150], [151, 160], [161, 165], [165, 166], [167, 171], [172, 175], [176, 187], [188, 194], [195, 205], [206, 213], [214, 220], [221, 224], [225, 233], [234, 241], [241, 242], [243, 247], [248, 254], [255, 258], [259, 263], [264, 274], [275, 278], [279, 282], [283, 294], [295, 299], [300, 304], [305, 309], [310, 311], [311, 320], [321, 331], [332, 342], [342, 343], [344, 350], [350, 351]]}
{"doc_key": "ai-test-277", "ner": [[6, 10, "organisation"], [15, 21, "organisation"], [12, 13, "university"], [23, 24, "university"], [27, 28, "field"], [31, 35, "organisation"], [38, 42, "organisation"], [49, 52, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[15, 21, 12, 13, "part-of", "", false, false], [23, 24, 27, 28, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "is", "a", "fellow", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", ",", "Stanford", "University", "'s", "Centre", "for", "Advanced", "Study", "in", "Behavioural", "Sciences", ",", "MIT", "'s", "Centre", "for", "Cognitive", "Science", ",", "the", "Canadian", "Institute", "for", "Advanced", "Research", "and", "the", "Canadian", "Psychological", "Association", ",", "and", "was", "elected", "a", "Fellow", "of", "the", "Royal", "Society", "of", "Canada", "in", "1998", "."], "sentence-detokenized": "He is a fellow of the American Association for Artificial Intelligence, Stanford University's Centre for Advanced Study in Behavioural Sciences, MIT's Centre for Cognitive Science, the Canadian Institute for Advanced Research and the Canadian Psychological Association, and was elected a Fellow of the Royal Society of Canada in 1998.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 42], [43, 46], [47, 57], [58, 70], [70, 71], [72, 80], [81, 91], [91, 93], [94, 100], [101, 104], [105, 113], [114, 119], [120, 122], [123, 134], [135, 143], [143, 144], [145, 148], [148, 150], [151, 157], [158, 161], [162, 171], [172, 179], [179, 180], [181, 184], [185, 193], [194, 203], [204, 207], [208, 216], [217, 225], [226, 229], [230, 233], [234, 242], [243, 256], [257, 268], [268, 269], [270, 273], [274, 277], [278, 285], [286, 287], [288, 294], [295, 297], [298, 301], [302, 307], [308, 315], [316, 318], [319, 325], [326, 328], [329, 333], [333, 334]]}
{"doc_key": "ai-test-278", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"], [15, 17, "misc"], [19, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 15, 17, "part-of", "", false, false], [0, 0, 19, 22, "part-of", "", false, false], [4, 5, 15, 17, "part-of", "", false, false], [4, 5, 19, 22, "part-of", "", false, false], [7, 7, 15, 17, "part-of", "", false, false], [7, 7, 19, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", "-", "along", "with", "Yoshua", "Bengio", "and", "Yann", "LeCun", "-", "are", "called", "by", "some", "the", "Fathers", "of", "AI", "and", "Godfathers", "of", "Deep", "Learning", "."], "sentence-detokenized": "Hinton - along with Yoshua Bengio and Yann LeCun - are called by some the Fathers of AI and Godfathers of Deep Learning.", "token2charspan": [[0, 6], [7, 8], [9, 14], [15, 19], [20, 26], [27, 33], [34, 37], [38, 42], [43, 48], [49, 50], [51, 54], [55, 61], [62, 64], [65, 69], [70, 73], [74, 81], [82, 84], [85, 87], [88, 91], [92, 102], [103, 105], [106, 110], [111, 119], [119, 120]]}
{"doc_key": "ai-test-279", "ner": [[6, 6, "product"], [18, 18, "misc"], [20, 21, "misc"], [22, 22, "product"], [26, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 18, 18, "related-to", "", false, false], [6, 6, 20, 21, "related-to", "", false, false], [18, 18, 22, 22, "named", "same", false, false], [26, 27, 22, 22, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "open", "source", "lightweight", "speech", "project", "eSpeak", ",", "which", "has", "its", "own", "synthesis", "approach", ",", "has", "experimented", "with", "Mandarin", "and", "Cantonese", ".", "eSpeak", "was", "used", "by", "Google", "Translate", "from", "May", "2010", "to", "2010", "."], "sentence-detokenized": "The open source lightweight speech project eSpeak, which has its own synthesis approach, has experimented with Mandarin and Cantonese. eSpeak was used by Google Translate from May 2010 to 2010.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 27], [28, 34], [35, 42], [43, 49], [49, 50], [51, 56], [57, 60], [61, 64], [65, 68], [69, 78], [79, 87], [87, 88], [89, 92], [93, 105], [106, 110], [111, 119], [120, 123], [124, 133], [133, 134], [135, 141], [142, 145], [146, 150], [151, 153], [154, 160], [161, 170], [171, 175], [176, 179], [180, 184], [185, 187], [188, 192], [192, 193]]}
{"doc_key": "ai-test-280", "ner": [[5, 7, "product"], [15, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 15, 16, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Also", "released", "in", "1982", ",", "Software", "Automatic", "Mouth", "was", "the", "first", "fully", "automated", "commercial", "speech", "synthesis", "program", "."], "sentence-detokenized": "Also released in 1982, Software Automatic Mouth was the first fully automated commercial speech synthesis program.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 21], [21, 22], [23, 31], [32, 41], [42, 47], [48, 51], [52, 55], [56, 61], [62, 67], [68, 77], [78, 88], [89, 95], [96, 105], [106, 113], [113, 114]]}
{"doc_key": "ai-test-281", "ner": [[4, 6, "metrics"], [8, 8, "metrics"], [11, 11, "metrics"], [13, 13, "metrics"], [16, 25, "metrics"], [27, 28, "metrics"], [31, 31, "metrics"], [34, 40, "metrics"], [44, 46, "metrics"], [48, 48, "metrics"], [51, 51, "metrics"], [53, 53, "metrics"], [56, 62, "metrics"], [67, 69, "metrics"], [71, 71, "metrics"], [74, 80, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[8, 8, 4, 6, "named", "", false, false], [11, 11, 4, 6, "named", "", false, false], [13, 13, 4, 6, "named", "", false, false], [16, 25, 4, 6, "named", "", false, false], [31, 31, 27, 28, "named", "", false, false], [34, 40, 27, 28, "named", "", false, false], [48, 48, 44, 46, "named", "", false, false], [51, 51, 44, 46, "named", "", false, false], [53, 53, 44, 46, "named", "", false, false], [56, 62, 44, 46, "named", "", false, false], [71, 71, 67, 69, "named", "", false, false], [74, 80, 67, 69, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["The", "column", "ratios", "are", "True", "Positive", "Rate", "(", "TPR", ",", "aka", "Sensitivity", "or", "recall", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "with", "complement", "False", "Negative", "Rate", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ";", "and", "True", "Negative", "Rate", "(", "TNR", ",", "aka", "Specificity", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", ",", "with", "complement", "False", "Positive", "Rate", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "The column ratios are True Positive Rate (TPR, aka Sensitivity or recall) (TP / (TP + FN)), with complement False Negative Rate (FNR) (FN / (TP + FN)); and True Negative Rate (TNR, aka Specificity, SPC) (TN / (TN + FP)), with complement False Positive Rate (FPR) (FP / (TN + FP)).", "token2charspan": [[0, 3], [4, 10], [11, 17], [18, 21], [22, 26], [27, 35], [36, 40], [41, 42], [42, 45], [45, 46], [47, 50], [51, 62], [63, 65], [66, 72], [72, 73], [74, 75], [75, 77], [78, 79], [80, 81], [81, 83], [84, 85], [86, 88], [88, 89], [89, 90], [90, 91], [92, 96], [97, 107], [108, 113], [114, 122], [123, 127], [128, 129], [129, 132], [132, 133], [134, 135], [135, 137], [138, 139], [140, 141], [141, 143], [144, 145], [146, 148], [148, 149], [149, 150], [150, 151], [152, 155], [156, 160], [161, 169], [170, 174], [175, 176], [176, 179], [179, 180], [181, 184], [185, 196], [196, 197], [198, 201], [201, 202], [203, 204], [204, 206], [207, 208], [209, 210], [210, 212], [213, 214], [215, 217], [217, 218], [218, 219], [219, 220], [221, 225], [226, 236], [237, 242], [243, 251], [252, 256], [257, 258], [258, 261], [261, 262], [263, 264], [264, 266], [267, 268], [269, 270], [270, 272], [273, 274], [275, 277], [277, 278], [278, 279], [279, 280]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 2, "person"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 17, 17, "role", "working_with", false, false], [2, 2, 17, 17, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "and", "Weber", "also", "collaborated", "on", "many", "other", "robots", ",", "and", "their", "experience", "of", "working", "with", "the", "Kismet"], "sentence-detokenized": "Edsinger and Weber also collaborated on many other robots, and their experience of working with the Kismet", "token2charspan": [[0, 8], [9, 12], [13, 18], [19, 23], [24, 36], [37, 39], [40, 44], [45, 50], [51, 57], [57, 58], [59, 62], [63, 68], [69, 79], [80, 82], [83, 90], [91, 95], [96, 99], [100, 106]]}
{"doc_key": "ai-test-283", "ner": [[0, 0, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 11, 11, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["R", "functionality", "is", "accessible", "from", "various", "scripting", "languages", ",", "such", "as", "Python", ",", "are", "also", "available", "."], "sentence-detokenized": "R functionality is accessible from various scripting languages, such as Python, are also available.", "token2charspan": [[0, 1], [2, 15], [16, 18], [19, 29], [30, 34], [35, 42], [43, 52], [53, 62], [62, 63], [64, 68], [69, 71], [72, 78], [78, 79], [80, 83], [84, 88], [89, 98], [98, 99]]}
{"doc_key": "ai-test-284", "ner": [[0, 0, "programlang"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "was", "one", "of", "the", "first", "robotic", "languages", "and", "was", "used", "in", "Unimate", "robots", "."], "sentence-detokenized": "VAL was one of the first robotic languages and was used in Unimate robots.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 18], [19, 24], [25, 32], [33, 42], [43, 46], [47, 50], [51, 55], [56, 58], [59, 66], [67, 73], [73, 74]]}
{"doc_key": "ai-test-285", "ner": [[13, 22, "conference"], [20, 20, "conference"], [23, 24, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 22, 23, 24, "physical", "", false, false], [20, 20, 13, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["They", "presented", "their", "database", "for", "the", "first", "time", "in", "poster", "form", "at", "the", "2009", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "Conference", "in", "Florida", "."], "sentence-detokenized": "They presented their database for the first time in poster form at the 2009 Computer Vision and Pattern Recognition (CVPR) Conference in Florida.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 29], [30, 33], [34, 37], [38, 43], [44, 48], [49, 51], [52, 58], [59, 63], [64, 66], [67, 70], [71, 75], [76, 84], [85, 91], [92, 95], [96, 103], [104, 115], [116, 117], [117, 121], [121, 122], [123, 133], [134, 136], [137, 144], [144, 145]]}
{"doc_key": "ai-test-286", "ner": [[0, 2, "misc"], [9, 10, "task"], [12, 13, "field"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 0, 2, "type-of", "", false, false], [12, 13, 0, 2, "type-of", "", false, false], [15, 16, 0, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Categorisation", "tasks", "where", "no", "labels", "are", "provided", "are", "called", "unsupervised", "classification", ",", "unsupervised", "learning", ",", "cluster", "analysis", "."], "sentence-detokenized": "Categorisation tasks where no labels are provided are called unsupervised classification, unsupervised learning, cluster analysis.", "token2charspan": [[0, 14], [15, 20], [21, 26], [27, 29], [30, 36], [37, 40], [41, 49], [50, 53], [54, 60], [61, 73], [74, 88], [88, 89], [90, 102], [103, 111], [111, 112], [113, 120], [121, 129], [129, 130]]}
{"doc_key": "ai-test-287", "ner": [[2, 3, "task"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "needs", "object", "recognition", ",", "to", "recognise", "and", "locate", "humans", "and", "to", "continue", "to", "recognise", "emotions", "."], "sentence-detokenized": "It needs object recognition, to recognise and locate humans and to continue to recognise emotions.", "token2charspan": [[0, 2], [3, 8], [9, 15], [16, 27], [27, 28], [29, 31], [32, 41], [42, 45], [46, 52], [53, 59], [60, 63], [64, 66], [67, 75], [76, 78], [79, 88], [89, 97], [97, 98]]}
{"doc_key": "ai-test-288", "ner": [[6, 7, "misc"], [9, 9, "misc"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "process", "is", "complex", "and", "involves", "both", "encoding", "and", "recall", "."], "sentence-detokenized": "The process is complex and involves both encoding and recall.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 26], [27, 35], [36, 40], [41, 49], [50, 53], [54, 60], [60, 61]]}
{"doc_key": "ai-test-289", "ner": [[8, 9, "product"], [13, 14, "product"], [32, 32, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 13, 14, "named", "", false, false], [8, 9, 32, 32, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Also", "known", "as", "parallel", "robots", ",", "or", "generalised", "Stewart", "platforms", "(", "in", "the", "Stewart", "platform", ",", "the", "actuators", "are", "paired", "on", "both", "the", "base", "and", "the", "platform", ")", ",", "these", "systems", "are", "articulated", "robots", "that", "use", "similar", "mechanisms", "for", "the", "movement", "of", "the", "robot", "at", "its", "base", ",", "or", "of", "one", "or", "more", "manipulator", "arms", "."], "sentence-detokenized": "Also known as parallel robots, or generalised Stewart platforms (in the Stewart platform, the actuators are paired on both the base and the platform), these systems are articulated robots that use similar mechanisms for the movement of the robot at its base, or of one or more manipulator arms.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 29], [29, 30], [31, 33], [34, 45], [46, 53], [54, 63], [64, 65], [65, 67], [68, 71], [72, 79], [80, 88], [88, 89], [90, 93], [94, 103], [104, 107], [108, 114], [115, 117], [118, 122], [123, 126], [127, 131], [132, 135], [136, 139], [140, 148], [148, 149], [149, 150], [151, 156], [157, 164], [165, 168], [169, 180], [181, 187], [188, 192], [193, 196], [197, 204], [205, 215], [216, 219], [220, 223], [224, 232], [233, 235], [236, 239], [240, 245], [246, 248], [249, 252], [253, 257], [257, 258], [259, 261], [262, 264], [265, 268], [269, 271], [272, 276], [277, 288], [289, 293], [293, 294]]}
{"doc_key": "ai-test-290", "ner": [[0, 1, "field"], [7, 8, "field"], [15, 16, "field"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 7, 8, "part-of", "subfield", false, false], [0, 1, 15, 16, "compare", "", false, false], [15, 16, 21, 22, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "vision", ",", "as", "a", "discipline", "of", "systems", "engineering", ",", "can", "be", "considered", "distinct", "from", "computer", "vision", ",", "a", "form", "of", "computer", "science", "."], "sentence-detokenized": "Machine vision, as a discipline of systems engineering, can be considered distinct from computer vision, a form of computer science.", "token2charspan": [[0, 7], [8, 14], [14, 15], [16, 18], [19, 20], [21, 31], [32, 34], [35, 42], [43, 54], [54, 55], [56, 59], [60, 62], [63, 73], [74, 82], [83, 87], [88, 96], [97, 103], [103, 104], [105, 106], [107, 111], [112, 114], [115, 123], [124, 131], [131, 132]]}
{"doc_key": "ai-test-291", "ner": [[4, 5, "algorithm"], [9, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 9, 11, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "activation", "function", "of", "LSTM", "gates", "is", "usually", "the", "logistic", "sigmoid", "function", "."], "sentence-detokenized": "The activation function of LSTM gates is usually the logistic sigmoid function.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 26], [27, 31], [32, 37], [38, 40], [41, 48], [49, 52], [53, 61], [62, 69], [70, 78], [78, 79]]}
{"doc_key": "ai-test-292", "ner": [[5, 6, "metrics"], [19, 22, "metrics"], [24, 24, "metrics"], [32, 34, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 19, 22, "named", "", false, false], [5, 6, 32, 34, "named", "", false, false], [24, 24, 19, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "other", "words", ",", "the", "sample", "mean", "is", "the", "efficient", "(", "necessarily", "unique", ")", "estimator", "and", "therefore", "also", "the", "minimum", "variance", "unbiased", "estimator", "(", "MVUE", ")", ",", "as", "well", "as", "being", "the", "maximum", "likelihood", "estimator", "."], "sentence-detokenized": "In other words, the sample mean is the efficient (necessarily unique) estimator and therefore also the minimum variance unbiased estimator (MVUE), as well as being the maximum likelihood estimator.", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 19], [20, 26], [27, 31], [32, 34], [35, 38], [39, 48], [49, 50], [50, 61], [62, 68], [68, 69], [70, 79], [80, 83], [84, 93], [94, 98], [99, 102], [103, 110], [111, 119], [120, 128], [129, 138], [139, 140], [140, 144], [144, 145], [145, 146], [147, 149], [150, 154], [155, 157], [158, 163], [164, 167], [168, 175], [176, 186], [187, 196], [196, 197]]}
{"doc_key": "ai-test-293", "ner": [[2, 3, "academicjournal"], [8, 10, "researcher"], [12, 13, "researcher"], [15, 16, "researcher"], [23, 26, "product"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 23, 26, "topic", "", false, false], [2, 3, 28, 29, "topic", "", false, false], [8, 10, 2, 3, "role", "", false, false], [12, 13, 2, 3, "role", "", false, false], [15, 16, 2, 3, "role", "", false, false], [23, 26, 28, 29, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "2001", "Scientific", "American", "article", ",", "written", "by", "Berners", "-", "Lee", ",", "James", "Hendler", "and", "Ora", "Lassila", ",", "described", "the", "expected", "evolution", "of", "today", "'s", "Web", "towards", "a", "Semantic", "Web", "."], "sentence-detokenized": "The 2001 Scientific American article, written by Berners-Lee, James Hendler and Ora Lassila, described the expected evolution of today's Web towards a Semantic Web.", "token2charspan": [[0, 3], [4, 8], [9, 19], [20, 28], [29, 36], [36, 37], [38, 45], [46, 48], [49, 56], [56, 57], [57, 60], [60, 61], [62, 67], [68, 75], [76, 79], [80, 83], [84, 91], [91, 92], [93, 102], [103, 106], [107, 115], [116, 125], [126, 128], [129, 134], [134, 136], [137, 140], [141, 148], [149, 150], [151, 159], [160, 163], [163, 164]]}
{"doc_key": "ai-test-294", "ner": [[0, 1, "misc"], [10, 11, "person"], [13, 13, "person"], [25, 25, "person"], [36, 36, "person"], [42, 43, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 11, 0, 1, "role", "actor_in_work", false, false], [13, 13, 10, 11, "named", "", false, false], [13, 13, 10, 11, "origin", "", false, false], [25, 25, 13, 13, "part-of", "", false, false], [42, 43, 13, 13, "role", "auditioned_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Blade", "Runner", "used", "several", "then", "lesser", "-", "known", "actors", ":", "Sean", "Young", "plays", "Rachael", ",", "an", "experimental", "replicant", "who", "is", "implanted", "with", "the", "memories", "of", "Tyrell", "'s", "niece", ",", "making", "her", "believe", "she", "is", "human", ";", "Sammon", ",", "pp.", "92", "-", "93", "Nina", "Axelrod", "auditioned", "for", "the", "role", "."], "sentence-detokenized": "Blade Runner used several then lesser-known actors: Sean Young plays Rachael, an experimental replicant who is implanted with the memories of Tyrell's niece, making her believe she is human; Sammon, pp. 92-93 Nina Axelrod auditioned for the role.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 25], [26, 30], [31, 37], [37, 38], [38, 43], [44, 50], [50, 51], [52, 56], [57, 62], [63, 68], [69, 76], [76, 77], [78, 80], [81, 93], [94, 103], [104, 107], [108, 110], [111, 120], [121, 125], [126, 129], [130, 138], [139, 141], [142, 148], [148, 150], [151, 156], [156, 157], [158, 164], [165, 168], [169, 176], [177, 180], [181, 183], [184, 189], [189, 190], [191, 197], [197, 198], [199, 202], [203, 205], [205, 206], [206, 208], [209, 213], [214, 221], [222, 232], [233, 236], [237, 240], [241, 245], [245, 246]]}
{"doc_key": "ai-test-295", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [12, 13, "university"], [20, 22, "product"], [24, 24, "product"], [42, 42, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 12, 13, "physical", "", false, false], [3, 4, 12, 13, "physical", "", false, false], [6, 7, 12, 13, "physical", "", false, false], [9, 10, 12, 13, "physical", "", false, false], [12, 13, 42, 42, "physical", "", true, false], [20, 22, 12, 13, "temporal", "", false, false], [24, 24, 12, 13, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Gerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "and", "Terry", "Winograd", "visited", "Edinburgh", "University", "in", "1971", "spreading", "the", "news", "about", "Micro", "-", "Planner", "and", "SHRDLU", "and", "questioning", "the", "uniform", "proof", "-", "of", "-", "solution", "approach", "that", "had", "been", "the", "mainstay", "of", "the", "Edinburgh", "logicians", "."], "sentence-detokenized": "Gerry Sussman, Eugene Charniak, Seymour Papert and Terry Winograd visited Edinburgh University in 1971 spreading the news about Micro-Planner and SHRDLU and questioning the uniform proof-of-solution approach that had been the mainstay of the Edinburgh logicians.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 21], [22, 30], [30, 31], [32, 39], [40, 46], [47, 50], [51, 56], [57, 65], [66, 73], [74, 83], [84, 94], [95, 97], [98, 102], [103, 112], [113, 116], [117, 121], [122, 127], [128, 133], [133, 134], [134, 141], [142, 145], [146, 152], [153, 156], [157, 168], [169, 172], [173, 180], [181, 186], [186, 187], [187, 189], [189, 190], [190, 198], [199, 207], [208, 212], [213, 216], [217, 221], [222, 225], [226, 234], [235, 237], [238, 241], [242, 251], [252, 261], [261, 262]]}
{"doc_key": "ai-test-296", "ner": [[7, 11, "field"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Walter", "'s", "work", "inspired", "later", "generations", "of", "robotics", "researchers", ",", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "Walter's work inspired later generations of robotics researchers, such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 6], [6, 8], [9, 13], [14, 22], [23, 28], [29, 40], [41, 43], [44, 52], [53, 64], [64, 65], [66, 70], [71, 73], [74, 80], [81, 87], [87, 88], [89, 93], [94, 101], [102, 105], [106, 110], [111, 117], [117, 118]]}
{"doc_key": "ai-test-297", "ner": [[7, 7, "algorithm"], [9, 10, "researcher"], [16, 22, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 9, 10, "origin", "", false, false], [7, 7, 16, 22, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Subsequently", ",", "a", "similar", "GPU", "-", "based", "CNN", "by", "Alex", "Krizhevsky", "et", "al", ".", "won", "the", "ImageNet", "2012", "Large", "Scale", "Visual", "Recognition", "Challenge", "."], "sentence-detokenized": "Subsequently, a similar GPU-based CNN by Alex Krizhevsky et al. won the ImageNet 2012 Large Scale Visual Recognition Challenge.", "token2charspan": [[0, 12], [12, 13], [14, 15], [16, 23], [24, 27], [27, 28], [28, 33], [34, 37], [38, 40], [41, 45], [46, 56], [57, 59], [60, 62], [62, 63], [64, 67], [68, 71], [72, 80], [81, 85], [86, 91], [92, 97], [98, 104], [105, 116], [117, 126], [126, 127]]}
{"doc_key": "ai-test-298", "ner": [[2, 3, "misc"], [9, 10, "metrics"], [13, 14, "metrics"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 2, 3, "type-of", "", false, false], [13, 14, 2, 3, "type-of", "", false, false], [13, 14, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Commonly", "used", "loss", "functions", "for", "probabilistic", "classification", "include", "the", "logarithmic", "loss", "and", "the", "Brier", "score", "between", "predicted", "and", "true", "probability", "distributions", "."], "sentence-detokenized": "Commonly used loss functions for probabilistic classification include the logarithmic loss and the Brier score between predicted and true probability distributions.", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 28], [29, 32], [33, 46], [47, 61], [62, 69], [70, 73], [74, 85], [86, 90], [91, 94], [95, 98], [99, 104], [105, 110], [111, 118], [119, 128], [129, 132], [133, 137], [138, 149], [150, 163], [163, 164]]}
{"doc_key": "ai-test-299", "ner": [[4, 4, "organisation"], [11, 11, "field"], [10, 10, "organisation"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 11, 11, "general-affiliation", "field_of_study", false, false], [4, 4, 17, 18, "part-of", "", false, false], [10, 10, 4, 4, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "May", "2016", ",", "NtechLab", "was", "admitted", "to", "the", "official", "NIST", "biometric", "technology", "tests", "among", "the", "three", "Russian", "companies", "."], "sentence-detokenized": "In May 2016, NtechLab was admitted to the official NIST biometric technology tests among the three Russian companies.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [13, 21], [22, 25], [26, 34], [35, 37], [38, 41], [42, 50], [51, 55], [56, 65], [66, 76], [77, 82], [83, 88], [89, 92], [93, 98], [99, 106], [107, 116], [116, 117]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "floating", "-", "point", "numbers", "only", "have", "a", "certain", "mathematical", "precision", "."], "sentence-detokenized": "However, floating-point numbers only have a certain mathematical precision.", "token2charspan": [[0, 7], [7, 8], [9, 17], [17, 18], [18, 23], [24, 31], [32, 36], [37, 41], [42, 43], [44, 51], [52, 64], [65, 74], [74, 75]]}
{"doc_key": "ai-test-301", "ner": [[5, 5, "organisation"], [12, 18, "conference"], [20, 20, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 12, 18, "role", "contributes_to", false, false], [20, 20, 12, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "2015", ",", "many", "of", "SenseTime", "'s", "papers", "were", "accepted", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "During 2015, many of SenseTime's papers were accepted at the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 6], [7, 11], [11, 12], [13, 17], [18, 20], [21, 30], [30, 32], [33, 39], [40, 44], [45, 53], [54, 56], [57, 60], [61, 71], [72, 74], [75, 83], [84, 90], [91, 94], [95, 102], [103, 114], [115, 116], [116, 120], [120, 121], [121, 122]]}
{"doc_key": "ai-test-302", "ner": [[5, 7, "task"], [9, 9, "task"], [12, 13, "task"], [15, 18, "task"], [25, 25, "misc"], [28, 33, "conference"], [41, 43, "misc"], [45, 46, "conference"], [23, 64, "misc"], [21, 66, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10], "relations": [[9, 9, 5, 7, "named", "", false, false], [15, 18, 12, 13, "named", "", false, false], [25, 25, 28, 33, "temporal", "", false, false], [41, 43, 45, 46, "temporal", "", false, false], [23, 64, 21, 66, "temporal", "", false, false]], "relations_mapping_to_source": [1, 3, 4, 5, 6], "sentence": ["Co", "-developed", "optimal", "algorithms", "for", "structure", "from", "motion", "(", "SFM", ",", "or", "Visual", "SLAM", ",", "simultaneous", "localisation", "and", "mapping", ",", "in", "Robotics", ";", "Best", "Paper", "Award", "at", "the", "Computer", "Vision", "and", "Pattern", "Recognition", "Conference", "1998", ")", ",", "characterised", "its", "ambiguities", "(", "David", "Marr", "Award", "at", "ICCV", "1999", ")", ",", "also", "characterised", "the", "identifiability", "and", "observability", "of", "visual", "-", "inertial", "sensor", "fusion", "(", "Best", "Paper", "Award", "in", "Robotics", "2015", ")", "."], "sentence-detokenized": "Co-developed optimal algorithms for structure from motion (SFM, or Visual SLAM, simultaneous localisation and mapping, in Robotics; Best Paper Award at the Computer Vision and Pattern Recognition Conference 1998), characterised its ambiguities (David Marr Award at ICCV 1999), also characterised the identifiability and observability of visual-inertial sensor fusion (Best Paper Award in Robotics 2015).", "token2charspan": [[0, 2], [2, 12], [13, 20], [21, 31], [32, 35], [36, 45], [46, 50], [51, 57], [58, 59], [59, 62], [62, 63], [64, 66], [67, 73], [74, 78], [78, 79], [80, 92], [93, 105], [106, 109], [110, 117], [117, 118], [119, 121], [122, 130], [130, 131], [132, 136], [137, 142], [143, 148], [149, 151], [152, 155], [156, 164], [165, 171], [172, 175], [176, 183], [184, 195], [196, 206], [207, 211], [211, 212], [212, 213], [214, 227], [228, 231], [232, 243], [244, 245], [245, 250], [251, 255], [256, 261], [262, 264], [265, 269], [270, 274], [274, 275], [275, 276], [277, 281], [282, 295], [296, 299], [300, 315], [316, 319], [320, 333], [334, 336], [337, 343], [343, 344], [344, 352], [353, 359], [360, 366], [367, 368], [368, 372], [373, 378], [379, 384], [385, 387], [388, 396], [397, 401], [401, 402], [402, 403]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 44], [45, 48], [49, 52], [53, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-304", "ner": [[0, 1, "task"], [7, 8, "field"], [10, 11, "field"], [13, 14, "field"], [22, 22, "task"], [21, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 7, 8, "part-of", "task_part_of_field", false, false], [0, 1, 10, 11, "part-of", "task_part_of_field", false, false], [0, 1, 13, 14, "part-of", "task_part_of_field", false, false], [0, 1, 22, 22, "part-of", "", false, false], [0, 1, 21, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Edge", "detection", "is", "a", "fundamental", "tool", "in", "image", "processing", ",", "machine", "vision", "and", "computer", "vision", ",", "especially", "in", "the", "areas", "of", "feature", "detection", "and", "feature", "extraction", "."], "sentence-detokenized": "Edge detection is a fundamental tool in image processing, machine vision and computer vision, especially in the areas of feature detection and feature extraction.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 19], [20, 31], [32, 36], [37, 39], [40, 45], [46, 56], [56, 57], [58, 65], [66, 72], [73, 76], [77, 85], [86, 92], [92, 93], [94, 104], [105, 107], [108, 111], [112, 117], [118, 120], [121, 128], [129, 138], [139, 142], [143, 150], [151, 161], [161, 162]]}
{"doc_key": "ai-test-305", "ner": [[10, 11, "misc"], [28, 31, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "example", "of", "this", "would", "be", "a", "variable", "such", "as", "outdoor", "temperature", "(", "mathtemp", "/", "math", ")", ",", "which", "in", "a", "given", "application", "could", "be", "recorded", "to", "several", "decimal", "places", "of", "accuracy", "(", "depending", "on", "the", "sensing", "device", ")", "."], "sentence-detokenized": "An example of this would be a variable such as outdoor temperature (mathtemp / math), which in a given application could be recorded to several decimal places of accuracy (depending on the sensing device).", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 18], [19, 24], [25, 27], [28, 29], [30, 38], [39, 43], [44, 46], [47, 54], [55, 66], [67, 68], [68, 76], [77, 78], [79, 83], [83, 84], [84, 85], [86, 91], [92, 94], [95, 96], [97, 102], [103, 114], [115, 120], [121, 123], [124, 132], [133, 135], [136, 143], [144, 151], [152, 158], [159, 161], [162, 170], [171, 172], [172, 181], [182, 184], [185, 188], [189, 196], [197, 203], [203, 204], [204, 205]]}
{"doc_key": "ai-test-306", "ner": [[3, 4, "person"], [6, 7, "person"], [9, 10, "person"], [20, 21, "person"], [23, 23, "misc"], [27, 27, "misc"], [29, 30, "person"], [32, 32, "organisation"], [34, 35, "person"], [37, 37, "organisation"], [39, 44, "person"], [45, 45, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[29, 30, 23, 23, "part-of", "", false, false], [29, 30, 27, 27, "role", "", false, false], [34, 35, 32, 32, "role", "", false, false], [39, 44, 37, 37, "role", "youtuber", false, false], [45, 45, 39, 44, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Returning", "judges", "are", "Fon", "Davis", ",", "Jessica", "Chobot", "and", "Leland", "Melvin", ",", "as", "well", "as", "celebrity", "guest", "judges", ",", "actor", "Clark", "Gregg", ",", "MythBusters", "host", "and", "former", "Battlebots", "builder", "Adam", "Savage", ",", "NFL", "player", "Vernon", "Davis", "and", "YouTube", "star", "Michael", "Stevens", ",", "also", "known", "as", "Vsauce", "."], "sentence-detokenized": "Returning judges are Fon Davis, Jessica Chobot and Leland Melvin, as well as celebrity guest judges, actor Clark Gregg, MythBusters host and former Battlebots builder Adam Savage, NFL player Vernon Davis and YouTube star Michael Stevens, also known as Vsauce.", "token2charspan": [[0, 9], [10, 16], [17, 20], [21, 24], [25, 30], [30, 31], [32, 39], [40, 46], [47, 50], [51, 57], [58, 64], [64, 65], [66, 68], [69, 73], [74, 76], [77, 86], [87, 92], [93, 99], [99, 100], [101, 106], [107, 112], [113, 118], [118, 119], [120, 131], [132, 136], [137, 140], [141, 147], [148, 158], [159, 166], [167, 171], [172, 178], [178, 179], [180, 183], [184, 190], [191, 197], [198, 203], [204, 207], [208, 215], [216, 220], [221, 228], [229, 236], [236, 237], [238, 242], [243, 248], [249, 251], [252, 258], [258, 259]]}
{"doc_key": "ai-test-307", "ner": [[11, 12, "algorithm"], [13, 17, "algorithm"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 19, 21, "part-of", "", false, false], [13, 17, 19, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["But", "these", "methods", "never", "prevailed", "over", "the", "non-uniform", ",", "internally", "elaborated", "Gaussian", "mixture", "model", "/", "hidden", "Markov", "model", "(", "GMM", "-", "HMM", ")", "technology", ",", "based", "on", "discriminatively", "trained", "generative", "speech", "models", "."], "sentence-detokenized": "But these methods never prevailed over the non-uniform, internally elaborated Gaussian mixture model/hidden Markov model (GMM-HMM) technology, based on discriminatively trained generative speech models.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 23], [24, 33], [34, 38], [39, 42], [43, 54], [54, 55], [56, 66], [67, 77], [78, 86], [87, 94], [95, 100], [100, 101], [101, 107], [108, 114], [115, 120], [121, 122], [122, 125], [125, 126], [126, 129], [129, 130], [131, 141], [141, 142], [143, 148], [149, 151], [152, 168], [169, 176], [177, 187], [188, 194], [195, 201], [201, 202]]}
{"doc_key": "ai-test-308", "ner": [[4, 4, "product"], [6, 7, "programlang"], [9, 9, "programlang"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Software", "packages", "such", "as", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", "and", "SciPy", "provide", "convenient", "ways", "to", "apply", "these", "different", "methods", "."], "sentence-detokenized": "Software packages such as MATLAB, GNU Octave, Scilab and SciPy provide convenient ways to apply these different methods.", "token2charspan": [[0, 8], [9, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 37], [38, 44], [44, 45], [46, 52], [53, 56], [57, 62], [63, 70], [71, 81], [82, 86], [87, 89], [90, 95], [96, 101], [102, 111], [112, 119], [119, 120]]}
{"doc_key": "ai-test-309", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [8, 9, "task"], [16, 17, "researcher"], [19, 20, "university"], [22, 23, "researcher"], [25, 28, "organisation"], [30, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 8, 9, "related-to", "", false, false], [0, 2, 16, 17, "origin", "", false, false], [0, 2, 22, 23, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [16, 17, 19, 20, "physical", "", false, false], [16, 17, 19, 20, "role", "", false, false], [22, 23, 25, 28, "physical", "", false, false], [22, 23, 25, 28, "role", "", false, false], [30, 30, 25, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", ",", "a", "speech", "processing", "algorithm", ",", "was", "first", "proposed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", "."], "sentence-detokenized": "Linear predictive coding (LPC), a speech processing algorithm, was first proposed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [30, 31], [32, 33], [34, 40], [41, 51], [52, 61], [61, 62], [63, 66], [67, 72], [73, 81], [82, 84], [85, 93], [94, 101], [102, 104], [105, 111], [112, 122], [123, 126], [127, 132], [133, 138], [139, 141], [142, 148], [149, 158], [159, 162], [163, 172], [173, 174], [174, 177], [177, 178], [179, 181], [182, 186], [186, 187]]}
{"doc_key": "ai-test-310", "ner": [[20, 27, "conference"], [29, 29, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[29, 29, 20, 27, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2006", ",", "on", "the", "occasion", "of", "the", "25th", "anniversary", "of", "the", "algorithm", ",", "a", "workshop", "was", "organised", "at", "the", "International", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "to", "summarise", "the", "most", "recent", "contributions", "and", "variations", "to", "the", "original", "algorithm", ",", "mostly", "aimed", "at", "improving", "the", "speed", "of", "the", "algorithm", ",", "the", "robustness", "and", "accuracy", "of", "the", "estimated", "solution", "and", "decreasing", "the", "dependence", "on", "user", "-", "defined", "constants", "."], "sentence-detokenized": "In 2006, on the occasion of the 25th anniversary of the algorithm, a workshop was organised at the International Conference on Computer Vision and Pattern Recognition (CVPR) to summarise the most recent contributions and variations to the original algorithm, mostly aimed at improving the speed of the algorithm, the robustness and accuracy of the estimated solution and decreasing the dependence on user-defined constants.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 24], [25, 27], [28, 31], [32, 36], [37, 48], [49, 51], [52, 55], [56, 65], [65, 66], [67, 68], [69, 77], [78, 81], [82, 91], [92, 94], [95, 98], [99, 112], [113, 123], [124, 126], [127, 135], [136, 142], [143, 146], [147, 154], [155, 166], [167, 168], [168, 172], [172, 173], [174, 176], [177, 186], [187, 190], [191, 195], [196, 202], [203, 216], [217, 220], [221, 231], [232, 234], [235, 238], [239, 247], [248, 257], [257, 258], [259, 265], [266, 271], [272, 274], [275, 284], [285, 288], [289, 294], [295, 297], [298, 301], [302, 311], [311, 312], [313, 316], [317, 327], [328, 331], [332, 340], [341, 343], [344, 347], [348, 357], [358, 366], [367, 370], [371, 381], [382, 385], [386, 396], [397, 399], [400, 404], [404, 405], [405, 412], [413, 422], [422, 423]]}
{"doc_key": "ai-test-311", "ner": [[3, 5, "university"], [8, 11, "organisation"], [13, 15, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Members", "attended", "the", "University", "of", "Debrecen", ",", "the", "Hungarian", "Academy", "of", "Sciences", ",", "E\u00f6tv\u00f6s", "Lor\u00e1nd", "University", ",", "etc", "."], "sentence-detokenized": "Members attended the University of Debrecen, the Hungarian Academy of Sciences, E\u00f6tv\u00f6s Lor\u00e1nd University, etc.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 31], [32, 34], [35, 43], [43, 44], [45, 48], [49, 58], [59, 66], [67, 69], [70, 78], [78, 79], [80, 86], [87, 93], [94, 104], [104, 105], [106, 109], [109, 110]]}
{"doc_key": "ai-test-312", "ner": [[2, 2, "algorithm"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 15, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "extend", "SVM", "to", "cases", "where", "data", "are", "not", "linearly", "separable", ",", "we", "introduce", "the", "loss", "function", ","], "sentence-detokenized": "To extend SVM to cases where data are not linearly separable, we introduce the loss function,", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 16], [17, 22], [23, 28], [29, 33], [34, 37], [38, 41], [42, 50], [51, 60], [60, 61], [62, 64], [65, 74], [75, 78], [79, 83], [84, 92], [92, 93]]}
{"doc_key": "ai-test-313", "ner": [[0, 2, "programlang"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 11, 12, "origin", "", false, false], [0, 2, 14, 15, "origin", "", false, false], [0, 2, 17, 18, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Logo", "is", "an", "educational", "programming", "language", ",", "designed", "in", "1967", "by", "Wally", "Feurzeig", ",", "Seymour", "Papert", "and", "Cynthia", "Solomon", "."], "sentence-detokenized": "Logo is an educational programming language, designed in 1967 by Wally Feurzeig, Seymour Papert and Cynthia Solomon.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 34], [35, 43], [43, 44], [45, 53], [54, 56], [57, 61], [62, 64], [65, 70], [71, 79], [79, 80], [81, 88], [89, 95], [96, 99], [100, 107], [108, 115], [115, 116]]}
{"doc_key": "ai-test-314", "ner": [[0, 3, "organisation"], [8, 43, "organisation"], [46, 50, "location"], [51, 51, "location"], [53, 60, "location"], [71, 74, "product"], [80, 87, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 8, 43, "role", "works_for", false, false], [8, 43, 46, 50, "physical", "", false, false], [46, 50, 51, 51, "physical", "", false, false], [51, 51, 53, 60, "physical", "", false, false], [71, 74, 0, 3, "origin", "", false, false], [80, 87, 71, 74, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "Eyring", "Research", "Institute", "was", "instrumental", "at", "the", "US", "Air", "Force", "Missile", "Directorate", "at", "Hill", "Air", "Force", "Base", "near", "Ogden", ",", "Utah", ",", "in", "producing", ",", "in", "the", "utmost", "military", "secrecy", ",", "the", "intelligent", "systems", "technology", "software", "that", "was", "critical", "to", "the", "GW", "programme", ".", "At", "Hill", "Air", "Force", "Base", "near", "Ogden", ",", "Utah", ",", "the", "Eyring", "Research", "Institute", "was", "instrumental", "in", "producing", ",", "in", "the", "utmost", "military", "secrecy", ",", "the", "intelligent", "systems", "technology", "software", "that", "was", "central", "to", "the", "Star", "Wars", "programme", ",", "later", "named", "by", "Reagan", "."], "sentence-detokenized": "The Eyring Research Institute was instrumental at the US Air Force Missile Directorate at Hill Air Force Base near Ogden, Utah, in producing, in the utmost military secrecy, the intelligent systems technology software that was critical to the GW programme. At Hill Air Force Base near Ogden, Utah, the Eyring Research Institute was instrumental in producing, in the utmost military secrecy, the intelligent systems technology software that was central to the Star Wars programme, later named by Reagan.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 29], [30, 33], [34, 46], [47, 49], [50, 53], [54, 56], [57, 60], [61, 66], [67, 74], [75, 86], [87, 89], [90, 94], [95, 98], [99, 104], [105, 109], [110, 114], [115, 120], [120, 121], [122, 126], [126, 127], [128, 130], [131, 140], [140, 141], [142, 144], [145, 148], [149, 155], [156, 164], [165, 172], [172, 173], [174, 177], [178, 189], [190, 197], [198, 208], [209, 217], [218, 222], [223, 226], [227, 235], [236, 238], [239, 242], [243, 245], [246, 255], [255, 256], [257, 259], [260, 264], [265, 268], [269, 274], [275, 279], [280, 284], [285, 290], [290, 291], [292, 296], [296, 297], [298, 301], [302, 308], [309, 317], [318, 327], [328, 331], [332, 344], [345, 347], [348, 357], [357, 358], [359, 361], [362, 365], [366, 372], [373, 381], [382, 389], [389, 390], [391, 394], [395, 406], [407, 414], [415, 425], [426, 434], [435, 439], [440, 443], [444, 451], [452, 454], [455, 458], [459, 463], [464, 468], [469, 478], [478, 479], [480, 485], [486, 491], [492, 494], [495, 501], [501, 502]]}
{"doc_key": "ai-test-315", "ner": [[11, 12, "field"], [22, 25, "researcher"], [27, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Over", "the", "decades", "he", "has", "researched", "and", "developed", "emerging", "fields", "of", "computer", "science", ",", "from", "compiler", ",", "programming", "languages", "and", "system", "architecture", "John", "F", ".", "Sowa", "and", "John", "Zachman", "(", "1992", ")", "."], "sentence-detokenized": "Over the decades he has researched and developed emerging fields of computer science, from compiler, programming languages and system architecture John F. Sowa and John Zachman (1992).", "token2charspan": [[0, 4], [5, 8], [9, 16], [17, 19], [20, 23], [24, 34], [35, 38], [39, 48], [49, 57], [58, 64], [65, 67], [68, 76], [77, 84], [84, 85], [86, 90], [91, 99], [99, 100], [101, 112], [113, 122], [123, 126], [127, 133], [134, 146], [147, 151], [152, 153], [153, 154], [155, 159], [160, 163], [164, 168], [169, 176], [177, 178], [178, 182], [182, 183], [183, 184]]}
{"doc_key": "ai-test-316", "ner": [[1, 1, "algorithm"], [7, 10, "algorithm"], [12, 13, "algorithm"], [18, 19, "field"], [21, 22, "field"], [26, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 10, 1, 1, "named", "", false, false], [12, 13, 1, 1, "named", "", false, false], [18, 19, 1, 1, "usage", "", false, false], [21, 22, 1, 1, "usage", "", false, false], [26, 28, 1, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Sobel", "operator", ",", "sometimes", "called", "the", "Sobel", "-", "Feldman", "operator", "or", "Sobel", "filter", ",", "is", "used", "in", "image", "processing", "and", "computer", "vision", ",", "especially", "in", "edge", "detection", "algorithms", ",", "where", "it", "creates", "an", "image", "that", "emphasises", "edges", "."], "sentence-detokenized": "The Sobel operator, sometimes called the Sobel-Feldman operator or Sobel filter, is used in image processing and computer vision, especially in edge detection algorithms, where it creates an image that emphasises edges.", "token2charspan": [[0, 3], [4, 9], [10, 18], [18, 19], [20, 29], [30, 36], [37, 40], [41, 46], [46, 47], [47, 54], [55, 63], [64, 66], [67, 72], [73, 79], [79, 80], [81, 83], [84, 88], [89, 91], [92, 97], [98, 108], [109, 112], [113, 121], [122, 128], [128, 129], [130, 140], [141, 143], [144, 148], [149, 158], [159, 169], [169, 170], [171, 176], [177, 179], [180, 187], [188, 190], [191, 196], [197, 201], [202, 212], [213, 218], [218, 219]]}
{"doc_key": "ai-test-317", "ner": [[0, 0, "algorithm"], [3, 4, "field"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 3, 4, "compare", "", false, false], [0, 0, 3, 4, "type-of", "", false, false], [0, 0, 15, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["LDA", "is", "a", "supervised", "learning", "algorithm", "that", "uses", "the", "labels", "in", "the", "data", ",", "while", "PCA", "is", "a", "learning", "algorithm", "that", "ignores", "the", "labels", "."], "sentence-detokenized": "LDA is a supervised learning algorithm that uses the labels in the data, while PCA is a learning algorithm that ignores the labels.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 19], [20, 28], [29, 38], [39, 43], [44, 48], [49, 52], [53, 59], [60, 62], [63, 66], [67, 71], [71, 72], [73, 78], [79, 82], [83, 85], [86, 87], [88, 96], [97, 106], [107, 111], [112, 119], [120, 123], [124, 130], [130, 131]]}
{"doc_key": "ai-test-318", "ner": [[5, 5, "algorithm"], [7, 9, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "linear", "classification", "algorithms", "include", "Winnow", ",", "support", "vector", "machine", "and", "logistic", "regression", "."], "sentence-detokenized": "Other linear classification algorithms include Winnow, support vector machine and logistic regression.", "token2charspan": [[0, 5], [6, 12], [13, 27], [28, 38], [39, 46], [47, 53], [53, 54], [55, 62], [63, 69], [70, 77], [78, 81], [82, 90], [91, 101], [101, 102]]}
{"doc_key": "ai-test-319", "ner": [[0, 0, "product"], [6, 7, "programlang"], [15, 17, "product"], [19, 19, "programlang"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 7, "general-affiliation", "", true, false], [0, 0, 15, 17, "general-affiliation", "", true, false], [0, 0, 19, 19, "general-affiliation", "", true, false], [0, 0, 21, 21, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["VTK", "consists", "of", "a", "library", "of", "C", "++", "classes", "and", "several", "interpreted", "interface", "layers", "including", "Tcl", "/", "Tk", ",", "Java", "and", "Python", "."], "sentence-detokenized": "VTK consists of a library of C++ classes and several interpreted interface layers including Tcl/Tk, Java and Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 17], [18, 25], [26, 28], [29, 30], [30, 32], [33, 40], [41, 44], [45, 52], [53, 64], [65, 74], [75, 81], [82, 91], [92, 95], [95, 96], [96, 98], [98, 99], [100, 104], [105, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-test-320", "ner": [[10, 12, "task"], [19, 21, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", ",", "text", "produced", "by", "spontaneous", "speech", "processing", "using", "automatic", "speech", "recognition", "and", "printed", "or", "handwritten", "text", "using", "optical", "character", "recognition", "contains", "processing", "noise", "."], "sentence-detokenized": "In addition, text produced by spontaneous speech processing using automatic speech recognition and printed or handwritten text using optical character recognition contains processing noise.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 17], [18, 26], [27, 29], [30, 41], [42, 48], [49, 59], [60, 65], [66, 75], [76, 82], [83, 94], [95, 98], [99, 106], [107, 109], [110, 121], [122, 126], [127, 132], [133, 140], [141, 150], [151, 162], [163, 171], [172, 182], [183, 188], [188, 189]]}
{"doc_key": "ai-test-321", "ner": [[0, 0, "researcher"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 9, 9, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "wrote", "several", "books", "and", "led", "the", "development", "of", "WordNet", ",", "an", "online", "word", "-", "link", "database", "usable", "by", "computer", "programmes", "."], "sentence-detokenized": "Miller wrote several books and led the development of WordNet, an online word-link database usable by computer programmes.", "token2charspan": [[0, 6], [7, 12], [13, 20], [21, 26], [27, 30], [31, 34], [35, 38], [39, 50], [51, 53], [54, 61], [61, 62], [63, 65], [66, 72], [73, 77], [77, 78], [78, 82], [83, 91], [92, 98], [99, 101], [102, 110], [111, 121], [121, 122]]}
{"doc_key": "ai-test-322", "ner": [[1, 1, "field"], [8, 10, "organisation"], [13, 13, "country"], [15, 16, "person"], [18, 20, "person"], [22, 23, "person"], [25, 26, "person"], [29, 29, "country"], [31, 34, "location"], [36, 37, "misc"], [38, 39, "person"], [42, 43, "person"], [45, 45, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 10, 13, 13, "physical", "", false, false], [15, 16, 29, 29, "physical", "", false, false], [18, 20, 29, 29, "physical", "", false, false], [22, 23, 29, 29, "physical", "", false, false], [25, 26, 29, 29, "physical", "", false, false], [31, 34, 1, 1, "general-affiliation", "", false, false], [31, 34, 38, 39, "artifact", "", false, false], [36, 37, 38, 39, "named", "", false, false], [42, 43, 45, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Contemporary", "automata", "are", "represented", "by", "the", "works", "of", "Cabaret", "Mechanical", "Theatre", "in", "the", "UK", ",", "Dug", "North", "and", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", ",", "Joe", "Jones", "in", "the", "USA", ",", "Le", "D\u00e9fenseur", "du", "Temps", "by", "French", "artist", "Jacques", "Monestier", ",", "and", "Fran\u00e7ois", "Junod", "in", "Switzerland", "."], "sentence-detokenized": "Contemporary automata are represented by the works of Cabaret Mechanical Theatre in the UK, Dug North and Chomick + Meder, Arthur Ganson, Joe Jones in the USA, Le D\u00e9fenseur du Temps by French artist Jacques Monestier, and Fran\u00e7ois Junod in Switzerland.", "token2charspan": [[0, 12], [13, 21], [22, 25], [26, 37], [38, 40], [41, 44], [45, 50], [51, 53], [54, 61], [62, 72], [73, 80], [81, 83], [84, 87], [88, 90], [90, 91], [92, 95], [96, 101], [102, 105], [106, 113], [114, 115], [116, 121], [121, 122], [123, 129], [130, 136], [136, 137], [138, 141], [142, 147], [148, 150], [151, 154], [155, 158], [158, 159], [160, 162], [163, 172], [173, 175], [176, 181], [182, 184], [185, 191], [192, 198], [199, 206], [207, 216], [216, 217], [218, 221], [222, 230], [231, 236], [237, 239], [240, 251], [251, 252]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 22, 22, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "includes", "the", "standard", "codefor", "/", "code", "and", "codewhile", "/", "code", "loops", ",", "but", "(", "as", "in", "other", "similar", "applications", "such", "as", "R", ")", ",", "the", "use", "of", "vector", "notation", "is", "encouraged", "and", "is", "often", "faster", "to", "run", "."], "sentence-detokenized": "MATLAB includes the standard codefor/code and codewhile/code loops, but (as in other similar applications such as R), the use of vector notation is encouraged and is often faster to run.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 28], [29, 36], [36, 37], [37, 41], [42, 45], [46, 55], [55, 56], [56, 60], [61, 66], [66, 67], [68, 71], [72, 73], [73, 75], [76, 78], [79, 84], [85, 92], [93, 105], [106, 110], [111, 113], [114, 115], [115, 116], [116, 117], [118, 121], [122, 125], [126, 128], [129, 135], [136, 144], [145, 147], [148, 158], [159, 162], [163, 165], [166, 171], [172, 178], [179, 181], [182, 185], [185, 186]]}
{"doc_key": "ai-test-324", "ner": [[3, 3, "researcher"], [9, 12, "conference"], [17, 19, "field"], [22, 28, "misc"], [31, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 22, 28, "win-defeat", "", false, false], [3, 3, 31, 40, "win-defeat", "", false, false], [22, 28, 9, 12, "temporal", "", false, false], [22, 28, 17, 19, "topic", "", false, false], [31, 40, 9, 12, "temporal", "", false, false], [31, 40, 17, 19, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2007", ",", "Pausch", "received", "two", "awards", "from", "the", "Association", "for", "Computing", "Machinery", "for", "his", "achievements", "in", "computer", "science", "education", ":", "the", "Karl", "V", ".", "Karlstrom", "Outstanding", "Educator", "Award", "and", "the", "ACM", "SIGCSE", "Award", "for", "Outstanding", "Contribution", "to", "Computer", "Science", "Education", "."], "sentence-detokenized": "In 2007, Pausch received two awards from the Association for Computing Machinery for his achievements in computer science education: the Karl V. Karlstrom Outstanding Educator Award and the ACM SIGCSE Award for Outstanding Contribution to Computer Science Education.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 24], [25, 28], [29, 35], [36, 40], [41, 44], [45, 56], [57, 60], [61, 70], [71, 80], [81, 84], [85, 88], [89, 101], [102, 104], [105, 113], [114, 121], [122, 131], [131, 132], [133, 136], [137, 141], [142, 143], [143, 144], [145, 154], [155, 166], [167, 175], [176, 181], [182, 185], [186, 189], [190, 193], [194, 200], [201, 206], [207, 210], [211, 222], [223, 235], [236, 238], [239, 247], [248, 255], [256, 265], [265, 266]]}
{"doc_key": "ai-test-325", "ner": [[3, 3, "person"], [8, 8, "product"], [9, 9, "product"], [17, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 8, 8, "role", "sells", false, false], [8, 8, 9, 9, "general-affiliation", "", false, false], [8, 8, 17, 18, "physical", "shipped_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "shipped", "in", "1961", "to", "General", "Motors", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was shipped in 1961 to General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 73], [74, 76], [77, 81], [82, 84], [85, 92], [93, 99], [99, 100]]}
{"doc_key": "ai-test-326", "ner": [[0, 1, "algorithm"], [5, 10, "field"], [11, 11, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 0, 1, "usage", "", false, false], [11, 11, 5, 10, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Semantic", "networks", "are", "used", "in", "natural", "language", "processing", "applications", "such", "as", "parsing", "."], "sentence-detokenized": "Semantic networks are used in natural language processing applications such as parsing.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 26], [27, 29], [30, 37], [38, 46], [47, 57], [58, 70], [71, 75], [76, 78], [79, 86], [86, 87]]}
{"doc_key": "ai-test-327", "ner": [[2, 4, "field"], [6, 7, "field"], [9, 10, "task"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 24, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[6, 7, 2, 4, "usage", "", false, false], [9, 10, 2, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Successful", "applications", "of", "deep", "learning", "include", "computer", "vision", "and", "speech", "recognition", ".", "Honglak", "Lee", ",", "Roger", "Grosse", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y", ".", "Ng", "."], "sentence-detokenized": "Successful applications of deep learning include computer vision and speech recognition. Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 10], [11, 23], [24, 26], [27, 31], [32, 40], [41, 48], [49, 57], [58, 64], [65, 68], [69, 75], [76, 87], [87, 88], [89, 96], [97, 100], [100, 101], [102, 107], [108, 114], [114, 115], [116, 122], [123, 132], [132, 133], [134, 140], [141, 142], [142, 143], [144, 146], [146, 147]]}
{"doc_key": "ai-test-328", "ner": [[4, 9, "product"], [15, 15, "misc"], [18, 18, "misc"], [24, 24, "product"], [28, 29, "task"], [31, 32, "task"], [34, 35, "task"], [37, 39, "field"], [41, 43, "task"], [45, 46, "field"], [48, 49, "task"], [51, 52, "task"], [55, 55, "task"], [57, 57, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 9, 15, 15, "physical", "travels_to", false, false], [4, 9, 18, 18, "physical", "travels_to", false, false], [24, 24, 4, 9, "part-of", "", false, false], [24, 24, 4, 9, "role", "maintains", false, false], [24, 24, 28, 29, "related-to", "has_ability_to", false, false], [24, 24, 31, 32, "related-to", "has_ability_to", false, false], [24, 24, 34, 35, "related-to", "has_ability_to", false, false], [24, 24, 37, 39, "related-to", "has_ability_to", false, false], [24, 24, 41, 43, "related-to", "has_ability_to", false, false], [24, 24, 45, 46, "related-to", "has_ability_to", false, false], [24, 24, 48, 49, "related-to", "has_ability_to", false, false], [24, 24, 51, 52, "related-to", "has_ability_to", false, false], [24, 24, 55, 55, "related-to", "has_ability_to", false, false], [24, 24, 57, 57, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["In", "addition", "to", "maintaining", "the", "Discovery", "One", "spacecraft", "'s", "systems", "during", "the", "interplanetary", "mission", "to", "Jupiter", "(", "or", "Saturn", "in", "the", "novel", ")", ",", "HAL", "is", "capable", "of", "speech", "synthesis", ",", "speech", "recognition", ",", "facial", "recognition", ",", "natural", "language", "processing", ",", "lip", "-", "reading", ",", "art", "appreciation", ",", "affective", "computing", ",", "automated", "reasoning", ",", "spacecraft", "piloting", "and", "chess", "."], "sentence-detokenized": "In addition to maintaining the Discovery One spacecraft's systems during the interplanetary mission to Jupiter (or Saturn in the novel), HAL is capable of speech synthesis, speech recognition, facial recognition, natural language processing, lip-reading, art appreciation, affective computing, automated reasoning, spacecraft piloting and chess.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 40], [41, 44], [45, 55], [55, 57], [58, 65], [66, 72], [73, 76], [77, 91], [92, 99], [100, 102], [103, 110], [111, 112], [112, 114], [115, 121], [122, 124], [125, 128], [129, 134], [134, 135], [135, 136], [137, 140], [141, 143], [144, 151], [152, 154], [155, 161], [162, 171], [171, 172], [173, 179], [180, 191], [191, 192], [193, 199], [200, 211], [211, 212], [213, 220], [221, 229], [230, 240], [240, 241], [242, 245], [245, 246], [246, 253], [253, 254], [255, 258], [259, 271], [271, 272], [273, 282], [283, 292], [292, 293], [294, 303], [304, 313], [313, 314], [315, 325], [326, 334], [335, 338], [339, 344], [344, 345]]}
{"doc_key": "ai-test-329", "ner": [[0, 1, "researcher"], [4, 4, "country"], [7, 9, "country"], [11, 11, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 4, "physical", "", false, false], [0, 1, 7, 9, "physical", "", false, false], [0, 1, 11, 11, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dr.", "Julesz", "emigrated", "from", "Hungary", "to", "the", "United", "States", "after", "the", "Soviet", "invasion", "of", "1956", "."], "sentence-detokenized": "Dr. Julesz emigrated from Hungary to the United States after the Soviet invasion of 1956.", "token2charspan": [[0, 3], [4, 10], [11, 20], [21, 25], [26, 33], [34, 36], [37, 40], [41, 47], [48, 54], [55, 60], [61, 64], [65, 71], [72, 80], [81, 83], [84, 88], [88, 89]]}
{"doc_key": "ai-test-330", "ner": [[5, 6, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "activation", "functions", "of", "the", "sigmoid", "function", "use", "a", "second", "non-linearity", "for", "large", "inputs", ":", "math", "\\", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+", "exp", "(", "-", "v", "_", "i", ")", ")", "^", "{", "-1", "}", "/", "math", "."], "sentence-detokenized": "The activation functions of the sigmoid function use a second non-linearity for large inputs: math\\ phi (v _ i) = (1 + exp (-v _ i)) ^ {-1} / math.", "token2charspan": [[0, 3], [4, 14], [15, 24], [25, 27], [28, 31], [32, 39], [40, 48], [49, 52], [53, 54], [55, 61], [62, 75], [76, 79], [80, 85], [86, 92], [92, 93], [94, 98], [98, 99], [100, 103], [104, 105], [105, 106], [107, 108], [109, 110], [110, 111], [112, 113], [114, 115], [115, 116], [117, 118], [119, 122], [123, 124], [124, 125], [125, 126], [127, 128], [129, 130], [130, 131], [131, 132], [133, 134], [135, 136], [136, 138], [138, 139], [140, 141], [142, 146], [146, 147]]}
{"doc_key": "ai-test-331", "ner": [[10, 12, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "probabilities", "are", "used", "to", "determine", "the", "target", "through", "a", "maximum", "likelihood", "decision", "."], "sentence-detokenized": "These probabilities are used to determine the target through a maximum likelihood decision.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 28], [29, 31], [32, 41], [42, 45], [46, 52], [53, 60], [61, 62], [63, 70], [71, 81], [82, 90], [90, 91]]}
{"doc_key": "ai-test-332", "ner": [[6, 8, "university"], [15, 16, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1984", "he", "moved", "to", "the", "University", "of", "Konstanz", "and", "in", "1990", "to", "the", "University", "of", "Salzburg", "."], "sentence-detokenized": "In 1984 he moved to the University of Konstanz and in 1990 to the University of Salzburg.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 16], [17, 19], [20, 23], [24, 34], [35, 37], [38, 46], [47, 50], [51, 53], [54, 58], [59, 61], [62, 65], [66, 76], [77, 79], [80, 88], [88, 89]]}
{"doc_key": "ai-test-333", "ner": [[7, 8, "metrics"], [10, 12, "metrics"], [14, 16, "metrics"], [18, 18, "metrics"], [20, 21, "metrics"], [23, 25, "metrics"], [28, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 12, 7, 8, "origin", "based_on", false, false], [14, 16, 7, 8, "origin", "based_on", false, false], [18, 18, 7, 8, "origin", "based_on", false, false], [20, 21, 7, 8, "origin", "based_on", false, false], [23, 25, 7, 8, "origin", "based_on", false, false], [28, 31, 7, 8, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Some", "popular", "fitness", "functions", "based", "on", "the", "confusion", "matrix", "are", "sensitivity", "/", "specificity", ",", "recall", "/", "accuracy", ",", "F-measure", ",", "Jaccard", "similarity", ",", "Matthews", "correlation", "coefficient", "and", "the", "cost", "/", "profit", "matrix", "which", "combines", "the", "costs", "and", "profits", "assigned", "to", "the", "4", "different", "types", "of", "classifications", "."], "sentence-detokenized": "Some popular fitness functions based on the confusion matrix are sensitivity/specificity, recall/accuracy, F-measure, Jaccard similarity, Matthews correlation coefficient and the cost/profit matrix which combines the costs and profits assigned to the 4 different types of classifications.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 30], [31, 36], [37, 39], [40, 43], [44, 53], [54, 60], [61, 64], [65, 76], [76, 77], [77, 88], [88, 89], [90, 96], [96, 97], [97, 105], [105, 106], [107, 116], [116, 117], [118, 125], [126, 136], [136, 137], [138, 146], [147, 158], [159, 170], [171, 174], [175, 178], [179, 183], [183, 184], [184, 190], [191, 197], [198, 203], [204, 212], [213, 216], [217, 222], [223, 226], [227, 234], [235, 243], [244, 246], [247, 250], [251, 252], [253, 262], [263, 268], [269, 271], [272, 287], [287, 288]]}
{"doc_key": "ai-test-334", "ner": [[6, 6, "product"], [8, 8, "product"], [10, 10, "product"], [12, 12, "product"], [15, 16, "programlang"], [27, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[27, 29, 6, 6, "part-of", "", false, false], [27, 29, 8, 8, "part-of", "", false, false], [27, 29, 10, 10, "part-of", "", false, false], [27, 29, 12, 12, "part-of", "", false, false], [27, 29, 15, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Common", "numerical", "programming", "environments", "such", "as", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", "and", "the", "R", "language", "provide", "some", "of", "the", "simplest", "feature", "extraction", "techniques", "(", "e.g.", "principal", "component", "analysis", ")", "using", "built", "-", "in", "commands", "."], "sentence-detokenized": "Common numerical programming environments such as MATLAB, SciLab, NumPy, Sklearn and the R language provide some of the simplest feature extraction techniques (e.g. principal component analysis) using built-in commands.", "token2charspan": [[0, 6], [7, 16], [17, 28], [29, 41], [42, 46], [47, 49], [50, 56], [56, 57], [58, 64], [64, 65], [66, 71], [71, 72], [73, 80], [81, 84], [85, 88], [89, 90], [91, 99], [100, 107], [108, 112], [113, 115], [116, 119], [120, 128], [129, 136], [137, 147], [148, 158], [159, 160], [160, 164], [165, 174], [175, 184], [185, 193], [193, 194], [195, 200], [201, 206], [206, 207], [207, 209], [210, 218], [218, 219]]}
{"doc_key": "ai-test-335", "ner": [[0, 3, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Industrial", "robots", "have", "been", "implemented", "to", "collaborate", "with", "humans", "in", "performing", "industrial", "manufacturing", "tasks", "."], "sentence-detokenized": "Industrial robots have been implemented to collaborate with humans in performing industrial manufacturing tasks.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 27], [28, 39], [40, 42], [43, 54], [55, 59], [60, 66], [67, 69], [70, 80], [81, 91], [92, 105], [106, 111], [111, 112]]}
{"doc_key": "ai-test-336", "ner": [[6, 6, "field"], [8, 11, "researcher"], [21, 22, "field"], [24, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 21, 22, "related-to", "", false, false], [6, 6, 24, 25, "related-to", "", false, false], [6, 6, 27, 28, "related-to", "", false, false], [8, 11, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "first", "published", "paper", "on", "CG", ",", "John", "F", ".", "Sowa", "applied", "it", "to", "a", "wide", "range", "of", "topics", "in", "artificial", "intelligence", ",", "computer", "science", "and", "cognitive", "science", "."], "sentence-detokenized": "In the first published paper on CG, John F. Sowa applied it to a wide range of topics in artificial intelligence, computer science and cognitive science.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [23, 28], [29, 31], [32, 34], [34, 35], [36, 40], [41, 42], [42, 43], [44, 48], [49, 56], [57, 59], [60, 62], [63, 64], [65, 69], [70, 75], [76, 78], [79, 85], [86, 88], [89, 99], [100, 112], [112, 113], [114, 122], [123, 130], [131, 134], [135, 144], [145, 152], [152, 153]]}
{"doc_key": "ai-test-337", "ner": [[0, 0, "metrics"], [4, 4, "metrics"], [10, 11, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "BLEU", "in", "its", "calculation", "of", "the", "brevity", "penalty", ",", "in", "that", "small", "variations", "in", "translation", "length", "do", "not", "affect", "the", "overall", "score", "as", "much", "."], "sentence-detokenized": "NIST also differs from BLEU in its calculation of the brevity penalty, in that small variations in translation length do not affect the overall score as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 46], [47, 49], [50, 53], [54, 61], [62, 69], [69, 70], [71, 73], [74, 78], [79, 84], [85, 95], [96, 98], [99, 110], [111, 117], [118, 120], [121, 124], [125, 131], [132, 135], [136, 143], [144, 149], [150, 152], [153, 157], [157, 158]]}
{"doc_key": "ai-test-338", "ner": [[1, 5, "misc"], [13, 13, "conference"], [18, 20, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 5, 13, 13, "temporal", "", false, false], [1, 5, 18, 20, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "IJCAI", "Award", "for", "Research", "Excellence", "is", "a", "biannual", "award", "given", "at", "the", "IJCAI", "conference", "to", "researchers", "in", "artificial", "intelligence", "in", "recognition", "of", "their", "career", "excellence", "."], "sentence-detokenized": "The IJCAI Award for Research Excellence is a biannual award given at the IJCAI conference to researchers in artificial intelligence in recognition of their career excellence.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 19], [20, 28], [29, 39], [40, 42], [43, 44], [45, 53], [54, 59], [60, 65], [66, 68], [69, 72], [73, 78], [79, 89], [90, 92], [93, 104], [105, 107], [108, 118], [119, 131], [132, 134], [135, 146], [147, 149], [150, 155], [156, 162], [163, 173], [173, 174]]}
{"doc_key": "ai-test-339", "ner": [[0, 0, "researcher"], [9, 9, "conference"], [19, 26, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 9, 9, "role", "", false, false], [0, 0, 19, 26, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lenat", "was", "one", "of", "the", "first", "members", "of", "the", "AAAI", "and", "is", "the", "only", "individual", "to", "have", "served", "on", "the", "Scientific", "Advisory", "Boards", "of", "Microsoft", "and", "Apple", "."], "sentence-detokenized": "Lenat was one of the first members of the AAAI and is the only individual to have served on the Scientific Advisory Boards of Microsoft and Apple.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 16], [17, 20], [21, 26], [27, 34], [35, 37], [38, 41], [42, 46], [47, 50], [51, 53], [54, 57], [58, 62], [63, 73], [74, 76], [77, 81], [82, 88], [89, 91], [92, 95], [96, 106], [107, 115], [116, 122], [123, 125], [126, 135], [136, 139], [140, 145], [145, 146]]}
{"doc_key": "ai-test-340", "ner": [[0, 0, "algorithm"], [5, 6, "misc"], [10, 12, "metrics"], [19, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 6, "related-to", "minimise", false, false], [10, 12, 5, 6, "type-of", "", false, false], [19, 19, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autoencoders", "are", "trained", "to", "minimise", "reconstruction", "errors", "(", "such", "as", "mean", "square", "error", ")", ",", "often", "referred", "to", "as", "loss", ":"], "sentence-detokenized": "Autoencoders are trained to minimise reconstruction errors (such as mean square error), often referred to as loss:", "token2charspan": [[0, 12], [13, 16], [17, 24], [25, 27], [28, 36], [37, 51], [52, 58], [59, 60], [60, 64], [65, 67], [68, 72], [73, 79], [80, 85], [85, 86], [86, 87], [88, 93], [94, 102], [103, 105], [106, 108], [109, 113], [113, 114]]}
{"doc_key": "ai-test-341", "ner": [[28, 30, "misc"], [34, 34, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[34, 34, 28, 30, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "alternative", "to", "using", "definitions", "is", "to", "consider", "the", "general", "relationship", "between", "word", "senses", "and", "to", "calculate", "the", "similarity", "of", "each", "pair", "of", "word", "senses", "from", "a", "given", "lexical", "knowledge", "base", ",", "such", "as", "WordNet", "."], "sentence-detokenized": "An alternative to using definitions is to consider the general relationship between word senses and to calculate the similarity of each pair of word senses from a given lexical knowledge base, such as WordNet.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 23], [24, 35], [36, 38], [39, 41], [42, 50], [51, 54], [55, 62], [63, 75], [76, 83], [84, 88], [89, 95], [96, 99], [100, 102], [103, 112], [113, 116], [117, 127], [128, 130], [131, 135], [136, 140], [141, 143], [144, 148], [149, 155], [156, 160], [161, 162], [163, 168], [169, 176], [177, 186], [187, 191], [191, 192], [193, 197], [198, 200], [201, 208], [208, 209]]}
{"doc_key": "ai-test-342", "ner": [[0, 2, "algorithm"], [9, 11, "researcher"], [22, 23, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 9, 11, "origin", "", false, false], [9, 11, 22, 23, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD", "-", "Lambda", "is", "a", "learning", "algorithm", "invented", "by", "Richard", "S.", "Sutton", "based", "on", "earlier", "work", "on", "time", "-", "difference", "learning", "by", "Arthur", "Samuel", "."], "sentence-detokenized": "TD-Lambda is a learning algorithm invented by Richard S. Sutton based on earlier work on time-difference learning by Arthur Samuel.", "token2charspan": [[0, 2], [2, 3], [3, 9], [10, 12], [13, 14], [15, 23], [24, 33], [34, 42], [43, 45], [46, 53], [54, 56], [57, 63], [64, 69], [70, 72], [73, 80], [81, 85], [86, 88], [89, 93], [93, 94], [94, 104], [105, 113], [114, 116], [117, 123], [124, 130], [130, 131]]}
{"doc_key": "ai-test-343", "ner": [[1, 2, "field"], [4, 4, "field"], [6, 7, "task"], [11, 13, "task"], [15, 15, "task"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 7, 1, 2, "part-of", "task_part_of_field", false, false], [6, 7, 4, 4, "part-of", "task_part_of_field", false, false], [11, 13, 6, 7, "named", "", false, false], [15, 15, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "data", "mining", "and", "statistics", ",", "hierarchical", "clustering", "(", "also", "called", "hierarchical", "cluster", "analysis", "or", "HCA", ")", "is", "a", "method", "of", "cluster", "analysis", "that", "seeks", "to", "construct", "a", "hierarchy", "of", "clusters", "."], "sentence-detokenized": "In data mining and statistics, hierarchical clustering (also called hierarchical cluster analysis or HCA) is a method of cluster analysis that seeks to construct a hierarchy of clusters.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 18], [19, 29], [29, 30], [31, 43], [44, 54], [55, 56], [56, 60], [61, 67], [68, 80], [81, 88], [89, 97], [98, 100], [101, 104], [104, 105], [106, 108], [109, 110], [111, 117], [118, 120], [121, 128], [129, 137], [138, 142], [143, 148], [149, 151], [152, 161], [162, 163], [164, 173], [174, 176], [177, 185], [185, 186]]}
{"doc_key": "ai-test-344", "ner": [[3, 3, "algorithm"], [8, 11, "field"], [10, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "concept", "of", "deconvolution", "is", "widely", "used", "in", "signal", "and", "image", "processing", "techniques", "."], "sentence-detokenized": "The concept of deconvolution is widely used in signal and image processing techniques.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 28], [29, 31], [32, 38], [39, 43], [44, 46], [47, 53], [54, 57], [58, 63], [64, 74], [75, 85], [85, 86]]}
{"doc_key": "ai-test-345", "ner": [[0, 1, "algorithm"], [20, 21, "misc"], [24, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 20, 21, "related-to", "enhances", false, false], [0, 1, 20, 21, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cognitive", "maps", "serve", "to", "build", "and", "accumulate", "spatial", "knowledge", ",", "allowing", "the", "mind", "'s", "eye", "to", "visualise", "images", "to", "reduce", "cognitive", "load", "and", "improve", "recall", "and", "learning", "of", "information", "."], "sentence-detokenized": "Cognitive maps serve to build and accumulate spatial knowledge, allowing the mind's eye to visualise images to reduce cognitive load and improve recall and learning of information.", "token2charspan": [[0, 9], [10, 14], [15, 20], [21, 23], [24, 29], [30, 33], [34, 44], [45, 52], [53, 62], [62, 63], [64, 72], [73, 76], [77, 81], [81, 83], [84, 87], [88, 90], [91, 100], [101, 107], [108, 110], [111, 117], [118, 127], [128, 132], [133, 136], [137, 144], [145, 151], [152, 155], [156, 164], [165, 167], [168, 179], [179, 180]]}
{"doc_key": "ai-test-346", "ner": [[7, 7, "programlang"], [9, 10, "programlang"], [12, 12, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["usually", "providing", "bindings", "to", "languages", "such", "as", "Python", ",", "C", "++", ",", "Java", ")", "."], "sentence-detokenized": "usually providing bindings to languages such as Python, C++, Java).", "token2charspan": [[0, 7], [8, 17], [18, 26], [27, 29], [30, 39], [40, 44], [45, 47], [48, 54], [54, 55], [56, 57], [57, 59], [59, 60], [61, 65], [65, 66], [66, 67]]}
{"doc_key": "ai-test-347", "ner": [[1, 3, "product"], [5, 5, "product"], [16, 17, "task"], [23, 25, "task"], [29, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 16, 17, "usage", "", false, false], [1, 3, 23, 25, "usage", "", false, false], [1, 3, 29, 33, "usage", "", false, false], [5, 5, 1, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "voice", "user", "interface", "(", "VUI", ")", "makes", "spoken", "human", "interaction", "with", "computers", "possible", ",", "using", "speech", "recognition", "to", "understand", "spoken", "commands", "and", "responses", "to", "questions", ",", "and", "usually", "text", "-", "to", "-", "speech", "to", "reproduce", "a", "response", "."], "sentence-detokenized": "A voice user interface (VUI) makes spoken human interaction with computers possible, using speech recognition to understand spoken commands and responses to questions, and usually text-to-speech to reproduce a response.", "token2charspan": [[0, 1], [2, 7], [8, 12], [13, 22], [23, 24], [24, 27], [27, 28], [29, 34], [35, 41], [42, 47], [48, 59], [60, 64], [65, 74], [75, 83], [83, 84], [85, 90], [91, 97], [98, 109], [110, 112], [113, 123], [124, 130], [131, 139], [140, 143], [144, 153], [154, 156], [157, 166], [166, 167], [168, 171], [172, 179], [180, 184], [184, 185], [185, 187], [187, 188], [188, 194], [195, 197], [198, 207], [208, 209], [210, 218], [218, 219]]}
{"doc_key": "ai-test-348", "ner": [[0, 0, "programlang"], [3, 4, "misc"], [7, 7, "programlang"], [13, 16, "researcher"], [18, 19, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 4, "general-affiliation", "is_a", false, false], [0, 0, 7, 7, "general-affiliation", "made_with", false, false], [0, 0, 13, 16, "origin", "", false, false], [13, 16, 18, 19, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Jess", "is", "a", "rules", "engine", "for", "the", "Java", "platform", "that", "was", "developed", "by", "Ernest", "Friedman", "-", "Hill", "of", "Sandia", "National", "."], "sentence-detokenized": "Jess is a rules engine for the Java platform that was developed by Ernest Friedman-Hill of Sandia National.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 15], [16, 22], [23, 26], [27, 30], [31, 35], [36, 44], [45, 49], [50, 53], [54, 63], [64, 66], [67, 73], [74, 82], [82, 83], [83, 87], [88, 90], [91, 97], [98, 106], [106, 107]]}
{"doc_key": "ai-test-349", "ner": [[4, 5, "algorithm"], [20, 20, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 20, 20, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "the", "case", "of", "multilayer", "perceptrons", ",", "where", "there", "is", "a", "hidden", "layer", ",", "more", "sophisticated", "algorithms", ",", "such", "as", "backpropagation", ",", "must", "be", "used", "."], "sentence-detokenized": "In the case of multilayer perceptrons, where there is a hidden layer, more sophisticated algorithms, such as backpropagation, must be used.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 25], [26, 37], [37, 38], [39, 44], [45, 50], [51, 53], [54, 55], [56, 62], [63, 68], [68, 69], [70, 74], [75, 88], [89, 99], [99, 100], [101, 105], [106, 108], [109, 124], [124, 125], [126, 130], [131, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-test-350", "ner": [[0, 1, "product"], [2, 6, "product"], [10, 17, "algorithm"], [22, 23, "field"], [27, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 6, 0, 1, "part-of", "", false, false], [2, 6, 10, 17, "usage", "", false, true], [10, 17, 22, 23, "related-to", "performs", false, false], [27, 31, 22, 23, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Google", "Translate", "'s", "neural", "machine", "translation", "system", "uses", "a", "large", "end", "-", "to", "-", "end", "artificial", "neural", "network", "that", "attempts", "to", "perform", "deep", "learning", ",", "in", "particular", "short", "-", "term", "memory", "networks", "."], "sentence-detokenized": "Google Translate's neural machine translation system uses a large end-to-end artificial neural network that attempts to perform deep learning, in particular short-term memory networks.", "token2charspan": [[0, 6], [7, 16], [16, 18], [19, 25], [26, 33], [34, 45], [46, 52], [53, 57], [58, 59], [60, 65], [66, 69], [69, 70], [70, 72], [72, 73], [73, 76], [77, 87], [88, 94], [95, 102], [103, 107], [108, 116], [117, 119], [120, 127], [128, 132], [133, 141], [141, 142], [143, 145], [146, 156], [157, 162], [162, 163], [163, 167], [168, 174], [175, 183], [183, 184]]}
{"doc_key": "ai-test-351", "ner": [[7, 7, "researcher"], [9, 9, "researcher"], [11, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "1980s", "and", "early", "1990s", ",", "Werbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Pearlmutter", "and", "others", "developed", "various", "methods", "for", "doing", "so", "."], "sentence-detokenized": "In the 1980s and early 1990s, Werbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Pearlmutter and others developed various methods for doing so.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 16], [17, 22], [23, 28], [28, 29], [30, 36], [36, 37], [38, 46], [46, 47], [48, 56], [56, 57], [58, 64], [65, 76], [76, 77], [78, 82], [83, 93], [93, 94], [95, 106], [107, 110], [111, 117], [118, 127], [128, 135], [136, 143], [144, 147], [148, 153], [154, 156], [156, 157]]}
{"doc_key": "ai-test-352", "ner": [[0, 3, "organisation"], [6, 6, "organisation"], [10, 11, "task"], [15, 15, "product"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[15, 15, 10, 11, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [3], "sentence": ["|", "Apple", "Apple", "Inc.", "originally", "licensed", "Nuance", "software", "to", "provide", "speech", "recognition", "capabilities", "for", "its", "Siri", "digital", "assistant", "."], "sentence-detokenized": "| Apple Apple Inc. originally licensed Nuance software to provide speech recognition capabilities for its Siri digital assistant.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 18], [19, 29], [30, 38], [39, 45], [46, 54], [55, 57], [58, 65], [66, 72], [73, 84], [85, 97], [98, 101], [102, 105], [106, 110], [111, 118], [119, 128], [128, 129]]}
{"doc_key": "ai-test-353", "ner": [[0, 0, "organisation"], [3, 4, "misc"], [7, 8, "person"], [12, 13, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 4, "role", "releases_movies_in_genre", false, false], [7, 8, 0, 0, "role", "directs_for", false, false], [12, 13, 0, 0, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "released", "several", "3D", "westerns", "produced", "by", "Sam", "Katzman", "and", "directed", "by", "William", "Castle", "."], "sentence-detokenized": "Columbia released several 3D westerns produced by Sam Katzman and directed by William Castle.", "token2charspan": [[0, 8], [9, 17], [18, 25], [26, 28], [29, 37], [38, 46], [47, 49], [50, 53], [54, 61], [62, 65], [66, 74], [75, 77], [78, 85], [86, 92], [92, 93]]}
{"doc_key": "ai-test-354", "ner": [[9, 10, "field"], [12, 12, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "incorporates", "knowledge", "and", "research", "in", "the", "fields", "of", "computer", "science", ",", "linguistics", "and", "computer", "engineering", "."], "sentence-detokenized": "It incorporates knowledge and research in the fields of computer science, linguistics and computer engineering.", "token2charspan": [[0, 2], [3, 15], [16, 25], [26, 29], [30, 38], [39, 41], [42, 45], [46, 52], [53, 55], [56, 64], [65, 72], [72, 73], [74, 85], [86, 89], [90, 98], [99, 110], [110, 111]]}
{"doc_key": "ai-test-355", "ner": [[5, 5, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", "is", "an", "example", "of", "R", "code", ":"], "sentence-detokenized": "Here is an example of R code:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 23], [24, 28], [28, 29]]}
{"doc_key": "ai-test-356", "ner": [[0, 2, "metrics"], [8, 10, "metrics"], [12, 12, "metrics"], [16, 18, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 8, 10, "part-of", "plotted_into", false, false], [0, 2, 16, 18, "part-of", "plotted_into", false, false], [12, 12, 8, 10, "named", "", false, false], [20, 20, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "ROC", "curve", "is", "created", "by", "plotting", "the", "TRUE", "positive", "rate", "(", "TPR", ")", "against", "the", "FALSE", "positive", "rate", "(", "FPR", ")", "at", "various", "threshold", "settings", "."], "sentence-detokenized": "The ROC curve is created by plotting the TRUE positive rate (TPR) against the FALSE positive rate (FPR) at various threshold settings.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 24], [25, 27], [28, 36], [37, 40], [41, 45], [46, 54], [55, 59], [60, 61], [61, 64], [64, 65], [66, 73], [74, 77], [78, 83], [84, 92], [93, 97], [98, 99], [99, 102], [102, 103], [104, 106], [107, 114], [115, 124], [125, 133], [133, 134]]}
{"doc_key": "ai-test-357", "ner": [[5, 7, "field"], [9, 10, "researcher"], [12, 13, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 5, 7, "related-to", "researches_field", false, false], [12, 13, 5, 7, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Research", "stagnated", "after", "the", "research", "on", "machine", "learning", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", ","], "sentence-detokenized": "Research stagnated after the research on machine learning by Marvin Minsky and Seymour Papert (1969),", "token2charspan": [[0, 8], [9, 18], [19, 24], [25, 28], [29, 37], [38, 40], [41, 48], [49, 57], [58, 60], [61, 67], [68, 74], [75, 78], [79, 86], [87, 93], [94, 95], [95, 99], [99, 100], [100, 101]]}
{"doc_key": "ai-test-358", "ner": [[6, 6, "task"], [9, 10, "programlang"], [12, 14, "product"], [16, 17, "programlang"], [19, 19, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 6, 9, 10, "related-to", "used_to_build", false, false], [6, 6, 12, 14, "related-to", "used_to_build", false, false], [6, 6, 16, 17, "related-to", "used_to_build", false, false], [6, 6, 19, 19, "related-to", "used_to_build", false, false], [6, 6, 22, 22, "related-to", "used_to_build", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "programming", "environments", "used", "to", "build", "DAQ", "applications", "include", "ladder", "logic", ",", "Visual", "C", "++", ",", "Visual", "Basic", ",", "LabVIEW", ",", "and", "MATLAB", "."], "sentence-detokenized": "Other programming environments used to build DAQ applications include ladder logic, Visual C++, Visual Basic, LabVIEW, and MATLAB.", "token2charspan": [[0, 5], [6, 17], [18, 30], [31, 35], [36, 38], [39, 44], [45, 48], [49, 61], [62, 69], [70, 76], [77, 82], [82, 83], [84, 90], [91, 92], [92, 94], [94, 95], [96, 102], [103, 108], [108, 109], [110, 117], [117, 118], [119, 122], [123, 129], [129, 130]]}
{"doc_key": "ai-test-359", "ner": [[15, 16, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "metric", "was", "designed", "to", "address", "some", "of", "the", "problems", "found", "in", "the", "more", "popular", "BLEU", "metric", ",", "and", "also", "to", "produce", "a", "good", "correlation", "with", "human", "judgement", "at", "the", "sentence", "or", "segment", "level", "."], "sentence-detokenized": "The metric was designed to address some of the problems found in the more popular BLEU metric, and also to produce a good correlation with human judgement at the sentence or segment level.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 26], [27, 34], [35, 39], [40, 42], [43, 46], [47, 55], [56, 61], [62, 64], [65, 68], [69, 73], [74, 81], [82, 86], [87, 93], [93, 94], [95, 98], [99, 103], [104, 106], [107, 114], [115, 116], [117, 121], [122, 133], [134, 138], [139, 144], [145, 154], [155, 157], [158, 161], [162, 170], [171, 173], [174, 181], [182, 187], [187, 188]]}
{"doc_key": "ai-test-360", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [14, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "semantic", "correlations", "between", "consecutive", "video", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and short-term memory are often used to exploit semantic correlations between consecutive video frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 83], [83, 84], [84, 88], [89, 95], [96, 99], [100, 105], [106, 110], [111, 113], [114, 121], [122, 130], [131, 143], [144, 151], [152, 163], [164, 169], [170, 176], [176, 177]]}
{"doc_key": "ai-test-361", "ner": [[3, 5, "product"], [7, 7, "product"], [14, 19, "product"], [22, 22, "product"], [38, 39, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 14, 19, "artifact", "", false, false], [3, 5, 38, 39, "named", "", false, false], [7, 7, 3, 5, "named", "", false, false], [22, 22, 14, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Mass", "-", "produced", "printed", "circuit", "boards", "(", "PCBs", ")", "are", "almost", "exclusively", "manufactured", "with", "pick", "-", "and", "-", "place", "robots", ",", "usually", "SCARA", "manipulators", ",", "which", "remove", "tiny", "electronic", "components", "from", "strips", "or", "trays", "and", "place", "them", "on", "the", "PCBs", "with", "high", "precision", "."], "sentence-detokenized": "Mass-produced printed circuit boards (PCBs) are almost exclusively manufactured with pick-and-place robots, usually SCARA manipulators, which remove tiny electronic components from strips or trays and place them on the PCBs with high precision.", "token2charspan": [[0, 4], [4, 5], [5, 13], [14, 21], [22, 29], [30, 36], [37, 38], [38, 42], [42, 43], [44, 47], [48, 54], [55, 66], [67, 79], [80, 84], [85, 89], [89, 90], [90, 93], [93, 94], [94, 99], [100, 106], [106, 107], [108, 115], [116, 121], [122, 134], [134, 135], [136, 141], [142, 148], [149, 153], [154, 164], [165, 175], [176, 180], [181, 187], [188, 190], [191, 196], [197, 200], [201, 206], [207, 211], [212, 214], [215, 218], [219, 223], [224, 228], [229, 233], [234, 243], [243, 244]]}
{"doc_key": "ai-test-362", "ner": [[4, 5, "field"], [15, 15, "algorithm"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 29, "researcher"], [37, 38, "algorithm"], [40, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 15, 4, 5, "part-of", "", false, false], [15, 15, 20, 21, "origin", "", false, false], [15, 15, 23, 24, "origin", "", false, false], [15, 15, 26, 29, "origin", "", false, false], [15, 15, 37, 38, "type-of", "", false, false], [37, 38, 40, 41, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "the", "context", "of", "machine", "learning", ",", "where", "it", "is", "most", "widely", "applied", "today", ",", "LDA", "was", "independently", "rediscovered", "by", "David", "Blei", ",", "Andrew", "Ng", "and", "Michael", "I", ".", "Jordan", "in", "2003", ",", "and", "presented", "as", "a", "graphical", "model", "for", "topic", "discovery", "."], "sentence-detokenized": "In the context of machine learning, where it is most widely applied today, LDA was independently rediscovered by David Blei, Andrew Ng and Michael I. Jordan in 2003, and presented as a graphical model for topic discovery.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 25], [26, 34], [34, 35], [36, 41], [42, 44], [45, 47], [48, 52], [53, 59], [60, 67], [68, 73], [73, 74], [75, 78], [79, 82], [83, 96], [97, 109], [110, 112], [113, 118], [119, 123], [123, 124], [125, 131], [132, 134], [135, 138], [139, 146], [147, 148], [148, 149], [150, 156], [157, 159], [160, 164], [164, 165], [166, 169], [170, 179], [180, 182], [183, 184], [185, 194], [195, 200], [201, 204], [205, 210], [211, 220], [220, 221]]}
{"doc_key": "ai-test-363", "ner": [[8, 8, "task"], [11, 11, "misc"], [14, 14, "metrics"], [16, 16, "metrics"], [18, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 8, 11, 11, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["Performance", "measured", "on", "test", "data", "from", "eight", "na\u00efve", "WSIs", "in", "various", "tauopathies", "resulted", "in", "recall", ",", "accuracy", "and", "F1", "scores", "of", "0.92", ",", "0.72", "and", "0.81", ",", "respectively", "."], "sentence-detokenized": "Performance measured on test data from eight na\u00efve WSIs in various tauopathies resulted in recall, accuracy and F1 scores of 0.92, 0.72 and 0.81, respectively.", "token2charspan": [[0, 11], [12, 20], [21, 23], [24, 28], [29, 33], [34, 38], [39, 44], [45, 50], [51, 55], [56, 58], [59, 66], [67, 78], [79, 87], [88, 90], [91, 97], [97, 98], [99, 107], [108, 111], [112, 114], [115, 121], [122, 124], [125, 129], [129, 130], [131, 135], [136, 139], [140, 144], [144, 145], [146, 158], [158, 159]]}
{"doc_key": "ai-test-364", "ner": [[5, 5, "field"], [10, 11, "field"], [14, 14, "field"], [20, 21, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 14, 14, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["With", "the", "help", "of", "advanced", "AR", "technologies", "(", "e.g.", "adding", "computer", "vision", ",", "embedding", "AR", "cameras", "in", "the", "smartphone", "and", "object", "recognition", ")", "information", "about", "the", "real", "world", "around", "the", "user", "becomes", "interactive", "and", "digitally", "manipulated", "."], "sentence-detokenized": "With the help of advanced AR technologies (e.g. adding computer vision, embedding AR cameras in the smartphone and object recognition) information about the real world around the user becomes interactive and digitally manipulated.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 25], [26, 28], [29, 41], [42, 43], [43, 47], [48, 54], [55, 63], [64, 70], [70, 71], [72, 81], [82, 84], [85, 92], [93, 95], [96, 99], [100, 110], [111, 114], [115, 121], [122, 133], [133, 134], [135, 146], [147, 152], [153, 156], [157, 161], [162, 167], [168, 174], [175, 178], [179, 183], [184, 191], [192, 203], [204, 207], [208, 217], [218, 229], [229, 230]]}
{"doc_key": "ai-test-365", "ner": [[3, 3, "researcher"], [9, 9, "organisation"], [17, 18, "field"], [28, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 9, 9, "role", "forms_company", false, false], [9, 9, 17, 18, "related-to", "works_with", false, false], [9, 9, 28, 30, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2014", ",", "Schmidhuber", "set", "up", "a", "company", ",", "Nnaisense", ",", "to", "work", "on", "commercial", "applications", "of", "artificial", "intelligence", "in", "fields", "such", "as", "finance", ",", "heavy", "industry", "and", "self", "-", "driving", "cars", "."], "sentence-detokenized": "In 2014, Schmidhuber set up a company, Nnaisense, to work on commercial applications of artificial intelligence in fields such as finance, heavy industry and self-driving cars.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 24], [25, 27], [28, 29], [30, 37], [37, 38], [39, 48], [48, 49], [50, 52], [53, 57], [58, 60], [61, 71], [72, 84], [85, 87], [88, 98], [99, 111], [112, 114], [115, 121], [122, 126], [127, 129], [130, 137], [137, 138], [139, 144], [145, 153], [154, 157], [158, 162], [162, 163], [163, 170], [171, 175], [175, 176]]}
{"doc_key": "ai-test-366", "ner": [[23, 25, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "not", "only", "alters", "the", "performance", "of", "all", "subsequent", "tests", "on", "the", "retained", "explanatory", "model", ",", "but", "may", "introduce", "bias", "and", "alter", "the", "mean", "squared", "error", "in", "estimation", "."], "sentence-detokenized": "This not only alters the performance of all subsequent tests on the retained explanatory model, but may introduce bias and alter the mean squared error in estimation.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 20], [21, 24], [25, 36], [37, 39], [40, 43], [44, 54], [55, 60], [61, 63], [64, 67], [68, 76], [77, 88], [89, 94], [94, 95], [96, 99], [100, 103], [104, 113], [114, 118], [119, 122], [123, 128], [129, 132], [133, 137], [138, 145], [146, 151], [152, 154], [155, 165], [165, 166]]}
{"doc_key": "ai-test-367", "ner": [[0, 0, "misc"], [6, 6, "algorithm"], [9, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 0, 0, "usage", "", false, false], [6, 6, 9, 10, "topic", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Bigraphs", "are", "used", "in", "most", "successful", "language", "models", "for", "speech", "recognition", "."], "sentence-detokenized": "Bigraphs are used in most successful language models for speech recognition.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 20], [21, 25], [26, 36], [37, 45], [46, 52], [53, 56], [57, 63], [64, 75], [75, 76]]}
{"doc_key": "ai-test-368", "ner": [[3, 4, "field"], [9, 11, "misc"], [17, 19, "misc"], [25, 27, "organisation"], [30, 32, "misc"], [38, 41, "organisation"], [44, 46, "misc"], [52, 56, "organisation"], [60, 62, "misc"], [68, 70, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[9, 11, 3, 4, "topic", "", false, false], [17, 19, 25, 27, "origin", "", false, false], [30, 32, 38, 41, "origin", "", false, false], [44, 46, 52, 56, "origin", "", false, false], [60, 62, 68, 70, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["His", "research", "in", "cognitive", "psychology", "has", "been", "awarded", "the", "Early", "Career", "Award", "(", "1984", ")", "and", "the", "Boyd", "McCandless", "Award", "(", "1986", ")", "from", "the", "American", "Psychological", "Association", ",", "the", "Troland", "Research", "Award", "(", "1993", ")", "from", "the", "National", "Academy", "of", "Sciences", ",", "the", "Henry", "Dale", "Prize", "(", "2004", ")", "from", "the", "Royal", "Institution", "of", "Great", "Britain", ",", "and", "the", "George", "Miller", "Prize", "(", "2010", ")", "from", "the", "Cognitive", "Neuroscience", "Society", "."], "sentence-detokenized": "His research in cognitive psychology has been awarded the Early Career Award (1984) and the Boyd McCandless Award (1986) from the American Psychological Association, the Troland Research Award (1993) from the National Academy of Sciences, the Henry Dale Prize (2004) from the Royal Institution of Great Britain, and the George Miller Prize (2010) from the Cognitive Neuroscience Society.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 25], [26, 36], [37, 40], [41, 45], [46, 53], [54, 57], [58, 63], [64, 70], [71, 76], [77, 78], [78, 82], [82, 83], [84, 87], [88, 91], [92, 96], [97, 107], [108, 113], [114, 115], [115, 119], [119, 120], [121, 125], [126, 129], [130, 138], [139, 152], [153, 164], [164, 165], [166, 169], [170, 177], [178, 186], [187, 192], [193, 194], [194, 198], [198, 199], [200, 204], [205, 208], [209, 217], [218, 225], [226, 228], [229, 237], [237, 238], [239, 242], [243, 248], [249, 253], [254, 259], [260, 261], [261, 265], [265, 266], [267, 271], [272, 275], [276, 281], [282, 293], [294, 296], [297, 302], [303, 310], [310, 311], [312, 315], [316, 319], [320, 326], [327, 333], [334, 339], [340, 341], [341, 345], [345, 346], [347, 351], [352, 355], [356, 365], [366, 378], [379, 386], [386, 387]]}
{"doc_key": "ai-test-369", "ner": [[1, 1, "misc"], [7, 7, "misc"], [9, 11, "product"], [15, 15, "researcher"], [17, 17, "researcher"], [24, 25, "researcher"], [27, 28, "researcher"], [30, 31, "task"], [33, 36, "researcher"], [38, 42, "researcher"], [43, 44, "task"], [46, 46, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[1, 1, 7, 7, "named", "", false, false], [1, 1, 46, 46, "named", "", false, false], [7, 7, 15, 15, "origin", "", false, false], [7, 7, 17, 17, "origin", "", false, false], [7, 7, 30, 31, "related-to", "used_for", false, false], [9, 11, 7, 7, "usage", "", false, false], [9, 11, 43, 44, "named", "", false, false], [24, 25, 7, 7, "usage", "", false, false], [24, 25, 33, 36, "named", "same", false, false], [27, 28, 7, 7, "usage", "", false, false], [27, 28, 38, 42, "named", "same", false, false], [43, 44, 46, 46, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["An", "eigenface", "(", "The", "approach", "of", "using", "eigenfaces", "for", "face", "recognition", "system", "was", "developed", "by", "Sirovich", "and", "Kirby", "(", "1987", ")", "and", "used", "by", "Matthew", "Turk", "and", "Alex", "Pentland", "in", "face", "classification", ".", "Turk", ",", "Matthew", "A", "and", "Pentland", ",", "Alex", "P", ".", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "An eigenface (The approach of using eigenfaces for face recognition system was developed by Sirovich and Kirby (1987) and used by Matthew Turk and Alex Pentland in face classification. Turk, Matthew A and Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 2], [3, 12], [13, 14], [14, 17], [18, 26], [27, 29], [30, 35], [36, 46], [47, 50], [51, 55], [56, 67], [68, 74], [75, 78], [79, 88], [89, 91], [92, 100], [101, 104], [105, 110], [111, 112], [112, 116], [116, 117], [118, 121], [122, 126], [127, 129], [130, 137], [138, 142], [143, 146], [147, 151], [152, 160], [161, 163], [164, 168], [169, 183], [183, 184], [185, 189], [189, 190], [191, 198], [199, 200], [201, 204], [205, 213], [213, 214], [215, 219], [220, 221], [221, 222], [223, 227], [228, 239], [240, 245], [246, 256], [256, 257]]}
{"doc_key": "ai-test-370", "ner": [[5, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "lexical", "dictionary", "such", "as", "Word", "Net", "can", "then", "be", "used", "to", "understand", "the", "context", "."], "sentence-detokenized": "A lexical dictionary such as WordNet can then be used to understand the context.", "token2charspan": [[0, 1], [2, 9], [10, 20], [21, 25], [26, 28], [29, 33], [33, 36], [37, 40], [41, 45], [46, 48], [49, 53], [54, 56], [57, 67], [68, 71], [72, 79], [79, 80]]}
{"doc_key": "ai-test-371", "ner": [[0, 0, "misc"], [8, 8, "misc"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 8, "part-of", "", false, false], [8, 8, 15, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hyponymy", "is", "the", "most", "frequently", "encoded", "relationship", "between", "synsets", "used", "in", "lexical", "databases", "such", "as", "WordNet", "."], "sentence-detokenized": "Hyponymy is the most frequently encoded relationship between synsets used in lexical databases such as WordNet.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 20], [21, 31], [32, 39], [40, 52], [53, 60], [61, 68], [69, 73], [74, 76], [77, 84], [85, 94], [95, 99], [100, 102], [103, 110], [110, 111]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [6, 7, "programlang"], [9, 9, "programlang"], [37, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 7, "general-affiliation", "", false, false], [0, 0, 9, 9, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "offers", "open", "source", "libraries", "in", "C", "++", "and", "Java", ",", "but", "many", "customers", "rely", "on", "community", "-", "developed", "libraries", "as", "the", "libraries", "include", "built", "-", "in", "capabilities", "for", "data", "retrieval", "(", "array", "-", "style", ")", "from", "DAP", "servers", "."], "sentence-detokenized": "OPeNDAP offers open source libraries in C++ and Java, but many customers rely on community-developed libraries as the libraries include built-in capabilities for data retrieval (array-style) from DAP servers.", "token2charspan": [[0, 7], [8, 14], [15, 19], [20, 26], [27, 36], [37, 39], [40, 41], [41, 43], [44, 47], [48, 52], [52, 53], [54, 57], [58, 62], [63, 72], [73, 77], [78, 80], [81, 90], [90, 91], [91, 100], [101, 110], [111, 113], [114, 117], [118, 127], [128, 135], [136, 141], [141, 142], [142, 144], [145, 157], [158, 161], [162, 166], [167, 176], [177, 178], [178, 183], [183, 184], [184, 189], [189, 190], [191, 195], [196, 199], [200, 207], [207, 208]]}
{"doc_key": "ai-test-373", "ner": [[4, 5, "misc"], [8, 8, "product"], [13, 14, "country"], [30, 31, "misc"], [44, 45, "organisation"], [46, 46, "product"], [48, 48, "organisation"], [50, 53, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 13, 14, "opposite", "", false, false], [8, 8, 13, 14, "artifact", "", false, false], [30, 31, 8, 8, "part-of", "", false, false], [46, 46, 44, 45, "artifact", "", false, false], [50, 53, 48, 48, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["On", "that", "page", ",", "Samurai", "Damashii", "hyped", "the", "Senkousha", "as", "the", "crystallisation", "of", "China", "'s", "four", "thousand", "years", "of", "scientific", "knowledge", ",", "commented", "on", "its", "crude", "design", "(", "e.g.", "the", "Chinese", "cannon", "in", "its", "crotch", ")", "and", "placed", "it", "s", "image", "between", "those", "of", "Honda", "'s", "ASIMO", "and", "Sony", "'s", "QRIO", "SDR", "-", "3X", "to", "juxtapose", "them", "."], "sentence-detokenized": "On that page, Samurai Damashii hyped the Senkousha as the crystallisation of China's four thousand years of scientific knowledge, commented on its crude design (e.g. the Chinese cannon in its crotch) and placed its image between those of Honda's ASIMO and Sony's QRIO SDR-3X to juxtapose them.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 21], [22, 30], [31, 36], [37, 40], [41, 50], [51, 53], [54, 57], [58, 73], [74, 76], [77, 82], [82, 84], [85, 89], [90, 98], [99, 104], [105, 107], [108, 118], [119, 128], [128, 129], [130, 139], [140, 142], [143, 146], [147, 152], [153, 159], [160, 161], [161, 165], [166, 169], [170, 177], [178, 184], [185, 187], [188, 191], [192, 198], [198, 199], [200, 203], [204, 210], [211, 213], [213, 214], [215, 220], [221, 228], [229, 234], [235, 237], [238, 243], [243, 245], [246, 251], [252, 255], [256, 260], [260, 262], [263, 267], [268, 271], [271, 272], [272, 274], [275, 277], [278, 287], [288, 292], [292, 293]]}
{"doc_key": "ai-test-374", "ner": [[8, 9, "algorithm"], [21, 21, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 21, 21, "part-of", "includes_functionality_of", false, false], [8, 9, 23, 23, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "also", "many", "programming", "libraries", "that", "contain", "neural", "network", "functionalities", "and", "can", "be", "used", "in", "custom", "implementations", "(", "such", "as", "TensorFlow", ",", "Theano", ",", "etc.", ")", "."], "sentence-detokenized": "There are also many programming libraries that contain neural network functionalities and can be used in custom implementations (such as TensorFlow, Theano, etc.).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 19], [20, 31], [32, 41], [42, 46], [47, 54], [55, 61], [62, 69], [70, 85], [86, 89], [90, 93], [94, 96], [97, 101], [102, 104], [105, 111], [112, 127], [128, 129], [129, 133], [134, 136], [137, 147], [147, 148], [149, 155], [155, 156], [157, 161], [161, 162], [162, 163]]}
{"doc_key": "ai-test-375", "ner": [[6, 9, "conference"], [11, 12, "organisation"], [15, 21, "conference"], [23, 24, "conference"], [27, 27, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", ",", "the", "IEEE", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "the", "IAPR", "and", "the", "SPIE", "."], "sentence-detokenized": "He is a member of the Association for Computing Machinery, the IEEE, the American Association for the Advancement of Science, the IAPR and the SPIE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 33], [34, 37], [38, 47], [48, 57], [57, 58], [59, 62], [63, 67], [67, 68], [69, 72], [73, 81], [82, 93], [94, 97], [98, 101], [102, 113], [114, 116], [117, 124], [124, 125], [126, 129], [130, 134], [135, 138], [139, 142], [143, 147], [147, 148]]}
{"doc_key": "ai-test-376", "ner": [[4, 4, "organisation"], [8, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 8, 10, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "test", "conducted", "by", "RET", "in", "2011", "with", "facial", "recognition", "system", "cameras", "mounted", "on", "trams", "ensured", "that", "people", "who", "were", "banned", "from", "city", "trams", "did", "not", "sneak", "in", "anyway", "."], "sentence-detokenized": "A test conducted by RET in 2011 with facial recognition system cameras mounted on trams ensured that people who were banned from city trams did not sneak in anyway.", "token2charspan": [[0, 1], [2, 6], [7, 16], [17, 19], [20, 23], [24, 26], [27, 31], [32, 36], [37, 43], [44, 55], [56, 62], [63, 70], [71, 78], [79, 81], [82, 87], [88, 95], [96, 100], [101, 107], [108, 111], [112, 116], [117, 123], [124, 128], [129, 133], [134, 139], [140, 143], [144, 147], [148, 153], [154, 156], [157, 163], [163, 164]]}
{"doc_key": "ai-test-377", "ner": [[5, 6, "person"], [9, 9, "organisation"], [18, 19, "person"], [21, 22, "person"], [26, 27, "person"], [29, 30, "person"], [32, 33, "person"], [35, 36, "person"], [38, 39, "person"], [41, 42, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[5, 6, 9, 9, "role", "works_for", false, false], [18, 19, 9, 9, "role", "works_for", false, false], [21, 22, 9, 9, "role", "works_for", false, false], [26, 27, 9, 9, "role", "works_for", false, false], [29, 30, 9, 9, "role", "works_for", false, false], [32, 33, 9, 9, "role", "works_for", false, false], [35, 36, 9, 9, "role", "works_for", false, false], [38, 39, 9, 9, "role", "works_for", false, false], [41, 42, 9, 9, "role", "works_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "film", ",", "adapted", "from", "Cole", "Porter", "'s", "popular", "Broadway", "musical", ",", "starred", "the", "MGM", "singing", "team", "of", "Howard", "Keel", "and", "Kathryn", "Grayson", ",", "supported", "by", "Ann", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Van", ",", "James", "Whitmore", ",", "Kurt", "Kasznar", "and", "Tommy", "Rall", "."], "sentence-detokenized": "The film, adapted from Cole Porter's popular Broadway musical, starred the MGM singing team of Howard Keel and Kathryn Grayson, supported by Ann Miller, Keenan Wynn, Bobby Van, James Whitmore, Kurt Kasznar and Tommy Rall.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 17], [18, 22], [23, 27], [28, 34], [34, 36], [37, 44], [45, 53], [54, 61], [61, 62], [63, 70], [71, 74], [75, 78], [79, 86], [87, 91], [92, 94], [95, 101], [102, 106], [107, 110], [111, 118], [119, 126], [126, 127], [128, 137], [138, 140], [141, 144], [145, 151], [151, 152], [153, 159], [160, 164], [164, 165], [166, 171], [172, 175], [175, 176], [177, 182], [183, 191], [191, 192], [193, 197], [198, 205], [206, 209], [210, 215], [216, 220], [220, 221]]}
{"doc_key": "ai-test-378", "ner": [[17, 20, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "applications", "should", "streamline", "call", "flows", ",", "minimise", "prompts", ",", "eliminate", "unnecessary", "iterations", "and", "enable", "an", "elaborate", "mixed", "-initiative", "dialogue", "system", ",", "allowing", "callers", "to", "enter", "multiple", "pieces", "of", "information", "in", "a", "single", "statement", "and", "in", "any", "order", "or", "combination", "."], "sentence-detokenized": "These applications should streamline call flows, minimise prompts, eliminate unnecessary iterations and enable an elaborate mixed-initiative dialogue system, allowing callers to enter multiple pieces of information in a single statement and in any order or combination.", "token2charspan": [[0, 5], [6, 18], [19, 25], [26, 36], [37, 41], [42, 47], [47, 48], [49, 57], [58, 65], [65, 66], [67, 76], [77, 88], [89, 99], [100, 103], [104, 110], [111, 113], [114, 123], [124, 129], [129, 140], [141, 149], [150, 156], [156, 157], [158, 166], [167, 174], [175, 177], [178, 183], [184, 192], [193, 199], [200, 202], [203, 214], [215, 217], [218, 219], [220, 226], [227, 236], [237, 240], [241, 243], [244, 247], [248, 253], [254, 256], [257, 268], [268, 269]]}
{"doc_key": "ai-test-379", "ner": [[5, 6, "algorithm"], [9, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "this", "purpose", ",", "traditional", "gradient", "descent", "(", "or", "stochastic", "gradient", "descent", ")", "methods", "can", "be", "adapted", ",", "where", "instead", "of", "taking", "a", "step", "in", "the", "direction", "of", "the", "gradient", "of", "the", "function", ",", "a", "step", "is", "taken", "in", "the", "direction", "of", "a", "vector", "selected", "from", "the", "subgradient", "of", "the", "function", "."], "sentence-detokenized": "For this purpose, traditional gradient descent (or stochastic gradient descent) methods can be adapted, where instead of taking a step in the direction of the gradient of the function, a step is taken in the direction of a vector selected from the subgradient of the function.", "token2charspan": [[0, 3], [4, 8], [9, 16], [16, 17], [18, 29], [30, 38], [39, 46], [47, 48], [48, 50], [51, 61], [62, 70], [71, 78], [78, 79], [80, 87], [88, 91], [92, 94], [95, 102], [102, 103], [104, 109], [110, 117], [118, 120], [121, 127], [128, 129], [130, 134], [135, 137], [138, 141], [142, 151], [152, 154], [155, 158], [159, 167], [168, 170], [171, 174], [175, 183], [183, 184], [185, 186], [187, 191], [192, 194], [195, 200], [201, 203], [204, 207], [208, 217], [218, 220], [221, 222], [223, 229], [230, 238], [239, 243], [244, 247], [248, 259], [260, 262], [263, 266], [267, 275], [275, 276]]}
{"doc_key": "ai-test-380", "ner": [[8, 10, "metrics"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Assuming", "that", "the", "distortion", "is", "measured", "by", "the", "mean", "squared", "error", ",", "the", "distortion", "D", ",", "is", "given", "by", ":"], "sentence-detokenized": "Assuming that the distortion is measured by the mean squared error, the distortion D, is given by:", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 28], [29, 31], [32, 40], [41, 43], [44, 47], [48, 52], [53, 60], [61, 66], [66, 67], [68, 71], [72, 82], [83, 84], [84, 85], [86, 88], [89, 94], [95, 97], [97, 98]]}
{"doc_key": "ai-test-381", "ner": [[0, 0, "algorithm"], [4, 5, "field"], [18, 19, "task"], [21, 22, "task"], [24, 25, "task"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 4, 5, "part-of", "", false, false], [18, 19, 0, 0, "part-of", "", false, false], [21, 22, 0, 0, "part-of", "", false, false], [24, 25, 0, 0, "part-of", "", false, false], [28, 29, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["MLPs", "were", "a", "popular", "machine", "learning", "solution", "in", "the", "1980s", ",", "finding", "applications", "in", "various", "fields", "such", "as", "speech", "recognition", ",", "image", "recognition", "and", "machine", "translation", "software", ",", "neural", "networks", "."], "sentence-detokenized": "MLPs were a popular machine learning solution in the 1980s, finding applications in various fields such as speech recognition, image recognition and machine translation software, neural networks.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 19], [20, 27], [28, 36], [37, 45], [46, 48], [49, 52], [53, 58], [58, 59], [60, 67], [68, 80], [81, 83], [84, 91], [92, 98], [99, 103], [104, 106], [107, 113], [114, 125], [125, 126], [127, 132], [133, 144], [145, 148], [149, 156], [157, 168], [169, 177], [177, 178], [179, 185], [186, 194], [194, 195]]}
{"doc_key": "ai-test-382", "ner": [[0, 0, "researcher"], [1, 4, "misc"], [6, 8, "university"], [16, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 8, "physical", "", false, false], [0, 0, 6, 8, "role", "", false, false], [1, 4, 0, 0, "origin", "", false, false], [16, 18, 0, 0, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "received", "his", "PhD", "from", "the", "University", "of", "Toronto", "in", "1979", ",", "under", "the", "supervision", "of", "C.", "Raymond", "Perrault", ","], "sentence-detokenized": "Allen received his PhD from the University of Toronto in 1979, under the supervision of C. Raymond Perrault,", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 22], [23, 27], [28, 31], [32, 42], [43, 45], [46, 53], [54, 56], [57, 61], [61, 62], [63, 68], [69, 72], [73, 84], [85, 87], [88, 90], [91, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-test-383", "ner": [[0, 0, "product"], [3, 5, "field"], [9, 9, "product"], [11, 11, "product"], [13, 13, "product"], [20, 20, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 3, 5, "related-to", "supports", false, false], [9, 9, 3, 5, "type-of", "", true, false], [11, 11, 3, 5, "type-of", "", true, false], [13, 13, 3, 5, "type-of", "", true, false], [13, 13, 20, 20, "related-to", "converting_to", true, false], [24, 24, 3, 5, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["OpenCV", "supports", "some", "deep", "learning", "framework", "models", "such", "as", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "after", "converting", "them", "to", "an", "ONNX", "model", ")", "and", "Caffe", "according", "to", "a", "defined", "list", "of", "supported", "layers", "."], "sentence-detokenized": "OpenCV supports some deep learning framework models such as TensorFlow, Torch, PyTorch (after converting them to an ONNX model) and Caffe according to a defined list of supported layers.", "token2charspan": [[0, 6], [7, 15], [16, 20], [21, 25], [26, 34], [35, 44], [45, 51], [52, 56], [57, 59], [60, 70], [70, 71], [72, 77], [77, 78], [79, 86], [87, 88], [88, 93], [94, 104], [105, 109], [110, 112], [113, 115], [116, 120], [121, 126], [126, 127], [128, 131], [132, 137], [138, 147], [148, 150], [151, 152], [153, 160], [161, 165], [166, 168], [169, 178], [179, 185], [185, 186]]}
{"doc_key": "ai-test-384", "ner": [[2, 2, "researcher"], [8, 11, "organisation"], [13, 13, "organisation"], [17, 21, "organisation"], [25, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 8, 11, "role", "", false, false], [2, 2, 17, 21, "role", "", false, false], [2, 2, 25, 25, "related-to", "lectures_in", false, false], [13, 13, 8, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Previously", ",", "Christensen", "was", "founding", "president", "of", "the", "European", "Robotics", "Research", "Network", "(", "EURON", ")", "and", "an", "IEEE", "Robotics", "and", "Automation", "Society", "Distinguished", "Lecturer", "in", "Robotics", "."], "sentence-detokenized": "Previously, Christensen was founding president of the European Robotics Research Network (EURON) and an IEEE Robotics and Automation Society Distinguished Lecturer in Robotics.", "token2charspan": [[0, 10], [10, 11], [12, 23], [24, 27], [28, 36], [37, 46], [47, 49], [50, 53], [54, 62], [63, 71], [72, 80], [81, 88], [89, 90], [90, 95], [95, 96], [97, 100], [101, 103], [104, 108], [109, 117], [118, 121], [122, 132], [133, 140], [141, 154], [155, 163], [164, 166], [167, 175], [175, 176]]}
{"doc_key": "ai-test-385", "ner": [[7, 8, "field"], [10, 11, "university"], [9, 13, "location"], [15, 20, "country"], [25, 25, "misc"], [27, 27, "field"], [30, 33, "organisation"], [35, 37, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 11, 9, 13, "physical", "", false, false], [9, 13, 15, 20, "physical", "", false, false], [25, 25, 27, 27, "topic", "", false, false], [30, 33, 35, 37, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "received", "his", "master", "'s", "degree", "in", "mathematics", "from", "Samarkand", "State", "University", ",", "Samarkand", ",", "Uzbek", "Soviet", "Socialist", "Republic", ",", "in", "1958", ",", "and", "his", "doctorate", "in", "statistics", "from", "the", "Institute", "of", "Control", "Sciences", ",", "Moscow", ",", "in", "1964", "."], "sentence-detokenized": "He received his master's degree in mathematics from Samarkand State University, Samarkand, Uzbek Soviet Socialist Republic, in 1958, and his doctorate in statistics from the Institute of Control Sciences, Moscow, in 1964.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 22], [22, 24], [25, 31], [32, 34], [35, 46], [47, 51], [52, 61], [62, 67], [68, 78], [78, 79], [80, 89], [89, 90], [91, 96], [97, 103], [104, 113], [114, 122], [122, 123], [124, 126], [127, 131], [131, 132], [133, 136], [137, 140], [141, 150], [151, 153], [154, 164], [165, 169], [170, 173], [174, 183], [184, 186], [187, 194], [195, 203], [203, 204], [205, 211], [211, 212], [213, 215], [216, 220], [220, 221]]}
{"doc_key": "ai-test-386", "ner": [[0, 2, "organisation"], [10, 12, "product"], [32, 33, "field"], [35, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 32, 33, "usage", "", false, false], [0, 2, 35, 37, "usage", "", false, false], [10, 12, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["However", ",", "Cycorp", "'s", "work", "is", "increasingly", "about", "giving", "the", "Cyc", "system", "the", "ability", "to", "communicate", "with", "end-users", "in", "natural", "language", ",", "and", "to", "assist", "in", "the", "ongoing", "knowledge", "formation", "process", "through", "machine", "learning", "and", "natural", "language", "understanding", "."], "sentence-detokenized": "However, Cycorp's work is increasingly about giving the Cyc system the ability to communicate with end-users in natural language, and to assist in the ongoing knowledge formation process through machine learning and natural language understanding.", "token2charspan": [[0, 7], [7, 8], [9, 15], [15, 17], [18, 22], [23, 25], [26, 38], [39, 44], [45, 51], [52, 55], [56, 59], [60, 66], [67, 70], [71, 78], [79, 81], [82, 93], [94, 98], [99, 108], [109, 111], [112, 119], [120, 128], [128, 129], [130, 133], [134, 136], [137, 143], [144, 146], [147, 150], [151, 158], [159, 168], [169, 178], [179, 186], [187, 194], [195, 202], [203, 211], [212, 215], [216, 223], [224, 232], [233, 246], [246, 247]]}
{"doc_key": "ai-test-387", "ner": [[58, 58, "metrics"], [60, 60, "metrics"], [62, 62, "metrics"], [64, 65, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "if", "the", "most", "suitable", "classifier", "for", "the", "problem", "is", "sought", ",", "the", "training", "dataset", "is", "used", "to", "train", "the", "candidate", "algorithms", ",", "the", "validation", "dataset", "is", "used", "to", "compare", "their", "performances", "and", "decide", "which", "one", "to", "stick", "with", ",", "and", "finally", ",", "the", "test", "dataset", "is", "used", "to", "obtain", "the", "performance", "characteristics", ",", "such", "as", "accuracy", ",", "sensitivity", ",", "specificity", ",", "F-", "measure", ",", "etc", "."], "sentence-detokenized": "For example, if the most suitable classifier for the problem is sought, the training dataset is used to train the candidate algorithms, the validation dataset is used to compare their performances and decide which one to stick with, and finally, the test dataset is used to obtain the performance characteristics, such as accuracy, sensitivity, specificity, F-measure, etc.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 19], [20, 24], [25, 33], [34, 44], [45, 48], [49, 52], [53, 60], [61, 63], [64, 70], [70, 71], [72, 75], [76, 84], [85, 92], [93, 95], [96, 100], [101, 103], [104, 109], [110, 113], [114, 123], [124, 134], [134, 135], [136, 139], [140, 150], [151, 158], [159, 161], [162, 166], [167, 169], [170, 177], [178, 183], [184, 196], [197, 200], [201, 207], [208, 213], [214, 217], [218, 220], [221, 226], [227, 231], [231, 232], [233, 236], [237, 244], [244, 245], [246, 249], [250, 254], [255, 262], [263, 265], [266, 270], [271, 273], [274, 280], [281, 284], [285, 296], [297, 312], [312, 313], [314, 318], [319, 321], [322, 330], [330, 331], [332, 343], [343, 344], [345, 356], [356, 357], [358, 360], [360, 367], [367, 368], [369, 372], [372, 373]]}
{"doc_key": "ai-test-388", "ner": [[1, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "root", "mean", "squared", "error", "is", "0.15", "."], "sentence-detokenized": "The root mean squared error is 0.15.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 21], [22, 27], [28, 30], [31, 35], [35, 36]]}
{"doc_key": "ai-test-389", "ner": [[7, 8, "misc"], [4, 4, "organisation"], [13, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 7, 8, "role", "", false, false], [13, 13, 7, 8, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1979", ",", "the", "IEEE", "organised", "a", "Micromouse", "competition", ",", "as", "featured", "in", "Spectrum", "magazine", "."], "sentence-detokenized": "In 1979, the IEEE organised a Micromouse competition, as featured in Spectrum magazine.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 27], [28, 29], [30, 40], [41, 52], [52, 53], [54, 56], [57, 65], [66, 68], [69, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-390", "ner": [[1, 2, "algorithm"], [7, 11, "field"], [12, 14, "task"], [16, 17, "task"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 7, 11, "part-of", "", false, false], [12, 14, 7, 11, "part-of", "task_part_of_field", false, false], [16, 17, 7, 11, "part-of", "task_part_of_field", false, false], [19, 20, 7, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Gabor", "space", "is", "very", "useful", "in", "image", "processing", "applications", "such", "as", "optical", "character", "recognition", ",", "iris", "recognition", "and", "fingerprint", "recognition", "."], "sentence-detokenized": "The Gabor space is very useful in image processing applications such as optical character recognition, iris recognition and fingerprint recognition.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 18], [19, 23], [24, 30], [31, 33], [34, 39], [40, 50], [51, 63], [64, 68], [69, 71], [72, 79], [80, 89], [90, 101], [101, 102], [103, 107], [108, 119], [120, 123], [124, 135], [136, 147], [147, 148]]}
{"doc_key": "ai-test-391", "ner": [[7, 7, "programlang"], [9, 9, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", "through", "high", "-", "level", "interfaces", "with", "Java", "and", "Tcl", "."], "sentence-detokenized": "or through high-level interfaces with Java and Tcl.", "token2charspan": [[0, 2], [3, 10], [11, 15], [15, 16], [16, 21], [22, 32], [33, 37], [38, 42], [43, 46], [47, 50], [50, 51]]}
{"doc_key": "ai-test-392", "ner": [[11, 13, "algorithm"], [18, 18, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 13, 18, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "recent", "research", ",", "kernel", "-", "based", "methods", ",", "such", "as", "support", "vector", "machines", ",", "have", "shown", "superior", "monitoring", "performance", "."], "sentence-detokenized": "In recent research, kernel-based methods, such as support vector machines, have shown superior monitoring performance.", "token2charspan": [[0, 2], [3, 9], [10, 18], [18, 19], [20, 26], [26, 27], [27, 32], [33, 40], [40, 41], [42, 46], [47, 49], [50, 57], [58, 64], [65, 73], [73, 74], [75, 79], [80, 85], [86, 94], [95, 105], [106, 117], [117, 118]]}
{"doc_key": "ai-test-393", "ner": [[14, 14, "misc"], [23, 23, "researcher"], [25, 25, "researcher"], [34, 34, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 34, 34, "usage", "", false, false], [25, 25, 34, 34, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["To", "illustrate", "the", "basic", "principles", "of", "pocketing", ",", "an", "analysis", "of", "the", "relationship", "between", "ozone", "and", "temperature", "is", "presented", "below", "(", "data", "from", "Rousseeuw", "and", "Leroy", "(", "1986", ")", ",", "analysis", "carried", "out", "in", "R", ")", "."], "sentence-detokenized": "To illustrate the basic principles of pocketing, an analysis of the relationship between ozone and temperature is presented below (data from Rousseeuw and Leroy (1986), analysis carried out in R).", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 23], [24, 34], [35, 37], [38, 47], [47, 48], [49, 51], [52, 60], [61, 63], [64, 67], [68, 80], [81, 88], [89, 94], [95, 98], [99, 110], [111, 113], [114, 123], [124, 129], [130, 131], [131, 135], [136, 140], [141, 150], [151, 154], [155, 160], [161, 162], [162, 166], [166, 167], [167, 168], [169, 177], [178, 185], [186, 189], [190, 192], [193, 194], [194, 195], [195, 196]]}
{"doc_key": "ai-test-394", "ner": [[0, 1, "organisation"], [11, 11, "product"], [18, 18, "product"], [21, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 0, 1, "artifact", "", false, false], [18, 18, 0, 1, "artifact", "", false, false], [21, 23, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Denso", "Wave", "is", "a", "subsidiary", "that", "manufactures", "automatic", "identification", "products", "(", "barcode", "readers", "and", "related", "products", ")", ",", "industrial", "robots", "and", "programmable", "logic", "controllers", "."], "sentence-detokenized": "Denso Wave is a subsidiary that manufactures automatic identification products (barcode readers and related products), industrial robots and programmable logic controllers.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 15], [16, 26], [27, 31], [32, 44], [45, 54], [55, 69], [70, 78], [79, 80], [80, 87], [88, 95], [96, 99], [100, 107], [108, 116], [116, 117], [117, 118], [119, 129], [130, 136], [137, 140], [141, 153], [154, 159], [160, 171], [171, 172]]}
{"doc_key": "ai-test-395", "ner": [[1, 4, "metrics"], [7, 9, "metrics"], [21, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 4, 21, 21, "compare", "", false, false], [7, 9, 1, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["While", "the", "bilingual", "evaluation", "study", "merely", "calculates", "the", "accuracy", "of", "the", "ngranes", "by", "adding", "equal", "weight", "to", "each", "of", "them", ",", "NIST", "also", "calculates", "the", "degree", "of", "information", "of", "a", "particular", "ngran", "."], "sentence-detokenized": "While the bilingual evaluation study merely calculates the accuracy of the ngranes by adding equal weight to each of them, NIST also calculates the degree of information of a particular ngran.", "token2charspan": [[0, 5], [6, 9], [10, 19], [20, 30], [31, 36], [37, 43], [44, 54], [55, 58], [59, 67], [68, 70], [71, 74], [75, 82], [83, 85], [86, 92], [93, 98], [99, 105], [106, 108], [109, 113], [114, 116], [117, 121], [121, 122], [123, 127], [128, 132], [133, 143], [144, 147], [148, 154], [155, 157], [158, 169], [170, 172], [173, 174], [175, 185], [186, 191], [191, 192]]}
{"doc_key": "ai-test-396", "ner": [[18, 18, "algorithm"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "particular", ",", "they", "are", "used", "during", "the", "calculation", "of", "the", "likelihood", "of", "a", "tree", "(", "in", "the", "Bayesian", "and", "maximum", "likelihood", "approaches", "to", "tree", "estimation", ")", "and", "are", "used", "to", "estimate", "the", "evolutionary", "distance", "between", "sequences", "from", "the", "observed", "differences", "between", "sequences", "."], "sentence-detokenized": "In particular, they are used during the calculation of the likelihood of a tree (in the Bayesian and maximum likelihood approaches to tree estimation) and are used to estimate the evolutionary distance between sequences from the observed differences between sequences.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 19], [20, 23], [24, 28], [29, 35], [36, 39], [40, 51], [52, 54], [55, 58], [59, 69], [70, 72], [73, 74], [75, 79], [80, 81], [81, 83], [84, 87], [88, 96], [97, 100], [101, 108], [109, 119], [120, 130], [131, 133], [134, 138], [139, 149], [149, 150], [151, 154], [155, 158], [159, 163], [164, 166], [167, 175], [176, 179], [180, 192], [193, 201], [202, 209], [210, 219], [220, 224], [225, 228], [229, 237], [238, 249], [250, 257], [258, 267], [267, 268]]}
{"doc_key": "ai-test-397", "ner": [[1, 3, "conference"], [20, 21, "misc"], [23, 23, "misc"], [46, 47, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 20, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Audio", "Engineering", "Society", "recommends", "a", "sampling", "frequency", "of", "48", "kHz", "for", "most", "applications", ",", "but", "recognises", "44.1", "kHz", "for", "compact", "discs", "(", "CDs", ")", "and", "other", "consumer", "uses", ",", "32", "kHz", "for", "broadcast", "-", "related", "applications", ",", "and", "96", "kHz", "for", "higher", "bandwidth", "or", "relaxed", "anti-aliasing", "filtering", "."], "sentence-detokenized": "The Audio Engineering Society recommends a sampling frequency of 48 kHz for most applications, but recognises 44.1 kHz for compact discs (CDs) and other consumer uses, 32 kHz for broadcast-related applications, and 96 kHz for higher bandwidth or relaxed anti-aliasing filtering.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 29], [30, 40], [41, 42], [43, 51], [52, 61], [62, 64], [65, 67], [68, 71], [72, 75], [76, 80], [81, 93], [93, 94], [95, 98], [99, 109], [110, 114], [115, 118], [119, 122], [123, 130], [131, 136], [137, 138], [138, 141], [141, 142], [143, 146], [147, 152], [153, 161], [162, 166], [166, 167], [168, 170], [171, 174], [175, 178], [179, 188], [188, 189], [189, 196], [197, 209], [209, 210], [211, 214], [215, 217], [218, 221], [222, 225], [226, 232], [233, 242], [243, 245], [246, 253], [254, 267], [268, 277], [277, 278]]}
{"doc_key": "ai-test-398", "ner": [[9, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Word", "and", "concept", "affectivity", "resources", "have", "been", "developed", "for", "WordNet", "{", "{", "cite", "journal"], "sentence-detokenized": "Word and concept affectivity resources have been developed for WordNet {{cite journal", "token2charspan": [[0, 4], [5, 8], [9, 16], [17, 28], [29, 38], [39, 43], [44, 48], [49, 58], [59, 62], [63, 70], [71, 72], [72, 73], [73, 77], [78, 85]]}
{"doc_key": "ai-test-399", "ner": [[1, 3, "misc"], [22, 23, "person"], [28, 31, "person"], [36, 38, "person"], [44, 47, "organisation"], [66, 67, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[28, 31, 36, 38, "role", "acts_in", false, false], [44, 47, 36, 38, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "red", "-green", "anaglyph", ",", "the", "audience", "was", "presented", "with", "three", "test", "reels", ",", "which", "included", "rural", "scenes", ",", "test", "shots", "of", "Marie", "Doro", ",", "a", "segment", "of", "John", "B", ".", "Mason", "performing", "various", "passages", "from", "Jim", "the", "Penman", "(", "a", "film", "released", "by", "Famous", "Players", "-", "Lasky", "that", "year", ",", "but", "not", "in", "3D", ")", ",", "oriental", "dancers", ",", "and", "a", "reel", "of", "images", "of", "Niagara", "Falls", "."], "sentence-detokenized": "In red-green anaglyph, the audience was presented with three test reels, which included rural scenes, test shots of Marie Doro, a segment of John B. Mason performing various passages from Jim the Penman (a film released by Famous Players-Lasky that year, but not in 3D), oriental dancers, and a reel of images of Niagara Falls.", "token2charspan": [[0, 2], [3, 6], [6, 12], [13, 21], [21, 22], [23, 26], [27, 35], [36, 39], [40, 49], [50, 54], [55, 60], [61, 65], [66, 71], [71, 72], [73, 78], [79, 87], [88, 93], [94, 100], [100, 101], [102, 106], [107, 112], [113, 115], [116, 121], [122, 126], [126, 127], [128, 129], [130, 137], [138, 140], [141, 145], [146, 147], [147, 148], [149, 154], [155, 165], [166, 173], [174, 182], [183, 187], [188, 191], [192, 195], [196, 202], [203, 204], [204, 205], [206, 210], [211, 219], [220, 222], [223, 229], [230, 237], [237, 238], [238, 243], [244, 248], [249, 253], [253, 254], [255, 258], [259, 262], [263, 265], [266, 268], [268, 269], [269, 270], [271, 279], [280, 287], [287, 288], [289, 292], [293, 294], [295, 299], [300, 302], [303, 309], [310, 312], [313, 320], [321, 326], [326, 327]]}
{"doc_key": "ai-test-400", "ner": [[7, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "particular", "way", "of", "implementing", "maximum", "likelihood", "estimation", "for", "this", "problem", "."], "sentence-detokenized": "This is a particular way of implementing maximum likelihood estimation for this problem.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 20], [21, 24], [25, 27], [28, 40], [41, 48], [49, 59], [60, 70], [71, 74], [75, 79], [80, 87], [87, 88]]}
{"doc_key": "ai-test-401", "ner": [[0, 3, "product"], [12, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Easily", "crawlable", "web", "servers", ",", "and", "integrates", "the", "features", "of", "sitemaps", "and", "RSS", "feeds", "into", "a", "decentralised", "mechanism", "for", "computational", "biologists", "and", "bioinformaticians", "to", "openly", "disseminate", "and", "retrieve", "metadata", "on", "biomedical", "resources", "."], "sentence-detokenized": "Easily crawlable web servers, and integrates the features of sitemaps and RSS feeds into a decentralised mechanism for computational biologists and bioinformaticians to openly disseminate and retrieve metadata on biomedical resources.", "token2charspan": [[0, 6], [7, 16], [17, 20], [21, 28], [28, 29], [30, 33], [34, 44], [45, 48], [49, 57], [58, 60], [61, 69], [70, 73], [74, 77], [78, 83], [84, 88], [89, 90], [91, 104], [105, 114], [115, 118], [119, 132], [133, 143], [144, 147], [148, 165], [166, 168], [169, 175], [176, 187], [188, 191], [192, 200], [201, 209], [210, 212], [213, 223], [224, 233], [233, 234]]}
{"doc_key": "ai-test-402", "ner": [[4, 12, "misc"], [15, 20, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "covered", "by", "the", "American", "National", "Standards", "Institute", "/", "NISO", "standard", "Z39.50", ",", "and", "the", "International", "Standards", "Organisation", "standard", "23950", "."], "sentence-detokenized": "It is covered by the American National Standards Institute / NISO standard Z39.50, and the International Standards Organisation standard 23950.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 20], [21, 29], [30, 38], [39, 48], [49, 58], [59, 60], [61, 65], [66, 74], [75, 81], [81, 82], [83, 86], [87, 90], [91, 104], [105, 114], [115, 127], [128, 136], [137, 142], [142, 143]]}
{"doc_key": "ai-test-403", "ner": [[16, 16, "misc"], [23, 24, "metrics"], [28, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "encoder", "and", "decoder", "are", "trained", "to", "take", "a", "sentence", "and", "reproduce", "the", "one", "-", "shot", "distribution", "of", "a", "corresponding", "paraphrase", "by", "minimising", "the", "perplexity", "through", "a", "simple", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The encoder and decoder are trained to take a sentence and reproduce the one-shot distribution of a corresponding paraphrase by minimising the perplexity through a simple stochastic gradient descent.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 27], [28, 35], [36, 38], [39, 43], [44, 45], [46, 54], [55, 58], [59, 68], [69, 72], [73, 76], [76, 77], [77, 81], [82, 94], [95, 97], [98, 99], [100, 113], [114, 124], [125, 127], [128, 138], [139, 142], [143, 153], [154, 161], [162, 163], [164, 170], [171, 181], [182, 190], [191, 198], [198, 199]]}
{"doc_key": "ai-test-404", "ner": [[4, 5, "field"], [8, 10, "task"], [12, 17, "task"], [28, 33, "task"], [35, 40, "task"], [42, 48, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 10, 4, 5, "part-of", "task_part_of_field", false, false], [12, 17, 4, 5, "part-of", "task_part_of_field", false, false], [28, 33, 4, 5, "part-of", "task_part_of_field", false, false], [35, 40, 4, 5, "part-of", "task_part_of_field", false, false], [42, 48, 4, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "typical", "applications", "of", "pattern", "recognition", "techniques", "are", "automatic", "speech", "recognition", ",", "classification", "of", "text", "into", "various", "categories", "(", "e.g.", "spam", "/", "non", "-spam", "e-mail", "messages", ")", ",", "recognition", "of", "handwriting", "on", "postal", "envelopes", ",", "automatic", "image", "recognition", "of", "human", "faces", "or", "extraction", "of", "handwriting", "images", "from", "medical", "forms", "."], "sentence-detokenized": "Other typical applications of pattern recognition techniques are automatic speech recognition, classification of text into various categories (e.g. spam/non-spam e-mail messages), recognition of handwriting on postal envelopes, automatic image recognition of human faces or extraction of handwriting images from medical forms.", "token2charspan": [[0, 5], [6, 13], [14, 26], [27, 29], [30, 37], [38, 49], [50, 60], [61, 64], [65, 74], [75, 81], [82, 93], [93, 94], [95, 109], [110, 112], [113, 117], [118, 122], [123, 130], [131, 141], [142, 143], [143, 147], [148, 152], [152, 153], [153, 156], [156, 161], [162, 168], [169, 177], [177, 178], [178, 179], [180, 191], [192, 194], [195, 206], [207, 209], [210, 216], [217, 226], [226, 227], [228, 237], [238, 243], [244, 255], [256, 258], [259, 264], [265, 270], [271, 273], [274, 284], [285, 287], [288, 299], [300, 306], [307, 311], [312, 319], [320, 325], [325, 326]]}
{"doc_key": "ai-test-405", "ner": [[0, 2, "algorithm"], [14, 15, "field"], [17, 18, "task"], [20, 21, "task"], [23, 25, "task"], [27, 30, "task"], [33, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 15, 0, 2, "usage", "", false, false], [17, 18, 0, 2, "usage", "", false, false], [20, 21, 0, 2, "usage", "", false, false], [23, 25, 0, 2, "usage", "", false, false], [27, 30, 0, 2, "usage", "", false, false], [33, 34, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Artificial", "neural", "networks", "have", "been", "used", "in", "a", "variety", "of", "tasks", ",", "such", "as", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "board", "and", "video", "games", ",", "and", "medical", "diagnosis", "."], "sentence-detokenized": "Artificial neural networks have been used in a variety of tasks, such as computer vision, speech recognition, machine translation, social network filtering, board and video games, and medical diagnosis.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 31], [32, 36], [37, 41], [42, 44], [45, 46], [47, 54], [55, 57], [58, 63], [63, 64], [65, 69], [70, 72], [73, 81], [82, 88], [88, 89], [90, 96], [97, 108], [108, 109], [110, 117], [118, 129], [129, 130], [131, 137], [138, 145], [146, 155], [155, 156], [157, 162], [163, 166], [167, 172], [173, 178], [178, 179], [180, 183], [184, 191], [192, 201], [201, 202]]}
{"doc_key": "ai-test-406", "ner": [[2, 3, "organisation"], [4, 4, "product"], [14, 14, "product"], [18, 18, "organisation"], [19, 20, "product"], [22, 22, "product"], [24, 26, "product"], [28, 28, "product"], [30, 30, "programlang"], [38, 39, "field"], [44, 48, "product"], [49, 49, "algorithm"], [51, 51, "algorithm"], [53, 54, "algorithm"], [57, 57, "product"], [64, 65, "task"], [71, 72, "algorithm"], [76, 76, "product"], [78, 78, "product"], [80, 82, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "relations": [[4, 4, 2, 3, "origin", "", false, false], [4, 4, 14, 14, "named", "same", false, false], [4, 4, 44, 48, "named", "same", false, false], [30, 30, 38, 39, "related-to", "used_for", false, false], [49, 49, 30, 30, "part-of", "", true, false], [49, 49, 44, 48, "origin", "", true, false], [51, 51, 30, 30, "part-of", "", true, false], [51, 51, 44, 48, "origin", "", true, false], [53, 54, 30, 30, "part-of", "", true, false], [53, 54, 44, 48, "origin", "", true, false], [57, 57, 64, 65, "related-to", "used_for", false, false], [71, 72, 57, 57, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Examples", "are", "Salford", "Systems", "CART", "(", "which", "has", "licensed", "proprietary", "code", "from", "the", "original", "CART", "authors", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "an", "open", "source", "software", "environment", "for", "statistical", "computing", ",", "which", "includes", "several", "CART", "implementations", "such", "as", "the", "rpart", ",", "party", "and", "randomForest", "packages", ")", ",", "Weka", "(", "a", "free", "and", "open", "source", "data", "mining", "suite", ",", "which", "contains", "many", "decision", "tree", "algorithms", ")", ",", "Orange", ",", "KNIME", ",", "Microsoft", "SQL", "Server", "programming", "language", ")", "."], "sentence-detokenized": "Examples are Salford Systems CART (which has licensed proprietary code from the original CART authors), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (an open source software environment for statistical computing, which includes several CART implementations such as the rpart, party and randomForest packages), Weka (a free and open source data mining suite, which contains many decision tree algorithms), Orange, KNIME, Microsoft SQL Server programming language).", "token2charspan": [[0, 8], [9, 12], [13, 20], [21, 28], [29, 33], [34, 35], [35, 40], [41, 44], [45, 53], [54, 65], [66, 70], [71, 75], [76, 79], [80, 88], [89, 93], [94, 101], [101, 102], [102, 103], [104, 107], [108, 112], [113, 120], [120, 121], [122, 132], [132, 133], [134, 137], [138, 148], [149, 154], [154, 155], [156, 162], [162, 163], [164, 165], [166, 167], [167, 169], [170, 174], [175, 181], [182, 190], [191, 202], [203, 206], [207, 218], [219, 228], [228, 229], [230, 235], [236, 244], [245, 252], [253, 257], [258, 273], [274, 278], [279, 281], [282, 285], [286, 291], [291, 292], [293, 298], [299, 302], [303, 315], [316, 324], [324, 325], [325, 326], [327, 331], [332, 333], [333, 334], [335, 339], [340, 343], [344, 348], [349, 355], [356, 360], [361, 367], [368, 373], [373, 374], [375, 380], [381, 389], [390, 394], [395, 403], [404, 408], [409, 419], [419, 420], [420, 421], [422, 428], [428, 429], [430, 435], [435, 436], [437, 446], [447, 450], [451, 457], [458, 469], [470, 478], [478, 479], [479, 480]]}
{"doc_key": "ai-test-407", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [10, 11, "researcher"], [13, 14, "university"], [16, 17, "researcher"], [19, 22, "organisation"], [24, 24, "organisation"], [32, 34, "researcher"], [36, 38, "researcher"], [40, 43, "organisation"], [54, 57, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 10, 11, "origin", "", false, false], [0, 2, 16, 17, "origin", "", false, false], [0, 2, 32, 34, "origin", "", false, false], [0, 2, 36, 38, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [10, 11, 13, 14, "physical", "", false, false], [10, 11, 13, 14, "role", "", false, false], [16, 17, 19, 22, "physical", "", false, false], [16, 17, 19, 22, "role", "", false, false], [24, 24, 19, 22, "named", "", false, false], [32, 34, 40, 43, "physical", "", false, false], [32, 34, 40, 43, "role", "", false, false], [36, 38, 40, 43, "physical", "", false, false], [36, 38, 40, 43, "role", "", false, false], [54, 57, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", "was", "first", "developed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", ",", "and", "later", "by", "Bishnu", "S.", "Atal", "and", "Manfred", "R.", "Schroeder", "of", "Bell", "Laboratories", "in", "the", "early", "and", "mid-1970s", ",", "becoming", "the", "basis", "for", "the", "first", "speech", "synthesiser", "DSP", "chips", "in", "the", "late", "1970s", "."], "sentence-detokenized": "Linear predictive coding (LPC) was first developed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966, and later by Bishnu S. Atal and Manfred R. Schroeder of Bell Laboratories in the early and mid-1970s, becoming the basis for the first speech synthesiser DSP chips in the late 1970s.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [31, 34], [35, 40], [41, 50], [51, 53], [54, 62], [63, 70], [71, 73], [74, 80], [81, 91], [92, 95], [96, 101], [102, 107], [108, 110], [111, 117], [118, 127], [128, 131], [132, 141], [142, 143], [143, 146], [146, 147], [148, 150], [151, 155], [155, 156], [157, 160], [161, 166], [167, 169], [170, 176], [177, 179], [180, 184], [185, 188], [189, 196], [197, 199], [200, 209], [210, 212], [213, 217], [218, 230], [231, 233], [234, 237], [238, 243], [244, 247], [248, 257], [257, 258], [259, 267], [268, 271], [272, 277], [278, 281], [282, 285], [286, 291], [292, 298], [299, 310], [311, 314], [315, 320], [321, 323], [324, 327], [328, 332], [333, 338], [338, 339]]}
{"doc_key": "ai-test-408", "ner": [[0, 3, "metrics"], [8, 8, "metrics"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 0, 3, "part-of", "", false, false], [10, 10, 0, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "F", "-", "score", "is", "a", "combination", "of", "accuracy", "and", "recovery", ",", "which", "provides", "a", "single", "score", "."], "sentence-detokenized": "The F-score is a combination of accuracy and recovery, which provides a single score.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 16], [17, 28], [29, 31], [32, 40], [41, 44], [45, 53], [53, 54], [55, 60], [61, 69], [70, 71], [72, 78], [79, 84], [84, 85]]}
{"doc_key": "ai-test-409", "ner": [[0, 1, "field"], [8, 10, "task"], [15, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 0, 1, "part-of", "task_part_of_field", false, false], [15, 18, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Image", "analysis", "tasks", "can", "be", "as", "simple", "as", "reading", "barcode", "labels", "or", "as", "sophisticated", "as", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Image analysis tasks can be as simple as reading barcode labels or as sophisticated as a facial recognition system.", "token2charspan": [[0, 5], [6, 14], [15, 20], [21, 24], [25, 27], [28, 30], [31, 37], [38, 40], [41, 48], [49, 56], [57, 63], [64, 66], [67, 69], [70, 83], [84, 86], [87, 88], [89, 95], [96, 107], [108, 114], [114, 115]]}
{"doc_key": "ai-test-410", "ner": [[5, 7, "algorithm"], [25, 26, "algorithm"], [33, 35, "algorithm"], [39, 39, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[33, 35, 25, 26, "type-of", "", false, false], [39, 39, 33, 35, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "special", "case", "of", "linear", "support", "vector", "machines", "can", "be", "most", "efficiently", "solved", "by", "the", "same", "kind", "of", "algorithms", "for", "optimising", "their", "close", "cousin", ",", "logistic", "regression", ";", "this", "class", "of", "algorithms", "includes", "stochastic", "gradient", "descent", "(", "e.g.", ",", "PEGASOS", ")", "."], "sentence-detokenized": "The special case of linear support vector machines can be most efficiently solved by the same kind of algorithms for optimising their close cousin, logistic regression; this class of algorithms includes stochastic gradient descent (e.g., PEGASOS).", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 19], [20, 26], [27, 34], [35, 41], [42, 50], [51, 54], [55, 57], [58, 62], [63, 74], [75, 81], [82, 84], [85, 88], [89, 93], [94, 98], [99, 101], [102, 112], [113, 116], [117, 127], [128, 133], [134, 139], [140, 146], [146, 147], [148, 156], [157, 167], [167, 168], [169, 173], [174, 179], [180, 182], [183, 193], [194, 202], [203, 213], [214, 222], [223, 230], [231, 232], [232, 236], [236, 237], [238, 245], [245, 246], [246, 247]]}
{"doc_key": "ai-test-411", "ner": [[1, 1, "product"], [28, 28, "product"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "Siri", "is", "asked", "\"", "Do", "you", "have", "a", "pet", "?", "\"", "on", "an", "iOS", "device", ",", "one", "of", "the", "answers", "is", "\"", "I", "used", "to", "have", "an", "AIBO", "."], "sentence-detokenized": "When Siri is asked \"Do you have a pet?\" on an iOS device, one of the answers is \"I used to have an AIBO.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 18], [19, 20], [20, 22], [23, 26], [27, 31], [32, 33], [34, 37], [37, 38], [38, 39], [40, 42], [43, 45], [46, 49], [50, 56], [56, 57], [58, 61], [62, 64], [65, 68], [69, 76], [77, 79], [80, 81], [81, 82], [83, 87], [88, 90], [91, 95], [96, 98], [99, 103], [103, 104]]}
{"doc_key": "ai-test-412", "ner": [[1, 2, "task"], [4, 6, "metrics"], [9, 9, "metrics"], [12, 13, "metrics"], [15, 15, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 1, 2, "part-of", "", false, false], [9, 9, 4, 6, "named", "", false, false], [12, 13, 1, 2, "part-of", "", false, false], [15, 15, 12, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "information", "retrieval", ",", "positive", "predictive", "value", "is", "called", "precision", ",", "and", "sensitivity", "is", "called", "recall", "."], "sentence-detokenized": "In information retrieval, positive predictive value is called precision, and sensitivity is called recall.", "token2charspan": [[0, 2], [3, 14], [15, 24], [24, 25], [26, 34], [35, 45], [46, 51], [52, 54], [55, 61], [62, 71], [71, 72], [73, 76], [77, 88], [89, 91], [92, 98], [99, 105], [105, 106]]}
{"doc_key": "ai-test-413", "ner": [[10, 11, "field"], [13, 13, "task"], [15, 15, "task"], [17, 18, "task"], [33, 34, "task"], [36, 37, "task"], [39, 43, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 13, 10, 11, "part-of", "task_part_of_field", false, false], [15, 15, 10, 11, "part-of", "task_part_of_field", false, false], [17, 18, 10, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "particular", ",", "his", "research", "focused", "on", "areas", "such", "as", "text", "mining", "(", "extraction", ",", "categorisation", ",", "novelty", "detection", ")", "and", "new", "theoretical", "frameworks", "such", "as", "a", "unified", "utility", "-", "based", "theory", "linking", "information", "retrieval", ",", "automatic", "summarisation", ",", "free", "-", "text", "question", "answering", "and", "related", "tasks", "."], "sentence-detokenized": "In particular, his research focused on areas such as text mining (extraction, categorisation, novelty detection) and new theoretical frameworks such as a unified utility-based theory linking information retrieval, automatic summarisation, free-text question answering and related tasks.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 27], [28, 35], [36, 38], [39, 44], [45, 49], [50, 52], [53, 57], [58, 64], [65, 66], [66, 76], [76, 77], [78, 92], [92, 93], [94, 101], [102, 111], [111, 112], [113, 116], [117, 120], [121, 132], [133, 143], [144, 148], [149, 151], [152, 153], [154, 161], [162, 169], [169, 170], [170, 175], [176, 182], [183, 190], [191, 202], [203, 212], [212, 213], [214, 223], [224, 237], [237, 238], [239, 243], [243, 244], [244, 248], [249, 257], [258, 267], [268, 271], [272, 279], [280, 285], [285, 286]]}
{"doc_key": "ai-test-414", "ner": [[6, 7, "product"], [15, 18, "misc"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Delta", "robots", "have", "base", "-", "mounted", "rotary", "actuators", "that", "move", "a", "lightweight", ",", "rigid", ",", "parallelogram", "-", "shaped", "arm", "."], "sentence-detokenized": "Delta robots have base-mounted rotary actuators that move a lightweight, rigid, parallelogram-shaped arm.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 22], [22, 23], [23, 30], [31, 37], [38, 47], [48, 52], [53, 57], [58, 59], [60, 71], [71, 72], [73, 78], [78, 79], [80, 93], [93, 94], [94, 100], [101, 104], [104, 105]]}
{"doc_key": "ai-test-415", "ner": [[8, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "outcomes", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", ",", "as", "follows", ":"], "sentence-detokenized": "The four outcomes can be formulated in a 2 \u00d7 2 contingency table or confusion matrix, as follows:", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 24], [25, 35], [36, 38], [39, 40], [41, 42], [43, 44], [45, 46], [47, 58], [59, 64], [65, 67], [68, 77], [78, 84], [84, 85], [86, 88], [89, 96], [96, 97]]}
{"doc_key": "ai-test-416", "ner": [[4, 5, "field"], [31, 32, "task"], [38, 39, "task"], [44, 46, "task"], [48, 50, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[31, 32, 4, 5, "part-of", "task_part_of_field", false, false], [38, 39, 4, 5, "part-of", "task_part_of_field", false, false], [44, 46, 4, 5, "part-of", "task_part_of_field", false, false], [48, 50, 4, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "actual", "task", "of", "data", "mining", "is", "the", "semi-automatic", "or", "automatic", "analysis", "of", "large", "amounts", "of", "data", "to", "extract", "unknown", "and", "interesting", "patterns", ",", "such", "as", "groups", "of", "data", "records", "(", "cluster", "analysis", ")", ",", "unusual", "records", "(", "anomaly", "detection", ")", "and", "dependencies", "(", "association", "rule", "mining", ",", "sequential", "pattern", "mining", ")", "."], "sentence-detokenized": "The actual task of data mining is the semi-automatic or automatic analysis of large amounts of data to extract unknown and interesting patterns, such as groups of data records (cluster analysis), unusual records (anomaly detection) and dependencies (association rule mining, sequential pattern mining).", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 18], [19, 23], [24, 30], [31, 33], [34, 37], [38, 52], [53, 55], [56, 65], [66, 74], [75, 77], [78, 83], [84, 91], [92, 94], [95, 99], [100, 102], [103, 110], [111, 118], [119, 122], [123, 134], [135, 143], [143, 144], [145, 149], [150, 152], [153, 159], [160, 162], [163, 167], [168, 175], [176, 177], [177, 184], [185, 193], [193, 194], [194, 195], [196, 203], [204, 211], [212, 213], [213, 220], [221, 230], [230, 231], [232, 235], [236, 248], [249, 250], [250, 261], [262, 266], [267, 273], [273, 274], [275, 285], [286, 293], [294, 300], [300, 301], [301, 302]]}
{"doc_key": "ai-test-417", "ner": [[2, 3, "product"], [5, 6, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 5, 6, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "a", "recommender", "system", ",", "sentiment", "analysis", "has", "proven", "to", "be", "a", "valuable", "technique", "."], "sentence-detokenized": "For a recommender system, sentiment analysis has proven to be a valuable technique.", "token2charspan": [[0, 3], [4, 5], [6, 17], [18, 24], [24, 25], [26, 35], [36, 44], [45, 48], [49, 55], [56, 58], [59, 61], [62, 63], [64, 72], [73, 82], [82, 83]]}
{"doc_key": "ai-test-418", "ner": [[3, 3, "misc"], [13, 14, "product"], [33, 33, "organisation"], [37, 38, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 13, 14, "usage", "", false, false], [33, 33, 37, 38, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Coincidentally", ",", "the", "Germans", "had", "very", "poorly", "chosen", "the", "operating", "frequency", "of", "the", "Wotan", "system", ",", "which", "operated", "on", "45", "MHz", ",", "which", "happened", "to", "be", "the", "frequency", "of", "the", "powerful", "but", "inactive", "BBC", "television", "station", "at", "Alexandra", "Palace", "."], "sentence-detokenized": "Coincidentally, the Germans had very poorly chosen the operating frequency of the Wotan system, which operated on 45 MHz, which happened to be the frequency of the powerful but inactive BBC television station at Alexandra Palace.", "token2charspan": [[0, 14], [14, 15], [16, 19], [20, 27], [28, 31], [32, 36], [37, 43], [44, 50], [51, 54], [55, 64], [65, 74], [75, 77], [78, 81], [82, 87], [88, 94], [94, 95], [96, 101], [102, 110], [111, 113], [114, 116], [117, 120], [120, 121], [122, 127], [128, 136], [137, 139], [140, 142], [143, 146], [147, 156], [157, 159], [160, 163], [164, 172], [173, 176], [177, 185], [186, 189], [190, 200], [201, 208], [209, 211], [212, 221], [222, 228], [228, 229]]}
{"doc_key": "ai-test-419", "ner": [[8, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "outcomes", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", ",", "as", "follows", ":"], "sentence-detokenized": "The four outcomes can be formulated in a 2 \u00d7 2 contingency table or confusion matrix, as follows:", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 24], [25, 35], [36, 38], [39, 40], [41, 42], [43, 44], [45, 46], [47, 58], [59, 64], [65, 67], [68, 77], [78, 84], [84, 85], [86, 88], [89, 96], [96, 97]]}
{"doc_key": "ai-test-420", "ner": [[1, 3, "misc"], [9, 9, "misc"], [13, 13, "product"], [15, 15, "product"], [17, 19, "product"], [28, 28, "misc"], [44, 46, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 13, 9, 9, "usage", "", false, false], [15, 15, 9, 9, "usage", "", false, false], [17, 19, 15, 15, "named", "", false, false], [28, 28, 9, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "Semantic", "Web", "applications", ",", "and", "in", "relatively", "popular", "RDF", "applications", "such", "as", "RSS", "and", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "resources", "tend", "to", "be", "represented", "by", "URIs", "that", "intentionally", "denote", ",", "and", "can", "be", "used", "to", "access", ",", "real", "data", "on", "the", "World", "Wide", "Web", "."], "sentence-detokenized": "In Semantic Web applications, and in relatively popular RDF applications such as RSS and FOAF (Friend a Friend), resources tend to be represented by URIs that intentionally denote, and can be used to access, real data on the World Wide Web.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 28], [28, 29], [30, 33], [34, 36], [37, 47], [48, 55], [56, 59], [60, 72], [73, 77], [78, 80], [81, 84], [85, 88], [89, 93], [94, 95], [95, 101], [102, 103], [104, 110], [110, 111], [111, 112], [113, 122], [123, 127], [128, 130], [131, 133], [134, 145], [146, 148], [149, 153], [154, 158], [159, 172], [173, 179], [179, 180], [181, 184], [185, 188], [189, 191], [192, 196], [197, 199], [200, 206], [206, 207], [208, 212], [213, 217], [218, 220], [221, 224], [225, 230], [231, 235], [236, 239], [239, 240]]}
{"doc_key": "ai-test-421", "ner": [[1, 7, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "has", "studied", "this", "topic", "in", "depth", "."], "sentence-detokenized": "The Association for the Advancement of Artificial Intelligence has studied this topic in depth.", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 35], [36, 38], [39, 49], [50, 62], [63, 66], [67, 74], [75, 79], [80, 85], [86, 88], [89, 94], [94, 95]]}
{"doc_key": "ai-test-422", "ner": [[6, 9, "product"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 18, 6, 9, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Starting", "as", "a", "curiosity", ",", "the", "Apple", "Macintosh", "speech", "system", "has", "evolved", "into", "a", "fully", "compatible", "programme", ",", "PlainTalk", ",", "for", "the", "visually", "impaired", "."], "sentence-detokenized": "Starting as a curiosity, the Apple Macintosh speech system has evolved into a fully compatible programme, PlainTalk, for the visually impaired.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 23], [23, 24], [25, 28], [29, 34], [35, 44], [45, 51], [52, 58], [59, 62], [63, 70], [71, 75], [76, 77], [78, 83], [84, 94], [95, 104], [104, 105], [106, 115], [115, 116], [117, 120], [121, 124], [125, 133], [134, 142], [142, 143]]}
{"doc_key": "ai-test-423", "ner": [[7, 7, "field"], [9, 10, "task"], [12, 13, "task"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 7, 7, "part-of", "task_part_of_field", false, false], [12, 13, 7, 7, "part-of", "task_part_of_field", false, false], [15, 16, 7, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Other", "areas", "of", "use", "of", "ontologies", "within", "NLP", "are", "information", "retrieval", ",", "information", "extraction", "and", "automatic", "summarisation", "."], "sentence-detokenized": "Other areas of use of ontologies within NLP are information retrieval, information extraction and automatic summarisation.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 18], [19, 21], [22, 32], [33, 39], [40, 43], [44, 47], [48, 59], [60, 69], [69, 70], [71, 82], [83, 93], [94, 97], [98, 107], [108, 121], [121, 122]]}
{"doc_key": "ai-test-424", "ner": [[7, 14, "organisation"], [17, 21, "organisation"], [24, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Institute", "has", "collaborated", "closely", "with", "the", "Howard", "Hughes", "Medical", "Institute", "'s", "Janelia", "Farm", "Campus", ",", "the", "Allen", "Institute", "for", "Brain", "Science", "and", "the", "National", "Institutes", "of", "Health", "to", "develop", "better", "methods", "for", "reconstructing", "neural", "architectures", "."], "sentence-detokenized": "The Institute has collaborated closely with the Howard Hughes Medical Institute's Janelia Farm Campus, the Allen Institute for Brain Science and the National Institutes of Health to develop better methods for reconstructing neural architectures.", "token2charspan": [[0, 3], [4, 13], [14, 17], [18, 30], [31, 38], [39, 43], [44, 47], [48, 54], [55, 61], [62, 69], [70, 79], [79, 81], [82, 89], [90, 94], [95, 101], [101, 102], [103, 106], [107, 112], [113, 122], [123, 126], [127, 132], [133, 140], [141, 144], [145, 148], [149, 157], [158, 168], [169, 171], [172, 178], [179, 181], [182, 189], [190, 196], [197, 204], [205, 208], [209, 223], [224, 230], [231, 244], [244, 245]]}
{"doc_key": "ai-test-425", "ner": [[2, 2, "organisation"], [5, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 2, 2, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Recently", ",", "Google", "announced", "that", "Google", "Translate", "translates", "approximately", "enough", "text", "to", "fill", "a", "million", "books", "in", "one", "day", "(", "2012", ")", "."], "sentence-detokenized": "Recently, Google announced that Google Translate translates approximately enough text to fill a million books in one day (2012).", "token2charspan": [[0, 8], [8, 9], [10, 16], [17, 26], [27, 31], [32, 38], [39, 48], [49, 59], [60, 73], [74, 80], [81, 85], [86, 88], [89, 93], [94, 95], [96, 103], [104, 109], [110, 112], [113, 116], [117, 120], [121, 122], [122, 126], [126, 127], [127, 128]]}
{"doc_key": "ai-test-426", "ner": [[15, 15, "country"], [17, 17, "country"], [19, 19, "country"], [21, 21, "country"], [23, 23, "country"], [25, 27, "country"], [36, 37, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "events", "are", "held", "all", "over", "the", "world", ",", "and", "are", "most", "popular", "in", "the", "UK", ",", "USA", ",", "Japan", ",", "Singapore", ",", "India", ",", "South", "Korea", "and", "are", "becoming", "popular", "in", "sub-continental", "countries", "such", "as", "Sri", "Lanka", "."], "sentence-detokenized": "The events are held all over the world, and are most popular in the UK, USA, Japan, Singapore, India, South Korea and are becoming popular in sub-continental countries such as Sri Lanka.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 19], [20, 23], [24, 28], [29, 32], [33, 38], [38, 39], [40, 43], [44, 47], [48, 52], [53, 60], [61, 63], [64, 67], [68, 70], [70, 71], [72, 75], [75, 76], [77, 82], [82, 83], [84, 93], [93, 94], [95, 100], [100, 101], [102, 107], [108, 113], [114, 117], [118, 121], [122, 130], [131, 138], [139, 141], [142, 157], [158, 167], [168, 172], [173, 175], [176, 179], [180, 185], [185, 186]]}
{"doc_key": "ai-test-427", "ner": [[6, 6, "programlang"], [11, 11, "programlang"], [13, 13, "programlang"], [15, 16, "programlang"], [19, 19, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "packages", "are", "mainly", "developed", "in", "R", ",", "and", "sometimes", "in", "Java", ",", "C", ",", "C", "++", ",", "and", "Fortran", "."], "sentence-detokenized": "These packages are mainly developed in R, and sometimes in Java, C, C++, and Fortran.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 25], [26, 35], [36, 38], [39, 40], [40, 41], [42, 45], [46, 55], [56, 58], [59, 63], [63, 64], [65, 66], [66, 67], [68, 69], [69, 71], [71, 72], [73, 76], [77, 84], [84, 85]]}
{"doc_key": "ai-test-428", "ner": [[2, 6, "conference"], [8, 8, "conference"], [11, 11, "researcher"], [13, 15, "researcher"], [17, 18, "researcher"], [21, 22, "algorithm"], [27, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[8, 8, 2, 6, "named", "", false, false], [11, 11, 2, 6, "physical", "", false, false], [11, 11, 2, 6, "role", "", false, false], [11, 11, 17, 18, "role", "teams_up_with", false, false], [11, 11, 21, 22, "usage", "", false, false], [13, 15, 2, 6, "physical", "", false, false], [13, 15, 2, 6, "role", "", false, false], [13, 15, 17, 18, "role", "teams_up_with", false, false], [13, 15, 21, 22, "usage", "", false, false], [17, 18, 2, 6, "physical", "", false, false], [17, 18, 2, 6, "role", "", false, false], [17, 18, 21, 22, "usage", "", false, false], [21, 22, 27, 32, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["At", "the", "2006", "European", "Computer", "Vision", "Conference", "(", "ECCV", ")", ",", "Dalal", "and", "Triggs", "teamed", "up", "with", "Cordelia", "Schmid", "to", "apply", "HOG", "detectors", "to", "the", "problem", "of", "human", "detection", "in", "film", "and", "video", "."], "sentence-detokenized": "At the 2006 European Computer Vision Conference (ECCV), Dalal and Triggs teamed up with Cordelia Schmid to apply HOG detectors to the problem of human detection in film and video.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 20], [21, 29], [30, 36], [37, 47], [48, 49], [49, 53], [53, 54], [54, 55], [56, 61], [62, 65], [66, 72], [73, 79], [80, 82], [83, 87], [88, 96], [97, 103], [104, 106], [107, 112], [113, 116], [117, 126], [127, 129], [130, 133], [134, 141], [142, 144], [145, 150], [151, 160], [161, 163], [164, 168], [169, 172], [173, 178], [178, 179]]}
{"doc_key": "ai-test-429", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [11, 12, "task"], [19, 19, "metrics"], [23, 23, "metrics"], [29, 29, "metrics"], [33, 35, "metrics"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 3, 11, 12, "related-to", "measured_with", false, false], [5, 5, 11, 12, "related-to", "measured_with", false, false], [19, 19, 11, 12, "related-to", "measured_with", false, false], [23, 23, 19, 19, "named", "", false, false], [29, 29, 19, 19, "named", "", false, false], [37, 37, 33, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "addition", "to", "sensitivity", "and", "specificity", ",", "the", "performance", "of", "a", "binary", "classification", "test", "can", "be", "measured", "by", "the", "positive", "predictive", "value", "(", "PPV", ")", ",", "also", "known", "as", "precision", ",", "and", "the", "negative", "predictive", "value", "(", "NPV", ")", "."], "sentence-detokenized": "In addition to sensitivity and specificity, the performance of a binary classification test can be measured by the positive predictive value (PPV), also known as precision, and the negative predictive value (NPV).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 42], [42, 43], [44, 47], [48, 59], [60, 62], [63, 64], [65, 71], [72, 86], [87, 91], [92, 95], [96, 98], [99, 107], [108, 110], [111, 114], [115, 123], [124, 134], [135, 140], [141, 142], [142, 145], [145, 146], [146, 147], [148, 152], [153, 158], [159, 161], [162, 171], [171, 172], [173, 176], [177, 180], [181, 189], [190, 200], [201, 206], [207, 208], [208, 211], [211, 212], [212, 213]]}
{"doc_key": "ai-test-430", "ner": [[12, 14, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "models", "can", "give", "partial", "credit", "for", "matches", "(", "e.g.", "using", "the", "Jaccard", "index", "criterion", ")", "."], "sentence-detokenized": "Such models can give partial credit for matches (e.g. using the Jaccard index criterion).", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 28], [29, 35], [36, 39], [40, 47], [48, 49], [49, 53], [54, 59], [60, 63], [64, 71], [72, 77], [78, 87], [87, 88], [88, 89]]}
{"doc_key": "ai-test-431", "ner": [[22, 27, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Furthermore", ",", "in", "the", "case", "of", "single", "-", "sample", "estimation", ",", "it", "demonstrates", "philosophical", "issues", "and", "possible", "misunderstandings", "in", "the", "use", "of", "maximum", "likelihood", "estimators", "and", "likelihood", "functions", "."], "sentence-detokenized": "Furthermore, in the case of single-sample estimation, it demonstrates philosophical issues and possible misunderstandings in the use of maximum likelihood estimators and likelihood functions.", "token2charspan": [[0, 11], [11, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 34], [34, 35], [35, 41], [42, 52], [52, 53], [54, 56], [57, 69], [70, 83], [84, 90], [91, 94], [95, 103], [104, 121], [122, 124], [125, 128], [129, 132], [133, 135], [136, 143], [144, 154], [155, 165], [166, 169], [170, 180], [181, 190], [190, 191]]}
