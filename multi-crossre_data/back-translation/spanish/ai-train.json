{"doc_key": "ai-train-1", "ner": [[1, 5, "product"], [13, 14, "field"], [16, 17, "task"], [19, 20, "task"], [24, 26, "task"], [29, 30, "field"], [31, 33, "researcher"], [35, 37, "researcher"], [39, 40, "researcher"], [42, 43, "researcher"], [45, 47, "researcher"], [49, 50, "researcher"], [52, 53, "researcher"], [55, 56, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[1, 5, 13, 14, "part-of", "", false, false], [1, 5, 13, 14, "usage", "", false, false], [1, 5, 16, 17, "part-of", "", false, false], [1, 5, 16, 17, "usage", "", false, false], [1, 5, 19, 20, "part-of", "", false, false], [1, 5, 19, 20, "usage", "", false, false], [1, 5, 29, 30, "part-of", "", false, false], [1, 5, 29, 30, "usage", "", false, false], [24, 26, 19, 20, "part-of", "", false, false], [24, 26, 19, 20, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Popular", "opinion", "-", "based", "recommender", "system", "approaches", "use", "several", "techniques", ",", "such", "as", "text", "mining", ",", "information", "retrieval", ",", "sentiment", "analysis", "(", "see", "also", "multimodal", "sentiment", "analysis", ")", "and", "deep", "learning", "X.Y", ".", "Feng", ",", "H", ".", "Zhang", ",", "Y.J.", "Ren", ",", "P.H.", "Shang", ",", "Y", ".", "Zhu", ",", "Y.C.", "Liang", ",", "R.C.", "Guan", ",", "D.", "Xu", ",", "(", "2019", ")", ",", ",", ",", "21", "(", "5", ")", ":", "e12957", "."], "sentence-detokenized": "Popular opinion-based recommender system approaches use several techniques, such as text mining, information retrieval, sentiment analysis (see also multimodal sentiment analysis) and deep learning X.Y. Feng, H. Zhang, Y.J. Ren, P.H. Shang, Y. Zhu, Y.C. Liang, R.C. Guan, D. Xu, (2019),,, 21 (5): e12957.", "token2charspan": [[0, 7], [8, 15], [15, 16], [16, 21], [22, 33], [34, 40], [41, 51], [52, 55], [56, 63], [64, 74], [74, 75], [76, 80], [81, 83], [84, 88], [89, 95], [95, 96], [97, 108], [109, 118], [118, 119], [120, 129], [130, 138], [139, 140], [140, 143], [144, 148], [149, 159], [160, 169], [170, 178], [178, 179], [180, 183], [184, 188], [189, 197], [198, 201], [201, 202], [203, 207], [207, 208], [209, 210], [210, 211], [212, 217], [217, 218], [219, 223], [224, 227], [227, 228], [229, 233], [234, 239], [239, 240], [241, 242], [242, 243], [244, 247], [247, 248], [249, 253], [254, 259], [259, 260], [261, 265], [266, 270], [270, 271], [272, 274], [275, 277], [277, 278], [279, 280], [280, 284], [284, 285], [285, 286], [286, 287], [287, 288], [289, 291], [292, 293], [293, 294], [294, 295], [295, 296], [297, 303], [303, 304]]}
{"doc_key": "ai-train-2", "ner": [[9, 9, "university"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 16, 9, 9, "physical", "", false, false], [15, 16, 9, 9, "role", "", false, false], [18, 19, 9, 9, "physical", "", false, false], [18, 19, 9, 9, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "advocates", "of", "procedural", "representations", "were", "mainly", "centred", "at", "MIT", ",", "under", "the", "leadership", "of", "Marvin", "Minsky", "and", "Seymour", "Papert", "."], "sentence-detokenized": "The advocates of procedural representations were mainly centred at MIT, under the leadership of Marvin Minsky and Seymour Papert.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 27], [28, 43], [44, 48], [49, 55], [56, 63], [64, 66], [67, 70], [70, 71], [72, 77], [78, 81], [82, 92], [93, 95], [96, 102], [103, 109], [110, 113], [114, 121], [122, 128], [128, 129]]}
{"doc_key": "ai-train-3", "ner": [[10, 10, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "standard", "interface", "and", "the", "calculator", "interface", "are", "written", "in", "Java", "."], "sentence-detokenized": "The standard interface and the calculator interface are written in Java.", "token2charspan": [[0, 3], [4, 12], [13, 22], [23, 26], [27, 30], [31, 41], [42, 51], [52, 55], [56, 63], [64, 66], [67, 71], [71, 72]]}
{"doc_key": "ai-train-4", "ner": [[0, 0, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 22, 22, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["Octave", "helps", "you", "solve", "linear", "and", "non-linear", "problems", "numerically", "and", "perform", "other", "numerical", "experiments", "using", "a", "program", "that", "is", "largely", "compatible", "with", "MATLAB", "."], "sentence-detokenized": "Octave helps you solve linear and non-linear problems numerically and perform other numerical experiments using a program that is largely compatible with MATLAB.", "token2charspan": [[0, 6], [7, 12], [13, 16], [17, 22], [23, 29], [30, 33], [34, 44], [45, 53], [54, 65], [66, 69], [70, 77], [78, 83], [84, 93], [94, 105], [106, 111], [112, 113], [114, 121], [122, 126], [127, 129], [130, 137], [138, 148], [149, 153], [154, 160], [160, 161]]}
{"doc_key": "ai-train-5", "ner": [[3, 6, "algorithm"], [10, 11, "misc"], [13, 14, "researcher"], [18, 21, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 6, 13, 14, "origin", "", false, false], [10, 11, 13, 14, "origin", "", false, false], [13, 14, 18, 21, "physical", "", false, false], [13, 14, 18, 21, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Variants", "of", "the", "backpropagation", "algorithm", ",", "as", "well", "as", "the", "unsupervised", "methods", "of", "Geoff", "Hinton", "and", "colleagues", "at", "the", "University", "of", "Toronto", ",", "can", "be", "used", "to", "train", "deep", "and", "highly", "non-linear", "neural", "architectures", ",", "{", "{", "cite", "journal"], "sentence-detokenized": "Variants of the backpropagation algorithm, as well as the unsupervised methods of Geoff Hinton and colleagues at the University of Toronto, can be used to train deep and highly non-linear neural architectures, {{cite journal", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 31], [32, 41], [41, 42], [43, 45], [46, 50], [51, 53], [54, 57], [58, 70], [71, 78], [79, 81], [82, 87], [88, 94], [95, 98], [99, 109], [110, 112], [113, 116], [117, 127], [128, 130], [131, 138], [138, 139], [140, 143], [144, 146], [147, 151], [152, 154], [155, 160], [161, 165], [166, 169], [170, 176], [177, 187], [188, 194], [195, 208], [208, 209], [210, 211], [211, 212], [212, 216], [217, 224]]}
{"doc_key": "ai-train-6", "ner": [[5, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", ",", "equivalently", ",", "using", "DCG", "notation", ":"], "sentence-detokenized": "or, equivalently, using DCG notation:", "token2charspan": [[0, 2], [2, 3], [4, 16], [16, 17], [18, 23], [24, 27], [28, 36], [36, 37]]}
{"doc_key": "ai-train-7", "ner": [[0, 3, "algorithm"], [7, 9, "algorithm"], [14, 19, "algorithm"], [20, 22, "algorithm"], [26, 26, "algorithm"], [28, 29, "algorithm"], [43, 44, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 7, 9, "type-of", "", false, false], [0, 3, 14, 19, "usage", "part-of?", true, false], [14, 19, 20, 22, "compare", "", false, false], [26, 26, 20, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Self", "-", "organising", "maps", "differ", "from", "other", "artificial", "neural", "networks", "in", "that", "they", "apply", "competitive", "learning", ",", "as", "opposed", "to", "error", "-correcting", "learning", "(", "such", "as", "backpropagation", "with", "gradient", "descent", ")", ",", "and", "in", "that", "they", "use", "a", "neighbourhood", "function", "to", "preserve", "the", "topological", "properties", "of", "the", "input", "space", "."], "sentence-detokenized": "Self-organising maps differ from other artificial neural networks in that they apply competitive learning, as opposed to error-correcting learning (such as backpropagation with gradient descent), and in that they use a neighbourhood function to preserve the topological properties of the input space.", "token2charspan": [[0, 4], [4, 5], [5, 15], [16, 20], [21, 27], [28, 32], [33, 38], [39, 49], [50, 56], [57, 65], [66, 68], [69, 73], [74, 78], [79, 84], [85, 96], [97, 105], [105, 106], [107, 109], [110, 117], [118, 120], [121, 126], [126, 137], [138, 146], [147, 148], [148, 152], [153, 155], [156, 171], [172, 176], [177, 185], [186, 193], [193, 194], [194, 195], [196, 199], [200, 202], [203, 207], [208, 212], [213, 216], [217, 218], [219, 232], [233, 241], [242, 244], [245, 253], [254, 257], [258, 269], [270, 280], [281, 283], [284, 287], [288, 293], [294, 299], [299, 300]]}
{"doc_key": "ai-train-8", "ner": [[10, 14, "organisation"], [24, 25, "misc"], [34, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Since", "the", "early", "1990s", ",", "several", "authorities", ",", "including", "the", "Audio", "Engineering", "Society", ",", "have", "recommended", "that", "dynamic", "range", "measurements", "be", "made", "with", "an", "audio", "signal", "present", ",", "which", "is", "then", "filtered", "into", "the", "noise", "floor", "measurement", "used", "to", "determine", "dynamic", "range", ".", "This", "avoids", "dubious", "measurements", "based", "on", "the", "use", "of", "empty", "media", "or", "squelch", "circuits", "."], "sentence-detokenized": "Since the early 1990s, several authorities, including the Audio Engineering Society, have recommended that dynamic range measurements be made with an audio signal present, which is then filtered into the noise floor measurement used to determine dynamic range. This avoids dubious measurements based on the use of empty media or squelch circuits.", "token2charspan": [[0, 5], [6, 9], [10, 15], [16, 21], [21, 22], [23, 30], [31, 42], [42, 43], [44, 53], [54, 57], [58, 63], [64, 75], [76, 83], [83, 84], [85, 89], [90, 101], [102, 106], [107, 114], [115, 120], [121, 133], [134, 136], [137, 141], [142, 146], [147, 149], [150, 155], [156, 162], [163, 170], [170, 171], [172, 177], [178, 180], [181, 185], [186, 194], [195, 199], [200, 203], [204, 209], [210, 215], [216, 227], [228, 232], [233, 235], [236, 245], [246, 253], [254, 259], [259, 260], [261, 265], [266, 272], [273, 280], [281, 293], [294, 299], [300, 302], [303, 306], [307, 310], [311, 313], [314, 319], [320, 325], [326, 328], [329, 336], [337, 345], [345, 346]]}
{"doc_key": "ai-train-9", "ner": [[7, 8, "misc"], [18, 19, "task"], [21, 22, "task"], [24, 25, "task"], [27, 28, "task"], [30, 30, "task"], [34, 35, "task"], [37, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[7, 8, 18, 19, "part-of", "concept_used_in", true, false], [7, 8, 21, 22, "part-of", "concept_used_in", false, false], [7, 8, 24, 25, "part-of", "concept_used_in", false, false], [7, 8, 27, 28, "part-of", "concept_used_in", false, false], [7, 8, 30, 30, "part-of", "concept_used_in", false, false], [7, 8, 34, 35, "part-of", "concept_used_in", false, false], [7, 8, 37, 39, "part-of", "concept_used_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "technique", "used", "in", "the", "creation", "of", "own", "faces", "and", "their", "use", "for", "recognition", "is", "also", "used", "outside", "face", "recognition", ":", "handwriting", "recognition", ",", "lip", "reading", ",", "voice", "recognition", ",", "sign", "language", "/", "hand", "gesture", "interpretation", "and", "medical", "image", "analysis", "."], "sentence-detokenized": "The technique used in the creation of own faces and their use for recognition is also used outside face recognition: handwriting recognition, lip reading, voice recognition, sign language/hand gesture interpretation and medical image analysis.", "token2charspan": [[0, 3], [4, 13], [14, 18], [19, 21], [22, 25], [26, 34], [35, 37], [38, 41], [42, 47], [48, 51], [52, 57], [58, 61], [62, 65], [66, 77], [78, 80], [81, 85], [86, 90], [91, 98], [99, 103], [104, 115], [115, 116], [117, 128], [129, 140], [140, 141], [142, 145], [146, 153], [153, 154], [155, 160], [161, 172], [172, 173], [174, 178], [179, 187], [187, 188], [188, 192], [193, 200], [201, 215], [216, 219], [220, 227], [228, 233], [234, 242], [242, 243]]}
{"doc_key": "ai-train-10", "ner": [[0, 3, "organisation"], [9, 13, "organisation"], [14, 15, "organisation"], [19, 55, "organisation"], [58, 62, "organisation"], [64, 64, "organisation"], [68, 71, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 6, 7, 8], "relations": [[9, 13, 0, 3, "part-of", "", false, false], [14, 15, 9, 13, "named", "", false, false], [19, 55, 0, 3, "part-of", "", false, false], [58, 62, 0, 3, "part-of", "", false, false], [64, 64, 58, 62, "named", "", false, false], [68, 71, 0, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 5, 6, 7], "sentence": ["The", "National", "Science", "Foundation", "was", "an", "umbrella", "for", "the", "National", "Aeronautics", "and", "Space", "Administration", "(", "NASA", ")", ",", "the", "U.S.", "Department", "of", "Energy", ",", "the", "U.S.", "Department", "of", "Commerce", ",", "NIST", ",", "the", "U.S.", "Department", "of", "Defense", ",", "the", "U.S.", "Department", "of", "Defense", ",", "and", "the", "U.S.", "Department", "of", "Defense", ".", "The", "US", "Department", "of", "Defense", ",", "the", "Defense", "Advanced", "Research", "Projects", "Agency", "(", "DARPA", ")", "and", "the", "Office", "of", "Naval", "Research", "coordinated", "studies", "to", "inform", "strategic", "planners", "in", "their", "deliberations", "."], "sentence-detokenized": "The National Science Foundation was an umbrella for the National Aeronautics and Space Administration (NASA), the U.S. Department of Energy, the U.S. Department of Commerce, NIST, the U.S. Department of Defense, the U.S. Department of Defense, and the U.S. Department of Defense.  The US Department of Defense, the Defense Advanced Research Projects Agency (DARPA) and the Office of Naval Research coordinated studies to inform strategic planners in their deliberations.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 31], [32, 35], [36, 38], [39, 47], [48, 51], [52, 55], [56, 64], [65, 76], [77, 80], [81, 86], [87, 101], [102, 103], [103, 107], [107, 108], [108, 109], [110, 113], [114, 118], [119, 129], [130, 132], [133, 139], [139, 140], [141, 144], [145, 149], [150, 160], [161, 163], [164, 172], [172, 173], [174, 178], [178, 179], [180, 183], [184, 188], [189, 199], [200, 202], [203, 210], [210, 211], [212, 215], [216, 220], [221, 231], [232, 234], [235, 242], [242, 243], [244, 247], [248, 251], [252, 256], [257, 267], [268, 270], [271, 278], [278, 279], [281, 284], [285, 287], [288, 298], [299, 301], [302, 309], [309, 310], [311, 314], [315, 322], [323, 331], [332, 340], [341, 349], [350, 356], [357, 358], [358, 363], [363, 364], [365, 368], [369, 372], [373, 379], [380, 382], [383, 388], [389, 397], [398, 409], [410, 417], [418, 420], [421, 427], [428, 437], [438, 446], [447, 449], [450, 455], [456, 469], [469, 470]]}
{"doc_key": "ai-train-11", "ner": [[5, 6, "metrics"], [10, 11, "algorithm"], [15, 18, "researcher"], [21, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 10, 11, "part-of", "", false, false], [15, 18, 21, 21, "related-to", "added_appendix_to_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "quick", "method", "for", "calculating", "maximum", "likelihood", "estimates", "for", "the", "probit", "model", "was", "proposed", "by", "Ronald", "Fisher", "as", "an", "appendix", "to", "Bliss", "'", "work", "in", "1935", "."], "sentence-detokenized": "A quick method for calculating maximum likelihood estimates for the probit model was proposed by Ronald Fisher as an appendix to Bliss' work in 1935.", "token2charspan": [[0, 1], [2, 7], [8, 14], [15, 18], [19, 30], [31, 38], [39, 49], [50, 59], [60, 63], [64, 67], [68, 74], [75, 80], [81, 84], [85, 93], [94, 96], [97, 103], [104, 110], [111, 113], [114, 116], [117, 125], [126, 128], [129, 134], [134, 135], [136, 140], [141, 143], [144, 148], [148, 149]]}
{"doc_key": "ai-train-12", "ner": [[10, 11, "product"], [14, 15, "product"], [18, 18, "organisation"], [20, 20, "product"], [23, 27, "organisation"], [25, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 20, 14, 15, "usage", "uses_software", false, false], [20, 20, 18, 18, "artifact", "", false, false], [20, 20, 25, 26, "named", "", false, false], [25, 26, 23, 27, "artifact", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Several", "of", "these", "programmes", "are", "available", "online", ",", "such", "as", "Google", "Translate", "and", "the", "SYSTRAN", "system", "that", "powers", "AltaVista", "'s", "BabelFish", "(", "now", "Yahoo", "'s", "Babelfish", "as", "of", "9", "May", "2008", ")", "."], "sentence-detokenized": "Several of these programmes are available online, such as Google Translate and the SYSTRAN system that powers AltaVista's BabelFish (now Yahoo's Babelfish as of 9 May 2008).", "token2charspan": [[0, 7], [8, 10], [11, 16], [17, 27], [28, 31], [32, 41], [42, 48], [48, 49], [50, 54], [55, 57], [58, 64], [65, 74], [75, 78], [79, 82], [83, 90], [91, 97], [98, 102], [103, 109], [110, 119], [119, 121], [122, 131], [132, 133], [133, 136], [137, 142], [142, 144], [145, 154], [155, 157], [158, 160], [161, 162], [163, 166], [167, 171], [171, 172], [172, 173]]}
{"doc_key": "ai-train-13", "ner": [[3, 3, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [20, 22, "field"], [26, 27, "misc"], [31, 32, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 3, 20, 22, "related-to", "", true, false], [3, 3, 26, 27, "related-to", "", true, false], [3, 3, 31, 32, "related-to", "", true, false], [7, 8, 20, 22, "related-to", "", true, false], [7, 8, 26, 27, "related-to", "", true, false], [7, 8, 31, 32, "related-to", "", true, false], [10, 11, 20, 22, "related-to", "", true, false], [10, 11, 26, 27, "related-to", "", true, false], [10, 11, 31, 32, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "2002", ",", "Hutter", ",", "together", "with", "J\u00fcrgen", "Schmidhuber", "and", "Shane", "Legg", ",", "developed", "and", "published", "a", "mathematical", "theory", "of", "artificial", "general", "intelligence", "based", "on", "idealised", "intelligent", "agents", "and", "reward", "-motivated", "reinforcement", "learning", "."], "sentence-detokenized": "In 2002, Hutter, together with J\u00fcrgen Schmidhuber and Shane Legg, developed and published a mathematical theory of artificial general intelligence based on idealised intelligent agents and reward-motivated reinforcement learning.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [15, 16], [17, 25], [26, 30], [31, 37], [38, 49], [50, 53], [54, 59], [60, 64], [64, 65], [66, 75], [76, 79], [80, 89], [90, 91], [92, 104], [105, 111], [112, 114], [115, 125], [126, 133], [134, 146], [147, 152], [153, 155], [156, 165], [166, 177], [178, 184], [185, 188], [189, 195], [195, 205], [206, 219], [220, 228], [228, 229]]}
{"doc_key": "ai-train-14", "ner": [[11, 11, "metrics"], [13, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 11, 13, 19, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "most", "common", "way", "is", "to", "use", "the", "so", "-", "called", "ROUGE", "(", "Recall", "-", "Oriented", "Understudy", "for", "Gisting", "Evaluation", ")", "measure", "."], "sentence-detokenized": "The most common way is to use the so-called ROUGE (Recall-Oriented Understudy for Gisting Evaluation) measure.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 19], [20, 22], [23, 25], [26, 29], [30, 33], [34, 36], [36, 37], [37, 43], [44, 49], [50, 51], [51, 57], [57, 58], [58, 66], [67, 77], [78, 81], [82, 89], [90, 100], [100, 101], [102, 109], [109, 110]]}
{"doc_key": "ai-train-15", "ner": [[0, 0, "product"], [14, 15, "programlang"], [17, 17, "programlang"], [19, 20, "researcher"], [22, 23, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 14, 15, "related-to", "", false, false], [0, 0, 17, 17, "related-to", "", false, false], [19, 20, 22, 23, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["RapidMiner", "provides", "learning", "schemes", ",", "models", "and", "algorithms", "and", "can", "be", "extended", "by", "scripting", "in", "R", "and", "Python", ".", "David", "Norris", ",", "Bloor", "Research", ",", "13", "November", "2013", "."], "sentence-detokenized": "RapidMiner provides learning schemes, models and algorithms and can be extended by scripting in R and Python. David Norris, Bloor Research, 13 November 2013.", "token2charspan": [[0, 10], [11, 19], [20, 28], [29, 36], [36, 37], [38, 44], [45, 48], [49, 59], [60, 63], [64, 67], [68, 70], [71, 79], [80, 82], [83, 92], [93, 95], [96, 97], [98, 101], [102, 108], [108, 109], [110, 115], [116, 122], [122, 123], [124, 129], [130, 138], [138, 139], [140, 142], [143, 151], [152, 156], [156, 157]]}
{"doc_key": "ai-train-16", "ner": [[0, 0, "product"], [10, 11, "field"], [13, 14, "task"], [18, 20, "misc"], [34, 36, "programlang"], [39, 40, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 10, 11, "related-to", "", false, false], [0, 0, 13, 14, "related-to", "", false, false], [0, 0, 39, 40, "related-to", "", true, false], [18, 20, 0, 0, "part-of", "", false, false], [39, 40, 34, 36, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["tity", "contains", "a", "collection", "of", "visualisation", "tools", "and", "algorithms", "for", "data", "analysis", "and", "predictive", "modelling", ",", "together", "with", "graphical", "user", "interfaces", "for", "easy", "access", "to", "these", "functions", ".", "But", "the", "most", "recent", ",", "fully", "Java", "-", "based", "version", "(", "Weka", "3", ")", ",", "whose", "development", "started", "in", "1997", ",", "is", "now", "used", "in", "many", "different", "application", "areas", ",", "in", "particular", "for", "educational", "and", "research", "purposes", "."], "sentence-detokenized": "tity contains a collection of visualisation tools and algorithms for data analysis and predictive modelling, together with graphical user interfaces for easy access to these functions. But the most recent, fully Java-based version (Weka 3), whose development started in 1997, is now used in many different application areas, in particular for educational and research purposes.", "token2charspan": [[0, 4], [5, 13], [14, 15], [16, 26], [27, 29], [30, 43], [44, 49], [50, 53], [54, 64], [65, 68], [69, 73], [74, 82], [83, 86], [87, 97], [98, 107], [107, 108], [109, 117], [118, 122], [123, 132], [133, 137], [138, 148], [149, 152], [153, 157], [158, 164], [165, 167], [168, 173], [174, 183], [183, 184], [185, 188], [189, 192], [193, 197], [198, 204], [204, 205], [206, 211], [212, 216], [216, 217], [217, 222], [223, 230], [231, 232], [232, 236], [237, 238], [238, 239], [239, 240], [241, 246], [247, 258], [259, 266], [267, 269], [270, 274], [274, 275], [276, 278], [279, 282], [283, 287], [288, 290], [291, 295], [296, 305], [306, 317], [318, 323], [323, 324], [325, 327], [328, 338], [339, 342], [343, 354], [355, 358], [359, 367], [368, 376], [376, 377]]}
{"doc_key": "ai-train-17", "ner": [[0, 0, "product"], [13, 20, "misc"], [23, 25, "misc"], [28, 35, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 20, 0, 0, "topic", "", false, false], [13, 20, 23, 25, "win-defeat", "", false, false], [23, 25, 28, 35, "temporal", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Eurisko", "made", "many", "interesting", "discoveries", "and", "enjoyed", "significant", "acclaim", ",", "as", "his", "paper", "Heuretics", ":", "Theoretical", "and", "Study", "of", "Heuristic", "Rules", "won", "the", "best", "paper", "award", "at", "the", "1982", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "Eurisko made many interesting discoveries and enjoyed significant acclaim, as his paper Heuretics: Theoretical and Study of Heuristic Rules won the best paper award at the 1982 Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 7], [8, 12], [13, 17], [18, 29], [30, 41], [42, 45], [46, 53], [54, 65], [66, 73], [73, 74], [75, 77], [78, 81], [82, 87], [88, 97], [97, 98], [99, 110], [111, 114], [115, 120], [121, 123], [124, 133], [134, 139], [140, 143], [144, 147], [148, 152], [153, 158], [159, 164], [165, 167], [168, 171], [172, 176], [177, 188], [189, 192], [193, 196], [197, 208], [209, 211], [212, 222], [223, 235], [235, 236]]}
{"doc_key": "ai-train-18", "ner": [[8, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["To", "account", "for", "multiple", "entities", ",", "a", "separate", "hinge", "loss", "is", "calculated", "for", "each", "capsule", "."], "sentence-detokenized": "To account for multiple entities, a separate hinge loss is calculated for each capsule.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 23], [24, 32], [32, 33], [34, 35], [36, 44], [45, 50], [51, 55], [56, 58], [59, 69], [70, 73], [74, 78], [79, 86], [86, 87]]}
{"doc_key": "ai-train-19", "ner": [[8, 10, "product"], [12, 13, "product"], [15, 16, "product"], [18, 19, "product"], [21, 23, "product"], [25, 26, "product"], [35, 42, "product"], [45, 46, "product"], [48, 49, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 10, 25, 26, "type-of", "", false, false], [12, 13, 25, 26, "type-of", "", false, false], [15, 16, 25, 26, "type-of", "", false, false], [18, 19, 25, 26, "type-of", "", false, false], [21, 23, 25, 26, "type-of", "", false, false], [45, 46, 35, 42, "type-of", "", false, false], [48, 49, 35, 42, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["With", "the", "emergence", "of", "conversational", "assistants", "such", "as", "Apple", "'s", "Siri", ",", "Amazon", "Alexa", ",", "Google", "Assistant", ",", "Microsoft", "Cortana", "and", "Samsung", "'s", "Bixby", ",", "voice", "portals", "can", "now", "be", "accessed", "through", "mobile", "devices", "and", "Far", "Field", "'s", "voice", "-", "enabled", "smart", "speakers", "such", "as", "Amazon", "Echo", "and", "Google", "Home", "."], "sentence-detokenized": "With the emergence of conversational assistants such as Apple's Siri, Amazon Alexa, Google Assistant, Microsoft Cortana and Samsung's Bixby, voice portals can now be accessed through mobile devices and Far Field's voice-enabled smart speakers such as Amazon Echo and Google Home.", "token2charspan": [[0, 4], [5, 8], [9, 18], [19, 21], [22, 36], [37, 47], [48, 52], [53, 55], [56, 61], [61, 63], [64, 68], [68, 69], [70, 76], [77, 82], [82, 83], [84, 90], [91, 100], [100, 101], [102, 111], [112, 119], [120, 123], [124, 131], [131, 133], [134, 139], [139, 140], [141, 146], [147, 154], [155, 158], [159, 162], [163, 165], [166, 174], [175, 182], [183, 189], [190, 197], [198, 201], [202, 205], [206, 211], [211, 213], [214, 219], [219, 220], [220, 227], [228, 233], [234, 242], [243, 247], [248, 250], [251, 257], [258, 262], [263, 266], [267, 273], [274, 278], [278, 279]]}
{"doc_key": "ai-train-20", "ner": [[2, 3, "field"], [6, 8, "algorithm"], [11, 13, "algorithm"], [15, 16, "algorithm"], [19, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 8, 2, 3, "type-of", "", false, false], [11, 13, 2, 3, "type-of", "", false, false], [15, 16, 2, 3, "type-of", "", false, false], [19, 19, 2, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Examples", "of", "supervised", "learning", "are", "the", "Naive", "Bayes", "classifier", ",", "the", "support", "vector", "machine", ",", "Gaussian", "mixtures", "and", "the", "network", "."], "sentence-detokenized": "Examples of supervised learning are the Naive Bayes classifier, the support vector machine, Gaussian mixtures and the network.", "token2charspan": [[0, 8], [9, 11], [12, 22], [23, 31], [32, 35], [36, 39], [40, 45], [46, 51], [52, 62], [62, 63], [64, 67], [68, 75], [76, 82], [83, 90], [90, 91], [92, 100], [101, 109], [110, 113], [114, 117], [118, 125], [125, 126]]}
{"doc_key": "ai-train-21", "ner": [[4, 5, "algorithm"], [25, 27, "algorithm"], [29, 29, "task"], [35, 36, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 25, 27, "part-of", "", true, false], [35, 36, 29, 29, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["You", "can", "use", "the", "OSD", "algorithm", "to", "mathematically", "derive", "O", "(", "sqrt", "{", "T", "})", "/", "mathematically", "regret", "bounds", "for", "the", "online", "version", "of", "the", "support", "vector", "machine", "for", "classification", ",", "which", "use", "the", "mathematical", "hinge", "loss", "v", "_t", "(", "w", ")", "=", "max", "{", "0", ",", "1", "-", "y", "_t", "(", "wdot", "x", "_t", ")", "}.", "/", "math"], "sentence-detokenized": "You can use the OSD algorithm to mathematically derive O(sqrt {T})/mathematically regret bounds for the online version of the support vector machine for classification, which use the mathematical hinge loss v _t (w) = max {0, 1 - y _t (wdot x _t)}. / math", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 15], [16, 19], [20, 29], [30, 32], [33, 47], [48, 54], [55, 56], [56, 57], [57, 61], [62, 63], [63, 64], [64, 66], [66, 67], [67, 81], [82, 88], [89, 95], [96, 99], [100, 103], [104, 110], [111, 118], [119, 121], [122, 125], [126, 133], [134, 140], [141, 148], [149, 152], [153, 167], [167, 168], [169, 174], [175, 178], [179, 182], [183, 195], [196, 201], [202, 206], [207, 208], [209, 211], [212, 213], [213, 214], [214, 215], [216, 217], [218, 221], [222, 223], [223, 224], [224, 225], [226, 227], [228, 229], [230, 231], [232, 234], [235, 236], [236, 240], [241, 242], [243, 245], [245, 246], [246, 248], [249, 250], [251, 255]]}
{"doc_key": "ai-train-22", "ner": [[2, 3, "task"], [5, 6, "task"], [8, 8, "task"], [10, 11, "task"], [13, 14, "task"], [16, 17, "task"], [19, 20, "task"], [22, 24, "task"], [26, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Applications", "include", "object", "recognition", ",", "robotic", "mapping", "and", "navigation", ",", "image", "stitching", ",", "3D", "modelling", ",", "gesture", "recognition", ",", "video", "tracking", ",", "individual", "wildlife", "identification", "and", "party", "movement", "."], "sentence-detokenized": "Applications include object recognition, robotic mapping and navigation, image stitching, 3D modelling, gesture recognition, video tracking, individual wildlife identification and party movement.", "token2charspan": [[0, 12], [13, 20], [21, 27], [28, 39], [39, 40], [41, 48], [49, 56], [57, 60], [61, 71], [71, 72], [73, 78], [79, 88], [88, 89], [90, 92], [93, 102], [102, 103], [104, 111], [112, 123], [123, 124], [125, 130], [131, 139], [139, 140], [141, 151], [152, 160], [161, 175], [176, 179], [180, 185], [186, 194], [194, 195]]}
{"doc_key": "ai-train-23", "ner": [[6, 7, "task"], [12, 13, "university"], [15, 17, "university"], [19, 20, "university"], [22, 23, "university"], [25, 30, "university"], [32, 34, "university"], [36, 39, "university"], [41, 42, "university"], [44, 49, "university"], [51, 51, "university"], [54, 58, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[6, 7, 12, 13, "related-to", "", true, false], [6, 7, 15, 17, "related-to", "", true, false], [6, 7, 19, 20, "related-to", "", true, false], [6, 7, 22, 23, "related-to", "", true, false], [6, 7, 25, 30, "related-to", "", true, false], [6, 7, 32, 34, "related-to", "", true, false], [6, 7, 36, 39, "related-to", "", true, false], [6, 7, 41, 42, "related-to", "", true, false], [6, 7, 44, 49, "related-to", "", true, false], [6, 7, 51, 51, "related-to", "", true, false], [6, 7, 54, 58, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Several", "groups", "and", "companies", "are", "researching", "pose", "estimation", ",", "including", "those", "at", "Brown", "University", ",", "Carnegie", "Mellon", "University", ",", "MPI", "Saarbruecken", ",", "Stanford", "University", ",", "University", "of", "California", "at", "San", "Diego", ",", "University", "of", "Toronto", ",", "\u00c9cole", "Centrale", "de", "Paris", ",", "ETH", "Zurich", ",", "National", "University", "of", "Science", "and", "Technology", "(", "NUST", ")", "and", "University", "of", "California", "at", "Irvine", "."], "sentence-detokenized": "Several groups and companies are researching pose estimation, including those at Brown University, Carnegie Mellon University, MPI Saarbruecken, Stanford University, University of California at San Diego, University of Toronto, \u00c9cole Centrale de Paris, ETH Zurich, National University of Science and Technology (NUST) and University of California at Irvine.", "token2charspan": [[0, 7], [8, 14], [15, 18], [19, 28], [29, 32], [33, 44], [45, 49], [50, 60], [60, 61], [62, 71], [72, 77], [78, 80], [81, 86], [87, 97], [97, 98], [99, 107], [108, 114], [115, 125], [125, 126], [127, 130], [131, 143], [143, 144], [145, 153], [154, 164], [164, 165], [166, 176], [177, 179], [180, 190], [191, 193], [194, 197], [198, 203], [203, 204], [205, 215], [216, 218], [219, 226], [226, 227], [228, 233], [234, 242], [243, 245], [246, 251], [251, 252], [253, 256], [257, 263], [263, 264], [265, 273], [274, 284], [285, 287], [288, 295], [296, 299], [300, 310], [311, 312], [312, 316], [316, 317], [318, 321], [322, 332], [333, 335], [336, 346], [347, 349], [350, 356], [356, 357]]}
{"doc_key": "ai-train-24", "ner": [[0, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sigmoid", "cross", "-entropy", "loss", "function", "is", "used", "to", "predict", "K", "independent", "probability", "values", "in", "maths", "0.1", "/", "maths", "0.1", "."], "sentence-detokenized": "The sigmoid cross-entropy loss function is used to predict K independent probability values in maths 0.1 / maths 0.1.", "token2charspan": [[0, 3], [4, 11], [12, 17], [17, 25], [26, 30], [31, 39], [40, 42], [43, 47], [48, 50], [51, 58], [59, 60], [61, 72], [73, 84], [85, 91], [92, 94], [95, 100], [101, 104], [105, 106], [107, 112], [113, 116], [116, 117]]}
{"doc_key": "ai-train-25", "ner": [[3, 5, "misc"], [7, 7, "field"], [9, 10, "field"], [13, 15, "university"], [17, 18, "country"], [22, 23, "misc"], [26, 29, "university"], [31, 31, "country"], [38, 38, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 5, 7, 7, "topic", "", false, false], [3, 5, 9, 10, "topic", "", false, false], [3, 5, 13, 15, "physical", "", true, false], [13, 15, 17, 18, "physical", "", false, false], [22, 23, 26, 29, "physical", "", true, false], [26, 29, 31, 31, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["He", "held", "the", "Johann", "Bernoulli", "Chair", "in", "Mathematics", "and", "Computer", "Science", "at", "the", "University", "of", "Groningen", "(", "The", "Netherlands", ")", "and", "the", "Toshiba", "Chair", "at", "the", "Tokyo", "Institute", "of", "Technology", "(", "Japan", ")", "before", "becoming", "a", "professor", "at", "Cambridge", "."], "sentence-detokenized": "He held the Johann Bernoulli Chair in Mathematics and Computer Science at the University of Groningen (The Netherlands) and the Toshiba Chair at the Tokyo Institute of Technology (Japan) before becoming a professor at Cambridge.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 18], [19, 28], [29, 34], [35, 37], [38, 49], [50, 53], [54, 62], [63, 70], [71, 73], [74, 77], [78, 88], [89, 91], [92, 101], [102, 103], [103, 106], [107, 118], [118, 119], [120, 123], [124, 127], [128, 135], [136, 141], [142, 144], [145, 148], [149, 154], [155, 164], [165, 167], [168, 178], [179, 180], [180, 185], [185, 186], [187, 193], [194, 202], [203, 204], [205, 214], [215, 217], [218, 227], [227, 228]]}
{"doc_key": "ai-train-26", "ner": [[5, 6, "algorithm"], [13, 13, "algorithm"], [16, 16, "algorithm"], [21, 22, "researcher"], [24, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 13, 13, "usage", "", true, false], [13, 13, 21, 22, "origin", "", false, false], [13, 13, 24, 25, "origin", "", false, false], [16, 16, 13, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Another", "technique", "especially", "used", "for", "recurrent", "neural", "networks", "is", "the", "short", "-", "term", "memory", "network", "(", "LSTM", ")", "of", "1997", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Another technique especially used for recurrent neural networks is the short-term memory network (LSTM) of 1997 by Sepp Hochreiter and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 7], [8, 17], [18, 28], [29, 33], [34, 37], [38, 47], [48, 54], [55, 63], [64, 66], [67, 70], [71, 76], [76, 77], [77, 81], [82, 88], [89, 96], [97, 98], [98, 102], [102, 103], [104, 106], [107, 111], [112, 114], [115, 119], [120, 130], [131, 134], [135, 141], [142, 153], [153, 154]]}
{"doc_key": "ai-train-27", "ner": [[4, 5, "programlang"], [8, 9, "product"], [15, 15, "product"], [48, 48, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 4, 5, "general-affiliation", "", false, false], [8, 9, 15, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "inclusion", "of", "a", "C", "++", "interpreter", "(", "CI", "NT", "up", "to", "version", "5.34", ",", "Cling", "from", "version", "6", "onwards", ")", "makes", "this", "package", "very", "versatile", ",", "as", "it", "can", "be", "used", "in", "interactive", ",", "scripting", "and", "compiled", "modes", "in", "a", "similar", "way", "to", "commercial", "products", "such", "as", "MATLAB", "."], "sentence-detokenized": "The inclusion of a C++ interpreter (CINT up to version 5.34, Cling from version 6 onwards) makes this package very versatile, as it can be used in interactive, scripting and compiled modes in a similar way to commercial products such as MATLAB.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 18], [19, 20], [20, 22], [23, 34], [35, 36], [36, 38], [38, 40], [41, 43], [44, 46], [47, 54], [55, 59], [59, 60], [61, 66], [67, 71], [72, 79], [80, 81], [82, 89], [89, 90], [91, 96], [97, 101], [102, 109], [110, 114], [115, 124], [124, 125], [126, 128], [129, 131], [132, 135], [136, 138], [139, 143], [144, 146], [147, 158], [158, 159], [160, 169], [170, 173], [174, 182], [183, 188], [189, 191], [192, 193], [194, 201], [202, 205], [206, 208], [209, 219], [220, 228], [229, 233], [234, 236], [237, 243], [243, 244]]}
{"doc_key": "ai-train-28", "ner": [[0, 2, "product"], [21, 23, "field"], [27, 28, "task"], [30, 32, "task"], [34, 35, "task"], [37, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 21, 23, "related-to", "", false, false], [27, 28, 21, 23, "part-of", "", false, false], [30, 32, 21, 23, "part-of", "", false, false], [34, 35, 21, 23, "part-of", "", false, false], [37, 38, 21, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Speech", "user", "interfaces", "that", "interpret", "and", "manage", "conversational", "state", "are", "a", "design", "challenge", "due", "to", "the", "inherent", "difficulty", "of", "integrating", "complex", "natural", "language", "processing", "tasks", "such", "as", "coreference", "resolution", ",", "named", "entity", "recognition", ",", "information", "retrieval", "and", "dialogue", "management", "."], "sentence-detokenized": "Speech user interfaces that interpret and manage conversational state are a design challenge due to the inherent difficulty of integrating complex natural language processing tasks such as coreference resolution, named entity recognition, information retrieval and dialogue management.", "token2charspan": [[0, 6], [7, 11], [12, 22], [23, 27], [28, 37], [38, 41], [42, 48], [49, 63], [64, 69], [70, 73], [74, 75], [76, 82], [83, 92], [93, 96], [97, 99], [100, 103], [104, 112], [113, 123], [124, 126], [127, 138], [139, 146], [147, 154], [155, 163], [164, 174], [175, 180], [181, 185], [186, 188], [189, 200], [201, 211], [211, 212], [213, 218], [219, 225], [226, 237], [237, 238], [239, 250], [251, 260], [261, 264], [265, 273], [274, 284], [284, 285]]}
{"doc_key": "ai-train-29", "ner": [[5, 7, "algorithm"], [9, 13, "algorithm"], [17, 18, "researcher"], [24, 27, "organisation"], [34, 35, "field"], [37, 38, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 7, 17, 18, "origin", "", false, false], [5, 7, 34, 35, "part-of", "", false, false], [5, 7, 37, 38, "part-of", "", false, false], [9, 13, 17, 18, "origin", "", false, false], [9, 13, 34, 35, "part-of", "", false, false], [9, 13, 37, 38, "part-of", "", false, false], [17, 18, 24, 27, "physical", "", false, false], [17, 18, 24, 27, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Between", "2009", "and", "2012", ",", "recurrent", "neural", "networks", "and", "feed", "-", "forward", "deep", "neural", "networks", "developed", "in", "J\u00fcrgen", "Schmidhuber", "'s", "research", "group", "at", "the", "Swiss", "AI", "lab", "IDSIA", "have", "won", "eight", "international", "competitions", "in", "pattern", "recognition", "and", "machine", "learning", "."], "sentence-detokenized": "Between 2009 and 2012, recurrent neural networks and feed-forward deep neural networks developed in J\u00fcrgen Schmidhuber's research group at the Swiss AI lab IDSIA have won eight international competitions in pattern recognition and machine learning.", "token2charspan": [[0, 7], [8, 12], [13, 16], [17, 21], [21, 22], [23, 32], [33, 39], [40, 48], [49, 52], [53, 57], [57, 58], [58, 65], [66, 70], [71, 77], [78, 86], [87, 96], [97, 99], [100, 106], [107, 118], [118, 120], [121, 129], [130, 135], [136, 138], [139, 142], [143, 148], [149, 151], [152, 155], [156, 161], [162, 166], [167, 170], [171, 176], [177, 190], [191, 203], [204, 206], [207, 214], [215, 226], [227, 230], [231, 238], [239, 247], [247, 248]]}
{"doc_key": "ai-train-30", "ner": [[1, 3, "product"], [6, 7, "product"], [9, 10, "product"], [14, 17, "task"], [16, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 6, 7, "usage", "", false, false], [1, 3, 9, 10, "usage", "", false, false], [1, 3, 14, 17, "usage", "", true, false], [1, 3, 16, 16, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Modern", "Windows", "desktop", "systems", "can", "use", "SAPI", "4", "and", "SAPI", "5", "components", "to", "support", "speech", "and", "speech", "synthesis", "."], "sentence-detokenized": "Modern Windows desktop systems can use SAPI 4 and SAPI 5 components to support speech and speech synthesis.", "token2charspan": [[0, 6], [7, 14], [15, 22], [23, 30], [31, 34], [35, 38], [39, 43], [44, 45], [46, 49], [50, 54], [55, 56], [57, 67], [68, 70], [71, 78], [79, 85], [86, 89], [90, 96], [97, 106], [106, 107]]}
{"doc_key": "ai-train-31", "ner": [[7, 12, "misc"], [14, 14, "field"], [17, 19, "university"], [26, 29, "field"], [31, 35, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 12, 14, 14, "topic", "topic_of_award", false, false], [7, 12, 17, 19, "origin", "", true, false], [26, 29, 31, 35, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "received", "two", "honorary", "degrees", ",", "an", "S.", "V.", "della", "laurea", "ad", "honorem", "in", "Psychology", "from", "the", "University", "of", "Padua", "in", "1995", "and", "a", "PhD", "in", "Industrial", "Design", "and", "Engineering", "from", "the", "Delft", "University", "of", "Technology", "."], "sentence-detokenized": "He received two honorary degrees, an S. V. della laurea ad honorem in Psychology from the University of Padua in 1995 and a PhD in Industrial Design and Engineering from the Delft University of Technology.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 24], [25, 32], [32, 33], [34, 36], [37, 39], [40, 42], [43, 48], [49, 55], [56, 58], [59, 66], [67, 69], [70, 80], [81, 85], [86, 89], [90, 100], [101, 103], [104, 109], [110, 112], [113, 117], [118, 121], [122, 123], [124, 127], [128, 130], [131, 141], [142, 148], [149, 152], [153, 164], [165, 169], [170, 173], [174, 179], [180, 190], [191, 193], [194, 204], [204, 205]]}
{"doc_key": "ai-train-32", "ner": [[4, 7, "researcher"], [11, 14, "organisation"], [16, 16, "location"], [18, 18, "researcher"], [29, 30, "misc"], [43, 45, "misc"], [61, 62, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 7, 11, 14, "physical", "", false, false], [4, 7, 11, 14, "role", "", false, false], [11, 14, 16, 16, "physical", "", false, false], [18, 18, 29, 30, "related-to", "works_with", true, false], [18, 18, 43, 45, "related-to", "works_with", true, false], [18, 18, 61, 62, "related-to", "works_with", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["With", "his", "former", "collaborator", "Laurent", "Cohen", ",", "a", "neurologist", "at", "the", "Piti\u00e9", "-", "Salp\u00eatri\u00e8re", "Hospital", "in", "Paris", ",", "Dehaene", "also", "identified", "patients", "with", "lesions", "in", "different", "regions", "of", "the", "parietal", "lobe", "with", "impaired", "multiplication", "but", "preserved", "subtraction", "(", "associated", "with", "lesions", "of", "the", "inferior", "parietal", "lobe", ")", "and", "others", "with", "impaired", "subtraction", "but", "preserved", "multiplication", "(", "associated", "with", "lesions", "of", "the", "intraparietal", "sulcus", ")", "."], "sentence-detokenized": "With his former collaborator Laurent Cohen, a neurologist at the Piti\u00e9-Salp\u00eatri\u00e8re Hospital in Paris, Dehaene also identified patients with lesions in different regions of the parietal lobe with impaired multiplication but preserved subtraction (associated with lesions of the inferior parietal lobe) and others with impaired subtraction but preserved multiplication (associated with lesions of the intraparietal sulcus).", "token2charspan": [[0, 4], [5, 8], [9, 15], [16, 28], [29, 36], [37, 42], [42, 43], [44, 45], [46, 57], [58, 60], [61, 64], [65, 70], [70, 71], [71, 82], [83, 91], [92, 94], [95, 100], [100, 101], [102, 109], [110, 114], [115, 125], [126, 134], [135, 139], [140, 147], [148, 150], [151, 160], [161, 168], [169, 171], [172, 175], [176, 184], [185, 189], [190, 194], [195, 203], [204, 218], [219, 222], [223, 232], [233, 244], [245, 246], [246, 256], [257, 261], [262, 269], [270, 272], [273, 276], [277, 285], [286, 294], [295, 299], [299, 300], [301, 304], [305, 311], [312, 316], [317, 325], [326, 337], [338, 341], [342, 351], [352, 366], [367, 368], [368, 378], [379, 383], [384, 391], [392, 394], [395, 398], [399, 412], [413, 419], [419, 420], [420, 421]]}
{"doc_key": "ai-train-33", "ner": [[6, 8, "product"], [13, 14, "misc"], [16, 17, "misc"], [24, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 14, 6, 8, "topic", "", false, false], [16, 17, 6, 8, "topic", "", false, false], [24, 24, 6, 8, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["More", "recently", ",", "fictionalised", "depictions", "of", "artificially", "intelligent", "robots", "in", "films", "such", "as", "Artificial", "Intelligence", "and", "Ex", "Machina", "and", "the", "2016", "television", "adaptation", "of", "Westworld", "have", "sparked", "public", "sympathy", "for", "the", "robots", "themselves", "."], "sentence-detokenized": "More recently, fictionalised depictions of artificially intelligent robots in films such as Artificial Intelligence and Ex Machina and the 2016 television adaptation of Westworld have sparked public sympathy for the robots themselves.", "token2charspan": [[0, 4], [5, 13], [13, 14], [15, 28], [29, 39], [40, 42], [43, 55], [56, 67], [68, 74], [75, 77], [78, 83], [84, 88], [89, 91], [92, 102], [103, 115], [116, 119], [120, 122], [123, 130], [131, 134], [135, 138], [139, 143], [144, 154], [155, 165], [166, 168], [169, 178], [179, 183], [184, 191], [192, 198], [199, 207], [208, 211], [212, 215], [216, 222], [223, 233], [233, 234]]}
{"doc_key": "ai-train-34", "ner": [[7, 8, "field"], [10, 12, "algorithm"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 12, 7, 8, "part-of", "", false, false], [14, 15, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "of", "the", "main", "methods", "used", "in", "unsupervised", "learning", "are", "principal", "component", "analysis", "and", "cluster", "analysis", "."], "sentence-detokenized": "Two of the main methods used in unsupervised learning are principal component analysis and cluster analysis.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 15], [16, 23], [24, 28], [29, 31], [32, 44], [45, 53], [54, 57], [58, 67], [68, 77], [78, 86], [87, 90], [91, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-train-35", "ner": [[0, 3, "organisation"], [24, 25, "misc"], [30, 31, "misc"], [33, 35, "person"], [40, 41, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[24, 25, 0, 3, "artifact", "", false, false], [30, 31, 0, 3, "artifact", "", false, false], [30, 31, 33, 35, "role", "director_of", false, false], [30, 31, 40, 41, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Walt", "Disney", "Company", "also", "began", "to", "make", "more", "prominent", "use", "of", "3D", "films", "in", "special", "locations", "to", "impress", "audiences", ",", "notable", "examples", "being", "Magic", "Journeys", "(", "1982", ")", "and", "Captain", "EO", "(", "Francis", "Ford", "Coppola", ",", "1986", ",", "starring", "Michael", "Jackson", ")", "."], "sentence-detokenized": "The Walt Disney Company also began to make more prominent use of 3D films in special locations to impress audiences, notable examples being Magic Journeys (1982) and Captain EO (Francis Ford Coppola, 1986, starring Michael Jackson).", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 23], [24, 28], [29, 34], [35, 37], [38, 42], [43, 47], [48, 57], [58, 61], [62, 64], [65, 67], [68, 73], [74, 76], [77, 84], [85, 94], [95, 97], [98, 105], [106, 115], [115, 116], [117, 124], [125, 133], [134, 139], [140, 145], [146, 154], [155, 156], [156, 160], [160, 161], [162, 165], [166, 173], [174, 176], [177, 178], [178, 185], [186, 190], [191, 198], [198, 199], [200, 204], [204, 205], [206, 214], [215, 222], [223, 230], [230, 231], [231, 232]]}
{"doc_key": "ai-train-36", "ner": [[12, 14, "field"], [19, 24, "task"], [26, 26, "task"], [28, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 24, 12, 14, "part-of", "", false, false], [26, 26, 12, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Since", "2002", ",", "perceptron", "training", "has", "become", "popular", "in", "the", "field", "of", "natural", "language", "processing", "for", "tasks", "such", "as", "part", "-", "of", "-", "speech", "labelling", "and", "parsing", "(", "Collins", ",", "2002", ")", "."], "sentence-detokenized": "Since 2002, perceptron training has become popular in the field of natural language processing for tasks such as part-of-speech labelling and parsing (Collins, 2002).", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 22], [23, 31], [32, 35], [36, 42], [43, 50], [51, 53], [54, 57], [58, 63], [64, 66], [67, 74], [75, 83], [84, 94], [95, 98], [99, 104], [105, 109], [110, 112], [113, 117], [117, 118], [118, 120], [120, 121], [121, 127], [128, 137], [138, 141], [142, 149], [150, 151], [151, 158], [158, 159], [160, 164], [164, 165], [165, 166]]}
{"doc_key": "ai-train-37", "ner": [[2, 3, "product"], [10, 14, "organisation"], [16, 17, "organisation"], [19, 19, "country"], [23, 26, "product"], [30, 31, "researcher"], [41, 41, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 14, 2, 3, "role", "introduces_to_market", true, false], [16, 17, 2, 3, "role", "introduces_to_market", true, false], [16, 17, 19, 19, "physical", "", false, false], [23, 26, 41, 41, "related-to", "sold_to", true, false], [30, 31, 23, 26, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "first", "palletising", "robot", "was", "introduced", "in", "1963", "by", "the", "company", "Fuji", "Yusoki", "Kogyo", ".", "by", "KUKA", "robotics", "in", "Germany", ",", "and", "the", "programmable", "universal", "assembly", "machine", "was", "invented", "by", "Victor", "Scheinman", "in", "1976", ",", "and", "the", "design", "was", "sold", "to", "Unimation", "."], "sentence-detokenized": "The first palletising robot was introduced in 1963 by the company Fuji Yusoki Kogyo. by KUKA robotics in Germany, and the programmable universal assembly machine was invented by Victor Scheinman in 1976, and the design was sold to Unimation.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 27], [28, 31], [32, 42], [43, 45], [46, 50], [51, 53], [54, 57], [58, 65], [66, 70], [71, 77], [78, 83], [83, 84], [85, 87], [88, 92], [93, 101], [102, 104], [105, 112], [112, 113], [114, 117], [118, 121], [122, 134], [135, 144], [145, 153], [154, 161], [162, 165], [166, 174], [175, 177], [178, 184], [185, 194], [195, 197], [198, 202], [202, 203], [204, 207], [208, 211], [212, 218], [219, 222], [223, 227], [228, 230], [231, 240], [240, 241]]}
{"doc_key": "ai-train-38", "ner": [[7, 8, "conference"], [10, 10, "researcher"], [17, 17, "field"], [38, 39, "researcher"], [46, 49, "researcher"], [60, 60, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 10, 7, 8, "role", "president_of", false, false], [10, 10, 38, 39, "role", "colleagues", false, false], [17, 17, 60, 60, "named", "same", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "mid-1990s", ",", "while", "president", "of", "the", "AAAI", ",", "Hayes", "initiated", "a", "series", "of", "attacks", "on", "AI", "critics", ",", "almost", "always", "couched", "in", "a", "tongue", "-", "in", "-", "cheek", "tone", ",", "and", "(", "along", "with", "his", "colleague", "Kenneth", "Ford", ")", "invented", "a", "prize", "named", "after", "Simon", "Newcomb", "to", "be", "awarded", "to", "the", "most", "ridiculous", "argument", "refuting", "the", "possibility", "of", "AI", "."], "sentence-detokenized": "In the mid-1990s, while president of the AAAI, Hayes initiated a series of attacks on AI critics, almost always couched in a tongue-in-cheek tone, and (along with his colleague Kenneth Ford) invented a prize named after Simon Newcomb to be awarded to the most ridiculous argument refuting the possibility of AI.", "token2charspan": [[0, 2], [3, 6], [7, 16], [16, 17], [18, 23], [24, 33], [34, 36], [37, 40], [41, 45], [45, 46], [47, 52], [53, 62], [63, 64], [65, 71], [72, 74], [75, 82], [83, 85], [86, 88], [89, 96], [96, 97], [98, 104], [105, 111], [112, 119], [120, 122], [123, 124], [125, 131], [131, 132], [132, 134], [134, 135], [135, 140], [141, 145], [145, 146], [147, 150], [151, 152], [152, 157], [158, 162], [163, 166], [167, 176], [177, 184], [185, 189], [189, 190], [191, 199], [200, 201], [202, 207], [208, 213], [214, 219], [220, 225], [226, 233], [234, 236], [237, 239], [240, 247], [248, 250], [251, 254], [255, 259], [260, 270], [271, 279], [280, 288], [289, 292], [293, 304], [305, 307], [308, 310], [310, 311]]}
{"doc_key": "ai-train-39", "ner": [[12, 16, "algorithm"], [36, 37, "algorithm"], [48, 50, "algorithm"], [54, 56, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 16, 36, 37, "named", "same", false, false], [48, 50, 12, 16, "type-of", "", false, false], [54, 56, 12, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["An", "optimal", "value", "for", "math\\alpha/", "math", "can", "be", "found", "by", "using", "a", "line", "search", "algorithm", ",", "i.e.", "the", "magnitude", "of", "math\\alpha/", "math", "is", "determined", "by", "searching", "for", "the", "value", "that", "minimises", "S", ",", "typically", "using", "a", "line", "search", "in", "the", "interval", "math\\", "alpha", "1", "/", "math", "or", "a", "backward", "line", "search", "such", "as", "the", "Armijo", "line", "search", "."], "sentence-detokenized": "An optimal value for math\\alpha/math can be found by using a line search algorithm, i.e. the magnitude of math\\alpha/math is determined by searching for the value that minimises S, typically using a line search in the interval math\\alpha 1/math or a backward line search such as the Armijo line search.", "token2charspan": [[0, 2], [3, 10], [11, 16], [17, 20], [21, 32], [32, 36], [37, 40], [41, 43], [44, 49], [50, 52], [53, 58], [59, 60], [61, 65], [66, 72], [73, 82], [82, 83], [84, 88], [89, 92], [93, 102], [103, 105], [106, 117], [117, 121], [122, 124], [125, 135], [136, 138], [139, 148], [149, 152], [153, 156], [157, 162], [163, 167], [168, 177], [178, 179], [179, 180], [181, 190], [191, 196], [197, 198], [199, 203], [204, 210], [211, 213], [214, 217], [218, 226], [227, 232], [232, 237], [238, 239], [239, 240], [240, 244], [245, 247], [248, 249], [250, 258], [259, 263], [264, 270], [271, 275], [276, 278], [279, 282], [283, 289], [290, 294], [295, 301], [301, 302]]}
{"doc_key": "ai-train-40", "ner": [[2, 9, "algorithm"], [6, 8, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "discusses", "Breadth", "-", "first", "and", "Depth", "-", "first", "search", "techniques", ",", "but", "ultimately", "concludes", "that", "the", "results", "represent", "expert", "systems", "that", "embody", "a", "lot", "of", "technical", "knowledge", ",", "but", "do", "not", "shed", "much", "light", "on", "the", "mental", "processes", "that", "humans", "use", "to", "solve", "these", "puzzles", "."], "sentence-detokenized": "He discusses Breadth-first and Depth-first search techniques, but ultimately concludes that the results represent expert systems that embody a lot of technical knowledge, but do not shed much light on the mental processes that humans use to solve these puzzles.", "token2charspan": [[0, 2], [3, 12], [13, 20], [20, 21], [21, 26], [27, 30], [31, 36], [36, 37], [37, 42], [43, 49], [50, 60], [60, 61], [62, 65], [66, 76], [77, 86], [87, 91], [92, 95], [96, 103], [104, 113], [114, 120], [121, 128], [129, 133], [134, 140], [141, 142], [143, 146], [147, 149], [150, 159], [160, 169], [169, 170], [171, 174], [175, 177], [178, 181], [182, 186], [187, 191], [192, 197], [198, 200], [201, 204], [205, 211], [212, 221], [222, 226], [227, 233], [234, 237], [238, 240], [241, 246], [247, 252], [253, 260], [260, 261]]}
{"doc_key": "ai-train-41", "ner": [[1, 1, "task"], [0, 4, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Speech", "recognition", "and", "speech", "synthesis", "are", "concerned", "with", "how", "spoken", "language", "can", "be", "understood", "or", "created", "by", "computers", "."], "sentence-detokenized": "Speech recognition and speech synthesis are concerned with how spoken language can be understood or created by computers.", "token2charspan": [[0, 6], [7, 18], [19, 22], [23, 29], [30, 39], [40, 43], [44, 53], [54, 58], [59, 62], [63, 69], [70, 78], [79, 82], [83, 85], [86, 96], [97, 99], [100, 107], [108, 110], [111, 120], [120, 121]]}
{"doc_key": "ai-train-42", "ner": [[14, 15, "algorithm"], [33, 35, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "math", "\\", "theta", "^", "{", "*}", "/", "math", "is", "usually", "estimated", "using", "a", "Maximum", "Likelihood", "(", "math", "\\", "theta", "^", "{", "*}", "=\\", "theta", "^", "{", "ML", "}", "/", "math", ")", "or", "Maximum", "A", "Posteriori", "(", "math", "\\", "theta", "^", "{", "*}", "=\\", "theta", "^", "{", "MAP", "}", "/", "math", ")", "procedure", "."], "sentence-detokenized": "This math\\ theta ^ {*} / math is usually estimated using a Maximum Likelihood (math\\ theta ^ {*} =\\ theta ^ {ML} / math) or Maximum A Posteriori (math\\ theta ^ {*} =\\ theta ^ {MAP} / math) procedure.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 16], [17, 18], [19, 20], [20, 22], [23, 24], [25, 29], [30, 32], [33, 40], [41, 50], [51, 56], [57, 58], [59, 66], [67, 77], [78, 79], [79, 83], [83, 84], [85, 90], [91, 92], [93, 94], [94, 96], [97, 99], [100, 105], [106, 107], [108, 109], [109, 111], [111, 112], [113, 114], [115, 119], [119, 120], [121, 123], [124, 131], [132, 133], [134, 144], [145, 146], [146, 150], [150, 151], [152, 157], [158, 159], [160, 161], [161, 163], [164, 166], [167, 172], [173, 174], [175, 176], [176, 179], [179, 180], [181, 182], [183, 187], [187, 188], [189, 198], [198, 199]]}
{"doc_key": "ai-train-43", "ner": [[9, 10, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "less", "widely", "spoken", "languages", "use", "the", "open", "source", "eSpeak", "synthesiser", "for", "their", "speech", ",", "producing", "a", "clunky", ",", "robotic", "voice", "that", "can", "be", "difficult", "to", "understand", "."], "sentence-detokenized": "Some less widely spoken languages use the open source eSpeak synthesiser for their speech, producing a clunky, robotic voice that can be difficult to understand.", "token2charspan": [[0, 4], [5, 9], [10, 16], [17, 23], [24, 33], [34, 37], [38, 41], [42, 46], [47, 53], [54, 60], [61, 72], [73, 76], [77, 82], [83, 89], [89, 90], [91, 100], [101, 102], [103, 109], [109, 110], [111, 118], [119, 124], [125, 129], [130, 133], [134, 136], [137, 146], [147, 149], [150, 160], [160, 161]]}
{"doc_key": "ai-train-44", "ner": [[19, 19, "programlang"], [34, 35, "programlang"], [37, 37, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 19, 34, 35, "compare", "", false, false], [19, 19, 37, 37, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Although", "primarily", "used", "by", "statisticians", "and", "other", "professionals", "who", "need", "an", "environment", "for", "statistical", "computing", "and", "software", "development", ",", "R", "can", "also", "function", "as", "a", "general", "matrix", "computing", "toolbox", ",", "with", "performance", "comparable", "to", "GNU", "Octave", "or", "MATLAB", "."], "sentence-detokenized": "Although primarily used by statisticians and other professionals who need an environment for statistical computing and software development, R can also function as a general matrix computing toolbox, with performance comparable to GNU Octave or MATLAB.", "token2charspan": [[0, 8], [9, 18], [19, 23], [24, 26], [27, 40], [41, 44], [45, 50], [51, 64], [65, 68], [69, 73], [74, 76], [77, 88], [89, 92], [93, 104], [105, 114], [115, 118], [119, 127], [128, 139], [139, 140], [141, 142], [143, 146], [147, 151], [152, 160], [161, 163], [164, 165], [166, 173], [174, 180], [181, 190], [191, 198], [198, 199], [200, 204], [205, 216], [217, 227], [228, 230], [231, 234], [235, 241], [242, 244], [245, 251], [251, 252]]}
{"doc_key": "ai-train-45", "ner": [[0, 0, "algorithm"], [3, 4, "field"], [8, 11, "misc"], [12, 13, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 4, "part-of", "", false, false], [0, 0, 12, 13, "origin", "", false, false], [8, 11, 12, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Heterodyning", "is", "a", "signal", "processing", "technique", "invented", "by", "Canadian", "inventor", "-", "engineer", "Reginald", "Fessenden", "that", "creates", "new", "frequencies", "by", "combining", "the", "blending", "of", "two", "frequencies", "."], "sentence-detokenized": "Heterodyning is a signal processing technique invented by Canadian inventor-engineer Reginald Fessenden that creates new frequencies by combining the blending of two frequencies.", "token2charspan": [[0, 12], [13, 15], [16, 17], [18, 24], [25, 35], [36, 45], [46, 54], [55, 57], [58, 66], [67, 75], [75, 76], [76, 84], [85, 93], [94, 103], [104, 108], [109, 116], [117, 120], [121, 132], [133, 135], [136, 145], [146, 149], [150, 158], [159, 161], [162, 165], [166, 177], [177, 178]]}
{"doc_key": "ai-train-46", "ner": [[13, 14, "person"], [15, 16, "misc"], [20, 22, "organisation"], [25, 25, "organisation"], [27, 29, "misc"], [32, 33, "person"], [36, 36, "organisation"], [38, 40, "misc"], [43, 44, "person"], [46, 47, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[13, 14, 15, 16, "role", "actor_in", false, false], [15, 16, 20, 22, "artifact", "", false, false], [27, 29, 25, 25, "artifact", "", false, false], [32, 33, 27, 29, "role", "actor_in", false, false], [38, 40, 36, 36, "artifact", "", false, false], [43, 44, 38, 40, "role", "actor_in", false, false], [46, 47, 38, 40, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Other", "feature", "films", "that", "helped", "put", "3D", "on", "the", "map", "that", "month", "were", "John", "Wayne", "'s", "Hondo", "(", "distributed", "by", "Warner", "Bros", ".", ")", ",", "Columbia", "'s", "Miss", "Sadie", "Thompson", ",", "starring", "Rita", "Hayworth", ",", "and", "Paramount", "'s", "Money", "From", "Home", ",", "starring", "Dean", "Martin", "and", "Jerry", "Lewis", "."], "sentence-detokenized": "Other feature films that helped put 3D on the map that month were John Wayne's Hondo (distributed by Warner Bros.), Columbia's Miss Sadie Thompson, starring Rita Hayworth, and Paramount's Money From Home, starring Dean Martin and Jerry Lewis.", "token2charspan": [[0, 5], [6, 13], [14, 19], [20, 24], [25, 31], [32, 35], [36, 38], [39, 41], [42, 45], [46, 49], [50, 54], [55, 60], [61, 65], [66, 70], [71, 76], [76, 78], [79, 84], [85, 86], [86, 97], [98, 100], [101, 107], [108, 112], [112, 113], [113, 114], [114, 115], [116, 124], [124, 126], [127, 131], [132, 137], [138, 146], [146, 147], [148, 156], [157, 161], [162, 170], [170, 171], [172, 175], [176, 185], [185, 187], [188, 193], [194, 198], [199, 203], [203, 204], [205, 213], [214, 218], [219, 225], [226, 229], [230, 235], [236, 241], [241, 242]]}
{"doc_key": "ai-train-47", "ner": [[0, 0, "product"], [3, 4, "field"], [5, 6, "task"], [11, 11, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 6, "general-affiliation", "", false, false], [0, 0, 11, 11, "artifact", "", false, false], [5, 6, 3, 4, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["DeepFace", "is", "a", "deep", "learning", "facial", "recognition", "system", "created", "by", "a", "Facebook", "research", "group", "."], "sentence-detokenized": "DeepFace is a deep learning facial recognition system created by a Facebook research group.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 18], [19, 27], [28, 34], [35, 46], [47, 53], [54, 61], [62, 64], [65, 66], [67, 75], [76, 84], [85, 90], [90, 91]]}
{"doc_key": "ai-train-48", "ner": [[1, 1, "field"], [8, 8, "conference"], [15, 16, "field"], [0, 28, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 15, 16, "part-of", "subfield", false, false], [8, 8, 1, 1, "topic", "", false, false], [0, 28, 1, 1, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Geometry", "processing", "is", "a", "regular", "research", "topic", "at", "SIGGRAPH", ",", "the", "leading", "academic", "conference", "on", "computer", "graphics", ",", "and", "the", "main", "theme", "of", "the", "annual", "Symposium", "on", "Geometry", "Processing", "."], "sentence-detokenized": "Geometry processing is a regular research topic at SIGGRAPH, the leading academic conference on computer graphics, and the main theme of the annual Symposium on Geometry Processing.", "token2charspan": [[0, 8], [9, 19], [20, 22], [23, 24], [25, 32], [33, 41], [42, 47], [48, 50], [51, 59], [59, 60], [61, 64], [65, 72], [73, 81], [82, 92], [93, 95], [96, 104], [105, 113], [113, 114], [115, 118], [119, 122], [123, 127], [128, 133], [134, 136], [137, 140], [141, 147], [148, 157], [158, 160], [161, 169], [170, 180], [180, 181]]}
{"doc_key": "ai-train-49", "ner": [[0, 1, "task"], [3, 4, "task"], [13, 15, "algorithm"], [17, 17, "algorithm"], [20, 22, "algorithm"], [24, 24, "algorithm"], [27, 29, "algorithm"], [31, 35, "algorithm"], [36, 36, "misc"], [41, 43, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[13, 15, 36, 36, "general-affiliation", "", false, false], [17, 17, 13, 15, "named", "", false, false], [20, 22, 36, 36, "general-affiliation", "", false, false], [24, 24, 20, 22, "named", "", false, false], [27, 29, 36, 36, "general-affiliation", "", false, false], [31, 35, 27, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Feature", "extraction", "and", "dimension", "reduction", "can", "be", "combined", "in", "a", "single", "step", "using", "principal", "component", "analysis", "(", "PCA", ")", ",", "linear", "discriminant", "analysis", "(", "LDA", ")", "or", "canonical", "correlation", "analysis", "(", "CCA", ")", "techniques", "as", "a", "pre-processing", "step", ",", "followed", "by", "k", "-", "NNN", "clustering", "into", "feature", "vectors", "in", "the", "reduced", "dimension", "space", "."], "sentence-detokenized": "Feature extraction and dimension reduction can be combined in a single step using principal component analysis (PCA), linear discriminant analysis (LDA) or canonical correlation analysis (CCA) techniques as a pre-processing step, followed by k -NNN clustering into feature vectors in the reduced dimension space.", "token2charspan": [[0, 7], [8, 18], [19, 22], [23, 32], [33, 42], [43, 46], [47, 49], [50, 58], [59, 61], [62, 63], [64, 70], [71, 75], [76, 81], [82, 91], [92, 101], [102, 110], [111, 112], [112, 115], [115, 116], [116, 117], [118, 124], [125, 137], [138, 146], [147, 148], [148, 151], [151, 152], [153, 155], [156, 165], [166, 177], [178, 186], [187, 188], [188, 191], [191, 192], [193, 203], [204, 206], [207, 208], [209, 223], [224, 228], [228, 229], [230, 238], [239, 241], [242, 243], [244, 245], [245, 248], [249, 259], [260, 264], [265, 272], [273, 280], [281, 283], [284, 287], [288, 295], [296, 305], [306, 311], [311, 312]]}
{"doc_key": "ai-train-50", "ner": [[0, 2, "algorithm"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 9, 10, "related-to", "good_at", true, false], [0, 2, 12, 13, "related-to", "good_at", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Artificial", "neural", "networks", "are", "computational", "models", "that", "excel", "in", "machine", "learning", "and", "pattern", "recognition", "."], "sentence-detokenized": "Artificial neural networks are computational models that excel in machine learning and pattern recognition.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 30], [31, 44], [45, 51], [52, 56], [57, 62], [63, 65], [66, 73], [74, 82], [83, 86], [87, 94], [95, 106], [106, 107]]}
{"doc_key": "ai-train-51", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 11, "misc"], [13, 17, "conference"], [19, 19, "conference"], [36, 37, "algorithm"], [41, 42, "researcher"], [44, 46, "researcher"], [38, 54, "misc"], [56, 65, "conference"], [67, 67, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[7, 11, 0, 2, "artifact", "", false, false], [7, 11, 4, 5, "artifact", "", false, false], [7, 11, 13, 17, "temporal", "", false, false], [19, 19, 13, 17, "named", "", false, false], [38, 54, 36, 37, "topic", "", false, false], [38, 54, 41, 42, "artifact", "", false, false], [38, 54, 44, 46, "artifact", "", false, false], [38, 54, 56, 65, "temporal", "", false, false], [67, 67, 56, 65, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["C", ".", "Papageorgiou", "and", "T.", "Poggio", ",", "A", "Trainable", "Pedestrian", "Detection", "system", ",", "International", "Journal", "of", "Computer", "Vision", "(", "IJCV", ")", ",", "pages", "1", ":", "15", "-", "33", ",", "2000", "others", "use", "local", "features", "such", "as", "the", "histogram", "of", "oriented", "gradients", "N.", "Dalal", ",", "B", ".", "Triggs", ",", "Histograms", "of", "oriented", "gradients", "for", "human", "detection", ",", "IEEE", "Computer", "Society", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", ",", "pages", "1", ":", "886-893", ",", "2005", "descriptors", "."], "sentence-detokenized": "C. Papageorgiou and T. Poggio, A Trainable Pedestrian Detection system, International Journal of Computer Vision (IJCV), pages 1: 15-33, 2000 others use local features such as the histogram of oriented gradients N. Dalal, B. Triggs, Histograms of oriented gradients for human detection, IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), pages 1: 886-893, 2005 descriptors.", "token2charspan": [[0, 1], [1, 2], [3, 15], [16, 19], [20, 22], [23, 29], [29, 30], [31, 32], [33, 42], [43, 53], [54, 63], [64, 70], [70, 71], [72, 85], [86, 93], [94, 96], [97, 105], [106, 112], [113, 114], [114, 118], [118, 119], [119, 120], [121, 126], [127, 128], [128, 129], [130, 132], [132, 133], [133, 135], [135, 136], [137, 141], [142, 148], [149, 152], [153, 158], [159, 167], [168, 172], [173, 175], [176, 179], [180, 189], [190, 192], [193, 201], [202, 211], [212, 214], [215, 220], [220, 221], [222, 223], [223, 224], [225, 231], [231, 232], [233, 243], [244, 246], [247, 255], [256, 265], [266, 269], [270, 275], [276, 285], [285, 286], [287, 291], [292, 300], [301, 308], [309, 319], [320, 322], [323, 331], [332, 338], [339, 342], [343, 350], [351, 362], [363, 364], [364, 368], [368, 369], [369, 370], [371, 376], [377, 378], [378, 379], [380, 387], [387, 388], [389, 393], [394, 405], [405, 406]]}
{"doc_key": "ai-train-52", "ner": [[1, 1, "algorithm"], [6, 9, "algorithm"], [15, 16, "task"], [14, 14, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 6, 9, "type-of", "", false, false], [15, 16, 1, 1, "usage", "", true, false], [15, 16, 14, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["An", "autoencoder", "is", "a", "type", "of", "artificial", "neural", "network", "that", "is", "used", "to", "learn", "unsupervised", "feature", "learning", "."], "sentence-detokenized": "An autoencoder is a type of artificial neural network that is used to learn unsupervised feature learning.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 19], [20, 24], [25, 27], [28, 38], [39, 45], [46, 53], [54, 58], [59, 61], [62, 66], [67, 69], [70, 75], [76, 88], [89, 96], [97, 105], [105, 106]]}
{"doc_key": "ai-train-53", "ner": [[0, 0, "researcher"], [6, 6, "organisation"], [14, 15, "field"], [17, 19, "field"], [24, 28, "organisation"], [30, 30, "organisation"], [36, 37, "field"], [39, 40, "field"], [45, 45, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 6, 6, "role", "fellow_of", false, false], [0, 0, 14, 15, "related-to", "contributes_to", false, false], [0, 0, 17, 19, "related-to", "contributes_to", false, false], [0, 0, 24, 28, "role", "fellow_of", false, false], [0, 0, 36, 37, "related-to", "contributes_to", false, false], [0, 0, 39, 40, "related-to", "contributes_to", false, false], [30, 30, 24, 28, "named", "", false, false], [45, 45, 24, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Haralick", "is", "a", "Fellow", "of", "the", "IEEE", "for", "his", "contributions", "in", "the", "field", "of", "computer", "vision", "and", "image", "processing", "and", "a", "member", "of", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", "for", "his", "contributions", "in", "pattern", "recognition", ",", "image", "processing", "and", "service", "to", "the", "IAPR", "."], "sentence-detokenized": "Haralick is a Fellow of the IEEE for his contributions in the field of computer vision and image processing and a member of the International Association for Pattern Recognition (IAPR) for his contributions in pattern recognition, image processing and service to the IAPR.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 20], [21, 23], [24, 27], [28, 32], [33, 36], [37, 40], [41, 54], [55, 57], [58, 61], [62, 67], [68, 70], [71, 79], [80, 86], [87, 90], [91, 96], [97, 107], [108, 111], [112, 113], [114, 120], [121, 123], [124, 127], [128, 141], [142, 153], [154, 157], [158, 165], [166, 177], [178, 179], [179, 183], [183, 184], [185, 188], [189, 192], [193, 206], [207, 209], [210, 217], [218, 229], [229, 230], [231, 236], [237, 247], [248, 251], [252, 259], [260, 262], [263, 266], [267, 271], [271, 272]]}
{"doc_key": "ai-train-54", "ner": [[4, 9, "task"], [12, 14, "algorithm"], [16, 16, "algorithm"], [23, 24, "researcher"], [26, 27, "organisation"], [29, 30, "researcher"], [33, 35, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 9, 12, 14, "usage", "", false, false], [12, 14, 23, 24, "origin", "", true, false], [12, 14, 29, 30, "origin", "", true, false], [16, 16, 12, 14, "named", "", false, false], [23, 24, 26, 27, "physical", "", false, false], [23, 24, 26, 27, "role", "", false, false], [29, 30, 33, 35, "physical", "", false, false], [29, 30, 33, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "first", "attempt", "at", "end", "-", "to", "-", "end", "ASR", "was", "with", "connectionist", "temporal", "classification", "(", "CTC", ")", "-", "based", "systems", "introduced", "by", "Alex", "Graves", "of", "Google", "DeepMind", "and", "Navdeep", "Jaitly", "of", "the", "University", "of", "Toronto", "in", "2014", "."], "sentence-detokenized": "The first attempt at end-to-end ASR was with connectionist temporal classification (CTC)-based systems introduced by Alex Graves of Google DeepMind and Navdeep Jaitly of the University of Toronto in 2014.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 20], [21, 24], [24, 25], [25, 27], [27, 28], [28, 31], [32, 35], [36, 39], [40, 44], [45, 58], [59, 67], [68, 82], [83, 84], [84, 87], [87, 88], [88, 89], [89, 94], [95, 102], [103, 113], [114, 116], [117, 121], [122, 128], [129, 131], [132, 138], [139, 147], [148, 151], [152, 159], [160, 166], [167, 169], [170, 173], [174, 184], [185, 187], [188, 195], [196, 198], [199, 203], [203, 204]]}
{"doc_key": "ai-train-55", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [10, 11, "algorithm"], [13, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 0, 2, "named", "", false, false], [10, 11, 0, 2, "type-of", "", false, false], [13, 13, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Fractional", "linear", "programming", "(", "FLC", ")", "is", "a", "generalisation", "of", "linear", "programming", "(", "LP", ")", "."], "sentence-detokenized": "Fractional linear programming (FLC) is a generalisation of linear programming (LP).", "token2charspan": [[0, 10], [11, 17], [18, 29], [30, 31], [31, 34], [34, 35], [36, 38], [39, 40], [41, 55], [56, 58], [59, 65], [66, 77], [78, 79], [79, 81], [81, 82], [82, 83]]}
{"doc_key": "ai-train-56", "ner": [[0, 0, "researcher"], [7, 12, "misc"], [15, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 7, 12, "win-defeat", "", false, false], [7, 12, 15, 22, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lafferty", "received", "numerous", "awards", ",", "including", "two", "Test", "-", "of", "-", "Time", "awards", "at", "the", "International", "Conference", "on", "Machine", "Learning", "2011", "and", "2012", ","], "sentence-detokenized": "Lafferty received numerous awards, including two Test-of-Time awards at the International Conference on Machine Learning 2011 and 2012,", "token2charspan": [[0, 8], [9, 17], [18, 26], [27, 33], [33, 34], [35, 44], [45, 48], [49, 53], [53, 54], [54, 56], [56, 57], [57, 61], [62, 68], [69, 71], [72, 75], [76, 89], [90, 100], [101, 103], [104, 111], [112, 120], [121, 125], [126, 129], [130, 134], [134, 135]]}
{"doc_key": "ai-train-57", "ner": [[11, 11, "product"], [13, 13, "programlang"], [25, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["With", "the", "advent", "of", "component", "-", "based", "frameworks", ",", "such", "as", ".NET", "and", "Java", ",", "component", "-", "based", "development", "environments", "are", "able", "to", "deploy", "the", "neural", "network", "developed", "in", "these", "frameworks", "as", "inheritable", "components", "."], "sentence-detokenized": "With the advent of component-based frameworks, such as .NET and Java, component-based development environments are able to deploy the neural network developed in these frameworks as inheritable components.", "token2charspan": [[0, 4], [5, 8], [9, 15], [16, 18], [19, 28], [28, 29], [29, 34], [35, 45], [45, 46], [47, 51], [52, 54], [55, 59], [60, 63], [64, 68], [68, 69], [70, 79], [79, 80], [80, 85], [86, 97], [98, 110], [111, 114], [115, 119], [120, 122], [123, 129], [130, 133], [134, 140], [141, 148], [149, 158], [159, 161], [162, 167], [168, 178], [179, 181], [182, 193], [194, 204], [204, 205]]}
{"doc_key": "ai-train-58", "ner": [[5, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["As", "in", "the", "case", "of", "BLEU", ",", "the", "basic", "unit", "of", "evaluation", "is", "the", "sentence", ",", "the", "algorithm", "first", "creates", "an", "alignment", "(", "see", "illustrations", ")", "between", "two", "sentences", ",", "the", "candidate", "translation", "string", "and", "the", "reference", "translation", "string", "."], "sentence-detokenized": "As in the case of BLEU, the basic unit of evaluation is the sentence, the algorithm first creates an alignment (see illustrations) between two sentences, the candidate translation string and the reference translation string.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 14], [15, 17], [18, 22], [22, 23], [24, 27], [28, 33], [34, 38], [39, 41], [42, 52], [53, 55], [56, 59], [60, 68], [68, 69], [70, 73], [74, 83], [84, 89], [90, 97], [98, 100], [101, 110], [111, 112], [112, 115], [116, 129], [129, 130], [131, 138], [139, 142], [143, 152], [152, 153], [154, 157], [158, 167], [168, 179], [180, 186], [187, 190], [191, 194], [195, 204], [205, 216], [217, 223], [223, 224]]}
{"doc_key": "ai-train-59", "ner": [[7, 11, "conference"], [21, 21, "task"], [23, 24, "task"], [28, 38, "metrics"], [30, 36, "metrics"], [41, 44, "conference"], [47, 47, "conference"], [50, 50, "location"], [52, 52, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 11, 21, 21, "related-to", "subject_at", false, false], [7, 11, 23, 24, "related-to", "subject_at", false, false], [28, 38, 7, 11, "temporal", "", false, false], [30, 36, 28, 38, "named", "", true, false], [47, 47, 41, 44, "named", "", false, false], [50, 50, 52, 52, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["One", "of", "the", "metrics", "used", "at", "the", "annual", "NIST", "document", "comprehension", "conferences", ",", "where", "research", "groups", "present", "their", "systems", "for", "both", "summarisation", "and", "translation", "tasks", ",", "is", "the", "ROUGE", "(", "Recall", "-", "Oriented", "Understudy", "for", "Gisting", "Evaluation", ")", "metric", ",", "in", "Neural", "Information", "Processing", "Systems", "Advances", "(", "NIPS", ")", ",", "Montreal", ",", "Canada", ",", "December", "-", "2014", "."], "sentence-detokenized": "One of the metrics used at the annual NIST document comprehension conferences, where research groups present their systems for both summarisation and translation tasks, is the ROUGE (Recall-Oriented Understudy for Gisting Evaluation) metric, in Neural Information Processing Systems Advances (NIPS), Montreal, Canada, December - 2014.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 18], [19, 23], [24, 26], [27, 30], [31, 37], [38, 42], [43, 51], [52, 65], [66, 77], [77, 78], [79, 84], [85, 93], [94, 100], [101, 108], [109, 114], [115, 122], [123, 126], [127, 131], [132, 145], [146, 149], [150, 161], [162, 167], [167, 168], [169, 171], [172, 175], [176, 181], [182, 183], [183, 189], [189, 190], [190, 198], [199, 209], [210, 213], [214, 221], [222, 232], [232, 233], [234, 240], [240, 241], [242, 244], [245, 251], [252, 263], [264, 274], [275, 282], [283, 291], [292, 293], [293, 297], [297, 298], [298, 299], [300, 308], [308, 309], [310, 316], [316, 317], [318, 326], [327, 328], [329, 333], [333, 334]]}
{"doc_key": "ai-train-60", "ner": [[6, 6, "programlang"], [8, 8, "product"], [10, 11, "programlang"], [15, 15, "product"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 10, 11, "type-of", "", false, false], [6, 6, 21, 21, "named", "", false, false], [8, 8, 10, 11, "part-of", "", false, false], [8, 8, 15, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Same", "implementation", ",", "to", "run", "in", "Java", "with", "JShell", "(", "Java", "9", "minimum", ")", ":", "codejshell", "scriptfile", "/", "codesyntaxhighlight", "lang", "=", "java"], "sentence-detokenized": "Same implementation, to run in Java with JShell (Java 9 minimum): codejshell scriptfile / codesyntaxhighlight lang = java", "token2charspan": [[0, 4], [5, 19], [19, 20], [21, 23], [24, 27], [28, 30], [31, 35], [36, 40], [41, 47], [48, 49], [49, 53], [54, 55], [56, 63], [63, 64], [64, 65], [66, 76], [77, 87], [88, 89], [90, 109], [110, 114], [115, 116], [117, 121]]}
{"doc_key": "ai-train-61", "ner": [[0, 3, "metrics"], [7, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 7, 8, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "NIST", "metric", "is", "based", "on", "the", "BLEU", "metric", ",", "but", "with", "some", "alterations", "."], "sentence-detokenized": "The NIST metric is based on the BLEU metric, but with some alterations.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 18], [19, 24], [25, 27], [28, 31], [32, 36], [37, 43], [43, 44], [45, 48], [49, 53], [54, 58], [59, 70], [70, 71]]}
{"doc_key": "ai-train-62", "ner": [[9, 12, "university"], [15, 17, "university"], [24, 25, "product"], [29, 30, "algorithm"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[24, 25, 9, 12, "origin", "", false, false], [24, 25, 15, 17, "origin", "", false, false], [24, 25, 29, 30, "type-of", "", false, false]], "relations_mapping_to_source": [2, 3, 4], "sentence": ["In", "the", "late", "1980s", ",", "two", "Dutch", "universities", ",", "the", "University", "of", "Groningen", "and", "the", "University", "of", "Twente", ",", "jointly", "initiated", "a", "project", "called", "Knowledge", "Graphs", ",", "which", "are", "semantic", "networks", "but", "with", "the", "added", "restriction", "that", "the", "edges", "are", "restricted", "to", "be", "of", "a", "limited", "set", "of", "possible", "relations", ",", "to", "facilitate", "the", "algebras", "in", "the", "graph", "."], "sentence-detokenized": "In the late 1980s, two Dutch universities, the University of Groningen and the University of Twente, jointly initiated a project called Knowledge Graphs, which are semantic networks but with the added restriction that the edges are restricted to be of a limited set of possible relations, to facilitate the algebras in the graph.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 17], [17, 18], [19, 22], [23, 28], [29, 41], [41, 42], [43, 46], [47, 57], [58, 60], [61, 70], [71, 74], [75, 78], [79, 89], [90, 92], [93, 99], [99, 100], [101, 108], [109, 118], [119, 120], [121, 128], [129, 135], [136, 145], [146, 152], [152, 153], [154, 159], [160, 163], [164, 172], [173, 181], [182, 185], [186, 190], [191, 194], [195, 200], [201, 212], [213, 217], [218, 221], [222, 227], [228, 231], [232, 242], [243, 245], [246, 248], [249, 251], [252, 253], [254, 261], [262, 265], [266, 268], [269, 277], [278, 287], [287, 288], [289, 291], [292, 302], [303, 306], [307, 315], [316, 318], [319, 322], [323, 328], [328, 329]]}
{"doc_key": "ai-train-63", "ner": [[0, 1, "product"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 16, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Grammar", "checkers", "are", "often", "implemented", "as", "a", "function", "of", "a", "larger", "program", ",", "such", "as", "a", "word", "processor", ",", "but", "are", "also", "available", "as", "a", "stand", "-", "alone", "application", "that", "can", "be", "activated", "from", "within", "programs", "that", "work", "with", "editable", "text", "."], "sentence-detokenized": "Grammar checkers are often implemented as a function of a larger program, such as a word processor, but are also available as a stand-alone application that can be activated from within programs that work with editable text.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 26], [27, 38], [39, 41], [42, 43], [44, 52], [53, 55], [56, 57], [58, 64], [65, 72], [72, 73], [74, 78], [79, 81], [82, 83], [84, 88], [89, 98], [98, 99], [100, 103], [104, 107], [108, 112], [113, 122], [123, 125], [126, 127], [128, 133], [133, 134], [134, 139], [140, 151], [152, 156], [157, 160], [161, 163], [164, 173], [174, 178], [179, 185], [186, 194], [195, 199], [200, 204], [205, 209], [210, 218], [219, 223], [223, 224]]}
{"doc_key": "ai-train-64", "ner": [[6, 12, "organisation"], [15, 21, "conference"], [23, 26, "organisation"], [32, 33, "conference"], [35, 37, "conference"], [39, 41, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "and", "the", "Cognitive", "Science", "Society", ",", "and", "editor", "of", "J.", "Automated", "Reasoning", ",", "J.", "Learning", "Sciences", "and", "J.", "Applied", "Ontology", "."], "sentence-detokenized": "He is a member of the American Association for the Advancement of Science, the Association for the Advancement of Artificial Intelligence and the Cognitive Science Society, and editor of J. Automated Reasoning, J. Learning Sciences and J. Applied Ontology.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 42], [43, 46], [47, 50], [51, 62], [63, 65], [66, 73], [73, 74], [75, 78], [79, 90], [91, 94], [95, 98], [99, 110], [111, 113], [114, 124], [125, 137], [138, 141], [142, 145], [146, 155], [156, 163], [164, 171], [171, 172], [173, 176], [177, 183], [184, 186], [187, 189], [190, 199], [200, 209], [209, 210], [211, 213], [214, 222], [223, 231], [232, 235], [236, 238], [239, 246], [247, 255], [255, 256]]}
{"doc_key": "ai-train-65", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [10, 11, "task"], [21, 22, "researcher"], [24, 25, "university"], [27, 28, "researcher"], [30, 33, "organisation"], [35, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 10, 11, "type-of", "", false, false], [0, 2, 21, 22, "origin", "", false, false], [0, 2, 27, 28, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [21, 22, 24, 25, "physical", "", false, false], [21, 22, 24, 25, "role", "", false, false], [27, 28, 30, 33, "role", "", false, false], [35, 35, 30, 33, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", ",", "a", "form", "of", "speech", "coding", ",", "began", "to", "be", "developed", "with", "the", "work", "of", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", "."], "sentence-detokenized": "Linear predictive coding (LPC), a form of speech coding, began to be developed with the work of Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [30, 31], [32, 33], [34, 38], [39, 41], [42, 48], [49, 55], [55, 56], [57, 62], [63, 65], [66, 68], [69, 78], [79, 83], [84, 87], [88, 92], [93, 95], [96, 104], [105, 112], [113, 115], [116, 122], [123, 133], [134, 137], [138, 143], [144, 149], [150, 152], [153, 159], [160, 169], [170, 173], [174, 183], [184, 185], [185, 188], [188, 189], [190, 192], [193, 197], [197, 198]]}
{"doc_key": "ai-train-66", "ner": [[55, 57, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "signal", "is", "also", "ergodic", ",", "all", "sampling", "paths", "exhibit", "the", "same", "time", "average", "and", "therefore", "mathR", "_", "x", "^", "{", "n", "/", "T", "_", "0", "}", "(", "\\", "tau", ")", "=", "widehat", "{", "R", "}", "_", "x", "^", "{", "n", "/", "T", "_", "0", "}", "(", "\\", "tau", ")", "/", "math", "in", "the", "mean", "square", "error", "sense", "."], "sentence-detokenized": "If the signal is also ergodic, all sampling paths exhibit the same time average and therefore mathR _ x ^ {n / T _ 0} (\\ tau) = widehat {R} _ x ^ {n / T _ 0} (\\ tau) / math in the mean square error sense.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 21], [22, 29], [29, 30], [31, 34], [35, 43], [44, 49], [50, 57], [58, 61], [62, 66], [67, 71], [72, 79], [80, 83], [84, 93], [94, 99], [100, 101], [102, 103], [104, 105], [106, 107], [107, 108], [109, 110], [111, 112], [113, 114], [115, 116], [116, 117], [118, 119], [119, 120], [121, 124], [124, 125], [126, 127], [128, 135], [136, 137], [137, 138], [138, 139], [140, 141], [142, 143], [144, 145], [146, 147], [147, 148], [149, 150], [151, 152], [153, 154], [155, 156], [156, 157], [158, 159], [159, 160], [161, 164], [164, 165], [166, 167], [168, 172], [173, 175], [176, 179], [180, 184], [185, 191], [192, 197], [198, 203], [203, 204]]}
{"doc_key": "ai-train-67", "ner": [[0, 1, "task"], [3, 4, "task"], [13, 15, "algorithm"], [17, 17, "algorithm"], [20, 22, "algorithm"], [24, 24, "algorithm"], [27, 29, "algorithm"], [31, 31, "algorithm"], [34, 36, "algorithm"], [38, 42, "algorithm"], [43, 44, "misc"], [48, 50, "algorithm"], [53, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[13, 15, 43, 44, "related-to", "", false, false], [17, 17, 13, 15, "named", "", false, false], [20, 22, 43, 44, "related-to", "", false, false], [24, 24, 20, 22, "named", "", false, false], [27, 29, 43, 44, "related-to", "", false, false], [31, 31, 27, 29, "named", "", false, false], [34, 36, 43, 44, "related-to", "", false, false], [38, 42, 34, 36, "named", "", false, false], [48, 50, 53, 54, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Feature", "extraction", "and", "dimension", "reduction", "can", "be", "combined", "in", "a", "single", "step", "using", "principal", "component", "analysis", "(", "PCA", ")", ",", "linear", "discriminant", "analysis", "(", "LDA", ")", ",", "canonical", "correlation", "analysis", "(", "CCA", ")", "or", "non-negative", "matrix", "factorisation", "(", "NMF", ")", "techniques", "as", "a", "pre-processing", "step", ",", "followed", "by", "K", "-", "NN", "clustering", "on", "feature", "vectors", "in", "the", "reduced", "dimension", "space", "."], "sentence-detokenized": "Feature extraction and dimension reduction can be combined in a single step using principal component analysis (PCA), linear discriminant analysis (LDA), canonical correlation analysis (CCA) or non-negative matrix factorisation (NMF) techniques as a pre-processing step, followed by K-NN clustering on feature vectors in the reduced dimension space.", "token2charspan": [[0, 7], [8, 18], [19, 22], [23, 32], [33, 42], [43, 46], [47, 49], [50, 58], [59, 61], [62, 63], [64, 70], [71, 75], [76, 81], [82, 91], [92, 101], [102, 110], [111, 112], [112, 115], [115, 116], [116, 117], [118, 124], [125, 137], [138, 146], [147, 148], [148, 151], [151, 152], [152, 153], [154, 163], [164, 175], [176, 184], [185, 186], [186, 189], [189, 190], [191, 193], [194, 206], [207, 213], [214, 227], [228, 229], [229, 232], [232, 233], [234, 244], [245, 247], [248, 249], [250, 264], [265, 269], [269, 270], [271, 279], [280, 282], [283, 284], [284, 285], [285, 287], [288, 298], [299, 301], [302, 309], [310, 317], [318, 320], [321, 324], [325, 332], [333, 342], [343, 348], [348, 349]]}
{"doc_key": "ai-train-68", "ner": [[3, 3, "programlang"], [5, 5, "programlang"], [7, 7, "programlang"], [9, 9, "programlang"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 15, 3, 3, "related-to", "program_type_compatible_with", false, false], [15, 15, 5, 5, "related-to", "program_type_compatible_with", false, false], [15, 15, 7, 7, "related-to", "program_type_compatible_with", false, false], [15, 15, 9, 9, "related-to", "program_type_compatible_with", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Libraries", "written", "in", "Perl", ",", "Java", ",", "ActiveX", "or", ".NET", "can", "be", "called", "directly", "from", "MATLAB", ","], "sentence-detokenized": "Libraries written in Perl, Java, ActiveX or .NET can be called directly from MATLAB,", "token2charspan": [[0, 9], [10, 17], [18, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 40], [41, 43], [44, 48], [49, 52], [53, 55], [56, 62], [63, 71], [72, 76], [77, 83], [83, 84]]}
{"doc_key": "ai-train-69", "ner": [[3, 7, "task"], [9, 11, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 7, 9, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "task", "of", "recognising", "named", "entities", "in", "text", "is", "Named", "Entity", "Recognition", ",", "while", "the", "task", "of", "determining", "the", "identity", "of", "named", "entities", "mentioned", "in", "text", "is", "called", "Entity", "Linking", "."], "sentence-detokenized": "The task of recognising named entities in text is Named Entity Recognition, while the task of determining the identity of named entities mentioned in text is called Entity Linking.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 23], [24, 29], [30, 38], [39, 41], [42, 46], [47, 49], [50, 55], [56, 62], [63, 74], [74, 75], [76, 81], [82, 85], [86, 90], [91, 93], [94, 105], [106, 109], [110, 118], [119, 121], [122, 127], [128, 136], [137, 146], [147, 149], [150, 154], [155, 157], [158, 164], [165, 171], [172, 179], [179, 180]]}
{"doc_key": "ai-train-70", "ner": [[1, 1, "algorithm"], [27, 27, "programlang"], [29, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 29, 29, "part-of", "", true, false], [29, 29, 27, 27, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "sigmoid", "functions", "and", "derivatives", "used", "in", "the", "package", "were", "originally", "included", "in", "the", "package", ",", "from", "version", "0.8.0", "onwards", ",", "they", "were", "published", "in", "a", "separate", "R", "package", "sigmoid", ",", "with", "the", "intention", "of", "allowing", "a", "more", "general", "use", "."], "sentence-detokenized": "The sigmoid functions and derivatives used in the package were originally included in the package, from version 0.8.0 onwards, they were published in a separate R package sigmoid, with the intention of allowing a more general use.", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 25], [26, 37], [38, 42], [43, 45], [46, 49], [50, 57], [58, 62], [63, 73], [74, 82], [83, 85], [86, 89], [90, 97], [97, 98], [99, 103], [104, 111], [112, 117], [118, 125], [125, 126], [127, 131], [132, 136], [137, 146], [147, 149], [150, 151], [152, 160], [161, 162], [163, 170], [171, 178], [178, 179], [180, 184], [185, 188], [189, 198], [199, 201], [202, 210], [211, 212], [213, 217], [218, 225], [226, 229], [229, 230]]}
{"doc_key": "ai-train-71", "ner": [[0, 1, "programlang"], [7, 11, "organisation"], [13, 13, "organisation"], [20, 20, "location"], [22, 22, "location"], [25, 26, "researcher"], [28, 29, "researcher"], [31, 32, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 25, 26, "artifact", "", true, false], [0, 1, 28, 29, "artifact", "", true, false], [0, 1, 31, 32, "artifact", "", true, false], [13, 13, 7, 11, "named", "", false, false], [13, 13, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false], [25, 26, 7, 11, "role", "", false, false], [28, 29, 7, 11, "role", "", false, false], [31, 32, 7, 11, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "logo", "was", "created", "in", "1967", "at", "Bolt", ",", "Beranek", "and", "Newman", "(", "BBN", ")", ",", "a", "research", "firm", "in", "Cambridge", ",", "Massachusetts", ",", "by", "Wally", "Feurzeig", ",", "Cynthia", "Solomon", "and", "Seymour", "Papert", "."], "sentence-detokenized": "The logo was created in 1967 at Bolt, Beranek and Newman (BBN), a research firm in Cambridge, Massachusetts, by Wally Feurzeig, Cynthia Solomon and Seymour Papert.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 20], [21, 23], [24, 28], [29, 31], [32, 36], [36, 37], [38, 45], [46, 49], [50, 56], [57, 58], [58, 61], [61, 62], [62, 63], [64, 65], [66, 74], [75, 79], [80, 82], [83, 92], [92, 93], [94, 107], [107, 108], [109, 111], [112, 117], [118, 126], [126, 127], [128, 135], [136, 143], [144, 147], [148, 155], [156, 162], [162, 163]]}
{"doc_key": "ai-train-72", "ner": [[0, 0, "misc"], [8, 10, "field"], [18, 19, "field"], [23, 24, "algorithm"], [27, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 10, "part-of", "", false, false], [0, 0, 18, 19, "compare", "", false, false], [23, 24, 18, 19, "part-of", "", false, false], [27, 28, 18, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Neuroevolution", "is", "commonly", "used", "as", "part", "of", "the", "reinforcement", "learning", "paradigm", ",", "and", "can", "be", "contrasted", "with", "conventional", "deep", "learning", "techniques", "that", "use", "gradient", "descent", "in", "a", "neural", "network", "with", "a", "fixed", "topology", "."], "sentence-detokenized": "Neuroevolution is commonly used as part of the reinforcement learning paradigm, and can be contrasted with conventional deep learning techniques that use gradient descent in a neural network with a fixed topology.", "token2charspan": [[0, 14], [15, 17], [18, 26], [27, 31], [32, 34], [35, 39], [40, 42], [43, 46], [47, 60], [61, 69], [70, 78], [78, 79], [80, 83], [84, 87], [88, 90], [91, 101], [102, 106], [107, 119], [120, 124], [125, 133], [134, 144], [145, 149], [150, 153], [154, 162], [163, 170], [171, 173], [174, 175], [176, 182], [183, 190], [191, 195], [196, 197], [198, 203], [204, 212], [212, 213]]}
{"doc_key": "ai-train-73", "ner": [[3, 4, "algorithm"], [51, 53, "metrics"], [55, 55, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[55, 55, 51, 53, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["If", "we", "use", "least", "squares", "to", "fit", "a", "hyperplane", "function", "\u0177", "=", "a", "+", "\u03b2", "supT", "/", "sup", "x", "to", "the", "data", "(", "x", "sub", "i", "/", "sub", ",", "y", "sub", "i", "/", "sub", ")", "sub", "1", "\u2264", "i", "\u2264n", "/", "sub", ",", "we", "could", "then", "evaluate", "the", "fit", "using", "the", "mean", "squared", "error", "(", "MSE", ")", "."], "sentence-detokenized": "If we use least squares to fit a hyperplane function \u0177 = a + \u03b2 supT / sup x to the data (x sub i / sub, y sub i / sub) sub 1 \u2264 i \u2264n / sub, we could then evaluate the fit using the mean squared error (MSE).", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 15], [16, 23], [24, 26], [27, 30], [31, 32], [33, 43], [44, 52], [53, 54], [55, 56], [57, 58], [59, 60], [61, 62], [63, 67], [68, 69], [70, 73], [74, 75], [76, 78], [79, 82], [83, 87], [88, 89], [89, 90], [91, 94], [95, 96], [97, 98], [99, 102], [102, 103], [104, 105], [106, 109], [110, 111], [112, 113], [114, 117], [117, 118], [119, 122], [123, 124], [125, 126], [127, 128], [129, 131], [132, 133], [134, 137], [137, 138], [139, 141], [142, 147], [148, 152], [153, 161], [162, 165], [166, 169], [170, 175], [176, 179], [180, 184], [185, 192], [193, 198], [199, 200], [200, 203], [203, 204], [204, 205]]}
{"doc_key": "ai-train-74", "ner": [[6, 6, "country"], [8, 8, "country"], [10, 10, "country"], [12, 12, "country"], [14, 14, "country"], [16, 16, "country"], [18, 18, "country"], [20, 20, "country"], [22, 22, "country"], [24, 24, "country"], [26, 26, "country"], [28, 28, "country"], [30, 31, "country"], [33, 33, "country"], [35, 35, "country"], [37, 38, "country"], [40, 40, "country"], [42, 42, "country"], [44, 44, "country"], [46, 46, "country"], [49, 49, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "company", "has", "international", "locations", "in", "Australia", ",", "Brazil", ",", "Canada", ",", "China", ",", "Germany", ",", "India", ",", "Italy", ",", "Japan", ",", "Korea", ",", "Lithuania", ",", "Poland", ",", "Malaysia", ",", "the", "Philippines", ",", "Russia", ",", "Singapore", ",", "South", "Africa", ",", "Spain", ",", "Taiwan", ",", "Thailand", ",", "Turkey", "and", "the", "UK", "."], "sentence-detokenized": "The company has international locations in Australia, Brazil, Canada, China, Germany, India, Italy, Japan, Korea, Lithuania, Poland, Malaysia, the Philippines, Russia, Singapore, South Africa, Spain, Taiwan, Thailand, Turkey and the UK.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 29], [30, 39], [40, 42], [43, 52], [52, 53], [54, 60], [60, 61], [62, 68], [68, 69], [70, 75], [75, 76], [77, 84], [84, 85], [86, 91], [91, 92], [93, 98], [98, 99], [100, 105], [105, 106], [107, 112], [112, 113], [114, 123], [123, 124], [125, 131], [131, 132], [133, 141], [141, 142], [143, 146], [147, 158], [158, 159], [160, 166], [166, 167], [168, 177], [177, 178], [179, 184], [185, 191], [191, 192], [193, 198], [198, 199], [200, 206], [206, 207], [208, 216], [216, 217], [218, 224], [225, 228], [229, 232], [233, 235], [235, 236]]}
{"doc_key": "ai-train-75", "ner": [[3, 3, "misc"], [5, 8, "field"], [13, 13, "organisation"], [16, 20, "university"], [28, 30, "organisation"], [32, 39, "university"], [43, 43, "university"], [45, 45, "university"], [47, 47, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 3, 5, 8, "topic", "", false, false], [3, 3, 13, 13, "origin", "", false, false], [3, 3, 16, 20, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "holds", "a", "PhD", "in", "electrical", "and", "computer", "engineering", "(", "2000", ")", "from", "Inria", "and", "the", "University", "of", "Nice", "Sophia", "Antipolis", ",", "and", "has", "held", "permanent", "positions", "at", "Siemens", "Corporate", "Technology", ",", "\u00c9cole", "des", "ponts", "ParisTech", ",", "as", "well", "as", "visiting", "positions", "at", "Rutgers", ",", "Yale", "and", "Houston", "Universities", "."], "sentence-detokenized": "He holds a PhD in electrical and computer engineering (2000) from Inria and the University of Nice Sophia Antipolis, and has held permanent positions at Siemens Corporate Technology, \u00c9cole des ponts ParisTech, as well as visiting positions at Rutgers, Yale and Houston Universities.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 14], [15, 17], [18, 28], [29, 32], [33, 41], [42, 53], [54, 55], [55, 59], [59, 60], [61, 65], [66, 71], [72, 75], [76, 79], [80, 90], [91, 93], [94, 98], [99, 105], [106, 115], [115, 116], [117, 120], [121, 124], [125, 129], [130, 139], [140, 149], [150, 152], [153, 160], [161, 170], [171, 181], [181, 182], [183, 188], [189, 192], [193, 198], [199, 208], [208, 209], [210, 212], [213, 217], [218, 220], [221, 229], [230, 239], [240, 242], [243, 250], [250, 251], [252, 256], [257, 260], [261, 268], [269, 281], [281, 282]]}
{"doc_key": "ai-train-76", "ner": [[6, 7, "researcher"], [9, 9, "researcher"], [14, 15, "product"], [11, 11, "country"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 6, 7, "role", "licensing_patent_to", false, false], [9, 9, 11, 11, "physical", "", false, false], [18, 18, 9, 9, "artifact", "", false, false], [18, 18, 14, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Licensing", "the", "original", "patent", "from", "inventor", "George", "Devol", ",", "Engelberger", "developed", "America", "'s", "first", "industrial", "robot", ",", "the", "Unimate", ",", "in", "the", "1950s", "."], "sentence-detokenized": "Licensing the original patent from inventor George Devol, Engelberger developed America's first industrial robot, the Unimate, in the 1950s.", "token2charspan": [[0, 9], [10, 13], [14, 22], [23, 29], [30, 34], [35, 43], [44, 50], [51, 56], [56, 57], [58, 69], [70, 79], [80, 87], [87, 89], [90, 95], [96, 106], [107, 112], [112, 113], [114, 117], [118, 125], [125, 126], [127, 129], [130, 133], [134, 139], [139, 140]]}
{"doc_key": "ai-train-77", "ner": [[4, 5, "task"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "input", "is", "called", "speech", "recognition", "and", "the", "output", "is", "called", "speech", "synthesis", "."], "sentence-detokenized": "The input is called speech recognition and the output is called speech synthesis.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 26], [27, 38], [39, 42], [43, 46], [47, 53], [54, 56], [57, 63], [64, 70], [71, 80], [80, 81]]}
{"doc_key": "ai-train-78", "ner": [[3, 3, "programlang"], [6, 6, "programlang"], [14, 14, "programlang"], [17, 17, "programlang"], [27, 27, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 14, 14, "named", "", false, false], [6, 6, 3, 3, "origin", "descendant_of", false, false], [6, 6, 17, 17, "general-affiliation", "", false, false], [6, 6, 27, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Descendants", "of", "the", "CLIPS", "language", "include", "Jess", "(", "a", "rule", "-", "based", "part", "of", "CLIPS", "rewritten", "in", "Java", ",", "which", "later", "grew", "in", "another", "direction", ")", ",", "JESS", "was", "originally", "inspired", "by"], "sentence-detokenized": "Descendants of the CLIPS language include Jess (a rule-based part of CLIPS rewritten in Java, which later grew in another direction), JESS was originally inspired by", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 24], [25, 33], [34, 41], [42, 46], [47, 48], [48, 49], [50, 54], [54, 55], [55, 60], [61, 65], [66, 68], [69, 74], [75, 84], [85, 87], [88, 92], [92, 93], [94, 99], [100, 105], [106, 110], [111, 113], [114, 121], [122, 131], [131, 132], [132, 133], [134, 138], [139, 142], [143, 153], [154, 162], [163, 165]]}
{"doc_key": "ai-train-79", "ner": [[6, 6, "product"], [11, 13, "product"], [16, 17, "organisation"], [21, 22, "product"], [39, 40, "product"], [42, 44, "product"], [62, 63, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 13, 6, 6, "type-of", "", false, false], [16, 17, 11, 13, "usage", "", false, false], [21, 22, 16, 17, "artifact", "", false, false], [39, 40, 16, 17, "origin", "", true, false], [39, 40, 62, 63, "related-to", "", true, false], [42, 44, 16, 17, "origin", "", true, false], [42, 44, 62, 63, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["It", "also", "created", "smart", "and", "flexible", "AGV", "applications", ",", "designing", "the", "Motivity", "control", "system", "used", "by", "RMT", "Robotics", "to", "develop", "its", "ADAM", "iAGV", "(", "automated", "guided", "vehicle", ")", ",", "used", "for", "complex", "pick", "and", "place", "operations", ",", "along", "with", "gantry", "systems", "and", "industrial", "robotic", "arms", ",", "used", "in", "Tier", "1", "automotive", "supply", "factories", "to", "move", "products", "from", "one", "process", "to", "another", "in", "non-linear", "layouts", "."], "sentence-detokenized": "It also created smart and flexible AGV applications, designing the Motivity control system used by RMT Robotics to develop its ADAM iAGV (automated guided vehicle), used for complex pick and place operations, along with gantry systems and industrial robotic arms, used in Tier 1 automotive supply factories to move products from one process to another in non-linear layouts.", "token2charspan": [[0, 2], [3, 7], [8, 15], [16, 21], [22, 25], [26, 34], [35, 38], [39, 51], [51, 52], [53, 62], [63, 66], [67, 75], [76, 83], [84, 90], [91, 95], [96, 98], [99, 102], [103, 111], [112, 114], [115, 122], [123, 126], [127, 131], [132, 136], [137, 138], [138, 147], [148, 154], [155, 162], [162, 163], [163, 164], [165, 169], [170, 173], [174, 181], [182, 186], [187, 190], [191, 196], [197, 207], [207, 208], [209, 214], [215, 219], [220, 226], [227, 234], [235, 238], [239, 249], [250, 257], [258, 262], [262, 263], [264, 268], [269, 271], [272, 276], [277, 278], [279, 289], [290, 296], [297, 306], [307, 309], [310, 314], [315, 323], [324, 328], [329, 332], [333, 340], [341, 343], [344, 351], [352, 354], [355, 365], [366, 373], [373, 374]]}
{"doc_key": "ai-train-80", "ner": [[7, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "parameters", "\u03b2", "are", "usually", "estimated", "by", "maximum", "likelihood", "."], "sentence-detokenized": "The parameters \u03b2 are usually estimated by maximum likelihood.", "token2charspan": [[0, 3], [4, 14], [15, 16], [17, 20], [21, 28], [29, 38], [39, 41], [42, 49], [50, 60], [60, 61]]}
{"doc_key": "ai-train-81", "ner": [[0, 5, "task"], [6, 6, "metrics"], [8, 8, "metrics"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 0, 5, "part-of", "", false, false], [8, 8, 0, 5, "part-of", "", false, false], [10, 10, 0, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Information", "retrieval", "metrics", ",", "such", "as", "precision", "and", "recall", "or", "DCG", ",", "are", "useful", "for", "assessing", "the", "quality", "of", "a", "recommendation", "method", "."], "sentence-detokenized": "Information retrieval metrics, such as precision and recall or DCG, are useful for assessing the quality of a recommendation method.", "token2charspan": [[0, 11], [12, 21], [22, 29], [29, 30], [31, 35], [36, 38], [39, 48], [49, 52], [53, 59], [60, 62], [63, 66], [66, 67], [68, 71], [72, 78], [79, 82], [83, 92], [93, 96], [97, 104], [105, 107], [108, 109], [110, 124], [125, 131], [131, 132]]}
{"doc_key": "ai-train-82", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "typical", "factory", "contains", "hundreds", "of", "industrial", "robots", "working", "on", "fully", "automated", "production", "lines", ",", "with", "one", "robot", "for", "every", "ten", "human", "workers", "."], "sentence-detokenized": "A typical factory contains hundreds of industrial robots working on fully automated production lines, with one robot for every ten human workers.", "token2charspan": [[0, 1], [2, 9], [10, 17], [18, 26], [27, 35], [36, 38], [39, 49], [50, 56], [57, 64], [65, 67], [68, 73], [74, 83], [84, 94], [95, 100], [100, 101], [102, 106], [107, 110], [111, 116], [117, 120], [121, 126], [127, 130], [131, 136], [137, 144], [144, 145]]}
{"doc_key": "ai-train-83", "ner": [[5, 5, "product"], [14, 16, "field"], [20, 21, "task"], [23, 24, "task"], [26, 27, "task"], [29, 30, "task"], [32, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[14, 16, 5, 5, "usage", "", false, true], [20, 21, 14, 16, "part-of", "", false, false], [23, 24, 14, 16, "part-of", "", false, false], [26, 27, 14, 16, "part-of", "", false, false], [29, 30, 14, 16, "part-of", "", false, false], [32, 33, 14, 16, "part-of", "", false, false], [35, 36, 14, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "the", "last", "decade", ",", "PCNNs", "have", "been", "used", "in", "a", "wide", "variety", "of", "image", "processing", "applications", ",", "including", ":", "image", "segmentation", ",", "feature", "generation", ",", "face", "extraction", ",", "motion", "detection", ",", "region", "growing", "and", "noise", "reduction", "."], "sentence-detokenized": "In the last decade, PCNNs have been used in a wide variety of image processing applications, including: image segmentation, feature generation, face extraction, motion detection, region growing and noise reduction.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [18, 19], [20, 25], [26, 30], [31, 35], [36, 40], [41, 43], [44, 45], [46, 50], [51, 58], [59, 61], [62, 67], [68, 78], [79, 91], [91, 92], [93, 102], [102, 103], [104, 109], [110, 122], [122, 123], [124, 131], [132, 142], [142, 143], [144, 148], [149, 159], [159, 160], [161, 167], [168, 177], [177, 178], [179, 185], [186, 193], [194, 197], [198, 203], [204, 213], [213, 214]]}
{"doc_key": "ai-train-84", "ner": [[0, 0, "researcher"], [16, 17, "field"], [22, 24, "misc"], [27, 33, "conference"], [35, 35, "conference"], [40, 42, "misc"], [45, 49, "conference"], [50, 51, "conference"], [53, 57, "conference"], [59, 59, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 0, 16, 17, "related-to", "contributes_to", false, false], [0, 0, 22, 24, "win-defeat", "", false, false], [0, 0, 40, 42, "win-defeat", "", false, false], [22, 24, 27, 33, "temporal", "", false, false], [35, 35, 27, 33, "named", "", false, false], [40, 42, 45, 49, "temporal", "", false, false], [40, 42, 53, 57, "temporal", "", false, false], [50, 51, 45, 49, "named", "", false, false], [59, 59, 53, 57, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Xu", "has", "published", "more", "than", "50", "papers", "in", "international", "conferences", "and", "journals", "in", "the", "field", "of", "computer", "vision", "and", "has", "won", "the", "best", "paper", "award", "at", "the", "International", "Conference", "on", "Non-Photorealistic", "Rendering", "and", "Animation", "(", "NPAR", ")", "2012", "and", "the", "best", "reviewer", "award", "at", "the", "Asian", "Conference", "on", "Computer", "Vision", "ACCV", "2012", "and", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "2015", "."], "sentence-detokenized": "Xu has published more than 50 papers in international conferences and journals in the field of computer vision and has won the best paper award at the International Conference on Non-Photorealistic Rendering and Animation (NPAR) 2012 and the best reviewer award at the Asian Conference on Computer Vision ACCV 2012 and International Conference on Computer Vision (ICCV) 2015.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 21], [22, 26], [27, 29], [30, 36], [37, 39], [40, 53], [54, 65], [66, 69], [70, 78], [79, 81], [82, 85], [86, 91], [92, 94], [95, 103], [104, 110], [111, 114], [115, 118], [119, 122], [123, 126], [127, 131], [132, 137], [138, 143], [144, 146], [147, 150], [151, 164], [165, 175], [176, 178], [179, 197], [198, 207], [208, 211], [212, 221], [222, 223], [223, 227], [227, 228], [229, 233], [234, 237], [238, 241], [242, 246], [247, 255], [256, 261], [262, 264], [265, 268], [269, 274], [275, 285], [286, 288], [289, 297], [298, 304], [305, 309], [310, 314], [315, 318], [319, 332], [333, 343], [344, 346], [347, 355], [356, 362], [363, 364], [364, 368], [368, 369], [370, 374], [374, 375]]}
{"doc_key": "ai-train-85", "ner": [[0, 0, "programlang"], [2, 3, "field"], [5, 6, "field"], [9, 10, "misc"], [13, 14, "researcher"], [16, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 2, 3, "part-of", "", false, false], [0, 0, 5, 6, "part-of", "", false, false], [0, 0, 9, 10, "type-of", "", false, false], [16, 18, 0, 0, "usage", "", false, false], [16, 18, 13, 14, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["CycL", "in", "computer", "science", "and", "artificial", "intelligence", "is", "an", "ontology", "language", "used", "by", "Doug", "Lenat", "'s", "Artificial", "Cyc", "project", "."], "sentence-detokenized": "CycL in computer science and artificial intelligence is an ontology language used by Doug Lenat's Artificial Cyc project.", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 24], [25, 28], [29, 39], [40, 52], [53, 55], [56, 58], [59, 67], [68, 76], [77, 81], [82, 84], [85, 89], [90, 95], [95, 97], [98, 108], [109, 112], [113, 120], [120, 121]]}
{"doc_key": "ai-train-86", "ner": [[2, 3, "task"], [6, 8, "metrics"], [19, 19, "metrics"], [21, 28, "metrics"], [38, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 8, 2, 3, "part-of", "", false, false], [19, 19, 6, 8, "named", "", false, false], [21, 28, 6, 8, "named", "", false, false], [38, 39, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Also", "in", "regression", "analysis", ",", "the", "mean", "squared", "error", ",", "often", "referred", "to", "as", "the", "mean", "squared", "error", "of", "prediction", "or", "out", "-", "of", "-", "sample", "mean", "squared", "error", ",", "can", "refer", "to", "the", "mean", "value", "of", "the", "quadratic", "deviations", "of", "the", "predictions", "of", "the", "TRUE", "values", ",", "over", "an", "out", "-", "of", "-", "sample", "test", "space", ",", "generated", "by", "a", "model", "estimated", "over", "a", "particular", "sample", "space", "."], "sentence-detokenized": "Also in regression analysis, the mean squared error, often referred to as the mean squared error of prediction or out-of-sample mean squared error, can refer to the mean value of the quadratic deviations of the predictions of the TRUE values, over an out-of-sample test space, generated by a model estimated over a particular sample space.", "token2charspan": [[0, 4], [5, 7], [8, 18], [19, 27], [27, 28], [29, 32], [33, 37], [38, 45], [46, 51], [51, 52], [53, 58], [59, 67], [68, 70], [71, 73], [74, 77], [78, 82], [83, 90], [91, 96], [97, 99], [100, 110], [111, 113], [114, 117], [117, 118], [118, 120], [120, 121], [121, 127], [128, 132], [133, 140], [141, 146], [146, 147], [148, 151], [152, 157], [158, 160], [161, 164], [165, 169], [170, 175], [176, 178], [179, 182], [183, 192], [193, 203], [204, 206], [207, 210], [211, 222], [223, 225], [226, 229], [230, 234], [235, 241], [241, 242], [243, 247], [248, 250], [251, 254], [254, 255], [255, 257], [257, 258], [258, 264], [265, 269], [270, 275], [275, 276], [277, 286], [287, 289], [290, 291], [292, 297], [298, 307], [308, 312], [313, 314], [315, 325], [326, 332], [333, 338], [338, 339]]}
{"doc_key": "ai-train-87", "ner": [[6, 8, "algorithm"], [10, 11, "algorithm"], [13, 22, "algorithm"], [33, 34, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 8, 10, 11, "compare", "", false, false], [6, 8, 13, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "terms", "of", "results", ",", "the", "C", "-", "HOG", "and", "R-", "HOG", "block", "descriptors", "perform", "comparably", ",", "with", "the", "C", "-", "HOG", "descriptors", "maintaining", "a", "slight", "advantage", "in", "detection", "failure", "rate", "with", "fixed", "false", "positive", "rates", "in", "both", "datasets", "."], "sentence-detokenized": "In terms of results, the C-HOG and R-HOG block descriptors perform comparably, with the C-HOG descriptors maintaining a slight advantage in detection failure rate with fixed false positive rates in both datasets.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 19], [19, 20], [21, 24], [25, 26], [26, 27], [27, 30], [31, 34], [35, 37], [37, 40], [41, 46], [47, 58], [59, 66], [67, 77], [77, 78], [79, 83], [84, 87], [88, 89], [89, 90], [90, 93], [94, 105], [106, 117], [118, 119], [120, 126], [127, 136], [137, 139], [140, 149], [150, 157], [158, 162], [163, 167], [168, 173], [174, 179], [180, 188], [189, 194], [195, 197], [198, 202], [203, 211], [211, 212]]}
{"doc_key": "ai-train-88", "ner": [[8, 11, "algorithm"], [12, 12, "misc"], [14, 16, "algorithm"], [18, 19, "algorithm"], [22, 23, "algorithm"], [26, 28, "algorithm"], [30, 32, "algorithm"], [34, 35, "misc"], [40, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 11, 12, 12, "usage", "", false, false], [14, 16, 34, 35, "usage", "", false, false], [18, 19, 34, 35, "usage", "", false, false], [22, 23, 34, 35, "usage", "", false, false], [26, 28, 34, 35, "usage", "", false, false], [30, 32, 34, 35, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Among", "the", "best", "-", "known", "recognition", "algorithms", "are", "principal", "component", "analysis", "using", "eigenfaces", ",", "linear", "discriminant", "analysis", ",", "elastic", "matching", "using", "the", "Fisherface", "algorithm", ",", "the", "hidden", "Markov", "model", ",", "multilinear", "subspace", "learning", "using", "tensor", "representation", "and", "neural", "-", "driven", "dynamic", "link", "matching", "."], "sentence-detokenized": "Among the best-known recognition algorithms are principal component analysis using eigenfaces, linear discriminant analysis, elastic matching using the Fisherface algorithm, the hidden Markov model, multilinear subspace learning using tensor representation and neural-driven dynamic link matching.", "token2charspan": [[0, 5], [6, 9], [10, 14], [14, 15], [15, 20], [21, 32], [33, 43], [44, 47], [48, 57], [58, 67], [68, 76], [77, 82], [83, 93], [93, 94], [95, 101], [102, 114], [115, 123], [123, 124], [125, 132], [133, 141], [142, 147], [148, 151], [152, 162], [163, 172], [172, 173], [174, 177], [178, 184], [185, 191], [192, 197], [197, 198], [199, 210], [211, 219], [220, 228], [229, 234], [235, 241], [242, 256], [257, 260], [261, 267], [267, 268], [268, 274], [275, 282], [283, 287], [288, 296], [296, 297]]}
{"doc_key": "ai-train-89", "ner": [[3, 7, "misc"], [18, 20, "location"], [39, 41, "location"], [56, 56, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[18, 20, 3, 7, "temporal", "", false, false], [39, 41, 3, 7, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Starting", "with", "the", "2019", "Toronto", "International", "Film", "Festival", ",", "films", "may", "now", "be", "restricted", "from", "screening", "at", "the", "Scotiabank", "Theatre", "Toronto", "-", "one", "of", "the", "festival", "'s", "main", "venues", "-", "and", "screened", "at", "other", "venues", "(", "such", "as", "the", "TIFF", "Bell", "Lightbox", "and", "other", "local", "cinemas", ")", "if", "they", "are", "distributed", "by", "a", "service", "such", "as", "Netflix", "."], "sentence-detokenized": "Starting with the 2019 Toronto International Film Festival, films may now be restricted from screening at the Scotiabank Theatre Toronto - one of the festival's main venues - and screened at other venues (such as the TIFF Bell Lightbox and other local cinemas) if they are distributed by a service such as Netflix.", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 22], [23, 30], [31, 44], [45, 49], [50, 58], [58, 59], [60, 65], [66, 69], [70, 73], [74, 76], [77, 87], [88, 92], [93, 102], [103, 105], [106, 109], [110, 120], [121, 128], [129, 136], [137, 138], [139, 142], [143, 145], [146, 149], [150, 158], [158, 160], [161, 165], [166, 172], [173, 174], [175, 178], [179, 187], [188, 190], [191, 196], [197, 203], [204, 205], [205, 209], [210, 212], [213, 216], [217, 221], [222, 226], [227, 235], [236, 239], [240, 245], [246, 251], [252, 259], [259, 260], [261, 263], [264, 268], [269, 272], [273, 284], [285, 287], [288, 289], [290, 297], [298, 302], [303, 305], [306, 313], [313, 314]]}
{"doc_key": "ai-train-90", "ner": [[0, 0, "organisation"], [5, 6, "researcher"], [2, 3, "organisation"], [12, 12, "researcher"], [22, 25, "product"], [36, 37, "researcher"], [41, 43, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 2, 3, "related-to", "purchases", false, false], [5, 6, 12, 12, "named", "same", false, false], [5, 6, 36, 37, "named", "same", false, false], [2, 3, 5, 6, "origin", "founded_by", false, false], [22, 25, 0, 0, "artifact", "", false, false], [41, 43, 36, 37, "artifact", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "bought", "Vicarm", "Inc.", "from", "Victor", "Scheinman", "in", "1977", "and", ",", "with", "his", "help", ",", "the", "company", "created", "and", "began", "producing", "the", "Programmable", "Universal", "Assembly", "Machine", ",", "a", "new", "model", "of", "robotic", "arm", ",", "and", "using", "Scheinman", "'s", "cutting", "-", "edge", "VAL", "programming", "language", "."], "sentence-detokenized": "Unimation bought Vicarm Inc. from Victor Scheinman in 1977 and, with his help, the company created and began producing the Programmable Universal Assembly Machine, a new model of robotic arm, and using Scheinman's cutting-edge VAL programming language.", "token2charspan": [[0, 9], [10, 16], [17, 23], [24, 28], [29, 33], [34, 40], [41, 50], [51, 53], [54, 58], [59, 62], [62, 63], [64, 68], [69, 72], [73, 77], [77, 78], [79, 82], [83, 90], [91, 98], [99, 102], [103, 108], [109, 118], [119, 122], [123, 135], [136, 145], [146, 154], [155, 162], [162, 163], [164, 165], [166, 169], [170, 175], [176, 178], [179, 186], [187, 190], [190, 191], [192, 195], [196, 201], [202, 211], [211, 213], [214, 221], [221, 222], [222, 226], [227, 230], [231, 242], [243, 251], [251, 252]]}
{"doc_key": "ai-train-91", "ner": [[0, 1, "product"], [6, 6, "programlang"], [10, 11, "algorithm"], [14, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 6, 6, "general-affiliation", "", false, false], [0, 1, 10, 11, "origin", "implementation_of", false, false], [0, 1, 14, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["J", "48", "is", "an", "open", "source", "Java", "implementation", "of", "the", "C4.5", "algorithm", "in", "the", "Weka", "data", "mining", "tool", "."], "sentence-detokenized": "J48 is an open source Java implementation of the C4.5 algorithm in the Weka data mining tool.", "token2charspan": [[0, 1], [1, 3], [4, 6], [7, 9], [10, 14], [15, 21], [22, 26], [27, 41], [42, 44], [45, 48], [49, 53], [54, 63], [64, 66], [67, 70], [71, 75], [76, 80], [81, 87], [88, 92], [92, 93]]}
{"doc_key": "ai-train-92", "ner": [[2, 2, "metrics"], [13, 14, "product"], [21, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 13, 14, "win-defeat", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "2004", "SSIM", "paper", "has", "been", "cited", "more", "than", "20,000", "times", "according", "to", "Google", "Scholar", ",", "and", "also", "received", "the", "2016", "IEEE", "Signal", "Processing", "Society", "Sustained", "Impact", "Award", ",", "which", "indicates", "that", "a", "paper", "has", "an", "unusually", "high", "impact", "for", "at", "least", "10", "years", "after", "publication", "."], "sentence-detokenized": "The 2004 SSIM paper has been cited more than 20,000 times according to Google Scholar, and also received the 2016 IEEE Signal Processing Society Sustained Impact Award, which indicates that a paper has an unusually high impact for at least 10 years after publication.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 19], [20, 23], [24, 28], [29, 34], [35, 39], [40, 44], [45, 51], [52, 57], [58, 67], [68, 70], [71, 77], [78, 85], [85, 86], [87, 90], [91, 95], [96, 104], [105, 108], [109, 113], [114, 118], [119, 125], [126, 136], [137, 144], [145, 154], [155, 161], [162, 167], [167, 168], [169, 174], [175, 184], [185, 189], [190, 191], [192, 197], [198, 201], [202, 204], [205, 214], [215, 219], [220, 226], [227, 230], [231, 233], [234, 239], [240, 242], [243, 248], [249, 254], [255, 266], [266, 267]]}
{"doc_key": "ai-train-93", "ner": [[0, 1, "task"], [23, 29, "product"], [39, 41, "product"], [44, 44, "organisation"], [45, 45, "product"], [48, 48, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 44, 44, "artifact", "", false, false], [23, 29, 0, 1, "related-to", "performs", false, false], [23, 29, 39, 41, "part-of", "", false, false], [44, 44, 48, 48, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Speech", "synthesis", "is", "on", "the", "verge", "of", "being", "completely", "indistinguishable", "from", "the", "voice", "of", "a", "real", "human", "with", "the", "introduction", "in", "2016", "of", "Adobe", "Voco", "speech", "generation", "and", "editing", "software", ",", "a", "prototype", "slated", "to", "be", "part", "of", "the", "Adobe", "Creative", "Suite", ",", "and", "DeepMind", "WaveNet", ",", "a", "Google", "prototype", "."], "sentence-detokenized": "Speech synthesis is on the verge of being completely indistinguishable from the voice of a real human with the introduction in 2016 of Adobe Voco speech generation and editing software, a prototype slated to be part of the Adobe Creative Suite, and DeepMind WaveNet, a Google prototype.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 22], [23, 26], [27, 32], [33, 35], [36, 41], [42, 52], [53, 70], [71, 75], [76, 79], [80, 85], [86, 88], [89, 90], [91, 95], [96, 101], [102, 106], [107, 110], [111, 123], [124, 126], [127, 131], [132, 134], [135, 140], [141, 145], [146, 152], [153, 163], [164, 167], [168, 175], [176, 184], [184, 185], [186, 187], [188, 197], [198, 204], [205, 207], [208, 210], [211, 215], [216, 218], [219, 222], [223, 228], [229, 237], [238, 243], [243, 244], [245, 248], [249, 257], [258, 265], [265, 266], [267, 268], [269, 275], [276, 285], [285, 286]]}
{"doc_key": "ai-train-94", "ner": [[0, 2, "researcher"], [7, 9, "organisation"], [15, 20, "organisation"], [26, 27, "conference"], [30, 34, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 7, 9, "role", "", false, false], [0, 2, 15, 20, "role", "", false, false], [0, 2, 26, 27, "role", "", false, false], [0, 2, 30, 34, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Poggio", "is", "an", "honorary", "member", "of", "the", "Neuroscience", "Research", "Program", ",", "a", "fellow", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "a", "founding", "member", "of", "the", "AAAI", "and", "the", "McGovern", "Institute", "for", "Brain", "Research", "."], "sentence-detokenized": "Poggio is an honorary member of the Neuroscience Research Program, a fellow of the American Academy of Arts and Sciences and a founding member of the AAAI and the McGovern Institute for Brain Research.", "token2charspan": [[0, 6], [7, 9], [10, 12], [13, 21], [22, 28], [29, 31], [32, 35], [36, 48], [49, 57], [58, 65], [65, 66], [67, 68], [69, 75], [76, 78], [79, 82], [83, 91], [92, 99], [100, 102], [103, 107], [108, 111], [112, 120], [121, 124], [125, 126], [127, 135], [136, 142], [143, 145], [146, 149], [150, 154], [155, 158], [159, 162], [163, 171], [172, 181], [182, 185], [186, 191], [192, 200], [200, 201]]}
{"doc_key": "ai-train-95", "ner": [[10, 10, "task"], [12, 13, "task"], [17, 19, "task"], [25, 25, "misc"], [26, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 10, 17, 19, "cause-effect", "", false, false], [12, 13, 17, 19, "cause-effect", "", false, false], [26, 27, 17, 19, "topic", "", false, false], [26, 27, 25, 25, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "1990s", ",", "encouraged", "by", "the", "successes", "in", "speech", "recognition", "and", "speech", "synthesis", ",", "research", "into", "speech", "translation", "began", "with", "the", "development", "of", "the", "German", "Verbmobil", "project", "."], "sentence-detokenized": "In the 1990s, encouraged by the successes in speech recognition and speech synthesis, research into speech translation began with the development of the German Verbmobil project.", "token2charspan": [[0, 2], [3, 6], [7, 12], [12, 13], [14, 24], [25, 27], [28, 31], [32, 41], [42, 44], [45, 51], [52, 63], [64, 67], [68, 74], [75, 84], [84, 85], [86, 94], [95, 99], [100, 106], [107, 118], [119, 124], [125, 129], [130, 133], [134, 145], [146, 148], [149, 152], [153, 159], [160, 169], [170, 177], [177, 178]]}
{"doc_key": "ai-train-96", "ner": [[3, 4, "researcher"], [8, 9, "researcher"], [11, 12, "researcher"], [15, 16, "algorithm"], [20, 21, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 8, 9, "role", "", false, false], [15, 16, 3, 4, "origin", "", false, false], [15, 16, 8, 9, "origin", "", false, false], [15, 16, 11, 12, "origin", "", false, false], [15, 16, 25, 25, "part-of", "", false, false], [20, 21, 15, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "1999", ",", "Felix", "Gers", "and", "his", "advisor", "J\u00fcrgen", "Schmidhuber", "and", "Fred", "Cummins", "introduced", "the", "oblivion", "gate", "(", "also", "called", "maintenance", "gate", ")", "into", "the", "LSTM", "architecture", ","], "sentence-detokenized": "In 1999, Felix Gers and his advisor J\u00fcrgen Schmidhuber and Fred Cummins introduced the oblivion gate (also called maintenance gate) into the LSTM architecture,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 19], [20, 23], [24, 27], [28, 35], [36, 42], [43, 54], [55, 58], [59, 63], [64, 71], [72, 82], [83, 86], [87, 95], [96, 100], [101, 102], [102, 106], [107, 113], [114, 125], [126, 130], [130, 131], [132, 136], [137, 140], [141, 145], [146, 158], [158, 159]]}
{"doc_key": "ai-train-97", "ner": [[1, 3, "field"], [5, 6, "field"], [9, 11, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 11, 1, 3, "part-of", "", false, false], [9, 11, 5, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "digital", "signal", "processing", "and", "information", "theory", ",", "the", "normalised", "sinc", "function", "is", "commonly", "defined", "by"], "sentence-detokenized": "In digital signal processing and information theory, the normalised sinc function is commonly defined by", "token2charspan": [[0, 2], [3, 10], [11, 17], [18, 28], [29, 32], [33, 44], [45, 51], [51, 52], [53, 56], [57, 67], [68, 72], [73, 81], [82, 84], [85, 93], [94, 101], [102, 104]]}
{"doc_key": "ai-train-98", "ner": [[2, 3, "field"], [7, 8, "researcher"], [15, 18, "conference"], [21, 25, "organisation"], [27, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 7, 8, "origin", "coined_term", false, false], [7, 8, 15, 18, "role", "", false, false], [7, 8, 21, 25, "role", "", false, false], [27, 27, 21, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "computational", "linguistics", "was", "coined", "by", "David", "Hays", ",", "a", "founding", "member", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "the", "International", "Committee", "for", "Computational", "Linguistics", "(", "ICCL", ")", "."], "sentence-detokenized": "The term computational linguistics was coined by David Hays, a founding member of the Association for Computational Linguistics and the International Committee for Computational Linguistics (ICCL).", "token2charspan": [[0, 3], [4, 8], [9, 22], [23, 34], [35, 38], [39, 45], [46, 48], [49, 54], [55, 59], [59, 60], [61, 62], [63, 71], [72, 78], [79, 81], [82, 85], [86, 97], [98, 101], [102, 115], [116, 127], [128, 131], [132, 135], [136, 149], [150, 159], [160, 163], [164, 177], [178, 189], [190, 191], [191, 195], [195, 196], [196, 197]]}
{"doc_key": "ai-train-99", "ner": [[9, 16, "misc"], [14, 14, "misc"], [35, 37, "metrics"], [39, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[39, 39, 35, 37, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["59", ",", "pp.", "2547-2553", ",", "Oct.", "2011", "In", "the", "one", "-dimensional", "polynomial", "-", "based", "DPD", "with", "memory", "(", "or", "without", "memory", ")", ",", "to", "solve", "the", "coefficients", "of", "the", "digital", "predistorter", "polynomials", "and", "minimise", "the", "mean", "square", "error", "(", "MSE", ")", ",", "the", "distorted", "output", "of", "the", "nonlinear", "system", "must", "be", "oversampled", "at", "a", "rate", "that", "captures", "the", "nonlinear", "products", "of", "the", "digital", "predistorter", "order", "."], "sentence-detokenized": "59, pp. 2547-2553, Oct. 2011 In the one-dimensional polynomial-based DPD with memory (or without memory), to solve the coefficients of the digital predistorter polynomials and minimise the mean square error (MSE), the distorted output of the nonlinear system must be oversampled at a rate that captures the nonlinear products of the digital predistorter order.", "token2charspan": [[0, 2], [2, 3], [4, 7], [8, 17], [17, 18], [19, 23], [24, 28], [29, 31], [32, 35], [36, 39], [39, 51], [52, 62], [62, 63], [63, 68], [69, 72], [73, 77], [78, 84], [85, 86], [86, 88], [89, 96], [97, 103], [103, 104], [104, 105], [106, 108], [109, 114], [115, 118], [119, 131], [132, 134], [135, 138], [139, 146], [147, 159], [160, 171], [172, 175], [176, 184], [185, 188], [189, 193], [194, 200], [201, 206], [207, 208], [208, 211], [211, 212], [212, 213], [214, 217], [218, 227], [228, 234], [235, 237], [238, 241], [242, 251], [252, 258], [259, 263], [264, 266], [267, 278], [279, 281], [282, 283], [284, 288], [289, 293], [294, 302], [303, 306], [307, 316], [317, 325], [326, 328], [329, 332], [333, 340], [341, 353], [354, 359], [359, 360]]}
{"doc_key": "ai-train-100", "ner": [[0, 1, "researcher"], [10, 10, "location"], [12, 14, "location"], [16, 17, "country"], [21, 21, "location"], [23, 23, "country"], [38, 46, "organisation"], [47, 49, "organisation"], [51, 51, "location"], [59, 60, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 1, 10, 10, "physical", "", false, false], [0, 1, 47, 49, "physical", "", false, false], [0, 1, 59, 60, "role", "", false, false], [10, 10, 12, 14, "physical", "", false, false], [12, 14, 16, 17, "physical", "", false, false], [38, 46, 47, 49, "part-of", "", false, false], [47, 49, 51, 51, "physical", "", false, false], [59, 60, 38, 46, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Boris", "Katz", ",", "(", "born", "5", "October", "1947", ",", "in", "Chi\u0219in\u0103u", ",", "S.S.S.R.", "of", "Moldova", ",", "Soviet", "Union", ",", "(", "now", "Chi\u0219in\u0103u", ",", "Moldova", ")", ")", "is", "an", "American", "senior", "research", "scientist", "(", "computer", "scientist", ")", "at", "the", "MIT", "Computer", "Science", "and", "Artificial", "Intelligence", "Laboratory", ",", "Massachusetts", "Institute", "of", "Technology", ",", "Cambridge", ",", "and", "head", "of", "the", "Laboratory", "'s", "InfoLab", "Group", "."], "sentence-detokenized": "Boris Katz, (born 5 October 1947, in Chi\u0219in\u0103u, S.S.S.R. of Moldova, Soviet Union, (now Chi\u0219in\u0103u, Moldova)) is an American senior research scientist (computer scientist) at the MIT Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, and head of the Laboratory's InfoLab Group.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 13], [13, 17], [18, 19], [20, 27], [28, 32], [32, 33], [34, 36], [37, 45], [45, 46], [47, 55], [56, 58], [59, 66], [66, 67], [68, 74], [75, 80], [80, 81], [82, 83], [83, 86], [87, 95], [95, 96], [97, 104], [104, 105], [105, 106], [107, 109], [110, 112], [113, 121], [122, 128], [129, 137], [138, 147], [148, 149], [149, 157], [158, 167], [167, 168], [169, 171], [172, 175], [176, 179], [180, 188], [189, 196], [197, 200], [201, 211], [212, 224], [225, 235], [235, 236], [237, 250], [251, 260], [261, 263], [264, 274], [274, 275], [276, 285], [285, 286], [287, 290], [291, 295], [296, 298], [299, 302], [303, 313], [313, 315], [316, 323], [324, 329], [329, 330]]}
