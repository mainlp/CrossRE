{"doc_key": "ai-dev-1", "ner": [[2, 2, "metrics"], [7, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 2, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Here", ",", "accuracy", "is", "measured", "by", "the", "error", "rate", ",", "which", "is", "defined", "as", ":"], "sentence-detokenized": "Here, accuracy is measured by the error rate, which is defined as:", "token2charspan": [[0, 4], [4, 5], [6, 14], [15, 17], [18, 26], [27, 29], [30, 33], [34, 39], [40, 44], [44, 45], [46, 51], [52, 54], [55, 62], [63, 65], [65, 66]]}
{"doc_key": "ai-dev-2", "ner": [[4, 4, "algorithm"], [11, 12, "misc"], [16, 18, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 11, 12, "type-of", "", false, false], [4, 4, 16, 18, "related-to", "", false, false], [4, 4, 19, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["From", "this", "perspective", ",", "SVM", "is", "closely", "related", "to", "other", "fundamental", "classification", "algorithms", ",", "such", "as", "regularised", "least", "squares", "logistic", "regression", "."], "sentence-detokenized": "From this perspective, SVM is closely related to other fundamental classification algorithms, such as regularised least squares logistic regression.", "token2charspan": [[0, 4], [5, 9], [10, 21], [21, 22], [23, 26], [27, 29], [30, 37], [38, 45], [46, 48], [49, 54], [55, 66], [67, 81], [82, 92], [92, 93], [94, 98], [99, 101], [102, 113], [114, 119], [120, 127], [128, 136], [137, 147], [147, 148]]}
{"doc_key": "ai-dev-3", "ner": [[0, 1, "person"], [3, 4, "person"], [13, 14, "person"], [16, 16, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 0, 1, "named", "actor_plays_character", false, false], [3, 4, 0, 1, "origin", "actor_plays_character", false, false], [16, 16, 13, 14, "named", "actor_plays_character", false, false], [16, 16, 13, 14, "origin", "actor_plays_character", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Brion", "James", "plays", "Leon", "Kowalski", ",", "a", "combat", "and", "labour", "replicant", ",", "and", "Joanna", "Cassidy", "plays", "Zhora", ",", "an", "assassin", "replicant", "."], "sentence-detokenized": "Brion James plays Leon Kowalski, a combat and labour replicant, and Joanna Cassidy plays Zhora, an assassin replicant.", "token2charspan": [[0, 5], [6, 11], [12, 17], [18, 22], [23, 31], [31, 32], [33, 34], [35, 41], [42, 45], [46, 52], [53, 62], [62, 63], [64, 67], [68, 74], [75, 82], [83, 88], [89, 94], [94, 95], [96, 98], [99, 107], [108, 117], [117, 118]]}
{"doc_key": "ai-dev-4", "ner": [[18, 20, "product"], [22, 22, "product"], [17, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 20, 17, 17, "physical", "", false, false], [22, 22, 18, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "image", "that", "was", "scanned", ",", "stored", "and", "recreated", "in", "digital", "pixels", "was", "displayed", "on", "the", "NIST", "Eastern", "Automated", "Computer", "(", "SEAC", ")", "."], "sentence-detokenized": "The first image that was scanned, stored and recreated in digital pixels was displayed on the NIST Eastern Automated Computer (SEAC).", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 20], [21, 24], [25, 32], [32, 33], [34, 40], [41, 44], [45, 54], [55, 57], [58, 65], [66, 72], [73, 76], [77, 86], [87, 89], [90, 93], [94, 98], [99, 106], [107, 116], [117, 125], [126, 127], [127, 131], [131, 132], [132, 133]]}
{"doc_key": "ai-dev-5", "ner": [[0, 6, "task"], [20, 21, "task"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 6, 20, 21, "part-of", "", false, false], [0, 6, 23, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Segmenting", "text", "into", "topics", "or", "discursive", "turns", "can", "be", "useful", "in", "some", "natural", "processing", "tasks", ":", "it", "can", "significantly", "improve", "information", "retrieval", "or", "speech", "recognition", "(", "indexing", "/", "recognising", "documents", "more", "accurately", "or", "resulting", "in", "the", "specific", "part", "of", "a", "document", "corresponding", "to", "the", "query", ")", "."], "sentence-detokenized": "Segmenting text into topics or discursive turns can be useful in some natural processing tasks: it can significantly improve information retrieval or speech recognition (indexing/recognising documents more accurately or resulting in the specific part of a document corresponding to the query).", "token2charspan": [[0, 10], [11, 15], [16, 20], [21, 27], [28, 30], [31, 41], [42, 47], [48, 51], [52, 54], [55, 61], [62, 64], [65, 69], [70, 77], [78, 88], [89, 94], [94, 95], [96, 98], [99, 102], [103, 116], [117, 124], [125, 136], [137, 146], [147, 149], [150, 156], [157, 168], [169, 170], [170, 178], [178, 179], [179, 190], [191, 200], [201, 205], [206, 216], [217, 219], [220, 229], [230, 232], [233, 236], [237, 245], [246, 250], [251, 253], [254, 255], [256, 264], [265, 278], [279, 281], [282, 285], [286, 291], [291, 292], [292, 293]]}
{"doc_key": "ai-dev-6", "ner": [[8, 9, "university"], [21, 22, "conference"], [24, 25, "university"], [34, 35, "researcher"], [37, 38, "researcher"], [40, 41, "researcher"], [43, 44, "researcher"], [46, 47, "researcher"], [49, 50, "researcher"], [52, 54, "researcher"], [56, 57, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[21, 22, 24, 25, "physical", "", false, false], [34, 35, 21, 22, "physical", "", false, false], [34, 35, 21, 22, "role", "", false, false], [34, 35, 21, 22, "temporal", "", false, false], [37, 38, 21, 22, "physical", "", false, false], [37, 38, 21, 22, "role", "", false, false], [37, 38, 21, 22, "temporal", "", false, false], [40, 41, 21, 22, "physical", "", false, false], [40, 41, 21, 22, "role", "", false, false], [40, 41, 21, 22, "temporal", "", false, false], [43, 44, 21, 22, "physical", "", false, false], [43, 44, 21, 22, "role", "", false, false], [43, 44, 21, 22, "temporal", "", false, false], [46, 47, 21, 22, "physical", "", false, false], [46, 47, 21, 22, "role", "", false, false], [46, 47, 21, 22, "temporal", "", false, false], [49, 50, 21, 22, "physical", "", false, false], [49, 50, 21, 22, "role", "", false, false], [49, 50, 21, 22, "temporal", "", false, false], [52, 54, 21, 22, "physical", "", false, false], [52, 54, 21, 22, "role", "", false, false], [52, 54, 21, 22, "temporal", "", false, false], [56, 57, 21, 22, "physical", "", false, false], [56, 57, 21, 22, "role", "", false, false], [56, 57, 21, 22, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "sentence": ["In", "1999", "he", "organised", "such", "a", "symposium", "at", "Indiana", "University", ",", "and", "in", "April", "2000", "he", "organised", "a", "larger", "symposium", "entitled", "Spiritual", "Robots", "at", "Stanford", "University", ",", "where", "he", "moderated", "a", "panel", "consisting", "of", "Ray", "Kurzweil", ",", "Hans", "Moravec", ",", "Kevin", "Kelly", ",", "Ralph", "Merkle", ",", "Bill", "Joy", ",", "Frank", "Drake", ",", "John", "Henry", "Holland", "and", "John", "Koza", "."], "sentence-detokenized": "In 1999 he organised such a symposium at Indiana University, and in April 2000 he organised a larger symposium entitled Spiritual Robots at Stanford University, where he moderated a panel consisting of Ray Kurzweil, Hans Moravec, Kevin Kelly, Ralph Merkle, Bill Joy, Frank Drake, John Henry Holland and John Koza.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 20], [21, 25], [26, 27], [28, 37], [38, 40], [41, 48], [49, 59], [59, 60], [61, 64], [65, 67], [68, 73], [74, 78], [79, 81], [82, 91], [92, 93], [94, 100], [101, 110], [111, 119], [120, 129], [130, 136], [137, 139], [140, 148], [149, 159], [159, 160], [161, 166], [167, 169], [170, 179], [180, 181], [182, 187], [188, 198], [199, 201], [202, 205], [206, 214], [214, 215], [216, 220], [221, 228], [228, 229], [230, 235], [236, 241], [241, 242], [243, 248], [249, 255], [255, 256], [257, 261], [262, 265], [265, 266], [267, 272], [273, 278], [278, 279], [280, 284], [285, 290], [291, 298], [299, 302], [303, 307], [308, 312], [312, 313]]}
{"doc_key": "ai-dev-7", "ner": [[4, 4, "metrics"], [5, 5, "metrics"], [8, 8, "metrics"], [9, 9, "metrics"], [18, 18, "metrics"], [40, 40, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 4, 18, 18, "named", "", false, false], [5, 5, 4, 4, "named", "", false, false], [8, 8, 40, 40, "named", "", false, false], [9, 9, 8, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "considers", "both", "the", "accuracy", "p", "and", "the", "recall", "r", "of", "the", "test", "to", "calculate", "the", "score", ":", "p", "is", "the", "number", "of", "correct", "positive", "results", "divided", "by", "the", "number", "of", "all", "positive", "results", "returned", "by", "the", "classifier", ",", "and", "r", "is", "the", "number", "of", "correct", "positive", "results", "divided", "by", "the", "number", "of", "all", "relevant", "samples", "(", "all", "samples", "that", "should", "have", "been", "identified", "as", "positive", ")", "."], "sentence-detokenized": "It considers both the accuracy p and the recall r of the test to calculate the score: p is the number of correct positive results divided by the number of all positive results returned by the classifier, and r is the number of correct positive results divided by the number of all relevant samples (all samples that should have been identified as positive).", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 21], [22, 30], [31, 32], [33, 36], [37, 40], [41, 47], [48, 49], [50, 52], [53, 56], [57, 61], [62, 64], [65, 74], [75, 78], [79, 84], [84, 85], [86, 87], [88, 90], [91, 94], [95, 101], [102, 104], [105, 112], [113, 121], [122, 129], [130, 137], [138, 140], [141, 144], [145, 151], [152, 154], [155, 158], [159, 167], [168, 175], [176, 184], [185, 187], [188, 191], [192, 202], [202, 203], [204, 207], [208, 209], [210, 212], [213, 216], [217, 223], [224, 226], [227, 234], [235, 243], [244, 251], [252, 259], [260, 262], [263, 266], [267, 273], [274, 276], [277, 280], [281, 289], [290, 297], [298, 299], [299, 302], [303, 310], [311, 315], [316, 322], [323, 327], [328, 332], [333, 343], [344, 346], [347, 355], [355, 356], [356, 357]]}
{"doc_key": "ai-dev-8", "ner": [[3, 4, "organisation"], [22, 22, "product"], [30, 31, "person"], [37, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 22, 22, "artifact", "", false, false], [22, 22, 30, 31, "win-defeat", "", false, false], [22, 22, 37, 37, "win-defeat", "", true, false], [30, 31, 37, 37, "win-defeat", "lose", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "the", "acquisition", "by", "Google", ",", "the", "company", "has", "scored", "a", "number", "of", "significant", "achievements", ",", "perhaps", "most", "notably", "the", "creation", "of", "AlphaGo", ",", "a", "programme", "that", "defeated", "world", "champion", "Lee", "Sedol", "in", "the", "complex", "game", "of", "Go", "."], "sentence-detokenized": "Since the acquisition by Google, the company has scored a number of significant achievements, perhaps most notably the creation of AlphaGo, a programme that defeated world champion Lee Sedol in the complex game of Go.", "token2charspan": [[0, 5], [6, 9], [10, 21], [22, 24], [25, 31], [31, 32], [33, 36], [37, 44], [45, 48], [49, 55], [56, 57], [58, 64], [65, 67], [68, 79], [80, 92], [92, 93], [94, 101], [102, 106], [107, 114], [115, 118], [119, 127], [128, 130], [131, 138], [138, 139], [140, 141], [142, 151], [152, 156], [157, 165], [166, 171], [172, 180], [181, 184], [185, 190], [191, 193], [194, 197], [198, 205], [206, 210], [211, 213], [214, 216], [216, 217]]}
{"doc_key": "ai-dev-9", "ner": [[11, 11, "misc"], [25, 25, "field"], [29, 31, "product"], [48, 49, "misc"], [12, 54, "misc"], [57, 57, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 25, 25, "part-of", "", false, false], [11, 11, 12, 54, "named", "same", false, false], [29, 31, 48, 49, "related-to", "", false, false], [29, 31, 12, 54, "usage", "", false, false], [29, 31, 57, 57, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Representing", "words", "in", "context", "through", "dense", "vectors", "of", "fixed", "size", "(", "word", "embedding", ")", "has", "become", "one", "of", "the", "most", "fundamental", "building", "blocks", "of", "several", "NLP", "systems", ".", "An", "unsupervised", "disambiguation", "system", "uses", "the", "similarity", "between", "word", "senses", "in", "a", "fixed", "context", "window", "to", "select", "the", "most", "appropriate", "word", "sense", "using", "a", "pre-trained", "word", "embedding", "model", "and", "WordNet", "."], "sentence-detokenized": "Representing words in context through dense vectors of fixed size (word embedding) has become one of the most fundamental building blocks of several NLP systems. An unsupervised disambiguation system uses the similarity between word senses in a fixed context window to select the most appropriate word sense using a pre-trained word embedding model and WordNet.", "token2charspan": [[0, 12], [13, 18], [19, 21], [22, 29], [30, 37], [38, 43], [44, 51], [52, 54], [55, 60], [61, 65], [66, 67], [67, 71], [72, 81], [81, 82], [83, 86], [87, 93], [94, 97], [98, 100], [101, 104], [105, 109], [110, 121], [122, 130], [131, 137], [138, 140], [141, 148], [149, 152], [153, 160], [160, 161], [162, 164], [165, 177], [178, 192], [193, 199], [200, 204], [205, 208], [209, 219], [220, 227], [228, 232], [233, 239], [240, 242], [243, 244], [245, 250], [251, 258], [259, 265], [266, 268], [269, 275], [276, 279], [280, 284], [285, 296], [297, 301], [302, 307], [308, 313], [314, 315], [316, 327], [328, 332], [333, 342], [343, 348], [349, 352], [353, 360], [360, 361]]}
{"doc_key": "ai-dev-10", "ner": [[0, 1, "field"], [5, 6, "field"], [8, 9, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 0, 1, "part-of", "", false, false], [8, 9, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "techniques", ",", "either", "supervised", "learning", "or", "unsupervised", "learning", ",", "have", "been", "used", "to", "induce", "such", "rules", "automatically", "."], "sentence-detokenized": "Machine learning techniques, either supervised learning or unsupervised learning, have been used to induce such rules automatically.", "token2charspan": [[0, 7], [8, 16], [17, 27], [27, 28], [29, 35], [36, 46], [47, 55], [56, 58], [59, 71], [72, 80], [80, 81], [82, 86], [87, 91], [92, 96], [97, 99], [100, 106], [107, 111], [112, 117], [118, 131], [131, 132]]}
{"doc_key": "ai-dev-11", "ner": [[3, 3, "researcher"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1969", ",", "Scheinman", "invented", "the", "Stanford", "arm", ","], "sentence-detokenized": "In 1969, Scheinman invented the Stanford arm,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 27], [28, 31], [32, 40], [41, 44], [44, 45]]}
{"doc_key": "ai-dev-12", "ner": [[2, 3, "metrics"], [8, 11, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Since", "the", "log", "loss", "is", "differentiable", ",", "a", "gradient", "-", "based", "method", "can", "be", "used", "to", "optimise", "the", "model", "."], "sentence-detokenized": "Since the log loss is differentiable, a gradient-based method can be used to optimise the model.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 18], [19, 21], [22, 36], [36, 37], [38, 39], [40, 48], [48, 49], [49, 54], [55, 61], [62, 65], [66, 68], [69, 73], [74, 76], [77, 85], [86, 89], [90, 95], [95, 96]]}
{"doc_key": "ai-dev-13", "ner": [[1, 2, "field"], [4, 6, "algorithm"], [8, 8, "algorithm"], [11, 13, "algorithm"], [16, 17, "field"], [27, 27, "task"], [29, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 6, 16, 17, "part-of", "", false, false], [8, 8, 4, 6, "named", "", false, false], [11, 13, 4, 6, "named", "", false, false], [16, 17, 1, 2, "part-of", "subfield", false, false], [27, 27, 16, 17, "part-of", "", false, false], [29, 30, 16, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "machine", "learning", ",", "support", "vector", "machines", "(", "SVMs", ",", "also", "support", "vector", "networks", ")", "are", "supervised", "learning", "models", "with", "learning", "algorithms", "that", "analyse", "data", "used", "for", "classification", "and", "regression", "analysis", "."], "sentence-detokenized": "In machine learning, support vector machines (SVMs, also support vector networks) are supervised learning models with learning algorithms that analyse data used for classification and regression analysis.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 28], [29, 35], [36, 44], [45, 46], [46, 50], [50, 51], [52, 56], [57, 64], [65, 71], [72, 80], [80, 81], [82, 85], [86, 96], [97, 105], [106, 112], [113, 117], [118, 126], [127, 137], [138, 142], [143, 150], [151, 155], [156, 160], [161, 164], [165, 179], [180, 183], [184, 194], [195, 203], [203, 204]]}
{"doc_key": "ai-dev-14", "ner": [[9, 9, "task"], [11, 11, "task"], [29, 29, "metrics"], [31, 31, "metrics"], [33, 33, "researcher"], [35, 35, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 9, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "2002", ")", "as", "an", "automatic", "metric", "for", "machine", "translation", "(", "MT", ")", "evaluation", ",", "many", "other", "methods", "have", "been", "proposed", "to", "revise", "or", "improve", "it", ",", "such", "as", "TER", ",", "METEOR", ",", "Banerjee", "and", "Lavie", ",", "(", "2005", ")", ",", "etc", "."], "sentence-detokenized": "(2002) as an automatic metric for machine translation (MT) evaluation, many other methods have been proposed to revise or improve it, such as TER, METEOR, Banerjee and Lavie, (2005), etc.", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 9], [10, 12], [13, 22], [23, 29], [30, 33], [34, 41], [42, 53], [54, 55], [55, 57], [57, 58], [59, 69], [69, 70], [71, 75], [76, 81], [82, 89], [90, 94], [95, 99], [100, 108], [109, 111], [112, 118], [119, 121], [122, 129], [130, 132], [132, 133], [134, 138], [139, 141], [142, 145], [145, 146], [147, 153], [153, 154], [155, 163], [164, 167], [168, 173], [173, 174], [175, 176], [176, 180], [180, 181], [181, 182], [183, 186], [186, 187]]}
{"doc_key": "ai-dev-15", "ner": [[3, 4, "misc"], [9, 9, "organisation"], [10, 10, "organisation"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 10, 10, "origin", "", false, false], [10, 10, 9, 9, "part-of", "", false, false], [16, 17, 10, 10, "role", "", false, false], [19, 20, 10, 10, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "includes", "an", "upper", "ontology", ",", "created", "by", "the", "IEEE", "P1600.1", "working", "group", "(", "originally", "by", "Ian", "Niles", "and", "Adam", "Pease", ")", "."], "sentence-detokenized": "It includes an upper ontology, created by the IEEE P1600.1 working group (originally by Ian Niles and Adam Pease).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 20], [21, 29], [29, 30], [31, 38], [39, 41], [42, 45], [46, 50], [51, 58], [59, 66], [67, 72], [73, 74], [74, 84], [85, 87], [88, 91], [92, 97], [98, 101], [102, 106], [107, 112], [112, 113], [113, 114]]}
{"doc_key": "ai-dev-16", "ner": [[1, 3, "misc"], [32, 34, "algorithm"], [36, 39, "algorithm"], [40, 41, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[32, 34, 1, 3, "part-of", "", true, false], [36, 39, 1, 3, "part-of", "", true, false], [40, 41, 36, 39, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "cryo", "electron", "tomography", ",", "where", "a", "limited", "number", "of", "projections", "are", "acquired", "due", "to", "hardware", "limitations", "and", "to", "avoid", "damage", "to", "the", "biological", "specimen", ",", "it", "can", "be", "used", "together", "with", "compressive", "sensing", "techniques", "or", "regularisation", "functions", "(", "e.g.", "Huber", "loss", ")", "to", "improve", "reconstruction", "for", "better", "interpretation", "."], "sentence-detokenized": "In cryo electron tomography, where a limited number of projections are acquired due to hardware limitations and to avoid damage to the biological specimen, it can be used together with compressive sensing techniques or regularisation functions (e.g. Huber loss) to improve reconstruction for better interpretation.", "token2charspan": [[0, 2], [3, 7], [8, 16], [17, 27], [27, 28], [29, 34], [35, 36], [37, 44], [45, 51], [52, 54], [55, 66], [67, 70], [71, 79], [80, 83], [84, 86], [87, 95], [96, 107], [108, 111], [112, 114], [115, 120], [121, 127], [128, 130], [131, 134], [135, 145], [146, 154], [154, 155], [156, 158], [159, 162], [163, 165], [166, 170], [171, 179], [180, 184], [185, 196], [197, 204], [205, 215], [216, 218], [219, 233], [234, 243], [244, 245], [245, 249], [250, 255], [256, 260], [260, 261], [262, 264], [265, 272], [273, 287], [288, 291], [292, 298], [299, 313], [313, 314]]}
{"doc_key": "ai-dev-17", "ner": [[4, 4, "misc"], [7, 7, "programlang"], [10, 10, "algorithm"], [13, 14, "algorithm"], [17, 17, "algorithm"], [24, 26, "product"], [29, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 4, 7, 7, "part-of", "", false, false], [10, 10, 4, 4, "type-of", "", false, false], [13, 14, 4, 4, "type-of", "", false, false], [17, 17, 4, 4, "type-of", "", false, false], [24, 26, 7, 7, "general-affiliation", "", true, false], [24, 26, 7, 7, "part-of", "", true, false], [29, 29, 24, 26, "role", "publishes", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["An", "implementation", "of", "various", "laundering", "procedures", "in", "R", ",", "including", "ZCA", "laundering", "and", "PCA", "laundering", "but", "also", "CCA", "laundering", ",", "is", "available", "in", "the", "R", "laundering", "package", "published", "on", "CRAN", "."], "sentence-detokenized": "An implementation of various laundering procedures in R, including ZCA laundering and PCA laundering but also CCA laundering, is available in the R laundering package published on CRAN.", "token2charspan": [[0, 2], [3, 17], [18, 20], [21, 28], [29, 39], [40, 50], [51, 53], [54, 55], [55, 56], [57, 66], [67, 70], [71, 81], [82, 85], [86, 89], [90, 100], [101, 104], [105, 109], [110, 113], [114, 124], [124, 125], [126, 128], [129, 138], [139, 141], [142, 145], [146, 147], [148, 158], [159, 166], [167, 176], [177, 179], [180, 184], [184, 185]]}
{"doc_key": "ai-dev-18", "ner": [[28, 28, "product"], [30, 30, "product"], [32, 32, "product"], [34, 34, "product"], [36, 36, "product"], [38, 38, "product"], [41, 42, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[28, 28, 32, 32, "compare", "", false, false], [28, 28, 34, 34, "compare", "", false, false], [28, 28, 36, 36, "compare", "", false, false], [28, 28, 38, 38, "compare", "", false, false], [28, 28, 41, 42, "compare", "", false, false], [30, 30, 32, 32, "compare", "", false, false], [30, 30, 34, 34, "compare", "", false, false], [30, 30, 36, 36, "compare", "", false, false], [30, 30, 38, 38, "compare", "", false, false], [30, 30, 41, 42, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Today", ",", "this", "field", "has", "become", "even", "more", "daunting", "and", "complex", "with", "the", "incorporation", "of", "circuit", ",", "system", "and", "signal", "analysis", "and", "design", "languages", "and", "software", ",", "from", "MATLAB", "and", "Simulink", "to", "NumPy", ",", "VHDL", ",", "PSpice", ",", "Verilog", "and", "even", "assembly", "language", "."], "sentence-detokenized": "Today, this field has become even more daunting and complex with the incorporation of circuit, system and signal analysis and design languages and software, from MATLAB and Simulink to NumPy, VHDL, PSpice, Verilog and even assembly language.", "token2charspan": [[0, 5], [5, 6], [7, 11], [12, 17], [18, 21], [22, 28], [29, 33], [34, 38], [39, 47], [48, 51], [52, 59], [60, 64], [65, 68], [69, 82], [83, 85], [86, 93], [93, 94], [95, 101], [102, 105], [106, 112], [113, 121], [122, 125], [126, 132], [133, 142], [143, 146], [147, 155], [155, 156], [157, 161], [162, 168], [169, 172], [173, 181], [182, 184], [185, 190], [190, 191], [192, 196], [196, 197], [198, 204], [204, 205], [206, 213], [214, 217], [218, 222], [223, 231], [232, 240], [240, 241]]}
{"doc_key": "ai-dev-19", "ner": [[5, 6, "person"], [16, 17, "person"], [21, 22, "organisation"], [26, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 22, 16, 17, "origin", "", false, false], [26, 26, 21, 22, "artifact", "builds", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "company", "was", "founded", "by", "Kiichiro", "Toyoda", "in", "1937", ",", "as", "a", "spin", "-", "off", "from", "Sakichi", "Toyoda", "'s", "company", ",", "Toyota", "Industries", ",", "to", "create", "automobiles", "."], "sentence-detokenized": "The company was founded by Kiichiro Toyoda in 1937, as a spin-off from Sakichi Toyoda's company, Toyota Industries, to create automobiles.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 26], [27, 35], [36, 42], [43, 45], [46, 50], [50, 51], [52, 54], [55, 56], [57, 61], [61, 62], [62, 65], [66, 70], [71, 78], [79, 85], [85, 87], [88, 95], [95, 96], [97, 103], [104, 114], [114, 115], [116, 118], [119, 125], [126, 137], [137, 138]]}
{"doc_key": "ai-dev-20", "ner": [[0, 1, "field"], [55, 55, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[55, 55, 0, 1, "origin", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Unsupervised", "learning", ",", "on", "the", "other", "hand", ",", "starts", "from", "training", "data", "that", "has", "not", "been", "labelled", "by", "hand", ",", "and", "attempts", "to", "find", "inherent", "patterns", "in", "the", "data", "that", "can", "be", "used", "to", "determine", "the", "correct", "output", "value", "for", "new", "data", "instances", "....", "A", "combination", "of", "the", "two", "that", "has", "recently", "been", "explored", "is", "semi-supervised", "learning", ",", "which", "uses", "a", "combination", "of", "labelled", "and", "unlabelled", "data", "(", "typically", "a", "small", "set", "of", "labelled", "data", "combined", "with", "a", "large", "amount", "of", "unlabelled", "data", ")", "."], "sentence-detokenized": "Unsupervised learning, on the other hand, starts from training data that has not been labelled by hand, and attempts to find inherent patterns in the data that can be used to determine the correct output value for new data instances.... A combination of the two that has recently been explored is semi-supervised learning, which uses a combination of labelled and unlabelled data (typically a small set of labelled data combined with a large amount of unlabelled data).", "token2charspan": [[0, 12], [13, 21], [21, 22], [23, 25], [26, 29], [30, 35], [36, 40], [40, 41], [42, 48], [49, 53], [54, 62], [63, 67], [68, 72], [73, 76], [77, 80], [81, 85], [86, 94], [95, 97], [98, 102], [102, 103], [104, 107], [108, 116], [117, 119], [120, 124], [125, 133], [134, 142], [143, 145], [146, 149], [150, 154], [155, 159], [160, 163], [164, 166], [167, 171], [172, 174], [175, 184], [185, 188], [189, 196], [197, 203], [204, 209], [210, 213], [214, 217], [218, 222], [223, 232], [232, 236], [237, 238], [239, 250], [251, 253], [254, 257], [258, 261], [262, 266], [267, 270], [271, 279], [280, 284], [285, 293], [294, 296], [297, 312], [313, 321], [321, 322], [323, 328], [329, 333], [334, 335], [336, 347], [348, 350], [351, 359], [360, 363], [364, 374], [375, 379], [380, 381], [381, 390], [391, 392], [393, 398], [399, 402], [403, 405], [406, 414], [415, 419], [420, 428], [429, 433], [434, 435], [436, 441], [442, 448], [449, 451], [452, 462], [463, 467], [467, 468], [468, 469]]}
{"doc_key": "ai-dev-21", "ner": [[20, 20, "organisation"], [22, 22, "product"], [24, 25, "organisation"], [27, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 20, 20, "artifact", "", false, false], [24, 25, 27, 27, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Despite", "these", "humanoid", "robots", "for", "utilitarian", "uses", ",", "there", "are", "some", "humanoid", "robots", "whose", "purpose", "is", "entertainment", ",", "such", "as", "Sony", "'s", "QRIO", "and", "Wow", "Wee", "'s", "RoboSapien", "."], "sentence-detokenized": "Despite these humanoid robots for utilitarian uses, there are some humanoid robots whose purpose is entertainment, such as Sony's QRIO and Wow Wee's RoboSapien.", "token2charspan": [[0, 7], [8, 13], [14, 22], [23, 29], [30, 33], [34, 45], [46, 50], [50, 51], [52, 57], [58, 61], [62, 66], [67, 75], [76, 82], [83, 88], [89, 96], [97, 99], [100, 113], [113, 114], [115, 119], [120, 122], [123, 127], [127, 129], [130, 134], [135, 138], [139, 142], [143, 146], [146, 148], [149, 159], [159, 160]]}
{"doc_key": "ai-dev-22", "ner": [[0, 2, "researcher"], [6, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 6, 12, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Webber", "became", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "in", "1991", ","], "sentence-detokenized": "Webber became a member of the Association for the Advancement of Artificial Intelligence in 1991,", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 22], [23, 25], [26, 29], [30, 41], [42, 45], [46, 49], [50, 61], [62, 64], [65, 75], [76, 88], [89, 91], [92, 96], [96, 97]]}
{"doc_key": "ai-dev-23", "ner": [[5, 6, "field"], [8, 8, "field"], [18, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 23, 5, 6, "part-of", "task_part_of_field", false, false], [18, 23, 8, 8, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "this", "company", "he", "developed", "data", "mining", "and", "database", "technology", ",", "more", "specifically", "high", "-", "level", "ontologies", "for", "automated", "natural", "language", "intelligence", "and", "understanding", "."], "sentence-detokenized": "In this company he developed data mining and database technology, more specifically high-level ontologies for automated natural language intelligence and understanding.", "token2charspan": [[0, 2], [3, 7], [8, 15], [16, 18], [19, 28], [29, 33], [34, 40], [41, 44], [45, 53], [54, 64], [64, 65], [66, 70], [71, 83], [84, 88], [88, 89], [89, 94], [95, 105], [106, 109], [110, 119], [120, 127], [128, 136], [137, 149], [150, 153], [154, 167], [167, 168]]}
{"doc_key": "ai-dev-24", "ner": [[22, 24, "misc"], [27, 30, "misc"], [33, 34, "misc"], [39, 39, "country"], [42, 44, "organisation"], [46, 46, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[22, 24, 39, 39, "physical", "", false, false], [27, 30, 39, 39, "physical", "", false, false], [33, 34, 39, 39, "physical", "", false, false], [42, 44, 46, 46, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["However", ",", "in", "recent", "years", ",", "one", "can", "observe", "the", "emergence", "of", "different", "e-services", "and", "related", "initiatives", "in", "developing", "countries", "such", "as", "the", "Nemmadi", "Project", ",", "the", "MCA21", "Mission", "Mode", "Project", "or", "the", "Digital", "India", "even", "more", ",", "in", "India", ";", "the", "Directorate", "of", "e-Governance", "in", "Pakistan", ";", "etc."], "sentence-detokenized": "However, in recent years, one can observe the emergence of different e-services and related initiatives in developing countries such as the Nemmadi Project, the MCA21 Mission Mode Project or the Digital India even more, in India; the Directorate of e-Governance in Pakistan; etc.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 18], [19, 24], [24, 25], [26, 29], [30, 33], [34, 41], [42, 45], [46, 55], [56, 58], [59, 68], [69, 79], [80, 83], [84, 91], [92, 103], [104, 106], [107, 117], [118, 127], [128, 132], [133, 135], [136, 139], [140, 147], [148, 155], [155, 156], [157, 160], [161, 166], [167, 174], [175, 179], [180, 187], [188, 190], [191, 194], [195, 202], [203, 208], [209, 213], [214, 218], [218, 219], [220, 222], [223, 228], [228, 229], [230, 233], [234, 245], [246, 248], [249, 261], [262, 264], [265, 273], [273, 274], [275, 279]]}
{"doc_key": "ai-dev-25", "ner": [[0, 0, "misc"], [2, 2, "field"], [4, 5, "field"], [7, 9, "university"], [12, 14, "university"], [21, 23, "university"], [27, 27, "misc"], [29, 30, "field"], [34, 36, "misc"], [38, 39, "university"], [41, 44, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 0, 2, 2, "topic", "", false, false], [0, 0, 4, 5, "topic", "", false, false], [0, 0, 7, 9, "origin", "", false, false], [7, 9, 12, 14, "part-of", "", false, false], [21, 23, 7, 9, "part-of", "", false, false], [27, 27, 29, 30, "topic", "", false, false], [27, 27, 38, 39, "origin", "", false, false], [34, 36, 38, 39, "origin", "", false, false], [38, 39, 41, 44, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["D.", "in", "Radiophysics", "and", "Electronics", "from", "the", "Rajabazar", "Science", "College", "campus", "of", "Calcutta", "University", "in", "1979", "as", "a", "student", "of", "the", "Indian", "Statistical", "Institute", ",", "and", "another", "Ph.D.", "in", "Electrical", "Engineering", "along", "with", "the", "Imperial", "College", "Diploma", "from", "Imperial", "College", ",", "University", "of", "London", "in", "1982", "."], "sentence-detokenized": "D. in Radiophysics and Electronics from the Rajabazar Science College campus of Calcutta University in 1979 as a student of the Indian Statistical Institute, and another Ph.D. in Electrical Engineering along with the Imperial College Diploma from Imperial College, University of London in 1982.", "token2charspan": [[0, 2], [3, 5], [6, 18], [19, 22], [23, 34], [35, 39], [40, 43], [44, 53], [54, 61], [62, 69], [70, 76], [77, 79], [80, 88], [89, 99], [100, 102], [103, 107], [108, 110], [111, 112], [113, 120], [121, 123], [124, 127], [128, 134], [135, 146], [147, 156], [156, 157], [158, 161], [162, 169], [170, 175], [176, 178], [179, 189], [190, 201], [202, 207], [208, 212], [213, 216], [217, 225], [226, 233], [234, 241], [242, 246], [247, 255], [256, 263], [263, 264], [265, 275], [276, 278], [279, 285], [286, 288], [289, 293], [293, 294]]}
{"doc_key": "ai-dev-26", "ner": [[0, 16, "location"], [20, 23, "misc"], [29, 30, "misc"], [32, 34, "person"], [36, 37, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[20, 23, 0, 16, "temporal", "", false, false], [29, 30, 0, 16, "temporal", "", false, false], [32, 34, 29, 30, "role", "actor_in", false, false], [36, 37, 29, 30, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["At", "Expo", "II", ",", "the", "world", "premieres", "of", "several", "never", "-", "before", "-", "seen", "3D", "films", "were", "announced", ",", "including", "The", "Wizard", "of", "Diamonds", "and", "Universal", "'s", "short", "film", "Hawaiian", "Nights", "starring", "Mamie", "Van", "Doren", "and", "Pinky", "Lee", "."], "sentence-detokenized": "At Expo II, the world premieres of several never-before-seen 3D films were announced, including The Wizard of Diamonds and Universal's short film Hawaiian Nights starring Mamie Van Doren and Pinky Lee.", "token2charspan": [[0, 2], [3, 7], [8, 10], [10, 11], [12, 15], [16, 21], [22, 31], [32, 34], [35, 42], [43, 48], [48, 49], [49, 55], [55, 56], [56, 60], [61, 63], [64, 69], [70, 74], [75, 84], [84, 85], [86, 95], [96, 99], [100, 106], [107, 109], [110, 118], [119, 122], [123, 132], [132, 134], [135, 140], [141, 145], [146, 154], [155, 161], [162, 170], [171, 176], [177, 180], [181, 186], [187, 190], [191, 196], [197, 200], [200, 201]]}
{"doc_key": "ai-dev-27", "ner": [[7, 8, "researcher"], [16, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 16, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "maximum", "submatrix", "problem", "was", "proposed", "by", "Ulf", "Grenander", "in", "1977", "as", "a", "simplified", "model", "for", "maximum", "likelihood", "estimation", "of", "patterns", "in", "digitised", "images", "."], "sentence-detokenized": "The maximum submatrix problem was proposed by Ulf Grenander in 1977 as a simplified model for maximum likelihood estimation of patterns in digitised images.", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 29], [30, 33], [34, 42], [43, 45], [46, 49], [50, 59], [60, 62], [63, 67], [68, 70], [71, 72], [73, 83], [84, 89], [90, 93], [94, 101], [102, 112], [113, 123], [124, 126], [127, 135], [136, 138], [139, 148], [149, 155], [155, 156]]}
{"doc_key": "ai-dev-28", "ner": [[0, 1, "product"], [3, 4, "product"], [6, 8, "product"], [10, 11, "product"], [13, 15, "product"], [17, 20, "product"], [31, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[31, 31, 0, 1, "part-of", "", false, false], [31, 31, 3, 4, "part-of", "", false, false], [31, 31, 6, 8, "part-of", "", false, false], [31, 31, 10, 11, "part-of", "", false, false], [31, 31, 13, 15, "part-of", "", false, false], [31, 31, 17, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["iPhone", "4S", ",", "iPad", "3", ",", "iPad", "Mini", "1G", ",", "iPad", "Air", ",", "iPad", "Pro", "1G", "and", "iPod", "Touch", "5", "G", "and", "later", "come", "with", "a", "more", "advanced", "voice", "assistant", "called", "Siri", "."], "sentence-detokenized": "iPhone 4S, iPad 3, iPad Mini 1G, iPad Air, iPad Pro 1G and iPod Touch 5G and later come with a more advanced voice assistant called Siri.", "token2charspan": [[0, 6], [7, 9], [9, 10], [11, 15], [16, 17], [17, 18], [19, 23], [24, 28], [29, 31], [31, 32], [33, 37], [38, 41], [41, 42], [43, 47], [48, 51], [52, 54], [55, 58], [59, 63], [64, 69], [70, 71], [71, 72], [73, 76], [77, 82], [83, 87], [88, 92], [93, 94], [95, 99], [100, 108], [109, 114], [115, 124], [125, 131], [132, 136], [136, 137]]}
{"doc_key": "ai-dev-29", "ner": [[7, 8, "metrics"], [11, 11, "metrics"], [16, 17, "metrics"], [47, 48, "metrics"], [55, 58, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 11, 47, 48, "named", "", false, false], [16, 17, 11, 11, "named", "", false, false], [47, 48, 55, 58, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["It", "is", "easy", "to", "check", "that", "the", "logistic", "loss", "and", "the", "binary", "cross", "-entropy", "loss", "(", "log", "loss", ")", "are", "in", "fact", "the", "same", "(", "up", "to", "a", "multiplicative", "constant", "math", "frac", "{", "1", "}", "{", "log", "(", "2", ")", "}", "/", "math", ")", ".", "{", "The", "cross", "-entropy", "loss", "is", "closely", "related", "to", "the", "Kullback", "-", "Leibler", "divergence", "between", "the", "empirical", "distribution", "and", "the", "predicted", "distribution", "."], "sentence-detokenized": "It is easy to check that the logistic loss and the binary cross-entropy loss (log loss) are in fact the same (up to a multiplicative constant math frac {1} {log (2)} / math). {The cross-entropy loss is closely related to the Kullback-Leibler divergence between the empirical distribution and the predicted distribution.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 13], [14, 19], [20, 24], [25, 28], [29, 37], [38, 42], [43, 46], [47, 50], [51, 57], [58, 63], [63, 71], [72, 76], [77, 78], [78, 81], [82, 86], [86, 87], [88, 91], [92, 94], [95, 99], [100, 103], [104, 108], [109, 110], [110, 112], [113, 115], [116, 117], [118, 132], [133, 141], [142, 146], [147, 151], [152, 153], [153, 154], [154, 155], [156, 157], [157, 160], [161, 162], [162, 163], [163, 164], [164, 165], [166, 167], [168, 172], [172, 173], [173, 174], [175, 176], [176, 179], [180, 185], [185, 193], [194, 198], [199, 201], [202, 209], [210, 217], [218, 220], [221, 224], [225, 233], [233, 234], [234, 241], [242, 252], [253, 260], [261, 264], [265, 274], [275, 287], [288, 291], [292, 295], [296, 305], [306, 318], [318, 319]]}
{"doc_key": "ai-dev-30", "ner": [[1, 2, "algorithm"], [11, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 1, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "EM", "algorithm", "is", "used", "to", "find", "the", "(", "local", ")", "maximum", "likelihood", "parameters", "of", "a", "statistical", "model", "in", "cases", "where", "the", "equations", "can", "not", "be", "solved", "directly", "."], "sentence-detokenized": "The EM algorithm is used to find the (local) maximum likelihood parameters of a statistical model in cases where the equations cannot be solved directly.", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 19], [20, 24], [25, 27], [28, 32], [33, 36], [37, 38], [38, 43], [43, 44], [45, 52], [53, 63], [64, 74], [75, 77], [78, 79], [80, 91], [92, 97], [98, 100], [101, 106], [107, 112], [113, 116], [117, 126], [127, 130], [130, 133], [134, 136], [137, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-dev-31", "ner": [[9, 10, "task"], [13, 17, "task"], [23, 23, "task"], [22, 28, "task"], [32, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "research", "was", "fundamental", "to", "the", "development", "of", "modern", "speech", "synthesis", "techniques", ",", "reading", "machines", "for", "the", "blind", ",", "the", "study", "of", "speech", "perception", "and", "recognition", ",", "and", "the", "development", "of", "the", "motor", "theory", "of", "speech", "perception", "."], "sentence-detokenized": "This research was fundamental to the development of modern speech synthesis techniques, reading machines for the blind, the study of speech perception and recognition, and the development of the motor theory of speech perception.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 29], [30, 32], [33, 36], [37, 48], [49, 51], [52, 58], [59, 65], [66, 75], [76, 86], [86, 87], [88, 95], [96, 104], [105, 108], [109, 112], [113, 118], [118, 119], [120, 123], [124, 129], [130, 132], [133, 139], [140, 150], [151, 154], [155, 166], [166, 167], [168, 171], [172, 175], [176, 187], [188, 190], [191, 194], [195, 200], [201, 207], [208, 210], [211, 217], [218, 228], [228, 229]]}
{"doc_key": "ai-dev-32", "ner": [[1, 1, "product"], [2, 4, "misc"], [6, 6, "misc"], [10, 12, "misc"], [15, 15, "product"], [17, 17, "product"], [19, 19, "product"], [26, 26, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 4, 1, 1, "origin", "", false, false], [2, 4, 10, 12, "type-of", "", false, false], [2, 4, 15, 15, "related-to", "program_for", false, false], [2, 4, 17, 17, "related-to", "program_for", false, false], [2, 4, 19, 19, "related-to", "program_for", false, false], [2, 4, 26, 26, "related-to", "program_for", false, false], [6, 6, 2, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "Arduino", "Integrated", "Development", "Environment", "(", "IDE", ")", "is", "a", "cross", "-platform", "application", "(", "for", "Windows", ",", "macOS", "and", "Linux", ")", "that", "is", "written", "in", "the", "Java", "programming", "language", "."], "sentence-detokenized": "The Arduino Integrated Development Environment (IDE) is a cross-platform application (for Windows, macOS and Linux) that is written in the Java programming language.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 34], [35, 46], [47, 48], [48, 51], [51, 52], [53, 55], [56, 57], [58, 63], [63, 72], [73, 84], [85, 86], [86, 89], [90, 97], [97, 98], [99, 104], [105, 108], [109, 114], [114, 115], [116, 120], [121, 123], [124, 131], [132, 134], [135, 138], [139, 143], [144, 155], [156, 164], [164, 165]]}
{"doc_key": "ai-dev-33", "ner": [[2, 3, "algorithm"], [10, 11, "field"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 10, 11, "opposite", "", false, false], [14, 15, 10, 11, "related-to", "works_with", false, false], [17, 18, 10, 11, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Research", "on", "neural", "networks", "stagnated", "after", "the", "publication", "of", "the", "machine", "learning", "research", "of", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", "."], "sentence-detokenized": "Research on neural networks stagnated after the publication of the machine learning research of Marvin Minsky and Seymour Papert (1969).", "token2charspan": [[0, 8], [9, 11], [12, 18], [19, 27], [28, 37], [38, 43], [44, 47], [48, 59], [60, 62], [63, 66], [67, 74], [75, 83], [84, 92], [93, 95], [96, 102], [103, 109], [110, 113], [114, 121], [122, 128], [129, 130], [130, 134], [134, 135], [135, 136]]}
{"doc_key": "ai-dev-34", "ner": [[17, 18, "organisation"], [20, 20, "organisation"], [23, 25, "country"], [27, 30, "organisation"], [33, 33, "country"], [35, 36, "organisation"], [39, 39, "country"], [41, 41, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[27, 30, 23, 25, "general-affiliation", "", false, false], [35, 36, 33, 33, "general-affiliation", "", false, false], [41, 41, 39, 39, "general-affiliation", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Only", "a", "few", "non-Japanese", "companies", "finally", "managed", "to", "survive", "in", "this", "market", ",", "the", "main", "ones", "being", "Adept", "Technology", ",", "St\u00e4ubli", ",", "the", "Swedish", "-", "Swiss", "company", "ABB", "Asea", "Brown", "Boveri", ",", "the", "German", "company", "KUKA", "Robotics", "and", "the", "Italian", "company", "Comau", "."], "sentence-detokenized": "Only a few non-Japanese companies finally managed to survive in this market, the main ones being Adept Technology, St\u00e4ubli, the Swedish-Swiss company ABB Asea Brown Boveri, the German company KUKA Robotics and the Italian company Comau.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 23], [24, 33], [34, 41], [42, 49], [50, 52], [53, 60], [61, 63], [64, 68], [69, 75], [75, 76], [77, 80], [81, 85], [86, 90], [91, 96], [97, 102], [103, 113], [113, 114], [115, 122], [122, 123], [124, 127], [128, 135], [135, 136], [136, 141], [142, 149], [150, 153], [154, 158], [159, 164], [165, 171], [171, 172], [173, 176], [177, 183], [184, 191], [192, 196], [197, 205], [206, 209], [210, 213], [214, 221], [222, 229], [230, 235], [235, 236]]}
{"doc_key": "ai-dev-35", "ner": [[9, 10, "conference"], [15, 15, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 15, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Research", "activities", "include", "an", "annual", "research", "conference", ",", "the", "RuleML", "Symposium", ",", "also", "known", "as", "RuleML", "for", "short", "."], "sentence-detokenized": "Research activities include an annual research conference, the RuleML Symposium, also known as RuleML for short.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 30], [31, 37], [38, 46], [47, 57], [57, 58], [59, 62], [63, 69], [70, 79], [79, 80], [81, 85], [86, 91], [92, 94], [95, 101], [102, 105], [106, 111], [111, 112]]}
{"doc_key": "ai-dev-36", "ner": [[9, 9, "field"], [11, 12, "field"], [14, 14, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Concepts", "are", "used", "as", "formal", "tools", "or", "models", "in", "mathematics", ",", "computer", "science", ",", "databases", "and", "artificial", "intelligence", ",", "where", "they", "are", "sometimes", "referred", "to", "as", "classes", ",", "schemas", "or", "categories", "."], "sentence-detokenized": "Concepts are used as formal tools or models in mathematics, computer science, databases and artificial intelligence, where they are sometimes referred to as classes, schemas or categories.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 20], [21, 27], [28, 33], [34, 36], [37, 43], [44, 46], [47, 58], [58, 59], [60, 68], [69, 76], [76, 77], [78, 87], [88, 91], [92, 102], [103, 115], [115, 116], [117, 122], [123, 127], [128, 131], [132, 141], [142, 150], [151, 153], [154, 156], [157, 164], [164, 165], [166, 173], [174, 176], [177, 187], [187, 188]]}
{"doc_key": "ai-dev-37", "ner": [[6, 8, "organisation"], [11, 14, "organisation"], [17, 17, "organisation"], [20, 22, "organisation"], [25, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "received", "awards", "from", "the", "American", "Psychological", "Association", ",", "the", "National", "Academy", "of", "Sciences", ",", "the", "Royal", ",", "the", "Cognitive", "Neuroscience", "Society", "and", "the", "American", "Humanist", "Association", "."], "sentence-detokenized": "He has received awards from the American Psychological Association, the National Academy of Sciences, the Royal, the Cognitive Neuroscience Society and the American Humanist Association.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 22], [23, 27], [28, 31], [32, 40], [41, 54], [55, 66], [66, 67], [68, 71], [72, 80], [81, 88], [89, 91], [92, 100], [100, 101], [102, 105], [106, 111], [111, 112], [113, 116], [117, 126], [127, 139], [140, 147], [148, 151], [152, 155], [156, 164], [165, 173], [174, 185], [185, 186]]}
{"doc_key": "ai-dev-38", "ner": [[1, 2, "person"], [4, 5, "person"], [7, 8, "person"], [15, 16, "person"], [21, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 26, 15, 16, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Starring", "Harrison", "Ford", ",", "Rutger", "Hauer", "and", "Sean", "Young", ",", "it", "is", "loosely", "based", "on", "Philip", "K", ".", "Dick", "'s", "novel", "Do", "Androids", "Dream", "of", "Electric", "Sheep", "(", "1968", ")", "."], "sentence-detokenized": "Starring Harrison Ford, Rutger Hauer and Sean Young, it is loosely based on Philip K. Dick's novel Do Androids Dream of Electric Sheep (1968).", "token2charspan": [[0, 8], [9, 17], [18, 22], [22, 23], [24, 30], [31, 36], [37, 40], [41, 45], [46, 51], [51, 52], [53, 55], [56, 58], [59, 66], [67, 72], [73, 75], [76, 82], [83, 84], [84, 85], [86, 90], [90, 92], [93, 98], [99, 101], [102, 110], [111, 116], [117, 119], [120, 128], [129, 134], [135, 136], [136, 140], [140, 141], [141, 142]]}
{"doc_key": "ai-dev-39", "ner": [[0, 1, "task"], [3, 5, "algorithm"], [11, 12, "field"], [14, 15, "task"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 3, 5, "usage", "", false, false], [0, 1, 11, 12, "part-of", "task_part_of_field", false, false], [0, 1, 14, 15, "part-of", "task_part_of_field", false, false], [0, 1, 17, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Image", "segmentation", "using", "k-means", "clustering", "algorithms", "has", "long", "been", "used", "for", "pattern", "recognition", ",", "object", "detection", "and", "medical", "imaging", "."], "sentence-detokenized": "Image segmentation using k-means clustering algorithms has long been used for pattern recognition, object detection and medical imaging.", "token2charspan": [[0, 5], [6, 18], [19, 24], [25, 32], [33, 43], [44, 54], [55, 58], [59, 63], [64, 68], [69, 73], [74, 77], [78, 85], [86, 97], [97, 98], [99, 105], [106, 115], [116, 119], [120, 127], [128, 135], [135, 136]]}
{"doc_key": "ai-dev-40", "ner": [[12, 12, "algorithm"], [15, 16, "algorithm"], [19, 19, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["General", "truncated", "normal", "sampling", "can", "be", "achieved", "using", "approximations", "to", "the", "normal", "CDF", "and", "the", "probit", "function", ",", "and", "R", "has", "a", "codertnorm", "(", ")", "/", "code", "function", "to", "generate", "truncated", "normal", "samples", "."], "sentence-detokenized": "General truncated normal sampling can be achieved using approximations to the normal CDF and the probit function, and R has a codertnorm () / code function to generate truncated normal samples.", "token2charspan": [[0, 7], [8, 17], [18, 24], [25, 33], [34, 37], [38, 40], [41, 49], [50, 55], [56, 70], [71, 73], [74, 77], [78, 84], [85, 88], [89, 92], [93, 96], [97, 103], [104, 112], [112, 113], [114, 117], [118, 119], [120, 123], [124, 125], [126, 136], [137, 138], [138, 139], [140, 141], [142, 146], [147, 155], [156, 158], [159, 167], [168, 177], [178, 184], [185, 192], [192, 193]]}
{"doc_key": "ai-dev-41", "ner": [[8, 10, "university"], [12, 12, "university"], [14, 15, "university"], [17, 18, "university"], [20, 20, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "also", "received", "honorary", "doctorates", "from", "the", "universities", "of", "Newcastle", ",", "Surrey", ",", "Tel", "Aviv", ",", "Simon", "Fraser", "and", "Troms\u00f8", "."], "sentence-detokenized": "He has also received honorary doctorates from the universities of Newcastle, Surrey, Tel Aviv, Simon Fraser and Troms\u00f8.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 20], [21, 29], [30, 40], [41, 45], [46, 49], [50, 62], [63, 65], [66, 75], [75, 76], [77, 83], [83, 84], [85, 88], [89, 93], [93, 94], [95, 100], [101, 107], [108, 111], [112, 118], [118, 119]]}
{"doc_key": "ai-dev-42", "ner": [[1, 1, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "Java", "implementation", "that", "uses", "zero", "-", "based", "array", "indices", "along", "with", "a", "convenient", "method", "for", "printing", "the", "order", "of", "resolved", "operations", ":"], "sentence-detokenized": "A Java implementation that uses zero-based array indices along with a convenient method for printing the order of resolved operations:", "token2charspan": [[0, 1], [2, 6], [7, 21], [22, 26], [27, 31], [32, 36], [36, 37], [37, 42], [43, 48], [49, 56], [57, 62], [63, 67], [68, 69], [70, 80], [81, 87], [88, 91], [92, 100], [101, 104], [105, 110], [111, 113], [114, 122], [123, 133], [133, 134]]}
{"doc_key": "ai-dev-43", "ner": [[7, 8, "metrics"], [11, 12, "metrics"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Such", "networks", "are", "usually", "trained", "in", "the", "cross", "-entropy", "(", "or", "cross", "-entropy", ")", "regime", ",", "resulting", "in", "a", "non-linear", "variant", "of", "multinomial", "logistic", "regression", "."], "sentence-detokenized": "Such networks are usually trained in the cross-entropy (or cross-entropy) regime, resulting in a non-linear variant of multinomial logistic regression.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 25], [26, 33], [34, 36], [37, 40], [41, 46], [46, 54], [55, 56], [56, 58], [59, 64], [64, 72], [72, 73], [74, 80], [80, 81], [82, 91], [92, 94], [95, 96], [97, 107], [108, 115], [116, 118], [119, 130], [131, 139], [140, 150], [150, 151]]}
{"doc_key": "ai-dev-44", "ner": [[1, 1, "conference"], [4, 4, "misc"], [5, 14, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 1, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ACL", "has", "a", "European", "Chapter", "(", "European", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ")", "."], "sentence-detokenized": "The ACL has a European Chapter (European Chapter of the Association for Computational Linguistics).", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 13], [14, 22], [23, 30], [31, 32], [32, 40], [41, 48], [49, 51], [52, 55], [56, 67], [68, 71], [72, 85], [86, 97], [97, 98], [98, 99]]}
{"doc_key": "ai-dev-45", "ner": [[3, 4, "researcher"], [6, 8, "researcher"], [22, 22, "misc"], [24, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 22, 22, "role", "", false, false], [6, 8, 22, 22, "role", "", false, false], [22, 22, 24, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "professors", ",", "Hal", "Abelson", "and", "Gerald", "Jay", "Sussman", ",", "chose", "to", "remain", "neutral", ";", "their", "group", "was", "variously", "referred", "to", "as", "Switzerland", "and", "Project", "MAC", "for", "the", "next", "30", "years", "."], "sentence-detokenized": "Two professors, Hal Abelson and Gerald Jay Sussman, chose to remain neutral; their group was variously referred to as Switzerland and Project MAC for the next 30 years.", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 27], [28, 31], [32, 38], [39, 42], [43, 50], [50, 51], [52, 57], [58, 60], [61, 67], [68, 75], [75, 76], [77, 82], [83, 88], [89, 92], [93, 102], [103, 111], [112, 114], [115, 117], [118, 129], [130, 133], [134, 141], [142, 145], [146, 149], [150, 153], [154, 158], [159, 161], [162, 167], [167, 168]]}
{"doc_key": "ai-dev-46", "ner": [[2, 2, "misc"], [4, 4, "researcher"], [8, 10, "university"], [15, 15, "organisation"], [20, 22, "organisation"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 4, 4, "temporal", "", false, false], [4, 4, 15, 15, "physical", "", false, false], [4, 4, 15, 15, "role", "", false, false], [4, 4, 20, 22, "role", "", false, false], [20, 22, 8, 10, "part-of", "", false, false], [26, 27, 20, 22, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["After", "his", "PhD", ",", "Ghahramani", "moved", "to", "the", "University", "of", "Toronto", "in", "1995", "as", "an", "ITRC", "postdoctoral", "fellow", "in", "the", "Artificial", "Intelligence", "Laboratory", ",", "working", "with", "Geoffrey", "Hinton", "."], "sentence-detokenized": "After his PhD, Ghahramani moved to the University of Toronto in 1995 as an ITRC postdoctoral fellow in the Artificial Intelligence Laboratory, working with Geoffrey Hinton.", "token2charspan": [[0, 5], [6, 9], [10, 13], [13, 14], [15, 25], [26, 31], [32, 34], [35, 38], [39, 49], [50, 52], [53, 60], [61, 63], [64, 68], [69, 71], [72, 74], [75, 79], [80, 92], [93, 99], [100, 102], [103, 106], [107, 117], [118, 130], [131, 141], [141, 142], [143, 150], [151, 155], [156, 164], [165, 171], [171, 172]]}
{"doc_key": "ai-dev-47", "ner": [[23, 24, "metrics"], [26, 26, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[26, 26, 23, 24, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Subsequent", "work", "focused", "on", "tackling", "these", "problems", ",", "but", "it", "was", "not", "until", "the", "advent", "of", "the", "modern", "computer", "and", "the", "popularisation", "of", "Maximum", "Likelihood", "(", "MLE", ")", "parameterisation", "techniques", "that", "research", "really", "took", "off", "."], "sentence-detokenized": "Subsequent work focused on tackling these problems, but it was not until the advent of the modern computer and the popularisation of Maximum Likelihood (MLE) parameterisation techniques that research really took off.", "token2charspan": [[0, 10], [11, 15], [16, 23], [24, 26], [27, 35], [36, 41], [42, 50], [50, 51], [52, 55], [56, 58], [59, 62], [63, 66], [67, 72], [73, 76], [77, 83], [84, 86], [87, 90], [91, 97], [98, 106], [107, 110], [111, 114], [115, 129], [130, 132], [133, 140], [141, 151], [152, 153], [153, 156], [156, 157], [158, 174], [175, 185], [186, 190], [191, 199], [200, 206], [207, 211], [212, 215], [215, 216]]}
{"doc_key": "ai-dev-48", "ner": [[5, 6, "person"], [9, 10, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "series", "was", "produced", "by", "David", "Fincher", "and", "starred", "Kevin", "Spacey", "."], "sentence-detokenized": "The series was produced by David Fincher and starred Kevin Spacey.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 26], [27, 32], [33, 40], [41, 44], [45, 52], [53, 58], [59, 65], [65, 66]]}
{"doc_key": "ai-dev-49", "ner": [[18, 18, "metrics"], [25, 26, "algorithm"], [32, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[25, 26, 32, 35, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Due", "to", "the", "limits", "of", "computational", "power", ",", "current", "in", "silico", "methods", "often", "have", "to", "trade", "speed", "for", "accuracy", ",", "for", "example", ",", "using", "fast", "protein", "docking", "methods", "instead", "of", "computationally", "expensive", "free", "-", "energy", "calculations", "."], "sentence-detokenized": "Due to the limits of computational power, current in silico methods often have to trade speed for accuracy, for example, using fast protein docking methods instead of computationally expensive free-energy calculations.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 17], [18, 20], [21, 34], [35, 40], [40, 41], [42, 49], [50, 52], [53, 59], [60, 67], [68, 73], [74, 78], [79, 81], [82, 87], [88, 93], [94, 97], [98, 106], [106, 107], [108, 111], [112, 119], [119, 120], [121, 126], [127, 131], [132, 139], [140, 147], [148, 155], [156, 163], [164, 166], [167, 182], [183, 192], [193, 197], [197, 198], [198, 204], [205, 217], [217, 218]]}
{"doc_key": "ai-dev-50", "ner": [[8, 9, "country"], [11, 11, "country"], [13, 13, "country"], [15, 15, "country"], [17, 17, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "had", "more", "than", "30", "locations", "in", "the", "United", "States", ",", "Canada", ",", "Mexico", ",", "Brazil", "and", "Argentina", "."], "sentence-detokenized": "It had more than 30 locations in the United States, Canada, Mexico, Brazil and Argentina.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 19], [20, 29], [30, 32], [33, 36], [37, 43], [44, 50], [50, 51], [52, 58], [58, 59], [60, 66], [66, 67], [68, 74], [75, 78], [79, 88], [88, 89]]}
{"doc_key": "ai-dev-51", "ner": [[4, 5, "field"], [10, 12, "product"], [14, 16, "algorithm"], [19, 20, "task"], [22, 23, "task"], [30, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 12, 4, 5, "part-of", "", false, false], [10, 12, 14, 16, "usage", "", false, false], [19, 20, 4, 5, "part-of", "task_part_of_field", false, false], [19, 20, 30, 30, "related-to", "performs", false, false], [22, 23, 4, 5, "part-of", "task_part_of_field", false, false], [22, 23, 30, 30, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Example", "of", "a", "typical", "computer", "vision", "computation", "pipeline", "for", "a", "face", "recognition", "system", "using", "k", "-", "NN", ",", "including", "feature", "extraction", "and", "dimension", "reduction", "pre-processing", "steps", "(", "usually", "implemented", "with", "OpenCV", ")", ":"], "sentence-detokenized": "Example of a typical computer vision computation pipeline for a face recognition system using k -NN, including feature extraction and dimension reduction pre-processing steps (usually implemented with OpenCV):", "token2charspan": [[0, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 36], [37, 48], [49, 57], [58, 61], [62, 63], [64, 68], [69, 80], [81, 87], [88, 93], [94, 95], [96, 97], [97, 99], [99, 100], [101, 110], [111, 118], [119, 129], [130, 133], [134, 143], [144, 153], [154, 168], [169, 174], [175, 176], [176, 183], [184, 195], [196, 200], [201, 207], [207, 208], [208, 209]]}
{"doc_key": "ai-dev-52", "ner": [[9, 11, "algorithm"], [13, 13, "misc"], [15, 16, "misc"], [18, 18, "misc"], [22, 22, "programlang"], [24, 24, "product"], [28, 29, "algorithm"], [32, 33, "misc"], [35, 35, "misc"], [37, 37, "misc"], [39, 39, "misc"], [46, 46, "misc"], [49, 50, "misc"], [53, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "has", "a", "rich", "feature", "set", ",", "libraries", "for", "constraint", "logic", "programming", ",", "multi-threading", ",", "unit", "testing", ",", "GUI", ",", "interfacing", "with", "Java", ",", "ODBC", "and", "others", ",", "alphabetised", "programming", ",", "a", "web", "server", ",", "SGML", ",", "RDF", ",", "RDFS", ",", "developer", "tools", "(", "including", "an", "IDE", "with", "a", "GUI", "debugger", "and", "a", "GUI", "profiler", ")", ",", "and", "extensive", "documentation", "."], "sentence-detokenized": "It has a rich feature set, libraries for constraint logic programming, multi-threading, unit testing, GUI, interfacing with Java, ODBC and others, alphabetised programming, a web server, SGML, RDF, RDFS, developer tools (including an IDE with a GUI debugger and a GUI profiler), and extensive documentation.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 13], [14, 21], [22, 25], [25, 26], [27, 36], [37, 40], [41, 51], [52, 57], [58, 69], [69, 70], [71, 86], [86, 87], [88, 92], [93, 100], [100, 101], [102, 105], [105, 106], [107, 118], [119, 123], [124, 128], [128, 129], [130, 134], [135, 138], [139, 145], [145, 146], [147, 159], [160, 171], [171, 172], [173, 174], [175, 178], [179, 185], [185, 186], [187, 191], [191, 192], [193, 196], [196, 197], [198, 202], [202, 203], [204, 213], [214, 219], [220, 221], [221, 230], [231, 233], [234, 237], [238, 242], [243, 244], [245, 248], [249, 257], [258, 261], [262, 263], [264, 267], [268, 276], [276, 277], [277, 278], [279, 282], [283, 292], [293, 306], [306, 307]]}
{"doc_key": "ai-dev-53", "ner": [[2, 2, "field"], [4, 5, "field"], [10, 12, "misc"], [14, 16, "misc"], [20, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 12, 2, 2, "part-of", "", true, false], [10, 12, 4, 5, "part-of", "", false, false], [10, 12, 20, 22, "type-of", "", false, false], [14, 16, 2, 2, "part-of", "", false, false], [14, 16, 4, 5, "part-of", "", false, false], [14, 16, 20, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "computer", "vision", "and", "image", "processing", ",", "the", "notion", "of", "scale", "space", "representation", "and", "Gaussian", "derivative", "operators", "is", "like", "a", "canonical", "multiscale", "representation", "."], "sentence-detokenized": "In computer vision and image processing, the notion of scale space representation and Gaussian derivative operators is like a canonical multiscale representation.", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 22], [23, 28], [29, 39], [39, 40], [41, 44], [45, 51], [52, 54], [55, 60], [61, 66], [67, 81], [82, 85], [86, 94], [95, 105], [106, 115], [116, 118], [119, 123], [124, 125], [126, 135], [136, 146], [147, 161], [161, 162]]}
{"doc_key": "ai-dev-54", "ner": [[11, 11, "organisation"], [7, 24, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 11, 7, 24, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "also", "the", "President", "of", "the", "Neural", "Information", "Processing", "Systems", "Foundation", ",", "a", "non-profit", "organisation", "that", "oversees", "the", "annual", "Neural", "Information", "Processing", "Systems", "Conference", "."], "sentence-detokenized": "He is also the President of the Neural Information Processing Systems Foundation, a non-profit organisation that oversees the annual Neural Information Processing Systems Conference.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 14], [15, 24], [25, 27], [28, 31], [32, 38], [39, 50], [51, 61], [62, 69], [70, 80], [80, 81], [82, 83], [84, 94], [95, 107], [108, 112], [113, 121], [122, 125], [126, 132], [133, 139], [140, 151], [152, 162], [163, 170], [171, 181], [181, 182]]}
{"doc_key": "ai-dev-55", "ner": [[1, 2, "task"], [5, 11, "metrics"], [12, 13, "misc"], [16, 16, "task"], [18, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 5, 11, "usage", "", false, false], [5, 11, 12, 13, "type-of", "", false, false], [16, 16, 18, 19, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["For", "regression", "analysis", "problems", "the", "squared", "error", "can", "be", "used", "as", "a", "loss", "function", ",", "for", "classification", "the", "cross", "-entropy", "can", "be", "used", "."], "sentence-detokenized": "For regression analysis problems the squared error can be used as a loss function, for classification the cross-entropy can be used.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 32], [33, 36], [37, 44], [45, 50], [51, 54], [55, 57], [58, 62], [63, 65], [66, 67], [68, 72], [73, 81], [81, 82], [83, 86], [87, 101], [102, 105], [106, 111], [111, 119], [120, 123], [124, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-dev-56", "ner": [[0, 1, "researcher"], [19, 19, "conference"], [17, 22, "conference"], [31, 31, "university"], [36, 38, "field"], [47, 51, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 19, 19, "role", "", false, false], [0, 1, 31, 31, "physical", "", false, false], [0, 1, 31, 31, "role", "", false, false], [0, 1, 47, 51, "role", "", false, false], [19, 19, 17, 22, "named", "same", false, false], [31, 31, 36, 38, "related-to", "subject_of_study_at", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Lafferty", "held", "many", "prestigious", "positions", ",", "including", "(", "1", ")", "programme", "co-chair", "and", "general", "co-chair", "of", "the", "Conference", "on", "Neural", "Information", "Processing", "Systems", "Foundation", "conferences", ";", "(", "2", ")", "co-director", "of", "CMU", "'s", "new", "Ph.D.", "programme", "in", "machine", "learning", ";", "(", "3", ")", "associate", "editor", "of", "the", "Journal", "of", "Machine", "Learning", "Research"], "sentence-detokenized": "Lafferty held many prestigious positions, including (1) programme co-chair and general co-chair of the Conference on Neural Information Processing Systems Foundation conferences; (2) co-director of CMU's new Ph.D. programme in machine learning; (3) associate editor of the Journal of Machine Learning Research", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 30], [31, 40], [40, 41], [42, 51], [52, 53], [53, 54], [54, 55], [56, 65], [66, 74], [75, 78], [79, 86], [87, 95], [96, 98], [99, 102], [103, 113], [114, 116], [117, 123], [124, 135], [136, 146], [147, 154], [155, 165], [166, 177], [177, 178], [179, 180], [180, 181], [181, 182], [183, 194], [195, 197], [198, 201], [201, 203], [204, 207], [208, 213], [214, 223], [224, 226], [227, 234], [235, 243], [243, 244], [245, 246], [246, 247], [247, 248], [249, 258], [259, 265], [266, 268], [269, 272], [273, 280], [281, 283], [284, 291], [292, 300], [301, 309]]}
{"doc_key": "ai-dev-57", "ner": [[0, 1, "misc"], [5, 5, "algorithm"], [7, 7, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 0, 1, "type-of", "", false, false], [7, 7, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Convex", "algorithms", ",", "such", "as", "AdaBoost", "and", "LogitBoost", ",", "can", "be", "defeated", "by", "random", "noise", ",", "so", "they", "can", "not", "learn", "basic", ",", "learnable", "combinations", "of", "weak", "hypotheses", "."], "sentence-detokenized": "Convex algorithms, such as AdaBoost and LogitBoost, can be defeated by random noise, so they cannot learn basic, learnable combinations of weak hypotheses.", "token2charspan": [[0, 6], [7, 17], [17, 18], [19, 23], [24, 26], [27, 35], [36, 39], [40, 50], [50, 51], [52, 55], [56, 58], [59, 67], [68, 70], [71, 77], [78, 83], [83, 84], [85, 87], [88, 92], [93, 96], [96, 99], [100, 105], [106, 111], [111, 112], [113, 122], [123, 135], [136, 138], [139, 143], [144, 154], [154, 155]]}
{"doc_key": "ai-dev-58", "ner": [[0, 0, "product"], [3, 7, "product"], [10, 13, "algorithm"], [20, 21, "algorithm"], [24, 29, "task"], [32, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 7, "type-of", "", false, false], [0, 0, 10, 13, "usage", "", false, false], [0, 0, 20, 21, "usage", "", false, false], [20, 21, 24, 29, "related-to", "used_for", true, false], [20, 21, 32, 33, "related-to", "used_for", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Apertium", "is", "a", "surface", "transfer", "machine", "translation", "system", "that", "uses", "finite", "-", "state", "transducers", "for", "all", "its", "lexical", "transformations", "and", "hidden", "Markov", "models", "for", "part", "-", "of", "-", "speech", "tagging", "or", "word", "category", "disambiguation", "."], "sentence-detokenized": "Apertium is a surface transfer machine translation system that uses finite-state transducers for all its lexical transformations and hidden Markov models for part-of-speech tagging or word category disambiguation.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 21], [22, 30], [31, 38], [39, 50], [51, 57], [58, 62], [63, 67], [68, 74], [74, 75], [75, 80], [81, 92], [93, 96], [97, 100], [101, 104], [105, 112], [113, 128], [129, 132], [133, 139], [140, 146], [147, 153], [154, 157], [158, 162], [162, 163], [163, 165], [165, 166], [166, 172], [173, 180], [181, 183], [184, 188], [189, 197], [198, 212], [212, 213]]}
{"doc_key": "ai-dev-59", "ner": [[1, 2, "misc"], [14, 17, "metrics"], [32, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 14, 17, "related-to", "", true, false], [14, 17, 32, 33, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "natural", "gradient", "of", "mathE", "f", "(", "x", ")", "/", "math", ",", "complying", "with", "Fisher", "'s", "information", "metric", "(", "a", "measure", "of", "informative", "distance", "between", "probability", "distributions", "and", "the", "curvature", "of", "the", "relative", "entropy", ")", ",", "now", "says"], "sentence-detokenized": "The natural gradient of mathE f (x) / math, complying with Fisher's information metric (a measure of informative distance between probability distributions and the curvature of the relative entropy), now says", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 23], [24, 29], [30, 31], [32, 33], [33, 34], [34, 35], [36, 37], [38, 42], [42, 43], [44, 53], [54, 58], [59, 65], [65, 67], [68, 79], [80, 86], [87, 88], [88, 89], [90, 97], [98, 100], [101, 112], [113, 121], [122, 129], [130, 141], [142, 155], [156, 159], [160, 163], [164, 173], [174, 176], [177, 180], [181, 189], [190, 197], [197, 198], [198, 199], [200, 203], [204, 208]]}
{"doc_key": "ai-dev-60", "ner": [[0, 3, "programlang"], [6, 9, "product"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 9, 0, 3, "origin", "", false, false], [11, 11, 0, 3, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "programming", "language", "S", "inspired", "the", "S", "'", "-", "PLUS", "and", "R", "systems", "."], "sentence-detokenized": "The programming language S inspired the S '-PLUS and R systems.", "token2charspan": [[0, 3], [4, 15], [16, 24], [25, 26], [27, 35], [36, 39], [40, 41], [42, 43], [43, 44], [44, 48], [49, 52], [53, 54], [55, 62], [62, 63]]}
{"doc_key": "ai-dev-61", "ner": [[5, 5, "product"], [10, 10, "product"], [13, 15, "product"], [19, 21, "researcher"], [23, 24, "researcher"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 10, 10, "named", "same", false, false], [13, 15, 10, 10, "origin", "derived_from", false, false], [13, 15, 19, 21, "origin", "", false, false], [13, 15, 23, 24, "origin", "", false, false], [13, 15, 26, 27, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "most", "influential", "implementation", "of", "Planner", "was", "the", "subset", "of", "Planner", ",", "called", "Micro", "-", "Planner", ",", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "."], "sentence-detokenized": "The most influential implementation of Planner was the subset of Planner, called Micro-Planner, implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd.", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 35], [36, 38], [39, 46], [47, 50], [51, 54], [55, 61], [62, 64], [65, 72], [72, 73], [74, 80], [81, 86], [86, 87], [87, 94], [94, 95], [96, 107], [108, 110], [111, 117], [118, 121], [122, 129], [129, 130], [131, 137], [138, 146], [147, 150], [151, 156], [157, 165], [165, 166]]}
{"doc_key": "ai-dev-62", "ner": [[4, 6, "country"], [8, 10, "researcher"], [21, 21, "misc"], [20, 26, "university"], [34, 36, "misc"], [43, 44, "misc"], [47, 49, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [[8, 10, 4, 6, "general-affiliation", "from_country", false, false], [20, 26, 21, 21, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "1779", ",", "the", "German", "-", "Denmark", "scientist", "Christian", "Gottlieb", "Kratzenstein", "won", "first", "prize", "in", "a", "competition", "organised", "by", "the", "Imperial", "Russian", "Academy", "of", "Sciences", "and", "Arts", "for", "the", "models", "he", "constructed", "of", "the", "human", "vocal", "tract", "that", "could", "produce", "the", "five", "long", "vowel", "sounds", "(", "in", "International", "Phonetic", "Alphabet", "notation", ")", ":"], "sentence-detokenized": "In 1779, the German-Denmark scientist Christian Gottlieb Kratzenstein won first prize in a competition organised by the Imperial Russian Academy of Sciences and Arts for the models he constructed of the human vocal tract that could produce the five long vowel sounds (in International Phonetic Alphabet notation):", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 19], [19, 20], [20, 27], [28, 37], [38, 47], [48, 56], [57, 69], [70, 73], [74, 79], [80, 85], [86, 88], [89, 90], [91, 102], [103, 112], [113, 115], [116, 119], [120, 128], [129, 136], [137, 144], [145, 147], [148, 156], [157, 160], [161, 165], [166, 169], [170, 173], [174, 180], [181, 183], [184, 195], [196, 198], [199, 202], [203, 208], [209, 214], [215, 220], [221, 225], [226, 231], [232, 239], [240, 243], [244, 248], [249, 253], [254, 259], [260, 266], [267, 268], [268, 270], [271, 284], [285, 293], [294, 302], [303, 311], [311, 312], [312, 313]]}
{"doc_key": "ai-dev-63", "ner": [[3, 4, "product"], [6, 7, "misc"], [10, 14, "misc"], [32, 34, "misc"], [55, 56, "task"], [61, 62, "product"], [64, 64, "product"], [68, 71, "task"], [70, 70, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 4, 61, 62, "related-to", "supports_program", false, false], [3, 4, 64, 64, "related-to", "supports_program", false, false], [6, 7, 3, 4, "part-of", "", false, false], [10, 14, 3, 4, "part-of", "", false, false], [32, 34, 3, 4, "part-of", "", false, false], [55, 56, 3, 4, "part-of", "", false, false], [68, 71, 3, 4, "part-of", "", false, false], [70, 70, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["New", "features", "in", "Office", "XP", "include", "smart", "tags", ",", "a", "selection", "-", "based", "search", "function", "that", "recognises", "different", "types", "of", "text", "in", "a", "document", "so", "users", "can", "perform", "additional", "actions", ";", "a", "task", "pane", "interface", "that", "consolidates", "the", "most", "popular", "menu", "bar", "commands", "on", "the", "right", "side", "of", "the", "screen", "for", "quick", "access", ";", "new", "document", "collaboration", "capabilities", ",", "support", "for", "MSN", "Groups", "and", "SharePoint", ";", "and", "integrated", "handwriting", "and", "speech", "recognition", "capabilities", "."], "sentence-detokenized": "New features in Office XP include smart tags, a selection-based search function that recognises different types of text in a document so users can perform additional actions; a task pane interface that consolidates the most popular menu bar commands on the right side of the screen for quick access; new document collaboration capabilities, support for MSN Groups and SharePoint; and integrated handwriting and speech recognition capabilities.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 22], [23, 25], [26, 33], [34, 39], [40, 44], [44, 45], [46, 47], [48, 57], [57, 58], [58, 63], [64, 70], [71, 79], [80, 84], [85, 95], [96, 105], [106, 111], [112, 114], [115, 119], [120, 122], [123, 124], [125, 133], [134, 136], [137, 142], [143, 146], [147, 154], [155, 165], [166, 173], [173, 174], [175, 176], [177, 181], [182, 186], [187, 196], [197, 201], [202, 214], [215, 218], [219, 223], [224, 231], [232, 236], [237, 240], [241, 249], [250, 252], [253, 256], [257, 262], [263, 267], [268, 270], [271, 274], [275, 281], [282, 285], [286, 291], [292, 298], [298, 299], [300, 303], [304, 312], [313, 326], [327, 339], [339, 340], [341, 348], [349, 352], [353, 356], [357, 363], [364, 367], [368, 378], [378, 379], [380, 383], [384, 394], [395, 406], [407, 410], [411, 417], [418, 429], [430, 442], [442, 443]]}
{"doc_key": "ai-dev-64", "ner": [[10, 11, "algorithm"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 14, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "many", "applications", "the", "units", "of", "these", "networks", "apply", "a", "sigmoid", "function", "as", "an", "activation", "function", "."], "sentence-detokenized": "In many applications the units of these networks apply a sigmoid function as an activation function.", "token2charspan": [[0, 2], [3, 7], [8, 20], [21, 24], [25, 30], [31, 33], [34, 39], [40, 48], [49, 54], [55, 56], [57, 64], [65, 73], [74, 76], [77, 79], [80, 90], [91, 99], [99, 100]]}
{"doc_key": "ai-dev-65", "ner": [[3, 3, "researcher"], [12, 17, "organisation"], [29, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 12, 17, "role", "", false, false], [3, 3, 29, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2001", ",", "Mehler", "was", "elected", "an", "honorary", "foreign", "member", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "and", "in", "2003", "he", "was", "elected", "a", "fellow", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In 2001, Mehler was elected an honorary foreign member of the American Academy of Arts and Sciences, and in 2003 he was elected a fellow of the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 27], [28, 30], [31, 39], [40, 47], [48, 54], [55, 57], [58, 61], [62, 70], [71, 78], [79, 81], [82, 86], [87, 90], [91, 99], [99, 100], [101, 104], [105, 107], [108, 112], [113, 115], [116, 119], [120, 127], [128, 129], [130, 136], [137, 139], [140, 143], [144, 152], [153, 164], [165, 168], [169, 172], [173, 184], [185, 187], [188, 195], [195, 196]]}
{"doc_key": "ai-dev-66", "ner": [[6, 8, "task"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 13, 14, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "extension", "of", "this", "concept", "to", "non", "-binary", "classifications", "gives", "rise", "to", "the", "confusion", "matrix", "."], "sentence-detokenized": "The extension of this concept to non-binary classifications gives rise to the confusion matrix.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 21], [22, 29], [30, 32], [33, 36], [36, 43], [44, 59], [60, 65], [66, 70], [71, 73], [74, 77], [78, 87], [88, 94], [94, 95]]}
{"doc_key": "ai-dev-67", "ner": [[14, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "updated", "estimate", "of", "the", "variance", "of", "measurement", "noise", "can", "be", "obtained", "from", "the", "maximum", "likelihood", "calculation", "."], "sentence-detokenized": "An updated estimate of the variance of measurement noise can be obtained from the maximum likelihood calculation.", "token2charspan": [[0, 2], [3, 10], [11, 19], [20, 22], [23, 26], [27, 35], [36, 38], [39, 50], [51, 56], [57, 60], [61, 63], [64, 72], [73, 77], [78, 81], [82, 89], [90, 100], [101, 112], [112, 113]]}
{"doc_key": "ai-dev-68", "ner": [[1, 2, "field"], [5, 7, "algorithm"], [8, 11, "field"], [9, 10, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 7, 8, 11, "usage", "", true, false], [5, 7, 9, 10, "related-to", "", true, false], [8, 11, 1, 2, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "machine", "learning", ",", "the", "perceptron", "is", "a", "supervised", "binary", "classification", "learning", "algorithm", "."], "sentence-detokenized": "In machine learning, the perceptron is a supervised binary classification learning algorithm.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 24], [25, 35], [36, 38], [39, 40], [41, 51], [52, 58], [59, 73], [74, 82], [83, 92], [92, 93]]}
{"doc_key": "ai-dev-69", "ner": [[8, 9, "field"], [11, 11, "field"], [16, 22, "conference"], [25, 29, "conference"], [32, 38, "conference"], [41, 46, "conference"], [48, 52, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[16, 22, 8, 9, "topic", "", false, false], [16, 22, 11, 11, "topic", "", false, false], [25, 29, 8, 9, "topic", "", false, false], [25, 29, 11, 11, "topic", "", false, false], [32, 38, 8, 9, "topic", "", false, false], [32, 38, 11, 11, "topic", "", false, false], [41, 46, 8, 9, "topic", "", false, false], [41, 46, 11, 11, "topic", "", false, false], [48, 52, 8, 9, "topic", "", false, false], [48, 52, 11, 11, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["She", "has", "also", "been", "area", "chair", "of", "several", "machine", "learning", "and", "vision", "conferences", ",", "such", "as", "the", "Conference", "on", "Neural", "Information", "Processing", "Systems", ",", "the", "International", "Conference", "on", "Learning", "Representations", ",", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "the", "International", "Conference", "on", "Computer", "Vision", "and", "the", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "She has also been area chair of several machine learning and vision conferences, such as the Conference on Neural Information Processing Systems, the International Conference on Learning Representations, the Conference on Computer Vision and Pattern Recognition, the International Conference on Computer Vision and the European Conference on Computer Vision.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 17], [18, 22], [23, 28], [29, 31], [32, 39], [40, 47], [48, 56], [57, 60], [61, 67], [68, 79], [79, 80], [81, 85], [86, 88], [89, 92], [93, 103], [104, 106], [107, 113], [114, 125], [126, 136], [137, 144], [144, 145], [146, 149], [150, 163], [164, 174], [175, 177], [178, 186], [187, 202], [202, 203], [204, 207], [208, 218], [219, 221], [222, 230], [231, 237], [238, 241], [242, 249], [250, 261], [261, 262], [263, 266], [267, 280], [281, 291], [292, 294], [295, 303], [304, 310], [311, 314], [315, 318], [319, 327], [328, 338], [339, 341], [342, 350], [351, 357], [357, 358]]}
{"doc_key": "ai-dev-70", "ner": [[1, 2, "algorithm"], [9, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 1, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "condensation", "algorithm", "has", "also", "been", "used", "for", "the", "facial", "recognition", "system", "in", "a", "video", "sequence", "."], "sentence-detokenized": "The condensation algorithm has also been used for the facial recognition system in a video sequence.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 30], [31, 35], [36, 40], [41, 45], [46, 49], [50, 53], [54, 60], [61, 72], [73, 79], [80, 82], [83, 84], [85, 90], [91, 99], [99, 100]]}
{"doc_key": "ai-dev-71", "ner": [[0, 2, "task"], [7, 14, "organisation"], [20, 20, "conference"], [24, 28, "academicjournal"], [32, 32, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[20, 20, 0, 2, "topic", "", false, false], [20, 20, 7, 14, "origin", "", false, false], [24, 28, 0, 2, "topic", "", false, false], [24, 28, 7, 14, "origin", "", true, false], [32, 32, 24, 28, "role", "edited_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Dissemination", "of", "information", "is", "also", "part", "of", "ELRA", "'s", "mission", ",", "which", "is", "carried", "out", "through", "the", "organisation", "of", "the", "LREC", "conference", "and", "the", "Language", "Resources", "and", "Evaluation", "Journal", ",", "published", "by", "Springer", "."], "sentence-detokenized": "Dissemination of information is also part of ELRA's mission, which is carried out through the organisation of the LREC conference and the Language Resources and Evaluation Journal, published by Springer.", "token2charspan": [[0, 13], [14, 16], [17, 28], [29, 31], [32, 36], [37, 41], [42, 44], [45, 49], [49, 51], [52, 59], [59, 60], [61, 66], [67, 69], [70, 77], [78, 81], [82, 89], [90, 93], [94, 106], [107, 109], [110, 113], [114, 118], [119, 129], [130, 133], [134, 137], [138, 146], [147, 156], [157, 160], [161, 171], [172, 179], [179, 180], [181, 190], [191, 193], [194, 202], [202, 203]]}
{"doc_key": "ai-dev-72", "ner": [[1, 8, "field"], [10, 11, "field"], [13, 15, "field"], [17, 18, "field"], [54, 55, "field"], [60, 60, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 8, 54, 55, "named", "", false, false], [13, 15, 1, 8, "named", "", false, false], [60, 60, 10, 11, "part-of", "", true, false], [60, 60, 13, 15, "part-of", "", true, false], [60, 60, 54, 55, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "linear", "time", "invariant", "(", "LTI", ")", "systems", "theory", ",", "control", "theory", "and", "digital", "signal", "processing", "or", "signal", "processing", ",", "the", "relationship", "between", "the", "input", "signal", ",", "math", "\\", "displaystyle", "x", "(", "t", ")", "/", "math", ",", "and", "the", "output", "signal", ",", "math", "\\", "displaystyle", "y", "(", "t", ")", "/", "math", ",", "of", "an", "LTI", "system", "is", "governed", "by", "a", "convolution", "operation", ":"], "sentence-detokenized": "In linear time invariant (LTI) systems theory, control theory and digital signal processing or signal processing, the relationship between the input signal, math\\ displaystyle x (t) / math, and the output signal, math\\ displaystyle y (t) / math, of an LTI system is governed by a convolution operation:", "token2charspan": [[0, 2], [3, 9], [10, 14], [15, 24], [25, 26], [26, 29], [29, 30], [31, 38], [39, 45], [45, 46], [47, 54], [55, 61], [62, 65], [66, 73], [74, 80], [81, 91], [92, 94], [95, 101], [102, 112], [112, 113], [114, 117], [118, 130], [131, 138], [139, 142], [143, 148], [149, 155], [155, 156], [157, 161], [161, 162], [163, 175], [176, 177], [178, 179], [179, 180], [180, 181], [182, 183], [184, 188], [188, 189], [190, 193], [194, 197], [198, 204], [205, 211], [211, 212], [213, 217], [217, 218], [219, 231], [232, 233], [234, 235], [235, 236], [236, 237], [238, 239], [240, 244], [244, 245], [246, 248], [249, 251], [252, 255], [256, 262], [263, 265], [266, 274], [275, 277], [278, 279], [280, 291], [292, 301], [301, 302]]}
{"doc_key": "ai-dev-73", "ner": [[16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 31, "field"], [33, 34, "product"], [36, 37, "field"], [39, 39, "field"], [41, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Because", "of", "its", "generality", ",", "the", "field", "is", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "game", "theory", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimisation", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Because of its generality, the field is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimisation, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 25], [25, 26], [27, 30], [31, 36], [37, 39], [40, 47], [48, 50], [51, 55], [56, 61], [62, 73], [73, 74], [75, 79], [80, 82], [83, 87], [88, 94], [94, 95], [96, 103], [104, 110], [110, 111], [112, 122], [123, 131], [131, 132], [133, 144], [145, 151], [151, 152], [153, 163], [163, 164], [164, 169], [170, 182], [182, 183], [184, 195], [196, 203], [203, 204], [205, 210], [211, 223], [223, 224], [225, 235], [236, 239], [240, 247], [248, 258], [258, 259]]}
{"doc_key": "ai-dev-74", "ner": [[0, 2, "algorithm"], [15, 18, "field"], [19, 20, "algorithm"], [26, 27, "algorithm"], [34, 35, "algorithm"], [38, 38, "algorithm"], [39, 41, "researcher"], [43, 44, "researcher"], [46, 48, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[15, 18, 0, 2, "usage", "", true, false], [19, 20, 15, 18, "part-of", "", true, false], [26, 27, 15, 18, "part-of", "", true, false], [34, 35, 15, 18, "part-of", "", true, false], [38, 38, 15, 18, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Stochastic", "gradient", "descent", "is", "a", "popular", "algorithm", "for", "training", "a", "wide", "range", "of", "models", "in", "machine", "learning", ",", "including", "support", "vector", "(", "linear", ")", "machines", ",", "logistic", "regression", "(", "see", ",", "for", "example", ",", "Vowpal", "Wabbit", ")", "and", "graphical", "models.Jenny", "Rose", "Finkel", ",", "Alex", "Kleeman", ",", "Christopher", "D.", "Manning", "(", "2008", ")", "."], "sentence-detokenized": "Stochastic gradient descent is a popular algorithm for training a wide range of models in machine learning, including support vector (linear) machines, logistic regression (see, for example, Vowpal Wabbit) and graphical models.Jenny Rose Finkel, Alex Kleeman, Christopher D. Manning (2008).", "token2charspan": [[0, 10], [11, 19], [20, 27], [28, 30], [31, 32], [33, 40], [41, 50], [51, 54], [55, 63], [64, 65], [66, 70], [71, 76], [77, 79], [80, 86], [87, 89], [90, 97], [98, 106], [106, 107], [108, 117], [118, 125], [126, 132], [133, 134], [134, 140], [140, 141], [142, 150], [150, 151], [152, 160], [161, 171], [172, 173], [173, 176], [176, 177], [178, 181], [182, 189], [189, 190], [191, 197], [198, 204], [204, 205], [206, 209], [210, 219], [220, 232], [233, 237], [238, 244], [244, 245], [246, 250], [251, 258], [258, 259], [260, 271], [272, 274], [275, 282], [283, 284], [284, 288], [288, 289], [289, 290]]}
{"doc_key": "ai-dev-75", "ner": [[8, 8, "organisation"], [12, 13, "product"], [20, 20, "country"], [22, 25, "university"], [27, 27, "location"], [29, 31, "university"], [33, 33, "location"], [35, 36, "university"], [38, 38, "location"], [40, 42, "university"], [44, 44, "location"], [46, 47, "university"], [49, 49, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 22, 25, "role", "donates_to", false, false], [8, 8, 29, 31, "role", "donates_to", false, false], [8, 8, 35, 36, "role", "donates_to", false, false], [8, 8, 40, 42, "role", "donates_to", false, false], [8, 8, 46, 47, "role", "donates_to", false, false], [12, 13, 8, 8, "origin", "donates", true, false], [22, 25, 27, 27, "physical", "", false, false], [27, 27, 20, 20, "physical", "", false, false], [29, 31, 33, 33, "physical", "", false, false], [33, 33, 20, 20, "physical", "", false, false], [35, 36, 38, 38, "physical", "", false, false], [38, 38, 20, 20, "physical", "", false, false], [40, 42, 44, 44, "physical", "", false, false], [44, 44, 20, 20, "physical", "", false, false], [46, 47, 49, 49, "physical", "", false, false], [49, 49, 20, 20, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "sentence": ["In", "August", "2011", ",", "it", "was", "announced", "that", "Hitachi", "would", "donate", "an", "electron", "microscope", "to", "each", "of", "five", "universities", "in", "Indonesia", "(", "University", "of", "North", "Sumatra", "in", "Medan", ",", "Indonesian", "Christian", "University", "in", "Jakarta", ",", "Padjadjaran", "University", "in", "Bandung", ",", "Jenderal", "Soedirman", "University", "in", "Purwokerto", "and", "Muhammadiyah", "University", "in", "Malang", ")", "."], "sentence-detokenized": "In August 2011, it was announced that Hitachi would donate an electron microscope to each of five universities in Indonesia (University of North Sumatra in Medan, Indonesian Christian University in Jakarta, Padjadjaran University in Bandung, Jenderal Soedirman University in Purwokerto and Muhammadiyah University in Malang).", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 18], [19, 22], [23, 32], [33, 37], [38, 45], [46, 51], [52, 58], [59, 61], [62, 70], [71, 81], [82, 84], [85, 89], [90, 92], [93, 97], [98, 110], [111, 113], [114, 123], [124, 125], [125, 135], [136, 138], [139, 144], [145, 152], [153, 155], [156, 161], [161, 162], [163, 173], [174, 183], [184, 194], [195, 197], [198, 205], [205, 206], [207, 218], [219, 229], [230, 232], [233, 240], [240, 241], [242, 250], [251, 260], [261, 271], [272, 274], [275, 285], [286, 289], [290, 302], [303, 313], [314, 316], [317, 323], [323, 324], [324, 325]]}
{"doc_key": "ai-dev-76", "ner": [[0, 0, "field"], [3, 4, "field"], [8, 9, "algorithm"], [11, 12, "algorithm"], [21, 22, "field"], [27, 28, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 4, "part-of", "", false, false], [0, 0, 21, 22, "related-to", "", true, false], [0, 0, 27, 28, "related-to", "", true, false], [8, 9, 0, 0, "type-of", "", false, false], [11, 12, 0, 0, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Optimisation", "techniques", "from", "operations", "research", ",", "such", "as", "linear", "programming", "or", "dynamic", "programming", ",", "are", "often", "impractical", "for", "large", "-", "scale", "software", "engineering", "problems", "due", "to", "their", "computational", "complexity", "."], "sentence-detokenized": "Optimisation techniques from operations research, such as linear programming or dynamic programming, are often impractical for large-scale software engineering problems due to their computational complexity.", "token2charspan": [[0, 12], [13, 23], [24, 28], [29, 39], [40, 48], [48, 49], [50, 54], [55, 57], [58, 64], [65, 76], [77, 79], [80, 87], [88, 99], [99, 100], [101, 104], [105, 110], [111, 122], [123, 126], [127, 132], [132, 133], [133, 138], [139, 147], [148, 159], [160, 168], [169, 172], [173, 175], [176, 181], [182, 195], [196, 206], [206, 207]]}
{"doc_key": "ai-dev-77", "ner": [[0, 0, "metrics"], [6, 6, "metrics"], [8, 10, "metrics"], [14, 15, "metrics"], [20, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 6, "compare", "", false, false], [0, 0, 8, 10, "compare", "", false, false], [14, 15, 8, 10, "part-of", "", false, false], [20, 23, 8, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sensitivity", "is", "not", "the", "same", "as", "precision", "or", "positive", "predictive", "value", "(", "ratio", "of", "TRUE", "positives", "to", "the", "combination", "of", "TRUE", "and", "FALSE", "positives", ")", ",", "which", "is", "as", "much", "a", "statement", "about", "the", "proportion", "of", "true", "positives", "in", "the", "population", "tested", "as", "it", "is", "about", "the", "test", "."], "sentence-detokenized": "Sensitivity is not the same as precision or positive predictive value (ratio of TRUE positives to the combination of TRUE and FALSE positives), which is as much a statement about the proportion of true positives in the population tested as it is about the test.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 22], [23, 27], [28, 30], [31, 40], [41, 43], [44, 52], [53, 63], [64, 69], [70, 71], [71, 76], [77, 79], [80, 84], [85, 94], [95, 97], [98, 101], [102, 113], [114, 116], [117, 121], [122, 125], [126, 131], [132, 141], [141, 142], [142, 143], [144, 149], [150, 152], [153, 155], [156, 160], [161, 162], [163, 172], [173, 178], [179, 182], [183, 193], [194, 196], [197, 201], [202, 211], [212, 214], [215, 218], [219, 229], [230, 236], [237, 239], [240, 242], [243, 245], [246, 251], [252, 255], [256, 260], [260, 261]]}
{"doc_key": "ai-dev-78", "ner": [[0, 1, "person"], [8, 8, "product"], [11, 11, "person"], [25, 25, "person"], [32, 34, "person"], [43, 45, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6], "relations": [[8, 8, 0, 1, "artifact", "", false, false], [32, 34, 43, 45, "role", "convinces", false, false], [43, 45, 8, 8, "role", "producer", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Hampton", "Fancher", "'s", "screenplay", "--", "Initially", "not", "titled", "Android", "-", "See", "Sammon", ",", "pp.", "32", "and", "38", "for", "explanation", "--", "was", "optioned", "in", "1977", ".", "Sammon", ",", "pp.", "23", "-", "30", "Producer", "Michael", "Deeley", "became", "interested", "in", "Fancher", "'s", "draft", "and", "convinced", "director", "Ridley", "Scott", "to", "film", "it", "."], "sentence-detokenized": "Hampton Fancher's screenplay -- Initially not titled Android - See Sammon, pp. 32 and 38 for explanation -- was optioned in 1977. Sammon, pp. 23-30 Producer Michael Deeley became interested in Fancher's draft and convinced director Ridley Scott to film it.", "token2charspan": [[0, 7], [8, 15], [15, 17], [18, 28], [29, 31], [32, 41], [42, 45], [46, 52], [53, 60], [61, 62], [63, 66], [67, 73], [73, 74], [75, 78], [79, 81], [82, 85], [86, 88], [89, 92], [93, 104], [105, 107], [108, 111], [112, 120], [121, 123], [124, 128], [128, 129], [130, 136], [136, 137], [138, 141], [142, 144], [144, 145], [145, 147], [148, 156], [157, 164], [165, 171], [172, 178], [179, 189], [190, 192], [193, 200], [200, 202], [203, 208], [209, 212], [213, 222], [223, 231], [232, 238], [239, 244], [245, 247], [248, 252], [253, 255], [255, 256]]}
{"doc_key": "ai-dev-79", "ner": [[0, 1, "field"], [3, 4, "task"], [6, 7, "task"], [10, 12, "misc"], [14, 15, "field"], [17, 19, "task"], [21, 22, "task"], [24, 25, "field"], [28, 31, "task"], [33, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 4, 0, 1, "part-of", "", false, false], [6, 7, 0, 1, "part-of", "", false, false], [10, 12, 0, 1, "part-of", "", false, false], [14, 15, 0, 1, "part-of", "", false, false], [17, 19, 0, 1, "part-of", "", false, false], [21, 22, 0, 1, "part-of", "", false, false], [24, 25, 0, 1, "part-of", "", false, false], [28, 31, 0, 1, "part-of", "", false, false], [33, 33, 0, 1, "part-of", "", false, false], [35, 36, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Text", "analysis", "involves", "information", "retrieval", ",", "lexical", "analysis", "to", "study", "word", "frequency", "distributions", ",", "pattern", "recognition", ",", "tagging", "/", "annotation", ",", "information", "extraction", ",", "data", "mining", "techniques", "including", "link", "and", "association", "analysis", ",", "visualisation", "and", "predictive", "analysis", "."], "sentence-detokenized": "Text analysis involves information retrieval, lexical analysis to study word frequency distributions, pattern recognition, tagging/annotation, information extraction, data mining techniques including link and association analysis, visualisation and predictive analysis.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 34], [35, 44], [44, 45], [46, 53], [54, 62], [63, 65], [66, 71], [72, 76], [77, 86], [87, 100], [100, 101], [102, 109], [110, 121], [121, 122], [123, 130], [130, 131], [131, 141], [141, 142], [143, 154], [155, 165], [165, 166], [167, 171], [172, 178], [179, 189], [190, 199], [200, 204], [205, 208], [209, 220], [221, 229], [229, 230], [231, 244], [245, 248], [249, 259], [260, 268], [268, 269]]}
{"doc_key": "ai-dev-80", "ner": [[3, 3, "product"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Several", "metrics", "use", "WordNet", ",", "a", "manually", "constructed", "lexical", "database", "of", "English", "words", "."], "sentence-detokenized": "Several metrics use WordNet, a manually constructed lexical database of English words.", "token2charspan": [[0, 7], [8, 15], [16, 19], [20, 27], [27, 28], [29, 30], [31, 39], [40, 51], [52, 59], [60, 68], [69, 71], [72, 79], [80, 85], [85, 86]]}
{"doc_key": "ai-dev-81", "ner": [[6, 7, "field"], [9, 10, "task"], [12, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "system", "uses", "a", "combination", "of", "computational", "linguistics", ",", "information", "retrieval", "and", "knowledge", "representation", "techniques", "to", "find", "answers", "."], "sentence-detokenized": "The system uses a combination of computational linguistics, information retrieval and knowledge representation techniques to find answers.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 17], [18, 29], [30, 32], [33, 46], [47, 58], [58, 59], [60, 71], [72, 81], [82, 85], [86, 95], [96, 110], [111, 121], [122, 124], [125, 129], [130, 137], [137, 138]]}
{"doc_key": "ai-dev-82", "ner": [[6, 9, "metrics"], [13, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 9, 13, 13, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "performance", "metric", ",", "the", "uncertainty", "coefficient", "has", "the", "advantage", "over", "simple", "precision", "that", "it", "is", "not", "affected", "by", "the", "relative", "sizes", "of", "the", "different", "classes", "."], "sentence-detokenized": "As a performance metric, the uncertainty coefficient has the advantage over simple precision that it is not affected by the relative sizes of the different classes.", "token2charspan": [[0, 2], [3, 4], [5, 16], [17, 23], [23, 24], [25, 28], [29, 40], [41, 52], [53, 56], [57, 60], [61, 70], [71, 75], [76, 82], [83, 92], [93, 97], [98, 100], [101, 103], [104, 107], [108, 116], [117, 119], [120, 123], [124, 132], [133, 138], [139, 141], [142, 145], [146, 155], [156, 163], [163, 164]]}
{"doc_key": "ai-dev-83", "ner": [[8, 9, "algorithm"], [11, 12, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Researchers", "have", "tried", "various", "methods", ",", "such", "as", "optical", "flow", ",", "Kalman", "filtering", ",", "Hidden", "Markov", "models", ",", "etc", "."], "sentence-detokenized": "Researchers have tried various methods, such as optical flow, Kalman filtering, Hidden Markov models, etc.", "token2charspan": [[0, 11], [12, 16], [17, 22], [23, 30], [31, 38], [38, 39], [40, 44], [45, 47], [48, 55], [56, 60], [60, 61], [62, 68], [69, 78], [78, 79], [80, 86], [87, 93], [94, 100], [100, 101], [102, 105], [105, 106]]}
{"doc_key": "ai-dev-84", "ner": [[13, 16, "conference"], [27, 29, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "has", "served", "as", "president", ",", "vice-president", "and", "secretary", "-", "treasurer", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "has", "been", "a", "board", "member", "and", "secretary", "of", "the", "Computing", "Research", "Association", "."], "sentence-detokenized": "She has served as president, vice-president and secretary-treasurer of the Association for Computational Linguistics and has been a board member and secretary of the Computing Research Association.", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 17], [18, 27], [27, 28], [29, 43], [44, 47], [48, 57], [57, 58], [58, 67], [68, 70], [71, 74], [75, 86], [87, 90], [91, 104], [105, 116], [117, 120], [121, 124], [125, 129], [130, 131], [132, 137], [138, 144], [145, 148], [149, 158], [159, 161], [162, 165], [166, 175], [176, 184], [185, 196], [196, 197]]}
{"doc_key": "ai-dev-85", "ner": [[6, 6, "programlang"], [8, 8, "product"], [10, 10, "programlang"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 10, 10, "compare", "", false, false], [6, 6, 12, 13, "related-to", "supports", false, false], [8, 8, 10, 10, "compare", "", false, false], [8, 8, 12, 13, "related-to", "supports", false, false], [10, 10, 12, 13, "related-to", "supports", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Like", "other", "similar", "languages", "such", "as", "APL", "and", "MATLAB", ",", "R", "supports", "matrix", "arithmetic", "."], "sentence-detokenized": "Like other similar languages such as APL and MATLAB, R supports matrix arithmetic.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 28], [29, 33], [34, 36], [37, 40], [41, 44], [45, 51], [51, 52], [53, 54], [55, 63], [64, 70], [71, 81], [81, 82]]}
{"doc_key": "ai-dev-86", "ner": [[7, 8, "misc"], [12, 13, "organisation"], [17, 18, "researcher"], [21, 23, "university"], [27, 32, "misc"], [34, 34, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 8, 12, 13, "physical", "", false, false], [7, 8, 27, 32, "temporal", "", false, false], [17, 18, 7, 8, "role", "arranges", false, false], [17, 18, 21, 23, "role", "works_for", false, false], [34, 34, 7, 8, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["On", "7", "June", "2014", ",", "at", "a", "Turing", "test", "competition", "at", "the", "Royal", "Society", ",", "organised", "by", "Kevin", "Warwick", "of", "the", "University", "of", "Reading", "to", "mark", "the", "60th", "anniversary", "of", "Turing", "'s", "death", ",", "Goostman", "won", "after", "33", "%", "of", "the", "judges", "were", "convinced", "that", "the", "bot", "was", "human", "."], "sentence-detokenized": "On 7 June 2014, at a Turing test competition at the Royal Society, organised by Kevin Warwick of the University of Reading to mark the 60th anniversary of Turing's death, Goostman won after 33% of the judges were convinced that the bot was human.", "token2charspan": [[0, 2], [3, 4], [5, 9], [10, 14], [14, 15], [16, 18], [19, 20], [21, 27], [28, 32], [33, 44], [45, 47], [48, 51], [52, 57], [58, 65], [65, 66], [67, 76], [77, 79], [80, 85], [86, 93], [94, 96], [97, 100], [101, 111], [112, 114], [115, 122], [123, 125], [126, 130], [131, 134], [135, 139], [140, 151], [152, 154], [155, 161], [161, 163], [164, 169], [169, 170], [171, 179], [180, 183], [184, 189], [190, 192], [192, 193], [194, 196], [197, 200], [201, 207], [208, 212], [213, 222], [223, 227], [228, 231], [232, 235], [236, 239], [240, 245], [245, 246]]}
{"doc_key": "ai-dev-87", "ner": [[1, 2, "product"], [4, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 1, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "collaborative", "robot", "or", "cobot", "is", "a", "robot", "that", "can", "safely", "and", "effectively", "interact", "with", "human", "workers", "while", "performing", "simple", "industrial", "tasks", "."], "sentence-detokenized": "A collaborative robot or cobot is a robot that can safely and effectively interact with human workers while performing simple industrial tasks.", "token2charspan": [[0, 1], [2, 15], [16, 21], [22, 24], [25, 30], [31, 33], [34, 35], [36, 41], [42, 46], [47, 50], [51, 57], [58, 61], [62, 73], [74, 82], [83, 87], [88, 93], [94, 101], [102, 107], [108, 118], [119, 125], [126, 136], [137, 142], [142, 143]]}
{"doc_key": "ai-dev-88", "ner": [[11, 12, "field"], [17, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "task"], [29, 30, "task"], [32, 34, "task"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[17, 18, 11, 12, "part-of", "task_part_of_field", false, false], [20, 21, 11, 12, "part-of", "task_part_of_field", false, false], [23, 24, 11, 12, "part-of", "task_part_of_field", false, false], [26, 27, 11, 12, "part-of", "task_part_of_field", false, false], [29, 30, 11, 12, "part-of", "task_part_of_field", false, false], [32, 34, 11, 12, "part-of", "task_part_of_field", false, false], [36, 37, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["This", "general", "framework", "has", "been", "applied", "to", "a", "wide", "variety", "of", "computer", "vision", "problems", ",", "such", "as", "feature", "detection", ",", "feature", "classification", ",", "image", "segmentation", ",", "image", "matching", ",", "motion", "estimation", ",", "shape", "key", "computation", "and", "object", "recognition", "."], "sentence-detokenized": "This general framework has been applied to a wide variety of computer vision problems, such as feature detection, feature classification, image segmentation, image matching, motion estimation, shape key computation and object recognition.", "token2charspan": [[0, 4], [5, 12], [13, 22], [23, 26], [27, 31], [32, 39], [40, 42], [43, 44], [45, 49], [50, 57], [58, 60], [61, 69], [70, 76], [77, 85], [85, 86], [87, 91], [92, 94], [95, 102], [103, 112], [112, 113], [114, 121], [122, 136], [136, 137], [138, 143], [144, 156], [156, 157], [158, 163], [164, 172], [172, 173], [174, 180], [181, 191], [191, 192], [193, 198], [199, 202], [203, 214], [215, 218], [219, 225], [226, 237], [237, 238]]}
{"doc_key": "ai-dev-89", "ner": [[6, 7, "task"], [9, 11, "algorithm"], [14, 15, "algorithm"], [26, 27, "algorithm"], [31, 32, "algorithm"], [36, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 7, 9, 11, "part-of", "", false, false], [6, 7, 14, 15, "usage", "", false, false], [9, 11, 26, 27, "named", "same", false, false], [26, 27, 31, 32, "related-to", "", false, false], [26, 27, 36, 37, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "many", "practical", "applications", ",", "the", "parameter", "estimation", "of", "naive", "Bayes", "models", "uses", "the", "maximum", "likelihood", "method", ",", "i.e.", "it", "is", "possible", "to", "work", "with", "the", "naive", "Bayes", "model", "without", "accepting", "Bayesian", "probability", "or", "using", "any", "Bayesian", "method", "."], "sentence-detokenized": "In many practical applications, the parameter estimation of naive Bayes models uses the maximum likelihood method, i.e. it is possible to work with the naive Bayes model without accepting Bayesian probability or using any Bayesian method.", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 30], [30, 31], [32, 35], [36, 45], [46, 56], [57, 59], [60, 65], [66, 71], [72, 78], [79, 83], [84, 87], [88, 95], [96, 106], [107, 113], [113, 114], [115, 119], [120, 122], [123, 125], [126, 134], [135, 137], [138, 142], [143, 147], [148, 151], [152, 157], [158, 163], [164, 169], [170, 177], [178, 187], [188, 196], [197, 208], [209, 211], [212, 217], [218, 221], [222, 230], [231, 237], [237, 238]]}
{"doc_key": "ai-dev-90", "ner": [[2, 4, "researcher"], [6, 7, "misc"], [12, 15, "university"], [17, 19, "researcher"], [21, 22, "misc"], [26, 26, "university"], [28, 28, "university"], [31, 31, "misc"], [38, 40, "university"], [46, 49, "misc"], [51, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[2, 4, 12, 15, "physical", "", false, false], [2, 4, 12, 15, "role", "", false, false], [2, 4, 17, 19, "social", "brothers", false, false], [6, 7, 2, 4, "named", "", false, false], [17, 19, 26, 26, "physical", "", false, false], [17, 19, 26, 26, "role", "", false, false], [17, 19, 28, 28, "physical", "", false, false], [17, 19, 28, 28, "role", "", false, false], [17, 19, 38, 40, "physical", "", false, false], [17, 19, 38, 40, "role", "", false, false], [21, 22, 17, 19, "named", "", false, false], [31, 31, 17, 19, "origin", "", false, false], [46, 49, 17, 19, "artifact", "", false, false], [46, 49, 51, 54, "part-of", "part", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Brothers", "-", "Victor", "Gershevich", "Katz", ",", "American", "mathematician", ",", "professor", "at", "the", "Massachusetts", "Institute", "of", "Technology", ";", "Mikhail", "Gershevich", "Katz", ",", "Israeli", "mathematician", ",", "graduate", "of", "Harvard", "and", "Columbia", "Universities", "(", "PhD", ",", "1984", ")", ",", "professor", "at", "Bar-", "Ilan", "University", ",", "author", "of", "the", "monograph", "Systolic", "Geometry", "and", "Topology", "(", "Mathematical", "Surveys", "and", "Monographs", ",", "vol", ".", "I", ")", "."], "sentence-detokenized": "Brothers - Victor Gershevich Katz, American mathematician, professor at the Massachusetts Institute of Technology; Mikhail Gershevich Katz, Israeli mathematician, graduate of Harvard and Columbia Universities (PhD, 1984), professor at Bar-Ilan University, author of the monograph Systolic Geometry and Topology (Mathematical Surveys and Monographs, vol. I).", "token2charspan": [[0, 8], [9, 10], [11, 17], [18, 28], [29, 33], [33, 34], [35, 43], [44, 57], [57, 58], [59, 68], [69, 71], [72, 75], [76, 89], [90, 99], [100, 102], [103, 113], [113, 114], [115, 122], [123, 133], [134, 138], [138, 139], [140, 147], [148, 161], [161, 162], [163, 171], [172, 174], [175, 182], [183, 186], [187, 195], [196, 208], [209, 210], [210, 213], [213, 214], [215, 219], [219, 220], [220, 221], [222, 231], [232, 234], [235, 239], [239, 243], [244, 254], [254, 255], [256, 262], [263, 265], [266, 269], [270, 279], [280, 288], [289, 297], [298, 301], [302, 310], [311, 312], [312, 324], [325, 332], [333, 336], [337, 347], [347, 348], [349, 352], [352, 353], [354, 355], [355, 356], [356, 357]]}
{"doc_key": "ai-dev-91", "ner": [[3, 4, "person"], [9, 10, "conference"], [16, 19, "organisation"], [21, 28, "location"], [32, 32, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 9, 10, "physical", "", false, false], [3, 4, 9, 10, "role", "", false, false], [3, 4, 16, 19, "role", "", false, false], [16, 19, 21, 28, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2000", ",", "Manuel", "Toharia", ",", "speaker", "at", "previous", "Campus", "Parties", ",", "and", "director", "of", "the", "Pr\u00edncipe", "Felipe", "Science", "Museum", "of", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", ",", "suggested", "to", "Ragagageles", "that", "the", "event", "should", "be", "expanded", "and", "made", "more", "international", "by", "moving", "it", "to", "the", "famous", "museum", "."], "sentence-detokenized": "In 2000, Manuel Toharia, speaker at previous Campus Parties, and director of the Pr\u00edncipe Felipe Science Museum of the City of Arts and Sciences in Valencia, suggested to Ragagageles that the event should be expanded and made more international by moving it to the famous museum.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 23], [23, 24], [25, 32], [33, 35], [36, 44], [45, 51], [52, 59], [59, 60], [61, 64], [65, 73], [74, 76], [77, 80], [81, 89], [90, 96], [97, 104], [105, 111], [112, 114], [115, 118], [119, 123], [124, 126], [127, 131], [132, 135], [136, 144], [145, 147], [148, 156], [156, 157], [158, 167], [168, 170], [171, 182], [183, 187], [188, 191], [192, 197], [198, 204], [205, 207], [208, 216], [217, 220], [221, 225], [226, 230], [231, 244], [245, 247], [248, 254], [255, 257], [258, 260], [261, 264], [265, 271], [272, 278], [278, 279]]}
{"doc_key": "ai-dev-92", "ner": [[5, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Within", "20", "minutes", ",", "a", "facial", "recognition", "system", "identifies", "personal", "data", ",", "such", "as", "surname", ",", "ID", "number", "and", "address", ",", "which", "are", "displayed", "in", "the", "street", "on", "a", "billboard", "."], "sentence-detokenized": "Within 20 minutes, a facial recognition system identifies personal data, such as surname, ID number and address, which are displayed in the street on a billboard.", "token2charspan": [[0, 6], [7, 9], [10, 17], [17, 18], [19, 20], [21, 27], [28, 39], [40, 46], [47, 57], [58, 66], [67, 71], [71, 72], [73, 77], [78, 80], [81, 88], [88, 89], [90, 92], [93, 99], [100, 103], [104, 111], [111, 112], [113, 118], [119, 122], [123, 132], [133, 135], [136, 139], [140, 146], [147, 149], [150, 151], [152, 161], [161, 162]]}
{"doc_key": "ai-dev-93", "ner": [[6, 6, "field"], [8, 8, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Recent", "research", "has", "increasingly", "focused", "on", "unsupervised", "and", "semi-supervised", "learning", "algorithms", "."], "sentence-detokenized": "Recent research has increasingly focused on unsupervised and semi-supervised learning algorithms.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 32], [33, 40], [41, 43], [44, 56], [57, 60], [61, 76], [77, 85], [86, 96], [96, 97]]}
{"doc_key": "ai-dev-94", "ner": [[5, 5, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Calculation", "of", "this", "example", "using", "Python", "code", ":"], "sentence-detokenized": "Calculation of this example using Python code:", "token2charspan": [[0, 11], [12, 14], [15, 19], [20, 27], [28, 33], [34, 40], [41, 45], [45, 46]]}
{"doc_key": "ai-dev-95", "ner": [[7, 8, "task"], [15, 16, "field"], [22, 22, "algorithm"], [24, 24, "algorithm"], [28, 30, "algorithm"], [33, 34, "researcher"], [36, 37, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[22, 22, 15, 16, "part-of", "", false, false], [22, 22, 28, 30, "type-of", "", false, false], [22, 22, 33, 34, "origin", "", false, false], [22, 22, 36, 37, "origin", "", false, false], [24, 24, 22, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Today", ",", "however", ",", "many", "aspects", "of", "speech", "recognition", "have", "been", "taken", "over", "by", "a", "deep", "learning", "method", "called", "short", "-", "term", "memory", "(", "LSTM", ")", ",", "a", "recurrent", "neural", "network", "published", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "in", "1997", "."], "sentence-detokenized": "Today, however, many aspects of speech recognition have been taken over by a deep learning method called short-term memory (LSTM), a recurrent neural network published by Sepp Hochreiter and J\u00fcrgen Schmidhuber in 1997.", "token2charspan": [[0, 5], [5, 6], [7, 14], [14, 15], [16, 20], [21, 28], [29, 31], [32, 38], [39, 50], [51, 55], [56, 60], [61, 66], [67, 71], [72, 74], [75, 76], [77, 81], [82, 90], [91, 97], [98, 104], [105, 110], [110, 111], [111, 115], [116, 122], [123, 124], [124, 128], [128, 129], [129, 130], [131, 132], [133, 142], [143, 149], [150, 157], [158, 167], [168, 170], [171, 175], [176, 186], [187, 190], [191, 197], [198, 209], [210, 212], [213, 217], [217, 218]]}
{"doc_key": "ai-dev-96", "ner": [[9, 9, "algorithm"], [15, 15, "algorithm"], [19, 19, "algorithm"], [24, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 15, 15, "compare", "", false, false], [9, 9, 24, 24, "named", "same", false, false], [19, 19, 24, 24, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "preliminary", "experimental", "results", "with", "noisy", "data", "sets", ",", "BrownBoost", "outperformed", "the", "generalisation", "error", "of", "AdaBoost", ";", "however", ",", "LogitBoost", "performed", "as", "well", "as", "BrownBoost", "."], "sentence-detokenized": "In preliminary experimental results with noisy data sets, BrownBoost outperformed the generalisation error of AdaBoost; however, LogitBoost performed as well as BrownBoost.", "token2charspan": [[0, 2], [3, 14], [15, 27], [28, 35], [36, 40], [41, 46], [47, 51], [52, 56], [56, 57], [58, 68], [69, 81], [82, 85], [86, 100], [101, 106], [107, 109], [110, 118], [118, 119], [120, 127], [127, 128], [129, 139], [140, 149], [150, 152], [153, 157], [158, 160], [161, 171], [171, 172]]}
{"doc_key": "ai-dev-97", "ner": [[0, 1, "algorithm"], [5, 7, "researcher"], [10, 11, "country"], [14, 16, "researcher"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 7, "part-of", "", false, false], [5, 7, 10, 11, "physical", "", false, false], [20, 21, 14, 16, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Evolutionary", "programming", "was", "introduced", "by", "Lawrence", "J.", "Fogel", "in", "the", "United", "States", ",", "while", "John", "Henry", "Holland", "called", "his", "method", "genetic", "algorithm", "."], "sentence-detokenized": "Evolutionary programming was introduced by Lawrence J. Fogel in the United States, while John Henry Holland called his method genetic algorithm.", "token2charspan": [[0, 12], [13, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 54], [55, 60], [61, 63], [64, 67], [68, 74], [75, 81], [81, 82], [83, 88], [89, 93], [94, 99], [100, 107], [108, 114], [115, 118], [119, 125], [126, 133], [134, 143], [143, 144]]}
{"doc_key": "ai-dev-98", "ner": [[2, 2, "researcher"], [4, 4, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 10, 11, "role", "", false, false], [2, 2, 13, 14, "role", "", false, false], [2, 2, 16, 17, "role", "", false, false], [2, 2, 19, 20, "role", "", false, false], [4, 4, 10, 11, "role", "", false, false], [4, 4, 13, 14, "role", "", false, false], [4, 4, 16, 17, "role", "", false, false], [4, 4, 19, 20, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Estimates", "by", "Doug", ",", "Alan", "and", "their", "colleagues", "(", "including", "Marvin", "Minsky", ",", "Allen", "Newell", ",", "Edward", "Feigenbaum", "and", "John", "McCarthy", ")", "indicated", "that", "such", "an", "effort", "would", "require", "between", "1000", "and", "3000", "person", "-", "years", "of", "effort", ",", "well", "beyond", "the", "standard", "academic", "project", "model", "."], "sentence-detokenized": "Estimates by Doug, Alan and their colleagues (including Marvin Minsky, Allen Newell, Edward Feigenbaum and John McCarthy) indicated that such an effort would require between 1000 and 3000 person-years of effort, well beyond the standard academic project model.", "token2charspan": [[0, 9], [10, 12], [13, 17], [17, 18], [19, 23], [24, 27], [28, 33], [34, 44], [45, 46], [46, 55], [56, 62], [63, 69], [69, 70], [71, 76], [77, 83], [83, 84], [85, 91], [92, 102], [103, 106], [107, 111], [112, 120], [120, 121], [122, 131], [132, 136], [137, 141], [142, 144], [145, 151], [152, 157], [158, 165], [166, 173], [174, 178], [179, 182], [183, 187], [188, 194], [194, 195], [195, 200], [201, 203], [204, 210], [210, 211], [212, 216], [217, 223], [224, 227], [228, 236], [237, 245], [246, 253], [254, 259], [259, 260]]}
{"doc_key": "ai-dev-99", "ner": [[6, 10, "metrics"], [12, 12, "metrics"], [15, 17, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 10, 12, 12, "part-of", "implemented_in", false, false], [15, 17, 20, 20, "part-of", "implemented_in", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "common", "criteria", "are", "the", "mean", "square", "error", "criterion", "implemented", "in", "MSECriterion", "and", "the", "cross", "-entropy", "criterion", "implemented", "in", "NLLCriterion", "."], "sentence-detokenized": "The most common criteria are the mean square error criterion implemented in MSECriterion and the cross-entropy criterion implemented in NLLCriterion.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 24], [25, 28], [29, 32], [33, 37], [38, 44], [45, 50], [51, 60], [61, 72], [73, 75], [76, 88], [89, 92], [93, 96], [97, 102], [102, 110], [111, 120], [121, 132], [133, 135], [136, 148], [148, 149]]}
{"doc_key": "ai-dev-100", "ner": [[0, 0, "researcher"], [11, 11, "organisation"], [15, 21, "misc"], [24, 27, "conference"], [37, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 11, 11, "role", "", false, false], [0, 0, 24, 27, "role", "", false, false], [0, 0, 37, 37, "role", "", false, false], [15, 21, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Zurada", "has", "served", "the", "engineering", "profession", "as", "a", "long", "-", "time", "IEEE", "volunteer", ":", "as", "IEEE", "Technical", "Activities", "Vice", "President", "in", "2014", ",", "as", "IEEE", "Computational", "Intelligence", "Society", "President", "in", "2004", "-", "05", ",", "and", "as", "an", "ADCOM", "member", "in", "2009", "-", "14", ",", "2016", "-", "18", ",", "and", "prior", "years", "."], "sentence-detokenized": "Zurada has served the engineering profession as a long-time IEEE volunteer: as IEEE Technical Activities Vice President in 2014, as IEEE Computational Intelligence Society President in 2004-05, and as an ADCOM member in 2009-14, 2016-18, and prior years.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 21], [22, 33], [34, 44], [45, 47], [48, 49], [50, 54], [54, 55], [55, 59], [60, 64], [65, 74], [74, 75], [76, 78], [79, 83], [84, 93], [94, 104], [105, 109], [110, 119], [120, 122], [123, 127], [127, 128], [129, 131], [132, 136], [137, 150], [151, 163], [164, 171], [172, 181], [182, 184], [185, 189], [189, 190], [190, 192], [192, 193], [194, 197], [198, 200], [201, 203], [204, 209], [210, 216], [217, 219], [220, 224], [224, 225], [225, 227], [227, 228], [229, 233], [233, 234], [234, 236], [236, 237], [238, 241], [242, 247], [248, 253], [253, 254]]}
{"doc_key": "ai-dev-101", "ner": [[3, 4, "field"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 3, 4, "part-of", "", false, false], [11, 12, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "general", ",", "computational", "linguistics", "involves", "linguists", ",", "computer", "scientists", ",", "artificial", "intelligence", "experts", ",", "mathematicians", ",", "logicians", ",", "philosophers", ",", "cognitive", "scientists", ",", "cognitive", "psychologists", ",", "psycholinguists", ",", "anthropologists", "and", "neuroscientists", ",", "among", "others", "."], "sentence-detokenized": "In general, computational linguistics involves linguists, computer scientists, artificial intelligence experts, mathematicians, logicians, philosophers, cognitive scientists, cognitive psychologists, psycholinguists, anthropologists and neuroscientists, among others.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 25], [26, 37], [38, 46], [47, 56], [56, 57], [58, 66], [67, 77], [77, 78], [79, 89], [90, 102], [103, 110], [110, 111], [112, 126], [126, 127], [128, 137], [137, 138], [139, 151], [151, 152], [153, 162], [163, 173], [173, 174], [175, 184], [185, 198], [198, 199], [200, 215], [215, 216], [217, 232], [233, 236], [237, 252], [252, 253], [254, 259], [260, 266], [266, 267]]}
{"doc_key": "ai-dev-102", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [14, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "correlations", "between", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and short-term memory are often used to exploit correlations between frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 83], [83, 84], [84, 88], [89, 95], [96, 99], [100, 105], [106, 110], [111, 113], [114, 121], [122, 134], [135, 142], [143, 149], [149, 150]]}
{"doc_key": "ai-dev-103", "ner": [[0, 0, "product"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Unimate", "was", "the", "first", "industrial", "robot", ","], "sentence-detokenized": "Unimate was the first industrial robot,", "token2charspan": [[0, 7], [8, 11], [12, 15], [16, 21], [22, 32], [33, 38], [38, 39]]}
{"doc_key": "ai-dev-104", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [11, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 11, 13, "win-defeat", "", false, false], [5, 6, 11, 13, "win-defeat", "", false, false], [8, 8, 11, 13, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Together", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "won", "the", "2018", "Turing", "Award", "."], "sentence-detokenized": "Together with Geoffrey Hinton and Yann LeCun, Bengio won the 2018 Turing Award.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 29], [30, 33], [34, 38], [39, 44], [44, 45], [46, 52], [53, 56], [57, 60], [61, 65], [66, 72], [73, 78], [78, 79]]}
{"doc_key": "ai-dev-105", "ner": [[5, 6, "country"], [17, 20, "misc"], [26, 26, "organisation"], [29, 32, "person"], [34, 35, "person"], [42, 44, "misc"], [50, 50, "country"], [57, 57, "country"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[17, 20, 5, 6, "physical", "filmed_in", false, false], [29, 32, 26, 26, "role", "host", false, false], [34, 35, 26, 26, "role", "reporter", false, false], [42, 44, 5, 6, "physical", "filmed_in", false, false], [42, 44, 50, 50, "physical", "distributed_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "series", "were", "shot", "in", "the", "UK", "for", "specific", "sectors", "of", "the", "global", "market", ",", "including", "two", "Robot", "Wars", "Extreme", "Warriors", "series", "with", "US", "competitors", "for", "TNN", "(", "with", "Mick", "Foley", "as", "host", "and", "Rebecca", "Grant", "as", "pit", "reporter", ")", ",", "two", "Dutch", "Robot", "Wars", "series", "for", "distribution", "in", "the", "Netherlands", ",", "and", "a", "single", "series", "for", "Germany", "."], "sentence-detokenized": "Other series were shot in the UK for specific sectors of the global market, including two Robot Wars Extreme Warriors series with US competitors for TNN (with Mick Foley as host and Rebecca Grant as pit reporter), two Dutch Robot Wars series for distribution in the Netherlands, and a single series for Germany.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 45], [46, 53], [54, 56], [57, 60], [61, 67], [68, 74], [74, 75], [76, 85], [86, 89], [90, 95], [96, 100], [101, 108], [109, 117], [118, 124], [125, 129], [130, 132], [133, 144], [145, 148], [149, 152], [153, 154], [154, 158], [159, 163], [164, 169], [170, 172], [173, 177], [178, 181], [182, 189], [190, 195], [196, 198], [199, 202], [203, 211], [211, 212], [212, 213], [214, 217], [218, 223], [224, 229], [230, 234], [235, 241], [242, 245], [246, 258], [259, 261], [262, 265], [266, 277], [277, 278], [279, 282], [283, 284], [285, 291], [292, 298], [299, 302], [303, 310], [310, 311]]}
{"doc_key": "ai-dev-106", "ner": [[8, 8, "researcher"], [13, 13, "product"], [30, 31, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 13, 13, "role", "", false, false], [30, 31, 13, 13, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "many", "years", ",", "starting", "in", "1986", ",", "Miller", "led", "the", "development", "of", "WordNet", ",", "a", "large", "computer", "-", "readable", "electronic", "reference", "that", "can", "be", "used", "in", "applications", "such", "as", "search", "engines", "."], "sentence-detokenized": "For many years, starting in 1986, Miller led the development of WordNet, a large computer-readable electronic reference that can be used in applications such as search engines.", "token2charspan": [[0, 3], [4, 8], [9, 14], [14, 15], [16, 24], [25, 27], [28, 32], [32, 33], [34, 40], [41, 44], [45, 48], [49, 60], [61, 63], [64, 71], [71, 72], [73, 74], [75, 80], [81, 89], [89, 90], [90, 98], [99, 109], [110, 119], [120, 124], [125, 128], [129, 131], [132, 136], [137, 139], [140, 152], [153, 157], [158, 160], [161, 167], [168, 175], [175, 176]]}
{"doc_key": "ai-dev-107", "ner": [[3, 5, "algorithm"], [7, 12, "algorithm"], [15, 16, "researcher"], [22, 25, "organisation"], [29, 31, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 15, 16, "origin", "", false, false], [3, 5, 29, 31, "win-defeat", "", false, false], [7, 12, 15, 16, "origin", "", false, false], [7, 12, 29, 31, "win-defeat", "", false, false], [15, 16, 22, 25, "physical", "", false, false], [15, 16, 22, 25, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Since", "2009", ",", "recurrent", "neural", "networks", "and", "feed", "-", "forward", "deep", "neural", "networks", "developed", "in", "J\u00fcrgen", "Schmidhuber", "'s", "research", "group", "at", "the", "Swiss", "AI", "lab", "IDSIA", "have", "won", "several", "international", "writing", "competitions", "...."], "sentence-detokenized": "Since 2009, recurrent neural networks and feed-forward deep neural networks developed in J\u00fcrgen Schmidhuber's research group at the Swiss AI lab IDSIA have won several international writing competitions....", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 21], [22, 28], [29, 37], [38, 41], [42, 46], [46, 47], [47, 54], [55, 59], [60, 66], [67, 75], [76, 85], [86, 88], [89, 95], [96, 107], [107, 109], [110, 118], [119, 124], [125, 127], [128, 131], [132, 137], [138, 140], [141, 144], [145, 150], [151, 155], [156, 159], [160, 167], [168, 181], [182, 189], [190, 202], [202, 206]]}
{"doc_key": "ai-dev-108", "ner": [[5, 6, "programlang"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "software", "is", "implemented", "in", "C", "++", "and", "wrapped", "for", "Python", "."], "sentence-detokenized": "The software is implemented in C++ and wrapped for Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 30], [31, 32], [32, 34], [35, 38], [39, 46], [47, 50], [51, 57], [57, 58]]}
{"doc_key": "ai-dev-109", "ner": [[8, 9, "country"], [14, 15, "misc"], [20, 21, "misc"], [33, 34, "misc"], [36, 36, "misc"], [38, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 21, 8, 9, "temporal", "", false, false], [20, 21, 14, 15, "artifact", "", false, false], [20, 21, 38, 38, "physical", "", false, false], [36, 36, 33, 34, "named", "", false, false], [36, 36, 38, 38, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1857", ",", "at", "the", "request", "of", "the", "Tokugawa", "shogunate", ",", "a", "group", "of", "Dutch", "engineers", "began", "work", "on", "the", "Nagasaki", "Yotetsusho", ",", "a", "modern", "Western", "-", "style", "foundry", "and", "shipyard", "near", "the", "Dutch", "settlement", "of", "Dejima", "in", "Nagasaki", "."], "sentence-detokenized": "In 1857, at the request of the Tokugawa shogunate, a group of Dutch engineers began work on the Nagasaki Yotetsusho, a modern Western-style foundry and shipyard near the Dutch settlement of Dejima in Nagasaki.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 39], [40, 49], [49, 50], [51, 52], [53, 58], [59, 61], [62, 67], [68, 77], [78, 83], [84, 88], [89, 91], [92, 95], [96, 104], [105, 115], [115, 116], [117, 118], [119, 125], [126, 133], [133, 134], [134, 139], [140, 147], [148, 151], [152, 160], [161, 165], [166, 169], [170, 175], [176, 186], [187, 189], [190, 196], [197, 199], [200, 208], [208, 209]]}
{"doc_key": "ai-dev-110", "ner": [[10, 14, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["We", "make", "it", "as", "accurate", "as", "possible", "by", "measuring", "the", "mean", "squared", "error", "between", "mathy", "/", "math", "and", "math", "\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", "/", "math", ":", "we", "want", "math", "(", "y", "-\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", ")", "^", "2", "/", "math", "to", "be", "minimum", ",", "both", "for", "mathx", "_", "1,1", "points", ",", "x", "_n", "/", "math", "and", "for", "points", "outside", "our", "sample", "."], "sentence-detokenized": "We make it as accurate as possible by measuring the mean squared error between mathy / math and math\\ hat {f} (x; D) / math: we want math (y -\\ hat {f} (x; D)) ^ 2 / math to be minimum, both for mathx _ 1,1 points, x _n / math and for points outside our sample.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 13], [14, 22], [23, 25], [26, 34], [35, 37], [38, 47], [48, 51], [52, 56], [57, 64], [65, 70], [71, 78], [79, 84], [85, 86], [87, 91], [92, 95], [96, 100], [100, 101], [102, 105], [106, 107], [107, 108], [108, 109], [110, 111], [111, 112], [112, 113], [114, 115], [115, 116], [117, 118], [119, 123], [123, 124], [125, 127], [128, 132], [133, 137], [138, 139], [139, 140], [141, 143], [144, 147], [148, 149], [149, 150], [150, 151], [152, 153], [153, 154], [154, 155], [156, 157], [157, 158], [158, 159], [160, 161], [162, 163], [164, 165], [166, 170], [171, 173], [174, 176], [177, 184], [184, 185], [186, 190], [191, 194], [195, 200], [201, 202], [203, 206], [207, 213], [213, 214], [215, 216], [217, 219], [220, 221], [222, 226], [227, 230], [231, 234], [235, 241], [242, 249], [250, 253], [254, 260], [260, 261]]}
{"doc_key": "ai-dev-111", "ner": [[6, 7, "researcher"], [14, 16, "organisation"], [22, 26, "product"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 7, 14, 16, "role", "", false, false], [22, 26, 14, 16, "temporal", "", false, false], [22, 26, 36, 37, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "subsequently", "extended", "an", "invitation", "for", "Wydner", "to", "attend", "the", "annual", "meeting", "of", "the", "American", "Translators", "Association", "the", "following", "October", ",", "where", "Weidner", "'s", "machine", "translation", "system", "was", "hailed", "as", "a", "long", "-", "awaited", "breakthrough", "in", "machine", "translation", "."], "sentence-detokenized": "He subsequently extended an invitation for Wydner to attend the annual meeting of the American Translators Association the following October, where Weidner's machine translation system was hailed as a long-awaited breakthrough in machine translation.", "token2charspan": [[0, 2], [3, 15], [16, 24], [25, 27], [28, 38], [39, 42], [43, 49], [50, 52], [53, 59], [60, 63], [64, 70], [71, 78], [79, 81], [82, 85], [86, 94], [95, 106], [107, 118], [119, 122], [123, 132], [133, 140], [140, 141], [142, 147], [148, 155], [155, 157], [158, 165], [166, 177], [178, 184], [185, 188], [189, 195], [196, 198], [199, 200], [201, 205], [205, 206], [206, 213], [214, 226], [227, 229], [230, 237], [238, 249], [249, 250]]}
{"doc_key": "ai-dev-112", "ner": [[2, 10, "conference"], [8, 8, "conference"], [12, 12, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 2, 10, "named", "", false, false], [8, 8, 2, 10, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["At", "the", "2018", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "Conference", ",", "Google", "researchers", "presented", "the", "work", "."], "sentence-detokenized": "At the 2018 Neural Information Processing Systems (NeurIPS) Conference, Google researchers presented the work.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 30], [31, 41], [42, 49], [50, 51], [51, 58], [58, 59], [60, 70], [70, 71], [72, 78], [79, 90], [91, 100], [101, 104], [105, 109], [109, 110]]}
{"doc_key": "ai-dev-113", "ner": [[1, 4, "algorithm"], [10, 11, "algorithm"], [15, 17, "metrics"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 4, 10, 11, "usage", "", false, false], [10, 11, 15, 17, "related-to", "", true, false], [15, 17, 23, 25, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Baum", "-", "Welch", "algorithm", "uses", "the", "well", "-", "known", "EM", "algorithm", "to", "find", "the", "maximum", "likelihood", "estimate", "of", "the", "parameters", "of", "a", "hidden", "Markov", "model", "given", "a", "set", "of", "observed", "feature", "vectors", "."], "sentence-detokenized": "The Baum-Welch algorithm uses the well-known EM algorithm to find the maximum likelihood estimate of the parameters of a hidden Markov model given a set of observed feature vectors.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 14], [15, 24], [25, 29], [30, 33], [34, 38], [38, 39], [39, 44], [45, 47], [48, 57], [58, 60], [61, 65], [66, 69], [70, 77], [78, 88], [89, 97], [98, 100], [101, 104], [105, 115], [116, 118], [119, 120], [121, 127], [128, 134], [135, 140], [141, 146], [147, 148], [149, 152], [153, 155], [156, 164], [165, 172], [173, 180], [180, 181]]}
{"doc_key": "ai-dev-114", "ner": [[9, 9, "product"], [11, 11, "product"], [32, 33, "misc"], [39, 46, "product"], [49, 51, "programlang"], [52, 57, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 9, 11, 11, "compare", "", false, false], [32, 33, 11, 11, "part-of", "", false, false], [39, 46, 11, 11, "part-of", "", false, false], [52, 57, 11, 11, "part-of", "", false, false], [52, 57, 49, 51, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": [")", "In", "addition", "to", "the", "taxonomic", "information", "contained", "in", "OpenCyc", ",", "ResearchCyc", "includes", "much", "more", "semantic", "knowledge", "(", "i.e.", "additional", "facts", "and", "rules", "of", "thumb", ")", "related", "to", "the", "concepts", "in", "its", "knowledge", "base", ";", "it", "also", "includes", "an", "extensive", "lexicon", ",", "parsing", "and", "English", "generation", "tools", ",", "and", "Java", "-", "based", "interfaces", "for", "knowledge", "editing", "and", "querying", "."], "sentence-detokenized": ") In addition to the taxonomic information contained in OpenCyc, ResearchCyc includes much more semantic knowledge (i.e. additional facts and rules of thumb) related to the concepts in its knowledge base; it also includes an extensive lexicon, parsing and English generation tools, and Java-based interfaces for knowledge editing and querying.", "token2charspan": [[0, 1], [2, 4], [5, 13], [14, 16], [17, 20], [21, 30], [31, 42], [43, 52], [53, 55], [56, 63], [63, 64], [65, 76], [77, 85], [86, 90], [91, 95], [96, 104], [105, 114], [115, 116], [116, 120], [121, 131], [132, 137], [138, 141], [142, 147], [148, 150], [151, 156], [156, 157], [158, 165], [166, 168], [169, 172], [173, 181], [182, 184], [185, 188], [189, 198], [199, 203], [203, 204], [205, 207], [208, 212], [213, 221], [222, 224], [225, 234], [235, 242], [242, 243], [244, 251], [252, 255], [256, 263], [264, 274], [275, 280], [280, 281], [282, 285], [286, 290], [290, 291], [291, 296], [297, 307], [308, 311], [312, 321], [322, 329], [330, 333], [334, 342], [342, 343]]}
{"doc_key": "ai-dev-115", "ner": [[0, 2, "algorithm"], [5, 6, "task"], [10, 11, "field"], [13, 14, "field"], [16, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 5, 6, "type-of", "", false, false], [5, 6, 10, 11, "part-of", "task_part_of_field", false, false], [5, 6, 13, 14, "part-of", "task_part_of_field", false, false], [5, 6, 16, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Hough", "transform", "is", "a", "feature", "extraction", "technique", "used", "in", "image", "analysis", ",", "computer", "vision", "and", "digital", "image", "processing", "."], "sentence-detokenized": "The Hough transform is a feature extraction technique used in image analysis, computer vision and digital image processing.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 22], [23, 24], [25, 32], [33, 43], [44, 53], [54, 58], [59, 61], [62, 67], [68, 76], [76, 77], [78, 86], [87, 93], [94, 97], [98, 105], [106, 111], [112, 122], [122, 123]]}
{"doc_key": "ai-dev-116", "ner": [[4, 4, "product"], [6, 10, "product"], [16, 16, "organisation"], [18, 18, "product"], [20, 21, "researcher"], [28, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 4, 6, 10, "named", "", false, false], [4, 4, 16, 16, "artifact", "", false, false], [4, 4, 18, 18, "origin", "developed_from", false, false], [18, 18, 20, 21, "artifact", "", false, false], [28, 29, 16, 16, "role", "supported", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1978", ",", "the", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "robot", "was", "developed", "by", "Unimation", "from", "Vicarm", "(", "Victor", "Scheinman", ")", "and", "with", "the", "support", "of", "General", "Motors", "."], "sentence-detokenized": "In 1978, the PUMA (Programmable Universal Machine for Assembly) robot was developed by Unimation from Vicarm (Victor Scheinman) and with the support of General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 19], [19, 31], [32, 41], [42, 49], [50, 53], [54, 62], [62, 63], [64, 69], [70, 73], [74, 83], [84, 86], [87, 96], [97, 101], [102, 108], [109, 110], [110, 116], [117, 126], [126, 127], [128, 131], [132, 136], [137, 140], [141, 148], [149, 151], [152, 159], [160, 166], [166, 167]]}
{"doc_key": "ai-dev-117", "ner": [[0, 0, "algorithm"], [6, 7, "researcher"], [9, 10, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 7, "origin", "", false, false], [0, 0, 9, 10, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["LSTM", "was", "proposed", "in", "1997", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "LSTM was proposed in 1997 by Sepp Hochreiter and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 20], [21, 25], [26, 28], [29, 33], [34, 44], [45, 48], [49, 55], [56, 67], [67, 68]]}
{"doc_key": "ai-dev-118", "ner": [[11, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "outcomes", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", ",", "as", "follows", ":"], "sentence-detokenized": "The four outcomes can be formulated in a 2 \u00d7 2 contingency table or confusion matrix, as follows:", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 24], [25, 35], [36, 38], [39, 40], [41, 42], [43, 44], [45, 46], [47, 58], [59, 64], [65, 67], [68, 77], [78, 84], [84, 85], [86, 88], [89, 96], [96, 97]]}
{"doc_key": "ai-dev-119", "ner": [[8, 8, "conference"], [11, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "also", "contributed", "greatly", "to", "the", "creation", "of", "ELRA", "and", "the", "LREC", "conference", "."], "sentence-detokenized": "It also contributed greatly to the creation of ELRA and the LREC conference.", "token2charspan": [[0, 2], [3, 7], [8, 19], [20, 27], [28, 30], [31, 34], [35, 43], [44, 46], [47, 51], [52, 55], [56, 59], [60, 64], [65, 75], [75, 76]]}
{"doc_key": "ai-dev-120", "ner": [[17, 18, "misc"], [22, 23, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[22, 23, 17, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["One", "of", "the", "most", "popular", "applications", "of", "serial", "robots", "in", "industry", "today", "is", "the", "pick", "and", "place", "assembly", "robot", ",", "called", "the", "SCARA", "robot", ",", "which", "has", "four", "degrees", "of", "freedom", "."], "sentence-detokenized": "One of the most popular applications of serial robots in industry today is the pick and place assembly robot, called the SCARA robot, which has four degrees of freedom.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 15], [16, 23], [24, 36], [37, 39], [40, 46], [47, 53], [54, 56], [57, 65], [66, 71], [72, 74], [75, 78], [79, 83], [84, 87], [88, 93], [94, 102], [103, 108], [108, 109], [110, 116], [117, 120], [121, 126], [127, 132], [132, 133], [134, 139], [140, 143], [144, 148], [149, 156], [157, 159], [160, 167], [167, 168]]}
{"doc_key": "ai-dev-121", "ner": [[15, 21, "conference"], [23, 23, "conference"], [27, 30, "conference"], [39, 39, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 15, 21, "named", "", false, false], [39, 39, 27, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "one", "of", "the", "founding", "members", "and", "former", "chair", "(", "2006-2008", ")", "of", "the", "Special", "Interest", "Group", "on", "Web", "as", "Corpus", "(", "SIGWAC", ")", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "also", "one", "of", "the", "founding", "organisers", "of", "SENSEVAL", "."], "sentence-detokenized": "He was one of the founding members and former chair (2006-2008) of the Special Interest Group on Web as Corpus (SIGWAC) of the Association for Computational Linguistics and also one of the founding organisers of SENSEVAL.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 13], [14, 17], [18, 26], [27, 34], [35, 38], [39, 45], [46, 51], [52, 53], [53, 62], [62, 63], [64, 66], [67, 70], [71, 78], [79, 87], [88, 93], [94, 96], [97, 100], [101, 103], [104, 110], [111, 112], [112, 118], [118, 119], [120, 122], [123, 126], [127, 138], [139, 142], [143, 156], [157, 168], [169, 172], [173, 177], [178, 181], [182, 184], [185, 188], [189, 197], [198, 208], [209, 211], [212, 220], [220, 221]]}
{"doc_key": "ai-dev-122", "ner": [[4, 4, "product"], [8, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 4, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "platform", ",", "LinguaStream", "provides", "an", "extensive", "Java", "API", "."], "sentence-detokenized": "As a platform, LinguaStream provides an extensive Java API.", "token2charspan": [[0, 2], [3, 4], [5, 13], [13, 14], [15, 27], [28, 36], [37, 39], [40, 49], [50, 54], [55, 58], [58, 59]]}
{"doc_key": "ai-dev-123", "ner": [[11, 11, "programlang"], [14, 16, "misc"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 19, 21, "type-of", "", false, false], [14, 16, 19, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "robot", "kit", "is", "based", "on", "Android", "and", "is", "programmed", "using", "Java", ",", "the", "block", "programming", "interface", "or", "other", "Android", "programming", "systems", "."], "sentence-detokenized": "The robot kit is based on Android and is programmed using Java, the block programming interface or other Android programming systems.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 16], [17, 22], [23, 25], [26, 33], [34, 37], [38, 40], [41, 51], [52, 57], [58, 62], [62, 63], [64, 67], [68, 73], [74, 85], [86, 95], [96, 98], [99, 104], [105, 112], [113, 124], [125, 132], [132, 133]]}
{"doc_key": "ai-dev-124", "ner": [[10, 13, "algorithm"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "linked", "list", "definition", "method", "specifies", "the", "use", "of", "a", "depth", "or", "breadth", "search", "."], "sentence-detokenized": "The linked list definition method specifies the use of a depth or breadth search.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 26], [27, 33], [34, 43], [44, 47], [48, 51], [52, 54], [55, 56], [57, 62], [63, 65], [66, 73], [74, 80], [80, 81]]}
{"doc_key": "ai-dev-125", "ner": [[19, 20, "task"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "regions", "could", "signal", "the", "presence", "of", "objects", "or", "parts", "of", "objects", "in", "the", "image", "domain", "with", "application", "to", "object", "recognition", "and", "/", "or", "video", "object", "tracking", "."], "sentence-detokenized": "These regions could signal the presence of objects or parts of objects in the image domain with application to object recognition and/or video object tracking.", "token2charspan": [[0, 5], [6, 13], [14, 19], [20, 26], [27, 30], [31, 39], [40, 42], [43, 50], [51, 53], [54, 59], [60, 62], [63, 70], [71, 73], [74, 77], [78, 83], [84, 90], [91, 95], [96, 107], [108, 110], [111, 117], [118, 129], [130, 133], [133, 134], [134, 136], [137, 142], [143, 149], [150, 158], [158, 159]]}
{"doc_key": "ai-dev-126", "ner": [[4, 5, "algorithm"], [7, 7, "product"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 4, 5, "type-of", "", false, false], [7, 7, 10, 10, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "a", "semantic", "network", "is", "WordNet", ",", "an", "English", "lexical", "database", "."], "sentence-detokenized": "An example of a semantic network is WordNet, an English lexical database.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 24], [25, 32], [33, 35], [36, 43], [43, 44], [45, 47], [48, 55], [56, 63], [64, 72], [72, 73]]}
{"doc_key": "ai-dev-127", "ner": [[0, 1, "task"], [7, 8, "field"], [10, 11, "field"], [20, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 7, 8, "part-of", "", false, false], [0, 1, 10, 11, "named", "same", false, false], [0, 1, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Speech", "recognition", "is", "an", "interdisciplinary", "subfield", "of", "computer", "science", "and", "computational", "linguistics", "that", "develops", "methodologies", "and", "technologies", "that", "enable", "the", "recognition", "and", "translation", "of", "spoken", "language", "into", "text", "by", "computers", "."], "sentence-detokenized": "Speech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methodologies and technologies that enable the recognition and translation of spoken language into text by computers.", "token2charspan": [[0, 6], [7, 18], [19, 21], [22, 24], [25, 42], [43, 51], [52, 54], [55, 63], [64, 71], [72, 75], [76, 89], [90, 101], [102, 106], [107, 115], [116, 129], [130, 133], [134, 146], [147, 151], [152, 158], [159, 162], [163, 174], [175, 178], [179, 190], [191, 193], [194, 200], [201, 209], [210, 214], [215, 219], [220, 222], [223, 232], [232, 233]]}
{"doc_key": "ai-dev-128", "ner": [[0, 1, "field"], [10, 11, "misc"], [16, 18, "field"], [20, 20, "task"], [21, 23, "task"], [45, 45, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 45, 45, "named", "same", false, false], [16, 18, 0, 1, "part-of", "subfield", false, false], [20, 20, 0, 1, "part-of", "", false, false], [20, 20, 16, 18, "part-of", "", false, false], [21, 23, 16, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Artificial", "intelligence", "has", "received", "the", "most", "attention", "in", "terms", "of", "applied", "ontology", "in", "subfields", "such", "as", "natural", "language", "processing", "within", "machine", "representation", "and", "knowledge", ",", "but", "ontology", "editors", "are", "often", "used", "in", "a", "number", "of", "fields", "such", "as", "education", "without", "the", "intention", "of", "contributing", "to", "AI", "."], "sentence-detokenized": "Artificial intelligence has received the most attention in terms of applied ontology in subfields such as natural language processing within machine representation and knowledge, but ontology editors are often used in a number of fields such as education without the intention of contributing to AI.", "token2charspan": [[0, 10], [11, 23], [24, 27], [28, 36], [37, 40], [41, 45], [46, 55], [56, 58], [59, 64], [65, 67], [68, 75], [76, 84], [85, 87], [88, 97], [98, 102], [103, 105], [106, 113], [114, 122], [123, 133], [134, 140], [141, 148], [149, 163], [164, 167], [168, 177], [177, 178], [179, 182], [183, 191], [192, 199], [200, 203], [204, 209], [210, 214], [215, 217], [218, 219], [220, 226], [227, 229], [230, 236], [237, 241], [242, 244], [245, 254], [255, 262], [263, 266], [267, 276], [277, 279], [280, 292], [293, 295], [296, 298], [298, 299]]}
{"doc_key": "ai-dev-129", "ner": [[10, 12, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 12, 14, 15, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["This", "update", "rule", "is", "in", "fact", "the", "update", "of", "the", "stochastic", "gradient", "descent", "for", "linear", "regression", "."], "sentence-detokenized": "This update rule is in fact the update of the stochastic gradient descent for linear regression.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 19], [20, 22], [23, 27], [28, 31], [32, 38], [39, 41], [42, 45], [46, 56], [57, 65], [66, 73], [74, 77], [78, 84], [85, 95], [95, 96]]}
{"doc_key": "ai-dev-130", "ner": [[5, 10, "organisation"], [13, 16, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "was", "elected", "to", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "the", "National", "Academy", "of", "Sciences", "and", "has", "received", "a", "number", "of", "awards", ":"], "sentence-detokenized": "He was elected to the American Academy of Arts and Sciences and the National Academy of Sciences and has received a number of awards:", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 21], [22, 30], [31, 38], [39, 41], [42, 46], [47, 50], [51, 59], [60, 63], [64, 67], [68, 76], [77, 84], [85, 87], [88, 96], [97, 100], [101, 104], [105, 113], [114, 115], [116, 122], [123, 125], [126, 132], [132, 133]]}
{"doc_key": "ai-dev-131", "ner": [[7, 7, "organisation"], [13, 14, "person"], [16, 19, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 13, 14, "related-to", "written_about_by", false, false], [7, 7, 16, 19, "related-to", "written_about_by", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "recent", "school", "of", "thought", "on", "Honda", "strategy", "was", "put", "forward", "by", "Gary", "Hamel", "and", "C.", "K", ".", "Prahalad", "in", "1989", "."], "sentence-detokenized": "The most recent school of thought on Honda strategy was put forward by Gary Hamel and C. K. Prahalad in 1989.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 22], [23, 25], [26, 33], [34, 36], [37, 42], [43, 51], [52, 55], [56, 59], [60, 67], [68, 70], [71, 75], [76, 81], [82, 85], [86, 88], [89, 90], [90, 91], [92, 100], [101, 103], [104, 108], [108, 109]]}
{"doc_key": "ai-dev-132", "ner": [[1, 1, "metrics"], [4, 7, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 4, 7, "related-to", "calculates", true, false], [1, 1, 19, 19, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["While", "BLEU", "merely", "calculates", "the", "accuracy", "of", "the", "ngranes", "by", "adding", "the", "same", "weight", "to", "each", "of", "them", ",", "NIST", "also", "calculates", "the", "degree", "of", "information", "of", "a", "particular", "ngran", "."], "sentence-detokenized": "While BLEU merely calculates the accuracy of the ngranes by adding the same weight to each of them, NIST also calculates the degree of information of a particular ngran.", "token2charspan": [[0, 5], [6, 10], [11, 17], [18, 28], [29, 32], [33, 41], [42, 44], [45, 48], [49, 56], [57, 59], [60, 66], [67, 70], [71, 75], [76, 82], [83, 85], [86, 90], [91, 93], [94, 98], [98, 99], [100, 104], [105, 109], [110, 120], [121, 124], [125, 131], [132, 134], [135, 146], [147, 149], [150, 151], [152, 162], [163, 168], [168, 169]]}
{"doc_key": "ai-dev-133", "ner": [[6, 9, "misc"], [12, 15, "conference"], [17, 17, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 9, 12, 15, "temporal", "", false, false], [17, 17, 12, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "is", "the", "recipient", "of", "the", "2019", "Lifetime", "Achievement", "Award", "from", "the", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "."], "sentence-detokenized": "He is the recipient of the 2019 Lifetime Achievement Award from the Association for Computational Linguistics (ACL).", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 19], [20, 22], [23, 26], [27, 31], [32, 40], [41, 52], [53, 58], [59, 63], [64, 67], [68, 79], [80, 83], [84, 97], [98, 109], [110, 111], [111, 114], [114, 115], [115, 116]]}
{"doc_key": "ai-dev-134", "ner": [[0, 2, "researcher"], [6, 11, "organisation"], [13, 13, "organisation"], [17, 21, "conference"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 6, 11, "role", "", false, false], [0, 2, 17, 21, "role", "", false, false], [13, 13, 6, 11, "named", "", false, false], [23, 23, 17, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sycara", "is", "a", "member", "of", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", "and", "the", "American", "Association", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Sycara is a member of the Institute of Electrical and Electronics Engineers (IEEE) and the American Association of Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 18], [19, 21], [22, 25], [26, 35], [36, 38], [39, 49], [50, 53], [54, 65], [66, 75], [76, 77], [77, 81], [81, 82], [83, 86], [87, 90], [91, 99], [100, 111], [112, 114], [115, 125], [126, 138], [139, 140], [140, 144], [144, 145], [145, 146]]}
{"doc_key": "ai-dev-135", "ner": [[2, 2, "product"], [11, 13, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 11, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "following", "MATLAB", "code", "shows", "a", "concrete", "solution", "to", "solve", "the", "system", "of", "non-linear", "equations", "presented", "in", "the", "previous", "section", ":", "See", "also"], "sentence-detokenized": "The following MATLAB code shows a concrete solution to solve the system of non-linear equations presented in the previous section: See also", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 31], [32, 33], [34, 42], [43, 51], [52, 54], [55, 60], [61, 64], [65, 71], [72, 74], [75, 85], [86, 95], [96, 105], [106, 108], [109, 112], [113, 121], [122, 129], [129, 130], [131, 134], [135, 139]]}
{"doc_key": "ai-dev-136", "ner": [[4, 6, "product"], [14, 14, "field"], [37, 38, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 14, 14, "related-to", "trained_by", true, false], [4, 6, 37, 38, "related-to", "trained_by", true, false], [14, 14, 37, 38, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "many", "cases", ",", "pattern", "recognition", "systems", "are", "trained", "from", "labelled", "training", "data", "(", "supervised", "learning", ")", ",", "but", "when", "labelled", "data", "is", "not", "available", ",", "other", "algorithms", "can", "be", "used", "to", "discover", "previously", "unknown", "patterns", "(", "unsupervised", "learning", ")", "."], "sentence-detokenized": "In many cases, pattern recognition systems are trained from labelled training data (supervised learning), but when labelled data is not available, other algorithms can be used to discover previously unknown patterns (unsupervised learning).", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 22], [23, 34], [35, 42], [43, 46], [47, 54], [55, 59], [60, 68], [69, 77], [78, 82], [83, 84], [84, 94], [95, 103], [103, 104], [104, 105], [106, 109], [110, 114], [115, 123], [124, 128], [129, 131], [132, 135], [136, 145], [145, 146], [147, 152], [153, 163], [164, 167], [168, 170], [171, 175], [176, 178], [179, 187], [188, 198], [199, 206], [207, 215], [216, 217], [217, 229], [230, 238], [238, 239], [239, 240]]}
{"doc_key": "ai-dev-137", "ner": [[5, 7, "researcher"], [10, 11, "country"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 10, 11, "physical", "", false, false], [5, 7, 24, 25, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "was", "first", "used", "by", "Lawrence", "J.", "Fogel", "in", "the", "United", "States", "in", "1960", "to", "use", "simulated", "evolution", "as", "a", "learning", "process", "to", "generate", "artificial", "intelligence", "."], "sentence-detokenized": "It was first used by Lawrence J. Fogel in the United States in 1960 to use simulated evolution as a learning process to generate artificial intelligence.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 17], [18, 20], [21, 29], [30, 32], [33, 38], [39, 41], [42, 45], [46, 52], [53, 59], [60, 62], [63, 67], [68, 70], [71, 74], [75, 84], [85, 94], [95, 97], [98, 99], [100, 108], [109, 116], [117, 119], [120, 128], [129, 139], [140, 152], [152, 153]]}
{"doc_key": "ai-dev-138", "ner": [[0, 1, "field"], [9, 11, "field"], [15, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 9, 11, "part-of", "", false, false], [15, 16, 9, 11, "part-of", "", false, false], [18, 19, 9, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Reinforcement", "learning", "is", "one", "of", "the", "three", "basic", "paradigms", "of", "machine", "learning", ",", "along", "with", "supervised", "learning", "and", "unsupervised", "learning", "."], "sentence-detokenized": "Reinforcement learning is one of the three basic paradigms of machine learning, along with supervised learning and unsupervised learning.", "token2charspan": [[0, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 42], [43, 48], [49, 58], [59, 61], [62, 69], [70, 78], [78, 79], [80, 85], [86, 90], [91, 101], [102, 110], [111, 114], [115, 127], [128, 136], [136, 137]]}
{"doc_key": "ai-dev-139", "ner": [[4, 5, "field"], [12, 12, "programlang"], [29, 30, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 29, 30, "usage", "applies", false, false], [12, 12, 29, 30, "usage", "applies", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "these", "cases", ",", "cloud", "computing", "and", "the", "open", "source", "programming", "language", "R", "can", "help", "smaller", "banks", "to", "adopt", "risk", "analytics", "and", "support", "branch", "-", "level", "supervision", "by", "applying", "predictive", "analytics", "."], "sentence-detokenized": "In these cases, cloud computing and the open source programming language R can help smaller banks to adopt risk analytics and support branch-level supervision by applying predictive analytics.", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 21], [22, 31], [32, 35], [36, 39], [40, 44], [45, 51], [52, 63], [64, 72], [73, 74], [75, 78], [79, 83], [84, 91], [92, 97], [98, 100], [101, 106], [107, 111], [112, 121], [122, 125], [126, 133], [134, 140], [140, 141], [141, 146], [147, 158], [159, 161], [162, 170], [171, 181], [182, 191], [191, 192]]}
{"doc_key": "ai-dev-140", "ner": [[11, 12, "researcher"], [16, 18, "algorithm"], [22, 23, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 22, 23, "named", "same", false, false], [16, 18, 11, 12, "origin", "proves_function", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["One", "of", "the", "first", "versions", "of", "the", "theorem", "was", "proved", "by", "George", "Cybenko", "in", "1989", "for", "sigmoid", "-", "type", "activation", "functions", ".", "Cybenko", "G.", "(", "1989", ")", ",", "2", "(", "4", ")", ",", "303-314", "."], "sentence-detokenized": "One of the first versions of the theorem was proved by George Cybenko in 1989 for sigmoid-type activation functions. Cybenko G. (1989), 2 (4), 303-314.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [17, 25], [26, 28], [29, 32], [33, 40], [41, 44], [45, 51], [52, 54], [55, 61], [62, 69], [70, 72], [73, 77], [78, 81], [82, 89], [89, 90], [90, 94], [95, 105], [106, 115], [115, 116], [117, 124], [125, 127], [128, 129], [129, 133], [133, 134], [134, 135], [136, 137], [138, 139], [139, 140], [140, 141], [141, 142], [143, 150], [150, 151]]}
{"doc_key": "ai-dev-141", "ner": [[8, 8, "algorithm"], [11, 12, "metrics"], [18, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 8, 8, "part-of", "", false, false], [18, 21, 11, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "this", "process", ",", "which", "is", "known", "as", "cross-validation", ",", "the", "MSE", "is", "often", "referred", "to", "as", "the", "mean", "squared", "prediction", "error", ",", "and", "is", "calculated", "as"], "sentence-detokenized": "In this process, which is known as cross-validation, the MSE is often referred to as the mean squared prediction error, and is calculated as", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 22], [23, 25], [26, 31], [32, 34], [35, 51], [51, 52], [53, 56], [57, 60], [61, 63], [64, 69], [70, 78], [79, 81], [82, 84], [85, 88], [89, 93], [94, 101], [102, 112], [113, 118], [118, 119], [120, 123], [124, 126], [127, 137], [138, 140]]}
{"doc_key": "ai-dev-142", "ner": [[0, 0, "task"], [5, 7, "task"], [9, 13, "task"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 7, "compare", "", false, false], [5, 7, 21, 22, "part-of", "", false, false], [9, 13, 5, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OMR", "is", "generally", "distinguished", "from", "optical", "character", "recognition", "(", "OCR", ")", "by", "the", "fact", "that", "it", "does", "not", "require", "a", "complicated", "pattern", "recognition", "engine", "."], "sentence-detokenized": "OMR is generally distinguished from optical character recognition (OCR) by the fact that it does not require a complicated pattern recognition engine.", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 30], [31, 35], [36, 43], [44, 53], [54, 65], [66, 67], [67, 70], [70, 71], [72, 74], [75, 78], [79, 83], [84, 88], [89, 91], [92, 96], [97, 100], [101, 108], [109, 110], [111, 122], [123, 130], [131, 142], [143, 149], [149, 150]]}
{"doc_key": "ai-dev-143", "ner": [[10, 10, "location"], [12, 12, "location"], [14, 14, "location"], [17, 18, "location"], [20, 21, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 14, 14, "physical", "", false, false], [17, 18, 12, 12, "physical", "", false, false], [20, 21, 12, 12, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2018", "and", "2019", ",", "the", "Championship", "was", "held", "in", "Houston", "and", "Detroit", ",", "Michigan", ",", "at", "TCF", "Center", "and", "Ford", "Field", "."], "sentence-detokenized": "In 2018 and 2019, the Championship was held in Houston and Detroit, Michigan, at TCF Center and Ford Field.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 16], [16, 17], [18, 21], [22, 34], [35, 38], [39, 43], [44, 46], [47, 54], [55, 58], [59, 66], [66, 67], [68, 76], [76, 77], [78, 80], [81, 84], [85, 91], [92, 95], [96, 100], [101, 106], [106, 107]]}
{"doc_key": "ai-dev-144", "ner": [[0, 0, "task"], [9, 10, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 0, "part-of", "", false, false], [12, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "considered", "as", "two", "distinct", "problems", ":", "binary", "classification", "and", "multi-class", "classification", "."], "sentence-detokenized": "Classification can be considered as two distinct problems: binary classification and multi-class classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 48], [49, 57], [57, 58], [59, 65], [66, 80], [81, 84], [85, 96], [97, 111], [111, 112]]}
{"doc_key": "ai-dev-145", "ner": [[4, 5, "product"], [8, 9, "product"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 4, 5, "type-of", "", false, false], [12, 13, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "examples", "of", "popular", "parallel", "robots", "are", "the", "Stewart", "platform", "and", "the", "Delta", "robot", "."], "sentence-detokenized": "Two examples of popular parallel robots are the Stewart platform and the Delta robot.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 23], [24, 32], [33, 39], [40, 43], [44, 47], [48, 55], [56, 64], [65, 68], [69, 72], [73, 78], [79, 84], [84, 85]]}
{"doc_key": "ai-dev-146", "ner": [[4, 6, "algorithm"], [21, 21, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 21, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "However", ",", "the", "ReLU", "activation", "function", ",", "which", "is", "indistinguishable", "in", "0", ",", "has", "become", "quite", "popular", ",", "e.g.", "in", "AlexNet", ")", "."], "sentence-detokenized": "(However, the ReLU activation function, which is indistinguishable in 0, has become quite popular, e.g. in AlexNet).", "token2charspan": [[0, 1], [1, 8], [8, 9], [10, 13], [14, 18], [19, 29], [30, 38], [38, 39], [40, 45], [46, 48], [49, 66], [67, 69], [70, 71], [71, 72], [73, 76], [77, 83], [84, 89], [90, 97], [97, 98], [99, 103], [104, 106], [107, 114], [114, 115], [115, 116]]}
{"doc_key": "ai-dev-147", "ner": [[0, 3, "metrics"], [11, 12, "task"], [15, 15, "task"], [18, 19, "task"], [21, 22, "task"], [25, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 25, 25, "named", "", true, false], [11, 12, 0, 3, "usage", "", true, false], [15, 15, 11, 12, "part-of", "", false, false], [18, 19, 11, 12, "part-of", "", false, false], [21, 22, 11, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "F", "-", "score", "is", "often", "used", "in", "the", "field", "of", "information", "retrieval", "to", "measure", "search", "performance", ",", "document", "ranking", "and", "query", "ranking", ",", "so", "F_beta", "has", "a", "wide", "application", "."], "sentence-detokenized": "The F-score is often used in the field of information retrieval to measure search performance, document ranking and query ranking, so F_beta has a wide application.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 20], [21, 25], [26, 28], [29, 32], [33, 38], [39, 41], [42, 53], [54, 63], [64, 66], [67, 74], [75, 81], [82, 93], [93, 94], [95, 103], [104, 111], [112, 115], [116, 121], [122, 129], [129, 130], [131, 133], [134, 140], [141, 144], [145, 146], [147, 151], [152, 163], [163, 164]]}
{"doc_key": "ai-dev-148", "ner": [[17, 18, "algorithm"], [20, 20, "algorithm"], [23, 24, "algorithm"], [26, 26, "algorithm"], [29, 31, "algorithm"], [33, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 20, 17, 18, "named", "", false, false], [26, 26, 23, 24, "named", "", false, false], [33, 33, 29, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "is", "done", "by", "modelling", "the", "received", "signal", "and", "then", "using", "a", "statistical", "estimation", "method", "such", "as", "maximum", "likelihood", "(", "ML", ")", ",", "majority", "voting", "(", "MV", ")", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "to", "make", "a", "decision", "on", "which", "library", "target", "best", "fits", "the", "model", "built", "with", "the", "received", "signal", "."], "sentence-detokenized": "This is done by modelling the received signal and then using a statistical estimation method such as maximum likelihood (ML), majority voting (MV) or maximum a posteriori (MAP) to make a decision on which library target best fits the model built with the received signal.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 15], [16, 25], [26, 29], [30, 38], [39, 45], [46, 49], [50, 54], [55, 60], [61, 62], [63, 74], [75, 85], [86, 92], [93, 97], [98, 100], [101, 108], [109, 119], [120, 121], [121, 123], [123, 124], [124, 125], [126, 134], [135, 141], [142, 143], [143, 145], [145, 146], [147, 149], [150, 157], [158, 159], [160, 170], [171, 172], [172, 175], [175, 176], [177, 179], [180, 184], [185, 186], [187, 195], [196, 198], [199, 204], [205, 212], [213, 219], [220, 224], [225, 229], [230, 233], [234, 239], [240, 245], [246, 250], [251, 254], [255, 263], [264, 270], [270, 271]]}
{"doc_key": "ai-dev-149", "ner": [[0, 0, "researcher"], [4, 5, "misc"], [7, 7, "field"], [10, 13, "university"], [19, 21, "misc"], [18, 18, "field"], [23, 24, "university"], [30, 30, "misc"], [32, 33, "field"], [36, 39, "university"], [46, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 0, 10, 13, "physical", "", false, false], [0, 0, 10, 13, "role", "", false, false], [0, 0, 23, 24, "physical", "", false, false], [0, 0, 23, 24, "role", "", false, false], [0, 0, 36, 39, "physical", "", false, false], [0, 0, 36, 39, "role", "", false, false], [4, 5, 0, 0, "origin", "", false, false], [4, 5, 7, 7, "topic", "", false, false], [19, 21, 0, 0, "origin", "", false, false], [19, 21, 18, 18, "topic", "", false, false], [30, 30, 0, 0, "origin", "", false, false], [30, 30, 32, 33, "topic", "", false, false], [46, 55, 30, 30, "named", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Sowa", "received", "a", "bachelor", "'s", "degree", "in", "mathematics", "from", "the", "Massachusetts", "Institute", "of", "Technology", "in", "1962", ",", "an", "applied", "master", "'s", "degree", "from", "Harvard", "University", "in", "1966", ",", "and", "a", "PhD", "in", "computer", "science", "from", "the", "Universit\u00e9", "Libre", "de", "Bruxelles", "in", "1999", "with", "a", "thesis", "entitled", "Knowledge", "Representation", ":", "Logical", ",", "Philosophical", ",", "and", "Computational", "Foundations", "."], "sentence-detokenized": "Sowa received a bachelor's degree in mathematics from the Massachusetts Institute of Technology in 1962, an applied master's degree from Harvard University in 1966, and a PhD in computer science from the Universit\u00e9 Libre de Bruxelles in 1999 with a thesis entitled Knowledge Representation: Logical, Philosophical, and Computational Foundations.", "token2charspan": [[0, 4], [5, 13], [14, 15], [16, 24], [24, 26], [27, 33], [34, 36], [37, 48], [49, 53], [54, 57], [58, 71], [72, 81], [82, 84], [85, 95], [96, 98], [99, 103], [103, 104], [105, 107], [108, 115], [116, 122], [122, 124], [125, 131], [132, 136], [137, 144], [145, 155], [156, 158], [159, 163], [163, 164], [165, 168], [169, 170], [171, 174], [175, 177], [178, 186], [187, 194], [195, 199], [200, 203], [204, 214], [215, 220], [221, 223], [224, 233], [234, 236], [237, 241], [242, 246], [247, 248], [249, 255], [256, 264], [265, 274], [275, 289], [289, 290], [291, 298], [298, 299], [300, 313], [313, 314], [315, 318], [319, 332], [333, 344], [344, 345]]}
{"doc_key": "ai-dev-150", "ner": [[1, 2, "task"], [8, 8, "task"], [18, 18, "metrics"], [20, 21, "metrics"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 8, 8, "general-affiliation", "", false, false], [18, 18, 1, 2, "part-of", "", true, false], [20, 21, 1, 2, "part-of", "", true, false], [24, 25, 1, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "paraphrase", "recognition", "can", "be", "posed", "as", "a", "classification", "problem", ",", "most", "standard", "evaluation", "metrics", ",", "such", "as", "accuracy", ",", "f1", "score", "or", "an", "ROC", "curve", ",", "work", "relatively", "well", "."], "sentence-detokenized": "Since paraphrase recognition can be posed as a classification problem, most standard evaluation metrics, such as accuracy, f1 score or an ROC curve, work relatively well.", "token2charspan": [[0, 5], [6, 16], [17, 28], [29, 32], [33, 35], [36, 41], [42, 44], [45, 46], [47, 61], [62, 69], [69, 70], [71, 75], [76, 84], [85, 95], [96, 103], [103, 104], [105, 109], [110, 112], [113, 121], [121, 122], [123, 125], [126, 131], [132, 134], [135, 137], [138, 141], [142, 147], [147, 148], [149, 153], [154, 164], [165, 169], [169, 170]]}
{"doc_key": "ai-dev-151", "ner": [[17, 17, "algorithm"], [27, 28, "algorithm"], [30, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 17, 27, 28, "opposite", "not_suited_for", false, false], [17, 17, 30, 31, "opposite", "not_suited_for", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "makes", "it", "practical", "for", "analysing", "large", "datasets", "(", "hundreds", "or", "thousands", "of", "taxa", ")", "and", "for", "bootstrapping", ",", "for", "which", "other", "means", "of", "analysis", "(", "e.g.", "maximum", "parsimony", ",", "maximum", "likelihood", ")", "may", "be", "computationally", "prohibitive", "."], "sentence-detokenized": "This makes it practical for analysing large datasets (hundreds or thousands of taxa) and for bootstrapping, for which other means of analysis (e.g. maximum parsimony, maximum likelihood) may be computationally prohibitive.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 37], [38, 43], [44, 52], [53, 54], [54, 62], [63, 65], [66, 75], [76, 78], [79, 83], [83, 84], [85, 88], [89, 92], [93, 106], [106, 107], [108, 111], [112, 117], [118, 123], [124, 129], [130, 132], [133, 141], [142, 143], [143, 147], [148, 155], [156, 165], [165, 166], [167, 174], [175, 185], [185, 186], [187, 190], [191, 193], [194, 209], [210, 221], [221, 222]]}
{"doc_key": "ai-dev-152", "ner": [[5, 5, "programlang"], [7, 7, "programlang"], [11, 14, "organisation"], [16, 16, "organisation"], [23, 23, "programlang"], [27, 36, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 23, 23, "named", "same", false, false], [16, 16, 11, 14, "named", "", false, false], [27, 36, 5, 5, "role", "submits", true, false], [27, 36, 7, 7, "role", "submits", true, false], [27, 36, 11, 14, "role", "submits_to", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "2002", "submission", "of", "the", "DAML", "+", "OIL", "language", "to", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", "the", "work", "done", "by", "the", "DAML", "contractors", "and", "the", "ad", "hoc", "Joint", "EU", "-", "US", "Committee", "on", "Markup", "Languages", "."], "sentence-detokenized": "The 2002 submission of the DAML + OIL language to the World Wide Web Consortium (W3C) the work done by the DAML contractors and the ad hoc Joint EU-US Committee on Markup Languages.", "token2charspan": [[0, 3], [4, 8], [9, 19], [20, 22], [23, 26], [27, 31], [32, 33], [34, 37], [38, 46], [47, 49], [50, 53], [54, 59], [60, 64], [65, 68], [69, 79], [80, 81], [81, 84], [84, 85], [86, 89], [90, 94], [95, 99], [100, 102], [103, 106], [107, 111], [112, 123], [124, 127], [128, 131], [132, 134], [135, 138], [139, 144], [145, 147], [147, 148], [148, 150], [151, 160], [161, 163], [164, 170], [171, 180], [180, 181]]}
{"doc_key": "ai-dev-153", "ner": [[3, 4, "misc"], [8, 8, "misc"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 3, 4, "part-of", "", true, false], [11, 12, 3, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "non-linear", "normalisation", "is", "when", "the", "normalisation", "follows", "a", "sigmoid", "function", ",", "in", "which", "case", "the", "normalised", "image", "is", "calculated", "according", "to", "the", "formula"], "sentence-detokenized": "An example of non-linear normalisation is when the normalisation follows a sigmoid function, in which case the normalised image is calculated according to the formula", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 24], [25, 38], [39, 41], [42, 46], [47, 50], [51, 64], [65, 72], [73, 74], [75, 82], [83, 91], [91, 92], [93, 95], [96, 101], [102, 106], [107, 110], [111, 121], [122, 127], [128, 130], [131, 141], [142, 151], [152, 154], [155, 158], [159, 166]]}
{"doc_key": "ai-dev-154", "ner": [[6, 7, "metrics"], [11, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 11, 11, "related-to", "used_together", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "pointed", "out", "that", "accuracy", "is", "often", "linked", "to", "memory", "to", "overcome", "this", "problem", "."], "sentence-detokenized": "It has been pointed out that accuracy is often linked to memory to overcome this problem.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 23], [24, 28], [29, 37], [38, 40], [41, 46], [47, 53], [54, 56], [57, 63], [64, 66], [67, 75], [76, 80], [81, 88], [88, 89]]}
{"doc_key": "ai-dev-155", "ner": [[7, 10, "metrics"], [13, 18, "metrics"], [23, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 24, 13, 18, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "most", "commonly", "used", "metrics", "are", "the", "root", "mean", "square", "error", "and", "the", "root", "mean", "square", "error", ",", "the", "latter", "used", "in", "the", "Netflix", "Prize", "."], "sentence-detokenized": "The most commonly used metrics are the root mean square error and the root mean square error, the latter used in the Netflix Prize.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 30], [31, 34], [35, 38], [39, 43], [44, 48], [49, 55], [56, 61], [62, 65], [66, 69], [70, 74], [75, 79], [80, 86], [87, 92], [92, 93], [94, 97], [98, 104], [105, 109], [110, 112], [113, 116], [117, 124], [125, 130], [130, 131]]}
{"doc_key": "ai-dev-156", "ner": [[10, 16, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "August", "2016", ",", "a", "research", "programme", "was", "announced", "with", "University", "College", "Hospital", "with", "the", "aim", "of", "developing", "an", "algorithm", "that", "can", "automatically", "differentiate", "healthy", "tissue", "from", "cancerous", "tissue", "in", "the", "head", "and", "neck", "areas", "."], "sentence-detokenized": "In August 2016, a research programme was announced with University College Hospital with the aim of developing an algorithm that can automatically differentiate healthy tissue from cancerous tissue in the head and neck areas.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 17], [18, 26], [27, 36], [37, 40], [41, 50], [51, 55], [56, 66], [67, 74], [75, 83], [84, 88], [89, 92], [93, 96], [97, 99], [100, 110], [111, 113], [114, 123], [124, 128], [129, 132], [133, 146], [147, 160], [161, 168], [169, 175], [176, 180], [181, 190], [191, 197], [198, 200], [201, 204], [205, 209], [210, 213], [214, 218], [219, 224], [224, 225]]}
{"doc_key": "ai-dev-157", "ner": [[17, 19, "organisation"], [22, 25, "organisation"], [28, 31, "organisation"], [34, 39, "organisation"], [42, 48, "organisation"], [51, 54, "organisation"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "impact", "of", "Posner", "'s", "theoretical", "and", "empirical", "contributions", "has", "been", "recognised", "through", "his", "membership", "of", "the", "American", "Psychological", "Association", ",", "the", "Association", "for", "Psychological", "Science", ",", "the", "Society", "of", "Experimental", "Psychologists", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "The impact of Posner's theoretical and empirical contributions has been recognised through his membership of the American Psychological Association, the Association for Psychological Science, the Society of Experimental Psychologists, the American Academy of Arts and Sciences, the American Association for the Advancement of Science and the National Academy of Sciences.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 20], [20, 22], [23, 34], [35, 38], [39, 48], [49, 62], [63, 66], [67, 71], [72, 82], [83, 90], [91, 94], [95, 105], [106, 108], [109, 112], [113, 121], [122, 135], [136, 147], [147, 148], [149, 152], [153, 164], [165, 168], [169, 182], [183, 190], [190, 191], [192, 195], [196, 203], [204, 206], [207, 219], [220, 233], [233, 234], [235, 238], [239, 247], [248, 255], [256, 258], [259, 263], [264, 267], [268, 276], [276, 277], [278, 281], [282, 290], [291, 302], [303, 306], [307, 310], [311, 322], [323, 325], [326, 333], [334, 337], [338, 341], [342, 350], [351, 358], [359, 361], [362, 370], [370, 371]]}
{"doc_key": "ai-dev-158", "ner": [[2, 2, "product"], [9, 10, "field"], [13, 14, "task"], [16, 18, "task"], [20, 20, "task"], [23, 25, "task"], [27, 27, "task"], [30, 31, "field"], [33, 34, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 2, 9, 10, "usage", "", false, false], [13, 14, 9, 10, "part-of", "", false, false], [16, 18, 9, 10, "part-of", "", false, false], [20, 20, 16, 18, "named", "", false, false], [23, 25, 9, 10, "part-of", "", false, false], [27, 27, 23, 25, "named", "", false, false], [30, 31, 9, 10, "part-of", "", false, false], [33, 34, 9, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["These", "intelligent", "chatbots", "make", "use", "of", "all", "types", "of", "artificial", "intelligence", "such", "as", "image", "moderation", "and", "natural", "language", "understanding", "(", "NLU", ")", ",", "natural", "language", "generation", "(", "NLG", ")", ",", "machine", "learning", "and", "deep", "learning", "."], "sentence-detokenized": "These intelligent chatbots make use of all types of artificial intelligence such as image moderation and natural language understanding (NLU), natural language generation (NLG), machine learning and deep learning.", "token2charspan": [[0, 5], [6, 17], [18, 26], [27, 31], [32, 35], [36, 38], [39, 42], [43, 48], [49, 51], [52, 62], [63, 75], [76, 80], [81, 83], [84, 89], [90, 100], [101, 104], [105, 112], [113, 121], [122, 135], [136, 137], [137, 140], [140, 141], [141, 142], [143, 150], [151, 159], [160, 170], [171, 172], [172, 175], [175, 176], [176, 177], [178, 185], [186, 194], [195, 198], [199, 203], [204, 212], [212, 213]]}
{"doc_key": "ai-dev-159", "ner": [[5, 5, "metrics"], [9, 9, "metrics"], [14, 14, "metrics"], [17, 24, "metrics"], [31, 32, "metrics"], [35, 35, "metrics"], [38, 44, "metrics"], [6, 51, "metrics"], [53, 53, "metrics"], [56, 62, "metrics"], [31, 72, "metrics"], [74, 74, "metrics"], [77, 83, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[9, 9, 5, 5, "named", "", false, false], [14, 14, 5, 5, "named", "", false, false], [17, 24, 5, 5, "named", "", false, false], [35, 35, 31, 32, "named", "", false, false], [38, 44, 31, 32, "named", "", false, false], [53, 53, 6, 51, "named", "", false, false], [56, 62, 6, 51, "named", "", false, false], [74, 74, 31, 72, "named", "", false, false], [77, 83, 31, 72, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "row", "ratios", "are", "the", "Positive", "Predictive", "Value", "(", "PPV", ",", "also", "known", "as", "precision", ")", "(", "TP", "/", "(", "TP", "+", "FP", ")", ")", ",", "with", "the", "complement", "of", "the", "False", "Discovery", "Rate", "(", "FDR", ")", "(", "FP", "/", "(", "TP", "+", "FP", ")", ")", ";", "and", "the", "Negative", "Predictive", "Value", "(", "NPV", ")", "(", "TN", "/", "(", "TN", "+", "FN", ")", ")", ",", "with", "the", "complement", "of", "the", "False", "Omission", "Rate", "(", "FOR", ")", "(", "FN", "/", "(", "TN", "+", "FN", ")", ")", "."], "sentence-detokenized": "The row ratios are the Positive Predictive Value (PPV, also known as precision) (TP / (TP + FP)), with the complement of the False Discovery Rate (FDR) (FP / (TP + FP)); and the Negative Predictive Value (NPV) (TN / (TN + FN)), with the complement of the False Omission Rate (FOR) (FN / (TN + FN)).", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 18], [19, 22], [23, 31], [32, 42], [43, 48], [49, 50], [50, 53], [53, 54], [55, 59], [60, 65], [66, 68], [69, 78], [78, 79], [80, 81], [81, 83], [84, 85], [86, 87], [87, 89], [90, 91], [92, 94], [94, 95], [95, 96], [96, 97], [98, 102], [103, 106], [107, 117], [118, 120], [121, 124], [125, 130], [131, 140], [141, 145], [146, 147], [147, 150], [150, 151], [152, 153], [153, 155], [156, 157], [158, 159], [159, 161], [162, 163], [164, 166], [166, 167], [167, 168], [168, 169], [170, 173], [174, 177], [178, 186], [187, 197], [198, 203], [204, 205], [205, 208], [208, 209], [210, 211], [211, 213], [214, 215], [216, 217], [217, 219], [220, 221], [222, 224], [224, 225], [225, 226], [226, 227], [228, 232], [233, 236], [237, 247], [248, 250], [251, 254], [255, 260], [261, 269], [270, 274], [275, 276], [276, 279], [279, 280], [281, 282], [282, 284], [285, 286], [287, 288], [288, 290], [291, 292], [293, 295], [295, 296], [296, 297], [297, 298]]}
{"doc_key": "ai-dev-160", "ner": [[8, 8, "misc"], [14, 15, "algorithm"], [17, 17, "algorithm"], [21, 23, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[17, 17, 14, 15, "named", "", false, false], [25, 25, 21, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "information", "is", "a", "mixture", "of", "sitemaps", "and", "RSS", "and", "is", "created", "using", "the", "Information", "Model", "(", "IM", ")", "and", "the", "Biomedical", "Resource", "Ontology", "(", "BRO", ")", "."], "sentence-detokenized": "The information is a mixture of sitemaps and RSS and is created using the Information Model (IM) and the Biomedical Resource Ontology (BRO).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 20], [21, 28], [29, 31], [32, 40], [41, 44], [45, 48], [49, 52], [53, 55], [56, 63], [64, 69], [70, 73], [74, 85], [86, 91], [92, 93], [93, 95], [95, 96], [97, 100], [101, 104], [105, 115], [116, 124], [125, 133], [134, 135], [135, 138], [138, 139], [139, 140]]}
{"doc_key": "ai-dev-161", "ner": [[1, 2, "task"], [7, 9, "algorithm"], [14, 14, "algorithm"], [21, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 14, 14, "origin", "based_on", false, false], [14, 14, 7, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Recent", "text", "recognition", "is", "based", "on", "a", "recurrent", "neural", "network", "(", "short", "-", "term", "memory", ")", "and", "does", "not", "require", "a", "linguistic", "model", "."], "sentence-detokenized": "Recent text recognition is based on a recurrent neural network (short-term memory) and does not require a linguistic model.", "token2charspan": [[0, 6], [7, 11], [12, 23], [24, 26], [27, 32], [33, 35], [36, 37], [38, 47], [48, 54], [55, 62], [63, 64], [64, 69], [69, 70], [70, 74], [75, 81], [81, 82], [83, 86], [87, 91], [92, 95], [96, 103], [104, 105], [106, 116], [117, 122], [122, 123]]}
{"doc_key": "ai-dev-162", "ner": [[0, 4, "misc"], [7, 8, "metrics"], [11, 12, "algorithm"], [16, 17, "metrics"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 0, 4, "type-of", "", false, false], [11, 12, 7, 8, "related-to", "", true, false], [16, 17, 0, 4, "type-of", "", false, false], [20, 21, 16, 17, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "most", "popular", "loss", "functions", "are", "the", "hinge", "loss", "(", "for", "linear", "SVMs", ")", "and", "the", "log", "loss", "(", "for", "logistic", "regression", ")", "."], "sentence-detokenized": "The most popular loss functions are the hinge loss (for linear SVMs) and the log loss (for logistic regression).", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 21], [22, 31], [32, 35], [36, 39], [40, 45], [46, 50], [51, 52], [52, 55], [56, 62], [63, 67], [67, 68], [69, 72], [73, 76], [77, 80], [81, 85], [86, 87], [87, 90], [91, 99], [100, 110], [110, 111], [111, 112]]}
{"doc_key": "ai-dev-163", "ner": [[0, 0, "metrics"], [10, 16, "metrics"], [18, 18, "metrics"], [21, 23, "metrics"], [25, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 10, 16, "compare", "", false, false], [0, 0, 21, 23, "compare", "", false, false], [18, 18, 10, 16, "named", "", false, false], [25, 25, 21, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SSIM", "is", "designed", "to", "improve", "on", "traditional", "methods", "such", "as", "maximum", "signal", "-", "to", "-", "noise", "ratio", "(", "PSNR", ")", "and", "mean", "squared", "error", "(", "MSE", ")", "."], "sentence-detokenized": "SSIM is designed to improve on traditional methods such as maximum signal-to-noise ratio (PSNR) and mean squared error (MSE).", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 19], [20, 27], [28, 30], [31, 42], [43, 50], [51, 55], [56, 58], [59, 66], [67, 73], [73, 74], [74, 76], [76, 77], [77, 82], [83, 88], [89, 90], [90, 94], [94, 95], [96, 99], [100, 104], [105, 112], [113, 118], [119, 120], [120, 123], [123, 124], [124, 125]]}
{"doc_key": "ai-dev-164", "ner": [[11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "work", "inspired", "later", "generations", "of", "robotics", "researchers", ",", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "His work inspired later generations of robotics researchers, such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 23], [24, 35], [36, 38], [39, 47], [48, 59], [59, 60], [61, 65], [66, 68], [69, 75], [76, 82], [82, 83], [84, 88], [89, 96], [97, 100], [101, 105], [106, 112], [112, 113]]}
{"doc_key": "ai-dev-165", "ner": [[11, 13, "algorithm"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 11, 13, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "addition", ",", "pulse", "training", "is", "not", "differentiable", ",", "which", "eliminates", "backpropagation", "-", "based", "training", "methods", "such", "as", "gradient", "descent", "."], "sentence-detokenized": "In addition, pulse training is not differentiable, which eliminates backpropagation-based training methods such as gradient descent.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 18], [19, 27], [28, 30], [31, 34], [35, 49], [49, 50], [51, 56], [57, 67], [68, 83], [83, 84], [84, 89], [90, 98], [99, 106], [107, 111], [112, 114], [115, 123], [124, 131], [131, 132]]}
{"doc_key": "ai-dev-166", "ner": [[8, 9, "metrics"], [15, 15, "metrics"], [18, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 15, 15, "related-to", "describes", false, false], [15, 15, 18, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "relationships", "can", "be", "easily", "represented", "by", "a", "confusion", "matrix", ",", "a", "table", "describing", "the", "accuracy", "of", "a", "classification", "model", "."], "sentence-detokenized": "These relationships can be easily represented by a confusion matrix, a table describing the accuracy of a classification model.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 26], [27, 33], [34, 45], [46, 48], [49, 50], [51, 60], [61, 67], [67, 68], [69, 70], [71, 76], [77, 87], [88, 91], [92, 100], [101, 103], [104, 105], [106, 120], [121, 126], [126, 127]]}
{"doc_key": "ai-dev-167", "ner": [[2, 10, "conference"], [8, 8, "conference"], [12, 12, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 2, 10, "named", "", false, false], [12, 12, 2, 10, "physical", "", false, false], [12, 12, 2, 10, "role", "", false, false], [12, 12, 2, 10, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["At", "the", "2018", "Neuronal", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "Conference", ",", "Google", "researchers", "presented", "the", "paper"], "sentence-detokenized": "At the 2018 Neuronal Information Processing Systems (NeurIPS) Conference, Google researchers presented the paper", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 20], [21, 32], [33, 43], [44, 51], [52, 53], [53, 60], [60, 61], [62, 72], [72, 73], [74, 80], [81, 92], [93, 102], [103, 106], [107, 112]]}
{"doc_key": "ai-dev-168", "ner": [[2, 4, "university"], [12, 12, "product"], [18, 20, "misc"], [17, 17, "conference"], [27, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 18, 20, "win-defeat", "", false, false], [18, 20, 17, 17, "temporal", "", false, false], [27, 30, 17, 17, "part-of", "", false, false], [27, 30, 17, 17, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "at", "Duke", ",", "he", "worked", "on", "the", "automatic", "crossword", "puzzle", "solution", "PROVERB", ",", "which", "won", "the", "AAAI", "Outstanding", "Paper", "Award", "in", "1999", "and", "competed", "in", "the", "American", "Crossword", "Puzzle", "Tournament", "."], "sentence-detokenized": "While at Duke, he worked on the automatic crossword puzzle solution PROVERB, which won the AAAI Outstanding Paper Award in 1999 and competed in the American Crossword Puzzle Tournament.", "token2charspan": [[0, 5], [6, 8], [9, 13], [13, 14], [15, 17], [18, 24], [25, 27], [28, 31], [32, 41], [42, 51], [52, 58], [59, 67], [68, 75], [75, 76], [77, 82], [83, 86], [87, 90], [91, 95], [96, 107], [108, 113], [114, 119], [120, 122], [123, 127], [128, 131], [132, 140], [141, 143], [144, 147], [148, 156], [157, 166], [167, 173], [174, 184], [184, 185]]}
{"doc_key": "ai-dev-169", "ner": [[2, 3, "location"], [5, 5, "location"], [15, 16, "country"], [18, 18, "country"], [20, 20, "country"], [22, 22, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 5, 5, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Headquartered", "in", "Rochester", "Hills", ",", "Michigan", ",", "the", "company", "had", "10", "regional", "locations", "in", "the", "United", "States", ",", "Canada", ",", "Mexico", "and", "Brazil", "."], "sentence-detokenized": "Headquartered in Rochester Hills, Michigan, the company had 10 regional locations in the United States, Canada, Mexico and Brazil.", "token2charspan": [[0, 13], [14, 16], [17, 26], [27, 32], [32, 33], [34, 42], [42, 43], [44, 47], [48, 55], [56, 59], [60, 62], [63, 71], [72, 81], [82, 84], [85, 88], [89, 95], [96, 102], [102, 103], [104, 110], [110, 111], [112, 118], [119, 122], [123, 129], [129, 130]]}
{"doc_key": "ai-dev-170", "ner": [[12, 12, "product"], [14, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "joins", "a", "collection", "of", "historically", "important", "robots", "that", "includes", "an", "early", "Unimate", "and", "Odetics", "'", "Odex", "1", "."], "sentence-detokenized": "It joins a collection of historically important robots that includes an early Unimate and Odetics' Odex 1.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 21], [22, 24], [25, 37], [38, 47], [48, 54], [55, 59], [60, 68], [69, 71], [72, 77], [78, 85], [86, 89], [90, 97], [97, 98], [99, 103], [104, 105], [105, 106]]}
{"doc_key": "ai-dev-171", "ner": [[8, 9, "researcher"], [13, 13, "organisation"], [15, 16, "researcher"], [26, 31, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 13, 13, "physical", "", false, false], [8, 9, 13, 13, "role", "", false, false], [15, 16, 13, 13, "physical", "", false, false], [15, 16, 13, 13, "role", "", false, false], [15, 16, 26, 31, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "guest", "editor", "for", "that", "issue", "will", "be", "David", "'s", "former", "colleague", "at", "NIST", ",", "Judah", "Levine", ",", "who", "is", "the", "most", "recent", "recipient", "of", "the", "I", ".", "I", ".", "Rabi", "Award", "."], "sentence-detokenized": "The guest editor for that issue will be David's former colleague at NIST, Judah Levine, who is the most recent recipient of the I. I. Rabi Award.", "token2charspan": [[0, 3], [4, 9], [10, 16], [17, 20], [21, 25], [26, 31], [32, 36], [37, 39], [40, 45], [45, 47], [48, 54], [55, 64], [65, 67], [68, 72], [72, 73], [74, 79], [80, 86], [86, 87], [88, 91], [92, 94], [95, 98], [99, 103], [104, 110], [111, 120], [121, 123], [124, 127], [128, 129], [129, 130], [131, 132], [132, 133], [134, 138], [139, 144], [144, 145]]}
{"doc_key": "ai-dev-172", "ner": [[12, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "can", "be", "arranged", "in", "a", "2", "\u00d7", "2", "contingency", "table", "(", "confusion", "matrix", ")", ",", "conventionally", "with", "the", "test", "result", "on", "the", "vertical", "axis", "and", "the", "actual", "condition", "on", "the", "horizontal", "axis", "."], "sentence-detokenized": "These can be arranged in a 2 \u00d7 2 contingency table (confusion matrix), conventionally with the test result on the vertical axis and the actual condition on the horizontal axis.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 21], [22, 24], [25, 26], [27, 28], [29, 30], [31, 32], [33, 44], [45, 50], [51, 52], [52, 61], [62, 68], [68, 69], [69, 70], [71, 85], [86, 90], [91, 94], [95, 99], [100, 106], [107, 109], [110, 113], [114, 122], [123, 127], [128, 131], [132, 135], [136, 142], [143, 152], [153, 155], [156, 159], [160, 170], [171, 175], [175, 176]]}
{"doc_key": "ai-dev-173", "ner": [[0, 4, "product"], [8, 8, "product"], [10, 10, "product"], [12, 13, "product"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 8, 8, "part-of", "", false, false], [0, 4, 10, 10, "part-of", "", false, false], [0, 4, 12, 13, "part-of", "", false, false], [0, 4, 15, 17, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Apple", "'s", "iOS", "operating", "system", "used", "on", "the", "iPhone", ",", "iPad", "and", "iPod", "Touch", "uses", "VoiceOver", "speech", "synthesis", "accessibility", "."], "sentence-detokenized": "Apple's iOS operating system used on the iPhone, iPad and iPod Touch uses VoiceOver speech synthesis accessibility.", "token2charspan": [[0, 5], [5, 7], [8, 11], [12, 21], [22, 28], [29, 33], [34, 36], [37, 40], [41, 47], [47, 48], [49, 53], [54, 57], [58, 62], [63, 68], [69, 73], [74, 83], [84, 90], [91, 100], [101, 114], [114, 115]]}
{"doc_key": "ai-dev-174", "ner": [[7, 9, "conference"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "the", "best", "system", "entering", "MUC", "-", "7", "scored", "93.39", "%", "of", "the", "F", "-", "measure", ",", "while", "the", "human", "annotators", "scored", "97.6", "%", "and", "96.95", "%", "."], "sentence-detokenized": "For example, the best system entering MUC-7 scored 93.39% of the F-measure, while the human annotators scored 97.6% and 96.95%.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 37], [38, 41], [41, 42], [42, 43], [44, 50], [51, 56], [56, 57], [58, 60], [61, 64], [65, 66], [66, 67], [67, 74], [74, 75], [76, 81], [82, 85], [86, 91], [92, 102], [103, 109], [110, 114], [114, 115], [116, 119], [120, 125], [125, 126], [126, 127]]}
{"doc_key": "ai-dev-175", "ner": [[8, 10, "algorithm"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 8, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Standard", "neural", "network", "training", "algorithms", ",", "such", "as", "stochastic", "gradient", "descent", "with", "backpropagation", ",", "are", "used", "for", "this", "purpose", "."], "sentence-detokenized": "Standard neural network training algorithms, such as stochastic gradient descent with backpropagation, are used for this purpose.", "token2charspan": [[0, 8], [9, 15], [16, 23], [24, 32], [33, 43], [43, 44], [45, 49], [50, 52], [53, 63], [64, 72], [73, 80], [81, 85], [86, 101], [101, 102], [103, 106], [107, 111], [112, 115], [116, 120], [121, 128], [128, 129]]}
{"doc_key": "ai-dev-176", "ner": [[0, 1, "organisation"], [18, 19, "country"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 18, 19, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Rotten", "Tomatoes", "is", "a", "top", "1000", "website", ",", "ranking", "400th", "worldwide", "and", "in", "the", "top", "150", "in", "the", "United", "States", ",", "according", "to", "the", "Alexa", "website", "rankings", "."], "sentence-detokenized": "Rotten Tomatoes is a top 1000 website, ranking 400th worldwide and in the top 150 in the United States, according to the Alexa website rankings.", "token2charspan": [[0, 6], [7, 15], [16, 18], [19, 20], [21, 24], [25, 29], [30, 37], [37, 38], [39, 46], [47, 52], [53, 62], [63, 66], [67, 69], [70, 73], [74, 77], [78, 81], [82, 84], [85, 88], [89, 95], [96, 102], [102, 103], [104, 113], [114, 116], [117, 120], [121, 126], [127, 134], [135, 143], [143, 144]]}
{"doc_key": "ai-dev-177", "ner": [[15, 16, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "general", ",", "all", "learning", "shows", "an", "incremental", "change", "over", "time", ",", "but", "describes", "a", "sigmoidal", "function", "that", "has", "different", "appearances", "depending", "on", "the", "time", "scale", "of", "observation", "."], "sentence-detokenized": "In general, all learning shows an incremental change over time, but describes a sigmoidal function that has different appearances depending on the time scale of observation.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 24], [25, 30], [31, 33], [34, 45], [46, 52], [53, 57], [58, 62], [62, 63], [64, 67], [68, 77], [78, 79], [80, 89], [90, 98], [99, 103], [104, 107], [108, 117], [118, 129], [130, 139], [140, 142], [143, 146], [147, 151], [152, 157], [158, 160], [161, 172], [172, 173]]}
{"doc_key": "ai-dev-178", "ner": [[1, 1, "metrics"], [7, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 7, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "SSD", "is", "also", "known", "as", "the", "root", "mean", "square", "error", "."], "sentence-detokenized": "The SSD is also known as the root mean square error.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 15], [16, 21], [22, 24], [25, 28], [29, 33], [34, 38], [39, 45], [46, 51], [51, 52]]}
{"doc_key": "ai-dev-179", "ner": [[0, 2, "algorithm"], [4, 5, "algorithm"], [8, 10, "algorithm"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 24, 25, "related-to", "can_be_related_to", true, false], [4, 5, 24, 25, "related-to", "can_be_related_to", true, false], [8, 10, 24, 25, "related-to", "can_be_related_to", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", ",", "neural", "networks", "or", "a", "naive", "Bayes", "classifier", "could", "be", "used", "in", "combination", "with", "measures", "of", "model", "quality", ",", "such", "as", "balanced", "accuracy", "."], "sentence-detokenized": "Decision tree learning, neural networks or a naive Bayes classifier could be used in combination with measures of model quality, such as balanced accuracy.", "token2charspan": [[0, 8], [9, 13], [14, 22], [22, 23], [24, 30], [31, 39], [40, 42], [43, 44], [45, 50], [51, 56], [57, 67], [68, 73], [74, 76], [77, 81], [82, 84], [85, 96], [97, 101], [102, 110], [111, 113], [114, 119], [120, 127], [127, 128], [129, 133], [134, 136], [137, 145], [146, 154], [154, 155]]}
{"doc_key": "ai-dev-180", "ner": [[15, 16, "conference"], [22, 26, "conference"], [27, 29, "misc"], [35, 37, "product"], [44, 47, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[27, 29, 22, 26, "origin", "", false, false], [27, 29, 22, 26, "temporal", "", false, false], [35, 37, 27, 29, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "is", "a", "past", "president", "(", "1979", ")", "and", "inaugural", "member", "(", "2011", ")", "of", "the", "ACL", ",", "a", "recipient", "of", "the", "1992", "Association", "for", "Computing", "Machinery", "Software", "Systems", "Award", "for", "his", "contribution", "to", "the", "Interlisp", "programming", "system", ",", "and", "a", "Fellow", "of", "the", "Association", "for", "Computing", "Machinery", "."], "sentence-detokenized": "He is a past president (1979) and inaugural member (2011) of the ACL, a recipient of the 1992 Association for Computing Machinery Software Systems Award for his contribution to the Interlisp programming system, and a Fellow of the Association for Computing Machinery.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 22], [23, 24], [24, 28], [28, 29], [30, 33], [34, 43], [44, 50], [51, 52], [52, 56], [56, 57], [58, 60], [61, 64], [65, 68], [68, 69], [70, 71], [72, 81], [82, 84], [85, 88], [89, 93], [94, 105], [106, 109], [110, 119], [120, 129], [130, 138], [139, 146], [147, 152], [153, 156], [157, 160], [161, 173], [174, 176], [177, 180], [181, 190], [191, 202], [203, 209], [209, 210], [211, 214], [215, 216], [217, 223], [224, 226], [227, 230], [231, 242], [243, 246], [247, 256], [257, 266], [266, 267]]}
{"doc_key": "ai-dev-181", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 9, "researcher"], [12, 15, "researcher"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 27, 28, "related-to", "", false, false], [5, 6, 27, 28, "related-to", "", false, false], [8, 9, 27, 28, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "is", "considered", "by", "Cade", "Metz", "to", "be", "one", "of", "the", "three", "people", "most", "responsible", "for", "the", "breakthrough", "in", "deep", "learning", "during", "the", "1990s", "and", "2000s", "."], "sentence-detokenized": "Along with Geoffrey Hinton and Yann LeCun, Bengio is considered by Cade Metz to be one of the three people most responsible for the breakthrough in deep learning during the 1990s and 2000s.", "token2charspan": [[0, 5], [6, 10], [11, 19], [20, 26], [27, 30], [31, 35], [36, 41], [41, 42], [43, 49], [50, 52], [53, 63], [64, 66], [67, 71], [72, 76], [77, 79], [80, 82], [83, 86], [87, 89], [90, 93], [94, 99], [100, 106], [107, 111], [112, 123], [124, 127], [128, 131], [132, 144], [145, 147], [148, 152], [153, 161], [162, 168], [169, 172], [173, 178], [179, 182], [183, 188], [188, 189]]}
{"doc_key": "ai-dev-182", "ner": [[1, 2, "field"], [4, 5, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "information", "theory", "and", "computer", "science", ",", "a", "code", "is", "usually", "thought", "of", "as", "an", "algorithm", "that", "uniquely", "represents", "symbols", "from", "some", "source", "alphabet", "by", "means", "of", "encoded", "strings", ",", "which", "may", "be", "in", "some", "other", "target", "alphabet", "."], "sentence-detokenized": "In information theory and computer science, a code is usually thought of as an algorithm that uniquely represents symbols from some source alphabet by means of encoded strings, which may be in some other target alphabet.", "token2charspan": [[0, 2], [3, 14], [15, 21], [22, 25], [26, 34], [35, 42], [42, 43], [44, 45], [46, 50], [51, 53], [54, 61], [62, 69], [70, 72], [73, 75], [76, 78], [79, 88], [89, 93], [94, 102], [103, 113], [114, 121], [122, 126], [127, 131], [132, 138], [139, 147], [148, 150], [151, 156], [157, 159], [160, 167], [168, 175], [175, 176], [177, 182], [183, 186], [187, 189], [190, 192], [193, 197], [198, 203], [204, 210], [211, 219], [219, 220]]}
{"doc_key": "ai-dev-183", "ner": [[8, 9, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 8, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "fairly", "simple", "non", "-linear", "function", ",", "the", "sigmoid", "function", ",", "like", "the", "logistic", "function", ",", "also", "has", "an", "easy", "-", "to", "-", "calculate", "derivative", ",", "which", "can", "be", "important", "when", "calculating", "weight", "updates", "in", "the", "network", "."], "sentence-detokenized": "A fairly simple non-linear function, the sigmoid function, like the logistic function, also has an easy-to-calculate derivative, which can be important when calculating weight updates in the network.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 19], [19, 26], [27, 35], [35, 36], [37, 40], [41, 48], [49, 57], [57, 58], [59, 63], [64, 67], [68, 76], [77, 85], [85, 86], [87, 91], [92, 95], [96, 98], [99, 103], [103, 104], [104, 106], [106, 107], [107, 116], [117, 127], [127, 128], [129, 134], [135, 138], [139, 141], [142, 151], [152, 156], [157, 168], [169, 175], [176, 183], [184, 186], [187, 190], [191, 198], [198, 199]]}
{"doc_key": "ai-dev-184", "ner": [[0, 0, "person"], [4, 4, "location"], [6, 6, "location"], [8, 10, "country"], [13, 13, "country"], [16, 17, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 4, 4, "physical", "", false, false], [4, 4, 6, 6, "physical", "", false, false], [6, 6, 8, 10, "physical", "", false, false], [6, 6, 13, 13, "physical", "", false, false], [6, 6, 16, 17, "physical", "", false, false], [13, 13, 8, 10, "origin", "", false, false], [16, 17, 13, 13, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["\u010capek", "was", "born", "in", "Hronov", ",", "Bohemia", "(", "Austria", "-", "Hungary", ",", "later", "Czechoslovakia", ",", "now", "Czech", "Republic", ")", "in", "1887", "."], "sentence-detokenized": "\u010capek was born in Hronov, Bohemia (Austria-Hungary, later Czechoslovakia, now Czech Republic) in 1887.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 17], [18, 24], [24, 25], [26, 33], [34, 35], [35, 42], [42, 43], [43, 50], [50, 51], [52, 57], [58, 72], [72, 73], [74, 77], [78, 83], [84, 92], [92, 93], [94, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-dev-185", "ner": [[5, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "specialised", "software", "can", "narrate", "RSS", "."], "sentence-detokenized": "Some specialised software can narrate RSS.", "token2charspan": [[0, 4], [5, 16], [17, 25], [26, 29], [30, 37], [38, 41], [41, 42]]}
{"doc_key": "ai-dev-186", "ner": [[6, 7, "task"], [11, 12, "task"], [14, 14, "task"], [17, 17, "task"], [21, 21, "task"], [29, 29, "task"], [32, 33, "task"], [38, 39, "task"], [42, 44, "product"], [46, 47, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[6, 7, 11, 12, "related-to", "", true, false], [6, 7, 14, 14, "related-to", "", true, false], [6, 7, 17, 17, "related-to", "", true, false], [32, 33, 29, 29, "usage", "", true, false], [42, 44, 38, 39, "type-of", "", false, false], [46, 47, 38, 39, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Aspects", "of", "ontology", "editors", "include", ":", "visual", "navigation", "possibilities", "within", "the", "knowledge", "model", ",", "inference", "engines", "and", "extraction", ";", "support", "for", "modules", ";", "import", "and", "export", "of", "foreign", "knowledge", "representation", "languages", "for", "ontology", "matching", ";", "and", "support", "for", "meta", "-ontologies", "such", "as", "OWL", "-", "S", ",", "Dublin", "Core", ",", "etc", "."], "sentence-detokenized": "Aspects of ontology editors include: visual navigation possibilities within the knowledge model, inference engines and extraction; support for modules; import and export of foreign knowledge representation languages for ontology matching; and support for meta-ontologies such as OWL-S, Dublin Core, etc.", "token2charspan": [[0, 7], [8, 10], [11, 19], [20, 27], [28, 35], [35, 36], [37, 43], [44, 54], [55, 68], [69, 75], [76, 79], [80, 89], [90, 95], [95, 96], [97, 106], [107, 114], [115, 118], [119, 129], [129, 130], [131, 138], [139, 142], [143, 150], [150, 151], [152, 158], [159, 162], [163, 169], [170, 172], [173, 180], [181, 190], [191, 205], [206, 215], [216, 219], [220, 228], [229, 237], [237, 238], [239, 242], [243, 250], [251, 254], [255, 259], [259, 270], [271, 275], [276, 278], [279, 282], [282, 283], [283, 284], [284, 285], [286, 292], [293, 297], [297, 298], [299, 302], [302, 303]]}
{"doc_key": "ai-dev-187", "ner": [[1, 1, "organisation"], [6, 10, "misc"], [13, 16, "task"], [20, 21, "field"], [25, 25, "misc"], [27, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 10, 1, 1, "origin", "", false, false], [13, 16, 6, 10, "part-of", "", false, false], [20, 21, 6, 10, "part-of", "", false, false], [25, 25, 20, 21, "type-of", "", false, false], [27, 28, 20, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "FBI", "has", "also", "launched", "its", "next", "-", "generation", "identification", "programme", "to", "include", "facial", "recognition", "in", "addition", "to", "more", "traditional", "biometric", "data", ",", "such", "as", "fingerprints", "and", "iris", "scans", ",", "which", "can", "be", "extracted", "from", "criminal", "and", "civil", "databases", "."], "sentence-detokenized": "The FBI has also launched its next-generation identification programme to include facial recognition in addition to more traditional biometric data, such as fingerprints and iris scans, which can be extracted from criminal and civil databases.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 16], [17, 25], [26, 29], [30, 34], [34, 35], [35, 45], [46, 60], [61, 70], [71, 73], [74, 81], [82, 88], [89, 100], [101, 103], [104, 112], [113, 115], [116, 120], [121, 132], [133, 142], [143, 147], [147, 148], [149, 153], [154, 156], [157, 169], [170, 173], [174, 178], [179, 184], [184, 185], [186, 191], [192, 195], [196, 198], [199, 208], [209, 213], [214, 222], [223, 226], [227, 232], [233, 242], [242, 243]]}
{"doc_key": "ai-dev-188", "ner": [[5, 6, "person"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "the", "2016", "season", ",", "Samantha", "Ponder", "was", "added", "as", "host", ",", "replacing", "Molly", "McGrath", "."], "sentence-detokenized": "For the 2016 season, Samantha Ponder was added as host, replacing Molly McGrath.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 19], [19, 20], [21, 29], [30, 36], [37, 40], [41, 46], [47, 49], [50, 54], [54, 55], [56, 65], [66, 71], [72, 79], [79, 80]]}
{"doc_key": "ai-dev-189", "ner": [[3, 5, "algorithm"], [18, 22, "misc"], [24, 24, "misc"], [26, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "adversarial", "search", "algorithm", "that", "is", "commonly", "used", "to", "play", "two", "-", "player", "machine", "games", "(", "tic", "-", "tac", "-", "toe", ",", "chess", ",", "go", ",", "etc.", ")", "."], "sentence-detokenized": "This is an adversarial search algorithm that is commonly used to play two-player machine games (tic-tac-toe, chess, go, etc.).", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 29], [30, 39], [40, 44], [45, 47], [48, 56], [57, 61], [62, 64], [65, 69], [70, 73], [73, 74], [74, 80], [81, 88], [89, 94], [95, 96], [96, 99], [99, 100], [100, 103], [103, 104], [104, 107], [107, 108], [109, 114], [114, 115], [116, 118], [118, 119], [120, 124], [124, 125], [125, 126]]}
{"doc_key": "ai-dev-190", "ner": [[6, 7, "field"], [9, 10, "field"], [17, 18, "field"], [20, 21, "field"], [23, 24, "field"]], "ner_mapping_to_source": [0, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "in", "the", "fields", "of", "computer", "vision", "and", "medical", "imaging", ",", "and", "makes", "intensive", "use", "of", "pattern", "recognition", ",", "digital", "geometry", "and", "signal", "processing", "."], "sentence-detokenized": "It is in the fields of computer vision and medical imaging, and makes intensive use of pattern recognition, digital geometry and signal processing.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 12], [13, 19], [20, 22], [23, 31], [32, 38], [39, 42], [43, 50], [51, 58], [58, 59], [60, 63], [64, 69], [70, 79], [80, 83], [84, 86], [87, 94], [95, 106], [106, 107], [108, 115], [116, 124], [125, 128], [129, 135], [136, 146], [146, 147]]}
{"doc_key": "ai-dev-191", "ner": [[2, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "a", "facial", "recognition", "system", ",", "for", "example", ",", "the", "image", "of", "a", "person", "'s", "face", "would", "be", "the", "input", ",", "and", "the", "output", "tag", "would", "be", "that", "person", "'s", "name", "."], "sentence-detokenized": "In a facial recognition system, for example, the image of a person's face would be the input, and the output tag would be that person's name.", "token2charspan": [[0, 2], [3, 4], [5, 11], [12, 23], [24, 30], [30, 31], [32, 35], [36, 43], [43, 44], [45, 48], [49, 54], [55, 57], [58, 59], [60, 66], [66, 68], [69, 73], [74, 79], [80, 82], [83, 86], [87, 92], [92, 93], [94, 97], [98, 101], [102, 108], [109, 112], [113, 118], [119, 121], [122, 126], [127, 133], [133, 135], [136, 140], [140, 141]]}
{"doc_key": "ai-dev-192", "ner": [[0, 1, "organisation"], [3, 4, "product"], [8, 10, "product"], [15, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 3, 4, "artifact", "", false, false], [3, 4, 8, 10, "part-of", "", false, false], [8, 10, 3, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Apple", "Inc", "introduced", "Face", "ID", "on", "the", "flagship", "i", "Phone", "X", "as", "the", "successor", "to", "Touch", "ID", "biometric", "authentication", ",", "a", "fingerprint", "-", "based", "system", "."], "sentence-detokenized": "Apple Inc introduced Face ID on the flagship iPhone X as the successor to Touch ID biometric authentication, a fingerprint-based system.", "token2charspan": [[0, 5], [6, 9], [10, 20], [21, 25], [26, 28], [29, 31], [32, 35], [36, 44], [45, 46], [46, 51], [52, 53], [54, 56], [57, 60], [61, 70], [71, 73], [74, 79], [80, 82], [83, 92], [93, 107], [107, 108], [109, 110], [111, 122], [122, 123], [123, 128], [129, 135], [135, 136]]}
{"doc_key": "ai-dev-193", "ner": [[3, 5, "metrics"], [8, 9, "metrics"], [22, 25, "metrics"], [28, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Or", "combine", "the", "F", "-", "measure", "with", "the", "R-", "squared", "evaluated", "for", "the", "raw", "model", "output", "and", "the", "target", ";", "or", "the", "cost", "/", "profit", "matrix", "with", "the", "correlation", "coefficient", ",", "etc", "."], "sentence-detokenized": "Or combine the F-measure with the R-squared evaluated for the raw model output and the target; or the cost/profit matrix with the correlation coefficient, etc.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 16], [16, 17], [17, 24], [25, 29], [30, 33], [34, 36], [36, 43], [44, 53], [54, 57], [58, 61], [62, 65], [66, 71], [72, 78], [79, 82], [83, 86], [87, 93], [93, 94], [95, 97], [98, 101], [102, 106], [106, 107], [107, 113], [114, 120], [121, 125], [126, 129], [130, 141], [142, 153], [153, 154], [155, 158], [158, 159]]}
{"doc_key": "ai-dev-194", "ner": [[1, 5, "conference"], [11, 13, "location"], [15, 15, "location"], [20, 23, "location"], [26, 26, "location"], [28, 28, "country"], [34, 38, "location"], [41, 47, "location"], [49, 51, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[1, 5, 11, 13, "physical", "", false, false], [1, 5, 20, 23, "physical", "", false, false], [1, 5, 34, 38, "physical", "", false, false], [1, 5, 41, 47, "physical", "", false, false], [11, 13, 15, 15, "physical", "", false, false], [20, 23, 26, 26, "physical", "", false, false], [26, 26, 28, 28, "physical", "", false, false], [34, 38, 49, 51, "physical", "", false, false], [41, 47, 49, 51, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "Spanish", "edition", "of", "Campus", "Party", "has", "been", "held", "at", "the", "Miguel", "Hern\u00e1ndez", "School", ",", "Ceulaj", ",", "and", "at", "the", "Polideportivo", "Municipal", "de", "Benalm\u00e1dena", ",", "in", "M\u00e1laga", ",", "Spain", ";", "and", "at", "both", "the", "Feria", "del", "Condado", "de", "Valencia", "and", "the", "Ciudad", "de", "las", "Artes", "y", "las", "Ciencias", "de", "Valencia", "for", "the", "last", "15", "years", "."], "sentence-detokenized": "The Spanish edition of Campus Party has been held at the Miguel Hern\u00e1ndez School, Ceulaj, and at the Polideportivo Municipal de Benalm\u00e1dena, in M\u00e1laga, Spain; and at both the Feria del Condado de Valencia and the Ciudad de las Artes y las Ciencias de Valencia for the last 15 years.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 22], [23, 29], [30, 35], [36, 39], [40, 44], [45, 49], [50, 52], [53, 56], [57, 63], [64, 73], [74, 80], [80, 81], [82, 88], [88, 89], [90, 93], [94, 96], [97, 100], [101, 114], [115, 124], [125, 127], [128, 139], [139, 140], [141, 143], [144, 150], [150, 151], [152, 157], [157, 158], [159, 162], [163, 165], [166, 170], [171, 174], [175, 180], [181, 184], [185, 192], [193, 195], [196, 204], [205, 208], [209, 212], [213, 219], [220, 222], [223, 226], [227, 232], [233, 234], [235, 238], [239, 247], [248, 250], [251, 259], [260, 263], [264, 267], [268, 272], [273, 275], [276, 281], [281, 282]]}
{"doc_key": "ai-dev-195", "ner": [[0, 0, "product"], [13, 13, "programlang"], [17, 17, "product"], [19, 19, "product"], [23, 23, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 13, 0, 0, "general-affiliation", "", false, false], [17, 17, 13, 13, "part-of", "", false, false], [19, 19, 13, 13, "part-of", "", false, false], [23, 23, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["gnuplot", "can", "be", "used", "from", "various", "programming", "languages", "to", "plot", "data", ",", "including", "Perl", "(", "via", "the", "PDL", "and", "CPAN", "packages", ")", ",", "Python", "(", "via", ")", "."], "sentence-detokenized": "gnuplot can be used from various programming languages to plot data, including Perl (via the PDL and CPAN packages), Python (via).", "token2charspan": [[0, 7], [8, 11], [12, 14], [15, 19], [20, 24], [25, 32], [33, 44], [45, 54], [55, 57], [58, 62], [63, 67], [67, 68], [69, 78], [79, 83], [84, 85], [85, 88], [89, 92], [93, 96], [97, 100], [101, 105], [106, 114], [114, 115], [115, 116], [117, 123], [124, 125], [125, 128], [128, 129], [129, 130]]}
{"doc_key": "ai-dev-196", "ner": [[3, 5, "product"], [19, 19, "conference"], [21, 21, "conference"], [35, 35, "conference"], [37, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 19, 3, 5, "topic", "", false, false], [21, 21, 3, 5, "topic", "", false, false], [35, 35, 3, 5, "topic", "", false, false], [37, 37, 3, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "field", "of", "spoken", "dialogue", "systems", "is", "quite", "broad", "and", "includes", "research", "(", "present", "at", "scientific", "conferences", "such", "as", "SIGdial", "and", "Interspeech", ")", "and", "a", "large", "industrial", "sector", "(", "with", "its", "own", "meetings", "such", "as", "SpeechTek", "and", "AVIOS", ")", "."], "sentence-detokenized": "The field of spoken dialogue systems is quite broad and includes research (present at scientific conferences such as SIGdial and Interspeech) and a large industrial sector (with its own meetings such as SpeechTek and AVIOS).", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 28], [29, 36], [37, 39], [40, 45], [46, 51], [52, 55], [56, 64], [65, 73], [74, 75], [75, 82], [83, 85], [86, 96], [97, 108], [109, 113], [114, 116], [117, 124], [125, 128], [129, 140], [140, 141], [142, 145], [146, 147], [148, 153], [154, 164], [165, 171], [172, 173], [173, 177], [178, 181], [182, 185], [186, 194], [195, 199], [200, 202], [203, 212], [213, 216], [217, 222], [222, 223], [223, 224]]}
{"doc_key": "ai-dev-197", "ner": [[2, 4, "field"], [7, 8, "task"], [10, 14, "task"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 2, 4, "part-of", "task_part_of_field", false, false], [10, 14, 2, 4, "part-of", "task_part_of_field", false, false], [15, 16, 2, 4, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Challenges", "in", "natural", "language", "processing", "often", "include", "speech", "recognition", ",", "natural", "language", "understanding", "and", "natural", "language", "generation", "."], "sentence-detokenized": "Challenges in natural language processing often include speech recognition, natural language understanding and natural language generation.", "token2charspan": [[0, 10], [11, 13], [14, 21], [22, 30], [31, 41], [42, 47], [48, 55], [56, 62], [63, 74], [74, 75], [76, 83], [84, 92], [93, 106], [107, 110], [111, 118], [119, 127], [128, 138], [138, 139]]}
{"doc_key": "ai-dev-198", "ner": [[5, 5, "product"], [8, 10, "product"], [37, 38, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 8, 10, "part-of", "", false, false], [5, 5, 37, 38, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "such", "as", "Siri", "in", "the", "iOS", "operating", "system", ",", "work", "with", "a", "pattern", "recognition", "technique", "similar", "to", "that", "of", "text", "-", "based", "systems", ",", "but", "with", "the", "former", ",", "user", "input", "is", "done", "through", "voice", "recognition", "."], "sentence-detokenized": "These systems, such as Siri in the iOS operating system, work with a pattern recognition technique similar to that of text-based systems, but with the former, user input is done through voice recognition.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 22], [23, 27], [28, 30], [31, 34], [35, 38], [39, 48], [49, 55], [55, 56], [57, 61], [62, 66], [67, 68], [69, 76], [77, 88], [89, 98], [99, 106], [107, 109], [110, 114], [115, 117], [118, 122], [122, 123], [123, 128], [129, 136], [136, 137], [138, 141], [142, 146], [147, 150], [151, 157], [157, 158], [159, 163], [164, 169], [170, 172], [173, 177], [178, 185], [186, 191], [192, 203], [203, 204]]}
{"doc_key": "ai-dev-199", "ner": [[2, 4, "algorithm"], [17, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 4, 17, 18, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Other", "more", "exotic", "fitness", "functions", "that", "explore", "the", "granularity", "of", "the", "model", "include", "the", "area", "under", "the", "ROC", "curve", "and", "the", "rank", "measure", "."], "sentence-detokenized": "Other more exotic fitness functions that explore the granularity of the model include the area under the ROC curve and the rank measure.", "token2charspan": [[0, 5], [6, 10], [11, 17], [18, 25], [26, 35], [36, 40], [41, 48], [49, 52], [53, 64], [65, 67], [68, 71], [72, 77], [78, 85], [86, 89], [90, 94], [95, 100], [101, 104], [105, 108], [109, 114], [115, 118], [119, 122], [123, 127], [128, 135], [135, 136]]}
{"doc_key": "ai-dev-200", "ner": [[2, 3, "product"], [7, 10, "researcher"], [15, 17, "product"], [22, 25, "organisation"], [27, 27, "organisation"], [36, 40, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 7, 10, "origin", "", false, false], [7, 10, 22, 25, "role", "", false, false], [15, 17, 7, 10, "origin", "", false, false], [27, 27, 22, 25, "named", "", false, false], [36, 40, 22, 25, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "term", "semantic", "web", "was", "coined", "by", "Tim", "Berners", "-", "Lee", ",", "inventor", "of", "the", "World", "Wide", "Web", "and", "director", "of", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "which", "oversees", "the", "development", "of", "proposed", "standards", "for", "the", "semantic", "web", "."], "sentence-detokenized": "The term semantic web was coined by Tim Berners-Lee, inventor of the World Wide Web and director of the World Wide Web Consortium (W3C), which oversees the development of proposed standards for the semantic web.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 25], [26, 32], [33, 35], [36, 39], [40, 47], [47, 48], [48, 51], [51, 52], [53, 61], [62, 64], [65, 68], [69, 74], [75, 79], [80, 83], [84, 87], [88, 96], [97, 99], [100, 103], [104, 109], [110, 114], [115, 118], [119, 129], [130, 131], [131, 134], [134, 135], [135, 136], [137, 142], [143, 151], [152, 155], [156, 167], [168, 170], [171, 179], [180, 189], [190, 193], [194, 197], [198, 206], [207, 210], [210, 211]]}
{"doc_key": "ai-dev-201", "ner": [[0, 1, "task"], [9, 9, "task"], [16, 17, "product"], [19, 23, "product"], [25, 25, "product"], [28, 29, "product"], [36, 37, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 16, 17, "opposite", "", false, false], [0, 1, 19, 23, "opposite", "", false, false], [0, 1, 28, 29, "opposite", "", false, false], [0, 1, 36, 37, "part-of", "", false, false], [9, 9, 0, 1, "named", "", false, false], [25, 25, 19, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Machine", "translation", ",", "sometimes", "referred", "to", "by", "the", "abbreviation", "MT", "(", "not", "to", "be", "confused", "with", "computer-assisted", "translation", ",", "machine", "-", "assisted", "human", "translation", "(", "MAHT", ")", "or", "interactive", "translation", ")", ",", "is", "a", "subfield", "of", "computational", "linguistics", "that", "investigates", "the", "use", "of", "software", "to", "translate", "text", "or", "speech", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Machine translation, sometimes referred to by the abbreviation MT (not to be confused with computer-assisted translation, machine-assisted human translation (MAHT) or interactive translation), is a subfield of computational linguistics that investigates the use of software to translate text or speech from one language to another.", "token2charspan": [[0, 7], [8, 19], [19, 20], [21, 30], [31, 39], [40, 42], [43, 45], [46, 49], [50, 62], [63, 65], [66, 67], [67, 70], [71, 73], [74, 76], [77, 85], [86, 90], [91, 108], [109, 120], [120, 121], [122, 129], [129, 130], [130, 138], [139, 144], [145, 156], [157, 158], [158, 162], [162, 163], [164, 166], [167, 178], [179, 190], [190, 191], [191, 192], [193, 195], [196, 197], [198, 206], [207, 209], [210, 223], [224, 235], [236, 240], [241, 253], [254, 257], [258, 261], [262, 264], [265, 273], [274, 276], [277, 286], [287, 291], [292, 294], [295, 301], [302, 306], [307, 310], [311, 319], [320, 322], [323, 330], [330, 331]]}
{"doc_key": "ai-dev-202", "ner": [[2, 5, "product"], [10, 12, "university"], [15, 16, "researcher"], [18, 19, "researcher"], [44, 45, "location"], [43, 43, "location"], [49, 52, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 5, 15, 16, "artifact", "", false, false], [2, 5, 18, 19, "artifact", "", false, false], [15, 16, 10, 12, "physical", "", false, false], [15, 16, 10, 12, "role", "", false, false], [18, 19, 10, 12, "physical", "", false, false], [18, 19, 10, 12, "role", "", false, false], [44, 45, 43, 43, "physical", "", false, false], [49, 52, 44, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "first", "interlanguage", "machine", "translation", "systems", "were", "also", "built", "at", "Stanford", "in", "the", "1970s", "by", "Roger", "Schank", "and", "Yorick", "Wilks", ";", "the", "former", "became", "the", "basis", "for", "a", "commercial", "funds", "transfer", "system", ",", "and", "the", "code", "for", "the", "latter", "is", "preserved", "in", "the", "Boston", "Computer", "Museum", "as", "the", "first", "interlanguage", "machine", "translation", "system", "."], "sentence-detokenized": "The first interlanguage machine translation systems were also built at Stanford in the 1970s by Roger Schank and Yorick Wilks; the former became the basis for a commercial funds transfer system, and the code for the latter is preserved in the Boston Computer Museum as the first interlanguage machine translation system.", "token2charspan": [[0, 3], [4, 9], [10, 23], [24, 31], [32, 43], [44, 51], [52, 56], [57, 61], [62, 67], [68, 70], [71, 79], [80, 82], [83, 86], [87, 92], [93, 95], [96, 101], [102, 108], [109, 112], [113, 119], [120, 125], [125, 126], [127, 130], [131, 137], [138, 144], [145, 148], [149, 154], [155, 158], [159, 160], [161, 171], [172, 177], [178, 186], [187, 193], [193, 194], [195, 198], [199, 202], [203, 207], [208, 211], [212, 215], [216, 222], [223, 225], [226, 235], [236, 238], [239, 242], [243, 249], [250, 258], [259, 265], [266, 268], [269, 272], [273, 278], [279, 292], [293, 300], [301, 312], [313, 319], [319, 320]]}
{"doc_key": "ai-dev-203", "ner": [[0, 0, "researcher"], [6, 10, "conference"], [12, 13, "conference"], [20, 25, "conference"], [27, 28, "conference"], [34, 37, "organisation"], [42, 42, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 6, 10, "role", "", false, false], [0, 0, 20, 25, "role", "", false, false], [0, 0, 34, 37, "role", "", false, false], [0, 0, 42, 42, "role", "", false, false], [12, 13, 6, 10, "named", "", false, false], [27, 28, 20, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sycara", "was", "programme", "chair", "of", "the", "Second", "International", "Semantic", "Web", "Conference", "(", "ISWC", "2003", ")", ";", "general", "chair", "of", "the", "Second", "International", "Conference", "on", "Autonomous", "Agents", "(", "Agents", "98", ")", ";", "chair", "of", "the", "Agents", "Conference", "Steering", "Committee", "(", "1999-2001", ")", ";", "AAAI", "fellowship", "chair", "(", "1993-1999", ")", ";"], "sentence-detokenized": "Sycara was programme chair of the Second International Semantic Web Conference (ISWC 2003); general chair of the Second International Conference on Autonomous Agents (Agents 98); chair of the Agents Conference Steering Committee (1999-2001); AAAI fellowship chair (1993-1999);", "token2charspan": [[0, 6], [7, 10], [11, 20], [21, 26], [27, 29], [30, 33], [34, 40], [41, 54], [55, 63], [64, 67], [68, 78], [79, 80], [80, 84], [85, 89], [89, 90], [90, 91], [92, 99], [100, 105], [106, 108], [109, 112], [113, 119], [120, 133], [134, 144], [145, 147], [148, 158], [159, 165], [166, 167], [167, 173], [174, 176], [176, 177], [177, 178], [179, 184], [185, 187], [188, 191], [192, 198], [199, 209], [210, 218], [219, 228], [229, 230], [230, 239], [239, 240], [240, 241], [242, 246], [247, 257], [258, 263], [264, 265], [265, 274], [274, 275], [275, 276]]}
{"doc_key": "ai-dev-204", "ner": [[8, 8, "conference"], [10, 13, "conference"], [15, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 13, 8, 8, "named", "", false, false], [15, 17, 8, 8, "part-of", "", false, false], [15, 17, 8, 8, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2016", ",", "she", "was", "selected", "as", "an", "ACL", "(", "Association", "for", "Computational", "Linguistics", ")", "Lifetime", "Achievement", "Award", "winner", "."], "sentence-detokenized": "In 2016, she was selected as an ACL (Association for Computational Linguistics) Lifetime Achievement Award winner.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 25], [26, 28], [29, 31], [32, 35], [36, 37], [37, 48], [49, 52], [53, 66], [67, 78], [78, 79], [80, 88], [89, 100], [101, 106], [107, 113], [113, 114]]}
{"doc_key": "ai-dev-205", "ner": [[0, 1, "researcher"], [3, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", ",", "Y", ".", "Bengio", ",", "P.", "Frasconi", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Sepp Hochreiter, Y. Bengio, P. Frasconi and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 15], [15, 16], [17, 18], [18, 19], [20, 26], [26, 27], [28, 30], [31, 39], [40, 43], [44, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-206", "ner": [[3, 3, "product"], [6, 9, "misc"], [11, 11, "programlang"], [21, 22, "product"], [38, 38, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 11, 11, "usage", "", false, false], [11, 11, 6, 9, "type-of", "", false, false], [11, 11, 21, 22, "related-to", "", false, false], [38, 38, 3, 3, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["For", "example", ",", "A.L.I.C.E.", "uses", "a", "mark", "-", "up", "language", "called", "AIML", ",", "which", "is", "specific", "to", "its", "function", "as", "a", "dialogue", "system", ",", "and", "which", "has", "since", "been", "adopted", "by", "several", "other", "developers", "of", "so", "-", "called", "Alicebots", "."], "sentence-detokenized": "For example, A.L.I.C.E. uses a mark-up language called AIML, which is specific to its function as a dialogue system, and which has since been adopted by several other developers of so-called Alicebots.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 23], [24, 28], [29, 30], [31, 35], [35, 36], [36, 38], [39, 47], [48, 54], [55, 59], [59, 60], [61, 66], [67, 69], [70, 78], [79, 81], [82, 85], [86, 94], [95, 97], [98, 99], [100, 108], [109, 115], [115, 116], [117, 120], [121, 126], [127, 130], [131, 136], [137, 141], [142, 149], [150, 152], [153, 160], [161, 166], [167, 177], [178, 180], [181, 183], [183, 184], [184, 190], [191, 200], [200, 201]]}
{"doc_key": "ai-dev-207", "ner": [[9, 15, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2000", "she", "was", "elected", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2000 she was elected a member of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [98, 99]]}
{"doc_key": "ai-dev-208", "ner": [[0, 2, "misc"], [4, 4, "misc"], [10, 15, "misc"], [24, 25, "algorithm"], [34, 35, "field"], [37, 38, "field"], [40, 41, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 10, 15, "type-of", "", false, false], [0, 2, 34, 35, "related-to", "performs", true, false], [0, 2, 37, 38, "related-to", "performs", true, false], [0, 2, 40, 41, "related-to", "performs", true, false], [4, 4, 0, 2, "named", "", false, false], [24, 25, 10, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Learning", "classifier", "systems", "(", "LCS", ")", "are", "a", "family", "of", "rule", "-", "based", "machine", "learning", "algorithms", "that", "combine", "a", "discovery", "component", ",", "typically", "a", "genetic", "algorithm", ",", "with", "a", "learning", "component", ",", "which", "performs", "supervised", "learning", ",", "reinforcement", "learning", "or", "unsupervised", "learning", "."], "sentence-detokenized": "Learning classifier systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, typically a genetic algorithm, with a learning component, which performs supervised learning, reinforcement learning or unsupervised learning.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 29], [29, 32], [32, 33], [34, 37], [38, 39], [40, 46], [47, 49], [50, 54], [54, 55], [55, 60], [61, 68], [69, 77], [78, 88], [89, 93], [94, 101], [102, 103], [104, 113], [114, 123], [123, 124], [125, 134], [135, 136], [137, 144], [145, 154], [154, 155], [156, 160], [161, 162], [163, 171], [172, 181], [181, 182], [183, 188], [189, 197], [198, 208], [209, 217], [217, 218], [219, 232], [233, 241], [242, 244], [245, 257], [258, 266], [266, 267]]}
{"doc_key": "ai-dev-209", "ner": [[14, 16, "algorithm"], [19, 19, "algorithm"], [27, 28, "algorithm"], [31, 31, "misc"], [42, 44, "algorithm"], [52, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 16, 27, 28, "origin", "", false, false], [14, 16, 31, 31, "usage", "", false, false], [19, 19, 14, 16, "named", "", false, false], [42, 44, 31, 31, "type-of", "", false, false], [42, 44, 52, 55, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "unknown", "parameters", "in", "each", "\u03b2subk", "/", "sub", "vector", "are", "usually", "estimated", "jointly", "by", "maximum", "a", "posteriori", "estimation", "(", "MAP", ")", ",", "which", "is", "an", "extension", "of", "maximum", "likelihood", "that", "uses", "regularisation", "of", "the", "weights", "to", "avoid", "pathological", "solutions", "(", "usually", "a", "squared", "regularising", "function", ",", "which", "is", "equivalent", "to", "placing", "a", "zero-mean", "Gaussian", "prior", "distribution", "on", "the", "weights", ",", "but", "other", "distributions", "are", "also", "possible", ")", "."], "sentence-detokenized": "The unknown parameters in each \u03b2subk / sub vector are usually estimated jointly by maximum a posteriori estimation (MAP), which is an extension of maximum likelihood that uses regularisation of the weights to avoid pathological solutions (usually a squared regularising function, which is equivalent to placing a zero-mean Gaussian prior distribution on the weights, but other distributions are also possible).", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 25], [26, 30], [31, 36], [37, 38], [39, 42], [43, 49], [50, 53], [54, 61], [62, 71], [72, 79], [80, 82], [83, 90], [91, 92], [93, 103], [104, 114], [115, 116], [116, 119], [119, 120], [120, 121], [122, 127], [128, 130], [131, 133], [134, 143], [144, 146], [147, 154], [155, 165], [166, 170], [171, 175], [176, 190], [191, 193], [194, 197], [198, 205], [206, 208], [209, 214], [215, 227], [228, 237], [238, 239], [239, 246], [247, 248], [249, 256], [257, 269], [270, 278], [278, 279], [280, 285], [286, 288], [289, 299], [300, 302], [303, 310], [311, 312], [313, 322], [323, 331], [332, 337], [338, 350], [351, 353], [354, 357], [358, 365], [365, 366], [367, 370], [371, 376], [377, 390], [391, 394], [395, 399], [400, 408], [408, 409], [409, 410]]}
{"doc_key": "ai-dev-210", "ner": [[10, 11, "researcher"], [13, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 13, 10, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "hierarchical", "structure", "of", "words", "has", "been", "explicitly", "mapped", "in", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "The hierarchical structure of words has been explicitly mapped in George Miller's Wordnet.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 29], [30, 35], [36, 39], [40, 44], [45, 55], [56, 62], [63, 65], [66, 72], [73, 79], [79, 81], [82, 89], [89, 90]]}
{"doc_key": "ai-dev-211", "ner": [[7, 14, "conference"], [21, 24, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[21, 24, 7, 14, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "example", "of", "its", "capabilities", "is", "the", "large", "-", "scale", "visual", "recognition", "challenge", "of", "ImageNet", ";", "it", "is", "a", "benchmark", "in", "object", "classification", "and", "detection", ",", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "An example of its capabilities is the large-scale visual recognition challenge of ImageNet; it is a benchmark in object classification and detection, with millions of images and hundreds of object classes.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 17], [18, 30], [31, 33], [34, 37], [38, 43], [43, 44], [44, 49], [50, 56], [57, 68], [69, 78], [79, 81], [82, 90], [90, 91], [92, 94], [95, 97], [98, 99], [100, 109], [110, 112], [113, 119], [120, 134], [135, 138], [139, 148], [148, 149], [150, 154], [155, 163], [164, 166], [167, 173], [174, 177], [178, 186], [187, 189], [190, 196], [197, 204], [204, 205]]}
{"doc_key": "ai-dev-212", "ner": [[1, 2, "misc"], [25, 25, "misc"], [27, 29, "person"], [32, 32, "misc"], [37, 38, "person"], [43, 45, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[25, 25, 1, 2, "general-affiliation", "", false, false], [32, 32, 1, 2, "general-affiliation", "", false, false], [32, 32, 27, 29, "artifact", "", false, false], [43, 45, 1, 2, "general-affiliation", "", false, false], [43, 45, 37, 38, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "science", "fiction", ",", "female", "-", "looking", "robots", "are", "often", "produced", "for", "use", "as", "domestic", "servants", "and", "sex", "slaves", ",", "as", "seen", "in", "the", "film", "Westworld", ",", "Paul", "J.", "McAuley", "'s", "novel", "Fairyland", "(", "1995", ")", "and", "Lester", "del", "Rey", "'s", "short", "story", "Helen", "O'", "Loy", "(", "1938", ")", ",", "and", "sometimes", "as", "warriors", ",", "assassins", "or", "labourers", "."], "sentence-detokenized": "In science fiction, female-looking robots are often produced for use as domestic servants and sex slaves, as seen in the film Westworld, Paul J. McAuley's novel Fairyland (1995) and Lester del Rey's short story Helen O'Loy (1938), and sometimes as warriors, assassins or labourers.", "token2charspan": [[0, 2], [3, 10], [11, 18], [18, 19], [20, 26], [26, 27], [27, 34], [35, 41], [42, 45], [46, 51], [52, 60], [61, 64], [65, 68], [69, 71], [72, 80], [81, 89], [90, 93], [94, 97], [98, 104], [104, 105], [106, 108], [109, 113], [114, 116], [117, 120], [121, 125], [126, 135], [135, 136], [137, 141], [142, 144], [145, 152], [152, 154], [155, 160], [161, 170], [171, 172], [172, 176], [176, 177], [178, 181], [182, 188], [189, 192], [193, 196], [196, 198], [199, 204], [205, 210], [211, 216], [217, 219], [219, 222], [223, 224], [224, 228], [228, 229], [229, 230], [231, 234], [235, 244], [245, 247], [248, 256], [256, 257], [258, 267], [268, 270], [271, 280], [280, 281]]}
{"doc_key": "ai-dev-213", "ner": [[0, 1, "task"], [3, 4, "task"], [6, 7, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["question", "answering", ",", "voice", "recognition", "and", "automatic", "translation", "."], "sentence-detokenized": "question answering, voice recognition and automatic translation.", "token2charspan": [[0, 8], [9, 18], [18, 19], [20, 25], [26, 37], [38, 41], [42, 51], [52, 63], [63, 64]]}
{"doc_key": "ai-dev-214", "ner": [[5, 6, "researcher"], [9, 13, "organisation"], [15, 18, "location"], [20, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 9, 13, "role", "", false, false], [9, 13, 15, 18, "physical", "", false, false], [15, 18, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "his", "seminal", "paper", ",", "Harry", "Blum", "of", "the", "Cambridge", "Air", "Force", "Research", "Laboratories", "at", "Hanscom", "Air", "Force", "Base", ",", "Bedford", ",", "Massachusetts", ",", "defined", "a", "medial", "axis", "to", "calculate", "the", "skeleton", "of", "a", "shape", ",", "using", "an", "intuitive", "model", "of", "fire", "propagation", "in", "a", "grass", "field", ",", "where", "the", "field", "has", "the", "shape", "of", "the", "given", "shape", "."], "sentence-detokenized": "In his seminal paper, Harry Blum of the Cambridge Air Force Research Laboratories at Hanscom Air Force Base, Bedford, Massachusetts, defined a medial axis to calculate the skeleton of a shape, using an intuitive model of fire propagation in a grass field, where the field has the shape of the given shape.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 20], [20, 21], [22, 27], [28, 32], [33, 35], [36, 39], [40, 49], [50, 53], [54, 59], [60, 68], [69, 81], [82, 84], [85, 92], [93, 96], [97, 102], [103, 107], [107, 108], [109, 116], [116, 117], [118, 131], [131, 132], [133, 140], [141, 142], [143, 149], [150, 154], [155, 157], [158, 167], [168, 171], [172, 180], [181, 183], [184, 185], [186, 191], [191, 192], [193, 198], [199, 201], [202, 211], [212, 217], [218, 220], [221, 225], [226, 237], [238, 240], [241, 242], [243, 248], [249, 254], [254, 255], [256, 261], [262, 265], [266, 271], [272, 275], [276, 279], [280, 285], [286, 288], [289, 292], [293, 298], [299, 304], [304, 305]]}
{"doc_key": "ai-dev-215", "ner": [[14, 14, "algorithm"], [16, 16, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 19, 20, "compare", "", false, false], [16, 16, 19, 20, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "unlike", "boosting", "algorithms", "that", "analytically", "minimise", "a", "convex", "loss", "function", "(", "e.g.", "AdaBoost", "and", "LogitBoost", ")", ",", "Brown", "Boost", "solves", "a", "system", "of", "two", "equations", "and", "two", "unknowns", "using", "standard", "numerical", "methods", "."], "sentence-detokenized": "However, unlike boosting algorithms that analytically minimise a convex loss function (e.g. AdaBoost and LogitBoost), BrownBoost solves a system of two equations and two unknowns using standard numerical methods.", "token2charspan": [[0, 7], [7, 8], [9, 15], [16, 24], [25, 35], [36, 40], [41, 53], [54, 62], [63, 64], [65, 71], [72, 76], [77, 85], [86, 87], [87, 91], [92, 100], [101, 104], [105, 115], [115, 116], [116, 117], [118, 123], [123, 128], [129, 135], [136, 137], [138, 144], [145, 147], [148, 151], [152, 161], [162, 165], [166, 169], [170, 178], [179, 184], [185, 193], [194, 203], [204, 211], [211, 212]]}
{"doc_key": "ai-dev-216", "ner": [[0, 0, "researcher"], [9, 11, "misc"], [18, 24, "conference"], [26, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 9, 11, "win-defeat", "", false, false], [0, 0, 18, 24, "role", "", false, false], [26, 26, 18, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Getoor", "has", "received", "several", "best", "paper", "awards", ",", "an", "NSF", "career", "award", "and", "is", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Getoor has received several best paper awards, an NSF career award and is a member of the Association for the Advancement of Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 27], [28, 32], [33, 38], [39, 45], [45, 46], [47, 49], [50, 53], [54, 60], [61, 66], [67, 70], [71, 73], [74, 75], [76, 82], [83, 85], [86, 89], [90, 101], [102, 105], [106, 109], [110, 121], [122, 124], [125, 135], [136, 148], [149, 150], [150, 154], [154, 155], [155, 156]]}
{"doc_key": "ai-dev-217", "ner": [[0, 3, "misc"], [8, 14, "misc"], [19, 22, "misc"], [27, 33, "misc"], [38, 39, "misc"], [43, 47, "university"], [52, 58, "misc"], [63, 99, "misc"], [77, 104, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Member", "of", "the", "ACM", "(", "2015", ")", "br", "Member", "of", "the", "Association", "for", "Computational", "Linguistics", "(", "2011", ")", "br", "Member", "of", "the", "AAAI", "(", "1994", ")", "br", "Member", "of", "the", "International", "Speech", "Communication", "Association", "(", "2011", ")", "br", "Honorary", "Doctorate", "(", "Hedersdoktor", ")", "KTH", "Royal", "Institute", "of", "Technology", "(", "2007", ")", "br", "Columbia", "School", "of", "Engineering", "Distinguished", "Teaching", "Award", "(", "2009", ")", "br", "IEEE", "James", "L.", "Flanagan", "Award", "for", "Speech", "and", "Audio", "Processing", "(", "2011", ")", "br", "ISCA", "Medal", "for", "Scientific", "Achievement", "(", "2011", ")", "br", "IEEE", "James", "L.", "Flanagan", "Award", "for", "Speech", "and", "Audio", "Processing", "(", "2011", ")", "br", "ISCA", "Medal", "for", "Scientific", "Achievement", "(", "2011", ")"], "sentence-detokenized": "Member of the ACM (2015) br Member of the Association for Computational Linguistics (2011) br Member of the AAAI (1994) br Member of the International Speech Communication Association (2011) br Honorary Doctorate (Hedersdoktor) KTH Royal Institute of Technology (2007) br Columbia School of Engineering Distinguished Teaching Award (2009) br IEEE James L. Flanagan Award for Speech and Audio Processing (2011) br ISCA Medal for Scientific Achievement (2011) br IEEE James L. Flanagan Award for Speech and Audio Processing (2011) br ISCA Medal for Scientific Achievement (2011)", "token2charspan": [[0, 6], [7, 9], [10, 13], [14, 17], [18, 19], [19, 23], [23, 24], [25, 27], [28, 34], [35, 37], [38, 41], [42, 53], [54, 57], [58, 71], [72, 83], [84, 85], [85, 89], [89, 90], [91, 93], [94, 100], [101, 103], [104, 107], [108, 112], [113, 114], [114, 118], [118, 119], [120, 122], [123, 129], [130, 132], [133, 136], [137, 150], [151, 157], [158, 171], [172, 183], [184, 185], [185, 189], [189, 190], [191, 193], [194, 202], [203, 212], [213, 214], [214, 226], [226, 227], [228, 231], [232, 237], [238, 247], [248, 250], [251, 261], [262, 263], [263, 267], [267, 268], [269, 271], [272, 280], [281, 287], [288, 290], [291, 302], [303, 316], [317, 325], [326, 331], [332, 333], [333, 337], [337, 338], [339, 341], [342, 346], [347, 352], [353, 355], [356, 364], [365, 370], [371, 374], [375, 381], [382, 385], [386, 391], [392, 402], [403, 404], [404, 408], [408, 409], [410, 412], [413, 417], [418, 423], [424, 427], [428, 438], [439, 450], [451, 452], [452, 456], [456, 457], [458, 460], [461, 465], [466, 471], [472, 474], [475, 483], [484, 489], [490, 493], [494, 500], [501, 504], [505, 510], [511, 521], [522, 523], [523, 527], [527, 528], [529, 531], [532, 536], [537, 542], [543, 546], [547, 557], [558, 569], [570, 571], [571, 575], [575, 576]]}
{"doc_key": "ai-dev-218", "ner": [[6, 6, "university"], [15, 17, "task"], [37, 39, "metrics"], [29, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[37, 39, 29, 33, "opposite", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["A", "frustrating", "result", "of", "the", "same", "Stanford", "study", "(", "and", "of", "other", "attempts", "to", "improve", "name", "recognition", "translation", ")", "is", "that", "many", "times", ",", "the", "inclusion", "of", "methods", "for", "translating", "named", "entities", "results", "in", "a", "decrease", "in", "bilingual", "translation", "assessment", "scores", "."], "sentence-detokenized": "A frustrating result of the same Stanford study (and of other attempts to improve name recognition translation) is that many times, the inclusion of methods for translating named entities results in a decrease in bilingual translation assessment scores.", "token2charspan": [[0, 1], [2, 13], [14, 20], [21, 23], [24, 27], [28, 32], [33, 41], [42, 47], [48, 49], [49, 52], [53, 55], [56, 61], [62, 70], [71, 73], [74, 81], [82, 86], [87, 98], [99, 110], [110, 111], [112, 114], [115, 119], [120, 124], [125, 130], [130, 131], [132, 135], [136, 145], [146, 148], [149, 156], [157, 160], [161, 172], [173, 178], [179, 187], [188, 195], [196, 198], [199, 200], [201, 209], [210, 212], [213, 222], [223, 234], [235, 245], [246, 252], [252, 253]]}
{"doc_key": "ai-dev-219", "ner": [[0, 0, "organisation"], [13, 16, "organisation"], [19, 25, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 13, 16, "role", "works_with", false, false], [0, 0, 19, 25, "role", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Medtronic", "is", "using", "the", "data", "collected", "from", "PM", "and", "is", "collaborating", "with", "researchers", "at", "Johns", "Hopkins", "Hospital", "and", "the", "University", "of", "Washington", "School", "of", "Medicine", "to", "help", "answer", "specific", "questions", "about", "heart", "disease", ",", "such", "as", "whether", "weak", "hearts", "cause", "arrhythmias", "or", "vice", "versa", "."], "sentence-detokenized": "Medtronic is using the data collected from PM and is collaborating with researchers at Johns Hopkins Hospital and the University of Washington School of Medicine to help answer specific questions about heart disease, such as whether weak hearts cause arrhythmias or vice versa.", "token2charspan": [[0, 9], [10, 12], [13, 18], [19, 22], [23, 27], [28, 37], [38, 42], [43, 45], [46, 49], [50, 52], [53, 66], [67, 71], [72, 83], [84, 86], [87, 92], [93, 100], [101, 109], [110, 113], [114, 117], [118, 128], [129, 131], [132, 142], [143, 149], [150, 152], [153, 161], [162, 164], [165, 169], [170, 176], [177, 185], [186, 195], [196, 201], [202, 207], [208, 215], [215, 216], [217, 221], [222, 224], [225, 232], [233, 237], [238, 244], [245, 250], [251, 262], [263, 265], [266, 270], [271, 276], [276, 277]]}
{"doc_key": "ai-dev-220", "ner": [[2, 2, "organisation"], [8, 8, "misc"], [11, 12, "person"], [14, 15, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 2, 2, "artifact", "made_by_studio", false, false], [11, 12, 8, 8, "role", "", false, false], [14, 15, 8, 8, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Next", "came", "Paramount", "'s", "first", "feature", "film", ",", "Sangaree", ",", "starring", "Fernando", "Lamas", "and", "Arlene", "Dahl", "."], "sentence-detokenized": "Next came Paramount's first feature film, Sangaree, starring Fernando Lamas and Arlene Dahl.", "token2charspan": [[0, 4], [5, 9], [10, 19], [19, 21], [22, 27], [28, 35], [36, 40], [40, 41], [42, 50], [50, 51], [52, 60], [61, 69], [70, 75], [76, 79], [80, 86], [87, 91], [91, 92]]}
{"doc_key": "ai-dev-221", "ner": [[0, 0, "programlang"], [9, 11, "researcher"], [13, 14, "researcher"], [18, 19, "organisation"], [21, 22, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 9, 11, "origin", "", false, false], [0, 0, 13, 14, "origin", "", false, false], [9, 11, 18, 19, "physical", "", false, false], [9, 11, 18, 19, "role", "", false, false], [13, 14, 21, 22, "physical", "", false, false], [13, 14, 21, 22, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["KRL", "is", "a", "knowledge", "representation", "language", ",", "developed", "by", "Daniel", "G.", "Bobrow", "and", "Terry", "Winograd", "while", "working", "at", "Xerox", "PARC", "and", "Stanford", "University", ",", "respectively", "."], "sentence-detokenized": "KRL is a knowledge representation language, developed by Daniel G. Bobrow and Terry Winograd while working at Xerox PARC and Stanford University, respectively.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 18], [19, 33], [34, 42], [42, 43], [44, 53], [54, 56], [57, 63], [64, 66], [67, 73], [74, 77], [78, 83], [84, 92], [93, 98], [99, 106], [107, 109], [110, 115], [116, 120], [121, 124], [125, 133], [134, 144], [144, 145], [146, 158], [158, 159]]}
{"doc_key": "ai-dev-222", "ner": [[3, 10, "conference"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 24, "researcher"], [32, 33, "task"], [35, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 10, 32, 33, "topic", "", true, false], [12, 13, 3, 10, "physical", "", false, false], [12, 13, 3, 10, "role", "", false, false], [12, 13, 3, 10, "temporal", "", false, false], [15, 16, 3, 10, "physical", "", false, false], [15, 16, 3, 10, "role", "", false, false], [15, 16, 3, 10, "temporal", "", false, false], [18, 19, 3, 10, "physical", "", false, false], [18, 19, 3, 10, "role", "", false, false], [18, 19, 3, 10, "temporal", "", false, false], [21, 24, 3, 10, "physical", "", false, false], [21, 24, 3, 10, "role", "", false, false], [21, 24, 3, 10, "temporal", "", false, false], [32, 33, 35, 37, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["At", "the", "2006", "IEEE", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "Qiang", "Zhu", ",", "Shai", "Avidan", ",", "Mei-Chen", "Yeh", "and", "Kwang", "-", "Ting", "Cheng", "presented", "an", "algorithm", "to", "significantly", "speed", "up", "person", "detection", "using", "HOG", "descriptor", "methods", "."], "sentence-detokenized": "At the 2006 IEEE Conference on Computer Vision and Pattern Recognition, Qiang Zhu, Shai Avidan, Mei-Chen Yeh and Kwang-Ting Cheng presented an algorithm to significantly speed up person detection using HOG descriptor methods.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 27], [28, 30], [31, 39], [40, 46], [47, 50], [51, 58], [59, 70], [70, 71], [72, 77], [78, 81], [81, 82], [83, 87], [88, 94], [94, 95], [96, 104], [105, 108], [109, 112], [113, 118], [118, 119], [119, 123], [124, 129], [130, 139], [140, 142], [143, 152], [153, 155], [156, 169], [170, 175], [176, 178], [179, 185], [186, 195], [196, 201], [202, 205], [206, 216], [217, 224], [224, 225]]}
{"doc_key": "ai-dev-223", "ner": [[0, 2, "researcher"], [7, 7, "conference"], [10, 12, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 7, 7, "role", "", false, false], [0, 2, 10, 12, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hayes", "is", "a", "founding", "member", "of", "the", "AAAI", "and", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Hayes is a founding member of the AAAI and the Cognitive Science Society.", "token2charspan": [[0, 5], [6, 8], [9, 10], [11, 19], [20, 26], [27, 29], [30, 33], [34, 38], [39, 42], [43, 46], [47, 56], [57, 64], [65, 72], [72, 73]]}
{"doc_key": "ai-dev-224", "ner": [[0, 1, "misc"], [5, 5, "field"], [7, 8, "field"], [10, 11, "field"], [13, 13, "field"], [15, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 24, "field"], [26, 26, "field"], [29, 29, "field"], [31, 32, "field"], [42, 43, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[0, 1, 5, 5, "part-of", "", false, false], [0, 1, 5, 5, "usage", "", false, false], [0, 1, 7, 8, "part-of", "", false, false], [0, 1, 7, 8, "usage", "", false, false], [0, 1, 10, 11, "part-of", "", false, false], [0, 1, 10, 11, "usage", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [0, 1, 13, 13, "usage", "", false, false], [0, 1, 15, 16, "part-of", "", false, false], [0, 1, 15, 16, "usage", "", false, false], [0, 1, 18, 19, "part-of", "", false, false], [0, 1, 18, 19, "usage", "", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 21, 22, "usage", "", false, false], [0, 1, 24, 24, "part-of", "", false, false], [0, 1, 24, 24, "usage", "", false, false], [0, 1, 26, 26, "part-of", "", false, false], [0, 1, 26, 26, "usage", "", false, false], [0, 1, 29, 29, "part-of", "", false, false], [0, 1, 29, 29, "usage", "", false, false], [0, 1, 31, 32, "part-of", "", false, false], [0, 1, 31, 32, "usage", "", false, false], [0, 1, 42, 43, "part-of", "", false, false], [0, 1, 42, 43, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "sentence": ["Time", "series", "are", "used", "in", "statistics", ",", "signal", "processing", ",", "pattern", "recognition", ",", "econometrics", ",", "mathematical", "finance", ",", "weather", "forecasting", ",", "earthquake", "prediction", ",", "electroencephalography", ",", "control", "engineering", ",", "astronomy", ",", "communications", "engineering", "and", ",", "in", "general", ",", "in", "any", "field", "of", "applied", "science", "and", "engineering", "involving", "time", "measurements", "."], "sentence-detokenized": "Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, earthquake prediction, electroencephalography, control engineering, astronomy, communications engineering and, in general, in any field of applied science and engineering involving time measurements.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 23], [24, 34], [34, 35], [36, 42], [43, 53], [53, 54], [55, 62], [63, 74], [74, 75], [76, 88], [88, 89], [90, 102], [103, 110], [110, 111], [112, 119], [120, 131], [131, 132], [133, 143], [144, 154], [154, 155], [156, 178], [178, 179], [180, 187], [188, 199], [199, 200], [201, 210], [210, 211], [212, 226], [227, 238], [239, 242], [242, 243], [244, 246], [247, 254], [254, 255], [256, 258], [259, 262], [263, 268], [269, 271], [272, 279], [280, 287], [288, 291], [292, 303], [304, 313], [314, 318], [319, 331], [331, 332]]}
{"doc_key": "ai-dev-225", "ner": [[13, 14, "metrics"], [38, 40, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "principle", ",", "exact", "recovery", "can", "be", "solved", "in", "its", "feasible", "range", "using", "maximum", "likelihood", ",", "but", "this", "is", "equivalent", "to", "solving", "a", "constrained", "or", "regularised", "cut", "problem", ",", "such", "as", "the", "minimum", "bisection", ",", "which", "is", "usually", "NP", "-", "complete", "."], "sentence-detokenized": "In principle, exact recovery can be solved in its feasible range using maximum likelihood, but this is equivalent to solving a constrained or regularised cut problem, such as the minimum bisection, which is usually NP-complete.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 19], [20, 28], [29, 32], [33, 35], [36, 42], [43, 45], [46, 49], [50, 58], [59, 64], [65, 70], [71, 78], [79, 89], [89, 90], [91, 94], [95, 99], [100, 102], [103, 113], [114, 116], [117, 124], [125, 126], [127, 138], [139, 141], [142, 153], [154, 157], [158, 165], [165, 166], [167, 171], [172, 174], [175, 178], [179, 186], [187, 196], [196, 197], [198, 203], [204, 206], [207, 214], [215, 217], [217, 218], [218, 226], [226, 227]]}
{"doc_key": "ai-dev-226", "ner": [[5, 6, "task"], [14, 14, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 14, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["in", "it", "s", "work", "on", "pedestrian", "detection", ",", "which", "was", "first", "described", "in", "the", "BMVC", "in", "2009", "."], "sentence-detokenized": "in its work on pedestrian detection, which was first described in the BMVC in 2009.", "token2charspan": [[0, 2], [3, 5], [5, 6], [7, 11], [12, 14], [15, 25], [26, 35], [35, 36], [37, 42], [43, 46], [47, 52], [53, 62], [63, 65], [66, 69], [70, 74], [75, 77], [78, 82], [82, 83]]}
{"doc_key": "ai-dev-227", "ner": [[5, 8, "conference"], [10, 11, "researcher"], [13, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 5, 8, "physical", "", false, false], [10, 11, 5, 8, "role", "", false, false], [10, 11, 13, 20, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2007", ",", "at", "the", "International", "Computer", "Vision", "Conference", ",", "Terzopoulos", "received", "the", "inaugural", "IEEE", "PAMI", "Computer", "Vision", "Distinguished", "Researcher", "Award", "for", "his", "pioneering", "and", "sustained", "research", "on", "deformable", "models", "and", "their", "applications", "."], "sentence-detokenized": "In 2007, at the International Computer Vision Conference, Terzopoulos received the inaugural IEEE PAMI Computer Vision Distinguished Researcher Award for his pioneering and sustained research on deformable models and their applications.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 29], [30, 38], [39, 45], [46, 56], [56, 57], [58, 69], [70, 78], [79, 82], [83, 92], [93, 97], [98, 102], [103, 111], [112, 118], [119, 132], [133, 143], [144, 149], [150, 153], [154, 157], [158, 168], [169, 172], [173, 182], [183, 191], [192, 194], [195, 205], [206, 212], [213, 216], [217, 222], [223, 235], [235, 236]]}
{"doc_key": "ai-dev-228", "ner": [[0, 2, "task"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Cluster", "analysis", "consists", "of", "assigning", "data", "points", "to", "clusters", "in", "such", "a", "way", "that", "elements", "of", "the", "same", "cluster", "are", "as", "similar", "as", "possible", ",", "while", "elements", "belonging", "to", "different", "clusters", "are", "as", "dissimilar", "as", "possible", "."], "sentence-detokenized": "Cluster analysis consists of assigning data points to clusters in such a way that elements of the same cluster are as similar as possible, while elements belonging to different clusters are as dissimilar as possible.", "token2charspan": [[0, 7], [8, 16], [17, 25], [26, 28], [29, 38], [39, 43], [44, 50], [51, 53], [54, 62], [63, 65], [66, 70], [71, 72], [73, 76], [77, 81], [82, 90], [91, 93], [94, 97], [98, 102], [103, 110], [111, 114], [115, 117], [118, 125], [126, 128], [129, 137], [137, 138], [139, 144], [145, 153], [154, 163], [164, 166], [167, 176], [177, 185], [186, 189], [190, 192], [193, 203], [204, 206], [207, 215], [215, 216]]}
{"doc_key": "ai-dev-229", "ner": [[10, 10, "field"], [14, 15, "field"], [17, 18, "task"], [20, 21, "field"], [24, 25, "field"], [27, 28, "field"], [31, 32, "field"], [35, 36, "task"], [38, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[10, 10, 14, 15, "named", "", false, false], [10, 10, 20, 21, "named", "", false, false], [10, 10, 27, 28, "named", "", false, false], [17, 18, 14, 15, "part-of", "task_part_of_field", false, false], [24, 25, 20, 21, "part-of", "", false, false], [31, 32, 27, 28, "part-of", "", false, false], [35, 36, 31, 32, "part-of", "", false, false], [38, 38, 31, 32, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["(", "2005", ")", "we", "can", "differentiate", "three", "different", "perspectives", "of", "text", "mining", ",", "namely", "text", "mining", "as", "information", "extraction", ",", "text", "mining", "as", "text", "data", "mining", "and", "text", "mining", "as", "a", "data", "mining", "process", "(", "knowledge", "discovery", "in", "databases", ")", ".", "Hotho", ",", "A.", ",", "N\u00fcrnberger", ",", "A.", "and", "Paa\u00df", ",", "G.", "(", "2005", ")", "."], "sentence-detokenized": "(2005) we can differentiate three different perspectives of text mining, namely text mining as information extraction, text mining as text data mining and text mining as a data mining process (knowledge discovery in databases).Hotho, A., N\u00fcrnberger, A. and Paa\u00df, G. (2005).", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 9], [10, 13], [14, 27], [28, 33], [34, 43], [44, 56], [57, 59], [60, 64], [65, 71], [71, 72], [73, 79], [80, 84], [85, 91], [92, 94], [95, 106], [107, 117], [117, 118], [119, 123], [124, 130], [131, 133], [134, 138], [139, 143], [144, 150], [151, 154], [155, 159], [160, 166], [167, 169], [170, 171], [172, 176], [177, 183], [184, 191], [192, 193], [193, 202], [203, 212], [213, 215], [216, 225], [225, 226], [226, 227], [227, 232], [232, 233], [234, 236], [236, 237], [238, 248], [248, 249], [250, 252], [253, 256], [257, 261], [261, 262], [263, 265], [266, 267], [267, 271], [271, 272], [272, 273]]}
{"doc_key": "ai-dev-230", "ner": [[1, 2, "product"], [15, 20, "location"], [22, 22, "location"], [23, 24, "location"], [34, 35, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 15, 20, "related-to", "developed_for", false, false], [15, 20, 22, 22, "physical", "", false, false], [22, 22, 23, 24, "physical", "", false, false], [34, 35, 1, 2, "role", "buys", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Rancho", "Arm", "was", "developed", "as", "a", "robotic", "arm", "to", "assist", "disabled", "patients", "at", "the", "Rancho", "Los", "Amigos", "National", "Rehabilitation", "Center", "in", "Downey", ",", "California", ";", "this", "computer", "-", "controlled", "arm", "was", "purchased", "by", "Stanford", "University", "in", "1963", "."], "sentence-detokenized": "The Rancho Arm was developed as a robotic arm to assist disabled patients at the Rancho Los Amigos National Rehabilitation Center in Downey, California; this computer-controlled arm was purchased by Stanford University in 1963.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 18], [19, 28], [29, 31], [32, 33], [34, 41], [42, 45], [46, 48], [49, 55], [56, 64], [65, 73], [74, 76], [77, 80], [81, 87], [88, 91], [92, 98], [99, 107], [108, 122], [123, 129], [130, 132], [133, 139], [139, 140], [141, 151], [151, 152], [153, 157], [158, 166], [166, 167], [167, 177], [178, 181], [182, 185], [186, 195], [196, 198], [199, 207], [208, 218], [219, 221], [222, 226], [226, 227]]}
{"doc_key": "ai-dev-231", "ner": [[1, 1, "university"], [3, 3, "researcher"], [10, 13, "organisation"], [21, 23, "organisation"], [27, 28, "researcher"], [30, 32, "researcher"], [45, 45, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 1, 1, "physical", "", false, false], [3, 3, 1, 1, "role", "", false, false], [3, 3, 10, 13, "role", "founder", false, false], [3, 3, 21, 23, "role", "founder", false, false], [21, 23, 45, 45, "physical", "", false, false], [27, 28, 21, 23, "role", "founder", false, false], [30, 32, 21, 23, "role", "founder", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["At", "UCSD", ",", "Norman", "was", "one", "of", "the", "founders", "of", "the", "Cognitive", "Science", "Institute", "and", "one", "of", "the", "organisers", "of", "the", "Cognitive", "Science", "Society", "(", "along", "with", "Roger", "Schank", ",", "Allan", "M.", "Collins", "and", "others", ")", ",", "which", "held", "it", "s", "first", "meeting", "on", "the", "UCSD", "campus", "in", "1979", "."], "sentence-detokenized": "At UCSD, Norman was one of the founders of the Cognitive Science Institute and one of the organisers of the Cognitive Science Society (along with Roger Schank, Allan M. Collins and others), which held its first meeting on the UCSD campus in 1979.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 23], [24, 26], [27, 30], [31, 39], [40, 42], [43, 46], [47, 56], [57, 64], [65, 74], [75, 78], [79, 82], [83, 85], [86, 89], [90, 100], [101, 103], [104, 107], [108, 117], [118, 125], [126, 133], [134, 135], [135, 140], [141, 145], [146, 151], [152, 158], [158, 159], [160, 165], [166, 168], [169, 176], [177, 180], [181, 187], [187, 188], [188, 189], [190, 195], [196, 200], [201, 203], [203, 204], [205, 210], [211, 218], [219, 221], [222, 225], [226, 230], [231, 237], [238, 240], [241, 245], [245, 246]]}
{"doc_key": "ai-dev-232", "ner": [[7, 8, "product"], [10, 11, "product"], [13, 14, "product"], [16, 18, "product"], [20, 21, "product"], [23, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 21, 16, 18, "type-of", "", false, false], [23, 28, 16, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "commonly", "used", "robot", "configurations", "are", "articulated", "robots", ",", "SCARA", "robots", ",", "delta", "robots", "and", "Cartesian", "coordinate", "robots", "(", "gantry", "robots", "or", "x", "-", "y", "-", "z", "robots", ")", "."], "sentence-detokenized": "The most commonly used robot configurations are articulated robots, SCARA robots, delta robots and Cartesian coordinate robots (gantry robots or x-y-z robots).", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 28], [29, 43], [44, 47], [48, 59], [60, 66], [66, 67], [68, 73], [74, 80], [80, 81], [82, 87], [88, 94], [95, 98], [99, 108], [109, 119], [120, 126], [127, 128], [128, 134], [135, 141], [142, 144], [145, 146], [146, 147], [147, 148], [148, 149], [149, 150], [151, 157], [157, 158], [158, 159]]}
{"doc_key": "ai-dev-233", "ner": [[8, 8, "programlang"], [9, 10, "misc"], [15, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 8, 8, "part-of", "", false, false], [15, 15, 9, 10, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "can", "also", "be", "used", "directly", "with", "the", "Perl", "TM", "module", "(", "which", "also", "supports", "LTM", ")", "."], "sentence-detokenized": "It can also be used directly with the Perl TM module (which also supports LTM).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 19], [20, 28], [29, 33], [34, 37], [38, 42], [43, 45], [46, 52], [53, 54], [54, 59], [60, 64], [65, 73], [74, 77], [77, 78], [78, 79]]}
{"doc_key": "ai-dev-234", "ner": [[8, 9, "organisation"], [17, 17, "organisation"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "was", "won", "by", "a", "US", "team", "from", "Newton", "Labs", ",", "and", "the", "contest", "was", "broadcast", "on", "CNN", "."], "sentence-detokenized": "It was won by a US team from Newton Labs, and the contest was broadcast on CNN.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 13], [14, 15], [16, 18], [19, 23], [24, 28], [29, 35], [36, 40], [40, 41], [42, 45], [46, 49], [50, 57], [58, 61], [62, 71], [72, 74], [75, 78], [78, 79]]}
{"doc_key": "ai-dev-235", "ner": [[0, 4, "misc"], [11, 12, "person"], [15, 16, "person"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 12, 0, 4, "role", "directs", false, false], [15, 16, 0, 4, "role", "acts_in", false, false], [18, 19, 0, 4, "role", "acts_in", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Butler", "'s", "in", "Love", ",", "a", "short", "film", "directed", "by", "David", "Arquette", "and", "starring", "Elizabeth", "Berkley", "and", "Thomas", "Jane", "was", "released", "on", "23", "June", "2008", "."], "sentence-detokenized": "The Butler's in Love, a short film directed by David Arquette and starring Elizabeth Berkley and Thomas Jane was released on 23 June 2008.", "token2charspan": [[0, 3], [4, 10], [10, 12], [13, 15], [16, 20], [20, 21], [22, 23], [24, 29], [30, 34], [35, 43], [44, 46], [47, 52], [53, 61], [62, 65], [66, 74], [75, 84], [85, 92], [93, 96], [97, 103], [104, 108], [109, 112], [113, 121], [122, 124], [125, 127], [128, 132], [133, 137], [137, 138]]}
{"doc_key": "ai-dev-236", "ner": [[3, 4, "product"], [11, 11, "field"], [18, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 18, 18, "general-affiliation", "", false, false], [11, 11, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "Word", "Net", "is", "a", "resource", "that", "includes", "a", "taxonomy", ",", "the", "elements", "of", "which", "are", "English", "word", "meanings", "."], "sentence-detokenized": "For example, WordNet is a resource that includes a taxonomy, the elements of which are English word meanings.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [17, 20], [21, 23], [24, 25], [26, 34], [35, 39], [40, 48], [49, 50], [51, 59], [59, 60], [61, 64], [65, 73], [74, 76], [77, 82], [83, 86], [87, 94], [95, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-dev-237", "ner": [[1, 3, "product"], [7, 7, "product"], [9, 9, "product"], [16, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 1, 3, "type-of", "", false, false], [7, 7, 16, 16, "related-to", "ability_to", false, false], [9, 9, 1, 3, "type-of", "", false, false], [9, 9, 16, 16, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Existing", "humanoid", "robot", "systems", ",", "such", "as", "ASIMO", "and", "QRIO", ",", "use", "many", "motors", "to", "achieve", "locomotion", "."], "sentence-detokenized": "Existing humanoid robot systems, such as ASIMO and QRIO, use many motors to achieve locomotion.", "token2charspan": [[0, 8], [9, 17], [18, 23], [24, 31], [31, 32], [33, 37], [38, 40], [41, 46], [47, 50], [51, 55], [55, 56], [57, 60], [61, 65], [66, 72], [73, 75], [76, 83], [84, 94], [94, 95]]}
{"doc_key": "ai-dev-238", "ner": [[0, 0, "metrics"], [5, 6, "metrics"], [8, 8, "metrics"], [10, 14, "misc"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 0, 0, "part-of", "", false, false], [8, 8, 0, 0, "part-of", "", false, false], [10, 14, 0, 0, "part-of", "", false, false], [16, 16, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LEPOR", "is", "designed", "with", "enhanced", "length", "penalty", ",", "precision", ",", "n-", "gram", "word", "order", "penalty", "and", "recall", "factors", "."], "sentence-detokenized": "LEPOR is designed with enhanced length penalty, precision, n-gram word order penalty and recall factors.", "token2charspan": [[0, 5], [6, 8], [9, 17], [18, 22], [23, 31], [32, 38], [39, 46], [46, 47], [48, 57], [57, 58], [59, 61], [61, 65], [66, 70], [71, 76], [77, 84], [85, 88], [89, 95], [96, 103], [103, 104]]}
{"doc_key": "ai-dev-239", "ner": [[5, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "based", "on", "the", "metric", "of", "bilingual", "student", "assessment", ",", "but", "with", "some", "alterations", "."], "sentence-detokenized": "It is based on the metric of bilingual student assessment, but with some alterations.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 14], [15, 18], [19, 25], [26, 28], [29, 38], [39, 46], [47, 57], [57, 58], [59, 62], [63, 67], [68, 72], [73, 84], [84, 85]]}
{"doc_key": "ai-dev-240", "ner": [[6, 6, "product"], [8, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "implementation", "in", "MATLAB", "/", "Octave", ":"], "sentence-detokenized": "This is an example implementation in MATLAB / Octave:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 33], [34, 36], [37, 43], [44, 45], [46, 52], [52, 53]]}
{"doc_key": "ai-dev-241", "ner": [[14, 14, "programlang"], [16, 16, "programlang"], [18, 18, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "designed", "to", "be", "used", "across", "a", "range", "of", "computer", "languages", ",", "including", "Python", ",", "Ruby", "and", "Scheme", "."], "sentence-detokenized": "It is designed to be used across a range of computer languages, including Python, Ruby and Scheme.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 20], [21, 25], [26, 32], [33, 34], [35, 40], [41, 43], [44, 52], [53, 62], [62, 63], [64, 73], [74, 80], [80, 81], [82, 86], [87, 90], [91, 97], [97, 98]]}
{"doc_key": "ai-dev-242", "ner": [[0, 0, "researcher"], [6, 7, "organisation"], [12, 14, "conference"], [20, 20, "academicjournal"], [25, 27, "organisation"], [32, 36, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 7, "role", "", false, false], [0, 0, 12, 14, "role", "", false, false], [0, 0, 20, 20, "role", "", false, false], [0, 0, 25, 27, "role", "", false, false], [0, 0, 32, 36, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hayes", "has", "served", "as", "secretary", "of", "the", "AISB", ",", "president", "and", "trustee", "of", "the", "IJCAI", ",", "associate", "editor", "of", "Artificial", "Intelligence", ",", "governor", "of", "the", "Cognitive", "Science", "Society", "and", "president", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "."], "sentence-detokenized": "Hayes has served as secretary of the AISB, president and trustee of the IJCAI, associate editor of Artificial Intelligence, governor of the Cognitive Science Society and president of the American Association for Artificial Intelligence.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 32], [33, 36], [37, 41], [41, 42], [43, 52], [53, 56], [57, 64], [65, 67], [68, 71], [72, 77], [77, 78], [79, 88], [89, 95], [96, 98], [99, 109], [110, 122], [122, 123], [124, 132], [133, 135], [136, 139], [140, 149], [150, 157], [158, 165], [166, 169], [170, 179], [180, 182], [183, 186], [187, 195], [196, 207], [208, 211], [212, 222], [223, 235], [235, 236]]}
{"doc_key": "ai-dev-243", "ner": [[4, 14, "misc"], [16, 18, "misc"], [23, 24, "person"], [29, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 24, 4, 14, "role", "directed_by", false, false], [23, 24, 16, 18, "role", "directed_by", false, false], [23, 24, 29, 33, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "of", "them", ",", "Now", "is", "the", "Time", "(", "to", "Put", "On", "Your", "Glasses", ")", "and", "Around", "is", "Around", ",", "were", "directed", "by", "Norman", "McLaren", "in", "1951", "for", "the", "National", "Film", "Board", "of", "Canada", "."], "sentence-detokenized": "Two of them, Now is the Time (to Put On Your Glasses) and Around is Around, were directed by Norman McLaren in 1951 for the National Film Board of Canada.", "token2charspan": [[0, 3], [4, 6], [7, 11], [11, 12], [13, 16], [17, 19], [20, 23], [24, 28], [29, 30], [30, 32], [33, 36], [37, 39], [40, 44], [45, 52], [52, 53], [54, 57], [58, 64], [65, 67], [68, 74], [74, 75], [76, 80], [81, 89], [90, 92], [93, 99], [100, 107], [108, 110], [111, 115], [116, 119], [120, 123], [124, 132], [133, 137], [138, 143], [144, 146], [147, 153], [153, 154]]}
{"doc_key": "ai-dev-244", "ner": [[1, 4, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "recommender", "system", "aims", "to", "predict", "a", "target", "user", "'s", "preference", "for", "an", "item", "."], "sentence-detokenized": "A recommender system aims to predict a target user's preference for an item.", "token2charspan": [[0, 1], [2, 13], [14, 20], [21, 25], [26, 28], [29, 36], [37, 38], [39, 45], [46, 50], [50, 52], [53, 63], [64, 67], [68, 70], [71, 75], [75, 76]]}
{"doc_key": "ai-dev-245", "ner": [[0, 0, "algorithm"], [4, 4, "field"], [6, 6, "field"], [8, 9, "field"], [11, 13, "field"], [15, 18, "field"], [17, 17, "field"], [20, 20, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 4, "part-of", "", true, false], [0, 0, 6, 6, "part-of", "", true, false], [0, 0, 8, 9, "part-of", "", true, false], [0, 0, 11, 13, "part-of", "", true, false], [0, 0, 15, 18, "part-of", "", true, false], [0, 0, 17, 17, "part-of", "", true, false], [0, 0, 20, 20, "part-of", "", true, false], [0, 0, 22, 23, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Convolution", "has", "applications", "including", "probability", ",", "statistics", ",", "computer", "vision", ",", "natural", "language", "processing", ",", "image", "and", "signal", "processing", ",", "engineering", "and", "differential", "equations", "."], "sentence-detokenized": "Convolution has applications including probability, statistics, computer vision, natural language processing, image and signal processing, engineering and differential equations.", "token2charspan": [[0, 11], [12, 15], [16, 28], [29, 38], [39, 50], [50, 51], [52, 62], [62, 63], [64, 72], [73, 79], [79, 80], [81, 88], [89, 97], [98, 108], [108, 109], [110, 115], [116, 119], [120, 126], [127, 137], [137, 138], [139, 150], [151, 154], [155, 167], [168, 177], [177, 178]]}
{"doc_key": "ai-dev-246", "ner": [[0, 0, "field"], [3, 5, "task"], [7, 8, "task"], [10, 10, "task"], [11, 11, "task"], [12, 12, "task"], [14, 15, "task"], [17, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "task"], [29, 29, "field"], [31, 31, "field"], [33, 35, "field"], [37, 37, "field"], [39, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[0, 0, 3, 5, "part-of", "", true, false], [0, 0, 7, 8, "part-of", "", true, false], [0, 0, 10, 10, "part-of", "", true, false], [0, 0, 11, 11, "part-of", "", true, false], [0, 0, 12, 12, "part-of", "", true, false], [0, 0, 14, 15, "part-of", "", true, false], [0, 0, 17, 18, "part-of", "", true, false], [0, 0, 20, 21, "part-of", "", true, false], [0, 0, 23, 24, "part-of", "", true, false], [0, 0, 26, 27, "part-of", "", true, false], [0, 0, 29, 29, "part-of", "", true, false], [0, 0, 31, 31, "part-of", "", true, false], [0, 0, 33, 35, "part-of", "", true, false], [0, 0, 37, 37, "part-of", "", true, false], [0, 0, 39, 39, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["DSP", "applications", "include", "audio", "signal", "processing", ",", "audio", "compression", ",", "digital", "image", "processing", ",", "video", "compression", ",", "speech", "processing", ",", "speech", "recognition", ",", "digital", "communications", ",", "digital", "synthesisers", ",", "radar", ",", "sonar", ",", "financial", "signal", "processing", ",", "seismology", "and", "biomedicine", "."], "sentence-detokenized": "DSP applications include audio signal processing, audio compression, digital image processing, video compression, speech processing, speech recognition, digital communications, digital synthesisers, radar, sonar, financial signal processing, seismology and biomedicine.", "token2charspan": [[0, 3], [4, 16], [17, 24], [25, 30], [31, 37], [38, 48], [48, 49], [50, 55], [56, 67], [67, 68], [69, 76], [77, 82], [83, 93], [93, 94], [95, 100], [101, 112], [112, 113], [114, 120], [121, 131], [131, 132], [133, 139], [140, 151], [151, 152], [153, 160], [161, 175], [175, 176], [177, 184], [185, 197], [197, 198], [199, 204], [204, 205], [206, 211], [211, 212], [213, 222], [223, 229], [230, 240], [240, 241], [242, 252], [253, 256], [257, 268], [268, 269]]}
{"doc_key": "ai-dev-247", "ner": [[11, 12, "misc"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "20", "February", "1912", "-", "11", "August", "2011", ")", "was", "an", "American", "inventor", ",", "best", "known", "for", "the", "creation", "of", "Unimate", ",", "the", "first", "industrial", "robot", "."], "sentence-detokenized": "(20 February 1912 - 11 August 2011) was an American inventor, best known for the creation of Unimate, the first industrial robot.", "token2charspan": [[0, 1], [1, 3], [4, 12], [13, 17], [18, 19], [20, 22], [23, 29], [30, 34], [34, 35], [36, 39], [40, 42], [43, 51], [52, 60], [60, 61], [62, 66], [67, 72], [73, 76], [77, 80], [81, 89], [90, 92], [93, 100], [100, 101], [102, 105], [106, 111], [112, 122], [123, 128], [128, 129]]}
{"doc_key": "ai-dev-248", "ner": [[1, 3, "researcher"], [5, 7, "researcher"], [9, 9, "researcher"], [21, 22, "algorithm"], [25, 27, "algorithm"], [31, 32, "task"], [36, 37, "algorithm"], [42, 43, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 3, 21, 22, "related-to", "writes_about", true, false], [5, 7, 21, 22, "related-to", "writes_about", true, false], [9, 9, 21, 22, "related-to", "writes_about", true, false], [21, 22, 25, 27, "related-to", "", true, false], [31, 32, 36, 37, "related-to", "", true, false], [42, 43, 36, 37, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["With", "David", "E.", "Rumelhart", "and", "Ronald", "J.", "Williams", ",", "Hinton", "co-authored", "a", "widely", "cited", "paper", "published", "in", "1986", "that", "popularised", "the", "backpropagation", "algorithm", "for", "training", "multilayer", "neural", "networks", ",", "The", "spectacular", "image", "recognition", "landmark", "of", "the", "Alex", "Net", "designed", "by", "his", "student", "Alex", "Krizhevsky", "{{", "cite", "web"], "sentence-detokenized": "With David E. Rumelhart and Ronald J. Williams, Hinton co-authored a widely cited paper published in 1986 that popularised the backpropagation algorithm for training multilayer neural networks, The spectacular image recognition landmark of the AlexNet designed by his student Alex Krizhevsky {{cite web", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 34], [35, 37], [38, 46], [46, 47], [48, 54], [55, 66], [67, 68], [69, 75], [76, 81], [82, 87], [88, 97], [98, 100], [101, 105], [106, 110], [111, 122], [123, 126], [127, 142], [143, 152], [153, 156], [157, 165], [166, 176], [177, 183], [184, 192], [192, 193], [194, 197], [198, 209], [210, 215], [216, 227], [228, 236], [237, 239], [240, 243], [244, 248], [248, 251], [252, 260], [261, 263], [264, 267], [268, 275], [276, 280], [281, 291], [292, 294], [294, 298], [299, 302]]}
{"doc_key": "ai-dev-249", "ner": [[10, 12, "metrics"], [14, 16, "metrics"], [18, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "value", "being", "predicted", "is", "continuously", "distributed", ",", "the", "mean", "square", "error", ",", "mean", "square", "error", "or", "mean", "absolute", "deviation", "can", "be", "used", "to", "summarise", "the", "errors", "."], "sentence-detokenized": "When the value being predicted is continuously distributed, the mean square error, mean square error or mean absolute deviation can be used to summarise the errors.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 20], [21, 30], [31, 33], [34, 46], [47, 58], [58, 59], [60, 63], [64, 68], [69, 75], [76, 81], [81, 82], [83, 87], [88, 94], [95, 100], [101, 103], [104, 108], [109, 117], [118, 127], [128, 131], [132, 134], [135, 139], [140, 142], [143, 152], [153, 156], [157, 163], [163, 164]]}
{"doc_key": "ai-dev-250", "ner": [[0, 1, "algorithm"], [14, 15, "field"]], "ner_mapping_to_source": [0, 2], "relations": [[0, 1, 14, 15, "part-of", "", true, false]], "relations_mapping_to_source": [1], "sentence": ["Conceptual", "clustering", "was", "developed", "mainly", "during", "the", "1980s", "as", "a", "machine", "learning", "paradigm", "for", "unsupervised", "learning", "."], "sentence-detokenized": "Conceptual clustering was developed mainly during the 1980s as a machine learning paradigm for unsupervised learning.", "token2charspan": [[0, 10], [11, 21], [22, 25], [26, 35], [36, 42], [43, 49], [50, 53], [54, 59], [60, 62], [63, 64], [65, 72], [73, 81], [82, 90], [91, 94], [95, 107], [108, 116], [116, 117]]}
{"doc_key": "ai-dev-251", "ner": [[9, 10, "product"], [27, 28, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "named", "entities", "can", "not", "be", "recognised", "by", "the", "machine", "translator", ",", "they", "may", "be", "mistranslated", "as", "common", "nouns", ",", "which", "would", "most", "likely", "not", "affect", "the", "bilingual", "evaluation", "score", "of", "the", "translation", ",", "but", "would", "change", "the", "human", "readability", "of", "the", "text", "."], "sentence-detokenized": "If named entities cannot be recognised by the machine translator, they may be mistranslated as common nouns, which would most likely not affect the bilingual evaluation score of the translation, but would change the human readability of the text.", "token2charspan": [[0, 2], [3, 8], [9, 17], [18, 21], [21, 24], [25, 27], [28, 38], [39, 41], [42, 45], [46, 53], [54, 64], [64, 65], [66, 70], [71, 74], [75, 77], [78, 91], [92, 94], [95, 101], [102, 107], [107, 108], [109, 114], [115, 120], [121, 125], [126, 132], [133, 136], [137, 143], [144, 147], [148, 157], [158, 168], [169, 174], [175, 177], [178, 181], [182, 193], [193, 194], [195, 198], [199, 204], [205, 211], [212, 215], [216, 221], [222, 233], [234, 236], [237, 240], [241, 245], [245, 246]]}
{"doc_key": "ai-dev-252", "ner": [[0, 1, "researcher"], [10, 11, "misc"], [12, 18, "conference"], [20, 22, "location"], [24, 24, "country"], [38, 39, "researcher"], [45, 45, "researcher"], [49, 50, "university"], [54, 55, "researcher"], [57, 58, "researcher"], [60, 61, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 11, "related-to", "writes_about", false, false], [0, 1, 12, 18, "temporal", "", true, false], [12, 18, 20, 22, "physical", "", false, false], [20, 22, 24, 24, "physical", "", false, false], [45, 45, 49, 50, "physical", "", false, false], [45, 45, 49, 50, "role", "", false, false], [54, 55, 49, 50, "physical", "", false, false], [54, 55, 49, 50, "role", "", false, false], [57, 58, 49, 50, "physical", "", false, false], [57, 58, 49, 50, "role", "", false, false], [60, 61, 49, 50, "physical", "", false, false], [60, 61, 49, 50, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Roger", "Schank", ",", "1969", ",", "A", "conceptual", "dependency", "parser", "for", "natural", "language", "Proceedings", "of", "the", "1969", "on", "Computational", "linguistics", ",", "S\u00e5ng", "-", "S\u00e4by", ",", "Sweden", ",", "pages", "1-", "3", "This", "model", ",", "partly", "influenced", "by", "the", "work", "of", "Sydney", "Lamb", ",", "was", "widely", "used", "by", "Schank", "'s", "students", "at", "Yale", "University", ",", "such", "as", "Robert", "Wilensky", ",", "Wendy", "Lehnert", "and", "Janet", "Kolodner", "."], "sentence-detokenized": "Roger Schank, 1969, A conceptual dependency parser for natural language Proceedings of the 1969 on Computational linguistics, S\u00e5ng-S\u00e4by, Sweden, pages 1-3 This model, partly influenced by the work of Sydney Lamb, was widely used by Schank's students at Yale University, such as Robert Wilensky, Wendy Lehnert and Janet Kolodner.", "token2charspan": [[0, 5], [6, 12], [12, 13], [14, 18], [18, 19], [20, 21], [22, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 71], [72, 83], [84, 86], [87, 90], [91, 95], [96, 98], [99, 112], [113, 124], [124, 125], [126, 130], [130, 131], [131, 135], [135, 136], [137, 143], [143, 144], [145, 150], [151, 153], [153, 154], [155, 159], [160, 165], [165, 166], [167, 173], [174, 184], [185, 187], [188, 191], [192, 196], [197, 199], [200, 206], [207, 211], [211, 212], [213, 216], [217, 223], [224, 228], [229, 231], [232, 238], [238, 240], [241, 249], [250, 252], [253, 257], [258, 268], [268, 269], [270, 274], [275, 277], [278, 284], [285, 293], [293, 294], [295, 300], [301, 308], [309, 312], [313, 318], [319, 327], [327, 328]]}
{"doc_key": "ai-dev-253", "ner": [[0, 4, "algorithm"], [6, 6, "algorithm"], [13, 13, "algorithm"], [15, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 0, 4, "named", "", false, false], [13, 13, 0, 4, "named", "", false, false], [15, 16, 0, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "improved", "maximum", "likelihood", "method", "(", "IMLM", ")", "is", "a", "combination", "of", "two", "MLM", "(", "maximum", "likelihood", ")", "estimators", "."], "sentence-detokenized": "The improved maximum likelihood method (IMLM) is a combination of two MLM (maximum likelihood) estimators.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 31], [32, 38], [39, 40], [40, 44], [44, 45], [46, 48], [49, 50], [51, 62], [63, 65], [66, 69], [70, 73], [74, 75], [75, 82], [83, 93], [93, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-dev-254", "ner": [[21, 22, "metrics"], [25, 26, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[25, 26, 21, 22, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["These", "methods", "can", "also", "analyse", "the", "outcome", "of", "a", "programme", "and", "its", "usefulness", ",", "and", "therefore", "may", "involve", "analysis", "of", "its", "confusion", "matrix", "(", "or", "confusion", "table", ")", "."], "sentence-detokenized": "These methods can also analyse the outcome of a programme and its usefulness, and therefore may involve analysis of its confusion matrix (or confusion table).", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 22], [23, 30], [31, 34], [35, 42], [43, 45], [46, 47], [48, 57], [58, 61], [62, 65], [66, 76], [76, 77], [78, 81], [82, 91], [92, 95], [96, 103], [104, 112], [113, 115], [116, 119], [120, 129], [130, 136], [137, 138], [138, 140], [141, 150], [151, 156], [156, 157], [157, 158]]}
{"doc_key": "ai-dev-255", "ner": [[0, 0, "product"], [5, 6, "researcher"], [8, 9, "researcher"], [11, 13, "researcher"], [19, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 6, "origin", "", false, false], [0, 0, 8, 9, "origin", "", false, false], [0, 0, 11, 13, "origin", "", false, false], [0, 0, 19, 23, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SURF", "was", "first", "published", "by", "Herbert", "Bay", ",", "Tinne", "Tuytelaars", "and", "Luc", "Van", "Gool", ",", "and", "presented", "at", "the", "2006", "European", "Computer", "Vision", "Conference", "."], "sentence-detokenized": "SURF was first published by Herbert Bay, Tinne Tuytelaars and Luc Van Gool, and presented at the 2006 European Computer Vision Conference.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 24], [25, 27], [28, 35], [36, 39], [39, 40], [41, 46], [47, 57], [58, 61], [62, 65], [66, 69], [70, 74], [74, 75], [76, 79], [80, 89], [90, 92], [93, 96], [97, 101], [102, 110], [111, 119], [120, 126], [127, 137], [137, 138]]}
{"doc_key": "ai-dev-256", "ner": [[0, 0, "task"], [7, 8, "field"], [10, 11, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 8, "part-of", "", false, false], [0, 0, 10, 11, "part-of", "", false, false], [0, 0, 13, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OCR", "is", "a", "field", "of", "research", "in", "pattern", "recognition", ",", "artificial", "intelligence", "and", "computer", "vision", "."], "sentence-detokenized": "OCR is a field of research in pattern recognition, artificial intelligence and computer vision.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 14], [15, 17], [18, 26], [27, 29], [30, 37], [38, 49], [49, 50], [51, 61], [62, 74], [75, 78], [79, 87], [88, 94], [94, 95]]}
{"doc_key": "ai-dev-257", "ner": [[6, 8, "metrics"], [11, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 15, 11, 13, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Continuing", "with", "the", "example", "using", "the", "maximum", "likelihood", "estimator", ",", "the", "probability", "density", "function", "(", "pdf", ")", "of", "the", "noise", "for", "a", "mathwn", "/", "math", "sample", "is"], "sentence-detokenized": "Continuing with the example using the maximum likelihood estimator, the probability density function (pdf) of the noise for a mathwn / math sample is", "token2charspan": [[0, 10], [11, 15], [16, 19], [20, 27], [28, 33], [34, 37], [38, 45], [46, 56], [57, 66], [66, 67], [68, 71], [72, 83], [84, 91], [92, 100], [101, 102], [102, 105], [105, 106], [107, 109], [110, 113], [114, 119], [120, 123], [124, 125], [126, 132], [133, 134], [135, 139], [140, 146], [147, 149]]}
{"doc_key": "ai-dev-258", "ner": [[2, 3, "field"], [5, 6, "task"], [8, 9, "task"], [11, 12, "task"], [14, 15, "task"], [17, 19, "task"], [21, 21, "task"], [23, 23, "task"], [25, 26, "task"], [28, 29, "task"], [31, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[5, 6, 2, 3, "part-of", "", false, false], [8, 9, 2, 3, "part-of", "", false, false], [11, 12, 2, 3, "part-of", "", false, false], [14, 15, 2, 3, "part-of", "", false, false], [17, 19, 2, 3, "part-of", "", false, false], [21, 21, 2, 3, "part-of", "", false, false], [23, 23, 2, 3, "part-of", "", false, false], [25, 26, 2, 3, "part-of", "", false, false], [28, 29, 2, 3, "part-of", "", false, false], [31, 33, 2, 3, "part-of", "", false, false], [35, 36, 2, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Subdomains", "of", "computer", "vision", "include", "scene", "reconstruction", ",", "event", "detection", ",", "video", "tracking", ",", "object", "recognition", ",", "3D", "pose", "estimation", ",", "learning", ",", "indexing", ",", "motion", "estimation", ",", "visual", "servoformation", ",", "3D", "scene", "modelling", "and", "image", "restoration", "."], "sentence-detokenized": "Subdomains of computer vision include scene reconstruction, event detection, video tracking, object recognition, 3D pose estimation, learning, indexing, motion estimation, visual servoformation, 3D scene modelling and image restoration.", "token2charspan": [[0, 10], [11, 13], [14, 22], [23, 29], [30, 37], [38, 43], [44, 58], [58, 59], [60, 65], [66, 75], [75, 76], [77, 82], [83, 91], [91, 92], [93, 99], [100, 111], [111, 112], [113, 115], [116, 120], [121, 131], [131, 132], [133, 141], [141, 142], [143, 151], [151, 152], [153, 159], [160, 170], [170, 171], [172, 178], [179, 193], [193, 194], [195, 197], [198, 203], [204, 213], [214, 217], [218, 223], [224, 235], [235, 236]]}
{"doc_key": "ai-dev-259", "ner": [[5, 8, "conference"], [10, 12, "researcher"], [14, 15, "misc"], [18, 21, "conference"], [23, 23, "researcher"], [25, 25, "researcher"], [27, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 8, 18, 21, "named", "", false, false], [10, 12, 14, 15, "win-defeat", "", false, false], [10, 12, 27, 28, "related-to", "writes_about", true, false], [14, 15, 5, 8, "temporal", "", false, false], [23, 23, 14, 15, "win-defeat", "", false, true], [23, 23, 27, 28, "related-to", "writes_about", true, false], [25, 25, 14, 15, "win-defeat", "", false, true], [25, 25, 27, 28, "related-to", "writes_about", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["In", "2013", ",", "at", "the", "International", "Computer", "Vision", "Conference", ",", "Terzopoulos", "was", "awarded", "the", "Helmholtz", "Prize", "for", "his", "1987", "work", "at", "ICCV", "with", "Kass", "and", "Witkin", "on", "active", "contour", "models", "."], "sentence-detokenized": "In 2013, at the International Computer Vision Conference, Terzopoulos was awarded the Helmholtz Prize for his 1987 work at ICCV with Kass and Witkin on active contour models.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 29], [30, 38], [39, 45], [46, 56], [56, 57], [58, 69], [70, 73], [74, 81], [82, 85], [86, 95], [96, 101], [102, 105], [106, 109], [110, 114], [115, 119], [120, 122], [123, 127], [128, 132], [133, 137], [138, 141], [142, 148], [149, 151], [152, 158], [159, 166], [167, 173], [173, 174]]}
{"doc_key": "ai-dev-260", "ner": [[20, 22, "task"], [23, 23, "algorithm"], [27, 28, "algorithm"], [30, 32, "algorithm"], [34, 35, "algorithm"], [37, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 22, 23, 23, "usage", "", true, false], [20, 22, 27, 28, "usage", "", true, false], [20, 22, 30, 32, "usage", "", true, false], [20, 22, 34, 35, "usage", "", true, false], [20, 22, 37, 37, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["If", "the", "regularisation", "function", "There", "are", "many", "algorithms", "for", "solving", "this", "type", "of", "problem", ";", "the", "most", "popular", "ones", "for", "linear", "classification", "are", "stochastic", "gradient", "descent", ")", "gradient", "descent", ",", "L", "-", "BFGS", ",", "coordinate", "descent", "and", "Newton", "'s", "methods", "."], "sentence-detokenized": "If the regularisation function There are many algorithms for solving this type of problem; the most popular ones for linear classification are stochastic gradient descent) gradient descent, L-BFGS, coordinate descent and Newton's methods.", "token2charspan": [[0, 2], [3, 6], [7, 21], [22, 30], [31, 36], [37, 40], [41, 45], [46, 56], [57, 60], [61, 68], [69, 73], [74, 78], [79, 81], [82, 89], [89, 90], [91, 94], [95, 99], [100, 107], [108, 112], [113, 116], [117, 123], [124, 138], [139, 142], [143, 153], [154, 162], [163, 170], [170, 171], [172, 180], [181, 188], [188, 189], [190, 191], [191, 192], [192, 196], [196, 197], [198, 208], [209, 216], [217, 220], [221, 227], [227, 229], [230, 237], [237, 238]]}
{"doc_key": "ai-dev-261", "ner": [[0, 3, "algorithm"], [6, 6, "algorithm"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 11, 12, "origin", "", false, false], [6, 6, 0, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Short", "-", "term", "memory", "networks", "(", "LSTM", ")", "were", "invented", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "in", "1997", "and", "set", "records", "for", "accuracy", "in", "multiple", "application", "domains", "."], "sentence-detokenized": "Short-term memory networks (LSTM) were invented by Sepp Hochreiter and J\u00fcrgen Schmidhuber in 1997 and set records for accuracy in multiple application domains.", "token2charspan": [[0, 5], [5, 6], [6, 10], [11, 17], [18, 26], [27, 28], [28, 32], [32, 33], [34, 38], [39, 47], [48, 50], [51, 55], [56, 66], [67, 70], [71, 77], [78, 89], [90, 92], [93, 97], [98, 101], [102, 105], [106, 113], [114, 117], [118, 126], [127, 129], [130, 138], [139, 150], [151, 158], [158, 159]]}
{"doc_key": "ai-dev-262", "ner": [[0, 0, "product"], [4, 6, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["TN", "was", "developed", "at", "Massachusetts", "General", "Hospital", "and", "tested", "in", "multiple", "settings", ",", "including", "extracting", "smoking", "status", ",", "family", "history", "of", "coronary", "artery", "disease", ",", "identifying", "patients", "with", "sleep", "disorders", ","], "sentence-detokenized": "TN was developed at Massachusetts General Hospital and tested in multiple settings, including extracting smoking status, family history of coronary artery disease, identifying patients with sleep disorders,", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 33], [34, 41], [42, 50], [51, 54], [55, 61], [62, 64], [65, 73], [74, 82], [82, 83], [84, 93], [94, 104], [105, 112], [113, 119], [119, 120], [121, 127], [128, 135], [136, 138], [139, 147], [148, 154], [155, 162], [162, 163], [164, 175], [176, 184], [185, 189], [190, 195], [196, 205], [205, 206]]}
{"doc_key": "ai-dev-263", "ner": [[3, 3, "researcher"], [8, 8, "product"], [17, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 8, "role", "sells", false, false], [8, 8, 17, 18, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "shipped", "in", "1961", "to", "General", "Motors", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was shipped in 1961 to General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 73], [74, 76], [77, 81], [82, 84], [85, 92], [93, 99], [99, 100]]}
{"doc_key": "ai-dev-264", "ner": [[0, 2, "conference"], [13, 14, "location"], [16, 16, "location"], [18, 18, "country"], [32, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 13, 14, "physical", "", false, false], [13, 14, 16, 16, "physical", "", false, false], [16, 16, 18, 18, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Campus", "Party", "Europe", "was", "held", "from", "14", "to", "18", "April", "2010", "at", "the", "Caja", "M\u00e1gica", "in", "Madrid", ",", "Spain", ",", "with", "800", "participants", "from", "each", "of", "the", "27", "member", "states", "of", "the", "European", "Union", "."], "sentence-detokenized": "Campus Party Europe was held from 14 to 18 April 2010 at the Caja M\u00e1gica in Madrid, Spain, with 800 participants from each of the 27 member states of the European Union.", "token2charspan": [[0, 6], [7, 12], [13, 19], [20, 23], [24, 28], [29, 33], [34, 36], [37, 39], [40, 42], [43, 48], [49, 53], [54, 56], [57, 60], [61, 65], [66, 72], [73, 75], [76, 82], [82, 83], [84, 89], [89, 90], [91, 95], [96, 99], [100, 112], [113, 117], [118, 122], [123, 125], [126, 129], [130, 132], [133, 139], [140, 146], [147, 149], [150, 153], [154, 162], [163, 168], [168, 169]]}
{"doc_key": "ai-dev-265", "ner": [[9, 9, "organisation"], [11, 13, "organisation"], [16, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 19, 9, 9, "origin", "", false, false], [16, 19, 11, 13, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2016", ",", "a", "collaboration", "was", "announced", "between", "DeepMind", "and", "Moorfields", "Eye", "Hospital", "to", "develop", "AI", "applications", "for", "healthcare", "."], "sentence-detokenized": "In July 2016, a collaboration was announced between DeepMind and Moorfields Eye Hospital to develop AI applications for healthcare.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 15], [16, 29], [30, 33], [34, 43], [44, 51], [52, 60], [61, 64], [65, 75], [76, 79], [80, 88], [89, 91], [92, 99], [100, 102], [103, 115], [116, 119], [120, 130], [130, 131]]}
{"doc_key": "ai-dev-266", "ner": [[5, 5, "misc"], [12, 14, "university"], [16, 16, "university"], [18, 19, "university"], [21, 22, "university"], [24, 24, "university"], [26, 26, "university"], [28, 31, "university"], [33, 34, "university"], [36, 37, "university"], [39, 39, "university"], [42, 44, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[5, 5, 12, 14, "physical", "", false, false], [5, 5, 16, 16, "physical", "", false, false], [5, 5, 18, 19, "physical", "", false, false], [5, 5, 21, 22, "physical", "", false, false], [5, 5, 24, 24, "physical", "", false, false], [5, 5, 26, 26, "physical", "", false, false], [5, 5, 28, 31, "physical", "", false, false], [5, 5, 33, 34, "physical", "", false, false], [5, 5, 36, 37, "physical", "", false, false], [5, 5, 39, 39, "physical", "", false, false], [5, 5, 42, 44, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["They", "ended", "up", "awarding", "eleven", "PR2s", "to", "different", "institutions", ",", "including", "the", "University", "of", "Freiburg", ",", "Bosch", ",", "Georgia", "Tech", ",", "KU", "Leuven", ",", "MIT", ",", "Stanford", ",", "Technical", "University", "of", "Munich", ",", "UC", "Berkeley", ",", "U", "Penn", ",", "USC", "and", "the", "University", "of", "Tokyo", "."], "sentence-detokenized": "They ended up awarding eleven PR2s to different institutions, including the University of Freiburg, Bosch, Georgia Tech, KU Leuven, MIT, Stanford, Technical University of Munich, UC Berkeley, U Penn, USC and the University of Tokyo.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 29], [30, 34], [35, 37], [38, 47], [48, 60], [60, 61], [62, 71], [72, 75], [76, 86], [87, 89], [90, 98], [98, 99], [100, 105], [105, 106], [107, 114], [115, 119], [119, 120], [121, 123], [124, 130], [130, 131], [132, 135], [135, 136], [137, 145], [145, 146], [147, 156], [157, 167], [168, 170], [171, 177], [177, 178], [179, 181], [182, 190], [190, 191], [192, 193], [194, 198], [198, 199], [200, 203], [204, 207], [208, 211], [212, 222], [223, 225], [226, 231], [231, 232]]}
{"doc_key": "ai-dev-267", "ner": [[0, 0, "metrics"], [2, 2, "metrics"], [4, 4, "metrics"], [6, 6, "metrics"], [17, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 17, 18, "part-of", "", false, false], [2, 2, 17, 18, "part-of", "", false, false], [4, 4, 17, 18, "part-of", "", false, false], [6, 6, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["TP", ",", "TN", ",", "FP", "and", "FN", "counts", "are", "usually", "stored", "in", "a", "table", "known", "as", "a", "confusion", "matrix", "."], "sentence-detokenized": "TP, TN, FP and FN counts are usually stored in a table known as a confusion matrix.", "token2charspan": [[0, 2], [2, 3], [4, 6], [6, 7], [8, 10], [11, 14], [15, 17], [18, 24], [25, 28], [29, 36], [37, 43], [44, 46], [47, 48], [49, 54], [55, 60], [61, 63], [64, 65], [66, 75], [76, 82], [82, 83]]}
{"doc_key": "ai-dev-268", "ner": [[6, 7, "metrics"], [9, 10, "metrics"], [12, 13, "metrics"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["As", "a", "set", "of", "characteristics", ",", "information", "gain", ",", "cross", "-entropy", ",", "mutual", "information", "and", "likelihood", "ratio", "are", "commonly", "used", "."], "sentence-detokenized": "As a set of characteristics, information gain, cross-entropy, mutual information and likelihood ratio are commonly used.", "token2charspan": [[0, 2], [3, 4], [5, 8], [9, 11], [12, 27], [27, 28], [29, 40], [41, 45], [45, 46], [47, 52], [52, 60], [60, 61], [62, 68], [69, 80], [81, 84], [85, 95], [96, 101], [102, 105], [106, 114], [115, 119], [119, 120]]}
{"doc_key": "ai-dev-269", "ner": [[13, 14, "task"], [16, 17, "task"], [19, 19, "task"], [21, 21, "task"], [23, 23, "task"], [25, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[25, 25, 23, 23, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "successfully", "applied", "to", "a", "variety", "of", "problems", ",", "such", "as", "robot", "control", ",", "lift", "programming", ",", "telecommunications", ",", "checkers", "and", "Go", "(", "AlphaGo", ")", "."], "sentence-detokenized": "It has been successfully applied to a variety of problems, such as robot control, lift programming, telecommunications, checkers and Go (AlphaGo).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 24], [25, 32], [33, 35], [36, 37], [38, 45], [46, 48], [49, 57], [57, 58], [59, 63], [64, 66], [67, 72], [73, 80], [80, 81], [82, 86], [87, 98], [98, 99], [100, 118], [118, 119], [120, 128], [129, 132], [133, 135], [136, 137], [137, 144], [144, 145], [145, 146]]}
{"doc_key": "ai-dev-270", "ner": [[11, 11, "misc"], [20, 23, "university"], [25, 25, "location"], [27, 27, "location"], [31, 37, "location"], [39, 41, "location"], [43, 43, "location"], [44, 44, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 11, 20, 23, "physical", "", false, false], [20, 23, 25, 25, "physical", "", false, false], [25, 25, 27, 27, "physical", "", false, false], [31, 37, 39, 41, "physical", "", false, false], [39, 41, 43, 43, "physical", "", false, false], [43, 43, 44, 44, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "the", "inaugural", "year", "of", "Mission", "8", ",", "the", "American", "venue", "was", "held", "on", "the", "campus", "of", "the", "Georgia", "Institute", "of", "Technology", "in", "Atlanta", ",", "Georgia", ",", "and", "the", "Asia", "/", "Pacific", "venue", "was", "held", "at", "the", "Beihang", "University", "Gymnasium", "in", "Beijing", "China", "."], "sentence-detokenized": "In 2018, the inaugural year of Mission 8, the American venue was held on the campus of the Georgia Institute of Technology in Atlanta, Georgia, and the Asia/Pacific venue was held at the Beihang University Gymnasium in Beijing China.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 22], [23, 27], [28, 30], [31, 38], [39, 40], [40, 41], [42, 45], [46, 54], [55, 60], [61, 64], [65, 69], [70, 72], [73, 76], [77, 83], [84, 86], [87, 90], [91, 98], [99, 108], [109, 111], [112, 122], [123, 125], [126, 133], [133, 134], [135, 142], [142, 143], [144, 147], [148, 151], [152, 156], [156, 157], [157, 164], [165, 170], [171, 174], [175, 179], [180, 182], [183, 186], [187, 194], [195, 205], [206, 215], [216, 218], [219, 226], [227, 232], [232, 233]]}
{"doc_key": "ai-dev-271", "ner": [[0, 1, "field"], [6, 7, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "origin", "", false, false], [0, 1, 6, 7, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "is", "closely", "related", "to", "pattern", "recognition", "and", "has", "its", "origins", "in", "artificial", "intelligence", "."], "sentence-detokenized": "Machine learning is closely related to pattern recognition and has its origins in artificial intelligence.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 35], [36, 38], [39, 46], [47, 58], [59, 62], [63, 66], [67, 70], [71, 78], [79, 81], [82, 92], [93, 105], [105, 106]]}
{"doc_key": "ai-dev-272", "ner": [[4, 4, "programlang"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "comes", "with", "3", "Java", "games", "that", "are", "controlled", "by", "the", "remote", "control", "and", "displayed", "on", "its", "LCD", "screen", "."], "sentence-detokenized": "It comes with 3 Java games that are controlled by the remote control and displayed on its LCD screen.", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 15], [16, 20], [21, 26], [27, 31], [32, 35], [36, 46], [47, 49], [50, 53], [54, 60], [61, 68], [69, 72], [73, 82], [83, 85], [86, 89], [90, 93], [94, 100], [100, 101]]}
{"doc_key": "ai-dev-273", "ner": [[7, 15, "task"], [18, 20, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 20, 7, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "commercially", "successful", "but", "specialised", "technique", "for", "estimating", "articulated", "body", "posture", ",", "based", "on", "computer", "vision", ",", "is", "optical", "motion", "capture", "."], "sentence-detokenized": "A commercially successful but specialised technique for estimating articulated body posture, based on computer vision, is optical motion capture.", "token2charspan": [[0, 1], [2, 14], [15, 25], [26, 29], [30, 41], [42, 51], [52, 55], [56, 66], [67, 78], [79, 83], [84, 91], [91, 92], [93, 98], [99, 101], [102, 110], [111, 117], [117, 118], [119, 121], [122, 129], [130, 136], [137, 144], [144, 145]]}
{"doc_key": "ai-dev-274", "ner": [[1, 1, "organisation"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 9, 10, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "SMR", "is", "very", "similar", "to", "the", "more", "popular", "Jaccard", "index", "."], "sentence-detokenized": "The SMR is very similar to the more popular Jaccard index.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 15], [16, 23], [24, 26], [27, 30], [31, 35], [36, 43], [44, 51], [52, 57], [57, 58]]}
{"doc_key": "ai-dev-275", "ner": [[1, 1, "product"], [3, 7, "product"], [16, 17, "researcher"], [21, 21, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4], "relations": [[1, 1, 16, 17, "artifact", "", false, false], [1, 1, 21, 21, "artifact", "", false, false], [3, 7, 1, 1, "named", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["The", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "is", "an", "industrial", "robot", "arm", "developed", "by", "Victor", "Scheinman", "at", "robotics", "pioneer", "Unimation", "."], "sentence-detokenized": "The PUMA (Programmable Universal Machine for Assembly) is an industrial robot arm developed by Victor Scheinman at robotics pioneer Unimation.", "token2charspan": [[0, 3], [4, 8], [9, 10], [10, 22], [23, 32], [33, 40], [41, 44], [45, 53], [53, 54], [55, 57], [58, 60], [61, 71], [72, 77], [78, 81], [82, 91], [92, 94], [95, 101], [102, 111], [112, 114], [115, 123], [124, 131], [132, 141], [141, 142]]}
{"doc_key": "ai-dev-276", "ner": [[4, 4, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "written", "in", "Python", "."], "sentence-detokenized": "It is written in Python.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 23], [23, 24]]}
{"doc_key": "ai-dev-277", "ner": [[1, 1, "misc"], [0, 0, "misc"], [12, 12, "field"], [14, 15, "field"], [17, 17, "field"], [23, 24, "field"], [26, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7], "relations": [[1, 1, 0, 0, "related-to", "metric_for", true, false], [1, 1, 12, 12, "part-of", "", false, false], [1, 1, 14, 15, "part-of", "", false, false], [1, 1, 17, 17, "part-of", "", false, false], [1, 1, 23, 24, "part-of", "", false, false], [1, 1, 26, 26, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6], "sentence": ["Hertz", "bandwidth", "is", "a", "central", "concept", "in", "many", "fields", ",", "such", "as", "electronics", ",", "information", "theory", ",", "digital", "communications", ",", "radio", "communications", ",", "signal", "processing", "and", "spectroscopy", ",", "and", "is", "one", "of", "the", "determinants", "of", "the", "capacity", "of", "a", "given", "communication", "channel", "."], "sentence-detokenized": "Hertz bandwidth is a central concept in many fields, such as electronics, information theory, digital communications, radio communications, signal processing and spectroscopy, and is one of the determinants of the capacity of a given communication channel.", "token2charspan": [[0, 5], [6, 15], [16, 18], [19, 20], [21, 28], [29, 36], [37, 39], [40, 44], [45, 51], [51, 52], [53, 57], [58, 60], [61, 72], [72, 73], [74, 85], [86, 92], [92, 93], [94, 101], [102, 116], [116, 117], [118, 123], [124, 138], [138, 139], [140, 146], [147, 157], [158, 161], [162, 174], [174, 175], [176, 179], [180, 182], [183, 186], [187, 189], [190, 193], [194, 206], [207, 209], [210, 213], [214, 222], [223, 225], [226, 227], [228, 233], [234, 247], [248, 255], [255, 256]]}
{"doc_key": "ai-dev-278", "ner": [[9, 9, "algorithm"], [11, 11, "algorithm"], [17, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 17, 20, "part-of", "", false, false], [11, 11, 17, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["If", "a", "convex", "loss", "is", "used", "(", "as", "in", "AdaBoost", ",", "LogitBoost", "and", "all", "members", "of", "the", "AnyBoost", "family", "of", "algorithms", ")", ",", "a", "higher", "margin", "example", "will", "receive", "less", "(", "or", "equal", ")", "weight", "than", "a", "lower", "margin", "example", "."], "sentence-detokenized": "If a convex loss is used (as in AdaBoost, LogitBoost and all members of the AnyBoost family of algorithms), a higher margin example will receive less (or equal) weight than a lower margin example.", "token2charspan": [[0, 2], [3, 4], [5, 11], [12, 16], [17, 19], [20, 24], [25, 26], [26, 28], [29, 31], [32, 40], [40, 41], [42, 52], [53, 56], [57, 60], [61, 68], [69, 71], [72, 75], [76, 84], [85, 91], [92, 94], [95, 105], [105, 106], [106, 107], [108, 109], [110, 116], [117, 123], [124, 131], [132, 136], [137, 144], [145, 149], [150, 151], [151, 153], [154, 159], [159, 160], [161, 167], [168, 172], [173, 174], [175, 180], [181, 187], [188, 195], [195, 196]]}
{"doc_key": "ai-dev-279", "ner": [[3, 7, "researcher"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Diploma", "thesis", "of", "Sepp", "Hochreiter", "1991", "Sepp", "Hochreiter", "."], "sentence-detokenized": "Diploma thesis of Sepp Hochreiter 1991 Sepp Hochreiter.", "token2charspan": [[0, 7], [8, 14], [15, 17], [18, 22], [23, 33], [34, 38], [39, 43], [44, 54], [54, 55]]}
{"doc_key": "ai-dev-280", "ner": [[4, 5, "algorithm"], [7, 7, "algorithm"], [10, 12, "algorithm"], [14, 14, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"], [27, 28, "algorithm"], [31, 32, "algorithm"], [34, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 7, 4, 5, "named", "", false, false], [14, 14, 10, 12, "named", "", false, false], [17, 19, 27, 28, "related-to", "", true, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Typical", "discriminative", "models", "include", "logistic", "regression", "(", "LR", ")", ",", "support", "vector", "machines", "(", "SVM", ")", ",", "conditional", "random", "fields", "(", "CRF", ")", "(", "specified", "on", "an", "undirected", "graph", ")", ",", "decision", "trees", ",", "neural", "networks", "and", "many", "others", "."], "sentence-detokenized": "Typical discriminative models include logistic regression (LR), support vector machines (SVM), conditional random fields (CRF) (specified on an undirected graph), decision trees, neural networks and many others.", "token2charspan": [[0, 7], [8, 22], [23, 29], [30, 37], [38, 46], [47, 57], [58, 59], [59, 61], [61, 62], [62, 63], [64, 71], [72, 78], [79, 87], [88, 89], [89, 92], [92, 93], [93, 94], [95, 106], [107, 113], [114, 120], [121, 122], [122, 125], [125, 126], [127, 128], [128, 137], [138, 140], [141, 143], [144, 154], [155, 160], [160, 161], [161, 162], [163, 171], [172, 177], [177, 178], [179, 185], [186, 194], [195, 198], [199, 203], [204, 210], [210, 211]]}
{"doc_key": "ai-dev-281", "ner": [[12, 14, "metrics"], [35, 36, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "then", "also", "possible", "to", "use", "these", "probabilities", "and", "evaluate", "the", "mean", "squared", "error", "(", "or", "some", "similar", "measure", ")", "between", "the", "probabilities", "and", "the", "true", "values", ",", "and", "then", "combine", "this", "with", "the", "confusion", "matrix", "to", "create", "very", "efficient", "fitness", "functions", "for", "logistic", "regression", "."], "sentence-detokenized": "It is then also possible to use these probabilities and evaluate the mean squared error (or some similar measure) between the probabilities and the true values, and then combine this with the confusion matrix to create very efficient fitness functions for logistic regression.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 15], [16, 24], [25, 27], [28, 31], [32, 37], [38, 51], [52, 55], [56, 64], [65, 68], [69, 73], [74, 81], [82, 87], [88, 89], [89, 91], [92, 96], [97, 104], [105, 112], [112, 113], [114, 121], [122, 125], [126, 139], [140, 143], [144, 147], [148, 152], [153, 159], [159, 160], [161, 164], [165, 169], [170, 177], [178, 182], [183, 187], [188, 191], [192, 201], [202, 208], [209, 211], [212, 218], [219, 223], [224, 233], [234, 241], [242, 251], [252, 255], [256, 264], [265, 275], [275, 276]]}
{"doc_key": "ai-dev-282", "ner": [[0, 2, "product"], [6, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 6, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VoiceOver", "first", "appeared", "in", "2005", "in", "Mac", "OS", "X", "Tiger", "(", "10.4", ")", "."], "sentence-detokenized": "VoiceOver first appeared in 2005 in Mac OS X Tiger (10.4).", "token2charspan": [[0, 9], [10, 15], [16, 24], [25, 27], [28, 32], [33, 35], [36, 39], [40, 42], [43, 44], [45, 50], [51, 52], [52, 56], [56, 57], [57, 58]]}
{"doc_key": "ai-dev-283", "ner": [[12, 13, "algorithm"], [18, 20, "misc"], [25, 26, "metrics"], [29, 31, "algorithm"], [61, 63, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 13, 18, 20, "related-to", "applied_to", false, false], [25, 26, 18, 20, "type-of", "", false, false], [25, 26, 29, 31, "related-to", "used_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "practice", ",", "machine", "learning", "algorithms", "cope", "with", "this", "by", "employing", "a", "convex", "approximation", "to", "the", "0", "-", "1", "loss", "function", "(", "such", "as", "the", "hinge", "loss", "for", "the", "support", "vector", "machine", ")", ",", "which", "is", "easier", "to", "optimise", ",", "or", "by", "imposing", "assumptions", "on", "the", "mathP", "(", "x", ",", "y", ")", "/", "math", "distribution", "(", "and", "thus", "cease", "to", "be", "agnostic", "learning", "algorithms", "to", "which", "the", "above", "result", "applies", ")", "."], "sentence-detokenized": "In practice, machine learning algorithms cope with this by employing a convex approximation to the 0-1 loss function (such as the hinge loss for the support vector machine), which is easier to optimise, or by imposing assumptions on the mathP (x, y) / math distribution (and thus cease to be agnostic learning algorithms to which the above result applies).", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 20], [21, 29], [30, 40], [41, 45], [46, 50], [51, 55], [56, 58], [59, 68], [69, 70], [71, 77], [78, 91], [92, 94], [95, 98], [99, 100], [100, 101], [101, 102], [103, 107], [108, 116], [117, 118], [118, 122], [123, 125], [126, 129], [130, 135], [136, 140], [141, 144], [145, 148], [149, 156], [157, 163], [164, 171], [171, 172], [172, 173], [174, 179], [180, 182], [183, 189], [190, 192], [193, 201], [201, 202], [203, 205], [206, 208], [209, 217], [218, 229], [230, 232], [233, 236], [237, 242], [243, 244], [244, 245], [245, 246], [247, 248], [248, 249], [250, 251], [252, 256], [257, 269], [270, 271], [271, 274], [275, 279], [280, 285], [286, 288], [289, 291], [292, 300], [301, 309], [310, 320], [321, 323], [324, 329], [330, 333], [334, 339], [340, 346], [347, 354], [354, 355], [355, 356]]}
{"doc_key": "ai-dev-284", "ner": [[0, 0, "misc"], [11, 13, "field"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 13, "usage", "", false, false], [0, 0, 22, 22, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Westworld", "(", "1973", ")", "was", "the", "first", "feature", "film", "to", "use", "digital", "image", "processing", "to", "simulate", "the", "point", "of", "view", "of", "an", "android", "."], "sentence-detokenized": "Westworld (1973) was the first feature film to use digital image processing to simulate the point of view of an android.", "token2charspan": [[0, 9], [10, 11], [11, 15], [15, 16], [17, 20], [21, 24], [25, 30], [31, 38], [39, 43], [44, 46], [47, 50], [51, 58], [59, 64], [65, 75], [76, 78], [79, 87], [88, 91], [92, 97], [98, 100], [101, 105], [106, 108], [109, 111], [112, 119], [119, 120]]}
{"doc_key": "ai-dev-285", "ner": [[7, 8, "task"], [10, 11, "task"], [13, 13, "task"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nowadays", "it", "is", "also", "commonly", "used", "in", "speech", "recognition", ",", "speech", "synthesis", ",", "diarisation", ",", "Xavier", "Anguera", "et", "al", "."], "sentence-detokenized": "Nowadays it is also commonly used in speech recognition, speech synthesis, diarisation, Xavier Anguera et al.", "token2charspan": [[0, 8], [9, 11], [12, 14], [15, 19], [20, 28], [29, 33], [34, 36], [37, 43], [44, 55], [55, 56], [57, 63], [64, 73], [73, 74], [75, 86], [86, 87], [88, 94], [95, 102], [103, 105], [106, 108], [108, 109]]}
{"doc_key": "ai-dev-286", "ner": [[7, 11, "algorithm"], [15, 16, "algorithm"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 16, 7, 11, "type-of", "", false, false], [19, 21, 7, 11, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Here", ",", "math", "/", "math", "is", "an", "element", "-", "wise", "activation", "function", "such", "as", "a", "sigmoid", "function", "or", "a", "rectified", "linear", "unit", "."], "sentence-detokenized": "Here, math / math is an element-wise activation function such as a sigmoid function or a rectified linear unit.", "token2charspan": [[0, 4], [4, 5], [6, 10], [11, 12], [13, 17], [18, 20], [21, 23], [24, 31], [31, 32], [32, 36], [37, 47], [48, 56], [57, 61], [62, 64], [65, 66], [67, 74], [75, 83], [84, 86], [87, 88], [89, 98], [99, 105], [106, 110], [110, 111]]}
{"doc_key": "ai-dev-287", "ner": [[12, 14, "algorithm"], [23, 23, "misc"], [25, 25, "misc"], [27, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "phonetic", "-", "based", "approaches", "(", "i.e.", "all", "models", "based", "on", "the", "Hidden", "Markov", "model", ")", "required", "separate", "components", "and", "training", "for", "the", "pronunciation", ",", "acoustic", "and", "linguistic", "models", "."], "sentence-detokenized": "Traditional phonetic-based approaches (i.e. all models based on the Hidden Markov model) required separate components and training for the pronunciation, acoustic and linguistic models.", "token2charspan": [[0, 11], [12, 20], [20, 21], [21, 26], [27, 37], [38, 39], [39, 43], [44, 47], [48, 54], [55, 60], [61, 63], [64, 67], [68, 74], [75, 81], [82, 87], [87, 88], [89, 97], [98, 106], [107, 117], [118, 121], [122, 130], [131, 134], [135, 138], [139, 152], [152, 153], [154, 162], [163, 166], [167, 177], [178, 184], [184, 185]]}
{"doc_key": "ai-dev-288", "ner": [[1, 3, "algorithm"], [7, 8, "field"], [10, 11, "field"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 3, 13, 14, "related-to", "used_for", false, false], [7, 8, 1, 3, "usage", "", false, false], [10, 11, 1, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Roberts", "cross", "operator", "is", "used", "in", "image", "processing", "and", "computer", "vision", "for", "edge", "detection", "."], "sentence-detokenized": "The Roberts cross operator is used in image processing and computer vision for edge detection.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 37], [38, 43], [44, 54], [55, 58], [59, 67], [68, 74], [75, 78], [79, 83], [84, 93], [93, 94]]}
{"doc_key": "ai-dev-289", "ner": [[0, 0, "metrics"], [2, 2, "metrics"], [25, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 25, 25, "opposite", "", false, false], [2, 2, 25, 25, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Sensitivity", "and", "specificity", "values", "are", "agnostic", "with", "respect", "to", "the", "percentage", "of", "positive", "cases", "in", "the", "population", "of", "interest", "(", "unlike", ",", "for", "example", ",", "precision", ")", "."], "sentence-detokenized": "Sensitivity and specificity values are agnostic with respect to the percentage of positive cases in the population of interest (unlike, for example, precision).", "token2charspan": [[0, 11], [12, 15], [16, 27], [28, 34], [35, 38], [39, 47], [48, 52], [53, 60], [61, 63], [64, 67], [68, 78], [79, 81], [82, 90], [91, 96], [97, 99], [100, 103], [104, 114], [115, 117], [118, 126], [127, 128], [128, 134], [134, 135], [136, 139], [140, 147], [147, 148], [149, 158], [158, 159], [159, 160]]}
{"doc_key": "ai-dev-290", "ner": [[1, 2, "algorithm"], [9, 9, "misc"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 1, 2, "topic", "", false, false], [9, 9, 11, 12, "artifact", "", false, false], [9, 9, 14, 15, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["But", "perceptron", "models", "became", "very", "unpopular", "with", "the", "book", "Perceptrons", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", ",", "published", "in", "1969", "."], "sentence-detokenized": "But perceptron models became very unpopular with the book Perceptrons by Marvin Minsky and Seymour Papert, published in 1969.", "token2charspan": [[0, 3], [4, 14], [15, 21], [22, 28], [29, 33], [34, 43], [44, 48], [49, 52], [53, 57], [58, 69], [70, 72], [73, 79], [80, 86], [87, 90], [91, 98], [99, 105], [105, 106], [107, 116], [117, 119], [120, 124], [124, 125]]}
{"doc_key": "ai-dev-291", "ner": [[1, 3, "conference"], [8, 8, "organisation"], [23, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 3, 23, 25, "topic", "", false, false], [8, 8, 1, 3, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Document", "Understanding", "Conferences", ",", "organised", "annually", "by", "NIST", ",", "have", "developed", "sophisticated", "evaluation", "criteria", "for", "techniques", "that", "take", "up", "the", "challenge", "of", "multiple", "document", "summarisation", "."], "sentence-detokenized": "The Document Understanding Conferences, organised annually by NIST, have developed sophisticated evaluation criteria for techniques that take up the challenge of multiple document summarisation.", "token2charspan": [[0, 3], [4, 12], [13, 26], [27, 38], [38, 39], [40, 49], [50, 58], [59, 61], [62, 66], [66, 67], [68, 72], [73, 82], [83, 96], [97, 107], [108, 116], [117, 120], [121, 131], [132, 136], [137, 141], [142, 144], [145, 148], [149, 158], [159, 161], [162, 170], [171, 179], [180, 193], [193, 194]]}
{"doc_key": "ai-dev-292", "ner": [[1, 1, "product"], [29, 30, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 29, 30, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "parallel", "manipulator", "is", "designed", "in", "such", "a", "way", "that", "each", "chain", "is", "usually", "short", ",", "single", "and", "therefore", "can", "be", "rigid", "against", "unwanted", "movements", ",", "compared", "to", "a", "serial", "manipulator", "."], "sentence-detokenized": "A parallel manipulator is designed in such a way that each chain is usually short, single and therefore can be rigid against unwanted movements, compared to a serial manipulator.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 34], [35, 37], [38, 42], [43, 44], [45, 48], [49, 53], [54, 58], [59, 64], [65, 67], [68, 75], [76, 81], [81, 82], [83, 89], [90, 93], [94, 103], [104, 107], [108, 110], [111, 116], [117, 124], [125, 133], [134, 143], [143, 144], [145, 153], [154, 156], [157, 158], [159, 165], [166, 177], [177, 178]]}
{"doc_key": "ai-dev-293", "ner": [[25, 25, "misc"], [27, 29, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "manipulator", "is", "what", "makes", "the", "robot", "move", ",", "and", "the", "design", "of", "these", "systems", "can", "be", "classified", "into", "several", "common", "types", ",", "such", "as", "SCARA", "and", "Cartesian", "coordinate", "robot", ",", "which", "use", "different", "coordinate", "systems", "to", "steer", "the", "arms", "of", "the", "machine", "."], "sentence-detokenized": "The manipulator is what makes the robot move, and the design of these systems can be classified into several common types, such as SCARA and Cartesian coordinate robot, which use different coordinate systems to steer the arms of the machine.", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 23], [24, 29], [30, 33], [34, 39], [40, 44], [44, 45], [46, 49], [50, 53], [54, 60], [61, 63], [64, 69], [70, 77], [78, 81], [82, 84], [85, 95], [96, 100], [101, 108], [109, 115], [116, 121], [121, 122], [123, 127], [128, 130], [131, 136], [137, 140], [141, 150], [151, 161], [162, 167], [167, 168], [169, 174], [175, 178], [179, 188], [189, 199], [200, 207], [208, 210], [211, 216], [217, 220], [221, 225], [226, 228], [229, 232], [233, 240], [240, 241]]}
{"doc_key": "ai-dev-294", "ner": [[3, 3, "country"], [10, 13, "organisation"], [16, 21, "organisation"], [24, 27, "organisation"], [30, 32, "organisation"], [35, 41, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 13, 3, 3, "physical", "", false, false], [16, 21, 3, 3, "physical", "", false, false], [24, 27, 3, 3, "physical", "", false, false], [30, 32, 3, 3, "physical", "", false, false], [35, 41, 3, 3, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "United", "States", "he", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "Linguistic", "Society", "of", "America", ",", "the", "American", "Philosophical", "Association", "and", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In the United States he is a member of the National Academy of Sciences, the American Academy of Arts and Sciences, the Linguistic Society of America, the American Philosophical Association and the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 20], [21, 23], [24, 26], [27, 28], [29, 35], [36, 38], [39, 42], [43, 51], [52, 59], [60, 62], [63, 71], [71, 72], [73, 76], [77, 85], [86, 93], [94, 96], [97, 101], [102, 105], [106, 114], [114, 115], [116, 119], [120, 130], [131, 138], [139, 141], [142, 149], [149, 150], [151, 154], [155, 163], [164, 177], [178, 189], [190, 193], [194, 197], [198, 206], [207, 218], [219, 222], [223, 226], [227, 238], [239, 241], [242, 249], [249, 250]]}
{"doc_key": "ai-dev-295", "ner": [[9, 11, "algorithm"], [13, 13, "algorithm"], [20, 20, "algorithm"], [27, 28, "algorithm"], [33, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 11, 20, 20, "named", "", false, false], [13, 13, 9, 11, "named", "", false, false], [20, 20, 27, 28, "compare", "", false, false], [20, 20, 33, 34, "related-to", "performs", false, false], [27, 28, 33, 34, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["They", "came", "to", "prominence", "with", "the", "popularity", "of", "the", "support", "vector", "machine", "(", "SVM", ")", "in", "the", "1990s", ",", "when", "SVM", "was", "found", "to", "be", "competitive", "with", "neural", "networks", "in", "tasks", "such", "as", "handwriting", "recognition", "."], "sentence-detokenized": "They came to prominence with the popularity of the support vector machine (SVM) in the 1990s, when SVM was found to be competitive with neural networks in tasks such as handwriting recognition.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 23], [24, 28], [29, 32], [33, 43], [44, 46], [47, 50], [51, 58], [59, 65], [66, 73], [74, 75], [75, 78], [78, 79], [80, 82], [83, 86], [87, 92], [92, 93], [94, 98], [99, 102], [103, 106], [107, 112], [113, 115], [116, 118], [119, 130], [131, 135], [136, 142], [143, 151], [152, 154], [155, 160], [161, 165], [166, 168], [169, 180], [181, 192], [192, 193]]}
{"doc_key": "ai-dev-296", "ner": [[2, 3, "misc"], [9, 9, "misc"], [13, 14, "algorithm"], [22, 23, "misc"], [27, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 9, "usage", "", false, false], [2, 3, 22, 23, "usage", "", false, false], [9, 9, 13, 14, "origin", "result_of_algorithm", false, false], [22, 23, 27, 28, "origin", "result_of_algorithm", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["An", "empirical", "bleaching", "transform", "is", "obtained", "by", "estimating", "the", "covariance", "(", "e.g.", "by", "maximum", "likelihood", ")", "and", "subsequently", "constructing", "a", "corresponding", "estimated", "bleaching", "matrix", "(", "e.g.", "by", "Cholesky", "decomposition", ")", "."], "sentence-detokenized": "An empirical bleaching transform is obtained by estimating the covariance (e.g. by maximum likelihood) and subsequently constructing a corresponding estimated bleaching matrix (e.g. by Cholesky decomposition).", "token2charspan": [[0, 2], [3, 12], [13, 22], [23, 32], [33, 35], [36, 44], [45, 47], [48, 58], [59, 62], [63, 73], [74, 75], [75, 79], [80, 82], [83, 90], [91, 101], [101, 102], [103, 106], [107, 119], [120, 132], [133, 134], [135, 148], [149, 158], [159, 168], [169, 175], [176, 177], [177, 181], [182, 184], [185, 193], [194, 207], [207, 208], [208, 209]]}
{"doc_key": "ai-dev-297", "ner": [[0, 0, "organisation"], [8, 9, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 0, 0, "artifact", "", false, false], [24, 24, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["IAI", "is", "the", "world", "'s", "largest", "manufacturer", "of", "Cartesian", "coordinate", "robots", "and", "is", "an", "established", "leader", "in", "low", "-", "cost", ",", "high", "-", "performance", "SCARA", "robots", "."], "sentence-detokenized": "IAI is the world's largest manufacturer of Cartesian coordinate robots and is an established leader in low-cost, high-performance SCARA robots.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [16, 18], [19, 26], [27, 39], [40, 42], [43, 52], [53, 63], [64, 70], [71, 74], [75, 77], [78, 80], [81, 92], [93, 99], [100, 102], [103, 106], [106, 107], [107, 111], [111, 112], [113, 117], [117, 118], [118, 129], [130, 135], [136, 142], [142, 143]]}
{"doc_key": "ai-dev-298", "ner": [[10, 11, "field"], [13, 14, "field"], [16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 28, "field"], [30, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["Formal", "concept", "analysis", "finds", "practical", "application", "in", "fields", "such", "as", "data", "mining", ",", "text", "mining", ",", "machine", "learning", ",", "knowledge", "management", ",", "semantic", "web", ",", "software", "development", ",", "chemistry", "and", "biology", "."], "sentence-detokenized": "Formal concept analysis finds practical application in fields such as data mining, text mining, machine learning, knowledge management, semantic web, software development, chemistry and biology.", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 29], [30, 39], [40, 51], [52, 54], [55, 61], [62, 66], [67, 69], [70, 74], [75, 81], [81, 82], [83, 87], [88, 94], [94, 95], [96, 103], [104, 112], [112, 113], [114, 123], [124, 134], [134, 135], [136, 144], [145, 148], [148, 149], [150, 158], [159, 170], [170, 171], [172, 181], [182, 185], [186, 193], [193, 194]]}
{"doc_key": "ai-dev-299", "ner": [[1, 2, "field"], [4, 6, "field"], [10, 11, "field"], [17, 18, "field"], [29, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 17, 18, "part-of", "", false, false], [4, 6, 29, 30, "topic", "", false, false], [10, 11, 4, 6, "named", "", false, false], [17, 18, 1, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", ",", "computational", "learning", "theory", "(", "or", "simply", "learning", "theory", ")", "is", "a", "subfield", "of", "artificial", "intelligence", "devoted", "to", "the", "study", "of", "the", "design", "and", "analysis", "of", "machine", "learning", "algorithms", "."], "sentence-detokenized": "In computer science, computational learning theory (or simply learning theory) is a subfield of artificial intelligence devoted to the study of the design and analysis of machine learning algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 34], [35, 43], [44, 50], [51, 52], [52, 54], [55, 61], [62, 70], [71, 77], [77, 78], [79, 81], [82, 83], [84, 92], [93, 95], [96, 106], [107, 119], [120, 127], [128, 130], [131, 134], [135, 140], [141, 143], [144, 147], [148, 154], [155, 158], [159, 167], [168, 170], [171, 178], [179, 187], [188, 198], [198, 199]]}
{"doc_key": "ai-dev-300", "ner": [[0, 1, "algorithm"], [3, 3, "algorithm"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 0, 1, "named", "", false, false], [10, 10, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Collaborative", "filtering", "(", "CF", ")", "is", "a", "technique", "used", "by", "recommender", "systems", "."], "sentence-detokenized": "Collaborative filtering (CF) is a technique used by recommender systems.", "token2charspan": [[0, 13], [14, 23], [24, 25], [25, 27], [27, 28], [29, 31], [32, 33], [34, 43], [44, 48], [49, 51], [52, 63], [64, 71], [71, 72]]}
{"doc_key": "ai-dev-301", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "false", "positive", "rate", "is", "the", "proportion", "of", "all", "negatives", "that", "still", "give", "positive", "test", "results", ",", "i.e.", "the", "conditional", "probability", "of", "a", "positive", "test", "result", "given", "an", "event", "that", "was", "not", "present", "."], "sentence-detokenized": "The false positive rate is the proportion of all negatives that still give positive test results, i.e. the conditional probability of a positive test result given an event that was not present.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 23], [24, 26], [27, 30], [31, 41], [42, 44], [45, 48], [49, 58], [59, 63], [64, 69], [70, 74], [75, 83], [84, 88], [89, 96], [96, 97], [98, 102], [103, 106], [107, 118], [119, 130], [131, 133], [134, 135], [136, 144], [145, 149], [150, 156], [157, 162], [163, 165], [166, 171], [172, 176], [177, 180], [181, 184], [185, 192], [192, 193]]}
{"doc_key": "ai-dev-302", "ner": [[1, 15, "misc"], [37, 37, "metrics"], [41, 41, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 15, 37, 37, "topic", "", false, false], [1, 15, 41, 41, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "VLDB", "'", "8", ":", "Proceedings", "of", "the", "34th", "International", "Conference", "on", "Very", "Large", "Data", "Bases", ",", "pages", "422--433", ".", "showed", "that", "the", "values", "given", "for", "mathC", "/", "math", "and", "mathK", "/", "math", "generally", "imply", "relatively", "low", "accuracy", "of", "iteratively", "computed", "SimRank", "scores", "."], "sentence-detokenized": "In VLDB '8: Proceedings of the 34th International Conference on Very Large Data Bases, pages 422--433. showed that the values given for mathC / math and mathK / math generally imply relatively low accuracy of iteratively computed SimRank scores.", "token2charspan": [[0, 2], [3, 7], [8, 9], [9, 10], [10, 11], [12, 23], [24, 26], [27, 30], [31, 35], [36, 49], [50, 60], [61, 63], [64, 68], [69, 74], [75, 79], [80, 85], [85, 86], [87, 92], [93, 101], [101, 102], [103, 109], [110, 114], [115, 118], [119, 125], [126, 131], [132, 135], [136, 141], [142, 143], [144, 148], [149, 152], [153, 158], [159, 160], [161, 165], [166, 175], [176, 181], [182, 192], [193, 196], [197, 205], [206, 208], [209, 220], [221, 229], [230, 237], [238, 244], [244, 245]]}
{"doc_key": "ai-dev-303", "ner": [[7, 10, "misc"], [11, 11, "misc"], [17, 18, "person"], [20, 22, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 7, 10, "general-affiliation", "", false, false], [11, 11, 17, 18, "artifact", "", false, false], [11, 11, 20, 22, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["June", "2015", "saw", "the", "premiere", "of", "the", "sci", "-", "fi", "drama", "Sense8", ",", "written", "and", "produced", "by", "the", "Wachowskis", "and", "J.", "Michael", "Straczynski", "."], "sentence-detokenized": "June 2015 saw the premiere of the sci-fi drama Sense8, written and produced by the Wachowskis and J. Michael Straczynski.", "token2charspan": [[0, 4], [5, 9], [10, 13], [14, 17], [18, 26], [27, 29], [30, 33], [34, 37], [37, 38], [38, 40], [41, 46], [47, 53], [53, 54], [55, 62], [63, 66], [67, 75], [76, 78], [79, 82], [83, 93], [94, 97], [98, 100], [101, 108], [109, 120], [120, 121]]}
{"doc_key": "ai-dev-304", "ner": [[1, 1, "misc"], [6, 8, "product"], [26, 28, "misc"], [36, 36, "country"], [38, 38, "country"], [40, 40, "country"], [42, 42, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 1, 6, 8, "topic", "", false, false], [36, 36, 26, 28, "type-of", "", false, false], [38, 38, 26, 28, "type-of", "", false, false], [40, 40, 26, 28, "type-of", "", false, false], [42, 42, 26, 28, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Although", "Eurotra", "never", "delivered", "a", "functioning", "machine", "translation", "system", ",", "the", "project", "had", "a", "major", "long", "-", "term", "impact", "on", "the", "fledgling", "language", "industries", "in", "the", "European", "Member", "States", ",", "particularly", "in", "the", "southern", "countries", "of", "Greece", ",", "Italy", ",", "Spain", "and", "Portugal", "."], "sentence-detokenized": "Although Eurotra never delivered a functioning machine translation system, the project had a major long-term impact on the fledgling language industries in the European Member States, particularly in the southern countries of Greece, Italy, Spain and Portugal.", "token2charspan": [[0, 8], [9, 16], [17, 22], [23, 32], [33, 34], [35, 46], [47, 54], [55, 66], [67, 73], [73, 74], [75, 78], [79, 86], [87, 90], [91, 92], [93, 98], [99, 103], [103, 104], [104, 108], [109, 115], [116, 118], [119, 122], [123, 132], [133, 141], [142, 152], [153, 155], [156, 159], [160, 168], [169, 175], [176, 182], [182, 183], [184, 196], [197, 199], [200, 203], [204, 212], [213, 222], [223, 225], [226, 232], [232, 233], [234, 239], [239, 240], [241, 246], [247, 250], [251, 259], [259, 260]]}
{"doc_key": "ai-dev-305", "ner": [[0, 1, "algorithm"], [7, 8, "task"], [17, 19, "task"], [21, 21, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 0, 1, "usage", "", true, false], [17, 19, 7, 8, "named", "", false, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "autoencoder", "has", "been", "successfully", "applied", "to", "machine", "translation", "of", "human", "languages", ",", "often", "referred", "to", "as", "neural", "machine", "translation", "(", "NMT", ")", "."], "sentence-detokenized": "The autoencoder has been successfully applied to machine translation of human languages, often referred to as neural machine translation (NMT).", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 24], [25, 37], [38, 45], [46, 48], [49, 56], [57, 68], [69, 71], [72, 77], [78, 87], [87, 88], [89, 94], [95, 103], [104, 106], [107, 109], [110, 116], [117, 124], [125, 136], [137, 138], [138, 141], [141, 142], [142, 143]]}
{"doc_key": "ai-dev-306", "ner": [[9, 11, "metrics"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Popular", "examples", "of", "likelihood", "-", "based", "fitness", "functions", "are", "maximum", "likelihood", "estimation", "and", "hinge", "loss", "."], "sentence-detokenized": "Popular examples of likelihood-based fitness functions are maximum likelihood estimation and hinge loss.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 30], [30, 31], [31, 36], [37, 44], [45, 54], [55, 58], [59, 66], [67, 77], [78, 88], [89, 92], [93, 98], [99, 103], [103, 104]]}
{"doc_key": "ai-dev-307", "ner": [[0, 1, "field"], [13, 16, "task"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 16, 0, 1, "part-of", "", false, false], [18, 19, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Data", "mining", "is", "a", "related", "field", "of", "study", ",", "which", "focuses", "on", "the", "exploratory", "analysis", "of", "data", "through", "unsupervised", "learning", "."], "sentence-detokenized": "Data mining is a related field of study, which focuses on the exploratory analysis of data through unsupervised learning.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 16], [17, 24], [25, 30], [31, 33], [34, 39], [39, 40], [41, 46], [47, 54], [55, 57], [58, 61], [62, 73], [74, 82], [83, 85], [86, 90], [91, 98], [99, 111], [112, 120], [120, 121]]}
{"doc_key": "ai-dev-308", "ner": [[0, 1, "algorithm"], [12, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 12, 14, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "filtering", "encompasses", "techniques", "for", "matching", "people", "with", "similar", "interests", "and", "making", "a", "recommendation", "system", "on", "this", "basis", "."], "sentence-detokenized": "Collaborative filtering encompasses techniques for matching people with similar interests and making a recommendation system on this basis.", "token2charspan": [[0, 13], [14, 23], [24, 35], [36, 46], [47, 50], [51, 59], [60, 66], [67, 71], [72, 79], [80, 89], [90, 93], [94, 100], [101, 102], [103, 117], [118, 124], [125, 127], [128, 132], [133, 138], [138, 139]]}
{"doc_key": "ai-dev-309", "ner": [[1, 6, "algorithm"], [11, 11, "programlang"], [14, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 17, 1, 6, "type-of", "", false, false], [14, 17, 11, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Several", "WordNet", "-", "based", "word", "similarity", "algorithms", "are", "implemented", "in", "a", "Perl", "package", "called", "WordNet", ":", ":", "Similarity", "."], "sentence-detokenized": "Several WordNet-based word similarity algorithms are implemented in a Perl package called WordNet:: Similarity.", "token2charspan": [[0, 7], [8, 15], [15, 16], [16, 21], [22, 26], [27, 37], [38, 48], [49, 52], [53, 64], [65, 67], [68, 69], [70, 74], [75, 82], [83, 89], [90, 97], [97, 98], [98, 99], [100, 110], [110, 111]]}
{"doc_key": "ai-dev-310", "ner": [[6, 6, "conference"], [8, 8, "conference"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 8, 6, 6, "named", "", false, false], [12, 13, 6, 6, "temporal", "", false, false], [15, 16, 6, 6, "temporal", "", false, false], [18, 19, 6, 6, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Another", "paper", ",", "presented", "at", "the", "CVPR", "(", "CVPR", ")", "2000", "by", "Erik", "Miller", ",", "Nicholas", "Matsakis", "and", "Paul", "Viola", ",", "will", "also", "be", "discussed", "."], "sentence-detokenized": "Another paper, presented at the CVPR (CVPR) 2000 by Erik Miller, Nicholas Matsakis and Paul Viola, will also be discussed.", "token2charspan": [[0, 7], [8, 13], [13, 14], [15, 24], [25, 27], [28, 31], [32, 36], [37, 38], [38, 42], [42, 43], [44, 48], [49, 51], [52, 56], [57, 63], [63, 64], [65, 73], [74, 82], [83, 86], [87, 91], [92, 97], [97, 98], [99, 103], [104, 108], [109, 111], [112, 121], [121, 122]]}
{"doc_key": "ai-dev-311", "ner": [[0, 0, "algorithm"], [8, 9, "misc"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 14, 15, "compare", "", false, false], [14, 15, 8, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["QC", "has", "not", "been", "evaluated", "against", "traditional", "modern", "clustering", "algorithms", ",", "apart", "from", "the", "Jaccard", "index", "."], "sentence-detokenized": "QC has not been evaluated against traditional modern clustering algorithms, apart from the Jaccard index.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 15], [16, 25], [26, 33], [34, 45], [46, 52], [53, 63], [64, 74], [74, 75], [76, 81], [82, 86], [87, 90], [91, 98], [99, 104], [104, 105]]}
{"doc_key": "ai-dev-312", "ner": [[2, 5, "misc"], [8, 10, "misc"], [14, 15, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 2, 5, "physical", "", false, false], [8, 10, 14, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "the", "VEX", "Robotics", "World", "Championships", ",", "a", "Parade", "of", "Nations", "is", "held", "in", "Freedom", "Hall", "and", "includes", "hundreds", "of", "students", "from", "more", "than", "30", "countries", "."], "sentence-detokenized": "During the VEX Robotics World Championships, a Parade of Nations is held in Freedom Hall and includes hundreds of students from more than 30 countries.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 23], [24, 29], [30, 43], [43, 44], [45, 46], [47, 53], [54, 56], [57, 64], [65, 67], [68, 72], [73, 75], [76, 83], [84, 88], [89, 92], [93, 101], [102, 110], [111, 113], [114, 122], [123, 127], [128, 132], [133, 137], [138, 140], [141, 150], [150, 151]]}
{"doc_key": "ai-dev-313", "ner": [[5, 9, "metrics"], [11, 11, "metrics"], [15, 17, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 5, 9, "named", "", false, false], [19, 19, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Other", "measures", "of", "accuracy", "are", "the", "single", "word", "error", "rate", "(", "SWER", ")", "and", "the", "command", "success", "rate", "(", "CSR", ")", "."], "sentence-detokenized": "Other measures of accuracy are the single word error rate (SWER) and the command success rate (CSR).", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [27, 30], [31, 34], [35, 41], [42, 46], [47, 52], [53, 57], [58, 59], [59, 63], [63, 64], [65, 68], [69, 72], [73, 80], [81, 88], [89, 93], [94, 95], [95, 98], [98, 99], [99, 100]]}
{"doc_key": "ai-dev-314", "ner": [[7, 8, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "presented", "their", "method", "and", "results", "at", "SIGGRAPH", "2000", "."], "sentence-detokenized": "They presented their method and results at SIGGRAPH 2000.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 27], [28, 31], [32, 39], [40, 42], [43, 51], [52, 56], [56, 57]]}
{"doc_key": "ai-dev-315", "ner": [[0, 2, "conference"], [7, 7, "misc"], [9, 13, "misc"], [18, 19, "conference"], [23, 28, "researcher"], [37, 38, "researcher"], [42, 44, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 7, 7, "origin", "", false, false], [7, 7, 18, 19, "physical", "", false, false], [7, 7, 18, 19, "temporal", "", false, false], [7, 7, 23, 28, "origin", "", false, false], [7, 7, 37, 38, "origin", "", false, false], [9, 13, 7, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "KDD", "Conference", "grew", "out", "of", "the", "KDD", "(", "Knowledge", "Discovery", "and", "Data", "Mining", ")", "workshops", "of", "the", "AAAI", "conferences", ",", "initiated", "by", "Gregory", "I", ".", "Piatetsky", "-", "Shapiro", "in", "1989", ",", "1991", "and", "1993", ",", "and", "Usama", "Fayyad", "in", "1994", ".", "Machinery", "|", "ACM", "."], "sentence-detokenized": "The KDD Conference grew out of the KDD (Knowledge Discovery and Data Mining) workshops of the AAAI conferences, initiated by Gregory I. Piatetsky-Shapiro in 1989, 1991 and 1993, and Usama Fayyad in 1994. Machinery | ACM.", "token2charspan": [[0, 3], [4, 7], [8, 18], [19, 23], [24, 27], [28, 30], [31, 34], [35, 38], [39, 40], [40, 49], [50, 59], [60, 63], [64, 68], [69, 75], [75, 76], [77, 86], [87, 89], [90, 93], [94, 98], [99, 110], [110, 111], [112, 121], [122, 124], [125, 132], [133, 134], [134, 135], [136, 145], [145, 146], [146, 153], [154, 156], [157, 161], [161, 162], [163, 167], [168, 171], [172, 176], [176, 177], [178, 181], [182, 187], [188, 194], [195, 197], [198, 202], [202, 203], [204, 213], [214, 215], [216, 219], [219, 220]]}
{"doc_key": "ai-dev-316", "ner": [[8, 11, "conference"], [13, 13, "conference"], [17, 22, "organisation"], [24, 24, "organisation"], [28, 32, "conference"], [34, 34, "conference"], [38, 44, "conference"], [46, 46, "conference"], [50, 55, "conference"], [57, 57, "conference"], [61, 66, "conference"], [68, 68, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[13, 13, 8, 11, "named", "", false, false], [24, 24, 17, 22, "named", "", false, false], [34, 34, 28, 32, "named", "", false, false], [46, 46, 38, 44, "named", "", false, false], [57, 57, 50, 55, "named", "", false, false], [68, 68, 61, 66, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["He", "has", "been", "elected", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", "(", "ACM", ")", ",", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", ",", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", ",", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "the", "American", "Association", "for", "Advancement", "of", "Science", "(", "AAAS", ")", "and", "the", "Society", "for", "Optics", "and", "Photonics", "Technology", "(", "SPIE", ")", "."], "sentence-detokenized": "He has been elected a member of the Association for Computing Machinery (ACM), the Institute of Electrical and Electronics Engineers (IEEE), the International Association for Pattern Recognition (IAPR), the Association for the Advancement of Artificial Intelligence (AAAI), the American Association for Advancement of Science (AAAS) and the Society for Optics and Photonics Technology (SPIE).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 21], [22, 28], [29, 31], [32, 35], [36, 47], [48, 51], [52, 61], [62, 71], [72, 73], [73, 76], [76, 77], [77, 78], [79, 82], [83, 92], [93, 95], [96, 106], [107, 110], [111, 122], [123, 132], [133, 134], [134, 138], [138, 139], [139, 140], [141, 144], [145, 158], [159, 170], [171, 174], [175, 182], [183, 194], [195, 196], [196, 200], [200, 201], [201, 202], [203, 206], [207, 218], [219, 222], [223, 226], [227, 238], [239, 241], [242, 252], [253, 265], [266, 267], [267, 271], [271, 272], [272, 273], [274, 277], [278, 286], [287, 298], [299, 302], [303, 314], [315, 317], [318, 325], [326, 327], [327, 331], [331, 332], [333, 336], [337, 340], [341, 348], [349, 352], [353, 359], [360, 363], [364, 373], [374, 384], [385, 386], [386, 390], [390, 391], [391, 392]]}
{"doc_key": "ai-dev-317", "ner": [[0, 1, "field"], [3, 3, "field"], [16, 17, "field"], [4, 32, "field"], [53, 56, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 17, "named", "", false, false], [3, 3, 4, 32, "named", "", false, false], [4, 32, 53, 56, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "learning", "and", "data", "mining", "often", "employ", "the", "same", "methods", "and", "overlap", "significantly", ",", "but", "while", "machine", "learning", "focuses", "on", "prediction", ",", "based", "on", "known", "properties", "learned", "from", "training", "data", ",", "data", "mining", "focuses", "on", "the", "discovery", "of", "(", "previously", ")", "unknown", "properties", "in", "the", "data", "(", "it", "is", "the", "analysis", "step", "of", "knowledge", "discovery", "in", "databases", ")", "."], "sentence-detokenized": "Machine learning and data mining often employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on known properties learned from training data, data mining focuses on the discovery of (previously) unknown properties in the data (it is the analysis step of knowledge discovery in databases).", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 25], [26, 32], [33, 38], [39, 45], [46, 49], [50, 54], [55, 62], [63, 66], [67, 74], [75, 88], [88, 89], [90, 93], [94, 99], [100, 107], [108, 116], [117, 124], [125, 127], [128, 138], [138, 139], [140, 145], [146, 148], [149, 154], [155, 165], [166, 173], [174, 178], [179, 187], [188, 192], [192, 193], [194, 198], [199, 205], [206, 213], [214, 216], [217, 220], [221, 230], [231, 233], [234, 235], [235, 245], [245, 246], [247, 254], [255, 265], [266, 268], [269, 272], [273, 277], [278, 279], [279, 281], [282, 284], [285, 288], [289, 297], [298, 302], [303, 305], [306, 315], [316, 325], [326, 328], [329, 338], [338, 339], [339, 340]]}
{"doc_key": "ai-dev-318", "ner": [[0, 0, "product"], [4, 4, "programlang"], [11, 11, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "general-affiliation", "", false, false], [0, 0, 4, 4, "related-to", "runs_on", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Indy", "is", "written", "in", "Java", "and", "therefore", "runs", "on", "most", "modern", "operating", "systems", "."], "sentence-detokenized": "Indy is written in Java and therefore runs on most modern operating systems.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 23], [24, 27], [28, 37], [38, 42], [43, 45], [46, 50], [51, 57], [58, 67], [68, 75], [75, 76]]}
{"doc_key": "ai-dev-319", "ner": [[0, 1, "algorithm"], [6, 8, "algorithm"], [10, 10, "algorithm"], [16, 18, "algorithm"], [20, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 6, 8, "type-of", "", true, false], [10, 10, 6, 8, "named", "", false, false], [16, 18, 6, 8, "type-of", "", true, false], [20, 20, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "NMF", "is", "an", "instance", "of", "non-negative", "quadratic", "programming", "(", "NQP", ")", ",", "as", "is", "the", "support", "vector", "machine", "(", "SVM", ")", "."], "sentence-detokenized": "The NMF is an instance of non-negative quadratic programming (NQP), as is the support vector machine (SVM).", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 13], [14, 22], [23, 25], [26, 38], [39, 48], [49, 60], [61, 62], [62, 65], [65, 66], [66, 67], [68, 70], [71, 73], [74, 77], [78, 85], [86, 92], [93, 100], [101, 102], [102, 105], [105, 106], [106, 107]]}
{"doc_key": "ai-dev-320", "ner": [[9, 10, "misc"], [13, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 10, 13, 15, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["The", "method", "is", "based", "on", "the", "estimation", "of", "the", "conditional", "probabilities", "using", "the", "non-parametric", "maximum", "likelihood", "method", "leading", "to"], "sentence-detokenized": "The method is based on the estimation of the conditional probabilities using the non-parametric maximum likelihood method leading to", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 26], [27, 37], [38, 40], [41, 44], [45, 56], [57, 70], [71, 76], [77, 80], [81, 95], [96, 103], [104, 114], [115, 121], [122, 129], [130, 132]]}
{"doc_key": "ai-dev-321", "ner": [[7, 7, "algorithm"], [9, 11, "algorithm"], [13, 15, "metrics"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "basic", "concepts", "of", "spectral", "estimation", "are", "autocorrelation", ",", "multidimensional", "Fourier", "transform", ",", "mean", "square", "error", "and", "entropy", "."], "sentence-detokenized": "The basic concepts of spectral estimation are autocorrelation, multidimensional Fourier transform, mean square error and entropy.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 21], [22, 30], [31, 41], [42, 45], [46, 61], [61, 62], [63, 79], [80, 87], [88, 97], [97, 98], [99, 103], [104, 110], [111, 116], [117, 120], [121, 128], [128, 129]]}
{"doc_key": "ai-dev-322", "ner": [[4, 5, "algorithm"], [10, 10, "field"], [12, 12, "algorithm"], [14, 16, "algorithm"], [18, 19, "task"], [21, 21, "field"], [23, 23, "field"], [25, 26, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[4, 5, 10, 10, "part-of", "", false, false], [4, 5, 12, 12, "part-of", "", false, false], [4, 5, 14, 16, "part-of", "", false, false], [4, 5, 18, 19, "part-of", "", false, false], [4, 5, 21, 21, "part-of", "", false, false], [4, 5, 23, 23, "part-of", "", false, false], [4, 5, 25, 26, "part-of", "", false, false], [4, 5, 28, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "application", "areas", "of", "kernel", "methods", "are", "diverse", "and", "include", "geostatistics", ",", "kriging", ",", "inverse", "distance", "weighting", ",", "3D", "reconstruction", ",", "bioinformatics", ",", "chemoinformatics", ",", "information", "extraction", "and", "handwriting", "recognition", "."], "sentence-detokenized": "The application areas of kernel methods are diverse and include geostatistics, kriging, inverse distance weighting, 3D reconstruction, bioinformatics, chemoinformatics, information extraction and handwriting recognition.", "token2charspan": [[0, 3], [4, 15], [16, 21], [22, 24], [25, 31], [32, 39], [40, 43], [44, 51], [52, 55], [56, 63], [64, 77], [77, 78], [79, 86], [86, 87], [88, 95], [96, 104], [105, 114], [114, 115], [116, 118], [119, 133], [133, 134], [135, 149], [149, 150], [151, 167], [167, 168], [169, 180], [181, 191], [192, 195], [196, 207], [208, 219], [219, 220]]}
{"doc_key": "ai-dev-323", "ner": [[12, 12, "organisation"], [14, 18, "product"], [20, 20, "product"], [25, 25, "organisation"], [26, 29, "product"], [31, 31, "product"], [35, 35, "product"], [38, 40, "product"], [42, 44, "product"], [46, 48, "product"], [52, 53, "product"], [55, 56, "product"], [59, 65, "product"], [69, 72, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[14, 18, 12, 12, "artifact", "", false, false], [14, 18, 35, 35, "compare", "", false, false], [14, 18, 38, 40, "compare", "", false, false], [14, 18, 42, 44, "compare", "", false, false], [14, 18, 46, 48, "compare", "", false, false], [14, 18, 52, 53, "compare", "", false, false], [14, 18, 55, 56, "compare", "", false, false], [14, 18, 59, 65, "compare", "", false, false], [14, 18, 69, 72, "compare", "", false, false], [20, 20, 14, 18, "named", "", false, false], [26, 29, 25, 25, "artifact", "", false, false], [26, 29, 35, 35, "compare", "", false, false], [26, 29, 38, 40, "compare", "", false, false], [26, 29, 42, 44, "compare", "", false, false], [26, 29, 46, 48, "compare", "", false, false], [26, 29, 52, 53, "compare", "", false, false], [26, 29, 55, 56, "compare", "", false, false], [26, 29, 59, 65, "compare", "", false, false], [26, 29, 69, 72, "compare", "", false, false], [31, 31, 26, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "sentence": ["Robots", "can", "be", "autonomous", "or", "semi-autonomous", "and", "range", "from", "humanoids", "such", "as", "Honda", "'s", "Advanced", "Step", "in", "Innovative", "Mobility", "(", "ASIMO", ")", "and", "TOSY", "'s", "TOSY", "Ping", "Pong", "Playing", "Robot", "(", "TOPIO", ")", ",", "to", "industrial", "robots", ",", "medical", "operating", "robots", ",", "patient", "assistance", "robots", ",", "canine", "therapy", "robots", ",", "collectively", "programmed", "swarm", "robots", ",", "UAV", "drones", "such", "as", "General", "Atomics", "'", "MQ", "-", "1", "Predator", ",", "and", "even", "microscopic", "nano", "-", "robots", "."], "sentence-detokenized": "Robots can be autonomous or semi-autonomous and range from humanoids such as Honda's Advanced Step in Innovative Mobility (ASIMO) and TOSY's TOSY Ping Pong Playing Robot (TOPIO), to industrial robots, medical operating robots, patient assistance robots, canine therapy robots, collectively programmed swarm robots, UAV drones such as General Atomics' MQ-1 Predator, and even microscopic nano-robots.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 24], [25, 27], [28, 43], [44, 47], [48, 53], [54, 58], [59, 68], [69, 73], [74, 76], [77, 82], [82, 84], [85, 93], [94, 98], [99, 101], [102, 112], [113, 121], [122, 123], [123, 128], [128, 129], [130, 133], [134, 138], [138, 140], [141, 145], [146, 150], [151, 155], [156, 163], [164, 169], [170, 171], [171, 176], [176, 177], [177, 178], [179, 181], [182, 192], [193, 199], [199, 200], [201, 208], [209, 218], [219, 225], [225, 226], [227, 234], [235, 245], [246, 252], [252, 253], [254, 260], [261, 268], [269, 275], [275, 276], [277, 289], [290, 300], [301, 306], [307, 313], [313, 314], [315, 318], [319, 325], [326, 330], [331, 333], [334, 341], [342, 349], [349, 350], [351, 353], [353, 354], [354, 355], [356, 364], [364, 365], [366, 369], [370, 374], [375, 386], [387, 391], [391, 392], [392, 398], [398, 399]]}
{"doc_key": "ai-dev-324", "ner": [[0, 0, "product"], [2, 3, "product"], [8, 13, "university"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [24, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 15, 16, "artifact", "", false, false], [0, 0, 18, 19, "artifact", "", false, false], [0, 0, 21, 22, "artifact", "", false, false], [0, 0, 24, 25, "artifact", "", false, false], [2, 3, 15, 16, "artifact", "", false, false], [2, 3, 18, 19, "artifact", "", false, false], [2, 3, 21, 22, "artifact", "", false, false], [2, 3, 24, 25, "artifact", "", false, false], [15, 16, 8, 13, "physical", "", false, false], [18, 19, 8, 13, "physical", "", false, false], [21, 22, 8, 13, "physical", "", false, false], [24, 25, 8, 13, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Freddy", "and", "Freddy", "II", "were", "robots", "built", "at", "Edinburgh", "University", "'s", "School", "of", "Computing", "by", "Pat", "Ambler", ",", "Robin", "Popplestone", ",", "Austin", "Tate", "and", "Donald", "Mitchie", ",", "and", "were", "capable", "of", "assembling", "wooden", "blocks", "over", "a", "period", "of", "several", "hours", "."], "sentence-detokenized": "Freddy and Freddy II were robots built at Edinburgh University's School of Computing by Pat Ambler, Robin Popplestone, Austin Tate and Donald Mitchie, and were capable of assembling wooden blocks over a period of several hours.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 20], [21, 25], [26, 32], [33, 38], [39, 41], [42, 51], [52, 62], [62, 64], [65, 71], [72, 74], [75, 84], [85, 87], [88, 91], [92, 98], [98, 99], [100, 105], [106, 117], [117, 118], [119, 125], [126, 130], [131, 134], [135, 141], [142, 149], [149, 150], [151, 154], [155, 159], [160, 167], [168, 170], [171, 181], [182, 188], [189, 195], [196, 200], [201, 202], [203, 209], [210, 212], [213, 220], [221, 226], [226, 227]]}
{"doc_key": "ai-dev-325", "ner": [[5, 5, "location"], [7, 7, "country"], [15, 17, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 7, 7, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "spent", "his", "childhood", "in", "Paris", ",", "France", ",", "where", "his", "parents", "had", "emigrated", "from", "Lithuania", "in", "the", "early", "1920s", "."], "sentence-detokenized": "He spent his childhood in Paris, France, where his parents had emigrated from Lithuania in the early 1920s.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 22], [23, 25], [26, 31], [31, 32], [33, 39], [39, 40], [41, 46], [47, 50], [51, 58], [59, 62], [63, 72], [73, 77], [78, 87], [88, 90], [91, 94], [95, 100], [101, 106], [106, 107]]}
{"doc_key": "ai-dev-326", "ner": [[2, 3, "researcher"], [6, 10, "misc"], [16, 19, "organisation"], [12, 15, "university"], [28, 32, "university"], [39, 40, "university"], [43, 45, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 3, 6, 10, "role", "", false, false], [2, 3, 12, 15, "physical", "", false, false], [2, 3, 28, 32, "role", "", false, false], [2, 3, 39, 40, "role", "", false, false], [2, 3, 43, 45, "role", "", false, false], [6, 10, 16, 19, "part-of", "", false, false], [16, 19, 12, 15, "part-of", "", false, false], [39, 40, 28, 32, "part-of", "", false, false], [43, 45, 28, 32, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Previously", ",", "Dr.", "Paulos", "held", "the", "Cooper-", "Siegel", "Associate", "Professor", "Chair", "at", "Carnegie", "Mellon", "University", "'s", "School", "of", "Computer", "Science", ",", "where", "he", "was", "a", "professor", "in", "the", "Human", "-", "Computer", "Interaction", "Institute", ",", "with", "courtesy", "appointments", "in", "the", "Robotics", "Institute", "and", "the", "Entertainment", "Technology", "Center", "."], "sentence-detokenized": "Previously, Dr. Paulos held the Cooper-Siegel Associate Professor Chair at Carnegie Mellon University's School of Computer Science, where he was a professor in the Human-Computer Interaction Institute, with courtesy appointments in the Robotics Institute and the Entertainment Technology Center.", "token2charspan": [[0, 10], [10, 11], [12, 15], [16, 22], [23, 27], [28, 31], [32, 39], [39, 45], [46, 55], [56, 65], [66, 71], [72, 74], [75, 83], [84, 90], [91, 101], [101, 103], [104, 110], [111, 113], [114, 122], [123, 130], [130, 131], [132, 137], [138, 140], [141, 144], [145, 146], [147, 156], [157, 159], [160, 163], [164, 169], [169, 170], [170, 178], [179, 190], [191, 200], [200, 201], [202, 206], [207, 215], [216, 228], [229, 231], [232, 235], [236, 244], [245, 254], [255, 258], [259, 262], [263, 276], [277, 287], [288, 294], [294, 295]]}
{"doc_key": "ai-dev-327", "ner": [[3, 4, "researcher"], [6, 7, "university"], [10, 11, "product"], [17, 21, "product"], [26, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 6, 7, "physical", "", false, false], [3, 4, 6, 7, "role", "", false, false], [10, 11, 3, 4, "artifact", "", false, false], [10, 11, 17, 21, "type-of", "", false, false], [10, 11, 26, 27, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1969", ",", "Victor", "Scheinman", "of", "Stanford", "University", "invented", "the", "Stanford", "arm", ",", "an", "all", "-", "electric", "6", "-", "axis", "articulated", "robot", "designed", "to", "enable", "an", "arm", "solution", "."], "sentence-detokenized": "In 1969, Victor Scheinman of Stanford University invented the Stanford arm, an all-electric 6-axis articulated robot designed to enable an arm solution.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 25], [26, 28], [29, 37], [38, 48], [49, 57], [58, 61], [62, 70], [71, 74], [74, 75], [76, 78], [79, 82], [82, 83], [83, 91], [92, 93], [93, 94], [94, 98], [99, 110], [111, 116], [117, 125], [126, 128], [129, 135], [136, 138], [139, 142], [143, 151], [151, 152]]}
{"doc_key": "ai-dev-328", "ner": [[5, 5, "product"], [15, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 15, 16, "related-to", "", false, false], [5, 5, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "creation", "and", "implementation", "of", "chatbots", "is", "still", "a", "developing", "area", ",", "strongly", "related", "to", "artificial", "intelligence", "and", "machine", "learning", ",", "so", "the", "solutions", "provided", ",", "while", "having", "obvious", "advantages", ",", "have", "some", "important", "limitations", "in", "terms", "of", "functionalities", "and", "use", "cases", "."], "sentence-detokenized": "The creation and implementation of chatbots is still a developing area, strongly related to artificial intelligence and machine learning, so the solutions provided, while having obvious advantages, have some important limitations in terms of functionalities and use cases.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 31], [32, 34], [35, 43], [44, 46], [47, 52], [53, 54], [55, 65], [66, 70], [70, 71], [72, 80], [81, 88], [89, 91], [92, 102], [103, 115], [116, 119], [120, 127], [128, 136], [136, 137], [138, 140], [141, 144], [145, 154], [155, 163], [163, 164], [165, 170], [171, 177], [178, 185], [186, 196], [196, 197], [198, 202], [203, 207], [208, 217], [218, 229], [230, 232], [233, 238], [239, 241], [242, 257], [258, 261], [262, 265], [266, 271], [271, 272]]}
{"doc_key": "ai-dev-329", "ner": [[7, 9, "university"], [11, 12, "product"], [20, 21, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 7, 9, "part-of", "", true, false], [20, 21, 11, 12, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "terms", "of", "freely", "available", "resources", ",", "Carnegie", "Mellon", "University", "'s", "Sphinx", "toolkit", "is", "a", "starting", "point", "to", "learn", "about", "speech", "recognition", "and", "start", "experimenting", "."], "sentence-detokenized": "In terms of freely available resources, Carnegie Mellon University's Sphinx toolkit is a starting point to learn about speech recognition and start experimenting.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 18], [19, 28], [29, 38], [38, 39], [40, 48], [49, 55], [56, 66], [66, 68], [69, 75], [76, 83], [84, 86], [87, 88], [89, 97], [98, 103], [104, 106], [107, 112], [113, 118], [119, 125], [126, 137], [138, 141], [142, 147], [148, 161], [161, 162]]}
{"doc_key": "ai-dev-330", "ner": [[0, 3, "misc"], [13, 16, "misc"], [18, 18, "misc"], [22, 22, "university"], [24, 24, "location"], [26, 26, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 13, 16, "temporal", "", false, false], [18, 18, 13, 16, "named", "", false, false], [18, 18, 24, 24, "physical", "", false, false], [22, 22, 18, 18, "role", "", false, false], [24, 24, 26, 26, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "formal", "RoboCup", "competition", "was", "preceded", "by", "the", "(", "often", "unrecognised", ")", "first", "Microrobot", "International", "Soccer", "Tournament", "(", "MIROSOT", ")", "held", "by", "KAIST", "in", "Taejon", ",", "Korea", ",", "in", "November", "1996", "."], "sentence-detokenized": "The formal RoboCup competition was preceded by the (often unrecognised) first Microrobot International Soccer Tournament (MIROSOT) held by KAIST in Taejon, Korea, in November 1996.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 30], [31, 34], [35, 43], [44, 46], [47, 50], [51, 52], [52, 57], [58, 70], [70, 71], [72, 77], [78, 88], [89, 102], [103, 109], [110, 120], [121, 122], [122, 129], [129, 130], [131, 135], [136, 138], [139, 144], [145, 147], [148, 154], [154, 155], [156, 161], [161, 162], [163, 165], [166, 174], [175, 179], [179, 180]]}
{"doc_key": "ai-dev-331", "ner": [[5, 5, "metrics"], [24, 25, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", "to", "the", "standard", "hinge", "loss", "math", "(", "1-", "yf", "(", "x", ")", ")", "_", "+", "/", "math", "for", "labelled", "data", ",", "a", "loss", "function", "math", "(", "-", "1", "|", "f", "(", "x", ")", "|", ")", "_", "+", "/", "math", "is", "introduced", "on", "unlabelled", "data", "letting", "math", "=", "operator", "name", "{", "sign", "}", "{", "f", "(", "x", ")", "}", "/", "math", "."], "sentence-detokenized": "In addition to the standard hinge loss math(1-yf (x)) _ + / math for labelled data, a loss function math (-1 | f (x) |) _ + / math is introduced on unlabelled data letting math = operator name {sign} {f (x)} / math.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 27], [28, 33], [34, 38], [39, 43], [43, 44], [44, 46], [46, 48], [49, 50], [50, 51], [51, 52], [52, 53], [54, 55], [56, 57], [58, 59], [60, 64], [65, 68], [69, 77], [78, 82], [82, 83], [84, 85], [86, 90], [91, 99], [100, 104], [105, 106], [106, 107], [107, 108], [109, 110], [111, 112], [113, 114], [114, 115], [115, 116], [117, 118], [118, 119], [120, 121], [122, 123], [124, 125], [126, 130], [131, 133], [134, 144], [145, 147], [148, 158], [159, 163], [164, 171], [172, 176], [177, 178], [179, 187], [188, 192], [193, 194], [194, 198], [198, 199], [200, 201], [201, 202], [203, 204], [204, 205], [205, 206], [206, 207], [208, 209], [210, 214], [214, 215]]}
{"doc_key": "ai-dev-332", "ner": [[3, 4, "misc"], [10, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 10, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "particular", ",", "the", "RLS", "is", "designed", "to", "minimise", "the", "mean", "square", "error", "between", "predicted", "values", "and", "TRUE", "labels", ",", "subject", "to", "regularisation", "."], "sentence-detokenized": "In particular, the RLS is designed to minimise the mean square error between predicted values and TRUE labels, subject to regularisation.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 22], [23, 25], [26, 34], [35, 37], [38, 46], [47, 50], [51, 55], [56, 62], [63, 68], [69, 76], [77, 86], [87, 93], [94, 97], [98, 102], [103, 109], [109, 110], [111, 118], [119, 121], [122, 136], [136, 137]]}
{"doc_key": "ai-dev-333", "ner": [[4, 6, "algorithm"], [9, 10, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Essentially", ",", "this", "combines", "maximum", "likelihood", "estimation", "with", "a", "regularisation", "procedure", "that", "favours", "simpler", "models", "over", "more", "complex", "ones", "."], "sentence-detokenized": "Essentially, this combines maximum likelihood estimation with a regularisation procedure that favours simpler models over more complex ones.", "token2charspan": [[0, 11], [11, 12], [13, 17], [18, 26], [27, 34], [35, 45], [46, 56], [57, 61], [62, 63], [64, 78], [79, 88], [89, 93], [94, 101], [102, 109], [110, 116], [117, 121], [122, 126], [127, 134], [135, 139], [139, 140]]}
{"doc_key": "ai-dev-334", "ner": [[1, 3, "metrics"], [9, 9, "metrics"], [11, 11, "metrics"], [14, 15, "misc"], [18, 19, "misc"], [32, 34, "algorithm"], [37, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 9, 1, 3, "named", "", false, false], [11, 11, 1, 3, "named", "", false, false], [14, 15, 18, 19, "related-to", "", false, false], [14, 15, 32, 34, "related-to", "ratio", false, false], [32, 34, 37, 39, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "true", "positive", "rate", "is", "also", "known", "as", "the", "sensitivity", ",", "recall", "or", "mathematical", "detection", "probability", "to", "the", "discrimination", "threshold", ")", "of", "the", "probability", "of", "detection", "on", "the", "y", "-axis", "versus", "the", "cumulative", "distribution", "function", "of", "the", "false", "alarm", "probability", "on", "the", "x-", "axis", "."], "sentence-detokenized": "The true positive rate is also known as the sensitivity, recall or mathematical detection probability to the discrimination threshold) of the probability of detection on the y-axis versus the cumulative distribution function of the false alarm probability on the x-axis.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 25], [26, 30], [31, 36], [37, 39], [40, 43], [44, 55], [55, 56], [57, 63], [64, 66], [67, 79], [80, 89], [90, 101], [102, 104], [105, 108], [109, 123], [124, 133], [133, 134], [135, 137], [138, 141], [142, 153], [154, 156], [157, 166], [167, 169], [170, 173], [174, 175], [175, 180], [181, 187], [188, 191], [192, 202], [203, 215], [216, 224], [225, 227], [228, 231], [232, 237], [238, 243], [244, 255], [256, 258], [259, 262], [263, 265], [265, 269], [269, 270]]}
{"doc_key": "ai-dev-335", "ner": [[3, 3, "misc"], [0, 1, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 3, 3, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Word", "Net", "is", "an", "example", "of", "a", "semantic", "network", "."], "sentence-detokenized": "WordNet is an example of a semantic network.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 13], [14, 21], [22, 24], [25, 26], [27, 35], [36, 43], [43, 44]]}
{"doc_key": "ai-dev-336", "ner": [[3, 5, "product"], [9, 10, "product"], [25, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[25, 27, 3, 5, "usage", "", false, false], [25, 27, 9, 10, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolonged", "use", "of", "speech", "recognition", "software", "in", "conjunction", "with", "word", "processing", "has", "been", "shown", "to", "be", "beneficial", "in", "strengthening", "short", "-", "term", "memory", "in", "patients", "with", "brain", "AVM", "who", "have", "been", "treated", "with", "resection", "."], "sentence-detokenized": "Prolonged use of speech recognition software in conjunction with word processing has been shown to be beneficial in strengthening short-term memory in patients with brain AVM who have been treated with resection.", "token2charspan": [[0, 9], [10, 13], [14, 16], [17, 23], [24, 35], [36, 44], [45, 47], [48, 59], [60, 64], [65, 69], [70, 80], [81, 84], [85, 89], [90, 95], [96, 98], [99, 101], [102, 112], [113, 115], [116, 129], [130, 135], [135, 136], [136, 140], [141, 147], [148, 150], [151, 159], [160, 164], [165, 170], [171, 174], [175, 178], [179, 183], [184, 188], [189, 196], [197, 201], [202, 211], [211, 212]]}
{"doc_key": "ai-dev-337", "ner": [[8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Its", "founding", "editors", "-", "in", "-", "chief", "were", "Ron", "Sun", ",", "Vasant", "Honavar", "and", "Gregg", "Oden", "(", "from", "1999", "to", "2014", ")", "."], "sentence-detokenized": "Its founding editors-in-chief were Ron Sun, Vasant Honavar and Gregg Oden (from 1999 to 2014).", "token2charspan": [[0, 3], [4, 12], [13, 20], [20, 21], [21, 23], [23, 24], [24, 29], [30, 34], [35, 38], [39, 42], [42, 43], [44, 50], [51, 58], [59, 62], [63, 68], [69, 73], [74, 75], [75, 79], [80, 84], [85, 87], [88, 92], [92, 93], [93, 94]]}
{"doc_key": "ai-dev-338", "ner": [[8, 9, "product"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 14, 15, "opposite", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Its", "\"", "parallel", "\"", "distinction", ",", "unlike", "a", "serial", "manipulator", ",", "is", "that", "the", "end", "-effector", "(", "or", "\"", "hand", "\"", ")", "of", "this", "link", "(", "or", "\"", "arm", "\"", ")", "is", "directly", "connected", "to", "it", "s", "base", "by", "a", "series", "of", "separate", "and", "independent", "links", "(", "typically", "three", "or", "six", ")", "working", "simultaneously", "."], "sentence-detokenized": "Its \"parallel\" distinction, unlike a serial manipulator, is that the end-effector (or \"hand\") of this link (or \"arm\") is directly connected to its base by a series of separate and independent links (typically three or six) working simultaneously.", "token2charspan": [[0, 3], [4, 5], [5, 13], [13, 14], [15, 26], [26, 27], [28, 34], [35, 36], [37, 43], [44, 55], [55, 56], [57, 59], [60, 64], [65, 68], [69, 72], [72, 81], [82, 83], [83, 85], [86, 87], [87, 91], [91, 92], [92, 93], [94, 96], [97, 101], [102, 106], [107, 108], [108, 110], [111, 112], [112, 115], [115, 116], [116, 117], [118, 120], [121, 129], [130, 139], [140, 142], [143, 145], [145, 146], [147, 151], [152, 154], [155, 156], [157, 163], [164, 166], [167, 175], [176, 179], [180, 191], [192, 197], [198, 199], [199, 208], [209, 214], [215, 217], [218, 221], [221, 222], [223, 230], [231, 245], [245, 246]]}
{"doc_key": "ai-dev-339", "ner": [[5, 6, "researcher"], [16, 17, "researcher"], [18, 19, "researcher"], [21, 31, "researcher"], [24, 25, "researcher"], [27, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "thesis", "supervisor", "was", "Professor", "Cordell", "Green", ",", "and", "his", "thesis", "/", "oral", "committee", "included", "Professors", "Edward", "Feigenbaum", "Joshua", "Lederberg", ",", "Paul", "Cohen", ",", "Allen", "Newell", ",", "Herbert", "Simon", ",", "Paul", "Cohen", ",", "Herbert", "Simon", "."], "sentence-detokenized": "His thesis supervisor was Professor Cordell Green, and his thesis/oral committee included Professors Edward Feigenbaum Joshua Lederberg, Paul Cohen, Allen Newell, Herbert Simon, Paul Cohen, Herbert Simon.", "token2charspan": [[0, 3], [4, 10], [11, 21], [22, 25], [26, 35], [36, 43], [44, 49], [49, 50], [51, 54], [55, 58], [59, 65], [65, 66], [66, 70], [71, 80], [81, 89], [90, 100], [101, 107], [108, 118], [119, 125], [126, 135], [135, 136], [137, 141], [142, 147], [147, 148], [149, 154], [155, 161], [161, 162], [163, 170], [171, 176], [176, 177], [178, 182], [183, 188], [188, 189], [190, 197], [198, 203], [203, 204]]}
{"doc_key": "ai-dev-340", "ner": [[3, 4, "metrics"], [7, 9, "metrics"], [11, 13, "metrics"], [15, 17, "metrics"], [21, 21, "metrics"], [23, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "functions", "include", "mean", "square", "error", ",", "mean", "square", "error", ",", "mean", "absolute", "error", ",", "relative", "square", "error", ",", "relative", "square", "error", ",", "relative", "absolute", "error", "and", "others", "."], "sentence-detokenized": "Such functions include mean square error, mean square error, mean absolute error, relative square error, relative square error, relative absolute error and others.", "token2charspan": [[0, 4], [5, 14], [15, 22], [23, 27], [28, 34], [35, 40], [40, 41], [42, 46], [47, 53], [54, 59], [59, 60], [61, 65], [66, 74], [75, 80], [80, 81], [82, 90], [91, 97], [98, 103], [103, 104], [105, 113], [114, 120], [121, 126], [126, 127], [128, 136], [137, 145], [146, 151], [152, 155], [156, 162], [162, 163]]}
{"doc_key": "ai-dev-341", "ner": [[4, 4, "programlang"], [6, 6, "programlang"], [8, 8, "product"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "links", "in", "Python", ",", "Java", "and", "MATLAB", "/", "OCTAVE", "."], "sentence-detokenized": "There are links in Python, Java and MATLAB / OCTAVE.", "token2charspan": [[0, 5], [6, 9], [10, 15], [16, 18], [19, 25], [25, 26], [27, 31], [32, 35], [36, 42], [43, 44], [45, 51], [51, 52]]}
{"doc_key": "ai-dev-342", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "MATLAB", "implementation", "can", "be", "found", "in", "the", "."], "sentence-detokenized": "A MATLAB implementation can be found in the.", "token2charspan": [[0, 1], [2, 8], [9, 23], [24, 27], [28, 30], [31, 36], [37, 39], [40, 43], [43, 44]]}
{"doc_key": "ai-dev-343", "ner": [[0, 1, "researcher"], [9, 10, "field"], [14, 15, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 10, 0, 1, "origin", "", false, false], [9, 10, 14, 15, "origin", "", false, false], [9, 10, 17, 18, "origin", "", false, false], [9, 10, 20, 21, "origin", "", false, false], [9, 10, 23, 26, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["John", "McCarthy", "is", "one", "of", "the", "founding", "fathers", "of", "artificial", "intelligence", ",", "along", "with", "Alan", "Turing", ",", "Marvin", "Minsky", ",", "Allen", "Newell", "and", "Herbert", "A", ".", "Simon", "."], "sentence-detokenized": "John McCarthy is one of the founding fathers of artificial intelligence, along with Alan Turing, Marvin Minsky, Allen Newell and Herbert A. Simon.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 23], [24, 27], [28, 36], [37, 44], [45, 47], [48, 58], [59, 71], [71, 72], [73, 78], [79, 83], [84, 88], [89, 95], [95, 96], [97, 103], [104, 110], [110, 111], [112, 117], [118, 124], [125, 128], [129, 136], [137, 138], [138, 139], [140, 145], [145, 146]]}
{"doc_key": "ai-dev-344", "ner": [[10, 12, "product"], [20, 20, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "parallel", "manipulator", "is", "a", "mechanical", "system", "that", "uses", "several", "manipulators", "in", "series", "to", "support", "a", "single", "platform", ",", "or", "end-effector", "."], "sentence-detokenized": "A parallel manipulator is a mechanical system that uses several manipulators in series to support a single platform, or end-effector.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 27], [28, 38], [39, 45], [46, 50], [51, 55], [56, 63], [64, 76], [77, 79], [80, 86], [87, 89], [90, 97], [98, 99], [100, 106], [107, 115], [115, 116], [117, 119], [120, 132], [132, 133]]}
{"doc_key": "ai-dev-345", "ner": [[0, 0, "product"], [3, 4, "task"], [7, 7, "product"], [9, 15, "product"], [27, 27, "misc"], [30, 30, "misc"], [33, 34, "misc"], [37, 42, "task"], [45, 48, "product"], [51, 52, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 7, 0, 0, "part-of", "", false, false], [7, 7, 3, 4, "type-of", "", false, false], [9, 15, 7, 7, "named", "", false, false], [27, 27, 7, 7, "part-of", "", false, false], [30, 30, 7, 7, "part-of", "", false, false], [33, 34, 7, 7, "part-of", "", false, false], [37, 42, 7, 7, "part-of", "", false, false], [45, 48, 7, 7, "part-of", "", false, false], [51, 52, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["GATE", "includes", "an", "information", "extraction", "system", "called", "ANNIE", "(", "A", "Nearly", "-", "New", "Information", "Extraction", "System", ")", ",", "which", "is", "a", "set", "of", "modules", "consisting", "of", "a", "tokeniser", ",", "a", "gazetteer", ",", "a", "sentence", "splitter", ",", "a", "part", "-", "of", "-", "speech", "tagger", ",", "a", "named", "entity", "recognition", "transducer", "and", "a", "coreference", "tagger", "."], "sentence-detokenized": "GATE includes an information extraction system called ANNIE (A Nearly-New Information Extraction System), which is a set of modules consisting of a tokeniser, a gazetteer, a sentence splitter, a part-of-speech tagger, a named entity recognition transducer and a coreference tagger.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 28], [29, 39], [40, 46], [47, 53], [54, 59], [60, 61], [61, 62], [63, 69], [69, 70], [70, 73], [74, 85], [86, 96], [97, 103], [103, 104], [104, 105], [106, 111], [112, 114], [115, 116], [117, 120], [121, 123], [124, 131], [132, 142], [143, 145], [146, 147], [148, 157], [157, 158], [159, 160], [161, 170], [170, 171], [172, 173], [174, 182], [183, 191], [191, 192], [193, 194], [195, 199], [199, 200], [200, 202], [202, 203], [203, 209], [210, 216], [216, 217], [218, 219], [220, 225], [226, 232], [233, 244], [245, 255], [256, 259], [260, 261], [262, 273], [274, 280], [280, 281]]}
{"doc_key": "ai-dev-346", "ner": [[3, 5, "university"], [13, 17, "country"], [20, 24, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "graduated", "from", "Moscow", "State", "University", "and", "in", "November", "1978", "left", "for", "the", "United", "States", "thanks", "to", "the", "personal", "intervention", "of", "Senator", "Edward", "M.", "Kennedy", "."], "sentence-detokenized": "He graduated from Moscow State University and in November 1978 left for the United States thanks to the personal intervention of Senator Edward M. Kennedy.", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 24], [25, 30], [31, 41], [42, 45], [46, 48], [49, 57], [58, 62], [63, 67], [68, 71], [72, 75], [76, 82], [83, 89], [90, 96], [97, 99], [100, 103], [104, 112], [113, 125], [126, 128], [129, 136], [137, 143], [144, 146], [147, 154], [154, 155]]}
{"doc_key": "ai-dev-347", "ner": [[4, 6, "organisation"], [9, 13, "misc"], [18, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 9, 13, "win-defeat", "", false, false], [9, 13, 18, 18, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2017", ",", "the", "DeepMind", "AlphaGo", "team", "received", "the", "inaugural", "IJCAI", "Marvin", "Minsky", "Medal", "for", "Outstanding", "Achievement", "in", "AI", "."], "sentence-detokenized": "In 2017, the DeepMind AlphaGo team received the inaugural IJCAI Marvin Minsky Medal for Outstanding Achievement in AI.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 21], [22, 29], [30, 34], [35, 43], [44, 47], [48, 57], [58, 63], [64, 70], [71, 77], [78, 83], [84, 87], [88, 99], [100, 111], [112, 114], [115, 117], [117, 118]]}
{"doc_key": "ai-dev-348", "ner": [[4, 6, "misc"], [7, 7, "misc"], [11, 12, "misc"], [21, 22, "misc"], [27, 27, "misc"], [33, 33, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 6, 7, 7, "related-to", "is_recorded_by", false, false], [7, 7, 11, 12, "cause-effect", "", false, false], [7, 7, 11, 12, "physical", "", false, false], [7, 7, 21, 22, "physical", "", false, false], [7, 7, 33, 33, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "ways", "of", "recording", "anomalous", "propagation", "are", "troposcatters", "causing", "irregularities", "in", "the", "troposphere", ",", "scattering", "due", "to", "meteors", ",", "refraction", "in", "ionised", "regions", "and", "layers", "of", "the", "ionosphere", ",", "and", "reflection", "from", "the", "ionosphere", "."], "sentence-detokenized": "Other ways of recording anomalous propagation are troposcatters causing irregularities in the troposphere, scattering due to meteors, refraction in ionised regions and layers of the ionosphere, and reflection from the ionosphere.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 23], [24, 33], [34, 45], [46, 49], [50, 63], [64, 71], [72, 86], [87, 89], [90, 93], [94, 105], [105, 106], [107, 117], [118, 121], [122, 124], [125, 132], [132, 133], [134, 144], [145, 147], [148, 155], [156, 163], [164, 167], [168, 174], [175, 177], [178, 181], [182, 192], [192, 193], [194, 197], [198, 208], [209, 213], [214, 217], [218, 228], [228, 229]]}
{"doc_key": "ai-dev-349", "ner": [[0, 2, "field"], [4, 4, "field"], [10, 10, "field"], [12, 13, "field"], [15, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 10, 10, "part-of", "", false, false], [0, 2, 12, 13, "part-of", "", false, false], [0, 2, 15, 16, "part-of", "", false, false], [0, 2, 18, 19, "part-of", "", false, false], [4, 4, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Natural", "language", "processing", "(", "NLP", ")", "is", "a", "subfield", "of", "linguistics", ",", "computer", "science", ",", "information", "engineering", "and", "artificial", "intelligence", "that", "deals", "with", "the", "interactions", "between", "computers", "and", "human", "(", "natural", ")", "languages", ",", "in", "particular", "how", "to", "programme", "computers", "to", "process", "and", "analyse", "large", "amounts", "of", "natural", "language", "data", "."], "sentence-detokenized": "Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering and artificial intelligence that deals with the interactions between computers and human (natural) languages, in particular how to programme computers to process and analyse large amounts of natural language data.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 29], [29, 32], [32, 33], [34, 36], [37, 38], [39, 47], [48, 50], [51, 62], [62, 63], [64, 72], [73, 80], [80, 81], [82, 93], [94, 105], [106, 109], [110, 120], [121, 133], [134, 138], [139, 144], [145, 149], [150, 153], [154, 166], [167, 174], [175, 184], [185, 188], [189, 194], [195, 196], [196, 203], [203, 204], [205, 214], [214, 215], [216, 218], [219, 229], [230, 233], [234, 236], [237, 246], [247, 256], [257, 259], [260, 267], [268, 271], [272, 279], [280, 285], [286, 293], [294, 296], [297, 304], [305, 313], [314, 318], [318, 319]]}
{"doc_key": "ai-dev-350", "ner": [[8, 9, "organisation"], [11, 12, "organisation"], [14, 14, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "active", "youth", "-", "led", "climate", "groups", "include", "Extinction", "Rebellion", ",", "Sunrise", "Movement", ",", "SustainUS", ",", "among", "others", "working", "at", "both", "transnational", "and", "local", "levels", "."], "sentence-detokenized": "Other active youth-led climate groups include Extinction Rebellion, Sunrise Movement, SustainUS, among others working at both transnational and local levels.", "token2charspan": [[0, 5], [6, 12], [13, 18], [18, 19], [19, 22], [23, 30], [31, 37], [38, 45], [46, 56], [57, 66], [66, 67], [68, 75], [76, 84], [84, 85], [86, 95], [95, 96], [97, 102], [103, 109], [110, 117], [118, 120], [121, 125], [126, 139], [140, 143], [144, 149], [150, 156], [156, 157]]}
