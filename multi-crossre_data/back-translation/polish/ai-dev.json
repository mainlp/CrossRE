{"doc_key": "ai-dev-1", "ner": [[2, 2, "metrics"], [5, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 9, 2, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Here", ",", "accuracy", "is", "measured", "by", "the", "rate", "of", "error", ",", "which", "is", "defined", "as", ":"], "sentence-detokenized": "Here, accuracy is measured by the rate of error, which is defined as:", "token2charspan": [[0, 4], [4, 5], [6, 14], [15, 17], [18, 26], [27, 29], [30, 33], [34, 38], [39, 41], [42, 47], [47, 48], [49, 54], [55, 57], [58, 65], [66, 68], [68, 69]]}
{"doc_key": "ai-dev-2", "ner": [[4, 4, "algorithm"], [11, 12, "misc"], [19, 21, "algorithm"], [16, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 11, 12, "type-of", "", false, false], [4, 4, 19, 21, "related-to", "", false, false], [4, 4, 16, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["From", "this", "perspective", ",", "SVM", "is", "closely", "related", "to", "other", "basic", "classification", "algorithms", ",", "such", "as", "logistic", "regression", "with", "least", "squares", "regularisation", "."], "sentence-detokenized": "From this perspective, SVM is closely related to other basic classification algorithms, such as logistic regression with least squares regularisation.", "token2charspan": [[0, 4], [5, 9], [10, 21], [21, 22], [23, 26], [27, 29], [30, 37], [38, 45], [46, 48], [49, 54], [55, 60], [61, 75], [76, 86], [86, 87], [88, 92], [93, 95], [96, 104], [105, 115], [116, 120], [121, 126], [127, 134], [135, 149], [149, 150]]}
{"doc_key": "ai-dev-3", "ner": [[0, 1, "person"], [3, 4, "person"], [13, 14, "person"], [16, 16, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 0, 1, "named", "actor_plays_character", false, false], [3, 4, 0, 1, "origin", "actor_plays_character", false, false], [16, 16, 13, 14, "named", "actor_plays_character", false, false], [16, 16, 13, 14, "origin", "actor_plays_character", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Brion", "James", "portrays", "Leon", "Kowalski", ",", "a", "combat", "and", "labour", "replicant", ",", "and", "Joanna", "Cassidy", "portrays", "Zhora", ",", "a", "replicant", "assassin", "."], "sentence-detokenized": "Brion James portrays Leon Kowalski, a combat and labour replicant, and Joanna Cassidy portrays Zhora, a replicant assassin.", "token2charspan": [[0, 5], [6, 11], [12, 20], [21, 25], [26, 34], [34, 35], [36, 37], [38, 44], [45, 48], [49, 55], [56, 65], [65, 66], [67, 70], [71, 77], [78, 85], [86, 94], [95, 100], [100, 101], [102, 103], [104, 113], [114, 122], [122, 123]]}
{"doc_key": "ai-dev-4", "ner": [[17, 20, "product"], [22, 22, "product"], [25, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 20, 25, 25, "physical", "", false, false], [22, 22, 17, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "image", "to", "be", "scanned", ",", "stored", "and", "reproduced", "in", "digital", "pixels", "was", "displayed", "on", "the", "Standards", "Eastern", "Automatic", "Computer", "(", "SEAC", ")", "at", "NIST", "."], "sentence-detokenized": "The first image to be scanned, stored and reproduced in digital pixels was displayed on the Standards Eastern Automatic Computer (SEAC) at NIST.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 18], [19, 21], [22, 29], [29, 30], [31, 37], [38, 41], [42, 52], [53, 55], [56, 63], [64, 70], [71, 74], [75, 84], [85, 87], [88, 91], [92, 101], [102, 109], [110, 119], [120, 128], [129, 130], [130, 134], [134, 135], [136, 138], [139, 143], [143, 144]]}
{"doc_key": "ai-dev-5", "ner": [[0, 6, "task"], [20, 21, "task"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 6, 20, 21, "part-of", "", false, false], [0, 6, 23, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Segmenting", "text", "into", "discursive", "topics", "or", "phrases", "can", "be", "useful", "in", "some", "natural", "processing", "tasks", ":", "it", "can", "significantly", "improve", "information", "retrieval", "or", "speech", "recognition", "(", "either", "by", "indexing", "/", "recognising", "documents", "more", "accurately", "or", "by", "providing", "the", "result", "with", "a", "specific", "section", "of", "the", "document", "that", "matches", "the", "query", ")", "."], "sentence-detokenized": "Segmenting text into discursive topics or phrases can be useful in some natural processing tasks: it can significantly improve information retrieval or speech recognition (either by indexing/recognising documents more accurately or by providing the result with a specific section of the document that matches the query).", "token2charspan": [[0, 10], [11, 15], [16, 20], [21, 31], [32, 38], [39, 41], [42, 49], [50, 53], [54, 56], [57, 63], [64, 66], [67, 71], [72, 79], [80, 90], [91, 96], [96, 97], [98, 100], [101, 104], [105, 118], [119, 126], [127, 138], [139, 148], [149, 151], [152, 158], [159, 170], [171, 172], [172, 178], [179, 181], [182, 190], [190, 191], [191, 202], [203, 212], [213, 217], [218, 228], [229, 231], [232, 234], [235, 244], [245, 248], [249, 255], [256, 260], [261, 262], [263, 271], [272, 279], [280, 282], [283, 286], [287, 295], [296, 300], [301, 308], [309, 312], [313, 318], [318, 319], [319, 320]]}
{"doc_key": "ai-dev-6", "ner": [[1, 2, "university"], [24, 25, "conference"], [16, 17, "university"], [34, 35, "researcher"], [37, 38, "researcher"], [40, 41, "researcher"], [43, 44, "researcher"], [46, 47, "researcher"], [49, 50, "researcher"], [52, 53, "researcher"], [54, 57, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[24, 25, 16, 17, "physical", "", false, false], [34, 35, 24, 25, "physical", "", false, false], [34, 35, 24, 25, "role", "", false, false], [34, 35, 24, 25, "temporal", "", false, false], [37, 38, 24, 25, "physical", "", false, false], [37, 38, 24, 25, "role", "", false, false], [37, 38, 24, 25, "temporal", "", false, false], [40, 41, 24, 25, "physical", "", false, false], [40, 41, 24, 25, "role", "", false, false], [40, 41, 24, 25, "temporal", "", false, false], [43, 44, 24, 25, "physical", "", false, false], [43, 44, 24, 25, "role", "", false, false], [43, 44, 24, 25, "temporal", "", false, false], [46, 47, 24, 25, "physical", "", false, false], [46, 47, 24, 25, "role", "", false, false], [46, 47, 24, 25, "temporal", "", false, false], [49, 50, 24, 25, "physical", "", false, false], [49, 50, 24, 25, "role", "", false, false], [49, 50, 24, 25, "temporal", "", false, false], [52, 53, 24, 25, "physical", "", false, false], [52, 53, 24, 25, "role", "", false, false], [52, 53, 24, 25, "temporal", "", false, false], [54, 57, 24, 25, "physical", "", false, false], [54, 57, 24, 25, "role", "", false, false], [54, 57, 24, 25, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "sentence": ["At", "Indiana", "University", "in", "1999", "he", "organised", "such", "a", "symposium", ",", "and", "in", "April", "2000", "at", "Stanford", "University", "he", "organised", "a", "larger", "symposium", "entitled", "Spiritual", "Robots", ",", "in", "which", "he", "moderated", "a", "panel", "comprising", "Ray", "Kurzweil", ",", "Hans", "Moravec", ",", "Kevin", "Kelly", ",", "Ralph", "Merkle", ",", "Bill", "Joy", ",", "Frank", "Drake", ",", "John", "Henry", "Holland", "and", "John", "Kozy", "."], "sentence-detokenized": "At Indiana University in 1999 he organised such a symposium, and in April 2000 at Stanford University he organised a larger symposium entitled Spiritual Robots, in which he moderated a panel comprising Ray Kurzweil, Hans Moravec, Kevin Kelly, Ralph Merkle, Bill Joy, Frank Drake, John Henry Holland and John Kozy.", "token2charspan": [[0, 2], [3, 10], [11, 21], [22, 24], [25, 29], [30, 32], [33, 42], [43, 47], [48, 49], [50, 59], [59, 60], [61, 64], [65, 67], [68, 73], [74, 78], [79, 81], [82, 90], [91, 101], [102, 104], [105, 114], [115, 116], [117, 123], [124, 133], [134, 142], [143, 152], [153, 159], [159, 160], [161, 163], [164, 169], [170, 172], [173, 182], [183, 184], [185, 190], [191, 201], [202, 205], [206, 214], [214, 215], [216, 220], [221, 228], [228, 229], [230, 235], [236, 241], [241, 242], [243, 248], [249, 255], [255, 256], [257, 261], [262, 265], [265, 266], [267, 272], [273, 278], [278, 279], [280, 284], [285, 290], [291, 298], [299, 302], [303, 307], [308, 312], [312, 313]]}
{"doc_key": "ai-dev-7", "ner": [[6, 6, "metrics"], [7, 7, "metrics"], [9, 13, "metrics"], [11, 11, "metrics"], [20, 20, "metrics"], [41, 41, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 6, 20, 20, "named", "", false, false], [7, 7, 6, 6, "named", "", false, false], [9, 13, 41, 41, "named", "", false, false], [11, 11, 9, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "takes", "into", "account", "both", "the", "precision", "p", "and", "the", "recall", "r", "of", "the", "test", "to", "calculate", "the", "score", ":", "p", "is", "the", "number", "of", "correct", "positives", "divided", "by", "the", "number", "of", "all", "positive", "results", "returned", "by", "the", "classifier", ",", "and", "r", "is", "the", "number", "of", "correct", "positives", "divided", "by", "the", "number", "of", "all", "relevant", "samples", "(", "all", "samples", "that", "should", "be", "identified", "as", "positive", ")", "."], "sentence-detokenized": "It takes into account both the precision p and the recall r of the test to calculate the score: p is the number of correct positives divided by the number of all positive results returned by the classifier, and r is the number of correct positives divided by the number of all relevant samples (all samples that should be identified as positive).", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 21], [22, 26], [27, 30], [31, 40], [41, 42], [43, 46], [47, 50], [51, 57], [58, 59], [60, 62], [63, 66], [67, 71], [72, 74], [75, 84], [85, 88], [89, 94], [94, 95], [96, 97], [98, 100], [101, 104], [105, 111], [112, 114], [115, 122], [123, 132], [133, 140], [141, 143], [144, 147], [148, 154], [155, 157], [158, 161], [162, 170], [171, 178], [179, 187], [188, 190], [191, 194], [195, 205], [205, 206], [207, 210], [211, 212], [213, 215], [216, 219], [220, 226], [227, 229], [230, 237], [238, 247], [248, 255], [256, 258], [259, 262], [263, 269], [270, 272], [273, 276], [277, 285], [286, 293], [294, 295], [295, 298], [299, 306], [307, 311], [312, 318], [319, 321], [322, 332], [333, 335], [336, 344], [344, 345], [345, 346]]}
{"doc_key": "ai-dev-8", "ner": [[4, 4, "organisation"], [25, 27, "product"], [33, 34, "person"], [40, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 25, 27, "artifact", "", false, false], [25, 27, 33, 34, "win-defeat", "", false, false], [25, 27, 40, 40, "win-defeat", "", true, false], [33, 34, 40, 40, "win-defeat", "lose", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "its", "acquisition", "by", "Google", ",", "the", "company", "has", "recorded", "a", "number", "of", "notable", "achievements", ",", "the", "most", "notable", "of", "which", "is", "the", "creation", "of", "AlphaGo", ",", "a", "programme", "that", "beat", "world", "champion", "Lee", "Sedol", "in", "the", "complex", "game", "of", "Go", "."], "sentence-detokenized": "Since its acquisition by Google, the company has recorded a number of notable achievements, the most notable of which is the creation of AlphaGo, a programme that beat world champion Lee Sedol in the complex game of Go.", "token2charspan": [[0, 5], [6, 9], [10, 21], [22, 24], [25, 31], [31, 32], [33, 36], [37, 44], [45, 48], [49, 57], [58, 59], [60, 66], [67, 69], [70, 77], [78, 90], [90, 91], [92, 95], [96, 100], [101, 108], [109, 111], [112, 117], [118, 120], [121, 124], [125, 133], [134, 136], [137, 144], [144, 145], [146, 147], [148, 157], [158, 162], [163, 167], [168, 173], [174, 182], [183, 186], [187, 192], [193, 195], [196, 199], [200, 207], [208, 212], [213, 215], [216, 218], [218, 219]]}
{"doc_key": "ai-dev-9", "ner": [[11, 12, "misc"], [25, 25, "field"], [28, 31, "product"], [48, 48, "misc"], [57, 57, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[11, 12, 25, 25, "part-of", "", false, false], [28, 31, 48, 48, "related-to", "", false, false], [28, 31, 57, 57, "usage", "", false, false]], "relations_mapping_to_source": [0, 2, 4], "sentence": ["Context", "-", "sensitive", "word", "representation", "through", "fixed", "-", "size", "vectors", "(", "word", "embeddings", ")", "has", "become", "one", "of", "the", "most", "fundamental", "building", "blocks", "in", "many", "NLP", "systems", ".", "The", "unsupervised", "disambiguation", "system", "uses", "the", "similarity", "between", "word", "senses", "in", "a", "fixed", "context", "window", "to", "select", "the", "most", "appropriate", "word", "sense", "using", "a", "pre-trained", "word", "embedding", "model", "and", "WordNet", "."], "sentence-detokenized": "Context-sensitive word representation through fixed-size vectors (word embeddings) has become one of the most fundamental building blocks in many NLP systems. The unsupervised disambiguation system uses the similarity between word senses in a fixed context window to select the most appropriate word sense using a pre-trained word embedding model and WordNet.", "token2charspan": [[0, 7], [7, 8], [8, 17], [18, 22], [23, 37], [38, 45], [46, 51], [51, 52], [52, 56], [57, 64], [65, 66], [66, 70], [71, 81], [81, 82], [83, 86], [87, 93], [94, 97], [98, 100], [101, 104], [105, 109], [110, 121], [122, 130], [131, 137], [138, 140], [141, 145], [146, 149], [150, 157], [157, 158], [159, 162], [163, 175], [176, 190], [191, 197], [198, 202], [203, 206], [207, 217], [218, 225], [226, 230], [231, 237], [238, 240], [241, 242], [243, 248], [249, 256], [257, 263], [264, 266], [267, 273], [274, 277], [278, 282], [283, 294], [295, 299], [300, 305], [306, 311], [312, 313], [314, 325], [326, 330], [331, 340], [341, 346], [347, 350], [351, 358], [358, 359]]}
{"doc_key": "ai-dev-10", "ner": [[0, 0, "field"], [5, 6, "field"], [8, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 0, 0, "part-of", "", false, false], [8, 12, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "techniques", ",", "both", "supervised", "learning", "and", "unsupervised", "learning", ",", "have", "been", "used", "to", "automatically", "induce", "such", "rules", "."], "sentence-detokenized": "Machine learning techniques, both supervised learning and unsupervised learning, have been used to automatically induce such rules.", "token2charspan": [[0, 7], [8, 16], [17, 27], [27, 28], [29, 33], [34, 44], [45, 53], [54, 57], [58, 70], [71, 79], [79, 80], [81, 85], [86, 90], [91, 95], [96, 98], [99, 112], [113, 119], [120, 124], [125, 130], [130, 131]]}
{"doc_key": "ai-dev-11", "ner": [[3, 3, "researcher"], [5, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1969", ",", "Scheinman", "invented", "the", "Stanford", "arm", ","], "sentence-detokenized": "In 1969, Scheinman invented the Stanford arm,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 27], [28, 31], [32, 40], [41, 44], [44, 45]]}
{"doc_key": "ai-dev-12", "ner": [[1, 2, "metrics"], [7, 10, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["As", "Log", "loss", "is", "differentiable", ",", "a", "gradient", "-", "based", "method", "can", "be", "used", "to", "optimise", "the", "model", "."], "sentence-detokenized": "As Log loss is differentiable, a gradient-based method can be used to optimise the model.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 29], [29, 30], [31, 32], [33, 41], [41, 42], [42, 47], [48, 54], [55, 58], [59, 61], [62, 66], [67, 69], [70, 78], [79, 82], [83, 88], [88, 89]]}
{"doc_key": "ai-dev-13", "ner": [[1, 2, "field"], [4, 6, "algorithm"], [8, 8, "algorithm"], [11, 13, "algorithm"], [16, 17, "field"], [28, 28, "task"], [30, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 6, 16, 17, "part-of", "", false, false], [8, 8, 4, 6, "named", "", false, false], [11, 13, 4, 6, "named", "", false, false], [16, 17, 1, 2, "part-of", "subfield", false, false], [28, 28, 16, 17, "part-of", "", false, false], [30, 31, 16, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "machine", "learning", ",", "support", "vector", "machines", "(", "SVMs", ",", "also", "support", "vector", "networks", ")", "are", "supervised", "learning", "models", "with", "learning", "algorithms", "that", "analyse", "the", "data", "used", "for", "classification", "and", "regression", "analysis", "."], "sentence-detokenized": "In machine learning, support vector machines (SVMs, also support vector networks) are supervised learning models with learning algorithms that analyse the data used for classification and regression analysis.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 28], [29, 35], [36, 44], [45, 46], [46, 50], [50, 51], [52, 56], [57, 64], [65, 71], [72, 80], [80, 81], [82, 85], [86, 96], [97, 105], [106, 112], [113, 117], [118, 126], [127, 137], [138, 142], [143, 150], [151, 154], [155, 159], [160, 164], [165, 168], [169, 183], [184, 187], [188, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-dev-14", "ner": [[10, 11, "task"], [13, 13, "task"], [30, 30, "metrics"], [32, 32, "metrics"], [34, 34, "researcher"], [36, 36, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 13, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": [",", "(", "2002", ")", "as", "an", "automatic", "metric", "for", "evaluating", "machine", "translation", "(", "MT", ")", ",", "many", "other", "methods", "have", "been", "proposed", "to", "verify", "or", "improve", "it", ",", "such", "as", "TER", ",", "METEOR", ",", "Banerjee", "and", "Lavie", ",", "(", "2005", ")", "etc", "."], "sentence-detokenized": ", (2002) as an automatic metric for evaluating machine translation (MT), many other methods have been proposed to verify or improve it, such as TER, METEOR, Banerjee and Lavie, (2005) etc.", "token2charspan": [[0, 1], [2, 3], [3, 7], [7, 8], [9, 11], [12, 14], [15, 24], [25, 31], [32, 35], [36, 46], [47, 54], [55, 66], [67, 68], [68, 70], [70, 71], [71, 72], [73, 77], [78, 83], [84, 91], [92, 96], [97, 101], [102, 110], [111, 113], [114, 120], [121, 123], [124, 131], [132, 134], [134, 135], [136, 140], [141, 143], [144, 147], [147, 148], [149, 155], [155, 156], [157, 165], [166, 169], [170, 175], [175, 176], [177, 178], [178, 182], [182, 183], [184, 187], [187, 188]]}
{"doc_key": "ai-dev-15", "ner": [[0, 4, "misc"], [9, 9, "organisation"], [10, 10, "organisation"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 10, 10, "origin", "", false, false], [10, 10, 9, 9, "part-of", "", false, false], [16, 17, 10, 10, "role", "", false, false], [19, 20, 10, 10, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "contains", "the", "top", "ontology", ",", "created", "by", "the", "IEEE", "P1600.1", "working", "group", "(", "originally", "by", "Ian", "Niles", "and", "Adam", "Pease", ")", "."], "sentence-detokenized": "It contains the top ontology, created by the IEEE P1600.1 working group (originally by Ian Niles and Adam Pease).", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 19], [20, 28], [28, 29], [30, 37], [38, 40], [41, 44], [45, 49], [50, 57], [58, 65], [66, 71], [72, 73], [73, 83], [84, 86], [87, 90], [91, 96], [97, 100], [101, 105], [106, 111], [111, 112], [112, 113]]}
{"doc_key": "ai-dev-16", "ner": [[1, 3, "misc"], [31, 33, "algorithm"], [35, 36, "algorithm"], [39, 40, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[31, 33, 1, 3, "part-of", "", true, false], [35, 36, 1, 3, "part-of", "", true, false], [39, 40, 35, 36, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "Cryo", "electron", "tomography", ",", "where", "a", "limited", "number", "of", "projections", "are", "acquired", "due", "to", "hardware", "limitations", "and", "to", "avoid", "damage", "to", "biological", "samples", ",", "it", "can", "be", "used", "together", "with", "compression", "sensing", "techniques", "or", "regularisation", "features", "(", "e.g.", "Huber", "loss", ")", "to", "improve", "reconstruction", "for", "better", "interpretation", "."], "sentence-detokenized": "In Cryo electron tomography, where a limited number of projections are acquired due to hardware limitations and to avoid damage to biological samples, it can be used together with compression sensing techniques or regularisation features (e.g. Huber loss) to improve reconstruction for better interpretation.", "token2charspan": [[0, 2], [3, 7], [8, 16], [17, 27], [27, 28], [29, 34], [35, 36], [37, 44], [45, 51], [52, 54], [55, 66], [67, 70], [71, 79], [80, 83], [84, 86], [87, 95], [96, 107], [108, 111], [112, 114], [115, 120], [121, 127], [128, 130], [131, 141], [142, 149], [149, 150], [151, 153], [154, 157], [158, 160], [161, 165], [166, 174], [175, 179], [180, 191], [192, 199], [200, 210], [211, 213], [214, 228], [229, 237], [238, 239], [239, 243], [244, 249], [250, 254], [254, 255], [256, 258], [259, 266], [267, 281], [282, 285], [286, 292], [293, 307], [307, 308]]}
{"doc_key": "ai-dev-17", "ner": [[4, 4, "misc"], [7, 7, "programlang"], [10, 12, "algorithm"], [14, 15, "algorithm"], [19, 19, "algorithm"], [20, 28, "product"], [31, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 4, 7, 7, "part-of", "", false, false], [10, 12, 4, 4, "type-of", "", false, false], [14, 15, 4, 4, "type-of", "", false, false], [19, 19, 4, 4, "type-of", "", false, false], [20, 28, 7, 7, "general-affiliation", "", true, false], [20, 28, 7, 7, "part-of", "", true, false], [31, 31, 20, 28, "role", "publishes", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "implementation", "of", "several", "whitening", "procedures", "in", "R", ",", "including", "ZCA", "-", "whitening", "and", "PCA", "whitening", ",", "but", "also", "CCA", "whitening", ",", "is", "available", "in", "the", "Whitening", "R", "package", "published", "on", "CRAN", "."], "sentence-detokenized": "The implementation of several whitening procedures in R, including ZCA-whitening and PCA whitening, but also CCA whitening, is available in the Whitening R package published on CRAN.", "token2charspan": [[0, 3], [4, 18], [19, 21], [22, 29], [30, 39], [40, 50], [51, 53], [54, 55], [55, 56], [57, 66], [67, 70], [70, 71], [71, 80], [81, 84], [85, 88], [89, 98], [98, 99], [100, 103], [104, 108], [109, 112], [113, 122], [122, 123], [124, 126], [127, 136], [137, 139], [140, 143], [144, 153], [154, 155], [156, 163], [164, 173], [174, 176], [177, 181], [181, 182]]}
{"doc_key": "ai-dev-18", "ner": [[31, 31, "product"], [33, 33, "product"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [41, 41, "product"], [44, 45, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[31, 31, 35, 35, "compare", "", false, false], [31, 31, 37, 37, "compare", "", false, false], [31, 31, 39, 39, "compare", "", false, false], [31, 31, 41, 41, "compare", "", false, false], [31, 31, 44, 45, "compare", "", false, false], [33, 33, 35, 35, "compare", "", false, false], [33, 33, 37, 37, "compare", "", false, false], [33, 33, 39, 39, "compare", "", false, false], [33, 33, 41, 41, "compare", "", false, false], [33, 33, 44, 45, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Today", ",", "the", "field", "has", "become", "even", "more", "daunting", "and", "complex", "with", "the", "addition", "of", "languages", "and", "software", "for", "the", "analysis", "and", "design", "of", "circuits", ",", "systems", "and", "signals", ",", "from", "MATLAB", "and", "Simulink", "to", "NumPy", ",", "VHDL", ",", "PSpice", ",", "Verilog", "and", "even", "Assembly", "language", "."], "sentence-detokenized": "Today, the field has become even more daunting and complex with the addition of languages and software for the analysis and design of circuits, systems and signals, from MATLAB and Simulink to NumPy, VHDL, PSpice, Verilog and even Assembly language.", "token2charspan": [[0, 5], [5, 6], [7, 10], [11, 16], [17, 20], [21, 27], [28, 32], [33, 37], [38, 46], [47, 50], [51, 58], [59, 63], [64, 67], [68, 76], [77, 79], [80, 89], [90, 93], [94, 102], [103, 106], [107, 110], [111, 119], [120, 123], [124, 130], [131, 133], [134, 142], [142, 143], [144, 151], [152, 155], [156, 163], [163, 164], [165, 169], [170, 176], [177, 180], [181, 189], [190, 192], [193, 198], [198, 199], [200, 204], [204, 205], [206, 212], [212, 213], [214, 221], [222, 225], [226, 230], [231, 239], [240, 248], [248, 249]]}
{"doc_key": "ai-dev-19", "ner": [[5, 6, "person"], [13, 14, "person"], [16, 18, "organisation"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 18, 13, 14, "origin", "", false, false], [20, 20, 16, 18, "artifact", "builds", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "company", "was", "founded", "by", "Kiichiro", "Toyoda", "in", "1937", "as", "a", "spinoff", "from", "Sakichi", "Toyoda", "of", "Toyota", "Industries", "to", "create", "cars", "."], "sentence-detokenized": "The company was founded by Kiichiro Toyoda in 1937 as a spinoff from Sakichi Toyoda of Toyota Industries to create cars.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 26], [27, 35], [36, 42], [43, 45], [46, 50], [51, 53], [54, 55], [56, 63], [64, 68], [69, 76], [77, 83], [84, 86], [87, 93], [94, 104], [105, 107], [108, 114], [115, 119], [119, 120]]}
{"doc_key": "ai-dev-20", "ner": [[0, 1, "field"], [53, 56, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[53, 56, 0, 1, "origin", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Unsupervised", "learning", ",", "on", "the", "other", "hand", ",", "assumes", "training", "data", "that", "has", "not", "been", "manually", "labelled", "and", "attempts", "to", "find", "inherent", "patterns", "in", "the", "data", "that", "can", "be", "used", "to", "determine", "the", "correct", "output", "value", "for", "new", "data", "instances", ".", "A", "combination", "of", "these", "two", "methods", "that", "has", "recently", "been", "explored", "is", "semi-supervised", "learning", ",", "which", "uses", "a", "combination", "of", "labelled", "and", "unlabelled", "data", "(", "typically", "a", "small", "set", "of", "labelled", "data", "combined", "with", "a", "large", "amount", "of", "unlabelled", "data", ")", "."], "sentence-detokenized": "Unsupervised learning, on the other hand, assumes training data that has not been manually labelled and attempts to find inherent patterns in the data that can be used to determine the correct output value for new data instances. A combination of these two methods that has recently been explored is semi-supervised learning, which uses a combination of labelled and unlabelled data (typically a small set of labelled data combined with a large amount of unlabelled data).", "token2charspan": [[0, 12], [13, 21], [21, 22], [23, 25], [26, 29], [30, 35], [36, 40], [40, 41], [42, 49], [50, 58], [59, 63], [64, 68], [69, 72], [73, 76], [77, 81], [82, 90], [91, 99], [100, 103], [104, 112], [113, 115], [116, 120], [121, 129], [130, 138], [139, 141], [142, 145], [146, 150], [151, 155], [156, 159], [160, 162], [163, 167], [168, 170], [171, 180], [181, 184], [185, 192], [193, 199], [200, 205], [206, 209], [210, 213], [214, 218], [219, 228], [228, 229], [230, 231], [232, 243], [244, 246], [247, 252], [253, 256], [257, 264], [265, 269], [270, 273], [274, 282], [283, 287], [288, 296], [297, 299], [300, 315], [316, 324], [324, 325], [326, 331], [332, 336], [337, 338], [339, 350], [351, 353], [354, 362], [363, 366], [367, 377], [378, 382], [383, 384], [384, 393], [394, 395], [396, 401], [402, 405], [406, 408], [409, 417], [418, 422], [423, 431], [432, 436], [437, 438], [439, 444], [445, 451], [452, 454], [455, 465], [466, 470], [470, 471], [471, 472]]}
{"doc_key": "ai-dev-21", "ner": [[19, 19, "organisation"], [20, 21, "product"], [23, 24, "organisation"], [26, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[20, 21, 19, 19, "artifact", "", false, false], [23, 24, 26, 26, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Despite", "these", "humanoid", "robots", "for", "utilitarian", "applications", ",", "there", "are", "some", "humanoid", "robots", "aimed", "at", "entertainment", ",", "such", "as", "Sony", "'s", "QRIO", "and", "Wow", "Wee", "'s", "RoboSapien", "."], "sentence-detokenized": "Despite these humanoid robots for utilitarian applications, there are some humanoid robots aimed at entertainment, such as Sony's QRIO and Wow Wee's RoboSapien.", "token2charspan": [[0, 7], [8, 13], [14, 22], [23, 29], [30, 33], [34, 45], [46, 58], [58, 59], [60, 65], [66, 69], [70, 74], [75, 83], [84, 90], [91, 96], [97, 99], [100, 113], [113, 114], [115, 119], [120, 122], [123, 127], [127, 129], [130, 134], [135, 138], [139, 142], [143, 146], [146, 148], [149, 159], [159, 160]]}
{"doc_key": "ai-dev-22", "ner": [[0, 0, "researcher"], [7, 13, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 7, 13, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Webber", "became", "a", "1991", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "Webber became a 1991 Fellow of the Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 20], [21, 27], [28, 30], [31, 34], [35, 46], [47, 50], [51, 54], [55, 66], [67, 69], [70, 80], [81, 93], [93, 94]]}
{"doc_key": "ai-dev-23", "ner": [[6, 6, "field"], [9, 9, "field"], [21, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 24, 6, 6, "part-of", "task_part_of_field", false, false], [21, 24, 9, 9, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["At", "this", "company", ",", "he", "developed", "data", "mining", "and", "database", "technology", ",", "more", "specifically", "high", "-", "level", "ontologies", "for", "intelligence", "and", "automatic", "natural", "language", "understanding", "."], "sentence-detokenized": "At this company, he developed data mining and database technology, more specifically high-level ontologies for intelligence and automatic natural language understanding.", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 19], [20, 29], [30, 34], [35, 41], [42, 45], [46, 54], [55, 65], [65, 66], [67, 71], [72, 84], [85, 89], [89, 90], [90, 95], [96, 106], [107, 110], [111, 123], [124, 127], [128, 137], [138, 145], [146, 154], [155, 168], [168, 169]]}
{"doc_key": "ai-dev-24", "ner": [[23, 24, "misc"], [26, 29, "misc"], [33, 35, "misc"], [36, 36, "country"], [38, 40, "organisation"], [42, 42, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[23, 24, 36, 36, "physical", "", false, false], [26, 29, 36, 36, "physical", "", false, false], [33, 35, 36, 36, "physical", "", false, false], [38, 40, 42, 42, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "recent", "years", ",", "however", ",", "one", "can", "see", "the", "emergence", "of", "various", "e-services", "and", "related", "initiatives", "in", "developing", "countries", ",", "such", "as", "Project", "Nemmadi", ",", "MCA21", "Mission", "Mode", "Project", "or", "even", "more", "Digital", "India", "in", "India", ";", "Electronic", "Government", "Directorate", "in", "Pakistan", ";", "etc."], "sentence-detokenized": "In recent years, however, one can see the emergence of various e-services and related initiatives in developing countries, such as Project Nemmadi, MCA21 Mission Mode Project or even more Digital India in India; Electronic Government Directorate in Pakistan; etc.", "token2charspan": [[0, 2], [3, 9], [10, 15], [15, 16], [17, 24], [24, 25], [26, 29], [30, 33], [34, 37], [38, 41], [42, 51], [52, 54], [55, 62], [63, 73], [74, 77], [78, 85], [86, 97], [98, 100], [101, 111], [112, 121], [121, 122], [123, 127], [128, 130], [131, 138], [139, 146], [146, 147], [148, 153], [154, 161], [162, 166], [167, 174], [175, 177], [178, 182], [183, 187], [188, 195], [196, 201], [202, 204], [205, 210], [210, 211], [212, 222], [223, 233], [234, 245], [246, 248], [249, 257], [257, 258], [259, 263]]}
{"doc_key": "ai-dev-25", "ner": [[2, 3, "misc"], [5, 6, "field"], [8, 9, "field"], [11, 13, "university"], [17, 19, "university"], [27, 29, "university"], [33, 33, "misc"], [35, 36, "field"], [40, 45, "misc"], [44, 44, "university"], [47, 49, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[2, 3, 5, 6, "topic", "", false, false], [2, 3, 8, 9, "topic", "", false, false], [2, 3, 11, 13, "origin", "", false, false], [11, 13, 17, 19, "part-of", "", false, false], [27, 29, 11, 13, "part-of", "", false, false], [33, 33, 35, 36, "topic", "", false, false], [33, 33, 44, 44, "origin", "", false, false], [40, 45, 44, 44, "origin", "", false, false], [44, 44, 47, 49, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["He", "obtained", "his", "PhD", "in", "radio", "physics", "and", "electronics", "from", "the", "Rajabazar", "Science", "College", "campus", "of", "the", "University", "of", "Calcutta", "in", "1979", "as", "a", "student", "at", "the", "Indian", "Statistical", "Institute", ",", "and", "another", "PhD", "in", "electrical", "engineering", "along", "with", "an", "Imperial", "College", "degree", "from", "Imperial", "College", ",", "University", "of", "London", ",", "in", "1982", "."], "sentence-detokenized": "He obtained his PhD in radio physics and electronics from the Rajabazar Science College campus of the University of Calcutta in 1979 as a student at the Indian Statistical Institute, and another PhD in electrical engineering along with an Imperial College degree from Imperial College, University of London, in 1982.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 19], [20, 22], [23, 28], [29, 36], [37, 40], [41, 52], [53, 57], [58, 61], [62, 71], [72, 79], [80, 87], [88, 94], [95, 97], [98, 101], [102, 112], [113, 115], [116, 124], [125, 127], [128, 132], [133, 135], [136, 137], [138, 145], [146, 148], [149, 152], [153, 159], [160, 171], [172, 181], [181, 182], [183, 186], [187, 194], [195, 198], [199, 201], [202, 212], [213, 224], [225, 230], [231, 235], [236, 238], [239, 247], [248, 255], [256, 262], [263, 267], [268, 276], [277, 284], [284, 285], [286, 296], [297, 299], [300, 306], [306, 307], [308, 310], [311, 315], [315, 316]]}
{"doc_key": "ai-dev-26", "ner": [[0, 1, "location"], [22, 23, "misc"], [31, 32, "misc"], [34, 36, "person"], [38, 39, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[22, 23, 0, 1, "temporal", "", false, false], [31, 32, 0, 1, "temporal", "", false, false], [34, 36, 31, 32, "role", "actor_in", false, false], [38, 39, 31, 32, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Expo", "II", "was", "announced", "as", "the", "venue", "for", "the", "world", "premiere", "of", "several", "films", "never", "before", "seen", "in", "3D", ",", "including", "'", "Diamond", "Wizard", "'", "and", "Universal", "'s", "short", "film", "'", "Hawaiian", "Nights", "with", "Mamie", "Van", "Doren", "and", "Pinky", "Lee", "'", "."], "sentence-detokenized": "Expo II was announced as the venue for the world premiere of several films never before seen in 3D, including 'Diamond Wizard' and Universal's short film 'Hawaiian Nights with Mamie Van Doren and Pinky Lee'.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 24], [25, 28], [29, 34], [35, 38], [39, 42], [43, 48], [49, 57], [58, 60], [61, 68], [69, 74], [75, 80], [81, 87], [88, 92], [93, 95], [96, 98], [98, 99], [100, 109], [110, 111], [111, 118], [119, 125], [125, 126], [127, 130], [131, 140], [140, 142], [143, 148], [149, 153], [154, 155], [155, 163], [164, 170], [171, 175], [176, 181], [182, 185], [186, 191], [192, 195], [196, 201], [202, 205], [205, 206], [206, 207]]}
{"doc_key": "ai-dev-27", "ner": [[7, 9, "researcher"], [16, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 9, 16, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "maximum", "subarray", "problem", "was", "proposed", "by", "Ulf", "Grenander", "in", "1977", "as", "a", "simplified", "model", "for", "maximum", "likelihood", "estimation", "of", "patterns", "in", "digital", "images", "."], "sentence-detokenized": "The maximum subarray problem was proposed by Ulf Grenander in 1977 as a simplified model for maximum likelihood estimation of patterns in digital images.", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 28], [29, 32], [33, 41], [42, 44], [45, 48], [49, 58], [59, 61], [62, 66], [67, 69], [70, 71], [72, 82], [83, 88], [89, 92], [93, 100], [101, 111], [112, 122], [123, 125], [126, 134], [135, 137], [138, 145], [146, 152], [152, 153]]}
{"doc_key": "ai-dev-28", "ner": [[0, 2, "product"], [4, 5, "product"], [8, 9, "product"], [12, 12, "product"], [15, 16, "product"], [18, 21, "product"], [33, 33, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[33, 33, 0, 2, "part-of", "", false, false], [33, 33, 4, 5, "part-of", "", false, false], [33, 33, 8, 9, "part-of", "", false, false], [33, 33, 12, 12, "part-of", "", false, false], [33, 33, 15, 16, "part-of", "", false, false], [33, 33, 18, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "iPhone", "4S", ",", "iPad", "3", ",", "iPad", "Mini", "1G", ",", "iPad", "Air", ",", "iPad", "Pro", "1G", ",", "iPod", "Touch", "5", "G", "and", "newer", ",", "all", "feature", "a", "more", "advanced", "voice", "assistant", "called", "Siri", "."], "sentence-detokenized": "The iPhone 4S, iPad 3, iPad Mini 1G, iPad Air, iPad Pro 1G, iPod Touch 5G and newer, all feature a more advanced voice assistant called Siri.", "token2charspan": [[0, 3], [4, 10], [11, 13], [13, 14], [15, 19], [20, 21], [21, 22], [23, 27], [28, 32], [33, 35], [35, 36], [37, 41], [42, 45], [45, 46], [47, 51], [52, 55], [56, 58], [58, 59], [60, 64], [65, 70], [71, 72], [72, 73], [74, 77], [78, 83], [83, 84], [85, 88], [89, 96], [97, 98], [99, 103], [104, 112], [113, 118], [119, 128], [129, 135], [136, 140], [140, 141]]}
{"doc_key": "ai-dev-29", "ner": [[6, 8, "metrics"], [10, 14, "metrics"], [16, 17, "metrics"], [47, 49, "metrics"], [55, 58, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 14, 47, 49, "named", "", false, false], [16, 17, 10, 14, "named", "", false, false], [47, 49, 55, 58, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["It", "is", "easy", "to", "check", "that", "the", "logistic", "loss", "and", "the", "binary", "cross", "entropy", "loss", "(", "log", "loss", ")", "are", "in", "fact", "the", "same", "(", "up", "to", "the", "multiplicative", "constant", "math", "\\", "frac", "{", "1", "}", "{", "log", "(", "2", ")", "}", "/", "math", ")", ".", "The", "cross", "entropy", "loss", "is", "closely", "related", "to", "the", "Kullback", "-", "Leibler", "divergence", "between", "the", "empirical", "distribution", "and", "the", "predicted", "distribution", "."], "sentence-detokenized": "It is easy to check that the logistic loss and the binary cross entropy loss (log loss) are in fact the same (up to the multiplicative constant math\\ frac {1} {log (2)} / math) .The cross entropy loss is closely related to the Kullback-Leibler divergence between the empirical distribution and the predicted distribution.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 13], [14, 19], [20, 24], [25, 28], [29, 37], [38, 42], [43, 46], [47, 50], [51, 57], [58, 63], [64, 71], [72, 76], [77, 78], [78, 81], [82, 86], [86, 87], [88, 91], [92, 94], [95, 99], [100, 103], [104, 108], [109, 110], [110, 112], [113, 115], [116, 119], [120, 134], [135, 143], [144, 148], [148, 149], [150, 154], [155, 156], [156, 157], [157, 158], [159, 160], [160, 163], [164, 165], [165, 166], [166, 167], [167, 168], [169, 170], [171, 175], [175, 176], [177, 178], [178, 181], [182, 187], [188, 195], [196, 200], [201, 203], [204, 211], [212, 219], [220, 222], [223, 226], [227, 235], [235, 236], [236, 243], [244, 254], [255, 262], [263, 266], [267, 276], [277, 289], [290, 293], [294, 297], [298, 307], [308, 320], [320, 321]]}
{"doc_key": "ai-dev-30", "ner": [[0, 2, "algorithm"], [11, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 14, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "EM", "algorithm", "is", "used", "to", "find", "the", "(", "local", ")", "maximum", "likelihood", "of", "the", "statistical", "model", "parameters", "in", "cases", "where", "the", "equations", "can", "not", "be", "solved", "directly", "."], "sentence-detokenized": "The EM algorithm is used to find the (local) maximum likelihood of the statistical model parameters in cases where the equations cannot be solved directly.", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 19], [20, 24], [25, 27], [28, 32], [33, 36], [37, 38], [38, 43], [43, 44], [45, 52], [53, 63], [64, 66], [67, 70], [71, 82], [83, 88], [89, 99], [100, 102], [103, 108], [109, 114], [115, 118], [119, 128], [129, 132], [132, 135], [136, 138], [139, 145], [146, 154], [154, 155]]}
{"doc_key": "ai-dev-31", "ner": [[9, 10, "task"], [13, 17, "task"], [22, 22, "task"], [24, 24, "task"], [29, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "research", "was", "fundamental", "to", "the", "development", "of", "modern", "speech", "synthesis", "techniques", ",", "reading", "machines", "for", "the", "blind", ",", "research", "into", "speech", "perception", "and", "recognition", "and", "the", "development", "of", "a", "motor", "theory", "of", "speech", "perception", "."], "sentence-detokenized": "This research was fundamental to the development of modern speech synthesis techniques, reading machines for the blind, research into speech perception and recognition and the development of a motor theory of speech perception.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 29], [30, 32], [33, 36], [37, 48], [49, 51], [52, 58], [59, 65], [66, 75], [76, 86], [86, 87], [88, 95], [96, 104], [105, 108], [109, 112], [113, 118], [118, 119], [120, 128], [129, 133], [134, 140], [141, 151], [152, 155], [156, 167], [168, 171], [172, 175], [176, 187], [188, 190], [191, 192], [193, 198], [199, 205], [206, 208], [209, 215], [216, 226], [226, 227]]}
{"doc_key": "ai-dev-32", "ner": [[0, 1, "product"], [2, 4, "misc"], [6, 6, "misc"], [11, 12, "misc"], [15, 15, "product"], [17, 17, "product"], [19, 19, "product"], [26, 28, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 4, 0, 1, "origin", "", false, false], [2, 4, 11, 12, "type-of", "", false, false], [2, 4, 15, 15, "related-to", "program_for", false, false], [2, 4, 17, 17, "related-to", "program_for", false, false], [2, 4, 19, 19, "related-to", "program_for", false, false], [2, 4, 26, 28, "related-to", "program_for", false, false], [6, 6, 2, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "Arduino", "Integrated", "Development", "Environment", "(", "IDE", ")", "is", "a", "cross", "-platform", "application", "(", "for", "Windows", ",", "macOS", "and", "Linux", ")", "that", "is", "written", "in", "the", "Java", "programming", "language", "."], "sentence-detokenized": "The Arduino Integrated Development Environment (IDE) is a cross-platform application (for Windows, macOS and Linux) that is written in the Java programming language.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 34], [35, 46], [47, 48], [48, 51], [51, 52], [53, 55], [56, 57], [58, 63], [63, 72], [73, 84], [85, 86], [86, 89], [90, 97], [97, 98], [99, 104], [105, 108], [109, 114], [114, 115], [116, 120], [121, 123], [124, 131], [132, 134], [135, 138], [139, 143], [144, 155], [156, 164], [164, 165]]}
{"doc_key": "ai-dev-33", "ner": [[2, 3, "algorithm"], [9, 10, "field"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 9, 10, "opposite", "", false, false], [13, 14, 9, 10, "related-to", "works_with", false, false], [16, 17, 9, 10, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Research", "on", "neural", "networks", "stagnated", "after", "the", "publication", "of", "machine", "learning", "research", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", "."], "sentence-detokenized": "Research on neural networks stagnated after the publication of machine learning research by Marvin Minsky and Seymour Papert (1969).", "token2charspan": [[0, 8], [9, 11], [12, 18], [19, 27], [28, 37], [38, 43], [44, 47], [48, 59], [60, 62], [63, 70], [71, 79], [80, 88], [89, 91], [92, 98], [99, 105], [106, 109], [110, 117], [118, 124], [125, 126], [126, 130], [130, 131], [131, 132]]}
{"doc_key": "ai-dev-34", "ner": [[18, 19, "organisation"], [21, 21, "organisation"], [23, 26, "country"], [27, 31, "organisation"], [33, 34, "country"], [36, 37, "organisation"], [39, 40, "country"], [42, 42, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[27, 31, 23, 26, "general-affiliation", "", false, false], [36, 37, 33, 34, "general-affiliation", "", false, false], [42, 42, 39, 40, "general-affiliation", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Only", "a", "few", "non-Japanese", "companies", "eventually", "managed", "to", "survive", "in", "this", "market", ",", "the", "main", "ones", "being", ":", "Adept", "Technology", ",", "St\u00e4ubli", ",", "the", "Swedish", "-", "Swiss", "ABB", "company", "Asea", "Brown", "Boveri", ",", "the", "German", "company", "KUKA", "Robotics", "and", "the", "Italian", "company", "Comau", "."], "sentence-detokenized": "Only a few non-Japanese companies eventually managed to survive in this market, the main ones being: Adept Technology, St\u00e4ubli, the Swedish-Swiss ABB company Asea Brown Boveri, the German company KUKA Robotics and the Italian company Comau.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 23], [24, 33], [34, 44], [45, 52], [53, 55], [56, 63], [64, 66], [67, 71], [72, 78], [78, 79], [80, 83], [84, 88], [89, 93], [94, 99], [99, 100], [101, 106], [107, 117], [117, 118], [119, 126], [126, 127], [128, 131], [132, 139], [139, 140], [140, 145], [146, 149], [150, 157], [158, 162], [163, 168], [169, 175], [175, 176], [177, 180], [181, 187], [188, 195], [196, 200], [201, 209], [210, 213], [214, 217], [218, 225], [226, 233], [234, 239], [239, 240]]}
{"doc_key": "ai-dev-35", "ner": [[7, 8, "conference"], [13, 14, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Research", "activities", "include", "the", "annual", "scientific", "conference", "RuleML", "Symposium", ",", "also", "known", "as", "RuleML", "for", "short", "."], "sentence-detokenized": "Research activities include the annual scientific conference RuleML Symposium, also known as RuleML for short.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 31], [32, 38], [39, 49], [50, 60], [61, 67], [68, 77], [77, 78], [79, 83], [84, 89], [90, 92], [93, 99], [100, 103], [104, 109], [109, 110]]}
{"doc_key": "ai-dev-36", "ner": [[9, 9, "field"], [11, 12, "field"], [14, 14, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Concepts", "are", "used", "as", "formal", "tools", "or", "models", "in", "mathematics", ",", "computer", "science", ",", "databases", "and", "artificial", "intelligence", ",", "where", "they", "are", "sometimes", "called", "classes", ",", "schemas", "or", "categories", "."], "sentence-detokenized": "Concepts are used as formal tools or models in mathematics, computer science, databases and artificial intelligence, where they are sometimes called classes, schemas or categories.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 20], [21, 27], [28, 33], [34, 36], [37, 43], [44, 46], [47, 58], [58, 59], [60, 68], [69, 76], [76, 77], [78, 87], [88, 91], [92, 102], [103, 115], [115, 116], [117, 122], [123, 127], [128, 131], [132, 141], [142, 148], [149, 156], [156, 157], [158, 165], [166, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-dev-37", "ner": [[7, 10, "organisation"], [13, 18, "organisation"], [19, 19, "organisation"], [21, 23, "organisation"], [25, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "the", "recipient", "of", "awards", "from", "the", "American", "Psychological", "Association", ",", "the", "National", "Academy", "of", "Sciences", ",", "the", "Royal", ",", "Cognitive", "Neuroscience", "Society", "and", "the", "American", "Humanist", "Association", "."], "sentence-detokenized": "He is the recipient of awards from the American Psychological Association, the National Academy of Sciences, the Royal, Cognitive Neuroscience Society and the American Humanist Association.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 19], [20, 22], [23, 29], [30, 34], [35, 38], [39, 47], [48, 61], [62, 73], [73, 74], [75, 78], [79, 87], [88, 95], [96, 98], [99, 107], [107, 108], [109, 112], [113, 118], [118, 119], [120, 129], [130, 142], [143, 150], [151, 154], [155, 158], [159, 167], [168, 176], [177, 188], [188, 189]]}
{"doc_key": "ai-dev-38", "ner": [[1, 2, "person"], [4, 5, "person"], [7, 8, "person"], [15, 19, "person"], [21, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 27, 15, 19, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Starring", "Harrison", "Ford", ",", "Rutger", "Hauer", "and", "Sean", "Young", ",", "it", "is", "loosely", "based", "on", "Philip", "K", ".", "Dick", "'s", "novel", "Do", "Androids", "Dream", "of", "Electric", "Sheep", "?", "(", "1968", ")", "."], "sentence-detokenized": "Starring Harrison Ford, Rutger Hauer and Sean Young, it is loosely based on Philip K. Dick's novel Do Androids Dream of Electric Sheep? (1968).", "token2charspan": [[0, 8], [9, 17], [18, 22], [22, 23], [24, 30], [31, 36], [37, 40], [41, 45], [46, 51], [51, 52], [53, 55], [56, 58], [59, 66], [67, 72], [73, 75], [76, 82], [83, 84], [84, 85], [86, 90], [90, 92], [93, 98], [99, 101], [102, 110], [111, 116], [117, 119], [120, 128], [129, 134], [134, 135], [136, 137], [137, 141], [141, 142], [142, 143]]}
{"doc_key": "ai-dev-39", "ner": [[1, 1, "task"], [3, 5, "algorithm"], [11, 12, "field"], [14, 15, "task"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 3, 5, "usage", "", false, false], [1, 1, 11, 12, "part-of", "task_part_of_field", false, false], [1, 1, 14, 15, "part-of", "task_part_of_field", false, false], [1, 1, 17, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Image", "segmentation", "using", "k-means", "clustering", "algorithms", "has", "long", "been", "used", "in", "pattern", "recognition", ",", "object", "detection", "and", "medical", "imaging", "."], "sentence-detokenized": "Image segmentation using k-means clustering algorithms has long been used in pattern recognition, object detection and medical imaging.", "token2charspan": [[0, 5], [6, 18], [19, 24], [25, 32], [33, 43], [44, 54], [55, 58], [59, 63], [64, 68], [69, 73], [74, 76], [77, 84], [85, 96], [96, 97], [98, 104], [105, 114], [115, 118], [119, 126], [127, 134], [134, 135]]}
{"doc_key": "ai-dev-40", "ner": [[14, 14, "algorithm"], [16, 18, "algorithm"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["General", "sampling", "from", "the", "truncated", "normal", "can", "be", "achieved", "using", "approximations", "to", "the", "normal", "CDF", "and", "a", "probit", "function", ",", "and", "R", "has", "a", "codertnorm", "(", ")", "/", "code", "function", "to", "generate", "samples", "of", "the", "truncated", "normal", "."], "sentence-detokenized": "General sampling from the truncated normal can be achieved using approximations to the normal CDF and a probit function, and R has a codertnorm () / code function to generate samples of the truncated normal.", "token2charspan": [[0, 7], [8, 16], [17, 21], [22, 25], [26, 35], [36, 42], [43, 46], [47, 49], [50, 58], [59, 64], [65, 79], [80, 82], [83, 86], [87, 93], [94, 97], [98, 101], [102, 103], [104, 110], [111, 119], [119, 120], [121, 124], [125, 126], [127, 130], [131, 132], [133, 143], [144, 145], [145, 146], [147, 148], [149, 153], [154, 162], [163, 165], [166, 174], [175, 182], [183, 185], [186, 189], [190, 199], [200, 206], [206, 207]]}
{"doc_key": "ai-dev-41", "ner": [[7, 10, "university"], [12, 12, "university"], [14, 16, "university"], [19, 21, "university"], [26, 26, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "also", "received", "honorary", "doctorates", "from", "the", "universities", "of", "Newcastle", ",", "Surrey", ",", "Tel", "Aviv", "University", ",", ",", "Simon", "Fraser", "University", "and", "the", "University", "of", "Troms\u00f8", "."], "sentence-detokenized": "He has also received honorary doctorates from the universities of Newcastle, Surrey, Tel Aviv University,, Simon Fraser University and the University of Troms\u00f8.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 20], [21, 29], [30, 40], [41, 45], [46, 49], [50, 62], [63, 65], [66, 75], [75, 76], [77, 83], [83, 84], [85, 88], [89, 93], [94, 104], [104, 105], [105, 106], [107, 112], [113, 119], [120, 130], [131, 134], [135, 138], [139, 149], [150, 152], [153, 159], [159, 160]]}
{"doc_key": "ai-dev-42", "ner": [[1, 1, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "Java", "implementation", "using", "zero", "-", "based", "array", "indexes", "together", "with", "a", "convenient", "method", "for", "printing", "the", "resolved", "order", "of", "operations", ":"], "sentence-detokenized": "A Java implementation using zero-based array indexes together with a convenient method for printing the resolved order of operations:", "token2charspan": [[0, 1], [2, 6], [7, 21], [22, 27], [28, 32], [32, 33], [33, 38], [39, 44], [45, 52], [53, 61], [62, 66], [67, 68], [69, 79], [80, 86], [87, 90], [91, 99], [100, 103], [104, 112], [113, 118], [119, 121], [122, 132], [132, 133]]}
{"doc_key": "ai-dev-43", "ner": [[7, 12, "metrics"], [21, 23, "algorithm"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "networks", "are", "commonly", "trained", "in", "the", "cross", "-entropy", "(", "or", "cross", "-entropy", ")", "regime", ",", "yielding", "a", "non-linear", "variant", "of", "multinomial", "logistic", "regression", "."], "sentence-detokenized": "Such networks are commonly trained in the cross-entropy (or cross-entropy) regime, yielding a non-linear variant of multinomial logistic regression.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 26], [27, 34], [35, 37], [38, 41], [42, 47], [47, 55], [56, 57], [57, 59], [60, 65], [65, 73], [73, 74], [75, 81], [81, 82], [83, 91], [92, 93], [94, 104], [105, 112], [113, 115], [116, 127], [128, 136], [137, 147], [147, 148]]}
{"doc_key": "ai-dev-44", "ner": [[0, 0, "conference"], [3, 3, "misc"], [6, 12, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["ACL", "has", "a", "European", "(", "European", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ")"], "sentence-detokenized": "ACL has a European (European Chapter of the Association for Computational Linguistics)", "token2charspan": [[0, 3], [4, 7], [8, 9], [10, 18], [19, 20], [20, 28], [29, 36], [37, 39], [40, 43], [44, 55], [56, 59], [60, 73], [74, 85], [85, 86]]}
{"doc_key": "ai-dev-45", "ner": [[3, 4, "researcher"], [6, 8, "researcher"], [22, 22, "misc"], [24, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 22, 22, "role", "", false, false], [6, 8, 22, 22, "role", "", false, false], [22, 22, 24, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "professors", ",", "Hal", "Abelson", "and", "Gerald", "Jay", "Sussman", ",", "decided", "to", "remain", "neutral", "-", "their", "group", "was", "variously", "referred", "to", "as", "Switzerland", "and", "Project", "MAC", "for", "the", "next", "30", "years", "."], "sentence-detokenized": "Two professors, Hal Abelson and Gerald Jay Sussman, decided to remain neutral - their group was variously referred to as Switzerland and Project MAC for the next 30 years.", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 27], [28, 31], [32, 38], [39, 42], [43, 50], [50, 51], [52, 59], [60, 62], [63, 69], [70, 77], [78, 79], [80, 85], [86, 91], [92, 95], [96, 105], [106, 114], [115, 117], [118, 120], [121, 132], [133, 136], [137, 144], [145, 148], [149, 152], [153, 156], [157, 161], [162, 164], [165, 170], [170, 171]]}
{"doc_key": "ai-dev-46", "ner": [[2, 3, "misc"], [5, 5, "researcher"], [8, 12, "university"], [16, 16, "organisation"], [21, 23, "organisation"], [27, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 5, 5, "temporal", "", false, false], [5, 5, 16, 16, "physical", "", false, false], [5, 5, 16, 16, "role", "", false, false], [5, 5, 21, 23, "role", "", false, false], [21, 23, 8, 12, "part-of", "", false, false], [27, 28, 21, 23, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["After", "completing", "his", "PhD", ",", "Ghahramani", "moved", "to", "the", "University", "of", "Toronto", "in", "1995", "as", "an", "ITRC", "Postdoctoral", "Fellow", "in", "the", "Artificial", "Intelligence", "Lab", ",", "working", "with", "Geoffrey", "Hinton", "."], "sentence-detokenized": "After completing his PhD, Ghahramani moved to the University of Toronto in 1995 as an ITRC Postdoctoral Fellow in the Artificial Intelligence Lab, working with Geoffrey Hinton.", "token2charspan": [[0, 5], [6, 16], [17, 20], [21, 24], [24, 25], [26, 36], [37, 42], [43, 45], [46, 49], [50, 60], [61, 63], [64, 71], [72, 74], [75, 79], [80, 82], [83, 85], [86, 90], [91, 103], [104, 110], [111, 113], [114, 117], [118, 128], [129, 141], [142, 145], [145, 146], [147, 154], [155, 159], [160, 168], [169, 175], [175, 176]]}
{"doc_key": "ai-dev-47", "ner": [[24, 25, "metrics"], [27, 27, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[27, 27, 24, 25, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Subsequent", "work", "has", "focused", "on", "solving", "these", "problems", ",", "but", "it", "was", "not", "until", "the", "advent", "of", "the", "modern", "computer", "and", "the", "popularisation", "of", "Maximum", "Likelihood", "(", "MLE", ")", "parameterisation", "techniques", "that", "research", "really", "flourished", "."], "sentence-detokenized": "Subsequent work has focused on solving these problems, but it was not until the advent of the modern computer and the popularisation of Maximum Likelihood (MLE) parameterisation techniques that research really flourished.", "token2charspan": [[0, 10], [11, 15], [16, 19], [20, 27], [28, 30], [31, 38], [39, 44], [45, 53], [53, 54], [55, 58], [59, 61], [62, 65], [66, 69], [70, 75], [76, 79], [80, 86], [87, 89], [90, 93], [94, 100], [101, 109], [110, 113], [114, 117], [118, 132], [133, 135], [136, 143], [144, 154], [155, 156], [156, 159], [159, 160], [161, 177], [178, 188], [189, 193], [194, 202], [203, 209], [210, 220], [220, 221]]}
{"doc_key": "ai-dev-48", "ner": [[5, 6, "person"], [9, 10, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "series", "was", "produced", "by", "David", "Fincher", "and", "starred", "Kevin", "Spacey", "."], "sentence-detokenized": "The series was produced by David Fincher and starred Kevin Spacey.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 26], [27, 32], [33, 40], [41, 44], [45, 52], [53, 58], [59, 65], [65, 66]]}
{"doc_key": "ai-dev-49", "ner": [[16, 16, "metrics"], [23, 24, "algorithm"], [30, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 24, 30, 31, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Due", "to", "limited", "computational", "power", ",", "current", "in", "silico", "methods", "usually", "have", "to", "trade", "speed", "for", "accuracy", ";", "for", "example", ",", "using", "fast", "protein", "docking", "methods", "instead", "of", "computationally", "expensive", "free", "energy", "calculations", "."], "sentence-detokenized": "Due to limited computational power, current in silico methods usually have to trade speed for accuracy; for example, using fast protein docking methods instead of computationally expensive free energy calculations.", "token2charspan": [[0, 3], [4, 6], [7, 14], [15, 28], [29, 34], [34, 35], [36, 43], [44, 46], [47, 53], [54, 61], [62, 69], [70, 74], [75, 77], [78, 83], [84, 89], [90, 93], [94, 102], [102, 103], [104, 107], [108, 115], [115, 116], [117, 122], [123, 127], [128, 135], [136, 143], [144, 151], [152, 159], [160, 162], [163, 178], [179, 188], [189, 193], [194, 200], [201, 213], [213, 214]]}
{"doc_key": "ai-dev-50", "ner": [[8, 9, "country"], [11, 11, "country"], [0, 13, "country"], [15, 15, "country"], [17, 17, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "has", "had", "more", "than", "30", "locations", "in", "the", "USA", ",", "Canada", ",", "Mexico", ",", "Brazil", "and", "Argentina", "."], "sentence-detokenized": "It has had more than 30 locations in the USA , Canada, Mexico, Brazil and Argentina.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 15], [16, 20], [21, 23], [24, 33], [34, 36], [37, 40], [41, 44], [45, 46], [47, 53], [53, 54], [55, 61], [61, 62], [63, 69], [70, 73], [74, 83], [83, 84]]}
{"doc_key": "ai-dev-51", "ner": [[9, 11, "product"], [13, 15, "algorithm"], [18, 19, "task"], [21, 22, "task"], [28, 28, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[9, 11, 13, 15, "usage", "", false, false], [18, 19, 28, 28, "related-to", "performs", false, false], [21, 22, 28, 28, "related-to", "performs", false, false]], "relations_mapping_to_source": [1, 3, 5], "sentence": ["An", "example", "of", "a", "typical", "computational", "pipeline", "for", "a", "face", "recognition", "system", "using", "k", "-", "NN", ",", "including", "feature", "extraction", "and", "pre-dimension", "reduction", "stages", "(", "typically", "implemented", "using", "OpenCV", ")", ":"], "sentence-detokenized": "An example of a typical computational pipeline for a face recognition system using k -NN, including feature extraction and pre-dimension reduction stages (typically implemented using OpenCV):", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 23], [24, 37], [38, 46], [47, 50], [51, 52], [53, 57], [58, 69], [70, 76], [77, 82], [83, 84], [85, 86], [86, 88], [88, 89], [90, 99], [100, 107], [108, 118], [119, 122], [123, 136], [137, 146], [147, 153], [154, 155], [155, 164], [165, 176], [177, 182], [183, 189], [189, 190], [190, 191]]}
{"doc_key": "ai-dev-52", "ner": [[9, 11, "algorithm"], [13, 13, "misc"], [15, 16, "misc"], [18, 18, "misc"], [22, 22, "programlang"], [24, 24, "product"], [28, 29, "algorithm"], [31, 32, "misc"], [34, 34, "misc"], [36, 36, "misc"], [38, 38, "misc"], [44, 44, "misc"], [46, 46, "misc"], [48, 49, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "has", "a", "rich", "feature", "set", ",", "libraries", "for", "constraint", "logic", "programming", ",", "multithreading", ",", "unit", "testing", ",", "GUI", ",", "interfaces", "to", "Java", ",", "ODBC", "and", "others", ",", "literate", "programming", ",", "web", "server", ",", "SGML", ",", "RDF", ",", "RDFS", ",", "developer", "tools", "(", "including", "IDE", "with", "debugger", "and", "GUI", "profiler", ")", "and", "extensive", "documentation", "."], "sentence-detokenized": "It has a rich feature set, libraries for constraint logic programming, multithreading, unit testing, GUI, interfaces to Java, ODBC and others, literate programming, web server, SGML, RDF, RDFS, developer tools (including IDE with debugger and GUI profiler) and extensive documentation.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 13], [14, 21], [22, 25], [25, 26], [27, 36], [37, 40], [41, 51], [52, 57], [58, 69], [69, 70], [71, 85], [85, 86], [87, 91], [92, 99], [99, 100], [101, 104], [104, 105], [106, 116], [117, 119], [120, 124], [124, 125], [126, 130], [131, 134], [135, 141], [141, 142], [143, 151], [152, 163], [163, 164], [165, 168], [169, 175], [175, 176], [177, 181], [181, 182], [183, 186], [186, 187], [188, 192], [192, 193], [194, 203], [204, 209], [210, 211], [211, 220], [221, 224], [225, 229], [230, 238], [239, 242], [243, 246], [247, 255], [255, 256], [257, 260], [261, 270], [271, 284], [284, 285]]}
{"doc_key": "ai-dev-53", "ner": [[1, 2, "field"], [5, 7, "field"], [10, 12, "misc"], [14, 16, "misc"], [20, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 12, 1, 2, "part-of", "", true, false], [10, 12, 5, 7, "part-of", "", false, false], [10, 12, 20, 22, "type-of", "", false, false], [14, 16, 1, 2, "part-of", "", false, false], [14, 16, 5, 7, "part-of", "", false, false], [14, 16, 20, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "computer", "vision", "and", "image", "processing", ",", "the", "notion", "of", "scale", "space", "representation", "and", "Gaussian", "derivative", "operators", "is", "as", "a", "canonical", "multiscale", "representation", "."], "sentence-detokenized": "In computer vision and image processing, the notion of scale space representation and Gaussian derivative operators is as a canonical multiscale representation.", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 22], [23, 28], [29, 39], [39, 40], [41, 44], [45, 51], [52, 54], [55, 60], [61, 66], [67, 81], [82, 85], [86, 94], [95, 105], [106, 115], [116, 118], [119, 121], [122, 123], [124, 133], [134, 144], [145, 159], [159, 160]]}
{"doc_key": "ai-dev-54", "ner": [[6, 10, "organisation"], [19, 24, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 10, 19, 24, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "also", "president", "of", "the", "Neural", "Information", "Processing", "Systems", "Foundation", ",", "a", "non-profit", "organisation", "that", "oversees", "the", "annual", "Conference", "on", "Neural", "Information", "Processing", "Systems", "."], "sentence-detokenized": "He is also president of the Neural Information Processing Systems Foundation, a non-profit organisation that oversees the annual Conference on Neural Information Processing Systems.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 20], [21, 23], [24, 27], [28, 34], [35, 46], [47, 57], [58, 65], [66, 76], [76, 77], [78, 79], [80, 90], [91, 103], [104, 108], [109, 117], [118, 121], [122, 128], [129, 139], [140, 142], [143, 149], [150, 161], [162, 172], [173, 180], [180, 181]]}
{"doc_key": "ai-dev-55", "ner": [[1, 2, "task"], [6, 7, "metrics"], [13, 14, "misc"], [17, 17, "task"], [18, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 6, 7, "usage", "", false, false], [6, 7, 13, 14, "type-of", "", false, false], [17, 17, 18, 20, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["For", "regression", "analysis", "problems", ",", "the", "quadratic", "error", "can", "be", "used", "as", "the", "loss", "function", ",", "for", "classification", "the", "cross", "entropy", "."], "sentence-detokenized": "For regression analysis problems, the quadratic error can be used as the loss function, for classification the cross entropy.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 32], [32, 33], [34, 37], [38, 47], [48, 53], [54, 57], [58, 60], [61, 65], [66, 68], [69, 72], [73, 77], [78, 86], [86, 87], [88, 91], [92, 106], [107, 110], [111, 116], [117, 124], [124, 125]]}
{"doc_key": "ai-dev-56", "ner": [[0, 2, "researcher"], [23, 25, "conference"], [20, 22, "conference"], [31, 36, "university"], [37, 38, "field"], [46, 50, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 23, 25, "role", "", false, false], [0, 2, 31, 36, "physical", "", false, false], [0, 2, 31, 36, "role", "", false, false], [0, 2, 46, 50, "role", "", false, false], [23, 25, 20, 22, "named", "same", false, false], [31, 36, 37, 38, "related-to", "subject_of_study_at", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Lafferty", "has", "held", "a", "number", "of", "prestigious", "positions", ",", "including", ":", "1", ")", "program", "and", "general", "co-chair", "of", "the", "Foundation", "Conference", "on", "Neural", "Information", "Processing", "Systems", ";", "2", ")", "co-director", "of", "CMU", "'s", "new", "PhD", "program", "in", "machine", "learning", ";", "3", ")", "associate", "editor", "of", "the", "Journal", "of", "Machine", "Learning", "Research"], "sentence-detokenized": "Lafferty has held a number of prestigious positions, including: 1) program and general co-chair of the Foundation Conference on Neural Information Processing Systems; 2) co-director of CMU's new PhD program in machine learning; 3) associate editor of the Journal of Machine Learning Research", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 19], [20, 26], [27, 29], [30, 41], [42, 51], [51, 52], [53, 62], [62, 63], [64, 65], [65, 66], [67, 74], [75, 78], [79, 86], [87, 95], [96, 98], [99, 102], [103, 113], [114, 124], [125, 127], [128, 134], [135, 146], [147, 157], [158, 165], [165, 166], [167, 168], [168, 169], [170, 181], [182, 184], [185, 188], [188, 190], [191, 194], [195, 198], [199, 206], [207, 209], [210, 217], [218, 226], [226, 227], [228, 229], [229, 230], [231, 240], [241, 247], [248, 250], [251, 254], [255, 262], [263, 265], [266, 273], [274, 282], [283, 291]]}
{"doc_key": "ai-dev-57", "ner": [[0, 1, "misc"], [4, 4, "algorithm"], [6, 6, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 0, 1, "type-of", "", false, false], [6, 6, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Convex", "algorithms", "such", "as", "AdaBoost", "and", "LogitBoost", "can", "be", "overcome", "by", "random", "noise", ",", "making", "them", "unable", "to", "learn", "basic", "and", "learnable", "combinations", "of", "weak", "hypotheses", "."], "sentence-detokenized": "Convex algorithms such as AdaBoost and LogitBoost can be overcome by random noise, making them unable to learn basic and learnable combinations of weak hypotheses.", "token2charspan": [[0, 6], [7, 17], [18, 22], [23, 25], [26, 34], [35, 38], [39, 49], [50, 53], [54, 56], [57, 65], [66, 68], [69, 75], [76, 81], [81, 82], [83, 89], [90, 94], [95, 101], [102, 104], [105, 110], [111, 116], [117, 120], [121, 130], [131, 143], [144, 146], [147, 151], [152, 162], [162, 163]]}
{"doc_key": "ai-dev-58", "ner": [[0, 0, "product"], [3, 6, "product"], [9, 11, "algorithm"], [17, 18, "algorithm"], [21, 26, "task"], [29, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 6, "type-of", "", false, false], [0, 0, 9, 11, "usage", "", false, false], [0, 0, 17, 18, "usage", "", false, false], [17, 18, 21, 26, "related-to", "used_for", true, false], [17, 18, 29, 30, "related-to", "used_for", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Apertium", "is", "a", "shallow", "machine", "translation", "system", "that", "uses", "finite", "state", "transducers", "for", "all", "lexical", "transformations", "and", "hidden", "Markov", "models", "for", "part", "-", "of", "-", "speech", "tagging", "and", "word", "category", "distinction", "."], "sentence-detokenized": "Apertium is a shallow machine translation system that uses finite state transducers for all lexical transformations and hidden Markov models for part-of-speech tagging and word category distinction.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 21], [22, 29], [30, 41], [42, 48], [49, 53], [54, 58], [59, 65], [66, 71], [72, 83], [84, 87], [88, 91], [92, 99], [100, 115], [116, 119], [120, 126], [127, 133], [134, 140], [141, 144], [145, 149], [149, 150], [150, 152], [152, 153], [153, 159], [160, 167], [168, 171], [172, 176], [177, 185], [186, 197], [197, 198]]}
{"doc_key": "ai-dev-59", "ner": [[0, 3, "misc"], [14, 17, "metrics"], [32, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 14, 17, "related-to", "", true, false], [14, 17, 32, 33, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "natural", "gradient", "of", "mathE", "f", "(", "x", ")", "/", "math", ",", "consistent", "with", "Fisher", "'s", "information", "metric", "(", "an", "information", "measure", "of", "the", "distance", "between", "probability", "distributions", "and", "the", "curvature", "of", "relative", "entropy", ")", ",", "is", "now", "of", "the", "form"], "sentence-detokenized": "The natural gradient of mathE f (x) / math, consistent with Fisher's information metric (an information measure of the distance between probability distributions and the curvature of relative entropy), is now of the form", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 23], [24, 29], [30, 31], [32, 33], [33, 34], [34, 35], [36, 37], [38, 42], [42, 43], [44, 54], [55, 59], [60, 66], [66, 68], [69, 80], [81, 87], [88, 89], [89, 91], [92, 103], [104, 111], [112, 114], [115, 118], [119, 127], [128, 135], [136, 147], [148, 161], [162, 165], [166, 169], [170, 179], [180, 182], [183, 191], [192, 199], [199, 200], [200, 201], [202, 204], [205, 208], [209, 211], [212, 215], [216, 220]]}
{"doc_key": "ai-dev-60", "ner": [[0, 5, "programlang"], [9, 12, "product"], [14, 15, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 12, 0, 5, "origin", "", false, false], [14, 15, 0, 5, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "S", "programming", "language", "was", "the", "inspiration", "for", "the", "'S", "'", "-", "PLUS", "and", "R", "systems", "."], "sentence-detokenized": "The S programming language was the inspiration for the 'S'-PLUS and R systems.", "token2charspan": [[0, 3], [4, 5], [6, 17], [18, 26], [27, 30], [31, 34], [35, 46], [47, 50], [51, 54], [55, 57], [57, 58], [58, 59], [59, 63], [64, 67], [68, 69], [70, 77], [77, 78]]}
{"doc_key": "ai-dev-61", "ner": [[10, 10, "product"], [13, 15, "product"], [19, 21, "researcher"], [23, 24, "researcher"], [26, 27, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[13, 15, 10, 10, "origin", "derived_from", false, false], [13, 15, 19, 21, "origin", "", false, false], [13, 15, 23, 24, "origin", "", false, false], [13, 15, 26, 27, "origin", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4], "sentence": ["The", "most", "influential", "implementation", "of", "Planner", "was", "a", "subset", "of", "Planner", ",", "called", "Micro", "-", "Planner", ",", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "."], "sentence-detokenized": "The most influential implementation of Planner was a subset of Planner, called Micro-Planner, implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd.", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 35], [36, 38], [39, 46], [47, 50], [51, 52], [53, 59], [60, 62], [63, 70], [70, 71], [72, 78], [79, 84], [84, 85], [85, 92], [92, 93], [94, 105], [106, 108], [109, 115], [116, 119], [120, 127], [127, 128], [129, 135], [136, 144], [145, 148], [149, 154], [155, 163], [163, 164]]}
{"doc_key": "ai-dev-62", "ner": [[3, 6, "country"], [8, 10, "researcher"], [19, 20, "misc"], [21, 26, "university"], [32, 33, "misc"], [32, 41, "misc"], [48, 50, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [[8, 10, 3, 6, "general-affiliation", "from_country", false, false], [21, 26, 19, 20, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "1779", ",", "the", "German", "-", "Danish", "scientist", "Christian", "Gottlieb", "Kratzenstein", "won", "first", "prize", "in", "a", "competition", "announced", "by", "the", "Russian", "Imperial", "Academy", "of", "Sciences", "and", "Arts", "for", "models", "of", "the", "human", "vocal", "tract", "he", "built", "that", "could", "produce", "five", "long", "vowels", "(", "in", "the", "notation", "of", "the", "International", "Phonetic", "Alphabet", ":"], "sentence-detokenized": "In 1779, the German-Danish scientist Christian Gottlieb Kratzenstein won first prize in a competition announced by the Russian Imperial Academy of Sciences and Arts for models of the human vocal tract he built that could produce five long vowels (in the notation of the International Phonetic Alphabet:", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 19], [19, 20], [20, 26], [27, 36], [37, 46], [47, 55], [56, 68], [69, 72], [73, 78], [79, 84], [85, 87], [88, 89], [90, 101], [102, 111], [112, 114], [115, 118], [119, 126], [127, 135], [136, 143], [144, 146], [147, 155], [156, 159], [160, 164], [165, 168], [169, 175], [176, 178], [179, 182], [183, 188], [189, 194], [195, 200], [201, 203], [204, 209], [210, 214], [215, 220], [221, 228], [229, 233], [234, 238], [239, 245], [246, 247], [247, 249], [250, 253], [254, 262], [263, 265], [266, 269], [270, 283], [284, 292], [293, 301], [301, 302]]}
{"doc_key": "ai-dev-63", "ner": [[3, 4, "product"], [6, 7, "misc"], [10, 14, "misc"], [31, 33, "misc"], [55, 57, "task"], [61, 62, "product"], [64, 64, "product"], [68, 68, "task"], [70, 71, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 4, 61, 62, "related-to", "supports_program", false, false], [3, 4, 64, 64, "related-to", "supports_program", false, false], [6, 7, 3, 4, "part-of", "", false, false], [10, 14, 3, 4, "part-of", "", false, false], [31, 33, 3, 4, "part-of", "", false, false], [55, 57, 3, 4, "part-of", "", false, false], [68, 68, 3, 4, "part-of", "", false, false], [70, 71, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["New", "features", "in", "Office", "XP", "include", "smart", "markup", ",", "a", "selection", "-", "based", "search", "function", "that", "recognises", "different", "text", "types", "in", "a", "document", "so", "users", "can", "perform", "additional", "actions", ";", "a", "task", "pane", "interface", "that", "consolidates", "popular", "menu", "bar", "commands", "on", "the", "right", "-", "hand", "side", "of", "the", "screen", "for", "easy", "quick", "access", ";", "new", "document", "collaboration", "capabilities", ",", "support", "for", "MSN", "Groups", "and", "SharePoint", ";", "and", "integrated", "handwriting", "and", "speech", "recognition", "."], "sentence-detokenized": "New features in Office XP include smart markup, a selection-based search function that recognises different text types in a document so users can perform additional actions; a task pane interface that consolidates popular menu bar commands on the right-hand side of the screen for easy quick access; new document collaboration capabilities, support for MSN Groups and SharePoint; and integrated handwriting and speech recognition.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 22], [23, 25], [26, 33], [34, 39], [40, 46], [46, 47], [48, 49], [50, 59], [59, 60], [60, 65], [66, 72], [73, 81], [82, 86], [87, 97], [98, 107], [108, 112], [113, 118], [119, 121], [122, 123], [124, 132], [133, 135], [136, 141], [142, 145], [146, 153], [154, 164], [165, 172], [172, 173], [174, 175], [176, 180], [181, 185], [186, 195], [196, 200], [201, 213], [214, 221], [222, 226], [227, 230], [231, 239], [240, 242], [243, 246], [247, 252], [252, 253], [253, 257], [258, 262], [263, 265], [266, 269], [270, 276], [277, 280], [281, 285], [286, 291], [292, 298], [298, 299], [300, 303], [304, 312], [313, 326], [327, 339], [339, 340], [341, 348], [349, 352], [353, 356], [357, 363], [364, 367], [368, 378], [378, 379], [380, 383], [384, 394], [395, 406], [407, 410], [411, 417], [418, 429], [429, 430]]}
{"doc_key": "ai-dev-64", "ner": [[12, 16, "algorithm"], [15, 15, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 16, 15, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "many", "applications", ",", "the", "units", "of", "these", "networks", "use", "a", "sigmoidal", "function", "as", "the", "activation", "function", "."], "sentence-detokenized": "In many applications, the units of these networks use a sigmoidal function as the activation function.", "token2charspan": [[0, 2], [3, 7], [8, 20], [20, 21], [22, 25], [26, 31], [32, 34], [35, 40], [41, 49], [50, 53], [54, 55], [56, 65], [66, 74], [75, 77], [78, 81], [82, 92], [93, 101], [101, 102]]}
{"doc_key": "ai-dev-65", "ner": [[3, 3, "researcher"], [11, 17, "organisation"], [29, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 11, 17, "role", "", false, false], [3, 3, 29, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2001", ",", "Mehler", "was", "elected", "a", "foreign", "honorary", "member", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "and", "in", "2003", "he", "was", "elected", "a", "Fellow", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In 2001, Mehler was elected a foreign honorary member of the American Academy of Arts and Sciences, and in 2003 he was elected a Fellow of the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 27], [28, 29], [30, 37], [38, 46], [47, 53], [54, 56], [57, 60], [61, 69], [70, 77], [78, 80], [81, 85], [86, 89], [90, 98], [98, 99], [100, 103], [104, 106], [107, 111], [112, 114], [115, 118], [119, 126], [127, 128], [129, 135], [136, 138], [139, 142], [143, 151], [152, 163], [164, 167], [168, 171], [172, 183], [184, 186], [187, 194], [194, 195]]}
{"doc_key": "ai-dev-66", "ner": [[4, 6, "task"], [8, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 8, 10, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Extending", "this", "concept", "to", "non", "-binary", "classifications", "yields", "a", "confusion", "matrix", "."], "sentence-detokenized": "Extending this concept to non-binary classifications yields a confusion matrix.", "token2charspan": [[0, 9], [10, 14], [15, 22], [23, 25], [26, 29], [29, 36], [37, 52], [53, 59], [60, 61], [62, 71], [72, 78], [78, 79]]}
{"doc_key": "ai-dev-67", "ner": [[13, 14, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "updated", "estimate", "of", "the", "measurement", "noise", "variance", "can", "be", "obtained", "from", "a", "maximum", "likelihood", "calculation", "of", "the"], "sentence-detokenized": "An updated estimate of the measurement noise variance can be obtained from a maximum likelihood calculation of the", "token2charspan": [[0, 2], [3, 10], [11, 19], [20, 22], [23, 26], [27, 38], [39, 44], [45, 53], [54, 57], [58, 60], [61, 69], [70, 74], [75, 76], [77, 84], [85, 95], [96, 107], [108, 110], [111, 114]]}
{"doc_key": "ai-dev-68", "ner": [[2, 4, "field"], [5, 5, "algorithm"], [8, 9, "field"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 8, 9, "usage", "", true, false], [5, 5, 12, 13, "related-to", "", true, false], [8, 9, 2, 4, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "machine", "learning", ",", "the", "perceptron", "is", "a", "supervised", "learning", "algorithm", "for", "binary", "classification", "."], "sentence-detokenized": "In machine learning, the perceptron is a supervised learning algorithm for binary classification.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 24], [25, 35], [36, 38], [39, 40], [41, 51], [52, 60], [61, 70], [71, 74], [75, 81], [82, 96], [96, 97]]}
{"doc_key": "ai-dev-69", "ner": [[11, 12, "field"], [14, 17, "field"], [20, 24, "conference"], [29, 30, "conference"], [34, 38, "conference"], [40, 44, "conference"], [46, 50, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[20, 24, 11, 12, "topic", "", false, false], [20, 24, 14, 17, "topic", "", false, false], [29, 30, 11, 12, "topic", "", false, false], [29, 30, 14, 17, "topic", "", false, false], [34, 38, 11, 12, "topic", "", false, false], [34, 38, 14, 17, "topic", "", false, false], [40, 44, 11, 12, "topic", "", false, false], [40, 44, 14, 17, "topic", "", false, false], [46, 50, 11, 12, "topic", "", false, false], [46, 50, 14, 17, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["She", "has", "also", "served", "as", "Area", "Chair", "at", "a", "number", "of", "machine", "learning", "and", "vision", "conferences", ",", "including", "the", "Conference", "on", "Neural", "Information", "Processing", "Systems", ",", "International", "Conference", "on", "Learning", "Representations", ",", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "International", "Conference", "on", "Computer", "Vision", "and", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "She has also served as Area Chair at a number of machine learning and vision conferences, including the Conference on Neural Information Processing Systems, International Conference on Learning Representations, Conference on Computer Vision and Pattern Recognition, International Conference on Computer Vision and European Conference on Computer Vision.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 19], [20, 22], [23, 27], [28, 33], [34, 36], [37, 38], [39, 45], [46, 48], [49, 56], [57, 65], [66, 69], [70, 76], [77, 88], [88, 89], [90, 99], [100, 103], [104, 114], [115, 117], [118, 124], [125, 136], [137, 147], [148, 155], [155, 156], [157, 170], [171, 181], [182, 184], [185, 193], [194, 209], [209, 210], [211, 221], [222, 224], [225, 233], [234, 240], [241, 244], [245, 252], [253, 264], [264, 265], [266, 279], [280, 290], [291, 293], [294, 302], [303, 309], [310, 313], [314, 322], [323, 333], [334, 336], [337, 345], [346, 352], [352, 353]]}
{"doc_key": "ai-dev-70", "ner": [[0, 2, "algorithm"], [8, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 10, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "condensation", "algorithm", "was", "also", "used", "for", "the", "facial", "recognition", "system", "in", "the", "video", "sequence", "."], "sentence-detokenized": "The condensation algorithm was also used for the facial recognition system in the video sequence.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 30], [31, 35], [36, 40], [41, 44], [45, 48], [49, 55], [56, 67], [68, 74], [75, 77], [78, 81], [82, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-dev-71", "ner": [[0, 2, "task"], [7, 7, "organisation"], [18, 18, "conference"], [22, 29, "academicjournal"], [29, 29, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[18, 18, 0, 2, "topic", "", false, false], [18, 18, 7, 7, "origin", "", false, false], [22, 29, 0, 2, "topic", "", false, false], [22, 29, 7, 7, "origin", "", true, false], [29, 29, 22, 29, "role", "edited_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Dissemination", "of", "information", "is", "also", "part", "of", "ELRA", "'s", "mission", ",", "which", "is", "carried", "out", "both", "through", "the", "LREC", "conference", "and", "the", "Language", "Resources", "and", "Evaluation", "Journal", "published", "by", "Springer", "."], "sentence-detokenized": "Dissemination of information is also part of ELRA's mission, which is carried out both through the LREC conference and the Language Resources and Evaluation Journal published by Springer.", "token2charspan": [[0, 13], [14, 16], [17, 28], [29, 31], [32, 36], [37, 41], [42, 44], [45, 49], [49, 51], [52, 59], [59, 60], [61, 66], [67, 69], [70, 77], [78, 81], [82, 86], [87, 94], [95, 98], [99, 103], [104, 114], [115, 118], [119, 122], [123, 131], [132, 141], [142, 145], [146, 156], [157, 164], [165, 174], [175, 177], [178, 186], [186, 187]]}
{"doc_key": "ai-dev-72", "ner": [[1, 8, "field"], [10, 11, "field"], [17, 19, "field"], [21, 22, "field"], [54, 55, "field"], [60, 61, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 8, 54, 55, "named", "", false, false], [17, 19, 1, 8, "named", "", false, false], [60, 61, 10, 11, "part-of", "", true, false], [60, 61, 17, 19, "part-of", "", true, false], [60, 61, 54, 55, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "linear", "time", "-", "invariant", "(", "LTI", ")", "theory", ",", "control", "theory", ",", "as", "well", "as", "in", "digital", "signal", "processing", "or", "signal", "processing", ",", "the", "relationship", "between", "the", "input", "signal", ",", "mathematical", "x", "(", "t", ")", "/", "mathematical", ",", "and", "the", "output", "signal", ",", "mathematical", "y", "(", "t", ")", "/", "mathematical", ",", "of", "an", "LTI", "system", "is", "governed", "by", "a", "convolution", "operation", ":"], "sentence-detokenized": "In linear time-invariant (LTI) theory, control theory, as well as in digital signal processing or signal processing, the relationship between the input signal, mathematical x (t) / mathematical, and the output signal, mathematical y (t) / mathematical, of an LTI system is governed by a convolution operation:", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [15, 24], [25, 26], [26, 29], [29, 30], [31, 37], [37, 38], [39, 46], [47, 53], [53, 54], [55, 57], [58, 62], [63, 65], [66, 68], [69, 76], [77, 83], [84, 94], [95, 97], [98, 104], [105, 115], [115, 116], [117, 120], [121, 133], [134, 141], [142, 145], [146, 151], [152, 158], [158, 159], [160, 172], [173, 174], [175, 176], [176, 177], [177, 178], [179, 180], [181, 193], [193, 194], [195, 198], [199, 202], [203, 209], [210, 216], [216, 217], [218, 230], [231, 232], [233, 234], [234, 235], [235, 236], [237, 238], [239, 251], [251, 252], [253, 255], [256, 258], [259, 262], [263, 269], [270, 272], [273, 281], [282, 284], [285, 286], [287, 298], [299, 308], [308, 309]]}
{"doc_key": "ai-dev-73", "ner": [[16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [24, 26, "field"], [28, 31, "field"], [33, 34, "product"], [36, 37, "field"], [39, 39, "field"], [42, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Due", "to", "its", "generality", ",", "the", "field", "is", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "game", "theory", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimisation", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Due to its generality, the field is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimisation, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 21], [21, 22], [23, 26], [27, 32], [33, 35], [36, 43], [44, 46], [47, 51], [52, 57], [58, 69], [69, 70], [71, 75], [76, 78], [79, 83], [84, 90], [90, 91], [92, 99], [100, 106], [106, 107], [108, 118], [119, 127], [127, 128], [129, 140], [141, 147], [147, 148], [149, 159], [159, 160], [160, 165], [166, 178], [178, 179], [180, 191], [192, 199], [199, 200], [201, 206], [207, 219], [219, 220], [221, 231], [232, 235], [236, 243], [244, 254], [254, 255]]}
{"doc_key": "ai-dev-74", "ner": [[0, 2, "algorithm"], [15, 16, "field"], [22, 23, "algorithm"], [26, 27, "algorithm"], [34, 35, "algorithm"], [38, 38, "algorithm"], [39, 41, "researcher"], [43, 44, "researcher"], [46, 48, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[15, 16, 0, 2, "usage", "", true, false], [22, 23, 15, 16, "part-of", "", true, false], [26, 27, 15, 16, "part-of", "", true, false], [34, 35, 15, 16, "part-of", "", true, false], [38, 38, 15, 16, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Stochastic", "gradient", "descent", "is", "a", "popular", "algorithm", "for", "training", "a", "wide", "range", "of", "models", "in", "machine", "learning", ",", "including", "(", "linear", ")", "support", "vector", "machines", ",", "logistic", "regression", "(", "see", ",", "for", "example", ",", "Vowpal", "Wabbit", ")", "and", "graphical", "models.Jenny", "Rose", "Finkel", ",", "Alex", "Kleeman", ",", "Christopher", "D.", "Manning", "(", "2008", ")", "."], "sentence-detokenized": "Stochastic gradient descent is a popular algorithm for training a wide range of models in machine learning, including (linear) support vector machines, logistic regression (see, for example, Vowpal Wabbit) and graphical models.Jenny Rose Finkel, Alex Kleeman, Christopher D. Manning (2008).", "token2charspan": [[0, 10], [11, 19], [20, 27], [28, 30], [31, 32], [33, 40], [41, 50], [51, 54], [55, 63], [64, 65], [66, 70], [71, 76], [77, 79], [80, 86], [87, 89], [90, 97], [98, 106], [106, 107], [108, 117], [118, 119], [119, 125], [125, 126], [127, 134], [135, 141], [142, 150], [150, 151], [152, 160], [161, 171], [172, 173], [173, 176], [176, 177], [178, 181], [182, 189], [189, 190], [191, 197], [198, 204], [204, 205], [206, 209], [210, 219], [220, 232], [233, 237], [238, 244], [244, 245], [246, 250], [251, 258], [258, 259], [260, 271], [272, 274], [275, 282], [283, 284], [284, 288], [288, 289], [289, 290]]}
{"doc_key": "ai-dev-75", "ner": [[8, 8, "organisation"], [11, 14, "product"], [20, 20, "country"], [22, 25, "university"], [27, 27, "location"], [29, 31, "university"], [33, 33, "location"], [35, 35, "university"], [38, 38, "location"], [40, 43, "university"], [44, 44, "location"], [46, 47, "university"], [49, 49, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 22, 25, "role", "donates_to", false, false], [8, 8, 29, 31, "role", "donates_to", false, false], [8, 8, 35, 35, "role", "donates_to", false, false], [8, 8, 40, 43, "role", "donates_to", false, false], [8, 8, 46, 47, "role", "donates_to", false, false], [11, 14, 8, 8, "origin", "donates", true, false], [22, 25, 27, 27, "physical", "", false, false], [27, 27, 20, 20, "physical", "", false, false], [29, 31, 33, 33, "physical", "", false, false], [33, 33, 20, 20, "physical", "", false, false], [35, 35, 38, 38, "physical", "", false, false], [38, 38, 20, 20, "physical", "", false, false], [40, 43, 44, 44, "physical", "", false, false], [44, 44, 20, 20, "physical", "", false, false], [46, 47, 49, 49, "physical", "", false, false], [49, 49, 20, 20, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "sentence": ["In", "August", "2011", ",", "it", "was", "announced", "that", "Hitachi", "would", "donate", "an", "electron", "microscope", "to", "each", "of", "five", "universities", "in", "Indonesia", "(", "University", "of", "North", "Sumatra", "in", "Medan", ",", "Indonesian", "Christian", "University", "in", "Jakarta", ",", "Padjadjaran", "University", "in", "Bandung", ",", "Jenderal", "Soedirman", "University", "in", "Purwokerto", "and", "Muhammadiyah", "University", "in", "Malang", ")", "."], "sentence-detokenized": "In August 2011, it was announced that Hitachi would donate an electron microscope to each of five universities in Indonesia (University of North Sumatra in Medan, Indonesian Christian University in Jakarta, Padjadjaran University in Bandung, Jenderal Soedirman University in Purwokerto and Muhammadiyah University in Malang).", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 18], [19, 22], [23, 32], [33, 37], [38, 45], [46, 51], [52, 58], [59, 61], [62, 70], [71, 81], [82, 84], [85, 89], [90, 92], [93, 97], [98, 110], [111, 113], [114, 123], [124, 125], [125, 135], [136, 138], [139, 144], [145, 152], [153, 155], [156, 161], [161, 162], [163, 173], [174, 183], [184, 194], [195, 197], [198, 205], [205, 206], [207, 218], [219, 229], [230, 232], [233, 240], [240, 241], [242, 250], [251, 260], [261, 271], [272, 274], [275, 285], [286, 289], [290, 302], [303, 313], [314, 316], [317, 323], [323, 324], [324, 325]]}
{"doc_key": "ai-dev-76", "ner": [[2, 2, "field"], [0, 3, "field"], [7, 8, "algorithm"], [10, 11, "algorithm"], [20, 21, "field"], [26, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 0, 3, "part-of", "", false, false], [2, 2, 20, 21, "related-to", "", true, false], [2, 2, 26, 27, "related-to", "", true, false], [7, 8, 2, 2, "type-of", "", false, false], [10, 11, 2, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Operational", "research", "optimisation", "techniques", ",", "such", "as", "linear", "programming", "or", "dynamic", "programming", ",", "are", "often", "impractical", "for", "large", "-", "scale", "software", "engineering", "problems", "due", "to", "their", "computational", "complexity", "."], "sentence-detokenized": "Operational research optimisation techniques, such as linear programming or dynamic programming, are often impractical for large-scale software engineering problems due to their computational complexity.", "token2charspan": [[0, 11], [12, 20], [21, 33], [34, 44], [44, 45], [46, 50], [51, 53], [54, 60], [61, 72], [73, 75], [76, 83], [84, 95], [95, 96], [97, 100], [101, 106], [107, 118], [119, 122], [123, 128], [128, 129], [129, 134], [135, 143], [144, 155], [156, 164], [165, 168], [169, 171], [172, 177], [178, 191], [192, 202], [202, 203]]}
{"doc_key": "ai-dev-77", "ner": [[0, 0, "metrics"], [6, 6, "metrics"], [8, 23, "metrics"], [15, 15, "metrics"], [20, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 6, "compare", "", false, false], [0, 0, 8, 23, "compare", "", false, false], [15, 15, 8, 23, "part-of", "", false, false], [20, 22, 8, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sensitivity", "is", "not", "the", "same", "as", "precision", "or", "positive", "predictive", "value", "(", "the", "ratio", "of", "TRUE", "positives", "to", "the", "combined", "TRUE", "and", "FALSE", "positives", ")", ",", "which", "is", "as", "much", "a", "statement", "about", "the", "proportion", "of", "true", "positives", "in", "the", "study", "population", "as", "it", "is", "about", "the", "test", "."], "sentence-detokenized": "Sensitivity is not the same as precision or positive predictive value (the ratio of TRUE positives to the combined TRUE and FALSE positives), which is as much a statement about the proportion of true positives in the study population as it is about the test.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 22], [23, 27], [28, 30], [31, 40], [41, 43], [44, 52], [53, 63], [64, 69], [70, 71], [71, 74], [75, 80], [81, 83], [84, 88], [89, 98], [99, 101], [102, 105], [106, 114], [115, 119], [120, 123], [124, 129], [130, 139], [139, 140], [140, 141], [142, 147], [148, 150], [151, 153], [154, 158], [159, 160], [161, 170], [171, 176], [177, 180], [181, 191], [192, 194], [195, 199], [200, 209], [210, 212], [213, 216], [217, 222], [223, 233], [234, 236], [237, 239], [240, 242], [243, 248], [249, 252], [253, 257], [257, 258]]}
{"doc_key": "ai-dev-78", "ner": [[2, 3, "person"], [8, 8, "product"], [11, 11, "person"], [25, 25, "person"], [32, 35, "person"], [44, 45, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6], "relations": [[8, 8, 2, 3, "artifact", "", false, false], [32, 35, 44, 45, "role", "convinces", false, false], [44, 45, 8, 8, "role", "producer", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Script", "by", "Hampton", "Fancher", "!", "--", "originally", "untitled", "Android", "-", "see", "Sammon", ",", "pp.", "32", "and", "38", "for", "clarification", "-", "was", "optioned", "in", "1977", ".", "Sammon", ",", "pp.", "23", "-", "30", "Producer", "Michael", "Deeley", "took", "an", "interest", "in", "Fancher", "'s", "sketch", "and", "convinced", "director", "Ridley", "Scott", "to", "film", "it", "."], "sentence-detokenized": "Script by Hampton Fancher! -- originally untitled Android - see Sammon, pp. 32 and 38 for clarification - was optioned in 1977. Sammon, pp. 23-30 Producer Michael Deeley took an interest in Fancher's sketch and convinced director Ridley Scott to film it.", "token2charspan": [[0, 6], [7, 9], [10, 17], [18, 25], [25, 26], [27, 29], [30, 40], [41, 49], [50, 57], [58, 59], [60, 63], [64, 70], [70, 71], [72, 75], [76, 78], [79, 82], [83, 85], [86, 89], [90, 103], [104, 105], [106, 109], [110, 118], [119, 121], [122, 126], [126, 127], [128, 134], [134, 135], [136, 139], [140, 142], [142, 143], [143, 145], [146, 154], [155, 162], [163, 169], [170, 174], [175, 177], [178, 186], [187, 189], [190, 197], [197, 199], [200, 206], [207, 210], [211, 220], [221, 229], [230, 236], [237, 242], [243, 245], [246, 250], [251, 253], [253, 254]]}
{"doc_key": "ai-dev-79", "ner": [[0, 1, "field"], [3, 4, "task"], [6, 7, "task"], [10, 12, "misc"], [14, 15, "field"], [17, 19, "task"], [21, 22, "task"], [24, 24, "field"], [28, 31, "task"], [33, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 4, 0, 1, "part-of", "", false, false], [6, 7, 0, 1, "part-of", "", false, false], [10, 12, 0, 1, "part-of", "", false, false], [14, 15, 0, 1, "part-of", "", false, false], [17, 19, 0, 1, "part-of", "", false, false], [21, 22, 0, 1, "part-of", "", false, false], [24, 24, 0, 1, "part-of", "", false, false], [28, 31, 0, 1, "part-of", "", false, false], [33, 33, 0, 1, "part-of", "", false, false], [35, 36, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Text", "analysis", "includes", "information", "retrieval", ",", "lexical", "analysis", "to", "examine", "word", "frequency", "distributions", ",", "pattern", "recognition", ",", "tagging", "/", "annotation", ",", "information", "extraction", ",", "data", "mining", "techniques", "including", "linkage", "and", "association", "analysis", ",", "visualisation", "and", "predictive", "analytics", "."], "sentence-detokenized": "Text analysis includes information retrieval, lexical analysis to examine word frequency distributions, pattern recognition, tagging/annotation, information extraction, data mining techniques including linkage and association analysis, visualisation and predictive analytics.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 34], [35, 44], [44, 45], [46, 53], [54, 62], [63, 65], [66, 73], [74, 78], [79, 88], [89, 102], [102, 103], [104, 111], [112, 123], [123, 124], [125, 132], [132, 133], [133, 143], [143, 144], [145, 156], [157, 167], [167, 168], [169, 173], [174, 180], [181, 191], [192, 201], [202, 209], [210, 213], [214, 225], [226, 234], [234, 235], [236, 249], [250, 253], [254, 264], [265, 274], [274, 275]]}
{"doc_key": "ai-dev-80", "ner": [[3, 3, "product"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Several", "metrics", "use", "WordNet", ",", "a", "manually", "constructed", "lexical", "database", "of", "English", "words", "."], "sentence-detokenized": "Several metrics use WordNet, a manually constructed lexical database of English words.", "token2charspan": [[0, 7], [8, 15], [16, 19], [20, 27], [27, 28], [29, 30], [31, 39], [40, 51], [52, 59], [60, 68], [69, 71], [72, 79], [80, 85], [85, 86]]}
{"doc_key": "ai-dev-81", "ner": [[8, 9, "field"], [11, 12, "task"], [14, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "system", "uses", "a", "combination", "of", "techniques", "from", "computational", "linguistics", ",", "information", "retrieval", "and", "knowledge", "representation", "to", "find", "answers", "."], "sentence-detokenized": "The system uses a combination of techniques from computational linguistics, information retrieval and knowledge representation to find answers.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 17], [18, 29], [30, 32], [33, 43], [44, 48], [49, 62], [63, 74], [74, 75], [76, 87], [88, 97], [98, 101], [102, 111], [112, 126], [127, 129], [130, 134], [135, 142], [142, 143]]}
{"doc_key": "ai-dev-82", "ner": [[5, 7, "metrics"], [13, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 13, 13, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "performance", "metric", ",", "the", "uncertainty", "factor", "has", "the", "advantage", "over", "simple", "accuracy", "that", "it", "is", "not", "affected", "by", "the", "relative", "size", "of", "the", "different", "classes", "."], "sentence-detokenized": "As a performance metric, the uncertainty factor has the advantage over simple accuracy that it is not affected by the relative size of the different classes.", "token2charspan": [[0, 2], [3, 4], [5, 16], [17, 23], [23, 24], [25, 28], [29, 40], [41, 47], [48, 51], [52, 55], [56, 65], [66, 70], [71, 77], [78, 86], [87, 91], [92, 94], [95, 97], [98, 101], [102, 110], [111, 113], [114, 117], [118, 126], [127, 131], [132, 134], [135, 138], [139, 148], [149, 156], [156, 157]]}
{"doc_key": "ai-dev-83", "ner": [[8, 9, "algorithm"], [11, 12, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Researchers", "have", "tried", "many", "methods", ",", "such", "as", "optical", "flow", ",", "Kalman", "filtering", ",", "hidden", "Markov", "models", ",", "etc", "."], "sentence-detokenized": "Researchers have tried many methods, such as optical flow, Kalman filtering, hidden Markov models, etc.", "token2charspan": [[0, 11], [12, 16], [17, 22], [23, 27], [28, 35], [35, 36], [37, 41], [42, 44], [45, 52], [53, 57], [57, 58], [59, 65], [66, 75], [75, 76], [77, 83], [84, 90], [91, 97], [97, 98], [99, 102], [102, 103]]}
{"doc_key": "ai-dev-84", "ner": [[13, 16, "conference"], [29, 31, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "has", "served", "as", "president", ",", "vice-president", "and", "secretary", "-", "treasurer", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "was", "a", "board", "member", "and", "secretary", "of", "the", "board", "of", "the", "Computing", "Research", "Association", "."], "sentence-detokenized": "She has served as president, vice-president and secretary-treasurer of the Association for Computational Linguistics and was a board member and secretary of the board of the Computing Research Association.", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 17], [18, 27], [27, 28], [29, 43], [44, 47], [48, 57], [57, 58], [58, 67], [68, 70], [71, 74], [75, 86], [87, 90], [91, 104], [105, 116], [117, 120], [121, 124], [125, 126], [127, 132], [133, 139], [140, 143], [144, 153], [154, 156], [157, 160], [161, 166], [167, 169], [170, 173], [174, 183], [184, 192], [193, 204], [204, 205]]}
{"doc_key": "ai-dev-85", "ner": [[6, 6, "programlang"], [8, 8, "product"], [10, 10, "programlang"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 10, 10, "compare", "", false, false], [6, 6, 12, 13, "related-to", "supports", false, false], [8, 8, 10, 10, "compare", "", false, false], [8, 8, 12, 13, "related-to", "supports", false, false], [10, 10, 12, 13, "related-to", "supports", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Like", "other", "similar", "languages", "such", "as", "APL", "and", "MATLAB", ",", "R", "supports", "matrix", "arithmetic", "."], "sentence-detokenized": "Like other similar languages such as APL and MATLAB, R supports matrix arithmetic.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 28], [29, 33], [34, 36], [37, 40], [41, 44], [45, 51], [51, 52], [53, 54], [55, 63], [64, 70], [71, 81], [81, 82]]}
{"doc_key": "ai-dev-86", "ner": [[10, 11, "misc"], [7, 9, "organisation"], [16, 17, "researcher"], [20, 23, "university"], [26, 31, "misc"], [33, 33, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 11, 7, 9, "physical", "", false, false], [10, 11, 26, 31, "temporal", "", false, false], [16, 17, 10, 11, "role", "arranges", false, false], [16, 17, 20, 23, "role", "works_for", false, false], [33, 33, 10, 11, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["On", "7", "June", "2014", ",", "in", "the", "Royal", "Society", "'s", "Turing", "test", "competition", ",", "organised", "by", "Kevin", "Warwick", "of", "the", "University", "of", "Reading", "to", "mark", "the", "60th", "anniversary", "of", "Turing", "'s", "death", ",", "Goostman", "won", "after", "33", "%", "of", "the", "judges", "were", "convinced", "that", "the", "bot", "was", "human", "."], "sentence-detokenized": "On 7 June 2014, in the Royal Society's Turing test competition, organised by Kevin Warwick of the University of Reading to mark the 60th anniversary of Turing's death, Goostman won after 33% of the judges were convinced that the bot was human.", "token2charspan": [[0, 2], [3, 4], [5, 9], [10, 14], [14, 15], [16, 18], [19, 22], [23, 28], [29, 36], [36, 38], [39, 45], [46, 50], [51, 62], [62, 63], [64, 73], [74, 76], [77, 82], [83, 90], [91, 93], [94, 97], [98, 108], [109, 111], [112, 119], [120, 122], [123, 127], [128, 131], [132, 136], [137, 148], [149, 151], [152, 158], [158, 160], [161, 166], [166, 167], [168, 176], [177, 180], [181, 186], [187, 189], [189, 190], [191, 193], [194, 197], [198, 204], [205, 209], [210, 219], [220, 224], [225, 228], [229, 232], [233, 236], [237, 242], [242, 243]]}
{"doc_key": "ai-dev-87", "ner": [[0, 2, "product"], [4, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "collaborative", "robot", "or", "cobot", "is", "a", "robot", "that", "can", "safely", "and", "effectively", "interact", "with", "human", "workers", "while", "performing", "simple", "industrial", "tasks", "."], "sentence-detokenized": "A collaborative robot or cobot is a robot that can safely and effectively interact with human workers while performing simple industrial tasks.", "token2charspan": [[0, 1], [2, 15], [16, 21], [22, 24], [25, 30], [31, 33], [34, 35], [36, 41], [42, 46], [47, 50], [51, 57], [58, 61], [62, 73], [74, 82], [83, 87], [88, 93], [94, 101], [102, 107], [108, 118], [119, 125], [126, 136], [137, 142], [142, 143]]}
{"doc_key": "ai-dev-88", "ner": [[13, 14, "field"], [18, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "task"], [29, 30, "task"], [32, 35, "task"], [37, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[18, 18, 13, 14, "part-of", "task_part_of_field", false, false], [20, 21, 13, 14, "part-of", "task_part_of_field", false, false], [23, 24, 13, 14, "part-of", "task_part_of_field", false, false], [26, 27, 13, 14, "part-of", "task_part_of_field", false, false], [29, 30, 13, 14, "part-of", "task_part_of_field", false, false], [32, 35, 13, 14, "part-of", "task_part_of_field", false, false], [37, 38, 13, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["This", "general", "framework", "has", "been", "applied", "to", "a", "wide", "variety", "of", "problems", "in", "computer", "vision", ",", "including", "feature", "detection", ",", "feature", "classification", ",", "image", "segmentation", ",", "image", "matching", ",", "motion", "estimation", ",", "computation", "of", "shape", "cues", "and", "object", "recognition", "."], "sentence-detokenized": "This general framework has been applied to a wide variety of problems in computer vision, including feature detection, feature classification, image segmentation, image matching, motion estimation, computation of shape cues and object recognition.", "token2charspan": [[0, 4], [5, 12], [13, 22], [23, 26], [27, 31], [32, 39], [40, 42], [43, 44], [45, 49], [50, 57], [58, 60], [61, 69], [70, 72], [73, 81], [82, 88], [88, 89], [90, 99], [100, 107], [108, 117], [117, 118], [119, 126], [127, 141], [141, 142], [143, 148], [149, 161], [161, 162], [163, 168], [169, 177], [177, 178], [179, 185], [186, 196], [196, 197], [198, 209], [210, 212], [213, 218], [219, 223], [224, 227], [228, 234], [235, 246], [246, 247]]}
{"doc_key": "ai-dev-89", "ner": [[5, 6, "task"], [8, 10, "algorithm"], [13, 14, "algorithm"], [27, 30, "algorithm"], [34, 34, "algorithm"], [39, 39, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 6, 8, 10, "part-of", "", false, false], [5, 6, 13, 14, "usage", "", false, false], [8, 10, 27, 30, "named", "same", false, false], [27, 30, 34, 34, "related-to", "", false, false], [27, 30, 39, 39, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "many", "practical", "applications", ",", "parameter", "estimation", "for", "na\u00efve", "Bayes", "models", "uses", "the", "maximum", "likelihood", "method", ";", "in", "other", "words", ",", "it", "is", "possible", "to", "work", "with", "a", "na\u00efve", "Bayes", "model", "without", "assuming", "Bayes", "probability", "or", "using", "any", "Bayes", "methods", "."], "sentence-detokenized": "In many practical applications, parameter estimation for na\u00efve Bayes models uses the maximum likelihood method; in other words, it is possible to work with a na\u00efve Bayes model without assuming Bayes probability or using any Bayes methods.", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 30], [30, 31], [32, 41], [42, 52], [53, 56], [57, 62], [63, 68], [69, 75], [76, 80], [81, 84], [85, 92], [93, 103], [104, 110], [110, 111], [112, 114], [115, 120], [121, 126], [126, 127], [128, 130], [131, 133], [134, 142], [143, 145], [146, 150], [151, 155], [156, 157], [158, 163], [164, 169], [170, 175], [176, 183], [184, 192], [193, 198], [199, 210], [211, 213], [214, 219], [220, 223], [224, 229], [230, 237], [237, 238]]}
{"doc_key": "ai-dev-90", "ner": [[2, 4, "researcher"], [6, 7, "misc"], [11, 14, "university"], [16, 18, "researcher"], [20, 21, "misc"], [25, 25, "university"], [27, 27, "university"], [30, 30, "misc"], [37, 39, "university"], [45, 48, "misc"], [50, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[2, 4, 11, 14, "physical", "", false, false], [2, 4, 11, 14, "role", "", false, false], [2, 4, 16, 18, "social", "brothers", false, false], [6, 7, 2, 4, "named", "", false, false], [16, 18, 25, 25, "physical", "", false, false], [16, 18, 25, 25, "role", "", false, false], [16, 18, 27, 27, "physical", "", false, false], [16, 18, 27, 27, "role", "", false, false], [16, 18, 37, 39, "physical", "", false, false], [16, 18, 37, 39, "role", "", false, false], [20, 21, 16, 18, "named", "", false, false], [30, 30, 16, 18, "origin", "", false, false], [45, 48, 16, 18, "artifact", "", false, false], [45, 48, 50, 53, "part-of", "part", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Brothers", "-", "Victor", "Gershevich", "Katz", ",", "American", "mathematician", ",", "professor", "at", "Massachusetts", "Institute", "of", "Technology", ";", "Mikhail", "Gershevich", "Katz", ",", "Israeli", "mathematician", ",", "graduate", "of", "Harvard", "and", "Columbia", "Universities", "(", "Ph.D.", ",", "1984", ")", ",", "professor", "at", "Bar-", "Ilan", "University", ",", "author", "of", "the", "monograph", "Systolic", "Geometry", "and", "Topology", "(", "Mathematical", "Surveys", "and", "Monographs", ",", "vol", "."], "sentence-detokenized": "Brothers - Victor Gershevich Katz, American mathematician, professor at Massachusetts Institute of Technology; Mikhail Gershevich Katz, Israeli mathematician, graduate of Harvard and Columbia Universities (Ph.D. , 1984), professor at Bar-Ilan University, author of the monograph Systolic Geometry and Topology (Mathematical Surveys and Monographs, vol.", "token2charspan": [[0, 8], [9, 10], [11, 17], [18, 28], [29, 33], [33, 34], [35, 43], [44, 57], [57, 58], [59, 68], [69, 71], [72, 85], [86, 95], [96, 98], [99, 109], [109, 110], [111, 118], [119, 129], [130, 134], [134, 135], [136, 143], [144, 157], [157, 158], [159, 167], [168, 170], [171, 178], [179, 182], [183, 191], [192, 204], [205, 206], [206, 211], [212, 213], [214, 218], [218, 219], [219, 220], [221, 230], [231, 233], [234, 238], [238, 242], [243, 253], [253, 254], [255, 261], [262, 264], [265, 268], [269, 278], [279, 287], [288, 296], [297, 300], [301, 309], [310, 311], [311, 323], [324, 331], [332, 335], [336, 346], [346, 347], [348, 351], [351, 352]]}
{"doc_key": "ai-dev-91", "ner": [[3, 4, "person"], [9, 10, "conference"], [15, 18, "organisation"], [20, 20, "location"], [24, 25, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 9, 10, "physical", "", false, false], [3, 4, 9, 10, "role", "", false, false], [3, 4, 15, 18, "role", "", false, false], [15, 18, 20, 20, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2000", ",", "Manuel", "Toharia", ",", "speaker", "of", "previous", "Campus", "Parties", "and", "director", "of", "the", "Pr\u00edncipe", "Felipe", "Science", "Museum", "in", "Valencia", ",", "suggested", "that", "Ragageles", "should", "expand", "and", "make", "the", "event", "more", "international", "by", "moving", "it", "to", "the", "famous", "museum", "."], "sentence-detokenized": "In 2000, Manuel Toharia, speaker of previous Campus Parties and director of the Pr\u00edncipe Felipe Science Museum in Valencia, suggested that Ragageles should expand and make the event more international by moving it to the famous museum.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 23], [23, 24], [25, 32], [33, 35], [36, 44], [45, 51], [52, 59], [60, 63], [64, 72], [73, 75], [76, 79], [80, 88], [89, 95], [96, 103], [104, 110], [111, 113], [114, 122], [122, 123], [124, 133], [134, 138], [139, 148], [149, 155], [156, 162], [163, 166], [167, 171], [172, 175], [176, 181], [182, 186], [187, 200], [201, 203], [204, 210], [211, 213], [214, 216], [217, 220], [221, 227], [228, 234], [234, 235]]}
{"doc_key": "ai-dev-92", "ner": [[4, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Within", "20", "minutes", ",", "the", "facial", "recognition", "system", "identifies", "personal", "information", ",", "including", "name", ",", "ID", "number", "and", "address", ",", "which", "is", "displayed", "on", "the", "street", "on", "an", "advertising", "screen", "."], "sentence-detokenized": "Within 20 minutes, the facial recognition system identifies personal information, including name, ID number and address, which is displayed on the street on an advertising screen.", "token2charspan": [[0, 6], [7, 9], [10, 17], [17, 18], [19, 22], [23, 29], [30, 41], [42, 48], [49, 59], [60, 68], [69, 80], [80, 81], [82, 91], [92, 96], [96, 97], [98, 100], [101, 107], [108, 111], [112, 119], [119, 120], [121, 126], [127, 129], [130, 139], [140, 142], [143, 146], [147, 153], [154, 156], [157, 159], [160, 171], [172, 178], [178, 179]]}
{"doc_key": "ai-dev-93", "ner": [[6, 7, "field"], [8, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Recent", "research", "has", "increasingly", "focused", "on", "unsupervised", "and", "semi-supervised", "learning", "algorithms", "."], "sentence-detokenized": "Recent research has increasingly focused on unsupervised and semi-supervised learning algorithms.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 32], [33, 40], [41, 43], [44, 56], [57, 60], [61, 76], [77, 85], [86, 96], [96, 97]]}
{"doc_key": "ai-dev-94", "ner": [[4, 5, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Calculating", "this", "example", "using", "Python", "code", ":"], "sentence-detokenized": "Calculating this example using Python code:", "token2charspan": [[0, 11], [12, 16], [17, 24], [25, 30], [31, 37], [38, 42], [42, 43]]}
{"doc_key": "ai-dev-95", "ner": [[7, 10, "task"], [15, 16, "field"], [19, 23, "algorithm"], [25, 25, "algorithm"], [28, 31, "algorithm"], [34, 35, "researcher"], [37, 38, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[19, 23, 15, 16, "part-of", "", false, false], [19, 23, 28, 31, "type-of", "", false, false], [19, 23, 34, 35, "origin", "", false, false], [19, 23, 37, 38, "origin", "", false, false], [25, 25, 19, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Today", ",", "however", ",", "many", "aspects", "of", "speech", "recognition", "have", "been", "taken", "over", "by", "a", "deep", "learning", "method", "called", "Long", "short", "-", "term", "memory", "(", "LSTM", ")", ",", "a", "recurrent", "neural", "network", "published", "by", "Sepp", "Hochreiter", "&", "J\u00fcrgen", "Schmidhuber", "in", "1997", "."], "sentence-detokenized": "Today, however, many aspects of speech recognition have been taken over by a deep learning method called Long short-term memory (LSTM), a recurrent neural network published by Sepp Hochreiter & J\u00fcrgen Schmidhuber in 1997.", "token2charspan": [[0, 5], [5, 6], [7, 14], [14, 15], [16, 20], [21, 28], [29, 31], [32, 38], [39, 50], [51, 55], [56, 60], [61, 66], [67, 71], [72, 74], [75, 76], [77, 81], [82, 90], [91, 97], [98, 104], [105, 109], [110, 115], [115, 116], [116, 120], [121, 127], [128, 129], [129, 133], [133, 134], [134, 135], [136, 137], [138, 147], [148, 154], [155, 162], [163, 172], [173, 175], [176, 180], [181, 191], [192, 193], [194, 200], [201, 212], [213, 215], [216, 220], [220, 221]]}
{"doc_key": "ai-dev-96", "ner": [[9, 9, "algorithm"], [11, 12, "algorithm"], [18, 19, "algorithm"], [24, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 11, 12, "compare", "", false, false], [9, 9, 24, 24, "named", "same", false, false], [18, 19, 24, 24, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "preliminary", "experimental", "results", "with", "noisy", "data", "sets", ",", "BrownBoost", "outperformed", "AdaBoost", "in", "generalisation", "error", ";", "however", ",", "LogitBoost", "performed", "just", "as", "well", "as", "BrownBoost", "."], "sentence-detokenized": "In preliminary experimental results with noisy data sets, BrownBoost outperformed AdaBoost in generalisation error; however, LogitBoost performed just as well as BrownBoost.", "token2charspan": [[0, 2], [3, 14], [15, 27], [28, 35], [36, 40], [41, 46], [47, 51], [52, 56], [56, 57], [58, 68], [69, 81], [82, 90], [91, 93], [94, 108], [109, 114], [114, 115], [116, 123], [123, 124], [125, 135], [136, 145], [146, 150], [151, 153], [154, 158], [159, 161], [162, 172], [172, 173]]}
{"doc_key": "ai-dev-97", "ner": [[0, 1, "algorithm"], [8, 10, "researcher"], [5, 7, "country"], [13, 15, "researcher"], [21, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 8, 10, "part-of", "", false, false], [8, 10, 5, 7, "physical", "", false, false], [21, 21, 13, 15, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Evolutionary", "programming", "was", "introduced", "in", "the", "USA", "by", "Lawrence", "J.", "Fogel", ",", "while", "John", "Henry", "Holland", "called", "his", "method", "the", "genetic", "algorithm", "."], "sentence-detokenized": "Evolutionary programming was introduced in the USA by Lawrence J. Fogel, while John Henry Holland called his method the genetic algorithm.", "token2charspan": [[0, 12], [13, 24], [25, 28], [29, 39], [40, 42], [43, 46], [47, 50], [51, 53], [54, 62], [63, 65], [66, 71], [71, 72], [73, 78], [79, 83], [84, 89], [90, 97], [98, 104], [105, 108], [109, 115], [116, 119], [120, 127], [128, 137], [137, 138]]}
{"doc_key": "ai-dev-98", "ner": [[2, 2, "researcher"], [4, 4, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 10, 11, "role", "", false, false], [2, 2, 13, 14, "role", "", false, false], [2, 2, 16, 17, "role", "", false, false], [2, 2, 19, 20, "role", "", false, false], [4, 4, 10, 11, "role", "", false, false], [4, 4, 13, 14, "role", "", false, false], [4, 4, 16, 17, "role", "", false, false], [4, 4, 19, 20, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Calculations", "by", "Doug", ",", "Alan", "and", "their", "colleagues", "(", "including", "Marvin", "Minsky", ",", "Allen", "Newell", ",", "Edward", "Feigenbaum", "and", "John", "McCarthy", ")", "indicated", "that", "the", "effort", "would", "require", "between", "1,000", "and", "3,000", "person", "-", "years", "of", "work", ",", "well", "beyond", "the", "standard", "academic", "project", "model", "."], "sentence-detokenized": "Calculations by Doug, Alan and their colleagues (including Marvin Minsky, Allen Newell, Edward Feigenbaum and John McCarthy) indicated that the effort would require between 1,000 and 3,000 person-years of work, well beyond the standard academic project model.", "token2charspan": [[0, 12], [13, 15], [16, 20], [20, 21], [22, 26], [27, 30], [31, 36], [37, 47], [48, 49], [49, 58], [59, 65], [66, 72], [72, 73], [74, 79], [80, 86], [86, 87], [88, 94], [95, 105], [106, 109], [110, 114], [115, 123], [123, 124], [125, 134], [135, 139], [140, 143], [144, 150], [151, 156], [157, 164], [165, 172], [173, 178], [179, 182], [183, 188], [189, 195], [195, 196], [196, 201], [202, 204], [205, 209], [209, 210], [211, 215], [216, 222], [223, 226], [227, 235], [236, 244], [245, 252], [253, 258], [258, 259]]}
{"doc_key": "ai-dev-99", "ner": [[4, 6, "metrics"], [10, 10, "metrics"], [12, 15, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 10, 10, "part-of", "implemented_in", false, false], [12, 15, 18, 18, "part-of", "implemented_in", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Common", "criteria", "are", "the", "Mean", "Squared", "Error", "criterion", "implemented", "in", "MSECriterion", "and", "the", "cross", "entropy", "criterion", "implemented", "in", "NLLCriterion", "."], "sentence-detokenized": "Common criteria are the Mean Squared Error criterion implemented in MSECriterion and the cross entropy criterion implemented in NLLCriterion.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 23], [24, 28], [29, 36], [37, 42], [43, 52], [53, 64], [65, 67], [68, 80], [81, 84], [85, 88], [89, 94], [95, 102], [103, 112], [113, 124], [125, 127], [128, 140], [140, 141]]}
{"doc_key": "ai-dev-100", "ner": [[0, 0, "researcher"], [11, 11, "organisation"], [15, 22, "misc"], [32, 35, "conference"], [44, 46, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 11, 11, "role", "", false, false], [0, 0, 32, 35, "role", "", false, false], [0, 0, 44, 46, "role", "", false, false], [15, 22, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Zurada", "has", "served", "the", "engineering", "profession", "as", "a", "long", "-", "time", "IEEE", "volunteer", ":", "as", "2014", "IEEE", "Vice", "-", "President", "-", "Technical", "Activities", "(", "TAB", "Chair", ")", ",", "as", "president", "of", "the", "IEEE", "Computational", "Intelligence", "Society", "in", "2004", "-", "05", ",", "and", "as", "an", "ADCOM", "member", "in", "2009", "-", "14", ",", "2016", "-", "18", "and", "earlier", "."], "sentence-detokenized": "Zurada has served the engineering profession as a long-time IEEE volunteer: as 2014 IEEE Vice-President-Technical Activities (TAB Chair), as president of the IEEE Computational Intelligence Society in 2004-05, and as an ADCOM member in 2009-14, 2016-18 and earlier.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 21], [22, 33], [34, 44], [45, 47], [48, 49], [50, 54], [54, 55], [55, 59], [60, 64], [65, 74], [74, 75], [76, 78], [79, 83], [84, 88], [89, 93], [93, 94], [94, 103], [103, 104], [104, 113], [114, 124], [125, 126], [126, 129], [130, 135], [135, 136], [136, 137], [138, 140], [141, 150], [151, 153], [154, 157], [158, 162], [163, 176], [177, 189], [190, 197], [198, 200], [201, 205], [205, 206], [206, 208], [208, 209], [210, 213], [214, 216], [217, 219], [220, 225], [226, 232], [233, 235], [236, 240], [240, 241], [241, 243], [243, 244], [245, 249], [249, 250], [250, 252], [253, 256], [257, 264], [264, 265]]}
{"doc_key": "ai-dev-101", "ner": [[3, 3, "field"], [12, 13, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 13, 3, 3, "part-of", "", false, false], [15, 16, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "general", ",", "computational", "linguistics", "draws", "on", "the", "involvement", "of", "linguists", ",", "computer", "scientists", ",", "artificial", "intelligence", "specialists", ",", "mathematicians", ",", "logicians", ",", "philosophers", ",", "cognitive", "scientists", ",", "cognitive", "psychologists", ",", "psycholinguists", ",", "anthropologists", "and", "neuroscientists", ",", "among", "others", "."], "sentence-detokenized": "In general, computational linguistics draws on the involvement of linguists, computer scientists, artificial intelligence specialists, mathematicians, logicians, philosophers, cognitive scientists, cognitive psychologists, psycholinguists, anthropologists and neuroscientists, among others.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 25], [26, 37], [38, 43], [44, 46], [47, 50], [51, 62], [63, 65], [66, 75], [75, 76], [77, 85], [86, 96], [96, 97], [98, 108], [109, 121], [122, 133], [133, 134], [135, 149], [149, 150], [151, 160], [160, 161], [162, 174], [174, 175], [176, 185], [186, 196], [196, 197], [198, 207], [208, 221], [221, 222], [223, 238], [238, 239], [240, 255], [256, 259], [260, 275], [275, 276], [277, 282], [283, 289], [289, 290]]}
{"doc_key": "ai-dev-102", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "correlations", "between", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and long short-term memory are often used to exploit correlations between frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [83, 88], [88, 89], [89, 93], [94, 100], [101, 104], [105, 110], [111, 115], [116, 118], [119, 126], [127, 139], [140, 147], [148, 154], [154, 155]]}
{"doc_key": "ai-dev-103", "ner": [[0, 0, "product"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Unimate", "was", "the", "first", "industrial", "robot", ","], "sentence-detokenized": "Unimate was the first industrial robot,", "token2charspan": [[0, 7], [8, 11], [12, 15], [16, 21], [22, 32], [33, 38], [38, 39]]}
{"doc_key": "ai-dev-104", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [10, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 10, 13, "win-defeat", "", false, false], [5, 6, 10, 13, "win-defeat", "", false, false], [8, 8, 10, 13, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Together", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "won", "the", "2018", "Turing", "Award", "."], "sentence-detokenized": "Together with Geoffrey Hinton and Yann LeCun, Bengio won the 2018 Turing Award.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 29], [30, 33], [34, 38], [39, 44], [44, 45], [46, 52], [53, 56], [57, 60], [61, 65], [66, 72], [73, 78], [78, 79]]}
{"doc_key": "ai-dev-105", "ner": [[6, 6, "country"], [17, 20, "misc"], [26, 27, "country"], [30, 31, "organisation"], [35, 36, "person"], [39, 40, "person"], [48, 50, "misc"], [56, 56, "country"], [61, 61, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[17, 20, 6, 6, "physical", "filmed_in", false, false], [35, 36, 30, 31, "role", "host", false, false], [39, 40, 30, 31, "role", "reporter", false, false], [48, 50, 6, 6, "physical", "filmed_in", false, false], [48, 50, 56, 56, "physical", "distributed_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Additional", "series", "were", "filmed", "in", "the", "UK", "for", "specific", "sectors", "of", "the", "global", "market", ",", "including", "two", "Robot", "Wars", "Extreme", "Warriors", "series", "featuring", "contestants", "from", "the", "United", "States", "for", "the", "TNN", "network", "(", "hosted", "by", "Mick", "Foley", ",", "with", "Rebecca", "Grant", "acting", "as", "channel", "reporter", ")", ",", "two", "Dutch", "Robot", "Wars", "series", "for", "distribution", "in", "the", "Netherlands", "and", "one", "series", "for", "Germany", "."], "sentence-detokenized": "Additional series were filmed in the UK for specific sectors of the global market, including two Robot Wars Extreme Warriors series featuring contestants from the United States for the TNN network (hosted by Mick Foley, with Rebecca Grant acting as channel reporter), two Dutch Robot Wars series for distribution in the Netherlands and one series for Germany.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 29], [30, 32], [33, 36], [37, 39], [40, 43], [44, 52], [53, 60], [61, 63], [64, 67], [68, 74], [75, 81], [81, 82], [83, 92], [93, 96], [97, 102], [103, 107], [108, 115], [116, 124], [125, 131], [132, 141], [142, 153], [154, 158], [159, 162], [163, 169], [170, 176], [177, 180], [181, 184], [185, 188], [189, 196], [197, 198], [198, 204], [205, 207], [208, 212], [213, 218], [218, 219], [220, 224], [225, 232], [233, 238], [239, 245], [246, 248], [249, 256], [257, 265], [265, 266], [266, 267], [268, 271], [272, 277], [278, 283], [284, 288], [289, 295], [296, 299], [300, 312], [313, 315], [316, 319], [320, 331], [332, 335], [336, 339], [340, 346], [347, 350], [351, 358], [358, 359]]}
{"doc_key": "ai-dev-106", "ner": [[8, 8, "researcher"], [13, 15, "product"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 13, 15, "role", "", false, false], [28, 29, 13, 15, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "many", "years", ",", "starting", "in", "1986", ",", "Miller", "led", "the", "development", "of", "WordNet", ",", "a", "large", ",", "computer", "-", "readable", "electronic", "reference", "used", "in", "applications", "such", "as", "search", "engines", "."], "sentence-detokenized": "For many years, starting in 1986, Miller led the development of WordNet, a large, computer-readable electronic reference used in applications such as search engines.", "token2charspan": [[0, 3], [4, 8], [9, 14], [14, 15], [16, 24], [25, 27], [28, 32], [32, 33], [34, 40], [41, 44], [45, 48], [49, 60], [61, 63], [64, 71], [71, 72], [73, 74], [75, 80], [80, 81], [82, 90], [90, 91], [91, 99], [100, 110], [111, 120], [121, 125], [126, 128], [129, 141], [142, 146], [147, 149], [150, 156], [157, 164], [164, 165]]}
{"doc_key": "ai-dev-107", "ner": [[3, 5, "algorithm"], [7, 10, "algorithm"], [13, 15, "researcher"], [19, 24, "organisation"], [28, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 13, 15, "origin", "", false, false], [3, 5, 28, 30, "win-defeat", "", false, false], [7, 10, 13, 15, "origin", "", false, false], [7, 10, 28, 30, "win-defeat", "", false, false], [13, 15, 19, 24, "physical", "", false, false], [13, 15, 19, 24, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Since", "2009", ",", "recurrent", "neural", "networks", "and", "deep", "feedforward", "neural", "networks", "developed", "in", "J\u00fcrgen", "Schmidhuber", "'s", "research", "group", "at", "IDSIA", "'s", "AI", "Lab", "in", "Switzerland", "have", "won", "several", "international", "handwriting", "competitions", "...."], "sentence-detokenized": "Since 2009, recurrent neural networks and deep feedforward neural networks developed in J\u00fcrgen Schmidhuber's research group at IDSIA's AI Lab in Switzerland have won several international handwriting competitions....", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 21], [22, 28], [29, 37], [38, 41], [42, 46], [47, 58], [59, 65], [66, 74], [75, 84], [85, 87], [88, 94], [95, 106], [106, 108], [109, 117], [118, 123], [124, 126], [127, 132], [132, 134], [135, 137], [138, 141], [142, 144], [145, 156], [157, 161], [162, 165], [166, 173], [174, 187], [188, 199], [200, 212], [212, 216]]}
{"doc_key": "ai-dev-108", "ner": [[5, 6, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "software", "is", "implemented", "in", "C", "++", "and", "is", "packaged", "for", "Python", "."], "sentence-detokenized": "The software is implemented in C ++ and is packaged for Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 30], [31, 32], [33, 35], [36, 39], [40, 42], [43, 51], [52, 55], [56, 62], [62, 63]]}
{"doc_key": "ai-dev-109", "ner": [[7, 9, "country"], [14, 15, "misc"], [20, 23, "misc"], [34, 36, "misc"], [37, 37, "misc"], [40, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 23, 7, 9, "temporal", "", false, false], [20, 23, 14, 15, "artifact", "", false, false], [20, 23, 40, 40, "physical", "", false, false], [37, 37, 34, 36, "named", "", false, false], [37, 37, 40, 40, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1857", ",", "at", "the", "request", "of", "the", "Tokugawa", "Shogunate", ",", "a", "group", "of", "Dutch", "engineers", "began", "work", "on", "the", "Nagasaki", "Yotetsusho", ",", "a", "modern", ",", "Western", "-", "style", "foundry", "and", "shipyard", "near", "the", "Dutch", "settlement", "of", "Dejima", ",", "in", "Nagasaki", "."], "sentence-detokenized": "In 1857, at the request of the Tokugawa Shogunate, a group of Dutch engineers began work on the Nagasaki Yotetsusho, a modern, Western-style foundry and shipyard near the Dutch settlement of Dejima, in Nagasaki.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 39], [40, 49], [49, 50], [51, 52], [53, 58], [59, 61], [62, 67], [68, 77], [78, 83], [84, 88], [89, 91], [92, 95], [96, 104], [105, 115], [115, 116], [117, 118], [119, 125], [125, 126], [127, 134], [134, 135], [135, 140], [141, 148], [149, 152], [153, 161], [162, 166], [167, 170], [171, 176], [177, 187], [188, 190], [191, 197], [197, 198], [199, 201], [202, 210], [210, 211]]}
{"doc_key": "ai-dev-110", "ner": [[9, 12, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["We", "make", "it", "as", "precise", "as", "possible", "by", "measuring", "the", "mean", "square", "error", "between", "math", "/", "math", "and", "math", "{", "f", "}", "(", "x", ";", "D", ")", "/", "math", ":", "we", "want", "math", "(", "y", "-", "the", "hat", "{", "f", "}", "(", "x", ";", "D", ")", ")", "^", "2", "/", "math", "to", "be", "minimal", ",", "both", "for", "mathx", "_", "1", ",", "^", "dots", ",", "x", "_n", "/", "math", ",", "and", "for", "points", "outside", "our", "sample", "."], "sentence-detokenized": "We make it as precise as possible by measuring the mean square error between math / math and math {f} (x; D) / math: we want math (y -the hat {f} (x; D)) ^ 2 / math to be minimal, both for mathx _ 1, ^ dots, x _n / math, and for points outside our sample.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 13], [14, 21], [22, 24], [25, 33], [34, 36], [37, 46], [47, 50], [51, 55], [56, 62], [63, 68], [69, 76], [77, 81], [82, 83], [84, 88], [89, 92], [93, 97], [98, 99], [99, 100], [100, 101], [102, 103], [103, 104], [104, 105], [106, 107], [107, 108], [109, 110], [111, 115], [115, 116], [117, 119], [120, 124], [125, 129], [130, 131], [131, 132], [133, 134], [134, 137], [138, 141], [142, 143], [143, 144], [144, 145], [146, 147], [147, 148], [148, 149], [150, 151], [151, 152], [152, 153], [154, 155], [156, 157], [158, 159], [160, 164], [165, 167], [168, 170], [171, 178], [178, 179], [180, 184], [185, 188], [189, 194], [195, 196], [197, 198], [198, 199], [200, 201], [202, 206], [206, 207], [208, 209], [210, 212], [213, 214], [215, 219], [219, 220], [221, 224], [225, 228], [229, 235], [236, 243], [244, 247], [248, 254], [254, 255]]}
{"doc_key": "ai-dev-111", "ner": [[3, 5, "researcher"], [9, 12, "organisation"], [19, 22, "product"], [29, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 9, 12, "role", "", false, false], [19, 22, 9, 12, "temporal", "", false, false], [19, 22, 29, 30, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "then", "invited", "Wydner", "to", "the", "annual", "meeting", "of", "the", "American", "Translators", "Association", "the", "following", "October", ",", "where", "the", "Weidner", "Machine", "Translation", "System", "was", "hailed", "as", "a", "breakthrough", "in", "machine", "translation", "."], "sentence-detokenized": "He then invited Wydner to the annual meeting of the American Translators Association the following October, where the Weidner Machine Translation System was hailed as a breakthrough in machine translation.", "token2charspan": [[0, 2], [3, 7], [8, 15], [16, 22], [23, 25], [26, 29], [30, 36], [37, 44], [45, 47], [48, 51], [52, 60], [61, 72], [73, 84], [85, 88], [89, 98], [99, 106], [106, 107], [108, 113], [114, 117], [118, 125], [126, 133], [134, 145], [146, 152], [153, 156], [157, 163], [164, 166], [167, 168], [169, 181], [182, 184], [185, 192], [193, 204], [204, 205]]}
{"doc_key": "ai-dev-112", "ner": [[2, 8, "conference"], [10, 10, "conference"], [15, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 2, 8, "named", "", false, false], [10, 10, 2, 8, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["At", "the", "2018", "Conference", "on", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", ",", "researchers", "from", "Google", "presented", "a", "paper", "."], "sentence-detokenized": "At the 2018 Conference on Neural Information Processing Systems (NeurIPS), researchers from Google presented a paper.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 22], [23, 25], [26, 32], [33, 44], [45, 55], [56, 63], [64, 65], [65, 72], [72, 73], [73, 74], [75, 86], [87, 91], [92, 98], [99, 108], [109, 110], [111, 116], [116, 117]]}
{"doc_key": "ai-dev-113", "ner": [[0, 3, "algorithm"], [10, 10, "algorithm"], [15, 19, "metrics"], [22, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 10, 10, "usage", "", false, false], [10, 10, 15, 19, "related-to", "", true, false], [15, 19, 22, 28, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Baum", "-", "Welch", "algorithm", "uses", "the", "well", "-", "known", "EM", "algorithm", "to", "find", "the", "maximum", "likelihood", "estimate", "of", "the", "parameters", "of", "a", "hidden", "Markov", "model", ",", "given", "a", "set", "of", "observed", "feature", "vectors", "."], "sentence-detokenized": "The Baum-Welch algorithm uses the well-known EM algorithm to find the maximum likelihood estimate of the parameters of a hidden Markov model, given a set of observed feature vectors.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 14], [15, 24], [25, 29], [30, 33], [34, 38], [38, 39], [39, 44], [45, 47], [48, 57], [58, 60], [61, 65], [66, 69], [70, 77], [78, 88], [89, 97], [98, 100], [101, 104], [105, 115], [116, 118], [119, 120], [121, 127], [128, 134], [135, 140], [140, 141], [142, 147], [148, 149], [150, 153], [154, 156], [157, 165], [166, 173], [174, 181], [181, 182]]}
{"doc_key": "ai-dev-114", "ner": [[8, 8, "product"], [10, 10, "product"], [29, 29, "misc"], [34, 42, "product"], [44, 46, "programlang"], [48, 52, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 8, 10, 10, "compare", "", false, false], [29, 29, 10, 10, "part-of", "", false, false], [34, 42, 10, 10, "part-of", "", false, false], [48, 52, 10, 10, "part-of", "", false, false], [48, 52, 44, 46, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "addition", "to", "the", "taxonomic", "information", "contained", "in", "OpenCyc", ",", "ResearchCyc", "contains", "much", "more", "semantic", "knowledge", "(", "i.e.", "additional", "facts", "and", "rules", ")", "about", "the", "concepts", "in", "its", "knowledge", "base", ";", "it", "also", "includes", "a", "large", "lexicon", ",", "English", "parsing", "and", "generation", "tools", "and", "Java", "-", "based", "interfaces", "for", "knowledge", "editing", "and", "querying", "."], "sentence-detokenized": "In addition to the taxonomic information contained in OpenCyc, ResearchCyc contains much more semantic knowledge (i.e. additional facts and rules) about the concepts in its knowledge base; it also includes a large lexicon, English parsing and generation tools and Java-based interfaces for knowledge editing and querying.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 28], [29, 40], [41, 50], [51, 53], [54, 61], [61, 62], [63, 74], [75, 83], [84, 88], [89, 93], [94, 102], [103, 112], [113, 114], [114, 118], [119, 129], [130, 135], [136, 139], [140, 145], [145, 146], [147, 152], [153, 156], [157, 165], [166, 168], [169, 172], [173, 182], [183, 187], [187, 188], [189, 191], [192, 196], [197, 205], [206, 207], [208, 213], [214, 221], [221, 222], [223, 230], [231, 238], [239, 242], [243, 253], [254, 259], [260, 263], [264, 268], [268, 269], [269, 274], [275, 285], [286, 289], [290, 299], [300, 307], [308, 311], [312, 320], [320, 321]]}
{"doc_key": "ai-dev-115", "ner": [[0, 2, "algorithm"], [5, 6, "task"], [11, 11, "field"], [13, 14, "field"], [16, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 5, 6, "type-of", "", false, false], [5, 6, 11, 11, "part-of", "task_part_of_field", false, false], [5, 6, 13, 14, "part-of", "task_part_of_field", false, false], [5, 6, 16, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Hough", "transform", "is", "a", "feature", "extraction", "technique", "used", "in", "image", "analysis", ",", "computer", "vision", "and", "digital", "image", "processing", "."], "sentence-detokenized": "The Hough transform is a feature extraction technique used in image analysis, computer vision and digital image processing.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 22], [23, 24], [25, 32], [33, 43], [44, 53], [54, 58], [59, 61], [62, 67], [68, 76], [76, 77], [78, 86], [87, 93], [94, 97], [98, 105], [106, 111], [112, 122], [122, 123]]}
{"doc_key": "ai-dev-116", "ner": [[4, 4, "product"], [6, 10, "product"], [16, 16, "organisation"], [18, 18, "product"], [20, 21, "researcher"], [28, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 4, 6, 10, "named", "", false, false], [4, 4, 16, 16, "artifact", "", false, false], [4, 4, 18, 18, "origin", "developed_from", false, false], [18, 18, 20, 21, "artifact", "", false, false], [28, 29, 16, 16, "role", "supported", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1978", ",", "the", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "robot", "was", "developed", "by", "Unimation", "from", "Vicarm", "(", "Victor", "Scheinman", ")", "and", "with", "the", "support", "of", "General", "Motors", "."], "sentence-detokenized": "In 1978, the PUMA (Programmable Universal Machine for Assembly) robot was developed by Unimation from Vicarm (Victor Scheinman) and with the support of General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 19], [19, 31], [32, 41], [42, 49], [50, 53], [54, 62], [62, 63], [64, 69], [70, 73], [74, 83], [84, 86], [87, 96], [97, 101], [102, 108], [109, 110], [110, 116], [117, 126], [126, 127], [128, 131], [132, 136], [137, 140], [141, 148], [149, 151], [152, 159], [160, 166], [166, 167]]}
{"doc_key": "ai-dev-117", "ner": [[0, 1, "algorithm"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 7, 8, "origin", "", false, false], [0, 1, 10, 11, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "LSTM", "was", "proposed", "in", "1997", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "The LSTM was proposed in 1997 by Sepp Hochreiter and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 21], [22, 24], [25, 29], [30, 32], [33, 37], [38, 48], [49, 52], [53, 59], [60, 71], [71, 72]]}
{"doc_key": "ai-dev-118", "ner": [[11, 12, "metrics"], [15, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "as", "a", "2", "\u00d7", "2", "contingency", "table", ",", "or", "confusion", "matrix", ",", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated as a 2 \u00d7 2 contingency table, or confusion matrix, as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [63, 64], [65, 67], [68, 77], [78, 84], [84, 85], [86, 88], [89, 96], [96, 97]]}
{"doc_key": "ai-dev-119", "ner": [[9, 9, "conference"], [12, 13, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "also", "contributed", "a", "lot", "through", "the", "creation", "of", "ELRA", "and", "the", "LREC", "conference", "."], "sentence-detokenized": "He also contributed a lot through the creation of ELRA and the LREC conference.", "token2charspan": [[0, 2], [3, 7], [8, 19], [20, 21], [22, 25], [26, 33], [34, 37], [38, 46], [47, 49], [50, 54], [55, 58], [59, 62], [63, 67], [68, 78], [78, 79]]}
{"doc_key": "ai-dev-120", "ner": [[17, 18, "misc"], [22, 23, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[22, 23, 17, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "popular", "application", "of", "serial", "robots", "in", "today", "'s", "industry", "is", "the", "pick", "-", "and", "-", "place", "assembly", "robot", ",", "called", "the", "SCARA", "robot", ",", "which", "has", "four", "degrees", "of", "freedom", "."], "sentence-detokenized": "A popular application of serial robots in today's industry is the pick-and-place assembly robot, called the SCARA robot, which has four degrees of freedom.", "token2charspan": [[0, 1], [2, 9], [10, 21], [22, 24], [25, 31], [32, 38], [39, 41], [42, 47], [47, 49], [50, 58], [59, 61], [62, 65], [66, 70], [70, 71], [71, 74], [74, 75], [75, 80], [81, 89], [90, 95], [95, 96], [97, 103], [104, 107], [108, 113], [114, 119], [119, 120], [121, 126], [127, 130], [131, 135], [136, 143], [144, 146], [147, 154], [154, 155]]}
{"doc_key": "ai-dev-121", "ner": [[15, 21, "conference"], [23, 23, "conference"], [27, 30, "conference"], [41, 41, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 15, 21, "named", "", false, false], [41, 41, 27, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "is", "one", "of", "the", "founding", "members", "and", "former", "chair", "(", "2006-2008", ")", "of", "the", "Special", "Interest", "Group", "on", "Web", "as", "Corpus", "(", "SIGWAC", ")", "at", "the", "Association", "for", "Computational", "Linguistics", ",", "as", "well", "as", "one", "of", "the", "founding", "organisers", "of", "SENSEVAL", "."], "sentence-detokenized": "He is one of the founding members and former chair (2006-2008) of the Special Interest Group on Web as Corpus (SIGWAC) at the Association for Computational Linguistics, as well as one of the founding organisers of SENSEVAL.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 12], [13, 16], [17, 25], [26, 33], [34, 37], [38, 44], [45, 50], [51, 52], [52, 61], [61, 62], [63, 65], [66, 69], [70, 77], [78, 86], [87, 92], [93, 95], [96, 99], [100, 102], [103, 109], [110, 111], [111, 117], [117, 118], [119, 121], [122, 125], [126, 137], [138, 141], [142, 155], [156, 167], [167, 168], [169, 171], [172, 176], [177, 179], [180, 183], [184, 186], [187, 190], [191, 199], [200, 210], [211, 213], [214, 222], [222, 223]]}
{"doc_key": "ai-dev-122", "ner": [[4, 4, "product"], [8, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 4, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "platform", ",", "LinguaStream", "provides", "an", "extensive", "Java", "API", "."], "sentence-detokenized": "As a platform, LinguaStream provides an extensive Java API.", "token2charspan": [[0, 2], [3, 4], [5, 13], [13, 14], [15, 27], [28, 36], [37, 39], [40, 49], [50, 54], [55, 58], [58, 59]]}
{"doc_key": "ai-dev-123", "ner": [[11, 11, "programlang"], [14, 16, "misc"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 19, 21, "type-of", "", false, false], [14, 16, 19, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "robot", "kit", "is", "based", "on", "Android", "and", "is", "programmed", "using", "Java", ",", "the", "Blocks", "programming", "interface", "or", "other", "Android", "programming", "systems", "."], "sentence-detokenized": "The robot kit is based on Android and is programmed using Java, the Blocks programming interface or other Android programming systems.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 16], [17, 22], [23, 25], [26, 33], [34, 37], [38, 40], [41, 51], [52, 57], [58, 62], [62, 63], [64, 67], [68, 74], [75, 86], [87, 96], [97, 99], [100, 105], [106, 113], [114, 125], [126, 133], [133, 134]]}
{"doc_key": "ai-dev-124", "ner": [[4, 14, "algorithm"], [16, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "method", "of", "defining", "a", "linked", "list", "determines", "the", "use", "of", "depth", "-", "first", "search", "or", "breadth", "-", "first", "search", "."], "sentence-detokenized": "The method of defining a linked list determines the use of depth-first search or breadth-first search.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 22], [23, 24], [25, 31], [32, 36], [37, 47], [48, 51], [52, 55], [56, 58], [59, 64], [64, 65], [65, 70], [71, 77], [78, 80], [81, 88], [88, 89], [89, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-dev-125", "ner": [[19, 20, "task"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "regions", "can", "signal", "the", "presence", "of", "objects", "or", "parts", "of", "objects", "in", "the", "image", "domain", "with", "applications", "to", "object", "recognition", "and", "/", "or", "object", "video", "tracking", "."], "sentence-detokenized": "These regions can signal the presence of objects or parts of objects in the image domain with applications to object recognition and/or object video tracking.", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 24], [25, 28], [29, 37], [38, 40], [41, 48], [49, 51], [52, 57], [58, 60], [61, 68], [69, 71], [72, 75], [76, 81], [82, 88], [89, 93], [94, 106], [107, 109], [110, 116], [117, 128], [129, 132], [132, 133], [133, 135], [136, 142], [143, 148], [149, 157], [157, 158]]}
{"doc_key": "ai-dev-126", "ner": [[3, 5, "algorithm"], [7, 7, "product"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 3, 5, "type-of", "", false, false], [7, 7, 14, 15, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "the", "Semantic", "Web", "is", "WordNet", ",", "a", "lexical", "database", "of", "the", "English", "language", "."], "sentence-detokenized": "An example of the Semantic Web is WordNet, a lexical database of the English language.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 17], [18, 26], [27, 30], [31, 33], [34, 41], [41, 42], [43, 44], [45, 52], [53, 61], [62, 64], [65, 68], [69, 76], [77, 85], [85, 86]]}
{"doc_key": "ai-dev-127", "ner": [[0, 1, "task"], [7, 8, "field"], [10, 11, "field"], [21, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 7, 8, "part-of", "", false, false], [0, 1, 10, 11, "named", "same", false, false], [0, 1, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Speech", "recognition", "is", "an", "interdisciplinary", "field", "of", "computer", "science", "and", "computational", "linguistics", "that", "develops", "methodologies", "and", "technologies", "that", "enable", "computers", "to", "recognise", "and", "translate", "spoken", "language", "into", "text", "."], "sentence-detokenized": "Speech recognition is an interdisciplinary field of computer science and computational linguistics that develops methodologies and technologies that enable computers to recognise and translate spoken language into text.", "token2charspan": [[0, 6], [7, 18], [19, 21], [22, 24], [25, 42], [43, 48], [49, 51], [52, 60], [61, 68], [69, 72], [73, 86], [87, 98], [99, 103], [104, 112], [113, 126], [127, 130], [131, 143], [144, 148], [149, 155], [156, 165], [166, 168], [169, 178], [179, 182], [183, 192], [193, 199], [200, 208], [209, 213], [214, 218], [218, 219]]}
{"doc_key": "ai-dev-128", "ner": [[0, 0, "field"], [10, 12, "misc"], [16, 18, "field"], [20, 20, "task"], [22, 23, "task"], [43, 43, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 43, 43, "named", "same", false, false], [16, 18, 0, 0, "part-of", "subfield", false, false], [20, 20, 0, 0, "part-of", "", false, false], [20, 20, 16, 18, "part-of", "", false, false], [22, 23, 16, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["AI", "has", "retained", "most", "of", "the", "attention", "in", "relation", "to", "ontologies", "used", "in", "sub-disciplines", "such", "as", "natural", "language", "processing", "within", "machines", "and", "knowledge", "representation", ",", "but", "ontology", "editors", "are", "often", "used", "in", "many", "fields", "such", "as", "education", "without", "the", "intention", "of", "contributing", "to", "AI", "."], "sentence-detokenized": "AI has retained most of the attention in relation to ontologies used in sub-disciplines such as natural language processing within machines and knowledge representation, but ontology editors are often used in many fields such as education without the intention of contributing to AI.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 20], [21, 23], [24, 27], [28, 37], [38, 40], [41, 49], [50, 52], [53, 63], [64, 68], [69, 71], [72, 87], [88, 92], [93, 95], [96, 103], [104, 112], [113, 123], [124, 130], [131, 139], [140, 143], [144, 153], [154, 168], [168, 169], [170, 173], [174, 182], [183, 190], [191, 194], [195, 200], [201, 205], [206, 208], [209, 213], [214, 220], [221, 225], [226, 228], [229, 238], [239, 246], [247, 250], [251, 260], [261, 263], [264, 276], [277, 279], [280, 282], [282, 283]]}
{"doc_key": "ai-dev-129", "ner": [[10, 12, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 12, 14, 15, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["This", "update", "rule", "is", "in", "fact", "an", "update", "of", "the", "stochastic", "gradient", "descent", "for", "linear", "regression", "."], "sentence-detokenized": "This update rule is in fact an update of the stochastic gradient descent for linear regression.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 19], [20, 22], [23, 27], [28, 30], [31, 37], [38, 40], [41, 44], [45, 55], [56, 64], [65, 72], [73, 76], [77, 83], [84, 94], [94, 95]]}
{"doc_key": "ai-dev-130", "ner": [[5, 10, "organisation"], [13, 17, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "was", "elected", "to", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "the", "National", "Academy", "of", "Sciences", "and", "received", "a", "number", "of", "awards", ":"], "sentence-detokenized": "He was elected to the American Academy of Arts and Sciences and the National Academy of Sciences and received a number of awards:", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 21], [22, 30], [31, 38], [39, 41], [42, 46], [47, 50], [51, 59], [60, 63], [64, 67], [68, 76], [77, 84], [85, 87], [88, 96], [97, 100], [101, 109], [110, 111], [112, 118], [119, 121], [122, 128], [128, 129]]}
{"doc_key": "ai-dev-131", "ner": [[13, 14, "person"], [16, 19, "person"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "most", "recent", "school", "of", "thought", "on", "Honda", "strategy", "was", "put", "forward", "by", "Gary", "Hamel", "and", "C.", "K", ".", "Prahalad", "in", "1989", "."], "sentence-detokenized": "The most recent school of thought on Honda strategy was put forward by Gary Hamel and C. K. Prahalad in 1989.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 22], [23, 25], [26, 33], [34, 36], [37, 42], [43, 51], [52, 55], [56, 59], [60, 67], [68, 70], [71, 75], [76, 81], [82, 85], [86, 88], [89, 90], [90, 91], [92, 100], [101, 103], [104, 108], [108, 109]]}
{"doc_key": "ai-dev-132", "ner": [[1, 1, "metrics"], [4, 7, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 4, 7, "related-to", "calculates", true, false], [1, 1, 18, 18, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["While", "BLEU", "simply", "calculates", "the", "precision", "of", "the", "n-", "grams", "by", "adding", "an", "equal", "weight", "to", "each", ",", "NIST", "also", "calculates", "how", "informative", "a", "given", "n-", "gram", "is", "."], "sentence-detokenized": "While BLEU simply calculates the precision of the n-grams by adding an equal weight to each, NIST also calculates how informative a given n-gram is.", "token2charspan": [[0, 5], [6, 10], [11, 17], [18, 28], [29, 32], [33, 42], [43, 45], [46, 49], [50, 52], [52, 57], [58, 60], [61, 67], [68, 70], [71, 76], [77, 83], [84, 86], [87, 91], [91, 92], [93, 97], [98, 102], [103, 113], [114, 117], [118, 129], [130, 131], [132, 137], [138, 140], [140, 144], [145, 147], [147, 148]]}
{"doc_key": "ai-dev-133", "ner": [[4, 9, "misc"], [11, 14, "conference"], [16, 16, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 9, 11, 14, "temporal", "", false, false], [16, 16, 11, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "honoured", "with", "the", "2019", "Lifetime", "Achievement", "Award", "from", "the", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "."], "sentence-detokenized": "He was honoured with the 2019 Lifetime Achievement Award from the Association for Computational Linguistics (ACL).", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 20], [21, 24], [25, 29], [30, 38], [39, 50], [51, 56], [57, 61], [62, 65], [66, 77], [78, 81], [82, 95], [96, 107], [108, 109], [109, 112], [112, 113], [113, 114]]}
{"doc_key": "ai-dev-134", "ner": [[0, 0, "researcher"], [6, 11, "organisation"], [13, 13, "organisation"], [20, 24, "conference"], [26, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 11, "role", "", false, false], [0, 0, 20, 24, "role", "", false, false], [13, 13, 6, 11, "named", "", false, false], [26, 26, 20, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sycara", "is", "a", "member", "of", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", "and", "a", "member", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Sycara is a member of the Institute of Electrical and Electronics Engineers (IEEE) and a member of the American Association for Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 18], [19, 21], [22, 25], [26, 35], [36, 38], [39, 49], [50, 53], [54, 65], [66, 75], [76, 77], [77, 81], [81, 82], [83, 86], [87, 88], [89, 95], [96, 98], [99, 102], [103, 111], [112, 123], [124, 127], [128, 138], [139, 151], [152, 153], [153, 157], [157, 158], [158, 159]]}
{"doc_key": "ai-dev-135", "ner": [[2, 2, "product"], [10, 13, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 10, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "following", "MATLAB", "code", "demonstrates", "a", "specific", "solution", "to", "solve", "the", "non-linear", "system", "of", "equations", "presented", "in", "the", "previous", "chapter", ":", "See", "also", "."], "sentence-detokenized": "The following MATLAB code demonstrates a specific solution to solve the non-linear system of equations presented in the previous chapter: See also.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 38], [39, 40], [41, 49], [50, 58], [59, 61], [62, 67], [68, 71], [72, 82], [83, 89], [90, 92], [93, 102], [103, 112], [113, 115], [116, 119], [120, 128], [129, 136], [136, 137], [138, 141], [142, 146], [146, 147]]}
{"doc_key": "ai-dev-136", "ner": [[0, 2, "product"], [13, 14, "field"], [36, 36, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 13, 14, "related-to", "trained_by", true, false], [0, 2, 36, 36, "related-to", "trained_by", true, false], [13, 14, 36, 36, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Pattern", "recognition", "systems", "are", "in", "many", "cases", "trained", "on", "tagged", "training", "data", "(", "supervised", "learning", ")", ",", "but", "when", "tagged", "data", "is", "not", "available", ",", "other", "algorithms", "can", "be", "used", "to", "discover", "previously", "unknown", "patterns", "(", "unsupervised", "learning", ")", "."], "sentence-detokenized": "Pattern recognition systems are in many cases trained on tagged training data (supervised learning), but when tagged data is not available, other algorithms can be used to discover previously unknown patterns (unsupervised learning).", "token2charspan": [[0, 7], [8, 19], [20, 27], [28, 31], [32, 34], [35, 39], [40, 45], [46, 53], [54, 56], [57, 63], [64, 72], [73, 77], [78, 79], [79, 89], [90, 98], [98, 99], [99, 100], [101, 104], [105, 109], [110, 116], [117, 121], [122, 124], [125, 128], [129, 138], [138, 139], [140, 145], [146, 156], [157, 160], [161, 163], [164, 168], [169, 171], [172, 180], [181, 191], [192, 199], [200, 208], [209, 210], [210, 222], [223, 231], [231, 232], [232, 233]]}
{"doc_key": "ai-dev-137", "ner": [[5, 7, "researcher"], [10, 11, "country"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 10, 11, "physical", "", false, false], [5, 7, 23, 24, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "was", "first", "applied", "by", "Lawrence", "J.", "Fogel", "in", "the", "USA", "in", "1960", "to", "use", "simulated", "evolution", "as", "a", "learning", "process", "to", "generate", "artificial", "intelligence", "."], "sentence-detokenized": "It was first applied by Lawrence J. Fogel in the USA in 1960 to use simulated evolution as a learning process to generate artificial intelligence.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 20], [21, 23], [24, 32], [33, 35], [36, 41], [42, 44], [45, 48], [49, 52], [53, 55], [56, 60], [61, 63], [64, 67], [68, 77], [78, 87], [88, 90], [91, 92], [93, 101], [102, 109], [110, 112], [113, 121], [122, 132], [133, 145], [145, 146]]}
{"doc_key": "ai-dev-138", "ner": [[0, 1, "field"], [8, 8, "field"], [13, 16, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 8, 8, "part-of", "", false, false], [13, 16, 8, 8, "part-of", "", false, false], [16, 17, 8, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Reinforcement", "learning", "is", "one", "of", "the", "three", "basic", "machine", "learning", "paradigms", ",", "alongside", "supervised", "learning", "and", "unsupervised", "learning", "."], "sentence-detokenized": "Reinforcement learning is one of the three basic machine learning paradigms, alongside supervised learning and unsupervised learning.", "token2charspan": [[0, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 42], [43, 48], [49, 56], [57, 65], [66, 75], [75, 76], [77, 86], [87, 97], [98, 106], [107, 110], [111, 123], [124, 132], [132, 133]]}
{"doc_key": "ai-dev-139", "ner": [[4, 5, "field"], [12, 12, "programlang"], [31, 32, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 31, 32, "usage", "applies", false, false], [12, 12, 31, 32, "usage", "applies", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "such", "cases", ",", "cloud", "computing", "and", "the", "open", "source", "programming", "language", "R", "can", "help", "smaller", "banks", "to", "adopt", "risk", "analytics", "and", "support", "branch", "-", "level", "monitoring", "through", "the", "use", "of", "predictive", "analytics", "."], "sentence-detokenized": "In such cases, cloud computing and the open source programming language R can help smaller banks to adopt risk analytics and support branch-level monitoring through the use of predictive analytics.", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 20], [21, 30], [31, 34], [35, 38], [39, 43], [44, 50], [51, 62], [63, 71], [72, 73], [74, 77], [78, 82], [83, 90], [91, 96], [97, 99], [100, 105], [106, 110], [111, 120], [121, 124], [125, 132], [133, 139], [139, 140], [140, 145], [146, 156], [157, 164], [165, 168], [169, 172], [173, 175], [176, 186], [187, 196], [196, 197]]}
{"doc_key": "ai-dev-140", "ner": [[11, 12, "researcher"], [16, 16, "algorithm"], [22, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 22, 22, "named", "same", false, false], [16, 16, 11, 12, "origin", "proves_function", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["One", "of", "the", "first", "versions", "of", "the", "theorem", "was", "proved", "by", "Georg", "Cybenko", "in", "1989", "for", "sigmoidal", "type", "activation", "functions", ".", "Cybenko", "G.", "(", "1989", ")", ",", "2", "(", "4", ")", ",", "303-314", "."], "sentence-detokenized": "One of the first versions of the theorem was proved by Georg Cybenko in 1989 for sigmoidal type activation functions. Cybenko G. (1989), 2 (4), 303-314.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [17, 25], [26, 28], [29, 32], [33, 40], [41, 44], [45, 51], [52, 54], [55, 60], [61, 68], [69, 71], [72, 76], [77, 80], [81, 90], [91, 95], [96, 106], [107, 116], [116, 117], [118, 125], [126, 128], [129, 130], [130, 134], [134, 135], [135, 136], [137, 138], [139, 140], [140, 141], [141, 142], [142, 143], [144, 151], [151, 152]]}
{"doc_key": "ai-dev-141", "ner": [[8, 8, "algorithm"], [11, 11, "metrics"], [18, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 8, 8, "part-of", "", false, false], [18, 22, 11, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "this", "process", ",", "which", "is", "known", "as", "cross-validation", ",", "the", "MSE", "is", "often", "referred", "to", "as", "the", "mean", "square", "error", "of", "prediction", "and", "is", "calculated", "as"], "sentence-detokenized": "In this process, which is known as cross-validation, the MSE is often referred to as the mean square error of prediction and is calculated as", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 22], [23, 25], [26, 31], [32, 34], [35, 51], [51, 52], [53, 56], [57, 60], [61, 63], [64, 69], [70, 78], [79, 81], [82, 84], [85, 88], [89, 93], [94, 100], [101, 106], [107, 109], [110, 120], [121, 124], [125, 127], [128, 138], [139, 141]]}
{"doc_key": "ai-dev-142", "ner": [[0, 0, "task"], [3, 5, "task"], [7, 7, "task"], [13, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 5, "compare", "", false, false], [3, 5, 13, 18, "part-of", "", false, false], [7, 7, 3, 5, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OMR", "differs", "from", "optical", "character", "recognition", "(", "OCR", ")", "in", "that", "a", "sophisticated", "pattern", "recognition", "engine", "is", "not", "required", "."], "sentence-detokenized": "OMR differs from optical character recognition (OCR) in that a sophisticated pattern recognition engine is not required.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 24], [25, 34], [35, 46], [47, 48], [48, 51], [51, 52], [53, 55], [56, 60], [61, 62], [63, 76], [77, 84], [85, 96], [97, 103], [104, 106], [107, 110], [111, 119], [119, 120]]}
{"doc_key": "ai-dev-143", "ner": [[10, 10, "location"], [12, 12, "location"], [14, 14, "location"], [16, 17, "location"], [19, 20, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 14, 14, "physical", "", false, false], [16, 17, 12, 12, "physical", "", false, false], [19, 20, 12, 12, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2018", "and", "2019", ",", "the", "championships", "were", "held", "in", "Houston", "and", "Detroit", ",", "Michigan", "at", "TCF", "Center", "and", "Ford", "Field", "."], "sentence-detokenized": "In 2018 and 2019, the championships were held in Houston and Detroit, Michigan at TCF Center and Ford Field.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 16], [16, 17], [18, 21], [22, 35], [36, 40], [41, 45], [46, 48], [49, 56], [57, 60], [61, 68], [68, 69], [70, 78], [79, 81], [82, 85], [86, 92], [93, 96], [97, 101], [102, 107], [107, 108]]}
{"doc_key": "ai-dev-144", "ner": [[0, 0, "task"], [10, 10, "task"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 0, 0, "part-of", "", false, false], [13, 14, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "thought", "of", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multi-class", "classification", "."], "sentence-detokenized": "Classification can be thought of as two separate problems - binary classification and multi-class classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 29], [30, 32], [33, 35], [36, 39], [40, 48], [49, 57], [58, 59], [60, 66], [67, 81], [82, 85], [86, 97], [98, 112], [112, 113]]}
{"doc_key": "ai-dev-145", "ner": [[4, 5, "product"], [7, 9, "product"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 4, 5, "type-of", "", false, false], [12, 13, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "examples", "of", "popular", "parallel", "robots", "are", "the", "Stewart", "platform", "and", "the", "Delta", "robot", "."], "sentence-detokenized": "Two examples of popular parallel robots are the Stewart platform and the Delta robot.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 23], [24, 32], [33, 39], [40, 43], [44, 47], [48, 55], [56, 64], [65, 68], [69, 72], [73, 78], [79, 84], [84, 85]]}
{"doc_key": "ai-dev-146", "ner": [[3, 6, "algorithm"], [21, 21, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 6, 21, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "However", ",", "the", "ReLU", "activation", "function", ",", "which", "is", "undifferentiated", "to", "0", ",", "has", "become", "quite", "popular", ",", "e.g.", "at", "AlexNet", ")"], "sentence-detokenized": "(However, the ReLU activation function, which is undifferentiated to 0, has become quite popular, e.g. at AlexNet)", "token2charspan": [[0, 1], [1, 8], [8, 9], [10, 13], [14, 18], [19, 29], [30, 38], [38, 39], [40, 45], [46, 48], [49, 65], [66, 68], [69, 70], [70, 71], [72, 75], [76, 82], [83, 88], [89, 96], [96, 97], [98, 102], [103, 105], [106, 113], [113, 114]]}
{"doc_key": "ai-dev-147", "ner": [[0, 3, "metrics"], [11, 12, "task"], [15, 15, "task"], [18, 19, "task"], [21, 22, "task"], [26, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 26, 26, "named", "", true, false], [11, 12, 0, 3, "usage", "", true, false], [15, 15, 11, 12, "part-of", "", false, false], [18, 19, 11, 12, "part-of", "", false, false], [21, 22, 11, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "F", "-", "score", "is", "often", "used", "in", "the", "field", "of", "information", "retrieval", "to", "measure", "search", "performance", ",", "document", "classification", "and", "query", "classification", ".", "and", "so", "F_beta", "is", "seen", "in", "wide", "use", "."], "sentence-detokenized": "The F-score is often used in the field of information retrieval to measure search performance, document classification and query classification. and so F_beta is seen in wide use.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 20], [21, 25], [26, 28], [29, 32], [33, 38], [39, 41], [42, 53], [54, 63], [64, 66], [67, 74], [75, 81], [82, 93], [93, 94], [95, 103], [104, 118], [119, 122], [123, 128], [129, 143], [143, 144], [145, 148], [149, 151], [152, 158], [159, 161], [162, 166], [167, 169], [170, 174], [175, 178], [178, 179]]}
{"doc_key": "ai-dev-148", "ner": [[17, 18, "algorithm"], [20, 20, "algorithm"], [23, 24, "algorithm"], [26, 26, "algorithm"], [29, 31, "algorithm"], [33, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 20, 17, 18, "named", "", false, false], [26, 26, 23, 24, "named", "", false, false], [33, 33, 29, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "is", "done", "by", "modelling", "the", "received", "signal", "and", "then", "using", "a", "statistical", "estimation", "method", "such", "as", "maximum", "likelihood", "(", "ML", ")", ",", "majority", "voting", "(", "MV", ")", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "to", "decide", "which", "target", "in", "the", "library", "best", "fits", "the", "model", "built", "using", "the", "received", "signal", "."], "sentence-detokenized": "This is done by modelling the received signal and then using a statistical estimation method such as maximum likelihood (ML), majority voting (MV) or maximum a posteriori (MAP) to decide which target in the library best fits the model built using the received signal.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 15], [16, 25], [26, 29], [30, 38], [39, 45], [46, 49], [50, 54], [55, 60], [61, 62], [63, 74], [75, 85], [86, 92], [93, 97], [98, 100], [101, 108], [109, 119], [120, 121], [121, 123], [123, 124], [124, 125], [126, 134], [135, 141], [142, 143], [143, 145], [145, 146], [147, 149], [150, 157], [158, 159], [160, 170], [171, 172], [172, 175], [175, 176], [177, 179], [180, 186], [187, 192], [193, 199], [200, 202], [203, 206], [207, 214], [215, 219], [220, 224], [225, 228], [229, 234], [235, 240], [241, 246], [247, 250], [251, 259], [260, 266], [266, 267]]}
{"doc_key": "ai-dev-149", "ner": [[0, 0, "researcher"], [3, 3, "misc"], [5, 7, "field"], [8, 11, "university"], [15, 17, "misc"], [18, 18, "field"], [21, 22, "university"], [27, 28, "misc"], [19, 32, "field"], [33, 36, "university"], [44, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 0, 8, 11, "physical", "", false, false], [0, 0, 8, 11, "role", "", false, false], [0, 0, 21, 22, "physical", "", false, false], [0, 0, 21, 22, "role", "", false, false], [0, 0, 33, 36, "physical", "", false, false], [0, 0, 33, 36, "role", "", false, false], [3, 3, 0, 0, "origin", "", false, false], [3, 3, 5, 7, "topic", "", false, false], [15, 17, 0, 0, "origin", "", false, false], [15, 17, 18, 18, "topic", "", false, false], [27, 28, 0, 0, "origin", "", false, false], [27, 28, 19, 32, "topic", "", false, false], [44, 53, 27, 28, "named", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Sowa", "received", "a", "BS", "in", "Mathematics", "from", "the", "Massachusetts", "Institute", "of", "Technology", "in", "1962", ",", "an", "MA", "in", "Applied", "Science", "from", "Harvard", "University", "in", "1966", "and", "a", "PhD", "in", "Computer", "Science", "from", "the", "Vrije", "Universiteit", "Brussel", "in", "1999", ",", "based", "on", "a", "dissertation", "entitled", "Knowledge", "Representation", ":", "Logical", ",", "Philosophical", ",", "and", "Computational", "Foundations", "."], "sentence-detokenized": "Sowa received a BS in Mathematics from the Massachusetts Institute of Technology in 1962, an MA in Applied Science from Harvard University in 1966 and a PhD in Computer Science from the Vrije Universiteit Brussel in 1999, based on a dissertation entitled Knowledge Representation: Logical, Philosophical, and Computational Foundations.", "token2charspan": [[0, 4], [5, 13], [14, 15], [16, 18], [19, 21], [22, 33], [34, 38], [39, 42], [43, 56], [57, 66], [67, 69], [70, 80], [81, 83], [84, 88], [88, 89], [90, 92], [93, 95], [96, 98], [99, 106], [107, 114], [115, 119], [120, 127], [128, 138], [139, 141], [142, 146], [147, 150], [151, 152], [153, 156], [157, 159], [160, 168], [169, 176], [177, 181], [182, 185], [186, 191], [192, 204], [205, 212], [213, 215], [216, 220], [220, 221], [222, 227], [228, 230], [231, 232], [233, 245], [246, 254], [255, 264], [265, 279], [279, 280], [281, 288], [288, 289], [290, 303], [303, 304], [305, 308], [309, 322], [323, 334], [334, 335]]}
{"doc_key": "ai-dev-150", "ner": [[1, 2, "task"], [8, 8, "task"], [15, 18, "metrics"], [20, 21, "metrics"], [23, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 8, 8, "general-affiliation", "", false, false], [15, 18, 1, 2, "part-of", "", true, false], [20, 21, 1, 2, "part-of", "", true, false], [23, 24, 1, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Because", "paraphrase", "recognition", "can", "be", "posed", "as", "a", "classification", "problem", ",", "most", "standard", "evaluation", "metrics", ",", "such", "as", "accuracy", ",", "f1", "score", "or", "ROC", "curve", ",", "perform", "relatively", "well", "."], "sentence-detokenized": "Because paraphrase recognition can be posed as a classification problem, most standard evaluation metrics, such as accuracy, f1 score or ROC curve, perform relatively well.", "token2charspan": [[0, 7], [8, 18], [19, 30], [31, 34], [35, 37], [38, 43], [44, 46], [47, 48], [49, 63], [64, 71], [71, 72], [73, 77], [78, 86], [87, 97], [98, 105], [105, 106], [107, 111], [112, 114], [115, 123], [123, 124], [125, 127], [128, 133], [134, 136], [137, 140], [141, 146], [146, 147], [148, 155], [156, 166], [167, 171], [171, 172]]}
{"doc_key": "ai-dev-151", "ner": [[18, 20, "algorithm"], [28, 29, "algorithm"], [32, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 20, 28, 29, "opposite", "not_suited_for", false, false], [18, 20, 32, 32, "opposite", "not_suited_for", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "makes", "it", "practical", "for", "analysing", "large", "data", "sets", "(", "hundreds", "or", "thousands", "of", "taxa", ")", "and", "for", "bootstrapping", ",", "for", "which", "other", "modes", "of", "analysis", "(", "e.g.", "maximum", "parsimony", ",", "maximum", "likelihood", ")", "can", "be", "computationally", "prohibitive", "."], "sentence-detokenized": "This makes it practical for analysing large data sets (hundreds or thousands of taxa) and for bootstrapping, for which other modes of analysis (e.g. maximum parsimony, maximum likelihood) can be computationally prohibitive.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 37], [38, 43], [44, 48], [49, 53], [54, 55], [55, 63], [64, 66], [67, 76], [77, 79], [80, 84], [84, 85], [86, 89], [90, 93], [94, 107], [107, 108], [109, 112], [113, 118], [119, 124], [125, 130], [131, 133], [134, 142], [143, 144], [144, 148], [149, 156], [157, 166], [166, 167], [168, 175], [176, 186], [186, 187], [188, 191], [192, 194], [195, 210], [211, 222], [222, 223]]}
{"doc_key": "ai-dev-152", "ner": [[3, 3, "programlang"], [5, 5, "programlang"], [8, 12, "organisation"], [14, 14, "organisation"], [25, 38, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[14, 14, 8, 12, "named", "", false, false], [25, 38, 3, 3, "role", "submits", true, false], [25, 38, 5, 5, "role", "submits", true, false], [25, 38, 8, 12, "role", "submits_to", true, false]], "relations_mapping_to_source": [1, 2, 3, 4], "sentence": ["Submission", "of", "the", "DAML", "+", "OIL", "language", "to", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", "in", "2002", "work", "done", "by", "DAML", "contractors", "and", "the", "ad", "hoc", "Joint", "Committee", "on", "Markup", "Languages", "of", "the", "European", "Union", "/", "United", "States", "."], "sentence-detokenized": "Submission of the DAML + OIL language to the World Wide Web Consortium (W3C) in 2002 work done by DAML contractors and the ad hoc Joint Committee on Markup Languages of the European Union / United States.", "token2charspan": [[0, 10], [11, 13], [14, 17], [18, 22], [23, 24], [25, 28], [29, 37], [38, 40], [41, 44], [45, 50], [51, 55], [56, 59], [60, 70], [71, 72], [72, 75], [75, 76], [77, 79], [80, 84], [85, 89], [90, 94], [95, 97], [98, 102], [103, 114], [115, 118], [119, 122], [123, 125], [126, 129], [130, 135], [136, 145], [146, 148], [149, 155], [156, 165], [166, 168], [169, 172], [173, 181], [182, 187], [188, 189], [190, 196], [197, 203], [203, 204]]}
{"doc_key": "ai-dev-153", "ner": [[3, 4, "misc"], [7, 8, "misc"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 3, 4, "part-of", "", true, false], [11, 12, 3, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "non-linear", "normalisation", "is", "when", "the", "normalisation", "follows", "a", "sigmoidal", "function", ",", "in", "which", "case", "the", "normalised", "image", "is", "calculated", "according", "to", "the", "formula"], "sentence-detokenized": "An example of non-linear normalisation is when the normalisation follows a sigmoidal function, in which case the normalised image is calculated according to the formula", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 24], [25, 38], [39, 41], [42, 46], [47, 50], [51, 64], [65, 72], [73, 74], [75, 84], [85, 93], [93, 94], [95, 97], [98, 103], [104, 108], [109, 112], [113, 123], [124, 129], [130, 132], [133, 143], [144, 153], [154, 156], [157, 160], [161, 168]]}
{"doc_key": "ai-dev-154", "ner": [[5, 5, "metrics"], [10, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 10, 11, "related-to", "used_together", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "pointed", "out", "that", "precision", "is", "usually", "combined", "with", "recall", "to", "overcome", "this", "problem", "."], "sentence-detokenized": "It was pointed out that precision is usually combined with recall to overcome this problem.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 18], [19, 23], [24, 33], [34, 36], [37, 44], [45, 53], [54, 58], [59, 65], [66, 68], [69, 77], [78, 82], [83, 90], [90, 91]]}
{"doc_key": "ai-dev-155", "ner": [[4, 6, "metrics"], [8, 10, "metrics"], [20, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 20, 8, 10, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Common", "metrics", "used", "are", "mean", "squared", "error", "and", "mean", "squared", "error", ",", "the", "latter", "of", "which", "was", "used", "in", "the", "Netflix", "award", "."], "sentence-detokenized": "Common metrics used are mean squared error and mean squared error, the latter of which was used in the Netflix award.", "token2charspan": [[0, 6], [7, 14], [15, 19], [20, 23], [24, 28], [29, 36], [37, 42], [43, 46], [47, 51], [52, 59], [60, 65], [65, 66], [67, 70], [71, 77], [78, 80], [81, 86], [87, 90], [91, 95], [96, 98], [99, 102], [103, 110], [111, 116], [116, 117]]}
{"doc_key": "ai-dev-156", "ner": [[8, 10, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "August", "2016", ",", "a", "research", "programme", "from", "University", "College", "Hospital", "was", "announced", "to", "develop", "an", "algorithm", "that", "can", "automatically", "distinguish", "between", "healthy", "and", "cancerous", "tissue", "in", "areas", "of", "the", "head", "and", "neck", "."], "sentence-detokenized": "In August 2016, a research programme from University College Hospital was announced to develop an algorithm that can automatically distinguish between healthy and cancerous tissue in areas of the head and neck.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 17], [18, 26], [27, 36], [37, 41], [42, 52], [53, 60], [61, 69], [70, 73], [74, 83], [84, 86], [87, 94], [95, 97], [98, 107], [108, 112], [113, 116], [117, 130], [131, 142], [143, 150], [151, 158], [159, 162], [163, 172], [173, 179], [180, 182], [183, 188], [189, 191], [192, 195], [196, 200], [201, 204], [205, 209], [209, 210]]}
{"doc_key": "ai-dev-157", "ner": [[3, 4, "researcher"], [16, 18, "organisation"], [20, 24, "organisation"], [27, 30, "organisation"], [34, 38, "organisation"], [40, 47, "organisation"], [50, 53, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 4, 16, 18, "role", "", false, false], [3, 4, 20, 24, "role", "", false, false], [3, 4, 27, 30, "role", "", false, false], [3, 4, 34, 38, "role", "", false, false], [3, 4, 40, 47, "role", "", false, false], [3, 4, 50, 53, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "impact", "of", "Posner", "'s", "theoretical", "and", "empirical", "contributions", "has", "been", "recognised", "through", "memberships", "in", "the", "American", "Psychological", "Association", ",", "the", "Association", "for", "Psychological", "Science", ",", "the", "Society", "of", "Experimental", "Psychologists", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "The impact of Posner's theoretical and empirical contributions has been recognised through memberships in the American Psychological Association, the Association for Psychological Science, the Society of Experimental Psychologists, the American Academy of Arts and Sciences, the American Association for the Advancement of Science and the National Academy of Sciences.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 20], [20, 22], [23, 34], [35, 38], [39, 48], [49, 62], [63, 66], [67, 71], [72, 82], [83, 90], [91, 102], [103, 105], [106, 109], [110, 118], [119, 132], [133, 144], [144, 145], [146, 149], [150, 161], [162, 165], [166, 179], [180, 187], [187, 188], [189, 192], [193, 200], [201, 203], [204, 216], [217, 230], [230, 231], [232, 235], [236, 244], [245, 252], [253, 255], [256, 260], [261, 264], [265, 273], [273, 274], [275, 278], [279, 287], [288, 299], [300, 303], [304, 307], [308, 319], [320, 322], [323, 330], [331, 334], [335, 338], [339, 347], [348, 355], [356, 358], [359, 367], [367, 368]]}
{"doc_key": "ai-dev-158", "ner": [[2, 2, "product"], [7, 8, "field"], [12, 13, "task"], [15, 17, "task"], [19, 19, "task"], [22, 24, "task"], [26, 26, "task"], [29, 30, "field"], [32, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 2, 7, 8, "usage", "", false, false], [12, 13, 7, 8, "part-of", "", false, false], [15, 17, 7, 8, "part-of", "", false, false], [19, 19, 15, 17, "named", "", false, false], [22, 24, 7, 8, "part-of", "", false, false], [26, 26, 22, 24, "named", "", false, false], [29, 30, 7, 8, "part-of", "", false, false], [32, 33, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["These", "intelligent", "Chatbots", "use", "all", "kinds", "of", "artificial", "intelligence", ",", "such", "as", "image", "moderation", "and", "natural", "language", "understanding", "(", "NLU", ")", ",", "natural", "language", "generation", "(", "NLG", ")", ",", "machine", "learning", "and", "deep", "learning", "."], "sentence-detokenized": "These intelligent Chatbots use all kinds of artificial intelligence, such as image moderation and natural language understanding (NLU), natural language generation (NLG), machine learning and deep learning.", "token2charspan": [[0, 5], [6, 17], [18, 26], [27, 30], [31, 34], [35, 40], [41, 43], [44, 54], [55, 67], [67, 68], [69, 73], [74, 76], [77, 82], [83, 93], [94, 97], [98, 105], [106, 114], [115, 128], [129, 130], [130, 133], [133, 134], [134, 135], [136, 143], [144, 152], [153, 163], [164, 165], [165, 168], [168, 169], [169, 170], [171, 178], [179, 187], [188, 191], [192, 196], [197, 205], [205, 206]]}
{"doc_key": "ai-dev-159", "ner": [[4, 6, "metrics"], [8, 8, "metrics"], [11, 11, "metrics"], [14, 21, "metrics"], [27, 29, "metrics"], [31, 31, "metrics"], [34, 41, "metrics"], [44, 46, "metrics"], [48, 48, "metrics"], [51, 58, "metrics"], [64, 66, "metrics"], [68, 68, "metrics"], [72, 77, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 4, 6, "named", "", false, false], [11, 11, 4, 6, "named", "", false, false], [14, 21, 4, 6, "named", "", false, false], [31, 31, 27, 29, "named", "", false, false], [34, 41, 27, 29, "named", "", false, false], [48, 48, 44, 46, "named", "", false, false], [51, 58, 44, 46, "named", "", false, false], [68, 68, 64, 66, "named", "", false, false], [72, 77, 64, 66, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "ordinal", "coefficients", "are", "Positive", "Predictive", "Value", "(", "PPV", ",", "a.k.a.", "precision", ")", "(", "TP", "/", "(", "TP", "+", "FP", ")", ")", ",", "with", "a", "complement", "of", "FALSE", "Discovery", "Rate", "(", "FDR", ")", "(", "FP", "/", "(", "TP", "+", "FP", ")", ")", ";", "and", "Negative", "Predictive", "Value", "(", "NPV", ")", "(", "TN", "/", "(", "TN", "+", "FN", ")", ")", ",", "with", "a", "complement", "of", "FALSE", "Omission", "Rate", "(", "FOR", ")", "(", "FN", "/", "(", "TN", "+", "FN", ")", ")", "."], "sentence-detokenized": "The ordinal coefficients are Positive Predictive Value (PPV, a.k.a. precision) (TP / (TP + FP)), with a complement of FALSE Discovery Rate (FDR) (FP / (TP + FP)); and Negative Predictive Value (NPV) (TN / (TN + FN)), with a complement of FALSE Omission Rate (FOR) (FN / (TN + FN)).", "token2charspan": [[0, 3], [4, 11], [12, 24], [25, 28], [29, 37], [38, 48], [49, 54], [55, 56], [56, 59], [59, 60], [61, 67], [68, 77], [77, 78], [79, 80], [80, 82], [83, 84], [85, 86], [86, 88], [89, 90], [91, 93], [93, 94], [94, 95], [95, 96], [97, 101], [102, 103], [104, 114], [115, 117], [118, 123], [124, 133], [134, 138], [139, 140], [140, 143], [143, 144], [145, 146], [146, 148], [149, 150], [151, 152], [152, 154], [155, 156], [157, 159], [159, 160], [160, 161], [161, 162], [163, 166], [167, 175], [176, 186], [187, 192], [193, 194], [194, 197], [197, 198], [199, 200], [200, 202], [203, 204], [205, 206], [206, 208], [209, 210], [211, 213], [213, 214], [214, 215], [215, 216], [217, 221], [222, 223], [224, 234], [235, 237], [238, 243], [244, 252], [253, 257], [258, 259], [259, 262], [262, 263], [264, 265], [265, 267], [268, 269], [270, 271], [271, 273], [274, 275], [276, 278], [278, 279], [279, 280], [280, 281]]}
{"doc_key": "ai-dev-160", "ner": [[8, 8, "misc"], [14, 15, "algorithm"], [17, 17, "algorithm"], [20, 22, "algorithm"], [24, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[17, 17, 14, 15, "named", "", false, false], [24, 24, 20, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "information", "is", "a", "mixture", "of", "sitemaps", "and", "RSS", "and", "is", "created", "using", "the", "Information", "Model", "(", "IM", ")", "and", "Biomedical", "Resource", "Ontology", "(", "BRO", ")", "."], "sentence-detokenized": "The information is a mixture of sitemaps and RSS and is created using the Information Model (IM) and Biomedical Resource Ontology (BRO).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 20], [21, 28], [29, 31], [32, 40], [41, 44], [45, 48], [49, 52], [53, 55], [56, 63], [64, 69], [70, 73], [74, 85], [86, 91], [92, 93], [93, 95], [95, 96], [97, 100], [101, 111], [112, 120], [121, 129], [130, 131], [131, 134], [134, 135], [135, 136]]}
{"doc_key": "ai-dev-161", "ner": [[2, 2, "task"], [8, 10, "algorithm"], [12, 16, "algorithm"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 12, 16, "origin", "based_on", false, false], [12, 16, 8, 10, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "latest", "text", "recognition", "is", "based", "on", "the", "Recurrent", "neural", "network", "(", "Long", "short", "-", "term", "memory", ")", "and", "does", "not", "require", "a", "language", "model", "."], "sentence-detokenized": "The latest text recognition is based on the Recurrent neural network (Long short-term memory) and does not require a language model.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 27], [28, 30], [31, 36], [37, 39], [40, 43], [44, 53], [54, 60], [61, 68], [69, 70], [70, 74], [75, 80], [80, 81], [81, 85], [86, 92], [92, 93], [94, 97], [98, 102], [103, 106], [107, 114], [115, 116], [117, 125], [126, 131], [131, 132]]}
{"doc_key": "ai-dev-162", "ner": [[1, 5, "misc"], [4, 4, "metrics"], [8, 9, "algorithm"], [12, 14, "metrics"], [17, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 1, 5, "type-of", "", false, false], [8, 9, 4, 4, "related-to", "", true, false], [12, 14, 1, 5, "type-of", "", false, false], [17, 18, 12, 14, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Popular", "loss", "functions", "are", "hinge", "loss", "(", "for", "linear", "SVMs", ")", "and", "log", "-", "loss", "(", "for", "logistic", "regression", ")", "."], "sentence-detokenized": "Popular loss functions are hinge loss (for linear SVMs) and log-loss (for logistic regression).", "token2charspan": [[0, 7], [8, 12], [13, 22], [23, 26], [27, 32], [33, 37], [38, 39], [39, 42], [43, 49], [50, 54], [54, 55], [56, 59], [60, 63], [63, 64], [64, 68], [69, 70], [70, 73], [74, 82], [83, 93], [93, 94], [94, 95]]}
{"doc_key": "ai-dev-163", "ner": [[0, 1, "metrics"], [9, 14, "metrics"], [16, 16, "metrics"], [19, 21, "metrics"], [23, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 9, 14, "compare", "", false, false], [0, 1, 19, 21, "compare", "", false, false], [16, 16, 9, 14, "named", "", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SSIM", "aims", "to", "improve", "on", "traditional", "methods", "such", "as", "signal", "-", "to", "-", "noise", "ratio", "(", "PSNR", ")", "and", "mean", "square", "error", "(", "MSE", ")", "."], "sentence-detokenized": "SSIM aims to improve on traditional methods such as signal-to-noise ratio (PSNR) and mean square error (MSE).", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 20], [21, 23], [24, 35], [36, 43], [44, 48], [49, 51], [52, 58], [58, 59], [59, 61], [61, 62], [62, 67], [68, 73], [74, 75], [75, 79], [79, 80], [81, 84], [85, 89], [90, 96], [97, 102], [103, 104], [104, 107], [107, 108], [108, 109]]}
{"doc_key": "ai-dev-164", "ner": [[10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "work", "has", "inspired", "generations", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "His work has inspired generations of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 21], [22, 33], [34, 36], [37, 45], [46, 57], [58, 62], [63, 65], [66, 72], [73, 79], [79, 80], [81, 85], [86, 93], [94, 97], [98, 102], [103, 109], [109, 110]]}
{"doc_key": "ai-dev-165", "ner": [[9, 13, "algorithm"], [18, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 18, 9, 13, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["Further", "impulse", "training", "is", "not", "differentiated", ",", "which", "eliminates", "back", "-", "propagation", "-", "based", "training", "methods", "such", "as", "gradient", "descent", "."], "sentence-detokenized": "Further impulse training is not differentiated, which eliminates back-propagation-based training methods such as gradient descent.", "token2charspan": [[0, 7], [8, 15], [16, 24], [25, 27], [28, 31], [32, 46], [46, 47], [48, 53], [54, 64], [65, 69], [69, 70], [70, 81], [81, 82], [82, 87], [88, 96], [97, 104], [105, 109], [110, 112], [113, 121], [122, 129], [129, 130]]}
{"doc_key": "ai-dev-166", "ner": [[8, 9, "metrics"], [16, 17, "metrics"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 16, 17, "related-to", "describes", false, false], [16, 17, 18, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "relationships", "can", "be", "easily", "represented", "by", "a", "confusion", "matrix", ",", "a", "table", "that", "describes", "the", "accuracy", "of", "the", "classification", "model", "."], "sentence-detokenized": "These relationships can be easily represented by a confusion matrix, a table that describes the accuracy of the classification model.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 26], [27, 33], [34, 45], [46, 48], [49, 50], [51, 60], [61, 67], [67, 68], [69, 70], [71, 76], [77, 81], [82, 91], [92, 95], [96, 104], [105, 107], [108, 111], [112, 126], [127, 132], [132, 133]]}
{"doc_key": "ai-dev-167", "ner": [[2, 8, "conference"], [10, 10, "conference"], [15, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 2, 8, "named", "", false, false], [15, 15, 2, 8, "physical", "", false, false], [15, 15, 2, 8, "role", "", false, false], [15, 15, 2, 8, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["At", "the", "2018", "Conference", "on", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", ",", "researchers", "from", "Google", "presented", "work"], "sentence-detokenized": "At the 2018 Conference on Neural Information Processing Systems (NeurIPS), researchers from Google presented work", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 22], [23, 25], [26, 32], [33, 44], [45, 55], [56, 63], [64, 65], [65, 72], [72, 73], [73, 74], [75, 86], [87, 91], [92, 98], [99, 108], [109, 113]]}
{"doc_key": "ai-dev-168", "ner": [[2, 2, "university"], [8, 8, "product"], [16, 18, "misc"], [20, 21, "conference"], [10, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 8, 16, 18, "win-defeat", "", false, false], [16, 18, 20, 21, "temporal", "", false, false], [10, 30, 20, 21, "part-of", "", false, false], [10, 30, 20, 21, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "at", "Duke", ",", "he", "worked", "on", "the", "PROVERB", "automatic", "crossword", "solution", ",", "which", "won", "the", "Outstanding", "Paper", "Award", "from", "AAAI", "in", "1999", "and", "competed", "in", "the", "American", "Crossword", "Puzzle", "Tournament", "."], "sentence-detokenized": "While at Duke, he worked on the PROVERB automatic crossword solution, which won the Outstanding Paper Award from AAAI in 1999 and competed in the American Crossword Puzzle Tournament.", "token2charspan": [[0, 5], [6, 8], [9, 13], [13, 14], [15, 17], [18, 24], [25, 27], [28, 31], [32, 39], [40, 49], [50, 59], [60, 68], [68, 69], [70, 75], [76, 79], [80, 83], [84, 95], [96, 101], [102, 107], [108, 112], [113, 117], [118, 120], [121, 125], [126, 129], [130, 138], [139, 141], [142, 145], [146, 154], [155, 164], [165, 171], [172, 182], [182, 183]]}
{"doc_key": "ai-dev-169", "ner": [[2, 3, "location"], [5, 5, "location"], [14, 15, "country"], [17, 17, "country"], [19, 19, "country"], [21, 21, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 5, 5, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Headquartered", "in", "Rochester", "Hills", ",", "Michigan", ",", "the", "company", "had", "10", "regional", "locations", "in", "the", "US", ",", "Canada", ",", "Mexico", "and", "Brazil", "."], "sentence-detokenized": "Headquartered in Rochester Hills, Michigan, the company had 10 regional locations in the US, Canada, Mexico and Brazil.", "token2charspan": [[0, 13], [14, 16], [17, 26], [27, 32], [32, 33], [34, 42], [42, 43], [44, 47], [48, 55], [56, 59], [60, 62], [63, 71], [72, 81], [82, 84], [85, 88], [89, 91], [91, 92], [93, 99], [99, 100], [101, 107], [108, 111], [112, 118], [118, 119]]}
{"doc_key": "ai-dev-170", "ner": [[12, 12, "product"], [14, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "joins", "a", "collection", "of", "historically", "important", "robots", "that", "includes", "the", "early", "Unimate", "and", "Odetics", "Odex", "1", "."], "sentence-detokenized": "It joins a collection of historically important robots that includes the early Unimate and Odetics Odex 1.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 21], [22, 24], [25, 37], [38, 47], [48, 54], [55, 59], [60, 68], [69, 72], [73, 78], [79, 86], [87, 90], [91, 98], [99, 103], [104, 105], [105, 106]]}
{"doc_key": "ai-dev-171", "ner": [[7, 8, "researcher"], [10, 10, "organisation"], [13, 14, "researcher"], [23, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 10, 10, "physical", "", false, false], [7, 8, 10, 10, "role", "", false, false], [13, 14, 10, 10, "physical", "", false, false], [13, 14, 10, 10, "role", "", false, false], [13, 14, 23, 28, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["This", "issue", "'s", "guest", "editor", "will", "be", "David", "'s", "former", "NIST", "colleague", ",", "Judah", "Levine", ",", "who", "is", "the", "latest", "recipient", "of", "the", "I", ".", "I", ".", "Rabi", "Award", "."], "sentence-detokenized": "This issue's guest editor will be David's former NIST colleague, Judah Levine, who is the latest recipient of the I. I. Rabi Award.", "token2charspan": [[0, 4], [5, 10], [10, 12], [13, 18], [19, 25], [26, 30], [31, 33], [34, 39], [39, 41], [42, 48], [49, 53], [54, 63], [63, 64], [65, 70], [71, 77], [77, 78], [79, 82], [83, 85], [86, 89], [90, 96], [97, 106], [107, 109], [110, 113], [114, 115], [115, 116], [117, 118], [118, 119], [120, 124], [125, 130], [130, 131]]}
{"doc_key": "ai-dev-172", "ner": [[12, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "can", "be", "arranged", "in", "a", "2", "\u00d7", "2", "contingency", "table", "(", "confusion", "matrix", ")", ",", "conventionally", "with", "the", "test", "score", "on", "the", "vertical", "axis", "and", "the", "actual", "condition", "on", "the", "horizontal", "axis", "."], "sentence-detokenized": "These can be arranged in a 2 \u00d7 2 contingency table (confusion matrix), conventionally with the test score on the vertical axis and the actual condition on the horizontal axis.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 21], [22, 24], [25, 26], [27, 28], [29, 30], [31, 32], [33, 44], [45, 50], [51, 52], [52, 61], [62, 68], [68, 69], [69, 70], [71, 85], [86, 90], [91, 94], [95, 99], [100, 105], [106, 108], [109, 112], [113, 121], [122, 126], [127, 130], [131, 134], [135, 141], [142, 151], [152, 154], [155, 158], [159, 169], [170, 174], [174, 175]]}
{"doc_key": "ai-dev-173", "ner": [[0, 3, "product"], [7, 7, "product"], [9, 9, "product"], [11, 12, "product"], [14, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 7, 7, "part-of", "", false, false], [0, 3, 9, 9, "part-of", "", false, false], [0, 3, 11, 12, "part-of", "", false, false], [0, 3, 14, 16, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Apple", "'s", "iOS", "operating", "system", "used", "on", "iPhone", ",", "iPad", "and", "iPod", "Touch", "uses", "VoiceOver", "speech", "synthesis", "."], "sentence-detokenized": "Apple's iOS operating system used on iPhone, iPad and iPod Touch uses VoiceOver speech synthesis.", "token2charspan": [[0, 5], [5, 7], [8, 11], [12, 21], [22, 28], [29, 33], [34, 36], [37, 43], [43, 44], [45, 49], [50, 53], [54, 58], [59, 64], [65, 69], [70, 79], [80, 86], [87, 96], [96, 97]]}
{"doc_key": "ai-dev-174", "ner": [[8, 10, "conference"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "the", "best", "system", "entering", "the", "MUC", "-", "7", "achieved", "a", "93.39", "%", "F", "-", "measure", ",", "while", "the", "human", "annotators", "achieved", "97.6", "%", "and", "96.95", "%", "."], "sentence-detokenized": "For example, the best system entering the MUC-7 achieved a 93.39% F-measure, while the human annotators achieved 97.6% and 96.95%.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 37], [38, 41], [42, 45], [45, 46], [46, 47], [48, 56], [57, 58], [59, 64], [64, 65], [66, 67], [67, 68], [68, 75], [75, 76], [77, 82], [83, 86], [87, 92], [93, 103], [104, 112], [113, 117], [117, 118], [119, 122], [123, 128], [128, 129], [129, 130]]}
{"doc_key": "ai-dev-175", "ner": [[13, 13, "algorithm"], [16, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 18, 13, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "is", "done", "using", "standard", "neural", "network", "training", "algorithms", ",", "such", "as", "stochastic", "gradient", "descent", "with", "back", "-", "propagation", "."], "sentence-detokenized": "This is done using standard neural network training algorithms, such as stochastic gradient descent with back-propagation.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 18], [19, 27], [28, 34], [35, 42], [43, 51], [52, 62], [62, 63], [64, 68], [69, 71], [72, 82], [83, 91], [92, 99], [100, 104], [105, 109], [109, 110], [110, 121], [121, 122]]}
{"doc_key": "ai-dev-176", "ner": [[0, 1, "organisation"], [18, 18, "country"], [25, 25, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 18, 18, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Rotten", "Tomatoes", "is", "a", "Top", "1000", "site", ",", "ranking", "around", "#", "400", "globally", "and", "Top", "150", "for", "the", "US", "only", ",", "according", "to", "website", "ranker", "Alexa", "."], "sentence-detokenized": "Rotten Tomatoes is a Top 1000 site, ranking around # 400 globally and Top 150 for the US only, according to website ranker Alexa.", "token2charspan": [[0, 6], [7, 15], [16, 18], [19, 20], [21, 24], [25, 29], [30, 34], [34, 35], [36, 43], [44, 50], [51, 52], [53, 56], [57, 65], [66, 69], [70, 73], [74, 77], [78, 81], [82, 85], [86, 88], [89, 93], [93, 94], [95, 104], [105, 107], [108, 115], [116, 122], [123, 128], [128, 129]]}
{"doc_key": "ai-dev-177", "ner": [[13, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "general", ",", "all", "learning", "shows", "incremental", "changes", "over", "time", ",", "but", "describes", "a", "sigmoidal", "function", "that", "has", "different", "appearances", "depending", "on", "the", "time", "scale", "of", "observation", "."], "sentence-detokenized": "In general, all learning shows incremental changes over time, but describes a sigmoidal function that has different appearances depending on the time scale of observation.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 24], [25, 30], [31, 42], [43, 50], [51, 55], [56, 60], [60, 61], [62, 65], [66, 75], [76, 77], [78, 87], [88, 96], [97, 101], [102, 105], [106, 115], [116, 127], [128, 137], [138, 140], [141, 144], [145, 149], [150, 155], [156, 158], [159, 170], [170, 171]]}
{"doc_key": "ai-dev-178", "ner": [[0, 0, "metrics"], [5, 7, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["SSD", "is", "also", "known", "as", "mean", "square", "error", "."], "sentence-detokenized": "SSD is also known as mean square error.", "token2charspan": [[0, 3], [4, 6], [7, 11], [12, 17], [18, 20], [21, 25], [26, 32], [33, 38], [38, 39]]}
{"doc_key": "ai-dev-179", "ner": [[0, 2, "algorithm"], [4, 5, "algorithm"], [7, 10, "algorithm"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 24, 25, "related-to", "can_be_related_to", true, false], [4, 5, 24, 25, "related-to", "can_be_related_to", true, false], [7, 10, 24, 25, "related-to", "can_be_related_to", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", ",", "neural", "networks", "or", "a", "naive", "Bayes", "classifier", "can", "be", "used", "in", "conjunction", "with", "measures", "of", "model", "quality", ",", "such", "as", "balanced", "accuracy"], "sentence-detokenized": "Decision tree learning, neural networks or a naive Bayes classifier can be used in conjunction with measures of model quality, such as balanced accuracy", "token2charspan": [[0, 8], [9, 13], [14, 22], [22, 23], [24, 30], [31, 39], [40, 42], [43, 44], [45, 50], [51, 56], [57, 67], [68, 71], [72, 74], [75, 79], [80, 82], [83, 94], [95, 99], [100, 108], [109, 111], [112, 117], [118, 125], [125, 126], [127, 131], [132, 134], [135, 143], [144, 152]]}
{"doc_key": "ai-dev-180", "ner": [[16, 16, "conference"], [21, 25, "conference"], [26, 28, "misc"], [34, 36, "product"], [43, 46, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[26, 28, 21, 25, "origin", "", false, false], [26, 28, 21, 25, "temporal", "", false, false], [34, 36, 26, 28, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "is", "a", "past", "president", "(", "1979", ")", "and", "inaugural", "Fellow", "(", "2011", ")", "of", "the", "ACL", ",", "co-recipient", "of", "the", "1992", "Association", "for", "Computing", "Machinery", "Software", "Systems", "Award", "for", "his", "contribution", "to", "the", "Interlisp", "programming", "system", ",", "and", "a", "Fellow", "of", "the", "Association", "for", "Computing", "Machinery", "."], "sentence-detokenized": "He is a past president (1979) and inaugural Fellow (2011) of the ACL, co-recipient of the 1992 Association for Computing Machinery Software Systems Award for his contribution to the Interlisp programming system, and a Fellow of the Association for Computing Machinery.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 22], [23, 24], [24, 28], [28, 29], [30, 33], [34, 43], [44, 50], [51, 52], [52, 56], [56, 57], [58, 60], [61, 64], [65, 68], [68, 69], [70, 82], [83, 85], [86, 89], [90, 94], [95, 106], [107, 110], [111, 120], [121, 130], [131, 139], [140, 147], [148, 153], [154, 157], [158, 161], [162, 174], [175, 177], [178, 181], [182, 191], [192, 203], [204, 210], [210, 211], [212, 215], [216, 217], [218, 224], [225, 227], [228, 231], [232, 243], [244, 247], [248, 257], [258, 267], [267, 268]]}
{"doc_key": "ai-dev-181", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [12, 13, "researcher"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 27, 28, "related-to", "", false, false], [5, 6, 27, 28, "related-to", "", false, false], [8, 8, 27, 28, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "is", "considered", "by", "Cade", "Metz", "to", "be", "one", "of", "the", "three", "people", "most", "responsible", "for", "the", "progress", "of", "deep", "learning", "in", "the", "1990s", "and", "2000s", "."], "sentence-detokenized": "Along with Geoffrey Hinton and Yann LeCun, Bengio is considered by Cade Metz to be one of the three people most responsible for the progress of deep learning in the 1990s and 2000s.", "token2charspan": [[0, 5], [6, 10], [11, 19], [20, 26], [27, 30], [31, 35], [36, 41], [41, 42], [43, 49], [50, 52], [53, 63], [64, 66], [67, 71], [72, 76], [77, 79], [80, 82], [83, 86], [87, 89], [90, 93], [94, 99], [100, 106], [107, 111], [112, 123], [124, 127], [128, 131], [132, 140], [141, 143], [144, 148], [149, 157], [158, 160], [161, 164], [165, 170], [171, 174], [175, 180], [180, 181]]}
{"doc_key": "ai-dev-182", "ner": [[1, 2, "field"], [4, 13, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "information", "theory", "and", "computer", "science", ",", "a", "code", "is", "usually", "considered", "to", "be", "an", "algorithm", "that", "uniquely", "represents", "symbols", "from", "some", "source", "alphabet", "by", "encoded", "strings", "of", "characters", "that", "may", "be", "in", "some", "other", "target", "alphabet", "."], "sentence-detokenized": "In information theory and computer science, a code is usually considered to be an algorithm that uniquely represents symbols from some source alphabet by encoded strings of characters that may be in some other target alphabet.", "token2charspan": [[0, 2], [3, 14], [15, 21], [22, 25], [26, 34], [35, 42], [42, 43], [44, 45], [46, 50], [51, 53], [54, 61], [62, 72], [73, 75], [76, 78], [79, 81], [82, 91], [92, 96], [97, 105], [106, 116], [117, 124], [125, 129], [130, 134], [135, 141], [142, 150], [151, 153], [154, 161], [162, 169], [170, 172], [173, 183], [184, 188], [189, 192], [193, 195], [196, 198], [199, 203], [204, 209], [210, 216], [217, 225], [225, 226]]}
{"doc_key": "ai-dev-183", "ner": [[8, 9, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 8, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "fairly", "simple", "non", "-linear", "function", ",", "a", "sigmoidal", "function", "such", "as", "the", "logistic", "function", ",", "also", "has", "an", "easily", "computable", "derivative", ",", "which", "can", "be", "important", "when", "calculating", "updates", "to", "the", "weights", "in", "the", "network", "."], "sentence-detokenized": "A fairly simple non-linear function, a sigmoidal function such as the logistic function, also has an easily computable derivative, which can be important when calculating updates to the weights in the network.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 19], [19, 26], [27, 35], [35, 36], [37, 38], [39, 48], [49, 57], [58, 62], [63, 65], [66, 69], [70, 78], [79, 87], [87, 88], [89, 93], [94, 97], [98, 100], [101, 107], [108, 118], [119, 129], [129, 130], [131, 136], [137, 140], [141, 143], [144, 153], [154, 158], [159, 170], [171, 178], [179, 181], [182, 185], [186, 193], [194, 196], [197, 200], [201, 208], [208, 209]]}
{"doc_key": "ai-dev-184", "ner": [[0, 0, "person"], [4, 4, "location"], [6, 6, "location"], [8, 8, "country"], [11, 11, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[0, 0, 4, 4, "physical", "", false, false], [4, 4, 6, 6, "physical", "", false, false], [6, 6, 8, 8, "physical", "", false, false], [6, 6, 11, 11, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4], "sentence": ["\u010capek", "was", "born", "in", "Hronov", "in", "Bohemia", "(", "Austro-Hungary", ",", "later", "Czechoslovakia", ",", "now", "the", "Czech", "Republic", ")", "in", "1887", "."], "sentence-detokenized": "\u010capek was born in Hronov in Bohemia (Austro-Hungary, later Czechoslovakia, now the Czech Republic) in 1887.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 17], [18, 24], [25, 27], [28, 35], [36, 37], [37, 51], [51, 52], [53, 58], [59, 73], [73, 74], [75, 78], [79, 82], [83, 88], [89, 97], [97, 98], [99, 101], [102, 106], [106, 107]]}
{"doc_key": "ai-dev-185", "ner": [[6, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "specialised", "programmes", "can", "run", "an", "RSS", "narrative", "."], "sentence-detokenized": "Some specialised programmes can run an RSS narrative.", "token2charspan": [[0, 4], [5, 16], [17, 27], [28, 31], [32, 35], [36, 38], [39, 42], [43, 52], [52, 53]]}
{"doc_key": "ai-dev-186", "ner": [[6, 7, "task"], [11, 12, "task"], [14, 14, "task"], [16, 16, "task"], [19, 21, "task"], [28, 29, "task"], [32, 33, "task"], [37, 38, "task"], [41, 43, "product"], [45, 46, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[6, 7, 11, 12, "related-to", "", true, false], [6, 7, 14, 14, "related-to", "", true, false], [6, 7, 16, 16, "related-to", "", true, false], [32, 33, 28, 29, "usage", "", true, false], [41, 43, 37, 38, "type-of", "", false, false], [45, 46, 37, 38, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Aspects", "of", "ontology", "editors", "include", ":", "visual", "navigation", "capabilities", "within", "the", "knowledge", "model", ",", "inference", "and", "extraction", "engines", ";", "support", "for", "modules", ";", "import", "and", "export", "of", "foreign", "knowledge", "representation", "languages", "for", "ontology", "matching", ";", "support", "for", "meta", "-ontologies", "such", "as", "OWL", "-", "S", ",", "Dublin", "Core", ",", "etc", "."], "sentence-detokenized": "Aspects of ontology editors include: visual navigation capabilities within the knowledge model, inference and extraction engines; support for modules; import and export of foreign knowledge representation languages for ontology matching; support for meta-ontologies such as OWL-S, Dublin Core, etc.", "token2charspan": [[0, 7], [8, 10], [11, 19], [20, 27], [28, 35], [35, 36], [37, 43], [44, 54], [55, 67], [68, 74], [75, 78], [79, 88], [89, 94], [94, 95], [96, 105], [106, 109], [110, 120], [121, 128], [128, 129], [130, 137], [138, 141], [142, 149], [149, 150], [151, 157], [158, 161], [162, 168], [169, 171], [172, 179], [180, 189], [190, 204], [205, 214], [215, 218], [219, 227], [228, 236], [236, 237], [238, 245], [246, 249], [250, 254], [254, 265], [266, 270], [271, 273], [274, 277], [277, 278], [278, 279], [279, 280], [281, 287], [288, 292], [292, 293], [294, 297], [297, 298]]}
{"doc_key": "ai-dev-187", "ner": [[0, 1, "organisation"], [6, 9, "misc"], [13, 17, "task"], [20, 20, "field"], [23, 23, "misc"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 9, 0, 1, "origin", "", false, false], [13, 17, 6, 9, "part-of", "", false, false], [20, 20, 6, 9, "part-of", "", false, false], [23, 23, 20, 20, "type-of", "", false, false], [25, 26, 20, 20, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "FBI", "has", "also", "introduced", "the", "Next", "Generation", "Identification", "programme", ",", "which", "includes", "facial", "recognition", "as", "well", "as", "more", "traditional", "biometrics", "such", "as", "fingerprints", "and", "iris", "scans", ",", "which", "can", "come", "from", "both", "criminal", "and", "civilian", "databases", "."], "sentence-detokenized": "The FBI has also introduced the Next Generation Identification programme, which includes facial recognition as well as more traditional biometrics such as fingerprints and iris scans, which can come from both criminal and civilian databases.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 16], [17, 27], [28, 31], [32, 36], [37, 47], [48, 62], [63, 72], [72, 73], [74, 79], [80, 88], [89, 95], [96, 107], [108, 110], [111, 115], [116, 118], [119, 123], [124, 135], [136, 146], [147, 151], [152, 154], [155, 167], [168, 171], [172, 176], [177, 182], [182, 183], [184, 189], [190, 193], [194, 198], [199, 203], [204, 208], [209, 217], [218, 221], [222, 230], [231, 240], [240, 241]]}
{"doc_key": "ai-dev-188", "ner": [[7, 8, "person"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "2016", "season", "saw", "the", "addition", "of", "Samantha", "Ponder", "as", "host", ",", "replacing", "Molly", "McGrath", "."], "sentence-detokenized": "The 2016 season saw the addition of Samantha Ponder as host, replacing Molly McGrath.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 19], [20, 23], [24, 32], [33, 35], [36, 44], [45, 51], [52, 54], [55, 59], [59, 60], [61, 70], [71, 76], [77, 84], [84, 85]]}
{"doc_key": "ai-dev-189", "ner": [[2, 5, "algorithm"], [17, 21, "misc"], [23, 23, "misc"], [25, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "adversarial", "search", "algorithm", "commonly", "used", "for", "machine", "play", "of", "two", "-", "player", "games", "(", "Tic", "-", "tac", "-", "toe", ",", "Chess", ",", "Go", ",", "etc.", ")", "."], "sentence-detokenized": "This is an adversarial search algorithm commonly used for machine play of two-player games (Tic-tac-toe, Chess, Go, etc.).", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 29], [30, 39], [40, 48], [49, 53], [54, 57], [58, 65], [66, 70], [71, 73], [74, 77], [77, 78], [78, 84], [85, 90], [91, 92], [92, 95], [95, 96], [96, 99], [99, 100], [100, 103], [103, 104], [105, 110], [110, 111], [112, 114], [114, 115], [116, 120], [120, 121], [121, 122]]}
{"doc_key": "ai-dev-190", "ner": [[5, 9, "field"], [7, 7, "field"], [10, 11, "field"], [17, 18, "field"], [20, 21, "field"], [24, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "covers", "the", "fields", "of", "computer", "or", "machine", "vision", "and", "medical", "imaging", "and", "makes", "extensive", "use", "of", "pattern", "recognition", ",", "digital", "geometry", "and", "signal", "processing", "."], "sentence-detokenized": "It covers the fields of computer or machine vision and medical imaging and makes extensive use of pattern recognition, digital geometry and signal processing.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 20], [21, 23], [24, 32], [33, 35], [36, 43], [44, 50], [51, 54], [55, 62], [63, 70], [71, 74], [75, 80], [81, 90], [91, 94], [95, 97], [98, 105], [106, 117], [117, 118], [119, 126], [127, 135], [136, 139], [140, 146], [147, 157], [157, 158]]}
{"doc_key": "ai-dev-191", "ner": [[3, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "a", "facial", "recognition", "system", ",", "for", "example", ",", "a", "photo", "of", "a", "person", "'s", "face", "will", "be", "the", "input", "and", "the", "output", "label", "will", "be", "that", "person", "'s", "name", "."], "sentence-detokenized": "In a facial recognition system, for example, a photo of a person's face will be the input and the output label will be that person's name.", "token2charspan": [[0, 2], [3, 4], [5, 11], [12, 23], [24, 30], [30, 31], [32, 35], [36, 43], [43, 44], [45, 46], [47, 52], [53, 55], [56, 57], [58, 64], [64, 66], [67, 71], [72, 76], [77, 79], [80, 83], [84, 89], [90, 93], [94, 97], [98, 104], [105, 110], [111, 115], [116, 118], [119, 123], [124, 130], [130, 132], [133, 137], [137, 138]]}
{"doc_key": "ai-dev-192", "ner": [[0, 1, "organisation"], [4, 7, "product"], [9, 11, "product"], [19, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 7, "artifact", "", false, false], [4, 7, 9, 11, "part-of", "", false, false], [9, 11, 4, 7, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Apple", "Inc", "has", "introduced", "Face", "ID", "in", "the", "flagship", "i", "Phone", "X", "as", "the", "successor", "to", "biometric", "authentication", "for", "Touch", "ID", ",", "a", "fingerprint", "-", "based", "system", "."], "sentence-detokenized": "Apple Inc has introduced Face ID in the flagship iPhone X as the successor to biometric authentication for Touch ID, a fingerprint-based system.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 24], [25, 29], [30, 32], [33, 35], [36, 39], [40, 48], [49, 50], [50, 55], [56, 57], [58, 60], [61, 64], [65, 74], [75, 77], [78, 87], [88, 102], [103, 106], [107, 112], [113, 115], [115, 116], [117, 118], [119, 130], [130, 131], [131, 136], [137, 143], [143, 144]]}
{"doc_key": "ai-dev-193", "ner": [[3, 5, "metrics"], [8, 9, "metrics"], [22, 25, "metrics"], [28, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Or", "combine", "the", "F", "-", "measure", "with", "the", "R-", "square", "estimated", "for", "the", "raw", "model", "output", "and", "the", "target", ";", "or", "the", "cost", "/", "benefit", "matrix", "with", "the", "correlation", "coefficient", ",", "and", "so", "on", "."], "sentence-detokenized": "Or combine the F-measure with the R-square estimated for the raw model output and the target; or the cost/benefit matrix with the correlation coefficient, and so on.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 16], [16, 17], [17, 24], [25, 29], [30, 33], [34, 36], [36, 42], [43, 52], [53, 56], [57, 60], [61, 64], [65, 70], [71, 77], [78, 81], [82, 85], [86, 92], [92, 93], [94, 96], [97, 100], [101, 105], [105, 106], [106, 113], [114, 120], [121, 125], [126, 129], [130, 141], [142, 153], [153, 154], [155, 158], [159, 161], [162, 164], [164, 165]]}
{"doc_key": "ai-dev-194", "ner": [[0, 6, "conference"], [12, 14, "location"], [16, 16, "location"], [18, 23, "location"], [25, 25, "location"], [27, 27, "country"], [33, 35, "location"], [37, 42, "location"], [44, 46, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 6, 12, 14, "physical", "", false, false], [0, 6, 18, 23, "physical", "", false, false], [0, 6, 33, 35, "physical", "", false, false], [0, 6, 37, 42, "physical", "", false, false], [12, 14, 16, 16, "physical", "", false, false], [18, 23, 25, 25, "physical", "", false, false], [25, 25, 27, 27, "physical", "", false, false], [33, 35, 44, 46, "physical", "", false, false], [37, 42, 44, 46, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "Spanish", "edition", "of", "the", "Campus", "Party", "has", "been", "held", "at", "the", "Colegio", "Miguel", "Hern\u00e1ndez", ",", "Ceulaj", "and", "the", "Municipal", "Sport", "Arena", "of", "Benalm\u00e1dena", "in", "M\u00e1laga", ",", "Spain", ";", "and", "at", "both", "the", "Valencia", "County", "Fair", "and", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", "over", "the", "past", "15", "years", "."], "sentence-detokenized": "The Spanish edition of the Campus Party has been held at the Colegio Miguel Hern\u00e1ndez, Ceulaj and the Municipal Sport Arena of Benalm\u00e1dena in M\u00e1laga, Spain; and at both the Valencia County Fair and the City of Arts and Sciences in Valencia over the past 15 years.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 22], [23, 26], [27, 33], [34, 39], [40, 43], [44, 48], [49, 53], [54, 56], [57, 60], [61, 68], [69, 75], [76, 85], [85, 86], [87, 93], [94, 97], [98, 101], [102, 111], [112, 117], [118, 123], [124, 126], [127, 138], [139, 141], [142, 148], [148, 149], [150, 155], [155, 156], [157, 160], [161, 163], [164, 168], [169, 172], [173, 181], [182, 188], [189, 193], [194, 197], [198, 201], [202, 206], [207, 209], [210, 214], [215, 218], [219, 227], [228, 230], [231, 239], [240, 244], [245, 248], [249, 253], [254, 256], [257, 262], [262, 263]]}
{"doc_key": "ai-dev-195", "ner": [[0, 0, "product"], [15, 15, "programlang"], [19, 19, "product"], [21, 21, "product"], [25, 25, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 15, 0, 0, "general-affiliation", "", false, false], [19, 19, 15, 15, "part-of", "", false, false], [21, 21, 15, 15, "part-of", "", false, false], [25, 25, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["gnuplot", "can", "be", "used", "with", "a", "variety", "of", "programming", "languages", "to", "plot", "data", ",", "including", "Perl", "(", "via", "the", "PDL", "and", "CPAN", "packages", ")", ",", "Python", "(", "via", ")", "."], "sentence-detokenized": "gnuplot can be used with a variety of programming languages to plot data, including Perl (via the PDL and CPAN packages), Python (via).", "token2charspan": [[0, 7], [8, 11], [12, 14], [15, 19], [20, 24], [25, 26], [27, 34], [35, 37], [38, 49], [50, 59], [60, 62], [63, 67], [68, 72], [72, 73], [74, 83], [84, 88], [89, 90], [90, 93], [94, 97], [98, 101], [102, 105], [106, 110], [111, 119], [119, 120], [120, 121], [122, 128], [129, 130], [130, 133], [133, 134], [134, 135]]}
{"doc_key": "ai-dev-196", "ner": [[3, 5, "product"], [19, 19, "conference"], [21, 21, "conference"], [35, 35, "conference"], [37, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 19, 3, 5, "topic", "", false, false], [21, 21, 3, 5, "topic", "", false, false], [35, 35, 3, 5, "topic", "", false, false], [37, 37, 3, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "field", "of", "spoken", "dialogue", "systems", "is", "quite", "large", "and", "includes", "research", "(", "presented", "at", "scientific", "conferences", "such", "as", "SIGdial", "and", "Interspeech", ")", "and", "the", "large", "industrial", "sector", "(", "with", "its", "own", "meetings", "such", "as", "SpeechTek", "and", "AVIOS", ")", "."], "sentence-detokenized": "The field of spoken dialogue systems is quite large and includes research (presented at scientific conferences such as SIGdial and Interspeech) and the large industrial sector (with its own meetings such as SpeechTek and AVIOS).", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 28], [29, 36], [37, 39], [40, 45], [46, 51], [52, 55], [56, 64], [65, 73], [74, 75], [75, 84], [85, 87], [88, 98], [99, 110], [111, 115], [116, 118], [119, 126], [127, 130], [131, 142], [142, 143], [144, 147], [148, 151], [152, 157], [158, 168], [169, 175], [176, 177], [177, 181], [182, 185], [186, 189], [190, 198], [199, 203], [204, 206], [207, 216], [217, 220], [221, 226], [226, 227], [227, 228]]}
{"doc_key": "ai-dev-197", "ner": [[0, 1, "field"], [7, 8, "task"], [11, 15, "task"], [16, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 0, 1, "part-of", "task_part_of_field", false, false], [11, 15, 0, 1, "part-of", "task_part_of_field", false, false], [16, 16, 0, 1, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Natural", "language", "processing", "challenges", "often", "relate", "to", "speech", "recognition", ",", "natural", "language", "understanding", "and", "natural", "language", "generation", "."], "sentence-detokenized": "Natural language processing challenges often relate to speech recognition, natural language understanding and natural language generation.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 38], [39, 44], [45, 51], [52, 54], [55, 61], [62, 73], [73, 74], [75, 82], [83, 91], [92, 105], [106, 109], [110, 117], [118, 126], [127, 137], [137, 138]]}
{"doc_key": "ai-dev-198", "ner": [[5, 5, "product"], [8, 10, "product"], [38, 39, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 8, 10, "part-of", "", false, false], [5, 5, 38, 39, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "such", "as", "Siri", "from", "the", "iOS", "operating", "system", ",", "operate", "on", "a", "similar", "pattern", "recognition", "technique", "to", "text", "-", "based", "systems", ",", "but", "in", "the", "case", "of", "the", "former", ",", "user", "input", "is", "done", "through", "speech", "recognition", "."], "sentence-detokenized": "These systems, such as Siri from the iOS operating system, operate on a similar pattern recognition technique to text-based systems, but in the case of the former, user input is done through speech recognition.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 22], [23, 27], [28, 32], [33, 36], [37, 40], [41, 50], [51, 57], [57, 58], [59, 66], [67, 69], [70, 71], [72, 79], [80, 87], [88, 99], [100, 109], [110, 112], [113, 117], [117, 118], [118, 123], [124, 131], [131, 132], [133, 136], [137, 139], [140, 143], [144, 148], [149, 151], [152, 155], [156, 162], [162, 163], [164, 168], [169, 174], [175, 177], [178, 182], [183, 190], [191, 197], [198, 209], [209, 210]]}
{"doc_key": "ai-dev-199", "ner": [[1, 3, "algorithm"], [16, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 3, 16, 17, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["More", "exotic", "fitness", "functions", "that", "explore", "the", "granularity", "of", "the", "model", "include", "the", "area", "under", "the", "ROC", "curve", "and", "the", "rank", "measure", "."], "sentence-detokenized": "More exotic fitness functions that explore the granularity of the model include the area under the ROC curve and the rank measure.", "token2charspan": [[0, 4], [5, 11], [12, 19], [20, 29], [30, 34], [35, 42], [43, 46], [47, 58], [59, 61], [62, 65], [66, 71], [72, 79], [80, 83], [84, 88], [89, 94], [95, 98], [99, 102], [103, 108], [109, 112], [113, 116], [117, 121], [122, 129], [129, 130]]}
{"doc_key": "ai-dev-200", "ner": [[2, 3, "product"], [7, 10, "researcher"], [21, 25, "organisation"], [27, 27, "organisation"], [37, 39, "product"]], "ner_mapping_to_source": [0, 1, 3, 4, 5], "relations": [[2, 3, 7, 10, "origin", "", false, false], [7, 10, 21, 25, "role", "", false, false], [27, 27, 21, 25, "named", "", false, false], [37, 39, 21, 25, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 3, 4], "sentence": ["The", "term", "Semantic", "Web", "was", "coined", "by", "Tim", "Berners", "-", "Lee", ",", "inventor", "of", "the", "World", "Wide", "Web", "and", "director", "of", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "which", "oversees", "the", "development", "of", "the", "proposed", "Semantic", "Web", "standards", "."], "sentence-detokenized": "The term Semantic Web was coined by Tim Berners-Lee, inventor of the World Wide Web and director of the World Wide Web Consortium (W3C), which oversees the development of the proposed Semantic Web standards.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 25], [26, 32], [33, 35], [36, 39], [40, 47], [47, 48], [48, 51], [51, 52], [53, 61], [62, 64], [65, 68], [69, 74], [75, 79], [80, 83], [84, 87], [88, 96], [97, 99], [100, 103], [104, 109], [110, 114], [115, 118], [119, 129], [130, 131], [131, 134], [134, 135], [135, 136], [137, 142], [143, 151], [152, 155], [156, 167], [168, 170], [171, 174], [175, 183], [184, 192], [193, 196], [197, 206], [206, 207]]}
{"doc_key": "ai-dev-201", "ner": [[0, 1, "task"], [5, 5, "task"], [12, 15, "product"], [17, 20, "product"], [22, 22, "product"], [25, 26, "product"], [33, 34, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 12, 15, "opposite", "", false, false], [0, 1, 17, 20, "opposite", "", false, false], [0, 1, 25, 26, "opposite", "", false, false], [0, 1, 33, 34, "part-of", "", false, false], [5, 5, 0, 1, "named", "", false, false], [22, 22, 17, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Machine", "translation", ",", "sometimes", "abbreviated", "MT", "(", "not", "to", "be", "confused", "with", "computer", "-", "aided", "translation", ",", "machine", "-", "assisted", "translation", "(", "MAHT", ")", "or", "interactive", "translation", ")", ",", "is", "a", "sub-discipline", "of", "computational", "linguistics", "that", "studies", "the", "use", "of", "software", "to", "translate", "text", "or", "speech", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Machine translation, sometimes abbreviated MT (not to be confused with computer-aided translation, machine-assisted translation (MAHT) or interactive translation), is a sub-discipline of computational linguistics that studies the use of software to translate text or speech from one language to another.", "token2charspan": [[0, 7], [8, 19], [19, 20], [21, 30], [31, 42], [43, 45], [46, 47], [47, 50], [51, 53], [54, 56], [57, 65], [66, 70], [71, 79], [79, 80], [80, 85], [86, 97], [97, 98], [99, 106], [106, 107], [107, 115], [116, 127], [128, 129], [129, 133], [133, 134], [135, 137], [138, 149], [150, 161], [161, 162], [162, 163], [164, 166], [167, 168], [169, 183], [184, 186], [187, 200], [201, 212], [213, 217], [218, 225], [226, 229], [230, 233], [234, 236], [237, 245], [246, 248], [249, 258], [259, 263], [264, 266], [267, 273], [274, 278], [279, 282], [283, 291], [292, 294], [295, 302], [302, 303]]}
{"doc_key": "ai-dev-202", "ner": [[1, 3, "product"], [8, 9, "university"], [13, 14, "researcher"], [16, 17, "researcher"], [38, 40, "location"], [42, 42, "location"], [46, 49, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 3, 13, 14, "artifact", "", false, false], [1, 3, 16, 17, "artifact", "", false, false], [13, 14, 8, 9, "physical", "", false, false], [13, 14, 8, 9, "role", "", false, false], [16, 17, 8, 9, "physical", "", false, false], [16, 17, 8, 9, "role", "", false, false], [38, 40, 42, 42, "physical", "", false, false], [46, 49, 38, 40, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Early", "interlingual", "MT", "systems", "were", "also", "built", "at", "Stanford", "in", "the", "1970s", "by", "Roger", "Schank", "and", "Yorick", "Wilks", ";", "the", "former", "became", "the", "basis", "of", "a", "commercial", "transfer", "system", "and", "the", "code", "for", "the", "latter", "is", "preserved", "at", "The", "Computer", "Museum", "in", "Boston", "as", "the", "first", "interlingual", "machine", "translation", "system", "."], "sentence-detokenized": "Early interlingual MT systems were also built at Stanford in the 1970s by Roger Schank and Yorick Wilks; the former became the basis of a commercial transfer system and the code for the latter is preserved at The Computer Museum in Boston as the first interlingual machine translation system.", "token2charspan": [[0, 5], [6, 18], [19, 21], [22, 29], [30, 34], [35, 39], [40, 45], [46, 48], [49, 57], [58, 60], [61, 64], [65, 70], [71, 73], [74, 79], [80, 86], [87, 90], [91, 97], [98, 103], [103, 104], [105, 108], [109, 115], [116, 122], [123, 126], [127, 132], [133, 135], [136, 137], [138, 148], [149, 157], [158, 164], [165, 168], [169, 172], [173, 177], [178, 181], [182, 185], [186, 192], [193, 195], [196, 205], [206, 208], [209, 212], [213, 221], [222, 228], [229, 231], [232, 238], [239, 241], [242, 245], [246, 251], [252, 264], [265, 272], [273, 284], [285, 291], [291, 292]]}
{"doc_key": "ai-dev-203", "ner": [[0, 1, "researcher"], [7, 11, "conference"], [13, 14, "conference"], [21, 25, "conference"], [28, 28, "conference"], [34, 37, "organisation"], [45, 45, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 7, 11, "role", "", false, false], [0, 1, 21, 25, "role", "", false, false], [0, 1, 34, 37, "role", "", false, false], [0, 1, 45, 45, "role", "", false, false], [13, 14, 7, 11, "named", "", false, false], [28, 28, 21, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sycara", "served", "as", "programme", "chair", "of", "the", "Second", "International", "Semantic", "Web", "Conference", "(", "ISWC", "2003", ")", ";", "general", "chair", "of", "the", "Second", "International", "Autonomous", "Agents", "Conference", "(", "Agents", "98", ")", ";", "chair", "of", "the", "Agents", "Conference", "Steering", "Committee", "(", "1999-2001", ")", ";", "chair", "of", "the", "AAAI", "Fellowship", "(", "1993-1999", ")", ";"], "sentence-detokenized": "Sycara served as programme chair of the Second International Semantic Web Conference (ISWC 2003); general chair of the Second International Autonomous Agents Conference (Agents 98); chair of the Agents Conference Steering Committee (1999-2001); chair of the AAAI Fellowship (1993-1999);", "token2charspan": [[0, 6], [7, 13], [14, 16], [17, 26], [27, 32], [33, 35], [36, 39], [40, 46], [47, 60], [61, 69], [70, 73], [74, 84], [85, 86], [86, 90], [91, 95], [95, 96], [96, 97], [98, 105], [106, 111], [112, 114], [115, 118], [119, 125], [126, 139], [140, 150], [151, 157], [158, 168], [169, 170], [170, 176], [177, 179], [179, 180], [180, 181], [182, 187], [188, 190], [191, 194], [195, 201], [202, 212], [213, 221], [222, 231], [232, 233], [233, 242], [242, 243], [243, 244], [245, 250], [251, 253], [254, 257], [258, 262], [263, 273], [274, 275], [275, 284], [284, 285], [285, 286]]}
{"doc_key": "ai-dev-204", "ner": [[11, 11, "conference"], [13, 16, "conference"], [18, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 16, 11, 11, "named", "", false, false], [18, 20, 11, 11, "part-of", "", false, false], [18, 20, 11, 11, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2016", ",", "she", "was", "selected", "as", "a", "recipient", "of", "the", "ACL", "(", "Association", "for", "Computational", "Linguistics", ")", "Lifetime", "Achievement", "Award", "."], "sentence-detokenized": "In 2016, she was selected as a recipient of the ACL (Association for Computational Linguistics) Lifetime Achievement Award.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 25], [26, 28], [29, 30], [31, 40], [41, 43], [44, 47], [48, 51], [52, 53], [53, 64], [65, 68], [69, 82], [83, 94], [94, 95], [96, 104], [105, 116], [117, 122], [122, 123]]}
{"doc_key": "ai-dev-205", "ner": [[0, 1, "researcher"], [3, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", ",", "Y", ".", "Bengio", ",", "P.", "Frasconi", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Sepp Hochreiter, Y. Bengio, P. Frasconi and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 15], [15, 16], [17, 18], [18, 19], [20, 26], [26, 27], [28, 30], [31, 39], [40, 43], [44, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-206", "ner": [[3, 3, "product"], [6, 7, "misc"], [9, 9, "programlang"], [19, 21, "product"], [35, 35, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 9, 9, "usage", "", false, false], [9, 9, 6, 7, "type-of", "", false, false], [9, 9, 19, 21, "related-to", "", false, false], [35, 35, 3, 3, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["For", "example", ",", "A.L.I.C.E.", "uses", "a", "markup", "language", "called", "AIML", ",", "which", "is", "specific", "to", "its", "function", "as", "a", "dialogue", "system", "and", "has", "since", "been", "adopted", "by", "various", "other", "developers", ",", "so", "-", "called", ",", "Alicebots", "."], "sentence-detokenized": "For example, A.L.I.C.E. uses a markup language called AIML, which is specific to its function as a dialogue system and has since been adopted by various other developers, so-called, Alicebots.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 23], [24, 28], [29, 30], [31, 37], [38, 46], [47, 53], [54, 58], [58, 59], [60, 65], [66, 68], [69, 77], [78, 80], [81, 84], [85, 93], [94, 96], [97, 98], [99, 107], [108, 114], [115, 118], [119, 122], [123, 128], [129, 133], [134, 141], [142, 144], [145, 152], [153, 158], [159, 169], [169, 170], [171, 173], [173, 174], [174, 180], [180, 181], [182, 191], [191, 192]]}
{"doc_key": "ai-dev-207", "ner": [[11, 17, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2000", ",", "she", "was", "elected", "as", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2000, she was elected as a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 24], [25, 27], [28, 29], [30, 36], [37, 39], [40, 43], [44, 55], [56, 59], [60, 63], [64, 75], [76, 78], [79, 89], [90, 102], [102, 103]]}
{"doc_key": "ai-dev-208", "ner": [[0, 2, "misc"], [4, 4, "misc"], [13, 15, "misc"], [24, 25, "algorithm"], [33, 34, "field"], [36, 37, "field"], [39, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 13, 15, "type-of", "", false, false], [0, 2, 33, 34, "related-to", "performs", true, false], [0, 2, 36, 37, "related-to", "performs", true, false], [0, 2, 39, 40, "related-to", "performs", true, false], [4, 4, 0, 2, "named", "", false, false], [24, 25, 13, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Learning", "classifier", "systems", "(", "LCS", ")", "are", "a", "family", "of", "rule", "-", "based", "machine", "learning", "algorithms", "that", "combine", "a", "discovery", "component", ",", "typically", "a", "genetic", "algorithm", ",", "with", "a", "learning", "component", "that", "performs", "supervised", "learning", ",", "reinforcement", "learning", "or", "unsupervised", "learning", "."], "sentence-detokenized": "Learning classifier systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, typically a genetic algorithm, with a learning component that performs supervised learning, reinforcement learning or unsupervised learning.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 29], [29, 32], [32, 33], [34, 37], [38, 39], [40, 46], [47, 49], [50, 54], [54, 55], [55, 60], [61, 68], [69, 77], [78, 88], [89, 93], [94, 101], [102, 103], [104, 113], [114, 123], [123, 124], [125, 134], [135, 136], [137, 144], [145, 154], [154, 155], [156, 160], [161, 162], [163, 171], [172, 181], [182, 186], [187, 195], [196, 206], [207, 215], [215, 216], [217, 230], [231, 239], [240, 242], [243, 255], [256, 264], [264, 265]]}
{"doc_key": "ai-dev-209", "ner": [[14, 27, "algorithm"], [18, 18, "algorithm"], [28, 28, "algorithm"], [30, 32, "misc"], [40, 43, "algorithm"], [50, 56, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 27, 28, 28, "origin", "", false, false], [14, 27, 30, 32, "usage", "", false, false], [18, 18, 14, 27, "named", "", false, false], [40, 43, 30, 32, "type-of", "", false, false], [40, 43, 50, 56, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "unknown", "parameters", "in", "each", "\u03b2subk", "/", "sub", "vector", "are", "usually", "jointly", "estimated", "using", "maximum", "a", "posteriori", "(", "MAP", ")", "estimation", ",", "which", "is", "an", "extension", "of", "maximum", "likelihood", "using", "regularisation", "of", "the", "weights", "to", "prevent", "pathological", "solutions", "(", "usually", "a", "quadratic", "regularisation", "function", "that", "is", "equivalent", "to", "placing", "the", "zero", "mean", "of", "the", "Gaussian", "prior", "distribution", "on", "the", "weights", ",", "but", "other", "distributions", "are", "also", "possible", ")", "."], "sentence-detokenized": "The unknown parameters in each \u03b2subk / sub vector are usually jointly estimated using maximum a posteriori (MAP) estimation, which is an extension of maximum likelihood using regularisation of the weights to prevent pathological solutions (usually a quadratic regularisation function that is equivalent to placing the zero mean of the Gaussian prior distribution on the weights, but other distributions are also possible).", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 25], [26, 30], [31, 36], [37, 38], [39, 42], [43, 49], [50, 53], [54, 61], [62, 69], [70, 79], [80, 85], [86, 93], [94, 95], [96, 106], [107, 108], [108, 111], [111, 112], [113, 123], [123, 124], [125, 130], [131, 133], [134, 136], [137, 146], [147, 149], [150, 157], [158, 168], [169, 174], [175, 189], [190, 192], [193, 196], [197, 204], [205, 207], [208, 215], [216, 228], [229, 238], [239, 240], [240, 247], [248, 249], [250, 259], [260, 274], [275, 283], [284, 288], [289, 291], [292, 302], [303, 305], [306, 313], [314, 317], [318, 322], [323, 327], [328, 330], [331, 334], [335, 343], [344, 349], [350, 362], [363, 365], [366, 369], [370, 377], [377, 378], [379, 382], [383, 388], [389, 402], [403, 406], [407, 411], [412, 420], [420, 421], [421, 422]]}
{"doc_key": "ai-dev-210", "ner": [[9, 10, "researcher"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 9, 10, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "hierarchical", "structure", "of", "words", "was", "explicitly", "mapped", "in", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "The hierarchical structure of words was explicitly mapped in George Miller's Wordnet.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 29], [30, 35], [36, 39], [40, 50], [51, 57], [58, 60], [61, 67], [68, 74], [74, 76], [77, 84], [84, 85]]}
{"doc_key": "ai-dev-211", "ner": [[7, 12, "conference"], [17, 26, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 26, 7, 12, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "illustration", "of", "their", "capabilities", "is", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", ";", "a", "benchmark", "in", "object", "classification", "and", "detection", ",", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "An illustration of their capabilities is the ImageNet Large Scale Visual Recognition Challenge; a benchmark in object classification and detection, with millions of images and hundreds of object classes.", "token2charspan": [[0, 2], [3, 15], [16, 18], [19, 24], [25, 37], [38, 40], [41, 44], [45, 53], [54, 59], [60, 65], [66, 72], [73, 84], [85, 94], [94, 95], [96, 97], [98, 107], [108, 110], [111, 117], [118, 132], [133, 136], [137, 146], [146, 147], [148, 152], [153, 161], [162, 164], [165, 171], [172, 175], [176, 184], [185, 187], [188, 194], [195, 202], [202, 203]]}
{"doc_key": "ai-dev-212", "ner": [[1, 2, "misc"], [25, 25, "misc"], [27, 30, "person"], [32, 32, "misc"], [37, 40, "person"], [43, 45, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[25, 25, 1, 2, "general-affiliation", "", false, false], [32, 32, 1, 2, "general-affiliation", "", false, false], [32, 32, 27, 30, "artifact", "", false, false], [43, 45, 1, 2, "general-affiliation", "", false, false], [43, 45, 37, 40, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "science", "fiction", ",", "female", "-", "looking", "robots", "are", "often", "produced", "for", "use", "as", "domestic", "servants", "and", "sex", "slaves", ",", "as", "seen", "in", "the", "film", "Westworld", ",", "Paul", "J", "McAuley", "'s", "novel", "Fairyland", "(", "1995", ")", "and", "Lester", "del", "Rey", "'s", "short", "story", "Helen", "O'", "Loy", "(", "1938", ")", ",", "and", "sometimes", "as", "warriors", ",", "assassins", "or", "workers", "."], "sentence-detokenized": "In science fiction, female-looking robots are often produced for use as domestic servants and sex slaves, as seen in the film Westworld, Paul J McAuley's novel Fairyland (1995) and Lester del Rey's short story Helen O'Loy (1938), and sometimes as warriors, assassins or workers.", "token2charspan": [[0, 2], [3, 10], [11, 18], [18, 19], [20, 26], [26, 27], [27, 34], [35, 41], [42, 45], [46, 51], [52, 60], [61, 64], [65, 68], [69, 71], [72, 80], [81, 89], [90, 93], [94, 97], [98, 104], [104, 105], [106, 108], [109, 113], [114, 116], [117, 120], [121, 125], [126, 135], [135, 136], [137, 141], [142, 143], [144, 151], [151, 153], [154, 159], [160, 169], [170, 171], [171, 175], [175, 176], [177, 180], [181, 187], [188, 191], [192, 195], [195, 197], [198, 203], [204, 209], [210, 215], [216, 218], [218, 221], [222, 223], [223, 227], [227, 228], [228, 229], [230, 233], [234, 243], [244, 246], [247, 255], [255, 256], [257, 266], [267, 269], [270, 277], [277, 278]]}
{"doc_key": "ai-dev-213", "ner": [[0, 1, "task"], [3, 4, "task"], [6, 7, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["answering", "questions", ",", "speech", "recognition", "and", "machine", "translation", "."], "sentence-detokenized": "answering questions, speech recognition and machine translation.", "token2charspan": [[0, 9], [10, 19], [19, 20], [21, 27], [28, 39], [40, 43], [44, 51], [52, 63], [63, 64]]}
{"doc_key": "ai-dev-214", "ner": [[5, 6, "researcher"], [9, 13, "organisation"], [15, 18, "location"], [20, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 9, 13, "role", "", false, false], [9, 13, 15, 18, "physical", "", false, false], [15, 18, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "his", "groundbreaking", "work", ",", "Harry", "Blum", "of", "the", "Air", "Force", "Cambridge", "Research", "Laboratories", "at", "Hanscom", "Air", "Force", "Base", ",", "Bedford", ",", "Massachusetts", ",", "defined", "a", "centre", "axis", "for", "calculating", "the", "skeleton", "of", "a", "shape", ",", "using", "an", "intuitive", "model", "of", "fire", "spread", "in", "a", "field", "of", "grass", "where", "the", "field", "has", "the", "form", "of", "a", "given", "shape", "."], "sentence-detokenized": "In his groundbreaking work, Harry Blum of the Air Force Cambridge Research Laboratories at Hanscom Air Force Base, Bedford, Massachusetts, defined a centre axis for calculating the skeleton of a shape, using an intuitive model of fire spread in a field of grass where the field has the form of a given shape.", "token2charspan": [[0, 2], [3, 6], [7, 21], [22, 26], [26, 27], [28, 33], [34, 38], [39, 41], [42, 45], [46, 49], [50, 55], [56, 65], [66, 74], [75, 87], [88, 90], [91, 98], [99, 102], [103, 108], [109, 113], [113, 114], [115, 122], [122, 123], [124, 137], [137, 138], [139, 146], [147, 148], [149, 155], [156, 160], [161, 164], [165, 176], [177, 180], [181, 189], [190, 192], [193, 194], [195, 200], [200, 201], [202, 207], [208, 210], [211, 220], [221, 226], [227, 229], [230, 234], [235, 241], [242, 244], [245, 246], [247, 252], [253, 255], [256, 261], [262, 267], [268, 271], [272, 277], [278, 281], [282, 285], [286, 290], [291, 293], [294, 295], [296, 301], [302, 307], [307, 308]]}
{"doc_key": "ai-dev-215", "ner": [[14, 14, "algorithm"], [16, 16, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 19, 20, "compare", "", false, false], [16, 16, 19, 20, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "unlike", "boosting", "algorithms", "that", "analytically", "minimise", "a", "convex", "loss", "function", "(", "e.g.", "AdaBoost", "and", "LogitBoost", ")", ",", "Brown", "Boost", "solves", "a", "system", "of", "two", "equations", "and", "two", "unknowns", "using", "standard", "numerical", "methods", "."], "sentence-detokenized": "However, unlike boosting algorithms that analytically minimise a convex loss function (e.g. AdaBoost and LogitBoost), BrownBoost solves a system of two equations and two unknowns using standard numerical methods.", "token2charspan": [[0, 7], [7, 8], [9, 15], [16, 24], [25, 35], [36, 40], [41, 53], [54, 62], [63, 64], [65, 71], [72, 76], [77, 85], [86, 87], [87, 91], [92, 100], [101, 104], [105, 115], [115, 116], [116, 117], [118, 123], [123, 128], [129, 135], [136, 137], [138, 144], [145, 147], [148, 151], [152, 161], [162, 165], [166, 169], [170, 178], [179, 184], [185, 193], [194, 203], [204, 211], [211, 212]]}
{"doc_key": "ai-dev-216", "ner": [[0, 0, "researcher"], [9, 11, "misc"], [15, 20, "conference"], [22, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 9, 11, "win-defeat", "", false, false], [0, 0, 15, 20, "role", "", false, false], [22, 22, 15, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Getoor", "has", "won", "multiple", "best", "paper", "awards", ",", "an", "NSF", "Career", "Award", "and", "is", "an", "Association", "for", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "Fellow", "."], "sentence-detokenized": "Getoor has won multiple best paper awards, an NSF Career Award and is an Association for Advancement of Artificial Intelligence (AAAI) Fellow.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 23], [24, 28], [29, 34], [35, 41], [41, 42], [43, 45], [46, 49], [50, 56], [57, 62], [63, 66], [67, 69], [70, 72], [73, 84], [85, 88], [89, 100], [101, 103], [104, 114], [115, 127], [128, 129], [129, 133], [133, 134], [135, 141], [141, 142]]}
{"doc_key": "ai-dev-217", "ner": [[0, 1, "misc"], [6, 10, "misc"], [11, 16, "misc"], [21, 25, "misc"], [30, 31, "misc"], [35, 39, "university"], [44, 52, "misc"], [57, 65, "misc"], [70, 74, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["ACM", "Fellow", "(", "2015", ")", "br", "Association", "for", "Computational", "Linguistics", "Fellow", "(", "2011", ")", "br", "AAAI", "Fellow", "(", "1994", ")", "br", "International", "Speech", "Communication", "Association", "Fellow", "(", "2011", ")", "br", "Honorary", "Doctorate", "(", "Hedersdoktor", ")", "KTH", "Royal", "Institute", "of", "Technology", "(", "2007", ")", "br", "Columbia", "Engineering", "School", "Alumni", "Association", "Distinguished", "Faculty", "Teaching", "award", "(", "2009", ")", "br", "IEEE", "James", "L.", "Flanagan", "Speech", "and", "Audio", "Processing", "Award", "(", "2011", ")", "br", "ISCA", "Medal", "for", "Scientific", "Achievement", "(", "2011", ")"], "sentence-detokenized": "ACM Fellow (2015) br Association for Computational Linguistics Fellow (2011) br AAAI Fellow (1994) br International Speech Communication Association Fellow (2011) br Honorary Doctorate (Hedersdoktor) KTH Royal Institute of Technology (2007) br Columbia Engineering School Alumni Association Distinguished Faculty Teaching award (2009) br IEEE James L. Flanagan Speech and Audio Processing Award (2011) br ISCA Medal for Scientific Achievement (2011)", "token2charspan": [[0, 3], [4, 10], [11, 12], [12, 16], [16, 17], [18, 20], [21, 32], [33, 36], [37, 50], [51, 62], [63, 69], [70, 71], [71, 75], [75, 76], [77, 79], [80, 84], [85, 91], [92, 93], [93, 97], [97, 98], [99, 101], [102, 115], [116, 122], [123, 136], [137, 148], [149, 155], [156, 157], [157, 161], [161, 162], [163, 165], [166, 174], [175, 184], [185, 186], [186, 198], [198, 199], [200, 203], [204, 209], [210, 219], [220, 222], [223, 233], [234, 235], [235, 239], [239, 240], [241, 243], [244, 252], [253, 264], [265, 271], [272, 278], [279, 290], [291, 304], [305, 312], [313, 321], [322, 327], [328, 329], [329, 333], [333, 334], [335, 337], [338, 342], [343, 348], [349, 351], [352, 360], [361, 367], [368, 371], [372, 377], [378, 388], [389, 394], [395, 396], [396, 400], [400, 401], [402, 404], [405, 409], [410, 415], [416, 419], [420, 430], [431, 442], [443, 444], [444, 448], [448, 449]]}
{"doc_key": "ai-dev-218", "ner": [[6, 6, "university"], [14, 16, "task"], [25, 31, "metrics"], [39, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[25, 31, 39, 41, "opposite", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["A", "frustrating", "result", "of", "the", "same", "Stanford", "study", "(", "and", "other", "attempts", "to", "improve", "name", "recognition", "translation", ")", "is", "that", "many", "times", "the", "decline", "in", "bilingual", "evaluation", "scores", "in", "terms", "of", "translation", "will", "be", "due", "to", "the", "inclusion", "of", "named", "entity", "translation", "methods", "."], "sentence-detokenized": "A frustrating result of the same Stanford study (and other attempts to improve name recognition translation) is that many times the decline in bilingual evaluation scores in terms of translation will be due to the inclusion of named entity translation methods.", "token2charspan": [[0, 1], [2, 13], [14, 20], [21, 23], [24, 27], [28, 32], [33, 41], [42, 47], [48, 49], [49, 52], [53, 58], [59, 67], [68, 70], [71, 78], [79, 83], [84, 95], [96, 107], [107, 108], [109, 111], [112, 116], [117, 121], [122, 127], [128, 131], [132, 139], [140, 142], [143, 152], [153, 163], [164, 170], [171, 173], [174, 179], [180, 182], [183, 194], [195, 199], [200, 202], [203, 206], [207, 209], [210, 213], [214, 223], [224, 226], [227, 232], [233, 239], [240, 251], [252, 259], [259, 260]]}
{"doc_key": "ai-dev-219", "ner": [[0, 0, "organisation"], [12, 14, "organisation"], [16, 20, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 12, 14, "role", "works_with", false, false], [0, 0, 16, 20, "role", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Medtronic", "is", "using", "the", "PM", "data", "collected", "and", "working", "with", "researchers", "at", "Johns", "Hopkins", "Hospital", "and", "Washington", "University", "School", "of", "Medicine", "to", "help", "answer", "specific", "questions", "about", "heart", "disease", ",", "such", "as", "whether", "weak", "hearts", "cause", "arrhythmias", "or", "vice", "versa", "."], "sentence-detokenized": "Medtronic is using the PM data collected and working with researchers at Johns Hopkins Hospital and Washington University School of Medicine to help answer specific questions about heart disease, such as whether weak hearts cause arrhythmias or vice versa.", "token2charspan": [[0, 9], [10, 12], [13, 18], [19, 22], [23, 25], [26, 30], [31, 40], [41, 44], [45, 52], [53, 57], [58, 69], [70, 72], [73, 78], [79, 86], [87, 95], [96, 99], [100, 110], [111, 121], [122, 128], [129, 131], [132, 140], [141, 143], [144, 148], [149, 155], [156, 164], [165, 174], [175, 180], [181, 186], [187, 194], [194, 195], [196, 200], [201, 203], [204, 211], [212, 216], [217, 223], [224, 229], [230, 241], [242, 244], [245, 249], [250, 255], [255, 256]]}
{"doc_key": "ai-dev-220", "ner": [[4, 5, "organisation"], [9, 9, "misc"], [11, 12, "person"], [14, 15, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 4, 5, "artifact", "made_by_studio", false, false], [11, 12, 9, 9, "role", "", false, false], [14, 15, 9, 9, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["It", "was", "followed", "by", "Paramount", "'s", "first", "film", ",", "Sangaree", "with", "Fernando", "Lamas", "and", "Arlene", "Dahl", "."], "sentence-detokenized": "It was followed by Paramount's first film, Sangaree with Fernando Lamas and Arlene Dahl.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 18], [19, 28], [28, 30], [31, 36], [37, 41], [41, 42], [43, 51], [52, 56], [57, 65], [66, 71], [72, 75], [76, 82], [83, 87], [87, 88]]}
{"doc_key": "ai-dev-221", "ner": [[0, 0, "programlang"], [8, 10, "researcher"], [12, 13, "researcher"], [17, 18, "organisation"], [20, 21, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 10, "origin", "", false, false], [0, 0, 12, 13, "origin", "", false, false], [8, 10, 17, 18, "physical", "", false, false], [8, 10, 17, 18, "role", "", false, false], [12, 13, 20, 21, "physical", "", false, false], [12, 13, 20, 21, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["KRL", "is", "a", "knowledge", "representation", "language", "developed", "by", "Daniel", "G.", "Bobrow", "and", "Terry", "Winograd", "while", "working", "at", "Xerox", "PARC", "and", "Stanford", "University", ",", "respectively", "."], "sentence-detokenized": "KRL is a knowledge representation language developed by Daniel G. Bobrow and Terry Winograd while working at Xerox PARC and Stanford University, respectively.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 18], [19, 33], [34, 42], [43, 52], [53, 55], [56, 62], [63, 65], [66, 72], [73, 76], [77, 82], [83, 91], [92, 97], [98, 105], [106, 108], [109, 114], [115, 119], [120, 123], [124, 132], [133, 143], [143, 144], [145, 157], [157, 158]]}
{"doc_key": "ai-dev-222", "ner": [[3, 10, "conference"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 24, "researcher"], [32, 33, "task"], [35, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 10, 32, 33, "topic", "", true, false], [12, 13, 3, 10, "physical", "", false, false], [12, 13, 3, 10, "role", "", false, false], [12, 13, 3, 10, "temporal", "", false, false], [15, 16, 3, 10, "physical", "", false, false], [15, 16, 3, 10, "role", "", false, false], [15, 16, 3, 10, "temporal", "", false, false], [18, 19, 3, 10, "physical", "", false, false], [18, 19, 3, 10, "role", "", false, false], [18, 19, 3, 10, "temporal", "", false, false], [21, 24, 3, 10, "physical", "", false, false], [21, 24, 3, 10, "role", "", false, false], [21, 24, 3, 10, "temporal", "", false, false], [32, 33, 35, 37, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["At", "the", "2006", "IEEE", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "Qiang", "Zhu", ",", "Shai", "Avidan", ",", "Mei-Chen", "Yeh", "and", "Kwang", "-", "Ting", "Cheng", "presented", "an", "algorithm", "to", "significantly", "speed", "up", "human", "detection", "using", "HOG", "descriptor", "methods", "."], "sentence-detokenized": "At the 2006 IEEE Conference on Computer Vision and Pattern Recognition, Qiang Zhu, Shai Avidan, Mei-Chen Yeh and Kwang-Ting Cheng presented an algorithm to significantly speed up human detection using HOG descriptor methods.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 27], [28, 30], [31, 39], [40, 46], [47, 50], [51, 58], [59, 70], [70, 71], [72, 77], [78, 81], [81, 82], [83, 87], [88, 94], [94, 95], [96, 104], [105, 108], [109, 112], [113, 118], [118, 119], [119, 123], [124, 129], [130, 139], [140, 142], [143, 152], [153, 155], [156, 169], [170, 175], [176, 178], [179, 184], [185, 194], [195, 200], [201, 204], [205, 215], [216, 223], [223, 224]]}
{"doc_key": "ai-dev-223", "ner": [[0, 0, "researcher"], [6, 6, "conference"], [9, 11, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 6, "role", "", false, false], [0, 0, 9, 11, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hayes", "is", "a", "member", "of", "the", "AAAI", "and", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Hayes is a member of the AAAI and the Cognitive Science Society.", "token2charspan": [[0, 5], [6, 8], [9, 10], [11, 17], [18, 20], [21, 24], [25, 29], [30, 33], [34, 37], [38, 47], [48, 55], [56, 63], [63, 64]]}
{"doc_key": "ai-dev-224", "ner": [[0, 1, "misc"], [5, 5, "field"], [7, 8, "field"], [10, 11, "field"], [13, 13, "field"], [15, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 24, "field"], [26, 26, "field"], [29, 29, "field"], [31, 31, "field"], [39, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[0, 1, 5, 5, "part-of", "", false, false], [0, 1, 5, 5, "usage", "", false, false], [0, 1, 7, 8, "part-of", "", false, false], [0, 1, 7, 8, "usage", "", false, false], [0, 1, 10, 11, "part-of", "", false, false], [0, 1, 10, 11, "usage", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [0, 1, 13, 13, "usage", "", false, false], [0, 1, 15, 16, "part-of", "", false, false], [0, 1, 15, 16, "usage", "", false, false], [0, 1, 18, 19, "part-of", "", false, false], [0, 1, 18, 19, "usage", "", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 21, 22, "usage", "", false, false], [0, 1, 24, 24, "part-of", "", false, false], [0, 1, 24, 24, "usage", "", false, false], [0, 1, 26, 26, "part-of", "", false, false], [0, 1, 26, 26, "usage", "", false, false], [0, 1, 29, 29, "part-of", "", false, false], [0, 1, 29, 29, "usage", "", false, false], [0, 1, 31, 31, "part-of", "", false, false], [0, 1, 31, 31, "usage", "", false, false], [0, 1, 39, 40, "part-of", "", false, false], [0, 1, 39, 40, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "sentence": ["Time", "series", "are", "used", "in", "statistics", ",", "signal", "processing", ",", "pattern", "recognition", ",", "econometrics", ",", "mathematical", "finance", ",", "weather", "forecasting", ",", "earthquake", "prediction", ",", "electroencephalography", ",", "control", "engineering", ",", "astronomy", ",", "communications", "engineering", "and", "pretty", "much", "every", "field", "of", "applied", "science", "and", "engineering", "that", "involves", "time", "measurements", "."], "sentence-detokenized": "Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, earthquake prediction, electroencephalography, control engineering, astronomy, communications engineering and pretty much every field of applied science and engineering that involves time measurements.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 23], [24, 34], [34, 35], [36, 42], [43, 53], [53, 54], [55, 62], [63, 74], [74, 75], [76, 88], [88, 89], [90, 102], [103, 110], [110, 111], [112, 119], [120, 131], [131, 132], [133, 143], [144, 154], [154, 155], [156, 178], [178, 179], [180, 187], [188, 199], [199, 200], [201, 210], [210, 211], [212, 226], [227, 238], [239, 242], [243, 249], [250, 254], [255, 260], [261, 266], [267, 269], [270, 277], [278, 285], [286, 289], [290, 301], [302, 306], [307, 315], [316, 320], [321, 333], [333, 334]]}
{"doc_key": "ai-dev-225", "ner": [[14, 15, "metrics"], [38, 40, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "principle", ",", "exact", "recovery", "can", "be", "solved", "within", "it", "s", "feasible", "range", "using", "maximum", "likelihood", ",", "but", "it", "comes", "down", "to", "solving", "a", "limited", "or", "regular", "cutting", "problem", ",", "such", "as", "minimum", "bisection", ",", "that", "is", "typically", "NP", "-", "complete", "."], "sentence-detokenized": "In principle, exact recovery can be solved within its feasible range using maximum likelihood, but it comes down to solving a limited or regular cutting problem, such as minimum bisection, that is typically NP-complete.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 19], [20, 28], [29, 32], [33, 35], [36, 42], [43, 49], [50, 52], [52, 53], [54, 62], [63, 68], [69, 74], [75, 82], [83, 93], [93, 94], [95, 98], [99, 101], [102, 107], [108, 112], [113, 115], [116, 123], [124, 125], [126, 133], [134, 136], [137, 144], [145, 152], [153, 160], [160, 161], [162, 166], [167, 169], [170, 177], [178, 187], [187, 188], [189, 193], [194, 196], [197, 206], [207, 209], [209, 210], [210, 218], [218, 219]]}
{"doc_key": "ai-dev-226", "ner": [[5, 6, "task"], [13, 13, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 13, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["in", "it", "s", "work", "to", "detect", "pedestrians", ",", "which", "was", "first", "described", "on", "BMVC", "in", "2009", "."], "sentence-detokenized": "in its work to detect pedestrians, which was first described on BMVC in 2009.", "token2charspan": [[0, 2], [3, 5], [5, 6], [7, 11], [12, 14], [15, 21], [22, 33], [33, 34], [35, 40], [41, 44], [45, 50], [51, 60], [61, 63], [64, 68], [69, 71], [72, 76], [76, 77]]}
{"doc_key": "ai-dev-227", "ner": [[5, 8, "conference"], [10, 10, "researcher"], [12, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 5, 8, "physical", "", false, false], [10, 10, 5, 8, "role", "", false, false], [10, 10, 12, 20, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2007", ",", "at", "the", "International", "Computer", "Vision", "Conference", ",", "Terzopoulos", "received", "the", "inaugural", "IEEE", "PAMI", "Computer", "Vision", "Distinguished", "Researcher", "Award", "for", "his", "pioneering", "and", "sustained", "research", "on", "deformable", "models", "and", "their", "applications", "."], "sentence-detokenized": "In 2007, at the International Computer Vision Conference, Terzopoulos received the inaugural IEEE PAMI Computer Vision Distinguished Researcher Award for his pioneering and sustained research on deformable models and their applications.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 29], [30, 38], [39, 45], [46, 56], [56, 57], [58, 69], [70, 78], [79, 82], [83, 92], [93, 97], [98, 102], [103, 111], [112, 118], [119, 132], [133, 143], [144, 149], [150, 153], [154, 157], [158, 168], [169, 172], [173, 182], [183, 191], [192, 194], [195, 205], [206, 212], [213, 216], [217, 222], [223, 235], [235, 236]]}
{"doc_key": "ai-dev-228", "ner": [[0, 1, "task"], [4, 4, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 4, 4, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cluster", "analysis", "or", "cluster", "analysis", "involves", "assigning", "data", "points", "to", "clusters", "in", "such", "a", "way", "that", "elements", "in", "the", "same", "cluster", "are", "as", "similar", "as", "possible", ",", "while", "elements", "belonging", "to", "different", "clusters", "are", "as", "dissimilar", "as", "possible", "."], "sentence-detokenized": "Cluster analysis or cluster analysis involves assigning data points to clusters in such a way that elements in the same cluster are as similar as possible, while elements belonging to different clusters are as dissimilar as possible.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 36], [37, 45], [46, 55], [56, 60], [61, 67], [68, 70], [71, 79], [80, 82], [83, 87], [88, 89], [90, 93], [94, 98], [99, 107], [108, 110], [111, 114], [115, 119], [120, 127], [128, 131], [132, 134], [135, 142], [143, 145], [146, 154], [154, 155], [156, 161], [162, 170], [171, 180], [181, 183], [184, 193], [194, 202], [203, 206], [207, 209], [210, 220], [221, 223], [224, 232], [232, 233]]}
{"doc_key": "ai-dev-229", "ner": [[15, 15, "field"], [17, 18, "task"], [20, 23, "field"], [24, 25, "field"], [27, 28, "field"], [31, 32, "field"], [35, 36, "task"], [38, 38, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8], "relations": [[17, 18, 15, 15, "part-of", "task_part_of_field", false, false], [24, 25, 20, 23, "part-of", "", false, false], [31, 32, 27, 28, "part-of", "", false, false], [35, 36, 31, 32, "part-of", "", false, false], [38, 38, 31, 32, "part-of", "", false, false]], "relations_mapping_to_source": [3, 4, 5, 6, 7], "sentence": ["(", "2005", ")", "we", "can", "distinguish", "three", "different", "perspectives", "of", "text", "mining", ",", "namely", "text", "mining", "as", "information", "extraction", ",", "text", "mining", "as", "text", "data", "mining", "and", "text", "mining", "as", "a", "Data", "mining", "process", "(", "Knowledge", "Discovery", "in", "Databases", ")", ".", "Hotho", ",", "A.", ",", "N\u00fcrnberger", ",", "A.", "and", "Paa\u00df", ",", "G.", "(", "2005", ")", "."], "sentence-detokenized": "(2005) we can distinguish three different perspectives of text mining, namely text mining as information extraction, text mining as text data mining and text mining as a Data mining process (Knowledge Discovery in Databases).Hotho, A., N\u00fcrnberger, A. and Paa\u00df, G. (2005).", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 9], [10, 13], [14, 25], [26, 31], [32, 41], [42, 54], [55, 57], [58, 62], [63, 69], [69, 70], [71, 77], [78, 82], [83, 89], [90, 92], [93, 104], [105, 115], [115, 116], [117, 121], [122, 128], [129, 131], [132, 136], [137, 141], [142, 148], [149, 152], [153, 157], [158, 164], [165, 167], [168, 169], [170, 174], [175, 181], [182, 189], [190, 191], [191, 200], [201, 210], [211, 213], [214, 223], [223, 224], [224, 225], [225, 230], [230, 231], [232, 234], [234, 235], [236, 246], [246, 247], [248, 250], [251, 254], [255, 259], [259, 260], [261, 263], [264, 265], [265, 269], [269, 270], [270, 271]]}
{"doc_key": "ai-dev-230", "ner": [[0, 2, "product"], [14, 19, "location"], [21, 21, "location"], [23, 23, "location"], [33, 35, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 14, 19, "related-to", "developed_for", false, false], [14, 19, 21, 21, "physical", "", false, false], [21, 21, 23, 23, "physical", "", false, false], [33, 35, 0, 2, "role", "buys", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Rancho", "arm", "was", "developed", "as", "a", "robotic", "arm", "to", "assist", "disabled", "patients", "at", "Rancho", "Los", "Amigos", "National", "Rehabilitation", "Centre", "in", "Downey", ",", "California", ";", "this", "computer", "-", "controlled", "arm", "was", "purchased", "by", "Stanford", "University", "in", "1963", "."], "sentence-detokenized": "The Rancho arm was developed as a robotic arm to assist disabled patients at Rancho Los Amigos National Rehabilitation Centre in Downey, California; this computer-controlled arm was purchased by Stanford University in 1963.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 18], [19, 28], [29, 31], [32, 33], [34, 41], [42, 45], [46, 48], [49, 55], [56, 64], [65, 73], [74, 76], [77, 83], [84, 87], [88, 94], [95, 103], [104, 118], [119, 125], [126, 128], [129, 135], [135, 136], [137, 147], [147, 148], [149, 153], [154, 162], [162, 163], [163, 173], [174, 177], [178, 181], [182, 191], [192, 194], [195, 203], [204, 214], [215, 217], [218, 222], [222, 223]]}
{"doc_key": "ai-dev-231", "ner": [[1, 1, "university"], [3, 3, "researcher"], [9, 12, "organisation"], [20, 22, "organisation"], [26, 27, "researcher"], [29, 31, "researcher"], [44, 44, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 1, 1, "physical", "", false, false], [3, 3, 1, 1, "role", "", false, false], [3, 3, 9, 12, "role", "founder", false, false], [3, 3, 20, 22, "role", "founder", false, false], [20, 22, 44, 44, "physical", "", false, false], [26, 27, 20, 22, "role", "founder", false, false], [29, 31, 20, 22, "role", "founder", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["At", "UCSD", ",", "Norman", "was", "a", "founder", "of", "the", "Institute", "for", "Cognitive", "Science", "and", "one", "of", "the", "organisers", "of", "the", "Cognitive", "Science", "Society", "(", "along", "with", "Roger", "Schank", ",", "Allan", "M.", "Collins", "and", "others", ")", ",", "which", "held", "it", "s", "first", "meeting", "on", "the", "UCSD", "campus", "in", "1979", "."], "sentence-detokenized": "At UCSD, Norman was a founder of the Institute for Cognitive Science and one of the organisers of the Cognitive Science Society (along with Roger Schank, Allan M. Collins and others), which held its first meeting on the UCSD campus in 1979.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 21], [22, 29], [30, 32], [33, 36], [37, 46], [47, 50], [51, 60], [61, 68], [69, 72], [73, 76], [77, 79], [80, 83], [84, 94], [95, 97], [98, 101], [102, 111], [112, 119], [120, 127], [128, 129], [129, 134], [135, 139], [140, 145], [146, 152], [152, 153], [154, 159], [160, 162], [163, 170], [171, 174], [175, 181], [181, 182], [182, 183], [184, 189], [190, 194], [195, 197], [197, 198], [199, 204], [205, 212], [213, 215], [216, 219], [220, 224], [225, 231], [232, 234], [235, 239], [239, 240]]}
{"doc_key": "ai-dev-232", "ner": [[6, 7, "product"], [9, 10, "product"], [12, 13, "product"], [17, 18, "product"], [21, 22, "product"], [24, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[21, 22, 17, 18, "type-of", "", false, false], [24, 29, 17, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "common", "robot", "configurations", "are", "articulated", "robots", ",", "SCARA", "robots", ",", "delta", "robots", "and", "robots", "with", "Cartesian", "coordinates", ",", "(", "gantry", "robots", "or", "x", "-", "y", "-", "z", "robots", ")", "."], "sentence-detokenized": "The most common robot configurations are articulated robots, SCARA robots, delta robots and robots with Cartesian coordinates, (gantry robots or x-y-z robots).", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 21], [22, 36], [37, 40], [41, 52], [53, 59], [59, 60], [61, 66], [67, 73], [73, 74], [75, 80], [81, 87], [88, 91], [92, 98], [99, 103], [104, 113], [114, 125], [125, 126], [127, 128], [128, 134], [135, 141], [142, 144], [145, 146], [146, 147], [147, 148], [148, 149], [149, 150], [151, 157], [157, 158], [158, 159]]}
{"doc_key": "ai-dev-233", "ner": [[8, 8, "programlang"], [9, 10, "misc"], [15, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 8, 8, "part-of", "", false, false], [15, 15, 9, 10, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Alternatively", ",", "it", "can", "be", "used", "directly", "with", "Perl", "Module", "TM", "(", "which", "also", "supports", "LTM", ")", "."], "sentence-detokenized": "Alternatively, it can be used directly with Perl Module TM (which also supports LTM).", "token2charspan": [[0, 13], [13, 14], [15, 17], [18, 21], [22, 24], [25, 29], [30, 38], [39, 43], [44, 48], [49, 55], [56, 58], [59, 60], [60, 65], [66, 70], [71, 79], [80, 83], [83, 84], [84, 85]]}
{"doc_key": "ai-dev-234", "ner": [[8, 10, "country"], [11, 12, "organisation"], [20, 20, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 8, 10, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "won", "by", "a", "team", "from", "the", "United", "States", "from", "Newton", "Labs", ",", "and", "the", "competition", "was", "shown", "on", "CNN", "."], "sentence-detokenized": "It was won by a team from the United States from Newton Labs, and the competition was shown on CNN.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 13], [14, 15], [16, 20], [21, 25], [26, 29], [30, 36], [37, 43], [44, 48], [49, 55], [56, 60], [60, 61], [62, 65], [66, 69], [70, 81], [82, 85], [86, 91], [92, 94], [95, 98], [98, 99]]}
{"doc_key": "ai-dev-235", "ner": [[0, 3, "misc"], [10, 12, "person"], [14, 15, "person"], [17, 22, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 12, 0, 3, "role", "directs", false, false], [14, 15, 0, 3, "role", "acts_in", false, false], [17, 22, 0, 3, "role", "acts_in", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Butler", "in", "Love", ",", "a", "short", "film", "directed", "by", "David", "Arquette", "and", "starring", "Elizabeth", "Berkley", "and", "Thomas", "Jane", ",", "was", "released", "on", "23", "June", "2008", "."], "sentence-detokenized": "The Butler in Love, a short film directed by David Arquette and starring Elizabeth Berkley and Thomas Jane, was released on 23 June 2008.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 18], [18, 19], [20, 21], [22, 27], [28, 32], [33, 41], [42, 44], [45, 50], [51, 59], [60, 63], [64, 72], [73, 82], [83, 90], [91, 94], [95, 101], [102, 106], [106, 107], [108, 111], [112, 120], [121, 123], [124, 126], [127, 131], [132, 136], [136, 137]]}
{"doc_key": "ai-dev-236", "ner": [[0, 0, "product"], [9, 10, "field"], [17, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 17, 17, "general-affiliation", "", false, false], [9, 10, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "for", "example", ",", "is", "a", "resource", "containing", "a", "taxonomy", "whose", "elements", "are", "the", "meanings", "of", "English", "words", "."], "sentence-detokenized": "WordNet, for example, is a resource containing a taxonomy whose elements are the meanings of English words.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 20], [20, 21], [22, 24], [25, 26], [27, 35], [36, 46], [47, 48], [49, 57], [58, 63], [64, 72], [73, 76], [77, 80], [81, 89], [90, 92], [93, 100], [101, 106], [106, 107]]}
{"doc_key": "ai-dev-237", "ner": [[1, 3, "product"], [7, 7, "product"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 1, 3, "type-of", "", false, false], [9, 9, 1, 3, "type-of", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["Existing", "humanoid", "robot", "systems", ",", "such", "as", "ASIMO", "and", "QRIO", ",", "use", "multiple", "motors", "to", "achieve", "locomotion", "."], "sentence-detokenized": "Existing humanoid robot systems, such as ASIMO and QRIO, use multiple motors to achieve locomotion.", "token2charspan": [[0, 8], [9, 17], [18, 23], [24, 31], [31, 32], [33, 37], [38, 40], [41, 46], [47, 50], [51, 55], [55, 56], [57, 60], [61, 69], [70, 76], [77, 79], [80, 87], [88, 98], [98, 99]]}
{"doc_key": "ai-dev-238", "ner": [[0, 0, "metrics"], [8, 9, "metrics"], [11, 12, "metrics"], [14, 18, "misc"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 9, 0, 0, "part-of", "", false, false], [11, 12, 0, 0, "part-of", "", false, false], [14, 18, 0, 0, "part-of", "", false, false], [20, 20, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LEPOR", "was", "designed", "with", "factors", "such", "as", "enhanced", "length", "penalty", ",", "precision", "penalty", ",", "n-", "gram", "word", "order", "penalty", "and", "recall", "."], "sentence-detokenized": "LEPOR was designed with factors such as enhanced length penalty, precision penalty, n-gram word order penalty and recall.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 23], [24, 31], [32, 36], [37, 39], [40, 48], [49, 55], [56, 63], [63, 64], [65, 74], [75, 82], [82, 83], [84, 86], [86, 90], [91, 95], [96, 101], [102, 109], [110, 113], [114, 120], [120, 121]]}
{"doc_key": "ai-dev-239", "ner": [[4, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "based", "on", "the", "Bilingual", "evaluation", "understudy", "metric", ",", "but", "with", "some", "modifications", "."], "sentence-detokenized": "It is based on the Bilingual evaluation understudy metric, but with some modifications.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 14], [15, 18], [19, 28], [29, 39], [40, 50], [51, 57], [57, 58], [59, 62], [63, 67], [68, 72], [73, 86], [86, 87]]}
{"doc_key": "ai-dev-240", "ner": [[6, 6, "product"], [8, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "implementation", "in", "MATLAB", "/", "Octave", ":"], "sentence-detokenized": "This is an example implementation in MATLAB / Octave:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 33], [34, 36], [37, 43], [44, 45], [46, 52], [52, 53]]}
{"doc_key": "ai-dev-241", "ner": [[13, 13, "programlang"], [15, 15, "programlang"], [17, 17, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "has", "been", "designed", "to", "be", "used", "by", "many", "computer", "languages", ",", "including", "Python", ",", "Ruby", "and", "Scheme", "."], "sentence-detokenized": "It has been designed to be used by many computer languages, including Python, Ruby and Scheme.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 20], [21, 23], [24, 26], [27, 31], [32, 34], [35, 39], [40, 48], [49, 58], [58, 59], [60, 69], [70, 76], [76, 77], [78, 82], [83, 86], [87, 93], [93, 94]]}
{"doc_key": "ai-dev-242", "ner": [[0, 0, "researcher"], [7, 7, "organisation"], [14, 14, "conference"], [19, 20, "academicjournal"], [25, 27, "organisation"], [32, 36, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 7, 7, "role", "", false, false], [0, 0, 14, 14, "role", "", false, false], [0, 0, 19, 20, "role", "", false, false], [0, 0, 25, 27, "role", "", false, false], [0, 0, 32, 36, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hayes", "has", "served", "as", "secretary", "of", "the", "AISB", ",", "chairman", "and", "trustee", "of", "the", "IJCAI", ",", "associate", "editor", "of", "Artificial", "Intelligence", ",", "governor", "of", "the", "Cognitive", "Science", "Society", "and", "president", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "."], "sentence-detokenized": "Hayes has served as secretary of the AISB, chairman and trustee of the IJCAI, associate editor of Artificial Intelligence, governor of the Cognitive Science Society and president of the American Association for Artificial Intelligence.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 32], [33, 36], [37, 41], [41, 42], [43, 51], [52, 55], [56, 63], [64, 66], [67, 70], [71, 76], [76, 77], [78, 87], [88, 94], [95, 97], [98, 108], [109, 121], [121, 122], [123, 131], [132, 134], [135, 138], [139, 148], [149, 156], [157, 164], [165, 168], [169, 178], [179, 181], [182, 185], [186, 194], [195, 206], [207, 210], [211, 221], [222, 234], [234, 235]]}
{"doc_key": "ai-dev-243", "ner": [[4, 18, "misc"], [16, 16, "misc"], [23, 24, "person"], [29, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 24, 4, 18, "role", "directed_by", false, false], [23, 24, 16, 16, "role", "directed_by", false, false], [23, 24, 29, 33, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "of", "them", ",", "Now", "is", "the", "Time", "(", "to", "Put", "On", "Your", "Glasses", ")", "and", "Around", "is", "Around", ",", "were", "directed", "by", "Norman", "McLaren", "in", "1951", "for", "the", "National", "Film", "Board", "of", "Canada", "."], "sentence-detokenized": "Two of them, Now is the Time (to Put On Your Glasses) and Around is Around, were directed by Norman McLaren in 1951 for the National Film Board of Canada.", "token2charspan": [[0, 3], [4, 6], [7, 11], [11, 12], [13, 16], [17, 19], [20, 23], [24, 28], [29, 30], [30, 32], [33, 36], [37, 39], [40, 44], [45, 52], [52, 53], [54, 57], [58, 64], [65, 67], [68, 74], [74, 75], [76, 80], [81, 89], [90, 92], [93, 99], [100, 107], [108, 110], [111, 115], [116, 119], [120, 123], [124, 132], [133, 137], [138, 143], [144, 146], [147, 153], [153, 154]]}
{"doc_key": "ai-dev-244", "ner": [[0, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "recommendation", "system", "aims", "to", "predict", "the", "preferences", "for", "a", "given", "item", "of", "the", "target", "user", "."], "sentence-detokenized": "The recommendation system aims to predict the preferences for a given item of the target user.", "token2charspan": [[0, 3], [4, 18], [19, 25], [26, 30], [31, 33], [34, 41], [42, 45], [46, 57], [58, 61], [62, 63], [64, 69], [70, 74], [75, 77], [78, 81], [82, 88], [89, 93], [93, 94]]}
{"doc_key": "ai-dev-245", "ner": [[0, 0, "algorithm"], [4, 4, "field"], [6, 6, "field"], [8, 9, "field"], [11, 18, "field"], [15, 15, "field"], [17, 17, "field"], [20, 20, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 4, "part-of", "", true, false], [0, 0, 6, 6, "part-of", "", true, false], [0, 0, 8, 9, "part-of", "", true, false], [0, 0, 11, 18, "part-of", "", true, false], [0, 0, 15, 15, "part-of", "", true, false], [0, 0, 17, 17, "part-of", "", true, false], [0, 0, 20, 20, "part-of", "", true, false], [0, 0, 22, 23, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Convolution", "has", "applications", "including", "probability", ",", "statistics", ",", "computer", "vision", ",", "natural", "language", "processing", ",", "image", "and", "signal", "processing", ",", "engineering", "and", "differential", "equations", "."], "sentence-detokenized": "Convolution has applications including probability, statistics, computer vision, natural language processing, image and signal processing, engineering and differential equations.", "token2charspan": [[0, 11], [12, 15], [16, 28], [29, 38], [39, 50], [50, 51], [52, 62], [62, 63], [64, 72], [73, 79], [79, 80], [81, 88], [89, 97], [98, 108], [108, 109], [110, 115], [116, 119], [120, 126], [127, 137], [137, 138], [139, 150], [151, 154], [155, 167], [168, 177], [177, 178]]}
{"doc_key": "ai-dev-246", "ner": [[0, 0, "field"], [3, 5, "task"], [7, 8, "task"], [10, 10, "task"], [11, 11, "task"], [12, 12, "task"], [14, 17, "task"], [18, 18, "task"], [20, 23, "task"], [27, 27, "task"], [29, 29, "field"], [31, 31, "field"], [33, 35, "field"], [37, 37, "field"], [39, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15], "relations": [[0, 0, 3, 5, "part-of", "", true, false], [0, 0, 7, 8, "part-of", "", true, false], [0, 0, 10, 10, "part-of", "", true, false], [0, 0, 11, 11, "part-of", "", true, false], [0, 0, 12, 12, "part-of", "", true, false], [0, 0, 14, 17, "part-of", "", true, false], [0, 0, 18, 18, "part-of", "", true, false], [0, 0, 20, 23, "part-of", "", true, false], [0, 0, 27, 27, "part-of", "", true, false], [0, 0, 29, 29, "part-of", "", true, false], [0, 0, 31, 31, "part-of", "", true, false], [0, 0, 33, 35, "part-of", "", true, false], [0, 0, 37, 37, "part-of", "", true, false], [0, 0, 39, 39, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14], "sentence": ["DSP", "applications", "include", "audio", "signal", "processing", ",", "audio", "compression", ",", "digital", "image", "processing", ",", "video", "compression", ",", "speech", "processing", ",", "speech", "recognition", ",", "digital", "communications", ",", "digital", "synthesisers", ",", "radar", ",", "sonar", ",", "financial", "signal", "processing", ",", "seismology", "and", "biomedicine", "."], "sentence-detokenized": "DSP applications include audio signal processing, audio compression, digital image processing, video compression, speech processing, speech recognition, digital communications, digital synthesisers, radar, sonar, financial signal processing, seismology and biomedicine.", "token2charspan": [[0, 3], [4, 16], [17, 24], [25, 30], [31, 37], [38, 48], [48, 49], [50, 55], [56, 67], [67, 68], [69, 76], [77, 82], [83, 93], [93, 94], [95, 100], [101, 112], [112, 113], [114, 120], [121, 131], [131, 132], [133, 139], [140, 151], [151, 152], [153, 160], [161, 175], [175, 176], [177, 184], [185, 197], [197, 198], [199, 204], [204, 205], [206, 211], [211, 212], [213, 222], [223, 229], [230, 240], [240, 241], [242, 252], [253, 256], [257, 268], [268, 269]]}
{"doc_key": "ai-dev-247", "ner": [[10, 12, "misc"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "20", "February", "1912", "-", "11", "August", "2011", ")", "was", "an", "American", "inventor", ",", "best", "known", "for", "creating", "Unimate", ",", "the", "first", "industrial", "robot", "."], "sentence-detokenized": "(20 February 1912 - 11 August 2011) was an American inventor, best known for creating Unimate, the first industrial robot.", "token2charspan": [[0, 1], [1, 3], [4, 12], [13, 17], [18, 19], [20, 22], [23, 29], [30, 34], [34, 35], [36, 39], [40, 42], [43, 51], [52, 60], [60, 61], [62, 66], [67, 72], [73, 76], [77, 85], [86, 93], [93, 94], [95, 98], [99, 104], [105, 115], [116, 121], [121, 122]]}
{"doc_key": "ai-dev-248", "ner": [[1, 3, "researcher"], [5, 7, "researcher"], [9, 9, "researcher"], [19, 24, "algorithm"], [27, 31, "algorithm"], [37, 38, "task"], [35, 36, "algorithm"], [44, 44, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 3, 19, 24, "related-to", "writes_about", true, false], [5, 7, 19, 24, "related-to", "writes_about", true, false], [9, 9, 19, 24, "related-to", "writes_about", true, false], [19, 24, 27, 31, "related-to", "", true, false], [37, 38, 35, 36, "related-to", "", true, false], [44, 44, 35, 36, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["With", "David", "E.", "Rumelhart", "and", "Ronald", "J.", "Williams", ",", "Hinton", "co-authored", "a", "highly", "cited", "paper", "published", "in", "1986", "that", "popularized", "the", "back", "-", "propagation", "algorithm", "for", "training", "multilayer", "neural", "networks", ",", "a", "dramatic", "milestone", "in", "Alex", "Net", "image", "recognition", "designed", "by", "his", "student", "Alex", "Krizhevsky", "{{", "cite", "web"], "sentence-detokenized": "With David E. Rumelhart and Ronald J. Williams, Hinton co-authored a highly cited paper published in 1986 that popularized the back-propagation algorithm for training multilayer neural networks, a dramatic milestone in AlexNet image recognition designed by his student Alex Krizhevsky {{cite web", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 34], [35, 37], [38, 46], [46, 47], [48, 54], [55, 66], [67, 68], [69, 75], [76, 81], [82, 87], [88, 97], [98, 100], [101, 105], [106, 110], [111, 122], [123, 126], [127, 131], [131, 132], [132, 143], [144, 153], [154, 157], [158, 166], [167, 177], [178, 184], [185, 193], [193, 194], [195, 196], [197, 205], [206, 215], [216, 218], [219, 223], [223, 226], [227, 232], [233, 244], [245, 253], [254, 256], [257, 260], [261, 268], [269, 273], [274, 284], [285, 287], [287, 291], [292, 295]]}
{"doc_key": "ai-dev-249", "ner": [[10, 12, "metrics"], [14, 17, "metrics"], [19, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "predicted", "value", "has", "a", "continuous", "distribution", ",", "the", "mean", "squared", "error", ",", "root", "mean", "square", "error", "or", "median", "absolute", "deviation", "can", "be", "used", "to", "summarise", "the", "errors", "."], "sentence-detokenized": "When the predicted value has a continuous distribution, the mean squared error, root mean square error or median absolute deviation can be used to summarise the errors.", "token2charspan": [[0, 4], [5, 8], [9, 18], [19, 24], [25, 28], [29, 30], [31, 41], [42, 54], [54, 55], [56, 59], [60, 64], [65, 72], [73, 78], [78, 79], [80, 84], [85, 89], [90, 96], [97, 102], [103, 105], [106, 112], [113, 121], [122, 131], [132, 135], [136, 138], [139, 143], [144, 146], [147, 156], [157, 160], [161, 167], [167, 168]]}
{"doc_key": "ai-dev-250", "ner": [[0, 1, "algorithm"], [10, 10, "field"], [9, 9, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 10, 10, "part-of", "", true, false], [0, 1, 9, 9, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Conceptual", "clustering", "developed", "mainly", "in", "the", "1980s", "as", "an", "unsupervised", "machine", "learning", "paradigm", "."], "sentence-detokenized": "Conceptual clustering developed mainly in the 1980s as an unsupervised machine learning paradigm.", "token2charspan": [[0, 10], [11, 21], [22, 31], [32, 38], [39, 41], [42, 45], [46, 51], [52, 54], [55, 57], [58, 70], [71, 78], [79, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-dev-251", "ner": [[9, 10, "product"], [30, 31, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "named", "units", "can", "not", "be", "recognised", "by", "a", "machine", "translator", ",", "they", "may", "be", "mistranslated", "as", "common", "nouns", ",", "which", "would", "probably", "not", "affect", "the", "translation", "score", "in", "a", "bilingual", "evaluation", ",", "but", "would", "change", "the", "human", "readability", "of", "the", "text", "."], "sentence-detokenized": "If named units cannot be recognised by a machine translator, they may be mistranslated as common nouns, which would probably not affect the translation score in a bilingual evaluation, but would change the human readability of the text.", "token2charspan": [[0, 2], [3, 8], [9, 14], [15, 18], [18, 21], [22, 24], [25, 35], [36, 38], [39, 40], [41, 48], [49, 59], [59, 60], [61, 65], [66, 69], [70, 72], [73, 86], [87, 89], [90, 96], [97, 102], [102, 103], [104, 109], [110, 115], [116, 124], [125, 128], [129, 135], [136, 139], [140, 151], [152, 157], [158, 160], [161, 162], [163, 172], [173, 183], [183, 184], [185, 188], [189, 194], [195, 201], [202, 205], [206, 211], [212, 223], [224, 226], [227, 230], [231, 235], [235, 236]]}
{"doc_key": "ai-dev-252", "ner": [[0, 1, "researcher"], [10, 11, "misc"], [12, 18, "conference"], [20, 22, "location"], [24, 24, "country"], [38, 39, "researcher"], [45, 46, "researcher"], [49, 50, "university"], [54, 55, "researcher"], [57, 58, "researcher"], [60, 61, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 11, "related-to", "writes_about", false, false], [0, 1, 12, 18, "temporal", "", true, false], [12, 18, 20, 22, "physical", "", false, false], [20, 22, 24, 24, "physical", "", false, false], [45, 46, 49, 50, "physical", "", false, false], [45, 46, 49, 50, "role", "", false, false], [54, 55, 49, 50, "physical", "", false, false], [54, 55, 49, 50, "role", "", false, false], [57, 58, 49, 50, "physical", "", false, false], [57, 58, 49, 50, "role", "", false, false], [60, 61, 49, 50, "physical", "", false, false], [60, 61, 49, 50, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Roger", "Schank", ",", "1969", ",", "A", "conceptual", "dependency", "parser", "for", "natural", "language", "Proceedings", "of", "the", "1969", "on", "Computational", "linguistics", ",", "S\u00e5ng", "-", "S\u00e4by", ",", "Sweden", ",", "pp.", "1-", "3", "This", "model", ",", "partly", "influenced", "by", "the", "work", "of", "Sydney", "Lamb", ",", "was", "widely", "used", "by", "Schank", "'s", "students", "at", "Yale", "University", ",", "such", "as", "Robert", "Wilensky", ",", "Wendy", "Lehnert", "and", "Janet", "Kolodner", "."], "sentence-detokenized": "Roger Schank, 1969, A conceptual dependency parser for natural language Proceedings of the 1969 on Computational linguistics, S\u00e5ng-S\u00e4by, Sweden, pp. 1-3 This model, partly influenced by the work of Sydney Lamb, was widely used by Schank's students at Yale University, such as Robert Wilensky, Wendy Lehnert and Janet Kolodner.", "token2charspan": [[0, 5], [6, 12], [12, 13], [14, 18], [18, 19], [20, 21], [22, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 71], [72, 83], [84, 86], [87, 90], [91, 95], [96, 98], [99, 112], [113, 124], [124, 125], [126, 130], [130, 131], [131, 135], [135, 136], [137, 143], [143, 144], [145, 148], [149, 151], [151, 152], [153, 157], [158, 163], [163, 164], [165, 171], [172, 182], [183, 185], [186, 189], [190, 194], [195, 197], [198, 204], [205, 209], [209, 210], [211, 214], [215, 221], [222, 226], [227, 229], [230, 236], [236, 238], [239, 247], [248, 250], [251, 255], [256, 266], [266, 267], [268, 272], [273, 275], [276, 282], [283, 291], [291, 292], [293, 298], [299, 306], [307, 310], [311, 316], [317, 325], [325, 326]]}
{"doc_key": "ai-dev-253", "ner": [[4, 4, "algorithm"], [6, 6, "algorithm"], [13, 13, "algorithm"], [3, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 4, 4, "named", "", false, false], [13, 13, 4, 4, "named", "", false, false], [3, 16, 4, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "improved", "maximum", "likelihood", "method", "(", "IMLM", ")", "is", "a", "combination", "of", "two", "MLM", "(", "maximum", "likelihood", ")", "estimators", "."], "sentence-detokenized": "The improved maximum likelihood method (IMLM) is a combination of two MLM (maximum likelihood) estimators.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 31], [32, 38], [39, 40], [40, 44], [44, 45], [46, 48], [49, 50], [51, 62], [63, 65], [66, 69], [70, 73], [74, 75], [75, 82], [83, 93], [93, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-dev-254", "ner": [[19, 20, "metrics"], [23, 24, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[23, 24, 19, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["These", "methods", "can", "also", "analyse", "a", "programme", "'s", "output", "and", "usability", ",", "and", "so", "may", "include", "analysis", "of", "its", "confusion", "matrix", "(", "or", "confusion", "table", ")", "."], "sentence-detokenized": "These methods can also analyse a programme's output and usability, and so may include analysis of its confusion matrix (or confusion table).", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 22], [23, 30], [31, 32], [33, 42], [42, 44], [45, 51], [52, 55], [56, 65], [65, 66], [67, 70], [71, 73], [74, 77], [78, 85], [86, 94], [95, 97], [98, 101], [102, 111], [112, 118], [119, 120], [120, 122], [123, 132], [133, 138], [138, 139], [139, 140]]}
{"doc_key": "ai-dev-255", "ner": [[0, 0, "product"], [5, 6, "researcher"], [8, 9, "researcher"], [12, 14, "researcher"], [18, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 6, "origin", "", false, false], [0, 0, 8, 9, "origin", "", false, false], [0, 0, 12, 14, "origin", "", false, false], [0, 0, 18, 23, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SURF", "was", "first", "published", "by", "Herbert", "Bay", ",", "Tinne", "Tuytelaars", "and", "Luc", "Van", "Gool", "and", "presented", "at", "the", "European", "Computer", "Vision", "Conference", "in", "2006", "."], "sentence-detokenized": "SURF was first published by Herbert Bay, Tinne Tuytelaars and Luc Van Gool and presented at the European Computer Vision Conference in 2006.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 24], [25, 27], [28, 35], [36, 39], [39, 40], [41, 46], [47, 57], [58, 61], [62, 65], [66, 69], [70, 74], [75, 78], [79, 88], [89, 91], [92, 95], [96, 104], [105, 113], [114, 120], [121, 131], [132, 134], [135, 139], [139, 140]]}
{"doc_key": "ai-dev-256", "ner": [[0, 0, "task"], [7, 8, "field"], [10, 11, "field"], [14, 14, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 8, "part-of", "", false, false], [0, 0, 10, 11, "part-of", "", false, false], [0, 0, 14, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OCR", "is", "a", "field", "of", "research", "in", "pattern", "recognition", ",", "artificial", "intelligence", "and", "computer", "vision", "."], "sentence-detokenized": "OCR is a field of research in pattern recognition, artificial intelligence and computer vision.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 14], [15, 17], [18, 26], [27, 29], [30, 37], [38, 49], [49, 50], [51, 61], [62, 74], [75, 78], [79, 87], [88, 94], [94, 95]]}
{"doc_key": "ai-dev-257", "ner": [[6, 8, "metrics"], [7, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 15, 7, 13, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Continuing", "with", "the", "example", "using", "the", "maximum", "likelihood", "estimator", ",", "the", "probability", "density", "function", "(", "pdf", ")", "of", "the", "noise", "for", "one", "sample", "of", "mathwn", "/", "math", "is"], "sentence-detokenized": "Continuing with the example using the maximum likelihood estimator, the probability density function (pdf) of the noise for one sample of mathwn / math is", "token2charspan": [[0, 10], [11, 15], [16, 19], [20, 27], [28, 33], [34, 37], [38, 45], [46, 56], [57, 66], [66, 67], [68, 71], [72, 83], [84, 91], [92, 100], [101, 102], [102, 105], [105, 106], [107, 109], [110, 113], [114, 119], [120, 123], [124, 127], [128, 134], [135, 137], [138, 144], [145, 146], [147, 151], [152, 154]]}
{"doc_key": "ai-dev-258", "ner": [[2, 3, "field"], [5, 6, "task"], [8, 9, "task"], [11, 12, "task"], [14, 15, "task"], [17, 19, "task"], [21, 21, "task"], [23, 23, "task"], [25, 26, "task"], [28, 29, "task"], [31, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[5, 6, 2, 3, "part-of", "", false, false], [8, 9, 2, 3, "part-of", "", false, false], [11, 12, 2, 3, "part-of", "", false, false], [14, 15, 2, 3, "part-of", "", false, false], [17, 19, 2, 3, "part-of", "", false, false], [21, 21, 2, 3, "part-of", "", false, false], [23, 23, 2, 3, "part-of", "", false, false], [25, 26, 2, 3, "part-of", "", false, false], [28, 29, 2, 3, "part-of", "", false, false], [31, 33, 2, 3, "part-of", "", false, false], [35, 36, 2, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Subdomains", "of", "computer", "vision", "include", "scene", "reconstruction", ",", "event", "detection", ",", "video", "tracking", ",", "object", "recognition", ",", "3D", "pose", "estimation", ",", "learning", ",", "indexing", ",", "motion", "estimation", ",", "visual", "servoing", ",", "3D", "scene", "modelling", "and", "image", "restoration", "."], "sentence-detokenized": "Subdomains of computer vision include scene reconstruction, event detection, video tracking, object recognition, 3D pose estimation, learning, indexing, motion estimation, visual servoing, 3D scene modelling and image restoration.", "token2charspan": [[0, 10], [11, 13], [14, 22], [23, 29], [30, 37], [38, 43], [44, 58], [58, 59], [60, 65], [66, 75], [75, 76], [77, 82], [83, 91], [91, 92], [93, 99], [100, 111], [111, 112], [113, 115], [116, 120], [121, 131], [131, 132], [133, 141], [141, 142], [143, 151], [151, 152], [153, 159], [160, 170], [170, 171], [172, 178], [179, 187], [187, 188], [189, 191], [192, 197], [198, 207], [208, 211], [212, 217], [218, 229], [229, 230]]}
{"doc_key": "ai-dev-259", "ner": [[11, 15, "conference"], [3, 3, "researcher"], [6, 8, "misc"], [18, 21, "conference"], [22, 22, "researcher"], [24, 24, "researcher"], [26, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 15, 18, 21, "named", "", false, false], [3, 3, 6, 8, "win-defeat", "", false, false], [3, 3, 26, 27, "related-to", "writes_about", true, false], [6, 8, 11, 15, "temporal", "", false, false], [22, 22, 6, 8, "win-defeat", "", false, true], [22, 22, 26, 27, "related-to", "writes_about", true, false], [24, 24, 6, 8, "win-defeat", "", false, true], [24, 24, 26, 27, "related-to", "writes_about", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["In", "2013", ",", "Terzopoulos", "was", "awarded", "the", "Helmholtz", "Prize", "at", "the", "International", "Conference", "on", "Computer", "Vision", "for", "his", "1987", "ICCV", "paper", "with", "Kass", "and", "Witkin", "on", "active", "contour", "models", "."], "sentence-detokenized": "In 2013, Terzopoulos was awarded the Helmholtz Prize at the International Conference on Computer Vision for his 1987 ICCV paper with Kass and Witkin on active contour models.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 24], [25, 32], [33, 36], [37, 46], [47, 52], [53, 55], [56, 59], [60, 73], [74, 84], [85, 87], [88, 96], [97, 103], [104, 107], [108, 111], [112, 116], [117, 121], [122, 127], [128, 132], [133, 137], [138, 141], [142, 148], [149, 151], [152, 158], [159, 166], [167, 173], [173, 174]]}
{"doc_key": "ai-dev-260", "ner": [[15, 16, "task"], [19, 20, "algorithm"], [21, 31, "algorithm"], [26, 28, "algorithm"], [30, 30, "algorithm"], [33, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[15, 16, 19, 20, "usage", "", true, false], [15, 16, 21, 31, "usage", "", true, false], [15, 16, 26, 28, "usage", "", true, false], [15, 16, 30, 30, "usage", "", true, false], [15, 16, 33, 34, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["If", "a", "regularisation", "function", "Many", "algorithms", "exist", "for", "solving", "such", "problems", ";", "popular", "ones", "for", "linear", "classification", "include", ":", "stochastic", "gradient", "descent", ")", "gradient", "descent", ",", "L", "-", "BFGS", ",", "coordinate", "descent", "and", "Newton", "'s", "methods", "."], "sentence-detokenized": "If a regularisation function Many algorithms exist for solving such problems; popular ones for linear classification include: stochastic gradient descent) gradient descent, L-BFGS, coordinate descent and Newton's methods.", "token2charspan": [[0, 2], [3, 4], [5, 19], [20, 28], [29, 33], [34, 44], [45, 50], [51, 54], [55, 62], [63, 67], [68, 76], [76, 77], [78, 85], [86, 90], [91, 94], [95, 101], [102, 116], [117, 124], [124, 125], [126, 136], [137, 145], [146, 153], [153, 154], [155, 163], [164, 171], [171, 172], [173, 174], [174, 175], [175, 179], [179, 180], [181, 191], [192, 199], [200, 203], [204, 210], [210, 212], [213, 220], [220, 221]]}
{"doc_key": "ai-dev-261", "ner": [[0, 4, "algorithm"], [6, 6, "algorithm"], [12, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 4, 12, 13, "origin", "", false, false], [6, 6, 0, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Long", "Short", "-", "term", "Memory", "(", "LSTM", ")", "networks", "were", "invented", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "in", "1997", "and", "have", "set", "accuracy", "records", "in", "many", "application", "fields", "."], "sentence-detokenized": "Long Short-term Memory (LSTM) networks were invented by Sepp Hochreiter and J\u00fcrgen Schmidhuber in 1997 and have set accuracy records in many application fields.", "token2charspan": [[0, 4], [5, 10], [10, 11], [11, 15], [16, 22], [23, 24], [24, 28], [28, 29], [30, 38], [39, 43], [44, 52], [53, 55], [56, 60], [61, 71], [72, 75], [76, 82], [83, 94], [95, 97], [98, 102], [103, 106], [107, 111], [112, 115], [116, 124], [125, 132], [133, 135], [136, 140], [141, 152], [153, 159], [159, 160]]}
{"doc_key": "ai-dev-262", "ner": [[0, 0, "product"], [4, 6, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["TN", "was", "developed", "at", "Massachusetts", "General", "Hospital", "and", "has", "been", "tested", "in", "a", "number", "of", "scenarios", ",", "including", "extraction", "of", "smoking", "status", ",", "family", "history", "of", "coronary", "heart", "disease", ",", "identification", "of", "patients", "with", "sleep", "disorders", ","], "sentence-detokenized": "TN was developed at Massachusetts General Hospital and has been tested in a number of scenarios, including extraction of smoking status, family history of coronary heart disease, identification of patients with sleep disorders,", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 33], [34, 41], [42, 50], [51, 54], [55, 58], [59, 63], [64, 70], [71, 73], [74, 75], [76, 82], [83, 85], [86, 95], [95, 96], [97, 106], [107, 117], [118, 120], [121, 128], [129, 135], [135, 136], [137, 143], [144, 151], [152, 154], [155, 163], [164, 169], [170, 177], [177, 178], [179, 193], [194, 196], [197, 205], [206, 210], [211, 216], [217, 226], [226, 227]]}
{"doc_key": "ai-dev-263", "ner": [[2, 2, "researcher"], [7, 7, "product"], [14, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 7, 7, "role", "sells", false, false], [7, 7, 14, 15, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1960", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "shipped", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960 Devol personally sold the first Unimate robot, which was shipped to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [8, 13], [14, 24], [25, 29], [30, 33], [34, 39], [40, 47], [48, 53], [53, 54], [55, 60], [61, 64], [65, 72], [73, 75], [76, 83], [84, 90], [91, 93], [94, 98], [98, 99]]}
{"doc_key": "ai-dev-264", "ner": [[0, 5, "conference"], [13, 14, "location"], [16, 16, "location"], [18, 18, "country"], [32, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 5, 13, 14, "physical", "", false, false], [13, 14, 16, 16, "physical", "", false, false], [16, 16, 18, 18, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Campus", "Party", "Europe", "took", "place", "from", "14", "-", "18", "April", "2010", "at", "the", "Caja", "M\u00e1gica", "in", "Madrid", ",", "Spain", ",", "with", "800", "participants", "from", "each", "of", "the", "27", "Member", "States", "of", "the", "European", "Union", "."], "sentence-detokenized": "Campus Party Europe took place from 14-18 April 2010 at the Caja M\u00e1gica in Madrid, Spain, with 800 participants from each of the 27 Member States of the European Union.", "token2charspan": [[0, 6], [7, 12], [13, 19], [20, 24], [25, 30], [31, 35], [36, 38], [38, 39], [39, 41], [42, 47], [48, 52], [53, 55], [56, 59], [60, 64], [65, 71], [72, 74], [75, 81], [81, 82], [83, 88], [88, 89], [90, 94], [95, 98], [99, 111], [112, 116], [117, 121], [122, 124], [125, 128], [129, 131], [132, 138], [139, 145], [146, 148], [149, 152], [153, 161], [162, 167], [167, 168]]}
{"doc_key": "ai-dev-265", "ner": [[4, 5, "organisation"], [8, 11, "organisation"], [13, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 16, 4, 5, "origin", "", false, false], [13, 16, 8, 11, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2016", ",", "DeepMind", "'s", "collaboration", "with", "Moorfields", "Eye", "Hospital", "to", "develop", "AI", "apps", "for", "healthcare", "was", "announced", "."], "sentence-detokenized": "In July 2016, DeepMind's collaboration with Moorfields Eye Hospital to develop AI apps for healthcare was announced.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 22], [22, 24], [25, 38], [39, 43], [44, 54], [55, 58], [59, 67], [68, 70], [71, 78], [79, 81], [82, 86], [87, 90], [91, 101], [102, 105], [106, 115], [115, 116]]}
{"doc_key": "ai-dev-266", "ner": [[7, 7, "misc"], [16, 16, "university"], [18, 18, "university"], [20, 21, "university"], [23, 24, "university"], [26, 26, "university"], [28, 32, "university"], [33, 33, "university"], [35, 36, "university"], [38, 39, "university"], [41, 41, "university"], [43, 46, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[7, 7, 16, 16, "physical", "", false, false], [7, 7, 18, 18, "physical", "", false, false], [7, 7, 20, 21, "physical", "", false, false], [7, 7, 23, 24, "physical", "", false, false], [7, 7, 26, 26, "physical", "", false, false], [7, 7, 28, 32, "physical", "", false, false], [7, 7, 33, 33, "physical", "", false, false], [7, 7, 35, 36, "physical", "", false, false], [7, 7, 38, 39, "physical", "", false, false], [7, 7, 41, 41, "physical", "", false, false], [7, 7, 43, 46, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["In", "the", "end", ",", "they", "awarded", "eleven", "FP2s", "to", "various", "institutions", ",", "including", "the", "University", "of", "Freiburg", ",", "Bosch", ",", "Georgia", "Tech", ",", "KU", "Leuven", ",", "MIT", ",", "Stanford", ",", "Technical", "University", "of", "Munich", ",", "UC", "Berkeley", ",", "U", "Penn", ",", "USC", "and", "the", "University", "of", "Tokyo", "."], "sentence-detokenized": "In the end, they awarded eleven FP2s to various institutions, including the University of Freiburg, Bosch, Georgia Tech, KU Leuven, MIT, Stanford, Technical University of Munich, UC Berkeley, U Penn, USC and the University of Tokyo.", "token2charspan": [[0, 2], [3, 6], [7, 10], [10, 11], [12, 16], [17, 24], [25, 31], [32, 36], [37, 39], [40, 47], [48, 60], [60, 61], [62, 71], [72, 75], [76, 86], [87, 89], [90, 98], [98, 99], [100, 105], [105, 106], [107, 114], [115, 119], [119, 120], [121, 123], [124, 130], [130, 131], [132, 135], [135, 136], [137, 145], [145, 146], [147, 156], [157, 167], [168, 170], [171, 177], [177, 178], [179, 181], [182, 190], [190, 191], [192, 193], [194, 198], [198, 199], [200, 203], [204, 207], [208, 211], [212, 222], [223, 225], [226, 231], [231, 232]]}
{"doc_key": "ai-dev-267", "ner": [[1, 1, "metrics"], [3, 3, "metrics"], [5, 5, "metrics"], [7, 7, "metrics"], [17, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 17, 18, "part-of", "", false, false], [3, 3, 17, 18, "part-of", "", false, false], [5, 5, 17, 18, "part-of", "", false, false], [7, 7, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "TP", ",", "TN", ",", "FP", "and", "FN", "counts", "are", "usually", "stored", "in", "a", "table", "called", "a", "confusion", "matrix", "."], "sentence-detokenized": "The TP, TN, FP and FN counts are usually stored in a table called a confusion matrix.", "token2charspan": [[0, 3], [4, 6], [6, 7], [8, 10], [10, 11], [12, 14], [15, 18], [19, 21], [22, 28], [29, 32], [33, 40], [41, 47], [48, 50], [51, 52], [53, 58], [59, 65], [66, 67], [68, 77], [78, 84], [84, 85]]}
{"doc_key": "ai-dev-268", "ner": [[0, 1, "metrics"], [3, 4, "metrics"], [6, 7, "metrics"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Information", "gain", ",", "cross", "entropy", ",", "mutual", "information", "and", "odds", "ratio", "are", "most", "commonly", "used", "as", "a", "set", "of", "features", "."], "sentence-detokenized": "Information gain, cross entropy, mutual information and odds ratio are most commonly used as a set of features.", "token2charspan": [[0, 11], [12, 16], [16, 17], [18, 23], [24, 31], [31, 32], [33, 39], [40, 51], [52, 55], [56, 60], [61, 66], [67, 70], [71, 75], [76, 84], [85, 89], [90, 92], [93, 94], [95, 98], [99, 101], [102, 110], [110, 111]]}
{"doc_key": "ai-dev-269", "ner": [[12, 13, "task"], [15, 16, "task"], [18, 18, "task"], [20, 20, "task"], [22, 22, "task"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[24, 24, 22, 22, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "successfully", "applied", "to", "a", "variety", "of", "problems", ",", "including", "robot", "control", ",", "lift", "scheduling", ",", "telecommunications", ",,", "checkers", "and", "Go", "(", "AlphaGo", ")", "."], "sentence-detokenized": "It has been successfully applied to a variety of problems, including robot control, lift scheduling, telecommunications,, checkers and Go (AlphaGo).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 24], [25, 32], [33, 35], [36, 37], [38, 45], [46, 48], [49, 57], [57, 58], [59, 68], [69, 74], [75, 82], [82, 83], [84, 88], [89, 99], [99, 100], [101, 119], [119, 121], [122, 130], [131, 134], [135, 137], [138, 139], [139, 146], [146, 147], [147, 148]]}
{"doc_key": "ai-dev-270", "ner": [[11, 12, "misc"], [18, 22, "university"], [24, 24, "location"], [26, 26, "location"], [30, 33, "location"], [37, 39, "location"], [41, 41, "location"], [42, 42, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 18, 22, "physical", "", false, false], [18, 22, 24, 24, "physical", "", false, false], [24, 24, 26, 26, "physical", "", false, false], [30, 33, 37, 39, "physical", "", false, false], [37, 39, 41, 41, "physical", "", false, false], [41, 41, 42, 42, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "the", "inaugural", "year", "of", "Mission", "8", ",", "the", "American", "Venue", "was", "held", "on", "the", "campus", "of", "Georgia", "Institute", "of", "Technology", "in", "Atlanta", ",", "Georgia", ",", "and", "the", "Asia", "/", "Pacific", "Venue", "was", "conducted", "at", "Beihang", "University", "Gymnasium", "in", "Beijing", "China", "."], "sentence-detokenized": "In 2018, the inaugural year of Mission 8, the American Venue was held on the campus of Georgia Institute of Technology in Atlanta, Georgia, and the Asia / Pacific Venue was conducted at Beihang University Gymnasium in Beijing China.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 22], [23, 27], [28, 30], [31, 38], [39, 40], [40, 41], [42, 45], [46, 54], [55, 60], [61, 64], [65, 69], [70, 72], [73, 76], [77, 83], [84, 86], [87, 94], [95, 104], [105, 107], [108, 118], [119, 121], [122, 129], [129, 130], [131, 138], [138, 139], [140, 143], [144, 147], [148, 152], [153, 154], [155, 162], [163, 168], [169, 172], [173, 182], [183, 185], [186, 193], [194, 204], [205, 214], [215, 217], [218, 225], [226, 231], [231, 232]]}
{"doc_key": "ai-dev-271", "ner": [[0, 1, "field"], [6, 7, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "origin", "", false, false], [0, 1, 6, 7, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "is", "strongly", "related", "to", "pattern", "recognition", "and", "is", "derived", "from", "artificial", "intelligence", "."], "sentence-detokenized": "Machine learning is strongly related to pattern recognition and is derived from artificial intelligence.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 28], [29, 36], [37, 39], [40, 47], [48, 59], [60, 63], [64, 66], [67, 74], [75, 79], [80, 90], [91, 103], [103, 104]]}
{"doc_key": "ai-dev-272", "ner": [[4, 4, "programlang"], [18, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "set", "includes", "3", "Java", "games", ",", "which", "are", "controlled", "by", "the", "remote", "control", "and", "displayed", "on", "its", "LCD", "screen", "."], "sentence-detokenized": "The set includes 3 Java games, which are controlled by the remote control and displayed on its LCD screen.", "token2charspan": [[0, 3], [4, 7], [8, 16], [17, 18], [19, 23], [24, 29], [29, 30], [31, 36], [37, 40], [41, 51], [52, 54], [55, 58], [59, 65], [66, 73], [74, 77], [78, 87], [88, 90], [91, 94], [95, 98], [99, 105], [105, 106]]}
{"doc_key": "ai-dev-273", "ner": [[6, 16, "task"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 6, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "commercial", "but", "specialised", "technique", "for", "estimating", "the", "position", "of", "an", "articulated", "body", "based", "on", "computer", "vision", "is", "optical", "motion", "capture", "."], "sentence-detokenized": "A commercial but specialised technique for estimating the position of an articulated body based on computer vision is optical motion capture.", "token2charspan": [[0, 1], [2, 12], [13, 16], [17, 28], [29, 38], [39, 42], [43, 53], [54, 57], [58, 66], [67, 69], [70, 72], [73, 84], [85, 89], [90, 95], [96, 98], [99, 107], [108, 114], [115, 117], [118, 125], [126, 132], [133, 140], [140, 141]]}
{"doc_key": "ai-dev-274", "ner": [[0, 1, "organisation"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 9, 10, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "SMC", "is", "very", "similar", "to", "the", "more", "popular", "Jaccard", "index", "."], "sentence-detokenized": "The SMC is very similar to the more popular Jaccard index.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 15], [16, 23], [24, 26], [27, 30], [31, 35], [36, 43], [44, 51], [52, 57], [57, 58]]}
{"doc_key": "ai-dev-275", "ner": [[0, 0, "product"], [2, 6, "product"], [9, 11, "product"], [21, 22, "researcher"], [27, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 9, 11, "named", "", false, false], [0, 0, 21, 22, "artifact", "", false, false], [0, 0, 27, 27, "artifact", "", false, false], [2, 6, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ",", "or", "Programmable", "Universal", "Manipulation", "Arm", ")", "is", "an", "industrial", "robotic", "arm", "developed", "by", "Victor", "Scheinman", "at", "pioneering", "robotics", "company", "Unimation", "."], "sentence-detokenized": "PUMA (Programmable Universal Machine for Assembly, or Programmable Universal Manipulation Arm) is an industrial robotic arm developed by Victor Scheinman at pioneering robotics company Unimation.", "token2charspan": [[0, 4], [5, 6], [6, 18], [19, 28], [29, 36], [37, 40], [41, 49], [49, 50], [51, 53], [54, 66], [67, 76], [77, 89], [90, 93], [93, 94], [95, 97], [98, 100], [101, 111], [112, 119], [120, 123], [124, 133], [134, 136], [137, 143], [144, 153], [154, 156], [157, 167], [168, 176], [177, 184], [185, 194], [194, 195]]}
{"doc_key": "ai-dev-276", "ner": [[5, 5, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "written", "in", "the", "Python", "language", "."], "sentence-detokenized": "It is written in the Python language.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 20], [21, 27], [28, 36], [36, 37]]}
{"doc_key": "ai-dev-277", "ner": [[0, 0, "misc"], [2, 2, "misc"], [12, 12, "field"], [14, 15, "field"], [17, 17, "field"], [20, 20, "field"], [22, 23, "field"], [25, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 2, 2, "related-to", "metric_for", true, false], [0, 0, 12, 12, "part-of", "", false, false], [0, 0, 14, 15, "part-of", "", false, false], [0, 0, 17, 17, "part-of", "", false, false], [0, 0, 20, 20, "part-of", "", false, false], [0, 0, 22, 23, "part-of", "", false, false], [0, 0, 25, 27, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Bandwidth", "in", "Hertz", "is", "a", "central", "concept", "in", "many", "fields", ",", "including", "electronics", ",", "information", "theory", ",", "digital", "communications", ",", "radiocommunications", ",", "signal", "processing", "and", "spectroscopy", ",", "and", "is", "one", "of", "the", "determinants", "of", "the", "capacity", "of", "a", "given", "communication", "channel", "."], "sentence-detokenized": "Bandwidth in Hertz is a central concept in many fields, including electronics, information theory, digital communications, radiocommunications, signal processing and spectroscopy, and is one of the determinants of the capacity of a given communication channel.", "token2charspan": [[0, 9], [10, 12], [13, 18], [19, 21], [22, 23], [24, 31], [32, 39], [40, 42], [43, 47], [48, 54], [54, 55], [56, 65], [66, 77], [77, 78], [79, 90], [91, 97], [97, 98], [99, 106], [107, 121], [121, 122], [123, 142], [142, 143], [144, 150], [151, 161], [162, 165], [166, 178], [178, 179], [180, 183], [184, 186], [187, 190], [191, 193], [194, 197], [198, 210], [211, 213], [214, 217], [218, 226], [227, 229], [230, 231], [232, 237], [238, 251], [252, 259], [259, 260]]}
{"doc_key": "ai-dev-278", "ner": [[8, 8, "algorithm"], [10, 10, "algorithm"], [15, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 15, 19, "part-of", "", false, false], [10, 10, 15, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["If", "convex", "loss", "is", "used", "(", "as", "in", "AdaBoost", ",", "LogitBoost", "and", "all", "members", "of", "the", "AnyBoost", "family", "of", "algorithms", ")", ",", "the", "example", "with", "a", "higher", "margin", "will", "receive", "less", "(", "or", "equal", ")", "weight", "than", "the", "example", "with", "a", "lower", "margin", "."], "sentence-detokenized": "If convex loss is used (as in AdaBoost, LogitBoost and all members of the AnyBoost family of algorithms), the example with a higher margin will receive less (or equal) weight than the example with a lower margin.", "token2charspan": [[0, 2], [3, 9], [10, 14], [15, 17], [18, 22], [23, 24], [24, 26], [27, 29], [30, 38], [38, 39], [40, 50], [51, 54], [55, 58], [59, 66], [67, 69], [70, 73], [74, 82], [83, 89], [90, 92], [93, 103], [103, 104], [104, 105], [106, 109], [110, 117], [118, 122], [123, 124], [125, 131], [132, 138], [139, 143], [144, 151], [152, 156], [157, 158], [158, 160], [161, 166], [166, 167], [168, 174], [175, 179], [180, 183], [184, 191], [192, 196], [197, 198], [199, 204], [205, 211], [211, 212]]}
{"doc_key": "ai-dev-279", "ner": [[1, 6, "researcher"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", "'s", "1991", "thesis", "Sepp", "Hochreiter", "."], "sentence-detokenized": "Sepp Hochreiter's 1991 thesis Sepp Hochreiter.", "token2charspan": [[0, 4], [5, 15], [15, 17], [18, 22], [23, 29], [30, 34], [35, 45], [45, 46]]}
{"doc_key": "ai-dev-280", "ner": [[4, 5, "algorithm"], [7, 7, "algorithm"], [10, 11, "algorithm"], [14, 14, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"], [27, 28, "algorithm"], [31, 32, "algorithm"], [34, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 7, 4, 5, "named", "", false, false], [14, 14, 10, 11, "named", "", false, false], [17, 19, 27, 28, "related-to", "", true, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Typical", "discriminative", "models", "include", "logistic", "regression", "(", "LR", ")", ",", "support", "vector", "machines", "(", "SVMs", ")", ",", "conditional", "random", "fields", "(", "CRFs", ")", "(", "defined", "on", "a", "non-directional", "graph", ")", ",", "decision", "trees", ",", "neural", "networks", "and", "many", "others", "."], "sentence-detokenized": "Typical discriminative models include logistic regression (LR), support vector machines (SVMs), conditional random fields (CRFs) (defined on a non-directional graph), decision trees, neural networks and many others.", "token2charspan": [[0, 7], [8, 22], [23, 29], [30, 37], [38, 46], [47, 57], [58, 59], [59, 61], [61, 62], [62, 63], [64, 71], [72, 78], [79, 87], [88, 89], [89, 93], [93, 94], [94, 95], [96, 107], [108, 114], [115, 121], [122, 123], [123, 127], [127, 128], [129, 130], [130, 137], [138, 140], [141, 142], [143, 158], [159, 164], [164, 165], [165, 166], [167, 175], [176, 181], [181, 182], [183, 189], [190, 198], [199, 202], [203, 207], [208, 214], [214, 215]]}
{"doc_key": "ai-dev-281", "ner": [[9, 12, "metrics"], [32, 33, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["You", "can", "then", "also", "use", "these", "probabilities", "and", "estimate", "the", "mean", "square", "error", "(", "or", "other", "similar", "measure", ")", "between", "the", "probabilities", "and", "the", "actual", "values", ",", "and", "combine", "this", "with", "the", "confounding", "matrix", "to", "create", "very", "efficient", "fitness", "functions", "for", "logistic", "regression", "."], "sentence-detokenized": "You can then also use these probabilities and estimate the mean square error (or other similar measure) between the probabilities and the actual values, and combine this with the confounding matrix to create very efficient fitness functions for logistic regression.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 17], [18, 21], [22, 27], [28, 41], [42, 45], [46, 54], [55, 58], [59, 63], [64, 70], [71, 76], [77, 78], [78, 80], [81, 86], [87, 94], [95, 102], [102, 103], [104, 111], [112, 115], [116, 129], [130, 133], [134, 137], [138, 144], [145, 151], [151, 152], [153, 156], [157, 164], [165, 169], [170, 174], [175, 178], [179, 190], [191, 197], [198, 200], [201, 207], [208, 212], [213, 222], [223, 230], [231, 240], [241, 244], [245, 253], [254, 264], [264, 265]]}
{"doc_key": "ai-dev-282", "ner": [[0, 0, "product"], [6, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VoiceOver", "first", "appeared", "in", "2005", "in", "Mac", "OS", "X", "Tiger", "(", "10.4", ")", "."], "sentence-detokenized": "VoiceOver first appeared in 2005 in Mac OS X Tiger (10.4).", "token2charspan": [[0, 9], [10, 15], [16, 24], [25, 27], [28, 32], [33, 35], [36, 39], [40, 42], [43, 44], [45, 50], [51, 52], [52, 56], [56, 57], [57, 58]]}
{"doc_key": "ai-dev-283", "ner": [[14, 14, "algorithm"], [19, 21, "misc"], [24, 26, "metrics"], [29, 31, "algorithm"], [61, 63, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 14, 19, 21, "related-to", "applied_to", false, false], [24, 26, 19, 21, "type-of", "", false, false], [24, 26, 29, 31, "related-to", "used_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "practice", ",", "machine", "learning", "algorithms", "deal", "with", "this", "either", "by", "applying", "a", "convex", "approximation", "to", "the", "0", "-", "1", "loss", "function", "(", "like", "the", "hinge", "loss", "for", "a", "support", "vector", "machine", ")", ",", "which", "is", "easier", "to", "optimise", ",", "or", "by", "imposing", "assumptions", "on", "the", "mathP", "(", "x", ",", "y", ")", "/", "math", "distribution", "(", "and", "thus", "ceasing", "to", "be", "agnostic", "learning", "algorithms", "to", "which", "the", "above", "result", "applies", ")", "."], "sentence-detokenized": "In practice, machine learning algorithms deal with this either by applying a convex approximation to the 0-1 loss function (like the hinge loss for a support vector machine), which is easier to optimise, or by imposing assumptions on the mathP (x, y) / math distribution (and thus ceasing to be agnostic learning algorithms to which the above result applies).", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 20], [21, 29], [30, 40], [41, 45], [46, 50], [51, 55], [56, 62], [63, 65], [66, 74], [75, 76], [77, 83], [84, 97], [98, 100], [101, 104], [105, 106], [106, 107], [107, 108], [109, 113], [114, 122], [123, 124], [124, 128], [129, 132], [133, 138], [139, 143], [144, 147], [148, 149], [150, 157], [158, 164], [165, 172], [172, 173], [173, 174], [175, 180], [181, 183], [184, 190], [191, 193], [194, 202], [202, 203], [204, 206], [207, 209], [210, 218], [219, 230], [231, 233], [234, 237], [238, 243], [244, 245], [245, 246], [246, 247], [248, 249], [249, 250], [251, 252], [253, 257], [258, 270], [271, 272], [272, 275], [276, 280], [281, 288], [289, 291], [292, 294], [295, 303], [304, 312], [313, 323], [324, 326], [327, 332], [333, 336], [337, 342], [343, 349], [350, 357], [357, 358], [358, 359]]}
{"doc_key": "ai-dev-284", "ner": [[0, 0, "misc"], [11, 13, "field"], [18, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 13, "usage", "", false, false], [0, 0, 18, 23, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Westworld", "(", "1973", ")", "was", "the", "first", "feature", "film", "to", "use", "digital", "image", "processing", "for", "photography", "to", "simulate", "an", "android", "'s", "point", "of", "view", "."], "sentence-detokenized": "Westworld (1973) was the first feature film to use digital image processing for photography to simulate an android's point of view.", "token2charspan": [[0, 9], [10, 11], [11, 15], [15, 16], [17, 20], [21, 24], [25, 30], [31, 38], [39, 43], [44, 46], [47, 50], [51, 58], [59, 64], [65, 75], [76, 79], [80, 91], [92, 94], [95, 103], [104, 106], [107, 114], [114, 116], [117, 122], [123, 125], [126, 130], [130, 131]]}
{"doc_key": "ai-dev-285", "ner": [[7, 8, "task"], [10, 11, "task"], [13, 13, "task"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "now", "also", "widely", "used", "in", "speech", "recognition", ",", "speech", "synthesis", ",", "diaristics", ",", "Xavier", "Anguera", "et", "al", "."], "sentence-detokenized": "It is now also widely used in speech recognition, speech synthesis, diaristics, Xavier Anguera et al.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 14], [15, 21], [22, 26], [27, 29], [30, 36], [37, 48], [48, 49], [50, 56], [57, 66], [66, 67], [68, 78], [78, 79], [80, 86], [87, 94], [95, 97], [98, 100], [100, 101]]}
{"doc_key": "ai-dev-286", "ner": [[6, 17, "algorithm"], [16, 16, "algorithm"], [19, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 16, 6, 17, "type-of", "", false, false], [19, 22, 6, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Here", ",", "math", "/", "sigma", "is", "an", "element", "-", "wise", "activation", "function", ",", "such", "as", "a", "sigmoidal", "function", "or", "a", "rectified", "linear", "unit", "."], "sentence-detokenized": "Here, math / sigma is an element-wise activation function, such as a sigmoidal function or a rectified linear unit.", "token2charspan": [[0, 4], [4, 5], [6, 10], [11, 12], [13, 18], [19, 21], [22, 24], [25, 32], [32, 33], [33, 37], [38, 48], [49, 57], [57, 58], [59, 63], [64, 66], [67, 68], [69, 78], [79, 87], [88, 90], [91, 92], [93, 102], [103, 109], [110, 114], [114, 115]]}
{"doc_key": "ai-dev-287", "ner": [[12, 14, "algorithm"], [23, 23, "misc"], [25, 25, "misc"], [27, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "phonetics", "-", "based", "approaches", "(", "i.e.", "all", "models", "based", "on", "a", "hidden", "Markov", "model", ")", "required", "separate", "components", "and", "training", "for", "the", "pronunciation", ",", "acoustic", "and", "language", "models", "."], "sentence-detokenized": "Traditional phonetics-based approaches (i.e. all models based on a hidden Markov model) required separate components and training for the pronunciation, acoustic and language models.", "token2charspan": [[0, 11], [12, 21], [21, 22], [22, 27], [28, 38], [39, 40], [40, 44], [45, 48], [49, 55], [56, 61], [62, 64], [65, 66], [67, 73], [74, 80], [81, 86], [86, 87], [88, 96], [97, 105], [106, 116], [117, 120], [121, 129], [130, 133], [134, 137], [138, 151], [151, 152], [153, 161], [162, 165], [166, 174], [175, 181], [181, 182]]}
{"doc_key": "ai-dev-288", "ner": [[0, 3, "algorithm"], [7, 8, "field"], [10, 11, "field"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 13, 14, "related-to", "used_for", false, false], [7, 8, 0, 3, "usage", "", false, false], [10, 11, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Roberts", "cross", "operator", "is", "used", "in", "image", "processing", "and", "computer", "vision", "for", "edge", "detection", "."], "sentence-detokenized": "The Roberts cross operator is used in image processing and computer vision for edge detection.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 37], [38, 43], [44, 54], [55, 58], [59, 67], [68, 74], [75, 78], [79, 83], [84, 93], [93, 94]]}
{"doc_key": "ai-dev-289", "ner": [[0, 0, "metrics"], [2, 2, "metrics"], [25, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 25, 25, "opposite", "", false, false], [2, 2, 25, 25, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Sensitivity", "and", "specificity", "values", "are", "agnostic", "to", "the", "percentage", "of", "positive", "cases", "in", "the", "population", "of", "interest", "(", "as", "opposed", "to", ",", "for", "example", ",", "precision", ")", "."], "sentence-detokenized": "Sensitivity and specificity values are agnostic to the percentage of positive cases in the population of interest (as opposed to, for example, precision).", "token2charspan": [[0, 11], [12, 15], [16, 27], [28, 34], [35, 38], [39, 47], [48, 50], [51, 54], [55, 65], [66, 68], [69, 77], [78, 83], [84, 86], [87, 90], [91, 101], [102, 104], [105, 113], [114, 115], [115, 117], [118, 125], [126, 128], [128, 129], [130, 133], [134, 141], [141, 142], [143, 152], [152, 153], [153, 154]]}
{"doc_key": "ai-dev-290", "ner": [[2, 3, "algorithm"], [10, 10, "misc"], [12, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 2, 3, "topic", "", false, false], [10, 10, 12, 13, "artifact", "", false, false], [10, 10, 15, 16, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["However", ",", "perceptron", "models", "became", "very", "unpopular", "with", "the", "book", "Perceptrons", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", ",", "published", "in", "1969", "."], "sentence-detokenized": "However, perceptron models became very unpopular with the book Perceptrons by Marvin Minsky and Seymour Papert, published in 1969.", "token2charspan": [[0, 7], [7, 8], [9, 19], [20, 26], [27, 33], [34, 38], [39, 48], [49, 53], [54, 57], [58, 62], [63, 74], [75, 77], [78, 84], [85, 91], [92, 95], [96, 103], [104, 110], [110, 111], [112, 121], [122, 124], [125, 129], [129, 130]]}
{"doc_key": "ai-dev-291", "ner": [[1, 4, "conference"], [8, 8, "organisation"], [23, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 4, 23, 25, "topic", "", false, false], [8, 8, 1, 4, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["At", "the", "Document", "Understanding", "conferences", "held", "annually", "by", "NIST", ",", "advanced", "criteria", "have", "been", "developed", "for", "evaluating", "techniques", "that", "address", "the", "challenge", "of", "summarising", "multiple", "documents", "."], "sentence-detokenized": "At the Document Understanding conferences held annually by NIST, advanced criteria have been developed for evaluating techniques that address the challenge of summarising multiple documents.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 29], [30, 41], [42, 46], [47, 55], [56, 58], [59, 63], [63, 64], [65, 73], [74, 82], [83, 87], [88, 92], [93, 102], [103, 106], [107, 117], [118, 128], [129, 133], [134, 141], [142, 145], [146, 155], [156, 158], [159, 170], [171, 179], [180, 189], [189, 190]]}
{"doc_key": "ai-dev-292", "ner": [[0, 1, "product"], [28, 30, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 28, 30, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "parallel", "manipulator", "is", "designed", "in", "such", "a", "way", "that", "each", "chain", "is", "usually", "short", ",", "straight", "and", "thus", "can", "be", "rigid", "against", "unwanted", "movement", ",", "compared", "to", "a", "serial", "manipulator", "."], "sentence-detokenized": "A parallel manipulator is designed in such a way that each chain is usually short, straight and thus can be rigid against unwanted movement, compared to a serial manipulator.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 34], [35, 37], [38, 42], [43, 44], [45, 48], [49, 53], [54, 58], [59, 64], [65, 67], [68, 75], [76, 81], [81, 82], [83, 91], [92, 95], [96, 100], [101, 104], [105, 107], [108, 113], [114, 121], [122, 130], [131, 139], [139, 140], [141, 149], [150, 152], [153, 154], [155, 161], [162, 173], [173, 174]]}
{"doc_key": "ai-dev-293", "ner": [[25, 25, "misc"], [27, 29, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "manipulator", "is", "what", "makes", "the", "robot", "move", ",", "and", "the", "design", "of", "these", "systems", "can", "be", "categorised", "into", "several", "common", "types", ",", "such", "as", "SCARA", "and", "Cartesian", "coordinate", "robot", ",", "which", "use", "different", "coordinate", "systems", "to", "guide", "the", "machine", "'s", "arms", "."], "sentence-detokenized": "The manipulator is what makes the robot move, and the design of these systems can be categorised into several common types, such as SCARA and Cartesian coordinate robot, which use different coordinate systems to guide the machine's arms.", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 23], [24, 29], [30, 33], [34, 39], [40, 44], [44, 45], [46, 49], [50, 53], [54, 60], [61, 63], [64, 69], [70, 77], [78, 81], [82, 84], [85, 96], [97, 101], [102, 109], [110, 116], [117, 122], [122, 123], [124, 128], [129, 131], [132, 137], [138, 141], [142, 151], [152, 162], [163, 168], [168, 169], [170, 175], [176, 179], [180, 189], [190, 200], [201, 208], [209, 211], [212, 217], [218, 221], [222, 229], [229, 231], [232, 236], [236, 237]]}
{"doc_key": "ai-dev-294", "ner": [[1, 3, "country"], [11, 18, "organisation"], [19, 22, "organisation"], [25, 28, "organisation"], [32, 33, "organisation"], [38, 42, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 18, 1, 3, "physical", "", false, false], [19, 22, 1, 3, "physical", "", false, false], [25, 28, 1, 3, "physical", "", false, false], [32, 33, 1, 3, "physical", "", false, false], [38, 42, 1, 3, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "United", "States", ",", "he", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "Linguistic", "Society", "of", "America", ",", "the", "American", "Philosophical", "Association", "and", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In the United States, he is a member of the National Academy of Sciences, the American Academy of Arts and Sciences, the Linguistic Society of America, the American Philosophical Association and the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 20], [20, 21], [22, 24], [25, 27], [28, 29], [30, 36], [37, 39], [40, 43], [44, 52], [53, 60], [61, 63], [64, 72], [72, 73], [74, 77], [78, 86], [87, 94], [95, 97], [98, 102], [103, 106], [107, 115], [115, 116], [117, 120], [121, 131], [132, 139], [140, 142], [143, 150], [150, 151], [152, 155], [156, 164], [165, 178], [179, 190], [191, 194], [195, 198], [199, 207], [208, 219], [220, 223], [224, 227], [228, 239], [240, 242], [243, 250], [250, 251]]}
{"doc_key": "ai-dev-295", "ner": [[7, 9, "algorithm"], [11, 11, "algorithm"], [18, 19, "algorithm"], [25, 26, "algorithm"], [31, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 9, 18, 19, "named", "", false, false], [11, 11, 7, 9, "named", "", false, false], [18, 19, 25, 26, "compare", "", false, false], [18, 19, 31, 32, "related-to", "performs", false, false], [25, 26, 31, 32, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Their", "popularity", "grew", "with", "the", "popularity", "of", "support", "vector", "machines", "(", "SVMs", ")", "in", "the", "1990s", ",", "when", "SVMs", "were", "found", "to", "be", "competitive", "with", "neural", "networks", "in", "tasks", "such", "as", "handwriting", "recognition", "."], "sentence-detokenized": "Their popularity grew with the popularity of support vector machines (SVMs) in the 1990s, when SVMs were found to be competitive with neural networks in tasks such as handwriting recognition.", "token2charspan": [[0, 5], [6, 16], [17, 21], [22, 26], [27, 30], [31, 41], [42, 44], [45, 52], [53, 59], [60, 68], [69, 70], [70, 74], [74, 75], [76, 78], [79, 82], [83, 88], [88, 89], [90, 94], [95, 99], [100, 104], [105, 110], [111, 113], [114, 116], [117, 128], [129, 133], [134, 140], [141, 149], [150, 152], [153, 158], [159, 163], [164, 166], [167, 178], [179, 190], [190, 191]]}
{"doc_key": "ai-dev-296", "ner": [[2, 3, "misc"], [8, 9, "misc"], [15, 16, "algorithm"], [10, 26, "misc"], [31, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 8, 9, "usage", "", false, false], [2, 3, 10, 26, "usage", "", false, false], [8, 9, 15, 16, "origin", "result_of_algorithm", false, false], [10, 26, 31, 32, "origin", "result_of_algorithm", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "empirical", "whitening", "transform", "is", "obtained", "by", "estimating", "the", "covariance", "matrix", "(", "e.g.", "using", "the", "maximum", "likelihood", "method", ")", "and", "then", "constructing", "the", "corresponding", "estimated", "whitening", "matrix", "(", "e.g.", "using", "the", "Cholesky", "decomposition", "method", ")", "."], "sentence-detokenized": "The empirical whitening transform is obtained by estimating the covariance matrix (e.g. using the maximum likelihood method) and then constructing the corresponding estimated whitening matrix (e.g. using the Cholesky decomposition method).", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 33], [34, 36], [37, 45], [46, 48], [49, 59], [60, 63], [64, 74], [75, 81], [82, 83], [83, 87], [88, 93], [94, 97], [98, 105], [106, 116], [117, 123], [123, 124], [125, 128], [129, 133], [134, 146], [147, 150], [151, 164], [165, 174], [175, 184], [185, 191], [192, 193], [193, 197], [198, 203], [204, 207], [208, 216], [217, 230], [231, 237], [237, 238], [238, 239]]}
{"doc_key": "ai-dev-297", "ner": [[0, 0, "organisation"], [8, 10, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 0, 0, "artifact", "", false, false], [23, 23, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["IAI", "is", "the", "world", "'s", "largest", "manufacturer", "of", "Cartesian", "coordinate", "robots", "and", "a", "recognised", "leader", "in", "low", "-", "cost", ",", "high", "-", "performance", "SCARA", "robots", "."], "sentence-detokenized": "IAI is the world's largest manufacturer of Cartesian coordinate robots and a recognised leader in low-cost, high-performance SCARA robots.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [16, 18], [19, 26], [27, 39], [40, 42], [43, 52], [53, 63], [64, 70], [71, 74], [75, 76], [77, 87], [88, 94], [95, 97], [98, 101], [101, 102], [102, 106], [106, 107], [108, 112], [112, 113], [113, 124], [125, 130], [131, 137], [137, 138]]}
{"doc_key": "ai-dev-298", "ner": [[10, 10, "field"], [13, 13, "field"], [15, 17, "field"], [19, 20, "field"], [22, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["Formal", "concept", "analysis", "finds", "practical", "applications", "in", "fields", "such", "as", "data", "mining", ",", "text", "mining", ",", "machine", "learning", ",", "knowledge", "management", ",", "the", "semantic", "web", ",", "software", "development", ",", "chemistry", "and", "biology", "."], "sentence-detokenized": "Formal concept analysis finds practical applications in fields such as data mining, text mining, machine learning, knowledge management, the semantic web, software development, chemistry and biology.", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 29], [30, 39], [40, 52], [53, 55], [56, 62], [63, 67], [68, 70], [71, 75], [76, 82], [82, 83], [84, 88], [89, 95], [95, 96], [97, 104], [105, 113], [113, 114], [115, 124], [125, 135], [135, 136], [137, 140], [141, 149], [150, 153], [153, 154], [155, 163], [164, 175], [175, 176], [177, 186], [187, 190], [191, 198], [198, 199]]}
{"doc_key": "ai-dev-299", "ner": [[1, 2, "field"], [4, 6, "field"], [10, 11, "field"], [17, 18, "field"], [29, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 17, 18, "part-of", "", false, false], [4, 6, 29, 31, "topic", "", false, false], [10, 11, 4, 6, "named", "", false, false], [17, 18, 1, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", ",", "computational", "learning", "theory", "(", "or", "simply", "learning", "theory", ")", "is", "a", "sub-domain", "of", "artificial", "intelligence", "dedicated", "to", "the", "study", "of", "the", "design", "and", "analysis", "of", "machine", "learning", "algorithms", "."], "sentence-detokenized": "In computer science, computational learning theory (or simply learning theory) is a sub-domain of artificial intelligence dedicated to the study of the design and analysis of machine learning algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 34], [35, 43], [44, 50], [51, 52], [52, 54], [55, 61], [62, 70], [71, 77], [77, 78], [79, 81], [82, 83], [84, 94], [95, 97], [98, 108], [109, 121], [122, 131], [132, 134], [135, 138], [139, 144], [145, 147], [148, 151], [152, 158], [159, 162], [163, 171], [172, 174], [175, 182], [183, 191], [192, 202], [202, 203]]}
{"doc_key": "ai-dev-300", "ner": [[0, 1, "algorithm"], [3, 3, "algorithm"], [10, 11, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 0, 1, "named", "", false, false], [10, 11, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Collaborative", "filtering", "(", "CF", ")", "is", "a", "technique", "used", "by", "recommender", "systems", "."], "sentence-detokenized": "Collaborative filtering (CF) is a technique used by recommender systems.", "token2charspan": [[0, 13], [14, 23], [24, 25], [25, 27], [27, 28], [29, 31], [32, 33], [34, 43], [44, 48], [49, 51], [52, 63], [64, 71], [71, 72]]}
{"doc_key": "ai-dev-301", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "FALSE", "positive", "rate", "is", "the", "proportion", "of", "all", "negative", "results", "that", "still", "give", "a", "positive", "test", "result", ",", "i.e.", "the", "conditional", "probability", "of", "a", "positive", "test", "result", "with", "an", "event", "that", "did", "not", "occur", "."], "sentence-detokenized": "The FALSE positive rate is the proportion of all negative results that still give a positive test result, i.e. the conditional probability of a positive test result with an event that did not occur.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 23], [24, 26], [27, 30], [31, 41], [42, 44], [45, 48], [49, 57], [58, 65], [66, 70], [71, 76], [77, 81], [82, 83], [84, 92], [93, 97], [98, 104], [104, 105], [106, 110], [111, 114], [115, 126], [127, 138], [139, 141], [142, 143], [144, 152], [153, 157], [158, 164], [165, 169], [170, 172], [173, 178], [179, 183], [184, 187], [188, 191], [192, 197], [197, 198]]}
{"doc_key": "ai-dev-302", "ner": [[1, 15, "misc"], [38, 40, "metrics"], [43, 43, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 15, 38, 40, "topic", "", false, false], [1, 15, 43, 43, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "VLDB", "'", "8", ":", "Proceedings", "of", "the", "34th", "International", "Conference", "on", "Very", "Large", "Data", "Bases", ",", "pages", "422--433", ".", "showed", "that", "the", "given", "values", "for", "mathC", "/", "math", "and", "mathK", "/", "math", "generally", "imply", "a", "relatively", "low", "accuracy", "of", "the", "iteratively", "calculated", "SimRank", "results", "."], "sentence-detokenized": "In VLDB '8: Proceedings of the 34th International Conference on Very Large Data Bases, pages 422--433. showed that the given values for mathC / math and mathK / math generally imply a relatively low accuracy of the iteratively calculated SimRank results.", "token2charspan": [[0, 2], [3, 7], [8, 9], [9, 10], [10, 11], [12, 23], [24, 26], [27, 30], [31, 35], [36, 49], [50, 60], [61, 63], [64, 68], [69, 74], [75, 79], [80, 85], [85, 86], [87, 92], [93, 101], [101, 102], [103, 109], [110, 114], [115, 118], [119, 124], [125, 131], [132, 135], [136, 141], [142, 143], [144, 148], [149, 152], [153, 158], [159, 160], [161, 165], [166, 175], [176, 181], [182, 183], [184, 194], [195, 198], [199, 207], [208, 210], [211, 214], [215, 226], [227, 237], [238, 245], [246, 253], [253, 254]]}
{"doc_key": "ai-dev-303", "ner": [[5, 8, "misc"], [9, 9, "misc"], [0, 18, "person"], [20, 22, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 5, 8, "general-affiliation", "", false, false], [9, 9, 0, 18, "artifact", "", false, false], [9, 9, 20, 22, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "June", "2015", ",", "the", "sci", "-", "fi", "drama", "Sense8", ",", "which", "was", "written", "and", "produced", "by", "The", "Wachowskis", "and", "J.", "Michael", "Straczynski", ",", "debuted", "."], "sentence-detokenized": "In June 2015, the sci-fi drama Sense8, which was written and produced by The Wachowskis and J. Michael Straczynski, debuted.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 21], [21, 22], [22, 24], [25, 30], [31, 37], [37, 38], [39, 44], [45, 48], [49, 56], [57, 60], [61, 69], [70, 72], [73, 76], [77, 87], [88, 91], [92, 94], [95, 102], [103, 114], [114, 115], [116, 123], [123, 124]]}
{"doc_key": "ai-dev-304", "ner": [[1, 2, "misc"], [7, 8, "product"], [29, 31, "misc"], [39, 39, "country"], [41, 41, "country"], [43, 43, "country"], [45, 45, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 2, 7, 8, "topic", "", false, false], [39, 39, 29, 31, "type-of", "", false, false], [41, 41, 29, 31, "type-of", "", false, false], [43, 43, 29, 31, "type-of", "", false, false], [45, 45, 29, 31, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Although", "Eurotra", "has", "never", "delivered", "a", "working", "MT", "system", ",", "the", "project", "has", "had", "a", "far", "-", "reaching", ",", "long", "-", "term", "impact", "on", "the", "nascent", "language", "industries", "in", "European", "member", "states", ",", "particularly", "in", "southern", "countries", "such", "as", "Greece", ",", "Italy", ",", "Spain", "and", "Portugal", "."], "sentence-detokenized": "Although Eurotra has never delivered a working MT system, the project has had a far-reaching, long-term impact on the nascent language industries in European member states, particularly in southern countries such as Greece, Italy, Spain and Portugal.", "token2charspan": [[0, 8], [9, 16], [17, 20], [21, 26], [27, 36], [37, 38], [39, 46], [47, 49], [50, 56], [56, 57], [58, 61], [62, 69], [70, 73], [74, 77], [78, 79], [80, 83], [83, 84], [84, 92], [92, 93], [94, 98], [98, 99], [99, 103], [104, 110], [111, 113], [114, 117], [118, 125], [126, 134], [135, 145], [146, 148], [149, 157], [158, 164], [165, 171], [171, 172], [173, 185], [186, 188], [189, 197], [198, 207], [208, 212], [213, 215], [216, 222], [222, 223], [224, 229], [229, 230], [231, 236], [237, 240], [241, 249], [249, 250]]}
{"doc_key": "ai-dev-305", "ner": [[0, 4, "algorithm"], [7, 9, "task"], [19, 21, "task"], [23, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 9, 0, 4, "usage", "", true, false], [19, 21, 7, 9, "named", "", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "autoencoder", "has", "been", "successfully", "applied", "to", "machine", "translation", "of", "human", "languages", ",", "which", "is", "usually", "referred", "to", "as", "neural", "machine", "translation", "(", "NMT", ")", "."], "sentence-detokenized": "The autoencoder has been successfully applied to machine translation of human languages, which is usually referred to as neural machine translation (NMT).", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 24], [25, 37], [38, 45], [46, 48], [49, 56], [57, 68], [69, 71], [72, 77], [78, 87], [87, 88], [89, 94], [95, 97], [98, 105], [106, 114], [115, 117], [118, 120], [121, 127], [128, 135], [136, 147], [148, 149], [149, 152], [152, 153], [153, 154]]}
{"doc_key": "ai-dev-306", "ner": [[9, 11, "metrics"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Popular", "examples", "of", "probability", "-", "based", "fitness", "functions", "include", "maximum", "likelihood", "estimation", "and", "hinge", "loss", "."], "sentence-detokenized": "Popular examples of probability-based fitness functions include maximum likelihood estimation and hinge loss.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 31], [31, 32], [32, 37], [38, 45], [46, 55], [56, 63], [64, 71], [72, 82], [83, 93], [94, 97], [98, 103], [104, 108], [108, 109]]}
{"doc_key": "ai-dev-307", "ner": [[0, 0, "field"], [1, 13, "task"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 13, 0, 0, "part-of", "", false, false], [15, 16, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Data", "mining", "is", "a", "related", "field", "of", "science", ",", "focusing", "on", "exploratory", "data", "analysis", "through", "unsupervised", "learning", "."], "sentence-detokenized": "Data mining is a related field of science, focusing on exploratory data analysis through unsupervised learning.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 16], [17, 24], [25, 30], [31, 33], [34, 41], [41, 42], [43, 51], [52, 54], [55, 66], [67, 71], [72, 80], [81, 88], [89, 101], [102, 110], [110, 111]]}
{"doc_key": "ai-dev-308", "ner": [[0, 1, "algorithm"], [12, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 12, 14, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "filtering", "involves", "techniques", "for", "matching", "people", "with", "similar", "interests", "and", "creating", "a", "recommendation", "system", "on", "this", "basis", "."], "sentence-detokenized": "Collaborative filtering involves techniques for matching people with similar interests and creating a recommendation system on this basis.", "token2charspan": [[0, 13], [14, 23], [24, 32], [33, 43], [44, 47], [48, 56], [57, 63], [64, 68], [69, 76], [77, 86], [87, 90], [91, 99], [100, 101], [102, 116], [117, 123], [124, 126], [127, 131], [132, 137], [137, 138]]}
{"doc_key": "ai-dev-309", "ner": [[3, 8, "algorithm"], [14, 14, "programlang"], [17, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 20, 3, 8, "type-of", "", false, false], [17, 20, 14, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "number", "of", "WordNet", "-", "based", "word", "similarity", "algorithms", "have", "been", "implemented", "in", "a", "Perl", "package", "called", "WordNet", ":", ":", "Similarity", "."], "sentence-detokenized": "A number of WordNet-based word similarity algorithms have been implemented in a Perl package called WordNet:: Similarity.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 19], [19, 20], [20, 25], [26, 30], [31, 41], [42, 52], [53, 57], [58, 62], [63, 74], [75, 77], [78, 79], [80, 84], [85, 92], [93, 99], [100, 107], [107, 108], [108, 109], [110, 120], [120, 121]]}
{"doc_key": "ai-dev-310", "ner": [[5, 5, "conference"], [7, 7, "conference"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 23, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 7, 5, 5, "named", "", false, false], [11, 12, 5, 5, "temporal", "", false, false], [14, 15, 5, 5, "temporal", "", false, false], [17, 23, 5, 5, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Another", "paper", ",", "presented", "at", "CVPR", "(", "CVPR", ")", "2000", "by", "Erik", "Miller", ",", "Nicholas", "Matsakis", "and", "Paul", "Viola", ",", "will", "also", "be", "discussed", "."], "sentence-detokenized": "Another paper, presented at CVPR (CVPR) 2000 by Erik Miller, Nicholas Matsakis and Paul Viola, will also be discussed.", "token2charspan": [[0, 7], [8, 13], [13, 14], [15, 24], [25, 27], [28, 32], [33, 34], [34, 38], [38, 39], [40, 44], [45, 47], [48, 52], [53, 59], [59, 60], [61, 69], [70, 78], [79, 82], [83, 87], [88, 93], [93, 94], [95, 99], [100, 104], [105, 107], [108, 117], [117, 118]]}
{"doc_key": "ai-dev-311", "ner": [[0, 0, "algorithm"], [7, 8, "misc"], [12, 14, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 12, 14, "compare", "", false, false], [12, 14, 7, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["QC", "was", "not", "evaluated", "against", "traditional", "modern", "clustering", "algorithms", ",", "other", "than", "the", "Jaccard", "index", "."], "sentence-detokenized": "QC was not evaluated against traditional modern clustering algorithms, other than the Jaccard index.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 20], [21, 28], [29, 40], [41, 47], [48, 58], [59, 69], [69, 70], [71, 76], [77, 81], [82, 85], [86, 93], [94, 99], [99, 100]]}
{"doc_key": "ai-dev-312", "ner": [[2, 5, "misc"], [8, 10, "misc"], [14, 15, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 2, 5, "physical", "", false, false], [8, 10, 14, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "the", "VEX", "Robotics", "World", "Championship", ",", "the", "Parade", "of", "Nations", "takes", "place", "in", "Freedom", "Hall", ",", "with", "hundreds", "of", "students", "from", "more", "than", "30", "countries", "taking", "part", "."], "sentence-detokenized": "During the VEX Robotics World Championship, the Parade of Nations takes place in Freedom Hall, with hundreds of students from more than 30 countries taking part.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 23], [24, 29], [30, 42], [42, 43], [44, 47], [48, 54], [55, 57], [58, 65], [66, 71], [72, 77], [78, 80], [81, 88], [89, 93], [93, 94], [95, 99], [100, 108], [109, 111], [112, 120], [121, 125], [126, 130], [131, 135], [136, 138], [139, 148], [149, 155], [156, 160], [160, 161]]}
{"doc_key": "ai-dev-313", "ner": [[5, 8, "metrics"], [10, 10, "metrics"], [13, 15, "metrics"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 5, 8, "named", "", false, false], [17, 17, 13, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Other", "measures", "of", "accuracy", "include", "Single", "Word", "Error", "Rate", "(", "SWER", ")", "and", "Command", "Success", "Rate", "(", "CSR", ")", "."], "sentence-detokenized": "Other measures of accuracy include Single Word Error Rate (SWER) and Command Success Rate (CSR).", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [27, 34], [35, 41], [42, 46], [47, 52], [53, 57], [58, 59], [59, 63], [63, 64], [65, 68], [69, 76], [77, 84], [85, 89], [90, 91], [91, 94], [94, 95], [95, 96]]}
{"doc_key": "ai-dev-314", "ner": [[7, 8, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "presented", "their", "method", "and", "results", "at", "SIGGRAPH", "2000", "."], "sentence-detokenized": "They presented their method and results at SIGGRAPH 2000.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 27], [28, 31], [32, 39], [40, 42], [43, 51], [52, 56], [56, 57]]}
{"doc_key": "ai-dev-315", "ner": [[0, 2, "conference"], [7, 7, "misc"], [9, 13, "misc"], [17, 18, "conference"], [24, 29, "researcher"], [37, 39, "researcher"], [42, 44, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 7, 7, "origin", "", false, false], [7, 7, 17, 18, "physical", "", false, false], [7, 7, 17, 18, "temporal", "", false, false], [7, 7, 24, 29, "origin", "", false, false], [7, 7, 37, 39, "origin", "", false, false], [9, 13, 7, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "KDD", "conference", "grew", "out", "of", "the", "KDD", "(", "Knowledge", "Discovery", "and", "Data", "Mining", ")", "workshops", "at", "AAAI", "conferences", ",", "which", "were", "initiated", "by", "Gregory", "I", ".", "Piatetsky", "-", "Shapiro", "in", "1989", ",", "1991", "and", "1993", "and", "Usama", "Fayyad", "in", "1994", ".", "Machinery", "|", "ACM", "."], "sentence-detokenized": "The KDD conference grew out of the KDD (Knowledge Discovery and Data Mining) workshops at AAAI conferences, which were initiated by Gregory I. Piatetsky-Shapiro in 1989, 1991 and 1993 and Usama Fayyad in 1994. Machinery | ACM.", "token2charspan": [[0, 3], [4, 7], [8, 18], [19, 23], [24, 27], [28, 30], [31, 34], [35, 38], [39, 40], [40, 49], [50, 59], [60, 63], [64, 68], [69, 75], [75, 76], [77, 86], [87, 89], [90, 94], [95, 106], [106, 107], [108, 113], [114, 118], [119, 128], [129, 131], [132, 139], [140, 141], [141, 142], [143, 152], [152, 153], [153, 160], [161, 163], [164, 168], [168, 169], [170, 174], [175, 178], [179, 183], [184, 187], [188, 193], [194, 200], [201, 203], [204, 208], [208, 209], [210, 219], [220, 221], [222, 225], [225, 226]]}
{"doc_key": "ai-dev-316", "ner": [[7, 10, "conference"], [12, 12, "conference"], [16, 21, "organisation"], [23, 23, "organisation"], [27, 31, "conference"], [33, 33, "conference"], [40, 43, "conference"], [45, 45, "conference"], [49, 54, "conference"], [56, 56, "conference"], [59, 65, "conference"], [67, 67, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[12, 12, 7, 10, "named", "", false, false], [23, 23, 16, 21, "named", "", false, false], [33, 33, 27, 31, "named", "", false, false], [45, 45, 40, 43, "named", "", false, false], [56, 56, 49, 54, "named", "", false, false], [67, 67, 59, 65, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["He", "was", "elected", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", "(", "ACM", ")", ",", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", ",", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", ",", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "the", "American", "Association", "for", "Advancement", "of", "Science", "(", "AAAS", ")", "and", "the", "Society", "for", "Optics", "and", "Photonics", "Technology", "(", "SPIE", ")", "."], "sentence-detokenized": "He was elected a member of the Association for Computing Machinery (ACM), the Institute of Electrical and Electronics Engineers (IEEE), the International Association for Pattern Recognition (IAPR), the Association for the Advancement of Artificial Intelligence (AAAI), the American Association for Advancement of Science (AAAS) and the Society for Optics and Photonics Technology (SPIE).", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 16], [17, 23], [24, 26], [27, 30], [31, 42], [43, 46], [47, 56], [57, 66], [67, 68], [68, 71], [71, 72], [72, 73], [74, 77], [78, 87], [88, 90], [91, 101], [102, 105], [106, 117], [118, 127], [128, 129], [129, 133], [133, 134], [134, 135], [136, 139], [140, 153], [154, 165], [166, 169], [170, 177], [178, 189], [190, 191], [191, 195], [195, 196], [196, 197], [198, 201], [202, 213], [214, 217], [218, 221], [222, 233], [234, 236], [237, 247], [248, 260], [261, 262], [262, 266], [266, 267], [267, 268], [269, 272], [273, 281], [282, 293], [294, 297], [298, 309], [310, 312], [313, 320], [321, 322], [322, 326], [326, 327], [328, 331], [332, 335], [336, 343], [344, 347], [348, 354], [355, 358], [359, 368], [369, 379], [380, 381], [381, 385], [385, 386], [386, 387]]}
{"doc_key": "ai-dev-317", "ner": [[0, 1, "field"], [3, 4, "field"], [18, 19, "field"], [33, 34, "field"], [53, 56, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 18, 19, "named", "", false, false], [3, 4, 33, 34, "named", "", false, false], [33, 34, 53, 56, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "learning", "and", "data", "mining", "often", "use", "the", "same", "methods", "and", "there", "is", "significant", "overlap", ",", "but", "while", "machine", "learning", "focuses", "on", "making", "predictions", "based", "on", "known", "properties", "learned", "from", "training", "data", ",", "data", "mining", "focuses", "on", "discovering", "(", "previously", ")", "unknown", "properties", "in", "the", "data", "(", "this", "is", "the", "analysis", "stage", "of", "knowledge", "discovery", "in", "databases", ")", "."], "sentence-detokenized": "Machine learning and data mining often use the same methods and there is significant overlap, but while machine learning focuses on making predictions based on known properties learned from training data, data mining focuses on discovering (previously) unknown properties in the data (this is the analysis stage of knowledge discovery in databases).", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 25], [26, 32], [33, 38], [39, 42], [43, 46], [47, 51], [52, 59], [60, 63], [64, 69], [70, 72], [73, 84], [85, 92], [92, 93], [94, 97], [98, 103], [104, 111], [112, 120], [121, 128], [129, 131], [132, 138], [139, 150], [151, 156], [157, 159], [160, 165], [166, 176], [177, 184], [185, 189], [190, 198], [199, 203], [203, 204], [205, 209], [210, 216], [217, 224], [225, 227], [228, 239], [240, 241], [241, 251], [251, 252], [253, 260], [261, 271], [272, 274], [275, 278], [279, 283], [284, 285], [285, 289], [290, 292], [293, 296], [297, 305], [306, 311], [312, 314], [315, 324], [325, 334], [335, 337], [338, 347], [347, 348], [348, 349]]}
{"doc_key": "ai-dev-318", "ner": [[0, 0, "product"], [4, 4, "programlang"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "general-affiliation", "", false, false], [0, 0, 4, 4, "related-to", "runs_on", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Indy", "is", "written", "in", "Java", "and", "therefore", "runs", "on", "most", "modern", "operating", "systems", "."], "sentence-detokenized": "Indy is written in Java and therefore runs on most modern operating systems.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 23], [24, 27], [28, 37], [38, 42], [43, 45], [46, 50], [51, 57], [58, 67], [68, 75], [75, 76]]}
{"doc_key": "ai-dev-319", "ner": [[0, 0, "algorithm"], [5, 7, "algorithm"], [9, 9, "algorithm"], [15, 17, "algorithm"], [19, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 7, "type-of", "", true, false], [9, 9, 5, 7, "named", "", false, false], [15, 17, 5, 7, "type-of", "", true, false], [19, 19, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["NMF", "is", "an", "instance", "of", "non-negative", "quadratic", "programming", "(", "NQP", ")", ",", "as", "is", "the", "support", "vector", "machine", "(", "SVM", ")", "."], "sentence-detokenized": "NMF is an instance of non-negative quadratic programming (NQP), as is the support vector machine (SVM).", "token2charspan": [[0, 3], [4, 6], [7, 9], [10, 18], [19, 21], [22, 34], [35, 44], [45, 56], [57, 58], [58, 61], [61, 62], [62, 63], [64, 66], [67, 69], [70, 73], [74, 81], [82, 88], [89, 96], [97, 98], [98, 101], [101, 102], [102, 103]]}
{"doc_key": "ai-dev-320", "ner": [[8, 9, "misc"], [11, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 11, 15, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["This", "method", "is", "based", "on", "the", "estimation", "of", "conditional", "probabilities", "using", "a", "non-parametric", "maximum", "likelihood", "method", ",", "which", "leads", "to", "a"], "sentence-detokenized": "This method is based on the estimation of conditional probabilities using a non-parametric maximum likelihood method, which leads to a", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 20], [21, 23], [24, 27], [28, 38], [39, 41], [42, 53], [54, 67], [68, 73], [74, 75], [76, 90], [91, 98], [99, 109], [110, 116], [116, 117], [118, 123], [124, 129], [130, 132], [133, 134]]}
{"doc_key": "ai-dev-321", "ner": [[8, 8, "algorithm"], [10, 13, "algorithm"], [15, 17, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "basic", "concepts", "related", "to", "spectral", "estimation", "are", "autocorrelation", ",", "the", "multivariate", "Fourier", "transform", ",", "mean", "squared", "error", "and", "entropy", "."], "sentence-detokenized": "The basic concepts related to spectral estimation are autocorrelation, the multivariate Fourier transform, mean squared error and entropy.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 26], [27, 29], [30, 38], [39, 49], [50, 53], [54, 69], [69, 70], [71, 74], [75, 87], [88, 95], [96, 105], [105, 106], [107, 111], [112, 119], [120, 125], [126, 129], [130, 137], [137, 138]]}
{"doc_key": "ai-dev-322", "ner": [[3, 4, "algorithm"], [9, 9, "field"], [11, 11, "algorithm"], [13, 15, "algorithm"], [17, 18, "task"], [20, 22, "field"], [24, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7, 8], "relations": [[3, 4, 9, 9, "part-of", "", false, false], [3, 4, 11, 11, "part-of", "", false, false], [3, 4, 13, 15, "part-of", "", false, false], [3, 4, 17, 18, "part-of", "", false, false], [3, 4, 20, 22, "part-of", "", false, false], [3, 4, 24, 25, "part-of", "", false, false], [3, 4, 27, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6, 7], "sentence": ["Application", "areas", "for", "kernel", "methods", "are", "diverse", "and", "include", "geostatistics", ",", "kriging", ",", "inverse", "distance", "weighting", ",", "3D", "reconstruction", ",", "bioinformatics", ",", "chemoinformatics", ",", "information", "extraction", "and", "handwriting", "recognition", "."], "sentence-detokenized": "Application areas for kernel methods are diverse and include geostatistics, kriging, inverse distance weighting, 3D reconstruction, bioinformatics, chemoinformatics, information extraction and handwriting recognition.", "token2charspan": [[0, 11], [12, 17], [18, 21], [22, 28], [29, 36], [37, 40], [41, 48], [49, 52], [53, 60], [61, 74], [74, 75], [76, 83], [83, 84], [85, 92], [93, 101], [102, 111], [111, 112], [113, 115], [116, 130], [130, 131], [132, 146], [146, 147], [148, 164], [164, 165], [166, 177], [178, 188], [189, 192], [193, 204], [205, 216], [216, 217]]}
{"doc_key": "ai-dev-323", "ner": [[13, 13, "organisation"], [15, 19, "product"], [21, 21, "product"], [25, 28, "product"], [30, 30, "product"], [34, 35, "product"], [37, 39, "product"], [41, 42, "product"], [44, 47, "product"], [51, 52, "product"], [54, 55, "product"], [59, 64, "product"], [67, 70, "product"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[15, 19, 13, 13, "artifact", "", false, false], [15, 19, 34, 35, "compare", "", false, false], [15, 19, 37, 39, "compare", "", false, false], [15, 19, 41, 42, "compare", "", false, false], [15, 19, 44, 47, "compare", "", false, false], [15, 19, 51, 52, "compare", "", false, false], [15, 19, 54, 55, "compare", "", false, false], [15, 19, 59, 64, "compare", "", false, false], [15, 19, 67, 70, "compare", "", false, false], [21, 21, 15, 19, "named", "", false, false], [25, 28, 34, 35, "compare", "", false, false], [25, 28, 37, 39, "compare", "", false, false], [25, 28, 41, 42, "compare", "", false, false], [25, 28, 44, 47, "compare", "", false, false], [25, 28, 51, 52, "compare", "", false, false], [25, 28, 54, 55, "compare", "", false, false], [25, 28, 59, 64, "compare", "", false, false], [25, 28, 67, 70, "compare", "", false, false], [30, 30, 25, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19], "sentence": ["Robots", "can", "be", "autonomous", "or", "semi-autonomous", "and", "range", "from", "humanoids", ",", "such", "as", "Honda", "'s", "Advanced", "Step", "in", "Innovative", "Mobility", "(", "ASIMO", ")", "and", "TOSY", "Ping", "Pong", "Playing", "Robot", "(", "TOPIO", ")", ",", "to", "industrial", "robots", ",", "medical", "surgical", "robots", ",", "patient", "assistance", "robots", ",", "dog", "therapy", "robots", ",", "collectively", "programmed", "swarm", "robots", ",", "UAV", "drones", "such", "as", "the", "General", "Atomics", "MQ", "-", "1", "Predator", "and", "even", "microscopic", "nano", "-", "robots", "."], "sentence-detokenized": "Robots can be autonomous or semi-autonomous and range from humanoids, such as Honda's Advanced Step in Innovative Mobility (ASIMO) and TOSY Ping Pong Playing Robot (TOPIO), to industrial robots, medical surgical robots, patient assistance robots, dog therapy robots, collectively programmed swarm robots, UAV drones such as the General Atomics MQ-1 Predator and even microscopic nano-robots.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 24], [25, 27], [28, 43], [44, 47], [48, 53], [54, 58], [59, 68], [68, 69], [70, 74], [75, 77], [78, 83], [83, 85], [86, 94], [95, 99], [100, 102], [103, 113], [114, 122], [123, 124], [124, 129], [129, 130], [131, 134], [135, 139], [140, 144], [145, 149], [150, 157], [158, 163], [164, 165], [165, 170], [170, 171], [171, 172], [173, 175], [176, 186], [187, 193], [193, 194], [195, 202], [203, 211], [212, 218], [218, 219], [220, 227], [228, 238], [239, 245], [245, 246], [247, 250], [251, 258], [259, 265], [265, 266], [267, 279], [280, 290], [291, 296], [297, 303], [303, 304], [305, 308], [309, 315], [316, 320], [321, 323], [324, 327], [328, 335], [336, 343], [344, 346], [346, 347], [347, 348], [349, 357], [358, 361], [362, 366], [367, 378], [379, 383], [383, 384], [384, 390], [390, 391]]}
{"doc_key": "ai-dev-324", "ner": [[0, 0, "product"], [2, 3, "product"], [8, 14, "university"], [17, 17, "researcher"], [19, 20, "researcher"], [22, 24, "researcher"], [25, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 17, 17, "artifact", "", false, false], [0, 0, 19, 20, "artifact", "", false, false], [0, 0, 22, 24, "artifact", "", false, false], [0, 0, 25, 26, "artifact", "", false, false], [2, 3, 17, 17, "artifact", "", false, false], [2, 3, 19, 20, "artifact", "", false, false], [2, 3, 22, 24, "artifact", "", false, false], [2, 3, 25, 26, "artifact", "", false, false], [17, 17, 8, 14, "physical", "", false, false], [19, 20, 8, 14, "physical", "", false, false], [22, 24, 8, 14, "physical", "", false, false], [25, 26, 8, 14, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Freddy", "and", "Freddy", "II", "were", "robots", "built", "at", "the", "University", "of", "Edinburgh", "School", "of", "Informatics", "by", "Pat", "Ambler", ",", "Robin", "Popplestone", ",", "Austin", "Tate", "and", "Donald", "Mitchie", "and", "were", "able", "to", "assemble", "wooden", "blocks", "in", "a", "matter", "of", "hours", "."], "sentence-detokenized": "Freddy and Freddy II were robots built at the University of Edinburgh School of Informatics by Pat Ambler, Robin Popplestone, Austin Tate and Donald Mitchie and were able to assemble wooden blocks in a matter of hours.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 20], [21, 25], [26, 32], [33, 38], [39, 41], [42, 45], [46, 56], [57, 59], [60, 69], [70, 76], [77, 79], [80, 91], [92, 94], [95, 98], [99, 105], [105, 106], [107, 112], [113, 124], [124, 125], [126, 132], [133, 137], [138, 141], [142, 148], [149, 156], [157, 160], [161, 165], [166, 170], [171, 173], [174, 182], [183, 189], [190, 196], [197, 199], [200, 201], [202, 208], [209, 211], [212, 217], [217, 218]]}
{"doc_key": "ai-dev-325", "ner": [[5, 5, "location"], [12, 13, "country"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "spent", "his", "childhood", "in", "Paris", ",", "where", "his", "parents", "emigrated", "from", "Lithuania", "in", "the", "early", "1920s", "."], "sentence-detokenized": "He spent his childhood in Paris, where his parents emigrated from Lithuania in the early 1920s.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 22], [23, 25], [26, 31], [31, 32], [33, 38], [39, 42], [43, 50], [51, 60], [61, 65], [66, 75], [76, 78], [79, 82], [83, 88], [89, 94], [94, 95]]}
{"doc_key": "ai-dev-326", "ner": [[2, 3, "researcher"], [8, 11, "misc"], [14, 17, "organisation"], [19, 21, "university"], [30, 35, "university"], [39, 41, "university"], [43, 47, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 3, 8, 11, "role", "", false, false], [2, 3, 19, 21, "physical", "", false, false], [2, 3, 30, 35, "role", "", false, false], [2, 3, 39, 41, "role", "", false, false], [2, 3, 43, 47, "role", "", false, false], [8, 11, 14, 17, "part-of", "", false, false], [14, 17, 19, 21, "part-of", "", false, false], [39, 41, 30, 35, "part-of", "", false, false], [43, 47, 30, 35, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Previously", ",", "Dr", "Paulos", "held", "the", "position", "of", "Cooper-", "Siegel", "Associate", "Professor", "in", "the", "School", "of", "Computer", "Science", "at", "Carnegie", "Mellon", "University", ",", "where", "he", "was", "a", "lecturer", "in", "the", "Human", "-", "Computer", "Interaction", "Institute", "and", "also", "worked", "at", "the", "Robotics", "Institute", "and", "the", "Center", "for", "Entertainment", "Technology", "."], "sentence-detokenized": "Previously, Dr Paulos held the position of Cooper-Siegel Associate Professor in the School of Computer Science at Carnegie Mellon University, where he was a lecturer in the Human-Computer Interaction Institute and also worked at the Robotics Institute and the Center for Entertainment Technology.", "token2charspan": [[0, 10], [10, 11], [12, 14], [15, 21], [22, 26], [27, 30], [31, 39], [40, 42], [43, 50], [50, 56], [57, 66], [67, 76], [77, 79], [80, 83], [84, 90], [91, 93], [94, 102], [103, 110], [111, 113], [114, 122], [123, 129], [130, 140], [140, 141], [142, 147], [148, 150], [151, 154], [155, 156], [157, 165], [166, 168], [169, 172], [173, 178], [178, 179], [179, 187], [188, 199], [200, 209], [210, 213], [214, 218], [219, 225], [226, 228], [229, 232], [233, 241], [242, 251], [252, 255], [256, 259], [260, 266], [267, 270], [271, 284], [285, 295], [295, 296]]}
{"doc_key": "ai-dev-327", "ner": [[3, 4, "researcher"], [6, 7, "university"], [10, 11, "product"], [18, 22, "product"], [26, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 6, 7, "physical", "", false, false], [3, 4, 6, 7, "role", "", false, false], [10, 11, 3, 4, "artifact", "", false, false], [10, 11, 18, 22, "type-of", "", false, false], [10, 11, 26, 30, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1969", ",", "Victor", "Scheinman", "of", "Stanford", "University", "invented", "the", "Stanford", "arm", ",", "an", "all", "-", "electric", ",", "six", "-", "axis", "articulated", "robot", "designed", "to", "enable", "the", "arm", "to", "be", "dissolved", "."], "sentence-detokenized": "In 1969, Victor Scheinman of Stanford University invented the Stanford arm, an all-electric, six-axis articulated robot designed to enable the arm to be dissolved.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 25], [26, 28], [29, 37], [38, 48], [49, 57], [58, 61], [62, 70], [71, 74], [74, 75], [76, 78], [79, 82], [82, 83], [83, 91], [91, 92], [93, 96], [96, 97], [97, 101], [102, 113], [114, 119], [120, 128], [129, 131], [132, 138], [139, 142], [143, 146], [147, 149], [150, 152], [153, 162], [162, 163]]}
{"doc_key": "ai-dev-328", "ner": [[5, 5, "product"], [16, 17, "field"], [19, 20, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 16, 17, "related-to", "", false, false], [5, 5, 19, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "creation", "and", "deployment", "of", "chatbots", "is", "an", "ever", "-", "evolving", "field", ",", "strongly", "linked", "to", "artificial", "intelligence", "and", "machine", "learning", ",", "so", "the", "solutions", "provided", ",", "while", "having", "obvious", "advantages", ",", "have", "some", "significant", "limitations", "in", "terms", "of", "functionality", "and", "use", "cases", "."], "sentence-detokenized": "The creation and deployment of chatbots is an ever-evolving field, strongly linked to artificial intelligence and machine learning, so the solutions provided, while having obvious advantages, have some significant limitations in terms of functionality and use cases.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 27], [28, 30], [31, 39], [40, 42], [43, 45], [46, 50], [50, 51], [51, 59], [60, 65], [65, 66], [67, 75], [76, 82], [83, 85], [86, 96], [97, 109], [110, 113], [114, 121], [122, 130], [130, 131], [132, 134], [135, 138], [139, 148], [149, 157], [157, 158], [159, 164], [165, 171], [172, 179], [180, 190], [190, 191], [192, 196], [197, 201], [202, 213], [214, 225], [226, 228], [229, 234], [235, 237], [238, 251], [252, 255], [256, 259], [260, 265], [265, 266]]}
{"doc_key": "ai-dev-329", "ner": [[7, 10, "university"], [11, 12, "product"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 7, 10, "part-of", "", true, false], [21, 22, 11, 12, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "terms", "of", "freely", "available", "resources", ",", "Carnegie", "Mellon", "University", "'s", "Sphinx", "toolkit", "is", "one", "place", "to", "start", "both", "learning", "about", "speech", "recognition", "and", "begin", "experimenting", "."], "sentence-detokenized": "In terms of freely available resources, Carnegie Mellon University's Sphinx toolkit is one place to start both learning about speech recognition and begin experimenting.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 18], [19, 28], [29, 38], [38, 39], [40, 48], [49, 55], [56, 66], [66, 68], [69, 75], [76, 83], [84, 86], [87, 90], [91, 96], [97, 99], [100, 105], [106, 110], [111, 119], [120, 125], [126, 132], [133, 144], [145, 148], [149, 154], [155, 168], [168, 169]]}
{"doc_key": "ai-dev-330", "ner": [[2, 3, "misc"], [13, 19, "misc"], [21, 21, "misc"], [25, 25, "university"], [27, 27, "location"], [29, 29, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 13, 19, "temporal", "", false, false], [21, 21, 13, 19, "named", "", false, false], [21, 21, 27, 27, "physical", "", false, false], [25, 25, 21, 21, "role", "", false, false], [27, 27, 29, 29, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "formal", "RoboCup", "competition", "was", "preceded", "by", "the", "(", "often", "unrecognised", ")", "first", "Micro", "Robot", "World", "Cup", "International", "Soccer", "Tournament", "(", "MIROSOT", ")", "organised", "by", "KAIST", "in", "Taejon", ",", "Korea", ",", "in", "November", "1996", "."], "sentence-detokenized": "The formal RoboCup competition was preceded by the (often unrecognised) first Micro Robot World Cup International Soccer Tournament (MIROSOT) organised by KAIST in Taejon, Korea, in November 1996.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 30], [31, 34], [35, 43], [44, 46], [47, 50], [51, 52], [52, 57], [58, 70], [70, 71], [72, 77], [78, 83], [84, 89], [90, 95], [96, 99], [100, 113], [114, 120], [121, 131], [132, 133], [133, 140], [140, 141], [142, 151], [152, 154], [155, 160], [161, 163], [164, 170], [170, 171], [172, 177], [177, 178], [179, 181], [182, 190], [191, 195], [195, 196]]}
{"doc_key": "ai-dev-331", "ner": [[5, 7, "metrics"], [24, 25, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", "to", "the", "standard", "hinge", "loss", "math", "(", "1-", "yf", "(", "x", ")", ")", "_", "+", "/", "math", "for", "labelled", "data", ",", "the", "loss", "function", "math", "(", "-", "1", "|", "f", "(", "x", ")", "|", ")", "_", "+", "/", "math", "is", "introduced", "over", "unlabelled", "data", "by", "allowing", "math", "=", "operatorname", "{", "sign", "}", "{", "f", "(", "x", ")", "}", "/", "math", "."], "sentence-detokenized": "In addition to the standard hinge loss math (1-yf (x)) _ + / math for labelled data, the loss function math (-1 | f (x) |) _ + / math is introduced over unlabelled data by allowing math = operatorname {sign} {f (x)} / math.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 27], [28, 33], [34, 38], [39, 43], [44, 45], [45, 47], [47, 49], [50, 51], [51, 52], [52, 53], [53, 54], [55, 56], [57, 58], [59, 60], [61, 65], [66, 69], [70, 78], [79, 83], [83, 84], [85, 88], [89, 93], [94, 102], [103, 107], [108, 109], [109, 110], [110, 111], [112, 113], [114, 115], [116, 117], [117, 118], [118, 119], [120, 121], [121, 122], [123, 124], [125, 126], [127, 128], [129, 133], [134, 136], [137, 147], [148, 152], [153, 163], [164, 168], [169, 171], [172, 180], [181, 185], [186, 187], [188, 200], [201, 202], [202, 206], [206, 207], [208, 209], [209, 210], [211, 212], [212, 213], [213, 214], [214, 215], [216, 217], [218, 222], [222, 223]]}
{"doc_key": "ai-dev-332", "ner": [[3, 4, "misc"], [9, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 9, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "particular", ",", "the", "RLS", "is", "designed", "to", "minimise", "the", "root", "mean", "square", "error", "between", "predicted", "values", "and", "TRUE", "labels", ",", "subject", "to", "regularity", "."], "sentence-detokenized": "In particular, the RLS is designed to minimise the root mean square error between predicted values and TRUE labels, subject to regularity.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 22], [23, 25], [26, 34], [35, 37], [38, 46], [47, 50], [51, 55], [56, 60], [61, 67], [68, 73], [74, 81], [82, 91], [92, 98], [99, 102], [103, 107], [108, 114], [114, 115], [116, 123], [124, 126], [127, 137], [137, 138]]}
{"doc_key": "ai-dev-333", "ner": [[4, 6, "algorithm"], [9, 10, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Essentially", ",", "this", "combines", "maximum", "likelihood", "estimation", "with", "a", "regularisation", "procedure", "that", "favours", "simpler", "models", "over", "more", "complex", "ones", "."], "sentence-detokenized": "Essentially, this combines maximum likelihood estimation with a regularisation procedure that favours simpler models over more complex ones.", "token2charspan": [[0, 11], [11, 12], [13, 17], [18, 26], [27, 34], [35, 45], [46, 56], [57, 61], [62, 63], [64, 78], [79, 88], [89, 93], [94, 101], [102, 109], [110, 116], [117, 121], [122, 126], [127, 134], [135, 139], [139, 140]]}
{"doc_key": "ai-dev-334", "ner": [[0, 3, "metrics"], [9, 9, "metrics"], [11, 11, "metrics"], [13, 15, "misc"], [18, 19, "misc"], [31, 36, "algorithm"], [37, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 9, 0, 3, "named", "", false, false], [11, 11, 0, 3, "named", "", false, false], [13, 15, 18, 19, "related-to", "", false, false], [13, 15, 31, 36, "related-to", "ratio", false, false], [31, 36, 37, 38, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "true", "alarm", "rate", "is", "also", "known", "as", "the", "sensitivity", ",", "recall", "or", "probability", "of", "detection", "maths", "to", "discrimination", "threshold", ")", "of", "the", "probability", "of", "detection", "on", "the", "y", "-axis", "versus", "the", "cumulative", "probability", "distribution", "function", "of", "false", "alarms", "on", "the", "x-", "axis", "."], "sentence-detokenized": "The true alarm rate is also known as the sensitivity, recall or probability of detection maths to discrimination threshold) of the probability of detection on the y-axis versus the cumulative probability distribution function of false alarms on the x-axis.", "token2charspan": [[0, 3], [4, 8], [9, 14], [15, 19], [20, 22], [23, 27], [28, 33], [34, 36], [37, 40], [41, 52], [52, 53], [54, 60], [61, 63], [64, 75], [76, 78], [79, 88], [89, 94], [95, 97], [98, 112], [113, 122], [122, 123], [124, 126], [127, 130], [131, 142], [143, 145], [146, 155], [156, 158], [159, 162], [163, 164], [164, 169], [170, 176], [177, 180], [181, 191], [192, 203], [204, 216], [217, 225], [226, 228], [229, 234], [235, 241], [242, 244], [245, 248], [249, 251], [251, 255], [255, 256]]}
{"doc_key": "ai-dev-335", "ner": [[1, 1, "misc"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 10, 1, 1, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "English", ",", "an", "example", "of", "the", "Semantic", "Web", "is", "WordNet", "."], "sentence-detokenized": "In English, an example of the Semantic Web is WordNet.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 14], [15, 22], [23, 25], [26, 29], [30, 38], [39, 42], [43, 45], [46, 53], [53, 54]]}
{"doc_key": "ai-dev-336", "ner": [[3, 6, "product"], [9, 10, "product"], [23, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 24, 3, 6, "usage", "", false, false], [23, 24, 9, 10, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolonged", "use", "of", "speech", "recognition", "software", "in", "combination", "with", "word", "processors", "has", "shown", "benefits", "for", "short", "-", "term", "memory", "enhancement", "in", "patients", "with", "brain", "AVMs", "who", "were", "treated", "with", "resection", "."], "sentence-detokenized": "Prolonged use of speech recognition software in combination with word processors has shown benefits for short-term memory enhancement in patients with brain AVMs who were treated with resection.", "token2charspan": [[0, 9], [10, 13], [14, 16], [17, 23], [24, 35], [36, 44], [45, 47], [48, 59], [60, 64], [65, 69], [70, 80], [81, 84], [85, 90], [91, 99], [100, 103], [104, 109], [109, 110], [110, 114], [115, 121], [122, 133], [134, 136], [137, 145], [146, 150], [151, 156], [157, 161], [162, 165], [166, 170], [171, 178], [179, 183], [184, 193], [193, 194]]}
{"doc_key": "ai-dev-337", "ner": [[8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Its", "founding", "editors", "-", "in", "-", "chief", "were", "Ron", "Sun", ",", "Vasant", "Honavar", "and", "Gregg", "Oden", "(", "from", "1999", "to", "2014", ")", "."], "sentence-detokenized": "Its founding editors-in-chief were Ron Sun, Vasant Honavar and Gregg Oden (from 1999 to 2014).", "token2charspan": [[0, 3], [4, 12], [13, 20], [20, 21], [21, 23], [23, 24], [24, 29], [30, 34], [35, 38], [39, 42], [42, 43], [44, 50], [51, 58], [59, 62], [63, 68], [69, 73], [74, 75], [75, 79], [80, 84], [85, 87], [88, 92], [92, 93], [93, 94]]}
{"doc_key": "ai-dev-338", "ner": [[9, 26, "product"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 26, 16, 17, "opposite", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Their", "'", "parallel", "'", "distinction", ",", "as", "opposed", "to", "a", "serial", "manipulator", ",", "is", "that", "the", "end", "effector", "(", "or", "'", "arm", "'", ")", "of", "this", "manipulator", "(", "or", "'", "arm", "'", ")", "is", "directly", "connected", "to", "its", "base", "by", "a", "series", "of", "(", "usually", "three", "or", "six", ")", "separate", "and", "independent", "connections", "operating", "simultaneously", "."], "sentence-detokenized": "Their 'parallel' distinction, as opposed to a serial manipulator, is that the end effector (or 'arm') of this manipulator (or 'arm') is directly connected to its base by a series of (usually three or six) separate and independent connections operating simultaneously.", "token2charspan": [[0, 5], [6, 7], [7, 15], [15, 16], [17, 28], [28, 29], [30, 32], [33, 40], [41, 43], [44, 45], [46, 52], [53, 64], [64, 65], [66, 68], [69, 73], [74, 77], [78, 81], [82, 90], [91, 92], [92, 94], [95, 96], [96, 99], [99, 100], [100, 101], [102, 104], [105, 109], [110, 121], [122, 123], [123, 125], [126, 127], [127, 130], [130, 131], [131, 132], [133, 135], [136, 144], [145, 154], [155, 157], [158, 161], [162, 166], [167, 169], [170, 171], [172, 178], [179, 181], [182, 183], [183, 190], [191, 196], [197, 199], [200, 203], [203, 204], [205, 213], [214, 217], [218, 229], [230, 241], [242, 251], [252, 266], [266, 267]]}
{"doc_key": "ai-dev-339", "ner": [[5, 6, "researcher"], [15, 16, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "thesis", "advisor", "was", "Professor", "Cordell", "Green", "and", "his", "thesis", "/", "oral", "committee", "included", "Professors", "Edward", "Feigenbaum", "Joshua", "Lederberg", ",", "Paul", "Cohen", ",", "Allen", "Newell", ",", "Herbert", "Simon", ",", "."], "sentence-detokenized": "His thesis advisor was Professor Cordell Green and his thesis/oral committee included Professors Edward Feigenbaum Joshua Lederberg, Paul Cohen, Allen Newell, Herbert Simon,.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 22], [23, 32], [33, 40], [41, 46], [47, 50], [51, 54], [55, 61], [61, 62], [62, 66], [67, 76], [77, 85], [86, 96], [97, 103], [104, 114], [115, 121], [122, 131], [131, 132], [133, 137], [138, 143], [143, 144], [145, 150], [151, 157], [157, 158], [159, 166], [167, 172], [172, 173], [173, 174]]}
{"doc_key": "ai-dev-340", "ner": [[3, 5, "metrics"], [7, 10, "metrics"], [12, 14, "metrics"], [16, 21, "metrics"], [25, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "functions", "include", "mean", "squared", "error", ",", "root", "mean", "squared", "error", ",", "mean", "absolute", "error", ",", "relative", "square", "error", ",", "relative", "square", "root", "error", ",", "absolute", "relative", "error", "and", "others", "."], "sentence-detokenized": "Such functions include mean squared error, root mean squared error, mean absolute error, relative square error, relative square root error, absolute relative error and others.", "token2charspan": [[0, 4], [5, 14], [15, 22], [23, 27], [28, 35], [36, 41], [41, 42], [43, 47], [48, 52], [53, 60], [61, 66], [66, 67], [68, 72], [73, 81], [82, 87], [87, 88], [89, 97], [98, 104], [105, 110], [110, 111], [112, 120], [121, 127], [128, 132], [133, 138], [138, 139], [140, 148], [149, 157], [158, 163], [164, 167], [168, 174], [174, 175]]}
{"doc_key": "ai-dev-341", "ner": [[4, 4, "programlang"], [6, 6, "programlang"], [8, 8, "product"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "bindings", "in", "Python", ",", "Java", "and", "MATLAB", "/", "OCTAVE", "."], "sentence-detokenized": "There are bindings in Python, Java and MATLAB / OCTAVE.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 21], [22, 28], [28, 29], [30, 34], [35, 38], [39, 45], [46, 47], [48, 54], [54, 55]]}
{"doc_key": "ai-dev-342", "ner": [[3, 3, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "implementation", "in", "MATLAB", "can", "be", "found", "at", "."], "sentence-detokenized": "An implementation in MATLAB can be found at.", "token2charspan": [[0, 2], [3, 17], [18, 20], [21, 27], [28, 31], [32, 34], [35, 40], [41, 43], [43, 44]]}
{"doc_key": "ai-dev-343", "ner": [[0, 1, "researcher"], [9, 10, "field"], [14, 15, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 10, 0, 1, "origin", "", false, false], [9, 10, 14, 15, "origin", "", false, false], [9, 10, 17, 18, "origin", "", false, false], [9, 10, 20, 21, "origin", "", false, false], [9, 10, 23, 26, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["John", "McCarthy", "is", "one", "of", "the", "founding", "fathers", "of", "artificial", "intelligence", ",", "along", "with", "Alan", "Turing", ",", "Marvin", "Minsky", ",", "Allen", "Newell", "and", "Herbert", "A", ".", "Simon", "."], "sentence-detokenized": "John McCarthy is one of the founding fathers of artificial intelligence, along with Alan Turing, Marvin Minsky, Allen Newell and Herbert A. Simon.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 23], [24, 27], [28, 36], [37, 44], [45, 47], [48, 58], [59, 71], [71, 72], [73, 78], [79, 83], [84, 88], [89, 95], [95, 96], [97, 103], [104, 110], [110, 111], [112, 117], [118, 124], [125, 128], [129, 136], [137, 138], [138, 139], [140, 145], [145, 146]]}
{"doc_key": "ai-dev-344", "ner": [[10, 11, "product"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "parallel", "manipulator", "is", "a", "mechanical", "system", "that", "uses", "several", "serial", "manipulators", "to", "operate", "a", "single", "platform", "or", "end", "effector", "."], "sentence-detokenized": "A parallel manipulator is a mechanical system that uses several serial manipulators to operate a single platform or end effector.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 27], [28, 38], [39, 45], [46, 50], [51, 55], [56, 63], [64, 70], [71, 83], [84, 86], [87, 94], [95, 96], [97, 103], [104, 112], [113, 115], [116, 119], [120, 128], [128, 129]]}
{"doc_key": "ai-dev-345", "ner": [[0, 0, "product"], [3, 4, "task"], [7, 7, "product"], [9, 15, "product"], [27, 27, "misc"], [29, 29, "misc"], [31, 32, "misc"], [34, 38, "task"], [41, 44, "product"], [46, 47, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 7, 0, 0, "part-of", "", false, false], [7, 7, 3, 4, "type-of", "", false, false], [9, 15, 7, 7, "named", "", false, false], [27, 27, 7, 7, "part-of", "", false, false], [29, 29, 7, 7, "part-of", "", false, false], [31, 32, 7, 7, "part-of", "", false, false], [34, 38, 7, 7, "part-of", "", false, false], [41, 44, 7, 7, "part-of", "", false, false], [46, 47, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["GATE", "includes", "an", "information", "extraction", "system", "called", "ANNIE", "(", "A", "Nearly", "-", "New", "Information", "Extraction", "System", ")", ",", "which", "is", "a", "set", "of", "modules", "consisting", "of", "a", "tokeniser", ",", "gazetteer", ",", "sentence", "divider", ",", "part", "-", "of", "-", "speech", "tagger", ",", "named", "entity", "recognition", "transducer", "and", "core", "tagger", "."], "sentence-detokenized": "GATE includes an information extraction system called ANNIE (A Nearly-New Information Extraction System), which is a set of modules consisting of a tokeniser, gazetteer, sentence divider, part-of-speech tagger, named entity recognition transducer and core tagger.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 28], [29, 39], [40, 46], [47, 53], [54, 59], [60, 61], [61, 62], [63, 69], [69, 70], [70, 73], [74, 85], [86, 96], [97, 103], [103, 104], [104, 105], [106, 111], [112, 114], [115, 116], [117, 120], [121, 123], [124, 131], [132, 142], [143, 145], [146, 147], [148, 157], [157, 158], [159, 168], [168, 169], [170, 178], [179, 186], [186, 187], [188, 192], [192, 193], [193, 195], [195, 196], [196, 202], [203, 209], [209, 210], [211, 216], [217, 223], [224, 235], [236, 246], [247, 250], [251, 255], [256, 262], [262, 263]]}
{"doc_key": "ai-dev-346", "ner": [[3, 5, "university"], [26, 27, "country"], [17, 22, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "graduated", "from", "Moscow", "State", "University", "and", "in", "November", "1978", ",", "thanks", "to", "the", "personal", "intervention", "of", "Senator", "Edward", "M.", "Kennedy", ",", "he", "left", "for", "the", "United", "States", "...."], "sentence-detokenized": "He graduated from Moscow State University and in November 1978, thanks to the personal intervention of Senator Edward M. Kennedy, he left for the United States....", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 24], [25, 30], [31, 41], [42, 45], [46, 48], [49, 57], [58, 62], [62, 63], [64, 70], [71, 73], [74, 77], [78, 86], [87, 99], [100, 102], [103, 110], [111, 117], [118, 120], [121, 128], [128, 129], [130, 132], [133, 137], [138, 141], [142, 145], [146, 152], [153, 159], [159, 163]]}
{"doc_key": "ai-dev-347", "ner": [[3, 6, "organisation"], [8, 13, "misc"], [18, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 6, 8, 13, "win-defeat", "", false, false], [8, 13, 18, 18, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2017", ",", "the", "DeepMind", "AlphaGo", "team", "received", "the", "inaugural", "IJCAI", "Marvin", "Minsky", "Medal", "for", "Outstanding", "Achievement", "in", "AI", "."], "sentence-detokenized": "In 2017, the DeepMind AlphaGo team received the inaugural IJCAI Marvin Minsky Medal for Outstanding Achievement in AI.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 21], [22, 29], [30, 34], [35, 43], [44, 47], [48, 57], [58, 63], [64, 70], [71, 77], [78, 83], [84, 87], [88, 99], [100, 111], [112, 114], [115, 117], [117, 118]]}
{"doc_key": "ai-dev-348", "ner": [[4, 5, "misc"], [7, 7, "misc"], [12, 12, "misc"], [22, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 7, 7, "related-to", "is_recorded_by", false, false], [7, 7, 12, 12, "cause-effect", "", false, false], [7, 7, 12, 12, "physical", "", false, false], [7, 7, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Other", "ways", "to", "record", "anomalous", "propagation", "include", "troposcatter", "causing", "irregularities", "in", "the", "troposphere", ",", "meteor", "-", "induced", "scattering", ",", "refraction", "in", "ionised", "regions", "and", "layers", "of", "the", "ionosphere", "and", "reflection", "from", "the", "ionosphere", "."], "sentence-detokenized": "Other ways to record anomalous propagation include troposcatter causing irregularities in the troposphere, meteor-induced scattering, refraction in ionised regions and layers of the ionosphere and reflection from the ionosphere.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 20], [21, 30], [31, 42], [43, 50], [51, 63], [64, 71], [72, 86], [87, 89], [90, 93], [94, 105], [105, 106], [107, 113], [113, 114], [114, 121], [122, 132], [132, 133], [134, 144], [145, 147], [148, 155], [156, 163], [164, 167], [168, 174], [175, 177], [178, 181], [182, 192], [193, 196], [197, 207], [208, 212], [213, 216], [217, 227], [227, 228]]}
{"doc_key": "ai-dev-349", "ner": [[0, 2, "field"], [4, 4, "field"], [10, 10, "field"], [12, 13, "field"], [15, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 10, 10, "part-of", "", false, false], [0, 2, 12, 13, "part-of", "", false, false], [0, 2, 15, 16, "part-of", "", false, false], [0, 2, 18, 19, "part-of", "", false, false], [4, 4, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Natural", "language", "processing", "(", "NLP", ")", "is", "a", "field", "of", "linguistics", ",", "computer", "science", ",", "information", "engineering", "and", "artificial", "intelligence", "that", "deals", "with", "the", "interactions", "between", "computers", "and", "human", "(", "natural", ")", "languages", ",", "in", "particular", "how", "to", "program", "computers", "to", "process", "and", "analyse", "large", "amounts", "of", "data", "in", "natural", "language", "."], "sentence-detokenized": "Natural language processing (NLP) is a field of linguistics, computer science, information engineering and artificial intelligence that deals with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyse large amounts of data in natural language.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 29], [29, 32], [32, 33], [34, 36], [37, 38], [39, 44], [45, 47], [48, 59], [59, 60], [61, 69], [70, 77], [77, 78], [79, 90], [91, 102], [103, 106], [107, 117], [118, 130], [131, 135], [136, 141], [142, 146], [147, 150], [151, 163], [164, 171], [172, 181], [182, 185], [186, 191], [192, 193], [193, 200], [200, 201], [202, 211], [211, 212], [213, 215], [216, 226], [227, 230], [231, 233], [234, 241], [242, 251], [252, 254], [255, 262], [263, 266], [267, 274], [275, 280], [281, 288], [289, 291], [292, 296], [297, 299], [300, 307], [308, 316], [316, 317]]}
{"doc_key": "ai-dev-350", "ner": [[6, 7, "organisation"], [9, 10, "organisation"], [12, 14, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "active", "youth", "climate", "groups", "include", "Extinction", "Rebellion", ",", "Sunrise", "Movement", ",", "SustainUS", ",", "and", "others", ",", "working", "both", "internationally", "and", "locally", "."], "sentence-detokenized": "Other active youth climate groups include Extinction Rebellion, Sunrise Movement, SustainUS, and others, working both internationally and locally.", "token2charspan": [[0, 5], [6, 12], [13, 18], [19, 26], [27, 33], [34, 41], [42, 52], [53, 62], [62, 63], [64, 71], [72, 80], [80, 81], [82, 91], [91, 92], [93, 96], [97, 103], [103, 104], [105, 112], [113, 117], [118, 133], [134, 137], [138, 145], [145, 146]]}
