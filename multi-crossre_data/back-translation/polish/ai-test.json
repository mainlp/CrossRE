{"doc_key": "ai-test-1", "ner": [[6, 8, "algorithm"], [10, 11, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "approaches", "to", "generative", "models", "include", "naive", "Bayes", "classifiers", ",", "Gaussian", "mixture", "models", ",", "variational", "autoencoders", "and", "others", "."], "sentence-detokenized": "Typical approaches to generative models include naive Bayes classifiers, Gaussian mixture models, variational autoencoders and others.", "token2charspan": [[0, 7], [8, 18], [19, 21], [22, 32], [33, 39], [40, 47], [48, 53], [54, 59], [60, 71], [71, 72], [73, 81], [82, 89], [90, 96], [96, 97], [98, 109], [110, 122], [123, 126], [127, 133], [133, 134]]}
{"doc_key": "ai-test-2", "ner": [[5, 5, "organisation"], [11, 11, "conference"], [14, 19, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 11, 11, "role", "", false, false], [14, 19, 11, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Finally", ",", "every", "other", "year", "ELRA", "organises", "a", "major", "conference", "called", "LREC", ",", "the", "International", "Language", "Resources", "and", "Evaluation", "Conference", "."], "sentence-detokenized": "Finally, every other year ELRA organises a major conference called LREC, the International Language Resources and Evaluation Conference.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 20], [21, 25], [26, 30], [31, 40], [41, 42], [43, 48], [49, 59], [60, 66], [67, 71], [71, 72], [73, 76], [77, 90], [91, 99], [100, 109], [110, 113], [114, 124], [125, 135], [135, 136]]}
{"doc_key": "ai-test-3", "ner": [[7, 11, "algorithm"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "task", "is", "usually", "to", "derive", "a", "maximum", "likelihood", "estimate", "of", "the", "HMM", "parameters", "given", "the", "output", "sequences", "."], "sentence-detokenized": "The task is usually to derive a maximum likelihood estimate of the HMM parameters given the output sequences.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 19], [20, 22], [23, 29], [30, 31], [32, 39], [40, 50], [51, 59], [60, 62], [63, 66], [67, 70], [71, 81], [82, 87], [88, 91], [92, 98], [99, 108], [108, 109]]}
{"doc_key": "ai-test-4", "ner": [[1, 1, "algorithm"], [4, 6, "algorithm"], [8, 9, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 8, 9, "compare", "", false, false], [4, 6, 8, 9, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Unlike", "neural", "networks", "and", "support", "vector", "machines", ",", "AdaBoost", "'s", "training", "process", "selects", "only", "those", "features", "known", "to", "improve", "the", "predictive", "power", "of", "the", "model", ",", "reducing", "dimensionality", "and", "potentially", "improving", "execution", "time", ",", "as", "irrelevant", "features", "do", "not", "need", "to", "be", "computed", "."], "sentence-detokenized": "Unlike neural networks and support vector machines, AdaBoost's training process selects only those features known to improve the predictive power of the model, reducing dimensionality and potentially improving execution time, as irrelevant features do not need to be computed.", "token2charspan": [[0, 6], [7, 13], [14, 22], [23, 26], [27, 34], [35, 41], [42, 50], [50, 51], [52, 60], [60, 62], [63, 71], [72, 79], [80, 87], [88, 92], [93, 98], [99, 107], [108, 113], [114, 116], [117, 124], [125, 128], [129, 139], [140, 145], [146, 148], [149, 152], [153, 158], [158, 159], [160, 168], [169, 183], [184, 187], [188, 199], [200, 209], [210, 219], [220, 224], [224, 225], [226, 228], [229, 239], [240, 248], [249, 251], [252, 255], [256, 260], [261, 263], [264, 266], [267, 275], [275, 276]]}
{"doc_key": "ai-test-5", "ner": [[0, 0, "misc"], [11, 14, "misc"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 14, "part-of", "", false, false], [11, 14, 15, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Troponymy", "is", "one", "of", "the", "possible", "relationships", "between", "verbs", "in", "the", "semantic", "web", "of", "the", "Word", "Net", "database", "."], "sentence-detokenized": "Troponymy is one of the possible relationships between verbs in the semantic web of the WordNet database.", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 19], [20, 23], [24, 32], [33, 46], [47, 54], [55, 60], [61, 63], [64, 67], [68, 76], [77, 80], [81, 83], [84, 87], [88, 92], [92, 95], [96, 104], [104, 105]]}
{"doc_key": "ai-test-6", "ner": [[8, 9, "task"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 11, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "framework", "language", "is", "a", "technology", "used", "to", "represent", "knowledge", "in", "artificial", "intelligence", "."], "sentence-detokenized": "A framework language is a technology used to represent knowledge in artificial intelligence.", "token2charspan": [[0, 1], [2, 11], [12, 20], [21, 23], [24, 25], [26, 36], [37, 41], [42, 44], [45, 54], [55, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-7", "ner": [[0, 0, "metrics"], [5, 7, "metrics"], [10, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 5, 7, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "the", "Bilingual", "evaluation", "understudy", "in", "calculating", "the", "conciseness", "penalty", ",", "as", "small", "differences", "in", "translation", "length", "do", "not", "affect", "the", "overall", "score", "as", "much", "."], "sentence-detokenized": "NIST also differs from the Bilingual evaluation understudy in calculating the conciseness penalty, as small differences in translation length do not affect the overall score as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 26], [27, 36], [37, 47], [48, 58], [59, 61], [62, 73], [74, 77], [78, 89], [90, 97], [97, 98], [99, 101], [102, 107], [108, 119], [120, 122], [123, 134], [135, 141], [142, 144], [145, 148], [149, 155], [156, 159], [160, 167], [168, 173], [174, 176], [177, 181], [181, 182]]}
{"doc_key": "ai-test-8", "ner": [[14, 15, "algorithm"], [17, 19, "algorithm"], [29, 34, "field"], [40, 40, "algorithm"], [43, 45, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 15, 29, 34, "usage", "", false, false], [17, 19, 29, 34, "usage", "", false, false], [40, 40, 29, 34, "type-of", "", false, false], [43, 45, 29, 34, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "model", "is", "pre-fitted", "to", "the", "training", "dataset", ",", "The", "model", "(", "e.g.", "a", "neural", "network", "or", "naive", "Bayes", "classifier", ")", "is", "trained", "on", "the", "training", "dataset", "using", "a", "supervised", "learning", "method", ",", "for", "example", "using", "optimisation", "methods", "such", "as", "gradient", "descent", "or", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The model is pre-fitted to the training dataset, The model (e.g. a neural network or naive Bayes classifier) is trained on the training dataset using a supervised learning method, for example using optimisation methods such as gradient descent or stochastic gradient descent.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 23], [24, 26], [27, 30], [31, 39], [40, 47], [47, 48], [49, 52], [53, 58], [59, 60], [60, 64], [65, 66], [67, 73], [74, 81], [82, 84], [85, 90], [91, 96], [97, 107], [107, 108], [109, 111], [112, 119], [120, 122], [123, 126], [127, 135], [136, 143], [144, 149], [150, 151], [152, 162], [163, 171], [172, 178], [178, 179], [180, 183], [184, 191], [192, 197], [198, 210], [211, 218], [219, 223], [224, 226], [227, 235], [236, 243], [244, 246], [247, 257], [258, 266], [267, 274], [274, 275]]}
{"doc_key": "ai-test-9", "ner": [[0, 0, "product"], [8, 9, "task"], [11, 11, "task"], [13, 15, "task"], [17, 20, "task"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 0, "usage", "", true, false], [11, 11, 0, 0, "usage", "", true, false], [13, 15, 0, 0, "usage", "", true, false], [17, 20, 0, 0, "usage", "", true, false], [24, 26, 0, 0, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["FrameNet", "has", "been", "used", "in", "applications", "such", "as", "question", "answering", ",", "paraphrasing", ",", "text", "entailment", "recognition", "and", "information", "extraction", ",", "either", "directly", "or", "through", "Semantic", "Role", "Labelling", "tools", "."], "sentence-detokenized": "FrameNet has been used in applications such as question answering, paraphrasing, text entailment recognition and information extraction, either directly or through Semantic Role Labelling tools.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 22], [23, 25], [26, 38], [39, 43], [44, 46], [47, 55], [56, 65], [65, 66], [67, 79], [79, 80], [81, 85], [86, 96], [97, 108], [109, 112], [113, 124], [125, 135], [135, 136], [137, 143], [144, 152], [153, 155], [156, 163], [164, 172], [173, 177], [178, 187], [188, 193], [193, 194]]}
{"doc_key": "ai-test-10", "ner": [[6, 7, "field"], [12, 12, "misc"], [15, 15, "product"], [18, 18, "misc"], [21, 21, "product"], [24, 27, "field"], [28, 28, "product"], [31, 33, "misc"], [36, 36, "product"], [38, 38, "product"], [40, 40, "product"], [43, 44, "misc"], [47, 48, "product"], [50, 51, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[15, 15, 12, 12, "general-affiliation", "", false, false], [21, 21, 18, 18, "general-affiliation", "", false, false], [28, 28, 24, 27, "general-affiliation", "", false, false], [36, 36, 31, 33, "type-of", "", false, false], [38, 38, 31, 33, "type-of", "", false, false], [40, 40, 31, 33, "type-of", "", false, false], [47, 48, 43, 44, "general-affiliation", "", false, false], [50, 51, 43, 44, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["This", "would", "include", "programmes", "such", "as", "data", "analysis", "and", "extraction", "tools", ",", "spreadsheets", "(", "e.g.", "Excel", ")", ",", "databases", "(", "e.g.", "Access", ")", ",", "statistical", "analysis", "(", "e.g.", "SAS", ")", ",", "generalised", "audit", "software", "(", "e.g.", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "business", "intelligence", "(", "e.g.", "Crystal", "Reports", "and", "Business", "Objects", ")", ",", "etc", "."], "sentence-detokenized": "This would include programmes such as data analysis and extraction tools, spreadsheets (e.g. Excel), databases (e.g. Access), statistical analysis (e.g. SAS), generalised audit software (e.g. ACL, Arbutus, EAS), business intelligence (e.g. Crystal Reports and Business Objects), etc.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 29], [30, 34], [35, 37], [38, 42], [43, 51], [52, 55], [56, 66], [67, 72], [72, 73], [74, 86], [87, 88], [88, 92], [93, 98], [98, 99], [99, 100], [101, 110], [111, 112], [112, 116], [117, 123], [123, 124], [124, 125], [126, 137], [138, 146], [147, 148], [148, 152], [153, 156], [156, 157], [157, 158], [159, 170], [171, 176], [177, 185], [186, 187], [187, 191], [192, 195], [195, 196], [197, 204], [204, 205], [206, 209], [209, 210], [210, 211], [212, 220], [221, 233], [234, 235], [235, 239], [240, 247], [248, 255], [256, 259], [260, 268], [269, 276], [276, 277], [277, 278], [279, 282], [282, 283]]}
{"doc_key": "ai-test-11", "ner": [[0, 1, "organisation"], [5, 6, "researcher"], [11, 11, "organisation"], [14, 15, "product"], [21, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 6, "origin", "", false, false], [5, 6, 11, 11, "role", "", false, false], [14, 15, 21, 22, "type-of", "", false, false], [21, 22, 5, 6, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Rethink", "Robotics", "-", "founded", "by", "Rodney", "Brooks", ",", "formerly", "associated", "with", "iRobot", "-", "unveiled", "Baxter", "in", "September", "2012", ";", "as", "an", "industrial", "robot", "designed", "to", "interact", "safely", "with", "neighbouring", "human", "workers", "and", "be", "programmable", "to", "perform", "simple", "tasks", "."], "sentence-detokenized": "Rethink Robotics - founded by Rodney Brooks, formerly associated with iRobot - unveiled Baxter in September 2012; as an industrial robot designed to interact safely with neighbouring human workers and be programmable to perform simple tasks.", "token2charspan": [[0, 7], [8, 16], [17, 18], [19, 26], [27, 29], [30, 36], [37, 43], [43, 44], [45, 53], [54, 64], [65, 69], [70, 76], [77, 78], [79, 87], [88, 94], [95, 97], [98, 107], [108, 112], [112, 113], [114, 116], [117, 119], [120, 130], [131, 136], [137, 145], [146, 148], [149, 157], [158, 164], [165, 169], [170, 182], [183, 188], [189, 196], [197, 200], [201, 203], [204, 216], [217, 219], [220, 227], [228, 234], [235, 240], [240, 241]]}
{"doc_key": "ai-test-12", "ner": [[1, 2, "field"], [6, 6, "task"], [8, 9, "task"], [11, 14, "task"], [16, 19, "task"], [21, 22, "task"], [24, 25, "task"], [28, 33, "task"], [35, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[6, 6, 1, 2, "part-of", "task_part_of_field", false, false], [8, 9, 1, 2, "part-of", "task_part_of_field", false, false], [11, 14, 1, 2, "part-of", "task_part_of_field", false, false], [16, 19, 1, 2, "part-of", "task_part_of_field", false, false], [21, 22, 1, 2, "part-of", "task_part_of_field", false, false], [24, 25, 1, 2, "part-of", "task_part_of_field", false, false], [28, 33, 1, 2, "part-of", "task_part_of_field", false, false], [35, 37, 1, 2, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Typical", "text", "mining", "tasks", "include", "text", "categorisation", ",", "text", "clustering", ",", "concept", "/", "entity", "extraction", ",", "creation", "of", "granular", "taxonomies", ",", "sentiment", "analysis", ",", "document", "summarisation", "and", "entity", "relationship", "modelling", "(", "i.e.", "learning", "relationships", "between", "named", "entity", "recognition", ")", "."], "sentence-detokenized": "Typical text mining tasks include text categorisation, text clustering, concept/entity extraction, creation of granular taxonomies, sentiment analysis, document summarisation and entity relationship modelling (i.e. learning relationships between named entity recognition).", "token2charspan": [[0, 7], [8, 12], [13, 19], [20, 25], [26, 33], [34, 38], [39, 53], [53, 54], [55, 59], [60, 70], [70, 71], [72, 79], [79, 80], [80, 86], [87, 97], [97, 98], [99, 107], [108, 110], [111, 119], [120, 130], [130, 131], [132, 141], [142, 150], [150, 151], [152, 160], [161, 174], [175, 178], [179, 185], [186, 198], [199, 208], [209, 210], [210, 214], [215, 223], [224, 237], [238, 245], [246, 251], [252, 258], [259, 270], [270, 271], [271, 272]]}
{"doc_key": "ai-test-13", "ner": [[5, 5, "metrics"], [8, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nevertheless", ",", "stemming", "reduces", "the", "precision", ",", "or", "TRUE", "negative", "rate", ",", "for", "such", "systems", "."], "sentence-detokenized": "Nevertheless, stemming reduces the precision, or TRUE negative rate, for such systems.", "token2charspan": [[0, 12], [12, 13], [14, 22], [23, 30], [31, 34], [35, 44], [44, 45], [46, 48], [49, 53], [54, 62], [63, 67], [67, 68], [69, 72], [73, 77], [78, 85], [85, 86]]}
{"doc_key": "ai-test-14", "ner": [[4, 5, "task"], [10, 12, "misc"], [18, 19, "misc"], [28, 28, "product"], [30, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 12, 4, 5, "temporal", "", false, false], [18, 19, 10, 12, "named", "", false, false], [28, 28, 10, 12, "usage", "", false, false], [30, 30, 10, 12, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "special", "case", "of", "keyword", "spotting", "is", "the", "detection", "of", "a", "wake", "word", "(", "also", "known", "as", "a", "hot", "word", ")", "used", "by", "personal", "digital", "assistants", "such", "as", "Alexa", "or", "Siri", "to", "wake", "up", "when", "their", "name", "is", "spoken", "."], "sentence-detokenized": "A special case of keyword spotting is the detection of a wake word (also known as a hot word) used by personal digital assistants such as Alexa or Siri to wake up when their name is spoken.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 17], [18, 25], [26, 34], [35, 37], [38, 41], [42, 51], [52, 54], [55, 56], [57, 61], [62, 66], [67, 68], [68, 72], [73, 78], [79, 81], [82, 83], [84, 87], [88, 92], [92, 93], [94, 98], [99, 101], [102, 110], [111, 118], [119, 129], [130, 134], [135, 137], [138, 143], [144, 146], [147, 151], [152, 154], [155, 159], [160, 162], [163, 167], [168, 173], [174, 178], [179, 181], [182, 188], [188, 189]]}
{"doc_key": "ai-test-15", "ner": [[0, 0, "programlang"], [9, 9, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 0, 0, "part-of", "", false, false], [11, 11, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "is", "an", "open", "source", "programming", "language", "that", "combines", "Prolog", "with", "Java", "."], "sentence-detokenized": "Prova is an open source programming language that combines Prolog with Java.", "token2charspan": [[0, 5], [6, 8], [9, 11], [12, 16], [17, 23], [24, 35], [36, 44], [45, 49], [50, 58], [59, 65], [66, 70], [71, 75], [75, 76]]}
{"doc_key": "ai-test-16", "ner": [[3, 6, "organisation"], [9, 9, "organisation"], [16, 18, "product"], [28, 32, "country"], [36, 36, "organisation"], [44, 44, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 6, 9, 9, "part-of", "", false, false], [3, 6, 9, 9, "role", "sells", false, false], [3, 6, 28, 32, "role", "sells_to", false, false], [36, 36, 44, 44, "opposite", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "1987", ",", "Tocibai", "Machine", ",", "a", "subsidiary", "of", "Toshiba", ",", "was", "accused", "of", "illegally", "selling", "CNC", "milling", "machines", "used", "to", "produce", "ultra", "-", "quiet", "submarine", "propellers", "to", "the", "Soviet", "Union", ",", "in", "violation", "of", "the", "CoCom", "Agreement", ",", "an", "international", "embargo", "on", "certain", "COMECON", "countries", "."], "sentence-detokenized": "In 1987, Tocibai Machine, a subsidiary of Toshiba, was accused of illegally selling CNC milling machines used to produce ultra-quiet submarine propellers to the Soviet Union, in violation of the CoCom Agreement, an international embargo on certain COMECON countries.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 24], [24, 25], [26, 27], [28, 38], [39, 41], [42, 49], [49, 50], [51, 54], [55, 62], [63, 65], [66, 75], [76, 83], [84, 87], [88, 95], [96, 104], [105, 109], [110, 112], [113, 120], [121, 126], [126, 127], [127, 132], [133, 142], [143, 153], [154, 156], [157, 160], [161, 167], [168, 173], [173, 174], [175, 177], [178, 187], [188, 190], [191, 194], [195, 200], [201, 210], [210, 211], [212, 214], [215, 228], [229, 236], [237, 239], [240, 247], [248, 255], [256, 265], [265, 266]]}
{"doc_key": "ai-test-17", "ner": [[0, 1, "researcher"], [6, 10, "product"], [20, 24, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 10, 0, 1, "artifact", "", false, false], [6, 10, 20, 24, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Engelberger", "'s", "most", "famous", "invention", ",", "the", "Unimate", "robotic", "industrial", "arm", ",", "was", "among", "the", "first", "people", "inducted", "into", "the", "Robot", "Hall", "of", "Fame", "in", "2003", "."], "sentence-detokenized": "Engelberger's most famous invention, the Unimate robotic industrial arm, was among the first people inducted into the Robot Hall of Fame in 2003.", "token2charspan": [[0, 11], [11, 13], [14, 18], [19, 25], [26, 35], [35, 36], [37, 40], [41, 48], [49, 56], [57, 67], [68, 71], [71, 72], [73, 76], [77, 82], [83, 86], [87, 92], [93, 99], [100, 108], [109, 113], [114, 117], [118, 123], [124, 128], [129, 131], [132, 136], [137, 139], [140, 144], [144, 145]]}
{"doc_key": "ai-test-18", "ner": [[5, 6, "misc"], [10, 10, "misc"], [12, 12, "person"], [22, 23, "field"], [17, 21, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 10, 10, "usage", "", false, false], [12, 12, 22, 23, "role", "", false, false], [22, 23, 17, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Originally", "the", "control", "was", "via", "static", "html", "web", "pages", "using", "CGI", ".", "Dalton", "'s", "work", "introduced", "a", "Java", "-", "based", "interface", "with", "augmented", "reality", ",", "which", "had", "limited", "success", "."], "sentence-detokenized": "Originally the control was via static html web pages using CGI. Dalton's work introduced a Java-based interface with augmented reality, which had limited success.", "token2charspan": [[0, 10], [11, 14], [15, 22], [23, 26], [27, 30], [31, 37], [38, 42], [43, 46], [47, 52], [53, 58], [59, 62], [62, 63], [64, 70], [70, 72], [73, 77], [78, 88], [89, 90], [91, 95], [95, 96], [96, 101], [102, 111], [112, 116], [117, 126], [127, 134], [134, 135], [136, 141], [142, 145], [146, 153], [154, 161], [161, 162]]}
{"doc_key": "ai-test-19", "ner": [[4, 6, "task"], [9, 9, "organisation"], [25, 28, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 9, 9, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["First", "publication", "on", "the", "LMF", "specification", "as", "ratified", "by", "ISO", "(", "this", "paper", "became", "(", "in", "2015", ")", "the", "9th", "most", "cited", "paper", "in", "the", "LREC", "conference", "from", "LREC", "papers", ")", ":"], "sentence-detokenized": "First publication on the LMF specification as ratified by ISO (this paper became (in 2015) the 9th most cited paper in the LREC conference from LREC papers):", "token2charspan": [[0, 5], [6, 17], [18, 20], [21, 24], [25, 28], [29, 42], [43, 45], [46, 54], [55, 57], [58, 61], [62, 63], [63, 67], [68, 73], [74, 80], [81, 82], [82, 84], [85, 89], [89, 90], [91, 94], [95, 98], [99, 103], [104, 109], [110, 115], [116, 118], [119, 122], [123, 127], [128, 138], [139, 143], [144, 148], [149, 155], [155, 156], [156, 157]]}
{"doc_key": "ai-test-20", "ner": [[0, 2, "metrics"], [14, 16, "metrics"], [17, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 16, 0, 2, "usage", "", false, false], [14, 16, 17, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "confusion", "matrix", "or", "fit", "matrix", "is", "often", "used", "as", "a", "tool", "to", "validate", "the", "accuracy", "of", "k", "-", "NN", "classification", "."], "sentence-detokenized": "The confusion matrix or fit matrix is often used as a tool to validate the accuracy of k -NN classification.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 23], [24, 27], [28, 34], [35, 37], [38, 43], [44, 48], [49, 51], [52, 53], [54, 58], [59, 61], [62, 70], [71, 74], [75, 83], [84, 86], [87, 88], [89, 90], [90, 92], [93, 107], [107, 108]]}
{"doc_key": "ai-test-21", "ner": [[1, 1, "algorithm"], [11, 11, "field"], [13, 14, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 11, 11, "part-of", "", false, false], [1, 1, 13, 14, "part-of", "", false, false], [1, 1, 16, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", "is", "one", "approach", "to", "predictive", "modelling", "used", "in", "statistics", ",", "data", "mining", "and", "machine", "learning", "."], "sentence-detokenized": "Decision tree learning is one approach to predictive modelling used in statistics, data mining and machine learning.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 25], [26, 29], [30, 38], [39, 41], [42, 52], [53, 62], [63, 67], [68, 70], [71, 81], [81, 82], [83, 87], [88, 94], [95, 98], [99, 106], [107, 115], [115, 116]]}
{"doc_key": "ai-test-22", "ner": [[6, 6, "misc"], [14, 15, "field"], [19, 21, "algorithm"], [23, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 14, 15, "related-to", "", true, false], [19, 21, 14, 15, "type-of", "", false, false], [23, 23, 14, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["At", "runtime", ",", "the", "target", "sentence", "prosody", "is", "superimposed", "on", "these", "minimal", "units", "using", "signal", "processing", "techniques", "such", "as", "linear", "predictive", "coding", ",", "PSOLA"], "sentence-detokenized": "At runtime, the target sentence prosody is superimposed on these minimal units using signal processing techniques such as linear predictive coding, PSOLA", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 22], [23, 31], [32, 39], [40, 42], [43, 55], [56, 58], [59, 64], [65, 72], [73, 78], [79, 84], [85, 91], [92, 102], [103, 113], [114, 118], [119, 121], [122, 128], [129, 139], [140, 146], [146, 147], [148, 153]]}
{"doc_key": "ai-test-23", "ner": [[3, 4, "field"], [6, 7, "field"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 3, 4, "usage", "", true, false], [17, 18, 6, 7, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "approach", "uses", "artificial", "intelligence", "and", "machine", "learning", "to", "allow", "researchers", "to", "visibly", "compare", "conventional", "and", "thermal", "facial", "images", "."], "sentence-detokenized": "This approach uses artificial intelligence and machine learning to allow researchers to visibly compare conventional and thermal facial images.", "token2charspan": [[0, 4], [5, 13], [14, 18], [19, 29], [30, 42], [43, 46], [47, 54], [55, 63], [64, 66], [67, 72], [73, 84], [85, 87], [88, 95], [96, 103], [104, 116], [117, 120], [121, 128], [129, 135], [136, 142], [142, 143]]}
{"doc_key": "ai-test-24", "ner": [[1, 2, "field"], [4, 5, "algorithm"], [10, 11, "task"], [15, 16, "misc"], [22, 23, "field"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 1, 2, "part-of", "", false, false], [4, 5, 10, 11, "topic", "", false, false], [10, 11, 15, 16, "origin", "", false, false], [22, 23, 1, 2, "part-of", "", false, false], [22, 23, 4, 5, "topic", "", false, false], [25, 26, 1, 2, "part-of", "", false, false], [25, 26, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "computer", "science", ",", "evolutionary", "computing", "is", "a", "family", "of", "global", "optimisation", "algorithms", "inspired", "by", "biological", "evolution", ",", "and", "a", "subfield", "of", "artificial", "intelligence", "and", "soft", "computing", "studies", "these", "algorithms", "."], "sentence-detokenized": "In computer science, evolutionary computing is a family of global optimisation algorithms inspired by biological evolution, and a subfield of artificial intelligence and soft computing studies these algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 33], [34, 43], [44, 46], [47, 48], [49, 55], [56, 58], [59, 65], [66, 78], [79, 89], [90, 98], [99, 101], [102, 112], [113, 122], [122, 123], [124, 127], [128, 129], [130, 138], [139, 141], [142, 152], [153, 165], [166, 169], [170, 174], [175, 184], [185, 192], [193, 198], [199, 209], [209, 210]]}
{"doc_key": "ai-test-25", "ner": [[8, 9, "metrics"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "some", "measure", "based", "on", "the", "confusion", "matrix", "could", "be", "combined", "with", "the", "mean", "square", "error", "assessed", "between", "the", "raw", "model", "outputs", "and", "the", "actual", "values", "."], "sentence-detokenized": "For example, some measure based on the confusion matrix could be combined with the mean square error assessed between the raw model outputs and the actual values.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [18, 25], [26, 31], [32, 34], [35, 38], [39, 48], [49, 55], [56, 61], [62, 64], [65, 73], [74, 78], [79, 82], [83, 87], [88, 94], [95, 100], [101, 109], [110, 117], [118, 121], [122, 125], [126, 131], [132, 139], [140, 143], [144, 147], [148, 154], [155, 161], [161, 162]]}
{"doc_key": "ai-test-26", "ner": [[6, 6, "product"], [9, 9, "researcher"], [5, 5, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 9, 9, "origin", "", false, false], [6, 6, 5, 5, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Most", "are", "results", "of", "the", "word2vec", "model", "developed", "by", "Mikolov", "et", "al", ".", "or", "variants", "thereof", "."], "sentence-detokenized": "Most are results of the word2vec model developed by Mikolov et al. or variants thereof.", "token2charspan": [[0, 4], [5, 8], [9, 16], [17, 19], [20, 23], [24, 32], [33, 38], [39, 48], [49, 51], [52, 59], [60, 62], [63, 65], [65, 66], [67, 69], [70, 78], [79, 86], [86, 87]]}
{"doc_key": "ai-test-27", "ner": [[14, 14, "conference"], [16, 21, "conference"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 23, 16, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "during", "this", "time", "that", "a", "total", "of", "43", "publications", "were", "recognised", "by", "CVPR", "and", "the", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "."], "sentence-detokenized": "It was during this time that a total of 43 publications were recognised by CVPR and the International Conference on Computer Vision (ICCV).", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 23], [24, 28], [29, 30], [31, 36], [37, 39], [40, 42], [43, 55], [56, 60], [61, 71], [72, 74], [75, 79], [80, 83], [84, 87], [88, 101], [102, 112], [113, 115], [116, 124], [125, 131], [132, 133], [133, 137], [137, 138], [138, 139]]}
{"doc_key": "ai-test-28", "ner": [[0, 0, "product"], [12, 12, "field"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 12, 12, "general-affiliation", "platform_for_education_about", false, false], [23, 24, 0, 0, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["AIBO", "has", "often", "been", "used", "as", "a", "low", "-", "cost", "platform", "for", "AI", "education", "and", "research", ",", "as", "it", "integrates", "a", "computer", ",", "computer", "vision", "and", "articulators", "in", "a", "package", "much", "cheaper", "than", "conventional", "research", "robots", "."], "sentence-detokenized": "AIBO has often been used as a low-cost platform for AI education and research, as it integrates a computer, computer vision and articulators in a package much cheaper than conventional research robots.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 19], [20, 24], [25, 27], [28, 29], [30, 33], [33, 34], [34, 38], [39, 47], [48, 51], [52, 54], [55, 64], [65, 68], [69, 77], [77, 78], [79, 81], [82, 84], [85, 95], [96, 97], [98, 106], [106, 107], [108, 116], [117, 123], [124, 127], [128, 140], [141, 143], [144, 145], [146, 153], [154, 158], [159, 166], [167, 171], [172, 184], [185, 193], [194, 200], [200, 201]]}
{"doc_key": "ai-test-29", "ner": [[6, 12, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "served", "as", "Programme", "Chair", "of", "the", "International", "Conference", "on", "Computer", "Vision", "2021", "."], "sentence-detokenized": "She served as Programme Chair of the International Conference on Computer Vision 2021.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 23], [24, 29], [30, 32], [33, 36], [37, 50], [51, 61], [62, 64], [65, 73], [74, 80], [81, 85], [85, 86]]}
{"doc_key": "ai-test-30", "ner": [[0, 0, "researcher"], [7, 7, "organisation"], [16, 16, "organisation"], [24, 25, "organisation"], [36, 39, "product"], [41, 41, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 7, 7, "role", "", false, false], [0, 0, 16, 16, "role", "", true, false], [16, 16, 24, 25, "role", "develops_with", false, false], [36, 39, 16, 16, "artifact", "", false, false], [41, 41, 36, 39, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Scheinman", ",", "after", "receiving", "a", "grant", "from", "Unimation", "to", "develop", "his", "designs", ",", "sold", "them", "to", "Unimation", ",", "which", ",", "with", "the", "support", "of", "General", "Motors", ",", "further", "developed", "them", "and", "then", "marketed", "them", "as", "the", "Programmable", "Universal", "Mounting", "Machine", "(", "PUMA", ")", "."], "sentence-detokenized": "Scheinman, after receiving a grant from Unimation to develop his designs, sold them to Unimation, which, with the support of General Motors, further developed them and then marketed them as the Programmable Universal Mounting Machine (PUMA).", "token2charspan": [[0, 9], [9, 10], [11, 16], [17, 26], [27, 28], [29, 34], [35, 39], [40, 49], [50, 52], [53, 60], [61, 64], [65, 72], [72, 73], [74, 78], [79, 83], [84, 86], [87, 96], [96, 97], [98, 103], [103, 104], [105, 109], [110, 113], [114, 121], [122, 124], [125, 132], [133, 139], [139, 140], [141, 148], [149, 158], [159, 163], [164, 167], [168, 172], [173, 181], [182, 186], [187, 189], [190, 193], [194, 206], [207, 216], [217, 225], [226, 233], [234, 235], [235, 239], [239, 240], [240, 241]]}
{"doc_key": "ai-test-31", "ner": [[6, 9, "task"], [8, 10, "task"], [14, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 6, 9, "general-affiliation", "works_with", false, false], [14, 14, 8, 10, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "overview", "of", "calibration", "methods", "for", "binary", "and", "multi-class", "classification", "tasks", "is", "provided", "by", "Gebel", "(", "2009", ")"], "sentence-detokenized": "An overview of calibration methods for binary and multi-class classification tasks is provided by Gebel (2009)", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 34], [35, 38], [39, 45], [46, 49], [50, 61], [62, 76], [77, 82], [83, 85], [86, 94], [95, 97], [98, 103], [104, 105], [105, 109], [109, 110]]}
{"doc_key": "ai-test-32", "ner": [[7, 9, "task"], [11, 11, "task"], [14, 15, "task"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "involved", "in", "areas", "such", "as", "optical", "character", "recognition", "(", "OCR", ")", ",", "speech", "synthesis", ",", "speech", "recognition", "technology", "and", "electronic", "keyboard", "instruments", "."], "sentence-detokenized": "He is involved in areas such as optical character recognition (OCR), speech synthesis, speech recognition technology and electronic keyboard instruments.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 23], [24, 28], [29, 31], [32, 39], [40, 49], [50, 61], [62, 63], [63, 66], [66, 67], [67, 68], [69, 75], [76, 85], [85, 86], [87, 93], [94, 105], [106, 116], [117, 120], [121, 131], [132, 140], [141, 152], [152, 153]]}
{"doc_key": "ai-test-33", "ner": [[9, 13, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "newer", "and", "cutting", "-", "edge", "techniques", ",", "the", "Kaldi", "toolkit", "can", "be", "used", "."], "sentence-detokenized": "For newer and cutting-edge techniques, the Kaldi toolkit can be used.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 21], [21, 22], [22, 26], [27, 37], [37, 38], [39, 42], [43, 48], [49, 56], [57, 60], [61, 63], [64, 68], [68, 69]]}
{"doc_key": "ai-test-34", "ner": [[0, 2, "researcher"], [8, 10, "organisation"], [15, 20, "organisation"], [21, 22, "organisation"], [24, 26, "researcher"], [29, 39, "organisation"], [37, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 8, 10, "role", "", false, false], [0, 2, 15, 20, "role", "", false, false], [0, 2, 21, 22, "role", "", false, false], [0, 2, 29, 39, "role", "", false, false], [0, 2, 37, 37, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Johnson", "-", "Laird", "is", "a", "Fellow", "of", "the", "American", "Philosophical", "Society", ",", "Fellow", "of", "the", "Royal", "Society", ",", "Fellow", "of", "the", "British", "Academy", ",", "William", "James", "Fellow", "of", "the", "Association", "for", "Psychological", "Science", "and", "Fellow", "of", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Johnson-Laird is a Fellow of the American Philosophical Society, Fellow of the Royal Society, Fellow of the British Academy, William James Fellow of the Association for Psychological Science and Fellow of the Cognitive Science Society.", "token2charspan": [[0, 7], [7, 8], [8, 13], [14, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 41], [42, 55], [56, 63], [63, 64], [65, 71], [72, 74], [75, 78], [79, 84], [85, 92], [92, 93], [94, 100], [101, 103], [104, 107], [108, 115], [116, 123], [123, 124], [125, 132], [133, 138], [139, 145], [146, 148], [149, 152], [153, 164], [165, 168], [169, 182], [183, 190], [191, 194], [195, 201], [202, 204], [205, 208], [209, 218], [219, 226], [227, 234], [234, 235]]}
{"doc_key": "ai-test-35", "ner": [[3, 8, "conference"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 21, "algorithm"], [25, 29, "task"], [31, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 11, 3, 8, "physical", "", false, false], [10, 11, 3, 8, "temporal", "", false, false], [13, 14, 3, 8, "physical", "", false, false], [13, 14, 3, 8, "temporal", "", false, false], [16, 17, 3, 8, "physical", "", false, false], [16, 17, 3, 8, "temporal", "", false, false], [19, 21, 16, 17, "role", "extends", false, false], [25, 29, 16, 17, "role", "extends", false, false], [31, 31, 25, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["At", "the", "2010", "IEEE", "International", "Conference", "on", "Image", "Processing", ",", "Rui", "Hu", ",", "Mark", "Banard", "and", "John", "Collomosse", "extended", "the", "HOG", "descriptor", "for", "use", "in", "sketch", "-", "based", "image", "retrieval", "(", "SBIR", ")", "."], "sentence-detokenized": "At the 2010 IEEE International Conference on Image Processing, Rui Hu, Mark Banard and John Collomosse extended the HOG descriptor for use in sketch-based image retrieval (SBIR).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 30], [31, 41], [42, 44], [45, 50], [51, 61], [61, 62], [63, 66], [67, 69], [69, 70], [71, 75], [76, 82], [83, 86], [87, 91], [92, 102], [103, 111], [112, 115], [116, 119], [120, 130], [131, 134], [135, 138], [139, 141], [142, 148], [148, 149], [149, 154], [155, 160], [161, 170], [171, 172], [172, 176], [176, 177], [177, 178]]}
{"doc_key": "ai-test-36", "ner": [[0, 0, "metrics"], [6, 6, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["BLEU", "uses", "a", "modified", "form", "of", "precision", "to", "compare", "a", "candidate", "translation", "with", "multiple", "reference", "translations", "."], "sentence-detokenized": "BLEU uses a modified form of precision to compare a candidate translation with multiple reference translations.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 20], [21, 25], [26, 28], [29, 38], [39, 41], [42, 49], [50, 51], [52, 61], [62, 73], [74, 78], [79, 87], [88, 97], [98, 110], [110, 111]]}
{"doc_key": "ai-test-37", "ner": [[31, 32, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "the", "case", "of", "a", "general", "math", "base", "space", "(", "Y", ",\u02d9", "mathcal", "{", "B", "},\u02d9", "nu", ")", "/", "math", "(", "i.e.", "a", "base", "space", "that", "is", "not", "countable", ")", ",", "relative", "entropy", "is", "usually", "considered", "."], "sentence-detokenized": "For the case of a general math base space (Y,\u02d9 mathcal {B},\u02d9 nu) / math (i.e. a base space that is not countable), relative entropy is usually considered.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 15], [16, 17], [18, 25], [26, 30], [31, 35], [36, 41], [42, 43], [43, 44], [44, 46], [47, 54], [55, 56], [56, 57], [57, 60], [61, 63], [63, 64], [65, 66], [67, 71], [72, 73], [73, 77], [78, 79], [80, 84], [85, 90], [91, 95], [96, 98], [99, 102], [103, 112], [112, 113], [113, 114], [115, 123], [124, 131], [132, 134], [135, 142], [143, 153], [153, 154]]}
{"doc_key": "ai-test-38", "ner": [[8, 8, "country"], [9, 11, "organisation"], [13, 13, "organisation"], [16, 16, "country"], [17, 18, "organisation"], [20, 20, "organisation"], [24, 26, "organisation"], [28, 29, "country"], [30, 35, "organisation"], [37, 37, "organisation"], [45, 46, "misc"], [44, 44, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[9, 11, 8, 8, "physical", "", false, false], [13, 13, 9, 11, "named", "", false, false], [17, 18, 16, 16, "physical", "", false, false], [20, 20, 17, 18, "named", "", false, false], [30, 35, 28, 29, "physical", "", false, false], [37, 37, 30, 35, "named", "", false, false], [45, 46, 44, 44, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Since", "October", "2011", ",", "existing", "partnerships", "with", "the", "U.S.", "National", "Park", "Service", "(", "NPS", ")", ",", "British", "Historic", "Scotland", "(", "HS", ")", ",", "the", "World", "Monuments", "Fund", "and", "Mexico", "'s", "Instituto", "Nacional", "de", "Antropolog\u00eda", "y", "Historia", "(", "INAH", ")", "have", "been", "significantly", "expanded", ",", "the", "CyArk", "website"], "sentence-detokenized": "Since October 2011, existing partnerships with the U.S. National Park Service (NPS), British Historic Scotland (HS), the World Monuments Fund and Mexico's Instituto Nacional de Antropolog\u00eda y Historia (INAH) have been significantly expanded, the CyArk website", "token2charspan": [[0, 5], [6, 13], [14, 18], [18, 19], [20, 28], [29, 41], [42, 46], [47, 50], [51, 55], [56, 64], [65, 69], [70, 77], [78, 79], [79, 82], [82, 83], [83, 84], [85, 92], [93, 101], [102, 110], [111, 112], [112, 114], [114, 115], [115, 116], [117, 120], [121, 126], [127, 136], [137, 141], [142, 145], [146, 152], [152, 154], [155, 164], [165, 173], [174, 176], [177, 189], [190, 191], [192, 200], [201, 202], [202, 206], [206, 207], [208, 212], [213, 217], [218, 231], [232, 240], [240, 241], [242, 245], [246, 251], [252, 259]]}
{"doc_key": "ai-test-39", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [11, 11, "product"], [13, 13, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 11, 11, "part-of", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [11, 11, 6, 7, "general-affiliation", "", false, false], [13, 13, 6, 7, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kernel", "SVMs", "are", "available", "in", "many", "machine", "learning", "toolkits", ",", "including", "LIBSVM", ",", "MATLAB", "and", "others", "."], "sentence-detokenized": "Kernel SVMs are available in many machine learning toolkits, including LIBSVM, MATLAB and others.", "token2charspan": [[0, 6], [7, 11], [12, 15], [16, 25], [26, 28], [29, 33], [34, 41], [42, 50], [51, 59], [59, 60], [61, 70], [71, 77], [77, 78], [79, 85], [86, 89], [90, 96], [96, 97]]}
{"doc_key": "ai-test-40", "ner": [[2, 4, "misc"], [13, 14, "location"], [16, 16, "location"], [17, 18, "country"], [21, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 13, 14, "physical", "", false, false], [2, 4, 21, 24, "temporal", "", false, false], [13, 14, 16, 16, "physical", "", false, false], [16, 16, 17, 18, "physical", "", false, false], [21, 24, 13, 14, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "2009", "Loebner", "Prize", "competition", "took", "place", "on", "6", "September", "2009", "at", "the", "Brighton", "Centre", ",", "Brighton", "UK", "in", "conjunction", "with", "the", "Interspeech", "2009", "conference", "."], "sentence-detokenized": "The 2009 Loebner Prize competition took place on 6 September 2009 at the Brighton Centre, Brighton UK in conjunction with the Interspeech 2009 conference.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 34], [35, 39], [40, 45], [46, 48], [49, 50], [51, 60], [61, 65], [66, 68], [69, 72], [73, 81], [82, 88], [88, 89], [90, 98], [99, 101], [102, 104], [105, 116], [117, 121], [122, 125], [126, 137], [138, 142], [143, 153], [153, 154]]}
{"doc_key": "ai-test-41", "ner": [[1, 3, "product"], [10, 10, "product"], [17, 19, "product"], [20, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[20, 22, 1, 3, "part-of", "", false, false], [20, 22, 10, 10, "part-of", "", false, false], [20, 22, 17, 19, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "QRIO", "humanoid", "robot", "was", "designed", "as", "a", "successor", "to", "AIBO", "and", "runs", "on", "the", "same", "underlying", "R", "-", "CODE", "Aperios", "operating", "system", "."], "sentence-detokenized": "The QRIO humanoid robot was designed as a successor to AIBO and runs on the same underlying R-CODE Aperios operating system.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 23], [24, 27], [28, 36], [37, 39], [40, 41], [42, 51], [52, 54], [55, 59], [60, 63], [64, 68], [69, 71], [72, 75], [76, 80], [81, 91], [92, 93], [93, 94], [94, 98], [99, 106], [107, 116], [117, 123], [123, 124]]}
{"doc_key": "ai-test-42", "ner": [[0, 2, "misc"], [7, 7, "algorithm"], [12, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 0, 2, "cause-effect", "", true, false], [12, 14, 0, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "speech", "waveforms", "are", "generated", "from", "the", "HMMs", "themselves", "based", "on", "a", "maximum", "likelihood", "criterion", "."], "sentence-detokenized": "The speech waveforms are generated from the HMMs themselves based on a maximum likelihood criterion.", "token2charspan": [[0, 3], [4, 10], [11, 20], [21, 24], [25, 34], [35, 39], [40, 43], [44, 48], [49, 59], [60, 65], [66, 68], [69, 70], [71, 78], [79, 89], [90, 99], [99, 100]]}
{"doc_key": "ai-test-43", "ner": [[0, 1, "product"], [5, 8, "task"], [10, 12, "task"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 5, 8, "type-of", "", false, false], [0, 1, 10, 12, "type-of", "", false, false], [0, 1, 16, 17, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "is", "a", "free", "multilingual", "statistical", "machine", "translation", "and", "neural", "machine", "translation", "service", "developed", "by", "Google", "to", "translate", "text", "and", "web", "pages", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Google Translate is a free multilingual statistical machine translation and neural machine translation service developed by Google to translate text and web pages from one language to another.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 39], [40, 51], [52, 59], [60, 71], [72, 75], [76, 82], [83, 90], [91, 102], [103, 110], [111, 120], [121, 123], [124, 130], [131, 133], [134, 143], [144, 148], [149, 152], [153, 156], [157, 162], [163, 167], [168, 171], [172, 180], [181, 183], [184, 191], [191, 192]]}
{"doc_key": "ai-test-44", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [14, 17, "field"], [21, 23, "task"], [25, 26, "task"], [28, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[21, 23, 5, 6, "part-of", "", false, true], [21, 23, 8, 9, "part-of", "", false, true], [21, 23, 11, 12, "part-of", "", false, true], [25, 26, 5, 6, "part-of", "", false, true], [25, 26, 8, 9, "part-of", "", false, true], [25, 26, 11, 12, "part-of", "", false, true], [28, 31, 5, 6, "part-of", "", false, true], [28, 31, 8, 9, "part-of", "", false, true], [28, 31, 11, 12, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Skeletons", "are", "widely", "used", "in", "computer", "vision", ",", "image", "analysis", ",", "pattern", "recognition", "and", "digital", "image", "processing", "for", "purposes", "such", "as", "optical", "character", "recognition", ",", "fingerprint", "recognition", ",", "visual", "inspection", "or", "compression", "."], "sentence-detokenized": "Skeletons are widely used in computer vision, image analysis, pattern recognition and digital image processing for purposes such as optical character recognition, fingerprint recognition, visual inspection or compression.", "token2charspan": [[0, 9], [10, 13], [14, 20], [21, 25], [26, 28], [29, 37], [38, 44], [44, 45], [46, 51], [52, 60], [60, 61], [62, 69], [70, 81], [82, 85], [86, 93], [94, 99], [100, 110], [111, 114], [115, 123], [124, 128], [129, 131], [132, 139], [140, 149], [150, 161], [161, 162], [163, 174], [175, 186], [186, 187], [188, 194], [195, 205], [206, 208], [209, 220], [220, 221]]}
{"doc_key": "ai-test-45", "ner": [[0, 6, "conference"], [11, 14, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 6, 11, 14, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "is", "a", "benchmark", "in", "object", "classification", "and", "detection", ",", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object classification and detection, with millions of images and hundreds of object classes.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 24], [25, 31], [32, 43], [44, 53], [54, 56], [57, 58], [59, 68], [69, 71], [72, 78], [79, 93], [94, 97], [98, 107], [107, 108], [109, 113], [114, 122], [123, 125], [126, 132], [133, 136], [137, 145], [146, 148], [149, 155], [156, 163], [163, 164]]}
{"doc_key": "ai-test-46", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [16, 19, "misc"], [21, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 16, 19, "part-of", "", false, false], [0, 0, 21, 25, "part-of", "", false, false], [4, 5, 16, 19, "part-of", "", false, false], [4, 5, 21, 25, "part-of", "", false, false], [7, 8, 16, 19, "part-of", "", false, false], [7, 8, 21, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Bengio", ",", "along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "is", "referred", "to", "by", "some", "as", "the", "godfathers", "of", "AI", "and", "the", "godfathers", "of", "Deep", "Learning", "."], "sentence-detokenized": "Bengio, along with Geoffrey Hinton and Yann LeCun, is referred to by some as the godfathers of AI and the godfathers of Deep Learning.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 18], [19, 27], [28, 34], [35, 38], [39, 43], [44, 49], [49, 50], [51, 53], [54, 62], [63, 65], [66, 68], [69, 73], [74, 76], [77, 80], [81, 91], [92, 94], [95, 97], [98, 101], [102, 105], [106, 116], [117, 119], [120, 124], [125, 133], [133, 134]]}
{"doc_key": "ai-test-47", "ner": [[6, 6, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "Life", "Fellow", "of", "IEEE", "."], "sentence-detokenized": "He is a Life Fellow of IEEE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 19], [20, 22], [23, 27], [27, 28]]}
{"doc_key": "ai-test-48", "ner": [[0, 1, "organisation"], [16, 21, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 16, 21, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NSA", "Bethesda", "is", "responsible", "for", "the", "operational", "support", "of", "the", "base", "for", "its", "main", "tenant", ",", "Walter", "Reed", "National", "Military", "Medical", "Center", "."], "sentence-detokenized": "NSA Bethesda is responsible for the operational support of the base for its main tenant, Walter Reed National Military Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 31], [32, 35], [36, 47], [48, 55], [56, 58], [59, 62], [63, 67], [68, 71], [72, 75], [76, 80], [81, 87], [87, 88], [89, 95], [96, 100], [101, 109], [110, 118], [119, 126], [127, 133], [133, 134]]}
{"doc_key": "ai-test-49", "ner": [[6, 7, "field"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "three", "main", "learning", "paradigms", "are", "supervised", "learning", ",", "unsupervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "The three main learning paradigms are supervised learning, unsupervised learning and reinforcement learning.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 23], [24, 33], [34, 37], [38, 48], [49, 57], [57, 58], [59, 71], [72, 80], [81, 84], [85, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-test-50", "ner": [[2, 2, "task"], [4, 6, "task"], [11, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Examples", "include", "control", ",", "planning", "and", "scheduling", ",", "the", "ability", "to", "answer", "diagnostic", "and", "consumer", "questions", ",", "handwriting", "recognition", ",", "natural", "language", "understanding", ",", "speech", "recognition", "and", "facial", "recognition", "."], "sentence-detokenized": "Examples include control, planning and scheduling, the ability to answer diagnostic and consumer questions, handwriting recognition, natural language understanding, speech recognition and facial recognition.", "token2charspan": [[0, 8], [9, 16], [17, 24], [24, 25], [26, 34], [35, 38], [39, 49], [49, 50], [51, 54], [55, 62], [63, 65], [66, 72], [73, 83], [84, 87], [88, 96], [97, 106], [106, 107], [108, 119], [120, 131], [131, 132], [133, 140], [141, 149], [150, 163], [163, 164], [165, 171], [172, 183], [184, 187], [188, 194], [195, 206], [206, 207]]}
{"doc_key": "ai-test-51", "ner": [[9, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1991", ",", "he", "was", "elected", "a", "fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "1990", ",", "founding", "fellow", ")", "."], "sentence-detokenized": "In 1991, he was elected a fellow of the Association for the Advancement of Artificial Intelligence (1990, founding fellow).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [99, 100], [100, 104], [104, 105], [106, 114], [115, 121], [121, 122], [122, 123]]}
{"doc_key": "ai-test-52", "ner": [[8, 9, "misc"], [13, 14, "algorithm"], [25, 28, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "by", "formulating", "the", "problem", "as", "a", "Toeplitz", "matrix", "solution", "and", "using", "Levinson", "recursion", ",", "we", "can", "estimate", "the", "filter", "with", "the", "smallest", "possible", "mean", "-", "square", "error", "relatively", "quickly", "."], "sentence-detokenized": "However, by formulating the problem as a Toeplitz matrix solution and using Levinson recursion, we can estimate the filter with the smallest possible mean-square error relatively quickly.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 23], [24, 27], [28, 35], [36, 38], [39, 40], [41, 49], [50, 56], [57, 65], [66, 69], [70, 75], [76, 84], [85, 94], [94, 95], [96, 98], [99, 102], [103, 111], [112, 115], [116, 122], [123, 127], [128, 131], [132, 140], [141, 149], [150, 154], [154, 155], [155, 161], [162, 167], [168, 178], [179, 186], [186, 187]]}
{"doc_key": "ai-test-53", "ner": [[0, 6, "conference"], [12, 16, "location"], [7, 19, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 6, 12, 16, "physical", "", false, false], [12, 16, 7, 19, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "15th", "edition", "of", "Campus", "Party", "Spain", "will", "be", "held", "at", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", "in", "July", "2011", "."], "sentence-detokenized": "The 15th edition of Campus Party Spain will be held at the City of Arts and Sciences in Valencia in July 2011.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 19], [20, 26], [27, 32], [33, 38], [39, 43], [44, 46], [47, 51], [52, 54], [55, 58], [59, 63], [64, 66], [67, 71], [72, 75], [76, 84], [85, 87], [88, 96], [97, 99], [100, 104], [105, 109], [109, 110]]}
{"doc_key": "ai-test-54", "ner": [[15, 15, "product"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Often", "this", "is", "generally", "only", "possible", "at", "the", "very", "end", "of", "complex", "games", "such", "as", "chess", "or", "go", ",", "because", "it", "is", "not", "computationally", "feasible", "to", "look", "ahead", "as", "far", "as", "the", "end", "of", "the", "game", "except", "towards", "the", "end", ",", "and", "instead", "the", "positions", "are", "given", "finite", "values", "as", "estimates", "of", "the", "degree", "of", "belief", "that", "they", "will", "lead", "to", "victory", "for", "one", "player", "or", "the", "other", "."], "sentence-detokenized": "Often this is generally only possible at the very end of complex games such as chess or go, because it is not computationally feasible to look ahead as far as the end of the game except towards the end, and instead the positions are given finite values as estimates of the degree of belief that they will lead to victory for one player or the other.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 23], [24, 28], [29, 37], [38, 40], [41, 44], [45, 49], [50, 53], [54, 56], [57, 64], [65, 70], [71, 75], [76, 78], [79, 84], [85, 87], [88, 90], [90, 91], [92, 99], [100, 102], [103, 105], [106, 109], [110, 125], [126, 134], [135, 137], [138, 142], [143, 148], [149, 151], [152, 155], [156, 158], [159, 162], [163, 166], [167, 169], [170, 173], [174, 178], [179, 185], [186, 193], [194, 197], [198, 201], [201, 202], [203, 206], [207, 214], [215, 218], [219, 228], [229, 232], [233, 238], [239, 245], [246, 252], [253, 255], [256, 265], [266, 268], [269, 272], [273, 279], [280, 282], [283, 289], [290, 294], [295, 299], [300, 304], [305, 309], [310, 312], [313, 320], [321, 324], [325, 328], [329, 335], [336, 338], [339, 342], [343, 348], [348, 349]]}
{"doc_key": "ai-test-55", "ner": [[3, 46, "algorithm"], [24, 25, "algorithm"], [27, 28, "algorithm"], [31, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 46, 24, 25, "compare", "", false, false], [3, 46, 27, 28, "compare", "", false, false], [3, 46, 31, 33, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "difference", "between", "the", "multinomial", "logit", "model", "and", "the", "numerous", "other", "methods", ",", "models", ",", "algorithms", ",", "etc.", "with", "the", "same", "basic", "configuration", "(", "perceptron", "algorithm", ",", "support", "vector", "machines", ",", "linear", "discriminant", "analysis", ",", "etc.", ")", "is", "the", "difference", "between", "the", "multinomial", "logit", "model", "and", "the", "numerous", "other", "methods", ",", "models", ",", "algorithms", ",", "etc.", "with", "the", "same", "basic", "configuration", "."], "sentence-detokenized": "The difference between the multinomial logit model and the numerous other methods, models, algorithms, etc. with the same basic configuration (perceptron algorithm, support vector machines, linear discriminant analysis, etc.) is the difference between the multinomial logit model and the numerous other methods, models, algorithms, etc. with the same basic configuration.", "token2charspan": [[0, 3], [4, 14], [15, 22], [23, 26], [27, 38], [39, 44], [45, 50], [51, 54], [55, 58], [59, 67], [68, 73], [74, 81], [81, 82], [83, 89], [89, 90], [91, 101], [101, 102], [103, 107], [108, 112], [113, 116], [117, 121], [122, 127], [128, 141], [142, 143], [143, 153], [154, 163], [163, 164], [165, 172], [173, 179], [180, 188], [188, 189], [190, 196], [197, 209], [210, 218], [218, 219], [220, 224], [224, 225], [226, 228], [229, 232], [233, 243], [244, 251], [252, 255], [256, 267], [268, 273], [274, 279], [280, 283], [284, 287], [288, 296], [297, 302], [303, 310], [310, 311], [312, 318], [318, 319], [320, 330], [330, 331], [332, 336], [337, 341], [342, 345], [346, 350], [351, 356], [357, 370], [370, 371]]}
{"doc_key": "ai-test-56", "ner": [[0, 3, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Association", "for", "Computational", "Linguistics", ",", "published", "by", "the"], "sentence-detokenized": "Association for Computational Linguistics, published by the", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [41, 42], [43, 52], [53, 55], [56, 59]]}
{"doc_key": "ai-test-57", "ner": [[3, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "a", "computerised", "face", "recognition", "system", ",", "each", "face", "is", "represented", "by", "a", "large", "number", "of", "pixel", "values", "."], "sentence-detokenized": "In a computerised face recognition system, each face is represented by a large number of pixel values.", "token2charspan": [[0, 2], [3, 4], [5, 17], [18, 22], [23, 34], [35, 41], [41, 42], [43, 47], [48, 52], [53, 55], [56, 67], [68, 70], [71, 72], [73, 78], [79, 85], [86, 88], [89, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-test-58", "ner": [[5, 6, "person"], [13, 15, "organisation"], [22, 22, "country"], [25, 26, "person"], [36, 38, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 13, 15, "role", "", false, false], [5, 6, 22, 22, "physical", "", false, false], [25, 26, 36, 38, "origin", "", false, false], [25, 26, 36, 38, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2002", ",", "his", "son", "Daniel", "Pearl", ",", "a", "journalist", "working", "for", "the", "Wall", "Street", "Journal", ",", "was", "kidnapped", "and", "murdered", "in", "Pakistan", ",", "prompting", "Judea", "and", "other", "family", "members", "and", "friends", "to", "set", "up", "the", "Daniel", "Pearl", "Foundation", "."], "sentence-detokenized": "In 2002, his son Daniel Pearl, a journalist working for the Wall Street Journal, was kidnapped and murdered in Pakistan, prompting Judea and other family members and friends to set up the Daniel Pearl Foundation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 23], [24, 29], [29, 30], [31, 32], [33, 43], [44, 51], [52, 55], [56, 59], [60, 64], [65, 71], [72, 79], [79, 80], [81, 84], [85, 94], [95, 98], [99, 107], [108, 110], [111, 119], [119, 120], [121, 130], [131, 136], [137, 140], [141, 146], [147, 153], [154, 161], [162, 165], [166, 173], [174, 176], [177, 180], [181, 183], [184, 187], [188, 194], [195, 200], [201, 211], [211, 212]]}
{"doc_key": "ai-test-59", "ner": [[4, 6, "organisation"], [17, 18, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 17, 18, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "late", "2006", ",", "Red", "Envelope", "Entertainment", "has", "expanded", "to", "produce", "original", "content", "with", "creators", "such", "as", "John", "Waters", "."], "sentence-detokenized": "Since late 2006, Red Envelope Entertainment has expanded to produce original content with creators such as John Waters.", "token2charspan": [[0, 5], [6, 10], [11, 15], [15, 16], [17, 20], [21, 29], [30, 43], [44, 47], [48, 56], [57, 59], [60, 67], [68, 76], [77, 84], [85, 89], [90, 98], [99, 103], [104, 106], [107, 111], [112, 118], [118, 119]]}
{"doc_key": "ai-test-60", "ner": [[6, 10, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "building", "is", "now", "part", "of", "Beth", "Israel", "Deaconess", "Medical", "Centre", "."], "sentence-detokenized": "The building is now part of Beth Israel Deaconess Medical Centre.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 32], [33, 39], [40, 49], [50, 57], [58, 64], [64, 65]]}
{"doc_key": "ai-test-61", "ner": [[19, 20, "field"], [22, 23, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "common", "theme", "of", "this", "work", "is", "the", "adoption", "of", "a", "sign", "-", "theoretic", "perspective", "on", "issues", "related", "to", "artificial", "intelligence", "and", "knowledge", "representation", "."], "sentence-detokenized": "A common theme of this work is the adoption of a sign-theoretic perspective on issues related to artificial intelligence and knowledge representation.", "token2charspan": [[0, 1], [2, 8], [9, 14], [15, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 43], [44, 46], [47, 48], [49, 53], [53, 54], [54, 63], [64, 75], [76, 78], [79, 85], [86, 93], [94, 96], [97, 107], [108, 120], [121, 124], [125, 134], [135, 149], [149, 150]]}
{"doc_key": "ai-test-62", "ner": [[5, 7, "task"], [9, 9, "task"], [21, 22, "task"], [41, 42, "task"], [44, 45, "task"], [51, 53, "task"], [55, 55, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 7, 21, 22, "type-of", "", false, false], [5, 7, 51, 53, "compare", "", false, false], [5, 7, 51, 53, "opposite", "", false, false], [9, 9, 5, 7, "named", "", false, false], [41, 42, 51, 53, "part-of", "", false, false], [44, 45, 51, 53, "part-of", "", false, false], [51, 53, 21, 22, "type-of", "", false, false], [55, 55, 51, 53, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["For", "example", ",", "the", "term", "neural", "machine", "translation", "(", "NMT", ")", "emphasises", "the", "fact", "that", "deep", "learning", "-", "based", "approaches", "to", "machine", "translation", "directly", "learn", "the", "sequence", "-", "to", "-", "sequence", "transformation", ",", "eliminating", "the", "need", "for", "intermediate", "steps", "such", "as", "word", "alignment", "and", "language", "modelling", ",", "which", "were", "used", "in", "statistical", "machine", "translation", "(", "SMT", ")", "."], "sentence-detokenized": "For example, the term neural machine translation (NMT) emphasises the fact that deep learning-based approaches to machine translation directly learn the sequence-to-sequence transformation, eliminating the need for intermediate steps such as word alignment and language modelling, which were used in statistical machine translation (SMT).", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 36], [37, 48], [49, 50], [50, 53], [53, 54], [55, 65], [66, 69], [70, 74], [75, 79], [80, 84], [85, 93], [93, 94], [94, 99], [100, 110], [111, 113], [114, 121], [122, 133], [134, 142], [143, 148], [149, 152], [153, 161], [161, 162], [162, 164], [164, 165], [165, 173], [174, 188], [188, 189], [190, 201], [202, 205], [206, 210], [211, 214], [215, 227], [228, 233], [234, 238], [239, 241], [242, 246], [247, 256], [257, 260], [261, 269], [270, 279], [279, 280], [281, 286], [287, 291], [292, 296], [297, 299], [300, 311], [312, 319], [320, 331], [332, 333], [333, 336], [336, 337], [337, 338]]}
{"doc_key": "ai-test-63", "ner": [[1, 1, "field"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 6, 7, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Most", "WSD", "research", "is", "done", "using", "Word", "Net", "as", "a", "reference", "sense", "resource", "for", "."], "sentence-detokenized": "Most WSD research is done using WordNet as a reference sense resource for.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 20], [21, 25], [26, 31], [32, 36], [36, 39], [40, 42], [43, 44], [45, 54], [55, 60], [61, 69], [70, 73], [73, 74]]}
{"doc_key": "ai-test-64", "ner": [[2, 3, "misc"], [10, 12, "researcher"], [13, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 12, 2, 3, "general-affiliation", "", false, true], [13, 14, 2, 3, "general-affiliation", "", false, true]], "relations_mapping_to_source": [0, 1], "sentence": ["Notable", "former", "PhD", "students", "and", "postdocs", "from", "his", "group", "are", "Richard", "Zemel", "and", "Zoubin", "Ghahramani", "."], "sentence-detokenized": "Notable former PhD students and postdocs from his group are Richard Zemel and Zoubin Ghahramani.", "token2charspan": [[0, 7], [8, 14], [15, 18], [19, 27], [28, 31], [32, 40], [41, 45], [46, 49], [50, 55], [56, 59], [60, 67], [68, 73], [74, 77], [78, 84], [85, 95], [95, 96]]}
{"doc_key": "ai-test-65", "ner": [[4, 5, "metrics"], [11, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 11, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Each", "prediction", "score", "or", "confusion", "matrix", "instance", "represents", "one", "point", "in", "ROC", "space", "."], "sentence-detokenized": "Each prediction score or confusion matrix instance represents one point in ROC space.", "token2charspan": [[0, 4], [5, 15], [16, 21], [22, 24], [25, 34], [35, 41], [42, 50], [51, 61], [62, 65], [66, 71], [72, 74], [75, 78], [79, 84], [84, 85]]}
{"doc_key": "ai-test-66", "ner": [[3, 3, "researcher"], [8, 9, "researcher"], [11, 12, "researcher"], [20, 21, "product"], [24, 26, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 24, 26, "physical", "", false, false], [8, 9, 24, 26, "physical", "", false, false], [11, 12, 24, 26, "physical", "", false, false], [20, 21, 3, 3, "artifact", "", false, false], [20, 21, 8, 9, "artifact", "", false, false], [20, 21, 11, 12, "artifact", "", false, false], [20, 21, 24, 26, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "1997", ",", "Thrun", ",", "together", "with", "colleagues", "Wolfram", "Burgard", "and", "Dieter", "Fox", ",", "created", "the", "world", "'s", "first", "robotic", "city", "guide", "at", "the", "Deutsches", "Museum", "Bonn", "(", "1997", ")", "."], "sentence-detokenized": "In 1997, Thrun, together with colleagues Wolfram Burgard and Dieter Fox, created the world's first robotic city guide at the Deutsches Museum Bonn (1997).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [14, 15], [16, 24], [25, 29], [30, 40], [41, 48], [49, 56], [57, 60], [61, 67], [68, 71], [71, 72], [73, 80], [81, 84], [85, 90], [90, 92], [93, 98], [99, 106], [107, 111], [112, 117], [118, 120], [121, 124], [125, 134], [135, 141], [142, 146], [147, 148], [148, 152], [152, 153], [153, 154]]}
{"doc_key": "ai-test-67", "ner": [[0, 1, "product"], [7, 7, "misc"], [23, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 0, 1, "part-of", "", false, false], [23, 25, 0, 1, "usage", "", false, false], [27, 28, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Word", "Net", "is", "a", "lexical", "database", "of", "semantic", "relationships", "between", "words", "in", "more", "than", "200", "languages", ".", "it", "s", "main", "applications", "are", "automatic", "natural", "language", "processing", "and", "artificial", "intelligence", "applications", "."], "sentence-detokenized": "WordNet is a lexical database of semantic relationships between words in more than 200 languages. its main applications are automatic natural language processing and artificial intelligence applications.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 32], [33, 41], [42, 55], [56, 63], [64, 69], [70, 72], [73, 77], [78, 82], [83, 86], [87, 96], [96, 97], [98, 100], [100, 101], [102, 106], [107, 119], [120, 123], [124, 133], [134, 141], [142, 150], [151, 161], [162, 165], [166, 176], [177, 189], [190, 202], [202, 203]]}
{"doc_key": "ai-test-68", "ner": [[5, 7, "field"], [11, 15, "conference"], [18, 26, "conference"], [28, 28, "conference"], [31, 33, "conference"], [39, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 15, 5, 7, "topic", "", false, false], [11, 15, 39, 40, "topic", "", false, false], [18, 26, 5, 7, "topic", "", false, false], [18, 26, 39, 40, "topic", "", false, false], [28, 28, 5, 7, "topic", "", false, false], [28, 28, 39, 40, "topic", "", false, false], [31, 33, 5, 7, "topic", "", false, false], [31, 33, 39, 40, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Conferences", "in", "the", "field", "of", "natural", "language", "processing", ",", "such", "as", "the", "Association", "for", "Computational", "Linguistics", ",", "the", "North", "American", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "EMNLP", ",", "and", "HLT", ",", "are", "beginning", "to", "include", "papers", "on", "speech", "processing", "."], "sentence-detokenized": "Conferences in the field of natural language processing, such as the Association for Computational Linguistics, the North American Chapter of the Association for Computational Linguistics, EMNLP, and HLT, are beginning to include papers on speech processing.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 24], [25, 27], [28, 35], [36, 44], [45, 55], [55, 56], [57, 61], [62, 64], [65, 68], [69, 80], [81, 84], [85, 98], [99, 110], [110, 111], [112, 115], [116, 121], [122, 130], [131, 138], [139, 141], [142, 145], [146, 157], [158, 161], [162, 175], [176, 187], [187, 188], [189, 194], [194, 195], [196, 199], [200, 203], [203, 204], [205, 208], [209, 218], [219, 221], [222, 229], [230, 236], [237, 239], [240, 246], [247, 257], [257, 258]]}
{"doc_key": "ai-test-69", "ner": [[3, 3, "programlang"], [20, 22, "misc"], [32, 34, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "set", "of", "Java", "programs", "uses", "a", "lexicon", "to", "work", "on", "varieties", "of", "biomedical", "texts", "by", "associating", "words", "with", "their", "parts", "of", "speech", ",", "which", "can", "be", "helpful", "for", "web", "searches", "or", "electronic", "medical", "records", "."], "sentence-detokenized": "A set of Java programs uses a lexicon to work on varieties of biomedical texts by associating words with their parts of speech, which can be helpful for web searches or electronic medical records.", "token2charspan": [[0, 1], [2, 5], [6, 8], [9, 13], [14, 22], [23, 27], [28, 29], [30, 37], [38, 40], [41, 45], [46, 48], [49, 58], [59, 61], [62, 72], [73, 78], [79, 81], [82, 93], [94, 99], [100, 104], [105, 110], [111, 116], [117, 119], [120, 126], [126, 127], [128, 133], [134, 137], [138, 140], [141, 148], [149, 152], [153, 156], [157, 165], [166, 168], [169, 179], [180, 187], [188, 195], [195, 196]]}
{"doc_key": "ai-test-70", "ner": [[9, 9, "algorithm"], [11, 11, "algorithm"], [12, 13, "algorithm"], [15, 15, "algorithm"], [17, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "a", "number", "of", "newer", "algorithms", "such", "as", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", ",", ",", ",", ",", ",", "and", "others", "."], "sentence-detokenized": "There are a number of newer algorithms such as LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost,,,,, and others.", "token2charspan": [[0, 5], [6, 9], [10, 11], [12, 18], [19, 21], [22, 27], [28, 38], [39, 43], [44, 46], [47, 54], [54, 55], [56, 66], [66, 67], [68, 78], [78, 79], [80, 87], [87, 88], [89, 98], [98, 99], [99, 100], [100, 101], [101, 102], [102, 103], [104, 107], [108, 114], [114, 115]]}
{"doc_key": "ai-test-71", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "implementation", "in", "Python", ":"], "sentence-detokenized": "This is an example implementation in Python:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 33], [34, 36], [37, 43], [43, 44]]}
{"doc_key": "ai-test-72", "ner": [[0, 0, "organisation"], [1, 2, "product"], [7, 9, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 0, 0, "artifact", "made_by_company", false, false], [7, 9, 1, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Mattel", "'s", "Intellivision", "games", "console", "offered", "the", "Intellivoice", "voice", "synthesis", "module", "in", "1982", "."], "sentence-detokenized": "Mattel's Intellivision games console offered the Intellivoice voice synthesis module in 1982.", "token2charspan": [[0, 6], [6, 8], [9, 22], [23, 28], [29, 36], [37, 44], [45, 48], [49, 61], [62, 67], [68, 77], [78, 84], [85, 87], [88, 92], [92, 93]]}
{"doc_key": "ai-test-73", "ner": [[5, 6, "task"], [10, 17, "task"], [20, 20, "field"], [22, 24, "task"], [27, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 17, 5, 6, "part-of", "", false, false], [20, 20, 5, 6, "part-of", "", false, false], [22, 24, 5, 6, "part-of", "", false, false], [27, 31, 22, 24, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "has", "also", "worked", "on", "machine", "translation", ",", "both", "on", "knowledge", "-", "based", "MT", "with", "high", "accuracy", "and", "on", "machine", "learning", "for", "statistical", "machine", "translation", "(", "e.g.", "MT", "based", "on", "generalised", "examples", ")", "."], "sentence-detokenized": "He has also worked on machine translation, both on knowledge-based MT with high accuracy and on machine learning for statistical machine translation (e.g. MT based on generalised examples).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 21], [22, 29], [30, 41], [41, 42], [43, 47], [48, 50], [51, 60], [60, 61], [61, 66], [67, 69], [70, 74], [75, 79], [80, 88], [89, 92], [93, 95], [96, 103], [104, 112], [113, 116], [117, 128], [129, 136], [137, 148], [149, 150], [150, 154], [155, 157], [158, 163], [164, 166], [167, 178], [179, 187], [187, 188], [188, 189]]}
{"doc_key": "ai-test-74", "ner": [[0, 1, "misc"], [7, 7, "misc"], [26, 27, "algorithm"], [29, 30, "field"], [32, 33, "field"], [35, 35, "field"], [37, 38, "field"], [40, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 26, 27, "general-affiliation", "", false, false], [0, 1, 29, 30, "general-affiliation", "", false, false], [0, 1, 32, 33, "general-affiliation", "", false, false], [0, 1, 35, 35, "general-affiliation", "", false, false], [0, 1, 37, 38, "general-affiliation", "", false, false], [0, 1, 40, 40, "general-affiliation", "", false, false], [7, 7, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "usually", "referred", "to", "as", "Mathematica", ")", "is", "a", "state", "-", "of", "-", "the", "-", "art", "computing", "system", "covering", "most", "technical", "fields", "-", "including", "neural", "networks", ",", "machine", "learning", ",", "image", "processing", ",", "geometry", ",", "data", "science", ",", "visualisation", "and", "more", "."], "sentence-detokenized": "Wolfram Mathematica (usually referred to as Mathematica) is a state-of-the-art computing system covering most technical fields - including neural networks, machine learning, image processing, geometry, data science, visualisation and more.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 28], [29, 37], [38, 40], [41, 43], [44, 55], [55, 56], [57, 59], [60, 61], [62, 67], [67, 68], [68, 70], [70, 71], [71, 74], [74, 75], [75, 78], [79, 88], [89, 95], [96, 104], [105, 109], [110, 119], [120, 126], [127, 128], [129, 138], [139, 145], [146, 154], [154, 155], [156, 163], [164, 172], [172, 173], [174, 179], [180, 190], [190, 191], [192, 200], [200, 201], [202, 206], [207, 214], [214, 215], [216, 229], [230, 233], [234, 238], [238, 239]]}
{"doc_key": "ai-test-75", "ner": [[2, 6, "product"], [10, 11, "researcher"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 17, 2, 6, "type-of", "", false, false], [17, 17, 10, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "digitally", "controlled", "and", "programmable", "robot", "was", "invented", "by", "George", "Devol", "in", "1954", "and", "eventually", "named", "Unimate", "."], "sentence-detokenized": "The first digitally controlled and programmable robot was invented by George Devol in 1954 and eventually named Unimate.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 30], [31, 34], [35, 47], [48, 53], [54, 57], [58, 66], [67, 69], [70, 76], [77, 82], [83, 85], [86, 90], [91, 94], [95, 105], [106, 111], [112, 119], [119, 120]]}
{"doc_key": "ai-test-76", "ner": [[1, 1, "algorithm"], [3, 3, "algorithm"], [16, 17, "task"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 3, 3, "compare", "", false, false], [3, 3, 16, 17, "general-affiliation", "", false, false], [3, 3, 19, 20, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Like", "DBNs", ",", "DBMs", "can", "learn", "complex", "and", "abstract", "internal", "input", "representations", "in", "tasks", "such", "as", "object", "recognition", "or", "speech", "recognition", ",", "using", "limited", "labelled", "data", "to", "tune", "representations", "built", "using", "a", "large", "set", "of", "unlabelled", "sensory", "input", "data", "."], "sentence-detokenized": "Like DBNs, DBMs can learn complex and abstract internal input representations in tasks such as object recognition or speech recognition, using limited labelled data to tune representations built using a large set of unlabelled sensory input data.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 15], [16, 19], [20, 25], [26, 33], [34, 37], [38, 46], [47, 55], [56, 61], [62, 77], [78, 80], [81, 86], [87, 91], [92, 94], [95, 101], [102, 113], [114, 116], [117, 123], [124, 135], [135, 136], [137, 142], [143, 150], [151, 159], [160, 164], [165, 167], [168, 172], [173, 188], [189, 194], [195, 200], [201, 202], [203, 208], [209, 212], [213, 215], [216, 226], [227, 234], [235, 240], [241, 245], [245, 246]]}
{"doc_key": "ai-test-77", "ner": [[6, 10, "task"], [12, 12, "conference"], [14, 14, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 12, 6, 10, "topic", "", false, false], [14, 14, 6, 10, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Scientific", "conferences", "with", "frequent", "papers", "on", "vision", "-", "based", "activity", "recognition", "are", "ICCV", "and", "CVPR", "."], "sentence-detokenized": "Scientific conferences with frequent papers on vision-based activity recognition are ICCV and CVPR.", "token2charspan": [[0, 10], [11, 22], [23, 27], [28, 36], [37, 43], [44, 46], [47, 53], [53, 54], [54, 59], [60, 68], [69, 80], [81, 84], [85, 89], [90, 93], [94, 98], [98, 99]]}
{"doc_key": "ai-test-78", "ner": [[1, 1, "field"], [4, 5, "algorithm"], [7, 7, "algorithm"], [16, 17, "metrics"], [19, 21, "metrics"], [23, 23, "metrics"], [36, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 5, 1, 1, "part-of", "", false, false], [4, 5, 16, 17, "related-to", "finds", false, false], [4, 5, 19, 21, "related-to", "finds", false, false], [4, 5, 36, 37, "related-to", "", false, false], [7, 7, 4, 5, "named", "", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "statistics", ",", "the", "expectation", "-maximisation", "(", "EM", ")", "algorithm", "is", "an", "iterative", "method", "for", "finding", "maximum", "likelihood", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "parameter", "estimates", "in", "statistical", "models", "where", "the", "model", "depends", "on", "unobserved", "latent", "variables", "."], "sentence-detokenized": "In statistics, the expectation-maximisation (EM) algorithm is an iterative method for finding maximum likelihood or maximum a posteriori (MAP) parameter estimates in statistical models where the model depends on unobserved latent variables.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 30], [30, 43], [44, 45], [45, 47], [47, 48], [49, 58], [59, 61], [62, 64], [65, 74], [75, 81], [82, 85], [86, 93], [94, 101], [102, 112], [113, 115], [116, 123], [124, 125], [126, 136], [137, 138], [138, 141], [141, 142], [143, 152], [153, 162], [163, 165], [166, 177], [178, 184], [185, 190], [191, 194], [195, 200], [201, 208], [209, 211], [212, 222], [223, 229], [230, 239], [239, 240]]}
{"doc_key": "ai-test-79", "ner": [[5, 8, "metrics"], [10, 10, "metrics"], [16, 18, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 5, 8, "named", "", false, false], [20, 20, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Similarly", ",", "researchers", "sometimes", "report", "a", "FALSE", "positive", "rate", "(", "FPR", ")", "as", "well", "as", "a", "FALSE", "negative", "rate", "(", "FNR", ")", "."], "sentence-detokenized": "Similarly, researchers sometimes report a FALSE positive rate (FPR) as well as a FALSE negative rate (FNR).", "token2charspan": [[0, 9], [9, 10], [11, 22], [23, 32], [33, 39], [40, 41], [42, 47], [48, 56], [57, 61], [62, 63], [63, 66], [66, 67], [68, 70], [71, 75], [76, 78], [79, 80], [81, 86], [87, 95], [96, 100], [101, 102], [102, 105], [105, 106], [106, 107]]}
{"doc_key": "ai-test-80", "ner": [[6, 11, "metrics"], [15, 15, "field"], [17, 19, "metrics"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 15, 6, 11, "usage", "", false, false], [22, 23, 17, 19, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "concept", "is", "similar", "to", "the", "signal", "-", "to", "-", "noise", "ratio", "used", "in", "the", "sciences", "and", "the", "confusion", "matrix", "used", "in", "artificial", "intelligence", "."], "sentence-detokenized": "This concept is similar to the signal-to-noise ratio used in the sciences and the confusion matrix used in artificial intelligence.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 23], [24, 26], [27, 30], [31, 37], [37, 38], [38, 40], [40, 41], [41, 46], [47, 52], [53, 57], [58, 60], [61, 64], [65, 73], [74, 77], [78, 81], [82, 91], [92, 98], [99, 103], [104, 106], [107, 117], [118, 130], [130, 131]]}
{"doc_key": "ai-test-81", "ner": [[1, 2, "field"], [12, 13, "researcher"], [19, 20, "researcher"], [22, 24, "researcher"], [32, 35, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 12, 13, "general-affiliation", "", false, false], [1, 2, 19, 20, "general-affiliation", "", false, false], [1, 2, 22, 24, "general-affiliation", "", false, false], [32, 35, 1, 2, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Human", "Augmentation", "Code", "of", "Ethics", ",", "which", "was", "originally", "introduced", "by", "Steve", "Mann", "in", "2004", "and", "refined", "with", "Ray", "Kurzweil", "and", "Marvin", "Minsky", "in", "2013", ",", "was", "finally", "ratified", "at", "the", "Virtual", "Reality", "Toronto", "conference", "on", "25", "June", "2017", "."], "sentence-detokenized": "The Human Augmentation Code of Ethics, which was originally introduced by Steve Mann in 2004 and refined with Ray Kurzweil and Marvin Minsky in 2013, was finally ratified at the Virtual Reality Toronto conference on 25 June 2017.", "token2charspan": [[0, 3], [4, 9], [10, 22], [23, 27], [28, 30], [31, 37], [37, 38], [39, 44], [45, 48], [49, 59], [60, 70], [71, 73], [74, 79], [80, 84], [85, 87], [88, 92], [93, 96], [97, 104], [105, 109], [110, 113], [114, 122], [123, 126], [127, 133], [134, 140], [141, 143], [144, 148], [148, 149], [150, 153], [154, 161], [162, 170], [171, 173], [174, 177], [178, 185], [186, 193], [194, 201], [202, 212], [213, 215], [216, 218], [219, 223], [224, 228], [228, 229]]}
{"doc_key": "ai-test-82", "ner": [[2, 4, "person"], [9, 10, "organisation"], [11, 18, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 4, 9, 10, "role", "directed_for", false, false], [2, 4, 11, 18, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1913", "Walter", "R.", "Booth", "directed", "10", "films", "for", "the", "British", "Cinematheque", ",", "presumably", "in", "collaboration", "with", "Cecil", "Hepworth", "."], "sentence-detokenized": "In 1913 Walter R. Booth directed 10 films for the British Cinematheque, presumably in collaboration with Cecil Hepworth.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 17], [18, 23], [24, 32], [33, 35], [36, 41], [42, 45], [46, 49], [50, 57], [58, 70], [70, 71], [72, 82], [83, 85], [86, 99], [100, 104], [105, 110], [111, 119], [119, 120]]}
{"doc_key": "ai-test-83", "ner": [[12, 13, "location"], [14, 15, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 15, 12, 13, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "presented", "their", "new", "robot", "in", "1961", "at", "a", "trade", "fair", "at", "Chicago", "'s", "Cow", "Palace", "."], "sentence-detokenized": "They presented their new robot in 1961 at a trade fair at Chicago's Cow Palace.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 24], [25, 30], [31, 33], [34, 38], [39, 41], [42, 43], [44, 49], [50, 54], [55, 57], [58, 65], [65, 67], [68, 71], [72, 78], [78, 79]]}
{"doc_key": "ai-test-84", "ner": [[2, 2, "product"], [6, 7, "task"], [10, 12, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 6, 7, "usage", "", false, false], [2, 2, 10, 12, "usage", "", false, false], [2, 2, 15, 16, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["While", "some", "chatbot", "applications", "use", "sophisticated", "word", "classification", "processes", ",", "natural", "language", "processing", "and", "sophisticated", "artificial", "intelligence", ",", "others", "simply", "scan", "for", "general", "keywords", "and", "generate", "responses", "using", "popular", "phrases", "obtained", "from", "a", "related", "library", "or", "database", "."], "sentence-detokenized": "While some chatbot applications use sophisticated word classification processes, natural language processing and sophisticated artificial intelligence, others simply scan for general keywords and generate responses using popular phrases obtained from a related library or database.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 31], [32, 35], [36, 49], [50, 54], [55, 69], [70, 79], [79, 80], [81, 88], [89, 97], [98, 108], [109, 112], [113, 126], [127, 137], [138, 150], [150, 151], [152, 158], [159, 165], [166, 170], [171, 174], [175, 182], [183, 191], [192, 195], [196, 204], [205, 214], [215, 220], [221, 228], [229, 236], [237, 245], [246, 250], [251, 252], [253, 260], [261, 268], [269, 271], [272, 280], [280, 281]]}
{"doc_key": "ai-test-85", "ner": [[5, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Proposed", "in", "2016", ",", "the", "WaveNet", "model", "achieves", "excellent", "speech", "quality", "results", "."], "sentence-detokenized": "Proposed in 2016, the WaveNet model achieves excellent speech quality results.", "token2charspan": [[0, 8], [9, 11], [12, 16], [16, 17], [18, 21], [22, 29], [30, 35], [36, 44], [45, 54], [55, 61], [62, 69], [70, 77], [77, 78]]}
{"doc_key": "ai-test-86", "ner": [[4, 4, "product"], [7, 7, "misc"], [9, 10, "misc"], [12, 13, "misc"], [15, 16, "misc"], [18, 20, "organisation"], [22, 22, "organisation"], [24, 27, "organisation"], [29, 29, "organisation"], [31, 34, "organisation"], [36, 37, "organisation"], [39, 41, "organisation"], [43, 45, "organisation"], [48, 48, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 4, 7, 7, "general-affiliation", "", false, false], [4, 4, 9, 10, "general-affiliation", "", false, false], [4, 4, 12, 13, "general-affiliation", "", false, false], [4, 4, 15, 16, "general-affiliation", "", false, false], [18, 20, 4, 4, "usage", "", false, false], [22, 22, 4, 4, "usage", "", false, false], [24, 27, 4, 4, "usage", "", false, false], [29, 29, 4, 4, "usage", "", false, false], [31, 34, 4, 4, "usage", "", false, false], [36, 37, 4, 4, "usage", "", false, false], [39, 41, 4, 4, "usage", "", false, false], [43, 45, 4, 4, "usage", "", false, false], [48, 48, 4, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organisations", "known", "to", "use", "ALE", "for", "emergency", "management", ",", "disaster", "relief", ",", "normal", "communications", "or", "emergency", "response", ":", "American", "Red", "Cross", ",", "FEMA", ",", "Disaster", "Medical", "Assistance", "Teams", ",", "NATO", ",", "Federal", "Bureau", "of", "Investigation", ",", "United", "Nations", ",", "AT", "&", "T", ",", "Civil", "Air", "Patrol", ",", "(", "ARES", ")", "."], "sentence-detokenized": "Organisations known to use ALE for emergency management, disaster relief, normal communications or emergency response: American Red Cross, FEMA, Disaster Medical Assistance Teams, NATO, Federal Bureau of Investigation, United Nations, AT & T, Civil Air Patrol, (ARES).", "token2charspan": [[0, 13], [14, 19], [20, 22], [23, 26], [27, 30], [31, 34], [35, 44], [45, 55], [55, 56], [57, 65], [66, 72], [72, 73], [74, 80], [81, 95], [96, 98], [99, 108], [109, 117], [117, 118], [119, 127], [128, 131], [132, 137], [137, 138], [139, 143], [143, 144], [145, 153], [154, 161], [162, 172], [173, 178], [178, 179], [180, 184], [184, 185], [186, 193], [194, 200], [201, 203], [204, 217], [217, 218], [219, 225], [226, 233], [233, 234], [235, 237], [238, 239], [240, 241], [241, 242], [243, 248], [249, 252], [253, 259], [259, 260], [261, 262], [262, 266], [266, 267], [267, 268]]}
{"doc_key": "ai-test-87", "ner": [[3, 4, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", ",", "the", "Kronecker", "delta", "(", "cf", ".", "the", "derivative", "of", "the", "sigmoidal", "function", ",", "expressed", "by", "the", "function", "itself", ")", "is", "used", "for", "simplicity", "."], "sentence-detokenized": "Here, the Kronecker delta (cf. the derivative of the sigmoidal function, expressed by the function itself) is used for simplicity.", "token2charspan": [[0, 4], [4, 5], [6, 9], [10, 19], [20, 25], [26, 27], [27, 29], [29, 30], [31, 34], [35, 45], [46, 48], [49, 52], [53, 62], [63, 71], [71, 72], [73, 82], [83, 85], [86, 89], [90, 98], [99, 105], [105, 106], [107, 109], [110, 114], [115, 118], [119, 129], [129, 130]]}
{"doc_key": "ai-test-88", "ner": [[11, 12, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "theory", "is", "based", "on", "philosophical", "foundations", "and", "was", "founded", "by", "Ray", "Solomonoff", "around", "1960", ".", "Samuel", "Rathmanner", "and", "Marcus", "Hutter", "."], "sentence-detokenized": "The theory is based on philosophical foundations and was founded by Ray Solomonoff around 1960. Samuel Rathmanner and Marcus Hutter.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 36], [37, 48], [49, 52], [53, 56], [57, 64], [65, 67], [68, 71], [72, 82], [83, 89], [90, 94], [94, 95], [96, 102], [103, 113], [114, 117], [118, 124], [125, 131], [131, 132]]}
{"doc_key": "ai-test-89", "ner": [[11, 11, "product"], [4, 5, "misc"], [8, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 4, 5, "type-of", "", false, false], [11, 11, 8, 16, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Originally", "designed", "as", "a", "semantic", "network", "based", "on", "psycholinguistic", "principles", ",", "WordNet", ",", "a", "freely", "accessible", "database", ",", "has", "been", "expanded", "by", "adding", "definitions", "and", "is", "now", "also", "seen", "as", "a", "dictionary", "."], "sentence-detokenized": "Originally designed as a semantic network based on psycholinguistic principles, WordNet, a freely accessible database, has been expanded by adding definitions and is now also seen as a dictionary.", "token2charspan": [[0, 10], [11, 19], [20, 22], [23, 24], [25, 33], [34, 41], [42, 47], [48, 50], [51, 67], [68, 78], [78, 79], [80, 87], [87, 88], [89, 90], [91, 97], [98, 108], [109, 117], [117, 118], [119, 122], [123, 127], [128, 136], [137, 139], [140, 146], [147, 158], [159, 162], [163, 165], [166, 169], [170, 174], [175, 179], [180, 182], [183, 184], [185, 195], [195, 196]]}
{"doc_key": "ai-test-90", "ner": [[2, 3, "field"], [12, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 2, 3, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Advances", "in", "computational", "imaging", "research", "are", "presented", "in", "several", "venues", ",", "including", "SIGGRAPH", "and", "publications", "."], "sentence-detokenized": "Advances in computational imaging research are presented in several venues, including SIGGRAPH and publications.", "token2charspan": [[0, 8], [9, 11], [12, 25], [26, 33], [34, 42], [43, 46], [47, 56], [57, 59], [60, 67], [68, 74], [74, 75], [76, 85], [86, 94], [95, 98], [99, 111], [111, 112]]}
{"doc_key": "ai-test-91", "ner": [[0, 0, "task"], [10, 10, "task"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 0, 0, "part-of", "", false, false], [13, 14, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "thought", "of", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multi-class", "classification", "."], "sentence-detokenized": "Classification can be thought of as two separate problems - binary classification and multi-class classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 29], [30, 32], [33, 35], [36, 39], [40, 48], [49, 57], [58, 59], [60, 66], [67, 81], [82, 85], [86, 97], [98, 112], [112, 113]]}
{"doc_key": "ai-test-92", "ner": [[13, 13, "algorithm"], [17, 18, "algorithm"], [21, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 13, 13, "type-of", "", false, false], [21, 21, 17, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Advanced", "gene", "search", "engines", "for", "both", "prokaryotic", "and", "eukaryotic", "genomes", "typically", "use", "complex", "probabilistic", "models", "such", "as", "hidden", "Markov", "models", "(", "HMMs", ")", "to", "combine", "information", "from", "multiple", "different", "signal", "and", "content", "measurements", "."], "sentence-detokenized": "Advanced gene search engines for both prokaryotic and eukaryotic genomes typically use complex probabilistic models such as hidden Markov models (HMMs) to combine information from multiple different signal and content measurements.", "token2charspan": [[0, 8], [9, 13], [14, 20], [21, 28], [29, 32], [33, 37], [38, 49], [50, 53], [54, 64], [65, 72], [73, 82], [83, 86], [87, 94], [95, 108], [109, 115], [116, 120], [121, 123], [124, 130], [131, 137], [138, 144], [145, 146], [146, 150], [150, 151], [152, 154], [155, 162], [163, 174], [175, 179], [180, 188], [189, 198], [199, 205], [206, 209], [210, 217], [218, 230], [230, 231]]}
{"doc_key": "ai-test-93", "ner": [[0, 0, "misc"], [3, 3, "misc"], [9, 10, "field"], [13, 14, "algorithm"], [17, 18, "algorithm"], [21, 21, "algorithm"], [31, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 9, 10, "part-of", "", false, false], [0, 0, 13, 14, "usage", "", false, false], [3, 3, 0, 0, "named", "", false, false], [17, 18, 0, 0, "origin", "", true, false], [21, 21, 17, 18, "named", "", false, false], [31, 32, 0, 0, "origin", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Neuroevolution", ",", "or", "neuro-evolution", ",", "is", "a", "form", "of", "artificial", "intelligence", "that", "uses", "evolutionary", "algorithms", "to", "generate", "artificial", "neural", "networks", "(", "ANNs", ")", ",", "parameters", ",", "topologies", "and", "rules", ".", "and", "evolutionary", "robotics", "."], "sentence-detokenized": "Neuroevolution, or neuro-evolution, is a form of artificial intelligence that uses evolutionary algorithms to generate artificial neural networks (ANNs), parameters, topologies and rules. and evolutionary robotics.", "token2charspan": [[0, 14], [14, 15], [16, 18], [19, 34], [34, 35], [36, 38], [39, 40], [41, 45], [46, 48], [49, 59], [60, 72], [73, 77], [78, 82], [83, 95], [96, 106], [107, 109], [110, 118], [119, 129], [130, 136], [137, 145], [146, 147], [147, 151], [151, 152], [152, 153], [154, 164], [164, 165], [166, 176], [177, 180], [181, 186], [186, 187], [188, 191], [192, 204], [205, 213], [213, 214]]}
{"doc_key": "ai-test-94", "ner": [[1, 1, "organisation"], [6, 6, "metrics"], [8, 8, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 1, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "IBM", "proposed", "and", "realised", "the", "BLEU", "system", "Papineni", "et", "al", "."], "sentence-detokenized": "As IBM proposed and realised the BLEU system Papineni et al.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 19], [20, 28], [29, 32], [33, 37], [38, 44], [45, 53], [54, 56], [57, 59], [59, 60]]}
{"doc_key": "ai-test-95", "ner": [[9, 16, "conference"], [18, 18, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 18, 9, 16, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2009", ",", "experts", "attended", "a", "conference", "organised", "by", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "to", "discuss", "whether", "computers", "and", "robots", "would", "be", "able", "to", "gain", "any", "autonomy", "and", "to", "what", "extent", "these", "capabilities", "could", "pose", "a", "threat", "or", "danger", "."], "sentence-detokenized": "In 2009, experts attended a conference organised by the Association for the Advancement of Artificial Intelligence (AAAI) to discuss whether computers and robots would be able to gain any autonomy and to what extent these capabilities could pose a threat or danger.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 25], [26, 27], [28, 38], [39, 48], [49, 51], [52, 55], [56, 67], [68, 71], [72, 75], [76, 87], [88, 90], [91, 101], [102, 114], [115, 116], [116, 120], [120, 121], [122, 124], [125, 132], [133, 140], [141, 150], [151, 154], [155, 161], [162, 167], [168, 170], [171, 175], [176, 178], [179, 183], [184, 187], [188, 196], [197, 200], [201, 203], [204, 208], [209, 215], [216, 221], [222, 234], [235, 240], [241, 245], [246, 247], [248, 254], [255, 257], [258, 264], [264, 265]]}
{"doc_key": "ai-test-96", "ner": [[24, 26, "metrics"], [27, 29, "researcher"], [31, 32, "researcher"], [34, 39, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[34, 39, 24, 26, "topic", "", false, false], [34, 39, 27, 29, "artifact", "", false, false], [34, 39, 31, 32, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["After", "boosting", ",", "a", "classifier", "constructed", "from", "200", "features", "could", "give", "a", "95", "%", "detection", "rate", "at", "^", "{", "-", "5", "}", "/", "math", "FALSE", "positive", "rate", ".P", ".", "Viola", ",", "M.", "Jones", ",", "Robust", "Real", "-", "time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "After boosting, a classifier constructed from 200 features could give a 95% detection rate at ^ {-5} / math FALSE positive rate .P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 17], [18, 28], [29, 40], [41, 45], [46, 49], [50, 58], [59, 64], [65, 69], [70, 71], [72, 74], [74, 75], [76, 85], [86, 90], [91, 93], [94, 95], [96, 97], [97, 98], [98, 99], [99, 100], [101, 102], [103, 107], [108, 113], [114, 122], [123, 127], [128, 130], [130, 131], [132, 137], [137, 138], [139, 141], [142, 147], [147, 148], [149, 155], [156, 160], [160, 161], [161, 165], [166, 172], [173, 182], [182, 183], [184, 188], [188, 189]]}
{"doc_key": "ai-test-97", "ner": [[4, 6, "programlang"], [9, 9, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "site", "was", "originally", "Perl", "-", "based", ",", "but", "IMDb", "no", "longer", "discloses", "what", "software", "it", "uses", "for", "security", "reasons", "."], "sentence-detokenized": "The site was originally Perl-based, but IMDb no longer discloses what software it uses for security reasons.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 23], [24, 28], [28, 29], [29, 34], [34, 35], [36, 39], [40, 44], [45, 47], [48, 54], [55, 64], [65, 69], [70, 78], [79, 81], [82, 86], [87, 90], [91, 99], [100, 107], [107, 108]]}
{"doc_key": "ai-test-98", "ner": [[7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "start", "-", "up", "was", "founded", "by", "Demis", "Hassabis", ",", "Shane", "Legg", "and", "Mustafa", "Suleyman", "in", "2010", "."], "sentence-detokenized": "The start-up was founded by Demis Hassabis, Shane Legg and Mustafa Suleyman in 2010.", "token2charspan": [[0, 3], [4, 9], [9, 10], [10, 12], [13, 16], [17, 24], [25, 27], [28, 33], [34, 42], [42, 43], [44, 49], [50, 54], [55, 58], [59, 66], [67, 75], [76, 78], [79, 83], [83, 84]]}
{"doc_key": "ai-test-99", "ner": [[4, 5, "misc"], [8, 10, "metrics"], [24, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 4, 5, "type-of", "", false, false], [24, 26, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "very", "commonly", "used", "loss", "functions", "are", "the", "mean", "square", "error", ",", "mathL", "(", "a", ")", "=", "a", "^", "2", "/", "math", ",", "and", "the", "absolute", "loss", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "/", "math", "."], "sentence-detokenized": "Two very commonly used loss functions are the mean square error, mathL (a) = a ^ 2 / math, and the absolute loss, mathL (a) = | a | / math.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 27], [28, 37], [38, 41], [42, 45], [46, 50], [51, 57], [58, 63], [63, 64], [65, 70], [71, 72], [72, 73], [73, 74], [75, 76], [77, 78], [79, 80], [81, 82], [83, 84], [85, 89], [89, 90], [91, 94], [95, 98], [99, 107], [108, 112], [112, 113], [114, 119], [120, 121], [121, 122], [122, 123], [124, 125], [126, 127], [128, 129], [130, 131], [132, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-test-100", "ner": [[3, 5, "algorithm"], [13, 15, "algorithm"], [17, 17, "algorithm"], [20, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 13, 15, "type-of", "example_of", false, false], [13, 15, 20, 21, "related-to", "", false, false], [17, 17, 13, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "soft", "-margin", "support", "vector", "machine", "described", "above", "is", "an", "example", "of", "an", "empirical", "risk", "minimisation", "(", "ERM", ")", "for", "hinge", "loss", "."], "sentence-detokenized": "The soft-margin support vector machine described above is an example of an empirical risk minimisation (ERM) for hinge loss.", "token2charspan": [[0, 3], [4, 8], [8, 15], [16, 23], [24, 30], [31, 38], [39, 48], [49, 54], [55, 57], [58, 60], [61, 68], [69, 71], [72, 74], [75, 84], [85, 89], [90, 102], [103, 104], [104, 107], [107, 108], [109, 112], [113, 118], [119, 123], [123, 124]]}
{"doc_key": "ai-test-101", "ner": [[1, 2, "field"], [5, 5, "task"], [7, 14, "task"], [19, 19, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 14, 1, 2, "origin", "", false, false], [7, 14, 5, 5, "type-of", "", false, false], [19, 19, 7, 14, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["A", "deep", "learning", "approach", "to", "MT", ",", "neural", "machine", "translation", "has", "made", "rapid", "progress", "in", "recent", "years", ",", "and", "Google", "has", "announced", "that", "its", "translation", "services", "now", "use", "this", "technology", "in", "place", "of", "previous", "statistical", "methods", "."], "sentence-detokenized": "A deep learning approach to MT, neural machine translation has made rapid progress in recent years, and Google has announced that its translation services now use this technology in place of previous statistical methods.", "token2charspan": [[0, 1], [2, 6], [7, 15], [16, 24], [25, 27], [28, 30], [30, 31], [32, 38], [39, 46], [47, 58], [59, 62], [63, 67], [68, 73], [74, 82], [83, 85], [86, 92], [93, 98], [98, 99], [100, 103], [104, 110], [111, 114], [115, 124], [125, 129], [130, 133], [134, 145], [146, 154], [155, 158], [159, 162], [163, 167], [168, 178], [179, 181], [182, 187], [188, 190], [191, 199], [200, 211], [212, 219], [219, 220]]}
{"doc_key": "ai-test-102", "ner": [[8, 8, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "working", "with", "large", "corpora", ",", "such", "as", "WordNet", ",", "this", "usually", "gives", "a", "very", "large", "increase", "in", "productivity", "."], "sentence-detokenized": "When working with large corpora, such as WordNet, this usually gives a very large increase in productivity.", "token2charspan": [[0, 4], [5, 12], [13, 17], [18, 23], [24, 31], [31, 32], [33, 37], [38, 40], [41, 48], [48, 49], [50, 54], [55, 62], [63, 68], [69, 70], [71, 75], [76, 81], [82, 90], [91, 93], [94, 106], [106, 107]]}
{"doc_key": "ai-test-103", "ner": [[0, 1, "task"], [5, 5, "field"], [16, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 16, 19, "part-of", "", false, false], [16, 19, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Face", "detection", "is", "used", "in", "biometrics", ",", "often", "as", "part", "of", "(", "or", "together", "with", ")", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Face detection is used in biometrics, often as part of (or together with) a facial recognition system.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 22], [23, 25], [26, 36], [36, 37], [38, 43], [44, 46], [47, 51], [52, 54], [55, 56], [56, 58], [59, 67], [68, 72], [72, 73], [74, 75], [76, 82], [83, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-test-104", "ner": [[2, 4, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["trained", "using", "maximum", "likelihood", "estimation", "."], "sentence-detokenized": "trained using maximum likelihood estimation.", "token2charspan": [[0, 7], [8, 13], [14, 21], [22, 32], [33, 43], [43, 44]]}
{"doc_key": "ai-test-105", "ner": [[3, 3, "country"], [5, 10, "organisation"], [13, 13, "location"], [15, 15, "country"], [17, 20, "organisation"], [22, 24, "country"], [28, 28, "organisation"], [33, 37, "organisation"], [39, 41, "country"], [50, 53, "organisation"], [55, 56, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[5, 10, 13, 13, "physical", "", false, false], [13, 13, 15, 15, "physical", "", false, false], [17, 20, 22, 24, "physical", "", false, false], [33, 37, 39, 41, "physical", "", false, false], [50, 53, 55, 56, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": [",", "Ltd.", "in", "Thailand", ";", "Komatsu", "(", "Shanghai", ")", "Ltd.", "in", "1996", "in", "Shanghai", ",", "China", ";", "Industrial", "Power", "Alliance", "Ltd.", "in", "Japan", ",", "a", "joint", "venture", "with", "Cummins", ",", "in", "1998", ";", "L", "&", "T-", "Komatsu", "Limited", "in", "India", "in", "1998", "(", "shares", "sold", "in", "2013", ")", ";", "and", "Komatsu", "Brasil", "International", "Ltda.", "in", "Brazil", "in", "1998", "."], "sentence-detokenized": ", Ltd. in Thailand; Komatsu (Shanghai) Ltd. in 1996 in Shanghai, China; Industrial Power Alliance Ltd. in Japan, a joint venture with Cummins, in 1998; L & T-Komatsu Limited in India in 1998 (shares sold in 2013); and Komatsu Brasil International Ltda. in Brazil in 1998.", "token2charspan": [[0, 1], [2, 6], [7, 9], [10, 18], [18, 19], [20, 27], [28, 29], [29, 37], [37, 38], [39, 43], [44, 46], [47, 51], [52, 54], [55, 63], [63, 64], [65, 70], [70, 71], [72, 82], [83, 88], [89, 97], [98, 102], [103, 105], [106, 111], [111, 112], [113, 114], [115, 120], [121, 128], [129, 133], [134, 141], [141, 142], [143, 145], [146, 150], [150, 151], [152, 153], [154, 155], [156, 158], [158, 165], [166, 173], [174, 176], [177, 182], [183, 185], [186, 190], [191, 192], [192, 198], [199, 203], [204, 206], [207, 211], [211, 212], [212, 213], [214, 217], [218, 225], [226, 232], [233, 246], [247, 252], [253, 255], [256, 262], [263, 265], [266, 270], [270, 271]]}
{"doc_key": "ai-test-106", "ner": [[0, 0, "organisation"], [4, 8, "misc"], [11, 11, "misc"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 14, 0, 0, "physical", "", false, false], [13, 14, 4, 8, "general-affiliation", "", false, false], [13, 14, 11, 11, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["dgp", "also", "occasionally", "hosts", "artists", "-", "in", "-", "residence", "(", "e.g.", "Oscar", "winner", "Chris", "Landreth", "."], "sentence-detokenized": "dgp also occasionally hosts artists-in-residence (e.g. Oscar winner Chris Landreth.", "token2charspan": [[0, 3], [4, 8], [9, 21], [22, 27], [28, 35], [35, 36], [36, 38], [38, 39], [39, 48], [49, 50], [50, 54], [55, 60], [61, 67], [68, 73], [74, 82], [82, 83]]}
{"doc_key": "ai-test-107", "ner": [[6, 8, "misc"], [11, 12, "misc"], [14, 17, "misc"], [22, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "currently", "includes", "four", "sub-competitions", "-", "RoboMaster", "Robotics", "Competition", ",", "RoboMaster", "Technical", "Challenge", ",", "ICRA", "RoboMaster", "AI", "Challenge", "and", "the", "new", "RoboMaster", "Youth", "Tournament", "."], "sentence-detokenized": "It currently includes four sub-competitions - RoboMaster Robotics Competition, RoboMaster Technical Challenge, ICRA RoboMaster AI Challenge and the new RoboMaster Youth Tournament.", "token2charspan": [[0, 2], [3, 12], [13, 21], [22, 26], [27, 43], [44, 45], [46, 56], [57, 65], [66, 77], [77, 78], [79, 89], [90, 99], [100, 109], [109, 110], [111, 115], [116, 126], [127, 129], [130, 139], [140, 143], [144, 147], [148, 151], [152, 162], [163, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-test-108", "ner": [[12, 14, "field"], [20, 23, "algorithm"], [27, 28, "algorithm"], [30, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 14, 27, 28, "usage", "", false, false], [12, 14, 30, 31, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["By", "the", "beginning", "of", "the", "21st", "century", ",", "the", "dominant", "strategy", "for", "speech", "processing", "had", "begun", "to", "move", "away", "from", "the", "Hidden", "Markov", "Model", "towards", "more", "modern", "neural", "networks", "and", "deep", "learning", "."], "sentence-detokenized": "By the beginning of the 21st century, the dominant strategy for speech processing had begun to move away from the Hidden Markov Model towards more modern neural networks and deep learning.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 23], [24, 28], [29, 36], [36, 37], [38, 41], [42, 50], [51, 59], [60, 63], [64, 70], [71, 81], [82, 85], [86, 91], [92, 94], [95, 99], [100, 104], [105, 109], [110, 113], [114, 120], [121, 127], [128, 133], [134, 141], [142, 146], [147, 153], [154, 160], [161, 169], [170, 173], [174, 178], [179, 187], [187, 188]]}
{"doc_key": "ai-test-109", "ner": [[8, 10, "misc"], [16, 18, "metrics"], [21, 23, "metrics"], [30, 32, "metrics"], [37, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 18, 21, 23, "related-to", "equal", false, false], [30, 32, 37, 39, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "equivalent", "expression", ",", "in", "the", "case", "of", "a", "binary", "target", "indicator", ",", "is", "that", "the", "positive", "indicator", "TRUE", "and", "the", "positive", "indicator", "FALSE", "are", "equal", "(", "and", "therefore", "the", "negative", "indicator", "FALSE", "and", "the", "negative", "indicator", "TRUE", "are", "equal", ")", "for", "each", "value", "of", "the", "sensitive", "feature", ":"], "sentence-detokenized": "Another equivalent expression, in the case of a binary target indicator, is that the positive indicator TRUE and the positive indicator FALSE are equal (and therefore the negative indicator FALSE and the negative indicator TRUE are equal) for each value of the sensitive feature:", "token2charspan": [[0, 7], [8, 18], [19, 29], [29, 30], [31, 33], [34, 37], [38, 42], [43, 45], [46, 47], [48, 54], [55, 61], [62, 71], [71, 72], [73, 75], [76, 80], [81, 84], [85, 93], [94, 103], [104, 108], [109, 112], [113, 116], [117, 125], [126, 135], [136, 141], [142, 145], [146, 151], [152, 153], [153, 156], [157, 166], [167, 170], [171, 179], [180, 189], [190, 195], [196, 199], [200, 203], [204, 212], [213, 222], [223, 227], [228, 231], [232, 237], [237, 238], [239, 242], [243, 247], [248, 253], [254, 256], [257, 260], [261, 270], [271, 278], [278, 279]]}
{"doc_key": "ai-test-110", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["MATLAB", "function", ","], "sentence-detokenized": "MATLAB function,", "token2charspan": [[0, 6], [7, 15], [15, 16]]}
{"doc_key": "ai-test-111", "ner": [[0, 2, "product"], [8, 8, "misc"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 0, 2, "part-of", "", false, false], [17, 18, 0, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "articulated", "robot", "is", "a", "robot", "that", "has", "rotating", "joints", "(", "e.g.", "a", "leg", "robot", "or", "an", "industrial", "robot", ")", "."], "sentence-detokenized": "An articulated robot is a robot that has rotating joints (e.g. a leg robot or an industrial robot).", "token2charspan": [[0, 2], [3, 14], [15, 20], [21, 23], [24, 25], [26, 31], [32, 36], [37, 40], [41, 49], [50, 56], [57, 58], [58, 62], [63, 64], [65, 68], [69, 74], [75, 77], [78, 80], [81, 91], [92, 97], [97, 98], [98, 99]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [6, 6, "product"], [8, 9, "product"], [13, 13, "misc"], [19, 21, "product"], [25, 29, "misc"], [31, 31, "location"], [33, 33, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 13, 13, "general-affiliation", "nationality", false, false], [0, 0, 25, 29, "usage", "", false, false], [0, 0, 31, 31, "physical", "", false, false], [6, 6, 0, 0, "named", "", false, false], [8, 9, 0, 0, "named", "", false, false], [31, 31, 33, 33, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "also", "known", "as", "Pandora", "Media", "or", "Pandora", "Radio", ")", "is", "an", "American", "music", "streaming", "radio", "service", "and", "automated", "recommender", "system", "powered", "by", "the", "Music", "Genome", "Project", "and", "based", "in", "Oakland", ",", "California", "."], "sentence-detokenized": "Pandora (also known as Pandora Media or Pandora Radio) is an American music streaming radio service and automated recommender system powered by the Music Genome Project and based in Oakland, California.", "token2charspan": [[0, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 30], [31, 36], [37, 39], [40, 47], [48, 53], [53, 54], [55, 57], [58, 60], [61, 69], [70, 75], [76, 85], [86, 91], [92, 99], [100, 103], [104, 113], [114, 125], [126, 132], [133, 140], [141, 143], [144, 147], [148, 153], [154, 160], [161, 168], [169, 172], [173, 178], [179, 181], [182, 189], [189, 190], [191, 201], [201, 202]]}
{"doc_key": "ai-test-113", "ner": [[7, 10, "organisation"], [17, 20, "organisation"], [26, 27, "conference"], [41, 41, "conference"], [43, 43, "conference"], [45, 45, "conference"], [47, 47, "conference"], [49, 49, "conference"], [51, 51, "conference"], [53, 53, "conference"], [55, 55, "conference"], [57, 57, "conference"], [59, 59, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "board", "member", "of", "the", "International", "Machine", "Learning", "Society", ",", "was", "a", "member", "of", "the", "executive", "council", "of", "AAAI", ",", "was", "PC", "co-chair", "of", "ICML", "2011", ",", "and", "has", "served", "as", "a", "senior", "PC", "member", "at", "conferences", "such", "as", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "UAI", ",", "VLDB", ",", "WSDM", "and", "WWW", "."], "sentence-detokenized": "She is a board member of the International Machine Learning Society, was a member of the executive council of AAAI, was PC co-chair of ICML 2011, and has served as a senior PC member at conferences such as AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM and WWW.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 14], [15, 21], [22, 24], [25, 28], [29, 42], [43, 50], [51, 59], [60, 67], [67, 68], [69, 72], [73, 74], [75, 81], [82, 84], [85, 88], [89, 98], [99, 106], [107, 109], [110, 114], [114, 115], [116, 119], [120, 122], [123, 131], [132, 134], [135, 139], [140, 144], [144, 145], [146, 149], [150, 153], [154, 160], [161, 163], [164, 165], [166, 172], [173, 175], [176, 182], [183, 185], [186, 197], [198, 202], [203, 205], [206, 210], [210, 211], [212, 216], [216, 217], [218, 223], [223, 224], [225, 229], [229, 230], [231, 234], [234, 235], [236, 242], [242, 243], [244, 247], [247, 248], [249, 253], [253, 254], [255, 259], [260, 263], [264, 267], [267, 268]]}
{"doc_key": "ai-test-114", "ner": [[0, 2, "researcher"], [5, 10, "organisation"], [12, 12, "organisation"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 10, "role", "", false, false], [12, 12, 5, 10, "named", "", false, false], [15, 15, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", "of", "the", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", "developed", "Robocrane", ",", "in", "which", "the", "platform", ",", "instead", "of", "being", "supported", "by", "six", "jacks", ",", "hangs", "from", "six", "cables", "."], "sentence-detokenized": "James S. Albus of the National Institute of Standards and Technology (NIST) developed Robocrane, in which the platform, instead of being supported by six jacks, hangs from six cables.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 17], [18, 21], [22, 30], [31, 40], [41, 43], [44, 53], [54, 57], [58, 68], [69, 70], [70, 74], [74, 75], [76, 85], [86, 95], [95, 96], [97, 99], [100, 105], [106, 109], [110, 118], [118, 119], [120, 127], [128, 130], [131, 136], [137, 146], [147, 149], [150, 153], [154, 159], [159, 160], [161, 166], [167, 171], [172, 175], [176, 182], [182, 183]]}
{"doc_key": "ai-test-115", "ner": [[3, 5, "algorithm"], [8, 9, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 3, 5, "type-of", "", false, false], [13, 14, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "class", "of", "direct", "search", "algorithms", "are", "various", "evolutionary", "algorithms", ",", "such", "as", "genetic", "algorithms", "."], "sentence-detokenized": "Another class of direct search algorithms are various evolutionary algorithms, such as genetic algorithms.", "token2charspan": [[0, 7], [8, 13], [14, 16], [17, 23], [24, 30], [31, 41], [42, 45], [46, 53], [54, 66], [67, 77], [77, 78], [79, 83], [84, 86], [87, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-test-116", "ner": [[0, 0, "organisation"], [3, 5, "misc"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 0, 0, "named", "", false, false], [6, 7, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["KUKA", "is", "a", "German", "manufacturer", "of", "industrial", "robots", "and", "factory", "automation", "solutions", "."], "sentence-detokenized": "KUKA is a German manufacturer of industrial robots and factory automation solutions.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 16], [17, 29], [30, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 73], [74, 83], [83, 84]]}
{"doc_key": "ai-test-117", "ner": [[5, 5, "misc"], [8, 9, "person"], [12, 18, "misc"], [21, 23, "person"], [25, 25, "misc"], [28, 30, "person"], [32, 33, "misc"], [36, 37, "person"], [40, 42, "misc"], [45, 47, "person"], [50, 53, "misc"], [56, 58, "person"], [60, 64, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 9, 5, 5, "usage", "", false, false], [12, 18, 8, 9, "artifact", "", false, false], [21, 23, 5, 5, "usage", "", false, false], [25, 25, 21, 23, "artifact", "", false, false], [28, 30, 5, 5, "usage", "", false, false], [32, 33, 28, 30, "artifact", "", false, false], [36, 37, 5, 5, "usage", "", false, false], [40, 42, 36, 37, "artifact", "", false, false], [45, 47, 5, 5, "usage", "", false, false], [50, 53, 45, 47, "artifact", "", false, false], [56, 58, 5, 5, "usage", "", false, false], [60, 64, 56, 58, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Other", "2016-2020", "films", "captured", "by", "IMAX", "cameras", "include", "Zack", "Snyder", "'s", "'", "Batman", "v", "Superman", ":", "Dawn", "of", "Justice", "'", ",", "Clint", "Eastwood", "'s", "'", "Sully", "'", ",", "Damien", "Chazelle", "'s", "'", "First", "Man", "'", ",", "Patty", "Jenkins", "'", "'", "Wonder", "Woman", "1984", "'", ",", "Cary", "Joji", "Fukunaga", "'s", "'", "No", "Time", "to", "Die", "'", "and", "Joseph", "Kosinski", "'s", "'", "Top", "Gun", "'", ":", "Maverick", "."], "sentence-detokenized": "Other 2016-2020 films captured by IMAX cameras include Zack Snyder's 'Batman v Superman: Dawn of Justice', Clint Eastwood's 'Sully', Damien Chazelle's 'First Man', Patty Jenkins' 'Wonder Woman 1984', Cary Joji Fukunaga's 'No Time to Die' and Joseph Kosinski's 'Top Gun': Maverick.", "token2charspan": [[0, 5], [6, 15], [16, 21], [22, 30], [31, 33], [34, 38], [39, 46], [47, 54], [55, 59], [60, 66], [66, 68], [69, 70], [70, 76], [77, 78], [79, 87], [87, 88], [89, 93], [94, 96], [97, 104], [104, 105], [105, 106], [107, 112], [113, 121], [121, 123], [124, 125], [125, 130], [130, 131], [131, 132], [133, 139], [140, 148], [148, 150], [151, 152], [152, 157], [158, 161], [161, 162], [162, 163], [164, 169], [170, 177], [177, 178], [179, 180], [180, 186], [187, 192], [193, 197], [197, 198], [198, 199], [200, 204], [205, 209], [210, 218], [218, 220], [221, 222], [222, 224], [225, 229], [230, 232], [233, 236], [236, 237], [238, 241], [242, 248], [249, 257], [257, 259], [260, 261], [261, 264], [265, 268], [268, 269], [269, 270], [271, 279], [279, 280]]}
{"doc_key": "ai-test-118", "ner": [[4, 5, "misc"], [12, 16, "organisation"], [18, 18, "organisation"], [28, 28, "misc"], [35, 36, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 28, 28, "named", "", false, false], [12, 16, 4, 5, "usage", "", false, false], [12, 16, 35, 36, "physical", "", false, false], [18, 18, 12, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "sample", "of", "the", "MICR", "E13B", "font", "was", "shown", "in", "July", "1956", "to", "the", "American", "Bankers", "Association", "(", "ABA", ")", ",", "which", "adopted", "it", "in", "1958", "as", "the", "MICR", "standard", "for", "negotiable", "documents", "in", "the", "United", "States", "."], "sentence-detokenized": "A sample of the MICR E13B font was shown in July 1956 to the American Bankers Association (ABA), which adopted it in 1958 as the MICR standard for negotiable documents in the United States.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 15], [16, 20], [21, 25], [26, 30], [31, 34], [35, 40], [41, 43], [44, 48], [49, 53], [54, 56], [57, 60], [61, 69], [70, 77], [78, 89], [90, 91], [91, 94], [94, 95], [95, 96], [97, 102], [103, 110], [111, 113], [114, 116], [117, 121], [122, 124], [125, 128], [129, 133], [134, 142], [143, 146], [147, 157], [158, 167], [168, 170], [171, 174], [175, 181], [182, 188], [188, 189]]}
{"doc_key": "ai-test-119", "ner": [[0, 2, "misc"], [18, 19, "field"], [22, 23, "field"], [26, 26, "field"], [28, 29, "field"], [31, 31, "field"], [33, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[18, 19, 0, 2, "usage", "", false, false], [22, 23, 18, 19, "part-of", "", false, false], [26, 26, 0, 2, "usage", "", false, false], [28, 29, 0, 2, "usage", "", false, false], [31, 31, 0, 2, "usage", "", false, false], [33, 33, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Local", "search", "algorithms", "are", "widely", "applied", "to", "a", "wide", "range", "of", "challenging", "computational", "problems", ",", "including", "problems", "in", "computer", "science", "(", "particularly", "artificial", "intelligence", ")", ",", "mathematics", ",", "operations", "research", ",", "engineering", "and", "bioinformatics", "."], "sentence-detokenized": "Local search algorithms are widely applied to a wide range of challenging computational problems, including problems in computer science (particularly artificial intelligence), mathematics, operations research, engineering and bioinformatics.", "token2charspan": [[0, 5], [6, 12], [13, 23], [24, 27], [28, 34], [35, 42], [43, 45], [46, 47], [48, 52], [53, 58], [59, 61], [62, 73], [74, 87], [88, 96], [96, 97], [98, 107], [108, 116], [117, 119], [120, 128], [129, 136], [137, 138], [138, 150], [151, 161], [162, 174], [174, 175], [175, 176], [177, 188], [188, 189], [190, 200], [201, 209], [209, 210], [211, 222], [223, 226], [227, 241], [241, 242]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [8, 8, "location"], [10, 10, "country"], [14, 14, "country"], [21, 22, "algorithm"], [24, 24, "algorithm"], [26, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 8, 8, "physical", "", false, false], [0, 1, 14, 14, "general-affiliation", "nationality", false, false], [0, 1, 21, 22, "general-affiliation", "topic_of_study", false, false], [0, 1, 24, 24, "general-affiliation", "topic_of_study", false, false], [8, 8, 10, 10, "physical", "", false, false], [24, 24, 26, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "born", "3", "September", "1947", ",", "Wallersdorf", ",", "Germany", ")", "is", "a", "German", "psychologist", "who", "studied", "the", "use", "of", "bounded", "rationality", "and", "heuristics", "in", "decision", "-", "making", "."], "sentence-detokenized": "Gerd Gigerenzer (born 3 September 1947, Wallersdorf, Germany) is a German psychologist who studied the use of bounded rationality and heuristics in decision-making.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 21], [22, 23], [24, 33], [34, 38], [38, 39], [40, 51], [51, 52], [53, 60], [60, 61], [62, 64], [65, 66], [67, 73], [74, 86], [87, 90], [91, 98], [99, 102], [103, 106], [107, 109], [110, 117], [118, 129], [130, 133], [134, 144], [145, 147], [148, 156], [156, 157], [157, 163], [163, 164]]}
{"doc_key": "ai-test-121", "ner": [[2, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["to", "minimise", "the", "mean", "square", "error", "."], "sentence-detokenized": "to minimise the mean square error.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 20], [21, 27], [28, 33], [33, 34]]}
{"doc_key": "ai-test-122", "ner": [[12, 13, "misc"], [16, 17, "organisation"], [33, 35, "field"], [53, 54, "misc"], [63, 65, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 13, 16, 17, "origin", "", false, false], [53, 54, 63, 65, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["But", "even", "an", "official", "language", "with", "a", "regulating", "academy", ",", "such", "as", "standard", "French", "from", "the", "Acad\u00e9mie", "fran\u00e7aise", ",", "is", "classified", "as", "a", "natural", "language", "(", "for", "example", ",", "in", "the", "field", "of", "natural", "language", "processing", ")", "because", "its", "normative", "points", "do", "not", "make", "it", "either", "sufficiently", "constructed", "to", "be", "classified", "as", "a", "constructed", "language", "or", "sufficiently", "controlled", "to", "be", "classified", "as", "a", "controlled", "natural", "language", "."], "sentence-detokenized": "But even an official language with a regulating academy, such as standard French from the Acad\u00e9mie fran\u00e7aise, is classified as a natural language (for example, in the field of natural language processing) because its normative points do not make it either sufficiently constructed to be classified as a constructed language or sufficiently controlled to be classified as a controlled natural language.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 20], [21, 29], [30, 34], [35, 36], [37, 47], [48, 55], [55, 56], [57, 61], [62, 64], [65, 73], [74, 80], [81, 85], [86, 89], [90, 98], [99, 108], [108, 109], [110, 112], [113, 123], [124, 126], [127, 128], [129, 136], [137, 145], [146, 147], [147, 150], [151, 158], [158, 159], [160, 162], [163, 166], [167, 172], [173, 175], [176, 183], [184, 192], [193, 203], [203, 204], [205, 212], [213, 216], [217, 226], [227, 233], [234, 236], [237, 240], [241, 245], [246, 248], [249, 255], [256, 268], [269, 280], [281, 283], [284, 286], [287, 297], [298, 300], [301, 302], [303, 314], [315, 323], [324, 326], [327, 339], [340, 350], [351, 353], [354, 356], [357, 367], [368, 370], [371, 372], [373, 383], [384, 391], [392, 400], [400, 401]]}
{"doc_key": "ai-test-123", "ner": [[13, 13, "metrics"], [15, 16, "metrics"], [18, 18, "metrics"], [37, 38, "metrics"], [40, 40, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[18, 18, 15, 16, "named", "", false, false], [40, 40, 37, 38, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "a", "number", "of", "other", "metrics", ",", "the", "simplest", "of", "which", "is", "accuracy", "or", "Fraction", "Correct", "(", "FC", ")", ",", "which", "measures", "the", "fraction", "of", "all", "instances", "that", "are", "correctly", "categorised", ";", "this", "is", "complemented", "by", "Fraction", "Incorrect", "(", "FiC", ")", "."], "sentence-detokenized": "There are a number of other metrics, the simplest of which is accuracy or Fraction Correct (FC), which measures the fraction of all instances that are correctly categorised; this is complemented by Fraction Incorrect (FiC).", "token2charspan": [[0, 5], [6, 9], [10, 11], [12, 18], [19, 21], [22, 27], [28, 35], [35, 36], [37, 40], [41, 49], [50, 52], [53, 58], [59, 61], [62, 70], [71, 73], [74, 82], [83, 90], [91, 92], [92, 94], [94, 95], [95, 96], [97, 102], [103, 111], [112, 115], [116, 124], [125, 127], [128, 131], [132, 141], [142, 146], [147, 150], [151, 160], [161, 172], [172, 173], [174, 178], [179, 181], [182, 194], [195, 197], [198, 206], [207, 216], [217, 218], [218, 221], [221, 222], [222, 223]]}
{"doc_key": "ai-test-124", "ner": [[0, 0, "researcher"], [6, 10, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 10, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cardie", "became", "a", "2016", "Fellow", "of", "the", "Association", "for", "Computational", "Linguistics", "."], "sentence-detokenized": "Cardie became a 2016 Fellow of the Association for Computational Linguistics.", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 20], [21, 27], [28, 30], [31, 34], [35, 46], [47, 50], [51, 64], [65, 76], [76, 77]]}
{"doc_key": "ai-test-125", "ner": [[21, 23, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Learning", "the", "parameters", "of", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i", ";\u0105", ")", "/", "math", "is", "usually", "performed", "by", "maximum", "likelihood", "learning", "for", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i", ";\u0105", ")", "/", "math", "."], "sentence-detokenized": "Learning the parameters of mathp (Y _ i | X _ i;\u0105) / math is usually performed by maximum likelihood learning for mathp (Y _ i | X _ i;\u0105) / math.", "token2charspan": [[0, 8], [9, 12], [13, 23], [24, 26], [27, 32], [33, 34], [34, 35], [36, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 47], [47, 49], [49, 50], [51, 52], [53, 57], [58, 60], [61, 68], [69, 78], [79, 81], [82, 89], [90, 100], [101, 109], [110, 113], [114, 119], [120, 121], [121, 122], [123, 124], [125, 126], [127, 128], [129, 130], [131, 132], [133, 134], [134, 136], [136, 137], [138, 139], [140, 144], [144, 145]]}
{"doc_key": "ai-test-126", "ner": [[0, 1, "task"], [4, 6, "algorithm"], [8, 9, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 0, 1, "usage", "", true, false], [8, 9, 4, 6, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cluster", "analysis", ",", "and", "non-negative", "matrix", "factorisation", "for", "descriptive", "mining", "."], "sentence-detokenized": "Cluster analysis, and non-negative matrix factorisation for descriptive mining.", "token2charspan": [[0, 7], [8, 16], [16, 17], [18, 21], [22, 34], [35, 41], [42, 55], [56, 59], [60, 71], [72, 78], [78, 79]]}
{"doc_key": "ai-test-127", "ner": [[1, 2, "field"], [5, 6, "field"], [16, 18, "field"], [20, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 18, 1, 2, "part-of", "", false, false], [16, 18, 5, 6, "part-of", "", false, false], [20, 21, 1, 2, "part-of", "", false, false], [20, 21, 5, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", "and", "the", "information", "technologies", "that", "enable", "it", ",", "the", "ability", "in", "computers", "to", "process", "natural", "language", "and", "machine", "learning", "has", "been", "king", "for", "a", "long", "time", "."], "sentence-detokenized": "In computer science and the information technologies that enable it, the ability in computers to process natural language and machine learning has been king for a long time.", "token2charspan": [[0, 2], [3, 11], [12, 19], [20, 23], [24, 27], [28, 39], [40, 52], [53, 57], [58, 64], [65, 67], [67, 68], [69, 72], [73, 80], [81, 83], [84, 93], [94, 96], [97, 104], [105, 112], [113, 121], [122, 125], [126, 133], [134, 142], [143, 146], [147, 151], [152, 156], [157, 160], [161, 162], [163, 167], [168, 172], [172, 173]]}
{"doc_key": "ai-test-128", "ner": [[3, 5, "algorithm"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 5, 9, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "Code", "for", "extracting", "Gabor", "features", "from", "images", "in", "MATLAB", "can", "be", "found", "at"], "sentence-detokenized": "(Code for extracting Gabor features from images in MATLAB can be found at", "token2charspan": [[0, 1], [1, 5], [6, 9], [10, 20], [21, 26], [27, 35], [36, 40], [41, 47], [48, 50], [51, 57], [58, 61], [62, 64], [65, 70], [71, 73]]}
{"doc_key": "ai-test-129", "ner": [[0, 0, "misc"], [13, 15, "algorithm"], [19, 19, "task"], [21, 21, "task"], [23, 24, "task"], [26, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 13, 15, "general-affiliation", "", false, false], [0, 0, 19, 19, "related-to", "solves_problem_of_type", false, false], [0, 0, 21, 21, "related-to", "solves_problem_of_type", false, false], [0, 0, 23, 24, "related-to", "solves_problem_of_type", false, false], [0, 0, 26, 27, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["NeuralExpert", "centres", "design", "specifications", "around", "the", "type", "of", "problem", "the", "user", "would", "like", "the", "neural", "network", "to", "solve", "(", "Classification", ",", "Prediction", ",", "function", "approximation", "or", "cluster", "analysis", ")", "."], "sentence-detokenized": "NeuralExpert centres design specifications around the type of problem the user would like the neural network to solve (Classification, Prediction, function approximation or cluster analysis).", "token2charspan": [[0, 12], [13, 20], [21, 27], [28, 42], [43, 49], [50, 53], [54, 58], [59, 61], [62, 69], [70, 73], [74, 78], [79, 84], [85, 89], [90, 93], [94, 100], [101, 108], [109, 111], [112, 117], [118, 119], [119, 133], [133, 134], [135, 145], [145, 146], [147, 155], [156, 169], [170, 172], [173, 180], [181, 189], [189, 190], [190, 191]]}
{"doc_key": "ai-test-130", "ner": [[2, 6, "misc"], [30, 32, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "size", "of", "the", "quantisation", "step", "(", "\u0394", ")", "is", "small", "relative", "to", "the", "variability", "of", "the", "quantised", "signal", ",", "it", "is", "relatively", "easy", "to", "show", "that", "the", "root", "mean", "square", "error", "produced", "by", "such", "a", "rounding", "operation", "will", "be", "approximately", "mathematical", "Delta", "^", "2", "/", "12", "/", "math.math"], "sentence-detokenized": "When the size of the quantisation step (\u0394) is small relative to the variability of the quantised signal, it is relatively easy to show that the root mean square error produced by such a rounding operation will be approximately mathematical Delta ^ 2 / 12 / math.math", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 20], [21, 33], [34, 38], [39, 40], [40, 41], [41, 42], [43, 45], [46, 51], [52, 60], [61, 63], [64, 67], [68, 79], [80, 82], [83, 86], [87, 96], [97, 103], [103, 104], [105, 107], [108, 110], [111, 121], [122, 126], [127, 129], [130, 134], [135, 139], [140, 143], [144, 148], [149, 153], [154, 160], [161, 166], [167, 175], [176, 178], [179, 183], [184, 185], [186, 194], [195, 204], [205, 209], [210, 212], [213, 226], [227, 239], [240, 245], [246, 247], [248, 249], [250, 251], [252, 254], [255, 256], [257, 266]]}
{"doc_key": "ai-test-131", "ner": [[14, 14, "product"], [24, 27, "researcher"], [29, 30, "researcher"], [32, 36, "researcher"], [36, 37, "researcher"], [39, 41, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Building", "a", "rich", "lexicon", "with", "an", "appropriate", "ontology", "requires", "considerable", "effort", ",", "e.g.", "the", "Wordnet", "lexicon", "required", "many", "man", "-", "years", "of", "work", ".", "G.", "A", ".", "Miller", ",", "R.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Gross", ",", "K", ".", "Miller", "."], "sentence-detokenized": "Building a rich lexicon with an appropriate ontology requires considerable effort, e.g. the Wordnet lexicon required many man-years of work. G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 8], [9, 10], [11, 15], [16, 23], [24, 28], [29, 31], [32, 43], [44, 52], [53, 61], [62, 74], [75, 81], [81, 82], [83, 87], [88, 91], [92, 99], [100, 107], [108, 116], [117, 121], [122, 125], [125, 126], [126, 131], [132, 134], [135, 139], [139, 140], [141, 143], [144, 145], [145, 146], [147, 153], [153, 154], [155, 157], [158, 166], [166, 167], [168, 170], [171, 173], [174, 182], [182, 183], [184, 186], [187, 192], [192, 193], [194, 195], [195, 196], [197, 203], [203, 204]]}
{"doc_key": "ai-test-132", "ner": [[0, 0, "organisation"], [18, 19, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Kawasaki", "'s", "portfolio", "also", "includes", "retractable", "roofs", ",", "floors", "and", "other", "giant", "structures", ",", "one", "example", "being", "the", "Sapporo", "Dome", "'", "retractable", "surface", "."], "sentence-detokenized": "Kawasaki's portfolio also includes retractable roofs, floors and other giant structures, one example being the Sapporo Dome 'retractable surface.", "token2charspan": [[0, 8], [8, 10], [11, 20], [21, 25], [26, 34], [35, 46], [47, 52], [52, 53], [54, 60], [61, 64], [65, 70], [71, 76], [77, 87], [87, 88], [89, 92], [93, 100], [101, 106], [107, 110], [111, 118], [119, 123], [124, 125], [125, 136], [137, 144], [144, 145]]}
{"doc_key": "ai-test-133", "ner": [[0, 1, "metrics"], [5, 7, "metrics"], [9, 13, "metrics"], [17, 18, "metrics"], [38, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 17, 18, "related-to", "", false, false], [0, 1, 38, 38, "opposite", "alternative_to", false, false], [5, 7, 0, 1, "type-of", "", false, false], [9, 13, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kappa", "statistics", ",", "such", "as", "Fleiss", "'", "kappa", "and", "Cohen", "'s", "kappa", ",", "are", "methods", "of", "calculating", "interrater", "reliability", "based", "on", "various", "assumptions", "about", "marginal", "or", "prior", "distributions", "and", "are", "increasingly", "used", "as", "chance", "-", "corrected", "alternatives", "for", "accuracy", "in", "other", "contexts", "."], "sentence-detokenized": "Kappa statistics, such as Fleiss' kappa and Cohen's kappa, are methods of calculating interrater reliability based on various assumptions about marginal or prior distributions and are increasingly used as chance-corrected alternatives for accuracy in other contexts.", "token2charspan": [[0, 5], [6, 16], [16, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 39], [40, 43], [44, 49], [49, 51], [52, 57], [57, 58], [59, 62], [63, 70], [71, 73], [74, 85], [86, 96], [97, 108], [109, 114], [115, 117], [118, 125], [126, 137], [138, 143], [144, 152], [153, 155], [156, 161], [162, 175], [176, 179], [180, 183], [184, 196], [197, 201], [202, 204], [205, 211], [211, 212], [212, 221], [222, 234], [235, 238], [239, 247], [248, 250], [251, 256], [257, 265], [265, 266]]}
{"doc_key": "ai-test-134", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [18, 18, "researcher"], [27, 29, "algorithm"], [31, 34, "algorithm"], [36, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 18, 18, "role", "student_of", false, false], [7, 8, 18, 18, "role", "student_of", false, false], [10, 11, 18, 18, "role", "student_of", false, false], [13, 14, 18, 18, "role", "student_of", false, false], [31, 34, 4, 5, "origin", "", false, false], [31, 34, 7, 8, "origin", "", false, false], [31, 34, 10, 11, "origin", "", false, false], [31, 34, 13, 14, "origin", "", false, false], [31, 34, 18, 18, "origin", "", false, false], [31, 34, 27, 29, "type-of", "", false, false], [36, 36, 31, 34, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Together", "with", "his", "students", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Graves", "and", "others", ",", "Schmidhuber", "published", "increasingly", "sophisticated", "versions", "of", "a", "type", "of", "recurrent", "neural", "network", "called", "long", "-", "term", "memory", "(", "LSTM", ")", "."], "sentence-detokenized": "Together with his students Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Graves and others, Schmidhuber published increasingly sophisticated versions of a type of recurrent neural network called long-term memory (LSTM).", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 26], [27, 31], [32, 42], [42, 43], [44, 49], [50, 54], [54, 55], [56, 60], [61, 68], [68, 69], [70, 74], [75, 81], [82, 85], [86, 92], [92, 93], [94, 105], [106, 115], [116, 128], [129, 142], [143, 151], [152, 154], [155, 156], [157, 161], [162, 164], [165, 174], [175, 181], [182, 189], [190, 196], [197, 201], [201, 202], [202, 206], [207, 213], [214, 215], [215, 219], [219, 220], [220, 221]]}
{"doc_key": "ai-test-135", "ner": [[4, 10, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "The", "first", "KUKA", "LBR", "3", "Cobot", "hits", "the", "market", "."], "sentence-detokenized": "2004 - The first KUKA LBR 3 Cobot hits the market.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 16], [17, 21], [22, 25], [26, 27], [28, 33], [34, 38], [39, 42], [43, 49], [49, 50]]}
{"doc_key": "ai-test-136", "ner": [[11, 13, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Two", "shallow", "approaches", "used", "to", "train", "and", "then", "discriminate", "are", "the", "Naive", "Bayes", "classifier", "and", "decision", "trees", "."], "sentence-detokenized": "Two shallow approaches used to train and then discriminate are the Naive Bayes classifier and decision trees.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 27], [28, 30], [31, 36], [37, 40], [41, 45], [46, 58], [59, 62], [63, 66], [67, 72], [73, 78], [79, 89], [90, 93], [94, 102], [103, 108], [108, 109]]}
{"doc_key": "ai-test-137", "ner": [[5, 5, "misc"], [13, 13, "person"], [15, 17, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 13, 13, "origin", "", false, false], [5, 5, 15, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "practical", "forms", "of", "photography", "were", "introduced", "in", "January", "1839", "by", "Louis", "Daguerre", "and", "Henry", "Fox", "Talbot", "."], "sentence-detokenized": "The first practical forms of photography were introduced in January 1839 by Louis Daguerre and Henry Fox Talbot.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 25], [26, 28], [29, 40], [41, 45], [46, 56], [57, 59], [60, 67], [68, 72], [73, 75], [76, 81], [82, 90], [91, 94], [95, 100], [101, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-138", "ner": [[3, 4, "task"], [7, 8, "task"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 15, 16, "part-of", "task_part_of_field", false, false], [7, 8, 15, 16, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "speech", "synthesis", "combined", "with", "speech", "recognition", "allows", "interaction", "with", "mobile", "devices", "through", "language", "processing", "interfaces", "."], "sentence-detokenized": "For example, speech synthesis combined with speech recognition allows interaction with mobile devices through language processing interfaces.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 19], [20, 29], [30, 38], [39, 43], [44, 50], [51, 62], [63, 69], [70, 81], [82, 86], [87, 93], [94, 101], [102, 109], [110, 118], [119, 129], [130, 140], [140, 141]]}
{"doc_key": "ai-test-139", "ner": [[0, 0, "product"], [14, 14, "programlang"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 14, 14, "general-affiliation", "", false, false], [0, 0, 16, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Phidgets", "can", "be", "programmed", "using", "a", "variety", "of", "software", "and", "programming", "languages", ",", "from", "Java", "to", "Microsoft", "Excel", "."], "sentence-detokenized": "Phidgets can be programmed using a variety of software and programming languages, from Java to Microsoft Excel.", "token2charspan": [[0, 8], [9, 12], [13, 15], [16, 26], [27, 32], [33, 34], [35, 42], [43, 45], [46, 54], [55, 58], [59, 70], [71, 80], [80, 81], [82, 86], [87, 91], [92, 94], [95, 104], [105, 110], [110, 111]]}
{"doc_key": "ai-test-140", "ner": [[2, 3, "field"], [9, 10, "researcher"], [12, 15, "misc"], [22, 23, "field"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 10, "origin", "", false, false], [9, 10, 22, 23, "general-affiliation", "topic_of_study", false, false], [9, 10, 25, 26, "general-affiliation", "topic_of_study", false, false], [12, 15, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "machine", "learning", "was", "coined", "in", "1959", "by", "Arthur", "Samuel", ",", "an", "American", "IBM", "employee", "and", "pioneer", "in", "the", "field", "of", "computer", "games", "and", "artificial", "intelligence", "."], "sentence-detokenized": "The term machine learning was coined in 1959 by Arthur Samuel, an American IBM employee and pioneer in the field of computer games and artificial intelligence.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 25], [26, 29], [30, 36], [37, 39], [40, 44], [45, 47], [48, 54], [55, 61], [61, 62], [63, 65], [66, 74], [75, 78], [79, 87], [88, 91], [92, 99], [100, 102], [103, 106], [107, 112], [113, 115], [116, 124], [125, 130], [131, 134], [135, 145], [146, 158], [158, 159]]}
{"doc_key": "ai-test-141", "ner": [[0, 1, "misc"], [2, 3, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Israeli", "poet", "David", "Avidan", ",", "fascinated", "by", "the", "technologies", "of", "the", "future", "and", "their", "relationship", "to", "the", "arts", ",", "wanted", "to", "explore", "the", "use", "of", "computers", "to", "write", "literature", "."], "sentence-detokenized": "Israeli poet David Avidan, fascinated by the technologies of the future and their relationship to the arts, wanted to explore the use of computers to write literature.", "token2charspan": [[0, 7], [8, 12], [13, 18], [19, 25], [25, 26], [27, 37], [38, 40], [41, 44], [45, 57], [58, 60], [61, 64], [65, 71], [72, 75], [76, 81], [82, 94], [95, 97], [98, 101], [102, 106], [106, 107], [108, 114], [115, 117], [118, 125], [126, 129], [130, 133], [134, 136], [137, 146], [147, 149], [150, 155], [156, 166], [166, 167]]}
{"doc_key": "ai-test-142", "ner": [[0, 6, "misc"], [9, 9, "organisation"], [16, 16, "location"], [26, 27, "location"], [28, 30, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 0, 6, "part-of", "", false, false], [28, 30, 26, 27, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "part", "of", "the", "GATEway", "project", "in", "2017", ",", "Oxbotica", "tested", "seven", "autonomous", "shuttle", "buses", "in", "Greenwich", ",", "navigating", "a", "two", "-", "mile", "riverside", "path", "near", "London", "'s", "The", "O2", "Arena", "on", "a", "route", "also", "used", "by", "pedestrians", "and", "cyclists", "."], "sentence-detokenized": "As part of the GATEway project in 2017, Oxbotica tested seven autonomous shuttle buses in Greenwich, navigating a two-mile riverside path near London's The O2 Arena on a route also used by pedestrians and cyclists.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 22], [23, 30], [31, 33], [34, 38], [38, 39], [40, 48], [49, 55], [56, 61], [62, 72], [73, 80], [81, 86], [87, 89], [90, 99], [99, 100], [101, 111], [112, 113], [114, 117], [117, 118], [118, 122], [123, 132], [133, 137], [138, 142], [143, 149], [149, 151], [152, 155], [156, 158], [159, 164], [165, 167], [168, 169], [170, 175], [176, 180], [181, 185], [186, 188], [189, 200], [201, 204], [205, 213], [213, 214]]}
{"doc_key": "ai-test-143", "ner": [[8, 9, "task"], [13, 15, "metrics"], [24, 26, "misc"], [27, 27, "metrics"], [29, 29, "metrics"], [32, 32, "metrics"], [34, 34, "metrics"], [36, 38, "metrics"], [41, 41, "metrics"], [43, 43, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[13, 15, 24, 26, "related-to", "is_a", false, false], [13, 15, 27, 27, "usage", "", false, false], [13, 15, 29, 29, "usage", "", false, false], [27, 27, 32, 32, "named", "same", false, false], [29, 29, 43, 43, "named", "same", false, false], [32, 32, 41, 41, "opposite", "", false, false], [32, 32, 43, 43, "opposite", "", false, false], [34, 34, 32, 32, "named", "", false, false], [36, 38, 32, 32, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["An", "unrelated", "but", "commonly", "used", "combination", "of", "basic", "information", "retrieval", "statistics", "is", "the", "F", "-", "score", ",", "which", "is", "the", "(", "possibly", "weighted", ")", "harmonic", "mean", "of", "recall", "and", "precision", ",", "where", "recall", "=", "sensitivity", "=", "TRUE", "positive", "rate", ",", "but", "specificity", "and", "precision", "are", "completely", "different", "measures", "."], "sentence-detokenized": "An unrelated but commonly used combination of basic information retrieval statistics is the F-score, which is the (possibly weighted) harmonic mean of recall and precision, where recall = sensitivity = TRUE positive rate, but specificity and precision are completely different measures.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 25], [26, 30], [31, 42], [43, 45], [46, 51], [52, 63], [64, 73], [74, 84], [85, 87], [88, 91], [92, 93], [93, 94], [94, 99], [99, 100], [101, 106], [107, 109], [110, 113], [114, 115], [115, 123], [124, 132], [132, 133], [134, 142], [143, 147], [148, 150], [151, 157], [158, 161], [162, 171], [171, 172], [173, 178], [179, 185], [186, 187], [188, 199], [200, 201], [202, 206], [207, 215], [216, 220], [220, 221], [222, 225], [226, 237], [238, 241], [242, 251], [252, 255], [256, 266], [267, 276], [277, 285], [285, 286]]}
{"doc_key": "ai-test-144", "ner": [[0, 1, "field"], [10, 10, "field"], [12, 12, "field"], [13, 14, "field"], [16, 17, "field"], [19, 21, "field"], [28, 29, "product"], [31, 34, "product"], [36, 38, "product"], [39, 40, "product"], [53, 55, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 10, "origin", "takes_inspiration_from", false, false], [0, 1, 12, 12, "origin", "takes_inspiration_from", false, false], [0, 1, 13, 14, "origin", "takes_inspiration_from", false, false], [0, 1, 16, 17, "origin", "takes_inspiration_from", false, false], [0, 1, 19, 21, "origin", "takes_inspiration_from", false, false], [28, 29, 0, 1, "origin", "", false, false], [31, 34, 0, 1, "origin", "", false, false], [36, 38, 0, 1, "origin", "", false, false], [39, 40, 0, 1, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Neuromorphic", "engineering", "is", "an", "interdisciplinary", "subject", "that", "draws", "inspiration", "from", "biology", ",", "physics", ",", "mathematics", ",", "computer", "science", "and", "electronic", "engineering", "to", "design", "artificial", "neural", "systems", "such", "as", "vision", "systems", ",", "head", "-", "eye", "systems", ",", "auditory", "processors", "and", "autonomous", "robots", ",", "whose", "physical", "architecture", "and", "design", "principles", "are", "based", "on", "those", "of", "biological", "neural", "systems", "."], "sentence-detokenized": "Neuromorphic engineering is an interdisciplinary subject that draws inspiration from biology, physics, mathematics, computer science and electronic engineering to design artificial neural systems such as vision systems, head-eye systems, auditory processors and autonomous robots, whose physical architecture and design principles are based on those of biological neural systems.", "token2charspan": [[0, 12], [13, 24], [25, 27], [28, 30], [31, 48], [49, 56], [57, 61], [62, 67], [68, 79], [80, 84], [85, 92], [92, 93], [94, 101], [101, 102], [103, 114], [114, 115], [116, 124], [125, 132], [133, 136], [137, 147], [148, 159], [160, 162], [163, 169], [170, 180], [181, 187], [188, 195], [196, 200], [201, 203], [204, 210], [211, 218], [218, 219], [220, 224], [224, 225], [225, 228], [229, 236], [236, 237], [238, 246], [247, 257], [258, 261], [262, 272], [273, 279], [279, 280], [281, 286], [287, 295], [296, 308], [309, 312], [313, 319], [320, 330], [331, 334], [335, 340], [341, 343], [344, 349], [350, 352], [353, 363], [364, 370], [371, 378], [378, 379]]}
{"doc_key": "ai-test-145", "ner": [[3, 6, "metrics"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 10, 3, 6, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["More", "specifically", ",", "the", "BIBO", "stability", "criterion", "requires", "that", "the", "ROC", "of", "the", "system", "includes", "a", "unit", "circle", "."], "sentence-detokenized": "More specifically, the BIBO stability criterion requires that the ROC of the system includes a unit circle.", "token2charspan": [[0, 4], [5, 17], [17, 18], [19, 22], [23, 27], [28, 37], [38, 47], [48, 56], [57, 61], [62, 65], [66, 69], [70, 72], [73, 76], [77, 83], [84, 92], [93, 94], [95, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-test-146", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "The", "programme", "was", "rewritten", "in", "Java", "starting", "in", "1998", "."], "sentence-detokenized": "2 The programme was rewritten in Java starting in 1998.", "token2charspan": [[0, 1], [2, 5], [6, 15], [16, 19], [20, 29], [30, 32], [33, 37], [38, 46], [47, 49], [50, 54], [54, 55]]}
{"doc_key": "ai-test-147", "ner": [[0, 1, "metrics"], [8, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 8, 9, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "MCC", "can", "be", "calculated", "directly", "from", "the", "confusion", "matrix", "using", "the", "formula", ":"], "sentence-detokenized": "The MCC can be calculated directly from the confusion matrix using the formula:", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 25], [26, 34], [35, 39], [40, 43], [44, 53], [54, 60], [61, 66], [67, 70], [71, 78], [78, 79]]}
{"doc_key": "ai-test-148", "ner": [[8, 13, "organisation"], [22, 27, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 13, 22, 27, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "developed", "by", "a", "team", "at", "the", "MIT", "-", "IBM", "Watson", "AI", "Lab", "and", "presented", "for", "the", "first", "time", "at", "the", "2018", "International", "Conference", "on", "Learning", "Representations", "."], "sentence-detokenized": "It was developed by a team at the MIT-IBM Watson AI Lab and presented for the first time at the 2018 International Conference on Learning Representations.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 29], [30, 33], [34, 37], [37, 38], [38, 41], [42, 48], [49, 51], [52, 55], [56, 59], [60, 69], [70, 73], [74, 77], [78, 83], [84, 88], [89, 91], [92, 95], [96, 100], [101, 114], [115, 125], [126, 128], [129, 137], [138, 153], [153, 154]]}
{"doc_key": "ai-test-149", "ner": [[2, 3, "metrics"], [15, 16, "metrics"], [18, 20, "metrics"], [49, 49, "metrics"], [51, 51, "metrics"], [56, 58, "metrics"], [61, 61, "metrics"], [63, 63, "metrics"], [65, 67, "metrics"], [72, 72, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[15, 16, 49, 49, "type-of", "", false, false], [15, 16, 56, 58, "related-to", "collapses_to_identity", false, false], [18, 20, 51, 51, "type-of", "", false, false], [18, 20, 56, 58, "related-to", "collapses_to_identity", false, false], [18, 20, 65, 67, "named", "same", false, false], [61, 61, 72, 72, "related-to", "collapses_to_identity", false, false], [63, 63, 72, 72, "related-to", "collapses_to_identity", false, false], [65, 67, 72, 72, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["When", "the", "TRUE", "prevalences", "for", "the", "two", "positive", "variables", "are", "equal", ",", "as", "assumed", "in", "Fleiss", "kappa", "and", "F", "-", "score", ",", "i.e.", "the", "number", "of", "positive", "predictors", "coincides", "with", "the", "number", "of", "positive", "classes", "in", "the", "dichotomous", "(", "two", "-", "class", ")", "case", ",", "the", "various", "measures", "of", "kappa", "and", "correlation", "collapse", "to", "identity", "with", "Youden", "'s", "J", ",", "and", "recall", ",", "precision", "and", "F", "-", "score", "are", "similarly", "identical", "with", "accuracy", "."], "sentence-detokenized": "When the TRUE prevalences for the two positive variables are equal, as assumed in Fleiss kappa and F-score, i.e. the number of positive predictors coincides with the number of positive classes in the dichotomous (two-class) case, the various measures of kappa and correlation collapse to identity with Youden's J, and recall, precision and F-score are similarly identical with accuracy.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 25], [26, 29], [30, 33], [34, 37], [38, 46], [47, 56], [57, 60], [61, 66], [66, 67], [68, 70], [71, 78], [79, 81], [82, 88], [89, 94], [95, 98], [99, 100], [100, 101], [101, 106], [106, 107], [108, 112], [113, 116], [117, 123], [124, 126], [127, 135], [136, 146], [147, 156], [157, 161], [162, 165], [166, 172], [173, 175], [176, 184], [185, 192], [193, 195], [196, 199], [200, 211], [212, 213], [213, 216], [216, 217], [217, 222], [222, 223], [224, 228], [228, 229], [230, 233], [234, 241], [242, 250], [251, 253], [254, 259], [260, 263], [264, 275], [276, 284], [285, 287], [288, 296], [297, 301], [302, 308], [308, 310], [311, 312], [312, 313], [314, 317], [318, 324], [324, 325], [326, 335], [336, 339], [340, 341], [341, 342], [342, 347], [348, 351], [352, 361], [362, 371], [372, 376], [377, 385], [385, 386]]}
{"doc_key": "ai-test-150", "ner": [[0, 7, "misc"], [5, 5, "misc"], [9, 9, "conference"], [14, 17, "task"], [18, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 7, 9, 9, "part-of", "", false, false], [0, 7, 9, 9, "physical", "", false, false], [0, 7, 9, 9, "temporal", "", false, false], [5, 5, 0, 7, "named", "", false, false], [14, 17, 0, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Building", "Educational", "Applications", "(", "BEA", ")", "workshop", "at", "NAACL", "2013", "hosted", "the", "inaugural", "NLI", "collaborative", "task", ".", "Tetreault", "et", "al", ",", "2013", "The", "competition", "resulted", "in", "29", "submissions", "from", "teams", "around", "the", "world", ",", "24", "of", "which", "also", "published", "a", "paper", "describing", "their", "systems", "and", "approaches", "."], "sentence-detokenized": "The Building Educational Applications (BEA) workshop at NAACL 2013 hosted the inaugural NLI collaborative task. Tetreault et al, 2013 The competition resulted in 29 submissions from teams around the world, 24 of which also published a paper describing their systems and approaches.", "token2charspan": [[0, 3], [4, 12], [13, 24], [25, 37], [38, 39], [39, 42], [42, 43], [44, 52], [53, 55], [56, 61], [62, 66], [67, 73], [74, 77], [78, 87], [88, 91], [92, 105], [106, 110], [110, 111], [112, 121], [122, 124], [125, 127], [127, 128], [129, 133], [134, 137], [138, 149], [150, 158], [159, 161], [162, 164], [165, 176], [177, 181], [182, 187], [188, 194], [195, 198], [199, 204], [204, 205], [206, 208], [209, 211], [212, 217], [218, 222], [223, 232], [233, 234], [235, 240], [241, 251], [252, 257], [258, 265], [266, 269], [270, 280], [280, 281]]}
{"doc_key": "ai-test-151", "ner": [[0, 1, "algorithm"], [5, 6, "algorithm"], [15, 16, "misc"], [19, 20, "misc"], [34, 39, "misc"], [38, 38, "algorithm"], [42, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 5, 6, "type-of", "", false, false], [0, 1, 15, 16, "related-to", "finds", false, false], [19, 20, 15, 16, "type-of", "", false, false], [42, 42, 38, 38, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Viterbi", "algorithm", "is", "a", "dynamic", "programming", "algorithm", "for", "finding", "the", "most", "likely", "sequence", "of", "hidden", "states", "called", "the", "Viterbi", "path", "resulting", "in", "a", "sequence", "of", "observed", "events", ",", "especially", "in", "the", "context", "of", "Markov", "information", "sources", "and", "hidden", "Markov", "models", "(", "HMMs", ")", "."], "sentence-detokenized": "The Viterbi algorithm is a dynamic programming algorithm for finding the most likely sequence of hidden states called the Viterbi path resulting in a sequence of observed events, especially in the context of Markov information sources and hidden Markov models (HMMs).", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 24], [25, 26], [27, 34], [35, 46], [47, 56], [57, 60], [61, 68], [69, 72], [73, 77], [78, 84], [85, 93], [94, 96], [97, 103], [104, 110], [111, 117], [118, 121], [122, 129], [130, 134], [135, 144], [145, 147], [148, 149], [150, 158], [159, 161], [162, 170], [171, 177], [177, 178], [179, 189], [190, 192], [193, 196], [197, 204], [205, 207], [208, 214], [215, 226], [227, 234], [235, 238], [239, 245], [246, 252], [253, 259], [260, 261], [261, 265], [265, 266], [266, 267]]}
{"doc_key": "ai-test-152", "ner": [[1, 1, "field"], [3, 5, "algorithm"], [7, 9, "misc"], [12, 13, "algorithm"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 1, 1, "part-of", "", false, false], [3, 5, 7, 9, "general-affiliation", "", false, false], [3, 5, 12, 13, "related-to", "generalizes_from", false, false], [3, 5, 15, 16, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "statistics", ",", "multinomial", "logistic", "regression", "is", "a", "classification", "method", "that", "generalises", "logistic", "regression", "to", "multiclass", "classification", ",", "i.e.", "with", "more", "than", "two", "possible", "discrete", "outcomes", "."], "sentence-detokenized": "In statistics, multinomial logistic regression is a classification method that generalises logistic regression to multiclass classification, i.e. with more than two possible discrete outcomes.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 26], [27, 35], [36, 46], [47, 49], [50, 51], [52, 66], [67, 73], [74, 78], [79, 90], [91, 99], [100, 110], [111, 113], [114, 124], [125, 139], [139, 140], [141, 145], [146, 150], [151, 155], [156, 160], [161, 164], [165, 173], [174, 182], [183, 191], [191, 192]]}
{"doc_key": "ai-test-153", "ner": [[1, 2, "algorithm"], [0, 10, "field"], [12, 14, "field"], [18, 18, "task"], [20, 20, "task"], [23, 24, "task"], [26, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 2, 0, 10, "part-of", "", false, false], [1, 2, 12, 14, "part-of", "", false, false], [18, 18, 1, 2, "usage", "", true, false], [20, 20, 1, 2, "usage", "", true, false], [23, 24, 1, 2, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hidden", "Markov", "models", "are", "known", "for", "their", "applications", "in", "reinforcement", "learning", "and", "temporal", "pattern", "recognition", ",", "such", "as", "speech", ",", "handwriting", "recognition", ",", "gesture", "recognition", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Hidden Markov models are known for their applications in reinforcement learning and temporal pattern recognition, such as speech, handwriting recognition, gesture recognition, Thad Starner, Alex Pentland.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 30], [31, 34], [35, 40], [41, 53], [54, 56], [57, 70], [71, 79], [80, 83], [84, 92], [93, 100], [101, 112], [112, 113], [114, 118], [119, 121], [122, 128], [128, 129], [130, 141], [142, 153], [153, 154], [155, 162], [163, 174], [174, 175], [176, 180], [181, 188], [188, 189], [190, 194], [195, 203], [203, 204]]}
{"doc_key": "ai-test-154", "ner": [[33, 37, "metrics"], [39, 40, "misc"]], "ner_mapping_to_source": [1, 2], "relations": [[33, 37, 39, 40, "related-to", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Essentially", ",", "this", "means", "that", "if", "thatn", "-", "gram", "has", "been", "seen", "more", "than", "k", "times", "in", "training", ",", "the", "conditional", "probability", "of", "the", "word", "given", "it", "s", "history", "is", "proportional", "to", "the", "maximum", "probability", "estimate", "of", "the", "tegon", "-", "gram", "."], "sentence-detokenized": "Essentially, this means that if thatn-gram has been seen more than k times in training, the conditional probability of the word given its history is proportional to the maximum probability estimate of the tegon -gram.", "token2charspan": [[0, 11], [11, 12], [13, 17], [18, 23], [24, 28], [29, 31], [32, 37], [37, 38], [38, 42], [43, 46], [47, 51], [52, 56], [57, 61], [62, 66], [67, 68], [69, 74], [75, 77], [78, 86], [86, 87], [88, 91], [92, 103], [104, 115], [116, 118], [119, 122], [123, 127], [128, 133], [134, 136], [136, 137], [138, 145], [146, 148], [149, 161], [162, 164], [165, 168], [169, 176], [177, 188], [189, 197], [198, 200], [201, 204], [205, 210], [211, 212], [212, 216], [216, 217]]}
{"doc_key": "ai-test-155", "ner": [[4, 5, "task"], [7, 8, "task"], [10, 12, "task"], [16, 18, "task"], [27, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[27, 29, 16, 18, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "interested", "in", "knowledge", "representation", ",", "commonsense", "reasoning", "and", "natural", "language", "understanding", ",", "believing", "that", "deep", "language", "understanding", "can", "currently", "only", "be", "achieved", "through", "the", "meaningful", "manual", "construction", "of", "semantically", "rich", "formalisms", "in", "combination", "with", "statistical", "preferences", "."], "sentence-detokenized": "He is interested in knowledge representation, commonsense reasoning and natural language understanding, believing that deep language understanding can currently only be achieved through the meaningful manual construction of semantically rich formalisms in combination with statistical preferences.", "token2charspan": [[0, 2], [3, 5], [6, 16], [17, 19], [20, 29], [30, 44], [44, 45], [46, 57], [58, 67], [68, 71], [72, 79], [80, 88], [89, 102], [102, 103], [104, 113], [114, 118], [119, 123], [124, 132], [133, 146], [147, 150], [151, 160], [161, 165], [166, 168], [169, 177], [178, 185], [186, 189], [190, 200], [201, 207], [208, 220], [221, 223], [224, 236], [237, 241], [242, 252], [253, 255], [256, 267], [268, 272], [273, 284], [285, 296], [296, 297]]}
{"doc_key": "ai-test-156", "ner": [[1, 1, "programlang"], [3, 3, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "JavaScript", ",", "Python", "or"], "sentence-detokenized": "In JavaScript, Python or", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 21], [22, 24]]}
{"doc_key": "ai-test-157", "ner": [[0, 2, "misc"], [7, 8, "misc"], [12, 12, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 7, 8, "part-of", "", false, false], [7, 8, 12, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Newcomb", "awards", "are", "announced", "in", "the", "AI", "Magazine", "published", "by", "the", "AAAI", "."], "sentence-detokenized": "The Newcomb awards are announced in the AI Magazine published by the AAAI.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 22], [23, 32], [33, 35], [36, 39], [40, 42], [43, 51], [52, 61], [62, 64], [65, 68], [69, 73], [73, 74]]}
{"doc_key": "ai-test-158", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "square", "error", "on", "a", "test", "set", "of", "100", "exemplars", "is", "0.084", ",", "which", "is", "smaller", "than", "the", "unnormalised", "error", "."], "sentence-detokenized": "The mean square error on a test set of 100 exemplars is 0.084, which is smaller than the unnormalised error.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 21], [22, 24], [25, 26], [27, 31], [32, 35], [36, 38], [39, 42], [43, 52], [53, 55], [56, 61], [61, 62], [63, 68], [69, 71], [72, 79], [80, 84], [85, 88], [89, 101], [102, 107], [107, 108]]}
{"doc_key": "ai-test-159", "ner": [[1, 3, "metrics"], [10, 12, "field"], [20, 22, "task"], [24, 24, "task"], [28, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 12, 1, 3, "usage", "", false, false], [20, 22, 10, 12, "part-of", "task_part_of_field", false, false], [24, 24, 20, 22, "named", "", false, false], [28, 28, 10, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "F", "-", "score", "has", "been", "widely", "used", "in", "the", "natural", "language", "processing", "literature", ",", "e.g.", "in", "the", "assessment", "of", "named", "entity", "recognition", "(", "NER", ")", "and", "word", "segmentation", "."], "sentence-detokenized": "The F-score has been widely used in the natural language processing literature, e.g. in the assessment of named entity recognition (NER) and word segmentation.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 15], [16, 20], [21, 27], [28, 32], [33, 35], [36, 39], [40, 47], [48, 56], [57, 67], [68, 78], [78, 79], [80, 84], [85, 87], [88, 91], [92, 102], [103, 105], [106, 111], [112, 118], [119, 130], [131, 132], [132, 135], [135, 136], [137, 140], [141, 145], [146, 158], [158, 159]]}
{"doc_key": "ai-test-160", "ner": [[0, 0, "product"], [5, 6, "product"], [17, 17, "misc"], [20, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 17, 17, "related-to", "performs_task", false, false], [0, 0, 20, 21, "related-to", "performs_task", false, false], [5, 6, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Chatbots", "are", "typically", "used", "in", "dialogue", "systems", "for", "a", "variety", "of", "purposes", ",", "including", "customer", "service", ",", "directing", "queries", "or", "collecting", "information", "."], "sentence-detokenized": "Chatbots are typically used in dialogue systems for a variety of purposes, including customer service, directing queries or collecting information.", "token2charspan": [[0, 8], [9, 12], [13, 22], [23, 27], [28, 30], [31, 39], [40, 47], [48, 51], [52, 53], [54, 61], [62, 64], [65, 73], [73, 74], [75, 84], [85, 93], [94, 101], [101, 102], [103, 112], [113, 120], [121, 123], [124, 134], [135, 146], [146, 147]]}
{"doc_key": "ai-test-161", "ner": [[3, 9, "conference"], [15, 21, "conference"], [29, 39, "conference"], [44, 44, "conference"], [48, 51, "conference"], [54, 54, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[15, 21, 3, 9, "named", "", false, false], [29, 39, 3, 9, "named", "", false, false], [44, 44, 29, 39, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Important", "journals", "include", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "later", "renamed", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", ",", "and", "as", "of", "September", "2014", "renamed", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "-", "after", "merging", "with", "ACM", "Publications", ")", ",", "Computer", "Speech", "and", "Language", "and", "Speech", "Communication", "."], "sentence-detokenized": "Important journals include IEEE Transactions on Speech and Audio Processing (later renamed IEEE Transactions on Audio, Speech and Language Processing, and as of September 2014 renamed IEEE / ACM Transactions on Audio, Speech and Language Processing - after merging with ACM Publications), Computer Speech and Language and Speech Communication.", "token2charspan": [[0, 9], [10, 18], [19, 26], [27, 31], [32, 44], [45, 47], [48, 54], [55, 58], [59, 64], [65, 75], [76, 77], [77, 82], [83, 90], [91, 95], [96, 108], [109, 111], [112, 117], [117, 118], [119, 125], [126, 129], [130, 138], [139, 149], [149, 150], [151, 154], [155, 157], [158, 160], [161, 170], [171, 175], [176, 183], [184, 188], [189, 190], [191, 194], [195, 207], [208, 210], [211, 216], [216, 217], [218, 224], [225, 228], [229, 237], [238, 248], [249, 250], [251, 256], [257, 264], [265, 269], [270, 273], [274, 286], [286, 287], [287, 288], [289, 297], [298, 304], [305, 308], [309, 317], [318, 321], [322, 328], [329, 342], [342, 343]]}
{"doc_key": "ai-test-162", "ner": [[0, 0, "algorithm"], [5, 6, "task"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 0, 0, "usage", "", false, false], [5, 6, 8, 9, "part-of", "task_part_of_field", false, false], [5, 6, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["EM", "is", "often", "used", "for", "data", "clustering", "in", "machine", "learning", "and", "computer", "vision", "."], "sentence-detokenized": "EM is often used for data clustering in machine learning and computer vision.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 16], [17, 20], [21, 25], [26, 36], [37, 39], [40, 47], [48, 56], [57, 60], [61, 69], [70, 76], [76, 77]]}
{"doc_key": "ai-test-163", "ner": [[8, 14, "metrics"], [23, 26, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 14, 23, 26, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["While", "there", "is", "no", "perfect", "way", "to", "describe", "the", "TRUE", "and", "FALSE", "confusion", "matrix", "of", "positives", "and", "negatives", "using", "a", "single", "number", ",", "the", "Matthews", "correlation", "coefficient", "is", "widely", "regarded", "as", "one", "of", "the", "best", "such", "measures", "."], "sentence-detokenized": "While there is no perfect way to describe the TRUE and FALSE confusion matrix of positives and negatives using a single number, the Matthews correlation coefficient is widely regarded as one of the best such measures.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 17], [18, 25], [26, 29], [30, 32], [33, 41], [42, 45], [46, 50], [51, 54], [55, 60], [61, 70], [71, 77], [78, 80], [81, 90], [91, 94], [95, 104], [105, 110], [111, 112], [113, 119], [120, 126], [126, 127], [128, 131], [132, 140], [141, 152], [153, 164], [165, 167], [168, 174], [175, 183], [184, 186], [187, 190], [191, 193], [194, 197], [198, 202], [203, 207], [208, 216], [216, 217]]}
{"doc_key": "ai-test-164", "ner": [[11, 12, "field"], [27, 28, "field"], [35, 36, "field"], [40, 41, "algorithm"], [43, 44, "task"], [46, 47, "algorithm"], [52, 53, "algorithm"], [55, 57, "algorithm"], [63, 65, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[35, 36, 27, 28, "part-of", "subfield", false, false], [40, 41, 35, 36, "part-of", "", false, true], [43, 44, 35, 36, "part-of", "", false, true], [46, 47, 35, 36, "part-of", "", false, true], [52, 53, 35, 36, "part-of", "", false, true], [55, 57, 35, 36, "part-of", "", false, true], [63, 65, 35, 36, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "datasets", "became", "larger", "and", "more", "complex", ",", "direct", ",", "practical", "data", "analysis", "was", "complemented", "by", "indirect", ",", "automated", "data", "processing", ",", "aided", "by", "other", "discoveries", "in", "computer", "science", ",", "especially", "in", "the", "field", "of", "machine", "learning", ",", "such", "as", "neural", "networks", ",", "cluster", "analysis", ",", "genetic", "algorithms", "(", "1950s", ")", ",", "decision", "tree", "and", "decision", "rule", "learning", "(", "1960", "s", ")", "and", "support", "vector", "machines", "(", "1990", "s", ")", "."], "sentence-detokenized": "As datasets became larger and more complex, direct, practical data analysis was complemented by indirect, automated data processing, aided by other discoveries in computer science, especially in the field of machine learning, such as neural networks, cluster analysis, genetic algorithms (1950s), decision tree and decision rule learning (1960s) and support vector machines (1990s).", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 25], [26, 29], [30, 34], [35, 42], [42, 43], [44, 50], [50, 51], [52, 61], [62, 66], [67, 75], [76, 79], [80, 92], [93, 95], [96, 104], [104, 105], [106, 115], [116, 120], [121, 131], [131, 132], [133, 138], [139, 141], [142, 147], [148, 159], [160, 162], [163, 171], [172, 179], [179, 180], [181, 191], [192, 194], [195, 198], [199, 204], [205, 207], [208, 215], [216, 224], [224, 225], [226, 230], [231, 233], [234, 240], [241, 249], [249, 250], [251, 258], [259, 267], [267, 268], [269, 276], [277, 287], [288, 289], [289, 294], [294, 295], [295, 296], [297, 305], [306, 310], [311, 314], [315, 323], [324, 328], [329, 337], [338, 339], [339, 343], [343, 344], [344, 345], [346, 349], [350, 357], [358, 364], [365, 373], [374, 375], [375, 379], [379, 380], [380, 381], [381, 382]]}
{"doc_key": "ai-test-165", "ner": [[4, 4, "researcher"], [8, 9, "misc"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 4, 4, "artifact", "", false, false], [8, 9, 16, 17, "artifact", "", false, false], [8, 9, 19, 20, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "autumn", "2005", ",", "Thrun", "published", "the", "textbook", "Probabilistic", "Robotics", "with", "his", "long", "-", "time", "collaborators", "Dieter", "Fox", "and", "Wolfram", "Burgard", "."], "sentence-detokenized": "In autumn 2005, Thrun published the textbook Probabilistic Robotics with his long-time collaborators Dieter Fox and Wolfram Burgard.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 21], [22, 31], [32, 35], [36, 44], [45, 58], [59, 67], [68, 72], [73, 76], [77, 81], [81, 82], [82, 86], [87, 100], [101, 107], [108, 111], [112, 115], [116, 123], [124, 131], [131, 132]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "and", "Pereiramath", "as", "follows", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum and Pereiramath as follows:", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 37], [38, 49], [50, 52], [53, 60], [60, 61]]}
{"doc_key": "ai-test-167", "ner": [[0, 1, "task"], [3, 3, "task"], [9, 14, "field"], [15, 16, "field"], [18, 20, "field"], [22, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 15, 16, "part-of", "task_part_of_field", false, false], [0, 1, 18, 20, "part-of", "task_part_of_field", false, false], [3, 3, 0, 1, "named", "", false, false], [15, 16, 9, 14, "part-of", "subfield", false, false], [18, 20, 9, 14, "part-of", "subfield", false, false], [22, 22, 18, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Question", "answering", "(", "QA", ")", "is", "a", "branch", "of", "computer", "science", "in", "the", "field", "of", "information", "retrieval", "and", "natural", "language", "processing", "(", "NLP", ")", "that", "deals", "with", "building", "systems", "that", "automatically", "answer", "questions", "asked", "by", "humans", "in", "natural", "language", "."], "sentence-detokenized": "Question answering (QA) is a branch of computer science in the field of information retrieval and natural language processing (NLP) that deals with building systems that automatically answer questions asked by humans in natural language.", "token2charspan": [[0, 8], [9, 18], [19, 20], [20, 22], [22, 23], [24, 26], [27, 28], [29, 35], [36, 38], [39, 47], [48, 55], [56, 58], [59, 62], [63, 68], [69, 71], [72, 83], [84, 93], [94, 97], [98, 105], [106, 114], [115, 125], [126, 127], [127, 130], [130, 131], [132, 136], [137, 142], [143, 147], [148, 156], [157, 164], [165, 169], [170, 183], [184, 190], [191, 200], [201, 206], [207, 209], [210, 216], [217, 219], [220, 227], [228, 236], [236, 237]]}
{"doc_key": "ai-test-168", "ner": [[10, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "in", "the", "version", "of", "the", "metric", "used", "in", "NIST", "evaluations", "prior", "to", "2009", ",", "the", "shortest", "reference", "sentence", "was", "used", "instead", "."], "sentence-detokenized": "However, in the version of the metric used in NIST evaluations prior to 2009, the shortest reference sentence was used instead.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 37], [38, 42], [43, 45], [46, 50], [51, 62], [63, 68], [69, 71], [72, 76], [76, 77], [78, 81], [82, 90], [91, 100], [101, 109], [110, 113], [114, 118], [119, 126], [126, 127]]}
{"doc_key": "ai-test-169", "ner": [[5, 5, "person"], [13, 14, "organisation"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 15, 15, "related-to", "invests_in", false, false], [15, 15, 13, 14, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["On", "27", "August", "2018", ",", "Toyota", "announced", "a", "$", "500", "million", "investment", "in", "Uber", "'s", "autonomous", "cars", "."], "sentence-detokenized": "On 27 August 2018, Toyota announced a $500 million investment in Uber's autonomous cars.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 17], [17, 18], [19, 25], [26, 35], [36, 37], [38, 39], [39, 42], [43, 50], [51, 61], [62, 64], [65, 69], [69, 71], [72, 82], [83, 87], [87, 88]]}
{"doc_key": "ai-test-170", "ner": [[6, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sample", "maximum", "is", "a", "maximum", "likelihood", "estimator", "for", "the", "population", "maximum", "but", ",", "as", "discussed", "above", ",", "it", "is", "biased", "."], "sentence-detokenized": "The sample maximum is a maximum likelihood estimator for the population maximum but, as discussed above, it is biased.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 21], [22, 23], [24, 31], [32, 42], [43, 52], [53, 56], [57, 60], [61, 71], [72, 79], [80, 83], [83, 84], [85, 87], [88, 97], [98, 103], [103, 104], [105, 107], [108, 110], [111, 117], [117, 118]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [3, 3, "misc"], [6, 6, "metrics"], [15, 17, "algorithm"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 3, "related-to", "overcomes", false, false], [0, 0, 6, 6, "related-to", "increases", false, false], [3, 3, 15, 17, "opposite", "", false, false], [3, 3, 19, 21, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LSI", "helps", "overcome", "synonymy", "by", "increasing", "recall", ",", "one", "of", "the", "most", "problematic", "limitations", "of", "Boolean", "keyword", "queries", "and", "vector", "space", "models", "."], "sentence-detokenized": "LSI helps overcome synonymy by increasing recall, one of the most problematic limitations of Boolean keyword queries and vector space models.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 27], [28, 30], [31, 41], [42, 48], [48, 49], [50, 53], [54, 56], [57, 60], [61, 65], [66, 77], [78, 89], [90, 92], [93, 100], [101, 108], [109, 116], [117, 120], [121, 127], [128, 133], [134, 140], [140, 141]]}
{"doc_key": "ai-test-172", "ner": [[0, 1, "task"], [20, 20, "programlang"], [22, 22, "programlang"], [24, 24, "programlang"], [26, 30, "programlang"], [31, 31, "programlang"], [33, 33, "programlang"], [35, 35, "programlang"], [37, 37, "programlang"], [39, 39, "programlang"], [41, 41, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 20, 20, "general-affiliation", "", false, false], [0, 1, 22, 22, "general-affiliation", "", false, false], [0, 1, 24, 24, "general-affiliation", "", false, false], [0, 1, 26, 30, "general-affiliation", "", false, false], [0, 1, 31, 31, "general-affiliation", "", false, false], [0, 1, 33, 33, "general-affiliation", "", false, false], [0, 1, 35, 35, "general-affiliation", "", false, false], [0, 1, 37, 37, "general-affiliation", "", false, false], [0, 1, 39, 39, "general-affiliation", "", false, false], [0, 1, 41, 41, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Data", "acquisition", "applications", "are", "usually", "controlled", "by", "programmes", "developed", "using", "a", "variety", "of", "general", "-", "purpose", "programming", "languages", "such", "as", "Assembly", ",", "BASIC", ",", "C", ",", "C", "+", "+", ",", "C", "#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", ",", "etc."], "sentence-detokenized": "Data acquisition applications are usually controlled by programmes developed using a variety of general-purpose programming languages such as Assembly, BASIC, C, C + +, C #, Fortran, Java, LabVIEW, Lisp, Pascal, etc.", "token2charspan": [[0, 4], [5, 16], [17, 29], [30, 33], [34, 41], [42, 52], [53, 55], [56, 66], [67, 76], [77, 82], [83, 84], [85, 92], [93, 95], [96, 103], [103, 104], [104, 111], [112, 123], [124, 133], [134, 138], [139, 141], [142, 150], [150, 151], [152, 157], [157, 158], [159, 160], [160, 161], [162, 163], [164, 165], [166, 167], [167, 168], [169, 170], [171, 172], [172, 173], [174, 181], [181, 182], [183, 187], [187, 188], [189, 196], [196, 197], [198, 202], [202, 203], [204, 210], [210, 211], [212, 216]]}
{"doc_key": "ai-test-173", "ner": [[3, 3, "organisation"], [6, 14, "product"], [10, 10, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 14, 3, 3, "artifact", "", false, false], [6, 14, 10, 10, "physical", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2003", ",", "Honda", "released", "a", "Cog", "advert", "in", "the", "UK", "and", "on", "the", "internet", "."], "sentence-detokenized": "In 2003, Honda released a Cog advert in the UK and on the internet.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 25], [26, 29], [30, 36], [37, 39], [40, 43], [44, 46], [47, 50], [51, 53], [54, 57], [58, 66], [66, 67]]}
{"doc_key": "ai-test-174", "ner": [[0, 4, "conference"], [6, 6, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 6, 6, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Association", "for", "Computational", "Linguistics", "defines", "computational", "linguistics", "as", ":"], "sentence-detokenized": "The Association for Computational Linguistics defines computational linguistics as:", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 33], [34, 45], [46, 53], [54, 67], [68, 79], [80, 82], [82, 83]]}
{"doc_key": "ai-test-175", "ner": [[0, 2, "algorithm"], [9, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 13, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["Expectation", "-maximisation", "algorithms", "can", "be", "used", "to", "calculate", "approximate", "maximum", "likelihood", "estimates", "of", "the", "unknown", "parameters", "of", "the", "state", "space", "in", "minimum", "variance", "filters", "and", "smoothers", "."], "sentence-detokenized": "Expectation-maximisation algorithms can be used to calculate approximate maximum likelihood estimates of the unknown parameters of the state space in minimum variance filters and smoothers.", "token2charspan": [[0, 11], [11, 24], [25, 35], [36, 39], [40, 42], [43, 47], [48, 50], [51, 60], [61, 72], [73, 80], [81, 91], [92, 101], [102, 104], [105, 108], [109, 116], [117, 127], [128, 130], [131, 134], [135, 140], [141, 146], [147, 149], [150, 157], [158, 166], [167, 174], [175, 178], [179, 188], [188, 189]]}
{"doc_key": "ai-test-176", "ner": [[3, 3, "misc"], [5, 7, "person"], [9, 10, "person"], [12, 13, "person"], [16, 17, "misc"], [18, 19, "person"], [22, 23, "person"], [27, 28, "person"], [29, 30, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 7, 3, 3, "role", "actor_in", false, false], [9, 10, 3, 3, "role", "actor_in", false, false], [12, 13, 3, 3, "role", "actor_in", false, false], [18, 19, 16, 17, "role", "model_for", false, false], [27, 28, 29, 30, "social", "family", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Correspondents", "included", "former", "Baywatch", "actresses", "Donna", "D'", "Errico", ",", "Carmen", "Electra", "and", "Traci", "Bingham", ",", "former", "Playboy", "Playmate", "Heidi", "Mark", ",", "comedian", "Arj", "Barker", "and", "identical", "twins", "Randy", "and", "Jason", "Sklar", "."], "sentence-detokenized": "Correspondents included former Baywatch actresses Donna D'Errico, Carmen Electra and Traci Bingham, former Playboy Playmate Heidi Mark, comedian Arj Barker and identical twins Randy and Jason Sklar.", "token2charspan": [[0, 14], [15, 23], [24, 30], [31, 39], [40, 49], [50, 55], [56, 58], [58, 64], [64, 65], [66, 72], [73, 80], [81, 84], [85, 90], [91, 98], [98, 99], [100, 106], [107, 114], [115, 123], [124, 129], [130, 134], [134, 135], [136, 144], [145, 148], [149, 155], [156, 159], [160, 169], [170, 175], [176, 181], [182, 185], [186, 191], [192, 197], [197, 198]]}
{"doc_key": "ai-test-177", "ner": [[8, 9, "task"], [11, 11, "task"], [16, 19, "product"], [22, 23, "task"], [25, 25, "task"], [30, 32, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 8, 9, "named", "", false, false], [16, 19, 8, 9, "general-affiliation", "", false, false], [25, 25, 22, 23, "named", "", false, false], [30, 32, 22, 23, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "is", "commonly", "used", "to", "generate", "representations", "for", "speech", "recognition", "(", "ASR", ")", ",", "such", "as", "the", "Sphinx", "CMU", "system", ",", "and", "speech", "synthesis", "(", "TTS", ")", ",", "such", "as", "the", "Festival", "system", "."], "sentence-detokenized": "It is commonly used to generate representations for speech recognition (ASR), such as the Sphinx CMU system, and speech synthesis (TTS), such as the Festival system.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 19], [20, 22], [23, 31], [32, 47], [48, 51], [52, 58], [59, 70], [71, 72], [72, 75], [75, 76], [76, 77], [78, 82], [83, 85], [86, 89], [90, 96], [97, 100], [101, 107], [107, 108], [109, 112], [113, 119], [120, 129], [130, 131], [131, 134], [134, 135], [135, 136], [137, 141], [142, 144], [145, 148], [149, 157], [158, 164], [164, 165]]}
{"doc_key": "ai-test-178", "ner": [[0, 0, "metrics"], [2, 4, "metrics"], [6, 6, "metrics"], [12, 12, "metrics"], [26, 27, "metrics"], [29, 29, "metrics"], [39, 40, "metrics"], [42, 42, "metrics"], [44, 46, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 4, 0, 0, "named", "", false, false], [6, 6, 2, 4, "named", "", false, false], [12, 12, 0, 0, "named", "", false, false], [29, 29, 26, 27, "named", "", false, false], [42, 42, 39, 40, "named", "", false, false], [44, 46, 39, 40, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sensitivity", "or", "TRUE", "Positive", "Rate", "(", "TPR", ")", ",", "also", "known", "as", "recall", ",", "is", "the", "proportion", "of", "people", "who", "test", "positive", "and", "are", "positive", "(", "TRUE", "Positive", ",", "TP", ")", "to", "all", "people", "who", "are", "actually", "positive", "(", "Condition", "Positive", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "Sensitivity or TRUE Positive Rate (TPR), also known as recall, is the proportion of people who test positive and are positive (TRUE Positive, TP) to all people who are actually positive (Condition Positive, CP = TP + FN).", "token2charspan": [[0, 11], [12, 14], [15, 19], [20, 28], [29, 33], [34, 35], [35, 38], [38, 39], [39, 40], [41, 45], [46, 51], [52, 54], [55, 61], [61, 62], [63, 65], [66, 69], [70, 80], [81, 83], [84, 90], [91, 94], [95, 99], [100, 108], [109, 112], [113, 116], [117, 125], [126, 127], [127, 131], [132, 140], [140, 141], [142, 144], [144, 145], [146, 148], [149, 152], [153, 159], [160, 163], [164, 167], [168, 176], [177, 185], [186, 187], [187, 196], [197, 205], [205, 206], [207, 209], [210, 211], [212, 214], [215, 216], [217, 219], [219, 220], [220, 221]]}
{"doc_key": "ai-test-179", "ner": [[1, 2, "task"], [10, 10, "conference"], [12, 13, "conference"], [15, 15, "conference"], [17, 17, "conference"], [19, 19, "conference"], [21, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 10, 1, 2, "topic", "", false, false], [12, 13, 1, 2, "topic", "", false, false], [15, 15, 1, 2, "topic", "", false, false], [17, 17, 1, 2, "topic", "", false, false], [19, 19, 1, 2, "topic", "", false, false], [21, 22, 1, 2, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Popular", "speech", "recognition", "conferences", "held", "every", "year", "or", "two", "include", "SpeechTEK", "and", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", "and", "IEEE", "ASRU", "."], "sentence-detokenized": "Popular speech recognition conferences held every year or two include SpeechTEK and SpeechTEK Europe, ICASSP, Interspeech / Eurospeech and IEEE ASRU.", "token2charspan": [[0, 7], [8, 14], [15, 26], [27, 38], [39, 43], [44, 49], [50, 54], [55, 57], [58, 61], [62, 69], [70, 79], [80, 83], [84, 93], [94, 100], [100, 101], [102, 108], [108, 109], [110, 121], [122, 123], [124, 134], [135, 138], [139, 143], [144, 148], [148, 149]]}
{"doc_key": "ai-test-180", "ner": [[0, 0, "researcher"], [3, 3, "researcher"], [17, 19, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 0, 0, "artifact", "", false, false], [22, 22, 3, 3, "artifact", "", false, false], [22, 22, 17, 19, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Devol", "worked", "with", "Engelberger", ",", "who", "served", "as", "the", "company", "'s", "president", ",", "to", "design", "and", "manufacture", "an", "industrial", "robot", "under", "the", "Unimate", "brand", "."], "sentence-detokenized": "Devol worked with Engelberger, who served as the company's president, to design and manufacture an industrial robot under the Unimate brand.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 29], [29, 30], [31, 34], [35, 41], [42, 44], [45, 48], [49, 56], [56, 58], [59, 68], [68, 69], [70, 72], [73, 79], [80, 83], [84, 95], [96, 98], [99, 109], [110, 115], [116, 121], [122, 125], [126, 133], [134, 139], [139, 140]]}
{"doc_key": "ai-test-181", "ner": [[0, 3, "algorithm"], [5, 5, "algorithm"], [9, 12, "algorithm"], [23, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 9, 12, "general-affiliation", "", false, false], [5, 5, 0, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "hidden", "Markov", "model", "(", "HMM", ")", "is", "a", "statistical", "Markov", "model", "in", "which", "the", "system", "being", "modelled", "is", "assumed", "to", "be", "a", "Markov", "process", "with", "unobserved", "(", "hidden", ")", "states", "."], "sentence-detokenized": "A hidden Markov model (HMM) is a statistical Markov model in which the system being modelled is assumed to be a Markov process with unobserved (hidden) states.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [22, 23], [23, 26], [26, 27], [28, 30], [31, 32], [33, 44], [45, 51], [52, 57], [58, 60], [61, 66], [67, 70], [71, 77], [78, 83], [84, 92], [93, 95], [96, 103], [104, 106], [107, 109], [110, 111], [112, 118], [119, 126], [127, 131], [132, 142], [143, 144], [144, 150], [150, 151], [152, 158], [158, 159]]}
{"doc_key": "ai-test-182", "ner": [[18, 22, "metrics"], [26, 26, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "property", ",", "which", "is", "undesirable", "in", "many", "applications", ",", "has", "led", "researchers", "to", "use", "alternatives", "such", "as", "mean", "absolute", "error", "or", "those", "based", "on", "the", "median", "."], "sentence-detokenized": "This property, which is undesirable in many applications, has led researchers to use alternatives such as mean absolute error or those based on the median.", "token2charspan": [[0, 4], [5, 13], [13, 14], [15, 20], [21, 23], [24, 35], [36, 38], [39, 43], [44, 56], [56, 57], [58, 61], [62, 65], [66, 77], [78, 80], [81, 84], [85, 97], [98, 102], [103, 105], [106, 110], [111, 119], [120, 125], [126, 128], [129, 134], [135, 140], [141, 143], [144, 147], [148, 154], [154, 155]]}
{"doc_key": "ai-test-183", "ner": [[24, 24, "algorithm"], [32, 33, "field"], [36, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[24, 24, 32, 33, "part-of", "", false, false], [24, 24, 36, 38, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Such", "a", "sequence", "(", "which", "at", "each", "stage", "depends", "on", "the", "outcome", "of", "the", "examination", "of", "the", "previous", "attributes", ")", "is", "called", "a", "decision", "tree", "and", "is", "used", "in", "the", "field", "of", "machine", "learning", "known", "as", "decision", "tree", "learning", "."], "sentence-detokenized": "Such a sequence (which at each stage depends on the outcome of the examination of the previous attributes) is called a decision tree and is used in the field of machine learning known as decision tree learning.", "token2charspan": [[0, 4], [5, 6], [7, 15], [16, 17], [17, 22], [23, 25], [26, 30], [31, 36], [37, 44], [45, 47], [48, 51], [52, 59], [60, 62], [63, 66], [67, 78], [79, 81], [82, 85], [86, 94], [95, 105], [105, 106], [107, 109], [110, 116], [117, 118], [119, 127], [128, 132], [133, 136], [137, 139], [140, 144], [145, 147], [148, 151], [152, 157], [158, 160], [161, 168], [169, 177], [178, 183], [184, 186], [187, 195], [196, 200], [201, 209], [209, 210]]}
{"doc_key": "ai-test-184", "ner": [[2, 3, "task"], [5, 5, "algorithm"], [20, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 5, 5, "compare", "", false, false], [20, 22, 5, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "in", "factor", "analysis", ",", "LCA", "can", "also", "be", "used", "to", "classify", "a", "case", "according", "to", "their", "membership", "of", "a", "maximum", "likelihood", "class", "."], "sentence-detokenized": "As in factor analysis, LCA can also be used to classify a case according to their membership of a maximum likelihood class.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 21], [21, 22], [23, 26], [27, 30], [31, 35], [36, 38], [39, 43], [44, 46], [47, 55], [56, 57], [58, 62], [63, 72], [73, 75], [76, 81], [82, 92], [93, 95], [96, 97], [98, 105], [106, 116], [117, 122], [122, 123]]}
{"doc_key": "ai-test-185", "ner": [[0, 2, "algorithm"], [6, 8, "metrics"], [10, 10, "metrics"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 6, 8, "usage", "", false, false], [6, 8, 12, 13, "related-to", "", false, false], [10, 10, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Supervised", "neural", "networks", "that", "use", "a", "mean", "squared", "error", "(", "MSE", ")", "cost", "function", "can", "use", "formal", "statistical", "methods", "to", "determine", "the", "confidence", "of", "the", "model", "being", "trained", "."], "sentence-detokenized": "Supervised neural networks that use a mean squared error (MSE) cost function can use formal statistical methods to determine the confidence of the model being trained.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 31], [32, 35], [36, 37], [38, 42], [43, 50], [51, 56], [57, 58], [58, 61], [61, 62], [63, 67], [68, 76], [77, 80], [81, 84], [85, 91], [92, 103], [104, 111], [112, 114], [115, 124], [125, 128], [129, 139], [140, 142], [143, 146], [147, 152], [153, 158], [159, 166], [166, 167]]}
{"doc_key": "ai-test-186", "ner": [[16, 18, "algorithm"], [20, 23, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 18, 20, 23, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "can", "be", "directly", "expressed", "as", "a", "linear", "programme", ",", "but", "it", "is", "also", "equivalent", "to", "Tikhonov", "'s", "regularity", "with", "the", "hinge", "loss", "function", ",", "mathV", "(", "f", "(", "x", ")", ",", "y", ")", "=", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "math", ":"], "sentence-detokenized": "This can be directly expressed as a linear programme, but it is also equivalent to Tikhonov's regularity with the hinge loss function, mathV (f (x), y) = max (0, 1 - yf (x)) / math:", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 20], [21, 30], [31, 33], [34, 35], [36, 42], [43, 52], [52, 53], [54, 57], [58, 60], [61, 63], [64, 68], [69, 79], [80, 82], [83, 91], [91, 93], [94, 104], [105, 109], [110, 113], [114, 119], [120, 124], [125, 133], [133, 134], [135, 140], [141, 142], [142, 143], [144, 145], [145, 146], [146, 147], [147, 148], [149, 150], [150, 151], [152, 153], [154, 157], [158, 159], [159, 160], [160, 161], [162, 163], [164, 165], [166, 168], [169, 170], [170, 171], [171, 172], [172, 173], [174, 175], [176, 180], [180, 181]]}
{"doc_key": "ai-test-187", "ner": [[6, 7, "researcher"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "technique", "is", "described", "in", "Breiman", "'s", "original", "paper", "and", "is", "implemented", "in", "the", "R", "package", "randomForest", "."], "sentence-detokenized": "The following technique is described in Breiman's original paper and is implemented in the R package randomForest.", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 26], [27, 36], [37, 39], [40, 47], [47, 49], [50, 58], [59, 64], [65, 68], [69, 71], [72, 83], [84, 86], [87, 90], [91, 92], [93, 100], [101, 113], [113, 114]]}
{"doc_key": "ai-test-188", "ner": [[8, 8, "metrics"], [41, 41, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "measures", "of", "image", "quality", ",", "such", "as", "PSNR", ",", "are", "usually", "performed", "on", "fixed", "-", "resolution", "images", "and", "do", "not", "take", "into", "account", "some", "aspects", "of", "the", "human", "visual", "system", ",", "such", "as", "the", "change", "in", "spatial", "resolution", "within", "the", "retina", "."], "sentence-detokenized": "Traditional measures of image quality, such as PSNR, are usually performed on fixed-resolution images and do not take into account some aspects of the human visual system, such as the change in spatial resolution within the retina.", "token2charspan": [[0, 11], [12, 20], [21, 23], [24, 29], [30, 37], [37, 38], [39, 43], [44, 46], [47, 51], [51, 52], [53, 56], [57, 64], [65, 74], [75, 77], [78, 83], [83, 84], [84, 94], [95, 101], [102, 105], [106, 108], [109, 112], [113, 117], [118, 122], [123, 130], [131, 135], [136, 143], [144, 146], [147, 150], [151, 156], [157, 163], [164, 170], [170, 171], [172, 176], [177, 179], [180, 183], [184, 190], [191, 193], [194, 201], [202, 212], [213, 219], [220, 223], [224, 230], [230, 231]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [10, 11, "person"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 17, "role", "", false, false], [3, 4, 16, 17, "role", "", false, false], [6, 7, 16, 17, "role", "", false, false], [16, 17, 10, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Dru", "and", "Macdonald", "Carey", "starred", "in", "Jack", "Broder", "'s", "colourful", "production", "of", "Hannah", "Lee", ",", "which", "premiered", "on", "19", "June", "1953", "."], "sentence-detokenized": "John Ireland, Joanne Dru and Macdonald Carey starred in Jack Broder's colourful production of Hannah Lee, which premiered on 19 June 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 55], [56, 60], [61, 67], [67, 69], [70, 79], [80, 90], [91, 93], [94, 100], [101, 104], [104, 105], [106, 111], [112, 121], [122, 124], [125, 127], [128, 132], [133, 137], [137, 138]]}
{"doc_key": "ai-test-190", "ner": [[4, 5, "task"], [11, 12, "field"], [17, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 11, 12, "usage", "", false, false], [17, 17, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "process", "is", "called", "image", "registration", "and", "uses", "various", "methods", "of", "computer", "vision", ",", "mainly", "related", "to", "tracking", "."], "sentence-detokenized": "This process is called image registration and uses various methods of computer vision, mainly related to tracking.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 22], [23, 28], [29, 41], [42, 45], [46, 50], [51, 58], [59, 66], [67, 69], [70, 78], [79, 85], [85, 86], [87, 93], [94, 101], [102, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-test-191", "ner": [[17, 18, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Now", "let", "us", "begin", "to", "explain", "the", "various", "possible", "relationships", "between", "the", "predicted", "and", "actual", "outcomes", ":", "Confusion", "matrix"], "sentence-detokenized": "Now let us begin to explain the various possible relationships between the predicted and actual outcomes: Confusion matrix", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 16], [17, 19], [20, 27], [28, 31], [32, 39], [40, 48], [49, 62], [63, 70], [71, 74], [75, 84], [85, 88], [89, 95], [96, 104], [104, 105], [106, 115], [116, 122]]}
{"doc_key": "ai-test-192", "ner": [[1, 1, "product"], [0, 4, "misc"], [6, 6, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 0, 4, "part-of", "", false, false], [1, 1, 0, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "VOICEBOX", "speech", "processing", "toolkit", "for", "MATLAB", "implements", "conversion", "and", "its", "inverse", "as", ":"], "sentence-detokenized": "The VOICEBOX speech processing toolkit for MATLAB implements conversion and its inverse as:", "token2charspan": [[0, 3], [4, 12], [13, 19], [20, 30], [31, 38], [39, 42], [43, 49], [50, 60], [61, 71], [72, 75], [76, 79], [80, 87], [88, 90], [90, 91]]}
{"doc_key": "ai-test-193", "ner": [[0, 0, "programlang"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 9, "general-affiliation", "", false, false], [0, 0, 11, 12, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "is", "a", "logic", "programming", "language", "related", "to", "artificial", "intelligence", "and", "computational", "linguistics", "."], "sentence-detokenized": "Prolog is a logic programming language related to artificial intelligence and computational linguistics.", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 17], [18, 29], [30, 38], [39, 46], [47, 49], [50, 60], [61, 73], [74, 77], [78, 91], [92, 103], [103, 104]]}
{"doc_key": "ai-test-194", "ner": [[0, 0, "researcher"], [9, 9, "field"], [11, 11, "field"], [17, 20, "organisation"], [22, 28, "organisation"], [29, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 9, 9, "related-to", "works_with_topic", false, false], [0, 0, 11, 11, "related-to", "works_with_topic", false, false], [0, 0, 17, 20, "role", "", false, false], [0, 0, 22, 28, "role", "", false, false], [0, 0, 29, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "has", "received", "numerous", "awards", "for", "her", "contributions", "to", "neuroscience", "and", "psychology", ",", "including", "membership", "of", "the", "Royal", "Society", "of", "London", ",", "the", "Royal", "Society", "of", "Canada", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner has received numerous awards for her contributions to neuroscience and psychology, including membership of the Royal Society of London, the Royal Society of Canada and the National Academy of Sciences.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 28], [29, 35], [36, 39], [40, 43], [44, 57], [58, 60], [61, 73], [74, 77], [78, 88], [88, 89], [90, 99], [100, 110], [111, 113], [114, 117], [118, 123], [124, 131], [132, 134], [135, 141], [141, 142], [143, 146], [147, 152], [153, 160], [161, 163], [164, 170], [171, 174], [175, 178], [179, 187], [188, 195], [196, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-test-195", "ner": [[11, 12, "field"], [17, 18, "task"], [21, 21, "task"], [24, 24, "task"], [27, 27, "task"], [29, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[17, 18, 11, 12, "part-of", "task_part_of_field", false, false], [21, 21, 11, 12, "part-of", "task_part_of_field", false, false], [24, 24, 11, 12, "part-of", "task_part_of_field", false, false], [27, 27, 11, 12, "part-of", "task_part_of_field", false, false], [29, 29, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["By", "combining", "these", "operators", ",", "algorithms", "can", "be", "obtained", "for", "many", "image", "processing", "tasks", ",", "such", "as", "feature", "extraction", ",", "image", "segmentation", ",", "image", "sharpening", ",", "image", "filtering", "or", "classification", "."], "sentence-detokenized": "By combining these operators, algorithms can be obtained for many image processing tasks, such as feature extraction, image segmentation, image sharpening, image filtering or classification.", "token2charspan": [[0, 2], [3, 12], [13, 18], [19, 28], [28, 29], [30, 40], [41, 44], [45, 47], [48, 56], [57, 60], [61, 65], [66, 71], [72, 82], [83, 88], [88, 89], [90, 94], [95, 97], [98, 105], [106, 116], [116, 117], [118, 123], [124, 136], [136, 137], [138, 143], [144, 154], [154, 155], [156, 161], [162, 171], [172, 174], [175, 189], [189, 190]]}
{"doc_key": "ai-test-196", "ner": [[7, 9, "university"], [15, 17, "organisation"], [19, 20, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 20, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "has", "been", "a", "professor", "at", "the", "Coll\u00e8ge", "de", "France", "since", "2017", "and", "director", "of", "INSERM", "Unit", "562", ",", "Cognitive", "Neuroimaging", ",", "since", "1989", "."], "sentence-detokenized": "He has been a professor at the Coll\u00e8ge de France since 2017 and director of INSERM Unit 562, Cognitive Neuroimaging, since 1989.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 13], [14, 23], [24, 26], [27, 30], [31, 38], [39, 41], [42, 48], [49, 54], [55, 59], [60, 63], [64, 72], [73, 75], [76, 82], [83, 87], [88, 91], [91, 92], [93, 102], [103, 115], [115, 116], [117, 122], [123, 127], [127, 128]]}
{"doc_key": "ai-test-197", "ner": [[12, 13, "algorithm"], [15, 18, "algorithm"], [23, 23, "algorithm"], [25, 31, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 25, 31, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["There", "are", "many", "approaches", "to", "learning", "these", "embeddings", ",", "in", "particular", "using", "Bayesian", "clustering", "or", "energy", "-", "based", "frameworks", ",", "and", "more", "recently", "TransE", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", "2013", ")", "."], "sentence-detokenized": "There are many approaches to learning these embeddings, in particular using Bayesian clustering or energy-based frameworks, and more recently TransE (Conference on Neural Information Processing Systems 2013).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 25], [26, 28], [29, 37], [38, 43], [44, 54], [54, 55], [56, 58], [59, 69], [70, 75], [76, 84], [85, 95], [96, 98], [99, 105], [105, 106], [106, 111], [112, 122], [122, 123], [124, 127], [128, 132], [133, 141], [142, 148], [149, 150], [150, 160], [161, 163], [164, 170], [171, 182], [183, 193], [194, 201], [202, 206], [206, 207], [207, 208]]}
{"doc_key": "ai-test-198", "ner": [[6, 8, "metrics"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "alternative", "to", "the", "Word", "Error", "Rate", "used", "in", "several", "countries", "."], "sentence-detokenized": "This is an alternative to the Word Error Rate used in several countries.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 25], [26, 29], [30, 34], [35, 40], [41, 45], [46, 50], [51, 53], [54, 61], [62, 71], [71, 72]]}
{"doc_key": "ai-test-199", "ner": [[0, 0, "algorithm"], [11, 12, "task"], [14, 15, "task"], [16, 18, "task"], [20, 22, "task"], [24, 28, "task"], [30, 31, "task"], [46, 46, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 0, 0, "usage", "", false, false], [14, 15, 0, 0, "usage", "", false, false], [16, 18, 0, 0, "usage", "", false, false], [20, 22, 0, 0, "usage", "", false, false], [24, 28, 0, 0, "usage", "", false, false], [30, 31, 0, 0, "usage", "", false, false], [46, 46, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["ANNs", "have", "been", "used", "for", "a", "variety", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "playing", "board", "and", "video", "games", ",", "medical", "diagnosis", "and", "even", "in", "activities", "traditionally", "thought", "to", "be", "reserved", "for", "humans", ",", "such", "as", "painting", "."], "sentence-detokenized": "ANNs have been used for a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games, medical diagnosis and even in activities traditionally thought to be reserved for humans, such as painting.", "token2charspan": [[0, 4], [5, 9], [10, 14], [15, 19], [20, 23], [24, 25], [26, 33], [34, 36], [37, 42], [42, 43], [44, 53], [54, 62], [63, 69], [69, 70], [71, 77], [78, 89], [89, 90], [91, 98], [99, 110], [110, 111], [112, 118], [119, 126], [127, 136], [136, 137], [138, 145], [146, 151], [152, 155], [156, 161], [162, 167], [167, 168], [169, 176], [177, 186], [187, 190], [191, 195], [196, 198], [199, 209], [210, 223], [224, 231], [232, 234], [235, 237], [238, 246], [247, 250], [251, 257], [257, 258], [259, 263], [264, 266], [267, 275], [275, 276]]}
{"doc_key": "ai-test-200", "ner": [[0, 4, "product"], [6, 6, "product"], [27, 29, "field"], [31, 31, "field"], [36, 36, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 27, 29, "related-to", "", false, false], [0, 4, 36, 36, "general-affiliation", "", false, false], [6, 6, 0, 4, "named", "", false, false], [31, 31, 27, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "is", "an", "open", "-", "source", "research", "platform", "and", "a", "collection", "of", "voice", ",", "audio", ",", "speech", ",", "text", "and", "natural", "language", "processing", "(", "NLP", ")", "algorithms", "written", "in", "Java", "and", "arranged", "in", "a", "modular", "and", "extensible", "structure", "that", "seeks", "to", "facilitate", "the", "addition", "of", "new", "algorithms", "."], "sentence-detokenized": "The Modular Audio Recognition Framework (MARF) is an open-source research platform and a collection of voice, audio, speech, text and natural language processing (NLP) algorithms written in Java and arranged in a modular and extensible structure that seeks to facilitate the addition of new algorithms.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 29], [30, 39], [40, 41], [41, 45], [45, 46], [47, 49], [50, 52], [53, 57], [57, 58], [58, 64], [65, 73], [74, 82], [83, 86], [87, 88], [89, 99], [100, 102], [103, 108], [108, 109], [110, 115], [115, 116], [117, 123], [123, 124], [125, 129], [130, 133], [134, 141], [142, 150], [151, 161], [162, 163], [163, 166], [166, 167], [168, 178], [179, 186], [187, 189], [190, 194], [195, 198], [199, 207], [208, 210], [211, 212], [213, 220], [221, 224], [225, 235], [236, 245], [246, 250], [251, 256], [257, 259], [260, 270], [271, 274], [275, 283], [284, 286], [287, 290], [291, 301], [301, 302]]}
{"doc_key": "ai-test-201", "ner": [[12, 14, "organisation"], [18, 18, "country"], [22, 24, "organisation"], [26, 28, "organisation"], [32, 33, "task"], [47, 49, "organisation"], [53, 53, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[22, 24, 18, 18, "physical", "", false, false], [22, 24, 32, 33, "usage", "", false, false], [22, 24, 47, 49, "named", "", false, false], [26, 28, 18, 18, "physical", "", false, false], [26, 28, 32, 33, "usage", "", false, false], [47, 49, 53, 53, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "a", "report", "by", "civil", "liberties", "and", "rights", "campaigning", "organisation", "Big", "Brother", "Watch", "revealed", "that", "two", "UK", "police", "forces", ",", "South", "Wales", "Police", "and", "the", "Metropolitan", "Police", ",", "were", "using", "facial", "recognition", "live", "at", "public", "events", "and", "in", "public", "spaces", ",", "in", "September", "2019", ",", "South", "Wales", "Police", "use", "of", "facial", "recognition", "was", "found", "to", "be", "lawful", "."], "sentence-detokenized": "In 2018, a report by civil liberties and rights campaigning organisation Big Brother Watch revealed that two UK police forces, South Wales Police and the Metropolitan Police, were using facial recognition live at public events and in public spaces, in September 2019, South Wales Police use of facial recognition was found to be lawful.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 20], [21, 26], [27, 36], [37, 40], [41, 47], [48, 59], [60, 72], [73, 76], [77, 84], [85, 90], [91, 99], [100, 104], [105, 108], [109, 111], [112, 118], [119, 125], [125, 126], [127, 132], [133, 138], [139, 145], [146, 149], [150, 153], [154, 166], [167, 173], [173, 174], [175, 179], [180, 185], [186, 192], [193, 204], [205, 209], [210, 212], [213, 219], [220, 226], [227, 230], [231, 233], [234, 240], [241, 247], [247, 248], [249, 251], [252, 261], [262, 266], [266, 267], [268, 273], [274, 279], [280, 286], [287, 290], [291, 293], [294, 300], [301, 312], [313, 316], [317, 322], [323, 325], [326, 328], [329, 335], [335, 336]]}
{"doc_key": "ai-test-202", "ner": [[0, 0, "product"], [5, 5, "programlang"], [14, 14, "field"], [17, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 5, "general-affiliation", "", false, false], [0, 0, 14, 14, "related-to", "", false, false], [0, 0, 17, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "has", "been", "ported", "to", "R", ",", "a", "freely", "available", "language", "and", "environment", "for", "statistical", "computing", "and", "graphics", "."], "sentence-detokenized": "ANIMAL has been ported to R, a freely available language and environment for statistical computing and graphics.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 22], [23, 25], [26, 27], [27, 28], [29, 30], [31, 37], [38, 47], [48, 56], [57, 60], [61, 72], [73, 76], [77, 88], [89, 98], [99, 102], [103, 111], [111, 112]]}
{"doc_key": "ai-test-203", "ner": [[0, 6, "algorithm"], [8, 10, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 6, 17, 19, "opposite", "alternative to", false, false], [8, 10, 0, 6, "named", "", false, false], [21, 21, 17, 19, "named", "", false, false], [24, 26, 0, 6, "usage", "", false, false], [24, 26, 17, 19, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "time", "-", "inhomogeneous", "hidden", "Bernoulli", "model", "(", "TI", "-", "HBM", ")", "is", "an", "alternative", "to", "the", "hidden", "Markov", "model", "(", "HMM", ")", "in", "automatic", "speech", "recognition", "."], "sentence-detokenized": "The time-inhomogeneous hidden Bernoulli model (TI-HBM) is an alternative to the hidden Markov model (HMM) in automatic speech recognition.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 22], [23, 29], [30, 39], [40, 45], [46, 47], [47, 49], [49, 50], [50, 53], [53, 54], [55, 57], [58, 60], [61, 72], [73, 75], [76, 79], [80, 86], [87, 93], [94, 99], [100, 101], [101, 104], [104, 105], [106, 108], [109, 118], [119, 125], [126, 137], [137, 138]]}
{"doc_key": "ai-test-204", "ner": [[4, 5, "organisation"], [12, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 12, 12, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "July", "2016", ",", "Nvidia", "demonstrated", "a", "new", "foveated", "rendering", "method", "at", "SIGGRAPH", ",", "claiming", "that", "it", "was", "invisible", "to", "users", "."], "sentence-detokenized": "In July 2016, Nvidia demonstrated a new foveated rendering method at SIGGRAPH, claiming that it was invisible to users.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 20], [21, 33], [34, 35], [36, 39], [40, 48], [49, 58], [59, 65], [66, 68], [69, 77], [77, 78], [79, 87], [88, 92], [93, 95], [96, 99], [100, 109], [110, 112], [113, 118], [118, 119]]}
{"doc_key": "ai-test-205", "ner": [[4, 6, "misc"], [9, 12, "researcher"], [17, 18, "researcher"], [20, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 9, 12, "origin", "", false, false], [4, 6, 17, 18, "origin", "", false, false], [4, 6, 20, 20, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Both", "are", "based", "on", "speech", "act", "theory", "developed", "by", "John", "Searle", "in", "the", "1960s", "and", "enriched", "by", "Terry", "Winograd", "and", "Flores", "in", "the", "1970s", "."], "sentence-detokenized": "Both are based on speech act theory developed by John Searle in the 1960s and enriched by Terry Winograd and Flores in the 1970s.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 17], [18, 24], [25, 28], [29, 35], [36, 45], [46, 48], [49, 53], [54, 60], [61, 63], [64, 67], [68, 73], [74, 77], [78, 86], [87, 89], [90, 95], [96, 104], [105, 108], [109, 115], [116, 118], [119, 122], [123, 128], [128, 129]]}
{"doc_key": "ai-test-206", "ner": [[0, 3, "algorithm"], [21, 23, "researcher"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 21, 23, "related-to", "", false, false], [24, 24, 21, 23, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Neural", "network", "models", "of", "concept", "formation", "and", "knowledge", "structure", "have", "opened", "up", "powerful", "hierarchical", "models", "of", "knowledge", "organisation", ",", "such", "as", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "Neural network models of concept formation and knowledge structure have opened up powerful hierarchical models of knowledge organisation, such as George Miller's Wordnet.", "token2charspan": [[0, 6], [7, 14], [15, 21], [22, 24], [25, 32], [33, 42], [43, 46], [47, 56], [57, 66], [67, 71], [72, 78], [79, 81], [82, 90], [91, 103], [104, 110], [111, 113], [114, 123], [124, 136], [136, 137], [138, 142], [143, 145], [146, 152], [153, 159], [159, 161], [162, 169], [169, 170]]}
{"doc_key": "ai-test-207", "ner": [[0, 1, "algorithm"], [12, 17, "field"], [16, 18, "product"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 17, "part-of", "", false, false], [0, 1, 21, 23, "part-of", "", false, false], [16, 18, 12, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Template", "matching", "has", "various", "applications", "and", "is", "used", "in", "areas", "such", "as", "face", "recognition", "(", "see", "facial", "recognition", "system", ")", "or", "medical", "image", "processing", "."], "sentence-detokenized": "Template matching has various applications and is used in areas such as face recognition (see facial recognition system) or medical image processing.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 29], [30, 42], [43, 46], [47, 49], [50, 54], [55, 57], [58, 63], [64, 68], [69, 71], [72, 76], [77, 88], [89, 90], [90, 93], [94, 100], [101, 112], [113, 119], [119, 120], [121, 123], [124, 131], [132, 137], [138, 148], [148, 149]]}
{"doc_key": "ai-test-208", "ner": [[12, 13, "researcher"], [15, 16, "researcher"], [20, 30, "organisation"], [32, 32, "organisation"], [40, 41, "algorithm"], [27, 52, "conference"], [50, 50, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 13, 20, 30, "role", "", false, false], [12, 13, 27, 52, "physical", "", false, false], [12, 13, 27, 52, "temporal", "", false, false], [12, 13, 50, 50, "physical", "", false, false], [15, 16, 20, 30, "role", "", false, false], [15, 16, 27, 52, "temporal", "", false, false], [32, 32, 20, 30, "named", "", false, false], [27, 52, 40, 41, "topic", "", false, false], [50, 50, 27, 52, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["However", ",", "their", "use", "did", "not", "become", "widespread", "until", "2005", ",", "when", "Navneet", "Dalal", "and", "Bill", "Triggs", ",", "researchers", "from", "the", "French", "National", "Institute", "for", "Research", "in", "Computer", "Science", "and", "Automation", "(", "INRIA", ")", ",", "presented", "their", "additional", "work", "on", "HOG", "descriptors", "at", "the", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "conference", "."], "sentence-detokenized": "However, their use did not become widespread until 2005, when Navneet Dalal and Bill Triggs, researchers from the French National Institute for Research in Computer Science and Automation (INRIA), presented their additional work on HOG descriptors at the Computer Vision and Pattern Recognition (CVPR) conference.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 18], [19, 22], [23, 26], [27, 33], [34, 44], [45, 50], [51, 55], [55, 56], [57, 61], [62, 69], [70, 75], [76, 79], [80, 84], [85, 91], [91, 92], [93, 104], [105, 109], [110, 113], [114, 120], [121, 129], [130, 139], [140, 143], [144, 152], [153, 155], [156, 164], [165, 172], [173, 176], [177, 187], [188, 189], [189, 194], [194, 195], [195, 196], [197, 206], [207, 212], [213, 223], [224, 228], [229, 231], [232, 235], [236, 247], [248, 250], [251, 254], [255, 263], [264, 270], [271, 274], [275, 282], [283, 294], [295, 296], [296, 300], [300, 301], [302, 312], [312, 313]]}
{"doc_key": "ai-test-209", "ner": [[4, 4, "university"], [17, 20, "organisation"], [22, 23, "organisation"], [30, 30, "field"], [35, 37, "researcher"], [39, 41, "researcher"], [43, 45, "researcher"], [47, 51, "organisation"], [54, 57, "organisation"], [62, 64, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[22, 23, 30, 30, "related-to", "", false, false], [35, 37, 22, 23, "physical", "", false, false], [35, 37, 22, 23, "role", "", false, false], [39, 41, 22, 23, "physical", "", false, false], [39, 41, 22, 23, "role", "", false, false], [43, 45, 22, 23, "physical", "", false, false], [43, 45, 22, 23, "role", "", false, false], [62, 64, 54, 57, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Prior", "to", "joining", "the", "Penn", "faculty", "in", "2002", ",", "he", "spent", "a", "decade", "(", "1991-2001", ")", "at", "AT", "&", "T", "Labs", "and", "Bell", "Labs", ",", "including", "as", "head", "of", "the", "AI", "department", "with", "colleagues", "including", "Michael", "L.", "Littman", ",", "David", "A.", "McAllester", "and", "Richard", "S.", "Sutton", ";", "the", "Secure", "Systems", "Research", "department", ";", "and", "the", "Machine", "Learning", "department", "with", "members", "such", "as", "Michael", "Collins", "and", "a", "leader", ")", "."], "sentence-detokenized": "Prior to joining the Penn faculty in 2002, he spent a decade (1991-2001) at AT & T Labs and Bell Labs, including as head of the AI department with colleagues including Michael L. Littman, David A. McAllester and Richard S. Sutton; the Secure Systems Research department; and the Machine Learning department with members such as Michael Collins and a leader).", "token2charspan": [[0, 5], [6, 8], [9, 16], [17, 20], [21, 25], [26, 33], [34, 36], [37, 41], [41, 42], [43, 45], [46, 51], [52, 53], [54, 60], [61, 62], [62, 71], [71, 72], [73, 75], [76, 78], [79, 80], [81, 82], [83, 87], [88, 91], [92, 96], [97, 101], [101, 102], [103, 112], [113, 115], [116, 120], [121, 123], [124, 127], [128, 130], [131, 141], [142, 146], [147, 157], [158, 167], [168, 175], [176, 178], [179, 186], [186, 187], [188, 193], [194, 196], [197, 207], [208, 211], [212, 219], [220, 222], [223, 229], [229, 230], [231, 234], [235, 241], [242, 249], [250, 258], [259, 269], [269, 270], [271, 274], [275, 278], [279, 286], [287, 295], [296, 306], [307, 311], [312, 319], [320, 324], [325, 327], [328, 335], [336, 343], [344, 347], [348, 349], [350, 356], [356, 357], [357, 358]]}
{"doc_key": "ai-test-210", "ner": [[6, 9, "field"], [13, 13, "field"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 9, 13, 13, "compare", "", false, false], [23, 24, 13, 13, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["When", "the", "data", "is", "unlabelled", ",", "supervised", "learning", "is", "not", "possible", "and", "an", "unsupervised", "learning", "approach", "is", "required", "that", "attempts", "to", "find", "natural", "Cluster", "analysis", "into", "groups", "and", "then", "map", "new", "data", "into", "these", "created", "groups", "."], "sentence-detokenized": "When the data is unlabelled, supervised learning is not possible and an unsupervised learning approach is required that attempts to find natural Cluster analysis into groups and then map new data into these created groups.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 27], [27, 28], [29, 39], [40, 48], [49, 51], [52, 55], [56, 64], [65, 68], [69, 71], [72, 84], [85, 93], [94, 102], [103, 105], [106, 114], [115, 119], [120, 128], [129, 131], [132, 136], [137, 144], [145, 152], [153, 161], [162, 166], [167, 173], [174, 177], [178, 182], [183, 186], [187, 190], [191, 195], [196, 200], [201, 206], [207, 214], [215, 221], [221, 222]]}
{"doc_key": "ai-test-211", "ner": [[3, 4, "field"], [15, 18, "organisation"], [25, 26, "field"], [28, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 15, 18, "origin", "", false, false], [3, 4, 25, 26, "part-of", "", false, false], [3, 4, 28, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "field", "of", "computer", "science", "developed", "in", "the", "1950s", "at", "academic", "institutions", "such", "as", "the", "MIT", "A.I", ".", "Lab", ",", "initially", "as", "a", "branch", "of", "artificial", "intelligence", "and", "robotics", "."], "sentence-detokenized": "This field of computer science developed in the 1950s at academic institutions such as the MIT A.I. Lab, initially as a branch of artificial intelligence and robotics.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 30], [31, 40], [41, 43], [44, 47], [48, 53], [54, 56], [57, 65], [66, 78], [79, 83], [84, 86], [87, 90], [91, 94], [95, 98], [98, 99], [100, 103], [103, 104], [105, 114], [115, 117], [118, 119], [120, 126], [127, 129], [130, 140], [141, 153], [154, 157], [158, 166], [166, 167]]}
{"doc_key": "ai-test-212", "ner": [[8, 10, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "can", "also", "be", "replaced", "by", "the", "following", "Log", "loss", "equation", ":"], "sentence-detokenized": "It can also be replaced by the following Log loss equation:", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 23], [24, 26], [27, 30], [31, 40], [41, 44], [45, 49], [50, 58], [58, 59]]}
{"doc_key": "ai-test-213", "ner": [[6, 8, "organisation"], [13, 15, "organisation"], [21, 23, "university"], [25, 25, "university"], [27, 28, "university"], [30, 33, "university"], [36, 36, "country"], [2, 2, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[6, 8, 2, 2, "related-to", "research_leader_in_field", false, false], [13, 15, 6, 8, "named", "", false, false], [13, 15, 2, 2, "related-to", "research_leader_in_field", false, false], [21, 23, 2, 2, "related-to", "research_leader_in_field", false, false], [25, 25, 2, 2, "related-to", "research_leader_in_field", false, false], [27, 28, 2, 2, "related-to", "research_leader_in_field", false, false], [30, 33, 36, 36, "physical", "", false, false], [30, 33, 2, 2, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Leaders", "in", "biomechatronics", "research", "include", "the", "Shirley", "Ryan", "AbilityLab", "(", "formerly", "the", "Rehabilitation", "Institute", "of", "Chicago", ")", ",", "the", "University", "of", "California", "at", "Berkeley", ",", "MIT", ",", "Stanford", "University", "and", "the", "University", "of", "Twente", "in", "the", "Netherlands", "."], "sentence-detokenized": "Leaders in biomechatronics research include the Shirley Ryan AbilityLab (formerly the Rehabilitation Institute of Chicago), the University of California at Berkeley, MIT, Stanford University and the University of Twente in the Netherlands.", "token2charspan": [[0, 7], [8, 10], [11, 26], [27, 35], [36, 43], [44, 47], [48, 55], [56, 60], [61, 71], [72, 73], [73, 81], [82, 85], [86, 100], [101, 110], [111, 113], [114, 121], [121, 122], [122, 123], [124, 127], [128, 138], [139, 141], [142, 152], [153, 155], [156, 164], [164, 165], [166, 169], [169, 170], [171, 179], [180, 190], [191, 194], [195, 198], [199, 209], [210, 212], [213, 219], [220, 222], [223, 226], [227, 238], [238, 239]]}
{"doc_key": "ai-test-214", "ner": [[29, 32, "metrics"], [44, 44, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Given", "a", "set", "of", "predicted", "values", "and", "a", "corresponding", "set", "of", "actual", "values", "for", "X", "for", "different", "time", "periods", ",", "a", "commonly", "used", "evaluation", "technique", "is", "to", "use", "the", "mean", "square", "prediction", "error", ";", "other", "measures", "are", "also", "available", "(", "see", "forecasting", "#", "forecasting", "accuracy", ")", "."], "sentence-detokenized": "Given a set of predicted values and a corresponding set of actual values for X for different time periods, a commonly used evaluation technique is to use the mean square prediction error; other measures are also available (see forecasting # forecasting accuracy).", "token2charspan": [[0, 5], [6, 7], [8, 11], [12, 14], [15, 24], [25, 31], [32, 35], [36, 37], [38, 51], [52, 55], [56, 58], [59, 65], [66, 72], [73, 76], [77, 78], [79, 82], [83, 92], [93, 97], [98, 105], [105, 106], [107, 108], [109, 117], [118, 122], [123, 133], [134, 143], [144, 146], [147, 149], [150, 153], [154, 157], [158, 162], [163, 169], [170, 180], [181, 186], [186, 187], [188, 193], [194, 202], [203, 206], [207, 211], [212, 221], [222, 223], [223, 226], [227, 238], [239, 240], [241, 252], [253, 261], [261, 262], [262, 263]]}
{"doc_key": "ai-test-215", "ner": [[15, 15, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "measures", ",", "such", "as", "the", "proportion", "of", "correct", "predictions", "(", "also", "referred", "to", "as", "accuracy", ")", ",", "are", "not", "useful", "when", "the", "two", "classes", "are", "very", "different", "."], "sentence-detokenized": "Other measures, such as the proportion of correct predictions (also referred to as accuracy), are not useful when the two classes are very different.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 20], [21, 23], [24, 27], [28, 38], [39, 41], [42, 49], [50, 61], [62, 63], [63, 67], [68, 76], [77, 79], [80, 82], [83, 91], [91, 92], [92, 93], [94, 97], [98, 101], [102, 108], [109, 113], [114, 117], [118, 121], [122, 129], [130, 133], [134, 138], [139, 148], [148, 149]]}
{"doc_key": "ai-test-216", "ner": [[5, 5, "product"], [14, 18, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 14, 18, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "alpha", "version", "of", "OpenCV", "was", "made", "available", "to", "the", "public", "at", "the", "Computer", "Vision", "and", "Pattern", "Recognition", "conference", "in", "2000", ",", "and", "five", "beta", "versions", "were", "released", "between", "2001", "and", "2005", "."], "sentence-detokenized": "The first alpha version of OpenCV was made available to the public at the Computer Vision and Pattern Recognition conference in 2000, and five beta versions were released between 2001 and 2005.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [24, 26], [27, 33], [34, 37], [38, 42], [43, 52], [53, 55], [56, 59], [60, 66], [67, 69], [70, 73], [74, 82], [83, 89], [90, 93], [94, 101], [102, 113], [114, 124], [125, 127], [128, 132], [132, 133], [134, 137], [138, 142], [143, 147], [148, 156], [157, 161], [162, 170], [171, 178], [179, 183], [184, 187], [188, 192], [192, 193]]}
{"doc_key": "ai-test-217", "ner": [[21, 21, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Results", "are", "presented", "that", "give", "a", "correlation", "of", "up", "to", "0.964", "with", "human", "assessment", "at", "corpus", "level", ",", "compared", "to", "a", "BLEU", "achievement", "of", "0.817", "on", "the", "same", "data", "set", "."], "sentence-detokenized": "Results are presented that give a correlation of up to 0.964 with human assessment at corpus level, compared to a BLEU achievement of 0.817 on the same data set.", "token2charspan": [[0, 7], [8, 11], [12, 21], [22, 26], [27, 31], [32, 33], [34, 45], [46, 48], [49, 51], [52, 54], [55, 60], [61, 65], [66, 71], [72, 82], [83, 85], [86, 92], [93, 98], [98, 99], [100, 108], [109, 111], [112, 113], [114, 118], [119, 130], [131, 133], [134, 139], [140, 142], [143, 146], [147, 151], [152, 156], [157, 160], [160, 161]]}
{"doc_key": "ai-test-218", "ner": [[4, 4, "metrics"], [17, 17, "metrics"], [19, 21, "metrics"], [23, 25, "metrics"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 17, 17, "compare", "", false, false], [4, 4, 19, 21, "compare", "", false, false], [4, 4, 23, 25, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "early", "version", "of", "VMAF", "was", "shown", "to", "outperform", "other", "image", "and", "video", "quality", "metrics", "such", "as", "SSIM", ",", "PSNR", "-", "HVS", "and", "VQM", "-", "VFD", "on", "three", "of", "the", "four", "data", "sets", "in", "terms", "of", "predictive", "accuracy", ",", "compared", "to", "subjective", "ratings", "."], "sentence-detokenized": "The early version of VMAF was shown to outperform other image and video quality metrics such as SSIM, PSNR -HVS and VQM-VFD on three of the four data sets in terms of predictive accuracy, compared to subjective ratings.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 20], [21, 25], [26, 29], [30, 35], [36, 38], [39, 49], [50, 55], [56, 61], [62, 65], [66, 71], [72, 79], [80, 87], [88, 92], [93, 95], [96, 100], [100, 101], [102, 106], [107, 108], [108, 111], [112, 115], [116, 119], [119, 120], [120, 123], [124, 126], [127, 132], [133, 135], [136, 139], [140, 144], [145, 149], [150, 154], [155, 157], [158, 163], [164, 166], [167, 177], [178, 186], [186, 187], [188, 196], [197, 199], [200, 210], [211, 218], [218, 219]]}
{"doc_key": "ai-test-219", "ner": [[20, 21, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 21, 28, 29, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "example", ",", "the", "ambiguity", "of", "the", "word", "'", "mouse", "'", "(", "animal", "or", "device", ")", "is", "not", "relevant", "in", "machine", "translation", ",", "but", "it", "is", "relevant", "in", "information", "retrieval", "."], "sentence-detokenized": "For example, the ambiguity of the word 'mouse' (animal or device) is not relevant in machine translation, but it is relevant in information retrieval.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 26], [27, 29], [30, 33], [34, 38], [39, 40], [40, 45], [45, 46], [47, 48], [48, 54], [55, 57], [58, 64], [64, 65], [66, 68], [69, 72], [73, 81], [82, 84], [85, 92], [93, 104], [104, 105], [106, 109], [110, 112], [113, 115], [116, 124], [125, 127], [128, 139], [140, 149], [149, 150]]}
{"doc_key": "ai-test-220", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 1, "usage", "", false, false], [12, 13, 6, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Geometric", "hashing", "was", "originally", "proposed", "in", "computer", "vision", "for", "2D", "and", "3D", "object", "recognition", ","], "sentence-detokenized": "Geometric hashing was originally proposed in computer vision for 2D and 3D object recognition,", "token2charspan": [[0, 9], [10, 17], [18, 21], [22, 32], [33, 41], [42, 44], [45, 53], [54, 60], [61, 64], [65, 67], [68, 71], [72, 74], [75, 81], [82, 93], [93, 94]]}
{"doc_key": "ai-test-221", "ner": [[9, 10, "field"], [13, 14, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 14, 9, 10, "part-of", "subfield", false, false], [16, 17, 9, 10, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "represents", "one", "of", "the", "three", "main", "categories", "of", "machine", "learning", ",", "alongside", "supervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "It represents one of the three main categories of machine learning, alongside supervised learning and reinforcement learning.", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 20], [21, 24], [25, 30], [31, 35], [36, 46], [47, 49], [50, 57], [58, 66], [66, 67], [68, 77], [78, 88], [89, 97], [98, 101], [102, 115], [116, 124], [124, 125]]}
{"doc_key": "ai-test-222", "ner": [[0, 4, "field"], [16, 16, "field"], [17, 19, "field"], [22, 23, "field"], [20, 26, "field"], [28, 31, "field"], [33, 34, "field"], [36, 37, "field"], [39, 39, "field"], [41, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 4, 16, 16, "part-of", "subfield", false, false], [0, 4, 17, 19, "part-of", "subfield", false, false], [0, 4, 22, 23, "part-of", "subfield", false, false], [0, 4, 20, 26, "part-of", "subfield", false, false], [0, 4, 28, 31, "part-of", "subfield", false, false], [0, 4, 33, 34, "part-of", "subfield", false, false], [0, 4, 36, 37, "part-of", "subfield", false, false], [0, 4, 39, 39, "part-of", "subfield", false, false], [0, 4, 41, 42, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Reinforcement", "learning", ",", "due", "to", "its", "generality", ",", "is", "studied", "in", "many", "other", "disciplines", "such", "as", "game", "theory", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimisation", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Reinforcement learning, due to its generality, is studied in many other disciplines such as game theory, control theory, operations research, information theory, simulation-based optimisation, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 13], [14, 22], [22, 23], [24, 27], [28, 30], [31, 34], [35, 45], [45, 46], [47, 49], [50, 57], [58, 60], [61, 65], [66, 71], [72, 83], [84, 88], [89, 91], [92, 96], [97, 103], [103, 104], [105, 112], [113, 119], [119, 120], [121, 131], [132, 140], [140, 141], [142, 153], [154, 160], [160, 161], [162, 172], [172, 173], [173, 178], [179, 191], [191, 192], [193, 204], [205, 212], [212, 213], [214, 219], [220, 232], [232, 233], [234, 244], [245, 248], [249, 256], [257, 267], [267, 268]]}
{"doc_key": "ai-test-223", "ner": [[0, 1, "field"], [6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "related-to", "", false, false], [0, 1, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pattern", "recognition", "is", "closely", "related", "to", "artificial", "intelligence", "and", "machine", "learning", ","], "sentence-detokenized": "Pattern recognition is closely related to artificial intelligence and machine learning,", "token2charspan": [[0, 7], [8, 19], [20, 22], [23, 30], [31, 38], [39, 41], [42, 52], [53, 65], [66, 69], [70, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-224", "ner": [[10, 11, "algorithm"], [14, 16, "field"], [17, 18, "field"], [29, 30, "task"], [32, 32, "task"], [34, 35, "task"], [37, 38, "algorithm"], [40, 42, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 11, 14, 16, "related-to", "", false, false], [10, 11, 17, 18, "related-to", "", false, false], [29, 30, 10, 11, "usage", "", true, false], [32, 32, 10, 11, "usage", "", true, false], [34, 35, 10, 11, "usage", "", true, false], [37, 38, 10, 11, "usage", "", true, false], [40, 42, 10, 11, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "software", "is", "used", "to", "design", ",", "train", "and", "implement", "neural", "network", "models", "(", "supervised", "learning", "and", "unsupervised", "learning", ")", "to", "perform", "a", "wide", "range", "of", "tasks", "such", "as", "data", "mining", ",", "classification", ",", "function", "approximation", ",", "multivariate", "regression", "and", "time", "series", "prediction", "."], "sentence-detokenized": "The software is used to design, train and implement neural network models (supervised learning and unsupervised learning) to perform a wide range of tasks such as data mining, classification, function approximation, multivariate regression and time series prediction.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 20], [21, 23], [24, 30], [30, 31], [32, 37], [38, 41], [42, 51], [52, 58], [59, 66], [67, 73], [74, 75], [75, 85], [86, 94], [95, 98], [99, 111], [112, 120], [120, 121], [122, 124], [125, 132], [133, 134], [135, 139], [140, 145], [146, 148], [149, 154], [155, 159], [160, 162], [163, 167], [168, 174], [174, 175], [176, 190], [190, 191], [192, 200], [201, 214], [214, 215], [216, 228], [229, 239], [240, 243], [244, 248], [249, 255], [256, 266], [266, 267]]}
{"doc_key": "ai-test-225", "ner": [[9, 15, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2016", ",", "he", "was", "elected", "a", "Fellow", "of", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2016, he was elected a Fellow of Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 47], [48, 51], [52, 55], [56, 67], [68, 70], [71, 81], [82, 94], [94, 95]]}
{"doc_key": "ai-test-226", "ner": [[6, 9, "organisation"], [15, 21, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", "(", "since", "2005", ")", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "(", "since", "2009", ")", ","], "sentence-detokenized": "He is a member of the National Academy of Sciences (since 2005), the American Academy of Arts and Sciences (since 2009),", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 38], [39, 41], [42, 50], [51, 52], [52, 57], [58, 62], [62, 63], [63, 64], [65, 68], [69, 77], [78, 85], [86, 88], [89, 93], [94, 97], [98, 106], [107, 108], [108, 113], [114, 118], [118, 119], [119, 120]]}
{"doc_key": "ai-test-227", "ner": [[3, 5, "misc"], [7, 14, "product"], [17, 17, "country"], [19, 19, "country"], [24, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 14, 3, 5, "temporal", "", false, false], [7, 14, 17, 17, "physical", "", false, false], [7, 14, 19, 19, "physical", "", false, false], [7, 14, 24, 25, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "the", "1973", "Yom", "Kippur", "War", ",", "Soviet", "-supplied", "surface", "-", "to", "-", "air", "missile", "batteries", "in", "Egypt", "and", "Syria", "inflicted", "heavy", "damage", "on", "Israeli", "jets", "."], "sentence-detokenized": "During the 1973 Yom Kippur War, Soviet-supplied surface-to-air missile batteries in Egypt and Syria inflicted heavy damage on Israeli jets.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 26], [27, 30], [30, 31], [32, 38], [38, 47], [48, 55], [55, 56], [56, 58], [58, 59], [59, 62], [63, 70], [71, 80], [81, 83], [84, 89], [90, 93], [94, 99], [100, 109], [110, 115], [116, 122], [123, 125], [126, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-test-228", "ner": [[9, 10, "product"], [14, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 15, 9, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Another", "resource", "(", "free", "but", "copyrighted", ")", "is", "the", "HTK", "book", "(", "and", "accompanying", "HTK", "toolkit", ")", "."], "sentence-detokenized": "Another resource (free but copyrighted) is the HTK book (and accompanying HTK toolkit).", "token2charspan": [[0, 7], [8, 16], [17, 18], [18, 22], [23, 26], [27, 38], [38, 39], [40, 42], [43, 46], [47, 50], [51, 55], [56, 57], [57, 60], [61, 73], [74, 77], [78, 85], [85, 86], [86, 87]]}
{"doc_key": "ai-test-229", "ner": [[6, 7, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "were", "taken", "up", "at", "the", "2004", "AAAI", "Spring", "Symposium", ",", "where", "linguists", ",", "computer", "scientists", "and", "other", "interested", "researchers", "first", "agreed", "on", "interests", "and", "proposed", "common", "tasks", "and", "benchmark", "data", "sets", "for", "systematic", "computational", "research", "on", "affect", ",", "attraction", ",", "subjectivity", "and", "sentiment", "in", "text", "."], "sentence-detokenized": "- were taken up at the 2004 AAAI Spring Symposium, where linguists, computer scientists and other interested researchers first agreed on interests and proposed common tasks and benchmark data sets for systematic computational research on affect, attraction, subjectivity and sentiment in text.", "token2charspan": [[0, 1], [2, 6], [7, 12], [13, 15], [16, 18], [19, 22], [23, 27], [28, 32], [33, 39], [40, 49], [49, 50], [51, 56], [57, 66], [66, 67], [68, 76], [77, 87], [88, 91], [92, 97], [98, 108], [109, 120], [121, 126], [127, 133], [134, 136], [137, 146], [147, 150], [151, 159], [160, 166], [167, 172], [173, 176], [177, 186], [187, 191], [192, 196], [197, 200], [201, 211], [212, 225], [226, 234], [235, 237], [238, 244], [244, 245], [246, 256], [256, 257], [258, 270], [271, 274], [275, 284], [285, 287], [288, 292], [292, 293]]}
{"doc_key": "ai-test-230", "ner": [[12, 13, "task"], [18, 19, "task"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "single", "grid", "can", "be", "analysed", "both", "in", "terms", "of", "content", "(", "visual", "inspection", ")", "and", "structure", "(", "cluster", "analysis", ",", "principal", "component", "analysis", "and", "various", "structural", "indicators", "relating", "to", "the", "complexity", "and", "extent", "of", "the", "assessments", "are", "the", "main", "techniques", "used", ")", "."], "sentence-detokenized": "A single grid can be analysed both in terms of content (visual inspection) and structure (cluster analysis, principal component analysis and various structural indicators relating to the complexity and extent of the assessments are the main techniques used).", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 17], [18, 20], [21, 29], [30, 34], [35, 37], [38, 43], [44, 46], [47, 54], [55, 56], [56, 62], [63, 73], [73, 74], [75, 78], [79, 88], [89, 90], [90, 97], [98, 106], [106, 107], [108, 117], [118, 127], [128, 136], [137, 140], [141, 148], [149, 159], [160, 170], [171, 179], [180, 182], [183, 186], [187, 197], [198, 201], [202, 208], [209, 211], [212, 215], [216, 227], [228, 231], [232, 235], [236, 240], [241, 251], [252, 256], [256, 257], [257, 258]]}
{"doc_key": "ai-test-231", "ner": [[3, 3, "organisation"], [10, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2018", ",", "Toyota", "was", "considered", "to", "be", "behind", "in", "Self", "-", "driving", "cars", "and", "in", "need", "of", "innovation", "."], "sentence-detokenized": "In 2018, Toyota was considered to be behind in Self-driving cars and in need of innovation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 30], [31, 33], [34, 36], [37, 43], [44, 46], [47, 51], [51, 52], [52, 59], [60, 64], [65, 68], [69, 71], [72, 76], [77, 79], [80, 90], [90, 91]]}
{"doc_key": "ai-test-232", "ner": [[39, 41, "misc"], [44, 44, "misc"], [47, 51, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "targets", "include", "natural", "objects", "such", "as", "land", ",", "sea", ",", "precipitation", "(", "such", "as", "rain", ",", "snow", "or", "hail", ")", ",", "dust", "storms", ",", "animals", "(", "especially", "birds", ")", ",", "atmospheric", "turbulence", "and", "other", "atmospheric", "effects", "such", "as", "reflections", "from", "the", "ionosphere", ",", "meteor", "plumes", "and", "three", "-", "body", "scatter", "spikes", "."], "sentence-detokenized": "Such targets include natural objects such as land, sea, precipitation (such as rain, snow or hail), dust storms, animals (especially birds), atmospheric turbulence and other atmospheric effects such as reflections from the ionosphere, meteor plumes and three-body scatter spikes.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 28], [29, 36], [37, 41], [42, 44], [45, 49], [49, 50], [51, 54], [54, 55], [56, 69], [70, 71], [71, 75], [76, 78], [79, 83], [83, 84], [85, 89], [90, 92], [93, 97], [97, 98], [98, 99], [100, 104], [105, 111], [111, 112], [113, 120], [121, 122], [122, 132], [133, 138], [138, 139], [139, 140], [141, 152], [153, 163], [164, 167], [168, 173], [174, 185], [186, 193], [194, 198], [199, 201], [202, 213], [214, 218], [219, 222], [223, 233], [233, 234], [235, 241], [242, 248], [249, 252], [253, 258], [258, 259], [259, 263], [264, 271], [272, 278], [278, 279]]}
{"doc_key": "ai-test-233", "ner": [[17, 17, "product"], [37, 37, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "planning", "and", "control", ",", "the", "main", "difference", "between", "humanoids", "and", "other", "types", "of", "robots", "(", "e.g.", "industrial", "robots", ")", "is", "that", "the", "robot", "'s", "movement", "must", "be", "human", "-", "like", ",", "using", "legged", "locomotion", ",", "especially", "bipedal", "gait", "."], "sentence-detokenized": "In planning and control, the main difference between humanoids and other types of robots (e.g. industrial robots) is that the robot's movement must be human-like, using legged locomotion, especially bipedal gait.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 23], [23, 24], [25, 28], [29, 33], [34, 44], [45, 52], [53, 62], [63, 66], [67, 72], [73, 78], [79, 81], [82, 88], [89, 90], [90, 94], [95, 105], [106, 112], [112, 113], [114, 116], [117, 121], [122, 125], [126, 131], [131, 133], [134, 142], [143, 147], [148, 150], [151, 156], [156, 157], [157, 161], [161, 162], [163, 168], [169, 175], [176, 186], [186, 187], [188, 198], [199, 206], [207, 211], [211, 212]]}
{"doc_key": "ai-test-234", "ner": [[0, 2, "algorithm"], [10, 11, "misc"], [15, 15, "metrics"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "gradient", "descent", "may", "take", "many", "iterations", "to", "calculate", "the", "local", "minimum", "with", "the", "required", "accuracy", "if", "the", "curvatures", "in", "different", "directions", "are", "very", "different", "for", "a", "given", "function", "."], "sentence-detokenized": "The gradient descent may take many iterations to calculate the local minimum with the required accuracy if the curvatures in different directions are very different for a given function.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 24], [25, 29], [30, 34], [35, 45], [46, 48], [49, 58], [59, 62], [63, 68], [69, 76], [77, 81], [82, 85], [86, 94], [95, 103], [104, 106], [107, 110], [111, 121], [122, 124], [125, 134], [135, 145], [146, 149], [150, 154], [155, 164], [165, 168], [169, 170], [171, 176], [177, 185], [185, 186]]}
{"doc_key": "ai-test-235", "ner": [[1, 6, "misc"], [10, 10, "misc"], [17, 22, "conference"], [26, 26, "location"], [28, 28, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 6, 10, 10, "part-of", "", true, false], [17, 22, 26, 26, "physical", "", false, true], [26, 26, 28, 28, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "RoboCup", "2D", "Soccer", "Simulation", "League", "1997", "was", "the", "first", "RoboCup", "competition", "promoted", "in", "conjunction", "with", "the", "International", "Joint", "Conference", "on", "Artificial", "Intelligence", ",", "held", "in", "Nagoya", ",", "Japan", ",", "from", "23", "-", "29", "August", "1997", "."], "sentence-detokenized": "The RoboCup 2D Soccer Simulation League 1997 was the first RoboCup competition promoted in conjunction with the International Joint Conference on Artificial Intelligence, held in Nagoya, Japan, from 23-29 August 1997.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 21], [22, 32], [33, 39], [40, 44], [45, 48], [49, 52], [53, 58], [59, 66], [67, 78], [79, 87], [88, 90], [91, 102], [103, 107], [108, 111], [112, 125], [126, 131], [132, 142], [143, 145], [146, 156], [157, 169], [169, 170], [171, 175], [176, 178], [179, 185], [185, 186], [187, 192], [192, 193], [194, 198], [199, 201], [201, 202], [202, 204], [205, 211], [212, 216], [216, 217]]}
{"doc_key": "ai-test-236", "ner": [[8, 8, "programlang"], [15, 15, "programlang"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "options", "include", "a", "built", "-", "in", "Python", "environment", ",", "as", "well", "as", "the", "R", "console", "and", "support", "for", "Rserve", "."], "sentence-detokenized": "Other programming options include a built-in Python environment, as well as the R console and support for Rserve.", "token2charspan": [[0, 5], [6, 17], [18, 25], [26, 33], [34, 35], [36, 41], [41, 42], [42, 44], [45, 51], [52, 63], [63, 64], [65, 67], [68, 72], [73, 75], [76, 79], [80, 81], [82, 89], [90, 93], [94, 101], [102, 105], [106, 112], [112, 113]]}
{"doc_key": "ai-test-237", "ner": [[1, 1, "location"], [8, 9, "field"], [11, 11, "field"], [14, 15, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [34, 34, "field"], [39, 40, "field"], [43, 44, "field"], [48, 49, "field"], [52, 56, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[14, 15, 11, 11, "related-to", "contributes_to_field", true, false], [17, 18, 11, 11, "related-to", "contributes_to_field", true, false], [20, 21, 11, 11, "related-to", "contributes_to_field", true, false], [43, 44, 39, 40, "part-of", "", false, false], [48, 49, 43, 44, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["From", "Bonn", ",", "he", "made", "fundamental", "contributions", "to", "artificial", "intelligence", "and", "robotics", "(", "with", "Wolfram", "Burgard", ",", "Dieter", "Fox", ",", "Sebastian", "Thrun", "among", "his", "students", ")", ",", "as", "well", "as", "to", "the", "development", "of", "software", "engineering", ",", "especially", "in", "civil", "engineering", ",", "and", "information", "systems", ",", "especially", "in", "geosciences", ".", "won", "the", "AAAI", "Classic", "Paper", "award", "of", "2016.2014", "."], "sentence-detokenized": "From Bonn, he made fundamental contributions to artificial intelligence and robotics (with Wolfram Burgard, Dieter Fox, Sebastian Thrun among his students), as well as to the development of software engineering, especially in civil engineering, and information systems, especially in geosciences. won the AAAI Classic Paper award of 2016.2014.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 13], [14, 18], [19, 30], [31, 44], [45, 47], [48, 58], [59, 71], [72, 75], [76, 84], [85, 86], [86, 90], [91, 98], [99, 106], [106, 107], [108, 114], [115, 118], [118, 119], [120, 129], [130, 135], [136, 141], [142, 145], [146, 154], [154, 155], [155, 156], [157, 159], [160, 164], [165, 167], [168, 170], [171, 174], [175, 186], [187, 189], [190, 198], [199, 210], [210, 211], [212, 222], [223, 225], [226, 231], [232, 243], [243, 244], [245, 248], [249, 260], [261, 268], [268, 269], [270, 280], [281, 283], [284, 295], [295, 296], [297, 300], [301, 304], [305, 309], [310, 317], [318, 323], [324, 329], [330, 332], [333, 342], [342, 343]]}
{"doc_key": "ai-test-238", "ner": [[2, 11, "conference"], [18, 20, "location"], [21, 21, "location"], [23, 23, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 11, 18, 20, "physical", "", false, false], [18, 20, 21, 21, "physical", "", false, false], [21, 21, 23, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "first", "US", "edition", "of", "the", "Campus", "Party", "will", "take", "place", "from", "20", "-", "22", "August", "at", "the", "TCF", "Center", "in", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "The first US edition of the Campus Party will take place from 20-22 August at the TCF Center in Detroit, Michigan.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 20], [21, 23], [24, 27], [28, 34], [35, 40], [41, 45], [46, 50], [51, 56], [57, 61], [62, 64], [64, 65], [65, 67], [68, 74], [75, 77], [78, 81], [82, 85], [86, 92], [93, 95], [96, 103], [103, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-test-239", "ner": [[2, 3, "researcher"], [6, 7, "researcher"], [9, 9, "researcher"], [13, 14, "misc"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 13, 14, "win-defeat", "", false, false], [6, 7, 13, 14, "win-defeat", "", false, false], [9, 9, 13, 14, "win-defeat", "", false, false], [13, 14, 23, 25, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Along", "with", "Yann", "LeCun", ",", "and", "Yoshua", "Bengio", ",", "Hinton", "won", "the", "2018", "Turing", "Award", "for", "conceptual", "and", "engineering", "breakthroughs", "that", "have", "made", "deep", "neural", "networks", "a", "critical", "component", "of", "computing", "."], "sentence-detokenized": "Along with Yann LeCun, and Yoshua Bengio, Hinton won the 2018 Turing Award for conceptual and engineering breakthroughs that have made deep neural networks a critical component of computing.", "token2charspan": [[0, 5], [6, 10], [11, 15], [16, 21], [21, 22], [23, 26], [27, 33], [34, 40], [40, 41], [42, 48], [49, 52], [53, 56], [57, 61], [62, 68], [69, 74], [75, 78], [79, 89], [90, 93], [94, 105], [106, 119], [120, 124], [125, 129], [130, 134], [135, 139], [140, 146], [147, 155], [156, 157], [158, 166], [167, 176], [177, 179], [180, 189], [189, 190]]}
{"doc_key": "ai-test-240", "ner": [[0, 3, "product"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 10, 10, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Euler", "Math", "Toolbox", "uses", "a", "matrix", "language", "similar", "to", "MATLAB", ",", "a", "system", "that", "has", "been", "under", "development", "since", "the", "1970s", "."], "sentence-detokenized": "The Euler Math Toolbox uses a matrix language similar to MATLAB, a system that has been under development since the 1970s.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 22], [23, 27], [28, 29], [30, 36], [37, 45], [46, 53], [54, 56], [57, 63], [63, 64], [65, 66], [67, 73], [74, 78], [79, 82], [83, 87], [88, 93], [94, 105], [106, 111], [112, 115], [116, 121], [121, 122]]}
{"doc_key": "ai-test-241", "ner": [[7, 7, "programlang"], [9, 10, "programlang"], [12, 12, "programlang"], [14, 14, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "languages", "make", "this", "portable", "(", "e.g.", "Scheme", ",", "Common", "Lisp", ",", "Perl", "or", "D", ")", "."], "sentence-detokenized": "Some languages make this portable (e.g. Scheme, Common Lisp, Perl or D).", "token2charspan": [[0, 4], [5, 14], [15, 19], [20, 24], [25, 33], [34, 35], [35, 39], [40, 46], [46, 47], [48, 54], [55, 59], [59, 60], [61, 65], [66, 68], [69, 70], [70, 71], [71, 72]]}
{"doc_key": "ai-test-242", "ner": [[6, 6, "misc"], [8, 9, "researcher"], [11, 12, "researcher"], [21, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 8, 9, "artifact", "", false, false], [6, 6, 11, 12, "artifact", "", false, false], [6, 6, 21, 22, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1969", ",", "the", "famous", "book", "Perceptrons", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "showed", "that", "it", "was", "impossible", "to", "learn", "the", "XOR", "function", "for", "these", "classes", "of", "networks", "."], "sentence-detokenized": "In 1969, the famous book Perceptrons by Marvin Minsky and Seymour Papert showed that it was impossible to learn the XOR function for these classes of networks.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 19], [20, 24], [25, 36], [37, 39], [40, 46], [47, 53], [54, 57], [58, 65], [66, 72], [73, 79], [80, 84], [85, 87], [88, 91], [92, 102], [103, 105], [106, 111], [112, 115], [116, 119], [120, 128], [129, 132], [133, 138], [139, 146], [147, 149], [150, 158], [158, 159]]}
{"doc_key": "ai-test-243", "ner": [[4, 8, "misc"], [12, 12, "product"], [18, 21, "organisation"], [25, 30, "organisation"], [33, 38, "location"], [40, 40, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 21, 12, 12, "usage", "", false, false], [18, 21, 33, 38, "physical", "", false, false], [25, 30, 18, 21, "named", "", false, false], [33, 38, 40, 40, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "large", "number", "of", "Russian", "scientific", "and", "technical", "documents", "were", "translated", "using", "SYSTRAN", "under", "the", "auspices", "of", "the", "USAF", "Foreign", "Technology", "Division", "(", "later", "the", "National", "Air", "and", "Space", "Intelligence", "Center", ")", "at", "Wright", "-", "Patterson", "Air", "Force", "Base", ",", "Ohio", "."], "sentence-detokenized": "A large number of Russian scientific and technical documents were translated using SYSTRAN under the auspices of the USAF Foreign Technology Division (later the National Air and Space Intelligence Center) at Wright-Patterson Air Force Base, Ohio.", "token2charspan": [[0, 1], [2, 7], [8, 14], [15, 17], [18, 25], [26, 36], [37, 40], [41, 50], [51, 60], [61, 65], [66, 76], [77, 82], [83, 90], [91, 96], [97, 100], [101, 109], [110, 112], [113, 116], [117, 121], [122, 129], [130, 140], [141, 149], [150, 151], [151, 156], [157, 160], [161, 169], [170, 173], [174, 177], [178, 183], [184, 196], [197, 203], [203, 204], [205, 207], [208, 214], [214, 215], [215, 224], [225, 228], [229, 234], [235, 239], [239, 240], [241, 245], [245, 246]]}
{"doc_key": "ai-test-244", "ner": [[0, 1, "field"], [4, 14, "field"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Semi-supervised", "learning", "falls", "between", "unsupervised", "learning", "(", "without", "any", "labelled", "training", "data", ")", "and", "supervised", "learning", "(", "with", "fully", "labelled", "training", "data", ")", "."], "sentence-detokenized": "Semi-supervised learning falls between unsupervised learning (without any labelled training data) and supervised learning (with fully labelled training data).", "token2charspan": [[0, 15], [16, 24], [25, 30], [31, 38], [39, 51], [52, 60], [61, 62], [62, 69], [70, 73], [74, 82], [83, 91], [92, 96], [96, 97], [98, 101], [102, 112], [113, 121], [122, 123], [123, 127], [128, 133], [134, 142], [143, 151], [152, 156], [156, 157], [157, 158]]}
{"doc_key": "ai-test-245", "ner": [[0, 3, "algorithm"], [8, 10, "algorithm"], [32, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 8, 10, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Ann", "-", "gram", "model", "is", "a", "kind", "of", "probabilistic", "language", "model", "for", "predicting", "the", "next", "element", "in", "such", "a", "sequence", "in", "the", "form", "of", "an", "(", "n", "-", "1", ")", "-", "order", "Markov", "model", ".effectively", "."], "sentence-detokenized": "Ann -gram model is a kind of probabilistic language model for predicting the next element in such a sequence in the form of an (n - 1) -order Markov model .effectively.", "token2charspan": [[0, 3], [4, 5], [5, 9], [10, 15], [16, 18], [19, 20], [21, 25], [26, 28], [29, 42], [43, 51], [52, 57], [58, 61], [62, 72], [73, 76], [77, 81], [82, 89], [90, 92], [93, 97], [98, 99], [100, 108], [109, 111], [112, 115], [116, 120], [121, 123], [124, 126], [127, 128], [128, 129], [130, 131], [132, 133], [133, 134], [135, 136], [136, 141], [142, 148], [149, 154], [155, 167], [167, 168]]}
{"doc_key": "ai-test-246", "ner": [[0, 2, "organisation"], [4, 4, "product"], [8, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 4, 4, "usage", "", false, false], [8, 14, 0, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Cleveland", "Clinic", "used", "Cyc", "to", "develop", "a", "natural", "language", "query", "interface", "for", "biomedical", "information", ",", "covering", "decades", "of", "cardiac", "surgery", "information", "."], "sentence-detokenized": "The Cleveland Clinic used Cyc to develop a natural language query interface for biomedical information, covering decades of cardiac surgery information.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 29], [30, 32], [33, 40], [41, 42], [43, 50], [51, 59], [60, 65], [66, 75], [76, 79], [80, 90], [91, 102], [102, 103], [104, 112], [113, 120], [121, 123], [124, 131], [132, 139], [140, 151], [151, 152]]}
{"doc_key": "ai-test-247", "ner": [[6, 6, "country"], [8, 9, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 6, 8, 9, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "incident", "strained", "relations", "between", "the", "US", "and", "Japan", "and", "led", "to", "the", "arrest", "and", "prosecution", "of", "two", "executives", ",", "as", "well", "as", "sanctions", "imposed", "on", "the", "company", "by", "both", "countries", "."], "sentence-detokenized": "The incident strained relations between the US and Japan and led to the arrest and prosecution of two executives, as well as sanctions imposed on the company by both countries.", "token2charspan": [[0, 3], [4, 12], [13, 21], [22, 31], [32, 39], [40, 43], [44, 46], [47, 50], [51, 56], [57, 60], [61, 64], [65, 67], [68, 71], [72, 78], [79, 82], [83, 94], [95, 97], [98, 101], [102, 112], [112, 113], [114, 116], [117, 121], [122, 124], [125, 134], [135, 142], [143, 145], [146, 149], [150, 157], [158, 160], [161, 165], [166, 175], [175, 176]]}
{"doc_key": "ai-test-248", "ner": [[6, 9, "algorithm"], [12, 13, "field"], [22, 22, "misc"], [34, 34, "misc"], [38, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 9, 12, 13, "type-of", "", false, false], [22, 22, 12, 13, "part-of", "", true, false], [34, 34, 12, 13, "part-of", "", true, false], [38, 38, 12, 13, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["If", "the", "modelling", "is", "done", "using", "an", "artificial", "neural", "network", "or", "other", "machine", "learning", ",", "the", "optimisation", "of", "the", "parameters", "is", "called", "training", ",", "while", "the", "optimisation", "of", "the", "model", "'s", "hyperparameters", "is", "called", "tuning", "and", "often", "uses", "cross-validation", "...."], "sentence-detokenized": "If the modelling is done using an artificial neural network or other machine learning, the optimisation of the parameters is called training, while the optimisation of the model's hyperparameters is called tuning and often uses cross-validation....", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 24], [25, 30], [31, 33], [34, 44], [45, 51], [52, 59], [60, 62], [63, 68], [69, 76], [77, 85], [85, 86], [87, 90], [91, 103], [104, 106], [107, 110], [111, 121], [122, 124], [125, 131], [132, 140], [140, 141], [142, 147], [148, 151], [152, 164], [165, 167], [168, 171], [172, 177], [177, 179], [180, 195], [196, 198], [199, 205], [206, 212], [213, 216], [217, 222], [223, 227], [228, 244], [244, 248]]}
{"doc_key": "ai-test-249", "ner": [[8, 8, "country"], [10, 10, "country"], [12, 12, "country"], [19, 20, "organisation"], [22, 22, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 20, 22, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Localised", "versions", "of", "the", "service", "available", "in", "the", "UK", ",", "India", "and", "Australia", "were", "withdrawn", "following", "the", "acquisition", "of", "Rotten", "Tomatoes", "by", "Fandango", "."], "sentence-detokenized": "Localised versions of the service available in the UK, India and Australia were withdrawn following the acquisition of Rotten Tomatoes by Fandango.", "token2charspan": [[0, 9], [10, 18], [19, 21], [22, 25], [26, 33], [34, 43], [44, 46], [47, 50], [51, 53], [53, 54], [55, 60], [61, 64], [65, 74], [75, 79], [80, 89], [90, 99], [100, 103], [104, 115], [116, 118], [119, 125], [126, 134], [135, 137], [138, 146], [146, 147]]}
{"doc_key": "ai-test-250", "ner": [[1, 1, "task"], [13, 14, "metrics"], [26, 27, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 13, 14, "related-to", "", false, false], [13, 14, 26, 27, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "NER", "model", "is", "one", "of", "a", "number", "of", "methods", "for", "determining", "the", "accuracy", "of", "live", "captioning", "in", "TV", "broadcasts", "and", "events", "that", "are", "produced", "using", "speech", "recognition", "."], "sentence-detokenized": "The NER model is one of a number of methods for determining the accuracy of live captioning in TV broadcasts and events that are produced using speech recognition.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 20], [21, 23], [24, 25], [26, 32], [33, 35], [36, 43], [44, 47], [48, 59], [60, 63], [64, 72], [73, 75], [76, 80], [81, 91], [92, 94], [95, 97], [98, 108], [109, 112], [113, 119], [120, 124], [125, 128], [129, 137], [138, 143], [144, 150], [151, 162], [162, 163]]}
{"doc_key": "ai-test-251", "ner": [[0, 0, "researcher"], [4, 10, "university"], [8, 9, "university"], [11, 11, "location"], [13, 17, "university"], [19, 20, "university"], [22, 22, "location"], [24, 29, "university"], [31, 32, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 10, "physical", "", false, false], [0, 0, 4, 10, "role", "", false, false], [0, 0, 8, 9, "physical", "", false, false], [0, 0, 8, 9, "role", "", false, false], [0, 0, 13, 17, "physical", "", false, false], [0, 0, 13, 17, "role", "", false, false], [0, 0, 19, 20, "physical", "", false, false], [0, 0, 19, 20, "role", "", false, false], [0, 0, 24, 29, "physical", "", false, false], [0, 0, 24, 29, "role", "", false, false], [8, 9, 11, 11, "physical", "", false, false], [13, 17, 22, 22, "physical", "", false, false], [19, 20, 22, 22, "physical", "", false, false], [24, 29, 31, 32, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Atran", "has", "taught", "at", "Cambridge", "University", ",", "the", "Hebrew", "University", "of", "Jerusalem", ",", "\u00c9cole", "pratique", "des", "hautes", "\u00e9tudes", "and", "\u00c9cole", "Polytechnique", "in", "Paris", "and", "John", "Jay", "College", "of", "Criminal", "Justice", "in", "New", "York", "."], "sentence-detokenized": "Atran has taught at Cambridge University, the Hebrew University of Jerusalem, \u00c9cole pratique des hautes \u00e9tudes and \u00c9cole Polytechnique in Paris and John Jay College of Criminal Justice in New York.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 40], [40, 41], [42, 45], [46, 52], [53, 63], [64, 66], [67, 76], [76, 77], [78, 83], [84, 92], [93, 96], [97, 103], [104, 110], [111, 114], [115, 120], [121, 134], [135, 137], [138, 143], [144, 147], [148, 152], [153, 156], [157, 164], [165, 167], [168, 176], [177, 184], [185, 187], [188, 191], [192, 196], [196, 197]]}
{"doc_key": "ai-test-252", "ner": [[0, 0, "product"], [7, 9, "task"], [13, 15, "researcher"], [16, 16, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 9, "origin", "", false, false], [0, 0, 7, 9, "related-to", "", false, false], [7, 9, 16, 16, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "was", "an", "early", "computer", "program", "for", "natural", "language", "understanding", ",", "developed", "by", "Terry", "Winograd", "at", "MIT", "between", "1968", "and", "1970"], "sentence-detokenized": "SHRDLU was an early computer program for natural language understanding, developed by Terry Winograd at MIT between 1968 and 1970", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 19], [20, 28], [29, 36], [37, 40], [41, 48], [49, 57], [58, 71], [71, 72], [73, 82], [83, 85], [86, 91], [92, 100], [101, 103], [104, 107], [108, 115], [116, 120], [121, 124], [125, 129]]}
{"doc_key": "ai-test-253", "ner": [[2, 3, "misc"], [5, 8, "field"], [9, 14, "university"], [15, 15, "location"], [17, 19, "country"], [16, 31, "university"], [31, 31, "misc"], [33, 36, "field"], [40, 40, "university"], [44, 45, "misc"], [37, 48, "field"], [53, 53, "misc"], [61, 65, "university"], [70, 71, "field"], [75, 76, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[2, 3, 5, 8, "topic", "", false, false], [2, 3, 9, 14, "origin", "", false, false], [9, 14, 15, 15, "physical", "", false, false], [9, 14, 16, 31, "role", "affiliated_with", false, false], [15, 15, 17, 19, "physical", "", false, false], [31, 31, 33, 36, "topic", "", false, false], [31, 31, 40, 40, "origin", "", false, false], [44, 45, 37, 48, "topic", "", false, false], [53, 53, 61, 65, "origin", "", false, false], [53, 53, 70, 71, "topic", "", false, false], [75, 76, 61, 65, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["He", "received", "a", "B.E.", "in", "electronic", "engineering", "from", "the", "B.M.S", ".", "College", "of", "Engineering", "in", "Bangalore", ",", "India", ",", "in", "1982", ",", "when", "it", "was", "affiliated", "with", "Bangalore", "University", ",", "an", "M.S.", "in", "electrical", "and", "computer", "engineering", "in", "1984", "from", "Drexel", "University", "and", "an", "M.S.", "in", "computer", "science", "in", "1989", ",", "and", "a", "Ph.D.", "in", "1990", ",", "respectively", ",", "from", "the", "University", "of", "Wisconsin", "-", "Madison", ",", "where", "he", "studied", "artificial", "intelligence", "and", "worked", "with", "Leonard", "Uhr", "."], "sentence-detokenized": "He received a B.E. in electronic engineering from the B.M.S. College of Engineering in Bangalore, India, in 1982, when it was affiliated with Bangalore University, an M.S. in electrical and computer engineering in 1984 from Drexel University and an M.S. in computer science in 1989, and a Ph.D. in 1990, respectively, from the University of Wisconsin-Madison, where he studied artificial intelligence and worked with Leonard Uhr.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 18], [19, 21], [22, 32], [33, 44], [45, 49], [50, 53], [54, 59], [59, 60], [61, 68], [69, 71], [72, 83], [84, 86], [87, 96], [96, 97], [98, 103], [103, 104], [105, 107], [108, 112], [112, 113], [114, 118], [119, 121], [122, 125], [126, 136], [137, 141], [142, 151], [152, 162], [162, 163], [164, 166], [167, 171], [172, 174], [175, 185], [186, 189], [190, 198], [199, 210], [211, 213], [214, 218], [219, 223], [224, 230], [231, 241], [242, 245], [246, 248], [249, 253], [254, 256], [257, 265], [266, 273], [274, 276], [277, 281], [281, 282], [283, 286], [287, 288], [289, 294], [295, 297], [298, 302], [302, 303], [304, 316], [316, 317], [318, 322], [323, 326], [327, 337], [338, 340], [341, 350], [350, 351], [351, 358], [358, 359], [360, 365], [366, 368], [369, 376], [377, 387], [388, 400], [401, 404], [405, 411], [412, 416], [417, 424], [425, 428], [428, 429]]}
{"doc_key": "ai-test-254", "ner": [[6, 7, "metrics"], [10, 10, "metrics"], [8, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Accuracy", "is", "usually", "assessed", "by", "the", "word", "error", "rate", "(", "WER", ")", ",", "while", "speed", "is", "measured", "by", "the", "real", "-", "time", "rate", "."], "sentence-detokenized": "Accuracy is usually assessed by the word error rate (WER), while speed is measured by the real-time rate.", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 28], [29, 31], [32, 35], [36, 40], [41, 46], [47, 51], [52, 53], [53, 56], [56, 57], [57, 58], [59, 64], [65, 70], [71, 73], [74, 82], [83, 85], [86, 89], [90, 94], [94, 95], [95, 99], [100, 104], [104, 105]]}
{"doc_key": "ai-test-255", "ner": [[3, 4, "researcher"], [8, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 8, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1971", ",", "Terry", "Winograd", "developed", "an", "early", "natural", "language", "processing", "engine", "capable", "of", "interpreting", "naturally", "written", "commands", "within", "a", "simple", "rule", "-", "governed", "environment", "."], "sentence-detokenized": "In 1971, Terry Winograd developed an early natural language processing engine capable of interpreting naturally written commands within a simple rule-governed environment.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 33], [34, 36], [37, 42], [43, 50], [51, 59], [60, 70], [71, 77], [78, 85], [86, 88], [89, 101], [102, 111], [112, 119], [120, 128], [129, 135], [136, 137], [138, 144], [145, 149], [149, 150], [150, 158], [159, 170], [170, 171]]}
{"doc_key": "ai-test-256", "ner": [[1, 2, "field"], [4, 5, "researcher"], [7, 15, "researcher"], [12, 13, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 4, 5, "related-to", "", false, false], [1, 2, 7, 15, "related-to", "", false, false], [1, 2, 12, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "artificial", "intelligence", ",", "Marvin", "Minsky", ",", "Herbert", "A", ".", "Simon", "and", "Allen", "Newell", "stand", "out", "."], "sentence-detokenized": "In artificial intelligence, Marvin Minsky, Herbert A. Simon and Allen Newell stand out.", "token2charspan": [[0, 2], [3, 13], [14, 26], [26, 27], [28, 34], [35, 41], [41, 42], [43, 50], [51, 52], [52, 53], [54, 59], [60, 63], [64, 69], [70, 76], [77, 82], [83, 86], [86, 87]]}
{"doc_key": "ai-test-257", "ner": [[9, 10, "field"], [30, 31, "field"], [33, 34, "field"], [39, 40, "field"], [48, 51, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[30, 31, 9, 10, "origin", "", true, false], [30, 31, 9, 10, "part-of", "", false, false], [30, 31, 39, 40, "compare", "", false, false], [33, 34, 9, 10, "origin", "", true, false], [33, 34, 9, 10, "part-of", "", false, false], [33, 34, 39, 40, "compare", "", false, false], [39, 40, 9, 10, "origin", "", true, false], [39, 40, 9, 10, "part-of", "", false, false], [39, 40, 48, 51, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "the", "second", "half", "of", "the", "20th", "century", ",", "electrical", "engineering", "itself", "split", "into", "several", "disciplines", ",", "specialising", "in", "the", "design", "and", "analysis", "of", "systems", "that", "manipulate", "physical", "signals", ";", "electronic", "engineering", "and", "computer", "engineering", "as", "examples", ";", "while", "design", "engineering", "evolved", "to", "address", "the", "functional", "design", "of", "user", "-", "machine", "interfaces", "."], "sentence-detokenized": "In the second half of the 20th century, electrical engineering itself split into several disciplines, specialising in the design and analysis of systems that manipulate physical signals; electronic engineering and computer engineering as examples; while design engineering evolved to address the functional design of user-machine interfaces.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 21], [22, 25], [26, 30], [31, 38], [38, 39], [40, 50], [51, 62], [63, 69], [70, 75], [76, 80], [81, 88], [89, 100], [100, 101], [102, 114], [115, 117], [118, 121], [122, 128], [129, 132], [133, 141], [142, 144], [145, 152], [153, 157], [158, 168], [169, 177], [178, 185], [185, 186], [187, 197], [198, 209], [210, 213], [214, 222], [223, 234], [235, 237], [238, 246], [246, 247], [248, 253], [254, 260], [261, 272], [273, 280], [281, 283], [284, 291], [292, 295], [296, 306], [307, 313], [314, 316], [317, 321], [321, 322], [322, 329], [330, 340], [340, 341]]}
{"doc_key": "ai-test-258", "ner": [[5, 5, "metrics"], [7, 8, "metrics"], [10, 10, "metrics"], [46, 48, "metrics"], [57, 57, "metrics"], [65, 67, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 10, 7, 8, "named", "", false, false], [46, 48, 57, 57, "named", "", false, false], [57, 57, 65, 67, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Perhaps", "the", "simplest", "statistic", "is", "accuracy", "or", "Fraction", "Correct", "(", "FC", ")", ",", "which", "measures", "the", "fraction", "of", "all", "instances", "that", "are", "correctly", "categorised", ";", "it", "is", "the", "ratio", "of", "the", "number", "of", "correct", "classifications", "to", "the", "total", "number", "of", "correct", "or", "incorrect", "classifications", ":", "(", "TP", "+", "TN", ")", "/", "Total", "Population", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "Perhaps the simplest statistic is accuracy or Fraction Correct (FC), which measures the fraction of all instances that are correctly categorised; it is the ratio of the number of correct classifications to the total number of correct or incorrect classifications: (TP + TN) / Total Population = (TP + TN) / (TP + TN + FP + FN).", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 30], [31, 33], [34, 42], [43, 45], [46, 54], [55, 62], [63, 64], [64, 66], [66, 67], [67, 68], [69, 74], [75, 83], [84, 87], [88, 96], [97, 99], [100, 103], [104, 113], [114, 118], [119, 122], [123, 132], [133, 144], [144, 145], [146, 148], [149, 151], [152, 155], [156, 161], [162, 164], [165, 168], [169, 175], [176, 178], [179, 186], [187, 202], [203, 205], [206, 209], [210, 215], [216, 222], [223, 225], [226, 233], [234, 236], [237, 246], [247, 262], [262, 263], [264, 265], [265, 267], [268, 269], [270, 272], [272, 273], [274, 275], [276, 281], [282, 292], [293, 294], [295, 296], [296, 298], [299, 300], [301, 303], [303, 304], [305, 306], [307, 308], [308, 310], [311, 312], [313, 315], [316, 317], [318, 320], [321, 322], [323, 325], [325, 326], [326, 327]]}
{"doc_key": "ai-test-259", "ner": [[14, 21, "conference"], [23, 25, "conference"], [30, 30, "location"], [36, 36, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 21, 30, 30, "physical", "", false, false], [23, 25, 14, 21, "named", "", false, false], [36, 36, 14, 21, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "academia", ",", "the", "main", "forums", "for", "research", "began", "in", "1995", ",", "when", "the", "first", "international", "Data", "Mining", "and", "Knowledge", "Discovery", "conference", "(", "KDD", "-", "95", ")", "was", "launched", "in", "Montreal", "under", "the", "auspices", "of", "the", "AAAI", "."], "sentence-detokenized": "In academia, the main forums for research began in 1995, when the first international Data Mining and Knowledge Discovery conference (KDD-95) was launched in Montreal under the auspices of the AAAI.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 32], [33, 41], [42, 47], [48, 50], [51, 55], [55, 56], [57, 61], [62, 65], [66, 71], [72, 85], [86, 90], [91, 97], [98, 101], [102, 111], [112, 121], [122, 132], [133, 134], [134, 137], [137, 138], [138, 140], [140, 141], [142, 145], [146, 154], [155, 157], [158, 166], [167, 172], [173, 176], [177, 185], [186, 188], [189, 192], [193, 197], [197, 198]]}
{"doc_key": "ai-test-260", "ner": [[9, 9, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "this", "approach", ",", "models", "are", "developed", "using", "various", "data", "mining", ",", "machine", "learning", "algorithms", "to", "predict", "user", "ratings", "for", "unrated", "items", "."], "sentence-detokenized": "In this approach, models are developed using various data mining, machine learning algorithms to predict user ratings for unrated items.", "token2charspan": [[0, 2], [3, 7], [8, 16], [16, 17], [18, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 57], [58, 64], [64, 65], [66, 73], [74, 82], [83, 93], [94, 96], [97, 104], [105, 109], [110, 117], [118, 121], [122, 129], [130, 135], [135, 136]]}
{"doc_key": "ai-test-261", "ner": [[11, 11, "algorithm"], [16, 17, "algorithm"], [19, 20, "algorithm"], [27, 28, "misc"], [30, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 11, 16, 17, "related-to", "equivalent", false, false], [16, 17, 19, 20, "usage", "", false, false], [19, 20, 30, 31, "usage", "", false, false], [30, 31, 27, 28, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "light", "of", "the", "above", "discussion", ",", "we", "see", "that", "the", "SVM", "technique", "is", "equivalent", "to", "empirical", "risk", "with", "Tikhonov", "regularisation", ",", "where", "in", "this", "case", "the", "loss", "function", "is", "the", "hinge", "loss"], "sentence-detokenized": "In light of the above discussion, we see that the SVM technique is equivalent to empirical risk with Tikhonov regularisation, where in this case the loss function is the hinge loss", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 15], [16, 21], [22, 32], [32, 33], [34, 36], [37, 40], [41, 45], [46, 49], [50, 53], [54, 63], [64, 66], [67, 77], [78, 80], [81, 90], [91, 95], [96, 100], [101, 109], [110, 124], [124, 125], [126, 131], [132, 134], [135, 139], [140, 144], [145, 148], [149, 153], [154, 162], [163, 165], [166, 169], [170, 175], [176, 180]]}
{"doc_key": "ai-test-262", "ner": [[6, 7, "person"], [11, 12, "person"], [15, 15, "organisation"], [17, 18, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[17, 18, 15, 15, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "2015", "edition", "was", "hosted", "by", "Molly", "McGrath", ",", "with", "commentators", "Chris", "Rose", "and", "former", "UFC", "fighter", "Kenny", "Florian", "."], "sentence-detokenized": "The 2015 edition was hosted by Molly McGrath, with commentators Chris Rose and former UFC fighter Kenny Florian.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 27], [28, 30], [31, 36], [37, 44], [44, 45], [46, 50], [51, 63], [64, 69], [70, 74], [75, 78], [79, 85], [86, 89], [90, 97], [98, 103], [104, 111], [111, 112]]}
{"doc_key": "ai-test-263", "ner": [[3, 5, "product"], [9, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [18, 18, "researcher"], [25, 25, "researcher"], [32, 33, "researcher"], [35, 37, "task"], [34, 43, "product"], [40, 41, "researcher"], [45, 45, "task"], [48, 50, "researcher"], [53, 55, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[3, 5, 9, 11, "origin", "", false, false], [3, 5, 13, 14, "origin", "", false, false], [3, 5, 16, 17, "origin", "", false, false], [3, 5, 18, 18, "origin", "", false, false], [13, 14, 40, 41, "named", "same", false, false], [16, 17, 25, 25, "named", "same", false, false], [16, 17, 32, 33, "named", "same", false, false], [35, 37, 34, 43, "related-to", "", false, false], [34, 43, 32, 33, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["A", "subset", "called", "Micro", "-", "Planner", "was", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "Sussman", ",", ",", ",", ",", ",", "and", "Winograd", "1971", "and", "has", "been", "used", "in", "Winograd", "'s", "SHRDLU", "natural", "language", "understanding", "programme", ",", "Eugene", "Charniak", "'s", "work", "on", "story", "understanding", ",", "Thorne", "McCarty", "'s", "work", "on", "legal", "reasoning", "and", "several", "other", "projects", "."], "sentence-detokenized": "A subset called Micro-Planner was implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd Sussman,,,,, and Winograd 1971 and has been used in Winograd's SHRDLU natural language understanding programme, Eugene Charniak's work on story understanding, Thorne McCarty's work on legal reasoning and several other projects.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [21, 22], [22, 29], [30, 33], [34, 45], [46, 48], [49, 55], [56, 59], [60, 67], [67, 68], [69, 75], [76, 84], [85, 88], [89, 94], [95, 103], [104, 111], [111, 112], [112, 113], [113, 114], [114, 115], [115, 116], [117, 120], [121, 129], [130, 134], [135, 138], [139, 142], [143, 147], [148, 152], [153, 155], [156, 164], [164, 166], [167, 173], [174, 181], [182, 190], [191, 204], [205, 214], [214, 215], [216, 222], [223, 231], [231, 233], [234, 238], [239, 241], [242, 247], [248, 261], [261, 262], [263, 269], [270, 277], [277, 279], [280, 284], [285, 287], [288, 293], [294, 303], [304, 307], [308, 315], [316, 321], [322, 330], [330, 331]]}
{"doc_key": "ai-test-264", "ner": [[0, 1, "product"], [9, 10, "product"], [14, 14, "task"], [16, 17, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "task"], [30, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[9, 10, 0, 1, "usage", "", true, false], [14, 14, 9, 10, "part-of", "", true, false], [16, 17, 9, 10, "part-of", "", true, false], [20, 21, 9, 10, "part-of", "", true, false], [23, 24, 9, 10, "part-of", "", true, false], [26, 27, 9, 10, "part-of", "", true, false], [30, 33, 9, 10, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Word", "Net", "has", "been", "used", "for", "many", "purposes", "in", "information", "systems", ",", "including", "word", "disambiguation", ",", "information", "retrieval", ",", "automatic", "text", "classification", ",", "automatic", "summarisation", ",", "machine", "translation", "and", "even", "automatic", "crossword", "puzzle", "generation", "."], "sentence-detokenized": "WordNet has been used for many purposes in information systems, including word disambiguation, information retrieval, automatic text classification, automatic summarisation, machine translation and even automatic crossword puzzle generation.", "token2charspan": [[0, 4], [4, 7], [8, 11], [12, 16], [17, 21], [22, 25], [26, 30], [31, 39], [40, 42], [43, 54], [55, 62], [62, 63], [64, 73], [74, 78], [79, 93], [93, 94], [95, 106], [107, 116], [116, 117], [118, 127], [128, 132], [133, 147], [147, 148], [149, 158], [159, 172], [172, 173], [174, 181], [182, 193], [194, 197], [198, 202], [203, 212], [213, 222], [223, 229], [230, 240], [240, 241]]}
{"doc_key": "ai-test-265", "ner": [[0, 0, "researcher"], [7, 7, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 7, 7, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Keutzer", "was", "made", "a", "Fellow", "of", "the", "IEEE", "in", "1996", "."], "sentence-detokenized": "Keutzer was made a Fellow of the IEEE in 1996.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 37], [38, 40], [41, 45], [45, 46]]}
{"doc_key": "ai-test-266", "ner": [[8, 10, "algorithm"], [53, 54, "misc"], [63, 64, "algorithm"], [66, 67, "algorithm"], [69, 70, "algorithm"], [72, 73, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[63, 64, 53, 54, "type-of", "", false, false], [66, 67, 53, 54, "type-of", "", false, false], [69, 70, 53, 54, "type-of", "", false, false], [72, 73, 53, 54, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "widely", "used", "type", "of", "composition", "is", "the", "non-linear", "weighted", "sum", ",", "where", "the", "maths", "f", "(", "x", ")", "=", "K", "left", "(", "sum", "_", "i", "w", "_", "and", "g", "_", "i", "(", "x", ")", "\u0105", "right", ")", "/", "maths", ",", "where", "the", "maths", "K", "/", "maths", "(", "commonly", "referred", "to", "as", "the", "activation", "function", ")", "is", "some", "predefined", "function", "such", "as", "the", "hyperbolic", "tangent", ",", "sigmoidal", "function", ",", "softmax", "function", "or", "rectifier", "function", "."], "sentence-detokenized": "A widely used type of composition is the non-linear weighted sum, where the maths f (x) = K left (sum _ i w _ and g _ i (x)\u0105 right) / maths, where the maths K / maths (commonly referred to as the activation function) is some predefined function such as the hyperbolic tangent, sigmoidal function, softmax function or rectifier function.", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 18], [19, 21], [22, 33], [34, 36], [37, 40], [41, 51], [52, 60], [61, 64], [64, 65], [66, 71], [72, 75], [76, 81], [82, 83], [84, 85], [85, 86], [86, 87], [88, 89], [90, 91], [92, 96], [97, 98], [98, 101], [102, 103], [104, 105], [106, 107], [108, 109], [110, 113], [114, 115], [116, 117], [118, 119], [120, 121], [121, 122], [122, 123], [123, 124], [125, 130], [130, 131], [132, 133], [134, 139], [139, 140], [141, 146], [147, 150], [151, 156], [157, 158], [159, 160], [161, 166], [167, 168], [168, 176], [177, 185], [186, 188], [189, 191], [192, 195], [196, 206], [207, 215], [215, 216], [217, 219], [220, 224], [225, 235], [236, 244], [245, 249], [250, 252], [253, 256], [257, 267], [268, 275], [275, 276], [277, 286], [287, 295], [295, 296], [297, 304], [305, 313], [314, 316], [317, 326], [327, 335], [335, 336]]}
{"doc_key": "ai-test-267", "ner": [[3, 3, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "film", "Westworld", ",", "female", "robots", "actually", "engaged", "in", "sexual", "intercourse", "with", "human", "men", "as", "part", "of", "a", "fake", "holiday", "world", "paid", "for", "by", "human", "customers", "."], "sentence-detokenized": "In the film Westworld, female robots actually engaged in sexual intercourse with human men as part of a fake holiday world paid for by human customers.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 21], [21, 22], [23, 29], [30, 36], [37, 45], [46, 53], [54, 56], [57, 63], [64, 75], [76, 80], [81, 86], [87, 90], [91, 93], [94, 98], [99, 101], [102, 103], [104, 108], [109, 116], [117, 122], [123, 127], [128, 131], [132, 134], [135, 140], [141, 150], [150, 151]]}
{"doc_key": "ai-test-268", "ner": [[7, 9, "task"], [23, 28, "task"], [31, 31, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 23, 28, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Typically", ",", "the", "process", "starts", "with", "the", "extraction", "of", "terminology", "and", "concepts", "or", "noun", "phrases", "from", "plain", "text", "using", "linguistic", "processors", "such", "as", "part", "-", "of", "-", "speech", "tagging", "and", "phrase", "chunking", "."], "sentence-detokenized": "Typically, the process starts with the extraction of terminology and concepts or noun phrases from plain text using linguistic processors such as part-of-speech tagging and phrase chunking.", "token2charspan": [[0, 9], [9, 10], [11, 14], [15, 22], [23, 29], [30, 34], [35, 38], [39, 49], [50, 52], [53, 64], [65, 68], [69, 77], [78, 80], [81, 85], [86, 93], [94, 98], [99, 104], [105, 109], [110, 115], [116, 126], [127, 137], [138, 142], [143, 145], [146, 150], [150, 151], [151, 153], [153, 154], [154, 160], [161, 168], [169, 172], [173, 179], [180, 188], [188, 189]]}
{"doc_key": "ai-test-269", "ner": [[13, 14, "field"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 13, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "demonstrated", "its", "performance", "on", "a", "number", "of", "problems", "of", "interest", "to", "the", "machine", "learning", "community", ",", "including", "handwriting", "recognition", "."], "sentence-detokenized": "They demonstrated its performance on a number of problems of interest to the machine learning community, including handwriting recognition.", "token2charspan": [[0, 4], [5, 17], [18, 21], [22, 33], [34, 36], [37, 38], [39, 45], [46, 48], [49, 57], [58, 60], [61, 69], [70, 72], [73, 76], [77, 84], [85, 93], [94, 103], [103, 104], [105, 114], [115, 126], [127, 138], [138, 139]]}
{"doc_key": "ai-test-270", "ner": [[3, 3, "university"], [5, 5, "researcher"], [12, 13, "researcher"], [17, 19, "product"], [21, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 5, 3, 3, "physical", "", false, false], [5, 5, 3, 3, "role", "", false, false], [17, 19, 12, 13, "origin", "", false, false], [17, 19, 21, 22, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "studying", "at", "Stanford", ",", "Scheinman", "was", "awarded", "a", "scholarship", "sponsored", "by", "George", "Devol", ",", "inventor", "of", "Unimate", ",", "the", "first", "industrial", "robot", "."], "sentence-detokenized": "While studying at Stanford, Scheinman was awarded a scholarship sponsored by George Devol, inventor of Unimate, the first industrial robot.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [26, 27], [28, 37], [38, 41], [42, 49], [50, 51], [52, 63], [64, 73], [74, 76], [77, 83], [84, 89], [89, 90], [91, 99], [100, 102], [103, 110], [110, 111], [112, 115], [116, 121], [122, 132], [133, 138], [138, 139]]}
{"doc_key": "ai-test-271", "ner": [[7, 8, "task"], [10, 12, "metrics"], [14, 14, "metrics"], [22, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 10, 12, "usage", "", true, false], [14, 14, 10, 12, "named", "", false, false], [22, 24, 10, 12, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Although", "originally", "used", "for", "the", "evaluation", "of", "machine", "translation", ",", "bilingual", "deficient", "evaluation", "(", "BLEU", ")", "has", "been", "successfully", "used", "to", "evaluate", "paraphrase", "generation", "models", "."], "sentence-detokenized": "Although originally used for the evaluation of machine translation, bilingual deficient evaluation (BLEU) has been successfully used to evaluate paraphrase generation models.", "token2charspan": [[0, 8], [9, 19], [20, 24], [25, 28], [29, 32], [33, 43], [44, 46], [47, 54], [55, 66], [66, 67], [68, 77], [78, 87], [88, 98], [99, 100], [100, 104], [104, 105], [106, 109], [110, 114], [115, 127], [128, 132], [133, 135], [136, 144], [145, 155], [156, 166], [167, 173], [173, 174]]}
{"doc_key": "ai-test-272", "ner": [[0, 0, "organisation"], [6, 8, "organisation"], [10, 10, "organisation"], [14, 14, "product"], [16, 16, "country"], [18, 18, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 8, "role", "licenses_to", false, false], [0, 0, 10, 10, "role", "licenses_to", false, false], [6, 8, 16, 16, "physical", "", false, false], [10, 10, 18, 18, "physical", "", false, false], [14, 14, 6, 8, "artifact", "produces", false, false], [14, 14, 10, 10, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "later", "licensed", "its", "technology", "to", "Kawasaki", "Heavy", "Industries", "and", "GKN", ",", "which", "manufactures", "Unimatics", "in", "Japan", "and", "England", "respectively", "."], "sentence-detokenized": "Unimation later licensed its technology to Kawasaki Heavy Industries and GKN, which manufactures Unimatics in Japan and England respectively.", "token2charspan": [[0, 9], [10, 15], [16, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 57], [58, 68], [69, 72], [73, 76], [76, 77], [78, 83], [84, 96], [97, 106], [107, 109], [110, 115], [116, 119], [120, 127], [128, 140], [140, 141]]}
{"doc_key": "ai-test-273", "ner": [[19, 21, "conference"], [37, 38, "field"], [58, 69, "field"], [62, 62, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[37, 38, 58, 69, "compare", "", false, false], [62, 62, 58, 69, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Much", "of", "the", "disagreement", "between", "the", "two", "research", "communities", "(", "which", "often", "have", "separate", "conferences", "and", "separate", "journals", ",", "ECML", "PKDD", "being", "the", "main", "exception", ")", "stems", "from", "the", "basic", "assumptions", "on", "which", "they", "work", ":", "in", "machine", "learning", ",", "performance", "is", "usually", "evaluated", "in", "terms", "of", "the", "ability", "to", "reproduce", "known", "knowledge", ",", "whereas", "in", "knowledge", "discovery", "and", "data", "mining", "(", "KDD", ")", "the", "key", "task", "is", "to", "discover", "previously", "unknown", "knowledge", "."], "sentence-detokenized": "Much of the disagreement between the two research communities (which often have separate conferences and separate journals, ECML PKDD being the main exception) stems from the basic assumptions on which they work: in machine learning, performance is usually evaluated in terms of the ability to reproduce known knowledge, whereas in knowledge discovery and data mining (KDD) the key task is to discover previously unknown knowledge.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 24], [25, 32], [33, 36], [37, 40], [41, 49], [50, 61], [62, 63], [63, 68], [69, 74], [75, 79], [80, 88], [89, 100], [101, 104], [105, 113], [114, 122], [122, 123], [124, 128], [129, 133], [134, 139], [140, 143], [144, 148], [149, 158], [158, 159], [160, 165], [166, 170], [171, 174], [175, 180], [181, 192], [193, 195], [196, 201], [202, 206], [207, 211], [211, 212], [213, 215], [216, 223], [224, 232], [232, 233], [234, 245], [246, 248], [249, 256], [257, 266], [267, 269], [270, 275], [276, 278], [279, 282], [283, 290], [291, 293], [294, 303], [304, 309], [310, 319], [319, 320], [321, 328], [329, 331], [332, 341], [342, 351], [352, 355], [356, 360], [361, 367], [368, 369], [369, 372], [372, 373], [374, 377], [378, 381], [382, 386], [387, 389], [390, 392], [393, 401], [402, 412], [413, 420], [421, 430], [430, 431]]}
{"doc_key": "ai-test-274", "ner": [[0, 1, "algorithm"], [9, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 9, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Hidden", "Markov", "models", "are", "the", "basis", "of", "most", "modern", "automatic", "speech", "recognition", "systems", "."], "sentence-detokenized": "Hidden Markov models are the basis of most modern automatic speech recognition systems.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 28], [29, 34], [35, 37], [38, 42], [43, 49], [50, 59], [60, 66], [67, 78], [79, 86], [86, 87]]}
{"doc_key": "ai-test-275", "ner": [[0, 1, "location"], [3, 5, "country"], [10, 11, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 3, 5, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "Bangalore", ",", "India", "-", "based", "company", "specialising", "in", "online", "handwriting", "recognition", "software", "."], "sentence-detokenized": "A Bangalore, India-based company specialising in online handwriting recognition software.", "token2charspan": [[0, 1], [2, 11], [11, 12], [13, 18], [18, 19], [19, 24], [25, 32], [33, 45], [46, 48], [49, 55], [56, 67], [68, 79], [80, 88], [88, 89]]}
{"doc_key": "ai-test-276", "ner": [[21, 23, "misc"], [45, 45, "metrics"], [47, 49, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[45, 45, 47, 49, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Do", "repeated", "translations", "converge", "to", "a", "single", "expression", "in", "both", "languages", "?", "I.e.", "does", "the", "translation", "method", "exhibit", "stationarity", "or", "produce", "a", "canonical", "form", "?", "Does", "the", "translation", "become", "stationary", "without", "losing", "the", "original", "meaning", "?", "This", "metric", "has", "been", "criticised", "as", "poorly", "correlated", "with", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "scores", "."], "sentence-detokenized": "Do repeated translations converge to a single expression in both languages? I.e. does the translation method exhibit stationarity or produce a canonical form? Does the translation become stationary without losing the original meaning? This metric has been criticised as poorly correlated with BLEU (BiLingual Evaluation Understudy) scores.", "token2charspan": [[0, 2], [3, 11], [12, 24], [25, 33], [34, 36], [37, 38], [39, 45], [46, 56], [57, 59], [60, 64], [65, 74], [74, 75], [76, 80], [81, 85], [86, 89], [90, 101], [102, 108], [109, 116], [117, 129], [130, 132], [133, 140], [141, 142], [143, 152], [153, 157], [157, 158], [159, 163], [164, 167], [168, 179], [180, 186], [187, 197], [198, 205], [206, 212], [213, 216], [217, 225], [226, 233], [233, 234], [235, 239], [240, 246], [247, 250], [251, 255], [256, 266], [267, 269], [270, 276], [277, 287], [288, 292], [293, 297], [298, 299], [299, 308], [309, 319], [320, 330], [330, 331], [332, 338], [338, 339]]}
{"doc_key": "ai-test-277", "ner": [[6, 10, "organisation"], [12, 20, "organisation"], [22, 25, "university"], [26, 26, "university"], [29, 32, "field"], [34, 39, "organisation"], [40, 42, "organisation"], [51, 56, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[12, 20, 22, 25, "part-of", "", false, false], [26, 26, 29, 32, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "is", "a", "Fellow", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", ",", "the", "Center", "for", "Advanced", "Study", "in", "the", "Behavioral", "Sciences", "at", "Stanford", "University", ",", "the", "MIT", "Center", "for", "Cognitive", "Science", ",", "the", "Canadian", "Institute", "for", "Advanced", "Research", ",", "the", "Canadian", "Psychological", "Association", ",", "and", "was", "elected", "a", "Fellow", "of", "the", "Royal", "Society", "of", "Canada", "in", "1998", "."], "sentence-detokenized": "He is a Fellow of the American Association for Artificial Intelligence, the Center for Advanced Study in the Behavioral Sciences at Stanford University, the MIT Center for Cognitive Science, the Canadian Institute for Advanced Research, the Canadian Psychological Association, and was elected a Fellow of the Royal Society of Canada in 1998.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 42], [43, 46], [47, 57], [58, 70], [70, 71], [72, 75], [76, 82], [83, 86], [87, 95], [96, 101], [102, 104], [105, 108], [109, 119], [120, 128], [129, 131], [132, 140], [141, 151], [151, 152], [153, 156], [157, 160], [161, 167], [168, 171], [172, 181], [182, 189], [189, 190], [191, 194], [195, 203], [204, 213], [214, 217], [218, 226], [227, 235], [235, 236], [237, 240], [241, 249], [250, 263], [264, 275], [275, 276], [277, 280], [281, 284], [285, 292], [293, 294], [295, 301], [302, 304], [305, 308], [309, 314], [315, 322], [323, 325], [326, 332], [333, 335], [336, 340], [340, 341]]}
{"doc_key": "ai-test-278", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [16, 19, "misc"], [21, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 16, 19, "part-of", "", false, false], [0, 0, 21, 25, "part-of", "", false, false], [4, 5, 16, 19, "part-of", "", false, false], [4, 5, 21, 25, "part-of", "", false, false], [7, 8, 16, 19, "part-of", "", false, false], [7, 8, 21, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", "-", "along", "with", "Yoshua", "Bengio", "and", "Yann", "LeCun", "-", "is", "referred", "to", "by", "some", "as", "the", "godfathers", "of", "AI", "and", "the", "godfathers", "of", "Deep", "Learning", "."], "sentence-detokenized": "Hinton - along with Yoshua Bengio and Yann LeCun - is referred to by some as the godfathers of AI and the godfathers of Deep Learning.", "token2charspan": [[0, 6], [7, 8], [9, 14], [15, 19], [20, 26], [27, 33], [34, 37], [38, 42], [43, 48], [49, 50], [51, 53], [54, 62], [63, 65], [66, 68], [69, 73], [74, 76], [77, 80], [81, 91], [92, 94], [95, 97], [98, 101], [102, 105], [106, 116], [117, 119], [120, 124], [125, 133], [133, 134]]}
{"doc_key": "ai-test-279", "ner": [[6, 6, "product"], [19, 19, "misc"], [21, 33, "misc"], [23, 23, "product"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 19, 19, "related-to", "", false, false], [6, 6, 21, 33, "related-to", "", false, false], [19, 19, 23, 23, "named", "same", false, false], [28, 29, 23, 23, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Lightweight", "open", "-", "source", "speech", "project", "eSpeak", ",", "which", "has", "its", "own", "approach", "to", "synthesis", ",", "has", "experimented", "with", "Mandarin", "and", "Cantonese", ".", "eSpeak", "has", "been", "used", "by", "Google", "Translate", "since", "May", "20102010", "."], "sentence-detokenized": "Lightweight open-source speech project eSpeak, which has its own approach to synthesis, has experimented with Mandarin and Cantonese. eSpeak has been used by Google Translate since May 20102010.", "token2charspan": [[0, 11], [12, 16], [16, 17], [17, 23], [24, 30], [31, 38], [39, 45], [45, 46], [47, 52], [53, 56], [57, 60], [61, 64], [65, 73], [74, 76], [77, 86], [86, 87], [88, 91], [92, 104], [105, 109], [110, 118], [119, 122], [123, 132], [132, 133], [134, 140], [141, 144], [145, 149], [150, 154], [155, 157], [158, 164], [165, 174], [175, 180], [181, 184], [185, 193], [193, 194]]}
{"doc_key": "ai-test-280", "ner": [[5, 7, "product"], [18, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 18, 19, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Also", "released", "in", "1982", ",", "Software", "Automatic", "Mouth", "was", "the", "first", "commercial", ",", "fully", "software", "-", "based", "voice", "synthesis", "programme", "."], "sentence-detokenized": "Also released in 1982, Software Automatic Mouth was the first commercial, fully software-based voice synthesis programme.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 21], [21, 22], [23, 31], [32, 41], [42, 47], [48, 51], [52, 55], [56, 61], [62, 72], [72, 73], [74, 79], [80, 88], [88, 89], [89, 94], [95, 100], [101, 110], [111, 120], [120, 121]]}
{"doc_key": "ai-test-281", "ner": [[4, 6, "metrics"], [8, 8, "metrics"], [11, 11, "metrics"], [13, 13, "metrics"], [16, 23, "metrics"], [29, 31, "metrics"], [37, 43, "metrics"], [46, 48, "metrics"], [50, 50, "metrics"], [53, 53, "metrics"], [55, 55, "metrics"], [59, 65, "metrics"], [71, 73, "metrics"], [75, 75, "metrics"], [78, 85, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[8, 8, 4, 6, "named", "", false, false], [11, 11, 4, 6, "named", "", false, false], [13, 13, 4, 6, "named", "", false, false], [16, 23, 4, 6, "named", "", false, false], [37, 43, 29, 31, "named", "", false, false], [50, 50, 46, 48, "named", "", false, false], [53, 53, 46, 48, "named", "", false, false], [55, 55, 46, 48, "named", "", false, false], [59, 65, 46, 48, "named", "", false, false], [75, 75, 71, 73, "named", "", false, false], [78, 85, 71, 73, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11], "sentence": ["The", "column", "coefficients", "are", "TRUE", "Positive", "Rate", "(", "TPR", ",", "aka", "Sensitivity", "or", "recall", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "with", "a", "complement", "of", "FALSE", "Negative", "Rate", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ";", "and", "TRUE", "Negative", "Rate", "(", "TNR", ",", "aka", "Specificity", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", ",", "with", "a", "complement", "of", "FALSE", "Positive", "Rate", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "The column coefficients are TRUE Positive Rate (TPR, aka Sensitivity or recall) (TP / (TP + FN)), with a complement of FALSE Negative Rate (FNR) (FN / (TP + FN)); and TRUE Negative Rate (TNR, aka Specificity, SPC) (TN / (TN + FP)), with a complement of FALSE Positive Rate (FPR) (FP / (TN + FP)).", "token2charspan": [[0, 3], [4, 10], [11, 23], [24, 27], [28, 32], [33, 41], [42, 46], [47, 48], [48, 51], [51, 52], [53, 56], [57, 68], [69, 71], [72, 78], [78, 79], [80, 81], [81, 83], [84, 85], [86, 87], [87, 89], [90, 91], [92, 94], [94, 95], [95, 96], [96, 97], [98, 102], [103, 104], [105, 115], [116, 118], [119, 124], [125, 133], [134, 138], [139, 140], [140, 143], [143, 144], [145, 146], [146, 148], [149, 150], [151, 152], [152, 154], [155, 156], [157, 159], [159, 160], [160, 161], [161, 162], [163, 166], [167, 171], [172, 180], [181, 185], [186, 187], [187, 190], [190, 191], [192, 195], [196, 207], [207, 208], [209, 212], [212, 213], [214, 215], [215, 217], [218, 219], [220, 221], [221, 223], [224, 225], [226, 228], [228, 229], [229, 230], [230, 231], [232, 236], [237, 238], [239, 249], [250, 252], [253, 258], [259, 267], [268, 272], [273, 274], [274, 277], [277, 278], [279, 280], [280, 282], [283, 284], [285, 286], [286, 288], [289, 290], [291, 293], [293, 294], [294, 295], [295, 296]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 2, "person"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 19, 19, "role", "working_with", false, false], [2, 2, 19, 19, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "and", "Weber", "have", "also", "collaborated", "on", "a", "number", "of", "other", "robots", ",", "and", "their", "experience", "of", "working", "with", "Kismet"], "sentence-detokenized": "Edsinger and Weber have also collaborated on a number of other robots, and their experience of working with Kismet", "token2charspan": [[0, 8], [9, 12], [13, 18], [19, 23], [24, 28], [29, 41], [42, 44], [45, 46], [47, 53], [54, 56], [57, 62], [63, 69], [69, 70], [71, 74], [75, 80], [81, 91], [92, 94], [95, 102], [103, 107], [108, 114]]}
{"doc_key": "ai-test-283", "ner": [[0, 0, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 11, 11, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["R", "functionality", "is", "available", "from", "several", "scripting", "languages", ",", "such", "as", "Python", ",", "are", "also", "available", "."], "sentence-detokenized": "R functionality is available from several scripting languages, such as Python, are also available.", "token2charspan": [[0, 1], [2, 15], [16, 18], [19, 28], [29, 33], [34, 41], [42, 51], [52, 61], [61, 62], [63, 67], [68, 70], [71, 77], [77, 78], [79, 82], [83, 87], [88, 97], [97, 98]]}
{"doc_key": "ai-test-284", "ner": [[0, 0, "programlang"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "was", "one", "of", "the", "first", "robotic", "languages", "and", "was", "used", "in", "Unimate", "robots", "."], "sentence-detokenized": "VAL was one of the first robotic languages and was used in Unimate robots.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 18], [19, 24], [25, 32], [33, 42], [43, 46], [47, 50], [51, 55], [56, 58], [59, 66], [67, 73], [73, 74]]}
{"doc_key": "ai-test-285", "ner": [[13, 20, "conference"], [22, 22, "conference"], [25, 25, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 20, 25, 25, "physical", "", false, false], [22, 22, 13, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["They", "presented", "their", "database", "for", "the", "first", "time", "in", "poster", "form", "at", "the", "2009", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "in", "Florida", "."], "sentence-detokenized": "They presented their database for the first time in poster form at the 2009 Conference on Computer Vision and Pattern Recognition (CVPR) in Florida.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 29], [30, 33], [34, 37], [38, 43], [44, 48], [49, 51], [52, 58], [59, 63], [64, 66], [67, 70], [71, 75], [76, 86], [87, 89], [90, 98], [99, 105], [106, 109], [110, 117], [118, 129], [130, 131], [131, 135], [135, 136], [137, 139], [140, 147], [147, 148]]}
{"doc_key": "ai-test-286", "ner": [[0, 1, "misc"], [12, 13, "task"], [16, 16, "field"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 13, 0, 1, "type-of", "", false, false], [16, 16, 0, 1, "type-of", "", false, false], [18, 19, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Categorisation", "tasks", "in", "which", "labels", "are", "not", "provided", "are", "referred", "to", "as", "unsupervised", "classification", ",", "unsupervised", "learning", ",", "cluster", "analysis", "."], "sentence-detokenized": "Categorisation tasks in which labels are not provided are referred to as unsupervised classification, unsupervised learning, cluster analysis.", "token2charspan": [[0, 14], [15, 20], [21, 23], [24, 29], [30, 36], [37, 40], [41, 44], [45, 53], [54, 57], [58, 66], [67, 69], [70, 72], [73, 85], [86, 100], [100, 101], [102, 114], [115, 123], [123, 124], [125, 132], [133, 141], [141, 142]]}
{"doc_key": "ai-test-287", "ner": [[3, 3, "task"], [12, 12, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Needs", "to", "recognise", "objects", ",", "recognise", "and", "locate", "people", "and", "further", "recognise", "emotions", "."], "sentence-detokenized": "Needs to recognise objects, recognise and locate people and further recognise emotions.", "token2charspan": [[0, 5], [6, 8], [9, 18], [19, 26], [26, 27], [28, 37], [38, 41], [42, 48], [49, 55], [56, 59], [60, 67], [68, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-288", "ner": [[6, 6, "misc"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "process", "is", "complex", "and", "includes", "encoding", "and", "recalling", "or", "downloading", "."], "sentence-detokenized": "The process is complex and includes encoding and recalling or downloading.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 26], [27, 35], [36, 44], [45, 48], [49, 58], [59, 61], [62, 73], [73, 74]]}
{"doc_key": "ai-test-289", "ner": [[7, 8, "product"], [12, 13, "product"], [30, 30, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 12, 13, "named", "", false, false], [7, 8, 30, 30, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Also", "known", "as", "parallel", "robots", "or", "generalised", "Stewart", "platforms", "(", "in", "a", "Stewart", "platform", ",", "actuators", "are", "paired", "on", "both", "the", "base", "and", "the", "platform", ")", ",", "these", "systems", "are", "articulated", "robots", "that", "use", "similar", "mechanisms", "to", "move", "either", "the", "robot", "on", "the", "base", "or", "one", "or", "more", "manipulator", "arms", "."], "sentence-detokenized": "Also known as parallel robots or generalised Stewart platforms (in a Stewart platform, actuators are paired on both the base and the platform), these systems are articulated robots that use similar mechanisms to move either the robot on the base or one or more manipulator arms.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 29], [30, 32], [33, 44], [45, 52], [53, 62], [63, 64], [64, 66], [67, 68], [69, 76], [77, 85], [85, 86], [87, 96], [97, 100], [101, 107], [108, 110], [111, 115], [116, 119], [120, 124], [125, 128], [129, 132], [133, 141], [141, 142], [142, 143], [144, 149], [150, 157], [158, 161], [162, 173], [174, 180], [181, 185], [186, 189], [190, 197], [198, 208], [209, 211], [212, 216], [217, 223], [224, 227], [228, 233], [234, 236], [237, 240], [241, 245], [246, 248], [249, 252], [253, 255], [256, 260], [261, 272], [273, 277], [277, 278]]}
{"doc_key": "ai-test-290", "ner": [[0, 1, "field"], [4, 5, "field"], [12, 20, "field"], [21, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 5, "part-of", "subfield", false, false], [0, 1, 12, 20, "compare", "", false, false], [12, 20, 21, 21, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "vision", "as", "a", "systems", "engineering", "discipline", "can", "be", "considered", "separate", "from", "computer", "vision", ",", "which", "is", "a", "form", "of", "computer", "science", "."], "sentence-detokenized": "Machine vision as a systems engineering discipline can be considered separate from computer vision, which is a form of computer science.", "token2charspan": [[0, 7], [8, 14], [15, 17], [18, 19], [20, 27], [28, 39], [40, 50], [51, 54], [55, 57], [58, 68], [69, 77], [78, 82], [83, 91], [92, 98], [98, 99], [100, 105], [106, 108], [109, 110], [111, 115], [116, 118], [119, 127], [128, 135], [135, 136]]}
{"doc_key": "ai-test-291", "ner": [[4, 5, "algorithm"], [8, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 8, 11, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "activation", "function", "of", "LSTM", "gates", "is", "often", "a", "logistic", "sigmoidal", "function", "."], "sentence-detokenized": "The activation function of LSTM gates is often a logistic sigmoidal function.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 26], [27, 31], [32, 37], [38, 40], [41, 46], [47, 48], [49, 57], [58, 67], [68, 76], [76, 77]]}
{"doc_key": "ai-test-292", "ner": [[4, 6, "metrics"], [19, 21, "metrics"], [23, 23, "metrics"], [32, 34, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 19, 21, "named", "", false, false], [4, 6, 32, 34, "named", "", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "other", "words", ",", "the", "sample", "mean", "is", "the", "(", "necessarily", "only", ")", "efficient", "estimator", "and", "therefore", "also", "the", "minimum", "variance", "unbiased", "(", "MVUE", ")", "estimator", ",", "in", "addition", "to", "being", "the", "maximum", "likelihood", "estimator", "."], "sentence-detokenized": "In other words, the sample mean is the (necessarily only) efficient estimator and therefore also the minimum variance unbiased (MVUE) estimator, in addition to being the maximum likelihood estimator.", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 19], [20, 26], [27, 31], [32, 34], [35, 38], [39, 40], [40, 51], [52, 56], [56, 57], [58, 67], [68, 77], [78, 81], [82, 91], [92, 96], [97, 100], [101, 108], [109, 117], [118, 126], [127, 128], [128, 132], [132, 133], [134, 143], [143, 144], [145, 147], [148, 156], [157, 159], [160, 165], [166, 169], [170, 177], [178, 188], [189, 198], [198, 199]]}
{"doc_key": "ai-test-293", "ner": [[3, 4, "academicjournal"], [7, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [23, 23, "product"], [26, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 23, 23, "topic", "", false, false], [3, 4, 26, 27, "topic", "", false, false], [7, 9, 3, 4, "role", "", false, false], [11, 12, 3, 4, "role", "", false, false], [14, 15, 3, 4, "role", "", false, false], [23, 23, 26, 27, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "a", "2001", "Scientific", "American", "article", ",", "Berners", "-", "Lee", ",", "James", "Hendler", "and", "Ora", "Lassila", "described", "the", "expected", "evolution", "of", "the", "existing", "Web", "towards", "the", "Semantic", "Web", "."], "sentence-detokenized": "In a 2001 Scientific American article, Berners-Lee, James Hendler and Ora Lassila described the expected evolution of the existing Web towards the Semantic Web.", "token2charspan": [[0, 2], [3, 4], [5, 9], [10, 20], [21, 29], [30, 37], [37, 38], [39, 46], [46, 47], [47, 50], [50, 51], [52, 57], [58, 65], [66, 69], [70, 73], [74, 81], [82, 91], [92, 95], [96, 104], [105, 114], [115, 117], [118, 121], [122, 130], [131, 134], [135, 142], [143, 146], [147, 155], [156, 159], [159, 160]]}
{"doc_key": "ai-test-294", "ner": [[12, 14, "misc"], [16, 17, "person"], [19, 19, "person"], [29, 31, "person"], [41, 41, "person"], [47, 48, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[16, 17, 12, 14, "role", "actor_in_work", false, false], [19, 19, 16, 17, "named", "", false, false], [19, 19, 16, 17, "origin", "", false, false], [29, 31, 19, 19, "part-of", "", false, false], [47, 48, 19, 19, "role", "auditioned_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["A", "number", "of", "lesser", "-", "known", "actors", "of", "the", "time", "were", "used", "in", "Blade", "Runner", ":", "Sean", "Young", "portrays", "Rachael", ",", "an", "experimental", "replicant", "implanted", "with", "the", "memories", "of", "Tyrell", "'s", "niece", ",", "causing", "her", "to", "believe", "she", "is", "human", ";", "Sammon", ",", "pp.", "92", "-", "93", "Nina", "Axelrod", "auditioned", "for", "the", "role", "."], "sentence-detokenized": "A number of lesser-known actors of the time were used in Blade Runner: Sean Young portrays Rachael, an experimental replicant implanted with the memories of Tyrell's niece, causing her to believe she is human; Sammon, pp. 92-93 Nina Axelrod auditioned for the role.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 18], [18, 19], [19, 24], [25, 31], [32, 34], [35, 38], [39, 43], [44, 48], [49, 53], [54, 56], [57, 62], [63, 69], [69, 70], [71, 75], [76, 81], [82, 90], [91, 98], [98, 99], [100, 102], [103, 115], [116, 125], [126, 135], [136, 140], [141, 144], [145, 153], [154, 156], [157, 163], [163, 165], [166, 171], [171, 172], [173, 180], [181, 184], [185, 187], [188, 195], [196, 199], [200, 202], [203, 208], [208, 209], [210, 216], [216, 217], [218, 221], [222, 224], [224, 225], [225, 227], [228, 232], [233, 240], [241, 251], [252, 255], [256, 259], [260, 264], [264, 265]]}
{"doc_key": "ai-test-295", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [13, 16, "university"], [23, 25, "product"], [27, 27, "product"], [43, 43, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 13, 16, "physical", "", false, false], [3, 4, 13, 16, "physical", "", false, false], [6, 7, 13, 16, "physical", "", false, false], [9, 10, 13, 16, "physical", "", false, false], [13, 16, 43, 43, "physical", "", true, false], [23, 25, 13, 16, "temporal", "", false, false], [27, 27, 13, 16, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Gerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "and", "Terry", "Winograd", "visited", "the", "University", "of", "Edinburgh", "in", "1971", ",", "spreading", "the", "word", "about", "Micro", "-", "Planner", "and", "SHRDLU", "and", "casting", "doubt", "on", "the", "Resolution", "Uniform", "Proof", "Procedure", "approach", "that", "was", "the", "mainstay", "of", "Edinburgh", "logicians", "."], "sentence-detokenized": "Gerry Sussman, Eugene Charniak, Seymour Papert and Terry Winograd visited the University of Edinburgh in 1971, spreading the word about Micro-Planner and SHRDLU and casting doubt on the Resolution Uniform Proof Procedure approach that was the mainstay of Edinburgh logicians.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 21], [22, 30], [30, 31], [32, 39], [40, 46], [47, 50], [51, 56], [57, 65], [66, 73], [74, 77], [78, 88], [89, 91], [92, 101], [102, 104], [105, 109], [109, 110], [111, 120], [121, 124], [125, 129], [130, 135], [136, 141], [141, 142], [142, 149], [150, 153], [154, 160], [161, 164], [165, 172], [173, 178], [179, 181], [182, 185], [186, 196], [197, 204], [205, 210], [211, 220], [221, 229], [230, 234], [235, 238], [239, 242], [243, 251], [252, 254], [255, 264], [265, 274], [274, 275]]}
{"doc_key": "ai-test-296", "ner": [[0, 0, "researcher"], [7, 7, "field"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 11, 12, "role", "inspires", false, false], [0, 0, 14, 15, "role", "inspires", false, false], [0, 0, 17, 18, "role", "inspires", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Walter", "'s", "work", "has", "inspired", "generations", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "Walter's work has inspired generations of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 6], [6, 8], [9, 13], [14, 17], [18, 26], [27, 38], [39, 41], [42, 50], [51, 62], [63, 67], [68, 70], [71, 77], [78, 84], [84, 85], [86, 90], [91, 98], [99, 102], [103, 107], [108, 114], [114, 115]]}
{"doc_key": "ai-test-297", "ner": [[6, 6, "algorithm"], [8, 9, "researcher"], [15, 21, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 8, 9, "origin", "", false, false], [6, 6, 15, 21, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Then", "a", "similar", "GPU", "-", "based", "CNN", "by", "Alex", "Krizhevsky", "et", "al", ".", "won", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "2012", "."], "sentence-detokenized": "Then a similar GPU-based CNN by Alex Krizhevsky et al. won the ImageNet Large Scale Visual Recognition Challenge 2012.", "token2charspan": [[0, 4], [5, 6], [7, 14], [15, 18], [18, 19], [19, 24], [25, 28], [29, 31], [32, 36], [37, 47], [48, 50], [51, 53], [53, 54], [55, 58], [59, 62], [63, 71], [72, 77], [78, 83], [84, 90], [91, 102], [103, 112], [113, 117], [117, 118]]}
{"doc_key": "ai-test-298", "ner": [[2, 3, "misc"], [8, 10, "metrics"], [12, 13, "metrics"], [17, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 10, 2, 3, "type-of", "", false, false], [12, 13, 2, 3, "type-of", "", false, false], [12, 13, 17, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Commonly", "used", "loss", "functions", "for", "probabilistic", "classification", "include", "log", "-", "loss", "and", "Brier", "score", "between", "predicted", "and", "TRUE", "probability", "distributions", "."], "sentence-detokenized": "Commonly used loss functions for probabilistic classification include log-loss and Brier score between predicted and TRUE probability distributions.", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 28], [29, 32], [33, 46], [47, 61], [62, 69], [70, 73], [73, 74], [74, 78], [79, 82], [83, 88], [89, 94], [95, 102], [103, 112], [113, 116], [117, 121], [122, 133], [134, 147], [147, 148]]}
{"doc_key": "ai-test-299", "ner": [[4, 4, "organisation"], [11, 11, "field"], [14, 14, "organisation"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 11, 11, "general-affiliation", "field_of_study", false, false], [4, 4, 17, 18, "part-of", "", false, false], [14, 14, 4, 4, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "May", "2016", ",", "NtechLab", "was", "approved", "for", "official", "testing", "of", "biometric", "technology", "by", "NIST", "among", "three", "Russian", "companies", "."], "sentence-detokenized": "In May 2016, NtechLab was approved for official testing of biometric technology by NIST among three Russian companies.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [13, 21], [22, 25], [26, 34], [35, 38], [39, 47], [48, 55], [56, 58], [59, 68], [69, 79], [80, 82], [83, 87], [88, 93], [94, 99], [100, 107], [108, 117], [117, 118]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "floating", "-", "point", "numbers", "only", "have", "a", "certain", "mathematical", "precision", "."], "sentence-detokenized": "However, floating-point numbers only have a certain mathematical precision.", "token2charspan": [[0, 7], [7, 8], [9, 17], [17, 18], [18, 23], [24, 31], [32, 36], [37, 41], [42, 43], [44, 51], [52, 64], [65, 74], [74, 75]]}
{"doc_key": "ai-test-301", "ner": [[6, 6, "organisation"], [12, 20, "conference"], [18, 18, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 12, 20, "role", "contributes_to", false, false], [18, 18, 12, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "2015", ",", "a", "number", "of", "SenseTime", "papers", "were", "accepted", "for", "the", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "Conference", "."], "sentence-detokenized": "During 2015, a number of SenseTime papers were accepted for the Computer Vision and Pattern Recognition (CVPR) Conference.", "token2charspan": [[0, 6], [7, 11], [11, 12], [13, 14], [15, 21], [22, 24], [25, 34], [35, 41], [42, 46], [47, 55], [56, 59], [60, 63], [64, 72], [73, 79], [80, 83], [84, 91], [92, 103], [104, 105], [105, 109], [109, 110], [111, 121], [121, 122]]}
{"doc_key": "ai-test-302", "ner": [[5, 7, "task"], [9, 9, "task"], [12, 13, "task"], [15, 18, "task"], [21, 21, "field"], [23, 25, "misc"], [28, 34, "conference"], [42, 44, "misc"], [46, 47, "conference"], [63, 65, "misc"], [67, 67, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[5, 7, 21, 21, "part-of", "task_part_of_field", false, false], [9, 9, 5, 7, "named", "", false, false], [12, 13, 21, 21, "part-of", "task_part_of_field", false, false], [15, 18, 12, 13, "named", "", false, false], [23, 25, 28, 34, "temporal", "", false, false], [42, 44, 46, 47, "temporal", "", false, false], [63, 65, 67, 67, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["He", "co-developed", "optimal", "algorithms", "for", "Structure", "From", "Motion", "(", "SFM", ",", "or", "Visual", "SLAM", ",", "simultaneous", "localisation", "and", "mapping", ",", "in", "Robotics", ";", "Best", "Paper", "Award", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "1998", ")", ",", "characterised", "its", "ambiguities", "(", "David", "Marr", "Prize", "at", "ICCV", "1999", ")", ",", "and", "characterised", "the", "identifiability", "and", "observability", "of", "visual", "-", "inertial", "sensor", "fusion", "(", "Best", "Paper", "Award", "at", "Robotics", "2015", ")", "."], "sentence-detokenized": "He co-developed optimal algorithms for Structure From Motion (SFM, or Visual SLAM, simultaneous localisation and mapping, in Robotics; Best Paper Award at the Conference on Computer Vision and Pattern Recognition 1998), characterised its ambiguities (David Marr Prize at ICCV 1999), and characterised the identifiability and observability of visual-inertial sensor fusion (Best Paper Award at Robotics 2015).", "token2charspan": [[0, 2], [3, 15], [16, 23], [24, 34], [35, 38], [39, 48], [49, 53], [54, 60], [61, 62], [62, 65], [65, 66], [67, 69], [70, 76], [77, 81], [81, 82], [83, 95], [96, 108], [109, 112], [113, 120], [120, 121], [122, 124], [125, 133], [133, 134], [135, 139], [140, 145], [146, 151], [152, 154], [155, 158], [159, 169], [170, 172], [173, 181], [182, 188], [189, 192], [193, 200], [201, 212], [213, 217], [217, 218], [218, 219], [220, 233], [234, 237], [238, 249], [250, 251], [251, 256], [257, 261], [262, 267], [268, 270], [271, 275], [276, 280], [280, 281], [281, 282], [283, 286], [287, 300], [301, 304], [305, 320], [321, 324], [325, 338], [339, 341], [342, 348], [348, 349], [349, 357], [358, 364], [365, 371], [372, 373], [373, 377], [378, 383], [384, 389], [390, 392], [393, 401], [402, 406], [406, 407], [407, 408]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 44], [45, 48], [49, 52], [53, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-304", "ner": [[0, 1, "task"], [7, 8, "field"], [10, 14, "field"], [13, 13, "field"], [21, 22, "task"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 7, 8, "part-of", "task_part_of_field", false, false], [0, 1, 10, 14, "part-of", "task_part_of_field", false, false], [0, 1, 13, 13, "part-of", "task_part_of_field", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 24, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Edge", "detection", "is", "an", "essential", "tool", "in", "image", "processing", ",", "machine", "vision", "and", "computer", "vision", ",", "especially", "in", "the", "areas", "of", "feature", "detection", "and", "feature", "extraction", "."], "sentence-detokenized": "Edge detection is an essential tool in image processing, machine vision and computer vision, especially in the areas of feature detection and feature extraction.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 20], [21, 30], [31, 35], [36, 38], [39, 44], [45, 55], [55, 56], [57, 64], [65, 71], [72, 75], [76, 84], [85, 91], [91, 92], [93, 103], [104, 106], [107, 110], [111, 116], [117, 119], [120, 127], [128, 137], [138, 141], [142, 149], [150, 160], [160, 161]]}
{"doc_key": "ai-test-305", "ner": [[9, 10, "misc"], [27, 32, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "example", "would", "be", "a", "variable", "such", "as", "the", "external", "temperature", "(", "mathtemp", "/", "math", ")", ",", "which", "in", "a", "given", "application", "can", "be", "recorded", "to", "several", "decimal", "places", "(", "depending", "on", "the", "measuring", "apparatus", ")", "."], "sentence-detokenized": "An example would be a variable such as the external temperature (mathtemp / math), which in a given application can be recorded to several decimal places (depending on the measuring apparatus).", "token2charspan": [[0, 2], [3, 10], [11, 16], [17, 19], [20, 21], [22, 30], [31, 35], [36, 38], [39, 42], [43, 51], [52, 63], [64, 65], [65, 73], [74, 75], [76, 80], [80, 81], [81, 82], [83, 88], [89, 91], [92, 93], [94, 99], [100, 111], [112, 115], [116, 118], [119, 127], [128, 130], [131, 138], [139, 146], [147, 153], [154, 155], [155, 164], [165, 167], [168, 171], [172, 181], [182, 191], [191, 192], [192, 193]]}
{"doc_key": "ai-test-306", "ner": [[3, 4, "person"], [6, 7, "person"], [9, 13, "person"], [17, 18, "person"], [20, 20, "misc"], [24, 24, "misc"], [26, 27, "person"], [29, 29, "organisation"], [31, 32, "person"], [34, 34, "organisation"], [36, 37, "person"], [40, 40, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[26, 27, 20, 20, "part-of", "", false, false], [26, 27, 24, 24, "role", "", false, false], [31, 32, 29, 29, "role", "", false, false], [36, 37, 34, 34, "role", "youtuber", false, false], [40, 40, 36, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Returning", "judges", "are", "Fon", "Davis", ",", "Jessica", "Chobot", "and", "Leland", "Melvin", ",", "as", "well", "as", "guest", "actors", "Clark", "Gregg", ",", "MythBusters", "host", "and", "former", "Battlebots", "builder", "Adam", "Savage", ",", "NFL", "player", "Vernon", "Davis", "and", "YouTube", "star", "Michael", "Stevens", "a.k.a", ".", "Vsauce", "."], "sentence-detokenized": "Returning judges are Fon Davis, Jessica Chobot and Leland Melvin, as well as guest actors Clark Gregg, MythBusters host and former Battlebots builder Adam Savage, NFL player Vernon Davis and YouTube star Michael Stevens a.k.a. Vsauce.", "token2charspan": [[0, 9], [10, 16], [17, 20], [21, 24], [25, 30], [30, 31], [32, 39], [40, 46], [47, 50], [51, 57], [58, 64], [64, 65], [66, 68], [69, 73], [74, 76], [77, 82], [83, 89], [90, 95], [96, 101], [101, 102], [103, 114], [115, 119], [120, 123], [124, 130], [131, 141], [142, 149], [150, 154], [155, 161], [161, 162], [163, 166], [167, 173], [174, 180], [181, 186], [187, 190], [191, 198], [199, 203], [204, 211], [212, 219], [220, 225], [225, 226], [227, 233], [233, 234]]}
{"doc_key": "ai-test-307", "ner": [[15, 16, "algorithm"], [17, 21, "algorithm"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 16, 23, 25, "part-of", "", false, false], [17, 21, 23, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "these", "methods", "have", "never", "won", "out", "over", "the", "technology", "of", "the", "non-uniform", "inner", "Gaussian", "mixture", "model", "/", "hidden", "Markov", "model", "(", "GMM", "-", "HMM", ")", "based", "on", "generative", "discriminatively", "trained", "speech", "models", "."], "sentence-detokenized": "However, these methods have never won out over the technology of the non-uniform inner Gaussian mixture model/hidden Markov model (GMM-HMM) based on generative discriminatively trained speech models.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 22], [23, 27], [28, 33], [34, 37], [38, 41], [42, 46], [47, 50], [51, 61], [62, 64], [65, 68], [69, 80], [81, 86], [87, 95], [96, 103], [104, 109], [109, 110], [110, 116], [117, 123], [124, 129], [130, 131], [131, 134], [134, 135], [135, 138], [138, 139], [140, 145], [146, 148], [149, 159], [160, 176], [177, 184], [185, 191], [192, 198], [198, 199]]}
{"doc_key": "ai-test-308", "ner": [[4, 4, "product"], [6, 7, "programlang"], [9, 9, "programlang"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Software", "packages", "such", "as", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", "and", "SciPy", "provide", "convenient", "ways", "to", "apply", "these", "different", "methods", "."], "sentence-detokenized": "Software packages such as MATLAB, GNU Octave, Scilab and SciPy provide convenient ways to apply these different methods.", "token2charspan": [[0, 8], [9, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 37], [38, 44], [44, 45], [46, 52], [53, 56], [57, 62], [63, 70], [71, 81], [82, 86], [87, 89], [90, 95], [96, 101], [102, 111], [112, 119], [119, 120]]}
{"doc_key": "ai-test-309", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [8, 9, "task"], [16, 17, "researcher"], [19, 20, "university"], [22, 23, "researcher"], [25, 28, "organisation"], [30, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 8, 9, "related-to", "", false, false], [0, 2, 16, 17, "origin", "", false, false], [0, 2, 22, 23, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [16, 17, 19, 20, "physical", "", false, false], [16, 17, 19, 20, "role", "", false, false], [22, 23, 25, 28, "physical", "", false, false], [22, 23, 25, 28, "role", "", false, false], [30, 30, 25, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", ",", "a", "speech", "processing", "algorithm", ",", "was", "first", "proposed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", "."], "sentence-detokenized": "Linear predictive coding (LPC), a speech processing algorithm, was first proposed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [30, 31], [32, 33], [34, 40], [41, 51], [52, 61], [61, 62], [63, 66], [67, 72], [73, 81], [82, 84], [85, 93], [94, 101], [102, 104], [105, 111], [112, 122], [123, 126], [127, 132], [133, 138], [139, 141], [142, 148], [149, 158], [159, 162], [163, 172], [173, 174], [174, 177], [177, 178], [179, 181], [182, 186], [186, 187]]}
{"doc_key": "ai-test-310", "ner": [[20, 27, "conference"], [29, 29, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[29, 29, 20, 27, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2006", ",", "on", "the", "occasion", "of", "the", "25th", "anniversary", "of", "the", "algorithm", ",", "a", "workshop", "was", "organised", "at", "the", "International", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", ",", "summarising", "the", "latest", "contributions", "and", "variations", "on", "the", "original", "algorithm", ",", "mainly", "aimed", "at", "improving", "the", "speed", "of", "the", "algorithm", ",", "the", "robustness", "and", "accuracy", "of", "the", "estimated", "solution", "and", "reducing", "the", "dependence", "on", "user", "-", "defined", "constants", "."], "sentence-detokenized": "In 2006, on the occasion of the 25th anniversary of the algorithm, a workshop was organised at the International Conference on Computer Vision and Pattern Recognition (CVPR), summarising the latest contributions and variations on the original algorithm, mainly aimed at improving the speed of the algorithm, the robustness and accuracy of the estimated solution and reducing the dependence on user-defined constants.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 24], [25, 27], [28, 31], [32, 36], [37, 48], [49, 51], [52, 55], [56, 65], [65, 66], [67, 68], [69, 77], [78, 81], [82, 91], [92, 94], [95, 98], [99, 112], [113, 123], [124, 126], [127, 135], [136, 142], [143, 146], [147, 154], [155, 166], [167, 168], [168, 172], [172, 173], [173, 174], [175, 186], [187, 190], [191, 197], [198, 211], [212, 215], [216, 226], [227, 229], [230, 233], [234, 242], [243, 252], [252, 253], [254, 260], [261, 266], [267, 269], [270, 279], [280, 283], [284, 289], [290, 292], [293, 296], [297, 306], [306, 307], [308, 311], [312, 322], [323, 326], [327, 335], [336, 338], [339, 342], [343, 352], [353, 361], [362, 365], [366, 374], [375, 378], [379, 389], [390, 392], [393, 397], [397, 398], [398, 405], [406, 415], [415, 416]]}
{"doc_key": "ai-test-311", "ner": [[4, 7, "university"], [9, 13, "organisation"], [15, 17, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Members", "have", "travelled", "to", "the", "University", "of", "Debrecen", ",", "the", "Hungarian", "Academy", "of", "Sciences", ",", "E\u00f6tv\u00f6s", "Lor\u00e1nd", "University", ",", "etc", "."], "sentence-detokenized": "Members have travelled to the University of Debrecen, the Hungarian Academy of Sciences, E\u00f6tv\u00f6s Lor\u00e1nd University, etc.", "token2charspan": [[0, 7], [8, 12], [13, 22], [23, 25], [26, 29], [30, 40], [41, 43], [44, 52], [52, 53], [54, 57], [58, 67], [68, 75], [76, 78], [79, 87], [87, 88], [89, 95], [96, 102], [103, 113], [113, 114], [115, 118], [118, 119]]}
{"doc_key": "ai-test-312", "ner": [[3, 4, "algorithm"], [16, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 16, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "extend", "the", "SVM", "to", "cases", "where", "the", "data", "are", "not", "linearly", "separable", ",", "we", "introduce", "a", "loss", "function", ","], "sentence-detokenized": "To extend the SVM to cases where the data are not linearly separable, we introduce a loss function,", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 17], [18, 20], [21, 26], [27, 32], [33, 36], [37, 41], [42, 45], [46, 49], [50, 58], [59, 68], [68, 69], [70, 72], [73, 82], [83, 84], [85, 89], [90, 98], [98, 99]]}
{"doc_key": "ai-test-313", "ner": [[0, 0, "programlang"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 10, 11, "origin", "", false, false], [0, 0, 13, 14, "origin", "", false, false], [0, 0, 16, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Logo", "is", "an", "educational", "programming", "language", "designed", "in", "1967", "by", "Wally", "Feurzeig", ",", "Seymour", "Papert", "and", "Cynthia", "Solomon", "."], "sentence-detokenized": "Logo is an educational programming language designed in 1967 by Wally Feurzeig, Seymour Papert and Cynthia Solomon.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 34], [35, 43], [44, 52], [53, 55], [56, 60], [61, 63], [64, 69], [70, 78], [78, 79], [80, 87], [88, 94], [95, 98], [99, 106], [107, 114], [114, 115]]}
{"doc_key": "ai-test-314", "ner": [[0, 3, "organisation"], [7, 12, "organisation"], [14, 17, "location"], [19, 19, "location"], [21, 22, "location"], [29, 32, "product"], [42, 45, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 7, 12, "role", "works_for", false, false], [7, 12, 14, 17, "physical", "", false, false], [14, 17, 19, 19, "physical", "", false, false], [19, 19, 21, 22, "physical", "", false, false], [29, 32, 0, 3, "origin", "", false, false], [42, 45, 29, 32, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "Eyring", "Research", "Institute", "was", "instrumental", "for", "the", "U.S.", "Air", "Force", "Missile", "Directorate", "at", "Hill", "Air", "Force", "Base", "near", "Ogden", ",", "Utah", "to", "produce", "in", "top", "military", "secret", ",", "Intelligent", "Systems", "Technology", "Software", ",", "which", "was", "the", "basis", "for", "the", "later", "named", "Reagan", "Star", "Wars", "programme", "."], "sentence-detokenized": "The Eyring Research Institute was instrumental for the U.S. Air Force Missile Directorate at Hill Air Force Base near Ogden, Utah to produce in top military secret, Intelligent Systems Technology Software, which was the basis for the later named Reagan Star Wars programme.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 29], [30, 33], [34, 46], [47, 50], [51, 54], [55, 59], [60, 63], [64, 69], [70, 77], [78, 89], [90, 92], [93, 97], [98, 101], [102, 107], [108, 112], [113, 117], [118, 123], [123, 124], [125, 129], [130, 132], [133, 140], [141, 143], [144, 147], [148, 156], [157, 163], [163, 164], [165, 176], [177, 184], [185, 195], [196, 204], [204, 205], [206, 211], [212, 215], [216, 219], [220, 225], [226, 229], [230, 233], [234, 239], [240, 245], [246, 252], [253, 257], [258, 262], [263, 272], [272, 273]]}
{"doc_key": "ai-test-315", "ner": [[12, 13, "field"], [22, 25, "researcher"], [27, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "decades", ",", "he", "has", "researched", "and", "developed", "the", "emerging", "fields", "of", "computer", "science", "from", "compiler", ",", "programming", "languages", "and", "systems", "architecture", "John", "F", ".", "Sowa", "and", "John", "Zachman", "(", "1992", ")", "."], "sentence-detokenized": "For decades, he has researched and developed the emerging fields of computer science from compiler, programming languages and systems architecture John F. Sowa and John Zachman (1992).", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 19], [20, 30], [31, 34], [35, 44], [45, 48], [49, 57], [58, 64], [65, 67], [68, 76], [77, 84], [85, 89], [90, 98], [98, 99], [100, 111], [112, 121], [122, 125], [126, 133], [134, 146], [147, 151], [152, 153], [153, 154], [155, 159], [160, 163], [164, 168], [169, 176], [177, 178], [178, 182], [182, 183], [183, 184]]}
{"doc_key": "ai-test-316", "ner": [[0, 12, "algorithm"], [9, 11, "algorithm"], [14, 15, "algorithm"], [20, 21, "field"], [23, 24, "field"], [29, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 11, 0, 12, "named", "", false, false], [14, 15, 0, 12, "named", "", false, false], [20, 21, 0, 12, "usage", "", false, false], [23, 24, 0, 12, "usage", "", false, false], [29, 30, 0, 12, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Sobel", "operator", ",", "sometimes", "referred", "to", "as", "the", "Sobel", "-", "Feldman", "operator", "or", "Sobel", "filter", ",", "is", "used", "in", "image", "processing", "and", "computer", "vision", ",", "particularly", "within", "edge", "detection", "algorithms", ",", "where", "it", "creates", "an", "image", "that", "highlights", "edges", "."], "sentence-detokenized": "The Sobel operator, sometimes referred to as the Sobel-Feldman operator or Sobel filter, is used in image processing and computer vision, particularly within edge detection algorithms, where it creates an image that highlights edges.", "token2charspan": [[0, 3], [4, 9], [10, 18], [18, 19], [20, 29], [30, 38], [39, 41], [42, 44], [45, 48], [49, 54], [54, 55], [55, 62], [63, 71], [72, 74], [75, 80], [81, 87], [87, 88], [89, 91], [92, 96], [97, 99], [100, 105], [106, 116], [117, 120], [121, 129], [130, 136], [136, 137], [138, 150], [151, 157], [158, 162], [163, 172], [173, 183], [183, 184], [185, 190], [191, 193], [194, 201], [202, 204], [205, 210], [211, 215], [216, 226], [227, 232], [232, 233]]}
{"doc_key": "ai-test-317", "ner": [[0, 0, "algorithm"], [3, 4, "field"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 3, 4, "compare", "", false, false], [0, 0, 3, 4, "type-of", "", false, false], [0, 0, 12, 12, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["LDA", "is", "a", "supervised", "learning", "algorithm", "that", "uses", "data", "labels", ",", "while", "PCA", "is", "a", "learning", "algorithm", "that", "ignores", "labels", "."], "sentence-detokenized": "LDA is a supervised learning algorithm that uses data labels, while PCA is a learning algorithm that ignores labels.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 19], [20, 28], [29, 38], [39, 43], [44, 48], [49, 53], [54, 60], [60, 61], [62, 67], [68, 71], [72, 74], [75, 76], [77, 85], [86, 95], [96, 100], [101, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-test-318", "ner": [[5, 5, "algorithm"], [7, 9, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "linear", "classification", "algorithms", "include", "Winnow", ",", "support", "vector", "machine", "and", "logistic", "regression", "."], "sentence-detokenized": "Other linear classification algorithms include Winnow, support vector machine and logistic regression.", "token2charspan": [[0, 5], [6, 12], [13, 27], [28, 38], [39, 46], [47, 53], [53, 54], [55, 62], [63, 69], [70, 77], [78, 81], [82, 90], [91, 101], [101, 102]]}
{"doc_key": "ai-test-319", "ner": [[0, 0, "product"], [4, 6, "programlang"], [16, 18, "product"], [20, 20, "programlang"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 4, 6, "general-affiliation", "", true, false], [0, 0, 16, 18, "general-affiliation", "", true, false], [0, 0, 20, 20, "general-affiliation", "", true, false], [0, 0, 22, 22, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["VTK", "consists", "of", "a", "C", "+", "+", "class", "library", "and", "several", "interpreted", "interface", "layers", ",", "including", "Tcl", "/", "Tk", ",", "Java", "and", "Python", "."], "sentence-detokenized": "VTK consists of a C + + class library and several interpreted interface layers, including Tcl / Tk, Java and Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 17], [18, 19], [20, 21], [22, 23], [24, 29], [30, 37], [38, 41], [42, 49], [50, 61], [62, 71], [72, 78], [78, 79], [80, 89], [90, 93], [94, 95], [96, 98], [98, 99], [100, 104], [105, 108], [109, 115], [115, 116]]}
{"doc_key": "ai-test-320", "ner": [[9, 11, "task"], [18, 20, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Also", ",", "text", "produced", "by", "processing", "spontaneous", "speech", "with", "automatic", "speech", "recognition", "and", "printed", "or", "handwritten", "text", "with", "optical", "character", "recognition", "contains", "processing", "noise", "."], "sentence-detokenized": "Also, text produced by processing spontaneous speech with automatic speech recognition and printed or handwritten text with optical character recognition contains processing noise.", "token2charspan": [[0, 4], [4, 5], [6, 10], [11, 19], [20, 22], [23, 33], [34, 45], [46, 52], [53, 57], [58, 67], [68, 74], [75, 86], [87, 90], [91, 98], [99, 101], [102, 113], [114, 118], [119, 123], [124, 131], [132, 141], [142, 153], [154, 162], [163, 173], [174, 179], [179, 180]]}
{"doc_key": "ai-test-321", "ner": [[0, 0, "researcher"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 10, 10, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "has", "written", "several", "books", "and", "led", "the", "development", "of", "WordNet", ",", "an", "online", "database", "of", "word", "relationships", "that", "can", "be", "used", "in", "computer", "programmes", "."], "sentence-detokenized": "Miller has written several books and led the development of WordNet, an online database of word relationships that can be used in computer programmes.", "token2charspan": [[0, 6], [7, 10], [11, 18], [19, 26], [27, 32], [33, 36], [37, 40], [41, 44], [45, 56], [57, 59], [60, 67], [67, 68], [69, 71], [72, 78], [79, 87], [88, 90], [91, 95], [96, 109], [110, 114], [115, 118], [119, 121], [122, 126], [127, 129], [130, 138], [139, 149], [149, 150]]}
{"doc_key": "ai-test-322", "ner": [[1, 1, "field"], [7, 9, "organisation"], [12, 12, "country"], [14, 15, "person"], [17, 19, "person"], [21, 22, "person"], [24, 25, "person"], [28, 28, "country"], [30, 34, "location"], [35, 36, "misc"], [37, 38, "person"], [40, 41, "person"], [43, 43, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[7, 9, 12, 12, "physical", "", false, false], [14, 15, 28, 28, "physical", "", false, false], [17, 19, 28, 28, "physical", "", false, false], [21, 22, 28, 28, "physical", "", false, false], [24, 25, 28, 28, "physical", "", false, false], [30, 34, 1, 1, "general-affiliation", "", false, false], [30, 34, 37, 38, "artifact", "", false, false], [35, 36, 37, 38, "named", "", false, false], [40, 41, 43, 43, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Contemporary", "automatons", "are", "represented", "by", "works", "by", "Cabaret", "Mechanical", "Theatre", "in", "the", "UK", ",", "Dug", "North", "and", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", ",", "Joe", "Jones", "in", "the", "US", ",", "Le", "D\u00e9fenseur", "du", "Temps", "by", "French", "artist", "Jacques", "Monestier", "and", "Fran\u00e7ois", "Junod", "in", "Switzerland", "."], "sentence-detokenized": "Contemporary automatons are represented by works by Cabaret Mechanical Theatre in the UK, Dug North and Chomick + Meder, Arthur Ganson, Joe Jones in the US, Le D\u00e9fenseur du Temps by French artist Jacques Monestier and Fran\u00e7ois Junod in Switzerland.", "token2charspan": [[0, 12], [13, 23], [24, 27], [28, 39], [40, 42], [43, 48], [49, 51], [52, 59], [60, 70], [71, 78], [79, 81], [82, 85], [86, 88], [88, 89], [90, 93], [94, 99], [100, 103], [104, 111], [112, 113], [114, 119], [119, 120], [121, 127], [128, 134], [134, 135], [136, 139], [140, 145], [146, 148], [149, 152], [153, 155], [155, 156], [157, 159], [160, 169], [170, 172], [173, 178], [179, 181], [182, 188], [189, 195], [196, 203], [204, 213], [214, 217], [218, 226], [227, 232], [233, 235], [236, 247], [247, 248]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 21, 21, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "includes", "standard", "codefor", "/", "code", "and", "codewhile", "/", "code", "loops", ",", "but", "(", "as", "in", "other", "similar", "applications", "such", "as", "R", ")", ",", "the", "use", "of", "vector", "notation", "is", "encouraged", "and", "is", "often", "faster", "to", "execute", "."], "sentence-detokenized": "MATLAB includes standard codefor/code and codewhile/code loops, but (as in other similar applications such as R), the use of vector notation is encouraged and is often faster to execute.", "token2charspan": [[0, 6], [7, 15], [16, 24], [25, 32], [32, 33], [33, 37], [38, 41], [42, 51], [51, 52], [52, 56], [57, 62], [62, 63], [64, 67], [68, 69], [69, 71], [72, 74], [75, 80], [81, 88], [89, 101], [102, 106], [107, 109], [110, 111], [111, 112], [112, 113], [114, 117], [118, 121], [122, 124], [125, 131], [132, 140], [141, 143], [144, 154], [155, 158], [159, 161], [162, 167], [168, 174], [175, 177], [178, 185], [185, 186]]}
{"doc_key": "ai-test-324", "ner": [[3, 3, "researcher"], [9, 13, "conference"], [17, 19, "field"], [21, 27, "misc"], [29, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 21, 27, "win-defeat", "", false, false], [3, 3, 29, 39, "win-defeat", "", false, false], [21, 27, 9, 13, "temporal", "", false, false], [21, 27, 17, 19, "topic", "", false, false], [29, 39, 9, 13, "temporal", "", false, false], [29, 39, 17, 19, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2007", ",", "Pausch", "received", "two", "awards", "from", "the", "Association", "for", "Computing", "Machinery", "for", "his", "achievements", "in", "computer", "science", "education", ":", "Karl", "V", ".", "Karlstrom", "Outstanding", "Educator", "Award", "and", "the", "ACM", "SIGCSE", "Award", "for", "Outstanding", "Contributions", "to", "Computer", "Science", "Education", "."], "sentence-detokenized": "In 2007, Pausch received two awards from the Association for Computing Machinery for his achievements in computer science education: Karl V. Karlstrom Outstanding Educator Award and the ACM SIGCSE Award for Outstanding Contributions to Computer Science Education.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 24], [25, 28], [29, 35], [36, 40], [41, 44], [45, 56], [57, 60], [61, 70], [71, 80], [81, 84], [85, 88], [89, 101], [102, 104], [105, 113], [114, 121], [122, 131], [131, 132], [133, 137], [138, 139], [139, 140], [141, 150], [151, 162], [163, 171], [172, 177], [178, 181], [182, 185], [186, 189], [190, 196], [197, 202], [203, 206], [207, 218], [219, 232], [233, 235], [236, 244], [245, 252], [253, 262], [262, 263]]}
{"doc_key": "ai-test-325", "ner": [[3, 3, "person"], [8, 8, "product"], [9, 9, "product"], [15, 16, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 8, 8, "role", "sells", false, false], [8, 8, 9, 9, "general-affiliation", "", false, false], [8, 8, 15, 16, "physical", "shipped_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "shipped", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was shipped to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 73], [74, 76], [77, 84], [85, 91], [92, 94], [95, 99], [99, 100]]}
{"doc_key": "ai-test-326", "ner": [[0, 1, "algorithm"], [5, 7, "field"], [12, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 12, 0, 1, "usage", "", false, false], [12, 12, 5, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Semantic", "networks", "are", "used", "in", "natural", "language", "processing", "applications", "such", "as", "semantic", "parsing", "."], "sentence-detokenized": "Semantic networks are used in natural language processing applications such as semantic parsing.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 26], [27, 29], [30, 37], [38, 46], [47, 57], [58, 70], [71, 75], [76, 78], [79, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-test-327", "ner": [[4, 5, "field"], [7, 8, "field"], [10, 11, "task"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 8, 4, 5, "usage", "", false, false], [10, 11, 4, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Some", "successful", "applications", "of", "deep", "learning", "are", "computer", "vision", "and", "speech", "recognition", ".", "Honglak", "Lee", ",", "Roger", "Grosse", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y", ".", "Ng", "."], "sentence-detokenized": "Some successful applications of deep learning are computer vision and speech recognition. Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 4], [5, 15], [16, 28], [29, 31], [32, 36], [37, 45], [46, 49], [50, 58], [59, 65], [66, 69], [70, 76], [77, 88], [88, 89], [90, 97], [98, 101], [101, 102], [103, 108], [109, 115], [115, 116], [117, 123], [124, 133], [133, 134], [135, 141], [142, 143], [143, 144], [145, 147], [147, 148]]}
{"doc_key": "ai-test-328", "ner": [[4, 10, "product"], [16, 16, "misc"], [19, 19, "misc"], [25, 25, "product"], [29, 30, "task"], [32, 36, "task"], [35, 35, "task"], [38, 40, "field"], [42, 43, "task"], [45, 46, "field"], [48, 49, "task"], [51, 52, "task"], [54, 56, "task"], [58, 59, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 10, 16, 16, "physical", "travels_to", false, false], [4, 10, 19, 19, "physical", "travels_to", false, false], [25, 25, 4, 10, "part-of", "", false, false], [25, 25, 4, 10, "role", "maintains", false, false], [25, 25, 29, 30, "related-to", "has_ability_to", false, false], [25, 25, 32, 36, "related-to", "has_ability_to", false, false], [25, 25, 35, 35, "related-to", "has_ability_to", false, false], [25, 25, 38, 40, "related-to", "has_ability_to", false, false], [25, 25, 42, 43, "related-to", "has_ability_to", false, false], [25, 25, 45, 46, "related-to", "has_ability_to", false, false], [25, 25, 48, 49, "related-to", "has_ability_to", false, false], [25, 25, 51, 52, "related-to", "has_ability_to", false, false], [25, 25, 54, 56, "related-to", "has_ability_to", false, false], [25, 25, 58, 59, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["In", "addition", "to", "maintaining", "the", "systems", "of", "the", "Discovery", "One", "spacecraft", "during", "an", "interplanetary", "mission", "to", "Jupiter", "(", "or", "Saturn", "in", "the", "novel", ")", ",", "HAL", "is", "capable", "of", "speech", "synthesis", ",", "speech", "recognition", ",", "facial", "recognition", ",", "natural", "language", "processing", ",", "lip", "reading", ",", "art", "appreciation", ",", "Affective", "computing", ",", "automatic", "reasoning", ",", "piloting", "a", "spacecraft", "and", "playing", "chess", "."], "sentence-detokenized": "In addition to maintaining the systems of the Discovery One spacecraft during an interplanetary mission to Jupiter (or Saturn in the novel), HAL is capable of speech synthesis, speech recognition, facial recognition, natural language processing, lip reading, art appreciation, Affective computing, automatic reasoning, piloting a spacecraft and playing chess.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 38], [39, 41], [42, 45], [46, 55], [56, 59], [60, 70], [71, 77], [78, 80], [81, 95], [96, 103], [104, 106], [107, 114], [115, 116], [116, 118], [119, 125], [126, 128], [129, 132], [133, 138], [138, 139], [139, 140], [141, 144], [145, 147], [148, 155], [156, 158], [159, 165], [166, 175], [175, 176], [177, 183], [184, 195], [195, 196], [197, 203], [204, 215], [215, 216], [217, 224], [225, 233], [234, 244], [244, 245], [246, 249], [250, 257], [257, 258], [259, 262], [263, 275], [275, 276], [277, 286], [287, 296], [296, 297], [298, 307], [308, 317], [317, 318], [319, 327], [328, 329], [330, 340], [341, 344], [345, 352], [353, 358], [358, 359]]}
{"doc_key": "ai-test-329", "ner": [[0, 1, "researcher"], [4, 4, "country"], [6, 8, "country"], [11, 13, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 4, "physical", "", false, false], [0, 1, 6, 8, "physical", "", false, false], [0, 1, 11, 13, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dr", "Julesz", "emigrated", "from", "Hungary", "to", "the", "United", "States", "after", "the", "Soviet", "invasion", "in", "1956", "."], "sentence-detokenized": "Dr Julesz emigrated from Hungary to the United States after the Soviet invasion in 1956.", "token2charspan": [[0, 2], [3, 9], [10, 19], [20, 24], [25, 32], [33, 35], [36, 39], [40, 46], [47, 53], [54, 59], [60, 63], [64, 70], [71, 79], [80, 82], [83, 87], [87, 88]]}
{"doc_key": "ai-test-330", "ner": [[3, 4, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Activation", "functions", "of", "sigmoidal", "functions", "exploit", "the", "second", "non-linearity", "for", "large", "input", "data", ":", "math", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+", "exp", "(", "-", "v", "_", "i", ")", ")", "^", "{", "-1", "}", "/", "math", "."], "sentence-detokenized": "Activation functions of sigmoidal functions exploit the second non-linearity for large input data: math phi (v _ i) = (1 + exp (-v _ i)) ^ {-1} / math.", "token2charspan": [[0, 10], [11, 20], [21, 23], [24, 33], [34, 43], [44, 51], [52, 55], [56, 62], [63, 76], [77, 80], [81, 86], [87, 92], [93, 97], [97, 98], [99, 103], [104, 107], [108, 109], [109, 110], [111, 112], [113, 114], [114, 115], [116, 117], [118, 119], [119, 120], [121, 122], [123, 126], [127, 128], [128, 129], [129, 130], [131, 132], [133, 134], [134, 135], [135, 136], [137, 138], [139, 140], [140, 142], [142, 143], [144, 145], [146, 150], [150, 151]]}
{"doc_key": "ai-test-331", "ner": [[11, 13, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "probabilities", "are", "used", "to", "determine", "what", "is", "being", "targeted", "using", "maximum", "likelihood", "decisions", "."], "sentence-detokenized": "These probabilities are used to determine what is being targeted using maximum likelihood decisions.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 28], [29, 31], [32, 41], [42, 46], [47, 49], [50, 55], [56, 64], [65, 70], [71, 78], [79, 89], [90, 99], [99, 100]]}
{"doc_key": "ai-test-332", "ner": [[5, 8, "university"], [14, 16, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1984", "he", "moved", "to", "the", "University", "of", "Constance", "and", "in", "1990", "to", "the", "University", "of", "Salzburg", "."], "sentence-detokenized": "In 1984 he moved to the University of Constance and in 1990 to the University of Salzburg.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 16], [17, 19], [20, 23], [24, 34], [35, 37], [38, 47], [48, 51], [52, 54], [55, 59], [60, 62], [63, 66], [67, 77], [78, 80], [81, 89], [89, 90]]}
{"doc_key": "ai-test-333", "ner": [[7, 8, "metrics"], [10, 12, "metrics"], [14, 16, "metrics"], [18, 18, "metrics"], [20, 21, "metrics"], [23, 25, "metrics"], [27, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 12, 7, 8, "origin", "based_on", false, false], [14, 16, 7, 8, "origin", "based_on", false, false], [18, 18, 7, 8, "origin", "based_on", false, false], [20, 21, 7, 8, "origin", "based_on", false, false], [23, 25, 7, 8, "origin", "based_on", false, false], [27, 31, 7, 8, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Some", "popular", "fitness", "functions", "based", "on", "the", "confusion", "matrix", "include", "sensitivity", "/", "specificity", ",", "recall", "/", "precision", ",", "F-measure", ",", "Jaccard", "similarity", ",", "Matthews", "correlation", "coefficient", "and", "a", "cost", "/", "benefit", "matrix", "that", "combines", "the", "costs", "and", "profits", "attributed", "to", "4", "different", "classification", "types", "."], "sentence-detokenized": "Some popular fitness functions based on the confusion matrix include sensitivity/specificity, recall/precision, F-measure, Jaccard similarity, Matthews correlation coefficient and a cost/benefit matrix that combines the costs and profits attributed to 4 different classification types.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 30], [31, 36], [37, 39], [40, 43], [44, 53], [54, 60], [61, 68], [69, 80], [80, 81], [81, 92], [92, 93], [94, 100], [100, 101], [101, 110], [110, 111], [112, 121], [121, 122], [123, 130], [131, 141], [141, 142], [143, 151], [152, 163], [164, 175], [176, 179], [180, 181], [182, 186], [186, 187], [187, 194], [195, 201], [202, 206], [207, 215], [216, 219], [220, 225], [226, 229], [230, 237], [238, 248], [249, 251], [252, 253], [254, 263], [264, 278], [279, 284], [284, 285]]}
{"doc_key": "ai-test-334", "ner": [[7, 7, "product"], [9, 9, "product"], [10, 11, "product"], [13, 13, "product"], [15, 17, "programlang"], [29, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[29, 31, 7, 7, "part-of", "", false, false], [29, 31, 9, 9, "part-of", "", false, false], [29, 31, 10, 11, "part-of", "", false, false], [29, 31, 13, 13, "part-of", "", false, false], [29, 31, 15, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Popular", "numerical", "programming", "environments", ",", "such", "as", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", "and", "the", "R", "language", ",", "provide", "some", "of", "the", "simpler", "feature", "extraction", "techniques", "(", "e.g.", "principal", "component", "analysis", ")", "through", "built", "-", "in", "commands", "."], "sentence-detokenized": "Popular numerical programming environments, such as MATLAB, SciLab, NumPy, Sklearn and the R language, provide some of the simpler feature extraction techniques (e.g. principal component analysis) through built-in commands.", "token2charspan": [[0, 7], [8, 17], [18, 29], [30, 42], [42, 43], [44, 48], [49, 51], [52, 58], [58, 59], [60, 66], [66, 67], [68, 73], [73, 74], [75, 82], [83, 86], [87, 90], [91, 92], [93, 101], [101, 102], [103, 110], [111, 115], [116, 118], [119, 122], [123, 130], [131, 138], [139, 149], [150, 160], [161, 162], [162, 166], [167, 176], [177, 186], [187, 195], [195, 196], [197, 204], [205, 210], [210, 211], [211, 213], [214, 222], [222, 223]]}
{"doc_key": "ai-test-335", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Industrial", "robots", "have", "been", "deployed", "to", "work", "with", "humans", "to", "perform", "industrial", "production", "tasks", "."], "sentence-detokenized": "Industrial robots have been deployed to work with humans to perform industrial production tasks.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 27], [28, 36], [37, 39], [40, 44], [45, 49], [50, 56], [57, 59], [60, 67], [68, 78], [79, 89], [90, 95], [95, 96]]}
{"doc_key": "ai-test-336", "ner": [[6, 6, "field"], [8, 11, "researcher"], [21, 22, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[6, 6, 21, 22, "related-to", "", false, false], [6, 6, 27, 28, "related-to", "", false, false], [8, 11, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["In", "his", "first", "published", "work", "on", "CG", ",", "John", "F", ".", "Sowa", "applied", "it", "to", "a", "wide", "range", "of", "topics", "in", "artificial", "intelligence", ",", "computer", "science", "and", "cognitive", "science", "."], "sentence-detokenized": "In his first published work on CG, John F. Sowa applied it to a wide range of topics in artificial intelligence, computer science and cognitive science.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [23, 27], [28, 30], [31, 33], [33, 34], [35, 39], [40, 41], [41, 42], [43, 47], [48, 55], [56, 58], [59, 61], [62, 63], [64, 68], [69, 74], [75, 77], [78, 84], [85, 87], [88, 98], [99, 111], [111, 112], [113, 121], [122, 129], [130, 133], [134, 143], [144, 151], [151, 152]]}
{"doc_key": "ai-test-337", "ner": [[0, 0, "metrics"], [4, 4, "metrics"], [7, 9, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "BLEU", "in", "calculating", "the", "brevity", "penalty", ",", "as", "small", "differences", "in", "translation", "length", "do", "not", "affect", "the", "overall", "result", "as", "much", "."], "sentence-detokenized": "NIST also differs from BLEU in calculating the brevity penalty, as small differences in translation length do not affect the overall result as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 27], [28, 30], [31, 42], [43, 46], [47, 54], [55, 62], [62, 63], [64, 66], [67, 72], [73, 84], [85, 87], [88, 99], [100, 106], [107, 109], [110, 113], [114, 120], [121, 124], [125, 132], [133, 139], [140, 142], [143, 147], [147, 148]]}
{"doc_key": "ai-test-338", "ner": [[0, 5, "misc"], [13, 13, "conference"], [16, 19, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 5, 13, 13, "temporal", "", false, false], [0, 5, 16, 19, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "IJCAI", "Award", "for", "Research", "Excellence", "is", "a", "biennial", "award", "presented", "at", "the", "IJCAI", "conference", "to", "artificial", "intelligence", "researchers", "in", "recognition", "of", "excellence", "in", "their", "careers", "."], "sentence-detokenized": "The IJCAI Award for Research Excellence is a biennial award presented at the IJCAI conference to artificial intelligence researchers in recognition of excellence in their careers.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 19], [20, 28], [29, 39], [40, 42], [43, 44], [45, 53], [54, 59], [60, 69], [70, 72], [73, 76], [77, 82], [83, 93], [94, 96], [97, 107], [108, 120], [121, 132], [133, 135], [136, 147], [148, 150], [151, 161], [162, 164], [165, 170], [171, 178], [178, 179]]}
{"doc_key": "ai-test-339", "ner": [[0, 0, "researcher"], [8, 8, "conference"], [18, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 8, "role", "", false, false], [0, 0, 18, 25, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lenat", "was", "one", "of", "the", "original", "members", "of", "AAAI", "and", "is", "the", "only", "person", "to", "sit", "on", "the", "scientific", "advisory", "boards", "of", "both", "Microsoft", "and", "Apple", "."], "sentence-detokenized": "Lenat was one of the original members of AAAI and is the only person to sit on the scientific advisory boards of both Microsoft and Apple.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 16], [17, 20], [21, 29], [30, 37], [38, 40], [41, 45], [46, 49], [50, 52], [53, 56], [57, 61], [62, 68], [69, 71], [72, 75], [76, 78], [79, 82], [83, 93], [94, 102], [103, 109], [110, 112], [113, 117], [118, 127], [128, 131], [132, 137], [137, 138]]}
{"doc_key": "ai-test-340", "ner": [[0, 0, "algorithm"], [5, 6, "misc"], [10, 12, "metrics"], [19, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 6, "related-to", "minimise", false, false], [10, 12, 5, 6, "type-of", "", false, false], [19, 19, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autoencoders", "are", "trained", "to", "minimise", "reconstruction", "errors", "(", "such", "as", "Mean", "squared", "error", ")", ",", "often", "referred", "to", "as", "loss", ":"], "sentence-detokenized": "Autoencoders are trained to minimise reconstruction errors (such as Mean squared error), often referred to as loss:", "token2charspan": [[0, 12], [13, 16], [17, 24], [25, 27], [28, 36], [37, 51], [52, 58], [59, 60], [60, 64], [65, 67], [68, 72], [73, 80], [81, 86], [86, 87], [87, 88], [89, 94], [95, 103], [104, 106], [107, 109], [110, 114], [114, 115]]}
{"doc_key": "ai-test-341", "ner": [[28, 30, "misc"], [34, 34, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[34, 34, 28, 30, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "alternative", "to", "using", "definitions", "is", "to", "consider", "the", "general", "relatedness", "of", "word", "senses", "and", "calculate", "the", "similarity", "of", "each", "pair", "of", "word", "senses", "based", "on", "a", "given", "lexical", "knowledge", "base", ",", "such", "as", "WordNet", "."], "sentence-detokenized": "An alternative to using definitions is to consider the general relatedness of word senses and calculate the similarity of each pair of word senses based on a given lexical knowledge base, such as WordNet.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 23], [24, 35], [36, 38], [39, 41], [42, 50], [51, 54], [55, 62], [63, 74], [75, 77], [78, 82], [83, 89], [90, 93], [94, 103], [104, 107], [108, 118], [119, 121], [122, 126], [127, 131], [132, 134], [135, 139], [140, 146], [147, 152], [153, 155], [156, 157], [158, 163], [164, 171], [172, 181], [182, 186], [186, 187], [188, 192], [193, 195], [196, 203], [203, 204]]}
{"doc_key": "ai-test-342", "ner": [[0, 2, "algorithm"], [9, 13, "researcher"], [21, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 9, 13, "origin", "", false, false], [9, 13, 21, 22, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD", "-", "Lambda", "is", "a", "learning", "algorithm", "invented", "by", "Richard", "S.", "Sutton", "based", "on", "earlier", "work", "on", "temporal", "difference", "learning", "by", "Arthur", "Samuel", "."], "sentence-detokenized": "TD-Lambda is a learning algorithm invented by Richard S. Sutton based on earlier work on temporal difference learning by Arthur Samuel.", "token2charspan": [[0, 2], [2, 3], [3, 9], [10, 12], [13, 14], [15, 23], [24, 33], [34, 42], [43, 45], [46, 53], [54, 56], [57, 63], [64, 69], [70, 72], [73, 80], [81, 85], [86, 88], [89, 97], [98, 108], [109, 117], [118, 120], [121, 127], [128, 134], [134, 135]]}
{"doc_key": "ai-test-343", "ner": [[1, 2, "field"], [4, 4, "field"], [6, 7, "task"], [12, 13, "task"], [15, 15, "task"], [20, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 7, 1, 2, "part-of", "task_part_of_field", false, false], [6, 7, 4, 4, "part-of", "task_part_of_field", false, false], [12, 13, 6, 7, "named", "", false, false], [15, 15, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "data", "mining", "and", "statistics", ",", "hierarchical", "clustering", "(", "also", "called", "hierarchical", "cluster", "analysis", "or", "HCA", ")", "is", "a", "cluster", "analysis", "method", "that", "seeks", "to", "build", "a", "hierarchy", "of", "clusters", "."], "sentence-detokenized": "In data mining and statistics, hierarchical clustering (also called hierarchical cluster analysis or HCA) is a cluster analysis method that seeks to build a hierarchy of clusters.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 18], [19, 29], [29, 30], [31, 43], [44, 54], [55, 56], [56, 60], [61, 67], [68, 80], [81, 88], [89, 97], [98, 100], [101, 104], [104, 105], [106, 108], [109, 110], [111, 118], [119, 127], [128, 134], [135, 139], [140, 145], [146, 148], [149, 154], [155, 156], [157, 166], [167, 169], [170, 178], [178, 179]]}
{"doc_key": "ai-test-344", "ner": [[3, 3, "algorithm"], [8, 11, "field"], [10, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "concept", "of", "deconvolution", "is", "widely", "used", "in", "signal", "and", "image", "processing", "techniques", "."], "sentence-detokenized": "The concept of deconvolution is widely used in signal and image processing techniques.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 28], [29, 31], [32, 38], [39, 43], [44, 46], [47, 53], [54, 57], [58, 63], [64, 74], [75, 85], [85, 86]]}
{"doc_key": "ai-test-345", "ner": [[0, 1, "algorithm"], [20, 21, "misc"], [24, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 20, 21, "related-to", "enhances", false, false], [0, 1, 20, 21, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cognitive", "maps", "are", "used", "to", "construct", "and", "accumulate", "spatial", "knowledge", ",", "allowing", "visualisation", "of", "images", "of", "the", "mind", "to", "reduce", "cognitive", "load", ",", "increase", "recall", "and", "learning", "of", "information", "."], "sentence-detokenized": "Cognitive maps are used to construct and accumulate spatial knowledge, allowing visualisation of images of the mind to reduce cognitive load, increase recall and learning of information.", "token2charspan": [[0, 9], [10, 14], [15, 18], [19, 23], [24, 26], [27, 36], [37, 40], [41, 51], [52, 59], [60, 69], [69, 70], [71, 79], [80, 93], [94, 96], [97, 103], [104, 106], [107, 110], [111, 115], [116, 118], [119, 125], [126, 135], [136, 140], [140, 141], [142, 150], [151, 157], [158, 161], [162, 170], [171, 173], [174, 185], [185, 186]]}
{"doc_key": "ai-test-346", "ner": [[8, 8, "programlang"], [10, 11, "programlang"], [13, 13, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": [",", "usually", "providing", "bindings", "to", "languages", "such", "as", "Python", ",", "C", "++", ",", "Java", ")", "."], "sentence-detokenized": ", usually providing bindings to languages such as Python, C ++, Java).", "token2charspan": [[0, 1], [2, 9], [10, 19], [20, 28], [29, 31], [32, 41], [42, 46], [47, 49], [50, 56], [56, 57], [58, 59], [60, 62], [62, 63], [64, 68], [68, 69], [69, 70]]}
{"doc_key": "ai-test-347", "ner": [[0, 3, "product"], [5, 5, "product"], [15, 16, "task"], [22, 23, "task"], [28, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 15, 16, "usage", "", false, false], [0, 3, 22, 23, "usage", "", false, false], [0, 3, 28, 31, "usage", "", false, false], [5, 5, 0, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "voice", "-user", "interface", "(", "VUI", ")", "enables", "spoken", "human", "-", "computer", "interaction", ",", "using", "speech", "recognition", "to", "understand", "verbal", "commands", "and", "answer", "questions", ",", "and", "typically", "converting", "text", "to", "speech", "to", "reproduce", "responses", "."], "sentence-detokenized": "The voice-user interface (VUI) enables spoken human-computer interaction, using speech recognition to understand verbal commands and answer questions, and typically converting text to speech to reproduce responses.", "token2charspan": [[0, 3], [4, 9], [9, 14], [15, 24], [25, 26], [26, 29], [29, 30], [31, 38], [39, 45], [46, 51], [51, 52], [52, 60], [61, 72], [72, 73], [74, 79], [80, 86], [87, 98], [99, 101], [102, 112], [113, 119], [120, 128], [129, 132], [133, 139], [140, 149], [149, 150], [151, 154], [155, 164], [165, 175], [176, 180], [181, 183], [184, 190], [191, 193], [194, 203], [204, 213], [213, 214]]}
{"doc_key": "ai-test-348", "ner": [[0, 0, "programlang"], [3, 4, "misc"], [7, 7, "programlang"], [13, 16, "researcher"], [18, 19, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 4, "general-affiliation", "is_a", false, false], [0, 0, 7, 7, "general-affiliation", "made_with", false, false], [0, 0, 13, 16, "origin", "", false, false], [13, 16, 18, 19, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Jess", "is", "a", "rules", "engine", "for", "the", "Java", "platform", "that", "was", "developed", "by", "Ernest", "Friedman", "-", "Hill", "of", "Sandia", "National", "."], "sentence-detokenized": "Jess is a rules engine for the Java platform that was developed by Ernest Friedman-Hill of Sandia National.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 15], [16, 22], [23, 26], [27, 30], [31, 35], [36, 44], [45, 49], [50, 53], [54, 63], [64, 66], [67, 73], [74, 82], [82, 83], [83, 87], [88, 90], [91, 97], [98, 106], [106, 107]]}
{"doc_key": "ai-test-349", "ner": [[1, 2, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 16, 16, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "multilayer", "perceptrons", ",", "where", "there", "is", "a", "hidden", "layer", ",", "more", "sophisticated", "algorithms", "such", "as", "backpropagation", "must", "be", "used", "."], "sentence-detokenized": "For multilayer perceptrons, where there is a hidden layer, more sophisticated algorithms such as backpropagation must be used.", "token2charspan": [[0, 3], [4, 14], [15, 26], [26, 27], [28, 33], [34, 39], [40, 42], [43, 44], [45, 51], [52, 57], [57, 58], [59, 63], [64, 77], [78, 88], [89, 93], [94, 96], [97, 112], [113, 117], [118, 120], [121, 125], [125, 126]]}
{"doc_key": "ai-test-350", "ner": [[0, 1, "product"], [2, 6, "product"], [10, 17, "algorithm"], [22, 23, "field"], [26, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 6, 0, 1, "part-of", "", false, false], [2, 6, 10, 17, "usage", "", false, true], [10, 17, 22, 23, "related-to", "performs", false, false], [26, 31, 22, 23, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Google", "Translate", "'s", "neural", "machine", "translation", "system", "uses", "a", "large", "end", "-", "to", "-", "end", "artificial", "neural", "network", "that", "attempts", "to", "perform", "deep", "learning", ",", "particularly", "long", "short", "-", "term", "memory", "networks", "."], "sentence-detokenized": "Google Translate's neural machine translation system uses a large end-to-end artificial neural network that attempts to perform deep learning, particularly long short-term memory networks.", "token2charspan": [[0, 6], [7, 16], [16, 18], [19, 25], [26, 33], [34, 45], [46, 52], [53, 57], [58, 59], [60, 65], [66, 69], [69, 70], [70, 72], [72, 73], [73, 76], [77, 87], [88, 94], [95, 102], [103, 107], [108, 116], [117, 119], [120, 127], [128, 132], [133, 141], [141, 142], [143, 155], [156, 160], [161, 166], [166, 167], [167, 171], [172, 178], [179, 187], [187, 188]]}
{"doc_key": "ai-test-351", "ner": [[14, 14, "researcher"], [16, 16, "researcher"], [18, 18, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Various", "methods", "for", "this", "purpose", "were", "developed", "in", "the", "1980s", "and", "early", "1990s", "by", "Werbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Pearlmutter", "and", "others", "."], "sentence-detokenized": "Various methods for this purpose were developed in the 1980s and early 1990s by Werbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Pearlmutter and others.", "token2charspan": [[0, 7], [8, 15], [16, 19], [20, 24], [25, 32], [33, 37], [38, 47], [48, 50], [51, 54], [55, 60], [61, 64], [65, 70], [71, 76], [77, 79], [80, 86], [86, 87], [88, 96], [96, 97], [98, 106], [106, 107], [108, 114], [115, 126], [126, 127], [128, 132], [133, 143], [143, 144], [145, 156], [157, 160], [161, 167], [167, 168]]}
{"doc_key": "ai-test-352", "ner": [[1, 1, "organisation"], [2, 3, "organisation"], [9, 9, "organisation"], [12, 13, "task"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 9, 9, "role", "licenses_from", false, false], [2, 3, 1, 1, "named", "", false, false], [17, 17, 1, 1, "origin", "", false, false], [17, 17, 12, 13, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["|", "Apple", "Apple", "Inc.", "originally", "licensed", "the", "software", "from", "Nuance", "to", "provide", "speech", "recognition", "capabilities", "to", "its", "Siri", "digital", "assistant", "."], "sentence-detokenized": "| Apple Apple Inc. originally licensed the software from Nuance to provide speech recognition capabilities to its Siri digital assistant.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 18], [19, 29], [30, 38], [39, 42], [43, 51], [52, 56], [57, 63], [64, 66], [67, 74], [75, 81], [82, 93], [94, 106], [107, 109], [110, 113], [114, 118], [119, 126], [127, 136], [136, 137]]}
{"doc_key": "ai-test-353", "ner": [[0, 0, "organisation"], [4, 5, "misc"], [8, 9, "person"], [13, 14, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 5, "role", "releases_movies_in_genre", false, false], [8, 9, 0, 0, "role", "directs_for", false, false], [13, 14, 0, 0, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "has", "released", "several", "3D", "westerns", "produced", "by", "Sam", "Katzman", "and", "directed", "by", "William", "Castle", "."], "sentence-detokenized": "Columbia has released several 3D westerns produced by Sam Katzman and directed by William Castle.", "token2charspan": [[0, 8], [9, 12], [13, 21], [22, 29], [30, 32], [33, 41], [42, 50], [51, 53], [54, 57], [58, 65], [66, 69], [70, 78], [79, 81], [82, 89], [90, 96], [96, 97]]}
{"doc_key": "ai-test-354", "ner": [[6, 12, "field"], [9, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "includes", "knowledge", "and", "research", "in", "computer", "science", ",", "linguistics", "and", "computer", "engineering", "."], "sentence-detokenized": "It includes knowledge and research in computer science, linguistics and computer engineering.", "token2charspan": [[0, 2], [3, 11], [12, 21], [22, 25], [26, 34], [35, 37], [38, 46], [47, 54], [54, 55], [56, 67], [68, 71], [72, 80], [81, 92], [92, 93]]}
{"doc_key": "ai-test-355", "ner": [[5, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Below", "is", "an", "example", "of", "R", "code", ":"], "sentence-detokenized": "Below is an example of R code:", "token2charspan": [[0, 5], [6, 8], [9, 11], [12, 19], [20, 22], [23, 24], [25, 29], [29, 30]]}
{"doc_key": "ai-test-356", "ner": [[0, 2, "metrics"], [7, 10, "metrics"], [12, 12, "metrics"], [16, 18, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 7, 10, "part-of", "plotted_into", false, false], [0, 2, 16, 18, "part-of", "plotted_into", false, false], [12, 12, 7, 10, "named", "", false, false], [20, 20, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "ROC", "curve", "is", "produced", "by", "plotting", "the", "TRUE", "positive", "rate", "(", "TPR", ")", "against", "the", "FALSE", "positive", "rate", "(", "FPR", ")", "at", "different", "threshold", "settings", "."], "sentence-detokenized": "The ROC curve is produced by plotting the TRUE positive rate (TPR) against the FALSE positive rate (FPR) at different threshold settings.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 25], [26, 28], [29, 37], [38, 41], [42, 46], [47, 55], [56, 60], [61, 62], [62, 65], [65, 66], [67, 74], [75, 78], [79, 84], [85, 93], [94, 98], [99, 100], [100, 103], [103, 104], [105, 107], [108, 117], [118, 127], [128, 136], [136, 137]]}
{"doc_key": "ai-test-357", "ner": [[3, 4, "field"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 3, 4, "related-to", "researches_field", false, false], [10, 11, 3, 4, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Research", "stagnated", "after", "machine", "learning", "research", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", ","], "sentence-detokenized": "Research stagnated after machine learning research by Marvin Minsky and Seymour Papert (1969),", "token2charspan": [[0, 8], [9, 18], [19, 24], [25, 32], [33, 41], [42, 50], [51, 53], [54, 60], [61, 67], [68, 71], [72, 79], [80, 86], [87, 88], [88, 92], [92, 93], [93, 94]]}
{"doc_key": "ai-test-358", "ner": [[8, 8, "task"], [11, 12, "programlang"], [14, 17, "product"], [19, 20, "programlang"], [22, 22, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 8, 11, 12, "related-to", "used_to_build", false, false], [8, 8, 14, 17, "related-to", "used_to_build", false, false], [8, 8, 19, 20, "related-to", "used_to_build", false, false], [8, 8, 22, 22, "related-to", "used_to_build", false, false], [8, 8, 24, 24, "related-to", "used_to_build", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "programming", "environments", "that", "are", "used", "to", "build", "DAQ", "applications", "include", "ladder", "logic", ",", "Visual", "C", "+", "+", ",", "Visual", "Basic", ",", "LabVIEW", "and", "MATLAB", "."], "sentence-detokenized": "Other programming environments that are used to build DAQ applications include ladder logic, Visual C + +, Visual Basic, LabVIEW and MATLAB.", "token2charspan": [[0, 5], [6, 17], [18, 30], [31, 35], [36, 39], [40, 44], [45, 47], [48, 53], [54, 57], [58, 70], [71, 78], [79, 85], [86, 91], [91, 92], [93, 99], [100, 101], [102, 103], [104, 105], [105, 106], [107, 113], [114, 119], [119, 120], [121, 128], [129, 132], [133, 139], [139, 140]]}
{"doc_key": "ai-test-359", "ner": [[16, 17, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "metric", "has", "been", "designed", "to", "address", "some", "of", "the", "problems", "found", "in", "the", "more", "popular", "BLEU", "metric", ",", "as", "well", "as", "to", "achieve", "good", "correlation", "with", "human", "assessment", "at", "the", "sentence", "or", "segment", "level", "."], "sentence-detokenized": "This metric has been designed to address some of the problems found in the more popular BLEU metric, as well as to achieve good correlation with human assessment at the sentence or segment level.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 29], [30, 32], [33, 40], [41, 45], [46, 48], [49, 52], [53, 61], [62, 67], [68, 70], [71, 74], [75, 79], [80, 87], [88, 92], [93, 99], [99, 100], [101, 103], [104, 108], [109, 111], [112, 114], [115, 122], [123, 127], [128, 139], [140, 144], [145, 150], [151, 161], [162, 164], [165, 168], [169, 177], [178, 180], [181, 188], [189, 194], [194, 195]]}
{"doc_key": "ai-test-360", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "semantic", "correlations", "between", "consecutive", "video", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and long short-term memory are often used to exploit semantic correlations between consecutive video frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [83, 88], [88, 89], [89, 93], [94, 100], [101, 104], [105, 110], [111, 115], [116, 118], [119, 126], [127, 135], [136, 148], [149, 156], [157, 168], [169, 174], [175, 181], [181, 182]]}
{"doc_key": "ai-test-361", "ner": [[3, 4, "product"], [7, 7, "product"], [14, 24, "product"], [23, 23, "product"], [39, 40, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 14, 24, "artifact", "", false, false], [3, 4, 39, 40, "named", "", false, false], [7, 7, 3, 4, "named", "", false, false], [23, 23, 14, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Mass", "-", "produced", "printed", "circuit", "boards", "(", "PCBs", ")", "are", "almost", "exclusively", "manufactured", "by", "pick", "-", "and", "-", "place", "robots", ",", "usually", "with", "SCARA", "manipulators", ",", "which", "remove", "small", "electronic", "components", "from", "tapes", "or", "trays", "and", "place", "them", "on", "PCBs", "with", "high", "accuracy", "."], "sentence-detokenized": "Mass-produced printed circuit boards (PCBs) are almost exclusively manufactured by pick-and-place robots, usually with SCARA manipulators, which remove small electronic components from tapes or trays and place them on PCBs with high accuracy.", "token2charspan": [[0, 4], [4, 5], [5, 13], [14, 21], [22, 29], [30, 36], [37, 38], [38, 42], [42, 43], [44, 47], [48, 54], [55, 66], [67, 79], [80, 82], [83, 87], [87, 88], [88, 91], [91, 92], [92, 97], [98, 104], [104, 105], [106, 113], [114, 118], [119, 124], [125, 137], [137, 138], [139, 144], [145, 151], [152, 157], [158, 168], [169, 179], [180, 184], [185, 190], [191, 193], [194, 199], [200, 203], [204, 209], [210, 214], [215, 217], [218, 222], [223, 227], [228, 232], [233, 241], [241, 242]]}
{"doc_key": "ai-test-362", "ner": [[4, 5, "field"], [15, 15, "algorithm"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 29, "researcher"], [36, 38, "algorithm"], [39, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 15, 4, 5, "part-of", "", false, false], [15, 15, 20, 21, "origin", "", false, false], [15, 15, 23, 24, "origin", "", false, false], [15, 15, 26, 29, "origin", "", false, false], [15, 15, 36, 38, "type-of", "", false, false], [36, 38, 39, 40, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "the", "context", "of", "machine", "learning", ",", "where", "it", "is", "most", "widely", "used", "today", ",", "LDA", "was", "rediscovered", "independently", "by", "David", "Blei", ",", "Andrew", "Ng", "and", "Michael", "I", ".", "Jordan", "in", "2003", "and", "presented", "as", "a", "graph", "model", "of", "topic", "discovery", "."], "sentence-detokenized": "In the context of machine learning, where it is most widely used today, LDA was rediscovered independently by David Blei, Andrew Ng and Michael I. Jordan in 2003 and presented as a graph model of topic discovery.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 25], [26, 34], [34, 35], [36, 41], [42, 44], [45, 47], [48, 52], [53, 59], [60, 64], [65, 70], [70, 71], [72, 75], [76, 79], [80, 92], [93, 106], [107, 109], [110, 115], [116, 120], [120, 121], [122, 128], [129, 131], [132, 135], [136, 143], [144, 145], [145, 146], [147, 153], [154, 156], [157, 161], [162, 165], [166, 175], [176, 178], [179, 180], [181, 186], [187, 192], [193, 195], [196, 201], [202, 211], [211, 212]]}
{"doc_key": "ai-test-363", "ner": [[8, 9, "task"], [11, 11, "misc"], [13, 13, "metrics"], [15, 15, "metrics"], [17, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 9, 11, 11, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["Measured", "performance", "on", "test", "data", "of", "eight", "naive", "WSIs", "in", "different", "tauopathies", "yielded", "recall", ",", "precision", "and", "F1", "scores", "of", "0.92", ",", "0.72", "and", "0.81", "respectively", "."], "sentence-detokenized": "Measured performance on test data of eight naive WSIs in different tauopathies yielded recall, precision and F1 scores of 0.92, 0.72 and 0.81 respectively.", "token2charspan": [[0, 8], [9, 20], [21, 23], [24, 28], [29, 33], [34, 36], [37, 42], [43, 48], [49, 53], [54, 56], [57, 66], [67, 78], [79, 86], [87, 93], [93, 94], [95, 104], [105, 108], [109, 111], [112, 118], [119, 121], [122, 126], [126, 127], [128, 132], [133, 136], [137, 141], [142, 154], [154, 155]]}
{"doc_key": "ai-test-364", "ner": [[5, 5, "field"], [10, 11, "field"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["With", "the", "help", "of", "advanced", "AR", "technologies", "(", "e.g.", "adding", "computer", "vision", ",", "embedding", "AR", "cameras", "in", "smartphones", "and", "object", "recognition", ")", ",", "information", "about", "the", "real", "world", "around", "the", "user", "becomes", "interactive", "and", "digitally", "manipulated", "."], "sentence-detokenized": "With the help of advanced AR technologies (e.g. adding computer vision, embedding AR cameras in smartphones and object recognition), information about the real world around the user becomes interactive and digitally manipulated.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 25], [26, 28], [29, 41], [42, 43], [43, 47], [48, 54], [55, 63], [64, 70], [70, 71], [72, 81], [82, 84], [85, 92], [93, 95], [96, 107], [108, 111], [112, 118], [119, 130], [130, 131], [131, 132], [133, 144], [145, 150], [151, 154], [155, 159], [160, 165], [166, 172], [173, 176], [177, 181], [182, 189], [190, 201], [202, 205], [206, 215], [216, 227], [227, 228]]}
{"doc_key": "ai-test-365", "ner": [[0, 0, "researcher"], [2, 2, "organisation"], [11, 12, "field"], [22, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 2, 2, "role", "forms_company", false, false], [2, 2, 11, 12, "related-to", "works_with", false, false], [2, 2, 22, 24, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Schmidhuber", "founded", "Nnaisense", "in", "2014", "to", "work", "on", "commercial", "applications", "of", "artificial", "intelligence", "in", "areas", "such", "as", "finance", ",", "heavy", "industry", "and", "self", "-", "driving", "cars", "."], "sentence-detokenized": "Schmidhuber founded Nnaisense in 2014 to work on commercial applications of artificial intelligence in areas such as finance, heavy industry and self-driving cars.", "token2charspan": [[0, 11], [12, 19], [20, 29], [30, 32], [33, 37], [38, 40], [41, 45], [46, 48], [49, 59], [60, 72], [73, 75], [76, 86], [87, 99], [100, 102], [103, 108], [109, 113], [114, 116], [117, 124], [124, 125], [126, 131], [132, 140], [141, 144], [145, 149], [149, 150], [150, 157], [158, 162], [162, 163]]}
{"doc_key": "ai-test-366", "ner": [[25, 28, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Not", "only", "does", "this", "change", "the", "results", "of", "all", "subsequent", "tests", "on", "the", "retained", "explanatory", "model", ",", "but", "it", "can", "also", "introduce", "bias", "and", "alter", "the", "mean", "squared", "error", "in", "the", "estimation", "."], "sentence-detokenized": "Not only does this change the results of all subsequent tests on the retained explanatory model, but it can also introduce bias and alter the mean squared error in the estimation.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 18], [19, 25], [26, 29], [30, 37], [38, 40], [41, 44], [45, 55], [56, 61], [62, 64], [65, 68], [69, 77], [78, 89], [90, 95], [95, 96], [97, 100], [101, 103], [104, 107], [108, 112], [113, 122], [123, 127], [128, 131], [132, 137], [138, 141], [142, 146], [147, 154], [155, 160], [161, 163], [164, 167], [168, 178], [178, 179]]}
{"doc_key": "ai-test-367", "ner": [[0, 0, "misc"], [6, 6, "algorithm"], [9, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 0, 0, "usage", "", false, false], [6, 6, 9, 10, "topic", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Bigrams", "are", "used", "in", "most", "successful", "language", "models", "for", "speech", "recognition", "."], "sentence-detokenized": "Bigrams are used in most successful language models for speech recognition.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 19], [20, 24], [25, 35], [36, 44], [45, 51], [52, 55], [56, 62], [63, 74], [74, 75]]}
{"doc_key": "ai-test-368", "ner": [[3, 4, "field"], [8, 10, "misc"], [15, 17, "misc"], [21, 24, "organisation"], [27, 29, "misc"], [35, 38, "organisation"], [41, 43, "misc"], [49, 53, "organisation"], [56, 58, "misc"], [64, 66, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[8, 10, 3, 4, "topic", "", false, false], [15, 17, 21, 24, "origin", "", false, false], [27, 29, 35, 38, "origin", "", false, false], [41, 43, 49, 53, "origin", "", false, false], [56, 58, 64, 66, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["His", "research", "in", "cognitive", "psychology", "has", "won", "the", "Early", "Career", "Award", "(", "1984", ")", "and", "Boyd", "McCandless", "Award", "1986", ")", "from", "the", "American", "Psychological", "Association", ",", "the", "Troland", "Research", "Award", "(", "1993", ")", "from", "the", "National", "Academy", "of", "Sciences", ",", "the", "Henry", "Dale", "Prize", "(", "2004", ")", "from", "the", "Royal", "Institution", "of", "Great", "Britain", "and", "the", "George", "Miller", "Prize", "(", "2010", ")", "from", "the", "Cognitive", "Neuroscience", "Society", "."], "sentence-detokenized": "His research in cognitive psychology has won the Early Career Award (1984) and Boyd McCandless Award 1986) from the American Psychological Association, the Troland Research Award (1993) from the National Academy of Sciences, the Henry Dale Prize (2004) from the Royal Institution of Great Britain and the George Miller Prize (2010) from the Cognitive Neuroscience Society.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 25], [26, 36], [37, 40], [41, 44], [45, 48], [49, 54], [55, 61], [62, 67], [68, 69], [69, 73], [73, 74], [75, 78], [79, 83], [84, 94], [95, 100], [101, 105], [105, 106], [107, 111], [112, 115], [116, 124], [125, 138], [139, 150], [150, 151], [152, 155], [156, 163], [164, 172], [173, 178], [179, 180], [180, 184], [184, 185], [186, 190], [191, 194], [195, 203], [204, 211], [212, 214], [215, 223], [223, 224], [225, 228], [229, 234], [235, 239], [240, 245], [246, 247], [247, 251], [251, 252], [253, 257], [258, 261], [262, 267], [268, 279], [280, 282], [283, 288], [289, 296], [297, 300], [301, 304], [305, 311], [312, 318], [319, 324], [325, 326], [326, 330], [330, 331], [332, 336], [337, 340], [341, 350], [351, 363], [364, 371], [371, 372]]}
{"doc_key": "ai-test-369", "ner": [[0, 0, "misc"], [6, 6, "misc"], [9, 11, "product"], [15, 15, "researcher"], [17, 17, "researcher"], [24, 25, "researcher"], [27, 28, "researcher"], [30, 31, "task"], [33, 36, "researcher"], [38, 42, "researcher"], [43, 44, "task"], [46, 46, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[0, 0, 6, 6, "named", "", false, false], [0, 0, 46, 46, "named", "", false, false], [6, 6, 15, 15, "origin", "", false, false], [6, 6, 17, 17, "origin", "", false, false], [6, 6, 30, 31, "related-to", "used_for", false, false], [9, 11, 6, 6, "usage", "", false, false], [9, 11, 43, 44, "named", "", false, false], [24, 25, 6, 6, "usage", "", false, false], [24, 25, 33, 36, "named", "same", false, false], [27, 28, 6, 6, "usage", "", false, false], [27, 28, 38, 42, "named", "same", false, false], [43, 44, 46, 46, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Eigenface", "(", "The", "approach", "of", "using", "eigenfaces", "in", "a", "face", "recognition", "system", "was", "developed", "by", "Sirovich", "and", "Kirby", "(", "1987", ")", "and", "used", "by", "Matthew", "Turk", "and", "Alex", "Pentland", "in", "face", "classification", ".", "Turk", ",", "Matthew", "A", "and", "Pentland", ",", "Alex", "P", ".", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "Eigenface (The approach of using eigenfaces in a face recognition system was developed by Sirovich and Kirby (1987) and used by Matthew Turk and Alex Pentland in face classification. Turk, Matthew A and Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 9], [10, 11], [11, 14], [15, 23], [24, 26], [27, 32], [33, 43], [44, 46], [47, 48], [49, 53], [54, 65], [66, 72], [73, 76], [77, 86], [87, 89], [90, 98], [99, 102], [103, 108], [109, 110], [110, 114], [114, 115], [116, 119], [120, 124], [125, 127], [128, 135], [136, 140], [141, 144], [145, 149], [150, 158], [159, 161], [162, 166], [167, 181], [181, 182], [183, 187], [187, 188], [189, 196], [197, 198], [199, 202], [203, 211], [211, 212], [213, 217], [218, 219], [219, 220], [221, 225], [226, 237], [238, 243], [244, 254], [254, 255]]}
{"doc_key": "ai-test-370", "ner": [[6, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "lexical", "dictionary", ",", "such", "as", "WordNet", ",", "can", "then", "be", "used", "to", "understand", "the", "context", "."], "sentence-detokenized": "A lexical dictionary, such as WordNet, can then be used to understand the context.", "token2charspan": [[0, 1], [2, 9], [10, 20], [20, 21], [22, 26], [27, 29], [30, 37], [37, 38], [39, 42], [43, 47], [48, 50], [51, 55], [56, 58], [59, 69], [70, 73], [74, 81], [81, 82]]}
{"doc_key": "ai-test-371", "ner": [[0, 0, "misc"], [8, 8, "misc"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 8, "part-of", "", false, false], [8, 8, 15, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hyponymy", "is", "the", "most", "commonly", "encoded", "relationship", "among", "synsets", "used", "in", "lexical", "databases", "such", "as", "WordNet", "."], "sentence-detokenized": "Hyponymy is the most commonly encoded relationship among synsets used in lexical databases such as WordNet.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 20], [21, 29], [30, 37], [38, 50], [51, 56], [57, 64], [65, 69], [70, 72], [73, 80], [81, 90], [91, 95], [96, 98], [99, 106], [106, 107]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [7, 9, "programlang"], [11, 11, "programlang"], [40, 41, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 9, "general-affiliation", "", false, false], [0, 0, 11, 11, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "offers", "open", "-", "source", "libraries", "in", "C", "+", "+", "and", "Java", ",", "but", "many", "customers", "rely", "on", "community", "-", "developed", "libraries", ",", "such", "as", "libraries", "include", "built", "-", "in", "capabilities", "to", "retrieve", "(", "array", "-", "style", ")", "data", "from", "DAP", "servers", "."], "sentence-detokenized": "OPeNDAP offers open-source libraries in C + + and Java, but many customers rely on community-developed libraries, such as libraries include built-in capabilities to retrieve (array-style) data from DAP servers.", "token2charspan": [[0, 7], [8, 14], [15, 19], [19, 20], [20, 26], [27, 36], [37, 39], [40, 41], [42, 43], [44, 45], [46, 49], [50, 54], [54, 55], [56, 59], [60, 64], [65, 74], [75, 79], [80, 82], [83, 92], [92, 93], [93, 102], [103, 112], [112, 113], [114, 118], [119, 121], [122, 131], [132, 139], [140, 145], [145, 146], [146, 148], [149, 161], [162, 164], [165, 173], [174, 175], [175, 180], [180, 181], [181, 186], [186, 187], [188, 192], [193, 197], [198, 201], [202, 209], [209, 210]]}
{"doc_key": "ai-test-373", "ner": [[4, 5, "misc"], [8, 8, "product"], [29, 32, "misc"], [43, 44, "organisation"], [45, 45, "product"], [47, 48, "organisation"], [49, 53, "product"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7], "relations": [[29, 32, 8, 8, "part-of", "", false, false], [45, 45, 43, 44, "artifact", "", false, false], [49, 53, 47, 48, "artifact", "", false, false]], "relations_mapping_to_source": [2, 3, 4], "sentence": ["On", "this", "page", ",", "Samurai", "Damashii", "exaggerated", "the", "Senkousha", "as", "the", "crystallisation", "of", "four", "thousand", "years", "of", "Chinese", "scientific", "knowledge", ",", "commented", "on", "the", "crude", "design", "(", "e.g.", "the", "Chinese", "cannon", "on", "the", "crotch", ")", "and", "placed", "it", "s", "image", "among", "those", "of", "Honda", "'s", "ASIMO", "and", "Sony", "'s", "QRIO", "SDR", "-", "3", "X", "for", "juxtaposition", "."], "sentence-detokenized": "On this page, Samurai Damashii exaggerated the Senkousha as the crystallisation of four thousand years of Chinese scientific knowledge, commented on the crude design (e.g. the Chinese cannon on the crotch) and placed its image among those of Honda's ASIMO and Sony's QRIO SDR-3X for juxtaposition.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 21], [22, 30], [31, 42], [43, 46], [47, 56], [57, 59], [60, 63], [64, 79], [80, 82], [83, 87], [88, 96], [97, 102], [103, 105], [106, 113], [114, 124], [125, 134], [134, 135], [136, 145], [146, 148], [149, 152], [153, 158], [159, 165], [166, 167], [167, 171], [172, 175], [176, 183], [184, 190], [191, 193], [194, 197], [198, 204], [204, 205], [206, 209], [210, 216], [217, 219], [219, 220], [221, 226], [227, 232], [233, 238], [239, 241], [242, 247], [247, 249], [250, 255], [256, 259], [260, 264], [264, 266], [267, 271], [272, 275], [275, 276], [276, 277], [277, 278], [279, 282], [283, 296], [296, 297]]}
{"doc_key": "ai-test-374", "ner": [[10, 11, "algorithm"], [24, 24, "product"], [26, 26, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 24, 24, "part-of", "includes_functionality_of", false, false], [10, 11, 26, 26, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "also", "a", "number", "of", "software", "libraries", "that", "incorporate", "neural", "network", "functionality", "and", "that", "can", "be", "used", "in", "custom", "implementations", "(", "such", "as", "TensorFlow", ",", "Theano", ",", "etc.", ")", "."], "sentence-detokenized": "There are also a number of software libraries that incorporate neural network functionality and that can be used in custom implementations (such as TensorFlow, Theano, etc.).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 16], [17, 23], [24, 26], [27, 35], [36, 45], [46, 50], [51, 62], [63, 69], [70, 77], [78, 91], [92, 95], [96, 100], [101, 104], [105, 107], [108, 112], [113, 115], [116, 122], [123, 138], [139, 140], [140, 144], [145, 147], [148, 158], [158, 159], [160, 166], [166, 167], [168, 172], [172, 173], [173, 174]]}
{"doc_key": "ai-test-375", "ner": [[5, 9, "conference"], [11, 11, "organisation"], [13, 19, "conference"], [21, 21, "conference"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "Fellow", "of", "the", "Association", "for", "Computing", "Machinery", ",", "IEEE", ",", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "IAPR", "and", "SPIE", "."], "sentence-detokenized": "He is a Fellow of the Association for Computing Machinery, IEEE, American Association for the Advancement of Science, IAPR and SPIE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 33], [34, 37], [38, 47], [48, 57], [57, 58], [59, 63], [63, 64], [65, 73], [74, 85], [86, 89], [90, 93], [94, 105], [106, 108], [109, 116], [116, 117], [118, 122], [123, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-test-376", "ner": [[1, 1, "organisation"], [6, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 6, 8, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "RET", "trial", "in", "2011", "with", "facial", "recognition", "system", "cameras", "mounted", "on", "trams", "ensured", "that", "people", "banned", "from", "city", "trams", "did", "not", "sneak", "on", "anyway", "."], "sentence-detokenized": "An RET trial in 2011 with facial recognition system cameras mounted on trams ensured that people banned from city trams did not sneak on anyway.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 20], [21, 25], [26, 32], [33, 44], [45, 51], [52, 59], [60, 67], [68, 70], [71, 76], [77, 84], [85, 89], [90, 96], [97, 103], [104, 108], [109, 113], [114, 119], [120, 123], [124, 127], [128, 133], [134, 136], [137, 143], [143, 144]]}
{"doc_key": "ai-test-377", "ner": [[2, 4, "person"], [6, 6, "organisation"], [17, 18, "person"], [20, 21, "person"], [25, 26, "person"], [28, 29, "person"], [31, 32, "person"], [34, 35, "person"], [37, 38, "person"], [40, 41, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[2, 4, 6, 6, "role", "works_for", false, false], [17, 18, 6, 6, "role", "works_for", false, false], [20, 21, 6, 6, "role", "works_for", false, false], [25, 26, 6, 6, "role", "works_for", false, false], [28, 29, 6, 6, "role", "works_for", false, false], [31, 32, 6, 6, "role", "works_for", false, false], [34, 35, 6, 6, "role", "works_for", false, false], [37, 38, 6, 6, "role", "works_for", false, false], [40, 41, 6, 6, "role", "works_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Adapted", "from", "Cole", "Porter", "'s", "popular", "Broadway", "musical", ",", "the", "film", "starred", "MGM", "'s", "songbird", "team", "of", "Howard", "Keel", "and", "Kathryn", "Grayson", ",", "supported", "by", "Ann", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Van", ",", "James", "Whitmore", ",", "Kurt", "Kashnar", "and", "Tommy", "Rall", "."], "sentence-detokenized": "Adapted from Cole Porter's popular Broadway musical, the film starred MGM's songbird team of Howard Keel and Kathryn Grayson, supported by Ann Miller, Keenan Wynn, Bobby Van, James Whitmore, Kurt Kashnar and Tommy Rall.", "token2charspan": [[0, 7], [8, 12], [13, 17], [18, 24], [24, 26], [27, 34], [35, 43], [44, 51], [51, 52], [53, 56], [57, 61], [62, 69], [70, 73], [73, 75], [76, 84], [85, 89], [90, 92], [93, 99], [100, 104], [105, 108], [109, 116], [117, 124], [124, 125], [126, 135], [136, 138], [139, 142], [143, 149], [149, 150], [151, 157], [158, 162], [162, 163], [164, 169], [170, 173], [173, 174], [175, 180], [181, 189], [189, 190], [191, 195], [196, 203], [204, 207], [208, 213], [214, 218], [218, 219]]}
{"doc_key": "ai-test-378", "ner": [[16, 19, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "applications", "should", "streamline", "call", "flows", ",", "minimise", "prompts", ",", "eliminate", "unnecessary", "iterations", "and", "enable", "extensive", "mixed", "-initiative", "dialogue", "systems", "that", "allow", "callers", "to", "enter", "several", "pieces", "of", "information", "in", "a", "single", "statement", "and", "in", "any", "order", "or", "combination", "."], "sentence-detokenized": "Such applications should streamline call flows, minimise prompts, eliminate unnecessary iterations and enable extensive mixed-initiative dialogue systems that allow callers to enter several pieces of information in a single statement and in any order or combination.", "token2charspan": [[0, 4], [5, 17], [18, 24], [25, 35], [36, 40], [41, 46], [46, 47], [48, 56], [57, 64], [64, 65], [66, 75], [76, 87], [88, 98], [99, 102], [103, 109], [110, 119], [120, 125], [125, 136], [137, 145], [146, 153], [154, 158], [159, 164], [165, 172], [173, 175], [176, 181], [182, 189], [190, 196], [197, 199], [200, 211], [212, 214], [215, 216], [217, 223], [224, 233], [234, 237], [238, 240], [241, 244], [245, 250], [251, 253], [254, 265], [265, 266]]}
{"doc_key": "ai-test-379", "ner": [[3, 4, "algorithm"], [7, 9, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 9, 3, 4, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Therefore", ",", "traditional", "gradient", "descent", "(", "or", "stochastic", "gradient", "descent", ")", "methods", "can", "be", "adapted", ",", "in", "which", ",", "instead", "of", "stepping", "in", "the", "direction", "of", "the", "gradient", "of", "the", "function", ",", "one", "steps", "in", "the", "direction", "of", "a", "vector", "selected", "from", "the", "subgradient", "of", "the", "function", "."], "sentence-detokenized": "Therefore, traditional gradient descent (or stochastic gradient descent) methods can be adapted, in which, instead of stepping in the direction of the gradient of the function, one steps in the direction of a vector selected from the subgradient of the function.", "token2charspan": [[0, 9], [9, 10], [11, 22], [23, 31], [32, 39], [40, 41], [41, 43], [44, 54], [55, 63], [64, 71], [71, 72], [73, 80], [81, 84], [85, 87], [88, 95], [95, 96], [97, 99], [100, 105], [105, 106], [107, 114], [115, 117], [118, 126], [127, 129], [130, 133], [134, 143], [144, 146], [147, 150], [151, 159], [160, 162], [163, 166], [167, 175], [175, 176], [177, 180], [181, 186], [187, 189], [190, 193], [194, 203], [204, 206], [207, 208], [209, 215], [216, 224], [225, 229], [230, 233], [234, 245], [246, 248], [249, 252], [253, 261], [261, 262]]}
{"doc_key": "ai-test-380", "ner": [[10, 12, "metrics"], [14, 17, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "distortion", "is", "assumed", "to", "be", "measured", "by", "the", "mean", "square", "error", ",", "the", "distortion", ",", "D", ",", "is", "given", "by", ":"], "sentence-detokenized": "If the distortion is assumed to be measured by the mean square error, the distortion, D, is given by:", "token2charspan": [[0, 2], [3, 6], [7, 17], [18, 20], [21, 28], [29, 31], [32, 34], [35, 43], [44, 46], [47, 50], [51, 55], [56, 62], [63, 68], [68, 69], [70, 73], [74, 84], [84, 85], [86, 87], [87, 88], [89, 91], [92, 97], [98, 100], [100, 101]]}
{"doc_key": "ai-test-381", "ner": [[0, 0, "algorithm"], [4, 5, "field"], [18, 19, "task"], [21, 22, "task"], [24, 25, "task"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 4, 5, "part-of", "", false, false], [18, 19, 0, 0, "part-of", "", false, false], [21, 22, 0, 0, "part-of", "", false, false], [24, 25, 0, 0, "part-of", "", false, false], [28, 29, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["MLPs", "were", "a", "popular", "machine", "learning", "solution", "in", "the", "1980s", ",", "finding", "applications", "in", "diverse", "fields", "such", "as", "speech", "recognition", ",", "image", "recognition", "and", "machine", "translation", "software", ",", "Neural", "Networks", "."], "sentence-detokenized": "MLPs were a popular machine learning solution in the 1980s, finding applications in diverse fields such as speech recognition, image recognition and machine translation software, Neural Networks.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 19], [20, 27], [28, 36], [37, 45], [46, 48], [49, 52], [53, 58], [58, 59], [60, 67], [68, 80], [81, 83], [84, 91], [92, 98], [99, 103], [104, 106], [107, 113], [114, 125], [125, 126], [127, 132], [133, 144], [145, 148], [149, 156], [157, 168], [169, 177], [177, 178], [179, 185], [186, 194], [194, 195]]}
{"doc_key": "ai-test-382", "ner": [[0, 0, "researcher"], [3, 4, "misc"], [6, 8, "university"], [16, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 8, "physical", "", false, false], [0, 0, 6, 8, "role", "", false, false], [3, 4, 0, 0, "origin", "", false, false], [16, 18, 0, 0, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "received", "his", "PhD", "from", "the", "University", "of", "Toronto", "in", "1979", ",", "under", "the", "supervision", "of", "C.", "Raymond", "Perrault", ","], "sentence-detokenized": "Allen received his PhD from the University of Toronto in 1979, under the supervision of C. Raymond Perrault,", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 22], [23, 27], [28, 31], [32, 42], [43, 45], [46, 53], [54, 56], [57, 61], [61, 62], [63, 68], [69, 72], [73, 84], [85, 87], [88, 90], [91, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-test-383", "ner": [[0, 0, "product"], [5, 6, "field"], [10, 10, "product"], [12, 12, "product"], [14, 14, "product"], [20, 20, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 5, 6, "related-to", "supports", false, false], [10, 10, 5, 6, "type-of", "", true, false], [12, 12, 5, 6, "type-of", "", true, false], [14, 14, 5, 6, "type-of", "", true, false], [14, 14, 20, 20, "related-to", "converting_to", true, false], [24, 24, 5, 6, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["OpenCV", "supports", "some", "models", "from", "deep", "learning", "frameworks", "such", "as", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "after", "conversion", "to", "the", "ONNX", "model", ")", "and", "Caffe", "according", "to", "a", "defined", "list", "of", "supported", "layers", "."], "sentence-detokenized": "OpenCV supports some models from deep learning frameworks such as TensorFlow, Torch, PyTorch (after conversion to the ONNX model) and Caffe according to a defined list of supported layers.", "token2charspan": [[0, 6], [7, 15], [16, 20], [21, 27], [28, 32], [33, 37], [38, 46], [47, 57], [58, 62], [63, 65], [66, 76], [76, 77], [78, 83], [83, 84], [85, 92], [93, 94], [94, 99], [100, 110], [111, 113], [114, 117], [118, 122], [123, 128], [128, 129], [130, 133], [134, 139], [140, 149], [150, 152], [153, 154], [155, 162], [163, 167], [168, 170], [171, 180], [181, 187], [187, 188]]}
{"doc_key": "ai-test-384", "ner": [[2, 2, "researcher"], [8, 11, "organisation"], [13, 13, "organisation"], [16, 20, "organisation"], [24, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 8, 11, "role", "", false, false], [2, 2, 16, 20, "role", "", false, false], [2, 2, 24, 24, "related-to", "lectures_in", false, false], [13, 13, 8, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Previously", ",", "Christensen", "was", "founding", "chairman", "of", "the", "European", "Robotics", "Research", "Network", "(", "EURON", ")", "and", "IEEE", "Robotics", "and", "Automation", "Society", "Distinguished", "Lecturer", "in", "Robotics", "."], "sentence-detokenized": "Previously, Christensen was founding chairman of the European Robotics Research Network (EURON) and IEEE Robotics and Automation Society Distinguished Lecturer in Robotics.", "token2charspan": [[0, 10], [10, 11], [12, 23], [24, 27], [28, 36], [37, 45], [46, 48], [49, 52], [53, 61], [62, 70], [71, 79], [80, 87], [88, 89], [89, 94], [94, 95], [96, 99], [100, 104], [105, 113], [114, 117], [118, 128], [129, 136], [137, 150], [151, 159], [160, 162], [163, 171], [171, 172]]}
{"doc_key": "ai-test-385", "ner": [[7, 8, "field"], [11, 13, "university"], [15, 15, "location"], [17, 20, "country"], [23, 24, "misc"], [26, 26, "field"], [29, 32, "organisation"], [33, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 13, 15, 15, "physical", "", false, false], [15, 15, 17, 20, "physical", "", false, false], [23, 24, 26, 26, "topic", "", false, false], [29, 32, 33, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "received", "his", "master", "'s", "degree", "in", "mathematics", "in", "1958", "from", "Samarkand", "State", "University", ",", "Samarkand", ",", "Uzbek", "Soviet", "Socialist", "Republic", ",", "and", "his", "PhD", "in", "statistics", "from", "the", "Institute", "of", "Control", "Sciences", "in", "Moscow", "in", "1964", "."], "sentence-detokenized": "He received his master's degree in mathematics in 1958 from Samarkand State University, Samarkand, Uzbek Soviet Socialist Republic, and his PhD in statistics from the Institute of Control Sciences in Moscow in 1964.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 22], [22, 24], [25, 31], [32, 34], [35, 46], [47, 49], [50, 54], [55, 59], [60, 69], [70, 75], [76, 86], [86, 87], [88, 97], [97, 98], [99, 104], [105, 111], [112, 121], [122, 130], [130, 131], [132, 135], [136, 139], [140, 143], [144, 146], [147, 157], [158, 162], [163, 166], [167, 176], [177, 179], [180, 187], [188, 196], [197, 199], [200, 206], [207, 209], [210, 214], [214, 215]]}
{"doc_key": "ai-test-386", "ner": [[7, 7, "organisation"], [12, 12, "product"], [30, 31, "field"], [33, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 30, 31, "usage", "", false, false], [7, 7, 33, 35, "usage", "", false, false], [12, 12, 7, 7, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Increasingly", ",", "however", ",", "the", "work", "at", "Cycorp", "is", "about", "giving", "the", "Cyc", "system", "the", "ability", "to", "communicate", "with", "end", "users", "in", "natural", "language", "and", "to", "support", "knowledge", "creation", "through", "machine", "learning", "and", "natural", "language", "understanding", "."], "sentence-detokenized": "Increasingly, however, the work at Cycorp is about giving the Cyc system the ability to communicate with end users in natural language and to support knowledge creation through machine learning and natural language understanding.", "token2charspan": [[0, 12], [12, 13], [14, 21], [21, 22], [23, 26], [27, 31], [32, 34], [35, 41], [42, 44], [45, 50], [51, 57], [58, 61], [62, 65], [66, 72], [73, 76], [77, 84], [85, 87], [88, 99], [100, 104], [105, 108], [109, 114], [115, 117], [118, 125], [126, 134], [135, 138], [139, 141], [142, 149], [150, 159], [160, 168], [169, 176], [177, 184], [185, 193], [194, 197], [198, 205], [206, 214], [215, 228], [228, 229]]}
{"doc_key": "ai-test-387", "ner": [[53, 53, "metrics"], [55, 55, "metrics"], [57, 57, "metrics"], [59, 60, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "if", "the", "most", "suitable", "classifier", "for", "a", "problem", "is", "sought", ",", "the", "training", "dataset", "is", "used", "to", "train", "candidate", "algorithms", ",", "the", "validation", "dataset", "is", "used", "to", "compare", "their", "performance", "and", "decide", "which", "one", "to", "take", ",", "and", "finally", "the", "test", "dataset", "is", "used", "to", "obtain", "performance", "characteristics", "such", "as", "accuracy", ",", "sensitivity", ",", "specificity", ",", "F-", "measure", "and", "so", "on", "."], "sentence-detokenized": "For example, if the most suitable classifier for a problem is sought, the training dataset is used to train candidate algorithms, the validation dataset is used to compare their performance and decide which one to take, and finally the test dataset is used to obtain performance characteristics such as accuracy, sensitivity, specificity, F-measure and so on.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 19], [20, 24], [25, 33], [34, 44], [45, 48], [49, 50], [51, 58], [59, 61], [62, 68], [68, 69], [70, 73], [74, 82], [83, 90], [91, 93], [94, 98], [99, 101], [102, 107], [108, 117], [118, 128], [128, 129], [130, 133], [134, 144], [145, 152], [153, 155], [156, 160], [161, 163], [164, 171], [172, 177], [178, 189], [190, 193], [194, 200], [201, 206], [207, 210], [211, 213], [214, 218], [218, 219], [220, 223], [224, 231], [232, 235], [236, 240], [241, 248], [249, 251], [252, 256], [257, 259], [260, 266], [267, 278], [279, 294], [295, 299], [300, 302], [303, 311], [311, 312], [313, 324], [324, 325], [326, 337], [337, 338], [339, 341], [341, 348], [349, 352], [353, 355], [356, 358], [358, 359]]}
{"doc_key": "ai-test-388", "ner": [[0, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "root", "mean", "square", "error", "is", "0.15", "."], "sentence-detokenized": "The root mean square error is 0.15.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 20], [21, 26], [27, 29], [30, 34], [34, 35]]}
{"doc_key": "ai-test-389", "ner": [[4, 5, "misc"], [10, 11, "organisation"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 4, 5, "role", "", false, false], [14, 15, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1979", ",", "a", "Micromouse", "competition", "was", "organised", "by", "the", "IEEE", "and", "featured", "in", "Spectrum", "magazine", "."], "sentence-detokenized": "In 1979, a Micromouse competition was organised by the IEEE and featured in Spectrum magazine.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 21], [22, 33], [34, 37], [38, 47], [48, 50], [51, 54], [55, 59], [60, 63], [64, 72], [73, 75], [76, 84], [85, 93], [93, 94]]}
{"doc_key": "ai-test-390", "ner": [[0, 2, "algorithm"], [8, 8, "field"], [12, 14, "task"], [16, 19, "task"], [18, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 8, 8, "part-of", "", false, false], [12, 14, 8, 8, "part-of", "task_part_of_field", false, false], [16, 19, 8, 8, "part-of", "task_part_of_field", false, false], [18, 18, 8, 8, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Gabor", "space", "is", "very", "useful", "for", "image", "processing", "applications", "such", "as", "optical", "character", "recognition", ",", "iris", "and", "fingerprint", "recognition", "."], "sentence-detokenized": "The Gabor space is very useful for image processing applications such as optical character recognition, iris and fingerprint recognition.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 18], [19, 23], [24, 30], [31, 34], [35, 40], [41, 51], [52, 64], [65, 69], [70, 72], [73, 80], [81, 90], [91, 102], [102, 103], [104, 108], [109, 112], [113, 124], [125, 136], [136, 137]]}
{"doc_key": "ai-test-391", "ner": [[7, 7, "programlang"], [9, 9, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", "via", "high", "-", "level", "interfaces", "to", "Java", "and", "Tcl", "."], "sentence-detokenized": "or via high-level interfaces to Java and Tcl.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [12, 17], [18, 28], [29, 31], [32, 36], [37, 40], [41, 44], [44, 45]]}
{"doc_key": "ai-test-392", "ner": [[10, 11, "algorithm"], [18, 18, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 18, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "recent", "studies", ",", "kernel", "-", "based", "methods", "such", "as", "support", "vector", "machines", "have", "shown", "higher", "performance", "in", "supervised", "."], "sentence-detokenized": "In recent studies, kernel-based methods such as support vector machines have shown higher performance in supervised.", "token2charspan": [[0, 2], [3, 9], [10, 17], [17, 18], [19, 25], [25, 26], [26, 31], [32, 39], [40, 44], [45, 47], [48, 55], [56, 62], [63, 71], [72, 76], [77, 82], [83, 89], [90, 101], [102, 104], [105, 115], [115, 116]]}
{"doc_key": "ai-test-393", "ner": [[17, 17, "misc"], [24, 24, "researcher"], [26, 26, "researcher"], [34, 34, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[24, 24, 34, 34, "usage", "", false, false], [26, 26, 34, 34, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["To", "illustrate", "the", "basic", "principles", "of", "bagging", ",", "the", "following", "is", "an", "analysis", "on", "the", "relationship", "between", "ozone", "and", "temperature", "(", "data", "are", "from", "Rousseeuw", "and", "Leroy", "(", "1986", ")", ",", "analysis", "done", "in", "R", ")", "."], "sentence-detokenized": "To illustrate the basic principles of bagging, the following is an analysis on the relationship between ozone and temperature (data are from Rousseeuw and Leroy (1986), analysis done in R).", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 23], [24, 34], [35, 37], [38, 45], [45, 46], [47, 50], [51, 60], [61, 63], [64, 66], [67, 75], [76, 78], [79, 82], [83, 95], [96, 103], [104, 109], [110, 113], [114, 125], [126, 127], [127, 131], [132, 135], [136, 140], [141, 150], [151, 154], [155, 160], [161, 162], [162, 166], [166, 167], [167, 168], [169, 177], [178, 182], [183, 185], [186, 187], [187, 188], [188, 189]]}
{"doc_key": "ai-test-394", "ner": [[0, 1, "organisation"], [11, 11, "product"], [18, 19, "product"], [21, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 0, 1, "artifact", "", false, false], [18, 19, 0, 1, "artifact", "", false, false], [21, 23, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Denso", "Wave", "is", "a", "subsidiary", "that", "manufactures", "automatic", "identification", "products", "(", "barcode", "readers", "and", "related", "products", ")", ",", "industrial", "robots", "and", "programmable", "logic", "controllers", "."], "sentence-detokenized": "Denso Wave is a subsidiary that manufactures automatic identification products (barcode readers and related products), industrial robots and programmable logic controllers.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 15], [16, 26], [27, 31], [32, 44], [45, 54], [55, 69], [70, 78], [79, 80], [80, 87], [88, 95], [96, 99], [100, 107], [108, 116], [116, 117], [117, 118], [119, 129], [130, 136], [137, 140], [141, 153], [154, 159], [160, 171], [171, 172]]}
{"doc_key": "ai-test-395", "ner": [[2, 4, "metrics"], [7, 9, "metrics"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 4, 17, 17, "compare", "", false, false], [7, 9, 2, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Where", "the", "Bilingual", "evaluation", "understudy", "simply", "calculates", "precisionn", "-", "grams", "by", "adding", "equal", "weight", "to", "each", ",", "NIST", "also", "calculates", "how", "informative", "a", "givenn", "-", "gram", "is", "."], "sentence-detokenized": "Where the Bilingual evaluation understudy simply calculates precisionn-grams by adding equal weight to each, NIST also calculates how informative a givenn-gram is.", "token2charspan": [[0, 5], [6, 9], [10, 19], [20, 30], [31, 41], [42, 48], [49, 59], [60, 70], [70, 71], [71, 76], [77, 79], [80, 86], [87, 92], [93, 99], [100, 102], [103, 107], [107, 108], [109, 113], [114, 118], [119, 129], [130, 133], [134, 145], [146, 147], [148, 154], [154, 155], [155, 159], [160, 162], [162, 163]]}
{"doc_key": "ai-test-396", "ner": [[12, 12, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "particular", ",", "they", "are", "used", "when", "calculating", "tree", "likelihoods", "(", "in", "Bayesian", "and", "maximum", "likelihood", "approaches", "to", "tree", "estimation", ")", "and", "are", "used", "to", "estimate", "the", "evolutionary", "distance", "between", "sequences", "based", "on", "observed", "differences", "between", "sequences", "."], "sentence-detokenized": "In particular, they are used when calculating tree likelihoods (in Bayesian and maximum likelihood approaches to tree estimation) and are used to estimate the evolutionary distance between sequences based on observed differences between sequences.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 19], [20, 23], [24, 28], [29, 33], [34, 45], [46, 50], [51, 62], [63, 64], [64, 66], [67, 75], [76, 79], [80, 87], [88, 98], [99, 109], [110, 112], [113, 117], [118, 128], [128, 129], [130, 133], [134, 137], [138, 142], [143, 145], [146, 154], [155, 158], [159, 171], [172, 180], [181, 188], [189, 198], [199, 204], [205, 207], [208, 216], [217, 228], [229, 236], [237, 246], [246, 247]]}
{"doc_key": "ai-test-397", "ner": [[0, 3, "conference"], [19, 20, "misc"], [22, 22, "misc"], [43, 44, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 19, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Audio", "Engineering", "Society", "recommends", "a", "48", "kHz", "sampling", "rate", "for", "most", "applications", ",", "but", "recognises", "44.1", "kHz", "for", "compact", "disc", "(", "CD", ")", "and", "other", "consumer", "applications", ",", "32", "kHz", "for", "broadcast", "applications", ",", "and", "96", "kHz", "for", "higher", "bandwidth", "or", "reduced", "anti-aliasing", "filter", "."], "sentence-detokenized": "The Audio Engineering Society recommends a 48 kHz sampling rate for most applications, but recognises 44.1 kHz for compact disc (CD) and other consumer applications, 32 kHz for broadcast applications, and 96 kHz for higher bandwidth or reduced anti-aliasing filter.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 29], [30, 40], [41, 42], [43, 45], [46, 49], [50, 58], [59, 63], [64, 67], [68, 72], [73, 85], [85, 86], [87, 90], [91, 101], [102, 106], [107, 110], [111, 114], [115, 122], [123, 127], [128, 129], [129, 131], [131, 132], [133, 136], [137, 142], [143, 151], [152, 164], [164, 165], [166, 168], [169, 172], [173, 176], [177, 186], [187, 199], [199, 200], [201, 204], [205, 207], [208, 211], [212, 215], [216, 222], [223, 232], [233, 235], [236, 243], [244, 257], [258, 264], [264, 265]]}
{"doc_key": "ai-test-398", "ner": [[11, 11, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Resources", "on", "the", "affectivity", "of", "words", "and", "concepts", "were", "made", "for", "WordNet", "{", "{", "cite", "journal"], "sentence-detokenized": "Resources on the affectivity of words and concepts were made for WordNet {{cite journal", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 28], [29, 31], [32, 37], [38, 41], [42, 50], [51, 55], [56, 60], [61, 64], [65, 72], [73, 74], [74, 75], [75, 79], [80, 87]]}
{"doc_key": "ai-test-399", "ner": [[1, 4, "misc"], [23, 24, "person"], [29, 33, "person"], [37, 39, "person"], [45, 50, "organisation"], [68, 68, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[29, 33, 37, 39, "role", "acts_in", false, false], [45, 50, 37, 39, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "red", "and", "green", "anaglyph", "presented", "the", "audience", "with", "three", "reels", "of", "test", "footage", ",", "which", "included", "rural", "scenes", ",", "test", "shots", "of", "Marie", "Doro", ",", "a", "segment", "of", "John", "B", ".", "Mason", "playing", "some", "excerpts", "from", "Jim", "the", "Penman", "(", "a", "film", "released", "by", "Famous", "Players", "-", "Lasky", "in", "the", "same", "year", ",", "but", "not", "in", "3D", ")", ",", "Oriental", "dancers", "and", "a", "reel", "of", "footage", "of", "Niagara", "Falls", "."], "sentence-detokenized": "The red and green anaglyph presented the audience with three reels of test footage, which included rural scenes, test shots of Marie Doro, a segment of John B. Mason playing some excerpts from Jim the Penman (a film released by Famous Players-Lasky in the same year, but not in 3D), Oriental dancers and a reel of footage of Niagara Falls.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 17], [18, 26], [27, 36], [37, 40], [41, 49], [50, 54], [55, 60], [61, 66], [67, 69], [70, 74], [75, 82], [82, 83], [84, 89], [90, 98], [99, 104], [105, 111], [111, 112], [113, 117], [118, 123], [124, 126], [127, 132], [133, 137], [137, 138], [139, 140], [141, 148], [149, 151], [152, 156], [157, 158], [158, 159], [160, 165], [166, 173], [174, 178], [179, 187], [188, 192], [193, 196], [197, 200], [201, 207], [208, 209], [209, 210], [211, 215], [216, 224], [225, 227], [228, 234], [235, 242], [242, 243], [243, 248], [249, 251], [252, 255], [256, 260], [261, 265], [265, 266], [267, 270], [271, 274], [275, 277], [278, 280], [280, 281], [281, 282], [283, 291], [292, 299], [300, 303], [304, 305], [306, 310], [311, 313], [314, 321], [322, 324], [325, 332], [333, 338], [338, 339]]}
{"doc_key": "ai-test-400", "ner": [[6, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "particular", "implementation", "of", "maximum", "likelihood", "estimation", "for", "this", "problem", "."], "sentence-detokenized": "This is a particular implementation of maximum likelihood estimation for this problem.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 20], [21, 35], [36, 38], [39, 46], [47, 57], [58, 68], [69, 72], [73, 77], [78, 85], [85, 86]]}
{"doc_key": "ai-test-401", "ner": [[0, 4, "product"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Crawler", "-", "friendly", "Web", "Servers", ",", "and", "integrates", "the", "features", "of", "sitemaps", "and", "RSS", "feeds", "into", "a", "decentralised", "mechanism", "for", "computational", "biologists", "and", "bioinformaticians", "to", "openly", "broadcast", "and", "download", "meta", "data", "on", "biomedical", "resources", "."], "sentence-detokenized": "Crawler-friendly Web Servers, and integrates the features of sitemaps and RSS feeds into a decentralised mechanism for computational biologists and bioinformaticians to openly broadcast and download meta data on biomedical resources.", "token2charspan": [[0, 7], [7, 8], [8, 16], [17, 20], [21, 28], [28, 29], [30, 33], [34, 44], [45, 48], [49, 57], [58, 60], [61, 69], [70, 73], [74, 77], [78, 83], [84, 88], [89, 90], [91, 104], [105, 114], [115, 118], [119, 132], [133, 143], [144, 147], [148, 165], [166, 168], [169, 175], [176, 185], [186, 189], [190, 198], [199, 203], [204, 208], [209, 211], [212, 222], [223, 232], [232, 233]]}
{"doc_key": "ai-test-402", "ner": [[5, 12, "misc"], [16, 21, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "covered", "by", "the", "American", "National", "Standards", "Institute", "/", "NISO", "standard", "Z39.50", ",", "and", "the", "International", "Organisation", "for", "Standardisation", "standard", "23950", "."], "sentence-detokenized": "It is covered by the American National Standards Institute / NISO standard Z39.50, and the International Organisation for Standardisation standard 23950.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 20], [21, 29], [30, 38], [39, 48], [49, 58], [59, 60], [61, 65], [66, 74], [75, 81], [81, 82], [83, 86], [87, 90], [91, 104], [105, 117], [118, 121], [122, 137], [138, 146], [147, 152], [152, 153]]}
{"doc_key": "ai-test-403", "ner": [[13, 17, "misc"], [23, 25, "metrics"], [27, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "encoder", "and", "decoder", "are", "trained", "to", "take", "a", "phrase", "and", "reproduce", "the", "one", "-", "hot", "distribution", "of", "the", "corresponding", "paraphrase", "by", "minimising", "perplexity", "using", "a", "simple", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The encoder and decoder are trained to take a phrase and reproduce the one-hot distribution of the corresponding paraphrase by minimising perplexity using a simple stochastic gradient descent.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 27], [28, 35], [36, 38], [39, 43], [44, 45], [46, 52], [53, 56], [57, 66], [67, 70], [71, 74], [74, 75], [75, 78], [79, 91], [92, 94], [95, 98], [99, 112], [113, 123], [124, 126], [127, 137], [138, 148], [149, 154], [155, 156], [157, 163], [164, 174], [175, 183], [184, 191], [191, 192]]}
{"doc_key": "ai-test-404", "ner": [[4, 5, "field"], [8, 9, "task"], [12, 17, "task"], [26, 31, "task"], [33, 43, "task"], [40, 46, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 4, 5, "part-of", "task_part_of_field", false, false], [12, 17, 4, 5, "part-of", "task_part_of_field", false, false], [26, 31, 4, 5, "part-of", "task_part_of_field", false, false], [33, 43, 4, 5, "part-of", "task_part_of_field", false, false], [40, 46, 4, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "typical", "applications", "of", "pattern", "recognition", "techniques", "include", "automatic", "speech", "recognition", ",", "classification", "of", "text", "into", "several", "categories", "(", "e.g.", "spam", "/", "spam", "emails", ")", ",", "recognition", "of", "handwriting", "on", "postal", "envelopes", ",", "automatic", "recognition", "of", "human", "face", "images", "or", "extraction", "of", "handwriting", "images", "from", "medical", "forms", "."], "sentence-detokenized": "Other typical applications of pattern recognition techniques include automatic speech recognition, classification of text into several categories (e.g. spam/spam emails), recognition of handwriting on postal envelopes, automatic recognition of human face images or extraction of handwriting images from medical forms.", "token2charspan": [[0, 5], [6, 13], [14, 26], [27, 29], [30, 37], [38, 49], [50, 60], [61, 68], [69, 78], [79, 85], [86, 97], [97, 98], [99, 113], [114, 116], [117, 121], [122, 126], [127, 134], [135, 145], [146, 147], [147, 151], [152, 156], [156, 157], [157, 161], [162, 168], [168, 169], [169, 170], [171, 182], [183, 185], [186, 197], [198, 200], [201, 207], [208, 217], [217, 218], [219, 228], [229, 240], [241, 243], [244, 249], [250, 254], [255, 261], [262, 264], [265, 275], [276, 278], [279, 290], [291, 297], [298, 302], [303, 310], [311, 316], [316, 317]]}
{"doc_key": "ai-test-405", "ner": [[0, 2, "algorithm"], [13, 14, "field"], [16, 17, "task"], [18, 20, "task"], [22, 24, "task"], [26, 30, "task"], [32, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 14, 0, 2, "usage", "", false, false], [16, 17, 0, 2, "usage", "", false, false], [18, 20, 0, 2, "usage", "", false, false], [22, 24, 0, 2, "usage", "", false, false], [26, 30, 0, 2, "usage", "", false, false], [32, 33, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Artificial", "neural", "networks", "have", "been", "used", "for", "a", "number", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "playing", "board", "and", "video", "games", "and", "medical", "diagnostics", "."], "sentence-detokenized": "Artificial neural networks have been used for a number of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games and medical diagnostics.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 31], [32, 36], [37, 41], [42, 45], [46, 47], [48, 54], [55, 57], [58, 63], [63, 64], [65, 74], [75, 83], [84, 90], [90, 91], [92, 98], [99, 110], [110, 111], [112, 119], [120, 131], [131, 132], [133, 139], [140, 147], [148, 157], [157, 158], [159, 166], [167, 172], [173, 176], [177, 182], [183, 188], [189, 192], [193, 200], [201, 212], [212, 213]]}
{"doc_key": "ai-test-406", "ner": [[2, 3, "organisation"], [4, 4, "product"], [13, 13, "product"], [17, 17, "organisation"], [18, 19, "product"], [21, 21, "product"], [23, 25, "product"], [27, 27, "product"], [29, 29, "programlang"], [38, 39, "field"], [43, 43, "product"], [48, 48, "algorithm"], [50, 50, "algorithm"], [52, 52, "algorithm"], [56, 56, "product"], [64, 66, "task"], [70, 71, "algorithm"], [75, 75, "product"], [77, 77, "product"], [79, 81, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "relations": [[4, 4, 2, 3, "origin", "", false, false], [4, 4, 13, 13, "named", "same", false, false], [4, 4, 43, 43, "named", "same", false, false], [29, 29, 38, 39, "related-to", "used_for", false, false], [48, 48, 29, 29, "part-of", "", true, false], [48, 48, 43, 43, "origin", "", true, false], [50, 50, 29, 29, "part-of", "", true, false], [50, 50, 43, 43, "origin", "", true, false], [52, 52, 29, 29, "part-of", "", true, false], [52, 52, 43, 43, "origin", "", true, false], [56, 56, 64, 66, "related-to", "used_for", false, false], [70, 71, 56, 56, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Examples", "include", "Salford", "Systems", "CART", "(", "which", "licensed", "proprietary", "code", "from", "the", "original", "CART", "authors", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "an", "open", "-", "source", "software", "environment", "for", "statistical", "computing", "that", "includes", "several", "CART", "implementations", "such", "as", "the", "rpart", ",", "party", "and", "randomForest", "packages", ")", ",", "Weka", "(", "a", "free", "and", "open", "-", "source", "data", "mining", "package", ",", "includes", "many", "decision", "tree", "algorithms", ")", ",", "Orange", ",", "KNIME", ",", "Microsoft", "SQL", "Server", "programming", "language", ")", "."], "sentence-detokenized": "Examples include Salford Systems CART (which licensed proprietary code from the original CART authors), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (an open-source software environment for statistical computing that includes several CART implementations such as the rpart, party and randomForest packages), Weka (a free and open-source data mining package, includes many decision tree algorithms), Orange, KNIME, Microsoft SQL Server programming language).", "token2charspan": [[0, 8], [9, 16], [17, 24], [25, 32], [33, 37], [38, 39], [39, 44], [45, 53], [54, 65], [66, 70], [71, 75], [76, 79], [80, 88], [89, 93], [94, 101], [101, 102], [102, 103], [104, 107], [108, 112], [113, 120], [120, 121], [122, 132], [132, 133], [134, 137], [138, 148], [149, 154], [154, 155], [156, 162], [162, 163], [164, 165], [166, 167], [167, 169], [170, 174], [174, 175], [175, 181], [182, 190], [191, 202], [203, 206], [207, 218], [219, 228], [229, 233], [234, 242], [243, 250], [251, 255], [256, 271], [272, 276], [277, 279], [280, 283], [284, 289], [289, 290], [291, 296], [297, 300], [301, 313], [314, 322], [322, 323], [323, 324], [325, 329], [330, 331], [331, 332], [333, 337], [338, 341], [342, 346], [346, 347], [347, 353], [354, 358], [359, 365], [366, 373], [373, 374], [375, 383], [384, 388], [389, 397], [398, 402], [403, 413], [413, 414], [414, 415], [416, 422], [422, 423], [424, 429], [429, 430], [431, 440], [441, 444], [445, 451], [452, 463], [464, 472], [472, 473], [473, 474]]}
{"doc_key": "ai-test-407", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [10, 11, "researcher"], [13, 14, "university"], [16, 17, "researcher"], [19, 22, "organisation"], [24, 24, "organisation"], [33, 35, "researcher"], [37, 40, "researcher"], [41, 44, "organisation"], [56, 61, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 10, 11, "origin", "", false, false], [0, 2, 16, 17, "origin", "", false, false], [0, 2, 33, 35, "origin", "", false, false], [0, 2, 37, 40, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [10, 11, 13, 14, "physical", "", false, false], [10, 11, 13, 14, "role", "", false, false], [16, 17, 19, 22, "physical", "", false, false], [16, 17, 19, 22, "role", "", false, false], [24, 24, 19, 22, "named", "", false, false], [33, 35, 41, 44, "physical", "", false, false], [33, 35, 41, 44, "role", "", false, false], [37, 40, 41, 44, "physical", "", false, false], [37, 40, 41, 44, "role", "", false, false], [56, 61, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", "was", "first", "developed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", ",", "and", "further", "developed", "by", "Bishnu", "S.", "Atala", "and", "Manfred", "R.", "Schroeder", "at", "Bell", "Labs", "in", "the", "early", "to", "mid", "1970s", ",", "becoming", "the", "basis", "for", "the", "first", "speech", "synthesis", "DSP", "chips", "in", "the", "late", "1970s", "."], "sentence-detokenized": "Linear predictive coding (LPC) was first developed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966, and further developed by Bishnu S. Atala and Manfred R. Schroeder at Bell Labs in the early to mid 1970s, becoming the basis for the first speech synthesis DSP chips in the late 1970s.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [31, 34], [35, 40], [41, 50], [51, 53], [54, 62], [63, 70], [71, 73], [74, 80], [81, 91], [92, 95], [96, 101], [102, 107], [108, 110], [111, 117], [118, 127], [128, 131], [132, 141], [142, 143], [143, 146], [146, 147], [148, 150], [151, 155], [155, 156], [157, 160], [161, 168], [169, 178], [179, 181], [182, 188], [189, 191], [192, 197], [198, 201], [202, 209], [210, 212], [213, 222], [223, 225], [226, 230], [231, 235], [236, 238], [239, 242], [243, 248], [249, 251], [252, 255], [256, 261], [261, 262], [263, 271], [272, 275], [276, 281], [282, 285], [286, 289], [290, 295], [296, 302], [303, 312], [313, 316], [317, 322], [323, 325], [326, 329], [330, 334], [335, 340], [340, 341]]}
{"doc_key": "ai-test-408", "ner": [[0, 3, "metrics"], [8, 8, "metrics"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 0, 3, "part-of", "", false, false], [10, 10, 0, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "F", "-", "score", "is", "a", "combination", "of", "precision", "and", "recall", ",", "giving", "a", "single", "score", "."], "sentence-detokenized": "The F-score is a combination of precision and recall, giving a single score.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 16], [17, 28], [29, 31], [32, 41], [42, 45], [46, 52], [52, 53], [54, 60], [61, 62], [63, 69], [70, 75], [75, 76]]}
{"doc_key": "ai-test-409", "ner": [[0, 1, "field"], [8, 11, "task"], [16, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 0, 1, "part-of", "task_part_of_field", false, false], [16, 19, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Image", "analysis", "tasks", "can", "be", "as", "simple", "as", "reading", "barcodes", "d", "tags", "or", "as", "advanced", "as", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Image analysis tasks can be as simple as reading barcodes d tags or as advanced as a facial recognition system.", "token2charspan": [[0, 5], [6, 14], [15, 20], [21, 24], [25, 27], [28, 30], [31, 37], [38, 40], [41, 48], [49, 57], [58, 59], [60, 64], [65, 67], [68, 70], [71, 79], [80, 82], [83, 84], [85, 91], [92, 103], [104, 110], [110, 111]]}
{"doc_key": "ai-test-410", "ner": [[5, 7, "algorithm"], [25, 26, "algorithm"], [33, 35, "algorithm"], [38, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[33, 35, 25, 26, "type-of", "", false, false], [38, 38, 33, 35, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "special", "case", "of", "linear", "support", "vector", "machines", "can", "be", "solved", "more", "efficiently", "by", "the", "same", "type", "of", "algorithms", "to", "optimise", "its", "close", "cousin", ",", "logistic", "regression", ";", "this", "class", "of", "algorithms", "includes", "Stochastic", "gradient", "descent", "(", "e.g.", "PEGASOS", ")", "."], "sentence-detokenized": "The special case of linear support vector machines can be solved more efficiently by the same type of algorithms to optimise its close cousin, logistic regression; this class of algorithms includes Stochastic gradient descent (e.g. PEGASOS).", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 19], [20, 26], [27, 34], [35, 41], [42, 50], [51, 54], [55, 57], [58, 64], [65, 69], [70, 81], [82, 84], [85, 88], [89, 93], [94, 98], [99, 101], [102, 112], [113, 115], [116, 124], [125, 128], [129, 134], [135, 141], [141, 142], [143, 151], [152, 162], [162, 163], [164, 168], [169, 174], [175, 177], [178, 188], [189, 197], [198, 208], [209, 217], [218, 225], [226, 227], [227, 231], [232, 239], [239, 240], [240, 241]]}
{"doc_key": "ai-test-411", "ner": [[1, 1, "product"], [4, 4, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 4, 4, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["When", "Siri", "on", "an", "iOS", "device", "is", "asked", "Do", "you", "have", "a", "pet", ",", "one", "of", "the", "answers", "is", "I", "used", "to", "have", "an", "AIBO", "."], "sentence-detokenized": "When Siri on an iOS device is asked Do you have a pet, one of the answers is I used to have an AIBO.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 15], [16, 19], [20, 26], [27, 29], [30, 35], [36, 38], [39, 42], [43, 47], [48, 49], [50, 53], [53, 54], [55, 58], [59, 61], [62, 65], [66, 73], [74, 76], [77, 78], [79, 83], [84, 86], [87, 91], [92, 94], [95, 99], [99, 100]]}
{"doc_key": "ai-test-412", "ner": [[1, 1, "task"], [4, 6, "metrics"], [11, 12, "metrics"], [2, 14, "metrics"]], "ner_mapping_to_source": [0, 1, 3, 4], "relations": [[4, 6, 1, 1, "part-of", "", false, false], [11, 12, 1, 1, "part-of", "", false, false], [2, 14, 11, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["In", "information", "retrieval", ",", "positive", "predictive", "value", "is", "called", "precision", "and", "sensitivity", "is", "called", "recall", "."], "sentence-detokenized": "In information retrieval, positive predictive value is called precision and sensitivity is called recall.", "token2charspan": [[0, 2], [3, 14], [15, 24], [24, 25], [26, 34], [35, 45], [46, 51], [52, 54], [55, 61], [62, 71], [72, 75], [76, 87], [88, 90], [91, 97], [98, 104], [104, 105]]}
{"doc_key": "ai-test-413", "ner": [[11, 11, "field"], [14, 14, "task"], [16, 16, "task"], [18, 19, "task"], [32, 33, "task"], [35, 36, "task"], [38, 42, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 14, 11, 11, "part-of", "task_part_of_field", false, false], [16, 16, 11, 11, "part-of", "task_part_of_field", false, false], [18, 19, 11, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "particular", ",", "his", "research", "has", "focused", "on", "areas", "such", "as", "text", "mining", "(", "extraction", ",", "categorisation", ",", "novelty", "detection", ")", "and", "on", "new", "theoretical", "frameworks", "such", "as", "unified", "utility", "theory", "combining", "information", "retrieval", ",", "automatic", "summarisation", ",", "free", "-", "text", "question", "answering", "and", "related", "tasks", "."], "sentence-detokenized": "In particular, his research has focused on areas such as text mining (extraction, categorisation, novelty detection) and on new theoretical frameworks such as unified utility theory combining information retrieval, automatic summarisation, free-text question answering and related tasks.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 27], [28, 31], [32, 39], [40, 42], [43, 48], [49, 53], [54, 56], [57, 61], [62, 68], [69, 70], [70, 80], [80, 81], [82, 96], [96, 97], [98, 105], [106, 115], [115, 116], [117, 120], [121, 123], [124, 127], [128, 139], [140, 150], [151, 155], [156, 158], [159, 166], [167, 174], [175, 181], [182, 191], [192, 203], [204, 213], [213, 214], [215, 224], [225, 238], [238, 239], [240, 244], [244, 245], [245, 249], [250, 258], [259, 268], [269, 272], [273, 280], [281, 286], [286, 287]]}
{"doc_key": "ai-test-414", "ner": [[0, 1, "product"], [6, 6, "product"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 0, 1, "part-of", "", false, false], [15, 16, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Delta", "robots", "have", "base", "-", "mounted", "rotary", "actuators", "that", "move", "a", "lightweight", ",", "rigid", ",", "parallelogrammed", "arm", "."], "sentence-detokenized": "Delta robots have base-mounted rotary actuators that move a lightweight, rigid, parallelogrammed arm.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 22], [22, 23], [23, 30], [31, 37], [38, 47], [48, 52], [53, 57], [58, 59], [60, 71], [71, 72], [73, 78], [78, 79], [80, 96], [97, 100], [100, 101]]}
{"doc_key": "ai-test-415", "ner": [[8, 12, "metrics"], [15, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "as", "a", "2", "\u00d7", "2", "contingency", "table", ",", "or", "confusion", "matrix", ",", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated as a 2 \u00d7 2 contingency table, or confusion matrix, as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [63, 64], [65, 67], [68, 77], [78, 84], [84, 85], [86, 88], [89, 96], [96, 97]]}
{"doc_key": "ai-test-416", "ner": [[31, 32, "task"], [38, 39, "task"], [45, 47, "task"], [49, 51, "task"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "actual", "task", "of", "data", "mining", "is", "the", "semi-automatic", "or", "automatic", "analysis", "of", "large", "amounts", "of", "data", "to", "extract", "unknown", "patterns", "of", "interest", ",", "such", "as", "groups", "of", "data", "records", "(", "cluster", "analysis", ")", ",", "unusual", "records", "(", "anomaly", "detection", ")", ",", "or", "relationships", "(", "association", "rule", "mining", ",", "sequence", "pattern", "mining", ")", "."], "sentence-detokenized": "The actual task of data mining is the semi-automatic or automatic analysis of large amounts of data to extract unknown patterns of interest, such as groups of data records (cluster analysis), unusual records (anomaly detection), or relationships (association rule mining, sequence pattern mining).", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 18], [19, 23], [24, 30], [31, 33], [34, 37], [38, 52], [53, 55], [56, 65], [66, 74], [75, 77], [78, 83], [84, 91], [92, 94], [95, 99], [100, 102], [103, 110], [111, 118], [119, 127], [128, 130], [131, 139], [139, 140], [141, 145], [146, 148], [149, 155], [156, 158], [159, 163], [164, 171], [172, 173], [173, 180], [181, 189], [189, 190], [190, 191], [192, 199], [200, 207], [208, 209], [209, 216], [217, 226], [226, 227], [227, 228], [229, 231], [232, 245], [246, 247], [247, 258], [259, 263], [264, 270], [270, 271], [272, 280], [281, 288], [289, 295], [295, 296], [296, 297]]}
{"doc_key": "ai-test-417", "ner": [[2, 3, "product"], [5, 6, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 5, 6, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "a", "recommender", "system", ",", "sentiment", "analysis", "has", "proven", "to", "be", "a", "valuable", "technique", "."], "sentence-detokenized": "For a recommender system, sentiment analysis has proven to be a valuable technique.", "token2charspan": [[0, 3], [4, 5], [6, 17], [18, 24], [24, 25], [26, 35], [36, 44], [45, 48], [49, 55], [56, 58], [59, 61], [62, 63], [64, 72], [73, 82], [82, 83]]}
{"doc_key": "ai-test-418", "ner": [[3, 3, "misc"], [9, 9, "product"], [33, 33, "organisation"], [37, 38, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 9, 9, "usage", "", false, false], [33, 33, 37, 38, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Coincidentally", ",", "the", "Germans", "got", "the", "frequency", "of", "the", "Wotan", "system", "very", "wrong", ";", "it", "was", "operating", "on", "45", "MHz", ",", "which", "just", "happened", "to", "be", "the", "frequency", "of", "the", "powerful", "but", "dormant", "BBC", "TV", "transmitter", "at", "Alexandra", "Palace", "."], "sentence-detokenized": "Coincidentally, the Germans got the frequency of the Wotan system very wrong; it was operating on 45 MHz, which just happened to be the frequency of the powerful but dormant BBC TV transmitter at Alexandra Palace.", "token2charspan": [[0, 14], [14, 15], [16, 19], [20, 27], [28, 31], [32, 35], [36, 45], [46, 48], [49, 52], [53, 58], [59, 65], [66, 70], [71, 76], [76, 77], [78, 80], [81, 84], [85, 94], [95, 97], [98, 100], [101, 104], [104, 105], [106, 111], [112, 116], [117, 125], [126, 128], [129, 131], [132, 135], [136, 145], [146, 148], [149, 152], [153, 161], [162, 165], [166, 173], [174, 177], [178, 180], [181, 192], [193, 195], [196, 205], [206, 212], [212, 213]]}
{"doc_key": "ai-test-419", "ner": [[8, 12, "metrics"], [15, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "as", "a", "2", "\u00d7", "2", "contingency", "table", ",", "or", "confusion", "matrix", ",", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated as a 2 \u00d7 2 contingency table, or confusion matrix, as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [63, 64], [65, 67], [68, 77], [78, 84], [84, 85], [86, 88], [89, 96], [96, 97]]}
{"doc_key": "ai-test-420", "ner": [[1, 3, "misc"], [11, 11, "misc"], [15, 15, "product"], [17, 17, "product"], [19, 21, "product"], [29, 29, "misc"], [43, 45, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 15, 11, 11, "usage", "", false, false], [17, 17, 11, 11, "usage", "", false, false], [19, 21, 17, 17, "named", "", false, false], [29, 29, 11, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "Semantic", "Web", "applications", ",", "as", "well", "as", "in", "relatively", "popular", "RDF", "applications", "such", "as", "RSS", "or", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "resources", "are", "usually", "represented", "by", "URIs", "that", "intentionally", "tag", "and", "can", "be", "used", "to", "access", "actual", "data", "on", "the", "World", "Wide", "Web", "."], "sentence-detokenized": "In Semantic Web applications, as well as in relatively popular RDF applications such as RSS or FOAF (Friend a Friend), resources are usually represented by URIs that intentionally tag and can be used to access actual data on the World Wide Web.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 28], [28, 29], [30, 32], [33, 37], [38, 40], [41, 43], [44, 54], [55, 62], [63, 66], [67, 79], [80, 84], [85, 87], [88, 91], [92, 94], [95, 99], [100, 101], [101, 107], [108, 109], [110, 116], [116, 117], [117, 118], [119, 128], [129, 132], [133, 140], [141, 152], [153, 155], [156, 160], [161, 165], [166, 179], [180, 183], [184, 187], [188, 191], [192, 194], [195, 199], [200, 202], [203, 209], [210, 216], [217, 221], [222, 224], [225, 228], [229, 234], [235, 239], [240, 243], [243, 244]]}
{"doc_key": "ai-test-421", "ner": [[0, 7, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "has", "researched", "the", "subject", "in", "depth"], "sentence-detokenized": "The Association for the Advancement of Artificial Intelligence has researched the subject in depth", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 35], [36, 38], [39, 49], [50, 62], [63, 66], [67, 77], [78, 81], [82, 89], [90, 92], [93, 98]]}
{"doc_key": "ai-test-422", "ner": [[5, 9, "product"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 16, 5, 9, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Starting", "as", "a", "curiosity", ",", "the", "Apple", "Macintosh", "speech", "system", "has", "evolved", "into", "a", "fully", "supported", "PlainTalk", "programme", ",", "for", "people", "with", "sight", "problems", "."], "sentence-detokenized": "Starting as a curiosity, the Apple Macintosh speech system has evolved into a fully supported PlainTalk programme, for people with sight problems.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 23], [23, 24], [25, 28], [29, 34], [35, 44], [45, 51], [52, 58], [59, 62], [63, 70], [71, 75], [76, 77], [78, 83], [84, 93], [94, 103], [104, 113], [113, 114], [115, 118], [119, 125], [126, 130], [131, 136], [137, 145], [145, 146]]}
{"doc_key": "ai-test-423", "ner": [[6, 6, "field"], [8, 9, "task"], [11, 12, "task"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 6, 6, "part-of", "task_part_of_field", false, false], [11, 12, 6, 6, "part-of", "task_part_of_field", false, false], [14, 15, 6, 6, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Other", "areas", "of", "ontology", "use", "in", "NLP", "include", "information", "retrieval", ",", "information", "extraction", "and", "automatic", "summarisation", "."], "sentence-detokenized": "Other areas of ontology use in NLP include information retrieval, information extraction and automatic summarisation.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 23], [24, 27], [28, 30], [31, 34], [35, 42], [43, 54], [55, 64], [64, 65], [66, 77], [78, 88], [89, 92], [93, 102], [103, 116], [116, 117]]}
{"doc_key": "ai-test-424", "ner": [[7, 14, "organisation"], [16, 21, "organisation"], [24, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "institute", "has", "worked", "closely", "with", "the", "Janelia", "Farm", "Campus", "of", "Howard", "Hughes", "Medical", "Institute", ",", "the", "Allen", "Institute", "for", "Brain", "Science", "and", "the", "National", "Institutes", "of", "Health", "to", "develop", "better", "methods", "for", "reconstructing", "neuronal", "architectures", "."], "sentence-detokenized": "The institute has worked closely with the Janelia Farm Campus of Howard Hughes Medical Institute, the Allen Institute for Brain Science and the National Institutes of Health to develop better methods for reconstructing neuronal architectures.", "token2charspan": [[0, 3], [4, 13], [14, 17], [18, 24], [25, 32], [33, 37], [38, 41], [42, 49], [50, 54], [55, 61], [62, 64], [65, 71], [72, 78], [79, 86], [87, 96], [96, 97], [98, 101], [102, 107], [108, 117], [118, 121], [122, 127], [128, 135], [136, 139], [140, 143], [144, 152], [153, 163], [164, 166], [167, 173], [174, 176], [177, 184], [185, 191], [192, 199], [200, 203], [204, 218], [219, 227], [228, 241], [241, 242]]}
{"doc_key": "ai-test-425", "ner": [[0, 0, "organisation"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 0, 0, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Google", "recently", "announced", "that", "Google", "Translate", "translates", "roughly", "enough", "text", "to", "fill", "1", "million", "books", "in", "one", "day", "(", "2012", ")", "."], "sentence-detokenized": "Google recently announced that Google Translate translates roughly enough text to fill 1 million books in one day (2012).", "token2charspan": [[0, 6], [7, 15], [16, 25], [26, 30], [31, 37], [38, 47], [48, 58], [59, 66], [67, 73], [74, 78], [79, 81], [82, 86], [87, 88], [89, 96], [97, 102], [103, 105], [106, 109], [110, 113], [114, 115], [115, 119], [119, 120], [120, 121]]}
{"doc_key": "ai-test-426", "ner": [[13, 13, "country"], [15, 15, "country"], [17, 17, "country"], [19, 19, "country"], [21, 21, "country"], [23, 25, "country"], [33, 34, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Events", "are", "held", "around", "the", "world", ",", "with", "the", "most", "popular", "in", "the", "UK", ",", "US", ",", "Japan", ",", "Singapore", ",", "India", ",", "South", "Korea", "and", "becoming", "popular", "in", "sub-continental", "countries", "such", "as", "Sri", "Lanka", "."], "sentence-detokenized": "Events are held around the world, with the most popular in the UK, US, Japan, Singapore, India, South Korea and becoming popular in sub-continental countries such as Sri Lanka.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 22], [23, 26], [27, 32], [32, 33], [34, 38], [39, 42], [43, 47], [48, 55], [56, 58], [59, 62], [63, 65], [65, 66], [67, 69], [69, 70], [71, 76], [76, 77], [78, 87], [87, 88], [89, 94], [94, 95], [96, 101], [102, 107], [108, 111], [112, 120], [121, 128], [129, 131], [132, 147], [148, 157], [158, 162], [163, 165], [166, 169], [170, 175], [175, 176]]}
{"doc_key": "ai-test-427", "ner": [[6, 6, "programlang"], [11, 11, "programlang"], [13, 13, "programlang"], [15, 16, "programlang"], [18, 18, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "packages", "are", "mainly", "developed", "in", "R", ",", "and", "sometimes", "in", "Java", ",", "C", ",", "C", "++", "and", "Fortran", "."], "sentence-detokenized": "These packages are mainly developed in R, and sometimes in Java, C, C ++ and Fortran.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 25], [26, 35], [36, 38], [39, 40], [40, 41], [42, 45], [46, 55], [56, 58], [59, 63], [63, 64], [65, 66], [66, 67], [68, 69], [70, 72], [73, 76], [77, 84], [84, 85]]}
{"doc_key": "ai-test-428", "ner": [[2, 9, "conference"], [7, 7, "conference"], [11, 11, "researcher"], [13, 13, "researcher"], [17, 18, "researcher"], [21, 22, "algorithm"], [27, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 7, 2, 9, "named", "", false, false], [11, 11, 2, 9, "physical", "", false, false], [11, 11, 2, 9, "role", "", false, false], [11, 11, 17, 18, "role", "teams_up_with", false, false], [11, 11, 21, 22, "usage", "", false, false], [13, 13, 2, 9, "physical", "", false, false], [13, 13, 2, 9, "role", "", false, false], [13, 13, 17, 18, "role", "teams_up_with", false, false], [13, 13, 21, 22, "usage", "", false, false], [17, 18, 2, 9, "physical", "", false, false], [17, 18, 2, 9, "role", "", false, false], [17, 18, 21, 22, "usage", "", false, false], [21, 22, 27, 32, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["At", "the", "European", "Computer", "Vision", "Conference", "(", "ECCV", ")", "2006", ",", "Dalal", "and", "Triggs", ",", "together", "with", "Cordelia", "Schmid", ",", "applied", "HOG", "detectors", "to", "the", "problem", "of", "detecting", "people", "in", "films", "and", "videos", "."], "sentence-detokenized": "At the European Computer Vision Conference (ECCV) 2006, Dalal and Triggs, together with Cordelia Schmid, applied HOG detectors to the problem of detecting people in films and videos.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 24], [25, 31], [32, 42], [43, 44], [44, 48], [48, 49], [50, 54], [54, 55], [56, 61], [62, 65], [66, 72], [72, 73], [74, 82], [83, 87], [88, 96], [97, 103], [103, 104], [105, 112], [113, 116], [117, 126], [127, 129], [130, 133], [134, 141], [142, 144], [145, 154], [155, 161], [162, 164], [165, 170], [171, 174], [175, 181], [181, 182]]}
{"doc_key": "ai-test-429", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [10, 12, "task"], [19, 21, "metrics"], [23, 23, "metrics"], [29, 29, "metrics"], [32, 35, "metrics"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 3, 10, 12, "related-to", "measured_with", false, false], [5, 5, 10, 12, "related-to", "measured_with", false, false], [19, 21, 10, 12, "related-to", "measured_with", false, false], [23, 23, 19, 21, "named", "", false, false], [29, 29, 19, 21, "named", "", false, false], [37, 37, 32, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "addition", "to", "sensitivity", "and", "specificity", ",", "the", "performance", "of", "a", "binary", "classification", "test", "can", "be", "measured", "by", "a", "positive", "predictive", "value", "(", "PPV", ")", ",", "also", "known", "as", "precision", ",", "and", "a", "negative", "predictive", "value", "(", "NPV", ")", "."], "sentence-detokenized": "In addition to sensitivity and specificity, the performance of a binary classification test can be measured by a positive predictive value (PPV), also known as precision, and a negative predictive value (NPV).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 42], [42, 43], [44, 47], [48, 59], [60, 62], [63, 64], [65, 71], [72, 86], [87, 91], [92, 95], [96, 98], [99, 107], [108, 110], [111, 112], [113, 121], [122, 132], [133, 138], [139, 140], [140, 143], [143, 144], [144, 145], [146, 150], [151, 156], [157, 159], [160, 169], [169, 170], [171, 174], [175, 176], [177, 185], [186, 196], [197, 202], [203, 204], [204, 207], [207, 208], [208, 209]]}
{"doc_key": "ai-test-430", "ner": [[13, 15, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "models", "can", "give", "partial", "credit", "for", "overlapping", "matches", "(", "e.g.", "using", "the", "Jaccard", "index", "criterion", "."], "sentence-detokenized": "Such models can give partial credit for overlapping matches (e.g. using the Jaccard index criterion.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 28], [29, 35], [36, 39], [40, 51], [52, 59], [60, 61], [61, 65], [66, 71], [72, 75], [76, 83], [84, 89], [90, 99], [99, 100]]}
{"doc_key": "ai-test-431", "ner": [[21, 26, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", ",", "for", "single", "-", "sample", "estimation", ",", "it", "shows", "the", "philosophical", "issues", "and", "possible", "misunderstandings", "in", "the", "use", "of", "maximum", "likelihood", "estimators", "and", "likelihood", "functions", "."], "sentence-detokenized": "In addition, for single-sample estimation, it shows the philosophical issues and possible misunderstandings in the use of maximum likelihood estimators and likelihood functions.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 16], [17, 23], [23, 24], [24, 30], [31, 41], [41, 42], [43, 45], [46, 51], [52, 55], [56, 69], [70, 76], [77, 80], [81, 89], [90, 107], [108, 110], [111, 114], [115, 118], [119, 121], [122, 129], [130, 140], [141, 151], [152, 155], [156, 166], [167, 176], [176, 177]]}
