{"doc_key": "ai-dev-1", "ner": [[2, 2, "metrics"], [7, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 11, 2, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Here", ",", "accuracy", "is", "measured", "by", "the", "error", "rate", ",", "which", "is", "defined", "as", ":"], "sentence-detokenized": "Here, accuracy is measured by the error rate, which is defined as:", "token2charspan": [[0, 4], [4, 5], [6, 14], [15, 17], [18, 26], [27, 29], [30, 33], [34, 39], [40, 44], [44, 45], [46, 51], [52, 54], [55, 62], [63, 65], [65, 66]]}
{"doc_key": "ai-dev-2", "ner": [[4, 4, "algorithm"], [11, 13, "misc"], [15, 17, "algorithm"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 11, 13, "type-of", "", false, false], [4, 4, 15, 17, "related-to", "", false, false], [4, 4, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["From", "this", "perspective", ",", "SVM", "is", "closely", "related", "to", "other", "basic", "classification", "algorithms", "such", "as", "regularized", "least", "squares", "logistic", "regression", "."], "sentence-detokenized": "From this perspective, SVM is closely related to other basic classification algorithms such as regularized least squares logistic regression.", "token2charspan": [[0, 4], [5, 9], [10, 21], [21, 22], [23, 26], [27, 29], [30, 37], [38, 45], [46, 48], [49, 54], [55, 60], [61, 75], [76, 86], [87, 91], [92, 94], [95, 106], [107, 112], [113, 120], [121, 129], [130, 140], [140, 141]]}
{"doc_key": "ai-dev-3", "ner": [[0, 1, "person"], [3, 4, "person"], [13, 14, "person"], [16, 16, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 0, 1, "named", "actor_plays_character", false, false], [3, 4, 0, 1, "origin", "actor_plays_character", false, false], [16, 16, 13, 14, "named", "actor_plays_character", false, false], [16, 16, 13, 14, "origin", "actor_plays_character", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Brion", "James", "plays", "Leon", "Kowalski", ",", "a", "combat", "and", "work", "replicant", ",", "and", "Joanna", "Cassidy", "plays", "Zhora", ",", "a", "replicant", "who", "is", "an", "assassin", "."], "sentence-detokenized": "Brion James plays Leon Kowalski, a combat and work replicant, and Joanna Cassidy plays Zhora, a replicant who is an assassin.", "token2charspan": [[0, 5], [6, 11], [12, 17], [18, 22], [23, 31], [31, 32], [33, 34], [35, 41], [42, 45], [46, 50], [51, 60], [60, 61], [62, 65], [66, 72], [73, 80], [81, 86], [87, 92], [92, 93], [94, 95], [96, 105], [106, 109], [110, 112], [113, 115], [116, 124], [124, 125]]}
{"doc_key": "ai-dev-4", "ner": [[17, 20, "product"], [22, 22, "product"], [25, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 20, 25, 25, "physical", "", false, false], [22, 22, 17, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "image", "to", "be", "scanned", ",", "saved", "and", "recreated", "in", "digital", "pixels", "was", "displayed", "on", "the", "Standards", "Eastern", "Automatic", "Computer", "(", "SEAC", ")", "at", "NIST", "."], "sentence-detokenized": "The first image to be scanned, saved and recreated in digital pixels was displayed on the Standards Eastern Automatic Computer (SEAC) at NIST.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 18], [19, 21], [22, 29], [29, 30], [31, 36], [37, 40], [41, 50], [51, 53], [54, 61], [62, 68], [69, 72], [73, 82], [83, 85], [86, 89], [90, 99], [100, 107], [108, 117], [118, 126], [127, 128], [128, 132], [132, 133], [134, 136], [137, 141], [141, 142]]}
{"doc_key": "ai-dev-5", "ner": [[0, 7, "task"], [21, 22, "task"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 7, 21, 22, "part-of", "", false, false], [0, 7, 24, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Segmentation", "of", "text", "into", "topics", "or", "discourse", "shifts", "can", "be", "useful", "in", "some", "natural", "processing", "tasks", ":", "it", "can", "significantly", "improve", "information", "retrieval", "or", "speech", "recognition", "(", "by", "indexing", "/", "recognizing", "documents", "more", "accurately", "or", "by", "returning", "the", "specific", "part", "of", "a", "document", "corresponding", "to", "the", "query", ")", "."], "sentence-detokenized": "Segmentation of text into topics or discourse shifts can be useful in some natural processing tasks: it can significantly improve information retrieval or speech recognition (by indexing/recognizing documents more accurately or by returning the specific part of a document corresponding to the query).", "token2charspan": [[0, 12], [13, 15], [16, 20], [21, 25], [26, 32], [33, 35], [36, 45], [46, 52], [53, 56], [57, 59], [60, 66], [67, 69], [70, 74], [75, 82], [83, 93], [94, 99], [99, 100], [101, 103], [104, 107], [108, 121], [122, 129], [130, 141], [142, 151], [152, 154], [155, 161], [162, 173], [174, 175], [175, 177], [178, 186], [186, 187], [187, 198], [199, 208], [209, 213], [214, 224], [225, 227], [228, 230], [231, 240], [241, 244], [245, 253], [254, 258], [259, 261], [262, 263], [264, 272], [273, 286], [287, 289], [290, 293], [294, 299], [299, 300], [300, 301]]}
{"doc_key": "ai-dev-6", "ner": [[1, 2, "university"], [21, 22, "conference"], [24, 27, "university"], [34, 35, "researcher"], [37, 38, "researcher"], [40, 41, "researcher"], [43, 44, "researcher"], [46, 47, "researcher"], [49, 50, "researcher"], [52, 54, "researcher"], [56, 57, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[21, 22, 24, 27, "physical", "", false, false], [34, 35, 21, 22, "physical", "", false, false], [34, 35, 21, 22, "role", "", false, false], [34, 35, 21, 22, "temporal", "", false, false], [37, 38, 21, 22, "physical", "", false, false], [37, 38, 21, 22, "role", "", false, false], [37, 38, 21, 22, "temporal", "", false, false], [40, 41, 21, 22, "physical", "", false, false], [40, 41, 21, 22, "role", "", false, false], [40, 41, 21, 22, "temporal", "", false, false], [43, 44, 21, 22, "physical", "", false, false], [43, 44, 21, 22, "role", "", false, false], [43, 44, 21, 22, "temporal", "", false, false], [46, 47, 21, 22, "physical", "", false, false], [46, 47, 21, 22, "role", "", false, false], [46, 47, 21, 22, "temporal", "", false, false], [49, 50, 21, 22, "physical", "", false, false], [49, 50, 21, 22, "role", "", false, false], [49, 50, 21, 22, "temporal", "", false, false], [52, 54, 21, 22, "physical", "", false, false], [52, 54, 21, 22, "role", "", false, false], [52, 54, 21, 22, "temporal", "", false, false], [56, 57, 21, 22, "physical", "", false, false], [56, 57, 21, 22, "role", "", false, false], [56, 57, 21, 22, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "sentence": ["At", "Indiana", "University", "in", "1999", "he", "organised", "such", "a", "symposium", ",", "and", "in", "April", "2000", "he", "organised", "a", "major", "symposium", "entitled", "Spiritual", "Robots", "at", "Stanford", "University", ",", "where", "he", "moderated", "a", "panel", "consisting", "of", "Ray", "Kurzweil", ",", "Hans", "Moravec", ",", "Kevin", "Kelly", ",", "Ralph", "Merkle", ",", "Bill", "Joy", ",", "Frank", "Drake", ",", "John", "Henry", "Holland", "and", "John", "Koza", "."], "sentence-detokenized": "At Indiana University in 1999 he organised such a symposium, and in April 2000 he organised a major symposium entitled Spiritual Robots at Stanford University, where he moderated a panel consisting of Ray Kurzweil, Hans Moravec, Kevin Kelly, Ralph Merkle, Bill Joy, Frank Drake, John Henry Holland and John Koza.", "token2charspan": [[0, 2], [3, 10], [11, 21], [22, 24], [25, 29], [30, 32], [33, 42], [43, 47], [48, 49], [50, 59], [59, 60], [61, 64], [65, 67], [68, 73], [74, 78], [79, 81], [82, 91], [92, 93], [94, 99], [100, 109], [110, 118], [119, 128], [129, 135], [136, 138], [139, 147], [148, 158], [158, 159], [160, 165], [166, 168], [169, 178], [179, 180], [181, 186], [187, 197], [198, 200], [201, 204], [205, 213], [213, 214], [215, 219], [220, 227], [227, 228], [229, 234], [235, 240], [240, 241], [242, 247], [248, 254], [254, 255], [256, 260], [261, 264], [264, 265], [266, 271], [272, 277], [277, 278], [279, 283], [284, 289], [290, 297], [298, 301], [302, 306], [307, 311], [311, 312]]}
{"doc_key": "ai-dev-7", "ner": [[1, 2, "metrics"], [3, 3, "metrics"], [6, 8, "metrics"], [7, 7, "metrics"], [20, 20, "metrics"], [40, 40, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 2, 20, 20, "named", "", false, false], [3, 3, 1, 2, "named", "", false, false], [6, 8, 40, 40, "named", "", false, false], [7, 7, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Both", "the", "precision", "p", "and", "the", "recall", "r", "of", "the", "test", "are", "taken", "into", "account", "to", "calculate", "the", "score", ":", "p", "is", "the", "number", "of", "correct", "positives", "divided", "by", "the", "number", "of", "all", "positives", "returned", "by", "the", "classifier", ",", "and", "r", "is", "the", "number", "of", "correct", "positives", "divided", "by", "the", "number", "of", "all", "relevant", "samples", "(", "all", "samples", "that", "should", "have", "been", "identified", "as", "positive", ")", "."], "sentence-detokenized": "Both the precision p and the recall r of the test are taken into account to calculate the score: p is the number of correct positives divided by the number of all positives returned by the classifier, and r is the number of correct positives divided by the number of all relevant samples (all samples that should have been identified as positive).", "token2charspan": [[0, 4], [5, 8], [9, 18], [19, 20], [21, 24], [25, 28], [29, 35], [36, 37], [38, 40], [41, 44], [45, 49], [50, 53], [54, 59], [60, 64], [65, 72], [73, 75], [76, 85], [86, 89], [90, 95], [95, 96], [97, 98], [99, 101], [102, 105], [106, 112], [113, 115], [116, 123], [124, 133], [134, 141], [142, 144], [145, 148], [149, 155], [156, 158], [159, 162], [163, 172], [173, 181], [182, 184], [185, 188], [189, 199], [199, 200], [201, 204], [205, 206], [207, 209], [210, 213], [214, 220], [221, 223], [224, 231], [232, 241], [242, 249], [250, 252], [253, 256], [257, 263], [264, 266], [267, 270], [271, 279], [280, 287], [288, 289], [289, 292], [293, 300], [301, 305], [306, 312], [313, 317], [318, 322], [323, 333], [334, 336], [337, 345], [345, 346], [346, 347]]}
{"doc_key": "ai-dev-8", "ner": [[1, 2, "organisation"], [25, 25, "product"], [33, 34, "person"], [40, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 25, 25, "artifact", "", false, false], [25, 25, 33, 34, "win-defeat", "", false, false], [25, 25, 40, 40, "win-defeat", "", true, false], [33, 34, 40, 40, "win-defeat", "lose", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "Google", "'s", "acquisition", ",", "the", "company", "has", "achieved", "a", "number", "of", "significant", "accomplishments", ",", "perhaps", "the", "most", "notable", "of", "which", "is", "the", "creation", "of", "AlphaGo", ",", "an", "application", "that", "defeated", "world", "champion", "Lee", "Sedol", "in", "the", "complex", "game", "of", "Go", "."], "sentence-detokenized": "Since Google's acquisition, the company has achieved a number of significant accomplishments, perhaps the most notable of which is the creation of AlphaGo, an application that defeated world champion Lee Sedol in the complex game of Go.", "token2charspan": [[0, 5], [6, 12], [12, 14], [15, 26], [26, 27], [28, 31], [32, 39], [40, 43], [44, 52], [53, 54], [55, 61], [62, 64], [65, 76], [77, 92], [92, 93], [94, 101], [102, 105], [106, 110], [111, 118], [119, 121], [122, 127], [128, 130], [131, 134], [135, 143], [144, 146], [147, 154], [154, 155], [156, 158], [159, 170], [171, 175], [176, 184], [185, 190], [191, 199], [200, 203], [204, 209], [210, 212], [213, 216], [217, 224], [225, 229], [230, 232], [233, 235], [235, 236]]}
{"doc_key": "ai-dev-9", "ner": [[15, 16, "misc"], [32, 34, "product"], [51, 52, "misc"], [56, 56, "misc"], [60, 60, "product"]], "ner_mapping_to_source": [0, 2, 3, 4, 5], "relations": [[15, 16, 56, 56, "named", "same", false, false], [32, 34, 51, 52, "related-to", "", false, false], [32, 34, 56, 56, "usage", "", false, false], [32, 34, 60, 60, "usage", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4], "sentence": ["Representation", "of", "words", "taking", "into", "account", "their", "context", "through", "dense", "vectors", "of", "fixed", "size", "(", "word", "embeddings", ")", "has", "become", "one", "of", "the", "most", "fundamental", "blocks", "in", "several", "NLP", "systems", ".", "An", "unsupervised", "disambiguation", "system", "uses", "the", "similarity", "of", "word", "senses", "in", "a", "fixed", "context", "window", "to", "select", "the", "most", "appropriate", "word", "sense", "using", "a", "pre-trained", "word", "embedding", "model", "and", "WordNet", "."], "sentence-detokenized": "Representation of words taking into account their context through dense vectors of fixed size (word embeddings) has become one of the most fundamental blocks in several NLP systems. An unsupervised disambiguation system uses the similarity of word senses in a fixed context window to select the most appropriate word sense using a pre-trained word embedding model and WordNet.", "token2charspan": [[0, 14], [15, 17], [18, 23], [24, 30], [31, 35], [36, 43], [44, 49], [50, 57], [58, 65], [66, 71], [72, 79], [80, 82], [83, 88], [89, 93], [94, 95], [95, 99], [100, 110], [110, 111], [112, 115], [116, 122], [123, 126], [127, 129], [130, 133], [134, 138], [139, 150], [151, 157], [158, 160], [161, 168], [169, 172], [173, 180], [180, 181], [182, 184], [185, 197], [198, 212], [213, 219], [220, 224], [225, 228], [229, 239], [240, 242], [243, 247], [248, 254], [255, 257], [258, 259], [260, 265], [266, 273], [274, 280], [281, 283], [284, 290], [291, 294], [295, 299], [300, 311], [312, 316], [317, 322], [323, 328], [329, 330], [331, 342], [343, 347], [348, 357], [358, 363], [364, 367], [368, 375], [375, 376]]}
{"doc_key": "ai-dev-10", "ner": [[5, 5, "field"], [7, 8, "field"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Machine", "learning", "methods", ",", "either", "supervised", "or", "unsupervised", "learning", ",", "have", "been", "used", "to", "create", "such", "rules", "automatically", "."], "sentence-detokenized": "Machine learning methods, either supervised or unsupervised learning, have been used to create such rules automatically.", "token2charspan": [[0, 7], [8, 16], [17, 24], [24, 25], [26, 32], [33, 43], [44, 46], [47, 59], [60, 68], [68, 69], [70, 74], [75, 79], [80, 84], [85, 87], [88, 94], [95, 99], [100, 105], [106, 119], [119, 120]]}
{"doc_key": "ai-dev-11", "ner": [[3, 3, "researcher"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1969", ",", "Scheinman", "invented", "the", "Stanford", "arm", ","], "sentence-detokenized": "In 1969, Scheinman invented the Stanford arm,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 27], [28, 31], [32, 40], [41, 44], [44, 45]]}
{"doc_key": "ai-dev-12", "ner": [[1, 3, "metrics"], [8, 11, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Since", "the", "Log", "loss", "is", "differentiable", ",", "a", "gradient", "-", "based", "method", "can", "be", "used", "to", "optimize", "the", "model", "."], "sentence-detokenized": "Since the Log loss is differentiable, a gradient-based method can be used to optimize the model.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 18], [19, 21], [22, 36], [36, 37], [38, 39], [40, 48], [48, 49], [49, 54], [55, 61], [62, 65], [66, 68], [69, 73], [74, 76], [77, 85], [86, 89], [90, 95], [95, 96]]}
{"doc_key": "ai-dev-13", "ner": [[1, 2, "field"], [4, 6, "algorithm"], [8, 8, "algorithm"], [11, 13, "algorithm"], [16, 16, "field"], [26, 26, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 6, 16, 16, "part-of", "", false, false], [8, 8, 4, 6, "named", "", false, false], [11, 13, 4, 6, "named", "", false, false], [16, 16, 1, 2, "part-of", "subfield", false, false], [26, 26, 16, 16, "part-of", "", false, false], [28, 29, 16, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "machine", "learning", ",", "support", "vector", "machines", "(", "SVMs", ",", "also", "support", "vector", "networks", ")", "are", "supervised", "learning", "models", "with", "learning", "algorithms", "that", "analyse", "data", "for", "classification", "and", "regression", "analysis", "."], "sentence-detokenized": "In machine learning, support vector machines (SVMs, also support vector networks) are supervised learning models with learning algorithms that analyse data for classification and regression analysis.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 28], [29, 35], [36, 44], [45, 46], [46, 50], [50, 51], [52, 56], [57, 64], [65, 71], [72, 80], [80, 81], [82, 85], [86, 96], [97, 105], [106, 112], [113, 117], [118, 126], [127, 137], [138, 142], [143, 150], [151, 155], [156, 159], [160, 174], [175, 178], [179, 189], [190, 198], [198, 199]]}
{"doc_key": "ai-dev-14", "ner": [[10, 11, "task"], [26, 26, "metrics"], [28, 28, "metrics"], [30, 30, "researcher"], [32, 32, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": [",", "(", "2002", ")", "as", "the", "automatic", "measure", "for", "evaluating", "machine", "translation", ",", "many", "other", "methods", "have", "been", "proposed", "to", "revise", "or", "improve", "it", ",", "e.g.", "TER", ",", "METEOR", ",", "Banerjee", "and", "Lavie", ",", "(", "2005", ")", "etc", "."], "sentence-detokenized": ", (2002) as the automatic measure for evaluating machine translation, many other methods have been proposed to revise or improve it, e.g. TER, METEOR, Banerjee and Lavie, (2005) etc.", "token2charspan": [[0, 1], [2, 3], [3, 7], [7, 8], [9, 11], [12, 15], [16, 25], [26, 33], [34, 37], [38, 48], [49, 56], [57, 68], [68, 69], [70, 74], [75, 80], [81, 88], [89, 93], [94, 98], [99, 107], [108, 110], [111, 117], [118, 120], [121, 128], [129, 131], [131, 132], [133, 137], [138, 141], [141, 142], [143, 149], [149, 150], [151, 159], [160, 163], [164, 169], [169, 170], [171, 172], [172, 176], [176, 177], [178, 181], [181, 182]]}
{"doc_key": "ai-dev-15", "ner": [[3, 4, "misc"], [9, 9, "organisation"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[3, 4, 9, 9, "origin", "", false, false], [15, 16, 9, 9, "role", "", false, false], [18, 19, 9, 9, "role", "", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["It", "contains", "an", "overarching", "ontology", "developed", "by", "the", "IEEE", "P1600.1", "Working", "Group", "(", "originally", "by", "Ian", "Niles", "and", "Adam", "Pease", ")", "."], "sentence-detokenized": "It contains an overarching ontology developed by the IEEE P1600.1 Working Group (originally by Ian Niles and Adam Pease).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 35], [36, 45], [46, 48], [49, 52], [53, 57], [58, 65], [66, 73], [74, 79], [80, 81], [81, 91], [92, 94], [95, 98], [99, 104], [105, 108], [109, 113], [114, 119], [119, 120], [120, 121]]}
{"doc_key": "ai-dev-16", "ner": [[1, 2, "misc"], [31, 33, "algorithm"], [35, 36, "algorithm"], [39, 40, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[31, 33, 1, 2, "part-of", "", true, false], [35, 36, 1, 2, "part-of", "", true, false], [39, 40, 35, 36, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "cryo-electron", "tomography", ",", "where", "the", "limited", "number", "of", "projections", "is", "acquired", "due", "to", "hardware", "limitations", "and", "to", "avoid", "damage", "to", "biological", "samples", ",", "it", "can", "be", "used", "in", "conjunction", "with", "compressive", "sensing", "techniques", "or", "regularization", "features", "(", "e.g.", "Huber", "loss", ")", "to", "improve", "reconstruction", "for", "better", "interpretation", "."], "sentence-detokenized": "In cryo-electron tomography, where the limited number of projections is acquired due to hardware limitations and to avoid damage to biological samples, it can be used in conjunction with compressive sensing techniques or regularization features (e.g. Huber loss) to improve reconstruction for better interpretation.", "token2charspan": [[0, 2], [3, 16], [17, 27], [27, 28], [29, 34], [35, 38], [39, 46], [47, 53], [54, 56], [57, 68], [69, 71], [72, 80], [81, 84], [85, 87], [88, 96], [97, 108], [109, 112], [113, 115], [116, 121], [122, 128], [129, 131], [132, 142], [143, 150], [150, 151], [152, 154], [155, 158], [159, 161], [162, 166], [167, 169], [170, 181], [182, 186], [187, 198], [199, 206], [207, 217], [218, 220], [221, 235], [236, 244], [245, 246], [246, 250], [251, 256], [257, 261], [261, 262], [263, 265], [266, 273], [274, 288], [289, 292], [293, 299], [300, 314], [314, 315]]}
{"doc_key": "ai-dev-17", "ner": [[7, 7, "programlang"], [10, 12, "algorithm"], [14, 16, "algorithm"], [20, 22, "algorithm"], [28, 30, "product"], [33, 33, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [[28, 30, 7, 7, "general-affiliation", "", true, false], [28, 30, 7, 7, "part-of", "", true, false], [33, 33, 28, 30, "role", "publishes", false, false]], "relations_mapping_to_source": [4, 5, 6], "sentence": ["An", "implementation", "of", "several", "whitening", "procedures", "in", "R", ",", "including", "ZCA", "-", "whitening", "and", "PCA", "-", "whitening", ",", "but", "also", "CCA", "-", "whitening", ",", "is", "available", "in", "the", "whitening", "R", "package", "published", "on", "CRAN", "."], "sentence-detokenized": "An implementation of several whitening procedures in R, including ZCA-whitening and PCA-whitening, but also CCA-whitening, is available in the whitening R package published on CRAN.", "token2charspan": [[0, 2], [3, 17], [18, 20], [21, 28], [29, 38], [39, 49], [50, 52], [53, 54], [54, 55], [56, 65], [66, 69], [69, 70], [70, 79], [80, 83], [84, 87], [87, 88], [88, 97], [97, 98], [99, 102], [103, 107], [108, 111], [111, 112], [112, 121], [121, 122], [123, 125], [126, 135], [136, 138], [139, 142], [143, 152], [153, 154], [155, 162], [163, 172], [173, 175], [176, 180], [180, 181]]}
{"doc_key": "ai-dev-18", "ner": [[28, 28, "product"], [30, 30, "product"], [32, 32, "product"], [34, 34, "product"], [36, 36, "product"], [38, 38, "product"], [41, 42, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[28, 28, 32, 32, "compare", "", false, false], [28, 28, 34, 34, "compare", "", false, false], [28, 28, 36, 36, "compare", "", false, false], [28, 28, 38, 38, "compare", "", false, false], [28, 28, 41, 42, "compare", "", false, false], [30, 30, 32, 32, "compare", "", false, false], [30, 30, 34, 34, "compare", "", false, false], [30, 30, 36, 36, "compare", "", false, false], [30, 30, 38, 38, "compare", "", false, false], [30, 30, 41, 42, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Today", ",", "the", "field", "has", "become", "even", "more", "daunting", "and", "complex", "with", "the", "addition", "of", "circuit", ",", "system", "and", "signal", "analysis", "and", "design", "languages", "and", "software", ",", "from", "MATLAB", "and", "Simulink", "to", "NumPy", ",", "VHDL", ",", "PSpice", ",", "Verilog", "and", "even", "assembly", "languages", "."], "sentence-detokenized": "Today, the field has become even more daunting and complex with the addition of circuit, system and signal analysis and design languages and software, from MATLAB and Simulink to NumPy, VHDL, PSpice, Verilog and even assembly languages.", "token2charspan": [[0, 5], [5, 6], [7, 10], [11, 16], [17, 20], [21, 27], [28, 32], [33, 37], [38, 46], [47, 50], [51, 58], [59, 63], [64, 67], [68, 76], [77, 79], [80, 87], [87, 88], [89, 95], [96, 99], [100, 106], [107, 115], [116, 119], [120, 126], [127, 136], [137, 140], [141, 149], [149, 150], [151, 155], [156, 162], [163, 166], [167, 175], [176, 178], [179, 184], [184, 185], [186, 190], [190, 191], [192, 198], [198, 199], [200, 207], [208, 211], [212, 216], [217, 225], [226, 235], [235, 236]]}
{"doc_key": "ai-dev-19", "ner": [[5, 6, "person"], [14, 14, "person"], [17, 18, "organisation"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[17, 18, 14, 14, "origin", "", false, false], [21, 21, 17, 18, "artifact", "builds", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "company", "was", "founded", "by", "Kiichiro", "Toyoda", "in", "1937", "as", "a", "spinoff", "from", "the", "Sakichi", "Toyoda", "company", "Toyota", "Industries", "to", "create", "cars", "."], "sentence-detokenized": "The company was founded by Kiichiro Toyoda in 1937 as a spinoff from the Sakichi Toyoda company Toyota Industries to create cars.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 26], [27, 35], [36, 42], [43, 45], [46, 50], [51, 53], [54, 55], [56, 63], [64, 68], [69, 72], [73, 80], [81, 87], [88, 95], [96, 102], [103, 113], [114, 116], [117, 123], [124, 128], [128, 129]]}
{"doc_key": "ai-dev-20", "ner": [[0, 1, "field"], [54, 55, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[54, 55, 0, 1, "origin", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Unsupervised", "learning", ",", "on", "the", "other", "hand", ",", "takes", "training", "data", "that", "has", "not", "been", "hand", "-", "labelled", "and", "tries", "to", "find", "inherent", "patterns", "in", "the", "data", "that", "can", "then", "be", "used", "to", "determine", "the", "correct", "output", "value", "for", "new", "data", "instances", ".", "A", "combination", "of", "the", "two", "that", "has", "recently", "been", "explored", "is", "semi-supervised", "learning", ",", "which", "uses", "a", "combination", "of", "labelled", "and", "unlabelled", "data", "(", "typically", "a", "small", "set", "of", "labelled", "data", "combined", "with", "a", "large", "amount", "of", "unlabelled", "data", ")", "."], "sentence-detokenized": "Unsupervised learning, on the other hand, takes training data that has not been hand-labelled and tries to find inherent patterns in the data that can then be used to determine the correct output value for new data instances. A combination of the two that has recently been explored is semi-supervised learning, which uses a combination of labelled and unlabelled data (typically a small set of labelled data combined with a large amount of unlabelled data).", "token2charspan": [[0, 12], [13, 21], [21, 22], [23, 25], [26, 29], [30, 35], [36, 40], [40, 41], [42, 47], [48, 56], [57, 61], [62, 66], [67, 70], [71, 74], [75, 79], [80, 84], [84, 85], [85, 93], [94, 97], [98, 103], [104, 106], [107, 111], [112, 120], [121, 129], [130, 132], [133, 136], [137, 141], [142, 146], [147, 150], [151, 155], [156, 158], [159, 163], [164, 166], [167, 176], [177, 180], [181, 188], [189, 195], [196, 201], [202, 205], [206, 209], [210, 214], [215, 224], [224, 225], [226, 227], [228, 239], [240, 242], [243, 246], [247, 250], [251, 255], [256, 259], [260, 268], [269, 273], [274, 282], [283, 285], [286, 301], [302, 310], [310, 311], [312, 317], [318, 322], [323, 324], [325, 336], [337, 339], [340, 348], [349, 352], [353, 363], [364, 368], [369, 370], [370, 379], [380, 381], [382, 387], [388, 391], [392, 394], [395, 403], [404, 408], [409, 417], [418, 422], [423, 424], [425, 430], [431, 437], [438, 440], [441, 451], [452, 456], [456, 457], [457, 458]]}
{"doc_key": "ai-dev-21", "ner": [[20, 21, "organisation"], [22, 22, "product"], [24, 25, "organisation"], [26, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 20, 21, "artifact", "", false, false], [24, 25, 26, 26, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Despite", "these", "humanoid", "robots", "for", "utilitarian", "use", ",", "there", "are", "some", "humanoid", "robots", "that", "aim", "to", "entertain", ",", "such", "as", "Sony", "'s", "QRIO", "and", "Wow", "Wees", "RoboSapien", "."], "sentence-detokenized": "Despite these humanoid robots for utilitarian use, there are some humanoid robots that aim to entertain, such as Sony's QRIO and Wow Wees RoboSapien.", "token2charspan": [[0, 7], [8, 13], [14, 22], [23, 29], [30, 33], [34, 45], [46, 49], [49, 50], [51, 56], [57, 60], [61, 65], [66, 74], [75, 81], [82, 86], [87, 90], [91, 93], [94, 103], [103, 104], [105, 109], [110, 112], [113, 117], [117, 119], [120, 124], [125, 128], [129, 132], [133, 137], [138, 148], [148, 149]]}
{"doc_key": "ai-dev-22", "ner": [[0, 0, "researcher"], [3, 9, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 3, 9, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Webber", "joined", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "in", "1991", ","], "sentence-detokenized": "Webber joined the Association for the Advancement of Artificial Intelligence in 1991,", "token2charspan": [[0, 6], [7, 13], [14, 17], [18, 29], [30, 33], [34, 37], [38, 49], [50, 52], [53, 63], [64, 76], [77, 79], [80, 84], [84, 85]]}
{"doc_key": "ai-dev-23", "ner": [[6, 7, "field"], [21, 24, "task"]], "ner_mapping_to_source": [0, 2], "relations": [[21, 24, 6, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "this", "company", ",", "he", "developed", "data", "mining", "and", "database", "technology", ",", "more", "specifically", "high", "-", "level", "ontologies", "for", "intelligence", "and", "automated", "natural", "language", "understanding", "."], "sentence-detokenized": "In this company, he developed data mining and database technology, more specifically high-level ontologies for intelligence and automated natural language understanding.", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 19], [20, 29], [30, 34], [35, 41], [42, 45], [46, 54], [55, 65], [65, 66], [67, 71], [72, 84], [85, 89], [89, 90], [90, 95], [96, 106], [107, 110], [111, 123], [124, 127], [128, 137], [138, 145], [146, 154], [155, 168], [168, 169]]}
{"doc_key": "ai-dev-24", "ner": [[19, 20, "misc"], [22, 25, "misc"], [27, 28, "misc"], [30, 30, "country"], [32, 34, "organisation"], [36, 36, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[19, 20, 30, 30, "physical", "", false, false], [22, 25, 30, 30, "physical", "", false, false], [27, 28, 30, 30, "physical", "", false, false], [32, 34, 36, 36, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["However", ",", "in", "recent", "years", ",", "various", "e-services", "and", "related", "initiatives", "have", "emerged", "in", "developing", "countries", ",", "such", "as", "Project", "Nemmadi", ",", "MCA21", "Mission", "Mode", "Project", "or", "Digital", "India", "in", "India", ",", "Electronic", "Government", "Directorate", "in", "Pakistan", ",", "etc."], "sentence-detokenized": "However, in recent years, various e-services and related initiatives have emerged in developing countries, such as Project Nemmadi, MCA21 Mission Mode Project or Digital India in India, Electronic Government Directorate in Pakistan, etc.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 18], [19, 24], [24, 25], [26, 33], [34, 44], [45, 48], [49, 56], [57, 68], [69, 73], [74, 81], [82, 84], [85, 95], [96, 105], [105, 106], [107, 111], [112, 114], [115, 122], [123, 130], [130, 131], [132, 137], [138, 145], [146, 150], [151, 158], [159, 161], [162, 169], [170, 175], [176, 178], [179, 184], [184, 185], [186, 196], [197, 207], [208, 219], [220, 222], [223, 231], [231, 232], [233, 237]]}
{"doc_key": "ai-dev-25", "ner": [[5, 6, "field"], [8, 8, "field"], [10, 12, "university"], [15, 17, "university"], [24, 26, "university"], [32, 33, "field"], [37, 40, "misc"], [42, 43, "university"], [45, 47, "university"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 7, 8, 9, 10], "relations": [[10, 12, 15, 17, "part-of", "", false, false], [24, 26, 10, 12, "part-of", "", false, false], [37, 40, 42, 43, "origin", "", false, false], [42, 43, 45, 47, "part-of", "", false, false]], "relations_mapping_to_source": [3, 4, 7, 8], "sentence": ["He", "received", "a", "PhD", "in", "Radio", "Physics", "and", "Electronics", "from", "Rajabazar", "Science", "College", "campus", "at", "University", "of", "Calcutta", "in", "1979", "as", "a", "student", "at", "Indian", "Statistical", "Institute", ",", "and", "another", "PhD", "in", "Electrical", "Engineering", "along", "with", "a", "Diploma", "from", "Imperial", "College", "from", "Imperial", "College", ",", "University", "of", "London", ",", "in", "1982", "."], "sentence-detokenized": "He received a PhD in Radio Physics and Electronics from Rajabazar Science College campus at University of Calcutta in 1979 as a student at Indian Statistical Institute, and another PhD in Electrical Engineering along with a Diploma from Imperial College from Imperial College, University of London, in 1982.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 17], [18, 20], [21, 26], [27, 34], [35, 38], [39, 50], [51, 55], [56, 65], [66, 73], [74, 81], [82, 88], [89, 91], [92, 102], [103, 105], [106, 114], [115, 117], [118, 122], [123, 125], [126, 127], [128, 135], [136, 138], [139, 145], [146, 157], [158, 167], [167, 168], [169, 172], [173, 180], [181, 184], [185, 187], [188, 198], [199, 210], [211, 216], [217, 221], [222, 223], [224, 231], [232, 236], [237, 245], [246, 253], [254, 258], [259, 267], [268, 275], [275, 276], [277, 287], [288, 290], [291, 297], [297, 298], [299, 301], [302, 306], [306, 307]]}
{"doc_key": "ai-dev-26", "ner": [[0, 1, "location"], [21, 23, "misc"], [28, 29, "misc"], [31, 33, "person"], [35, 36, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 23, 0, 1, "temporal", "", false, false], [28, 29, 0, 1, "temporal", "", false, false], [31, 33, 28, 29, "role", "actor_in", false, false], [35, 36, 28, 29, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Expo", "II", "was", "announced", "as", "the", "site", "of", "the", "world", "premiere", "of", "several", "films", "never", "before", "shown", "in", "3D", ",", "including", "The", "Diamond", "Wizard", "and", "the", "Universal", "short", "Hawaiian", "Nights", "starring", "Mamie", "Van", "Doren", "and", "Pinky", "Lee", "."], "sentence-detokenized": "Expo II was announced as the site of the world premiere of several films never before shown in 3D, including The Diamond Wizard and the Universal short Hawaiian Nights starring Mamie Van Doren and Pinky Lee.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 24], [25, 28], [29, 33], [34, 36], [37, 40], [41, 46], [47, 55], [56, 58], [59, 66], [67, 72], [73, 78], [79, 85], [86, 91], [92, 94], [95, 97], [97, 98], [99, 108], [109, 112], [113, 120], [121, 127], [128, 131], [132, 135], [136, 145], [146, 151], [152, 160], [161, 167], [168, 176], [177, 182], [183, 186], [187, 192], [193, 196], [197, 202], [203, 206], [206, 207]]}
{"doc_key": "ai-dev-27", "ner": [[7, 8, "researcher"], [16, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 16, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "maximum", "subfield", "problem", "was", "proposed", "by", "Ulf", "Grenander", "in", "1977", "as", "a", "simplified", "model", "for", "maximum", "likelihood", "estimation", "of", "patterns", "in", "digitized", "images", "."], "sentence-detokenized": "The maximum subfield problem was proposed by Ulf Grenander in 1977 as a simplified model for maximum likelihood estimation of patterns in digitized images.", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 28], [29, 32], [33, 41], [42, 44], [45, 48], [49, 58], [59, 61], [62, 66], [67, 69], [70, 71], [72, 82], [83, 88], [89, 92], [93, 100], [101, 111], [112, 122], [123, 125], [126, 134], [135, 137], [138, 147], [148, 154], [154, 155]]}
{"doc_key": "ai-dev-28", "ner": [[0, 1, "product"], [3, 4, "product"], [6, 8, "product"], [10, 11, "product"], [13, 15, "product"], [17, 20, "product"], [32, 32, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[32, 32, 0, 1, "part-of", "", false, false], [32, 32, 3, 4, "part-of", "", false, false], [32, 32, 6, 8, "part-of", "", false, false], [32, 32, 10, 11, "part-of", "", false, false], [32, 32, 13, 15, "part-of", "", false, false], [32, 32, 17, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["iPhone", "4S", ",", "iPad", "3", ",", "iPad", "Mini", "1G", ",", "iPad", "Air", ",", "iPad", "Pro", "1G", ",", "iPod", "Touch", "5", "G", "and", "newer", "models", "all", "have", "a", "more", "advanced", "voice", "assistant", "called", "Siri", "."], "sentence-detokenized": "iPhone 4S, iPad 3, iPad Mini 1G, iPad Air, iPad Pro 1G, iPod Touch 5G and newer models all have a more advanced voice assistant called Siri.", "token2charspan": [[0, 6], [7, 9], [9, 10], [11, 15], [16, 17], [17, 18], [19, 23], [24, 28], [29, 31], [31, 32], [33, 37], [38, 41], [41, 42], [43, 47], [48, 51], [52, 54], [54, 55], [56, 60], [61, 66], [67, 68], [68, 69], [70, 73], [74, 79], [80, 86], [87, 90], [91, 95], [96, 97], [98, 102], [103, 111], [112, 117], [118, 127], [128, 134], [135, 139], [139, 140]]}
{"doc_key": "ai-dev-29", "ner": [[7, 8, "metrics"], [11, 14, "metrics"], [16, 17, "metrics"], [47, 49, "metrics"], [55, 59, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 14, 47, 49, "named", "", false, false], [16, 17, 11, 14, "named", "", false, false], [47, 49, 55, 59, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["It", "is", "easy", "to", "check", "that", "the", "logistic", "loss", "and", "the", "binary", "cross", "entropy", "loss", "(", "Log", "loss", ")", "are", "actually", "the", "same", "(", "up", "to", "a", "multiplicative", "constant", "math", "\\", "fromc", "{", "1", "}", "{", "\\", "log", "(", "2", ")", "}", "/", "math", ")", ".", "The", "cross", "-entropy", "loss", "is", "closely", "related", "to", "the", "Kullback", "-", "Leibler", "divergence", "between", "the", "empirical", "distribution", "and", "the", "predicted", "distribution", "."], "sentence-detokenized": "It is easy to check that the logistic loss and the binary cross entropy loss (Log loss) are actually the same (up to a multiplicative constant math\\ fromc {1} {\\ log (2)} / math) . The cross-entropy loss is closely related to the Kullback-Leibler divergence between the empirical distribution and the predicted distribution.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 13], [14, 19], [20, 24], [25, 28], [29, 37], [38, 42], [43, 46], [47, 50], [51, 57], [58, 63], [64, 71], [72, 76], [77, 78], [78, 81], [82, 86], [86, 87], [88, 91], [92, 100], [101, 104], [105, 109], [110, 111], [111, 113], [114, 116], [117, 118], [119, 133], [134, 142], [143, 147], [147, 148], [149, 154], [155, 156], [156, 157], [157, 158], [159, 160], [160, 161], [162, 165], [166, 167], [167, 168], [168, 169], [169, 170], [171, 172], [173, 177], [177, 178], [179, 180], [181, 184], [185, 190], [190, 198], [199, 203], [204, 206], [207, 214], [215, 222], [223, 225], [226, 229], [230, 238], [238, 239], [239, 246], [247, 257], [258, 265], [266, 269], [270, 279], [280, 292], [293, 296], [297, 300], [301, 310], [311, 323], [323, 324]]}
{"doc_key": "ai-dev-30", "ner": [[0, 2, "algorithm"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 10, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "EM", "algorithm", "is", "used", "to", "find", "(", "local", ")", "maximum", "likelihood", "parameters", "for", "a", "statistical", "model", "in", "cases", "where", "the", "equations", "can", "not", "be", "solved", "directly", "."], "sentence-detokenized": "The EM algorithm is used to find (local) maximum likelihood parameters for a statistical model in cases where the equations cannot be solved directly.", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 19], [20, 24], [25, 27], [28, 32], [33, 34], [34, 39], [39, 40], [41, 48], [49, 59], [60, 70], [71, 74], [75, 76], [77, 88], [89, 94], [95, 97], [98, 103], [104, 109], [110, 113], [114, 123], [124, 127], [127, 130], [131, 133], [134, 140], [141, 149], [149, 150]]}
{"doc_key": "ai-dev-31", "ner": [[9, 10, "task"], [13, 17, "task"], [22, 23, "task"], [25, 26, "task"], [32, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "research", "was", "fundamental", "to", "the", "development", "of", "modern", "speech", "synthesis", "techniques", ",", "reading", "machines", "for", "the", "blind", ",", "the", "study", "of", "speech", "perception", "and", "speech", "recognition", ",", "and", "the", "development", "of", "motor", "theory", "of", "speech", "perception", "."], "sentence-detokenized": "This research was fundamental to the development of modern speech synthesis techniques, reading machines for the blind, the study of speech perception and speech recognition, and the development of motor theory of speech perception.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 29], [30, 32], [33, 36], [37, 48], [49, 51], [52, 58], [59, 65], [66, 75], [76, 86], [86, 87], [88, 95], [96, 104], [105, 108], [109, 112], [113, 118], [118, 119], [120, 123], [124, 129], [130, 132], [133, 139], [140, 150], [151, 154], [155, 161], [162, 173], [173, 174], [175, 178], [179, 182], [183, 194], [195, 197], [198, 203], [204, 210], [211, 213], [214, 220], [221, 231], [231, 232]]}
{"doc_key": "ai-dev-32", "ner": [[0, 1, "product"], [2, 4, "misc"], [6, 6, "misc"], [10, 12, "misc"], [15, 15, "product"], [17, 17, "product"], [19, 19, "product"], [24, 24, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 4, 0, 1, "origin", "", false, false], [2, 4, 10, 12, "type-of", "", false, false], [2, 4, 15, 15, "related-to", "program_for", false, false], [2, 4, 17, 17, "related-to", "program_for", false, false], [2, 4, 19, 19, "related-to", "program_for", false, false], [2, 4, 24, 24, "related-to", "program_for", false, false], [6, 6, 2, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "Arduino", "Integrated", "Development", "Environment", "(", "IDE", ")", "is", "a", "cross", "-platform", "application", "(", "for", "Windows", ",", "macOS", "and", "Linux", ")", "written", "in", "the", "Java", "programming", "language", "."], "sentence-detokenized": "The Arduino Integrated Development Environment (IDE) is a cross-platform application (for Windows, macOS and Linux) written in the Java programming language.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 34], [35, 46], [47, 48], [48, 51], [51, 52], [53, 55], [56, 57], [58, 63], [63, 72], [73, 84], [85, 86], [86, 89], [90, 97], [97, 98], [99, 104], [105, 108], [109, 114], [114, 115], [116, 123], [124, 126], [127, 130], [131, 135], [136, 147], [148, 156], [156, 157]]}
{"doc_key": "ai-dev-33", "ner": [[2, 3, "algorithm"], [17, 18, "field"], [9, 10, "researcher"], [12, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 17, 18, "opposite", "", false, false], [9, 10, 17, 18, "related-to", "works_with", false, false], [12, 14, 17, 18, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Research", "on", "neural", "networks", "stagnated", "after", "the", "publication", "of", "Marvin", "Minsky", "and", "Seymour", "Papert", "'s", "research", "on", "machine", "learning", "(", "1969", ")", "."], "sentence-detokenized": "Research on neural networks stagnated after the publication of Marvin Minsky and Seymour Papert's research on machine learning (1969).", "token2charspan": [[0, 8], [9, 11], [12, 18], [19, 27], [28, 37], [38, 43], [44, 47], [48, 59], [60, 62], [63, 69], [70, 76], [77, 80], [81, 88], [89, 95], [95, 97], [98, 106], [107, 109], [110, 117], [118, 126], [127, 128], [128, 132], [132, 133], [133, 134]]}
{"doc_key": "ai-dev-34", "ner": [[20, 21, "organisation"], [23, 23, "organisation"], [26, 28, "country"], [30, 33, "organisation"], [36, 36, "country"], [38, 39, "organisation"], [42, 42, "country"], [44, 44, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[30, 33, 26, 28, "general-affiliation", "", false, false], [38, 39, 36, 36, "general-affiliation", "", false, false], [44, 44, 42, 42, "general-affiliation", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Only", "a", "few", "non-Japanese", "companies", "eventually", "managed", "to", "survive", "in", "this", "market", ",", "the", "most", "important", "of", "which", "are", ":", "Adept", "Technology", ",", "St\u00e4ubli", ",", "the", "Swedish", "-", "Swiss", "company", "ABB", "Asea", "Brown", "Boveri", ",", "the", "German", "company", "KUKA", "Robotics", "and", "the", "Italian", "company", "Comau", "."], "sentence-detokenized": "Only a few non-Japanese companies eventually managed to survive in this market, the most important of which are: Adept Technology, St\u00e4ubli, the Swedish-Swiss company ABB Asea Brown Boveri, the German company KUKA Robotics and the Italian company Comau.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 23], [24, 33], [34, 44], [45, 52], [53, 55], [56, 63], [64, 66], [67, 71], [72, 78], [78, 79], [80, 83], [84, 88], [89, 98], [99, 101], [102, 107], [108, 111], [111, 112], [113, 118], [119, 129], [129, 130], [131, 138], [138, 139], [140, 143], [144, 151], [151, 152], [152, 157], [158, 165], [166, 169], [170, 174], [175, 180], [181, 187], [187, 188], [189, 192], [193, 199], [200, 207], [208, 212], [213, 221], [222, 225], [226, 229], [230, 237], [238, 245], [246, 251], [251, 252]]}
{"doc_key": "ai-dev-35", "ner": [[9, 10, "conference"], [15, 15, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 15, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Research", "activities", "include", "an", "annual", "research", "conference", ",", "the", "RuleML", "Symposium", ",", "also", "known", "as", "RuleML", "."], "sentence-detokenized": "Research activities include an annual research conference, the RuleML Symposium, also known as RuleML.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 30], [31, 37], [38, 46], [47, 57], [57, 58], [59, 62], [63, 69], [70, 79], [79, 80], [81, 85], [86, 91], [92, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-dev-36", "ner": [[9, 9, "field"], [11, 12, "field"], [14, 14, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Concepts", "are", "used", "as", "formal", "tools", "or", "models", "in", "mathematics", ",", "computer", "science", ",", "databases", "and", "artificial", "intelligence", ",", "where", "they", "are", "sometimes", "called", "classes", ",", "schemas", "or", "categories", "."], "sentence-detokenized": "Concepts are used as formal tools or models in mathematics, computer science, databases and artificial intelligence, where they are sometimes called classes, schemas or categories.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 20], [21, 27], [28, 33], [34, 36], [37, 43], [44, 46], [47, 58], [58, 59], [60, 68], [69, 76], [76, 77], [78, 87], [88, 91], [92, 102], [103, 115], [115, 116], [117, 122], [123, 127], [128, 131], [132, 141], [142, 148], [149, 156], [156, 157], [158, 165], [166, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-dev-37", "ner": [[6, 8, "organisation"], [11, 14, "organisation"], [16, 17, "organisation"], [19, 21, "organisation"], [24, 26, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "received", "awards", "from", "the", "American", "Psychological", "Association", ",", "the", "National", "Academy", "of", "Sciences", ",", "the", "Royal", ",", "Cognitive", "Neuroscience", "Society", "and", "the", "American", "Humanist", "Association", "."], "sentence-detokenized": "He has received awards from the American Psychological Association, the National Academy of Sciences, the Royal, Cognitive Neuroscience Society and the American Humanist Association.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 22], [23, 27], [28, 31], [32, 40], [41, 54], [55, 66], [66, 67], [68, 71], [72, 80], [81, 88], [89, 91], [92, 100], [100, 101], [102, 105], [106, 111], [111, 112], [113, 122], [123, 135], [136, 143], [144, 147], [148, 151], [152, 160], [161, 169], [170, 181], [181, 182]]}
{"doc_key": "ai-dev-38", "ner": [[0, 5, "person"], [7, 8, "person"], [10, 11, "person"], [17, 21, "person"], [23, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[23, 29, 17, 21, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "film", ",", "starring", "Harrison", "Ford", ",", "Rutger", "Hauer", "and", "Sean", "Young", ",", "is", "loosely", "based", "on", "Philip", "K", ".", "Dick", "'s", "novel", "Do", "Androids", "Dream", "of", "Electric", "Sheep", "?", "(", "1968", ")", "."], "sentence-detokenized": "The film, starring Harrison Ford, Rutger Hauer and Sean Young, is loosely based on Philip K. Dick's novel Do Androids Dream of Electric Sheep? (1968).", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 18], [19, 27], [28, 32], [32, 33], [34, 40], [41, 46], [47, 50], [51, 55], [56, 61], [61, 62], [63, 65], [66, 73], [74, 79], [80, 82], [83, 89], [90, 91], [91, 92], [93, 97], [97, 99], [100, 105], [106, 108], [109, 117], [118, 123], [124, 126], [127, 135], [136, 141], [141, 142], [143, 144], [144, 148], [148, 149], [149, 150]]}
{"doc_key": "ai-dev-39", "ner": [[0, 2, "task"], [3, 5, "algorithm"], [11, 12, "field"], [14, 15, "task"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 3, 5, "usage", "", false, false], [0, 2, 11, 12, "part-of", "task_part_of_field", false, false], [0, 2, 14, 15, "part-of", "task_part_of_field", false, false], [0, 2, 17, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Image", "segmentation", "using", "k-means", "clustering", "algorithms", "has", "long", "been", "used", "for", "pattern", "recognition", ",", "object", "detection", "and", "medical", "imaging", "."], "sentence-detokenized": "Image segmentation using k-means clustering algorithms has long been used for pattern recognition, object detection and medical imaging.", "token2charspan": [[0, 5], [6, 18], [19, 24], [25, 32], [33, 43], [44, 54], [55, 58], [59, 63], [64, 68], [69, 73], [74, 77], [78, 85], [86, 97], [97, 98], [99, 105], [106, 115], [116, 119], [120, 127], [128, 135], [135, 136]]}
{"doc_key": "ai-dev-40", "ner": [[14, 14, "algorithm"], [17, 18, "algorithm"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["General", "sampling", "from", "the", "truncated", "normal", "can", "be", "achieved", "using", "approximations", "to", "the", "normal", "CDF", "and", "the", "probit", "function", ",", "and", "R", "has", "a", "codertnorm", "(", ")", "/", "code", "function", "for", "generating", "truncated", "normal", "samples", "."], "sentence-detokenized": "General sampling from the truncated normal can be achieved using approximations to the normal CDF and the probit function, and R has a codertnorm()/code function for generating truncated normal samples.", "token2charspan": [[0, 7], [8, 16], [17, 21], [22, 25], [26, 35], [36, 42], [43, 46], [47, 49], [50, 58], [59, 64], [65, 79], [80, 82], [83, 86], [87, 93], [94, 97], [98, 101], [102, 105], [106, 112], [113, 121], [121, 122], [123, 126], [127, 128], [129, 132], [133, 134], [135, 145], [145, 146], [146, 147], [147, 148], [148, 152], [153, 161], [162, 165], [166, 176], [177, 186], [187, 193], [194, 201], [201, 202]]}
{"doc_key": "ai-dev-41", "ner": [[7, 10, "university"], [12, 12, "university"], [14, 16, "university"], [18, 20, "university"], [23, 25, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "also", "received", "honorary", "doctorates", "from", "the", "Universities", "of", "Newcastle", ",", "Surrey", ",", "Tel", "Aviv", "University", ",", "Simon", "Fraser", "University", "and", "the", "University", "of", "Troms\u00f8", "."], "sentence-detokenized": "He has also received honorary doctorates from the Universities of Newcastle, Surrey, Tel Aviv University, Simon Fraser University and the University of Troms\u00f8.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 20], [21, 29], [30, 40], [41, 45], [46, 49], [50, 62], [63, 65], [66, 75], [75, 76], [77, 83], [83, 84], [85, 88], [89, 93], [94, 104], [104, 105], [106, 111], [112, 118], [119, 129], [130, 133], [134, 137], [138, 148], [149, 151], [152, 158], [158, 159]]}
{"doc_key": "ai-dev-42", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "Java", "implementation", "that", "uses", "zero", "-", "based", "array", "indexes", "along", "with", "a", "convenient", "method", "for", "printing", "the", "resolved", "order", "of", "operations", ":"], "sentence-detokenized": "A Java implementation that uses zero-based array indexes along with a convenient method for printing the resolved order of operations:", "token2charspan": [[0, 1], [2, 6], [7, 21], [22, 26], [27, 31], [32, 36], [36, 37], [37, 42], [43, 48], [49, 56], [57, 62], [63, 67], [68, 69], [70, 80], [81, 87], [88, 91], [92, 100], [101, 104], [105, 113], [114, 119], [120, 122], [123, 133], [133, 134]]}
{"doc_key": "ai-dev-43", "ner": [[7, 8, "metrics"], [11, 12, "metrics"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Such", "networks", "are", "usually", "trained", "under", "a", "cross", "entropy", "(", "or", "cross", "-entropy", ")", "scheme", ",", "which", "provides", "a", "non-linear", "variant", "of", "multinomial", "logistic", "regression", "."], "sentence-detokenized": "Such networks are usually trained under a cross entropy (or cross-entropy) scheme, which provides a non-linear variant of multinomial logistic regression.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 25], [26, 33], [34, 39], [40, 41], [42, 47], [48, 55], [56, 57], [57, 59], [60, 65], [65, 73], [73, 74], [75, 81], [81, 82], [83, 88], [89, 97], [98, 99], [100, 110], [111, 118], [119, 121], [122, 133], [134, 142], [143, 153], [153, 154]]}
{"doc_key": "ai-dev-44", "ner": [[0, 0, "conference"], [3, 3, "misc"], [4, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["ACL", "has", "a", "European", "Chapter", "(", "European", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ")"], "sentence-detokenized": "ACL has a European Chapter (European Chapter of the Association for Computational Linguistics)", "token2charspan": [[0, 3], [4, 7], [8, 9], [10, 18], [19, 26], [27, 28], [28, 36], [37, 44], [45, 47], [48, 51], [52, 63], [64, 67], [68, 81], [82, 93], [93, 94]]}
{"doc_key": "ai-dev-45", "ner": [[3, 4, "researcher"], [6, 8, "researcher"], [21, 21, "misc"], [23, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 21, 21, "role", "", false, false], [6, 8, 21, 21, "role", "", false, false], [21, 21, 23, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "professors", ",", "Hal", "Abelson", "and", "Gerald", "Jay", "Sussman", ",", "chose", "to", "remain", "neutral", "-", "their", "group", "was", "referred", "to", "as", "Switzerland", "and", "Project", "MAC", "for", "the", "next", "30", "years", "."], "sentence-detokenized": "Two professors, Hal Abelson and Gerald Jay Sussman, chose to remain neutral - their group was referred to as Switzerland and Project MAC for the next 30 years.", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 27], [28, 31], [32, 38], [39, 42], [43, 50], [50, 51], [52, 57], [58, 60], [61, 67], [68, 75], [76, 77], [78, 83], [84, 89], [90, 93], [94, 102], [103, 105], [106, 108], [109, 120], [121, 124], [125, 132], [133, 136], [137, 140], [141, 144], [145, 149], [150, 152], [153, 158], [158, 159]]}
{"doc_key": "ai-dev-46", "ner": [[2, 2, "misc"], [4, 4, "researcher"], [8, 10, "university"], [15, 15, "organisation"], [20, 22, "organisation"], [28, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 4, 4, "temporal", "", false, false], [4, 4, 15, 15, "physical", "", false, false], [4, 4, 15, 15, "role", "", false, false], [4, 4, 20, 22, "role", "", false, false], [20, 22, 8, 10, "part-of", "", false, false], [28, 29, 20, 22, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["After", "his", "PhD", ",", "Ghahramani", "moved", "to", "the", "University", "of", "Toronto", "in", "1995", "as", "an", "ITRC", "Postdoctoral", "Fellow", "in", "the", "Artificial", "Intelligence", "Lab", ",", "where", "he", "worked", "with", "Geoffrey", "Hinton", "."], "sentence-detokenized": "After his PhD, Ghahramani moved to the University of Toronto in 1995 as an ITRC Postdoctoral Fellow in the Artificial Intelligence Lab, where he worked with Geoffrey Hinton.", "token2charspan": [[0, 5], [6, 9], [10, 13], [13, 14], [15, 25], [26, 31], [32, 34], [35, 38], [39, 49], [50, 52], [53, 60], [61, 63], [64, 68], [69, 71], [72, 74], [75, 79], [80, 92], [93, 99], [100, 102], [103, 106], [107, 117], [118, 130], [131, 134], [134, 135], [136, 141], [142, 144], [145, 151], [152, 156], [157, 165], [166, 172], [172, 173]]}
{"doc_key": "ai-dev-47", "ner": [[23, 24, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Later", "work", "focused", "on", "solving", "these", "problems", ",", "but", "it", "was", "only", "with", "the", "introduction", "of", "the", "modern", "computer", "and", "the", "popularisation", "of", "Maximum", "Likelihood", "(", "MLE", ")", "parameterisation", "techniques", "that", "research", "really", "took", "off", "."], "sentence-detokenized": "Later work focused on solving these problems, but it was only with the introduction of the modern computer and the popularisation of Maximum Likelihood (MLE) parameterisation techniques that research really took off.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 21], [22, 29], [30, 35], [36, 44], [44, 45], [46, 49], [50, 52], [53, 56], [57, 61], [62, 66], [67, 70], [71, 83], [84, 86], [87, 90], [91, 97], [98, 106], [107, 110], [111, 114], [115, 129], [130, 132], [133, 140], [141, 151], [152, 153], [153, 156], [156, 157], [158, 174], [175, 185], [186, 190], [191, 199], [200, 206], [207, 211], [212, 215], [215, 216]]}
{"doc_key": "ai-dev-48", "ner": [[5, 7, "person"], [9, 10, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "series", "was", "produced", "by", "David", "Fincher", "and", "starred", "Kevin", "Spacey", "."], "sentence-detokenized": "The series was produced by David Fincher and starred Kevin Spacey.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 26], [27, 32], [33, 40], [41, 44], [45, 52], [53, 58], [59, 65], [65, 66]]}
{"doc_key": "ai-dev-49", "ner": [[17, 27, "metrics"], [23, 24, "algorithm"], [33, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 24, 33, 35, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Due", "to", "the", "limitations", "of", "computing", "power", ",", "current", "in", "silico", "methods", "must", "usually", "trade", "speed", "for", "accuracy", ";", "for", "example", ",", "fast", "protein", "docking", "methods", "must", "be", "used", "instead", "of", "computationally", "expensive", "free", "energy", "calculations", "."], "sentence-detokenized": "Due to the limitations of computing power, current in silico methods must usually trade speed for accuracy; for example, fast protein docking methods must be used instead of computationally expensive free energy calculations.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 22], [23, 25], [26, 35], [36, 41], [41, 42], [43, 50], [51, 53], [54, 60], [61, 68], [69, 73], [74, 81], [82, 87], [88, 93], [94, 97], [98, 106], [106, 107], [108, 111], [112, 119], [119, 120], [121, 125], [126, 133], [134, 141], [142, 149], [150, 154], [155, 157], [158, 162], [163, 170], [171, 173], [174, 189], [190, 199], [200, 204], [205, 211], [212, 224], [224, 225]]}
{"doc_key": "ai-dev-50", "ner": [[6, 7, "country"], [9, 9, "country"], [11, 11, "country"], [13, 13, "country"], [15, 15, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "had", "over", "30", "outlets", "in", "the", "US", ",", "Canada", ",", "Mexico", ",", "Brazil", "and", "Argentina", "."], "sentence-detokenized": "It had over 30 outlets in the US, Canada, Mexico, Brazil and Argentina.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 22], [23, 25], [26, 29], [30, 32], [32, 33], [34, 40], [40, 41], [42, 48], [48, 49], [50, 56], [57, 60], [61, 70], [70, 71]]}
{"doc_key": "ai-dev-51", "ner": [[5, 5, "field"], [11, 13, "product"], [15, 17, "algorithm"], [23, 24, "task"], [26, 27, "task"], [32, 32, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 13, 5, 5, "part-of", "", false, false], [11, 13, 15, 17, "usage", "", false, false], [23, 24, 5, 5, "part-of", "task_part_of_field", false, false], [23, 24, 32, 32, "related-to", "performs", false, false], [26, 27, 5, 5, "part-of", "task_part_of_field", false, false], [26, 27, 32, 32, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["An", "example", "of", "a", "typical", "computer", "vision", "computation", "pipeline", "for", "a", "face", "recognition", "system", "using", "k", "-", "NN", ",", "including", "preprocessing", "steps", "for", "feature", "extraction", "and", "dimension", "reduction", "(", "usually", "implemented", "with", "OpenCV", ")", ":"], "sentence-detokenized": "An example of a typical computer vision computation pipeline for a face recognition system using k -NN, including preprocessing steps for feature extraction and dimension reduction (usually implemented with OpenCV):", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 23], [24, 32], [33, 39], [40, 51], [52, 60], [61, 64], [65, 66], [67, 71], [72, 83], [84, 90], [91, 96], [97, 98], [99, 100], [100, 102], [102, 103], [104, 113], [114, 127], [128, 133], [134, 137], [138, 145], [146, 156], [157, 160], [161, 170], [171, 180], [181, 182], [182, 189], [190, 201], [202, 206], [207, 213], [213, 214], [214, 215]]}
{"doc_key": "ai-dev-52", "ner": [[10, 13, "algorithm"], [15, 15, "misc"], [17, 18, "misc"], [20, 20, "misc"], [24, 24, "programlang"], [26, 26, "product"], [30, 31, "algorithm"], [34, 35, "misc"], [37, 37, "misc"], [39, 39, "misc"], [41, 41, "misc"], [48, 48, "misc"], [51, 52, "misc"], [54, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "has", "a", "rich", "set", "of", "features", ",", "libraries", "for", "logic", "programming", "with", "constraints", ",", "multithreading", ",", "unit", "testing", ",", "GUI", ",", "interfaces", "to", "Java", ",", "ODBC", "and", "others", ",", "literary", "programming", ",", "a", "web", "server", ",", "SGML", ",", "RDF", ",", "RDFS", ",", "development", "tools", "(", "including", "an", "IDE", "with", "a", "GUI", "debugger", "and", "GUI", "profiles", ")", "and", "extensive", "documentation", "."], "sentence-detokenized": "It has a rich set of features, libraries for logic programming with constraints, multithreading, unit testing, GUI, interfaces to Java, ODBC and others, literary programming, a web server, SGML, RDF, RDFS, development tools (including an IDE with a GUI debugger and GUI profiles) and extensive documentation.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 13], [14, 17], [18, 20], [21, 29], [29, 30], [31, 40], [41, 44], [45, 50], [51, 62], [63, 67], [68, 79], [79, 80], [81, 95], [95, 96], [97, 101], [102, 109], [109, 110], [111, 114], [114, 115], [116, 126], [127, 129], [130, 134], [134, 135], [136, 140], [141, 144], [145, 151], [151, 152], [153, 161], [162, 173], [173, 174], [175, 176], [177, 180], [181, 187], [187, 188], [189, 193], [193, 194], [195, 198], [198, 199], [200, 204], [204, 205], [206, 217], [218, 223], [224, 225], [225, 234], [235, 237], [238, 241], [242, 246], [247, 248], [249, 252], [253, 261], [262, 265], [266, 269], [270, 278], [278, 279], [280, 283], [284, 293], [294, 307], [307, 308]]}
{"doc_key": "ai-dev-53", "ner": [[1, 2, "field"], [4, 5, "field"], [10, 12, "misc"], [14, 18, "misc"], [19, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 12, 1, 2, "part-of", "", true, false], [10, 12, 4, 5, "part-of", "", false, false], [10, 12, 19, 21, "type-of", "", false, false], [14, 18, 1, 2, "part-of", "", false, false], [14, 18, 4, 5, "part-of", "", false, false], [14, 18, 19, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "computer", "vision", "and", "image", "processing", ",", "the", "concept", "of", "scalar", "space", "representation", "and", "Gaussian", "derived", "operators", "is", "a", "canonical", "multiscale", "representation", "."], "sentence-detokenized": "In computer vision and image processing, the concept of scalar space representation and Gaussian derived operators is a canonical multiscale representation.", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 22], [23, 28], [29, 39], [39, 40], [41, 44], [45, 52], [53, 55], [56, 62], [63, 68], [69, 83], [84, 87], [88, 96], [97, 104], [105, 114], [115, 117], [118, 119], [120, 129], [130, 140], [141, 155], [155, 156]]}
{"doc_key": "ai-dev-54", "ner": [[7, 11, "organisation"], [20, 24, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 11, 20, 24, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "also", "the", "President", "of", "the", "Neural", "Information", "Processing", "Systems", "Foundation", ",", "a", "non-profit", "organization", "that", "oversees", "the", "annual", "Neural", "Information", "Processing", "Systems", "Conference", "."], "sentence-detokenized": "He is also the President of the Neural Information Processing Systems Foundation, a non-profit organization that oversees the annual Neural Information Processing Systems Conference.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 14], [15, 24], [25, 27], [28, 31], [32, 38], [39, 50], [51, 61], [62, 69], [70, 80], [80, 81], [82, 83], [84, 94], [95, 107], [108, 112], [113, 121], [122, 125], [126, 132], [133, 139], [140, 151], [152, 162], [163, 170], [171, 181], [181, 182]]}
{"doc_key": "ai-dev-55", "ner": [[6, 7, "metrics"], [13, 14, "misc"], [18, 18, "task"], [20, 22, "metrics"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[6, 7, 13, 14, "type-of", "", false, false], [18, 18, 20, 22, "usage", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["For", "regression", "analysis", "problems", ",", "the", "squared", "error", "can", "be", "used", "as", "the", "loss", "function", ",", "and", "for", "classification", ",", "the", "cross", "entropy", "can", "be", "used", "."], "sentence-detokenized": "For regression analysis problems, the squared error can be used as the loss function, and for classification, the cross entropy can be used.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 32], [32, 33], [34, 37], [38, 45], [46, 51], [52, 55], [56, 58], [59, 63], [64, 66], [67, 70], [71, 75], [76, 84], [84, 85], [86, 89], [90, 93], [94, 108], [108, 109], [110, 113], [114, 119], [120, 127], [128, 131], [132, 134], [135, 139], [139, 140]]}
{"doc_key": "ai-dev-56", "ner": [[0, 0, "researcher"], [17, 20, "conference"], [22, 27, "conference"], [36, 36, "university"], [40, 41, "field"], [50, 54, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 17, 20, "role", "", false, false], [0, 0, 36, 36, "physical", "", false, false], [0, 0, 36, 36, "role", "", false, false], [0, 0, 50, 54, "role", "", false, false], [17, 20, 22, 27, "named", "same", false, false], [36, 36, 40, 41, "related-to", "subject_of_study_at", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Lafferty", "held", "many", "prestigious", "positions", ",", "including", ":", "1", ")", "program", "co-chair", "and", "general", "co-chair", "of", "the", "Neural", "Information", "Processing", "Systems", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", ")", "Foundation", "conferences", ";", "2", ")", "co-director", "of", "CMU", "'s", "new", "Ph.D.", "Machine", "Learning", "Ph.D.", "Program", ";", "3", ")", "co-editor", "of", "the", "Journal", "of", "Machine", "Learning", "Research"], "sentence-detokenized": "Lafferty held many prestigious positions, including: 1) program co-chair and general co-chair of the Neural Information Processing Systems (Conference on Neural Information Processing Systems) Foundation conferences; 2) co-director of CMU's new Ph.D. Machine Learning Ph.D. Program; 3) co-editor of the Journal of Machine Learning Research", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 30], [31, 40], [40, 41], [42, 51], [51, 52], [53, 54], [54, 55], [56, 63], [64, 72], [73, 76], [77, 84], [85, 93], [94, 96], [97, 100], [101, 107], [108, 119], [120, 130], [131, 138], [139, 140], [140, 150], [151, 153], [154, 160], [161, 172], [173, 183], [184, 191], [191, 192], [193, 203], [204, 215], [215, 216], [217, 218], [218, 219], [220, 231], [232, 234], [235, 238], [238, 240], [241, 244], [245, 250], [251, 258], [259, 267], [268, 273], [274, 281], [281, 282], [283, 284], [284, 285], [286, 295], [296, 298], [299, 302], [303, 310], [311, 313], [314, 321], [322, 330], [331, 339]]}
{"doc_key": "ai-dev-57", "ner": [[0, 1, "misc"], [5, 5, "algorithm"], [7, 7, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 0, 1, "type-of", "", false, false], [7, 7, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Convex", "algorithms", ",", "such", "as", "AdaBoost", "and", "LogitBoost", ",", "can", "be", "defeated", "by", "random", "noise", ",", "so", "they", "can", "not", "learn", "basic", "and", "learnable", "combinations", "of", "weak", "hypotheses", "."], "sentence-detokenized": "Convex algorithms, such as AdaBoost and LogitBoost, can be defeated by random noise, so they cannot learn basic and learnable combinations of weak hypotheses.", "token2charspan": [[0, 6], [7, 17], [17, 18], [19, 23], [24, 26], [27, 35], [36, 39], [40, 50], [50, 51], [52, 55], [56, 58], [59, 67], [68, 70], [71, 77], [78, 83], [83, 84], [85, 87], [88, 92], [93, 96], [96, 99], [100, 105], [106, 111], [112, 115], [116, 125], [126, 138], [139, 141], [142, 146], [147, 157], [157, 158]]}
{"doc_key": "ai-dev-58", "ner": [[0, 1, "product"], [3, 8, "product"], [12, 14, "algorithm"], [21, 21, "algorithm"], [25, 30, "task"], [32, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 3, 8, "type-of", "", false, false], [0, 1, 12, 14, "usage", "", false, false], [0, 1, 21, 21, "usage", "", false, false], [21, 21, 25, 30, "related-to", "used_for", true, false], [21, 21, 32, 34, "related-to", "used_for", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Apertium", "is", "a", "machine", "translation", "system", "with", "shallow", "transfer", ",", "which", "uses", "finite", "state", "transducers", "for", "all", "its", "lexical", "transformations", "and", "hidden", "Markov", "models", "for", "part", "-", "of", "-", "speech", "tagging", "or", "word", "category", "disambiguation", "."], "sentence-detokenized": "Apertium is a machine translation system with shallow transfer, which uses finite state transducers for all its lexical transformations and hidden Markov models for part-of-speech tagging or word category disambiguation.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 21], [22, 33], [34, 40], [41, 45], [46, 53], [54, 62], [62, 63], [64, 69], [70, 74], [75, 81], [82, 87], [88, 99], [100, 103], [104, 107], [108, 111], [112, 119], [120, 135], [136, 139], [140, 146], [147, 153], [154, 160], [161, 164], [165, 169], [169, 170], [170, 172], [172, 173], [173, 179], [180, 187], [188, 190], [191, 195], [196, 204], [205, 219], [219, 220]]}
{"doc_key": "ai-dev-59", "ner": [[1, 2, "misc"], [15, 17, "metrics"], [30, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 15, 17, "related-to", "", true, false], [15, 17, 30, 31, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "natural", "gradient", "of", "mathE", "f", "(", "x", ")", "/", "math", ",", "consistent", "with", "the", "Fisher", "information", "metric", "(", "an", "information", "distance", "measure", "between", "probability", "distributions", "and", "the", "curvature", "of", "relative", "entropy", ")", ",", "is", "now"], "sentence-detokenized": "The natural gradient of mathE f (x) / math, consistent with the Fisher information metric (an information distance measure between probability distributions and the curvature of relative entropy), is now", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 23], [24, 29], [30, 31], [32, 33], [33, 34], [34, 35], [36, 37], [38, 42], [42, 43], [44, 54], [55, 59], [60, 63], [64, 70], [71, 82], [83, 89], [90, 91], [91, 93], [94, 105], [106, 114], [115, 122], [123, 130], [131, 142], [143, 156], [157, 160], [161, 164], [165, 174], [175, 177], [178, 186], [187, 194], [194, 195], [195, 196], [197, 199], [200, 203]]}
{"doc_key": "ai-dev-60", "ner": [[0, 4, "programlang"], [7, 10, "product"], [12, 12, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 10, 0, 4, "origin", "", false, false], [12, 12, 0, 4, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "S", "programming", "language", "has", "inspired", "the", "S", "'", "-", "PLUS", "and", "R", "systems", "."], "sentence-detokenized": "The S programming language has inspired the S'-PLUS and R systems.", "token2charspan": [[0, 3], [4, 5], [6, 17], [18, 26], [27, 30], [31, 39], [40, 43], [44, 45], [45, 46], [46, 47], [47, 51], [52, 55], [56, 57], [58, 65], [65, 66]]}
{"doc_key": "ai-dev-61", "ner": [[5, 5, "product"], [10, 10, "product"], [12, 14, "product"], [18, 20, "researcher"], [22, 23, "researcher"], [25, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 10, 10, "named", "same", false, false], [12, 14, 10, 10, "origin", "derived_from", false, false], [12, 14, 18, 20, "origin", "", false, false], [12, 14, 22, 23, "origin", "", false, false], [12, 14, 25, 26, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "most", "influential", "implementation", "of", "Planner", "was", "the", "subset", "of", "Planner", "called", "Micro", "-", "Planner", ",", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "."], "sentence-detokenized": "The most influential implementation of Planner was the subset of Planner called Micro-Planner, implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd.", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 35], [36, 38], [39, 46], [47, 50], [51, 54], [55, 61], [62, 64], [65, 72], [73, 79], [80, 85], [85, 86], [86, 93], [93, 94], [95, 106], [107, 109], [110, 116], [117, 120], [121, 128], [128, 129], [130, 136], [137, 145], [146, 149], [150, 155], [156, 164], [164, 165]]}
{"doc_key": "ai-dev-62", "ner": [[4, 6, "country"], [8, 10, "researcher"], [20, 20, "misc"], [21, 24, "university"], [30, 32, "misc"], [38, 39, "misc"], [42, 44, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [[8, 10, 4, 6, "general-affiliation", "from_country", false, false], [21, 24, 20, 20, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "1779", ",", "the", "German", "-", "Danish", "scientist", "Christian", "Gottlieb", "Kratzenstein", "won", "first", "prize", "in", "a", "competition", "organised", "by", "the", "Russian", "Imperial", "Academy", "of", "Sciences", "for", "models", "of", "the", "human", "vocal", "tract", "that", "could", "produce", "the", "five", "long", "vowel", "sounds", "(", "in", "international", "phonetic", "alphabet", "notation", ")", ":"], "sentence-detokenized": "In 1779, the German-Danish scientist Christian Gottlieb Kratzenstein won first prize in a competition organised by the Russian Imperial Academy of Sciences for models of the human vocal tract that could produce the five long vowel sounds (in international phonetic alphabet notation):", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 19], [19, 20], [20, 26], [27, 36], [37, 46], [47, 55], [56, 68], [69, 72], [73, 78], [79, 84], [85, 87], [88, 89], [90, 101], [102, 111], [112, 114], [115, 118], [119, 126], [127, 135], [136, 143], [144, 146], [147, 155], [156, 159], [160, 166], [167, 169], [170, 173], [174, 179], [180, 185], [186, 191], [192, 196], [197, 202], [203, 210], [211, 214], [215, 219], [220, 224], [225, 230], [231, 237], [238, 239], [239, 241], [242, 255], [256, 264], [265, 273], [274, 282], [282, 283], [283, 284]]}
{"doc_key": "ai-dev-63", "ner": [[5, 6, "product"], [8, 9, "misc"], [12, 16, "misc"], [34, 36, "misc"], [58, 59, "task"], [64, 65, "product"], [67, 67, "product"], [71, 72, "task"], [74, 75, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 6, 64, 65, "related-to", "supports_program", false, false], [5, 6, 67, 67, "related-to", "supports_program", false, false], [8, 9, 5, 6, "part-of", "", false, false], [12, 16, 5, 6, "part-of", "", false, false], [34, 36, 5, 6, "part-of", "", false, false], [58, 59, 5, 6, "part-of", "", false, false], [71, 72, 5, 6, "part-of", "", false, false], [74, 75, 5, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Among", "the", "new", "features", "in", "Office", "XP", "are", "smart", "tags", ",", "a", "selection", "-", "based", "search", "function", "that", "recognizes", "different", "types", "of", "text", "in", "a", "document", "so", "users", "can", "perform", "additional", "actions", ";", "a", "task", "screen", "interface", "that", "groups", "popular", "commands", "in", "the", "menu", "bar", "on", "the", "right", "side", "of", "the", "screen", "for", "easy", "quick", "access", ";", "new", "document", "collaboration", "capabilities", ",", "support", "for", "MSN", "Groups", "and", "SharePoint", ";", "and", "integrated", "handwriting", "recognition", "and", "speech", "recognition", "."], "sentence-detokenized": "Among the new features in Office XP are smart tags, a selection-based search function that recognizes different types of text in a document so users can perform additional actions; a task screen interface that groups popular commands in the menu bar on the right side of the screen for easy quick access; new document collaboration capabilities, support for MSN Groups and SharePoint; and integrated handwriting recognition and speech recognition.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 22], [23, 25], [26, 32], [33, 35], [36, 39], [40, 45], [46, 50], [50, 51], [52, 53], [54, 63], [63, 64], [64, 69], [70, 76], [77, 85], [86, 90], [91, 101], [102, 111], [112, 117], [118, 120], [121, 125], [126, 128], [129, 130], [131, 139], [140, 142], [143, 148], [149, 152], [153, 160], [161, 171], [172, 179], [179, 180], [181, 182], [183, 187], [188, 194], [195, 204], [205, 209], [210, 216], [217, 224], [225, 233], [234, 236], [237, 240], [241, 245], [246, 249], [250, 252], [253, 256], [257, 262], [263, 267], [268, 270], [271, 274], [275, 281], [282, 285], [286, 290], [291, 296], [297, 303], [303, 304], [305, 308], [309, 317], [318, 331], [332, 344], [344, 345], [346, 353], [354, 357], [358, 361], [362, 368], [369, 372], [373, 383], [383, 384], [385, 388], [389, 399], [400, 411], [412, 423], [424, 427], [428, 434], [435, 446], [446, 447]]}
{"doc_key": "ai-dev-64", "ner": [[11, 12, "algorithm"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 15, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "many", "applications", ",", "the", "devices", "in", "these", "networks", "use", "a", "sigmoid", "function", "as", "an", "activation", "function", "."], "sentence-detokenized": "In many applications, the devices in these networks use a sigmoid function as an activation function.", "token2charspan": [[0, 2], [3, 7], [8, 20], [20, 21], [22, 25], [26, 33], [34, 36], [37, 42], [43, 51], [52, 55], [56, 57], [58, 65], [66, 74], [75, 77], [78, 80], [81, 91], [92, 100], [100, 101]]}
{"doc_key": "ai-dev-65", "ner": [[3, 3, "researcher"], [12, 19, "organisation"], [29, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 12, 19, "role", "", false, false], [3, 3, 29, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2001", ",", "Mehler", "was", "elected", "an", "Honorary", "Foreign", "Member", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "and", "in", "2003", "he", "was", "elected", "a", "Fellow", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In 2001, Mehler was elected an Honorary Foreign Member of the American Academy of Arts and Sciences, and in 2003 he was elected a Fellow of the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 27], [28, 30], [31, 39], [40, 47], [48, 54], [55, 57], [58, 61], [62, 70], [71, 78], [79, 81], [82, 86], [87, 90], [91, 99], [99, 100], [101, 104], [105, 107], [108, 112], [113, 115], [116, 119], [120, 127], [128, 129], [130, 136], [137, 139], [140, 143], [144, 152], [153, 164], [165, 168], [169, 172], [173, 184], [185, 187], [188, 195], [195, 196]]}
{"doc_key": "ai-dev-66", "ner": [[6, 8, "task"], [10, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 10, 12, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "extension", "of", "this", "concept", "to", "non", "-binary", "classifications", "yields", "the", "confusion", "matrix", "."], "sentence-detokenized": "The extension of this concept to non-binary classifications yields the confusion matrix.", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 21], [22, 29], [30, 32], [33, 36], [36, 43], [44, 59], [60, 66], [67, 70], [71, 80], [81, 87], [87, 88]]}
{"doc_key": "ai-dev-67", "ner": [[16, 17, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "updated", "estimate", "of", "the", "variance", "of", "the", "measurement", "noise", "can", "be", "obtained", "by", "calculating", "the", "maximum", "likelihood"], "sentence-detokenized": "An updated estimate of the variance of the measurement noise can be obtained by calculating the maximum likelihood", "token2charspan": [[0, 2], [3, 10], [11, 19], [20, 22], [23, 26], [27, 35], [36, 38], [39, 42], [43, 54], [55, 60], [61, 64], [65, 67], [68, 76], [77, 79], [80, 91], [92, 95], [96, 103], [104, 114]]}
{"doc_key": "ai-dev-68", "ner": [[1, 2, "field"], [4, 5, "algorithm"], [10, 11, "field"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 10, 11, "usage", "", true, false], [4, 5, 13, 14, "related-to", "", true, false], [10, 11, 1, 2, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "machine", "learning", ",", "the", "perceptron", "is", "an", "algorithm", "for", "supervised", "learning", "of", "binary", "classification", "."], "sentence-detokenized": "In machine learning, the perceptron is an algorithm for supervised learning of binary classification.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 24], [25, 35], [36, 38], [39, 41], [42, 51], [52, 55], [56, 66], [67, 75], [76, 78], [79, 85], [86, 100], [100, 101]]}
{"doc_key": "ai-dev-69", "ner": [[11, 12, "field"], [14, 14, "field"], [18, 23, "conference"], [25, 29, "conference"], [31, 37, "conference"], [39, 43, "conference"], [45, 49, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[18, 23, 11, 12, "topic", "", false, false], [18, 23, 14, 14, "topic", "", false, false], [25, 29, 11, 12, "topic", "", false, false], [25, 29, 14, 14, "topic", "", false, false], [31, 37, 11, 12, "topic", "", false, false], [31, 37, 14, 14, "topic", "", false, false], [39, 43, 11, 12, "topic", "", false, false], [39, 43, 14, 14, "topic", "", false, false], [45, 49, 11, 12, "topic", "", false, false], [45, 49, 14, 14, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["She", "has", "also", "served", "as", "area", "chair", "for", "several", "conferences", "on", "machine", "learning", "and", "vision", ",", "including", "the", "Conference", "on", "Neural", "Information", "Processing", "Systems", ",", "International", "Conference", "on", "Learning", "Representations", ",", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "International", "Conference", "on", "Computer", "Vision", "and", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "She has also served as area chair for several conferences on machine learning and vision, including the Conference on Neural Information Processing Systems, International Conference on Learning Representations, Conference on Computer Vision and Pattern Recognition, International Conference on Computer Vision and European Conference on Computer Vision.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 19], [20, 22], [23, 27], [28, 33], [34, 37], [38, 45], [46, 57], [58, 60], [61, 68], [69, 77], [78, 81], [82, 88], [88, 89], [90, 99], [100, 103], [104, 114], [115, 117], [118, 124], [125, 136], [137, 147], [148, 155], [155, 156], [157, 170], [171, 181], [182, 184], [185, 193], [194, 209], [209, 210], [211, 221], [222, 224], [225, 233], [234, 240], [241, 244], [245, 252], [253, 264], [264, 265], [266, 279], [280, 290], [291, 293], [294, 302], [303, 309], [310, 313], [314, 322], [323, 333], [334, 336], [337, 345], [346, 352], [352, 353]]}
{"doc_key": "ai-dev-70", "ner": [[0, 2, "algorithm"], [8, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 10, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "condensation", "algorithm", "has", "also", "been", "applied", "to", "face", "recognition", "system", "in", "a", "video", "sequence", "."], "sentence-detokenized": "The condensation algorithm has also been applied to face recognition system in a video sequence.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 30], [31, 35], [36, 40], [41, 48], [49, 51], [52, 56], [57, 68], [69, 75], [76, 78], [79, 80], [81, 86], [87, 95], [95, 96]]}
{"doc_key": "ai-dev-71", "ner": [[0, 2, "task"], [7, 7, "organisation"], [17, 17, "conference"], [21, 25, "academicjournal"], [29, 29, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[17, 17, 0, 2, "topic", "", false, false], [17, 17, 7, 7, "origin", "", false, false], [21, 25, 0, 2, "topic", "", false, false], [21, 25, 7, 7, "origin", "", true, false], [29, 29, 21, 25, "role", "edited_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Dissemination", "of", "information", "is", "also", "part", "of", "ELRA", "'s", "tasks", ",", "both", "through", "the", "organisation", "of", "the", "LREC", "conference", "and", "the", "Language", "Resources", "and", "Evaluation", "Journal", ",", "published", "by", "Springer", "."], "sentence-detokenized": "Dissemination of information is also part of ELRA's tasks, both through the organisation of the LREC conference and the Language Resources and Evaluation Journal, published by Springer.", "token2charspan": [[0, 13], [14, 16], [17, 28], [29, 31], [32, 36], [37, 41], [42, 44], [45, 49], [49, 51], [52, 57], [57, 58], [59, 63], [64, 71], [72, 75], [76, 88], [89, 91], [92, 95], [96, 100], [101, 111], [112, 115], [116, 119], [120, 128], [129, 138], [139, 142], [143, 153], [154, 161], [161, 162], [163, 172], [173, 175], [176, 184], [184, 185]]}
{"doc_key": "ai-dev-72", "ner": [[1, 8, "field"], [10, 11, "field"], [14, 16, "field"], [18, 19, "field"], [55, 60, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 8, 55, 60, "named", "", false, false], [14, 16, 1, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "linear", "time", "invariant", "(", "LTI", ")", "systems", "theory", ",", "control", "theory", "and", "in", "digital", "signal", "processing", "or", "signal", "processing", ",", "the", "relationship", "between", "the", "input", "signal", ",", "math", "\\", "displaystyle", "x", "(", "t", ")", "/", "math", ",", "and", "the", "output", "signal", ",", "math", "\\", "displaystyle", "y", "(", "t", ")", "/", "math", ",", "in", "an", "LTI", "system", "is", "controlled", "by", "a", "convolution", "operation", ":"], "sentence-detokenized": "In linear time invariant (LTI) systems theory, control theory and in digital signal processing or signal processing, the relationship between the input signal, math\\ displaystyle x(t)/math, and the output signal, math\\ displaystyle y(t)/math, in an LTI system is controlled by a convolution operation:", "token2charspan": [[0, 2], [3, 9], [10, 14], [15, 24], [25, 26], [26, 29], [29, 30], [31, 38], [39, 45], [45, 46], [47, 54], [55, 61], [62, 65], [66, 68], [69, 76], [77, 83], [84, 94], [95, 97], [98, 104], [105, 115], [115, 116], [117, 120], [121, 133], [134, 141], [142, 145], [146, 151], [152, 158], [158, 159], [160, 164], [164, 165], [166, 178], [179, 180], [180, 181], [181, 182], [182, 183], [183, 184], [184, 188], [188, 189], [190, 193], [194, 197], [198, 204], [205, 211], [211, 212], [213, 217], [217, 218], [219, 231], [232, 233], [233, 234], [234, 235], [235, 236], [236, 237], [237, 241], [241, 242], [243, 245], [246, 248], [249, 252], [253, 259], [260, 262], [263, 273], [274, 276], [277, 278], [279, 290], [291, 300], [300, 301]]}
{"doc_key": "ai-dev-73", "ner": [[16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 31, "field"], [33, 34, "product"], [36, 37, "field"], [39, 39, "field"], [42, 43, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Because", "of", "its", "generality", ",", "the", "field", "is", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "game", "theory", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimization", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", ",", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Because of its generality, the field is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, statistics, and genetic algorithms.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 25], [25, 26], [27, 30], [31, 36], [37, 39], [40, 47], [48, 50], [51, 55], [56, 61], [62, 73], [73, 74], [75, 79], [80, 82], [83, 87], [88, 94], [94, 95], [96, 103], [104, 110], [110, 111], [112, 122], [123, 131], [131, 132], [133, 144], [145, 151], [151, 152], [153, 163], [163, 164], [164, 169], [170, 182], [182, 183], [184, 195], [196, 203], [203, 204], [205, 210], [211, 223], [223, 224], [225, 235], [235, 236], [237, 240], [241, 248], [249, 259], [259, 260]]}
{"doc_key": "ai-dev-74", "ner": [[0, 2, "algorithm"], [13, 14, "field"], [25, 26, "algorithm"], [30, 31, "algorithm"], [34, 34, "algorithm"], [35, 37, "researcher"], [39, 40, "researcher"], [42, 44, "researcher"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[13, 14, 0, 2, "usage", "", true, false], [25, 26, 13, 14, "part-of", "", true, false], [30, 31, 13, 14, "part-of", "", true, false], [34, 34, 13, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 2, 3, 4], "sentence": ["Stochastic", "gradient", "descent", "is", "a", "popular", "algorithm", "for", "training", "a", "wide", "range", "of", "machine", "learning", "models", ",", "including", "(", "linear", ")", "support", "vector", "machines", ",", "logistic", "regression", "(", "see", "e.g.", "Vowpal", "Wabbit", ")", "and", "graphical", "models.Jenny", "Rose", "Finkel", ",", "Alex", "Kleeman", ",", "Christopher", "D.", "Manning", "(", "2008", ")", "."], "sentence-detokenized": "Stochastic gradient descent is a popular algorithm for training a wide range of machine learning models, including (linear) support vector machines, logistic regression (see e.g. Vowpal Wabbit) and graphical models.Jenny Rose Finkel, Alex Kleeman, Christopher D. Manning (2008).", "token2charspan": [[0, 10], [11, 19], [20, 27], [28, 30], [31, 32], [33, 40], [41, 50], [51, 54], [55, 63], [64, 65], [66, 70], [71, 76], [77, 79], [80, 87], [88, 96], [97, 103], [103, 104], [105, 114], [115, 116], [116, 122], [122, 123], [124, 131], [132, 138], [139, 147], [147, 148], [149, 157], [158, 168], [169, 170], [170, 173], [174, 178], [179, 185], [186, 192], [192, 193], [194, 197], [198, 207], [208, 220], [221, 225], [226, 232], [232, 233], [234, 238], [239, 246], [246, 247], [248, 259], [260, 262], [263, 270], [271, 272], [272, 276], [276, 277], [277, 278]]}
{"doc_key": "ai-dev-75", "ner": [[8, 8, "organisation"], [12, 13, "product"], [20, 20, "country"], [22, 25, "university"], [27, 27, "location"], [29, 31, "university"], [33, 33, "location"], [35, 36, "university"], [38, 38, "location"], [40, 42, "university"], [44, 44, "location"], [46, 47, "university"], [49, 49, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 22, 25, "role", "donates_to", false, false], [8, 8, 29, 31, "role", "donates_to", false, false], [8, 8, 35, 36, "role", "donates_to", false, false], [8, 8, 40, 42, "role", "donates_to", false, false], [8, 8, 46, 47, "role", "donates_to", false, false], [12, 13, 8, 8, "origin", "donates", true, false], [22, 25, 27, 27, "physical", "", false, false], [27, 27, 20, 20, "physical", "", false, false], [29, 31, 33, 33, "physical", "", false, false], [33, 33, 20, 20, "physical", "", false, false], [35, 36, 38, 38, "physical", "", false, false], [38, 38, 20, 20, "physical", "", false, false], [40, 42, 44, 44, "physical", "", false, false], [44, 44, 20, 20, "physical", "", false, false], [46, 47, 49, 49, "physical", "", false, false], [49, 49, 20, 20, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "sentence": ["In", "August", "2011", ",", "it", "was", "announced", "that", "Hitachi", "would", "donate", "an", "electron", "microscope", "to", "each", "of", "five", "universities", "in", "Indonesia", "(", "University", "of", "North", "Sumatra", "in", "Medan", ",", "Indonesian", "Christian", "University", "in", "Jakarta", ",", "Padjadjaran", "University", "in", "Bandung", ",", "Jenderal", "Soedirman", "University", "in", "Purwokerto", "and", "Muhammadiyah", "University", "in", "Malang", ")", "."], "sentence-detokenized": "In August 2011, it was announced that Hitachi would donate an electron microscope to each of five universities in Indonesia (University of North Sumatra in Medan, Indonesian Christian University in Jakarta, Padjadjaran University in Bandung, Jenderal Soedirman University in Purwokerto and Muhammadiyah University in Malang).", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 18], [19, 22], [23, 32], [33, 37], [38, 45], [46, 51], [52, 58], [59, 61], [62, 70], [71, 81], [82, 84], [85, 89], [90, 92], [93, 97], [98, 110], [111, 113], [114, 123], [124, 125], [125, 135], [136, 138], [139, 144], [145, 152], [153, 155], [156, 161], [161, 162], [163, 173], [174, 183], [184, 194], [195, 197], [198, 205], [205, 206], [207, 218], [219, 229], [230, 232], [233, 240], [240, 241], [242, 250], [251, 260], [261, 271], [272, 274], [275, 285], [286, 289], [290, 302], [303, 313], [314, 316], [317, 323], [323, 324], [324, 325]]}
{"doc_key": "ai-dev-76", "ner": [[3, 4, "field"], [7, 8, "algorithm"], [10, 11, "algorithm"], [23, 23, "metrics"]], "ner_mapping_to_source": [1, 2, 3, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Optimization", "techniques", "in", "operations", "research", "such", "as", "linear", "programming", "or", "dynamic", "programming", "are", "often", "impractical", "for", "large", "software", "development", "problems", "due", "to", "their", "complexity", "."], "sentence-detokenized": "Optimization techniques in operations research such as linear programming or dynamic programming are often impractical for large software development problems due to their complexity.", "token2charspan": [[0, 12], [13, 23], [24, 26], [27, 37], [38, 46], [47, 51], [52, 54], [55, 61], [62, 73], [74, 76], [77, 84], [85, 96], [97, 100], [101, 106], [107, 118], [119, 122], [123, 128], [129, 137], [138, 149], [150, 158], [159, 162], [163, 165], [166, 171], [172, 182], [182, 183]]}
{"doc_key": "ai-dev-77", "ner": [[0, 0, "metrics"], [6, 6, "metrics"], [8, 10, "metrics"], [15, 17, "metrics"], [20, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 6, "compare", "", false, false], [0, 0, 8, 10, "compare", "", false, false], [15, 17, 8, 10, "part-of", "", false, false], [20, 24, 8, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sensitivity", "is", "not", "the", "same", "as", "precision", "or", "positive", "predictive", "value", "(", "the", "ratio", "of", "TRUE", "positive", "results", "to", "combined", "TRUE", "and", "FALSE", "positive", "results", ")", ",", "which", "is", "as", "much", "a", "statement", "about", "the", "proportion", "of", "actual", "positive", "results", "in", "the", "tested", "population", "as", "about", "the", "test", "."], "sentence-detokenized": "Sensitivity is not the same as precision or positive predictive value (the ratio of TRUE positive results to combined TRUE and FALSE positive results), which is as much a statement about the proportion of actual positive results in the tested population as about the test.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 22], [23, 27], [28, 30], [31, 40], [41, 43], [44, 52], [53, 63], [64, 69], [70, 71], [71, 74], [75, 80], [81, 83], [84, 88], [89, 97], [98, 105], [106, 108], [109, 117], [118, 122], [123, 126], [127, 132], [133, 141], [142, 149], [149, 150], [150, 151], [152, 157], [158, 160], [161, 163], [164, 168], [169, 170], [171, 180], [181, 186], [187, 190], [191, 201], [202, 204], [205, 211], [212, 220], [221, 228], [229, 231], [232, 235], [236, 242], [243, 253], [254, 256], [257, 262], [263, 266], [267, 271], [271, 272]]}
{"doc_key": "ai-dev-78", "ner": [[5, 6, "person"], [12, 12, "product"], [15, 15, "person"], [30, 30, "person"], [37, 38, "person"], [42, 43, "person"], [48, 50, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 6, 42, 43, "named", "same", false, false], [12, 12, 5, 6, "artifact", "", false, false], [37, 38, 48, 50, "role", "convinces", false, false], [48, 50, 12, 12, "role", "producer", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "script", "was", "written", "by", "Hampton", "Fancher", "!", "--", "not", "originally", "titled", "Android", "--", "see", "Sammon", ",", "pp.", "32", "and", "38", "for", "an", "explanation", "--", "was", "sold", "in", "1977", ".", "Sammon", ",", "pp.", "23", "-", "30", "Producer", "Michael", "Deeley", "became", "interested", "in", "Fancher", "'s", "draft", "and", "persuaded", "director", "Ridley", "Scott", "to", "film", "it", "."], "sentence-detokenized": "The script was written by Hampton Fancher! -- not originally titled Android -- see Sammon, pp. 32 and 38 for an explanation -- was sold in 1977. Sammon, pp. 23-30 Producer Michael Deeley became interested in Fancher's draft and persuaded director Ridley Scott to film it.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 22], [23, 25], [26, 33], [34, 41], [41, 42], [43, 45], [46, 49], [50, 60], [61, 67], [68, 75], [76, 78], [79, 82], [83, 89], [89, 90], [91, 94], [95, 97], [98, 101], [102, 104], [105, 108], [109, 111], [112, 123], [124, 126], [127, 130], [131, 135], [136, 138], [139, 143], [143, 144], [145, 151], [151, 152], [153, 156], [157, 159], [159, 160], [160, 162], [163, 171], [172, 179], [180, 186], [187, 193], [194, 204], [205, 207], [208, 215], [215, 217], [218, 223], [224, 227], [228, 237], [238, 246], [247, 253], [254, 259], [260, 262], [263, 267], [268, 270], [270, 271]]}
{"doc_key": "ai-dev-79", "ner": [[0, 1, "field"], [3, 4, "task"], [6, 7, "task"], [10, 12, "misc"], [14, 15, "field"], [17, 19, "task"], [21, 22, "task"], [24, 24, "field"], [28, 31, "task"], [33, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 4, 0, 1, "part-of", "", false, false], [6, 7, 0, 1, "part-of", "", false, false], [10, 12, 0, 1, "part-of", "", false, false], [14, 15, 0, 1, "part-of", "", false, false], [17, 19, 0, 1, "part-of", "", false, false], [21, 22, 0, 1, "part-of", "", false, false], [24, 24, 0, 1, "part-of", "", false, false], [28, 31, 0, 1, "part-of", "", false, false], [33, 33, 0, 1, "part-of", "", false, false], [35, 36, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Text", "analysis", "includes", "information", "retrieval", ",", "lexical", "analysis", "to", "study", "word", "frequency", "distributions", ",", "pattern", "recognition", ",", "tagging", "/", "annotation", ",", "information", "extraction", ",", "data", "mining", "techniques", "including", "link", "and", "association", "analysis", ",", "visualisation", "and", "predictive", "analysis", "."], "sentence-detokenized": "Text analysis includes information retrieval, lexical analysis to study word frequency distributions, pattern recognition, tagging/annotation, information extraction, data mining techniques including link and association analysis, visualisation and predictive analysis.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 34], [35, 44], [44, 45], [46, 53], [54, 62], [63, 65], [66, 71], [72, 76], [77, 86], [87, 100], [100, 101], [102, 109], [110, 121], [121, 122], [123, 130], [130, 131], [131, 141], [141, 142], [143, 154], [155, 165], [165, 166], [167, 171], [172, 178], [179, 189], [190, 199], [200, 204], [205, 208], [209, 220], [221, 229], [229, 230], [231, 244], [245, 248], [249, 259], [260, 268], [268, 269]]}
{"doc_key": "ai-dev-80", "ner": [[3, 3, "product"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Several", "measures", "use", "WordNet", ",", "a", "manually", "constructed", "lexical", "database", "of", "English", "words", "."], "sentence-detokenized": "Several measures use WordNet, a manually constructed lexical database of English words.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 28], [28, 29], [30, 31], [32, 40], [41, 52], [53, 60], [61, 69], [70, 72], [73, 80], [81, 86], [86, 87]]}
{"doc_key": "ai-dev-81", "ner": [[8, 9, "field"], [11, 12, "task"], [14, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "system", "uses", "a", "combination", "of", "techniques", "from", "computational", "linguistics", ",", "information", "retrieval", "and", "knowledge", "representation", "to", "find", "answers", "."], "sentence-detokenized": "The system uses a combination of techniques from computational linguistics, information retrieval and knowledge representation to find answers.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 17], [18, 29], [30, 32], [33, 43], [44, 48], [49, 62], [63, 74], [74, 75], [76, 87], [88, 97], [98, 101], [102, 111], [112, 126], [127, 129], [130, 134], [135, 142], [142, 143]]}
{"doc_key": "ai-dev-82", "ner": [[0, 2, "metrics"], [27, 27, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 27, 27, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "uncertainty", "coefficient", "has", "the", "advantage", "that", "it", "is", "not", "affected", "by", "the", "relative", "size", "of", "the", "different", "classes", "as", "a", "performance", "measure", "compared", "to", "the", "simple", "accuracy", "."], "sentence-detokenized": "The uncertainty coefficient has the advantage that it is not affected by the relative size of the different classes as a performance measure compared to the simple accuracy.", "token2charspan": [[0, 3], [4, 15], [16, 27], [28, 31], [32, 35], [36, 45], [46, 50], [51, 53], [54, 56], [57, 60], [61, 69], [70, 72], [73, 76], [77, 85], [86, 90], [91, 93], [94, 97], [98, 107], [108, 115], [116, 118], [119, 120], [121, 132], [133, 140], [141, 149], [150, 152], [153, 156], [157, 163], [164, 172], [172, 173]]}
{"doc_key": "ai-dev-83", "ner": [[10, 11, "algorithm"], [13, 14, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Researchers", "have", "experimented", "with", "a", "number", "of", "methods", "such", "as", "optical", "flow", ",", "Kalman", "filtering", ",", "hidden", "Markov", "models", ",", "etc", "."], "sentence-detokenized": "Researchers have experimented with a number of methods such as optical flow, Kalman filtering, hidden Markov models, etc.", "token2charspan": [[0, 11], [12, 16], [17, 29], [30, 34], [35, 36], [37, 43], [44, 46], [47, 54], [55, 59], [60, 62], [63, 70], [71, 75], [75, 76], [77, 83], [84, 93], [93, 94], [95, 101], [102, 108], [109, 115], [115, 116], [117, 120], [120, 121]]}
{"doc_key": "ai-dev-84", "ner": [[14, 17, "conference"], [30, 32, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "has", "served", "as", "President", ",", "Vice", "President", ",", "Secretary", "and", "Treasurer", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "as", "a", "Board", "Member", "and", "Secretary", "of", "the", "Board", "of", "the", "Computing", "Research", "Association", "."], "sentence-detokenized": "She has served as President, Vice President, Secretary and Treasurer of the Association for Computational Linguistics and as a Board Member and Secretary of the Board of the Computing Research Association.", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 17], [18, 27], [27, 28], [29, 33], [34, 43], [43, 44], [45, 54], [55, 58], [59, 68], [69, 71], [72, 75], [76, 87], [88, 91], [92, 105], [106, 117], [118, 121], [122, 124], [125, 126], [127, 132], [133, 139], [140, 143], [144, 153], [154, 156], [157, 160], [161, 166], [167, 169], [170, 173], [174, 183], [184, 192], [193, 204], [204, 205]]}
{"doc_key": "ai-dev-85", "ner": [[7, 7, "programlang"], [9, 9, "product"], [11, 11, "programlang"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 11, 11, "compare", "", false, false], [7, 7, 13, 14, "related-to", "supports", false, false], [9, 9, 11, 11, "compare", "", false, false], [9, 9, 13, 14, "related-to", "supports", false, false], [11, 11, 13, 14, "related-to", "supports", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Like", "other", "similar", "languages", ",", "such", "as", "APL", "and", "MATLAB", ",", "R", "supports", "matrix", "arithmetic", "."], "sentence-detokenized": "Like other similar languages, such as APL and MATLAB, R supports matrix arithmetic.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 28], [28, 29], [30, 34], [35, 37], [38, 41], [42, 45], [46, 52], [52, 53], [54, 55], [56, 64], [65, 71], [72, 82], [82, 83]]}
{"doc_key": "ai-dev-86", "ner": [[8, 9, "organisation"], [16, 17, "researcher"], [20, 23, "university"], [26, 31, "misc"], [5, 5, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[16, 17, 20, 23, "role", "works_for", false, false]], "relations_mapping_to_source": [3], "sentence": ["On", "7", "June", "2014", ",", "Goostman", "won", "a", "Royal", "Society", "Turing", "test", "competition", ",", "organised", "by", "Kevin", "Warwick", "of", "the", "University", "of", "Reading", "to", "mark", "the", "60th", "anniversary", "of", "Turing", "'s", "death", ",", "after", "33", "%", "of", "the", "judges", "were", "convinced", "that", "the", "robot", "was", "human", "."], "sentence-detokenized": "On 7 June 2014, Goostman won a Royal Society Turing test competition, organised by Kevin Warwick of the University of Reading to mark the 60th anniversary of Turing's death, after 33% of the judges were convinced that the robot was human.", "token2charspan": [[0, 2], [3, 4], [5, 9], [10, 14], [14, 15], [16, 24], [25, 28], [29, 30], [31, 36], [37, 44], [45, 51], [52, 56], [57, 68], [68, 69], [70, 79], [80, 82], [83, 88], [89, 96], [97, 99], [100, 103], [104, 114], [115, 117], [118, 125], [126, 128], [129, 133], [134, 137], [138, 142], [143, 154], [155, 157], [158, 164], [164, 166], [167, 172], [172, 173], [174, 179], [180, 182], [182, 183], [184, 186], [187, 190], [191, 197], [198, 202], [203, 212], [213, 217], [218, 221], [222, 227], [228, 231], [232, 237], [237, 238]]}
{"doc_key": "ai-dev-87", "ner": [[1, 2, "product"], [4, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 1, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "collaborative", "robot", "or", "cobot", "is", "a", "robot", "that", "can", "safely", "and", "efficiently", "interact", "with", "human", "workers", "while", "performing", "simple", "industrial", "tasks", "."], "sentence-detokenized": "A collaborative robot or cobot is a robot that can safely and efficiently interact with human workers while performing simple industrial tasks.", "token2charspan": [[0, 1], [2, 15], [16, 21], [22, 24], [25, 30], [31, 33], [34, 35], [36, 41], [42, 46], [47, 50], [51, 57], [58, 61], [62, 73], [74, 82], [83, 87], [88, 93], [94, 101], [102, 107], [108, 118], [119, 125], [126, 136], [137, 142], [142, 143]]}
{"doc_key": "ai-dev-88", "ner": [[13, 14, "field"], [17, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "task"], [29, 30, "task"], [32, 34, "task"], [37, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[17, 18, 13, 14, "part-of", "task_part_of_field", false, false], [20, 21, 13, 14, "part-of", "task_part_of_field", false, false], [23, 24, 13, 14, "part-of", "task_part_of_field", false, false], [26, 27, 13, 14, "part-of", "task_part_of_field", false, false], [29, 30, 13, 14, "part-of", "task_part_of_field", false, false], [32, 34, 13, 14, "part-of", "task_part_of_field", false, false], [37, 38, 13, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["This", "general", "framework", "has", "been", "applied", "to", "a", "wide", "range", "of", "problems", "in", "computer", "vision", ",", "including", "feature", "detection", ",", "feature", "classification", ",", "image", "segmentation", ",", "image", "matching", ",", "motion", "estimation", ",", "shape", "indicator", "computation", ",", "and", "object", "recognition", "."], "sentence-detokenized": "This general framework has been applied to a wide range of problems in computer vision, including feature detection, feature classification, image segmentation, image matching, motion estimation, shape indicator computation, and object recognition.", "token2charspan": [[0, 4], [5, 12], [13, 22], [23, 26], [27, 31], [32, 39], [40, 42], [43, 44], [45, 49], [50, 55], [56, 58], [59, 67], [68, 70], [71, 79], [80, 86], [86, 87], [88, 97], [98, 105], [106, 115], [115, 116], [117, 124], [125, 139], [139, 140], [141, 146], [147, 159], [159, 160], [161, 166], [167, 175], [175, 176], [177, 183], [184, 194], [194, 195], [196, 201], [202, 211], [212, 223], [223, 224], [225, 228], [229, 235], [236, 247], [247, 248]]}
{"doc_key": "ai-dev-89", "ner": [[5, 6, "task"], [8, 10, "algorithm"], [13, 14, "algorithm"], [26, 26, "algorithm"], [31, 32, "algorithm"], [36, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 6, 8, 10, "part-of", "", false, false], [5, 6, 13, 14, "usage", "", false, false], [8, 10, 26, 26, "named", "same", false, false], [26, 26, 31, 32, "related-to", "", false, false], [26, 26, 36, 37, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "many", "practical", "applications", ",", "parameter", "estimation", "for", "naive", "Bayes", "models", "uses", "the", "maximum", "likelihood", "method", ";", "in", "other", "words", ",", "one", "can", "work", "with", "the", "naive", "Bayes", "model", "without", "accepting", "Bayesian", "likelihood", "or", "using", "any", "Bayesian", "methods", "."], "sentence-detokenized": "In many practical applications, parameter estimation for naive Bayes models uses the maximum likelihood method; in other words, one can work with the naive Bayes model without accepting Bayesian likelihood or using any Bayesian methods.", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 30], [30, 31], [32, 41], [42, 52], [53, 56], [57, 62], [63, 68], [69, 75], [76, 80], [81, 84], [85, 92], [93, 103], [104, 110], [110, 111], [112, 114], [115, 120], [121, 126], [126, 127], [128, 131], [132, 135], [136, 140], [141, 145], [146, 149], [150, 155], [156, 161], [162, 167], [168, 175], [176, 185], [186, 194], [195, 205], [206, 208], [209, 214], [215, 218], [219, 227], [228, 235], [235, 236]]}
{"doc_key": "ai-dev-90", "ner": [[2, 4, "researcher"], [6, 7, "misc"], [11, 14, "university"], [16, 18, "researcher"], [20, 21, "misc"], [25, 25, "university"], [27, 27, "university"], [29, 29, "misc"], [36, 42, "university"], [44, 47, "misc"], [49, 52, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[2, 4, 11, 14, "physical", "", false, false], [2, 4, 11, 14, "role", "", false, false], [2, 4, 16, 18, "social", "brothers", false, false], [6, 7, 2, 4, "named", "", false, false], [16, 18, 25, 25, "physical", "", false, false], [16, 18, 25, 25, "role", "", false, false], [16, 18, 27, 27, "physical", "", false, false], [16, 18, 27, 27, "role", "", false, false], [16, 18, 36, 42, "physical", "", false, false], [16, 18, 36, 42, "role", "", false, false], [20, 21, 16, 18, "named", "", false, false], [29, 29, 16, 18, "origin", "", false, false], [44, 47, 16, 18, "artifact", "", false, false], [44, 47, 49, 52, "part-of", "part", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Brothers", "-", "Victor", "Gershevich", "Katz", ",", "American", "mathematician", ",", "professor", "at", "Massachusetts", "Institute", "of", "Technology", ";", "Mikhail", "Gershevich", "Katz", ",", "Israeli", "mathematician", ",", "graduated", "from", "Harvard", "and", "Columbia", "(", "Ph.D.", ",", "1984", ")", ",", "professor", "at", "Bar-", "Ilan", "University", ",", "author", "of", "the", "monograph", "Systolic", "Geometry", "and", "Topology", "(", "Mathematical", "Surveys", "and", "Monographs", ",", "vol", "."], "sentence-detokenized": "Brothers - Victor Gershevich Katz, American mathematician, professor at Massachusetts Institute of Technology; Mikhail Gershevich Katz, Israeli mathematician, graduated from Harvard and Columbia (Ph.D. , 1984), professor at Bar-Ilan University, author of the monograph Systolic Geometry and Topology (Mathematical Surveys and Monographs, vol.", "token2charspan": [[0, 8], [9, 10], [11, 17], [18, 28], [29, 33], [33, 34], [35, 43], [44, 57], [57, 58], [59, 68], [69, 71], [72, 85], [86, 95], [96, 98], [99, 109], [109, 110], [111, 118], [119, 129], [130, 134], [134, 135], [136, 143], [144, 157], [157, 158], [159, 168], [169, 173], [174, 181], [182, 185], [186, 194], [195, 196], [196, 201], [202, 203], [204, 208], [208, 209], [209, 210], [211, 220], [221, 223], [224, 228], [228, 232], [233, 243], [243, 244], [245, 251], [252, 254], [255, 258], [259, 268], [269, 277], [278, 286], [287, 290], [291, 299], [300, 301], [301, 313], [314, 321], [322, 325], [326, 336], [336, 337], [338, 341], [341, 342]]}
{"doc_key": "ai-dev-91", "ner": [[3, 6, "person"], [10, 11, "conference"], [16, 20, "organisation"], [22, 28, "location"], [32, 32, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 10, 11, "physical", "", false, false], [3, 6, 10, 11, "role", "", false, false], [3, 6, 16, 20, "role", "", false, false], [16, 20, 22, 28, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2000", ",", "Manuel", "Toharia", ",", "a", "speaker", "at", "previous", "Campus", "Parties", "and", "director", "of", "the", "Pr\u00edncipe", "Felipe", "Museum", "of", "Sciences", "in", "Valencia", "'s", "city", "of", "arts", "and", "sciences", ",", "suggested", "that", "Ragageles", "expand", "and", "make", "the", "event", "more", "international", "by", "moving", "it", "to", "the", "famous", "museum", "."], "sentence-detokenized": "In 2000, Manuel Toharia, a speaker at previous Campus Parties and director of the Pr\u00edncipe Felipe Museum of Sciences in Valencia's city of arts and sciences, suggested that Ragageles expand and make the event more international by moving it to the famous museum.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 23], [23, 24], [25, 26], [27, 34], [35, 37], [38, 46], [47, 53], [54, 61], [62, 65], [66, 74], [75, 77], [78, 81], [82, 90], [91, 97], [98, 104], [105, 107], [108, 116], [117, 119], [120, 128], [128, 130], [131, 135], [136, 138], [139, 143], [144, 147], [148, 156], [156, 157], [158, 167], [168, 172], [173, 182], [183, 189], [190, 193], [194, 198], [199, 202], [203, 208], [209, 213], [214, 227], [228, 230], [231, 237], [238, 240], [241, 243], [244, 247], [248, 254], [255, 261], [261, 262]]}
{"doc_key": "ai-dev-92", "ner": [[5, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Within", "20", "minutes", ",", "a", "facial", "recognition", "system", "identifies", "personal", "information", ",", "including", "surname", ",", "ID", "number", "and", "address", ",", "which", "is", "displayed", "on", "the", "street", "on", "an", "advertising", "screen", "."], "sentence-detokenized": "Within 20 minutes, a facial recognition system identifies personal information, including surname, ID number and address, which is displayed on the street on an advertising screen.", "token2charspan": [[0, 6], [7, 9], [10, 17], [17, 18], [19, 20], [21, 27], [28, 39], [40, 46], [47, 57], [58, 66], [67, 78], [78, 79], [80, 89], [90, 97], [97, 98], [99, 101], [102, 108], [109, 112], [113, 120], [120, 121], [122, 127], [128, 130], [131, 140], [141, 143], [144, 147], [148, 154], [155, 157], [158, 160], [161, 172], [173, 179], [179, 180]]}
{"doc_key": "ai-dev-93", "ner": [[6, 7, "field"], [9, 9, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Recent", "research", "has", "increasingly", "focused", "on", "unsupervised", "learning", "and", "semi-supervised", "learning", "algorithms", "."], "sentence-detokenized": "Recent research has increasingly focused on unsupervised learning and semi-supervised learning algorithms.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 32], [33, 40], [41, 43], [44, 56], [57, 65], [66, 69], [70, 85], [86, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-dev-94", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Calculation", "of", "this", "example", "using", "Python", "code", ":"], "sentence-detokenized": "Calculation of this example using Python code:", "token2charspan": [[0, 11], [12, 14], [15, 19], [20, 27], [28, 33], [34, 40], [41, 45], [45, 46]]}
{"doc_key": "ai-dev-95", "ner": [[7, 8, "task"], [15, 15, "field"], [19, 23, "algorithm"], [25, 25, "algorithm"], [29, 31, "algorithm"], [34, 35, "researcher"], [37, 38, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[19, 23, 15, 15, "part-of", "", false, false], [19, 23, 29, 31, "type-of", "", false, false], [19, 23, 34, 35, "origin", "", false, false], [19, 23, 37, 38, "origin", "", false, false], [25, 25, 19, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Today", ",", "however", ",", "many", "aspects", "of", "speech", "recognition", "have", "been", "taken", "over", "by", "a", "deep", "learning", "method", "called", "Long", "short", "-", "term", "memory", "(", "LSTM", ")", ",", "a", "recurrent", "neural", "network", "published", "by", "Sepp", "Hochreiter", "&", "J\u00fcrgen", "Schmidhuber", "in", "1997", "."], "sentence-detokenized": "Today, however, many aspects of speech recognition have been taken over by a deep learning method called Long short-term memory (LSTM), a recurrent neural network published by Sepp Hochreiter & J\u00fcrgen Schmidhuber in 1997.", "token2charspan": [[0, 5], [5, 6], [7, 14], [14, 15], [16, 20], [21, 28], [29, 31], [32, 38], [39, 50], [51, 55], [56, 60], [61, 66], [67, 71], [72, 74], [75, 76], [77, 81], [82, 90], [91, 97], [98, 104], [105, 109], [110, 115], [115, 116], [116, 120], [121, 127], [128, 129], [129, 133], [133, 134], [134, 135], [136, 137], [138, 147], [148, 154], [155, 162], [163, 172], [173, 175], [176, 180], [181, 191], [192, 193], [194, 200], [201, 212], [213, 215], [216, 220], [220, 221]]}
{"doc_key": "ai-dev-96", "ner": [[8, 8, "algorithm"], [10, 11, "algorithm"], [17, 17, "algorithm"], [22, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 10, 11, "compare", "", false, false], [8, 8, 22, 22, "named", "same", false, false], [17, 17, 22, 22, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "preliminary", "experimental", "results", "with", "noisy", "datasets", ",", "BrownBoost", "outperformed", "AdaBoost", "'s", "generalization", "error", ";", "however", ",", "LogitBoost", "performed", "as", "well", "as", "BrownBoost", "."], "sentence-detokenized": "In preliminary experimental results with noisy datasets, BrownBoost outperformed AdaBoost's generalization error; however, LogitBoost performed as well as BrownBoost.", "token2charspan": [[0, 2], [3, 14], [15, 27], [28, 35], [36, 40], [41, 46], [47, 55], [55, 56], [57, 67], [68, 80], [81, 89], [89, 91], [92, 106], [107, 112], [112, 113], [114, 121], [121, 122], [123, 133], [134, 143], [144, 146], [147, 151], [152, 154], [155, 165], [165, 166]]}
{"doc_key": "ai-dev-97", "ner": [[0, 1, "algorithm"], [5, 7, "researcher"], [10, 10, "country"], [13, 15, "researcher"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 7, "part-of", "", false, false], [5, 7, 10, 10, "physical", "", false, false], [20, 21, 13, 15, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Evolutionary", "programming", "was", "introduced", "by", "Lawrence", "J.", "Fogel", "in", "the", "US", ",", "while", "John", "Henry", "Holland", "called", "his", "method", "a", "genetic", "algorithm", "."], "sentence-detokenized": "Evolutionary programming was introduced by Lawrence J. Fogel in the US, while John Henry Holland called his method a genetic algorithm.", "token2charspan": [[0, 12], [13, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 54], [55, 60], [61, 63], [64, 67], [68, 70], [70, 71], [72, 77], [78, 82], [83, 88], [89, 96], [97, 103], [104, 107], [108, 114], [115, 116], [117, 124], [125, 134], [134, 135]]}
{"doc_key": "ai-dev-98", "ner": [[0, 0, "researcher"], [2, 2, "researcher"], [8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 8, 9, "role", "", false, false], [0, 0, 11, 12, "role", "", false, false], [0, 0, 14, 15, "role", "", false, false], [0, 0, 17, 18, "role", "", false, false], [2, 2, 8, 9, "role", "", false, false], [2, 2, 11, 12, "role", "", false, false], [2, 2, 14, 15, "role", "", false, false], [2, 2, 17, 18, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Doug", ",", "Alan", "and", "their", "colleagues", "(", "including", "Marvin", "Minsky", ",", "Allen", "Newell", ",", "Edward", "Feigenbaum", "and", "John", "McCarthy", ")", "calculated", "that", "this", "effort", "would", "require", "between", "1000", "and", "3000", "person", "-", "years", "of", "effort", ",", "which", "is", "far", "more", "than", "the", "standard", "academic", "project", "model", "."], "sentence-detokenized": "Doug, Alan and their colleagues (including Marvin Minsky, Allen Newell, Edward Feigenbaum and John McCarthy) calculated that this effort would require between 1000 and 3000 person-years of effort, which is far more than the standard academic project model.", "token2charspan": [[0, 4], [4, 5], [6, 10], [11, 14], [15, 20], [21, 31], [32, 33], [33, 42], [43, 49], [50, 56], [56, 57], [58, 63], [64, 70], [70, 71], [72, 78], [79, 89], [90, 93], [94, 98], [99, 107], [107, 108], [109, 119], [120, 124], [125, 129], [130, 136], [137, 142], [143, 150], [151, 158], [159, 163], [164, 167], [168, 172], [173, 179], [179, 180], [180, 185], [186, 188], [189, 195], [195, 196], [197, 202], [203, 205], [206, 209], [210, 214], [215, 219], [220, 223], [224, 232], [233, 241], [242, 249], [250, 255], [255, 256]]}
{"doc_key": "ai-dev-99", "ner": [[4, 6, "metrics"], [10, 10, "metrics"], [13, 15, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 10, 10, "part-of", "implemented_in", false, false], [13, 15, 18, 18, "part-of", "implemented_in", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Common", "criteria", "are", "the", "mean", "squared", "error", "criterion", "implemented", "in", "MSECriterion", "and", "the", "cross", "entropy", "criterion", "implemented", "in", "NLLCriterion", "."], "sentence-detokenized": "Common criteria are the mean squared error criterion implemented in MSECriterion and the cross entropy criterion implemented in NLLCriterion.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 23], [24, 28], [29, 36], [37, 42], [43, 52], [53, 64], [65, 67], [68, 80], [81, 84], [85, 88], [89, 94], [95, 102], [103, 112], [113, 124], [125, 127], [128, 140], [140, 141]]}
{"doc_key": "ai-dev-100", "ner": [[0, 0, "researcher"], [13, 13, "organisation"], [16, 28, "misc"], [31, 34, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 13, 13, "role", "", false, false], [0, 0, 31, 34, "role", "", false, false], [16, 28, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 3], "sentence": ["Zurada", "has", "served", "the", "engineering", "profession", "as", "a", "long", "-", "time", "volunteer", "in", "IEEE", ":", "as", "IEEE", "Vice", "-", "President", "-", "Technical", "Activities", "(", "TAB", "Chair", ")", "in", "2014", ",", "as", "IEEE", "Computational", "Intelligence", "Society", "Chair", "in", "2004", "-", "05", ",", "and", "as", "ADCOM", "member", "in", "2009", "-", "14", ",", "2016", "-", "18", "and", "previous", "years", "."], "sentence-detokenized": "Zurada has served the engineering profession as a long-time volunteer in IEEE: as IEEE Vice-President-Technical Activities (TAB Chair) in 2014, as IEEE Computational Intelligence Society Chair in 2004-05, and as ADCOM member in 2009-14, 2016-18 and previous years.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 21], [22, 33], [34, 44], [45, 47], [48, 49], [50, 54], [54, 55], [55, 59], [60, 69], [70, 72], [73, 77], [77, 78], [79, 81], [82, 86], [87, 91], [91, 92], [92, 101], [101, 102], [102, 111], [112, 122], [123, 124], [124, 127], [128, 133], [133, 134], [135, 137], [138, 142], [142, 143], [144, 146], [147, 151], [152, 165], [166, 178], [179, 186], [187, 192], [193, 195], [196, 200], [200, 201], [201, 203], [203, 204], [205, 208], [209, 211], [212, 217], [218, 224], [225, 227], [228, 232], [232, 233], [233, 235], [235, 236], [237, 241], [241, 242], [242, 244], [245, 248], [249, 257], [258, 263], [263, 264]]}
{"doc_key": "ai-dev-101", "ner": [[3, 4, "field"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 3, 4, "part-of", "", false, false], [12, 13, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "general", ",", "computational", "linguistics", "draws", "on", "linguists", ",", "computer", "scientists", ",", "artificial", "intelligence", "experts", ",", "mathematicians", ",", "logicians", ",", "philosophers", ",", "cognitive", "scientists", ",", "cognitive", "psychologists", ",", "psycholinguists", ",", "anthropologists", "and", "neuroscientists", ",", "among", "others", "."], "sentence-detokenized": "In general, computational linguistics draws on linguists, computer scientists, artificial intelligence experts, mathematicians, logicians, philosophers, cognitive scientists, cognitive psychologists, psycholinguists, anthropologists and neuroscientists, among others.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 25], [26, 37], [38, 43], [44, 46], [47, 56], [56, 57], [58, 66], [67, 77], [77, 78], [79, 89], [90, 102], [103, 110], [110, 111], [112, 126], [126, 127], [128, 137], [137, 138], [139, 151], [151, 152], [153, 162], [163, 173], [173, 174], [175, 184], [185, 198], [198, 199], [200, 215], [215, 216], [217, 232], [233, 236], [237, 252], [252, 253], [254, 259], [260, 266], [266, 267]]}
{"doc_key": "ai-dev-102", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "the", "correlations", "between", "images", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and long short-term memory are often used to exploit the correlations between images.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [83, 88], [88, 89], [89, 93], [94, 100], [101, 104], [105, 110], [111, 115], [116, 118], [119, 126], [127, 130], [131, 143], [144, 151], [152, 158], [158, 159]]}
{"doc_key": "ai-dev-103", "ner": [[0, 2, "product"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Unimate", "was", "the", "first", "industrial", "robot", ","], "sentence-detokenized": "Unimate was the first industrial robot,", "token2charspan": [[0, 7], [8, 11], [12, 15], [16, 21], [22, 32], [33, 38], [38, 39]]}
{"doc_key": "ai-dev-104", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [10, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 10, 13, "win-defeat", "", false, false], [5, 6, 10, 13, "win-defeat", "", false, false], [8, 8, 10, 13, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "won", "the", "2018", "Turing", "Prize", "."], "sentence-detokenized": "Along with Geoffrey Hinton and Yann LeCun, Bengio won the 2018 Turing Prize.", "token2charspan": [[0, 5], [6, 10], [11, 19], [20, 26], [27, 30], [31, 35], [36, 41], [41, 42], [43, 49], [50, 53], [54, 57], [58, 62], [63, 69], [70, 75], [75, 76]]}
{"doc_key": "ai-dev-105", "ner": [[6, 6, "country"], [20, 23, "misc"], [25, 25, "country"], [29, 30, "organisation"], [33, 35, "person"], [38, 39, "person"], [48, 50, "misc"], [55, 55, "country"], [61, 61, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[20, 23, 6, 6, "physical", "filmed_in", false, false], [33, 35, 29, 30, "role", "host", false, false], [38, 39, 29, 30, "role", "reporter", false, false], [48, 50, 6, 6, "physical", "filmed_in", false, false], [48, 50, 55, 55, "physical", "distributed_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Additional", "series", "were", "filmed", "at", "the", "UK", "venue", "for", "specific", "sectors", "of", "the", "global", "market", ",", "including", "two", "series", "of", "Robot", "Wars", "Extreme", "Warriors", "with", "US", "competitors", "for", "the", "TNN", "network", "(", "with", "Mick", "Foley", "as", "host", "and", "Rebecca", "Grant", "as", "pit", "reporter", ")", ",", "two", "series", "of", "Dutch", "Robot", "Wars", "for", "distribution", "in", "the", "Netherlands", "and", "a", "single", "series", "for", "Germany", "."], "sentence-detokenized": "Additional series were filmed at the UK venue for specific sectors of the global market, including two series of Robot Wars Extreme Warriors with US competitors for the TNN network (with Mick Foley as host and Rebecca Grant as pit reporter), two series of Dutch Robot Wars for distribution in the Netherlands and a single series for Germany.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 29], [30, 32], [33, 36], [37, 39], [40, 45], [46, 49], [50, 58], [59, 66], [67, 69], [70, 73], [74, 80], [81, 87], [87, 88], [89, 98], [99, 102], [103, 109], [110, 112], [113, 118], [119, 123], [124, 131], [132, 140], [141, 145], [146, 148], [149, 160], [161, 164], [165, 168], [169, 172], [173, 180], [181, 182], [182, 186], [187, 191], [192, 197], [198, 200], [201, 205], [206, 209], [210, 217], [218, 223], [224, 226], [227, 230], [231, 239], [239, 240], [240, 241], [242, 245], [246, 252], [253, 255], [256, 261], [262, 267], [268, 272], [273, 276], [277, 289], [290, 292], [293, 296], [297, 308], [309, 312], [313, 314], [315, 321], [322, 328], [329, 332], [333, 340], [340, 341]]}
{"doc_key": "ai-dev-106", "ner": [[6, 6, "researcher"], [11, 13, "product"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 11, 13, "role", "", false, false], [28, 29, 11, 13, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "many", "years", "from", "1986", ",", "Miller", "led", "the", "development", "of", "WordNet", ",", "a", "large", "computer", "-", "readable", "electronic", "reference", "that", "can", "be", "used", "in", "applications", "such", "as", "search", "engines", "."], "sentence-detokenized": "For many years from 1986, Miller led the development of WordNet, a large computer-readable electronic reference that can be used in applications such as search engines.", "token2charspan": [[0, 3], [4, 8], [9, 14], [15, 19], [20, 24], [24, 25], [26, 32], [33, 36], [37, 40], [41, 52], [53, 55], [56, 63], [63, 64], [65, 66], [67, 72], [73, 81], [81, 82], [82, 90], [91, 101], [102, 111], [112, 116], [117, 120], [121, 123], [124, 128], [129, 131], [132, 144], [145, 149], [150, 152], [153, 159], [160, 167], [167, 168]]}
{"doc_key": "ai-dev-107", "ner": [[4, 5, "algorithm"], [8, 11, "algorithm"], [14, 15, "researcher"], [21, 24, "organisation"], [28, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 14, 15, "origin", "", false, false], [4, 5, 28, 30, "win-defeat", "", false, false], [8, 11, 14, 15, "origin", "", false, false], [8, 11, 28, 30, "win-defeat", "", false, false], [14, 15, 21, 24, "physical", "", false, false], [14, 15, 21, 24, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Since", "2009", ",", "the", "recurrent", "neural", "networks", "and", "deep", "feedforward", "neural", "networks", "developed", "in", "J\u00fcrgen", "Schmidhuber", "'s", "research", "group", "at", "the", "Swiss", "AI", "Lab", "IDSIA", "have", "won", "several", "international", "handwriting", "competitions", "."], "sentence-detokenized": "Since 2009, the recurrent neural networks and deep feedforward neural networks developed in J\u00fcrgen Schmidhuber's research group at the Swiss AI Lab IDSIA have won several international handwriting competitions.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 15], [16, 25], [26, 32], [33, 41], [42, 45], [46, 50], [51, 62], [63, 69], [70, 78], [79, 88], [89, 91], [92, 98], [99, 110], [110, 112], [113, 121], [122, 127], [128, 130], [131, 134], [135, 140], [141, 143], [144, 147], [148, 153], [154, 158], [159, 162], [163, 170], [171, 184], [185, 196], [197, 209], [209, 210]]}
{"doc_key": "ai-dev-108", "ner": [[5, 6, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "software", "is", "implemented", "in", "C", "++", "and", "is", "wrapped", "in", "Python", "."], "sentence-detokenized": "The software is implemented in C++ and is wrapped in Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 30], [31, 32], [32, 34], [35, 38], [39, 41], [42, 49], [50, 52], [53, 59], [59, 60]]}
{"doc_key": "ai-dev-109", "ner": [[8, 9, "country"], [14, 15, "misc"], [19, 20, "misc"], [32, 34, "misc"], [35, 35, "misc"], [37, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[19, 20, 8, 9, "temporal", "", false, false], [19, 20, 14, 15, "artifact", "", false, false], [19, 20, 37, 37, "physical", "", false, false], [35, 35, 32, 34, "named", "", false, false], [35, 35, 37, 37, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1857", ",", "at", "the", "request", "of", "the", "Tokugawa", "shogunate", ",", "a", "group", "of", "Dutch", "engineers", "began", "work", "on", "Nagasaki", "Yotetsusho", ",", "a", "modern", "Western", "-", "style", "foundry", "and", "shipyard", "near", "the", "Dutch", "settlement", "of", "Dejima", "in", "Nagasaki", "."], "sentence-detokenized": "In 1857, at the request of the Tokugawa shogunate, a group of Dutch engineers began work on Nagasaki Yotetsusho, a modern Western-style foundry and shipyard near the Dutch settlement of Dejima in Nagasaki.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 39], [40, 49], [49, 50], [51, 52], [53, 58], [59, 61], [62, 67], [68, 77], [78, 83], [84, 88], [89, 91], [92, 100], [101, 111], [111, 112], [113, 114], [115, 121], [122, 129], [129, 130], [130, 135], [136, 143], [144, 147], [148, 156], [157, 161], [162, 165], [166, 171], [172, 182], [183, 185], [186, 192], [193, 195], [196, 204], [204, 205]]}
{"doc_key": "ai-dev-110", "ner": [[10, 12, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["We", "do", "this", "as", "accurately", "as", "possible", "by", "measuring", "the", "mean", "squared", "error", "between", "mathy", "/", "math", "and", "math", "\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", "/", "math", ":", "we", "want", "math", "(", "y", "-\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", ")", "^", "2", "/", "math", "to", "be", "minimal", ",", "both", "for", "mathx", "_", "1", ",\\", "dots", ",", "x", "_n", "/", "math", "and", "for", "points", "outside", "our", "sample", "."], "sentence-detokenized": "We do this as accurately as possible by measuring the mean squared error between mathy/math and math\\ hat {f} (x; D) / math: we want math (y -\\ hat {f} (x; D)) ^ 2 / math to be minimal, both for mathx _ 1,\\ dots, x _n / math and for points outside our sample.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 13], [14, 24], [25, 27], [28, 36], [37, 39], [40, 49], [50, 53], [54, 58], [59, 66], [67, 72], [73, 80], [81, 86], [86, 87], [87, 91], [92, 95], [96, 100], [100, 101], [102, 105], [106, 107], [107, 108], [108, 109], [110, 111], [111, 112], [112, 113], [114, 115], [115, 116], [117, 118], [119, 123], [123, 124], [125, 127], [128, 132], [133, 137], [138, 139], [139, 140], [141, 143], [144, 147], [148, 149], [149, 150], [150, 151], [152, 153], [153, 154], [154, 155], [156, 157], [157, 158], [158, 159], [160, 161], [162, 163], [164, 165], [166, 170], [171, 173], [174, 176], [177, 184], [184, 185], [186, 190], [191, 194], [195, 200], [201, 202], [203, 204], [204, 206], [207, 211], [211, 212], [213, 214], [215, 217], [218, 219], [220, 224], [225, 228], [229, 232], [233, 239], [240, 247], [248, 251], [252, 258], [258, 259]]}
{"doc_key": "ai-dev-111", "ner": [[3, 4, "researcher"], [11, 13, "organisation"], [19, 24, "product"], [33, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 11, 13, "role", "", false, false], [19, 24, 11, 13, "temporal", "", false, false], [19, 24, 33, 34, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "subsequently", "invited", "Wydner", "to", "attend", "the", "annual", "meeting", "of", "the", "American", "Translators", "Association", "the", "following", "October", ",", "where", "Weidner", "'s", "machine", "translation", "system", "was", "hailed", "as", "a", "hoped", "-", "for", "breakthrough", "in", "machine", "translation", "."], "sentence-detokenized": "He subsequently invited Wydner to attend the annual meeting of the American Translators Association the following October, where Weidner's machine translation system was hailed as a hoped-for breakthrough in machine translation.", "token2charspan": [[0, 2], [3, 15], [16, 23], [24, 30], [31, 33], [34, 40], [41, 44], [45, 51], [52, 59], [60, 62], [63, 66], [67, 75], [76, 87], [88, 99], [100, 103], [104, 113], [114, 121], [121, 122], [123, 128], [129, 136], [136, 138], [139, 146], [147, 158], [159, 165], [166, 169], [170, 176], [177, 179], [180, 181], [182, 187], [187, 188], [188, 191], [192, 204], [205, 207], [208, 215], [216, 227], [227, 228]]}
{"doc_key": "ai-dev-112", "ner": [[2, 8, "conference"], [10, 10, "conference"], [15, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 2, 8, "named", "", false, false], [10, 10, 2, 8, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["At", "the", "2018", "Conference", "on", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", ",", "researchers", "from", "Google", "presented", "work", "at", "the", "conference", "."], "sentence-detokenized": "At the 2018 Conference on Neural Information Processing Systems (NeurIPS), researchers from Google presented work at the conference.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 22], [23, 25], [26, 32], [33, 44], [45, 55], [56, 63], [64, 65], [65, 72], [72, 73], [73, 74], [75, 86], [87, 91], [92, 98], [99, 108], [109, 113], [114, 116], [117, 120], [121, 131], [131, 132]]}
{"doc_key": "ai-dev-113", "ner": [[0, 4, "algorithm"], [10, 12, "algorithm"], [15, 17, "metrics"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 4, 10, 12, "usage", "", false, false], [10, 12, 15, 17, "related-to", "", true, false], [15, 17, 23, 25, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Baum", "-", "Welch", "algorithm", "uses", "the", "well", "-", "known", "EM", "algorithm", "to", "find", "the", "maximum", "likelihood", "estimate", "of", "the", "parameters", "of", "a", "hidden", "Markov", "model", "given", "a", "set", "of", "observed", "function", "vectors", "."], "sentence-detokenized": "The Baum-Welch algorithm uses the well-known EM algorithm to find the maximum likelihood estimate of the parameters of a hidden Markov model given a set of observed function vectors.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 14], [15, 24], [25, 29], [30, 33], [34, 38], [38, 39], [39, 44], [45, 47], [48, 57], [58, 60], [61, 65], [66, 69], [70, 77], [78, 88], [89, 97], [98, 100], [101, 104], [105, 115], [116, 118], [119, 120], [121, 127], [128, 134], [135, 140], [141, 146], [147, 148], [149, 152], [153, 155], [156, 164], [165, 173], [174, 181], [181, 182]]}
{"doc_key": "ai-dev-114", "ner": [[8, 8, "product"], [10, 10, "product"], [30, 31, "misc"], [37, 45, "product"], [51, 56, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[8, 8, 10, 10, "compare", "", false, false], [30, 31, 10, 10, "part-of", "", false, false], [37, 45, 10, 10, "part-of", "", false, false], [51, 56, 10, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": [")", "In", "addition", "to", "the", "taxonomic", "information", "in", "OpenCyc", ",", "ResearchCyc", "contains", "significantly", "more", "semantic", "knowledge", "(", "i.e.", "additional", "facts", "and", "rules", "of", "thumb", ")", "about", "the", "concepts", "in", "the", "knowledge", "base", ";", "it", "also", "contains", "a", "large", "lexicon", ",", "tools", "for", "analysing", "and", "generating", "English", ",", "and", "Java", "-", "based", "interfaces", "for", "editing", "and", "searching", "knowledge", "."], "sentence-detokenized": ") In addition to the taxonomic information in OpenCyc, ResearchCyc contains significantly more semantic knowledge (i.e. additional facts and rules of thumb) about the concepts in the knowledge base; it also contains a large lexicon, tools for analysing and generating English, and Java-based interfaces for editing and searching knowledge.", "token2charspan": [[0, 1], [2, 4], [5, 13], [14, 16], [17, 20], [21, 30], [31, 42], [43, 45], [46, 53], [53, 54], [55, 66], [67, 75], [76, 89], [90, 94], [95, 103], [104, 113], [114, 115], [115, 119], [120, 130], [131, 136], [137, 140], [141, 146], [147, 149], [150, 155], [155, 156], [157, 162], [163, 166], [167, 175], [176, 178], [179, 182], [183, 192], [193, 197], [197, 198], [199, 201], [202, 206], [207, 215], [216, 217], [218, 223], [224, 231], [231, 232], [233, 238], [239, 242], [243, 252], [253, 256], [257, 267], [268, 275], [275, 276], [277, 280], [281, 285], [285, 286], [286, 291], [292, 302], [303, 306], [307, 314], [315, 318], [319, 328], [329, 338], [338, 339]]}
{"doc_key": "ai-dev-115", "ner": [[0, 3, "algorithm"], [5, 6, "task"], [10, 11, "field"], [13, 14, "field"], [16, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 5, 6, "type-of", "", false, false], [5, 6, 10, 11, "part-of", "task_part_of_field", false, false], [5, 6, 13, 14, "part-of", "task_part_of_field", false, false], [5, 6, 16, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Hough", "transform", "is", "a", "feature", "extraction", "technique", "used", "for", "image", "analysis", ",", "computer", "vision", "and", "digital", "image", "processing", "."], "sentence-detokenized": "The Hough transform is a feature extraction technique used for image analysis, computer vision and digital image processing.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 22], [23, 24], [25, 32], [33, 43], [44, 53], [54, 58], [59, 62], [63, 68], [69, 77], [77, 78], [79, 87], [88, 94], [95, 98], [99, 106], [107, 112], [113, 123], [123, 124]]}
{"doc_key": "ai-dev-116", "ner": [[7, 11, "product"], [16, 16, "organisation"], [18, 18, "product"], [20, 21, "researcher"], [27, 28, "organisation"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[18, 18, 20, 21, "artifact", "", false, false], [27, 28, 16, 16, "role", "supported", false, false]], "relations_mapping_to_source": [3, 4], "sentence": ["In", "1978", ",", "the", "PUMA", "robot", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "was", "developed", "by", "Unimation", "from", "Vicarm", "(", "Victor", "Scheinman", ")", "and", "with", "support", "from", "General", "Motors", "."], "sentence-detokenized": "In 1978, the PUMA robot (Programmable Universal Machine for Assembly) was developed by Unimation from Vicarm (Victor Scheinman) and with support from General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 23], [24, 25], [25, 37], [38, 47], [48, 55], [56, 59], [60, 68], [68, 69], [70, 73], [74, 83], [84, 86], [87, 96], [97, 101], [102, 108], [109, 110], [110, 116], [117, 126], [126, 127], [128, 131], [132, 136], [137, 144], [145, 149], [150, 157], [158, 164], [164, 165]]}
{"doc_key": "ai-dev-117", "ner": [[0, 1, "algorithm"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 7, 8, "origin", "", false, false], [0, 1, 10, 11, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "LSTM", "was", "proposed", "in", "1997", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "The LSTM was proposed in 1997 by Sepp Hochreiter and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 21], [22, 24], [25, 29], [30, 32], [33, 37], [38, 48], [49, 52], [53, 59], [60, 71], [71, 72]]}
{"doc_key": "ai-dev-118", "ner": [[11, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated in a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [64, 66], [67, 76], [77, 83], [84, 86], [87, 94], [94, 95]]}
{"doc_key": "ai-dev-119", "ner": [[8, 8, "conference"], [11, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "also", "contributed", "greatly", "to", "the", "creation", "of", "ELRA", "and", "the", "LREC", "conference", "."], "sentence-detokenized": "He also contributed greatly to the creation of ELRA and the LREC conference.", "token2charspan": [[0, 2], [3, 7], [8, 19], [20, 27], [28, 30], [31, 34], [35, 43], [44, 46], [47, 51], [52, 55], [56, 59], [60, 64], [65, 75], [75, 76]]}
{"doc_key": "ai-dev-120", "ner": [[11, 17, "misc"], [20, 21, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 21, 11, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "popular", "application", "of", "serial", "robots", "in", "today", "'s", "industry", "is", "pick", "-", "and", "-", "place", "assembly", "robots", ",", "called", "SCARA", "robots", ",", "which", "have", "four", "degrees", "of", "freedom", "."], "sentence-detokenized": "A popular application of serial robots in today's industry is pick-and-place assembly robots, called SCARA robots, which have four degrees of freedom.", "token2charspan": [[0, 1], [2, 9], [10, 21], [22, 24], [25, 31], [32, 38], [39, 41], [42, 47], [47, 49], [50, 58], [59, 61], [62, 66], [66, 67], [67, 70], [70, 71], [71, 76], [77, 85], [86, 92], [92, 93], [94, 100], [101, 106], [107, 113], [113, 114], [115, 120], [121, 125], [126, 130], [131, 138], [139, 141], [142, 149], [149, 150]]}
{"doc_key": "ai-dev-121", "ner": [[13, 19, "conference"], [21, 21, "conference"], [25, 28, "conference"], [35, 35, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 21, 13, 19, "named", "", false, false], [35, 35, 25, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "a", "founding", "member", "and", "past", "chair", "(", "2006-2008", ")", "of", "the", "Special", "Interest", "Group", "on", "Web", "as", "Corpus", "(", "SIGWAC", ")", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "also", "a", "founding", "organizer", "of", "SENSEVAL", "."], "sentence-detokenized": "He was a founding member and past chair (2006-2008) of the Special Interest Group on Web as Corpus (SIGWAC) of the Association for Computational Linguistics and also a founding organizer of SENSEVAL.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 17], [18, 24], [25, 28], [29, 33], [34, 39], [40, 41], [41, 50], [50, 51], [52, 54], [55, 58], [59, 66], [67, 75], [76, 81], [82, 84], [85, 88], [89, 91], [92, 98], [99, 100], [100, 106], [106, 107], [108, 110], [111, 114], [115, 126], [127, 130], [131, 144], [145, 156], [157, 160], [161, 165], [166, 167], [168, 176], [177, 186], [187, 189], [190, 198], [198, 199]]}
{"doc_key": "ai-dev-122", "ner": [[4, 4, "product"], [8, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 4, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "platform", ",", "LinguaStream", "offers", "a", "comprehensive", "Java", "API", "."], "sentence-detokenized": "As a platform, LinguaStream offers a comprehensive Java API.", "token2charspan": [[0, 2], [3, 4], [5, 13], [13, 14], [15, 27], [28, 34], [35, 36], [37, 50], [51, 55], [56, 59], [59, 60]]}
{"doc_key": "ai-dev-123", "ner": [[12, 12, "programlang"], [15, 17, "misc"], [20, 22, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 12, 20, 22, "type-of", "", false, false], [15, 17, 20, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "robot", "set", "is", "Android", "-", "based", "and", "it", "is", "programmed", "using", "Java", ",", "the", "Blocks", "programming", "interface", "or", "other", "Android", "programming", "systems", "."], "sentence-detokenized": "The robot set is Android-based and it is programmed using Java, the Blocks programming interface or other Android programming systems.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 16], [17, 24], [24, 25], [25, 30], [31, 34], [35, 37], [38, 40], [41, 51], [52, 57], [58, 62], [62, 63], [64, 67], [68, 74], [75, 86], [87, 96], [97, 99], [100, 105], [106, 113], [114, 125], [126, 133], [133, 134]]}
{"doc_key": "ai-dev-124", "ner": [[12, 15, "algorithm"], [18, 21, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "method", "of", "defining", "the", "linked", "list", "specifies", "the", "use", "of", "a", "depth", "-", "first", "search", "or", "a", "width", "-", "first", "search", "."], "sentence-detokenized": "The method of defining the linked list specifies the use of a depth-first search or a width-first search.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 22], [23, 26], [27, 33], [34, 38], [39, 48], [49, 52], [53, 56], [57, 59], [60, 61], [62, 67], [67, 68], [68, 73], [74, 80], [81, 83], [84, 85], [86, 91], [91, 92], [92, 97], [98, 104], [104, 105]]}
{"doc_key": "ai-dev-125", "ner": [[17, 18, "task"], [22, 25, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "regions", "can", "signal", "the", "presence", "of", "objects", "or", "parts", "of", "objects", "in", "the", "image", "domain", "for", "object", "recognition", "and", "/", "or", "video", "tracking", "of", "objects", "."], "sentence-detokenized": "These regions can signal the presence of objects or parts of objects in the image domain for object recognition and/or video tracking of objects.", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 24], [25, 28], [29, 37], [38, 40], [41, 48], [49, 51], [52, 57], [58, 60], [61, 68], [69, 71], [72, 75], [76, 81], [82, 88], [89, 92], [93, 99], [100, 111], [112, 115], [115, 116], [116, 118], [119, 124], [125, 133], [134, 136], [137, 144], [144, 145]]}
{"doc_key": "ai-dev-126", "ner": [[4, 5, "algorithm"], [7, 9, "product"], [13, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 4, 5, "type-of", "", false, false], [7, 9, 13, 13, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "a", "semantic", "network", "is", "WordNet", ",", "a", "lexical", "database", "in", "English", "."], "sentence-detokenized": "An example of a semantic network is WordNet, a lexical database in English.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 24], [25, 32], [33, 35], [36, 43], [43, 44], [45, 46], [47, 54], [55, 63], [64, 66], [67, 74], [74, 75]]}
{"doc_key": "ai-dev-127", "ner": [[0, 3, "task"], [7, 8, "field"], [10, 12, "field"], [21, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 7, 8, "part-of", "", false, false], [0, 3, 10, 12, "named", "same", false, false], [0, 3, 10, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Speech", "recognition", "is", "an", "interdisciplinary", "subfield", "of", "computer", "science", "and", "computational", "linguistics", "that", "develops", "methods", "and", "technologies", "that", "enable", "computers", "to", "recognise", "and", "translate", "spoken", "language", "into", "text", "."], "sentence-detokenized": "Speech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methods and technologies that enable computers to recognise and translate spoken language into text.", "token2charspan": [[0, 6], [7, 18], [19, 21], [22, 24], [25, 42], [43, 51], [52, 54], [55, 63], [64, 71], [72, 75], [76, 89], [90, 101], [102, 106], [107, 115], [116, 123], [124, 127], [128, 140], [141, 145], [146, 152], [153, 162], [163, 165], [166, 175], [176, 179], [180, 189], [190, 196], [197, 205], [206, 210], [211, 215], [215, 216]]}
{"doc_key": "ai-dev-128", "ner": [[0, 1, "field"], [7, 9, "misc"], [13, 15, "field"], [17, 17, "task"], [19, 20, "task"], [41, 42, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 41, 42, "named", "same", false, false], [13, 15, 0, 1, "part-of", "subfield", false, false], [17, 17, 0, 1, "part-of", "", false, false], [17, 17, 13, 15, "part-of", "", false, false], [19, 20, 13, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Artificial", "intelligence", "has", "received", "most", "attention", "on", "applied", "ontology", "in", "sub-fields", "such", "as", "natural", "language", "processing", "in", "machine", "and", "knowledge", "representation", ",", "but", "ontology", "editors", "are", "often", "used", "in", "a", "number", "of", "areas", "such", "as", "education", "without", "intending", "to", "contribute", "to", "artificial", "intelligence", "."], "sentence-detokenized": "Artificial intelligence has received most attention on applied ontology in sub-fields such as natural language processing in machine and knowledge representation, but ontology editors are often used in a number of areas such as education without intending to contribute to artificial intelligence.", "token2charspan": [[0, 10], [11, 23], [24, 27], [28, 36], [37, 41], [42, 51], [52, 54], [55, 62], [63, 71], [72, 74], [75, 85], [86, 90], [91, 93], [94, 101], [102, 110], [111, 121], [122, 124], [125, 132], [133, 136], [137, 146], [147, 161], [161, 162], [163, 166], [167, 175], [176, 183], [184, 187], [188, 193], [194, 198], [199, 201], [202, 203], [204, 210], [211, 213], [214, 219], [220, 224], [225, 227], [228, 237], [238, 245], [246, 255], [256, 258], [259, 269], [270, 272], [273, 283], [284, 296], [296, 297]]}
{"doc_key": "ai-dev-129", "ner": [[6, 11, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 11, 13, 14, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["This", "update", "rule", "is", "actually", "the", "stochastic", "update", "of", "the", "gradient", "descent", "for", "linear", "regression", "."], "sentence-detokenized": "This update rule is actually the stochastic update of the gradient descent for linear regression.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 19], [20, 28], [29, 32], [33, 43], [44, 50], [51, 53], [54, 57], [58, 66], [67, 74], [75, 78], [79, 85], [86, 96], [96, 97]]}
{"doc_key": "ai-dev-130", "ner": [[5, 10, "organisation"], [13, 16, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "was", "elected", "to", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "the", "National", "Academy", "of", "Sciences", "and", "has", "received", "a", "number", "of", "awards", ":"], "sentence-detokenized": "He was elected to the American Academy of Arts and Sciences and the National Academy of Sciences and has received a number of awards:", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 21], [22, 30], [31, 38], [39, 41], [42, 46], [47, 50], [51, 59], [60, 63], [64, 67], [68, 76], [77, 84], [85, 87], [88, 96], [97, 100], [101, 104], [105, 113], [114, 115], [116, 122], [123, 125], [126, 132], [132, 133]]}
{"doc_key": "ai-dev-131", "ner": [[4, 5, "organisation"], [11, 12, "person"], [14, 16, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 11, 12, "related-to", "written_about_by", false, false], [4, 5, 14, 16, "related-to", "written_about_by", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "latest", "thinking", "on", "Honda", "'s", "strategy", "was", "put", "forward", "by", "Gary", "Hamel", "and", "C.K", ".", "Prahalad", "in", "1989", "."], "sentence-detokenized": "The latest thinking on Honda's strategy was put forward by Gary Hamel and C.K. Prahalad in 1989.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 22], [23, 28], [28, 30], [31, 39], [40, 43], [44, 47], [48, 55], [56, 58], [59, 63], [64, 69], [70, 73], [74, 77], [77, 78], [79, 87], [88, 90], [91, 95], [95, 96]]}
{"doc_key": "ai-dev-132", "ner": [[1, 1, "metrics"], [3, 6, "metrics"], [13, 13, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 3, 6, "related-to", "calculates", true, false], [1, 1, 13, 13, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Where", "BLEU", "simply", "calculates", "gram", "precision", "by", "giving", "equal", "weight", "to", "each", ",", "NIST", "also", "calculates", "how", "informative", "a", "particular", "yarn", "gram", "is", "."], "sentence-detokenized": "Where BLEU simply calculates gram precision by giving equal weight to each, NIST also calculates how informative a particular yarn gram is.", "token2charspan": [[0, 5], [6, 10], [11, 17], [18, 28], [29, 33], [34, 43], [44, 46], [47, 53], [54, 59], [60, 66], [67, 69], [70, 74], [74, 75], [76, 80], [81, 85], [86, 96], [97, 100], [101, 112], [113, 114], [115, 125], [126, 130], [131, 135], [136, 138], [138, 139]]}
{"doc_key": "ai-dev-133", "ner": [[5, 8, "misc"], [11, 14, "conference"], [16, 16, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 8, 11, 14, "temporal", "", false, false], [16, 16, 11, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "honored", "with", "the", "2019", "Lifetime", "Achievement", "Award", "from", "the", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "."], "sentence-detokenized": "He was honored with the 2019 Lifetime Achievement Award from the Association for Computational Linguistics (ACL).", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 19], [20, 23], [24, 28], [29, 37], [38, 49], [50, 55], [56, 60], [61, 64], [65, 76], [77, 80], [81, 94], [95, 106], [107, 108], [108, 111], [111, 112], [112, 113]]}
{"doc_key": "ai-dev-134", "ner": [[0, 1, "researcher"], [6, 11, "organisation"], [13, 13, "organisation"], [20, 24, "conference"], [26, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 6, 11, "role", "", false, false], [0, 1, 20, 24, "role", "", false, false], [13, 13, 6, 11, "named", "", false, false], [26, 26, 20, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sycara", "is", "a", "member", "of", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", "and", "a", "member", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Sycara is a member of the Institute of Electrical and Electronics Engineers (IEEE) and a member of the American Association for Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 18], [19, 21], [22, 25], [26, 35], [36, 38], [39, 49], [50, 53], [54, 65], [66, 75], [76, 77], [77, 81], [81, 82], [83, 86], [87, 88], [89, 95], [96, 98], [99, 102], [103, 111], [112, 123], [124, 127], [128, 138], [139, 151], [152, 153], [153, 157], [157, 158], [158, 159]]}
{"doc_key": "ai-dev-135", "ner": [[11, 11, "misc"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "MATLAB", "code", "demonstrates", "a", "concrete", "solution", "for", "solving", "the", "nonlinear", "system", "of", "equations", "presented", "in", "the", "previous", "section", ":", "see", "also"], "sentence-detokenized": "The following MATLAB code demonstrates a concrete solution for solving the nonlinear system of equations presented in the previous section: see also", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 38], [39, 40], [41, 49], [50, 58], [59, 62], [63, 70], [71, 74], [75, 84], [85, 91], [92, 94], [95, 104], [105, 114], [115, 117], [118, 121], [122, 130], [131, 138], [138, 139], [140, 143], [144, 148]]}
{"doc_key": "ai-dev-136", "ner": [[0, 2, "product"], [13, 14, "field"], [36, 37, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 13, 14, "related-to", "trained_by", true, false], [0, 2, 36, 37, "related-to", "trained_by", true, false], [13, 14, 36, 37, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Pattern", "recognition", "systems", "are", "in", "many", "cases", "trained", "from", "labelled", "training", "data", "(", "supervised", "learning", ")", ",", "but", "when", "labelled", "data", "are", "not", "available", ",", "other", "algorithms", "can", "be", "used", "to", "detect", "previously", "unknown", "patterns", "(", "unsupervised", "learning", ")", "."], "sentence-detokenized": "Pattern recognition systems are in many cases trained from labelled training data (supervised learning), but when labelled data are not available, other algorithms can be used to detect previously unknown patterns (unsupervised learning).", "token2charspan": [[0, 7], [8, 19], [20, 27], [28, 31], [32, 34], [35, 39], [40, 45], [46, 53], [54, 58], [59, 67], [68, 76], [77, 81], [82, 83], [83, 93], [94, 102], [102, 103], [103, 104], [105, 108], [109, 113], [114, 122], [123, 127], [128, 131], [132, 135], [136, 145], [145, 146], [147, 152], [153, 163], [164, 167], [168, 170], [171, 175], [176, 178], [179, 185], [186, 196], [197, 204], [205, 213], [214, 215], [215, 227], [228, 236], [236, 237], [237, 238]]}
{"doc_key": "ai-dev-137", "ner": [[5, 7, "researcher"], [10, 10, "country"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 10, 10, "physical", "", false, false], [5, 7, 23, 24, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "was", "first", "used", "by", "Lawrence", "J.", "Fogel", "in", "the", "US", "in", "1960", "to", "use", "simulated", "evolution", "as", "a", "learning", "process", "to", "create", "artificial", "intelligence", "."], "sentence-detokenized": "It was first used by Lawrence J. Fogel in the US in 1960 to use simulated evolution as a learning process to create artificial intelligence.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 17], [18, 20], [21, 29], [30, 32], [33, 38], [39, 41], [42, 45], [46, 48], [49, 51], [52, 56], [57, 59], [60, 63], [64, 73], [74, 83], [84, 86], [87, 88], [89, 97], [98, 105], [106, 108], [109, 115], [116, 126], [127, 139], [139, 140]]}
{"doc_key": "ai-dev-138", "ner": [[0, 1, "field"], [10, 11, "field"], [15, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 10, 11, "part-of", "", false, false], [15, 16, 10, 11, "part-of", "", false, false], [18, 19, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Reinforced", "learning", "is", "one", "of", "the", "three", "basic", "paradigms", "of", "machine", "learning", ",", "along", "with", "supervised", "learning", "and", "unsupervised", "learning", "."], "sentence-detokenized": "Reinforced learning is one of the three basic paradigms of machine learning, along with supervised learning and unsupervised learning.", "token2charspan": [[0, 10], [11, 19], [20, 22], [23, 26], [27, 29], [30, 33], [34, 39], [40, 45], [46, 55], [56, 58], [59, 66], [67, 75], [75, 76], [77, 82], [83, 87], [88, 98], [99, 107], [108, 111], [112, 124], [125, 133], [133, 134]]}
{"doc_key": "ai-dev-139", "ner": [[4, 5, "field"], [12, 12, "programlang"], [28, 29, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 28, 29, "usage", "applies", false, false], [12, 12, 28, 29, "usage", "applies", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "such", "cases", ",", "cloud", "computing", "and", "the", "open", "source", "programming", "language", "R", "can", "help", "smaller", "banks", "adopt", "risk", "analysis", "and", "support", "branch", "-", "level", "monitoring", "by", "applying", "predictive", "analytics", "."], "sentence-detokenized": "In such cases, cloud computing and the open source programming language R can help smaller banks adopt risk analysis and support branch-level monitoring by applying predictive analytics.", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 20], [21, 30], [31, 34], [35, 38], [39, 43], [44, 50], [51, 62], [63, 71], [72, 73], [74, 77], [78, 82], [83, 90], [91, 96], [97, 102], [103, 107], [108, 116], [117, 120], [121, 128], [129, 135], [135, 136], [136, 141], [142, 152], [153, 155], [156, 164], [165, 175], [176, 185], [185, 186]]}
{"doc_key": "ai-dev-140", "ner": [[11, 12, "researcher"], [19, 20, "algorithm"], [22, 23, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 22, 23, "named", "same", false, false], [19, 20, 11, 12, "origin", "proves_function", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["One", "of", "the", "first", "versions", "of", "the", "theorem", "was", "proved", "by", "George", "Cybenko", "in", "1989", "for", "activation", "functions", "with", "sigmoid", "function", ".", "Cybenko", "G.", "(", "1989", ")", ",", "2", "(", "4", ")", ",", "303-314", "."], "sentence-detokenized": "One of the first versions of the theorem was proved by George Cybenko in 1989 for activation functions with sigmoid function. Cybenko G. (1989), 2 (4), 303-314.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [17, 25], [26, 28], [29, 32], [33, 40], [41, 44], [45, 51], [52, 54], [55, 61], [62, 69], [70, 72], [73, 77], [78, 81], [82, 92], [93, 102], [103, 107], [108, 115], [116, 124], [124, 125], [126, 133], [134, 136], [137, 138], [138, 142], [142, 143], [143, 144], [145, 146], [147, 148], [148, 149], [149, 150], [150, 151], [152, 159], [159, 160]]}
{"doc_key": "ai-dev-141", "ner": [[6, 8, "algorithm"], [9, 9, "metrics"], [14, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 6, 8, "part-of", "", false, false], [14, 18, 9, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "this", "process", ",", "known", "as", "cross-validation", ",", "the", "MSE", "is", "often", "called", "the", "mean", "squared", "prediction", "error", "and", "is", "calculated", "as"], "sentence-detokenized": "In this process, known as cross-validation, the MSE is often called the mean squared prediction error and is calculated as", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 22], [23, 25], [26, 42], [42, 43], [44, 47], [48, 51], [52, 54], [55, 60], [61, 67], [68, 71], [72, 76], [77, 84], [85, 95], [96, 101], [102, 105], [106, 108], [109, 119], [120, 122]]}
{"doc_key": "ai-dev-142", "ner": [[0, 0, "task"], [4, 6, "task"], [8, 8, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 6, "compare", "", false, false], [8, 8, 4, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["OMR", "generally", "differs", "from", "optical", "character", "recognition", "(", "OCR", ")", "in", "that", "it", "does", "not", "require", "a", "complex", "pattern", "recognition", "engine", "."], "sentence-detokenized": "OMR generally differs from optical character recognition (OCR) in that it does not require a complex pattern recognition engine.", "token2charspan": [[0, 3], [4, 13], [14, 21], [22, 26], [27, 34], [35, 44], [45, 56], [57, 58], [58, 61], [61, 62], [63, 65], [66, 70], [71, 73], [74, 78], [79, 82], [83, 90], [91, 92], [93, 100], [101, 108], [109, 120], [121, 127], [127, 128]]}
{"doc_key": "ai-dev-143", "ner": [[10, 10, "location"], [12, 12, "location"], [14, 14, "location"], [17, 18, "location"], [20, 21, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 14, 14, "physical", "", false, false], [17, 18, 12, 12, "physical", "", false, false], [20, 21, 12, 12, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2018", "and", "2019", ",", "the", "championship", "was", "held", "in", "Houston", "and", "Detroit", ",", "Michigan", "at", "the", "TCF", "Center", "and", "Ford", "Field", "."], "sentence-detokenized": "In 2018 and 2019, the championship was held in Houston and Detroit, Michigan at the TCF Center and Ford Field.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 16], [16, 17], [18, 21], [22, 34], [35, 38], [39, 43], [44, 46], [47, 54], [55, 58], [59, 66], [66, 67], [68, 76], [77, 79], [80, 83], [84, 87], [88, 94], [95, 98], [99, 103], [104, 109], [109, 110]]}
{"doc_key": "ai-dev-144", "ner": [[0, 0, "task"], [9, 10, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 0, "part-of", "", false, false], [12, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "considered", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multiclass", "classification", "."], "sentence-detokenized": "Classification can be considered as two separate problems - binary classification and multiclass classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 48], [49, 57], [58, 59], [60, 66], [67, 81], [82, 85], [86, 96], [97, 111], [111, 112]]}
{"doc_key": "ai-dev-145", "ner": [[4, 5, "product"], [8, 9, "product"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 4, 5, "type-of", "", false, false], [12, 13, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "examples", "of", "popular", "parallel", "robots", "are", "the", "Stewart", "platform", "and", "the", "Delta", "robot", "."], "sentence-detokenized": "Two examples of popular parallel robots are the Stewart platform and the Delta robot.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 23], [24, 32], [33, 39], [40, 43], [44, 47], [48, 55], [56, 64], [65, 68], [69, 72], [73, 78], [79, 84], [84, 85]]}
{"doc_key": "ai-dev-146", "ner": [[4, 6, "algorithm"], [21, 21, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 21, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "Nevertheless", ",", "the", "ReLU", "activation", "function", ",", "which", "is", "non-differentiable", "at", "0", ",", "has", "become", "quite", "popular", ",", "e.g.", "in", "AlexNet", ")"], "sentence-detokenized": "(Nevertheless, the ReLU activation function, which is non-differentiable at 0, has become quite popular, e.g. in AlexNet)", "token2charspan": [[0, 1], [1, 13], [13, 14], [15, 18], [19, 23], [24, 34], [35, 43], [43, 44], [45, 50], [51, 53], [54, 72], [73, 75], [76, 77], [77, 78], [79, 82], [83, 89], [90, 95], [96, 103], [103, 104], [105, 109], [110, 112], [113, 120], [120, 121]]}
{"doc_key": "ai-dev-147", "ner": [[0, 2, "metrics"], [7, 9, "task"], [11, 11, "task"], [13, 14, "task"], [16, 19, "task"], [20, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 20, 21, "named", "", true, false], [7, 9, 0, 2, "usage", "", true, false], [11, 11, 7, 9, "part-of", "", false, false], [13, 14, 7, 9, "part-of", "", false, false], [16, 19, 7, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["F", "-", "score", "is", "often", "used", "in", "information", "retrieval", "for", "measuring", "searches", ",", "document", "classification", "and", "query", "classification", ",", "and", "F_beta", "is", "therefore", "widely", "used", "."], "sentence-detokenized": "F-score is often used in information retrieval for measuring searches, document classification and query classification, and F_beta is therefore widely used.", "token2charspan": [[0, 1], [1, 2], [2, 7], [8, 10], [11, 16], [17, 21], [22, 24], [25, 36], [37, 46], [47, 50], [51, 60], [61, 69], [69, 70], [71, 79], [80, 94], [95, 98], [99, 104], [105, 119], [119, 120], [121, 124], [125, 131], [132, 134], [135, 144], [145, 151], [152, 156], [156, 157]]}
{"doc_key": "ai-dev-148", "ner": [[17, 18, "algorithm"], [20, 20, "algorithm"], [23, 24, "algorithm"], [26, 26, "algorithm"], [29, 31, "algorithm"], [33, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 20, 17, 18, "named", "", false, false], [26, 26, 23, 24, "named", "", false, false], [33, 33, 29, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "is", "done", "by", "modelling", "the", "received", "signal", "and", "then", "using", "a", "statistical", "estimation", "method", "such", "as", "maximum", "likelihood", "(", "ML", ")", ",", "majority", "voting", "(", "MV", ")", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "to", "decide", "which", "measure", "in", "the", "library", "best", "fits", "the", "model", "built", "using", "the", "received", "signal", "."], "sentence-detokenized": "This is done by modelling the received signal and then using a statistical estimation method such as maximum likelihood (ML), majority voting (MV) or maximum a posteriori (MAP) to decide which measure in the library best fits the model built using the received signal.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 15], [16, 25], [26, 29], [30, 38], [39, 45], [46, 49], [50, 54], [55, 60], [61, 62], [63, 74], [75, 85], [86, 92], [93, 97], [98, 100], [101, 108], [109, 119], [120, 121], [121, 123], [123, 124], [124, 125], [126, 134], [135, 141], [142, 143], [143, 145], [145, 146], [147, 149], [150, 157], [158, 159], [160, 170], [171, 172], [172, 175], [175, 176], [177, 179], [180, 186], [187, 192], [193, 200], [201, 203], [204, 207], [208, 215], [216, 220], [221, 225], [226, 229], [230, 235], [236, 241], [242, 247], [248, 251], [252, 260], [261, 267], [267, 268]]}
{"doc_key": "ai-dev-149", "ner": [[0, 0, "researcher"], [3, 3, "misc"], [5, 5, "field"], [8, 11, "university"], [16, 16, "misc"], [18, 19, "field"], [21, 22, "university"], [28, 28, "misc"], [30, 31, "field"], [34, 36, "university"], [43, 51, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 0, 8, 11, "physical", "", false, false], [0, 0, 8, 11, "role", "", false, false], [0, 0, 21, 22, "physical", "", false, false], [0, 0, 21, 22, "role", "", false, false], [0, 0, 34, 36, "physical", "", false, false], [0, 0, 34, 36, "role", "", false, false], [3, 3, 0, 0, "origin", "", false, false], [3, 3, 5, 5, "topic", "", false, false], [16, 16, 0, 0, "origin", "", false, false], [16, 16, 18, 19, "topic", "", false, false], [28, 28, 0, 0, "origin", "", false, false], [28, 28, 30, 31, "topic", "", false, false], [43, 51, 28, 28, "named", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Sowa", "received", "a", "BS", "in", "mathematics", "from", "the", "Massachusetts", "Institute", "of", "Technology", "in", "1962", ",", "an", "MA", "in", "applied", "mathematics", "from", "Harvard", "University", "in", "1966", ",", "and", "a", "PhD", "in", "computer", "science", "from", "the", "Vrije", "Universiteit", "Brussel", "in", "1999", "on", "a", "thesis", "entitled", "Knowledge", "Representation", ":", "Logical", ",", "Philosophical", "and", "Computational", "Foundations", "."], "sentence-detokenized": "Sowa received a BS in mathematics from the Massachusetts Institute of Technology in 1962, an MA in applied mathematics from Harvard University in 1966, and a PhD in computer science from the Vrije Universiteit Brussel in 1999 on a thesis entitled Knowledge Representation: Logical, Philosophical and Computational Foundations.", "token2charspan": [[0, 4], [5, 13], [14, 15], [16, 18], [19, 21], [22, 33], [34, 38], [39, 42], [43, 56], [57, 66], [67, 69], [70, 80], [81, 83], [84, 88], [88, 89], [90, 92], [93, 95], [96, 98], [99, 106], [107, 118], [119, 123], [124, 131], [132, 142], [143, 145], [146, 150], [150, 151], [152, 155], [156, 157], [158, 161], [162, 164], [165, 173], [174, 181], [182, 186], [187, 190], [191, 196], [197, 209], [210, 217], [218, 220], [221, 225], [226, 228], [229, 230], [231, 237], [238, 246], [247, 256], [257, 271], [271, 272], [273, 280], [280, 281], [282, 295], [296, 299], [300, 313], [314, 325], [325, 326]]}
{"doc_key": "ai-dev-150", "ner": [[1, 3, "task"], [18, 18, "metrics"], [20, 21, "metrics"], [23, 24, "metrics"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[18, 18, 1, 3, "part-of", "", true, false], [20, 21, 1, 3, "part-of", "", true, false], [23, 24, 1, 3, "part-of", "", true, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Since", "recognition", "of", "transcriptions", "can", "be", "considered", "as", "a", "classification", "problem", ",", "most", "standard", "evaluation", "methods", "such", "as", "accuracy", ",", "f1", "score", "or", "ROC", "curve", "perform", "relatively", "well", "."], "sentence-detokenized": "Since recognition of transcriptions can be considered as a classification problem, most standard evaluation methods such as accuracy, f1 score or ROC curve perform relatively well.", "token2charspan": [[0, 5], [6, 17], [18, 20], [21, 35], [36, 39], [40, 42], [43, 53], [54, 56], [57, 58], [59, 73], [74, 81], [81, 82], [83, 87], [88, 96], [97, 107], [108, 115], [116, 120], [121, 123], [124, 132], [132, 133], [134, 136], [137, 142], [143, 145], [146, 149], [150, 155], [156, 163], [164, 174], [175, 179], [179, 180]]}
{"doc_key": "ai-dev-151", "ner": [[19, 19, "algorithm"], [26, 27, "algorithm"], [29, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 19, 26, 27, "opposite", "not_suited_for", false, false], [19, 19, 29, 30, "opposite", "not_suited_for", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "makes", "it", "practical", "for", "analysis", "of", "large", "data", "sets", "(", "hundreds", "or", "thousands", "of", "taxa", ")", "and", "for", "bootstrapping", "where", "other", "analysis", "methods", "(", "e.g.", "maximum", "parsimony", ",", "maximum", "likelihood", ")", "may", "be", "computationally", "prohibitive", "."], "sentence-detokenized": "This makes it practical for analysis of large data sets (hundreds or thousands of taxa) and for bootstrapping where other analysis methods (e.g. maximum parsimony, maximum likelihood) may be computationally prohibitive.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 36], [37, 39], [40, 45], [46, 50], [51, 55], [56, 57], [57, 65], [66, 68], [69, 78], [79, 81], [82, 86], [86, 87], [88, 91], [92, 95], [96, 109], [110, 115], [116, 121], [122, 130], [131, 138], [139, 140], [140, 144], [145, 152], [153, 162], [162, 163], [164, 171], [172, 182], [182, 183], [184, 187], [188, 190], [191, 206], [207, 218], [218, 219]]}
{"doc_key": "ai-dev-152", "ner": [[6, 6, "programlang"], [12, 15, "organisation"], [17, 17, "organisation"], [28, 40, "organisation"]], "ner_mapping_to_source": [0, 2, 3, 5], "relations": [[17, 17, 12, 15, "named", "", false, false], [28, 40, 6, 6, "role", "submits", true, false], [28, 40, 12, 15, "role", "submits_to", true, false]], "relations_mapping_to_source": [1, 2, 4], "sentence": ["The", "submission", "in", "2002", "of", "the", "DAML", "+", "OIL", "language", "to", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", "the", "work", "done", "by", "the", "DAML", "contractors", "and", "the", "ad", "hoc", "Joint", "Committee", "on", "Markup", "Languages", "in", "the", "EU", "and", "the", "US", "."], "sentence-detokenized": "The submission in 2002 of the DAML + OIL language to the World Wide Web Consortium (W3C) the work done by the DAML contractors and the ad hoc Joint Committee on Markup Languages in the EU and the US.", "token2charspan": [[0, 3], [4, 14], [15, 17], [18, 22], [23, 25], [26, 29], [30, 34], [35, 36], [37, 40], [41, 49], [50, 52], [53, 56], [57, 62], [63, 67], [68, 71], [72, 82], [83, 84], [84, 87], [87, 88], [89, 92], [93, 97], [98, 102], [103, 105], [106, 109], [110, 114], [115, 126], [127, 130], [131, 134], [135, 137], [138, 141], [142, 147], [148, 157], [158, 160], [161, 167], [168, 177], [178, 180], [181, 184], [185, 187], [188, 191], [192, 195], [196, 198], [198, 199]]}
{"doc_key": "ai-dev-153", "ner": [[3, 4, "misc"], [7, 8, "misc"], [11, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 3, 4, "part-of", "", true, false], [11, 15, 3, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "non-linear", "normalization", "is", "when", "the", "normalization", "follows", "a", "sigmoid", "function", ",", "in", "which", "case", "the", "normalized", "image", "is", "calculated", "according", "to", "the", "formula"], "sentence-detokenized": "An example of non-linear normalization is when the normalization follows a sigmoid function, in which case the normalized image is calculated according to the formula", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 24], [25, 38], [39, 41], [42, 46], [47, 50], [51, 64], [65, 72], [73, 74], [75, 82], [83, 91], [91, 92], [93, 95], [96, 101], [102, 106], [107, 110], [111, 121], [122, 127], [128, 130], [131, 141], [142, 151], [152, 154], [155, 158], [159, 166]]}
{"doc_key": "ai-dev-154", "ner": [[6, 7, "metrics"], [11, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 11, 12, "related-to", "used_together", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "pointed", "out", "that", "precision", "is", "usually", "combined", "with", "recall", "to", "solve", "this", "problem", "."], "sentence-detokenized": "It has been pointed out that precision is usually combined with recall to solve this problem.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 23], [24, 28], [29, 38], [39, 41], [42, 49], [50, 58], [59, 63], [64, 70], [71, 73], [74, 79], [80, 84], [85, 92], [92, 93]]}
{"doc_key": "ai-dev-155", "ner": [[6, 8, "metrics"], [11, 14, "metrics"], [23, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 24, 11, 14, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "commonly", "used", "metrics", "are", "the", "mean", "squared", "error", "and", "the", "mean", "squared", "error", "root", ",", "the", "latter", "has", "been", "used", "in", "the", "Netflix", "price", "."], "sentence-detokenized": "The commonly used metrics are the mean squared error and the mean squared error root, the latter has been used in the Netflix price.", "token2charspan": [[0, 3], [4, 12], [13, 17], [18, 25], [26, 29], [30, 33], [34, 38], [39, 46], [47, 52], [53, 56], [57, 60], [61, 65], [66, 73], [74, 79], [80, 84], [84, 85], [86, 89], [90, 96], [97, 100], [101, 105], [106, 110], [111, 113], [114, 117], [118, 125], [126, 131], [131, 132]]}
{"doc_key": "ai-dev-156", "ner": [[10, 13, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "August", "2016", ",", "a", "research", "programme", "was", "announced", "with", "University", "College", "Hospital", "to", "develop", "an", "algorithm", "that", "can", "automatically", "distinguish", "between", "healthy", "and", "cancerous", "tissue", "in", "the", "head", "and", "neck", "region", "."], "sentence-detokenized": "In August 2016, a research programme was announced with University College Hospital to develop an algorithm that can automatically distinguish between healthy and cancerous tissue in the head and neck region.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 17], [18, 26], [27, 36], [37, 40], [41, 50], [51, 55], [56, 66], [67, 74], [75, 83], [84, 86], [87, 94], [95, 97], [98, 107], [108, 112], [113, 116], [117, 130], [131, 142], [143, 150], [151, 158], [159, 162], [163, 172], [173, 179], [180, 182], [183, 186], [187, 191], [192, 195], [196, 200], [201, 207], [207, 208]]}
{"doc_key": "ai-dev-157", "ner": [[3, 4, "researcher"], [16, 18, "organisation"], [21, 24, "organisation"], [27, 30, "organisation"], [33, 38, "organisation"], [41, 47, "organisation"], [51, 54, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 4, 16, 18, "role", "", false, false], [3, 4, 21, 24, "role", "", false, false], [3, 4, 27, 30, "role", "", false, false], [3, 4, 33, 38, "role", "", false, false], [3, 4, 41, 47, "role", "", false, false], [3, 4, 51, 54, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "impact", "of", "Posner", "'s", "theoretical", "and", "empirical", "contributions", "has", "been", "recognized", "through", "membership", "in", "the", "American", "Psychological", "Association", ",", "the", "Association", "for", "Psychological", "Science", ",", "the", "Society", "of", "Experimental", "Psychologists", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "The impact of Posner's theoretical and empirical contributions has been recognized through membership in the American Psychological Association, the Association for Psychological Science, the Society of Experimental Psychologists, the American Academy of Arts and Sciences, the American Association for the Advancement of Science, and the National Academy of Sciences.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 20], [20, 22], [23, 34], [35, 38], [39, 48], [49, 62], [63, 66], [67, 71], [72, 82], [83, 90], [91, 101], [102, 104], [105, 108], [109, 117], [118, 131], [132, 143], [143, 144], [145, 148], [149, 160], [161, 164], [165, 178], [179, 186], [186, 187], [188, 191], [192, 199], [200, 202], [203, 215], [216, 229], [229, 230], [231, 234], [235, 243], [244, 251], [252, 254], [255, 259], [260, 263], [264, 272], [272, 273], [274, 277], [278, 286], [287, 298], [299, 302], [303, 306], [307, 318], [319, 321], [322, 329], [329, 330], [331, 334], [335, 338], [339, 347], [348, 355], [356, 358], [359, 367], [367, 368]]}
{"doc_key": "ai-dev-158", "ner": [[2, 2, "product"], [9, 12, "field"], [14, 15, "task"], [17, 19, "task"], [21, 21, "task"], [24, 26, "task"], [28, 28, "task"], [31, 32, "field"], [34, 35, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 2, 9, 12, "usage", "", false, false], [14, 15, 9, 12, "part-of", "", false, false], [17, 19, 9, 12, "part-of", "", false, false], [21, 21, 17, 19, "named", "", false, false], [24, 26, 9, 12, "part-of", "", false, false], [28, 28, 24, 26, "named", "", false, false], [31, 32, 9, 12, "part-of", "", false, false], [34, 35, 9, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["These", "intelligent", "chatbots", "make", "use", "of", "all", "forms", "of", "artificial", "intelligence", ",", "such", "as", "image", "moderation", "and", "natural", "language", "understanding", "(", "NLU", ")", ",", "natural", "language", "generation", "(", "NLG", ")", ",", "machine", "learning", "and", "deep", "learning", "."], "sentence-detokenized": "These intelligent chatbots make use of all forms of artificial intelligence, such as image moderation and natural language understanding (NLU), natural language generation (NLG), machine learning and deep learning.", "token2charspan": [[0, 5], [6, 17], [18, 26], [27, 31], [32, 35], [36, 38], [39, 42], [43, 48], [49, 51], [52, 62], [63, 75], [75, 76], [77, 81], [82, 84], [85, 90], [91, 101], [102, 105], [106, 113], [114, 122], [123, 136], [137, 138], [138, 141], [141, 142], [142, 143], [144, 151], [152, 160], [161, 171], [172, 173], [173, 176], [176, 177], [177, 178], [179, 186], [187, 195], [196, 199], [200, 204], [205, 213], [213, 214]]}
{"doc_key": "ai-dev-159", "ner": [[4, 6, "metrics"], [8, 8, "metrics"], [12, 12, "metrics"], [15, 22, "metrics"], [26, 28, "metrics"], [30, 30, "metrics"], [33, 39, "metrics"], [43, 45, "metrics"], [47, 47, "metrics"], [50, 57, "metrics"], [61, 63, "metrics"], [65, 65, "metrics"], [68, 74, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 4, 6, "named", "", false, false], [12, 12, 4, 6, "named", "", false, false], [15, 22, 4, 6, "named", "", false, false], [30, 30, 26, 28, "named", "", false, false], [33, 39, 26, 28, "named", "", false, false], [47, 47, 43, 45, "named", "", false, false], [50, 57, 43, 45, "named", "", false, false], [65, 65, 61, 63, "named", "", false, false], [68, 74, 61, 63, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "row", "ratios", "are", "positive", "predictive", "value", "(", "PPV", ",", "also", "called", "precision", ")", "(", "TP", "/", "(", "TP", "+", "FP", ")", ")", ",", "complemented", "by", "FALSE", "detection", "rate", "(", "FDR", ")", "(", "FP", "/", "(", "TP", "+", "FP", ")", ")", ";", "and", "negative", "predictive", "value", "(", "NPV", ")", "(", "TN", "/", "(", "TN", "+", "FN", ")", ")", ",", "complemented", "by", "FALSE", "omission", "rate", "(", "FOR", ")", "(", "FN", "/", "(", "TN", "+", "FN", ")", ")", "."], "sentence-detokenized": "The row ratios are positive predictive value (PPV, also called precision) (TP/(TP+FP)), complemented by FALSE detection rate (FDR) (FP/(TP+FP)); and negative predictive value (NPV) (TN/(TN+FN)), complemented by FALSE omission rate (FOR) (FN/(TN+FN)).", "token2charspan": [[0, 3], [4, 7], [8, 14], [15, 18], [19, 27], [28, 38], [39, 44], [45, 46], [46, 49], [49, 50], [51, 55], [56, 62], [63, 72], [72, 73], [74, 75], [75, 77], [77, 78], [78, 79], [79, 81], [81, 82], [82, 84], [84, 85], [85, 86], [86, 87], [88, 100], [101, 103], [104, 109], [110, 119], [120, 124], [125, 126], [126, 129], [129, 130], [131, 132], [132, 134], [134, 135], [135, 136], [136, 138], [138, 139], [139, 141], [141, 142], [142, 143], [143, 144], [145, 148], [149, 157], [158, 168], [169, 174], [175, 176], [176, 179], [179, 180], [181, 182], [182, 184], [184, 185], [185, 186], [186, 188], [188, 189], [189, 191], [191, 192], [192, 193], [193, 194], [195, 207], [208, 210], [211, 216], [217, 225], [226, 230], [231, 232], [232, 235], [235, 236], [237, 238], [238, 240], [240, 241], [241, 242], [242, 244], [244, 245], [245, 247], [247, 248], [248, 249], [249, 250]]}
{"doc_key": "ai-dev-160", "ner": [[8, 8, "misc"], [14, 15, "algorithm"], [17, 17, "algorithm"], [21, 23, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[17, 17, 14, 15, "named", "", false, false], [25, 25, 21, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "information", "is", "a", "mixture", "of", "sitemaps", "and", "RSS", "and", "is", "created", "using", "the", "Information", "Model", "(", "IM", ")", "and", "the", "Biomedical", "Resource", "Ontology", "(", "BRO", ")", "."], "sentence-detokenized": "The information is a mixture of sitemaps and RSS and is created using the Information Model (IM) and the Biomedical Resource Ontology (BRO).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 20], [21, 28], [29, 31], [32, 40], [41, 44], [45, 48], [49, 52], [53, 55], [56, 63], [64, 69], [70, 73], [74, 85], [86, 91], [92, 93], [93, 95], [95, 96], [97, 100], [101, 104], [105, 115], [116, 124], [125, 133], [134, 135], [135, 138], [138, 139], [139, 140]]}
{"doc_key": "ai-dev-161", "ner": [[2, 3, "task"], [7, 9, "algorithm"], [11, 15, "algorithm"], [22, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 11, 15, "origin", "based_on", false, false], [11, 15, 7, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "latest", "text", "recognition", "is", "based", "on", "recurrent", "neural", "networks", "(", "long", "short", "-", "term", "memory", ")", "and", "does", "not", "require", "a", "language", "model", "."], "sentence-detokenized": "The latest text recognition is based on recurrent neural networks (long short-term memory) and does not require a language model.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 27], [28, 30], [31, 36], [37, 39], [40, 49], [50, 56], [57, 65], [66, 67], [67, 71], [72, 77], [77, 78], [78, 82], [83, 89], [89, 90], [91, 94], [95, 99], [100, 103], [104, 111], [112, 113], [114, 122], [123, 128], [128, 129]]}
{"doc_key": "ai-dev-162", "ner": [[1, 2, "misc"], [4, 6, "metrics"], [9, 10, "algorithm"], [14, 15, "metrics"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 1, 2, "type-of", "", false, false], [9, 10, 4, 6, "related-to", "", true, false], [14, 15, 1, 2, "type-of", "", false, false], [18, 19, 14, 15, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Popular", "loss", "functions", "include", "the", "hinge", "loss", "(", "for", "linear", "SVMs", ")", "and", "the", "log", "loss", "(", "for", "logistic", "regression", ")", "."], "sentence-detokenized": "Popular loss functions include the hinge loss (for linear SVMs) and the log loss (for logistic regression).", "token2charspan": [[0, 7], [8, 12], [13, 22], [23, 30], [31, 34], [35, 40], [41, 45], [46, 47], [47, 50], [51, 57], [58, 62], [62, 63], [64, 67], [68, 71], [72, 75], [76, 80], [81, 82], [82, 85], [86, 94], [95, 105], [105, 106], [106, 107]]}
{"doc_key": "ai-dev-163", "ner": [[0, 0, "metrics"], [12, 18, "metrics"], [10, 10, "metrics"], [23, 25, "metrics"], [21, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 12, 18, "compare", "", false, false], [0, 0, 23, 25, "compare", "", false, false], [10, 10, 12, 18, "named", "", false, false], [21, 21, 23, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SSIM", "is", "designed", "to", "improve", "on", "traditional", "methods", "such", "as", "PSNR", "(", "peak", "signal", "-", "to", "-", "noise", "ratio", ")", "and", "MSE", "(", "mean", "squared", "error", ")", "."], "sentence-detokenized": "SSIM is designed to improve on traditional methods such as PSNR (peak signal-to-noise ratio) and MSE (mean squared error).", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 19], [20, 27], [28, 30], [31, 42], [43, 50], [51, 55], [56, 58], [59, 63], [64, 65], [65, 69], [70, 76], [76, 77], [77, 79], [79, 80], [80, 85], [86, 91], [91, 92], [93, 96], [97, 100], [101, 102], [102, 106], [107, 114], [115, 120], [120, 121], [121, 122]]}
{"doc_key": "ai-dev-164", "ner": [[9, 10, "researcher"], [12, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "work", "inspired", "subsequent", "generations", "of", "roboticists", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "His work inspired subsequent generations of roboticists such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 28], [29, 40], [41, 43], [44, 55], [56, 60], [61, 63], [64, 70], [71, 77], [77, 78], [79, 83], [84, 91], [92, 95], [96, 100], [101, 107], [107, 108]]}
{"doc_key": "ai-dev-165", "ner": [[17, 18, "algorithm"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Furthermore", ",", "pulse", "training", "is", "not", "differentiable", ",", "which", "precludes", "backpropagation", "-", "based", "training", "methods", "such", "as", "gradient", "descent", "."], "sentence-detokenized": "Furthermore, pulse training is not differentiable, which precludes backpropagation-based training methods such as gradient descent.", "token2charspan": [[0, 11], [11, 12], [13, 18], [19, 27], [28, 30], [31, 34], [35, 49], [49, 50], [51, 56], [57, 66], [67, 82], [82, 83], [83, 88], [89, 97], [98, 105], [106, 110], [111, 113], [114, 122], [123, 130], [130, 131]]}
{"doc_key": "ai-dev-166", "ner": [[8, 9, "metrics"], [15, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 15, 16, "related-to", "describes", false, false]], "relations_mapping_to_source": [0], "sentence": ["These", "relationships", "can", "be", "easily", "represented", "by", "a", "confusion", "matrix", ",", "a", "table", "describing", "the", "accuracy", "of", "a", "classification", "model", "."], "sentence-detokenized": "These relationships can be easily represented by a confusion matrix, a table describing the accuracy of a classification model.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 26], [27, 33], [34, 45], [46, 48], [49, 50], [51, 60], [61, 67], [67, 68], [69, 70], [71, 76], [77, 87], [88, 91], [92, 100], [101, 103], [104, 105], [106, 120], [121, 126], [126, 127]]}
{"doc_key": "ai-dev-167", "ner": [[2, 8, "conference"], [10, 10, "conference"], [15, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 2, 8, "named", "", false, false], [15, 17, 2, 8, "physical", "", false, false], [15, 17, 2, 8, "role", "", false, false], [15, 17, 2, 8, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["At", "the", "2018", "Conference", "on", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", ",", "researchers", "from", "Google", "presented", "their", "work"], "sentence-detokenized": "At the 2018 Conference on Neural Information Processing Systems (NeurIPS), researchers from Google presented their work", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 22], [23, 25], [26, 32], [33, 44], [45, 55], [56, 63], [64, 65], [65, 72], [72, 73], [73, 74], [75, 86], [87, 91], [92, 98], [99, 108], [109, 114], [115, 119]]}
{"doc_key": "ai-dev-168", "ner": [[4, 4, "university"], [13, 13, "product"], [18, 20, "misc"], [24, 24, "conference"], [29, 32, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 13, 18, 20, "win-defeat", "", false, false], [18, 20, 24, 24, "temporal", "", false, false], [29, 32, 24, 24, "part-of", "", false, false], [29, 32, 24, 24, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "his", "time", "at", "Duke", ",", "he", "worked", "on", "an", "automated", "crossword", "solver", "PROVERB", ",", "which", "won", "an", "Outstanding", "Paper", "Award", "in", "1999", "from", "AAAI", "and", "competed", "in", "the", "American", "Crossword", "Puzzle", "Tournament", "."], "sentence-detokenized": "During his time at Duke, he worked on an automated crossword solver PROVERB, which won an Outstanding Paper Award in 1999 from AAAI and competed in the American Crossword Puzzle Tournament.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 18], [19, 23], [23, 24], [25, 27], [28, 34], [35, 37], [38, 40], [41, 50], [51, 60], [61, 67], [68, 75], [75, 76], [77, 82], [83, 86], [87, 89], [90, 101], [102, 107], [108, 113], [114, 116], [117, 121], [122, 126], [127, 131], [132, 135], [136, 144], [145, 147], [148, 151], [152, 160], [161, 170], [171, 177], [178, 188], [188, 189]]}
{"doc_key": "ai-dev-169", "ner": [[5, 6, "location"], [8, 10, "location"], [17, 18, "country"], [20, 20, "country"], [22, 22, "country"], [24, 24, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 6, 8, 10, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "company", "was", "headquartered", "in", "Rochester", "Hills", ",", "Michigan", ",", "and", "had", "10", "regional", "locations", "in", "the", "United", "States", ",", "Canada", ",", "Mexico", "and", "Brazil", "."], "sentence-detokenized": "The company was headquartered in Rochester Hills, Michigan, and had 10 regional locations in the United States, Canada, Mexico and Brazil.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 29], [30, 32], [33, 42], [43, 48], [48, 49], [50, 58], [58, 59], [60, 63], [64, 67], [68, 70], [71, 79], [80, 89], [90, 92], [93, 96], [97, 103], [104, 110], [110, 111], [112, 118], [118, 119], [120, 126], [127, 130], [131, 137], [137, 138]]}
{"doc_key": "ai-dev-170", "ner": [[12, 12, "product"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "joins", "a", "collection", "of", "historically", "important", "robots", "that", "includes", "an", "early", "Unimate", "and", "the", "Odetics", "Odex", "1", "."], "sentence-detokenized": "It joins a collection of historically important robots that includes an early Unimate and the Odetics Odex 1.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 21], [22, 24], [25, 37], [38, 47], [48, 54], [55, 59], [60, 68], [69, 71], [72, 77], [78, 85], [86, 89], [90, 93], [94, 101], [102, 106], [107, 108], [108, 109]]}
{"doc_key": "ai-dev-171", "ner": [[8, 9, "researcher"], [13, 13, "organisation"], [15, 20, "researcher"], [26, 31, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 13, 13, "physical", "", false, false], [8, 9, 13, 13, "role", "", false, false], [15, 20, 13, 13, "physical", "", false, false], [15, 20, 13, 13, "role", "", false, false], [15, 20, 26, 31, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["A", "guest", "editor", "for", "this", "issue", "will", "be", "David", "'s", "former", "colleague", "at", "NIST", ",", "Judah", "Levine", ",", "who", "is", "the", "most", "recent", "recipient", "of", "the", "I.I", ".", "I", ".", "Rabi", "Award", "."], "sentence-detokenized": "A guest editor for this issue will be David's former colleague at NIST, Judah Levine, who is the most recent recipient of the I.I. I. Rabi Award.", "token2charspan": [[0, 1], [2, 7], [8, 14], [15, 18], [19, 23], [24, 29], [30, 34], [35, 37], [38, 43], [43, 45], [46, 52], [53, 62], [63, 65], [66, 70], [70, 71], [72, 77], [78, 84], [84, 85], [86, 89], [90, 92], [93, 96], [97, 101], [102, 108], [109, 118], [119, 121], [122, 125], [126, 129], [129, 130], [131, 132], [132, 133], [134, 138], [139, 144], [144, 145]]}
{"doc_key": "ai-dev-172", "ner": [[13, 14, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "can", "be", "set", "out", "in", "a", "2", "\u00d7", "2", "contingency", "table", "(", "confusion", "matrix", ")", ",", "usually", "with", "the", "test", "result", "on", "the", "vertical", "axis", "and", "the", "actual", "condition", "on", "the", "horizontal", "axis", "."], "sentence-detokenized": "These can be set out in a 2 \u00d7 2 contingency table (confusion matrix), usually with the test result on the vertical axis and the actual condition on the horizontal axis.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 16], [17, 20], [21, 23], [24, 25], [26, 27], [28, 29], [30, 31], [32, 43], [44, 49], [50, 51], [51, 60], [61, 67], [67, 68], [68, 69], [70, 77], [78, 82], [83, 86], [87, 91], [92, 98], [99, 101], [102, 105], [106, 114], [115, 119], [120, 123], [124, 127], [128, 134], [135, 144], [145, 147], [148, 151], [152, 162], [163, 167], [167, 168]]}
{"doc_key": "ai-dev-173", "ner": [[0, 4, "product"], [8, 8, "product"], [10, 10, "product"], [12, 13, "product"], [16, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 8, 8, "part-of", "", false, false], [0, 4, 10, 10, "part-of", "", false, false], [0, 4, 12, 13, "part-of", "", false, false], [0, 4, 16, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Apple", "'s", "iOS", "operating", "system", ",", "used", "on", "iPhone", ",", "iPad", "and", "iPod", "Touch", ",", "uses", "VoiceOver", "speech", "synthesis", "to", "make", "it", "accessible", "."], "sentence-detokenized": "Apple's iOS operating system, used on iPhone, iPad and iPod Touch, uses VoiceOver speech synthesis to make it accessible.", "token2charspan": [[0, 5], [5, 7], [8, 11], [12, 21], [22, 28], [28, 29], [30, 34], [35, 37], [38, 44], [44, 45], [46, 50], [51, 54], [55, 59], [60, 65], [65, 66], [67, 71], [72, 81], [82, 88], [89, 98], [99, 101], [102, 106], [107, 109], [110, 120], [120, 121]]}
{"doc_key": "ai-dev-174", "ner": [[7, 9, "conference"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "the", "best", "system", "entering", "MUC", "-", "7", "achieved", "93.39", "%", "of", "the", "F", "-", "target", ",", "while", "human", "annotators", "achieved", "97.6", "%", "and", "96.95", "%", "."], "sentence-detokenized": "For example, the best system entering MUC-7 achieved 93.39% of the F-target, while human annotators achieved 97.6% and 96.95%.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 37], [38, 41], [41, 42], [42, 43], [44, 52], [53, 58], [58, 59], [60, 62], [63, 66], [67, 68], [68, 69], [69, 75], [75, 76], [77, 82], [83, 88], [89, 99], [100, 108], [109, 113], [113, 114], [115, 118], [119, 124], [124, 125], [125, 126]]}
{"doc_key": "ai-dev-175", "ner": [[12, 14, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 16, 12, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "is", "done", "using", "standard", "neural", "network", "training", "algorithms", ",", "such", "as", "stochastic", "gradient", "descent", "with", "backpropagation", "."], "sentence-detokenized": "This is done using standard neural network training algorithms, such as stochastic gradient descent with backpropagation.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 18], [19, 27], [28, 34], [35, 42], [43, 51], [52, 62], [62, 63], [64, 68], [69, 71], [72, 82], [83, 91], [92, 99], [100, 104], [105, 120], [120, 121]]}
{"doc_key": "ai-dev-176", "ner": [[0, 2, "organisation"], [18, 18, "country"], [26, 26, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 18, 18, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Rotten", "Tomatoes", "is", "a", "top", "1000", "website", ",", "ranking", "around", "#", "400", "globally", "and", "top", "150", "for", "the", "US", "alone", ",", "according", "to", "website", "ranking", "site", "Alexa", "."], "sentence-detokenized": "Rotten Tomatoes is a top 1000 website, ranking around #400 globally and top 150 for the US alone, according to website ranking site Alexa.", "token2charspan": [[0, 6], [7, 15], [16, 18], [19, 20], [21, 24], [25, 29], [30, 37], [37, 38], [39, 46], [47, 53], [54, 55], [55, 58], [59, 67], [68, 71], [72, 75], [76, 79], [80, 83], [84, 87], [88, 90], [91, 96], [96, 97], [98, 107], [108, 110], [111, 118], [119, 126], [127, 131], [132, 137], [137, 138]]}
{"doc_key": "ai-dev-177", "ner": [[14, 16, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "general", ",", "all", "learning", "shows", "incremental", "changes", "over", "time", ",", "but", "describes", "a", "sigmoid", "function", "that", "has", "different", "appearances", "depending", "on", "the", "time", "scale", "of", "the", "observation", "."], "sentence-detokenized": "In general, all learning shows incremental changes over time, but describes a sigmoid function that has different appearances depending on the time scale of the observation.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 24], [25, 30], [31, 42], [43, 50], [51, 55], [56, 60], [60, 61], [62, 65], [66, 75], [76, 77], [78, 85], [86, 94], [95, 99], [100, 103], [104, 113], [114, 125], [126, 135], [136, 138], [139, 142], [143, 147], [148, 153], [154, 156], [157, 160], [161, 172], [172, 173]]}
{"doc_key": "ai-dev-178", "ner": [[0, 0, "metrics"], [6, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["SSD", "is", "also", "known", "as", "the", "mean", "squared", "error", "."], "sentence-detokenized": "SSD is also known as the mean squared error.", "token2charspan": [[0, 3], [4, 6], [7, 11], [12, 17], [18, 20], [21, 24], [25, 29], [30, 37], [38, 43], [43, 44]]}
{"doc_key": "ai-dev-179", "ner": [[0, 2, "algorithm"], [4, 5, "algorithm"], [8, 10, "algorithm"], [23, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 23, 24, "related-to", "can_be_related_to", true, false], [4, 5, 23, 24, "related-to", "can_be_related_to", true, false], [8, 10, 23, 24, "related-to", "can_be_related_to", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Learning", "decision", "trees", ",", "neural", "networks", "or", "a", "naive", "Bayes", "classifier", "can", "be", "used", "in", "combination", "with", "measures", "of", "model", "quality", ",", "e.g.", "balanced", "accuracy"], "sentence-detokenized": "Learning decision trees, neural networks or a naive Bayes classifier can be used in combination with measures of model quality, e.g. balanced accuracy", "token2charspan": [[0, 8], [9, 17], [18, 23], [23, 24], [25, 31], [32, 40], [41, 43], [44, 45], [46, 51], [52, 57], [58, 68], [69, 72], [73, 75], [76, 80], [81, 83], [84, 95], [96, 100], [101, 109], [110, 112], [113, 118], [119, 126], [126, 127], [128, 132], [133, 141], [142, 150]]}
{"doc_key": "ai-dev-180", "ner": [[15, 15, "conference"], [21, 25, "conference"], [26, 28, "misc"], [34, 39, "product"], [43, 46, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[26, 28, 21, 25, "origin", "", false, false], [26, 28, 21, 25, "temporal", "", false, false], [34, 39, 26, 28, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "is", "a", "past", "President", "(", "1979", ")", "and", "first", "Fellow", "(", "2011", ")", "of", "ACL", ",", "a", "co-recipient", "of", "the", "1992", "Association", "for", "Computing", "Machinery", "Software", "Systems", "Award", "for", "his", "contribution", "to", "the", "Interlisp", "programming", "system", ",", "and", "a", "Fellow", "of", "the", "Association", "for", "Computing", "Machinery", "."], "sentence-detokenized": "He is a past President (1979) and first Fellow (2011) of ACL, a co-recipient of the 1992 Association for Computing Machinery Software Systems Award for his contribution to the Interlisp programming system, and a Fellow of the Association for Computing Machinery.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 22], [23, 24], [24, 28], [28, 29], [30, 33], [34, 39], [40, 46], [47, 48], [48, 52], [52, 53], [54, 56], [57, 60], [60, 61], [62, 63], [64, 76], [77, 79], [80, 83], [84, 88], [89, 100], [101, 104], [105, 114], [115, 124], [125, 133], [134, 141], [142, 147], [148, 151], [152, 155], [156, 168], [169, 171], [172, 175], [176, 185], [186, 197], [198, 204], [204, 205], [206, 209], [210, 211], [212, 218], [219, 221], [222, 225], [226, 237], [238, 241], [242, 251], [252, 261], [261, 262]]}
{"doc_key": "ai-dev-181", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [12, 13, "researcher"], [27, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 27, 30, "related-to", "", false, false], [5, 6, 27, 30, "related-to", "", false, false], [8, 8, 27, 30, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "is", "considered", "by", "Cade", "Metz", "to", "be", "one", "of", "the", "three", "people", "most", "responsible", "for", "the", "development", "of", "deep", "learning", "in", "the", "1990s", "and", "2000s", "."], "sentence-detokenized": "Along with Geoffrey Hinton and Yann LeCun, Bengio is considered by Cade Metz to be one of the three people most responsible for the development of deep learning in the 1990s and 2000s.", "token2charspan": [[0, 5], [6, 10], [11, 19], [20, 26], [27, 30], [31, 35], [36, 41], [41, 42], [43, 49], [50, 52], [53, 63], [64, 66], [67, 71], [72, 76], [77, 79], [80, 82], [83, 86], [87, 89], [90, 93], [94, 99], [100, 106], [107, 111], [112, 123], [124, 127], [128, 131], [132, 143], [144, 146], [147, 151], [152, 160], [161, 163], [164, 167], [168, 173], [174, 177], [178, 183], [183, 184]]}
{"doc_key": "ai-dev-182", "ner": [[1, 2, "field"], [4, 5, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "information", "theory", "and", "computer", "science", ",", "a", "code", "is", "usually", "considered", "as", "an", "algorithm", "that", "uniquely", "represents", "symbols", "from", "some", "source", "alphabet", "using", "coded", "strings", "that", "may", "be", "in", "another", "target", "alphabet", "."], "sentence-detokenized": "In information theory and computer science, a code is usually considered as an algorithm that uniquely represents symbols from some source alphabet using coded strings that may be in another target alphabet.", "token2charspan": [[0, 2], [3, 14], [15, 21], [22, 25], [26, 34], [35, 42], [42, 43], [44, 45], [46, 50], [51, 53], [54, 61], [62, 72], [73, 75], [76, 78], [79, 88], [89, 93], [94, 102], [103, 113], [114, 121], [122, 126], [127, 131], [132, 138], [139, 147], [148, 153], [154, 159], [160, 167], [168, 172], [173, 176], [177, 179], [180, 182], [183, 190], [191, 197], [198, 206], [206, 207]]}
{"doc_key": "ai-dev-183", "ner": [[7, 10, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 7, 10, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "rather", "simple", "non-linear", "function", ",", "the", "sigmoid", "function", ",", "such", "as", "the", "logistic", "function", ",", "also", "has", "an", "easily", "computable", "derivative", "function", ",", "which", "can", "be", "important", "when", "computing", "the", "weight", "updates", "in", "the", "network", "."], "sentence-detokenized": "A rather simple non-linear function, the sigmoid function, such as the logistic function, also has an easily computable derivative function, which can be important when computing the weight updates in the network.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 26], [27, 35], [35, 36], [37, 40], [41, 48], [49, 57], [57, 58], [59, 63], [64, 66], [67, 70], [71, 79], [80, 88], [88, 89], [90, 94], [95, 98], [99, 101], [102, 108], [109, 119], [120, 130], [131, 139], [139, 140], [141, 146], [147, 150], [151, 153], [154, 163], [164, 168], [169, 178], [179, 182], [183, 189], [190, 197], [198, 200], [201, 204], [205, 212], [212, 213]]}
{"doc_key": "ai-dev-184", "ner": [[0, 0, "person"], [4, 4, "location"], [6, 6, "location"], [8, 10, "country"], [13, 13, "country"], [16, 18, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 4, 4, "physical", "", false, false], [4, 4, 6, 6, "physical", "", false, false], [6, 6, 8, 10, "physical", "", false, false], [6, 6, 13, 13, "physical", "", false, false], [6, 6, 16, 18, "physical", "", false, false], [13, 13, 8, 10, "origin", "", false, false], [16, 18, 13, 13, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["\u010capek", "was", "born", "in", "Hronov", "in", "Bohemia", "(", "Austria", "-", "Hungary", ",", "later", "Czechoslovakia", ",", "now", "the", "Czech", "Republic", ")", "in", "1887", "."], "sentence-detokenized": "\u010capek was born in Hronov in Bohemia (Austria-Hungary, later Czechoslovakia, now the Czech Republic) in 1887.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 17], [18, 24], [25, 27], [28, 35], [36, 37], [37, 44], [44, 45], [45, 52], [52, 53], [54, 59], [60, 74], [74, 75], [76, 79], [80, 83], [84, 89], [90, 98], [98, 99], [100, 102], [103, 107], [107, 108]]}
{"doc_key": "ai-dev-185", "ner": [[5, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "specialized", "programs", "can", "tell", "RSS", "."], "sentence-detokenized": "Some specialized programs can tell RSS.", "token2charspan": [[0, 4], [5, 16], [17, 25], [26, 29], [30, 34], [35, 38], [38, 39]]}
{"doc_key": "ai-dev-186", "ner": [[6, 6, "task"], [11, 12, "task"], [17, 17, "task"], [19, 21, "task"], [32, 33, "task"], [38, 39, "task"], [42, 44, "product"], [46, 47, "product"]], "ner_mapping_to_source": [0, 1, 3, 4, 6, 7, 8, 9], "relations": [[6, 6, 11, 12, "related-to", "", true, false], [6, 6, 17, 17, "related-to", "", true, false], [42, 44, 38, 39, "type-of", "", false, false], [46, 47, 38, 39, "type-of", "", false, false]], "relations_mapping_to_source": [0, 2, 4, 5], "sentence": ["Aspects", "of", "ontology", "editors", "include", ":", "visual", "navigation", "capabilities", "within", "the", "knowledge", "model", ",", "inference", "engines", "and", "extraction", ";", "support", "for", "modules", ";", "import", "and", "export", "of", "foreign", "knowledge", "representation", "languages", "for", "ontology", "matching", ";", "and", "support", "for", "meta", "-ontologies", "such", "as", "OWL", "-", "S", ",", "Dublin", "Core", ",", "etc", "."], "sentence-detokenized": "Aspects of ontology editors include: visual navigation capabilities within the knowledge model, inference engines and extraction; support for modules; import and export of foreign knowledge representation languages for ontology matching; and support for meta-ontologies such as OWL-S, Dublin Core, etc.", "token2charspan": [[0, 7], [8, 10], [11, 19], [20, 27], [28, 35], [35, 36], [37, 43], [44, 54], [55, 67], [68, 74], [75, 78], [79, 88], [89, 94], [94, 95], [96, 105], [106, 113], [114, 117], [118, 128], [128, 129], [130, 137], [138, 141], [142, 149], [149, 150], [151, 157], [158, 161], [162, 168], [169, 171], [172, 179], [180, 189], [190, 204], [205, 214], [215, 218], [219, 227], [228, 236], [236, 237], [238, 241], [242, 249], [250, 253], [254, 258], [258, 269], [270, 274], [275, 277], [278, 281], [281, 282], [282, 283], [283, 284], [285, 291], [292, 296], [296, 297], [298, 301], [301, 302]]}
{"doc_key": "ai-dev-187", "ner": [[0, 1, "organisation"], [6, 11, "misc"], [13, 14, "task"], [20, 20, "field"], [23, 23, "misc"], [25, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 11, 0, 1, "origin", "", false, false], [13, 14, 6, 11, "part-of", "", false, false], [20, 20, 6, 11, "part-of", "", false, false], [23, 23, 20, 20, "type-of", "", false, false], [25, 27, 20, 20, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "FBI", "has", "also", "launched", "its", "Next", "Generation", "Identification", "program", ",", "which", "includes", "facial", "recognition", "as", "well", "as", "more", "traditional", "biometrics", "such", "as", "fingerprints", "and", "iris", "scans", "that", "can", "be", "retrieved", "from", "both", "criminal", "and", "civil", "databases", "."], "sentence-detokenized": "The FBI has also launched its Next Generation Identification program, which includes facial recognition as well as more traditional biometrics such as fingerprints and iris scans that can be retrieved from both criminal and civil databases.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 16], [17, 25], [26, 29], [30, 34], [35, 45], [46, 60], [61, 68], [68, 69], [70, 75], [76, 84], [85, 91], [92, 103], [104, 106], [107, 111], [112, 114], [115, 119], [120, 131], [132, 142], [143, 147], [148, 150], [151, 163], [164, 167], [168, 172], [173, 178], [179, 183], [184, 187], [188, 190], [191, 200], [201, 205], [206, 210], [211, 219], [220, 223], [224, 229], [230, 239], [239, 240]]}
{"doc_key": "ai-dev-188", "ner": [[5, 6, "person"], [14, 15, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "2016", "season", ",", "Samantha", "Ponder", "was", "added", "as", "host", "in", "place", "of", "Molly", "McGrath", "."], "sentence-detokenized": "In the 2016 season, Samantha Ponder was added as host in place of Molly McGrath.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [18, 19], [20, 28], [29, 35], [36, 39], [40, 45], [46, 48], [49, 53], [54, 56], [57, 62], [63, 65], [66, 71], [72, 79], [79, 80]]}
{"doc_key": "ai-dev-189", "ner": [[3, 5, "algorithm"], [17, 21, "misc"], [23, 23, "misc"], [25, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "an", "opponent", "search", "algorithm", "commonly", "used", "for", "machine", "play", "of", "two", "-", "player", "games", "(", "tic", "-", "tac", "-", "toe", ",", "chess", ",", "go", ",", "etc.", ")", "."], "sentence-detokenized": "It is an opponent search algorithm commonly used for machine play of two-player games (tic-tac-toe, chess, go, etc.).", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 17], [18, 24], [25, 34], [35, 43], [44, 48], [49, 52], [53, 60], [61, 65], [66, 68], [69, 72], [72, 73], [73, 79], [80, 85], [86, 87], [87, 90], [90, 91], [91, 94], [94, 95], [95, 98], [98, 99], [100, 105], [105, 106], [107, 109], [109, 110], [111, 115], [115, 116], [116, 117]]}
{"doc_key": "ai-dev-190", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 15, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "covers", "the", "areas", "of", "computer", "vision", "or", "machine", "vision", "and", "medical", "imaging", ",", "and", "makes", "extensive", "use", "of", "pattern", "recognition", ",", "digital", "geometry", "and", "signal", "processing", "."], "sentence-detokenized": "It covers the areas of computer vision or machine vision and medical imaging, and makes extensive use of pattern recognition, digital geometry and signal processing.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 19], [20, 22], [23, 31], [32, 38], [39, 41], [42, 49], [50, 56], [57, 60], [61, 68], [69, 76], [76, 77], [78, 81], [82, 87], [88, 97], [98, 101], [102, 104], [105, 112], [113, 124], [124, 125], [126, 133], [134, 142], [143, 146], [147, 153], [154, 164], [164, 165]]}
{"doc_key": "ai-dev-191", "ner": [[5, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "in", "a", "facial", "recognition", "system", ",", "an", "image", "of", "a", "person", "'s", "face", "would", "be", "the", "input", ",", "and", "the", "output", "label", "would", "be", "that", "person", "'s", "name", "."], "sentence-detokenized": "For example, in a facial recognition system, an image of a person's face would be the input, and the output label would be that person's name.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 17], [18, 24], [25, 36], [37, 43], [43, 44], [45, 47], [48, 53], [54, 56], [57, 58], [59, 65], [65, 67], [68, 72], [73, 78], [79, 81], [82, 85], [86, 91], [91, 92], [93, 96], [97, 100], [101, 107], [108, 113], [114, 119], [120, 122], [123, 127], [128, 134], [134, 136], [137, 141], [141, 142]]}
{"doc_key": "ai-dev-192", "ner": [[0, 1, "organisation"], [3, 4, "product"], [8, 10, "product"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 3, 4, "artifact", "", false, false], [3, 4, 8, 10, "part-of", "", false, false], [8, 10, 3, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Apple", "Inc.", "introduced", "Face", "ID", "on", "the", "flagship", "i", "Phone", "X", "as", "a", "biometric", "authentication", "successor", "to", "Touch", "ID", ",", "a", "fingerprint", "-", "based", "system", "."], "sentence-detokenized": "Apple Inc. introduced Face ID on the flagship iPhone X as a biometric authentication successor to Touch ID, a fingerprint-based system.", "token2charspan": [[0, 5], [6, 10], [11, 21], [22, 26], [27, 29], [30, 32], [33, 36], [37, 45], [46, 47], [47, 52], [53, 54], [55, 57], [58, 59], [60, 69], [70, 84], [85, 94], [95, 97], [98, 103], [104, 106], [106, 107], [108, 109], [110, 121], [121, 122], [122, 127], [128, 134], [134, 135]]}
{"doc_key": "ai-dev-193", "ner": [[3, 5, "metrics"], [7, 9, "metrics"], [22, 26, "metrics"], [28, 30, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Or", "combine", "the", "F", "-", "target", "with", "the", "R-", "squared", "evaluated", "for", "the", "raw", "model", "output", "and", "the", "target", ";", "or", "combine", "the", "cost", "/", "benefit", "matrix", "with", "the", "correlation", "coefficient", ",", "etc", "."], "sentence-detokenized": "Or combine the F-target with the R-squared evaluated for the raw model output and the target; or combine the cost/benefit matrix with the correlation coefficient, etc.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 16], [16, 17], [17, 23], [24, 28], [29, 32], [33, 35], [35, 42], [43, 52], [53, 56], [57, 60], [61, 64], [65, 70], [71, 77], [78, 81], [82, 85], [86, 92], [92, 93], [94, 96], [97, 104], [105, 108], [109, 113], [113, 114], [114, 121], [122, 128], [129, 133], [134, 137], [138, 149], [150, 161], [161, 162], [163, 166], [166, 167]]}
{"doc_key": "ai-dev-194", "ner": [[1, 6, "conference"], [12, 14, "location"], [16, 16, "location"], [19, 23, "location"], [25, 25, "location"], [27, 27, "country"], [33, 35, "location"], [38, 42, "location"], [44, 44, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[1, 6, 12, 14, "physical", "", false, false], [1, 6, 19, 23, "physical", "", false, false], [1, 6, 33, 35, "physical", "", false, false], [1, 6, 38, 42, "physical", "", false, false], [12, 14, 16, 16, "physical", "", false, false], [19, 23, 25, 25, "physical", "", false, false], [25, 25, 27, 27, "physical", "", false, false], [33, 35, 44, 44, "physical", "", false, false], [38, 42, 44, 44, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "Spanish", "edition", "of", "the", "Campus", "Party", "has", "been", "held", "at", "the", "Colegio", "Miguel", "Hern\u00e1ndez", ",", "Ceulaj", "and", "the", "Municipal", "Sports", "Arena", "in", "Benalm\u00e1dena", "in", "M\u00e1laga", ",", "Spain", ",", "and", "at", "both", "the", "Valencia", "County", "Fair", "and", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", "over", "the", "last", "15", "years", "."], "sentence-detokenized": "The Spanish edition of the Campus Party has been held at the Colegio Miguel Hern\u00e1ndez, Ceulaj and the Municipal Sports Arena in Benalm\u00e1dena in M\u00e1laga, Spain, and at both the Valencia County Fair and the City of Arts and Sciences in Valencia over the last 15 years.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 22], [23, 26], [27, 33], [34, 39], [40, 43], [44, 48], [49, 53], [54, 56], [57, 60], [61, 68], [69, 75], [76, 85], [85, 86], [87, 93], [94, 97], [98, 101], [102, 111], [112, 118], [119, 124], [125, 127], [128, 139], [140, 142], [143, 149], [149, 150], [151, 156], [156, 157], [158, 161], [162, 164], [165, 169], [170, 173], [174, 182], [183, 189], [190, 194], [195, 198], [199, 202], [203, 207], [208, 210], [211, 215], [216, 219], [220, 228], [229, 231], [232, 240], [241, 245], [246, 249], [250, 254], [255, 257], [258, 263], [263, 264]]}
{"doc_key": "ai-dev-195", "ner": [[0, 0, "product"], [13, 13, "programlang"], [16, 16, "product"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[13, 13, 0, 0, "general-affiliation", "", false, false], [16, 16, 13, 13, "part-of", "", false, false], [22, 22, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 3], "sentence": ["gnuplot", "can", "be", "used", "from", "various", "programming", "languages", "to", "graph", "data", ",", "including", "Perl", "(", "via", "PDL", "and", "CPAN", "packages", ")", ",", "Python", "(", "via", ")", "."], "sentence-detokenized": "gnuplot can be used from various programming languages to graph data, including Perl (via PDL and CPAN packages), Python (via).", "token2charspan": [[0, 7], [8, 11], [12, 14], [15, 19], [20, 24], [25, 32], [33, 44], [45, 54], [55, 57], [58, 63], [64, 68], [68, 69], [70, 79], [80, 84], [85, 86], [86, 89], [90, 93], [94, 97], [98, 102], [103, 111], [111, 112], [112, 113], [114, 120], [121, 122], [122, 125], [125, 126], [126, 127]]}
{"doc_key": "ai-dev-196", "ner": [[3, 5, "product"], [20, 20, "conference"], [22, 22, "conference"], [36, 36, "conference"], [38, 38, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[20, 20, 3, 5, "topic", "", false, false], [22, 22, 3, 5, "topic", "", false, false], [36, 36, 3, 5, "topic", "", false, false], [38, 38, 3, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "field", "of", "speech", "dialogue", "systems", "is", "quite", "large", "and", "includes", "both", "research", "(", "presented", "at", "scientific", "conferences", "such", "as", "SIGdial", "and", "Interspeech", ")", "and", "a", "large", "industrial", "sector", "(", "with", "its", "own", "meetings", "such", "as", "SpeechTek", "and", "AVIOS", ")", "."], "sentence-detokenized": "The field of speech dialogue systems is quite large and includes both research (presented at scientific conferences such as SIGdial and Interspeech) and a large industrial sector (with its own meetings such as SpeechTek and AVIOS).", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 28], [29, 36], [37, 39], [40, 45], [46, 51], [52, 55], [56, 64], [65, 69], [70, 78], [79, 80], [80, 89], [90, 92], [93, 103], [104, 115], [116, 120], [121, 123], [124, 131], [132, 135], [136, 147], [147, 148], [149, 152], [153, 154], [155, 160], [161, 171], [172, 178], [179, 180], [180, 184], [185, 188], [189, 192], [193, 201], [202, 206], [207, 209], [210, 219], [220, 223], [224, 229], [229, 230], [230, 231]]}
{"doc_key": "ai-dev-197", "ner": [[2, 4, "field"], [7, 8, "task"], [10, 12, "task"], [14, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 2, 4, "part-of", "task_part_of_field", false, false], [10, 12, 2, 4, "part-of", "task_part_of_field", false, false], [14, 16, 2, 4, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Challenges", "in", "natural", "language", "processing", "often", "include", "speech", "recognition", ",", "natural", "language", "understanding", "and", "natural", "language", "generation", "."], "sentence-detokenized": "Challenges in natural language processing often include speech recognition, natural language understanding and natural language generation.", "token2charspan": [[0, 10], [11, 13], [14, 21], [22, 30], [31, 41], [42, 47], [48, 55], [56, 62], [63, 74], [74, 75], [76, 83], [84, 92], [93, 106], [107, 110], [111, 118], [119, 127], [128, 138], [138, 139]]}
{"doc_key": "ai-dev-198", "ner": [[5, 5, "product"], [8, 10, "product"], [36, 37, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 8, 10, "part-of", "", false, false], [5, 5, 36, 37, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "such", "as", "Siri", "in", "the", "iOS", "operating", "system", ",", "use", "a", "pattern", "recognition", "technique", "similar", "to", "that", "used", "in", "text", "-", "based", "systems", ",", "but", "in", "the", "former", ",", "user", "input", "is", "via", "speech", "recognition", "."], "sentence-detokenized": "These systems, such as Siri in the iOS operating system, use a pattern recognition technique similar to that used in text-based systems, but in the former, user input is via speech recognition.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 22], [23, 27], [28, 30], [31, 34], [35, 38], [39, 48], [49, 55], [55, 56], [57, 60], [61, 62], [63, 70], [71, 82], [83, 92], [93, 100], [101, 103], [104, 108], [109, 113], [114, 116], [117, 121], [121, 122], [122, 127], [128, 135], [135, 136], [137, 140], [141, 143], [144, 147], [148, 154], [154, 155], [156, 160], [161, 166], [167, 169], [170, 173], [174, 180], [181, 192], [192, 193]]}
{"doc_key": "ai-dev-199", "ner": [[1, 4, "algorithm"], [16, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 4, 16, 17, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["More", "exotic", "fitness", "functions", "that", "examine", "the", "granularity", "of", "the", "model", "include", "the", "area", "under", "the", "ROC", "curve", "and", "the", "rank", "measure", "."], "sentence-detokenized": "More exotic fitness functions that examine the granularity of the model include the area under the ROC curve and the rank measure.", "token2charspan": [[0, 4], [5, 11], [12, 19], [20, 29], [30, 34], [35, 42], [43, 46], [47, 58], [59, 61], [62, 65], [66, 71], [72, 79], [80, 83], [84, 88], [89, 94], [95, 98], [99, 102], [103, 108], [109, 112], [113, 116], [117, 121], [122, 129], [129, 130]]}
{"doc_key": "ai-dev-200", "ner": [[2, 3, "product"], [7, 12, "researcher"], [16, 18, "product"], [23, 26, "organisation"], [28, 28, "organisation"], [37, 41, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 7, 12, "origin", "", false, false], [7, 12, 23, 26, "role", "", false, false], [16, 18, 7, 12, "origin", "", false, false], [28, 28, 23, 26, "named", "", false, false], [37, 41, 23, 26, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "term", "Semantic", "Web", "was", "coined", "by", "Tim", "Berners", "-", "Lee", ",", "the", "inventor", "of", "the", "World", "Wide", "Web", "and", "director", "of", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "which", "oversees", "the", "development", "of", "proposed", "standards", "for", "the", "Semantic", "Web", "."], "sentence-detokenized": "The term Semantic Web was coined by Tim Berners-Lee, the inventor of the World Wide Web and director of the World Wide Web Consortium (W3C), which oversees the development of proposed standards for the Semantic Web.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 25], [26, 32], [33, 35], [36, 39], [40, 47], [47, 48], [48, 51], [51, 52], [53, 56], [57, 65], [66, 68], [69, 72], [73, 78], [79, 83], [84, 87], [88, 91], [92, 100], [101, 103], [104, 107], [108, 113], [114, 118], [119, 122], [123, 133], [134, 135], [135, 138], [138, 139], [139, 140], [141, 146], [147, 155], [156, 159], [160, 171], [172, 174], [175, 183], [184, 193], [194, 197], [198, 201], [202, 210], [211, 214], [214, 215]]}
{"doc_key": "ai-dev-201", "ner": [[0, 1, "task"], [7, 7, "task"], [14, 17, "product"], [19, 23, "product"], [25, 25, "product"], [28, 32, "product"], [36, 37, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 14, 17, "opposite", "", false, false], [0, 1, 19, 23, "opposite", "", false, false], [0, 1, 28, 32, "opposite", "", false, false], [0, 1, 36, 37, "part-of", "", false, false], [7, 7, 0, 1, "named", "", false, false], [25, 25, 19, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Machine", "translation", ",", "sometimes", "referred", "to", "as", "MT", "(", "not", "to", "be", "confused", "with", "computer", "-", "aided", "translation", ",", "machine", "-", "aided", "human", "translation", "(", "MAHT", ")", "or", "interactive", "translation", ")", ",", "is", "a", "subfield", "of", "computational", "linguistics", "that", "examines", "the", "use", "of", "software", "to", "translate", "text", "or", "speech", "from", "one", "language", "into", "another", "."], "sentence-detokenized": "Machine translation, sometimes referred to as MT (not to be confused with computer-aided translation, machine-aided human translation (MAHT) or interactive translation), is a subfield of computational linguistics that examines the use of software to translate text or speech from one language into another.", "token2charspan": [[0, 7], [8, 19], [19, 20], [21, 30], [31, 39], [40, 42], [43, 45], [46, 48], [49, 50], [50, 53], [54, 56], [57, 59], [60, 68], [69, 73], [74, 82], [82, 83], [83, 88], [89, 100], [100, 101], [102, 109], [109, 110], [110, 115], [116, 121], [122, 133], [134, 135], [135, 139], [139, 140], [141, 143], [144, 155], [156, 167], [167, 168], [168, 169], [170, 172], [173, 174], [175, 183], [184, 186], [187, 200], [201, 212], [213, 217], [218, 226], [227, 230], [231, 234], [235, 237], [238, 246], [247, 249], [250, 259], [260, 264], [265, 267], [268, 274], [275, 279], [280, 283], [284, 292], [293, 297], [298, 305], [305, 306]]}
{"doc_key": "ai-dev-202", "ner": [[1, 3, "product"], [8, 8, "university"], [13, 14, "researcher"], [16, 17, "researcher"], [39, 41, "location"], [43, 43, "location"], [47, 50, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 3, 13, 14, "artifact", "", false, false], [1, 3, 16, 17, "artifact", "", false, false], [13, 14, 8, 8, "physical", "", false, false], [13, 14, 8, 8, "role", "", false, false], [16, 17, 8, 8, "physical", "", false, false], [16, 17, 8, 8, "role", "", false, false], [39, 41, 43, 43, "physical", "", false, false], [47, 50, 39, 41, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Early", "interlingual", "MT", "systems", "were", "also", "built", "at", "Stanford", "in", "the", "1970s", "by", "Roger", "Schank", "and", "Yorick", "Wilks", ";", "the", "former", "became", "the", "basis", "for", "a", "commercial", "money", "transfer", "system", ",", "and", "the", "latter", "'s", "code", "is", "preserved", "at", "The", "Computer", "Museum", "in", "Boston", "as", "the", "first", "interlingual", "machine", "translation", "system", "."], "sentence-detokenized": "Early interlingual MT systems were also built at Stanford in the 1970s by Roger Schank and Yorick Wilks; the former became the basis for a commercial money transfer system, and the latter's code is preserved at The Computer Museum in Boston as the first interlingual machine translation system.", "token2charspan": [[0, 5], [6, 18], [19, 21], [22, 29], [30, 34], [35, 39], [40, 45], [46, 48], [49, 57], [58, 60], [61, 64], [65, 70], [71, 73], [74, 79], [80, 86], [87, 90], [91, 97], [98, 103], [103, 104], [105, 108], [109, 115], [116, 122], [123, 126], [127, 132], [133, 136], [137, 138], [139, 149], [150, 155], [156, 164], [165, 171], [171, 172], [173, 176], [177, 180], [181, 187], [187, 189], [190, 194], [195, 197], [198, 207], [208, 210], [211, 214], [215, 223], [224, 230], [231, 233], [234, 240], [241, 243], [244, 247], [248, 253], [254, 266], [267, 274], [275, 286], [287, 293], [293, 294]]}
{"doc_key": "ai-dev-203", "ner": [[0, 1, "researcher"], [8, 12, "conference"], [14, 15, "conference"], [22, 27, "conference"], [29, 30, "conference"], [36, 39, "organisation"], [48, 48, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 8, 12, "role", "", false, false], [0, 1, 22, 27, "role", "", false, false], [0, 1, 36, 39, "role", "", false, false], [0, 1, 48, 48, "role", "", false, false], [14, 15, 8, 12, "named", "", false, false], [29, 30, 22, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sycara", "has", "served", "as", "Program", "Chair", "of", "the", "Second", "International", "Semantic", "Web", "Conference", "(", "ISWC", "2003", ")", ",", "General", "Chair", "of", "the", "Second", "International", "Conference", "on", "Autonomous", "Agents", "(", "Agents", "98", ")", ",", "Chair", "of", "the", "Agents", "Conference", "Steering", "Committee", "(", "1999-2001", ")", ",", "and", "Chair", "of", "the", "AAAI", "Fellowship", "(", "1993-1999", ")", ";"], "sentence-detokenized": "Sycara has served as Program Chair of the Second International Semantic Web Conference (ISWC 2003), General Chair of the Second International Conference on Autonomous Agents (Agents 98), Chair of the Agents Conference Steering Committee (1999-2001), and Chair of the AAAI Fellowship (1993-1999);", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 20], [21, 28], [29, 34], [35, 37], [38, 41], [42, 48], [49, 62], [63, 71], [72, 75], [76, 86], [87, 88], [88, 92], [93, 97], [97, 98], [98, 99], [100, 107], [108, 113], [114, 116], [117, 120], [121, 127], [128, 141], [142, 152], [153, 155], [156, 166], [167, 173], [174, 175], [175, 181], [182, 184], [184, 185], [185, 186], [187, 192], [193, 195], [196, 199], [200, 206], [207, 217], [218, 226], [227, 236], [237, 238], [238, 247], [247, 248], [248, 249], [250, 253], [254, 259], [260, 262], [263, 266], [267, 271], [272, 282], [283, 284], [284, 293], [293, 294], [294, 295]]}
{"doc_key": "ai-dev-204", "ner": [[11, 11, "conference"], [13, 16, "conference"], [18, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 16, 11, 11, "named", "", false, false], [18, 20, 11, 11, "part-of", "", false, false], [18, 20, 11, 11, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2016", ",", "she", "was", "selected", "as", "the", "winner", "of", "the", "ACL", "(", "Association", "for", "Computational", "Linguistics", ")", "Lifetime", "Achievement", "Award", "."], "sentence-detokenized": "In 2016, she was selected as the winner of the ACL (Association for Computational Linguistics) Lifetime Achievement Award.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 25], [26, 28], [29, 32], [33, 39], [40, 42], [43, 46], [47, 50], [51, 52], [52, 63], [64, 67], [68, 81], [82, 93], [93, 94], [95, 103], [104, 115], [116, 121], [121, 122]]}
{"doc_key": "ai-dev-205", "ner": [[0, 1, "researcher"], [3, 5, "researcher"], [7, 8, "researcher"], [11, 12, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", ",", "Y", ".", "Bengio", ",", "P.", "Frasconi", ",", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Sepp Hochreiter, Y. Bengio, P. Frasconi, and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 15], [15, 16], [17, 18], [18, 19], [20, 26], [26, 27], [28, 30], [31, 39], [39, 40], [41, 44], [45, 51], [52, 63], [63, 64]]}
{"doc_key": "ai-dev-206", "ner": [[3, 3, "product"], [6, 7, "misc"], [9, 11, "programlang"], [19, 23, "product"], [36, 36, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 9, 11, "usage", "", false, false], [9, 11, 6, 7, "type-of", "", false, false], [9, 11, 19, 23, "related-to", "", false, false], [36, 36, 3, 3, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["For", "example", ",", "A.L.I.C.E.", "uses", "a", "markup", "language", "called", "AIML", ",", "which", "is", "specific", "to", "its", "function", "as", "a", "dialogue", "system", ",", "and", "which", "has", "since", "been", "adopted", "by", "various", "other", "developers", "of", "so", "-", "called", "Alicebots", "."], "sentence-detokenized": "For example, A.L.I.C.E. uses a markup language called AIML, which is specific to its function as a dialogue system, and which has since been adopted by various other developers of so-called Alicebots.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 23], [24, 28], [29, 30], [31, 37], [38, 46], [47, 53], [54, 58], [58, 59], [60, 65], [66, 68], [69, 77], [78, 80], [81, 84], [85, 93], [94, 96], [97, 98], [99, 107], [108, 114], [114, 115], [116, 119], [120, 125], [126, 129], [130, 135], [136, 140], [141, 148], [149, 151], [152, 159], [160, 165], [166, 176], [177, 179], [180, 182], [182, 183], [183, 189], [190, 199], [199, 200]]}
{"doc_key": "ai-dev-207", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2000", ",", "she", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2000, she was elected a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 24], [25, 26], [27, 33], [34, 36], [37, 40], [41, 52], [53, 56], [57, 60], [61, 72], [73, 75], [76, 86], [87, 99], [99, 100]]}
{"doc_key": "ai-dev-208", "ner": [[0, 2, "misc"], [4, 4, "misc"], [10, 15, "misc"], [24, 25, "algorithm"], [34, 35, "field"], [37, 38, "field"], [41, 42, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 10, 15, "type-of", "", false, false], [0, 2, 34, 35, "related-to", "performs", true, false], [0, 2, 37, 38, "related-to", "performs", true, false], [0, 2, 41, 42, "related-to", "performs", true, false], [4, 4, 0, 2, "named", "", false, false], [24, 25, 10, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Learning", "classifier", "systems", "(", "LCS", ")", "are", "a", "family", "of", "rule", "-", "based", "machine", "learning", "algorithms", "that", "combine", "a", "discovery", "component", ",", "typically", "a", "genetic", "algorithm", ",", "with", "a", "learning", "component", "that", "performs", "either", "supervised", "learning", ",", "reinforced", "learning", ",", "or", "unsupervised", "learning", "."], "sentence-detokenized": "Learning classifier systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, typically a genetic algorithm, with a learning component that performs either supervised learning, reinforced learning, or unsupervised learning.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 29], [29, 32], [32, 33], [34, 37], [38, 39], [40, 46], [47, 49], [50, 54], [54, 55], [55, 60], [61, 68], [69, 77], [78, 88], [89, 93], [94, 101], [102, 103], [104, 113], [114, 123], [123, 124], [125, 134], [135, 136], [137, 144], [145, 154], [154, 155], [156, 160], [161, 162], [163, 171], [172, 181], [182, 186], [187, 195], [196, 202], [203, 213], [214, 222], [222, 223], [224, 234], [235, 243], [243, 244], [245, 247], [248, 260], [261, 269], [269, 270]]}
{"doc_key": "ai-dev-209", "ner": [[14, 15, "algorithm"], [19, 19, "algorithm"], [27, 28, "algorithm"], [30, 31, "misc"], [41, 43, "algorithm"], [51, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 15, 27, 28, "origin", "", false, false], [14, 15, 30, 31, "usage", "", false, false], [19, 19, 14, 15, "named", "", false, false], [41, 43, 30, 31, "type-of", "", false, false], [41, 43, 51, 55, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "unknown", "parameters", "in", "each", "vector", "\u03b2subk", "/", "sub", "are", "typically", "jointly", "estimated", "using", "maximum", "a", "posteriori", "estimation", "(", "MAP", ")", ",", "which", "is", "an", "extension", "of", "maximum", "likelihood", "with", "adjustment", "of", "the", "weights", "to", "prevent", "pathological", "solutions", "(", "usually", "a", "squared", "adjustment", "function", ",", "which", "is", "equivalent", "to", "placing", "a", "Gaussian", "prior", "distribution", "with", "zero-mean", "on", "the", "weights", ",", "but", "other", "distributions", "are", "also", "possible", ")", "."], "sentence-detokenized": "The unknown parameters in each vector \u03b2subk/sub are typically jointly estimated using maximum a posteriori estimation (MAP), which is an extension of maximum likelihood with adjustment of the weights to prevent pathological solutions (usually a squared adjustment function, which is equivalent to placing a Gaussian prior distribution with zero-mean on the weights, but other distributions are also possible).", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 25], [26, 30], [31, 37], [38, 43], [43, 44], [44, 47], [48, 51], [52, 61], [62, 69], [70, 79], [80, 85], [86, 93], [94, 95], [96, 106], [107, 117], [118, 119], [119, 122], [122, 123], [123, 124], [125, 130], [131, 133], [134, 136], [137, 146], [147, 149], [150, 157], [158, 168], [169, 173], [174, 184], [185, 187], [188, 191], [192, 199], [200, 202], [203, 210], [211, 223], [224, 233], [234, 235], [235, 242], [243, 244], [245, 252], [253, 263], [264, 272], [272, 273], [274, 279], [280, 282], [283, 293], [294, 296], [297, 304], [305, 306], [307, 315], [316, 321], [322, 334], [335, 339], [340, 349], [350, 352], [353, 356], [357, 364], [364, 365], [366, 369], [370, 375], [376, 389], [390, 393], [394, 398], [399, 407], [407, 408], [408, 409]]}
{"doc_key": "ai-dev-210", "ner": [[10, 12, "researcher"], [13, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 13, 10, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "hierarchical", "structure", "of", "words", "has", "been", "explicitly", "mapped", "in", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "The hierarchical structure of words has been explicitly mapped in George Miller's Wordnet.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 29], [30, 35], [36, 39], [40, 44], [45, 55], [56, 62], [63, 65], [66, 72], [73, 79], [79, 81], [82, 89], [89, 90]]}
{"doc_key": "ai-dev-211", "ner": [[0, 8, "conference"], [19, 22, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 22, 0, 8, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "is", "an", "example", "of", "their", "capabilities", ";", "this", "is", "a", "benchmark", "in", "object", "classification", "and", "detection", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "The ImageNet Large Scale Visual Recognition Challenge is an example of their capabilities; this is a benchmark in object classification and detection with millions of images and hundreds of object classes.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 24], [25, 31], [32, 43], [44, 53], [54, 56], [57, 59], [60, 67], [68, 70], [71, 76], [77, 89], [89, 90], [91, 95], [96, 98], [99, 100], [101, 110], [111, 113], [114, 120], [121, 135], [136, 139], [140, 149], [150, 154], [155, 163], [164, 166], [167, 173], [174, 177], [178, 186], [187, 189], [190, 196], [197, 204], [204, 205]]}
{"doc_key": "ai-dev-212", "ner": [[1, 2, "misc"], [24, 24, "misc"], [26, 29, "person"], [31, 31, "misc"], [36, 38, "person"], [41, 43, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[24, 24, 1, 2, "general-affiliation", "", false, false], [31, 31, 1, 2, "general-affiliation", "", false, false], [31, 31, 26, 29, "artifact", "", false, false], [41, 43, 1, 2, "general-affiliation", "", false, false], [41, 43, 36, 38, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "science", "fiction", ",", "female", "-", "looking", "robots", "are", "often", "depicted", "for", "use", "as", "servants", "and", "sex", "slaves", ",", "as", "seen", "in", "the", "film", "Westworld", ",", "Paul", "J.", "McAuley", "'s", "novel", "Fairyland", "(", "1995", ")", "and", "Lester", "del", "Rey's", "short", "story", "Helen", "O'", "Loy", "(", "1938", ")", ",", "and", "sometimes", "as", "warriors", ",", "killers", "or", "workers", "."], "sentence-detokenized": "In science fiction, female-looking robots are often depicted for use as servants and sex slaves, as seen in the film Westworld, Paul J. McAuley's novel Fairyland (1995) and Lester del Rey's short story Helen O'Loy (1938), and sometimes as warriors, killers or workers.", "token2charspan": [[0, 2], [3, 10], [11, 18], [18, 19], [20, 26], [26, 27], [27, 34], [35, 41], [42, 45], [46, 51], [52, 60], [61, 64], [65, 68], [69, 71], [72, 80], [81, 84], [85, 88], [89, 95], [95, 96], [97, 99], [100, 104], [105, 107], [108, 111], [112, 116], [117, 126], [126, 127], [128, 132], [133, 135], [136, 143], [143, 145], [146, 151], [152, 161], [162, 163], [163, 167], [167, 168], [169, 172], [173, 179], [180, 183], [184, 189], [190, 195], [196, 201], [202, 207], [208, 210], [210, 213], [214, 215], [215, 219], [219, 220], [220, 221], [222, 225], [226, 235], [236, 238], [239, 247], [247, 248], [249, 256], [257, 259], [260, 267], [267, 268]]}
{"doc_key": "ai-dev-213", "ner": [[0, 1, "task"], [3, 4, "task"], [6, 7, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["answering", "questions", ",", "speech", "recognition", "and", "machine", "translation", "."], "sentence-detokenized": "answering questions, speech recognition and machine translation.", "token2charspan": [[0, 9], [10, 19], [19, 20], [21, 27], [28, 39], [40, 43], [44, 51], [52, 63], [63, 64]]}
{"doc_key": "ai-dev-214", "ner": [[5, 6, "researcher"], [8, 12, "organisation"], [14, 17, "location"], [19, 19, "location"], [21, 21, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 8, 12, "role", "", false, false], [8, 12, 14, 17, "physical", "", false, false], [14, 17, 19, 19, "physical", "", false, false], [19, 19, 21, 21, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "his", "seminal", "paper", ",", "Harry", "Blum", "of", "Air", "Force", "Cambridge", "Research", "Laboratories", "at", "Hanscom", "Air", "Force", "Base", "in", "Bedford", ",", "Massachusetts", ",", "defined", "a", "medial", "axis", "for", "calculating", "a", "skeleton", "of", "a", "shape", "using", "an", "intuitive", "model", "of", "fire", "spread", "in", "a", "grass", "field", "where", "the", "field", "has", "the", "given", "shape", "."], "sentence-detokenized": "In his seminal paper, Harry Blum of Air Force Cambridge Research Laboratories at Hanscom Air Force Base in Bedford, Massachusetts, defined a medial axis for calculating a skeleton of a shape using an intuitive model of fire spread in a grass field where the field has the given shape.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 20], [20, 21], [22, 27], [28, 32], [33, 35], [36, 39], [40, 45], [46, 55], [56, 64], [65, 77], [78, 80], [81, 88], [89, 92], [93, 98], [99, 103], [104, 106], [107, 114], [114, 115], [116, 129], [129, 130], [131, 138], [139, 140], [141, 147], [148, 152], [153, 156], [157, 168], [169, 170], [171, 179], [180, 182], [183, 184], [185, 190], [191, 196], [197, 199], [200, 209], [210, 215], [216, 218], [219, 223], [224, 230], [231, 233], [234, 235], [236, 241], [242, 247], [248, 253], [254, 257], [258, 263], [264, 267], [268, 271], [272, 277], [278, 283], [283, 284]]}
{"doc_key": "ai-dev-215", "ner": [[14, 14, "algorithm"], [16, 16, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 19, 20, "compare", "", false, false], [16, 16, 19, 20, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "unlike", "boosting", "algorithms", "that", "analytically", "minimize", "a", "convex", "loss", "function", "(", "e.g.", "AdaBoost", "and", "LogitBoost", ")", ",", "Brown", "Boost", "solves", "a", "system", "of", "two", "equations", "and", "two", "unknowns", "using", "standard", "numerical", "methods", "."], "sentence-detokenized": "However, unlike boosting algorithms that analytically minimize a convex loss function (e.g. AdaBoost and LogitBoost), BrownBoost solves a system of two equations and two unknowns using standard numerical methods.", "token2charspan": [[0, 7], [7, 8], [9, 15], [16, 24], [25, 35], [36, 40], [41, 53], [54, 62], [63, 64], [65, 71], [72, 76], [77, 85], [86, 87], [87, 91], [92, 100], [101, 104], [105, 115], [115, 116], [116, 117], [118, 123], [123, 128], [129, 135], [136, 137], [138, 144], [145, 147], [148, 151], [152, 161], [162, 165], [166, 169], [170, 178], [179, 184], [185, 193], [194, 203], [204, 211], [211, 212]]}
{"doc_key": "ai-dev-216", "ner": [[0, 0, "researcher"], [9, 11, "misc"], [18, 24, "conference"], [26, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 9, 11, "win-defeat", "", false, false], [0, 0, 18, 24, "role", "", false, false], [26, 26, 18, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Getoor", "has", "received", "several", "best", "paper", "awards", ",", "an", "NSF", "Career", "Award", "and", "is", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "Fellow", "."], "sentence-detokenized": "Getoor has received several best paper awards, an NSF Career Award and is a member of the Association for the Advancement of Artificial Intelligence (AAAI) Fellow.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 27], [28, 32], [33, 38], [39, 45], [45, 46], [47, 49], [50, 53], [54, 60], [61, 66], [67, 70], [71, 73], [74, 75], [76, 82], [83, 85], [86, 89], [90, 101], [102, 105], [106, 109], [110, 121], [122, 124], [125, 135], [136, 148], [149, 150], [150, 154], [154, 155], [156, 162], [162, 163]]}
{"doc_key": "ai-dev-217", "ner": [[0, 1, "misc"], [6, 10, "misc"], [15, 16, "misc"], [21, 25, "misc"], [30, 30, "misc"], [35, 39, "university"], [44, 52, "misc"], [57, 65, "misc"], [70, 74, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["ACM", "Fellow", "(", "2015", ")", "br", "Association", "for", "Computational", "Linguistics", "Fellow", "(", "2011", ")", "br", "AAAI", "Fellow", "(", "1994", ")", "br", "International", "Speech", "Communication", "Association", "Fellow", "(", "2011", ")", "br", "\u00c6resdoktorat", "(", "Honorary", "Doctorate", ")", "KTH", "Royal", "Institute", "of", "Technology", "(", "2007", ")", "br", "Columbia", "Engineering", "School", "Alumni", "Association", "Distinguished", "Faculty", "Teaching", "award", "(", "2009", ")", "br", "IEEE", "James", "L.", "Flanagan", "Speech", "and", "Audio", "Processing", "Award", "(", "2011", ")", "br", "ISCA", "Medal", "for", "Scientific", "Achievement", "(", "2011", ")"], "sentence-detokenized": "ACM Fellow (2015) br Association for Computational Linguistics Fellow (2011) br AAAI Fellow (1994) br International Speech Communication Association Fellow (2011) br \u00c6resdoktorat (Honorary Doctorate) KTH Royal Institute of Technology (2007) br Columbia Engineering School Alumni Association Distinguished Faculty Teaching award (2009) br IEEE James L. Flanagan Speech and Audio Processing Award (2011) br ISCA Medal for Scientific Achievement (2011)", "token2charspan": [[0, 3], [4, 10], [11, 12], [12, 16], [16, 17], [18, 20], [21, 32], [33, 36], [37, 50], [51, 62], [63, 69], [70, 71], [71, 75], [75, 76], [77, 79], [80, 84], [85, 91], [92, 93], [93, 97], [97, 98], [99, 101], [102, 115], [116, 122], [123, 136], [137, 148], [149, 155], [156, 157], [157, 161], [161, 162], [163, 165], [166, 178], [179, 180], [180, 188], [189, 198], [198, 199], [200, 203], [204, 209], [210, 219], [220, 222], [223, 233], [234, 235], [235, 239], [239, 240], [241, 243], [244, 252], [253, 264], [265, 271], [272, 278], [279, 290], [291, 304], [305, 312], [313, 321], [322, 327], [328, 329], [329, 333], [333, 334], [335, 337], [338, 342], [343, 348], [349, 351], [352, 360], [361, 367], [368, 371], [372, 377], [378, 388], [389, 394], [395, 396], [396, 400], [400, 401], [402, 404], [405, 409], [410, 415], [416, 419], [420, 430], [431, 442], [443, 444], [444, 448], [448, 449]]}
{"doc_key": "ai-dev-218", "ner": [[6, 6, "university"], [15, 18, "task"], [28, 29, "metrics"], [43, 45, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[28, 29, 43, 45, "opposite", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["A", "frustrating", "result", "of", "the", "same", "Stanford", "study", "(", "and", "other", "attempts", "to", "improve", "the", "translation", "of", "name", "recognition", ")", "is", "that", "many", "times", "a", "decrease", "in", "the", "bilingual", "evaluation", "score", "for", "translation", "will", "be", "the", "result", "of", "the", "inclusion", "of", "methods", "for", "translating", "named", "entities", "."], "sentence-detokenized": "A frustrating result of the same Stanford study (and other attempts to improve the translation of name recognition) is that many times a decrease in the bilingual evaluation score for translation will be the result of the inclusion of methods for translating named entities.", "token2charspan": [[0, 1], [2, 13], [14, 20], [21, 23], [24, 27], [28, 32], [33, 41], [42, 47], [48, 49], [49, 52], [53, 58], [59, 67], [68, 70], [71, 78], [79, 82], [83, 94], [95, 97], [98, 102], [103, 114], [114, 115], [116, 118], [119, 123], [124, 128], [129, 134], [135, 136], [137, 145], [146, 148], [149, 152], [153, 162], [163, 173], [174, 179], [180, 183], [184, 195], [196, 200], [201, 203], [204, 207], [208, 214], [215, 217], [218, 221], [222, 231], [232, 234], [235, 242], [243, 246], [247, 258], [259, 264], [265, 273], [273, 274]]}
{"doc_key": "ai-dev-219", "ner": [[0, 0, "organisation"], [11, 13, "organisation"], [15, 20, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 13, "role", "works_with", false, false], [0, 0, 15, 20, "role", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Medtronic", "uses", "the", "collected", "PM", "data", "and", "collaborates", "with", "researchers", "at", "Johns", "Hopkins", "Hospital", "and", "Washington", "University", "School", "of", "Medicine", "to", "help", "answer", "specific", "questions", "about", "heart", "disease", ",", "such", "as", "whether", "weak", "hearts", "cause", "arrhythmias", "or", "vice", "versa", "."], "sentence-detokenized": "Medtronic uses the collected PM data and collaborates with researchers at Johns Hopkins Hospital and Washington University School of Medicine to help answer specific questions about heart disease, such as whether weak hearts cause arrhythmias or vice versa.", "token2charspan": [[0, 9], [10, 14], [15, 18], [19, 28], [29, 31], [32, 36], [37, 40], [41, 53], [54, 58], [59, 70], [71, 73], [74, 79], [80, 87], [88, 96], [97, 100], [101, 111], [112, 122], [123, 129], [130, 132], [133, 141], [142, 144], [145, 149], [150, 156], [157, 165], [166, 175], [176, 181], [182, 187], [188, 195], [195, 196], [197, 201], [202, 204], [205, 212], [213, 217], [218, 224], [225, 230], [231, 242], [243, 245], [246, 250], [251, 256], [256, 257]]}
{"doc_key": "ai-dev-220", "ner": [[4, 5, "organisation"], [10, 10, "misc"], [13, 14, "person"], [16, 17, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 4, 5, "artifact", "made_by_studio", false, false], [13, 14, 10, 10, "role", "", false, false], [16, 17, 10, 10, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "was", "followed", "by", "Paramount", "'s", "first", "feature", "film", ",", "Sangaree", ",", "starring", "Fernando", "Lamas", "and", "Arlene", "Dahl", "."], "sentence-detokenized": "This was followed by Paramount's first feature film, Sangaree, starring Fernando Lamas and Arlene Dahl.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 20], [21, 30], [30, 32], [33, 38], [39, 46], [47, 51], [51, 52], [53, 61], [61, 62], [63, 71], [72, 80], [81, 86], [87, 90], [91, 97], [98, 102], [102, 103]]}
{"doc_key": "ai-dev-221", "ner": [[0, 1, "programlang"], [8, 10, "researcher"], [12, 13, "researcher"], [17, 18, "organisation"], [20, 21, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 8, 10, "origin", "", false, false], [0, 1, 12, 13, "origin", "", false, false], [8, 10, 17, 18, "physical", "", false, false], [8, 10, 17, 18, "role", "", false, false], [12, 13, 20, 21, "physical", "", false, false], [12, 13, 20, 21, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["KRL", "is", "a", "knowledge", "representation", "language", "developed", "by", "Daniel", "G.", "Bobrow", "and", "Terry", "Winograd", "while", "working", "at", "Xerox", "PARC", "and", "Stanford", "University", ",", "respectively", "."], "sentence-detokenized": "KRL is a knowledge representation language developed by Daniel G. Bobrow and Terry Winograd while working at Xerox PARC and Stanford University, respectively.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 18], [19, 33], [34, 42], [43, 52], [53, 55], [56, 62], [63, 65], [66, 72], [73, 76], [77, 82], [83, 91], [92, 97], [98, 105], [106, 108], [109, 114], [115, 119], [120, 123], [124, 132], [133, 143], [143, 144], [145, 157], [157, 158]]}
{"doc_key": "ai-dev-222", "ner": [[2, 9, "conference"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"], [31, 34, "task"], [38, 40, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 9, 31, 34, "topic", "", true, false], [13, 14, 2, 9, "physical", "", false, false], [13, 14, 2, 9, "role", "", false, false], [13, 14, 2, 9, "temporal", "", false, false], [16, 17, 2, 9, "physical", "", false, false], [16, 17, 2, 9, "role", "", false, false], [16, 17, 2, 9, "temporal", "", false, false], [19, 20, 2, 9, "physical", "", false, false], [19, 20, 2, 9, "role", "", false, false], [19, 20, 2, 9, "temporal", "", false, false], [22, 25, 2, 9, "physical", "", false, false], [22, 25, 2, 9, "role", "", false, false], [22, 25, 2, 9, "temporal", "", false, false], [31, 34, 38, 40, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["At", "the", "IEEE", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "in", "2006", ",", "Qiang", "Zhu", ",", "Shai", "Avidan", ",", "Mei-Chen", "Yeh", "and", "Kwang", "-", "Ting", "Cheng", "presented", "an", "algorithm", "that", "enables", "human", "detection", "to", "be", "significantly", "accelerated", "using", "HOG", "descriptor", "methods", "."], "sentence-detokenized": "At the IEEE Conference on Computer Vision and Pattern Recognition in 2006, Qiang Zhu, Shai Avidan, Mei-Chen Yeh and Kwang-Ting Cheng presented an algorithm that enables human detection to be significantly accelerated using HOG descriptor methods.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 22], [23, 25], [26, 34], [35, 41], [42, 45], [46, 53], [54, 65], [66, 68], [69, 73], [73, 74], [75, 80], [81, 84], [84, 85], [86, 90], [91, 97], [97, 98], [99, 107], [108, 111], [112, 115], [116, 121], [121, 122], [122, 126], [127, 132], [133, 142], [143, 145], [146, 155], [156, 160], [161, 168], [169, 174], [175, 184], [185, 187], [188, 190], [191, 204], [205, 216], [217, 222], [223, 226], [227, 237], [238, 245], [245, 246]]}
{"doc_key": "ai-dev-223", "ner": [[0, 1, "researcher"], [5, 5, "conference"], [8, 10, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 5, 5, "role", "", false, false], [0, 1, 8, 10, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hayes", "is", "a", "member", "of", "AAAI", "and", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Hayes is a member of AAAI and the Cognitive Science Society.", "token2charspan": [[0, 5], [6, 8], [9, 10], [11, 17], [18, 20], [21, 25], [26, 29], [30, 33], [34, 43], [44, 51], [52, 59], [59, 60]]}
{"doc_key": "ai-dev-224", "ner": [[0, 1, "misc"], [5, 5, "field"], [7, 8, "field"], [10, 11, "field"], [13, 13, "field"], [15, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 32, "field"], [38, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[0, 1, 5, 5, "part-of", "", false, false], [0, 1, 5, 5, "usage", "", false, false], [0, 1, 7, 8, "part-of", "", false, false], [0, 1, 7, 8, "usage", "", false, false], [0, 1, 10, 11, "part-of", "", false, false], [0, 1, 10, 11, "usage", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [0, 1, 13, 13, "usage", "", false, false], [0, 1, 15, 16, "part-of", "", false, false], [0, 1, 15, 16, "usage", "", false, false], [0, 1, 18, 19, "part-of", "", false, false], [0, 1, 18, 19, "usage", "", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 21, 22, "usage", "", false, false], [0, 1, 24, 24, "part-of", "", false, false], [0, 1, 24, 24, "usage", "", false, false], [0, 1, 26, 27, "part-of", "", false, false], [0, 1, 26, 27, "usage", "", false, false], [0, 1, 29, 29, "part-of", "", false, false], [0, 1, 29, 29, "usage", "", false, false], [0, 1, 31, 32, "part-of", "", false, false], [0, 1, 31, 32, "usage", "", false, false], [0, 1, 38, 39, "part-of", "", false, false], [0, 1, 38, 39, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "sentence": ["Time", "series", "are", "used", "in", "statistics", ",", "signal", "processing", ",", "pattern", "recognition", ",", "econometrics", ",", "mathematical", "finance", ",", "weather", "forecasting", ",", "earthquake", "prediction", ",", "electroencephalography", ",", "control", "engineering", ",", "astronomy", ",", "communications", "engineering", "and", "virtually", "all", "areas", "of", "applied", "science", "and", "engineering", "that", "involve", "temporal", "measurements", "."], "sentence-detokenized": "Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, earthquake prediction, electroencephalography, control engineering, astronomy, communications engineering and virtually all areas of applied science and engineering that involve temporal measurements.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 23], [24, 34], [34, 35], [36, 42], [43, 53], [53, 54], [55, 62], [63, 74], [74, 75], [76, 88], [88, 89], [90, 102], [103, 110], [110, 111], [112, 119], [120, 131], [131, 132], [133, 143], [144, 154], [154, 155], [156, 178], [178, 179], [180, 187], [188, 199], [199, 200], [201, 210], [210, 211], [212, 226], [227, 238], [239, 242], [243, 252], [253, 256], [257, 262], [263, 265], [266, 273], [274, 281], [282, 285], [286, 297], [298, 302], [303, 310], [311, 319], [320, 332], [332, 333]]}
{"doc_key": "ai-dev-225", "ner": [[13, 14, "metrics"], [36, 38, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "principle", ",", "exact", "recovery", "can", "be", "solved", "within", "the", "feasible", "range", "using", "maximum", "likelihood", ",", "but", "this", "is", "equivalent", "to", "solving", "a", "constrained", "or", "regularized", "intersection", "problem", "such", "as", "minimum", "bisection", ",", "which", "is", "typically", "NP", "-", "complete", "."], "sentence-detokenized": "In principle, exact recovery can be solved within the feasible range using maximum likelihood, but this is equivalent to solving a constrained or regularized intersection problem such as minimum bisection, which is typically NP-complete.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 19], [20, 28], [29, 32], [33, 35], [36, 42], [43, 49], [50, 53], [54, 62], [63, 68], [69, 74], [75, 82], [83, 93], [93, 94], [95, 98], [99, 103], [104, 106], [107, 117], [118, 120], [121, 128], [129, 130], [131, 142], [143, 145], [146, 157], [158, 170], [171, 178], [179, 183], [184, 186], [187, 194], [195, 204], [204, 205], [206, 211], [212, 214], [215, 224], [225, 227], [227, 228], [228, 236], [236, 237]]}
{"doc_key": "ai-dev-226", "ner": [[4, 8, "task"], [13, 13, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 13, 4, 8, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["in", "their", "work", "on", "pedestrian", "detection", ",", "which", "was", "first", "described", "at", "the", "BMVC", "in", "2009", "."], "sentence-detokenized": "in their work on pedestrian detection, which was first described at the BMVC in 2009.", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 16], [17, 27], [28, 37], [37, 38], [39, 44], [45, 48], [49, 54], [55, 64], [65, 67], [68, 71], [72, 76], [77, 79], [80, 84], [84, 85]]}
{"doc_key": "ai-dev-227", "ner": [[5, 9, "conference"], [11, 11, "researcher"], [15, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 5, 9, "physical", "", false, false], [11, 11, 5, 9, "role", "", false, false], [11, 11, 15, 22, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2007", ",", "at", "the", "International", "Conference", "on", "Computer", "Vision", ",", "Terzopoulos", "was", "awarded", "the", "first", "IEEE", "PAMI", "Computer", "Vision", "Distinguished", "Researcher", "Award", "for", "pioneering", "and", "sustained", "research", "into", "deformable", "models", "and", "their", "applications", "."], "sentence-detokenized": "In 2007, at the International Conference on Computer Vision, Terzopoulos was awarded the first IEEE PAMI Computer Vision Distinguished Researcher Award for pioneering and sustained research into deformable models and their applications.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 29], [30, 40], [41, 43], [44, 52], [53, 59], [59, 60], [61, 72], [73, 76], [77, 84], [85, 88], [89, 94], [95, 99], [100, 104], [105, 113], [114, 120], [121, 134], [135, 145], [146, 151], [152, 155], [156, 166], [167, 170], [171, 180], [181, 189], [190, 194], [195, 205], [206, 212], [213, 216], [217, 222], [223, 235], [235, 236]]}
{"doc_key": "ai-dev-228", "ner": [[0, 1, "task"], [3, 4, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 3, 4, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cluster", "analysis", "or", "cluster", "analysis", "involves", "assigning", "data", "points", "to", "clusters", "so", "that", "elements", "in", "the", "same", "cluster", "are", "as", "similar", "as", "possible", ",", "while", "elements", "belonging", "to", "different", "clusters", "are", "as", "different", "as", "possible", "."], "sentence-detokenized": "Cluster analysis or cluster analysis involves assigning data points to clusters so that elements in the same cluster are as similar as possible, while elements belonging to different clusters are as different as possible.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 36], [37, 45], [46, 55], [56, 60], [61, 67], [68, 70], [71, 79], [80, 82], [83, 87], [88, 96], [97, 99], [100, 103], [104, 108], [109, 116], [117, 120], [121, 123], [124, 131], [132, 134], [135, 143], [143, 144], [145, 150], [151, 159], [160, 169], [170, 172], [173, 182], [183, 191], [192, 195], [196, 198], [199, 208], [209, 211], [212, 220], [220, 221]]}
{"doc_key": "ai-dev-229", "ner": [[10, 11, "field"], [14, 15, "field"], [17, 18, "task"], [20, 21, "field"], [23, 25, "field"], [27, 28, "field"], [30, 31, "field"], [33, 34, "task"], [36, 36, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[10, 11, 14, 15, "named", "", false, false], [10, 11, 20, 21, "named", "", false, false], [10, 11, 27, 28, "named", "", false, false], [17, 18, 14, 15, "part-of", "task_part_of_field", false, false], [23, 25, 20, 21, "part-of", "", false, false], [30, 31, 27, 28, "part-of", "", false, false], [33, 34, 30, 31, "part-of", "", false, false], [36, 36, 30, 31, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["(", "2005", ")", "we", "can", "distinguish", "three", "different", "perspectives", "on", "text", "mining", ",", "namely", "text", "mining", "as", "information", "extraction", ",", "text", "mining", "as", "text", "data", "mining", "and", "text", "mining", "as", "data", "mining", "(", "Knowledge", "Discovery", "in", "Databases", ")", ".", "Hotho", ",", "A.", ",", "N\u00fcrnberger", ",", "A.", "and", "Paa\u00df", ",", "G.", "(", "2005", ")", "."], "sentence-detokenized": "(2005) we can distinguish three different perspectives on text mining, namely text mining as information extraction, text mining as text data mining and text mining as data mining (Knowledge Discovery in Databases).Hotho, A., N\u00fcrnberger, A. and Paa\u00df, G. (2005).", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 9], [10, 13], [14, 25], [26, 31], [32, 41], [42, 54], [55, 57], [58, 62], [63, 69], [69, 70], [71, 77], [78, 82], [83, 89], [90, 92], [93, 104], [105, 115], [115, 116], [117, 121], [122, 128], [129, 131], [132, 136], [137, 141], [142, 148], [149, 152], [153, 157], [158, 164], [165, 167], [168, 172], [173, 179], [180, 181], [181, 190], [191, 200], [201, 203], [204, 213], [213, 214], [214, 215], [215, 220], [220, 221], [222, 224], [224, 225], [226, 236], [236, 237], [238, 240], [241, 244], [245, 249], [249, 250], [251, 253], [254, 255], [255, 259], [259, 260], [260, 261]]}
{"doc_key": "ai-dev-230", "ner": [[0, 2, "product"], [15, 20, "location"], [22, 22, "location"], [24, 24, "location"], [34, 35, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 15, 20, "related-to", "developed_for", false, false], [15, 20, 22, 22, "physical", "", false, false], [22, 22, 24, 24, "physical", "", false, false], [34, 35, 0, 2, "role", "buys", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Rancho", "Arm", "was", "developed", "as", "a", "robotic", "arm", "to", "assist", "disabled", "patients", "at", "the", "Rancho", "Los", "Amigos", "National", "Rehabilitation", "Center", "in", "Downey", ",", "California", ";", "this", "computer", "-", "controlled", "arm", "was", "purchased", "by", "Stanford", "University", "in", "1963", "."], "sentence-detokenized": "The Rancho Arm was developed as a robotic arm to assist disabled patients at the Rancho Los Amigos National Rehabilitation Center in Downey, California; this computer-controlled arm was purchased by Stanford University in 1963.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 18], [19, 28], [29, 31], [32, 33], [34, 41], [42, 45], [46, 48], [49, 55], [56, 64], [65, 73], [74, 76], [77, 80], [81, 87], [88, 91], [92, 98], [99, 107], [108, 122], [123, 129], [130, 132], [133, 139], [139, 140], [141, 151], [151, 152], [153, 157], [158, 166], [166, 167], [167, 177], [178, 181], [182, 185], [186, 195], [196, 198], [199, 207], [208, 218], [219, 221], [222, 226], [226, 227]]}
{"doc_key": "ai-dev-231", "ner": [[1, 1, "university"], [3, 3, "researcher"], [7, 10, "organisation"], [19, 21, "organisation"], [25, 26, "researcher"], [28, 30, "researcher"], [43, 43, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 1, 1, "physical", "", false, false], [3, 3, 1, 1, "role", "", false, false], [3, 3, 7, 10, "role", "founder", false, false], [3, 3, 19, 21, "role", "founder", false, false], [19, 21, 43, 43, "physical", "", false, false], [25, 26, 19, 21, "role", "founder", false, false], [28, 30, 19, 21, "role", "founder", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["At", "UCSD", ",", "Norman", "helped", "found", "the", "Institute", "for", "Cognitive", "Science", "and", "was", "one", "of", "the", "organizers", "of", "the", "Cognitive", "Science", "Society", "(", "along", "with", "Roger", "Schank", ",", "Allan", "M.", "Collins", "and", "others", ")", ",", "which", "held", "it", "s", "first", "meeting", "on", "the", "UCSD", "campus", "in", "1979", "."], "sentence-detokenized": "At UCSD, Norman helped found the Institute for Cognitive Science and was one of the organizers of the Cognitive Science Society (along with Roger Schank, Allan M. Collins and others), which held its first meeting on the UCSD campus in 1979.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 22], [23, 28], [29, 32], [33, 42], [43, 46], [47, 56], [57, 64], [65, 68], [69, 72], [73, 76], [77, 79], [80, 83], [84, 94], [95, 97], [98, 101], [102, 111], [112, 119], [120, 127], [128, 129], [129, 134], [135, 139], [140, 145], [146, 152], [152, 153], [154, 159], [160, 162], [163, 170], [171, 174], [175, 181], [181, 182], [182, 183], [184, 189], [190, 194], [195, 197], [197, 198], [199, 204], [205, 212], [213, 215], [216, 219], [220, 224], [225, 231], [232, 234], [235, 239], [239, 240]]}
{"doc_key": "ai-dev-232", "ner": [[7, 8, "product"], [10, 11, "product"], [13, 14, "product"], [16, 18, "product"], [20, 21, "product"], [23, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 21, 16, 18, "type-of", "", false, false], [23, 28, 16, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "commonly", "used", "robot", "configurations", "are", "articulated", "robots", ",", "SCARA", "robots", ",", "delta", "robots", "and", "Cartesian", "coordinate", "robots", "(", "gantry", "robots", "or", "x", "-", "y", "-", "z", "robots", ")", "."], "sentence-detokenized": "The most commonly used robot configurations are articulated robots, SCARA robots, delta robots and Cartesian coordinate robots (gantry robots or x-y-z robots).", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 28], [29, 43], [44, 47], [48, 59], [60, 66], [66, 67], [68, 73], [74, 80], [80, 81], [82, 87], [88, 94], [95, 98], [99, 108], [109, 119], [120, 126], [127, 128], [128, 134], [135, 141], [142, 144], [145, 146], [146, 147], [147, 148], [148, 149], [149, 150], [151, 157], [157, 158], [158, 159]]}
{"doc_key": "ai-dev-233", "ner": [[8, 8, "programlang"], [9, 10, "misc"], [15, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 8, 8, "part-of", "", false, false], [15, 15, 9, 10, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Alternatively", ",", "it", "can", "be", "used", "directly", "with", "Perl", "Module", "TM", "(", "which", "also", "supports", "LTM", ")", "."], "sentence-detokenized": "Alternatively, it can be used directly with Perl Module TM (which also supports LTM).", "token2charspan": [[0, 13], [13, 14], [15, 17], [18, 21], [22, 24], [25, 29], [30, 38], [39, 43], [44, 48], [49, 55], [56, 58], [59, 60], [60, 65], [66, 70], [71, 79], [80, 83], [83, 84], [84, 85]]}
{"doc_key": "ai-dev-234", "ner": [[5, 5, "country"], [8, 11, "organisation"], [17, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 5, 5, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "won", "by", "an", "American", "team", "from", "Newton", "Labs", ",", "and", "the", "competition", "was", "broadcast", "on", "CNN", "."], "sentence-detokenized": "It was won by an American team from Newton Labs, and the competition was broadcast on CNN.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 13], [14, 16], [17, 25], [26, 30], [31, 35], [36, 42], [43, 47], [47, 48], [49, 52], [53, 56], [57, 68], [69, 72], [73, 82], [83, 85], [86, 89], [89, 90]]}
{"doc_key": "ai-dev-235", "ner": [[0, 4, "misc"], [11, 12, "person"], [15, 16, "person"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 12, 0, 4, "role", "directs", false, false], [15, 16, 0, 4, "role", "acts_in", false, false], [18, 19, 0, 4, "role", "acts_in", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Butler", "'s", "in", "Love", ",", "a", "short", "film", "directed", "by", "David", "Arquette", "and", "starring", "Elizabeth", "Berkley", "and", "Thomas", "Jane", ",", "was", "released", "on", "23", "June", "2008", "."], "sentence-detokenized": "The Butler's in Love, a short film directed by David Arquette and starring Elizabeth Berkley and Thomas Jane, was released on 23 June 2008.", "token2charspan": [[0, 3], [4, 10], [10, 12], [13, 15], [16, 20], [20, 21], [22, 23], [24, 29], [30, 34], [35, 43], [44, 46], [47, 52], [53, 61], [62, 65], [66, 74], [75, 84], [85, 92], [93, 96], [97, 103], [104, 108], [108, 109], [110, 113], [114, 122], [123, 125], [126, 128], [129, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-dev-236", "ner": [[0, 2, "product"], [10, 10, "field"], [16, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 16, 16, "general-affiliation", "", false, false], [10, 10, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "for", "example", ",", "is", "a", "resource", "with", "a", "taxonomy", "whose", "elements", "are", "meanings", "of", "English", "words", "."], "sentence-detokenized": "WordNet, for example, is a resource with a taxonomy whose elements are meanings of English words.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 20], [20, 21], [22, 24], [25, 26], [27, 35], [36, 40], [41, 42], [43, 51], [52, 57], [58, 66], [67, 70], [71, 79], [80, 82], [83, 90], [91, 96], [96, 97]]}
{"doc_key": "ai-dev-237", "ner": [[1, 3, "product"], [5, 5, "product"], [7, 7, "product"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 1, 3, "type-of", "", false, false], [5, 5, 12, 13, "related-to", "ability_to", false, false], [7, 7, 1, 3, "type-of", "", false, false], [7, 7, 12, 13, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Existing", "humanoid", "robotic", "systems", "like", "ASIMO", "and", "QRIO", "use", "many", "motors", "to", "move", "forward", "."], "sentence-detokenized": "Existing humanoid robotic systems like ASIMO and QRIO use many motors to move forward.", "token2charspan": [[0, 8], [9, 17], [18, 25], [26, 33], [34, 38], [39, 44], [45, 48], [49, 53], [54, 57], [58, 62], [63, 69], [70, 72], [73, 77], [78, 85], [85, 86]]}
{"doc_key": "ai-dev-238", "ner": [[0, 0, "metrics"], [7, 8, "metrics"], [10, 10, "metrics"], [12, 16, "misc"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 0, 0, "part-of", "", false, false], [10, 10, 0, 0, "part-of", "", false, false], [12, 16, 0, 0, "part-of", "", false, false], [18, 18, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LEPOR", "is", "designed", "with", "the", "factors", "improved", "length", "penalty", ",", "precision", ",", "n-", "gram", "word", "distribution", "penalty", "and", "recall", "."], "sentence-detokenized": "LEPOR is designed with the factors improved length penalty, precision, n-gram word distribution penalty and recall.", "token2charspan": [[0, 5], [6, 8], [9, 17], [18, 22], [23, 26], [27, 34], [35, 43], [44, 50], [51, 58], [58, 59], [60, 69], [69, 70], [71, 73], [73, 77], [78, 82], [83, 95], [96, 103], [104, 107], [108, 114], [114, 115]]}
{"doc_key": "ai-dev-239", "ner": [[5, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "based", "on", "the", "bilingual", "student", "evaluation", "metric", ",", "but", "with", "some", "modifications", "."], "sentence-detokenized": "It is based on the bilingual student evaluation metric, but with some modifications.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 14], [15, 18], [19, 28], [29, 36], [37, 47], [48, 54], [54, 55], [56, 59], [60, 64], [65, 69], [70, 83], [83, 84]]}
{"doc_key": "ai-dev-240", "ner": [[8, 10, "product"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "of", "an", "implementation", "in", "MATLAB", "/", "Octave", ":"], "sentence-detokenized": "This is an example of an implementation in MATLAB/Octave:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 24], [25, 39], [40, 42], [43, 49], [49, 50], [50, 56], [56, 57]]}
{"doc_key": "ai-dev-241", "ner": [[14, 14, "programlang"], [16, 16, "programlang"], [18, 18, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "designed", "to", "be", "used", "via", "a", "number", "of", "computer", "languages", ",", "including", "Python", ",", "Ruby", "and", "Scheme", "."], "sentence-detokenized": "It is designed to be used via a number of computer languages, including Python, Ruby and Scheme.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 20], [21, 25], [26, 29], [30, 31], [32, 38], [39, 41], [42, 50], [51, 60], [60, 61], [62, 71], [72, 78], [78, 79], [80, 84], [85, 88], [89, 95], [95, 96]]}
{"doc_key": "ai-dev-242", "ner": [[0, 0, "researcher"], [6, 6, "organisation"], [12, 12, "conference"], [16, 17, "academicjournal"], [22, 24, "organisation"], [30, 34, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 6, "role", "", false, false], [0, 0, 12, 12, "role", "", false, false], [0, 0, 16, 17, "role", "", false, false], [0, 0, 22, 24, "role", "", false, false], [0, 0, 30, 34, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hayes", "has", "served", "as", "secretary", "of", "AISB", ",", "president", "and", "trustee", "of", "IJCAI", ",", "co-editor", "of", "Artificial", "Intelligence", ",", "governor", "of", "the", "Cognitive", "Science", "Society", ",", "and", "president", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "."], "sentence-detokenized": "Hayes has served as secretary of AISB, president and trustee of IJCAI, co-editor of Artificial Intelligence, governor of the Cognitive Science Society, and president of the American Association for Artificial Intelligence.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 32], [33, 37], [37, 38], [39, 48], [49, 52], [53, 60], [61, 63], [64, 69], [69, 70], [71, 80], [81, 83], [84, 94], [95, 107], [107, 108], [109, 117], [118, 120], [121, 124], [125, 134], [135, 142], [143, 150], [150, 151], [152, 155], [156, 165], [166, 168], [169, 172], [173, 181], [182, 193], [194, 197], [198, 208], [209, 221], [221, 222]]}
{"doc_key": "ai-dev-243", "ner": [[4, 14, "misc"], [16, 18, "misc"], [23, 24, "person"], [29, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 24, 4, 14, "role", "directed_by", false, false], [23, 24, 16, 18, "role", "directed_by", false, false], [23, 24, 29, 33, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "of", "them", ",", "Now", "is", "the", "Time", "(", "to", "Put", "On", "Your", "Glasses", ")", "and", "Around", "is", "Around", ",", "were", "directed", "by", "Norman", "McLaren", "in", "1951", "for", "the", "National", "Film", "Board", "of", "Canada", "."], "sentence-detokenized": "Two of them, Now is the Time (to Put On Your Glasses) and Around is Around, were directed by Norman McLaren in 1951 for the National Film Board of Canada.", "token2charspan": [[0, 3], [4, 6], [7, 11], [11, 12], [13, 16], [17, 19], [20, 23], [24, 28], [29, 30], [30, 32], [33, 36], [37, 39], [40, 44], [45, 52], [52, 53], [54, 57], [58, 64], [65, 67], [68, 74], [74, 75], [76, 80], [81, 89], [90, 92], [93, 99], [100, 107], [108, 110], [111, 115], [116, 119], [120, 123], [124, 132], [133, 137], [138, 143], [144, 146], [147, 153], [153, 154]]}
{"doc_key": "ai-dev-244", "ner": [[1, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "recommendation", "system", "aims", "to", "predict", "a", "target", "user", "'s", "preference", "for", "a", "product", "."], "sentence-detokenized": "A recommendation system aims to predict a target user's preference for a product.", "token2charspan": [[0, 1], [2, 16], [17, 23], [24, 28], [29, 31], [32, 39], [40, 41], [42, 48], [49, 53], [53, 55], [56, 66], [67, 70], [71, 72], [73, 80], [80, 81]]}
{"doc_key": "ai-dev-245", "ner": [[0, 0, "algorithm"], [4, 4, "field"], [6, 6, "field"], [8, 9, "field"], [11, 13, "field"], [15, 15, "field"], [17, 18, "field"], [20, 20, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 4, "part-of", "", true, false], [0, 0, 6, 6, "part-of", "", true, false], [0, 0, 8, 9, "part-of", "", true, false], [0, 0, 11, 13, "part-of", "", true, false], [0, 0, 15, 15, "part-of", "", true, false], [0, 0, 17, 18, "part-of", "", true, false], [0, 0, 20, 20, "part-of", "", true, false], [0, 0, 22, 23, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Convolution", "is", "used", "in", "probability", ",", "statistics", ",", "computer", "vision", ",", "natural", "language", "processing", ",", "image", "and", "signal", "processing", ",", "engineering", "and", "differential", "equations", "."], "sentence-detokenized": "Convolution is used in probability, statistics, computer vision, natural language processing, image and signal processing, engineering and differential equations.", "token2charspan": [[0, 11], [12, 14], [15, 19], [20, 22], [23, 34], [34, 35], [36, 46], [46, 47], [48, 56], [57, 63], [63, 64], [65, 72], [73, 81], [82, 92], [92, 93], [94, 99], [100, 103], [104, 110], [111, 121], [121, 122], [123, 134], [135, 138], [139, 151], [152, 161], [161, 162]]}
{"doc_key": "ai-dev-246", "ner": [[2, 2, "field"], [4, 6, "task"], [8, 9, "task"], [11, 11, "task"], [12, 13, "task"], [15, 16, "task"], [18, 19, "task"], [21, 22, "task"], [24, 24, "task"], [27, 28, "task"], [30, 30, "field"], [32, 32, "field"], [34, 36, "field"], [38, 38, "field"], [40, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[2, 2, 4, 6, "part-of", "", true, false], [2, 2, 8, 9, "part-of", "", true, false], [2, 2, 11, 11, "part-of", "", true, false], [2, 2, 12, 13, "part-of", "", true, false], [2, 2, 15, 16, "part-of", "", true, false], [2, 2, 18, 19, "part-of", "", true, false], [2, 2, 21, 22, "part-of", "", true, false], [2, 2, 24, 24, "part-of", "", true, false], [2, 2, 27, 28, "part-of", "", true, false], [2, 2, 30, 30, "part-of", "", true, false], [2, 2, 32, 32, "part-of", "", true, false], [2, 2, 34, 36, "part-of", "", true, false], [2, 2, 38, 38, "part-of", "", true, false], [2, 2, 40, 40, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Applications", "for", "DSP", "include", "audio", "signal", "processing", ",", "audio", "compression", ",", "digital", "image", "processing", ",", "video", "compression", ",", "speech", "processing", ",", "speech", "recognition", ",", "digital", "communications", ",", "digital", "synthesizers", ",", "radar", ",", "sonar", ",", "financial", "signal", "processing", ",", "seismology", "and", "biomedicine", "."], "sentence-detokenized": "Applications for DSP include audio signal processing, audio compression, digital image processing, video compression, speech processing, speech recognition, digital communications, digital synthesizers, radar, sonar, financial signal processing, seismology and biomedicine.", "token2charspan": [[0, 12], [13, 16], [17, 20], [21, 28], [29, 34], [35, 41], [42, 52], [52, 53], [54, 59], [60, 71], [71, 72], [73, 80], [81, 86], [87, 97], [97, 98], [99, 104], [105, 116], [116, 117], [118, 124], [125, 135], [135, 136], [137, 143], [144, 155], [155, 156], [157, 164], [165, 179], [179, 180], [181, 188], [189, 201], [201, 202], [203, 208], [208, 209], [210, 215], [215, 216], [217, 226], [227, 233], [234, 244], [244, 245], [246, 256], [257, 260], [261, 272], [272, 273]]}
{"doc_key": "ai-dev-247", "ner": [[11, 12, "misc"], [17, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "20", "February", "1912", "-", "11", "August", "2011", ")", "was", "an", "American", "inventor", "best", "known", "for", "creating", "Unimate", ",", "the", "first", "industrial", "robot", "."], "sentence-detokenized": "(20 February 1912 - 11 August 2011) was an American inventor best known for creating Unimate, the first industrial robot.", "token2charspan": [[0, 1], [1, 3], [4, 12], [13, 17], [18, 19], [20, 22], [23, 29], [30, 34], [34, 35], [36, 39], [40, 42], [43, 51], [52, 60], [61, 65], [66, 71], [72, 75], [76, 84], [85, 92], [92, 93], [94, 97], [98, 103], [104, 114], [115, 120], [120, 121]]}
{"doc_key": "ai-dev-248", "ner": [[2, 4, "researcher"], [6, 8, "researcher"], [10, 10, "researcher"], [21, 23, "algorithm"], [26, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 21, 23, "related-to", "writes_about", true, false], [6, 8, 21, 23, "related-to", "writes_about", true, false], [10, 10, 21, 23, "related-to", "writes_about", true, false], [21, 23, 26, 28, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Along", "with", "David", "E.", "Rumelhart", "and", "Ronald", "J.", "Williams", ",", "Hinton", "co-authored", "a", "widely", "cited", "paper", "published", "in", "1986", "that", "popularized", "the", "backpropagation", "algorithm", "for", "training", "multilayer", "neural", "networks", "."], "sentence-detokenized": "Along with David E. Rumelhart and Ronald J. Williams, Hinton co-authored a widely cited paper published in 1986 that popularized the backpropagation algorithm for training multilayer neural networks.", "token2charspan": [[0, 5], [6, 10], [11, 16], [17, 19], [20, 29], [30, 33], [34, 40], [41, 43], [44, 52], [52, 53], [54, 60], [61, 72], [73, 74], [75, 81], [82, 87], [88, 93], [94, 103], [104, 106], [107, 111], [112, 116], [117, 128], [129, 132], [133, 148], [149, 158], [159, 162], [163, 171], [172, 182], [183, 189], [190, 198], [198, 199]]}
{"doc_key": "ai-dev-249", "ner": [[10, 12, "metrics"], [15, 18, "metrics"], [21, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "value", "being", "predicted", "is", "continuously", "distributed", ",", "the", "mean", "squared", "error", ",", "the", "mean", "squared", "error", "root", "or", "the", "absolute", "median", "deviation", "can", "be", "used", "to", "sum", "the", "errors", "."], "sentence-detokenized": "When the value being predicted is continuously distributed, the mean squared error, the mean squared error root or the absolute median deviation can be used to sum the errors.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 20], [21, 30], [31, 33], [34, 46], [47, 58], [58, 59], [60, 63], [64, 68], [69, 76], [77, 82], [82, 83], [84, 87], [88, 92], [93, 100], [101, 106], [107, 111], [112, 114], [115, 118], [119, 127], [128, 134], [135, 144], [145, 148], [149, 151], [152, 156], [157, 159], [160, 163], [164, 167], [168, 174], [174, 175]]}
{"doc_key": "ai-dev-250", "ner": [[0, 1, "algorithm"], [14, 15, "field"]], "ner_mapping_to_source": [0, 2], "relations": [[0, 1, 14, 15, "part-of", "", true, false]], "relations_mapping_to_source": [1], "sentence": ["Conceptual", "clustering", "was", "mainly", "developed", "in", "the", "1980s", "as", "a", "machine", "learning", "paradigm", "for", "unsupervised", "learning", "."], "sentence-detokenized": "Conceptual clustering was mainly developed in the 1980s as a machine learning paradigm for unsupervised learning.", "token2charspan": [[0, 10], [11, 21], [22, 25], [26, 32], [33, 42], [43, 45], [46, 49], [50, 55], [56, 58], [59, 60], [61, 68], [69, 77], [78, 86], [87, 90], [91, 103], [104, 112], [112, 113]]}
{"doc_key": "ai-dev-251", "ner": [[8, 10, "product"], [27, 27, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "named", "entities", "can", "not", "be", "recognised", "by", "the", "machine", "translator", ",", "they", "may", "be", "incorrectly", "translated", "as", "common", "nouns", ",", "which", "is", "unlikely", "to", "affect", "the", "bilingual", "evaluation", "rating", "of", "the", "translation", ",", "but", "will", "alter", "the", "human", "readability", "of", "the", "text", "."], "sentence-detokenized": "If named entities cannot be recognised by the machine translator, they may be incorrectly translated as common nouns, which is unlikely to affect the bilingual evaluation rating of the translation, but will alter the human readability of the text.", "token2charspan": [[0, 2], [3, 8], [9, 17], [18, 21], [21, 24], [25, 27], [28, 38], [39, 41], [42, 45], [46, 53], [54, 64], [64, 65], [66, 70], [71, 74], [75, 77], [78, 89], [90, 100], [101, 103], [104, 110], [111, 116], [116, 117], [118, 123], [124, 126], [127, 135], [136, 138], [139, 145], [146, 149], [150, 159], [160, 170], [171, 177], [178, 180], [181, 184], [185, 196], [196, 197], [198, 201], [202, 206], [207, 212], [213, 216], [217, 222], [223, 234], [235, 237], [238, 241], [242, 246], [246, 247]]}
{"doc_key": "ai-dev-252", "ner": [[0, 1, "researcher"], [10, 11, "misc"], [12, 18, "conference"], [20, 22, "location"], [24, 24, "country"], [38, 39, "researcher"], [45, 46, "researcher"], [49, 50, "university"], [54, 55, "researcher"], [57, 58, "researcher"], [60, 61, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 11, "related-to", "writes_about", false, false], [0, 1, 12, 18, "temporal", "", true, false], [12, 18, 20, 22, "physical", "", false, false], [20, 22, 24, 24, "physical", "", false, false], [45, 46, 49, 50, "physical", "", false, false], [45, 46, 49, 50, "role", "", false, false], [54, 55, 49, 50, "physical", "", false, false], [54, 55, 49, 50, "role", "", false, false], [57, 58, 49, 50, "physical", "", false, false], [57, 58, 49, 50, "role", "", false, false], [60, 61, 49, 50, "physical", "", false, false], [60, 61, 49, 50, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Roger", "Schank", ",", "1969", ",", "A", "conceptual", "dependency", "parser", "for", "natural", "language", "Proceedings", "of", "the", "1969", "on", "Computational", "linguistics", ",", "S\u00e5ng", "-", "S\u00e4by", ",", "Sweden", ",", "pages", "1-", "3", "This", "model", ",", "partly", "influenced", "by", "the", "work", "of", "Sydney", "Lamb", ",", "was", "widely", "used", "by", "Schank", "'s", "students", "at", "Yale", "University", ",", "such", "as", "Robert", "Wilensky", ",", "Wendy", "Lehnert", "and", "Janet", "Kolodner", "."], "sentence-detokenized": "Roger Schank, 1969, A conceptual dependency parser for natural language Proceedings of the 1969 on Computational linguistics, S\u00e5ng-S\u00e4by, Sweden, pages 1-3 This model, partly influenced by the work of Sydney Lamb, was widely used by Schank's students at Yale University, such as Robert Wilensky, Wendy Lehnert and Janet Kolodner.", "token2charspan": [[0, 5], [6, 12], [12, 13], [14, 18], [18, 19], [20, 21], [22, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 71], [72, 83], [84, 86], [87, 90], [91, 95], [96, 98], [99, 112], [113, 124], [124, 125], [126, 130], [130, 131], [131, 135], [135, 136], [137, 143], [143, 144], [145, 150], [151, 153], [153, 154], [155, 159], [160, 165], [165, 166], [167, 173], [174, 184], [185, 187], [188, 191], [192, 196], [197, 199], [200, 206], [207, 211], [211, 212], [213, 216], [217, 223], [224, 228], [229, 231], [232, 238], [238, 240], [241, 249], [250, 252], [253, 257], [258, 268], [268, 269], [270, 274], [275, 277], [278, 284], [285, 293], [293, 294], [295, 300], [301, 308], [309, 312], [313, 318], [319, 327], [327, 328]]}
{"doc_key": "ai-dev-253", "ner": [[1, 3, "algorithm"], [5, 8, "algorithm"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[5, 8, 1, 3, "named", "", false, false], [14, 15, 1, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["Improved", "maximum", "likelihood", "method", "(", "IMLM", ")", "is", "a", "combination", "of", "two", "MLM", "(", "maximum", "likelihood", ")", "estimators", "."], "sentence-detokenized": "Improved maximum likelihood method (IMLM) is a combination of two MLM (maximum likelihood) estimators.", "token2charspan": [[0, 8], [9, 16], [17, 27], [28, 34], [35, 36], [36, 40], [40, 41], [42, 44], [45, 46], [47, 58], [59, 61], [62, 65], [66, 69], [70, 71], [71, 78], [79, 89], [89, 90], [91, 101], [101, 102]]}
{"doc_key": "ai-dev-254", "ner": [[19, 20, "metrics"], [23, 24, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[23, 24, 19, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["These", "methods", "can", "also", "analyse", "a", "program", "'s", "output", "and", "its", "usefulness", "and", "may", "therefore", "include", "analysis", "of", "its", "confusion", "matrix", "(", "or", "confusion", "table", ")", "."], "sentence-detokenized": "These methods can also analyse a program's output and its usefulness and may therefore include analysis of its confusion matrix (or confusion table).", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 22], [23, 30], [31, 32], [33, 40], [40, 42], [43, 49], [50, 53], [54, 57], [58, 68], [69, 72], [73, 76], [77, 86], [87, 94], [95, 103], [104, 106], [107, 110], [111, 120], [121, 127], [128, 129], [129, 131], [132, 141], [142, 147], [147, 148], [148, 149]]}
{"doc_key": "ai-dev-255", "ner": [[0, 0, "product"], [5, 6, "researcher"], [8, 9, "researcher"], [11, 13, "researcher"], [18, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 6, "origin", "", false, false], [0, 0, 8, 9, "origin", "", false, false], [0, 0, 11, 13, "origin", "", false, false], [0, 0, 18, 24, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SURF", "was", "first", "published", "by", "Herbert", "Bay", ",", "Tinne", "Tuytelaars", "and", "Luc", "Van", "Gool", "and", "presented", "at", "the", "European", "Conference", "on", "Computer", "Vision", "in", "2006", "."], "sentence-detokenized": "SURF was first published by Herbert Bay, Tinne Tuytelaars and Luc Van Gool and presented at the European Conference on Computer Vision in 2006.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 24], [25, 27], [28, 35], [36, 39], [39, 40], [41, 46], [47, 57], [58, 61], [62, 65], [66, 69], [70, 74], [75, 78], [79, 88], [89, 91], [92, 95], [96, 104], [105, 115], [116, 118], [119, 127], [128, 134], [135, 137], [138, 142], [142, 143]]}
{"doc_key": "ai-dev-256", "ner": [[0, 2, "task"], [6, 7, "field"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 6, 7, "part-of", "", false, false], [0, 2, 9, 10, "part-of", "", false, false], [0, 2, 12, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OCR", "is", "a", "research", "area", "in", "pattern", "recognition", ",", "artificial", "intelligence", "and", "computer", "vision", "."], "sentence-detokenized": "OCR is a research area in pattern recognition, artificial intelligence and computer vision.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 17], [18, 22], [23, 25], [26, 33], [34, 45], [45, 46], [47, 57], [58, 70], [71, 74], [75, 83], [84, 90], [90, 91]]}
{"doc_key": "ai-dev-257", "ner": [[8, 10, "metrics"], [13, 15, "algorithm"], [17, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 17, 13, 15, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["If", "we", "continue", "with", "the", "example", "using", "the", "maximum", "likelihood", "estimator", ",", "the", "probability", "density", "function", "(", "pdf", ")", "for", "the", "noise", "for", "a", "sample", "is", "mathwn", "/", "math"], "sentence-detokenized": "If we continue with the example using the maximum likelihood estimator, the probability density function (pdf) for the noise for a sample is mathwn/math", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 19], [20, 23], [24, 31], [32, 37], [38, 41], [42, 49], [50, 60], [61, 70], [70, 71], [72, 75], [76, 87], [88, 95], [96, 104], [105, 106], [106, 109], [109, 110], [111, 114], [115, 118], [119, 124], [125, 128], [129, 130], [131, 137], [138, 140], [141, 147], [147, 148], [148, 152]]}
{"doc_key": "ai-dev-258", "ner": [[2, 3, "field"], [5, 6, "task"], [8, 9, "task"], [11, 12, "task"], [14, 15, "task"], [17, 19, "task"], [21, 21, "task"], [23, 23, "task"], [25, 26, "task"], [28, 29, "task"], [31, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[5, 6, 2, 3, "part-of", "", false, false], [8, 9, 2, 3, "part-of", "", false, false], [11, 12, 2, 3, "part-of", "", false, false], [14, 15, 2, 3, "part-of", "", false, false], [17, 19, 2, 3, "part-of", "", false, false], [21, 21, 2, 3, "part-of", "", false, false], [23, 23, 2, 3, "part-of", "", false, false], [25, 26, 2, 3, "part-of", "", false, false], [28, 29, 2, 3, "part-of", "", false, false], [31, 33, 2, 3, "part-of", "", false, false], [35, 36, 2, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Sub-areas", "of", "computer", "vision", "include", "scene", "reconstruction", ",", "event", "detection", ",", "video", "tracking", ",", "object", "recognition", ",", "3D", "position", "evaluation", ",", "learning", ",", "indexing", ",", "motion", "estimation", ",", "visual", "servoing", ",", "3D", "scene", "modelling", "and", "image", "restoration", "."], "sentence-detokenized": "Sub-areas of computer vision include scene reconstruction, event detection, video tracking, object recognition, 3D position evaluation, learning, indexing, motion estimation, visual servoing, 3D scene modelling and image restoration.", "token2charspan": [[0, 9], [10, 12], [13, 21], [22, 28], [29, 36], [37, 42], [43, 57], [57, 58], [59, 64], [65, 74], [74, 75], [76, 81], [82, 90], [90, 91], [92, 98], [99, 110], [110, 111], [112, 114], [115, 123], [124, 134], [134, 135], [136, 144], [144, 145], [146, 154], [154, 155], [156, 162], [163, 173], [173, 174], [175, 181], [182, 190], [190, 191], [192, 194], [195, 200], [201, 210], [211, 214], [215, 220], [221, 232], [232, 233]]}
{"doc_key": "ai-dev-259", "ner": [[5, 9, "conference"], [11, 11, "researcher"], [15, 16, "misc"], [19, 19, "conference"], [23, 23, "researcher"], [25, 25, "researcher"], [27, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 9, 19, 19, "named", "", false, false], [11, 11, 15, 16, "win-defeat", "", false, false], [11, 11, 27, 27, "related-to", "writes_about", true, false], [15, 16, 5, 9, "temporal", "", false, false], [23, 23, 15, 16, "win-defeat", "", false, true], [23, 23, 27, 27, "related-to", "writes_about", true, false], [25, 25, 15, 16, "win-defeat", "", false, true], [25, 25, 27, 27, "related-to", "writes_about", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["In", "2013", ",", "at", "the", "International", "Conference", "on", "Computer", "Vision", ",", "Terzopoulos", "was", "awarded", "a", "Helmholtz", "Prize", "for", "his", "1987", "ICCV", "publication", "with", "Kass", "and", "Witkin", "on", "active", "contour", "models", "."], "sentence-detokenized": "In 2013, at the International Conference on Computer Vision, Terzopoulos was awarded a Helmholtz Prize for his 1987 ICCV publication with Kass and Witkin on active contour models.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 29], [30, 40], [41, 43], [44, 52], [53, 59], [59, 60], [61, 72], [73, 76], [77, 84], [85, 86], [87, 96], [97, 102], [103, 106], [107, 110], [111, 115], [116, 120], [121, 132], [133, 137], [138, 142], [143, 146], [147, 153], [154, 156], [157, 163], [164, 171], [172, 178], [178, 179]]}
{"doc_key": "ai-dev-260", "ner": [[16, 17, "task"], [19, 21, "algorithm"], [23, 24, "algorithm"], [26, 28, "algorithm"], [30, 31, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 17, 19, 21, "usage", "", true, false], [16, 17, 23, 24, "usage", "", true, false], [16, 17, 26, 28, "usage", "", true, false], [16, 17, 30, 31, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["If", "the", "control", "function", "There", "are", "many", "algorithms", "for", "solving", "such", "problems", ";", "popular", "algorithms", "for", "linear", "classification", "include", "Stochastic", "gradient", "descent", ")", "gradient", "descent", ",", "L", "-", "BFGS", ",", "coordinate", "descent", "and", "Newton", "methods", "."], "sentence-detokenized": "If the control function There are many algorithms for solving such problems; popular algorithms for linear classification include Stochastic gradient descent) gradient descent, L-BFGS, coordinate descent and Newton methods.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 23], [24, 29], [30, 33], [34, 38], [39, 49], [50, 53], [54, 61], [62, 66], [67, 75], [75, 76], [77, 84], [85, 95], [96, 99], [100, 106], [107, 121], [122, 129], [130, 140], [141, 149], [150, 157], [157, 158], [159, 167], [168, 175], [175, 176], [177, 178], [178, 179], [179, 183], [183, 184], [185, 195], [196, 203], [204, 207], [208, 214], [215, 222], [222, 223]]}
{"doc_key": "ai-dev-261", "ner": [[0, 3, "algorithm"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[0, 3, 11, 12, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Long", "Short", "Term", "Memory", "(", "LSTM", ")", "networks", "were", "invented", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "in", "1997", "and", "have", "set", "accuracy", "records", "in", "several", "applications", "."], "sentence-detokenized": "Long Short Term Memory (LSTM) networks were invented by Sepp Hochreiter and J\u00fcrgen Schmidhuber in 1997 and have set accuracy records in several applications.", "token2charspan": [[0, 4], [5, 10], [11, 15], [16, 22], [23, 24], [24, 28], [28, 29], [30, 38], [39, 43], [44, 52], [53, 55], [56, 60], [61, 71], [72, 75], [76, 82], [83, 94], [95, 97], [98, 102], [103, 106], [107, 111], [112, 115], [116, 124], [125, 132], [133, 135], [136, 143], [144, 156], [156, 157]]}
{"doc_key": "ai-dev-262", "ner": [[0, 0, "product"], [4, 6, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["TN", "was", "developed", "at", "Massachusetts", "General", "Hospital", "and", "was", "tested", "in", "several", "scenarios", ",", "including", "extraction", "of", "smoking", "status", ",", "family", "history", "of", "coronary", "artery", "disease", ",", "and", "identification", "of", "patients", "with", "sleep", "disorders", ","], "sentence-detokenized": "TN was developed at Massachusetts General Hospital and was tested in several scenarios, including extraction of smoking status, family history of coronary artery disease, and identification of patients with sleep disorders,", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 33], [34, 41], [42, 50], [51, 54], [55, 58], [59, 65], [66, 68], [69, 76], [77, 86], [86, 87], [88, 97], [98, 108], [109, 111], [112, 119], [120, 126], [126, 127], [128, 134], [135, 142], [143, 145], [146, 154], [155, 161], [162, 169], [169, 170], [171, 174], [175, 189], [190, 192], [193, 201], [202, 206], [207, 212], [213, 222], [222, 223]]}
{"doc_key": "ai-dev-263", "ner": [[3, 3, "researcher"], [15, 16, "organisation"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "delivered", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was delivered to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 75], [76, 78], [79, 86], [87, 93], [94, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-dev-264", "ner": [[0, 3, "conference"], [12, 13, "location"], [15, 15, "location"], [17, 17, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 12, 13, "physical", "", false, false], [12, 13, 15, 15, "physical", "", false, false], [15, 15, 17, 17, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Campus", "Party", "Europe", "was", "held", "on", "14", "-", "18", "April", "2010", "at", "Caja", "M\u00e1gica", "in", "Madrid", ",", "Spain", ",", "with", "800", "participants", "from", "each", "of", "the", "27", "EU", "Member", "States", "."], "sentence-detokenized": "Campus Party Europe was held on 14-18 April 2010 at Caja M\u00e1gica in Madrid, Spain, with 800 participants from each of the 27 EU Member States.", "token2charspan": [[0, 6], [7, 12], [13, 19], [20, 23], [24, 28], [29, 31], [32, 34], [34, 35], [35, 37], [38, 43], [44, 48], [49, 51], [52, 56], [57, 63], [64, 66], [67, 73], [73, 74], [75, 80], [80, 81], [82, 86], [87, 90], [91, 103], [104, 108], [109, 113], [114, 116], [117, 120], [121, 123], [124, 126], [127, 133], [134, 140], [140, 141]]}
{"doc_key": "ai-dev-265", "ner": [[7, 7, "organisation"], [9, 14, "organisation"], [16, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 21, 7, 7, "origin", "", false, false], [16, 21, 9, 14, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2016", ",", "a", "collaboration", "between", "DeepMind", "and", "Moorfields", "Eye", "Hospital", "was", "announced", "to", "develop", "AI", "applications", "for", "the", "healthcare", "sector", "."], "sentence-detokenized": "In July 2016, a collaboration between DeepMind and Moorfields Eye Hospital was announced to develop AI applications for the healthcare sector.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 15], [16, 29], [30, 37], [38, 46], [47, 50], [51, 61], [62, 65], [66, 74], [75, 78], [79, 88], [89, 91], [92, 99], [100, 102], [103, 115], [116, 119], [120, 123], [124, 134], [135, 141], [141, 142]]}
{"doc_key": "ai-dev-266", "ner": [[5, 5, "misc"], [11, 12, "university"], [14, 14, "university"], [16, 17, "university"], [19, 20, "university"], [22, 22, "university"], [24, 24, "university"], [26, 28, "university"], [30, 31, "university"], [33, 34, "university"], [36, 36, "university"], [39, 41, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[5, 5, 11, 12, "physical", "", false, false], [5, 5, 14, 14, "physical", "", false, false], [5, 5, 16, 17, "physical", "", false, false], [5, 5, 19, 20, "physical", "", false, false], [5, 5, 22, 22, "physical", "", false, false], [5, 5, 24, 24, "physical", "", false, false], [5, 5, 26, 28, "physical", "", false, false], [5, 5, 30, 31, "physical", "", false, false], [5, 5, 33, 34, "physical", "", false, false], [5, 5, 36, 36, "physical", "", false, false], [5, 5, 39, 41, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["They", "ended", "up", "awarding", "11", "PR2s", "to", "various", "institutions", ",", "including", "Freiburg", "University", ",", "Bosch", ",", "Georgia", "Tech", ",", "KU", "Leuven", ",", "MIT", ",", "Stanford", ",", "Munich", "Technical", "University", ",", "UC", "Berkeley", ",", "U", "Penn", ",", "USC", "and", "the", "University", "of", "Tokyo", "."], "sentence-detokenized": "They ended up awarding 11 PR2s to various institutions, including Freiburg University, Bosch, Georgia Tech, KU Leuven, MIT, Stanford, Munich Technical University, UC Berkeley, U Penn, USC and the University of Tokyo.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 25], [26, 30], [31, 33], [34, 41], [42, 54], [54, 55], [56, 65], [66, 74], [75, 85], [85, 86], [87, 92], [92, 93], [94, 101], [102, 106], [106, 107], [108, 110], [111, 117], [117, 118], [119, 122], [122, 123], [124, 132], [132, 133], [134, 140], [141, 150], [151, 161], [161, 162], [163, 165], [166, 174], [174, 175], [176, 177], [178, 182], [182, 183], [184, 187], [188, 191], [192, 195], [196, 206], [207, 209], [210, 215], [215, 216]]}
{"doc_key": "ai-dev-267", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [7, 7, "metrics"], [9, 9, "metrics"], [18, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 18, 19, "part-of", "", false, false], [5, 5, 18, 19, "part-of", "", false, false], [7, 7, 18, 19, "part-of", "", false, false], [9, 9, 18, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "counts", "of", "TP", ",", "TN", ",", "FP", "and", "FN", "are", "usually", "stored", "in", "a", "table", "called", "the", "confusion", "matrix", "."], "sentence-detokenized": "The counts of TP, TN, FP and FN are usually stored in a table called the confusion matrix.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 16], [16, 17], [18, 20], [20, 21], [22, 24], [25, 28], [29, 31], [32, 35], [36, 43], [44, 50], [51, 53], [54, 55], [56, 61], [62, 68], [69, 72], [73, 82], [83, 89], [89, 90]]}
{"doc_key": "ai-dev-268", "ner": [[4, 5, "metrics"], [7, 8, "metrics"], [10, 11, "metrics"], [13, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["As", "function", "sets", ",", "information", "gain", ",", "cross", "-entropy", ",", "mutual", "information", "and", "odds", "ratio", "are", "usually", "used", "."], "sentence-detokenized": "As function sets, information gain, cross-entropy, mutual information and odds ratio are usually used.", "token2charspan": [[0, 2], [3, 11], [12, 16], [16, 17], [18, 29], [30, 34], [34, 35], [36, 41], [41, 49], [49, 50], [51, 57], [58, 69], [70, 73], [74, 78], [79, 84], [85, 88], [89, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-dev-269", "ner": [[10, 11, "task"], [13, 14, "task"], [16, 16, "task"], [18, 18, "task"], [20, 20, "task"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[22, 22, 20, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "successfully", "applied", "to", "various", "problems", ",", "including", "robot", "control", ",", "elevator", "scheduling", ",", "telecommunications", ",", "checkers", "and", "Go", "(", "AlphaGo", ")", "."], "sentence-detokenized": "It has been successfully applied to various problems, including robot control, elevator scheduling, telecommunications, checkers and Go (AlphaGo).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 24], [25, 32], [33, 35], [36, 43], [44, 52], [52, 53], [54, 63], [64, 69], [70, 77], [77, 78], [79, 87], [88, 98], [98, 99], [100, 118], [118, 119], [120, 128], [129, 132], [133, 135], [136, 137], [137, 144], [144, 145], [145, 146]]}
{"doc_key": "ai-dev-270", "ner": [[11, 12, "misc"], [17, 20, "university"], [22, 22, "location"], [24, 24, "location"], [28, 32, "location"], [35, 37, "location"], [39, 39, "location"], [41, 41, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 17, 20, "physical", "", false, false], [17, 20, 22, 22, "physical", "", false, false], [22, 22, 24, 24, "physical", "", false, false], [28, 32, 35, 37, "physical", "", false, false], [35, 37, 39, 39, "physical", "", false, false], [39, 39, 41, 41, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "the", "first", "year", "of", "Mission", "8", ",", "the", "US", "site", "was", "held", "at", "the", "Georgia", "Institute", "of", "Technology", "in", "Atlanta", ",", "Georgia", ",", "and", "the", "Asia", "/", "Pacific", "site", "was", "held", "at", "Beihang", "University", "Gymnasium", "in", "Beijing", ",", "China", "."], "sentence-detokenized": "In 2018, the first year of Mission 8, the US site was held at the Georgia Institute of Technology in Atlanta, Georgia, and the Asia/Pacific site was held at Beihang University Gymnasium in Beijing, China.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 18], [19, 23], [24, 26], [27, 34], [35, 36], [36, 37], [38, 41], [42, 44], [45, 49], [50, 53], [54, 58], [59, 61], [62, 65], [66, 73], [74, 83], [84, 86], [87, 97], [98, 100], [101, 108], [108, 109], [110, 117], [117, 118], [119, 122], [123, 126], [127, 131], [131, 132], [132, 139], [140, 144], [145, 148], [149, 153], [154, 156], [157, 164], [165, 175], [176, 185], [186, 188], [189, 196], [196, 197], [198, 203], [203, 204]]}
{"doc_key": "ai-dev-271", "ner": [[0, 1, "field"], [6, 7, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "origin", "", false, false], [0, 1, 6, 7, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "is", "strongly", "related", "to", "pattern", "recognition", "and", "derives", "from", "artificial", "intelligence", "."], "sentence-detokenized": "Machine learning is strongly related to pattern recognition and derives from artificial intelligence.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 28], [29, 36], [37, 39], [40, 47], [48, 59], [60, 63], [64, 71], [72, 76], [77, 87], [88, 100], [100, 101]]}
{"doc_key": "ai-dev-272", "ner": [[16, 18, "product"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "comes", "with", "3", "Java", "games", "that", "are", "controlled", "with", "the", "remote", "control", "and", "displayed", "on", "the", "LCD", "screen", "."], "sentence-detokenized": "It comes with 3 Java games that are controlled with the remote control and displayed on the LCD screen.", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 15], [16, 20], [21, 26], [27, 31], [32, 35], [36, 46], [47, 51], [52, 55], [56, 62], [63, 70], [71, 74], [75, 84], [85, 87], [88, 91], [92, 95], [96, 102], [102, 103]]}
{"doc_key": "ai-dev-273", "ner": [[5, 17, "task"], [18, 20, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 20, 5, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "commercially", "successful", "but", "specialised", "computer", "vision", "-", "based", "technique", "for", "estimating", "the", "position", "of", "articulated", "bodies", "is", "optical", "motion", "capture", "."], "sentence-detokenized": "A commercially successful but specialised computer vision-based technique for estimating the position of articulated bodies is optical motion capture.", "token2charspan": [[0, 1], [2, 14], [15, 25], [26, 29], [30, 41], [42, 50], [51, 57], [57, 58], [58, 63], [64, 73], [74, 77], [78, 88], [89, 92], [93, 101], [102, 104], [105, 116], [117, 123], [124, 126], [127, 134], [135, 141], [142, 149], [149, 150]]}
{"doc_key": "ai-dev-274", "ner": [[0, 1, "organisation"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 9, 10, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "SMC", "is", "very", "similar", "to", "the", "more", "popular", "Jaccard", "index", "."], "sentence-detokenized": "The SMC is very similar to the more popular Jaccard index.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 15], [16, 23], [24, 26], [27, 30], [31, 35], [36, 43], [44, 51], [52, 57], [57, 58]]}
{"doc_key": "ai-dev-275", "ner": [[0, 0, "product"], [2, 6, "product"], [8, 11, "product"], [20, 21, "researcher"], [27, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 11, "named", "", false, false], [0, 0, 20, 21, "artifact", "", false, false], [0, 0, 27, 27, "artifact", "", false, false], [2, 6, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", "or", "Programmable", "Universal", "Manipulation", "Arm", ")", "is", "an", "industrial", "robotic", "arm", "developed", "by", "Victor", "Scheinman", "of", "the", "pioneering", "robotics", "company", "Unimation", "."], "sentence-detokenized": "PUMA (Programmable Universal Machine for Assembly or Programmable Universal Manipulation Arm) is an industrial robotic arm developed by Victor Scheinman of the pioneering robotics company Unimation.", "token2charspan": [[0, 4], [5, 6], [6, 18], [19, 28], [29, 36], [37, 40], [41, 49], [50, 52], [53, 65], [66, 75], [76, 88], [89, 92], [92, 93], [94, 96], [97, 99], [100, 110], [111, 118], [119, 122], [123, 132], [133, 135], [136, 142], [143, 152], [153, 155], [156, 159], [160, 170], [171, 179], [180, 187], [188, 197], [197, 198]]}
{"doc_key": "ai-dev-276", "ner": [[4, 4, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "written", "in", "Python", "."], "sentence-detokenized": "It is written in Python.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 23], [23, 24]]}
{"doc_key": "ai-dev-277", "ner": [[0, 0, "misc"], [2, 4, "misc"], [12, 12, "field"], [14, 15, "field"], [17, 17, "field"], [23, 24, "field"], [26, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7], "relations": [[0, 0, 2, 4, "related-to", "metric_for", true, false], [0, 0, 12, 12, "part-of", "", false, false], [0, 0, 14, 15, "part-of", "", false, false], [0, 0, 17, 17, "part-of", "", false, false], [0, 0, 23, 24, "part-of", "", false, false], [0, 0, 26, 26, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6], "sentence": ["Bandwidth", "in", "hertz", "is", "a", "key", "concept", "in", "many", "fields", ",", "including", "electronics", ",", "information", "theory", ",", "digital", "communications", ",", "radio", "communications", ",", "signal", "processing", "and", "spectroscopy", ",", "and", "it", "is", "one", "of", "the", "determining", "factors", "for", "the", "capacity", "of", "a", "given", "communication", "channel", "."], "sentence-detokenized": "Bandwidth in hertz is a key concept in many fields, including electronics, information theory, digital communications, radio communications, signal processing and spectroscopy, and it is one of the determining factors for the capacity of a given communication channel.", "token2charspan": [[0, 9], [10, 12], [13, 18], [19, 21], [22, 23], [24, 27], [28, 35], [36, 38], [39, 43], [44, 50], [50, 51], [52, 61], [62, 73], [73, 74], [75, 86], [87, 93], [93, 94], [95, 102], [103, 117], [117, 118], [119, 124], [125, 139], [139, 140], [141, 147], [148, 158], [159, 162], [163, 175], [175, 176], [177, 180], [181, 183], [184, 186], [187, 190], [191, 193], [194, 197], [198, 209], [210, 217], [218, 221], [222, 225], [226, 234], [235, 237], [238, 239], [240, 245], [246, 259], [260, 267], [267, 268]]}
{"doc_key": "ai-dev-278", "ner": [[9, 9, "algorithm"], [11, 11, "algorithm"], [17, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 17, 20, "part-of", "", false, false], [11, 11, 17, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["If", "a", "convex", "loss", "is", "used", "(", "as", "in", "AdaBoost", ",", "LogitBoost", "and", "all", "members", "of", "the", "AnyBoost", "family", "of", "algorithms", ")", ",", "a", "larger", "margin", "example", "will", "receive", "less", "(", "or", "equal", ")", "weight", "than", "a", "smaller", "margin", "example", "."], "sentence-detokenized": "If a convex loss is used (as in AdaBoost, LogitBoost and all members of the AnyBoost family of algorithms), a larger margin example will receive less (or equal) weight than a smaller margin example.", "token2charspan": [[0, 2], [3, 4], [5, 11], [12, 16], [17, 19], [20, 24], [25, 26], [26, 28], [29, 31], [32, 40], [40, 41], [42, 52], [53, 56], [57, 60], [61, 68], [69, 71], [72, 75], [76, 84], [85, 91], [92, 94], [95, 105], [105, 106], [106, 107], [108, 109], [110, 116], [117, 123], [124, 131], [132, 136], [137, 144], [145, 149], [150, 151], [151, 153], [154, 159], [159, 160], [161, 167], [168, 172], [173, 174], [175, 182], [183, 189], [190, 197], [197, 198]]}
{"doc_key": "ai-dev-279", "ner": [[0, 1, "researcher"], [7, 8, "researcher"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sepp", "Hochreiter", "'s", "diploma", "thesis", "from", "1991", "Sepp", "Hochreiter", "."], "sentence-detokenized": "Sepp Hochreiter's diploma thesis from 1991 Sepp Hochreiter.", "token2charspan": [[0, 4], [5, 15], [15, 17], [18, 25], [26, 32], [33, 37], [38, 42], [43, 47], [48, 58], [58, 59]]}
{"doc_key": "ai-dev-280", "ner": [[4, 5, "algorithm"], [7, 7, "algorithm"], [14, 14, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"], [27, 28, "algorithm"], [31, 32, "algorithm"], [34, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[7, 7, 4, 5, "named", "", false, false], [17, 19, 27, 28, "related-to", "", true, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["Typical", "discriminative", "models", "include", "logistic", "regression", "(", "LR", ")", ",", "support", "vector", "machines", "(", "SVM", ")", ",", "conditional", "random", "fields", "(", "CRF", ")", "(", "specified", "over", "an", "undirected", "graph", ")", ",", "decision", "trees", ",", "neural", "networks", "and", "many", "others", "."], "sentence-detokenized": "Typical discriminative models include logistic regression (LR), support vector machines (SVM), conditional random fields (CRF) (specified over an undirected graph), decision trees, neural networks and many others.", "token2charspan": [[0, 7], [8, 22], [23, 29], [30, 37], [38, 46], [47, 57], [58, 59], [59, 61], [61, 62], [62, 63], [64, 71], [72, 78], [79, 87], [88, 89], [89, 92], [92, 93], [93, 94], [95, 106], [107, 113], [114, 120], [121, 122], [122, 125], [125, 126], [127, 128], [128, 137], [138, 142], [143, 145], [146, 156], [157, 162], [162, 163], [163, 164], [165, 173], [174, 179], [179, 180], [181, 187], [188, 196], [197, 200], [201, 205], [206, 212], [212, 213]]}
{"doc_key": "ai-dev-281", "ner": [[11, 13, "metrics"], [32, 34, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "also", "possible", "to", "use", "these", "probabilities", "and", "evaluate", "the", "mean", "squared", "error", "(", "or", "other", "similar", "measure", ")", "between", "the", "probabilities", "and", "the", "actual", "values", "and", "then", "combine", "this", "with", "the", "confusion", "matrix", "to", "create", "very", "efficient", "fitness", "functions", "for", "logistic", "regression", "."], "sentence-detokenized": "It is also possible to use these probabilities and evaluate the mean squared error (or other similar measure) between the probabilities and the actual values and then combine this with the confusion matrix to create very efficient fitness functions for logistic regression.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 19], [20, 22], [23, 26], [27, 32], [33, 46], [47, 50], [51, 59], [60, 63], [64, 68], [69, 76], [77, 82], [83, 84], [84, 86], [87, 92], [93, 100], [101, 108], [108, 109], [110, 117], [118, 121], [122, 135], [136, 139], [140, 143], [144, 150], [151, 157], [158, 161], [162, 166], [167, 174], [175, 179], [180, 184], [185, 188], [189, 198], [199, 205], [206, 208], [209, 215], [216, 220], [221, 230], [231, 238], [239, 248], [249, 252], [253, 261], [262, 272], [272, 273]]}
{"doc_key": "ai-dev-282", "ner": [[0, 1, "product"], [7, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 7, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VoiceOver", "was", "first", "used", "in", "2005", "in", "Mac", "OS", "X", "Tiger", "(", "10.4", ")", "."], "sentence-detokenized": "VoiceOver was first used in 2005 in Mac OS X Tiger (10.4).", "token2charspan": [[0, 9], [10, 13], [14, 19], [20, 24], [25, 27], [28, 32], [33, 35], [36, 39], [40, 42], [43, 44], [45, 50], [51, 52], [52, 56], [56, 57], [57, 58]]}
{"doc_key": "ai-dev-283", "ner": [[13, 14, "algorithm"], [20, 21, "misc"], [25, 26, "metrics"], [28, 30, "algorithm"], [60, 64, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 14, 20, 21, "related-to", "applied_to", false, false], [25, 26, 20, 21, "type-of", "", false, false], [25, 26, 28, 30, "related-to", "used_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "practice", ",", "machine", "learning", "algorithms", "cope", "with", "this", "either", "by", "applying", "a", "convex", "approximation", "to", "the", "0", "-", "1", "loss", "function", "(", "such", "as", "hinge", "loss", "for", "support", "vector", "machines", ")", ",", "which", "is", "easier", "to", "optimize", ",", "or", "by", "imposing", "assumptions", "on", "the", "distribution", "mathP", "(", "x", ",", "y", ")", "/", "math", "(", "and", "thus", "ceasing", "to", "be", "agnostic", "learning", "algorithms", ",", "to", "which", "the", "above", "result", "applies", ")", "."], "sentence-detokenized": "In practice, machine learning algorithms cope with this either by applying a convex approximation to the 0-1 loss function (such as hinge loss for support vector machines), which is easier to optimize, or by imposing assumptions on the distribution mathP (x, y) / math (and thus ceasing to be agnostic learning algorithms, to which the above result applies).", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 20], [21, 29], [30, 40], [41, 45], [46, 50], [51, 55], [56, 62], [63, 65], [66, 74], [75, 76], [77, 83], [84, 97], [98, 100], [101, 104], [105, 106], [106, 107], [107, 108], [109, 113], [114, 122], [123, 124], [124, 128], [129, 131], [132, 137], [138, 142], [143, 146], [147, 154], [155, 161], [162, 170], [170, 171], [171, 172], [173, 178], [179, 181], [182, 188], [189, 191], [192, 200], [200, 201], [202, 204], [205, 207], [208, 216], [217, 228], [229, 231], [232, 235], [236, 248], [249, 254], [255, 256], [256, 257], [257, 258], [259, 260], [260, 261], [262, 263], [264, 268], [269, 270], [270, 273], [274, 278], [279, 286], [287, 289], [290, 292], [293, 301], [302, 310], [311, 321], [321, 322], [323, 325], [326, 331], [332, 335], [336, 341], [342, 348], [349, 356], [356, 357], [357, 358]]}
{"doc_key": "ai-dev-284", "ner": [[0, 0, "misc"], [11, 13, "field"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 13, "usage", "", false, false], [0, 0, 16, 17, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Westworld", "(", "1973", ")", "was", "the", "first", "feature", "film", "to", "use", "digital", "imaging", "to", "simulate", "an", "android", "'s", "point", "of", "view", "."], "sentence-detokenized": "Westworld (1973) was the first feature film to use digital imaging to simulate an android's point of view.", "token2charspan": [[0, 9], [10, 11], [11, 15], [15, 16], [17, 20], [21, 24], [25, 30], [31, 38], [39, 43], [44, 46], [47, 50], [51, 58], [59, 66], [67, 69], [70, 78], [79, 81], [82, 89], [89, 91], [92, 97], [98, 100], [101, 105], [105, 106]]}
{"doc_key": "ai-dev-285", "ner": [[7, 8, "task"], [10, 11, "task"], [13, 14, "task"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "now", "also", "widely", "used", "in", "speech", "recognition", ",", "speech", "synthesis", ",", "diary", "writing", ",", "Xavier", "Anguera", "et", "al", "."], "sentence-detokenized": "It is now also widely used in speech recognition, speech synthesis, diary writing, Xavier Anguera et al.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 14], [15, 21], [22, 26], [27, 29], [30, 36], [37, 48], [48, 49], [50, 56], [57, 66], [66, 67], [68, 73], [74, 81], [81, 82], [83, 89], [90, 97], [98, 100], [101, 103], [103, 104]]}
{"doc_key": "ai-dev-286", "ner": [[9, 12, "algorithm"], [15, 16, "algorithm"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 16, 9, 12, "type-of", "", false, false], [19, 21, 9, 12, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Here", ",", "math", "\\", "sigma", "/", "math", "is", "an", "elementwise", "activation", "function", "such", "as", "a", "sigmoid", "function", "or", "a", "rectified", "linear", "unit", "."], "sentence-detokenized": "Here, math\\ sigma/math is an elementwise activation function such as a sigmoid function or a rectified linear unit.", "token2charspan": [[0, 4], [4, 5], [6, 10], [10, 11], [12, 17], [17, 18], [18, 22], [23, 25], [26, 28], [29, 40], [41, 51], [52, 60], [61, 65], [66, 68], [69, 70], [71, 78], [79, 87], [88, 90], [91, 92], [93, 102], [103, 109], [110, 114], [114, 115]]}
{"doc_key": "ai-dev-287", "ner": [[8, 8, "algorithm"], [22, 22, "misc"], [24, 24, "misc"], [27, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "phonetic", "-", "based", "(", "i.e.", ",", "all", "hidden", "Markov", "model", "-", "based", ")", "approaches", "required", "separate", "components", "and", "training", "for", "the", "pronunciation", ",", "acoustics", ",", "and", "language", "models", "."], "sentence-detokenized": "Traditional phonetic-based (i.e., all hidden Markov model-based) approaches required separate components and training for the pronunciation, acoustics, and language models.", "token2charspan": [[0, 11], [12, 20], [20, 21], [21, 26], [27, 28], [28, 32], [32, 33], [34, 37], [38, 44], [45, 51], [52, 57], [57, 58], [58, 63], [63, 64], [65, 75], [76, 84], [85, 93], [94, 104], [105, 108], [109, 117], [118, 121], [122, 125], [126, 139], [139, 140], [141, 150], [150, 151], [152, 155], [156, 164], [165, 171], [171, 172]]}
{"doc_key": "ai-dev-288", "ner": [[0, 3, "algorithm"], [7, 8, "field"], [10, 11, "field"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 13, 14, "related-to", "used_for", false, false], [7, 8, 0, 3, "usage", "", false, false], [10, 11, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Robert", "'s", "cross", "operator", "is", "used", "in", "image", "processing", "and", "computer", "vision", "for", "edge", "detection", "."], "sentence-detokenized": "Robert's cross operator is used in image processing and computer vision for edge detection.", "token2charspan": [[0, 6], [6, 8], [9, 14], [15, 23], [24, 26], [27, 31], [32, 34], [35, 40], [41, 51], [52, 55], [56, 64], [65, 71], [72, 75], [76, 80], [81, 90], [90, 91]]}
{"doc_key": "ai-dev-289", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [23, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 23, 26, "opposite", "", false, false], [5, 5, 23, 26, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "values", "for", "sensitivity", "and", "specificity", "are", "independent", "of", "the", "percentage", "of", "positive", "cases", "in", "the", "population", "of", "interest", "(", "as", "opposed", "to", "precision", ",", "for", "example", ")", "."], "sentence-detokenized": "The values for sensitivity and specificity are independent of the percentage of positive cases in the population of interest (as opposed to precision, for example).", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 26], [27, 30], [31, 42], [43, 46], [47, 58], [59, 61], [62, 65], [66, 76], [77, 79], [80, 88], [89, 94], [95, 97], [98, 101], [102, 112], [113, 115], [116, 124], [125, 126], [126, 128], [129, 136], [137, 139], [140, 149], [149, 150], [151, 154], [155, 162], [162, 163], [163, 164]]}
{"doc_key": "ai-dev-290", "ner": [[1, 3, "algorithm"], [10, 10, "misc"], [12, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 1, 3, "topic", "", false, false], [10, 10, 12, 13, "artifact", "", false, false], [10, 10, 15, 16, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["But", "perceptron", "models", "were", "made", "very", "unpopular", "by", "the", "book", "Perceptrons", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", ",", "published", "in", "1969", "."], "sentence-detokenized": "But perceptron models were made very unpopular by the book Perceptrons by Marvin Minsky and Seymour Papert, published in 1969.", "token2charspan": [[0, 3], [4, 14], [15, 21], [22, 26], [27, 31], [32, 36], [37, 46], [47, 49], [50, 53], [54, 58], [59, 70], [71, 73], [74, 80], [81, 87], [88, 91], [92, 99], [100, 106], [106, 107], [108, 117], [118, 120], [121, 125], [125, 126]]}
{"doc_key": "ai-dev-291", "ner": [[2, 4, "conference"], [9, 9, "organisation"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 4, 24, 26, "topic", "", false, false], [9, 9, 2, 4, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["At", "the", "Document", "Understanding", "Conferences", ",", "held", "annually", "by", "NIST", ",", "sophisticated", "evaluation", "criteria", "have", "been", "developed", "for", "techniques", "that", "address", "the", "challenge", "of", "summarizing", "multiple", "documents", "."], "sentence-detokenized": "At the Document Understanding Conferences, held annually by NIST, sophisticated evaluation criteria have been developed for techniques that address the challenge of summarizing multiple documents.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 29], [30, 41], [41, 42], [43, 47], [48, 56], [57, 59], [60, 64], [64, 65], [66, 79], [80, 90], [91, 99], [100, 104], [105, 109], [110, 119], [120, 123], [124, 134], [135, 139], [140, 147], [148, 151], [152, 161], [162, 164], [165, 176], [177, 185], [186, 195], [195, 196]]}
{"doc_key": "ai-dev-292", "ner": [[1, 2, "product"], [25, 26, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 25, 26, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "parallel", "manipulator", "is", "designed", "so", "that", "each", "chain", "is", "usually", "short", "and", "simple", "and", "can", "thus", "be", "rigid", "against", "unwanted", "movement", "compared", "to", "a", "series", "manipulator", "."], "sentence-detokenized": "A parallel manipulator is designed so that each chain is usually short and simple and can thus be rigid against unwanted movement compared to a series manipulator.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 34], [35, 37], [38, 42], [43, 47], [48, 53], [54, 56], [57, 64], [65, 70], [71, 74], [75, 81], [82, 85], [86, 89], [90, 94], [95, 97], [98, 103], [104, 111], [112, 120], [121, 129], [130, 138], [139, 141], [142, 143], [144, 150], [151, 162], [162, 163]]}
{"doc_key": "ai-dev-293", "ner": [[26, 26, "misc"], [28, 30, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "the", "manipulator", "that", "makes", "the", "robot", "move", ",", "and", "the", "design", "of", "these", "systems", "can", "be", "divided", "into", "several", "common", "types", ",", "such", "as", "SCARA", "and", "Cartesian", "coordinate", "robots", ",", "which", "use", "different", "coordinate", "systems", "to", "control", "the", "machine", "'s", "arms", "."], "sentence-detokenized": "It is the manipulator that makes the robot move, and the design of these systems can be divided into several common types, such as SCARA and Cartesian coordinate robots, which use different coordinate systems to control the machine's arms.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 21], [22, 26], [27, 32], [33, 36], [37, 42], [43, 47], [47, 48], [49, 52], [53, 56], [57, 63], [64, 66], [67, 72], [73, 80], [81, 84], [85, 87], [88, 95], [96, 100], [101, 108], [109, 115], [116, 121], [121, 122], [123, 127], [128, 130], [131, 136], [137, 140], [141, 150], [151, 161], [162, 168], [168, 169], [170, 175], [176, 179], [180, 189], [190, 200], [201, 208], [209, 211], [212, 219], [220, 223], [224, 231], [231, 233], [234, 238], [238, 239]]}
{"doc_key": "ai-dev-294", "ner": [[2, 2, "country"], [10, 13, "organisation"], [16, 21, "organisation"], [24, 27, "organisation"], [30, 32, "organisation"], [35, 41, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 13, 2, 2, "physical", "", false, false], [16, 21, 2, 2, "physical", "", false, false], [24, 27, 2, 2, "physical", "", false, false], [30, 32, 2, 2, "physical", "", false, false], [35, 41, 2, 2, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "US", ",", "he", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "Linguistic", "Society", "of", "America", ",", "the", "American", "Philosophical", "Association", "and", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In the US, he is a member of the National Academy of Sciences, the American Academy of Arts and Sciences, the Linguistic Society of America, the American Philosophical Association and the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 6], [7, 9], [9, 10], [11, 13], [14, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 41], [42, 49], [50, 52], [53, 61], [61, 62], [63, 66], [67, 75], [76, 83], [84, 86], [87, 91], [92, 95], [96, 104], [104, 105], [106, 109], [110, 120], [121, 128], [129, 131], [132, 139], [139, 140], [141, 144], [145, 153], [154, 167], [168, 179], [180, 183], [184, 187], [188, 196], [197, 208], [209, 212], [213, 216], [217, 228], [229, 231], [232, 239], [239, 240]]}
{"doc_key": "ai-dev-295", "ner": [[9, 11, "algorithm"], [13, 13, "algorithm"], [20, 21, "algorithm"], [27, 28, "algorithm"], [33, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 11, 20, 21, "named", "", false, false], [13, 13, 9, 11, "named", "", false, false], [20, 21, 27, 28, "compare", "", false, false], [20, 21, 33, 34, "related-to", "performs", false, false], [27, 28, 33, 34, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["They", "gained", "much", "attention", "with", "the", "popularity", "of", "the", "support", "vector", "machine", "(", "SVM", ")", "in", "the", "1990s", ",", "when", "the", "SVM", "proved", "to", "be", "competitive", "with", "neural", "networks", "on", "tasks", "such", "as", "handwriting", "recognition", "."], "sentence-detokenized": "They gained much attention with the popularity of the support vector machine (SVM) in the 1990s, when the SVM proved to be competitive with neural networks on tasks such as handwriting recognition.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 26], [27, 31], [32, 35], [36, 46], [47, 49], [50, 53], [54, 61], [62, 68], [69, 76], [77, 78], [78, 81], [81, 82], [83, 85], [86, 89], [90, 95], [95, 96], [97, 101], [102, 105], [106, 109], [110, 116], [117, 119], [120, 122], [123, 134], [135, 139], [140, 146], [147, 155], [156, 158], [159, 164], [165, 169], [170, 172], [173, 184], [185, 196], [196, 197]]}
{"doc_key": "ai-dev-296", "ner": [[2, 3, "misc"], [9, 9, "misc"], [13, 14, "algorithm"], [22, 25, "misc"], [27, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 9, "usage", "", false, false], [2, 3, 22, 25, "usage", "", false, false], [9, 9, 13, 14, "origin", "result_of_algorithm", false, false], [22, 25, 27, 28, "origin", "result_of_algorithm", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["An", "empirical", "whitening", "transformation", "is", "obtained", "by", "estimating", "the", "covariance", "(", "e.g.", "by", "maximum", "likelihood", ")", "and", "then", "constructing", "a", "corresponding", "estimated", "whitening", "matrix", "(", "e.g.", "by", "Cholesky", "decomposition", ")", "."], "sentence-detokenized": "An empirical whitening transformation is obtained by estimating the covariance (e.g. by maximum likelihood) and then constructing a corresponding estimated whitening matrix (e.g. by Cholesky decomposition).", "token2charspan": [[0, 2], [3, 12], [13, 22], [23, 37], [38, 40], [41, 49], [50, 52], [53, 63], [64, 67], [68, 78], [79, 80], [80, 84], [85, 87], [88, 95], [96, 106], [106, 107], [108, 111], [112, 116], [117, 129], [130, 131], [132, 145], [146, 155], [156, 165], [166, 172], [173, 174], [174, 178], [179, 181], [182, 190], [191, 204], [204, 205], [205, 206]]}
{"doc_key": "ai-dev-297", "ner": [[0, 2, "organisation"], [8, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 8, 0, 2, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["IAI", "is", "the", "world", "'s", "largest", "manufacturer", "of", "Cartesian", "coordinate", "robots", "and", "is", "an", "established", "leader", "in", "low", "-", "cost", ",", "high", "-", "performance", "SCARA", "robots", "."], "sentence-detokenized": "IAI is the world's largest manufacturer of Cartesian coordinate robots and is an established leader in low-cost, high-performance SCARA robots.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [16, 18], [19, 26], [27, 39], [40, 42], [43, 52], [53, 63], [64, 70], [71, 74], [75, 77], [78, 80], [81, 92], [93, 99], [100, 102], [103, 106], [106, 107], [107, 111], [111, 112], [113, 117], [117, 118], [118, 129], [130, 135], [136, 142], [142, 143]]}
{"doc_key": "ai-dev-298", "ner": [[10, 11, "field"], [13, 14, "field"], [16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 28, "field"], [30, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["Formal", "concept", "analysis", "has", "practical", "applications", "in", "areas", "such", "as", "data", "mining", ",", "text", "mining", ",", "machine", "learning", ",", "knowledge", "management", ",", "semantic", "web", ",", "software", "development", ",", "chemistry", "and", "biology", "."], "sentence-detokenized": "Formal concept analysis has practical applications in areas such as data mining, text mining, machine learning, knowledge management, semantic web, software development, chemistry and biology.", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 27], [28, 37], [38, 50], [51, 53], [54, 59], [60, 64], [65, 67], [68, 72], [73, 79], [79, 80], [81, 85], [86, 92], [92, 93], [94, 101], [102, 110], [110, 111], [112, 121], [122, 132], [132, 133], [134, 142], [143, 146], [146, 147], [148, 156], [157, 168], [168, 169], [170, 179], [180, 183], [184, 191], [191, 192]]}
{"doc_key": "ai-dev-299", "ner": [[1, 2, "field"], [4, 6, "field"], [10, 11, "field"], [17, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 17, 22, "part-of", "", false, false], [10, 11, 4, 6, "named", "", false, false], [17, 22, 1, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["In", "computer", "science", ",", "computational", "learning", "theory", "(", "or", "just", "learning", "theory", ")", "is", "a", "subfield", "of", "artificial", "intelligence", "that", "deals", "with", "the", "design", "and", "analysis", "of", "machine", "learning", "algorithms", "."], "sentence-detokenized": "In computer science, computational learning theory (or just learning theory) is a subfield of artificial intelligence that deals with the design and analysis of machine learning algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 34], [35, 43], [44, 50], [51, 52], [52, 54], [55, 59], [60, 68], [69, 75], [75, 76], [77, 79], [80, 81], [82, 90], [91, 93], [94, 104], [105, 117], [118, 122], [123, 128], [129, 133], [134, 137], [138, 144], [145, 148], [149, 157], [158, 160], [161, 168], [169, 177], [178, 188], [188, 189]]}
{"doc_key": "ai-dev-300", "ner": [[0, 1, "algorithm"], [3, 5, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 5, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "Filtering", "(", "CF", ")", "is", "a", "technique", "used", "by", "recommendation", "systems", "."], "sentence-detokenized": "Collaborative Filtering (CF) is a technique used by recommendation systems.", "token2charspan": [[0, 13], [14, 23], [24, 25], [25, 27], [27, 28], [29, 31], [32, 33], [34, 43], [44, 48], [49, 51], [52, 66], [67, 74], [74, 75]]}
{"doc_key": "ai-dev-301", "ner": [[1, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "FALSE", "positive", "rate", "is", "the", "proportion", "of", "all", "negative", "results", "that", "still", "yield", "positive", "test", "results", ",", "i.e.", "the", "conditional", "probability", "of", "a", "positive", "test", "result", "given", "an", "event", "that", "was", "not", "present", "."], "sentence-detokenized": "The FALSE positive rate is the proportion of all negative results that still yield positive test results, i.e. the conditional probability of a positive test result given an event that was not present.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 23], [24, 26], [27, 30], [31, 41], [42, 44], [45, 48], [49, 57], [58, 65], [66, 70], [71, 76], [77, 82], [83, 91], [92, 96], [97, 104], [104, 105], [106, 110], [111, 114], [115, 126], [127, 138], [139, 141], [142, 143], [144, 152], [153, 157], [158, 164], [165, 170], [171, 173], [174, 179], [180, 184], [185, 188], [189, 192], [193, 200], [200, 201]]}
{"doc_key": "ai-dev-302", "ner": [[1, 15, "misc"], [38, 38, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 15, 38, 38, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "VLDB", "'", "8", ":", "Proceedings", "of", "the", "34th", "International", "Conference", "on", "Very", "Large", "Data", "Bases", ",", "pages", "422-433", ".", "showed", "that", "the", "given", "values", "for", "mathC", "/", "math", "and", "mathK", "/", "math", "generally", "imply", "a", "relatively", "low", "accuracy", "of", "iteratively", "computed", "SimRank", "scores", "."], "sentence-detokenized": "In VLDB '8: Proceedings of the 34th International Conference on Very Large Data Bases, pages 422-433. showed that the given values for mathC/math and mathK/math generally imply a relatively low accuracy of iteratively computed SimRank scores.", "token2charspan": [[0, 2], [3, 7], [8, 9], [9, 10], [10, 11], [12, 23], [24, 26], [27, 30], [31, 35], [36, 49], [50, 60], [61, 63], [64, 68], [69, 74], [75, 79], [80, 85], [85, 86], [87, 92], [93, 100], [100, 101], [102, 108], [109, 113], [114, 117], [118, 123], [124, 130], [131, 134], [135, 140], [140, 141], [141, 145], [146, 149], [150, 155], [155, 156], [156, 160], [161, 170], [171, 176], [177, 178], [179, 189], [190, 193], [194, 202], [203, 205], [206, 217], [218, 226], [227, 234], [235, 241], [241, 242]]}
{"doc_key": "ai-dev-303", "ner": [[0, 3, "misc"], [4, 4, "misc"], [15, 16, "person"], [18, 20, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 0, 3, "general-affiliation", "", false, false], [4, 4, 15, 16, "artifact", "", false, false], [4, 4, 18, 20, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "science", "fiction", "drama", "Sense8", "premiered", "in", "June", "2015", "and", "was", "written", "and", "produced", "by", "The", "Wachowskis", "and", "J.", "Michael", "Straczynski", "."], "sentence-detokenized": "The science fiction drama Sense8 premiered in June 2015 and was written and produced by The Wachowskis and J. Michael Straczynski.", "token2charspan": [[0, 3], [4, 11], [12, 19], [20, 25], [26, 32], [33, 42], [43, 45], [46, 50], [51, 55], [56, 59], [60, 63], [64, 71], [72, 75], [76, 84], [85, 87], [88, 91], [92, 102], [103, 106], [107, 109], [110, 117], [118, 129], [129, 130]]}
{"doc_key": "ai-dev-304", "ner": [[1, 1, "misc"], [6, 7, "product"], [26, 28, "misc"], [36, 36, "country"], [38, 38, "country"], [40, 40, "country"], [42, 42, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 1, 6, 7, "topic", "", false, false], [36, 36, 26, 28, "type-of", "", false, false], [38, 38, 26, 28, "type-of", "", false, false], [40, 40, 26, 28, "type-of", "", false, false], [42, 42, 26, 28, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Although", "Eurotra", "never", "delivered", "a", "working", "MT", "system", ",", "the", "project", "had", "a", "far", "-", "reaching", "long", "-", "term", "impact", "on", "the", "nascent", "language", "industries", "in", "European", "Member", "States", ",", "particularly", "in", "the", "southern", "countries", "of", "Greece", ",", "Italy", ",", "Spain", "and", "Portugal", "."], "sentence-detokenized": "Although Eurotra never delivered a working MT system, the project had a far-reaching long-term impact on the nascent language industries in European Member States, particularly in the southern countries of Greece, Italy, Spain and Portugal.", "token2charspan": [[0, 8], [9, 16], [17, 22], [23, 32], [33, 34], [35, 42], [43, 45], [46, 52], [52, 53], [54, 57], [58, 65], [66, 69], [70, 71], [72, 75], [75, 76], [76, 84], [85, 89], [89, 90], [90, 94], [95, 101], [102, 104], [105, 108], [109, 116], [117, 125], [126, 136], [137, 139], [140, 148], [149, 155], [156, 162], [162, 163], [164, 176], [177, 179], [180, 183], [184, 192], [193, 202], [203, 205], [206, 212], [212, 213], [214, 219], [219, 220], [221, 226], [227, 230], [231, 239], [239, 240]]}
{"doc_key": "ai-dev-305", "ner": [[0, 1, "algorithm"], [6, 7, "task"], [14, 16, "task"], [18, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 7, 0, 1, "usage", "", true, false], [14, 16, 6, 7, "named", "", false, false], [18, 18, 14, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autoencoders", "have", "been", "successfully", "used", "for", "machine", "translation", "of", "human", "languages", ",", "commonly", "called", "neural", "machine", "translation", "(", "NMT", ")", "."], "sentence-detokenized": "Autoencoders have been successfully used for machine translation of human languages, commonly called neural machine translation (NMT).", "token2charspan": [[0, 12], [13, 17], [18, 22], [23, 35], [36, 40], [41, 44], [45, 52], [53, 64], [65, 67], [68, 73], [74, 83], [83, 84], [85, 93], [94, 100], [101, 107], [108, 115], [116, 127], [128, 129], [129, 132], [132, 133], [133, 134]]}
{"doc_key": "ai-dev-306", "ner": [[9, 11, "metrics"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Popular", "examples", "of", "fitness", "functions", "based", "on", "probabilities", "include", "maximum", "likelihood", "estimation", "and", "hinge", "loss", "."], "sentence-detokenized": "Popular examples of fitness functions based on probabilities include maximum likelihood estimation and hinge loss.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 37], [38, 43], [44, 46], [47, 60], [61, 68], [69, 76], [77, 87], [88, 98], [99, 102], [103, 108], [109, 113], [113, 114]]}
{"doc_key": "ai-dev-307", "ner": [[0, 3, "field"], [10, 12, "task"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 12, 0, 3, "part-of", "", false, false], [14, 15, 0, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Data", "mining", "is", "a", "related", "research", "area", "that", "focuses", "on", "exploratory", "data", "analysis", "using", "unsupervised", "learning", "."], "sentence-detokenized": "Data mining is a related research area that focuses on exploratory data analysis using unsupervised learning.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 16], [17, 24], [25, 33], [34, 38], [39, 43], [44, 51], [52, 54], [55, 66], [67, 71], [72, 80], [81, 86], [87, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-dev-308", "ner": [[0, 1, "algorithm"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 12, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "filtering", "includes", "techniques", "to", "match", "people", "with", "similar", "interests", "and", "create", "recommendation", "systems", "on", "this", "basis", "."], "sentence-detokenized": "Collaborative filtering includes techniques to match people with similar interests and create recommendation systems on this basis.", "token2charspan": [[0, 13], [14, 23], [24, 32], [33, 43], [44, 46], [47, 52], [53, 59], [60, 64], [65, 72], [73, 82], [83, 86], [87, 93], [94, 108], [109, 116], [117, 119], [120, 124], [125, 130], [130, 131]]}
{"doc_key": "ai-dev-309", "ner": [[3, 8, "algorithm"], [16, 19, "product"]], "ner_mapping_to_source": [0, 2], "relations": [[16, 19, 3, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "number", "of", "WordNet", "-", "based", "word", "concatenation", "algorithms", "are", "implemented", "in", "a", "Perl", "package", "called", "WordNet", ":", ":", "Similarity", "."], "sentence-detokenized": "A number of WordNet-based word concatenation algorithms are implemented in a Perl package called WordNet:: Similarity.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 19], [19, 20], [20, 25], [26, 30], [31, 44], [45, 55], [56, 59], [60, 71], [72, 74], [75, 76], [77, 81], [82, 89], [90, 96], [97, 104], [104, 105], [105, 106], [107, 117], [117, 118]]}
{"doc_key": "ai-dev-310", "ner": [[4, 4, "conference"], [6, 6, "conference"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 4, 4, "named", "", false, false], [10, 11, 4, 4, "temporal", "", false, false], [13, 14, 4, 4, "temporal", "", false, false], [16, 17, 4, 4, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Another", "paper", "presented", "at", "CVPR", "(", "CVPR", ")", "2000", "by", "Erik", "Miller", ",", "Nicholas", "Matsakis", "and", "Paul", "Viola", "will", "also", "be", "discussed", "."], "sentence-detokenized": "Another paper presented at CVPR (CVPR) 2000 by Erik Miller, Nicholas Matsakis and Paul Viola will also be discussed.", "token2charspan": [[0, 7], [8, 13], [14, 23], [24, 26], [27, 31], [32, 33], [33, 37], [37, 38], [39, 43], [44, 46], [47, 51], [52, 58], [58, 59], [60, 68], [69, 77], [78, 81], [82, 86], [87, 92], [93, 97], [98, 102], [103, 105], [106, 115], [115, 116]]}
{"doc_key": "ai-dev-311", "ner": [[0, 1, "algorithm"], [8, 9, "misc"], [13, 15, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 13, 15, "compare", "", false, false], [13, 15, 8, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["QC", "has", "not", "been", "evaluated", "against", "traditional", "modern", "clustering", "algorithms", ",", "except", "for", "the", "Jaccard", "index", "."], "sentence-detokenized": "QC has not been evaluated against traditional modern clustering algorithms, except for the Jaccard index.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 15], [16, 25], [26, 33], [34, 45], [46, 52], [53, 63], [64, 74], [74, 75], [76, 82], [83, 86], [87, 90], [91, 98], [99, 104], [104, 105]]}
{"doc_key": "ai-dev-312", "ner": [[2, 5, "misc"], [8, 10, "misc"], [15, 16, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 2, 5, "physical", "", false, false], [8, 10, 15, 16, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "the", "VEX", "Robotics", "World", "Championship", ",", "a", "parade", "of", "nations", "will", "be", "held", "in", "Freedom", "Hall", "with", "hundreds", "of", "students", "from", "more", "than", "30", "countries", "."], "sentence-detokenized": "During the VEX Robotics World Championship, a parade of nations will be held in Freedom Hall with hundreds of students from more than 30 countries.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 23], [24, 29], [30, 42], [42, 43], [44, 45], [46, 52], [53, 55], [56, 63], [64, 68], [69, 71], [72, 76], [77, 79], [80, 87], [88, 92], [93, 97], [98, 106], [107, 109], [110, 118], [119, 123], [124, 128], [129, 133], [134, 136], [137, 146], [146, 147]]}
{"doc_key": "ai-dev-313", "ner": [[7, 10, "metrics"], [5, 5, "metrics"], [15, 17, "metrics"], [13, 13, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 7, 10, "named", "", false, false], [13, 13, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Other", "measures", "of", "accuracy", "include", "SWER", "(", "Single", "Word", "Error", "Rate", ")", "and", "CSR", "(", "Command", "Success", "Rate", ")", "."], "sentence-detokenized": "Other measures of accuracy include SWER (Single Word Error Rate) and CSR (Command Success Rate).", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [27, 34], [35, 39], [40, 41], [41, 47], [48, 52], [53, 58], [59, 63], [63, 64], [65, 68], [69, 72], [73, 74], [74, 81], [82, 89], [90, 94], [94, 95], [95, 96]]}
{"doc_key": "ai-dev-314", "ner": [[7, 8, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "presented", "their", "methodology", "and", "results", "in", "SIGGRAPH", "2000", "."], "sentence-detokenized": "They presented their methodology and results in SIGGRAPH 2000.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 32], [33, 36], [37, 44], [45, 47], [48, 56], [57, 61], [61, 62]]}
{"doc_key": "ai-dev-315", "ner": [[0, 2, "conference"], [9, 16, "misc"], [17, 19, "conference"], [25, 30, "researcher"], [38, 39, "researcher"], [43, 45, "conference"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "KDD", "conference", "grew", "out", "of", "the", "KDD", "(", "Knowledge", "Discovery", "and", "Data", "Mining", ")", "workshops", "at", "the", "AAAI", "conferences", ",", "which", "were", "started", "by", "Gregory", "I", ".", "Piatetsky", "-", "Shapiro", "in", "1989", ",", "1991", "and", "1993", "and", "Usama", "Fayyad", "in", "1994", ".", "Machinery", "|", "ACM", "."], "sentence-detokenized": "The KDD conference grew out of the KDD (Knowledge Discovery and Data Mining) workshops at the AAAI conferences, which were started by Gregory I. Piatetsky-Shapiro in 1989, 1991 and 1993 and Usama Fayyad in 1994. Machinery | ACM.", "token2charspan": [[0, 3], [4, 7], [8, 18], [19, 23], [24, 27], [28, 30], [31, 34], [35, 38], [39, 40], [40, 49], [50, 59], [60, 63], [64, 68], [69, 75], [75, 76], [77, 86], [87, 89], [90, 93], [94, 98], [99, 110], [110, 111], [112, 117], [118, 122], [123, 130], [131, 133], [134, 141], [142, 143], [143, 144], [145, 154], [154, 155], [155, 162], [163, 165], [166, 170], [170, 171], [172, 176], [177, 180], [181, 185], [186, 189], [190, 195], [196, 202], [203, 205], [206, 210], [210, 211], [212, 221], [222, 223], [224, 227], [227, 228]]}
{"doc_key": "ai-dev-316", "ner": [[8, 11, "conference"], [13, 13, "conference"], [17, 22, "organisation"], [24, 24, "organisation"], [28, 32, "conference"], [34, 34, "conference"], [38, 44, "conference"], [46, 46, "conference"], [50, 55, "conference"], [57, 57, "conference"], [61, 66, "conference"], [68, 68, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[13, 13, 8, 11, "named", "", false, false], [24, 24, 17, 22, "named", "", false, false], [34, 34, 28, 32, "named", "", false, false], [46, 46, 38, 44, "named", "", false, false], [57, 57, 50, 55, "named", "", false, false], [68, 68, 61, 66, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["He", "has", "been", "elected", "a", "Fellow", "of", "the", "Association", "for", "Computing", "Machinery", "(", "ACM", ")", ",", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", ",", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", ",", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "the", "American", "Association", "for", "Advancement", "of", "Science", "(", "AAAS", ")", "and", "the", "Society", "for", "Optics", "and", "Photonics", "Technology", "(", "SPIE", ")", "."], "sentence-detokenized": "He has been elected a Fellow of the Association for Computing Machinery (ACM), the Institute of Electrical and Electronics Engineers (IEEE), the International Association for Pattern Recognition (IAPR), the Association for the Advancement of Artificial Intelligence (AAAI), the American Association for Advancement of Science (AAAS) and the Society for Optics and Photonics Technology (SPIE).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 21], [22, 28], [29, 31], [32, 35], [36, 47], [48, 51], [52, 61], [62, 71], [72, 73], [73, 76], [76, 77], [77, 78], [79, 82], [83, 92], [93, 95], [96, 106], [107, 110], [111, 122], [123, 132], [133, 134], [134, 138], [138, 139], [139, 140], [141, 144], [145, 158], [159, 170], [171, 174], [175, 182], [183, 194], [195, 196], [196, 200], [200, 201], [201, 202], [203, 206], [207, 218], [219, 222], [223, 226], [227, 238], [239, 241], [242, 252], [253, 265], [266, 267], [267, 271], [271, 272], [272, 273], [274, 277], [278, 286], [287, 298], [299, 302], [303, 314], [315, 317], [318, 325], [326, 327], [327, 331], [331, 332], [333, 336], [337, 340], [341, 348], [349, 352], [353, 359], [360, 363], [364, 373], [374, 384], [385, 386], [386, 390], [390, 391], [391, 392]]}
{"doc_key": "ai-dev-317", "ner": [[0, 1, "field"], [3, 4, "field"], [19, 20, "field"], [34, 35, "field"], [56, 59, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 19, 20, "named", "", false, false], [3, 4, 34, 35, "named", "", false, false], [34, 35, 56, 59, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "learning", "and", "data", "mining", "often", "use", "the", "same", "methods", "and", "overlap", "to", "a", "large", "extent", ",", "but", "while", "machine", "learning", "focuses", "on", "prediction", "based", "on", "known", "properties", "learned", "from", "the", "training", "data", ",", "data", "mining", "focuses", "on", "the", "discovery", "of", "(", "previously", ")", "unknown", "properties", "in", "the", "data", "(", "this", "is", "the", "analysis", "step", "of", "knowledge", "discovery", "in", "databases", ")", "."], "sentence-detokenized": "Machine learning and data mining often use the same methods and overlap to a large extent, but while machine learning focuses on prediction based on known properties learned from the training data, data mining focuses on the discovery of (previously) unknown properties in the data (this is the analysis step of knowledge discovery in databases).", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 25], [26, 32], [33, 38], [39, 42], [43, 46], [47, 51], [52, 59], [60, 63], [64, 71], [72, 74], [75, 76], [77, 82], [83, 89], [89, 90], [91, 94], [95, 100], [101, 108], [109, 117], [118, 125], [126, 128], [129, 139], [140, 145], [146, 148], [149, 154], [155, 165], [166, 173], [174, 178], [179, 182], [183, 191], [192, 196], [196, 197], [198, 202], [203, 209], [210, 217], [218, 220], [221, 224], [225, 234], [235, 237], [238, 239], [239, 249], [249, 250], [251, 258], [259, 269], [270, 272], [273, 276], [277, 281], [282, 283], [283, 287], [288, 290], [291, 294], [295, 303], [304, 308], [309, 311], [312, 321], [322, 331], [332, 334], [335, 344], [344, 345], [345, 346]]}
{"doc_key": "ai-dev-318", "ner": [[0, 1, "product"], [4, 5, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 4, 5, "general-affiliation", "", false, false], [0, 1, 4, 5, "related-to", "runs_on", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Indy", "is", "written", "in", "Java", "and", "can", "therefore", "run", "on", "most", "modern", "operating", "systems", "."], "sentence-detokenized": "Indy is written in Java and can therefore run on most modern operating systems.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 23], [24, 27], [28, 31], [32, 41], [42, 45], [46, 48], [49, 53], [54, 60], [61, 70], [71, 78], [78, 79]]}
{"doc_key": "ai-dev-319", "ner": [[0, 1, "algorithm"], [5, 7, "algorithm"], [9, 9, "algorithm"], [13, 15, "algorithm"], [17, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 7, "type-of", "", true, false], [9, 9, 5, 7, "named", "", false, false], [13, 15, 5, 7, "type-of", "", true, false], [17, 17, 13, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["NMF", "is", "an", "example", "of", "nonnegative", "quadratic", "programming", "(", "NQP", ")", "like", "the", "support", "vector", "machine", "(", "SVM", ")", "."], "sentence-detokenized": "NMF is an example of nonnegative quadratic programming (NQP) like the support vector machine (SVM).", "token2charspan": [[0, 3], [4, 6], [7, 9], [10, 17], [18, 20], [21, 32], [33, 42], [43, 54], [55, 56], [56, 59], [59, 60], [61, 65], [66, 69], [70, 77], [78, 84], [85, 92], [93, 94], [94, 97], [97, 98], [98, 99]]}
{"doc_key": "ai-dev-320", "ner": [[9, 10, "misc"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 10, 13, 14, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["The", "method", "is", "based", "on", "the", "estimation", "of", "the", "conditional", "probabilities", "using", "the", "non-parametric", "maximum", "likelihood", "method", ",", "which", "leads", "to"], "sentence-detokenized": "The method is based on the estimation of the conditional probabilities using the non-parametric maximum likelihood method, which leads to", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 26], [27, 37], [38, 40], [41, 44], [45, 56], [57, 70], [71, 76], [77, 80], [81, 95], [96, 103], [104, 114], [115, 121], [121, 122], [123, 128], [129, 134], [135, 137]]}
{"doc_key": "ai-dev-321", "ner": [[7, 7, "algorithm"], [9, 12, "algorithm"], [14, 16, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "basic", "concepts", "of", "spectral", "estimation", "include", "autocorrelation", ",", "multi", "-D", "Fourier", "transform", ",", "mean", "square", "error", "and", "entropy", "."], "sentence-detokenized": "The basic concepts of spectral estimation include autocorrelation, multi-D Fourier transform, mean square error and entropy.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 21], [22, 30], [31, 41], [42, 49], [50, 65], [65, 66], [67, 72], [72, 74], [75, 82], [83, 92], [92, 93], [94, 98], [99, 105], [106, 111], [112, 115], [116, 123], [123, 124]]}
{"doc_key": "ai-dev-322", "ner": [[3, 4, "algorithm"], [9, 9, "field"], [11, 11, "algorithm"], [13, 15, "algorithm"], [17, 18, "task"], [20, 20, "field"], [22, 22, "field"], [24, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 4, 9, 9, "part-of", "", false, false], [3, 4, 11, 11, "part-of", "", false, false], [3, 4, 13, 15, "part-of", "", false, false], [3, 4, 17, 18, "part-of", "", false, false], [3, 4, 20, 20, "part-of", "", false, false], [3, 4, 22, 22, "part-of", "", false, false], [3, 4, 24, 25, "part-of", "", false, false], [3, 4, 27, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "applications", "of", "kernel", "methods", "are", "diverse", "and", "include", "geostatistics", ",", "kriging", ",", "inverse", "distance", "weighting", ",", "3D", "reconstruction", ",", "bioinformatics", ",", "chemoinformatics", ",", "information", "extraction", "and", "handwriting", "recognition", "."], "sentence-detokenized": "The applications of kernel methods are diverse and include geostatistics, kriging, inverse distance weighting, 3D reconstruction, bioinformatics, chemoinformatics, information extraction and handwriting recognition.", "token2charspan": [[0, 3], [4, 16], [17, 19], [20, 26], [27, 34], [35, 38], [39, 46], [47, 50], [51, 58], [59, 72], [72, 73], [74, 81], [81, 82], [83, 90], [91, 99], [100, 109], [109, 110], [111, 113], [114, 128], [128, 129], [130, 144], [144, 145], [146, 162], [162, 163], [164, 175], [176, 186], [187, 190], [191, 202], [203, 214], [214, 215]]}
{"doc_key": "ai-dev-323", "ner": [[11, 11, "organisation"], [13, 17, "product"], [19, 19, "product"], [22, 22, "organisation"], [24, 28, "product"], [30, 30, "product"], [36, 36, "product"], [40, 42, "product"], [44, 46, "product"], [50, 51, "product"], [53, 54, "product"], [56, 62, "product"], [65, 66, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13], "relations": [[13, 17, 11, 11, "artifact", "", false, false], [13, 17, 36, 36, "compare", "", false, false], [13, 17, 40, 42, "compare", "", false, false], [13, 17, 44, 46, "compare", "", false, false], [13, 17, 50, 51, "compare", "", false, false], [13, 17, 53, 54, "compare", "", false, false], [13, 17, 56, 62, "compare", "", false, false], [13, 17, 65, 66, "compare", "", false, false], [19, 19, 13, 17, "named", "", false, false], [24, 28, 22, 22, "artifact", "", false, false], [24, 28, 36, 36, "compare", "", false, false], [24, 28, 40, 42, "compare", "", false, false], [24, 28, 44, 46, "compare", "", false, false], [24, 28, 50, 51, "compare", "", false, false], [24, 28, 53, 54, "compare", "", false, false], [24, 28, 56, 62, "compare", "", false, false], [24, 28, 65, 66, "compare", "", false, false], [30, 30, 24, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19], "sentence": ["Robots", "can", "be", "autonomous", "or", "semi-autonomous", "and", "range", "from", "humanoids", "like", "Honda", "'s", "Advanced", "Step", "in", "Innovative", "Mobility", "(", "ASIMO", ")", "and", "TOSY", "'s", "TOSY", "Ping", "Pong", "Playing", "Robot", "(", "TOPIO", ")", "to", "industrial", "robots", ",", "medical", "operating", "robots", ",", "patient-", "assisting", "robots", ",", "canine", "therapy", "robots", ",", "collectively", "programmed", "sword", "robots", ",", "UAV", "drones", "like", "General", "Atomic", "'s", "MQ", "-", "1", "Predator", "and", "even", "microscopic", "nanorobots", "."], "sentence-detokenized": "Robots can be autonomous or semi-autonomous and range from humanoids like Honda's Advanced Step in Innovative Mobility (ASIMO) and TOSY's TOSY Ping Pong Playing Robot (TOPIO) to industrial robots, medical operating robots, patient-assisting robots, canine therapy robots, collectively programmed sword robots, UAV drones like General Atomic's MQ-1 Predator and even microscopic nanorobots.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 24], [25, 27], [28, 43], [44, 47], [48, 53], [54, 58], [59, 68], [69, 73], [74, 79], [79, 81], [82, 90], [91, 95], [96, 98], [99, 109], [110, 118], [119, 120], [120, 125], [125, 126], [127, 130], [131, 135], [135, 137], [138, 142], [143, 147], [148, 152], [153, 160], [161, 166], [167, 168], [168, 173], [173, 174], [175, 177], [178, 188], [189, 195], [195, 196], [197, 204], [205, 214], [215, 221], [221, 222], [223, 231], [231, 240], [241, 247], [247, 248], [249, 255], [256, 263], [264, 270], [270, 271], [272, 284], [285, 295], [296, 301], [302, 308], [308, 309], [310, 313], [314, 320], [321, 325], [326, 333], [334, 340], [340, 342], [343, 345], [345, 346], [346, 347], [348, 356], [357, 360], [361, 365], [366, 377], [378, 388], [388, 389]]}
{"doc_key": "ai-dev-324", "ner": [[22, 22, "product"], [24, 25, "product"], [3, 8, "university"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[22, 22, 10, 11, "artifact", "", false, false], [22, 22, 13, 14, "artifact", "", false, false], [22, 22, 16, 17, "artifact", "", false, false], [22, 22, 19, 20, "artifact", "", false, false], [24, 25, 10, 11, "artifact", "", false, false], [24, 25, 13, 14, "artifact", "", false, false], [24, 25, 16, 17, "artifact", "", false, false], [24, 25, 19, 20, "artifact", "", false, false], [10, 11, 3, 8, "physical", "", false, false], [13, 14, 3, 8, "physical", "", false, false], [16, 17, 3, 8, "physical", "", false, false], [19, 20, 3, 8, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Built", "at", "the", "University", "of", "Edinburgh", "School", "of", "Informatics", "by", "Pat", "Ambler", ",", "Robin", "Popplestone", ",", "Austin", "Tate", "and", "Donald", "Mitchie", ",", "Freddy", "and", "Freddy", "II", "were", "robots", "capable", "of", "collecting", "wooden", "blocks", "in", "a", "matter", "of", "hours", "."], "sentence-detokenized": "Built at the University of Edinburgh School of Informatics by Pat Ambler, Robin Popplestone, Austin Tate and Donald Mitchie, Freddy and Freddy II were robots capable of collecting wooden blocks in a matter of hours.", "token2charspan": [[0, 5], [6, 8], [9, 12], [13, 23], [24, 26], [27, 36], [37, 43], [44, 46], [47, 58], [59, 61], [62, 65], [66, 72], [72, 73], [74, 79], [80, 91], [91, 92], [93, 99], [100, 104], [105, 108], [109, 115], [116, 123], [123, 124], [125, 131], [132, 135], [136, 142], [143, 145], [146, 150], [151, 157], [158, 165], [166, 168], [169, 179], [180, 186], [187, 193], [194, 196], [197, 198], [199, 205], [206, 208], [209, 214], [214, 215]]}
{"doc_key": "ai-dev-325", "ner": [[5, 5, "location"], [7, 7, "country"], [15, 15, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 7, 7, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "spent", "his", "childhood", "in", "Paris", ",", "France", ",", "where", "his", "parents", "had", "emigrated", "from", "Lithuania", "in", "the", "early", "1920s", "."], "sentence-detokenized": "He spent his childhood in Paris, France, where his parents had emigrated from Lithuania in the early 1920s.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 22], [23, 25], [26, 31], [31, 32], [33, 39], [39, 40], [41, 46], [47, 50], [51, 58], [59, 62], [63, 72], [73, 77], [78, 87], [88, 90], [91, 94], [95, 100], [101, 106], [106, 107]]}
{"doc_key": "ai-dev-326", "ner": [[0, 0, "researcher"], [4, 8, "misc"], [11, 14, "organisation"], [16, 18, "university"], [26, 30, "university"], [37, 38, "university"], [41, 43, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 4, 8, "role", "", false, false], [0, 0, 16, 18, "physical", "", false, false], [0, 0, 26, 30, "role", "", false, false], [0, 0, 37, 38, "role", "", false, false], [0, 0, 41, 43, "role", "", false, false], [4, 8, 11, 14, "part-of", "", false, false], [11, 14, 16, 18, "part-of", "", false, false], [37, 38, 26, 30, "part-of", "", false, false], [41, 43, 26, 30, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Paulos", "previously", "held", "the", "Cooper-", "Siegel", "Associate", "Professor", "Chair", "at", "the", "School", "of", "Computer", "Science", "at", "Carnegie", "Mellon", "University", ",", "where", "he", "was", "faculty", "in", "the", "Human", "-", "Computer", "Interaction", "Institute", "with", "appointments", "to", "faculty", "in", "the", "Robotics", "Institute", "and", "the", "Entertainment", "Technology", "Center", "."], "sentence-detokenized": "Paulos previously held the Cooper-Siegel Associate Professor Chair at the School of Computer Science at Carnegie Mellon University, where he was faculty in the Human-Computer Interaction Institute with appointments to faculty in the Robotics Institute and the Entertainment Technology Center.", "token2charspan": [[0, 6], [7, 17], [18, 22], [23, 26], [27, 34], [34, 40], [41, 50], [51, 60], [61, 66], [67, 69], [70, 73], [74, 80], [81, 83], [84, 92], [93, 100], [101, 103], [104, 112], [113, 119], [120, 130], [130, 131], [132, 137], [138, 140], [141, 144], [145, 152], [153, 155], [156, 159], [160, 165], [165, 166], [166, 174], [175, 186], [187, 196], [197, 201], [202, 214], [215, 217], [218, 225], [226, 228], [229, 232], [233, 241], [242, 251], [252, 255], [256, 259], [260, 273], [274, 284], [285, 291], [291, 292]]}
{"doc_key": "ai-dev-327", "ner": [[3, 4, "researcher"], [6, 7, "university"], [10, 13, "product"], [17, 21, "product"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 6, 7, "physical", "", false, false], [3, 4, 6, 7, "role", "", false, false], [10, 13, 3, 4, "artifact", "", false, false], [10, 13, 17, 21, "type-of", "", false, false], [10, 13, 25, 26, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1969", ",", "Victor", "Scheinman", "of", "Stanford", "University", "invented", "the", "Stanford", "Arm", ",", "an", "all", "-", "electric", "6", "-", "axis", "articulated", "robot", "designed", "to", "enable", "arm", "release", "."], "sentence-detokenized": "In 1969, Victor Scheinman of Stanford University invented the Stanford Arm, an all-electric 6-axis articulated robot designed to enable arm release.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 25], [26, 28], [29, 37], [38, 48], [49, 57], [58, 61], [62, 70], [71, 74], [74, 75], [76, 78], [79, 82], [82, 83], [83, 91], [92, 93], [93, 94], [94, 98], [99, 110], [111, 116], [117, 125], [126, 128], [129, 135], [136, 139], [140, 147], [147, 148]]}
{"doc_key": "ai-dev-328", "ner": [[5, 5, "product"], [15, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 15, 16, "related-to", "", false, false], [5, 5, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "creation", "and", "deployment", "of", "chatbots", "is", "still", "an", "evolving", "area", ",", "strongly", "related", "to", "artificial", "intelligence", "and", "machine", "learning", ",", "so", "while", "the", "available", "solutions", "have", "obvious", "advantages", ",", "they", "have", "some", "important", "limitations", "in", "terms", "of", "functionalities", "and", "applicability", "."], "sentence-detokenized": "The creation and deployment of chatbots is still an evolving area, strongly related to artificial intelligence and machine learning, so while the available solutions have obvious advantages, they have some important limitations in terms of functionalities and applicability.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 27], [28, 30], [31, 39], [40, 42], [43, 48], [49, 51], [52, 60], [61, 65], [65, 66], [67, 75], [76, 83], [84, 86], [87, 97], [98, 110], [111, 114], [115, 122], [123, 131], [131, 132], [133, 135], [136, 141], [142, 145], [146, 155], [156, 165], [166, 170], [171, 178], [179, 189], [189, 190], [191, 195], [196, 200], [201, 205], [206, 215], [216, 227], [228, 230], [231, 236], [237, 239], [240, 255], [256, 259], [260, 273], [273, 274]]}
{"doc_key": "ai-dev-329", "ner": [[7, 9, "university"], [11, 13, "product"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 13, 7, 9, "part-of", "", true, false], [21, 22, 11, 13, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "terms", "of", "freely", "available", "resources", ",", "Carnegie", "Mellon", "University", "'s", "Sphinx", "toolkit", "is", "a", "good", "place", "to", "start", "learning", "about", "speech", "recognition", "and", "start", "experimenting", "."], "sentence-detokenized": "In terms of freely available resources, Carnegie Mellon University's Sphinx toolkit is a good place to start learning about speech recognition and start experimenting.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 18], [19, 28], [29, 38], [38, 39], [40, 48], [49, 55], [56, 66], [66, 68], [69, 75], [76, 83], [84, 86], [87, 88], [89, 93], [94, 99], [100, 102], [103, 108], [109, 117], [118, 123], [124, 130], [131, 142], [143, 146], [147, 152], [153, 166], [166, 167]]}
{"doc_key": "ai-dev-330", "ner": [[2, 3, "misc"], [13, 24, "misc"], [16, 16, "misc"], [29, 29, "university"], [31, 31, "location"], [33, 33, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 13, 24, "temporal", "", false, false], [16, 16, 13, 24, "named", "", false, false], [16, 16, 31, 31, "physical", "", false, false], [29, 29, 16, 16, "role", "", false, false], [31, 31, 33, 33, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "formal", "RoboCup", "competition", "was", "initiated", "by", "the", "(", "often", "unnoticed", ")", "first", "international", "soccer", "tournament", "MIROSOT", "(", "International", "Micro", "Robot", "World", "Cup", "Soccer", "Tournament", ")", ",", "hosted", "by", "KAIST", "in", "Taejon", ",", "Korea", ",", "in", "November", "1996", "."], "sentence-detokenized": "The formal RoboCup competition was initiated by the (often unnoticed) first international soccer tournament MIROSOT (International Micro Robot World Cup Soccer Tournament), hosted by KAIST in Taejon, Korea, in November 1996.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 30], [31, 34], [35, 44], [45, 47], [48, 51], [52, 53], [53, 58], [59, 68], [68, 69], [70, 75], [76, 89], [90, 96], [97, 107], [108, 115], [116, 117], [117, 130], [131, 136], [137, 142], [143, 148], [149, 152], [153, 159], [160, 170], [170, 171], [171, 172], [173, 179], [180, 182], [183, 188], [189, 191], [192, 198], [198, 199], [200, 205], [205, 206], [207, 209], [210, 218], [219, 223], [223, 224]]}
{"doc_key": "ai-dev-331", "ner": [[8, 9, "metrics"], [26, 27, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", "to", "the", "standard", "mathematical", "calculation", "of", "hinge", "loss", "(", "1-", "yf", "(", "x", ")", ")", "_", "+", "/", "math", "for", "labeled", "data", ",", "a", "loss", "function", "math", "(", "-", "1", "|", "f", "(", "x", ")", "|", ")", "_", "+", "/", "math", "introduced", "over", "the", "unlabeled", "data", "by", "letting", "mathy", "=\\", "operator", "name", "{", "sign", "}", "{", "f", "(", "x", ")", "}", "/", "math", "."], "sentence-detokenized": "In addition to the standard mathematical calculation of hinge loss (1-yf (x)) _ + / math for labeled data, a loss function math (-1 | f (x) |) _ + / math introduced over the unlabeled data by letting mathy =\\ operator name {sign} {f (x)} / math.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 27], [28, 40], [41, 52], [53, 55], [56, 61], [62, 66], [67, 68], [68, 70], [70, 72], [73, 74], [74, 75], [75, 76], [76, 77], [78, 79], [80, 81], [82, 83], [84, 88], [89, 92], [93, 100], [101, 105], [105, 106], [107, 108], [109, 113], [114, 122], [123, 127], [128, 129], [129, 130], [130, 131], [132, 133], [134, 135], [136, 137], [137, 138], [138, 139], [140, 141], [141, 142], [143, 144], [145, 146], [147, 148], [149, 153], [154, 164], [165, 169], [170, 173], [174, 183], [184, 188], [189, 191], [192, 199], [200, 205], [206, 208], [209, 217], [218, 222], [223, 224], [224, 228], [228, 229], [230, 231], [231, 232], [233, 234], [234, 235], [235, 236], [236, 237], [238, 239], [240, 244], [244, 245]]}
{"doc_key": "ai-dev-332", "ner": [[3, 4, "misc"], [9, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 9, 11, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "particular", ",", "RLS", "is", "designed", "to", "minimize", "the", "mean", "squared", "error", "between", "the", "predicted", "values", "and", "the", "true", "labels", "subject", "to", "adjustment", "."], "sentence-detokenized": "In particular, RLS is designed to minimize the mean squared error between the predicted values and the true labels subject to adjustment.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 21], [22, 30], [31, 33], [34, 42], [43, 46], [47, 51], [52, 59], [60, 65], [66, 73], [74, 77], [78, 87], [88, 94], [95, 98], [99, 102], [103, 107], [108, 114], [115, 122], [123, 125], [126, 136], [136, 137]]}
{"doc_key": "ai-dev-333", "ner": [[5, 7, "algorithm"], [10, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 10, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "is", "a", "combination", "of", "maximum", "likelihood", "estimation", "with", "a", "regularization", "procedure", "that", "favors", "simpler", "models", "over", "more", "complex", "models", "."], "sentence-detokenized": "This is a combination of maximum likelihood estimation with a regularization procedure that favors simpler models over more complex models.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 21], [22, 24], [25, 32], [33, 43], [44, 54], [55, 59], [60, 61], [62, 76], [77, 86], [87, 91], [92, 98], [99, 106], [107, 113], [114, 118], [119, 123], [124, 131], [132, 138], [138, 139]]}
{"doc_key": "ai-dev-334", "ner": [[1, 4, "metrics"], [10, 10, "metrics"], [12, 12, "metrics"], [14, 15, "misc"], [19, 20, "misc"], [33, 35, "algorithm"], [38, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 10, 1, 4, "named", "", false, false], [12, 12, 1, 4, "named", "", false, false], [14, 15, 19, 20, "related-to", "", false, false], [14, 15, 33, 35, "related-to", "ratio", false, false], [33, 35, 38, 40, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "true", "-", "positive", "rate", "is", "also", "known", "as", "the", "sensitivity", ",", "recall", "or", "detection", "probability", "mathematics", "to", "the", "discrimination", "threshold", ")", "of", "the", "detection", "probability", "on", "the", "y", "-axis", "relative", "to", "the", "cumulative", "distribution", "function", "of", "the", "false", "alarm", "probability", "on", "the", "x-", "axis", "."], "sentence-detokenized": "The true-positive rate is also known as the sensitivity, recall or detection probability mathematics to the discrimination threshold) of the detection probability on the y-axis relative to the cumulative distribution function of the false alarm probability on the x-axis.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 17], [18, 22], [23, 25], [26, 30], [31, 36], [37, 39], [40, 43], [44, 55], [55, 56], [57, 63], [64, 66], [67, 76], [77, 88], [89, 100], [101, 103], [104, 107], [108, 122], [123, 132], [132, 133], [134, 136], [137, 140], [141, 150], [151, 162], [163, 165], [166, 169], [170, 171], [171, 176], [177, 185], [186, 188], [189, 192], [193, 203], [204, 216], [217, 225], [226, 228], [229, 232], [233, 238], [239, 244], [245, 256], [257, 259], [260, 263], [264, 266], [266, 270], [270, 271]]}
{"doc_key": "ai-dev-335", "ner": [[1, 1, "misc"], [3, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 1, 1, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "English", ",", "Word", "Net", "is", "an", "example", "of", "a", "semantic", "network", "."], "sentence-detokenized": "In English, WordNet is an example of a semantic network.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 16], [16, 19], [20, 22], [23, 25], [26, 33], [34, 36], [37, 38], [39, 47], [48, 55], [55, 56]]}
{"doc_key": "ai-dev-336", "ner": [[5, 7, "product"], [11, 12, "product"], [27, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[27, 29, 5, 7, "usage", "", false, false], [27, 29, 11, 12, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Long", "-", "term", "use", "of", "speech", "recognition", "software", "in", "conjunction", "with", "word", "processors", "has", "shown", "benefits", "for", "rebuilding", "short", "-", "term", "memory", "in", "AVM", "patients", "in", "the", "brain", "who", "have", "been", "treated", "with", "resection", "."], "sentence-detokenized": "Long-term use of speech recognition software in conjunction with word processors has shown benefits for rebuilding short-term memory in AVM patients in the brain who have been treated with resection.", "token2charspan": [[0, 4], [4, 5], [5, 9], [10, 13], [14, 16], [17, 23], [24, 35], [36, 44], [45, 47], [48, 59], [60, 64], [65, 69], [70, 80], [81, 84], [85, 90], [91, 99], [100, 103], [104, 114], [115, 120], [120, 121], [121, 125], [126, 132], [133, 135], [136, 139], [140, 148], [149, 151], [152, 155], [156, 161], [162, 165], [166, 170], [171, 175], [176, 183], [184, 188], [189, 198], [198, 199]]}
{"doc_key": "ai-dev-337", "ner": [[8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "original", "editors", "-", "in", "-", "chief", "were", "Ron", "Sun", ",", "Vasant", "Honavar", "and", "Gregg", "Oden", "(", "from", "1999", "to", "2014", ")", "."], "sentence-detokenized": "The original editors-in-chief were Ron Sun, Vasant Honavar and Gregg Oden (from 1999 to 2014).", "token2charspan": [[0, 3], [4, 12], [13, 20], [20, 21], [21, 23], [23, 24], [24, 29], [30, 34], [35, 38], [39, 42], [42, 43], [44, 50], [51, 58], [59, 62], [63, 68], [69, 73], [74, 75], [75, 79], [80, 84], [85, 87], [88, 92], [92, 93], [93, 94]]}
{"doc_key": "ai-dev-338", "ner": [[7, 8, "product"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 12, 13, "opposite", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Their", "\"", "parallel", "\"", "difference", "from", "a", "series", "manipulator", "is", "that", "the", "end", "effector", "(", "or", "\"", "hand", "\"", ")", "of", "this", "joint", "(", "or", "\"", "arm", "\"", ")", "is", "directly", "connected", "to", "its", "base", "by", "a", "series", "(", "usually", "three", "or", "six", ")", "of", "separate", "and", "independent", "joints", "operating", "simultaneously", "."], "sentence-detokenized": "Their \"parallel\" difference from a series manipulator is that the end effector (or \"hand\") of this joint (or \"arm\") is directly connected to its base by a series (usually three or six) of separate and independent joints operating simultaneously.", "token2charspan": [[0, 5], [6, 7], [7, 15], [15, 16], [17, 27], [28, 32], [33, 34], [35, 41], [42, 53], [54, 56], [57, 61], [62, 65], [66, 69], [70, 78], [79, 80], [80, 82], [83, 84], [84, 88], [88, 89], [89, 90], [91, 93], [94, 98], [99, 104], [105, 106], [106, 108], [109, 110], [110, 113], [113, 114], [114, 115], [116, 118], [119, 127], [128, 137], [138, 140], [141, 144], [145, 149], [150, 152], [153, 154], [155, 161], [162, 163], [163, 170], [171, 176], [177, 179], [180, 183], [183, 184], [185, 187], [188, 196], [197, 200], [201, 212], [213, 219], [220, 229], [230, 244], [244, 245]]}
{"doc_key": "ai-dev-339", "ner": [[5, 6, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "thesis", "advisor", "was", "Professor", "Cordell", "Green", ",", "and", "his", "thesis", "/", "oral", "committee", "consisted", "of", "Professors", "Edward", "Feigenbaum", ",", "Joshua", "Lederberg", ",", "Paul", "Cohen", ",", "Allen", "Newell", ",", "Herbert", "Simon", ",", "."], "sentence-detokenized": "His thesis advisor was Professor Cordell Green, and his thesis/ oral committee consisted of Professors Edward Feigenbaum, Joshua Lederberg, Paul Cohen, Allen Newell, Herbert Simon,.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 22], [23, 32], [33, 40], [41, 46], [46, 47], [48, 51], [52, 55], [56, 62], [62, 63], [64, 68], [69, 78], [79, 88], [89, 91], [92, 102], [103, 109], [110, 120], [120, 121], [122, 128], [129, 138], [138, 139], [140, 144], [145, 150], [150, 151], [152, 157], [158, 164], [164, 165], [166, 173], [174, 179], [179, 180], [180, 181]]}
{"doc_key": "ai-dev-340", "ner": [[4, 6, "metrics"], [9, 14, "metrics"], [17, 19, "metrics"], [22, 24, "metrics"], [27, 32, "metrics"], [35, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "functions", "include", "the", "mean", "squared", "error", ",", "the", "root", "of", "the", "mean", "squared", "error", ",", "the", "mean", "absolute", "error", ",", "the", "relative", "squared", "error", ",", "the", "root", "of", "the", "relative", "squared", "error", ",", "the", "relative", "absolute", "error", ",", "and", "others", "."], "sentence-detokenized": "Such functions include the mean squared error, the root of the mean squared error, the mean absolute error, the relative squared error, the root of the relative squared error, the relative absolute error, and others.", "token2charspan": [[0, 4], [5, 14], [15, 22], [23, 26], [27, 31], [32, 39], [40, 45], [45, 46], [47, 50], [51, 55], [56, 58], [59, 62], [63, 67], [68, 75], [76, 81], [81, 82], [83, 86], [87, 91], [92, 100], [101, 106], [106, 107], [108, 111], [112, 120], [121, 128], [129, 134], [134, 135], [136, 139], [140, 144], [145, 147], [148, 151], [152, 160], [161, 168], [169, 174], [174, 175], [176, 179], [180, 188], [189, 197], [198, 203], [203, 204], [205, 208], [209, 215], [215, 216]]}
{"doc_key": "ai-dev-341", "ner": [[4, 4, "programlang"], [6, 6, "programlang"], [8, 8, "product"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Bindings", "are", "available", "in", "Python", ",", "Java", "and", "MATLAB", "/", "OCTAVE", "."], "sentence-detokenized": "Bindings are available in Python, Java and MATLAB / OCTAVE.", "token2charspan": [[0, 8], [9, 12], [13, 22], [23, 25], [26, 32], [32, 33], [34, 38], [39, 42], [43, 49], [50, 51], [52, 58], [58, 59]]}
{"doc_key": "ai-dev-342", "ner": [[3, 3, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "implementation", "in", "MATLAB", "can", "be", "found", "on", "the", "website", "."], "sentence-detokenized": "An implementation in MATLAB can be found on the website.", "token2charspan": [[0, 2], [3, 17], [18, 20], [21, 27], [28, 31], [32, 34], [35, 40], [41, 43], [44, 47], [48, 55], [55, 56]]}
{"doc_key": "ai-dev-343", "ner": [[0, 2, "researcher"], [8, 9, "field"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 2, "origin", "", false, false], [8, 9, 13, 14, "origin", "", false, false], [8, 9, 16, 17, "origin", "", false, false], [8, 9, 19, 20, "origin", "", false, false], [8, 9, 22, 25, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["John", "McCarthy", "is", "one", "of", "the", "founders", "of", "artificial", "intelligence", ",", "along", "with", "Alan", "Turing", ",", "Marvin", "Minsky", ",", "Allen", "Newell", "and", "Herbert", "A", ".", "Simon", "."], "sentence-detokenized": "John McCarthy is one of the founders of artificial intelligence, along with Alan Turing, Marvin Minsky, Allen Newell and Herbert A. Simon.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 23], [24, 27], [28, 36], [37, 39], [40, 50], [51, 63], [63, 64], [65, 70], [71, 75], [76, 80], [81, 87], [87, 88], [89, 95], [96, 102], [102, 103], [104, 109], [110, 116], [117, 120], [121, 128], [129, 130], [130, 131], [132, 137], [137, 138]]}
{"doc_key": "ai-dev-344", "ner": [[10, 12, "product"], [18, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "parallel", "manipulator", "is", "a", "mechanical", "system", "that", "uses", "multiple", "serial", "manipulators", "to", "support", "a", "single", "platform", "or", "end-effector", "."], "sentence-detokenized": "A parallel manipulator is a mechanical system that uses multiple serial manipulators to support a single platform or end-effector.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 27], [28, 38], [39, 45], [46, 50], [51, 55], [56, 64], [65, 71], [72, 84], [85, 87], [88, 95], [96, 97], [98, 104], [105, 113], [114, 116], [117, 129], [129, 130]]}
{"doc_key": "ai-dev-345", "ner": [[0, 0, "product"], [3, 4, "task"], [7, 7, "product"], [9, 15, "product"], [27, 27, "misc"], [30, 30, "misc"], [33, 34, "misc"], [37, 42, "task"], [45, 48, "product"], [51, 52, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 7, 0, 0, "part-of", "", false, false], [7, 7, 3, 4, "type-of", "", false, false], [9, 15, 7, 7, "named", "", false, false], [27, 27, 7, 7, "part-of", "", false, false], [30, 30, 7, 7, "part-of", "", false, false], [33, 34, 7, 7, "part-of", "", false, false], [37, 42, 7, 7, "part-of", "", false, false], [45, 48, 7, 7, "part-of", "", false, false], [51, 52, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["GATE", "includes", "an", "information", "extraction", "system", "called", "ANNIE", "(", "A", "Nearly", "-", "New", "Information", "Extraction", "System", ")", ",", "which", "is", "a", "set", "of", "modules", "consisting", "of", "a", "tokenizer", ",", "a", "gazetteer", ",", "a", "sentence", "splitter", ",", "a", "part", "-", "of", "-", "speech", "tagger", ",", "a", "named", "entity", "recognition", "transducer", "and", "a", "coreference", "tagger", "."], "sentence-detokenized": "GATE includes an information extraction system called ANNIE (A Nearly-New Information Extraction System), which is a set of modules consisting of a tokenizer, a gazetteer, a sentence splitter, a part-of-speech tagger, a named entity recognition transducer and a coreference tagger.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 28], [29, 39], [40, 46], [47, 53], [54, 59], [60, 61], [61, 62], [63, 69], [69, 70], [70, 73], [74, 85], [86, 96], [97, 103], [103, 104], [104, 105], [106, 111], [112, 114], [115, 116], [117, 120], [121, 123], [124, 131], [132, 142], [143, 145], [146, 147], [148, 157], [157, 158], [159, 160], [161, 170], [170, 171], [172, 173], [174, 182], [183, 191], [191, 192], [193, 194], [195, 199], [199, 200], [200, 202], [202, 203], [203, 209], [210, 216], [216, 217], [218, 219], [220, 225], [226, 232], [233, 244], [245, 255], [256, 259], [260, 261], [262, 273], [274, 280], [280, 281]]}
{"doc_key": "ai-dev-346", "ner": [[3, 5, "university"], [14, 16, "country"], [24, 27, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "graduated", "from", "Moscow", "State", "University", ",", "and", "in", "November", "1978", "he", "left", "for", "the", "United", "States", ",", "thanks", "to", "the", "personal", "intervention", "of", "Senator", "Edward", "M.", "Kennedy", "."], "sentence-detokenized": "He graduated from Moscow State University, and in November 1978 he left for the United States, thanks to the personal intervention of Senator Edward M. Kennedy.", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 24], [25, 30], [31, 41], [41, 42], [43, 46], [47, 49], [50, 58], [59, 63], [64, 66], [67, 71], [72, 75], [76, 79], [80, 86], [87, 93], [93, 94], [95, 101], [102, 104], [105, 108], [109, 117], [118, 130], [131, 133], [134, 141], [142, 148], [149, 151], [152, 159], [159, 160]]}
{"doc_key": "ai-dev-347", "ner": [[3, 8, "organisation"], [9, 21, "misc"], [18, 20, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 8, 9, 21, "win-defeat", "", false, false], [9, 21, 18, 20, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2017", ",", "the", "DeepMind", "AlphaGo", "team", "received", "the", "first", "IJCAI", "Marvin", "Minsky", "Medal", "for", "outstanding", "achievement", "in", "artificial", "intelligence", "from", "IJCAI", "."], "sentence-detokenized": "In 2017, the DeepMind AlphaGo team received the first IJCAI Marvin Minsky Medal for outstanding achievement in artificial intelligence from IJCAI.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 21], [22, 29], [30, 34], [35, 43], [44, 47], [48, 53], [54, 59], [60, 66], [67, 73], [74, 79], [80, 83], [84, 95], [96, 107], [108, 110], [111, 121], [122, 134], [135, 139], [140, 145], [145, 146]]}
{"doc_key": "ai-dev-348", "ner": [[4, 5, "misc"], [10, 11, "misc"], [16, 16, "misc"], [25, 26, "misc"], [31, 32, "misc"], [36, 36, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 10, 11, "related-to", "is_recorded_by", false, false], [10, 11, 16, 16, "cause-effect", "", false, false], [10, 11, 16, 16, "physical", "", false, false], [10, 11, 25, 26, "physical", "", false, false], [10, 11, 36, 36, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "ways", "in", "which", "anomalous", "propagation", "is", "detected", "are", "by", "tropospheric", "craters", "causing", "irregularities", "in", "the", "troposphere", ",", "scattering", "due", "to", "meteors", ",", "refraction", "in", "ionised", "regions", "and", "layers", "of", "the", "ionosphere", "and", "reflection", "from", "the", "ionosphere", "."], "sentence-detokenized": "Other ways in which anomalous propagation is detected are by tropospheric craters causing irregularities in the troposphere, scattering due to meteors, refraction in ionised regions and layers of the ionosphere and reflection from the ionosphere.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 19], [20, 29], [30, 41], [42, 44], [45, 53], [54, 57], [58, 60], [61, 73], [74, 81], [82, 89], [90, 104], [105, 107], [108, 111], [112, 123], [123, 124], [125, 135], [136, 139], [140, 142], [143, 150], [150, 151], [152, 162], [163, 165], [166, 173], [174, 181], [182, 185], [186, 192], [193, 195], [196, 199], [200, 210], [211, 214], [215, 225], [226, 230], [231, 234], [235, 245], [245, 246]]}
{"doc_key": "ai-dev-349", "ner": [[0, 2, "field"], [4, 6, "field"], [10, 10, "field"], [12, 13, "field"], [15, 16, "field"], [18, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 10, 10, "part-of", "", false, false], [0, 2, 12, 13, "part-of", "", false, false], [0, 2, 15, 16, "part-of", "", false, false], [0, 2, 18, 20, "part-of", "", false, false], [4, 6, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Natural", "language", "processing", "(", "NLP", ")", "is", "a", "subfield", "of", "linguistics", ",", "computer", "science", ",", "information", "technology", "and", "artificial", "intelligence", "that", "deals", "with", "the", "interaction", "between", "computers", "and", "human", "(", "natural", ")", "languages", ",", "in", "particular", "how", "to", "program", "computers", "to", "process", "and", "analyse", "large", "amounts", "of", "natural", "language", "data", "."], "sentence-detokenized": "Natural language processing (NLP) is a subfield of linguistics, computer science, information technology and artificial intelligence that deals with the interaction between computers and human (natural) languages, in particular how to program computers to process and analyse large amounts of natural language data.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 29], [29, 32], [32, 33], [34, 36], [37, 38], [39, 47], [48, 50], [51, 62], [62, 63], [64, 72], [73, 80], [80, 81], [82, 93], [94, 104], [105, 108], [109, 119], [120, 132], [133, 137], [138, 143], [144, 148], [149, 152], [153, 164], [165, 172], [173, 182], [183, 186], [187, 192], [193, 194], [194, 201], [201, 202], [203, 212], [212, 213], [214, 216], [217, 227], [228, 231], [232, 234], [235, 242], [243, 252], [253, 255], [256, 263], [264, 267], [268, 275], [276, 281], [282, 289], [290, 292], [293, 300], [301, 309], [310, 314], [314, 315]]}
{"doc_key": "ai-dev-350", "ner": [[8, 9, "organisation"], [11, 12, "organisation"], [14, 16, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "active", "youth", "-", "led", "climate", "groups", "include", "Extinction", "Rebellion", ",", "Sunrise", "Movement", ",", "SustainUS", ",", "and", "others", "working", "at", "both", "transnational", "and", "local", "levels", "."], "sentence-detokenized": "Other active youth-led climate groups include Extinction Rebellion, Sunrise Movement, SustainUS, and others working at both transnational and local levels.", "token2charspan": [[0, 5], [6, 12], [13, 18], [18, 19], [19, 22], [23, 30], [31, 37], [38, 45], [46, 56], [57, 66], [66, 67], [68, 75], [76, 84], [84, 85], [86, 95], [95, 96], [97, 100], [101, 107], [108, 115], [116, 118], [119, 123], [124, 137], [138, 141], [142, 147], [148, 154], [154, 155]]}
