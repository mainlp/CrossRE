{"doc_key": "ai-test-1", "ner": [[4, 6, "algorithm"], [8, 9, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "generative", "models", "include", "naive", "Bayes", "classifiers", ",", "Gaussian", "mixture", "models", ",", "variational", "autoencoders", "and", "others", "."], "sentence-detokenized": "Typical generative models include naive Bayes classifiers, Gaussian mixture models, variational autoencoders and others.", "token2charspan": [[0, 7], [8, 18], [19, 25], [26, 33], [34, 39], [40, 45], [46, 57], [57, 58], [59, 67], [68, 75], [76, 82], [82, 83], [84, 95], [96, 108], [109, 112], [113, 119], [119, 120]]}
{"doc_key": "ai-test-2", "ner": [[5, 5, "organisation"], [11, 11, "conference"], [14, 20, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 11, 11, "role", "", false, false], [14, 20, 11, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Finally", ",", "every", "two", "years", "ELRA", "organises", "a", "major", "conference", ",", "LREC", ",", "the", "International", "Conference", "on", "Language", "Resources", "and", "Evaluation", "."], "sentence-detokenized": "Finally, every two years ELRA organises a major conference, LREC, the International Conference on Language Resources and Evaluation.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 18], [19, 24], [25, 29], [30, 39], [40, 41], [42, 47], [48, 58], [58, 59], [60, 64], [64, 65], [66, 69], [70, 83], [84, 94], [95, 97], [98, 106], [107, 116], [117, 120], [121, 131], [131, 132]]}
{"doc_key": "ai-test-3", "ner": [[7, 11, "algorithm"], [15, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "task", "is", "usually", "to", "derive", "the", "maximum", "likelihood", "estimate", "of", "the", "parameters", "of", "the", "HMM", "from", "the", "output", "sequences", "."], "sentence-detokenized": "The task is usually to derive the maximum likelihood estimate of the parameters of the HMM from the output sequences.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 19], [20, 22], [23, 29], [30, 33], [34, 41], [42, 52], [53, 61], [62, 64], [65, 68], [69, 79], [80, 82], [83, 86], [87, 90], [91, 95], [96, 99], [100, 106], [107, 116], [116, 117]]}
{"doc_key": "ai-test-4", "ner": [[1, 1, "algorithm"], [4, 6, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Unlike", "neural", "networks", "and", "support", "vector", "machines", ",", "the", "AdaBoost", "training", "process", "selects", "only", "those", "features", "that", "are", "known", "to", "improve", "the", "model", "'s", "predictive", "power", ",", "reducing", "dimensionality", "and", "potentially", "improving", "execution", "time", "since", "irrelevant", "features", "do", "not", "need", "to", "be", "computed", "."], "sentence-detokenized": "Unlike neural networks and support vector machines, the AdaBoost training process selects only those features that are known to improve the model's predictive power, reducing dimensionality and potentially improving execution time since irrelevant features do not need to be computed.", "token2charspan": [[0, 6], [7, 13], [14, 22], [23, 26], [27, 34], [35, 41], [42, 50], [50, 51], [52, 55], [56, 64], [65, 73], [74, 81], [82, 89], [90, 94], [95, 100], [101, 109], [110, 114], [115, 118], [119, 124], [125, 127], [128, 135], [136, 139], [140, 145], [145, 147], [148, 158], [159, 164], [164, 165], [166, 174], [175, 189], [190, 193], [194, 205], [206, 215], [216, 225], [226, 230], [231, 236], [237, 247], [248, 256], [257, 259], [260, 263], [264, 268], [269, 271], [272, 274], [275, 283], [283, 284]]}
{"doc_key": "ai-test-5", "ner": [[0, 1, "misc"], [11, 12, "misc"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 11, 12, "part-of", "", false, false], [11, 12, 15, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Troponymy", "is", "one", "of", "the", "possible", "relations", "between", "verbs", "in", "the", "semantic", "network", "of", "the", "Word", "Net", "database", "."], "sentence-detokenized": "Troponymy is one of the possible relations between verbs in the semantic network of the WordNet database.", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 19], [20, 23], [24, 32], [33, 42], [43, 50], [51, 56], [57, 59], [60, 63], [64, 72], [73, 80], [81, 83], [84, 87], [88, 92], [92, 95], [96, 104], [104, 105]]}
{"doc_key": "ai-test-6", "ner": [[8, 9, "task"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 11, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "framework", "language", "is", "a", "technology", "used", "for", "knowledge", "representation", "in", "artificial", "intelligence", "."], "sentence-detokenized": "A framework language is a technology used for knowledge representation in artificial intelligence.", "token2charspan": [[0, 1], [2, 11], [12, 20], [21, 23], [24, 25], [26, 36], [37, 41], [42, 45], [46, 55], [56, 70], [71, 73], [74, 84], [85, 97], [97, 98]]}
{"doc_key": "ai-test-7", "ner": [[0, 0, "metrics"], [5, 7, "metrics"], [13, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 5, 7, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "the", "Bilingual", "Evaluation", "Substudy", "in", "its", "calculation", "of", "the", "penalty", "for", "brevity", ",", "in", "that", "small", "variations", "in", "translation", "length", "do", "not", "affect", "the", "overall", "score", "as", "much", "."], "sentence-detokenized": "NIST also differs from the Bilingual Evaluation Substudy in its calculation of the penalty for brevity, in that small variations in translation length do not affect the overall score as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 26], [27, 36], [37, 47], [48, 56], [57, 59], [60, 63], [64, 75], [76, 78], [79, 82], [83, 90], [91, 94], [95, 102], [102, 103], [104, 106], [107, 111], [112, 117], [118, 128], [129, 131], [132, 143], [144, 150], [151, 153], [154, 157], [158, 164], [165, 168], [169, 176], [177, 182], [183, 185], [186, 190], [190, 191]]}
{"doc_key": "ai-test-8", "ner": [[15, 16, "algorithm"], [19, 21, "algorithm"], [31, 31, "field"], [41, 42, "algorithm"], [44, 46, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 16, 31, 31, "usage", "", false, false], [19, 21, 31, 31, "usage", "", false, false], [41, 42, 31, 31, "type-of", "", false, false], [44, 46, 31, 31, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "model", "is", "initially", "fitted", "to", "a", "training", "dataset", ",", "The", "model", "(", "e.g.", "a", "neural", "network", "or", "a", "naive", "Bayes", "classifier", ")", "is", "trained", "on", "the", "training", "dataset", "using", "a", "supervised", "learning", "method", ",", "e.g.", "using", "optimization", "methods", "such", "as", "gradient", "descent", "or", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The model is initially fitted to a training dataset, The model (e.g. a neural network or a naive Bayes classifier) is trained on the training dataset using a supervised learning method, e.g. using optimization methods such as gradient descent or stochastic gradient descent.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 22], [23, 29], [30, 32], [33, 34], [35, 43], [44, 51], [51, 52], [53, 56], [57, 62], [63, 64], [64, 68], [69, 70], [71, 77], [78, 85], [86, 88], [89, 90], [91, 96], [97, 102], [103, 113], [113, 114], [115, 117], [118, 125], [126, 128], [129, 132], [133, 141], [142, 149], [150, 155], [156, 157], [158, 168], [169, 177], [178, 184], [184, 185], [186, 190], [191, 196], [197, 209], [210, 217], [218, 222], [223, 225], [226, 234], [235, 242], [243, 245], [246, 256], [257, 265], [266, 273], [273, 274]]}
{"doc_key": "ai-test-9", "ner": [[0, 0, "product"], [8, 9, "task"], [11, 11, "task"], [13, 15, "task"], [17, 18, "task"], [24, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 0, "usage", "", true, false], [11, 11, 0, 0, "usage", "", true, false], [13, 15, 0, 0, "usage", "", true, false], [17, 18, 0, 0, "usage", "", true, false], [24, 27, 0, 0, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["FrameNet", "has", "been", "used", "in", "applications", "such", "as", "questionnaire", "answering", ",", "paraphrasing", ",", "textual", "context", "recognition", "and", "information", "extraction", ",", "either", "directly", "or", "using", "semantic", "role", "labelling", "tools", "."], "sentence-detokenized": "FrameNet has been used in applications such as questionnaire answering, paraphrasing, textual context recognition and information extraction, either directly or using semantic role labelling tools.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 22], [23, 25], [26, 38], [39, 43], [44, 46], [47, 60], [61, 70], [70, 71], [72, 84], [84, 85], [86, 93], [94, 101], [102, 113], [114, 117], [118, 129], [130, 140], [140, 141], [142, 148], [149, 157], [158, 160], [161, 166], [167, 175], [176, 180], [181, 190], [191, 196], [196, 197]]}
{"doc_key": "ai-test-10", "ner": [[5, 6, "field"], [11, 11, "misc"], [14, 14, "product"], [17, 17, "misc"], [20, 20, "product"], [23, 24, "field"], [27, 27, "product"], [30, 32, "misc"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [42, 43, "misc"], [46, 47, "product"], [49, 50, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[14, 14, 11, 11, "general-affiliation", "", false, false], [20, 20, 17, 17, "general-affiliation", "", false, false], [27, 27, 23, 24, "general-affiliation", "", false, false], [35, 35, 30, 32, "type-of", "", false, false], [37, 37, 30, 32, "type-of", "", false, false], [39, 39, 30, 32, "type-of", "", false, false], [46, 47, 42, 43, "general-affiliation", "", false, false], [49, 50, 42, 43, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["This", "includes", "applications", "such", "as", "data", "analysis", "and", "extraction", "tools", ",", "spreadsheets", "(", "e.g.", "Excel", ")", ",", "databases", "(", "e.g.", "Access", ")", ",", "statistical", "analysis", "(", "e.g.", "SAS", ")", ",", "general", "audit", "software", "(", "e.g.", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "business", "intelligence", "(", "e.g.", "Crystal", "Reports", "and", "Business", "Objects", ")", ",", "etc", "."], "sentence-detokenized": "This includes applications such as data analysis and extraction tools, spreadsheets (e.g. Excel), databases (e.g. Access), statistical analysis (e.g. SAS), general audit software (e.g. ACL, Arbutus, EAS), business intelligence (e.g. Crystal Reports and Business Objects), etc.", "token2charspan": [[0, 4], [5, 13], [14, 26], [27, 31], [32, 34], [35, 39], [40, 48], [49, 52], [53, 63], [64, 69], [69, 70], [71, 83], [84, 85], [85, 89], [90, 95], [95, 96], [96, 97], [98, 107], [108, 109], [109, 113], [114, 120], [120, 121], [121, 122], [123, 134], [135, 143], [144, 145], [145, 149], [150, 153], [153, 154], [154, 155], [156, 163], [164, 169], [170, 178], [179, 180], [180, 184], [185, 188], [188, 189], [190, 197], [197, 198], [199, 202], [202, 203], [203, 204], [205, 213], [214, 226], [227, 228], [228, 232], [233, 240], [241, 248], [249, 252], [253, 261], [262, 269], [269, 270], [270, 271], [272, 275], [275, 276]]}
{"doc_key": "ai-test-11", "ner": [[0, 1, "organisation"], [5, 6, "researcher"], [10, 10, "organisation"], [13, 13, "product"], [19, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 6, "origin", "", false, false], [5, 6, 10, 10, "role", "", false, false], [13, 13, 19, 20, "type-of", "", false, false], [19, 20, 5, 6, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Rethink", "Robotics", "-", "founded", "by", "Rodney", "Brooks", ",", "formerly", "of", "iRobot", "-", "introduced", "Baxter", "in", "September", "2012", "as", "an", "industrial", "robot", "designed", "to", "safely", "interact", "with", "nearby", "human", "workers", "and", "can", "be", "programmed", "to", "perform", "simple", "tasks", "."], "sentence-detokenized": "Rethink Robotics - founded by Rodney Brooks, formerly of iRobot - introduced Baxter in September 2012 as an industrial robot designed to safely interact with nearby human workers and can be programmed to perform simple tasks.", "token2charspan": [[0, 7], [8, 16], [17, 18], [19, 26], [27, 29], [30, 36], [37, 43], [43, 44], [45, 53], [54, 56], [57, 63], [64, 65], [66, 76], [77, 83], [84, 86], [87, 96], [97, 101], [102, 104], [105, 107], [108, 118], [119, 124], [125, 133], [134, 136], [137, 143], [144, 152], [153, 157], [158, 164], [165, 170], [171, 178], [179, 182], [183, 186], [187, 189], [190, 200], [201, 203], [204, 211], [212, 218], [219, 224], [224, 225]]}
{"doc_key": "ai-test-12", "ner": [[5, 6, "task"], [8, 9, "task"], [11, 14, "task"], [16, 18, "task"], [20, 21, "task"], [23, 24, "task"], [27, 30, "task"], [37, 38, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "text", "mining", "tasks", "include", "text", "categorization", ",", "text", "grouping", ",", "concept", "/", "entity", "extraction", ",", "granular", "taxonomy", "production", ",", "sentiment", "analysis", ",", "document", "summarization", ",", "and", "modeling", "of", "entity", "relationships", "(", "i.e.", ",", "learning", "relationships", "between", "named", "entities", ")", "."], "sentence-detokenized": "Typical text mining tasks include text categorization, text grouping, concept/entity extraction, granular taxonomy production, sentiment analysis, document summarization, and modeling of entity relationships (i.e., learning relationships between named entities).", "token2charspan": [[0, 7], [8, 12], [13, 19], [20, 25], [26, 33], [34, 38], [39, 53], [53, 54], [55, 59], [60, 68], [68, 69], [70, 77], [77, 78], [78, 84], [85, 95], [95, 96], [97, 105], [106, 114], [115, 125], [125, 126], [127, 136], [137, 145], [145, 146], [147, 155], [156, 169], [169, 170], [171, 174], [175, 183], [184, 186], [187, 193], [194, 207], [208, 209], [209, 213], [213, 214], [215, 223], [224, 237], [238, 245], [246, 251], [252, 260], [260, 261], [261, 262]]}
{"doc_key": "ai-test-13", "ner": [[5, 6, "metrics"], [8, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nevertheless", ",", "strain", "estimates", "reduce", "the", "precision", "or", "true", "negative", "rate", "of", "such", "systems", "."], "sentence-detokenized": "Nevertheless, strain estimates reduce the precision or true negative rate of such systems.", "token2charspan": [[0, 12], [12, 13], [14, 20], [21, 30], [31, 37], [38, 41], [42, 51], [52, 54], [55, 59], [60, 68], [69, 73], [74, 76], [77, 81], [82, 89], [89, 90]]}
{"doc_key": "ai-test-14", "ner": [[4, 5, "task"], [10, 11, "misc"], [15, 16, "misc"], [27, 27, "product"], [29, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 11, 4, 5, "temporal", "", false, false], [15, 16, 10, 11, "named", "", false, false], [27, 27, 10, 11, "usage", "", false, false], [29, 29, 10, 11, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "particular", "case", "of", "keyword", "spotting", "is", "the", "detection", "of", "wake", "words", "(", "also", "called", "hot", "words", ")", ",", "which", "are", "used", "by", "personal", "digital", "assistants", "like", "Alexa", "or", "Siri", "to", "wake", "up", "when", "their", "name", "is", "spoken", "."], "sentence-detokenized": "A particular case of keyword spotting is the detection of wake words (also called hot words), which are used by personal digital assistants like Alexa or Siri to wake up when their name is spoken.", "token2charspan": [[0, 1], [2, 12], [13, 17], [18, 20], [21, 28], [29, 37], [38, 40], [41, 44], [45, 54], [55, 57], [58, 62], [63, 68], [69, 70], [70, 74], [75, 81], [82, 85], [86, 91], [91, 92], [92, 93], [94, 99], [100, 103], [104, 108], [109, 111], [112, 120], [121, 128], [129, 139], [140, 144], [145, 150], [151, 153], [154, 158], [159, 161], [162, 166], [167, 169], [170, 174], [175, 180], [181, 185], [186, 188], [189, 195], [195, 196]]}
{"doc_key": "ai-test-15", "ner": [[0, 1, "programlang"], [9, 9, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 0, 1, "part-of", "", false, false], [11, 11, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "is", "an", "open", "source", "programming", "language", "that", "combines", "Prolog", "with", "Java", "."], "sentence-detokenized": "Prova is an open source programming language that combines Prolog with Java.", "token2charspan": [[0, 5], [6, 8], [9, 11], [12, 16], [17, 23], [24, 35], [36, 44], [45, 49], [50, 58], [59, 65], [66, 70], [71, 75], [75, 76]]}
{"doc_key": "ai-test-16", "ner": [[3, 6, "organisation"], [9, 9, "organisation"], [16, 18, "product"], [30, 33, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 6, 9, 9, "part-of", "", false, false], [3, 6, 9, 9, "role", "sells", false, false], [3, 6, 30, 33, "role", "sells_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1987", ",", "Tocibai", "Machine", ",", "a", "subsidiary", "of", "Toshiba", ",", "was", "accused", "of", "illegally", "selling", "CNC", "milling", "material", ",", "used", "to", "make", "very", "quiet", "submarine", "propellers", ",", "to", "the", "Soviet", "Union", "in", "violation", "of", "the", "CoCom", "agreement", ",", "an", "international", "embargo", "on", "certain", "countries", "to", "COMECON", "countries", "."], "sentence-detokenized": "In 1987, Tocibai Machine, a subsidiary of Toshiba, was accused of illegally selling CNC milling material, used to make very quiet submarine propellers, to the Soviet Union in violation of the CoCom agreement, an international embargo on certain countries to COMECON countries.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 24], [24, 25], [26, 27], [28, 38], [39, 41], [42, 49], [49, 50], [51, 54], [55, 62], [63, 65], [66, 75], [76, 83], [84, 87], [88, 95], [96, 104], [104, 105], [106, 110], [111, 113], [114, 118], [119, 123], [124, 129], [130, 139], [140, 150], [150, 151], [152, 154], [155, 158], [159, 165], [166, 171], [172, 174], [175, 184], [185, 187], [188, 191], [192, 197], [198, 207], [207, 208], [209, 211], [212, 225], [226, 233], [234, 236], [237, 244], [245, 254], [255, 257], [258, 265], [266, 275], [275, 276]]}
{"doc_key": "ai-test-17", "ner": [[0, 1, "researcher"], [7, 10, "product"], [21, 24, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 10, 0, 1, "artifact", "", false, false], [7, 10, 21, 24, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Engelberger", "'s", "most", "famous", "co-invention", ",", "the", "Unimate", "industrial", "robot", "arm", ",", "was", "among", "the", "first", "to", "be", "inducted", "into", "the", "Robot", "Hall", "of", "Fame", "in", "2003", "."], "sentence-detokenized": "Engelberger's most famous co-invention, the Unimate industrial robot arm, was among the first to be inducted into the Robot Hall of Fame in 2003.", "token2charspan": [[0, 11], [11, 13], [14, 18], [19, 25], [26, 38], [38, 39], [40, 43], [44, 51], [52, 62], [63, 68], [69, 72], [72, 73], [74, 77], [78, 83], [84, 87], [88, 93], [94, 96], [97, 99], [100, 108], [109, 113], [114, 117], [118, 123], [124, 128], [129, 131], [132, 136], [137, 139], [140, 144], [144, 145]]}
{"doc_key": "ai-test-18", "ner": [[5, 5, "misc"], [10, 10, "misc"], [13, 13, "person"], [21, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 10, 10, "usage", "", false, false], [13, 13, 21, 27, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Initially", "it", "was", "managed", "via", "static", "html", "web", "pages", "with", "CGI", ",", "but", "Dalton", "worked", "to", "introduce", "a", "Java", "-", "based", "augmented", "-", "reality", "interface", ",", "which", "had", "limited", "success", "."], "sentence-detokenized": "Initially it was managed via static html web pages with CGI, but Dalton worked to introduce a Java-based augmented-reality interface, which had limited success.", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 24], [25, 28], [29, 35], [36, 40], [41, 44], [45, 50], [51, 55], [56, 59], [59, 60], [61, 64], [65, 71], [72, 78], [79, 81], [82, 91], [92, 93], [94, 98], [98, 99], [99, 104], [105, 114], [114, 115], [115, 122], [123, 132], [132, 133], [134, 139], [140, 143], [144, 151], [152, 159], [159, 160]]}
{"doc_key": "ai-test-19", "ner": [[5, 7, "task"], [13, 13, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 13, 13, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "publication", "on", "the", "LMF", "specification", "after", "it", "has", "been", "ratified", "by", "ISO", "(", "this", "paper", "became", "(", "in", "2015", ")", "the", "9th", "most", "cited", "paper", "within", "the", "LREC", "conferences", "from", "LREC", "papers", ")", ":"], "sentence-detokenized": "The first publication on the LMF specification after it has been ratified by ISO (this paper became (in 2015) the 9th most cited paper within the LREC conferences from LREC papers):", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 24], [25, 28], [29, 32], [33, 46], [47, 52], [53, 55], [56, 59], [60, 64], [65, 73], [74, 76], [77, 80], [81, 82], [82, 86], [87, 92], [93, 99], [100, 101], [101, 103], [104, 108], [108, 109], [110, 113], [114, 117], [118, 122], [123, 128], [129, 134], [135, 141], [142, 145], [146, 150], [151, 162], [163, 167], [168, 172], [173, 179], [179, 180], [180, 181]]}
{"doc_key": "ai-test-20", "ner": [[1, 2, "metrics"], [15, 16, "metrics"], [18, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 16, 1, 2, "usage", "", false, false], [15, 16, 18, 21, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "confusion", "matrix", "or", "matching", "matrix", "is", "often", "used", "as", "a", "tool", "to", "validate", "the", "accuracy", "of", "the", "k", "-", "NN", "classification", "."], "sentence-detokenized": "A confusion matrix or matching matrix is often used as a tool to validate the accuracy of the k -NN classification.", "token2charspan": [[0, 1], [2, 11], [12, 18], [19, 21], [22, 30], [31, 37], [38, 40], [41, 46], [47, 51], [52, 54], [55, 56], [57, 61], [62, 64], [65, 73], [74, 77], [78, 86], [87, 89], [90, 93], [94, 95], [96, 97], [97, 99], [100, 114], [114, 115]]}
{"doc_key": "ai-test-21", "ner": [[0, 1, "algorithm"], [12, 12, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 12, "part-of", "", false, false], [0, 1, 14, 15, "part-of", "", false, false], [0, 1, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", "is", "one", "of", "the", "prediction", "modelling", "methods", "used", "in", "statistics", ",", "data", "mining", "and", "machine", "learning", "."], "sentence-detokenized": "Decision tree learning is one of the prediction modelling methods used in statistics, data mining and machine learning.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 47], [48, 57], [58, 65], [66, 70], [71, 73], [74, 84], [84, 85], [86, 90], [91, 97], [98, 101], [102, 109], [110, 118], [118, 119]]}
{"doc_key": "ai-test-22", "ner": [[6, 6, "misc"], [19, 21, "algorithm"], [23, 23, "algorithm"]], "ner_mapping_to_source": [0, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["At", "runtime", ",", "a", "sentence", "'s", "prosody", "is", "superimposed", "on", "these", "minimal", "units", "using", "signal", "processing", "techniques", "such", "as", "linear", "predictive", "coding", ",", "PSOLA"], "sentence-detokenized": "At runtime, a sentence's prosody is superimposed on these minimal units using signal processing techniques such as linear predictive coding, PSOLA", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 13], [14, 22], [22, 24], [25, 32], [33, 35], [36, 48], [49, 51], [52, 57], [58, 65], [66, 71], [72, 77], [78, 84], [85, 95], [96, 106], [107, 111], [112, 114], [115, 121], [122, 132], [133, 139], [139, 140], [141, 146]]}
{"doc_key": "ai-test-23", "ner": [[3, 4, "field"], [6, 8, "field"], [16, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 17, 3, 4, "usage", "", true, false], [16, 17, 6, 8, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "method", "used", "artificial", "intelligence", "and", "machine", "learning", "to", "allow", "researchers", "to", "compare", "conventional", "and", "thermal", "facial", "images", "."], "sentence-detokenized": "This method used artificial intelligence and machine learning to allow researchers to compare conventional and thermal facial images.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 27], [28, 40], [41, 44], [45, 52], [53, 61], [62, 64], [65, 70], [71, 82], [83, 85], [86, 93], [94, 106], [107, 110], [111, 118], [119, 125], [126, 132], [132, 133]]}
{"doc_key": "ai-test-24", "ner": [[1, 2, "field"], [4, 5, "algorithm"], [12, 13, "task"], [16, 17, "misc"], [23, 24, "field"], [26, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 1, 2, "part-of", "", false, false], [4, 5, 12, 13, "topic", "", false, false], [12, 13, 16, 17, "origin", "", false, false], [23, 24, 1, 2, "part-of", "", false, false], [23, 24, 4, 5, "topic", "", false, false], [26, 27, 1, 2, "part-of", "", false, false], [26, 27, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "computer", "science", ",", "evolutionary", "computation", "is", "a", "family", "of", "algorithms", "for", "global", "optimization", "inspired", "by", "biological", "evolution", ",", "and", "the", "subfield", "of", "artificial", "intelligence", "and", "soft", "computing", "that", "studies", "these", "algorithms", "."], "sentence-detokenized": "In computer science, evolutionary computation is a family of algorithms for global optimization inspired by biological evolution, and the subfield of artificial intelligence and soft computing that studies these algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 33], [34, 45], [46, 48], [49, 50], [51, 57], [58, 60], [61, 71], [72, 75], [76, 82], [83, 95], [96, 104], [105, 107], [108, 118], [119, 128], [128, 129], [130, 133], [134, 137], [138, 146], [147, 149], [150, 160], [161, 173], [174, 177], [178, 182], [183, 192], [193, 197], [198, 205], [206, 211], [212, 222], [222, 223]]}
{"doc_key": "ai-test-25", "ner": [[11, 12, "metrics"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "one", "can", "combine", "a", "measure", "based", "on", "the", "confusion", "matrix", "with", "the", "mean", "squared", "error", "evaluated", "between", "the", "raw", "model", "results", "and", "the", "actual", "values", "."], "sentence-detokenized": "For example, one can combine a measure based on the confusion matrix with the mean squared error evaluated between the raw model results and the actual values.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 20], [21, 28], [29, 30], [31, 38], [39, 44], [45, 47], [48, 51], [52, 61], [62, 68], [69, 73], [74, 77], [78, 82], [83, 90], [91, 96], [97, 106], [107, 114], [115, 118], [119, 122], [123, 128], [129, 136], [137, 140], [141, 144], [145, 151], [152, 158], [158, 159]]}
{"doc_key": "ai-test-26", "ner": [[5, 6, "product"], [9, 9, "researcher"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 9, 9, "origin", "", false, false], [5, 6, 16, 16, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Most", "are", "results", "of", "the", "word2vec", "model", "developed", "by", "Mikolov", "et", "al", ".", "or", "variants", "of", "word2vec", "."], "sentence-detokenized": "Most are results of the word2vec model developed by Mikolov et al. or variants of word2vec.", "token2charspan": [[0, 4], [5, 8], [9, 16], [17, 19], [20, 23], [24, 32], [33, 38], [39, 48], [49, 51], [52, 59], [60, 62], [63, 65], [65, 66], [67, 69], [70, 78], [79, 81], [82, 90], [90, 91]]}
{"doc_key": "ai-test-27", "ner": [[14, 14, "conference"], [17, 21, "conference"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 23, 17, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "during", "this", "period", "that", "a", "total", "of", "43", "publications", "were", "recognised", "by", "CVPR", "and", "the", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "."], "sentence-detokenized": "It was during this period that a total of 43 publications were recognised by CVPR and the International Conference on Computer Vision (ICCV).", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 25], [26, 30], [31, 32], [33, 38], [39, 41], [42, 44], [45, 57], [58, 62], [63, 73], [74, 76], [77, 81], [82, 85], [86, 89], [90, 103], [104, 114], [115, 117], [118, 126], [127, 133], [134, 135], [135, 139], [139, 140], [140, 141]]}
{"doc_key": "ai-test-28", "ner": [[0, 0, "product"], [16, 17, "field"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 16, 17, "general-affiliation", "platform_for_education_about", false, false], [24, 25, 0, 0, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["AIBO", "has", "been", "widely", "used", "as", "a", "low", "-", "cost", "platform", "for", "teaching", "and", "research", "in", "artificial", "intelligence", "because", "it", "integrates", "a", "computer", ",", "computer", "vision", "and", "articulators", "into", "a", "package", "that", "is", "far", "cheaper", "than", "conventional", "research", "robots", "."], "sentence-detokenized": "AIBO has been widely used as a low-cost platform for teaching and research in artificial intelligence because it integrates a computer, computer vision and articulators into a package that is far cheaper than conventional research robots.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 20], [21, 25], [26, 28], [29, 30], [31, 34], [34, 35], [35, 39], [40, 48], [49, 52], [53, 61], [62, 65], [66, 74], [75, 77], [78, 88], [89, 101], [102, 109], [110, 112], [113, 123], [124, 125], [126, 134], [134, 135], [136, 144], [145, 151], [152, 155], [156, 168], [169, 173], [174, 175], [176, 183], [184, 188], [189, 191], [192, 195], [196, 203], [204, 208], [209, 221], [222, 230], [231, 237], [237, 238]]}
{"doc_key": "ai-test-29", "ner": [[8, 13, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "has", "been", "the", "programme", "chair", "of", "the", "International", "Conference", "on", "Computer", "Vision", "2021", "."], "sentence-detokenized": "She has been the programme chair of the International Conference on Computer Vision 2021.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 16], [17, 26], [27, 32], [33, 35], [36, 39], [40, 53], [54, 64], [65, 67], [68, 76], [77, 83], [84, 88], [88, 89]]}
{"doc_key": "ai-test-30", "ner": [[11, 11, "researcher"], [5, 5, "organisation"], [16, 16, "organisation"], [25, 26, "organisation"], [33, 37, "product"], [39, 39, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 5, 5, "role", "", false, false], [11, 11, 16, 16, "role", "", true, false], [16, 16, 25, 26, "role", "develops_with", false, false], [33, 37, 16, 16, "artifact", "", false, false], [39, 39, 33, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["After", "receiving", "a", "grant", "from", "Unimation", "to", "develop", "his", "designs", ",", "Scheinman", "sold", "these", "designs", "to", "Unimation", ",", "which", "further", "developed", "them", "with", "support", "from", "General", "Motors", "and", "later", "marketed", "them", "as", "the", "Programmable", "Universal", "Machine", "for", "Assembly", "(", "PUMA", ")", "."], "sentence-detokenized": "After receiving a grant from Unimation to develop his designs, Scheinman sold these designs to Unimation, which further developed them with support from General Motors and later marketed them as the Programmable Universal Machine for Assembly (PUMA).", "token2charspan": [[0, 5], [6, 15], [16, 17], [18, 23], [24, 28], [29, 38], [39, 41], [42, 49], [50, 53], [54, 61], [61, 62], [63, 72], [73, 77], [78, 83], [84, 91], [92, 94], [95, 104], [104, 105], [106, 111], [112, 119], [120, 129], [130, 134], [135, 139], [140, 147], [148, 152], [153, 160], [161, 167], [168, 171], [172, 177], [178, 186], [187, 191], [192, 194], [195, 198], [199, 211], [212, 221], [222, 229], [230, 233], [234, 242], [243, 244], [244, 248], [248, 249], [249, 250]]}
{"doc_key": "ai-test-31", "ner": [[11, 12, "task"], [14, 16, "task"], [0, 0, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 12, "general-affiliation", "works_with", false, false], [0, 0, 14, 16, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Gebel", "(", "2009", ")", "provides", "an", "overview", "of", "calibration", "methods", "for", "binary", "classification", "and", "multi-class", "classification", "tasks", "."], "sentence-detokenized": "Gebel (2009) provides an overview of calibration methods for binary classification and multi-class classification tasks.", "token2charspan": [[0, 5], [6, 7], [7, 11], [11, 12], [13, 21], [22, 24], [25, 33], [34, 36], [37, 48], [49, 56], [57, 60], [61, 67], [68, 82], [83, 86], [87, 98], [99, 113], [114, 119], [119, 120]]}
{"doc_key": "ai-test-32", "ner": [[7, 9, "task"], [11, 11, "task"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "involved", "in", "areas", "such", "as", "optical", "character", "recognition", "(", "OCR", ")", ",", "speech", "synthesis", ",", "speech", "recognition", "technology", "and", "electronic", "keyboard", "instruments", "."], "sentence-detokenized": "He is involved in areas such as optical character recognition (OCR), speech synthesis, speech recognition technology and electronic keyboard instruments.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 23], [24, 28], [29, 31], [32, 39], [40, 49], [50, 61], [62, 63], [63, 66], [66, 67], [67, 68], [69, 75], [76, 85], [85, 86], [87, 93], [94, 105], [106, 116], [117, 120], [121, 131], [132, 140], [141, 152], [152, 153]]}
{"doc_key": "ai-test-33", "ner": [[7, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "newer", "and", "more", "advanced", "techniques", ",", "the", "Kaldi", "toolkit", "can", "be", "used", "."], "sentence-detokenized": "For newer and more advanced techniques, the Kaldi toolkit can be used.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 18], [19, 27], [28, 38], [38, 39], [40, 43], [44, 49], [50, 57], [58, 61], [62, 64], [65, 69], [69, 70]]}
{"doc_key": "ai-test-34", "ner": [[0, 3, "researcher"], [8, 10, "organisation"], [16, 17, "organisation"], [23, 24, "organisation"], [27, 28, "researcher"], [32, 35, "organisation"], [41, 43, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 8, 10, "role", "", false, false], [0, 3, 16, 17, "role", "", false, false], [0, 3, 23, 24, "role", "", false, false], [0, 3, 32, 35, "role", "", false, false], [0, 3, 41, 43, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Johnson", "-", "Laird", "is", "a", "Fellow", "of", "the", "American", "Philosophical", "Society", ",", "a", "Fellow", "of", "the", "Royal", "Society", ",", "a", "Fellow", "of", "the", "British", "Academy", ",", "a", "William", "James", "Fellow", "of", "the", "Association", "for", "Psychological", "Science", "and", "a", "Fellow", "of", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Johnson-Laird is a Fellow of the American Philosophical Society, a Fellow of the Royal Society, a Fellow of the British Academy, a William James Fellow of the Association for Psychological Science and a Fellow of the Cognitive Science Society.", "token2charspan": [[0, 7], [7, 8], [8, 13], [14, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 41], [42, 55], [56, 63], [63, 64], [65, 66], [67, 73], [74, 76], [77, 80], [81, 86], [87, 94], [94, 95], [96, 97], [98, 104], [105, 107], [108, 111], [112, 119], [120, 127], [127, 128], [129, 130], [131, 138], [139, 144], [145, 151], [152, 154], [155, 158], [159, 170], [171, 174], [175, 188], [189, 196], [197, 200], [201, 202], [203, 209], [210, 212], [213, 216], [217, 226], [227, 234], [235, 242], [242, 243]]}
{"doc_key": "ai-test-35", "ner": [[3, 8, "conference"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [20, 22, "algorithm"], [25, 29, "task"], [31, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 11, 3, 8, "physical", "", false, false], [10, 11, 3, 8, "temporal", "", false, false], [13, 14, 3, 8, "physical", "", false, false], [13, 14, 3, 8, "temporal", "", false, false], [16, 17, 3, 8, "physical", "", false, false], [16, 17, 3, 8, "temporal", "", false, false], [20, 22, 16, 17, "role", "extends", false, false], [25, 29, 16, 17, "role", "extends", false, false], [31, 31, 25, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["At", "the", "2010", "IEEE", "International", "Conference", "on", "Image", "Processing", ",", "Rui", "Hu", ",", "Mark", "Banard", "and", "John", "Collomosse", "extended", "the", "HOG", "descriptor", "for", "use", "in", "sketch", "-", "based", "image", "retrieval", "(", "SBIR", ")", "."], "sentence-detokenized": "At the 2010 IEEE International Conference on Image Processing, Rui Hu, Mark Banard and John Collomosse extended the HOG descriptor for use in sketch-based image retrieval (SBIR).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 30], [31, 41], [42, 44], [45, 50], [51, 61], [61, 62], [63, 66], [67, 69], [69, 70], [71, 75], [76, 82], [83, 86], [87, 91], [92, 102], [103, 111], [112, 115], [116, 119], [120, 130], [131, 134], [135, 138], [139, 141], [142, 148], [148, 149], [149, 154], [155, 160], [161, 170], [171, 172], [172, 176], [176, 177], [177, 178]]}
{"doc_key": "ai-test-36", "ner": [[0, 0, "metrics"], [6, 7, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 7, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["BLEU", "uses", "a", "modified", "form", "of", "precision", "to", "compare", "a", "candidate", "translation", "with", "several", "reference", "translations", "."], "sentence-detokenized": "BLEU uses a modified form of precision to compare a candidate translation with several reference translations.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 20], [21, 25], [26, 28], [29, 38], [39, 41], [42, 49], [50, 51], [52, 61], [62, 73], [74, 78], [79, 86], [87, 96], [97, 109], [109, 110]]}
{"doc_key": "ai-test-37", "ner": [[35, 36, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "case", "of", "a", "general", "basis", "space", "math", "(", "Y", ",\\", "mathcal", "{", "B", "},\\", "now", ")", "/", "math", "(", "i.e.", "a", "basis", "space", "which", "is", "not", "countable", ")", ",", "one", "typically", "considers", "the", "relative", "entropy", "."], "sentence-detokenized": "In the case of a general basis space math (Y,\\ mathcal {B},\\ now) / math (i.e. a basis space which is not countable), one typically considers the relative entropy.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 16], [17, 24], [25, 30], [31, 36], [37, 41], [42, 43], [43, 44], [44, 46], [47, 54], [55, 56], [56, 57], [57, 60], [61, 64], [64, 65], [66, 67], [68, 72], [73, 74], [74, 78], [79, 80], [81, 86], [87, 92], [93, 98], [99, 101], [102, 105], [106, 115], [115, 116], [116, 117], [118, 121], [122, 131], [132, 141], [142, 145], [146, 154], [155, 162], [162, 163]]}
{"doc_key": "ai-test-38", "ner": [[10, 10, "country"], [11, 13, "organisation"], [16, 16, "organisation"], [20, 20, "country"], [21, 22, "organisation"], [24, 24, "organisation"], [28, 30, "organisation"], [34, 39, "organisation"], [41, 41, "organisation"], [48, 48, "misc"], [49, 49, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11], "relations": [[11, 13, 10, 10, "physical", "", false, false], [16, 16, 11, 13, "named", "", false, false], [21, 22, 20, 20, "physical", "", false, false], [24, 24, 21, 22, "named", "", false, false], [41, 41, 34, 39, "named", "", false, false], [48, 48, 49, 49, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6], "sentence": ["By", "October", "2011", ",", "the", "already", "existing", "partnerships", "with", "the", "US", "National", "Park", "Service", "(", "NPS", ")", ",", "the", "UK", "'s", "Historic", "Scotland", "(", "HS", ")", ",", "the", "World", "Monuments", "Fund", "and", "Mexico", "'s", "Instituto", "Nacional", "de", "Antropolog\u00eda", "y", "Historia", "(", "INAH", ")", "had", "been", "significantly", "expanded", ",", "CyArk", "website"], "sentence-detokenized": "By October 2011, the already existing partnerships with the US National Park Service (NPS), the UK's Historic Scotland (HS), the World Monuments Fund and Mexico's Instituto Nacional de Antropolog\u00eda y Historia (INAH) had been significantly expanded, CyArk website", "token2charspan": [[0, 2], [3, 10], [11, 15], [15, 16], [17, 20], [21, 28], [29, 37], [38, 50], [51, 55], [56, 59], [60, 62], [63, 71], [72, 76], [77, 84], [85, 86], [86, 89], [89, 90], [90, 91], [92, 95], [96, 98], [98, 100], [101, 109], [110, 118], [119, 120], [120, 122], [122, 123], [123, 124], [125, 128], [129, 134], [135, 144], [145, 149], [150, 153], [154, 160], [160, 162], [163, 172], [173, 181], [182, 184], [185, 197], [198, 199], [200, 208], [209, 210], [210, 214], [214, 215], [216, 219], [220, 224], [225, 238], [239, 247], [247, 248], [249, 254], [255, 262]]}
{"doc_key": "ai-test-39", "ner": [[0, 2, "algorithm"], [6, 8, "field"], [11, 11, "product"], [13, 13, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 11, 11, "part-of", "", false, false], [0, 2, 13, 13, "part-of", "", false, false], [11, 11, 6, 8, "general-affiliation", "", false, false], [13, 13, 6, 8, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kernel", "SVMs", "are", "available", "in", "many", "machine", "learning", "toolkits", ",", "including", "LIBSVM", ",", "MATLAB", "and", "others", "."], "sentence-detokenized": "Kernel SVMs are available in many machine learning toolkits, including LIBSVM, MATLAB and others.", "token2charspan": [[0, 6], [7, 11], [12, 15], [16, 25], [26, 28], [29, 33], [34, 41], [42, 50], [51, 59], [59, 60], [61, 70], [71, 77], [77, 78], [79, 85], [86, 89], [90, 96], [96, 97]]}
{"doc_key": "ai-test-40", "ner": [[2, 5, "misc"], [13, 14, "location"], [16, 16, "location"], [17, 17, "country"], [23, 25, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 5, 13, 14, "physical", "", false, false], [2, 5, 23, 25, "temporal", "", false, false], [13, 14, 16, 16, "physical", "", false, false], [16, 16, 17, 17, "physical", "", false, false], [23, 25, 13, 14, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "2009", "Loebner", "Prize", "competition", "was", "held", "on", "6", "September", "2009", "at", "the", "Brighton", "Centre", ",", "Brighton", "UK", ",", "in", "conjunction", "with", "the", "Interspeech", "2009", "conference", "."], "sentence-detokenized": "The 2009 Loebner Prize competition was held on 6 September 2009 at the Brighton Centre, Brighton UK, in conjunction with the Interspeech 2009 conference.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 34], [35, 38], [39, 43], [44, 46], [47, 48], [49, 58], [59, 63], [64, 66], [67, 70], [71, 79], [80, 86], [86, 87], [88, 96], [97, 99], [99, 100], [101, 103], [104, 115], [116, 120], [121, 124], [125, 136], [137, 141], [142, 152], [152, 153]]}
{"doc_key": "ai-test-41", "ner": [[1, 4, "product"], [7, 8, "product"], [16, 18, "product"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 21, 1, 4, "part-of", "", false, false], [19, 21, 7, 8, "part-of", "", false, false], [19, 21, 16, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "QRIO", "humanoid", "robot", "is", "designed", "as", "AIBO", "'s", "successor", "and", "runs", "on", "the", "same", "basic", "R", "-", "CODE", "Aperios", "operating", "system", "."], "sentence-detokenized": "The QRIO humanoid robot is designed as AIBO's successor and runs on the same basic R-CODE Aperios operating system.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 23], [24, 26], [27, 35], [36, 38], [39, 43], [43, 45], [46, 55], [56, 59], [60, 64], [65, 67], [68, 71], [72, 76], [77, 82], [83, 84], [84, 85], [85, 89], [90, 97], [98, 107], [108, 114], [114, 115]]}
{"doc_key": "ai-test-42", "ner": [[0, 1, "misc"], [5, 5, "algorithm"], [9, 11, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 0, 1, "cause-effect", "", true, false], [9, 11, 0, 1, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Speech", "waveforms", "are", "generated", "from", "HMMs", "based", "on", "the", "maximum", "likelihood", "criterion", "."], "sentence-detokenized": "Speech waveforms are generated from HMMs based on the maximum likelihood criterion.", "token2charspan": [[0, 6], [7, 16], [17, 20], [21, 30], [31, 35], [36, 40], [41, 46], [47, 49], [50, 53], [54, 61], [62, 72], [73, 82], [82, 83]]}
{"doc_key": "ai-test-43", "ner": [[0, 3, "product"], [5, 8, "task"], [10, 13, "task"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 5, 8, "type-of", "", false, false], [0, 3, 10, 13, "type-of", "", false, false], [0, 3, 16, 17, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "is", "a", "free", "multilingual", "statistical", "machine", "translation", "and", "neural", "machine", "translation", "tool", "developed", "by", "Google", "to", "translate", "text", "and", "websites", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Google Translate is a free multilingual statistical machine translation and neural machine translation tool developed by Google to translate text and websites from one language to another.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 39], [40, 51], [52, 59], [60, 71], [72, 75], [76, 82], [83, 90], [91, 102], [103, 107], [108, 117], [118, 120], [121, 127], [128, 130], [131, 140], [141, 145], [146, 149], [150, 158], [159, 163], [164, 167], [168, 176], [177, 179], [180, 187], [187, 188]]}
{"doc_key": "ai-test-44", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [14, 16, "field"], [21, 23, "task"], [25, 26, "task"], [28, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[21, 23, 5, 6, "part-of", "", false, true], [21, 23, 8, 9, "part-of", "", false, true], [21, 23, 11, 12, "part-of", "", false, true], [25, 26, 5, 6, "part-of", "", false, true], [25, 26, 8, 9, "part-of", "", false, true], [25, 26, 11, 12, "part-of", "", false, true], [28, 31, 5, 6, "part-of", "", false, true], [28, 31, 8, 9, "part-of", "", false, true], [28, 31, 11, 12, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Skeletons", "are", "widely", "used", "in", "computer", "vision", ",", "image", "analysis", ",", "pattern", "recognition", "and", "digital", "image", "processing", "for", "purposes", "such", "as", "optical", "character", "recognition", ",", "fingerprint", "recognition", ",", "visual", "inspection", "or", "compression", "."], "sentence-detokenized": "Skeletons are widely used in computer vision, image analysis, pattern recognition and digital image processing for purposes such as optical character recognition, fingerprint recognition, visual inspection or compression.", "token2charspan": [[0, 9], [10, 13], [14, 20], [21, 25], [26, 28], [29, 37], [38, 44], [44, 45], [46, 51], [52, 60], [60, 61], [62, 69], [70, 81], [82, 85], [86, 93], [94, 99], [100, 110], [111, 114], [115, 123], [124, 128], [129, 131], [132, 139], [140, 149], [150, 161], [161, 162], [163, 174], [175, 186], [186, 187], [188, 194], [195, 205], [206, 208], [209, 220], [220, 221]]}
{"doc_key": "ai-test-45", "ner": [[0, 6, "conference"], [11, 14, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 6, 11, 14, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "is", "a", "benchmark", "in", "object", "classification", "and", "detection", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object classification and detection with millions of images and hundreds of object classes.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 24], [25, 31], [32, 43], [44, 53], [54, 56], [57, 58], [59, 68], [69, 71], [72, 78], [79, 93], [94, 97], [98, 107], [108, 112], [113, 121], [122, 124], [125, 131], [132, 135], [136, 144], [145, 147], [148, 154], [155, 162], [162, 163]]}
{"doc_key": "ai-test-46", "ner": [[0, 10, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [17, 19, "misc"], [22, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 10, 17, 19, "part-of", "", false, false], [0, 10, 22, 25, "part-of", "", false, false], [4, 5, 17, 19, "part-of", "", false, false], [4, 5, 22, 25, "part-of", "", false, false], [7, 8, 17, 19, "part-of", "", false, false], [7, 8, 22, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Bengio", ",", "along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "is", "referred", "to", "by", "some", "as", "the", "godfathers", "of", "AI", "and", "the", "godfathers", "of", "Deep", "Learning", "."], "sentence-detokenized": "Bengio, along with Geoffrey Hinton and Yann LeCun, is referred to by some as the godfathers of AI and the godfathers of Deep Learning.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 18], [19, 27], [28, 34], [35, 38], [39, 43], [44, 49], [49, 50], [51, 53], [54, 62], [63, 65], [66, 68], [69, 73], [74, 76], [77, 80], [81, 91], [92, 94], [95, 97], [98, 101], [102, 105], [106, 116], [117, 119], [120, 124], [125, 133], [133, 134]]}
{"doc_key": "ai-test-47", "ner": [[7, 7, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "Life", "Fellow", "of", "the", "IEEE", "."], "sentence-detokenized": "He is a Life Fellow of the IEEE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 19], [20, 22], [23, 26], [27, 31], [31, 32]]}
{"doc_key": "ai-test-48", "ner": [[0, 1, "organisation"], [13, 18, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 13, 18, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NSA", "Bethesda", "is", "responsible", "for", "the", "operational", "support", "of", "the", "largest", "tenant", ",", "Walter", "Reed", "National", "Military", "Medical", "Center", "."], "sentence-detokenized": "NSA Bethesda is responsible for the operational support of the largest tenant, Walter Reed National Military Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 31], [32, 35], [36, 47], [48, 55], [56, 58], [59, 62], [63, 70], [71, 77], [77, 78], [79, 85], [86, 90], [91, 99], [100, 108], [109, 116], [117, 123], [123, 124]]}
{"doc_key": "ai-test-49", "ner": [[6, 7, "field"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "three", "main", "learning", "paradigms", "are", "supervised", "learning", ",", "unsupervised", "learning", "and", "reinforced", "learning", "."], "sentence-detokenized": "The three main learning paradigms are supervised learning, unsupervised learning and reinforced learning.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 23], [24, 33], [34, 37], [38, 48], [49, 57], [57, 58], [59, 71], [72, 80], [81, 84], [85, 95], [96, 104], [104, 105]]}
{"doc_key": "ai-test-50", "ner": [[2, 2, "task"], [4, 6, "task"], [11, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Examples", "include", "control", ",", "planning", "and", "scheduling", ",", "the", "ability", "to", "answer", "diagnostic", "and", "consumer", "questions", ",", "handwriting", "recognition", ",", "natural", "language", "understanding", ",", "speech", "recognition", "and", "facial", "recognition", "."], "sentence-detokenized": "Examples include control, planning and scheduling, the ability to answer diagnostic and consumer questions, handwriting recognition, natural language understanding, speech recognition and facial recognition.", "token2charspan": [[0, 8], [9, 16], [17, 24], [24, 25], [26, 34], [35, 38], [39, 49], [49, 50], [51, 54], [55, 62], [63, 65], [66, 72], [73, 83], [84, 87], [88, 96], [97, 106], [106, 107], [108, 119], [120, 131], [131, 132], [133, 140], [141, 149], [150, 163], [163, 164], [165, 171], [172, 183], [184, 187], [188, 194], [195, 206], [206, 207]]}
{"doc_key": "ai-test-51", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1991", "he", "was", "elected", "as", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "1990", ",", "founding", "member", ")", "."], "sentence-detokenized": "In 1991 he was elected as a member of the Association for the Advancement of Artificial Intelligence (1990, founding member).", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 22], [23, 25], [26, 27], [28, 34], [35, 37], [38, 41], [42, 53], [54, 57], [58, 61], [62, 73], [74, 76], [77, 87], [88, 100], [101, 102], [102, 106], [106, 107], [108, 116], [117, 123], [123, 124], [124, 125]]}
{"doc_key": "ai-test-52", "ner": [[11, 12, "misc"], [15, 16, "algorithm"], [29, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "by", "formulating", "the", "problem", "as", "the", "solution", "of", "a", "Toeplitz", "matrix", "and", "applying", "Levinson", "recursion", ",", "we", "can", "relatively", "quickly", "estimate", "a", "filter", "with", "the", "least", "possible", "mean", "squared", "error", "."], "sentence-detokenized": "However, by formulating the problem as the solution of a Toeplitz matrix and applying Levinson recursion, we can relatively quickly estimate a filter with the least possible mean squared error.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 23], [24, 27], [28, 35], [36, 38], [39, 42], [43, 51], [52, 54], [55, 56], [57, 65], [66, 72], [73, 76], [77, 85], [86, 94], [95, 104], [104, 105], [106, 108], [109, 112], [113, 123], [124, 131], [132, 140], [141, 142], [143, 149], [150, 154], [155, 158], [159, 164], [165, 173], [174, 178], [179, 186], [187, 192], [192, 193]]}
{"doc_key": "ai-test-53", "ner": [[5, 14, "conference"], [18, 22, "location"], [15, 17, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 14, 18, 22, "physical", "", false, false], [18, 22, 15, 17, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2011", ",", "the", "15th", "edition", "of", "Campus", "Party", "Spain", "will", "be", "held", "in", "Valencia", ",", "the", "City", "of", "Arts", "and", "Sciences", "."], "sentence-detokenized": "In July 2011, the 15th edition of Campus Party Spain will be held in Valencia, the City of Arts and Sciences.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 22], [23, 30], [31, 33], [34, 40], [41, 46], [47, 52], [53, 57], [58, 60], [61, 65], [66, 68], [69, 77], [77, 78], [79, 82], [83, 87], [88, 90], [91, 95], [96, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-test-54", "ner": [[13, 13, "product"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "often", "only", "possible", "at", "the", "end", "of", "complicated", "games", "such", "as", "chess", "or", "go", ",", "as", "it", "is", "not", "possible", "computationally", "to", "look", "forward", "to", "the", "end", "of", "the", "game", "except", "towards", "the", "end", ",", "and", "instead", "positions", "are", "given", "final", "values", "as", "an", "estimate", "of", "the", "degree", "of", "belief", "that", "they", "will", "lead", "to", "a", "victory", "for", "one", "player", "or", "the", "other", "."], "sentence-detokenized": "This is often only possible at the end of complicated games such as chess or go, as it is not possible computationally to look forward to the end of the game except towards the end, and instead positions are given final values as an estimate of the degree of belief that they will lead to a victory for one player or the other.", "token2charspan": [[0, 4], [5, 7], [8, 13], [14, 18], [19, 27], [28, 30], [31, 34], [35, 38], [39, 41], [42, 53], [54, 59], [60, 64], [65, 67], [68, 73], [74, 76], [77, 79], [79, 80], [81, 83], [84, 86], [87, 89], [90, 93], [94, 102], [103, 118], [119, 121], [122, 126], [127, 134], [135, 137], [138, 141], [142, 145], [146, 148], [149, 152], [153, 157], [158, 164], [165, 172], [173, 176], [177, 180], [180, 181], [182, 185], [186, 193], [194, 203], [204, 207], [208, 213], [214, 219], [220, 226], [227, 229], [230, 232], [233, 241], [242, 244], [245, 248], [249, 255], [256, 258], [259, 265], [266, 270], [271, 275], [276, 280], [281, 285], [286, 288], [289, 290], [291, 298], [299, 302], [303, 306], [307, 313], [314, 316], [317, 320], [321, 326], [326, 327]]}
{"doc_key": "ai-test-55", "ner": [[4, 6, "algorithm"], [23, 24, "algorithm"], [30, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[4, 6, 23, 24, "compare", "", false, false], [4, 6, 30, 32, "compare", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["The", "difference", "between", "the", "multinomial", "logit", "model", "and", "numerous", "other", "methods", ",", "models", ",", "algorithms", ",", "etc.", "with", "the", "same", "basic", "structure", "(", "perceptron", "algorithm", ",", "support", "vector", "machines", ",", "linear", "discriminant", "analysis", ",", "etc", "."], "sentence-detokenized": "The difference between the multinomial logit model and numerous other methods, models, algorithms, etc. with the same basic structure (perceptron algorithm, support vector machines, linear discriminant analysis, etc.", "token2charspan": [[0, 3], [4, 14], [15, 22], [23, 26], [27, 38], [39, 44], [45, 50], [51, 54], [55, 63], [64, 69], [70, 77], [77, 78], [79, 85], [85, 86], [87, 97], [97, 98], [99, 103], [104, 108], [109, 112], [113, 117], [118, 123], [124, 133], [134, 135], [135, 145], [146, 155], [155, 156], [157, 164], [165, 171], [172, 180], [180, 181], [182, 188], [189, 201], [202, 210], [210, 211], [212, 215], [215, 216]]}
{"doc_key": "ai-test-56", "ner": [[0, 3, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Association", "for", "Computational", "Linguistics", ",", "published", "by"], "sentence-detokenized": "Association for Computational Linguistics, published by", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [41, 42], [43, 52], [53, 55]]}
{"doc_key": "ai-test-57", "ner": [[5, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "a", "computer", "-", "based", "face", "recognition", "system", ",", "each", "face", "is", "represented", "by", "a", "large", "number", "of", "pixel", "values", "."], "sentence-detokenized": "In a computer-based face recognition system, each face is represented by a large number of pixel values.", "token2charspan": [[0, 2], [3, 4], [5, 13], [13, 14], [14, 19], [20, 24], [25, 36], [37, 43], [43, 44], [45, 49], [50, 54], [55, 57], [58, 69], [70, 72], [73, 74], [75, 80], [81, 87], [88, 90], [91, 96], [97, 103], [103, 104]]}
{"doc_key": "ai-test-58", "ner": [[6, 7, "person"], [14, 16, "organisation"], [23, 23, "country"], [26, 26, "person"], [37, 39, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 7, 14, 16, "role", "", false, false], [6, 7, 23, 23, "physical", "", false, false], [26, 26, 37, 39, "origin", "", false, false], [26, 26, 37, 39, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2002", ",", "his", "son", ",", "Daniel", "Pearl", ",", "a", "journalist", "working", "for", "the", "Wall", "Street", "Journal", ",", "was", "kidnapped", "and", "murdered", "in", "Pakistan", ",", "prompting", "Judea", "and", "other", "family", "members", "and", "friends", "to", "set", "up", "the", "Daniel", "Pearl", "Foundation", "."], "sentence-detokenized": "In 2002, his son, Daniel Pearl, a journalist working for the Wall Street Journal, was kidnapped and murdered in Pakistan, prompting Judea and other family members and friends to set up the Daniel Pearl Foundation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [16, 17], [18, 24], [25, 30], [30, 31], [32, 33], [34, 44], [45, 52], [53, 56], [57, 60], [61, 65], [66, 72], [73, 80], [80, 81], [82, 85], [86, 95], [96, 99], [100, 108], [109, 111], [112, 120], [120, 121], [122, 131], [132, 137], [138, 141], [142, 147], [148, 154], [155, 162], [163, 166], [167, 174], [175, 177], [178, 181], [182, 184], [185, 188], [189, 195], [196, 201], [202, 212], [212, 213]]}
{"doc_key": "ai-test-59", "ner": [[4, 6, "organisation"], [17, 18, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 17, 18, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["From", "late", "2006", ",", "Red", "Envelope", "Entertainment", "also", "expanded", "to", "produce", "original", "content", "with", "filmmakers", "such", "as", "John", "Waters", "."], "sentence-detokenized": "From late 2006, Red Envelope Entertainment also expanded to produce original content with filmmakers such as John Waters.", "token2charspan": [[0, 4], [5, 9], [10, 14], [14, 15], [16, 19], [20, 28], [29, 42], [43, 47], [48, 56], [57, 59], [60, 67], [68, 76], [77, 84], [85, 89], [90, 100], [101, 105], [106, 108], [109, 113], [114, 120], [120, 121]]}
{"doc_key": "ai-test-60", "ner": [[6, 10, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "building", "is", "now", "part", "of", "Beth", "Israel", "Deaconess", "Medical", "Center", "."], "sentence-detokenized": "The building is now part of Beth Israel Deaconess Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 32], [33, 39], [40, 49], [50, 57], [58, 64], [64, 65]]}
{"doc_key": "ai-test-61", "ner": [[18, 19, "field"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "common", "theme", "in", "this", "work", "is", "the", "introduction", "of", "a", "sign", "theoretic", "perspective", "on", "issues", "related", "to", "artificial", "intelligence", "and", "knowledge", "representation", "."], "sentence-detokenized": "A common theme in this work is the introduction of a sign theoretic perspective on issues related to artificial intelligence and knowledge representation.", "token2charspan": [[0, 1], [2, 8], [9, 14], [15, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 47], [48, 50], [51, 52], [53, 57], [58, 67], [68, 79], [80, 82], [83, 89], [90, 97], [98, 100], [101, 111], [112, 124], [125, 128], [129, 138], [139, 153], [153, 154]]}
{"doc_key": "ai-test-62", "ner": [[5, 7, "task"], [9, 9, "task"], [21, 22, "task"], [38, 39, "task"], [41, 44, "task"], [48, 50, "task"], [52, 52, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 7, 21, 22, "type-of", "", false, false], [5, 7, 48, 50, "compare", "", false, false], [5, 7, 48, 50, "opposite", "", false, false], [9, 9, 5, 7, "named", "", false, false], [38, 39, 48, 50, "part-of", "", false, false], [41, 44, 48, 50, "part-of", "", false, false], [48, 50, 21, 22, "type-of", "", false, false], [52, 52, 48, 50, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["For", "example", ",", "the", "term", "neural", "machine", "translation", "(", "NMT", ")", "emphasizes", "the", "fact", "that", "deep", "learning", "-", "based", "methods", "for", "machine", "translation", "directly", "learn", "sequence", "-", "to", "-", "sequence", "transformations", ",", "thus", "obviating", "intermediate", "steps", "such", "as", "word", "alignment", "and", "language", "modeling", ",", "which", "were", "used", "in", "statistical", "machine", "translation", "(", "SMT", ")", "."], "sentence-detokenized": "For example, the term neural machine translation (NMT) emphasizes the fact that deep learning-based methods for machine translation directly learn sequence-to-sequence transformations, thus obviating intermediate steps such as word alignment and language modeling, which were used in statistical machine translation (SMT).", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 36], [37, 48], [49, 50], [50, 53], [53, 54], [55, 65], [66, 69], [70, 74], [75, 79], [80, 84], [85, 93], [93, 94], [94, 99], [100, 107], [108, 111], [112, 119], [120, 131], [132, 140], [141, 146], [147, 155], [155, 156], [156, 158], [158, 159], [159, 167], [168, 183], [183, 184], [185, 189], [190, 199], [200, 212], [213, 218], [219, 223], [224, 226], [227, 231], [232, 241], [242, 245], [246, 254], [255, 263], [263, 264], [265, 270], [271, 275], [276, 280], [281, 283], [284, 295], [296, 303], [304, 315], [316, 317], [317, 320], [320, 321], [321, 322]]}
{"doc_key": "ai-test-63", "ner": [[4, 5, "field"], [9, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 9, 10, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Most", "research", "in", "the", "WSD", "field", "is", "conducted", "using", "Word", "Net", "as", "a", "reference", "directory", "of", "meanings", "for", "."], "sentence-detokenized": "Most research in the WSD field is conducted using WordNet as a reference directory of meanings for.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 24], [25, 30], [31, 33], [34, 43], [44, 49], [50, 54], [54, 57], [58, 60], [61, 62], [63, 72], [73, 82], [83, 85], [86, 94], [95, 98], [98, 99]]}
{"doc_key": "ai-test-64", "ner": [[2, 2, "misc"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 2, 2, "general-affiliation", "", false, true], [14, 15, 2, 2, "general-affiliation", "", false, true]], "relations_mapping_to_source": [0, 1], "sentence": ["Notable", "former", "PhD", "students", "and", "postdoctoral", "researchers", "from", "his", "group", "include", "Richard", "Zemel", "and", "Zoubin", "Ghahramani", "."], "sentence-detokenized": "Notable former PhD students and postdoctoral researchers from his group include Richard Zemel and Zoubin Ghahramani.", "token2charspan": [[0, 7], [8, 14], [15, 18], [19, 27], [28, 31], [32, 44], [45, 56], [57, 61], [62, 65], [66, 71], [72, 79], [80, 87], [88, 93], [94, 97], [98, 104], [105, 115], [115, 116]]}
{"doc_key": "ai-test-65", "ner": [[8, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Each", "prediction", "result", "or", "each", "occurrence", "of", "a", "confusion", "matrix", "represents", "a", "point", "in", "the", "ROC", "area", "."], "sentence-detokenized": "Each prediction result or each occurrence of a confusion matrix represents a point in the ROC area.", "token2charspan": [[0, 4], [5, 15], [16, 22], [23, 25], [26, 30], [31, 41], [42, 44], [45, 46], [47, 56], [57, 63], [64, 74], [75, 76], [77, 82], [83, 85], [86, 89], [90, 93], [94, 98], [98, 99]]}
{"doc_key": "ai-test-66", "ner": [[3, 6, "researcher"], [9, 10, "researcher"], [12, 13, "researcher"], [20, 22, "product"], [25, 27, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 25, 27, "physical", "", false, false], [9, 10, 25, 27, "physical", "", false, false], [12, 13, 25, 27, "physical", "", false, false], [20, 22, 3, 6, "artifact", "", false, false], [20, 22, 9, 10, "artifact", "", false, false], [20, 22, 12, 13, "artifact", "", false, false], [20, 22, 25, 27, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "1997", ",", "Thrun", ",", "together", "with", "his", "colleagues", "Wolfram", "Burgard", "and", "Dieter", "Fox", ",", "developed", "the", "world", "'s", "first", "robot", "tour", "guide", "at", "the", "Deutsches", "Museum", "Bonn", "(", "1997", ")", "."], "sentence-detokenized": "In 1997, Thrun, together with his colleagues Wolfram Burgard and Dieter Fox, developed the world's first robot tour guide at the Deutsches Museum Bonn (1997).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [14, 15], [16, 24], [25, 29], [30, 33], [34, 44], [45, 52], [53, 60], [61, 64], [65, 71], [72, 75], [75, 76], [77, 86], [87, 90], [91, 96], [96, 98], [99, 104], [105, 110], [111, 115], [116, 121], [122, 124], [125, 128], [129, 138], [139, 145], [146, 150], [151, 152], [152, 156], [156, 157], [157, 158]]}
{"doc_key": "ai-test-67", "ner": [[0, 2, "product"], [7, 7, "misc"], [21, 24, "field"], [26, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 0, 2, "part-of", "", false, false], [21, 24, 0, 2, "usage", "", false, false], [26, 28, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Word", "Net", "is", "a", "lexical", "database", "of", "semantic", "relationships", "between", "words", "in", "more", "than", "200", "languages", ",", "primarily", "used", "for", "automatic", "processing", "of", "natural", "languages", "and", "artificial", "intelligence", "applications", "."], "sentence-detokenized": "WordNet is a lexical database of semantic relationships between words in more than 200 languages, primarily used for automatic processing of natural languages and artificial intelligence applications.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 32], [33, 41], [42, 55], [56, 63], [64, 69], [70, 72], [73, 77], [78, 82], [83, 86], [87, 96], [96, 97], [98, 107], [108, 112], [113, 116], [117, 126], [127, 137], [138, 140], [141, 148], [149, 158], [159, 162], [163, 173], [174, 186], [187, 199], [199, 200]]}
{"doc_key": "ai-test-68", "ner": [[0, 3, "field"], [8, 11, "conference"], [14, 22, "conference"], [24, 24, "conference"], [26, 26, "conference"], [34, 35, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 11, 0, 3, "topic", "", false, false], [8, 11, 34, 35, "topic", "", false, false], [14, 22, 0, 3, "topic", "", false, false], [14, 22, 34, 35, "topic", "", false, false], [24, 24, 0, 3, "topic", "", false, false], [24, 24, 34, 35, "topic", "", false, false], [26, 26, 0, 3, "topic", "", false, false], [26, 26, 34, 35, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Natural", "language", "processing", "conferences", ",", "such", "as", "the", "Association", "for", "Computational", "Linguistics", ",", "the", "North", "American", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "EMNLP", "and", "HLT", ",", "have", "started", "to", "include", "papers", "on", "speech", "processing", "."], "sentence-detokenized": "Natural language processing conferences, such as the Association for Computational Linguistics, the North American Chapter of the Association for Computational Linguistics, EMNLP and HLT, have started to include papers on speech processing.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 39], [39, 40], [41, 45], [46, 48], [49, 52], [53, 64], [65, 68], [69, 82], [83, 94], [94, 95], [96, 99], [100, 105], [106, 114], [115, 122], [123, 125], [126, 129], [130, 141], [142, 145], [146, 159], [160, 171], [171, 172], [173, 178], [179, 182], [183, 186], [186, 187], [188, 192], [193, 200], [201, 203], [204, 211], [212, 218], [219, 221], [222, 228], [229, 239], [239, 240]]}
{"doc_key": "ai-test-69", "ner": [[22, 23, "misc"], [35, 37, "misc"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "set", "of", "Java", "programs", "uses", "the", "lexicon", "to", "work", "through", "the", "variations", "in", "biomedical", "texts", "by", "relating", "words", "according", "to", "their", "word", "parts", ",", "which", "can", "be", "useful", "for", "web", "searches", "or", "in", "an", "electronic", "health", "record", "."], "sentence-detokenized": "A set of Java programs uses the lexicon to work through the variations in biomedical texts by relating words according to their word parts, which can be useful for web searches or in an electronic health record.", "token2charspan": [[0, 1], [2, 5], [6, 8], [9, 13], [14, 22], [23, 27], [28, 31], [32, 39], [40, 42], [43, 47], [48, 55], [56, 59], [60, 70], [71, 73], [74, 84], [85, 90], [91, 93], [94, 102], [103, 108], [109, 118], [119, 121], [122, 127], [128, 132], [133, 138], [138, 139], [140, 145], [146, 149], [150, 152], [153, 159], [160, 163], [164, 167], [168, 176], [177, 179], [180, 182], [183, 185], [186, 196], [197, 203], [204, 210], [210, 211]]}
{"doc_key": "ai-test-70", "ner": [[7, 7, "algorithm"], [9, 9, "algorithm"], [11, 11, "algorithm"], [13, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "many", "newer", "algorithms", "such", "as", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", "and", "others", "."], "sentence-detokenized": "There are many newer algorithms such as LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost and others.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 20], [21, 31], [32, 36], [37, 39], [40, 47], [47, 48], [49, 59], [59, 60], [61, 71], [71, 72], [73, 80], [80, 81], [82, 91], [92, 95], [96, 102], [102, 103]]}
{"doc_key": "ai-test-71", "ner": [[8, 8, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "of", "an", "implementation", "in", "Python", ":"], "sentence-detokenized": "This is an example of an implementation in Python:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 24], [25, 39], [40, 42], [43, 49], [49, 50]]}
{"doc_key": "ai-test-72", "ner": [[0, 1, "organisation"], [5, 6, "task"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Mattel", "Intellivision", "game", "console", "Intellivoice", "Voice", "Synthesis", "module", "became", "available", "in", "1982", "."], "sentence-detokenized": "The Mattel Intellivision game console Intellivoice Voice Synthesis module became available in 1982.", "token2charspan": [[0, 3], [4, 10], [11, 24], [25, 29], [30, 37], [38, 50], [51, 56], [57, 66], [67, 73], [74, 80], [81, 90], [91, 93], [94, 98], [98, 99]]}
{"doc_key": "ai-test-73", "ner": [[5, 6, "task"], [9, 15, "task"], [17, 18, "field"], [20, 22, "task"], [25, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 15, 5, 6, "part-of", "", false, false], [17, 18, 5, 6, "part-of", "", false, false], [20, 22, 5, 6, "part-of", "", false, false], [25, 29, 20, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "has", "also", "worked", "on", "machine", "translation", ",", "both", "high", "-", "precision", "knowledge", "-", "based", "MT", "and", "machine", "learning", "for", "statistical", "machine", "translation", "(", "e.g.", "generalised", "example", "-", "based", "MT", ")", "."], "sentence-detokenized": "He has also worked on machine translation, both high-precision knowledge-based MT and machine learning for statistical machine translation (e.g. generalised example-based MT).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 21], [22, 29], [30, 41], [41, 42], [43, 47], [48, 52], [52, 53], [53, 62], [63, 72], [72, 73], [73, 78], [79, 81], [82, 85], [86, 93], [94, 102], [103, 106], [107, 118], [119, 126], [127, 138], [139, 140], [140, 144], [145, 156], [157, 164], [164, 165], [165, 170], [171, 173], [173, 174], [174, 175]]}
{"doc_key": "ai-test-74", "ner": [[0, 1, "misc"], [5, 5, "misc"], [20, 21, "algorithm"], [23, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 32, "field"], [34, 35, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 20, 21, "general-affiliation", "", false, false], [0, 1, 23, 24, "general-affiliation", "", false, false], [0, 1, 26, 27, "general-affiliation", "", false, false], [0, 1, 29, 29, "general-affiliation", "", false, false], [0, 1, 31, 32, "general-affiliation", "", false, false], [0, 1, 34, 35, "general-affiliation", "", false, false], [5, 5, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "commonly", "called", "Mathematica", ")", "is", "a", "modern", "technical", "computing", "system", "that", "covers", "most", "technical", "areas", "-", "including", "neural", "networks", ",", "machine", "learning", ",", "image", "processing", ",", "geometry", ",", "computer", "science", ",", "visualizations", "and", "others", "."], "sentence-detokenized": "Wolfram Mathematica (commonly called Mathematica) is a modern technical computing system that covers most technical areas - including neural networks, machine learning, image processing, geometry, computer science, visualizations and others.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 29], [30, 36], [37, 48], [48, 49], [50, 52], [53, 54], [55, 61], [62, 71], [72, 81], [82, 88], [89, 93], [94, 100], [101, 105], [106, 115], [116, 121], [122, 123], [124, 133], [134, 140], [141, 149], [149, 150], [151, 158], [159, 167], [167, 168], [169, 174], [175, 185], [185, 186], [187, 195], [195, 196], [197, 205], [206, 213], [213, 214], [215, 229], [230, 233], [234, 240], [240, 241]]}
{"doc_key": "ai-test-75", "ner": [[2, 6, "product"], [10, 11, "researcher"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 18, 2, 6, "type-of", "", false, false], [18, 18, 10, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "digitally", "controlled", "and", "programmable", "robot", "was", "invented", "by", "George", "Devol", "in", "1954", "and", "was", "eventually", "called", "Unimate", "."], "sentence-detokenized": "The first digitally controlled and programmable robot was invented by George Devol in 1954 and was eventually called Unimate.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 30], [31, 34], [35, 47], [48, 53], [54, 57], [58, 66], [67, 69], [70, 76], [77, 82], [83, 85], [86, 90], [91, 94], [95, 98], [99, 109], [110, 116], [117, 124], [124, 125]]}
{"doc_key": "ai-test-76", "ner": [[1, 1, "algorithm"], [3, 3, "algorithm"], [17, 18, "task"], [20, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 3, 3, "compare", "", false, false], [3, 3, 17, 18, "general-affiliation", "", false, false], [3, 3, 20, 22, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Like", "DBNs", ",", "DBMs", "can", "learn", "complex", "and", "abstract", "internal", "representations", "of", "inputs", "in", "tasks", "such", "as", "object", "recognition", "or", "speech", "recognition", "using", "limited", "labeled", "data", "to", "fine", "-", "tune", "the", "representations", "built", "using", "a", "large", "set", "of", "unlabeled", "sensory", "input", "data", "."], "sentence-detokenized": "Like DBNs, DBMs can learn complex and abstract internal representations of inputs in tasks such as object recognition or speech recognition using limited labeled data to fine-tune the representations built using a large set of unlabeled sensory input data.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 15], [16, 19], [20, 25], [26, 33], [34, 37], [38, 46], [47, 55], [56, 71], [72, 74], [75, 81], [82, 84], [85, 90], [91, 95], [96, 98], [99, 105], [106, 117], [118, 120], [121, 127], [128, 139], [140, 145], [146, 153], [154, 161], [162, 166], [167, 169], [170, 174], [174, 175], [175, 179], [180, 183], [184, 199], [200, 205], [206, 211], [212, 213], [214, 219], [220, 223], [224, 226], [227, 236], [237, 244], [245, 250], [251, 255], [255, 256]]}
{"doc_key": "ai-test-77", "ner": [[5, 10, "task"], [14, 14, "conference"], [16, 16, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 5, 10, "topic", "", false, false], [16, 16, 5, 10, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Scientific", "conferences", "where", "work", "on", "vision", "-", "based", "activity", "recognition", "is", "often", "shown", "are", "ICCV", "and", "CVPR", "."], "sentence-detokenized": "Scientific conferences where work on vision-based activity recognition is often shown are ICCV and CVPR.", "token2charspan": [[0, 10], [11, 22], [23, 28], [29, 33], [34, 36], [37, 43], [43, 44], [44, 49], [50, 58], [59, 70], [71, 73], [74, 79], [80, 85], [86, 89], [90, 94], [95, 98], [99, 103], [103, 104]]}
{"doc_key": "ai-test-78", "ner": [[1, 1, "field"], [4, 5, "algorithm"], [16, 17, "metrics"], [19, 21, "metrics"], [23, 23, "metrics"], [37, 37, "misc"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6], "relations": [[4, 5, 1, 1, "part-of", "", false, false], [4, 5, 16, 17, "related-to", "finds", false, false], [4, 5, 19, 21, "related-to", "finds", false, false], [4, 5, 37, 37, "related-to", "", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5], "sentence": ["In", "statistics", ",", "an", "expectation", "-maximization", "(", "EM", ")", "algorithm", "is", "an", "iterative", "method", "for", "finding", "maximum", "likelihood", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "estimates", "of", "parameters", "in", "statistical", "models", "where", "the", "model", "depends", "on", "unobserved", "latent", "variables", "."], "sentence-detokenized": "In statistics, an expectation-maximization (EM) algorithm is an iterative method for finding maximum likelihood or maximum a posteriori (MAP) estimates of parameters in statistical models where the model depends on unobserved latent variables.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 17], [18, 29], [29, 42], [43, 44], [44, 46], [46, 47], [48, 57], [58, 60], [61, 63], [64, 73], [74, 80], [81, 84], [85, 92], [93, 100], [101, 111], [112, 114], [115, 122], [123, 124], [125, 135], [136, 137], [137, 140], [140, 141], [142, 151], [152, 154], [155, 165], [166, 168], [169, 180], [181, 187], [188, 193], [194, 197], [198, 203], [204, 211], [212, 214], [215, 225], [226, 232], [233, 242], [242, 243]]}
{"doc_key": "ai-test-79", "ner": [[5, 7, "metrics"], [9, 11, "metrics"], [12, 14, "metrics"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 11, 5, 7, "named", "", false, false], [16, 16, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Similarly", ",", "investigators", "sometimes", "report", "FALSE", "Positive", "Rate", "(", "FPR", ")", "and", "FALSE", "Negative", "Rate", "(", "FNR", ")", "."], "sentence-detokenized": "Similarly, investigators sometimes report FALSE Positive Rate (FPR) and FALSE Negative Rate (FNR).", "token2charspan": [[0, 9], [9, 10], [11, 24], [25, 34], [35, 41], [42, 47], [48, 56], [57, 61], [62, 63], [63, 66], [66, 67], [68, 71], [72, 77], [78, 86], [87, 91], [92, 93], [93, 96], [96, 97], [97, 98]]}
{"doc_key": "ai-test-80", "ner": [[5, 10, "metrics"], [13, 13, "field"], [17, 18, "metrics"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 13, 5, 10, "usage", "", false, false], [21, 22, 17, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "concept", "corresponds", "to", "the", "signal", "-", "to", "-", "noise", "ratio", "used", "in", "science", "and", "to", "the", "confusion", "matrix", "used", "in", "artificial", "intelligence", "."], "sentence-detokenized": "The concept corresponds to the signal-to-noise ratio used in science and to the confusion matrix used in artificial intelligence.", "token2charspan": [[0, 3], [4, 11], [12, 23], [24, 26], [27, 30], [31, 37], [37, 38], [38, 40], [40, 41], [41, 46], [47, 52], [53, 57], [58, 60], [61, 68], [69, 72], [73, 75], [76, 79], [80, 89], [90, 96], [97, 101], [102, 104], [105, 115], [116, 128], [128, 129]]}
{"doc_key": "ai-test-81", "ner": [[5, 6, "field"], [11, 12, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [31, 34, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 11, 12, "general-affiliation", "", false, false], [5, 6, 18, 19, "general-affiliation", "", false, false], [5, 6, 21, 22, "general-affiliation", "", false, false], [31, 34, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Code", "of", "Ethics", "for", "Human", "Augmentation", ",", "originally", "introduced", "by", "Steve", "Mann", "in", "2004", "and", "refined", "with", "Ray", "Kurzweil", "and", "Marvin", "Minsky", "in", "2013", ",", "was", "finally", "ratified", "at", "the", "Virtual", "Reality", "Toronto", "conference", "on", "25", "June", "2017", "."], "sentence-detokenized": "The Code of Ethics for Human Augmentation, originally introduced by Steve Mann in 2004 and refined with Ray Kurzweil and Marvin Minsky in 2013, was finally ratified at the Virtual Reality Toronto conference on 25 June 2017.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 18], [19, 22], [23, 28], [29, 41], [41, 42], [43, 53], [54, 64], [65, 67], [68, 73], [74, 78], [79, 81], [82, 86], [87, 90], [91, 98], [99, 103], [104, 107], [108, 116], [117, 120], [121, 127], [128, 134], [135, 137], [138, 142], [142, 143], [144, 147], [148, 155], [156, 164], [165, 167], [168, 171], [172, 179], [180, 187], [188, 195], [196, 206], [207, 209], [210, 212], [213, 217], [218, 222], [222, 223]]}
{"doc_key": "ai-test-82", "ner": [[3, 5, "person"], [11, 13, "organisation"], [19, 20, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 11, 13, "role", "directed_for", false, false], [3, 5, 19, 20, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1913", ",", "Walter", "R.", "Booth", "directed", "10", "films", "for", "the", "British", "Cinema", "Company", ",", "probably", "in", "collaboration", "with", "Cecil", "Hepworth", "."], "sentence-detokenized": "In 1913, Walter R. Booth directed 10 films for the British Cinema Company, probably in collaboration with Cecil Hepworth.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 18], [19, 24], [25, 33], [34, 36], [37, 42], [43, 46], [47, 50], [51, 58], [59, 65], [66, 73], [73, 74], [75, 83], [84, 86], [87, 100], [101, 105], [106, 111], [112, 120], [120, 121]]}
{"doc_key": "ai-test-83", "ner": [[11, 11, "location"], [13, 14, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 11, 11, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "presented", "their", "new", "robot", "in", "1961", "at", "a", "fair", "in", "Chicago", "'s", "Cow", "Palace", "."], "sentence-detokenized": "They presented their new robot in 1961 at a fair in Chicago's Cow Palace.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 24], [25, 30], [31, 33], [34, 38], [39, 41], [42, 43], [44, 48], [49, 51], [52, 59], [59, 61], [62, 65], [66, 72], [72, 73]]}
{"doc_key": "ai-test-84", "ner": [[10, 11, "field"], [15, 16, "field"]], "ner_mapping_to_source": [2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["While", "some", "chatbot", "applications", "use", "extensive", "word", "classification", "processes", ",", "natural", "language", "processors", "and", "sophisticated", "artificial", "intelligence", ",", "others", "simply", "scan", "for", "general", "keywords", "and", "generate", "answers", "using", "common", "phrases", "from", "an", "associated", "library", "or", "database", "."], "sentence-detokenized": "While some chatbot applications use extensive word classification processes, natural language processors and sophisticated artificial intelligence, others simply scan for general keywords and generate answers using common phrases from an associated library or database.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 31], [32, 35], [36, 45], [46, 50], [51, 65], [66, 75], [75, 76], [77, 84], [85, 93], [94, 104], [105, 108], [109, 122], [123, 133], [134, 146], [146, 147], [148, 154], [155, 161], [162, 166], [167, 170], [171, 178], [179, 187], [188, 191], [192, 200], [201, 208], [209, 214], [215, 221], [222, 229], [230, 234], [235, 237], [238, 248], [249, 256], [257, 259], [260, 268], [268, 269]]}
{"doc_key": "ai-test-85", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "WaveNet", "model", "proposed", "in", "2016", "achieves", "good", "results", "in", "terms", "of", "speech", "quality", "."], "sentence-detokenized": "The WaveNet model proposed in 2016 achieves good results in terms of speech quality.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 43], [44, 48], [49, 56], [57, 59], [60, 65], [66, 68], [69, 75], [76, 83], [83, 84]]}
{"doc_key": "ai-test-86", "ner": [[4, 4, "product"], [6, 7, "misc"], [9, 10, "misc"], [12, 13, "misc"], [15, 18, "misc"], [20, 22, "organisation"], [24, 24, "organisation"], [26, 28, "organisation"], [31, 31, "organisation"], [33, 36, "organisation"], [38, 38, "organisation"], [40, 40, "organisation"], [42, 44, "organisation"], [46, 46, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 4, 6, 7, "general-affiliation", "", false, false], [4, 4, 9, 10, "general-affiliation", "", false, false], [4, 4, 12, 13, "general-affiliation", "", false, false], [4, 4, 15, 18, "general-affiliation", "", false, false], [20, 22, 4, 4, "usage", "", false, false], [24, 24, 4, 4, "usage", "", false, false], [26, 28, 4, 4, "usage", "", false, false], [31, 31, 4, 4, "usage", "", false, false], [33, 36, 4, 4, "usage", "", false, false], [38, 38, 4, 4, "usage", "", false, false], [40, 40, 4, 4, "usage", "", false, false], [42, 44, 4, 4, "usage", "", false, false], [46, 46, 4, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organisations", "known", "to", "use", "ALE", "for", "disaster", "management", ",", "disaster", "relief", ",", "general", "communications", "or", "response", "in", "extraordinary", "situations", ":", "American", "Red", "Cross", ",", "FEMA", ",", "Disaster", "Medical", "Assistance", "Teams", ",", "NATO", ",", "Federal", "Bureau", "of", "Investigation", ",", "UN", ",", "AT&T", ",", "Civil", "Air", "Patrol", "(", "ARES", ")", "."], "sentence-detokenized": "Organisations known to use ALE for disaster management, disaster relief, general communications or response in extraordinary situations: American Red Cross, FEMA, Disaster Medical Assistance Teams, NATO, Federal Bureau of Investigation, UN, AT&T, Civil Air Patrol (ARES).", "token2charspan": [[0, 13], [14, 19], [20, 22], [23, 26], [27, 30], [31, 34], [35, 43], [44, 54], [54, 55], [56, 64], [65, 71], [71, 72], [73, 80], [81, 95], [96, 98], [99, 107], [108, 110], [111, 124], [125, 135], [135, 136], [137, 145], [146, 149], [150, 155], [155, 156], [157, 161], [161, 162], [163, 171], [172, 179], [180, 190], [191, 196], [196, 197], [198, 202], [202, 203], [204, 211], [212, 218], [219, 221], [222, 235], [235, 236], [237, 239], [239, 240], [241, 245], [245, 246], [247, 252], [253, 256], [257, 263], [264, 265], [265, 269], [269, 270], [270, 271]]}
{"doc_key": "ai-test-87", "ner": [[2, 3, "algorithm"], [15, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", "the", "Kronecker", "delta", "is", "used", "for", "simplicity", "(", "cf", ".", "the", "derivative", "of", "a", "sigmoid", "function", ",", "which", "is", "expressed", "via", "the", "function", "itself", ")", "."], "sentence-detokenized": "Here the Kronecker delta is used for simplicity (cf. the derivative of a sigmoid function, which is expressed via the function itself).", "token2charspan": [[0, 4], [5, 8], [9, 18], [19, 24], [25, 27], [28, 32], [33, 36], [37, 47], [48, 49], [49, 51], [51, 52], [53, 56], [57, 67], [68, 70], [71, 72], [73, 80], [81, 89], [89, 90], [91, 96], [97, 99], [100, 109], [110, 113], [114, 117], [118, 126], [127, 133], [133, 134], [134, 135]]}
{"doc_key": "ai-test-88", "ner": [[12, 13, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "theory", "is", "based", "on", "a", "philosophical", "foundation", "and", "was", "founded", "by", "Ray", "Solomonoff", "around", "1960", ".", "Samuel", "Rathmanner", "and", "Marcus", "Hutter", "."], "sentence-detokenized": "The theory is based on a philosophical foundation and was founded by Ray Solomonoff around 1960. Samuel Rathmanner and Marcus Hutter.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 24], [25, 38], [39, 49], [50, 53], [54, 57], [58, 65], [66, 68], [69, 72], [73, 83], [84, 90], [91, 95], [95, 96], [97, 103], [104, 114], [115, 118], [119, 125], [126, 132], [132, 133]]}
{"doc_key": "ai-test-89", "ner": [[0, 0, "product"], [10, 11, "misc"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 11, "type-of", "", false, false], [0, 0, 14, 15, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "a", "freely", "accessible", "database", "originally", "designed", "as", "a", "semantic", "network", "based", "on", "psycholinguistic", "principles", ",", "was", "expanded", "to", "include", "definitions", "and", "is", "now", "also", "considered", "a", "dictionary", "."], "sentence-detokenized": "WordNet, a freely accessible database originally designed as a semantic network based on psycholinguistic principles, was expanded to include definitions and is now also considered a dictionary.", "token2charspan": [[0, 7], [7, 8], [9, 10], [11, 17], [18, 28], [29, 37], [38, 48], [49, 57], [58, 60], [61, 62], [63, 71], [72, 79], [80, 85], [86, 88], [89, 105], [106, 116], [116, 117], [118, 121], [122, 130], [131, 133], [134, 141], [142, 153], [154, 157], [158, 160], [161, 164], [165, 169], [170, 180], [181, 182], [183, 193], [193, 194]]}
{"doc_key": "ai-test-90", "ner": [[2, 3, "field"], [12, 15, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 15, 2, 3, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Advances", "in", "computational", "imaging", "research", "are", "presented", "in", "several", "venues", ",", "including", "SIGGRAPH", "and", "SIGGRAPH", "publications", "."], "sentence-detokenized": "Advances in computational imaging research are presented in several venues, including SIGGRAPH and SIGGRAPH publications.", "token2charspan": [[0, 8], [9, 11], [12, 25], [26, 33], [34, 42], [43, 46], [47, 56], [57, 59], [60, 67], [68, 74], [74, 75], [76, 85], [86, 94], [95, 98], [99, 107], [108, 120], [120, 121]]}
{"doc_key": "ai-test-91", "ner": [[0, 0, "task"], [9, 10, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 0, "part-of", "", false, false], [12, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "considered", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multiclass", "classification", "."], "sentence-detokenized": "Classification can be considered as two separate problems - binary classification and multiclass classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 48], [49, 57], [58, 59], [60, 66], [67, 81], [82, 85], [86, 96], [97, 111], [111, 112]]}
{"doc_key": "ai-test-92", "ner": [[11, 11, "algorithm"], [16, 16, "algorithm"], [20, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 16, 11, 11, "type-of", "", false, false], [20, 20, 16, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Advanced", "geneticists", "for", "both", "prokaryotic", "and", "eukaryotic", "genomes", "typically", "use", "complex", "probabilistic", "models", ",", "such", "as", "hidden", "Markov", "models", "(", "HMMs", ")", ",", "to", "combine", "information", "from", "a", "variety", "of", "signal", "and", "content", "measurements", "."], "sentence-detokenized": "Advanced geneticists for both prokaryotic and eukaryotic genomes typically use complex probabilistic models, such as hidden Markov models (HMMs), to combine information from a variety of signal and content measurements.", "token2charspan": [[0, 8], [9, 20], [21, 24], [25, 29], [30, 41], [42, 45], [46, 56], [57, 64], [65, 74], [75, 78], [79, 86], [87, 100], [101, 107], [107, 108], [109, 113], [114, 116], [117, 123], [124, 130], [131, 137], [138, 139], [139, 143], [143, 144], [144, 145], [146, 148], [149, 156], [157, 168], [169, 173], [174, 175], [176, 183], [184, 186], [187, 193], [194, 197], [198, 205], [206, 218], [218, 219]]}
{"doc_key": "ai-test-93", "ner": [[0, 0, "misc"], [2, 4, "misc"], [7, 8, "field"], [11, 12, "algorithm"], [15, 16, "algorithm"], [19, 19, "algorithm"], [29, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 7, 8, "part-of", "", false, false], [0, 0, 11, 12, "usage", "", false, false], [2, 4, 0, 0, "named", "", false, false], [15, 16, 0, 0, "origin", "", true, false], [19, 19, 15, 16, "named", "", false, false], [29, 30, 0, 0, "origin", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Neuroevolution", "or", "neuroevolution", "is", "a", "form", "of", "artificial", "intelligence", "that", "uses", "evolutionary", "algorithms", "to", "generate", "artificial", "neural", "networks", "(", "ANN", ")", ",", "parameters", ",", "topology", "and", "rules", ".", "and", "evolutionary", "robotics", "."], "sentence-detokenized": "Neuroevolution or neuroevolution is a form of artificial intelligence that uses evolutionary algorithms to generate artificial neural networks (ANN), parameters, topology and rules. and evolutionary robotics.", "token2charspan": [[0, 14], [15, 17], [18, 32], [33, 35], [36, 37], [38, 42], [43, 45], [46, 56], [57, 69], [70, 74], [75, 79], [80, 92], [93, 103], [104, 106], [107, 115], [116, 126], [127, 133], [134, 142], [143, 144], [144, 147], [147, 148], [148, 149], [150, 160], [160, 161], [162, 170], [171, 174], [175, 180], [180, 181], [182, 185], [186, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-test-94", "ner": [[1, 1, "organisation"], [5, 7, "metrics"], [8, 8, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 1, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "IBM", "proposed", "and", "realized", "the", "BLEU", "system", "Papineni", "et", "al", "."], "sentence-detokenized": "Since IBM proposed and realized the BLEU system Papineni et al.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 22], [23, 31], [32, 35], [36, 40], [41, 47], [48, 56], [57, 59], [60, 62], [62, 63]]}
{"doc_key": "ai-test-95", "ner": [[10, 16, "conference"], [18, 18, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 18, 10, 16, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2009", ",", "experts", "attended", "a", "conference", "organised", "by", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "to", "discuss", "whether", "computers", "and", "robots", "could", "become", "capable", "of", "autonomy", "and", "to", "what", "extent", "these", "capabilities", "could", "pose", "a", "threat", "or", "danger", "."], "sentence-detokenized": "In 2009, experts attended a conference organised by the Association for the Advancement of Artificial Intelligence (AAAI) to discuss whether computers and robots could become capable of autonomy and to what extent these capabilities could pose a threat or danger.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 25], [26, 27], [28, 38], [39, 48], [49, 51], [52, 55], [56, 67], [68, 71], [72, 75], [76, 87], [88, 90], [91, 101], [102, 114], [115, 116], [116, 120], [120, 121], [122, 124], [125, 132], [133, 140], [141, 150], [151, 154], [155, 161], [162, 167], [168, 174], [175, 182], [183, 185], [186, 194], [195, 198], [199, 201], [202, 206], [207, 213], [214, 219], [220, 232], [233, 238], [239, 243], [244, 245], [246, 252], [253, 255], [256, 262], [262, 263]]}
{"doc_key": "ai-test-96", "ner": [[25, 27, "metrics"], [28, 30, "researcher"], [32, 33, "researcher"], [35, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[35, 40, 25, 27, "topic", "", false, false], [35, 40, 28, 30, "artifact", "", false, false], [35, 40, 32, 33, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["After", "boosting", ",", "a", "classifier", "constructed", "from", "200", "features", "can", "give", "a", "95", "%", "detection", "rate", "under", "a", "^", "{", "-", "5", "}", "/", "math", "FALSE", "positive", "rate", ".P", ".", "Viola", ",", "M.", "Jones", ",", "Robust", "Real", "-", "time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "After boosting, a classifier constructed from 200 features can give a 95% detection rate under a ^ {-5} / math FALSE positive rate .P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 17], [18, 28], [29, 40], [41, 45], [46, 49], [50, 58], [59, 62], [63, 67], [68, 69], [70, 72], [72, 73], [74, 83], [84, 88], [89, 94], [95, 96], [97, 98], [99, 100], [100, 101], [101, 102], [102, 103], [104, 105], [106, 110], [111, 116], [117, 125], [126, 130], [131, 133], [133, 134], [135, 140], [140, 141], [142, 144], [145, 150], [150, 151], [152, 158], [159, 163], [163, 164], [164, 168], [169, 175], [176, 185], [185, 186], [187, 191], [191, 192]]}
{"doc_key": "ai-test-97", "ner": [[9, 9, "organisation"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "site", "was", "originally", "Perl", "-", "based", ",", "but", "IMDb", "no", "longer", "discloses", "which", "software", "it", "uses", "for", "security", "reasons", "."], "sentence-detokenized": "The site was originally Perl-based, but IMDb no longer discloses which software it uses for security reasons.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 23], [24, 28], [28, 29], [29, 34], [34, 35], [36, 39], [40, 44], [45, 47], [48, 54], [55, 64], [65, 70], [71, 79], [80, 82], [83, 87], [88, 91], [92, 100], [101, 108], [108, 109]]}
{"doc_key": "ai-test-98", "ner": [[5, 6, "researcher"], [8, 9, "researcher"], [11, 13, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "startup", "was", "founded", "by", "Demis", "Hassabis", ",", "Shane", "Legg", "and", "Mustafa", "Suleyman", "in", "2010", "."], "sentence-detokenized": "The startup was founded by Demis Hassabis, Shane Legg and Mustafa Suleyman in 2010.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 26], [27, 32], [33, 41], [41, 42], [43, 48], [49, 53], [54, 57], [58, 65], [66, 74], [75, 77], [78, 82], [82, 83]]}
{"doc_key": "ai-test-99", "ner": [[4, 5, "misc"], [8, 10, "metrics"], [23, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 4, 5, "type-of", "", false, false], [23, 24, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "very", "commonly", "used", "loss", "functions", "are", "the", "mean", "squared", "error", ",", "mathL", "(", "a", ")", "=", "a^2", "/", "math", ",", "and", "the", "absolute", "loss", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "/", "math", "."], "sentence-detokenized": "Two very commonly used loss functions are the mean squared error, mathL (a) = a^2/math, and the absolute loss, mathL (a) = | a |/math.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 27], [28, 37], [38, 41], [42, 45], [46, 50], [51, 58], [59, 64], [64, 65], [66, 71], [72, 73], [73, 74], [74, 75], [76, 77], [78, 81], [81, 82], [82, 86], [86, 87], [88, 91], [92, 95], [96, 104], [105, 109], [109, 110], [111, 116], [117, 118], [118, 119], [119, 120], [121, 122], [123, 124], [125, 126], [127, 128], [128, 129], [129, 133], [133, 134]]}
{"doc_key": "ai-test-100", "ner": [[3, 5, "algorithm"], [12, 14, "algorithm"], [16, 16, "algorithm"], [19, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 12, 14, "type-of", "example_of", false, false], [12, 14, 19, 20, "related-to", "", false, false], [16, 16, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "soft", "-margin", "support", "vector", "machine", "described", "above", "is", "an", "example", "of", "empirical", "risk", "minimization", "(", "ERM", ")", "for", "hinge", "loss", "."], "sentence-detokenized": "The soft-margin support vector machine described above is an example of empirical risk minimization (ERM) for hinge loss.", "token2charspan": [[0, 3], [4, 8], [8, 15], [16, 23], [24, 30], [31, 38], [39, 48], [49, 54], [55, 57], [58, 60], [61, 68], [69, 71], [72, 81], [82, 86], [87, 99], [100, 101], [101, 104], [104, 105], [106, 109], [110, 115], [116, 120], [120, 121]]}
{"doc_key": "ai-test-101", "ner": [[11, 11, "task"], [0, 3, "task"], [22, 22, "organisation"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[0, 3, 11, 11, "type-of", "", false, false], [22, 22, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["Neural", "machine", "translation", "is", "a", "deep", "learning", "-", "based", "approach", "to", "MT", "and", "has", "made", "rapid", "progress", "in", "recent", "years", ",", "with", "Google", "announcing", "that", "its", "translation", "services", "now", "use", "this", "technology", "rather", "than", "the", "previous", "statistical", "methods", "."], "sentence-detokenized": "Neural machine translation is a deep learning-based approach to MT and has made rapid progress in recent years, with Google announcing that its translation services now use this technology rather than the previous statistical methods.", "token2charspan": [[0, 6], [7, 14], [15, 26], [27, 29], [30, 31], [32, 36], [37, 45], [45, 46], [46, 51], [52, 60], [61, 63], [64, 66], [67, 70], [71, 74], [75, 79], [80, 85], [86, 94], [95, 97], [98, 104], [105, 110], [110, 111], [112, 116], [117, 123], [124, 134], [135, 139], [140, 143], [144, 155], [156, 164], [165, 168], [169, 172], [173, 177], [178, 188], [189, 195], [196, 200], [201, 204], [205, 213], [214, 225], [226, 233], [233, 234]]}
{"doc_key": "ai-test-102", "ner": [[15, 15, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "often", "results", "in", "very", "large", "performance", "gains", "when", "working", "with", "large", "corpora", "such", "as", "WordNet", "."], "sentence-detokenized": "This often results in very large performance gains when working with large corpora such as WordNet.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 21], [22, 26], [27, 32], [33, 44], [45, 50], [51, 55], [56, 63], [64, 68], [69, 74], [75, 82], [83, 87], [88, 90], [91, 98], [98, 99]]}
{"doc_key": "ai-test-103", "ner": [[0, 1, "task"], [5, 5, "field"], [18, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 18, 20, "part-of", "", false, false], [18, 20, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Face", "detection", "is", "used", "in", "biometrics", ",", "often", "as", "part", "of", "(", "or", "in", "conjunction", "with", ")", "a", "face", "recognition", "system", "."], "sentence-detokenized": "Face detection is used in biometrics, often as part of (or in conjunction with) a face recognition system.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 22], [23, 25], [26, 36], [36, 37], [38, 43], [44, 46], [47, 51], [52, 54], [55, 56], [56, 58], [59, 61], [62, 73], [74, 78], [78, 79], [80, 81], [82, 86], [87, 98], [99, 105], [105, 106]]}
{"doc_key": "ai-test-104", "ner": [[2, 4, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["trained", "using", "maximum", "likelihood", "estimation", "."], "sentence-detokenized": "trained using maximum likelihood estimation.", "token2charspan": [[0, 7], [8, 13], [14, 21], [22, 32], [33, 43], [43, 44]]}
{"doc_key": "ai-test-105", "ner": [[3, 3, "country"], [5, 9, "organisation"], [13, 13, "location"], [15, 15, "country"], [17, 20, "organisation"], [22, 22, "country"], [28, 28, "organisation"], [33, 35, "organisation"], [37, 37, "country"], [48, 51, "organisation"], [53, 53, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[5, 9, 13, 13, "physical", "", false, false], [13, 13, 15, 15, "physical", "", false, false], [17, 20, 22, 22, "physical", "", false, false], [33, 35, 37, 37, "physical", "", false, false], [48, 51, 53, 53, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ltd", ".", "in", "Thailand", ";", "Komatsu", "(", "Shanghai", ")", "Ltd.", "in", "1996", "in", "Shanghai", ",", "China", ";", "Industrial", "Power", "Alliance", "Ltd.", "in", "Japan", ",", "a", "joint", "venture", "with", "Cummins", ",", "in", "1998", ";", "L&T-", "Komatsu", "Limited", "in", "India", "in", "1998", "(", "shares", "sold", "in", "2013", ")", ";", "and", "Komatsu", "Brasil", "International", "Ltda.", "in", "Brazil", "in", "1998", "."], "sentence-detokenized": "Ltd. in Thailand; Komatsu (Shanghai) Ltd. in 1996 in Shanghai, China; Industrial Power Alliance Ltd. in Japan, a joint venture with Cummins, in 1998; L&T-Komatsu Limited in India in 1998 (shares sold in 2013); and Komatsu Brasil International Ltda. in Brazil in 1998.", "token2charspan": [[0, 3], [3, 4], [5, 7], [8, 16], [16, 17], [18, 25], [26, 27], [27, 35], [35, 36], [37, 41], [42, 44], [45, 49], [50, 52], [53, 61], [61, 62], [63, 68], [68, 69], [70, 80], [81, 86], [87, 95], [96, 100], [101, 103], [104, 109], [109, 110], [111, 112], [113, 118], [119, 126], [127, 131], [132, 139], [139, 140], [141, 143], [144, 148], [148, 149], [150, 154], [154, 161], [162, 169], [170, 172], [173, 178], [179, 181], [182, 186], [187, 188], [188, 194], [195, 199], [200, 202], [203, 207], [207, 208], [208, 209], [210, 213], [214, 221], [222, 228], [229, 242], [243, 248], [249, 251], [252, 258], [259, 261], [262, 266], [266, 267]]}
{"doc_key": "ai-test-106", "ner": [[0, 0, "organisation"], [4, 6, "misc"], [11, 12, "person"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[11, 12, 0, 0, "physical", "", false, false], [11, 12, 4, 6, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["dgp", "also", "occasionally", "hosts", "artists", "in", "residency", "(", "e.g.", "Oscar-", "winner", "Chris", "Landreth", "."], "sentence-detokenized": "dgp also occasionally hosts artists in residency (e.g. Oscar-winner Chris Landreth.", "token2charspan": [[0, 3], [4, 8], [9, 21], [22, 27], [28, 35], [36, 38], [39, 48], [49, 50], [50, 54], [55, 61], [61, 67], [68, 73], [74, 82], [82, 83]]}
{"doc_key": "ai-test-107", "ner": [[6, 8, "misc"], [10, 12, "misc"], [14, 17, "misc"], [21, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "currently", "includes", "four", "sub-competitions", "-", "RoboMaster", "Robotics", "Competition", ",", "RoboMaster", "Technical", "Challenge", ",", "ICRA", "RoboMaster", "AI", "Challenge", "and", "the", "new", "RoboMaster", "Youth", "Tournament", "."], "sentence-detokenized": "It currently includes four sub-competitions - RoboMaster Robotics Competition, RoboMaster Technical Challenge, ICRA RoboMaster AI Challenge and the new RoboMaster Youth Tournament.", "token2charspan": [[0, 2], [3, 12], [13, 21], [22, 26], [27, 43], [44, 45], [46, 56], [57, 65], [66, 77], [77, 78], [79, 89], [90, 99], [100, 109], [109, 110], [111, 115], [116, 126], [127, 129], [130, 139], [140, 143], [144, 147], [148, 151], [152, 162], [163, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-test-108", "ner": [[9, 10, "field"], [15, 18, "algorithm"], [22, 23, "algorithm"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 22, 23, "usage", "", false, false], [9, 10, 25, 26, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "the", "early", "2000s", ",", "the", "dominant", "approach", "to", "speech", "processing", "began", "to", "shift", "from", "the", "Hidden", "Markov", "Model", "to", "more", "modern", "neural", "networks", "and", "deep", "learning", "."], "sentence-detokenized": "In the early 2000s, the dominant approach to speech processing began to shift from the Hidden Markov Model to more modern neural networks and deep learning.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 18], [18, 19], [20, 23], [24, 32], [33, 41], [42, 44], [45, 51], [52, 62], [63, 68], [69, 71], [72, 77], [78, 82], [83, 86], [87, 93], [94, 100], [101, 106], [107, 109], [110, 114], [115, 121], [122, 128], [129, 137], [138, 141], [142, 146], [147, 155], [155, 156]]}
{"doc_key": "ai-test-109", "ner": [[8, 10, "misc"], [14, 16, "metrics"], [19, 21, "metrics"], [28, 30, "metrics"], [33, 35, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 16, 19, 21, "related-to", "equal", false, false], [28, 30, 33, 35, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "equivalent", "expression", "in", "the", "case", "of", "a", "binary", "target", "rate", "is", "that", "the", "true", "positive", "rate", "and", "the", "false", "positive", "rate", "are", "equal", "(", "and", "therefore", "the", "false", "negative", "rate", "and", "the", "true", "negative", "rate", "are", "equal", ")", "for", "each", "value", "of", "the", "sensitive", "properties", ":"], "sentence-detokenized": "Another equivalent expression in the case of a binary target rate is that the true positive rate and the false positive rate are equal (and therefore the false negative rate and the true negative rate are equal) for each value of the sensitive properties:", "token2charspan": [[0, 7], [8, 18], [19, 29], [30, 32], [33, 36], [37, 41], [42, 44], [45, 46], [47, 53], [54, 60], [61, 65], [66, 68], [69, 73], [74, 77], [78, 82], [83, 91], [92, 96], [97, 100], [101, 104], [105, 110], [111, 119], [120, 124], [125, 128], [129, 134], [135, 136], [136, 139], [140, 149], [150, 153], [154, 159], [160, 168], [169, 173], [174, 177], [178, 181], [182, 186], [187, 195], [196, 200], [201, 204], [205, 210], [210, 211], [212, 215], [216, 220], [221, 226], [227, 229], [230, 233], [234, 243], [244, 254], [254, 255]]}
{"doc_key": "ai-test-110", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["MATLAB", "function", ","], "sentence-detokenized": "MATLAB function,", "token2charspan": [[0, 6], [7, 15], [15, 16]]}
{"doc_key": "ai-test-111", "ner": [[1, 2, "product"], [7, 7, "misc"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 1, 2, "part-of", "", false, false], [16, 17, 1, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "articulated", "robot", "is", "a", "robot", "with", "rotating", "joints", "(", "e.g.", "a", "legged", "robot", "or", "an", "industrial", "robot", ")", "."], "sentence-detokenized": "An articulated robot is a robot with rotating joints (e.g. a legged robot or an industrial robot).", "token2charspan": [[0, 2], [3, 14], [15, 20], [21, 23], [24, 25], [26, 31], [32, 36], [37, 45], [46, 52], [53, 54], [54, 58], [59, 60], [61, 67], [68, 73], [74, 76], [77, 79], [80, 90], [91, 96], [96, 97], [97, 98]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [5, 6, "product"], [8, 9, "product"], [13, 13, "misc"], [17, 19, "product"], [26, 29, "misc"], [32, 32, "location"], [34, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 13, 13, "general-affiliation", "nationality", false, false], [0, 0, 26, 29, "usage", "", false, false], [0, 0, 32, 32, "physical", "", false, false], [5, 6, 0, 0, "named", "", false, false], [8, 9, 0, 0, "named", "", false, false], [32, 32, 34, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "also", "known", "as", "Pandora", "Media", "or", "Pandora", "Radio", ")", "is", "an", "American", "music", "streaming", "and", "automated", "recommender", "system", "internet", "radio", "service", "operated", "by", "the", "Music", "Genome", "Project", "and", "headquartered", "in", "Oakland", ",", "California", "."], "sentence-detokenized": "Pandora (also known as Pandora Media or Pandora Radio) is an American music streaming and automated recommender system internet radio service operated by the Music Genome Project and headquartered in Oakland, California.", "token2charspan": [[0, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 30], [31, 36], [37, 39], [40, 47], [48, 53], [53, 54], [55, 57], [58, 60], [61, 69], [70, 75], [76, 85], [86, 89], [90, 99], [100, 111], [112, 118], [119, 127], [128, 133], [134, 141], [142, 150], [151, 153], [154, 157], [158, 163], [164, 170], [171, 178], [179, 182], [183, 196], [197, 199], [200, 207], [207, 208], [209, 219], [219, 220]]}
{"doc_key": "ai-test-113", "ner": [[7, 10, "organisation"], [16, 18, "organisation"], [24, 25, "conference"], [39, 39, "conference"], [41, 41, "conference"], [43, 43, "conference"], [45, 45, "conference"], [47, 47, "conference"], [49, 49, "conference"], [51, 51, "conference"], [53, 53, "conference"], [55, 55, "conference"], [58, 58, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "board", "member", "of", "the", "International", "Machine", "Learning", "Society", ",", "has", "served", "on", "the", "AAAI", "Executive", "Council", ",", "was", "PC", "co-chair", "at", "ICML", "2011", ",", "and", "has", "served", "as", "a", "senior", "PC", "member", "at", "conferences", "such", "as", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "UAI", ",", "VLDB", ",", "WSDM", ",", "and", "WWW", "."], "sentence-detokenized": "She is a board member of the International Machine Learning Society, has served on the AAAI Executive Council, was PC co-chair at ICML 2011, and has served as a senior PC member at conferences such as AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM, and WWW.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 14], [15, 21], [22, 24], [25, 28], [29, 42], [43, 50], [51, 59], [60, 67], [67, 68], [69, 72], [73, 79], [80, 82], [83, 86], [87, 91], [92, 101], [102, 109], [109, 110], [111, 114], [115, 117], [118, 126], [127, 129], [130, 134], [135, 139], [139, 140], [141, 144], [145, 148], [149, 155], [156, 158], [159, 160], [161, 167], [168, 170], [171, 177], [178, 180], [181, 192], [193, 197], [198, 200], [201, 205], [205, 206], [207, 211], [211, 212], [213, 218], [218, 219], [220, 224], [224, 225], [226, 229], [229, 230], [231, 237], [237, 238], [239, 242], [242, 243], [244, 248], [248, 249], [250, 254], [254, 255], [256, 259], [260, 263], [263, 264]]}
{"doc_key": "ai-test-114", "ner": [[0, 2, "researcher"], [5, 10, "organisation"], [12, 14, "organisation"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 10, "role", "", false, false], [12, 14, 5, 10, "named", "", false, false], [16, 16, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", "of", "the", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", "has", "developed", "Robocrane", ",", "in", "which", "the", "platform", "hangs", "from", "six", "cables", "instead", "of", "being", "supported", "by", "six", "jacks", "."], "sentence-detokenized": "James S. Albus of the National Institute of Standards and Technology (NIST) has developed Robocrane, in which the platform hangs from six cables instead of being supported by six jacks.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 17], [18, 21], [22, 30], [31, 40], [41, 43], [44, 53], [54, 57], [58, 68], [69, 70], [70, 74], [74, 75], [76, 79], [80, 89], [90, 99], [99, 100], [101, 103], [104, 109], [110, 113], [114, 122], [123, 128], [129, 133], [134, 137], [138, 144], [145, 152], [153, 155], [156, 161], [162, 171], [172, 174], [175, 178], [179, 184], [184, 185]]}
{"doc_key": "ai-test-115", "ner": [[3, 8, "algorithm"], [10, 11, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 3, 8, "type-of", "", false, false], [14, 15, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "class", "of", "algorithms", "for", "direct", "search", "are", "the", "various", "evolutionary", "algorithms", ",", "e.g.", "genetic", "algorithms", "."], "sentence-detokenized": "Another class of algorithms for direct search are the various evolutionary algorithms, e.g. genetic algorithms.", "token2charspan": [[0, 7], [8, 13], [14, 16], [17, 27], [28, 31], [32, 38], [39, 45], [46, 49], [50, 53], [54, 61], [62, 74], [75, 85], [85, 86], [87, 91], [92, 99], [100, 110], [110, 111]]}
{"doc_key": "ai-test-116", "ner": [[0, 1, "organisation"], [3, 4, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["KUKA", "is", "a", "German", "manufacturer", "of", "industrial", "robots", "and", "factory", "automation", "solutions", "."], "sentence-detokenized": "KUKA is a German manufacturer of industrial robots and factory automation solutions.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 16], [17, 29], [30, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 73], [74, 83], [83, 84]]}
{"doc_key": "ai-test-117", "ner": [[13, 13, "person"], [16, 22, "misc"], [24, 24, "person"], [27, 27, "misc"], [29, 31, "person"], [32, 33, "misc"], [35, 36, "person"], [38, 40, "misc"], [42, 43, "person"], [46, 49, "misc"], [51, 51, "person"], [54, 57, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[16, 22, 13, 13, "artifact", "", false, false], [27, 27, 24, 24, "artifact", "", false, false], [32, 33, 29, 31, "artifact", "", false, false], [38, 40, 35, 36, "artifact", "", false, false], [46, 49, 42, 43, "artifact", "", false, false], [54, 57, 51, 51, "artifact", "", false, false]], "relations_mapping_to_source": [1, 3, 5, 7, 9, 11], "sentence": ["Other", "films", "between", "2016", "and", "2020", "that", "were", "shot", "with", "IMAX", "cameras", "included", "Zack", "Snyder", "'s", "Batman", "v", "Superman", ":", "Dawn", "of", "Justice", ",", "Clint", "Eastwood", "'s", "Sully", ",", "Damien", "Chazelle", "'s", "First", "Man", ",", "Patty", "Jenkins", "'", "Wonder", "Woman", "1984", ",", "Cary", "Joji", "Fukunaga", "'s", "No", "Time", "to", "Die", "and", "Joseph", "Kosinski", "'s", "Top", "Gun", ":", "Maverick", "."], "sentence-detokenized": "Other films between 2016 and 2020 that were shot with IMAX cameras included Zack Snyder's Batman v Superman: Dawn of Justice, Clint Eastwood's Sully, Damien Chazelle's First Man, Patty Jenkins' Wonder Woman 1984, Cary Joji Fukunaga's No Time to Die and Joseph Kosinski's Top Gun: Maverick.", "token2charspan": [[0, 5], [6, 11], [12, 19], [20, 24], [25, 28], [29, 33], [34, 38], [39, 43], [44, 48], [49, 53], [54, 58], [59, 66], [67, 75], [76, 80], [81, 87], [87, 89], [90, 96], [97, 98], [99, 107], [107, 108], [109, 113], [114, 116], [117, 124], [124, 125], [126, 131], [132, 140], [140, 142], [143, 148], [148, 149], [150, 156], [157, 165], [165, 167], [168, 173], [174, 177], [177, 178], [179, 184], [185, 192], [192, 193], [194, 200], [201, 206], [207, 211], [211, 212], [213, 217], [218, 222], [223, 231], [231, 233], [234, 236], [237, 241], [242, 244], [245, 248], [249, 252], [253, 259], [260, 268], [268, 270], [271, 274], [275, 278], [278, 279], [280, 288], [288, 289]]}
{"doc_key": "ai-test-118", "ner": [[0, 1, "misc"], [9, 11, "organisation"], [13, 13, "organisation"], [33, 34, "country"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[9, 11, 0, 1, "usage", "", false, false], [9, 11, 33, 34, "physical", "", false, false], [13, 13, 9, 11, "named", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["The", "MICR", "E13B", "typeface", "trial", "was", "shown", "to", "the", "American", "Bankers", "Association", "(", "ABA", ")", "in", "July", "1956", ",", "which", "adopted", "it", "in", "1958", "as", "the", "MICR", "standard", "for", "negotiable", "documents", "in", "the", "United", "States", "."], "sentence-detokenized": "The MICR E13B typeface trial was shown to the American Bankers Association (ABA) in July 1956, which adopted it in 1958 as the MICR standard for negotiable documents in the United States.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 22], [23, 28], [29, 32], [33, 38], [39, 41], [42, 45], [46, 54], [55, 62], [63, 74], [75, 76], [76, 79], [79, 80], [81, 83], [84, 88], [89, 93], [93, 94], [95, 100], [101, 108], [109, 111], [112, 114], [115, 119], [120, 122], [123, 126], [127, 131], [132, 140], [141, 144], [145, 155], [156, 165], [166, 168], [169, 172], [173, 179], [180, 186], [186, 187]]}
{"doc_key": "ai-test-119", "ner": [[0, 2, "misc"], [15, 16, "field"], [19, 20, "field"], [23, 23, "field"], [25, 26, "field"], [28, 28, "field"], [30, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 16, 0, 2, "usage", "", false, false], [19, 20, 15, 16, "part-of", "", false, false], [23, 23, 0, 2, "usage", "", false, false], [25, 26, 0, 2, "usage", "", false, false], [28, 28, 0, 2, "usage", "", false, false], [30, 30, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Local", "search", "algorithms", "are", "widely", "used", "for", "many", "hard", "computational", "problems", ",", "including", "problems", "in", "computer", "science", "(", "especially", "artificial", "intelligence", ")", ",", "mathematics", ",", "operations", "research", ",", "engineering", "and", "bioinformatics", "."], "sentence-detokenized": "Local search algorithms are widely used for many hard computational problems, including problems in computer science (especially artificial intelligence), mathematics, operations research, engineering and bioinformatics.", "token2charspan": [[0, 5], [6, 12], [13, 23], [24, 27], [28, 34], [35, 39], [40, 43], [44, 48], [49, 53], [54, 67], [68, 76], [76, 77], [78, 87], [88, 96], [97, 99], [100, 108], [109, 116], [117, 118], [118, 128], [129, 139], [140, 152], [152, 153], [153, 154], [155, 166], [166, 167], [168, 178], [179, 187], [187, 188], [189, 200], [201, 204], [205, 219], [219, 220]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [8, 8, "location"], [10, 12, "country"], [14, 14, "country"], [22, 23, "algorithm"], [25, 25, "algorithm"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 8, 8, "physical", "", false, false], [0, 1, 14, 14, "general-affiliation", "nationality", false, false], [0, 1, 22, 23, "general-affiliation", "topic_of_study", false, false], [0, 1, 25, 25, "general-affiliation", "topic_of_study", false, false], [8, 8, 10, 12, "physical", "", false, false], [25, 25, 27, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "born", "3", "September", "1947", "in", "Wallersdorf", ",", "Germany", ")", "is", "a", "German", "psychologist", "who", "has", "studied", "the", "use", "of", "bounded", "rationality", "and", "heuristics", "in", "decision", "-", "making", "."], "sentence-detokenized": "Gerd Gigerenzer (born 3 September 1947 in Wallersdorf, Germany) is a German psychologist who has studied the use of bounded rationality and heuristics in decision-making.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 21], [22, 23], [24, 33], [34, 38], [39, 41], [42, 53], [53, 54], [55, 62], [62, 63], [64, 66], [67, 68], [69, 75], [76, 88], [89, 92], [93, 96], [97, 104], [105, 108], [109, 112], [113, 115], [116, 123], [124, 135], [136, 139], [140, 150], [151, 153], [154, 162], [162, 163], [163, 169], [169, 170]]}
{"doc_key": "ai-test-121", "ner": [[3, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["to", "minimize", "the", "mean", "squared", "error", "."], "sentence-detokenized": "to minimize the mean squared error.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 20], [21, 28], [29, 34], [34, 35]]}
{"doc_key": "ai-test-122", "ner": [[13, 14, "misc"], [17, 18, "organisation"], [29, 31, "field"], [50, 51, "misc"], [60, 62, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 14, 17, 18, "origin", "", false, false], [50, 51, 60, 62, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "even", "an", "official", "language", "with", "a", "regulating", "academy", ",", "such", "as", "Standard", "French", "with", "the", "Acad\u00e9mie", "fran\u00e7aise", ",", "is", "classified", "as", "a", "natural", "language", "(", "e.g.", "in", "natural", "language", "processing", ")", ",", "since", "its", "normative", "points", "do", "not", "make", "it", "either", "constructed", "enough", "to", "be", "classified", "as", "a", "constructed", "language", "or", "controlled", "enough", "to", "be", "classified", "as", "a", "controlled", "natural", "language", "."], "sentence-detokenized": "However, even an official language with a regulating academy, such as Standard French with the Acad\u00e9mie fran\u00e7aise, is classified as a natural language (e.g. in natural language processing), since its normative points do not make it either constructed enough to be classified as a constructed language or controlled enough to be classified as a controlled natural language.", "token2charspan": [[0, 7], [7, 8], [9, 13], [14, 16], [17, 25], [26, 34], [35, 39], [40, 41], [42, 52], [53, 60], [60, 61], [62, 66], [67, 69], [70, 78], [79, 85], [86, 90], [91, 94], [95, 103], [104, 113], [113, 114], [115, 117], [118, 128], [129, 131], [132, 133], [134, 141], [142, 150], [151, 152], [152, 156], [157, 159], [160, 167], [168, 176], [177, 187], [187, 188], [188, 189], [190, 195], [196, 199], [200, 209], [210, 216], [217, 219], [220, 223], [224, 228], [229, 231], [232, 238], [239, 250], [251, 257], [258, 260], [261, 263], [264, 274], [275, 277], [278, 279], [280, 291], [292, 300], [301, 303], [304, 314], [315, 321], [322, 324], [325, 327], [328, 338], [339, 341], [342, 343], [344, 354], [355, 362], [363, 371], [371, 372]]}
{"doc_key": "ai-test-123", "ner": [[13, 13, "metrics"], [15, 16, "metrics"], [18, 21, "metrics"], [36, 37, "metrics"], [39, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[18, 21, 15, 16, "named", "", false, false], [39, 39, 36, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "a", "number", "of", "other", "measures", ",", "the", "simplest", "of", "which", "is", "accuracy", "or", "Fraction", "Correct", "(", "FC", ")", ",", "which", "measures", "the", "proportion", "of", "all", "cases", "that", "are", "correctly", "categorised", ";", "the", "complement", "is", "Fraction", "Incorrect", "(", "FiC", ")", "."], "sentence-detokenized": "There are a number of other measures, the simplest of which is accuracy or Fraction Correct (FC), which measures the proportion of all cases that are correctly categorised; the complement is Fraction Incorrect (FiC).", "token2charspan": [[0, 5], [6, 9], [10, 11], [12, 18], [19, 21], [22, 27], [28, 36], [36, 37], [38, 41], [42, 50], [51, 53], [54, 59], [60, 62], [63, 71], [72, 74], [75, 83], [84, 91], [92, 93], [93, 95], [95, 96], [96, 97], [98, 103], [104, 112], [113, 116], [117, 127], [128, 130], [131, 134], [135, 140], [141, 145], [146, 149], [150, 159], [160, 171], [171, 172], [173, 176], [177, 187], [188, 190], [191, 199], [200, 209], [210, 211], [211, 214], [214, 215], [215, 216]]}
{"doc_key": "ai-test-124", "ner": [[0, 0, "researcher"], [6, 9, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 9, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cardie", "became", "a", "Fellow", "of", "the", "Association", "for", "Computational", "Linguistics", "in", "2016", "."], "sentence-detokenized": "Cardie became a Fellow of the Association for Computational Linguistics in 2016.", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 22], [23, 25], [26, 29], [30, 41], [42, 45], [46, 59], [60, 71], [72, 74], [75, 79], [79, 80]]}
{"doc_key": "ai-test-125", "ner": [[13, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Learning", "of", "the", "parameters", "math", "\\", "theta", "/", "math", "is", "usually", "done", "by", "maximum", "likelihood", "learning", "for", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i", ";\\", "theta", ")", "/", "math", "."], "sentence-detokenized": "Learning of the parameters math\\ theta / math is usually done by maximum likelihood learning for mathp (Y _ i | X _ i;\\ theta) / math.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 26], [27, 31], [31, 32], [33, 38], [39, 40], [41, 45], [46, 48], [49, 56], [57, 61], [62, 64], [65, 72], [73, 83], [84, 92], [93, 96], [97, 102], [103, 104], [104, 105], [106, 107], [108, 109], [110, 111], [112, 113], [114, 115], [116, 117], [117, 119], [120, 125], [125, 126], [127, 128], [129, 133], [133, 134]]}
{"doc_key": "ai-test-126", "ner": [[0, 1, "task"], [3, 5, "algorithm"], [7, 8, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 0, 1, "usage", "", true, false], [7, 8, 3, 5, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cluster", "analysis", "and", "non-negative", "matrix", "factorization", "for", "descriptive", "mining", "."], "sentence-detokenized": "Cluster analysis and non-negative matrix factorization for descriptive mining.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 33], [34, 40], [41, 54], [55, 58], [59, 70], [71, 77], [77, 78]]}
{"doc_key": "ai-test-127", "ner": [[1, 2, "field"], [5, 6, "field"], [16, 18, "field"], [20, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 18, 1, 2, "part-of", "", false, false], [16, 18, 5, 6, "part-of", "", false, false], [20, 23, 1, 2, "part-of", "", false, false], [20, 23, 5, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", "and", "the", "information", "technology", "it", "enables", ",", "the", "ability", "of", "computers", "to", "perform", "natural", "language", "processing", "and", "machine", "learning", "has", "been", "a", "long", "-", "standing", "challenge", "."], "sentence-detokenized": "In computer science and the information technology it enables, the ability of computers to perform natural language processing and machine learning has been a long-standing challenge.", "token2charspan": [[0, 2], [3, 11], [12, 19], [20, 23], [24, 27], [28, 39], [40, 50], [51, 53], [54, 61], [61, 62], [63, 66], [67, 74], [75, 77], [78, 87], [88, 90], [91, 98], [99, 106], [107, 115], [116, 126], [127, 130], [131, 138], [139, 147], [148, 151], [152, 156], [157, 158], [159, 163], [163, 164], [164, 172], [173, 182], [182, 183]]}
{"doc_key": "ai-test-128", "ner": [[4, 6, "algorithm"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 10, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "The", "code", "for", "Gabor", "feature", "extraction", "from", "images", "in", "MATLAB", "can", "be", "found", "at"], "sentence-detokenized": "(The code for Gabor feature extraction from images in MATLAB can be found at", "token2charspan": [[0, 1], [1, 4], [5, 9], [10, 13], [14, 19], [20, 27], [28, 38], [39, 43], [44, 50], [51, 53], [54, 60], [61, 64], [65, 67], [68, 73], [74, 76]]}
{"doc_key": "ai-test-129", "ner": [[0, 0, "misc"], [14, 15, "algorithm"], [19, 19, "task"], [21, 21, "task"], [23, 24, "task"], [26, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 14, 15, "general-affiliation", "", false, false], [0, 0, 19, 19, "related-to", "solves_problem_of_type", false, false], [0, 0, 21, 21, "related-to", "solves_problem_of_type", false, false], [0, 0, 23, 24, "related-to", "solves_problem_of_type", false, false], [0, 0, 26, 27, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["NeuralExpert", "centres", "the", "design", "specifications", "around", "the", "type", "of", "problem", "the", "user", "wants", "the", "neural", "network", "to", "solve", "(", "classification", ",", "prediction", ",", "function", "approximation", "or", "cluster", "analysis", ")", "."], "sentence-detokenized": "NeuralExpert centres the design specifications around the type of problem the user wants the neural network to solve (classification, prediction, function approximation or cluster analysis).", "token2charspan": [[0, 12], [13, 20], [21, 24], [25, 31], [32, 46], [47, 53], [54, 57], [58, 62], [63, 65], [66, 73], [74, 77], [78, 82], [83, 88], [89, 92], [93, 99], [100, 107], [108, 110], [111, 116], [117, 118], [118, 132], [132, 133], [134, 144], [144, 145], [146, 154], [155, 168], [169, 171], [172, 179], [180, 188], [188, 189], [189, 190]]}
{"doc_key": "ai-test-130", "ner": [[1, 3, "misc"], [27, 29, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "quantization", "magnitude", "(", "\u0394", ")", "is", "small", "compared", "to", "the", "variation", "of", "the", "signal", "being", "quantized", ",", "it", "is", "relatively", "straightforward", "to", "show", "that", "the", "mean", "square", "error", "arising", "from", "such", "a", "rounding", "operation", "will", "be", "approximately", "math", "\\", "Delta", "^", "2", "/", "12", "/", "math.math"], "sentence-detokenized": "When the quantization magnitude (\u0394) is small compared to the variation of the signal being quantized, it is relatively straightforward to show that the mean square error arising from such a rounding operation will be approximately math\\ Delta ^ 2 / 12 / math.math", "token2charspan": [[0, 4], [5, 8], [9, 21], [22, 31], [32, 33], [33, 34], [34, 35], [36, 38], [39, 44], [45, 53], [54, 56], [57, 60], [61, 70], [71, 73], [74, 77], [78, 84], [85, 90], [91, 100], [100, 101], [102, 104], [105, 107], [108, 118], [119, 134], [135, 137], [138, 142], [143, 147], [148, 151], [152, 156], [157, 163], [164, 169], [170, 177], [178, 182], [183, 187], [188, 189], [190, 198], [199, 208], [209, 213], [214, 216], [217, 230], [231, 235], [235, 236], [237, 242], [243, 244], [245, 246], [247, 248], [249, 251], [252, 253], [254, 263]]}
{"doc_key": "ai-test-131", "ner": [[24, 27, "researcher"], [29, 30, "researcher"], [32, 35, "researcher"], [37, 38, "researcher"], [40, 42, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "construction", "of", "a", "comprehensive", "encyclopaedia", "with", "an", "appropriate", "ontology", "requires", "considerable", "effort", ",", "e.g.", "the", "Wordnet", "encyclopaedia", "required", "many", "man", "-", "years", ".", "G.", "A", ".", "Miller", ",", "R.", "Beckwith", ",", "C", ".", "D.", "Fellbaum", ",", "D.", "Gross", ",", "K", ".", "Miller", "."], "sentence-detokenized": "The construction of a comprehensive encyclopaedia with an appropriate ontology requires considerable effort, e.g. the Wordnet encyclopaedia required many man-years. G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 3], [4, 16], [17, 19], [20, 21], [22, 35], [36, 49], [50, 54], [55, 57], [58, 69], [70, 78], [79, 87], [88, 100], [101, 107], [107, 108], [109, 113], [114, 117], [118, 125], [126, 139], [140, 148], [149, 153], [154, 157], [157, 158], [158, 163], [163, 164], [165, 167], [168, 169], [169, 170], [171, 177], [177, 178], [179, 181], [182, 190], [190, 191], [192, 193], [193, 194], [195, 197], [198, 206], [206, 207], [208, 210], [211, 216], [216, 217], [218, 219], [219, 220], [221, 227], [227, 228]]}
{"doc_key": "ai-test-132", "ner": [[0, 1, "organisation"], [20, 21, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 21, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Kawasaki", "'s", "portfolio", "also", "includes", "retractable", "roofs", ",", "floors", "and", "other", "giant", "structures", ",", "such", "as", "the", "retractable", "surface", "of", "Sapporo", "Dome", "."], "sentence-detokenized": "Kawasaki's portfolio also includes retractable roofs, floors and other giant structures, such as the retractable surface of Sapporo Dome.", "token2charspan": [[0, 8], [8, 10], [11, 20], [21, 25], [26, 34], [35, 46], [47, 52], [52, 53], [54, 60], [61, 64], [65, 70], [71, 76], [77, 87], [87, 88], [89, 93], [94, 96], [97, 100], [101, 112], [113, 120], [121, 123], [124, 131], [132, 136], [136, 137]]}
{"doc_key": "ai-test-133", "ner": [[0, 1, "metrics"], [4, 6, "metrics"], [8, 10, "metrics"], [15, 16, "metrics"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 15, 16, "related-to", "", false, false], [0, 1, 37, 37, "opposite", "alternative_to", false, false], [4, 6, 0, 1, "type-of", "", false, false], [8, 10, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kappa", "statistics", "such", "as", "Fleiss", "'", "kappa", "and", "Cohen", "'s", "kappa", "are", "methods", "for", "calculating", "inter-rater", "reliability", "based", "on", "different", "assumptions", "about", "marginal", "or", "priority", "distributions", ",", "and", "they", "are", "increasingly", "used", "as", "randomly", "corrected", "alternatives", "to", "accuracy", "in", "other", "contexts", "."], "sentence-detokenized": "Kappa statistics such as Fleiss' kappa and Cohen's kappa are methods for calculating inter-rater reliability based on different assumptions about marginal or priority distributions, and they are increasingly used as randomly corrected alternatives to accuracy in other contexts.", "token2charspan": [[0, 5], [6, 16], [17, 21], [22, 24], [25, 31], [31, 32], [33, 38], [39, 42], [43, 48], [48, 50], [51, 56], [57, 60], [61, 68], [69, 72], [73, 84], [85, 96], [97, 108], [109, 114], [115, 117], [118, 127], [128, 139], [140, 145], [146, 154], [155, 157], [158, 166], [167, 180], [180, 181], [182, 185], [186, 190], [191, 194], [195, 207], [208, 212], [213, 215], [216, 224], [225, 234], [235, 247], [248, 250], [251, 259], [260, 262], [263, 268], [269, 277], [277, 278]]}
{"doc_key": "ai-test-134", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [18, 18, "researcher"], [27, 29, "algorithm"], [31, 34, "algorithm"], [36, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 18, 18, "role", "student_of", false, false], [7, 8, 18, 18, "role", "student_of", false, false], [10, 11, 18, 18, "role", "student_of", false, false], [13, 14, 18, 18, "role", "student_of", false, false], [31, 34, 4, 5, "origin", "", false, false], [31, 34, 7, 8, "origin", "", false, false], [31, 34, 10, 11, "origin", "", false, false], [31, 34, 13, 14, "origin", "", false, false], [31, 34, 18, 18, "origin", "", false, false], [31, 34, 27, 29, "type-of", "", false, false], [36, 36, 31, 34, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Together", "with", "his", "students", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Graves", "and", "others", ",", "Schmidhuber", "published", "increasingly", "sophisticated", "versions", "of", "a", "type", "of", "recurrent", "neural", "network", "called", "Long", "Short", "Term", "Memory", "(", "LSTM", ")", "."], "sentence-detokenized": "Together with his students Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Graves and others, Schmidhuber published increasingly sophisticated versions of a type of recurrent neural network called Long Short Term Memory (LSTM).", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 26], [27, 31], [32, 42], [42, 43], [44, 49], [50, 54], [54, 55], [56, 60], [61, 68], [68, 69], [70, 74], [75, 81], [82, 85], [86, 92], [92, 93], [94, 105], [106, 115], [116, 128], [129, 142], [143, 151], [152, 154], [155, 156], [157, 161], [162, 164], [165, 174], [175, 181], [182, 189], [190, 196], [197, 201], [202, 207], [208, 212], [213, 219], [220, 221], [221, 225], [225, 226], [226, 227]]}
{"doc_key": "ai-test-135", "ner": [[4, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "The", "first", "Cobot", "KUKA", "LBR", "3", "is", "released", "."], "sentence-detokenized": "2004 - The first Cobot KUKA LBR 3 is released.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 16], [17, 22], [23, 27], [28, 31], [32, 33], [34, 36], [37, 45], [45, 46]]}
{"doc_key": "ai-test-136", "ner": [[10, 12, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Two", "superficial", "methods", "used", "for", "training", "and", "then", "clarification", "are", "Naive", "Bayes", "classifier", "and", "decision", "trees", "."], "sentence-detokenized": "Two superficial methods used for training and then clarification are Naive Bayes classifier and decision trees.", "token2charspan": [[0, 3], [4, 15], [16, 23], [24, 28], [29, 32], [33, 41], [42, 45], [46, 50], [51, 64], [65, 68], [69, 74], [75, 80], [81, 91], [92, 95], [96, 104], [105, 110], [110, 111]]}
{"doc_key": "ai-test-137", "ner": [[5, 5, "misc"], [12, 13, "person"], [15, 17, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 12, 13, "origin", "", false, false], [5, 5, 15, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "practical", "forms", "of", "photography", "were", "introduced", "in", "January", "1839", "by", "Louis", "Daguerre", "and", "Henry", "Fox", "Talbot", "."], "sentence-detokenized": "The first practical forms of photography were introduced in January 1839 by Louis Daguerre and Henry Fox Talbot.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 25], [26, 28], [29, 40], [41, 45], [46, 56], [57, 59], [60, 67], [68, 72], [73, 75], [76, 81], [82, 90], [91, 94], [95, 100], [101, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-138", "ner": [[3, 4, "task"], [7, 8, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "speech", "synthesis", "combined", "with", "speech", "recognition", "allows", "interaction", "with", "mobile", "devices", "via", "language", "processing", "interfaces", "."], "sentence-detokenized": "For example, speech synthesis combined with speech recognition allows interaction with mobile devices via language processing interfaces.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 19], [20, 29], [30, 38], [39, 43], [44, 50], [51, 62], [63, 69], [70, 81], [82, 86], [87, 93], [94, 101], [102, 105], [106, 114], [115, 125], [126, 136], [136, 137]]}
{"doc_key": "ai-test-139", "ner": [[0, 0, "product"], [15, 15, "programlang"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 15, 15, "general-affiliation", "", false, false], [0, 0, 17, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Phidgets", "can", "be", "programmed", "using", "a", "variety", "of", "software", "and", "programming", "languages", ",", "ranging", "from", "Java", "to", "Microsoft", "Excel", "."], "sentence-detokenized": "Phidgets can be programmed using a variety of software and programming languages, ranging from Java to Microsoft Excel.", "token2charspan": [[0, 8], [9, 12], [13, 15], [16, 26], [27, 32], [33, 34], [35, 42], [43, 45], [46, 54], [55, 58], [59, 70], [71, 80], [80, 81], [82, 89], [90, 94], [95, 99], [100, 102], [103, 112], [113, 118], [118, 119]]}
{"doc_key": "ai-test-140", "ner": [[2, 4, "field"], [9, 10, "researcher"], [13, 15, "misc"], [19, 20, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 9, 10, "origin", "", false, false], [9, 10, 19, 20, "general-affiliation", "topic_of_study", false, false], [9, 10, 22, 23, "general-affiliation", "topic_of_study", false, false], [13, 15, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "machine", "learning", "was", "coined", "in", "1959", "by", "Arthur", "Samuel", ",", "an", "American", "IBM", "employee", "and", "pioneer", "in", "computer", "games", "and", "artificial", "intelligence", "."], "sentence-detokenized": "The term machine learning was coined in 1959 by Arthur Samuel, an American IBM employee and pioneer in computer games and artificial intelligence.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 25], [26, 29], [30, 36], [37, 39], [40, 44], [45, 47], [48, 54], [55, 61], [61, 62], [63, 65], [66, 74], [75, 78], [79, 87], [88, 91], [92, 99], [100, 102], [103, 111], [112, 117], [118, 121], [122, 132], [133, 145], [145, 146]]}
{"doc_key": "ai-test-141", "ner": [[13, 14, "misc"], [15, 16, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 16, 13, 14, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Fascinated", "by", "the", "technologies", "of", "the", "future", "and", "their", "relationship", "to", "art", ",", "Israeli", "poet", "David", "Avidan", "wanted", "to", "explore", "the", "use", "of", "computers", "to", "write", "literature", "."], "sentence-detokenized": "Fascinated by the technologies of the future and their relationship to art, Israeli poet David Avidan wanted to explore the use of computers to write literature.", "token2charspan": [[0, 10], [11, 13], [14, 17], [18, 30], [31, 33], [34, 37], [38, 44], [45, 48], [49, 54], [55, 67], [68, 70], [71, 74], [74, 75], [76, 83], [84, 88], [89, 94], [95, 101], [102, 108], [109, 111], [112, 119], [120, 123], [124, 127], [128, 130], [131, 140], [141, 143], [144, 149], [150, 160], [160, 161]]}
{"doc_key": "ai-test-142", "ner": [[4, 5, "misc"], [9, 9, "organisation"], [16, 16, "location"], [30, 30, "location"], [27, 28, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 4, 5, "part-of", "", false, false], [27, 28, 30, 30, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "part", "of", "the", "GATEway", "project", "in", "2017", ",", "Oxbotica", "trialled", "seven", "autonomous", "shuttle", "buses", "in", "Greenwich", ",", "navigating", "a", "two", "-", "mile", "riverside", "path", "near", "the", "O2", "Arena", "in", "London", "on", "a", "route", "also", "used", "by", "pedestrians", "and", "cyclists", "."], "sentence-detokenized": "As part of the GATEway project in 2017, Oxbotica trialled seven autonomous shuttle buses in Greenwich, navigating a two-mile riverside path near the O2 Arena in London on a route also used by pedestrians and cyclists.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 22], [23, 30], [31, 33], [34, 38], [38, 39], [40, 48], [49, 57], [58, 63], [64, 74], [75, 82], [83, 88], [89, 91], [92, 101], [101, 102], [103, 113], [114, 115], [116, 119], [119, 120], [120, 124], [125, 134], [135, 139], [140, 144], [145, 148], [149, 151], [152, 157], [158, 160], [161, 167], [168, 170], [171, 172], [173, 178], [179, 183], [184, 188], [189, 191], [192, 203], [204, 207], [208, 216], [216, 217]]}
{"doc_key": "ai-test-143", "ner": [[10, 11, "task"], [14, 18, "metrics"], [25, 26, "misc"], [28, 28, "metrics"], [30, 30, "metrics"], [33, 33, "metrics"], [35, 35, "metrics"], [37, 39, "metrics"], [42, 42, "metrics"], [44, 44, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[14, 18, 25, 26, "related-to", "is_a", false, false], [14, 18, 28, 28, "usage", "", false, false], [14, 18, 30, 30, "usage", "", false, false], [28, 28, 33, 33, "named", "same", false, false], [30, 30, 44, 44, "named", "same", false, false], [33, 33, 42, 42, "opposite", "", false, false], [33, 33, 44, 44, "opposite", "", false, false], [35, 35, 33, 33, "named", "", false, false], [37, 39, 33, 33, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["An", "unrelated", "but", "commonly", "used", "combination", "of", "basic", "statistics", "from", "information", "retrieval", "is", "the", "F", "-", "score", ",", "which", "is", "a", "(", "possibly", "weighted", ")", "harmonic", "average", "of", "recall", "and", "precision", ",", "where", "recall", "=", "sensitivity", "=", "SANDT", "positive", "rate", ",", "but", "specificity", "and", "precision", "are", "completely", "different", "measures", "."], "sentence-detokenized": "An unrelated but commonly used combination of basic statistics from information retrieval is the F-score, which is a (possibly weighted) harmonic average of recall and precision, where recall = sensitivity = SANDT positive rate, but specificity and precision are completely different measures.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 25], [26, 30], [31, 42], [43, 45], [46, 51], [52, 62], [63, 67], [68, 79], [80, 89], [90, 92], [93, 96], [97, 98], [98, 99], [99, 104], [104, 105], [106, 111], [112, 114], [115, 116], [117, 118], [118, 126], [127, 135], [135, 136], [137, 145], [146, 153], [154, 156], [157, 163], [164, 167], [168, 177], [177, 178], [179, 184], [185, 191], [192, 193], [194, 205], [206, 207], [208, 213], [214, 222], [223, 227], [227, 228], [229, 232], [233, 244], [245, 248], [249, 258], [259, 262], [263, 273], [274, 283], [284, 292], [292, 293]]}
{"doc_key": "ai-test-144", "ner": [[0, 1, "field"], [10, 10, "field"], [12, 12, "field"], [14, 14, "field"], [16, 17, "field"], [19, 19, "field"], [28, 29, "product"], [31, 34, "product"], [36, 37, "product"], [39, 40, "product"], [51, 53, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 10, "origin", "takes_inspiration_from", false, false], [0, 1, 12, 12, "origin", "takes_inspiration_from", false, false], [0, 1, 14, 14, "origin", "takes_inspiration_from", false, false], [0, 1, 16, 17, "origin", "takes_inspiration_from", false, false], [0, 1, 19, 19, "origin", "takes_inspiration_from", false, false], [28, 29, 0, 1, "origin", "", false, false], [31, 34, 0, 1, "origin", "", false, false], [36, 37, 0, 1, "origin", "", false, false], [39, 40, 0, 1, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Neuromorphic", "engineering", "is", "an", "interdisciplinary", "subject", "that", "draws", "inspiration", "from", "biology", ",", "physics", ",", "mathematics", ",", "computer", "science", "and", "electronics", "to", "design", "artificial", "neural", "systems", ",", "such", "as", "vision", "systems", ",", "head", "-", "eye", "systems", ",", "auditory", "processors", "and", "autonomous", "robots", ",", "whose", "physical", "architecture", "and", "design", "principles", "are", "based", "on", "biological", "nervous", "systems", "."], "sentence-detokenized": "Neuromorphic engineering is an interdisciplinary subject that draws inspiration from biology, physics, mathematics, computer science and electronics to design artificial neural systems, such as vision systems, head-eye systems, auditory processors and autonomous robots, whose physical architecture and design principles are based on biological nervous systems.", "token2charspan": [[0, 12], [13, 24], [25, 27], [28, 30], [31, 48], [49, 56], [57, 61], [62, 67], [68, 79], [80, 84], [85, 92], [92, 93], [94, 101], [101, 102], [103, 114], [114, 115], [116, 124], [125, 132], [133, 136], [137, 148], [149, 151], [152, 158], [159, 169], [170, 176], [177, 184], [184, 185], [186, 190], [191, 193], [194, 200], [201, 208], [208, 209], [210, 214], [214, 215], [215, 218], [219, 226], [226, 227], [228, 236], [237, 247], [248, 251], [252, 262], [263, 269], [269, 270], [271, 276], [277, 285], [286, 298], [299, 302], [303, 309], [310, 320], [321, 324], [325, 330], [331, 333], [334, 344], [345, 352], [353, 360], [360, 361]]}
{"doc_key": "ai-test-145", "ner": [[3, 8, "metrics"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 10, 3, 8, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["More", "specifically", ",", "the", "BIBO", "stability", "criterion", "requires", "that", "the", "ROC", "of", "the", "system", "encompasses", "the", "unit", "circle", "."], "sentence-detokenized": "More specifically, the BIBO stability criterion requires that the ROC of the system encompasses the unit circle.", "token2charspan": [[0, 4], [5, 17], [17, 18], [19, 22], [23, 27], [28, 37], [38, 47], [48, 56], [57, 61], [62, 65], [66, 69], [70, 72], [73, 76], [77, 83], [84, 95], [96, 99], [100, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-146", "ner": [[6, 7, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "The", "program", "was", "rewritten", "in", "Java", "in", "early", "1998", "."], "sentence-detokenized": "2 The program was rewritten in Java in early 1998.", "token2charspan": [[0, 1], [2, 5], [6, 13], [14, 17], [18, 27], [28, 30], [31, 35], [36, 38], [39, 44], [45, 49], [49, 50]]}
{"doc_key": "ai-test-147", "ner": [[0, 1, "metrics"], [8, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 8, 9, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "MCC", "can", "be", "calculated", "directly", "from", "the", "confusion", "matrix", "using", "the", "formula", ":"], "sentence-detokenized": "The MCC can be calculated directly from the confusion matrix using the formula:", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 25], [26, 34], [35, 39], [40, 43], [44, 53], [54, 60], [61, 66], [67, 70], [71, 78], [78, 79]]}
{"doc_key": "ai-test-148", "ner": [[8, 13, "organisation"], [20, 26, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 13, 20, 26, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "developed", "by", "a", "team", "from", "the", "MIT", "-", "IBM", "Watson", "AI", "Lab", "and", "was", "first", "presented", "at", "the", "International", "Conference", "on", "Learning", "Representations", "in", "2018", "."], "sentence-detokenized": "It was developed by a team from the MIT-IBM Watson AI Lab and was first presented at the International Conference on Learning Representations in 2018.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 31], [32, 35], [36, 39], [39, 40], [40, 43], [44, 50], [51, 53], [54, 57], [58, 61], [62, 65], [66, 71], [72, 81], [82, 84], [85, 88], [89, 102], [103, 113], [114, 116], [117, 125], [126, 141], [142, 144], [145, 149], [149, 150]]}
{"doc_key": "ai-test-149", "ner": [[2, 3, "metrics"], [14, 15, "metrics"], [17, 22, "metrics"], [47, 47, "metrics"], [55, 57, "metrics"], [60, 60, "metrics"], [62, 62, "metrics"], [64, 66, "metrics"], [71, 71, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6, 7, 8, 9], "relations": [[14, 15, 47, 47, "type-of", "", false, false], [14, 15, 55, 57, "related-to", "collapses_to_identity", false, false], [17, 22, 55, 57, "related-to", "collapses_to_identity", false, false], [17, 22, 64, 66, "named", "same", false, false], [60, 60, 71, 71, "related-to", "collapses_to_identity", false, false], [62, 62, 71, 71, "related-to", "collapses_to_identity", false, false], [64, 66, 71, 71, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [0, 1, 3, 4, 5, 6, 7], "sentence": ["When", "the", "true", "prevalences", "of", "the", "two", "positive", "variables", "are", "equal", "as", "assumed", "in", "Fleiss", "kappa", "and", "F", "-", "score", ",", "i.e.", "the", "number", "of", "positive", "predictions", "is", "equal", "to", "the", "number", "of", "positive", "classes", "in", "the", "dichotomous", "(", "two", "-", "class", ")", "case", ",", "the", "various", "kappa", "and", "correlation", "measures", "coincide", "to", "identity", "with", "Youden", "'s", "J", ",", "and", "recall", ",", "precision", "and", "F", "-", "score", "are", "also", "identical", "to", "accuracy", "."], "sentence-detokenized": "When the true prevalences of the two positive variables are equal as assumed in Fleiss kappa and F-score, i.e. the number of positive predictions is equal to the number of positive classes in the dichotomous (two-class) case, the various kappa and correlation measures coincide to identity with Youden's J, and recall, precision and F-score are also identical to accuracy.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 25], [26, 28], [29, 32], [33, 36], [37, 45], [46, 55], [56, 59], [60, 65], [66, 68], [69, 76], [77, 79], [80, 86], [87, 92], [93, 96], [97, 98], [98, 99], [99, 104], [104, 105], [106, 110], [111, 114], [115, 121], [122, 124], [125, 133], [134, 145], [146, 148], [149, 154], [155, 157], [158, 161], [162, 168], [169, 171], [172, 180], [181, 188], [189, 191], [192, 195], [196, 207], [208, 209], [209, 212], [212, 213], [213, 218], [218, 219], [220, 224], [224, 225], [226, 229], [230, 237], [238, 243], [244, 247], [248, 259], [260, 268], [269, 277], [278, 280], [281, 289], [290, 294], [295, 301], [301, 303], [304, 305], [305, 306], [307, 310], [311, 317], [317, 318], [319, 328], [329, 332], [333, 334], [334, 335], [335, 340], [341, 344], [345, 349], [350, 359], [360, 362], [363, 371], [371, 372]]}
{"doc_key": "ai-test-150", "ner": [[0, 7, "misc"], [5, 5, "misc"], [9, 9, "conference"], [14, 17, "task"], [18, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 7, 9, 9, "part-of", "", false, false], [0, 7, 9, 9, "physical", "", false, false], [0, 7, 9, 9, "temporal", "", false, false], [5, 5, 0, 7, "named", "", false, false], [14, 17, 0, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Building", "Educational", "Applications", "(", "BEA", ")", "workshop", "at", "NAACL", "2013", "hosted", "the", "first", "shared", "NLI", "task", ".", "Tetreault", "et", "al", ",", "2013", "The", "competition", "resulted", "in", "29", "entries", "from", "teams", "around", "the", "world", ",", "24", "of", "which", "also", "published", "an", "article", "describing", "their", "systems", "and", "approaches", "."], "sentence-detokenized": "The Building Educational Applications (BEA) workshop at NAACL 2013 hosted the first shared NLI task. Tetreault et al, 2013 The competition resulted in 29 entries from teams around the world, 24 of which also published an article describing their systems and approaches.", "token2charspan": [[0, 3], [4, 12], [13, 24], [25, 37], [38, 39], [39, 42], [42, 43], [44, 52], [53, 55], [56, 61], [62, 66], [67, 73], [74, 77], [78, 83], [84, 90], [91, 94], [95, 99], [99, 100], [101, 110], [111, 113], [114, 116], [116, 117], [118, 122], [123, 126], [127, 138], [139, 147], [148, 150], [151, 153], [154, 161], [162, 166], [167, 172], [173, 179], [180, 183], [184, 189], [189, 190], [191, 193], [194, 196], [197, 202], [203, 207], [208, 217], [218, 220], [221, 228], [229, 239], [240, 245], [246, 253], [254, 257], [258, 268], [268, 269]]}
{"doc_key": "ai-test-151", "ner": [[0, 3, "algorithm"], [5, 8, "algorithm"], [15, 16, "misc"], [20, 21, "misc"], [40, 40, "algorithm"], [44, 44, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6], "relations": [[0, 3, 5, 8, "type-of", "", false, false], [0, 3, 15, 16, "related-to", "finds", false, false], [20, 21, 15, 16, "type-of", "", false, false], [44, 44, 40, 40, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Viterbi", "algorithm", "is", "a", "dynamic", "programming", "algorithm", "for", "finding", "the", "most", "likely", "sequence", "of", "hidden", "states", ",", "called", "the", "Viterbi", "path", ",", "resulting", "in", "a", "sequence", "of", "observed", "events", ",", "especially", "in", "the", "context", "of", "Markov", "information", "sources", "and", "hidden", "Markov", "models", "(", "HMM", ")", "."], "sentence-detokenized": "The Viterbi algorithm is a dynamic programming algorithm for finding the most likely sequence of hidden states, called the Viterbi path, resulting in a sequence of observed events, especially in the context of Markov information sources and hidden Markov models (HMM).", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 24], [25, 26], [27, 34], [35, 46], [47, 56], [57, 60], [61, 68], [69, 72], [73, 77], [78, 84], [85, 93], [94, 96], [97, 103], [104, 110], [110, 111], [112, 118], [119, 122], [123, 130], [131, 135], [135, 136], [137, 146], [147, 149], [150, 151], [152, 160], [161, 163], [164, 172], [173, 179], [179, 180], [181, 191], [192, 194], [195, 198], [199, 206], [207, 209], [210, 216], [217, 228], [229, 236], [237, 240], [241, 247], [248, 254], [255, 261], [262, 263], [263, 266], [266, 267], [267, 268]]}
{"doc_key": "ai-test-152", "ner": [[1, 1, "field"], [3, 6, "algorithm"], [8, 10, "misc"], [12, 13, "algorithm"], [15, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 1, 1, "part-of", "", false, false], [3, 6, 8, 10, "general-affiliation", "", false, false], [3, 6, 12, 13, "related-to", "generalizes_from", false, false], [3, 6, 15, 18, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "statistics", ",", "multinomial", "logistic", "regression", "is", "a", "classification", "method", "that", "generalizes", "logistic", "regression", "to", "multiclass", "classification", ",", "i.e.", "with", "more", "than", "two", "possible", "discrete", "outcomes", "."], "sentence-detokenized": "In statistics, multinomial logistic regression is a classification method that generalizes logistic regression to multiclass classification, i.e. with more than two possible discrete outcomes.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 26], [27, 35], [36, 46], [47, 49], [50, 51], [52, 66], [67, 73], [74, 78], [79, 90], [91, 99], [100, 110], [111, 113], [114, 124], [125, 139], [139, 140], [141, 145], [146, 150], [151, 155], [156, 160], [161, 164], [165, 173], [174, 182], [183, 191], [191, 192]]}
{"doc_key": "ai-test-153", "ner": [[0, 2, "algorithm"], [9, 10, "field"], [12, 15, "field"], [17, 17, "task"], [19, 20, "task"], [22, 23, "task"], [25, 26, "researcher"], [28, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 9, 10, "part-of", "", false, false], [0, 2, 12, 15, "part-of", "", false, false], [17, 17, 0, 2, "usage", "", true, false], [19, 20, 0, 2, "usage", "", true, false], [22, 23, 0, 2, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hidden", "Markov", "models", "are", "known", "for", "their", "applications", "in", "reinforcement", "learning", "and", "temporal", "pattern", "recognition", "such", "as", "speech", ",", "handwriting", "recognition", ",", "gesture", "recognition", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Hidden Markov models are known for their applications in reinforcement learning and temporal pattern recognition such as speech, handwriting recognition, gesture recognition, Thad Starner, Alex Pentland.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 30], [31, 34], [35, 40], [41, 53], [54, 56], [57, 70], [71, 79], [80, 83], [84, 92], [93, 100], [101, 112], [113, 117], [118, 120], [121, 127], [127, 128], [129, 140], [141, 152], [152, 153], [154, 161], [162, 173], [173, 174], [175, 179], [180, 187], [187, 188], [189, 193], [194, 202], [202, 203]]}
{"doc_key": "ai-test-154", "ner": [[5, 8, "misc"], [32, 34, "metrics"], [37, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 8, 37, 38, "named", "", false, false], [32, 34, 37, 38, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "basically", "means", "that", "if", "a", "-", "gram", "has", "been", "seen", "more", "than", "k", "times", "in", "training", ",", "the", "conditional", "probability", "of", "a", "word", "given", "it", "s", "history", "is", "proportional", "to", "the", "maximum", "likelihood", "estimate", "for", "that", "-", "gram", "."], "sentence-detokenized": "This basically means that if a -gram has been seen more than k times in training, the conditional probability of a word given its history is proportional to the maximum likelihood estimate for that -gram.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 25], [26, 28], [29, 30], [31, 32], [32, 36], [37, 40], [41, 45], [46, 50], [51, 55], [56, 60], [61, 62], [63, 68], [69, 71], [72, 80], [80, 81], [82, 85], [86, 97], [98, 109], [110, 112], [113, 114], [115, 119], [120, 125], [126, 128], [128, 129], [130, 137], [138, 140], [141, 153], [154, 156], [157, 160], [161, 168], [169, 179], [180, 188], [189, 192], [193, 197], [198, 199], [199, 203], [203, 204]]}
{"doc_key": "ai-test-155", "ner": [[4, 5, "task"], [7, 8, "task"], [10, 12, "task"], [16, 18, "task"], [26, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[26, 27, 16, 18, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "interested", "in", "knowledge", "representation", ",", "logical", "reasoning", "and", "natural", "language", "understanding", ",", "believing", "that", "deep", "language", "understanding", "can", "currently", "only", "be", "achieved", "by", "extensive", "handwork", "with", "semantically", "rich", "formalisms", "combined", "with", "statistical", "preferences", "."], "sentence-detokenized": "He is interested in knowledge representation, logical reasoning and natural language understanding, believing that deep language understanding can currently only be achieved by extensive handwork with semantically rich formalisms combined with statistical preferences.", "token2charspan": [[0, 2], [3, 5], [6, 16], [17, 19], [20, 29], [30, 44], [44, 45], [46, 53], [54, 63], [64, 67], [68, 75], [76, 84], [85, 98], [98, 99], [100, 109], [110, 114], [115, 119], [120, 128], [129, 142], [143, 146], [147, 156], [157, 161], [162, 164], [165, 173], [174, 176], [177, 186], [187, 195], [196, 200], [201, 213], [214, 218], [219, 229], [230, 238], [239, 243], [244, 255], [256, 267], [267, 268]]}
{"doc_key": "ai-test-156", "ner": [[1, 1, "programlang"], [3, 3, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "JavaScript", ",", "Python", "or"], "sentence-detokenized": "In JavaScript, Python or", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 21], [22, 24]]}
{"doc_key": "ai-test-157", "ner": [[0, 4, "misc"], [6, 7, "misc"], [11, 11, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 6, 7, "part-of", "", false, false], [6, 7, 11, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Newcomb", "awards", "are", "published", "in", "AI", "Magazine", ",", "published", "by", "AAAI", "."], "sentence-detokenized": "The Newcomb awards are published in AI Magazine, published by AAAI.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 22], [23, 32], [33, 35], [36, 38], [39, 47], [47, 48], [49, 58], [59, 61], [62, 66], [66, 67]]}
{"doc_key": "ai-test-158", "ner": [[1, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "squared", "error", "on", "a", "test", "set", "of", "100", "copies", "is", "0.084", ",", "which", "is", "less", "than", "the", "unnormalized", "error", "."], "sentence-detokenized": "The mean squared error on a test set of 100 copies is 0.084, which is less than the unnormalized error.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 25], [26, 27], [28, 32], [33, 36], [37, 39], [40, 43], [44, 50], [51, 53], [54, 59], [59, 60], [61, 66], [67, 69], [70, 74], [75, 79], [80, 83], [84, 96], [97, 102], [102, 103]]}
{"doc_key": "ai-test-159", "ner": [[0, 3, "metrics"], [10, 13, "field"], [20, 22, "task"], [24, 24, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 13, 0, 3, "usage", "", false, false], [20, 22, 10, 13, "part-of", "task_part_of_field", false, false], [24, 24, 20, 22, "named", "", false, false], [27, 28, 10, 13, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "F", "-", "score", "has", "been", "widely", "used", "in", "the", "natural", "language", "processing", "literature", ",", "e.g.", "for", "the", "evaluation", "of", "named", "entity", "recognition", "(", "NER", ")", "and", "word", "segmentation", "."], "sentence-detokenized": "The F-score has been widely used in the natural language processing literature, e.g. for the evaluation of named entity recognition (NER) and word segmentation.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 15], [16, 20], [21, 27], [28, 32], [33, 35], [36, 39], [40, 47], [48, 56], [57, 67], [68, 78], [78, 79], [80, 84], [85, 88], [89, 92], [93, 103], [104, 106], [107, 112], [113, 119], [120, 131], [132, 133], [133, 136], [136, 137], [138, 141], [142, 146], [147, 159], [159, 160]]}
{"doc_key": "ai-test-160", "ner": [[0, 0, "product"], [5, 6, "product"], [15, 16, "misc"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 15, 16, "related-to", "performs_task", false, false], [0, 0, 18, 19, "related-to", "performs_task", false, false], [5, 6, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Chatbots", "are", "typically", "used", "in", "dialogue", "systems", "for", "various", "purposes", ",", "including", "customer", "service", ",", "request", "placement", "or", "information", "gathering", "."], "sentence-detokenized": "Chatbots are typically used in dialogue systems for various purposes, including customer service, request placement or information gathering.", "token2charspan": [[0, 8], [9, 12], [13, 22], [23, 27], [28, 30], [31, 39], [40, 47], [48, 51], [52, 59], [60, 68], [68, 69], [70, 79], [80, 88], [89, 96], [96, 97], [98, 105], [106, 115], [116, 118], [119, 130], [131, 140], [140, 141]]}
{"doc_key": "ai-test-161", "ner": [[3, 9, "conference"], [13, 21, "conference"], [27, 37, "conference"], [47, 50, "conference"], [52, 53, "conference"]], "ner_mapping_to_source": [0, 1, 2, 4, 5], "relations": [[13, 21, 3, 9, "named", "", false, false], [27, 37, 3, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Major", "journals", "include", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "later", "renamed", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "and", "since", "September", "2014", "renamed", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "-", "after", "merging", "with", "an", "ACM", "publication", ")", ",", "Computer", "Speech", "and", "Language", "and", "Speech", "Communication", "."], "sentence-detokenized": "Major journals include IEEE Transactions on Speech and Audio Processing (later renamed IEEE Transactions on Audio, Speech and Language Processing and since September 2014 renamed IEEE/ACM Transactions on Audio, Speech and Language Processing - after merging with an ACM publication), Computer Speech and Language and Speech Communication.", "token2charspan": [[0, 5], [6, 14], [15, 22], [23, 27], [28, 40], [41, 43], [44, 50], [51, 54], [55, 60], [61, 71], [72, 73], [73, 78], [79, 86], [87, 91], [92, 104], [105, 107], [108, 113], [113, 114], [115, 121], [122, 125], [126, 134], [135, 145], [146, 149], [150, 155], [156, 165], [166, 170], [171, 178], [179, 183], [183, 184], [184, 187], [188, 200], [201, 203], [204, 209], [209, 210], [211, 217], [218, 221], [222, 230], [231, 241], [242, 243], [244, 249], [250, 257], [258, 262], [263, 265], [266, 269], [270, 281], [281, 282], [282, 283], [284, 292], [293, 299], [300, 303], [304, 312], [313, 316], [317, 323], [324, 337], [337, 338]]}
{"doc_key": "ai-test-162", "ner": [[0, 0, "algorithm"], [5, 6, "task"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 0, 0, "usage", "", false, false], [5, 6, 8, 9, "part-of", "task_part_of_field", false, false], [5, 6, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["EM", "is", "often", "used", "for", "data", "clustering", "in", "machine", "learning", "and", "computer", "vision", "."], "sentence-detokenized": "EM is often used for data clustering in machine learning and computer vision.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 16], [17, 20], [21, 25], [26, 36], [37, 39], [40, 47], [48, 56], [57, 60], [61, 69], [70, 76], [76, 77]]}
{"doc_key": "ai-test-163", "ner": [[8, 10, "metrics"], [24, 27, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 10, 24, 27, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["Although", "there", "is", "no", "perfect", "way", "to", "describe", "the", "confusion", "matrix", "of", "TRUE", "and", "FALSE", "positive", "and", "negative", "results", "with", "a", "single", "number", ",", "Matthew", "'s", "correlation", "coefficient", "is", "generally", "considered", "to", "be", "one", "of", "the", "best", "measures", "of", "this", "kind", "."], "sentence-detokenized": "Although there is no perfect way to describe the confusion matrix of TRUE and FALSE positive and negative results with a single number, Matthew's correlation coefficient is generally considered to be one of the best measures of this kind.", "token2charspan": [[0, 8], [9, 14], [15, 17], [18, 20], [21, 28], [29, 32], [33, 35], [36, 44], [45, 48], [49, 58], [59, 65], [66, 68], [69, 73], [74, 77], [78, 83], [84, 92], [93, 96], [97, 105], [106, 113], [114, 118], [119, 120], [121, 127], [128, 134], [134, 135], [136, 143], [143, 145], [146, 157], [158, 169], [170, 172], [173, 182], [183, 193], [194, 196], [197, 199], [200, 203], [204, 206], [207, 210], [211, 215], [216, 224], [225, 227], [228, 232], [233, 237], [237, 238]]}
{"doc_key": "ai-test-164", "ner": [[15, 18, "field"], [32, 33, "field"], [37, 38, "field"], [42, 43, "algorithm"], [45, 46, "task"], [48, 49, "algorithm"], [54, 57, "algorithm"], [59, 60, "algorithm"], [66, 68, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[37, 38, 32, 33, "part-of", "subfield", false, false], [42, 43, 37, 38, "part-of", "", false, true], [45, 46, 37, 38, "part-of", "", false, true], [48, 49, 37, 38, "part-of", "", false, true], [54, 57, 37, 38, "part-of", "", false, true], [59, 60, 37, 38, "part-of", "", false, true], [66, 68, 37, 38, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "data", "sets", "have", "become", "larger", "and", "more", "complex", ",", "direct", ",", "hands", "-", "on", "data", "analysis", "has", "been", "complemented", "by", "indirect", ",", "automated", "data", "processing", ",", "aided", "by", "other", "discoveries", "in", "computer", "science", ",", "notably", "in", "machine", "learning", ",", "such", "as", "neural", "networks", ",", "cluster", "analysis", ",", "genetic", "algorithms", "(", "1950s", ")", ",", "learning", "of", "decision", "trees", "and", "decision", "rules", "(", "1960", "s", ")", "and", "support", "vector", "machines", "(", "1990", "s", ")", "."], "sentence-detokenized": "As data sets have become larger and more complex, direct, hands-on data analysis has been complemented by indirect, automated data processing, aided by other discoveries in computer science, notably in machine learning, such as neural networks, cluster analysis, genetic algorithms (1950s), learning of decision trees and decision rules (1960s) and support vector machines (1990s).", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 17], [18, 24], [25, 31], [32, 35], [36, 40], [41, 48], [48, 49], [50, 56], [56, 57], [58, 63], [63, 64], [64, 66], [67, 71], [72, 80], [81, 84], [85, 89], [90, 102], [103, 105], [106, 114], [114, 115], [116, 125], [126, 130], [131, 141], [141, 142], [143, 148], [149, 151], [152, 157], [158, 169], [170, 172], [173, 181], [182, 189], [189, 190], [191, 198], [199, 201], [202, 209], [210, 218], [218, 219], [220, 224], [225, 227], [228, 234], [235, 243], [243, 244], [245, 252], [253, 261], [261, 262], [263, 270], [271, 281], [282, 283], [283, 288], [288, 289], [289, 290], [291, 299], [300, 302], [303, 311], [312, 317], [318, 321], [322, 330], [331, 336], [337, 338], [338, 342], [342, 343], [343, 344], [345, 348], [349, 356], [357, 363], [364, 372], [373, 374], [374, 378], [378, 379], [379, 380], [380, 381]]}
{"doc_key": "ai-test-165", "ner": [[4, 4, "researcher"], [9, 10, "misc"], [17, 18, "researcher"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 4, 4, "artifact", "", false, false], [9, 10, 17, 18, "artifact", "", false, false], [9, 10, 20, 21, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "autumn", "2005", ",", "Thrun", "published", "a", "textbook", "entitled", "Probabilistic", "Robotics", "with", "his", "long", "-", "time", "collaborators", "Dieter", "Fox", "and", "Wolfram", "Burgard", "."], "sentence-detokenized": "In autumn 2005, Thrun published a textbook entitled Probabilistic Robotics with his long-time collaborators Dieter Fox and Wolfram Burgard.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 21], [22, 31], [32, 33], [34, 42], [43, 51], [52, 65], [66, 74], [75, 79], [80, 83], [84, 88], [88, 89], [89, 93], [94, 107], [108, 114], [115, 118], [119, 122], [123, 130], [131, 138], [138, 139]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "and", "Pereiramath", "as", "follows", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum and Pereiramath as follows:", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 37], [38, 49], [50, 52], [53, 60], [60, 61]]}
{"doc_key": "ai-test-167", "ner": [[0, 1, "task"], [3, 5, "task"], [7, 8, "field"], [11, 12, "field"], [14, 16, "field"], [18, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 11, 12, "part-of", "task_part_of_field", false, false], [0, 1, 14, 16, "part-of", "task_part_of_field", false, false], [3, 5, 0, 1, "named", "", false, false], [11, 12, 7, 8, "part-of", "subfield", false, false], [14, 16, 7, 8, "part-of", "subfield", false, false], [18, 20, 14, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Question", "Answering", "(", "QA", ")", "is", "a", "computer", "science", "discipline", "in", "information", "retrieval", "and", "natural", "language", "processing", "(", "NLP", ")", "that", "deals", "with", "building", "systems", "that", "automatically", "answer", "questions", "asked", "by", "humans", "in", "a", "natural", "language", "."], "sentence-detokenized": "Question Answering (QA) is a computer science discipline in information retrieval and natural language processing (NLP) that deals with building systems that automatically answer questions asked by humans in a natural language.", "token2charspan": [[0, 8], [9, 18], [19, 20], [20, 22], [22, 23], [24, 26], [27, 28], [29, 37], [38, 45], [46, 56], [57, 59], [60, 71], [72, 81], [82, 85], [86, 93], [94, 102], [103, 113], [114, 115], [115, 118], [118, 119], [120, 124], [125, 130], [131, 135], [136, 144], [145, 152], [153, 157], [158, 171], [172, 178], [179, 188], [189, 194], [195, 197], [198, 204], [205, 207], [208, 209], [210, 217], [218, 226], [226, 227]]}
{"doc_key": "ai-test-168", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "in", "the", "version", "of", "the", "metric", "used", "in", "NIST", "evaluations", "prior", "to", "2009", ",", "the", "shortest", "reference", "phrase", "was", "used", "instead", "."], "sentence-detokenized": "However, in the version of the metric used in NIST evaluations prior to 2009, the shortest reference phrase was used instead.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 37], [38, 42], [43, 45], [46, 50], [51, 62], [63, 68], [69, 71], [72, 76], [76, 77], [78, 81], [82, 90], [91, 100], [101, 107], [108, 111], [112, 116], [117, 124], [124, 125]]}
{"doc_key": "ai-test-169", "ner": [[5, 5, "person"], [13, 14, "organisation"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 15, 15, "related-to", "invests_in", false, false], [15, 15, 13, 14, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["On", "27", "August", "2018", ",", "Toyota", "announced", "a", "$", "500", "million", "investment", "in", "Uber", "'s", "autonomous", "cars", "."], "sentence-detokenized": "On 27 August 2018, Toyota announced a $500 million investment in Uber's autonomous cars.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 17], [17, 18], [19, 25], [26, 35], [36, 37], [38, 39], [39, 42], [43, 50], [51, 61], [62, 64], [65, 69], [69, 71], [72, 82], [83, 87], [87, 88]]}
{"doc_key": "ai-test-170", "ner": [[5, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sample", "maximum", "is", "the", "maximum", "likelihood", "estimate", "of", "the", "population", "maximum", ",", "but", "as", "mentioned", "above", "it", "is", "skewed", "."], "sentence-detokenized": "The sample maximum is the maximum likelihood estimate of the population maximum, but as mentioned above it is skewed.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 21], [22, 25], [26, 33], [34, 44], [45, 53], [54, 56], [57, 60], [61, 71], [72, 79], [79, 80], [81, 84], [85, 87], [88, 97], [98, 103], [104, 106], [107, 109], [110, 116], [116, 117]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [3, 3, "misc"], [6, 9, "metrics"], [17, 19, "algorithm"], [21, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 3, "related-to", "overcomes", false, false], [0, 0, 6, 9, "related-to", "increases", false, false], [3, 3, 17, 19, "opposite", "", false, false], [3, 3, 21, 23, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LSI", "helps", "overcome", "synonymy", "by", "increasing", "recall", ",", "which", "is", "one", "of", "the", "most", "problematic", "limitations", "of", "Boolean", "keyword", "searches", "and", "vector", "space", "models", "."], "sentence-detokenized": "LSI helps overcome synonymy by increasing recall, which is one of the most problematic limitations of Boolean keyword searches and vector space models.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 27], [28, 30], [31, 41], [42, 48], [48, 49], [50, 55], [56, 58], [59, 62], [63, 65], [66, 69], [70, 74], [75, 86], [87, 98], [99, 101], [102, 109], [110, 117], [118, 126], [127, 130], [131, 137], [138, 143], [144, 150], [150, 151]]}
{"doc_key": "ai-test-172", "ner": [[18, 18, "programlang"], [20, 20, "programlang"], [22, 22, "programlang"], [24, 25, "programlang"], [27, 27, "programlang"], [29, 29, "programlang"], [31, 31, "programlang"], [33, 33, "programlang"], [35, 35, "programlang"], [37, 37, "programlang"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [], "relations_mapping_to_source": [], "sentence": ["Data", "acquisition", "programs", "are", "usually", "controlled", "by", "software", "programs", "developed", "using", "various", "general", "purpose", "programming", "languages", "such", "as", "Assembly", ",", "BASIC", ",", "C", ",", "C", "++", ",", "C#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", ",", "etc."], "sentence-detokenized": "Data acquisition programs are usually controlled by software programs developed using various general purpose programming languages such as Assembly, BASIC, C, C++, C#, Fortran, Java, LabVIEW, Lisp, Pascal, etc.", "token2charspan": [[0, 4], [5, 16], [17, 25], [26, 29], [30, 37], [38, 48], [49, 51], [52, 60], [61, 69], [70, 79], [80, 85], [86, 93], [94, 101], [102, 109], [110, 121], [122, 131], [132, 136], [137, 139], [140, 148], [148, 149], [150, 155], [155, 156], [157, 158], [158, 159], [160, 161], [161, 163], [163, 164], [165, 167], [167, 168], [169, 176], [176, 177], [178, 182], [182, 183], [184, 191], [191, 192], [193, 197], [197, 198], [199, 205], [205, 206], [207, 211]]}
{"doc_key": "ai-test-173", "ner": [[3, 3, "organisation"], [10, 10, "country"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2003", ",", "Honda", "broadcast", "its", "Cog", "advertisement", "in", "the", "UK", "and", "on", "the", "Internet", "."], "sentence-detokenized": "In 2003, Honda broadcast its Cog advertisement in the UK and on the Internet.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 24], [25, 28], [29, 32], [33, 46], [47, 49], [50, 53], [54, 56], [57, 60], [61, 63], [64, 67], [68, 76], [76, 77]]}
{"doc_key": "ai-test-174", "ner": [[0, 4, "conference"], [6, 7, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 6, 7, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Association", "for", "Computational", "Linguistics", "defines", "computational", "linguistics", "as", ":"], "sentence-detokenized": "The Association for Computational Linguistics defines computational linguistics as:", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 33], [34, 45], [46, 53], [54, 67], [68, 79], [80, 82], [82, 83]]}
{"doc_key": "ai-test-175", "ner": [[0, 2, "algorithm"], [9, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 11, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["Expectation", "maximization", "algorithms", "can", "be", "used", "to", "compute", "approximate", "maximum", "likelihood", "estimates", "of", "unknown", "state", "parameters", "in", "minimum", "variance", "filters", "and", "smoothers", "."], "sentence-detokenized": "Expectation maximization algorithms can be used to compute approximate maximum likelihood estimates of unknown state parameters in minimum variance filters and smoothers.", "token2charspan": [[0, 11], [12, 24], [25, 35], [36, 39], [40, 42], [43, 47], [48, 50], [51, 58], [59, 70], [71, 78], [79, 89], [90, 99], [100, 102], [103, 110], [111, 116], [117, 127], [128, 130], [131, 138], [139, 147], [148, 155], [156, 159], [160, 169], [169, 170]]}
{"doc_key": "ai-test-176", "ner": [[7, 9, "person"], [11, 12, "person"], [14, 15, "person"], [18, 19, "misc"], [20, 21, "person"], [24, 25, "person"], [29, 29, "person"], [31, 32, "person"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8], "relations": [[20, 21, 18, 19, "role", "model_for", false, false], [29, 29, 31, 32, "social", "family", false, false]], "relations_mapping_to_source": [3, 4], "sentence": ["Among", "the", "correspondents", "were", "former", "Baywatch", "actresses", "Donna", "D'", "Errico", ",", "Carmen", "Electra", "and", "Traci", "Bingham", ",", "former", "Playboy", "Playmate", "Heidi", "Mark", ",", "comedian", "Arj", "Barker", "and", "identical", "twins", "Randy", "and", "Jason", "Sklar", "."], "sentence-detokenized": "Among the correspondents were former Baywatch actresses Donna D'Errico, Carmen Electra and Traci Bingham, former Playboy Playmate Heidi Mark, comedian Arj Barker and identical twins Randy and Jason Sklar.", "token2charspan": [[0, 5], [6, 9], [10, 24], [25, 29], [30, 36], [37, 45], [46, 55], [56, 61], [62, 64], [64, 70], [70, 71], [72, 78], [79, 86], [87, 90], [91, 96], [97, 104], [104, 105], [106, 112], [113, 120], [121, 129], [130, 135], [136, 140], [140, 141], [142, 150], [151, 154], [155, 161], [162, 165], [166, 175], [176, 181], [182, 187], [188, 191], [192, 197], [198, 203], [203, 204]]}
{"doc_key": "ai-test-177", "ner": [[8, 9, "task"], [11, 11, "task"], [16, 18, "product"], [21, 22, "task"], [24, 24, "task"], [29, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 8, 9, "named", "", false, false], [16, 18, 8, 9, "general-affiliation", "", false, false], [24, 24, 21, 22, "named", "", false, false], [29, 30, 21, 22, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "is", "often", "used", "to", "generate", "representations", "for", "speech", "recognition", "(", "ASR", ")", ",", "e.g.", "the", "CMU", "Sphinx", "system", ",", "and", "speech", "synthesis", "(", "TTS", ")", ",", "e.g.", "the", "Festival", "system", "."], "sentence-detokenized": "It is often used to generate representations for speech recognition (ASR), e.g. the CMU Sphinx system, and speech synthesis (TTS), e.g. the Festival system.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 16], [17, 19], [20, 28], [29, 44], [45, 48], [49, 55], [56, 67], [68, 69], [69, 72], [72, 73], [73, 74], [75, 79], [80, 83], [84, 87], [88, 94], [95, 101], [101, 102], [103, 106], [107, 113], [114, 123], [124, 125], [125, 128], [128, 129], [129, 130], [131, 135], [136, 139], [140, 148], [149, 155], [155, 156]]}
{"doc_key": "ai-test-178", "ner": [[0, 0, "metrics"], [2, 4, "metrics"], [6, 6, "metrics"], [12, 12, "metrics"], [26, 27, "metrics"], [29, 29, "metrics"], [40, 41, "metrics"], [43, 43, "metrics"], [45, 47, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 4, 0, 0, "named", "", false, false], [6, 6, 2, 4, "named", "", false, false], [12, 12, 0, 0, "named", "", false, false], [29, 29, 26, 27, "named", "", false, false], [43, 43, 40, 41, "named", "", false, false], [45, 47, 40, 41, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sensitivity", "or", "TRUE", "Positive", "Rate", "(", "TPR", ")", ",", "also", "known", "as", "recall", ",", "is", "the", "proportion", "of", "people", "who", "test", "positive", "and", "are", "positive", "(", "TRUE", "Positive", ",", "TP", ")", "of", "all", "the", "people", "who", "are", "actually", "positive", "(", "Condition", "Positive", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "Sensitivity or TRUE Positive Rate (TPR), also known as recall, is the proportion of people who test positive and are positive (TRUE Positive, TP) of all the people who are actually positive (Condition Positive, CP = TP + FN).", "token2charspan": [[0, 11], [12, 14], [15, 19], [20, 28], [29, 33], [34, 35], [35, 38], [38, 39], [39, 40], [41, 45], [46, 51], [52, 54], [55, 61], [61, 62], [63, 65], [66, 69], [70, 80], [81, 83], [84, 90], [91, 94], [95, 99], [100, 108], [109, 112], [113, 116], [117, 125], [126, 127], [127, 131], [132, 140], [140, 141], [142, 144], [144, 145], [146, 148], [149, 152], [153, 156], [157, 163], [164, 167], [168, 171], [172, 180], [181, 189], [190, 191], [191, 200], [201, 209], [209, 210], [211, 213], [214, 215], [216, 218], [219, 220], [221, 223], [223, 224], [224, 225]]}
{"doc_key": "ai-test-179", "ner": [[1, 2, "task"], [11, 11, "conference"], [13, 14, "conference"], [16, 16, "conference"], [18, 20, "conference"], [22, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6], "relations": [[11, 11, 1, 2, "topic", "", false, false], [13, 14, 1, 2, "topic", "", false, false], [16, 16, 1, 2, "topic", "", false, false], [18, 20, 1, 2, "topic", "", false, false], [22, 23, 1, 2, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4, 5], "sentence": ["Popular", "speech", "recognition", "conferences", "held", "every", "one", "or", "two", "years", "include", "SpeechTEK", "and", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", "and", "IEEE", "ASRU", "."], "sentence-detokenized": "Popular speech recognition conferences held every one or two years include SpeechTEK and SpeechTEK Europe, ICASSP, Interspeech/Eurospeech and IEEE ASRU.", "token2charspan": [[0, 7], [8, 14], [15, 26], [27, 38], [39, 43], [44, 49], [50, 53], [54, 56], [57, 60], [61, 66], [67, 74], [75, 84], [85, 88], [89, 98], [99, 105], [105, 106], [107, 113], [113, 114], [115, 126], [126, 127], [127, 137], [138, 141], [142, 146], [147, 151], [151, 152]]}
{"doc_key": "ai-test-180", "ner": [[0, 0, "researcher"], [3, 3, "researcher"], [15, 16, "product"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[20, 20, 0, 0, "artifact", "", false, false], [20, 20, 3, 3, "artifact", "", false, false], [20, 20, 15, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Devol", "collaborated", "with", "Engelberger", ",", "the", "company", "'s", "CEO", ",", "to", "develop", "and", "produce", "an", "industrial", "robot", "under", "the", "name", "Unimate", "."], "sentence-detokenized": "Devol collaborated with Engelberger, the company's CEO, to develop and produce an industrial robot under the name Unimate.", "token2charspan": [[0, 5], [6, 18], [19, 23], [24, 35], [35, 36], [37, 40], [41, 48], [48, 50], [51, 54], [54, 55], [56, 58], [59, 66], [67, 70], [71, 78], [79, 81], [82, 92], [93, 98], [99, 104], [105, 108], [109, 113], [114, 121], [121, 122]]}
{"doc_key": "ai-test-181", "ner": [[1, 3, "algorithm"], [5, 7, "algorithm"], [9, 14, "algorithm"], [23, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 3, 9, 14, "general-affiliation", "", false, false], [5, 7, 1, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "hidden", "Markov", "model", "(", "HMM", ")", "is", "a", "statistical", "Markov", "model", "in", "which", "the", "system", "being", "modelled", "is", "assumed", "to", "be", "a", "Markov", "process", "with", "unobserved", "(", "hidden", ")", "states", "."], "sentence-detokenized": "A hidden Markov model (HMM) is a statistical Markov model in which the system being modelled is assumed to be a Markov process with unobserved (hidden) states.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [22, 23], [23, 26], [26, 27], [28, 30], [31, 32], [33, 44], [45, 51], [52, 57], [58, 60], [61, 66], [67, 70], [71, 77], [78, 83], [84, 92], [93, 95], [96, 103], [104, 106], [107, 109], [110, 111], [112, 118], [119, 126], [127, 131], [132, 142], [143, 144], [144, 150], [150, 151], [152, 158], [158, 159]]}
{"doc_key": "ai-test-182", "ner": [[19, 21, "metrics"], [26, 27, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "property", ",", "which", "is", "undesirable", "in", "many", "applications", ",", "has", "led", "researchers", "to", "use", "alternatives", "such", "as", "the", "mean", "absolute", "error", "or", "alternatives", "based", "on", "the", "median", "."], "sentence-detokenized": "This property, which is undesirable in many applications, has led researchers to use alternatives such as the mean absolute error or alternatives based on the median.", "token2charspan": [[0, 4], [5, 13], [13, 14], [15, 20], [21, 23], [24, 35], [36, 38], [39, 43], [44, 56], [56, 57], [58, 61], [62, 65], [66, 77], [78, 80], [81, 84], [85, 97], [98, 102], [103, 105], [106, 109], [110, 114], [115, 123], [124, 129], [130, 132], [133, 145], [146, 151], [152, 154], [155, 158], [159, 165], [165, 166]]}
{"doc_key": "ai-test-183", "ner": [[22, 24, "algorithm"], [31, 32, "field"], [35, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 24, 31, 32, "part-of", "", false, false], [22, 24, 35, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Such", "a", "sequence", "(", "which", "depends", "on", "the", "result", "of", "the", "examination", "of", "previous", "attributes", "at", "each", "step", ")", "is", "called", "a", "decision", "tree", "and", "is", "used", "in", "the", "field", "of", "machine", "learning", "known", "as", "decision", "tree", "learning", "."], "sentence-detokenized": "Such a sequence (which depends on the result of the examination of previous attributes at each step) is called a decision tree and is used in the field of machine learning known as decision tree learning.", "token2charspan": [[0, 4], [5, 6], [7, 15], [16, 17], [17, 22], [23, 30], [31, 33], [34, 37], [38, 44], [45, 47], [48, 51], [52, 63], [64, 66], [67, 75], [76, 86], [87, 89], [90, 94], [95, 99], [99, 100], [101, 103], [104, 110], [111, 112], [113, 121], [122, 126], [127, 130], [131, 133], [134, 138], [139, 141], [142, 145], [146, 151], [152, 154], [155, 162], [163, 171], [172, 177], [178, 180], [181, 189], [190, 194], [195, 203], [203, 204]]}
{"doc_key": "ai-test-184", "ner": [[2, 3, "task"], [5, 5, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 5, 5, "compare", "", false, false], [19, 20, 5, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "in", "factor", "analysis", ",", "LCA", "can", "also", "be", "used", "to", "classify", "cases", "according", "to", "their", "class", "membership", "with", "maximum", "likelihood", "."], "sentence-detokenized": "As in factor analysis, LCA can also be used to classify cases according to their class membership with maximum likelihood.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 21], [21, 22], [23, 26], [27, 30], [31, 35], [36, 38], [39, 43], [44, 46], [47, 55], [56, 61], [62, 71], [72, 74], [75, 80], [81, 86], [87, 97], [98, 102], [103, 110], [111, 121], [121, 122]]}
{"doc_key": "ai-test-185", "ner": [[0, 2, "algorithm"], [5, 7, "metrics"], [9, 9, "metrics"], [10, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 7, "usage", "", false, false], [5, 7, 10, 12, "related-to", "", false, false], [9, 9, 5, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Supervised", "neural", "networks", "using", "a", "mean", "squared", "error", "(", "MSE", ")", "cost", "function", "can", "use", "formal", "statistical", "methods", "to", "determine", "the", "confidence", "of", "the", "trained", "model", "."], "sentence-detokenized": "Supervised neural networks using a mean squared error (MSE) cost function can use formal statistical methods to determine the confidence of the trained model.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 32], [33, 34], [35, 39], [40, 47], [48, 53], [54, 55], [55, 58], [58, 59], [60, 64], [65, 73], [74, 77], [78, 81], [82, 88], [89, 100], [101, 108], [109, 111], [112, 121], [122, 125], [126, 136], [137, 139], [140, 143], [144, 151], [152, 157], [157, 158]]}
{"doc_key": "ai-test-186", "ner": [[15, 16, "algorithm"], [18, 20, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 16, 18, 20, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "can", "be", "expressed", "directly", "as", "a", "linear", "program", ",", "but", "it", "also", "corresponds", "to", "Tikhonov", "regularization", "with", "hinged", "loss", "function", ",", "mathV", "(", "f", "(", "x", ")", ",", "y", ")", "=\\", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "math", ":"], "sentence-detokenized": "This can be expressed directly as a linear program, but it also corresponds to Tikhonov regularization with hinged loss function, mathV (f (x), y) =\\ max (0, 1 - yf (x)) / math:", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 21], [22, 30], [31, 33], [34, 35], [36, 42], [43, 50], [50, 51], [52, 55], [56, 58], [59, 63], [64, 75], [76, 78], [79, 87], [88, 102], [103, 107], [108, 114], [115, 119], [120, 128], [128, 129], [130, 135], [136, 137], [137, 138], [139, 140], [140, 141], [141, 142], [142, 143], [144, 145], [145, 146], [147, 149], [150, 153], [154, 155], [155, 156], [156, 157], [158, 159], [160, 161], [162, 164], [165, 166], [166, 167], [167, 168], [168, 169], [170, 171], [172, 176], [176, 177]]}
{"doc_key": "ai-test-187", "ner": [[6, 7, "researcher"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "technique", "was", "described", "in", "Breiman", "'s", "original", "article", "and", "is", "implemented", "in", "the", "R", "package", "randomForest", "."], "sentence-detokenized": "The following technique was described in Breiman's original article and is implemented in the R package randomForest.", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 27], [28, 37], [38, 40], [41, 48], [48, 50], [51, 59], [60, 67], [68, 71], [72, 74], [75, 86], [87, 89], [90, 93], [94, 95], [96, 103], [104, 116], [116, 117]]}
{"doc_key": "ai-test-188", "ner": [[7, 7, "metrics"], [39, 39, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "image", "quality", "measurements", ",", "such", "as", "PSNR", ",", "are", "typically", "performed", "on", "fixed", "resolution", "images", "and", "do", "not", "take", "into", "account", "certain", "aspects", "of", "the", "human", "visual", "system", ",", "such", "as", "the", "change", "in", "spatial", "resolution", "across", "the", "retina", "."], "sentence-detokenized": "Traditional image quality measurements, such as PSNR, are typically performed on fixed resolution images and do not take into account certain aspects of the human visual system, such as the change in spatial resolution across the retina.", "token2charspan": [[0, 11], [12, 17], [18, 25], [26, 38], [38, 39], [40, 44], [45, 47], [48, 52], [52, 53], [54, 57], [58, 67], [68, 77], [78, 80], [81, 86], [87, 97], [98, 104], [105, 108], [109, 111], [112, 115], [116, 120], [121, 125], [126, 133], [134, 141], [142, 149], [150, 152], [153, 156], [157, 162], [163, 169], [170, 176], [176, 177], [178, 182], [183, 185], [186, 189], [190, 196], [197, 199], [200, 207], [208, 218], [219, 225], [226, 229], [230, 236], [236, 237]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [10, 12, "person"], [15, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 15, 18, "role", "", false, false], [3, 4, 15, 18, "role", "", false, false], [6, 7, 15, 18, "role", "", false, false], [15, 18, 10, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Dru", "and", "Macdonald", "Carey", "starred", "in", "Jack", "Broder", "'s", "colour", "production", "Hannah", "Lee", ",", "which", "opened", "on", "19", "June", "1953", "."], "sentence-detokenized": "John Ireland, Joanne Dru and Macdonald Carey starred in Jack Broder's colour production Hannah Lee, which opened on 19 June 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 55], [56, 60], [61, 67], [67, 69], [70, 76], [77, 87], [88, 94], [95, 98], [98, 99], [100, 105], [106, 112], [113, 115], [116, 118], [119, 123], [124, 128], [128, 129]]}
{"doc_key": "ai-test-190", "ner": [[4, 6, "task"], [11, 12, "field"], [17, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 11, 12, "usage", "", false, false], [17, 17, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "process", "is", "called", "image", "registration", "and", "uses", "various", "methods", "of", "computer", "vision", ",", "mostly", "related", "to", "tracking", "."], "sentence-detokenized": "This process is called image registration and uses various methods of computer vision, mostly related to tracking.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 22], [23, 28], [29, 41], [42, 45], [46, 50], [51, 58], [59, 66], [67, 69], [70, 78], [79, 85], [85, 86], [87, 93], [94, 101], [102, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-test-191", "ner": [[17, 18, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Now", "let", "'s", "start", "explaining", "the", "different", "possible", "correlations", "between", "the", "predicted", "and", "the", "actual", "result", ":", "confusion", "matrix"], "sentence-detokenized": "Now let's start explaining the different possible correlations between the predicted and the actual result: confusion matrix", "token2charspan": [[0, 3], [4, 7], [7, 9], [10, 15], [16, 26], [27, 30], [31, 40], [41, 49], [50, 62], [63, 70], [71, 74], [75, 84], [85, 88], [89, 92], [93, 99], [100, 106], [106, 107], [108, 117], [118, 124]]}
{"doc_key": "ai-test-192", "ner": [[0, 4, "misc"], [6, 6, "product"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "VOICEBOX", "speech", "processing", "toolkit", "in", "MATLAB", "implements", "the", "conversion", "and", "its", "inverse", "form", "as", ":"], "sentence-detokenized": "The VOICEBOX speech processing toolkit in MATLAB implements the conversion and its inverse form as:", "token2charspan": [[0, 3], [4, 12], [13, 19], [20, 30], [31, 38], [39, 41], [42, 48], [49, 59], [60, 63], [64, 74], [75, 78], [79, 82], [83, 90], [91, 95], [96, 98], [98, 99]]}
{"doc_key": "ai-test-193", "ner": [[0, 1, "programlang"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 8, 9, "general-affiliation", "", false, false], [0, 1, 11, 12, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "is", "a", "logic", "programming", "language", "associated", "with", "artificial", "intelligence", "and", "computational", "linguistics", "."], "sentence-detokenized": "Prolog is a logic programming language associated with artificial intelligence and computational linguistics.", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 17], [18, 29], [30, 38], [39, 49], [50, 54], [55, 65], [66, 78], [79, 82], [83, 96], [97, 108], [108, 109]]}
{"doc_key": "ai-test-194", "ner": [[0, 0, "researcher"], [9, 9, "field"], [11, 11, "field"], [17, 20, "organisation"], [22, 26, "organisation"], [29, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 9, 9, "related-to", "works_with_topic", false, false], [0, 0, 11, 11, "related-to", "works_with_topic", false, false], [0, 0, 17, 20, "role", "", false, false], [0, 0, 22, 26, "role", "", false, false], [0, 0, 29, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "has", "received", "numerous", "awards", "for", "his", "contributions", "to", "neuroscience", "and", "psychology", ",", "including", "membership", "of", "the", "Royal", "Society", "of", "London", ",", "the", "Royal", "Society", "of", "Canada", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner has received numerous awards for his contributions to neuroscience and psychology, including membership of the Royal Society of London, the Royal Society of Canada and the National Academy of Sciences.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 28], [29, 35], [36, 39], [40, 43], [44, 57], [58, 60], [61, 73], [74, 77], [78, 88], [88, 89], [90, 99], [100, 110], [111, 113], [114, 117], [118, 123], [124, 131], [132, 134], [135, 141], [141, 142], [143, 146], [147, 152], [153, 160], [161, 163], [164, 170], [171, 174], [175, 178], [179, 187], [188, 195], [196, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-test-195", "ner": [[17, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "task"], [29, 29, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["By", "combining", "these", "operators", ",", "algorithms", "can", "be", "obtained", "for", "many", "image", "processing", "tasks", ",", "such", "as", "feature", "extraction", ",", "image", "segmentation", ",", "image", "sharpening", ",", "image", "filtering", "and", "classification", "."], "sentence-detokenized": "By combining these operators, algorithms can be obtained for many image processing tasks, such as feature extraction, image segmentation, image sharpening, image filtering and classification.", "token2charspan": [[0, 2], [3, 12], [13, 18], [19, 28], [28, 29], [30, 40], [41, 44], [45, 47], [48, 56], [57, 60], [61, 65], [66, 71], [72, 82], [83, 88], [88, 89], [90, 94], [95, 97], [98, 105], [106, 116], [116, 117], [118, 123], [124, 136], [136, 137], [138, 143], [144, 154], [154, 155], [156, 161], [162, 171], [172, 175], [176, 190], [190, 191]]}
{"doc_key": "ai-test-196", "ner": [[9, 12, "university"], [17, 19, "organisation"], [21, 22, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 22, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["From", "2017", ",", "he", "is", "a", "professor", "at", "the", "Coll\u00e8ge", "de", "France", "and", "has", "been", "head", "of", "INSERM", "Unit", "562", ",", "Cognitive", "Neuroimaging", ",", "since", "1989", "."], "sentence-detokenized": "From 2017, he is a professor at the Coll\u00e8ge de France and has been head of INSERM Unit 562, Cognitive Neuroimaging, since 1989.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 13], [14, 16], [17, 18], [19, 28], [29, 31], [32, 35], [36, 43], [44, 46], [47, 53], [54, 57], [58, 61], [62, 66], [67, 71], [72, 74], [75, 81], [82, 86], [87, 90], [90, 91], [92, 101], [102, 114], [114, 115], [116, 121], [122, 126], [126, 127]]}
{"doc_key": "ai-test-197", "ner": [[12, 20, "algorithm"], [16, 18, "algorithm"], [22, 22, "algorithm"], [24, 30, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[22, 22, 24, 30, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["There", "are", "many", "methods", "to", "learn", "these", "embeddings", ",", "in", "particular", "using", "Bayesian", "clustering", "frameworks", "or", "energy", "-", "based", "frameworks", "and", "recently", "TransE", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", "2013", ")", "."], "sentence-detokenized": "There are many methods to learn these embeddings, in particular using Bayesian clustering frameworks or energy-based frameworks and recently TransE (Conference on Neural Information Processing Systems 2013).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 22], [23, 25], [26, 31], [32, 37], [38, 48], [48, 49], [50, 52], [53, 63], [64, 69], [70, 78], [79, 89], [90, 100], [101, 103], [104, 110], [110, 111], [111, 116], [117, 127], [128, 131], [132, 140], [141, 147], [148, 149], [149, 159], [160, 162], [163, 169], [170, 181], [182, 192], [193, 200], [201, 205], [205, 206], [206, 207]]}
{"doc_key": "ai-test-198", "ner": [[6, 7, "metrics"], [8, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 8, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "is", "an", "alternative", "to", "the", "Word", "Error", "Rate", "used", "in", "several", "countries", "."], "sentence-detokenized": "It is an alternative to the Word Error Rate used in several countries.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 20], [21, 23], [24, 27], [28, 32], [33, 38], [39, 43], [44, 48], [49, 51], [52, 59], [60, 69], [69, 70]]}
{"doc_key": "ai-test-199", "ner": [[0, 1, "algorithm"], [11, 12, "task"], [14, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 27, "task"], [29, 31, "task"], [45, 45, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 0, 1, "usage", "", false, false], [14, 15, 0, 1, "usage", "", false, false], [17, 18, 0, 1, "usage", "", false, false], [20, 22, 0, 1, "usage", "", false, false], [24, 27, 0, 1, "usage", "", false, false], [29, 31, 0, 1, "usage", "", false, false], [45, 45, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["ANNs", "have", "been", "used", "for", "a", "variety", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "board", "and", "video", "games", ",", "medical", "diagnosis", "and", "even", "for", "activities", "traditionally", "thought", "to", "be", "reserved", "for", "humans", ",", "such", "as", "painting", "."], "sentence-detokenized": "ANNs have been used for a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, board and video games, medical diagnosis and even for activities traditionally thought to be reserved for humans, such as painting.", "token2charspan": [[0, 4], [5, 9], [10, 14], [15, 19], [20, 23], [24, 25], [26, 33], [34, 36], [37, 42], [42, 43], [44, 53], [54, 62], [63, 69], [69, 70], [71, 77], [78, 89], [89, 90], [91, 98], [99, 110], [110, 111], [112, 118], [119, 126], [127, 136], [136, 137], [138, 143], [144, 147], [148, 153], [154, 159], [159, 160], [161, 168], [169, 178], [179, 182], [183, 187], [188, 191], [192, 202], [203, 216], [217, 224], [225, 227], [228, 230], [231, 239], [240, 243], [244, 250], [250, 251], [252, 256], [257, 259], [260, 268], [268, 269]]}
{"doc_key": "ai-test-200", "ner": [[0, 4, "product"], [6, 8, "product"], [25, 27, "field"], [29, 29, "field"], [34, 34, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 25, 27, "related-to", "", false, false], [0, 4, 34, 34, "general-affiliation", "", false, false], [6, 8, 0, 4, "named", "", false, false], [29, 29, 25, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "is", "an", "open", "source", "research", "platform", "and", "collection", "of", "voice", ",", "audio", ",", "speech", ",", "text", "and", "natural", "language", "processing", "(", "NLP", ")", "algorithms", "written", "in", "Java", "and", "organized", "in", "a", "modular", "and", "extensible", "framework", "that", "attempts", "to", "facilitate", "the", "addition", "of", "new", "algorithms", "."], "sentence-detokenized": "The Modular Audio Recognition Framework (MARF) is an open source research platform and collection of voice, audio, speech, text and natural language processing (NLP) algorithms written in Java and organized in a modular and extensible framework that attempts to facilitate the addition of new algorithms.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 29], [30, 39], [40, 41], [41, 45], [45, 46], [47, 49], [50, 52], [53, 57], [58, 64], [65, 73], [74, 82], [83, 86], [87, 97], [98, 100], [101, 106], [106, 107], [108, 113], [113, 114], [115, 121], [121, 122], [123, 127], [128, 131], [132, 139], [140, 148], [149, 159], [160, 161], [161, 164], [164, 165], [166, 176], [177, 184], [185, 187], [188, 192], [193, 196], [197, 206], [207, 209], [210, 211], [212, 219], [220, 223], [224, 234], [235, 244], [245, 249], [250, 258], [259, 261], [262, 272], [273, 276], [277, 285], [286, 288], [289, 292], [293, 303], [303, 304]]}
{"doc_key": "ai-test-201", "ner": [[11, 13, "organisation"], [17, 17, "country"], [21, 23, "organisation"], [26, 27, "organisation"], [32, 33, "task"], [47, 50, "organisation"], [53, 54, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[21, 23, 17, 17, "physical", "", false, false], [21, 23, 32, 33, "usage", "", false, false], [21, 23, 47, 50, "named", "", false, false], [26, 27, 17, 17, "physical", "", false, false], [26, 27, 32, 33, "usage", "", false, false], [47, 50, 53, 54, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "a", "report", "by", "civil", "liberties", "and", "rights", "organisation", "Big", "Brother", "Watch", "revealed", "that", "two", "UK", "police", "forces", ",", "South", "Wales", "Police", "and", "the", "Metropolitan", "Police", ",", "were", "using", "live", "facial", "recognition", "at", "public", "events", "and", "in", "public", "spaces", ",", "and", "in", "September", "2019", ",", "South", "Wales", "Police", "'s", "use", "of", "facial", "recognition", "was", "declared", "legal", "."], "sentence-detokenized": "In 2018, a report by civil liberties and rights organisation Big Brother Watch revealed that two UK police forces, South Wales Police and the Metropolitan Police, were using live facial recognition at public events and in public spaces, and in September 2019, South Wales Police's use of facial recognition was declared legal.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 20], [21, 26], [27, 36], [37, 40], [41, 47], [48, 60], [61, 64], [65, 72], [73, 78], [79, 87], [88, 92], [93, 96], [97, 99], [100, 106], [107, 113], [113, 114], [115, 120], [121, 126], [127, 133], [134, 137], [138, 141], [142, 154], [155, 161], [161, 162], [163, 167], [168, 173], [174, 178], [179, 185], [186, 197], [198, 200], [201, 207], [208, 214], [215, 218], [219, 221], [222, 228], [229, 235], [235, 236], [237, 240], [241, 243], [244, 253], [254, 258], [258, 259], [260, 265], [266, 271], [272, 278], [278, 280], [281, 284], [285, 287], [288, 294], [295, 306], [307, 310], [311, 319], [320, 325], [325, 326]]}
{"doc_key": "ai-test-202", "ner": [[0, 0, "product"], [5, 7, "programlang"], [14, 15, "field"], [17, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 7, "general-affiliation", "", false, false], [0, 0, 14, 15, "related-to", "", false, false], [0, 0, 17, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "has", "been", "adapted", "to", "R", ",", "a", "freely", "available", "language", "and", "environment", "for", "statistical", "calculations", "and", "graphics", "."], "sentence-detokenized": "ANIMAL has been adapted to R, a freely available language and environment for statistical calculations and graphics.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 23], [24, 26], [27, 28], [28, 29], [30, 31], [32, 38], [39, 48], [49, 57], [58, 61], [62, 73], [74, 77], [78, 89], [90, 102], [103, 106], [107, 115], [115, 116]]}
{"doc_key": "ai-test-203", "ner": [[3, 10, "algorithm"], [0, 1, "algorithm"], [15, 17, "algorithm"], [13, 13, "algorithm"], [20, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 10, 15, 17, "opposite", "alternative to", false, false], [0, 1, 3, 10, "named", "", false, false], [13, 13, 15, 17, "named", "", false, false], [20, 22, 3, 10, "usage", "", false, false], [20, 22, 15, 17, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["TI", "-HBM", "(", "Time", "-inhomogeneous", "hidden", "Bernoulli", "model", ")", "is", "an", "alternative", "to", "HMM", "(", "hidden", "Markov", "model", ")", "for", "automatic", "speech", "recognition", "."], "sentence-detokenized": "TI-HBM (Time-inhomogeneous hidden Bernoulli model) is an alternative to HMM (hidden Markov model) for automatic speech recognition.", "token2charspan": [[0, 2], [2, 6], [7, 8], [8, 12], [12, 26], [27, 33], [34, 43], [44, 49], [49, 50], [51, 53], [54, 56], [57, 68], [69, 71], [72, 75], [76, 77], [77, 83], [84, 90], [91, 96], [96, 97], [98, 101], [102, 111], [112, 118], [119, 130], [130, 131]]}
{"doc_key": "ai-test-204", "ner": [[4, 4, "organisation"], [7, 7, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 7, 7, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "July", "2016", ",", "Nvidia", "demonstrated", "during", "SIGGRAPH", "a", "new", "method", "of", "foveated", "rendering", ",", "which", "is", "claimed", "to", "be", "invisible", "to", "users", "."], "sentence-detokenized": "In July 2016, Nvidia demonstrated during SIGGRAPH a new method of foveated rendering, which is claimed to be invisible to users.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 20], [21, 33], [34, 40], [41, 49], [50, 51], [52, 55], [56, 62], [63, 65], [66, 74], [75, 84], [84, 85], [86, 91], [92, 94], [95, 102], [103, 105], [106, 108], [109, 118], [119, 121], [122, 127], [127, 128]]}
{"doc_key": "ai-test-205", "ner": [[4, 6, "misc"], [10, 11, "researcher"], [18, 19, "researcher"], [21, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 10, 11, "origin", "", false, false], [4, 6, 18, 19, "origin", "", false, false], [4, 6, 21, 21, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Both", "are", "based", "on", "speech", "action", "theory", ",", "developed", "by", "John", "Searle", "in", "the", "1960s", "and", "refined", "by", "Terry", "Winograd", "and", "Flores", "in", "the", "1970s", "."], "sentence-detokenized": "Both are based on speech action theory, developed by John Searle in the 1960s and refined by Terry Winograd and Flores in the 1970s.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 17], [18, 24], [25, 31], [32, 38], [38, 39], [40, 49], [50, 52], [53, 57], [58, 64], [65, 67], [68, 71], [72, 77], [78, 81], [82, 89], [90, 92], [93, 98], [99, 107], [108, 111], [112, 118], [119, 121], [122, 125], [126, 131], [131, 132]]}
{"doc_key": "ai-test-206", "ner": [[0, 2, "algorithm"], [20, 21, "researcher"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 20, 21, "related-to", "", false, false], [23, 23, 20, 21, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Neural", "network", "models", "of", "concept", "formation", "and", "knowledge", "structure", "have", "opened", "up", "effective", "hierarchical", "models", "of", "knowledge", "organisation", "such", "as", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "Neural network models of concept formation and knowledge structure have opened up effective hierarchical models of knowledge organisation such as George Miller's Wordnet.", "token2charspan": [[0, 6], [7, 14], [15, 21], [22, 24], [25, 32], [33, 42], [43, 46], [47, 56], [57, 66], [67, 71], [72, 78], [79, 81], [82, 91], [92, 104], [105, 111], [112, 114], [115, 124], [125, 137], [138, 142], [143, 145], [146, 152], [153, 159], [159, 161], [162, 169], [169, 170]]}
{"doc_key": "ai-test-207", "ner": [[0, 1, "algorithm"], [7, 8, "field"], [11, 13, "product"], [16, 17, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 7, 8, "part-of", "", false, false], [0, 1, 16, 17, "part-of", "", false, false], [11, 13, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Template", "matching", "has", "various", "applications", ",", "including", "facial", "recognition", "(", "see", "facial", "recognition", "system", ")", "and", "medical", "imaging", "."], "sentence-detokenized": "Template matching has various applications, including facial recognition (see facial recognition system) and medical imaging.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 29], [30, 42], [42, 43], [44, 53], [54, 60], [61, 72], [73, 74], [74, 77], [78, 84], [85, 96], [97, 103], [103, 104], [105, 108], [109, 116], [117, 124], [124, 125]]}
{"doc_key": "ai-test-208", "ner": [[12, 13, "researcher"], [15, 16, "researcher"], [21, 30, "organisation"], [32, 32, "organisation"], [40, 41, "algorithm"], [43, 50, "conference"], [52, 52, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 13, 21, 30, "role", "", false, false], [12, 13, 43, 50, "physical", "", false, false], [12, 13, 43, 50, "temporal", "", false, false], [12, 13, 52, 52, "physical", "", false, false], [15, 16, 21, 30, "role", "", false, false], [15, 16, 43, 50, "temporal", "", false, false], [32, 32, 21, 30, "named", "", false, false], [43, 50, 40, 41, "topic", "", false, false], [52, 52, 43, 50, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["However", ",", "it", "s", "use", "only", "became", "widespread", "in", "2005", ",", "when", "Navneet", "Dalal", "and", "Bill", "Triggs", ",", "researchers", "from", "the", "French", "National", "Institute", "for", "Research", "in", "Computer", "Science", "and", "Automation", "(", "INRIA", ")", ",", "presented", "their", "complementary", "work", "on", "HOG", "descriptors", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "However, its use only became widespread in 2005, when Navneet Dalal and Bill Triggs, researchers from the French National Institute for Research in Computer Science and Automation (INRIA), presented their complementary work on HOG descriptors at the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 7], [7, 8], [9, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 39], [40, 42], [43, 47], [47, 48], [49, 53], [54, 61], [62, 67], [68, 71], [72, 76], [77, 83], [83, 84], [85, 96], [97, 101], [102, 105], [106, 112], [113, 121], [122, 131], [132, 135], [136, 144], [145, 147], [148, 156], [157, 164], [165, 168], [169, 179], [180, 181], [181, 186], [186, 187], [187, 188], [189, 198], [199, 204], [205, 218], [219, 223], [224, 226], [227, 230], [231, 242], [243, 245], [246, 249], [250, 260], [261, 263], [264, 272], [273, 279], [280, 283], [284, 291], [292, 303], [304, 305], [305, 309], [309, 310], [310, 311]]}
{"doc_key": "ai-test-209", "ner": [[16, 18, "organisation"], [20, 21, "organisation"], [34, 36, "researcher"], [38, 41, "researcher"], [43, 45, "researcher"], [47, 51, "organisation"], [55, 57, "organisation"], [62, 63, "researcher"]], "ner_mapping_to_source": [1, 2, 4, 5, 6, 7, 8, 9], "relations": [[34, 36, 20, 21, "physical", "", false, false], [34, 36, 20, 21, "role", "", false, false], [38, 41, 20, 21, "physical", "", false, false], [38, 41, 20, 21, "role", "", false, false], [43, 45, 20, 21, "physical", "", false, false], [43, 45, 20, 21, "role", "", false, false], [62, 63, 55, 57, "role", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "sentence": ["Before", "joining", "the", "Penn", "faculty", "in", "2002", ",", "he", "spent", "a", "decade", "(", "1991-2001", ")", "at", "AT", "&T", "Labs", "and", "Bell", "Labs", ",", "including", "as", "head", "of", "the", "AI", "department", "with", "colleagues", "such", "as", "Michael", "L.", "Littman", ",", "David", "A", ".", "McAllester", "and", "Richard", "S.", "Sutton", ",", "the", "Secure", "Systems", "Research", "Division", ",", "and", "the", "Machine", "Learning", "Division", "with", "members", "such", "as", "Michael", "Collins", "and", "the", "Head", ")", "."], "sentence-detokenized": "Before joining the Penn faculty in 2002, he spent a decade (1991-2001) at AT&T Labs and Bell Labs, including as head of the AI department with colleagues such as Michael L. Littman, David A. McAllester and Richard S. Sutton, the Secure Systems Research Division, and the Machine Learning Division with members such as Michael Collins and the Head).", "token2charspan": [[0, 6], [7, 14], [15, 18], [19, 23], [24, 31], [32, 34], [35, 39], [39, 40], [41, 43], [44, 49], [50, 51], [52, 58], [59, 60], [60, 69], [69, 70], [71, 73], [74, 76], [76, 78], [79, 83], [84, 87], [88, 92], [93, 97], [97, 98], [99, 108], [109, 111], [112, 116], [117, 119], [120, 123], [124, 126], [127, 137], [138, 142], [143, 153], [154, 158], [159, 161], [162, 169], [170, 172], [173, 180], [180, 181], [182, 187], [188, 189], [189, 190], [191, 201], [202, 205], [206, 213], [214, 216], [217, 223], [223, 224], [225, 228], [229, 235], [236, 243], [244, 252], [253, 261], [261, 262], [263, 266], [267, 270], [271, 278], [279, 287], [288, 296], [297, 301], [302, 309], [310, 314], [315, 317], [318, 325], [326, 333], [334, 337], [338, 341], [342, 346], [346, 347], [347, 348]]}
{"doc_key": "ai-test-210", "ner": [[5, 6, "field"], [13, 13, "field"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 13, 13, "compare", "", false, false], [23, 24, 13, 13, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["When", "data", "are", "unlabeled", ",", "supervised", "learning", "is", "not", "possible", ",", "and", "an", "unsupervised", "learning", "method", "is", "needed", "that", "attempts", "to", "find", "natural", "cluster", "analyses", "for", "groups", ",", "and", "then", "maps", "new", "data", "to", "these", "formed", "groups", "."], "sentence-detokenized": "When data are unlabeled, supervised learning is not possible, and an unsupervised learning method is needed that attempts to find natural cluster analyses for groups, and then maps new data to these formed groups.", "token2charspan": [[0, 4], [5, 9], [10, 13], [14, 23], [23, 24], [25, 35], [36, 44], [45, 47], [48, 51], [52, 60], [60, 61], [62, 65], [66, 68], [69, 81], [82, 90], [91, 97], [98, 100], [101, 107], [108, 112], [113, 121], [122, 124], [125, 129], [130, 137], [138, 145], [146, 154], [155, 158], [159, 165], [165, 166], [167, 170], [171, 175], [176, 180], [181, 184], [185, 189], [190, 192], [193, 198], [199, 205], [206, 212], [212, 213]]}
{"doc_key": "ai-test-211", "ner": [[3, 4, "field"], [15, 18, "organisation"], [25, 26, "field"], [28, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 15, 18, "origin", "", false, false], [3, 4, 25, 26, "part-of", "", false, false], [3, 4, 28, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "field", "of", "computer", "science", "was", "developed", "in", "the", "1950s", "at", "academic", "institutions", "like", "the", "MIT", "A.I", ".", "Lab", ",", "initially", "as", "a", "branch", "of", "artificial", "intelligence", "and", "robotics", "."], "sentence-detokenized": "This field of computer science was developed in the 1950s at academic institutions like the MIT A.I. Lab, initially as a branch of artificial intelligence and robotics.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 30], [31, 34], [35, 44], [45, 47], [48, 51], [52, 57], [58, 60], [61, 69], [70, 82], [83, 87], [88, 91], [92, 95], [96, 99], [99, 100], [101, 104], [104, 105], [106, 115], [116, 118], [119, 120], [121, 127], [128, 130], [131, 141], [142, 154], [155, 158], [159, 167], [167, 168]]}
{"doc_key": "ai-test-212", "ner": [[7, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "can", "also", "be", "replaced", "by", "the", "log", "equation", "below", ":"], "sentence-detokenized": "It can also be replaced by the log equation below:", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 23], [24, 26], [27, 30], [31, 34], [35, 43], [44, 49], [49, 50]]}
{"doc_key": "ai-test-213", "ner": [[0, 3, "organisation"], [7, 10, "organisation"], [14, 18, "university"], [20, 20, "university"], [22, 23, "university"], [26, 28, "university"], [31, 32, "country"], [35, 35, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 3, 35, 35, "related-to", "research_leader_in_field", false, false], [7, 10, 0, 3, "named", "", false, false], [7, 10, 35, 35, "related-to", "research_leader_in_field", false, false], [14, 18, 35, 35, "related-to", "research_leader_in_field", false, false], [20, 20, 35, 35, "related-to", "research_leader_in_field", false, false], [22, 23, 35, 35, "related-to", "research_leader_in_field", false, false], [26, 28, 31, 32, "physical", "", false, false], [26, 28, 35, 35, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "Shirley", "Ryan", "AbilityLab", "(", "formerly", "the", "Rehabilitation", "Institute", "of", "Chicago", ")", ",", "the", "University", "of", "California", "at", "Berkeley", ",", "MIT", ",", "Stanford", "University", "and", "the", "University", "of", "Twente", "in", "the", "Netherlands", "are", "leaders", "in", "biomechatronics", "research", "."], "sentence-detokenized": "The Shirley Ryan AbilityLab (formerly the Rehabilitation Institute of Chicago), the University of California at Berkeley, MIT, Stanford University and the University of Twente in the Netherlands are leaders in biomechatronics research.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 27], [28, 29], [29, 37], [38, 41], [42, 56], [57, 66], [67, 69], [70, 77], [77, 78], [78, 79], [80, 83], [84, 94], [95, 97], [98, 108], [109, 111], [112, 120], [120, 121], [122, 125], [125, 126], [127, 135], [136, 146], [147, 150], [151, 154], [155, 165], [166, 168], [169, 175], [176, 178], [179, 182], [183, 194], [195, 198], [199, 206], [207, 209], [210, 225], [226, 234], [234, 235]]}
{"doc_key": "ai-test-214", "ner": [[28, 31, "metrics"], [41, 42, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Given", "a", "set", "of", "predicted", "values", "and", "a", "corresponding", "set", "of", "actual", "values", "for", "X", "for", "different", "time", "periods", ",", "a", "common", "evaluation", "technique", "is", "to", "use", "the", "mean", "squared", "prediction", "error", ";", "other", "measures", "also", "exist", "(", "see", "forecasts", "#", "forecast", "accuracy", ")", "."], "sentence-detokenized": "Given a set of predicted values and a corresponding set of actual values for X for different time periods, a common evaluation technique is to use the mean squared prediction error; other measures also exist (see forecasts # forecast accuracy).", "token2charspan": [[0, 5], [6, 7], [8, 11], [12, 14], [15, 24], [25, 31], [32, 35], [36, 37], [38, 51], [52, 55], [56, 58], [59, 65], [66, 72], [73, 76], [77, 78], [79, 82], [83, 92], [93, 97], [98, 105], [105, 106], [107, 108], [109, 115], [116, 126], [127, 136], [137, 139], [140, 142], [143, 146], [147, 150], [151, 155], [156, 163], [164, 174], [175, 180], [180, 181], [182, 187], [188, 196], [197, 201], [202, 207], [208, 209], [209, 212], [213, 222], [223, 224], [225, 233], [234, 242], [242, 243], [243, 244]]}
{"doc_key": "ai-test-215", "ner": [[13, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "measures", ",", "such", "as", "the", "proportion", "of", "correct", "predictions", "(", "also", "called", "accuracy", ")", ",", "are", "not", "useful", "when", "the", "two", "classes", "are", "very", "different", "in", "size", "."], "sentence-detokenized": "Other measures, such as the proportion of correct predictions (also called accuracy), are not useful when the two classes are very different in size.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 20], [21, 23], [24, 27], [28, 38], [39, 41], [42, 49], [50, 61], [62, 63], [63, 67], [68, 74], [75, 83], [83, 84], [84, 85], [86, 89], [90, 93], [94, 100], [101, 105], [106, 109], [110, 113], [114, 121], [122, 125], [126, 130], [131, 140], [141, 143], [144, 148], [148, 149]]}
{"doc_key": "ai-test-216", "ner": [[5, 5, "product"], [15, 19, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 15, 19, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "alpha", "version", "of", "OpenCV", "was", "released", "to", "the", "public", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "in", "2000", ",", "and", "five", "beta", "versions", "were", "released", "between", "2001", "and", "2005", "."], "sentence-detokenized": "The first alpha version of OpenCV was released to the public at the Conference on Computer Vision and Pattern Recognition in 2000, and five beta versions were released between 2001 and 2005.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [24, 26], [27, 33], [34, 37], [38, 46], [47, 49], [50, 53], [54, 60], [61, 63], [64, 67], [68, 78], [79, 81], [82, 90], [91, 97], [98, 101], [102, 109], [110, 121], [122, 124], [125, 129], [129, 130], [131, 134], [135, 139], [140, 144], [145, 153], [154, 158], [159, 167], [168, 175], [176, 180], [181, 184], [185, 189], [189, 190]]}
{"doc_key": "ai-test-217", "ner": [[21, 21, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Results", "have", "been", "presented", "which", "give", "a", "correlation", "of", "up", "to", "0.964", "with", "human", "ratings", "at", "corpus", "level", "compared", "to", "the", "BLEU", "result", "of", "0.817", "on", "the", "same", "dataset", "."], "sentence-detokenized": "Results have been presented which give a correlation of up to 0.964 with human ratings at corpus level compared to the BLEU result of 0.817 on the same dataset.", "token2charspan": [[0, 7], [8, 12], [13, 17], [18, 27], [28, 33], [34, 38], [39, 40], [41, 52], [53, 55], [56, 58], [59, 61], [62, 67], [68, 72], [73, 78], [79, 86], [87, 89], [90, 96], [97, 102], [103, 111], [112, 114], [115, 118], [119, 123], [124, 130], [131, 133], [134, 139], [140, 142], [143, 146], [147, 151], [152, 159], [159, 160]]}
{"doc_key": "ai-test-218", "ner": [[4, 4, "metrics"], [18, 18, "metrics"], [20, 22, "metrics"], [24, 26, "metrics"], [36, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 18, 18, "compare", "", false, false], [4, 4, 20, 22, "compare", "", false, false], [4, 4, 24, 26, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["An", "early", "version", "of", "VMAF", "has", "been", "shown", "to", "outperform", "other", "image", "and", "video", "quality", "measures", "such", "as", "SSIM", ",", "PSNR", "-", "HVS", "and", "VQM", "-", "VFD", "on", "three", "out", "of", "four", "datasets", "in", "terms", "of", "prediction", "accuracy", "compared", "to", "subjective", "assessments", "."], "sentence-detokenized": "An early version of VMAF has been shown to outperform other image and video quality measures such as SSIM, PSNR -HVS and VQM-VFD on three out of four datasets in terms of prediction accuracy compared to subjective assessments.", "token2charspan": [[0, 2], [3, 8], [9, 16], [17, 19], [20, 24], [25, 28], [29, 33], [34, 39], [40, 42], [43, 53], [54, 59], [60, 65], [66, 69], [70, 75], [76, 83], [84, 92], [93, 97], [98, 100], [101, 105], [105, 106], [107, 111], [112, 113], [113, 116], [117, 120], [121, 124], [124, 125], [125, 128], [129, 131], [132, 137], [138, 141], [142, 144], [145, 149], [150, 158], [159, 161], [162, 167], [168, 170], [171, 181], [182, 190], [191, 199], [200, 202], [203, 213], [214, 225], [225, 226]]}
{"doc_key": "ai-test-219", "ner": [[18, 19, "task"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 25, 26, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "example", ",", "the", "ambiguity", "of", "\"", "mouse", "\"", "(", "animal", "or", "device", ")", "is", "not", "relevant", "in", "machine", "translation", ",", "but", "is", "relevant", "in", "information", "retrieval", "."], "sentence-detokenized": "For example, the ambiguity of \"mouse\" (animal or device) is not relevant in machine translation, but is relevant in information retrieval.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 26], [27, 29], [30, 31], [31, 36], [36, 37], [38, 39], [39, 45], [46, 48], [49, 55], [55, 56], [57, 59], [60, 63], [64, 72], [73, 75], [76, 83], [84, 95], [95, 96], [97, 100], [101, 103], [104, 112], [113, 115], [116, 127], [128, 137], [137, 138]]}
{"doc_key": "ai-test-220", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [9, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 1, "usage", "", false, false], [9, 10, 6, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Geometric", "hashing", "was", "originally", "proposed", "in", "computer", "vision", "for", "object", "recognition", "in", "2D", "and", "3D", ","], "sentence-detokenized": "Geometric hashing was originally proposed in computer vision for object recognition in 2D and 3D,", "token2charspan": [[0, 9], [10, 17], [18, 21], [22, 32], [33, 41], [42, 44], [45, 53], [54, 60], [61, 64], [65, 71], [72, 83], [84, 86], [87, 89], [90, 93], [94, 96], [96, 97]]}
{"doc_key": "ai-test-221", "ner": [[9, 10, "field"], [13, 14, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 14, 9, 10, "part-of", "subfield", false, false], [16, 17, 9, 10, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "is", "one", "of", "the", "three", "main", "categories", "of", "machine", "learning", "along", "with", "supervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "It is one of the three main categories of machine learning along with supervised learning and reinforcement learning.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 12], [13, 16], [17, 22], [23, 27], [28, 38], [39, 41], [42, 49], [50, 58], [59, 64], [65, 69], [70, 80], [81, 89], [90, 93], [94, 107], [108, 116], [116, 117]]}
{"doc_key": "ai-test-222", "ner": [[5, 6, "field"], [16, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 25, "field"], [27, 30, "field"], [32, 33, "field"], [35, 36, "field"], [38, 38, "field"], [41, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[5, 6, 16, 16, "part-of", "subfield", false, false], [5, 6, 18, 19, "part-of", "subfield", false, false], [5, 6, 21, 22, "part-of", "subfield", false, false], [5, 6, 24, 25, "part-of", "subfield", false, false], [5, 6, 27, 30, "part-of", "subfield", false, false], [5, 6, 32, 33, "part-of", "subfield", false, false], [5, 6, 35, 36, "part-of", "subfield", false, false], [5, 6, 38, 38, "part-of", "subfield", false, false], [5, 6, 41, 42, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Because", "of", "its", "generality", ",", "reinforcement", "learning", "is", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "games", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimization", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", ",", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Because of its generality, reinforcement learning is studied in many other disciplines, such as games, control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, statistics, and genetic algorithms.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 25], [25, 26], [27, 40], [41, 49], [50, 52], [53, 60], [61, 63], [64, 68], [69, 74], [75, 86], [86, 87], [88, 92], [93, 95], [96, 101], [101, 102], [103, 110], [111, 117], [117, 118], [119, 129], [130, 138], [138, 139], [140, 151], [152, 158], [158, 159], [160, 170], [170, 171], [171, 176], [177, 189], [189, 190], [191, 202], [203, 210], [210, 211], [212, 217], [218, 230], [230, 231], [232, 242], [242, 243], [244, 247], [248, 255], [256, 266], [266, 267]]}
{"doc_key": "ai-test-223", "ner": [[0, 2, "field"], [6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 7, "related-to", "", false, false], [0, 2, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pattern", "recognition", "is", "closely", "linked", "to", "artificial", "intelligence", "and", "machine", "learning", ","], "sentence-detokenized": "Pattern recognition is closely linked to artificial intelligence and machine learning,", "token2charspan": [[0, 7], [8, 19], [20, 22], [23, 30], [31, 37], [38, 40], [41, 51], [52, 64], [65, 68], [69, 76], [77, 85], [85, 86]]}
{"doc_key": "ai-test-224", "ner": [[10, 10, "algorithm"], [14, 15, "field"], [17, 18, "field"], [28, 29, "task"], [31, 31, "task"], [33, 34, "task"], [36, 37, "algorithm"], [39, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 10, 14, 15, "related-to", "", false, false], [10, 10, 17, 18, "related-to", "", false, false], [28, 29, 10, 10, "usage", "", true, false], [31, 31, 10, 10, "usage", "", true, false], [33, 34, 10, 10, "usage", "", true, false], [36, 37, 10, 10, "usage", "", true, false], [39, 41, 10, 10, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "software", "is", "used", "to", "design", ",", "train", "and", "implement", "neural", "network", "models", "(", "supervised", "learning", "and", "unsupervised", "learning", ")", "to", "perform", "a", "variety", "of", "tasks", "such", "as", "data", "mining", ",", "classification", ",", "function", "approximation", ",", "multivariate", "regression", "and", "time", "series", "prediction", "."], "sentence-detokenized": "The software is used to design, train and implement neural network models (supervised learning and unsupervised learning) to perform a variety of tasks such as data mining, classification, function approximation, multivariate regression and time series prediction.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 20], [21, 23], [24, 30], [30, 31], [32, 37], [38, 41], [42, 51], [52, 58], [59, 66], [67, 73], [74, 75], [75, 85], [86, 94], [95, 98], [99, 111], [112, 120], [120, 121], [122, 124], [125, 132], [133, 134], [135, 142], [143, 145], [146, 151], [152, 156], [157, 159], [160, 164], [165, 171], [171, 172], [173, 187], [187, 188], [189, 197], [198, 211], [211, 212], [213, 225], [226, 236], [237, 240], [241, 245], [246, 252], [253, 263], [263, 264]]}
{"doc_key": "ai-test-225", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2016", ",", "he", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2016, he was elected a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [98, 99]]}
{"doc_key": "ai-test-226", "ner": [[6, 9, "organisation"], [16, 21, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", "(", "since", "2005", ")", "and", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "(", "since", "2009", ")", ","], "sentence-detokenized": "She is a member of the National Academy of Sciences (since 2005) and the American Academy of Arts and Sciences (since 2009),", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 15], [16, 18], [19, 22], [23, 31], [32, 39], [40, 42], [43, 51], [52, 53], [53, 58], [59, 63], [63, 64], [65, 68], [69, 72], [73, 81], [82, 89], [90, 92], [93, 97], [98, 101], [102, 110], [111, 112], [112, 117], [118, 122], [122, 123], [123, 124]]}
{"doc_key": "ai-test-227", "ner": [[3, 5, "misc"], [16, 16, "country"], [18, 18, "country"], [23, 25, "misc"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["During", "the", "1973", "Yom", "Kippur", "War", ",", "Soviet", "surface", "-", "to", "-", "air", "missile", "batteries", "in", "Egypt", "and", "Syria", "caused", "heavy", "damage", "to", "Israeli", "fighter", "aircraft", "."], "sentence-detokenized": "During the 1973 Yom Kippur War, Soviet surface-to-air missile batteries in Egypt and Syria caused heavy damage to Israeli fighter aircraft.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 26], [27, 30], [30, 31], [32, 38], [39, 46], [46, 47], [47, 49], [49, 50], [50, 53], [54, 61], [62, 71], [72, 74], [75, 80], [81, 84], [85, 90], [91, 97], [98, 103], [104, 110], [111, 113], [114, 121], [122, 129], [130, 138], [138, 139]]}
{"doc_key": "ai-test-228", "ner": [[11, 12, "product"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 17, 11, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Another", "resource", "(", "free", ",", "but", "copyright", "protected", ")", "is", "the", "HTK", "book", "(", "and", "its", "HTK", "toolkit", ")", "."], "sentence-detokenized": "Another resource (free, but copyright protected) is the HTK book (and its HTK toolkit).", "token2charspan": [[0, 7], [8, 16], [17, 18], [18, 22], [22, 23], [24, 27], [28, 37], [38, 47], [47, 48], [49, 51], [52, 55], [56, 59], [60, 64], [65, 66], [66, 69], [70, 73], [74, 77], [78, 85], [85, 86], [86, 87]]}
{"doc_key": "ai-test-229", "ner": [[5, 8, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "was", "taken", "at", "the", "AAAI", "Spring", "Symposium", "2004", ",", "where", "linguists", ",", "computer", "scientists", "and", "other", "interested", "researchers", "aligned", "their", "interests", "for", "the", "first", "time", "and", "proposed", "joi", "nt", "tasks", "and", "benchmark", "datasets", "for", "systematic", "computer", "-", "based", "research", "on", "affect", ",", "appeal", ",", "subjectivity", "and", "emotion", "in", "text", "."], "sentence-detokenized": "- was taken at the AAAI Spring Symposium 2004, where linguists, computer scientists and other interested researchers aligned their interests for the first time and proposed joint tasks and benchmark datasets for systematic computer-based research on affect, appeal, subjectivity and emotion in text.", "token2charspan": [[0, 1], [2, 5], [6, 11], [12, 14], [15, 18], [19, 23], [24, 30], [31, 40], [41, 45], [45, 46], [47, 52], [53, 62], [62, 63], [64, 72], [73, 83], [84, 87], [88, 93], [94, 104], [105, 116], [117, 124], [125, 130], [131, 140], [141, 144], [145, 148], [149, 154], [155, 159], [160, 163], [164, 172], [173, 176], [176, 178], [179, 184], [185, 188], [189, 198], [199, 207], [208, 211], [212, 222], [223, 231], [231, 232], [232, 237], [238, 246], [247, 249], [250, 256], [256, 257], [258, 264], [264, 265], [266, 278], [279, 282], [283, 290], [291, 293], [294, 298], [298, 299]]}
{"doc_key": "ai-test-230", "ner": [[12, 13, "task"], [18, 19, "task"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "single", "grid", "can", "be", "analysed", "both", "in", "terms", "of", "content", "(", "eye", "inspection", ")", "and", "structure", "(", "cluster", "analysis", ",", "principal", "component", "analysis", "and", "a", "series", "of", "structural", "indices", "relating", "to", "the", "complexity", "and", "range", "of", "the", "assessments", "are", "the", "main", "techniques", "used", ")", "."], "sentence-detokenized": "A single grid can be analysed both in terms of content (eye inspection) and structure (cluster analysis, principal component analysis and a series of structural indices relating to the complexity and range of the assessments are the main techniques used).", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 17], [18, 20], [21, 29], [30, 34], [35, 37], [38, 43], [44, 46], [47, 54], [55, 56], [56, 59], [60, 70], [70, 71], [72, 75], [76, 85], [86, 87], [87, 94], [95, 103], [103, 104], [105, 114], [115, 124], [125, 133], [134, 137], [138, 139], [140, 146], [147, 149], [150, 160], [161, 168], [169, 177], [178, 180], [181, 184], [185, 195], [196, 199], [200, 205], [206, 208], [209, 212], [213, 224], [225, 228], [229, 232], [233, 237], [238, 248], [249, 253], [253, 254], [254, 255]]}
{"doc_key": "ai-test-231", "ner": [[3, 3, "organisation"], [12, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2018", ",", "Toyota", "was", "considered", "to", "be", "behind", "in", "terms", "of", "self", "-", "driving", "cars", "and", "in", "need", "of", "innovation", "."], "sentence-detokenized": "In 2018, Toyota was considered to be behind in terms of self-driving cars and in need of innovation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 30], [31, 33], [34, 36], [37, 43], [44, 46], [47, 52], [53, 55], [56, 60], [60, 61], [61, 68], [69, 73], [74, 77], [78, 80], [81, 85], [86, 88], [89, 99], [99, 100]]}
{"doc_key": "ai-test-232", "ner": [[37, 38, "misc"], [40, 41, "misc"], [43, 45, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "targets", "include", "natural", "objects", "such", "as", "land", ",", "sea", ",", "precipitation", "(", "e.g.", "rain", ",", "snow", "or", "hail", ")", ",", "sandstorms", ",", "animals", "(", "especially", "birds", ")", ",", "atmospheric", "turbulence", "and", "other", "atmospheric", "effects", "such", "as", "ionospheric", "reflections", ",", "meteor", "trails", "and", "tri-prop", "scattering", "tips", "."], "sentence-detokenized": "Such targets include natural objects such as land, sea, precipitation (e.g. rain, snow or hail), sandstorms, animals (especially birds), atmospheric turbulence and other atmospheric effects such as ionospheric reflections, meteor trails and tri-prop scattering tips.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 28], [29, 36], [37, 41], [42, 44], [45, 49], [49, 50], [51, 54], [54, 55], [56, 69], [70, 71], [71, 75], [76, 80], [80, 81], [82, 86], [87, 89], [90, 94], [94, 95], [95, 96], [97, 107], [107, 108], [109, 116], [117, 118], [118, 128], [129, 134], [134, 135], [135, 136], [137, 148], [149, 159], [160, 163], [164, 169], [170, 181], [182, 189], [190, 194], [195, 197], [198, 209], [210, 221], [221, 222], [223, 229], [230, 236], [237, 240], [241, 249], [250, 260], [261, 265], [265, 266]]}
{"doc_key": "ai-test-233", "ner": [[17, 18, "product"], [38, 39, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "planning", "and", "control", ",", "the", "essential", "difference", "between", "humanoids", "and", "other", "types", "of", "robots", "(", "e.g.", "industrial", "robots", ")", "is", "that", "the", "robot", "'s", "movement", "must", "be", "human", "-", "like", ",", "using", "leg", "movement", ",", "in", "particular", "bipedal", "gait", "."], "sentence-detokenized": "In planning and control, the essential difference between humanoids and other types of robots (e.g. industrial robots) is that the robot's movement must be human-like, using leg movement, in particular bipedal gait.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 23], [23, 24], [25, 28], [29, 38], [39, 49], [50, 57], [58, 67], [68, 71], [72, 77], [78, 83], [84, 86], [87, 93], [94, 95], [95, 99], [100, 110], [111, 117], [117, 118], [119, 121], [122, 126], [127, 130], [131, 136], [136, 138], [139, 147], [148, 152], [153, 155], [156, 161], [161, 162], [162, 166], [166, 167], [168, 173], [174, 177], [178, 186], [186, 187], [188, 190], [191, 201], [202, 209], [210, 214], [214, 215]]}
{"doc_key": "ai-test-234", "ner": [[0, 2, "algorithm"], [10, 11, "misc"], [15, 15, "metrics"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "gradient", "descent", "may", "take", "many", "iterations", "to", "calculate", "a", "local", "minimum", "with", "the", "necessary", "accuracy", "if", "the", "curvature", "in", "different", "directions", "is", "very", "different", "for", "the", "given", "function", "."], "sentence-detokenized": "The gradient descent may take many iterations to calculate a local minimum with the necessary accuracy if the curvature in different directions is very different for the given function.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 24], [25, 29], [30, 34], [35, 45], [46, 48], [49, 58], [59, 60], [61, 66], [67, 74], [75, 79], [80, 83], [84, 93], [94, 102], [103, 105], [106, 109], [110, 119], [120, 122], [123, 132], [133, 143], [144, 146], [147, 151], [152, 161], [162, 165], [166, 169], [170, 175], [176, 184], [184, 185]]}
{"doc_key": "ai-test-235", "ner": [[0, 7, "misc"], [17, 22, "conference"], [26, 26, "location"], [28, 28, "country"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[17, 22, 26, 26, "physical", "", false, true], [26, 26, 28, 28, "physical", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["The", "RoboCup", "2D", "Soccer", "Simulation", "League", "1997", "was", "the", "first", "RoboCup", "competition", "held", "in", "conjunction", "with", "the", "International", "Joint", "Conference", "on", "Artificial", "Intelligence", ",", "held", "in", "Nagoya", ",", "Japan", ",", "from", "23", "to", "29", "August", "1997", "."], "sentence-detokenized": "The RoboCup 2D Soccer Simulation League 1997 was the first RoboCup competition held in conjunction with the International Joint Conference on Artificial Intelligence, held in Nagoya, Japan, from 23 to 29 August 1997.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 21], [22, 32], [33, 39], [40, 44], [45, 48], [49, 52], [53, 58], [59, 66], [67, 78], [79, 83], [84, 86], [87, 98], [99, 103], [104, 107], [108, 121], [122, 127], [128, 138], [139, 141], [142, 152], [153, 165], [165, 166], [167, 171], [172, 174], [175, 181], [181, 182], [183, 188], [188, 189], [190, 194], [195, 197], [198, 200], [201, 203], [204, 210], [211, 215], [215, 216]]}
{"doc_key": "ai-test-236", "ner": [[18, 18, "product"]], "ner_mapping_to_source": [2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "options", "include", "an", "embedded", "Python", "environment", "and", "an", "R", "console", ",", "as", "well", "as", "support", "for", "Rserve", "."], "sentence-detokenized": "Other programming options include an embedded Python environment and an R console, as well as support for Rserve.", "token2charspan": [[0, 5], [6, 17], [18, 25], [26, 33], [34, 36], [37, 45], [46, 52], [53, 64], [65, 68], [69, 71], [72, 73], [74, 81], [81, 82], [83, 85], [86, 90], [91, 93], [94, 101], [102, 105], [106, 112], [112, 113]]}
{"doc_key": "ai-test-237", "ner": [[1, 1, "location"], [9, 10, "field"], [12, 12, "field"], [15, 16, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [32, 33, "field"], [37, 38, "field"], [41, 42, "field"], [46, 46, "field"], [47, 51, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[15, 16, 12, 12, "related-to", "contributes_to_field", true, false], [18, 19, 12, 12, "related-to", "contributes_to_field", true, false], [21, 22, 12, 12, "related-to", "contributes_to_field", true, false], [41, 42, 37, 38, "part-of", "", false, false], [46, 46, 41, 42, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["From", "Bonn", ",", "he", "has", "made", "significant", "contributions", "to", "artificial", "intelligence", "and", "robotics", "(", "with", "Wolfram", "Burgard", ",", "Dieter", "Fox", "and", "Sebastian", "Thrun", "among", "his", "students", ")", "and", "to", "the", "development", "of", "software", "engineering", ",", "especially", "in", "civil", "engineering", ",", "and", "information", "systems", ",", "especially", "in", "geosciences.Won", "the", "AAAI", "Classic", "Paper", "award", "in", "2016.2014", "."], "sentence-detokenized": "From Bonn, he has made significant contributions to artificial intelligence and robotics (with Wolfram Burgard, Dieter Fox and Sebastian Thrun among his students) and to the development of software engineering, especially in civil engineering, and information systems, especially in geosciences.Won the AAAI Classic Paper award in 2016.2014.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 13], [14, 17], [18, 22], [23, 34], [35, 48], [49, 51], [52, 62], [63, 75], [76, 79], [80, 88], [89, 90], [90, 94], [95, 102], [103, 110], [110, 111], [112, 118], [119, 122], [123, 126], [127, 136], [137, 142], [143, 148], [149, 152], [153, 161], [161, 162], [163, 166], [167, 169], [170, 173], [174, 185], [186, 188], [189, 197], [198, 209], [209, 210], [211, 221], [222, 224], [225, 230], [231, 242], [242, 243], [244, 247], [248, 259], [260, 267], [267, 268], [269, 279], [280, 282], [283, 298], [299, 302], [303, 307], [308, 315], [316, 321], [322, 327], [328, 330], [331, 340], [340, 341]]}
{"doc_key": "ai-test-238", "ner": [[2, 8, "conference"], [17, 18, "location"], [20, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 8, 17, 18, "physical", "", false, false], [17, 18, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "first", "US", "edition", "of", "Campus", "Party", "will", "take", "place", "from", "20", "-", "22", "August", "at", "the", "TCF", "Center", "in", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "The first US edition of Campus Party will take place from 20-22 August at the TCF Center in Detroit, Michigan.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 20], [21, 23], [24, 30], [31, 36], [37, 41], [42, 46], [47, 52], [53, 57], [58, 60], [60, 61], [61, 63], [64, 70], [71, 73], [74, 77], [78, 81], [82, 88], [89, 91], [92, 99], [99, 100], [101, 109], [109, 110]]}
{"doc_key": "ai-test-239", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [12, 13, "misc"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 12, 13, "win-defeat", "", false, false], [5, 6, 12, 13, "win-defeat", "", false, false], [8, 8, 12, 13, "win-defeat", "", false, false], [12, 13, 22, 24, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Along", "with", "Yann", "LeCun", "and", "Yoshua", "Bengio", ",", "Hinton", "won", "the", "2018", "Turing", "Award", "for", "conceptual", "and", "technical", "breakthroughs", "that", "have", "made", "deep", "neural", "networks", "a", "critical", "component", "of", "computing", "."], "sentence-detokenized": "Along with Yann LeCun and Yoshua Bengio, Hinton won the 2018 Turing Award for conceptual and technical breakthroughs that have made deep neural networks a critical component of computing.", "token2charspan": [[0, 5], [6, 10], [11, 15], [16, 21], [22, 25], [26, 32], [33, 39], [39, 40], [41, 47], [48, 51], [52, 55], [56, 60], [61, 67], [68, 73], [74, 77], [78, 88], [89, 92], [93, 102], [103, 116], [117, 121], [122, 126], [127, 131], [132, 136], [137, 143], [144, 152], [153, 154], [155, 163], [164, 173], [174, 176], [177, 186], [186, 187]]}
{"doc_key": "ai-test-240", "ner": [[0, 2, "product"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 9, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Euler", "Math", "Toolbox", "uses", "a", "matrix", "language", "similar", "to", "MATLAB", ",", "a", "system", "that", "has", "been", "under", "development", "since", "the", "1970s", "."], "sentence-detokenized": "Euler Math Toolbox uses a matrix language similar to MATLAB, a system that has been under development since the 1970s.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 23], [24, 25], [26, 32], [33, 41], [42, 49], [50, 52], [53, 59], [59, 60], [61, 62], [63, 69], [70, 74], [75, 78], [79, 83], [84, 89], [90, 101], [102, 107], [108, 111], [112, 117], [117, 118]]}
{"doc_key": "ai-test-241", "ner": [[9, 9, "programlang"], [11, 12, "programlang"], [14, 14, "programlang"], [16, 16, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "languages", "allow", "you", "to", "transfer", "it", "(", "e.g.", "Scheme", ",", "Common", "Lisp", ",", "Perl", "or", "D", ")", "."], "sentence-detokenized": "Some languages allow you to transfer it (e.g. Scheme, Common Lisp, Perl or D).", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 24], [25, 27], [28, 36], [37, 39], [40, 41], [41, 45], [46, 52], [52, 53], [54, 60], [61, 65], [65, 66], [67, 71], [72, 74], [75, 76], [76, 77], [77, 78]]}
{"doc_key": "ai-test-242", "ner": [[7, 7, "misc"], [9, 10, "researcher"], [12, 13, "researcher"], [26, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 9, 10, "artifact", "", false, false], [7, 7, 12, 13, "artifact", "", false, false], [7, 7, 26, 27, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1969", ",", "a", "famous", "book", "entitled", "Perceptrons", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "showed", "that", "it", "was", "impossible", "for", "these", "network", "classes", "to", "learn", "an", "XOR", "function", "."], "sentence-detokenized": "In 1969, a famous book entitled Perceptrons by Marvin Minsky and Seymour Papert showed that it was impossible for these network classes to learn an XOR function.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 22], [23, 31], [32, 43], [44, 46], [47, 53], [54, 60], [61, 64], [65, 72], [73, 79], [80, 86], [87, 91], [92, 94], [95, 98], [99, 109], [110, 113], [114, 119], [120, 127], [128, 135], [136, 138], [139, 144], [145, 147], [148, 151], [152, 160], [160, 161]]}
{"doc_key": "ai-test-243", "ner": [[4, 8, "misc"], [12, 12, "product"], [15, 18, "organisation"], [21, 29, "organisation"], [30, 35, "location"], [37, 37, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[15, 18, 12, 12, "usage", "", false, false], [15, 18, 30, 35, "physical", "", false, false], [21, 29, 15, 18, "named", "", false, false], [30, 35, 37, 37, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "large", "number", "of", "Russian", "scientific", "and", "technical", "documents", "were", "translated", "using", "SYSTRAN", "of", "the", "USAF", "Foreign", "Technology", "Division", "(", "later", "the", "National", "Air", "and", "Space", "Intelligence", "Center", ")", "at", "Wright", "-", "Patterson", "Air", "Force", "Base", "in", "Ohio", "."], "sentence-detokenized": "A large number of Russian scientific and technical documents were translated using SYSTRAN of the USAF Foreign Technology Division (later the National Air and Space Intelligence Center) at Wright-Patterson Air Force Base in Ohio.", "token2charspan": [[0, 1], [2, 7], [8, 14], [15, 17], [18, 25], [26, 36], [37, 40], [41, 50], [51, 60], [61, 65], [66, 76], [77, 82], [83, 90], [91, 93], [94, 97], [98, 102], [103, 110], [111, 121], [122, 130], [131, 132], [132, 137], [138, 141], [142, 150], [151, 154], [155, 158], [159, 164], [165, 177], [178, 184], [184, 185], [186, 188], [189, 195], [195, 196], [196, 205], [206, 209], [210, 215], [216, 220], [221, 223], [224, 228], [228, 229]]}
{"doc_key": "ai-test-244", "ner": [[0, 1, "field"], [4, 5, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Semi-supervised", "learning", "lies", "between", "unsupervised", "learning", "(", "without", "labelled", "training", "data", ")", "and", "supervised", "learning", "(", "with", "fully", "labelled", "training", "data", ")", "."], "sentence-detokenized": "Semi-supervised learning lies between unsupervised learning (without labelled training data) and supervised learning (with fully labelled training data).", "token2charspan": [[0, 15], [16, 24], [25, 29], [30, 37], [38, 50], [51, 59], [60, 61], [61, 68], [69, 77], [78, 86], [87, 91], [91, 92], [93, 96], [97, 107], [108, 116], [117, 118], [118, 122], [123, 128], [129, 137], [138, 146], [147, 151], [151, 152], [152, 153]]}
{"doc_key": "ai-test-245", "ner": [[0, 4, "algorithm"], [9, 12, "algorithm"], [31, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 9, 12, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Ann", "-", "gram", "model", "is", "a", "type", "of", "probabilistic", "language", "model", "for", "predicting", "the", "next", "element", "in", "such", "a", "sequence", "in", "terms", "of", "an", "(", "n", "-", "1", ")", "-order", "Markov", "model", ".effectively", "."], "sentence-detokenized": "The Ann -gram model is a type of probabilistic language model for predicting the next element in such a sequence in terms of an (n - 1)-order Markov model .effectively.", "token2charspan": [[0, 3], [4, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 24], [25, 29], [30, 32], [33, 46], [47, 55], [56, 61], [62, 65], [66, 76], [77, 80], [81, 85], [86, 93], [94, 96], [97, 101], [102, 103], [104, 112], [113, 115], [116, 121], [122, 124], [125, 127], [128, 129], [129, 130], [131, 132], [133, 134], [134, 135], [135, 141], [142, 148], [149, 154], [155, 167], [167, 168]]}
{"doc_key": "ai-test-246", "ner": [[0, 2, "organisation"], [5, 5, "product"], [9, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 5, 5, "usage", "", false, false], [9, 16, 0, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Cleveland", "Clinic", "has", "used", "Cyc", "to", "develop", "a", "natural", "language", "query", "interface", "for", "biomedical", "information", "that", "includes", "decades", "of", "information", "on", "cardiac", "and", "thoracic", "surgeries", "."], "sentence-detokenized": "The Cleveland Clinic has used Cyc to develop a natural language query interface for biomedical information that includes decades of information on cardiac and thoracic surgeries.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 24], [25, 29], [30, 33], [34, 36], [37, 44], [45, 46], [47, 54], [55, 63], [64, 69], [70, 79], [80, 83], [84, 94], [95, 106], [107, 111], [112, 120], [121, 128], [129, 131], [132, 143], [144, 146], [147, 154], [155, 158], [159, 167], [168, 177], [177, 178]]}
{"doc_key": "ai-test-247", "ner": [[5, 6, "country"], [8, 8, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 8, 8, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "incident", "strained", "relations", "between", "the", "US", "and", "Japan", ",", "resulting", "in", "the", "arrest", "and", "prosecution", "of", "two", "senior", "executives", "and", "the", "imposition", "of", "sanctions", "on", "the", "company", "by", "both", "countries", "."], "sentence-detokenized": "The incident strained relations between the US and Japan, resulting in the arrest and prosecution of two senior executives and the imposition of sanctions on the company by both countries.", "token2charspan": [[0, 3], [4, 12], [13, 21], [22, 31], [32, 39], [40, 43], [44, 46], [47, 50], [51, 56], [56, 57], [58, 67], [68, 70], [71, 74], [75, 81], [82, 85], [86, 97], [98, 100], [101, 104], [105, 111], [112, 122], [123, 126], [127, 130], [131, 141], [142, 144], [145, 154], [155, 157], [158, 161], [162, 169], [170, 172], [173, 177], [178, 187], [187, 188]]}
{"doc_key": "ai-test-248", "ner": [[7, 9, "algorithm"], [12, 13, "field"], [20, 20, "misc"], [29, 30, "misc"], [33, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 9, 12, 13, "type-of", "", false, false], [20, 20, 12, 13, "part-of", "", true, false], [29, 30, 12, 13, "part-of", "", true, false], [33, 33, 12, 13, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["If", "the", "modeling", "is", "performed", "by", "an", "artificial", "neural", "network", "or", "other", "machine", "learning", ",", "optimization", "of", "parameters", "is", "called", "training", ",", "while", "optimization", "of", "model", "hyperparameters", "is", "called", "tuning", "and", "often", "uses", "cross-validation", "."], "sentence-detokenized": "If the modeling is performed by an artificial neural network or other machine learning, optimization of parameters is called training, while optimization of model hyperparameters is called tuning and often uses cross-validation.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 18], [19, 28], [29, 31], [32, 34], [35, 45], [46, 52], [53, 60], [61, 63], [64, 69], [70, 77], [78, 86], [86, 87], [88, 100], [101, 103], [104, 114], [115, 117], [118, 124], [125, 133], [133, 134], [135, 140], [141, 153], [154, 156], [157, 162], [163, 178], [179, 181], [182, 188], [189, 195], [196, 199], [200, 205], [206, 210], [211, 227], [227, 228]]}
{"doc_key": "ai-test-249", "ner": [[7, 7, "country"], [9, 9, "country"], [11, 11, "country"], [20, 21, "organisation"], [16, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[20, 21, 16, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Localised", "versions", "of", "the", "site", "in", "the", "UK", ",", "India", "and", "Australia", "were", "shut", "down", "following", "Fandango", "'s", "acquisition", "of", "Rotten", "Tomatoes", "."], "sentence-detokenized": "Localised versions of the site in the UK, India and Australia were shut down following Fandango's acquisition of Rotten Tomatoes.", "token2charspan": [[0, 9], [10, 18], [19, 21], [22, 25], [26, 30], [31, 33], [34, 37], [38, 40], [40, 41], [42, 47], [48, 51], [52, 61], [62, 66], [67, 71], [72, 76], [77, 86], [87, 95], [95, 97], [98, 109], [110, 112], [113, 119], [120, 128], [128, 129]]}
{"doc_key": "ai-test-250", "ner": [[13, 14, "metrics"], [24, 25, "task"]], "ner_mapping_to_source": [1, 2], "relations": [[13, 14, 24, 25, "related-to", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["The", "NER", "model", "is", "one", "of", "a", "number", "of", "methods", "to", "determine", "the", "accuracy", "of", "live", "subtitles", "in", "TV", "broadcasts", "and", "events", "produced", "using", "speech", "recognition", "."], "sentence-detokenized": "The NER model is one of a number of methods to determine the accuracy of live subtitles in TV broadcasts and events produced using speech recognition.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 20], [21, 23], [24, 25], [26, 32], [33, 35], [36, 43], [44, 46], [47, 56], [57, 60], [61, 69], [70, 72], [73, 77], [78, 87], [88, 90], [91, 93], [94, 104], [105, 108], [109, 115], [116, 124], [125, 130], [131, 137], [138, 149], [149, 150]]}
{"doc_key": "ai-test-251", "ner": [[0, 0, "researcher"], [4, 5, "university"], [7, 8, "university"], [10, 10, "location"], [12, 16, "university"], [18, 19, "university"], [21, 21, "location"], [24, 29, "university"], [31, 33, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 5, "physical", "", false, false], [0, 0, 4, 5, "role", "", false, false], [0, 0, 7, 8, "physical", "", false, false], [0, 0, 7, 8, "role", "", false, false], [0, 0, 12, 16, "physical", "", false, false], [0, 0, 12, 16, "role", "", false, false], [0, 0, 18, 19, "physical", "", false, false], [0, 0, 18, 19, "role", "", false, false], [0, 0, 24, 29, "physical", "", false, false], [0, 0, 24, 29, "role", "", false, false], [7, 8, 10, 10, "physical", "", false, false], [12, 16, 21, 21, "physical", "", false, false], [18, 19, 21, 21, "physical", "", false, false], [24, 29, 31, 33, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Atran", "has", "taught", "at", "Cambridge", "University", ",", "Hebrew", "University", "in", "Jerusalem", ",", "\u00c9cole", "pratique", "des", "hautes", "\u00e9tudes", "and", "\u00c9cole", "Polytechnique", "in", "Paris", ",", "and", "John", "Jay", "College", "of", "Criminal", "Justice", "in", "New", "York", "City", "."], "sentence-detokenized": "Atran has taught at Cambridge University, Hebrew University in Jerusalem, \u00c9cole pratique des hautes \u00e9tudes and \u00c9cole Polytechnique in Paris, and John Jay College of Criminal Justice in New York City.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 40], [40, 41], [42, 48], [49, 59], [60, 62], [63, 72], [72, 73], [74, 79], [80, 88], [89, 92], [93, 99], [100, 106], [107, 110], [111, 116], [117, 130], [131, 133], [134, 139], [139, 140], [141, 144], [145, 149], [150, 153], [154, 161], [162, 164], [165, 173], [174, 181], [182, 184], [185, 188], [189, 193], [194, 198], [198, 199]]}
{"doc_key": "ai-test-252", "ner": [[0, 0, "product"], [7, 9, "task"], [13, 14, "researcher"], [16, 16, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 9, "origin", "", false, false], [0, 0, 7, 9, "related-to", "", false, false], [7, 9, 16, 16, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "was", "an", "early", "computer", "program", "for", "natural", "language", "understanding", ",", "developed", "by", "Terry", "Winograd", "at", "MIT", "in", "1968", "-", "1970", "."], "sentence-detokenized": "SHRDLU was an early computer program for natural language understanding, developed by Terry Winograd at MIT in 1968-1970.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 19], [20, 28], [29, 36], [37, 40], [41, 48], [49, 57], [58, 71], [71, 72], [73, 82], [83, 85], [86, 91], [92, 100], [101, 103], [104, 107], [108, 110], [111, 115], [115, 116], [116, 120], [120, 121]]}
{"doc_key": "ai-test-253", "ner": [[3, 3, "misc"], [5, 6, "field"], [9, 13, "university"], [15, 15, "location"], [17, 17, "country"], [26, 27, "university"], [30, 30, "misc"], [32, 35, "field"], [39, 41, "university"], [43, 43, "misc"], [45, 47, "field"], [51, 52, "misc"], [56, 60, "university"], [65, 66, "field"], [70, 71, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[3, 3, 5, 6, "topic", "", false, false], [3, 3, 9, 13, "origin", "", false, false], [9, 13, 15, 15, "physical", "", false, false], [9, 13, 26, 27, "role", "affiliated_with", false, false], [15, 15, 17, 17, "physical", "", false, false], [30, 30, 32, 35, "topic", "", false, false], [30, 30, 39, 41, "origin", "", false, false], [43, 43, 45, 47, "topic", "", false, false], [51, 52, 56, 60, "origin", "", false, false], [51, 52, 65, 66, "topic", "", false, false], [70, 71, 56, 60, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["He", "received", "a", "B.E.", "in", "electronic", "engineering", "from", "the", "B.M.S", ".", "College", "of", "Engineering", "in", "Bangalore", ",", "India", ",", "in", "1982", "when", "it", "was", "affiliated", "with", "Bangalore", "University", ",", "an", "M.S.", "in", "electrical", "and", "computer", "engineering", "in", "1984", "from", "Drexel", "University", "and", "an", "M.S.", "in", "computer", "science", "in", "1989", "and", "a", "Ph.D.", "in", "1990", "from", "the", "University", "of", "Wisconsin", "-", "Madison", ",", "where", "he", "studied", "artificial", "intelligence", "and", "worked", "with", "Leonard", "Uhr", "."], "sentence-detokenized": "He received a B.E. in electronic engineering from the B.M.S. College of Engineering in Bangalore, India, in 1982 when it was affiliated with Bangalore University, an M.S. in electrical and computer engineering in 1984 from Drexel University and an M.S. in computer science in 1989 and a Ph.D. in 1990 from the University of Wisconsin-Madison, where he studied artificial intelligence and worked with Leonard Uhr.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 18], [19, 21], [22, 32], [33, 44], [45, 49], [50, 53], [54, 59], [59, 60], [61, 68], [69, 71], [72, 83], [84, 86], [87, 96], [96, 97], [98, 103], [103, 104], [105, 107], [108, 112], [113, 117], [118, 120], [121, 124], [125, 135], [136, 140], [141, 150], [151, 161], [161, 162], [163, 165], [166, 170], [171, 173], [174, 184], [185, 188], [189, 197], [198, 209], [210, 212], [213, 217], [218, 222], [223, 229], [230, 240], [241, 244], [245, 247], [248, 252], [253, 255], [256, 264], [265, 272], [273, 275], [276, 280], [281, 284], [285, 286], [287, 292], [293, 295], [296, 300], [301, 305], [306, 309], [310, 320], [321, 323], [324, 333], [333, 334], [334, 341], [341, 342], [343, 348], [349, 351], [352, 359], [360, 370], [371, 383], [384, 387], [388, 394], [395, 399], [400, 407], [408, 411], [411, 412]]}
{"doc_key": "ai-test-254", "ner": [[6, 8, "metrics"], [10, 10, "metrics"], [19, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Accuracy", "is", "usually", "assessed", "using", "the", "word", "error", "rate", "(", "WER", ")", ",", "while", "speed", "is", "measured", "using", "the", "real", "-", "time", "factor", "."], "sentence-detokenized": "Accuracy is usually assessed using the word error rate (WER), while speed is measured using the real-time factor.", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 28], [29, 34], [35, 38], [39, 43], [44, 49], [50, 54], [55, 56], [56, 59], [59, 60], [60, 61], [62, 67], [68, 73], [74, 76], [77, 85], [86, 91], [92, 95], [96, 100], [100, 101], [101, 105], [106, 112], [112, 113]]}
{"doc_key": "ai-test-255", "ner": [[3, 4, "researcher"], [8, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 8, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1971", ",", "Terry", "Winograd", "developed", "an", "early", "natural", "language", "processing", "engine", "that", "could", "interpret", "naturally", "written", "commands", "in", "a", "simple", "rule", "-", "driven", "environment", "."], "sentence-detokenized": "In 1971, Terry Winograd developed an early natural language processing engine that could interpret naturally written commands in a simple rule-driven environment.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 33], [34, 36], [37, 42], [43, 50], [51, 59], [60, 70], [71, 77], [78, 82], [83, 88], [89, 98], [99, 108], [109, 116], [117, 125], [126, 128], [129, 130], [131, 137], [138, 142], [142, 143], [143, 149], [150, 161], [161, 162]]}
{"doc_key": "ai-test-256", "ner": [[4, 5, "field"], [7, 8, "researcher"], [10, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 7, 8, "related-to", "", false, false], [4, 5, 10, 13, "related-to", "", false, false], [4, 5, 15, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "field", "of", "artificial", "intelligence", ",", "Marvin", "Minsky", ",", "Herbert", "A", ".", "Simon", "and", "Allen", "Newell", "are", "prominent", "."], "sentence-detokenized": "In the field of artificial intelligence, Marvin Minsky, Herbert A. Simon and Allen Newell are prominent.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 26], [27, 39], [39, 40], [41, 47], [48, 54], [54, 55], [56, 63], [64, 65], [65, 66], [67, 72], [73, 76], [77, 82], [83, 89], [90, 93], [94, 103], [103, 104]]}
{"doc_key": "ai-test-257", "ner": [[9, 10, "field"], [32, 32, "field"], [34, 37, "field"], [38, 39, "field"], [48, 51, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[32, 32, 9, 10, "origin", "", true, false], [32, 32, 9, 10, "part-of", "", false, false], [32, 32, 38, 39, "compare", "", false, false], [34, 37, 9, 10, "origin", "", true, false], [34, 37, 9, 10, "part-of", "", false, false], [34, 37, 38, 39, "compare", "", false, false], [38, 39, 9, 10, "origin", "", true, false], [38, 39, 9, 10, "part-of", "", false, false], [38, 39, 48, 51, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "the", "latter", "half", "of", "the", "20th", "century", ",", "electrical", "engineering", "itself", "was", "divided", "into", "several", "disciplines", "specialising", "in", "the", "design", "and", "analysis", "of", "systems", "that", "manipulate", "physical", "signals", ",", "such", "as", "electronics", "and", "computer", "engineering", ",", "while", "design", "engineering", "evolved", "to", "deal", "with", "the", "functional", "design", "of", "user", "-", "machine", "interfaces", "."], "sentence-detokenized": "In the latter half of the 20th century, electrical engineering itself was divided into several disciplines specialising in the design and analysis of systems that manipulate physical signals, such as electronics and computer engineering, while design engineering evolved to deal with the functional design of user-machine interfaces.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 21], [22, 25], [26, 30], [31, 38], [38, 39], [40, 50], [51, 62], [63, 69], [70, 73], [74, 81], [82, 86], [87, 94], [95, 106], [107, 119], [120, 122], [123, 126], [127, 133], [134, 137], [138, 146], [147, 149], [150, 157], [158, 162], [163, 173], [174, 182], [183, 190], [190, 191], [192, 196], [197, 199], [200, 211], [212, 215], [216, 224], [225, 236], [236, 237], [238, 243], [244, 250], [251, 262], [263, 270], [271, 273], [274, 278], [279, 283], [284, 287], [288, 298], [299, 305], [306, 308], [309, 313], [313, 314], [314, 321], [322, 332], [332, 333]]}
{"doc_key": "ai-test-258", "ner": [[5, 5, "metrics"], [7, 8, "metrics"], [10, 10, "metrics"], [46, 48, "metrics"], [55, 57, "metrics"], [61, 67, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 10, 7, 8, "named", "", false, false], [46, 48, 55, 57, "named", "", false, false], [55, 57, 61, 67, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Perhaps", "the", "simplest", "statistic", "is", "accuracy", "or", "Fraction", "Correct", "(", "FC", ")", ",", "which", "measures", "the", "proportion", "of", "all", "cases", "that", "are", "correctly", "categorized", ";", "it", "is", "the", "ratio", "of", "the", "number", "of", "correct", "classifications", "to", "the", "total", "number", "of", "correct", "or", "incorrect", "classifications", ":", "(", "TP", "+", "TN", ")", "/", "Total", "Population", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "Perhaps the simplest statistic is accuracy or Fraction Correct (FC), which measures the proportion of all cases that are correctly categorized; it is the ratio of the number of correct classifications to the total number of correct or incorrect classifications: (TP + TN) / Total Population = (TP + TN) / (TP + TN + FP + FN).", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 30], [31, 33], [34, 42], [43, 45], [46, 54], [55, 62], [63, 64], [64, 66], [66, 67], [67, 68], [69, 74], [75, 83], [84, 87], [88, 98], [99, 101], [102, 105], [106, 111], [112, 116], [117, 120], [121, 130], [131, 142], [142, 143], [144, 146], [147, 149], [150, 153], [154, 159], [160, 162], [163, 166], [167, 173], [174, 176], [177, 184], [185, 200], [201, 203], [204, 207], [208, 213], [214, 220], [221, 223], [224, 231], [232, 234], [235, 244], [245, 260], [260, 261], [262, 263], [263, 265], [266, 267], [268, 270], [270, 271], [272, 273], [274, 279], [280, 290], [291, 292], [293, 294], [294, 296], [297, 298], [299, 301], [301, 302], [303, 304], [305, 306], [306, 308], [309, 310], [311, 313], [314, 315], [316, 318], [319, 320], [321, 323], [323, 324], [324, 325]]}
{"doc_key": "ai-test-259", "ner": [[16, 24, "conference"], [26, 31, "conference"], [33, 33, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 24, 33, 33, "physical", "", false, false], [26, 31, 16, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "the", "academic", "community", ",", "the", "main", "forums", "for", "research", "started", "in", "1995", ",", "when", "the", "first", "International", "Conference", "on", "Data", "Mining", "and", "Knowledge", "Discovery", "(", "KDD", "-", "95", ")", "was", "held", "in", "Montreal", "under", "AAAI", "sponsorship", "."], "sentence-detokenized": "In the academic community, the main forums for research started in 1995, when the first International Conference on Data Mining and Knowledge Discovery (KDD-95) was held in Montreal under AAAI sponsorship.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 25], [25, 26], [27, 30], [31, 35], [36, 42], [43, 46], [47, 55], [56, 63], [64, 66], [67, 71], [71, 72], [73, 77], [78, 81], [82, 87], [88, 101], [102, 112], [113, 115], [116, 120], [121, 127], [128, 131], [132, 141], [142, 151], [152, 153], [153, 156], [156, 157], [157, 159], [159, 160], [161, 164], [165, 169], [170, 172], [173, 181], [182, 187], [188, 192], [193, 204], [204, 205]]}
{"doc_key": "ai-test-260", "ner": [[9, 10, "field"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "this", "approach", ",", "models", "are", "developed", "using", "various", "data", "mining", "and", "machine", "learning", "algorithms", "to", "predict", "users", "'", "valuation", "of", "unvalued", "goods", "."], "sentence-detokenized": "In this approach, models are developed using various data mining and machine learning algorithms to predict users' valuation of unvalued goods.", "token2charspan": [[0, 2], [3, 7], [8, 16], [16, 17], [18, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 57], [58, 64], [65, 68], [69, 76], [77, 85], [86, 96], [97, 99], [100, 107], [108, 113], [113, 114], [115, 124], [125, 127], [128, 136], [137, 142], [142, 143]]}
{"doc_key": "ai-test-261", "ner": [[16, 17, "algorithm"], [19, 20, "algorithm"], [24, 25, "misc"], [31, 32, "metrics"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[16, 17, 19, 20, "usage", "", false, false], [19, 20, 31, 32, "usage", "", false, false], [31, 32, 24, 25, "type-of", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["In", "light", "of", "the", "above", "discussion", ",", "we", "can", "see", "that", "the", "SVM", "technique", "corresponds", "to", "empirical", "risk", "with", "Tikhonov", "regularization", ",", "where", "the", "loss", "function", "in", "this", "case", "is", "a", "hinge", "loss"], "sentence-detokenized": "In light of the above discussion, we can see that the SVM technique corresponds to empirical risk with Tikhonov regularization, where the loss function in this case is a hinge loss", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 15], [16, 21], [22, 32], [32, 33], [34, 36], [37, 40], [41, 44], [45, 49], [50, 53], [54, 57], [58, 67], [68, 79], [80, 82], [83, 92], [93, 97], [98, 102], [103, 111], [112, 126], [126, 127], [128, 133], [134, 137], [138, 142], [143, 151], [152, 154], [155, 159], [160, 164], [165, 167], [168, 169], [170, 175], [176, 180]]}
{"doc_key": "ai-test-262", "ner": [[6, 7, "person"], [9, 11, "person"], [15, 16, "person"]], "ner_mapping_to_source": [0, 1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "2015", "edition", "was", "presented", "by", "Molly", "McGrath", "with", "Chris", "Rose", "and", "former", "UFC", "fighter", "Kenny", "Florian", "as", "commentators", "."], "sentence-detokenized": "The 2015 edition was presented by Molly McGrath with Chris Rose and former UFC fighter Kenny Florian as commentators.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 30], [31, 33], [34, 39], [40, 47], [48, 52], [53, 58], [59, 63], [64, 67], [68, 74], [75, 78], [79, 86], [87, 92], [93, 100], [101, 103], [104, 116], [116, 117]]}
{"doc_key": "ai-test-263", "ner": [[3, 5, "product"], [9, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [18, 18, "researcher"], [21, 21, "researcher"], [33, 33, "product"], [35, 37, "researcher"], [40, 41, "task"], [43, 45, "researcher"], [48, 49, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 8, 9, 10, 11, 12], "relations": [[3, 5, 9, 11, "origin", "", false, false], [3, 5, 13, 14, "origin", "", false, false], [3, 5, 16, 17, "origin", "", false, false], [3, 5, 18, 18, "origin", "", false, false], [13, 14, 35, 37, "named", "same", false, false], [16, 17, 21, 21, "named", "same", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["A", "subset", "called", "Micro", "-", "Planner", "was", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "Sussman", ",", "and", "Winograd", "1971", "and", "was", "used", "in", "Winograd", "'s", "natural", "language", "understanding", "program", "SHRDLU", ",", "Eugene", "Charniak", "'s", "work", "on", "history", "comprehension", ",", "Thorne", "McCarty", "'s", "work", "on", "legal", "reasoning", "and", "some", "other", "projects", "."], "sentence-detokenized": "A subset called Micro-Planner was implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd Sussman, and Winograd 1971 and was used in Winograd's natural language understanding program SHRDLU, Eugene Charniak's work on history comprehension, Thorne McCarty's work on legal reasoning and some other projects.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [21, 22], [22, 29], [30, 33], [34, 45], [46, 48], [49, 55], [56, 59], [60, 67], [67, 68], [69, 75], [76, 84], [85, 88], [89, 94], [95, 103], [104, 111], [111, 112], [113, 116], [117, 125], [126, 130], [131, 134], [135, 138], [139, 143], [144, 146], [147, 155], [155, 157], [158, 165], [166, 174], [175, 188], [189, 196], [197, 203], [203, 204], [205, 211], [212, 220], [220, 222], [223, 227], [228, 230], [231, 238], [239, 252], [252, 253], [254, 260], [261, 268], [268, 270], [271, 275], [276, 278], [279, 284], [285, 294], [295, 298], [299, 303], [304, 309], [310, 318], [318, 319]]}
{"doc_key": "ai-test-264", "ner": [[0, 1, "product"], [11, 12, "product"], [15, 17, "task"], [19, 20, "task"], [22, 24, "task"], [26, 27, "task"], [29, 30, "task"], [33, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 0, 1, "usage", "", true, false], [15, 17, 11, 12, "part-of", "", true, false], [19, 20, 11, 12, "part-of", "", true, false], [22, 24, 11, 12, "part-of", "", true, false], [26, 27, 11, 12, "part-of", "", true, false], [29, 30, 11, 12, "part-of", "", true, false], [33, 35, 11, 12, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Word", "Net", "has", "been", "used", "for", "a", "number", "of", "purposes", "in", "information", "systems", ",", "including", "word", "sense", "disambiguation", ",", "information", "retrieval", ",", "automatic", "text", "classification", ",", "automatic", "summarization", ",", "machine", "translation", "and", "even", "automatic", "crossword", "generation", "."], "sentence-detokenized": "WordNet has been used for a number of purposes in information systems, including word sense disambiguation, information retrieval, automatic text classification, automatic summarization, machine translation and even automatic crossword generation.", "token2charspan": [[0, 4], [4, 7], [8, 11], [12, 16], [17, 21], [22, 25], [26, 27], [28, 34], [35, 37], [38, 46], [47, 49], [50, 61], [62, 69], [69, 70], [71, 80], [81, 85], [86, 91], [92, 106], [106, 107], [108, 119], [120, 129], [129, 130], [131, 140], [141, 145], [146, 160], [160, 161], [162, 171], [172, 185], [185, 186], [187, 194], [195, 206], [207, 210], [211, 215], [216, 225], [226, 235], [236, 246], [246, 247]]}
{"doc_key": "ai-test-265", "ner": [[0, 1, "researcher"], [7, 7, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 7, 7, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Keutzer", "was", "named", "a", "Fellow", "of", "the", "IEEE", "in", "1996", "."], "sentence-detokenized": "Keutzer was named a Fellow of the IEEE in 1996.", "token2charspan": [[0, 7], [8, 11], [12, 17], [18, 19], [20, 26], [27, 29], [30, 33], [34, 38], [39, 41], [42, 46], [46, 47]]}
{"doc_key": "ai-test-266", "ner": [[8, 10, "algorithm"], [55, 56, "misc"], [64, 65, "algorithm"], [67, 68, "algorithm"], [70, 71, "algorithm"], [73, 74, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[64, 65, 55, 56, "type-of", "", false, false], [67, 68, 55, 56, "type-of", "", false, false], [70, 71, 55, 56, "type-of", "", false, false], [73, 74, 55, 56, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "widely", "used", "type", "of", "composition", "is", "the", "non-linear", "weighted", "sum", ",", "where", "math", "\\", "textstyle", "f", "(", "x", ")", "=", "K", "\\", "left", "(", "\\", "sum", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "\\", "right", ")", "/", "math", ",", "where", "math", "\\", "textstyle", "K", "/", "math", "(", "commonly", "called", "the", "activation", "function", ")", "is", "a", "predefined", "function", ",", "e.g.", "hyperbolic", "tangent", ",", "sigmoid", "function", ",", "softmax", "function", "or", "rectifier", "function", "."], "sentence-detokenized": "A widely used type of composition is the non-linear weighted sum, where math\\ textstyle f (x) = K\\ left (\\ sum _ i w _ i g _ i (x)\\ right) / math, where math\\ textstyle K / math (commonly called the activation function) is a predefined function, e.g. hyperbolic tangent, sigmoid function, softmax function or rectifier function.", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 18], [19, 21], [22, 33], [34, 36], [37, 40], [41, 51], [52, 60], [61, 64], [64, 65], [66, 71], [72, 76], [76, 77], [78, 87], [88, 89], [90, 91], [91, 92], [92, 93], [94, 95], [96, 97], [97, 98], [99, 103], [104, 105], [105, 106], [107, 110], [111, 112], [113, 114], [115, 116], [117, 118], [119, 120], [121, 122], [123, 124], [125, 126], [127, 128], [128, 129], [129, 130], [130, 131], [132, 137], [137, 138], [139, 140], [141, 145], [145, 146], [147, 152], [153, 157], [157, 158], [159, 168], [169, 170], [171, 172], [173, 177], [178, 179], [179, 187], [188, 194], [195, 198], [199, 209], [210, 218], [218, 219], [220, 222], [223, 224], [225, 235], [236, 244], [244, 245], [246, 250], [251, 261], [262, 269], [269, 270], [271, 278], [279, 287], [287, 288], [289, 296], [297, 305], [306, 308], [309, 318], [319, 327], [327, 328]]}
{"doc_key": "ai-test-267", "ner": [[3, 3, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "movie", "Westworld", ",", "female", "robots", "actually", "had", "intercourse", "with", "human", "men", "as", "part", "of", "the", "fantasy", "holiday", "world", "that", "human", "customers", "paid", "to", "participate", "in", "."], "sentence-detokenized": "In the movie Westworld, female robots actually had intercourse with human men as part of the fantasy holiday world that human customers paid to participate in.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [22, 23], [24, 30], [31, 37], [38, 46], [47, 50], [51, 62], [63, 67], [68, 73], [74, 77], [78, 80], [81, 85], [86, 88], [89, 92], [93, 100], [101, 108], [109, 114], [115, 119], [120, 125], [126, 135], [136, 140], [141, 143], [144, 155], [156, 158], [158, 159]]}
{"doc_key": "ai-test-268", "ner": [[6, 7, "task"], [21, 26, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 21, 26, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Typically", ",", "the", "process", "starts", "with", "extracting", "terminology", "and", "concepts", "or", "noun", "phrases", "from", "plain", "text", "using", "linguistic", "processors", "such", "as", "part", "-", "of", "-", "speech", "tagging", "and", "phrase", "chunking", "."], "sentence-detokenized": "Typically, the process starts with extracting terminology and concepts or noun phrases from plain text using linguistic processors such as part-of-speech tagging and phrase chunking.", "token2charspan": [[0, 9], [9, 10], [11, 14], [15, 22], [23, 29], [30, 34], [35, 45], [46, 57], [58, 61], [62, 70], [71, 73], [74, 78], [79, 86], [87, 91], [92, 97], [98, 102], [103, 108], [109, 119], [120, 130], [131, 135], [136, 138], [139, 143], [143, 144], [144, 146], [146, 147], [147, 153], [154, 161], [162, 165], [166, 172], [173, 181], [181, 182]]}
{"doc_key": "ai-test-269", "ner": [[18, 19, "task"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "demonstrated", "its", "performance", "on", "a", "number", "of", "problems", "of", "interest", "to", "the", "machine", "learning", "community", ",", "including", "handwriting", "recognition", "."], "sentence-detokenized": "They demonstrated its performance on a number of problems of interest to the machine learning community, including handwriting recognition.", "token2charspan": [[0, 4], [5, 17], [18, 21], [22, 33], [34, 36], [37, 38], [39, 45], [46, 48], [49, 57], [58, 60], [61, 69], [70, 72], [73, 76], [77, 84], [85, 93], [94, 103], [103, 104], [105, 114], [115, 126], [127, 138], [138, 139]]}
{"doc_key": "ai-test-270", "ner": [[2, 2, "university"], [4, 4, "researcher"], [10, 13, "researcher"], [16, 18, "product"], [20, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 2, 2, "physical", "", false, false], [4, 4, 2, 2, "role", "", false, false], [16, 18, 10, 13, "origin", "", false, false], [16, 18, 20, 21, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "at", "Stanford", ",", "Scheinman", "received", "a", "scholarship", "sponsored", "by", "George", "Devol", ",", "the", "inventor", "of", "Unimate", ",", "the", "first", "industrial", "robot", "."], "sentence-detokenized": "While at Stanford, Scheinman received a scholarship sponsored by George Devol, the inventor of Unimate, the first industrial robot.", "token2charspan": [[0, 5], [6, 8], [9, 17], [17, 18], [19, 28], [29, 37], [38, 39], [40, 51], [52, 61], [62, 64], [65, 71], [72, 77], [77, 78], [79, 82], [83, 91], [92, 94], [95, 102], [102, 103], [104, 107], [108, 113], [114, 124], [125, 130], [130, 131]]}
{"doc_key": "ai-test-271", "ner": [[5, 6, "task"], [9, 15, "metrics"], [13, 13, "metrics"], [22, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 9, 15, "usage", "", true, false], [13, 13, 9, 15, "named", "", false, false], [22, 24, 9, 15, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Although", "originally", "used", "to", "evaluate", "machine", "translations", ",", "the", "Bilingual", "Evaluation", "Understudy", "(", "BLEU", ")", "has", "also", "been", "used", "successfully", "to", "evaluate", "paraphrase", "generation", "models", "."], "sentence-detokenized": "Although originally used to evaluate machine translations, the Bilingual Evaluation Understudy (BLEU) has also been used successfully to evaluate paraphrase generation models.", "token2charspan": [[0, 8], [9, 19], [20, 24], [25, 27], [28, 36], [37, 44], [45, 57], [57, 58], [59, 62], [63, 72], [73, 83], [84, 94], [95, 96], [96, 100], [100, 101], [102, 105], [106, 110], [111, 115], [116, 120], [121, 133], [134, 136], [137, 145], [146, 156], [157, 167], [168, 174], [174, 175]]}
{"doc_key": "ai-test-272", "ner": [[0, 0, "organisation"], [6, 8, "organisation"], [10, 10, "organisation"], [14, 14, "product"], [16, 16, "country"], [19, 19, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 8, "role", "licenses_to", false, false], [0, 0, 10, 10, "role", "licenses_to", false, false], [6, 8, 16, 16, "physical", "", false, false], [10, 10, 19, 19, "physical", "", false, false], [14, 14, 6, 8, "artifact", "produces", false, false], [14, 14, 10, 10, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "later", "licensed", "its", "technology", "to", "Kawasaki", "Heavy", "Industries", "and", "GKN", ",", "which", "manufactured", "Unimates", "in", "Japan", "and", "the", "UK", "respectively", "."], "sentence-detokenized": "Unimation later licensed its technology to Kawasaki Heavy Industries and GKN, which manufactured Unimates in Japan and the UK respectively.", "token2charspan": [[0, 9], [10, 15], [16, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 57], [58, 68], [69, 72], [73, 76], [76, 77], [78, 83], [84, 96], [97, 105], [106, 108], [109, 114], [115, 118], [119, 122], [123, 125], [126, 138], [138, 139]]}
{"doc_key": "ai-test-273", "ner": [[18, 19, "conference"], [36, 37, "field"], [55, 59, "field"], [61, 64, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[36, 37, 55, 59, "compare", "", false, false], [61, 64, 55, 59, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Much", "of", "the", "confusion", "between", "these", "two", "research", "communities", "(", "which", "often", "have", "separate", "conferences", "and", "journals", ",", "ECML", "PKDD", "being", "a", "major", "exception", ")", "is", "due", "to", "the", "basic", "assumptions", "they", "work", "from", ":", "in", "machine", "learning", ",", "performance", "is", "usually", "assessed", "in", "terms", "of", "the", "ability", "to", "reproduce", "known", "knowledge", ",", "whereas", "in", "knowledge", "discovery", "and", "data", "mining", "(", "KDD", ")", ",", "the", "main", "task", "is", "to", "discover", "previously", "unknown", "knowledge", "."], "sentence-detokenized": "Much of the confusion between these two research communities (which often have separate conferences and journals, ECML PKDD being a major exception) is due to the basic assumptions they work from: in machine learning, performance is usually assessed in terms of the ability to reproduce known knowledge, whereas in knowledge discovery and data mining (KDD), the main task is to discover previously unknown knowledge.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 29], [30, 35], [36, 39], [40, 48], [49, 60], [61, 62], [62, 67], [68, 73], [74, 78], [79, 87], [88, 99], [100, 103], [104, 112], [112, 113], [114, 118], [119, 123], [124, 129], [130, 131], [132, 137], [138, 147], [147, 148], [149, 151], [152, 155], [156, 158], [159, 162], [163, 168], [169, 180], [181, 185], [186, 190], [191, 195], [195, 196], [197, 199], [200, 207], [208, 216], [216, 217], [218, 229], [230, 232], [233, 240], [241, 249], [250, 252], [253, 258], [259, 261], [262, 265], [266, 273], [274, 276], [277, 286], [287, 292], [293, 302], [302, 303], [304, 311], [312, 314], [315, 324], [325, 334], [335, 338], [339, 343], [344, 350], [351, 352], [352, 355], [355, 356], [356, 357], [358, 361], [362, 366], [367, 371], [372, 374], [375, 377], [378, 386], [387, 397], [398, 405], [406, 415], [415, 416]]}
{"doc_key": "ai-test-274", "ner": [[0, 0, "algorithm"], [9, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 9, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Hidden", "Markov", "models", "are", "the", "basis", "of", "most", "modern", "automatic", "speech", "recognition", "systems", "."], "sentence-detokenized": "Hidden Markov models are the basis of most modern automatic speech recognition systems.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 28], [29, 34], [35, 37], [38, 42], [43, 49], [50, 59], [60, 66], [67, 78], [79, 86], [86, 87]]}
{"doc_key": "ai-test-275", "ner": [[4, 4, "location"], [6, 8, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 6, 8, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": [",", "a", "company", "in", "Bangalore", ",", "India", ",", "that", "specializes", "in", "online", "handwriting", "recognition", "software", "."], "sentence-detokenized": ", a company in Bangalore, India, that specializes in online handwriting recognition software.", "token2charspan": [[0, 1], [2, 3], [4, 11], [12, 14], [15, 24], [24, 25], [26, 31], [31, 32], [33, 37], [38, 49], [50, 52], [53, 59], [60, 71], [72, 83], [84, 92], [92, 93]]}
{"doc_key": "ai-test-276", "ner": [[24, 25, "misc"], [51, 53, "metrics"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Do", "repeated", "translations", "converge", "to", "a", "single", "term", "in", "both", "languages", "?", "I.e.", "does", "the", "translation", "method", "show", "stationarity", "or", "does", "it", "produce", "a", "canonical", "form", "?", "Does", "the", "translation", "become", "stationary", "without", "losing", "the", "original", "meaning", "?", "This", "metric", "has", "been", "criticised", "for", "not", "correlating", "well", "with", "the", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "score", "."], "sentence-detokenized": "Do repeated translations converge to a single term in both languages? I.e. does the translation method show stationarity or does it produce a canonical form? Does the translation become stationary without losing the original meaning? This metric has been criticised for not correlating well with the BLEU (BiLingual Evaluation Understudy) score.", "token2charspan": [[0, 2], [3, 11], [12, 24], [25, 33], [34, 36], [37, 38], [39, 45], [46, 50], [51, 53], [54, 58], [59, 68], [68, 69], [70, 74], [75, 79], [80, 83], [84, 95], [96, 102], [103, 107], [108, 120], [121, 123], [124, 128], [129, 131], [132, 139], [140, 141], [142, 151], [152, 156], [156, 157], [158, 162], [163, 166], [167, 178], [179, 185], [186, 196], [197, 204], [205, 211], [212, 215], [216, 224], [225, 232], [232, 233], [234, 238], [239, 245], [246, 249], [250, 254], [255, 265], [266, 269], [270, 273], [274, 285], [286, 290], [291, 295], [296, 299], [300, 304], [305, 306], [306, 315], [316, 326], [327, 337], [337, 338], [339, 344], [344, 345]]}
{"doc_key": "ai-test-277", "ner": [[6, 10, "organisation"], [13, 20, "organisation"], [22, 23, "university"], [26, 26, "university"], [29, 30, "field"], [33, 37, "organisation"], [40, 44, "organisation"], [50, 53, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[13, 20, 22, 23, "part-of", "", false, false], [26, 26, 29, 30, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "is", "a", "member", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", ",", "the", "Center", "for", "Advanced", "Study", "in", "the", "Behavioral", "Sciences", "at", "Stanford", "University", ",", "the", "MIT", "Center", "for", "Cognitive", "Science", ",", "the", "Canadian", "Institute", "for", "Advanced", "Research", ",", "the", "Canadian", "Psychological", "Association", "and", "was", "elected", "a", "Fellow", "of", "the", "Royal", "Society", "of", "Canada", "in", "1998", "."], "sentence-detokenized": "He is a member of the American Association for Artificial Intelligence, the Center for Advanced Study in the Behavioral Sciences at Stanford University, the MIT Center for Cognitive Science, the Canadian Institute for Advanced Research, the Canadian Psychological Association and was elected a Fellow of the Royal Society of Canada in 1998.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 42], [43, 46], [47, 57], [58, 70], [70, 71], [72, 75], [76, 82], [83, 86], [87, 95], [96, 101], [102, 104], [105, 108], [109, 119], [120, 128], [129, 131], [132, 140], [141, 151], [151, 152], [153, 156], [157, 160], [161, 167], [168, 171], [172, 181], [182, 189], [189, 190], [191, 194], [195, 203], [204, 213], [214, 217], [218, 226], [227, 235], [235, 236], [237, 240], [241, 249], [250, 263], [264, 275], [276, 279], [280, 283], [284, 291], [292, 293], [294, 300], [301, 303], [304, 307], [308, 313], [314, 321], [322, 324], [325, 331], [332, 334], [335, 339], [339, 340]]}
{"doc_key": "ai-test-278", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [17, 19, "misc"], [22, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 17, 19, "part-of", "", false, false], [0, 0, 22, 25, "part-of", "", false, false], [4, 5, 17, 19, "part-of", "", false, false], [4, 5, 22, 25, "part-of", "", false, false], [7, 8, 17, 19, "part-of", "", false, false], [7, 8, 22, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", "-", "along", "with", "Yoshua", "Bengio", "and", "Yann", "LeCun", "-", "is", "referred", "to", "by", "some", "as", "the", "godfathers", "of", "AI", "and", "the", "godfathers", "of", "Deep", "Learning", "."], "sentence-detokenized": "Hinton - along with Yoshua Bengio and Yann LeCun - is referred to by some as the godfathers of AI and the godfathers of Deep Learning.", "token2charspan": [[0, 6], [7, 8], [9, 14], [15, 19], [20, 26], [27, 33], [34, 37], [38, 42], [43, 48], [49, 50], [51, 53], [54, 62], [63, 65], [66, 68], [69, 73], [74, 76], [77, 80], [81, 91], [92, 94], [95, 97], [98, 101], [102, 105], [106, 116], [117, 119], [120, 124], [125, 133], [133, 134]]}
{"doc_key": "ai-test-279", "ner": [[6, 6, "product"], [20, 20, "misc"], [22, 23, "misc"], [24, 25, "product"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 20, 20, "related-to", "", false, false], [6, 6, 22, 23, "related-to", "", false, false], [20, 20, 24, 25, "named", "same", false, false], [28, 29, 24, 25, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "lightweight", "open", "source", "speech", "project", "eSpeak", ",", "which", "has", "its", "own", "approach", "to", "synthesis", ",", "has", "been", "experimenting", "with", "Mandarin", "and", "Cantonese", ".", "eSpeak", "was", "used", "by", "Google", "Translate", "from", "May", "2010", "to", "2010", "."], "sentence-detokenized": "The lightweight open source speech project eSpeak, which has its own approach to synthesis, has been experimenting with Mandarin and Cantonese. eSpeak was used by Google Translate from May 2010 to 2010.", "token2charspan": [[0, 3], [4, 15], [16, 20], [21, 27], [28, 34], [35, 42], [43, 49], [49, 50], [51, 56], [57, 60], [61, 64], [65, 68], [69, 77], [78, 80], [81, 90], [90, 91], [92, 95], [96, 100], [101, 114], [115, 119], [120, 128], [129, 132], [133, 142], [142, 143], [144, 150], [151, 154], [155, 159], [160, 162], [163, 169], [170, 179], [180, 184], [185, 188], [189, 193], [194, 196], [197, 201], [201, 202]]}
{"doc_key": "ai-test-280", "ner": [[0, 3, "product"], [13, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 13, 16, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Software", "Automatic", "Mouth", "was", "also", "released", "in", "1982", "and", "was", "the", "first", "commercial", "voice", "synthesis", "program", "that", "was", "entirely", "software", "."], "sentence-detokenized": "Software Automatic Mouth was also released in 1982 and was the first commercial voice synthesis program that was entirely software.", "token2charspan": [[0, 8], [9, 18], [19, 24], [25, 28], [29, 33], [34, 42], [43, 45], [46, 50], [51, 54], [55, 58], [59, 62], [63, 68], [69, 79], [80, 85], [86, 95], [96, 103], [104, 108], [109, 112], [113, 121], [122, 130], [130, 131]]}
{"doc_key": "ai-test-281", "ner": [[5, 7, "metrics"], [9, 9, "metrics"], [13, 13, "metrics"], [15, 15, "metrics"], [18, 24, "metrics"], [29, 31, "metrics"], [33, 33, "metrics"], [36, 42, "metrics"], [46, 48, "metrics"], [50, 50, "metrics"], [54, 54, "metrics"], [56, 56, "metrics"], [59, 66, "metrics"], [70, 72, "metrics"], [74, 74, "metrics"], [77, 83, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[9, 9, 5, 7, "named", "", false, false], [13, 13, 5, 7, "named", "", false, false], [15, 15, 5, 7, "named", "", false, false], [18, 24, 5, 7, "named", "", false, false], [33, 33, 29, 31, "named", "", false, false], [36, 42, 29, 31, "named", "", false, false], [50, 50, 46, 48, "named", "", false, false], [54, 54, 46, 48, "named", "", false, false], [56, 56, 46, 48, "named", "", false, false], [59, 66, 46, 48, "named", "", false, false], [74, 74, 70, 72, "named", "", false, false], [77, 83, 70, 72, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["The", "column", "ratios", "are", ":", "true", "positive", "rate", "(", "TPR", ",", "also", "called", "sensitivity", "or", "recall", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "with", "complement", "FALSE", "negative", "rate", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ",", "and", "true", "negative", "rate", "(", "TNR", ",", "also", "called", "specificity", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", ",", "with", "complement", "FALSE", "positive", "rate", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "The column ratios are: true positive rate (TPR, also called sensitivity or recall) (TP/(TP+FN)), with complement FALSE negative rate (FNR) (FN/(TP+FN)), and true negative rate (TNR, also called specificity, SPC) (TN/(TN+FP)), with complement FALSE positive rate (FPR) (FP/(TN+FP)).", "token2charspan": [[0, 3], [4, 10], [11, 17], [18, 21], [21, 22], [23, 27], [28, 36], [37, 41], [42, 43], [43, 46], [46, 47], [48, 52], [53, 59], [60, 71], [72, 74], [75, 81], [81, 82], [83, 84], [84, 86], [86, 87], [87, 88], [88, 90], [90, 91], [91, 93], [93, 94], [94, 95], [95, 96], [97, 101], [102, 112], [113, 118], [119, 127], [128, 132], [133, 134], [134, 137], [137, 138], [139, 140], [140, 142], [142, 143], [143, 144], [144, 146], [146, 147], [147, 149], [149, 150], [150, 151], [151, 152], [153, 156], [157, 161], [162, 170], [171, 175], [176, 177], [177, 180], [180, 181], [182, 186], [187, 193], [194, 205], [205, 206], [207, 210], [210, 211], [212, 213], [213, 215], [215, 216], [216, 217], [217, 219], [219, 220], [220, 222], [222, 223], [223, 224], [224, 225], [226, 230], [231, 241], [242, 247], [248, 256], [257, 261], [262, 263], [263, 266], [266, 267], [268, 269], [269, 271], [271, 272], [272, 273], [273, 275], [275, 276], [276, 278], [278, 279], [279, 280], [280, 281]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 2, "person"], [14, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 14, 14, "role", "working_with", false, false], [2, 2, 14, 14, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "and", "Weber", "also", "collaborated", "on", "many", "other", "robots", ",", "and", "their", "experience", "with", "Kismet"], "sentence-detokenized": "Edsinger and Weber also collaborated on many other robots, and their experience with Kismet", "token2charspan": [[0, 8], [9, 12], [13, 18], [19, 23], [24, 36], [37, 39], [40, 44], [45, 50], [51, 57], [57, 58], [59, 62], [63, 68], [69, 79], [80, 84], [85, 91]]}
{"doc_key": "ai-test-283", "ner": [[11, 11, "programlang"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["R", "functions", "are", "also", "available", "from", "several", "scripting", "languages", "such", "as", "Python", "."], "sentence-detokenized": "R functions are also available from several scripting languages such as Python.", "token2charspan": [[0, 1], [2, 11], [12, 15], [16, 20], [21, 30], [31, 35], [36, 43], [44, 53], [54, 63], [64, 68], [69, 71], [72, 78], [78, 79]]}
{"doc_key": "ai-test-284", "ner": [[0, 0, "programlang"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "was", "one", "of", "the", "first", "robot", "languages", "and", "was", "used", "in", "Unimate", "robots", "."], "sentence-detokenized": "VAL was one of the first robot languages and was used in Unimate robots.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 18], [19, 24], [25, 30], [31, 40], [41, 44], [45, 48], [49, 53], [54, 56], [57, 64], [65, 71], [71, 72]]}
{"doc_key": "ai-test-285", "ner": [[13, 20, "conference"], [22, 22, "conference"], [25, 25, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 20, 25, 25, "physical", "", false, false], [22, 22, 13, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["They", "presented", "their", "database", "for", "the", "first", "time", "as", "a", "poster", "at", "the", "2009", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "in", "Florida", "."], "sentence-detokenized": "They presented their database for the first time as a poster at the 2009 Conference on Computer Vision and Pattern Recognition (CVPR) in Florida.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 29], [30, 33], [34, 37], [38, 43], [44, 48], [49, 51], [52, 53], [54, 60], [61, 63], [64, 67], [68, 72], [73, 83], [84, 86], [87, 95], [96, 102], [103, 106], [107, 114], [115, 126], [127, 128], [128, 132], [132, 133], [134, 136], [137, 144], [144, 145]]}
{"doc_key": "ai-test-286", "ner": [[0, 2, "misc"], [9, 10, "task"], [12, 13, "field"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 0, 2, "type-of", "", false, false], [12, 13, 0, 2, "type-of", "", false, false], [15, 16, 0, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Categorisation", "tasks", "where", "no", "labels", "are", "provided", "are", "called", "unsupervised", "classification", ",", "unsupervised", "learning", "and", "cluster", "analysis", "."], "sentence-detokenized": "Categorisation tasks where no labels are provided are called unsupervised classification, unsupervised learning and cluster analysis.", "token2charspan": [[0, 14], [15, 20], [21, 26], [27, 29], [30, 36], [37, 40], [41, 49], [50, 53], [54, 60], [61, 73], [74, 88], [88, 89], [90, 102], [103, 111], [112, 115], [116, 123], [124, 132], [132, 133]]}
{"doc_key": "ai-test-287", "ner": [[5, 6, "task"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "must", "be", "able", "to", "recognise", "objects", ",", "recognise", "and", "locate", "people", "and", "further", "recognise", "emotions", "."], "sentence-detokenized": "It must be able to recognise objects, recognise and locate people and further recognise emotions.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 15], [16, 18], [19, 28], [29, 36], [36, 37], [38, 47], [48, 51], [52, 58], [59, 65], [66, 69], [70, 77], [78, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-test-288", "ner": [[6, 6, "misc"], [8, 8, "misc"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "process", "is", "complex", "and", "involves", "encoding", "and", "recall", "or", "retrieval", "."], "sentence-detokenized": "The process is complex and involves encoding and recall or retrieval.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 26], [27, 35], [36, 44], [45, 48], [49, 55], [56, 58], [59, 68], [68, 69]]}
{"doc_key": "ai-test-289", "ner": [[10, 11, "product"], [15, 16, "product"], [30, 30, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 15, 16, "named", "", false, false], [10, 11, 30, 30, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "also", "known", "as", "parallel", "robots", "or", "generalised", "Stewart", "platforms", "(", "in", "the", "Stewart", "platform", "the", "actuators", "are", "paired", "together", "on", "both", "base", "and", "platform", ")", ",", "are", "articulated", "robots", "that", "use", "similar", "mechanisms", "to", "move", "either", "the", "robot", "on", "its", "base", "or", "one", "or", "more", "manipulator", "arms", "."], "sentence-detokenized": "These systems, also known as parallel robots or generalised Stewart platforms (in the Stewart platform the actuators are paired together on both base and platform), are articulated robots that use similar mechanisms to move either the robot on its base or one or more manipulator arms.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 25], [26, 28], [29, 37], [38, 44], [45, 47], [48, 59], [60, 67], [68, 77], [78, 79], [79, 81], [82, 85], [86, 93], [94, 102], [103, 106], [107, 116], [117, 120], [121, 127], [128, 136], [137, 139], [140, 144], [145, 149], [150, 153], [154, 162], [162, 163], [163, 164], [165, 168], [169, 180], [181, 187], [188, 192], [193, 196], [197, 204], [205, 215], [216, 218], [219, 223], [224, 230], [231, 234], [235, 240], [241, 243], [244, 247], [248, 252], [253, 255], [256, 259], [260, 262], [263, 267], [268, 279], [280, 284], [284, 285]]}
{"doc_key": "ai-test-290", "ner": [[0, 1, "field"], [4, 5, "field"], [14, 18, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 5, "part-of", "subfield", false, false], [0, 1, 14, 18, "compare", "", false, false], [14, 18, 22, 23, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "vision", "as", "a", "systems", "engineering", "discipline", "can", "be", "considered", "as", "being", "different", "from", "computer", "vision", ",", "which", "is", "a", "form", "of", "computer", "science", "."], "sentence-detokenized": "Machine vision as a systems engineering discipline can be considered as being different from computer vision, which is a form of computer science.", "token2charspan": [[0, 7], [8, 14], [15, 17], [18, 19], [20, 27], [28, 39], [40, 50], [51, 54], [55, 57], [58, 68], [69, 71], [72, 77], [78, 87], [88, 92], [93, 101], [102, 108], [108, 109], [110, 115], [116, 118], [119, 120], [121, 125], [126, 128], [129, 137], [138, 145], [145, 146]]}
{"doc_key": "ai-test-291", "ner": [[4, 5, "algorithm"], [9, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 9, 11, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "activation", "function", "for", "LSTM", "gates", "is", "often", "the", "logistic", "sigmoid", "function", "."], "sentence-detokenized": "The activation function for LSTM gates is often the logistic sigmoid function.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 27], [28, 32], [33, 38], [39, 41], [42, 47], [48, 51], [52, 60], [61, 68], [69, 77], [77, 78]]}
{"doc_key": "ai-test-292", "ner": [[5, 6, "metrics"], [19, 22, "metrics"], [24, 27, "metrics"], [32, 34, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 19, 22, "named", "", false, false], [5, 6, 32, 34, "named", "", false, false], [24, 27, 19, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "other", "words", ",", "the", "sample", "mean", "is", "the", "(", "necessarily", "unique", ")", "efficient", "estimator", "and", "thus", "also", "the", "unbiased", "minimum", "variance", "estimator", "(", "MVUE", ")", ",", "in", "addition", "to", "being", "the", "maximum", "likelihood", "estimator", "."], "sentence-detokenized": "In other words, the sample mean is the (necessarily unique) efficient estimator and thus also the unbiased minimum variance estimator (MVUE), in addition to being the maximum likelihood estimator.", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 19], [20, 26], [27, 31], [32, 34], [35, 38], [39, 40], [40, 51], [52, 58], [58, 59], [60, 69], [70, 79], [80, 83], [84, 88], [89, 93], [94, 97], [98, 106], [107, 114], [115, 123], [124, 133], [134, 135], [135, 139], [139, 140], [140, 141], [142, 144], [145, 153], [154, 156], [157, 162], [163, 166], [167, 174], [175, 185], [186, 195], [195, 196]]}
{"doc_key": "ai-test-293", "ner": [[3, 4, "academicjournal"], [7, 19, "researcher"], [11, 23, "researcher"], [14, 25, "researcher"], [33, 33, "product"], [36, 37, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 33, 33, "topic", "", false, false], [3, 4, 36, 37, "topic", "", false, false], [7, 19, 3, 4, "role", "", false, false], [11, 23, 3, 4, "role", "", false, false], [14, 25, 3, 4, "role", "", false, false], [33, 33, 36, 37, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "the", "2001", "Scientific", "American", "article", "by", "Berners", "-", "Lee", ",", "James", "Hendler", "and", "Ora", "Lassila", ",", "Berners", "-", "Lee", ",", "James", "Hendler", "and", "Ora", "Lassila", "described", "an", "expected", "evolution", "of", "the", "existing", "web", "into", "a", "semantic", "web", "."], "sentence-detokenized": "In the 2001 Scientific American article by Berners-Lee, James Hendler and Ora Lassila, Berners-Lee, James Hendler and Ora Lassila described an expected evolution of the existing web into a semantic web.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 22], [23, 31], [32, 39], [40, 42], [43, 50], [50, 51], [51, 54], [54, 55], [56, 61], [62, 69], [70, 73], [74, 77], [78, 85], [85, 86], [87, 94], [94, 95], [95, 98], [98, 99], [100, 105], [106, 113], [114, 117], [118, 121], [122, 129], [130, 139], [140, 142], [143, 151], [152, 161], [162, 164], [165, 168], [169, 177], [178, 181], [182, 186], [187, 188], [189, 197], [198, 201], [201, 202]]}
{"doc_key": "ai-test-294", "ner": [[0, 1, "misc"], [14, 15, "person"], [17, 17, "person"], [26, 26, "person"], [40, 40, "person"], [46, 47, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 15, 0, 1, "role", "actor_in_work", false, false], [17, 17, 14, 15, "named", "", false, false], [17, 17, 14, 15, "origin", "", false, false], [26, 26, 17, 17, "part-of", "", false, false], [46, 47, 17, 17, "role", "auditioned_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Blade", "Runner", "used", "a", "number", "of", "lesser", "-", "known", "actors", "from", "that", "era", ":", "Sean", "Young", "plays", "Rachael", ",", "an", "experimental", "replicant", "who", "is", "implanted", "with", "Tyrell", "'s", "niece", "'s", "memories", ",", "causing", "her", "to", "believe", "she", "is", "human", ";", "Sammon", ",", "pp.", "92", "-", "93", "Nina", "Axelrod", "auditioned", "for", "the", "role", "."], "sentence-detokenized": "Blade Runner used a number of lesser-known actors from that era: Sean Young plays Rachael, an experimental replicant who is implanted with Tyrell's niece's memories, causing her to believe she is human; Sammon, pp. 92-93 Nina Axelrod auditioned for the role.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 19], [20, 26], [27, 29], [30, 36], [36, 37], [37, 42], [43, 49], [50, 54], [55, 59], [60, 63], [63, 64], [65, 69], [70, 75], [76, 81], [82, 89], [89, 90], [91, 93], [94, 106], [107, 116], [117, 120], [121, 123], [124, 133], [134, 138], [139, 145], [145, 147], [148, 153], [153, 155], [156, 164], [164, 165], [166, 173], [174, 177], [178, 180], [181, 188], [189, 192], [193, 195], [196, 201], [201, 202], [203, 209], [209, 210], [211, 214], [215, 217], [217, 218], [218, 220], [221, 225], [226, 233], [234, 244], [245, 248], [249, 252], [253, 257], [257, 258]]}
{"doc_key": "ai-test-295", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [13, 15, "university"], [24, 26, "product"], [28, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 13, 15, "physical", "", false, false], [3, 4, 13, 15, "physical", "", false, false], [6, 7, 13, 15, "physical", "", false, false], [9, 10, 13, 15, "physical", "", false, false], [24, 26, 13, 15, "temporal", "", false, false], [28, 28, 13, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6], "sentence": ["Gerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "and", "Terry", "Winograd", "visited", "the", "University", "of", "Edinburgh", "in", "1971", "to", "spread", "the", "news", "of", "the", "Micro", "-", "Planner", "and", "SHRDLU", "and", "cast", "doubt", "on", "the", "approach", "to", "uniform", "proof", "procedure", "which", "had", "been", "the", "mainstay", "of", "the", "Edinburgh", "logicians", "."], "sentence-detokenized": "Gerry Sussman, Eugene Charniak, Seymour Papert and Terry Winograd visited the University of Edinburgh in 1971 to spread the news of the Micro-Planner and SHRDLU and cast doubt on the approach to uniform proof procedure which had been the mainstay of the Edinburgh logicians.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 21], [22, 30], [30, 31], [32, 39], [40, 46], [47, 50], [51, 56], [57, 65], [66, 73], [74, 77], [78, 88], [89, 91], [92, 101], [102, 104], [105, 109], [110, 112], [113, 119], [120, 123], [124, 128], [129, 131], [132, 135], [136, 141], [141, 142], [142, 149], [150, 153], [154, 160], [161, 164], [165, 169], [170, 175], [176, 178], [179, 182], [183, 191], [192, 194], [195, 202], [203, 208], [209, 218], [219, 224], [225, 228], [229, 233], [234, 237], [238, 246], [247, 249], [250, 253], [254, 263], [264, 273], [273, 274]]}
{"doc_key": "ai-test-296", "ner": [[0, 1, "researcher"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[0, 1, 12, 13, "role", "inspires", false, false], [0, 1, 15, 16, "role", "inspires", false, false], [0, 1, 18, 19, "role", "inspires", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Walter", "'s", "work", "has", "inspired", "subsequent", "generations", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "Walter's work has inspired subsequent generations of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 6], [6, 8], [9, 13], [14, 17], [18, 26], [27, 37], [38, 49], [50, 52], [53, 61], [62, 73], [74, 78], [79, 81], [82, 88], [89, 95], [95, 96], [97, 101], [102, 109], [110, 113], [114, 118], [119, 125], [125, 126]]}
{"doc_key": "ai-test-297", "ner": [[7, 27, "algorithm"], [9, 10, "researcher"], [14, 22, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 27, 9, 10, "origin", "", false, false], [7, 27, 14, 22, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Subsequently", ",", "a", "similar", "GPU", "-", "based", "CNN", "by", "Alex", "Krizhevsky", "et", "al", ".", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "2012", "with", "a", "similar", "GPU", "-", "based", "CNN", "."], "sentence-detokenized": "Subsequently, a similar GPU-based CNN by Alex Krizhevsky et al. ImageNet Large Scale Visual Recognition Challenge 2012 with a similar GPU-based CNN.", "token2charspan": [[0, 12], [12, 13], [14, 15], [16, 23], [24, 27], [27, 28], [28, 33], [34, 37], [38, 40], [41, 45], [46, 56], [57, 59], [60, 62], [62, 63], [64, 72], [73, 78], [79, 84], [85, 91], [92, 103], [104, 113], [114, 118], [119, 123], [124, 125], [126, 133], [134, 137], [137, 138], [138, 143], [144, 147], [147, 148]]}
{"doc_key": "ai-test-298", "ner": [[2, 3, "misc"], [8, 9, "metrics"], [11, 12, "metrics"], [18, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 2, 3, "type-of", "", false, false], [11, 12, 2, 3, "type-of", "", false, false], [11, 12, 18, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Commonly", "used", "loss", "functions", "for", "probabilistic", "classification", "include", "log", "loss", "and", "Brier", "score", "between", "the", "predicted", "and", "the", "TRUE", "probability", "distribution", "."], "sentence-detokenized": "Commonly used loss functions for probabilistic classification include log loss and Brier score between the predicted and the TRUE probability distribution.", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 28], [29, 32], [33, 46], [47, 61], [62, 69], [70, 73], [74, 78], [79, 82], [83, 88], [89, 94], [95, 102], [103, 106], [107, 116], [117, 120], [121, 124], [125, 129], [130, 141], [142, 154], [154, 155]]}
{"doc_key": "ai-test-299", "ner": [[4, 4, "organisation"], [13, 13, "field"], [8, 8, "organisation"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 13, 13, "general-affiliation", "field_of_study", false, false], [4, 4, 18, 19, "part-of", "", false, false], [8, 8, 4, 4, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "May", "2016", ",", "NtechLab", "was", "included", "in", "NIST", "'s", "official", "test", "of", "biometric", "technology", "among", "the", "three", "Russian", "companies", "."], "sentence-detokenized": "In May 2016, NtechLab was included in NIST's official test of biometric technology among the three Russian companies.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [13, 21], [22, 25], [26, 34], [35, 37], [38, 42], [42, 44], [45, 53], [54, 58], [59, 61], [62, 71], [72, 82], [83, 88], [89, 92], [93, 98], [99, 106], [107, 116], [116, 117]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Voluntary", "numbers", ",", "however", ",", "have", "only", "a", "certain", "mathematical", "precision", "."], "sentence-detokenized": "Voluntary numbers, however, have only a certain mathematical precision.", "token2charspan": [[0, 9], [10, 17], [17, 18], [19, 26], [26, 27], [28, 32], [33, 37], [38, 39], [40, 47], [48, 60], [61, 70], [70, 71]]}
{"doc_key": "ai-test-301", "ner": [[5, 5, "organisation"], [12, 18, "conference"], [20, 20, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 12, 18, "role", "contributes_to", false, false], [20, 20, 12, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "2015", ",", "many", "of", "SenseTime", "'s", "papers", "were", "accepted", "to", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "During 2015, many of SenseTime's papers were accepted to the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 6], [7, 11], [11, 12], [13, 17], [18, 20], [21, 30], [30, 32], [33, 39], [40, 44], [45, 53], [54, 56], [57, 60], [61, 71], [72, 74], [75, 83], [84, 90], [91, 94], [95, 102], [103, 114], [115, 116], [116, 120], [120, 121], [121, 122]]}
{"doc_key": "ai-test-302", "ner": [[6, 8, "task"], [10, 10, "task"], [12, 13, "task"], [15, 18, "task"], [21, 21, "field"], [23, 25, "misc"], [27, 33, "conference"], [41, 43, "misc"], [45, 49, "conference"], [63, 65, "misc"], [67, 67, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[6, 8, 21, 21, "part-of", "task_part_of_field", false, false], [10, 10, 6, 8, "named", "", false, false], [12, 13, 21, 21, "part-of", "task_part_of_field", false, false], [15, 18, 12, 13, "named", "", false, false], [23, 25, 27, 33, "temporal", "", false, false], [41, 43, 45, 49, "temporal", "", false, false], [63, 65, 67, 67, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["He", "helped", "develop", "optimal", "algorithms", "for", "Structure", "From", "Motion", "(", "SFM", "or", "Visual", "SLAM", ",", "simultaneous", "localization", "and", "mapping", ",", "in", "Robotics", ";", "Best", "Paper", "Award", "at", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "1998", ")", ",", "characterized", "its", "ambiguities", "(", "David", "Marr", "Prize", "at", "ICCV", "1999", ")", ",", "and", "also", "characterized", "the", "identifiability", "and", "observability", "of", "visual", "-", "inertial", "sensor", "fusion", "(", "Best", "Paper", "Award", "at", "Robotics", "2015", ")", "."], "sentence-detokenized": "He helped develop optimal algorithms for Structure From Motion (SFM or Visual SLAM, simultaneous localization and mapping, in Robotics; Best Paper Award at Conference on Computer Vision and Pattern Recognition 1998), characterized its ambiguities (David Marr Prize at ICCV 1999), and also characterized the identifiability and observability of visual-inertial sensor fusion (Best Paper Award at Robotics 2015).", "token2charspan": [[0, 2], [3, 9], [10, 17], [18, 25], [26, 36], [37, 40], [41, 50], [51, 55], [56, 62], [63, 64], [64, 67], [68, 70], [71, 77], [78, 82], [82, 83], [84, 96], [97, 109], [110, 113], [114, 121], [121, 122], [123, 125], [126, 134], [134, 135], [136, 140], [141, 146], [147, 152], [153, 155], [156, 166], [167, 169], [170, 178], [179, 185], [186, 189], [190, 197], [198, 209], [210, 214], [214, 215], [215, 216], [217, 230], [231, 234], [235, 246], [247, 248], [248, 253], [254, 258], [259, 264], [265, 267], [268, 272], [273, 277], [277, 278], [278, 279], [280, 283], [284, 288], [289, 302], [303, 306], [307, 322], [323, 326], [327, 340], [341, 343], [344, 350], [350, 351], [351, 359], [360, 366], [367, 373], [374, 375], [375, 379], [380, 385], [386, 391], [392, 394], [395, 403], [404, 408], [408, 409], [409, 410]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 44], [45, 48], [49, 52], [53, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-304", "ner": [[0, 3, "task"], [7, 8, "field"], [10, 11, "field"], [13, 14, "field"], [21, 24, "task"], [25, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 7, 8, "part-of", "task_part_of_field", false, false], [0, 3, 10, 11, "part-of", "task_part_of_field", false, false], [0, 3, 13, 14, "part-of", "task_part_of_field", false, false], [0, 3, 21, 24, "part-of", "", false, false], [0, 3, 25, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Edge", "detection", "is", "a", "fundamental", "tool", "in", "image", "processing", ",", "machine", "vision", "and", "computer", "vision", ",", "especially", "in", "the", "areas", "of", "feature", "detection", "and", "feature", "extraction", "."], "sentence-detokenized": "Edge detection is a fundamental tool in image processing, machine vision and computer vision, especially in the areas of feature detection and feature extraction.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 19], [20, 31], [32, 36], [37, 39], [40, 45], [46, 56], [56, 57], [58, 65], [66, 72], [73, 76], [77, 85], [86, 92], [92, 93], [94, 104], [105, 107], [108, 111], [112, 117], [118, 120], [121, 128], [129, 138], [139, 142], [143, 150], [151, 161], [161, 162]]}
{"doc_key": "ai-test-305", "ner": [[9, 10, "misc"], [27, 28, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "example", "of", "this", "is", "a", "variable", "such", "as", "outdoor", "temperature", "(", "mathtemp", "/", "math", ")", ",", "which", "in", "a", "given", "application", "can", "be", "recorded", "to", "several", "decimal", "places", "(", "depending", "on", "the", "measuring", "device", ")", "."], "sentence-detokenized": "An example of this is a variable such as outdoor temperature (mathtemp / math), which in a given application can be recorded to several decimal places (depending on the measuring device).", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 18], [19, 21], [22, 23], [24, 32], [33, 37], [38, 40], [41, 48], [49, 60], [61, 62], [62, 70], [71, 72], [73, 77], [77, 78], [78, 79], [80, 85], [86, 88], [89, 90], [91, 96], [97, 108], [109, 112], [113, 115], [116, 124], [125, 127], [128, 135], [136, 143], [144, 150], [151, 152], [152, 161], [162, 164], [165, 168], [169, 178], [179, 185], [185, 186], [186, 187]]}
{"doc_key": "ai-test-306", "ner": [[4, 5, "person"], [7, 8, "person"], [10, 11, "person"], [20, 21, "person"], [29, 30, "person"], [32, 32, "organisation"], [35, 36, "person"], [40, 42, "person"], [43, 43, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 6, 7, 8, 10, 11], "relations": [[35, 36, 32, 32, "role", "", false, false], [43, 43, 40, 42, "named", "", false, false]], "relations_mapping_to_source": [2, 4], "sentence": ["The", "returning", "judges", "are", "Fon", "Davis", ",", "Jessica", "Chobot", "and", "Leland", "Melvin", "as", "well", "as", "guest", "judges", "such", "as", "actor", "Clark", "Gregg", ",", "MythBusters", "host", "and", "former", "Battlebots", "builder", "Adam", "Savage", ",", "NFL", "tight", "end", "Vernon", "Davis", "and", "YouTube", "star", "Michael", "Stevens", "aka", "Vsauce", "."], "sentence-detokenized": "The returning judges are Fon Davis, Jessica Chobot and Leland Melvin as well as guest judges such as actor Clark Gregg, MythBusters host and former Battlebots builder Adam Savage, NFL tight end Vernon Davis and YouTube star Michael Stevens aka Vsauce.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 24], [25, 28], [29, 34], [34, 35], [36, 43], [44, 50], [51, 54], [55, 61], [62, 68], [69, 71], [72, 76], [77, 79], [80, 85], [86, 92], [93, 97], [98, 100], [101, 106], [107, 112], [113, 118], [118, 119], [120, 131], [132, 136], [137, 140], [141, 147], [148, 158], [159, 166], [167, 171], [172, 178], [178, 179], [180, 183], [184, 189], [190, 193], [194, 200], [201, 206], [207, 210], [211, 218], [219, 223], [224, 231], [232, 239], [240, 243], [244, 250], [250, 251]]}
{"doc_key": "ai-test-307", "ner": [[10, 11, "algorithm"], [12, 16, "algorithm"], [18, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 18, 20, "part-of", "", false, false], [12, 16, 18, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "these", "methods", "never", "won", "over", "the", "disparate", "internal", "Gaussian", "mixture", "model", "/", "Hidden", "Markov", "model", "(", "GMM", "-", "HMM", ")", "technology", "based", "on", "generative", "models", "of", "speech", "that", "are", "trained", "discriminatively", "."], "sentence-detokenized": "However, these methods never won over the disparate internal Gaussian mixture model/Hidden Markov model (GMM-HMM) technology based on generative models of speech that are trained discriminatively.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 22], [23, 28], [29, 32], [33, 37], [38, 41], [42, 51], [52, 60], [61, 69], [70, 77], [78, 83], [83, 84], [84, 90], [91, 97], [98, 103], [104, 105], [105, 108], [108, 109], [109, 112], [112, 113], [114, 124], [125, 130], [131, 133], [134, 144], [145, 151], [152, 154], [155, 161], [162, 166], [167, 170], [171, 178], [179, 195], [195, 196]]}
{"doc_key": "ai-test-308", "ner": [[4, 4, "product"], [6, 7, "programlang"], [9, 9, "programlang"], [11, 12, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Software", "packages", "such", "as", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", "and", "SciPy", "allow", "these", "different", "methods", "to", "be", "applied", "in", "a", "practical", "way", "."], "sentence-detokenized": "Software packages such as MATLAB, GNU Octave, Scilab and SciPy allow these different methods to be applied in a practical way.", "token2charspan": [[0, 8], [9, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 37], [38, 44], [44, 45], [46, 52], [53, 56], [57, 62], [63, 68], [69, 74], [75, 84], [85, 92], [93, 95], [96, 98], [99, 106], [107, 109], [110, 111], [112, 121], [122, 125], [125, 126]]}
{"doc_key": "ai-test-309", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [10, 11, "task"], [17, 18, "researcher"], [20, 21, "university"], [23, 24, "researcher"], [26, 29, "organisation"], [31, 31, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 10, 11, "related-to", "", false, false], [0, 2, 17, 18, "origin", "", false, false], [0, 2, 23, 24, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [17, 18, 20, 21, "physical", "", false, false], [17, 18, 20, 21, "role", "", false, false], [23, 24, 26, 29, "physical", "", false, false], [23, 24, 26, 29, "role", "", false, false], [31, 31, 26, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Linear", "Predictive", "Coding", "(", "LPC", ")", ",", "an", "algorithm", "for", "processing", "speech", ",", "was", "first", "proposed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", "."], "sentence-detokenized": "Linear Predictive Coding (LPC), an algorithm for processing speech, was first proposed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [30, 31], [32, 34], [35, 44], [45, 48], [49, 59], [60, 66], [66, 67], [68, 71], [72, 77], [78, 86], [87, 89], [90, 98], [99, 106], [107, 109], [110, 116], [117, 127], [128, 131], [132, 137], [138, 143], [144, 146], [147, 153], [154, 163], [164, 167], [168, 177], [178, 179], [179, 182], [182, 183], [184, 186], [187, 191], [191, 192]]}
{"doc_key": "ai-test-310", "ner": [[20, 27, "conference"], [29, 29, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[29, 29, 20, 27, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2006", ",", "on", "the", "occasion", "of", "the", "25th", "anniversary", "of", "the", "algorithm", ",", "a", "workshop", "was", "held", "at", "the", "International", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "to", "summarise", "recent", "contributions", "and", "variations", "to", "the", "original", "algorithm", ",", "mostly", "aimed", "at", "improving", "the", "speed", "of", "the", "algorithm", ",", "the", "robustness", "and", "accuracy", "of", "the", "estimated", "solution", "and", "reducing", "the", "dependence", "on", "user", "-", "defined", "constants", "."], "sentence-detokenized": "In 2006, on the occasion of the 25th anniversary of the algorithm, a workshop was held at the International Conference on Computer Vision and Pattern Recognition (CVPR) to summarise recent contributions and variations to the original algorithm, mostly aimed at improving the speed of the algorithm, the robustness and accuracy of the estimated solution and reducing the dependence on user-defined constants.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 24], [25, 27], [28, 31], [32, 36], [37, 48], [49, 51], [52, 55], [56, 65], [65, 66], [67, 68], [69, 77], [78, 81], [82, 86], [87, 89], [90, 93], [94, 107], [108, 118], [119, 121], [122, 130], [131, 137], [138, 141], [142, 149], [150, 161], [162, 163], [163, 167], [167, 168], [169, 171], [172, 181], [182, 188], [189, 202], [203, 206], [207, 217], [218, 220], [221, 224], [225, 233], [234, 243], [243, 244], [245, 251], [252, 257], [258, 260], [261, 270], [271, 274], [275, 280], [281, 283], [284, 287], [288, 297], [297, 298], [299, 302], [303, 313], [314, 317], [318, 326], [327, 329], [330, 333], [334, 343], [344, 352], [353, 356], [357, 365], [366, 369], [370, 380], [381, 383], [384, 388], [388, 389], [389, 396], [397, 406], [406, 407]]}
{"doc_key": "ai-test-311", "ner": [[4, 6, "university"], [9, 12, "organisation"], [14, 16, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Members", "went", "to", "the", "University", "of", "Debrecen", ",", "the", "Hungarian", "Academy", "of", "Sciences", ",", "E\u00f6tv\u00f6s", "Lor\u00e1nd", "University", ",", "etc", "."], "sentence-detokenized": "Members went to the University of Debrecen, the Hungarian Academy of Sciences, E\u00f6tv\u00f6s Lor\u00e1nd University, etc.", "token2charspan": [[0, 7], [8, 12], [13, 15], [16, 19], [20, 30], [31, 33], [34, 42], [42, 43], [44, 47], [48, 57], [58, 65], [66, 68], [69, 77], [77, 78], [79, 85], [86, 92], [93, 103], [103, 104], [105, 108], [108, 109]]}
{"doc_key": "ai-test-312", "ner": [[3, 3, "algorithm"], [17, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 17, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "extend", "the", "SVM", "to", "cases", "where", "the", "data", "are", "not", "linearly", "separable", ",", "we", "introduce", "the", "loss", "function", ","], "sentence-detokenized": "To extend the SVM to cases where the data are not linearly separable, we introduce the loss function,", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 17], [18, 20], [21, 26], [27, 32], [33, 36], [37, 41], [42, 45], [46, 49], [50, 58], [59, 68], [68, 69], [70, 72], [73, 82], [83, 86], [87, 91], [92, 100], [100, 101]]}
{"doc_key": "ai-test-313", "ner": [[0, 1, "programlang"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 10, 11, "origin", "", false, false], [0, 1, 13, 14, "origin", "", false, false], [0, 1, 16, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Logo", "is", "an", "educational", "programming", "language", "designed", "in", "1967", "by", "Wally", "Feurzeig", ",", "Seymour", "Papert", "and", "Cynthia", "Solomon", "."], "sentence-detokenized": "Logo is an educational programming language designed in 1967 by Wally Feurzeig, Seymour Papert and Cynthia Solomon.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 34], [35, 43], [44, 52], [53, 55], [56, 60], [61, 63], [64, 69], [70, 78], [78, 79], [80, 87], [88, 94], [95, 98], [99, 106], [107, 114], [114, 115]]}
{"doc_key": "ai-test-314", "ner": [[0, 5, "organisation"], [10, 14, "organisation"], [16, 19, "location"], [21, 21, "location"], [23, 23, "location"], [28, 33, "product"], [40, 43, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 5, 10, 14, "role", "works_for", false, false], [10, 14, 16, 19, "physical", "", false, false], [16, 19, 21, 21, "physical", "", false, false], [21, 21, 23, 23, "physical", "", false, false], [28, 33, 0, 5, "origin", "", false, false], [40, 43, 28, 33, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "Eyring", "Research", "Institute", "played", "an", "important", "role", "for", "the", "U.S.", "Air", "Force", "Missile", "Directorate", "at", "Hill", "Air", "Force", "Base", "near", "Ogden", ",", "Utah", ",", "by", "producing", "the", "intelligent", "systems", "technology", "software", "that", "was", "fundamental", "to", "the", "later", "-", "named", "Reagan", "Star", "Wars", "program", ",", "under", "the", "highest", "military", "secrecy", "."], "sentence-detokenized": "The Eyring Research Institute played an important role for the U.S. Air Force Missile Directorate at Hill Air Force Base near Ogden, Utah, by producing the intelligent systems technology software that was fundamental to the later-named Reagan Star Wars program, under the highest military secrecy.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 29], [30, 36], [37, 39], [40, 49], [50, 54], [55, 58], [59, 62], [63, 67], [68, 71], [72, 77], [78, 85], [86, 97], [98, 100], [101, 105], [106, 109], [110, 115], [116, 120], [121, 125], [126, 131], [131, 132], [133, 137], [137, 138], [139, 141], [142, 151], [152, 155], [156, 167], [168, 175], [176, 186], [187, 195], [196, 200], [201, 204], [205, 216], [217, 219], [220, 223], [224, 229], [229, 230], [230, 235], [236, 242], [243, 247], [248, 252], [253, 260], [260, 261], [262, 267], [268, 271], [272, 279], [280, 288], [289, 296], [296, 297]]}
{"doc_key": "ai-test-315", "ner": [[11, 12, "field"], [21, 24, "researcher"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Over", "the", "decades", "he", "has", "researched", "and", "developed", "new", "areas", "of", "computer", "science", "from", "compiler", ",", "programming", "language", "and", "system", "architecture", "John", "F", ".", "Sowa", "and", "John", "Zachman", "(", "1992", ")", "."], "sentence-detokenized": "Over the decades he has researched and developed new areas of computer science from compiler, programming language and system architecture John F. Sowa and John Zachman (1992).", "token2charspan": [[0, 4], [5, 8], [9, 16], [17, 19], [20, 23], [24, 34], [35, 38], [39, 48], [49, 52], [53, 58], [59, 61], [62, 70], [71, 78], [79, 83], [84, 92], [92, 93], [94, 105], [106, 114], [115, 118], [119, 125], [126, 138], [139, 143], [144, 145], [145, 146], [147, 151], [152, 155], [156, 160], [161, 168], [169, 170], [170, 174], [174, 175], [175, 176]]}
{"doc_key": "ai-test-316", "ner": [[0, 2, "algorithm"], [7, 10, "algorithm"], [13, 14, "algorithm"], [19, 20, "field"], [22, 23, "field"], [27, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 10, 0, 2, "named", "", false, false], [13, 14, 0, 2, "named", "", false, false], [19, 20, 0, 2, "usage", "", false, false], [22, 23, 0, 2, "usage", "", false, false], [27, 29, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Sobel", "operator", ",", "sometimes", "called", "the", "Sobel", "-", "Feldman", "operator", "or", "the", "Sobel", "filter", ",", "is", "used", "in", "image", "processing", "and", "computer", "vision", ",", "especially", "in", "edge", "detection", "algorithms", ",", "where", "it", "creates", "an", "image", "that", "highlights", "edges", "."], "sentence-detokenized": "The Sobel operator, sometimes called the Sobel-Feldman operator or the Sobel filter, is used in image processing and computer vision, especially in edge detection algorithms, where it creates an image that highlights edges.", "token2charspan": [[0, 3], [4, 9], [10, 18], [18, 19], [20, 29], [30, 36], [37, 40], [41, 46], [46, 47], [47, 54], [55, 63], [64, 66], [67, 70], [71, 76], [77, 83], [83, 84], [85, 87], [88, 92], [93, 95], [96, 101], [102, 112], [113, 116], [117, 125], [126, 132], [132, 133], [134, 144], [145, 147], [148, 152], [153, 162], [163, 173], [173, 174], [175, 180], [181, 183], [184, 191], [192, 194], [195, 200], [201, 205], [206, 216], [217, 222], [222, 223]]}
{"doc_key": "ai-test-317", "ner": [[0, 1, "algorithm"], [3, 3, "field"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 3, 3, "compare", "", false, false], [0, 1, 3, 3, "type-of", "", false, false], [0, 1, 15, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["LDA", "is", "a", "supervised", "learning", "algorithm", "that", "uses", "the", "labels", "of", "the", "data", ",", "while", "PCA", "is", "a", "learning", "algorithm", "that", "does", "not", "take", "the", "labels", "into", "account", "."], "sentence-detokenized": "LDA is a supervised learning algorithm that uses the labels of the data, while PCA is a learning algorithm that does not take the labels into account.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 19], [20, 28], [29, 38], [39, 43], [44, 48], [49, 52], [53, 59], [60, 62], [63, 66], [67, 71], [71, 72], [73, 78], [79, 82], [83, 85], [86, 87], [88, 96], [97, 106], [107, 111], [112, 116], [117, 120], [121, 125], [126, 129], [130, 136], [137, 141], [142, 149], [149, 150]]}
{"doc_key": "ai-test-318", "ner": [[5, 5, "algorithm"], [7, 9, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "linear", "classification", "algorithms", "include", "Winnow", ",", "support", "vector", "machine", "and", "logistic", "regression", "."], "sentence-detokenized": "Other linear classification algorithms include Winnow, support vector machine and logistic regression.", "token2charspan": [[0, 5], [6, 12], [13, 27], [28, 38], [39, 46], [47, 53], [53, 54], [55, 62], [63, 69], [70, 77], [78, 81], [82, 90], [91, 101], [101, 102]]}
{"doc_key": "ai-test-319", "ner": [[0, 0, "product"], [4, 5, "programlang"], [15, 17, "product"], [19, 19, "programlang"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 4, 5, "general-affiliation", "", true, false], [0, 0, 15, 17, "general-affiliation", "", true, false], [0, 0, 19, 19, "general-affiliation", "", true, false], [0, 0, 21, 21, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["VTK", "consists", "of", "a", "C", "++", "class", "library", "and", "several", "interpreted", "interface", "layers", ",", "including", "Tcl", "/", "Tk", ",", "Java", "and", "Python", "."], "sentence-detokenized": "VTK consists of a C++ class library and several interpreted interface layers, including Tcl/Tk, Java and Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 17], [18, 19], [19, 21], [22, 27], [28, 35], [36, 39], [40, 47], [48, 59], [60, 69], [70, 76], [76, 77], [78, 87], [88, 91], [91, 92], [92, 94], [94, 95], [96, 100], [101, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-320", "ner": [[7, 9, "task"], [16, 18, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Text", "produced", "by", "processing", "spontaneous", "speech", "using", "automatic", "speech", "recognition", "and", "printed", "or", "handwritten", "text", "using", "optical", "character", "recognition", "also", "contains", "processing", "noise", "."], "sentence-detokenized": "Text produced by processing spontaneous speech using automatic speech recognition and printed or handwritten text using optical character recognition also contains processing noise.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 27], [28, 39], [40, 46], [47, 52], [53, 62], [63, 69], [70, 81], [82, 85], [86, 93], [94, 96], [97, 108], [109, 113], [114, 119], [120, 127], [128, 137], [138, 149], [150, 154], [155, 163], [164, 174], [175, 180], [180, 181]]}
{"doc_key": "ai-test-321", "ner": [[0, 0, "researcher"], [9, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 9, 11, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "wrote", "several", "books", "and", "led", "the", "development", "of", "WordNet", ",", "an", "online", "word", "association", "database", "that", "can", "be", "used", "by", "computer", "programs", "."], "sentence-detokenized": "Miller wrote several books and led the development of WordNet, an online word association database that can be used by computer programs.", "token2charspan": [[0, 6], [7, 12], [13, 20], [21, 26], [27, 30], [31, 34], [35, 38], [39, 50], [51, 53], [54, 61], [61, 62], [63, 65], [66, 72], [73, 77], [78, 89], [90, 98], [99, 103], [104, 107], [108, 110], [111, 115], [116, 118], [119, 127], [128, 136], [136, 137]]}
{"doc_key": "ai-test-322", "ner": [[1, 1, "field"], [7, 9, "organisation"], [12, 12, "country"], [14, 15, "person"], [17, 19, "person"], [21, 22, "person"], [24, 25, "person"], [28, 28, "country"], [30, 33, "location"], [35, 36, "misc"], [37, 38, "person"], [40, 41, "person"], [43, 43, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[7, 9, 12, 12, "physical", "", false, false], [14, 15, 28, 28, "physical", "", false, false], [17, 19, 28, 28, "physical", "", false, false], [21, 22, 28, 28, "physical", "", false, false], [24, 25, 28, 28, "physical", "", false, false], [30, 33, 1, 1, "general-affiliation", "", false, false], [30, 33, 37, 38, "artifact", "", false, false], [35, 36, 37, 38, "named", "", false, false], [40, 41, 43, 43, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Modern", "automata", "are", "represented", "by", "works", "by", "Cabaret", "Mechanical", "Theatre", "in", "the", "UK", ",", "Dug", "North", "and", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", ",", "Joe", "Jones", "in", "the", "US", ",", "Le", "D\u00e9fenseur", "du", "Temps", "by", "French", "artist", "Jacques", "Monestier", "and", "Fran\u00e7ois", "Junod", "in", "Switzerland", "."], "sentence-detokenized": "Modern automata are represented by works by Cabaret Mechanical Theatre in the UK, Dug North and Chomick + Meder, Arthur Ganson, Joe Jones in the US, Le D\u00e9fenseur du Temps by French artist Jacques Monestier and Fran\u00e7ois Junod in Switzerland.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 31], [32, 34], [35, 40], [41, 43], [44, 51], [52, 62], [63, 70], [71, 73], [74, 77], [78, 80], [80, 81], [82, 85], [86, 91], [92, 95], [96, 103], [104, 105], [106, 111], [111, 112], [113, 119], [120, 126], [126, 127], [128, 131], [132, 137], [138, 140], [141, 144], [145, 147], [147, 148], [149, 151], [152, 161], [162, 164], [165, 170], [171, 173], [174, 180], [181, 187], [188, 195], [196, 205], [206, 209], [210, 218], [219, 224], [225, 227], [228, 239], [239, 240]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 21, 21, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "provides", "standard", "codefor", "/", "code", "and", "codewhile", "/", "code", "loops", ",", "but", "(", "as", "in", "other", "similar", "programs", ",", "e.g.", "R", ")", "it", "is", "recommended", "to", "use", "vectorized", "notation", ",", "which", "is", "often", "faster", "to", "execute", "."], "sentence-detokenized": "MATLAB provides standard codefor/code and codewhile/code loops, but (as in other similar programs, e.g. R) it is recommended to use vectorized notation, which is often faster to execute.", "token2charspan": [[0, 6], [7, 15], [16, 24], [25, 32], [32, 33], [33, 37], [38, 41], [42, 51], [51, 52], [52, 56], [57, 62], [62, 63], [64, 67], [68, 69], [69, 71], [72, 74], [75, 80], [81, 88], [89, 97], [97, 98], [99, 103], [104, 105], [105, 106], [107, 109], [110, 112], [113, 124], [125, 127], [128, 131], [132, 142], [143, 151], [151, 152], [153, 158], [159, 161], [162, 167], [168, 174], [175, 177], [178, 185], [185, 186]]}
{"doc_key": "ai-test-324", "ner": [[0, 0, "researcher"], [6, 9, "conference"], [16, 18, "field"], [19, 23, "misc"], [26, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 19, 23, "win-defeat", "", false, false], [0, 0, 26, 35, "win-defeat", "", false, false], [19, 23, 6, 9, "temporal", "", false, false], [19, 23, 16, 18, "topic", "", false, false], [26, 35, 6, 9, "temporal", "", false, false], [26, 35, 16, 18, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pausch", "received", "two", "awards", "from", "the", "Association", "for", "Computing", "Machinery", "in", "2007", "for", "his", "achievements", "in", "computer", "science", "education", ".", "Karlstrom", "Outstanding", "Educator", "Award", "and", "the", "ACM", "SIGCSE", "Award", "for", "Outstanding", "Contributions", "to", "Computer", "Science", "Education", "."], "sentence-detokenized": "Pausch received two awards from the Association for Computing Machinery in 2007 for his achievements in computer science education. Karlstrom Outstanding Educator Award and the ACM SIGCSE Award for Outstanding Contributions to Computer Science Education.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 26], [27, 31], [32, 35], [36, 47], [48, 51], [52, 61], [62, 71], [72, 74], [75, 79], [80, 83], [84, 87], [88, 100], [101, 103], [104, 112], [113, 120], [121, 130], [130, 131], [132, 141], [142, 153], [154, 162], [163, 168], [169, 172], [173, 176], [177, 180], [181, 187], [188, 193], [194, 197], [198, 209], [210, 223], [224, 226], [227, 235], [236, 243], [244, 253], [253, 254]]}
{"doc_key": "ai-test-325", "ner": [[3, 3, "person"], [8, 11, "product"], [15, 16, "organisation"]], "ner_mapping_to_source": [0, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "delivered", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was delivered to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 75], [76, 78], [79, 86], [87, 93], [94, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-test-326", "ner": [[0, 1, "algorithm"], [5, 8, "field"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 13, 0, 1, "usage", "", false, false], [12, 13, 5, 8, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Semantic", "networks", "are", "used", "in", "natural", "language", "processing", "applications", ",", "such", "as", "semantic", "parsing", "."], "sentence-detokenized": "Semantic networks are used in natural language processing applications, such as semantic parsing.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 26], [27, 29], [30, 37], [38, 46], [47, 57], [58, 70], [70, 71], [72, 76], [77, 79], [80, 88], [89, 96], [96, 97]]}
{"doc_key": "ai-test-327", "ner": [[4, 5, "field"], [7, 8, "field"], [10, 11, "task"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 8, 4, 5, "usage", "", false, false], [10, 11, 4, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Some", "successful", "applications", "of", "deep", "learning", "are", "computer", "vision", "and", "speech", "recognition", ".", "Honglak", "Lee", ",", "Roger", "Grosse", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y", ".", "Ng", "."], "sentence-detokenized": "Some successful applications of deep learning are computer vision and speech recognition. Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 4], [5, 15], [16, 28], [29, 31], [32, 36], [37, 45], [46, 49], [50, 58], [59, 65], [66, 69], [70, 76], [77, 88], [88, 89], [90, 97], [98, 101], [101, 102], [103, 108], [109, 115], [115, 116], [117, 123], [124, 133], [133, 134], [135, 141], [142, 143], [143, 144], [145, 147], [147, 148]]}
{"doc_key": "ai-test-328", "ner": [[4, 9, "product"], [15, 15, "misc"], [18, 18, "misc"], [24, 24, "product"], [29, 30, "task"], [32, 33, "task"], [35, 36, "task"], [38, 40, "field"], [42, 43, "task"], [45, 46, "field"], [48, 49, "task"], [51, 52, "task"], [54, 55, "task"], [57, 58, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 9, 15, 15, "physical", "travels_to", false, false], [4, 9, 18, 18, "physical", "travels_to", false, false], [24, 24, 4, 9, "part-of", "", false, false], [24, 24, 4, 9, "role", "maintains", false, false], [24, 24, 29, 30, "related-to", "has_ability_to", false, false], [24, 24, 32, 33, "related-to", "has_ability_to", false, false], [24, 24, 35, 36, "related-to", "has_ability_to", false, false], [24, 24, 38, 40, "related-to", "has_ability_to", false, false], [24, 24, 42, 43, "related-to", "has_ability_to", false, false], [24, 24, 45, 46, "related-to", "has_ability_to", false, false], [24, 24, 48, 49, "related-to", "has_ability_to", false, false], [24, 24, 51, 52, "related-to", "has_ability_to", false, false], [24, 24, 54, 55, "related-to", "has_ability_to", false, false], [24, 24, 57, 58, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["In", "addition", "to", "maintaining", "the", "Discovery", "One", "spacecraft", "'s", "systems", "during", "the", "interplanetary", "mission", "to", "Jupiter", "(", "or", "Saturn", "in", "the", "novel", ")", ",", "HAL", "is", "capable", "of", "performing", "speech", "synthesis", ",", "speech", "recognition", ",", "facial", "recognition", ",", "natural", "language", "processing", ",", "lip", "reading", ",", "art", "comprehension", ",", "affective", "computing", ",", "automated", "reasoning", ",", "spacecraft", "control", "and", "chess", "games", "."], "sentence-detokenized": "In addition to maintaining the Discovery One spacecraft's systems during the interplanetary mission to Jupiter (or Saturn in the novel), HAL is capable of performing speech synthesis, speech recognition, facial recognition, natural language processing, lip reading, art comprehension, affective computing, automated reasoning, spacecraft control and chess games.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 40], [41, 44], [45, 55], [55, 57], [58, 65], [66, 72], [73, 76], [77, 91], [92, 99], [100, 102], [103, 110], [111, 112], [112, 114], [115, 121], [122, 124], [125, 128], [129, 134], [134, 135], [135, 136], [137, 140], [141, 143], [144, 151], [152, 154], [155, 165], [166, 172], [173, 182], [182, 183], [184, 190], [191, 202], [202, 203], [204, 210], [211, 222], [222, 223], [224, 231], [232, 240], [241, 251], [251, 252], [253, 256], [257, 264], [264, 265], [266, 269], [270, 283], [283, 284], [285, 294], [295, 304], [304, 305], [306, 315], [316, 325], [325, 326], [327, 337], [338, 345], [346, 349], [350, 355], [356, 361], [361, 362]]}
{"doc_key": "ai-test-329", "ner": [[0, 1, "researcher"], [4, 4, "country"], [7, 8, "country"], [11, 11, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 4, "physical", "", false, false], [0, 1, 7, 8, "physical", "", false, false], [0, 1, 11, 11, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dr", "Julesz", "emigrated", "from", "Hungary", "to", "the", "United", "States", "after", "the", "Soviet", "invasion", "of", "1956", "."], "sentence-detokenized": "Dr Julesz emigrated from Hungary to the United States after the Soviet invasion of 1956.", "token2charspan": [[0, 2], [3, 9], [10, 19], [20, 24], [25, 32], [33, 35], [36, 39], [40, 46], [47, 53], [54, 59], [60, 63], [64, 70], [71, 79], [80, 82], [83, 87], [87, 88]]}
{"doc_key": "ai-test-330", "ner": [[0, 0, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sigmoid", "activation", "functions", "use", "a", "different", "non-linearity", "for", "large", "inputs", ":", "math", "\\", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+\\", "exp", "(", "-", "v", "_", "i", ")", ")", "^", "{", "-1", "}", "/", "math", "."], "sentence-detokenized": "Sigmoid activation functions use a different non-linearity for large inputs: math\\ phi (v _ i) = (1 +\\ exp (-v _ i)) ^ {-1} / math.", "token2charspan": [[0, 7], [8, 18], [19, 28], [29, 32], [33, 34], [35, 44], [45, 58], [59, 62], [63, 68], [69, 75], [75, 76], [77, 81], [81, 82], [83, 86], [87, 88], [88, 89], [90, 91], [92, 93], [93, 94], [95, 96], [97, 98], [98, 99], [100, 102], [103, 106], [107, 108], [108, 109], [109, 110], [111, 112], [113, 114], [114, 115], [115, 116], [117, 118], [119, 120], [120, 122], [122, 123], [124, 125], [126, 130], [130, 131]]}
{"doc_key": "ai-test-331", "ner": [[13, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "probabilities", "are", "used", "to", "determine", "what", "the", "target", "is", ",", "using", "a", "maximum", "likelihood", "decision", "."], "sentence-detokenized": "These probabilities are used to determine what the target is, using a maximum likelihood decision.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 28], [29, 31], [32, 41], [42, 46], [47, 50], [51, 57], [58, 60], [60, 61], [62, 67], [68, 69], [70, 77], [78, 88], [89, 97], [97, 98]]}
{"doc_key": "ai-test-332", "ner": [[6, 8, "university"], [14, 16, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1984", "he", "moved", "to", "the", "University", "of", "Konstanz", "and", "in", "1990", "to", "the", "University", "of", "Salzburg", "."], "sentence-detokenized": "In 1984 he moved to the University of Konstanz and in 1990 to the University of Salzburg.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 16], [17, 19], [20, 23], [24, 34], [35, 37], [38, 46], [47, 50], [51, 53], [54, 58], [59, 61], [62, 65], [66, 76], [77, 79], [80, 88], [88, 89]]}
{"doc_key": "ai-test-333", "ner": [[6, 8, "metrics"], [10, 12, "metrics"], [14, 16, "metrics"], [18, 18, "metrics"], [20, 21, "metrics"], [23, 25, "metrics"], [27, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 12, 6, 8, "origin", "based_on", false, false], [14, 16, 6, 8, "origin", "based_on", false, false], [18, 18, 6, 8, "origin", "based_on", false, false], [20, 21, 6, 8, "origin", "based_on", false, false], [23, 25, 6, 8, "origin", "based_on", false, false], [27, 32, 6, 8, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Some", "popular", "fitness", "functions", "based", "on", "the", "confusion", "matrix", "include", "sensitivity", "/", "specificity", ",", "recall", "/", "precision", ",", "F-measure", ",", "Jaccard", "coincidence", ",", "Matthews", "correlation", "coefficient", "and", "cost", "/", "benefit", "matrix", ",", "which", "combines", "the", "costs", "and", "benefits", "assigned", "to", "the", "4", "different", "types", "of", "classifications", "."], "sentence-detokenized": "Some popular fitness functions based on the confusion matrix include sensitivity/specificity, recall/precision, F-measure, Jaccard coincidence, Matthews correlation coefficient and cost/benefit matrix, which combines the costs and benefits assigned to the 4 different types of classifications.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 30], [31, 36], [37, 39], [40, 43], [44, 53], [54, 60], [61, 68], [69, 80], [80, 81], [81, 92], [92, 93], [94, 100], [100, 101], [101, 110], [110, 111], [112, 121], [121, 122], [123, 130], [131, 142], [142, 143], [144, 152], [153, 164], [165, 176], [177, 180], [181, 185], [185, 186], [186, 193], [194, 200], [200, 201], [202, 207], [208, 216], [217, 220], [221, 226], [227, 230], [231, 239], [240, 248], [249, 251], [252, 255], [256, 257], [258, 267], [268, 273], [274, 276], [277, 292], [292, 293]]}
{"doc_key": "ai-test-334", "ner": [[6, 6, "product"], [8, 8, "product"], [10, 10, "product"], [12, 12, "product"], [14, 16, "programlang"], [28, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[28, 30, 6, 6, "part-of", "", false, false], [28, 30, 8, 8, "part-of", "", false, false], [28, 30, 10, 10, "part-of", "", false, false], [28, 30, 12, 12, "part-of", "", false, false], [28, 30, 14, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Common", "numerical", "programming", "environments", "such", "as", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", "and", "the", "R", "language", "provide", "some", "of", "the", "simpler", "techniques", "for", "extracting", "functions", "(", "e.g.", "principal", "component", "analysis", ")", "via", "built", "-", "in", "commands", "."], "sentence-detokenized": "Common numerical programming environments such as MATLAB, SciLab, NumPy, Sklearn and the R language provide some of the simpler techniques for extracting functions (e.g. principal component analysis) via built-in commands.", "token2charspan": [[0, 6], [7, 16], [17, 28], [29, 41], [42, 46], [47, 49], [50, 56], [56, 57], [58, 64], [64, 65], [66, 71], [71, 72], [73, 80], [81, 84], [85, 88], [89, 90], [91, 99], [100, 107], [108, 112], [113, 115], [116, 119], [120, 127], [128, 138], [139, 142], [143, 153], [154, 163], [164, 165], [165, 169], [170, 179], [180, 189], [190, 198], [198, 199], [200, 203], [204, 209], [209, 210], [210, 212], [213, 221], [221, 222]]}
{"doc_key": "ai-test-335", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Industrial", "robots", "have", "been", "deployed", "to", "collaborate", "with", "humans", "to", "perform", "industrial", "production", "tasks", "."], "sentence-detokenized": "Industrial robots have been deployed to collaborate with humans to perform industrial production tasks.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 27], [28, 36], [37, 39], [40, 51], [52, 56], [57, 63], [64, 66], [67, 74], [75, 85], [86, 96], [97, 102], [102, 103]]}
{"doc_key": "ai-test-336", "ner": [[6, 6, "field"], [8, 11, "researcher"], [21, 22, "field"], [24, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 21, 22, "related-to", "", false, false], [6, 6, 24, 25, "related-to", "", false, false], [6, 6, 27, 28, "related-to", "", false, false], [8, 11, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "first", "published", "article", "on", "CGs", ",", "John", "F", ".", "Sowa", "applied", "them", "to", "a", "wide", "range", "of", "topics", "in", "artificial", "intelligence", ",", "computer", "science", "and", "cognitive", "science", "."], "sentence-detokenized": "In the first published article on CGs, John F. Sowa applied them to a wide range of topics in artificial intelligence, computer science and cognitive science.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [23, 30], [31, 33], [34, 37], [37, 38], [39, 43], [44, 45], [45, 46], [47, 51], [52, 59], [60, 64], [65, 67], [68, 69], [70, 74], [75, 80], [81, 83], [84, 90], [91, 93], [94, 104], [105, 117], [117, 118], [119, 127], [128, 135], [136, 139], [140, 149], [150, 157], [157, 158]]}
{"doc_key": "ai-test-337", "ner": [[0, 0, "metrics"], [4, 4, "metrics"], [10, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "BLEU", "in", "its", "calculation", "of", "the", "penalty", "for", "brevity", ",", "in", "that", "small", "variations", "in", "translation", "length", "do", "not", "affect", "the", "overall", "score", "as", "much", "."], "sentence-detokenized": "NIST also differs from BLEU in its calculation of the penalty for brevity, in that small variations in translation length do not affect the overall score as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 46], [47, 49], [50, 53], [54, 61], [62, 65], [66, 73], [73, 74], [75, 77], [78, 82], [83, 88], [89, 99], [100, 102], [103, 114], [115, 121], [122, 124], [125, 128], [129, 135], [136, 139], [140, 147], [148, 153], [154, 156], [157, 161], [161, 162]]}
{"doc_key": "ai-test-338", "ner": [[0, 6, "misc"], [21, 23, "field"]], "ner_mapping_to_source": [0, 2], "relations": [[0, 6, 21, 23, "topic", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["The", "IJCAI", "Award", "for", "Research", "Excellence", "is", "a", "bi-annual", "award", "presented", "at", "the", "IJCAI", "conference", "to", "researchers", "in", "the", "field", "of", "artificial", "intelligence", "in", "recognition", "of", "their", "outstanding", "careers", "."], "sentence-detokenized": "The IJCAI Award for Research Excellence is a bi-annual award presented at the IJCAI conference to researchers in the field of artificial intelligence in recognition of their outstanding careers.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 19], [20, 28], [29, 39], [40, 42], [43, 44], [45, 54], [55, 60], [61, 70], [71, 73], [74, 77], [78, 83], [84, 94], [95, 97], [98, 109], [110, 112], [113, 116], [117, 122], [123, 125], [126, 136], [137, 149], [150, 152], [153, 164], [165, 167], [168, 173], [174, 185], [186, 193], [193, 194]]}
{"doc_key": "ai-test-339", "ner": [[0, 0, "researcher"], [4, 5, "conference"], [17, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 5, "role", "", false, false], [0, 0, 17, 25, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lenat", "was", "one", "of", "AAAI", "'s", "original", "Fellows", "and", "is", "the", "only", "person", "to", "have", "served", "on", "both", "Microsoft", "'s", "and", "Apple", "'s", "scientific", "advisory", "boards", "."], "sentence-detokenized": "Lenat was one of AAAI's original Fellows and is the only person to have served on both Microsoft's and Apple's scientific advisory boards.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 16], [17, 21], [21, 23], [24, 32], [33, 40], [41, 44], [45, 47], [48, 51], [52, 56], [57, 63], [64, 66], [67, 71], [72, 78], [79, 81], [82, 86], [87, 96], [96, 98], [99, 102], [103, 108], [108, 110], [111, 121], [122, 130], [131, 137], [137, 138]]}
{"doc_key": "ai-test-340", "ner": [[0, 0, "algorithm"], [5, 6, "misc"], [9, 11, "metrics"], [16, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 6, "related-to", "minimise", false, false], [9, 11, 5, 6, "type-of", "", false, false], [16, 16, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autoencoders", "are", "trained", "to", "minimize", "reconstruction", "error", "(", "e.g.", "mean", "squared", "error", ")", ",", "often", "called", "loss", ":"], "sentence-detokenized": "Autoencoders are trained to minimize reconstruction error (e.g. mean squared error), often called loss:", "token2charspan": [[0, 12], [13, 16], [17, 24], [25, 27], [28, 36], [37, 51], [52, 57], [58, 59], [59, 63], [64, 68], [69, 76], [77, 82], [82, 83], [83, 84], [85, 90], [91, 97], [98, 102], [102, 103]]}
{"doc_key": "ai-test-341", "ner": [[33, 35, "misc"], [38, 38, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[38, 38, 33, 35, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "alternative", "to", "the", "use", "of", "definitions", "is", "to", "take", "into", "account", "the", "general", "word", "sense", "relatedness", "and", "calculate", "the", "similarity", "between", "each", "pair", "of", "word", "senses", "on", "the", "basis", "of", "a", "given", "lexical", "knowledge", "base", "such", "as", "WordNet", "."], "sentence-detokenized": "An alternative to the use of definitions is to take into account the general word sense relatedness and calculate the similarity between each pair of word senses on the basis of a given lexical knowledge base such as WordNet.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 21], [22, 25], [26, 28], [29, 40], [41, 43], [44, 46], [47, 51], [52, 56], [57, 64], [65, 68], [69, 76], [77, 81], [82, 87], [88, 99], [100, 103], [104, 113], [114, 117], [118, 128], [129, 136], [137, 141], [142, 146], [147, 149], [150, 154], [155, 161], [162, 164], [165, 168], [169, 174], [175, 177], [178, 179], [180, 185], [186, 193], [194, 203], [204, 208], [209, 213], [214, 216], [217, 224], [224, 225]]}
{"doc_key": "ai-test-342", "ner": [[0, 3, "algorithm"], [9, 11, "researcher"], [14, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 9, 11, "origin", "", false, false], [9, 11, 14, 16, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD", "-", "Lambda", "is", "a", "learning", "algorithm", "invented", "by", "Richard", "S.", "Sutton", "based", "on", "Arthur", "Samuel", "'s", "earlier", "work", "on", "time", "difference", "learning", "."], "sentence-detokenized": "TD-Lambda is a learning algorithm invented by Richard S. Sutton based on Arthur Samuel's earlier work on time difference learning.", "token2charspan": [[0, 2], [2, 3], [3, 9], [10, 12], [13, 14], [15, 23], [24, 33], [34, 42], [43, 45], [46, 53], [54, 56], [57, 63], [64, 69], [70, 72], [73, 79], [80, 86], [86, 88], [89, 96], [97, 101], [102, 104], [105, 109], [110, 120], [121, 129], [129, 130]]}
{"doc_key": "ai-test-343", "ner": [[1, 2, "field"], [4, 4, "field"], [6, 8, "task"], [12, 14, "task"], [16, 19, "task"], [22, 24, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 8, 1, 2, "part-of", "task_part_of_field", false, false], [6, 8, 4, 4, "part-of", "task_part_of_field", false, false], [12, 14, 6, 8, "named", "", false, false], [16, 19, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "data", "mining", "and", "statistics", ",", "hierarchical", "cluster", "analysis", "(", "also", "called", "hierarchical", "cluster", "analysis", "or", "HCA", ")", "is", "a", "method", "of", "cluster", "analysis", "that", "seeks", "to", "build", "a", "hierarchy", "of", "clusters", "."], "sentence-detokenized": "In data mining and statistics, hierarchical cluster analysis (also called hierarchical cluster analysis or HCA) is a method of cluster analysis that seeks to build a hierarchy of clusters.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 18], [19, 29], [29, 30], [31, 43], [44, 51], [52, 60], [61, 62], [62, 66], [67, 73], [74, 86], [87, 94], [95, 103], [104, 106], [107, 110], [110, 111], [112, 114], [115, 116], [117, 123], [124, 126], [127, 134], [135, 143], [144, 148], [149, 154], [155, 157], [158, 163], [164, 165], [166, 175], [176, 178], [179, 187], [187, 188]]}
{"doc_key": "ai-test-344", "ner": [[2, 4, "algorithm"], [7, 8, "field"], [10, 11, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 4, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "term", "deconvolution", "is", "widely", "used", "in", "signal", "processing", "and", "image", "processing", "techniques", "."], "sentence-detokenized": "The term deconvolution is widely used in signal processing and image processing techniques.", "token2charspan": [[0, 3], [4, 8], [9, 22], [23, 25], [26, 32], [33, 37], [38, 40], [41, 47], [48, 58], [59, 62], [63, 68], [69, 79], [80, 90], [90, 91]]}
{"doc_key": "ai-test-345", "ner": [[0, 1, "algorithm"], [22, 23, "misc"], [26, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 22, 23, "related-to", "enhances", false, false], [0, 1, 22, 23, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cognitive", "maps", "serve", "to", "build", "and", "accumulate", "spatial", "knowledge", ",", "allowing", "the", "mind", "'s", "eye", "to", "visualise", "images", "in", "order", "to", "reduce", "cognitive", "load", ",", "improve", "recall", "and", "learning", "of", "information", "."], "sentence-detokenized": "Cognitive maps serve to build and accumulate spatial knowledge, allowing the mind's eye to visualise images in order to reduce cognitive load, improve recall and learning of information.", "token2charspan": [[0, 9], [10, 14], [15, 20], [21, 23], [24, 29], [30, 33], [34, 44], [45, 52], [53, 62], [62, 63], [64, 72], [73, 76], [77, 81], [81, 83], [84, 87], [88, 90], [91, 100], [101, 107], [108, 110], [111, 116], [117, 119], [120, 126], [127, 136], [137, 141], [141, 142], [143, 150], [151, 157], [158, 161], [162, 170], [171, 173], [174, 185], [185, 186]]}
{"doc_key": "ai-test-346", "ner": [[8, 8, "programlang"], [10, 11, "programlang"], [13, 13, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": [",", "typically", "containing", "bindings", "to", "languages", "such", "as", "Python", ",", "C", "++", ",", "Java", ")", "."], "sentence-detokenized": ", typically containing bindings to languages such as Python, C++, Java).", "token2charspan": [[0, 1], [2, 11], [12, 22], [23, 31], [32, 34], [35, 44], [45, 49], [50, 52], [53, 59], [59, 60], [61, 62], [62, 64], [64, 65], [66, 70], [70, 71], [71, 72]]}
{"doc_key": "ai-test-347", "ner": [[1, 3, "product"], [5, 5, "product"], [15, 16, "task"], [22, 23, "task"], [26, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 15, 16, "usage", "", false, false], [1, 3, 22, 23, "usage", "", false, false], [1, 3, 26, 30, "usage", "", false, false], [5, 5, 1, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "voice", "-user", "interface", "(", "VUI", ")", "enables", "spoken", "human", "interaction", "with", "computers", "by", "using", "speech", "recognition", "to", "understand", "spoken", "commands", "and", "questionnaire", "responses", "and", "typical", "text", "-", "to", "-", "speech", "to", "play", "back", "a", "response", "."], "sentence-detokenized": "A voice-user interface (VUI) enables spoken human interaction with computers by using speech recognition to understand spoken commands and questionnaire responses and typical text-to-speech to play back a response.", "token2charspan": [[0, 1], [2, 7], [7, 12], [13, 22], [23, 24], [24, 27], [27, 28], [29, 36], [37, 43], [44, 49], [50, 61], [62, 66], [67, 76], [77, 79], [80, 85], [86, 92], [93, 104], [105, 107], [108, 118], [119, 125], [126, 134], [135, 138], [139, 152], [153, 162], [163, 166], [167, 174], [175, 179], [179, 180], [180, 182], [182, 183], [183, 189], [190, 192], [193, 197], [198, 202], [203, 204], [205, 213], [213, 214]]}
{"doc_key": "ai-test-348", "ner": [[0, 1, "programlang"], [3, 4, "misc"], [11, 14, "researcher"], [16, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4], "relations": [[0, 1, 3, 4, "general-affiliation", "is_a", false, false], [0, 1, 11, 14, "origin", "", false, false], [11, 14, 16, 17, "role", "", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["Jess", "is", "a", "rules", "engine", "for", "the", "Java", "platform", "developed", "by", "Ernest", "Friedman", "-", "Hill", "of", "Sandia", "National", "."], "sentence-detokenized": "Jess is a rules engine for the Java platform developed by Ernest Friedman-Hill of Sandia National.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 15], [16, 22], [23, 26], [27, 30], [31, 35], [36, 44], [45, 54], [55, 57], [58, 64], [65, 73], [73, 74], [74, 78], [79, 81], [82, 88], [89, 97], [97, 98]]}
{"doc_key": "ai-test-349", "ner": [[1, 2, "algorithm"], [14, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 14, 14, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "multilayer", "perceptrons", "where", "a", "hidden", "layer", "exists", ",", "more", "sophisticated", "algorithms", "such", "as", "backpropagation", "must", "be", "used", "."], "sentence-detokenized": "For multilayer perceptrons where a hidden layer exists, more sophisticated algorithms such as backpropagation must be used.", "token2charspan": [[0, 3], [4, 14], [15, 26], [27, 32], [33, 34], [35, 41], [42, 47], [48, 54], [54, 55], [56, 60], [61, 74], [75, 85], [86, 90], [91, 93], [94, 109], [110, 114], [115, 117], [118, 122], [122, 123]]}
{"doc_key": "ai-test-350", "ner": [[0, 1, "product"], [3, 6, "product"], [10, 17, "algorithm"], [22, 23, "field"], [26, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 0, 1, "part-of", "", false, false], [3, 6, 10, 17, "usage", "", false, true], [10, 17, 22, 23, "related-to", "performs", false, false], [26, 32, 22, 23, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Google", "Translate", "'s", "neural", "machine", "translation", "system", "uses", "a", "large", "end", "-", "to", "-", "end", "artificial", "neural", "network", "that", "attempts", "to", "perform", "deep", "learning", ",", "especially", "networks", "with", "long", "short", "-", "term", "memory", "."], "sentence-detokenized": "Google Translate's neural machine translation system uses a large end-to-end artificial neural network that attempts to perform deep learning, especially networks with long short-term memory.", "token2charspan": [[0, 6], [7, 16], [16, 18], [19, 25], [26, 33], [34, 45], [46, 52], [53, 57], [58, 59], [60, 65], [66, 69], [69, 70], [70, 72], [72, 73], [73, 76], [77, 87], [88, 94], [95, 102], [103, 107], [108, 116], [117, 119], [120, 127], [128, 132], [133, 141], [141, 142], [143, 153], [154, 162], [163, 167], [168, 172], [173, 178], [178, 179], [179, 183], [184, 190], [190, 191]]}
{"doc_key": "ai-test-351", "ner": [[7, 7, "researcher"], [9, 9, "researcher"], [11, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "1980s", "and", "early", "1990s", ",", "Werbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Pearlmutter", "and", "others", "developed", "various", "methods", "to", "do", "this", "."], "sentence-detokenized": "In the 1980s and early 1990s, Werbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Pearlmutter and others developed various methods to do this.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 16], [17, 22], [23, 28], [28, 29], [30, 36], [36, 37], [38, 46], [46, 47], [48, 56], [56, 57], [58, 64], [65, 76], [76, 77], [78, 82], [83, 93], [93, 94], [95, 106], [107, 110], [111, 117], [118, 127], [128, 135], [136, 143], [144, 146], [147, 149], [150, 154], [154, 155]]}
{"doc_key": "ai-test-352", "ner": [[1, 1, "organisation"], [2, 3, "organisation"], [8, 8, "organisation"], [11, 12, "task"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 8, 8, "role", "licenses_from", false, false], [2, 3, 1, 1, "named", "", false, false], [17, 17, 1, 1, "origin", "", false, false], [17, 17, 11, 12, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["|", "Apple", "Apple", "Inc.", "originally", "licensed", "software", "from", "Nuance", "to", "enable", "speech", "recognition", "for", "its", "digital", "assistant", "Siri", "."], "sentence-detokenized": "| Apple Apple Inc. originally licensed software from Nuance to enable speech recognition for its digital assistant Siri.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 18], [19, 29], [30, 38], [39, 47], [48, 52], [53, 59], [60, 62], [63, 69], [70, 76], [77, 88], [89, 92], [93, 96], [97, 104], [105, 114], [115, 119], [119, 120]]}
{"doc_key": "ai-test-353", "ner": [[0, 0, "organisation"], [3, 4, "misc"], [7, 8, "person"], [12, 13, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 4, "role", "releases_movies_in_genre", false, false], [7, 8, 0, 0, "role", "directs_for", false, false], [12, 13, 0, 0, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "released", "several", "3D", "westerns", "produced", "by", "Sam", "Katzman", "and", "directed", "by", "William", "Castle", "."], "sentence-detokenized": "Columbia released several 3D westerns produced by Sam Katzman and directed by William Castle.", "token2charspan": [[0, 8], [9, 17], [18, 25], [26, 28], [29, 37], [38, 46], [47, 49], [50, 53], [54, 61], [62, 65], [66, 74], [75, 77], [78, 85], [86, 92], [92, 93]]}
{"doc_key": "ai-test-354", "ner": [[6, 7, "field"], [9, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "includes", "knowledge", "and", "research", "in", "computer", "science", ",", "linguistics", "and", "computer", "engineering", "."], "sentence-detokenized": "It includes knowledge and research in computer science, linguistics and computer engineering.", "token2charspan": [[0, 2], [3, 11], [12, 21], [22, 25], [26, 34], [35, 37], [38, 46], [47, 54], [54, 55], [56, 67], [68, 71], [72, 80], [81, 92], [92, 93]]}
{"doc_key": "ai-test-355", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", "is", "an", "example", "of", "an", "R", "code", ":"], "sentence-detokenized": "Here is an example of an R code:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 24], [25, 26], [27, 31], [31, 32]]}
{"doc_key": "ai-test-356", "ner": [[0, 2, "metrics"], [8, 10, "metrics"], [12, 12, "metrics"], [16, 18, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 8, 10, "part-of", "plotted_into", false, false], [0, 2, 16, 18, "part-of", "plotted_into", false, false], [12, 12, 8, 10, "named", "", false, false], [20, 20, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "ROC", "curve", "is", "created", "by", "plotting", "the", "true", "positive", "rate", "(", "TPR", ")", "against", "the", "false", "positive", "rate", "(", "FPR", ")", "at", "different", "threshold", "values", "."], "sentence-detokenized": "The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at different threshold values.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 24], [25, 27], [28, 36], [37, 40], [41, 45], [46, 54], [55, 59], [60, 61], [61, 64], [64, 65], [66, 73], [74, 77], [78, 83], [84, 92], [93, 97], [98, 99], [99, 102], [102, 103], [104, 106], [107, 116], [117, 126], [127, 133], [133, 134]]}
{"doc_key": "ai-test-357", "ner": [[11, 12, "field"], [3, 4, "researcher"], [6, 8, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 11, 12, "related-to", "researches_field", false, false], [6, 8, 11, 12, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Research", "stagnated", "after", "Marvin", "Minsky", "and", "Seymour", "Papert", "'s", "research", "on", "machine", "learning", "(", "1969", ")", ","], "sentence-detokenized": "Research stagnated after Marvin Minsky and Seymour Papert's research on machine learning (1969),", "token2charspan": [[0, 8], [9, 18], [19, 24], [25, 31], [32, 38], [39, 42], [43, 50], [51, 57], [57, 59], [60, 68], [69, 71], [72, 79], [80, 88], [89, 90], [90, 94], [94, 95], [95, 96]]}
{"doc_key": "ai-test-358", "ner": [[9, 10, "programlang"], [12, 14, "product"], [16, 17, "programlang"], [19, 19, "product"], [21, 21, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "environments", "used", "to", "build", "DAQ", "applications", "include", "ladder", "logic", ",", "Visual", "C", "++", ",", "Visual", "Basic", ",", "LabVIEW", "and", "MATLAB", "."], "sentence-detokenized": "Other programming environments used to build DAQ applications include ladder logic, Visual C++, Visual Basic, LabVIEW and MATLAB.", "token2charspan": [[0, 5], [6, 17], [18, 30], [31, 35], [36, 38], [39, 44], [45, 48], [49, 61], [62, 69], [70, 76], [77, 82], [82, 83], [84, 90], [91, 92], [92, 94], [94, 95], [96, 102], [103, 108], [108, 109], [110, 117], [118, 121], [122, 128], [128, 129]]}
{"doc_key": "ai-test-359", "ner": [[15, 18, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "metric", "was", "developed", "to", "address", "some", "of", "the", "problems", "found", "in", "the", "more", "popular", "BLEU", "metric", "and", "to", "achieve", "a", "good", "correlation", "with", "human", "judgements", "at", "sentence", "or", "segment", "level", "."], "sentence-detokenized": "The metric was developed to address some of the problems found in the more popular BLEU metric and to achieve a good correlation with human judgements at sentence or segment level.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 24], [25, 27], [28, 35], [36, 40], [41, 43], [44, 47], [48, 56], [57, 62], [63, 65], [66, 69], [70, 74], [75, 82], [83, 87], [88, 94], [95, 98], [99, 101], [102, 109], [110, 111], [112, 116], [117, 128], [129, 133], [134, 139], [140, 150], [151, 153], [154, 162], [163, 165], [166, 173], [174, 179], [179, 180]]}
{"doc_key": "ai-test-360", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "the", "semantic", "correlations", "between", "successive", "video", "images", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and long short-term memory are often used to exploit the semantic correlations between successive video images.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [83, 88], [88, 89], [89, 93], [94, 100], [101, 104], [105, 110], [111, 115], [116, 118], [119, 126], [127, 130], [131, 139], [140, 152], [153, 160], [161, 171], [172, 177], [178, 184], [184, 185]]}
{"doc_key": "ai-test-361", "ner": [[7, 7, "product"], [14, 19, "product"], [39, 40, "product"]], "ner_mapping_to_source": [1, 2, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Mass", "-", "produced", "printed", "circuit", "boards", "(", "PCBs", ")", "are", "manufactured", "almost", "exclusively", "by", "pick", "-", "and", "-", "place", "robots", ",", "typically", "with", "SCARA", "manipulators", ",", "which", "remove", "small", "electronic", "components", "from", "strips", "or", "trays", "and", "place", "them", "on", "the", "boards", "with", "great", "accuracy", "."], "sentence-detokenized": "Mass-produced printed circuit boards (PCBs) are manufactured almost exclusively by pick-and-place robots, typically with SCARA manipulators, which remove small electronic components from strips or trays and place them on the boards with great accuracy.", "token2charspan": [[0, 4], [4, 5], [5, 13], [14, 21], [22, 29], [30, 36], [37, 38], [38, 42], [42, 43], [44, 47], [48, 60], [61, 67], [68, 79], [80, 82], [83, 87], [87, 88], [88, 91], [91, 92], [92, 97], [98, 104], [104, 105], [106, 115], [116, 120], [121, 126], [127, 139], [139, 140], [141, 146], [147, 153], [154, 159], [160, 170], [171, 181], [182, 186], [187, 193], [194, 196], [197, 202], [203, 206], [207, 212], [213, 217], [218, 220], [221, 224], [225, 231], [232, 236], [237, 242], [243, 251], [251, 252]]}
{"doc_key": "ai-test-362", "ner": [[4, 5, "field"], [15, 15, "algorithm"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 29, "researcher"], [36, 37, "algorithm"], [39, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 15, 4, 5, "part-of", "", false, false], [15, 15, 20, 21, "origin", "", false, false], [15, 15, 23, 24, "origin", "", false, false], [15, 15, 26, 29, "origin", "", false, false], [15, 15, 36, 37, "type-of", "", false, false], [36, 37, 39, 40, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "the", "context", "of", "machine", "learning", ",", "where", "it", "is", "most", "widely", "used", "today", ",", "LDA", "was", "independently", "rediscovered", "by", "David", "Blei", ",", "Andrew", "Ng", "and", "Michael", "I", ".", "Jordan", "in", "2003", "and", "presented", "as", "a", "graphical", "model", "for", "topic", "discovery", "."], "sentence-detokenized": "In the context of machine learning, where it is most widely used today, LDA was independently rediscovered by David Blei, Andrew Ng and Michael I. Jordan in 2003 and presented as a graphical model for topic discovery.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 25], [26, 34], [34, 35], [36, 41], [42, 44], [45, 47], [48, 52], [53, 59], [60, 64], [65, 70], [70, 71], [72, 75], [76, 79], [80, 93], [94, 106], [107, 109], [110, 115], [116, 120], [120, 121], [122, 128], [129, 131], [132, 135], [136, 143], [144, 145], [145, 146], [147, 153], [154, 156], [157, 161], [162, 165], [166, 175], [176, 178], [179, 180], [181, 190], [191, 196], [197, 200], [201, 206], [207, 216], [216, 217]]}
{"doc_key": "ai-test-363", "ner": [[9, 9, "task"], [12, 12, "misc"], [16, 16, "metrics"], [18, 18, "metrics"], [20, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 12, 12, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "measured", "performance", "on", "test", "data", "from", "eight", "na\u00efve", "WSIs", "across", "different", "tauopathies", "resulted", "in", "a", "recall", ",", "precision", "and", "F1", "score", "of", "0.92", ",", "0.72", "and", "0.81", ",", "respectively", "."], "sentence-detokenized": "The measured performance on test data from eight na\u00efve WSIs across different tauopathies resulted in a recall, precision and F1 score of 0.92, 0.72 and 0.81, respectively.", "token2charspan": [[0, 3], [4, 12], [13, 24], [25, 27], [28, 32], [33, 37], [38, 42], [43, 48], [49, 54], [55, 59], [60, 66], [67, 76], [77, 88], [89, 97], [98, 100], [101, 102], [103, 109], [109, 110], [111, 120], [121, 124], [125, 127], [128, 133], [134, 136], [137, 141], [141, 142], [143, 147], [148, 151], [152, 156], [156, 157], [158, 170], [170, 171]]}
{"doc_key": "ai-test-364", "ner": [[7, 8, "field"], [16, 17, "task"]], "ner_mapping_to_source": [1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Using", "advanced", "AR", "technologies", "(", "e.g.", "adding", "computer", "vision", ",", "integrating", "AR", "cameras", "in", "smartphones", "and", "object", "recognition", ")", ",", "the", "information", "about", "the", "user", "'s", "surrounding", "real", "world", "becomes", "interactive", "and", "digitally", "manipulated", "."], "sentence-detokenized": "Using advanced AR technologies (e.g. adding computer vision, integrating AR cameras in smartphones and object recognition), the information about the user's surrounding real world becomes interactive and digitally manipulated.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 30], [31, 32], [32, 36], [37, 43], [44, 52], [53, 59], [59, 60], [61, 72], [73, 75], [76, 83], [84, 86], [87, 98], [99, 102], [103, 109], [110, 121], [121, 122], [122, 123], [124, 127], [128, 139], [140, 145], [146, 149], [150, 154], [154, 156], [157, 168], [169, 173], [174, 179], [180, 187], [188, 199], [200, 203], [204, 213], [214, 225], [225, 226]]}
{"doc_key": "ai-test-365", "ner": [[3, 3, "researcher"], [8, 8, "organisation"], [16, 18, "field"], [27, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 8, 8, "role", "forms_company", false, false], [8, 8, 16, 18, "related-to", "works_with", false, false], [8, 8, 27, 29, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2014", ",", "Schmidhuber", "formed", "a", "company", ",", "Nnaisense", ",", "to", "work", "on", "commercial", "applications", "of", "artificial", "intelligence", "in", "areas", "such", "as", "finance", ",", "heavy", "industry", "and", "self", "-", "driving", "cars", "."], "sentence-detokenized": "In 2014, Schmidhuber formed a company, Nnaisense, to work on commercial applications of artificial intelligence in areas such as finance, heavy industry and self-driving cars.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 27], [28, 29], [30, 37], [37, 38], [39, 48], [48, 49], [50, 52], [53, 57], [58, 60], [61, 71], [72, 84], [85, 87], [88, 98], [99, 111], [112, 114], [115, 120], [121, 125], [126, 128], [129, 136], [136, 137], [138, 143], [144, 152], [153, 156], [157, 161], [161, 162], [162, 169], [170, 174], [174, 175]]}
{"doc_key": "ai-test-366", "ner": [[24, 26, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "not", "only", "changes", "the", "results", "of", "all", "subsequent", "tests", "of", "the", "retained", "explanatory", "model", ",", "but", "can", "also", "introduce", "bias", "and", "change", "the", "mean", "square", "error", "of", "the", "estimate", "."], "sentence-detokenized": "This not only changes the results of all subsequent tests of the retained explanatory model, but can also introduce bias and change the mean square error of the estimate.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 21], [22, 25], [26, 33], [34, 36], [37, 40], [41, 51], [52, 57], [58, 60], [61, 64], [65, 73], [74, 85], [86, 91], [91, 92], [93, 96], [97, 100], [101, 105], [106, 115], [116, 120], [121, 124], [125, 131], [132, 135], [136, 140], [141, 147], [148, 153], [154, 156], [157, 160], [161, 169], [169, 170]]}
{"doc_key": "ai-test-367", "ner": [[0, 0, "misc"], [9, 10, "task"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Bigrams", "are", "used", "in", "most", "successful", "language", "models", "for", "speech", "recognition", "."], "sentence-detokenized": "Bigrams are used in most successful language models for speech recognition.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 19], [20, 24], [25, 35], [36, 44], [45, 51], [52, 55], [56, 62], [63, 74], [74, 75]]}
{"doc_key": "ai-test-368", "ner": [[3, 4, "field"], [8, 10, "misc"], [16, 18, "misc"], [24, 26, "organisation"], [29, 31, "misc"], [37, 40, "organisation"], [43, 45, "misc"], [51, 55, "organisation"], [58, 60, "misc"], [66, 68, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[8, 10, 3, 4, "topic", "", false, false], [16, 18, 24, 26, "origin", "", false, false], [29, 31, 37, 40, "origin", "", false, false], [43, 45, 51, 55, "origin", "", false, false], [58, 60, 66, 68, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["His", "research", "in", "cognitive", "psychology", "has", "won", "the", "Early", "Career", "Award", "(", "1984", ")", "and", "the", "Boyd", "McCandless", "Award", "(", "1986", ")", "from", "the", "American", "Psychological", "Association", ",", "the", "Troland", "Research", "Award", "(", "1993", ")", "from", "the", "National", "Academy", "of", "Sciences", ",", "the", "Henry", "Dale", "Prize", "(", "2004", ")", "from", "the", "Royal", "Institution", "of", "Great", "Britain", "and", "the", "George", "Miller", "Prize", "(", "2010", ")", "from", "the", "Cognitive", "Neuroscience", "Society", "."], "sentence-detokenized": "His research in cognitive psychology has won the Early Career Award (1984) and the Boyd McCandless Award (1986) from the American Psychological Association, the Troland Research Award (1993) from the National Academy of Sciences, the Henry Dale Prize (2004) from the Royal Institution of Great Britain and the George Miller Prize (2010) from the Cognitive Neuroscience Society.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 25], [26, 36], [37, 40], [41, 44], [45, 48], [49, 54], [55, 61], [62, 67], [68, 69], [69, 73], [73, 74], [75, 78], [79, 82], [83, 87], [88, 98], [99, 104], [105, 106], [106, 110], [110, 111], [112, 116], [117, 120], [121, 129], [130, 143], [144, 155], [155, 156], [157, 160], [161, 168], [169, 177], [178, 183], [184, 185], [185, 189], [189, 190], [191, 195], [196, 199], [200, 208], [209, 216], [217, 219], [220, 228], [228, 229], [230, 233], [234, 239], [240, 244], [245, 250], [251, 252], [252, 256], [256, 257], [258, 262], [263, 266], [267, 272], [273, 284], [285, 287], [288, 293], [294, 301], [302, 305], [306, 309], [310, 316], [317, 323], [324, 329], [330, 331], [331, 335], [335, 336], [337, 341], [342, 345], [346, 355], [356, 368], [369, 376], [376, 377]]}
{"doc_key": "ai-test-369", "ner": [[1, 1, "misc"], [7, 7, "misc"], [9, 11, "product"], [15, 15, "researcher"], [17, 17, "researcher"], [24, 25, "researcher"], [27, 28, "researcher"], [30, 31, "task"], [33, 36, "researcher"], [38, 42, "researcher"], [43, 44, "task"], [46, 46, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[1, 1, 7, 7, "named", "", false, false], [1, 1, 46, 46, "named", "", false, false], [7, 7, 15, 15, "origin", "", false, false], [7, 7, 17, 17, "origin", "", false, false], [7, 7, 30, 31, "related-to", "used_for", false, false], [9, 11, 7, 7, "usage", "", false, false], [9, 11, 43, 44, "named", "", false, false], [24, 25, 7, 7, "usage", "", false, false], [24, 25, 33, 36, "named", "same", false, false], [27, 28, 7, 7, "usage", "", false, false], [27, 28, 38, 42, "named", "same", false, false], [43, 44, 46, 46, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["An", "eigenface", "(", "The", "approach", "of", "using", "eigenfaces", "for", "face", "recognition", "systems", "was", "developed", "by", "Sirovich", "and", "Kirby", "(", "1987", ")", "and", "used", "by", "Matthew", "Turk", "and", "Alex", "Pentland", "for", "face", "classification", ".", "Turk", ",", "Matthew", "A.", "and", "Pentland", ",", "Alex", "P", ".", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "An eigenface (The approach of using eigenfaces for face recognition systems was developed by Sirovich and Kirby (1987) and used by Matthew Turk and Alex Pentland for face classification. Turk, Matthew A. and Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 2], [3, 12], [13, 14], [14, 17], [18, 26], [27, 29], [30, 35], [36, 46], [47, 50], [51, 55], [56, 67], [68, 75], [76, 79], [80, 89], [90, 92], [93, 101], [102, 105], [106, 111], [112, 113], [113, 117], [117, 118], [119, 122], [123, 127], [128, 130], [131, 138], [139, 143], [144, 147], [148, 152], [153, 161], [162, 165], [166, 170], [171, 185], [185, 186], [187, 191], [191, 192], [193, 200], [201, 203], [204, 207], [208, 216], [216, 217], [218, 222], [223, 224], [224, 225], [226, 230], [231, 242], [243, 248], [249, 259], [259, 260]]}
{"doc_key": "ai-test-370", "ner": [[4, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "lexical", "dictionary", "like", "Word", "Net", "can", "then", "be", "used", "to", "understand", "the", "context", "."], "sentence-detokenized": "A lexical dictionary like WordNet can then be used to understand the context.", "token2charspan": [[0, 1], [2, 9], [10, 20], [21, 25], [26, 30], [30, 33], [34, 37], [38, 42], [43, 45], [46, 50], [51, 53], [54, 64], [65, 68], [69, 76], [76, 77]]}
{"doc_key": "ai-test-371", "ner": [[0, 2, "misc"], [8, 8, "misc"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 8, 8, "part-of", "", false, false], [8, 8, 15, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hyponymy", "is", "the", "most", "frequently", "coded", "relation", "between", "synsets", "used", "in", "lexical", "databases", "such", "as", "WordNet", "."], "sentence-detokenized": "Hyponymy is the most frequently coded relation between synsets used in lexical databases such as WordNet.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 20], [21, 31], [32, 37], [38, 46], [47, 54], [55, 62], [63, 67], [68, 70], [71, 78], [79, 88], [89, 93], [94, 96], [97, 104], [104, 105]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [6, 7, "programlang"], [9, 9, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 7, "general-affiliation", "", false, false], [0, 0, 9, 9, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "offers", "open", "source", "libraries", "in", "C", "++", "and", "Java", ",", "but", "many", "clients", "rely", "on", "community", "-", "developed", "libraries", ",", "such", "as", "libraries", "with", "built", "-", "in", "functions", "to", "retrieve", "data", "(", "array", "-", "style", ")", "from", "DAP", "servers", "."], "sentence-detokenized": "OPeNDAP offers open source libraries in C++ and Java, but many clients rely on community-developed libraries, such as libraries with built-in functions to retrieve data (array-style) from DAP servers.", "token2charspan": [[0, 7], [8, 14], [15, 19], [20, 26], [27, 36], [37, 39], [40, 41], [41, 43], [44, 47], [48, 52], [52, 53], [54, 57], [58, 62], [63, 70], [71, 75], [76, 78], [79, 88], [88, 89], [89, 98], [99, 108], [108, 109], [110, 114], [115, 117], [118, 127], [128, 132], [133, 138], [138, 139], [139, 141], [142, 151], [152, 154], [155, 163], [164, 168], [169, 170], [170, 175], [175, 176], [176, 181], [181, 182], [183, 187], [188, 191], [192, 199], [199, 200]]}
{"doc_key": "ai-test-373", "ner": [[4, 5, "misc"], [7, 8, "product"], [13, 14, "country"], [31, 32, "misc"], [46, 47, "organisation"], [48, 48, "product"], [50, 51, "organisation"], [52, 55, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 13, 14, "opposite", "", false, false], [7, 8, 13, 14, "artifact", "", false, false], [31, 32, 7, 8, "part-of", "", false, false], [48, 48, 46, 47, "artifact", "", false, false], [52, 55, 50, 51, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["On", "this", "page", ",", "Samurai", "Damashii", "exaggerated", "the", "Senkousha", "as", "a", "crystallization", "of", "China", "'s", "four", "thousand", "years", "of", "scientific", "knowledge", ",", "commented", "on", "its", "crude", "design", "(", "e.g.", ",", "the", "Chinese", "cannon", "on", "the", "crotch", ")", ",", "and", "placed", "it", "s", "image", "among", "pictures", "of", "Honda", "'s", "ASIMO", "and", "Sony", "'s", "QRIO", "SDR", "-", "3X", "to", "contrast", "it", "."], "sentence-detokenized": "On this page, Samurai Damashii exaggerated the Senkousha as a crystallization of China's four thousand years of scientific knowledge, commented on its crude design (e.g., the Chinese cannon on the crotch), and placed its image among pictures of Honda's ASIMO and Sony's QRIO SDR-3X to contrast it.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 21], [22, 30], [31, 42], [43, 46], [47, 56], [57, 59], [60, 61], [62, 77], [78, 80], [81, 86], [86, 88], [89, 93], [94, 102], [103, 108], [109, 111], [112, 122], [123, 132], [132, 133], [134, 143], [144, 146], [147, 150], [151, 156], [157, 163], [164, 165], [165, 169], [169, 170], [171, 174], [175, 182], [183, 189], [190, 192], [193, 196], [197, 203], [203, 204], [204, 205], [206, 209], [210, 216], [217, 219], [219, 220], [221, 226], [227, 232], [233, 241], [242, 244], [245, 250], [250, 252], [253, 258], [259, 262], [263, 267], [267, 269], [270, 274], [275, 278], [278, 279], [279, 281], [282, 284], [285, 293], [294, 296], [296, 297]]}
{"doc_key": "ai-test-374", "ner": [[7, 7, "algorithm"], [19, 19, "product"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 19, 19, "part-of", "includes_functionality_of", false, false], [7, 7, 21, 21, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "also", "many", "programming", "libraries", "containing", "neural", "network", "functions", "that", "can", "be", "used", "in", "custom", "implementations", "(", "e.g.", "TensorFlow", ",", "Theano", ",", "etc.", ")", "."], "sentence-detokenized": "There are also many programming libraries containing neural network functions that can be used in custom implementations (e.g. TensorFlow, Theano, etc.).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 19], [20, 31], [32, 41], [42, 52], [53, 59], [60, 67], [68, 77], [78, 82], [83, 86], [87, 89], [90, 94], [95, 97], [98, 104], [105, 120], [121, 122], [122, 126], [127, 137], [137, 138], [139, 145], [145, 146], [147, 151], [151, 152], [152, 153]]}
{"doc_key": "ai-test-375", "ner": [[6, 9, "conference"], [11, 11, "organisation"], [13, 19, "conference"], [21, 21, "conference"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", ",", "IEEE", ",", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "IAPR", "and", "SPIE", "."], "sentence-detokenized": "He is a member of the Association for Computing Machinery, IEEE, American Association for the Advancement of Science, IAPR and SPIE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 33], [34, 37], [38, 47], [48, 57], [57, 58], [59, 63], [63, 64], [65, 73], [74, 85], [86, 89], [90, 93], [94, 105], [106, 108], [109, 116], [116, 117], [118, 122], [123, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-test-376", "ner": [[3, 3, "organisation"], [7, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 7, 8, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "trial", "in", "RET", "in", "2011", "of", "face", "recognition", "cameras", "fitted", "to", "trams", "ensured", "that", "people", "excluded", "from", "the", "city", "'s", "trams", "did", "n't", "sneak", "in", "anyway", "."], "sentence-detokenized": "A trial in RET in 2011 of face recognition cameras fitted to trams ensured that people excluded from the city's trams didn't sneak in anyway.", "token2charspan": [[0, 1], [2, 7], [8, 10], [11, 14], [15, 17], [18, 22], [23, 25], [26, 30], [31, 42], [43, 50], [51, 57], [58, 60], [61, 66], [67, 74], [75, 79], [80, 86], [87, 95], [96, 100], [101, 104], [105, 109], [109, 111], [112, 117], [118, 121], [121, 124], [125, 130], [131, 133], [134, 140], [140, 141]]}
{"doc_key": "ai-test-377", "ner": [[7, 7, "person"], [9, 9, "organisation"], [16, 17, "person"], [19, 20, "person"], [26, 27, "person"], [29, 30, "person"], [32, 33, "person"], [35, 36, "person"], [38, 39, "person"], [41, 42, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 7, 9, 9, "role", "works_for", false, false], [16, 17, 9, 9, "role", "works_for", false, false], [19, 20, 9, 9, "role", "works_for", false, false], [26, 27, 9, 9, "role", "works_for", false, false], [29, 30, 9, 9, "role", "works_for", false, false], [32, 33, 9, 9, "role", "works_for", false, false], [35, 36, 9, 9, "role", "works_for", false, false], [38, 39, 9, 9, "role", "works_for", false, false], [41, 42, 9, 9, "role", "works_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "film", ",", "adapted", "from", "the", "popular", "Cole", "Porter", "Broadway", "musical", ",", "starred", "MGM", "songbird", "team", "Howard", "Keel", "and", "Kathryn", "Grayson", ",", "who", "were", "supported", "by", "Ann", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Van", ",", "James", "Whitmore", ",", "Kurt", "Kasznar", "and", "Tommy", "Rall", "."], "sentence-detokenized": "The film, adapted from the popular Cole Porter Broadway musical, starred MGM songbird team Howard Keel and Kathryn Grayson, who were supported by Ann Miller, Keenan Wynn, Bobby Van, James Whitmore, Kurt Kasznar and Tommy Rall.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 17], [18, 22], [23, 26], [27, 34], [35, 39], [40, 46], [47, 55], [56, 63], [63, 64], [65, 72], [73, 76], [77, 85], [86, 90], [91, 97], [98, 102], [103, 106], [107, 114], [115, 122], [122, 123], [124, 127], [128, 132], [133, 142], [143, 145], [146, 149], [150, 156], [156, 157], [158, 164], [165, 169], [169, 170], [171, 176], [177, 180], [180, 181], [182, 187], [188, 196], [196, 197], [198, 202], [203, 210], [211, 214], [215, 220], [221, 225], [225, 226]]}
{"doc_key": "ai-test-378", "ner": [[21, 25, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "applications", "should", "streamline", "call", "flows", ",", "minimise", "the", "number", "of", "calls", ",", "eliminate", "unnecessary", "repetitions", "and", "allow", "for", "an", "elaborate", "dialogue", "system", "with", "mixed", "initiatives", ",", "allowing", "callers", "to", "enter", "more", "information", "in", "a", "single", "utterance", "and", "in", "any", "order", "or", "combination", "."], "sentence-detokenized": "Such applications should streamline call flows, minimise the number of calls, eliminate unnecessary repetitions and allow for an elaborate dialogue system with mixed initiatives, allowing callers to enter more information in a single utterance and in any order or combination.", "token2charspan": [[0, 4], [5, 17], [18, 24], [25, 35], [36, 40], [41, 46], [46, 47], [48, 56], [57, 60], [61, 67], [68, 70], [71, 76], [76, 77], [78, 87], [88, 99], [100, 111], [112, 115], [116, 121], [122, 125], [126, 128], [129, 138], [139, 147], [148, 154], [155, 159], [160, 165], [166, 177], [177, 178], [179, 187], [188, 195], [196, 198], [199, 204], [205, 209], [210, 221], [222, 224], [225, 226], [227, 233], [234, 243], [244, 247], [248, 250], [251, 254], [255, 260], [261, 263], [264, 275], [275, 276]]}
{"doc_key": "ai-test-379", "ner": [[9, 12, "algorithm"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["As", "such", ",", "traditional", "gradient", "descent", "methods", "(", "or", "stochastic", "gradient", "descent", "methods", ")", "can", "be", "adapted", "where", "instead", "of", "taking", "a", "step", "in", "the", "direction", "of", "the", "function", "'s", "gradient", ",", "a", "step", "is", "taken", "in", "the", "direction", "of", "a", "vector", "selected", "from", "the", "function", "'s", "subgradient", "."], "sentence-detokenized": "As such, traditional gradient descent methods (or stochastic gradient descent methods) can be adapted where instead of taking a step in the direction of the function's gradient, a step is taken in the direction of a vector selected from the function's subgradient.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 29], [30, 37], [38, 45], [46, 47], [47, 49], [50, 60], [61, 69], [70, 77], [78, 85], [85, 86], [87, 90], [91, 93], [94, 101], [102, 107], [108, 115], [116, 118], [119, 125], [126, 127], [128, 132], [133, 135], [136, 139], [140, 149], [150, 152], [153, 156], [157, 165], [165, 167], [168, 176], [176, 177], [178, 179], [180, 184], [185, 187], [188, 193], [194, 196], [197, 200], [201, 210], [211, 213], [214, 215], [216, 222], [223, 231], [232, 236], [237, 240], [241, 249], [249, 251], [252, 263], [263, 264]]}
{"doc_key": "ai-test-380", "ner": [[11, 15, "metrics"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "it", "is", "assumed", "that", "the", "distortion", "is", "measured", "as", "the", "mean", "of", "the", "squared", "error", ",", "the", "distortion", "D", "is", "given", "by", ":"], "sentence-detokenized": "If it is assumed that the distortion is measured as the mean of the squared error, the distortion D is given by:", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 16], [17, 21], [22, 25], [26, 36], [37, 39], [40, 48], [49, 51], [52, 55], [56, 60], [61, 63], [64, 67], [68, 75], [76, 81], [81, 82], [83, 86], [87, 97], [98, 99], [100, 102], [103, 108], [109, 111], [111, 112]]}
{"doc_key": "ai-test-381", "ner": [[0, 0, "algorithm"], [18, 19, "task"], [21, 22, "task"], [28, 29, "product"]], "ner_mapping_to_source": [0, 2, 3, 5], "relations": [[18, 19, 0, 0, "part-of", "", false, false], [21, 22, 0, 0, "part-of", "", false, false], [28, 29, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [1, 2, 4], "sentence": ["MLPs", "were", "a", "popular", "machine", "learning", "solution", "in", "the", "1980s", "and", "found", "application", "in", "various", "fields", "such", "as", "speech", "recognition", ",", "image", "recognition", "and", "machine", "translation", "software", ",", "neural", "networks", "."], "sentence-detokenized": "MLPs were a popular machine learning solution in the 1980s and found application in various fields such as speech recognition, image recognition and machine translation software, neural networks.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 19], [20, 27], [28, 36], [37, 45], [46, 48], [49, 52], [53, 58], [59, 62], [63, 68], [69, 80], [81, 83], [84, 91], [92, 98], [99, 103], [104, 106], [107, 113], [114, 125], [125, 126], [127, 132], [133, 144], [145, 148], [149, 156], [157, 168], [169, 177], [177, 178], [179, 185], [186, 194], [194, 195]]}
{"doc_key": "ai-test-382", "ner": [[0, 0, "researcher"], [3, 3, "misc"], [6, 8, "university"], [15, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 8, "physical", "", false, false], [0, 0, 6, 8, "role", "", false, false], [3, 3, 0, 0, "origin", "", false, false], [15, 17, 0, 0, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "received", "his", "PhD", "from", "the", "University", "of", "Toronto", "in", "1979", "under", "the", "supervision", "of", "C.", "Raymond", "Perrault", ","], "sentence-detokenized": "Allen received his PhD from the University of Toronto in 1979 under the supervision of C. Raymond Perrault,", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 22], [23, 27], [28, 31], [32, 42], [43, 45], [46, 53], [54, 56], [57, 61], [62, 67], [68, 71], [72, 83], [84, 86], [87, 89], [90, 97], [98, 106], [106, 107]]}
{"doc_key": "ai-test-383", "ner": [[0, 0, "product"], [5, 7, "field"], [9, 9, "product"], [11, 11, "product"], [13, 13, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6], "relations": [[0, 0, 5, 7, "related-to", "supports", false, false], [9, 9, 5, 7, "type-of", "", true, false], [11, 11, 5, 7, "type-of", "", true, false], [13, 13, 5, 7, "type-of", "", true, false], [23, 23, 5, 7, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5], "sentence": ["OpenCV", "supports", "some", "models", "from", "deep", "learning", "frameworks", "like", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "after", "conversion", "to", "an", "ONNX", "model", ")", "and", "Caffe", "according", "to", "a", "defined", "list", "of", "supported", "layers", "."], "sentence-detokenized": "OpenCV supports some models from deep learning frameworks like TensorFlow, Torch, PyTorch (after conversion to an ONNX model) and Caffe according to a defined list of supported layers.", "token2charspan": [[0, 6], [7, 15], [16, 20], [21, 27], [28, 32], [33, 37], [38, 46], [47, 57], [58, 62], [63, 73], [73, 74], [75, 80], [80, 81], [82, 89], [90, 91], [91, 96], [97, 107], [108, 110], [111, 113], [114, 118], [119, 124], [124, 125], [126, 129], [130, 135], [136, 145], [146, 148], [149, 150], [151, 158], [159, 163], [164, 166], [167, 176], [177, 183], [183, 184]]}
{"doc_key": "ai-test-384", "ner": [[0, 2, "researcher"], [8, 11, "organisation"], [13, 13, "organisation"], [16, 20, "organisation"], [24, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 8, 11, "role", "", false, false], [0, 2, 16, 20, "role", "", false, false], [0, 2, 24, 24, "related-to", "lectures_in", false, false], [13, 13, 8, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Christensen", "is", "a", "former", "founding", "chair", "of", "the", "European", "Robotics", "Research", "Network", "(", "EURON", ")", "and", "IEEE", "Robotics", "and", "Automation", "Society", "Distinguished", "Lecturer", "in", "Robotics", "."], "sentence-detokenized": "Christensen is a former founding chair of the European Robotics Research Network (EURON) and IEEE Robotics and Automation Society Distinguished Lecturer in Robotics.", "token2charspan": [[0, 11], [12, 14], [15, 16], [17, 23], [24, 32], [33, 38], [39, 41], [42, 45], [46, 54], [55, 63], [64, 72], [73, 80], [81, 82], [82, 87], [87, 88], [89, 92], [93, 97], [98, 106], [107, 110], [111, 121], [122, 129], [130, 143], [144, 152], [153, 155], [156, 164], [164, 165]]}
{"doc_key": "ai-test-385", "ner": [[7, 7, "field"], [9, 11, "university"], [13, 13, "location"], [15, 18, "country"], [23, 24, "misc"], [26, 26, "field"], [29, 32, "organisation"], [34, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[9, 11, 13, 13, "physical", "", false, false], [13, 13, 15, 18, "physical", "", false, false], [23, 24, 26, 26, "topic", "", false, false], [29, 32, 34, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "received", "his", "master", "'s", "degree", "in", "mathematics", "from", "Samarkand", "State", "University", ",", "Samarkand", ",", "Uzbek", "Soviet", "Socialist", "Republic", "in", "1958", "and", "a", "doctoral", "degree", "in", "statistics", "from", "the", "Institute", "of", "Control", "Sciences", ",", "Moscow", "in", "1964", "."], "sentence-detokenized": "He received his master's degree in mathematics from Samarkand State University, Samarkand, Uzbek Soviet Socialist Republic in 1958 and a doctoral degree in statistics from the Institute of Control Sciences, Moscow in 1964.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 22], [22, 24], [25, 31], [32, 34], [35, 46], [47, 51], [52, 61], [62, 67], [68, 78], [78, 79], [80, 89], [89, 90], [91, 96], [97, 103], [104, 113], [114, 122], [123, 125], [126, 130], [131, 134], [135, 136], [137, 145], [146, 152], [153, 155], [156, 166], [167, 171], [172, 175], [176, 185], [186, 188], [189, 196], [197, 205], [205, 206], [207, 213], [214, 216], [217, 221], [221, 222]]}
{"doc_key": "ai-test-386", "ner": [[4, 7, "organisation"], [11, 13, "product"], [29, 30, "field"], [32, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 7, 29, 30, "usage", "", false, false], [4, 7, 32, 34, "usage", "", false, false], [11, 13, 4, 7, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["However", ",", "work", "at", "Cycorp", "is", "increasingly", "focused", "on", "enabling", "the", "Cyc", "system", "to", "communicate", "with", "end-users", "in", "natural", "language", "and", "assist", "in", "the", "ongoing", "knowledge", "creation", "process", "through", "machine", "learning", "and", "natural", "language", "understanding", "."], "sentence-detokenized": "However, work at Cycorp is increasingly focused on enabling the Cyc system to communicate with end-users in natural language and assist in the ongoing knowledge creation process through machine learning and natural language understanding.", "token2charspan": [[0, 7], [7, 8], [9, 13], [14, 16], [17, 23], [24, 26], [27, 39], [40, 47], [48, 50], [51, 59], [60, 63], [64, 67], [68, 74], [75, 77], [78, 89], [90, 94], [95, 104], [105, 107], [108, 115], [116, 124], [125, 128], [129, 135], [136, 138], [139, 142], [143, 150], [151, 160], [161, 169], [170, 177], [178, 185], [186, 193], [194, 202], [203, 206], [207, 214], [215, 223], [224, 237], [237, 238]]}
{"doc_key": "ai-test-387", "ner": [[54, 54, "metrics"], [56, 56, "metrics"], [58, 58, "metrics"], [60, 61, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "if", "the", "best", "suited", "classifier", "is", "searched", "for", "the", "problem", ",", "the", "training", "dataset", "is", "used", "to", "train", "the", "potential", "algorithms", ",", "the", "validation", "dataset", "is", "used", "to", "compare", "their", "performance", "and", "decide", "which", "algorithm", "to", "choose", ",", "and", "finally", "the", "test", "dataset", "is", "used", "to", "obtain", "performance", "properties", "such", "as", "accuracy", ",", "sensitivity", ",", "specificity", ",", "F-", "measure", ",", "etc", "."], "sentence-detokenized": "For example, if the best suited classifier is searched for the problem, the training dataset is used to train the potential algorithms, the validation dataset is used to compare their performance and decide which algorithm to choose, and finally the test dataset is used to obtain performance properties such as accuracy, sensitivity, specificity, F-measure, etc.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 19], [20, 24], [25, 31], [32, 42], [43, 45], [46, 54], [55, 58], [59, 62], [63, 70], [70, 71], [72, 75], [76, 84], [85, 92], [93, 95], [96, 100], [101, 103], [104, 109], [110, 113], [114, 123], [124, 134], [134, 135], [136, 139], [140, 150], [151, 158], [159, 161], [162, 166], [167, 169], [170, 177], [178, 183], [184, 195], [196, 199], [200, 206], [207, 212], [213, 222], [223, 225], [226, 232], [232, 233], [234, 237], [238, 245], [246, 249], [250, 254], [255, 262], [263, 265], [266, 270], [271, 273], [274, 280], [281, 292], [293, 303], [304, 308], [309, 311], [312, 320], [320, 321], [322, 333], [333, 334], [335, 346], [346, 347], [348, 350], [350, 357], [357, 358], [359, 362], [362, 363]]}
{"doc_key": "ai-test-388", "ner": [[1, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "squared", "error", "is", "0.15", "."], "sentence-detokenized": "The mean squared error is 0.15.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 25], [26, 30], [30, 31]]}
{"doc_key": "ai-test-389", "ner": [[7, 11, "misc"], [4, 4, "organisation"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 7, 11, "role", "", false, false], [14, 15, 7, 11, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1979", ",", "the", "IEEE", "organised", "a", "Micromouse", "competition", ",", "which", "was", "featured", "in", "Spectrum", "magazine", "."], "sentence-detokenized": "In 1979, the IEEE organised a Micromouse competition, which was featured in Spectrum magazine.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 27], [28, 29], [30, 40], [41, 52], [52, 53], [54, 59], [60, 63], [64, 72], [73, 75], [76, 84], [85, 93], [93, 94]]}
{"doc_key": "ai-test-390", "ner": [[0, 3, "algorithm"], [12, 14, "task"], [16, 17, "task"], [19, 20, "task"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Gabor", "area", "is", "very", "useful", "in", "image", "processing", "applications", "such", "as", "optical", "character", "recognition", ",", "iris", "recognition", "and", "fingerprint", "recognition", "."], "sentence-detokenized": "The Gabor area is very useful in image processing applications such as optical character recognition, iris recognition and fingerprint recognition.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 17], [18, 22], [23, 29], [30, 32], [33, 38], [39, 49], [50, 62], [63, 67], [68, 70], [71, 78], [79, 88], [89, 100], [100, 101], [102, 106], [107, 118], [119, 122], [123, 134], [135, 146], [146, 147]]}
{"doc_key": "ai-test-391", "ner": [[7, 7, "programlang"], [9, 9, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", "via", "high", "-", "level", "interfaces", "to", "Java", "and", "Tcl", "."], "sentence-detokenized": "or via high-level interfaces to Java and Tcl.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [12, 17], [18, 28], [29, 31], [32, 36], [37, 40], [41, 44], [44, 45]]}
{"doc_key": "ai-test-392", "ner": [[20, 21, "field"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "recent", "research", ",", "kernel", "-", "based", "methods", "such", "as", "support", "vector", "machines", "have", "been", "shown", "to", "be", "superior", "in", "supervised", "methods", "."], "sentence-detokenized": "In recent research, kernel-based methods such as support vector machines have been shown to be superior in supervised methods.", "token2charspan": [[0, 2], [3, 9], [10, 18], [18, 19], [20, 26], [26, 27], [27, 32], [33, 40], [41, 45], [46, 48], [49, 56], [57, 63], [64, 72], [73, 77], [78, 82], [83, 88], [89, 91], [92, 94], [95, 103], [104, 106], [107, 117], [118, 125], [125, 126]]}
{"doc_key": "ai-test-393", "ner": [[14, 14, "misc"], [23, 23, "researcher"], [25, 25, "researcher"], [33, 33, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 33, 33, "usage", "", false, false], [25, 25, 33, 33, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["To", "illustrate", "the", "basic", "principles", "of", "bagging", ",", "an", "analysis", "of", "the", "relationship", "between", "ozone", "and", "temperature", "is", "shown", "below", "(", "data", "from", "Rousseeuw", "and", "Leroy", "(", "1986", ")", ",", "analysis", "performed", "in", "R", ")", "."], "sentence-detokenized": "To illustrate the basic principles of bagging, an analysis of the relationship between ozone and temperature is shown below (data from Rousseeuw and Leroy (1986), analysis performed in R).", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 23], [24, 34], [35, 37], [38, 45], [45, 46], [47, 49], [50, 58], [59, 61], [62, 65], [66, 78], [79, 86], [87, 92], [93, 96], [97, 108], [109, 111], [112, 117], [118, 123], [124, 125], [125, 129], [130, 134], [135, 144], [145, 148], [149, 154], [155, 156], [156, 160], [160, 161], [161, 162], [163, 171], [172, 181], [182, 184], [185, 186], [186, 187], [187, 188]]}
{"doc_key": "ai-test-394", "ner": [[0, 1, "organisation"], [20, 22, "product"]], "ner_mapping_to_source": [0, 3], "relations": [[20, 22, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [2], "sentence": ["Denso", "Wave", "is", "a", "subsidiary", "producing", "automatic", "identification", "products", "(", "barcode", "readers", "and", "related", "products", ")", ",", "industrial", "robots", "and", "programmable", "logic", "controllers", "."], "sentence-detokenized": "Denso Wave is a subsidiary producing automatic identification products (barcode readers and related products), industrial robots and programmable logic controllers.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 15], [16, 26], [27, 36], [37, 46], [47, 61], [62, 70], [71, 72], [72, 79], [80, 87], [88, 91], [92, 99], [100, 108], [108, 109], [109, 110], [111, 121], [122, 128], [129, 132], [133, 145], [146, 151], [152, 163], [163, 164]]}
{"doc_key": "ai-test-395", "ner": [[1, 4, "metrics"], [7, 9, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 4, 18, 18, "compare", "", false, false], [7, 9, 1, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Whereas", "the", "Bilingual", "Evaluation", "Understudy", "simply", "calculates", "the", "precision", "of", "ethnograms", "by", "giving", "equal", "weight", "to", "each", ",", "NIST", "also", "calculates", "how", "informative", "a", "particularngram", "is", "."], "sentence-detokenized": "Whereas the Bilingual Evaluation Understudy simply calculates the precision of ethnograms by giving equal weight to each, NIST also calculates how informative a particularngram is.", "token2charspan": [[0, 7], [8, 11], [12, 21], [22, 32], [33, 43], [44, 50], [51, 61], [62, 65], [66, 75], [76, 78], [79, 89], [90, 92], [93, 99], [100, 105], [106, 112], [113, 115], [116, 120], [120, 121], [122, 126], [127, 131], [132, 142], [143, 146], [147, 158], [159, 160], [161, 176], [177, 179], [179, 180]]}
{"doc_key": "ai-test-396", "ner": [[13, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "are", "mainly", "used", "to", "calculate", "the", "probability", "of", "a", "tree", "(", "in", "Bayesian", "and", "maximum", "likelihood", "tree", "estimation", "methods", ")", "and", "to", "estimate", "the", "evolutionary", "distance", "between", "sequences", "from", "the", "observed", "differences", "between", "the", "sequences", "."], "sentence-detokenized": "They are mainly used to calculate the probability of a tree (in Bayesian and maximum likelihood tree estimation methods) and to estimate the evolutionary distance between sequences from the observed differences between the sequences.", "token2charspan": [[0, 4], [5, 8], [9, 15], [16, 20], [21, 23], [24, 33], [34, 37], [38, 49], [50, 52], [53, 54], [55, 59], [60, 61], [61, 63], [64, 72], [73, 76], [77, 84], [85, 95], [96, 100], [101, 111], [112, 119], [119, 120], [121, 124], [125, 127], [128, 136], [137, 140], [141, 153], [154, 162], [163, 170], [171, 180], [181, 185], [186, 189], [190, 198], [199, 210], [211, 218], [219, 222], [223, 232], [232, 233]]}
{"doc_key": "ai-test-397", "ner": [[0, 3, "conference"], [18, 19, "misc"], [21, 21, "misc"], [44, 45, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 21, 18, 19, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Audio", "Engineering", "Society", "recommends", "48", "kHz", "sampling", "rate", "for", "most", "applications", ",", "but", "recognizes", "44.1", "kHz", "for", "Compact", "Disc", "(", "CD", ")", "and", "other", "consumer", "applications", ",", "32", "kHz", "for", "transmission", "-", "related", "applications", ",", "and", "96", "kHz", "for", "higher", "bandwidth", "or", "relaxed", "anti-aliasing", "filtering", "."], "sentence-detokenized": "The Audio Engineering Society recommends 48 kHz sampling rate for most applications, but recognizes 44.1 kHz for Compact Disc (CD) and other consumer applications, 32 kHz for transmission-related applications, and 96 kHz for higher bandwidth or relaxed anti-aliasing filtering.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 29], [30, 40], [41, 43], [44, 47], [48, 56], [57, 61], [62, 65], [66, 70], [71, 83], [83, 84], [85, 88], [89, 99], [100, 104], [105, 108], [109, 112], [113, 120], [121, 125], [126, 127], [127, 129], [129, 130], [131, 134], [135, 140], [141, 149], [150, 162], [162, 163], [164, 166], [167, 170], [171, 174], [175, 187], [187, 188], [188, 195], [196, 208], [208, 209], [210, 213], [214, 216], [217, 220], [221, 224], [225, 231], [232, 241], [242, 244], [245, 252], [253, 266], [267, 276], [276, 277]]}
{"doc_key": "ai-test-398", "ner": [[12, 12, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Resources", "for", "the", "affectivity", "of", "words", "and", "concepts", "have", "been", "created", "for", "WordNet", "{", "{", "cite", "journal"], "sentence-detokenized": "Resources for the affectivity of words and concepts have been created for WordNet {{cite journal", "token2charspan": [[0, 9], [10, 13], [14, 17], [18, 29], [30, 32], [33, 38], [39, 42], [43, 51], [52, 56], [57, 61], [62, 69], [70, 73], [74, 81], [82, 83], [83, 84], [84, 88], [89, 96]]}
{"doc_key": "ai-test-399", "ner": [[1, 4, "misc"], [23, 24, "person"], [29, 32, "person"], [39, 41, "person"], [47, 50, "organisation"], [69, 70, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[29, 32, 39, 41, "role", "acts_in", false, false], [47, 50, 39, 41, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "red", "and", "green", "anaglyph", ",", "the", "audience", "was", "presented", "with", "three", "test", "reels", ",", "which", "included", "rural", "scenes", ",", "audition", "footage", "of", "Marie", "Doro", ",", "a", "segment", "with", "John", "B", ".", "Mason", "playing", "a", "series", "of", "passages", "from", "Jim", "the", "Penman", "(", "a", "film", "released", "by", "Famous", "Players", "-", "Lasky", "that", "year", ",", "but", "not", "in", "3D", ")", ",", "Oriental", "dancers", ",", "and", "a", "reel", "of", "footage", "of", "Niagara", "Falls", "."], "sentence-detokenized": "In red and green anaglyph, the audience was presented with three test reels, which included rural scenes, audition footage of Marie Doro, a segment with John B. Mason playing a series of passages from Jim the Penman (a film released by Famous Players-Lasky that year, but not in 3D), Oriental dancers, and a reel of footage of Niagara Falls.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 16], [17, 25], [25, 26], [27, 30], [31, 39], [40, 43], [44, 53], [54, 58], [59, 64], [65, 69], [70, 75], [75, 76], [77, 82], [83, 91], [92, 97], [98, 104], [104, 105], [106, 114], [115, 122], [123, 125], [126, 131], [132, 136], [136, 137], [138, 139], [140, 147], [148, 152], [153, 157], [158, 159], [159, 160], [161, 166], [167, 174], [175, 176], [177, 183], [184, 186], [187, 195], [196, 200], [201, 204], [205, 208], [209, 215], [216, 217], [217, 218], [219, 223], [224, 232], [233, 235], [236, 242], [243, 250], [250, 251], [251, 256], [257, 261], [262, 266], [266, 267], [268, 271], [272, 275], [276, 278], [279, 281], [281, 282], [282, 283], [284, 292], [293, 300], [300, 301], [302, 305], [306, 307], [308, 312], [313, 315], [316, 323], [324, 326], [327, 334], [335, 340], [340, 341]]}
{"doc_key": "ai-test-400", "ner": [[7, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "special", "way", "of", "implementing", "maximum", "likelihood", "estimation", "for", "this", "problem", "."], "sentence-detokenized": "This is a special way of implementing maximum likelihood estimation for this problem.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 17], [18, 21], [22, 24], [25, 37], [38, 45], [46, 56], [57, 67], [68, 71], [72, 76], [77, 84], [84, 85]]}
{"doc_key": "ai-test-401", "ner": [[0, 4, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Crawler", "-", "friendly", "web", "servers", ",", "and", "it", "integrates", "the", "functionality", "of", "sitemaps", "and", "RSS", "feeds", "into", "a", "decentralised", "mechanism", "that", "enables", "computational", "biologists", "and", "bioinformaticians", "to", "openly", "publish", "and", "retrieve", "metadata", "about", "biomedical", "resources", "."], "sentence-detokenized": "Crawler-friendly web servers, and it integrates the functionality of sitemaps and RSS feeds into a decentralised mechanism that enables computational biologists and bioinformaticians to openly publish and retrieve metadata about biomedical resources.", "token2charspan": [[0, 7], [7, 8], [8, 16], [17, 20], [21, 28], [28, 29], [30, 33], [34, 36], [37, 47], [48, 51], [52, 65], [66, 68], [69, 77], [78, 81], [82, 85], [86, 91], [92, 96], [97, 98], [99, 112], [113, 122], [123, 127], [128, 135], [136, 149], [150, 160], [161, 164], [165, 182], [183, 185], [186, 192], [193, 200], [201, 204], [205, 213], [214, 222], [223, 228], [229, 239], [240, 249], [249, 250]]}
{"doc_key": "ai-test-402", "ner": [[4, 11, "misc"], [13, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "covered", "by", "American", "National", "Standards", "Institute", "/", "NISO", "standard", "Z39.50", "and", "International", "Organization", "for", "Standardization", "standard", "23950", "."], "sentence-detokenized": "It is covered by American National Standards Institute/NISO standard Z39.50 and International Organization for Standardization standard 23950.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 25], [26, 34], [35, 44], [45, 54], [54, 55], [55, 59], [60, 68], [69, 75], [76, 79], [80, 93], [94, 106], [107, 110], [111, 126], [127, 135], [136, 141], [141, 142]]}
{"doc_key": "ai-test-403", "ner": [[13, 18, "misc"], [23, 23, "metrics"], [26, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "encoder", "and", "decoder", "are", "trained", "to", "take", "a", "phrase", "and", "reproduce", "the", "one", "-", "hot", "distribution", "of", "a", "corresponding", "paraphrase", "by", "minimizing", "perplexity", "using", "simple", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The encoder and decoder are trained to take a phrase and reproduce the one-hot distribution of a corresponding paraphrase by minimizing perplexity using simple stochastic gradient descent.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 27], [28, 35], [36, 38], [39, 43], [44, 45], [46, 52], [53, 56], [57, 66], [67, 70], [71, 74], [74, 75], [75, 78], [79, 91], [92, 94], [95, 96], [97, 110], [111, 121], [122, 124], [125, 135], [136, 146], [147, 152], [153, 159], [160, 170], [171, 179], [180, 187], [187, 188]]}
{"doc_key": "ai-test-404", "ner": [[8, 10, "task"], [12, 17, "task"], [27, 31, "task"], [33, 39, "task"], [41, 47, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "typical", "applications", "of", "pattern", "recognition", "techniques", "are", "automatic", "speech", "recognition", ",", "classification", "of", "text", "into", "multiple", "categories", "(", "e.g.", "spam", "/", "non", "-spam", "emails", ")", ",", "handwriting", "recognition", "on", "mail", "envelopes", ",", "automatic", "recognition", "of", "images", "of", "human", "faces", "or", "extraction", "of", "handwriting", "images", "from", "medical", "forms", "."], "sentence-detokenized": "Other typical applications of pattern recognition techniques are automatic speech recognition, classification of text into multiple categories (e.g. spam/non-spam emails), handwriting recognition on mail envelopes, automatic recognition of images of human faces or extraction of handwriting images from medical forms.", "token2charspan": [[0, 5], [6, 13], [14, 26], [27, 29], [30, 37], [38, 49], [50, 60], [61, 64], [65, 74], [75, 81], [82, 93], [93, 94], [95, 109], [110, 112], [113, 117], [118, 122], [123, 131], [132, 142], [143, 144], [144, 148], [149, 153], [153, 154], [154, 157], [157, 162], [163, 169], [169, 170], [170, 171], [172, 183], [184, 195], [196, 198], [199, 203], [204, 213], [213, 214], [215, 224], [225, 236], [237, 239], [240, 246], [247, 249], [250, 255], [256, 261], [262, 264], [265, 275], [276, 278], [279, 290], [291, 297], [298, 302], [303, 310], [311, 316], [316, 317]]}
{"doc_key": "ai-test-405", "ner": [[0, 2, "algorithm"], [13, 14, "field"], [16, 17, "task"], [19, 20, "task"], [22, 24, "task"], [26, 29, "task"], [32, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 14, 0, 2, "usage", "", false, false], [16, 17, 0, 2, "usage", "", false, false], [19, 20, 0, 2, "usage", "", false, false], [22, 24, 0, 2, "usage", "", false, false], [26, 29, 0, 2, "usage", "", false, false], [32, 33, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Artificial", "neural", "networks", "have", "been", "used", "for", "a", "variety", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "board", "and", "video", "games", ",", "and", "medical", "diagnosis", "."], "sentence-detokenized": "Artificial neural networks have been used for a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, board and video games, and medical diagnosis.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 31], [32, 36], [37, 41], [42, 45], [46, 47], [48, 55], [56, 58], [59, 64], [64, 65], [66, 75], [76, 84], [85, 91], [91, 92], [93, 99], [100, 111], [111, 112], [113, 120], [121, 132], [132, 133], [134, 140], [141, 148], [149, 158], [158, 159], [160, 165], [166, 169], [170, 175], [176, 181], [181, 182], [183, 186], [187, 194], [195, 204], [204, 205]]}
{"doc_key": "ai-test-406", "ner": [[2, 3, "organisation"], [4, 4, "product"], [19, 19, "organisation"], [20, 21, "product"], [23, 23, "product"], [25, 27, "product"], [29, 29, "product"], [31, 31, "programlang"], [36, 37, "field"], [46, 46, "algorithm"], [48, 48, "algorithm"], [54, 54, "product"], [61, 62, "task"], [69, 70, "algorithm"], [73, 73, "product"], [75, 75, "product"], [77, 78, "product"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 17, 18, 19], "relations": [[4, 4, 2, 3, "origin", "", false, false], [31, 31, 36, 37, "related-to", "used_for", false, false], [46, 46, 31, 31, "part-of", "", true, false], [48, 48, 31, 31, "part-of", "", true, false], [54, 54, 61, 62, "related-to", "used_for", false, false], [69, 70, 54, 54, "part-of", "", false, false]], "relations_mapping_to_source": [0, 3, 4, 6, 10, 11], "sentence": ["Examples", "include", "Salford", "Systems", "CART", "(", "which", "has", "licensed", "the", "proprietary", "code", "from", "the", "original", "CART", "authors", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "an", "open", "source", "statistical", "computing", "environment", "which", "includes", "several", "CART", "implementations", "such", "as", "rpart", ",", "party", "and", "randomForest", "packages", ")", ",", "Weka", "(", "a", "free", "and", "open", "source", "data", "mining", "package", "which", "includes", "many", "algorithms", "for", "decision", "trees", ")", ",", "Orange", ",", "KNIME", ",", "Microsoft", "SQL", "Server", "programming", "language", ")", "."], "sentence-detokenized": "Examples include Salford Systems CART (which has licensed the proprietary code from the original CART authors), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (an open source statistical computing environment which includes several CART implementations such as rpart, party and randomForest packages), Weka (a free and open source data mining package which includes many algorithms for decision trees), Orange, KNIME, Microsoft SQL Server programming language).", "token2charspan": [[0, 8], [9, 16], [17, 24], [25, 32], [33, 37], [38, 39], [39, 44], [45, 48], [49, 57], [58, 61], [62, 73], [74, 78], [79, 83], [84, 87], [88, 96], [97, 101], [102, 109], [109, 110], [110, 111], [112, 115], [116, 120], [121, 128], [128, 129], [130, 140], [140, 141], [142, 145], [146, 156], [157, 162], [162, 163], [164, 170], [170, 171], [172, 173], [174, 175], [175, 177], [178, 182], [183, 189], [190, 201], [202, 211], [212, 223], [224, 229], [230, 238], [239, 246], [247, 251], [252, 267], [268, 272], [273, 275], [276, 281], [281, 282], [283, 288], [289, 292], [293, 305], [306, 314], [314, 315], [315, 316], [317, 321], [322, 323], [323, 324], [325, 329], [330, 333], [334, 338], [339, 345], [346, 350], [351, 357], [358, 365], [366, 371], [372, 380], [381, 385], [386, 396], [397, 400], [401, 409], [410, 415], [415, 416], [416, 417], [418, 424], [424, 425], [426, 431], [431, 432], [433, 442], [443, 446], [447, 453], [454, 465], [466, 474], [474, 475], [475, 476]]}
{"doc_key": "ai-test-407", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [10, 11, "researcher"], [13, 14, "university"], [16, 17, "researcher"], [19, 22, "organisation"], [25, 25, "organisation"], [33, 35, "researcher"], [37, 39, "researcher"], [41, 42, "organisation"], [55, 59, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 10, 11, "origin", "", false, false], [0, 2, 16, 17, "origin", "", false, false], [0, 2, 33, 35, "origin", "", false, false], [0, 2, 37, 39, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [10, 11, 13, 14, "physical", "", false, false], [10, 11, 13, 14, "role", "", false, false], [16, 17, 19, 22, "physical", "", false, false], [16, 17, 19, 22, "role", "", false, false], [25, 25, 19, 22, "named", "", false, false], [33, 35, 41, 42, "physical", "", false, false], [33, 35, 41, 42, "role", "", false, false], [37, 39, 41, 42, "physical", "", false, false], [37, 39, 41, 42, "role", "", false, false], [55, 59, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", "was", "first", "developed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", "and", "then", "further", "developed", "by", "Bishnu", "S.", "Atal", "and", "Manfred", "R.", "Schroeder", "at", "Bell", "Labs", "in", "the", "early", "and", "mid-1970s", "and", "became", "the", "basis", "for", "the", "first", "DSP", "chips", "for", "speech", "synthesis", "in", "the", "late", "1970s", "."], "sentence-detokenized": "Linear predictive coding (LPC) was first developed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966 and then further developed by Bishnu S. Atal and Manfred R. Schroeder at Bell Labs in the early and mid-1970s and became the basis for the first DSP chips for speech synthesis in the late 1970s.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [31, 34], [35, 40], [41, 50], [51, 53], [54, 62], [63, 70], [71, 73], [74, 80], [81, 91], [92, 95], [96, 101], [102, 107], [108, 110], [111, 117], [118, 127], [128, 131], [132, 141], [142, 143], [143, 146], [146, 147], [148, 150], [151, 155], [156, 159], [160, 164], [165, 172], [173, 182], [183, 185], [186, 192], [193, 195], [196, 200], [201, 204], [205, 212], [213, 215], [216, 225], [226, 228], [229, 233], [234, 238], [239, 241], [242, 245], [246, 251], [252, 255], [256, 265], [266, 269], [270, 276], [277, 280], [281, 286], [287, 290], [291, 294], [295, 300], [301, 304], [305, 310], [311, 314], [315, 321], [322, 331], [332, 334], [335, 338], [339, 343], [344, 349], [349, 350]]}
{"doc_key": "ai-test-408", "ner": [[1, 3, "metrics"], [8, 8, "metrics"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 1, 3, "part-of", "", false, false], [10, 10, 1, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "F", "-", "score", "is", "a", "combination", "of", "precision", "and", "recall", ",", "resulting", "in", "a", "single", "score", "."], "sentence-detokenized": "An F-score is a combination of precision and recall, resulting in a single score.", "token2charspan": [[0, 2], [3, 4], [4, 5], [5, 10], [11, 13], [14, 15], [16, 27], [28, 30], [31, 40], [41, 44], [45, 51], [51, 52], [53, 62], [63, 65], [66, 67], [68, 74], [75, 80], [80, 81]]}
{"doc_key": "ai-test-409", "ner": [[8, 11, "task"], [16, 18, "product"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Image", "analysis", "tasks", "can", "be", "as", "simple", "as", "reading", "barcodes", "d", "tags", "or", "as", "advanced", "as", "facial", "recognition", "systems", "."], "sentence-detokenized": "Image analysis tasks can be as simple as reading barcodes d tags or as advanced as facial recognition systems.", "token2charspan": [[0, 5], [6, 14], [15, 20], [21, 24], [25, 27], [28, 30], [31, 37], [38, 40], [41, 48], [49, 57], [58, 59], [60, 64], [65, 67], [68, 70], [71, 79], [80, 82], [83, 89], [90, 101], [102, 109], [109, 110]]}
{"doc_key": "ai-test-410", "ner": [[5, 7, "algorithm"], [25, 26, "algorithm"], [33, 35, "algorithm"], [39, 39, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[33, 35, 25, 26, "type-of", "", false, false], [39, 39, 33, 35, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "special", "case", "of", "linear", "support", "vector", "machines", "can", "be", "solved", "more", "efficiently", "using", "the", "same", "kind", "of", "algorithms", "for", "optimizing", "its", "close", "cousin", ",", "logistic", "regression", ";", "this", "class", "of", "algorithms", "includes", "stochastic", "gradient", "descent", "(", "e.g.", ",", "PEGASOS", ")", "."], "sentence-detokenized": "The special case of linear support vector machines can be solved more efficiently using the same kind of algorithms for optimizing its close cousin, logistic regression; this class of algorithms includes stochastic gradient descent (e.g., PEGASOS).", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 19], [20, 26], [27, 34], [35, 41], [42, 50], [51, 54], [55, 57], [58, 64], [65, 69], [70, 81], [82, 87], [88, 91], [92, 96], [97, 101], [102, 104], [105, 115], [116, 119], [120, 130], [131, 134], [135, 140], [141, 147], [147, 148], [149, 157], [158, 168], [168, 169], [170, 174], [175, 180], [181, 183], [184, 194], [195, 203], [204, 214], [215, 223], [224, 231], [232, 233], [233, 237], [237, 238], [239, 246], [246, 247], [247, 248]]}
{"doc_key": "ai-test-411", "ner": [[1, 1, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "Siri", "on", "an", "iOS", "device", "is", "asked", "Do", "you", "have", "a", "pet", "?", "one", "of", "the", "answers", "is", "I", "used", "to", "have", "an", "AIBO", "."], "sentence-detokenized": "When Siri on an iOS device is asked Do you have a pet? one of the answers is I used to have an AIBO.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 15], [16, 19], [20, 26], [27, 29], [30, 35], [36, 38], [39, 42], [43, 47], [48, 49], [50, 53], [53, 54], [55, 58], [59, 61], [62, 65], [66, 73], [74, 76], [77, 78], [79, 83], [84, 86], [87, 91], [92, 94], [95, 99], [99, 100]]}
{"doc_key": "ai-test-412", "ner": [[1, 2, "task"], [5, 7, "metrics"], [10, 10, "metrics"], [13, 14, "metrics"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 7, 1, 2, "part-of", "", false, false], [10, 10, 5, 7, "named", "", false, false], [13, 14, 1, 2, "part-of", "", false, false], [17, 17, 13, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "information", "retrieval", ",", "the", "positive", "predictive", "value", "is", "called", "precision", ",", "and", "the", "sensitivity", "is", "called", "recall", "."], "sentence-detokenized": "In information retrieval, the positive predictive value is called precision, and the sensitivity is called recall.", "token2charspan": [[0, 2], [3, 14], [15, 24], [24, 25], [26, 29], [30, 38], [39, 49], [50, 55], [56, 58], [59, 65], [66, 75], [75, 76], [77, 80], [81, 84], [85, 96], [97, 99], [100, 106], [107, 113], [113, 114]]}
{"doc_key": "ai-test-413", "ner": [[8, 9, "field"], [11, 11, "task"], [13, 13, "task"], [15, 16, "task"], [30, 31, "task"], [33, 34, "task"], [36, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 11, 8, 9, "part-of", "task_part_of_field", false, false], [13, 13, 8, 9, "part-of", "task_part_of_field", false, false], [15, 16, 8, 9, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["His", "research", "focused", "particularly", "on", "areas", "such", "as", "text", "mining", "(", "extraction", ",", "categorization", ",", "news", "detection", ")", "and", "new", "theoretical", "frameworks", "such", "as", "a", "unified", "utility", "theory", "that", "bridges", "information", "retrieval", ",", "automatic", "summarization", ",", "free", "-", "text", "question", "answering", ",", "and", "related", "tasks", "."], "sentence-detokenized": "His research focused particularly on areas such as text mining (extraction, categorization, news detection) and new theoretical frameworks such as a unified utility theory that bridges information retrieval, automatic summarization, free-text question answering, and related tasks.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 33], [34, 36], [37, 42], [43, 47], [48, 50], [51, 55], [56, 62], [63, 64], [64, 74], [74, 75], [76, 90], [90, 91], [92, 96], [97, 106], [106, 107], [108, 111], [112, 115], [116, 127], [128, 138], [139, 143], [144, 146], [147, 148], [149, 156], [157, 164], [165, 171], [172, 176], [177, 184], [185, 196], [197, 206], [206, 207], [208, 217], [218, 231], [231, 232], [233, 237], [237, 238], [238, 242], [243, 251], [252, 261], [261, 262], [263, 266], [267, 274], [275, 280], [280, 281]]}
{"doc_key": "ai-test-414", "ner": [[3, 4, "product"], [15, 16, "misc"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Delta", "robots", "have", "rotary", "actuators", "mounted", "at", "the", "bottom", "that", "move", "a", "light", ",", "rigid", "parallelogram", "arm", "."], "sentence-detokenized": "Delta robots have rotary actuators mounted at the bottom that move a light, rigid parallelogram arm.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 24], [25, 34], [35, 42], [43, 45], [46, 49], [50, 56], [57, 61], [62, 66], [67, 68], [69, 74], [74, 75], [76, 81], [82, 95], [96, 99], [99, 100]]}
{"doc_key": "ai-test-415", "ner": [[8, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated in a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [64, 66], [67, 76], [77, 83], [84, 86], [87, 94], [94, 95]]}
{"doc_key": "ai-test-416", "ner": [[2, 2, "field"], [30, 31, "task"], [37, 38, "task"], [43, 45, "task"], [47, 49, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[30, 31, 2, 2, "part-of", "task_part_of_field", false, false], [37, 38, 2, 2, "part-of", "task_part_of_field", false, false], [43, 45, 2, 2, "part-of", "task_part_of_field", false, false], [47, 49, 2, 2, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "real", "data", "mining", "task", "is", "the", "semi-automatic", "or", "automatic", "analysis", "of", "large", "data", "sets", "in", "order", "to", "extract", "unknown", ",", "interesting", "patterns", "such", "as", "groups", "of", "data", "records", "(", "cluster", "analysis", ")", ",", "unusual", "records", "(", "anomaly", "detection", ")", "and", "dependencies", "(", "association", "rule", "mining", ",", "sequential", "pattern", "mining", ")", "."], "sentence-detokenized": "The real data mining task is the semi-automatic or automatic analysis of large data sets in order to extract unknown, interesting patterns such as groups of data records (cluster analysis), unusual records (anomaly detection) and dependencies (association rule mining, sequential pattern mining).", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 20], [21, 25], [26, 28], [29, 32], [33, 47], [48, 50], [51, 60], [61, 69], [70, 72], [73, 78], [79, 83], [84, 88], [89, 91], [92, 97], [98, 100], [101, 108], [109, 116], [116, 117], [118, 129], [130, 138], [139, 143], [144, 146], [147, 153], [154, 156], [157, 161], [162, 169], [170, 171], [171, 178], [179, 187], [187, 188], [188, 189], [190, 197], [198, 205], [206, 207], [207, 214], [215, 224], [224, 225], [226, 229], [230, 242], [243, 244], [244, 255], [256, 260], [261, 267], [267, 268], [269, 279], [280, 287], [288, 294], [294, 295], [295, 296]]}
{"doc_key": "ai-test-417", "ner": [[2, 3, "product"], [5, 11, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 5, 11, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "a", "recommendation", "system", ",", "emotion", "analysis", "has", "proven", "to", "be", "a", "valuable", "technique", "."], "sentence-detokenized": "For a recommendation system, emotion analysis has proven to be a valuable technique.", "token2charspan": [[0, 3], [4, 5], [6, 20], [21, 27], [27, 28], [29, 36], [37, 45], [46, 49], [50, 56], [57, 59], [60, 62], [63, 64], [65, 73], [74, 83], [83, 84]]}
{"doc_key": "ai-test-418", "ner": [[3, 4, "misc"], [38, 39, "location"]], "ner_mapping_to_source": [0, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["By", "chance", ",", "the", "Germans", "had", "chosen", "the", "Wotan", "system", "'s", "operating", "frequency", "very", "badly", ";", "it", "was", "operating", "on", "45", "MHz", ",", "which", "happened", "to", "be", "the", "frequency", "of", "the", "powerful", "but", "dormant", "BBC", "television", "transmitter", "at", "Alexandra", "Palace", "."], "sentence-detokenized": "By chance, the Germans had chosen the Wotan system's operating frequency very badly; it was operating on 45 MHz, which happened to be the frequency of the powerful but dormant BBC television transmitter at Alexandra Palace.", "token2charspan": [[0, 2], [3, 9], [9, 10], [11, 14], [15, 22], [23, 26], [27, 33], [34, 37], [38, 43], [44, 50], [50, 52], [53, 62], [63, 72], [73, 77], [78, 83], [83, 84], [85, 87], [88, 91], [92, 101], [102, 104], [105, 107], [108, 111], [111, 112], [113, 118], [119, 127], [128, 130], [131, 133], [134, 137], [138, 147], [148, 150], [151, 154], [155, 163], [164, 167], [168, 175], [176, 179], [180, 190], [191, 202], [203, 205], [206, 215], [216, 222], [222, 223]]}
{"doc_key": "ai-test-419", "ner": [[8, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated in a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [64, 66], [67, 76], [77, 83], [84, 86], [87, 94], [94, 95]]}
{"doc_key": "ai-test-420", "ner": [[1, 3, "misc"], [8, 9, "misc"], [12, 12, "product"], [14, 14, "product"], [16, 18, "product"], [27, 27, "misc"], [41, 43, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 12, 8, 9, "usage", "", false, false], [14, 14, 8, 9, "usage", "", false, false], [16, 18, 14, 14, "named", "", false, false], [27, 27, 8, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "semantic", "web", "applications", "and", "in", "relatively", "popular", "RDF", "applications", "such", "as", "RSS", "and", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "resources", "tend", "to", "be", "represented", "by", "URIs", "that", "deliberately", "indicate", "and", "can", "be", "used", "to", "access", "actual", "data", "on", "the", "World", "Wide", "Web", "."], "sentence-detokenized": "In semantic web applications and in relatively popular RDF applications such as RSS and FOAF (Friend a Friend), resources tend to be represented by URIs that deliberately indicate and can be used to access actual data on the World Wide Web.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 28], [29, 32], [33, 35], [36, 46], [47, 54], [55, 58], [59, 71], [72, 76], [77, 79], [80, 83], [84, 87], [88, 92], [93, 94], [94, 100], [101, 102], [103, 109], [109, 110], [110, 111], [112, 121], [122, 126], [127, 129], [130, 132], [133, 144], [145, 147], [148, 152], [153, 157], [158, 170], [171, 179], [180, 183], [184, 187], [188, 190], [191, 195], [196, 198], [199, 205], [206, 212], [213, 217], [218, 220], [221, 224], [225, 230], [231, 235], [236, 239], [239, 240]]}
{"doc_key": "ai-test-421", "ner": [[0, 7, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "has", "studied", "this", "issue", "in", "depth"], "sentence-detokenized": "The Association for the Advancement of Artificial Intelligence has studied this issue in depth", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 35], [36, 38], [39, 49], [50, 62], [63, 66], [67, 74], [75, 79], [80, 85], [86, 88], [89, 94]]}
{"doc_key": "ai-test-422", "ner": [[0, 6, "product"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 19, 0, 6, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "speech", "system", "in", "the", "Apple", "Macintosh", "started", "as", "a", "curiosity", "and", "has", "evolved", "into", "a", "fully", "supported", "application", "PlainTalk", "for", "people", "with", "vision", "problems", "."], "sentence-detokenized": "The speech system in the Apple Macintosh started as a curiosity and has evolved into a fully supported application PlainTalk for people with vision problems.", "token2charspan": [[0, 3], [4, 10], [11, 17], [18, 20], [21, 24], [25, 30], [31, 40], [41, 48], [49, 51], [52, 53], [54, 63], [64, 67], [68, 71], [72, 79], [80, 84], [85, 86], [87, 92], [93, 102], [103, 114], [115, 124], [125, 128], [129, 135], [136, 140], [141, 147], [148, 156], [156, 157]]}
{"doc_key": "ai-test-423", "ner": [[7, 7, "field"], [9, 10, "task"], [12, 13, "task"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 7, 7, "part-of", "task_part_of_field", false, false], [12, 13, 7, 7, "part-of", "task_part_of_field", false, false], [15, 16, 7, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Other", "areas", "where", "ontologies", "are", "used", "in", "NLP", "include", "information", "retrieval", ",", "information", "extraction", "and", "automatic", "summarization", "."], "sentence-detokenized": "Other areas where ontologies are used in NLP include information retrieval, information extraction and automatic summarization.", "token2charspan": [[0, 5], [6, 11], [12, 17], [18, 28], [29, 32], [33, 37], [38, 40], [41, 44], [45, 52], [53, 64], [65, 74], [74, 75], [76, 87], [88, 98], [99, 102], [103, 112], [113, 126], [126, 127]]}
{"doc_key": "ai-test-424", "ner": [[7, 15, "organisation"], [18, 22, "organisation"], [25, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Institute", "has", "worked", "closely", "with", "the", "Janelia", "Farm", "Campus", "of", "the", "Howard", "Hughes", "Medical", "Institute", ",", "the", "Allen", "Institute", "for", "Brain", "Science", "and", "the", "National", "Institutes", "of", "Health", "to", "develop", "better", "methods", "for", "reconstructing", "neuronal", "architectures", "."], "sentence-detokenized": "The Institute has worked closely with the Janelia Farm Campus of the Howard Hughes Medical Institute, the Allen Institute for Brain Science and the National Institutes of Health to develop better methods for reconstructing neuronal architectures.", "token2charspan": [[0, 3], [4, 13], [14, 17], [18, 24], [25, 32], [33, 37], [38, 41], [42, 49], [50, 54], [55, 61], [62, 64], [65, 68], [69, 75], [76, 82], [83, 90], [91, 100], [100, 101], [102, 105], [106, 111], [112, 121], [122, 125], [126, 131], [132, 139], [140, 143], [144, 147], [148, 156], [157, 167], [168, 170], [171, 177], [178, 180], [181, 188], [189, 195], [196, 203], [204, 207], [208, 222], [223, 231], [232, 245], [245, 246]]}
{"doc_key": "ai-test-425", "ner": [[2, 2, "organisation"], [5, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 2, 2, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Recently", ",", "Google", "announced", "that", "Google", "Translate", "translates", "about", "enough", "text", "to", "fill", "1", "million", "books", "in", "one", "day", "(", "2012", ")", "."], "sentence-detokenized": "Recently, Google announced that Google Translate translates about enough text to fill 1 million books in one day (2012).", "token2charspan": [[0, 8], [8, 9], [10, 16], [17, 26], [27, 31], [32, 38], [39, 48], [49, 59], [60, 65], [66, 72], [73, 77], [78, 80], [81, 85], [86, 87], [88, 95], [96, 101], [102, 104], [105, 108], [109, 112], [113, 114], [114, 118], [118, 119], [119, 120]]}
{"doc_key": "ai-test-426", "ner": [[13, 13, "country"], [15, 15, "country"], [17, 17, "country"], [19, 19, "country"], [21, 21, "country"], [22, 28, "country"], [35, 36, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Events", "are", "held", "all", "over", "the", "world", "and", "are", "most", "popular", "in", "the", "UK", ",", "USA", ",", "Japan", ",", "Singapore", ",", "India", "and", "South", "Korea", ",", "and", "are", "becoming", "popular", "in", "subcontinent", "countries", "such", "as", "Sri", "Lanka", "."], "sentence-detokenized": "Events are held all over the world and are most popular in the UK, USA, Japan, Singapore, India and South Korea, and are becoming popular in subcontinent countries such as Sri Lanka.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 24], [25, 28], [29, 34], [35, 38], [39, 42], [43, 47], [48, 55], [56, 58], [59, 62], [63, 65], [65, 66], [67, 70], [70, 71], [72, 77], [77, 78], [79, 88], [88, 89], [90, 95], [96, 99], [100, 105], [106, 111], [111, 112], [113, 116], [117, 120], [121, 129], [130, 137], [138, 140], [141, 153], [154, 163], [164, 168], [169, 171], [172, 175], [176, 181], [181, 182]]}
{"doc_key": "ai-test-427", "ner": [[6, 8, "programlang"], [12, 12, "programlang"], [14, 14, "programlang"], [16, 17, "programlang"], [19, 19, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "packages", "are", "primarily", "developed", "in", "R", ",", "but", "sometimes", "also", "in", "Java", ",", "C", ",", "C", "++", "and", "Fortran", "."], "sentence-detokenized": "These packages are primarily developed in R, but sometimes also in Java, C, C++ and Fortran.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 28], [29, 38], [39, 41], [42, 43], [43, 44], [45, 48], [49, 58], [59, 63], [64, 66], [67, 71], [71, 72], [73, 74], [74, 75], [76, 77], [77, 79], [80, 83], [84, 91], [91, 92]]}
{"doc_key": "ai-test-428", "ner": [[4, 18, "conference"], [10, 10, "conference"], [15, 15, "researcher"], [17, 17, "researcher"], [20, 21, "researcher"], [24, 25, "algorithm"], [30, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 10, 4, 18, "named", "", false, false], [15, 15, 4, 18, "physical", "", false, false], [15, 15, 4, 18, "role", "", false, false], [15, 15, 20, 21, "role", "teams_up_with", false, false], [15, 15, 24, 25, "usage", "", false, false], [17, 17, 4, 18, "physical", "", false, false], [17, 17, 4, 18, "role", "", false, false], [17, 17, 20, 21, "role", "teams_up_with", false, false], [17, 17, 24, 25, "usage", "", false, false], [20, 21, 4, 18, "physical", "", false, false], [20, 21, 4, 18, "role", "", false, false], [20, 21, 24, 25, "usage", "", false, false], [24, 25, 30, 35, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["As", "part", "of", "the", "European", "Conference", "on", "Computer", "Vision", "(", "ECCV", ")", "in", "2006", ",", "Dalal", "and", "Triggs", "worked", "with", "Cordelia", "Schmid", "to", "apply", "HOG", "detectors", "to", "the", "problem", "of", "detecting", "people", "in", "movies", "and", "videos", "."], "sentence-detokenized": "As part of the European Conference on Computer Vision (ECCV) in 2006, Dalal and Triggs worked with Cordelia Schmid to apply HOG detectors to the problem of detecting people in movies and videos.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 23], [24, 34], [35, 37], [38, 46], [47, 53], [54, 55], [55, 59], [59, 60], [61, 63], [64, 68], [68, 69], [70, 75], [76, 79], [80, 86], [87, 93], [94, 98], [99, 107], [108, 114], [115, 117], [118, 123], [124, 127], [128, 137], [138, 140], [141, 144], [145, 152], [153, 155], [156, 165], [166, 172], [173, 175], [176, 182], [183, 186], [187, 193], [193, 194]]}
{"doc_key": "ai-test-429", "ner": [[3, 3, "metrics"], [5, 7, "metrics"], [11, 11, "task"], [18, 20, "metrics"], [22, 22, "metrics"], [28, 28, "metrics"], [31, 33, "metrics"], [35, 35, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 3, 11, 11, "related-to", "measured_with", false, false], [5, 7, 11, 11, "related-to", "measured_with", false, false], [18, 20, 11, 11, "related-to", "measured_with", false, false], [22, 22, 18, 20, "named", "", false, false], [28, 28, 18, 20, "named", "", false, false], [35, 35, 31, 33, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "addition", "to", "sensitivity", "and", "specificity", ",", "the", "performance", "of", "a", "binary", "classification", "test", "can", "be", "measured", "by", "positive", "predictive", "value", "(", "PPV", ")", ",", "also", "known", "as", "precision", ",", "and", "negative", "predictive", "value", "(", "NPV", ")", "."], "sentence-detokenized": "In addition to sensitivity and specificity, the performance of a binary classification test can be measured by positive predictive value (PPV), also known as precision, and negative predictive value (NPV).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 42], [42, 43], [44, 47], [48, 59], [60, 62], [63, 64], [65, 71], [72, 86], [87, 91], [92, 95], [96, 98], [99, 107], [108, 110], [111, 119], [120, 130], [131, 136], [137, 138], [138, 141], [141, 142], [142, 143], [144, 148], [149, 154], [155, 157], [158, 167], [167, 168], [169, 172], [173, 181], [182, 192], [193, 198], [199, 200], [200, 203], [203, 204], [204, 205]]}
{"doc_key": "ai-test-430", "ner": [[13, 14, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "models", "can", "give", "partial", "credit", "for", "overlapping", "matches", "(", "e.g.", "using", "the", "Jaccard", "criterion", ")", "."], "sentence-detokenized": "Such models can give partial credit for overlapping matches (e.g. using the Jaccard criterion).", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 28], [29, 35], [36, 39], [40, 51], [52, 59], [60, 61], [61, 65], [66, 71], [72, 75], [76, 83], [84, 93], [93, 94], [94, 95]]}
{"doc_key": "ai-test-431", "ner": [[24, 29, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "case", "of", "estimates", "based", "on", "a", "single", "sample", ",", "it", "also", "highlights", "philosophical", "issues", "and", "possible", "misunderstandings", "related", "to", "the", "use", "of", "maximum", "likelihood", "estimators", "and", "likelihood", "functions", "."], "sentence-detokenized": "In the case of estimates based on a single sample, it also highlights philosophical issues and possible misunderstandings related to the use of maximum likelihood estimators and likelihood functions.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 24], [25, 30], [31, 33], [34, 35], [36, 42], [43, 49], [49, 50], [51, 53], [54, 58], [59, 69], [70, 83], [84, 90], [91, 94], [95, 103], [104, 121], [122, 129], [130, 132], [133, 136], [137, 140], [141, 143], [144, 151], [152, 162], [163, 173], [174, 177], [178, 188], [189, 198], [198, 199]]}
