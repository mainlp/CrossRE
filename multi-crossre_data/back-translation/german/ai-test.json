{"doc_key": "ai-test-1", "ner": [[5, 7, "algorithm"], [9, 9, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "generative", "modelling", "approaches", "include", "Naive", "Bayes", "classifiers", ",", "Gaussian", "mixed", "models", ",", "variational", "auto-encoders", "and", "others", "."], "sentence-detokenized": "Typical generative modelling approaches include Naive Bayes classifiers, Gaussian mixed models, variational auto-encoders and others.", "token2charspan": [[0, 7], [8, 18], [19, 28], [29, 39], [40, 47], [48, 53], [54, 59], [60, 71], [71, 72], [73, 81], [82, 87], [88, 94], [94, 95], [96, 107], [108, 121], [122, 125], [126, 132], [132, 133]]}
{"doc_key": "ai-test-2", "ner": [[5, 5, "organisation"], [10, 10, "conference"], [13, 18, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 10, 10, "role", "", false, false], [13, 18, 10, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Finally", ",", "every", "two", "years", "ELRA", "organises", "a", "major", "conference", "LREC", ",", "the", "International", "Language", "Resources", "and", "Evaluation", "Conference", "."], "sentence-detokenized": "Finally, every two years ELRA organises a major conference LREC, the International Language Resources and Evaluation Conference.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 18], [19, 24], [25, 29], [30, 39], [40, 41], [42, 47], [48, 58], [59, 63], [63, 64], [65, 68], [69, 82], [83, 91], [92, 101], [102, 105], [106, 116], [117, 127], [127, 128]]}
{"doc_key": "ai-test-3", "ner": [[7, 10, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "task", "is", "usually", "to", "derive", "a", "maximum", "likelihood", "estimate", "of", "the", "parameters", "of", "the", "HMM", "from", "the", "output", "sequences", "."], "sentence-detokenized": "The task is usually to derive a maximum likelihood estimate of the parameters of the HMM from the output sequences.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 19], [20, 22], [23, 29], [30, 31], [32, 39], [40, 50], [51, 59], [60, 62], [63, 66], [67, 77], [78, 80], [81, 84], [85, 88], [89, 93], [94, 97], [98, 104], [105, 114], [114, 115]]}
{"doc_key": "ai-test-4", "ner": [[1, 1, "algorithm"], [4, 6, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Unlike", "neural", "networks", "and", "support", "vector", "machines", ",", "the", "AdaBoost", "training", "process", "selects", "only", "those", "features", "known", "to", "improve", "the", "predictive", "power", "of", "the", "model", ",", "reducing", "dimensionality", "and", "potentially", "shortening", "execution", "time", "by", "eliminating", "the", "need", "to", "compute", "irrelevant", "features", "."], "sentence-detokenized": "Unlike neural networks and support vector machines, the AdaBoost training process selects only those features known to improve the predictive power of the model, reducing dimensionality and potentially shortening execution time by eliminating the need to compute irrelevant features.", "token2charspan": [[0, 6], [7, 13], [14, 22], [23, 26], [27, 34], [35, 41], [42, 50], [50, 51], [52, 55], [56, 64], [65, 73], [74, 81], [82, 89], [90, 94], [95, 100], [101, 109], [110, 115], [116, 118], [119, 126], [127, 130], [131, 141], [142, 147], [148, 150], [151, 154], [155, 160], [160, 161], [162, 170], [171, 185], [186, 189], [190, 201], [202, 212], [213, 222], [223, 227], [228, 230], [231, 242], [243, 246], [247, 251], [252, 254], [255, 262], [263, 273], [274, 282], [282, 283]]}
{"doc_key": "ai-test-5", "ner": [[0, 0, "misc"], [11, 13, "misc"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 13, "part-of", "", false, false], [11, 13, 15, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Troponymy", "is", "one", "of", "the", "possible", "relationships", "between", "verbs", "in", "the", "semantic", "network", "of", "the", "Word", "Net", "database", "."], "sentence-detokenized": "Troponymy is one of the possible relationships between verbs in the semantic network of the WordNet database.", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 19], [20, 23], [24, 32], [33, 46], [47, 54], [55, 60], [61, 63], [64, 67], [68, 76], [77, 84], [85, 87], [88, 91], [92, 96], [96, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-test-6", "ner": [[8, 9, "task"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 11, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "framework", "language", "is", "a", "technology", "used", "to", "represent", "knowledge", "in", "artificial", "intelligence", "."], "sentence-detokenized": "A framework language is a technology used to represent knowledge in artificial intelligence.", "token2charspan": [[0, 1], [2, 11], [12, 20], [21, 23], [24, 25], [26, 36], [37, 41], [42, 44], [45, 54], [55, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-7", "ner": [[0, 0, "metrics"], [4, 8, "metrics"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 8, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "Bilingual", "Evaluation", "Understudy", "in", "the", "calculation", "of", "the", "Brevity", "Penalty", ",", "as", "small", "deviations", "in", "translation", "length", "do", "not", "affect", "the", "overall", "score", "as", "much", "."], "sentence-detokenized": "NIST also differs from Bilingual Evaluation Understudy in the calculation of the Brevity Penalty, as small deviations in translation length do not affect the overall score as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 32], [33, 43], [44, 54], [55, 57], [58, 61], [62, 73], [74, 76], [77, 80], [81, 88], [89, 96], [96, 97], [98, 100], [101, 106], [107, 117], [118, 120], [121, 132], [133, 139], [140, 142], [143, 146], [147, 153], [154, 157], [158, 165], [166, 171], [172, 174], [175, 179], [179, 180]]}
{"doc_key": "ai-test-8", "ner": [[16, 17, "algorithm"], [20, 22, "algorithm"], [33, 33, "field"], [42, 47, "algorithm"], [45, 47, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 17, 33, 33, "usage", "", false, false], [20, 22, 33, 33, "usage", "", false, false], [42, 47, 33, 33, "type-of", "", false, false], [45, 47, 33, 33, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "model", "is", "first", "fitted", "to", "a", "training", "data", "set", ".", "The", "model", "(", "e.g.", "a", "neural", "network", "or", "a", "Naive", "Bayes", "classifier", ")", "is", "trained", "on", "the", "training", "data", "set", "using", "a", "supervised", "learning", "method", ",", "e.g.", "optimisation", "methods", "such", "as", "gradient", "descent", "or", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The model is first fitted to a training data set. The model (e.g. a neural network or a Naive Bayes classifier) is trained on the training data set using a supervised learning method, e.g. optimisation methods such as gradient descent or stochastic gradient descent.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 18], [19, 25], [26, 28], [29, 30], [31, 39], [40, 44], [45, 48], [48, 49], [50, 53], [54, 59], [60, 61], [61, 65], [66, 67], [68, 74], [75, 82], [83, 85], [86, 87], [88, 93], [94, 99], [100, 110], [110, 111], [112, 114], [115, 122], [123, 125], [126, 129], [130, 138], [139, 143], [144, 147], [148, 153], [154, 155], [156, 166], [167, 175], [176, 182], [182, 183], [184, 188], [189, 201], [202, 209], [210, 214], [215, 217], [218, 226], [227, 234], [235, 237], [238, 248], [249, 257], [258, 265], [265, 266]]}
{"doc_key": "ai-test-9", "ner": [[0, 0, "product"], [8, 9, "task"], [11, 11, "task"], [13, 15, "task"], [17, 18, "task"], [26, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 0, "usage", "", true, false], [11, 11, 0, 0, "usage", "", true, false], [13, 15, 0, 0, "usage", "", true, false], [17, 18, 0, 0, "usage", "", true, false], [26, 28, 0, 0, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["FrameNet", "has", "been", "used", "in", "applications", "such", "as", "question", "answering", ",", "paraphrasing", ",", "text", "link", "detection", "and", "information", "extraction", "either", "directly", "or", "with", "the", "help", "of", "semantic", "role", "labelling", "tools", "."], "sentence-detokenized": "FrameNet has been used in applications such as question answering, paraphrasing, text link detection and information extraction either directly or with the help of semantic role labelling tools.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 22], [23, 25], [26, 38], [39, 43], [44, 46], [47, 55], [56, 65], [65, 66], [67, 79], [79, 80], [81, 85], [86, 90], [91, 100], [101, 104], [105, 116], [117, 127], [128, 134], [135, 143], [144, 146], [147, 151], [152, 155], [156, 160], [161, 163], [164, 172], [173, 177], [178, 187], [188, 193], [193, 194]]}
{"doc_key": "ai-test-10", "ner": [[11, 11, "misc"], [14, 14, "product"], [17, 17, "misc"], [20, 20, "product"], [23, 24, "field"], [27, 27, "product"], [30, 32, "misc"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [42, 43, "misc"], [46, 47, "product"], [50, 50, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[14, 14, 11, 11, "general-affiliation", "", false, false], [20, 20, 17, 17, "general-affiliation", "", false, false], [27, 27, 23, 24, "general-affiliation", "", false, false], [35, 35, 30, 32, "type-of", "", false, false], [37, 37, 30, 32, "type-of", "", false, false], [39, 39, 30, 32, "type-of", "", false, false], [46, 47, 42, 43, "general-affiliation", "", false, false], [50, 50, 42, 43, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["This", "includes", "programmes", "such", "as", "data", "analysis", "and", "extraction", "tools", ",", "spreadsheets", "(", "e.g.", "Excel", ")", ",", "databases", "(", "e.g.", "Access", ")", ",", "statistical", "analysis", "(", "e.g.", "SAS", ")", ",", "general", "audit", "software", "(", "e.g.", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "business", "intelligence", "(", "e.g.", "Crystal", "Reports", "and", "Business", "Objects", ")", ",", "etc", "."], "sentence-detokenized": "This includes programmes such as data analysis and extraction tools, spreadsheets (e.g. Excel), databases (e.g. Access), statistical analysis (e.g. SAS), general audit software (e.g. ACL, Arbutus, EAS), business intelligence (e.g. Crystal Reports and Business Objects), etc.", "token2charspan": [[0, 4], [5, 13], [14, 24], [25, 29], [30, 32], [33, 37], [38, 46], [47, 50], [51, 61], [62, 67], [67, 68], [69, 81], [82, 83], [83, 87], [88, 93], [93, 94], [94, 95], [96, 105], [106, 107], [107, 111], [112, 118], [118, 119], [119, 120], [121, 132], [133, 141], [142, 143], [143, 147], [148, 151], [151, 152], [152, 153], [154, 161], [162, 167], [168, 176], [177, 178], [178, 182], [183, 186], [186, 187], [188, 195], [195, 196], [197, 200], [200, 201], [201, 202], [203, 211], [212, 224], [225, 226], [226, 230], [231, 238], [239, 246], [247, 250], [251, 259], [260, 267], [267, 268], [268, 269], [270, 273], [273, 274]]}
{"doc_key": "ai-test-11", "ner": [[0, 1, "organisation"], [5, 6, "researcher"], [12, 12, "organisation"], [15, 15, "product"], [23, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 6, "origin", "", false, false], [5, 6, 12, 12, "role", "", false, false], [15, 15, 23, 24, "type-of", "", false, false], [23, 24, 5, 6, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Rethink", "Robotics", "-", "founded", "by", "Rodney", "Brooks", ",", "who", "previously", "worked", "at", "iRobot", "-", "introduced", "Baxter", "in", "September", "2012", ".", "Baxter", "is", "an", "industrial", "robot", "designed", "to", "safely", "interact", "with", "adjacent", "human", "workers", "and", "can", "be", "programmed", "to", "perform", "simple", "tasks", "."], "sentence-detokenized": "Rethink Robotics - founded by Rodney Brooks, who previously worked at iRobot - introduced Baxter in September 2012. Baxter is an industrial robot designed to safely interact with adjacent human workers and can be programmed to perform simple tasks.", "token2charspan": [[0, 7], [8, 16], [17, 18], [19, 26], [27, 29], [30, 36], [37, 43], [43, 44], [45, 48], [49, 59], [60, 66], [67, 69], [70, 76], [77, 78], [79, 89], [90, 96], [97, 99], [100, 109], [110, 114], [114, 115], [116, 122], [123, 125], [126, 128], [129, 139], [140, 145], [146, 154], [155, 157], [158, 164], [165, 173], [174, 178], [179, 187], [188, 193], [194, 201], [202, 205], [206, 209], [210, 212], [213, 223], [224, 226], [227, 234], [235, 241], [242, 247], [247, 248]]}
{"doc_key": "ai-test-12", "ner": [[5, 6, "task"], [8, 9, "task"], [11, 14, "task"], [16, 19, "task"], [21, 22, "task"], [24, 25, "task"], [27, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "text", "mining", "tasks", "include", "text", "categorisation", ",", "text", "clustering", ",", "concept", "/", "entity", "extraction", ",", "creation", "of", "granular", "taxonomies", ",", "sentiment", "analysis", ",", "document", "summarisation", "and", "entity", "relationship", "modelling", "(", "i.e.", "learning", "relationships", "between", "named", "entities", ")", "."], "sentence-detokenized": "Typical text mining tasks include text categorisation, text clustering, concept/entity extraction, creation of granular taxonomies, sentiment analysis, document summarisation and entity relationship modelling (i.e. learning relationships between named entities).", "token2charspan": [[0, 7], [8, 12], [13, 19], [20, 25], [26, 33], [34, 38], [39, 53], [53, 54], [55, 59], [60, 70], [70, 71], [72, 79], [79, 80], [80, 86], [87, 97], [97, 98], [99, 107], [108, 110], [111, 119], [120, 130], [130, 131], [132, 141], [142, 150], [150, 151], [152, 160], [161, 174], [175, 178], [179, 185], [186, 198], [199, 208], [209, 210], [210, 214], [215, 223], [224, 237], [238, 245], [246, 251], [252, 260], [260, 261], [261, 262]]}
{"doc_key": "ai-test-13", "ner": [[8, 8, "metrics"], [11, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Nevertheless", ",", "stemming", "in", "such", "systems", "reduces", "the", "precision", "or", "the", "TRUE", "negative", "rate", "."], "sentence-detokenized": "Nevertheless, stemming in such systems reduces the precision or the TRUE negative rate.", "token2charspan": [[0, 12], [12, 13], [14, 22], [23, 25], [26, 30], [31, 38], [39, 46], [47, 50], [51, 60], [61, 63], [64, 67], [68, 72], [73, 81], [82, 86], [86, 87]]}
{"doc_key": "ai-test-14", "ner": [[4, 5, "task"], [10, 11, "misc"], [15, 16, "misc"], [28, 28, "product"], [30, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 11, 4, 5, "temporal", "", false, false], [15, 16, 10, 11, "named", "", false, false], [28, 28, 10, 11, "usage", "", false, false], [30, 31, 10, 11, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "special", "case", "of", "keyword", "spotting", "is", "the", "detection", "of", "wake", "words", "(", "also", "called", "hot", "words", ")", ",", "which", "are", "used", "by", "personal", "digital", "assistants", "such", "as", "Alexa", "or", "Siri", "to", "wake", "up", "when", "their", "name", "is", "spoken", "."], "sentence-detokenized": "A special case of keyword spotting is the detection of wake words (also called hot words), which are used by personal digital assistants such as Alexa or Siri to wake up when their name is spoken.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 17], [18, 25], [26, 34], [35, 37], [38, 41], [42, 51], [52, 54], [55, 59], [60, 65], [66, 67], [67, 71], [72, 78], [79, 82], [83, 88], [88, 89], [89, 90], [91, 96], [97, 100], [101, 105], [106, 108], [109, 117], [118, 125], [126, 136], [137, 141], [142, 144], [145, 150], [151, 153], [154, 158], [159, 161], [162, 166], [167, 169], [170, 174], [175, 180], [181, 185], [186, 188], [189, 195], [195, 196]]}
{"doc_key": "ai-test-15", "ner": [[0, 0, "programlang"], [9, 9, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 0, 0, "part-of", "", false, false], [11, 11, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "is", "an", "open", "source", "programming", "language", "that", "combines", "Prolog", "with", "Java", "."], "sentence-detokenized": "Prova is an open source programming language that combines Prolog with Java.", "token2charspan": [[0, 5], [6, 8], [9, 11], [12, 16], [17, 23], [24, 35], [36, 44], [45, 49], [50, 58], [59, 65], [66, 70], [71, 75], [75, 76]]}
{"doc_key": "ai-test-16", "ner": [[3, 4, "organisation"], [9, 9, "organisation"], [16, 20, "product"], [29, 31, "country"], [37, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[3, 4, 9, 9, "part-of", "", false, false], [3, 4, 9, 9, "role", "sells", false, false], [3, 4, 29, 31, "role", "sells_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1987", ",", "Tocibai", "Machine", ",", "a", "subsidiary", "of", "Toshiba", ",", "was", "accused", "of", "illegally", "selling", "CNC", "milled", "parts", "for", "the", "production", "of", "very", "quiet", "submarine", "propellers", "to", "the", "Soviet", "Union", "in", "violation", "of", "the", "CoCom", "agreement", ",", "an", "international", "embargo", "against", "certain", "countries", "."], "sentence-detokenized": "In 1987, Tocibai Machine, a subsidiary of Toshiba, was accused of illegally selling CNC milled parts for the production of very quiet submarine propellers to the Soviet Union in violation of the CoCom agreement, an international embargo against certain countries.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 24], [24, 25], [26, 27], [28, 38], [39, 41], [42, 49], [49, 50], [51, 54], [55, 62], [63, 65], [66, 75], [76, 83], [84, 87], [88, 94], [95, 100], [101, 104], [105, 108], [109, 119], [120, 122], [123, 127], [128, 133], [134, 143], [144, 154], [155, 157], [158, 161], [162, 168], [169, 174], [175, 177], [178, 187], [188, 190], [191, 194], [195, 200], [201, 210], [210, 211], [212, 214], [215, 228], [229, 236], [237, 244], [245, 252], [253, 262], [262, 263]]}
{"doc_key": "ai-test-17", "ner": [[0, 1, "researcher"], [7, 10, "product"], [22, 26, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 10, 0, 1, "artifact", "", false, false], [7, 10, 22, 26, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Engelberger", "'s", "most", "famous", "co-invention", ",", "the", "Unimate", "industrial", "robot", "arm", ",", "was", "one", "of", "the", "first", "to", "be", "inducted", "into", "the", "Robot", "Hall", "of", "Fame", "in", "2003", "."], "sentence-detokenized": "Engelberger's most famous co-invention, the Unimate industrial robot arm, was one of the first to be inducted into the Robot Hall of Fame in 2003.", "token2charspan": [[0, 11], [11, 13], [14, 18], [19, 25], [26, 38], [38, 39], [40, 43], [44, 51], [52, 62], [63, 68], [69, 72], [72, 73], [74, 77], [78, 81], [82, 84], [85, 88], [89, 94], [95, 97], [98, 100], [101, 109], [110, 114], [115, 118], [119, 124], [125, 129], [130, 132], [133, 137], [138, 140], [141, 145], [145, 146]]}
{"doc_key": "ai-test-18", "ner": [[3, 3, "misc"], [8, 8, "misc"], [10, 10, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 8, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Originally", "driven", "by", "static", "HTML", "web", "pages", "using", "CGI", ",", "Dalton", "introduced", "a", "Java", "-", "based", "augmented", "reality", "interface", "that", "had", "limited", "success", "."], "sentence-detokenized": "Originally driven by static HTML web pages using CGI, Dalton introduced a Java-based augmented reality interface that had limited success.", "token2charspan": [[0, 10], [11, 17], [18, 20], [21, 27], [28, 32], [33, 36], [37, 42], [43, 48], [49, 52], [52, 53], [54, 60], [61, 71], [72, 73], [74, 78], [78, 79], [79, 84], [85, 94], [95, 102], [103, 112], [113, 117], [118, 121], [122, 129], [130, 137], [137, 138]]}
{"doc_key": "ai-test-19", "ner": [[5, 6, "task"], [10, 10, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 10, 10, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "publication", "on", "the", "LMF", "specification", "as", "ratified", "by", "ISO", "(", "this", "paper", "became", "(", "2015", ")", "the", "9th", "most", "cited", "paper", "within", "LREC", "conferences", "of", "LREC", "papers", ")", ":"], "sentence-detokenized": "The first publication on the LMF specification as ratified by ISO (this paper became (2015) the 9th most cited paper within LREC conferences of LREC papers):", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 24], [25, 28], [29, 32], [33, 46], [47, 49], [50, 58], [59, 61], [62, 65], [66, 67], [67, 71], [72, 77], [78, 84], [85, 86], [86, 90], [90, 91], [92, 95], [96, 99], [100, 104], [105, 110], [111, 116], [117, 123], [124, 128], [129, 140], [141, 143], [144, 148], [149, 155], [155, 156], [156, 157]]}
{"doc_key": "ai-test-20", "ner": [[1, 2, "metrics"], [15, 16, "metrics"], [18, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 16, 1, 2, "usage", "", false, false], [15, 16, 18, 21, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "confusion", "matrix", "or", "matching", "matrix", "is", "often", "used", "as", "a", "tool", "to", "check", "the", "accuracy", "of", "the", "k", "-", "NN", "classification", "."], "sentence-detokenized": "A confusion matrix or matching matrix is often used as a tool to check the accuracy of the k -NN classification.", "token2charspan": [[0, 1], [2, 11], [12, 18], [19, 21], [22, 30], [31, 37], [38, 40], [41, 46], [47, 51], [52, 54], [55, 56], [57, 61], [62, 64], [65, 70], [71, 74], [75, 83], [84, 86], [87, 90], [91, 92], [93, 94], [94, 96], [97, 111], [111, 112]]}
{"doc_key": "ai-test-21", "ner": [[0, 1, "algorithm"], [12, 12, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 12, "part-of", "", false, false], [0, 1, 14, 15, "part-of", "", false, false], [0, 1, 17, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", "is", "one", "of", "the", "predictive", "modelling", "approaches", "used", "in", "statistics", ",", "data", "mining", "and", "machine", "learning", "."], "sentence-detokenized": "Decision tree learning is one of the predictive modelling approaches used in statistics, data mining and machine learning.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 47], [48, 57], [58, 68], [69, 73], [74, 76], [77, 87], [87, 88], [89, 93], [94, 100], [101, 104], [105, 112], [113, 121], [121, 122]]}
{"doc_key": "ai-test-22", "ner": [[4, 7, "misc"], [21, 23, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["At", "runtime", ",", "the", "target", "persody", "of", "a", "sentence", "is", "superimposed", "on", "these", "minimal", "units", "using", "signal", "processing", "techniques", "such", "as", "linear", "predictive", "coding", "and", "PSOLA", "."], "sentence-detokenized": "At runtime, the target persody of a sentence is superimposed on these minimal units using signal processing techniques such as linear predictive coding and PSOLA.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 22], [23, 30], [31, 33], [34, 35], [36, 44], [45, 47], [48, 60], [61, 63], [64, 69], [70, 77], [78, 83], [84, 89], [90, 96], [97, 107], [108, 118], [119, 123], [124, 126], [127, 133], [134, 144], [145, 151], [152, 155], [156, 161], [161, 162]]}
{"doc_key": "ai-test-23", "ner": [[3, 4, "field"], [6, 8, "field"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 20, 3, 4, "usage", "", true, false], [19, 20, 6, 8, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "approach", "used", "artificial", "intelligence", "and", "machine", "learning", "to", "provide", "researchers", "with", "a", "visible", "comparison", "between", "conventional", "and", "thermal", "face", "images", "."], "sentence-detokenized": "This approach used artificial intelligence and machine learning to provide researchers with a visible comparison between conventional and thermal face images.", "token2charspan": [[0, 4], [5, 13], [14, 18], [19, 29], [30, 42], [43, 46], [47, 54], [55, 63], [64, 66], [67, 74], [75, 86], [87, 91], [92, 93], [94, 101], [102, 112], [113, 120], [121, 133], [134, 137], [138, 145], [146, 150], [151, 157], [157, 158]]}
{"doc_key": "ai-test-24", "ner": [[1, 2, "field"], [4, 5, "algorithm"], [12, 13, "task"], [16, 17, "misc"], [23, 24, "field"], [26, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 1, 2, "part-of", "", false, false], [4, 5, 12, 13, "topic", "", false, false], [12, 13, 16, 17, "origin", "", false, false], [23, 24, 1, 2, "part-of", "", false, false], [23, 24, 4, 5, "topic", "", false, false], [26, 27, 1, 2, "part-of", "", false, false], [26, 27, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "computer", "science", ",", "evolutionary", "computation", "is", "a", "family", "of", "algorithms", "for", "global", "optimisation", "inspired", "by", "biological", "evolution", ",", "and", "the", "subfield", "of", "artificial", "intelligence", "and", "soft", "computing", "that", "studies", "these", "algorithms", "."], "sentence-detokenized": "In computer science, evolutionary computation is a family of algorithms for global optimisation inspired by biological evolution, and the subfield of artificial intelligence and soft computing that studies these algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 33], [34, 45], [46, 48], [49, 50], [51, 57], [58, 60], [61, 71], [72, 75], [76, 82], [83, 95], [96, 104], [105, 107], [108, 118], [119, 128], [128, 129], [130, 133], [134, 137], [138, 146], [147, 149], [150, 160], [161, 173], [174, 177], [178, 182], [183, 192], [193, 197], [198, 205], [206, 211], [212, 222], [222, 223]]}
{"doc_key": "ai-test-25", "ner": [[11, 12, "metrics"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "one", "can", "combine", "a", "measure", "based", "on", "the", "confusion", "matrix", "with", "the", "mean", "square", "error", "between", "the", "raw", "data", "of", "the", "model", "and", "the", "actual", "values", "."], "sentence-detokenized": "For example, one can combine a measure based on the confusion matrix with the mean square error between the raw data of the model and the actual values.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 20], [21, 28], [29, 30], [31, 38], [39, 44], [45, 47], [48, 51], [52, 61], [62, 68], [69, 73], [74, 77], [78, 82], [83, 89], [90, 95], [96, 103], [104, 107], [108, 111], [112, 116], [117, 119], [120, 123], [124, 129], [130, 133], [134, 137], [138, 144], [145, 151], [151, 152]]}
{"doc_key": "ai-test-26", "ner": [[5, 6, "product"], [9, 9, "researcher"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 9, 9, "origin", "", false, false], [5, 6, 16, 16, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Most", "are", "results", "of", "the", "word2vec", "model", "developed", "by", "Mikolov", "et", "al", ".", "or", "variants", "of", "word2vec", "."], "sentence-detokenized": "Most are results of the word2vec model developed by Mikolov et al. or variants of word2vec.", "token2charspan": [[0, 4], [5, 8], [9, 16], [17, 19], [20, 23], [24, 32], [33, 38], [39, 48], [49, 51], [52, 59], [60, 62], [63, 65], [65, 66], [67, 69], [70, 78], [79, 81], [82, 90], [90, 91]]}
{"doc_key": "ai-test-27", "ner": [[13, 13, "conference"], [16, 20, "conference"], [22, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 22, 16, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["During", "this", "time", ",", "a", "total", "of", "43", "publications", "were", "recognised", "by", "the", "CVPR", "and", "the", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "."], "sentence-detokenized": "During this time, a total of 43 publications were recognised by the CVPR and the International Conference on Computer Vision (ICCV).", "token2charspan": [[0, 6], [7, 11], [12, 16], [16, 17], [18, 19], [20, 25], [26, 28], [29, 31], [32, 44], [45, 49], [50, 60], [61, 63], [64, 67], [68, 72], [73, 76], [77, 80], [81, 94], [95, 105], [106, 108], [109, 117], [118, 124], [125, 126], [126, 130], [130, 131], [131, 132]]}
{"doc_key": "ai-test-28", "ner": [[0, 1, "product"], [3, 11, "field"], [20, 21, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 3, 11, "general-affiliation", "platform_for_education_about", false, false], [20, 21, 0, 1, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "AIBO", "has", "proven", "to", "be", "a", "cost-effective", "platform", "for", "artificial", "intelligence", "education", "and", "research", ",", "integrating", "a", "computer", ",", "computer", "vision", "and", "articulators", "in", "a", "package", "that", "is", "significantly", "cheaper", "than", "traditional", "research", "robots", "."], "sentence-detokenized": "The AIBO has proven to be a cost-effective platform for artificial intelligence education and research, integrating a computer, computer vision and articulators in a package that is significantly cheaper than traditional research robots.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 19], [20, 22], [23, 25], [26, 27], [28, 42], [43, 51], [52, 55], [56, 66], [67, 79], [80, 89], [90, 93], [94, 102], [102, 103], [104, 115], [116, 117], [118, 126], [126, 127], [128, 136], [137, 143], [144, 147], [148, 160], [161, 163], [164, 165], [166, 173], [174, 178], [179, 181], [182, 195], [196, 203], [204, 208], [209, 220], [221, 229], [230, 236], [236, 237]]}
{"doc_key": "ai-test-29", "ner": [[7, 12, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "was", "the", "programme", "chair", "of", "the", "International", "Conference", "on", "Computer", "Vision", "2021", "."], "sentence-detokenized": "She was the programme chair of the International Conference on Computer Vision 2021.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 21], [22, 27], [28, 30], [31, 34], [35, 48], [49, 59], [60, 62], [63, 71], [72, 78], [79, 83], [83, 84]]}
{"doc_key": "ai-test-30", "ner": [[1, 1, "researcher"], [6, 7, "organisation"], [17, 17, "organisation"], [27, 28, "organisation"], [37, 41, "product"], [43, 43, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 1, 6, 7, "role", "", false, false], [1, 1, 17, 17, "role", "", true, false], [17, 17, 27, 28, "role", "develops_with", false, false], [37, 41, 17, 17, "artifact", "", false, false], [43, 43, 37, 41, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["After", "Scheinman", "received", "a", "grant", "from", "Unimation", "to", "develop", "his", "designs", ",", "he", "sold", "these", "designs", "to", "Unimation", ",", "which", "further", "developed", "them", "with", "the", "support", "of", "General", "Motors", "and", "later", "brought", "them", "to", "market", "as", "the", "Programmable", "Universal", "Machine", "for", "Assembly", "(", "PUMA", ")", "."], "sentence-detokenized": "After Scheinman received a grant from Unimation to develop his designs, he sold these designs to Unimation, which further developed them with the support of General Motors and later brought them to market as the Programmable Universal Machine for Assembly (PUMA).", "token2charspan": [[0, 5], [6, 15], [16, 24], [25, 26], [27, 32], [33, 37], [38, 47], [48, 50], [51, 58], [59, 62], [63, 70], [70, 71], [72, 74], [75, 79], [80, 85], [86, 93], [94, 96], [97, 106], [106, 107], [108, 113], [114, 121], [122, 131], [132, 136], [137, 141], [142, 145], [146, 153], [154, 156], [157, 164], [165, 171], [172, 175], [176, 181], [182, 189], [190, 194], [195, 197], [198, 204], [205, 207], [208, 211], [212, 224], [225, 234], [235, 242], [243, 246], [247, 255], [256, 257], [257, 261], [261, 262], [262, 263]]}
{"doc_key": "ai-test-31", "ner": [[6, 6, "task"], [8, 11, "task"], [14, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 6, 6, "general-affiliation", "works_with", false, false], [14, 14, 8, 11, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "overview", "of", "calibration", "methods", "for", "binary", "and", "multi-class", "classification", "tasks", "is", "given", "by", "Gebel", "(", "2009", ")"], "sentence-detokenized": "An overview of calibration methods for binary and multi-class classification tasks is given by Gebel (2009)", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 34], [35, 38], [39, 45], [46, 49], [50, 61], [62, 76], [77, 82], [83, 85], [86, 91], [92, 94], [95, 100], [101, 102], [102, 106], [106, 107]]}
{"doc_key": "ai-test-32", "ner": [[7, 9, "task"], [11, 11, "task"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 7, 9, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "involved", "in", "areas", "such", "as", "optical", "character", "recognition", "(", "OCR", ")", ",", "speech", "synthesis", ",", "speech", "recognition", "technology", "and", "electronic", "keyboard", "instruments", "."], "sentence-detokenized": "He is involved in areas such as optical character recognition (OCR), speech synthesis, speech recognition technology and electronic keyboard instruments.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 23], [24, 28], [29, 31], [32, 39], [40, 49], [50, 61], [62, 63], [63, 66], [66, 67], [67, 68], [69, 75], [76, 85], [85, 86], [87, 93], [94, 105], [106, 116], [117, 120], [121, 131], [132, 140], [141, 152], [152, 153]]}
{"doc_key": "ai-test-33", "ner": [[8, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "newer", "and", "more", "modern", "techniques", ",", "the", "Kaldi", "toolkit", "can", "be", "used", "."], "sentence-detokenized": "For newer and more modern techniques, the Kaldi toolkit can be used.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 18], [19, 25], [26, 36], [36, 37], [38, 41], [42, 47], [48, 55], [56, 59], [60, 62], [63, 67], [67, 68]]}
{"doc_key": "ai-test-34", "ner": [[0, 2, "researcher"], [8, 10, "organisation"], [16, 22, "organisation"], [23, 24, "organisation"], [27, 28, "researcher"], [32, 35, "organisation"], [41, 43, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 8, 10, "role", "", false, false], [0, 2, 16, 22, "role", "", false, false], [0, 2, 23, 24, "role", "", false, false], [0, 2, 32, 35, "role", "", false, false], [0, 2, 41, 43, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Johnson", "-", "Laird", "is", "a", "Fellow", "of", "the", "American", "Philosophical", "Society", ",", "a", "Fellow", "of", "the", "Royal", "Society", ",", "a", "Fellow", "of", "the", "British", "Academy", ",", "a", "William", "James", "Fellow", "of", "the", "Association", "for", "Psychological", "Science", "and", "a", "Fellow", "of", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Johnson-Laird is a Fellow of the American Philosophical Society, a Fellow of the Royal Society, a Fellow of the British Academy, a William James Fellow of the Association for Psychological Science and a Fellow of the Cognitive Science Society.", "token2charspan": [[0, 7], [7, 8], [8, 13], [14, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 41], [42, 55], [56, 63], [63, 64], [65, 66], [67, 73], [74, 76], [77, 80], [81, 86], [87, 94], [94, 95], [96, 97], [98, 104], [105, 107], [108, 111], [112, 119], [120, 127], [127, 128], [129, 130], [131, 138], [139, 144], [145, 151], [152, 154], [155, 158], [159, 170], [171, 174], [175, 188], [189, 196], [197, 200], [201, 202], [203, 209], [210, 212], [213, 216], [217, 226], [227, 234], [235, 242], [242, 243]]}
{"doc_key": "ai-test-35", "ner": [[2, 6, "conference"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"], [21, 22, "algorithm"], [26, 30, "task"], [32, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 12, 2, 6, "physical", "", false, false], [11, 12, 2, 6, "temporal", "", false, false], [14, 15, 2, 6, "physical", "", false, false], [14, 15, 2, 6, "temporal", "", false, false], [17, 18, 2, 6, "physical", "", false, false], [17, 18, 2, 6, "temporal", "", false, false], [21, 22, 17, 18, "role", "extends", false, false], [26, 30, 17, 18, "role", "extends", false, false], [32, 32, 26, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["At", "the", "IEEE", "International", "Conference", "on", "Image", "Processing", "in", "2010", ",", "Rui", "Hu", ",", "Mark", "Banard", "and", "John", "Collomosse", "extended", "the", "HOG", "descriptor", "for", "use", "in", "sketch", "-", "based", "image", "retrieval", "(", "SBIR", ")", "."], "sentence-detokenized": "At the IEEE International Conference on Image Processing in 2010, Rui Hu, Mark Banard and John Collomosse extended the HOG descriptor for use in sketch-based image retrieval (SBIR).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 25], [26, 36], [37, 39], [40, 45], [46, 56], [57, 59], [60, 64], [64, 65], [66, 69], [70, 72], [72, 73], [74, 78], [79, 85], [86, 89], [90, 94], [95, 105], [106, 114], [115, 118], [119, 122], [123, 133], [134, 137], [138, 141], [142, 144], [145, 151], [151, 152], [152, 157], [158, 163], [164, 173], [174, 175], [175, 179], [179, 180], [180, 181]]}
{"doc_key": "ai-test-36", "ner": [[0, 0, "metrics"], [6, 7, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 7, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["BLEU", "uses", "a", "modified", "form", "of", "precision", "to", "compare", "a", "candidate", "translation", "with", "several", "reference", "translations", "."], "sentence-detokenized": "BLEU uses a modified form of precision to compare a candidate translation with several reference translations.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 20], [21, 25], [26, 28], [29, 38], [39, 41], [42, 49], [50, 51], [52, 61], [62, 73], [74, 78], [79, 86], [87, 96], [97, 109], [109, 110]]}
{"doc_key": "ai-test-37", "ner": [[35, 36, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "the", "case", "of", "a", "general", "base", "space", "math", "(", "Y", ",\\", "mathcal", "{", "B", "},\\", "nu", ")", "/", "math", "(", "i.e.", "a", "base", "space", "that", "is", "not", "countable", ")", ",", "one", "usually", "considers", "the", "relative", "entropy", "."], "sentence-detokenized": "For the case of a general base space math (Y,\\ mathcal {B},\\ nu) / math (i.e. a base space that is not countable), one usually considers the relative entropy.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 15], [16, 17], [18, 25], [26, 30], [31, 36], [37, 41], [42, 43], [43, 44], [44, 46], [47, 54], [55, 56], [56, 57], [57, 60], [61, 63], [63, 64], [65, 66], [67, 71], [72, 73], [73, 77], [78, 79], [80, 84], [85, 90], [91, 95], [96, 98], [99, 102], [103, 112], [112, 113], [113, 114], [115, 118], [119, 126], [127, 136], [137, 140], [141, 149], [150, 157], [157, 158]]}
{"doc_key": "ai-test-38", "ner": [[16, 17, "country"], [8, 10, "organisation"], [12, 12, "organisation"], [26, 27, "country"], [19, 20, "organisation"], [22, 22, "organisation"], [30, 32, "organisation"], [34, 35, "country"], [36, 41, "organisation"], [43, 45, "organisation"], [52, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11], "relations": [[8, 10, 16, 17, "physical", "", false, false], [12, 12, 8, 10, "named", "", false, false], [19, 20, 26, 27, "physical", "", false, false], [22, 22, 19, 20, "named", "", false, false], [36, 41, 34, 35, "physical", "", false, false], [43, 45, 36, 41, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "October", "2011", ",", "existing", "partnerships", "with", "the", "National", "Park", "Service", "(", "NPS", ")", "of", "the", "United", "States", ",", "Historic", "Scotland", "(", "HS", ")", "of", "the", "United", "Kingdom", ",", "the", "World", "Monuments", "Fund", "and", "Mexico", "'s", "Instituto", "Nacional", "de", "Antropolog\u00eda", "y", "Historia", "(", "INAH", ")", "were", "significantly", "expanded", ",", "according", "to", "the", "CyArk", "website"], "sentence-detokenized": "In October 2011, existing partnerships with the National Park Service (NPS) of the United States, Historic Scotland (HS) of the United Kingdom, the World Monuments Fund and Mexico's Instituto Nacional de Antropolog\u00eda y Historia (INAH) were significantly expanded, according to the CyArk website", "token2charspan": [[0, 2], [3, 10], [11, 15], [15, 16], [17, 25], [26, 38], [39, 43], [44, 47], [48, 56], [57, 61], [62, 69], [70, 71], [71, 74], [74, 75], [76, 78], [79, 82], [83, 89], [90, 96], [96, 97], [98, 106], [107, 115], [116, 117], [117, 119], [119, 120], [121, 123], [124, 127], [128, 134], [135, 142], [142, 143], [144, 147], [148, 153], [154, 163], [164, 168], [169, 172], [173, 179], [179, 181], [182, 191], [192, 200], [201, 203], [204, 216], [217, 218], [219, 227], [228, 229], [229, 233], [233, 234], [235, 239], [240, 253], [254, 262], [262, 263], [264, 273], [274, 276], [277, 280], [281, 286], [287, 294]]}
{"doc_key": "ai-test-39", "ner": [[0, 1, "algorithm"], [11, 11, "product"], [13, 13, "product"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[0, 1, 11, 11, "part-of", "", false, false], [0, 1, 13, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Kernel", "SVMs", "are", "available", "in", "many", "machine", "learning", "toolkits", ",", "including", "LIBSVM", ",", "MATLAB", "and", "others", "."], "sentence-detokenized": "Kernel SVMs are available in many machine learning toolkits, including LIBSVM, MATLAB and others.", "token2charspan": [[0, 6], [7, 11], [12, 15], [16, 25], [26, 28], [29, 33], [34, 41], [42, 50], [51, 59], [59, 60], [61, 70], [71, 77], [77, 78], [79, 85], [86, 89], [90, 96], [96, 97]]}
{"doc_key": "ai-test-40", "ner": [[2, 4, "misc"], [13, 14, "location"], [16, 16, "location"], [17, 19, "country"], [23, 25, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 13, 14, "physical", "", false, false], [2, 4, 23, 25, "temporal", "", false, false], [13, 14, 16, 16, "physical", "", false, false], [16, 16, 17, 19, "physical", "", false, false], [23, 25, 13, 14, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "2009", "Loebner", "Prize", "competition", "took", "place", "on", "6", "September", "2009", "at", "the", "Brighton", "Centre", ",", "Brighton", "UK", ",", "in", "conjunction", "with", "the", "Interspeech", "2009", "conference", "."], "sentence-detokenized": "The 2009 Loebner Prize competition took place on 6 September 2009 at the Brighton Centre, Brighton UK, in conjunction with the Interspeech 2009 conference.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 34], [35, 39], [40, 45], [46, 48], [49, 50], [51, 60], [61, 65], [66, 68], [69, 72], [73, 81], [82, 88], [88, 89], [90, 98], [99, 101], [101, 102], [103, 105], [106, 117], [118, 122], [123, 126], [127, 138], [139, 143], [144, 154], [154, 155]]}
{"doc_key": "ai-test-41", "ner": [[2, 3, "product"], [10, 10, "product"], [15, 17, "product"], [18, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[18, 20, 2, 3, "part-of", "", false, false], [18, 20, 10, 10, "part-of", "", false, false], [18, 20, 15, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "humanoid", "QRIO", "robot", "was", "developed", "as", "a", "successor", "to", "AIBO", "and", "runs", "the", "same", "R", "-", "CODE", "Aperios", "operating", "system", "."], "sentence-detokenized": "The humanoid QRIO robot was developed as a successor to AIBO and runs the same R-CODE Aperios operating system.", "token2charspan": [[0, 3], [4, 12], [13, 17], [18, 23], [24, 27], [28, 37], [38, 40], [41, 42], [43, 52], [53, 55], [56, 60], [61, 64], [65, 69], [70, 73], [74, 78], [79, 80], [80, 81], [81, 85], [86, 93], [94, 103], [104, 110], [110, 111]]}
{"doc_key": "ai-test-42", "ner": [[1, 2, "misc"], [7, 7, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 1, 2, "cause-effect", "", true, false], [12, 13, 1, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "speech", "waveforms", "are", "generated", "from", "the", "HMMs", "themselves", "based", "on", "the", "maximum", "likelihood", "criterion", "."], "sentence-detokenized": "The speech waveforms are generated from the HMMs themselves based on the maximum likelihood criterion.", "token2charspan": [[0, 3], [4, 10], [11, 20], [21, 24], [25, 34], [35, 39], [40, 43], [44, 48], [49, 59], [60, 65], [66, 68], [69, 72], [73, 80], [81, 91], [92, 101], [101, 102]]}
{"doc_key": "ai-test-43", "ner": [[0, 1, "product"], [5, 11, "task"], [9, 9, "task"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 5, 11, "type-of", "", false, false], [0, 1, 9, 9, "type-of", "", false, false], [0, 1, 15, 15, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "is", "a", "free", ",", "multilingual", "statistical", "and", "neural", "machine", "translation", "service", "developed", "by", "Google", "to", "translate", "text", "and", "websites", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Google Translate is a free, multilingual statistical and neural machine translation service developed by Google to translate text and websites from one language to another.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 21], [22, 26], [26, 27], [28, 40], [41, 52], [53, 56], [57, 63], [64, 71], [72, 83], [84, 91], [92, 101], [102, 104], [105, 111], [112, 114], [115, 124], [125, 129], [130, 133], [134, 142], [143, 147], [148, 151], [152, 160], [161, 163], [164, 171], [171, 172]]}
{"doc_key": "ai-test-44", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [14, 16, "field"], [20, 22, "task"], [24, 25, "task"], [27, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[20, 22, 5, 6, "part-of", "", false, true], [20, 22, 8, 9, "part-of", "", false, true], [20, 22, 11, 12, "part-of", "", false, true], [24, 25, 5, 6, "part-of", "", false, true], [24, 25, 8, 9, "part-of", "", false, true], [24, 25, 11, 12, "part-of", "", false, true], [27, 30, 5, 6, "part-of", "", false, true], [27, 30, 8, 9, "part-of", "", false, true], [27, 30, 11, 12, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Skeletons", "are", "widely", "used", "in", "computer", "vision", ",", "image", "analysis", ",", "pattern", "recognition", "and", "digital", "image", "processing", ",", "e.g.", "for", "optical", "character", "recognition", ",", "fingerprint", "recognition", ",", "visual", "inspection", "or", "compression", "."], "sentence-detokenized": "Skeletons are widely used in computer vision, image analysis, pattern recognition and digital image processing, e.g. for optical character recognition, fingerprint recognition, visual inspection or compression.", "token2charspan": [[0, 9], [10, 13], [14, 20], [21, 25], [26, 28], [29, 37], [38, 44], [44, 45], [46, 51], [52, 60], [60, 61], [62, 69], [70, 81], [82, 85], [86, 93], [94, 99], [100, 110], [110, 111], [112, 116], [117, 120], [121, 128], [129, 138], [139, 150], [150, 151], [152, 163], [164, 175], [175, 176], [177, 183], [184, 194], [195, 197], [198, 209], [209, 210]]}
{"doc_key": "ai-test-45", "ner": [[1, 6, "conference"], [11, 14, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 6, 11, 14, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "is", "a", "benchmark", "for", "object", "classification", "and", "recognition", ",", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "The ImageNet Large Scale Visual Recognition Challenge is a benchmark for object classification and recognition, with millions of images and hundreds of object classes.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 24], [25, 31], [32, 43], [44, 53], [54, 56], [57, 58], [59, 68], [69, 72], [73, 79], [80, 94], [95, 98], [99, 110], [110, 111], [112, 116], [117, 125], [126, 128], [129, 135], [136, 139], [140, 148], [149, 151], [152, 158], [159, 166], [166, 167]]}
{"doc_key": "ai-test-46", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 11, "researcher"], [17, 19, "misc"], [22, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 17, 19, "part-of", "", false, false], [0, 0, 22, 25, "part-of", "", false, false], [4, 5, 17, 19, "part-of", "", false, false], [4, 5, 22, 25, "part-of", "", false, false], [7, 11, 17, 19, "part-of", "", false, false], [7, 11, 22, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Bengio", ",", "along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "is", "considered", "by", "some", "to", "be", "the", "godfather", "of", "AI", "and", "the", "godfather", "of", "Deep", "Learning", "."], "sentence-detokenized": "Bengio, along with Geoffrey Hinton and Yann LeCun, is considered by some to be the godfather of AI and the godfather of Deep Learning.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 18], [19, 27], [28, 34], [35, 38], [39, 43], [44, 49], [49, 50], [51, 53], [54, 64], [65, 67], [68, 72], [73, 75], [76, 78], [79, 82], [83, 92], [93, 95], [96, 98], [99, 102], [103, 106], [107, 116], [117, 119], [120, 124], [125, 133], [133, 134]]}
{"doc_key": "ai-test-47", "ner": [[7, 7, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "Life", "Fellow", "of", "the", "IEEE", "."], "sentence-detokenized": "He is a Life Fellow of the IEEE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 19], [20, 22], [23, 26], [27, 31], [31, 32]]}
{"doc_key": "ai-test-48", "ner": [[0, 1, "organisation"], [13, 18, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 13, 18, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NSA", "Bethesda", "is", "responsible", "for", "providing", "operational", "support", "to", "its", "primary", "tenant", ",", "Walter", "Reed", "National", "Military", "Medical", "Center", "."], "sentence-detokenized": "NSA Bethesda is responsible for providing operational support to its primary tenant, Walter Reed National Military Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 31], [32, 41], [42, 53], [54, 61], [62, 64], [65, 68], [69, 76], [77, 83], [83, 84], [85, 91], [92, 96], [97, 105], [106, 114], [115, 122], [123, 129], [129, 130]]}
{"doc_key": "ai-test-49", "ner": [[6, 7, "field"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "three", "main", "learning", "paradigms", "are", "supervised", "learning", ",", "unsupervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "The three main learning paradigms are supervised learning, unsupervised learning and reinforcement learning.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 23], [24, 33], [34, 37], [38, 48], [49, 57], [57, 58], [59, 71], [72, 80], [81, 84], [85, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-test-50", "ner": [[2, 2, "task"], [4, 6, "task"], [8, 12, "task"], [14, 15, "task"], [17, 19, "task"], [21, 22, "task"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Examples", "include", "control", ",", "planning", "and", "scheduling", ",", "answering", "diagnostic", "and", "consumer", "questions", ",", "handwriting", "recognition", ",", "natural", "language", "understanding", ",", "speech", "recognition", "and", "facial", "recognition", "."], "sentence-detokenized": "Examples include control, planning and scheduling, answering diagnostic and consumer questions, handwriting recognition, natural language understanding, speech recognition and facial recognition.", "token2charspan": [[0, 8], [9, 16], [17, 24], [24, 25], [26, 34], [35, 38], [39, 49], [49, 50], [51, 60], [61, 71], [72, 75], [76, 84], [85, 94], [94, 95], [96, 107], [108, 119], [119, 120], [121, 128], [129, 137], [138, 151], [151, 152], [153, 159], [160, 171], [172, 175], [176, 182], [183, 194], [194, 195]]}
{"doc_key": "ai-test-51", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1991", ",", "he", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "1990", ",", "Founding", "Fellow", ")", "."], "sentence-detokenized": "In 1991, he was elected a Fellow of the Association for the Advancement of Artificial Intelligence (1990, Founding Fellow).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [99, 100], [100, 104], [104, 105], [106, 114], [115, 121], [121, 122], [122, 123]]}
{"doc_key": "ai-test-52", "ner": [[11, 12, "misc"], [15, 15, "algorithm"], [29, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "by", "formulating", "the", "problem", "as", "a", "solution", "of", "a", "Toeplitz", "matrix", "and", "using", "Levinson", "recursion", ",", "we", "can", "relatively", "quickly", "estimate", "a", "filter", "with", "the", "smallest", "possible", "mean", "square", "error", "."], "sentence-detokenized": "However, by formulating the problem as a solution of a Toeplitz matrix and using Levinson recursion, we can relatively quickly estimate a filter with the smallest possible mean square error.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 23], [24, 27], [28, 35], [36, 38], [39, 40], [41, 49], [50, 52], [53, 54], [55, 63], [64, 70], [71, 74], [75, 80], [81, 89], [90, 99], [99, 100], [101, 103], [104, 107], [108, 118], [119, 126], [127, 135], [136, 137], [138, 144], [145, 149], [150, 153], [154, 162], [163, 171], [172, 176], [177, 183], [184, 189], [189, 190]]}
{"doc_key": "ai-test-53", "ner": [[5, 10, "conference"], [16, 20, "location"], [12, 22, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 10, 16, 20, "physical", "", false, false], [16, 20, 12, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2011", ",", "the", "15th", "edition", "of", "Campus", "Party", "Spain", "will", "take", "place", "in", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", "."], "sentence-detokenized": "In July 2011, the 15th edition of Campus Party Spain will take place in the City of Arts and Sciences in Valencia.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 22], [23, 30], [31, 33], [34, 40], [41, 46], [47, 52], [53, 57], [58, 62], [63, 68], [69, 71], [72, 75], [76, 80], [81, 83], [84, 88], [89, 92], [93, 101], [102, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-test-54", "ner": [[13, 13, "product"], [15, 19, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "usually", "only", "possible", "at", "the", "end", "of", "complicated", "games", "such", "as", "chess", "or", "go", ",", "as", "it", "is", "not", "mathematically", "possible", "to", "look", "into", "the", "future", "until", "the", "end", "of", "the", "game", ",", "except", "towards", "the", "end", ",", "and", "instead", "the", "positions", "are", "given", "finite", "values", "indicating", "the", "degree", "of", "belief", "that", "they", "will", "lead", "to", "a", "victory", "for", "one", "player", "or", "another", "."], "sentence-detokenized": "This is usually only possible at the end of complicated games such as chess or go, as it is not mathematically possible to look into the future until the end of the game, except towards the end, and instead the positions are given finite values indicating the degree of belief that they will lead to a victory for one player or another.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 20], [21, 29], [30, 32], [33, 36], [37, 40], [41, 43], [44, 55], [56, 61], [62, 66], [67, 69], [70, 75], [76, 78], [79, 81], [81, 82], [83, 85], [86, 88], [89, 91], [92, 95], [96, 110], [111, 119], [120, 122], [123, 127], [128, 132], [133, 136], [137, 143], [144, 149], [150, 153], [154, 157], [158, 160], [161, 164], [165, 169], [169, 170], [171, 177], [178, 185], [186, 189], [190, 193], [193, 194], [195, 198], [199, 206], [207, 210], [211, 220], [221, 224], [225, 230], [231, 237], [238, 244], [245, 255], [256, 259], [260, 266], [267, 269], [270, 276], [277, 281], [282, 286], [287, 291], [292, 296], [297, 299], [300, 301], [302, 309], [310, 313], [314, 317], [318, 324], [325, 327], [328, 335], [335, 336]]}
{"doc_key": "ai-test-55", "ner": [[4, 50, "algorithm"], [23, 24, "algorithm"], [30, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[4, 50, 23, 24, "compare", "", false, false], [4, 50, 30, 32, "compare", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["The", "difference", "between", "the", "multinomial", "logit", "model", "and", "numerous", "other", "methods", ",", "models", ",", "algorithms", ",", "etc.", "with", "the", "same", "basic", "structure", "(", "perceptron", "algorithm", ",", "support", "vector", "machines", ",", "linear", "discriminant", "analysis", ",", "etc.", ")", "is", "that", "the", "multinomial", "logit", "model", "is", "able", "to", "provide", "a", "wide", "range", "of", "information", "."], "sentence-detokenized": "The difference between the multinomial logit model and numerous other methods, models, algorithms, etc. with the same basic structure (perceptron algorithm, support vector machines, linear discriminant analysis, etc.) is that the multinomial logit model is able to provide a wide range of information.", "token2charspan": [[0, 3], [4, 14], [15, 22], [23, 26], [27, 38], [39, 44], [45, 50], [51, 54], [55, 63], [64, 69], [70, 77], [77, 78], [79, 85], [85, 86], [87, 97], [97, 98], [99, 103], [104, 108], [109, 112], [113, 117], [118, 123], [124, 133], [134, 135], [135, 145], [146, 155], [155, 156], [157, 164], [165, 171], [172, 180], [180, 181], [182, 188], [189, 201], [202, 210], [210, 211], [212, 216], [216, 217], [218, 220], [221, 225], [226, 229], [230, 241], [242, 247], [248, 253], [254, 256], [257, 261], [262, 264], [265, 272], [273, 274], [275, 279], [280, 285], [286, 288], [289, 300], [300, 301]]}
{"doc_key": "ai-test-56", "ner": [[0, 3, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Association", "for", "Computational", "Linguistics", ",", "published", "by"], "sentence-detokenized": "Association for Computational Linguistics, published by", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [41, 42], [43, 52], [53, 55]]}
{"doc_key": "ai-test-57", "ner": [[2, 4, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "computerised", "facial", "recognition", "systems", ",", "each", "face", "is", "represented", "by", "a", "large", "number", "of", "pixel", "values", "."], "sentence-detokenized": "In computerised facial recognition systems, each face is represented by a large number of pixel values.", "token2charspan": [[0, 2], [3, 15], [16, 22], [23, 34], [35, 42], [42, 43], [44, 48], [49, 53], [54, 56], [57, 68], [69, 71], [72, 73], [74, 79], [80, 86], [87, 89], [90, 95], [96, 102], [102, 103]]}
{"doc_key": "ai-test-58", "ner": [[5, 6, "person"], [12, 16, "organisation"], [21, 21, "country"], [25, 25, "person"], [37, 39, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 12, 16, "role", "", false, false], [5, 6, 21, 21, "physical", "", false, false], [25, 25, 37, 39, "origin", "", false, false], [25, 25, 37, 39, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2002", ",", "his", "son", "Daniel", "Pearl", ",", "a", "journalist", "for", "the", "Wall", "Street", "Journal", ",", "was", "kidnapped", "and", "murdered", "in", "Pakistan", ".", "This", "prompted", "Judea", "and", "other", "members", "of", "the", "family", "and", "friends", "to", "establish", "the", "Daniel", "Pearl", "Foundation", "."], "sentence-detokenized": "In 2002, his son Daniel Pearl, a journalist for the Wall Street Journal, was kidnapped and murdered in Pakistan. This prompted Judea and other members of the family and friends to establish the Daniel Pearl Foundation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 23], [24, 29], [29, 30], [31, 32], [33, 43], [44, 47], [48, 51], [52, 56], [57, 63], [64, 71], [71, 72], [73, 76], [77, 86], [87, 90], [91, 99], [100, 102], [103, 111], [111, 112], [113, 117], [118, 126], [127, 132], [133, 136], [137, 142], [143, 150], [151, 153], [154, 157], [158, 164], [165, 168], [169, 176], [177, 179], [180, 189], [190, 193], [194, 200], [201, 206], [207, 217], [217, 218]]}
{"doc_key": "ai-test-59", "ner": [[4, 6, "organisation"], [17, 18, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 17, 18, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "late", "2006", ",", "Red", "Envelope", "Entertainment", "also", "expanded", "into", "original", "content", "production", "with", "filmmakers", "such", "as", "John", "Waters", "."], "sentence-detokenized": "In late 2006, Red Envelope Entertainment also expanded into original content production with filmmakers such as John Waters.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 26], [27, 40], [41, 45], [46, 54], [55, 59], [60, 68], [69, 76], [77, 87], [88, 92], [93, 103], [104, 108], [109, 111], [112, 116], [117, 123], [123, 124]]}
{"doc_key": "ai-test-60", "ner": [[7, 11, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "building", "is", "now", "part", "of", "the", "Beth", "Israel", "Deaconess", "Medical", "Center", "."], "sentence-detokenized": "The building is now part of the Beth Israel Deaconess Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 31], [32, 36], [37, 43], [44, 53], [54, 61], [62, 68], [68, 69]]}
{"doc_key": "ai-test-61", "ner": [[18, 19, "field"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "common", "theme", "of", "this", "work", "is", "the", "adoption", "of", "a", "sign", "-", "theoretic", "perspective", "on", "issues", "of", "artificial", "intelligence", "and", "knowledge", "representation", "."], "sentence-detokenized": "A common theme of this work is the adoption of a sign-theoretic perspective on issues of artificial intelligence and knowledge representation.", "token2charspan": [[0, 1], [2, 8], [9, 14], [15, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 43], [44, 46], [47, 48], [49, 53], [53, 54], [54, 63], [64, 75], [76, 78], [79, 85], [86, 88], [89, 99], [100, 112], [113, 116], [117, 126], [127, 141], [141, 142]]}
{"doc_key": "ai-test-62", "ner": [[2, 4, "task"], [6, 10, "task"], [22, 23, "task"], [41, 42, "task"], [44, 45, "task"], [48, 50, "task"], [52, 52, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 4, 22, 23, "type-of", "", false, false], [2, 4, 48, 50, "compare", "", false, false], [2, 4, 48, 50, "opposite", "", false, false], [6, 10, 2, 4, "named", "", false, false], [41, 42, 48, 50, "part-of", "", false, false], [44, 45, 48, 50, "part-of", "", false, false], [48, 50, 22, 23, "type-of", "", false, false], [52, 52, 48, 50, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "term", "neural", "machine", "translation", "(", "NMT", ")", ",", "for", "example", ",", "highlights", "the", "fact", "that", "deep", "learning", "-", "based", "approaches", "to", "machine", "translation", "learn", "sequence", "-", "to", "-", "sequence", "transformations", "directly", ",", "eliminating", "the", "need", "for", "intermediate", "steps", "such", "as", "word", "alignment", "and", "language", "modelling", "used", "in", "statistical", "machine", "translation", "(", "SMT", ")", "."], "sentence-detokenized": "The term neural machine translation (NMT), for example, highlights the fact that deep learning-based approaches to machine translation learn sequence-to-sequence transformations directly, eliminating the need for intermediate steps such as word alignment and language modelling used in statistical machine translation (SMT).", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 23], [24, 35], [36, 37], [37, 40], [40, 41], [41, 42], [43, 46], [47, 54], [54, 55], [56, 66], [67, 70], [71, 75], [76, 80], [81, 85], [86, 94], [94, 95], [95, 100], [101, 111], [112, 114], [115, 122], [123, 134], [135, 140], [141, 149], [149, 150], [150, 152], [152, 153], [153, 161], [162, 177], [178, 186], [186, 187], [188, 199], [200, 203], [204, 208], [209, 212], [213, 225], [226, 231], [232, 236], [237, 239], [240, 244], [245, 254], [255, 258], [259, 267], [268, 277], [278, 282], [283, 285], [286, 297], [298, 305], [306, 317], [318, 319], [319, 322], [322, 323], [323, 324]]}
{"doc_key": "ai-test-63", "ner": [[6, 6, "field"], [10, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 6, 10, 11, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Most", "research", "in", "the", "field", "of", "WSD", "is", "conducted", "using", "Word", "Net", "as", "a", "reference", "sense", "inventory", "."], "sentence-detokenized": "Most research in the field of WSD is conducted using WordNet as a reference sense inventory.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 26], [27, 29], [30, 33], [34, 36], [37, 46], [47, 52], [53, 57], [57, 60], [61, 63], [64, 65], [66, 75], [76, 81], [82, 91], [91, 92]]}
{"doc_key": "ai-test-64", "ner": [[2, 3, "misc"], [10, 11, "researcher"], [13, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 2, 3, "general-affiliation", "", false, true], [13, 14, 2, 3, "general-affiliation", "", false, true]], "relations_mapping_to_source": [0, 1], "sentence": ["Notable", "former", "PhD", "students", "and", "postdocs", "in", "his", "group", "include", "Richard", "Zemel", "and", "Zoubin", "Ghahramani", "."], "sentence-detokenized": "Notable former PhD students and postdocs in his group include Richard Zemel and Zoubin Ghahramani.", "token2charspan": [[0, 7], [8, 14], [15, 18], [19, 27], [28, 31], [32, 40], [41, 43], [44, 47], [48, 53], [54, 61], [62, 69], [70, 75], [76, 79], [80, 86], [87, 97], [97, 98]]}
{"doc_key": "ai-test-65", "ner": [[7, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Each", "prediction", "result", "or", "instance", "of", "a", "confusion", "matrix", "represents", "a", "point", "in", "the", "ROC", "space", "."], "sentence-detokenized": "Each prediction result or instance of a confusion matrix represents a point in the ROC space.", "token2charspan": [[0, 4], [5, 15], [16, 22], [23, 25], [26, 34], [35, 37], [38, 39], [40, 49], [50, 56], [57, 67], [68, 69], [70, 75], [76, 78], [79, 82], [83, 86], [87, 92], [92, 93]]}
{"doc_key": "ai-test-66", "ner": [[3, 3, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [17, 19, "product"], [22, 25, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 22, 25, "physical", "", false, false], [7, 8, 22, 25, "physical", "", false, false], [10, 11, 22, 25, "physical", "", false, false], [17, 19, 3, 3, "artifact", "", false, false], [17, 19, 7, 8, "artifact", "", false, false], [17, 19, 10, 11, "artifact", "", false, false], [17, 19, 22, 25, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "1997", ",", "Thrun", "and", "his", "colleagues", "Wolfram", "Burgard", "and", "Dieter", "Fox", "developed", "the", "world", "'s", "first", "robot-assisted", "visitor", "guide", "at", "the", "Deutsches", "Museum", "in", "Bonn", "(", "1997", ")", "."], "sentence-detokenized": "In 1997, Thrun and his colleagues Wolfram Burgard and Dieter Fox developed the world's first robot-assisted visitor guide at the Deutsches Museum in Bonn (1997).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 18], [19, 22], [23, 33], [34, 41], [42, 49], [50, 53], [54, 60], [61, 64], [65, 74], [75, 78], [79, 84], [84, 86], [87, 92], [93, 107], [108, 115], [116, 121], [122, 124], [125, 128], [129, 138], [139, 145], [146, 148], [149, 153], [154, 155], [155, 159], [159, 160], [160, 161]]}
{"doc_key": "ai-test-67", "ner": [[0, 1, "product"], [7, 7, "misc"], [23, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 0, 1, "part-of", "", false, false], [23, 25, 0, 1, "usage", "", false, false], [27, 28, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Word", "Net", "is", "a", "lexical", "database", "of", "semantic", "relations", "between", "words", "in", "more", "than", "200", "languages", ".", "It", "is", "mainly", "used", "for", "automatic", "natural", "language", "processing", "and", "artificial", "intelligence", "applications", "."], "sentence-detokenized": "WordNet is a lexical database of semantic relations between words in more than 200 languages. It is mainly used for automatic natural language processing and artificial intelligence applications.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 32], [33, 41], [42, 51], [52, 59], [60, 65], [66, 68], [69, 73], [74, 78], [79, 82], [83, 92], [92, 93], [94, 96], [97, 99], [100, 106], [107, 111], [112, 115], [116, 125], [126, 133], [134, 142], [143, 153], [154, 157], [158, 168], [169, 181], [182, 194], [194, 195]]}
{"doc_key": "ai-test-68", "ner": [[5, 7, "field"], [12, 15, "conference"], [17, 25, "conference"], [27, 27, "conference"], [29, 31, "conference"], [37, 38, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 15, 5, 7, "topic", "", false, false], [12, 15, 37, 38, "topic", "", false, false], [17, 25, 5, 7, "topic", "", false, false], [17, 25, 37, 38, "topic", "", false, false], [27, 27, 5, 7, "topic", "", false, false], [27, 27, 37, 38, "topic", "", false, false], [29, 31, 5, 7, "topic", "", false, false], [29, 31, 37, 38, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Conferences", "in", "the", "field", "of", "natural", "language", "processing", ",", "such", "as", "the", "Association", "for", "Computational", "Linguistics", ",", "North", "American", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "EMNLP", "and", "HLT", ",", "are", "beginning", "to", "include", "contributions", "on", "language", "processing", "."], "sentence-detokenized": "Conferences in the field of natural language processing, such as the Association for Computational Linguistics, North American Chapter of the Association for Computational Linguistics, EMNLP and HLT, are beginning to include contributions on language processing.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 24], [25, 27], [28, 35], [36, 44], [45, 55], [55, 56], [57, 61], [62, 64], [65, 68], [69, 80], [81, 84], [85, 98], [99, 110], [110, 111], [112, 117], [118, 126], [127, 134], [135, 137], [138, 141], [142, 153], [154, 157], [158, 171], [172, 183], [183, 184], [185, 190], [191, 194], [195, 198], [198, 199], [200, 203], [204, 213], [214, 216], [217, 224], [225, 238], [239, 241], [242, 250], [251, 261], [261, 262]]}
{"doc_key": "ai-test-69", "ner": [[21, 24, "misc"], [36, 38, "misc"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "number", "of", "Java", "programs", "use", "the", "lexicon", "to", "process", "the", "variations", "in", "biomedical", "texts", "by", "assigning", "words", "to", "their", "part", "of", "speech", ",", "which", "can", "be", "helpful", "when", "searching", "on", "the", "Internet", "or", "in", "an", "electronic", "patient", "record", "."], "sentence-detokenized": "A number of Java programs use the lexicon to process the variations in biomedical texts by assigning words to their part of speech, which can be helpful when searching on the Internet or in an electronic patient record.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 16], [17, 25], [26, 29], [30, 33], [34, 41], [42, 44], [45, 52], [53, 56], [57, 67], [68, 70], [71, 81], [82, 87], [88, 90], [91, 100], [101, 106], [107, 109], [110, 115], [116, 120], [121, 123], [124, 130], [130, 131], [132, 137], [138, 141], [142, 144], [145, 152], [153, 157], [158, 167], [168, 170], [171, 174], [175, 183], [184, 186], [187, 189], [190, 192], [193, 203], [204, 211], [212, 218], [218, 219]]}
{"doc_key": "ai-test-70", "ner": [[7, 7, "algorithm"], [9, 9, "algorithm"], [11, 11, "algorithm"], [13, 13, "algorithm"], [15, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "many", "newer", "algorithms", "such", "as", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", ",", "and", "others", "."], "sentence-detokenized": "There are many newer algorithms such as LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost, and others.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 20], [21, 31], [32, 36], [37, 39], [40, 47], [47, 48], [49, 59], [59, 60], [61, 71], [71, 72], [73, 80], [80, 81], [82, 91], [91, 92], [93, 96], [97, 103], [103, 104]]}
{"doc_key": "ai-test-71", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "sample", "implementation", "in", "Python", ":"], "sentence-detokenized": "This is a sample implementation in Python:", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 16], [17, 31], [32, 34], [35, 41], [41, 42]]}
{"doc_key": "ai-test-72", "ner": [[0, 0, "organisation"], [1, 2, "product"], [7, 7, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 0, 0, "artifact", "made_by_company", false, false], [7, 7, 1, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Mattel", "'s", "Intellivision", "game", "console", "offered", "the", "Intellivoice", "speech", "synthesis", "module", "in", "1982", "."], "sentence-detokenized": "Mattel's Intellivision game console offered the Intellivoice speech synthesis module in 1982.", "token2charspan": [[0, 6], [6, 8], [9, 22], [23, 27], [28, 35], [36, 43], [44, 47], [48, 60], [61, 67], [68, 77], [78, 84], [85, 87], [88, 92], [92, 93]]}
{"doc_key": "ai-test-73", "ner": [[4, 5, "task"], [8, 14, "task"], [16, 17, "field"], [19, 21, "task"], [24, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 14, 4, 5, "part-of", "", false, false], [16, 17, 4, 5, "part-of", "", false, false], [19, 21, 4, 5, "part-of", "", false, false], [24, 28, 19, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "also", "worked", "on", "machine", "translation", ",", "both", "high", "-", "precision", "knowledge", "-", "based", "MT", "and", "machine", "learning", "for", "statistical", "machine", "translation", "(", "e.g.", "generalised", "example", "-", "based", "MT", ")", "."], "sentence-detokenized": "He also worked on machine translation, both high-precision knowledge-based MT and machine learning for statistical machine translation (e.g. generalised example-based MT).", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 17], [18, 25], [26, 37], [37, 38], [39, 43], [44, 48], [48, 49], [49, 58], [59, 68], [68, 69], [69, 74], [75, 77], [78, 81], [82, 89], [90, 98], [99, 102], [103, 114], [115, 122], [123, 134], [135, 136], [136, 140], [141, 152], [153, 160], [160, 161], [161, 166], [167, 169], [169, 170], [170, 171]]}
{"doc_key": "ai-test-74", "ner": [[0, 1, "misc"], [5, 5, "misc"], [20, 21, "algorithm"], [23, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 32, "field"], [34, 34, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 20, 21, "general-affiliation", "", false, false], [0, 1, 23, 24, "general-affiliation", "", false, false], [0, 1, 26, 27, "general-affiliation", "", false, false], [0, 1, 29, 29, "general-affiliation", "", false, false], [0, 1, 31, 32, "general-affiliation", "", false, false], [0, 1, 34, 34, "general-affiliation", "", false, false], [5, 5, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "usually", "called", "Mathematica", ")", "is", "a", "modern", "technical", "computing", "system", "that", "covers", "most", "technical", "areas", "-", "including", "neural", "networks", ",", "machine", "learning", ",", "image", "processing", ",", "geometry", ",", "data", "science", ",", "visualisations", "and", "others", "."], "sentence-detokenized": "Wolfram Mathematica (usually called Mathematica) is a modern technical computing system that covers most technical areas - including neural networks, machine learning, image processing, geometry, data science, visualisations and others.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 28], [29, 35], [36, 47], [47, 48], [49, 51], [52, 53], [54, 60], [61, 70], [71, 80], [81, 87], [88, 92], [93, 99], [100, 104], [105, 114], [115, 120], [121, 122], [123, 132], [133, 139], [140, 148], [148, 149], [150, 157], [158, 166], [166, 167], [168, 173], [174, 184], [184, 185], [186, 194], [194, 195], [196, 200], [201, 208], [208, 209], [210, 224], [225, 228], [229, 235], [235, 236]]}
{"doc_key": "ai-test-75", "ner": [[2, 6, "product"], [10, 12, "researcher"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 17, 2, 6, "type-of", "", false, false], [17, 17, 10, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "digitally", "operated", "and", "programmable", "robot", "was", "invented", "by", "George", "Devol", "in", "1954", "and", "eventually", "named", "Unimate", "."], "sentence-detokenized": "The first digitally operated and programmable robot was invented by George Devol in 1954 and eventually named Unimate.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 28], [29, 32], [33, 45], [46, 51], [52, 55], [56, 64], [65, 67], [68, 74], [75, 80], [81, 83], [84, 88], [89, 92], [93, 103], [104, 109], [110, 117], [117, 118]]}
{"doc_key": "ai-test-76", "ner": [[1, 1, "algorithm"], [3, 3, "algorithm"], [20, 22, "task"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[1, 1, 3, 3, "compare", "", false, false], [3, 3, 20, 22, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["Like", "DBNs", ",", "DBMs", "can", "learn", "complex", "and", "abstract", "internal", "representations", "of", "the", "input", "in", "tasks", "such", "as", "object", "or", "speech", "recognition", "by", "using", "limited", ",", "labelled", "data", "to", "fine", "-", "tune", "representations", "created", "with", "a", "large", "set", "of", "unlabelled", "sensory", "input", "data", "."], "sentence-detokenized": "Like DBNs, DBMs can learn complex and abstract internal representations of the input in tasks such as object or speech recognition by using limited, labelled data to fine-tune representations created with a large set of unlabelled sensory input data.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 15], [16, 19], [20, 25], [26, 33], [34, 37], [38, 46], [47, 55], [56, 71], [72, 74], [75, 78], [79, 84], [85, 87], [88, 93], [94, 98], [99, 101], [102, 108], [109, 111], [112, 118], [119, 130], [131, 133], [134, 139], [140, 147], [147, 148], [149, 157], [158, 162], [163, 165], [166, 170], [170, 171], [171, 175], [176, 191], [192, 199], [200, 204], [205, 206], [207, 212], [213, 216], [217, 219], [220, 230], [231, 238], [239, 244], [245, 249], [249, 250]]}
{"doc_key": "ai-test-77", "ner": [[5, 9, "task"], [13, 13, "conference"], [15, 15, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 13, 5, 9, "topic", "", false, false], [15, 15, 5, 9, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Scientific", "conferences", "where", "papers", "on", "image", "-", "based", "activity", "recognition", "frequently", "appear", "are", "ICCV", "and", "CVPR", "."], "sentence-detokenized": "Scientific conferences where papers on image-based activity recognition frequently appear are ICCV and CVPR.", "token2charspan": [[0, 10], [11, 22], [23, 28], [29, 35], [36, 38], [39, 44], [44, 45], [45, 50], [51, 59], [60, 71], [72, 82], [83, 89], [90, 93], [94, 98], [99, 102], [103, 107], [107, 108]]}
{"doc_key": "ai-test-78", "ner": [[1, 1, "field"], [4, 5, "algorithm"], [7, 7, "algorithm"], [34, 34, "misc"]], "ner_mapping_to_source": [0, 1, 2, 6], "relations": [[4, 5, 1, 1, "part-of", "", false, false], [4, 5, 34, 34, "related-to", "", false, false], [7, 7, 4, 5, "named", "", false, false]], "relations_mapping_to_source": [0, 3, 4], "sentence": ["In", "statistics", ",", "an", "expectation", "maximisation", "(", "EM", ")", "algorithm", "is", "an", "iterative", "method", "for", "obtaining", "maximum", "likelihood", "or", "maximum", "a", "posteriori", "estimates", "of", "parameters", "in", "statistical", "models", "where", "the", "model", "depends", "on", "unobserved", "latent", "variables", "."], "sentence-detokenized": "In statistics, an expectation maximisation (EM) algorithm is an iterative method for obtaining maximum likelihood or maximum a posteriori estimates of parameters in statistical models where the model depends on unobserved latent variables.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 17], [18, 29], [30, 42], [43, 44], [44, 46], [46, 47], [48, 57], [58, 60], [61, 63], [64, 73], [74, 80], [81, 84], [85, 94], [95, 102], [103, 113], [114, 116], [117, 124], [125, 126], [127, 137], [138, 147], [148, 150], [151, 161], [162, 164], [165, 176], [177, 183], [184, 189], [190, 193], [194, 199], [200, 207], [208, 210], [211, 221], [222, 228], [229, 238], [238, 239]]}
{"doc_key": "ai-test-79", "ner": [[6, 8, "metrics"], [10, 10, "metrics"], [14, 16, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 6, 8, "named", "", false, false], [18, 18, 14, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Similarly", ",", "examiners", "sometimes", "report", "the", "FALSE", "positive", "rate", "(", "FPR", ")", "and", "the", "FALSE", "negative", "rate", "(", "FNR", ")", "."], "sentence-detokenized": "Similarly, examiners sometimes report the FALSE positive rate (FPR) and the FALSE negative rate (FNR).", "token2charspan": [[0, 9], [9, 10], [11, 20], [21, 30], [31, 37], [38, 41], [42, 47], [48, 56], [57, 61], [62, 63], [63, 66], [66, 67], [68, 71], [72, 75], [76, 81], [82, 90], [91, 95], [96, 97], [97, 100], [100, 101], [101, 102]]}
{"doc_key": "ai-test-80", "ner": [[6, 11, "metrics"], [14, 14, "field"], [17, 18, "metrics"], [21, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 14, 6, 11, "usage", "", false, false], [21, 22, 17, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "concept", "is", "similar", "to", "the", "signal", "-", "to", "-", "noise", "ratio", "used", "in", "science", "and", "the", "confusion", "matrix", "used", "in", "artificial", "intelligence", "."], "sentence-detokenized": "The concept is similar to the signal-to-noise ratio used in science and the confusion matrix used in artificial intelligence.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 25], [26, 29], [30, 36], [36, 37], [37, 39], [39, 40], [40, 45], [46, 51], [52, 56], [57, 59], [60, 67], [68, 71], [72, 75], [76, 85], [86, 92], [93, 97], [98, 100], [101, 111], [112, 124], [124, 125]]}
{"doc_key": "ai-test-81", "ner": [[5, 6, "field"], [11, 13, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [31, 35, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 11, 13, "general-affiliation", "", false, false], [5, 6, 18, 19, "general-affiliation", "", false, false], [5, 6, 21, 22, "general-affiliation", "", false, false], [31, 35, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Code", "of", "Ethics", "for", "Human", "Augmentation", ",", "originally", "introduced", "by", "Steve", "Mann", "in", "2004", "and", "refined", "with", "Ray", "Kurzweil", "and", "Marvin", "Minsky", "in", "2013", ",", "was", "finally", "ratified", "at", "the", "Virtual", "Reality", "Toronto", "conference", "on", "25", "June", "2017", "."], "sentence-detokenized": "The Code of Ethics for Human Augmentation, originally introduced by Steve Mann in 2004 and refined with Ray Kurzweil and Marvin Minsky in 2013, was finally ratified at the Virtual Reality Toronto conference on 25 June 2017.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 18], [19, 22], [23, 28], [29, 41], [41, 42], [43, 53], [54, 64], [65, 67], [68, 73], [74, 78], [79, 81], [82, 86], [87, 90], [91, 98], [99, 103], [104, 107], [108, 116], [117, 120], [121, 127], [128, 134], [135, 137], [138, 142], [142, 143], [144, 147], [148, 155], [156, 164], [165, 167], [168, 171], [172, 179], [180, 187], [188, 195], [196, 206], [207, 209], [210, 212], [213, 217], [218, 222], [222, 223]]}
{"doc_key": "ai-test-82", "ner": [[2, 4, "person"], [11, 11, "organisation"], [17, 18, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 4, 11, 11, "role", "directed_for", false, false], [2, 4, 17, 18, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1913", "Walter", "R.", "Booth", "directed", "10", "films", "for", "the", "British", "Kinoplastikon", ",", "presumably", "in", "collaboration", "with", "Cecil", "Hepworth", "."], "sentence-detokenized": "In 1913 Walter R. Booth directed 10 films for the British Kinoplastikon, presumably in collaboration with Cecil Hepworth.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 17], [18, 23], [24, 32], [33, 35], [36, 41], [42, 45], [46, 49], [50, 57], [58, 71], [71, 72], [73, 83], [84, 86], [87, 100], [101, 105], [106, 111], [112, 120], [120, 121]]}
{"doc_key": "ai-test-83", "ner": [[16, 16, "location"], [13, 14, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 16, 16, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "presented", "their", "new", "robot", "in", "1961", "at", "a", "trade", "fair", "at", "the", "Cow", "Palace", "in", "Chicago", "."], "sentence-detokenized": "They presented their new robot in 1961 at a trade fair at the Cow Palace in Chicago.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 24], [25, 30], [31, 33], [34, 38], [39, 41], [42, 43], [44, 49], [50, 54], [55, 57], [58, 61], [62, 65], [66, 72], [73, 75], [76, 83], [83, 84]]}
{"doc_key": "ai-test-84", "ner": [[10, 11, "field"], [15, 16, "field"]], "ner_mapping_to_source": [2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["While", "some", "chatbot", "applications", "use", "extensive", "word", "classification", "processes", ",", "natural", "language", "processors", "and", "sophisticated", "artificial", "intelligence", ",", "others", "simply", "search", "for", "common", "keywords", "and", "generate", "responses", "based", "on", "generic", "phrases", "drawn", "from", "an", "associated", "library", "or", "database", "."], "sentence-detokenized": "While some chatbot applications use extensive word classification processes, natural language processors and sophisticated artificial intelligence, others simply search for common keywords and generate responses based on generic phrases drawn from an associated library or database.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 31], [32, 35], [36, 45], [46, 50], [51, 65], [66, 75], [75, 76], [77, 84], [85, 93], [94, 104], [105, 108], [109, 122], [123, 133], [134, 146], [146, 147], [148, 154], [155, 161], [162, 168], [169, 172], [173, 179], [180, 188], [189, 192], [193, 201], [202, 211], [212, 217], [218, 220], [221, 228], [229, 236], [237, 242], [243, 247], [248, 250], [251, 261], [262, 269], [270, 272], [273, 281], [281, 282]]}
{"doc_key": "ai-test-85", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "WaveNet", "model", "proposed", "in", "2016", "achieves", "excellent", "voice", "quality", "performance", "."], "sentence-detokenized": "The WaveNet model proposed in 2016 achieves excellent voice quality performance.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 43], [44, 53], [54, 59], [60, 67], [68, 79], [79, 80]]}
{"doc_key": "ai-test-86", "ner": [[4, 4, "product"], [6, 7, "misc"], [9, 10, "misc"], [12, 13, "misc"], [15, 18, "misc"], [20, 22, "organisation"], [24, 24, "organisation"], [26, 28, "organisation"], [31, 31, "organisation"], [33, 36, "organisation"], [38, 39, "organisation"], [41, 41, "organisation"], [43, 45, "organisation"], [48, 48, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 4, 6, 7, "general-affiliation", "", false, false], [4, 4, 9, 10, "general-affiliation", "", false, false], [4, 4, 12, 13, "general-affiliation", "", false, false], [4, 4, 15, 18, "general-affiliation", "", false, false], [20, 22, 4, 4, "usage", "", false, false], [24, 24, 4, 4, "usage", "", false, false], [26, 28, 4, 4, "usage", "", false, false], [31, 31, 4, 4, "usage", "", false, false], [33, 36, 4, 4, "usage", "", false, false], [38, 39, 4, 4, "usage", "", false, false], [41, 41, 4, 4, "usage", "", false, false], [43, 45, 4, 4, "usage", "", false, false], [48, 48, 4, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organisations", "known", "to", "use", "ALE", "for", "emergency", "management", ",", "disaster", "relief", ",", "normal", "communications", "or", "response", "to", "extraordinary", "situations", ":", "American", "Red", "Cross", ",", "FEMA", ",", "Disaster", "Medical", "Assistance", "Teams", ",", "NATO", ",", "Federal", "Bureau", "of", "Investigation", ",", "United", "Nations", ",", "AT&T", ",", "Civil", "Air", "Patrol", ",", "(", "ARES", ")", "."], "sentence-detokenized": "Organisations known to use ALE for emergency management, disaster relief, normal communications or response to extraordinary situations: American Red Cross, FEMA, Disaster Medical Assistance Teams, NATO, Federal Bureau of Investigation, United Nations, AT&T, Civil Air Patrol, (ARES).", "token2charspan": [[0, 13], [14, 19], [20, 22], [23, 26], [27, 30], [31, 34], [35, 44], [45, 55], [55, 56], [57, 65], [66, 72], [72, 73], [74, 80], [81, 95], [96, 98], [99, 107], [108, 110], [111, 124], [125, 135], [135, 136], [137, 145], [146, 149], [150, 155], [155, 156], [157, 161], [161, 162], [163, 171], [172, 179], [180, 190], [191, 196], [196, 197], [198, 202], [202, 203], [204, 211], [212, 218], [219, 221], [222, 235], [235, 236], [237, 243], [244, 251], [251, 252], [253, 257], [257, 258], [259, 264], [265, 268], [269, 275], [275, 276], [277, 278], [278, 282], [282, 283], [283, 284]]}
{"doc_key": "ai-test-87", "ner": [[6, 7, "algorithm"], [17, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", ",", "for", "simplicity", ",", "the", "Kronecker", "delta", "is", "used", "(", "cf", ".", "the", "derivative", "of", "a", "sigmoid", "function", "expressed", "by", "the", "function", "itself", ")", "."], "sentence-detokenized": "Here, for simplicity, the Kronecker delta is used (cf. the derivative of a sigmoid function expressed by the function itself).", "token2charspan": [[0, 4], [4, 5], [6, 9], [10, 20], [20, 21], [22, 25], [26, 35], [36, 41], [42, 44], [45, 49], [50, 51], [51, 53], [53, 54], [55, 58], [59, 69], [70, 72], [73, 74], [75, 82], [83, 91], [92, 101], [102, 104], [105, 108], [109, 117], [118, 124], [124, 125], [125, 126]]}
{"doc_key": "ai-test-88", "ner": [[13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "theory", "is", "based", "on", "philosophical", "principles", "and", "was", "founded", "around", "1960", "by", "Ray", "Solomonoff", ".", "Samuel", "Rathmanner", "and", "Marcus", "Hutter", "."], "sentence-detokenized": "The theory is based on philosophical principles and was founded around 1960 by Ray Solomonoff. Samuel Rathmanner and Marcus Hutter.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 36], [37, 47], [48, 51], [52, 55], [56, 63], [64, 70], [71, 75], [76, 78], [79, 82], [83, 93], [93, 94], [95, 101], [102, 112], [113, 116], [117, 123], [124, 130], [130, 131]]}
{"doc_key": "ai-test-89", "ner": [[0, 0, "product"], [10, 12, "misc"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 12, "type-of", "", false, false], [0, 0, 14, 15, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["WordNet", ",", "a", "freely", "available", "database", "originally", "conceived", "as", "a", "semantic", "network", "based", "on", "psycholinguistic", "principles", ",", "has", "been", "extended", "by", "adding", "definitions", "and", "is", "now", "also", "considered", "a", "dictionary", "."], "sentence-detokenized": "WordNet, a freely available database originally conceived as a semantic network based on psycholinguistic principles, has been extended by adding definitions and is now also considered a dictionary.", "token2charspan": [[0, 7], [7, 8], [9, 10], [11, 17], [18, 27], [28, 36], [37, 47], [48, 57], [58, 60], [61, 62], [63, 71], [72, 79], [80, 85], [86, 88], [89, 105], [106, 116], [116, 117], [118, 121], [122, 126], [127, 135], [136, 138], [139, 145], [146, 157], [158, 161], [162, 164], [165, 168], [169, 173], [174, 184], [185, 186], [187, 197], [197, 198]]}
{"doc_key": "ai-test-90", "ner": [[5, 6, "field"], [15, 15, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 15, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Advances", "in", "the", "field", "of", "computational", "imaging", "research", "are", "presented", "in", "various", "venues", ",", "including", "SIGGRAPH", "publications", "and", "the", "."], "sentence-detokenized": "Advances in the field of computational imaging research are presented in various venues, including SIGGRAPH publications and the.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 21], [22, 24], [25, 38], [39, 46], [47, 55], [56, 59], [60, 69], [70, 72], [73, 80], [81, 87], [87, 88], [89, 98], [99, 107], [108, 120], [121, 124], [125, 128], [128, 129]]}
{"doc_key": "ai-test-91", "ner": [[0, 0, "task"], [9, 10, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 0, "part-of", "", false, false], [12, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "considered", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multiclass", "classification", "."], "sentence-detokenized": "Classification can be considered as two separate problems - binary classification and multiclass classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 48], [49, 57], [58, 59], [60, 66], [67, 81], [82, 85], [86, 96], [97, 111], [111, 112]]}
{"doc_key": "ai-test-92", "ner": [[11, 11, "algorithm"], [20, 20, "algorithm"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Advanced", "gene", "finders", "for", "prokaryotic", "and", "eukaryotic", "genomes", "typically", "use", "complex", "probabilistic", "models", ",", "such", "as", "hidden", "Markov", "models", "(", "HMMs", ")", ",", "to", "combine", "information", "from", "a", "variety", "of", "different", "signal", "and", "content", "measurements", "."], "sentence-detokenized": "Advanced gene finders for prokaryotic and eukaryotic genomes typically use complex probabilistic models, such as hidden Markov models (HMMs), to combine information from a variety of different signal and content measurements.", "token2charspan": [[0, 8], [9, 13], [14, 21], [22, 25], [26, 37], [38, 41], [42, 52], [53, 60], [61, 70], [71, 74], [75, 82], [83, 96], [97, 103], [103, 104], [105, 109], [110, 112], [113, 119], [120, 126], [127, 133], [134, 135], [135, 139], [139, 140], [140, 141], [142, 144], [145, 152], [153, 164], [165, 169], [170, 171], [172, 179], [180, 182], [183, 192], [193, 199], [200, 203], [204, 211], [212, 224], [224, 225]]}
{"doc_key": "ai-test-93", "ner": [[0, 0, "misc"], [5, 6, "field"], [9, 10, "algorithm"], [13, 14, "algorithm"], [17, 17, "algorithm"], [27, 28, "algorithm"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [[17, 17, 13, 14, "named", "", false, false]], "relations_mapping_to_source": [4], "sentence": ["Neuroevolution", "is", "a", "form", "of", "artificial", "intelligence", "that", "uses", "evolutionary", "algorithms", "to", "generate", "artificial", "neural", "networks", "(", "ANN", ")", ",", "parameters", ",", "topology", "and", "rules", ".", "and", "evolutionary", "robotics", "."], "sentence-detokenized": "Neuroevolution is a form of artificial intelligence that uses evolutionary algorithms to generate artificial neural networks (ANN), parameters, topology and rules. and evolutionary robotics.", "token2charspan": [[0, 14], [15, 17], [18, 19], [20, 24], [25, 27], [28, 38], [39, 51], [52, 56], [57, 61], [62, 74], [75, 85], [86, 88], [89, 97], [98, 108], [109, 115], [116, 124], [125, 126], [126, 129], [129, 130], [130, 131], [132, 142], [142, 143], [144, 152], [153, 156], [157, 162], [162, 163], [164, 167], [168, 180], [181, 189], [189, 190]]}
{"doc_key": "ai-test-94", "ner": [[1, 1, "organisation"], [6, 7, "metrics"], [9, 9, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 1, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "IBM", "proposed", "and", "implemented", "the", "BLEU", "system", ",", "Papineni", "et", "al", "."], "sentence-detokenized": "Since IBM proposed and implemented the BLEU system, Papineni et al.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 22], [23, 34], [35, 38], [39, 43], [44, 50], [50, 51], [52, 60], [61, 63], [64, 66], [66, 67]]}
{"doc_key": "ai-test-95", "ner": [[8, 14, "conference"], [16, 16, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 16, 8, 14, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2009", ",", "at", "a", "conference", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "experts", "discussed", "whether", "computers", "and", "robots", "might", "be", "able", "to", "achieve", "autonomy", "and", "to", "what", "extent", "these", "capabilities", "might", "pose", "a", "threat", "or", "danger", "."], "sentence-detokenized": "In 2009, at a conference of the Association for the Advancement of Artificial Intelligence (AAAI), experts discussed whether computers and robots might be able to achieve autonomy and to what extent these capabilities might pose a threat or danger.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 13], [14, 24], [25, 27], [28, 31], [32, 43], [44, 47], [48, 51], [52, 63], [64, 66], [67, 77], [78, 90], [91, 92], [92, 96], [96, 97], [97, 98], [99, 106], [107, 116], [117, 124], [125, 134], [135, 138], [139, 145], [146, 151], [152, 154], [155, 159], [160, 162], [163, 170], [171, 179], [180, 183], [184, 186], [187, 191], [192, 198], [199, 204], [205, 217], [218, 223], [224, 228], [229, 230], [231, 237], [238, 240], [241, 247], [247, 248]]}
{"doc_key": "ai-test-96", "ner": [[26, 28, "metrics"], [29, 33, "researcher"], [33, 34, "researcher"], [36, 41, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[36, 41, 26, 28, "topic", "", false, false], [36, 41, 29, 33, "artifact", "", false, false], [36, 41, 33, 34, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["After", "boosting", ",", "a", "classifier", "constructed", "from", "200", "features", "could", "achieve", "a", "recognition", "rate", "of", "95", "%", "at", "a", "^", "{", "-", "5", "}", "/", "math", "FALSE", "positive", "rate", ".P", ".", "Viola", ",", "M.", "Jones", ",", "Robust", "Real", "-", "time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "After boosting, a classifier constructed from 200 features could achieve a recognition rate of 95% at a ^ {-5} / math FALSE positive rate .P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 17], [18, 28], [29, 40], [41, 45], [46, 49], [50, 58], [59, 64], [65, 72], [73, 74], [75, 86], [87, 91], [92, 94], [95, 97], [97, 98], [99, 101], [102, 103], [104, 105], [106, 107], [107, 108], [108, 109], [109, 110], [111, 112], [113, 117], [118, 123], [124, 132], [133, 137], [138, 140], [140, 141], [142, 147], [147, 148], [149, 151], [152, 157], [157, 158], [159, 165], [166, 170], [170, 171], [171, 175], [176, 182], [183, 192], [192, 193], [194, 198], [198, 199]]}
{"doc_key": "ai-test-97", "ner": [[6, 6, "programlang"], [9, 9, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "website", "was", "originally", "based", "on", "Perl", ",", "but", "IMDb", "no", "longer", "discloses", "which", "software", "is", "used", "for", "security", "reasons", "."], "sentence-detokenized": "The website was originally based on Perl, but IMDb no longer discloses which software is used for security reasons.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 26], [27, 32], [33, 35], [36, 40], [40, 41], [42, 45], [46, 50], [51, 53], [54, 60], [61, 70], [71, 76], [77, 85], [86, 88], [89, 93], [94, 97], [98, 106], [107, 114], [114, 115]]}
{"doc_key": "ai-test-98", "ner": [[9, 10, "researcher"], [12, 13, "researcher"], [15, 16, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "start", "-", "up", "was", "founded", "in", "2010", "by", "Demis", "Hassabis", ",", "Shane", "Legg", "and", "Mustafa", "Suleyman", "."], "sentence-detokenized": "The start-up was founded in 2010 by Demis Hassabis, Shane Legg and Mustafa Suleyman.", "token2charspan": [[0, 3], [4, 9], [9, 10], [10, 12], [13, 16], [17, 24], [25, 27], [28, 32], [33, 35], [36, 41], [42, 50], [50, 51], [52, 57], [58, 62], [63, 66], [67, 74], [75, 83], [83, 84]]}
{"doc_key": "ai-test-99", "ner": [[4, 5, "misc"], [8, 10, "metrics"], [25, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 4, 5, "type-of", "", false, false], [25, 26, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "very", "commonly", "used", "loss", "functions", "are", "the", "mean", "square", "error", ",", "mathL", "(", "a", ")", "=", "a", "^", "2", "/", "math", ",", "and", "the", "absolute", "loss", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "/", "math", "."], "sentence-detokenized": "Two very commonly used loss functions are the mean square error, mathL (a) = a ^ 2 / math, and the absolute loss, mathL (a) = | a | / math.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 27], [28, 37], [38, 41], [42, 45], [46, 50], [51, 57], [58, 63], [63, 64], [65, 70], [71, 72], [72, 73], [73, 74], [75, 76], [77, 78], [79, 80], [81, 82], [83, 84], [85, 89], [89, 90], [91, 94], [95, 98], [99, 107], [108, 112], [112, 113], [114, 119], [120, 121], [121, 122], [122, 123], [124, 125], [126, 127], [128, 129], [130, 131], [132, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-test-100", "ner": [[1, 5, "algorithm"], [13, 15, "algorithm"], [17, 17, "algorithm"], [20, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 5, 13, 15, "type-of", "example_of", false, false], [13, 15, 20, 21, "related-to", "", false, false], [17, 17, 13, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "soft", "margin", "support", "vector", "machine", "described", "above", "is", "an", "example", "of", "an", "empirical", "risk", "minimisation", "(", "ERM", ")", "for", "hinge", "loss", "."], "sentence-detokenized": "The soft margin support vector machine described above is an example of an empirical risk minimisation (ERM) for hinge loss.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 23], [24, 30], [31, 38], [39, 48], [49, 54], [55, 57], [58, 60], [61, 68], [69, 71], [72, 74], [75, 84], [85, 89], [90, 102], [103, 104], [104, 107], [107, 108], [109, 112], [113, 118], [119, 123], [123, 124]]}
{"doc_key": "ai-test-101", "ner": [[5, 5, "field"], [11, 11, "task"], [0, 2, "task"], [22, 22, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 5, "origin", "", false, false], [0, 2, 11, 11, "type-of", "", false, false], [22, 22, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Neural", "machine", "translation", ",", "a", "Deep", "Learning", "-", "based", "approach", "to", "MT", ",", "has", "made", "rapid", "progress", "in", "recent", "years", ",", "and", "Google", "has", "announced", "that", "its", "translation", "services", "will", "now", "use", "this", "technology", "instead", "of", "the", "statistical", "methods", "used", "in", "the", "past", "."], "sentence-detokenized": "Neural machine translation, a Deep Learning-based approach to MT, has made rapid progress in recent years, and Google has announced that its translation services will now use this technology instead of the statistical methods used in the past.", "token2charspan": [[0, 6], [7, 14], [15, 26], [26, 27], [28, 29], [30, 34], [35, 43], [43, 44], [44, 49], [50, 58], [59, 61], [62, 64], [64, 65], [66, 69], [70, 74], [75, 80], [81, 89], [90, 92], [93, 99], [100, 105], [105, 106], [107, 110], [111, 117], [118, 121], [122, 131], [132, 136], [137, 140], [141, 152], [153, 161], [162, 166], [167, 170], [171, 174], [175, 179], [180, 190], [191, 198], [199, 201], [202, 205], [206, 217], [218, 225], [226, 230], [231, 233], [234, 237], [238, 242], [242, 243]]}
{"doc_key": "ai-test-102", "ner": [[15, 15, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "usually", "leads", "to", "very", "large", "performance", "gains", "when", "working", "with", "large", "corpora", "such", "as", "WordNet", "."], "sentence-detokenized": "This usually leads to very large performance gains when working with large corpora such as WordNet.", "token2charspan": [[0, 4], [5, 12], [13, 18], [19, 21], [22, 26], [27, 32], [33, 44], [45, 50], [51, 55], [56, 63], [64, 68], [69, 74], [75, 82], [83, 87], [88, 90], [91, 98], [98, 99]]}
{"doc_key": "ai-test-103", "ner": [[0, 1, "task"], [5, 5, "field"], [17, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 17, 19, "part-of", "", false, false], [17, 19, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Facial", "recognition", "is", "used", "in", "biometrics", ",", "often", "as", "part", "of", "(", "or", "together", "with", ")", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Facial recognition is used in biometrics, often as part of (or together with) a facial recognition system.", "token2charspan": [[0, 6], [7, 18], [19, 21], [22, 26], [27, 29], [30, 40], [40, 41], [42, 47], [48, 50], [51, 55], [56, 58], [59, 60], [60, 62], [63, 71], [72, 76], [76, 77], [78, 79], [80, 86], [87, 98], [99, 105], [105, 106]]}
{"doc_key": "ai-test-104", "ner": [[2, 4, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["trained", "by", "maximum", "likelihood", "estimation", "."], "sentence-detokenized": "trained by maximum likelihood estimation.", "token2charspan": [[0, 7], [8, 10], [11, 18], [19, 29], [30, 40], [40, 41]]}
{"doc_key": "ai-test-105", "ner": [[3, 3, "country"], [5, 9, "organisation"], [13, 13, "location"], [15, 15, "country"], [17, 20, "organisation"], [22, 22, "country"], [28, 30, "organisation"], [33, 37, "organisation"], [39, 40, "country"], [50, 54, "organisation"], [55, 57, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[5, 9, 13, 13, "physical", "", false, false], [13, 13, 15, 15, "physical", "", false, false], [17, 20, 22, 22, "physical", "", false, false], [33, 37, 39, 40, "physical", "", false, false], [50, 54, 55, 57, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ltd", ".", "in", "Thailand", ";", "Komatsu", "(", "Shanghai", ")", "Ltd.", "in", "1996", "in", "Shanghai", ",", "China", ";", "Industrial", "Power", "Alliance", "Ltd.", "in", "Japan", ",", "a", "joint", "venture", "with", "Cummins", ",", "in", "1998", ";", "L", "&", "T-", "Komatsu", "Limited", "in", "India", "in", "1998", "(", "shares", "sold", "in", "2013", ")", ";", "and", "Komatsu", "Brasil", "International", "Ltda.", "in", "Brazil", "in", "1998", "."], "sentence-detokenized": "Ltd. in Thailand; Komatsu (Shanghai) Ltd. in 1996 in Shanghai, China; Industrial Power Alliance Ltd. in Japan, a joint venture with Cummins, in 1998; L & T-Komatsu Limited in India in 1998 (shares sold in 2013); and Komatsu Brasil International Ltda. in Brazil in 1998.", "token2charspan": [[0, 3], [3, 4], [5, 7], [8, 16], [16, 17], [18, 25], [26, 27], [27, 35], [35, 36], [37, 41], [42, 44], [45, 49], [50, 52], [53, 61], [61, 62], [63, 68], [68, 69], [70, 80], [81, 86], [87, 95], [96, 100], [101, 103], [104, 109], [109, 110], [111, 112], [113, 118], [119, 126], [127, 131], [132, 139], [139, 140], [141, 143], [144, 148], [148, 149], [150, 151], [152, 153], [154, 156], [156, 163], [164, 171], [172, 174], [175, 180], [181, 183], [184, 188], [189, 190], [190, 196], [197, 201], [202, 204], [205, 209], [209, 210], [210, 211], [212, 215], [216, 223], [224, 230], [231, 244], [245, 250], [251, 253], [254, 260], [261, 263], [264, 268], [268, 269]]}
{"doc_key": "ai-test-106", "ner": [[0, 0, "organisation"], [4, 6, "misc"], [11, 12, "person"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[11, 12, 0, 0, "physical", "", false, false], [11, 12, 4, 6, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["dgp", "also", "occasionally", "hosts", "artists", "in", "residencies", "(", "e.g.", "Oscar", "winner", "Chris", "Landreth", ")", "."], "sentence-detokenized": "dgp also occasionally hosts artists in residencies (e.g. Oscar winner Chris Landreth).", "token2charspan": [[0, 3], [4, 8], [9, 21], [22, 27], [28, 35], [36, 38], [39, 50], [51, 52], [52, 56], [57, 62], [63, 69], [70, 75], [76, 84], [84, 85], [85, 86]]}
{"doc_key": "ai-test-107", "ner": [[7, 9, "misc"], [12, 14, "misc"], [17, 20, "misc"], [24, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "currently", "comprises", "four", "sub-competitions", "-", "the", "RoboMaster", "Robotics", "Competition", ",", "the", "RoboMaster", "Technical", "Challenge", ",", "the", "ICRA", "RoboMaster", "AI", "Challenge", "and", "the", "new", "RoboMaster", "Youth", "Tournament", "."], "sentence-detokenized": "It currently comprises four sub-competitions - the RoboMaster Robotics Competition, the RoboMaster Technical Challenge, the ICRA RoboMaster AI Challenge and the new RoboMaster Youth Tournament.", "token2charspan": [[0, 2], [3, 12], [13, 22], [23, 27], [28, 44], [45, 46], [47, 50], [51, 61], [62, 70], [71, 82], [82, 83], [84, 87], [88, 98], [99, 108], [109, 118], [118, 119], [120, 123], [124, 128], [129, 139], [140, 142], [143, 152], [153, 156], [157, 160], [161, 164], [165, 175], [176, 181], [182, 192], [192, 193]]}
{"doc_key": "ai-test-108", "ner": [[15, 17, "algorithm"], [21, 22, "algorithm"], [12, 25, "field"]], "ner_mapping_to_source": [1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "early", "2000s", ",", "the", "dominant", "language", "processing", "strategy", "began", "to", "shift", "from", "the", "Hidden", "Markov", "Model", "to", "more", "modern", "neural", "networks", "and", "Deep", "Learning", "."], "sentence-detokenized": "In the early 2000s, the dominant language processing strategy began to shift from the Hidden Markov Model to more modern neural networks and Deep Learning.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 18], [18, 19], [20, 23], [24, 32], [33, 41], [42, 52], [53, 61], [62, 67], [68, 70], [71, 76], [77, 81], [82, 85], [86, 92], [93, 99], [100, 105], [106, 108], [109, 113], [114, 120], [121, 127], [128, 136], [137, 140], [141, 145], [146, 154], [154, 155]]}
{"doc_key": "ai-test-109", "ner": [[8, 10, "misc"], [14, 17, "metrics"], [20, 23, "metrics"], [30, 33, "metrics"], [36, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 17, 20, 23, "related-to", "equal", false, false], [30, 33, 36, 39, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "equivalent", "expression", "in", "the", "case", "of", "a", "binary", "target", "rate", "is", "that", "the", "true", "-", "positive", "rate", "and", "the", "false", "-", "positive", "rate", "are", "equal", "(", "and", "therefore", "the", "false", "-", "negative", "rate", "and", "the", "true", "-", "negative", "rate", "are", "equal", ")", "for", "each", "value", "of", "the", "sensitive", "characteristics", ":"], "sentence-detokenized": "Another equivalent expression in the case of a binary target rate is that the true-positive rate and the false-positive rate are equal (and therefore the false-negative rate and the true-negative rate are equal) for each value of the sensitive characteristics:", "token2charspan": [[0, 7], [8, 18], [19, 29], [30, 32], [33, 36], [37, 41], [42, 44], [45, 46], [47, 53], [54, 60], [61, 65], [66, 68], [69, 73], [74, 77], [78, 82], [82, 83], [83, 91], [92, 96], [97, 100], [101, 104], [105, 110], [110, 111], [111, 119], [120, 124], [125, 128], [129, 134], [135, 136], [136, 139], [140, 149], [150, 153], [154, 159], [159, 160], [160, 168], [169, 173], [174, 177], [178, 181], [182, 186], [186, 187], [187, 195], [196, 200], [201, 204], [205, 210], [210, 211], [212, 215], [216, 220], [221, 226], [227, 229], [230, 233], [234, 243], [244, 259], [259, 260]]}
{"doc_key": "ai-test-110", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "MATLAB", "function", ","], "sentence-detokenized": "The MATLAB function,", "token2charspan": [[0, 3], [4, 10], [11, 19], [19, 20]]}
{"doc_key": "ai-test-111", "ner": [[1, 2, "product"], [16, 17, "product"]], "ner_mapping_to_source": [0, 2], "relations": [[16, 17, 1, 2, "type-of", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["An", "articulated", "robot", "is", "a", "robot", "with", "swivel", "joints", "(", "e.g.", "a", "legged", "robot", "or", "an", "industrial", "robot", ")", "."], "sentence-detokenized": "An articulated robot is a robot with swivel joints (e.g. a legged robot or an industrial robot).", "token2charspan": [[0, 2], [3, 14], [15, 20], [21, 23], [24, 25], [26, 31], [32, 36], [37, 43], [44, 50], [51, 52], [52, 56], [57, 58], [59, 65], [66, 71], [72, 74], [75, 77], [78, 88], [89, 94], [94, 95], [95, 96]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [5, 6, "product"], [8, 9, "product"], [13, 13, "misc"], [21, 23, "product"], [28, 30, "misc"], [34, 34, "location"], [36, 36, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 13, 13, "general-affiliation", "nationality", false, false], [0, 0, 28, 30, "usage", "", false, false], [0, 0, 34, 34, "physical", "", false, false], [5, 6, 0, 0, "named", "", false, false], [8, 9, 0, 0, "named", "", false, false], [34, 34, 36, 36, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "also", "known", "as", "Pandora", "Media", "or", "Pandora", "Radio", ")", "is", "an", "American", "internet", "radio", "service", "for", "music", "streaming", "and", "automated", "recommendation", "systems", ",", "operated", "by", "the", "Music", "Genome", "Project", "and", "headquartered", "in", "Oakland", ",", "California", "."], "sentence-detokenized": "Pandora (also known as Pandora Media or Pandora Radio) is an American internet radio service for music streaming and automated recommendation systems, operated by the Music Genome Project and headquartered in Oakland, California.", "token2charspan": [[0, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 30], [31, 36], [37, 39], [40, 47], [48, 53], [53, 54], [55, 57], [58, 60], [61, 69], [70, 78], [79, 84], [85, 92], [93, 96], [97, 102], [103, 112], [113, 116], [117, 126], [127, 141], [142, 149], [149, 150], [151, 159], [160, 162], [163, 166], [167, 172], [173, 179], [180, 187], [188, 191], [192, 205], [206, 208], [209, 216], [216, 217], [218, 228], [228, 229]]}
{"doc_key": "ai-test-113", "ner": [[7, 10, "organisation"], [17, 20, "organisation"], [23, 24, "conference"], [38, 38, "conference"], [40, 40, "conference"], [42, 42, "conference"], [44, 44, "conference"], [46, 46, "conference"], [48, 48, "conference"], [50, 50, "conference"], [52, 52, "conference"], [54, 54, "conference"], [57, 57, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "board", "member", "of", "the", "International", "Machine", "Learning", "Society", ",", "was", "a", "member", "of", "the", "Executive", "Council", "of", "AAAI", ",", "co-chaired", "ICML", "2011", ",", "and", "has", "served", "as", "a", "senior", "PC", "member", "for", "conferences", "such", "as", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "UAI", ",", "VLDB", ",", "WSDM", ",", "and", "WWW", "."], "sentence-detokenized": "She is a board member of the International Machine Learning Society, was a member of the Executive Council of AAAI, co-chaired ICML 2011, and has served as a senior PC member for conferences such as AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM, and WWW.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 14], [15, 21], [22, 24], [25, 28], [29, 42], [43, 50], [51, 59], [60, 67], [67, 68], [69, 72], [73, 74], [75, 81], [82, 84], [85, 88], [89, 98], [99, 106], [107, 109], [110, 114], [114, 115], [116, 126], [127, 131], [132, 136], [136, 137], [138, 141], [142, 145], [146, 152], [153, 155], [156, 157], [158, 164], [165, 167], [168, 174], [175, 178], [179, 190], [191, 195], [196, 198], [199, 203], [203, 204], [205, 209], [209, 210], [211, 216], [216, 217], [218, 222], [222, 223], [224, 227], [227, 228], [229, 235], [235, 236], [237, 240], [240, 241], [242, 246], [246, 247], [248, 252], [252, 253], [254, 257], [258, 261], [261, 262]]}
{"doc_key": "ai-test-114", "ner": [[0, 3, "researcher"], [5, 10, "organisation"], [12, 12, "organisation"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 5, 10, "role", "", false, false], [12, 12, 5, 10, "named", "", false, false], [16, 16, 0, 3, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", "of", "the", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", "developed", "the", "Robocrane", ",", "in", "which", "the", "platform", "hangs", "from", "six", "cables", "instead", "of", "being", "supported", "by", "six", "jacks", "."], "sentence-detokenized": "James S. Albus of the National Institute of Standards and Technology (NIST) developed the Robocrane, in which the platform hangs from six cables instead of being supported by six jacks.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 17], [18, 21], [22, 30], [31, 40], [41, 43], [44, 53], [54, 57], [58, 68], [69, 70], [70, 74], [74, 75], [76, 85], [86, 89], [90, 99], [99, 100], [101, 103], [104, 109], [110, 113], [114, 122], [123, 128], [129, 133], [134, 137], [138, 144], [145, 152], [153, 155], [156, 161], [162, 171], [172, 174], [175, 178], [179, 184], [184, 185]]}
{"doc_key": "ai-test-115", "ner": [[3, 4, "algorithm"], [9, 10, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 3, 4, "type-of", "", false, false], [13, 14, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "class", "of", "direct", "search", "algorithms", "are", "the", "various", "evolutionary", "algorithms", ",", "e.g.", "genetic", "algorithms", "."], "sentence-detokenized": "Another class of direct search algorithms are the various evolutionary algorithms, e.g. genetic algorithms.", "token2charspan": [[0, 7], [8, 13], [14, 16], [17, 23], [24, 30], [31, 41], [42, 45], [46, 49], [50, 57], [58, 70], [71, 81], [81, 82], [83, 87], [88, 95], [96, 106], [106, 107]]}
{"doc_key": "ai-test-116", "ner": [[0, 0, "organisation"], [3, 4, "misc"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 0, 0, "named", "", false, false], [6, 7, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["KUKA", "is", "a", "German", "manufacturer", "of", "industrial", "robots", "and", "factory", "automation", "solutions", "."], "sentence-detokenized": "KUKA is a German manufacturer of industrial robots and factory automation solutions.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 16], [17, 29], [30, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 73], [74, 83], [83, 84]]}
{"doc_key": "ai-test-117", "ner": [[19, 20, "person"], [11, 17, "misc"], [24, 25, "person"], [22, 22, "misc"], [30, 31, "person"], [27, 28, "misc"], [37, 38, "person"], [33, 35, "misc"], [45, 47, "person"], [40, 44, "misc"], [52, 53, "person"], [49, 55, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[11, 17, 19, 20, "artifact", "", false, false], [22, 22, 24, 25, "artifact", "", false, false], [27, 28, 30, 31, "artifact", "", false, false], [33, 35, 37, 38, "artifact", "", false, false], [40, 44, 45, 47, "artifact", "", false, false], [49, 55, 52, 53, "artifact", "", false, false]], "relations_mapping_to_source": [1, 3, 5, 7, 9, 11], "sentence": ["Other", "films", "shot", "with", "IMAX", "cameras", "between", "2016", "and", "2020", "include", "Batman", "v", "Superman", ":", "Dawn", "of", "Justice", "by", "Zack", "Snyder", ",", "Sully", "by", "Clint", "Eastwood", ",", "First", "Man", "by", "Damien", "Chazelle", ",", "Wonder", "Woman", "1984", "by", "Patty", "Jenkins", ",", "No", "Time", "to", "Die", "by", "Cary", "Joji", "Fukunaga", "and", "Top", "Gun", "by", "Joseph", "Kosinski", ":", "Maverick", "."], "sentence-detokenized": "Other films shot with IMAX cameras between 2016 and 2020 include Batman v Superman: Dawn of Justice by Zack Snyder, Sully by Clint Eastwood, First Man by Damien Chazelle, Wonder Woman 1984 by Patty Jenkins, No Time to Die by Cary Joji Fukunaga and Top Gun by Joseph Kosinski: Maverick.", "token2charspan": [[0, 5], [6, 11], [12, 16], [17, 21], [22, 26], [27, 34], [35, 42], [43, 47], [48, 51], [52, 56], [57, 64], [65, 71], [72, 73], [74, 82], [82, 83], [84, 88], [89, 91], [92, 99], [100, 102], [103, 107], [108, 114], [114, 115], [116, 121], [122, 124], [125, 130], [131, 139], [139, 140], [141, 146], [147, 150], [151, 153], [154, 160], [161, 169], [169, 170], [171, 177], [178, 183], [184, 188], [189, 191], [192, 197], [198, 205], [205, 206], [207, 209], [210, 214], [215, 217], [218, 221], [222, 224], [225, 229], [230, 234], [235, 243], [244, 247], [248, 251], [252, 255], [256, 258], [259, 265], [266, 274], [274, 275], [276, 284], [284, 285]]}
{"doc_key": "ai-test-118", "ner": [[7, 7, "misc"], [12, 14, "organisation"], [16, 18, "organisation"], [34, 35, "country"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[12, 14, 7, 7, "usage", "", false, false], [12, 14, 34, 35, "physical", "", false, false], [16, 18, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["The", "test", "version", "of", "the", "MICR", "font", "E13B", "was", "submitted", "to", "the", "American", "Bankers", "Association", "(", "ABA", ")", "in", "July", "1956", ",", "which", "adopted", "it", "as", "the", "MICR", "standard", "for", "negotiable", "documents", "in", "the", "United", "States", "in", "1958", "."], "sentence-detokenized": "The test version of the MICR font E13B was submitted to the American Bankers Association (ABA) in July 1956, which adopted it as the MICR standard for negotiable documents in the United States in 1958.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 19], [20, 23], [24, 28], [29, 33], [34, 38], [39, 42], [43, 52], [53, 55], [56, 59], [60, 68], [69, 76], [77, 88], [89, 90], [90, 93], [93, 94], [95, 97], [98, 102], [103, 107], [107, 108], [109, 114], [115, 122], [123, 125], [126, 128], [129, 132], [133, 137], [138, 146], [147, 150], [151, 161], [162, 171], [172, 174], [175, 178], [179, 185], [186, 192], [193, 195], [196, 200], [200, 201]]}
{"doc_key": "ai-test-119", "ner": [[0, 2, "misc"], [15, 15, "field"], [19, 20, "field"], [23, 23, "field"], [25, 26, "field"], [28, 28, "field"], [30, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 15, 0, 2, "usage", "", false, false], [19, 20, 15, 15, "part-of", "", false, false], [23, 23, 0, 2, "usage", "", false, false], [25, 26, 0, 2, "usage", "", false, false], [28, 28, 0, 2, "usage", "", false, false], [30, 30, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Local", "search", "algorithms", "are", "widely", "applied", "to", "many", "difficult", "computational", "problems", ",", "including", "problems", "in", "computer", "science", "(", "especially", "artificial", "intelligence", ")", ",", "mathematics", ",", "operations", "research", ",", "engineering", "and", "bioinformatics", "."], "sentence-detokenized": "Local search algorithms are widely applied to many difficult computational problems, including problems in computer science (especially artificial intelligence), mathematics, operations research, engineering and bioinformatics.", "token2charspan": [[0, 5], [6, 12], [13, 23], [24, 27], [28, 34], [35, 42], [43, 45], [46, 50], [51, 60], [61, 74], [75, 83], [83, 84], [85, 94], [95, 103], [104, 106], [107, 115], [116, 123], [124, 125], [125, 135], [136, 146], [147, 159], [159, 160], [160, 161], [162, 173], [173, 174], [175, 185], [186, 194], [194, 195], [196, 207], [208, 211], [212, 226], [226, 227]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [8, 8, "location"], [10, 10, "country"], [14, 14, "country"], [22, 23, "algorithm"], [25, 25, "algorithm"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 8, 8, "physical", "", false, false], [0, 1, 14, 14, "general-affiliation", "nationality", false, false], [0, 1, 22, 23, "general-affiliation", "topic_of_study", false, false], [0, 1, 25, 25, "general-affiliation", "topic_of_study", false, false], [8, 8, 10, 10, "physical", "", false, false], [25, 25, 27, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "born", "3", "September", "1947", "in", "Wallersdorf", ",", "Germany", ")", "is", "a", "German", "psychologist", "who", "has", "studied", "the", "use", "of", "bounded", "rationality", "and", "heuristics", "in", "decision", "-", "making", "."], "sentence-detokenized": "Gerd Gigerenzer (born 3 September 1947 in Wallersdorf, Germany) is a German psychologist who has studied the use of bounded rationality and heuristics in decision-making.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 21], [22, 23], [24, 33], [34, 38], [39, 41], [42, 53], [53, 54], [55, 62], [62, 63], [64, 66], [67, 68], [69, 75], [76, 88], [89, 92], [93, 96], [97, 104], [105, 108], [109, 112], [113, 115], [116, 123], [124, 135], [136, 139], [140, 150], [151, 153], [154, 162], [162, 163], [163, 169], [169, 170]]}
{"doc_key": "ai-test-121", "ner": [[3, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["to", "minimise", "the", "mean", "square", "error", "."], "sentence-detokenized": "to minimise the mean square error.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 20], [21, 27], [28, 33], [33, 34]]}
{"doc_key": "ai-test-122", "ner": [[13, 14, "misc"], [17, 18, "organisation"], [32, 34, "field"], [50, 51, "misc"], [60, 62, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 14, 17, 18, "origin", "", false, false], [50, 51, 60, 62, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "even", "an", "official", "language", "with", "a", "regulating", "academy", ",", "such", "as", "standard", "French", "with", "the", "Acad\u00e9mie", "fran\u00e7aise", ",", "is", "classified", "as", "a", "natural", "language", "(", "e.g.", "in", "the", "field", "of", "natural", "language", "processing", ")", "because", "its", "prescriptive", "points", "make", "it", "neither", "constructed", "enough", "to", "be", "classified", "as", "a", "constructed", "language", "nor", "controlled", "enough", "to", "be", "classified", "as", "a", "controlled", "natural", "language", "."], "sentence-detokenized": "However, even an official language with a regulating academy, such as standard French with the Acad\u00e9mie fran\u00e7aise, is classified as a natural language (e.g. in the field of natural language processing) because its prescriptive points make it neither constructed enough to be classified as a constructed language nor controlled enough to be classified as a controlled natural language.", "token2charspan": [[0, 7], [7, 8], [9, 13], [14, 16], [17, 25], [26, 34], [35, 39], [40, 41], [42, 52], [53, 60], [60, 61], [62, 66], [67, 69], [70, 78], [79, 85], [86, 90], [91, 94], [95, 103], [104, 113], [113, 114], [115, 117], [118, 128], [129, 131], [132, 133], [134, 141], [142, 150], [151, 152], [152, 156], [157, 159], [160, 163], [164, 169], [170, 172], [173, 180], [181, 189], [190, 200], [200, 201], [202, 209], [210, 213], [214, 226], [227, 233], [234, 238], [239, 241], [242, 249], [250, 261], [262, 268], [269, 271], [272, 274], [275, 285], [286, 288], [289, 290], [291, 302], [303, 311], [312, 315], [316, 326], [327, 333], [334, 336], [337, 339], [340, 350], [351, 353], [354, 355], [356, 366], [367, 374], [375, 383], [383, 384]]}
{"doc_key": "ai-test-123", "ner": [[11, 11, "metrics"], [13, 14, "metrics"], [16, 16, "metrics"], [35, 36, "metrics"], [38, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 16, 13, 14, "named", "", false, false], [38, 38, 35, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "a", "number", "of", "other", "metrics", ",", "the", "simplest", "being", "accuracy", "or", "Fraction", "Correct", "(", "FC", ")", ",", "which", "measures", "the", "proportion", "of", "all", "instances", "that", "have", "been", "correctly", "categorised", ";", "the", "complement", "is", "Fraction", "Incorrect", "(", "FiC", ")", "."], "sentence-detokenized": "There are a number of other metrics, the simplest being accuracy or Fraction Correct (FC), which measures the proportion of all instances that have been correctly categorised; the complement is Fraction Incorrect (FiC).", "token2charspan": [[0, 5], [6, 9], [10, 11], [12, 18], [19, 21], [22, 27], [28, 35], [35, 36], [37, 40], [41, 49], [50, 55], [56, 64], [65, 67], [68, 76], [77, 84], [85, 86], [86, 88], [88, 89], [89, 90], [91, 96], [97, 105], [106, 109], [110, 120], [121, 123], [124, 127], [128, 137], [138, 142], [143, 147], [148, 152], [153, 162], [163, 174], [174, 175], [176, 179], [180, 190], [191, 193], [194, 202], [203, 212], [213, 214], [214, 217], [217, 218], [218, 219]]}
{"doc_key": "ai-test-124", "ner": [[0, 0, "researcher"], [7, 10, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 7, 10, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cardie", "was", "made", "a", "Fellow", "of", "the", "Association", "for", "Computational", "Linguistics", "in", "2016", "."], "sentence-detokenized": "Cardie was made a Fellow of the Association for Computational Linguistics in 2016.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 17], [18, 24], [25, 27], [28, 31], [32, 43], [44, 47], [48, 61], [62, 73], [74, 76], [77, 81], [81, 82]]}
{"doc_key": "ai-test-125", "ner": [[12, 14, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Learning", "the", "parameters", "math", "\\", "theta", "/", "math", "is", "usually", "done", "by", "maximum", "likelihood", "learning", "for", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i", ";\\", "theta", ")", "/", "math", "."], "sentence-detokenized": "Learning the parameters math\\ theta / math is usually done by maximum likelihood learning for mathp (Y _ i | X _ i;\\ theta) / math.", "token2charspan": [[0, 8], [9, 12], [13, 23], [24, 28], [28, 29], [30, 35], [36, 37], [38, 42], [43, 45], [46, 53], [54, 58], [59, 61], [62, 69], [70, 80], [81, 89], [90, 93], [94, 99], [100, 101], [101, 102], [103, 104], [105, 106], [107, 108], [109, 110], [111, 112], [113, 114], [114, 116], [117, 122], [122, 123], [124, 125], [126, 130], [130, 131]]}
{"doc_key": "ai-test-126", "ner": [[0, 1, "task"], [3, 5, "algorithm"], [7, 8, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 0, 1, "usage", "", true, false], [7, 8, 3, 5, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cluster", "analysis", "and", "non-negative", "matrix", "factorisation", "for", "descriptive", "mining", "."], "sentence-detokenized": "Cluster analysis and non-negative matrix factorisation for descriptive mining.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 33], [34, 40], [41, 54], [55, 58], [59, 70], [71, 77], [77, 78]]}
{"doc_key": "ai-test-127", "ner": [[1, 2, "field"], [5, 6, "field"], [17, 19, "field"], [21, 24, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[17, 19, 1, 2, "part-of", "", false, false], [17, 19, 5, 6, "part-of", "", false, false], [21, 24, 1, 2, "part-of", "", false, false], [21, 24, 5, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", "and", "the", "information", "technology", "that", "makes", "it", "possible", ",", "the", "ability", "of", "computers", "to", "process", "natural", "language", "and", "do", "machine", "learning", "is", "a", "long", "-", "term", "challenge", "."], "sentence-detokenized": "In computer science and the information technology that makes it possible, the ability of computers to process natural language and do machine learning is a long-term challenge.", "token2charspan": [[0, 2], [3, 11], [12, 19], [20, 23], [24, 27], [28, 39], [40, 50], [51, 55], [56, 61], [62, 64], [65, 73], [73, 74], [75, 78], [79, 86], [87, 89], [90, 99], [100, 102], [103, 110], [111, 118], [119, 127], [128, 131], [132, 134], [135, 142], [143, 151], [152, 154], [155, 156], [157, 161], [161, 162], [162, 166], [167, 176], [176, 177]]}
{"doc_key": "ai-test-128", "ner": [[4, 6, "algorithm"], [10, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 10, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "The", "code", "for", "extracting", "Gabor", "features", "from", "images", "in", "MATLAB", "can", "be", "found", "in"], "sentence-detokenized": "(The code for extracting Gabor features from images in MATLAB can be found in", "token2charspan": [[0, 1], [1, 4], [5, 9], [10, 13], [14, 24], [25, 30], [31, 39], [40, 44], [45, 51], [52, 54], [55, 61], [62, 65], [66, 68], [69, 74], [75, 77]]}
{"doc_key": "ai-test-129", "ner": [[1, 1, "misc"], [18, 19, "algorithm"], [21, 21, "task"], [23, 23, "task"], [25, 26, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 1, 18, 19, "general-affiliation", "", false, false], [1, 1, 21, 21, "related-to", "solves_problem_of_type", false, false], [1, 1, 23, 23, "related-to", "solves_problem_of_type", false, false], [1, 1, 25, 26, "related-to", "solves_problem_of_type", false, false], [1, 1, 28, 29, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "NeuralExpert", "focuses", "the", "design", "specifications", "on", "the", "type", "of", "problem", "the", "user", "wants", "to", "solve", "with", "the", "neural", "network", "(", "classification", ",", "prediction", ",", "function", "approximation", "or", "cluster", "analysis", ")", "."], "sentence-detokenized": "The NeuralExpert focuses the design specifications on the type of problem the user wants to solve with the neural network (classification, prediction, function approximation or cluster analysis).", "token2charspan": [[0, 3], [4, 16], [17, 24], [25, 28], [29, 35], [36, 50], [51, 53], [54, 57], [58, 62], [63, 65], [66, 73], [74, 77], [78, 82], [83, 88], [89, 91], [92, 97], [98, 102], [103, 106], [107, 113], [114, 121], [122, 123], [123, 137], [137, 138], [139, 149], [149, 150], [151, 159], [160, 173], [174, 176], [177, 184], [185, 193], [193, 194], [194, 195]]}
{"doc_key": "ai-test-130", "ner": [[2, 4, "misc"], [30, 32, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "quantisation", "step", "size", "(", "\u0394", ")", "is", "small", "in", "relation", "to", "the", "variation", "of", "the", "signal", "to", "be", "quantised", ",", "it", "is", "relatively", "easy", "to", "show", "that", "the", "mean", "square", "error", "resulting", "from", "such", "a", "rounding", "operation", "is", "approximately", "math", "\\", "Delta", "^", "2", "/", "12", "/", "math.math"], "sentence-detokenized": "If the quantisation step size (\u0394) is small in relation to the variation of the signal to be quantised, it is relatively easy to show that the mean square error resulting from such a rounding operation is approximately math\\ Delta ^ 2 / 12 / math.math", "token2charspan": [[0, 2], [3, 6], [7, 19], [20, 24], [25, 29], [30, 31], [31, 32], [32, 33], [34, 36], [37, 42], [43, 45], [46, 54], [55, 57], [58, 61], [62, 71], [72, 74], [75, 78], [79, 85], [86, 88], [89, 91], [92, 101], [101, 102], [103, 105], [106, 108], [109, 119], [120, 124], [125, 127], [128, 132], [133, 137], [138, 141], [142, 146], [147, 153], [154, 159], [160, 169], [170, 174], [175, 179], [180, 181], [182, 190], [191, 200], [201, 203], [204, 217], [218, 222], [222, 223], [224, 229], [230, 231], [232, 233], [234, 235], [236, 238], [239, 240], [241, 250]]}
{"doc_key": "ai-test-131", "ner": [[26, 29, "researcher"], [31, 32, "researcher"], [34, 36, "researcher"], [38, 39, "researcher"], [41, 43, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "construction", "of", "a", "comprehensive", "lexicon", "with", "a", "suitable", "ontology", "requires", "considerable", "effort", ",", "e.g.", "the", "Wordnet", "lexicon", "required", "many", "person", "-", "years", "of", "work", ".", "G.", "A", ".", "Miller", ",", "R.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Gross", ",", "K", ".", "Miller", "."], "sentence-detokenized": "The construction of a comprehensive lexicon with a suitable ontology requires considerable effort, e.g. the Wordnet lexicon required many person-years of work. G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 3], [4, 16], [17, 19], [20, 21], [22, 35], [36, 43], [44, 48], [49, 50], [51, 59], [60, 68], [69, 77], [78, 90], [91, 97], [97, 98], [99, 103], [104, 107], [108, 115], [116, 123], [124, 132], [133, 137], [138, 144], [144, 145], [145, 150], [151, 153], [154, 158], [158, 159], [160, 162], [163, 164], [164, 165], [166, 172], [172, 173], [174, 176], [177, 185], [185, 186], [187, 189], [190, 192], [193, 201], [201, 202], [203, 205], [206, 211], [211, 212], [213, 214], [214, 215], [216, 222], [222, 223]]}
{"doc_key": "ai-test-132", "ner": [[0, 0, "organisation"], [22, 23, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[22, 23, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Kawasaki", "'s", "portfolio", "also", "includes", "retractable", "roofs", ",", "floors", "and", "other", "giant", "structures", ",", "such", "as", "the", "retractable", "surface", "of", "the", "\"", "Sapporo", "Dome", "\"", "."], "sentence-detokenized": "Kawasaki's portfolio also includes retractable roofs, floors and other giant structures, such as the retractable surface of the \"Sapporo Dome\".", "token2charspan": [[0, 8], [8, 10], [11, 20], [21, 25], [26, 34], [35, 46], [47, 52], [52, 53], [54, 60], [61, 64], [65, 70], [71, 76], [77, 87], [87, 88], [89, 93], [94, 96], [97, 100], [101, 112], [113, 120], [121, 123], [124, 127], [128, 129], [129, 136], [137, 141], [141, 142], [142, 143]]}
{"doc_key": "ai-test-133", "ner": [[0, 1, "metrics"], [4, 6, "metrics"], [8, 10, "metrics"], [15, 16, "metrics"], [37, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 15, 16, "related-to", "", false, false], [0, 1, 37, 38, "opposite", "alternative_to", false, false], [4, 6, 0, 1, "type-of", "", false, false], [8, 10, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kappa", "statistics", "such", "as", "Fleiss", "'", "kappa", "and", "Cohen", "'s", "kappa", "are", "methods", "for", "calculating", "inter-rater", "reliability", "based", "on", "different", "assumptions", "about", "the", "marginal", "or", "prior", "distributions", "and", "are", "increasingly", "used", "as", "chance", "-", "adjusted", "alternatives", "to", "accuracy", "in", "other", "contexts", "."], "sentence-detokenized": "Kappa statistics such as Fleiss' kappa and Cohen's kappa are methods for calculating inter-rater reliability based on different assumptions about the marginal or prior distributions and are increasingly used as chance-adjusted alternatives to accuracy in other contexts.", "token2charspan": [[0, 5], [6, 16], [17, 21], [22, 24], [25, 31], [31, 32], [33, 38], [39, 42], [43, 48], [48, 50], [51, 56], [57, 60], [61, 68], [69, 72], [73, 84], [85, 96], [97, 108], [109, 114], [115, 117], [118, 127], [128, 139], [140, 145], [146, 149], [150, 158], [159, 161], [162, 167], [168, 181], [182, 185], [186, 189], [190, 202], [203, 207], [208, 210], [211, 217], [217, 218], [218, 226], [227, 239], [240, 242], [243, 251], [252, 254], [255, 260], [261, 269], [269, 270]]}
{"doc_key": "ai-test-134", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [18, 18, "researcher"], [25, 27, "algorithm"], [35, 37, "algorithm"], [33, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 18, 18, "role", "student_of", false, false], [7, 8, 18, 18, "role", "student_of", false, false], [10, 11, 18, 18, "role", "student_of", false, false], [13, 14, 18, 18, "role", "student_of", false, false], [35, 37, 4, 5, "origin", "", false, false], [35, 37, 7, 8, "origin", "", false, false], [35, 37, 10, 11, "origin", "", false, false], [35, 37, 13, 14, "origin", "", false, false], [35, 37, 18, 18, "origin", "", false, false], [35, 37, 25, 27, "type-of", "", false, false], [33, 33, 35, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Together", "with", "his", "students", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Graves", "and", "others", ",", "Schmidhuber", "published", "increasingly", "sophisticated", "versions", "of", "a", "recurrent", "neural", "network", ",", "the", "so", "-", "called", "LSTM", "(", "Long", "Short", "Memory", ")", "."], "sentence-detokenized": "Together with his students Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Graves and others, Schmidhuber published increasingly sophisticated versions of a recurrent neural network, the so-called LSTM (Long Short Memory).", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 26], [27, 31], [32, 42], [42, 43], [44, 49], [50, 54], [54, 55], [56, 60], [61, 68], [68, 69], [70, 74], [75, 81], [82, 85], [86, 92], [92, 93], [94, 105], [106, 115], [116, 128], [129, 142], [143, 151], [152, 154], [155, 156], [157, 166], [167, 173], [174, 181], [181, 182], [183, 186], [187, 189], [189, 190], [190, 196], [197, 201], [202, 203], [203, 207], [208, 213], [214, 220], [220, 221], [221, 222]]}
{"doc_key": "ai-test-135", "ner": [[4, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "The", "first", "Cobot", "KUKA", "LBR", "3", "is", "launched", "."], "sentence-detokenized": "2004 - The first Cobot KUKA LBR 3 is launched.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 16], [17, 22], [23, 27], [28, 31], [32, 33], [34, 36], [37, 45], [45, 46]]}
{"doc_key": "ai-test-136", "ner": [[10, 12, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Two", "superficial", "approaches", "used", "for", "training", "and", "subsequent", "disambiguation", "are", "Naive", "Bayes", "classifiers", "and", "decision", "trees", "."], "sentence-detokenized": "Two superficial approaches used for training and subsequent disambiguation are Naive Bayes classifiers and decision trees.", "token2charspan": [[0, 3], [4, 15], [16, 26], [27, 31], [32, 35], [36, 44], [45, 48], [49, 59], [60, 74], [75, 78], [79, 84], [85, 90], [91, 102], [103, 106], [107, 115], [116, 121], [121, 122]]}
{"doc_key": "ai-test-137", "ner": [[12, 13, "person"], [15, 17, "person"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "first", "practical", "forms", "of", "photography", "were", "introduced", "in", "January", "1839", "by", "Louis", "Daguerre", "and", "Henry", "Fox", "Talbot", "."], "sentence-detokenized": "The first practical forms of photography were introduced in January 1839 by Louis Daguerre and Henry Fox Talbot.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 25], [26, 28], [29, 40], [41, 45], [46, 56], [57, 59], [60, 67], [68, 72], [73, 75], [76, 81], [82, 90], [91, 94], [95, 100], [101, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-138", "ner": [[3, 5, "task"], [7, 8, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "speech", "synthesis", "combined", "with", "speech", "recognition", "enables", "interaction", "with", "mobile", "devices", "via", "speech", "processing", "interfaces", "."], "sentence-detokenized": "For example, speech synthesis combined with speech recognition enables interaction with mobile devices via speech processing interfaces.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 19], [20, 29], [30, 38], [39, 43], [44, 50], [51, 62], [63, 70], [71, 82], [83, 87], [88, 94], [95, 102], [103, 106], [107, 113], [114, 124], [125, 135], [135, 136]]}
{"doc_key": "ai-test-139", "ner": [[0, 0, "product"], [15, 15, "programlang"], [17, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 15, 15, "general-affiliation", "", false, false], [0, 0, 17, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Phidgets", "can", "be", "programmed", "with", "a", "variety", "of", "software", "and", "programming", "languages", ",", "ranging", "from", "Java", "to", "Microsoft", "Excel", "."], "sentence-detokenized": "Phidgets can be programmed with a variety of software and programming languages, ranging from Java to Microsoft Excel.", "token2charspan": [[0, 8], [9, 12], [13, 15], [16, 26], [27, 31], [32, 33], [34, 41], [42, 44], [45, 53], [54, 57], [58, 69], [70, 79], [79, 80], [81, 88], [89, 93], [94, 98], [99, 101], [102, 111], [112, 117], [117, 118]]}
{"doc_key": "ai-test-140", "ner": [[2, 3, "field"], [9, 10, "researcher"], [13, 15, "misc"], [22, 23, "field"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 10, "origin", "", false, false], [9, 10, 22, 23, "general-affiliation", "topic_of_study", false, false], [9, 10, 25, 26, "general-affiliation", "topic_of_study", false, false], [13, 15, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "machine", "learning", "was", "coined", "in", "1959", "by", "Arthur", "Samuel", ",", "an", "American", "IBM", "employee", "and", "pioneer", "in", "the", "field", "of", "computer", "games", "and", "artificial", "intelligence", "."], "sentence-detokenized": "The term machine learning was coined in 1959 by Arthur Samuel, an American IBM employee and pioneer in the field of computer games and artificial intelligence.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 25], [26, 29], [30, 36], [37, 39], [40, 44], [45, 47], [48, 54], [55, 61], [61, 62], [63, 65], [66, 74], [75, 78], [79, 87], [88, 91], [92, 99], [100, 102], [103, 106], [107, 112], [113, 115], [116, 124], [125, 130], [131, 134], [135, 145], [146, 158], [158, 159]]}
{"doc_key": "ai-test-141", "ner": [[1, 2, "misc"], [3, 4, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 1, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Israeli", "poet", "David", "Avidan", ",", "fascinated", "by", "future", "technologies", "and", "their", "relationship", "to", "art", ",", "wanted", "to", "explore", "the", "use", "of", "computers", "to", "write", "literature", "."], "sentence-detokenized": "The Israeli poet David Avidan, fascinated by future technologies and their relationship to art, wanted to explore the use of computers to write literature.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 22], [23, 29], [29, 30], [31, 41], [42, 44], [45, 51], [52, 64], [65, 68], [69, 74], [75, 87], [88, 90], [91, 94], [94, 95], [96, 102], [103, 105], [106, 113], [114, 117], [118, 121], [122, 124], [125, 134], [135, 137], [138, 143], [144, 154], [154, 155]]}
{"doc_key": "ai-test-142", "ner": [[0, 5, "misc"], [7, 7, "organisation"], [14, 14, "location"], [27, 28, "location"], [29, 32, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 7, 0, 5, "part-of", "", false, false], [29, 32, 27, 28, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "part", "of", "the", "GATEway", "project", ",", "Oxbotica", "tested", "seven", "autonomous", "shuttle", "buses", "in", "Greenwich", "in", "2017", ",", "driving", "along", "a", "two", "-", "mile", "riverside", "path", "near", "London", "'s", "O2", "Arena", "that", "is", "also", "used", "by", "pedestrians", "and", "cyclists", "."], "sentence-detokenized": "As part of the GATEway project, Oxbotica tested seven autonomous shuttle buses in Greenwich in 2017, driving along a two-mile riverside path near London's O2 Arena that is also used by pedestrians and cyclists.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 22], [23, 30], [30, 31], [32, 40], [41, 47], [48, 53], [54, 64], [65, 72], [73, 78], [79, 81], [82, 91], [92, 94], [95, 99], [99, 100], [101, 108], [109, 114], [115, 116], [117, 120], [120, 121], [121, 125], [126, 135], [136, 140], [141, 145], [146, 152], [152, 154], [155, 157], [158, 163], [164, 168], [169, 171], [172, 176], [177, 181], [182, 184], [185, 196], [197, 200], [201, 209], [209, 210]]}
{"doc_key": "ai-test-143", "ner": [[10, 11, "task"], [14, 16, "metrics"], [23, 24, "misc"], [26, 26, "metrics"], [28, 28, "metrics"], [31, 31, "metrics"], [33, 33, "metrics"], [35, 37, "metrics"], [40, 40, "metrics"], [42, 42, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[14, 16, 23, 24, "related-to", "is_a", false, false], [14, 16, 26, 26, "usage", "", false, false], [14, 16, 28, 28, "usage", "", false, false], [26, 26, 31, 31, "named", "same", false, false], [28, 28, 42, 42, "named", "same", false, false], [31, 31, 40, 40, "opposite", "", false, false], [31, 31, 42, 42, "opposite", "", false, false], [33, 33, 31, 31, "named", "", false, false], [35, 37, 31, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["An", "unrelated", "but", "commonly", "used", "combination", "of", "basic", "statistics", "from", "information", "retrieval", "is", "the", "F", "-", "score", ",", "a", "(", "possibly", "weighted", ")", "harmonic", "mean", "of", "recall", "and", "precision", ",", "where", "recall", "=", "sensitivity", "=", "TRUE", "positive", "rate", ",", "but", "specificity", "and", "precision", "are", "completely", "different", "measures", "."], "sentence-detokenized": "An unrelated but commonly used combination of basic statistics from information retrieval is the F-score, a (possibly weighted) harmonic mean of recall and precision, where recall = sensitivity = TRUE positive rate, but specificity and precision are completely different measures.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 25], [26, 30], [31, 42], [43, 45], [46, 51], [52, 62], [63, 67], [68, 79], [80, 89], [90, 92], [93, 96], [97, 98], [98, 99], [99, 104], [104, 105], [106, 107], [108, 109], [109, 117], [118, 126], [126, 127], [128, 136], [137, 141], [142, 144], [145, 151], [152, 155], [156, 165], [165, 166], [167, 172], [173, 179], [180, 181], [182, 193], [194, 195], [196, 200], [201, 209], [210, 214], [214, 215], [216, 219], [220, 231], [232, 235], [236, 245], [246, 249], [250, 260], [261, 270], [271, 279], [279, 280]]}
{"doc_key": "ai-test-144", "ner": [[0, 1, "field"], [10, 10, "field"], [12, 12, "field"], [14, 14, "field"], [16, 17, "field"], [19, 21, "field"], [28, 28, "product"], [29, 34, "product"], [36, 37, "product"], [39, 40, "product"], [48, 54, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 10, "origin", "takes_inspiration_from", false, false], [0, 1, 12, 12, "origin", "takes_inspiration_from", false, false], [0, 1, 14, 14, "origin", "takes_inspiration_from", false, false], [0, 1, 16, 17, "origin", "takes_inspiration_from", false, false], [0, 1, 19, 21, "origin", "takes_inspiration_from", false, false], [28, 28, 0, 1, "origin", "", false, false], [29, 34, 0, 1, "origin", "", false, false], [36, 37, 0, 1, "origin", "", false, false], [39, 40, 0, 1, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Neuromorphic", "engineering", "is", "an", "interdisciplinary", "field", "that", "draws", "inspiration", "from", "biology", ",", "physics", ",", "mathematics", ",", "computer", "science", "and", "electrical", "engineering", "to", "develop", "artificial", "neural", "systems", "such", "as", "vision", "systems", ",", "head", "-", "eye", "systems", ",", "hearing", "processors", "and", "autonomous", "robots", "whose", "physical", "architecture", "and", "design", "principles", "are", "based", "on", "those", "of", "biological", "nervous", "systems", "."], "sentence-detokenized": "Neuromorphic engineering is an interdisciplinary field that draws inspiration from biology, physics, mathematics, computer science and electrical engineering to develop artificial neural systems such as vision systems, head-eye systems, hearing processors and autonomous robots whose physical architecture and design principles are based on those of biological nervous systems.", "token2charspan": [[0, 12], [13, 24], [25, 27], [28, 30], [31, 48], [49, 54], [55, 59], [60, 65], [66, 77], [78, 82], [83, 90], [90, 91], [92, 99], [99, 100], [101, 112], [112, 113], [114, 122], [123, 130], [131, 134], [135, 145], [146, 157], [158, 160], [161, 168], [169, 179], [180, 186], [187, 194], [195, 199], [200, 202], [203, 209], [210, 217], [217, 218], [219, 223], [223, 224], [224, 227], [228, 235], [235, 236], [237, 244], [245, 255], [256, 259], [260, 270], [271, 277], [278, 283], [284, 292], [293, 305], [306, 309], [310, 316], [317, 327], [328, 331], [332, 337], [338, 340], [341, 346], [347, 349], [350, 360], [361, 368], [369, 376], [376, 377]]}
{"doc_key": "ai-test-145", "ner": [[3, 5, "metrics"], [9, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 9, 3, 5, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Specifically", ",", "the", "BIBO", "stability", "criterion", "requires", "that", "the", "ROC", "of", "the", "system", "encompasses", "the", "unit", "circle", "."], "sentence-detokenized": "Specifically, the BIBO stability criterion requires that the ROC of the system encompasses the unit circle.", "token2charspan": [[0, 12], [12, 13], [14, 17], [18, 22], [23, 32], [33, 42], [43, 51], [52, 56], [57, 60], [61, 64], [65, 67], [68, 71], [72, 78], [79, 90], [91, 94], [95, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-test-146", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "The", "programme", "was", "rewritten", "in", "Java", "from", "1998", "."], "sentence-detokenized": "2 The programme was rewritten in Java from 1998.", "token2charspan": [[0, 1], [2, 5], [6, 15], [16, 19], [20, 29], [30, 32], [33, 37], [38, 42], [43, 47], [47, 48]]}
{"doc_key": "ai-test-147", "ner": [[0, 1, "metrics"], [8, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 8, 9, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "MCC", "can", "be", "calculated", "directly", "from", "the", "confusion", "matrix", "using", "the", "following", "formula", ":"], "sentence-detokenized": "The MCC can be calculated directly from the confusion matrix using the following formula:", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 25], [26, 34], [35, 39], [40, 43], [44, 53], [54, 60], [61, 66], [67, 70], [71, 80], [81, 88], [88, 89]]}
{"doc_key": "ai-test-148", "ner": [[8, 13, "organisation"], [19, 24, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 13, 19, 24, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "developed", "by", "a", "team", "from", "the", "MIT", "-", "IBM", "Watson", "AI", "Lab", "and", "first", "presented", "at", "the", "International", "Conference", "on", "Learning", "Representations", "2018", "."], "sentence-detokenized": "It was developed by a team from the MIT-IBM Watson AI Lab and first presented at the International Conference on Learning Representations 2018.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 31], [32, 35], [36, 39], [39, 40], [40, 43], [44, 50], [51, 53], [54, 57], [58, 61], [62, 67], [68, 77], [78, 80], [81, 84], [85, 98], [99, 109], [110, 112], [113, 121], [122, 137], [138, 142], [142, 143]]}
{"doc_key": "ai-test-149", "ner": [[2, 3, "metrics"], [15, 16, "metrics"], [18, 20, "metrics"], [56, 58, "metrics"], [61, 61, "metrics"], [63, 63, "metrics"], [65, 67, "metrics"], [72, 72, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 5, 6, 7, 8, 9], "relations": [[15, 16, 56, 58, "related-to", "collapses_to_identity", false, false], [18, 20, 56, 58, "related-to", "collapses_to_identity", false, false], [18, 20, 65, 67, "named", "same", false, false], [61, 61, 72, 72, "related-to", "collapses_to_identity", false, false], [63, 63, 72, 72, "related-to", "collapses_to_identity", false, false], [65, 67, 72, 72, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [1, 3, 4, 5, 6, 7], "sentence": ["If", "the", "TRUE", "prevalences", "for", "the", "two", "positive", "variables", "are", "equal", ",", "as", "assumed", "in", "Fleiss", "kappa", "and", "F", "-", "score", ",", "i.e.", "the", "number", "of", "positive", "predictions", "equals", "the", "number", "of", "positive", "classes", "in", "the", "dichotomous", "(", "two", "-", "class", ")", "case", ",", "then", "the", "various", "kappa", "and", "correlation", "measures", "collapse", "and", "are", "identical", "to", "Youden", "'s", "J", ",", "and", "recall", ",", "precision", "and", "F", "-", "score", "are", "also", "identical", "to", "accuracy", "."], "sentence-detokenized": "If the TRUE prevalences for the two positive variables are equal, as assumed in Fleiss kappa and F-score, i.e. the number of positive predictions equals the number of positive classes in the dichotomous (two-class) case, then the various kappa and correlation measures collapse and are identical to Youden's J, and recall, precision and F-score are also identical to accuracy.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 23], [24, 27], [28, 31], [32, 35], [36, 44], [45, 54], [55, 58], [59, 64], [64, 65], [66, 68], [69, 76], [77, 79], [80, 86], [87, 92], [93, 96], [97, 98], [98, 99], [99, 104], [104, 105], [106, 110], [111, 114], [115, 121], [122, 124], [125, 133], [134, 145], [146, 152], [153, 156], [157, 163], [164, 166], [167, 175], [176, 183], [184, 186], [187, 190], [191, 202], [203, 204], [204, 207], [207, 208], [208, 213], [213, 214], [215, 219], [219, 220], [221, 225], [226, 229], [230, 237], [238, 243], [244, 247], [248, 259], [260, 268], [269, 277], [278, 281], [282, 285], [286, 295], [296, 298], [299, 305], [305, 307], [308, 309], [309, 310], [311, 314], [315, 321], [321, 322], [323, 332], [333, 336], [337, 338], [338, 339], [339, 344], [345, 348], [349, 353], [354, 363], [364, 366], [367, 375], [375, 376]]}
{"doc_key": "ai-test-150", "ner": [[1, 7, "misc"], [5, 5, "misc"], [9, 9, "conference"], [14, 17, "task"], [18, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 7, 9, 9, "part-of", "", false, false], [1, 7, 9, 9, "physical", "", false, false], [1, 7, 9, 9, "temporal", "", false, false], [5, 5, 1, 7, "named", "", false, false], [14, 17, 1, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Building", "Educational", "Applications", "(", "BEA", ")", "workshop", "at", "NAACL", "2013", "hosted", "the", "first", "NLI", "collaborative", "task", ".", "Tetreault", "et", "al.", ",", "2013", "The", "competition", "resulted", "in", "29", "entries", "from", "teams", "around", "the", "world", ",", "24", "of", "which", "also", "published", "a", "paper", "describing", "their", "systems", "and", "approaches", "."], "sentence-detokenized": "The Building Educational Applications (BEA) workshop at NAACL 2013 hosted the first NLI collaborative task. Tetreault et al., 2013 The competition resulted in 29 entries from teams around the world, 24 of which also published a paper describing their systems and approaches.", "token2charspan": [[0, 3], [4, 12], [13, 24], [25, 37], [38, 39], [39, 42], [42, 43], [44, 52], [53, 55], [56, 61], [62, 66], [67, 73], [74, 77], [78, 83], [84, 87], [88, 101], [102, 106], [106, 107], [108, 117], [118, 120], [121, 124], [124, 125], [126, 130], [131, 134], [135, 146], [147, 155], [156, 158], [159, 161], [162, 169], [170, 174], [175, 180], [181, 187], [188, 191], [192, 197], [197, 198], [199, 201], [202, 204], [205, 210], [211, 215], [216, 225], [226, 227], [228, 233], [234, 244], [245, 250], [251, 258], [259, 262], [263, 273], [273, 274]]}
{"doc_key": "ai-test-151", "ner": [[1, 2, "algorithm"], [5, 7, "algorithm"], [15, 16, "misc"], [22, 23, "misc"], [42, 42, "algorithm"], [46, 46, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6], "relations": [[1, 2, 5, 7, "type-of", "", false, false], [1, 2, 15, 16, "related-to", "finds", false, false], [22, 23, 15, 16, "type-of", "", false, false], [46, 46, 42, 42, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Viterbi", "algorithm", "is", "a", "dynamic", "programming", "algorithm", "for", "finding", "the", "most", "likely", "sequence", "of", "hidden", "states", ",", "the", "so", "-", "called", "Viterbi", "path", ",", "leading", "to", "a", "sequence", "of", "observed", "events", ",", "especially", "in", "the", "context", "of", "Markov", "information", "sources", "and", "hidden", "Markov", "models", "(", "HMM", ")", "."], "sentence-detokenized": "The Viterbi algorithm is a dynamic programming algorithm for finding the most likely sequence of hidden states, the so-called Viterbi path, leading to a sequence of observed events, especially in the context of Markov information sources and hidden Markov models (HMM).", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 24], [25, 26], [27, 34], [35, 46], [47, 56], [57, 60], [61, 68], [69, 72], [73, 77], [78, 84], [85, 93], [94, 96], [97, 103], [104, 110], [110, 111], [112, 115], [116, 118], [118, 119], [119, 125], [126, 133], [134, 138], [138, 139], [140, 147], [148, 150], [151, 152], [153, 161], [162, 164], [165, 173], [174, 180], [180, 181], [182, 192], [193, 195], [196, 199], [200, 207], [208, 210], [211, 217], [218, 229], [230, 237], [238, 241], [242, 248], [249, 255], [256, 262], [263, 264], [264, 267], [267, 268], [268, 269]]}
{"doc_key": "ai-test-152", "ner": [[1, 1, "field"], [3, 7, "algorithm"], [8, 9, "misc"], [12, 13, "algorithm"], [15, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 7, 1, 1, "part-of", "", false, false], [3, 7, 8, 9, "general-affiliation", "", false, false], [3, 7, 12, 13, "related-to", "generalizes_from", false, false], [3, 7, 15, 18, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "statistics", ",", "multinomial", "logistic", "regression", "is", "a", "classification", "method", "that", "generalises", "logistic", "regression", "to", "classification", "in", "multiple", "classes", ",", "i.e.", "with", "more", "than", "two", "possible", "discrete", "outcomes", "."], "sentence-detokenized": "In statistics, multinomial logistic regression is a classification method that generalises logistic regression to classification in multiple classes, i.e. with more than two possible discrete outcomes.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 26], [27, 35], [36, 46], [47, 49], [50, 51], [52, 66], [67, 73], [74, 78], [79, 90], [91, 99], [100, 110], [111, 113], [114, 128], [129, 131], [132, 140], [141, 148], [148, 149], [150, 154], [155, 159], [160, 164], [165, 169], [170, 173], [174, 182], [183, 191], [192, 200], [200, 201]]}
{"doc_key": "ai-test-153", "ner": [[0, 3, "algorithm"], [10, 11, "field"], [13, 15, "field"], [19, 19, "task"], [21, 22, "task"], [24, 25, "task"], [27, 28, "researcher"], [30, 31, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 3, 10, 11, "part-of", "", false, false], [0, 3, 13, 15, "part-of", "", false, false], [19, 19, 0, 3, "usage", "", true, false], [21, 22, 0, 3, "usage", "", true, false], [24, 25, 0, 3, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hidden", "Markov", "models", "are", "well", "known", "for", "their", "applications", "in", "reinforcement", "learning", "and", "temporal", "pattern", "recognition", ",", "such", "as", "speech", ",", "handwriting", "recognition", ",", "gesture", "recognition", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Hidden Markov models are well known for their applications in reinforcement learning and temporal pattern recognition, such as speech, handwriting recognition, gesture recognition, Thad Starner, Alex Pentland.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 29], [30, 35], [36, 39], [40, 45], [46, 58], [59, 61], [62, 75], [76, 84], [85, 88], [89, 97], [98, 105], [106, 117], [117, 118], [119, 123], [124, 126], [127, 133], [133, 134], [135, 146], [147, 158], [158, 159], [160, 167], [168, 179], [179, 180], [181, 185], [186, 193], [193, 194], [195, 199], [200, 208], [208, 209]]}
{"doc_key": "ai-test-154", "ner": [[19, 22, "metrics"], [15, 25, "misc"]], "ner_mapping_to_source": [1, 2], "relations": [[19, 22, 15, 25, "related-to", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Essentially", ",", "this", "means", "that", "the", "conditional", "probability", "of", "a", "word", "given", "it", "s", "history", "is", "proportional", "to", "the", "maximum", "likelihood", "estimate", "of", "thatn", "-", "gram", "if", "it", "has", "been", "seen", "more", "than", "k", "times", "in", "training", "."], "sentence-detokenized": "Essentially, this means that the conditional probability of a word given its history is proportional to the maximum likelihood estimate of thatn -gram if it has been seen more than k times in training.", "token2charspan": [[0, 11], [11, 12], [13, 17], [18, 23], [24, 28], [29, 32], [33, 44], [45, 56], [57, 59], [60, 61], [62, 66], [67, 72], [73, 75], [75, 76], [77, 84], [85, 87], [88, 100], [101, 103], [104, 107], [108, 115], [116, 126], [127, 135], [136, 138], [139, 144], [145, 146], [146, 150], [151, 153], [154, 156], [157, 160], [161, 165], [166, 170], [171, 175], [176, 180], [181, 182], [183, 188], [189, 191], [192, 200], [200, 201]]}
{"doc_key": "ai-test-155", "ner": [[4, 5, "task"], [7, 7, "task"], [9, 11, "task"], [16, 18, "task"], [26, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[26, 28, 16, 18, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "interested", "in", "knowledge", "representation", ",", "reasoning", "and", "natural", "language", "understanding", ".", "He", "believes", "that", "deep", "language", "understanding", "can", "currently", "only", "be", "achieved", "through", "the", "manual", "development", "of", "semantically", "rich", "formalisms", "combined", "with", "statistical", "preferences", "."], "sentence-detokenized": "He is interested in knowledge representation, reasoning and natural language understanding. He believes that deep language understanding can currently only be achieved through the manual development of semantically rich formalisms combined with statistical preferences.", "token2charspan": [[0, 2], [3, 5], [6, 16], [17, 19], [20, 29], [30, 44], [44, 45], [46, 55], [56, 59], [60, 67], [68, 76], [77, 90], [90, 91], [92, 94], [95, 103], [104, 108], [109, 113], [114, 122], [123, 136], [137, 140], [141, 150], [151, 155], [156, 158], [159, 167], [168, 175], [176, 179], [180, 186], [187, 198], [199, 201], [202, 214], [215, 219], [220, 230], [231, 239], [240, 244], [245, 256], [257, 268], [268, 269]]}
{"doc_key": "ai-test-156", "ner": [[1, 1, "programlang"], [3, 3, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "JavaScript", ",", "Python", "or"], "sentence-detokenized": "In JavaScript, Python or", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 21], [22, 24]]}
{"doc_key": "ai-test-157", "ner": [[1, 2, "misc"], [7, 8, "misc"], [12, 12, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 2, 7, 8, "part-of", "", false, false], [7, 8, 12, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Newcomb", "Awards", "are", "published", "in", "the", "AI", "Magazine", "published", "by", "the", "AAAI", "."], "sentence-detokenized": "The Newcomb Awards are published in the AI Magazine published by the AAAI.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 22], [23, 32], [33, 35], [36, 39], [40, 42], [43, 51], [52, 61], [62, 64], [65, 68], [69, 73], [73, 74]]}
{"doc_key": "ai-test-158", "ner": [[1, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "square", "error", "for", "a", "test", "set", "of", "100", "examples", "is", "0.084", ",", "which", "is", "smaller", "than", "the", "non-normalised", "error", "."], "sentence-detokenized": "The mean square error for a test set of 100 examples is 0.084, which is smaller than the non-normalised error.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 21], [22, 25], [26, 27], [28, 32], [33, 36], [37, 39], [40, 43], [44, 52], [53, 55], [56, 61], [61, 62], [63, 68], [69, 71], [72, 79], [80, 84], [85, 88], [89, 103], [104, 109], [109, 110]]}
{"doc_key": "ai-test-159", "ner": [[0, 4, "metrics"], [9, 11, "field"], [17, 19, "task"], [21, 21, "task"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 11, 0, 4, "usage", "", false, false], [17, 19, 9, 11, "part-of", "task_part_of_field", false, false], [21, 21, 17, 19, "named", "", false, false], [25, 26, 9, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "F", "-", "score", "is", "widely", "used", "in", "the", "natural", "language", "processing", "literature", ",", "for", "example", "in", "named", "entity", "recognition", "(", "NER", ")", "assessment", "and", "word", "segmentation", "."], "sentence-detokenized": "The F-score is widely used in the natural language processing literature, for example in named entity recognition (NER) assessment and word segmentation.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 21], [22, 26], [27, 29], [30, 33], [34, 41], [42, 50], [51, 61], [62, 72], [72, 73], [74, 77], [78, 85], [86, 88], [89, 94], [95, 101], [102, 113], [114, 115], [115, 118], [118, 119], [120, 130], [131, 134], [135, 139], [140, 152], [152, 153]]}
{"doc_key": "ai-test-160", "ner": [[0, 0, "product"], [5, 6, "product"], [16, 17, "misc"], [19, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 16, 17, "related-to", "performs_task", false, false], [0, 0, 19, 20, "related-to", "performs_task", false, false], [5, 6, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Chatbots", "are", "typically", "used", "in", "dialogue", "systems", "for", "various", "purposes", ",", "e.g.", "for", "customer", "service", ",", "forwarding", "enquiries", "or", "obtaining", "information", "."], "sentence-detokenized": "Chatbots are typically used in dialogue systems for various purposes, e.g. for customer service, forwarding enquiries or obtaining information.", "token2charspan": [[0, 8], [9, 12], [13, 22], [23, 27], [28, 30], [31, 39], [40, 47], [48, 51], [52, 59], [60, 68], [68, 69], [70, 74], [75, 78], [79, 87], [88, 95], [95, 96], [97, 107], [108, 117], [118, 120], [121, 130], [131, 142], [142, 143]]}
{"doc_key": "ai-test-161", "ner": [[4, 10, "conference"], [14, 23, "conference"], [28, 38, "conference"], [48, 51, "conference"], [53, 54, "conference"]], "ner_mapping_to_source": [0, 1, 2, 4, 5], "relations": [[14, 23, 4, 10, "named", "", false, false], [28, 38, 4, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Important", "journals", "are", "the", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "later", "renamed", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "and", "since", "September", "2014", "renamed", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "-", "after", "merging", "with", "an", "ACM", "publication", ")", ",", "Computer", "Speech", "and", "Language", "and", "Speech", "Communication", "."], "sentence-detokenized": "Important journals are the IEEE Transactions on Speech and Audio Processing (later renamed IEEE Transactions on Audio, Speech and Language Processing and since September 2014 renamed IEEE / ACM Transactions on Audio, Speech and Language Processing - after merging with an ACM publication), Computer Speech and Language and Speech Communication.", "token2charspan": [[0, 9], [10, 18], [19, 22], [23, 26], [27, 31], [32, 44], [45, 47], [48, 54], [55, 58], [59, 64], [65, 75], [76, 77], [77, 82], [83, 90], [91, 95], [96, 108], [109, 111], [112, 117], [117, 118], [119, 125], [126, 129], [130, 138], [139, 149], [150, 153], [154, 159], [160, 169], [170, 174], [175, 182], [183, 187], [188, 189], [190, 193], [194, 206], [207, 209], [210, 215], [215, 216], [217, 223], [224, 227], [228, 236], [237, 247], [248, 249], [250, 255], [256, 263], [264, 268], [269, 271], [272, 275], [276, 287], [287, 288], [288, 289], [290, 298], [299, 305], [306, 309], [310, 318], [319, 322], [323, 329], [330, 343], [343, 344]]}
{"doc_key": "ai-test-162", "ner": [[0, 0, "algorithm"], [5, 6, "task"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 0, 0, "usage", "", false, false], [5, 6, 8, 9, "part-of", "task_part_of_field", false, false], [5, 6, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["EM", "is", "often", "used", "for", "clustering", "data", "in", "machine", "learning", "and", "computer", "vision", "."], "sentence-detokenized": "EM is often used for clustering data in machine learning and computer vision.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 16], [17, 20], [21, 31], [32, 36], [37, 39], [40, 47], [48, 56], [57, 60], [61, 69], [70, 76], [76, 77]]}
{"doc_key": "ai-test-163", "ner": [[9, 11, "metrics"], [24, 27, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 11, 24, 27, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["While", "there", "is", "no", "perfect", "way", "to", "describe", "the", "confusion", "matrix", "of", "TRUE", "and", "FALSE", "positives", "and", "negatives", "with", "a", "single", "number", ",", "the", "Matthews", "correlation", "coefficient", "is", "generally", "considered", "one", "of", "the", "best", "measures", "of", "its", "kind", "."], "sentence-detokenized": "While there is no perfect way to describe the confusion matrix of TRUE and FALSE positives and negatives with a single number, the Matthews correlation coefficient is generally considered one of the best measures of its kind.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 17], [18, 25], [26, 29], [30, 32], [33, 41], [42, 45], [46, 55], [56, 62], [63, 65], [66, 70], [71, 74], [75, 80], [81, 90], [91, 94], [95, 104], [105, 109], [110, 111], [112, 118], [119, 125], [125, 126], [127, 130], [131, 139], [140, 151], [152, 163], [164, 166], [167, 176], [177, 187], [188, 191], [192, 194], [195, 198], [199, 203], [204, 212], [213, 215], [216, 219], [220, 224], [224, 225]]}
{"doc_key": "ai-test-164", "ner": [[11, 12, "field"], [25, 26, "field"], [30, 31, "field"], [35, 36, "algorithm"], [38, 39, "task"], [41, 42, "algorithm"], [47, 49, "algorithm"], [51, 52, "algorithm"], [58, 60, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[30, 31, 25, 26, "part-of", "subfield", false, false], [35, 36, 30, 31, "part-of", "", false, true], [38, 39, 30, 31, "part-of", "", false, true], [41, 42, 30, 31, "part-of", "", false, true], [47, 49, 30, 31, "part-of", "", false, true], [51, 52, 30, 31, "part-of", "", false, true], [58, 60, 30, 31, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "the", "size", "and", "complexity", "of", "datasets", "increased", ",", "direct", "practical", "data", "analysis", "was", "complemented", "by", "indirect", "automated", "data", "processing", "supported", "by", "other", "discoveries", "in", "computer", "science", ",", "particularly", "in", "machine", "learning", ",", "such", "as", "neural", "networks", ",", "cluster", "analysis", ",", "genetic", "algorithms", "(", "1950s", ")", ",", "decision", "tree", "learning", "and", "decision", "rules", "(", "1960", "s", ")", "and", "support", "vector", "machines", "(", "1990", "s", ")", "."], "sentence-detokenized": "As the size and complexity of datasets increased, direct practical data analysis was complemented by indirect automated data processing supported by other discoveries in computer science, particularly in machine learning, such as neural networks, cluster analysis, genetic algorithms (1950s), decision tree learning and decision rules (1960s) and support vector machines (1990s).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 15], [16, 26], [27, 29], [30, 38], [39, 48], [48, 49], [50, 56], [57, 66], [67, 71], [72, 80], [81, 84], [85, 97], [98, 100], [101, 109], [110, 119], [120, 124], [125, 135], [136, 145], [146, 148], [149, 154], [155, 166], [167, 169], [170, 178], [179, 186], [186, 187], [188, 200], [201, 203], [204, 211], [212, 220], [220, 221], [222, 226], [227, 229], [230, 236], [237, 245], [245, 246], [247, 254], [255, 263], [263, 264], [265, 272], [273, 283], [284, 285], [285, 290], [290, 291], [291, 292], [293, 301], [302, 306], [307, 315], [316, 319], [320, 328], [329, 334], [335, 336], [336, 340], [340, 341], [341, 342], [343, 346], [347, 354], [355, 361], [362, 370], [371, 372], [372, 376], [376, 377], [377, 378], [378, 379]]}
{"doc_key": "ai-test-165", "ner": [[4, 4, "researcher"], [23, 24, "misc"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 24, 4, 4, "artifact", "", false, false], [23, 24, 13, 14, "artifact", "", false, false], [23, 24, 16, 17, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "autumn", "2005", ",", "Thrun", ",", "together", "with", "his", "long", "-", "time", "collaborators", "Dieter", "Fox", "and", "Wolfram", "Burgard", ",", "published", "a", "textbook", "entitled", "Probabilistic", "Robotics", "."], "sentence-detokenized": "In autumn 2005, Thrun, together with his long-time collaborators Dieter Fox and Wolfram Burgard, published a textbook entitled Probabilistic Robotics.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 21], [21, 22], [23, 31], [32, 36], [37, 40], [41, 45], [45, 46], [46, 50], [51, 64], [65, 71], [72, 75], [76, 79], [80, 87], [88, 95], [95, 96], [97, 106], [107, 108], [109, 117], [118, 126], [127, 140], [141, 149], [149, 150]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "and", "Pereiramath", "as", "follows", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum and Pereiramath as follows:", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 37], [38, 49], [50, 52], [53, 60], [60, 61]]}
{"doc_key": "ai-test-167", "ner": [[0, 1, "task"], [3, 3, "task"], [9, 10, "field"], [15, 16, "field"], [18, 20, "field"], [22, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 15, 16, "part-of", "task_part_of_field", false, false], [0, 1, 18, 20, "part-of", "task_part_of_field", false, false], [3, 3, 0, 1, "named", "", false, false], [15, 16, 9, 10, "part-of", "subfield", false, false], [18, 20, 9, 10, "part-of", "subfield", false, false], [22, 22, 18, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Question", "answering", "(", "QA", ")", "is", "a", "subfield", "of", "computer", "science", "in", "the", "areas", "of", "information", "retrieval", "and", "natural", "language", "processing", "(", "NLP", ")", "that", "deals", "with", "the", "development", "of", "systems", "that", "automatically", "answer", "questions", "posed", "by", "humans", "in", "natural", "language", "."], "sentence-detokenized": "Question answering (QA) is a subfield of computer science in the areas of information retrieval and natural language processing (NLP) that deals with the development of systems that automatically answer questions posed by humans in natural language.", "token2charspan": [[0, 8], [9, 18], [19, 20], [20, 22], [22, 23], [24, 26], [27, 28], [29, 37], [38, 40], [41, 49], [50, 57], [58, 60], [61, 64], [65, 70], [71, 73], [74, 85], [86, 95], [96, 99], [100, 107], [108, 116], [117, 127], [128, 129], [129, 132], [132, 133], [134, 138], [139, 144], [145, 149], [150, 153], [154, 165], [166, 168], [169, 176], [177, 181], [182, 195], [196, 202], [203, 212], [213, 218], [219, 221], [222, 228], [229, 231], [232, 239], [240, 248], [248, 249]]}
{"doc_key": "ai-test-168", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "in", "the", "version", "of", "the", "metric", "used", "in", "NIST", "evaluations", "prior", "to", "2009", ",", "the", "shortest", "reference", "rate", "was", "used", "instead", "."], "sentence-detokenized": "However, in the version of the metric used in NIST evaluations prior to 2009, the shortest reference rate was used instead.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 37], [38, 42], [43, 45], [46, 50], [51, 62], [63, 68], [69, 71], [72, 76], [76, 77], [78, 81], [82, 90], [91, 100], [101, 105], [106, 109], [110, 114], [115, 122], [122, 123]]}
{"doc_key": "ai-test-169", "ner": [[5, 5, "person"], [16, 16, "organisation"], [13, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 13, 13, "related-to", "invests_in", false, false], [13, 13, 16, 16, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["On", "27", "August", "2018", ",", "Toyota", "announced", "a", "$", "500", "million", "investment", "in", "autonomous", "cars", "from", "Uber", "."], "sentence-detokenized": "On 27 August 2018, Toyota announced a $500 million investment in autonomous cars from Uber.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 17], [17, 18], [19, 25], [26, 35], [36, 37], [38, 39], [39, 42], [43, 50], [51, 61], [62, 64], [65, 75], [76, 80], [81, 85], [86, 90], [90, 91]]}
{"doc_key": "ai-test-170", "ner": [[5, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sample", "maximum", "is", "the", "maximum", "likelihood", "estimator", "for", "the", "population", "maximum", ",", "but", "is", "biased", "as", "mentioned", "earlier", "."], "sentence-detokenized": "The sample maximum is the maximum likelihood estimator for the population maximum, but is biased as mentioned earlier.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 21], [22, 25], [26, 33], [34, 44], [45, 54], [55, 58], [59, 62], [63, 73], [74, 81], [81, 82], [83, 86], [87, 89], [90, 96], [97, 99], [100, 109], [110, 117], [117, 118]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [3, 3, "misc"], [6, 6, "metrics"], [15, 17, "algorithm"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 3, "related-to", "overcomes", false, false], [0, 0, 6, 6, "related-to", "increases", false, false], [3, 3, 15, 17, "opposite", "", false, false], [3, 3, 19, 21, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LSI", "helps", "overcome", "synonymy", "by", "increasing", "retrievability", ",", "one", "of", "the", "most", "problematic", "constraints", "in", "Boolean", "keyword", "queries", "and", "vector", "space", "models", "."], "sentence-detokenized": "LSI helps overcome synonymy by increasing retrievability, one of the most problematic constraints in Boolean keyword queries and vector space models.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 27], [28, 30], [31, 41], [42, 56], [56, 57], [58, 61], [62, 64], [65, 68], [69, 73], [74, 85], [86, 97], [98, 100], [101, 108], [109, 116], [117, 124], [125, 128], [129, 135], [136, 141], [142, 148], [148, 149]]}
{"doc_key": "ai-test-172", "ner": [[17, 17, "programlang"], [19, 19, "programlang"], [21, 21, "programlang"], [23, 24, "programlang"], [26, 26, "programlang"], [28, 28, "programlang"], [30, 30, "programlang"], [32, 32, "programlang"], [34, 34, "programlang"], [36, 36, "programlang"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [], "relations_mapping_to_source": [], "sentence": ["Data", "acquisition", "applications", "are", "usually", "controlled", "by", "software", "programs", "developed", "in", "various", "general", "programming", "languages", "such", "as", "Assembler", ",", "BASIC", ",", "C", ",", "C", "+", ",", "C#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", ",", "etc."], "sentence-detokenized": "Data acquisition applications are usually controlled by software programs developed in various general programming languages such as Assembler, BASIC, C, C+, C#, Fortran, Java, LabVIEW, Lisp, Pascal, etc.", "token2charspan": [[0, 4], [5, 16], [17, 29], [30, 33], [34, 41], [42, 52], [53, 55], [56, 64], [65, 73], [74, 83], [84, 86], [87, 94], [95, 102], [103, 114], [115, 124], [125, 129], [130, 132], [133, 142], [142, 143], [144, 149], [149, 150], [151, 152], [152, 153], [154, 155], [155, 156], [156, 157], [158, 160], [160, 161], [162, 169], [169, 170], [171, 175], [175, 176], [177, 184], [184, 185], [186, 190], [190, 191], [192, 198], [198, 199], [200, 204]]}
{"doc_key": "ai-test-173", "ner": [[3, 3, "organisation"], [10, 10, "country"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2003", ",", "Honda", "released", "its", "Cog", "advertisements", "in", "the", "UK", "and", "on", "the", "internet", "."], "sentence-detokenized": "In 2003, Honda released its Cog advertisements in the UK and on the internet.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 27], [28, 31], [32, 46], [47, 49], [50, 53], [54, 56], [57, 60], [61, 63], [64, 67], [68, 76], [76, 77]]}
{"doc_key": "ai-test-174", "ner": [[1, 7, "conference"], [6, 7, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 7, 6, 7, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Association", "for", "Computational", "Linguistics", "defines", "computational", "linguistics", "as", ":"], "sentence-detokenized": "The Association for Computational Linguistics defines computational linguistics as:", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 33], [34, 45], [46, 53], [54, 67], [68, 79], [80, 82], [82, 83]]}
{"doc_key": "ai-test-175", "ner": [[0, 1, "algorithm"], [9, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 9, 12, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["Expectation", "maximisation", "algorithms", "can", "be", "used", "to", "compute", "approximate", "maximum", "likelihood", "estimates", "of", "unknown", "state", "space", "parameters", "within", "minimum", "variance", "filters", "and", "smoothers", "."], "sentence-detokenized": "Expectation maximisation algorithms can be used to compute approximate maximum likelihood estimates of unknown state space parameters within minimum variance filters and smoothers.", "token2charspan": [[0, 11], [12, 24], [25, 35], [36, 39], [40, 42], [43, 47], [48, 50], [51, 58], [59, 70], [71, 78], [79, 89], [90, 99], [100, 102], [103, 110], [111, 116], [117, 122], [123, 133], [134, 140], [141, 148], [149, 157], [158, 165], [166, 169], [170, 179], [179, 180]]}
{"doc_key": "ai-test-176", "ner": [[5, 7, "person"], [9, 10, "person"], [12, 13, "person"], [16, 17, "misc"], [18, 19, "person"], [22, 23, "person"], [27, 27, "person"], [29, 30, "person"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8], "relations": [[18, 19, 16, 17, "role", "model_for", false, false], [27, 27, 29, 30, "social", "family", false, false]], "relations_mapping_to_source": [3, 4], "sentence": ["Correspondents", "included", "former", "Baywatch", "actresses", "Donna", "D'", "Errico", ",", "Carmen", "Electra", "and", "Traci", "Bingham", ",", "former", "Playboy", "Playmate", "Heidi", "Mark", ",", "comedian", "Arj", "Barker", "and", "identical", "twins", "Randy", "and", "Jason", "Sklar", "."], "sentence-detokenized": "Correspondents included former Baywatch actresses Donna D'Errico, Carmen Electra and Traci Bingham, former Playboy Playmate Heidi Mark, comedian Arj Barker and identical twins Randy and Jason Sklar.", "token2charspan": [[0, 14], [15, 23], [24, 30], [31, 39], [40, 49], [50, 55], [56, 58], [58, 64], [64, 65], [66, 72], [73, 80], [81, 84], [85, 90], [91, 98], [98, 99], [100, 106], [107, 114], [115, 123], [124, 129], [130, 134], [134, 135], [136, 144], [145, 148], [149, 155], [156, 159], [160, 169], [170, 175], [176, 181], [182, 185], [186, 191], [192, 197], [197, 198]]}
{"doc_key": "ai-test-177", "ner": [[8, 9, "task"], [11, 11, "task"], [16, 18, "product"], [21, 22, "task"], [24, 24, "task"], [29, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 8, 9, "named", "", false, false], [16, 18, 8, 9, "general-affiliation", "", false, false], [24, 24, 21, 22, "named", "", false, false], [29, 30, 21, 22, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "is", "commonly", "used", "to", "generate", "representations", "for", "speech", "recognition", "(", "ASR", ")", ",", "e.g.", "the", "CMU", "Sphinx", "system", ",", "and", "speech", "synthesis", "(", "TTS", ")", ",", "e.g.", "the", "Festival", "system", "."], "sentence-detokenized": "It is commonly used to generate representations for speech recognition (ASR), e.g. the CMU Sphinx system, and speech synthesis (TTS), e.g. the Festival system.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 19], [20, 22], [23, 31], [32, 47], [48, 51], [52, 58], [59, 70], [71, 72], [72, 75], [75, 76], [76, 77], [78, 82], [83, 86], [87, 90], [91, 97], [98, 104], [104, 105], [106, 109], [110, 116], [117, 126], [127, 128], [128, 131], [131, 132], [132, 133], [134, 138], [139, 142], [143, 151], [152, 158], [158, 159]]}
{"doc_key": "ai-test-178", "ner": [[0, 1, "metrics"], [3, 5, "metrics"], [7, 7, "metrics"], [12, 14, "metrics"], [23, 24, "metrics"], [26, 26, "metrics"], [36, 37, "metrics"], [39, 39, "metrics"], [41, 43, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 5, 0, 1, "named", "", false, false], [7, 7, 3, 5, "named", "", false, false], [12, 14, 0, 1, "named", "", false, false], [26, 26, 23, 24, "named", "", false, false], [39, 39, 36, 37, "named", "", false, false], [41, 43, 36, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "sensitivity", "or", "TRUE", "positive", "rate", "(", "TPR", ")", ",", "also", "called", "recall", ",", "is", "the", "proportion", "of", "people", "who", "test", "positive", "(", "TRUE", "positive", ",", "TP", ")", "to", "all", "people", "who", "are", "actually", "positive", "(", "condition", "positive", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "The sensitivity or TRUE positive rate (TPR), also called recall, is the proportion of people who test positive (TRUE positive, TP) to all people who are actually positive (condition positive, CP = TP + FN).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 23], [24, 32], [33, 37], [38, 39], [39, 42], [42, 43], [43, 44], [45, 49], [50, 56], [57, 63], [63, 64], [65, 67], [68, 71], [72, 82], [83, 85], [86, 92], [93, 96], [97, 101], [102, 110], [111, 112], [112, 116], [117, 125], [125, 126], [127, 129], [129, 130], [131, 133], [134, 137], [138, 144], [145, 148], [149, 152], [153, 161], [162, 170], [171, 172], [172, 181], [182, 190], [190, 191], [192, 194], [195, 196], [197, 199], [200, 201], [202, 204], [204, 205], [205, 206]]}
{"doc_key": "ai-test-179", "ner": [[11, 11, "conference"], [13, 14, "conference"], [16, 16, "conference"], [18, 18, "conference"], [20, 20, "conference"], [23, 24, "conference"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Popular", "speech", "recognition", "conferences", "held", "every", "one", "to", "two", "years", "include", "SpeechTEK", "and", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", "and", "the", "IEEE", "ASRU", "."], "sentence-detokenized": "Popular speech recognition conferences held every one to two years include SpeechTEK and SpeechTEK Europe, ICASSP, Interspeech / Eurospeech and the IEEE ASRU.", "token2charspan": [[0, 7], [8, 14], [15, 26], [27, 38], [39, 43], [44, 49], [50, 53], [54, 56], [57, 60], [61, 66], [67, 74], [75, 84], [85, 88], [89, 98], [99, 105], [105, 106], [107, 113], [113, 114], [115, 126], [127, 128], [129, 139], [140, 143], [144, 147], [148, 152], [153, 157], [157, 158]]}
{"doc_key": "ai-test-180", "ner": [[0, 0, "researcher"], [3, 3, "researcher"], [18, 19, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[24, 24, 0, 0, "artifact", "", false, false], [24, 24, 3, 3, "artifact", "", false, false], [24, 24, 18, 19, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Devol", "worked", "with", "Engelberger", ",", "who", "served", "as", "president", "of", "the", "company", ",", "to", "develop", "and", "produce", "an", "industrial", "robot", "under", "the", "brand", "name", "Unimate", "."], "sentence-detokenized": "Devol worked with Engelberger, who served as president of the company, to develop and produce an industrial robot under the brand name Unimate.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 29], [29, 30], [31, 34], [35, 41], [42, 44], [45, 54], [55, 57], [58, 61], [62, 69], [69, 70], [71, 73], [74, 81], [82, 85], [86, 93], [94, 96], [97, 107], [108, 113], [114, 119], [120, 123], [124, 129], [130, 134], [135, 142], [142, 143]]}
{"doc_key": "ai-test-181", "ner": [[1, 3, "algorithm"], [5, 5, "algorithm"], [9, 12, "algorithm"], [22, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 3, 9, 12, "general-affiliation", "", false, false], [5, 5, 1, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "hidden", "Markov", "model", "(", "HMM", ")", "is", "a", "statistical", "Markov", "model", "in", "which", "the", "modelled", "system", "is", "assumed", "to", "be", "a", "Markov", "process", "with", "unobserved", "(", "hidden", ")", "states", "."], "sentence-detokenized": "A hidden Markov model (HMM) is a statistical Markov model in which the modelled system is assumed to be a Markov process with unobserved (hidden) states.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [22, 23], [23, 26], [26, 27], [28, 30], [31, 32], [33, 44], [45, 51], [52, 57], [58, 60], [61, 66], [67, 70], [71, 79], [80, 86], [87, 89], [90, 97], [98, 100], [101, 103], [104, 105], [106, 112], [113, 120], [121, 125], [126, 136], [137, 138], [138, 144], [144, 145], [146, 152], [152, 153]]}
{"doc_key": "ai-test-182", "ner": [[15, 17, "metrics"], [20, 20, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "undesirable", "property", "in", "many", "applications", "has", "led", "researchers", "to", "use", "alternatives", "such", "as", "the", "mean", "absolute", "error", "or", "the", "median", "."], "sentence-detokenized": "This undesirable property in many applications has led researchers to use alternatives such as the mean absolute error or the median.", "token2charspan": [[0, 4], [5, 16], [17, 25], [26, 28], [29, 33], [34, 46], [47, 50], [51, 54], [55, 66], [67, 69], [70, 73], [74, 86], [87, 91], [92, 94], [95, 98], [99, 103], [104, 112], [113, 118], [119, 121], [122, 125], [126, 132], [132, 133]]}
{"doc_key": "ai-test-183", "ner": [[23, 24, "algorithm"], [32, 33, "field"], [36, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 24, 32, 33, "part-of", "", false, false], [23, 24, 36, 38, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Such", "a", "sequence", "(", "which", "at", "each", "stage", "depends", "on", "the", "result", "of", "the", "examination", "of", "the", "preceding", "attributes", ")", "is", "called", "a", "decision", "tree", "and", "is", "applied", "in", "the", "field", "of", "machine", "learning", ",", "called", "decision", "tree", "learning", "."], "sentence-detokenized": "Such a sequence (which at each stage depends on the result of the examination of the preceding attributes) is called a decision tree and is applied in the field of machine learning, called decision tree learning.", "token2charspan": [[0, 4], [5, 6], [7, 15], [16, 17], [17, 22], [23, 25], [26, 30], [31, 36], [37, 44], [45, 47], [48, 51], [52, 58], [59, 61], [62, 65], [66, 77], [78, 80], [81, 84], [85, 94], [95, 105], [105, 106], [107, 109], [110, 116], [117, 118], [119, 127], [128, 132], [133, 136], [137, 139], [140, 147], [148, 150], [151, 154], [155, 160], [161, 163], [164, 171], [172, 180], [180, 181], [182, 188], [189, 197], [198, 202], [203, 211], [211, 212]]}
{"doc_key": "ai-test-184", "ner": [[2, 3, "task"], [5, 5, "algorithm"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 5, 5, "compare", "", false, false], [20, 21, 5, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "with", "factor", "analysis", ",", "LCA", "can", "also", "be", "used", "to", "classify", "cases", "according", "to", "their", "membership", "of", "a", "particular", "maximum", "likelihood", "class", "."], "sentence-detokenized": "As with factor analysis, LCA can also be used to classify cases according to their membership of a particular maximum likelihood class.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 23], [23, 24], [25, 28], [29, 32], [33, 37], [38, 40], [41, 45], [46, 48], [49, 57], [58, 63], [64, 73], [74, 76], [77, 82], [83, 93], [94, 96], [97, 98], [99, 109], [110, 117], [118, 128], [129, 134], [134, 135]]}
{"doc_key": "ai-test-185", "ner": [[0, 3, "algorithm"], [6, 8, "metrics"], [10, 10, "metrics"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 6, 8, "usage", "", false, false], [6, 8, 12, 13, "related-to", "", false, false], [10, 10, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["For", "supervised", "neural", "networks", "using", "a", "mean", "square", "error", "(", "MSE", ")", "cost", "function", ",", "formal", "statistical", "methods", "can", "be", "used", "to", "determine", "the", "reliability", "of", "the", "trained", "model", "."], "sentence-detokenized": "For supervised neural networks using a mean square error (MSE) cost function, formal statistical methods can be used to determine the reliability of the trained model.", "token2charspan": [[0, 3], [4, 14], [15, 21], [22, 30], [31, 36], [37, 38], [39, 43], [44, 50], [51, 56], [57, 58], [58, 61], [61, 62], [63, 67], [68, 76], [76, 77], [78, 84], [85, 96], [97, 104], [105, 108], [109, 111], [112, 116], [117, 119], [120, 129], [130, 133], [134, 145], [146, 148], [149, 152], [153, 160], [161, 166], [166, 167]]}
{"doc_key": "ai-test-186", "ner": [[16, 17, "algorithm"], [20, 22, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 17, 20, 22, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "can", "be", "expressed", "directly", "as", "a", "linear", "programme", ",", "but", "is", "also", "equivalent", "to", "the", "Tikhonov", "regularisation", "with", "the", "hinge", "loss", "function", ",", "mathV", "(", "f", "(", "x", ")", ",", "y", ")", "=\\", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "math", ":"], "sentence-detokenized": "This can be expressed directly as a linear programme, but is also equivalent to the Tikhonov regularisation with the hinge loss function, mathV (f (x), y) =\\ max (0, 1 - yf (x)) / math:", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 21], [22, 30], [31, 33], [34, 35], [36, 42], [43, 52], [52, 53], [54, 57], [58, 60], [61, 65], [66, 76], [77, 79], [80, 83], [84, 92], [93, 107], [108, 112], [113, 116], [117, 122], [123, 127], [128, 136], [136, 137], [138, 143], [144, 145], [145, 146], [147, 148], [148, 149], [149, 150], [150, 151], [152, 153], [153, 154], [155, 157], [158, 161], [162, 163], [163, 164], [164, 165], [166, 167], [168, 169], [170, 172], [173, 174], [174, 175], [175, 176], [176, 177], [178, 179], [180, 184], [184, 185]]}
{"doc_key": "ai-test-187", "ner": [[10, 10, "researcher"], [16, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "technique", "was", "described", "in", "the", "original", "paper", "by", "Breiman", "and", "is", "implemented", "in", "the", "R", "package", "randomForest", "."], "sentence-detokenized": "The following technique was described in the original paper by Breiman and is implemented in the R package randomForest.", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 27], [28, 37], [38, 40], [41, 44], [45, 53], [54, 59], [60, 62], [63, 70], [71, 74], [75, 77], [78, 89], [90, 92], [93, 96], [97, 98], [99, 106], [107, 119], [119, 120]]}
{"doc_key": "ai-test-188", "ner": [[6, 6, "metrics"], [37, 37, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "image", "quality", "measurements", "such", "as", "PSNR", "are", "usually", "performed", "for", "fixed", "resolution", "images", "and", "do", "not", "take", "into", "account", "some", "aspects", "of", "the", "human", "visual", "system", ",", "such", "as", "the", "change", "in", "spatial", "resolution", "on", "the", "retina", "."], "sentence-detokenized": "Traditional image quality measurements such as PSNR are usually performed for fixed resolution images and do not take into account some aspects of the human visual system, such as the change in spatial resolution on the retina.", "token2charspan": [[0, 11], [12, 17], [18, 25], [26, 38], [39, 43], [44, 46], [47, 51], [52, 55], [56, 63], [64, 73], [74, 77], [78, 83], [84, 94], [95, 101], [102, 105], [106, 108], [109, 112], [113, 117], [118, 122], [123, 130], [131, 135], [136, 143], [144, 146], [147, 150], [151, 156], [157, 163], [164, 170], [170, 171], [172, 176], [177, 179], [180, 183], [184, 190], [191, 193], [194, 201], [202, 212], [213, 215], [216, 219], [220, 226], [226, 227]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [11, 11, "person"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 15, 16, "role", "", false, false], [3, 4, 15, 16, "role", "", false, false], [6, 7, 15, 16, "role", "", false, false], [15, 16, 11, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Dru", "and", "Macdonald", "Carey", "starred", "in", "the", "Jack", "Broder", "colour", "production", "Hannah", "Lee", ",", "which", "premiered", "on", "19", "June", "1953", "."], "sentence-detokenized": "John Ireland, Joanne Dru and Macdonald Carey starred in the Jack Broder colour production Hannah Lee, which premiered on 19 June 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 55], [56, 59], [60, 64], [65, 71], [72, 78], [79, 89], [90, 96], [97, 100], [100, 101], [102, 107], [108, 117], [118, 120], [121, 123], [124, 128], [129, 133], [133, 134]]}
{"doc_key": "ai-test-190", "ner": [[4, 5, "task"], [9, 10, "field"], [16, 16, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 9, 10, "usage", "", false, false], [16, 16, 9, 10, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "process", "is", "called", "image", "registration", "and", "uses", "various", "computer", "vision", "methods", ",", "mostly", "related", "to", "tracking", "."], "sentence-detokenized": "This process is called image registration and uses various computer vision methods, mostly related to tracking.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 22], [23, 28], [29, 41], [42, 45], [46, 50], [51, 58], [59, 67], [68, 74], [75, 82], [82, 83], [84, 90], [91, 98], [99, 101], [102, 110], [110, 111]]}
{"doc_key": "ai-test-191", "ner": [[16, 17, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Let", "us", "now", "begin", "to", "explain", "the", "various", "possible", "relationships", "between", "predicted", "and", "actual", "outcomes", ":", "Confusion", "matrix"], "sentence-detokenized": "Let us now begin to explain the various possible relationships between predicted and actual outcomes: Confusion matrix", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [17, 19], [20, 27], [28, 31], [32, 39], [40, 48], [49, 62], [63, 70], [71, 80], [81, 84], [85, 91], [92, 100], [100, 101], [102, 111], [112, 118]]}
{"doc_key": "ai-test-192", "ner": [[1, 1, "product"], [2, 4, "misc"], [6, 6, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 2, 4, "part-of", "", false, false], [1, 1, 2, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "VOICEBOX", "speech", "processing", "toolbox", "for", "MATLAB", "implements", "the", "conversion", "and", "its", "inversion", "as", ":"], "sentence-detokenized": "The VOICEBOX speech processing toolbox for MATLAB implements the conversion and its inversion as:", "token2charspan": [[0, 3], [4, 12], [13, 19], [20, 30], [31, 38], [39, 42], [43, 49], [50, 60], [61, 64], [65, 75], [76, 79], [80, 83], [84, 93], [94, 96], [96, 97]]}
{"doc_key": "ai-test-193", "ner": [[0, 0, "programlang"], [8, 9, "field"], [11, 11, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 9, "general-affiliation", "", false, false], [0, 0, 11, 11, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "is", "a", "logical", "programming", "language", "associated", "with", "artificial", "intelligence", "and", "computational", "linguistics", "."], "sentence-detokenized": "Prolog is a logical programming language associated with artificial intelligence and computational linguistics.", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 19], [20, 31], [32, 40], [41, 51], [52, 56], [57, 67], [68, 80], [81, 84], [85, 98], [99, 110], [110, 111]]}
{"doc_key": "ai-test-194", "ner": [[0, 0, "researcher"], [9, 9, "field"], [11, 11, "field"], [17, 20, "organisation"], [23, 26, "organisation"], [29, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 9, 9, "related-to", "works_with_topic", false, false], [0, 0, 11, 11, "related-to", "works_with_topic", false, false], [0, 0, 17, 20, "role", "", false, false], [0, 0, 23, 26, "role", "", false, false], [0, 0, 29, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "has", "received", "numerous", "awards", "for", "her", "contributions", "to", "neuroscience", "and", "psychology", ",", "including", "memberships", "in", "the", "Royal", "Society", "of", "London", ",", "the", "Royal", "Society", "of", "Canada", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner has received numerous awards for her contributions to neuroscience and psychology, including memberships in the Royal Society of London, the Royal Society of Canada and the National Academy of Sciences.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 28], [29, 35], [36, 39], [40, 43], [44, 57], [58, 60], [61, 73], [74, 77], [78, 88], [88, 89], [90, 99], [100, 111], [112, 114], [115, 118], [119, 124], [125, 132], [133, 135], [136, 142], [142, 143], [144, 147], [148, 153], [154, 161], [162, 164], [165, 171], [172, 175], [176, 179], [180, 188], [189, 196], [197, 199], [200, 208], [208, 209]]}
{"doc_key": "ai-test-195", "ner": [[16, 17, "task"], [19, 20, "task"], [23, 23, "task"], [26, 26, "task"], [28, 28, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["By", "combining", "these", "operators", ",", "one", "obtains", "algorithms", "for", "many", "image", "processing", "tasks", ",", "such", "as", "feature", "extraction", ",", "image", "segmentation", ",", "image", "sharpening", ",", "image", "filtering", "and", "classification", "."], "sentence-detokenized": "By combining these operators, one obtains algorithms for many image processing tasks, such as feature extraction, image segmentation, image sharpening, image filtering and classification.", "token2charspan": [[0, 2], [3, 12], [13, 18], [19, 28], [28, 29], [30, 33], [34, 41], [42, 52], [53, 56], [57, 61], [62, 67], [68, 78], [79, 84], [84, 85], [86, 90], [91, 93], [94, 101], [102, 112], [112, 113], [114, 119], [120, 132], [132, 133], [134, 139], [140, 150], [150, 151], [152, 157], [158, 167], [168, 171], [172, 186], [186, 187]]}
{"doc_key": "ai-test-196", "ner": [[7, 10, "university"], [15, 17, "organisation"], [19, 20, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 20, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "has", "been", "a", "professor", "at", "the", "Coll\u00e8ge", "de", "France", "since", "2017", "and", "director", "of", "INSERM", "Unit", "562", ",", "Cognitive", "Neuroimaging", ",", "since", "1989", "."], "sentence-detokenized": "He has been a professor at the Coll\u00e8ge de France since 2017 and director of INSERM Unit 562, Cognitive Neuroimaging, since 1989.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 13], [14, 23], [24, 26], [27, 30], [31, 38], [39, 41], [42, 48], [49, 54], [55, 59], [60, 63], [64, 72], [73, 75], [76, 82], [83, 87], [88, 91], [91, 92], [93, 102], [103, 115], [115, 116], [117, 122], [123, 127], [127, 128]]}
{"doc_key": "ai-test-197", "ner": [[12, 14, "algorithm"], [16, 19, "algorithm"], [24, 24, "algorithm"], [26, 32, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[24, 24, 26, 32, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["There", "are", "many", "approaches", "to", "learning", "these", "embeddings", ",", "in", "particular", "with", "Bayesian", "clustering", "frameworks", "or", "energy", "-", "based", "frameworks", "and", "more", "recently", "with", "TransE", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", "2013", ")", "."], "sentence-detokenized": "There are many approaches to learning these embeddings, in particular with Bayesian clustering frameworks or energy-based frameworks and more recently with TransE (Conference on Neural Information Processing Systems 2013).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 25], [26, 28], [29, 37], [38, 43], [44, 54], [54, 55], [56, 58], [59, 69], [70, 74], [75, 83], [84, 94], [95, 105], [106, 108], [109, 115], [115, 116], [116, 121], [122, 132], [133, 136], [137, 141], [142, 150], [151, 155], [156, 162], [163, 164], [164, 174], [175, 177], [178, 184], [185, 196], [197, 207], [208, 215], [216, 220], [220, 221], [221, 222]]}
{"doc_key": "ai-test-198", "ner": [[6, 6, "metrics"], [7, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 6, 6, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "is", "an", "alternative", "to", "the", "Word", "Error", "Rate", ",", "which", "is", "used", "in", "several", "countries", "."], "sentence-detokenized": "It is an alternative to the Word Error Rate, which is used in several countries.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 20], [21, 23], [24, 27], [28, 32], [33, 38], [39, 43], [43, 44], [45, 50], [51, 53], [54, 58], [59, 61], [62, 69], [70, 79], [79, 80]]}
{"doc_key": "ai-test-199", "ner": [[0, 0, "algorithm"], [11, 12, "task"], [14, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 27, "task"], [29, 30, "task"], [45, 45, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 0, 0, "usage", "", false, false], [14, 15, 0, 0, "usage", "", false, false], [17, 18, 0, 0, "usage", "", false, false], [20, 22, 0, 0, "usage", "", false, false], [24, 27, 0, 0, "usage", "", false, false], [29, 30, 0, 0, "usage", "", false, false], [45, 45, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["ANNs", "have", "been", "used", "for", "a", "variety", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "board", "and", "video", "games", ",", "medical", "diagnosis", ",", "and", "even", "activities", "traditionally", "thought", "to", "be", "reserved", "for", "humans", ",", "such", "as", "painting", "."], "sentence-detokenized": "ANNs have been used for a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, board and video games, medical diagnosis, and even activities traditionally thought to be reserved for humans, such as painting.", "token2charspan": [[0, 4], [5, 9], [10, 14], [15, 19], [20, 23], [24, 25], [26, 33], [34, 36], [37, 42], [42, 43], [44, 53], [54, 62], [63, 69], [69, 70], [71, 77], [78, 89], [89, 90], [91, 98], [99, 110], [110, 111], [112, 118], [119, 126], [127, 136], [136, 137], [138, 143], [144, 147], [148, 153], [154, 159], [159, 160], [161, 168], [169, 178], [178, 179], [180, 183], [184, 188], [189, 199], [200, 213], [214, 221], [222, 224], [225, 227], [228, 236], [237, 240], [241, 247], [247, 248], [249, 253], [254, 256], [257, 265], [265, 266]]}
{"doc_key": "ai-test-200", "ner": [[0, 3, "product"], [5, 5, "product"], [24, 26, "field"], [28, 28, "field"], [33, 34, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 24, 26, "related-to", "", false, false], [0, 3, 33, 34, "general-affiliation", "", false, false], [5, 5, 0, 3, "named", "", false, false], [28, 28, 24, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "is", "an", "open", "source", "research", "platform", "and", "collection", "of", "voice", ",", "sound", ",", "speech", ",", "text", "and", "natural", "language", "processing", "(", "NLP", ")", "algorithms", "written", "in", "Java", "and", "arranged", "in", "a", "modular", "and", "extensible", "framework", "designed", "to", "facilitate", "the", "addition", "of", "new", "algorithms", "."], "sentence-detokenized": "Modular Audio Recognition Framework (MARF) is an open source research platform and collection of voice, sound, speech, text and natural language processing (NLP) algorithms written in Java and arranged in a modular and extensible framework designed to facilitate the addition of new algorithms.", "token2charspan": [[0, 7], [8, 13], [14, 25], [26, 35], [36, 37], [37, 41], [41, 42], [43, 45], [46, 48], [49, 53], [54, 60], [61, 69], [70, 78], [79, 82], [83, 93], [94, 96], [97, 102], [102, 103], [104, 109], [109, 110], [111, 117], [117, 118], [119, 123], [124, 127], [128, 135], [136, 144], [145, 155], [156, 157], [157, 160], [160, 161], [162, 172], [173, 180], [181, 183], [184, 188], [189, 192], [193, 201], [202, 204], [205, 206], [207, 214], [215, 218], [219, 229], [230, 239], [240, 248], [249, 251], [252, 262], [263, 266], [267, 275], [276, 278], [279, 282], [283, 293], [293, 294]]}
{"doc_key": "ai-test-201", "ner": [[9, 11, "organisation"], [15, 15, "country"], [19, 21, "organisation"], [24, 27, "organisation"], [29, 31, "task"], [44, 46, "organisation"], [47, 52, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[19, 21, 15, 15, "physical", "", false, false], [19, 21, 29, 31, "usage", "", false, false], [19, 21, 44, 46, "named", "", false, false], [24, 27, 15, 15, "physical", "", false, false], [24, 27, 29, 31, "usage", "", false, false], [44, 46, 47, 52, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "a", "report", "by", "civil", "liberties", "organisation", "Big", "Brother", "Watch", "revealed", "that", "two", "UK", "police", "forces", ",", "South", "Wales", "Police", "and", "the", "Metropolitan", "Police", ",", "were", "using", "live", "facial", "recognition", "at", "public", "events", "and", "in", "public", "spaces", ";", "in", "September", "2019", ",", "South", "Wales", "Police", "'s", "use", "of", "facial", "recognition", "was", "declared", "lawful", "."], "sentence-detokenized": "In 2018, a report by civil liberties organisation Big Brother Watch revealed that two UK police forces, South Wales Police and the Metropolitan Police, were using live facial recognition at public events and in public spaces; in September 2019, South Wales Police's use of facial recognition was declared lawful.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 20], [21, 26], [27, 36], [37, 49], [50, 53], [54, 61], [62, 67], [68, 76], [77, 81], [82, 85], [86, 88], [89, 95], [96, 102], [102, 103], [104, 109], [110, 115], [116, 122], [123, 126], [127, 130], [131, 143], [144, 150], [150, 151], [152, 156], [157, 162], [163, 167], [168, 174], [175, 186], [187, 189], [190, 196], [197, 203], [204, 207], [208, 210], [211, 217], [218, 224], [224, 225], [226, 228], [229, 238], [239, 243], [243, 244], [245, 250], [251, 256], [257, 263], [263, 265], [266, 269], [270, 272], [273, 279], [280, 291], [292, 295], [296, 304], [305, 311], [311, 312]]}
{"doc_key": "ai-test-202", "ner": [[0, 1, "product"], [4, 4, "programlang"], [13, 14, "field"], [16, 16, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 4, "general-affiliation", "", false, false], [0, 1, 13, 14, "related-to", "", false, false], [0, 1, 16, 16, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "was", "ported", "to", "R", ",", "a", "freely", "available", "language", "and", "environment", "for", "statistical", "calculations", "and", "graphics", "."], "sentence-detokenized": "ANIMAL was ported to R, a freely available language and environment for statistical calculations and graphics.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 20], [21, 22], [22, 23], [24, 25], [26, 32], [33, 42], [43, 51], [52, 55], [56, 67], [68, 71], [72, 83], [84, 96], [97, 100], [101, 109], [109, 110]]}
{"doc_key": "ai-test-203", "ner": [[0, 6, "algorithm"], [8, 10, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 6, 17, 19, "opposite", "alternative to", false, false], [8, 10, 0, 6, "named", "", false, false], [21, 21, 17, 19, "named", "", false, false], [24, 26, 0, 6, "usage", "", false, false], [24, 26, 17, 19, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "time", "-", "inhomogeneous", "hidden", "Bernoulli", "model", "(", "TI", "-", "HBM", ")", "is", "an", "alternative", "to", "the", "hidden", "Markov", "model", "(", "HMM", ")", "for", "automatic", "speech", "recognition", "."], "sentence-detokenized": "The time-inhomogeneous hidden Bernoulli model (TI-HBM) is an alternative to the hidden Markov model (HMM) for automatic speech recognition.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 22], [23, 29], [30, 39], [40, 45], [46, 47], [47, 49], [49, 50], [50, 53], [53, 54], [55, 57], [58, 60], [61, 72], [73, 75], [76, 79], [80, 86], [87, 93], [94, 99], [100, 101], [101, 104], [104, 105], [106, 109], [110, 119], [120, 126], [127, 138], [138, 139]]}
{"doc_key": "ai-test-204", "ner": [[4, 4, "organisation"], [13, 13, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 13, 13, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "July", "2016", ",", "Nvidia", "demonstrated", "a", "new", "method", "of", "foveated", "rendering", "at", "SIGGRAPH", "that", "is", "supposedly", "invisible", "to", "the", "user", "."], "sentence-detokenized": "In July 2016, Nvidia demonstrated a new method of foveated rendering at SIGGRAPH that is supposedly invisible to the user.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 20], [21, 33], [34, 35], [36, 39], [40, 46], [47, 49], [50, 58], [59, 68], [69, 71], [72, 80], [81, 85], [86, 88], [89, 99], [100, 109], [110, 112], [113, 116], [117, 121], [121, 122]]}
{"doc_key": "ai-test-205", "ner": [[5, 7, "misc"], [10, 11, "researcher"], [19, 20, "researcher"], [22, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 7, 10, 11, "origin", "", false, false], [5, 7, 19, 20, "origin", "", false, false], [5, 7, 22, 22, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Both", "are", "based", "on", "the", "speech", "act", "theory", "developed", "by", "John", "Searle", "in", "the", "1960s", "and", "further", "developed", "by", "Terry", "Winograd", "and", "Flores", "in", "the", "1970s", "."], "sentence-detokenized": "Both are based on the speech act theory developed by John Searle in the 1960s and further developed by Terry Winograd and Flores in the 1970s.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 17], [18, 21], [22, 28], [29, 32], [33, 39], [40, 49], [50, 52], [53, 57], [58, 64], [65, 67], [68, 71], [72, 77], [78, 81], [82, 89], [90, 99], [100, 102], [103, 108], [109, 117], [118, 121], [122, 128], [129, 131], [132, 135], [136, 141], [141, 142]]}
{"doc_key": "ai-test-206", "ner": [[0, 3, "algorithm"], [20, 22, "researcher"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 20, 22, "related-to", "", false, false], [23, 23, 20, 22, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Neural", "network", "models", "of", "concept", "formation", "and", "knowledge", "structure", "have", "opened", "up", "powerful", "hierarchical", "models", "of", "knowledge", "organisation", "such", "as", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "Neural network models of concept formation and knowledge structure have opened up powerful hierarchical models of knowledge organisation such as George Miller's Wordnet.", "token2charspan": [[0, 6], [7, 14], [15, 21], [22, 24], [25, 32], [33, 42], [43, 46], [47, 56], [57, 66], [67, 71], [72, 78], [79, 81], [82, 90], [91, 103], [104, 110], [111, 113], [114, 123], [124, 136], [137, 141], [142, 144], [145, 151], [152, 158], [158, 160], [161, 168], [168, 169]]}
{"doc_key": "ai-test-207", "ner": [[0, 1, "algorithm"], [12, 13, "field"], [16, 18, "product"], [21, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 13, "part-of", "", false, false], [0, 1, 21, 22, "part-of", "", false, false], [16, 18, 12, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Template", "matching", "has", "various", "applications", "and", "is", "used", "in", "areas", "such", "as", "face", "recognition", "(", "see", "face", "recognition", "system", ")", "and", "medical", "imaging", "."], "sentence-detokenized": "Template matching has various applications and is used in areas such as face recognition (see face recognition system) and medical imaging.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 29], [30, 42], [43, 46], [47, 49], [50, 54], [55, 57], [58, 63], [64, 68], [69, 71], [72, 76], [77, 88], [89, 90], [90, 93], [94, 98], [99, 110], [111, 117], [117, 118], [119, 122], [123, 130], [131, 138], [138, 139]]}
{"doc_key": "ai-test-208", "ner": [[13, 14, "researcher"], [16, 17, "researcher"], [22, 31, "organisation"], [33, 33, "organisation"], [41, 42, "algorithm"], [45, 51, "conference"], [53, 53, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 14, 22, 31, "role", "", false, false], [13, 14, 45, 51, "physical", "", false, false], [13, 14, 45, 51, "temporal", "", false, false], [13, 14, 53, 53, "physical", "", false, false], [16, 17, 22, 31, "role", "", false, false], [16, 17, 45, 51, "temporal", "", false, false], [33, 33, 22, 31, "named", "", false, false], [45, 51, 41, 42, "topic", "", false, false], [53, 53, 45, 51, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["However", ",", "it", "s", "use", "did", "not", "become", "widespread", "until", "2005", ",", "when", "Navneet", "Dalal", "and", "Bill", "Triggs", ",", "researchers", "at", "the", "French", "National", "Institute", "for", "Research", "in", "Computer", "Science", "and", "Automation", "(", "INRIA", ")", ",", "presented", "their", "complementary", "work", "on", "HOG", "descriptors", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "However, its use did not become widespread until 2005, when Navneet Dalal and Bill Triggs, researchers at the French National Institute for Research in Computer Science and Automation (INRIA), presented their complementary work on HOG descriptors at the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 7], [7, 8], [9, 11], [11, 12], [13, 16], [17, 20], [21, 24], [25, 31], [32, 42], [43, 48], [49, 53], [53, 54], [55, 59], [60, 67], [68, 73], [74, 77], [78, 82], [83, 89], [89, 90], [91, 102], [103, 105], [106, 109], [110, 116], [117, 125], [126, 135], [136, 139], [140, 148], [149, 151], [152, 160], [161, 168], [169, 172], [173, 183], [184, 185], [185, 190], [190, 191], [191, 192], [193, 202], [203, 208], [209, 222], [223, 227], [228, 230], [231, 234], [235, 246], [247, 249], [250, 253], [254, 264], [265, 267], [268, 276], [277, 283], [284, 287], [288, 295], [296, 307], [308, 309], [309, 313], [313, 314], [314, 315]]}
{"doc_key": "ai-test-209", "ner": [[16, 19, "organisation"], [21, 22, "organisation"], [35, 37, "researcher"], [39, 42, "researcher"], [45, 47, "researcher"], [50, 53, "organisation"], [57, 59, "organisation"], [64, 65, "researcher"]], "ner_mapping_to_source": [1, 2, 4, 5, 6, 7, 8, 9], "relations": [[35, 37, 21, 22, "physical", "", false, false], [35, 37, 21, 22, "role", "", false, false], [39, 42, 21, 22, "physical", "", false, false], [39, 42, 21, 22, "role", "", false, false], [45, 47, 21, 22, "physical", "", false, false], [45, 47, 21, 22, "role", "", false, false], [64, 65, 57, 59, "role", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "sentence": ["Before", "joining", "the", "Penn", "faculty", "in", "2002", ",", "he", "spent", "a", "decade", "(", "1991-2001", ")", "at", "AT", "&", "T", "Labs", "and", "Bell", "Labs", ",", "including", "as", "head", "of", "the", "AI", "department", "with", "colleagues", "such", "as", "Michael", "L.", "Littman", ",", "David", "A", ".", "McAllester", ",", "and", "Richard", "S.", "Sutton", ",", "the", "secure", "systems", "research", "department", ",", "and", "the", "machine", "learning", "department", "with", "members", "such", "as", "Michael", "Collins", "and", "Head", ")", "."], "sentence-detokenized": "Before joining the Penn faculty in 2002, he spent a decade (1991-2001) at AT & T Labs and Bell Labs, including as head of the AI department with colleagues such as Michael L. Littman, David A. McAllester, and Richard S. Sutton, the secure systems research department, and the machine learning department with members such as Michael Collins and Head).", "token2charspan": [[0, 6], [7, 14], [15, 18], [19, 23], [24, 31], [32, 34], [35, 39], [39, 40], [41, 43], [44, 49], [50, 51], [52, 58], [59, 60], [60, 69], [69, 70], [71, 73], [74, 76], [77, 78], [79, 80], [81, 85], [86, 89], [90, 94], [95, 99], [99, 100], [101, 110], [111, 113], [114, 118], [119, 121], [122, 125], [126, 128], [129, 139], [140, 144], [145, 155], [156, 160], [161, 163], [164, 171], [172, 174], [175, 182], [182, 183], [184, 189], [190, 191], [191, 192], [193, 203], [203, 204], [205, 208], [209, 216], [217, 219], [220, 226], [226, 227], [228, 231], [232, 238], [239, 246], [247, 255], [256, 266], [266, 267], [268, 271], [272, 275], [276, 283], [284, 292], [293, 303], [304, 308], [309, 316], [317, 321], [322, 324], [325, 332], [333, 340], [341, 344], [345, 349], [349, 350], [350, 351]]}
{"doc_key": "ai-test-210", "ner": [[5, 7, "field"], [13, 13, "field"], [23, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 13, 13, "compare", "", false, false], [23, 25, 13, 13, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["When", "data", "is", "unlabelled", ",", "supervised", "learning", "is", "not", "possible", ",", "and", "an", "unsupervised", "learning", "approach", "is", "required", "that", "attempts", "to", "find", "natural", "cluster", "analyses", "to", "groups", "and", "then", "assigns", "new", "data", "to", "these", "formed", "groups", "."], "sentence-detokenized": "When data is unlabelled, supervised learning is not possible, and an unsupervised learning approach is required that attempts to find natural cluster analyses to groups and then assigns new data to these formed groups.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 23], [23, 24], [25, 35], [36, 44], [45, 47], [48, 51], [52, 60], [60, 61], [62, 65], [66, 68], [69, 81], [82, 90], [91, 99], [100, 102], [103, 111], [112, 116], [117, 125], [126, 128], [129, 133], [134, 141], [142, 149], [150, 158], [159, 161], [162, 168], [169, 172], [173, 177], [178, 185], [186, 189], [190, 194], [195, 197], [198, 203], [204, 210], [211, 217], [217, 218]]}
{"doc_key": "ai-test-211", "ner": [[3, 7, "field"], [15, 18, "organisation"], [25, 26, "field"], [28, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 7, 15, 18, "origin", "", false, false], [3, 7, 25, 26, "part-of", "", false, false], [3, 7, 28, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "field", "of", "computer", "science", "developed", "in", "the", "1950s", "at", "academic", "institutions", "such", "as", "the", "MIT", "A.I", ".", "Lab", ",", "originally", "as", "a", "branch", "of", "artificial", "intelligence", "and", "robotics", "."], "sentence-detokenized": "This field of computer science developed in the 1950s at academic institutions such as the MIT A.I. Lab, originally as a branch of artificial intelligence and robotics.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 30], [31, 40], [41, 43], [44, 47], [48, 53], [54, 56], [57, 65], [66, 78], [79, 83], [84, 86], [87, 90], [91, 94], [95, 98], [98, 99], [100, 103], [103, 104], [105, 115], [116, 118], [119, 120], [121, 127], [128, 130], [131, 141], [142, 154], [155, 158], [159, 167], [167, 168]]}
{"doc_key": "ai-test-212", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "could", "also", "be", "replaced", "by", "the", "log", "loss", "equation", "below", ":"], "sentence-detokenized": "It could also be replaced by the log loss equation below:", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 16], [17, 25], [26, 28], [29, 32], [33, 36], [37, 41], [42, 50], [51, 56], [56, 57]]}
{"doc_key": "ai-test-213", "ner": [[1, 3, "organisation"], [7, 10, "organisation"], [14, 18, "university"], [20, 20, "university"], [22, 23, "university"], [26, 28, "university"], [31, 32, "country"], [41, 41, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 3, 41, 41, "related-to", "research_leader_in_field", false, false], [7, 10, 1, 3, "named", "", false, false], [7, 10, 41, 41, "related-to", "research_leader_in_field", false, false], [14, 18, 41, 41, "related-to", "research_leader_in_field", false, false], [20, 20, 41, 41, "related-to", "research_leader_in_field", false, false], [22, 23, 41, 41, "related-to", "research_leader_in_field", false, false], [26, 28, 31, 32, "physical", "", false, false], [26, 28, 41, 41, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "Shirley", "Ryan", "AbilityLab", "(", "formerly", "the", "Rehabilitation", "Institute", "of", "Chicago", ")", ",", "the", "University", "of", "California", "at", "Berkeley", ",", "MIT", ",", "Stanford", "University", "and", "the", "University", "of", "Twente", "in", "the", "Netherlands", "are", "the", "leading", "research", "institutions", "in", "the", "field", "of", "biomechatronics", "."], "sentence-detokenized": "The Shirley Ryan AbilityLab (formerly the Rehabilitation Institute of Chicago), the University of California at Berkeley, MIT, Stanford University and the University of Twente in the Netherlands are the leading research institutions in the field of biomechatronics.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 27], [28, 29], [29, 37], [38, 41], [42, 56], [57, 66], [67, 69], [70, 77], [77, 78], [78, 79], [80, 83], [84, 94], [95, 97], [98, 108], [109, 111], [112, 120], [120, 121], [122, 125], [125, 126], [127, 135], [136, 146], [147, 150], [151, 154], [155, 165], [166, 168], [169, 175], [176, 178], [179, 182], [183, 194], [195, 198], [199, 202], [203, 210], [211, 219], [220, 232], [233, 235], [236, 239], [240, 245], [246, 248], [249, 264], [264, 265]]}
{"doc_key": "ai-test-214", "ner": [[28, 31, "metrics"], [42, 43, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Given", "a", "set", "of", "predicted", "values", "and", "a", "corresponding", "set", "of", "actual", "values", "for", "X", "for", "different", "time", "periods", ",", "a", "common", "evaluation", "technique", "is", "to", "use", "the", "mean", "squared", "prediction", "error", ";", "other", "measures", "are", "also", "available", "(", "see", "Forecast", "#", "Prediction", "Accuracy", ")", "."], "sentence-detokenized": "Given a set of predicted values and a corresponding set of actual values for X for different time periods, a common evaluation technique is to use the mean squared prediction error; other measures are also available (see Forecast # Prediction Accuracy).", "token2charspan": [[0, 5], [6, 7], [8, 11], [12, 14], [15, 24], [25, 31], [32, 35], [36, 37], [38, 51], [52, 55], [56, 58], [59, 65], [66, 72], [73, 76], [77, 78], [79, 82], [83, 92], [93, 97], [98, 105], [105, 106], [107, 108], [109, 115], [116, 126], [127, 136], [137, 139], [140, 142], [143, 146], [147, 150], [151, 155], [156, 163], [164, 174], [175, 180], [180, 181], [182, 187], [188, 196], [197, 200], [201, 205], [206, 215], [216, 217], [217, 220], [221, 229], [230, 231], [232, 242], [243, 251], [251, 252], [252, 253]]}
{"doc_key": "ai-test-215", "ner": [[13, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "measures", ",", "such", "as", "the", "proportion", "of", "correct", "predictions", "(", "also", "called", "accuracy", ")", ",", "are", "not", "useful", "if", "the", "two", "classes", "are", "very", "different", "in", "size", "."], "sentence-detokenized": "Other measures, such as the proportion of correct predictions (also called accuracy), are not useful if the two classes are very different in size.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 20], [21, 23], [24, 27], [28, 38], [39, 41], [42, 49], [50, 61], [62, 63], [63, 67], [68, 74], [75, 83], [83, 84], [84, 85], [86, 89], [90, 93], [94, 100], [101, 103], [104, 107], [108, 111], [112, 119], [120, 123], [124, 128], [129, 138], [139, 141], [142, 146], [146, 147]]}
{"doc_key": "ai-test-216", "ner": [[5, 5, "product"], [15, 20, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 15, 20, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "alpha", "version", "of", "OpenCV", "was", "released", "to", "the", "public", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "in", "2000", ",", "and", "five", "beta", "versions", "were", "released", "between", "2001", "and", "2005", "."], "sentence-detokenized": "The first alpha version of OpenCV was released to the public at the Conference on Computer Vision and Pattern Recognition in 2000, and five beta versions were released between 2001 and 2005.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [24, 26], [27, 33], [34, 37], [38, 46], [47, 49], [50, 53], [54, 60], [61, 63], [64, 67], [68, 78], [79, 81], [82, 90], [91, 97], [98, 101], [102, 109], [110, 121], [122, 124], [125, 129], [129, 130], [131, 134], [135, 139], [140, 144], [145, 153], [154, 158], [159, 167], [168, 175], [176, 180], [181, 184], [185, 189], [189, 190]]}
{"doc_key": "ai-test-217", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Results", "were", "presented", "showing", "a", "correlation", "of", "up", "to", "0.964", "with", "human", "judgement", "at", "the", "corpus", "level", ",", "compared", "to", "the", "BLEU", "result", "of", "0.817", "for", "the", "same", "data", "set", "."], "sentence-detokenized": "Results were presented showing a correlation of up to 0.964 with human judgement at the corpus level, compared to the BLEU result of 0.817 for the same data set.", "token2charspan": [[0, 7], [8, 12], [13, 22], [23, 30], [31, 32], [33, 44], [45, 47], [48, 50], [51, 53], [54, 59], [60, 64], [65, 70], [71, 80], [81, 83], [84, 87], [88, 94], [95, 100], [100, 101], [102, 110], [111, 113], [114, 117], [118, 122], [123, 129], [130, 132], [133, 138], [139, 142], [143, 146], [147, 151], [152, 156], [157, 160], [160, 161]]}
{"doc_key": "ai-test-218", "ner": [[4, 4, "metrics"], [18, 18, "metrics"], [20, 22, "metrics"], [24, 26, "metrics"], [37, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 18, 18, "compare", "", false, false], [4, 4, 20, 22, "compare", "", false, false], [4, 4, 24, 26, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["An", "early", "version", "of", "VMAF", "has", "been", "shown", "to", "outperform", "other", "image", "and", "video", "quality", "metrics", "such", "as", "SSIM", ",", "PSNR", "-", "HVS", "and", "VQM", "-", "VFD", "on", "three", "out", "of", "four", "data", "sets", "in", "terms", "of", "predictive", "accuracy", "when", "compared", "to", "subjective", "ratings", "."], "sentence-detokenized": "An early version of VMAF has been shown to outperform other image and video quality metrics such as SSIM, PSNR -HVS and VQM-VFD on three out of four data sets in terms of predictive accuracy when compared to subjective ratings.", "token2charspan": [[0, 2], [3, 8], [9, 16], [17, 19], [20, 24], [25, 28], [29, 33], [34, 39], [40, 42], [43, 53], [54, 59], [60, 65], [66, 69], [70, 75], [76, 83], [84, 91], [92, 96], [97, 99], [100, 104], [104, 105], [106, 110], [111, 112], [112, 115], [116, 119], [120, 123], [123, 124], [124, 127], [128, 130], [131, 136], [137, 140], [141, 143], [144, 148], [149, 153], [154, 158], [159, 161], [162, 167], [168, 170], [171, 181], [182, 190], [191, 195], [196, 204], [205, 207], [208, 218], [219, 226], [226, 227]]}
{"doc_key": "ai-test-219", "ner": [[18, 23, "task"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 23, 25, 26, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "example", ",", "the", "ambiguity", "of", "\"", "mouse", "\"", "(", "animal", "or", "device", ")", "is", "not", "relevant", "for", "machine", "translation", ",", "but", "it", "is", "for", "information", "retrieval", "."], "sentence-detokenized": "For example, the ambiguity of \"mouse\" (animal or device) is not relevant for machine translation, but it is for information retrieval.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 26], [27, 29], [30, 31], [31, 36], [36, 37], [38, 39], [39, 45], [46, 48], [49, 55], [55, 56], [57, 59], [60, 63], [64, 72], [73, 76], [77, 84], [85, 96], [96, 97], [98, 101], [102, 104], [105, 107], [108, 111], [112, 123], [124, 133], [133, 134]]}
{"doc_key": "ai-test-220", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [9, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 1, "usage", "", false, false], [9, 10, 6, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Geometric", "hashing", "was", "originally", "proposed", "in", "computer", "vision", "for", "object", "recognition", "in", "2D", "and", "3D", ","], "sentence-detokenized": "Geometric hashing was originally proposed in computer vision for object recognition in 2D and 3D,", "token2charspan": [[0, 9], [10, 17], [18, 21], [22, 32], [33, 41], [42, 44], [45, 53], [54, 60], [61, 64], [65, 71], [72, 83], [84, 86], [87, 89], [90, 93], [94, 96], [96, 97]]}
{"doc_key": "ai-test-221", "ner": [[9, 10, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 15, 9, 10, "part-of", "subfield", false, false], [17, 18, 9, 10, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "forms", "one", "of", "the", "three", "main", "categories", "of", "machine", "learning", ",", "along", "with", "supervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "It forms one of the three main categories of machine learning, along with supervised learning and reinforcement learning.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 15], [16, 19], [20, 25], [26, 30], [31, 41], [42, 44], [45, 52], [53, 61], [61, 62], [63, 68], [69, 73], [74, 84], [85, 93], [94, 97], [98, 111], [112, 120], [120, 121]]}
{"doc_key": "ai-test-222", "ner": [[0, 2, "field"], [17, 18, "field"], [20, 21, "field"], [23, 24, "field"], [26, 29, "field"], [31, 32, "field"], [34, 35, "field"], [37, 37, "field"], [39, 40, "algorithm"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[0, 2, 17, 18, "part-of", "subfield", false, false], [0, 2, 20, 21, "part-of", "subfield", false, false], [0, 2, 23, 24, "part-of", "subfield", false, false], [0, 2, 26, 29, "part-of", "subfield", false, false], [0, 2, 31, 32, "part-of", "subfield", false, false], [0, 2, 34, 35, "part-of", "subfield", false, false], [0, 2, 37, 37, "part-of", "subfield", false, false], [0, 2, 39, 40, "part-of", "subfield", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Reinforcement", "learning", "is", "studied", "in", "many", "other", "disciplines", "due", "to", "its", "generality", ",", "e.g.", "in", "game", "and", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimisation", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Reinforcement learning is studied in many other disciplines due to its generality, e.g. in game and control theory, operations research, information theory, simulation-based optimisation, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 13], [14, 22], [23, 25], [26, 33], [34, 36], [37, 41], [42, 47], [48, 59], [60, 63], [64, 66], [67, 70], [71, 81], [81, 82], [83, 87], [88, 90], [91, 95], [96, 99], [100, 107], [108, 114], [114, 115], [116, 126], [127, 135], [135, 136], [137, 148], [149, 155], [155, 156], [157, 167], [167, 168], [168, 173], [174, 186], [186, 187], [188, 199], [200, 207], [207, 208], [209, 214], [215, 227], [227, 228], [229, 239], [240, 243], [244, 251], [252, 262], [262, 263]]}
{"doc_key": "ai-test-223", "ner": [[0, 1, "field"], [6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "related-to", "", false, false], [0, 1, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pattern", "recognition", "is", "closely", "related", "to", "artificial", "intelligence", "and", "machine", "learning", ","], "sentence-detokenized": "Pattern recognition is closely related to artificial intelligence and machine learning,", "token2charspan": [[0, 7], [8, 19], [20, 22], [23, 30], [31, 38], [39, 41], [42, 52], [53, 65], [66, 69], [70, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-224", "ner": [[10, 11, "algorithm"], [14, 14, "field"], [16, 17, "field"], [27, 28, "task"], [30, 30, "task"], [32, 33, "task"], [35, 36, "algorithm"], [38, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 11, 14, 14, "related-to", "", false, false], [10, 11, 16, 17, "related-to", "", false, false], [27, 28, 10, 11, "usage", "", true, false], [30, 30, 10, 11, "usage", "", true, false], [32, 33, 10, 11, "usage", "", true, false], [35, 36, 10, 11, "usage", "", true, false], [38, 40, 10, 11, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "software", "is", "used", "to", "design", ",", "train", "and", "deploy", "neural", "network", "models", "(", "supervised", "and", "unsupervised", "learning", ")", "to", "perform", "a", "variety", "of", "tasks", "such", "as", "data", "mining", ",", "classification", ",", "function", "approximation", ",", "multivariate", "regression", "and", "time", "series", "prediction", "."], "sentence-detokenized": "The software is used to design, train and deploy neural network models (supervised and unsupervised learning) to perform a variety of tasks such as data mining, classification, function approximation, multivariate regression and time series prediction.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 20], [21, 23], [24, 30], [30, 31], [32, 37], [38, 41], [42, 48], [49, 55], [56, 63], [64, 70], [71, 72], [72, 82], [83, 86], [87, 99], [100, 108], [108, 109], [110, 112], [113, 120], [121, 122], [123, 130], [131, 133], [134, 139], [140, 144], [145, 147], [148, 152], [153, 159], [159, 160], [161, 175], [175, 176], [177, 185], [186, 199], [199, 200], [201, 213], [214, 224], [225, 228], [229, 233], [234, 240], [241, 251], [251, 252]]}
{"doc_key": "ai-test-225", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2016", ",", "he", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2016, he was elected a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [98, 99]]}
{"doc_key": "ai-test-226", "ner": [[6, 9, "organisation"], [16, 21, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["She", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", "(", "since", "2005", ")", "and", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "(", "since", "2009", ")", ","], "sentence-detokenized": "She is a member of the National Academy of Sciences (since 2005) and the American Academy of Arts and Sciences (since 2009),", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 15], [16, 18], [19, 22], [23, 31], [32, 39], [40, 42], [43, 51], [52, 53], [53, 58], [59, 63], [63, 64], [65, 68], [69, 72], [73, 81], [82, 89], [90, 92], [93, 97], [98, 101], [102, 110], [111, 112], [112, 117], [118, 122], [122, 123], [123, 124]]}
{"doc_key": "ai-test-227", "ner": [[3, 5, "misc"], [24, 24, "country"], [26, 26, "country"], [20, 23, "misc"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["During", "the", "1973", "Yom", "Kippur", "War", ",", "Soviet", "-supplied", "surface", "-", "to", "-", "air", "missile", "batteries", "inflicted", "heavy", "damage", "on", "Israeli", "fighter", "aircraft", "in", "Egypt", "and", "Syria", "."], "sentence-detokenized": "During the 1973 Yom Kippur War, Soviet-supplied surface-to-air missile batteries inflicted heavy damage on Israeli fighter aircraft in Egypt and Syria.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 26], [27, 30], [30, 31], [32, 38], [38, 47], [48, 55], [55, 56], [56, 58], [58, 59], [59, 62], [63, 70], [71, 80], [81, 90], [91, 96], [97, 103], [104, 106], [107, 114], [115, 122], [123, 131], [132, 134], [135, 140], [141, 144], [145, 150], [150, 151]]}
{"doc_key": "ai-test-228", "ner": [[10, 11, "product"], [15, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 16, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Another", "(", "free", ",", "but", "copyrighted", ")", "resource", "is", "the", "HTK", "book", "(", "and", "its", "HTK", "toolkit", ")", "."], "sentence-detokenized": "Another (free, but copyrighted) resource is the HTK book (and its HTK toolkit).", "token2charspan": [[0, 7], [8, 9], [9, 13], [13, 14], [15, 18], [19, 30], [30, 31], [32, 40], [41, 43], [44, 47], [48, 51], [52, 56], [57, 58], [58, 61], [62, 65], [66, 69], [70, 77], [77, 78], [78, 79]]}
{"doc_key": "ai-test-229", "ner": [[9, 9, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "were", "taken", "up", "at", "the", "AAAI", "Spring", "Symposium", "2004", ",", "where", "linguists", ",", "computer", "scientists", "and", "other", "interested", "researchers", "for", "the", "first", "time", "aligned", "their", "interests", "and", "proposed", "common", "tasks", "and", "benchmark", "datasets", "for", "the", "systematic", "computational", "study", "of", "affect", ",", "appeal", ",", "subjectivity", "and", "mood", "in", "texts", "."], "sentence-detokenized": "- were taken up at the AAAI Spring Symposium 2004, where linguists, computer scientists and other interested researchers for the first time aligned their interests and proposed common tasks and benchmark datasets for the systematic computational study of affect, appeal, subjectivity and mood in texts.", "token2charspan": [[0, 1], [2, 6], [7, 12], [13, 15], [16, 18], [19, 22], [23, 27], [28, 34], [35, 44], [45, 49], [49, 50], [51, 56], [57, 66], [66, 67], [68, 76], [77, 87], [88, 91], [92, 97], [98, 108], [109, 120], [121, 124], [125, 128], [129, 134], [135, 139], [140, 147], [148, 153], [154, 163], [164, 167], [168, 176], [177, 183], [184, 189], [190, 193], [194, 203], [204, 212], [213, 216], [217, 220], [221, 231], [232, 245], [246, 251], [252, 254], [255, 261], [261, 262], [263, 269], [269, 270], [271, 283], [284, 287], [288, 292], [293, 295], [296, 301], [301, 302]]}
{"doc_key": "ai-test-230", "ner": [[9, 9, "task"], [14, 15, "task"], [17, 19, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "single", "grid", "can", "be", "analysed", "both", "substantively", "(", "eyeballing", ")", "and", "structurally", "(", "cluster", "analysis", ",", "principal", "component", "analysis", "and", "a", "range", "of", "structural", "indices", "relating", "to", "the", "complexity", "and", "scale", "of", "the", "assessments", "are", "the", "main", "techniques", "used", ")", "."], "sentence-detokenized": "A single grid can be analysed both substantively (eyeballing) and structurally (cluster analysis, principal component analysis and a range of structural indices relating to the complexity and scale of the assessments are the main techniques used).", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 17], [18, 20], [21, 29], [30, 34], [35, 48], [49, 50], [50, 60], [60, 61], [62, 65], [66, 78], [79, 80], [80, 87], [88, 96], [96, 97], [98, 107], [108, 117], [118, 126], [127, 130], [131, 132], [133, 138], [139, 141], [142, 152], [153, 160], [161, 169], [170, 172], [173, 176], [177, 187], [188, 191], [192, 197], [198, 200], [201, 204], [205, 216], [217, 220], [221, 224], [225, 229], [230, 240], [241, 245], [245, 246], [246, 247]]}
{"doc_key": "ai-test-231", "ner": [[3, 6, "organisation"], [10, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2018", ",", "Toyota", "was", "seen", "as", "lagging", "behind", "in", "self", "-", "driving", "cars", "and", "in", "need", "of", "innovation", "."], "sentence-detokenized": "In 2018, Toyota was seen as lagging behind in self-driving cars and in need of innovation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 24], [25, 27], [28, 35], [36, 42], [43, 45], [46, 50], [50, 51], [51, 58], [59, 63], [64, 67], [68, 70], [71, 75], [76, 78], [79, 89], [89, 90]]}
{"doc_key": "ai-test-232", "ner": [[40, 41, "misc"], [43, 44, "misc"], [46, 49, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "targets", "include", "natural", "objects", "such", "as", "the", "ground", ",", "the", "sea", ",", "precipitation", "(", "such", "as", "rain", ",", "snow", "or", "hail", ")", ",", "sandstorms", ",", "animals", "(", "especially", "birds", ")", ",", "atmospheric", "turbulence", "and", "other", "atmospheric", "effects", "such", "as", "ionospheric", "reflections", ",", "meteor", "trails", "and", "three", "-", "body", "scattering", "."], "sentence-detokenized": "These targets include natural objects such as the ground, the sea, precipitation (such as rain, snow or hail), sandstorms, animals (especially birds), atmospheric turbulence and other atmospheric effects such as ionospheric reflections, meteor trails and three-body scattering.", "token2charspan": [[0, 5], [6, 13], [14, 21], [22, 29], [30, 37], [38, 42], [43, 45], [46, 49], [50, 56], [56, 57], [58, 61], [62, 65], [65, 66], [67, 80], [81, 82], [82, 86], [87, 89], [90, 94], [94, 95], [96, 100], [101, 103], [104, 108], [108, 109], [109, 110], [111, 121], [121, 122], [123, 130], [131, 132], [132, 142], [143, 148], [148, 149], [149, 150], [151, 162], [163, 173], [174, 177], [178, 183], [184, 195], [196, 203], [204, 208], [209, 211], [212, 223], [224, 235], [235, 236], [237, 243], [244, 250], [251, 254], [255, 260], [260, 261], [261, 265], [266, 276], [276, 277]]}
{"doc_key": "ai-test-233", "ner": [[17, 18, "product"], [42, 43, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "planning", "and", "control", ",", "the", "main", "difference", "between", "humanoids", "and", "other", "types", "of", "robots", "(", "e.g.", "industrial", "robots", ")", "is", "that", "the", "robot", "'s", "movement", "must", "be", "human", "-", "like", ",", "i.e.", "it", "must", "move", "on", "its", "legs", ",", "especially", "on", "two", "legs", "."], "sentence-detokenized": "In planning and control, the main difference between humanoids and other types of robots (e.g. industrial robots) is that the robot's movement must be human-like, i.e. it must move on its legs, especially on two legs.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 23], [23, 24], [25, 28], [29, 33], [34, 44], [45, 52], [53, 62], [63, 66], [67, 72], [73, 78], [79, 81], [82, 88], [89, 90], [90, 94], [95, 105], [106, 112], [112, 113], [114, 116], [117, 121], [122, 125], [126, 131], [131, 133], [134, 142], [143, 147], [148, 150], [151, 156], [156, 157], [157, 161], [161, 162], [163, 167], [168, 170], [171, 175], [176, 180], [181, 183], [184, 187], [188, 192], [192, 193], [194, 204], [205, 207], [208, 211], [212, 216], [216, 217]]}
{"doc_key": "ai-test-234", "ner": [[0, 1, "algorithm"], [9, 10, "misc"], [14, 14, "metrics"], [17, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Gradient", "descent", "may", "require", "many", "iterations", "to", "calculate", "a", "local", "minimum", "with", "the", "required", "accuracy", "if", "the", "curvature", "is", "very", "different", "in", "different", "directions", "for", "the", "given", "function", "."], "sentence-detokenized": "Gradient descent may require many iterations to calculate a local minimum with the required accuracy if the curvature is very different in different directions for the given function.", "token2charspan": [[0, 8], [9, 16], [17, 20], [21, 28], [29, 33], [34, 44], [45, 47], [48, 57], [58, 59], [60, 65], [66, 73], [74, 78], [79, 82], [83, 91], [92, 100], [101, 103], [104, 107], [108, 117], [118, 120], [121, 125], [126, 135], [136, 138], [139, 148], [149, 159], [160, 163], [164, 167], [168, 173], [174, 182], [182, 183]]}
{"doc_key": "ai-test-235", "ner": [[1, 6, "misc"], [17, 22, "conference"], [24, 24, "location"], [12, 26, "country"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[17, 22, 24, 24, "physical", "", false, true], [24, 24, 12, 26, "physical", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["The", "RoboCup", "2D", "Soccer", "Simulation", "League", "1997", "was", "the", "first", "RoboCup", "competition", "held", "in", "conjunction", "with", "the", "International", "Joint", "Conference", "on", "Artificial", "Intelligence", "in", "Nagoya", ",", "Japan", ",", "23", "-", "29", "August", "1997", "."], "sentence-detokenized": "The RoboCup 2D Soccer Simulation League 1997 was the first RoboCup competition held in conjunction with the International Joint Conference on Artificial Intelligence in Nagoya, Japan, 23-29 August 1997.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 21], [22, 32], [33, 39], [40, 44], [45, 48], [49, 52], [53, 58], [59, 66], [67, 78], [79, 83], [84, 86], [87, 98], [99, 103], [104, 107], [108, 121], [122, 127], [128, 138], [139, 141], [142, 152], [153, 165], [166, 168], [169, 175], [175, 176], [177, 182], [182, 183], [184, 186], [186, 187], [187, 189], [190, 196], [197, 201], [201, 202]]}
{"doc_key": "ai-test-236", "ner": [[17, 17, "product"]], "ner_mapping_to_source": [2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "options", "include", "an", "embedded", "Python", "environment", "and", "R", "console", ",", "as", "well", "as", "support", "for", "Rserve", "."], "sentence-detokenized": "Other programming options include an embedded Python environment and R console, as well as support for Rserve.", "token2charspan": [[0, 5], [6, 17], [18, 25], [26, 33], [34, 36], [37, 45], [46, 52], [53, 64], [65, 68], [69, 70], [71, 78], [78, 79], [80, 82], [83, 87], [88, 90], [91, 98], [99, 102], [103, 109], [109, 110]]}
{"doc_key": "ai-test-237", "ner": [[1, 1, "location"], [8, 9, "field"], [11, 11, "field"], [14, 15, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [33, 39, "field"], [38, 38, "field"], [42, 43, "field"], [48, 50, "field"], [56, 59, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[14, 15, 11, 11, "related-to", "contributes_to_field", true, false], [17, 18, 11, 11, "related-to", "contributes_to_field", true, false], [20, 21, 11, 11, "related-to", "contributes_to_field", true, false], [42, 43, 38, 38, "part-of", "", false, false], [48, 50, 42, 43, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["From", "Bonn", ",", "he", "made", "fundamental", "contributions", "to", "artificial", "intelligence", "and", "robotics", "(", "with", "Wolfram", "Burgard", ",", "Dieter", "Fox", ",", "Sebastian", "Thrun", ",", "among", "others", ")", "as", "well", "as", "to", "the", "development", "of", "software", "engineering", ",", "especially", "in", "civil", "engineering", ",", "and", "information", "systems", ",", "especially", "in", "the", "geosciences", ".", "In", "2016", "he", "was", "awarded", "the", "AAAI", "Classic", "Paper", "Award.2014", "."], "sentence-detokenized": "From Bonn, he made fundamental contributions to artificial intelligence and robotics (with Wolfram Burgard, Dieter Fox, Sebastian Thrun, among others) as well as to the development of software engineering, especially in civil engineering, and information systems, especially in the geosciences. In 2016 he was awarded the AAAI Classic Paper Award.2014.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 13], [14, 18], [19, 30], [31, 44], [45, 47], [48, 58], [59, 71], [72, 75], [76, 84], [85, 86], [86, 90], [91, 98], [99, 106], [106, 107], [108, 114], [115, 118], [118, 119], [120, 129], [130, 135], [135, 136], [137, 142], [143, 149], [149, 150], [151, 153], [154, 158], [159, 161], [162, 164], [165, 168], [169, 180], [181, 183], [184, 192], [193, 204], [204, 205], [206, 216], [217, 219], [220, 225], [226, 237], [237, 238], [239, 242], [243, 254], [255, 262], [262, 263], [264, 274], [275, 277], [278, 281], [282, 293], [293, 294], [295, 297], [298, 302], [303, 305], [306, 309], [310, 317], [318, 321], [322, 326], [327, 334], [335, 340], [341, 351], [351, 352]]}
{"doc_key": "ai-test-238", "ner": [[2, 7, "conference"], [18, 19, "location"], [21, 21, "location"], [23, 23, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 7, 18, 19, "physical", "", false, false], [18, 19, 21, 21, "physical", "", false, false], [21, 21, 23, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "first", "USA", "edition", "of", "the", "Campus", "Party", "will", "take", "place", "from", "20", "to", "22", "August", "at", "the", "TCF", "Center", "in", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "The first USA edition of the Campus Party will take place from 20 to 22 August at the TCF Center in Detroit, Michigan.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 21], [22, 24], [25, 28], [29, 35], [36, 41], [42, 46], [47, 51], [52, 57], [58, 62], [63, 65], [66, 68], [69, 71], [72, 78], [79, 81], [82, 85], [86, 89], [90, 96], [97, 99], [100, 107], [107, 108], [109, 117], [117, 118]]}
{"doc_key": "ai-test-239", "ner": [[2, 4, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [12, 13, "misc"], [22, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 12, 13, "win-defeat", "", false, false], [5, 6, 12, 13, "win-defeat", "", false, false], [8, 8, 12, 13, "win-defeat", "", false, false], [12, 13, 22, 25, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Together", "with", "Yann", "LeCun", "and", "Yoshua", "Bengio", ",", "Hinton", "received", "the", "2018", "Turing", "Award", "for", "conceptual", "and", "technical", "breakthroughs", "that", "have", "made", "deep", "neural", "networks", "a", "critical", "component", "of", "data", "processing", "."], "sentence-detokenized": "Together with Yann LeCun and Yoshua Bengio, Hinton received the 2018 Turing Award for conceptual and technical breakthroughs that have made deep neural networks a critical component of data processing.", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 24], [25, 28], [29, 35], [36, 42], [42, 43], [44, 50], [51, 59], [60, 63], [64, 68], [69, 75], [76, 81], [82, 85], [86, 96], [97, 100], [101, 110], [111, 124], [125, 129], [130, 134], [135, 139], [140, 144], [145, 151], [152, 160], [161, 162], [163, 171], [172, 181], [182, 184], [185, 189], [190, 200], [200, 201]]}
{"doc_key": "ai-test-240", "ner": [[0, 3, "product"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 10, 10, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Euler", "Math", "Toolbox", "uses", "a", "matrix", "language", "similar", "to", "MATLAB", ",", "a", "system", "developed", "since", "the", "1970s", "."], "sentence-detokenized": "The Euler Math Toolbox uses a matrix language similar to MATLAB, a system developed since the 1970s.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 22], [23, 27], [28, 29], [30, 36], [37, 45], [46, 53], [54, 56], [57, 63], [63, 64], [65, 66], [67, 73], [74, 83], [84, 89], [90, 93], [94, 99], [99, 100]]}
{"doc_key": "ai-test-241", "ner": [[11, 11, "programlang"], [13, 14, "programlang"], [16, 16, "programlang"], [18, 18, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "languages", "make", "this", "possible", "in", "a", "portable", "way", "(", "e.g.", "Scheme", ",", "Common", "Lisp", ",", "Perl", "or", "D", ")", "."], "sentence-detokenized": "Some languages make this possible in a portable way (e.g. Scheme, Common Lisp, Perl or D).", "token2charspan": [[0, 4], [5, 14], [15, 19], [20, 24], [25, 33], [34, 36], [37, 38], [39, 47], [48, 51], [52, 53], [53, 57], [58, 64], [64, 65], [66, 72], [73, 77], [77, 78], [79, 83], [84, 86], [87, 88], [88, 89], [89, 90]]}
{"doc_key": "ai-test-242", "ner": [[8, 8, "misc"], [10, 11, "researcher"], [13, 17, "researcher"], [31, 32, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 10, 11, "artifact", "", false, false], [8, 8, 13, 17, "artifact", "", false, false], [8, 8, 31, 32, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1969", ",", "in", "a", "famous", "book", "entitled", "Perceptrons", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", ",", "it", "was", "shown", "that", "it", "is", "impossible", "for", "these", "classes", "of", "networks", "to", "learn", "an", "XOR", "function", "."], "sentence-detokenized": "In 1969, in a famous book entitled Perceptrons by Marvin Minsky and Seymour Papert, it was shown that it is impossible for these classes of networks to learn an XOR function.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 13], [14, 20], [21, 25], [26, 34], [35, 46], [47, 49], [50, 56], [57, 63], [64, 67], [68, 75], [76, 82], [82, 83], [84, 86], [87, 90], [91, 96], [97, 101], [102, 104], [105, 107], [108, 118], [119, 122], [123, 128], [129, 136], [137, 139], [140, 148], [149, 151], [152, 157], [158, 160], [161, 164], [165, 173], [173, 174]]}
{"doc_key": "ai-test-243", "ner": [[33, 37, "misc"], [41, 41, "product"], [5, 8, "organisation"], [12, 17, "organisation"], [20, 25, "location"], [27, 27, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 8, 41, 41, "usage", "", false, false], [5, 8, 20, 25, "physical", "", false, false], [12, 17, 5, 8, "named", "", false, false], [20, 25, 27, 27, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Under", "the", "auspices", "of", "the", "USAF", "Foreign", "Technology", "Division", "(", "later", "the", "National", "Air", "and", "Space", "Intelligence", "Center", ")", "at", "Wright", "-", "Patterson", "Air", "Force", "Base", ",", "Ohio", ",", "a", "large", "number", "of", "Russian", "scientific", "and", "technical", "documents", "were", "translated", "using", "SYSTRAN", "."], "sentence-detokenized": "Under the auspices of the USAF Foreign Technology Division (later the National Air and Space Intelligence Center) at Wright-Patterson Air Force Base, Ohio, a large number of Russian scientific and technical documents were translated using SYSTRAN.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 21], [22, 25], [26, 30], [31, 38], [39, 49], [50, 58], [59, 60], [60, 65], [66, 69], [70, 78], [79, 82], [83, 86], [87, 92], [93, 105], [106, 112], [112, 113], [114, 116], [117, 123], [123, 124], [124, 133], [134, 137], [138, 143], [144, 148], [148, 149], [150, 154], [154, 155], [156, 157], [158, 163], [164, 170], [171, 173], [174, 181], [182, 192], [193, 196], [197, 206], [207, 216], [217, 221], [222, 232], [233, 238], [239, 246], [246, 247]]}
{"doc_key": "ai-test-244", "ner": [[0, 1, "field"], [4, 5, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Semi-supervised", "learning", "lies", "between", "unsupervised", "learning", "(", "without", "labelled", "training", "data", ")", "and", "supervised", "learning", "(", "with", "fully", "labelled", "training", "data", ")", "."], "sentence-detokenized": "Semi-supervised learning lies between unsupervised learning (without labelled training data) and supervised learning (with fully labelled training data).", "token2charspan": [[0, 15], [16, 24], [25, 29], [30, 37], [38, 50], [51, 59], [60, 61], [61, 68], [69, 77], [78, 86], [87, 91], [91, 92], [93, 96], [97, 107], [108, 116], [117, 118], [118, 122], [123, 128], [129, 137], [138, 146], [147, 151], [151, 152], [152, 153]]}
{"doc_key": "ai-test-245", "ner": [[0, 3, "algorithm"], [8, 10, "algorithm"], [25, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 8, 10, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Ann", "Gram", "model", "is", "a", "kind", "of", "probabilistic", "language", "model", "for", "predicting", "the", "next", "element", "in", "such", "a", "sequence", "in", "the", "form", "of", "a", "Markov", "model", "(", "n", "-", "1", ")", "-", "efficient", "order", "."], "sentence-detokenized": "The Ann Gram model is a kind of probabilistic language model for predicting the next element in such a sequence in the form of a Markov model (n - 1) - efficient order.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 18], [19, 21], [22, 23], [24, 28], [29, 31], [32, 45], [46, 54], [55, 60], [61, 64], [65, 75], [76, 79], [80, 84], [85, 92], [93, 95], [96, 100], [101, 102], [103, 111], [112, 114], [115, 118], [119, 123], [124, 126], [127, 128], [129, 135], [136, 141], [142, 143], [143, 144], [145, 146], [147, 148], [148, 149], [150, 151], [152, 161], [162, 167], [167, 168]]}
{"doc_key": "ai-test-246", "ner": [[1, 3, "organisation"], [5, 6, "product"], [9, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 3, 5, 6, "usage", "", false, false], [9, 15, 1, 3, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Cleveland", "Clinic", "has", "used", "Cyc", "to", "develop", "a", "natural", "language", "query", "interface", "for", "biomedical", "information", "that", "includes", "decades", "of", "cardiothoracic", "surgery", "information", "."], "sentence-detokenized": "The Cleveland Clinic has used Cyc to develop a natural language query interface for biomedical information that includes decades of cardiothoracic surgery information.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 24], [25, 29], [30, 33], [34, 36], [37, 44], [45, 46], [47, 54], [55, 63], [64, 69], [70, 79], [80, 83], [84, 94], [95, 106], [107, 111], [112, 120], [121, 128], [129, 131], [132, 146], [147, 154], [155, 166], [166, 167]]}
{"doc_key": "ai-test-247", "ner": [[6, 7, "country"], [9, 10, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 9, 10, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "incident", "strained", "relations", "between", "the", "United", "States", "and", "Japan", "and", "led", "to", "the", "arrest", "and", "prosecution", "of", "two", "executives", "and", "the", "imposition", "of", "sanctions", "on", "the", "company", "by", "both", "countries", "."], "sentence-detokenized": "The incident strained relations between the United States and Japan and led to the arrest and prosecution of two executives and the imposition of sanctions on the company by both countries.", "token2charspan": [[0, 3], [4, 12], [13, 21], [22, 31], [32, 39], [40, 43], [44, 50], [51, 57], [58, 61], [62, 67], [68, 71], [72, 75], [76, 78], [79, 82], [83, 89], [90, 93], [94, 105], [106, 108], [109, 112], [113, 123], [124, 127], [128, 131], [132, 142], [143, 145], [146, 155], [156, 158], [159, 162], [163, 170], [171, 173], [174, 178], [179, 188], [188, 189]]}
{"doc_key": "ai-test-248", "ner": [[7, 9, "algorithm"], [4, 13, "field"], [22, 22, "misc"], [35, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 9, 4, 13, "type-of", "", false, false], [22, 22, 4, 13, "part-of", "", true, false], [35, 35, 4, 13, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["If", "the", "modelling", "is", "done", "by", "an", "artificial", "neural", "network", "or", "other", "machine", "learning", ",", "the", "optimisation", "of", "the", "parameters", "is", "called", "training", ",", "while", "the", "optimisation", "of", "the", "hyperparameters", "of", "the", "model", "is", "called", "tuning", "and", "cross-validation", "is", "often", "used", "."], "sentence-detokenized": "If the modelling is done by an artificial neural network or other machine learning, the optimisation of the parameters is called training, while the optimisation of the hyperparameters of the model is called tuning and cross-validation is often used.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 24], [25, 27], [28, 30], [31, 41], [42, 48], [49, 56], [57, 59], [60, 65], [66, 73], [74, 82], [82, 83], [84, 87], [88, 100], [101, 103], [104, 107], [108, 118], [119, 121], [122, 128], [129, 137], [137, 138], [139, 144], [145, 148], [149, 161], [162, 164], [165, 168], [169, 184], [185, 187], [188, 191], [192, 197], [198, 200], [201, 207], [208, 214], [215, 218], [219, 235], [236, 238], [239, 244], [245, 249], [249, 250]]}
{"doc_key": "ai-test-249", "ner": [[11, 11, "country"], [13, 13, "country"], [15, 17, "country"], [24, 25, "organisation"], [20, 20, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[24, 25, 20, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Localised", "versions", "of", "the", "site", ",", "which", "were", "available", "in", "the", "UK", ",", "India", "and", "Australia", ",", "were", "discontinued", "following", "Fandango", "'s", "acquisition", "of", "Rotten", "Tomatoes", "."], "sentence-detokenized": "Localised versions of the site, which were available in the UK, India and Australia, were discontinued following Fandango's acquisition of Rotten Tomatoes.", "token2charspan": [[0, 9], [10, 18], [19, 21], [22, 25], [26, 30], [30, 31], [32, 37], [38, 42], [43, 52], [53, 55], [56, 59], [60, 62], [62, 63], [64, 69], [70, 73], [74, 83], [83, 84], [85, 89], [90, 102], [103, 112], [113, 121], [121, 123], [124, 135], [136, 138], [139, 145], [146, 154], [154, 155]]}
{"doc_key": "ai-test-250", "ner": [[11, 12, "metrics"], [22, 23, "task"]], "ner_mapping_to_source": [1, 2], "relations": [[11, 12, 22, 23, "related-to", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["The", "NER", "model", "is", "one", "of", "several", "methods", "for", "determining", "the", "accuracy", "of", "live", "subtitles", "for", "television", "programmes", "and", "events", "produced", "using", "speech", "recognition", "."], "sentence-detokenized": "The NER model is one of several methods for determining the accuracy of live subtitles for television programmes and events produced using speech recognition.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 20], [21, 23], [24, 31], [32, 39], [40, 43], [44, 55], [56, 59], [60, 68], [69, 71], [72, 76], [77, 86], [87, 90], [91, 101], [102, 112], [113, 116], [117, 123], [124, 132], [133, 138], [139, 145], [146, 157], [157, 158]]}
{"doc_key": "ai-test-251", "ner": [[0, 0, "researcher"], [4, 5, "university"], [8, 9, "university"], [11, 13, "location"], [14, 18, "university"], [21, 22, "university"], [24, 24, "location"], [28, 33, "university"], [35, 37, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 5, "physical", "", false, false], [0, 0, 4, 5, "role", "", false, false], [0, 0, 8, 9, "physical", "", false, false], [0, 0, 8, 9, "role", "", false, false], [0, 0, 14, 18, "physical", "", false, false], [0, 0, 14, 18, "role", "", false, false], [0, 0, 21, 22, "physical", "", false, false], [0, 0, 21, 22, "role", "", false, false], [0, 0, 28, 33, "physical", "", false, false], [0, 0, 28, 33, "role", "", false, false], [8, 9, 11, 13, "physical", "", false, false], [14, 18, 24, 24, "physical", "", false, false], [21, 22, 24, 24, "physical", "", false, false], [28, 33, 35, 37, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Atran", "has", "taught", "at", "Cambridge", "University", ",", "the", "Hebrew", "University", "in", "Jerusalem", ",", "the", "\u00c9cole", "pratique", "des", "hautes", "\u00e9tudes", "and", "the", "\u00c9cole", "Polytechnique", "in", "Paris", ",", "and", "the", "John", "Jay", "College", "of", "Criminal", "Justice", "in", "New", "York", "City", "."], "sentence-detokenized": "Atran has taught at Cambridge University, the Hebrew University in Jerusalem, the \u00c9cole pratique des hautes \u00e9tudes and the \u00c9cole Polytechnique in Paris, and the John Jay College of Criminal Justice in New York City.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 40], [40, 41], [42, 45], [46, 52], [53, 63], [64, 66], [67, 76], [76, 77], [78, 81], [82, 87], [88, 96], [97, 100], [101, 107], [108, 114], [115, 118], [119, 122], [123, 128], [129, 142], [143, 145], [146, 151], [151, 152], [153, 156], [157, 160], [161, 165], [166, 169], [170, 177], [178, 180], [181, 189], [190, 197], [198, 200], [201, 204], [205, 209], [210, 214], [214, 215]]}
{"doc_key": "ai-test-252", "ner": [[0, 0, "product"], [6, 9, "task"], [12, 13, "researcher"], [15, 16, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 9, "origin", "", false, false], [0, 0, 6, 9, "related-to", "", false, false], [6, 9, 15, 16, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "was", "an", "early", "computer", "programme", "for", "natural", "language", "understanding", "developed", "by", "Terry", "Winograd", "at", "MIT", "in", "1968", "-", "1970", "."], "sentence-detokenized": "SHRDLU was an early computer programme for natural language understanding developed by Terry Winograd at MIT in 1968-1970.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 19], [20, 28], [29, 38], [39, 42], [43, 50], [51, 59], [60, 73], [74, 83], [84, 86], [87, 92], [93, 101], [102, 104], [105, 108], [109, 111], [112, 116], [116, 117], [117, 121], [121, 122]]}
{"doc_key": "ai-test-253", "ner": [[3, 3, "misc"], [5, 7, "field"], [11, 15, "university"], [17, 17, "location"], [19, 19, "country"], [26, 27, "university"], [30, 30, "misc"], [32, 35, "field"], [37, 38, "university"], [43, 44, "misc"], [45, 45, "field"], [52, 53, "misc"], [57, 61, "university"], [66, 67, "field"], [71, 72, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[3, 3, 5, 7, "topic", "", false, false], [3, 3, 11, 15, "origin", "", false, false], [11, 15, 17, 17, "physical", "", false, false], [11, 15, 26, 27, "role", "affiliated_with", false, false], [17, 17, 19, 19, "physical", "", false, false], [30, 30, 32, 35, "topic", "", false, false], [30, 30, 37, 38, "origin", "", false, false], [43, 44, 45, 45, "topic", "", false, false], [52, 53, 57, 61, "origin", "", false, false], [52, 53, 66, 67, "topic", "", false, false], [71, 72, 57, 61, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["He", "earned", "a", "B.E.", "in", "electrical", "engineering", "in", "1982", "from", "the", "B.M.S", ".", "College", "of", "Engineering", "in", "Bangalore", ",", "India", ",", "which", "was", "then", "affiliated", "with", "Bangalore", "University", ",", "an", "M.S.", "in", "electrical", "and", "computer", "engineering", "from", "Drexel", "University", "in", "1984", "and", "an", "M.S.", "in", "computer", "science", "in", "1989", ",", "and", "a", "Ph.D.", "in", "1990", "from", "the", "University", "of", "Wisconsin", "-", "Madison", ",", "where", "he", "studied", "artificial", "intelligence", "and", "worked", "with", "Leonard", "Uhr", "."], "sentence-detokenized": "He earned a B.E. in electrical engineering in 1982 from the B.M.S. College of Engineering in Bangalore, India, which was then affiliated with Bangalore University, an M.S. in electrical and computer engineering from Drexel University in 1984 and an M.S. in computer science in 1989, and a Ph.D. in 1990 from the University of Wisconsin-Madison, where he studied artificial intelligence and worked with Leonard Uhr.", "token2charspan": [[0, 2], [3, 9], [10, 11], [12, 16], [17, 19], [20, 30], [31, 42], [43, 45], [46, 50], [51, 55], [56, 59], [60, 65], [65, 66], [67, 74], [75, 77], [78, 89], [90, 92], [93, 102], [102, 103], [104, 109], [109, 110], [111, 116], [117, 120], [121, 125], [126, 136], [137, 141], [142, 151], [152, 162], [162, 163], [164, 166], [167, 171], [172, 174], [175, 185], [186, 189], [190, 198], [199, 210], [211, 215], [216, 222], [223, 233], [234, 236], [237, 241], [242, 245], [246, 248], [249, 253], [254, 256], [257, 265], [266, 273], [274, 276], [277, 281], [281, 282], [283, 286], [287, 288], [289, 294], [295, 297], [298, 302], [303, 307], [308, 311], [312, 322], [323, 325], [326, 335], [335, 336], [336, 343], [343, 344], [345, 350], [351, 353], [354, 361], [362, 372], [373, 385], [386, 389], [390, 396], [397, 401], [402, 409], [410, 413], [413, 414]]}
{"doc_key": "ai-test-254", "ner": [[6, 8, "metrics"], [10, 10, "metrics"], [19, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Accuracy", "is", "usually", "assessed", "with", "the", "word", "error", "rate", "(", "WER", ")", ",", "while", "speed", "is", "measured", "with", "the", "real", "-", "time", "factor", "."], "sentence-detokenized": "Accuracy is usually assessed with the word error rate (WER), while speed is measured with the real-time factor.", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 28], [29, 33], [34, 37], [38, 42], [43, 48], [49, 53], [54, 55], [55, 58], [58, 59], [59, 60], [61, 66], [67, 72], [73, 75], [76, 84], [85, 89], [90, 93], [94, 98], [98, 99], [99, 103], [104, 110], [110, 111]]}
{"doc_key": "ai-test-255", "ner": [[3, 4, "researcher"], [8, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 8, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1971", ",", "Terry", "Winograd", "developed", "an", "early", "natural", "language", "processing", "machine", "that", "was", "able", "to", "interpret", "naturally", "written", "commands", "in", "a", "simple", ",", "rule", "-", "driven", "environment", "."], "sentence-detokenized": "In 1971, Terry Winograd developed an early natural language processing machine that was able to interpret naturally written commands in a simple, rule-driven environment.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 33], [34, 36], [37, 42], [43, 50], [51, 59], [60, 70], [71, 78], [79, 83], [84, 87], [88, 92], [93, 95], [96, 105], [106, 115], [116, 123], [124, 132], [133, 135], [136, 137], [138, 144], [144, 145], [146, 150], [150, 151], [151, 157], [158, 169], [169, 170]]}
{"doc_key": "ai-test-256", "ner": [[4, 5, "field"], [7, 8, "researcher"], [10, 13, "researcher"], [15, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 7, 8, "related-to", "", false, false], [4, 5, 10, 13, "related-to", "", false, false], [4, 5, 15, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "field", "of", "artificial", "intelligence", ",", "Marvin", "Minsky", ",", "Herbert", "A", ".", "Simon", "and", "Allen", "Newell", "are", "worthy", "of", "mention", "."], "sentence-detokenized": "In the field of artificial intelligence, Marvin Minsky, Herbert A. Simon and Allen Newell are worthy of mention.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 26], [27, 39], [39, 40], [41, 47], [48, 54], [54, 55], [56, 63], [64, 65], [65, 66], [67, 72], [73, 76], [77, 82], [83, 89], [90, 93], [94, 100], [101, 103], [104, 111], [111, 112]]}
{"doc_key": "ai-test-257", "ner": [[31, 31, "field"], [33, 34, "field"], [37, 39, "field"], [47, 50, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[31, 31, 37, 39, "compare", "", false, false], [33, 34, 37, 39, "compare", "", false, false], [37, 39, 47, 50, "topic", "", false, false]], "relations_mapping_to_source": [2, 5, 8], "sentence": ["In", "the", "second", "half", "of", "the", "20th", "century", ",", "electrical", "engineering", "itself", "divided", "into", "several", "disciplines", "specialising", "in", "the", "design", "and", "analysis", "of", "systems", "that", "process", "physical", "signals", ",", "such", "as", "electrical", "and", "computer", "engineering", ",", "while", "design", "engineering", "developed", ",", "concerned", "with", "the", "functional", "design", "of", "user", "-", "machine", "interfaces", "."], "sentence-detokenized": "In the second half of the 20th century, electrical engineering itself divided into several disciplines specialising in the design and analysis of systems that process physical signals, such as electrical and computer engineering, while design engineering developed, concerned with the functional design of user-machine interfaces.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 21], [22, 25], [26, 30], [31, 38], [38, 39], [40, 50], [51, 62], [63, 69], [70, 77], [78, 82], [83, 90], [91, 102], [103, 115], [116, 118], [119, 122], [123, 129], [130, 133], [134, 142], [143, 145], [146, 153], [154, 158], [159, 166], [167, 175], [176, 183], [183, 184], [185, 189], [190, 192], [193, 203], [204, 207], [208, 216], [217, 228], [228, 229], [230, 235], [236, 242], [243, 254], [255, 264], [264, 265], [266, 275], [276, 280], [281, 284], [285, 295], [296, 302], [303, 305], [306, 310], [310, 311], [311, 318], [319, 329], [329, 330]]}
{"doc_key": "ai-test-258", "ner": [[5, 5, "metrics"], [7, 8, "metrics"], [10, 10, "metrics"], [46, 48, "metrics"], [56, 57, "metrics"], [65, 67, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 10, 7, 8, "named", "", false, false], [46, 48, 56, 57, "named", "", false, false], [56, 57, 65, 67, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Perhaps", "the", "simplest", "statistic", "is", "accuracy", "or", "Fraction", "Correct", "(", "FC", ")", ",", "which", "measures", "the", "proportion", "of", "all", "instances", "that", "are", "correctly", "categorised", ";", "it", "is", "the", "ratio", "of", "the", "number", "of", "correct", "classifications", "to", "the", "total", "number", "of", "correct", "or", "incorrect", "classifications", ":", "(", "TP", "+", "TN", ")", "/", "total", "population", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "Perhaps the simplest statistic is accuracy or Fraction Correct (FC), which measures the proportion of all instances that are correctly categorised; it is the ratio of the number of correct classifications to the total number of correct or incorrect classifications: (TP + TN) / total population = (TP + TN) / (TP + TN + FP + FN).", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 30], [31, 33], [34, 42], [43, 45], [46, 54], [55, 62], [63, 64], [64, 66], [66, 67], [67, 68], [69, 74], [75, 83], [84, 87], [88, 98], [99, 101], [102, 105], [106, 115], [116, 120], [121, 124], [125, 134], [135, 146], [146, 147], [148, 150], [151, 153], [154, 157], [158, 163], [164, 166], [167, 170], [171, 177], [178, 180], [181, 188], [189, 204], [205, 207], [208, 211], [212, 217], [218, 224], [225, 227], [228, 235], [236, 238], [239, 248], [249, 264], [264, 265], [266, 267], [267, 269], [270, 271], [272, 274], [274, 275], [276, 277], [278, 283], [284, 294], [295, 296], [297, 298], [298, 300], [301, 302], [303, 305], [305, 306], [307, 308], [309, 310], [310, 312], [313, 314], [315, 317], [318, 319], [320, 322], [323, 324], [325, 327], [327, 328], [328, 329]]}
{"doc_key": "ai-test-259", "ner": [[15, 23, "conference"], [25, 27, "conference"], [33, 33, "location"], [39, 39, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 23, 33, 33, "physical", "", false, false], [25, 27, 15, 23, "named", "", false, false], [39, 39, 15, 23, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "academic", "community", ",", "the", "main", "forums", "for", "research", "began", "in", "1995", "when", "the", "first", "international", "conference", ",", "Data", "Mining", "and", "Knowledge", "Discovery", "(", "KDD", "-", "95", ")", ",", "was", "launched", "in", "Montreal", "under", "the", "auspices", "of", "the", "AAAI", "."], "sentence-detokenized": "In the academic community, the main forums for research began in 1995 when the first international conference, Data Mining and Knowledge Discovery (KDD-95), was launched in Montreal under the auspices of the AAAI.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 25], [25, 26], [27, 30], [31, 35], [36, 42], [43, 46], [47, 55], [56, 61], [62, 64], [65, 69], [70, 74], [75, 78], [79, 84], [85, 98], [99, 109], [109, 110], [111, 115], [116, 122], [123, 126], [127, 136], [137, 146], [147, 148], [148, 151], [151, 152], [152, 154], [154, 155], [155, 156], [157, 160], [161, 169], [170, 172], [173, 181], [182, 187], [188, 191], [192, 200], [201, 203], [204, 207], [208, 212], [212, 213]]}
{"doc_key": "ai-test-260", "ner": [[12, 12, "field"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "this", "approach", ",", "models", "are", "developed", "using", "various", "data", "mining", "and", "machine", "learning", "algorithms", "to", "predict", "users", "'", "ratings", "of", "unrated", "items", "."], "sentence-detokenized": "In this approach, models are developed using various data mining and machine learning algorithms to predict users' ratings of unrated items.", "token2charspan": [[0, 2], [3, 7], [8, 16], [16, 17], [18, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 57], [58, 64], [65, 68], [69, 76], [77, 85], [86, 96], [97, 99], [100, 107], [108, 113], [113, 114], [115, 122], [123, 125], [126, 133], [134, 139], [139, 140]]}
{"doc_key": "ai-test-261", "ner": [[13, 14, "algorithm"], [11, 17, "algorithm"], [23, 26, "misc"], [27, 28, "metrics"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[13, 14, 11, 17, "usage", "", false, false], [11, 17, 27, 28, "usage", "", false, false], [27, 28, 23, 26, "type-of", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Given", "the", "above", "discussion", ",", "we", "see", "that", "the", "SVM", "technique", "corresponds", "to", "empirical", "risk", "with", "Tikhonov", "regularisation", ",", "in", "which", "case", "the", "loss", "function", "is", "the", "hinge", "loss"], "sentence-detokenized": "Given the above discussion, we see that the SVM technique corresponds to empirical risk with Tikhonov regularisation, in which case the loss function is the hinge loss", "token2charspan": [[0, 5], [6, 9], [10, 15], [16, 26], [26, 27], [28, 30], [31, 34], [35, 39], [40, 43], [44, 47], [48, 57], [58, 69], [70, 72], [73, 82], [83, 87], [88, 92], [93, 101], [102, 116], [116, 117], [118, 120], [121, 126], [127, 131], [132, 135], [136, 140], [141, 149], [150, 152], [153, 156], [157, 162], [163, 167]]}
{"doc_key": "ai-test-262", "ner": [[6, 7, "person"], [10, 11, "person"], [16, 18, "person"]], "ner_mapping_to_source": [0, 1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "2015", "edition", "was", "hosted", "by", "Molly", "McGrath", ",", "with", "Chris", "Rose", "and", "former", "UFC", "fighter", "Kenny", "Florian", "as", "commentators", "."], "sentence-detokenized": "The 2015 edition was hosted by Molly McGrath, with Chris Rose and former UFC fighter Kenny Florian as commentators.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 27], [28, 30], [31, 36], [37, 44], [44, 45], [46, 50], [51, 56], [57, 61], [62, 65], [66, 72], [73, 76], [77, 84], [85, 90], [91, 98], [99, 101], [102, 114], [114, 115]]}
{"doc_key": "ai-test-263", "ner": [[3, 5, "product"], [9, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [18, 18, "researcher"], [20, 21, "researcher"], [30, 32, "task"], [34, 34, "product"], [36, 36, "researcher"], [41, 42, "task"], [44, 46, "researcher"], [49, 50, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12], "relations": [[3, 5, 9, 11, "origin", "", false, false], [3, 5, 13, 14, "origin", "", false, false], [3, 5, 16, 17, "origin", "", false, false], [3, 5, 18, 18, "origin", "", false, false], [13, 14, 36, 36, "named", "same", false, false], [16, 17, 20, 21, "named", "same", false, false], [30, 32, 34, 34, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 7], "sentence": ["A", "subset", "called", "Micro", "-", "Planner", "was", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "Sussman", "and", "Winograd", "in", "1971", "and", "has", "been", "used", "in", "Winograd", "'s", "natural", "language", "understanding", "programme", "SHRDLU", ",", "Eugene", "Charniak", "'s", "work", "on", "story", "understanding", ",", "Thorne", "McCarty", "'s", "work", "on", "legal", "reasoning", "and", "several", "other", "projects", "."], "sentence-detokenized": "A subset called Micro-Planner was implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd Sussman and Winograd in 1971 and has been used in Winograd's natural language understanding programme SHRDLU, Eugene Charniak's work on story understanding, Thorne McCarty's work on legal reasoning and several other projects.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [21, 22], [22, 29], [30, 33], [34, 45], [46, 48], [49, 55], [56, 59], [60, 67], [67, 68], [69, 75], [76, 84], [85, 88], [89, 94], [95, 103], [104, 111], [112, 115], [116, 124], [125, 127], [128, 132], [133, 136], [137, 140], [141, 145], [146, 150], [151, 153], [154, 162], [162, 164], [165, 172], [173, 181], [182, 195], [196, 205], [206, 212], [212, 213], [214, 220], [221, 229], [229, 231], [232, 236], [237, 239], [240, 245], [246, 259], [259, 260], [261, 267], [268, 275], [275, 277], [278, 282], [283, 285], [286, 291], [292, 301], [302, 305], [306, 313], [314, 319], [320, 328], [328, 329]]}
{"doc_key": "ai-test-264", "ner": [[0, 1, "product"], [11, 12, "product"], [15, 17, "task"], [19, 20, "task"], [22, 24, "task"], [26, 27, "task"], [29, 30, "task"], [33, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 0, 1, "usage", "", true, false], [15, 17, 11, 12, "part-of", "", true, false], [19, 20, 11, 12, "part-of", "", true, false], [22, 24, 11, 12, "part-of", "", true, false], [26, 27, 11, 12, "part-of", "", true, false], [29, 30, 11, 12, "part-of", "", true, false], [33, 36, 11, 12, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Word", "Net", "has", "been", "used", "for", "a", "number", "of", "purposes", "in", "information", "systems", ",", "including", "word", "sense", "disambiguation", ",", "information", "retrieval", ",", "automatic", "text", "classification", ",", "automatic", "summarisation", ",", "machine", "translation", "and", "even", "automatic", "crossword", "puzzle", "creation", "."], "sentence-detokenized": "WordNet has been used for a number of purposes in information systems, including word sense disambiguation, information retrieval, automatic text classification, automatic summarisation, machine translation and even automatic crossword puzzle creation.", "token2charspan": [[0, 4], [4, 7], [8, 11], [12, 16], [17, 21], [22, 25], [26, 27], [28, 34], [35, 37], [38, 46], [47, 49], [50, 61], [62, 69], [69, 70], [71, 80], [81, 85], [86, 91], [92, 106], [106, 107], [108, 119], [120, 129], [129, 130], [131, 140], [141, 145], [146, 160], [160, 161], [162, 171], [172, 185], [185, 186], [187, 194], [195, 206], [207, 210], [211, 215], [216, 225], [226, 235], [236, 242], [243, 251], [251, 252]]}
{"doc_key": "ai-test-265", "ner": [[0, 0, "researcher"], [7, 7, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 7, 7, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Keutzer", "was", "made", "a", "Fellow", "of", "the", "IEEE", "in", "1996", "."], "sentence-detokenized": "Keutzer was made a Fellow of the IEEE in 1996.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 37], [38, 40], [41, 45], [45, 46]]}
{"doc_key": "ai-test-266", "ner": [[8, 10, "algorithm"], [55, 56, "misc"], [66, 67, "algorithm"], [70, 71, "algorithm"], [74, 75, "algorithm"], [78, 79, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[66, 67, 55, 56, "type-of", "", false, false], [70, 71, 55, 56, "type-of", "", false, false], [74, 75, 55, 56, "type-of", "", false, false], [78, 79, 55, 56, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "widely", "used", "type", "of", "composition", "is", "the", "non-linear", "weighted", "sum", ",", "where", "math", "\\", "textstyle", "f", "(", "x", ")", "=", "K", "\\", "left", "(", "\\", "sum", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "\\", "right", ")", "/", "math", ",", "where", "math", "\\", "textstyle", "K", "/", "math", "(", "commonly", "called", "the", "activation", "function", ")", "is", "a", "predefined", "function", ",", "such", "as", "the", "hyperbolic", "tangent", ",", "the", "sigmoid", "function", ",", "the", "softmax", "function", "or", "the", "rectifier", "function", "."], "sentence-detokenized": "A widely used type of composition is the non-linear weighted sum, where math\\ textstyle f (x) = K\\ left (\\ sum _ i w _ i g _ i (x)\\ right) / math, where math\\ textstyle K / math (commonly called the activation function) is a predefined function, such as the hyperbolic tangent, the sigmoid function, the softmax function or the rectifier function.", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 18], [19, 21], [22, 33], [34, 36], [37, 40], [41, 51], [52, 60], [61, 64], [64, 65], [66, 71], [72, 76], [76, 77], [78, 87], [88, 89], [90, 91], [91, 92], [92, 93], [94, 95], [96, 97], [97, 98], [99, 103], [104, 105], [105, 106], [107, 110], [111, 112], [113, 114], [115, 116], [117, 118], [119, 120], [121, 122], [123, 124], [125, 126], [127, 128], [128, 129], [129, 130], [130, 131], [132, 137], [137, 138], [139, 140], [141, 145], [145, 146], [147, 152], [153, 157], [157, 158], [159, 168], [169, 170], [171, 172], [173, 177], [178, 179], [179, 187], [188, 194], [195, 198], [199, 209], [210, 218], [218, 219], [220, 222], [223, 224], [225, 235], [236, 244], [244, 245], [246, 250], [251, 253], [254, 257], [258, 268], [269, 276], [276, 277], [278, 281], [282, 289], [290, 298], [298, 299], [300, 303], [304, 311], [312, 320], [321, 323], [324, 327], [328, 337], [338, 346], [346, 347]]}
{"doc_key": "ai-test-267", "ner": [[3, 8, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "film", "Westworld", ",", "female", "robots", "actually", "have", "sexual", "intercourse", "with", "human", "men", "as", "part", "of", "the", "fictional", "holiday", "world", "that", "human", "customers", "pay", "for", "."], "sentence-detokenized": "In the film Westworld, female robots actually have sexual intercourse with human men as part of the fictional holiday world that human customers pay for.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 21], [21, 22], [23, 29], [30, 36], [37, 45], [46, 50], [51, 57], [58, 69], [70, 74], [75, 80], [81, 84], [85, 87], [88, 92], [93, 95], [96, 99], [100, 109], [110, 117], [118, 123], [124, 128], [129, 134], [135, 144], [145, 148], [149, 152], [152, 153]]}
{"doc_key": "ai-test-268", "ner": [[7, 8, "task"], [23, 28, "task"], [30, 31, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 23, 28, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Typically", ",", "the", "process", "begins", "with", "the", "extraction", "of", "terminology", "and", "concepts", "or", "noun", "phrases", "from", "plain", "text", "using", "linguistic", "processors", "such", "as", "part", "-", "of", "-", "speech", "tagging", "and", "phrase", "chunking", "."], "sentence-detokenized": "Typically, the process begins with the extraction of terminology and concepts or noun phrases from plain text using linguistic processors such as part-of-speech tagging and phrase chunking.", "token2charspan": [[0, 9], [9, 10], [11, 14], [15, 22], [23, 29], [30, 34], [35, 38], [39, 49], [50, 52], [53, 64], [65, 68], [69, 77], [78, 80], [81, 85], [86, 93], [94, 98], [99, 104], [105, 109], [110, 115], [116, 126], [127, 137], [138, 142], [143, 145], [146, 150], [150, 151], [151, 153], [153, 154], [154, 160], [161, 168], [169, 172], [173, 179], [180, 188], [188, 189]]}
{"doc_key": "ai-test-269", "ner": [[13, 14, "field"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 13, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "demonstrated", "its", "performance", "on", "a", "range", "of", "problems", "of", "interest", "to", "the", "machine", "learning", "community", ",", "including", "handwriting", "recognition", "."], "sentence-detokenized": "They demonstrated its performance on a range of problems of interest to the machine learning community, including handwriting recognition.", "token2charspan": [[0, 4], [5, 17], [18, 21], [22, 33], [34, 36], [37, 38], [39, 44], [45, 47], [48, 56], [57, 59], [60, 68], [69, 71], [72, 75], [76, 83], [84, 92], [93, 102], [102, 103], [104, 113], [114, 125], [126, 137], [137, 138]]}
{"doc_key": "ai-test-270", "ner": [[3, 3, "university"], [5, 5, "researcher"], [11, 12, "researcher"], [18, 18, "product"], [22, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 5, 3, 3, "physical", "", false, false], [5, 5, 3, 3, "role", "", false, false], [18, 18, 11, 12, "origin", "", false, false], [18, 18, 22, 23, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "studying", "at", "Stanford", ",", "Scheinman", "received", "a", "scholarship", "sponsored", "by", "George", "Devol", ",", "the", "inventor", "of", "the", "Unimate", ",", "the", "first", "industrial", "robot", "."], "sentence-detokenized": "While studying at Stanford, Scheinman received a scholarship sponsored by George Devol, the inventor of the Unimate, the first industrial robot.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [26, 27], [28, 37], [38, 46], [47, 48], [49, 60], [61, 70], [71, 73], [74, 80], [81, 86], [86, 87], [88, 91], [92, 100], [101, 103], [104, 107], [108, 115], [115, 116], [117, 120], [121, 126], [127, 137], [138, 143], [143, 144]]}
{"doc_key": "ai-test-271", "ner": [[4, 5, "task"], [8, 10, "metrics"], [12, 15, "metrics"], [21, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 8, 10, "usage", "", true, false], [12, 15, 8, 10, "named", "", false, false], [21, 23, 8, 10, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Originally", "used", "to", "evaluate", "machine", "translation", ",", "the", "bilingual", "evaluation", "study", "(", "BLEU", ")", "has", "also", "been", "successfully", "used", "to", "evaluate", "paraphrase", "generation", "models", "."], "sentence-detokenized": "Originally used to evaluate machine translation, the bilingual evaluation study (BLEU) has also been successfully used to evaluate paraphrase generation models.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 27], [28, 35], [36, 47], [47, 48], [49, 52], [53, 62], [63, 73], [74, 79], [80, 81], [81, 85], [85, 86], [87, 90], [91, 95], [96, 100], [101, 113], [114, 118], [119, 121], [122, 130], [131, 141], [142, 152], [153, 159], [159, 160]]}
{"doc_key": "ai-test-272", "ner": [[0, 0, "organisation"], [6, 8, "organisation"], [10, 10, "organisation"], [16, 17, "country"], [18, 18, "country"]], "ner_mapping_to_source": [0, 1, 2, 4, 5], "relations": [[0, 0, 6, 8, "role", "licenses_to", false, false], [0, 0, 10, 10, "role", "licenses_to", false, false], [6, 8, 16, 17, "physical", "", false, false], [10, 10, 18, 18, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Unimation", "later", "licensed", "its", "technology", "to", "Kawasaki", "Heavy", "Industries", "and", "GKN", ",", "which", "manufactured", "Unimates", "in", "Japan", "and", "England", "respectively", "."], "sentence-detokenized": "Unimation later licensed its technology to Kawasaki Heavy Industries and GKN, which manufactured Unimates in Japan and England respectively.", "token2charspan": [[0, 9], [10, 15], [16, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 57], [58, 68], [69, 72], [73, 76], [76, 77], [78, 83], [84, 96], [97, 105], [106, 108], [109, 114], [115, 118], [119, 126], [127, 139], [139, 140]]}
{"doc_key": "ai-test-273", "ner": [[19, 22, "conference"], [37, 38, "field"], [56, 60, "field"], [62, 62, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[37, 38, 56, 60, "compare", "", false, false], [62, 62, 56, 60, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Much", "of", "the", "confusion", "between", "these", "two", "research", "communities", "(", "which", "often", "have", "separate", "conferences", "and", "journals", ",", "with", "ECML", "PKDD", "being", "a", "major", "exception", ")", "stems", "from", "the", "basic", "assumptions", "with", "which", "they", "operate", ":", "In", "machine", "learning", ",", "performance", "is", "usually", "evaluated", "in", "terms", "of", "the", "ability", "to", "reproduce", "known", "knowledge", ",", "whereas", "in", "knowledge", "discovery", "and", "data", "mining", "(", "KDD", ")", ",", "the", "main", "task", "is", "to", "discover", "previously", "unknown", "knowledge", "."], "sentence-detokenized": "Much of the confusion between these two research communities (which often have separate conferences and journals, with ECML PKDD being a major exception) stems from the basic assumptions with which they operate: In machine learning, performance is usually evaluated in terms of the ability to reproduce known knowledge, whereas in knowledge discovery and data mining (KDD), the main task is to discover previously unknown knowledge.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 29], [30, 35], [36, 39], [40, 48], [49, 60], [61, 62], [62, 67], [68, 73], [74, 78], [79, 87], [88, 99], [100, 103], [104, 112], [112, 113], [114, 118], [119, 123], [124, 128], [129, 134], [135, 136], [137, 142], [143, 152], [152, 153], [154, 159], [160, 164], [165, 168], [169, 174], [175, 186], [187, 191], [192, 197], [198, 202], [203, 210], [210, 211], [212, 214], [215, 222], [223, 231], [231, 232], [233, 244], [245, 247], [248, 255], [256, 265], [266, 268], [269, 274], [275, 277], [278, 281], [282, 289], [290, 292], [293, 302], [303, 308], [309, 318], [318, 319], [320, 327], [328, 330], [331, 340], [341, 350], [351, 354], [355, 359], [360, 366], [367, 368], [368, 371], [371, 372], [372, 373], [374, 377], [378, 382], [383, 387], [388, 390], [391, 393], [394, 402], [403, 413], [414, 421], [422, 431], [431, 432]]}
{"doc_key": "ai-test-274", "ner": [[9, 12, "product"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Hidden", "Markov", "models", "are", "the", "basis", "for", "most", "modern", "automatic", "speech", "recognition", "systems", "."], "sentence-detokenized": "Hidden Markov models are the basis for most modern automatic speech recognition systems.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 28], [29, 34], [35, 38], [39, 43], [44, 50], [51, 60], [61, 67], [68, 79], [80, 87], [87, 88]]}
{"doc_key": "ai-test-275", "ner": [[3, 3, "location"], [5, 5, "country"], [10, 11, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 5, 5, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["a", "company", "in", "Bangalore", ",", "India", ",", "specialising", "in", "online", "handwriting", "recognition", "software", "."], "sentence-detokenized": "a company in Bangalore, India, specialising in online handwriting recognition software.", "token2charspan": [[0, 1], [2, 9], [10, 12], [13, 22], [22, 23], [24, 29], [29, 30], [31, 43], [44, 46], [47, 53], [54, 65], [66, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-276", "ner": [[24, 25, "misc"], [50, 52, "metrics"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Do", "repeated", "translations", "converge", "on", "a", "single", "expression", "in", "both", "languages", "?", "I.e.", "does", "the", "translation", "method", "show", "stationarity", "or", "does", "it", "produce", "a", "canonical", "form", "?", "Does", "the", "translation", "become", "stationary", "without", "losing", "the", "original", "meaning", "?", "This", "metric", "has", "been", "criticised", "for", "not", "correlating", "well", "with", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "scores", "."], "sentence-detokenized": "Do repeated translations converge on a single expression in both languages? I.e. does the translation method show stationarity or does it produce a canonical form? Does the translation become stationary without losing the original meaning? This metric has been criticised for not correlating well with BLEU (BiLingual Evaluation Understudy) scores.", "token2charspan": [[0, 2], [3, 11], [12, 24], [25, 33], [34, 36], [37, 38], [39, 45], [46, 56], [57, 59], [60, 64], [65, 74], [74, 75], [76, 80], [81, 85], [86, 89], [90, 101], [102, 108], [109, 113], [114, 126], [127, 129], [130, 134], [135, 137], [138, 145], [146, 147], [148, 157], [158, 162], [162, 163], [164, 168], [169, 172], [173, 184], [185, 191], [192, 202], [203, 210], [211, 217], [218, 221], [222, 230], [231, 238], [238, 239], [240, 244], [245, 251], [252, 255], [256, 260], [261, 271], [272, 275], [276, 279], [280, 291], [292, 296], [297, 301], [302, 306], [307, 308], [308, 317], [318, 328], [329, 339], [339, 340], [341, 347], [347, 348]]}
{"doc_key": "ai-test-277", "ner": [[6, 10, "organisation"], [13, 20, "organisation"], [22, 23, "university"], [26, 26, "university"], [29, 30, "field"], [33, 37, "organisation"], [40, 42, "organisation"], [50, 53, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[13, 20, 22, 23, "part-of", "", false, false], [26, 26, 29, 30, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "is", "a", "fellow", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", ",", "the", "Center", "for", "Advanced", "Study", "in", "the", "Behavioral", "Sciences", "at", "Stanford", "University", ",", "the", "MIT", "Center", "for", "Cognitive", "Science", ",", "the", "Canadian", "Institute", "for", "Advanced", "Research", ",", "the", "Canadian", "Psychological", "Association", "and", "was", "elected", "a", "Fellow", "of", "the", "Royal", "Society", "of", "Canada", "in", "1998", "."], "sentence-detokenized": "He is a fellow of the American Association for Artificial Intelligence, the Center for Advanced Study in the Behavioral Sciences at Stanford University, the MIT Center for Cognitive Science, the Canadian Institute for Advanced Research, the Canadian Psychological Association and was elected a Fellow of the Royal Society of Canada in 1998.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 42], [43, 46], [47, 57], [58, 70], [70, 71], [72, 75], [76, 82], [83, 86], [87, 95], [96, 101], [102, 104], [105, 108], [109, 119], [120, 128], [129, 131], [132, 140], [141, 151], [151, 152], [153, 156], [157, 160], [161, 167], [168, 171], [172, 181], [182, 189], [189, 190], [191, 194], [195, 203], [204, 213], [214, 217], [218, 226], [227, 235], [235, 236], [237, 240], [241, 249], [250, 263], [264, 275], [276, 279], [280, 283], [284, 291], [292, 293], [294, 300], [301, 303], [304, 307], [308, 313], [314, 321], [322, 324], [325, 331], [332, 334], [335, 339], [339, 340]]}
{"doc_key": "ai-test-278", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [17, 19, "misc"], [22, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 17, 19, "part-of", "", false, false], [0, 0, 22, 25, "part-of", "", false, false], [4, 5, 17, 19, "part-of", "", false, false], [4, 5, 22, 25, "part-of", "", false, false], [7, 8, 17, 19, "part-of", "", false, false], [7, 8, 22, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", "-", "along", "with", "Yoshua", "Bengio", "and", "Yann", "LeCun", "-", "is", "considered", "by", "some", "to", "be", "the", "godfather", "of", "AI", "and", "the", "godfather", "of", "Deep", "Learning", "."], "sentence-detokenized": "Hinton - along with Yoshua Bengio and Yann LeCun - is considered by some to be the godfather of AI and the godfather of Deep Learning.", "token2charspan": [[0, 6], [7, 8], [9, 14], [15, 19], [20, 26], [27, 33], [34, 37], [38, 42], [43, 48], [49, 50], [51, 53], [54, 64], [65, 67], [68, 72], [73, 75], [76, 78], [79, 82], [83, 92], [93, 95], [96, 98], [99, 102], [103, 106], [107, 116], [117, 119], [120, 124], [125, 133], [133, 134]]}
{"doc_key": "ai-test-279", "ner": [[7, 7, "product"], [20, 20, "misc"], [22, 23, "misc"], [24, 24, "product"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 7, 20, 20, "related-to", "", false, false], [7, 7, 22, 23, "related-to", "", false, false], [20, 20, 24, 24, "named", "same", false, false], [28, 29, 24, 24, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "lightweight", "open", "-", "source", "language", "project", "eSpeak", ",", "which", "takes", "its", "own", "approach", "to", "synthesis", ",", "has", "experimented", "with", "Mandarin", "and", "Cantonese", ".", "eSpeak", "was", "used", "by", "Google", "Translate", "from", "May", "2010", "to", "2010", "."], "sentence-detokenized": "The lightweight open-source language project eSpeak, which takes its own approach to synthesis, has experimented with Mandarin and Cantonese. eSpeak was used by Google Translate from May 2010 to 2010.", "token2charspan": [[0, 3], [4, 15], [16, 20], [20, 21], [21, 27], [28, 36], [37, 44], [45, 51], [51, 52], [53, 58], [59, 64], [65, 68], [69, 72], [73, 81], [82, 84], [85, 94], [94, 95], [96, 99], [100, 112], [113, 117], [118, 126], [127, 130], [131, 140], [140, 141], [142, 148], [149, 152], [153, 157], [158, 160], [161, 167], [168, 177], [178, 182], [183, 186], [187, 191], [192, 194], [195, 199], [199, 200]]}
{"doc_key": "ai-test-280", "ner": [[0, 2, "product"], [13, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 13, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Software", "Automatic", "Mouth", "was", "also", "released", "in", "1982", "and", "was", "the", "first", "commercial", "speech", "synthesis", "programme", "to", "consist", "entirely", "of", "software", "."], "sentence-detokenized": "Software Automatic Mouth was also released in 1982 and was the first commercial speech synthesis programme to consist entirely of software.", "token2charspan": [[0, 8], [9, 18], [19, 24], [25, 28], [29, 33], [34, 42], [43, 45], [46, 50], [51, 54], [55, 58], [59, 62], [63, 68], [69, 79], [80, 86], [87, 96], [97, 106], [107, 109], [110, 117], [118, 126], [127, 129], [130, 138], [138, 139]]}
{"doc_key": "ai-test-281", "ner": [[4, 6, "metrics"], [8, 8, "metrics"], [12, 12, "metrics"], [11, 14, "metrics"], [17, 23, "metrics"], [30, 32, "metrics"], [34, 34, "metrics"], [38, 44, "metrics"], [47, 49, "metrics"], [51, 51, "metrics"], [55, 55, "metrics"], [57, 57, "metrics"], [61, 67, "metrics"], [73, 75, "metrics"], [77, 77, "metrics"], [80, 86, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[8, 8, 4, 6, "named", "", false, false], [12, 12, 4, 6, "named", "", false, false], [11, 14, 4, 6, "named", "", false, false], [17, 23, 4, 6, "named", "", false, false], [34, 34, 30, 32, "named", "", false, false], [38, 44, 30, 32, "named", "", false, false], [51, 51, 47, 49, "named", "", false, false], [55, 55, 47, 49, "named", "", false, false], [57, 57, 47, 49, "named", "", false, false], [61, 67, 47, 49, "named", "", false, false], [77, 77, 73, 75, "named", "", false, false], [80, 86, 73, 75, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["The", "column", "ratios", "are", "TRUE", "positive", "rate", "(", "TPR", ",", "also", "called", "sensitivity", "or", "recall", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "with", "the", "complement", "of", "FALSE", "negative", "rate", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ";", "and", "TRUE", "negative", "rate", "(", "TNR", ",", "also", "called", "specificity", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", ",", "with", "the", "complement", "of", "FALSE", "positive", "rate", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "The column ratios are TRUE positive rate (TPR, also called sensitivity or recall) (TP / (TP + FN)), with the complement of FALSE negative rate (FNR) (FN / (TP + FN)); and TRUE negative rate (TNR, also called specificity, SPC) (TN / (TN + FP)), with the complement of FALSE positive rate (FPR) (FP / (TN + FP)).", "token2charspan": [[0, 3], [4, 10], [11, 17], [18, 21], [22, 26], [27, 35], [36, 40], [41, 42], [42, 45], [45, 46], [47, 51], [52, 58], [59, 70], [71, 73], [74, 80], [80, 81], [82, 83], [83, 85], [86, 87], [88, 89], [89, 91], [92, 93], [94, 96], [96, 97], [97, 98], [98, 99], [100, 104], [105, 108], [109, 119], [120, 122], [123, 128], [129, 137], [138, 142], [143, 144], [144, 147], [147, 148], [149, 150], [150, 152], [153, 154], [155, 156], [156, 158], [159, 160], [161, 163], [163, 164], [164, 165], [165, 166], [167, 170], [171, 175], [176, 184], [185, 189], [190, 191], [191, 194], [194, 195], [196, 200], [201, 207], [208, 219], [219, 220], [221, 224], [224, 225], [226, 227], [227, 229], [230, 231], [232, 233], [233, 235], [236, 237], [238, 240], [240, 241], [241, 242], [242, 243], [244, 248], [249, 252], [253, 263], [264, 266], [267, 272], [273, 281], [282, 286], [287, 288], [288, 291], [291, 292], [293, 294], [294, 296], [297, 298], [299, 300], [300, 302], [303, 304], [305, 307], [307, 308], [308, 309], [309, 310]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 2, "person"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 16, 16, "role", "working_with", false, false], [2, 2, 16, 16, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "and", "Weber", "have", "also", "collaborated", "on", "many", "other", "robots", ",", "and", "their", "experience", "with", "the", "Kismet"], "sentence-detokenized": "Edsinger and Weber have also collaborated on many other robots, and their experience with the Kismet", "token2charspan": [[0, 8], [9, 12], [13, 18], [19, 23], [24, 28], [29, 41], [42, 44], [45, 49], [50, 55], [56, 62], [62, 63], [64, 67], [68, 73], [74, 84], [85, 89], [90, 93], [94, 100]]}
{"doc_key": "ai-test-283", "ner": [[12, 12, "programlang"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "R", "functions", "are", "also", "accessible", "via", "various", "scripting", "languages", "such", "as", "Python", "."], "sentence-detokenized": "The R functions are also accessible via various scripting languages such as Python.", "token2charspan": [[0, 3], [4, 5], [6, 15], [16, 19], [20, 24], [25, 35], [36, 39], [40, 47], [48, 57], [58, 67], [68, 72], [73, 75], [76, 82], [82, 83]]}
{"doc_key": "ai-test-284", "ner": [[0, 0, "programlang"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "was", "one", "of", "the", "first", "robot", "languages", "and", "was", "used", "in", "Unimate", "robots", "."], "sentence-detokenized": "VAL was one of the first robot languages and was used in Unimate robots.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 18], [19, 24], [25, 30], [31, 40], [41, 44], [45, 48], [49, 53], [54, 56], [57, 64], [65, 71], [71, 72]]}
{"doc_key": "ai-test-285", "ner": [[13, 23, "conference"], [21, 21, "conference"], [25, 25, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 23, 25, 25, "physical", "", false, false], [21, 21, 13, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["They", "presented", "their", "database", "for", "the", "first", "time", "as", "a", "poster", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "2009", "in", "Florida", "."], "sentence-detokenized": "They presented their database for the first time as a poster at the Conference on Computer Vision and Pattern Recognition (CVPR) 2009 in Florida.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 29], [30, 33], [34, 37], [38, 43], [44, 48], [49, 51], [52, 53], [54, 60], [61, 63], [64, 67], [68, 78], [79, 81], [82, 90], [91, 97], [98, 101], [102, 109], [110, 121], [122, 123], [123, 127], [127, 128], [129, 133], [134, 136], [137, 144], [144, 145]]}
{"doc_key": "ai-test-286", "ner": [[0, 2, "misc"], [9, 10, "task"], [12, 13, "field"], [15, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 0, 2, "type-of", "", false, false], [12, 13, 0, 2, "type-of", "", false, false], [15, 16, 0, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Categorisation", "tasks", "where", "no", "labels", "are", "provided", "are", "called", "unsupervised", "classification", ",", "unsupervised", "learning", "and", "cluster", "analysis", "."], "sentence-detokenized": "Categorisation tasks where no labels are provided are called unsupervised classification, unsupervised learning and cluster analysis.", "token2charspan": [[0, 14], [15, 20], [21, 26], [27, 29], [30, 36], [37, 40], [41, 49], [50, 53], [54, 60], [61, 73], [74, 88], [88, 89], [90, 102], [103, 111], [112, 115], [116, 123], [124, 132], [132, 133]]}
{"doc_key": "ai-test-287", "ner": [[3, 4, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "about", "object", "recognition", ",", "recognising", "and", "locating", "people", "and", "further", "emotion", "recognition", "."], "sentence-detokenized": "It is about object recognition, recognising and locating people and further emotion recognition.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 18], [19, 30], [30, 31], [32, 43], [44, 47], [48, 56], [57, 63], [64, 67], [68, 75], [76, 83], [84, 95], [95, 96]]}
{"doc_key": "ai-test-288", "ner": [[6, 6, "misc"], [8, 8, "misc"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "process", "is", "complex", "and", "includes", "coding", "and", "retrieval", "."], "sentence-detokenized": "The process is complex and includes coding and retrieval.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 26], [27, 35], [36, 42], [43, 46], [47, 56], [56, 57]]}
{"doc_key": "ai-test-289", "ner": [[10, 11, "product"], [15, 18, "product"], [32, 33, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 15, 18, "named", "", false, false], [10, 11, 32, 33, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "also", "known", "as", "parallel", "robots", "or", "generalised", "Stewart", "platforms", "(", "in", "the", "Stewart", "platform", ",", "the", "actuators", "are", "paired", "on", "both", "the", "base", "and", "the", "platform", ")", ",", "are", "articulated", "robots", "that", "use", "similar", "mechanisms", "to", "move", "either", "the", "robot", "on", "its", "base", "or", "one", "or", "more", "manipulator", "arms", "."], "sentence-detokenized": "These systems, also known as parallel robots or generalised Stewart platforms (in the Stewart platform, the actuators are paired on both the base and the platform), are articulated robots that use similar mechanisms to move either the robot on its base or one or more manipulator arms.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 25], [26, 28], [29, 37], [38, 44], [45, 47], [48, 59], [60, 67], [68, 77], [78, 79], [79, 81], [82, 85], [86, 93], [94, 102], [102, 103], [104, 107], [108, 117], [118, 121], [122, 128], [129, 131], [132, 136], [137, 140], [141, 145], [146, 149], [150, 153], [154, 162], [162, 163], [163, 164], [165, 168], [169, 180], [181, 187], [188, 192], [193, 196], [197, 204], [205, 215], [216, 218], [219, 223], [224, 230], [231, 234], [235, 240], [241, 243], [244, 247], [248, 252], [253, 255], [256, 259], [260, 262], [263, 267], [268, 279], [280, 284], [284, 285]]}
{"doc_key": "ai-test-290", "ner": [[0, 1, "field"], [4, 5, "field"], [13, 13, "field"], [12, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 5, "part-of", "subfield", false, false], [0, 1, 13, 13, "compare", "", false, false], [13, 13, 12, 19, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "vision", "as", "a", "systems", "engineering", "discipline", "is", "to", "be", "distinguished", "from", "computer", "vision", ",", "a", "form", "of", "computer", "science", "."], "sentence-detokenized": "Machine vision as a systems engineering discipline is to be distinguished from computer vision, a form of computer science.", "token2charspan": [[0, 7], [8, 14], [15, 17], [18, 19], [20, 27], [28, 39], [40, 50], [51, 53], [54, 56], [57, 59], [60, 73], [74, 78], [79, 87], [88, 94], [94, 95], [96, 97], [98, 102], [103, 105], [106, 114], [115, 122], [122, 123]]}
{"doc_key": "ai-test-291", "ner": [[5, 6, "algorithm"], [10, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 10, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "activation", "function", "of", "the", "LSTM", "gates", "is", "often", "the", "logistic", "sigmoid", "function", "."], "sentence-detokenized": "The activation function of the LSTM gates is often the logistic sigmoid function.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 26], [27, 30], [31, 35], [36, 41], [42, 44], [45, 50], [51, 54], [55, 63], [64, 71], [72, 80], [80, 81]]}
{"doc_key": "ai-test-292", "ner": [[5, 6, "metrics"], [19, 22, "metrics"], [24, 24, "metrics"], [31, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 19, 22, "named", "", false, false], [5, 6, 31, 33, "named", "", false, false], [24, 24, 19, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "other", "words", ",", "the", "sample", "mean", "is", "the", "(", "necessarily", "only", ")", "efficient", "estimator", "and", "thus", "also", "the", "unbiased", "minimum", "variance", "estimator", "(", "MVUE", ")", ",", "which", "is", "also", "the", "maximum", "likelihood", "estimator", "."], "sentence-detokenized": "In other words, the sample mean is the (necessarily only) efficient estimator and thus also the unbiased minimum variance estimator (MVUE), which is also the maximum likelihood estimator.", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 19], [20, 26], [27, 31], [32, 34], [35, 38], [39, 40], [40, 51], [52, 56], [56, 57], [58, 67], [68, 77], [78, 81], [82, 86], [87, 91], [92, 95], [96, 104], [105, 112], [113, 121], [122, 131], [132, 133], [133, 137], [137, 138], [138, 139], [140, 145], [146, 148], [149, 153], [154, 157], [158, 165], [166, 176], [177, 186], [186, 187]]}
{"doc_key": "ai-test-293", "ner": [[1, 1, "academicjournal"], [5, 7, "researcher"], [9, 10, "researcher"], [12, 14, "researcher"], [24, 24, "product"], [27, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 1, 24, 24, "topic", "", false, false], [1, 1, 27, 28, "topic", "", false, false], [5, 7, 1, 1, "role", "", false, false], [9, 10, 1, 1, "role", "", false, false], [12, 14, 1, 1, "role", "", false, false], [24, 24, 27, 28, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "Scientific", "American", "article", "by", "Berners", "-", "Lee", ",", "James", "Hendler", "and", "Ora", "Lassila", "from", "2001", "described", "the", "expected", "further", "development", "of", "the", "existing", "web", "into", "a", "semantic", "web", "."], "sentence-detokenized": "The Scientific American article by Berners-Lee, James Hendler and Ora Lassila from 2001 described the expected further development of the existing web into a semantic web.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 31], [32, 34], [35, 42], [42, 43], [43, 46], [46, 47], [48, 53], [54, 61], [62, 65], [66, 69], [70, 77], [78, 82], [83, 87], [88, 97], [98, 101], [102, 110], [111, 118], [119, 130], [131, 133], [134, 137], [138, 146], [147, 150], [151, 155], [156, 157], [158, 166], [167, 170], [170, 171]]}
{"doc_key": "ai-test-294", "ner": [[0, 2, "misc"], [12, 13, "person"], [15, 15, "person"], [36, 36, "person"], [42, 43, "person"]], "ner_mapping_to_source": [0, 1, 2, 4, 5], "relations": [[12, 13, 0, 2, "role", "actor_in_work", false, false], [15, 15, 12, 13, "named", "", false, false], [15, 15, 12, 13, "origin", "", false, false], [42, 43, 15, 15, "role", "auditioned_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 4], "sentence": ["Blade", "Runner", "featured", "a", "number", "of", "then", "lesser", "-", "known", "actors", ":", "Sean", "Young", "plays", "Rachael", ",", "an", "experimental", "replicant", "implanted", "with", "the", "memories", "of", "Tyrell", "'s", "niece", "so", "that", "she", "believes", "she", "is", "human", ";", "Sammon", ",", "pp.", "92", "-", "93", "Nina", "Axelrod", "auditioned", "for", "the", "role", "."], "sentence-detokenized": "Blade Runner featured a number of then lesser-known actors: Sean Young plays Rachael, an experimental replicant implanted with the memories of Tyrell's niece so that she believes she is human; Sammon, pp. 92-93 Nina Axelrod auditioned for the role.", "token2charspan": [[0, 5], [6, 12], [13, 21], [22, 23], [24, 30], [31, 33], [34, 38], [39, 45], [45, 46], [46, 51], [52, 58], [58, 59], [60, 64], [65, 70], [71, 76], [77, 84], [84, 85], [86, 88], [89, 101], [102, 111], [112, 121], [122, 126], [127, 130], [131, 139], [140, 142], [143, 149], [149, 151], [152, 157], [158, 160], [161, 165], [166, 169], [170, 178], [179, 182], [183, 185], [186, 191], [191, 192], [193, 199], [199, 200], [201, 204], [205, 207], [207, 208], [208, 210], [211, 215], [216, 223], [224, 234], [235, 238], [239, 242], [243, 247], [247, 248]]}
{"doc_key": "ai-test-295", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [13, 16, "university"], [23, 25, "product"], [27, 27, "product"], [41, 41, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 13, 16, "physical", "", false, false], [3, 4, 13, 16, "physical", "", false, false], [6, 7, 13, 16, "physical", "", false, false], [9, 10, 13, 16, "physical", "", false, false], [13, 16, 41, 41, "physical", "", true, false], [23, 25, 13, 16, "temporal", "", false, false], [27, 27, 13, 16, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Gerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "and", "Terry", "Winograd", "visited", "the", "University", "of", "Edinburgh", "in", "1971", "and", "spread", "the", "news", "about", "Micro", "-", "Planner", "and", "SHRDLU", ",", "challenging", "the", "unitary", "proof", "approach", "that", "had", "been", "the", "mainstay", "of", "the", "Edinburgh", "logicians", "."], "sentence-detokenized": "Gerry Sussman, Eugene Charniak, Seymour Papert and Terry Winograd visited the University of Edinburgh in 1971 and spread the news about Micro-Planner and SHRDLU, challenging the unitary proof approach that had been the mainstay of the Edinburgh logicians.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 21], [22, 30], [30, 31], [32, 39], [40, 46], [47, 50], [51, 56], [57, 65], [66, 73], [74, 77], [78, 88], [89, 91], [92, 101], [102, 104], [105, 109], [110, 113], [114, 120], [121, 124], [125, 129], [130, 135], [136, 141], [141, 142], [142, 149], [150, 153], [154, 160], [160, 161], [162, 173], [174, 177], [178, 185], [186, 191], [192, 200], [201, 205], [206, 209], [210, 214], [215, 218], [219, 227], [228, 230], [231, 234], [235, 244], [245, 254], [254, 255]]}
{"doc_key": "ai-test-296", "ner": [[0, 1, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[0, 1, 11, 12, "role", "inspires", false, false], [0, 1, 14, 15, "role", "inspires", false, false], [0, 1, 17, 18, "role", "inspires", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Walter", "'s", "work", "inspired", "subsequent", "generations", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "Walter's work inspired subsequent generations of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 6], [6, 8], [9, 13], [14, 22], [23, 33], [34, 45], [46, 48], [49, 57], [58, 69], [70, 74], [75, 77], [78, 84], [85, 91], [91, 92], [93, 97], [98, 105], [106, 109], [110, 114], [115, 121], [121, 122]]}
{"doc_key": "ai-test-297", "ner": [[7, 7, "algorithm"], [9, 10, "researcher"], [16, 22, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 9, 10, "origin", "", false, false], [7, 7, 16, 22, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Subsequently", ",", "a", "similar", "GPU", "-", "based", "CNN", "by", "Alex", "Krizhevsky", "et", "al", ".", "won", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "2012", "."], "sentence-detokenized": "Subsequently, a similar GPU-based CNN by Alex Krizhevsky et al. won the ImageNet Large Scale Visual Recognition Challenge 2012.", "token2charspan": [[0, 12], [12, 13], [14, 15], [16, 23], [24, 27], [27, 28], [28, 33], [34, 37], [38, 40], [41, 45], [46, 56], [57, 59], [60, 62], [62, 63], [64, 67], [68, 71], [72, 80], [81, 86], [87, 92], [93, 99], [100, 111], [112, 121], [122, 126], [126, 127]]}
{"doc_key": "ai-test-298", "ner": [[2, 3, "misc"], [8, 9, "metrics"], [12, 13, "metrics"], [18, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 2, 3, "type-of", "", false, false], [12, 13, 2, 3, "type-of", "", false, false], [12, 13, 18, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Commonly", "used", "loss", "functions", "for", "probabilistic", "classification", "include", "log", "loss", "and", "the", "Brier", "score", "between", "the", "predicted", "and", "true", "probability", "distributions", "."], "sentence-detokenized": "Commonly used loss functions for probabilistic classification include log loss and the Brier score between the predicted and true probability distributions.", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 28], [29, 32], [33, 46], [47, 61], [62, 69], [70, 73], [74, 78], [79, 82], [83, 86], [87, 92], [93, 98], [99, 106], [107, 110], [111, 120], [121, 124], [125, 129], [130, 141], [142, 155], [155, 156]]}
{"doc_key": "ai-test-299", "ner": [[4, 4, "organisation"], [19, 19, "organisation"], [9, 10, "misc"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[4, 4, 9, 10, "part-of", "", false, false], [19, 19, 4, 4, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "May", "2016", ",", "NtechLab", "was", "one", "of", "three", "Russian", "companies", "approved", "for", "official", "testing", "of", "biometrics", "technology", "by", "NIST", "."], "sentence-detokenized": "In May 2016, NtechLab was one of three Russian companies approved for official testing of biometrics technology by NIST.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [13, 21], [22, 25], [26, 29], [30, 32], [33, 38], [39, 46], [47, 56], [57, 65], [66, 69], [70, 78], [79, 86], [87, 89], [90, 100], [101, 111], [112, 114], [115, 119], [119, 120]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "floating", "point", "numbers", "only", "have", "a", "certain", "mathematical", "accuracy", "."], "sentence-detokenized": "However, floating point numbers only have a certain mathematical accuracy.", "token2charspan": [[0, 7], [7, 8], [9, 17], [18, 23], [24, 31], [32, 36], [37, 41], [42, 43], [44, 51], [52, 64], [65, 73], [73, 74]]}
{"doc_key": "ai-test-301", "ner": [[5, 5, "organisation"], [12, 18, "conference"], [20, 20, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 12, 18, "role", "contributes_to", false, false], [20, 20, 12, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2015", ",", "many", "of", "SenseTime", "'s", "papers", "were", "accepted", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "In 2015, many of SenseTime's papers were accepted at the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 13], [14, 16], [17, 26], [26, 28], [29, 35], [36, 40], [41, 49], [50, 52], [53, 56], [57, 67], [68, 70], [71, 79], [80, 86], [87, 90], [91, 98], [99, 110], [111, 112], [112, 116], [116, 117], [117, 118]]}
{"doc_key": "ai-test-302", "ner": [[6, 8, "task"], [10, 10, "task"], [13, 14, "task"], [16, 19, "task"], [22, 22, "field"], [24, 26, "misc"], [29, 35, "conference"], [43, 45, "misc"], [47, 48, "conference"], [66, 68, "misc"], [70, 70, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[6, 8, 22, 22, "part-of", "task_part_of_field", false, false], [10, 10, 6, 8, "named", "", false, false], [13, 14, 22, 22, "part-of", "task_part_of_field", false, false], [16, 19, 13, 14, "named", "", false, false], [24, 26, 29, 35, "temporal", "", false, false], [43, 45, 47, 48, "temporal", "", false, false], [66, 68, 70, 70, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["He", "has", "co-developed", "optimal", "algorithms", "for", "Structure", "From", "Motion", "(", "SFM", ",", "or", "Visual", "SLAM", ",", "simultaneous", "localisation", "and", "mapping", ",", "in", "Robotics", ";", "Best", "Paper", "Award", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "1998", ")", ",", "characterised", "their", "ambiguities", "(", "David", "Marr", "Prize", "at", "ICCV", "1999", ")", "and", "also", "characterised", "the", "identifiability", "and", "observability", "of", "the", "fusion", "of", "visual", "and", "inertial", "sensors", "(", "Best", "Paper", "Award", "at", "Robotics", "2015", ")", "."], "sentence-detokenized": "He has co-developed optimal algorithms for Structure From Motion (SFM, or Visual SLAM, simultaneous localisation and mapping, in Robotics; Best Paper Award at the Conference on Computer Vision and Pattern Recognition 1998), characterised their ambiguities (David Marr Prize at ICCV 1999) and also characterised the identifiability and observability of the fusion of visual and inertial sensors (Best Paper Award at Robotics 2015).", "token2charspan": [[0, 2], [3, 6], [7, 19], [20, 27], [28, 38], [39, 42], [43, 52], [53, 57], [58, 64], [65, 66], [66, 69], [69, 70], [71, 73], [74, 80], [81, 85], [85, 86], [87, 99], [100, 112], [113, 116], [117, 124], [124, 125], [126, 128], [129, 137], [137, 138], [139, 143], [144, 149], [150, 155], [156, 158], [159, 162], [163, 173], [174, 176], [177, 185], [186, 192], [193, 196], [197, 204], [205, 216], [217, 221], [221, 222], [222, 223], [224, 237], [238, 243], [244, 255], [256, 257], [257, 262], [263, 267], [268, 273], [274, 276], [277, 281], [282, 286], [286, 287], [288, 291], [292, 296], [297, 310], [311, 314], [315, 330], [331, 334], [335, 348], [349, 351], [352, 355], [356, 362], [363, 365], [366, 372], [373, 376], [377, 385], [386, 393], [394, 395], [395, 399], [400, 405], [406, 411], [412, 414], [415, 423], [424, 428], [428, 429], [429, 430]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Society", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Society for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 40], [41, 44], [45, 48], [49, 60], [61, 63], [64, 74], [75, 87], [87, 88]]}
{"doc_key": "ai-test-304", "ner": [[0, 1, "task"], [7, 8, "field"], [10, 10, "field"], [11, 14, "field"], [21, 22, "task"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 7, 8, "part-of", "task_part_of_field", false, false], [0, 1, 10, 10, "part-of", "task_part_of_field", false, false], [0, 1, 11, 14, "part-of", "task_part_of_field", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 24, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Edge", "detection", "is", "a", "fundamental", "tool", "in", "image", "processing", ",", "machine", "vision", "and", "computer", "vision", ",", "especially", "in", "the", "areas", "of", "feature", "detection", "and", "feature", "extraction", "."], "sentence-detokenized": "Edge detection is a fundamental tool in image processing, machine vision and computer vision, especially in the areas of feature detection and feature extraction.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 19], [20, 31], [32, 36], [37, 39], [40, 45], [46, 56], [56, 57], [58, 65], [66, 72], [73, 76], [77, 85], [86, 92], [92, 93], [94, 104], [105, 107], [108, 111], [112, 117], [118, 120], [121, 128], [129, 138], [139, 142], [143, 150], [151, 161], [161, 162]]}
{"doc_key": "ai-test-305", "ner": [[10, 11, "misc"], [24, 25, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "example", "of", "this", "would", "be", "a", "variable", "such", "as", "outdoor", "temperature", "(", "mathtemp", "/", "math", ")", ",", "which", "can", "be", "recorded", "to", "several", "decimal", "places", "in", "a", "particular", "application", "(", "depending", "on", "the", "measuring", "device", ")", "."], "sentence-detokenized": "An example of this would be a variable such as outdoor temperature (mathtemp / math), which can be recorded to several decimal places in a particular application (depending on the measuring device).", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 18], [19, 24], [25, 27], [28, 29], [30, 38], [39, 43], [44, 46], [47, 54], [55, 66], [67, 68], [68, 76], [77, 78], [79, 83], [83, 84], [84, 85], [86, 91], [92, 95], [96, 98], [99, 107], [108, 110], [111, 118], [119, 126], [127, 133], [134, 136], [137, 138], [139, 149], [150, 161], [162, 163], [163, 172], [173, 175], [176, 179], [180, 189], [190, 196], [196, 197], [197, 198]]}
{"doc_key": "ai-test-306", "ner": [[4, 5, "person"], [7, 8, "person"], [10, 15, "person"], [22, 23, "person"], [31, 32, "person"], [36, 37, "person"], [41, 42, "person"], [44, 44, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 6, 8, 10, 11], "relations": [[44, 44, 41, 42, "named", "", false, false]], "relations_mapping_to_source": [4], "sentence": ["The", "returning", "judges", "are", "Fon", "Davis", ",", "Jessica", "Chobot", "and", "Leland", "Melvin", ",", "as", "well", "as", "celebrity", "guest", "judges", "such", "as", "actor", "Clark", "Gregg", ",", "MythBusters", "host", "and", "former", "Battlebots", "creator", "Adam", "Savage", ",", "NFL", "tightman", "Vernon", "Davis", "and", "YouTube", "star", "Michael", "Stevens", "aka", "Vsauce", "."], "sentence-detokenized": "The returning judges are Fon Davis, Jessica Chobot and Leland Melvin, as well as celebrity guest judges such as actor Clark Gregg, MythBusters host and former Battlebots creator Adam Savage, NFL tightman Vernon Davis and YouTube star Michael Stevens aka Vsauce.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 24], [25, 28], [29, 34], [34, 35], [36, 43], [44, 50], [51, 54], [55, 61], [62, 68], [68, 69], [70, 72], [73, 77], [78, 80], [81, 90], [91, 96], [97, 103], [104, 108], [109, 111], [112, 117], [118, 123], [124, 129], [129, 130], [131, 142], [143, 147], [148, 151], [152, 158], [159, 169], [170, 177], [178, 182], [183, 189], [189, 190], [191, 194], [195, 203], [204, 210], [211, 216], [217, 220], [221, 228], [229, 233], [234, 241], [242, 249], [250, 253], [254, 260], [260, 261]]}
{"doc_key": "ai-test-307", "ner": [[9, 11, "algorithm"], [13, 15, "algorithm"], [6, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 11, 6, 26, "part-of", "", false, false], [13, 15, 6, 26, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "these", "methods", "could", "never", "prevail", "against", "the", "Gaussian", "Mixture", "Model", "/", "Hidden", "Markov", "Model", "(", "GMM", "-", "HMM", ")", "technology", ",", "which", "is", "based", "on", "generative", ",", "discriminatively", "trained", "language", "models", "and", "relies", "on", "inconsistent", "internal", "processing", "."], "sentence-detokenized": "However, these methods could never prevail against the Gaussian Mixture Model / Hidden Markov Model (GMM-HMM) technology, which is based on generative, discriminatively trained language models and relies on inconsistent internal processing.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 22], [23, 28], [29, 34], [35, 42], [43, 50], [51, 54], [55, 63], [64, 71], [72, 77], [78, 79], [80, 86], [87, 93], [94, 99], [100, 101], [101, 104], [104, 105], [105, 108], [108, 109], [110, 120], [120, 121], [122, 127], [128, 130], [131, 136], [137, 139], [140, 150], [150, 151], [152, 168], [169, 176], [177, 185], [186, 192], [193, 196], [197, 203], [204, 206], [207, 219], [220, 228], [229, 239], [239, 240]]}
{"doc_key": "ai-test-308", "ner": [[4, 4, "product"], [6, 7, "programlang"], [9, 9, "programlang"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Software", "packages", "such", "as", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", "and", "SciPy", "provide", "convenient", "ways", "to", "apply", "these", "different", "methods", "."], "sentence-detokenized": "Software packages such as MATLAB, GNU Octave, Scilab and SciPy provide convenient ways to apply these different methods.", "token2charspan": [[0, 8], [9, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 37], [38, 44], [44, 45], [46, 52], [53, 56], [57, 62], [63, 70], [71, 81], [82, 86], [87, 89], [90, 95], [96, 101], [102, 111], [112, 119], [119, 120]]}
{"doc_key": "ai-test-309", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [8, 9, "task"], [18, 20, "researcher"], [21, 22, "university"], [24, 26, "researcher"], [27, 29, "organisation"], [32, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 8, 9, "related-to", "", false, false], [0, 2, 18, 20, "origin", "", false, false], [0, 2, 24, 26, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [18, 20, 21, 22, "physical", "", false, false], [18, 20, 21, 22, "role", "", false, false], [24, 26, 27, 29, "physical", "", false, false], [24, 26, 27, 29, "role", "", false, false], [32, 32, 27, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", ",", "a", "speech", "processing", "algorithm", ",", "was", "first", "proposed", "in", "1966", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "."], "sentence-detokenized": "Linear predictive coding (LPC), a speech processing algorithm, was first proposed in 1966 by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT).", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [30, 31], [32, 33], [34, 40], [41, 51], [52, 61], [61, 62], [63, 66], [67, 72], [73, 81], [82, 84], [85, 89], [90, 92], [93, 101], [102, 109], [110, 112], [113, 119], [120, 130], [131, 134], [135, 140], [141, 146], [147, 149], [150, 156], [157, 166], [167, 170], [171, 180], [181, 182], [182, 185], [185, 186], [186, 187]]}
{"doc_key": "ai-test-310", "ner": [[19, 26, "conference"], [28, 28, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[28, 28, 19, 26, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["On", "the", "occasion", "of", "the", "25th", "anniversary", "of", "the", "algorithm", ",", "a", "workshop", "was", "organised", "in", "2006", "at", "the", "International", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "to", "summarise", "recent", "contributions", "and", "variations", "of", "the", "original", "algorithm", ",", "mainly", "aimed", "at", "improving", "the", "speed", "of", "the", "algorithm", ",", "the", "robustness", "and", "accuracy", "of", "the", "estimated", "solution", ",", "and", "reducing", "the", "dependence", "on", "user", "-", "defined", "constants", "."], "sentence-detokenized": "On the occasion of the 25th anniversary of the algorithm, a workshop was organised in 2006 at the International Conference on Computer Vision and Pattern Recognition (CVPR) to summarise recent contributions and variations of the original algorithm, mainly aimed at improving the speed of the algorithm, the robustness and accuracy of the estimated solution, and reducing the dependence on user-defined constants.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 18], [19, 22], [23, 27], [28, 39], [40, 42], [43, 46], [47, 56], [56, 57], [58, 59], [60, 68], [69, 72], [73, 82], [83, 85], [86, 90], [91, 93], [94, 97], [98, 111], [112, 122], [123, 125], [126, 134], [135, 141], [142, 145], [146, 153], [154, 165], [166, 167], [167, 171], [171, 172], [173, 175], [176, 185], [186, 192], [193, 206], [207, 210], [211, 221], [222, 224], [225, 228], [229, 237], [238, 247], [247, 248], [249, 255], [256, 261], [262, 264], [265, 274], [275, 278], [279, 284], [285, 287], [288, 291], [292, 301], [301, 302], [303, 306], [307, 317], [318, 321], [322, 330], [331, 333], [334, 337], [338, 347], [348, 356], [356, 357], [358, 361], [362, 370], [371, 374], [375, 385], [386, 388], [389, 393], [393, 394], [394, 401], [402, 411], [411, 412]]}
{"doc_key": "ai-test-311", "ner": [[3, 5, "university"], [8, 11, "organisation"], [13, 15, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Members", "visited", "the", "University", "of", "Debrecen", ",", "the", "Hungarian", "Academy", "of", "Sciences", ",", "E\u00f6tv\u00f6s", "Lor\u00e1nd", "University", ",", "etc", "."], "sentence-detokenized": "Members visited the University of Debrecen, the Hungarian Academy of Sciences, E\u00f6tv\u00f6s Lor\u00e1nd University, etc.", "token2charspan": [[0, 7], [8, 15], [16, 19], [20, 30], [31, 33], [34, 42], [42, 43], [44, 47], [48, 57], [58, 65], [66, 68], [69, 77], [77, 78], [79, 85], [86, 92], [93, 103], [103, 104], [105, 108], [108, 109]]}
{"doc_key": "ai-test-312", "ner": [[2, 2, "algorithm"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 16, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "extend", "SVM", "to", "cases", "where", "the", "data", "are", "not", "linearly", "separable", ",", "we", "introduce", "the", "loss", "function", ","], "sentence-detokenized": "To extend SVM to cases where the data are not linearly separable, we introduce the loss function,", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 16], [17, 22], [23, 28], [29, 32], [33, 37], [38, 41], [42, 45], [46, 54], [55, 64], [64, 65], [66, 68], [69, 78], [79, 82], [83, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-test-313", "ner": [[0, 0, "programlang"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 10, 11, "origin", "", false, false], [0, 0, 13, 14, "origin", "", false, false], [0, 0, 16, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Logo", "is", "an", "educational", "programming", "language", "developed", "in", "1967", "by", "Wally", "Feurzeig", ",", "Seymour", "Papert", "and", "Cynthia", "Solomon", "."], "sentence-detokenized": "Logo is an educational programming language developed in 1967 by Wally Feurzeig, Seymour Papert and Cynthia Solomon.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 34], [35, 43], [44, 53], [54, 56], [57, 61], [62, 64], [65, 70], [71, 79], [79, 80], [81, 88], [89, 95], [96, 99], [100, 107], [108, 115], [115, 116]]}
{"doc_key": "ai-test-314", "ner": [[0, 3, "organisation"], [24, 28, "organisation"], [30, 33, "location"], [35, 35, "location"], [37, 39, "location"], [18, 23, "product"], [40, 51, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 24, 28, "role", "works_for", false, false], [24, 28, 30, 33, "physical", "", false, false], [30, 33, 35, 35, "physical", "", false, false], [35, 35, 37, 39, "physical", "", false, false], [18, 23, 0, 3, "origin", "", false, false], [40, 51, 18, 23, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "Eyring", "Research", "Institute", "was", "instrumental", "in", "the", "development", ",", "under", "the", "strictest", "military", "secrecy", ",", "of", "the", "Intelligent", "Systems", "Technology", "software", "for", "the", "U.S.", "Air", "Force", "Missile", "Directorate", "at", "Hill", "Air", "Force", "Base", "near", "Ogden", ",", "Utah", ",", "which", "formed", "the", "basis", "for", "the", "Star", "Wars", "programme", "later", "named", "after", "Reagan", "."], "sentence-detokenized": "The Eyring Research Institute was instrumental in the development, under the strictest military secrecy, of the Intelligent Systems Technology software for the U.S. Air Force Missile Directorate at Hill Air Force Base near Ogden, Utah, which formed the basis for the Star Wars programme later named after Reagan.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 29], [30, 33], [34, 46], [47, 49], [50, 53], [54, 65], [65, 66], [67, 72], [73, 76], [77, 86], [87, 95], [96, 103], [103, 104], [105, 107], [108, 111], [112, 123], [124, 131], [132, 142], [143, 151], [152, 155], [156, 159], [160, 164], [165, 168], [169, 174], [175, 182], [183, 194], [195, 197], [198, 202], [203, 206], [207, 212], [213, 217], [218, 222], [223, 228], [228, 229], [230, 234], [234, 235], [236, 241], [242, 248], [249, 252], [253, 258], [259, 262], [263, 266], [267, 271], [272, 276], [277, 286], [287, 292], [293, 298], [299, 304], [305, 311], [311, 312]]}
{"doc_key": "ai-test-315", "ner": [[12, 13, "field"], [24, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Over", "the", "decades", ",", "he", "has", "researched", "and", "developed", "emerging", "areas", "of", "computer", "science", ",", "from", "compilers", "to", "programming", "languages", "to", "system", "architectures", "(", "John", "F", ".", "Sowa", "and", "John", "Zachman", ",", "1992", ")", "."], "sentence-detokenized": "Over the decades, he has researched and developed emerging areas of computer science, from compilers to programming languages to system architectures (John F. Sowa and John Zachman, 1992).", "token2charspan": [[0, 4], [5, 8], [9, 16], [16, 17], [18, 20], [21, 24], [25, 35], [36, 39], [40, 49], [50, 58], [59, 64], [65, 67], [68, 76], [77, 84], [84, 85], [86, 90], [91, 100], [101, 103], [104, 115], [116, 125], [126, 128], [129, 135], [136, 149], [150, 151], [151, 155], [156, 157], [157, 158], [159, 163], [164, 167], [168, 172], [173, 180], [180, 181], [182, 186], [186, 187], [187, 188]]}
{"doc_key": "ai-test-316", "ner": [[1, 2, "algorithm"], [7, 10, "algorithm"], [12, 13, "algorithm"], [18, 19, "field"], [21, 22, "field"], [26, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 10, 1, 2, "named", "", false, false], [12, 13, 1, 2, "named", "", false, false], [18, 19, 1, 2, "usage", "", false, false], [21, 22, 1, 2, "usage", "", false, false], [26, 28, 1, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Sobel", "operator", ",", "sometimes", "called", "the", "Sobel", "-", "Feldman", "operator", "or", "Sobel", "filter", ",", "is", "used", "in", "image", "processing", "and", "computer", "vision", ",", "particularly", "in", "edge", "detection", "algorithms", "where", "it", "produces", "an", "image", "that", "highlights", "edges", "."], "sentence-detokenized": "The Sobel operator, sometimes called the Sobel-Feldman operator or Sobel filter, is used in image processing and computer vision, particularly in edge detection algorithms where it produces an image that highlights edges.", "token2charspan": [[0, 3], [4, 9], [10, 18], [18, 19], [20, 29], [30, 36], [37, 40], [41, 46], [46, 47], [47, 54], [55, 63], [64, 66], [67, 72], [73, 79], [79, 80], [81, 83], [84, 88], [89, 91], [92, 97], [98, 108], [109, 112], [113, 121], [122, 128], [128, 129], [130, 142], [143, 145], [146, 150], [151, 160], [161, 171], [172, 177], [178, 180], [181, 189], [190, 192], [193, 198], [199, 203], [204, 214], [215, 220], [220, 221]]}
{"doc_key": "ai-test-317", "ner": [[0, 0, "algorithm"], [3, 3, "field"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 3, 3, "compare", "", false, false], [0, 0, 3, 3, "type-of", "", false, false], [0, 0, 15, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["LDA", "is", "a", "supervised", "learning", "algorithm", "that", "uses", "the", "labels", "of", "the", "data", ",", "while", "PCA", "is", "a", "learning", "algorithm", "that", "ignores", "the", "labels", "."], "sentence-detokenized": "LDA is a supervised learning algorithm that uses the labels of the data, while PCA is a learning algorithm that ignores the labels.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 19], [20, 28], [29, 38], [39, 43], [44, 48], [49, 52], [53, 59], [60, 62], [63, 66], [67, 71], [71, 72], [73, 78], [79, 82], [83, 85], [86, 87], [88, 96], [97, 106], [107, 111], [112, 119], [120, 123], [124, 130], [130, 131]]}
{"doc_key": "ai-test-318", "ner": [[5, 5, "algorithm"], [7, 9, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "linear", "classification", "algorithms", "are", "Winnow", ",", "Support", "Vector", "Machine", "and", "logistic", "regression", "."], "sentence-detokenized": "Other linear classification algorithms are Winnow, Support Vector Machine and logistic regression.", "token2charspan": [[0, 5], [6, 12], [13, 27], [28, 38], [39, 42], [43, 49], [49, 50], [51, 58], [59, 65], [66, 73], [74, 77], [78, 86], [87, 97], [97, 98]]}
{"doc_key": "ai-test-319", "ner": [[0, 0, "product"], [15, 17, "product"], [19, 19, "programlang"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[0, 0, 15, 17, "general-affiliation", "", true, false], [0, 0, 19, 19, "general-affiliation", "", true, false], [0, 0, 21, 21, "general-affiliation", "", true, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["VTK", "consists", "of", "a", "C", "++", "class", "library", "and", "several", "interpreted", "interface", "layers", ",", "including", "Tcl", "/", "Tk", ",", "Java", "and", "Python", "."], "sentence-detokenized": "VTK consists of a C++ class library and several interpreted interface layers, including Tcl/Tk, Java and Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 17], [18, 19], [19, 21], [22, 27], [28, 35], [36, 39], [40, 47], [48, 59], [60, 69], [70, 76], [76, 77], [78, 87], [88, 91], [91, 92], [92, 94], [94, 95], [96, 100], [101, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-320", "ner": [[7, 9, "task"], [16, 18, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Text", "generated", "by", "processing", "spontaneous", "speech", "using", "automatic", "speech", "recognition", "and", "printed", "or", "handwritten", "text", "using", "optical", "character", "recognition", "also", "contains", "processing", "noise", "."], "sentence-detokenized": "Text generated by processing spontaneous speech using automatic speech recognition and printed or handwritten text using optical character recognition also contains processing noise.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 28], [29, 40], [41, 47], [48, 53], [54, 63], [64, 70], [71, 82], [83, 86], [87, 94], [95, 97], [98, 109], [110, 114], [115, 120], [121, 128], [129, 138], [139, 150], [151, 155], [156, 164], [165, 175], [176, 181], [181, 182]]}
{"doc_key": "ai-test-321", "ner": [[0, 0, "researcher"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 9, 9, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "wrote", "several", "books", "and", "led", "the", "development", "of", "WordNet", ",", "an", "online", "database", "of", "word", "associations", "that", "can", "be", "used", "by", "computer", "programs", "."], "sentence-detokenized": "Miller wrote several books and led the development of WordNet, an online database of word associations that can be used by computer programs.", "token2charspan": [[0, 6], [7, 12], [13, 20], [21, 26], [27, 30], [31, 34], [35, 38], [39, 50], [51, 53], [54, 61], [61, 62], [63, 65], [66, 72], [73, 81], [82, 84], [85, 89], [90, 102], [103, 107], [108, 111], [112, 114], [115, 119], [120, 122], [123, 131], [132, 140], [140, 141]]}
{"doc_key": "ai-test-322", "ner": [[1, 1, "field"], [8, 10, "organisation"], [13, 14, "country"], [16, 17, "person"], [19, 21, "person"], [23, 24, "person"], [26, 27, "person"], [30, 31, "country"], [33, 35, "location"], [38, 39, "misc"], [40, 41, "person"], [43, 44, "person"], [46, 46, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 10, 13, 14, "physical", "", false, false], [16, 17, 30, 31, "physical", "", false, false], [19, 21, 30, 31, "physical", "", false, false], [23, 24, 30, 31, "physical", "", false, false], [26, 27, 30, 31, "physical", "", false, false], [33, 35, 1, 1, "general-affiliation", "", false, false], [33, 35, 40, 41, "artifact", "", false, false], [38, 39, 40, 41, "named", "", false, false], [43, 44, 46, 46, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Contemporary", "automata", "are", "represented", "by", "the", "works", "of", "Cabaret", "Mechanical", "Theatre", "in", "the", "United", "Kingdom", ",", "Dug", "North", "and", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", ",", "Joe", "Jones", "in", "the", "United", "States", ",", "Le", "D\u00e9fenseur", "du", "Temps", "by", "French", "artist", "Jacques", "Monestier", "and", "Fran\u00e7ois", "Junod", "in", "Switzerland", "."], "sentence-detokenized": "Contemporary automata are represented by the works of Cabaret Mechanical Theatre in the United Kingdom, Dug North and Chomick + Meder, Arthur Ganson, Joe Jones in the United States, Le D\u00e9fenseur du Temps by French artist Jacques Monestier and Fran\u00e7ois Junod in Switzerland.", "token2charspan": [[0, 12], [13, 21], [22, 25], [26, 37], [38, 40], [41, 44], [45, 50], [51, 53], [54, 61], [62, 72], [73, 80], [81, 83], [84, 87], [88, 94], [95, 102], [102, 103], [104, 107], [108, 113], [114, 117], [118, 125], [126, 127], [128, 133], [133, 134], [135, 141], [142, 148], [148, 149], [150, 153], [154, 159], [160, 162], [163, 166], [167, 173], [174, 180], [180, 181], [182, 184], [185, 194], [195, 197], [198, 203], [204, 206], [207, 213], [214, 220], [221, 228], [229, 238], [239, 242], [243, 251], [252, 257], [258, 260], [261, 272], [272, 273]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 21, 21, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "includes", "standard", "codefor", "/", "code", "and", "codewhile", "/", "code", "loops", ",", "but", "(", "as", "in", "other", "similar", "applications", ",", "e.g.", "R", ")", "it", "is", "recommended", "to", "use", "the", "vectorised", "notation", ",", "which", "can", "often", "be", "executed", "more", "quickly", "."], "sentence-detokenized": "MATLAB includes standard codefor/code and codewhile/code loops, but (as in other similar applications, e.g. R) it is recommended to use the vectorised notation, which can often be executed more quickly.", "token2charspan": [[0, 6], [7, 15], [16, 24], [25, 32], [32, 33], [33, 37], [38, 41], [42, 51], [51, 52], [52, 56], [57, 62], [62, 63], [64, 67], [68, 69], [69, 71], [72, 74], [75, 80], [81, 88], [89, 101], [101, 102], [103, 107], [108, 109], [109, 110], [111, 113], [114, 116], [117, 128], [129, 131], [132, 135], [136, 139], [140, 150], [151, 159], [159, 160], [161, 166], [167, 170], [171, 176], [177, 179], [180, 188], [189, 193], [194, 201], [201, 202]]}
{"doc_key": "ai-test-324", "ner": [[0, 0, "researcher"], [6, 10, "conference"], [16, 18, "field"], [21, 27, "misc"], [30, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 21, 27, "win-defeat", "", false, false], [0, 0, 30, 39, "win-defeat", "", false, false], [21, 27, 6, 10, "temporal", "", false, false], [21, 27, 16, 18, "topic", "", false, false], [30, 39, 6, 10, "temporal", "", false, false], [30, 39, 16, 18, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pausch", "received", "two", "awards", "from", "the", "Association", "for", "Computing", "Machinery", "in", "2007", "for", "his", "achievements", "in", "computer", "science", "education", ":", "the", "Karl", "V", ".", "Karlstrom", "Outstanding", "Educator", "Award", "and", "the", "ACM", "SIGCSE", "Award", "for", "Outstanding", "Contributions", "to", "Computer", "Science", "Education", "."], "sentence-detokenized": "Pausch received two awards from the Association for Computing Machinery in 2007 for his achievements in computer science education: the Karl V. Karlstrom Outstanding Educator Award and the ACM SIGCSE Award for Outstanding Contributions to Computer Science Education.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 26], [27, 31], [32, 35], [36, 47], [48, 51], [52, 61], [62, 71], [72, 74], [75, 79], [80, 83], [84, 87], [88, 100], [101, 103], [104, 112], [113, 120], [121, 130], [130, 131], [132, 135], [136, 140], [141, 142], [142, 143], [144, 153], [154, 165], [166, 174], [175, 180], [181, 184], [185, 188], [189, 192], [193, 199], [200, 205], [206, 209], [210, 221], [222, 235], [236, 238], [239, 247], [248, 255], [256, 265], [265, 266]]}
{"doc_key": "ai-test-325", "ner": [[3, 3, "person"], [8, 9, "product"], [15, 16, "organisation"]], "ner_mapping_to_source": [0, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "delivered", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was delivered to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 75], [76, 78], [79, 86], [87, 93], [94, 96], [97, 101], [101, 102]]}
{"doc_key": "ai-test-326", "ner": [[0, 1, "algorithm"], [5, 7, "field"], [11, 11, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 0, 1, "usage", "", false, false], [11, 11, 5, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Semantic", "networks", "are", "used", "in", "natural", "language", "processing", "applications", "such", "as", "semantic", "parsing", "."], "sentence-detokenized": "Semantic networks are used in natural language processing applications such as semantic parsing.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 26], [27, 29], [30, 37], [38, 46], [47, 57], [58, 70], [71, 75], [76, 78], [79, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-test-327", "ner": [[4, 5, "field"], [7, 8, "field"], [10, 11, "task"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 8, 4, 5, "usage", "", false, false], [10, 11, 4, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Some", "successful", "applications", "of", "Deep", "Learning", "are", "computer", "vision", "and", "speech", "recognition", ".", "Honglak", "Lee", ",", "Roger", "Grosse", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y", ".", "Ng", "."], "sentence-detokenized": "Some successful applications of Deep Learning are computer vision and speech recognition. Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 4], [5, 15], [16, 28], [29, 31], [32, 36], [37, 45], [46, 49], [50, 58], [59, 65], [66, 69], [70, 76], [77, 88], [88, 89], [90, 97], [98, 101], [101, 102], [103, 108], [109, 115], [115, 116], [117, 123], [124, 133], [133, 134], [135, 141], [142, 143], [143, 144], [145, 147], [147, 148]]}
{"doc_key": "ai-test-328", "ner": [[5, 9, "product"], [16, 16, "misc"], [19, 19, "misc"], [25, 25, "product"], [29, 30, "task"], [32, 33, "task"], [35, 36, "task"], [38, 40, "field"], [42, 43, "task"], [45, 46, "field"], [48, 49, "task"], [51, 52, "task"], [54, 55, "task"], [57, 57, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[5, 9, 16, 16, "physical", "travels_to", false, false], [5, 9, 19, 19, "physical", "travels_to", false, false], [25, 25, 5, 9, "part-of", "", false, false], [25, 25, 5, 9, "role", "maintains", false, false], [25, 25, 29, 30, "related-to", "has_ability_to", false, false], [25, 25, 32, 33, "related-to", "has_ability_to", false, false], [25, 25, 35, 36, "related-to", "has_ability_to", false, false], [25, 25, 38, 40, "related-to", "has_ability_to", false, false], [25, 25, 42, 43, "related-to", "has_ability_to", false, false], [25, 25, 45, 46, "related-to", "has_ability_to", false, false], [25, 25, 48, 49, "related-to", "has_ability_to", false, false], [25, 25, 51, 52, "related-to", "has_ability_to", false, false], [25, 25, 54, 55, "related-to", "has_ability_to", false, false], [25, 25, 57, 57, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["In", "addition", "to", "maintaining", "the", "systems", "of", "the", "Discovery", "One", "spacecraft", "during", "its", "interplanetary", "mission", "to", "Jupiter", "(", "or", "Saturn", "in", "the", "novel", ")", ",", "HAL", "is", "capable", "of", "speech", "synthesis", ",", "speech", "recognition", ",", "facial", "recognition", ",", "natural", "language", "processing", ",", "lip", "reading", ",", "art", "appreciation", ",", "affective", "computing", ",", "automated", "reasoning", ",", "spacecraft", "control", "and", "chess", "."], "sentence-detokenized": "In addition to maintaining the systems of the Discovery One spacecraft during its interplanetary mission to Jupiter (or Saturn in the novel), HAL is capable of speech synthesis, speech recognition, facial recognition, natural language processing, lip reading, art appreciation, affective computing, automated reasoning, spacecraft control and chess.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 38], [39, 41], [42, 45], [46, 55], [56, 59], [60, 70], [71, 77], [78, 81], [82, 96], [97, 104], [105, 107], [108, 115], [116, 117], [117, 119], [120, 126], [127, 129], [130, 133], [134, 139], [139, 140], [140, 141], [142, 145], [146, 148], [149, 156], [157, 159], [160, 166], [167, 176], [176, 177], [178, 184], [185, 196], [196, 197], [198, 204], [205, 216], [216, 217], [218, 225], [226, 234], [235, 245], [245, 246], [247, 250], [251, 258], [258, 259], [260, 263], [264, 276], [276, 277], [278, 287], [288, 297], [297, 298], [299, 308], [309, 318], [318, 319], [320, 330], [331, 338], [339, 342], [343, 348], [348, 349]]}
{"doc_key": "ai-test-329", "ner": [[0, 1, "researcher"], [4, 4, "country"], [7, 8, "country"], [11, 11, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 4, "physical", "", false, false], [0, 1, 7, 8, "physical", "", false, false], [0, 1, 11, 11, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dr", "Julesz", "emigrated", "from", "Hungary", "to", "the", "United", "States", "after", "the", "Soviet", "invasion", "in", "1956", "."], "sentence-detokenized": "Dr Julesz emigrated from Hungary to the United States after the Soviet invasion in 1956.", "token2charspan": [[0, 2], [3, 9], [10, 19], [20, 24], [25, 32], [33, 35], [36, 39], [40, 46], [47, 53], [54, 59], [60, 63], [64, 70], [71, 79], [80, 82], [83, 87], [87, 88]]}
{"doc_key": "ai-test-330", "ner": [[3, 4, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Activation", "functions", "with", "sigmoid", "function", "use", "a", "second", "non-linearity", "for", "large", "inputs", ":", "math", "\\", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+\\", "exp", "(", "-", "v", "_", "i", ")", ")", "^", "{", "-1", "}", "/", "math", "."], "sentence-detokenized": "Activation functions with sigmoid function use a second non-linearity for large inputs: math\\ phi (v _ i) = (1 +\\ exp (-v _ i)) ^ {-1} / math.", "token2charspan": [[0, 10], [11, 20], [21, 25], [26, 33], [34, 42], [43, 46], [47, 48], [49, 55], [56, 69], [70, 73], [74, 79], [80, 86], [86, 87], [88, 92], [92, 93], [94, 97], [98, 99], [99, 100], [101, 102], [103, 104], [104, 105], [106, 107], [108, 109], [109, 110], [111, 113], [114, 117], [118, 119], [119, 120], [120, 121], [122, 123], [124, 125], [125, 126], [126, 127], [128, 129], [130, 131], [131, 133], [133, 134], [135, 136], [137, 141], [141, 142]]}
{"doc_key": "ai-test-331", "ner": [[10, 12, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "probabilities", "are", "used", "to", "determine", "the", "target", "using", "a", "maximum", "likelihood", "decision", "."], "sentence-detokenized": "These probabilities are used to determine the target using a maximum likelihood decision.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 28], [29, 31], [32, 41], [42, 45], [46, 52], [53, 58], [59, 60], [61, 68], [69, 79], [80, 88], [88, 89]]}
{"doc_key": "ai-test-332", "ner": [[6, 8, "university"], [14, 16, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1984", "he", "moved", "to", "the", "University", "of", "Konstanz", "and", "in", "1990", "to", "the", "University", "of", "Salzburg", "."], "sentence-detokenized": "In 1984 he moved to the University of Konstanz and in 1990 to the University of Salzburg.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 16], [17, 19], [20, 23], [24, 34], [35, 37], [38, 46], [47, 50], [51, 53], [54, 58], [59, 61], [62, 65], [66, 76], [77, 79], [80, 88], [88, 89]]}
{"doc_key": "ai-test-333", "ner": [[6, 7, "metrics"], [9, 11, "metrics"], [13, 15, "metrics"], [17, 17, "metrics"], [19, 20, "metrics"], [22, 24, "metrics"], [26, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 11, 6, 7, "origin", "based_on", false, false], [13, 15, 6, 7, "origin", "based_on", false, false], [17, 17, 6, 7, "origin", "based_on", false, false], [19, 20, 6, 7, "origin", "based_on", false, false], [22, 24, 6, 7, "origin", "based_on", false, false], [26, 29, 6, 7, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Common", "fitness", "functions", "based", "on", "the", "confusion", "matrix", "include", "sensitivity", "/", "specificity", ",", "recall", "/", "precision", ",", "F-measure", ",", "Jaccard", "similarity", ",", "Matthews", "correlation", "coefficient", "and", "cost", "/", "profit", "matrix", ",", "which", "combines", "the", "costs", "and", "profits", "of", "the", "four", "different", "classification", "types", "."], "sentence-detokenized": "Common fitness functions based on the confusion matrix include sensitivity/specificity, recall/precision, F-measure, Jaccard similarity, Matthews correlation coefficient and cost/profit matrix, which combines the costs and profits of the four different classification types.", "token2charspan": [[0, 6], [7, 14], [15, 24], [25, 30], [31, 33], [34, 37], [38, 47], [48, 54], [55, 62], [63, 74], [74, 75], [75, 86], [86, 87], [88, 94], [94, 95], [95, 104], [104, 105], [106, 115], [115, 116], [117, 124], [125, 135], [135, 136], [137, 145], [146, 157], [158, 169], [170, 173], [174, 178], [178, 179], [179, 185], [186, 192], [192, 193], [194, 199], [200, 208], [209, 212], [213, 218], [219, 222], [223, 230], [231, 233], [234, 237], [238, 242], [243, 252], [253, 267], [268, 273], [273, 274]]}
{"doc_key": "ai-test-334", "ner": [[6, 6, "product"], [8, 8, "product"], [10, 10, "product"], [12, 12, "product"], [15, 16, "programlang"], [27, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[27, 29, 6, 6, "part-of", "", false, false], [27, 29, 8, 8, "part-of", "", false, false], [27, 29, 10, 10, "part-of", "", false, false], [27, 29, 12, 12, "part-of", "", false, false], [27, 29, 15, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Common", "numerical", "programming", "environments", "such", "as", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", "and", "the", "R", "language", "provide", "some", "of", "the", "simpler", "feature", "extraction", "techniques", "(", "e.g.", "principal", "component", "analysis", ")", "via", "built", "-", "in", "commands", "."], "sentence-detokenized": "Common numerical programming environments such as MATLAB, SciLab, NumPy, Sklearn and the R language provide some of the simpler feature extraction techniques (e.g. principal component analysis) via built-in commands.", "token2charspan": [[0, 6], [7, 16], [17, 28], [29, 41], [42, 46], [47, 49], [50, 56], [56, 57], [58, 64], [64, 65], [66, 71], [71, 72], [73, 80], [81, 84], [85, 88], [89, 90], [91, 99], [100, 107], [108, 112], [113, 115], [116, 119], [120, 127], [128, 135], [136, 146], [147, 157], [158, 159], [159, 163], [164, 173], [174, 183], [184, 192], [192, 193], [194, 197], [198, 203], [203, 204], [204, 206], [207, 215], [215, 216]]}
{"doc_key": "ai-test-335", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Industrial", "robots", "are", "used", "to", "work", "with", "humans", "and", "perform", "tasks", "in", "industrial", "manufacturing", "."], "sentence-detokenized": "Industrial robots are used to work with humans and perform tasks in industrial manufacturing.", "token2charspan": [[0, 10], [11, 17], [18, 21], [22, 26], [27, 29], [30, 34], [35, 39], [40, 46], [47, 50], [51, 58], [59, 64], [65, 67], [68, 78], [79, 92], [92, 93]]}
{"doc_key": "ai-test-336", "ner": [[6, 6, "field"], [8, 11, "researcher"], [21, 22, "field"], [24, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 21, 22, "related-to", "", false, false], [6, 6, 24, 25, "related-to", "", false, false], [6, 6, 27, 28, "related-to", "", false, false], [8, 11, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "first", "published", "work", "on", "CGs", ",", "John", "F", ".", "Sowa", "applied", "them", "to", "a", "wide", "range", "of", "topics", "in", "artificial", "intelligence", ",", "computer", "science", "and", "cognitive", "science", "."], "sentence-detokenized": "In the first published work on CGs, John F. Sowa applied them to a wide range of topics in artificial intelligence, computer science and cognitive science.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [23, 27], [28, 30], [31, 34], [34, 35], [36, 40], [41, 42], [42, 43], [44, 48], [49, 56], [57, 61], [62, 64], [65, 66], [67, 71], [72, 77], [78, 80], [81, 87], [88, 90], [91, 101], [102, 114], [114, 115], [116, 124], [125, 132], [133, 136], [137, 146], [147, 154], [154, 155]]}
{"doc_key": "ai-test-337", "ner": [[0, 0, "metrics"], [4, 5, "metrics"], [10, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 5, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "BLEU", "in", "the", "calculation", "of", "the", "penalty", "for", "shortness", ",", "as", "small", "deviations", "in", "transmission", "length", "do", "not", "affect", "the", "overall", "score", "as", "much", "."], "sentence-detokenized": "NIST also differs from BLEU in the calculation of the penalty for shortness, as small deviations in transmission length do not affect the overall score as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 46], [47, 49], [50, 53], [54, 61], [62, 65], [66, 75], [75, 76], [77, 79], [80, 85], [86, 96], [97, 99], [100, 112], [113, 119], [120, 122], [123, 126], [127, 133], [134, 137], [138, 145], [146, 151], [152, 154], [155, 159], [159, 160]]}
{"doc_key": "ai-test-338", "ner": [[1, 6, "misc"], [21, 23, "field"]], "ner_mapping_to_source": [0, 2], "relations": [[1, 6, 21, 23, "topic", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["The", "IJCAI", "Award", "for", "Research", "Excellence", "is", "presented", "every", "two", "years", "at", "the", "IJCAI", "conference", "to", "researchers", "in", "the", "field", "of", "artificial", "intelligence", "in", "recognition", "of", "outstanding", "achievements", "in", "their", "careers", "."], "sentence-detokenized": "The IJCAI Award for Research Excellence is presented every two years at the IJCAI conference to researchers in the field of artificial intelligence in recognition of outstanding achievements in their careers.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 19], [20, 28], [29, 39], [40, 42], [43, 52], [53, 58], [59, 62], [63, 68], [69, 71], [72, 75], [76, 81], [82, 92], [93, 95], [96, 107], [108, 110], [111, 114], [115, 120], [121, 123], [124, 134], [135, 147], [148, 150], [151, 162], [163, 165], [166, 177], [178, 190], [191, 193], [194, 199], [200, 207], [207, 208]]}
{"doc_key": "ai-test-339", "ner": [[0, 0, "researcher"], [9, 9, "conference"], [19, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 9, 9, "role", "", false, false], [0, 0, 19, 25, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lenat", "was", "one", "of", "the", "first", "Fellows", "of", "the", "AAAI", "and", "is", "the", "only", "person", "to", "serve", "on", "the", "scientific", "advisory", "boards", "of", "Microsoft", "and", "Apple", "."], "sentence-detokenized": "Lenat was one of the first Fellows of the AAAI and is the only person to serve on the scientific advisory boards of Microsoft and Apple.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 16], [17, 20], [21, 26], [27, 34], [35, 37], [38, 41], [42, 46], [47, 50], [51, 53], [54, 57], [58, 62], [63, 69], [70, 72], [73, 78], [79, 81], [82, 85], [86, 96], [97, 105], [106, 112], [113, 115], [116, 125], [126, 129], [130, 135], [135, 136]]}
{"doc_key": "ai-test-340", "ner": [[0, 0, "algorithm"], [5, 6, "misc"], [9, 11, "metrics"], [15, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 6, "related-to", "minimise", false, false], [9, 11, 5, 6, "type-of", "", false, false], [15, 18, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autoencoders", "are", "trained", "to", "minimise", "reconstruction", "errors", "(", "e.g.", "mean", "square", "error", ")", ",", "often", "referred", "to", "as", "loss", ":"], "sentence-detokenized": "Autoencoders are trained to minimise reconstruction errors (e.g. mean square error), often referred to as loss:", "token2charspan": [[0, 12], [13, 16], [17, 24], [25, 27], [28, 36], [37, 51], [52, 58], [59, 60], [60, 64], [65, 69], [70, 76], [77, 82], [82, 83], [83, 84], [85, 90], [91, 99], [100, 102], [103, 105], [106, 110], [110, 111]]}
{"doc_key": "ai-test-341", "ner": [[29, 31, "misc"], [34, 34, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[34, 34, 29, 31, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "alternative", "to", "using", "the", "definitions", "is", "to", "consider", "the", "general", "word", "-", "sense", "relationship", "and", "calculate", "the", "similarity", "of", "each", "word", "-", "sense", "pair", "based", "on", "a", "specific", "lexical", "knowledge", "base", "such", "as", "WordNet", "."], "sentence-detokenized": "An alternative to using the definitions is to consider the general word-sense relationship and calculate the similarity of each word-sense pair based on a specific lexical knowledge base such as WordNet.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 23], [24, 27], [28, 39], [40, 42], [43, 45], [46, 54], [55, 58], [59, 66], [67, 71], [71, 72], [72, 77], [78, 90], [91, 94], [95, 104], [105, 108], [109, 119], [120, 122], [123, 127], [128, 132], [132, 133], [133, 138], [139, 143], [144, 149], [150, 152], [153, 154], [155, 163], [164, 171], [172, 181], [182, 186], [187, 191], [192, 194], [195, 202], [202, 203]]}
{"doc_key": "ai-test-342", "ner": [[0, 2, "algorithm"], [9, 11, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 9, 11, "origin", "", false, false], [9, 11, 18, 19, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD", "-", "Lambda", "is", "a", "learning", "algorithm", "invented", "by", "Richard", "S.", "Sutton", ",", "based", "on", "earlier", "work", "by", "Arthur", "Samuel", "on", "learning", "with", "temporal", "differences", "."], "sentence-detokenized": "TD-Lambda is a learning algorithm invented by Richard S. Sutton, based on earlier work by Arthur Samuel on learning with temporal differences.", "token2charspan": [[0, 2], [2, 3], [3, 9], [10, 12], [13, 14], [15, 23], [24, 33], [34, 42], [43, 45], [46, 53], [54, 56], [57, 63], [63, 64], [65, 70], [71, 73], [74, 81], [82, 86], [87, 89], [90, 96], [97, 103], [104, 106], [107, 115], [116, 120], [121, 129], [130, 141], [141, 142]]}
{"doc_key": "ai-test-343", "ner": [[4, 5, "field"], [7, 7, "field"], [9, 10, "task"], [14, 16, "task"], [18, 18, "task"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 10, 4, 5, "part-of", "task_part_of_field", false, false], [9, 10, 7, 7, "part-of", "task_part_of_field", false, false], [14, 16, 9, 10, "named", "", false, false], [18, 18, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "fields", "of", "data", "mining", "and", "statistics", ",", "hierarchical", "clustering", "(", "also", "called", "hierarchical", "cluster", "analysis", "or", "HCA", ")", "is", "a", "method", "of", "cluster", "analysis", "that", "aims", "to", "build", "a", "hierarchy", "of", "clusters", "."], "sentence-detokenized": "In the fields of data mining and statistics, hierarchical clustering (also called hierarchical cluster analysis or HCA) is a method of cluster analysis that aims to build a hierarchy of clusters.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 21], [22, 28], [29, 32], [33, 43], [43, 44], [45, 57], [58, 68], [69, 70], [70, 74], [75, 81], [82, 94], [95, 102], [103, 111], [112, 114], [115, 118], [118, 119], [120, 122], [123, 124], [125, 131], [132, 134], [135, 142], [143, 151], [152, 156], [157, 161], [162, 164], [165, 170], [171, 172], [173, 182], [183, 185], [186, 194], [194, 195]]}
{"doc_key": "ai-test-344", "ner": [[3, 3, "algorithm"], [10, 11, "field"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "concept", "of", "deconvolution", "is", "widely", "used", "in", "signal", "and", "image", "processing", "techniques", "."], "sentence-detokenized": "The concept of deconvolution is widely used in signal and image processing techniques.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 28], [29, 31], [32, 38], [39, 43], [44, 46], [47, 53], [54, 57], [58, 63], [64, 74], [75, 85], [85, 86]]}
{"doc_key": "ai-test-345", "ner": [[0, 1, "algorithm"], [21, 22, "misc"], [26, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 21, 22, "related-to", "enhances", false, false], [0, 1, 21, 22, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cognitive", "maps", "are", "used", "to", "build", "and", "accumulate", "spatial", "knowledge", "and", "allow", "the", "mind", "'s", "eye", "to", "visualise", "images", "to", "reduce", "cognitive", "load", "and", "improve", "information", "recall", "and", "learning", "."], "sentence-detokenized": "Cognitive maps are used to build and accumulate spatial knowledge and allow the mind's eye to visualise images to reduce cognitive load and improve information recall and learning.", "token2charspan": [[0, 9], [10, 14], [15, 18], [19, 23], [24, 26], [27, 32], [33, 36], [37, 47], [48, 55], [56, 65], [66, 69], [70, 75], [76, 79], [80, 84], [84, 86], [87, 90], [91, 93], [94, 103], [104, 110], [111, 113], [114, 120], [121, 130], [131, 135], [136, 139], [140, 147], [148, 159], [160, 166], [167, 170], [171, 179], [179, 180]]}
{"doc_key": "ai-test-346", "ner": [[7, 7, "programlang"], [9, 10, "programlang"], [12, 12, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["which", "usually", "binds", "to", "languages", "such", "as", "Python", ",", "C", "++", ",", "Java", ")", "."], "sentence-detokenized": "which usually binds to languages such as Python, C++, Java).", "token2charspan": [[0, 5], [6, 13], [14, 19], [20, 22], [23, 32], [33, 37], [38, 40], [41, 47], [47, 48], [49, 50], [50, 52], [52, 53], [54, 58], [58, 59], [59, 60]]}
{"doc_key": "ai-test-347", "ner": [[1, 3, "product"], [5, 5, "product"], [15, 17, "task"], [22, 23, "task"], [27, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 15, 17, "usage", "", false, false], [1, 3, 22, 23, "usage", "", false, false], [1, 3, 27, 31, "usage", "", false, false], [5, 5, 1, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "voice", "user", "interface", "(", "VUI", ")", "enables", "spoken", "human", "interaction", "with", "computers", "by", "using", "speech", "recognition", "to", "understand", "spoken", "commands", "and", "answer", "questions", ",", "and", "usually", "converts", "text", "to", "speech", "to", "render", "a", "response", "."], "sentence-detokenized": "A voice user interface (VUI) enables spoken human interaction with computers by using speech recognition to understand spoken commands and answer questions, and usually converts text to speech to render a response.", "token2charspan": [[0, 1], [2, 7], [8, 12], [13, 22], [23, 24], [24, 27], [27, 28], [29, 36], [37, 43], [44, 49], [50, 61], [62, 66], [67, 76], [77, 79], [80, 85], [86, 92], [93, 104], [105, 107], [108, 118], [119, 125], [126, 134], [135, 138], [139, 145], [146, 155], [155, 156], [157, 160], [161, 168], [169, 177], [178, 182], [183, 185], [186, 192], [193, 195], [196, 202], [203, 204], [205, 213], [213, 214]]}
{"doc_key": "ai-test-348", "ner": [[0, 0, "programlang"], [3, 4, "misc"], [11, 15, "researcher"], [16, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4], "relations": [[0, 0, 3, 4, "general-affiliation", "is_a", false, false], [0, 0, 11, 15, "origin", "", false, false], [11, 15, 16, 17, "role", "", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["Jess", "is", "a", "rules", "engine", "for", "the", "Java", "platform", "developed", "by", "Ernest", "Friedman", "-", "Hill", "of", "Sandia", "National", "."], "sentence-detokenized": "Jess is a rules engine for the Java platform developed by Ernest Friedman-Hill of Sandia National.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 15], [16, 22], [23, 26], [27, 30], [31, 35], [36, 44], [45, 54], [55, 57], [58, 64], [65, 73], [73, 74], [74, 78], [79, 81], [82, 88], [89, 97], [97, 98]]}
{"doc_key": "ai-test-349", "ner": [[1, 3, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 3, 15, 15, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "multilayer", "perceptrons", "where", "there", "is", "a", "hidden", "layer", ",", "more", "sophisticated", "algorithms", "such", "as", "backpropagation", "must", "be", "used", "."], "sentence-detokenized": "For multilayer perceptrons where there is a hidden layer, more sophisticated algorithms such as backpropagation must be used.", "token2charspan": [[0, 3], [4, 14], [15, 26], [27, 32], [33, 38], [39, 41], [42, 43], [44, 50], [51, 56], [56, 57], [58, 62], [63, 76], [77, 87], [88, 92], [93, 95], [96, 111], [112, 116], [117, 119], [120, 124], [124, 125]]}
{"doc_key": "ai-test-350", "ner": [[0, 1, "product"], [3, 6, "product"], [10, 17, "algorithm"], [20, 21, "field"], [24, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 0, 1, "part-of", "", false, false], [3, 6, 10, 17, "usage", "", false, true], [10, 17, 20, 21, "related-to", "performs", false, false], [24, 28, 20, 21, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Google", "Translate", "'s", "neural", "machine", "translation", "system", "uses", "a", "large", "end", "-", "to", "-", "end", "artificial", "neural", "network", "that", "attempts", "Deep", "Learning", ",", "specifically", "long", "-", "term", "memory", "networks", "."], "sentence-detokenized": "Google Translate's neural machine translation system uses a large end-to-end artificial neural network that attempts Deep Learning, specifically long-term memory networks.", "token2charspan": [[0, 6], [7, 16], [16, 18], [19, 25], [26, 33], [34, 45], [46, 52], [53, 57], [58, 59], [60, 65], [66, 69], [69, 70], [70, 72], [72, 73], [73, 76], [77, 87], [88, 94], [95, 102], [103, 107], [108, 116], [117, 121], [122, 130], [130, 131], [132, 144], [145, 149], [149, 150], [150, 154], [155, 161], [162, 170], [170, 171]]}
{"doc_key": "ai-test-351", "ner": [[13, 13, "researcher"], [15, 15, "researcher"], [17, 17, "researcher"], [19, 20, "researcher"], [22, 22, "researcher"], [25, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Various", "methods", "for", "this", "were", "developed", "in", "the", "1980s", "and", "early", "1990s", "by", "Werbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Pearlmutter", "and", "others", "."], "sentence-detokenized": "Various methods for this were developed in the 1980s and early 1990s by Werbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Pearlmutter and others.", "token2charspan": [[0, 7], [8, 15], [16, 19], [20, 24], [25, 29], [30, 39], [40, 42], [43, 46], [47, 52], [53, 56], [57, 62], [63, 68], [69, 71], [72, 78], [78, 79], [80, 88], [88, 89], [90, 98], [98, 99], [100, 106], [107, 118], [118, 119], [120, 124], [125, 135], [135, 136], [137, 148], [149, 152], [153, 159], [159, 160]]}
{"doc_key": "ai-test-352", "ner": [[0, 1, "organisation"], [2, 3, "organisation"], [8, 8, "organisation"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[0, 1, 8, 8, "role", "licenses_from", false, false], [2, 3, 0, 1, "named", "", false, false], [16, 16, 0, 1, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["|", "Apple", "Apple", "Inc.", "originally", "licensed", "software", "from", "Nuance", "to", "add", "voice", "recognition", "capabilities", "to", "its", "Siri", "digital", "assistant", "."], "sentence-detokenized": "| Apple Apple Inc. originally licensed software from Nuance to add voice recognition capabilities to its Siri digital assistant.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 18], [19, 29], [30, 38], [39, 47], [48, 52], [53, 59], [60, 62], [63, 66], [67, 72], [73, 84], [85, 97], [98, 100], [101, 104], [105, 109], [110, 117], [118, 127], [127, 128]]}
{"doc_key": "ai-test-353", "ner": [[0, 0, "organisation"], [3, 4, "misc"], [7, 8, "person"], [12, 13, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 4, "role", "releases_movies_in_genre", false, false], [7, 8, 0, 0, "role", "directs_for", false, false], [12, 13, 0, 0, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "released", "several", "3D", "Westerns", "produced", "by", "Sam", "Katzman", "and", "directed", "by", "William", "Castle", "."], "sentence-detokenized": "Columbia released several 3D Westerns produced by Sam Katzman and directed by William Castle.", "token2charspan": [[0, 8], [9, 17], [18, 25], [26, 28], [29, 37], [38, 46], [47, 49], [50, 53], [54, 61], [62, 65], [66, 74], [75, 77], [78, 85], [86, 92], [92, 93]]}
{"doc_key": "ai-test-354", "ner": [[9, 10, "field"], [12, 12, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "encompasses", "knowledge", "and", "research", "in", "the", "fields", "of", "computer", "science", ",", "linguistics", "and", "computer", "engineering", "."], "sentence-detokenized": "It encompasses knowledge and research in the fields of computer science, linguistics and computer engineering.", "token2charspan": [[0, 2], [3, 14], [15, 24], [25, 28], [29, 37], [38, 40], [41, 44], [45, 51], [52, 54], [55, 63], [64, 71], [71, 72], [73, 84], [85, 88], [89, 97], [98, 109], [109, 110]]}
{"doc_key": "ai-test-355", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", "is", "an", "example", "of", "R", "code", ":"], "sentence-detokenized": "Here is an example of R code:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 23], [24, 28], [28, 29]]}
{"doc_key": "ai-test-356", "ner": [[1, 2, "metrics"], [8, 10, "metrics"], [12, 12, "metrics"], [16, 18, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 8, 10, "part-of", "plotted_into", false, false], [1, 2, 16, 18, "part-of", "plotted_into", false, false], [12, 12, 8, 10, "named", "", false, false], [20, 20, 16, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "ROC", "curve", "is", "created", "by", "plotting", "the", "TRUE", "positive", "rate", "(", "TPR", ")", "against", "the", "FALSE", "positive", "rate", "(", "FPR", ")", "at", "different", "thresholds", "."], "sentence-detokenized": "The ROC curve is created by plotting the TRUE positive rate (TPR) against the FALSE positive rate (FPR) at different thresholds.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 24], [25, 27], [28, 36], [37, 40], [41, 45], [46, 54], [55, 59], [60, 61], [61, 64], [64, 65], [66, 73], [74, 77], [78, 83], [84, 92], [93, 97], [98, 99], [99, 102], [102, 103], [104, 106], [107, 116], [117, 127], [127, 128]]}
{"doc_key": "ai-test-357", "ner": [[4, 5, "field"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 4, 5, "related-to", "researches_field", false, false], [10, 11, 4, 5, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["After", "the", "exploration", "of", "machine", "learning", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", ",", "research", "stagnated", ","], "sentence-detokenized": "After the exploration of machine learning by Marvin Minsky and Seymour Papert (1969), research stagnated,", "token2charspan": [[0, 5], [6, 9], [10, 21], [22, 24], [25, 32], [33, 41], [42, 44], [45, 51], [52, 58], [59, 62], [63, 70], [71, 77], [78, 79], [79, 83], [83, 84], [84, 85], [86, 94], [95, 104], [104, 105]]}
{"doc_key": "ai-test-358", "ner": [[9, 10, "programlang"], [12, 14, "product"], [16, 17, "programlang"], [19, 19, "product"], [21, 21, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "environments", "used", "to", "create", "DAQ", "applications", "are", "Ladder", "Diagram", ",", "Visual", "C", "++", ",", "Visual", "Basic", ",", "LabVIEW", "and", "MATLAB", "."], "sentence-detokenized": "Other programming environments used to create DAQ applications are Ladder Diagram, Visual C++, Visual Basic, LabVIEW and MATLAB.", "token2charspan": [[0, 5], [6, 17], [18, 30], [31, 35], [36, 38], [39, 45], [46, 49], [50, 62], [63, 66], [67, 73], [74, 81], [81, 82], [83, 89], [90, 91], [91, 93], [93, 94], [95, 101], [102, 107], [107, 108], [109, 116], [117, 120], [121, 127], [127, 128]]}
{"doc_key": "ai-test-359", "ner": [[14, 15, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "metric", "was", "developed", "to", "address", "some", "of", "the", "problems", "of", "the", "more", "familiar", "BLEU", "metric", "and", "to", "correlate", "well", "with", "human", "judgement", "at", "sentence", "or", "segment", "level", "."], "sentence-detokenized": "The metric was developed to address some of the problems of the more familiar BLEU metric and to correlate well with human judgement at sentence or segment level.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 24], [25, 27], [28, 35], [36, 40], [41, 43], [44, 47], [48, 56], [57, 59], [60, 63], [64, 68], [69, 77], [78, 82], [83, 89], [90, 93], [94, 96], [97, 106], [107, 111], [112, 116], [117, 122], [123, 132], [133, 135], [136, 144], [145, 147], [148, 155], [156, 161], [161, 162]]}
{"doc_key": "ai-test-360", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "-", "term", "memory", "are", "widely", "used", "to", "exploit", "the", "semantic", "correlations", "between", "successive", "video", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and long-term memory are widely used to exploit the semantic correlations between successive video frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [82, 83], [83, 87], [88, 94], [95, 98], [99, 105], [106, 110], [111, 113], [114, 121], [122, 125], [126, 134], [135, 147], [148, 155], [156, 166], [167, 172], [173, 179], [179, 180]]}
{"doc_key": "ai-test-361", "ner": [[4, 6, "product"], [8, 8, "product"], [15, 20, "product"], [42, 43, "product"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[4, 6, 15, 20, "artifact", "", false, false], [4, 6, 42, 43, "named", "", false, false], [8, 8, 4, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "mass", "production", ",", "printed", "circuit", "boards", "(", "PCBs", ")", "are", "made", "almost", "exclusively", "by", "pick", "-", "and", "-", "place", "robots", ",", "typically", "with", "SCARA", "manipulators", ",", "which", "pick", "up", "tiny", "electronic", "components", "from", "strips", "or", "trays", "and", "place", "them", "on", "the", "PCBs", "with", "great", "accuracy", "."], "sentence-detokenized": "In mass production, printed circuit boards (PCBs) are made almost exclusively by pick-and-place robots, typically with SCARA manipulators, which pick up tiny electronic components from strips or trays and place them on the PCBs with great accuracy.", "token2charspan": [[0, 2], [3, 7], [8, 18], [18, 19], [20, 27], [28, 35], [36, 42], [43, 44], [44, 48], [48, 49], [50, 53], [54, 58], [59, 65], [66, 77], [78, 80], [81, 85], [85, 86], [86, 89], [89, 90], [90, 95], [96, 102], [102, 103], [104, 113], [114, 118], [119, 124], [125, 137], [137, 138], [139, 144], [145, 149], [150, 152], [153, 157], [158, 168], [169, 179], [180, 184], [185, 191], [192, 194], [195, 200], [201, 204], [205, 210], [211, 215], [216, 218], [219, 222], [223, 227], [228, 232], [233, 238], [239, 247], [247, 248]]}
{"doc_key": "ai-test-362", "ner": [[4, 5, "field"], [15, 15, "algorithm"], [22, 23, "researcher"], [25, 26, "researcher"], [28, 32, "researcher"], [36, 37, "algorithm"], [39, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 15, 4, 5, "part-of", "", false, false], [15, 15, 22, 23, "origin", "", false, false], [15, 15, 25, 26, "origin", "", false, false], [15, 15, 28, 32, "origin", "", false, false], [15, 15, 36, 37, "type-of", "", false, false], [36, 37, 39, 40, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "the", "context", "of", "machine", "learning", ",", "where", "it", "is", "most", "commonly", "applied", "today", ",", "LDA", "was", "independently", "rediscovered", "in", "2003", "by", "David", "Blei", ",", "Andrew", "Ng", "and", "Michael", "I", ".", "Jordan", "and", "presented", "as", "a", "graphical", "model", "for", "topic", "discovery", "."], "sentence-detokenized": "In the context of machine learning, where it is most commonly applied today, LDA was independently rediscovered in 2003 by David Blei, Andrew Ng and Michael I. Jordan and presented as a graphical model for topic discovery.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 25], [26, 34], [34, 35], [36, 41], [42, 44], [45, 47], [48, 52], [53, 61], [62, 69], [70, 75], [75, 76], [77, 80], [81, 84], [85, 98], [99, 111], [112, 114], [115, 119], [120, 122], [123, 128], [129, 133], [133, 134], [135, 141], [142, 144], [145, 148], [149, 156], [157, 158], [158, 159], [160, 166], [167, 170], [171, 180], [181, 183], [184, 185], [186, 195], [196, 201], [202, 205], [206, 211], [212, 221], [221, 222]]}
{"doc_key": "ai-test-363", "ner": [[8, 8, "task"], [11, 11, "misc"], [13, 13, "metrics"], [15, 15, "metrics"], [17, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 8, 11, 11, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["Measured", "performance", "on", "test", "data", "from", "eight", "na\u00efve", "WSIs", "across", "different", "tauopathies", "yielded", "recall", ",", "precision", "and", "F1", "of", "0.92", ",", "0.72", "and", "0.81", ",", "respectively", "."], "sentence-detokenized": "Measured performance on test data from eight na\u00efve WSIs across different tauopathies yielded recall, precision and F1 of 0.92, 0.72 and 0.81, respectively.", "token2charspan": [[0, 8], [9, 20], [21, 23], [24, 28], [29, 33], [34, 38], [39, 44], [45, 50], [51, 55], [56, 62], [63, 72], [73, 84], [85, 92], [93, 99], [99, 100], [101, 110], [111, 114], [115, 117], [118, 120], [121, 125], [125, 126], [127, 131], [132, 135], [136, 140], [140, 141], [142, 154], [154, 155]]}
{"doc_key": "ai-test-364", "ner": [[11, 12, "field"], [20, 21, "task"]], "ner_mapping_to_source": [1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["With", "the", "help", "of", "advanced", "AR", "technologies", "(", "e.g.", "by", "adding", "computer", "vision", ",", "building", "AR", "cameras", "into", "smartphones", "and", "object", "recognition", ")", ",", "information", "about", "the", "user", "'s", "real", "environment", "is", "manipulated", "interactively", "and", "digitally", "."], "sentence-detokenized": "With the help of advanced AR technologies (e.g. by adding computer vision, building AR cameras into smartphones and object recognition), information about the user's real environment is manipulated interactively and digitally.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 25], [26, 28], [29, 41], [42, 43], [43, 47], [48, 50], [51, 57], [58, 66], [67, 73], [73, 74], [75, 83], [84, 86], [87, 94], [95, 99], [100, 111], [112, 115], [116, 122], [123, 134], [134, 135], [135, 136], [137, 148], [149, 154], [155, 158], [159, 163], [163, 165], [166, 170], [171, 182], [183, 185], [186, 197], [198, 211], [212, 215], [216, 225], [225, 226]]}
{"doc_key": "ai-test-365", "ner": [[3, 5, "researcher"], [7, 8, "organisation"], [14, 16, "field"], [25, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 7, 8, "role", "forms_company", false, false], [7, 8, 14, 16, "related-to", "works_with", false, false], [7, 8, 25, 27, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2014", ",", "Schmidhuber", "founded", "the", "company", "Nnaisense", "to", "work", "on", "commercial", "applications", "of", "artificial", "intelligence", "in", "areas", "such", "as", "finance", ",", "heavy", "industry", "and", "self", "-", "driving", "cars", "."], "sentence-detokenized": "In 2014, Schmidhuber founded the company Nnaisense to work on commercial applications of artificial intelligence in areas such as finance, heavy industry and self-driving cars.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 28], [29, 32], [33, 40], [41, 50], [51, 53], [54, 58], [59, 61], [62, 72], [73, 85], [86, 88], [89, 99], [100, 112], [113, 115], [116, 121], [122, 126], [127, 129], [130, 137], [137, 138], [139, 144], [145, 153], [154, 157], [158, 162], [162, 163], [163, 170], [171, 175], [175, 176]]}
{"doc_key": "ai-test-366", "ner": [[24, 26, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "not", "only", "changes", "the", "power", "of", "all", "subsequent", "tests", "for", "the", "retained", "explanatory", "model", ",", "but", "can", "also", "introduce", "bias", "and", "change", "the", "mean", "square", "error", "in", "the", "estimation", "."], "sentence-detokenized": "This not only changes the power of all subsequent tests for the retained explanatory model, but can also introduce bias and change the mean square error in the estimation.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 21], [22, 25], [26, 31], [32, 34], [35, 38], [39, 49], [50, 55], [56, 59], [60, 63], [64, 72], [73, 84], [85, 90], [90, 91], [92, 95], [96, 99], [100, 104], [105, 114], [115, 119], [120, 123], [124, 130], [131, 134], [135, 139], [140, 146], [147, 152], [153, 155], [156, 159], [160, 170], [170, 171]]}
{"doc_key": "ai-test-367", "ner": [[0, 0, "misc"], [9, 10, "task"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Bigrams", "are", "used", "in", "most", "successful", "speech", "models", "for", "speech", "recognition", "."], "sentence-detokenized": "Bigrams are used in most successful speech models for speech recognition.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 19], [20, 24], [25, 35], [36, 42], [43, 49], [50, 53], [54, 60], [61, 72], [72, 73]]}
{"doc_key": "ai-test-368", "ner": [[4, 5, "field"], [11, 13, "misc"], [19, 21, "misc"], [27, 29, "organisation"], [32, 34, "misc"], [40, 43, "organisation"], [46, 48, "misc"], [54, 58, "organisation"], [62, 64, "misc"], [70, 72, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[11, 13, 4, 5, "topic", "", false, false], [19, 21, 27, 29, "origin", "", false, false], [32, 34, 40, 43, "origin", "", false, false], [46, 48, 54, 58, "origin", "", false, false], [62, 64, 70, 72, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["For", "his", "research", "in", "cognitive", "psychology", ",", "he", "has", "received", "the", "Early", "Career", "Award", "(", "1984", ")", "and", "the", "Boyd", "McCandless", "Award", "(", "1986", ")", "from", "the", "American", "Psychological", "Association", ",", "the", "Troland", "Research", "Award", "(", "1993", ")", "from", "the", "National", "Academy", "of", "Sciences", ",", "the", "Henry", "Dale", "Prize", "(", "2004", ")", "from", "the", "Royal", "Institution", "of", "Great", "Britain", ",", "and", "the", "George", "Miller", "Prize", "(", "2010", ")", "from", "the", "Cognitive", "Neuroscience", "Society", "."], "sentence-detokenized": "For his research in cognitive psychology, he has received the Early Career Award (1984) and the Boyd McCandless Award (1986) from the American Psychological Association, the Troland Research Award (1993) from the National Academy of Sciences, the Henry Dale Prize (2004) from the Royal Institution of Great Britain, and the George Miller Prize (2010) from the Cognitive Neuroscience Society.", "token2charspan": [[0, 3], [4, 7], [8, 16], [17, 19], [20, 29], [30, 40], [40, 41], [42, 44], [45, 48], [49, 57], [58, 61], [62, 67], [68, 74], [75, 80], [81, 82], [82, 86], [86, 87], [88, 91], [92, 95], [96, 100], [101, 111], [112, 117], [118, 119], [119, 123], [123, 124], [125, 129], [130, 133], [134, 142], [143, 156], [157, 168], [168, 169], [170, 173], [174, 181], [182, 190], [191, 196], [197, 198], [198, 202], [202, 203], [204, 208], [209, 212], [213, 221], [222, 229], [230, 232], [233, 241], [241, 242], [243, 246], [247, 252], [253, 257], [258, 263], [264, 265], [265, 269], [269, 270], [271, 275], [276, 279], [280, 285], [286, 297], [298, 300], [301, 306], [307, 314], [314, 315], [316, 319], [320, 323], [324, 330], [331, 337], [338, 343], [344, 345], [345, 349], [349, 350], [351, 355], [356, 359], [360, 369], [370, 382], [383, 390], [390, 391]]}
{"doc_key": "ai-test-369", "ner": [[1, 1, "misc"], [7, 7, "misc"], [10, 12, "product"], [16, 16, "researcher"], [18, 18, "researcher"], [25, 26, "researcher"], [28, 29, "researcher"], [31, 32, "task"], [34, 37, "researcher"], [39, 43, "researcher"], [44, 45, "task"], [47, 47, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[1, 1, 7, 7, "named", "", false, false], [1, 1, 47, 47, "named", "", false, false], [7, 7, 16, 16, "origin", "", false, false], [7, 7, 18, 18, "origin", "", false, false], [7, 7, 31, 32, "related-to", "used_for", false, false], [10, 12, 7, 7, "usage", "", false, false], [10, 12, 44, 45, "named", "", false, false], [25, 26, 7, 7, "usage", "", false, false], [25, 26, 34, 37, "named", "same", false, false], [28, 29, 7, 7, "usage", "", false, false], [28, 29, 39, 43, "named", "same", false, false], [44, 45, 47, 47, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["An", "eigenface", "(", "The", "approach", "of", "using", "eigenfaces", "for", "a", "face", "recognition", "system", "was", "developed", "by", "Sirovich", "and", "Kirby", "(", "1987", ")", "and", "used", "by", "Matthew", "Turk", "and", "Alex", "Pentland", "in", "face", "classification", ".", "Turk", ",", "Matthew", "A.", "and", "Pentland", ",", "Alex", "P", ".", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "An eigenface (The approach of using eigenfaces for a face recognition system was developed by Sirovich and Kirby (1987) and used by Matthew Turk and Alex Pentland in face classification. Turk, Matthew A. and Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 2], [3, 12], [13, 14], [14, 17], [18, 26], [27, 29], [30, 35], [36, 46], [47, 50], [51, 52], [53, 57], [58, 69], [70, 76], [77, 80], [81, 90], [91, 93], [94, 102], [103, 106], [107, 112], [113, 114], [114, 118], [118, 119], [120, 123], [124, 128], [129, 131], [132, 139], [140, 144], [145, 148], [149, 153], [154, 162], [163, 165], [166, 170], [171, 185], [185, 186], [187, 191], [191, 192], [193, 200], [201, 203], [204, 207], [208, 216], [216, 217], [218, 222], [223, 224], [224, 225], [226, 230], [231, 242], [243, 248], [249, 259], [259, 260]]}
{"doc_key": "ai-test-370", "ner": [[5, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "lexical", "dictionary", "such", "as", "Word", "Net", "can", "then", "be", "consulted", "to", "understand", "the", "context", "."], "sentence-detokenized": "A lexical dictionary such as WordNet can then be consulted to understand the context.", "token2charspan": [[0, 1], [2, 9], [10, 20], [21, 25], [26, 28], [29, 33], [33, 36], [37, 40], [41, 45], [46, 48], [49, 58], [59, 61], [62, 72], [73, 76], [77, 84], [84, 85]]}
{"doc_key": "ai-test-371", "ner": [[0, 0, "misc"], [8, 8, "misc"], [15, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 8, "part-of", "", false, false], [8, 8, 15, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hyponymy", "is", "the", "most", "commonly", "encoded", "relationship", "between", "synsets", "used", "in", "lexical", "databases", "such", "as", "WordNet", "."], "sentence-detokenized": "Hyponymy is the most commonly encoded relationship between synsets used in lexical databases such as WordNet.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 20], [21, 29], [30, 37], [38, 50], [51, 58], [59, 66], [67, 71], [72, 74], [75, 82], [83, 92], [93, 97], [98, 100], [101, 108], [108, 109]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [7, 8, "programlang"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 7, 8, "general-affiliation", "", false, false], [0, 0, 10, 10, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "provides", "open", "-", "source", "libraries", "in", "C", "++", "and", "Java", ",", "but", "many", "customers", "rely", "on", "community", "-", "developed", "libraries", ",", "such", "as", "libraries", "that", "contain", "embedded", "functions", "for", "retrieving", "data", "(", "array", "-", "style", ")", "from", "DAP", "servers", "."], "sentence-detokenized": "OPeNDAP provides open-source libraries in C++ and Java, but many customers rely on community-developed libraries, such as libraries that contain embedded functions for retrieving data (array-style) from DAP servers.", "token2charspan": [[0, 7], [8, 16], [17, 21], [21, 22], [22, 28], [29, 38], [39, 41], [42, 43], [43, 45], [46, 49], [50, 54], [54, 55], [56, 59], [60, 64], [65, 74], [75, 79], [80, 82], [83, 92], [92, 93], [93, 102], [103, 112], [112, 113], [114, 118], [119, 121], [122, 131], [132, 136], [137, 144], [145, 153], [154, 163], [164, 167], [168, 178], [179, 183], [184, 185], [185, 190], [190, 191], [191, 196], [196, 197], [198, 202], [203, 206], [207, 214], [214, 215]]}
{"doc_key": "ai-test-373", "ner": [[4, 5, "misc"], [9, 9, "product"], [31, 32, "misc"], [47, 47, "product"], [49, 50, "organisation"], [51, 56, "product"]], "ner_mapping_to_source": [0, 1, 3, 5, 6, 7], "relations": [[31, 32, 9, 9, "part-of", "", false, false], [51, 56, 49, 50, "artifact", "", false, false]], "relations_mapping_to_source": [2, 4], "sentence": ["On", "this", "page", ",", "Samurai", "Damashii", "exaggeratedly", "portrayed", "the", "Senkousha", "as", "a", "crystallisation", "of", "China", "'s", "four", "thousand", "years", "of", "scientific", "knowledge", ",", "commented", "on", "the", "crude", "design", "(", "e.g.", "the", "Chinese", "cannon", "in", "the", "crotch", ")", "and", "placed", "his", "image", "next", "to", "images", "of", "Honda", "'s", "ASIMO", "and", "Sony", "'s", "QRIO", "SDR", "-", "3", "X", "for", "juxtaposition", "."], "sentence-detokenized": "On this page, Samurai Damashii exaggeratedly portrayed the Senkousha as a crystallisation of China's four thousand years of scientific knowledge, commented on the crude design (e.g. the Chinese cannon in the crotch) and placed his image next to images of Honda's ASIMO and Sony's QRIO SDR-3X for juxtaposition.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 21], [22, 30], [31, 44], [45, 54], [55, 58], [59, 68], [69, 71], [72, 73], [74, 89], [90, 92], [93, 98], [98, 100], [101, 105], [106, 114], [115, 120], [121, 123], [124, 134], [135, 144], [144, 145], [146, 155], [156, 158], [159, 162], [163, 168], [169, 175], [176, 177], [177, 181], [182, 185], [186, 193], [194, 200], [201, 203], [204, 207], [208, 214], [214, 215], [216, 219], [220, 226], [227, 230], [231, 236], [237, 241], [242, 244], [245, 251], [252, 254], [255, 260], [260, 262], [263, 268], [269, 272], [273, 277], [277, 279], [280, 284], [285, 288], [288, 289], [289, 290], [290, 291], [292, 295], [296, 309], [309, 310]]}
{"doc_key": "ai-test-374", "ner": [[8, 9, "algorithm"], [20, 20, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 20, 20, "part-of", "includes_functionality_of", false, false], [8, 9, 22, 22, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "also", "many", "programming", "libraries", "that", "contain", "neural", "network", "functions", "that", "can", "be", "used", "in", "custom", "implementations", "(", "e.g.", "TensorFlow", ",", "Theano", ",", "etc.", ")", "."], "sentence-detokenized": "There are also many programming libraries that contain neural network functions that can be used in custom implementations (e.g. TensorFlow, Theano, etc.).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 19], [20, 31], [32, 41], [42, 46], [47, 54], [55, 61], [62, 69], [70, 79], [80, 84], [85, 88], [89, 91], [92, 96], [97, 99], [100, 106], [107, 122], [123, 124], [124, 128], [129, 139], [139, 140], [141, 147], [147, 148], [149, 153], [153, 154], [154, 155]]}
{"doc_key": "ai-test-375", "ner": [[6, 9, "conference"], [11, 11, "organisation"], [13, 19, "conference"], [21, 21, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "Fellow", "of", "the", "Association", "for", "Computing", "Machinery", ",", "IEEE", ",", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "IAPR", "and", "SPIE", "."], "sentence-detokenized": "He is a Fellow of the Association for Computing Machinery, IEEE, American Association for the Advancement of Science, IAPR and SPIE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 33], [34, 37], [38, 47], [48, 57], [57, 58], [59, 63], [63, 64], [65, 73], [74, 85], [86, 89], [90, 93], [94, 105], [106, 108], [109, 116], [116, 117], [118, 122], [123, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-test-376", "ner": [[3, 3, "organisation"], [7, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 7, 8, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "trial", "by", "RET", "in", "2011", "of", "facial", "recognition", "cameras", "mounted", "on", "trams", "ensured", "that", "people", "who", "were", "denied", "access", "to", "the", "trams", "did", "not", "sneak", "in", "anyway", "."], "sentence-detokenized": "A trial by RET in 2011 of facial recognition cameras mounted on trams ensured that people who were denied access to the trams did not sneak in anyway.", "token2charspan": [[0, 1], [2, 7], [8, 10], [11, 14], [15, 17], [18, 22], [23, 25], [26, 32], [33, 44], [45, 52], [53, 60], [61, 63], [64, 69], [70, 77], [78, 82], [83, 89], [90, 93], [94, 98], [99, 105], [106, 112], [113, 115], [116, 119], [120, 125], [126, 129], [130, 133], [134, 139], [140, 142], [143, 149], [149, 150]]}
{"doc_key": "ai-test-377", "ner": [[3, 13, "person"], [17, 17, "person"], [20, 21, "person"], [25, 26, "person"], [28, 29, "person"], [31, 32, "person"], [34, 35, "person"], [37, 38, "person"], [40, 41, "person"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "film", ",", "based", "on", "the", "popular", "Broadway", "musical", "by", "Cole", "Porter", ",", "starred", "MGM", "singing", "duo", "Howard", "Keel", "and", "Kathryn", "Grayson", ",", "supported", "by", "Ann", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Van", ",", "James", "Whitmore", ",", "Kurt", "Kasznar", "and", "Tommy", "Rall", "."], "sentence-detokenized": "The film, based on the popular Broadway musical by Cole Porter, starred MGM singing duo Howard Keel and Kathryn Grayson, supported by Ann Miller, Keenan Wynn, Bobby Van, James Whitmore, Kurt Kasznar and Tommy Rall.", "token2charspan": [[0, 3], [4, 8], [8, 9], [10, 15], [16, 18], [19, 22], [23, 30], [31, 39], [40, 47], [48, 50], [51, 55], [56, 62], [62, 63], [64, 71], [72, 75], [76, 83], [84, 87], [88, 94], [95, 99], [100, 103], [104, 111], [112, 119], [119, 120], [121, 130], [131, 133], [134, 137], [138, 144], [144, 145], [146, 152], [153, 157], [157, 158], [159, 164], [165, 168], [168, 169], [170, 175], [176, 184], [184, 185], [186, 190], [191, 198], [199, 202], [203, 208], [209, 213], [213, 214]]}
{"doc_key": "ai-test-378", "ner": [[16, 19, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "applications", "should", "streamline", "call", "flow", ",", "minimise", "prompts", ",", "eliminate", "unnecessary", "iterations", "and", "enable", "sophisticated", "mixed", "initiative", "dialogues", "where", "the", "caller", "can", "enter", "multiple", "pieces", "of", "information", "in", "a", "single", "utterance", "and", "in", "any", "order", "or", "combination", "."], "sentence-detokenized": "Such applications should streamline call flow, minimise prompts, eliminate unnecessary iterations and enable sophisticated mixed initiative dialogues where the caller can enter multiple pieces of information in a single utterance and in any order or combination.", "token2charspan": [[0, 4], [5, 17], [18, 24], [25, 35], [36, 40], [41, 45], [45, 46], [47, 55], [56, 63], [63, 64], [65, 74], [75, 86], [87, 97], [98, 101], [102, 108], [109, 122], [123, 128], [129, 139], [140, 149], [150, 155], [156, 159], [160, 166], [167, 170], [171, 176], [177, 185], [186, 192], [193, 195], [196, 207], [208, 210], [211, 212], [213, 219], [220, 229], [230, 233], [234, 236], [237, 240], [241, 246], [247, 249], [250, 261], [261, 262]]}
{"doc_key": "ai-test-379", "ner": [[4, 4, "algorithm"], [7, 9, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 9, 4, 4, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Thus", ",", "conventional", "gradient", "descent", "(", "or", "stochastic", "gradient", "descent", ")", "methods", "can", "be", "adapted", ",", "where", "instead", "of", "taking", "a", "step", "in", "the", "direction", "of", "the", "function", "gradient", ",", "a", "step", "is", "taken", "in", "the", "direction", "of", "a", "vector", "selected", "from", "the", "partial", "gradient", "of", "the", "function", "."], "sentence-detokenized": "Thus, conventional gradient descent (or stochastic gradient descent) methods can be adapted, where instead of taking a step in the direction of the function gradient, a step is taken in the direction of a vector selected from the partial gradient of the function.", "token2charspan": [[0, 4], [4, 5], [6, 18], [19, 27], [28, 35], [36, 37], [37, 39], [40, 50], [51, 59], [60, 67], [67, 68], [69, 76], [77, 80], [81, 83], [84, 91], [91, 92], [93, 98], [99, 106], [107, 109], [110, 116], [117, 118], [119, 123], [124, 126], [127, 130], [131, 140], [141, 143], [144, 147], [148, 156], [157, 165], [165, 166], [167, 168], [169, 173], [174, 176], [177, 182], [183, 185], [186, 189], [190, 199], [200, 202], [203, 204], [205, 211], [212, 220], [221, 225], [226, 229], [230, 237], [238, 246], [247, 249], [250, 253], [254, 262], [262, 263]]}
{"doc_key": "ai-test-380", "ner": [[8, 10, "metrics"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Assuming", "that", "the", "distortion", "is", "measured", "by", "the", "mean", "square", "error", ",", "the", "distortion", "D", "is", "given", "by", ":"], "sentence-detokenized": "Assuming that the distortion is measured by the mean square error, the distortion D is given by:", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 28], [29, 31], [32, 40], [41, 43], [44, 47], [48, 52], [53, 59], [60, 65], [65, 66], [67, 70], [71, 81], [82, 83], [84, 86], [87, 92], [93, 95], [95, 96]]}
{"doc_key": "ai-test-381", "ner": [[0, 0, "algorithm"], [4, 5, "field"], [17, 18, "task"], [20, 21, "task"], [23, 23, "task"], [27, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 4, 5, "part-of", "", false, false], [17, 18, 0, 0, "part-of", "", false, false], [20, 21, 0, 0, "part-of", "", false, false], [23, 23, 0, 0, "part-of", "", false, false], [27, 28, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["MLPs", "were", "a", "popular", "machine", "learning", "solution", "in", "the", "1980s", ",", "applied", "in", "various", "fields", "such", "as", "speech", "recognition", ",", "image", "recognition", "and", "machine", "translation", "software", ",", "neural", "networks", "."], "sentence-detokenized": "MLPs were a popular machine learning solution in the 1980s, applied in various fields such as speech recognition, image recognition and machine translation software, neural networks.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 19], [20, 27], [28, 36], [37, 45], [46, 48], [49, 52], [53, 58], [58, 59], [60, 67], [68, 70], [71, 78], [79, 85], [86, 90], [91, 93], [94, 100], [101, 112], [112, 113], [114, 119], [120, 131], [132, 135], [136, 143], [144, 155], [156, 164], [164, 165], [166, 172], [173, 181], [181, 182]]}
{"doc_key": "ai-test-382", "ner": [[0, 0, "researcher"], [1, 4, "misc"], [6, 9, "university"], [15, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 9, "physical", "", false, false], [0, 0, 6, 9, "role", "", false, false], [1, 4, 0, 0, "origin", "", false, false], [15, 17, 0, 0, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "received", "his", "PhD", "from", "the", "University", "of", "Toronto", "in", "1979", "under", "the", "supervision", "of", "C.", "Raymond", "Perrault", ","], "sentence-detokenized": "Allen received his PhD from the University of Toronto in 1979 under the supervision of C. Raymond Perrault,", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 22], [23, 27], [28, 31], [32, 42], [43, 45], [46, 53], [54, 56], [57, 61], [62, 67], [68, 71], [72, 83], [84, 86], [87, 89], [90, 97], [98, 106], [106, 107]]}
{"doc_key": "ai-test-383", "ner": [[0, 0, "product"], [5, 7, "field"], [10, 10, "product"], [12, 12, "product"], [14, 14, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6], "relations": [[0, 0, 5, 7, "related-to", "supports", false, false], [10, 10, 5, 7, "type-of", "", true, false], [12, 12, 5, 7, "type-of", "", true, false], [14, 14, 5, 7, "type-of", "", true, false], [24, 24, 5, 7, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5], "sentence": ["OpenCV", "supports", "some", "models", "from", "deep", "learning", "frameworks", "such", "as", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "after", "conversion", "to", "an", "ONNX", "model", ")", "and", "Caffe", "according", "to", "a", "defined", "list", "of", "supported", "layers", "."], "sentence-detokenized": "OpenCV supports some models from deep learning frameworks such as TensorFlow, Torch, PyTorch (after conversion to an ONNX model) and Caffe according to a defined list of supported layers.", "token2charspan": [[0, 6], [7, 15], [16, 20], [21, 27], [28, 32], [33, 37], [38, 46], [47, 57], [58, 62], [63, 65], [66, 76], [76, 77], [78, 83], [83, 84], [85, 92], [93, 94], [94, 99], [100, 110], [111, 113], [114, 116], [117, 121], [122, 127], [127, 128], [129, 132], [133, 138], [139, 148], [149, 151], [152, 153], [154, 161], [162, 166], [167, 169], [170, 179], [180, 186], [186, 187]]}
{"doc_key": "ai-test-384", "ner": [[2, 2, "researcher"], [9, 12, "organisation"], [14, 14, "organisation"], [18, 22, "organisation"], [19, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 9, 12, "role", "", false, false], [2, 2, 18, 22, "role", "", false, false], [2, 2, 19, 26, "related-to", "lectures_in", false, false], [14, 14, 9, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Previously", ",", "Christensen", "was", "the", "founding", "chair", "of", "the", "European", "Robotics", "Research", "Network", "(", "EURON", ")", "and", "an", "IEEE", "Robotics", "and", "Automation", "Society", "Distinguished", "Lecturer", "in", "Robotics", "."], "sentence-detokenized": "Previously, Christensen was the founding chair of the European Robotics Research Network (EURON) and an IEEE Robotics and Automation Society Distinguished Lecturer in Robotics.", "token2charspan": [[0, 10], [10, 11], [12, 23], [24, 27], [28, 31], [32, 40], [41, 46], [47, 49], [50, 53], [54, 62], [63, 71], [72, 80], [81, 88], [89, 90], [90, 95], [95, 96], [97, 100], [101, 103], [104, 108], [109, 117], [118, 121], [122, 132], [133, 140], [141, 154], [155, 163], [164, 166], [167, 175], [175, 176]]}
{"doc_key": "ai-test-385", "ner": [[7, 7, "field"], [9, 11, "university"], [13, 13, "location"], [15, 18, "country"], [24, 24, "misc"], [26, 26, "field"], [29, 32, "organisation"], [34, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[9, 11, 13, 13, "physical", "", false, false], [13, 13, 15, 18, "physical", "", false, false], [24, 24, 26, 26, "topic", "", false, false], [29, 32, 34, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "earned", "a", "master", "'s", "degree", "in", "mathematics", "from", "Samarkand", "State", "University", ",", "Samarkand", ",", "Uzbek", "Soviet", "Socialist", "Republic", ",", "in", "1958", "and", "a", "doctorate", "in", "statistics", "from", "the", "Institute", "of", "Control", "Sciences", "in", "Moscow", "in", "1964", "."], "sentence-detokenized": "He earned a master's degree in mathematics from Samarkand State University, Samarkand, Uzbek Soviet Socialist Republic, in 1958 and a doctorate in statistics from the Institute of Control Sciences in Moscow in 1964.", "token2charspan": [[0, 2], [3, 9], [10, 11], [12, 18], [18, 20], [21, 27], [28, 30], [31, 42], [43, 47], [48, 57], [58, 63], [64, 74], [74, 75], [76, 85], [85, 86], [87, 92], [93, 99], [100, 109], [110, 118], [118, 119], [120, 122], [123, 127], [128, 131], [132, 133], [134, 143], [144, 146], [147, 157], [158, 162], [163, 166], [167, 176], [177, 179], [180, 187], [188, 196], [197, 199], [200, 206], [207, 209], [210, 214], [214, 215]]}
{"doc_key": "ai-test-386", "ner": [[7, 7, "organisation"], [12, 13, "product"], [31, 32, "field"], [34, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 31, 32, "usage", "", false, false], [7, 7, 34, 36, "usage", "", false, false], [12, 13, 7, 7, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Increasingly", ",", "however", ",", "the", "work", "at", "Cycorp", "is", "to", "enable", "the", "Cyc", "system", "to", "communicate", "with", "end", "users", "in", "natural", "language", "and", "to", "support", "the", "ongoing", "knowledge", "creation", "process", "through", "machine", "learning", "and", "natural", "language", "understanding", "."], "sentence-detokenized": "Increasingly, however, the work at Cycorp is to enable the Cyc system to communicate with end users in natural language and to support the ongoing knowledge creation process through machine learning and natural language understanding.", "token2charspan": [[0, 12], [12, 13], [14, 21], [21, 22], [23, 26], [27, 31], [32, 34], [35, 41], [42, 44], [45, 47], [48, 54], [55, 58], [59, 62], [63, 69], [70, 72], [73, 84], [85, 89], [90, 93], [94, 99], [100, 102], [103, 110], [111, 119], [120, 123], [124, 126], [127, 134], [135, 138], [139, 146], [147, 156], [157, 165], [166, 173], [174, 181], [182, 189], [190, 198], [199, 202], [203, 210], [211, 219], [220, 233], [233, 234]]}
{"doc_key": "ai-test-387", "ner": [[55, 55, "metrics"], [57, 57, "metrics"], [59, 59, "metrics"], [61, 64, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "when", "searching", "for", "the", "most", "suitable", "classifier", "for", "a", "problem", ",", "the", "training", "dataset", "is", "used", "to", "train", "the", "candidate", "algorithms", ",", "the", "validation", "dataset", "is", "used", "to", "compare", "their", "performances", "and", "decide", "which", "one", "to", "choose", ",", "and", "finally", "the", "test", "dataset", "is", "used", "to", "obtain", "the", "performance", "characteristics", "such", "as", "accuracy", ",", "sensitivity", ",", "specificity", ",", "F-", "measure", ",", "etc", "."], "sentence-detokenized": "For example, when searching for the most suitable classifier for a problem, the training dataset is used to train the candidate algorithms, the validation dataset is used to compare their performances and decide which one to choose, and finally the test dataset is used to obtain the performance characteristics such as accuracy, sensitivity, specificity, F-measure, etc.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [18, 27], [28, 31], [32, 35], [36, 40], [41, 49], [50, 60], [61, 64], [65, 66], [67, 74], [74, 75], [76, 79], [80, 88], [89, 96], [97, 99], [100, 104], [105, 107], [108, 113], [114, 117], [118, 127], [128, 138], [138, 139], [140, 143], [144, 154], [155, 162], [163, 165], [166, 170], [171, 173], [174, 181], [182, 187], [188, 200], [201, 204], [205, 211], [212, 217], [218, 221], [222, 224], [225, 231], [231, 232], [233, 236], [237, 244], [245, 248], [249, 253], [254, 261], [262, 264], [265, 269], [270, 272], [273, 279], [280, 283], [284, 295], [296, 311], [312, 316], [317, 319], [320, 328], [328, 329], [330, 341], [341, 342], [343, 354], [354, 355], [356, 358], [358, 365], [365, 366], [367, 370], [370, 371]]}
{"doc_key": "ai-test-388", "ner": [[1, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "square", "error", "is", "0.15", "."], "sentence-detokenized": "The mean square error is 0.15.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 21], [22, 24], [25, 29], [29, 30]]}
{"doc_key": "ai-test-389", "ner": [[4, 5, "misc"], [10, 10, "organisation"], [16, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 10, 4, 5, "role", "", false, false], [16, 16, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1979", ",", "a", "micromouse", "competition", "was", "organised", "by", "the", "IEEE", "and", "published", "in", "the", "journal", "Spectrum", "."], "sentence-detokenized": "In 1979, a micromouse competition was organised by the IEEE and published in the journal Spectrum.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 21], [22, 33], [34, 37], [38, 47], [48, 50], [51, 54], [55, 59], [60, 63], [64, 73], [74, 76], [77, 80], [81, 88], [89, 97], [97, 98]]}
{"doc_key": "ai-test-390", "ner": [[0, 1, "algorithm"], [11, 13, "task"], [15, 16, "task"], [18, 19, "task"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Gabor", "space", "is", "very", "useful", "in", "image", "processing", "applications", "such", "as", "optical", "character", "recognition", ",", "iris", "recognition", "and", "fingerprint", "recognition", "."], "sentence-detokenized": "Gabor space is very useful in image processing applications such as optical character recognition, iris recognition and fingerprint recognition.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 19], [20, 26], [27, 29], [30, 35], [36, 46], [47, 59], [60, 64], [65, 67], [68, 75], [76, 85], [86, 97], [97, 98], [99, 103], [104, 115], [116, 119], [120, 131], [132, 143], [143, 144]]}
{"doc_key": "ai-test-391", "ner": [[7, 7, "programlang"], [9, 9, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", "via", "high", "-", "level", "interfaces", "to", "Java", "and", "Tcl", "."], "sentence-detokenized": "or via high-level interfaces to Java and Tcl.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [12, 17], [18, 28], [29, 31], [32, 36], [37, 40], [41, 44], [44, 45]]}
{"doc_key": "ai-test-392", "ner": [[18, 18, "field"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "recent", "research", ",", "kernel", "-", "based", "methods", "such", "as", "support", "vector", "machines", "have", "shown", "superior", "performance", "in", "monitoring", "."], "sentence-detokenized": "In recent research, kernel-based methods such as support vector machines have shown superior performance in monitoring.", "token2charspan": [[0, 2], [3, 9], [10, 18], [18, 19], [20, 26], [26, 27], [27, 32], [33, 40], [41, 45], [46, 48], [49, 56], [57, 63], [64, 72], [73, 77], [78, 83], [84, 92], [93, 104], [105, 107], [108, 118], [118, 119]]}
{"doc_key": "ai-test-393", "ner": [[14, 14, "misc"], [23, 23, "researcher"], [25, 25, "researcher"], [32, 32, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 32, 32, "usage", "", false, false], [25, 25, 32, 32, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["To", "illustrate", "the", "basic", "principles", "of", "dredging", ",", "an", "analysis", "of", "the", "relationship", "between", "ozone", "and", "temperature", "is", "presented", "below", "(", "data", "from", "Rousseeuw", "and", "Leroy", "(", "1986", ")", ",", "analysis", "in", "R", ")", "."], "sentence-detokenized": "To illustrate the basic principles of dredging, an analysis of the relationship between ozone and temperature is presented below (data from Rousseeuw and Leroy (1986), analysis in R).", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 23], [24, 34], [35, 37], [38, 46], [46, 47], [48, 50], [51, 59], [60, 62], [63, 66], [67, 79], [80, 87], [88, 93], [94, 97], [98, 109], [110, 112], [113, 122], [123, 128], [129, 130], [130, 134], [135, 139], [140, 149], [150, 153], [154, 159], [160, 161], [161, 165], [165, 166], [166, 167], [168, 176], [177, 179], [180, 181], [181, 182], [182, 183]]}
{"doc_key": "ai-test-394", "ner": [[0, 1, "organisation"], [18, 19, "product"], [21, 23, "product"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[18, 19, 0, 1, "artifact", "", false, false], [21, 23, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["Denso", "Wave", "is", "a", "subsidiary", "that", "manufactures", "automatic", "identification", "products", "(", "barcode", "readers", "and", "related", "products", ")", ",", "industrial", "robots", "and", "programmable", "logic", "controllers", "."], "sentence-detokenized": "Denso Wave is a subsidiary that manufactures automatic identification products (barcode readers and related products), industrial robots and programmable logic controllers.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 15], [16, 26], [27, 31], [32, 44], [45, 54], [55, 69], [70, 78], [79, 80], [80, 87], [88, 95], [96, 99], [100, 107], [108, 116], [116, 117], [117, 118], [119, 129], [130, 136], [137, 140], [141, 153], [154, 159], [160, 171], [171, 172]]}
{"doc_key": "ai-test-395", "ner": [[2, 4, "metrics"], [8, 9, "metrics"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 4, 17, 17, "compare", "", false, false], [8, 9, 2, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["While", "the", "bilingual", "evaluation", "study", "only", "calculates", "the", "precision", "of", "the", "n-grams", "and", "weights", "them", "equally", ",", "NIST", "also", "calculates", "how", "informative", "a", "given", "n-", "gram", "is", "."], "sentence-detokenized": "While the bilingual evaluation study only calculates the precision of the n-grams and weights them equally, NIST also calculates how informative a given n-gram is.", "token2charspan": [[0, 5], [6, 9], [10, 19], [20, 30], [31, 36], [37, 41], [42, 52], [53, 56], [57, 66], [67, 69], [70, 73], [74, 81], [82, 85], [86, 93], [94, 98], [99, 106], [106, 107], [108, 112], [113, 117], [118, 128], [129, 132], [133, 144], [145, 146], [147, 152], [153, 155], [155, 159], [160, 162], [162, 163]]}
{"doc_key": "ai-test-396", "ner": [[15, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "particular", ",", "they", "are", "used", "in", "calculating", "the", "likelihood", "of", "a", "tree", "(", "in", "Bayesian", "and", "maximum", "likelihood", "approaches", "to", "tree", "estimation", ")", "and", "in", "estimating", "the", "evolutionary", "distance", "between", "sequences", "based", "on", "the", "observed", "differences", "between", "sequences", "."], "sentence-detokenized": "In particular, they are used in calculating the likelihood of a tree (in Bayesian and maximum likelihood approaches to tree estimation) and in estimating the evolutionary distance between sequences based on the observed differences between sequences.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 19], [20, 23], [24, 28], [29, 31], [32, 43], [44, 47], [48, 58], [59, 61], [62, 63], [64, 68], [69, 70], [70, 72], [73, 81], [82, 85], [86, 93], [94, 104], [105, 115], [116, 118], [119, 123], [124, 134], [134, 135], [136, 139], [140, 142], [143, 153], [154, 157], [158, 170], [171, 179], [180, 187], [188, 197], [198, 203], [204, 206], [207, 210], [211, 219], [220, 231], [232, 239], [240, 249], [249, 250]]}
{"doc_key": "ai-test-397", "ner": [[1, 3, "conference"], [20, 21, "misc"], [23, 23, "misc"], [46, 47, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 20, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Audio", "Engineering", "Society", "recommends", "a", "sampling", "rate", "of", "48", "kHz", "for", "most", "applications", ",", "but", "recognises", "44.1", "kHz", "for", "compact", "disc", "(", "CD", ")", "and", "other", "consumer", "applications", ",", "32", "kHz", "for", "transmission", "-", "related", "applications", ",", "and", "96", "kHz", "for", "higher", "bandwidth", "or", "relaxed", "anti-aliasing", "filters", "."], "sentence-detokenized": "The Audio Engineering Society recommends a sampling rate of 48 kHz for most applications, but recognises 44.1 kHz for compact disc (CD) and other consumer applications, 32 kHz for transmission-related applications, and 96 kHz for higher bandwidth or relaxed anti-aliasing filters.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 29], [30, 40], [41, 42], [43, 51], [52, 56], [57, 59], [60, 62], [63, 66], [67, 70], [71, 75], [76, 88], [88, 89], [90, 93], [94, 104], [105, 109], [110, 113], [114, 117], [118, 125], [126, 130], [131, 132], [132, 134], [134, 135], [136, 139], [140, 145], [146, 154], [155, 167], [167, 168], [169, 171], [172, 175], [176, 179], [180, 192], [192, 193], [193, 200], [201, 213], [213, 214], [215, 218], [219, 221], [222, 225], [226, 229], [230, 236], [237, 246], [247, 249], [250, 257], [258, 271], [272, 279], [279, 280]]}
{"doc_key": "ai-test-398", "ner": [[11, 11, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Resources", "for", "the", "affectivity", "of", "words", "and", "concepts", "were", "developed", "for", "WordNet", "{", "{", "cite", "journal"], "sentence-detokenized": "Resources for the affectivity of words and concepts were developed for WordNet {{cite journal", "token2charspan": [[0, 9], [10, 13], [14, 17], [18, 29], [30, 32], [33, 38], [39, 42], [43, 51], [52, 56], [57, 66], [67, 70], [71, 78], [79, 80], [80, 81], [81, 85], [86, 93]]}
{"doc_key": "ai-test-399", "ner": [[1, 4, "misc"], [22, 23, "person"], [28, 31, "person"], [36, 38, "person"], [47, 50, "organisation"], [67, 68, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[28, 31, 36, 38, "role", "acts_in", false, false], [47, 50, 36, 38, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "red", "and", "green", "anaglyph", ",", "the", "audience", "was", "presented", "with", "three", "test", "reels", ",", "including", "rural", "scenes", ",", "test", "footage", "of", "Marie", "Doro", ",", "a", "clip", "of", "John", "B", ".", "Mason", "playing", "some", "passages", "from", "Jim", "the", "Penman", "(", "a", "film", "released", "the", "same", "year", "by", "Famous", "Players", "-", "Lasky", ",", "but", "not", "in", "3D", ")", ",", "oriental", "dancers", ",", "and", "a", "reel", "with", "footage", "of", "Niagara", "Falls", "."], "sentence-detokenized": "In red and green anaglyph, the audience was presented with three test reels, including rural scenes, test footage of Marie Doro, a clip of John B. Mason playing some passages from Jim the Penman (a film released the same year by Famous Players-Lasky, but not in 3D), oriental dancers, and a reel with footage of Niagara Falls.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 16], [17, 25], [25, 26], [27, 30], [31, 39], [40, 43], [44, 53], [54, 58], [59, 64], [65, 69], [70, 75], [75, 76], [77, 86], [87, 92], [93, 99], [99, 100], [101, 105], [106, 113], [114, 116], [117, 122], [123, 127], [127, 128], [129, 130], [131, 135], [136, 138], [139, 143], [144, 145], [145, 146], [147, 152], [153, 160], [161, 165], [166, 174], [175, 179], [180, 183], [184, 187], [188, 194], [195, 196], [196, 197], [198, 202], [203, 211], [212, 215], [216, 220], [221, 225], [226, 228], [229, 235], [236, 243], [243, 244], [244, 249], [249, 250], [251, 254], [255, 258], [259, 261], [262, 264], [264, 265], [265, 266], [267, 275], [276, 283], [283, 284], [285, 288], [289, 290], [291, 295], [296, 300], [301, 308], [309, 311], [312, 319], [320, 325], [325, 326]]}
{"doc_key": "ai-test-400", "ner": [[7, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "particular", "way", "of", "implementing", "maximum", "likelihood", "estimation", "for", "this", "problem", "."], "sentence-detokenized": "This is a particular way of implementing maximum likelihood estimation for this problem.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 20], [21, 24], [25, 27], [28, 40], [41, 48], [49, 59], [60, 70], [71, 74], [75, 79], [80, 87], [87, 88]]}
{"doc_key": "ai-test-401", "ner": [[0, 4, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["crawler", "-", "friendly", "web", "servers", ",", "and", "it", "integrates", "the", "functions", "of", "sitemaps", "and", "RSS", "feeds", "into", "a", "decentralised", "mechanism", "for", "computational", "biologists", "and", "bioinformaticians", "to", "openly", "disseminate", "and", "retrieve", "metadata", "about", "biomedical", "resources", "."], "sentence-detokenized": "crawler-friendly web servers, and it integrates the functions of sitemaps and RSS feeds into a decentralised mechanism for computational biologists and bioinformaticians to openly disseminate and retrieve metadata about biomedical resources.", "token2charspan": [[0, 7], [7, 8], [8, 16], [17, 20], [21, 28], [28, 29], [30, 33], [34, 36], [37, 47], [48, 51], [52, 61], [62, 64], [65, 73], [74, 77], [78, 81], [82, 87], [88, 92], [93, 94], [95, 108], [109, 118], [119, 122], [123, 136], [137, 147], [148, 151], [152, 169], [170, 172], [173, 179], [180, 191], [192, 195], [196, 204], [205, 213], [214, 219], [220, 230], [231, 240], [240, 241]]}
{"doc_key": "ai-test-402", "ner": [[5, 12, "misc"], [15, 20, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "covered", "by", "the", "American", "National", "Standards", "Institute", "/", "NISO", "standard", "Z39.50", "and", "the", "International", "Organization", "for", "Standardization", "standard", "23950", "."], "sentence-detokenized": "It is covered by the American National Standards Institute / NISO standard Z39.50 and the International Organization for Standardization standard 23950.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 20], [21, 29], [30, 38], [39, 48], [49, 58], [59, 60], [61, 65], [66, 74], [75, 81], [82, 85], [86, 89], [90, 103], [104, 116], [117, 120], [121, 136], [137, 145], [146, 151], [151, 152]]}
{"doc_key": "ai-test-403", "ner": [[13, 17, "misc"], [23, 23, "metrics"], [27, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "encoder", "and", "decoder", "are", "trained", "to", "take", "a", "phrase", "and", "reproduce", "the", "one", "-", "hot", "distribution", "of", "a", "corresponding", "paraphrase", "by", "minimising", "perplexity", "using", "a", "simple", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The encoder and decoder are trained to take a phrase and reproduce the one-hot distribution of a corresponding paraphrase by minimising perplexity using a simple stochastic gradient descent.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 27], [28, 35], [36, 38], [39, 43], [44, 45], [46, 52], [53, 56], [57, 66], [67, 70], [71, 74], [74, 75], [75, 78], [79, 91], [92, 94], [95, 96], [97, 110], [111, 121], [122, 124], [125, 135], [136, 146], [147, 152], [153, 154], [155, 161], [162, 172], [173, 181], [182, 189], [189, 190]]}
{"doc_key": "ai-test-404", "ner": [[8, 10, "task"], [12, 17, "task"], [27, 31, "task"], [33, 39, "task"], [41, 47, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "typical", "applications", "of", "pattern", "recognition", "techniques", "are", "automatic", "speech", "recognition", ",", "classification", "of", "text", "into", "different", "categories", "(", "e.g.", "spam", "/", "non", "-spam", "emails", ")", ",", "handwriting", "recognition", "on", "postal", "envelopes", ",", "automatic", "recognition", "of", "images", "of", "human", "faces", "or", "extraction", "of", "handwriting", "images", "from", "medical", "forms", "."], "sentence-detokenized": "Other typical applications of pattern recognition techniques are automatic speech recognition, classification of text into different categories (e.g. spam/non-spam emails), handwriting recognition on postal envelopes, automatic recognition of images of human faces or extraction of handwriting images from medical forms.", "token2charspan": [[0, 5], [6, 13], [14, 26], [27, 29], [30, 37], [38, 49], [50, 60], [61, 64], [65, 74], [75, 81], [82, 93], [93, 94], [95, 109], [110, 112], [113, 117], [118, 122], [123, 132], [133, 143], [144, 145], [145, 149], [150, 154], [154, 155], [155, 158], [158, 163], [164, 170], [170, 171], [171, 172], [173, 184], [185, 196], [197, 199], [200, 206], [207, 216], [216, 217], [218, 227], [228, 239], [240, 242], [243, 249], [250, 252], [253, 258], [259, 264], [265, 267], [268, 278], [279, 281], [282, 293], [294, 300], [301, 305], [306, 313], [314, 319], [319, 320]]}
{"doc_key": "ai-test-405", "ner": [[0, 2, "algorithm"], [13, 14, "field"], [16, 17, "task"], [19, 20, "task"], [22, 24, "task"], [26, 29, "task"], [32, 33, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 14, 0, 2, "usage", "", false, false], [16, 17, 0, 2, "usage", "", false, false], [19, 20, 0, 2, "usage", "", false, false], [22, 24, 0, 2, "usage", "", false, false], [26, 29, 0, 2, "usage", "", false, false], [32, 33, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Artificial", "neural", "networks", "have", "been", "used", "for", "a", "variety", "of", "tasks", ",", "including", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "board", "and", "video", "games", ",", "and", "medical", "diagnosis", "."], "sentence-detokenized": "Artificial neural networks have been used for a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, board and video games, and medical diagnosis.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 31], [32, 36], [37, 41], [42, 45], [46, 47], [48, 55], [56, 58], [59, 64], [64, 65], [66, 75], [76, 84], [85, 91], [91, 92], [93, 99], [100, 111], [111, 112], [113, 120], [121, 132], [132, 133], [134, 140], [141, 148], [149, 158], [158, 159], [160, 165], [166, 169], [170, 175], [176, 181], [181, 182], [183, 186], [187, 194], [195, 204], [204, 205]]}
{"doc_key": "ai-test-406", "ner": [[2, 3, "organisation"], [4, 4, "product"], [18, 18, "organisation"], [19, 20, "product"], [22, 22, "product"], [24, 26, "product"], [28, 28, "product"], [30, 30, "programlang"], [38, 40, "field"], [48, 48, "algorithm"], [50, 50, "algorithm"], [52, 52, "algorithm"], [56, 56, "product"], [74, 74, "product"], [76, 76, "product"], [78, 80, "product"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 17, 18, 19], "relations": [[4, 4, 2, 3, "origin", "", false, false], [30, 30, 38, 40, "related-to", "used_for", false, false], [48, 48, 30, 30, "part-of", "", true, false], [50, 50, 30, 30, "part-of", "", true, false], [52, 52, 30, 30, "part-of", "", true, false]], "relations_mapping_to_source": [0, 3, 4, 6, 8], "sentence": ["Examples", "include", "Salford", "Systems", "CART", "(", "which", "licensed", "the", "proprietary", "code", "of", "the", "original", "CART", "authors", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "an", "open", "source", "software", "environment", "for", "statistical", "computing", "that", "includes", "several", "CART", "implementations", "such", "as", "the", "rpart", ",", "party", "and", "randomForest", "packages", ")", ",", "Weka", "(", "a", "free", "and", "open", "source", "data", "mining", "suite", "that", "includes", "many", "decision", "tree", "algorithms", ")", ",", "Orange", ",", "KNIME", ",", "Microsoft", "SQL", "Server", "programming", "language", ")", "."], "sentence-detokenized": "Examples include Salford Systems CART (which licensed the proprietary code of the original CART authors), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (an open source software environment for statistical computing that includes several CART implementations such as the rpart, party and randomForest packages), Weka (a free and open source data mining suite that includes many decision tree algorithms), Orange, KNIME, Microsoft SQL Server programming language).", "token2charspan": [[0, 8], [9, 16], [17, 24], [25, 32], [33, 37], [38, 39], [39, 44], [45, 53], [54, 57], [58, 69], [70, 74], [75, 77], [78, 81], [82, 90], [91, 95], [96, 103], [103, 104], [104, 105], [106, 109], [110, 114], [115, 122], [122, 123], [124, 134], [134, 135], [136, 139], [140, 150], [151, 156], [156, 157], [158, 164], [164, 165], [166, 167], [168, 169], [169, 171], [172, 176], [177, 183], [184, 192], [193, 204], [205, 208], [209, 220], [221, 230], [231, 235], [236, 244], [245, 252], [253, 257], [258, 273], [274, 278], [279, 281], [282, 285], [286, 291], [291, 292], [293, 298], [299, 302], [303, 315], [316, 324], [324, 325], [325, 326], [327, 331], [332, 333], [333, 334], [335, 339], [340, 343], [344, 348], [349, 355], [356, 360], [361, 367], [368, 373], [374, 378], [379, 387], [388, 392], [393, 401], [402, 406], [407, 417], [417, 418], [418, 419], [420, 426], [426, 427], [428, 433], [433, 434], [435, 444], [445, 448], [449, 455], [456, 467], [468, 476], [476, 477], [477, 478]]}
{"doc_key": "ai-test-407", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [12, 13, "researcher"], [15, 16, "university"], [18, 20, "researcher"], [21, 24, "organisation"], [26, 28, "organisation"], [33, 35, "researcher"], [37, 39, "researcher"], [41, 44, "organisation"], [56, 59, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 12, 13, "origin", "", false, false], [0, 2, 18, 20, "origin", "", false, false], [0, 2, 33, 35, "origin", "", false, false], [0, 2, 37, 39, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [12, 13, 15, 16, "physical", "", false, false], [12, 13, 15, 16, "role", "", false, false], [18, 20, 21, 24, "physical", "", false, false], [18, 20, 21, 24, "role", "", false, false], [26, 28, 21, 24, "named", "", false, false], [33, 35, 41, 44, "physical", "", false, false], [33, 35, 41, 44, "role", "", false, false], [37, 39, 41, 44, "physical", "", false, false], [37, 39, 41, 44, "role", "", false, false], [56, 59, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", "was", "first", "developed", "in", "1966", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "and", "then", "further", "developed", "by", "Bishnu", "S.", "Atal", "and", "Manfred", "R.", "Schroeder", "at", "Bell", "Labs", "in", "the", "early", "to", "mid-1970s", "and", "served", "as", "the", "basis", "for", "the", "first", "speech", "synthesiser", "DSP", "chips", "in", "the", "late", "1970s", "."], "sentence-detokenized": "Linear predictive coding (LPC) was first developed in 1966 by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) and then further developed by Bishnu S. Atal and Manfred R. Schroeder at Bell Labs in the early to mid-1970s and served as the basis for the first speech synthesiser DSP chips in the late 1970s.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [31, 34], [35, 40], [41, 50], [51, 53], [54, 58], [59, 61], [62, 70], [71, 78], [79, 81], [82, 88], [89, 99], [100, 103], [104, 109], [110, 115], [116, 118], [119, 125], [126, 135], [136, 139], [140, 149], [150, 151], [151, 154], [154, 155], [156, 159], [160, 164], [165, 172], [173, 182], [183, 185], [186, 192], [193, 195], [196, 200], [201, 204], [205, 212], [213, 215], [216, 225], [226, 228], [229, 233], [234, 238], [239, 241], [242, 245], [246, 251], [252, 254], [255, 264], [265, 268], [269, 275], [276, 278], [279, 282], [283, 288], [289, 292], [293, 296], [297, 302], [303, 309], [310, 321], [322, 325], [326, 331], [332, 334], [335, 338], [339, 343], [344, 349], [349, 350]]}
{"doc_key": "ai-test-408", "ner": [[1, 3, "metrics"], [8, 8, "metrics"], [10, 11, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 1, 3, "part-of", "", false, false], [10, 11, 1, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "F", "-", "Score", "is", "a", "combination", "of", "Precision", "and", "Recall", "that", "results", "in", "a", "single", "score", "."], "sentence-detokenized": "An F-Score is a combination of Precision and Recall that results in a single score.", "token2charspan": [[0, 2], [3, 4], [4, 5], [5, 10], [11, 13], [14, 15], [16, 27], [28, 30], [31, 40], [41, 44], [45, 51], [52, 56], [57, 64], [65, 67], [68, 69], [70, 76], [77, 82], [82, 83]]}
{"doc_key": "ai-test-409", "ner": [[8, 10, "task"], [14, 16, "product"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Image", "analysis", "tasks", "can", "be", "as", "simple", "as", "reading", "barcodes", "or", "as", "sophisticated", "as", "facial", "recognition", "systems", "."], "sentence-detokenized": "Image analysis tasks can be as simple as reading barcodes or as sophisticated as facial recognition systems.", "token2charspan": [[0, 5], [6, 14], [15, 20], [21, 24], [25, 27], [28, 30], [31, 37], [38, 40], [41, 48], [49, 57], [58, 60], [61, 63], [64, 77], [78, 80], [81, 87], [88, 99], [100, 107], [107, 108]]}
{"doc_key": "ai-test-410", "ner": [[5, 7, "algorithm"], [29, 30, "algorithm"], [37, 39, "algorithm"], [42, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[37, 39, 29, 30, "type-of", "", false, false], [42, 42, 37, 39, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "special", "case", "of", "linear", "support", "vector", "machines", "can", "be", "solved", "more", "efficiently", "by", "the", "same", "type", "of", "algorithms", "that", "are", "used", "to", "optimise", "it", "s", "close", "relative", ",", "logistic", "regression", ";", "this", "class", "of", "algorithms", "includes", "stochastic", "gradient", "descent", "(", "e.g.", "PEGASOS", ")", "."], "sentence-detokenized": "The special case of linear support vector machines can be solved more efficiently by the same type of algorithms that are used to optimise its close relative, logistic regression; this class of algorithms includes stochastic gradient descent (e.g. PEGASOS).", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 19], [20, 26], [27, 34], [35, 41], [42, 50], [51, 54], [55, 57], [58, 64], [65, 69], [70, 81], [82, 84], [85, 88], [89, 93], [94, 98], [99, 101], [102, 112], [113, 117], [118, 121], [122, 126], [127, 129], [130, 138], [139, 141], [141, 142], [143, 148], [149, 157], [157, 158], [159, 167], [168, 178], [178, 179], [180, 184], [185, 190], [191, 193], [194, 204], [205, 213], [214, 224], [225, 233], [234, 241], [242, 243], [243, 247], [248, 255], [255, 256], [256, 257]]}
{"doc_key": "ai-test-411", "ner": [[1, 1, "product"], [30, 30, "product"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "Siri", "is", "asked", "on", "an", "iOS", "device", ",", "\"", "Do", "you", "have", "a", "pet", "?", "\"", ",", "one", "of", "the", "answers", "is", ":", "\"", "I", "used", "to", "have", "an", "AIBO", "\"", "."], "sentence-detokenized": "When Siri is asked on an iOS device, \"Do you have a pet?\", one of the answers is: \"I used to have an AIBO\".", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 18], [19, 21], [22, 24], [25, 28], [29, 35], [35, 36], [37, 38], [38, 40], [41, 44], [45, 49], [50, 51], [52, 55], [55, 56], [56, 57], [57, 58], [59, 62], [63, 65], [66, 69], [70, 77], [78, 80], [80, 81], [82, 83], [83, 84], [85, 89], [90, 92], [93, 97], [98, 100], [101, 105], [105, 106], [106, 107]]}
{"doc_key": "ai-test-412", "ner": [[1, 2, "task"], [5, 8, "metrics"], [10, 10, "metrics"], [13, 14, "metrics"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 8, 1, 2, "part-of", "", false, false], [10, 10, 5, 8, "named", "", false, false], [13, 14, 1, 2, "part-of", "", false, false], [16, 16, 13, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "information", "retrieval", ",", "the", "positive", "predictive", "value", "is", "called", "precision", "and", "the", "sensitivity", "is", "called", "recall", "."], "sentence-detokenized": "In information retrieval, the positive predictive value is called precision and the sensitivity is called recall.", "token2charspan": [[0, 2], [3, 14], [15, 24], [24, 25], [26, 29], [30, 38], [39, 49], [50, 55], [56, 58], [59, 65], [66, 75], [76, 79], [80, 83], [84, 95], [96, 98], [99, 105], [106, 112], [112, 113]]}
{"doc_key": "ai-test-413", "ner": [[11, 12, "field"], [14, 14, "task"], [16, 16, "task"], [18, 19, "task"], [36, 37, "task"], [39, 40, "task"], [42, 46, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[14, 14, 11, 12, "part-of", "task_part_of_field", false, false], [16, 16, 11, 12, "part-of", "task_part_of_field", false, false], [18, 19, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "particular", ",", "his", "research", "has", "focused", "on", "areas", "such", "as", "text", "mining", "(", "extraction", ",", "categorisation", ",", "novelty", "detection", ")", "and", "on", "new", "theoretical", "frameworks", "such", "as", "a", "unified", "usage", "-", "based", "theory", "that", "combines", "information", "retrieval", ",", "automatic", "summarisation", ",", "free", "-", "text", "question", "answering", "and", "related", "tasks", "."], "sentence-detokenized": "In particular, his research has focused on areas such as text mining (extraction, categorisation, novelty detection) and on new theoretical frameworks such as a unified usage-based theory that combines information retrieval, automatic summarisation, free-text question answering and related tasks.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 27], [28, 31], [32, 39], [40, 42], [43, 48], [49, 53], [54, 56], [57, 61], [62, 68], [69, 70], [70, 80], [80, 81], [82, 96], [96, 97], [98, 105], [106, 115], [115, 116], [117, 120], [121, 123], [124, 127], [128, 139], [140, 150], [151, 155], [156, 158], [159, 160], [161, 168], [169, 174], [174, 175], [175, 180], [181, 187], [188, 192], [193, 201], [202, 213], [214, 223], [223, 224], [225, 234], [235, 248], [248, 249], [250, 254], [254, 255], [255, 259], [260, 268], [269, 278], [279, 282], [283, 290], [291, 296], [296, 297]]}
{"doc_key": "ai-test-414", "ner": [[0, 1, "product"], [6, 8, "product"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 8, 0, 1, "part-of", "", false, false], [14, 15, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Delta", "robots", "have", "base", "-", "mounted", "rotary", "drives", "that", "move", "a", "lightweight", ",", "rigid", "parallelogram", "arm", "."], "sentence-detokenized": "Delta robots have base-mounted rotary drives that move a lightweight, rigid parallelogram arm.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 22], [22, 23], [23, 30], [31, 37], [38, 44], [45, 49], [50, 54], [55, 56], [57, 68], [68, 69], [70, 75], [76, 89], [90, 93], [93, 94]]}
{"doc_key": "ai-test-415", "ner": [[8, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated in a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [64, 66], [67, 76], [77, 83], [84, 86], [87, 94], [94, 95]]}
{"doc_key": "ai-test-416", "ner": [[4, 5, "field"], [32, 33, "task"], [40, 41, "task"], [46, 48, "task"], [50, 52, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[32, 33, 4, 5, "part-of", "task_part_of_field", false, false], [40, 41, 4, 5, "part-of", "task_part_of_field", false, false], [46, 48, 4, 5, "part-of", "task_part_of_field", false, false], [50, 52, 4, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "actual", "task", "of", "data", "mining", "is", "the", "semi-automatic", "or", "automatic", "analysis", "of", "large", "amounts", "of", "data", "in", "order", "to", "extract", "unknown", ",", "interesting", "patterns", "such", "as", "groups", "of", "data", "sets", "(", "cluster", "analysis", ")", ",", "unusual", "data", "sets", "(", "anomaly", "detection", ")", "and", "dependencies", "(", "association", "rule", "mining", ",", "sequential", "pattern", "mining", ")", "."], "sentence-detokenized": "The actual task of data mining is the semi-automatic or automatic analysis of large amounts of data in order to extract unknown, interesting patterns such as groups of data sets (cluster analysis), unusual data sets (anomaly detection) and dependencies (association rule mining, sequential pattern mining).", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 18], [19, 23], [24, 30], [31, 33], [34, 37], [38, 52], [53, 55], [56, 65], [66, 74], [75, 77], [78, 83], [84, 91], [92, 94], [95, 99], [100, 102], [103, 108], [109, 111], [112, 119], [120, 127], [127, 128], [129, 140], [141, 149], [150, 154], [155, 157], [158, 164], [165, 167], [168, 172], [173, 177], [178, 179], [179, 186], [187, 195], [195, 196], [196, 197], [198, 205], [206, 210], [211, 215], [216, 217], [217, 224], [225, 234], [234, 235], [236, 239], [240, 252], [253, 254], [254, 265], [266, 270], [271, 277], [277, 278], [279, 289], [290, 297], [298, 304], [304, 305], [305, 306]]}
{"doc_key": "ai-test-417", "ner": [[2, 7, "product"], [5, 11, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 7, 5, 11, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "a", "recommendation", "system", ",", "sentiment", "analysis", "has", "proven", "to", "be", "a", "valuable", "technique", "."], "sentence-detokenized": "For a recommendation system, sentiment analysis has proven to be a valuable technique.", "token2charspan": [[0, 3], [4, 5], [6, 20], [21, 27], [27, 28], [29, 38], [39, 47], [48, 51], [52, 58], [59, 61], [62, 64], [65, 66], [67, 75], [76, 85], [85, 86]]}
{"doc_key": "ai-test-418", "ner": [[3, 3, "misc"], [37, 38, "location"]], "ner_mapping_to_source": [0, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Coincidentally", ",", "the", "Germans", "had", "chosen", "the", "operating", "frequency", "of", "the", "Wotan", "system", "very", "badly", ";", "it", "operated", "on", "45", "MHz", ",", "which", "happened", "to", "be", "the", "frequency", "of", "the", "powerful", "but", "sleeping", "BBC", "television", "station", "at", "Alexandra", "Palace", "."], "sentence-detokenized": "Coincidentally, the Germans had chosen the operating frequency of the Wotan system very badly; it operated on 45 MHz, which happened to be the frequency of the powerful but sleeping BBC television station at Alexandra Palace.", "token2charspan": [[0, 14], [14, 15], [16, 19], [20, 27], [28, 31], [32, 38], [39, 42], [43, 52], [53, 62], [63, 65], [66, 69], [70, 75], [76, 82], [83, 87], [88, 93], [93, 94], [95, 97], [98, 106], [107, 109], [110, 112], [113, 116], [116, 117], [118, 123], [124, 132], [133, 135], [136, 138], [139, 142], [143, 152], [153, 155], [156, 159], [160, 168], [169, 172], [173, 181], [182, 185], [186, 196], [197, 204], [205, 207], [208, 217], [218, 224], [224, 225]]}
{"doc_key": "ai-test-419", "ner": [[8, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated in a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [64, 66], [67, 76], [77, 83], [84, 86], [87, 94], [94, 95]]}
{"doc_key": "ai-test-420", "ner": [[1, 3, "misc"], [10, 10, "misc"], [13, 13, "product"], [15, 15, "product"], [17, 19, "product"], [27, 28, "misc"], [35, 38, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 13, 10, 10, "usage", "", false, false], [15, 15, 10, 10, "usage", "", false, false], [17, 19, 15, 15, "named", "", false, false], [27, 28, 10, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "Semantic", "Web", "applications", "and", "in", "relatively", "popular", "applications", "of", "RDF", "such", "as", "RSS", "and", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "resources", "are", "usually", "represented", "by", "URIs", "that", "intentionally", "denote", "actual", "data", "on", "the", "World", "Wide", "Web", "and", "can", "be", "used", "to", "access", "it", "."], "sentence-detokenized": "In Semantic Web applications and in relatively popular applications of RDF such as RSS and FOAF (Friend a Friend), resources are usually represented by URIs that intentionally denote actual data on the World Wide Web and can be used to access it.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 28], [29, 32], [33, 35], [36, 46], [47, 54], [55, 67], [68, 70], [71, 74], [75, 79], [80, 82], [83, 86], [87, 90], [91, 95], [96, 97], [97, 103], [104, 105], [106, 112], [112, 113], [113, 114], [115, 124], [125, 128], [129, 136], [137, 148], [149, 151], [152, 156], [157, 161], [162, 175], [176, 182], [183, 189], [190, 194], [195, 197], [198, 201], [202, 207], [208, 212], [213, 216], [217, 220], [221, 224], [225, 227], [228, 232], [233, 235], [236, 242], [243, 245], [245, 246]]}
{"doc_key": "ai-test-421", "ner": [[1, 7, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "has", "studied", "this", "issue", "in", "depth"], "sentence-detokenized": "The Association for the Advancement of Artificial Intelligence has studied this issue in depth", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 35], [36, 38], [39, 49], [50, 62], [63, 66], [67, 74], [75, 79], [80, 85], [86, 88], [89, 94]]}
{"doc_key": "ai-test-422", "ner": [[5, 10, "product"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 17, 5, 10, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["From", "a", "curiosity", ",", "the", "speech", "system", "of", "the", "Apple", "Macintosh", "has", "evolved", "into", "a", "fully", "supported", "PlainTalk", "programme", "for", "people", "with", "visual", "impairments", "."], "sentence-detokenized": "From a curiosity, the speech system of the Apple Macintosh has evolved into a fully supported PlainTalk programme for people with visual impairments.", "token2charspan": [[0, 4], [5, 6], [7, 16], [16, 17], [18, 21], [22, 28], [29, 35], [36, 38], [39, 42], [43, 48], [49, 58], [59, 62], [63, 70], [71, 75], [76, 77], [78, 83], [84, 93], [94, 103], [104, 113], [114, 117], [118, 124], [125, 129], [130, 136], [137, 148], [148, 149]]}
{"doc_key": "ai-test-423", "ner": [[10, 10, "field"], [12, 13, "task"], [15, 16, "task"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[12, 13, 10, 10, "part-of", "task_part_of_field", false, false], [15, 16, 10, 10, "part-of", "task_part_of_field", false, false], [18, 19, 10, 10, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Other", "areas", "of", "application", "for", "ontologies", "in", "the", "context", "of", "NLP", "are", "information", "retrieval", ",", "information", "extraction", "and", "automatic", "summaries", "."], "sentence-detokenized": "Other areas of application for ontologies in the context of NLP are information retrieval, information extraction and automatic summaries.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 26], [27, 30], [31, 41], [42, 44], [45, 48], [49, 56], [57, 59], [60, 63], [64, 67], [68, 79], [80, 89], [89, 90], [91, 102], [103, 113], [114, 117], [118, 127], [128, 137], [137, 138]]}
{"doc_key": "ai-test-424", "ner": [[7, 14, "organisation"], [15, 22, "organisation"], [25, 29, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Institute", "has", "worked", "closely", "with", "the", "Janelia", "Farm", "Campus", "of", "the", "Howard", "Hughes", "Medical", "Institute", ",", "the", "Allen", "Institute", "for", "Brain", "Science", "and", "the", "National", "Institutes", "of", "Health", "to", "develop", "better", "methods", "for", "reconstructing", "neural", "architectures", "."], "sentence-detokenized": "The Institute has worked closely with the Janelia Farm Campus of the Howard Hughes Medical Institute, the Allen Institute for Brain Science and the National Institutes of Health to develop better methods for reconstructing neural architectures.", "token2charspan": [[0, 3], [4, 13], [14, 17], [18, 24], [25, 32], [33, 37], [38, 41], [42, 49], [50, 54], [55, 61], [62, 64], [65, 68], [69, 75], [76, 82], [83, 90], [91, 100], [100, 101], [102, 105], [106, 111], [112, 121], [122, 125], [126, 131], [132, 139], [140, 143], [144, 147], [148, 156], [157, 167], [168, 170], [171, 177], [178, 180], [181, 188], [189, 195], [196, 203], [204, 207], [208, 222], [223, 229], [230, 243], [243, 244]]}
{"doc_key": "ai-test-425", "ner": [[2, 2, "organisation"], [5, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 12, 2, 2, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Recently", ",", "Google", "announced", "that", "Google", "Translate", "translates", "so", "much", "text", "in", "one", "day", "that", "it", "could", "fill", "1", "million", "books", "(", "2012", ")", "."], "sentence-detokenized": "Recently, Google announced that Google Translate translates so much text in one day that it could fill 1 million books (2012).", "token2charspan": [[0, 8], [8, 9], [10, 16], [17, 26], [27, 31], [32, 38], [39, 48], [49, 59], [60, 62], [63, 67], [68, 72], [73, 75], [76, 79], [80, 83], [84, 88], [89, 91], [92, 97], [98, 102], [103, 104], [105, 112], [113, 118], [119, 120], [120, 124], [124, 125], [125, 126]]}
{"doc_key": "ai-test-426", "ner": [[15, 16, "country"], [18, 20, "country"], [22, 22, "country"], [24, 24, "country"], [26, 26, "country"], [28, 31, "country"], [42, 43, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "event", "s", "take", "place", "all", "over", "the", "world", "and", "are", "particularly", "popular", "in", "the", "United", "Kingdom", ",", "the", "United", "States", ",", "Japan", ",", "Singapore", ",", "India", "and", "South", "Korea", ",", "and", "are", "also", "becoming", "increasingly", "popular", "in", "subcontinent", "countries", "such", "as", "Sri", "Lanka", "."], "sentence-detokenized": "The events take place all over the world and are particularly popular in the United Kingdom, the United States, Japan, Singapore, India and South Korea, and are also becoming increasingly popular in subcontinent countries such as Sri Lanka.", "token2charspan": [[0, 3], [4, 9], [9, 10], [11, 15], [16, 21], [22, 25], [26, 30], [31, 34], [35, 40], [41, 44], [45, 48], [49, 61], [62, 69], [70, 72], [73, 76], [77, 83], [84, 91], [91, 92], [93, 96], [97, 103], [104, 110], [110, 111], [112, 117], [117, 118], [119, 128], [128, 129], [130, 135], [136, 139], [140, 145], [146, 151], [151, 152], [153, 156], [157, 160], [161, 165], [166, 174], [175, 187], [188, 195], [196, 198], [199, 211], [212, 221], [222, 226], [227, 229], [230, 233], [234, 239], [239, 240]]}
{"doc_key": "ai-test-427", "ner": [[6, 6, "programlang"], [11, 11, "programlang"], [13, 13, "programlang"], [15, 16, "programlang"], [18, 18, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "packages", "are", "mainly", "developed", "in", "R", ",", "sometimes", "also", "in", "Java", ",", "C", ",", "C", "++", "and", "Fortran", "."], "sentence-detokenized": "These packages are mainly developed in R, sometimes also in Java, C, C++ and Fortran.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 25], [26, 35], [36, 38], [39, 40], [40, 41], [42, 51], [52, 56], [57, 59], [60, 64], [64, 65], [66, 67], [67, 68], [69, 70], [70, 72], [73, 76], [77, 84], [84, 85]]}
{"doc_key": "ai-test-428", "ner": [[2, 15, "conference"], [8, 8, "conference"], [12, 12, "researcher"], [14, 14, "researcher"], [17, 20, "researcher"], [23, 25, "algorithm"], [29, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[8, 8, 2, 15, "named", "", false, false], [12, 12, 2, 15, "physical", "", false, false], [12, 12, 2, 15, "role", "", false, false], [12, 12, 17, 20, "role", "teams_up_with", false, false], [12, 12, 23, 25, "usage", "", false, false], [14, 14, 2, 15, "physical", "", false, false], [14, 14, 2, 15, "role", "", false, false], [14, 14, 17, 20, "role", "teams_up_with", false, false], [14, 14, 23, 25, "usage", "", false, false], [17, 20, 2, 15, "physical", "", false, false], [17, 20, 2, 15, "role", "", false, false], [17, 20, 23, 25, "usage", "", false, false], [23, 25, 29, 34, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["At", "the", "European", "Conference", "on", "Computer", "Vision", "(", "ECCV", ")", "2006", ",", "Dalal", "and", "Triggs", "worked", "with", "Cordelia", "Schmid", "on", "the", "application", "of", "HOG", "detectors", "to", "the", "problem", "of", "human", "recognition", "in", "films", "and", "videos", "."], "sentence-detokenized": "At the European Conference on Computer Vision (ECCV) 2006, Dalal and Triggs worked with Cordelia Schmid on the application of HOG detectors to the problem of human recognition in films and videos.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 26], [27, 29], [30, 38], [39, 45], [46, 47], [47, 51], [51, 52], [53, 57], [57, 58], [59, 64], [65, 68], [69, 75], [76, 82], [83, 87], [88, 96], [97, 103], [104, 106], [107, 110], [111, 122], [123, 125], [126, 129], [130, 139], [140, 142], [143, 146], [147, 154], [155, 157], [158, 163], [164, 175], [176, 178], [179, 184], [185, 188], [189, 195], [195, 196]]}
{"doc_key": "ai-test-429", "ner": [[3, 3, "metrics"], [5, 7, "metrics"], [11, 11, "task"], [19, 21, "metrics"], [23, 23, "metrics"], [29, 29, "metrics"], [33, 35, "metrics"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[3, 3, 11, 11, "related-to", "measured_with", false, false], [5, 7, 11, 11, "related-to", "measured_with", false, false], [19, 21, 11, 11, "related-to", "measured_with", false, false], [23, 23, 19, 21, "named", "", false, false], [29, 29, 19, 21, "named", "", false, false], [37, 37, 33, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "addition", "to", "sensitivity", "and", "specificity", ",", "the", "performance", "of", "a", "binary", "classification", "test", "can", "be", "measured", "with", "the", "positive", "predictive", "value", "(", "PPV", ")", ",", "also", "known", "as", "precision", ",", "and", "the", "negative", "predictive", "value", "(", "NPV", ")", "."], "sentence-detokenized": "In addition to sensitivity and specificity, the performance of a binary classification test can be measured with the positive predictive value (PPV), also known as precision, and the negative predictive value (NPV).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 42], [42, 43], [44, 47], [48, 59], [60, 62], [63, 64], [65, 71], [72, 86], [87, 91], [92, 95], [96, 98], [99, 107], [108, 112], [113, 116], [117, 125], [126, 136], [137, 142], [143, 144], [144, 147], [147, 148], [148, 149], [150, 154], [155, 160], [161, 163], [164, 173], [173, 174], [175, 178], [179, 182], [183, 191], [192, 202], [203, 208], [209, 210], [210, 213], [213, 214], [214, 215]]}
{"doc_key": "ai-test-430", "ner": [[14, 16, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "such", "models", ",", "overlapping", "matches", "can", "be", "partially", "credited", "(", "e.g.", "using", "the", "Jaccard", "index", "criterion", ")", "."], "sentence-detokenized": "In such models, overlapping matches can be partially credited (e.g. using the Jaccard index criterion).", "token2charspan": [[0, 2], [3, 7], [8, 14], [14, 15], [16, 27], [28, 35], [36, 39], [40, 42], [43, 52], [53, 61], [62, 63], [63, 67], [68, 73], [74, 77], [78, 85], [86, 91], [92, 101], [101, 102], [102, 103]]}
{"doc_key": "ai-test-431", "ner": [[19, 25, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Furthermore", ",", "in", "the", "case", "of", "single", "sample", "estimation", ",", "philosophical", "issues", "and", "possible", "misunderstandings", "in", "the", "use", "of", "maximum", "likelihood", "estimators", "and", "likelihood", "functions", "are", "highlighted", "."], "sentence-detokenized": "Furthermore, in the case of single sample estimation, philosophical issues and possible misunderstandings in the use of maximum likelihood estimators and likelihood functions are highlighted.", "token2charspan": [[0, 11], [11, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 34], [35, 41], [42, 52], [52, 53], [54, 67], [68, 74], [75, 78], [79, 87], [88, 105], [106, 108], [109, 112], [113, 116], [117, 119], [120, 127], [128, 138], [139, 149], [150, 153], [154, 164], [165, 174], [175, 178], [179, 190], [190, 191]]}
