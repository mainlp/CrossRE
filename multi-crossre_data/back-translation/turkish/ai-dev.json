{"doc_key": "ai-dev-1", "ner": [[0, 0, "metrics"], [6, 7, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 0, 0, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Accuracy", "is", "measured", "here", "by", "the", "error", "rate", ",", "defined", "as"], "sentence-detokenized": "Accuracy is measured here by the error rate, defined as", "token2charspan": [[0, 8], [9, 11], [12, 20], [21, 25], [26, 28], [29, 32], [33, 38], [39, 43], [43, 44], [45, 52], [53, 55]]}
{"doc_key": "ai-dev-2", "ner": [[4, 4, "algorithm"], [8, 12, "misc"], [15, 17, "algorithm"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 8, 12, "type-of", "", false, false], [4, 4, 15, 17, "related-to", "", false, false], [4, 4, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "this", "respect", ",", "SVM", "is", "closely", "related", "to", "other", "basic", "classification", "algorithms", "such", "as", "regularised", "least", "squares", "logistic", "regression", "."], "sentence-detokenized": "In this respect, SVM is closely related to other basic classification algorithms such as regularised least squares logistic regression.", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 20], [21, 23], [24, 31], [32, 39], [40, 42], [43, 48], [49, 54], [55, 69], [70, 80], [81, 85], [86, 88], [89, 100], [101, 106], [107, 114], [115, 123], [124, 134], [134, 135]]}
{"doc_key": "ai-dev-3", "ner": [[0, 2, "person"], [3, 12, "person"], [13, 15, "person"], [16, 18, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 12, 0, 2, "named", "actor_plays_character", false, false], [3, 12, 0, 2, "origin", "actor_plays_character", false, false], [16, 18, 13, 15, "named", "actor_plays_character", false, false], [16, 18, 13, 15, "origin", "actor_plays_character", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Brion", "James", "plays", "Leon", "Kowalski", ",", "a", "warrior", "and", "labourer", "replicant", ",", "and", "Joanna", "Cassidy", "plays", "Zhora", ",", "an", "assassin", "replicant", "."], "sentence-detokenized": "Brion James plays Leon Kowalski, a warrior and labourer replicant, and Joanna Cassidy plays Zhora, an assassin replicant.", "token2charspan": [[0, 5], [6, 11], [12, 17], [18, 22], [23, 31], [31, 32], [33, 34], [35, 42], [43, 46], [47, 55], [56, 65], [65, 66], [67, 70], [71, 77], [78, 85], [86, 91], [92, 97], [97, 98], [99, 101], [102, 110], [111, 120], [120, 121]]}
{"doc_key": "ai-dev-4", "ner": [[15, 20, "product"], [22, 22, "product"], [24, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 20, 24, 25, "physical", "", false, false], [22, 22, 15, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "image", ",", "scanned", ",", "stored", "and", "reconstructed", "into", "digital", "pixels", ",", "was", "imaged", "on", "the", "Standard", "Eastern", "Automated", "Computer", "(", "SEAC", ")", "at", "NIST", "."], "sentence-detokenized": "The first image, scanned, stored and reconstructed into digital pixels, was imaged on the Standard Eastern Automated Computer (SEAC) at NIST.", "token2charspan": [[0, 3], [4, 9], [10, 15], [15, 16], [17, 24], [24, 25], [26, 32], [33, 36], [37, 50], [51, 55], [56, 63], [64, 70], [70, 71], [72, 75], [76, 82], [83, 85], [86, 89], [90, 98], [99, 106], [107, 116], [117, 125], [126, 127], [127, 131], [131, 132], [133, 135], [136, 140], [140, 141]]}
{"doc_key": "ai-dev-5", "ner": [[0, 6, "task"], [20, 21, "task"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 6, 20, 21, "part-of", "", false, false], [0, 6, 23, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Breaking", "text", "into", "topics", "or", "discourse", "turns", "can", "be", "useful", "in", "some", "natural", "processing", "tasks", ":", "it", "can", "significantly", "improve", "information", "retrieval", "or", "speech", "recognition", "(", "by", "indexing", "/", "recognising", "documents", "more", "precisely", "or", "giving", "as", "a", "result", "a", "specific", "part", "of", "a", "document", "corresponding", "to", "the", "query", ")", "."], "sentence-detokenized": "Breaking text into topics or discourse turns can be useful in some natural processing tasks: it can significantly improve information retrieval or speech recognition (by indexing/recognising documents more precisely or giving as a result a specific part of a document corresponding to the query).", "token2charspan": [[0, 8], [9, 13], [14, 18], [19, 25], [26, 28], [29, 38], [39, 44], [45, 48], [49, 51], [52, 58], [59, 61], [62, 66], [67, 74], [75, 85], [86, 91], [91, 92], [93, 95], [96, 99], [100, 113], [114, 121], [122, 133], [134, 143], [144, 146], [147, 153], [154, 165], [166, 167], [167, 169], [170, 178], [178, 179], [179, 190], [191, 200], [201, 205], [206, 215], [216, 218], [219, 225], [226, 228], [229, 230], [231, 237], [238, 239], [240, 248], [249, 253], [254, 256], [257, 258], [259, 267], [268, 281], [282, 284], [285, 288], [289, 294], [294, 295], [295, 296]]}
{"doc_key": "ai-dev-6", "ner": [[7, 9, "university"], [24, 25, "conference"], [21, 22, "university"], [34, 35, "researcher"], [37, 38, "researcher"], [40, 41, "researcher"], [43, 44, "researcher"], [46, 47, "researcher"], [49, 50, "researcher"], [52, 54, "researcher"], [56, 57, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[24, 25, 21, 22, "physical", "", false, false], [34, 35, 24, 25, "physical", "", false, false], [34, 35, 24, 25, "role", "", false, false], [34, 35, 24, 25, "temporal", "", false, false], [37, 38, 24, 25, "physical", "", false, false], [37, 38, 24, 25, "role", "", false, false], [37, 38, 24, 25, "temporal", "", false, false], [40, 41, 24, 25, "physical", "", false, false], [40, 41, 24, 25, "role", "", false, false], [40, 41, 24, 25, "temporal", "", false, false], [43, 44, 24, 25, "physical", "", false, false], [43, 44, 24, 25, "role", "", false, false], [43, 44, 24, 25, "temporal", "", false, false], [46, 47, 24, 25, "physical", "", false, false], [46, 47, 24, 25, "role", "", false, false], [46, 47, 24, 25, "temporal", "", false, false], [49, 50, 24, 25, "physical", "", false, false], [49, 50, 24, 25, "role", "", false, false], [49, 50, 24, 25, "temporal", "", false, false], [52, 54, 24, 25, "physical", "", false, false], [52, 54, 24, 25, "role", "", false, false], [52, 54, 24, 25, "temporal", "", false, false], [56, 57, 24, 25, "physical", "", false, false], [56, 57, 24, 25, "role", "", false, false], [56, 57, 24, 25, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "sentence": ["In", "1999", "he", "organised", "such", "a", "symposium", "at", "Indiana", "University", ",", "and", "in", "April", "2000", "he", "organised", "a", "larger", "symposium", "at", "Stanford", "University", "entitled", "Spiritual", "Robots", ",", "where", "he", "moderated", "a", "panel", "consisting", "of", "Ray", "Kurzweil", ",", "Hans", "Moravec", ",", "Kevin", "Kelly", ",", "Ralph", "Merkle", ",", "Bill", "Joy", ",", "Frank", "Drake", ",", "John", "Henry", "Holland", "and", "John", "Koza", "."], "sentence-detokenized": "In 1999 he organised such a symposium at Indiana University, and in April 2000 he organised a larger symposium at Stanford University entitled Spiritual Robots, where he moderated a panel consisting of Ray Kurzweil, Hans Moravec, Kevin Kelly, Ralph Merkle, Bill Joy, Frank Drake, John Henry Holland and John Koza.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 20], [21, 25], [26, 27], [28, 37], [38, 40], [41, 48], [49, 59], [59, 60], [61, 64], [65, 67], [68, 73], [74, 78], [79, 81], [82, 91], [92, 93], [94, 100], [101, 110], [111, 113], [114, 122], [123, 133], [134, 142], [143, 152], [153, 159], [159, 160], [161, 166], [167, 169], [170, 179], [180, 181], [182, 187], [188, 198], [199, 201], [202, 205], [206, 214], [214, 215], [216, 220], [221, 228], [228, 229], [230, 235], [236, 241], [241, 242], [243, 248], [249, 255], [255, 256], [257, 261], [262, 265], [265, 266], [267, 272], [273, 278], [278, 279], [280, 284], [285, 290], [291, 298], [299, 302], [303, 307], [308, 312], [312, 313]]}
{"doc_key": "ai-dev-7", "ner": [[11, 11, "metrics"], [12, 14, "metrics"], [15, 17, "metrics"], [16, 16, "metrics"], [21, 21, "metrics"], [43, 45, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 21, 21, "named", "", false, false], [12, 14, 11, 11, "named", "", false, false], [15, 17, 43, 45, "named", "", false, false], [16, 16, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["To", "calculate", "the", "score", ",", "it", "takes", "into", "account", "both", "the", "precision", "p", "and", "the", "recall", "r", "of", "the", "test", ":", "p", "is", "the", "number", "of", "true", "positive", "results", "divided", "by", "the", "number", "of", "all", "positive", "results", "returned", "by", "the", "classifier", ",", "and", "r", "is", "the", "number", "of", "true", "positive", "results", "divided", "by", "the", "number", "of", "all", "relevant", "samples", "(", "all", "samples", "that", "should", "be", "identified", "as", "positive", ")", "."], "sentence-detokenized": "To calculate the score, it takes into account both the precision p and the recall r of the test: p is the number of true positive results divided by the number of all positive results returned by the classifier, and r is the number of true positive results divided by the number of all relevant samples (all samples that should be identified as positive).", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 22], [22, 23], [24, 26], [27, 32], [33, 37], [38, 45], [46, 50], [51, 54], [55, 64], [65, 66], [67, 70], [71, 74], [75, 81], [82, 83], [84, 86], [87, 90], [91, 95], [95, 96], [97, 98], [99, 101], [102, 105], [106, 112], [113, 115], [116, 120], [121, 129], [130, 137], [138, 145], [146, 148], [149, 152], [153, 159], [160, 162], [163, 166], [167, 175], [176, 183], [184, 192], [193, 195], [196, 199], [200, 210], [210, 211], [212, 215], [216, 217], [218, 220], [221, 224], [225, 231], [232, 234], [235, 239], [240, 248], [249, 256], [257, 264], [265, 267], [268, 271], [272, 278], [279, 281], [282, 285], [286, 294], [295, 302], [303, 304], [304, 307], [308, 315], [316, 320], [321, 327], [328, 330], [331, 341], [342, 344], [345, 353], [353, 354], [354, 355]]}
{"doc_key": "ai-dev-8", "ner": [[4, 4, "organisation"], [27, 27, "product"], [34, 35, "person"], [41, 41, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 27, 27, "artifact", "", false, false], [27, 27, 34, 35, "win-defeat", "", false, false], [27, 27, 41, 41, "win-defeat", "", true, false], [34, 35, 41, 41, "win-defeat", "lose", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "the", "acquisition", "of", "Google", ",", "the", "company", "has", "achieved", "a", "number", "of", "significant", "successes", ",", "perhaps", "the", "most", "notable", "of", "which", "was", "the", "creation", "of", "the", "AlphaGo", "programme", ",", "which", "defeated", "world", "champion", "Lee", "Sedol", "in", "the", "complex", "game", "of", "Go", "."], "sentence-detokenized": "Since the acquisition of Google, the company has achieved a number of significant successes, perhaps the most notable of which was the creation of the AlphaGo programme, which defeated world champion Lee Sedol in the complex game of Go.", "token2charspan": [[0, 5], [6, 9], [10, 21], [22, 24], [25, 31], [31, 32], [33, 36], [37, 44], [45, 48], [49, 57], [58, 59], [60, 66], [67, 69], [70, 81], [82, 91], [91, 92], [93, 100], [101, 104], [105, 109], [110, 117], [118, 120], [121, 126], [127, 130], [131, 134], [135, 143], [144, 146], [147, 150], [151, 158], [159, 168], [168, 169], [170, 175], [176, 184], [185, 190], [191, 199], [200, 203], [204, 209], [210, 212], [213, 216], [217, 224], [225, 229], [230, 232], [233, 235], [235, 236]]}
{"doc_key": "ai-dev-9", "ner": [[14, 15, "misc"], [27, 27, "field"], [30, 33, "product"], [39, 39, "misc"], [56, 56, "misc"], [59, 59, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 15, 27, 27, "part-of", "", false, false], [14, 15, 56, 56, "named", "same", false, false], [30, 33, 39, 39, "related-to", "", false, false], [30, 33, 56, 56, "usage", "", false, false], [30, 33, 59, 59, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Representing", "words", "taking", "into", "account", "their", "context", "through", "fixed", "-", "size", "dense", "vectors", "(", "word", "embeddings", ")", "has", "become", "one", "of", "the", "most", "fundamental", "blocks", "in", "many", "NLP", "systems", ".", "An", "unsupervised", "disambiguation", "system", "uses", "the", "similarity", "between", "word", "meanings", "in", "a", "fixed", "context", "window", "to", "select", "the", "most", "appropriate", "word", "meaning", "using", "a", "pre-trained", "word", "embedding", "model", "and", "WordNet", "."], "sentence-detokenized": "Representing words taking into account their context through fixed-size dense vectors (word embeddings) has become one of the most fundamental blocks in many NLP systems. An unsupervised disambiguation system uses the similarity between word meanings in a fixed context window to select the most appropriate word meaning using a pre-trained word embedding model and WordNet.", "token2charspan": [[0, 12], [13, 18], [19, 25], [26, 30], [31, 38], [39, 44], [45, 52], [53, 60], [61, 66], [66, 67], [67, 71], [72, 77], [78, 85], [86, 87], [87, 91], [92, 102], [102, 103], [104, 107], [108, 114], [115, 118], [119, 121], [122, 125], [126, 130], [131, 142], [143, 149], [150, 152], [153, 157], [158, 161], [162, 169], [169, 170], [171, 173], [174, 186], [187, 201], [202, 208], [209, 213], [214, 217], [218, 228], [229, 236], [237, 241], [242, 250], [251, 253], [254, 255], [256, 261], [262, 269], [270, 276], [277, 279], [280, 286], [287, 290], [291, 295], [296, 307], [308, 312], [313, 320], [321, 326], [327, 328], [329, 340], [341, 345], [346, 355], [356, 361], [362, 365], [366, 373], [373, 374]]}
{"doc_key": "ai-dev-10", "ner": [[0, 1, "field"], [5, 6, "field"], [8, 9, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 0, 1, "part-of", "", false, false], [8, 9, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "techniques", ",", "either", "supervised", "learning", "or", "unsupervised", "learning", ",", "have", "been", "used", "to", "automatically", "generate", "such", "rules", "."], "sentence-detokenized": "Machine learning techniques, either supervised learning or unsupervised learning, have been used to automatically generate such rules.", "token2charspan": [[0, 7], [8, 16], [17, 27], [27, 28], [29, 35], [36, 46], [47, 55], [56, 58], [59, 71], [72, 80], [80, 81], [82, 86], [87, 91], [92, 96], [97, 99], [100, 113], [114, 122], [123, 127], [128, 133], [133, 134]]}
{"doc_key": "ai-dev-11", "ner": [[2, 2, "researcher"], [4, 6, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 2, 2, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1969", "Scheinman", "invented", "the", "Stanford", "arm", ","], "sentence-detokenized": "In 1969 Scheinman invented the Stanford arm,", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 26], [27, 30], [31, 39], [40, 43], [43, 44]]}
{"doc_key": "ai-dev-12", "ner": [[1, 4, "metrics"], [8, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Since", "the", "log", "loss", "is", "differentiable", ",", "a", "gradient", "-", "based", "method", "can", "be", "used", "to", "optimise", "the", "model", "."], "sentence-detokenized": "Since the log loss is differentiable, a gradient-based method can be used to optimise the model.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 18], [19, 21], [22, 36], [36, 37], [38, 39], [40, 48], [48, 49], [49, 54], [55, 61], [62, 65], [66, 68], [69, 73], [74, 76], [77, 85], [86, 89], [90, 95], [95, 96]]}
{"doc_key": "ai-dev-13", "ner": [[0, 2, "field"], [4, 7, "algorithm"], [9, 9, "algorithm"], [12, 15, "algorithm"], [18, 19, "field"], [29, 29, "task"], [31, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 7, 18, 19, "part-of", "", false, false], [9, 9, 4, 7, "named", "", false, false], [12, 15, 4, 7, "named", "", false, false], [18, 19, 0, 2, "part-of", "subfield", false, false], [29, 29, 18, 19, "part-of", "", false, false], [31, 32, 18, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "machine", "learning", ",", "support", "-", "vector", "machines", "(", "SVMs", ",", "also", "support", "-", "vector", "networks", ")", "are", "supervised", "learning", "models", "with", "learning", "algorithms", "that", "analyse", "data", "used", "for", "classification", "and", "regression", "analysis", "."], "sentence-detokenized": "In machine learning, support-vector machines (SVMs, also support-vector networks) are supervised learning models with learning algorithms that analyse data used for classification and regression analysis.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 28], [28, 29], [29, 35], [36, 44], [45, 46], [46, 50], [50, 51], [52, 56], [57, 64], [64, 65], [65, 71], [72, 80], [80, 81], [82, 85], [86, 96], [97, 105], [106, 112], [113, 117], [118, 126], [127, 137], [138, 142], [143, 150], [151, 155], [156, 160], [161, 164], [165, 179], [180, 183], [184, 194], [195, 203], [203, 204]]}
{"doc_key": "ai-dev-14", "ner": [[10, 11, "task"], [13, 13, "task"], [4, 4, "metrics"], [17, 17, "metrics"], [19, 19, "researcher"], [21, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 13, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "2002", ")", "proposed", "TER", "as", "an", "automatic", "metric", "for", "Machine", "Translation", "(", "MT", ")", "evaluation", ",", "METEOR", ",", "Banerjee", "and", "Lavie", ",", "(", "2005", ")", ",", "etc", ".", "Many", "other", "methods", "have", "been", "proposed", "to", "revise", "or", "improve", "it", "."], "sentence-detokenized": "(2002) proposed TER as an automatic metric for Machine Translation (MT) evaluation, METEOR, Banerjee and Lavie, (2005), etc. Many other methods have been proposed to revise or improve it.", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 15], [16, 19], [20, 22], [23, 25], [26, 35], [36, 42], [43, 46], [47, 54], [55, 66], [67, 68], [68, 70], [70, 71], [72, 82], [82, 83], [84, 90], [90, 91], [92, 100], [101, 104], [105, 110], [110, 111], [112, 113], [113, 117], [117, 118], [118, 119], [120, 123], [123, 124], [125, 129], [130, 135], [136, 143], [144, 148], [149, 153], [154, 162], [163, 165], [166, 172], [173, 175], [176, 183], [184, 186], [186, 187]]}
{"doc_key": "ai-dev-15", "ner": [[3, 4, "misc"], [8, 8, "organisation"], [11, 11, "organisation"], [15, 16, "researcher"], [14, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 11, 11, "origin", "", false, false], [11, 11, 8, 8, "part-of", "", false, false], [15, 16, 11, 11, "role", "", false, false], [14, 19, 11, 11, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "contains", "a", "meta", "-ontology", "created", "by", "the", "IEEE", "working", "group", "P1600.1", "(", "originally", "by", "Ian", "Niles", "and", "Adam", "Pease", ")", "."], "sentence-detokenized": "It contains a meta-ontology created by the IEEE working group P1600.1 (originally by Ian Niles and Adam Pease).", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 18], [18, 27], [28, 35], [36, 38], [39, 42], [43, 47], [48, 55], [56, 61], [62, 69], [70, 71], [71, 81], [82, 84], [85, 88], [89, 94], [95, 98], [99, 103], [104, 109], [109, 110], [110, 111]]}
{"doc_key": "ai-dev-16", "ner": [[0, 3, "misc"], [33, 35, "algorithm"], [37, 38, "algorithm"], [41, 42, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[33, 35, 0, 3, "part-of", "", true, false], [37, 38, 0, 3, "part-of", "", true, false], [41, 42, 37, 38, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "Cryo", "Electron", "Tomography", ",", "where", "a", "limited", "number", "of", "projections", "are", "obtained", "due", "to", "hardware", "limitations", "and", "to", "avoid", "damage", "to", "the", "biological", "sample", ",", "it", "can", "be", "used", "in", "combination", "with", "compressive", "sensing", "techniques", "or", "regularisation", "functions", "(", "e.g.", "Huber", "loss", ")", "to", "improve", "reconstruction", "for", "better", "interpretation", "."], "sentence-detokenized": "In Cryo Electron Tomography, where a limited number of projections are obtained due to hardware limitations and to avoid damage to the biological sample, it can be used in combination with compressive sensing techniques or regularisation functions (e.g. Huber loss) to improve reconstruction for better interpretation.", "token2charspan": [[0, 2], [3, 7], [8, 16], [17, 27], [27, 28], [29, 34], [35, 36], [37, 44], [45, 51], [52, 54], [55, 66], [67, 70], [71, 79], [80, 83], [84, 86], [87, 95], [96, 107], [108, 111], [112, 114], [115, 120], [121, 127], [128, 130], [131, 134], [135, 145], [146, 152], [152, 153], [154, 156], [157, 160], [161, 163], [164, 168], [169, 171], [172, 183], [184, 188], [189, 200], [201, 208], [209, 219], [220, 222], [223, 237], [238, 247], [248, 249], [249, 253], [254, 259], [260, 264], [264, 265], [266, 268], [269, 276], [277, 291], [292, 295], [296, 302], [303, 317], [317, 318]]}
{"doc_key": "ai-dev-17", "ner": [[4, 4, "misc"], [7, 7, "programlang"], [10, 11, "algorithm"], [13, 14, "algorithm"], [18, 19, "algorithm"], [25, 27, "product"], [30, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 4, 7, 7, "part-of", "", false, false], [10, 11, 4, 4, "type-of", "", false, false], [13, 14, 4, 4, "type-of", "", false, false], [18, 19, 4, 4, "type-of", "", false, false], [25, 27, 7, 7, "general-affiliation", "", true, false], [25, 27, 7, 7, "part-of", "", true, false], [30, 30, 25, 27, "role", "publishes", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["An", "application", "of", "various", "whitening", "procedures", "in", "R", ",", "including", "ZCA", "whitening", "and", "PCA", "whitening", "as", "well", "as", "CCA", "whitening", ",", "is", "available", "in", "the", "whitening", "R", "package", "published", "in", "CRAN", "."], "sentence-detokenized": "An application of various whitening procedures in R, including ZCA whitening and PCA whitening as well as CCA whitening, is available in the whitening R package published in CRAN.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 25], [26, 35], [36, 46], [47, 49], [50, 51], [51, 52], [53, 62], [63, 66], [67, 76], [77, 80], [81, 84], [85, 94], [95, 97], [98, 102], [103, 105], [106, 109], [110, 119], [119, 120], [121, 123], [124, 133], [134, 136], [137, 140], [141, 150], [151, 152], [153, 160], [161, 170], [171, 173], [174, 178], [178, 179]]}
{"doc_key": "ai-dev-18", "ner": [[28, 28, "product"], [27, 31, "product"], [32, 32, "product"], [34, 34, "product"], [36, 36, "product"], [38, 39, "product"], [41, 42, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[28, 28, 32, 32, "compare", "", false, false], [28, 28, 34, 34, "compare", "", false, false], [28, 28, 36, 36, "compare", "", false, false], [28, 28, 38, 39, "compare", "", false, false], [28, 28, 41, 42, "compare", "", false, false], [27, 31, 32, 32, "compare", "", false, false], [27, 31, 34, 34, "compare", "", false, false], [27, 31, 36, 36, "compare", "", false, false], [27, 31, 38, 39, "compare", "", false, false], [27, 31, 41, 42, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Today", ",", "this", "field", "has", "become", "even", "more", "daunting", "and", "complex", "with", "the", "addition", "of", "circuit", ",", "system", "and", "signal", "analysis", "and", "design", "languages", "and", "software", ",", "from", "MATLAB", "and", "Simulink", "to", "NumPy", ",", "VHDL", ",", "PSpice", ",", "Verilog", "and", "even", "Assembly", "language", "."], "sentence-detokenized": "Today, this field has become even more daunting and complex with the addition of circuit, system and signal analysis and design languages and software, from MATLAB and Simulink to NumPy, VHDL, PSpice, Verilog and even Assembly language.", "token2charspan": [[0, 5], [5, 6], [7, 11], [12, 17], [18, 21], [22, 28], [29, 33], [34, 38], [39, 47], [48, 51], [52, 59], [60, 64], [65, 68], [69, 77], [78, 80], [81, 88], [88, 89], [90, 96], [97, 100], [101, 107], [108, 116], [117, 120], [121, 127], [128, 137], [138, 141], [142, 150], [150, 151], [152, 156], [157, 163], [164, 167], [168, 176], [177, 179], [180, 185], [185, 186], [187, 191], [191, 192], [193, 199], [199, 200], [201, 208], [209, 212], [213, 217], [218, 226], [227, 235], [235, 236]]}
{"doc_key": "ai-dev-19", "ner": [[7, 10, "person"], [13, 14, "person"], [16, 18, "organisation"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 18, 13, 14, "origin", "", false, false], [20, 20, 16, 18, "artifact", "builds", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "company", "was", "founded", "in", "1937", "by", "Kiichiro", "Toyoda", "as", "a", "subsidiary", "of", "Sakichi", "Toyoda", "'s", "Toyota", "Industries", "to", "produce", "automobiles", "."], "sentence-detokenized": "The company was founded in 1937 by Kiichiro Toyoda as a subsidiary of Sakichi Toyoda's Toyota Industries to produce automobiles.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 26], [27, 31], [32, 34], [35, 43], [44, 50], [51, 53], [54, 55], [56, 66], [67, 69], [70, 77], [78, 84], [84, 86], [87, 93], [94, 104], [105, 107], [108, 115], [116, 127], [127, 128]]}
{"doc_key": "ai-dev-20", "ner": [[1, 6, "field"], [52, 53, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[52, 53, 1, 6, "origin", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Unsupervised", "learning", ",", "on", "the", "other", "hand", ",", "assumes", "training", "data", "that", "has", "not", "been", "manually", "labelled", "and", "attempts", "to", "find", "natural", "patterns", "in", "the", "data", "that", "can", "be", "used", "to", "determine", "the", "correct", "output", "value", "for", "new", "data", "samples", ".", "A", "combination", "of", "the", "two", "that", "has", "recently", "been", "explored", "is", "semi-supervised", "learning", ",", "which", "uses", "a", "combination", "of", "labelled", "and", "unlabelled", "data", "(", "typically", "a", "small", "set", "of", "labelled", "data", "combined", "with", "a", "large", "amount", "of", "unlabelled", "data", ")", "."], "sentence-detokenized": "Unsupervised learning, on the other hand, assumes training data that has not been manually labelled and attempts to find natural patterns in the data that can be used to determine the correct output value for new data samples. A combination of the two that has recently been explored is semi-supervised learning, which uses a combination of labelled and unlabelled data (typically a small set of labelled data combined with a large amount of unlabelled data).", "token2charspan": [[0, 12], [13, 21], [21, 22], [23, 25], [26, 29], [30, 35], [36, 40], [40, 41], [42, 49], [50, 58], [59, 63], [64, 68], [69, 72], [73, 76], [77, 81], [82, 90], [91, 99], [100, 103], [104, 112], [113, 115], [116, 120], [121, 128], [129, 137], [138, 140], [141, 144], [145, 149], [150, 154], [155, 158], [159, 161], [162, 166], [167, 169], [170, 179], [180, 183], [184, 191], [192, 198], [199, 204], [205, 208], [209, 212], [213, 217], [218, 225], [225, 226], [227, 228], [229, 240], [241, 243], [244, 247], [248, 251], [252, 256], [257, 260], [261, 269], [270, 274], [275, 283], [284, 286], [287, 302], [303, 311], [311, 312], [313, 318], [319, 323], [324, 325], [326, 337], [338, 340], [341, 349], [350, 353], [354, 364], [365, 369], [370, 371], [371, 380], [381, 382], [383, 388], [389, 392], [393, 395], [396, 404], [405, 409], [410, 418], [419, 423], [424, 425], [426, 431], [432, 438], [439, 441], [442, 452], [453, 457], [457, 458], [458, 459]]}
{"doc_key": "ai-dev-21", "ner": [[22, 22, "organisation"], [24, 24, "product"], [26, 27, "organisation"], [29, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[24, 24, 22, 22, "artifact", "", false, false], [26, 27, 29, 29, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Despite", "these", "humanoid", "robots", "aimed", "at", "utilitarian", "uses", ",", "there", "are", "also", "some", "humanoid", "robots", "aimed", "at", "recreational", "uses", ",", "such", "as", "Sony", "'s", "QRIO", "and", "Wow", "Wee", "'s", "RoboSapien", "."], "sentence-detokenized": "Despite these humanoid robots aimed at utilitarian uses, there are also some humanoid robots aimed at recreational uses, such as Sony's QRIO and Wow Wee's RoboSapien.", "token2charspan": [[0, 7], [8, 13], [14, 22], [23, 29], [30, 35], [36, 38], [39, 50], [51, 55], [55, 56], [57, 62], [63, 66], [67, 71], [72, 76], [77, 85], [86, 92], [93, 98], [99, 101], [102, 114], [115, 119], [119, 120], [121, 125], [126, 128], [129, 133], [133, 135], [136, 140], [141, 144], [145, 148], [149, 152], [152, 154], [155, 165], [165, 166]]}
{"doc_key": "ai-dev-22", "ner": [[0, 2, "researcher"], [4, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 4, 12, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Webber", "became", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "in", "1991", ","], "sentence-detokenized": "Webber became a member of the Association for the Advancement of Artificial Intelligence in 1991,", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 22], [23, 25], [26, 29], [30, 41], [42, 45], [46, 49], [50, 61], [62, 64], [65, 75], [76, 88], [89, 91], [92, 96], [96, 97]]}
{"doc_key": "ai-dev-23", "ner": [[11, 12, "field"], [14, 14, "field"], [22, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 25, 11, 12, "part-of", "task_part_of_field", false, false], [22, 25, 14, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["At", "this", "company", "he", "was", "developing", "high", "-", "level", "ontologies", "for", "data", "mining", "and", "database", "technology", ",", "more", "specifically", "for", "intelligence", "and", "automated", "natural", "language", "understanding", "."], "sentence-detokenized": "At this company he was developing high-level ontologies for data mining and database technology, more specifically for intelligence and automated natural language understanding.", "token2charspan": [[0, 2], [3, 7], [8, 15], [16, 18], [19, 22], [23, 33], [34, 38], [38, 39], [39, 44], [45, 55], [56, 59], [60, 64], [65, 71], [72, 75], [76, 84], [85, 95], [95, 96], [97, 101], [102, 114], [115, 118], [119, 131], [132, 135], [136, 145], [146, 153], [154, 162], [163, 176], [176, 177]]}
{"doc_key": "ai-dev-24", "ner": [[18, 19, "misc"], [21, 24, "misc"], [26, 29, "misc"], [29, 29, "country"], [31, 33, "organisation"], [35, 35, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 19, 29, 29, "physical", "", false, false], [21, 24, 29, 29, "physical", "", false, false], [26, 29, 29, 29, "physical", "", false, false], [31, 33, 35, 35, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["However", ",", "in", "recent", "years", ",", "different", "e-services", "and", "related", "initiatives", "have", "emerged", "in", "developing", "countries", ",", "e.g.", "Nemmadi", "Project", ",", "MCA21", "Mission", "Mode", "Project", "or", "Digital", "India", "in", "India", ";", "Electronic", "Government", "Directorate", "in", "Pakistan", ",", "etc."], "sentence-detokenized": "However, in recent years, different e-services and related initiatives have emerged in developing countries, e.g. Nemmadi Project, MCA21 Mission Mode Project or Digital India in India; Electronic Government Directorate in Pakistan, etc.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 18], [19, 24], [24, 25], [26, 35], [36, 46], [47, 50], [51, 58], [59, 70], [71, 75], [76, 83], [84, 86], [87, 97], [98, 107], [107, 108], [109, 113], [114, 121], [122, 129], [129, 130], [131, 136], [137, 144], [145, 149], [150, 157], [158, 160], [161, 168], [169, 174], [175, 177], [178, 183], [183, 184], [185, 195], [196, 206], [207, 218], [219, 221], [222, 230], [230, 231], [232, 236]]}
{"doc_key": "ai-dev-25", "ner": [[11, 29, "misc"], [15, 16, "field"], [18, 19, "field"], [20, 22, "university"], [25, 28, "university"], [4, 7, "university"], [32, 32, "misc"], [34, 35, "field"], [38, 39, "misc"], [37, 37, "university"], [41, 46, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[11, 29, 15, 16, "topic", "", false, false], [11, 29, 18, 19, "topic", "", false, false], [11, 29, 20, 22, "origin", "", false, false], [20, 22, 25, 28, "part-of", "", false, false], [4, 7, 20, 22, "part-of", "", false, false], [32, 32, 34, 35, "topic", "", false, false], [32, 32, 37, 37, "origin", "", false, false], [38, 39, 37, 37, "origin", "", false, false], [37, 37, 41, 46, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["As", "a", "student", "of", "the", "Indian", "Statistical", "Institute", ",", "he", "obtained", "a", "PhD", "degree", "in", "Radio", "Physics", "and", "Electronics", "from", "Rajabazar", "Science", "College", "campus", "of", "Calcutta", "University", "in", "1979", "and", "another", "PhD", "degree", "in", "Electrical", "Engineering", "with", "Imperial", "College", "Diploma", "from", "Imperial", "College", ",", "University", "of", "London", "in", "1982", "."], "sentence-detokenized": "As a student of the Indian Statistical Institute, he obtained a PhD degree in Radio Physics and Electronics from Rajabazar Science College campus of Calcutta University in 1979 and another PhD degree in Electrical Engineering with Imperial College Diploma from Imperial College, University of London in 1982.", "token2charspan": [[0, 2], [3, 4], [5, 12], [13, 15], [16, 19], [20, 26], [27, 38], [39, 48], [48, 49], [50, 52], [53, 61], [62, 63], [64, 67], [68, 74], [75, 77], [78, 83], [84, 91], [92, 95], [96, 107], [108, 112], [113, 122], [123, 130], [131, 138], [139, 145], [146, 148], [149, 157], [158, 168], [169, 171], [172, 176], [177, 180], [181, 188], [189, 192], [193, 199], [200, 202], [203, 213], [214, 225], [226, 230], [231, 239], [240, 247], [248, 255], [256, 260], [261, 269], [270, 277], [277, 278], [279, 289], [290, 292], [293, 299], [300, 302], [303, 307], [307, 308]]}
{"doc_key": "ai-dev-26", "ner": [[0, 22, "location"], [23, 26, "misc"], [31, 32, "misc"], [34, 37, "person"], [33, 39, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[23, 26, 0, 22, "temporal", "", false, false], [31, 32, 0, 22, "temporal", "", false, false], [34, 37, 31, 32, "role", "actor_in", false, false], [33, 39, 31, 32, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Expo", "II", "has", "been", "announced", "as", "the", "world", "premiere", "location", "for", "several", "films", "that", "have", "never", "before", "been", "shown", "in", "3D", ",", "including", "The", "Wizard", "of", "Diamonds", "and", "the", "Universal", "short", "Hawaiian", "Nights", "with", "Mamie", "Van", "Doren", "and", "Pinky", "Lee", "."], "sentence-detokenized": "Expo II has been announced as the world premiere location for several films that have never before been shown in 3D, including The Wizard of Diamonds and the Universal short Hawaiian Nights with Mamie Van Doren and Pinky Lee.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 16], [17, 26], [27, 29], [30, 33], [34, 39], [40, 48], [49, 57], [58, 61], [62, 69], [70, 75], [76, 80], [81, 85], [86, 91], [92, 98], [99, 103], [104, 109], [110, 112], [113, 115], [115, 116], [117, 126], [127, 130], [131, 137], [138, 140], [141, 149], [150, 153], [154, 157], [158, 167], [168, 173], [174, 182], [183, 189], [190, 194], [195, 200], [201, 204], [205, 210], [211, 214], [215, 220], [221, 224], [224, 225]]}
{"doc_key": "ai-dev-27", "ner": [[7, 8, "researcher"], [17, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 17, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "maximum", "subsequence", "problem", "was", "proposed", "by", "Ulf", "Grenander", "in", "1977", "as", "a", "simplified", "model", "for", "maximum", "likelihood", "estimation", "of", "patterns", "in", "digitised", "images", "."], "sentence-detokenized": "The maximum subsequence problem was proposed by Ulf Grenander in 1977 as a simplified model for maximum likelihood estimation of patterns in digitised images.", "token2charspan": [[0, 3], [4, 11], [12, 23], [24, 31], [32, 35], [36, 44], [45, 47], [48, 51], [52, 61], [62, 64], [65, 69], [70, 72], [73, 74], [75, 85], [86, 91], [92, 95], [96, 103], [104, 114], [115, 125], [126, 128], [129, 137], [138, 140], [141, 150], [151, 157], [157, 158]]}
{"doc_key": "ai-dev-28", "ner": [[0, 1, "product"], [3, 4, "product"], [7, 8, "product"], [11, 11, "product"], [14, 15, "product"], [17, 20, "product"], [33, 33, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[33, 33, 0, 1, "part-of", "", false, false], [33, 33, 3, 4, "part-of", "", false, false], [33, 33, 7, 8, "part-of", "", false, false], [33, 33, 11, 11, "part-of", "", false, false], [33, 33, 14, 15, "part-of", "", false, false], [33, 33, 17, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["iPhone", "4S", ",", "iPad", "3", ",", "iPad", "Mini", "1G", ",", "iPad", "Air", ",", "iPad", "Pro", "1G", ",", "iPod", "Touch", "5", "G", "and", "later", "models", "all", "come", "with", "a", "more", "advanced", "voice", "assistant", "called", "Siri", "."], "sentence-detokenized": "iPhone 4S, iPad 3, iPad Mini 1G, iPad Air, iPad Pro 1G, iPod Touch 5G and later models all come with a more advanced voice assistant called Siri.", "token2charspan": [[0, 6], [7, 9], [9, 10], [11, 15], [16, 17], [17, 18], [19, 23], [24, 28], [29, 31], [31, 32], [33, 37], [38, 41], [41, 42], [43, 47], [48, 51], [52, 54], [54, 55], [56, 60], [61, 66], [67, 68], [68, 69], [70, 73], [74, 79], [80, 86], [87, 90], [91, 95], [96, 100], [101, 102], [103, 107], [108, 116], [117, 122], [123, 132], [133, 139], [140, 144], [144, 145]]}
{"doc_key": "ai-dev-29", "ner": [[7, 8, "metrics"], [11, 14, "metrics"], [16, 17, "metrics"], [37, 39, "metrics"], [44, 47, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 14, 37, 39, "named", "", false, false], [16, 17, 11, 14, "named", "", false, false], [37, 39, 44, 47, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["It", "is", "easy", "to", "check", "that", "the", "logistic", "loss", "and", "the", "binary", "cross", "entropy", "loss", "(", "Log", "loss", ")", "are", "actually", "the", "same", "(", "up", "to", "a", "multiplicative", "constant", "math", "\\", "frac", "{", "1", "}", "{", "Cross", "entropy", "loss", "is", "closely", "related", "to", "the", "Kullback", "-", "Leibler", "difference", "between", "the", "empirical", "distribution", "and", "the", "predicted", "distribution", "."], "sentence-detokenized": "It is easy to check that the logistic loss and the binary cross entropy loss (Log loss) are actually the same (up to a multiplicative constant math\\ frac {1} {Cross entropy loss is closely related to the Kullback-Leibler difference between the empirical distribution and the predicted distribution.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 13], [14, 19], [20, 24], [25, 28], [29, 37], [38, 42], [43, 46], [47, 50], [51, 57], [58, 63], [64, 71], [72, 76], [77, 78], [78, 81], [82, 86], [86, 87], [88, 91], [92, 100], [101, 104], [105, 109], [110, 111], [111, 113], [114, 116], [117, 118], [119, 133], [134, 142], [143, 147], [147, 148], [149, 153], [154, 155], [155, 156], [156, 157], [158, 159], [159, 164], [165, 172], [173, 177], [178, 180], [181, 188], [189, 196], [197, 199], [200, 203], [204, 212], [212, 213], [213, 220], [221, 231], [232, 239], [240, 243], [244, 253], [254, 266], [267, 270], [271, 274], [275, 284], [285, 297], [297, 298]]}
{"doc_key": "ai-dev-30", "ner": [[0, 2, "algorithm"], [11, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "EM", "algorithm", "is", "used", "to", "find", "the", "(", "local", ")", "maximum", "likelihood", "parameters", "of", "a", "statistical", "model", "when", "the", "equations", "can", "not", "be", "solved", "directly", "."], "sentence-detokenized": "The EM algorithm is used to find the (local) maximum likelihood parameters of a statistical model when the equations cannot be solved directly.", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 19], [20, 24], [25, 27], [28, 32], [33, 36], [37, 38], [38, 43], [43, 44], [45, 52], [53, 63], [64, 74], [75, 77], [78, 79], [80, 91], [92, 97], [98, 102], [103, 106], [107, 116], [117, 120], [120, 123], [124, 126], [127, 133], [134, 142], [142, 143]]}
{"doc_key": "ai-dev-31", "ner": [[11, 12, "task"], [15, 21, "task"], [22, 22, "task"], [25, 25, "task"], [6, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "research", "has", "formed", "the", "basis", "for", "the", "development", "of", "modern", "speech", "synthesis", "techniques", ",", "reading", "machines", "for", "the", "blind", ",", "speech", "perception", "and", "speech", "recognition", "studies", ",", "and", "the", "motor", "theory", "of", "speech", "perception", "."], "sentence-detokenized": "This research has formed the basis for the development of modern speech synthesis techniques, reading machines for the blind, speech perception and speech recognition studies, and the motor theory of speech perception.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 24], [25, 28], [29, 34], [35, 38], [39, 42], [43, 54], [55, 57], [58, 64], [65, 71], [72, 81], [82, 92], [92, 93], [94, 101], [102, 110], [111, 114], [115, 118], [119, 124], [124, 125], [126, 132], [133, 143], [144, 147], [148, 154], [155, 166], [167, 174], [174, 175], [176, 179], [180, 183], [184, 189], [190, 196], [197, 199], [200, 206], [207, 217], [217, 218]]}
{"doc_key": "ai-dev-32", "ner": [[0, 1, "product"], [2, 4, "misc"], [6, 6, "misc"], [10, 12, "misc"], [15, 15, "product"], [17, 17, "product"], [19, 19, "product"], [24, 24, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 4, 0, 1, "origin", "", false, false], [2, 4, 10, 12, "type-of", "", false, false], [2, 4, 15, 15, "related-to", "program_for", false, false], [2, 4, 17, 17, "related-to", "program_for", false, false], [2, 4, 19, 19, "related-to", "program_for", false, false], [2, 4, 24, 24, "related-to", "program_for", false, false], [6, 6, 2, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "Arduino", "integrated", "development", "environment", "(", "IDE", ")", "is", "a", "cross", "-platform", "application", "(", "for", "Windows", ",", "macOS", "and", "Linux", ")", "written", "in", "the", "Java", "programming", "language", "."], "sentence-detokenized": "The Arduino integrated development environment (IDE) is a cross-platform application (for Windows, macOS and Linux) written in the Java programming language.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 34], [35, 46], [47, 48], [48, 51], [51, 52], [53, 55], [56, 57], [58, 63], [63, 72], [73, 84], [85, 86], [86, 89], [90, 97], [97, 98], [99, 104], [105, 108], [109, 114], [114, 115], [116, 123], [124, 126], [127, 130], [131, 135], [136, 147], [148, 156], [156, 157]]}
{"doc_key": "ai-dev-33", "ner": [[0, 2, "algorithm"], [8, 10, "field"], [12, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 8, 10, "opposite", "", false, false], [12, 13, 8, 10, "related-to", "works_with", false, false], [15, 16, 8, 10, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Neural", "network", "research", "stagnated", "after", "the", "publication", "of", "machine", "learning", "research", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", "."], "sentence-detokenized": "Neural network research stagnated after the publication of machine learning research by Marvin Minsky and Seymour Papert (1969).", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 33], [34, 39], [40, 43], [44, 55], [56, 58], [59, 66], [67, 75], [76, 84], [85, 87], [88, 94], [95, 101], [102, 105], [106, 113], [114, 120], [121, 122], [122, 126], [126, 127], [127, 128]]}
{"doc_key": "ai-dev-34", "ner": [[18, 19, "organisation"], [21, 21, "organisation"], [24, 26, "country"], [28, 31, "organisation"], [32, 35, "country"], [36, 37, "organisation"], [40, 40, "country"], [42, 42, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[28, 31, 24, 26, "general-affiliation", "", false, false], [36, 37, 32, 35, "general-affiliation", "", false, false], [42, 42, 40, 40, "general-affiliation", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Only", "a", "few", "non-Japanese", "companies", "have", "managed", "to", "survive", "in", "this", "market", ",", "the", "main", "ones", "being", ":", "Adept", "Technology", ",", "St\u00e4ubli", ",", "the", "Swedish", "-", "Swiss", "company", "ABB", "Asea", "Brown", "Boveri", ",", "the", "German", "company", "KUKA", "Robotics", "and", "the", "Italian", "company", "Comau", "."], "sentence-detokenized": "Only a few non-Japanese companies have managed to survive in this market, the main ones being: Adept Technology, St\u00e4ubli, the Swedish-Swiss company ABB Asea Brown Boveri, the German company KUKA Robotics and the Italian company Comau.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 23], [24, 33], [34, 38], [39, 46], [47, 49], [50, 57], [58, 60], [61, 65], [66, 72], [72, 73], [74, 77], [78, 82], [83, 87], [88, 93], [93, 94], [95, 100], [101, 111], [111, 112], [113, 120], [120, 121], [122, 125], [126, 133], [133, 134], [134, 139], [140, 147], [148, 151], [152, 156], [157, 162], [163, 169], [169, 170], [171, 174], [175, 181], [182, 189], [190, 194], [195, 203], [204, 207], [208, 211], [212, 219], [220, 227], [228, 233], [233, 234]]}
{"doc_key": "ai-dev-35", "ner": [[7, 15, "conference"], [9, 9, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 9, 7, 15, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Research", "activities", "include", "an", "annual", "research", "conference", "called", "the", "RuleML", "Symposium", ",", "also", "known", "as", "RuleML", "for", "short", "."], "sentence-detokenized": "Research activities include an annual research conference called the RuleML Symposium, also known as RuleML for short.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 30], [31, 37], [38, 46], [47, 57], [58, 64], [65, 68], [69, 75], [76, 85], [85, 86], [87, 91], [92, 97], [98, 100], [101, 107], [108, 111], [112, 117], [117, 118]]}
{"doc_key": "ai-dev-36", "ner": [[8, 9, "field"], [11, 12, "field"], [14, 14, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Concepts", "are", "used", "as", "formal", "tools", "or", "models", "in", "mathematics", ",", "computer", "science", ",", "databases", "and", "artificial", "intelligence", "and", "are", "sometimes", "referred", "to", "as", "classes", ",", "schemas", "or", "categories", "."], "sentence-detokenized": "Concepts are used as formal tools or models in mathematics, computer science, databases and artificial intelligence and are sometimes referred to as classes, schemas or categories.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 20], [21, 27], [28, 33], [34, 36], [37, 43], [44, 46], [47, 58], [58, 59], [60, 68], [69, 76], [76, 77], [78, 87], [88, 91], [92, 102], [103, 115], [116, 119], [120, 123], [124, 133], [134, 142], [143, 145], [146, 148], [149, 156], [156, 157], [158, 165], [166, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-dev-37", "ner": [[6, 8, "organisation"], [11, 14, "organisation"], [17, 21, "organisation"], [20, 21, "organisation"], [25, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "won", "awards", "from", "the", "American", "Psychological", "Association", ",", "the", "National", "Academy", "of", "Sciences", ",", "the", "Royal", "Society", "for", "Cognitive", "Neuroscience", ",", "and", "the", "American", "Humanist", "Association", "."], "sentence-detokenized": "He has won awards from the American Psychological Association, the National Academy of Sciences, the Royal Society for Cognitive Neuroscience, and the American Humanist Association.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 17], [18, 22], [23, 26], [27, 35], [36, 49], [50, 61], [61, 62], [63, 66], [67, 75], [76, 83], [84, 86], [87, 95], [95, 96], [97, 100], [101, 106], [107, 114], [115, 118], [119, 128], [129, 141], [141, 142], [143, 146], [147, 150], [151, 159], [160, 168], [169, 180], [180, 181]]}
{"doc_key": "ai-dev-38", "ner": [[1, 2, "person"], [4, 5, "person"], [7, 8, "person"], [15, 19, "person"], [21, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[21, 27, 15, 19, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Starring", "Harrison", "Ford", ",", "Rutger", "Hauer", "and", "Sean", "Young", ",", "the", "film", "is", "based", "on", "Philip", "K", ".", "Dick", "'s", "novel", "Do", "Androids", "Dream", "of", "Electric", "Sheep", "?", "(", "1968", ")", "."], "sentence-detokenized": "Starring Harrison Ford, Rutger Hauer and Sean Young, the film is based on Philip K. Dick's novel Do Androids Dream of Electric Sheep? (1968).", "token2charspan": [[0, 8], [9, 17], [18, 22], [22, 23], [24, 30], [31, 36], [37, 40], [41, 45], [46, 51], [51, 52], [53, 56], [57, 61], [62, 64], [65, 70], [71, 73], [74, 80], [81, 82], [82, 83], [84, 88], [88, 90], [91, 96], [97, 99], [100, 108], [109, 114], [115, 117], [118, 126], [127, 132], [132, 133], [134, 135], [135, 139], [139, 140], [140, 141]]}
{"doc_key": "ai-dev-39", "ner": [[9, 10, "task"], [0, 3, "algorithm"], [12, 13, "field"], [15, 16, "task"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 10, 0, 3, "usage", "", false, false], [9, 10, 12, 13, "part-of", "task_part_of_field", false, false], [9, 10, 15, 16, "part-of", "task_part_of_field", false, false], [9, 10, 18, 19, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["K", "-means", "clustering", "algorithms", "have", "long", "been", "used", "for", "image", "segmentation", ",", "pattern", "recognition", ",", "object", "detection", "and", "medical", "imaging", "."], "sentence-detokenized": "K-means clustering algorithms have long been used for image segmentation, pattern recognition, object detection and medical imaging.", "token2charspan": [[0, 1], [1, 7], [8, 18], [19, 29], [30, 34], [35, 39], [40, 44], [45, 49], [50, 53], [54, 59], [60, 72], [72, 73], [74, 81], [82, 93], [93, 94], [95, 101], [102, 111], [112, 115], [116, 123], [124, 131], [131, 132]]}
{"doc_key": "ai-dev-40", "ner": [[14, 14, "algorithm"], [11, 17, "algorithm"], [20, 20, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["General", "sampling", "from", "the", "truncated", "normal", "can", "be", "obtained", "using", "approximations", "to", "the", "normal", "CDF", "and", "probit", "function", ",", "and", "R", "has", "the", "codertnorm", "(", ")", "/", "code", "function", "to", "generate", "truncated", "normal", "samples", "."], "sentence-detokenized": "General sampling from the truncated normal can be obtained using approximations to the normal CDF and probit function, and R has the codertnorm()/code function to generate truncated normal samples.", "token2charspan": [[0, 7], [8, 16], [17, 21], [22, 25], [26, 35], [36, 42], [43, 46], [47, 49], [50, 58], [59, 64], [65, 79], [80, 82], [83, 86], [87, 93], [94, 97], [98, 101], [102, 108], [109, 117], [117, 118], [119, 122], [123, 124], [125, 128], [129, 132], [133, 143], [143, 144], [144, 145], [145, 146], [146, 150], [151, 159], [160, 162], [163, 171], [172, 181], [182, 188], [189, 196], [196, 197]]}
{"doc_key": "ai-dev-41", "ner": [[7, 7, "university"], [9, 9, "university"], [11, 13, "university"], [15, 17, "university"], [19, 22, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "also", "received", "honorary", "doctorates", "from", "Newcastle", ",", "Surrey", ",", "Tel", "Aviv", "University", ",", "Simon", "Fraser", "University", "and", "the", "University", "of", "Troms\u00f8", "."], "sentence-detokenized": "He has also received honorary doctorates from Newcastle, Surrey, Tel Aviv University, Simon Fraser University and the University of Troms\u00f8.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 20], [21, 29], [30, 40], [41, 45], [46, 55], [55, 56], [57, 63], [63, 64], [65, 68], [69, 73], [74, 84], [84, 85], [86, 91], [92, 98], [99, 109], [110, 113], [114, 117], [118, 128], [129, 131], [132, 138], [138, 139]]}
{"doc_key": "ai-dev-42", "ner": [[1, 1, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "Java", "applet", "that", "uses", "zero", "-", "based", "array", "indexes", "together", "with", "a", "convenience", "method", "for", "printing", "the", "solved", "sequence", "of", "operations", ":"], "sentence-detokenized": "A Java applet that uses zero-based array indexes together with a convenience method for printing the solved sequence of operations:", "token2charspan": [[0, 1], [2, 6], [7, 13], [14, 18], [19, 23], [24, 28], [28, 29], [29, 34], [35, 40], [41, 48], [49, 57], [58, 62], [63, 64], [65, 76], [77, 83], [84, 87], [88, 96], [97, 100], [101, 107], [108, 116], [117, 119], [120, 130], [130, 131]]}
{"doc_key": "ai-dev-43", "ner": [[7, 8, "metrics"], [11, 12, "metrics"], [20, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Such", "networks", "are", "usually", "trained", "under", "the", "Cross", "-entropy", "(", "or", "cross", "-entropy", ")", "regime", "and", "yield", "a", "non-linear", "variant", "of", "multinomial", "logistic", "regression", "."], "sentence-detokenized": "Such networks are usually trained under the Cross-entropy (or cross-entropy) regime and yield a non-linear variant of multinomial logistic regression.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 25], [26, 33], [34, 39], [40, 43], [44, 49], [49, 57], [58, 59], [59, 61], [62, 67], [67, 75], [75, 76], [77, 83], [84, 87], [88, 93], [94, 95], [96, 106], [107, 114], [115, 117], [118, 129], [130, 138], [139, 149], [149, 150]]}
{"doc_key": "ai-dev-44", "ner": [[0, 1, "conference"], [3, 3, "misc"], [4, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["ACL", "has", "a", "European", "chapter", "(", "European", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ")", "."], "sentence-detokenized": "ACL has a European chapter (European Chapter of the Association for Computational Linguistics).", "token2charspan": [[0, 3], [4, 7], [8, 9], [10, 18], [19, 26], [27, 28], [28, 36], [37, 44], [45, 47], [48, 51], [52, 63], [64, 67], [68, 81], [82, 93], [93, 94], [94, 95]]}
{"doc_key": "ai-dev-45", "ner": [[3, 4, "researcher"], [6, 8, "researcher"], [23, 23, "misc"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 23, 23, "role", "", false, false], [6, 8, 23, 23, "role", "", false, false], [23, 23, 25, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "professors", ",", "Hal", "Abelson", "and", "Gerald", "Jay", "Sussman", ",", "preferred", "to", "remain", "neutral", "-", "their", "group", "was", "variously", "referred", "to", "as", "the", "Swiss", "and", "MAC", "Project", "for", "the", "next", "30", "years", "."], "sentence-detokenized": "Two professors, Hal Abelson and Gerald Jay Sussman, preferred to remain neutral - their group was variously referred to as the Swiss and MAC Project for the next 30 years.", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 27], [28, 31], [32, 38], [39, 42], [43, 50], [50, 51], [52, 61], [62, 64], [65, 71], [72, 79], [80, 81], [82, 87], [88, 93], [94, 97], [98, 107], [108, 116], [117, 119], [120, 122], [123, 126], [127, 132], [133, 136], [137, 140], [141, 148], [149, 152], [153, 156], [157, 161], [162, 164], [165, 170], [170, 171]]}
{"doc_key": "ai-dev-46", "ner": [[1, 2, "misc"], [4, 4, "researcher"], [6, 9, "university"], [14, 14, "organisation"], [23, 26, "organisation"], [19, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 2, 4, 4, "temporal", "", false, false], [4, 4, 14, 14, "physical", "", false, false], [4, 4, 14, 14, "role", "", false, false], [4, 4, 23, 26, "role", "", false, false], [23, 26, 6, 9, "part-of", "", false, false], [19, 22, 23, 26, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Following", "his", "PhD", ",", "Ghahramani", "joined", "the", "University", "of", "Toronto", "in", "1995", "as", "an", "ITRC", "Postdoctoral", "Fellow", ",", "working", "with", "Geoffrey", "Hinton", "in", "the", "Artificial", "Intelligence", "Laboratory", "."], "sentence-detokenized": "Following his PhD, Ghahramani joined the University of Toronto in 1995 as an ITRC Postdoctoral Fellow, working with Geoffrey Hinton in the Artificial Intelligence Laboratory.", "token2charspan": [[0, 9], [10, 13], [14, 17], [17, 18], [19, 29], [30, 36], [37, 40], [41, 51], [52, 54], [55, 62], [63, 65], [66, 70], [71, 73], [74, 76], [77, 81], [82, 94], [95, 101], [101, 102], [103, 110], [111, 115], [116, 124], [125, 131], [132, 134], [135, 138], [139, 149], [150, 162], [163, 173], [173, 174]]}
{"doc_key": "ai-dev-47", "ner": [[22, 23, "metrics"], [25, 25, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[25, 25, 22, 23, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Subsequent", "work", "focused", "on", "addressing", "these", "issues", ",", "but", "it", "was", "not", "until", "the", "advent", "of", "modern", "computing", "and", "the", "popularisation", "of", "Maximum", "Likelihood", "(", "MLE", ")", "parameterisation", "techniques", "that", "research", "really", "began", "."], "sentence-detokenized": "Subsequent work focused on addressing these issues, but it was not until the advent of modern computing and the popularisation of Maximum Likelihood (MLE) parameterisation techniques that research really began.", "token2charspan": [[0, 10], [11, 15], [16, 23], [24, 26], [27, 37], [38, 43], [44, 50], [50, 51], [52, 55], [56, 58], [59, 62], [63, 66], [67, 72], [73, 76], [77, 83], [84, 86], [87, 93], [94, 103], [104, 107], [108, 111], [112, 126], [127, 129], [130, 137], [138, 148], [149, 150], [150, 153], [153, 154], [155, 171], [172, 182], [183, 187], [188, 196], [197, 203], [204, 209], [209, 210]]}
{"doc_key": "ai-dev-48", "ner": [[5, 6, "person"], [9, 10, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "series", "was", "produced", "by", "David", "Fincher", "and", "starred", "Kevin", "Spacey", "."], "sentence-detokenized": "The series was produced by David Fincher and starred Kevin Spacey.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 26], [27, 32], [33, 40], [41, 44], [45, 52], [53, 58], [59, 65], [65, 66]]}
{"doc_key": "ai-dev-49", "ner": [[17, 17, "metrics"], [24, 26, "algorithm"], [31, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[24, 26, 31, 33, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Due", "to", "limitations", "in", "computational", "power", ",", "current", "in", "silico", "methods", "often", "have", "to", "sacrifice", "speed", "for", "accuracy", ";", "for", "example", ",", "use", "fast", "protein", "docking", "methods", "instead", "of", "computationally", "costly", "free", "energy", "calculations", "."], "sentence-detokenized": "Due to limitations in computational power, current in silico methods often have to sacrifice speed for accuracy; for example, use fast protein docking methods instead of computationally costly free energy calculations.", "token2charspan": [[0, 3], [4, 6], [7, 18], [19, 21], [22, 35], [36, 41], [41, 42], [43, 50], [51, 53], [54, 60], [61, 68], [69, 74], [75, 79], [80, 82], [83, 92], [93, 98], [99, 102], [103, 111], [111, 112], [113, 116], [117, 124], [124, 125], [126, 129], [130, 134], [135, 142], [143, 150], [151, 158], [159, 166], [167, 169], [170, 185], [186, 192], [193, 197], [198, 204], [205, 217], [217, 218]]}
{"doc_key": "ai-dev-50", "ner": [[8, 8, "country"], [10, 10, "country"], [12, 12, "country"], [14, 14, "country"], [16, 16, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "had", "more", "than", "30", "locations", "in", "the", "USA", ",", "Canada", ",", "Mexico", ",", "Brazil", "and", "Argentina", "."], "sentence-detokenized": "It had more than 30 locations in the USA, Canada, Mexico, Brazil and Argentina.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 19], [20, 29], [30, 32], [33, 36], [37, 40], [40, 41], [42, 48], [48, 49], [50, 56], [56, 57], [58, 64], [65, 68], [69, 78], [78, 79]]}
{"doc_key": "ai-dev-51", "ner": [[4, 5, "field"], [10, 12, "product"], [14, 16, "algorithm"], [19, 20, "task"], [22, 23, "task"], [30, 30, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 12, 4, 5, "part-of", "", false, false], [10, 12, 14, 16, "usage", "", false, false], [19, 20, 4, 5, "part-of", "task_part_of_field", false, false], [19, 20, 30, 30, "related-to", "performs", false, false], [22, 23, 4, 5, "part-of", "task_part_of_field", false, false], [22, 23, 30, 30, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Example", "of", "a", "typical", "computer", "vision", "computational", "pipeline", "for", "a", "face", "recognition", "system", "using", "k", "-", "NN", ",", "including", "feature", "extraction", "and", "dimension", "reduction", "preprocessing", "steps", "(", "usually", "implemented", "with", "OpenCV", ")", ":"], "sentence-detokenized": "Example of a typical computer vision computational pipeline for a face recognition system using k -NN, including feature extraction and dimension reduction preprocessing steps (usually implemented with OpenCV):", "token2charspan": [[0, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 36], [37, 50], [51, 59], [60, 63], [64, 65], [66, 70], [71, 82], [83, 89], [90, 95], [96, 97], [98, 99], [99, 101], [101, 102], [103, 112], [113, 120], [121, 131], [132, 135], [136, 145], [146, 155], [156, 169], [170, 175], [176, 177], [177, 184], [185, 196], [197, 201], [202, 208], [208, 209], [209, 210]]}
{"doc_key": "ai-dev-52", "ner": [[8, 10, "algorithm"], [12, 12, "misc"], [14, 15, "misc"], [17, 17, "misc"], [21, 21, "programlang"], [23, 23, "product"], [27, 28, "algorithm"], [31, 32, "misc"], [34, 34, "misc"], [36, 36, "misc"], [38, 38, "misc"], [45, 45, "misc"], [48, 48, "misc"], [51, 51, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "has", "a", "rich", "set", "of", "features", ",", "constraint", "logic", "programming", ",", "multi-threading", ",", "unit", "testing", ",", "GUI", ",", "interfacing", "to", "Java", ",", "ODBC", "and", "others", ",", "literate", "programming", ",", "a", "web", "server", ",", "SGML", ",", "RDF", ",", "RDFS", ",", "developer", "tools", "(", "including", "an", "IDE", "with", "GUI", "debugger", "and", "GUI", "profiler", ")", "and", "extensive", "documentation", "."], "sentence-detokenized": "It has a rich set of features, constraint logic programming, multi-threading, unit testing, GUI, interfacing to Java, ODBC and others, literate programming, a web server, SGML, RDF, RDFS, developer tools (including an IDE with GUI debugger and GUI profiler) and extensive documentation.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 13], [14, 17], [18, 20], [21, 29], [29, 30], [31, 41], [42, 47], [48, 59], [59, 60], [61, 76], [76, 77], [78, 82], [83, 90], [90, 91], [92, 95], [95, 96], [97, 108], [109, 111], [112, 116], [116, 117], [118, 122], [123, 126], [127, 133], [133, 134], [135, 143], [144, 155], [155, 156], [157, 158], [159, 162], [163, 169], [169, 170], [171, 175], [175, 176], [177, 180], [180, 181], [182, 186], [186, 187], [188, 197], [198, 203], [204, 205], [205, 214], [215, 217], [218, 221], [222, 226], [227, 230], [231, 239], [240, 243], [244, 247], [248, 256], [256, 257], [258, 261], [262, 271], [272, 285], [285, 286]]}
{"doc_key": "ai-dev-53", "ner": [[1, 2, "field"], [0, 7, "field"], [9, 12, "misc"], [14, 18, "misc"], [19, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 12, 1, 2, "part-of", "", true, false], [9, 12, 0, 7, "part-of", "", false, false], [9, 12, 19, 20, "type-of", "", false, false], [14, 18, 1, 2, "part-of", "", false, false], [14, 18, 0, 7, "part-of", "", false, false], [14, 18, 19, 20, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "computer", "vision", "and", "image", "processing", ",", "the", "concept", "of", "scale", "space", "representation", "and", "Gaussian", "derivative", "operators", "is", "a", "canonical", "multiscale", "representation", "."], "sentence-detokenized": "In computer vision and image processing, the concept of scale space representation and Gaussian derivative operators is a canonical multiscale representation.", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 22], [23, 28], [29, 39], [39, 40], [41, 44], [45, 52], [53, 55], [56, 61], [62, 67], [68, 82], [83, 86], [87, 95], [96, 106], [107, 116], [117, 119], [120, 121], [122, 131], [132, 142], [143, 157], [157, 158]]}
{"doc_key": "ai-dev-54", "ner": [[10, 10, "organisation"], [9, 23, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 10, 9, 23, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "also", "president", "of", "the", "Neural", "Information", "Processing", "Systems", "Foundation", ",", "a", "non-profit", "organisation", "that", "runs", "the", "annual", "Neural", "Information", "Processing", "Systems", "Conference", "."], "sentence-detokenized": "He is also president of the Neural Information Processing Systems Foundation, a non-profit organisation that runs the annual Neural Information Processing Systems Conference.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 20], [21, 23], [24, 27], [28, 34], [35, 46], [47, 57], [58, 65], [66, 76], [76, 77], [78, 79], [80, 90], [91, 103], [104, 108], [109, 113], [114, 117], [118, 124], [125, 131], [132, 143], [144, 154], [155, 162], [163, 173], [173, 174]]}
{"doc_key": "ai-dev-55", "ner": [[1, 2, "task"], [5, 6, "metrics"], [12, 13, "misc"], [16, 16, "task"], [17, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 5, 6, "usage", "", false, false], [5, 6, 12, 13, "type-of", "", false, false], [16, 16, 17, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["For", "regression", "analysis", "problems", "the", "squared", "error", "can", "be", "used", "as", "a", "loss", "function", ",", "for", "classification", "cross", "entropy", "can", "be", "used", "."], "sentence-detokenized": "For regression analysis problems the squared error can be used as a loss function, for classification cross entropy can be used.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 32], [33, 36], [37, 44], [45, 50], [51, 54], [55, 57], [58, 62], [63, 65], [66, 67], [68, 72], [73, 81], [81, 82], [83, 86], [87, 101], [102, 107], [108, 115], [116, 119], [120, 122], [123, 127], [127, 128]]}
{"doc_key": "ai-dev-56", "ner": [[0, 0, "researcher"], [19, 22, "conference"], [28, 28, "conference"], [37, 38, "university"], [40, 53, "field"], [50, 54, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 19, 22, "role", "", false, false], [0, 0, 37, 38, "physical", "", false, false], [0, 0, 37, 38, "role", "", false, false], [0, 0, 50, 54, "role", "", false, false], [19, 22, 28, 28, "named", "same", false, false], [37, 38, 40, 53, "related-to", "subject_of_study_at", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Lafferty", "has", "served", "in", "many", "prestigious", "positions", ",", "including", ":", "1", ")", "Programme", "co-chair", "and", "general", "co-chair", "of", "the", "Neural", "Information", "Processing", "Systems", "(", "Neural", "Information", "Processing", "Systems", "Conference", ")", "Foundation", "conferences", ";", "2", ")", "Co-director", "of", "CMU", "'s", "new", "Machine", "Learning", "PhD", "Programme", ";", "3", ")", "Associate", "editor", "of", "Journal", "of", "Machine", "Learning", "Research"], "sentence-detokenized": "Lafferty has served in many prestigious positions, including: 1) Programme co-chair and general co-chair of the Neural Information Processing Systems (Neural Information Processing Systems Conference) Foundation conferences; 2) Co-director of CMU's new Machine Learning PhD Programme; 3) Associate editor of Journal of Machine Learning Research", "token2charspan": [[0, 8], [9, 12], [13, 19], [20, 22], [23, 27], [28, 39], [40, 49], [49, 50], [51, 60], [60, 61], [62, 63], [63, 64], [65, 74], [75, 83], [84, 87], [88, 95], [96, 104], [105, 107], [108, 111], [112, 118], [119, 130], [131, 141], [142, 149], [150, 151], [151, 157], [158, 169], [170, 180], [181, 188], [189, 199], [199, 200], [201, 211], [212, 223], [223, 224], [225, 226], [226, 227], [228, 239], [240, 242], [243, 246], [246, 248], [249, 252], [253, 260], [261, 269], [270, 273], [274, 283], [283, 284], [285, 286], [286, 287], [288, 297], [298, 304], [305, 307], [308, 315], [316, 318], [319, 326], [327, 335], [336, 344]]}
{"doc_key": "ai-dev-57", "ner": [[1, 1, "misc"], [4, 4, "algorithm"], [6, 6, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 1, 1, "type-of", "", false, false], [6, 6, 1, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Convex", "algorithms", "such", "as", "AdaBoost", "and", "LogitBoost", "can", "be", "defeated", "by", "random", "noise", "because", "they", "can", "not", "learn", "basic", "and", "learnable", "combinations", "of", "weak", "hypotheses", "."], "sentence-detokenized": "Convex algorithms such as AdaBoost and LogitBoost can be defeated by random noise because they cannot learn basic and learnable combinations of weak hypotheses.", "token2charspan": [[0, 6], [7, 17], [18, 22], [23, 25], [26, 34], [35, 38], [39, 49], [50, 53], [54, 56], [57, 65], [66, 68], [69, 75], [76, 81], [82, 89], [90, 94], [95, 98], [98, 101], [102, 107], [108, 113], [114, 117], [118, 127], [128, 140], [141, 143], [144, 148], [149, 159], [159, 160]]}
{"doc_key": "ai-dev-58", "ner": [[0, 0, "product"], [1, 7, "product"], [10, 12, "algorithm"], [18, 19, "algorithm"], [22, 27, "task"], [21, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 1, 7, "type-of", "", false, false], [0, 0, 10, 12, "usage", "", false, false], [0, 0, 18, 19, "usage", "", false, false], [18, 19, 22, 27, "related-to", "used_for", true, false], [18, 19, 21, 31, "related-to", "used_for", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Apertium", "is", "a", "shallow", "transfer", "machine", "translation", "system", "that", "uses", "finite", "state", "transducers", "for", "all", "lexical", "transformations", "and", "hidden", "Markov", "models", "for", "part", "-", "of", "-", "speech", "tagging", "or", "lexical", "category", "disambiguation", "."], "sentence-detokenized": "Apertium is a shallow transfer machine translation system that uses finite state transducers for all lexical transformations and hidden Markov models for part-of-speech tagging or lexical category disambiguation.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 21], [22, 30], [31, 38], [39, 50], [51, 57], [58, 62], [63, 67], [68, 74], [75, 80], [81, 92], [93, 96], [97, 100], [101, 108], [109, 124], [125, 128], [129, 135], [136, 142], [143, 149], [150, 153], [154, 158], [158, 159], [159, 161], [161, 162], [162, 168], [169, 176], [177, 179], [180, 187], [188, 196], [197, 211], [211, 212]]}
{"doc_key": "ai-dev-59", "ner": [[0, 12, "misc"], [14, 18, "metrics"], [32, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 12, 14, 18, "related-to", "", true, false], [14, 18, 32, 33, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "natural", "gradient", "of", "mathE", "f", "(", "x", ")", "/", "math", ",", "in", "accordance", "with", "the", "Fisher", "information", "metric", "(", "the", "measure", "of", "informational", "distance", "between", "probability", "distributions", "and", "the", "curvature", "of", "relative", "entropy", ")", ",", "is", "now"], "sentence-detokenized": "The natural gradient of mathE f (x) / math, in accordance with the Fisher information metric (the measure of informational distance between probability distributions and the curvature of relative entropy), is now", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 23], [24, 29], [30, 31], [32, 33], [33, 34], [34, 35], [36, 37], [38, 42], [42, 43], [44, 46], [47, 57], [58, 62], [63, 66], [67, 73], [74, 85], [86, 92], [93, 94], [94, 97], [98, 105], [106, 108], [109, 122], [123, 131], [132, 139], [140, 151], [152, 165], [166, 169], [170, 173], [174, 183], [184, 186], [187, 195], [196, 203], [203, 204], [204, 205], [206, 208], [209, 212]]}
{"doc_key": "ai-dev-60", "ner": [[0, 3, "programlang"], [6, 9, "product"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 9, 0, 3, "origin", "", false, false], [11, 11, 0, 3, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "S", "programming", "language", "inspired", "the", "S", "'", "-", "PLUS", "and", "R", "systems", "."], "sentence-detokenized": "The S programming language inspired the S'-PLUS and R systems.", "token2charspan": [[0, 3], [4, 5], [6, 17], [18, 26], [27, 35], [36, 39], [40, 41], [41, 42], [42, 43], [43, 47], [48, 51], [52, 53], [54, 61], [61, 62]]}
{"doc_key": "ai-dev-61", "ner": [[4, 6, "product"], [10, 10, "product"], [12, 14, "product"], [18, 20, "researcher"], [22, 23, "researcher"], [25, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 6, 10, 10, "named", "same", false, false], [12, 14, 10, 10, "origin", "derived_from", false, false], [12, 14, 18, 20, "origin", "", false, false], [12, 14, 22, 23, "origin", "", false, false], [12, 14, 25, 26, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "most", "effective", "implementation", "of", "Planner", "is", "a", "subset", "of", "Planner", "called", "Micro", "-", "Planner", ",", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "."], "sentence-detokenized": "The most effective implementation of Planner is a subset of Planner called Micro-Planner, implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd.", "token2charspan": [[0, 3], [4, 8], [9, 18], [19, 33], [34, 36], [37, 44], [45, 47], [48, 49], [50, 56], [57, 59], [60, 67], [68, 74], [75, 80], [80, 81], [81, 88], [88, 89], [90, 101], [102, 104], [105, 111], [112, 115], [116, 123], [123, 124], [125, 131], [132, 140], [141, 144], [145, 150], [151, 159], [159, 160]]}
{"doc_key": "ai-dev-62", "ner": [[4, 6, "country"], [8, 10, "researcher"], [21, 21, "misc"], [19, 27, "university"], [32, 35, "misc"], [34, 34, "misc"], [44, 46, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [[8, 10, 4, 6, "general-affiliation", "from_country", false, false], [19, 27, 21, 21, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "1779", ",", "the", "German", "-", "Danish", "scientist", "Christian", "Gottlieb", "Kratzenstein", "won", "the", "first", "prize", "in", "a", "competition", "announced", "by", "the", "Russian", "Imperial", "Academy", "of", "Sciences", "and", "Arts", "for", "his", "model", "of", "the", "human", "vocal", "tract", "from", "which", "five", "long", "vowels", "(", "in", "the", "International", "Phonetic", "Alphabet", "notation", ")", "could", "be", "produced", ":"], "sentence-detokenized": "In 1779, the German-Danish scientist Christian Gottlieb Kratzenstein won the first prize in a competition announced by the Russian Imperial Academy of Sciences and Arts for his model of the human vocal tract from which five long vowels (in the International Phonetic Alphabet notation) could be produced:", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 19], [19, 20], [20, 26], [27, 36], [37, 46], [47, 55], [56, 68], [69, 72], [73, 76], [77, 82], [83, 88], [89, 91], [92, 93], [94, 105], [106, 115], [116, 118], [119, 122], [123, 130], [131, 139], [140, 147], [148, 150], [151, 159], [160, 163], [164, 168], [169, 172], [173, 176], [177, 182], [183, 185], [186, 189], [190, 195], [196, 201], [202, 207], [208, 212], [213, 218], [219, 223], [224, 228], [229, 235], [236, 237], [237, 239], [240, 243], [244, 257], [258, 266], [267, 275], [276, 284], [284, 285], [286, 291], [292, 294], [295, 303], [303, 304]]}
{"doc_key": "ai-dev-63", "ner": [[3, 5, "product"], [6, 31, "misc"], [8, 14, "misc"], [32, 34, "misc"], [57, 59, "task"], [63, 64, "product"], [66, 66, "product"], [70, 71, "task"], [73, 74, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 5, 63, 64, "related-to", "supports_program", false, false], [3, 5, 66, 66, "related-to", "supports_program", false, false], [6, 31, 3, 5, "part-of", "", false, false], [8, 14, 3, 5, "part-of", "", false, false], [32, 34, 3, 5, "part-of", "", false, false], [57, 59, 3, 5, "part-of", "", false, false], [70, 71, 3, 5, "part-of", "", false, false], [73, 74, 3, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["New", "features", "in", "Office", "XP", "include", "smart", "tags", ",", "a", "selection", "-", "based", "search", "feature", "that", "recognises", "different", "types", "of", "text", "in", "a", "document", "so", "users", "can", "take", "additional", "actions", ";", "a", "task", "pane", "interface", "that", "consolidates", "popular", "menu", "bar", "commands", "to", "the", "right", "side", "of", "the", "screen", ",", "making", "them", "easier", "to", "access", "quickly", ";", "new", "document", "collaboration", "features", ",", "support", "for", "MSN", "Groups", "and", "SharePoint", ";", "and", "integrated", "handwriting", "recognition", "and", "speech", "recognition", "."], "sentence-detokenized": "New features in Office XP include smart tags, a selection-based search feature that recognises different types of text in a document so users can take additional actions; a task pane interface that consolidates popular menu bar commands to the right side of the screen, making them easier to access quickly; new document collaboration features, support for MSN Groups and SharePoint; and integrated handwriting recognition and speech recognition.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 22], [23, 25], [26, 33], [34, 39], [40, 44], [44, 45], [46, 47], [48, 57], [57, 58], [58, 63], [64, 70], [71, 78], [79, 83], [84, 94], [95, 104], [105, 110], [111, 113], [114, 118], [119, 121], [122, 123], [124, 132], [133, 135], [136, 141], [142, 145], [146, 150], [151, 161], [162, 169], [169, 170], [171, 172], [173, 177], [178, 182], [183, 192], [193, 197], [198, 210], [211, 218], [219, 223], [224, 227], [228, 236], [237, 239], [240, 243], [244, 249], [250, 254], [255, 257], [258, 261], [262, 268], [268, 269], [270, 276], [277, 281], [282, 288], [289, 291], [292, 298], [299, 306], [306, 307], [308, 311], [312, 320], [321, 334], [335, 343], [343, 344], [345, 352], [353, 356], [357, 360], [361, 367], [368, 371], [372, 382], [382, 383], [384, 387], [388, 398], [399, 410], [411, 422], [423, 426], [427, 433], [434, 445], [445, 446]]}
{"doc_key": "ai-dev-64", "ner": [[8, 11, "algorithm"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 11, 13, 14, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "many", "applications", "the", "units", "of", "these", "networks", "apply", "a", "sigmoid", "function", "as", "activation", "function", "."], "sentence-detokenized": "In many applications the units of these networks apply a sigmoid function as activation function.", "token2charspan": [[0, 2], [3, 7], [8, 20], [21, 24], [25, 30], [31, 33], [34, 39], [40, 48], [49, 54], [55, 56], [57, 64], [65, 73], [74, 76], [77, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-dev-65", "ner": [[0, 3, "researcher"], [8, 14, "organisation"], [19, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 8, 14, "role", "", false, false], [0, 3, 19, 28, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Mehler", "was", "elected", "an", "honorary", "foreign", "member", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "in", "2001", "and", "a", "fellow", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "in", "2003", "."], "sentence-detokenized": "Mehler was elected an honorary foreign member of the American Academy of Arts and Sciences in 2001 and a fellow of the American Association for the Advancement of Science in 2003.", "token2charspan": [[0, 6], [7, 10], [11, 18], [19, 21], [22, 30], [31, 38], [39, 45], [46, 48], [49, 52], [53, 61], [62, 69], [70, 72], [73, 77], [78, 81], [82, 90], [91, 93], [94, 98], [99, 102], [103, 104], [105, 111], [112, 114], [115, 118], [119, 127], [128, 139], [140, 143], [144, 147], [148, 159], [160, 162], [163, 170], [171, 173], [174, 178], [178, 179]]}
{"doc_key": "ai-dev-66", "ner": [[3, 6, "task"], [8, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 6, 8, 10, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Extending", "this", "concept", "to", "non", "-binary", "classifications", "yields", "the", "confusion", "matrix", "."], "sentence-detokenized": "Extending this concept to non-binary classifications yields the confusion matrix.", "token2charspan": [[0, 9], [10, 14], [15, 22], [23, 25], [26, 29], [29, 36], [37, 52], [53, 59], [60, 63], [64, 73], [74, 80], [80, 81]]}
{"doc_key": "ai-dev-67", "ner": [[11, 12, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "updated", "measurement", "noise", "variance", "estimate", "can", "be", "obtained", "from", "the", "maximum", "likelihood", "calculation"], "sentence-detokenized": "An updated measurement noise variance estimate can be obtained from the maximum likelihood calculation", "token2charspan": [[0, 2], [3, 10], [11, 22], [23, 28], [29, 37], [38, 46], [47, 50], [51, 53], [54, 62], [63, 67], [68, 71], [72, 79], [80, 90], [91, 102]]}
{"doc_key": "ai-dev-68", "ner": [[1, 1, "field"], [5, 6, "algorithm"], [10, 11, "field"], [12, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 10, 11, "usage", "", true, false], [5, 6, 12, 14, "related-to", "", true, false], [10, 11, 1, 1, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "machine", "learning", ",", "the", "perceptron", "is", "an", "algorithm", "for", "supervised", "learning", "of", "binary", "classification", "."], "sentence-detokenized": "In machine learning, the perceptron is an algorithm for supervised learning of binary classification.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 24], [25, 35], [36, 38], [39, 41], [42, 51], [52, 55], [56, 66], [67, 75], [76, 78], [79, 85], [86, 100], [100, 101]]}
{"doc_key": "ai-dev-69", "ner": [[9, 11, "field"], [12, 13, "field"], [16, 24, "conference"], [25, 29, "conference"], [32, 38, "conference"], [41, 45, "conference"], [49, 53, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[16, 24, 9, 11, "topic", "", false, false], [16, 24, 12, 13, "topic", "", false, false], [25, 29, 9, 11, "topic", "", false, false], [25, 29, 12, 13, "topic", "", false, false], [32, 38, 9, 11, "topic", "", false, false], [32, 38, 12, 13, "topic", "", false, false], [41, 45, 9, 11, "topic", "", false, false], [41, 45, 12, 13, "topic", "", false, false], [49, 53, 9, 11, "topic", "", false, false], [49, 53, 12, 13, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["He", "has", "also", "served", "as", "Area", "Chair", "for", "several", "machine", "learning", "and", "vision", "conferences", ",", "including", "the", "Conference", "on", "Neural", "Information", "Processing", "Systems", ",", "the", "International", "Conference", "on", "Learning", "Representations", ",", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "the", "International", "Conference", "on", "Computer", "Vision", ",", "and", "the", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "He has also served as Area Chair for several machine learning and vision conferences, including the Conference on Neural Information Processing Systems, the International Conference on Learning Representations, the Conference on Computer Vision and Pattern Recognition, the International Conference on Computer Vision, and the European Conference on Computer Vision.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 21], [22, 26], [27, 32], [33, 36], [37, 44], [45, 52], [53, 61], [62, 65], [66, 72], [73, 84], [84, 85], [86, 95], [96, 99], [100, 110], [111, 113], [114, 120], [121, 132], [133, 143], [144, 151], [151, 152], [153, 156], [157, 170], [171, 181], [182, 184], [185, 193], [194, 209], [209, 210], [211, 214], [215, 225], [226, 228], [229, 237], [238, 244], [245, 248], [249, 256], [257, 268], [268, 269], [270, 273], [274, 287], [288, 298], [299, 301], [302, 310], [311, 317], [317, 318], [319, 322], [323, 326], [327, 335], [336, 346], [347, 349], [350, 358], [359, 365], [365, 366]]}
{"doc_key": "ai-dev-70", "ner": [[0, 3, "algorithm"], [8, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "intensification", "algorithm", "has", "also", "been", "used", "for", "face", "recognition", "in", "a", "video", "sequence", "."], "sentence-detokenized": "The intensification algorithm has also been used for face recognition in a video sequence.", "token2charspan": [[0, 3], [4, 19], [20, 29], [30, 33], [34, 38], [39, 43], [44, 48], [49, 52], [53, 57], [58, 69], [70, 72], [73, 74], [75, 80], [81, 89], [89, 90]]}
{"doc_key": "ai-dev-71", "ner": [[0, 2, "task"], [6, 6, "organisation"], [19, 19, "conference"], [24, 29, "academicjournal"], [32, 32, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 19, 0, 2, "topic", "", false, false], [19, 19, 6, 6, "origin", "", false, false], [24, 29, 0, 2, "topic", "", false, false], [24, 29, 6, 6, "origin", "", true, false], [32, 32, 24, 29, "role", "edited_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Knowledge", "Dissemination", "is", "also", "part", "of", "ELRA", "'s", "missions", "and", "is", "carried", "out", "both", "through", "the", "organisation", "of", "the", "LREC", "conference", "and", "through", "the", "Journal", "of", "Language", "Resources", "and", "Evaluation", "edited", "by", "Springer", "."], "sentence-detokenized": "Knowledge Dissemination is also part of ELRA's missions and is carried out both through the organisation of the LREC conference and through the Journal of Language Resources and Evaluation edited by Springer.", "token2charspan": [[0, 9], [10, 23], [24, 26], [27, 31], [32, 36], [37, 39], [40, 44], [44, 46], [47, 55], [56, 59], [60, 62], [63, 70], [71, 74], [75, 79], [80, 87], [88, 91], [92, 104], [105, 107], [108, 111], [112, 116], [117, 127], [128, 131], [132, 139], [140, 143], [144, 151], [152, 154], [155, 163], [164, 173], [174, 177], [178, 188], [189, 195], [196, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-dev-72", "ner": [[0, 9, "field"], [11, 12, "field"], [15, 17, "field"], [19, 22, "field"], [54, 57, "field"], [62, 62, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 9, 54, 57, "named", "", false, false], [15, 17, 0, 9, "named", "", false, false], [62, 62, 11, 12, "part-of", "", true, false], [62, 62, 15, 17, "part-of", "", true, false], [62, 62, 54, 57, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "linear", "time", "-", "invariant", "(", "LTI", ")", "system", "theory", ",", "control", "theory", ",", "and", "digital", "signal", "processing", "or", "signal", "processing", ",", "the", "relationship", "between", "the", "input", "signal", ",", "math", "\\", "displaystyle", "x", "(", "t", ")", "/", "math", ",", "and", "the", "output", "signal", ",", "math", "\\", "displaystyle", "y", "(", "t", ")", "/", "math", ",", "of", "an", "LTI", "system", "is", "governed", "by", "a", "convolution", "operation", ":"], "sentence-detokenized": "In linear time-invariant (LTI) system theory, control theory, and digital signal processing or signal processing, the relationship between the input signal, math\\ displaystyle x(t) / math, and the output signal, math\\ displaystyle y(t) / math, of an LTI system is governed by a convolution operation:", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [15, 24], [25, 26], [26, 29], [29, 30], [31, 37], [38, 44], [44, 45], [46, 53], [54, 60], [60, 61], [62, 65], [66, 73], [74, 80], [81, 91], [92, 94], [95, 101], [102, 112], [112, 113], [114, 117], [118, 130], [131, 138], [139, 142], [143, 148], [149, 155], [155, 156], [157, 161], [161, 162], [163, 175], [176, 177], [177, 178], [178, 179], [179, 180], [181, 182], [183, 187], [187, 188], [189, 192], [193, 196], [197, 203], [204, 210], [210, 211], [212, 216], [216, 217], [218, 230], [231, 232], [232, 233], [233, 234], [234, 235], [236, 237], [238, 242], [242, 243], [244, 246], [247, 249], [250, 253], [254, 260], [261, 263], [264, 272], [273, 275], [276, 277], [278, 289], [290, 299], [299, 300]]}
{"doc_key": "ai-dev-73", "ner": [[15, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 25, "field"], [27, 30, "field"], [32, 33, "product"], [35, 36, "field"], [38, 38, "field"], [40, 41, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Due", "to", "its", "generality", ",", "this", "area", "is", "studied", "in", "many", "other", "disciplines", "such", "as", "game", "theory", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimisation", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Due to its generality, this area is studied in many other disciplines such as game theory, control theory, operations research, information theory, simulation-based optimisation, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 21], [21, 22], [23, 27], [28, 32], [33, 35], [36, 43], [44, 46], [47, 51], [52, 57], [58, 69], [70, 74], [75, 77], [78, 82], [83, 89], [89, 90], [91, 98], [99, 105], [105, 106], [107, 117], [118, 126], [126, 127], [128, 139], [140, 146], [146, 147], [148, 158], [158, 159], [159, 164], [165, 177], [177, 178], [179, 190], [191, 198], [198, 199], [200, 205], [206, 218], [218, 219], [220, 230], [231, 234], [235, 242], [243, 253], [253, 254]]}
{"doc_key": "ai-dev-74", "ner": [[0, 2, "algorithm"], [14, 16, "field"], [22, 23, "algorithm"], [26, 27, "algorithm"], [33, 34, "algorithm"], [37, 38, "algorithm"], [38, 40, "researcher"], [42, 43, "researcher"], [45, 47, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[14, 16, 0, 2, "usage", "", true, false], [22, 23, 14, 16, "part-of", "", true, false], [26, 27, 14, 16, "part-of", "", true, false], [33, 34, 14, 16, "part-of", "", true, false], [37, 38, 14, 16, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Stochastic", "gradient", "descent", "is", "a", "popular", "algorithm", "for", "training", "a", "wide", "variety", "of", "models", "in", "machine", "learning", ",", "including", "(", "linear", ")", "support", "vector", "machines", ",", "logistic", "regression", "(", "see", ",", "e.g.", ",", "Vowpal", "Wabbit", ")", "and", "graphical", "models.Jenny", "Rose", "Finkel", ",", "Alex", "Kleeman", ",", "Christopher", "D.", "Manning", "(", "2008", ")", "."], "sentence-detokenized": "Stochastic gradient descent is a popular algorithm for training a wide variety of models in machine learning, including (linear) support vector machines, logistic regression (see, e.g., Vowpal Wabbit) and graphical models.Jenny Rose Finkel, Alex Kleeman, Christopher D. Manning (2008).", "token2charspan": [[0, 10], [11, 19], [20, 27], [28, 30], [31, 32], [33, 40], [41, 50], [51, 54], [55, 63], [64, 65], [66, 70], [71, 78], [79, 81], [82, 88], [89, 91], [92, 99], [100, 108], [108, 109], [110, 119], [120, 121], [121, 127], [127, 128], [129, 136], [137, 143], [144, 152], [152, 153], [154, 162], [163, 173], [174, 175], [175, 178], [178, 179], [180, 184], [184, 185], [186, 192], [193, 199], [199, 200], [201, 204], [205, 214], [215, 227], [228, 232], [233, 239], [239, 240], [241, 245], [246, 253], [253, 254], [255, 266], [267, 269], [270, 277], [278, 279], [279, 283], [283, 284], [284, 285]]}
{"doc_key": "ai-dev-75", "ner": [[8, 8, "organisation"], [12, 13, "product"], [20, 23, "university"], [25, 25, "location"], [27, 29, "university"], [30, 31, "location"], [33, 34, "university"], [36, 36, "location"], [38, 40, "university"], [42, 42, "location"], [44, 45, "university"], [47, 47, "location"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 20, 23, "role", "donates_to", false, false], [8, 8, 27, 29, "role", "donates_to", false, false], [8, 8, 33, 34, "role", "donates_to", false, false], [8, 8, 38, 40, "role", "donates_to", false, false], [8, 8, 44, 45, "role", "donates_to", false, false], [12, 13, 8, 8, "origin", "donates", true, false], [20, 23, 25, 25, "physical", "", false, false], [27, 29, 30, 31, "physical", "", false, false], [33, 34, 36, 36, "physical", "", false, false], [38, 40, 42, 42, "physical", "", false, false], [44, 45, 47, 47, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 8, 10, 12, 14], "sentence": ["In", "August", "2011", ",", "it", "was", "announced", "that", "Hitachi", "would", "donate", "one", "electron", "microscope", "each", "to", "five", "Indonesian", "universities", "(", "University", "of", "North", "Sumatra", "in", "Medan", ",", "Indonesia", "Christian", "University", "in", "Jakarta", ",", "Padjadjaran", "University", "in", "Bandung", ",", "Jenderal", "Soedirman", "University", "in", "Purwokerto", "and", "Muhammadiyah", "University", "in", "Malang", ")", "."], "sentence-detokenized": "In August 2011, it was announced that Hitachi would donate one electron microscope each to five Indonesian universities (University of North Sumatra in Medan, Indonesia Christian University in Jakarta, Padjadjaran University in Bandung, Jenderal Soedirman University in Purwokerto and Muhammadiyah University in Malang).", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 18], [19, 22], [23, 32], [33, 37], [38, 45], [46, 51], [52, 58], [59, 62], [63, 71], [72, 82], [83, 87], [88, 90], [91, 95], [96, 106], [107, 119], [120, 121], [121, 131], [132, 134], [135, 140], [141, 148], [149, 151], [152, 157], [157, 158], [159, 168], [169, 178], [179, 189], [190, 192], [193, 200], [200, 201], [202, 213], [214, 224], [225, 227], [228, 235], [235, 236], [237, 245], [246, 255], [256, 266], [267, 269], [270, 280], [281, 284], [285, 297], [298, 308], [309, 311], [312, 318], [318, 319], [319, 320]]}
{"doc_key": "ai-dev-76", "ner": [[2, 2, "field"], [0, 1, "field"], [6, 7, "algorithm"], [9, 11, "algorithm"], [18, 19, "field"], [23, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 0, 1, "part-of", "", false, false], [2, 2, 18, 19, "related-to", "", true, false], [2, 2, 23, 25, "related-to", "", true, false], [6, 7, 2, 2, "type-of", "", false, false], [9, 11, 2, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Operations", "research", "optimisation", "techniques", "such", "as", "linear", "programming", "or", "dynamic", "programming", "are", "often", "impractical", "for", "large", "-", "scale", "software", "engineering", "problems", "due", "to", "their", "computational", "complexity", "."], "sentence-detokenized": "Operations research optimisation techniques such as linear programming or dynamic programming are often impractical for large-scale software engineering problems due to their computational complexity.", "token2charspan": [[0, 10], [11, 19], [20, 32], [33, 43], [44, 48], [49, 51], [52, 58], [59, 70], [71, 73], [74, 81], [82, 93], [94, 97], [98, 103], [104, 115], [116, 119], [120, 125], [125, 126], [126, 131], [132, 140], [141, 152], [153, 161], [162, 165], [166, 168], [169, 174], [175, 188], [189, 199], [199, 200]]}
{"doc_key": "ai-dev-77", "ner": [[0, 1, "metrics"], [6, 6, "metrics"], [8, 10, "metrics"], [15, 17, "metrics"], [12, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 6, 6, "compare", "", false, false], [0, 1, 8, 10, "compare", "", false, false], [15, 17, 8, 10, "part-of", "", false, false], [12, 22, 8, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Precision", "is", "not", "the", "same", "as", "certainty", "or", "positive", "predictive", "value", "(", "the", "ratio", "of", "TRUE", "positives", "to", "combined", "TRUE", "and", "FALSE", "positives", ")", ",", "which", "is", "a", "statement", "about", "the", "test", "as", "well", "as", "about", "the", "proportion", "of", "true", "positives", "in", "the", "population", "being", "tested", "."], "sentence-detokenized": "Precision is not the same as certainty or positive predictive value (the ratio of TRUE positives to combined TRUE and FALSE positives), which is a statement about the test as well as about the proportion of true positives in the population being tested.", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 20], [21, 25], [26, 28], [29, 38], [39, 41], [42, 50], [51, 61], [62, 67], [68, 69], [69, 72], [73, 78], [79, 81], [82, 86], [87, 96], [97, 99], [100, 108], [109, 113], [114, 117], [118, 123], [124, 133], [133, 134], [134, 135], [136, 141], [142, 144], [145, 146], [147, 156], [157, 162], [163, 166], [167, 171], [172, 174], [175, 179], [180, 182], [183, 188], [189, 192], [193, 203], [204, 206], [207, 211], [212, 221], [222, 224], [225, 228], [229, 239], [240, 245], [246, 252], [252, 253]]}
{"doc_key": "ai-dev-78", "ner": [[5, 6, "person"], [12, 12, "product"], [31, 31, "person"], [38, 39, "person"], [43, 43, "person"], [49, 50, "person"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6], "relations": [[5, 6, 43, 43, "named", "same", false, false], [12, 12, 5, 6, "artifact", "", false, false], [38, 39, 49, 50, "role", "convinces", false, false], [49, 50, 12, 12, "role", "producer", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "screenplay", "was", "written", "by", "Hampton", "Fancher", "!", "--", "not", "originally", "called", "Android", "--", "see", "Sammon", ",", "pp.", "32", "and", "38", "for", "an", "explanation", "--", "was", "picked", "up", "in", "1977", ".", "Sammon", ",", "pp.", "23", "-", "30", "Producer", "Michael", "Deeley", "became", "interested", "in", "Fancher", "'s", "draft", "and", "convinced", "director", "Ridley", "Scott", "to", "make", "the", "film", "."], "sentence-detokenized": "The screenplay was written by Hampton Fancher! -- not originally called Android -- see Sammon, pp. 32 and 38 for an explanation -- was picked up in 1977. Sammon, pp. 23-30 Producer Michael Deeley became interested in Fancher's draft and convinced director Ridley Scott to make the film.", "token2charspan": [[0, 3], [4, 14], [15, 18], [19, 26], [27, 29], [30, 37], [38, 45], [45, 46], [47, 49], [50, 53], [54, 64], [65, 71], [72, 79], [80, 82], [83, 86], [87, 93], [93, 94], [95, 98], [99, 101], [102, 105], [106, 108], [109, 112], [113, 115], [116, 127], [128, 130], [131, 134], [135, 141], [142, 144], [145, 147], [148, 152], [152, 153], [154, 160], [160, 161], [162, 165], [166, 168], [168, 169], [169, 171], [172, 180], [181, 188], [189, 195], [196, 202], [203, 213], [214, 216], [217, 224], [224, 226], [227, 232], [233, 236], [237, 246], [247, 255], [256, 262], [263, 268], [269, 271], [272, 276], [277, 280], [281, 285], [285, 286]]}
{"doc_key": "ai-dev-79", "ner": [[0, 1, "field"], [7, 8, "task"], [10, 11, "task"], [14, 16, "misc"], [18, 19, "field"], [21, 23, "task"], [25, 26, "task"], [3, 4, "field"], [28, 31, "task"], [33, 34, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[7, 8, 0, 1, "part-of", "", false, false], [10, 11, 0, 1, "part-of", "", false, false], [14, 16, 0, 1, "part-of", "", false, false], [18, 19, 0, 1, "part-of", "", false, false], [21, 23, 0, 1, "part-of", "", false, false], [25, 26, 0, 1, "part-of", "", false, false], [3, 4, 0, 1, "part-of", "", false, false], [28, 31, 0, 1, "part-of", "", false, false], [33, 34, 0, 1, "part-of", "", false, false], [35, 36, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Text", "analysis", "includes", "data", "mining", "techniques", "including", "information", "retrieval", ",", "lexical", "analysis", "to", "examine", "word", "frequency", "distributions", ",", "pattern", "recognition", ",", "tagging", "/", "annotation", ",", "information", "extraction", ",", "link", "and", "association", "analysis", ",", "visualisation", "and", "predictive", "analytics", "."], "sentence-detokenized": "Text analysis includes data mining techniques including information retrieval, lexical analysis to examine word frequency distributions, pattern recognition, tagging/annotation, information extraction, link and association analysis, visualisation and predictive analytics.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 27], [28, 34], [35, 45], [46, 55], [56, 67], [68, 77], [77, 78], [79, 86], [87, 95], [96, 98], [99, 106], [107, 111], [112, 121], [122, 135], [135, 136], [137, 144], [145, 156], [156, 157], [158, 165], [165, 166], [166, 176], [176, 177], [178, 189], [190, 200], [200, 201], [202, 206], [207, 210], [211, 222], [223, 231], [231, 232], [233, 246], [247, 250], [251, 261], [262, 271], [271, 272]]}
{"doc_key": "ai-dev-80", "ner": [[3, 3, "product"], [10, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 12, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Several", "measures", "use", "WordNet", ",", "a", "manually", "created", "lexical", "database", "of", "English", "words", "."], "sentence-detokenized": "Several measures use WordNet, a manually created lexical database of English words.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 28], [28, 29], [30, 31], [32, 40], [41, 48], [49, 56], [57, 65], [66, 68], [69, 76], [77, 82], [82, 83]]}
{"doc_key": "ai-dev-81", "ner": [[6, 7, "field"], [9, 12, "task"], [13, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "system", "uses", "a", "combination", "of", "computational", "linguistics", ",", "knowledge", "retrieval", "and", "knowledge", "representation", "techniques", "to", "find", "answers", "."], "sentence-detokenized": "The system uses a combination of computational linguistics, knowledge retrieval and knowledge representation techniques to find answers.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 17], [18, 29], [30, 32], [33, 46], [47, 58], [58, 59], [60, 69], [70, 79], [80, 83], [84, 93], [94, 108], [109, 119], [120, 122], [123, 127], [128, 135], [135, 136]]}
{"doc_key": "ai-dev-82", "ner": [[5, 7, "metrics"], [13, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 13, 13, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "performance", "measure", ",", "the", "uncertainty", "coefficient", "has", "the", "advantage", "over", "simple", "accuracy", "that", "it", "is", "not", "affected", "by", "the", "relative", "size", "of", "different", "classes", "."], "sentence-detokenized": "As a performance measure, the uncertainty coefficient has the advantage over simple accuracy that it is not affected by the relative size of different classes.", "token2charspan": [[0, 2], [3, 4], [5, 16], [17, 24], [24, 25], [26, 29], [30, 41], [42, 53], [54, 57], [58, 61], [62, 71], [72, 76], [77, 83], [84, 92], [93, 97], [98, 100], [101, 103], [104, 107], [108, 116], [117, 119], [120, 123], [124, 132], [133, 137], [138, 140], [141, 150], [151, 158], [158, 159]]}
{"doc_key": "ai-dev-83", "ner": [[9, 10, "algorithm"], [12, 13, "algorithm"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Researchers", "have", "tried", "a", "number", "of", "methods", "such", "as", "optical", "flow", ",", "Kalman", "filtering", ",", "Hidden", "Markov", "models", ",", "etc", "."], "sentence-detokenized": "Researchers have tried a number of methods such as optical flow, Kalman filtering, Hidden Markov models, etc.", "token2charspan": [[0, 11], [12, 16], [17, 22], [23, 24], [25, 31], [32, 34], [35, 42], [43, 47], [48, 50], [51, 58], [59, 63], [63, 64], [65, 71], [72, 81], [81, 82], [83, 89], [90, 96], [97, 103], [103, 104], [105, 108], [108, 109]]}
{"doc_key": "ai-dev-84", "ner": [[13, 18, "conference"], [29, 32, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "served", "as", "President", ",", "Vice", "President", ",", "and", "Secretary", "-", "Treasurer", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "and", "as", "a", "board", "member", "and", "board", "secretary", "of", "the", "Computing", "Research", "Association", "."], "sentence-detokenized": "He has served as President, Vice President, and Secretary-Treasurer of the Association for Computational Linguistics, and as a board member and board secretary of the Computing Research Association.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 26], [26, 27], [28, 32], [33, 42], [42, 43], [44, 47], [48, 57], [57, 58], [58, 67], [68, 70], [71, 74], [75, 86], [87, 90], [91, 104], [105, 116], [116, 117], [118, 121], [122, 124], [125, 126], [127, 132], [133, 139], [140, 143], [144, 149], [150, 159], [160, 162], [163, 166], [167, 176], [177, 185], [186, 197], [197, 198]]}
{"doc_key": "ai-dev-85", "ner": [[7, 7, "programlang"], [9, 9, "product"], [11, 11, "programlang"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 11, 11, "compare", "", false, false], [7, 7, 13, 14, "related-to", "supports", false, false], [9, 9, 11, 11, "compare", "", false, false], [9, 9, 13, 14, "related-to", "supports", false, false], [11, 11, 13, 14, "related-to", "supports", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["As", "with", "other", "similar", "languages", "such", "as", "APL", "and", "MATLAB", ",", "R", "supports", "matrix", "arithmetic", "."], "sentence-detokenized": "As with other similar languages such as APL and MATLAB, R supports matrix arithmetic.", "token2charspan": [[0, 2], [3, 7], [8, 13], [14, 21], [22, 31], [32, 36], [37, 39], [40, 43], [44, 47], [48, 54], [54, 55], [56, 57], [58, 66], [67, 73], [74, 84], [84, 85]]}
{"doc_key": "ai-dev-86", "ner": [[23, 23, "misc"], [27, 30, "organisation"], [15, 16, "researcher"], [18, 19, "university"], [7, 13, "misc"], [31, 31, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[23, 23, 27, 30, "physical", "", false, false], [23, 23, 7, 13, "temporal", "", false, false], [15, 16, 23, 23, "role", "arranges", false, false], [15, 16, 18, 19, "role", "works_for", false, false], [31, 31, 23, 23, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["On", "7", "June", "2014", ",", "to", "mark", "the", "60th", "anniversary", "of", "Turing", "'s", "death", ",", "Kevin", "Warwick", "of", "Reading", "University", "organised", "a", "Turing", "test", "competition", "at", "the", "Royal", "Society", ",", "which", "Goostman", "won", "after", "33", "%", "of", "the", "judges", "were", "convinced", "that", "the", "robot", "was", "human", "."], "sentence-detokenized": "On 7 June 2014, to mark the 60th anniversary of Turing's death, Kevin Warwick of Reading University organised a Turing test competition at the Royal Society, which Goostman won after 33% of the judges were convinced that the robot was human.", "token2charspan": [[0, 2], [3, 4], [5, 9], [10, 14], [14, 15], [16, 18], [19, 23], [24, 27], [28, 32], [33, 44], [45, 47], [48, 54], [54, 56], [57, 62], [62, 63], [64, 69], [70, 77], [78, 80], [81, 88], [89, 99], [100, 109], [110, 111], [112, 118], [119, 123], [124, 135], [136, 138], [139, 142], [143, 148], [149, 156], [156, 157], [158, 163], [164, 172], [173, 176], [177, 182], [183, 185], [185, 186], [187, 189], [190, 193], [194, 200], [201, 205], [206, 215], [216, 220], [221, 224], [225, 230], [231, 234], [235, 240], [240, 241]]}
{"doc_key": "ai-dev-87", "ner": [[0, 2, "product"], [5, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "collaborative", "robot", ",", "or", "cobot", ",", "is", "a", "robot", "that", "can", "safely", "and", "effectively", "interact", "with", "human", "workers", "while", "performing", "simple", "industrial", "tasks", "."], "sentence-detokenized": "A collaborative robot, or cobot, is a robot that can safely and effectively interact with human workers while performing simple industrial tasks.", "token2charspan": [[0, 1], [2, 15], [16, 21], [21, 22], [23, 25], [26, 31], [31, 32], [33, 35], [36, 37], [38, 43], [44, 48], [49, 52], [53, 59], [60, 63], [64, 75], [76, 84], [85, 89], [90, 95], [96, 103], [104, 109], [110, 120], [121, 127], [128, 138], [139, 144], [144, 145]]}
{"doc_key": "ai-dev-88", "ner": [[12, 14, "field"], [17, 18, "task"], [20, 21, "task"], [23, 26, "task"], [27, 27, "task"], [29, 30, "task"], [32, 35, "task"], [37, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[17, 18, 12, 14, "part-of", "task_part_of_field", false, false], [20, 21, 12, 14, "part-of", "task_part_of_field", false, false], [23, 26, 12, 14, "part-of", "task_part_of_field", false, false], [27, 27, 12, 14, "part-of", "task_part_of_field", false, false], [29, 30, 12, 14, "part-of", "task_part_of_field", false, false], [32, 35, 12, 14, "part-of", "task_part_of_field", false, false], [37, 38, 12, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["This", "general", "framework", "has", "been", "applied", "to", "a", "wide", "variety", "of", "problems", "in", "computer", "vision", ",", "including", "feature", "detection", ",", "feature", "classification", ",", "image", "segmentation", ",", "image", "matching", ",", "motion", "estimation", ",", "computation", "of", "shape", "cues", "and", "object", "recognition", "."], "sentence-detokenized": "This general framework has been applied to a wide variety of problems in computer vision, including feature detection, feature classification, image segmentation, image matching, motion estimation, computation of shape cues and object recognition.", "token2charspan": [[0, 4], [5, 12], [13, 22], [23, 26], [27, 31], [32, 39], [40, 42], [43, 44], [45, 49], [50, 57], [58, 60], [61, 69], [70, 72], [73, 81], [82, 88], [88, 89], [90, 99], [100, 107], [108, 117], [117, 118], [119, 126], [127, 141], [141, 142], [143, 148], [149, 161], [161, 162], [163, 168], [169, 177], [177, 178], [179, 185], [186, 196], [196, 197], [198, 209], [210, 212], [213, 218], [219, 223], [224, 227], [228, 234], [235, 246], [246, 247]]}
{"doc_key": "ai-dev-89", "ner": [[5, 6, "task"], [8, 10, "algorithm"], [12, 15, "algorithm"], [26, 36, "algorithm"], [32, 32, "algorithm"], [37, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 6, 8, 10, "part-of", "", false, false], [5, 6, 12, 15, "usage", "", false, false], [8, 10, 26, 36, "named", "same", false, false], [26, 36, 32, 32, "related-to", "", false, false], [26, 36, 37, 37, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "many", "practical", "applications", ",", "parameter", "estimation", "for", "naive", "Bayesian", "models", "uses", "the", "maximum", "likelihood", "method", ";", "in", "other", "words", ",", "one", "can", "work", "with", "a", "naive", "Bayesian", "model", "without", "accepting", "Bayesian", "probability", "or", "using", "any", "Bayesian", "method", "."], "sentence-detokenized": "In many practical applications, parameter estimation for naive Bayesian models uses the maximum likelihood method; in other words, one can work with a naive Bayesian model without accepting Bayesian probability or using any Bayesian method.", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 30], [30, 31], [32, 41], [42, 52], [53, 56], [57, 62], [63, 71], [72, 78], [79, 83], [84, 87], [88, 95], [96, 106], [107, 113], [113, 114], [115, 117], [118, 123], [124, 129], [129, 130], [131, 134], [135, 138], [139, 143], [144, 148], [149, 150], [151, 156], [157, 165], [166, 171], [172, 179], [180, 189], [190, 198], [199, 210], [211, 213], [214, 219], [220, 223], [224, 232], [233, 239], [239, 240]]}
{"doc_key": "ai-dev-90", "ner": [[2, 4, "researcher"], [6, 7, "misc"], [10, 15, "university"], [17, 19, "researcher"], [21, 22, "misc"], [26, 26, "university"], [28, 28, "university"], [31, 31, "misc"], [37, 40, "university"], [46, 49, "misc"], [51, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[2, 4, 10, 15, "physical", "", false, false], [2, 4, 10, 15, "role", "", false, false], [2, 4, 17, 19, "social", "brothers", false, false], [6, 7, 2, 4, "named", "", false, false], [17, 19, 26, 26, "physical", "", false, false], [17, 19, 26, 26, "role", "", false, false], [17, 19, 28, 28, "physical", "", false, false], [17, 19, 28, 28, "role", "", false, false], [17, 19, 37, 40, "physical", "", false, false], [17, 19, 37, 40, "role", "", false, false], [21, 22, 17, 19, "named", "", false, false], [31, 31, 17, 19, "origin", "", false, false], [46, 49, 17, 19, "artifact", "", false, false], [46, 49, 51, 54, "part-of", "part", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Brothers", "-", "Victor", "Gershevich", "Katz", ",", "American", "mathematician", ",", "professor", "at", "the", "Massachusetts", "Institute", "of", "Technology", ";", "Mikhail", "Gershevich", "Katz", ",", "Israeli", "mathematician", ",", "graduate", "of", "Harvard", "and", "Columbia", "universities", "(", "PhD", ",", "1984", ")", ",", "professor", "at", "Bar-", "Ilan", "University", ",", "author", "of", "the", "monograph", "Systolic", "Geometry", "and", "Topology", "(", "Mathematical", "Surveys", "and", "Monographs", ",", "vol", "."], "sentence-detokenized": "Brothers - Victor Gershevich Katz, American mathematician, professor at the Massachusetts Institute of Technology; Mikhail Gershevich Katz, Israeli mathematician, graduate of Harvard and Columbia universities (PhD, 1984), professor at Bar-Ilan University, author of the monograph Systolic Geometry and Topology (Mathematical Surveys and Monographs, vol.", "token2charspan": [[0, 8], [9, 10], [11, 17], [18, 28], [29, 33], [33, 34], [35, 43], [44, 57], [57, 58], [59, 68], [69, 71], [72, 75], [76, 89], [90, 99], [100, 102], [103, 113], [113, 114], [115, 122], [123, 133], [134, 138], [138, 139], [140, 147], [148, 161], [161, 162], [163, 171], [172, 174], [175, 182], [183, 186], [187, 195], [196, 208], [209, 210], [210, 213], [213, 214], [215, 219], [219, 220], [220, 221], [222, 231], [232, 234], [235, 239], [239, 243], [244, 254], [254, 255], [256, 262], [263, 265], [266, 269], [270, 279], [280, 288], [289, 297], [298, 301], [302, 310], [311, 312], [312, 324], [325, 332], [333, 336], [337, 347], [347, 348], [349, 352], [352, 353]]}
{"doc_key": "ai-dev-91", "ner": [[3, 4, "person"], [8, 11, "conference"], [15, 19, "organisation"], [20, 27, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 8, 11, "physical", "", false, false], [3, 4, 8, 11, "role", "", false, false], [3, 4, 15, 19, "role", "", false, false], [15, 19, 20, 27, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2000", ",", "Manuel", "Toharia", ",", "a", "speaker", "at", "previous", "Campus", "Parties", "and", "director", "of", "the", "Pr\u00edncipe", "Felipe", "Science", "Museum", "in", "Valencia", "'s", "City", "of", "Arts", "and", "Sciences", ",", "suggested", "that", "Ragageles", "expand", "and", "make", "the", "event", "more", "international", "by", "moving", "it", "to", "the", "famous", "museum", "."], "sentence-detokenized": "In 2000, Manuel Toharia, a speaker at previous Campus Parties and director of the Pr\u00edncipe Felipe Science Museum in Valencia's City of Arts and Sciences, suggested that Ragageles expand and make the event more international by moving it to the famous museum.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 23], [23, 24], [25, 26], [27, 34], [35, 37], [38, 46], [47, 53], [54, 61], [62, 65], [66, 74], [75, 77], [78, 81], [82, 90], [91, 97], [98, 105], [106, 112], [113, 115], [116, 124], [124, 126], [127, 131], [132, 134], [135, 139], [140, 143], [144, 152], [152, 153], [154, 163], [164, 168], [169, 178], [179, 185], [186, 189], [190, 194], [195, 198], [199, 204], [205, 209], [210, 223], [224, 226], [227, 233], [234, 236], [237, 239], [240, 243], [244, 250], [251, 257], [257, 258]]}
{"doc_key": "ai-dev-92", "ner": [[4, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Within", "20", "minutes", ",", "the", "facial", "recognition", "system", "identifies", "personal", "information", "such", "as", "family", "name", ",", "ID", "number", "and", "address", ",", "which", "is", "displayed", "on", "an", "advertising", "screen", "on", "the", "street", "."], "sentence-detokenized": "Within 20 minutes, the facial recognition system identifies personal information such as family name, ID number and address, which is displayed on an advertising screen on the street.", "token2charspan": [[0, 6], [7, 9], [10, 17], [17, 18], [19, 22], [23, 29], [30, 41], [42, 48], [49, 59], [60, 68], [69, 80], [81, 85], [86, 88], [89, 95], [96, 100], [100, 101], [102, 104], [105, 111], [112, 115], [116, 123], [123, 124], [125, 130], [131, 133], [134, 143], [144, 146], [147, 149], [150, 161], [162, 168], [169, 171], [172, 175], [176, 182], [182, 183]]}
{"doc_key": "ai-dev-93", "ner": [[6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Recent", "research", "has", "increasingly", "focussed", "on", "unsupervised", "learning", "and", "semi-supervised", "learning", "algorithms", "."], "sentence-detokenized": "Recent research has increasingly focussed on unsupervised learning and semi-supervised learning algorithms.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 32], [33, 41], [42, 44], [45, 57], [58, 66], [67, 70], [71, 86], [87, 95], [96, 106], [106, 107]]}
{"doc_key": "ai-dev-94", "ner": [[5, 5, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Calculation", "of", "this", "example", "using", "Python", "code", ":"], "sentence-detokenized": "Calculation of this example using Python code:", "token2charspan": [[0, 11], [12, 14], [15, 19], [20, 27], [28, 33], [34, 40], [41, 45], [45, 46]]}
{"doc_key": "ai-dev-95", "ner": [[6, 8, "task"], [15, 16, "field"], [19, 23, "algorithm"], [25, 25, "algorithm"], [29, 31, "algorithm"], [34, 35, "researcher"], [33, 38, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[19, 23, 15, 16, "part-of", "", false, false], [19, 23, 29, 31, "type-of", "", false, false], [19, 23, 34, 35, "origin", "", false, false], [19, 23, 33, 38, "origin", "", false, false], [25, 25, 19, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Today", ",", "however", ",", "many", "aspects", "of", "speech", "recognition", "have", "been", "taken", "over", "by", "a", "deep", "learning", "method", "called", "Long", "short", "-", "term", "memory", "(", "LSTM", ")", ",", "a", "recurrent", "neural", "network", "published", "by", "Sepp", "Hochreiter", "&", "J\u00fcrgen", "Schmidhuber", "in", "1997", "."], "sentence-detokenized": "Today, however, many aspects of speech recognition have been taken over by a deep learning method called Long short-term memory (LSTM), a recurrent neural network published by Sepp Hochreiter & J\u00fcrgen Schmidhuber in 1997.", "token2charspan": [[0, 5], [5, 6], [7, 14], [14, 15], [16, 20], [21, 28], [29, 31], [32, 38], [39, 50], [51, 55], [56, 60], [61, 66], [67, 71], [72, 74], [75, 76], [77, 81], [82, 90], [91, 97], [98, 104], [105, 109], [110, 115], [115, 116], [116, 120], [121, 127], [128, 129], [129, 133], [133, 134], [134, 135], [136, 137], [138, 147], [148, 154], [155, 162], [163, 172], [173, 175], [176, 180], [181, 191], [192, 193], [194, 200], [201, 212], [213, 215], [216, 220], [220, 221]]}
{"doc_key": "ai-dev-96", "ner": [[8, 8, "algorithm"], [14, 14, "algorithm"], [18, 18, "algorithm"], [23, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 14, 14, "compare", "", false, false], [8, 8, 23, 23, "named", "same", false, false], [18, 18, 23, 23, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "preliminary", "experimental", "results", "with", "noisy", "datasets", ",", "BrownBoost", "outperformed", "the", "generalisation", "error", "of", "AdaBoost", ";", "however", ",", "LogitBoost", "performed", "as", "well", "as", "BrownBoost", "."], "sentence-detokenized": "In preliminary experimental results with noisy datasets, BrownBoost outperformed the generalisation error of AdaBoost; however, LogitBoost performed as well as BrownBoost.", "token2charspan": [[0, 2], [3, 14], [15, 27], [28, 35], [36, 40], [41, 46], [47, 55], [55, 56], [57, 67], [68, 80], [81, 84], [85, 99], [100, 105], [106, 108], [109, 117], [117, 118], [119, 126], [126, 127], [128, 138], [139, 148], [149, 151], [152, 156], [157, 159], [160, 170], [170, 171]]}
{"doc_key": "ai-dev-97", "ner": [[0, 1, "algorithm"], [8, 10, "researcher"], [6, 7, "country"], [13, 14, "researcher"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 8, 10, "part-of", "", false, false], [8, 10, 6, 7, "physical", "", false, false], [20, 21, 13, 14, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Evolutionary", "programming", "was", "introduced", "in", "the", "USA", "by", "Lawrence", "J.", "Fogel", ",", "and", "John", "Henry", "Holland", "called", "his", "method", "the", "genetic", "algorithm", "."], "sentence-detokenized": "Evolutionary programming was introduced in the USA by Lawrence J. Fogel, and John Henry Holland called his method the genetic algorithm.", "token2charspan": [[0, 12], [13, 24], [25, 28], [29, 39], [40, 42], [43, 46], [47, 50], [51, 53], [54, 62], [63, 65], [66, 71], [71, 72], [73, 76], [77, 81], [82, 87], [88, 95], [96, 102], [103, 106], [107, 113], [114, 117], [118, 125], [126, 135], [135, 136]]}
{"doc_key": "ai-dev-98", "ner": [[9, 9, "researcher"], [11, 11, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 9, 17, 18, "role", "", false, false], [9, 9, 20, 21, "role", "", false, false], [9, 9, 23, 24, "role", "", false, false], [9, 9, 26, 27, "role", "", false, false], [11, 11, 17, 18, "role", "", false, false], [11, 11, 20, 21, "role", "", false, false], [11, 11, 23, 24, "role", "", false, false], [11, 11, 26, 27, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Back", "-", "of", "-", "the", "-", "envelope", "calculations", "by", "Doug", ",", "Alan", "and", "their", "colleagues", "(", "including", "Marvin", "Minsky", ",", "Allen", "Newell", ",", "Edward", "Feigenbaum", "and", "John", "McCarthy", ")", "indicated", "that", "this", "effort", "would", "require", "between", "1000", "and", "3000", "person", "-", "years", "of", "effort", ",", "far", "beyond", "the", "standard", "academic", "project", "model", "."], "sentence-detokenized": "Back-of-the-envelope calculations by Doug, Alan and their colleagues (including Marvin Minsky, Allen Newell, Edward Feigenbaum and John McCarthy) indicated that this effort would require between 1000 and 3000 person-years of effort, far beyond the standard academic project model.", "token2charspan": [[0, 4], [4, 5], [5, 7], [7, 8], [8, 11], [11, 12], [12, 20], [21, 33], [34, 36], [37, 41], [41, 42], [43, 47], [48, 51], [52, 57], [58, 68], [69, 70], [70, 79], [80, 86], [87, 93], [93, 94], [95, 100], [101, 107], [107, 108], [109, 115], [116, 126], [127, 130], [131, 135], [136, 144], [144, 145], [146, 155], [156, 160], [161, 165], [166, 172], [173, 178], [179, 186], [187, 194], [195, 199], [200, 203], [204, 208], [209, 215], [215, 216], [216, 221], [222, 224], [225, 231], [231, 232], [233, 236], [237, 243], [244, 247], [248, 256], [257, 265], [266, 273], [274, 279], [279, 280]]}
{"doc_key": "ai-dev-99", "ner": [[3, 7, "metrics"], [9, 10, "metrics"], [13, 15, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 7, 9, 10, "part-of", "implemented_in", false, false], [13, 15, 18, 18, "part-of", "implemented_in", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Common", "metrics", "are", "the", "Mean", "Squared", "Error", "metric", "implemented", "in", "MSECriterion", "and", "the", "cross", "entropy", "metric", "implemented", "in", "NLLCriterion", "."], "sentence-detokenized": "Common metrics are the Mean Squared Error metric implemented in MSECriterion and the cross entropy metric implemented in NLLCriterion.", "token2charspan": [[0, 6], [7, 14], [15, 18], [19, 22], [23, 27], [28, 35], [36, 41], [42, 48], [49, 60], [61, 63], [64, 76], [77, 80], [81, 84], [85, 90], [91, 98], [99, 105], [106, 117], [118, 120], [121, 133], [133, 134]]}
{"doc_key": "ai-dev-100", "ner": [[0, 1, "researcher"], [16, 22, "misc"], [32, 37, "conference"], [38, 38, "conference"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[0, 1, 32, 37, "role", "", false, false], [0, 1, 38, 38, "role", "", false, false], [16, 22, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Mr", "Zurada", "has", "served", "the", "engineering", "profession", "as", "a", "long", "-", "time", "IEEE", "volunteer", ",", "including", "2014", "IEEE", "Vice", "President", "-", "Technical", "Activities", "(", "TAB", "Chair", ")", ",", "2004", "-", "05", "IEEE", "Computational", "Intelligence", "Society", "President", ",", "and", "ADCOM", "member", "in", "2009", "-", "14", ",", "2016", "-", "18", "and", "earlier", "years", "."], "sentence-detokenized": "Mr Zurada has served the engineering profession as a long-time IEEE volunteer, including 2014 IEEE Vice President-Technical Activities (TAB Chair), 2004-05 IEEE Computational Intelligence Society President, and ADCOM member in 2009-14, 2016-18 and earlier years.", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 20], [21, 24], [25, 36], [37, 47], [48, 50], [51, 52], [53, 57], [57, 58], [58, 62], [63, 67], [68, 77], [77, 78], [79, 88], [89, 93], [94, 98], [99, 103], [104, 113], [113, 114], [114, 123], [124, 134], [135, 136], [136, 139], [140, 145], [145, 146], [146, 147], [148, 152], [152, 153], [153, 155], [156, 160], [161, 174], [175, 187], [188, 195], [196, 205], [205, 206], [207, 210], [211, 216], [217, 223], [224, 226], [227, 231], [231, 232], [232, 234], [234, 235], [236, 240], [240, 241], [241, 243], [244, 247], [248, 255], [256, 261], [261, 262]]}
{"doc_key": "ai-dev-101", "ner": [[3, 10, "field"], [12, 13, "field"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 13, 3, 10, "part-of", "", false, false], [15, 16, 3, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "general", ",", "computational", "linguistics", "relies", "on", "the", "participation", "of", "linguists", ",", "computer", "scientists", ",", "artificial", "intelligence", "specialists", ",", "mathematicians", ",", "logicians", ",", "philosophers", ",", "cognitive", "scientists", ",", "cognitive", "psychologists", ",", "psycholinguists", ",", "anthropologists", "and", "neuroscientists", ",", "among", "others", "."], "sentence-detokenized": "In general, computational linguistics relies on the participation of linguists, computer scientists, artificial intelligence specialists, mathematicians, logicians, philosophers, cognitive scientists, cognitive psychologists, psycholinguists, anthropologists and neuroscientists, among others.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 25], [26, 37], [38, 44], [45, 47], [48, 51], [52, 65], [66, 68], [69, 78], [78, 79], [80, 88], [89, 99], [99, 100], [101, 111], [112, 124], [125, 136], [136, 137], [138, 152], [152, 153], [154, 163], [163, 164], [165, 177], [177, 178], [179, 188], [189, 199], [199, 200], [201, 210], [211, 224], [224, 225], [226, 241], [241, 242], [243, 258], [259, 262], [263, 278], [278, 279], [280, 285], [286, 292], [292, 293]]}
{"doc_key": "ai-dev-102", "ner": [[3, 5, "algorithm"], [8, 9, "algorithm"], [11, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "Dynamic", "Markov", "Networks", ",", "Convolutional", "Neural", "Networks", "and", "Long", "Short", "Term", "Memory", "are", "often", "used", "to", "exploit", "inter", "-", "frame", "correlations", "."], "sentence-detokenized": "Techniques such as Dynamic Markov Networks, Convolutional Neural Networks and Long Short Term Memory are often used to exploit inter-frame correlations.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [83, 88], [89, 93], [94, 100], [101, 104], [105, 110], [111, 115], [116, 118], [119, 126], [127, 132], [132, 133], [133, 138], [139, 151], [151, 152]]}
{"doc_key": "ai-dev-103", "ner": [[0, 0, "product"], [1, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 1, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Unimate", "was", "the", "first", "industrial", "robot", ","], "sentence-detokenized": "Unimate was the first industrial robot,", "token2charspan": [[0, 7], [8, 11], [12, 15], [16, 21], [22, 32], [33, 38], [38, 39]]}
{"doc_key": "ai-dev-104", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [0, 0, "researcher"], [11, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 11, 14, "win-defeat", "", false, false], [7, 8, 11, 14, "win-defeat", "", false, false], [0, 0, 11, 14, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Bengio", ",", "along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "won", "the", "2018", "Turing", "Award", "."], "sentence-detokenized": "Bengio, along with Geoffrey Hinton and Yann LeCun, won the 2018 Turing Award.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 18], [19, 27], [28, 34], [35, 38], [39, 43], [44, 49], [49, 50], [51, 54], [55, 58], [59, 63], [64, 70], [71, 76], [76, 77]]}
{"doc_key": "ai-dev-105", "ner": [[22, 24, "country"], [16, 26, "misc"], [27, 27, "country"], [29, 32, "organisation"], [34, 38, "person"], [40, 41, "person"], [50, 58, "misc"], [49, 56, "country"], [62, 63, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[16, 26, 22, 24, "physical", "filmed_in", false, false], [34, 38, 29, 32, "role", "host", false, false], [40, 41, 29, 32, "role", "reporter", false, false], [50, 58, 22, 24, "physical", "filmed_in", false, false], [50, 58, 49, 56, "physical", "distributed_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Additional", "series", "were", "filmed", "for", "specific", "sectors", "of", "the", "global", "market", ",", "including", "two", "series", "of", "Robot", "Wars", "Extreme", "Warriors", "on", "location", "in", "the", "UK", ",", "with", "US", "competitors", "for", "the", "TNN", "network", "(", "hosted", "by", "Mick", "Foley", "and", "with", "Rebecca", "Grant", "serving", "as", "pit", "reporter", ")", ",", "two", "Dutch", "Robot", "Wars", "for", "distribution", "in", "the", "Netherlands", ",", "and", "a", "single", "series", "for", "Germany", "."], "sentence-detokenized": "Additional series were filmed for specific sectors of the global market, including two series of Robot Wars Extreme Warriors on location in the UK, with US competitors for the TNN network (hosted by Mick Foley and with Rebecca Grant serving as pit reporter), two Dutch Robot Wars for distribution in the Netherlands, and a single series for Germany.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 29], [30, 33], [34, 42], [43, 50], [51, 53], [54, 57], [58, 64], [65, 71], [71, 72], [73, 82], [83, 86], [87, 93], [94, 96], [97, 102], [103, 107], [108, 115], [116, 124], [125, 127], [128, 136], [137, 139], [140, 143], [144, 146], [146, 147], [148, 152], [153, 155], [156, 167], [168, 171], [172, 175], [176, 179], [180, 187], [188, 189], [189, 195], [196, 198], [199, 203], [204, 209], [210, 213], [214, 218], [219, 226], [227, 232], [233, 240], [241, 243], [244, 247], [248, 256], [256, 257], [257, 258], [259, 262], [263, 268], [269, 274], [275, 279], [280, 283], [284, 296], [297, 299], [300, 303], [304, 315], [315, 316], [317, 320], [321, 322], [323, 329], [330, 336], [337, 340], [341, 348], [348, 349]]}
{"doc_key": "ai-dev-106", "ner": [[8, 8, "researcher"], [13, 13, "product"], [30, 31, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 13, 13, "role", "", false, false], [30, 31, 13, 13, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "many", "years", ",", "starting", "in", "1986", ",", "Miller", "directed", "the", "development", "of", "WordNet", ",", "a", "large", "computer", "-", "readable", "electronic", "reference", "that", "can", "be", "used", "in", "applications", "such", "as", "search", "engines", "."], "sentence-detokenized": "For many years, starting in 1986, Miller directed the development of WordNet, a large computer-readable electronic reference that can be used in applications such as search engines.", "token2charspan": [[0, 3], [4, 8], [9, 14], [14, 15], [16, 24], [25, 27], [28, 32], [32, 33], [34, 40], [41, 49], [50, 53], [54, 65], [66, 68], [69, 76], [76, 77], [78, 79], [80, 85], [86, 94], [94, 95], [95, 103], [104, 114], [115, 124], [125, 129], [130, 133], [134, 136], [137, 141], [142, 144], [145, 157], [158, 162], [163, 165], [166, 172], [173, 180], [180, 181]]}
{"doc_key": "ai-dev-107", "ner": [[3, 5, "algorithm"], [7, 12, "algorithm"], [18, 20, "researcher"], [21, 28, "organisation"], [31, 33, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 18, 20, "origin", "", false, false], [3, 5, 31, 33, "win-defeat", "", false, false], [7, 12, 18, 20, "origin", "", false, false], [7, 12, 31, 33, "win-defeat", "", false, false], [18, 20, 21, 28, "physical", "", false, false], [18, 20, 21, 28, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Since", "2009", ",", "recurrent", "neural", "networks", "and", "deep", "feed", "-", "forward", "neural", "networks", "developed", "in", "the", "research", "group", "of", "J\u00fcrgen", "Schmidhuber", "at", "the", "Swiss", "Artificial", "Intelligence", "Laboratory", "IDSIA", "have", "won", "several", "international", "handwriting", "competitions", "..."], "sentence-detokenized": "Since 2009, recurrent neural networks and deep feed-forward neural networks developed in the research group of J\u00fcrgen Schmidhuber at the Swiss Artificial Intelligence Laboratory IDSIA have won several international handwriting competitions...", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 21], [22, 28], [29, 37], [38, 41], [42, 46], [47, 51], [51, 52], [52, 59], [60, 66], [67, 75], [76, 85], [86, 88], [89, 92], [93, 101], [102, 107], [108, 110], [111, 117], [118, 129], [130, 132], [133, 136], [137, 142], [143, 153], [154, 166], [167, 177], [178, 183], [184, 188], [189, 192], [193, 200], [201, 214], [215, 226], [227, 239], [239, 242]]}
{"doc_key": "ai-dev-108", "ner": [[5, 6, "programlang"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "software", "is", "implemented", "in", "C", "++", "and", "packaged", "for", "Python", "."], "sentence-detokenized": "The software is implemented in C++ and packaged for Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 30], [31, 32], [32, 34], [35, 38], [39, 47], [48, 51], [52, 58], [58, 59]]}
{"doc_key": "ai-dev-109", "ner": [[6, 9, "country"], [14, 38, "misc"], [20, 20, "misc"], [32, 35, "misc"], [36, 36, "misc"], [19, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 20, 6, 9, "temporal", "", false, false], [20, 20, 14, 38, "artifact", "", false, false], [20, 20, 19, 19, "physical", "", false, false], [36, 36, 32, 35, "named", "", false, false], [36, 36, 19, 19, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1857", ",", "at", "the", "request", "of", "the", "Tokugawa", "Shogunate", ",", "a", "group", "of", "Dutch", "engineers", "began", "work", "on", "Nagasaki", "Yotetsusho", ",", "a", "modern", ",", "Western", "-", "style", "foundry", "and", "shipyard", "near", "the", "Dutch", "settlement", "of", "Dejima", "in", "Nagasaki", "."], "sentence-detokenized": "In 1857, at the request of the Tokugawa Shogunate, a group of Dutch engineers began work on Nagasaki Yotetsusho, a modern, Western-style foundry and shipyard near the Dutch settlement of Dejima in Nagasaki.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 39], [40, 49], [49, 50], [51, 52], [53, 58], [59, 61], [62, 67], [68, 77], [78, 83], [84, 88], [89, 91], [92, 100], [101, 111], [111, 112], [113, 114], [115, 121], [121, 122], [123, 130], [130, 131], [131, 136], [137, 144], [145, 148], [149, 157], [158, 162], [163, 166], [167, 172], [173, 183], [184, 186], [187, 193], [194, 196], [197, 205], [205, 206]]}
{"doc_key": "ai-dev-110", "ner": [[10, 12, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["We", "make", "it", "as", "precise", "as", "possible", "by", "measuring", "the", "mean", "squared", "error", "between", "math", "/", "math", "and", "math", "\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", "/", "math", ":", "math", "(", "y", "-\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", ")", "we", "want", "both", "for", "mathx", "_", "1", ",\\", "points", ",", "x", "_n", "/", "math", "and", "for", "points", "outside", "our", "sample", "^", "2", "/", "math", "will", "be", "minimal", "."], "sentence-detokenized": "We make it as precise as possible by measuring the mean squared error between math / math and math\\ hat {f} (x; D) / math: math (y -\\ hat {f} (x; D)) we want both for mathx _ 1,\\ points, x _n / math and for points outside our sample ^ 2 / math will be minimal.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 13], [14, 21], [22, 24], [25, 33], [34, 36], [37, 46], [47, 50], [51, 55], [56, 63], [64, 69], [70, 77], [78, 82], [83, 84], [85, 89], [90, 93], [94, 98], [98, 99], [100, 103], [104, 105], [105, 106], [106, 107], [108, 109], [109, 110], [110, 111], [112, 113], [113, 114], [115, 116], [117, 121], [121, 122], [123, 127], [128, 129], [129, 130], [131, 133], [134, 137], [138, 139], [139, 140], [140, 141], [142, 143], [143, 144], [144, 145], [146, 147], [147, 148], [148, 149], [150, 152], [153, 157], [158, 162], [163, 166], [167, 172], [173, 174], [175, 176], [176, 178], [179, 185], [185, 186], [187, 188], [189, 191], [192, 193], [194, 198], [199, 202], [203, 206], [207, 213], [214, 221], [222, 225], [226, 232], [233, 234], [235, 236], [237, 238], [239, 243], [244, 248], [249, 251], [252, 259], [259, 260]]}
{"doc_key": "ai-dev-111", "ner": [[3, 3, "researcher"], [12, 16, "organisation"], [22, 25, "product"], [32, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 12, 16, "role", "", false, false], [22, 25, 12, 16, "temporal", "", false, false], [22, 25, 32, 34, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "then", "sent", "Wydner", "an", "invitation", "to", "attend", "the", "annual", "meeting", "of", "the", "American", "Translators", "Association", "the", "following", "October", ",", "where", "the", "Weidner", "Machine", "Translation", "System", "was", "hailed", "as", "a", "promising", "breakthrough", "in", "machine", "translation", "."], "sentence-detokenized": "He then sent Wydner an invitation to attend the annual meeting of the American Translators Association the following October, where the Weidner Machine Translation System was hailed as a promising breakthrough in machine translation.", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 19], [20, 22], [23, 33], [34, 36], [37, 43], [44, 47], [48, 54], [55, 62], [63, 65], [66, 69], [70, 78], [79, 90], [91, 102], [103, 106], [107, 116], [117, 124], [124, 125], [126, 131], [132, 135], [136, 143], [144, 151], [152, 163], [164, 170], [171, 174], [175, 181], [182, 184], [185, 186], [187, 196], [197, 209], [210, 212], [213, 220], [221, 232], [232, 233]]}
{"doc_key": "ai-dev-112", "ner": [[1, 7, "conference"], [9, 9, "conference"], [13, 14, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 1, 7, "named", "", false, false], [9, 9, 1, 7, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["At", "the", "2018", "Neural", "Information", "Processing", "Systems", "Conference", "(", "NeurIPS", ")", ",", "researchers", "from", "Google", "presented", "the", "study", "."], "sentence-detokenized": "At the 2018 Neural Information Processing Systems Conference (NeurIPS), researchers from Google presented the study.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 30], [31, 41], [42, 49], [50, 60], [61, 62], [62, 69], [69, 70], [70, 71], [72, 83], [84, 88], [89, 95], [96, 105], [106, 109], [110, 115], [115, 116]]}
{"doc_key": "ai-dev-113", "ner": [[0, 4, "algorithm"], [10, 11, "algorithm"], [14, 18, "metrics"], [22, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 4, 10, 11, "usage", "", false, false], [10, 11, 14, 18, "related-to", "", true, false], [14, 18, 22, 25, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Baum", "-", "Welch", "algorithm", "uses", "the", "well", "-", "known", "EM", "algorithm", "to", "find", "the", "maximum", "likelihood", "estimate", "of", "the", "parameters", "of", "a", "hidden", "Markov", "model", "given", "a", "set", "of", "observed", "feature", "vectors", "."], "sentence-detokenized": "The Baum-Welch algorithm uses the well-known EM algorithm to find the maximum likelihood estimate of the parameters of a hidden Markov model given a set of observed feature vectors.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 14], [15, 24], [25, 29], [30, 33], [34, 38], [38, 39], [39, 44], [45, 47], [48, 57], [58, 60], [61, 65], [66, 69], [70, 77], [78, 88], [89, 97], [98, 100], [101, 104], [105, 115], [116, 118], [119, 120], [121, 127], [128, 134], [135, 140], [141, 146], [147, 148], [149, 152], [153, 155], [156, 164], [165, 172], [173, 180], [180, 181]]}
{"doc_key": "ai-dev-114", "ner": [[9, 9, "product"], [11, 30, "product"], [28, 31, "misc"], [37, 44, "product"], [50, 55, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[9, 9, 11, 30, "compare", "", false, false], [28, 31, 11, 30, "part-of", "", false, false], [37, 44, 11, 30, "part-of", "", false, false], [50, 55, 11, 30, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": [")", "In", "addition", "to", "the", "taxonomic", "information", "available", "in", "OpenCyc", ",", "ResearchCyc", "contains", "significantly", "more", "semantic", "information", "(", "i.e.", ",", "additional", "facts", "and", "ground", "rules", ")", "incorporating", "concepts", "from", "the", "knowledge", "base", ";", "it", "also", "includes", "a", "large", "dictionary", ",", "English", "parsing", "and", "generation", "tools", ",", "and", "Java", "-", "based", "interfaces", "for", "information", "organisation", "and", "querying", "."], "sentence-detokenized": ") In addition to the taxonomic information available in OpenCyc, ResearchCyc contains significantly more semantic information (i.e., additional facts and ground rules) incorporating concepts from the knowledge base; it also includes a large dictionary, English parsing and generation tools, and Java-based interfaces for information organisation and querying.", "token2charspan": [[0, 1], [2, 4], [5, 13], [14, 16], [17, 20], [21, 30], [31, 42], [43, 52], [53, 55], [56, 63], [63, 64], [65, 76], [77, 85], [86, 99], [100, 104], [105, 113], [114, 125], [126, 127], [127, 131], [131, 132], [133, 143], [144, 149], [150, 153], [154, 160], [161, 166], [166, 167], [168, 181], [182, 190], [191, 195], [196, 199], [200, 209], [210, 214], [214, 215], [216, 218], [219, 223], [224, 232], [233, 234], [235, 240], [241, 251], [251, 252], [253, 260], [261, 268], [269, 272], [273, 283], [284, 289], [289, 290], [291, 294], [295, 299], [299, 300], [300, 305], [306, 316], [317, 320], [321, 332], [333, 345], [346, 349], [350, 358], [358, 359]]}
{"doc_key": "ai-dev-115", "ner": [[1, 3, "algorithm"], [5, 6, "task"], [10, 11, "field"], [13, 14, "field"], [9, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 5, 6, "type-of", "", false, false], [5, 6, 10, 11, "part-of", "task_part_of_field", false, false], [5, 6, 13, 14, "part-of", "task_part_of_field", false, false], [5, 6, 9, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Hough", "transform", "is", "a", "feature", "extraction", "technique", "used", "in", "image", "analysis", ",", "computer", "vision", "and", "digital", "image", "processing", "."], "sentence-detokenized": "The Hough transform is a feature extraction technique used in image analysis, computer vision and digital image processing.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 22], [23, 24], [25, 32], [33, 43], [44, 53], [54, 58], [59, 61], [62, 67], [68, 76], [76, 77], [78, 86], [87, 93], [94, 97], [98, 105], [106, 111], [112, 122], [122, 123]]}
{"doc_key": "ai-dev-116", "ner": [[4, 4, "product"], [6, 10, "product"], [16, 18, "organisation"], [21, 21, "product"], [23, 24, "researcher"], [27, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 4, 6, 10, "named", "", false, false], [4, 4, 16, 18, "artifact", "", false, false], [4, 4, 21, 21, "origin", "developed_from", false, false], [21, 21, 23, 24, "artifact", "", false, false], [27, 28, 16, 18, "role", "supported", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1978", ",", "the", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "robot", "was", "developed", "by", "Unimation", "with", "the", "support", "of", "Vicarm", "(", "Victor", "Scheinman", ")", "and", "General", "Motors", "."], "sentence-detokenized": "In 1978, the PUMA (Programmable Universal Machine for Assembly) robot was developed by Unimation with the support of Vicarm (Victor Scheinman) and General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 19], [19, 31], [32, 41], [42, 49], [50, 53], [54, 62], [62, 63], [64, 69], [70, 73], [74, 83], [84, 86], [87, 96], [97, 101], [102, 105], [106, 113], [114, 116], [117, 123], [124, 125], [125, 131], [132, 141], [141, 142], [143, 146], [147, 154], [155, 161], [161, 162]]}
{"doc_key": "ai-dev-117", "ner": [[0, 0, "algorithm"], [6, 7, "researcher"], [9, 10, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 7, "origin", "", false, false], [0, 0, 9, 10, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["LSTM", "was", "proposed", "in", "1997", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "LSTM was proposed in 1997 by Sepp Hochreiter and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 20], [21, 25], [26, 28], [29, 33], [34, 44], [45, 48], [49, 55], [56, 67], [67, 68]]}
{"doc_key": "ai-dev-118", "ner": [[6, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated in a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [64, 66], [67, 76], [77, 83], [84, 86], [87, 94], [94, 95]]}
{"doc_key": "ai-dev-119", "ner": [[9, 9, "conference"], [11, 13, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "also", "contributed", "a", "lot", "through", "the", "foundation", "of", "ELRA", "and", "the", "LREC", "conference", "."], "sentence-detokenized": "He also contributed a lot through the foundation of ELRA and the LREC conference.", "token2charspan": [[0, 2], [3, 7], [8, 19], [20, 21], [22, 25], [26, 33], [34, 37], [38, 48], [49, 51], [52, 56], [57, 60], [61, 64], [65, 69], [70, 80], [80, 81]]}
{"doc_key": "ai-dev-120", "ner": [[11, 28, "misc"], [27, 28, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[27, 28, 11, 28, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "popular", "application", "for", "serial", "robots", "in", "today", "'s", "industry", "is", "the", "pick", "-", "and", "-", "place", "assembly", "robot", "with", "four", "degrees", "of", "freedom", ",", "called", "the", "SCARA", "robot", "."], "sentence-detokenized": "A popular application for serial robots in today's industry is the pick-and-place assembly robot with four degrees of freedom, called the SCARA robot.", "token2charspan": [[0, 1], [2, 9], [10, 21], [22, 25], [26, 32], [33, 39], [40, 42], [43, 48], [48, 50], [51, 59], [60, 62], [63, 66], [67, 71], [71, 72], [72, 75], [75, 76], [76, 81], [82, 90], [91, 96], [97, 101], [102, 106], [107, 114], [115, 117], [118, 125], [125, 126], [127, 133], [134, 137], [138, 143], [144, 149], [149, 150]]}
{"doc_key": "ai-dev-121", "ner": [[0, 19, "conference"], [21, 21, "conference"], [23, 28, "conference"], [38, 39, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[21, 21, 0, 19, "named", "", false, false], [38, 39, 23, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "a", "founding", "member", "and", "past", "chair", "(", "2006-2008", ")", "of", "the", "Special", "Interest", "Group", "on", "Web", "as", "Corpus", "(", "SIGWAC", ")", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "and", "was", "also", "one", "of", "the", "founding", "organisers", "of", "SENSEVAL", "."], "sentence-detokenized": "He was a founding member and past chair (2006-2008) of the Special Interest Group on Web as Corpus (SIGWAC) of the Association for Computational Linguistics, and was also one of the founding organisers of SENSEVAL.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 17], [18, 24], [25, 28], [29, 33], [34, 39], [40, 41], [41, 50], [50, 51], [52, 54], [55, 58], [59, 66], [67, 75], [76, 81], [82, 84], [85, 88], [89, 91], [92, 98], [99, 100], [100, 106], [106, 107], [108, 110], [111, 114], [115, 126], [127, 130], [131, 144], [145, 156], [156, 157], [158, 161], [162, 165], [166, 170], [171, 174], [175, 177], [178, 181], [182, 190], [191, 201], [202, 204], [205, 213], [213, 214]]}
{"doc_key": "ai-dev-122", "ner": [[4, 4, "product"], [8, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 4, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "platform", ",", "LinguaStream", "provides", "a", "comprehensive", "Java", "API", "."], "sentence-detokenized": "As a platform, LinguaStream provides a comprehensive Java API.", "token2charspan": [[0, 2], [3, 4], [5, 13], [13, 14], [15, 27], [28, 36], [37, 38], [39, 52], [53, 57], [58, 61], [61, 62]]}
{"doc_key": "ai-dev-123", "ner": [[11, 11, "programlang"], [13, 15, "misc"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 20, 20, "type-of", "", false, false], [13, 15, 20, 20, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "robot", "kit", "is", "Android", "-", "based", "and", "is", "programmed", "using", "Java", ",", "Blocks", "programming", "interface", "or", "other", "Android", "programming", "systems", "."], "sentence-detokenized": "The robot kit is Android-based and is programmed using Java, Blocks programming interface or other Android programming systems.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 16], [17, 24], [24, 25], [25, 30], [31, 34], [35, 37], [38, 48], [49, 54], [55, 59], [59, 60], [61, 67], [68, 79], [80, 89], [90, 92], [93, 98], [99, 106], [107, 118], [119, 126], [126, 127]]}
{"doc_key": "ai-dev-124", "ner": [[11, 14, "algorithm"], [16, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "method", "of", "defining", "the", "linked", "list", "specifies", "whether", "to", "use", "depth", "-", "first", "search", "or", "breadth", "-", "first", "search", "."], "sentence-detokenized": "The method of defining the linked list specifies whether to use depth-first search or breadth-first search.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 22], [23, 26], [27, 33], [34, 38], [39, 48], [49, 56], [57, 59], [60, 63], [64, 69], [69, 70], [70, 75], [76, 82], [83, 85], [86, 93], [93, 94], [94, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-dev-125", "ner": [[7, 7, "task"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "regions", "can", "be", "applied", "to", "object", "recognition", "and", "/", "or", "object", "video", "tracking", "to", "indicate", "the", "presence", "of", "objects", "or", "parts", "of", "objects", "in", "the", "image", "area", "."], "sentence-detokenized": "These regions can be applied to object recognition and/or object video tracking to indicate the presence of objects or parts of objects in the image area.", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 20], [21, 28], [29, 31], [32, 38], [39, 50], [51, 54], [54, 55], [55, 57], [58, 64], [65, 70], [71, 79], [80, 82], [83, 91], [92, 95], [96, 104], [105, 107], [108, 115], [116, 118], [119, 124], [125, 127], [128, 135], [136, 138], [139, 142], [143, 148], [149, 153], [153, 154]]}
{"doc_key": "ai-dev-126", "ner": [[0, 6, "algorithm"], [7, 7, "product"], [13, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 0, 6, "type-of", "", false, false], [7, 7, 13, 13, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "a", "semantic", "network", "is", "WordNet", ",", "a", "lexical", "database", "of", "English", "."], "sentence-detokenized": "An example of a semantic network is WordNet, a lexical database of English.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 24], [25, 32], [33, 35], [36, 43], [43, 44], [45, 46], [47, 54], [55, 63], [64, 66], [67, 74], [74, 75]]}
{"doc_key": "ai-dev-127", "ner": [[0, 19, "task"], [7, 27, "field"], [10, 22, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 19, 7, 27, "part-of", "", false, false], [0, 19, 10, 22, "named", "same", false, false], [0, 19, 10, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Speech", "recognition", "is", "an", "interdisciplinary", "subfield", "of", "computer", "science", "and", "computational", "linguistics", "that", "develops", "methodologies", "and", "technologies", "that", "enable", "spoken", "language", "to", "be", "recognised", "and", "transcribed", "by", "computers", "."], "sentence-detokenized": "Speech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methodologies and technologies that enable spoken language to be recognised and transcribed by computers.", "token2charspan": [[0, 6], [7, 18], [19, 21], [22, 24], [25, 42], [43, 51], [52, 54], [55, 63], [64, 71], [72, 75], [76, 89], [90, 101], [102, 106], [107, 115], [116, 129], [130, 133], [134, 146], [147, 151], [152, 158], [159, 165], [166, 174], [175, 177], [178, 180], [181, 191], [192, 195], [196, 207], [208, 210], [211, 220], [220, 221]]}
{"doc_key": "ai-dev-128", "ner": [[0, 41, "field"], [8, 10, "misc"], [14, 16, "field"], [21, 21, "task"], [18, 19, "task"], [42, 42, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 41, 42, 42, "named", "same", false, false], [14, 16, 0, 41, "part-of", "subfield", false, false], [21, 21, 0, 41, "part-of", "", false, false], [21, 21, 14, 16, "part-of", "", false, false], [18, 19, 14, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Artificial", "intelligence", "has", "seen", "the", "most", "interest", "in", "applied", "ontology", "in", "sub-fields", "such", "as", "natural", "language", "processing", "and", "knowledge", "representation", "within", "machines", ",", "but", "ontology", "editors", "are", "often", "used", "in", "various", "fields", "such", "as", "education", "without", "the", "intention", "of", "contributing", "to", "artificial", "intelligence", "."], "sentence-detokenized": "Artificial intelligence has seen the most interest in applied ontology in sub-fields such as natural language processing and knowledge representation within machines, but ontology editors are often used in various fields such as education without the intention of contributing to artificial intelligence.", "token2charspan": [[0, 10], [11, 23], [24, 27], [28, 32], [33, 36], [37, 41], [42, 50], [51, 53], [54, 61], [62, 70], [71, 73], [74, 84], [85, 89], [90, 92], [93, 100], [101, 109], [110, 120], [121, 124], [125, 134], [135, 149], [150, 156], [157, 165], [165, 166], [167, 170], [171, 179], [180, 187], [188, 191], [192, 197], [198, 202], [203, 205], [206, 213], [214, 220], [221, 225], [226, 228], [229, 238], [239, 246], [247, 250], [251, 260], [261, 263], [264, 276], [277, 279], [280, 290], [291, 303], [303, 304]]}
{"doc_key": "ai-dev-129", "ner": [[5, 9, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 9, 11, 12, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["This", "update", "rule", "is", "actually", "a", "stochastic", "gradient", "descent", "update", "for", "linear", "regression", "."], "sentence-detokenized": "This update rule is actually a stochastic gradient descent update for linear regression.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 19], [20, 28], [29, 30], [31, 41], [42, 50], [51, 58], [59, 65], [66, 69], [70, 76], [77, 87], [87, 88]]}
{"doc_key": "ai-dev-130", "ner": [[5, 10, "organisation"], [3, 16, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "was", "elected", "to", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "the", "National", "Academy", "of", "Sciences", "and", "received", "a", "number", "of", "awards", ":"], "sentence-detokenized": "He was elected to the American Academy of Arts and Sciences and the National Academy of Sciences and received a number of awards:", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 21], [22, 30], [31, 38], [39, 41], [42, 46], [47, 50], [51, 59], [60, 63], [64, 67], [68, 76], [77, 84], [85, 87], [88, 96], [97, 100], [101, 109], [110, 111], [112, 118], [119, 121], [122, 128], [128, 129]]}
{"doc_key": "ai-dev-131", "ner": [[7, 8, "organisation"], [14, 15, "person"], [17, 20, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 14, 15, "related-to", "written_about_by", false, false], [7, 8, 17, 20, "related-to", "written_about_by", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "recent", "school", "of", "thought", "on", "Honda", "'s", "strategy", "was", "put", "forward", "by", "Gary", "Hamel", "and", "C.", "K", ".", "Prahalad", "in", "1989", "."], "sentence-detokenized": "The most recent school of thought on Honda's strategy was put forward by Gary Hamel and C. K. Prahalad in 1989.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 22], [23, 25], [26, 33], [34, 36], [37, 42], [42, 44], [45, 53], [54, 57], [58, 61], [62, 69], [70, 72], [73, 77], [78, 83], [84, 87], [88, 90], [91, 92], [92, 93], [94, 102], [103, 105], [106, 110], [110, 111]]}
{"doc_key": "ai-dev-132", "ner": [[0, 1, "metrics"], [6, 6, "metrics"], [14, 14, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 6, "related-to", "calculates", true, false], [0, 1, 14, 14, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["While", "BLEU", "simply", "calculates", "n-", "gram", "precision", "by", "giving", "equal", "weight", "to", "each", ",", "NIST", "also", "calculates", "how", "informative", "a", "given", "n-", "gram", "is", "."], "sentence-detokenized": "While BLEU simply calculates n-gram precision by giving equal weight to each, NIST also calculates how informative a given n-gram is.", "token2charspan": [[0, 5], [6, 10], [11, 17], [18, 28], [29, 31], [31, 35], [36, 45], [46, 48], [49, 55], [56, 61], [62, 68], [69, 71], [72, 76], [76, 77], [78, 82], [83, 87], [88, 98], [99, 102], [103, 114], [115, 116], [117, 122], [123, 125], [125, 129], [130, 132], [132, 133]]}
{"doc_key": "ai-dev-133", "ner": [[5, 8, "misc"], [11, 14, "conference"], [16, 16, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 8, 11, 14, "temporal", "", false, false], [16, 16, 11, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "honoured", "with", "the", "2019", "Lifetime", "Achievement", "Award", "by", "the", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "."], "sentence-detokenized": "He was honoured with the 2019 Lifetime Achievement Award by the Association for Computational Linguistics (ACL).", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 20], [21, 24], [25, 29], [30, 38], [39, 50], [51, 56], [57, 59], [60, 63], [64, 75], [76, 79], [80, 93], [94, 105], [106, 107], [107, 110], [110, 111], [111, 112]]}
{"doc_key": "ai-dev-134", "ner": [[0, 2, "researcher"], [5, 11, "organisation"], [13, 13, "organisation"], [20, 24, "conference"], [26, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 5, 11, "role", "", false, false], [0, 2, 20, 24, "role", "", false, false], [13, 13, 5, 11, "named", "", false, false], [26, 26, 20, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sycara", "is", "a", "Fellow", "of", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", "and", "a", "Fellow", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Sycara is a Fellow of the Institute of Electrical and Electronics Engineers (IEEE) and a Fellow of the American Association for Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 18], [19, 21], [22, 25], [26, 35], [36, 38], [39, 49], [50, 53], [54, 65], [66, 75], [76, 77], [77, 81], [81, 82], [83, 86], [87, 88], [89, 95], [96, 98], [99, 102], [103, 111], [112, 123], [124, 127], [128, 138], [139, 151], [152, 153], [153, 157], [157, 158], [158, 159]]}
{"doc_key": "ai-dev-135", "ner": [[2, 2, "product"], [11, 13, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 11, 13, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "following", "MATLAB", "code", "shows", "a", "concrete", "solution", "to", "solve", "the", "system", "of", "nonlinear", "equations", "presented", "in", "the", "previous", "section", ":", "See", "also"], "sentence-detokenized": "The following MATLAB code shows a concrete solution to solve the system of nonlinear equations presented in the previous section: See also", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 31], [32, 33], [34, 42], [43, 51], [52, 54], [55, 60], [61, 64], [65, 71], [72, 74], [75, 84], [85, 94], [95, 104], [105, 107], [108, 111], [112, 120], [121, 128], [128, 129], [130, 133], [134, 138]]}
{"doc_key": "ai-dev-136", "ner": [[0, 2, "product"], [13, 14, "field"], [36, 36, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 13, 14, "related-to", "trained_by", true, false], [0, 2, 36, 36, "related-to", "trained_by", true, false], [13, 14, 36, 36, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Pattern", "recognition", "systems", "are", "in", "most", "cases", "trained", "from", "labelled", "training", "data", "(", "supervised", "learning", ")", ",", "but", "other", "algorithms", "can", "be", "used", "to", "discover", "previously", "unknown", "patterns", "when", "labelled", "data", "is", "not", "available", "(", "unsupervised", "learning", ")", "."], "sentence-detokenized": "Pattern recognition systems are in most cases trained from labelled training data (supervised learning), but other algorithms can be used to discover previously unknown patterns when labelled data is not available (unsupervised learning).", "token2charspan": [[0, 7], [8, 19], [20, 27], [28, 31], [32, 34], [35, 39], [40, 45], [46, 53], [54, 58], [59, 67], [68, 76], [77, 81], [82, 83], [83, 93], [94, 102], [102, 103], [103, 104], [105, 108], [109, 114], [115, 125], [126, 129], [130, 132], [133, 137], [138, 140], [141, 149], [150, 160], [161, 168], [169, 177], [178, 182], [183, 191], [192, 196], [197, 199], [200, 203], [204, 213], [214, 215], [215, 227], [228, 236], [236, 237], [237, 238]]}
{"doc_key": "ai-dev-137", "ner": [[5, 7, "researcher"], [10, 10, "country"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 10, 10, "physical", "", false, false], [5, 7, 24, 25, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "was", "first", "used", "by", "Lawrence", "J.", "Fogel", "in", "the", "USA", "in", "1960", "to", "use", "simulated", "evolution", "as", "a", "learning", "process", "aimed", "at", "producing", "artificial", "intelligence", "."], "sentence-detokenized": "It was first used by Lawrence J. Fogel in the USA in 1960 to use simulated evolution as a learning process aimed at producing artificial intelligence.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 17], [18, 20], [21, 29], [30, 32], [33, 38], [39, 41], [42, 45], [46, 49], [50, 52], [53, 57], [58, 60], [61, 64], [65, 74], [75, 84], [85, 87], [88, 89], [90, 98], [99, 106], [107, 112], [113, 115], [116, 125], [126, 136], [137, 149], [149, 150]]}
{"doc_key": "ai-dev-138", "ner": [[0, 1, "field"], [8, 9, "field"], [13, 14, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 8, 9, "part-of", "", false, false], [13, 14, 8, 9, "part-of", "", false, false], [16, 17, 8, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Reinforcement", "learning", "is", "one", "of", "the", "three", "main", "machine", "learning", "paradigms", ",", "alongside", "supervised", "learning", "and", "unsupervised", "learning", "."], "sentence-detokenized": "Reinforcement learning is one of the three main machine learning paradigms, alongside supervised learning and unsupervised learning.", "token2charspan": [[0, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 42], [43, 47], [48, 55], [56, 64], [65, 74], [74, 75], [76, 85], [86, 96], [97, 105], [106, 109], [110, 122], [123, 131], [131, 132]]}
{"doc_key": "ai-dev-139", "ner": [[4, 5, "field"], [12, 12, "programlang"], [28, 29, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 28, 29, "usage", "applies", false, false], [12, 12, 28, 29, "usage", "applies", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "such", "cases", ",", "cloud", "computing", "and", "the", "open", "source", "programming", "language", "R", "can", "help", "small", "banks", "adopt", "risk", "analytics", "and", "support", "branch", "-", "level", "monitoring", "by", "applying", "predictive", "analytics", "."], "sentence-detokenized": "In such cases, cloud computing and the open source programming language R can help small banks adopt risk analytics and support branch-level monitoring by applying predictive analytics.", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 20], [21, 30], [31, 34], [35, 38], [39, 43], [44, 50], [51, 62], [63, 71], [72, 73], [74, 77], [78, 82], [83, 88], [89, 94], [95, 100], [101, 105], [106, 115], [116, 119], [120, 127], [128, 134], [134, 135], [135, 140], [141, 151], [152, 154], [155, 163], [164, 174], [175, 184], [184, 185]]}
{"doc_key": "ai-dev-140", "ner": [[11, 12, "researcher"], [16, 16, "algorithm"], [22, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 22, 22, "named", "same", false, false], [16, 16, 11, 12, "origin", "proves_function", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["One", "of", "the", "first", "versions", "of", "the", "theorem", "was", "proved", "by", "George", "Cybenko", "in", "1989", "for", "sigmoid", "function", "activation", "functions", ".", "Cybenko", "G.", "(", "1989", ")", ",", "2", "(", "4", ")", ",", "303-314", "."], "sentence-detokenized": "One of the first versions of the theorem was proved by George Cybenko in 1989 for sigmoid function activation functions. Cybenko G. (1989), 2 (4), 303-314.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [17, 25], [26, 28], [29, 32], [33, 40], [41, 44], [45, 51], [52, 54], [55, 61], [62, 69], [70, 72], [73, 77], [78, 81], [82, 89], [90, 98], [99, 109], [110, 119], [119, 120], [121, 128], [129, 131], [132, 133], [133, 137], [137, 138], [138, 139], [140, 141], [142, 143], [143, 144], [144, 145], [145, 146], [147, 154], [154, 155]]}
{"doc_key": "ai-dev-141", "ner": [[8, 9, "metrics"], [13, 17, "metrics"]], "ner_mapping_to_source": [1, 2], "relations": [[13, 17, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["In", "this", "process", ",", "known", "as", "cross-validation", ",", "MSE", "is", "often", "referred", "to", "as", "mean", "squared", "prediction", "error", "and", "is", "calculated", "as", "follows"], "sentence-detokenized": "In this process, known as cross-validation, MSE is often referred to as mean squared prediction error and is calculated as follows", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 22], [23, 25], [26, 42], [42, 43], [44, 47], [48, 50], [51, 56], [57, 65], [66, 68], [69, 71], [72, 76], [77, 84], [85, 95], [96, 101], [102, 105], [106, 108], [109, 119], [120, 122], [123, 130]]}
{"doc_key": "ai-dev-142", "ner": [[0, 0, "task"], [4, 16, "task"], [9, 11, "task"], [15, 15, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 16, "compare", "", false, false], [4, 16, 15, 15, "part-of", "", false, false], [9, 11, 4, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OMR", "is", "often", "distinguished", "from", "optical", "character", "recognition", "(", "OCR", ")", "in", "that", "a", "complex", "pattern", "recognition", "engine", "is", "not", "required", "."], "sentence-detokenized": "OMR is often distinguished from optical character recognition (OCR) in that a complex pattern recognition engine is not required.", "token2charspan": [[0, 3], [4, 6], [7, 12], [13, 26], [27, 31], [32, 39], [40, 49], [50, 61], [62, 63], [63, 66], [66, 67], [68, 70], [71, 75], [76, 77], [78, 85], [86, 93], [94, 105], [106, 112], [113, 115], [116, 119], [120, 128], [128, 129]]}
{"doc_key": "ai-dev-143", "ner": [[9, 10, "location"], [11, 11, "location"], [13, 13, "location"], [16, 17, "location"], [19, 20, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 11, 13, 13, "physical", "", false, false], [16, 17, 11, 11, "physical", "", false, false], [19, 20, 11, 11, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "championship", "was", "held", "in", "2018", "and", "2019", "in", "Houston", "and", "Detroit", ",", "Michigan", "at", "the", "TCF", "Centre", "and", "Ford", "Field", "."], "sentence-detokenized": "The championship was held in 2018 and 2019 in Houston and Detroit, Michigan at the TCF Centre and Ford Field.", "token2charspan": [[0, 3], [4, 16], [17, 20], [21, 25], [26, 28], [29, 33], [34, 37], [38, 42], [43, 45], [46, 53], [54, 57], [58, 65], [65, 66], [67, 75], [76, 78], [79, 82], [83, 86], [87, 93], [94, 97], [98, 102], [103, 108], [108, 109]]}
{"doc_key": "ai-dev-144", "ner": [[0, 0, "task"], [9, 9, "task"], [10, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 0, 0, "part-of", "", false, false], [10, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "considered", "as", "two", "separate", "problems", ",", "binary", "classification", "and", "multiclass", "classification", "."], "sentence-detokenized": "Classification can be considered as two separate problems, binary classification and multiclass classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 48], [49, 57], [57, 58], [59, 65], [66, 80], [81, 84], [85, 95], [96, 110], [110, 111]]}
{"doc_key": "ai-dev-145", "ner": [[2, 7, "product"], [8, 9, "product"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 2, 7, "type-of", "", false, false], [12, 12, 2, 7, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "examples", "of", "popular", "parallel", "robots", "are", "the", "Stewart", "platform", "and", "the", "Delta", "robot", "."], "sentence-detokenized": "Two examples of popular parallel robots are the Stewart platform and the Delta robot.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 23], [24, 32], [33, 39], [40, 43], [44, 47], [48, 55], [56, 64], [65, 68], [69, 72], [73, 78], [79, 84], [84, 85]]}
{"doc_key": "ai-dev-146", "ner": [[4, 22, "algorithm"], [23, 24, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 22, 23, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "However", ",", "the", "ReLU", "activation", "function", ",", "which", "can", "not", "be", "differentiated", "at", "0", ",", "has", "become", "quite", "popular", ",", "for", "example", "in", "AlexNet", ")"], "sentence-detokenized": "(However, the ReLU activation function, which cannot be differentiated at 0, has become quite popular, for example in AlexNet)", "token2charspan": [[0, 1], [1, 8], [8, 9], [10, 13], [14, 18], [19, 29], [30, 38], [38, 39], [40, 45], [46, 49], [49, 52], [53, 55], [56, 70], [71, 73], [74, 75], [75, 76], [77, 80], [81, 87], [88, 93], [94, 101], [101, 102], [103, 106], [107, 114], [115, 117], [118, 125], [125, 126]]}
{"doc_key": "ai-dev-147", "ner": [[0, 4, "metrics"], [23, 24, "task"], [12, 12, "task"], [14, 14, "task"], [15, 18, "task"], [27, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 4, 27, 27, "named", "", true, false], [23, 24, 0, 4, "usage", "", true, false], [12, 12, 23, 24, "part-of", "", false, false], [14, 14, 23, 24, "part-of", "", false, false], [15, 18, 23, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "F", "-", "score", "is", "often", "used", "to", "measure", "the", "performance", "of", "search", ",", "document", "classification", "and", "query", "classification", "in", "the", "field", "of", "information", "retrieval", "and", "therefore", "F_beta", "has", "a", "wide", "range", "of", "applications", "."], "sentence-detokenized": "The F-score is often used to measure the performance of search, document classification and query classification in the field of information retrieval and therefore F_beta has a wide range of applications.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 20], [21, 25], [26, 28], [29, 36], [37, 40], [41, 52], [53, 55], [56, 62], [62, 63], [64, 72], [73, 87], [88, 91], [92, 97], [98, 112], [113, 115], [116, 119], [120, 125], [126, 128], [129, 140], [141, 150], [151, 154], [155, 164], [165, 171], [172, 175], [176, 177], [178, 182], [183, 188], [189, 191], [192, 204], [204, 205]]}
{"doc_key": "ai-dev-148", "ner": [[17, 18, "algorithm"], [20, 20, "algorithm"], [23, 24, "algorithm"], [26, 26, "algorithm"], [29, 31, "algorithm"], [33, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 20, 17, 18, "named", "", false, false], [26, 26, 23, 24, "named", "", false, false], [33, 33, 29, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "is", "done", "by", "modelling", "the", "received", "signal", "and", "then", "using", "a", "statistical", "estimation", "method", "such", "as", "maximum", "likelihood", "(", "ML", ")", ",", "majority", "voting", "(", "MV", ")", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "to", "decide", "which", "target", "in", "the", "library", "best", "fits", "the", "model", "built", "using", "the", "received", "signal", "."], "sentence-detokenized": "This is done by modelling the received signal and then using a statistical estimation method such as maximum likelihood (ML), majority voting (MV) or maximum a posteriori (MAP) to decide which target in the library best fits the model built using the received signal.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 15], [16, 25], [26, 29], [30, 38], [39, 45], [46, 49], [50, 54], [55, 60], [61, 62], [63, 74], [75, 85], [86, 92], [93, 97], [98, 100], [101, 108], [109, 119], [120, 121], [121, 123], [123, 124], [124, 125], [126, 134], [135, 141], [142, 143], [143, 145], [145, 146], [147, 149], [150, 157], [158, 159], [160, 170], [171, 172], [172, 175], [175, 176], [177, 179], [180, 186], [187, 192], [193, 199], [200, 202], [203, 206], [207, 214], [215, 219], [220, 224], [225, 228], [229, 234], [235, 240], [241, 246], [247, 250], [251, 259], [260, 266], [266, 267]]}
{"doc_key": "ai-dev-149", "ner": [[0, 2, "researcher"], [3, 16, "misc"], [6, 6, "field"], [8, 13, "university"], [17, 29, "misc"], [20, 20, "field"], [23, 24, "university"], [30, 30, "misc"], [32, 35, "field"], [36, 38, "university"], [46, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 8, 13, "physical", "", false, false], [0, 2, 8, 13, "role", "", false, false], [0, 2, 23, 24, "physical", "", false, false], [0, 2, 23, 24, "role", "", false, false], [0, 2, 36, 38, "physical", "", false, false], [0, 2, 36, 38, "role", "", false, false], [3, 16, 0, 2, "origin", "", false, false], [3, 16, 6, 6, "topic", "", false, false], [17, 29, 0, 2, "origin", "", false, false], [17, 29, 20, 20, "topic", "", false, false], [30, 30, 0, 2, "origin", "", false, false], [30, 30, 32, 35, "topic", "", false, false], [46, 54, 30, 30, "named", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Sowa", "received", "a", "B.Sc", ".", "in", "mathematics", "from", "the", "Massachusetts", "Institute", "of", "Technology", "in", "1962", ",", "an", "M.Sc", ".", "in", "applied", "mathematics", "from", "Harvard", "University", "in", "1966", ",", "and", "a", "Ph.D.", "in", "computer", "science", "from", "the", "Vrije", "Universiteit", "Brussel", "in", "1999", ",", "with", "a", "thesis", "on", "Knowledge", "Representation", ":", "Logical", ",", "Philosophical", "and", "Computational", "Foundations", "."], "sentence-detokenized": "Sowa received a B.Sc. in mathematics from the Massachusetts Institute of Technology in 1962, an M.Sc. in applied mathematics from Harvard University in 1966, and a Ph.D. in computer science from the Vrije Universiteit Brussel in 1999, with a thesis on Knowledge Representation: Logical, Philosophical and Computational Foundations.", "token2charspan": [[0, 4], [5, 13], [14, 15], [16, 20], [20, 21], [22, 24], [25, 36], [37, 41], [42, 45], [46, 59], [60, 69], [70, 72], [73, 83], [84, 86], [87, 91], [91, 92], [93, 95], [96, 100], [100, 101], [102, 104], [105, 112], [113, 124], [125, 129], [130, 137], [138, 148], [149, 151], [152, 156], [156, 157], [158, 161], [162, 163], [164, 169], [170, 172], [173, 181], [182, 189], [190, 194], [195, 198], [199, 204], [205, 217], [218, 225], [226, 228], [229, 233], [233, 234], [235, 239], [240, 241], [242, 248], [249, 251], [252, 261], [262, 276], [276, 277], [278, 285], [285, 286], [287, 300], [301, 304], [305, 318], [319, 330], [330, 331]]}
{"doc_key": "ai-dev-150", "ner": [[1, 2, "task"], [8, 8, "task"], [17, 17, "metrics"], [19, 20, "metrics"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 8, 8, "general-affiliation", "", false, false], [17, 17, 1, 2, "part-of", "", true, false], [19, 20, 1, 2, "part-of", "", true, false], [22, 23, 1, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "paraphrase", "recognition", "can", "be", "posed", "as", "a", "classification", "problem", ",", "most", "standard", "evaluation", "measures", "such", "as", "accuracy", ",", "f1", "score", "or", "ROC", "curve", "give", "relatively", "good", "results", "."], "sentence-detokenized": "Since paraphrase recognition can be posed as a classification problem, most standard evaluation measures such as accuracy, f1 score or ROC curve give relatively good results.", "token2charspan": [[0, 5], [6, 16], [17, 28], [29, 32], [33, 35], [36, 41], [42, 44], [45, 46], [47, 61], [62, 69], [69, 70], [71, 75], [76, 84], [85, 95], [96, 104], [105, 109], [110, 112], [113, 121], [121, 122], [123, 125], [126, 131], [132, 134], [135, 138], [139, 144], [145, 149], [150, 160], [161, 165], [166, 173], [173, 174]]}
{"doc_key": "ai-dev-151", "ner": [[17, 18, "algorithm"], [26, 27, "algorithm"], [29, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 26, 27, "opposite", "not_suited_for", false, false], [17, 18, 29, 29, "opposite", "not_suited_for", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "makes", "it", "practical", "for", "analysing", "large", "data", "sets", "(", "hundreds", "or", "thousands", "of", "taxa", ")", "and", "for", "bootstrapping", ",", "where", "other", "analysis", "tools", "(", "e.g.", "maximum", "parsimony", ",", "maximum", "likelihood", ")", "can", "be", "computationally", "prohibitive", "."], "sentence-detokenized": "This makes it practical for analysing large data sets (hundreds or thousands of taxa) and for bootstrapping, where other analysis tools (e.g. maximum parsimony, maximum likelihood) can be computationally prohibitive.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 37], [38, 43], [44, 48], [49, 53], [54, 55], [55, 63], [64, 66], [67, 76], [77, 79], [80, 84], [84, 85], [86, 89], [90, 93], [94, 107], [107, 108], [109, 114], [115, 120], [121, 129], [130, 135], [136, 137], [137, 141], [142, 149], [150, 159], [159, 160], [161, 168], [169, 179], [179, 180], [181, 184], [185, 187], [188, 203], [204, 215], [215, 216]]}
{"doc_key": "ai-dev-152", "ner": [[4, 6, "programlang"], [9, 13, "organisation"], [15, 15, "organisation"], [24, 24, "programlang"], [28, 38, "organisation"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[15, 15, 9, 13, "named", "", false, false], [28, 38, 4, 6, "role", "submits", true, false], [28, 38, 9, 13, "role", "submits_to", true, false]], "relations_mapping_to_source": [1, 3, 4], "sentence": ["The", "submission", "of", "the", "DAML", "+", "OIL", "language", "to", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", "in", "2002", "was", "the", "work", "of", "the", "DAML", "contractors", "and", "the", "European", "Union", "/", "United", "States", "Joint", "Committee", "on", "Temporary", "Markup", "Languages", "."], "sentence-detokenized": "The submission of the DAML+OIL language to the World Wide Web Consortium (W3C) in 2002 was the work of the DAML contractors and the European Union/United States Joint Committee on Temporary Markup Languages.", "token2charspan": [[0, 3], [4, 14], [15, 17], [18, 21], [22, 26], [26, 27], [27, 30], [31, 39], [40, 42], [43, 46], [47, 52], [53, 57], [58, 61], [62, 72], [73, 74], [74, 77], [77, 78], [79, 81], [82, 86], [87, 90], [91, 94], [95, 99], [100, 102], [103, 106], [107, 111], [112, 123], [124, 127], [128, 131], [132, 140], [141, 146], [146, 147], [147, 153], [154, 160], [161, 166], [167, 176], [177, 179], [180, 189], [190, 196], [197, 206], [206, 207]]}
{"doc_key": "ai-dev-153", "ner": [[3, 3, "misc"], [0, 6, "misc"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 6, 3, 3, "part-of", "", true, false], [11, 12, 3, 3, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "non-linear", "normalisation", "is", "when", "the", "normalisation", "follows", "a", "sigmoid", "function", ",", "in", "which", "case", "the", "normalised", "image", "is", "calculated", "according", "to", "the", "following", "formula"], "sentence-detokenized": "An example of non-linear normalisation is when the normalisation follows a sigmoid function, in which case the normalised image is calculated according to the following formula", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 24], [25, 38], [39, 41], [42, 46], [47, 50], [51, 64], [65, 72], [73, 74], [75, 82], [83, 91], [91, 92], [93, 95], [96, 101], [102, 106], [107, 110], [111, 121], [122, 127], [128, 130], [131, 141], [142, 151], [152, 154], [155, 158], [159, 168], [169, 176]]}
{"doc_key": "ai-dev-154", "ner": [[5, 6, "metrics"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 6, 10, 10, "related-to", "used_together", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "noted", "that", "sensitivity", "is", "often", "paired", "with", "recall", "to", "overcome", "this", "problem"], "sentence-detokenized": "It has been noted that sensitivity is often paired with recall to overcome this problem", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 17], [18, 22], [23, 34], [35, 37], [38, 43], [44, 50], [51, 55], [56, 62], [63, 65], [66, 74], [75, 79], [80, 87]]}
{"doc_key": "ai-dev-155", "ner": [[4, 13, "metrics"], [8, 10, "metrics"], [15, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 19, 8, 10, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Commonly", "used", "measures", "are", "mean", "squared", "error", "and", "root", "mean", "squared", "error", ",", "the", "latter", "used", "in", "the", "Netflix", "Prize", "."], "sentence-detokenized": "Commonly used measures are mean squared error and root mean squared error, the latter used in the Netflix Prize.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 26], [27, 31], [32, 39], [40, 45], [46, 49], [50, 54], [55, 59], [60, 67], [68, 73], [73, 74], [75, 78], [79, 85], [86, 90], [91, 93], [94, 97], [98, 105], [106, 111], [111, 112]]}
{"doc_key": "ai-dev-156", "ner": [[10, 12, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "August", "2016", ",", "a", "research", "programme", "was", "announced", "with", "University", "College", "Hospital", "to", "develop", "an", "algorithm", "that", "can", "automatically", "distinguish", "between", "healthy", "and", "cancerous", "tissue", "in", "the", "head", "and", "neck", "regions", "."], "sentence-detokenized": "In August 2016, a research programme was announced with University College Hospital to develop an algorithm that can automatically distinguish between healthy and cancerous tissue in the head and neck regions.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 17], [18, 26], [27, 36], [37, 40], [41, 50], [51, 55], [56, 66], [67, 74], [75, 83], [84, 86], [87, 94], [95, 97], [98, 107], [108, 112], [113, 116], [117, 130], [131, 142], [143, 150], [151, 158], [159, 162], [163, 172], [173, 179], [180, 182], [183, 186], [187, 191], [192, 195], [196, 200], [201, 208], [208, 209]]}
{"doc_key": "ai-dev-157", "ner": [[17, 19, "organisation"], [22, 29, "organisation"], [30, 31, "organisation"], [34, 53, "organisation"], [43, 47, "organisation"], [52, 55, "organisation"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "impact", "of", "Posner", "'s", "theoretical", "and", "empirical", "contributions", "has", "been", "recognised", "through", "his", "membership", "in", "the", "American", "Psychological", "Association", ",", "the", "Association", "for", "Psychological", "Science", ",", "the", "Society", "of", "Experimental", "Psychologists", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "The impact of Posner's theoretical and empirical contributions has been recognised through his membership in the American Psychological Association, the Association for Psychological Science, the Society of Experimental Psychologists, the American Academy of Arts and Sciences, the American Association for the Advancement of Science, and the National Academy of Sciences.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 20], [20, 22], [23, 34], [35, 38], [39, 48], [49, 62], [63, 66], [67, 71], [72, 82], [83, 90], [91, 94], [95, 105], [106, 108], [109, 112], [113, 121], [122, 135], [136, 147], [147, 148], [149, 152], [153, 164], [165, 168], [169, 182], [183, 190], [190, 191], [192, 195], [196, 203], [204, 206], [207, 219], [220, 233], [233, 234], [235, 238], [239, 247], [248, 255], [256, 258], [259, 263], [264, 267], [268, 276], [276, 277], [278, 281], [282, 290], [291, 302], [303, 306], [307, 310], [311, 322], [323, 325], [326, 333], [333, 334], [335, 338], [339, 342], [343, 351], [352, 359], [360, 362], [363, 371], [371, 372]]}
{"doc_key": "ai-dev-158", "ner": [[2, 2, "product"], [3, 8, "field"], [11, 12, "task"], [14, 16, "task"], [18, 18, "task"], [21, 23, "task"], [25, 25, "task"], [28, 32, "field"], [31, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 2, 3, 8, "usage", "", false, false], [11, 12, 3, 8, "part-of", "", false, false], [14, 16, 3, 8, "part-of", "", false, false], [18, 18, 14, 16, "named", "", false, false], [21, 23, 3, 8, "part-of", "", false, false], [25, 25, 21, 23, "named", "", false, false], [28, 32, 3, 8, "part-of", "", false, false], [31, 31, 3, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["These", "Intelligent", "Chatbots", "utilise", "all", "kinds", "of", "artificial", "intelligence", "such", "as", "image", "inspection", "and", "natural", "language", "understanding", "(", "NLU", ")", ",", "natural", "language", "generation", "(", "NLG", ")", ",", "machine", "learning", "and", "deep", "learning", "."], "sentence-detokenized": "These Intelligent Chatbots utilise all kinds of artificial intelligence such as image inspection and natural language understanding (NLU), natural language generation (NLG), machine learning and deep learning.", "token2charspan": [[0, 5], [6, 17], [18, 26], [27, 34], [35, 38], [39, 44], [45, 47], [48, 58], [59, 71], [72, 76], [77, 79], [80, 85], [86, 96], [97, 100], [101, 108], [109, 117], [118, 131], [132, 133], [133, 136], [136, 137], [137, 138], [139, 146], [147, 155], [156, 166], [167, 168], [168, 171], [171, 172], [172, 173], [174, 181], [182, 190], [191, 194], [195, 199], [200, 208], [208, 209]]}
{"doc_key": "ai-dev-159", "ner": [[4, 6, "metrics"], [8, 8, "metrics"], [11, 11, "metrics"], [14, 21, "metrics"], [26, 28, "metrics"], [30, 30, "metrics"], [36, 40, "metrics"], [43, 45, "metrics"], [47, 47, "metrics"], [50, 60, "metrics"], [62, 64, "metrics"], [66, 66, "metrics"], [69, 76, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 4, 6, "named", "", false, false], [11, 11, 4, 6, "named", "", false, false], [14, 21, 4, 6, "named", "", false, false], [30, 30, 26, 28, "named", "", false, false], [36, 40, 26, 28, "named", "", false, false], [47, 47, 43, 45, "named", "", false, false], [50, 60, 43, 45, "named", "", false, false], [66, 66, 62, 64, "named", "", false, false], [69, 76, 62, 64, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "line", "rates", "are", "Positive", "Predictive", "Value", "(", "PPV", ",", "aka", "precision", ")", "(", "TP", "/", "(", "TP", "+", "FP", ")", ")", ",", "it", "s", "complement", "False", "Discovery", "Rate", "(", "FDR", ")", "(", "FP", "/", "(", "TP", "+", "FP", ")", ")", ";", "and", "Negative", "Predictive", "Value", "(", "NPV", ")", "(", "TN", "/", "(", "TN", "+", "FN", ")", ")", ",", "it", "s", "complement", "False", "Skip", "Rate", "(", "FOR", ")", "(", "FN", "/", "(", "TN", "+", "FN", ")", ")", "."], "sentence-detokenized": "The line rates are Positive Predictive Value (PPV, aka precision) (TP / (TP + FP)), its complement False Discovery Rate (FDR) (FP / (TP + FP)); and Negative Predictive Value (NPV) (TN / (TN + FN)), its complement False Skip Rate (FOR) (FN / (TN + FN)).", "token2charspan": [[0, 3], [4, 8], [9, 14], [15, 18], [19, 27], [28, 38], [39, 44], [45, 46], [46, 49], [49, 50], [51, 54], [55, 64], [64, 65], [66, 67], [67, 69], [70, 71], [72, 73], [73, 75], [76, 77], [78, 80], [80, 81], [81, 82], [82, 83], [84, 86], [86, 87], [88, 98], [99, 104], [105, 114], [115, 119], [120, 121], [121, 124], [124, 125], [126, 127], [127, 129], [130, 131], [132, 133], [133, 135], [136, 137], [138, 140], [140, 141], [141, 142], [142, 143], [144, 147], [148, 156], [157, 167], [168, 173], [174, 175], [175, 178], [178, 179], [180, 181], [181, 183], [184, 185], [186, 187], [187, 189], [190, 191], [192, 194], [194, 195], [195, 196], [196, 197], [198, 200], [200, 201], [202, 212], [213, 218], [219, 223], [224, 228], [229, 230], [230, 233], [233, 234], [235, 236], [236, 238], [239, 240], [241, 242], [242, 244], [245, 246], [247, 249], [249, 250], [250, 251], [251, 252]]}
{"doc_key": "ai-dev-160", "ner": [[8, 8, "misc"], [14, 15, "algorithm"], [17, 17, "algorithm"], [21, 23, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[17, 17, 14, 15, "named", "", false, false], [25, 25, 21, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "information", "is", "a", "mixture", "of", "sitemaps", "and", "RSS", "and", "was", "created", "using", "the", "Information", "Model", "(", "IM", ")", "and", "the", "Biomedical", "Resource", "Ontology", "(", "BRO", ")", "."], "sentence-detokenized": "The information is a mixture of sitemaps and RSS and was created using the Information Model (IM) and the Biomedical Resource Ontology (BRO).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 20], [21, 28], [29, 31], [32, 40], [41, 44], [45, 48], [49, 52], [53, 56], [57, 64], [65, 70], [71, 74], [75, 86], [87, 92], [93, 94], [94, 96], [96, 97], [98, 101], [102, 105], [106, 116], [117, 125], [126, 134], [135, 136], [136, 139], [139, 140], [140, 141]]}
{"doc_key": "ai-dev-161", "ner": [[1, 3, "task"], [6, 8, "algorithm"], [10, 14, "algorithm"], [21, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 3, 10, 14, "origin", "based_on", false, false], [10, 14, 6, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Recent", "text", "recognition", "is", "based", "on", "Recurrent", "neural", "network", "(", "Long", "short", "-", "term", "memory", ")", "and", "does", "not", "require", "a", "language", "model", "."], "sentence-detokenized": "Recent text recognition is based on Recurrent neural network (Long short-term memory) and does not require a language model.", "token2charspan": [[0, 6], [7, 11], [12, 23], [24, 26], [27, 32], [33, 35], [36, 45], [46, 52], [53, 60], [61, 62], [62, 66], [67, 72], [72, 73], [73, 77], [78, 84], [84, 85], [86, 89], [90, 94], [95, 98], [99, 106], [107, 108], [109, 117], [118, 123], [123, 124]]}
{"doc_key": "ai-dev-162", "ner": [[1, 3, "misc"], [4, 5, "metrics"], [8, 9, "algorithm"], [12, 13, "metrics"], [15, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 1, 3, "type-of", "", false, false], [8, 9, 4, 5, "related-to", "", true, false], [12, 13, 1, 3, "type-of", "", false, false], [15, 17, 12, 13, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Popular", "loss", "functions", "include", "hinge", "loss", "(", "for", "linear", "SVMs", ")", "and", "log", "loss", "(", "for", "logistic", "regression", ")", "."], "sentence-detokenized": "Popular loss functions include hinge loss (for linear SVMs) and log loss (for logistic regression).", "token2charspan": [[0, 7], [8, 12], [13, 22], [23, 30], [31, 36], [37, 41], [42, 43], [43, 46], [47, 53], [54, 58], [58, 59], [60, 63], [64, 67], [68, 72], [73, 74], [74, 77], [78, 86], [87, 97], [97, 98], [98, 99]]}
{"doc_key": "ai-dev-163", "ner": [[0, 0, "metrics"], [9, 15, "metrics"], [17, 17, "metrics"], [20, 22, "metrics"], [24, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 9, 15, "compare", "", false, false], [0, 0, 20, 22, "compare", "", false, false], [17, 17, 9, 15, "named", "", false, false], [24, 24, 20, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SSIM", "is", "designed", "to", "improve", "traditional", "methods", "such", "as", "peak", "signal", "-", "to", "-", "noise", "ratio", "(", "PSNR", ")", "and", "mean", "squared", "error", "(", "MSE", ")", "."], "sentence-detokenized": "SSIM is designed to improve traditional methods such as peak signal-to-noise ratio (PSNR) and mean squared error (MSE).", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 19], [20, 27], [28, 39], [40, 47], [48, 52], [53, 55], [56, 60], [61, 67], [67, 68], [68, 70], [70, 71], [71, 76], [77, 82], [83, 84], [84, 88], [88, 89], [90, 93], [94, 98], [99, 106], [107, 112], [113, 114], [114, 117], [117, 118], [118, 119]]}
{"doc_key": "ai-dev-164", "ner": [[11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "work", "inspired", "the", "next", "generation", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "His work inspired the next generation of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 26], [27, 37], [38, 40], [41, 49], [50, 61], [62, 66], [67, 69], [70, 76], [77, 83], [83, 84], [85, 89], [90, 97], [98, 101], [102, 106], [107, 113], [113, 114]]}
{"doc_key": "ai-dev-165", "ner": [[17, 18, "algorithm"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Further", "pulse", "training", "can", "not", "be", "differentiated", ",", "which", "eliminates", "backpropagation", "-", "based", "training", "methods", "such", "as", "gradient", "descent", "."], "sentence-detokenized": "Further pulse training cannot be differentiated, which eliminates backpropagation-based training methods such as gradient descent.", "token2charspan": [[0, 7], [8, 13], [14, 22], [23, 26], [26, 29], [30, 32], [33, 47], [47, 48], [49, 54], [55, 65], [66, 81], [81, 82], [82, 87], [88, 96], [97, 104], [105, 109], [110, 112], [113, 121], [122, 129], [129, 130]]}
{"doc_key": "ai-dev-166", "ner": [[8, 9, "metrics"], [14, 16, "metrics"], [18, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 14, 16, "related-to", "describes", false, false], [14, 16, 18, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "relationship", "can", "be", "easily", "represented", "by", "the", "confusion", "matrix", ",", "a", "table", "describing", "the", "accuracy", "of", "a", "classification", "model", "."], "sentence-detokenized": "This relationship can be easily represented by the confusion matrix, a table describing the accuracy of a classification model.", "token2charspan": [[0, 4], [5, 17], [18, 21], [22, 24], [25, 31], [32, 43], [44, 46], [47, 50], [51, 60], [61, 67], [67, 68], [69, 70], [71, 76], [77, 87], [88, 91], [92, 100], [101, 103], [104, 105], [106, 120], [121, 126], [126, 127]]}
{"doc_key": "ai-dev-167", "ner": [[1, 7, "conference"], [9, 9, "conference"], [13, 14, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 1, 7, "named", "", false, false], [13, 14, 1, 7, "physical", "", false, false], [13, 14, 1, 7, "role", "", false, false], [13, 14, 1, 7, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["At", "the", "2018", "Neural", "Information", "Processing", "Systems", "Conference", "(", "NeurIPS", ")", ",", "researchers", "from", "Google", "presented", "their", "work"], "sentence-detokenized": "At the 2018 Neural Information Processing Systems Conference (NeurIPS), researchers from Google presented their work", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 30], [31, 41], [42, 49], [50, 60], [61, 62], [62, 69], [69, 70], [70, 71], [72, 83], [84, 88], [89, 95], [96, 105], [106, 111], [112, 116]]}
{"doc_key": "ai-dev-168", "ner": [[3, 4, "university"], [13, 13, "product"], [18, 20, "misc"], [21, 22, "conference"], [27, 32, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 13, 18, 20, "win-defeat", "", false, false], [18, 20, 21, 22, "temporal", "", false, false], [27, 32, 21, 22, "part-of", "", false, false], [27, 32, 21, 22, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "his", "time", "at", "Duke", ",", "he", "worked", "on", "the", "automated", "puzzle", "solver", "PROVERB", ",", "which", "won", "an", "Outstanding", "Paper", "Award", "from", "AAAI", "in", "1999", "and", "competed", "in", "the", "American", "Crossword", "Puzzle", "Tournament", "."], "sentence-detokenized": "During his time at Duke, he worked on the automated puzzle solver PROVERB, which won an Outstanding Paper Award from AAAI in 1999 and competed in the American Crossword Puzzle Tournament.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 18], [19, 23], [23, 24], [25, 27], [28, 34], [35, 37], [38, 41], [42, 51], [52, 58], [59, 65], [66, 73], [73, 74], [75, 80], [81, 84], [85, 87], [88, 99], [100, 105], [106, 111], [112, 116], [117, 121], [122, 124], [125, 129], [130, 133], [134, 142], [143, 145], [146, 149], [150, 158], [159, 168], [169, 175], [176, 186], [186, 187]]}
{"doc_key": "ai-dev-169", "ner": [[2, 3, "location"], [1, 5, "location"], [14, 15, "country"], [17, 17, "country"], [19, 19, "country"], [21, 21, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 1, 5, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Headquartered", "in", "Rochester", "Hills", ",", "Michigan", ",", "the", "company", "had", "10", "regional", "locations", "in", "the", "US", ",", "Canada", ",", "Mexico", "and", "Brazil", "."], "sentence-detokenized": "Headquartered in Rochester Hills, Michigan, the company had 10 regional locations in the US, Canada, Mexico and Brazil.", "token2charspan": [[0, 13], [14, 16], [17, 26], [27, 32], [32, 33], [34, 42], [42, 43], [44, 47], [48, 55], [56, 59], [60, 62], [63, 71], [72, 81], [82, 84], [85, 88], [89, 91], [91, 92], [93, 99], [99, 100], [101, 107], [108, 111], [112, 118], [118, 119]]}
{"doc_key": "ai-dev-170", "ner": [[11, 11, "product"], [13, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "joins", "a", "collection", "of", "historically", "significant", "robots", "including", "an", "old", "Unimate", "and", "Odetics", "Odex", "1", "."], "sentence-detokenized": "It joins a collection of historically significant robots including an old Unimate and Odetics Odex 1.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 21], [22, 24], [25, 37], [38, 49], [50, 56], [57, 66], [67, 69], [70, 73], [74, 81], [82, 85], [86, 93], [94, 98], [99, 100], [100, 101]]}
{"doc_key": "ai-dev-171", "ner": [[7, 8, "researcher"], [11, 12, "organisation"], [14, 17, "researcher"], [21, 31, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 11, 12, "physical", "", false, false], [7, 8, 11, 12, "role", "", false, false], [14, 17, 11, 12, "physical", "", false, false], [14, 17, 11, 12, "role", "", false, false], [14, 17, 21, 31, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["This", "issue", "'s", "guest", "editor", "will", "be", "David", "'s", "former", "colleague", "at", "NIST", ",", "Judah", "Levine", ",", "the", "most", "recent", "recipient", "of", "the", "I", ".", "I", ".", "Rabi", "Award", ".", "Rabi", "Award", "."], "sentence-detokenized": "This issue's guest editor will be David's former colleague at NIST, Judah Levine, the most recent recipient of the I. I. Rabi Award. Rabi Award.", "token2charspan": [[0, 4], [5, 10], [10, 12], [13, 18], [19, 25], [26, 30], [31, 33], [34, 39], [39, 41], [42, 48], [49, 58], [59, 61], [62, 66], [66, 67], [68, 73], [74, 80], [80, 81], [82, 85], [86, 90], [91, 97], [98, 107], [108, 110], [111, 114], [115, 116], [116, 117], [118, 119], [119, 120], [121, 125], [126, 131], [131, 132], [133, 137], [138, 143], [143, 144]]}
{"doc_key": "ai-dev-172", "ner": [[13, 14, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "can", "conventionally", "be", "organised", "as", "a", "2", "\u00d7", "2", "contingency", "table", "(", "confusion", "matrix", ")", "with", "the", "test", "result", "on", "the", "vertical", "axis", "and", "the", "actual", "situation", "on", "the", "horizontal", "axis", "."], "sentence-detokenized": "These can conventionally be organised as a 2 \u00d7 2 contingency table (confusion matrix) with the test result on the vertical axis and the actual situation on the horizontal axis.", "token2charspan": [[0, 5], [6, 9], [10, 24], [25, 27], [28, 37], [38, 40], [41, 42], [43, 44], [45, 46], [47, 48], [49, 60], [61, 66], [67, 68], [68, 77], [78, 84], [84, 85], [86, 90], [91, 94], [95, 99], [100, 106], [107, 109], [110, 113], [114, 122], [123, 127], [128, 131], [132, 135], [136, 142], [143, 152], [153, 155], [156, 159], [160, 170], [171, 175], [175, 176]]}
{"doc_key": "ai-dev-173", "ner": [[0, 5, "product"], [6, 6, "product"], [8, 8, "product"], [11, 12, "product"], [14, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 5, 6, 6, "part-of", "", false, false], [0, 5, 8, 8, "part-of", "", false, false], [0, 5, 11, 12, "part-of", "", false, false], [0, 5, 14, 16, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Apple", "iOS", "operating", "system", "for", "iPhone", ",", "iPad", ",", "and", "iPod", "Touch", "uses", "VoiceOver", "speech", "synthesis", "accessibility", "."], "sentence-detokenized": "The Apple iOS operating system for iPhone, iPad, and iPod Touch uses VoiceOver speech synthesis accessibility.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 23], [24, 30], [31, 34], [35, 41], [41, 42], [43, 47], [47, 48], [49, 52], [53, 57], [58, 63], [64, 68], [69, 78], [79, 85], [86, 95], [96, 109], [109, 110]]}
{"doc_key": "ai-dev-174", "ner": [[7, 9, "conference"], [10, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "the", "best", "system", "entering", "MUC", "-", "7", "achieved", "an", "F-", "measure", "of", "93.39", "%", ",", "while", "the", "human", "interpreters", "scored", "97.6", "%", "and", "96.95", "%", "."], "sentence-detokenized": "For example, the best system entering MUC-7 achieved an F-measure of 93.39%, while the human interpreters scored 97.6% and 96.95%.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 37], [38, 41], [41, 42], [42, 43], [44, 52], [53, 55], [56, 58], [58, 65], [66, 68], [69, 74], [74, 75], [75, 76], [77, 82], [83, 86], [87, 92], [93, 105], [106, 112], [113, 117], [117, 118], [119, 122], [123, 128], [128, 129], [129, 130]]}
{"doc_key": "ai-dev-175", "ner": [[11, 13, "algorithm"], [14, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 16, 11, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "is", "done", "using", "standard", "neural", "network", "training", "algorithms", "such", "as", "stochastic", "gradient", "descent", "with", "back", "propagation", "."], "sentence-detokenized": "This is done using standard neural network training algorithms such as stochastic gradient descent with back propagation.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 18], [19, 27], [28, 34], [35, 42], [43, 51], [52, 62], [63, 67], [68, 70], [71, 81], [82, 90], [91, 98], [99, 103], [104, 108], [109, 120], [120, 121]]}
{"doc_key": "ai-dev-176", "ner": [[0, 1, "organisation"], [18, 19, "country"], [23, 27, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 18, 19, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Rotten", "Tomatoes", "is", "among", "the", "top", "1000", "sites", ",", "ranking", "400th", "worldwide", "and", "in", "the", "top", "150", "for", "the", "US", "only", ",", "according", "to", "website", "ranking", "site", "Alexa", "."], "sentence-detokenized": "Rotten Tomatoes is among the top 1000 sites, ranking 400th worldwide and in the top 150 for the US only, according to website ranking site Alexa.", "token2charspan": [[0, 6], [7, 15], [16, 18], [19, 24], [25, 28], [29, 32], [33, 37], [38, 43], [43, 44], [45, 52], [53, 58], [59, 68], [69, 72], [73, 75], [76, 79], [80, 83], [84, 87], [88, 91], [92, 95], [96, 98], [99, 103], [103, 104], [105, 114], [115, 117], [118, 125], [126, 133], [134, 138], [139, 144], [144, 145]]}
{"doc_key": "ai-dev-177", "ner": [[15, 16, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "general", ",", "all", "learnings", "show", "an", "increasing", "change", "over", "time", ",", "but", "define", "a", "Sigmoid", "function", "with", "different", "appearances", "depending", "on", "the", "time", "scale", "of", "the", "observation", "."], "sentence-detokenized": "In general, all learnings show an increasing change over time, but define a Sigmoid function with different appearances depending on the time scale of the observation.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 25], [26, 30], [31, 33], [34, 44], [45, 51], [52, 56], [57, 61], [61, 62], [63, 66], [67, 73], [74, 75], [76, 83], [84, 92], [93, 97], [98, 107], [108, 119], [120, 129], [130, 132], [133, 136], [137, 141], [142, 147], [148, 150], [151, 154], [155, 166], [166, 167]]}
{"doc_key": "ai-dev-178", "ner": [[0, 1, "metrics"], [5, 7, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 5, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["SSD", "is", "also", "known", "as", "mean", "squared", "error", "."], "sentence-detokenized": "SSD is also known as mean squared error.", "token2charspan": [[0, 3], [4, 6], [7, 11], [12, 17], [18, 20], [21, 25], [26, 33], [34, 39], [39, 40]]}
{"doc_key": "ai-dev-179", "ner": [[0, 2, "algorithm"], [4, 5, "algorithm"], [7, 9, "algorithm"], [21, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 21, 22, "related-to", "can_be_related_to", true, false], [4, 5, 21, 22, "related-to", "can_be_related_to", true, false], [7, 9, 21, 22, "related-to", "can_be_related_to", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", ",", "neural", "networks", "or", "naive", "Bayesian", "classifier", "can", "be", "used", "in", "combination", "with", "model", "quality", "measures", "such", "as", "balanced", "accuracy"], "sentence-detokenized": "Decision tree learning, neural networks or naive Bayesian classifier can be used in combination with model quality measures such as balanced accuracy", "token2charspan": [[0, 8], [9, 13], [14, 22], [22, 23], [24, 30], [31, 39], [40, 42], [43, 48], [49, 57], [58, 68], [69, 72], [73, 75], [76, 80], [81, 83], [84, 95], [96, 100], [101, 106], [107, 114], [115, 123], [124, 128], [129, 131], [132, 140], [141, 149]]}
{"doc_key": "ai-dev-180", "ner": [[14, 15, "conference"], [20, 24, "conference"], [18, 27, "misc"], [31, 34, "product"], [38, 44, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[18, 27, 20, 24, "origin", "", false, false], [18, 27, 20, 24, "temporal", "", false, false], [31, 34, 18, 27, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "is", "a", "past", "president", "(", "1979", ")", "and", "inaugural", "member", "(", "2011", ")", "of", "ACL", ",", "co-recipient", "of", "the", "1992", "Association", "for", "Computing", "Machinery", "Software", "Systems", "Award", "for", "contributions", "to", "the", "Interlisp", "programming", "system", ",", "and", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", "."], "sentence-detokenized": "He is a past president (1979) and inaugural member (2011) of ACL, co-recipient of the 1992 Association for Computing Machinery Software Systems Award for contributions to the Interlisp programming system, and a member of the Association for Computing Machinery.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 22], [23, 24], [24, 28], [28, 29], [30, 33], [34, 43], [44, 50], [51, 52], [52, 56], [56, 57], [58, 60], [61, 64], [64, 65], [66, 78], [79, 81], [82, 85], [86, 90], [91, 102], [103, 106], [107, 116], [117, 126], [127, 135], [136, 143], [144, 149], [150, 153], [154, 167], [168, 170], [171, 174], [175, 184], [185, 196], [197, 203], [203, 204], [205, 208], [209, 210], [211, 217], [218, 220], [221, 224], [225, 236], [237, 240], [241, 250], [251, 260], [260, 261]]}
{"doc_key": "ai-dev-181", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [12, 14, "researcher"], [25, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 25, 27, "related-to", "", false, false], [5, 6, 25, 27, "related-to", "", false, false], [8, 8, 25, 27, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "is", "recognised", "by", "Cade", "Metz", "as", "one", "of", "the", "three", "people", "most", "responsible", "for", "the", "advancement", "of", "deep", "learning", "during", "the", "1990s", "and", "2000s", "."], "sentence-detokenized": "Along with Geoffrey Hinton and Yann LeCun, Bengio is recognised by Cade Metz as one of the three people most responsible for the advancement of deep learning during the 1990s and 2000s.", "token2charspan": [[0, 5], [6, 10], [11, 19], [20, 26], [27, 30], [31, 35], [36, 41], [41, 42], [43, 49], [50, 52], [53, 63], [64, 66], [67, 71], [72, 76], [77, 79], [80, 83], [84, 86], [87, 90], [91, 96], [97, 103], [104, 108], [109, 120], [121, 124], [125, 128], [129, 140], [141, 143], [144, 148], [149, 157], [158, 164], [165, 168], [169, 174], [175, 178], [179, 184], [184, 185]]}
{"doc_key": "ai-dev-182", "ner": [[1, 2, "field"], [0, 5, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "information", "theory", "and", "computer", "science", ",", "a", "code", "is", "generally", "regarded", "as", "an", "algorithm", "that", "uniquely", "represents", "symbols", "in", "some", "source", "alphabet", "with", "encoded", "strings", "that", "may", "be", "in", "another", "target", "alphabet", "."], "sentence-detokenized": "In information theory and computer science, a code is generally regarded as an algorithm that uniquely represents symbols in some source alphabet with encoded strings that may be in another target alphabet.", "token2charspan": [[0, 2], [3, 14], [15, 21], [22, 25], [26, 34], [35, 42], [42, 43], [44, 45], [46, 50], [51, 53], [54, 63], [64, 72], [73, 75], [76, 78], [79, 88], [89, 93], [94, 102], [103, 113], [114, 121], [122, 124], [125, 129], [130, 136], [137, 145], [146, 150], [151, 158], [159, 166], [167, 171], [172, 175], [176, 178], [179, 181], [182, 189], [190, 196], [197, 205], [205, 206]]}
{"doc_key": "ai-dev-183", "ner": [[6, 7, "algorithm"], [2, 3, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 6, 7, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Like", "the", "logistic", "function", ",", "the", "sigmoid", "function", ",", "which", "is", "a", "fairly", "simple", "nonlinear", "function", ",", "has", "an", "easily", "computable", "derivative", ",", "which", "can", "be", "important", "when", "calculating", "weight", "updates", "in", "the", "network", "."], "sentence-detokenized": "Like the logistic function, the sigmoid function, which is a fairly simple nonlinear function, has an easily computable derivative, which can be important when calculating weight updates in the network.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 26], [26, 27], [28, 31], [32, 39], [40, 48], [48, 49], [50, 55], [56, 58], [59, 60], [61, 67], [68, 74], [75, 84], [85, 93], [93, 94], [95, 98], [99, 101], [102, 108], [109, 119], [120, 130], [130, 131], [132, 137], [138, 141], [142, 144], [145, 154], [155, 159], [160, 171], [172, 178], [179, 186], [187, 189], [190, 193], [194, 201], [201, 202]]}
{"doc_key": "ai-dev-184", "ner": [[6, 6, "location"], [8, 8, "location"], [10, 12, "country"], [15, 15, "country"], [18, 19, "country"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[6, 6, 8, 8, "physical", "", false, false], [8, 8, 10, 12, "physical", "", false, false], [8, 8, 15, 15, "physical", "", false, false], [8, 8, 18, 19, "physical", "", false, false], [15, 15, 10, 12, "origin", "", false, false], [18, 19, 15, 15, "origin", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6], "sentence": ["\u010capek", "was", "born", "in", "1887", "in", "Hronov", ",", "Bohemia", "(", "Austria", "-", "Hungary", ",", "later", "Czechoslovakia", ",", "now", "Czech", "Republic", ")", "."], "sentence-detokenized": "\u010capek was born in 1887 in Hronov, Bohemia (Austria-Hungary, later Czechoslovakia, now Czech Republic).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 41], [42, 43], [43, 50], [50, 51], [51, 58], [58, 59], [60, 65], [66, 80], [80, 81], [82, 85], [86, 91], [92, 100], [100, 101], [101, 102]]}
{"doc_key": "ai-dev-185", "ner": [[5, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "specialised", "software", "can", "tell", "RSS", "."], "sentence-detokenized": "Some specialised software can tell RSS.", "token2charspan": [[0, 4], [5, 16], [17, 25], [26, 29], [30, 34], [35, 38], [38, 39]]}
{"doc_key": "ai-dev-186", "ner": [[6, 7, "task"], [16, 17, "task"], [10, 10, "task"], [13, 13, "task"], [19, 36, "task"], [27, 28, "task"], [30, 32, "task"], [37, 38, "task"], [41, 43, "product"], [45, 46, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[6, 7, 16, 17, "related-to", "", true, false], [6, 7, 10, 10, "related-to", "", true, false], [6, 7, 13, 13, "related-to", "", true, false], [30, 32, 27, 28, "usage", "", true, false], [41, 43, 37, 38, "type-of", "", false, false], [45, 46, 37, 38, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Features", "of", "ontology", "editors", "include", ":", "visual", "navigation", "facilities", ",", "inference", "engines", "and", "extraction", "within", "the", "knowledge", "model", ";", "module", "support", ";", "import", "and", "export", "of", "foreign", "knowledge", "representation", "languages", "for", "ontology", "matching", ";", "and", "support", "of", "meta", "-ontologies", "such", "as", "OWL", "-", "S", ",", "Dublin", "Core", ",", "etc", "."], "sentence-detokenized": "Features of ontology editors include: visual navigation facilities, inference engines and extraction within the knowledge model; module support; import and export of foreign knowledge representation languages for ontology matching; and support of meta-ontologies such as OWL-S, Dublin Core, etc.", "token2charspan": [[0, 8], [9, 11], [12, 20], [21, 28], [29, 36], [36, 37], [38, 44], [45, 55], [56, 66], [66, 67], [68, 77], [78, 85], [86, 89], [90, 100], [101, 107], [108, 111], [112, 121], [122, 127], [127, 128], [129, 135], [136, 143], [143, 144], [145, 151], [152, 155], [156, 162], [163, 165], [166, 173], [174, 183], [184, 198], [199, 208], [209, 212], [213, 221], [222, 230], [230, 231], [232, 235], [236, 243], [244, 246], [247, 251], [251, 262], [263, 267], [268, 270], [271, 274], [274, 275], [275, 276], [276, 277], [278, 284], [285, 289], [289, 290], [291, 294], [294, 295]]}
{"doc_key": "ai-dev-187", "ner": [[0, 2, "organisation"], [4, 37, "misc"], [13, 17, "task"], [20, 20, "field"], [23, 23, "misc"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 37, 0, 2, "origin", "", false, false], [13, 17, 4, 37, "part-of", "", false, false], [20, 20, 4, 37, "part-of", "", false, false], [23, 23, 20, 20, "type-of", "", false, false], [25, 26, 20, 20, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "FBI", "has", "also", "launched", "its", "Next", "Generation", "Identification", "programme", ",", "which", "includes", "facial", "recognition", "as", "well", "as", "more", "traditional", "biometrics", "such", "as", "fingerprints", "and", "iris", "scans", ",", "and", "can", "be", "drawn", "from", "both", "criminal", "and", "civil", "databases", "."], "sentence-detokenized": "The FBI has also launched its Next Generation Identification programme, which includes facial recognition as well as more traditional biometrics such as fingerprints and iris scans, and can be drawn from both criminal and civil databases.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 16], [17, 25], [26, 29], [30, 34], [35, 45], [46, 60], [61, 70], [70, 71], [72, 77], [78, 86], [87, 93], [94, 105], [106, 108], [109, 113], [114, 116], [117, 121], [122, 133], [134, 144], [145, 149], [150, 152], [153, 165], [166, 169], [170, 174], [175, 180], [180, 181], [182, 185], [186, 189], [190, 192], [193, 198], [199, 203], [204, 208], [209, 217], [218, 221], [222, 227], [228, 237], [237, 238]]}
{"doc_key": "ai-dev-188", "ner": [[5, 6, "person"], [8, 10, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "the", "2016", "season", ",", "Samantha", "Ponder", "replaced", "Molly", "McGrath", "as", "host", "."], "sentence-detokenized": "For the 2016 season, Samantha Ponder replaced Molly McGrath as host.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 19], [19, 20], [21, 29], [30, 36], [37, 45], [46, 51], [52, 59], [60, 62], [63, 67], [67, 68]]}
{"doc_key": "ai-dev-189", "ner": [[6, 7, "algorithm"], [17, 21, "misc"], [23, 23, "misc"], [25, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "a", "widely", "used", "opponent", "search", "algorithm", "for", "machine", "play", "of", "two", "-", "player", "games", "(", "Tic", "-", "tac", "-", "toe", ",", "Chess", ",", "Go", ",", "etc.", ")", "."], "sentence-detokenized": "It is a widely used opponent search algorithm for machine play of two-player games (Tic-tac-toe, Chess, Go, etc.).", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 19], [20, 28], [29, 35], [36, 45], [46, 49], [50, 57], [58, 62], [63, 65], [66, 69], [69, 70], [70, 76], [77, 82], [83, 84], [84, 87], [87, 88], [88, 91], [91, 92], [92, 95], [95, 96], [97, 102], [102, 103], [104, 106], [106, 107], [108, 112], [112, 113], [113, 114]]}
{"doc_key": "ai-dev-190", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [18, 19, "field"], [21, 22, "field"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "includes", "the", "fields", "of", "computer", "vision", "or", "machine", "vision", "and", "medical", "imaging", "and", "makes", "intensive", "use", "of", "pattern", "recognition", ",", "digital", "geometry", "and", "signal", "processing", "."], "sentence-detokenized": "It includes the fields of computer vision or machine vision and medical imaging and makes intensive use of pattern recognition, digital geometry and signal processing.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 22], [23, 25], [26, 34], [35, 41], [42, 44], [45, 52], [53, 59], [60, 63], [64, 71], [72, 79], [80, 83], [84, 89], [90, 99], [100, 103], [104, 106], [107, 114], [115, 126], [126, 127], [128, 135], [136, 144], [145, 148], [149, 155], [156, 166], [166, 167]]}
{"doc_key": "ai-dev-191", "ner": [[4, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "in", "a", "face", "recognition", "system", ",", "a", "picture", "of", "a", "person", "'s", "face", "is", "the", "input", "and", "the", "output", "label", "is", "the", "name", "of", "that", "person", "."], "sentence-detokenized": "For example, in a face recognition system, a picture of a person's face is the input and the output label is the name of that person.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 17], [18, 22], [23, 34], [35, 41], [41, 42], [43, 44], [45, 52], [53, 55], [56, 57], [58, 64], [64, 66], [67, 71], [72, 74], [75, 78], [79, 84], [85, 88], [89, 92], [93, 99], [100, 105], [106, 108], [109, 112], [113, 117], [118, 120], [121, 125], [126, 132], [132, 133]]}
{"doc_key": "ai-dev-192", "ner": [[0, 1, "organisation"], [4, 7, "product"], [9, 11, "product"], [17, 19, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 7, "artifact", "", false, false], [4, 7, 9, 11, "part-of", "", false, false], [9, 11, 4, 7, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Apple", "Inc", "has", "introduced", "Face", "ID", "in", "its", "flagship", "i", "Phone", "X", "as", "the", "biometric", "authentication", "successor", "to", "Touch", "ID", ",", "a", "fingerprint", "-", "based", "system", "."], "sentence-detokenized": "Apple Inc has introduced Face ID in its flagship iPhone X as the biometric authentication successor to Touch ID, a fingerprint-based system.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 24], [25, 29], [30, 32], [33, 35], [36, 39], [40, 48], [49, 50], [50, 55], [56, 57], [58, 60], [61, 64], [65, 74], [75, 89], [90, 99], [100, 102], [103, 108], [109, 111], [111, 112], [113, 114], [115, 126], [126, 127], [127, 132], [133, 139], [139, 140]]}
{"doc_key": "ai-dev-193", "ner": [[2, 5, "metrics"], [6, 14, "metrics"], [22, 26, "metrics"], [28, 30, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Or", "combine", "the", "F", "-", "measure", "with", "the", "raw", "model", "output", "and", "the", "R-", "square", "evaluated", "for", "the", "target", ";", "or", "combine", "the", "cost", "/", "gain", "matrix", "with", "the", "correlation", "coefficient", ",", "etc", "."], "sentence-detokenized": "Or combine the F-measure with the raw model output and the R-square evaluated for the target; or combine the cost/gain matrix with the correlation coefficient, etc.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 16], [16, 17], [17, 24], [25, 29], [30, 33], [34, 37], [38, 43], [44, 50], [51, 54], [55, 58], [59, 61], [61, 67], [68, 77], [78, 81], [82, 85], [86, 92], [92, 93], [94, 96], [97, 104], [105, 108], [109, 113], [113, 114], [114, 118], [119, 125], [126, 130], [131, 134], [135, 146], [147, 158], [158, 159], [160, 163], [163, 164]]}
{"doc_key": "ai-dev-194", "ner": [[8, 13, "conference"], [16, 18, "location"], [20, 20, "location"], [23, 27, "location"], [29, 29, "location"], [7, 31, "country"], [36, 38, "location"], [41, 45, "location"], [46, 47, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 13, 16, 18, "physical", "", false, false], [8, 13, 23, 27, "physical", "", false, false], [8, 13, 36, 38, "physical", "", false, false], [8, 13, 41, 45, "physical", "", false, false], [16, 18, 20, 20, "physical", "", false, false], [23, 27, 29, 29, "physical", "", false, false], [29, 29, 7, 31, "physical", "", false, false], [36, 38, 46, 47, "physical", "", false, false], [41, 45, 46, 47, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Over", "the", "past", "15", "years", ",", "the", "Spanish", "edition", "of", "Campus", "Party", "has", "taken", "place", "at", "Colegio", "Miguel", "Hern\u00e1ndez", ",", "Ceulaj", "and", "the", "Municipal", "Sports", "Arena", "of", "Benalm\u00e1dena", "in", "Malaga", ",", "Spain", ";", "and", "at", "the", "Valencia", "County", "Fair", "and", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", "."], "sentence-detokenized": "Over the past 15 years, the Spanish edition of Campus Party has taken place at Colegio Miguel Hern\u00e1ndez, Ceulaj and the Municipal Sports Arena of Benalm\u00e1dena in Malaga, Spain; and at the Valencia County Fair and the City of Arts and Sciences in Valencia.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 22], [22, 23], [24, 27], [28, 35], [36, 43], [44, 46], [47, 53], [54, 59], [60, 63], [64, 69], [70, 75], [76, 78], [79, 86], [87, 93], [94, 103], [103, 104], [105, 111], [112, 115], [116, 119], [120, 129], [130, 136], [137, 142], [143, 145], [146, 157], [158, 160], [161, 167], [167, 168], [169, 174], [174, 175], [176, 179], [180, 182], [183, 186], [187, 195], [196, 202], [203, 207], [208, 211], [212, 215], [216, 220], [221, 223], [224, 228], [229, 232], [233, 241], [242, 244], [245, 253], [253, 254]]}
{"doc_key": "ai-dev-195", "ner": [[0, 0, "product"], [14, 14, "programlang"], [17, 17, "product"], [19, 19, "product"], [23, 23, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 14, 0, 0, "general-affiliation", "", false, false], [17, 17, 14, 14, "part-of", "", false, false], [19, 19, 14, 14, "part-of", "", false, false], [23, 23, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["gnuplot", "can", "be", "used", "to", "generate", "data", "graphs", "from", "various", "programming", "languages", ",", "including", "Perl", "(", "via", "PDL", "and", "CPAN", "packages", ")", ",", "Python", "(", "via", ")", "."], "sentence-detokenized": "gnuplot can be used to generate data graphs from various programming languages, including Perl (via PDL and CPAN packages), Python (via).", "token2charspan": [[0, 7], [8, 11], [12, 14], [15, 19], [20, 22], [23, 31], [32, 36], [37, 43], [44, 48], [49, 56], [57, 68], [69, 78], [78, 79], [80, 89], [90, 94], [95, 96], [96, 99], [100, 103], [104, 107], [108, 112], [113, 121], [121, 122], [122, 123], [124, 130], [131, 132], [132, 135], [135, 136], [136, 137]]}
{"doc_key": "ai-dev-196", "ner": [[3, 5, "product"], [18, 18, "conference"], [20, 20, "conference"], [34, 34, "conference"], [36, 36, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[18, 18, 3, 5, "topic", "", false, false], [20, 20, 3, 5, "topic", "", false, false], [34, 34, 3, 5, "topic", "", false, false], [36, 36, 3, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "field", "of", "spoken", "dialogue", "systems", "is", "quite", "broad", "and", "includes", "research", "(", "with", "scientific", "conferences", "such", "as", "SIGdial", "and", "Interspeech", ")", "and", "a", "large", "industrial", "sector", "(", "with", "its", "own", "meetings", "such", "as", "SpeechTek", "and", "AVIOS", ")", "."], "sentence-detokenized": "The field of spoken dialogue systems is quite broad and includes research (with scientific conferences such as SIGdial and Interspeech) and a large industrial sector (with its own meetings such as SpeechTek and AVIOS).", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 28], [29, 36], [37, 39], [40, 45], [46, 51], [52, 55], [56, 64], [65, 73], [74, 75], [75, 79], [80, 90], [91, 102], [103, 107], [108, 110], [111, 118], [119, 122], [123, 134], [134, 135], [136, 139], [140, 141], [142, 147], [148, 158], [159, 165], [166, 167], [167, 171], [172, 175], [176, 179], [180, 188], [189, 193], [194, 196], [197, 206], [207, 210], [211, 216], [216, 217], [217, 218]]}
{"doc_key": "ai-dev-197", "ner": [[2, 4, "field"], [7, 8, "task"], [12, 12, "task"], [14, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 2, 4, "part-of", "task_part_of_field", false, false], [12, 12, 2, 4, "part-of", "task_part_of_field", false, false], [14, 16, 2, 4, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Challenges", "in", "natural", "language", "processing", "often", "include", "speech", "recognition", ",", "natural", "language", "understanding", "and", "natural", "language", "generation", "."], "sentence-detokenized": "Challenges in natural language processing often include speech recognition, natural language understanding and natural language generation.", "token2charspan": [[0, 10], [11, 13], [14, 21], [22, 30], [31, 41], [42, 47], [48, 55], [56, 62], [63, 74], [74, 75], [76, 83], [84, 92], [93, 106], [107, 110], [111, 118], [119, 127], [128, 138], [138, 139]]}
{"doc_key": "ai-dev-198", "ner": [[5, 5, "product"], [5, 10, "product"], [16, 39, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 5, 10, "part-of", "", false, false], [5, 5, 16, 39, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "such", "as", "Siri", "of", "the", "iOS", "operating", "system", ",", "work", "with", "a", "pattern", "recognition", "technique", "similar", "to", "that", "of", "text", "-", "based", "systems", ",", "but", "in", "the", "former", ",", "user", "input", "is", "carried", "out", "through", "speech", "recognition", "."], "sentence-detokenized": "These systems, such as Siri of the iOS operating system, work with a pattern recognition technique similar to that of text-based systems, but in the former, user input is carried out through speech recognition.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 22], [23, 27], [28, 30], [31, 34], [35, 38], [39, 48], [49, 55], [55, 56], [57, 61], [62, 66], [67, 68], [69, 76], [77, 88], [89, 98], [99, 106], [107, 109], [110, 114], [115, 117], [118, 122], [122, 123], [123, 128], [129, 136], [136, 137], [138, 141], [142, 144], [145, 148], [149, 155], [155, 156], [157, 161], [162, 167], [168, 170], [171, 178], [179, 182], [183, 190], [191, 197], [198, 209], [209, 210]]}
{"doc_key": "ai-dev-199", "ner": [[1, 3, "algorithm"], [12, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 3, 12, 14, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["More", "exotic", "fitness", "functions", "that", "investigate", "model", "granularity", "include", "the", "area", "under", "the", "ROC", "curve", "and", "the", "rank", "measure", "."], "sentence-detokenized": "More exotic fitness functions that investigate model granularity include the area under the ROC curve and the rank measure.", "token2charspan": [[0, 4], [5, 11], [12, 19], [20, 29], [30, 34], [35, 46], [47, 52], [53, 64], [65, 72], [73, 76], [77, 81], [82, 87], [88, 91], [92, 95], [96, 101], [102, 105], [106, 109], [110, 114], [115, 122], [122, 123]]}
{"doc_key": "ai-dev-200", "ner": [[2, 3, "product"], [7, 10, "researcher"], [14, 17, "product"], [25, 25, "organisation"], [27, 27, "organisation"], [38, 38, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 7, 10, "origin", "", false, false], [7, 10, 25, 25, "role", "", false, false], [14, 17, 7, 10, "origin", "", false, false], [27, 27, 25, 25, "named", "", false, false], [38, 38, 25, 25, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "term", "Semantic", "Web", "was", "coined", "by", "Tim", "Berners", "-", "Lee", ",", "inventor", "of", "the", "World", "Wide", "Web", "and", "director", "of", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "which", "oversees", "the", "development", "of", "proposed", "Semantic", "Web", "standards", "."], "sentence-detokenized": "The term Semantic Web was coined by Tim Berners-Lee, inventor of the World Wide Web and director of the World Wide Web Consortium (W3C), which oversees the development of proposed Semantic Web standards.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 25], [26, 32], [33, 35], [36, 39], [40, 47], [47, 48], [48, 51], [51, 52], [53, 61], [62, 64], [65, 68], [69, 74], [75, 79], [80, 83], [84, 87], [88, 96], [97, 99], [100, 103], [104, 109], [110, 114], [115, 118], [119, 129], [130, 131], [131, 134], [134, 135], [135, 136], [137, 142], [143, 151], [152, 155], [156, 167], [168, 170], [171, 179], [180, 188], [189, 192], [193, 202], [202, 203]]}
{"doc_key": "ai-dev-201", "ner": [[0, 1, "task"], [5, 5, "task"], [12, 13, "product"], [15, 19, "product"], [21, 21, "product"], [24, 25, "product"], [32, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 12, 13, "opposite", "", false, false], [0, 1, 15, 19, "opposite", "", false, false], [0, 1, 24, 25, "opposite", "", false, false], [0, 1, 32, 33, "part-of", "", false, false], [5, 5, 0, 1, "named", "", false, false], [21, 21, 15, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Machine", "translation", ",", "sometimes", "abbreviated", "MT", "(", "not", "to", "be", "confused", "with", "computer-assisted", "translation", ",", "machine", "-", "assisted", "human", "translation", "(", "MAHT", ")", "or", "interactive", "translation", ")", ",", "is", "a", "subfield", "of", "computational", "linguistics", "that", "investigates", "the", "use", "of", "software", "to", "translate", "text", "or", "speech", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Machine translation, sometimes abbreviated MT (not to be confused with computer-assisted translation, machine-assisted human translation (MAHT) or interactive translation), is a subfield of computational linguistics that investigates the use of software to translate text or speech from one language to another.", "token2charspan": [[0, 7], [8, 19], [19, 20], [21, 30], [31, 42], [43, 45], [46, 47], [47, 50], [51, 53], [54, 56], [57, 65], [66, 70], [71, 88], [89, 100], [100, 101], [102, 109], [109, 110], [110, 118], [119, 124], [125, 136], [137, 138], [138, 142], [142, 143], [144, 146], [147, 158], [159, 170], [170, 171], [171, 172], [173, 175], [176, 177], [178, 186], [187, 189], [190, 203], [204, 215], [216, 220], [221, 233], [234, 237], [238, 241], [242, 244], [245, 253], [254, 256], [257, 266], [267, 271], [272, 274], [275, 281], [282, 286], [287, 290], [291, 299], [300, 302], [303, 310], [310, 311]]}
{"doc_key": "ai-dev-202", "ner": [[2, 6, "product"], [15, 16, "university"], [10, 11, "researcher"], [13, 14, "researcher"], [44, 45, "location"], [51, 56, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6], "relations": [[2, 6, 10, 11, "artifact", "", false, false], [2, 6, 13, 14, "artifact", "", false, false], [10, 11, 15, 16, "physical", "", false, false], [10, 11, 15, 16, "role", "", false, false], [13, 14, 15, 16, "physical", "", false, false], [13, 14, 15, 16, "role", "", false, false], [51, 56, 44, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 7], "sentence": ["The", "first", "cross", "-language", "MT", "systems", "were", "also", "built", "by", "Roger", "Schank", "and", "Yorick", "Wilks", "at", "Stanford", "in", "the", "1970s", ";", "the", "former", "became", "the", "basis", "of", "a", "commercial", "system", "for", "transferring", "funds", ",", "and", "the", "code", "for", "the", "latter", "is", "preserved", "in", "the", "Computer", "Museum", "in", "Boston", "as", "the", "first", "cross", "-", "language", "machine", "translation", "system", "."], "sentence-detokenized": "The first cross-language MT systems were also built by Roger Schank and Yorick Wilks at Stanford in the 1970s; the former became the basis of a commercial system for transferring funds, and the code for the latter is preserved in the Computer Museum in Boston as the first cross-language machine translation system.", "token2charspan": [[0, 3], [4, 9], [10, 15], [15, 24], [25, 27], [28, 35], [36, 40], [41, 45], [46, 51], [52, 54], [55, 60], [61, 67], [68, 71], [72, 78], [79, 84], [85, 87], [88, 96], [97, 99], [100, 103], [104, 109], [109, 110], [111, 114], [115, 121], [122, 128], [129, 132], [133, 138], [139, 141], [142, 143], [144, 154], [155, 161], [162, 165], [166, 178], [179, 184], [184, 185], [186, 189], [190, 193], [194, 198], [199, 202], [203, 206], [207, 213], [214, 216], [217, 226], [227, 229], [230, 233], [234, 242], [243, 249], [250, 252], [253, 259], [260, 262], [263, 266], [267, 272], [273, 278], [278, 279], [279, 287], [288, 295], [296, 307], [308, 314], [314, 315]]}
{"doc_key": "ai-dev-203", "ner": [[0, 3, "researcher"], [8, 12, "conference"], [14, 15, "conference"], [22, 27, "conference"], [30, 30, "conference"], [33, 39, "organisation"], [43, 44, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 8, 12, "role", "", false, false], [0, 3, 22, 27, "role", "", false, false], [0, 3, 33, 39, "role", "", false, false], [0, 3, 43, 44, "role", "", false, false], [14, 15, 8, 12, "named", "", false, false], [30, 30, 22, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sycara", "has", "served", "as", "programme", "chair", "of", "the", "Second", "International", "Semantic", "Web", "Conference", "(", "ISWC", "2003", ")", ";", "general", "chair", "of", "the", "Second", "International", "Conference", "on", "Autonomous", "Agents", "(", "Agents", "98", ")", ";", "chair", "of", "the", "Agents", "Conference", "Steering", "Committee", "(", "1999-2001", ")", ";", "AAAI", "scholarship", "chair", "(", "1993-1999", ")", ";"], "sentence-detokenized": "Sycara has served as programme chair of the Second International Semantic Web Conference (ISWC 2003); general chair of the Second International Conference on Autonomous Agents (Agents 98); chair of the Agents Conference Steering Committee (1999-2001); AAAI scholarship chair (1993-1999);", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 20], [21, 30], [31, 36], [37, 39], [40, 43], [44, 50], [51, 64], [65, 73], [74, 77], [78, 88], [89, 90], [90, 94], [95, 99], [99, 100], [100, 101], [102, 109], [110, 115], [116, 118], [119, 122], [123, 129], [130, 143], [144, 154], [155, 157], [158, 168], [169, 175], [176, 177], [177, 183], [184, 186], [186, 187], [187, 188], [189, 194], [195, 197], [198, 201], [202, 208], [209, 219], [220, 228], [229, 238], [239, 240], [240, 249], [249, 250], [250, 251], [252, 256], [257, 268], [269, 274], [275, 276], [276, 285], [285, 286], [286, 287]]}
{"doc_key": "ai-dev-204", "ner": [[11, 11, "conference"], [13, 16, "conference"], [18, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 16, 11, 11, "named", "", false, false], [18, 20, 11, 11, "part-of", "", false, false], [18, 20, 11, 11, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2016", ",", "he", "was", "selected", "as", "the", "recipient", "of", "the", "ACL", "(", "Association", "for", "Computational", "Linguistics", ")", "Lifetime", "Achievement", "Award", "."], "sentence-detokenized": "In 2016, he was selected as the recipient of the ACL (Association for Computational Linguistics) Lifetime Achievement Award.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 24], [25, 27], [28, 31], [32, 41], [42, 44], [45, 48], [49, 52], [53, 54], [54, 65], [66, 69], [70, 83], [84, 95], [95, 96], [97, 105], [106, 117], [118, 123], [123, 124]]}
{"doc_key": "ai-dev-205", "ner": [[0, 1, "researcher"], [3, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", ",", "Y", ".", "Bengio", ",", "P.", "Frasconi", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Sepp Hochreiter, Y. Bengio, P. Frasconi and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 15], [15, 16], [17, 18], [18, 19], [20, 26], [26, 27], [28, 30], [31, 39], [40, 43], [44, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-206", "ner": [[3, 17, "product"], [6, 7, "misc"], [9, 9, "programlang"], [18, 19, "product"], [31, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 17, 9, 9, "usage", "", false, false], [9, 9, 6, 7, "type-of", "", false, false], [9, 9, 18, 19, "related-to", "", false, false], [31, 31, 3, 17, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["For", "example", ",", "A.L.I.C.E.", "uses", "a", "markup", "language", "called", "AIML", "that", "is", "specific", "to", "its", "function", "as", "a", "dialogue", "system", ",", "and", "has", "since", "been", "adopted", "by", "various", "other", "developers", "called", "Alicebot", "."], "sentence-detokenized": "For example, A.L.I.C.E. uses a markup language called AIML that is specific to its function as a dialogue system, and has since been adopted by various other developers called Alicebot.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 23], [24, 28], [29, 30], [31, 37], [38, 46], [47, 53], [54, 58], [59, 63], [64, 66], [67, 75], [76, 78], [79, 82], [83, 91], [92, 94], [95, 96], [97, 105], [106, 112], [112, 113], [114, 117], [118, 121], [122, 127], [128, 132], [133, 140], [141, 143], [144, 151], [152, 157], [158, 168], [169, 175], [176, 184], [184, 185]]}
{"doc_key": "ai-dev-207", "ner": [[8, 17, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2000", ",", "he", "was", "elected", "as", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2000, he was elected as a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 28], [29, 35], [36, 38], [39, 42], [43, 54], [55, 58], [59, 62], [63, 74], [75, 77], [78, 88], [89, 101], [101, 102]]}
{"doc_key": "ai-dev-208", "ner": [[0, 2, "misc"], [4, 4, "misc"], [10, 14, "misc"], [15, 25, "algorithm"], [33, 34, "field"], [36, 37, "field"], [39, 40, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 10, 14, "type-of", "", false, false], [0, 2, 33, 34, "related-to", "performs", true, false], [0, 2, 36, 37, "related-to", "performs", true, false], [0, 2, 39, 40, "related-to", "performs", true, false], [4, 4, 0, 2, "named", "", false, false], [15, 25, 10, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Learning", "classifier", "systems", "(", "LCS", ")", "are", "a", "family", "of", "rule", "-", "based", "machine", "learning", "algorithms", "that", "combine", "a", "discovery", "component", ",", "typically", "a", "genetic", "algorithm", ",", "with", "a", "learning", "component", "that", "performs", "supervised", "learning", ",", "reinforcement", "learning", "or", "unsupervised", "learning", "."], "sentence-detokenized": "Learning classifier systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, typically a genetic algorithm, with a learning component that performs supervised learning, reinforcement learning or unsupervised learning.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 29], [29, 32], [32, 33], [34, 37], [38, 39], [40, 46], [47, 49], [50, 54], [54, 55], [55, 60], [61, 68], [69, 77], [78, 88], [89, 93], [94, 101], [102, 103], [104, 113], [114, 123], [123, 124], [125, 134], [135, 136], [137, 144], [145, 154], [154, 155], [156, 160], [161, 162], [163, 171], [172, 181], [182, 186], [187, 195], [196, 206], [207, 215], [215, 216], [217, 230], [231, 239], [240, 242], [243, 255], [256, 264], [264, 265]]}
{"doc_key": "ai-dev-209", "ner": [[15, 16, "algorithm"], [18, 18, "algorithm"], [24, 28, "algorithm"], [31, 32, "misc"], [41, 58, "algorithm"], [51, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[15, 16, 24, 28, "origin", "", false, false], [15, 16, 31, 32, "usage", "", false, false], [18, 18, 15, 16, "named", "", false, false], [41, 58, 31, 32, "type-of", "", false, false], [41, 58, 51, 55, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "unknown", "parameters", "in", "each", "\u03b2subk", "/", "sub", "vector", "are", "typically", "estimated", "together", "with", "maximum", "a", "posteriori", "(", "MAP", ")", "estimation", ",", "which", "is", "an", "extension", "of", "maximum", "likelihood", "using", "the", "regularisation", "of", "the", "weights", "to", "avoid", "pathological", "solutions", "(", "usually", "a", "quadratic", "regularisation", "function", ",", "which", "is", "equivalent", "to", "fitting", "a", "zero-mean", "Gaussian", "prior", "distribution", "to", "the", "weights", ",", "but", "other", "distributions", "are", "also", "possible", ")", "."], "sentence-detokenized": "The unknown parameters in each \u03b2subk/sub vector are typically estimated together with maximum a posteriori (MAP) estimation, which is an extension of maximum likelihood using the regularisation of the weights to avoid pathological solutions (usually a quadratic regularisation function, which is equivalent to fitting a zero-mean Gaussian prior distribution to the weights, but other distributions are also possible).", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 25], [26, 30], [31, 36], [36, 37], [37, 40], [41, 47], [48, 51], [52, 61], [62, 71], [72, 80], [81, 85], [86, 93], [94, 95], [96, 106], [107, 108], [108, 111], [111, 112], [113, 123], [123, 124], [125, 130], [131, 133], [134, 136], [137, 146], [147, 149], [150, 157], [158, 168], [169, 174], [175, 178], [179, 193], [194, 196], [197, 200], [201, 208], [209, 211], [212, 217], [218, 230], [231, 240], [241, 242], [242, 249], [250, 251], [252, 261], [262, 276], [277, 285], [285, 286], [287, 292], [293, 295], [296, 306], [307, 309], [310, 317], [318, 319], [320, 329], [330, 338], [339, 344], [345, 357], [358, 360], [361, 364], [365, 372], [372, 373], [374, 377], [378, 383], [384, 397], [398, 401], [402, 406], [407, 415], [415, 416], [416, 417]]}
{"doc_key": "ai-dev-210", "ner": [[9, 9, "researcher"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 9, 9, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "hierarchical", "structure", "of", "words", "is", "clearly", "mapped", "in", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "The hierarchical structure of words is clearly mapped in George Miller's Wordnet.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 29], [30, 35], [36, 38], [39, 46], [47, 53], [54, 56], [57, 63], [64, 70], [70, 72], [73, 80], [80, 81]]}
{"doc_key": "ai-dev-211", "ner": [[0, 7, "conference"], [12, 14, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 14, 0, 7, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Competition", "is", "a", "benchmark", "in", "object", "classification", "and", "detection", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "The ImageNet Large Scale Visual Recognition Competition is a benchmark in object classification and detection with millions of images and hundreds of object classes.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 24], [25, 31], [32, 43], [44, 55], [56, 58], [59, 60], [61, 70], [71, 73], [74, 80], [81, 95], [96, 99], [100, 109], [110, 114], [115, 123], [124, 126], [127, 133], [134, 137], [138, 146], [147, 149], [150, 156], [157, 164], [164, 165]]}
{"doc_key": "ai-dev-212", "ner": [[0, 2, "misc"], [32, 32, "misc"], [41, 43, "person"], [36, 36, "misc"], [55, 57, "person"], [48, 50, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[32, 32, 0, 2, "general-affiliation", "", false, false], [36, 36, 0, 2, "general-affiliation", "", false, false], [36, 36, 41, 43, "artifact", "", false, false], [48, 50, 0, 2, "general-affiliation", "", false, false], [48, 50, 55, 57, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "science", "fiction", ",", "female", "-", "looking", "robots", "are", "often", "produced", "for", "use", "as", "domestic", "servants", "and", "sexual", "slaves", ",", "sometimes", "as", "warriors", ",", "murderers", "or", "labourers", ",", "as", "in", "the", "film", "Westworld", ",", "the", "novel", "Fairyland", "(", "1995", ")", "by", "Paul", "J.", "McAuley", "and", "the", "short", "story", "Helen", "O'", "Loy", "(", "1938", ")", "by", "Lester", "del", "Rey", "."], "sentence-detokenized": "In science fiction, female-looking robots are often produced for use as domestic servants and sexual slaves, sometimes as warriors, murderers or labourers, as in the film Westworld, the novel Fairyland (1995) by Paul J. McAuley and the short story Helen O'Loy (1938) by Lester del Rey.", "token2charspan": [[0, 2], [3, 10], [11, 18], [18, 19], [20, 26], [26, 27], [27, 34], [35, 41], [42, 45], [46, 51], [52, 60], [61, 64], [65, 68], [69, 71], [72, 80], [81, 89], [90, 93], [94, 100], [101, 107], [107, 108], [109, 118], [119, 121], [122, 130], [130, 131], [132, 141], [142, 144], [145, 154], [154, 155], [156, 158], [159, 161], [162, 165], [166, 170], [171, 180], [180, 181], [182, 185], [186, 191], [192, 201], [202, 203], [203, 207], [207, 208], [209, 211], [212, 216], [217, 219], [220, 227], [228, 231], [232, 235], [236, 241], [242, 247], [248, 253], [254, 256], [256, 259], [260, 261], [261, 265], [265, 266], [267, 269], [270, 276], [277, 280], [281, 284], [284, 285]]}
{"doc_key": "ai-dev-213", "ner": [[0, 1, "task"], [3, 4, "task"], [6, 7, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["question", "answering", ",", "speech", "recognition", "and", "machine", "translation", "."], "sentence-detokenized": "question answering, speech recognition and machine translation.", "token2charspan": [[0, 8], [9, 18], [18, 19], [20, 26], [27, 38], [39, 42], [43, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-214", "ner": [[0, 6, "researcher"], [7, 13, "organisation"], [14, 19, "location"], [20, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 6, 7, 13, "role", "", false, false], [7, 13, 14, 19, "physical", "", false, false], [14, 19, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "his", "seminal", "paper", ",", "Harry", "Blum", "of", "the", "Air", "Force", "Cambridge", "Research", "Laboratories", "at", "Hanscom", "Air", "Force", "Base", "in", "Bedford", ",", "Massachusetts", ",", "defined", "a", "medial", "axis", "to", "calculate", "the", "skeleton", "of", "a", "shape", "using", "a", "heuristic", "model", "of", "fire", "spread", "on", "a", "grass", "field", "where", "the", "field", "has", "the", "given", "shape", "."], "sentence-detokenized": "In his seminal paper, Harry Blum of the Air Force Cambridge Research Laboratories at Hanscom Air Force Base in Bedford, Massachusetts, defined a medial axis to calculate the skeleton of a shape using a heuristic model of fire spread on a grass field where the field has the given shape.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 20], [20, 21], [22, 27], [28, 32], [33, 35], [36, 39], [40, 43], [44, 49], [50, 59], [60, 68], [69, 81], [82, 84], [85, 92], [93, 96], [97, 102], [103, 107], [108, 110], [111, 118], [118, 119], [120, 133], [133, 134], [135, 142], [143, 144], [145, 151], [152, 156], [157, 159], [160, 169], [170, 173], [174, 182], [183, 185], [186, 187], [188, 193], [194, 199], [200, 201], [202, 211], [212, 217], [218, 220], [221, 225], [226, 232], [233, 235], [236, 237], [238, 243], [244, 249], [250, 255], [256, 259], [260, 265], [266, 269], [270, 273], [274, 279], [280, 285], [285, 286]]}
{"doc_key": "ai-dev-215", "ner": [[14, 14, "algorithm"], [4, 16, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 19, 20, "compare", "", false, false], [4, 16, 19, 20, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "unlike", "boost", "algorithms", "that", "analytically", "minimise", "a", "convex", "loss", "function", "(", "e.g.", "AdaBoost", "and", "LogitBoost", ")", ",", "Brown", "Boost", "solves", "a", "system", "of", "two", "equations", "and", "two", "unknowns", "using", "standard", "numerical", "methods", "."], "sentence-detokenized": "However, unlike boost algorithms that analytically minimise a convex loss function (e.g. AdaBoost and LogitBoost), BrownBoost solves a system of two equations and two unknowns using standard numerical methods.", "token2charspan": [[0, 7], [7, 8], [9, 15], [16, 21], [22, 32], [33, 37], [38, 50], [51, 59], [60, 61], [62, 68], [69, 73], [74, 82], [83, 84], [84, 88], [89, 97], [98, 101], [102, 112], [112, 113], [113, 114], [115, 120], [120, 125], [126, 132], [133, 134], [135, 141], [142, 144], [145, 148], [149, 158], [159, 162], [163, 166], [167, 175], [176, 181], [182, 190], [191, 200], [201, 208], [208, 209]]}
{"doc_key": "ai-dev-216", "ner": [[0, 1, "researcher"], [8, 10, "misc"], [18, 24, "conference"], [26, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 8, 10, "win-defeat", "", false, false], [0, 1, 18, 24, "role", "", false, false], [26, 26, 18, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Getoor", "has", "received", "numerous", "best", "paper", "awards", ",", "NSF", "Career", "Awards", ",", "and", "is", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Getoor has received numerous best paper awards, NSF Career Awards, and is a Fellow of the Association for the Advancement of Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 28], [29, 33], [34, 39], [40, 46], [46, 47], [48, 51], [52, 58], [59, 65], [65, 66], [67, 70], [71, 73], [74, 75], [76, 82], [83, 85], [86, 89], [90, 101], [102, 105], [106, 109], [110, 121], [122, 124], [125, 135], [136, 148], [149, 150], [150, 154], [154, 155], [155, 156]]}
{"doc_key": "ai-dev-217", "ner": [[0, 1, "misc"], [6, 10, "misc"], [15, 16, "misc"], [21, 25, "misc"], [30, 31, "misc"], [35, 39, "university"], [44, 52, "misc"], [57, 67, "misc"], [70, 74, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["ACM", "Fellow", "(", "2015", ")", "br", "Association", "for", "Computational", "Linguistics", "Fellow", "(", "2011", ")", "br", "AAAI", "Fellow", "(", "1994", ")", "br", "International", "Speech", "Communication", "Association", "Fellow", "(", "2011", ")", "br", "Honorary", "Doctorate", "(", "Hedersdoktor", ")", "KTH", "Royal", "Institute", "of", "Technology", "(", "2007", ")", "br", "Columbia", "Engineering", "School", "Alumni", "Association", "Distinguished", "Faculty", "Teaching", "award", "(", "2009", ")", "br", "IEEE", "James", "L.", "Flanagan", "Speech", "and", "Audio", "Processing", "Award", "(", "2011", ")", "br", "ISCA", "Medal", "for", "Scientific", "Achievement", "(", "2011", ")"], "sentence-detokenized": "ACM Fellow (2015) br Association for Computational Linguistics Fellow (2011) br AAAI Fellow (1994) br International Speech Communication Association Fellow (2011) br Honorary Doctorate (Hedersdoktor) KTH Royal Institute of Technology (2007) br Columbia Engineering School Alumni Association Distinguished Faculty Teaching award (2009) br IEEE James L. Flanagan Speech and Audio Processing Award (2011) br ISCA Medal for Scientific Achievement (2011)", "token2charspan": [[0, 3], [4, 10], [11, 12], [12, 16], [16, 17], [18, 20], [21, 32], [33, 36], [37, 50], [51, 62], [63, 69], [70, 71], [71, 75], [75, 76], [77, 79], [80, 84], [85, 91], [92, 93], [93, 97], [97, 98], [99, 101], [102, 115], [116, 122], [123, 136], [137, 148], [149, 155], [156, 157], [157, 161], [161, 162], [163, 165], [166, 174], [175, 184], [185, 186], [186, 198], [198, 199], [200, 203], [204, 209], [210, 219], [220, 222], [223, 233], [234, 235], [235, 239], [239, 240], [241, 243], [244, 252], [253, 264], [265, 271], [272, 278], [279, 290], [291, 304], [305, 312], [313, 321], [322, 327], [328, 329], [329, 333], [333, 334], [335, 337], [338, 342], [343, 348], [349, 351], [352, 360], [361, 367], [368, 371], [372, 377], [378, 388], [389, 394], [395, 396], [396, 400], [400, 401], [402, 404], [405, 409], [410, 415], [416, 419], [420, 430], [431, 442], [443, 444], [444, 448], [448, 449]]}
{"doc_key": "ai-dev-218", "ner": [[8, 8, "university"], [15, 17, "task"], [36, 38, "metrics"], [25, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[36, 38, 25, 28, "opposite", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["A", "frustrating", "consequence", "of", "the", "same", "study", "by", "Stanford", "(", "and", "other", "attempts", "to", "improve", "name", "recognition", "translation", ")", "is", "that", "the", "inclusion", "of", "methods", "for", "named", "entity", "translation", "often", "results", "in", "a", "drop", "in", "the", "Bilingual", "evaluation", "reserve", "scores", "for", "translation", "."], "sentence-detokenized": "A frustrating consequence of the same study by Stanford (and other attempts to improve name recognition translation) is that the inclusion of methods for named entity translation often results in a drop in the Bilingual evaluation reserve scores for translation.", "token2charspan": [[0, 1], [2, 13], [14, 25], [26, 28], [29, 32], [33, 37], [38, 43], [44, 46], [47, 55], [56, 57], [57, 60], [61, 66], [67, 75], [76, 78], [79, 86], [87, 91], [92, 103], [104, 115], [115, 116], [117, 119], [120, 124], [125, 128], [129, 138], [139, 141], [142, 149], [150, 153], [154, 159], [160, 166], [167, 178], [179, 184], [185, 192], [193, 195], [196, 197], [198, 202], [203, 205], [206, 209], [210, 219], [220, 230], [231, 238], [239, 245], [246, 249], [250, 261], [261, 262]]}
{"doc_key": "ai-dev-219", "ner": [[0, 0, "organisation"], [12, 14, "organisation"], [16, 20, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 12, 14, "role", "works_with", false, false], [0, 0, 16, 20, "role", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Medtronic", "is", "using", "the", "PM", "data", "collected", "and", "working", "with", "researchers", "at", "Johns", "Hopkins", "Hospital", "and", "Washington", "University", "School", "of", "Medicine", "to", "help", "answer", "specific", "questions", "about", "heart", "disease", ",", "such", "as", "whether", "weak", "hearts", "cause", "arrhythmias", "or", "vice", "versa", "."], "sentence-detokenized": "Medtronic is using the PM data collected and working with researchers at Johns Hopkins Hospital and Washington University School of Medicine to help answer specific questions about heart disease, such as whether weak hearts cause arrhythmias or vice versa.", "token2charspan": [[0, 9], [10, 12], [13, 18], [19, 22], [23, 25], [26, 30], [31, 40], [41, 44], [45, 52], [53, 57], [58, 69], [70, 72], [73, 78], [79, 86], [87, 95], [96, 99], [100, 110], [111, 121], [122, 128], [129, 131], [132, 140], [141, 143], [144, 148], [149, 155], [156, 164], [165, 174], [175, 180], [181, 186], [187, 194], [194, 195], [196, 200], [201, 203], [204, 211], [212, 216], [217, 223], [224, 229], [230, 241], [242, 244], [245, 249], [250, 255], [255, 256]]}
{"doc_key": "ai-dev-220", "ner": [[2, 2, "organisation"], [8, 8, "misc"], [10, 11, "person"], [8, 14, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 8, 2, 2, "artifact", "made_by_studio", false, false], [10, 11, 8, 8, "role", "", false, false], [8, 14, 8, 8, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Then", "came", "Paramount", "'s", "first", "feature", "film", ",", "Sangaree", "with", "Fernando", "Lamas", "and", "Arlene", "Dahl", "."], "sentence-detokenized": "Then came Paramount's first feature film, Sangaree with Fernando Lamas and Arlene Dahl.", "token2charspan": [[0, 4], [5, 9], [10, 19], [19, 21], [22, 27], [28, 35], [36, 40], [40, 41], [42, 50], [51, 55], [56, 64], [65, 70], [71, 74], [75, 81], [82, 86], [86, 87]]}
{"doc_key": "ai-dev-221", "ner": [[0, 0, "programlang"], [8, 10, "researcher"], [12, 13, "researcher"], [15, 16, "organisation"], [14, 19, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 10, "origin", "", false, false], [0, 0, 12, 13, "origin", "", false, false], [8, 10, 15, 16, "physical", "", false, false], [8, 10, 15, 16, "role", "", false, false], [12, 13, 14, 19, "physical", "", false, false], [12, 13, 14, 19, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["KRL", "is", "a", "knowledge", "representation", "language", "developed", "by", "Daniel", "G.", "Bobrow", "and", "Terry", "Winograd", "at", "Xerox", "PARC", "and", "Stanford", "University", "respectively", "."], "sentence-detokenized": "KRL is a knowledge representation language developed by Daniel G. Bobrow and Terry Winograd at Xerox PARC and Stanford University respectively.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 18], [19, 33], [34, 42], [43, 52], [53, 55], [56, 62], [63, 65], [66, 72], [73, 76], [77, 82], [83, 91], [92, 94], [95, 100], [101, 105], [106, 109], [110, 118], [119, 129], [130, 142], [142, 143]]}
{"doc_key": "ai-dev-222", "ner": [[25, 36, "conference"], [0, 1, "researcher"], [3, 4, "researcher"], [6, 8, "researcher"], [9, 12, "researcher"], [19, 20, "task"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[25, 36, 19, 20, "topic", "", true, false], [0, 1, 25, 36, "physical", "", false, false], [0, 1, 25, 36, "role", "", false, false], [0, 1, 25, 36, "temporal", "", false, false], [3, 4, 25, 36, "physical", "", false, false], [3, 4, 25, 36, "role", "", false, false], [3, 4, 25, 36, "temporal", "", false, false], [6, 8, 25, 36, "physical", "", false, false], [6, 8, 25, 36, "role", "", false, false], [6, 8, 25, 36, "temporal", "", false, false], [9, 12, 25, 36, "physical", "", false, false], [9, 12, 25, 36, "role", "", false, false], [9, 12, 25, 36, "temporal", "", false, false], [19, 20, 22, 24, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Qiang", "Zhu", ",", "Shai", "Avidan", ",", "Mei-Chen", "Yeh", "and", "Kwang", "-", "Ting", "Cheng", "presented", "an", "algorithm", "that", "significantly", "accelerates", "human", "detection", "using", "HOG", "descriptor", "methods", "at", "the", "IEEE", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "in", "2006", "."], "sentence-detokenized": "Qiang Zhu, Shai Avidan, Mei-Chen Yeh and Kwang-Ting Cheng presented an algorithm that significantly accelerates human detection using HOG descriptor methods at the IEEE Conference on Computer Vision and Pattern Recognition in 2006.", "token2charspan": [[0, 5], [6, 9], [9, 10], [11, 15], [16, 22], [22, 23], [24, 32], [33, 36], [37, 40], [41, 46], [46, 47], [47, 51], [52, 57], [58, 67], [68, 70], [71, 80], [81, 85], [86, 99], [100, 111], [112, 117], [118, 127], [128, 133], [134, 137], [138, 148], [149, 156], [157, 159], [160, 163], [164, 168], [169, 179], [180, 182], [183, 191], [192, 198], [199, 202], [203, 210], [211, 222], [223, 225], [226, 230], [230, 231]]}
{"doc_key": "ai-dev-223", "ner": [[0, 0, "researcher"], [6, 6, "conference"], [8, 12, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 6, "role", "", false, false], [0, 0, 8, 12, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hayes", "is", "a", "founding", "member", "of", "AAAI", "and", "the", "Association", "for", "Cognitive", "Science", "."], "sentence-detokenized": "Hayes is a founding member of AAAI and the Association for Cognitive Science.", "token2charspan": [[0, 5], [6, 8], [9, 10], [11, 19], [20, 26], [27, 29], [30, 34], [35, 38], [39, 42], [43, 54], [55, 58], [59, 68], [69, 76], [76, 77]]}
{"doc_key": "ai-dev-224", "ner": [[0, 1, "misc"], [5, 5, "field"], [7, 8, "field"], [10, 11, "field"], [13, 13, "field"], [15, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 34, "field"], [35, 37, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[0, 1, 5, 5, "part-of", "", false, false], [0, 1, 5, 5, "usage", "", false, false], [0, 1, 7, 8, "part-of", "", false, false], [0, 1, 7, 8, "usage", "", false, false], [0, 1, 10, 11, "part-of", "", false, false], [0, 1, 10, 11, "usage", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [0, 1, 13, 13, "usage", "", false, false], [0, 1, 15, 16, "part-of", "", false, false], [0, 1, 15, 16, "usage", "", false, false], [0, 1, 18, 19, "part-of", "", false, false], [0, 1, 18, 19, "usage", "", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 21, 22, "usage", "", false, false], [0, 1, 24, 24, "part-of", "", false, false], [0, 1, 24, 24, "usage", "", false, false], [0, 1, 26, 27, "part-of", "", false, false], [0, 1, 26, 27, "usage", "", false, false], [0, 1, 29, 29, "part-of", "", false, false], [0, 1, 29, 29, "usage", "", false, false], [0, 1, 31, 34, "part-of", "", false, false], [0, 1, 31, 34, "usage", "", false, false], [0, 1, 35, 37, "part-of", "", false, false], [0, 1, 35, 37, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "sentence": ["Time", "series", "are", "used", "in", "statistics", ",", "signal", "processing", ",", "pattern", "recognition", ",", "econometrics", ",", "mathematical", "finance", ",", "weather", "forecasting", ",", "earthquake", "prediction", ",", "electroencephalography", ",", "control", "engineering", ",", "astronomy", ",", "communications", "engineering", ",", "and", "applied", "science", "and", "engineering", ",", "which", "largely", "involve", "temporal", "measurements", "."], "sentence-detokenized": "Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, earthquake prediction, electroencephalography, control engineering, astronomy, communications engineering, and applied science and engineering, which largely involve temporal measurements.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 23], [24, 34], [34, 35], [36, 42], [43, 53], [53, 54], [55, 62], [63, 74], [74, 75], [76, 88], [88, 89], [90, 102], [103, 110], [110, 111], [112, 119], [120, 131], [131, 132], [133, 143], [144, 154], [154, 155], [156, 178], [178, 179], [180, 187], [188, 199], [199, 200], [201, 210], [210, 211], [212, 226], [227, 238], [238, 239], [240, 243], [244, 251], [252, 259], [260, 263], [264, 275], [275, 276], [277, 282], [283, 290], [291, 298], [299, 307], [308, 320], [320, 321]]}
{"doc_key": "ai-dev-225", "ner": [[13, 14, "metrics"], [34, 36, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "principle", ",", "exact", "recovery", "can", "be", "solved", "in", "the", "feasible", "range", "using", "maximum", "likelihood", ",", "but", "this", "implies", "solving", "a", "constrained", "or", "regular", "cut", "problem", "such", "as", "minimum", "bisimulation", ",", "which", "is", "typically", "NP", "-", "complete", "."], "sentence-detokenized": "In principle, exact recovery can be solved in the feasible range using maximum likelihood, but this implies solving a constrained or regular cut problem such as minimum bisimulation, which is typically NP-complete.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 19], [20, 28], [29, 32], [33, 35], [36, 42], [43, 45], [46, 49], [50, 58], [59, 64], [65, 70], [71, 78], [79, 89], [89, 90], [91, 94], [95, 99], [100, 107], [108, 115], [116, 117], [118, 129], [130, 132], [133, 140], [141, 144], [145, 152], [153, 157], [158, 160], [161, 168], [169, 181], [181, 182], [183, 188], [189, 191], [192, 201], [202, 204], [204, 205], [205, 213], [213, 214]]}
{"doc_key": "ai-dev-226", "ner": [[1, 2, "task"], [10, 11, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 1, 2, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "pedestrian", "detection", "studies", ",", "which", "were", "first", "announced", "at", "the", "BMVC", "in", "2009", "."], "sentence-detokenized": "In pedestrian detection studies, which were first announced at the BMVC in 2009.", "token2charspan": [[0, 2], [3, 13], [14, 23], [24, 31], [31, 32], [33, 38], [39, 43], [44, 49], [50, 59], [60, 62], [63, 66], [67, 71], [72, 74], [75, 79], [79, 80]]}
{"doc_key": "ai-dev-227", "ner": [[14, 22, "conference"], [4, 12, "misc"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Terzopoulos", "was", "awarded", "the", "first", "IEEE", "PAMI", "Computer", "Vision", "Distinguished", "Researcher", "Award", "in", "2007", "at", "the", "International", "Conference", "on", "Computer", "Vision", "for", "his", "pioneering", "and", "sustained", "research", "on", "deformable", "models", "and", "their", "applications", "."], "sentence-detokenized": "Terzopoulos was awarded the first IEEE PAMI Computer Vision Distinguished Researcher Award in 2007 at the International Conference on Computer Vision for his pioneering and sustained research on deformable models and their applications.", "token2charspan": [[0, 11], [12, 15], [16, 23], [24, 27], [28, 33], [34, 38], [39, 43], [44, 52], [53, 59], [60, 73], [74, 84], [85, 90], [91, 93], [94, 98], [99, 101], [102, 105], [106, 119], [120, 130], [131, 133], [134, 142], [143, 149], [150, 153], [154, 157], [158, 168], [169, 172], [173, 182], [183, 191], [192, 194], [195, 205], [206, 212], [213, 216], [217, 222], [223, 235], [235, 236]]}
{"doc_key": "ai-dev-228", "ner": [[0, 1, "task"], [4, 4, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 4, 4, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cluster", "analysis", "or", "cluster", "analysis", "involves", "assigning", "data", "points", "to", "clusters", "so", "that", "items", "belonging", "to", "the", "same", "cluster", "are", "as", "similar", "as", "possible", "and", "items", "belonging", "to", "different", "clusters", "are", "as", "different", "as", "possible", "."], "sentence-detokenized": "Cluster analysis or cluster analysis involves assigning data points to clusters so that items belonging to the same cluster are as similar as possible and items belonging to different clusters are as different as possible.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 36], [37, 45], [46, 55], [56, 60], [61, 67], [68, 70], [71, 79], [80, 82], [83, 87], [88, 93], [94, 103], [104, 106], [107, 110], [111, 115], [116, 123], [124, 127], [128, 130], [131, 138], [139, 141], [142, 150], [151, 154], [155, 160], [161, 170], [171, 173], [174, 183], [184, 192], [193, 196], [197, 199], [200, 209], [210, 212], [213, 221], [221, 222]]}
{"doc_key": "ai-dev-229", "ner": [[27, 46, "task"], [20, 22, "field"], [34, 35, "field"], [30, 31, "field"], [43, 44, "field"], [47, 47, "task"], [48, 49, "misc"]], "ner_mapping_to_source": [2, 3, 4, 5, 6, 7, 8], "relations": [[34, 35, 20, 22, "part-of", "", false, false], [43, 44, 30, 31, "part-of", "", false, false], [47, 47, 43, 44, "part-of", "", false, false], [48, 49, 43, 44, "part-of", "", false, false]], "relations_mapping_to_source": [4, 5, 6, 7], "sentence": ["Hotho", ",", "A.", ",", "N\u00fcrnberger", ",", "A.", "and", "Paa\u00df", ",", "G.", "(", "2005", ")", "we", "can", "distinguish", "three", "different", "perspectives", "of", "text", "mining", ":", "text", "mining", "as", "knowledge", "extraction", ",", "text", "mining", "as", "text", "data", "mining", "and", "text", "mining", "as", "a", "process", "of", "Data", "mining", "(", "Knowledge", "Discovery", "in", "Databases", ")", ".", "Hotho", ",", "A.", ",", "N\u00fcrnberger", ",", "A.", "and", "Paa\u00df", ",", "G.", "(", "2005", ")", "."], "sentence-detokenized": "Hotho, A., N\u00fcrnberger, A. and Paa\u00df, G. (2005) we can distinguish three different perspectives of text mining: text mining as knowledge extraction, text mining as text data mining and text mining as a process of Data mining (Knowledge Discovery in Databases).Hotho, A., N\u00fcrnberger, A. and Paa\u00df, G. (2005).", "token2charspan": [[0, 5], [5, 6], [7, 9], [9, 10], [11, 21], [21, 22], [23, 25], [26, 29], [30, 34], [34, 35], [36, 38], [39, 40], [40, 44], [44, 45], [46, 48], [49, 52], [53, 64], [65, 70], [71, 80], [81, 93], [94, 96], [97, 101], [102, 108], [108, 109], [110, 114], [115, 121], [122, 124], [125, 134], [135, 145], [145, 146], [147, 151], [152, 158], [159, 161], [162, 166], [167, 171], [172, 178], [179, 182], [183, 187], [188, 194], [195, 197], [198, 199], [200, 207], [208, 210], [211, 215], [216, 222], [223, 224], [224, 233], [234, 243], [244, 246], [247, 256], [256, 257], [257, 258], [258, 263], [263, 264], [265, 267], [267, 268], [269, 279], [279, 280], [281, 283], [284, 287], [288, 292], [292, 293], [294, 296], [297, 298], [298, 302], [302, 303], [303, 304]]}
{"doc_key": "ai-dev-230", "ner": [[0, 1, "product"], [13, 20, "location"], [22, 22, "location"], [24, 24, "location"], [34, 35, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 13, 20, "related-to", "developed_for", false, false], [13, 20, 22, 22, "physical", "", false, false], [22, 22, 24, 24, "physical", "", false, false], [34, 35, 0, 1, "role", "buys", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Rancho", "Arm", "was", "developed", "as", "a", "robotic", "arm", "to", "assist", "disabled", "patients", "at", "the", "Rancho", "Los", "Amigos", "National", "Rehabilitation", "Centre", "in", "Downey", ",", "California", ";", "the", "computer", "-", "controlled", "arm", "was", "purchased", "by", "Stanford", "University", "in", "1963", "."], "sentence-detokenized": "The Rancho Arm was developed as a robotic arm to assist disabled patients at the Rancho Los Amigos National Rehabilitation Centre in Downey, California; the computer-controlled arm was purchased by Stanford University in 1963.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 18], [19, 28], [29, 31], [32, 33], [34, 41], [42, 45], [46, 48], [49, 55], [56, 64], [65, 73], [74, 76], [77, 80], [81, 87], [88, 91], [92, 98], [99, 107], [108, 122], [123, 129], [130, 132], [133, 139], [139, 140], [141, 151], [151, 152], [153, 156], [157, 165], [165, 166], [166, 176], [177, 180], [181, 184], [185, 194], [195, 197], [198, 206], [207, 217], [218, 220], [221, 225], [225, 226]]}
{"doc_key": "ai-dev-231", "ner": [[13, 13, "university"], [8, 11, "organisation"], [33, 34, "organisation"], [21, 22, "researcher"], [24, 27, "researcher"], [44, 44, "university"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6], "relations": [[33, 34, 44, 44, "physical", "", false, false], [21, 22, 33, 34, "role", "founder", false, false], [24, 27, 33, 34, "role", "founder", false, false]], "relations_mapping_to_source": [4, 5, 6], "sentence": ["Norman", "was", "one", "of", "the", "founders", "of", "the", "Institute", "for", "Cognitive", "Science", "at", "UCSD", "and", "one", "of", "the", "organisers", "(", "with", "Roger", "Schank", ",", "Allan", "M.", "Collins", "and", "others", ")", "of", "the", "Cognitive", "Science", "Society", ",", "which", "held", "it", "s", "first", "meeting", "on", "the", "UCSD", "campus", "in", "1979", "."], "sentence-detokenized": "Norman was one of the founders of the Institute for Cognitive Science at UCSD and one of the organisers (with Roger Schank, Allan M. Collins and others) of the Cognitive Science Society, which held its first meeting on the UCSD campus in 1979.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 17], [18, 21], [22, 30], [31, 33], [34, 37], [38, 47], [48, 51], [52, 61], [62, 69], [70, 72], [73, 77], [78, 81], [82, 85], [86, 88], [89, 92], [93, 103], [104, 105], [105, 109], [110, 115], [116, 122], [122, 123], [124, 129], [130, 132], [133, 140], [141, 144], [145, 151], [151, 152], [153, 155], [156, 159], [160, 169], [170, 177], [178, 185], [185, 186], [187, 192], [193, 197], [198, 200], [200, 201], [202, 207], [208, 215], [216, 218], [219, 222], [223, 227], [228, 234], [235, 237], [238, 242], [242, 243]]}
{"doc_key": "ai-dev-232", "ner": [[7, 8, "product"], [10, 11, "product"], [13, 14, "product"], [16, 18, "product"], [20, 21, "product"], [23, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 21, 16, 18, "type-of", "", false, false], [23, 28, 16, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "commonly", "used", "robot", "configurations", "are", "articulated", "robots", ",", "SCARA", "robots", ",", "delta", "robots", "and", "Cartesian", "coordinate", "robots", "(", "gantry", "robots", "or", "x", "-", "y", "-", "z", "robots", ")", "."], "sentence-detokenized": "The most commonly used robot configurations are articulated robots, SCARA robots, delta robots and Cartesian coordinate robots (gantry robots or x-y-z robots).", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 28], [29, 43], [44, 47], [48, 59], [60, 66], [66, 67], [68, 73], [74, 80], [80, 81], [82, 87], [88, 94], [95, 98], [99, 108], [109, 119], [120, 126], [127, 128], [128, 134], [135, 141], [142, 144], [145, 146], [146, 147], [147, 148], [148, 149], [149, 150], [151, 157], [157, 158], [158, 159]]}
{"doc_key": "ai-dev-233", "ner": [[9, 9, "programlang"], [10, 11, "misc"], [16, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 9, 9, "part-of", "", false, false], [16, 16, 10, 11, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Alternatively", ",", "it", "can", "be", "used", "directly", "with", "the", "Perl", "Module", "TM", "(", "which", "also", "supports", "LTM", ")", "."], "sentence-detokenized": "Alternatively, it can be used directly with the Perl Module TM (which also supports LTM).", "token2charspan": [[0, 13], [13, 14], [15, 17], [18, 21], [22, 24], [25, 29], [30, 38], [39, 43], [44, 47], [48, 52], [53, 59], [60, 62], [63, 64], [64, 69], [70, 74], [75, 83], [84, 87], [87, 88], [88, 89]]}
{"doc_key": "ai-dev-234", "ner": [[6, 7, "country"], [10, 11, "organisation"], [16, 16, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 6, 7, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "competition", "was", "won", "by", "a", "United", "States", "team", "from", "Newton", "Labs", "and", "was", "shown", "on", "CNN", "."], "sentence-detokenized": "This competition was won by a United States team from Newton Labs and was shown on CNN.", "token2charspan": [[0, 4], [5, 16], [17, 20], [21, 24], [25, 27], [28, 29], [30, 36], [37, 43], [44, 48], [49, 53], [54, 60], [61, 65], [66, 69], [70, 73], [74, 79], [80, 82], [83, 86], [86, 87]]}
{"doc_key": "ai-dev-235", "ner": [[0, 10, "misc"], [11, 12, "person"], [15, 17, "person"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 12, 0, 10, "role", "directs", false, false], [15, 17, 0, 10, "role", "acts_in", false, false], [18, 19, 0, 10, "role", "acts_in", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Butler", "'s", "in", "Love", ",", "a", "short", "film", "directed", "by", "David", "Arquette", "and", "starring", "Elizabeth", "Berkley", "and", "Thomas", "Jane", ",", "was", "released", "on", "23", "June", "2008", "."], "sentence-detokenized": "The Butler's in Love, a short film directed by David Arquette and starring Elizabeth Berkley and Thomas Jane, was released on 23 June 2008.", "token2charspan": [[0, 3], [4, 10], [10, 12], [13, 15], [16, 20], [20, 21], [22, 23], [24, 29], [30, 34], [35, 43], [44, 46], [47, 52], [53, 61], [62, 65], [66, 74], [75, 84], [85, 92], [93, 96], [97, 103], [104, 108], [108, 109], [110, 113], [114, 122], [123, 125], [126, 128], [129, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-dev-236", "ner": [[3, 4, "product"], [10, 10, "field"], [17, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 17, 17, "general-affiliation", "", false, false], [10, 10, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "Word", "Net", "is", "a", "resource", "containing", "a", "taxonomy", "whose", "elements", "are", "the", "meanings", "of", "English", "words", "."], "sentence-detokenized": "For example, WordNet is a resource containing a taxonomy whose elements are the meanings of English words.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [17, 20], [21, 23], [24, 25], [26, 34], [35, 45], [46, 47], [48, 56], [57, 62], [63, 71], [72, 75], [76, 79], [80, 88], [89, 91], [92, 99], [100, 105], [105, 106]]}
{"doc_key": "ai-dev-237", "ner": [[1, 3, "product"], [7, 7, "product"], [9, 9, "product"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 1, 3, "type-of", "", false, false], [7, 7, 18, 19, "related-to", "ability_to", false, false], [9, 9, 1, 3, "type-of", "", false, false], [9, 9, 18, 19, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Current", "humanoid", "robot", "systems", ",", "such", "as", "ASIMO", "and", "QRIO", ",", "use", "a", "large", "number", "of", "motors", "to", "provide", "movement", "."], "sentence-detokenized": "Current humanoid robot systems, such as ASIMO and QRIO, use a large number of motors to provide movement.", "token2charspan": [[0, 7], [8, 16], [17, 22], [23, 30], [30, 31], [32, 36], [37, 39], [40, 45], [46, 49], [50, 54], [54, 55], [56, 59], [60, 61], [62, 67], [68, 74], [75, 77], [78, 84], [85, 87], [88, 95], [96, 104], [104, 105]]}
{"doc_key": "ai-dev-238", "ner": [[5, 6, "metrics"], [8, 8, "metrics"], [10, 14, "misc"], [16, 16, "metrics"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["LEPOR", "is", "designed", "with", "improved", "length", "penalty", ",", "precision", ",", "n-", "gram", "word", "order", "penalty", "and", "recall", "factors", "."], "sentence-detokenized": "LEPOR is designed with improved length penalty, precision, n-gram word order penalty and recall factors.", "token2charspan": [[0, 5], [6, 8], [9, 17], [18, 22], [23, 31], [32, 38], [39, 46], [46, 47], [48, 57], [57, 58], [59, 61], [61, 65], [66, 70], [71, 76], [77, 84], [85, 88], [89, 95], [96, 103], [103, 104]]}
{"doc_key": "ai-dev-239", "ner": [[0, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Bilingual", "assessment", "is", "based", "on", "the", "substitute", "metric", ",", "but", "with", "some", "modifications", "."], "sentence-detokenized": "The Bilingual assessment is based on the substitute metric, but with some modifications.", "token2charspan": [[0, 3], [4, 13], [14, 24], [25, 27], [28, 33], [34, 36], [37, 40], [41, 51], [52, 58], [58, 59], [60, 63], [64, 68], [69, 73], [74, 87], [87, 88]]}
{"doc_key": "ai-dev-240", "ner": [[6, 8, "product"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "application", "in", "MATLAB", "/", "Octave", ":"], "sentence-detokenized": "This is an example application in MATLAB/Octave:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 30], [31, 33], [34, 40], [40, 41], [41, 47], [47, 48]]}
{"doc_key": "ai-dev-241", "ner": [[0, 0, "programlang"], [13, 13, "programlang"], [15, 15, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Python", "is", "designed", "for", "use", "through", "a", "number", "of", "computer", "languages", ",", "including", "Ruby", "and", "Scheme", "."], "sentence-detokenized": "Python is designed for use through a number of computer languages, including Ruby and Scheme.", "token2charspan": [[0, 6], [7, 9], [10, 18], [19, 22], [23, 26], [27, 34], [35, 36], [37, 43], [44, 46], [47, 55], [56, 65], [65, 66], [67, 76], [77, 81], [82, 85], [86, 92], [92, 93]]}
{"doc_key": "ai-dev-242", "ner": [[0, 0, "researcher"], [6, 7, "organisation"], [13, 14, "conference"], [19, 20, "academicjournal"], [24, 27, "organisation"], [33, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 7, "role", "", false, false], [0, 0, 13, 14, "role", "", false, false], [0, 0, 19, 20, "role", "", false, false], [0, 0, 24, 27, "role", "", false, false], [0, 0, 33, 37, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hayes", "has", "served", "as", "secretary", "of", "the", "AISB", ",", "president", "and", "trustee", "of", "the", "IJCAI", ",", "associate", "editor", "of", "Artificial", "Intelligence", ",", "governor", "of", "the", "Cognitive", "Science", "Society", ",", "and", "president", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "."], "sentence-detokenized": "Hayes has served as secretary of the AISB, president and trustee of the IJCAI, associate editor of Artificial Intelligence, governor of the Cognitive Science Society, and president of the American Association for Artificial Intelligence.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 32], [33, 36], [37, 41], [41, 42], [43, 52], [53, 56], [57, 64], [65, 67], [68, 71], [72, 77], [77, 78], [79, 88], [89, 95], [96, 98], [99, 109], [110, 122], [122, 123], [124, 132], [133, 135], [136, 139], [140, 149], [150, 157], [158, 165], [165, 166], [167, 170], [171, 180], [181, 183], [184, 187], [188, 196], [197, 208], [209, 212], [213, 223], [224, 236], [236, 237]]}
{"doc_key": "ai-dev-243", "ner": [[4, 14, "misc"], [16, 18, "misc"], [23, 24, "person"], [26, 31, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 24, 4, 14, "role", "directed_by", false, false], [23, 24, 16, 18, "role", "directed_by", false, false], [23, 24, 26, 31, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "of", "these", ",", "Now", "is", "the", "Time", "(", "to", "Put", "On", "Your", "Glasses", ")", "and", "Around", "is", "Around", ",", "were", "directed", "by", "Norman", "McLaren", "for", "the", "National", "Film", "Board", "of", "Canada", "in", "1951", "."], "sentence-detokenized": "Two of these, Now is the Time (to Put On Your Glasses) and Around is Around, were directed by Norman McLaren for the National Film Board of Canada in 1951.", "token2charspan": [[0, 3], [4, 6], [7, 12], [12, 13], [14, 17], [18, 20], [21, 24], [25, 29], [30, 31], [31, 33], [34, 37], [38, 40], [41, 45], [46, 53], [53, 54], [55, 58], [59, 65], [66, 68], [69, 75], [75, 76], [77, 81], [82, 90], [91, 93], [94, 100], [101, 108], [109, 112], [113, 116], [117, 125], [126, 130], [131, 136], [137, 139], [140, 146], [147, 149], [150, 154], [154, 155]]}
{"doc_key": "ai-dev-244", "ner": [[1, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "recommender", "system", "aims", "to", "predict", "a", "target", "user", "'s", "preference", "for", "an", "item", "."], "sentence-detokenized": "A recommender system aims to predict a target user's preference for an item.", "token2charspan": [[0, 1], [2, 13], [14, 20], [21, 25], [26, 28], [29, 36], [37, 38], [39, 45], [46, 50], [50, 52], [53, 63], [64, 67], [68, 70], [71, 75], [75, 76]]}
{"doc_key": "ai-dev-245", "ner": [[0, 1, "algorithm"], [4, 4, "field"], [6, 6, "field"], [8, 9, "field"], [11, 13, "field"], [15, 15, "field"], [17, 18, "field"], [20, 21, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 1, 4, 4, "part-of", "", true, false], [0, 1, 6, 6, "part-of", "", true, false], [0, 1, 8, 9, "part-of", "", true, false], [0, 1, 11, 13, "part-of", "", true, false], [0, 1, 15, 15, "part-of", "", true, false], [0, 1, 17, 18, "part-of", "", true, false], [0, 1, 20, 21, "part-of", "", true, false], [0, 1, 22, 23, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Convolution", "has", "applications", "in", "probability", ",", "statistics", ",", "computer", "vision", ",", "natural", "language", "processing", ",", "image", "and", "signal", "processing", ",", "engineering", "and", "differential", "equations", "."], "sentence-detokenized": "Convolution has applications in probability, statistics, computer vision, natural language processing, image and signal processing, engineering and differential equations.", "token2charspan": [[0, 11], [12, 15], [16, 28], [29, 31], [32, 43], [43, 44], [45, 55], [55, 56], [57, 65], [66, 72], [72, 73], [74, 81], [82, 90], [91, 101], [101, 102], [103, 108], [109, 112], [113, 119], [120, 130], [130, 131], [132, 143], [144, 147], [148, 160], [161, 170], [170, 171]]}
{"doc_key": "ai-dev-246", "ner": [[0, 0, "field"], [3, 5, "task"], [7, 8, "task"], [10, 10, "task"], [11, 11, "task"], [12, 12, "task"], [14, 15, "task"], [17, 18, "task"], [20, 23, "task"], [26, 27, "task"], [29, 29, "field"], [31, 31, "field"], [33, 35, "field"], [37, 37, "field"], [39, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15], "relations": [[0, 0, 3, 5, "part-of", "", true, false], [0, 0, 7, 8, "part-of", "", true, false], [0, 0, 10, 10, "part-of", "", true, false], [0, 0, 11, 11, "part-of", "", true, false], [0, 0, 12, 12, "part-of", "", true, false], [0, 0, 14, 15, "part-of", "", true, false], [0, 0, 17, 18, "part-of", "", true, false], [0, 0, 20, 23, "part-of", "", true, false], [0, 0, 26, 27, "part-of", "", true, false], [0, 0, 29, 29, "part-of", "", true, false], [0, 0, 31, 31, "part-of", "", true, false], [0, 0, 33, 35, "part-of", "", true, false], [0, 0, 37, 37, "part-of", "", true, false], [0, 0, 39, 39, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14], "sentence": ["DSP", "applications", "include", "audio", "signal", "processing", ",", "audio", "compression", ",", "digital", "image", "processing", ",", "video", "compression", ",", "speech", "processing", ",", "speech", "recognition", ",", "digital", "communications", ",", "digital", "synthesizers", ",", "radar", ",", "sonar", ",", "financial", "signal", "processing", ",", "seismology", "and", "biomedicine", "."], "sentence-detokenized": "DSP applications include audio signal processing, audio compression, digital image processing, video compression, speech processing, speech recognition, digital communications, digital synthesizers, radar, sonar, financial signal processing, seismology and biomedicine.", "token2charspan": [[0, 3], [4, 16], [17, 24], [25, 30], [31, 37], [38, 48], [48, 49], [50, 55], [56, 67], [67, 68], [69, 76], [77, 82], [83, 93], [93, 94], [95, 100], [101, 112], [112, 113], [114, 120], [121, 131], [131, 132], [133, 139], [140, 151], [151, 152], [153, 160], [161, 175], [175, 176], [177, 184], [185, 197], [197, 198], [199, 204], [204, 205], [206, 211], [211, 212], [213, 222], [223, 229], [230, 240], [240, 241], [242, 252], [253, 256], [257, 268], [268, 269]]}
{"doc_key": "ai-dev-247", "ner": [[11, 23, "misc"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "20", "February", "1912", "-", "11", "August", "2011", ")", "was", "an", "American", "inventor", "best", "known", "for", "creating", "the", "first", "industrial", "robot", ",", "the", "Unimate", "."], "sentence-detokenized": "(20 February 1912 - 11 August 2011) was an American inventor best known for creating the first industrial robot, the Unimate.", "token2charspan": [[0, 1], [1, 3], [4, 12], [13, 17], [18, 19], [20, 22], [23, 29], [30, 34], [34, 35], [36, 39], [40, 42], [43, 51], [52, 60], [61, 65], [66, 71], [72, 75], [76, 84], [85, 88], [89, 94], [95, 105], [106, 111], [111, 112], [113, 116], [117, 124], [124, 125]]}
{"doc_key": "ai-dev-248", "ner": [[5, 7, "researcher"], [9, 13, "researcher"], [0, 0, "researcher"], [23, 27, "algorithm"], [30, 32, "algorithm"], [36, 37, "task"], [39, 46, "algorithm"], [47, 47, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[5, 7, 23, 27, "related-to", "writes_about", true, false], [9, 13, 23, 27, "related-to", "writes_about", true, false], [0, 0, 23, 27, "related-to", "writes_about", true, false], [23, 27, 30, 32, "related-to", "", true, false], [36, 37, 39, 46, "related-to", "", true, false], [47, 47, 39, 46, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", "was", "co-author", ",", "with", "David", "E.", "Rumelhart", "and", "Ronald", "J.", "Williams", ",", "of", "a", "highly", "cited", "paper", "published", "in", "1986", "that", "popularised", "the", "back", "-", "propagation", "algorithm", "for", "training", "multilayer", "neural", "networks", ",", "the", "dramatic", "image", "recognition", "landmark", "Alex", "Net", ",", "designed", "by", "his", "student", "Alex", "Krizhevsky", "{{", "cite", "web"], "sentence-detokenized": "Hinton was co-author, with David E. Rumelhart and Ronald J. Williams, of a highly cited paper published in 1986 that popularised the back-propagation algorithm for training multilayer neural networks, the dramatic image recognition landmark AlexNet, designed by his student Alex Krizhevsky {{cite web", "token2charspan": [[0, 6], [7, 10], [11, 20], [20, 21], [22, 26], [27, 32], [33, 35], [36, 45], [46, 49], [50, 56], [57, 59], [60, 68], [68, 69], [70, 72], [73, 74], [75, 81], [82, 87], [88, 93], [94, 103], [104, 106], [107, 111], [112, 116], [117, 128], [129, 132], [133, 137], [137, 138], [138, 149], [150, 159], [160, 163], [164, 172], [173, 183], [184, 190], [191, 199], [199, 200], [201, 204], [205, 213], [214, 219], [220, 231], [232, 240], [241, 245], [245, 248], [248, 249], [250, 258], [259, 261], [262, 265], [266, 273], [274, 278], [279, 289], [290, 292], [292, 296], [297, 300]]}
{"doc_key": "ai-dev-249", "ner": [[9, 11, "metrics"], [13, 16, "metrics"], [18, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "estimated", "value", "is", "continuously", "distributed", ",", "the", "mean", "squared", "error", ",", "root", "mean", "squared", "error", "or", "median", "absolute", "deviation", "can", "be", "used", "to", "summarise", "the", "errors", "."], "sentence-detokenized": "When the estimated value is continuously distributed, the mean squared error, root mean squared error or median absolute deviation can be used to summarise the errors.", "token2charspan": [[0, 4], [5, 8], [9, 18], [19, 24], [25, 27], [28, 40], [41, 52], [52, 53], [54, 57], [58, 62], [63, 70], [71, 76], [76, 77], [78, 82], [83, 87], [88, 95], [96, 101], [102, 104], [105, 111], [112, 120], [121, 130], [131, 134], [135, 137], [138, 142], [143, 145], [146, 155], [156, 159], [160, 166], [166, 167]]}
{"doc_key": "ai-dev-250", "ner": [[0, 1, "algorithm"], [10, 11, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 10, 11, "part-of", "", true, false], [0, 1, 14, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Conceptual", "clustering", "was", "originally", "developed", "in", "the", "1980s", "as", "a", "machine", "learning", "paradigm", "for", "unsupervised", "learning", "."], "sentence-detokenized": "Conceptual clustering was originally developed in the 1980s as a machine learning paradigm for unsupervised learning.", "token2charspan": [[0, 10], [11, 21], [22, 25], [26, 36], [37, 46], [47, 49], [50, 53], [54, 59], [60, 62], [63, 64], [65, 72], [73, 81], [82, 90], [91, 94], [95, 107], [108, 116], [116, 117]]}
{"doc_key": "ai-dev-251", "ner": [[8, 10, "product"], [28, 30, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "named", "entities", "can", "not", "be", "recognised", "by", "the", "machine", "translator", ",", "they", "may", "be", "erroneously", "translated", "as", "common", "names", ",", "which", "most", "likely", "does", "not", "affect", "the", "Bilingual", "evaluation", "backup", "rating", "of", "the", "translation", ",", "but", "changes", "the", "human", "readability", "of", "the", "text", "."], "sentence-detokenized": "If named entities cannot be recognised by the machine translator, they may be erroneously translated as common names, which most likely does not affect the Bilingual evaluation backup rating of the translation, but changes the human readability of the text.", "token2charspan": [[0, 2], [3, 8], [9, 17], [18, 21], [21, 24], [25, 27], [28, 38], [39, 41], [42, 45], [46, 53], [54, 64], [64, 65], [66, 70], [71, 74], [75, 77], [78, 89], [90, 100], [101, 103], [104, 110], [111, 116], [116, 117], [118, 123], [124, 128], [129, 135], [136, 140], [141, 144], [145, 151], [152, 155], [156, 165], [166, 176], [177, 183], [184, 190], [191, 193], [194, 197], [198, 209], [209, 210], [211, 214], [215, 222], [223, 226], [227, 232], [233, 244], [245, 247], [248, 251], [252, 256], [256, 257]]}
{"doc_key": "ai-dev-252", "ner": [[0, 3, "researcher"], [10, 11, "misc"], [12, 18, "conference"], [20, 22, "location"], [24, 24, "country"], [32, 37, "researcher"], [45, 46, "researcher"], [48, 50, "university"], [54, 55, "researcher"], [57, 58, "researcher"], [60, 61, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 3, 10, 11, "related-to", "writes_about", false, false], [0, 3, 12, 18, "temporal", "", true, false], [12, 18, 20, 22, "physical", "", false, false], [20, 22, 24, 24, "physical", "", false, false], [45, 46, 48, 50, "physical", "", false, false], [45, 46, 48, 50, "role", "", false, false], [54, 55, 48, 50, "physical", "", false, false], [54, 55, 48, 50, "role", "", false, false], [57, 58, 48, 50, "physical", "", false, false], [57, 58, 48, 50, "role", "", false, false], [60, 61, 48, 50, "physical", "", false, false], [60, 61, 48, 50, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Roger", "Schank", ",", "1969", ",", "A", "conceptual", "dependency", "parser", "for", "natural", "language", "Proceedings", "of", "the", "1969", "on", "Computational", "linguistics", ",", "S\u00e5ng", "-", "S\u00e4by", ",", "Sweden", ",", "pages", "1", "-", "3", "Partly", "influenced", "by", "the", "work", "of", "Sydney", "Lamb", ",", "this", "model", "was", "widely", "used", "by", "Schank", "'s", "students", "at", "Yale", "University", ",", "such", "as", "Robert", "Wilensky", ",", "Wendy", "Lehnert", "and", "Janet", "Kolodner", "."], "sentence-detokenized": "Roger Schank, 1969, A conceptual dependency parser for natural language Proceedings of the 1969 on Computational linguistics, S\u00e5ng-S\u00e4by, Sweden, pages 1-3 Partly influenced by the work of Sydney Lamb, this model was widely used by Schank's students at Yale University, such as Robert Wilensky, Wendy Lehnert and Janet Kolodner.", "token2charspan": [[0, 5], [6, 12], [12, 13], [14, 18], [18, 19], [20, 21], [22, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 71], [72, 83], [84, 86], [87, 90], [91, 95], [96, 98], [99, 112], [113, 124], [124, 125], [126, 130], [130, 131], [131, 135], [135, 136], [137, 143], [143, 144], [145, 150], [151, 152], [152, 153], [153, 154], [155, 161], [162, 172], [173, 175], [176, 179], [180, 184], [185, 187], [188, 194], [195, 199], [199, 200], [201, 205], [206, 211], [212, 215], [216, 222], [223, 227], [228, 230], [231, 237], [237, 239], [240, 248], [249, 251], [252, 256], [257, 267], [267, 268], [269, 273], [274, 276], [277, 283], [284, 292], [292, 293], [294, 299], [300, 307], [308, 311], [312, 317], [318, 326], [326, 327]]}
{"doc_key": "ai-dev-253", "ner": [[2, 4, "algorithm"], [6, 6, "algorithm"], [13, 13, "algorithm"], [15, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 2, 4, "named", "", false, false], [13, 13, 2, 4, "named", "", false, false], [15, 16, 2, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "improved", "maximum", "likelihood", "method", "(", "IMLM", ")", "is", "a", "combination", "of", "two", "MLM", "(", "maximum", "likelihood", ")", "estimators", "."], "sentence-detokenized": "The improved maximum likelihood method (IMLM) is a combination of two MLM (maximum likelihood) estimators.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 31], [32, 38], [39, 40], [40, 44], [44, 45], [46, 48], [49, 50], [51, 62], [63, 65], [66, 69], [70, 73], [74, 75], [75, 82], [83, 93], [93, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-dev-254", "ner": [[18, 20, "metrics"], [24, 24, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[24, 24, 18, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["These", "methods", "can", "also", "analyse", "the", "output", "and", "usefulness", "of", "a", "program", "and", "may", "therefore", "include", "analysis", "of", "the", "confusion", "matrix", "(", "or", "confusion", "table", ")", "."], "sentence-detokenized": "These methods can also analyse the output and usefulness of a program and may therefore include analysis of the confusion matrix (or confusion table).", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 22], [23, 30], [31, 34], [35, 41], [42, 45], [46, 56], [57, 59], [60, 61], [62, 69], [70, 73], [74, 77], [78, 87], [88, 95], [96, 104], [105, 107], [108, 111], [112, 121], [122, 128], [129, 130], [130, 132], [133, 142], [143, 148], [148, 149], [149, 150]]}
{"doc_key": "ai-dev-255", "ner": [[0, 1, "product"], [5, 6, "researcher"], [8, 9, "researcher"], [11, 13, "researcher"], [16, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 6, "origin", "", false, false], [0, 1, 8, 9, "origin", "", false, false], [0, 1, 11, 13, "origin", "", false, false], [0, 1, 16, 23, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SURF", "was", "first", "published", "by", "Herbert", "Bay", ",", "Tinne", "Tuytelaars", "and", "Luc", "Van", "Gool", "and", "presented", "at", "the", "2006", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "SURF was first published by Herbert Bay, Tinne Tuytelaars and Luc Van Gool and presented at the 2006 European Conference on Computer Vision.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 24], [25, 27], [28, 35], [36, 39], [39, 40], [41, 46], [47, 57], [58, 61], [62, 65], [66, 69], [70, 74], [75, 78], [79, 88], [89, 91], [92, 95], [96, 100], [101, 109], [110, 120], [121, 123], [124, 132], [133, 139], [139, 140]]}
{"doc_key": "ai-dev-256", "ner": [[0, 0, "task"], [6, 7, "field"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 6, 7, "part-of", "", false, false], [0, 0, 9, 10, "part-of", "", false, false], [0, 0, 12, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OCR", "is", "a", "research", "area", "in", "pattern", "recognition", ",", "artificial", "intelligence", "and", "computer", "vision", "."], "sentence-detokenized": "OCR is a research area in pattern recognition, artificial intelligence and computer vision.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 17], [18, 22], [23, 25], [26, 33], [34, 45], [45, 46], [47, 57], [58, 70], [71, 74], [75, 83], [84, 90], [90, 91]]}
{"doc_key": "ai-dev-257", "ner": [[4, 7, "metrics"], [10, 12, "algorithm"], [14, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 16, 10, 12, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Continuing", "the", "example", "using", "the", "maximum", "likelihood", "estimator", ",", "the", "probability", "density", "function", "(", "pdf", ")", "of", "the", "noise", "for", "a", "sample", "mathwn", "/", "math", "is"], "sentence-detokenized": "Continuing the example using the maximum likelihood estimator, the probability density function (pdf) of the noise for a sample mathwn/math is", "token2charspan": [[0, 10], [11, 14], [15, 22], [23, 28], [29, 32], [33, 40], [41, 51], [52, 61], [61, 62], [63, 66], [67, 78], [79, 86], [87, 95], [96, 97], [97, 100], [100, 101], [102, 104], [105, 108], [109, 114], [115, 118], [119, 120], [121, 127], [128, 134], [134, 135], [135, 139], [140, 142]]}
{"doc_key": "ai-dev-258", "ner": [[1, 3, "field"], [5, 6, "task"], [8, 9, "task"], [11, 12, "task"], [14, 15, "task"], [18, 19, "task"], [21, 21, "task"], [23, 23, "task"], [25, 26, "task"], [28, 29, "task"], [31, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[5, 6, 1, 3, "part-of", "", false, false], [8, 9, 1, 3, "part-of", "", false, false], [11, 12, 1, 3, "part-of", "", false, false], [14, 15, 1, 3, "part-of", "", false, false], [18, 19, 1, 3, "part-of", "", false, false], [21, 21, 1, 3, "part-of", "", false, false], [23, 23, 1, 3, "part-of", "", false, false], [25, 26, 1, 3, "part-of", "", false, false], [28, 29, 1, 3, "part-of", "", false, false], [31, 33, 1, 3, "part-of", "", false, false], [35, 36, 1, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Subfields", "of", "computer", "vision", "include", "scene", "reconstruction", ",", "event", "detection", ",", "video", "tracking", ",", "object", "recognition", ",", "3D", "pose", "estimation", ",", "learning", ",", "indexing", ",", "motion", "estimation", ",", "visual", "servoing", ",", "3D", "scene", "modelling", "and", "image", "restoration", "."], "sentence-detokenized": "Subfields of computer vision include scene reconstruction, event detection, video tracking, object recognition, 3D pose estimation, learning, indexing, motion estimation, visual servoing, 3D scene modelling and image restoration.", "token2charspan": [[0, 9], [10, 12], [13, 21], [22, 28], [29, 36], [37, 42], [43, 57], [57, 58], [59, 64], [65, 74], [74, 75], [76, 81], [82, 90], [90, 91], [92, 98], [99, 110], [110, 111], [112, 114], [115, 119], [120, 130], [130, 131], [132, 140], [140, 141], [142, 150], [150, 151], [152, 158], [159, 169], [169, 170], [171, 177], [178, 186], [186, 187], [188, 190], [191, 196], [197, 206], [207, 210], [211, 216], [217, 228], [228, 229]]}
{"doc_key": "ai-dev-259", "ner": [[3, 9, "conference"], [11, 11, "researcher"], [14, 16, "misc"], [19, 20, "conference"], [29, 29, "researcher"], [31, 31, "researcher"], [23, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 9, 19, 20, "named", "", false, false], [11, 11, 14, 16, "win-defeat", "", false, false], [11, 11, 23, 24, "related-to", "writes_about", true, false], [14, 16, 3, 9, "temporal", "", false, false], [29, 29, 14, 16, "win-defeat", "", false, true], [29, 29, 23, 24, "related-to", "writes_about", true, false], [31, 31, 14, 16, "win-defeat", "", false, true], [31, 31, 23, 24, "related-to", "writes_about", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["In", "2013", ",", "at", "the", "International", "Conference", "on", "Computer", "Vision", ",", "Terzopoulos", "was", "awarded", "the", "Helmholtz", "Prize", "for", "the", "1987", "ICCV", "paper", "on", "active", "contour", "models", ",", "together", "with", "Kass", "and", "Witkin", "."], "sentence-detokenized": "In 2013, at the International Conference on Computer Vision, Terzopoulos was awarded the Helmholtz Prize for the 1987 ICCV paper on active contour models, together with Kass and Witkin.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 29], [30, 40], [41, 43], [44, 52], [53, 59], [59, 60], [61, 72], [73, 76], [77, 84], [85, 88], [89, 98], [99, 104], [105, 108], [109, 112], [113, 117], [118, 122], [123, 128], [129, 131], [132, 138], [139, 146], [147, 153], [153, 154], [155, 163], [164, 168], [169, 173], [174, 177], [178, 184], [184, 185]]}
{"doc_key": "ai-dev-260", "ner": [[13, 14, "task"], [16, 18, "algorithm"], [20, 21, "algorithm"], [23, 25, "algorithm"], [27, 28, "algorithm"], [30, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 14, 16, 18, "usage", "", true, false], [13, 14, 20, 21, "usage", "", true, false], [13, 14, 23, 25, "usage", "", true, false], [13, 14, 27, 28, "usage", "", true, false], [13, 14, 30, 30, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Regularity", "function", "Many", "algorithms", "exist", "for", "solving", "such", "problems", ";", "popular", "ones", "for", "linear", "classification", "include", "Stochastic", "gradient", "descent", ")", "gradient", "descent", ",", "L", "-", "BFGS", ",", "coordinate", "descent", "and", "Newton", "methods", "."], "sentence-detokenized": "Regularity function Many algorithms exist for solving such problems; popular ones for linear classification include Stochastic gradient descent) gradient descent, L-BFGS, coordinate descent and Newton methods.", "token2charspan": [[0, 10], [11, 19], [20, 24], [25, 35], [36, 41], [42, 45], [46, 53], [54, 58], [59, 67], [67, 68], [69, 76], [77, 81], [82, 85], [86, 92], [93, 107], [108, 115], [116, 126], [127, 135], [136, 143], [143, 144], [145, 153], [154, 161], [161, 162], [163, 164], [164, 165], [165, 169], [169, 170], [171, 181], [182, 189], [190, 193], [194, 200], [201, 208], [208, 209]]}
{"doc_key": "ai-dev-261", "ner": [[0, 4, "algorithm"], [6, 6, "algorithm"], [12, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 4, 12, 13, "origin", "", false, false], [6, 6, 0, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Long", "short", "-", "term", "memory", "(", "LSTM", ")", "networks", "were", "invented", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "in", "1997", "and", "have", "broken", "accuracy", "records", "in", "many", "application", "areas", "."], "sentence-detokenized": "Long short-term memory (LSTM) networks were invented by Sepp Hochreiter and J\u00fcrgen Schmidhuber in 1997 and have broken accuracy records in many application areas.", "token2charspan": [[0, 4], [5, 10], [10, 11], [11, 15], [16, 22], [23, 24], [24, 28], [28, 29], [30, 38], [39, 43], [44, 52], [53, 55], [56, 60], [61, 71], [72, 75], [76, 82], [83, 94], [95, 97], [98, 102], [103, 106], [107, 111], [112, 118], [119, 127], [128, 135], [136, 138], [139, 143], [144, 155], [156, 161], [161, 162]]}
{"doc_key": "ai-dev-262", "ner": [[0, 1, "product"], [5, 7, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 5, 7, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "TN", "was", "developed", "at", "Massachusetts", "General", "Hospital", "and", "tested", "in", "a", "number", "of", "scenarios", ",", "including", "smoking", "status", ",", "family", "history", "of", "coronary", "artery", "disease", ",", "and", "identification", "of", "patients", "with", "sleep", "disorders", ","], "sentence-detokenized": "The TN was developed at Massachusetts General Hospital and tested in a number of scenarios, including smoking status, family history of coronary artery disease, and identification of patients with sleep disorders,", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 20], [21, 23], [24, 37], [38, 45], [46, 54], [55, 58], [59, 65], [66, 68], [69, 70], [71, 77], [78, 80], [81, 90], [90, 91], [92, 101], [102, 109], [110, 116], [116, 117], [118, 124], [125, 132], [133, 135], [136, 144], [145, 151], [152, 159], [159, 160], [161, 164], [165, 179], [180, 182], [183, 191], [192, 196], [197, 202], [203, 212], [212, 213]]}
{"doc_key": "ai-dev-263", "ner": [[2, 2, "researcher"], [7, 7, "product"], [10, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 7, 7, "role", "sells", false, false], [7, 7, 10, 15, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1960", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "shipped", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960 Devol personally sold the first Unimate robot, which was shipped to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [8, 13], [14, 24], [25, 29], [30, 33], [34, 39], [40, 47], [48, 53], [53, 54], [55, 60], [61, 64], [65, 72], [73, 75], [76, 83], [84, 90], [91, 93], [94, 98], [98, 99]]}
{"doc_key": "ai-dev-264", "ner": [[0, 5, "conference"], [14, 15, "location"], [17, 17, "location"], [19, 19, "country"], [31, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 5, 14, 15, "physical", "", false, false], [14, 15, 17, 17, "physical", "", false, false], [17, 17, 19, 19, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "European", "Campus", "Party", "was", "held", "on", "14", "-", "18", "April", "2010", "at", "the", "Caja", "M\u00e1gica", "in", "Madrid", ",", "Spain", "with", "800", "participants", "from", "each", "of", "the", "27", "member", "states", "of", "the", "European", "Union", "."], "sentence-detokenized": "The European Campus Party was held on 14-18 April 2010 at the Caja M\u00e1gica in Madrid, Spain with 800 participants from each of the 27 member states of the European Union.", "token2charspan": [[0, 3], [4, 12], [13, 19], [20, 25], [26, 29], [30, 34], [35, 37], [38, 40], [40, 41], [41, 43], [44, 49], [50, 54], [55, 57], [58, 61], [62, 66], [67, 73], [74, 76], [77, 83], [83, 84], [85, 90], [91, 95], [96, 99], [100, 112], [113, 117], [118, 122], [123, 125], [126, 129], [130, 132], [133, 139], [140, 146], [147, 149], [150, 153], [154, 162], [163, 168], [168, 169]]}
{"doc_key": "ai-dev-265", "ner": [[4, 4, "organisation"], [6, 8, "organisation"], [14, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 18, 4, 4, "origin", "", false, false], [14, 18, 6, 8, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2016", ",", "DeepMind", "and", "Moorfields", "Eye", "Hospital", "announced", "a", "collaboration", "to", "develop", "artificial", "intelligence", "applications", "for", "healthcare", "."], "sentence-detokenized": "In July 2016, DeepMind and Moorfields Eye Hospital announced a collaboration to develop artificial intelligence applications for healthcare.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 22], [23, 26], [27, 37], [38, 41], [42, 50], [51, 60], [61, 62], [63, 76], [77, 79], [80, 87], [88, 98], [99, 111], [112, 124], [125, 128], [129, 139], [139, 140]]}
{"doc_key": "ai-dev-266", "ner": [[1, 1, "misc"], [8, 12, "university"], [14, 14, "university"], [16, 17, "university"], [19, 20, "university"], [22, 22, "university"], [24, 24, "university"], [26, 29, "university"], [31, 32, "university"], [34, 35, "university"], [37, 37, "university"], [39, 42, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[1, 1, 8, 12, "physical", "", false, false], [1, 1, 14, 14, "physical", "", false, false], [1, 1, 16, 17, "physical", "", false, false], [1, 1, 19, 20, "physical", "", false, false], [1, 1, 22, 22, "physical", "", false, false], [1, 1, 24, 24, "physical", "", false, false], [1, 1, 26, 29, "physical", "", false, false], [1, 1, 31, 32, "physical", "", false, false], [1, 1, 34, 35, "physical", "", false, false], [1, 1, 37, 37, "physical", "", false, false], [1, 1, 39, 42, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Eleven", "PR2s", "were", "awarded", "to", "different", "institutions", ",", "including", "the", "University", "of", "Freiburg", ",", "Bosch", ",", "Georgia", "Tech", ",", "KU", "Leuven", ",", "MIT", ",", "Stanford", ",", "Technical", "University", "of", "Munich", ",", "UC", "Berkeley", ",", "U", "Penn", ",", "USC", "and", "the", "University", "of", "Tokyo", "."], "sentence-detokenized": "Eleven PR2s were awarded to different institutions, including the University of Freiburg, Bosch, Georgia Tech, KU Leuven, MIT, Stanford, Technical University of Munich, UC Berkeley, U Penn, USC and the University of Tokyo.", "token2charspan": [[0, 6], [7, 11], [12, 16], [17, 24], [25, 27], [28, 37], [38, 50], [50, 51], [52, 61], [62, 65], [66, 76], [77, 79], [80, 88], [88, 89], [90, 95], [95, 96], [97, 104], [105, 109], [109, 110], [111, 113], [114, 120], [120, 121], [122, 125], [125, 126], [127, 135], [135, 136], [137, 146], [147, 157], [158, 160], [161, 167], [167, 168], [169, 171], [172, 180], [180, 181], [182, 183], [184, 188], [188, 189], [190, 193], [194, 197], [198, 201], [202, 212], [213, 215], [216, 221], [221, 222]]}
{"doc_key": "ai-dev-267", "ner": [[2, 2, "metrics"], [4, 4, "metrics"], [6, 6, "metrics"], [8, 9, "metrics"], [17, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 17, 19, "part-of", "", false, false], [4, 4, 17, 19, "part-of", "", false, false], [6, 6, 17, 19, "part-of", "", false, false], [8, 9, 17, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "numbers", "TP", ",", "TN", ",", "FP", "and", "FN", "are", "usually", "kept", "in", "a", "table", "known", "as", "a", "confusion", "matrix", "."], "sentence-detokenized": "The numbers TP, TN, FP and FN are usually kept in a table known as a confusion matrix.", "token2charspan": [[0, 3], [4, 11], [12, 14], [14, 15], [16, 18], [18, 19], [20, 22], [23, 26], [27, 29], [30, 33], [34, 41], [42, 46], [47, 49], [50, 51], [52, 57], [58, 63], [64, 66], [67, 68], [69, 78], [79, 85], [85, 86]]}
{"doc_key": "ai-dev-268", "ner": [[0, 1, "metrics"], [3, 4, "metrics"], [6, 7, "metrics"], [9, 11, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Information", "gain", ",", "cross", "entropy", ",", "mutual", "information", "and", "likelihood", "ratio", "are", "usually", "used", "as", "feature", "sets", "."], "sentence-detokenized": "Information gain, cross entropy, mutual information and likelihood ratio are usually used as feature sets.", "token2charspan": [[0, 11], [12, 16], [16, 17], [18, 23], [24, 31], [31, 32], [33, 39], [40, 51], [52, 55], [56, 66], [67, 72], [73, 76], [77, 84], [85, 89], [90, 92], [93, 100], [101, 105], [105, 106]]}
{"doc_key": "ai-dev-269", "ner": [[10, 11, "task"], [13, 14, "task"], [16, 16, "task"], [18, 18, "task"], [20, 20, "task"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[22, 22, 20, 20, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "successfully", "applied", "to", "problems", "as", "diverse", "as", "robot", "control", ",", "lift", "scheduling", ",", "telecommunications", ",", "checkers", "and", "Go", "(", "AlphaGo", ")", "."], "sentence-detokenized": "It has been successfully applied to problems as diverse as robot control, lift scheduling, telecommunications, checkers and Go (AlphaGo).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 24], [25, 32], [33, 35], [36, 44], [45, 47], [48, 55], [56, 58], [59, 64], [65, 72], [72, 73], [74, 78], [79, 89], [89, 90], [91, 109], [109, 110], [111, 119], [120, 123], [124, 126], [127, 128], [128, 135], [135, 136], [136, 137]]}
{"doc_key": "ai-dev-270", "ner": [[11, 13, "misc"], [18, 25, "university"], [23, 23, "location"], [17, 17, "location"], [28, 32, "location"], [37, 39, "location"], [41, 41, "location"], [43, 43, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 13, 18, 25, "physical", "", false, false], [18, 25, 23, 23, "physical", "", false, false], [23, 23, 17, 17, "physical", "", false, false], [28, 32, 37, 39, "physical", "", false, false], [37, 39, 41, 41, "physical", "", false, false], [41, 41, 43, 43, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "the", "inaugural", "year", "of", "Mission", "8", ",", "the", "Americas", "Campus", "was", "held", "at", "the", "Georgia", "Institute", "of", "Technology", "campus", "in", "Atlanta", ",", "Georgia", ",", "and", "the", "Asia", "/", "Pacific", "Campus", "was", "held", "at", "the", "Beihang", "University", "Gymnasium", "in", "Beijing", ",", "China", "."], "sentence-detokenized": "In 2018, the inaugural year of Mission 8, the Americas Campus was held at the Georgia Institute of Technology campus in Atlanta, Georgia, and the Asia/Pacific Campus was held at the Beihang University Gymnasium in Beijing, China.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 22], [23, 27], [28, 30], [31, 38], [39, 40], [40, 41], [42, 45], [46, 54], [55, 61], [62, 65], [66, 70], [71, 73], [74, 77], [78, 85], [86, 95], [96, 98], [99, 109], [110, 116], [117, 119], [120, 127], [127, 128], [129, 136], [136, 137], [138, 141], [142, 145], [146, 150], [150, 151], [151, 158], [159, 165], [166, 169], [170, 174], [175, 177], [178, 181], [182, 189], [190, 200], [201, 210], [211, 213], [214, 221], [221, 222], [223, 228], [228, 229]]}
{"doc_key": "ai-dev-271", "ner": [[0, 1, "field"], [3, 7, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 3, 7, "origin", "", false, false], [0, 1, 3, 7, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "is", "closely", "related", "to", "pattern", "recognition", "and", "originates", "from", "artificial", "intelligence", "."], "sentence-detokenized": "Machine learning is closely related to pattern recognition and originates from artificial intelligence.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 35], [36, 38], [39, 46], [47, 58], [59, 62], [63, 73], [74, 78], [79, 89], [90, 102], [102, 103]]}
{"doc_key": "ai-dev-272", "ner": [[3, 3, "programlang"], [11, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Comes", "with", "3", "Java", "games", "controlled", "by", "remote", "control", "and", "displayed", "on", "the", "LCD", "screen", "."], "sentence-detokenized": "Comes with 3 Java games controlled by remote control and displayed on the LCD screen.", "token2charspan": [[0, 5], [6, 10], [11, 12], [13, 17], [18, 23], [24, 34], [35, 37], [38, 44], [45, 52], [53, 56], [57, 66], [67, 69], [70, 73], [74, 77], [78, 84], [84, 85]]}
{"doc_key": "ai-dev-273", "ner": [[5, 12, "task"], [15, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 17, 5, 12, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "commercially", "successful", "but", "specialised", "computer", "vision", "-", "based", "articulated", "body", "pose", "estimation", "technique", "is", "optical", "motion", "capture", "."], "sentence-detokenized": "A commercially successful but specialised computer vision-based articulated body pose estimation technique is optical motion capture.", "token2charspan": [[0, 1], [2, 14], [15, 25], [26, 29], [30, 41], [42, 50], [51, 57], [57, 58], [58, 63], [64, 75], [76, 80], [81, 85], [86, 96], [97, 106], [107, 109], [110, 117], [118, 124], [125, 132], [132, 133]]}
{"doc_key": "ai-dev-274", "ner": [[1, 1, "organisation"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 9, 10, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "SMC", "is", "very", "similar", "to", "the", "more", "popular", "Jaccard", "index", "."], "sentence-detokenized": "The SMC is very similar to the more popular Jaccard index.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 15], [16, 23], [24, 26], [27, 30], [31, 35], [36, 43], [44, 51], [52, 57], [57, 58]]}
{"doc_key": "ai-dev-275", "ner": [[0, 0, "product"], [2, 6, "product"], [8, 11, "product"], [20, 21, "researcher"], [22, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 11, "named", "", false, false], [0, 0, 20, 21, "artifact", "", false, false], [0, 0, 22, 27, "artifact", "", false, false], [2, 6, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", "or", "Programmable", "Universal", "Manipulation", "Arm", ")", "is", "an", "industrial", "robotic", "arm", "developed", "by", "Victor", "Scheinman", "at", "the", "pioneering", "robotics", "company", "Unimation", "."], "sentence-detokenized": "PUMA (Programmable Universal Machine for Assembly or Programmable Universal Manipulation Arm) is an industrial robotic arm developed by Victor Scheinman at the pioneering robotics company Unimation.", "token2charspan": [[0, 4], [5, 6], [6, 18], [19, 28], [29, 36], [37, 40], [41, 49], [50, 52], [53, 65], [66, 75], [76, 88], [89, 92], [92, 93], [94, 96], [97, 99], [100, 110], [111, 118], [119, 122], [123, 132], [133, 135], [136, 142], [143, 152], [153, 155], [156, 159], [160, 170], [171, 179], [180, 187], [188, 197], [197, 198]]}
{"doc_key": "ai-dev-276", "ner": [[3, 5, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "written", "in", "Python", "language", "."], "sentence-detokenized": "It is written in Python language.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 23], [24, 32], [32, 33]]}
{"doc_key": "ai-dev-277", "ner": [[0, 0, "misc"], [2, 2, "misc"], [12, 12, "field"], [14, 15, "field"], [17, 17, "field"], [20, 20, "field"], [23, 24, "field"], [26, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 2, 2, "related-to", "metric_for", true, false], [0, 0, 12, 12, "part-of", "", false, false], [0, 0, 14, 15, "part-of", "", false, false], [0, 0, 17, 17, "part-of", "", false, false], [0, 0, 20, 20, "part-of", "", false, false], [0, 0, 23, 24, "part-of", "", false, false], [0, 0, 26, 30, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Bandwidth", "in", "hertz", "is", "a", "central", "concept", "in", "many", "fields", ",", "including", "electronics", ",", "information", "theory", ",", "digital", "communications", ",", "radio", "communications", ",", "signal", "processing", "and", "spectroscopy", ",", "and", "is", "one", "of", "the", "determinants", "of", "the", "capacity", "of", "a", "given", "communication", "channel", "."], "sentence-detokenized": "Bandwidth in hertz is a central concept in many fields, including electronics, information theory, digital communications, radio communications, signal processing and spectroscopy, and is one of the determinants of the capacity of a given communication channel.", "token2charspan": [[0, 9], [10, 12], [13, 18], [19, 21], [22, 23], [24, 31], [32, 39], [40, 42], [43, 47], [48, 54], [54, 55], [56, 65], [66, 77], [77, 78], [79, 90], [91, 97], [97, 98], [99, 106], [107, 121], [121, 122], [123, 128], [129, 143], [143, 144], [145, 151], [152, 162], [163, 166], [167, 179], [179, 180], [181, 184], [185, 187], [188, 191], [192, 194], [195, 198], [199, 211], [212, 214], [215, 218], [219, 227], [228, 230], [231, 232], [233, 238], [239, 252], [253, 260], [260, 261]]}
{"doc_key": "ai-dev-278", "ner": [[13, 13, "algorithm"], [15, 15, "algorithm"], [17, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 13, 17, 20, "part-of", "", false, false], [15, 15, 17, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["If", "a", "convex", "loss", "is", "used", "(", "as", "in", "all", "members", "of", "the", "AdaBoost", ",", "LogitBoost", "and", "AnyBoost", "family", "of", "algorithms", ")", ",", "a", "higher", "margin", "sample", "will", "receive", "less", "(", "or", "equal", ")", "weight", "than", "a", "lower", "margin", "sample", "."], "sentence-detokenized": "If a convex loss is used (as in all members of the AdaBoost, LogitBoost and AnyBoost family of algorithms), a higher margin sample will receive less (or equal) weight than a lower margin sample.", "token2charspan": [[0, 2], [3, 4], [5, 11], [12, 16], [17, 19], [20, 24], [25, 26], [26, 28], [29, 31], [32, 35], [36, 43], [44, 46], [47, 50], [51, 59], [59, 60], [61, 71], [72, 75], [76, 84], [85, 91], [92, 94], [95, 105], [105, 106], [106, 107], [108, 109], [110, 116], [117, 123], [124, 130], [131, 135], [136, 143], [144, 148], [149, 150], [150, 152], [153, 158], [158, 159], [160, 166], [167, 171], [172, 173], [174, 179], [180, 186], [187, 193], [193, 194]]}
{"doc_key": "ai-dev-279", "ner": [[0, 1, "researcher"], [6, 7, "researcher"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sepp", "Hochreiter", "'s", "1991", "diploma", "thesis", "Sepp", "Hochreiter", "."], "sentence-detokenized": "Sepp Hochreiter's 1991 diploma thesis Sepp Hochreiter.", "token2charspan": [[0, 4], [5, 15], [15, 17], [18, 22], [23, 30], [31, 37], [38, 42], [43, 53], [53, 54]]}
{"doc_key": "ai-dev-280", "ner": [[4, 5, "algorithm"], [7, 7, "algorithm"], [10, 11, "algorithm"], [14, 14, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"], [27, 28, "algorithm"], [31, 32, "algorithm"], [34, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 7, 4, 5, "named", "", false, false], [14, 14, 10, 11, "named", "", false, false], [17, 19, 27, 28, "related-to", "", true, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Typical", "discriminative", "models", "include", "logistic", "regression", "(", "LR", ")", ",", "support", "vector", "machines", "(", "SVM", ")", ",", "conditional", "random", "fields", "(", "CRFs", ")", "(", "specified", "on", "an", "undirected", "graph", ")", ",", "decision", "trees", ",", "neural", "networks", "and", "others", "."], "sentence-detokenized": "Typical discriminative models include logistic regression (LR), support vector machines (SVM), conditional random fields (CRFs) (specified on an undirected graph), decision trees, neural networks and others.", "token2charspan": [[0, 7], [8, 22], [23, 29], [30, 37], [38, 46], [47, 57], [58, 59], [59, 61], [61, 62], [62, 63], [64, 71], [72, 78], [79, 87], [88, 89], [89, 92], [92, 93], [93, 94], [95, 106], [107, 113], [114, 120], [121, 122], [122, 126], [126, 127], [128, 129], [129, 138], [139, 141], [142, 144], [145, 155], [156, 161], [161, 162], [162, 163], [164, 172], [173, 178], [178, 179], [180, 186], [187, 195], [196, 199], [200, 206], [206, 207]]}
{"doc_key": "ai-dev-281", "ner": [[10, 13, "metrics"], [31, 34, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "then", "possible", "to", "use", "these", "probabilities", "and", "evaluate", "the", "mean", "squared", "error", "(", "or", "a", "similar", "measure", ")", "between", "the", "probabilities", "and", "the", "actual", "values", ",", "then", "combine", "this", "with", "the", "confusion", "matrix", "to", "generate", "very", "efficient", "fitness", "functions", "for", "logistic", "regression", "."], "sentence-detokenized": "It is then possible to use these probabilities and evaluate the mean squared error (or a similar measure) between the probabilities and the actual values, then combine this with the confusion matrix to generate very efficient fitness functions for logistic regression.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 19], [20, 22], [23, 26], [27, 32], [33, 46], [47, 50], [51, 59], [60, 63], [64, 68], [69, 76], [77, 82], [83, 84], [84, 86], [87, 88], [89, 96], [97, 104], [104, 105], [106, 113], [114, 117], [118, 131], [132, 135], [136, 139], [140, 146], [147, 153], [153, 154], [155, 159], [160, 167], [168, 172], [173, 177], [178, 181], [182, 191], [192, 198], [199, 201], [202, 210], [211, 215], [216, 225], [226, 233], [234, 243], [244, 247], [248, 256], [257, 267], [267, 268]]}
{"doc_key": "ai-dev-282", "ner": [[0, 3, "product"], [4, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 4, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VoiceOver", "first", "appeared", "in", "Mac", "OS", "X", "Tiger", "(", "10.4", ")", "in", "2005", "."], "sentence-detokenized": "VoiceOver first appeared in Mac OS X Tiger (10.4) in 2005.", "token2charspan": [[0, 9], [10, 15], [16, 24], [25, 27], [28, 31], [32, 34], [35, 36], [37, 42], [43, 44], [44, 48], [48, 49], [50, 52], [53, 57], [57, 58]]}
{"doc_key": "ai-dev-283", "ner": [[14, 14, "algorithm"], [15, 21, "misc"], [25, 27, "metrics"], [30, 32, "algorithm"], [60, 70, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 14, 15, 21, "related-to", "applied_to", false, false], [25, 27, 15, 21, "type-of", "", false, false], [25, 27, 30, 32, "related-to", "used_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "practice", ",", "machine", "learning", "algorithms", "deal", "with", "this", "either", "by", "using", "a", "convex", "approximation", "to", "the", "0", "-", "1", "loss", "function", "(", "such", "as", "the", "hinge", "loss", "for", "a", "support", "vector", "machine", ")", ",", "which", "is", "easier", "to", "optimise", ",", "or", "by", "applying", "assumptions", "to", "the", "mathP", "(", "x", ",", "y", ")", "/", "math", "distribution", "(", "and", "thus", "ceasing", "to", "be", "agnostic", "learning", "algorithms", ",", "where", "the", "above", "conclusion", "holds", ")", "."], "sentence-detokenized": "In practice, machine learning algorithms deal with this either by using a convex approximation to the 0-1 loss function (such as the hinge loss for a support vector machine), which is easier to optimise, or by applying assumptions to the mathP (x, y) / math distribution (and thus ceasing to be agnostic learning algorithms, where the above conclusion holds).", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 20], [21, 29], [30, 40], [41, 45], [46, 50], [51, 55], [56, 62], [63, 65], [66, 71], [72, 73], [74, 80], [81, 94], [95, 97], [98, 101], [102, 103], [103, 104], [104, 105], [106, 110], [111, 119], [120, 121], [121, 125], [126, 128], [129, 132], [133, 138], [139, 143], [144, 147], [148, 149], [150, 157], [158, 164], [165, 172], [172, 173], [173, 174], [175, 180], [181, 183], [184, 190], [191, 193], [194, 202], [202, 203], [204, 206], [207, 209], [210, 218], [219, 230], [231, 233], [234, 237], [238, 243], [244, 245], [245, 246], [246, 247], [248, 249], [249, 250], [251, 252], [253, 257], [258, 270], [271, 272], [272, 275], [276, 280], [281, 288], [289, 291], [292, 294], [295, 303], [304, 312], [313, 323], [323, 324], [325, 330], [331, 334], [335, 340], [341, 351], [352, 357], [357, 358], [358, 359]]}
{"doc_key": "ai-dev-284", "ner": [[0, 0, "misc"], [11, 13, "field"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 13, "usage", "", false, false], [0, 0, 24, 24, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Westworld", "(", "1973", ")", "was", "the", "first", "feature", "film", "to", "use", "digital", "image", "processing", "in", "photography", "to", "simulate", "the", "point", "of", "view", "of", "an", "android", "."], "sentence-detokenized": "Westworld (1973) was the first feature film to use digital image processing in photography to simulate the point of view of an android.", "token2charspan": [[0, 9], [10, 11], [11, 15], [15, 16], [17, 20], [21, 24], [25, 30], [31, 38], [39, 43], [44, 46], [47, 50], [51, 58], [59, 64], [65, 75], [76, 78], [79, 90], [91, 93], [94, 102], [103, 106], [107, 112], [113, 115], [116, 120], [121, 123], [124, 126], [127, 134], [134, 135]]}
{"doc_key": "ai-dev-285", "ner": [[6, 7, "task"], [9, 10, "task"], [12, 13, "task"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "now", "widely", "used", "in", "speech", "recognition", ",", "speech", "synthesis", ",", "diary", "keeping", ",", "Xavier", "Anguera", "et", "al", "."], "sentence-detokenized": "It is now widely used in speech recognition, speech synthesis, diary keeping, Xavier Anguera et al.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 16], [17, 21], [22, 24], [25, 31], [32, 43], [43, 44], [45, 51], [52, 61], [61, 62], [63, 68], [69, 76], [76, 77], [78, 84], [85, 92], [93, 95], [96, 98], [98, 99]]}
{"doc_key": "ai-dev-286", "ner": [[7, 13, "algorithm"], [18, 19, "algorithm"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 19, 7, 13, "type-of", "", false, false], [22, 24, 7, 13, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Here", ",", "math", "\\", "sigma", "/", "math", "is", "an", "element", "-", "wise", "activation", "function", ",", "such", "as", "a", "sigmoid", "function", "or", "a", "smoothed", "linear", "unit", "."], "sentence-detokenized": "Here, math\\ sigma / math is an element-wise activation function, such as a sigmoid function or a smoothed linear unit.", "token2charspan": [[0, 4], [4, 5], [6, 10], [10, 11], [12, 17], [18, 19], [20, 24], [25, 27], [28, 30], [31, 38], [38, 39], [39, 43], [44, 54], [55, 63], [63, 64], [65, 69], [70, 72], [73, 74], [75, 82], [83, 91], [92, 94], [95, 96], [97, 105], [106, 112], [113, 117], [117, 118]]}
{"doc_key": "ai-dev-287", "ner": [[8, 9, "algorithm"], [22, 22, "misc"], [24, 24, "misc"], [26, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "phonetics", "-", "based", "(", "i.e.", ",", "all", "Hidden", "Markov", "model", "-", "based", ")", "approaches", "have", "required", "separate", "components", "and", "training", "for", "pronunciation", ",", "acoustics", "and", "language", "modelling", "."], "sentence-detokenized": "Traditional phonetics-based (i.e., all Hidden Markov model-based) approaches have required separate components and training for pronunciation, acoustics and language modelling.", "token2charspan": [[0, 11], [12, 21], [21, 22], [22, 27], [28, 29], [29, 33], [33, 34], [35, 38], [39, 45], [46, 52], [53, 58], [58, 59], [59, 64], [64, 65], [66, 76], [77, 81], [82, 90], [91, 99], [100, 110], [111, 114], [115, 123], [124, 127], [128, 141], [141, 142], [143, 152], [153, 156], [157, 165], [166, 175], [175, 176]]}
{"doc_key": "ai-dev-288", "ner": [[0, 2, "algorithm"], [9, 10, "field"], [12, 13, "field"], [6, 8, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 6, 8, "related-to", "used_for", false, false], [9, 10, 0, 2, "usage", "", false, false], [12, 13, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Roberts", "cross", "operator", "is", "used", "for", "edge", "detection", "in", "image", "processing", "and", "computer", "vision", "."], "sentence-detokenized": "Roberts cross operator is used for edge detection in image processing and computer vision.", "token2charspan": [[0, 7], [8, 13], [14, 22], [23, 25], [26, 30], [31, 34], [35, 39], [40, 49], [50, 52], [53, 58], [59, 69], [70, 73], [74, 82], [83, 89], [89, 90]]}
{"doc_key": "ai-dev-289", "ner": [[0, 0, "metrics"], [2, 2, "metrics"], [25, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 25, 25, "opposite", "", false, false], [2, 2, 25, 25, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Sensitivity", "and", "specificity", "values", "are", "independent", "of", "the", "percentage", "of", "positive", "cases", "in", "the", "population", "of", "interest", "(", "as", "opposed", "to", ",", "for", "example", ",", "precision", ")", "."], "sentence-detokenized": "Sensitivity and specificity values are independent of the percentage of positive cases in the population of interest (as opposed to, for example, precision).", "token2charspan": [[0, 11], [12, 15], [16, 27], [28, 34], [35, 38], [39, 50], [51, 53], [54, 57], [58, 68], [69, 71], [72, 80], [81, 86], [87, 89], [90, 93], [94, 104], [105, 107], [108, 116], [117, 118], [118, 120], [121, 128], [129, 131], [131, 132], [133, 136], [137, 144], [144, 145], [146, 155], [155, 156], [156, 157]]}
{"doc_key": "ai-dev-290", "ner": [[2, 3, "algorithm"], [13, 13, "misc"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 13, 2, 3, "topic", "", false, false], [13, 13, 15, 16, "artifact", "", false, false], [13, 13, 18, 19, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["However", ",", "perceptron", "models", "became", "less", "popular", "with", "the", "publication", "of", "the", "book", "Perceptrons", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "in", "1969", "."], "sentence-detokenized": "However, perceptron models became less popular with the publication of the book Perceptrons by Marvin Minsky and Seymour Papert in 1969.", "token2charspan": [[0, 7], [7, 8], [9, 19], [20, 26], [27, 33], [34, 38], [39, 46], [47, 51], [52, 55], [56, 67], [68, 70], [71, 74], [75, 79], [80, 91], [92, 94], [95, 101], [102, 108], [109, 112], [113, 120], [121, 127], [128, 130], [131, 135], [135, 136]]}
{"doc_key": "ai-dev-291", "ner": [[0, 3, "conference"], [8, 8, "organisation"], [22, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 22, 24, "topic", "", false, false], [8, 8, 0, 3, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Document", "Comprehension", "Conferences", ",", "organised", "annually", "by", "NIST", ",", "have", "developed", "sophisticated", "evaluation", "criteria", "for", "techniques", "that", "recognise", "the", "challenge", "of", "multiple", "document", "summarisation", "."], "sentence-detokenized": "The Document Comprehension Conferences, organised annually by NIST, have developed sophisticated evaluation criteria for techniques that recognise the challenge of multiple document summarisation.", "token2charspan": [[0, 3], [4, 12], [13, 26], [27, 38], [38, 39], [40, 49], [50, 58], [59, 61], [62, 66], [66, 67], [68, 72], [73, 82], [83, 96], [97, 107], [108, 116], [117, 120], [121, 131], [132, 136], [137, 146], [147, 150], [151, 160], [161, 163], [164, 172], [173, 181], [182, 195], [195, 196]]}
{"doc_key": "ai-dev-292", "ner": [[0, 2, "product"], [27, 27, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 27, 27, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "parallel", "manipulator", "is", "designed", "in", "such", "a", "way", "that", "each", "chain", "can", "be", "generally", "short", ",", "simple", "and", "therefore", "rigid", "against", "unwanted", "movements", "compared", "to", "a", "serial", "manipulator", "."], "sentence-detokenized": "A parallel manipulator is designed in such a way that each chain can be generally short, simple and therefore rigid against unwanted movements compared to a serial manipulator.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 34], [35, 37], [38, 42], [43, 44], [45, 48], [49, 53], [54, 58], [59, 64], [65, 68], [69, 71], [72, 81], [82, 87], [87, 88], [89, 95], [96, 99], [100, 109], [110, 115], [116, 123], [124, 132], [133, 142], [143, 151], [152, 154], [155, 156], [157, 163], [164, 175], [175, 176]]}
{"doc_key": "ai-dev-293", "ner": [[25, 25, "misc"], [27, 29, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "manipulator", "is", "what", "makes", "the", "robot", "move", ",", "and", "the", "design", "of", "these", "systems", "can", "be", "divided", "into", "several", "common", "types", ",", "such", "as", "SCARA", "and", "cartesian", "coordinate", "robot", ",", "which", "use", "different", "coordinate", "systems", "to", "guide", "the", "machine", "'s", "arms", "."], "sentence-detokenized": "The manipulator is what makes the robot move, and the design of these systems can be divided into several common types, such as SCARA and cartesian coordinate robot, which use different coordinate systems to guide the machine's arms.", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 23], [24, 29], [30, 33], [34, 39], [40, 44], [44, 45], [46, 49], [50, 53], [54, 60], [61, 63], [64, 69], [70, 77], [78, 81], [82, 84], [85, 92], [93, 97], [98, 105], [106, 112], [113, 118], [118, 119], [120, 124], [125, 127], [128, 133], [134, 137], [138, 147], [148, 158], [159, 164], [164, 165], [166, 171], [172, 175], [176, 185], [186, 196], [197, 204], [205, 207], [208, 213], [214, 217], [218, 225], [225, 227], [228, 232], [232, 233]]}
{"doc_key": "ai-dev-294", "ner": [[10, 14, "organisation"], [17, 22, "organisation"], [26, 30, "organisation"], [31, 32, "organisation"], [36, 42, "organisation"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "United", "States", ",", "he", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Linguistic", "Association", ",", "the", "American", "Philosophical", "Association", ",", "and", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In the United States, he is a member of the National Academy of Sciences, the American Academy of Arts and Sciences, the American Linguistic Association, the American Philosophical Association, and the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 20], [20, 21], [22, 24], [25, 27], [28, 29], [30, 36], [37, 39], [40, 43], [44, 52], [53, 60], [61, 63], [64, 72], [72, 73], [74, 77], [78, 86], [87, 94], [95, 97], [98, 102], [103, 106], [107, 115], [115, 116], [117, 120], [121, 129], [130, 140], [141, 152], [152, 153], [154, 157], [158, 166], [167, 180], [181, 192], [192, 193], [194, 197], [198, 201], [202, 210], [211, 222], [223, 226], [227, 230], [231, 242], [243, 245], [246, 253], [253, 254]]}
{"doc_key": "ai-dev-295", "ner": [[4, 7, "algorithm"], [9, 11, "algorithm"], [24, 24, "algorithm"], [28, 29, "algorithm"], [34, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 7, 24, 24, "named", "", false, false], [9, 11, 4, 7, "named", "", false, false], [24, 24, 28, 29, "compare", "", false, false], [24, 24, 34, 35, "related-to", "performs", false, false], [28, 29, 34, 35, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["With", "the", "popularity", "of", "the", "support", "vector", "machine", "(", "SVM", ")", "in", "the", "1990s", ",", "they", "gained", "great", "importance", "when", "it", "was", "seen", "that", "SVM", "could", "compete", "with", "neural", "networks", "in", "tasks", "such", "as", "handwriting", "recognition", "."], "sentence-detokenized": "With the popularity of the support vector machine (SVM) in the 1990s, they gained great importance when it was seen that SVM could compete with neural networks in tasks such as handwriting recognition.", "token2charspan": [[0, 4], [5, 8], [9, 19], [20, 22], [23, 26], [27, 34], [35, 41], [42, 49], [50, 51], [51, 54], [54, 55], [56, 58], [59, 62], [63, 68], [68, 69], [70, 74], [75, 81], [82, 87], [88, 98], [99, 103], [104, 106], [107, 110], [111, 115], [116, 120], [121, 124], [125, 130], [131, 138], [139, 143], [144, 150], [151, 159], [160, 162], [163, 168], [169, 173], [174, 176], [177, 188], [189, 200], [200, 201]]}
{"doc_key": "ai-dev-296", "ner": [[2, 4, "misc"], [8, 9, "misc"], [12, 14, "algorithm"], [23, 23, "misc"], [26, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 8, 9, "usage", "", false, false], [2, 4, 23, 23, "usage", "", false, false], [8, 9, 12, 14, "origin", "result_of_algorithm", false, false], [23, 23, 26, 28, "origin", "result_of_algorithm", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["An", "empirical", "whitening", "transformation", "is", "obtained", "by", "estimating", "the", "covariance", "(", "e.g.", "by", "maximum", "likelihood", ")", "and", "then", "constructing", "a", "corresponding", "estimated", "whitening", "matrix", "(", "e.g.", "by", "Cholesky", "decomposition", ")", "."], "sentence-detokenized": "An empirical whitening transformation is obtained by estimating the covariance (e.g. by maximum likelihood) and then constructing a corresponding estimated whitening matrix (e.g. by Cholesky decomposition).", "token2charspan": [[0, 2], [3, 12], [13, 22], [23, 37], [38, 40], [41, 49], [50, 52], [53, 63], [64, 67], [68, 78], [79, 80], [80, 84], [85, 87], [88, 95], [96, 106], [106, 107], [108, 111], [112, 116], [117, 129], [130, 131], [132, 145], [146, 155], [156, 165], [166, 172], [173, 174], [174, 178], [179, 181], [182, 190], [191, 204], [204, 205], [205, 206]]}
{"doc_key": "ai-dev-297", "ner": [[0, 1, "organisation"], [7, 10, "product"], [15, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 10, 0, 1, "artifact", "", false, false], [15, 24, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["IAI", "is", "the", "world", "'s", "largest", "manufacturer", "of", "Cartesian", "coordinate", "robots", "and", "an", "established", "leader", "in", "low", "-", "cost", ",", "high", "-", "performance", "SCARA", "robots", "."], "sentence-detokenized": "IAI is the world's largest manufacturer of Cartesian coordinate robots and an established leader in low-cost, high-performance SCARA robots.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [16, 18], [19, 26], [27, 39], [40, 42], [43, 52], [53, 63], [64, 70], [71, 74], [75, 77], [78, 89], [90, 96], [97, 99], [100, 103], [103, 104], [104, 108], [108, 109], [110, 114], [114, 115], [115, 126], [127, 132], [133, 139], [139, 140]]}
{"doc_key": "ai-dev-298", "ner": [[10, 11, "field"], [13, 14, "field"], [16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 28, "field"], [8, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["Formal", "concept", "analysis", "finds", "practical", "applications", "in", "areas", "such", "as", "data", "mining", ",", "text", "mining", ",", "machine", "learning", ",", "knowledge", "management", ",", "semantic", "web", ",", "software", "development", ",", "chemistry", "and", "biology", "."], "sentence-detokenized": "Formal concept analysis finds practical applications in areas such as data mining, text mining, machine learning, knowledge management, semantic web, software development, chemistry and biology.", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 29], [30, 39], [40, 52], [53, 55], [56, 61], [62, 66], [67, 69], [70, 74], [75, 81], [81, 82], [83, 87], [88, 94], [94, 95], [96, 103], [104, 112], [112, 113], [114, 123], [124, 134], [134, 135], [136, 144], [145, 148], [148, 149], [150, 158], [159, 170], [170, 171], [172, 181], [182, 185], [186, 193], [193, 194]]}
{"doc_key": "ai-dev-299", "ner": [[0, 2, "field"], [4, 6, "field"], [11, 11, "field"], [17, 18, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 17, 18, "part-of", "", false, false], [4, 6, 27, 28, "topic", "", false, false], [11, 11, 4, 6, "named", "", false, false], [17, 18, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", ",", "computational", "learning", "theory", "(", "or", "simply", "learning", "theory", ")", "is", "a", "subfield", "of", "artificial", "intelligence", "dedicated", "to", "studying", "the", "design", "and", "analysis", "of", "machine", "learning", "algorithms", "."], "sentence-detokenized": "In computer science, computational learning theory (or simply learning theory) is a subfield of artificial intelligence dedicated to studying the design and analysis of machine learning algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 34], [35, 43], [44, 50], [51, 52], [52, 54], [55, 61], [62, 70], [71, 77], [77, 78], [79, 81], [82, 83], [84, 92], [93, 95], [96, 106], [107, 119], [120, 129], [130, 132], [133, 141], [142, 145], [146, 152], [153, 156], [157, 165], [166, 168], [169, 176], [177, 185], [186, 196], [196, 197]]}
{"doc_key": "ai-dev-300", "ner": [[0, 1, "algorithm"], [3, 5, "algorithm"], [10, 10, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 0, 1, "named", "", false, false], [10, 10, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Collaborative", "filtering", "(", "CF", ")", "is", "a", "technique", "used", "by", "recommender", "systems", "."], "sentence-detokenized": "Collaborative filtering (CF) is a technique used by recommender systems.", "token2charspan": [[0, 13], [14, 23], [24, 25], [25, 27], [27, 28], [29, 31], [32, 33], [34, 43], [44, 48], [49, 51], [52, 63], [64, 71], [71, 72]]}
{"doc_key": "ai-dev-301", "ner": [[2, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "FALSE", "positive", "rate", "is", "the", "proportion", "of", "all", "negatives", "that", "nevertheless", "yield", "positive", "test", "results", ",", "i.e.", "the", "conditional", "probability", "of", "a", "positive", "test", "result", "given", "a", "non-existent", "event", "."], "sentence-detokenized": "The FALSE positive rate is the proportion of all negatives that nevertheless yield positive test results, i.e. the conditional probability of a positive test result given a non-existent event.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 23], [24, 26], [27, 30], [31, 41], [42, 44], [45, 48], [49, 58], [59, 63], [64, 76], [77, 82], [83, 91], [92, 96], [97, 104], [104, 105], [106, 110], [111, 114], [115, 126], [127, 138], [139, 141], [142, 143], [144, 152], [153, 157], [158, 164], [165, 170], [171, 172], [173, 185], [186, 191], [191, 192]]}
{"doc_key": "ai-dev-302", "ner": [[0, 14, "misc"], [36, 37, "metrics"], [40, 40, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 14, 36, 37, "topic", "", false, false], [0, 14, 40, 40, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["VLDB", "'", "8", ":", "Proceedings", "of", "the", "34th", "International", "Conference", "on", "Very", "Large", "Data", "Bases", ",", "pages", "422--433", ".", "showed", "that", "the", "values", "given", "for", "mathC", "/", "math", "and", "mathK", "/", "math", "generally", "imply", "relatively", "low", "accuracy", "of", "iteratively", "computed", "SimRank", "scores", "."], "sentence-detokenized": "VLDB '8: Proceedings of the 34th International Conference on Very Large Data Bases, pages 422--433. showed that the values given for mathC/ math and mathK/ math generally imply relatively low accuracy of iteratively computed SimRank scores.", "token2charspan": [[0, 4], [5, 6], [6, 7], [7, 8], [9, 20], [21, 23], [24, 27], [28, 32], [33, 46], [47, 57], [58, 60], [61, 65], [66, 71], [72, 76], [77, 82], [82, 83], [84, 89], [90, 98], [98, 99], [100, 106], [107, 111], [112, 115], [116, 122], [123, 128], [129, 132], [133, 138], [138, 139], [140, 144], [145, 148], [149, 154], [154, 155], [156, 160], [161, 170], [171, 176], [177, 187], [188, 191], [192, 200], [201, 203], [204, 215], [216, 224], [225, 232], [233, 239], [239, 240]]}
{"doc_key": "ai-dev-303", "ner": [[1, 5, "misc"], [0, 0, "misc"], [10, 12, "person"], [13, 15, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 1, 5, "general-affiliation", "", false, false], [0, 0, 10, 12, "artifact", "", false, false], [0, 0, 13, 15, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Sense8", ",", "a", "science", "fiction", "drama", "written", "and", "produced", "by", "The", "Wachowskis", "and", "J.", "Michael", "Straczynski", ",", "was", "released", "in", "June", "2015", "."], "sentence-detokenized": "Sense8, a science fiction drama written and produced by The Wachowskis and J. Michael Straczynski, was released in June 2015.", "token2charspan": [[0, 6], [6, 7], [8, 9], [10, 17], [18, 25], [26, 31], [32, 39], [40, 43], [44, 52], [53, 55], [56, 59], [60, 70], [71, 74], [75, 77], [78, 85], [86, 97], [97, 98], [99, 102], [103, 111], [112, 114], [115, 119], [120, 124], [124, 125]]}
{"doc_key": "ai-dev-304", "ner": [[0, 3, "misc"], [4, 8, "product"], [28, 29, "misc"], [38, 38, "country"], [40, 40, "country"], [42, 42, "country"], [44, 44, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 4, 8, "topic", "", false, false], [38, 38, 28, 29, "type-of", "", false, false], [40, 40, 28, 29, "type-of", "", false, false], [42, 42, 28, 29, "type-of", "", false, false], [44, 44, 28, 29, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Although", "Eurotra", "has", "never", "delivered", "a", "working", "MT", "system", ",", "the", "project", "has", "had", "a", "far", "-", "reaching", "long", "-", "term", "impact", "on", "the", "fledgling", "language", "industries", "in", "European", "member", "states", ",", "especially", "in", "southern", "countries", "such", "as", "Greece", ",", "Italy", ",", "Spain", "and", "Portugal", "."], "sentence-detokenized": "Although Eurotra has never delivered a working MT system, the project has had a far-reaching long-term impact on the fledgling language industries in European member states, especially in southern countries such as Greece, Italy, Spain and Portugal.", "token2charspan": [[0, 8], [9, 16], [17, 20], [21, 26], [27, 36], [37, 38], [39, 46], [47, 49], [50, 56], [56, 57], [58, 61], [62, 69], [70, 73], [74, 77], [78, 79], [80, 83], [83, 84], [84, 92], [93, 97], [97, 98], [98, 102], [103, 109], [110, 112], [113, 116], [117, 126], [127, 135], [136, 146], [147, 149], [150, 158], [159, 165], [166, 172], [172, 173], [174, 184], [185, 187], [188, 196], [197, 206], [207, 211], [212, 214], [215, 221], [221, 222], [223, 228], [228, 229], [230, 235], [236, 239], [240, 248], [248, 249]]}
{"doc_key": "ai-dev-305", "ner": [[0, 1, "algorithm"], [17, 19, "task"], [21, 21, "task"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [2], "sentence": ["The", "autoencoder", "has", "been", "successfully", "applied", "to", "machine", "translation", "of", "human", "languages", ",", "often", "referred", "to", "as", "neural", "machine", "translation", "(", "NMT", ")", "."], "sentence-detokenized": "The autoencoder has been successfully applied to machine translation of human languages, often referred to as neural machine translation (NMT).", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 24], [25, 37], [38, 45], [46, 48], [49, 56], [57, 68], [69, 71], [72, 77], [78, 87], [87, 88], [89, 94], [95, 103], [104, 106], [107, 109], [110, 116], [117, 124], [125, 136], [137, 138], [138, 141], [141, 142], [142, 143]]}
{"doc_key": "ai-dev-306", "ner": [[9, 11, "metrics"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Popular", "examples", "of", "fitness", "functions", "based", "on", "probabilities", "include", "maximum", "likelihood", "estimation", "and", "hinge", "loss", "."], "sentence-detokenized": "Popular examples of fitness functions based on probabilities include maximum likelihood estimation and hinge loss.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 37], [38, 43], [44, 46], [47, 60], [61, 68], [69, 76], [77, 87], [88, 98], [99, 102], [103, 108], [109, 113], [113, 114]]}
{"doc_key": "ai-dev-307", "ner": [[0, 1, "field"], [11, 13, "task"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 13, 0, 1, "part-of", "", false, false], [15, 16, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Data", "mining", "is", "a", "related", "field", "of", "study", "that", "focuses", "on", "exploratory", "data", "analysis", "through", "unsupervised", "learning", "."], "sentence-detokenized": "Data mining is a related field of study that focuses on exploratory data analysis through unsupervised learning.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 16], [17, 24], [25, 30], [31, 33], [34, 39], [40, 44], [45, 52], [53, 55], [56, 67], [68, 72], [73, 81], [82, 89], [90, 102], [103, 111], [111, 112]]}
{"doc_key": "ai-dev-308", "ner": [[0, 1, "algorithm"], [13, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 13, 14, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "filtering", "involves", "techniques", "for", "matching", "people", "with", "similar", "interests", "and", "building", "a", "recommender", "system", "on", "this", "basis", "."], "sentence-detokenized": "Collaborative filtering involves techniques for matching people with similar interests and building a recommender system on this basis.", "token2charspan": [[0, 13], [14, 23], [24, 32], [33, 43], [44, 47], [48, 56], [57, 63], [64, 68], [69, 76], [77, 86], [87, 90], [91, 99], [100, 101], [102, 113], [114, 120], [121, 123], [124, 128], [129, 134], [134, 135]]}
{"doc_key": "ai-dev-309", "ner": [[0, 8, "algorithm"], [16, 16, "programlang"], [9, 11, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 11, 0, 8, "type-of", "", false, false], [9, 11, 16, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "set", "of", "WordNet", "-", "based", "word", "similarity", "algorithms", "WordNet", "::", "Similarity", "is", "implemented", "in", "a", "Perl", "package", "."], "sentence-detokenized": "A set of WordNet-based word similarity algorithms WordNet:: Similarity is implemented in a Perl package.", "token2charspan": [[0, 1], [2, 5], [6, 8], [9, 16], [16, 17], [17, 22], [23, 27], [28, 38], [39, 49], [50, 57], [57, 59], [60, 70], [71, 73], [74, 85], [86, 88], [89, 90], [91, 95], [96, 103], [103, 104]]}
{"doc_key": "ai-dev-310", "ner": [[4, 4, "conference"], [6, 6, "conference"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 4, 4, "named", "", false, false], [10, 11, 4, 4, "temporal", "", false, false], [13, 14, 4, 4, "temporal", "", false, false], [16, 17, 4, 4, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Another", "paper", "presented", "in", "CVPR", "(", "CVPR", ")", "2000", "by", "Erik", "Miller", ",", "Nicholas", "Matsakis", "and", "Paul", "Viola", "will", "also", "be", "discussed", "."], "sentence-detokenized": "Another paper presented in CVPR (CVPR) 2000 by Erik Miller, Nicholas Matsakis and Paul Viola will also be discussed.", "token2charspan": [[0, 7], [8, 13], [14, 23], [24, 26], [27, 31], [32, 33], [33, 37], [37, 38], [39, 43], [44, 46], [47, 51], [52, 58], [58, 59], [60, 68], [69, 77], [78, 81], [82, 86], [87, 92], [93, 97], [98, 102], [103, 105], [106, 115], [115, 116]]}
{"doc_key": "ai-dev-311", "ner": [[0, 0, "algorithm"], [8, 9, "misc"], [12, 14, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 12, 14, "compare", "", false, false], [12, 14, 8, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["QC", "has", "not", "been", "evaluated", "against", "traditional", "modern", "clustering", "algorithms", "other", "than", "the", "Jaccard", "index", "."], "sentence-detokenized": "QC has not been evaluated against traditional modern clustering algorithms other than the Jaccard index.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 15], [16, 25], [26, 33], [34, 45], [46, 52], [53, 63], [64, 74], [75, 80], [81, 85], [86, 89], [90, 97], [98, 103], [103, 104]]}
{"doc_key": "ai-dev-312", "ner": [[1, 5, "misc"], [8, 10, "misc"], [13, 15, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 1, 5, "physical", "", false, false], [8, 10, 13, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "the", "VEX", "Robotics", "World", "Championships", ",", "a", "Parade", "of", "Nations", "is", "organised", "in", "Freedom", "Hall", "with", "hundreds", "of", "students", "from", "more", "than", "30", "countries", "."], "sentence-detokenized": "During the VEX Robotics World Championships, a Parade of Nations is organised in Freedom Hall with hundreds of students from more than 30 countries.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 23], [24, 29], [30, 43], [43, 44], [45, 46], [47, 53], [54, 56], [57, 64], [65, 67], [68, 77], [78, 80], [81, 88], [89, 93], [94, 98], [99, 107], [108, 110], [111, 119], [120, 124], [125, 129], [130, 134], [135, 137], [138, 147], [147, 148]]}
{"doc_key": "ai-dev-313", "ner": [[4, 7, "metrics"], [9, 9, "metrics"], [12, 14, "metrics"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 9, 4, 7, "named", "", false, false], [16, 16, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Other", "accuracy", "measures", "include", "Single", "Word", "Error", "Rate", "(", "SWER", ")", "and", "Command", "Success", "Rate", "(", "CSR", ")", "."], "sentence-detokenized": "Other accuracy measures include Single Word Error Rate (SWER) and Command Success Rate (CSR).", "token2charspan": [[0, 5], [6, 14], [15, 23], [24, 31], [32, 38], [39, 43], [44, 49], [50, 54], [55, 56], [56, 60], [60, 61], [62, 65], [66, 73], [74, 81], [82, 86], [87, 88], [88, 91], [91, 92], [92, 93]]}
{"doc_key": "ai-dev-314", "ner": [[7, 8, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "presented", "their", "methods", "and", "results", "at", "SIGGRAPH", "2000", "."], "sentence-detokenized": "They presented their methods and results at SIGGRAPH 2000.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 28], [29, 32], [33, 40], [41, 43], [44, 52], [53, 57], [57, 58]]}
{"doc_key": "ai-dev-315", "ner": [[0, 2, "conference"], [6, 6, "misc"], [8, 12, "misc"], [15, 17, "conference"], [21, 33, "researcher"], [34, 35, "researcher"], [39, 41, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 6, 6, "origin", "", false, false], [6, 6, 15, 17, "physical", "", false, false], [6, 6, 15, 17, "temporal", "", false, false], [6, 6, 21, 33, "origin", "", false, false], [6, 6, 34, 35, "origin", "", false, false], [8, 12, 6, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "KDD", "Conference", "grew", "out", "of", "KDD", "(", "Knowledge", "Discovery", "and", "Data", "Mining", ")", "workshops", "at", "AAAI", "conferences", ",", "initiated", "by", "Gregory", "I", ".", "Piatetsky", "-", "Shapiro", "in", "1989", ",", "1991", "and", "1993", "and", "Usama", "Fayyad", "in", "1994", ".", "Machinery", "|", "ACM", "."], "sentence-detokenized": "The KDD Conference grew out of KDD (Knowledge Discovery and Data Mining) workshops at AAAI conferences, initiated by Gregory I. Piatetsky-Shapiro in 1989, 1991 and 1993 and Usama Fayyad in 1994. Machinery | ACM.", "token2charspan": [[0, 3], [4, 7], [8, 18], [19, 23], [24, 27], [28, 30], [31, 34], [35, 36], [36, 45], [46, 55], [56, 59], [60, 64], [65, 71], [71, 72], [73, 82], [83, 85], [86, 90], [91, 102], [102, 103], [104, 113], [114, 116], [117, 124], [125, 126], [126, 127], [128, 137], [137, 138], [138, 145], [146, 148], [149, 153], [153, 154], [155, 159], [160, 163], [164, 168], [169, 172], [173, 178], [179, 185], [186, 188], [189, 193], [193, 194], [195, 204], [205, 206], [207, 210], [210, 211]]}
{"doc_key": "ai-dev-316", "ner": [[8, 11, "conference"], [13, 13, "conference"], [16, 21, "organisation"], [23, 23, "organisation"], [26, 30, "conference"], [32, 36, "conference"], [37, 50, "conference"], [43, 43, "conference"], [39, 52, "conference"], [54, 54, "conference"], [57, 62, "conference"], [64, 64, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[13, 13, 8, 11, "named", "", false, false], [23, 23, 16, 21, "named", "", false, false], [32, 36, 26, 30, "named", "", false, false], [43, 43, 37, 50, "named", "", false, false], [54, 54, 39, 52, "named", "", false, false], [64, 64, 57, 62, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["He", "has", "been", "elected", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", "(", "ACM", ")", ",", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", ",", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", ",", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "American", "Association", "for", "the", "Advancement", "of", "Science", "(", "AAAS", ")", "and", "Society", "for", "Optics", "and", "Photonics", "Technology", "(", "SPIE", ")", "."], "sentence-detokenized": "He has been elected a member of the Association for Computing Machinery (ACM), Institute of Electrical and Electronics Engineers (IEEE), International Association for Pattern Recognition (IAPR), Association for the Advancement of Artificial Intelligence (AAAI), American Association for the Advancement of Science (AAAS) and Society for Optics and Photonics Technology (SPIE).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 21], [22, 28], [29, 31], [32, 35], [36, 47], [48, 51], [52, 61], [62, 71], [72, 73], [73, 76], [76, 77], [77, 78], [79, 88], [89, 91], [92, 102], [103, 106], [107, 118], [119, 128], [129, 130], [130, 134], [134, 135], [135, 136], [137, 150], [151, 162], [163, 166], [167, 174], [175, 186], [187, 188], [188, 192], [192, 193], [193, 194], [195, 206], [207, 210], [211, 214], [215, 226], [227, 229], [230, 240], [241, 253], [254, 255], [255, 259], [259, 260], [260, 261], [262, 270], [271, 282], [283, 286], [287, 290], [291, 302], [303, 305], [306, 313], [314, 315], [315, 319], [319, 320], [321, 324], [325, 332], [333, 336], [337, 343], [344, 347], [348, 357], [358, 368], [369, 370], [370, 374], [374, 375], [375, 376]]}
{"doc_key": "ai-dev-317", "ner": [[0, 1, "field"], [3, 4, "field"], [16, 17, "field"], [32, 46, "field"], [54, 57, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 17, "named", "", false, false], [3, 4, 32, 46, "named", "", false, false], [32, 46, 54, 57, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "learning", "and", "data", "mining", "often", "use", "the", "same", "methods", "and", "have", "considerable", "overlap", ",", "but", "machine", "learning", "focuses", "on", "predictions", "based", "on", "known", "features", "lear", "nt", "from", "training", "data", ",", "while", "data", "mining", "focuses", "on", "the", "discovery", "of", "(", "previously", ")", "unknown", "features", "in", "the", "data", "(", "this", "is", "the", "analysis", "step", "of", "knowledge", "discovery", "in", "databases", ")", "."], "sentence-detokenized": "Machine learning and data mining often use the same methods and have considerable overlap, but machine learning focuses on predictions based on known features learnt from training data, while data mining focuses on the discovery of (previously) unknown features in the data (this is the analysis step of knowledge discovery in databases).", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 25], [26, 32], [33, 38], [39, 42], [43, 46], [47, 51], [52, 59], [60, 63], [64, 68], [69, 81], [82, 89], [89, 90], [91, 94], [95, 102], [103, 111], [112, 119], [120, 122], [123, 134], [135, 140], [141, 143], [144, 149], [150, 158], [159, 163], [163, 165], [166, 170], [171, 179], [180, 184], [184, 185], [186, 191], [192, 196], [197, 203], [204, 211], [212, 214], [215, 218], [219, 228], [229, 231], [232, 233], [233, 243], [243, 244], [245, 252], [253, 261], [262, 264], [265, 268], [269, 273], [274, 275], [275, 279], [280, 282], [283, 286], [287, 295], [296, 300], [301, 303], [304, 313], [314, 323], [324, 326], [327, 336], [336, 337], [337, 338]]}
{"doc_key": "ai-dev-318", "ner": [[0, 0, "product"], [3, 4, "programlang"], [11, 11, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 3, 4, "general-affiliation", "", false, false], [0, 0, 3, 4, "related-to", "runs_on", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Indy", "is", "written", "in", "Java", "and", "therefore", "runs", "on", "most", "modern", "operating", "systems", "."], "sentence-detokenized": "Indy is written in Java and therefore runs on most modern operating systems.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 23], [24, 27], [28, 37], [38, 42], [43, 45], [46, 50], [51, 57], [58, 67], [68, 75], [75, 76]]}
{"doc_key": "ai-dev-319", "ner": [[0, 0, "algorithm"], [5, 7, "algorithm"], [9, 9, "algorithm"], [14, 16, "algorithm"], [18, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 7, "type-of", "", true, false], [9, 9, 5, 7, "named", "", false, false], [14, 16, 5, 7, "type-of", "", true, false], [18, 18, 14, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["NMF", "is", "an", "example", "of", "non-negative", "quadratic", "programming", "(", "NQP", ")", ",", "just", "like", "support", "vector", "machine", "(", "SVM", ")", "."], "sentence-detokenized": "NMF is an example of non-negative quadratic programming (NQP), just like support vector machine (SVM).", "token2charspan": [[0, 3], [4, 6], [7, 9], [10, 17], [18, 20], [21, 33], [34, 43], [44, 55], [56, 57], [57, 60], [60, 61], [61, 62], [63, 67], [68, 72], [73, 80], [81, 87], [88, 95], [96, 97], [97, 100], [100, 101], [101, 102]]}
{"doc_key": "ai-dev-320", "ner": [[8, 9, "misc"], [12, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 12, 14, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["The", "method", "is", "based", "on", "the", "estimation", "of", "conditional", "probabilities", "using", "the", "non-parametric", "maximum", "likelihood", "method", "."], "sentence-detokenized": "The method is based on the estimation of conditional probabilities using the non-parametric maximum likelihood method.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 26], [27, 37], [38, 40], [41, 52], [53, 66], [67, 72], [73, 76], [77, 91], [92, 99], [100, 110], [111, 117], [117, 118]]}
{"doc_key": "ai-dev-321", "ner": [[7, 7, "algorithm"], [9, 11, "algorithm"], [13, 15, "metrics"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Basic", "concepts", "related", "to", "spectral", "estimation", "include", "autocorrelation", ",", "multidimensional", "Fourier", "transform", ",", "mean", "square", "error", "and", "entropy", "."], "sentence-detokenized": "Basic concepts related to spectral estimation include autocorrelation, multidimensional Fourier transform, mean square error and entropy.", "token2charspan": [[0, 5], [6, 14], [15, 22], [23, 25], [26, 34], [35, 45], [46, 53], [54, 69], [69, 70], [71, 87], [88, 95], [96, 105], [105, 106], [107, 111], [112, 118], [119, 124], [125, 128], [129, 136], [136, 137]]}
{"doc_key": "ai-dev-322", "ner": [[3, 4, "algorithm"], [9, 9, "field"], [11, 11, "algorithm"], [13, 15, "algorithm"], [17, 18, "task"], [20, 22, "field"], [24, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7, 8], "relations": [[3, 4, 9, 9, "part-of", "", false, false], [3, 4, 11, 11, "part-of", "", false, false], [3, 4, 13, 15, "part-of", "", false, false], [3, 4, 17, 18, "part-of", "", false, false], [3, 4, 20, 22, "part-of", "", false, false], [3, 4, 24, 25, "part-of", "", false, false], [3, 4, 27, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6, 7], "sentence": ["Application", "areas", "of", "kernel", "methods", "are", "diverse", "and", "include", "geostatistics", ",", "kriging", ",", "inverse", "distance", "weighting", ",", "3D", "reconstruction", ",", "bioinformatics", ",", "cheminformatics", ",", "information", "extraction", "and", "handwriting", "recognition", "."], "sentence-detokenized": "Application areas of kernel methods are diverse and include geostatistics, kriging, inverse distance weighting, 3D reconstruction, bioinformatics, cheminformatics, information extraction and handwriting recognition.", "token2charspan": [[0, 11], [12, 17], [18, 20], [21, 27], [28, 35], [36, 39], [40, 47], [48, 51], [52, 59], [60, 73], [73, 74], [75, 82], [82, 83], [84, 91], [92, 100], [101, 110], [110, 111], [112, 114], [115, 129], [129, 130], [131, 145], [145, 146], [147, 162], [162, 163], [164, 175], [176, 186], [187, 190], [191, 202], [203, 214], [214, 215]]}
{"doc_key": "ai-dev-323", "ner": [[12, 12, "organisation"], [14, 18, "product"], [20, 22, "product"], [23, 23, "organisation"], [25, 29, "product"], [31, 31, "product"], [34, 35, "product"], [37, 39, "product"], [41, 43, "product"], [45, 47, "product"], [50, 51, "product"], [53, 64, "product"], [57, 62, "product"], [66, 67, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[14, 18, 12, 12, "artifact", "", false, false], [14, 18, 34, 35, "compare", "", false, false], [14, 18, 37, 39, "compare", "", false, false], [14, 18, 41, 43, "compare", "", false, false], [14, 18, 45, 47, "compare", "", false, false], [14, 18, 50, 51, "compare", "", false, false], [14, 18, 53, 64, "compare", "", false, false], [14, 18, 57, 62, "compare", "", false, false], [14, 18, 66, 67, "compare", "", false, false], [20, 22, 14, 18, "named", "", false, false], [25, 29, 23, 23, "artifact", "", false, false], [25, 29, 34, 35, "compare", "", false, false], [25, 29, 37, 39, "compare", "", false, false], [25, 29, 41, 43, "compare", "", false, false], [25, 29, 45, 47, "compare", "", false, false], [25, 29, 50, 51, "compare", "", false, false], [25, 29, 53, 64, "compare", "", false, false], [25, 29, 57, 62, "compare", "", false, false], [25, 29, 66, 67, "compare", "", false, false], [31, 31, 25, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "sentence": ["Robots", "can", "be", "autonomous", "or", "semi-autonomous", "and", "range", "from", "humanoids", "such", "as", "Honda", "'s", "Advanced", "Step", "in", "Innovative", "Mobility", "(", "ASIMO", ")", "and", "TOSY", "'s", "TOSY", "Ping", "Pong", "Playing", "Robot", "(", "TOPIO", ")", "to", "industrial", "robots", ",", "medical", "surgical", "robots", ",", "patient", "assistance", "robots", ",", "canine", "therapy", "robots", ",", "mass-programmed", "swarm", "robots", ",", "UAV", "drones", "such", "as", "General", "Atomics", "MQ", "-", "1", "Predator", ",", "and", "even", "microscopic", "nanobots", "."], "sentence-detokenized": "Robots can be autonomous or semi-autonomous and range from humanoids such as Honda's Advanced Step in Innovative Mobility (ASIMO) and TOSY's TOSY Ping Pong Playing Robot (TOPIO) to industrial robots, medical surgical robots, patient assistance robots, canine therapy robots, mass-programmed swarm robots, UAV drones such as General Atomics MQ-1 Predator, and even microscopic nanobots.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 24], [25, 27], [28, 43], [44, 47], [48, 53], [54, 58], [59, 68], [69, 73], [74, 76], [77, 82], [82, 84], [85, 93], [94, 98], [99, 101], [102, 112], [113, 121], [122, 123], [123, 128], [128, 129], [130, 133], [134, 138], [138, 140], [141, 145], [146, 150], [151, 155], [156, 163], [164, 169], [170, 171], [171, 176], [176, 177], [178, 180], [181, 191], [192, 198], [198, 199], [200, 207], [208, 216], [217, 223], [223, 224], [225, 232], [233, 243], [244, 250], [250, 251], [252, 258], [259, 266], [267, 273], [273, 274], [275, 290], [291, 296], [297, 303], [303, 304], [305, 308], [309, 315], [316, 320], [321, 323], [324, 331], [332, 339], [340, 342], [342, 343], [343, 344], [345, 353], [353, 354], [355, 358], [359, 363], [364, 375], [376, 384], [384, 385]]}
{"doc_key": "ai-dev-324", "ner": [[0, 0, "product"], [2, 3, "product"], [19, 27, "university"], [8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 8, 9, "artifact", "", false, false], [0, 0, 11, 12, "artifact", "", false, false], [0, 0, 14, 15, "artifact", "", false, false], [0, 0, 17, 18, "artifact", "", false, false], [2, 3, 8, 9, "artifact", "", false, false], [2, 3, 11, 12, "artifact", "", false, false], [2, 3, 14, 15, "artifact", "", false, false], [2, 3, 17, 18, "artifact", "", false, false], [8, 9, 19, 27, "physical", "", false, false], [11, 12, 19, 27, "physical", "", false, false], [14, 15, 19, 27, "physical", "", false, false], [17, 18, 19, 27, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Freddy", "and", "Freddy", "II", "were", "robots", "built", "by", "Pat", "Ambler", ",", "Robin", "Popplestone", ",", "Austin", "Tate", "and", "Donald", "Mitchie", "at", "the", "University", "of", "Edinburgh", "'s", "School", "of", "Informatics", "and", "were", "able", "to", "put", "together", "wooden", "blocks", "in", "a", "few", "hours", "."], "sentence-detokenized": "Freddy and Freddy II were robots built by Pat Ambler, Robin Popplestone, Austin Tate and Donald Mitchie at the University of Edinburgh's School of Informatics and were able to put together wooden blocks in a few hours.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 20], [21, 25], [26, 32], [33, 38], [39, 41], [42, 45], [46, 52], [52, 53], [54, 59], [60, 71], [71, 72], [73, 79], [80, 84], [85, 88], [89, 95], [96, 103], [104, 106], [107, 110], [111, 121], [122, 124], [125, 134], [134, 136], [137, 143], [144, 146], [147, 158], [159, 162], [163, 167], [168, 172], [173, 175], [176, 179], [180, 188], [189, 195], [196, 202], [203, 205], [206, 207], [208, 211], [212, 217], [217, 218]]}
{"doc_key": "ai-dev-325", "ner": [[5, 5, "location"], [6, 7, "country"], [14, 14, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 6, 7, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "spent", "his", "childhood", "in", "Paris", ",", "France", ",", "where", "his", "family", "emigrated", "from", "Lithuania", "in", "the", "early", "1920s", "."], "sentence-detokenized": "He spent his childhood in Paris, France, where his family emigrated from Lithuania in the early 1920s.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 22], [23, 25], [26, 31], [31, 32], [33, 39], [39, 40], [41, 46], [47, 50], [51, 57], [58, 67], [68, 72], [73, 82], [83, 85], [86, 89], [90, 95], [96, 101], [101, 102]]}
{"doc_key": "ai-dev-326", "ner": [[0, 1, "researcher"], [5, 11, "misc"], [12, 15, "organisation"], [17, 19, "university"], [24, 39, "university"], [43, 45, "university"], [48, 50, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 5, 11, "role", "", false, false], [0, 1, 17, 19, "physical", "", false, false], [0, 1, 24, 39, "role", "", false, false], [0, 1, 43, 45, "role", "", false, false], [0, 1, 48, 50, "role", "", false, false], [5, 11, 12, 15, "part-of", "", false, false], [12, 15, 17, 19, "part-of", "", false, false], [43, 45, 24, 39, "part-of", "", false, false], [48, 50, 24, 39, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Dr", "Paulos", "previously", "held", "the", "Cooper-", "Siegel", "Associate", "Professorial", "Chair", "in", "the", "School", "of", "Computer", "Science", "at", "Carnegie", "Mellon", "University", ",", "where", "he", "was", "a", "faculty", "member", "in", "the", "Institute", "for", "Human", "-", "Computer", "Interaction", ",", "as", "well", "as", "a", "faculty", "member", "in", "the", "Robotics", "Institute", "and", "the", "Entertainment", "Technology", "Center", "."], "sentence-detokenized": "Dr Paulos previously held the Cooper-Siegel Associate Professorial Chair in the School of Computer Science at Carnegie Mellon University, where he was a faculty member in the Institute for Human-Computer Interaction, as well as a faculty member in the Robotics Institute and the Entertainment Technology Center.", "token2charspan": [[0, 2], [3, 9], [10, 20], [21, 25], [26, 29], [30, 37], [37, 43], [44, 53], [54, 66], [67, 72], [73, 75], [76, 79], [80, 86], [87, 89], [90, 98], [99, 106], [107, 109], [110, 118], [119, 125], [126, 136], [136, 137], [138, 143], [144, 146], [147, 150], [151, 152], [153, 160], [161, 167], [168, 170], [171, 174], [175, 184], [185, 188], [189, 194], [194, 195], [195, 203], [204, 215], [215, 216], [217, 219], [220, 224], [225, 227], [228, 229], [230, 237], [238, 244], [245, 247], [248, 251], [252, 260], [261, 270], [271, 274], [275, 278], [279, 292], [293, 303], [304, 310], [310, 311]]}
{"doc_key": "ai-dev-327", "ner": [[3, 4, "researcher"], [6, 7, "university"], [9, 11, "product"], [12, 22, "product"], [27, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 6, 7, "physical", "", false, false], [3, 4, 6, 7, "role", "", false, false], [9, 11, 3, 4, "artifact", "", false, false], [9, 11, 12, 22, "type-of", "", false, false], [9, 11, 27, 28, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1969", ",", "Victor", "Scheinman", "of", "Stanford", "University", "invented", "the", "Stanford", "arm", ",", "an", "all", "-", "electric", ",", "6", "-", "axis", "articulated", "robot", "designed", "to", "allow", "an", "arm", "solution", "."], "sentence-detokenized": "In 1969, Victor Scheinman of Stanford University invented the Stanford arm, an all-electric, 6-axis articulated robot designed to allow an arm solution.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 25], [26, 28], [29, 37], [38, 48], [49, 57], [58, 61], [62, 70], [71, 74], [74, 75], [76, 78], [79, 82], [82, 83], [83, 91], [91, 92], [93, 94], [94, 95], [95, 99], [100, 111], [112, 117], [118, 126], [127, 129], [130, 135], [136, 138], [139, 142], [143, 151], [151, 152]]}
{"doc_key": "ai-dev-328", "ner": [[4, 6, "product"], [15, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 15, 16, "related-to", "", false, false], [4, 6, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "creation", "and", "implementation", "of", "chatbots", "is", "still", "an", "emerging", "field", ",", "largely", "related", "to", "artificial", "intelligence", "and", "machine", "learning", ",", "so", "the", "solutions", "provided", ",", "while", "having", "obvious", "advantages", ",", "have", "some", "significant", "limitations", "in", "terms", "of", "functionality", "and", "use", "cases", "."], "sentence-detokenized": "The creation and implementation of chatbots is still an emerging field, largely related to artificial intelligence and machine learning, so the solutions provided, while having obvious advantages, have some significant limitations in terms of functionality and use cases.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 31], [32, 34], [35, 43], [44, 46], [47, 52], [53, 55], [56, 64], [65, 70], [70, 71], [72, 79], [80, 87], [88, 90], [91, 101], [102, 114], [115, 118], [119, 126], [127, 135], [135, 136], [137, 139], [140, 143], [144, 153], [154, 162], [162, 163], [164, 169], [170, 176], [177, 184], [185, 195], [195, 196], [197, 201], [202, 206], [207, 218], [219, 230], [231, 233], [234, 239], [240, 242], [243, 256], [257, 260], [261, 264], [265, 270], [270, 271]]}
{"doc_key": "ai-dev-329", "ner": [[6, 8, "university"], [10, 11, "product"], [23, 26, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 6, 8, "part-of", "", true, false], [23, 26, 10, 11, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "terms", "of", "free", "resources", ",", "Carnegie", "Mellon", "University", "'s", "Sphinx", "toolkit", "is", "a", "good", "place", "to", "start", ",", "both", "to", "learn", "about", "speech", "recognition", "and", "to", "start", "experimenting", "."], "sentence-detokenized": "In terms of free resources, Carnegie Mellon University's Sphinx toolkit is a good place to start, both to learn about speech recognition and to start experimenting.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 16], [17, 26], [26, 27], [28, 36], [37, 43], [44, 54], [54, 56], [57, 63], [64, 71], [72, 74], [75, 76], [77, 81], [82, 87], [88, 90], [91, 96], [96, 97], [98, 102], [103, 105], [106, 111], [112, 117], [118, 124], [125, 136], [137, 140], [141, 143], [144, 149], [150, 163], [163, 164]]}
{"doc_key": "ai-dev-330", "ner": [[2, 5, "misc"], [9, 15, "misc"], [17, 17, "misc"], [31, 31, "university"], [25, 27, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 5, 9, 15, "temporal", "", false, false], [17, 17, 9, 15, "named", "", false, false], [17, 17, 25, 27, "physical", "", false, false], [31, 31, 17, 17, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Prior", "to", "the", "official", "RoboCup", "competition", ",", "the", "first", "International", "Micro", "Robot", "World", "Cup", "Football", "Tournament", "(", "MIROSOT", ")", "was", "held", "in", "November", "1996", "in", "Taejon", ",", "Korea", ",", "organised", "by", "KAIST", "(", "not", "generally", "recognised", ")", "."], "sentence-detokenized": "Prior to the official RoboCup competition, the first International Micro Robot World Cup Football Tournament (MIROSOT) was held in November 1996 in Taejon, Korea, organised by KAIST (not generally recognised).", "token2charspan": [[0, 5], [6, 8], [9, 12], [13, 21], [22, 29], [30, 41], [41, 42], [43, 46], [47, 52], [53, 66], [67, 72], [73, 78], [79, 84], [85, 88], [89, 97], [98, 108], [109, 110], [110, 117], [117, 118], [119, 122], [123, 127], [128, 130], [131, 139], [140, 144], [145, 147], [148, 154], [154, 155], [156, 161], [161, 162], [163, 172], [173, 175], [176, 181], [182, 183], [183, 186], [187, 196], [197, 207], [207, 208], [208, 209]]}
{"doc_key": "ai-dev-331", "ner": [[5, 6, "metrics"], [23, 24, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", "to", "the", "standard", "hinge", "loss", "maths", "(", "1-", "yf", "(", "x", ")", ")", "Maths", "for", "data", "labelled", "_", "+", "/,", "a", "loss", "function", "maths", "(", "-", "1", "|", "f", "(", "x", ")", "|", ")", "_", "+", "/", "maths", "is", "introduced", "over", "unlabelled", "data", "by", "allowing", "mathy", "=\\", "operatorname", "{", "sign", "}", "{", "f", "(", "x", ")", "}", "/", "math", "."], "sentence-detokenized": "In addition to the standard hinge loss maths (1-yf (x)) Maths for data labelled _ + /, a loss function maths (-1 | f (x) |) _ + / maths is introduced over unlabelled data by allowing mathy =\\ operatorname {sign} {f (x)} / math.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 27], [28, 33], [34, 38], [39, 44], [45, 46], [46, 48], [48, 50], [51, 52], [52, 53], [53, 54], [54, 55], [56, 61], [62, 65], [66, 70], [71, 79], [80, 81], [82, 83], [84, 86], [87, 88], [89, 93], [94, 102], [103, 108], [109, 110], [110, 111], [111, 112], [113, 114], [115, 116], [117, 118], [118, 119], [119, 120], [121, 122], [122, 123], [124, 125], [126, 127], [128, 129], [130, 135], [136, 138], [139, 149], [150, 154], [155, 165], [166, 170], [171, 173], [174, 182], [183, 188], [189, 191], [192, 204], [205, 206], [206, 210], [210, 211], [212, 213], [213, 214], [215, 216], [216, 217], [217, 218], [218, 219], [220, 221], [222, 226], [226, 227]]}
{"doc_key": "ai-dev-332", "ner": [[3, 3, "misc"], [8, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 8, 11, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "particular", ",", "RLS", "is", "designed", "to", "minimise", "the", "mean", "squared", "error", "between", "predicted", "values", "and", "TRUE", "labels", "and", "is", "subject", "to", "regularisation", "."], "sentence-detokenized": "In particular, RLS is designed to minimise the mean squared error between predicted values and TRUE labels and is subject to regularisation.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 21], [22, 30], [31, 33], [34, 42], [43, 46], [47, 51], [52, 59], [60, 65], [66, 73], [74, 83], [84, 90], [91, 94], [95, 99], [100, 106], [107, 110], [111, 113], [114, 121], [122, 124], [125, 139], [139, 140]]}
{"doc_key": "ai-dev-333", "ner": [[3, 5, "algorithm"], [8, 9, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 5, 8, 9, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Essentially", "this", "combines", "maximum", "likelihood", "estimation", "with", "a", "regularisation", "procedure", "that", "favours", "simpler", "models", "over", "more", "complex", "models", "."], "sentence-detokenized": "Essentially this combines maximum likelihood estimation with a regularisation procedure that favours simpler models over more complex models.", "token2charspan": [[0, 11], [12, 16], [17, 25], [26, 33], [34, 44], [45, 55], [56, 60], [61, 62], [63, 77], [78, 87], [88, 92], [93, 100], [101, 108], [109, 115], [116, 120], [121, 125], [126, 133], [134, 140], [140, 141]]}
{"doc_key": "ai-dev-334", "ner": [[0, 6, "metrics"], [7, 8, "metrics"], [41, 41, "metrics"], [37, 38, "misc"], [39, 44, "misc"], [18, 20, "algorithm"], [21, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 8, 0, 6, "named", "", false, false], [41, 41, 0, 6, "named", "", false, false], [37, 38, 39, 44, "related-to", "", false, false], [37, 38, 18, 20, "related-to", "ratio", false, false], [18, 20, 21, 25, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "true", "-", "positive", "rate", "is", "the", "sensitivity", "of", "the", "detection", "probability", "on", "the", "y", "-axis", "to", "the", "cumulative", "distribution", "function", "of", "the", "false", "alarm", "probability", "on", "the", "x", "-", "axis", ",", "also", "known", "as", "the", "mathematical", "detection", "probability", "to", "the", "recall", "or", "discrimination", "threshold", "."], "sentence-detokenized": "The true-positive rate is the sensitivity of the detection probability on the y-axis to the cumulative distribution function of the false alarm probability on the x-axis, also known as the mathematical detection probability to the recall or discrimination threshold.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 17], [18, 22], [23, 25], [26, 29], [30, 41], [42, 44], [45, 48], [49, 58], [59, 70], [71, 73], [74, 77], [78, 79], [79, 84], [85, 87], [88, 91], [92, 102], [103, 115], [116, 124], [125, 127], [128, 131], [132, 137], [138, 143], [144, 155], [156, 158], [159, 162], [163, 164], [164, 165], [165, 169], [169, 170], [171, 175], [176, 181], [182, 184], [185, 188], [189, 201], [202, 211], [212, 223], [224, 226], [227, 230], [231, 237], [238, 240], [241, 255], [256, 265], [265, 266]]}
{"doc_key": "ai-dev-335", "ner": [[3, 4, "product"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "English", ",", "Word", "Net", "is", "an", "example", "of", "a", "semantic", "network", "."], "sentence-detokenized": "In English, WordNet is an example of a semantic network.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 16], [16, 19], [20, 22], [23, 25], [26, 33], [34, 36], [37, 38], [39, 47], [48, 55], [55, 56]]}
{"doc_key": "ai-dev-336", "ner": [[5, 7, "product"], [10, 13, "product"], [21, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 22, 5, 7, "usage", "", false, false], [21, 22, 10, 13, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Long", "-", "term", "use", "of", "speech", "recognition", "software", "in", "combination", "with", "word", "processors", "has", "benefited", "short", "-", "term", "memory", "retraining", "in", "brain", "AVM", "patients", "treated", "with", "resection", "."], "sentence-detokenized": "Long-term use of speech recognition software in combination with word processors has benefited short-term memory retraining in brain AVM patients treated with resection.", "token2charspan": [[0, 4], [4, 5], [5, 9], [10, 13], [14, 16], [17, 23], [24, 35], [36, 44], [45, 47], [48, 59], [60, 64], [65, 69], [70, 80], [81, 84], [85, 94], [95, 100], [100, 101], [101, 105], [106, 112], [113, 123], [124, 126], [127, 132], [133, 136], [137, 145], [146, 153], [154, 158], [159, 168], [168, 169]]}
{"doc_key": "ai-dev-337", "ner": [[8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "founding", "editors", "-", "in", "-", "chief", "were", "Ron", "Sun", ",", "Vasant", "Honavar", "and", "Gregg", "Oden", "(", "from", "1999", "to", "2014", ")", "."], "sentence-detokenized": "The founding editors-in-chief were Ron Sun, Vasant Honavar and Gregg Oden (from 1999 to 2014).", "token2charspan": [[0, 3], [4, 12], [13, 20], [20, 21], [21, 23], [23, 24], [24, 29], [30, 34], [35, 38], [39, 42], [42, 43], [44, 50], [51, 58], [59, 62], [63, 68], [69, 73], [74, 75], [75, 79], [80, 84], [85, 87], [88, 92], [92, 93], [93, 94]]}
{"doc_key": "ai-dev-338", "ner": [[9, 10, "product"], [15, 23, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 10, 15, 23, "opposite", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["'", "Parallel", "'", "separations", ",", "as", "opposed", "to", "a", "series", "manipulator", ",", "is", "that", "the", "end", "effector", "(", "or", "'", "hand", "'", ")", "of", "this", "link", "(", "or", "'", "arm", "'", ")", "is", "connected", "directly", "to", "it", "s", "base", "by", "a", "series", "(", "usually", "three", "or", "six", ")", "of", "separate", "and", "independent", "links", "operating", "simultaneously", "."], "sentence-detokenized": "'Parallel' separations, as opposed to a series manipulator, is that the end effector (or 'hand') of this link (or 'arm') is connected directly to its base by a series (usually three or six) of separate and independent links operating simultaneously.", "token2charspan": [[0, 1], [1, 9], [9, 10], [11, 22], [22, 23], [24, 26], [27, 34], [35, 37], [38, 39], [40, 46], [47, 58], [58, 59], [60, 62], [63, 67], [68, 71], [72, 75], [76, 84], [85, 86], [86, 88], [89, 90], [90, 94], [94, 95], [95, 96], [97, 99], [100, 104], [105, 109], [110, 111], [111, 113], [114, 115], [115, 118], [118, 119], [119, 120], [121, 123], [124, 133], [134, 142], [143, 145], [146, 148], [148, 149], [150, 154], [155, 157], [158, 159], [160, 166], [167, 168], [168, 175], [176, 181], [182, 184], [185, 188], [188, 189], [190, 192], [193, 201], [202, 205], [206, 217], [218, 223], [224, 233], [234, 248], [248, 249]]}
{"doc_key": "ai-dev-339", "ner": [[5, 6, "researcher"], [15, 16, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 27, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "thesis", "supervisor", "was", "Professor", "Cordell", "Green", "and", "his", "thesis", "/", "oral", "committee", "included", "Professors", "Edward", "Feigenbaum", "Joshua", "Lederberg", ",", "Paul", "Cohen", ",", "Allen", "Newell", ",", "Herbert", "Simon", "."], "sentence-detokenized": "His thesis supervisor was Professor Cordell Green and his thesis/ oral committee included Professors Edward Feigenbaum Joshua Lederberg, Paul Cohen, Allen Newell, Herbert Simon.", "token2charspan": [[0, 3], [4, 10], [11, 21], [22, 25], [26, 35], [36, 43], [44, 49], [50, 53], [54, 57], [58, 64], [64, 65], [66, 70], [71, 80], [81, 89], [90, 100], [101, 107], [108, 118], [119, 125], [126, 135], [135, 136], [137, 141], [142, 147], [147, 148], [149, 154], [155, 161], [161, 162], [163, 170], [171, 176], [176, 177]]}
{"doc_key": "ai-dev-340", "ner": [[4, 5, "metrics"], [7, 10, "metrics"], [12, 14, "metrics"], [16, 18, "metrics"], [20, 25, "metrics"], [26, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "functions", "include", "mean", "square", "error", ",", "root", "mean", "square", "error", ",", "mean", "absolute", "error", ",", "relative", "square", "error", ",", "root", "relative", "square", "error", ",", "relative", "absolute", "error", "and", "others", "."], "sentence-detokenized": "Such functions include mean square error, root mean square error, mean absolute error, relative square error, root relative square error, relative absolute error and others.", "token2charspan": [[0, 4], [5, 14], [15, 22], [23, 27], [28, 34], [35, 40], [40, 41], [42, 46], [47, 51], [52, 58], [59, 64], [64, 65], [66, 70], [71, 79], [80, 85], [85, 86], [87, 95], [96, 102], [103, 108], [108, 109], [110, 114], [115, 123], [124, 130], [131, 136], [136, 137], [138, 146], [147, 155], [156, 161], [162, 165], [166, 172], [172, 173]]}
{"doc_key": "ai-dev-341", "ner": [[0, 0, "programlang"], [2, 2, "programlang"], [4, 6, "programlang"]], "ner_mapping_to_source": [0, 1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Python", ",", "Java", "and", "MATLAB", "/", "OCTAVE", "have", "connectors", "."], "sentence-detokenized": "Python, Java and MATLAB/OCTAVE have connectors.", "token2charspan": [[0, 6], [6, 7], [8, 12], [13, 16], [17, 23], [23, 24], [24, 30], [31, 35], [36, 46], [46, 47]]}
{"doc_key": "ai-dev-342", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "implementation", "in", "MATLAB", "can", "be", "found", "here", "."], "sentence-detokenized": "An implementation in MATLAB can be found here.", "token2charspan": [[0, 2], [3, 17], [18, 20], [21, 27], [28, 31], [32, 34], [35, 40], [41, 45], [45, 46]]}
{"doc_key": "ai-dev-343", "ner": [[0, 1, "researcher"], [8, 10, "field"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 10, 0, 1, "origin", "", false, false], [8, 10, 13, 14, "origin", "", false, false], [8, 10, 16, 17, "origin", "", false, false], [8, 10, 19, 20, "origin", "", false, false], [8, 10, 22, 25, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["John", "McCarthy", "is", "one", "of", "the", "founding", "fathers", "of", "artificial", "intelligence", "along", "with", "Alan", "Turing", ",", "Marvin", "Minsky", ",", "Allen", "Newell", "and", "Herbert", "A", ".", "Simon", "."], "sentence-detokenized": "John McCarthy is one of the founding fathers of artificial intelligence along with Alan Turing, Marvin Minsky, Allen Newell and Herbert A. Simon.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 23], [24, 27], [28, 36], [37, 44], [45, 47], [48, 58], [59, 71], [72, 77], [78, 82], [83, 87], [88, 94], [94, 95], [96, 102], [103, 109], [109, 110], [111, 116], [117, 123], [124, 127], [128, 135], [136, 137], [137, 138], [139, 144], [144, 145]]}
{"doc_key": "ai-dev-344", "ner": [[2, 11, "product"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "parallel", "manipulator", "is", "a", "mechanical", "system", "that", "uses", "several", "serial", "manipulators", "to", "support", "a", "single", "platform", "or", "end", "effector", "."], "sentence-detokenized": "A parallel manipulator is a mechanical system that uses several serial manipulators to support a single platform or end effector.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 27], [28, 38], [39, 45], [46, 50], [51, 55], [56, 63], [64, 70], [71, 83], [84, 86], [87, 94], [95, 96], [97, 103], [104, 112], [113, 115], [116, 119], [120, 128], [128, 129]]}
{"doc_key": "ai-dev-345", "ner": [[0, 0, "product"], [3, 6, "task"], [7, 7, "product"], [9, 15, "product"], [27, 27, "misc"], [30, 32, "misc"], [33, 34, "misc"], [37, 45, "task"], [46, 48, "product"], [51, 52, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 7, 0, 0, "part-of", "", false, false], [7, 7, 3, 6, "type-of", "", false, false], [9, 15, 7, 7, "named", "", false, false], [27, 27, 7, 7, "part-of", "", false, false], [30, 32, 7, 7, "part-of", "", false, false], [33, 34, 7, 7, "part-of", "", false, false], [37, 45, 7, 7, "part-of", "", false, false], [46, 48, 7, 7, "part-of", "", false, false], [51, 52, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["GATE", "includes", "an", "information", "extraction", "system", "called", "ANNIE", "(", "A", "Nearly", "-", "New", "Information", "Extraction", "System", ")", ",", "which", "consists", "of", "a", "set", "of", "modules", "including", "a", "tokeniser", ",", "a", "gazetteer", ",", "a", "sentence", "separator", ",", "a", "Part", "-", "of", "-", "speech", "tagger", ",", "a", "Named", "entity", "recognition", "transducer", "and", "a", "coreference", "tagger", "."], "sentence-detokenized": "GATE includes an information extraction system called ANNIE (A Nearly-New Information Extraction System), which consists of a set of modules including a tokeniser, a gazetteer, a sentence separator, a Part-of-speech tagger, a Named entity recognition transducer and a coreference tagger.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 28], [29, 39], [40, 46], [47, 53], [54, 59], [60, 61], [61, 62], [63, 69], [69, 70], [70, 73], [74, 85], [86, 96], [97, 103], [103, 104], [104, 105], [106, 111], [112, 120], [121, 123], [124, 125], [126, 129], [130, 132], [133, 140], [141, 150], [151, 152], [153, 162], [162, 163], [164, 165], [166, 175], [175, 176], [177, 178], [179, 187], [188, 197], [197, 198], [199, 200], [201, 205], [205, 206], [206, 208], [208, 209], [209, 215], [216, 222], [222, 223], [224, 225], [226, 231], [232, 238], [239, 250], [251, 261], [262, 265], [266, 267], [268, 279], [280, 286], [286, 287]]}
{"doc_key": "ai-dev-346", "ner": [[2, 5, "university"], [7, 11, "country"], [20, 24, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "graduated", "from", "Moscow", "State", "University", "and", "travelled", "to", "the", "United", "States", "in", "November", "1978", "thanks", "to", "the", "personal", "intervention", "of", "Senator", "Edward", "M.", "Kennedy", "."], "sentence-detokenized": "He graduated from Moscow State University and travelled to the United States in November 1978 thanks to the personal intervention of Senator Edward M. Kennedy.", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 24], [25, 30], [31, 41], [42, 45], [46, 55], [56, 58], [59, 62], [63, 69], [70, 76], [77, 79], [80, 88], [89, 93], [94, 100], [101, 103], [104, 107], [108, 116], [117, 129], [130, 132], [133, 140], [141, 147], [148, 150], [151, 158], [158, 159]]}
{"doc_key": "ai-dev-347", "ner": [[3, 17, "organisation"], [8, 12, "misc"], [18, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 17, 8, 12, "win-defeat", "", false, false], [8, 12, 18, 18, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2017", ",", "the", "DeepMind", "AlphaGo", "team", "received", "the", "IJCAI", "Marvin", "Minsky", "medal", "for", "Outstanding", "Achievements", "in", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2017, the DeepMind AlphaGo team received the IJCAI Marvin Minsky medal for Outstanding Achievements in Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 21], [22, 29], [30, 34], [35, 43], [44, 47], [48, 53], [54, 60], [61, 67], [68, 73], [74, 77], [78, 89], [90, 102], [103, 105], [106, 116], [117, 129], [129, 130]]}
{"doc_key": "ai-dev-348", "ner": [[4, 5, "misc"], [9, 14, "misc"], [12, 14, "misc"], [21, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 9, 14, "related-to", "is_recorded_by", false, false], [9, 14, 12, 14, "cause-effect", "", false, false], [9, 14, 12, 14, "physical", "", false, false], [9, 14, 21, 28, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Other", "ways", "in", "which", "anomalous", "propagation", "is", "recorded", "are", "troposcatters", "causing", "irregularities", "in", "the", "troposphere", ",", "scattering", "from", "meteorites", ",", "refraction", "in", "ionised", "regions", "and", "layers", "of", "the", "ionosphere", ",", "and", "reflection", "from", "the", "ionosphere", "."], "sentence-detokenized": "Other ways in which anomalous propagation is recorded are troposcatters causing irregularities in the troposphere, scattering from meteorites, refraction in ionised regions and layers of the ionosphere, and reflection from the ionosphere.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 19], [20, 29], [30, 41], [42, 44], [45, 53], [54, 57], [58, 71], [72, 79], [80, 94], [95, 97], [98, 101], [102, 113], [113, 114], [115, 125], [126, 130], [131, 141], [141, 142], [143, 153], [154, 156], [157, 164], [165, 172], [173, 176], [177, 183], [184, 186], [187, 190], [191, 201], [201, 202], [203, 206], [207, 217], [218, 222], [223, 226], [227, 237], [237, 238]]}
{"doc_key": "ai-dev-349", "ner": [[0, 2, "field"], [4, 4, "field"], [10, 12, "field"], [13, 26, "field"], [15, 17, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 10, 12, "part-of", "", false, false], [0, 2, 13, 26, "part-of", "", false, false], [0, 2, 15, 17, "part-of", "", false, false], [0, 2, 18, 19, "part-of", "", false, false], [4, 4, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Natural", "language", "processing", "(", "NLP", ")", "is", "a", "subfield", "of", "linguistics", ",", "computer", "science", ",", "information", "engineering", "and", "artificial", "intelligence", "that", "deals", "with", "the", "interactions", "between", "computers", "and", "human", "(", "natural", ")", "languages", ",", "in", "particular", "how", "to", "program", "computers", "to", "process", "and", "analyse", "large", "amounts", "of", "natural", "language", "data", "."], "sentence-detokenized": "Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering and artificial intelligence that deals with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyse large amounts of natural language data.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 29], [29, 32], [32, 33], [34, 36], [37, 38], [39, 47], [48, 50], [51, 62], [62, 63], [64, 72], [73, 80], [80, 81], [82, 93], [94, 105], [106, 109], [110, 120], [121, 133], [134, 138], [139, 144], [145, 149], [150, 153], [154, 166], [167, 174], [175, 184], [185, 188], [189, 194], [195, 196], [196, 203], [203, 204], [205, 214], [214, 215], [216, 218], [219, 229], [230, 233], [234, 236], [237, 244], [245, 254], [255, 257], [258, 265], [266, 269], [270, 277], [278, 283], [284, 291], [292, 294], [295, 302], [303, 311], [312, 316], [316, 317]]}
{"doc_key": "ai-dev-350", "ner": [[8, 9, "organisation"], [11, 12, "organisation"], [14, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "active", "youth", "-", "led", "climate", "groups", "include", "Extinction", "Rebellion", ",", "Sunrise", "Movement", ",", "SustainUS", "and", "others", "working", "at", "both", "transnational", "and", "local", "levels", "."], "sentence-detokenized": "Other active youth-led climate groups include Extinction Rebellion, Sunrise Movement, SustainUS and others working at both transnational and local levels.", "token2charspan": [[0, 5], [6, 12], [13, 18], [18, 19], [19, 22], [23, 30], [31, 37], [38, 45], [46, 56], [57, 66], [66, 67], [68, 75], [76, 84], [84, 85], [86, 95], [96, 99], [100, 106], [107, 114], [115, 117], [118, 122], [123, 136], [137, 140], [141, 146], [147, 153], [153, 154]]}
