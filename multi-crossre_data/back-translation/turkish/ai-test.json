{"doc_key": "ai-test-1", "ner": [[5, 7, "algorithm"], [9, 10, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "generative", "model", "approaches", "include", "naive", "Bayesian", "classifiers", ",", "Gaussian", "mixture", "models", ",", "variational", "autoencoders", "and", "others", "."], "sentence-detokenized": "Typical generative model approaches include naive Bayesian classifiers, Gaussian mixture models, variational autoencoders and others.", "token2charspan": [[0, 7], [8, 18], [19, 24], [25, 35], [36, 43], [44, 49], [50, 58], [59, 70], [70, 71], [72, 80], [81, 88], [89, 95], [95, 96], [97, 108], [109, 121], [122, 125], [126, 132], [132, 133]]}
{"doc_key": "ai-test-2", "ner": [[5, 5, "organisation"], [7, 7, "conference"], [10, 16, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 7, 7, "role", "", false, false], [10, 16, 7, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Finally", ",", "every", "two", "years", "ELRA", "organises", "LREC", ",", "the", "International", "Conference", "on", "Language", "Resources", "and", "Evaluation", "."], "sentence-detokenized": "Finally, every two years ELRA organises LREC, the International Conference on Language Resources and Evaluation.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 18], [19, 24], [25, 29], [30, 39], [40, 44], [44, 45], [46, 49], [50, 63], [64, 74], [75, 77], [78, 86], [87, 96], [97, 100], [101, 111], [111, 112]]}
{"doc_key": "ai-test-3", "ner": [[6, 9, "algorithm"], [12, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "task", "is", "usually", "to", "derive", "a", "maximum", "likelihood", "estimate", "of", "the", "HMM", "parameters", "given", "the", "output", "sequences", "."], "sentence-detokenized": "The task is usually to derive a maximum likelihood estimate of the HMM parameters given the output sequences.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 19], [20, 22], [23, 29], [30, 31], [32, 39], [40, 50], [51, 59], [60, 62], [63, 66], [67, 70], [71, 81], [82, 87], [88, 91], [92, 98], [99, 108], [108, 109]]}
{"doc_key": "ai-test-4", "ner": [[1, 1, "algorithm"], [4, 6, "algorithm"], [9, 9, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 9, 9, "compare", "", false, false], [4, 6, 9, 9, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Unlike", "neural", "networks", "and", "Support", "vector", "machine", ",", "the", "AdaBoost", "training", "process", "selects", "only", "features", "known", "to", "improve", "the", "predictive", "power", "of", "the", "model", ",", "reducing", "dimensionality", "and", "potentially", "improving", "execution", "time", "as", "irrelevant", "features", "need", "not", "be", "computed", "."], "sentence-detokenized": "Unlike neural networks and Support vector machine, the AdaBoost training process selects only features known to improve the predictive power of the model, reducing dimensionality and potentially improving execution time as irrelevant features need not be computed.", "token2charspan": [[0, 6], [7, 13], [14, 22], [23, 26], [27, 34], [35, 41], [42, 49], [49, 50], [51, 54], [55, 63], [64, 72], [73, 80], [81, 88], [89, 93], [94, 102], [103, 108], [109, 111], [112, 119], [120, 123], [124, 134], [135, 140], [141, 143], [144, 147], [148, 153], [153, 154], [155, 163], [164, 178], [179, 182], [183, 194], [195, 204], [205, 214], [215, 219], [220, 222], [223, 233], [234, 242], [243, 247], [248, 251], [252, 254], [255, 263], [263, 264]]}
{"doc_key": "ai-test-5", "ner": [[0, 0, "misc"], [11, 11, "misc"], [10, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 11, "part-of", "", false, false], [11, 11, 10, 17, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Troponymy", "is", "one", "of", "the", "possible", "relations", "between", "verbs", "in", "the", "semantic", "network", "of", "the", "Word", "Net", "database", "."], "sentence-detokenized": "Troponymy is one of the possible relations between verbs in the semantic network of the WordNet database.", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 19], [20, 23], [24, 32], [33, 42], [43, 50], [51, 56], [57, 59], [60, 63], [64, 72], [73, 80], [81, 83], [84, 87], [88, 92], [92, 95], [96, 104], [104, 105]]}
{"doc_key": "ai-test-6", "ner": [[7, 8, "task"], [9, 11, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 9, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "framework", "language", "is", "a", "technology", "for", "knowledge", "representation", "in", "artificial", "intelligence", "."], "sentence-detokenized": "A framework language is a technology for knowledge representation in artificial intelligence.", "token2charspan": [[0, 1], [2, 11], [12, 20], [21, 23], [24, 25], [26, 36], [37, 40], [41, 50], [51, 65], [66, 68], [69, 79], [80, 92], [92, 93]]}
{"doc_key": "ai-test-7", "ner": [[0, 0, "metrics"], [3, 7, "metrics"], [10, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 3, 7, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "the", "Bilingual", "evaluation", "stunt", "in", "calculating", "the", "brevity", "penalty", ",", "to", "the", "extent", "that", "small", "differences", "in", "translation", "length", "do", "not", "affect", "the", "overall", "score", "too", "much", "."], "sentence-detokenized": "NIST also differs from the Bilingual evaluation stunt in calculating the brevity penalty, to the extent that small differences in translation length do not affect the overall score too much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 26], [27, 36], [37, 47], [48, 53], [54, 56], [57, 68], [69, 72], [73, 80], [81, 88], [88, 89], [90, 92], [93, 96], [97, 103], [104, 108], [109, 114], [115, 126], [127, 129], [130, 141], [142, 148], [149, 151], [152, 155], [156, 162], [163, 166], [167, 174], [175, 180], [181, 184], [185, 189], [189, 190]]}
{"doc_key": "ai-test-8", "ner": [[16, 17, "algorithm"], [19, 21, "algorithm"], [31, 33, "field"], [42, 43, "algorithm"], [45, 47, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 17, 31, 33, "usage", "", false, false], [19, 21, 31, 33, "usage", "", false, false], [42, 43, 31, 33, "type-of", "", false, false], [45, 47, 31, 33, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "model", "is", "initially", "placed", "on", "a", "training", "data", "set", ",", "The", "model", "(", "e.g.", "a", "neural", "network", "or", "naive", "Bayes", "classifier", ")", "is", "trained", "on", "the", "training", "data", "set", "using", "a", "supervised", "learning", "method", ",", "e.g.", "using", "optimisation", "methods", "such", "as", "gradient", "descent", "or", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The model is initially placed on a training data set, The model (e.g. a neural network or naive Bayes classifier) is trained on the training data set using a supervised learning method, e.g. using optimisation methods such as gradient descent or stochastic gradient descent.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 22], [23, 29], [30, 32], [33, 34], [35, 43], [44, 48], [49, 52], [52, 53], [54, 57], [58, 63], [64, 65], [65, 69], [70, 71], [72, 78], [79, 86], [87, 89], [90, 95], [96, 101], [102, 112], [112, 113], [114, 116], [117, 124], [125, 127], [128, 131], [132, 140], [141, 145], [146, 149], [150, 155], [156, 157], [158, 168], [169, 177], [178, 184], [184, 185], [186, 190], [191, 196], [197, 209], [210, 217], [218, 222], [223, 225], [226, 234], [235, 242], [243, 245], [246, 256], [257, 265], [266, 273], [273, 274]]}
{"doc_key": "ai-test-9", "ner": [[0, 0, "product"], [15, 16, "task"], [18, 18, "task"], [20, 22, "task"], [24, 25, "task"], [7, 9, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[15, 16, 0, 0, "usage", "", true, false], [18, 18, 0, 0, "usage", "", true, false], [20, 22, 0, 0, "usage", "", true, false], [24, 25, 0, 0, "usage", "", true, false], [7, 9, 0, 0, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["FrameNet", "has", "been", "used", "directly", "or", "via", "Semantic", "Role", "Labelling", "tools", "in", "applications", "such", "as", "question", "answering", ",", "paraphrasing", ",", "textual", "entailment", "recognition", "and", "information", "extraction", "."], "sentence-detokenized": "FrameNet has been used directly or via Semantic Role Labelling tools in applications such as question answering, paraphrasing, textual entailment recognition and information extraction.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 22], [23, 31], [32, 34], [35, 38], [39, 47], [48, 52], [53, 62], [63, 68], [69, 71], [72, 84], [85, 89], [90, 92], [93, 101], [102, 111], [111, 112], [113, 125], [125, 126], [127, 134], [135, 145], [146, 157], [158, 161], [162, 173], [174, 184], [184, 185]]}
{"doc_key": "ai-test-10", "ner": [[5, 6, "field"], [11, 11, "misc"], [14, 14, "product"], [17, 17, "misc"], [20, 20, "product"], [23, 26, "field"], [27, 27, "product"], [30, 32, "misc"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [42, 43, "misc"], [46, 47, "product"], [49, 50, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[14, 14, 11, 11, "general-affiliation", "", false, false], [20, 20, 17, 17, "general-affiliation", "", false, false], [27, 27, 23, 26, "general-affiliation", "", false, false], [35, 35, 30, 32, "type-of", "", false, false], [37, 37, 30, 32, "type-of", "", false, false], [39, 39, 30, 32, "type-of", "", false, false], [46, 47, 42, 43, "general-affiliation", "", false, false], [49, 50, 42, 43, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["This", "includes", "programmes", "such", "as", "data", "analysis", "and", "extraction", "tools", ",", "spreadsheets", "(", "e.g.", "Excel", ")", ",", "databases", "(", "e.g.", "Access", ")", ",", "statistical", "analysis", "(", "e.g.", "SAS", ")", ",", "generalised", "audit", "software", "(", "e.g.", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "business", "intelligence", "(", "e.g.", "Crystal", "Reports", "and", "Business", "Objects", ")", ",", "etc", "."], "sentence-detokenized": "This includes programmes such as data analysis and extraction tools, spreadsheets (e.g. Excel), databases (e.g. Access), statistical analysis (e.g. SAS), generalised audit software (e.g. ACL, Arbutus, EAS), business intelligence (e.g. Crystal Reports and Business Objects), etc.", "token2charspan": [[0, 4], [5, 13], [14, 24], [25, 29], [30, 32], [33, 37], [38, 46], [47, 50], [51, 61], [62, 67], [67, 68], [69, 81], [82, 83], [83, 87], [88, 93], [93, 94], [94, 95], [96, 105], [106, 107], [107, 111], [112, 118], [118, 119], [119, 120], [121, 132], [133, 141], [142, 143], [143, 147], [148, 151], [151, 152], [152, 153], [154, 165], [166, 171], [172, 180], [181, 182], [182, 186], [187, 190], [190, 191], [192, 199], [199, 200], [201, 204], [204, 205], [205, 206], [207, 215], [216, 228], [229, 230], [230, 234], [235, 242], [243, 250], [251, 254], [255, 263], [264, 271], [271, 272], [272, 273], [274, 277], [277, 278]]}
{"doc_key": "ai-test-11", "ner": [[0, 1, "organisation"], [5, 8, "researcher"], [9, 10, "organisation"], [13, 13, "product"], [19, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 8, "origin", "", false, false], [5, 8, 9, 10, "role", "", false, false], [13, 13, 19, 20, "type-of", "", false, false], [19, 20, 5, 8, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Rethink", "Robotics", ",", "founded", "by", "Rodney", "Brooks", ",", "formerly", "of", "iRobot", ",", "introduced", "Baxter", "in", "September", "2012", "as", "an", "industrial", "robot", "designed", "to", "interact", "safely", "with", "neighbouring", "human", "workers", "and", "programmed", "to", "perform", "simple", "tasks", "."], "sentence-detokenized": "Rethink Robotics, founded by Rodney Brooks, formerly of iRobot, introduced Baxter in September 2012 as an industrial robot designed to interact safely with neighbouring human workers and programmed to perform simple tasks.", "token2charspan": [[0, 7], [8, 16], [16, 17], [18, 25], [26, 28], [29, 35], [36, 42], [42, 43], [44, 52], [53, 55], [56, 62], [62, 63], [64, 74], [75, 81], [82, 84], [85, 94], [95, 99], [100, 102], [103, 105], [106, 116], [117, 122], [123, 131], [132, 134], [135, 143], [144, 150], [151, 155], [156, 168], [169, 174], [175, 182], [183, 186], [187, 197], [198, 200], [201, 208], [209, 215], [216, 221], [221, 222]]}
{"doc_key": "ai-test-12", "ner": [[1, 2, "field"], [6, 6, "task"], [8, 9, "task"], [11, 18, "task"], [16, 19, "task"], [21, 22, "task"], [24, 25, "task"], [27, 29, "task"], [36, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[6, 6, 1, 2, "part-of", "task_part_of_field", false, false], [8, 9, 1, 2, "part-of", "task_part_of_field", false, false], [11, 18, 1, 2, "part-of", "task_part_of_field", false, false], [16, 19, 1, 2, "part-of", "task_part_of_field", false, false], [21, 22, 1, 2, "part-of", "task_part_of_field", false, false], [24, 25, 1, 2, "part-of", "task_part_of_field", false, false], [27, 29, 1, 2, "part-of", "task_part_of_field", false, false], [36, 38, 1, 2, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Typical", "text", "mining", "tasks", "include", "text", "categorisation", ",", "text", "clustering", ",", "concept", "/", "entity", "extraction", ",", "generation", "of", "detailed", "taxonomies", ",", "sentiment", "analysis", ",", "document", "summarisation", "and", "entity", "relationship", "modelling", "(", "i.e.", ",", "learning", "relationships", "between", "named", "entity", "recognition", ")", "."], "sentence-detokenized": "Typical text mining tasks include text categorisation, text clustering, concept/entity extraction, generation of detailed taxonomies, sentiment analysis, document summarisation and entity relationship modelling (i.e., learning relationships between named entity recognition).", "token2charspan": [[0, 7], [8, 12], [13, 19], [20, 25], [26, 33], [34, 38], [39, 53], [53, 54], [55, 59], [60, 70], [70, 71], [72, 79], [79, 80], [80, 86], [87, 97], [97, 98], [99, 109], [110, 112], [113, 121], [122, 132], [132, 133], [134, 143], [144, 152], [152, 153], [154, 162], [163, 176], [177, 180], [181, 187], [188, 200], [201, 210], [211, 212], [212, 216], [216, 217], [218, 226], [227, 240], [241, 248], [249, 254], [255, 261], [262, 273], [273, 274], [274, 275]]}
{"doc_key": "ai-test-13", "ner": [[5, 5, "metrics"], [7, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "rooting", "reduces", "the", "sensitivity", "or", "TRUE", "negative", "rate", "for", "such", "systems", "."], "sentence-detokenized": "However, rooting reduces the sensitivity or TRUE negative rate for such systems.", "token2charspan": [[0, 7], [7, 8], [9, 16], [17, 24], [25, 28], [29, 40], [41, 43], [44, 48], [49, 57], [58, 62], [63, 66], [67, 71], [72, 79], [79, 80]]}
{"doc_key": "ai-test-14", "ner": [[3, 6, "task"], [7, 8, "misc"], [12, 13, "misc"], [26, 26, "product"], [28, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 3, 6, "temporal", "", false, false], [12, 13, 7, 8, "named", "", false, false], [26, 26, 7, 8, "usage", "", false, false], [28, 28, 7, 8, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "special", "case", "of", "keyword", "detection", "is", "wake", "word", "(", "also", "called", "hot", "word", ")", "detection", ",", "which", "is", "used", "by", "personal", "digital", "assistants", "such", "as", "Alexa", "or", "Siri", "to", "wake", "up", "when", "their", "name", "is", "spoken", "."], "sentence-detokenized": "A special case of keyword detection is wake word (also called hot word) detection, which is used by personal digital assistants such as Alexa or Siri to wake up when their name is spoken.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 17], [18, 25], [26, 35], [36, 38], [39, 43], [44, 48], [49, 50], [50, 54], [55, 61], [62, 65], [66, 70], [70, 71], [72, 81], [81, 82], [83, 88], [89, 91], [92, 96], [97, 99], [100, 108], [109, 116], [117, 127], [128, 132], [133, 135], [136, 141], [142, 144], [145, 149], [150, 152], [153, 157], [158, 160], [161, 165], [166, 171], [172, 176], [177, 179], [180, 186], [186, 187]]}
{"doc_key": "ai-test-15", "ner": [[0, 0, "programlang"], [9, 9, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 0, 0, "part-of", "", false, false], [11, 11, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "is", "an", "open", "source", "programming", "language", "that", "combines", "Prolog", "with", "Java", "."], "sentence-detokenized": "Prova is an open source programming language that combines Prolog with Java.", "token2charspan": [[0, 5], [6, 8], [9, 11], [12, 16], [17, 23], [24, 35], [36, 44], [45, 49], [50, 58], [59, 65], [66, 70], [71, 75], [75, 76]]}
{"doc_key": "ai-test-16", "ner": [[3, 4, "organisation"], [9, 9, "organisation"], [16, 18, "product"], [27, 30, "country"], [34, 34, "organisation"], [42, 42, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[3, 4, 9, 9, "part-of", "", false, false], [3, 4, 9, 9, "role", "sells", false, false], [3, 4, 27, 30, "role", "sells_to", false, false], [34, 34, 42, 42, "opposite", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "1987", ",", "Tocibai", "Machine", ",", "a", "subsidiary", "of", "Toshiba", ",", "was", "accused", "of", "illegally", "selling", "CNC", "milling", "cutters", "used", "to", "manufacture", "very", "quiet", "submarine", "propellers", "to", "the", "Soviet", "Union", "in", "violation", "of", "the", "CoCom", "agreement", ",", "an", "international", "embargo", "imposed", "on", "COMECON", "countries", "by", "certain", "countries", "."], "sentence-detokenized": "In 1987, Tocibai Machine, a subsidiary of Toshiba, was accused of illegally selling CNC milling cutters used to manufacture very quiet submarine propellers to the Soviet Union in violation of the CoCom agreement, an international embargo imposed on COMECON countries by certain countries.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 24], [24, 25], [26, 27], [28, 38], [39, 41], [42, 49], [49, 50], [51, 54], [55, 62], [63, 65], [66, 75], [76, 83], [84, 87], [88, 95], [96, 103], [104, 108], [109, 111], [112, 123], [124, 128], [129, 134], [135, 144], [145, 155], [156, 158], [159, 162], [163, 169], [170, 175], [176, 178], [179, 188], [189, 191], [192, 195], [196, 201], [202, 211], [211, 212], [213, 215], [216, 229], [230, 237], [238, 245], [246, 248], [249, 256], [257, 266], [267, 269], [270, 277], [278, 287], [287, 288]]}
{"doc_key": "ai-test-17", "ner": [[0, 0, "researcher"], [8, 15, "product"], [18, 23, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 15, 0, 0, "artifact", "", false, false], [8, 15, 18, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Engelberger", "'s", "most", "famous", "joint", "invention", ",", "the", "Unimate", "industrial", "robot", "arm", ",", "was", "among", "the", "first", "members", "of", "the", "Robot", "Hall", "of", "Fame", "in", "2003", "."], "sentence-detokenized": "Engelberger's most famous joint invention, the Unimate industrial robot arm, was among the first members of the Robot Hall of Fame in 2003.", "token2charspan": [[0, 11], [11, 13], [14, 18], [19, 25], [26, 31], [32, 41], [41, 42], [43, 46], [47, 54], [55, 65], [66, 71], [72, 75], [75, 76], [77, 80], [81, 86], [87, 90], [91, 96], [97, 104], [105, 107], [108, 111], [112, 117], [118, 122], [123, 125], [126, 130], [131, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-test-18", "ner": [[3, 4, "misc"], [8, 8, "misc"], [10, 11, "person"], [17, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 8, 8, "usage", "", false, false], [10, 11, 17, 19, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Initially", "controlled", "through", "static", "html", "web", "pages", "using", "CGI", ",", "Dalton", "'s", "work", "saw", "the", "introduction", "of", "an", "augmented", "reality", "Java", "-", "based", "interface", ",", "which", "met", "with", "limited", "success", "."], "sentence-detokenized": "Initially controlled through static html web pages using CGI, Dalton's work saw the introduction of an augmented reality Java-based interface, which met with limited success.", "token2charspan": [[0, 9], [10, 20], [21, 28], [29, 35], [36, 40], [41, 44], [45, 50], [51, 56], [57, 60], [60, 61], [62, 68], [68, 70], [71, 75], [76, 79], [80, 83], [84, 96], [97, 99], [100, 102], [103, 112], [113, 120], [121, 125], [125, 126], [126, 131], [132, 141], [141, 142], [143, 148], [149, 152], [153, 157], [158, 165], [166, 173], [173, 174]]}
{"doc_key": "ai-test-19", "ner": [[4, 5, "task"], [8, 8, "organisation"], [26, 26, "conference"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 8, 8, "origin", "", false, false], [26, 26, 23, 23, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["First", "publication", "on", "the", "LMF", "specification", "approved", "by", "ISO", "(", "this", "paper", "was", "(", "in", "2015", ")", "the", "9th", "most", "cited", "paper", "among", "LREC", "papers", "at", "LREC", "conferences", ")", ":"], "sentence-detokenized": "First publication on the LMF specification approved by ISO (this paper was (in 2015) the 9th most cited paper among LREC papers at LREC conferences):", "token2charspan": [[0, 5], [6, 17], [18, 20], [21, 24], [25, 28], [29, 42], [43, 51], [52, 54], [55, 58], [59, 60], [60, 64], [65, 70], [71, 74], [75, 76], [76, 78], [79, 83], [83, 84], [85, 88], [89, 92], [93, 97], [98, 103], [104, 109], [110, 115], [116, 120], [121, 127], [128, 130], [131, 135], [136, 147], [147, 148], [148, 149]]}
{"doc_key": "ai-test-20", "ner": [[0, 2, "metrics"], [14, 16, "metrics"], [17, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 16, 0, 2, "usage", "", false, false], [14, 16, 17, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "confusion", "matrix", "or", "matching", "matrix", "is", "often", "used", "as", "a", "tool", "to", "confirm", "the", "accuracy", "of", "k", "-", "NN", "classification", "."], "sentence-detokenized": "The confusion matrix or matching matrix is often used as a tool to confirm the accuracy of k -NN classification.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 23], [24, 32], [33, 39], [40, 42], [43, 48], [49, 53], [54, 56], [57, 58], [59, 63], [64, 66], [67, 74], [75, 78], [79, 87], [88, 90], [91, 92], [93, 94], [94, 96], [97, 111], [111, 112]]}
{"doc_key": "ai-test-21", "ner": [[0, 1, "algorithm"], [12, 12, "field"], [14, 15, "field"], [11, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 12, "part-of", "", false, false], [0, 1, 14, 15, "part-of", "", false, false], [0, 1, 11, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", "is", "one", "of", "the", "predictive", "modelling", "approaches", "used", "in", "statistics", ",", "data", "mining", "and", "machine", "learning", "."], "sentence-detokenized": "Decision tree learning is one of the predictive modelling approaches used in statistics, data mining and machine learning.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 47], [48, 57], [58, 68], [69, 73], [74, 76], [77, 87], [87, 88], [89, 93], [94, 100], [101, 104], [105, 112], [113, 121], [121, 122]]}
{"doc_key": "ai-test-22", "ner": [[5, 6, "misc"], [16, 17, "field"], [21, 23, "algorithm"], [25, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 16, 17, "related-to", "", true, false], [21, 23, 16, 17, "type-of", "", false, false], [25, 25, 16, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["At", "runtime", ",", "the", "target", "prosody", "of", "a", "sentence", "is", "superimposed", "on", "these", "minimal", "units", "through", "signal", "processing", "techniques", "such", "as", "linear", "predictive", "coding", ",", "PSOLA"], "sentence-detokenized": "At runtime, the target prosody of a sentence is superimposed on these minimal units through signal processing techniques such as linear predictive coding, PSOLA", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 22], [23, 30], [31, 33], [34, 35], [36, 44], [45, 47], [48, 60], [61, 63], [64, 69], [70, 77], [78, 83], [84, 91], [92, 98], [99, 109], [110, 120], [121, 125], [126, 128], [129, 135], [136, 146], [147, 153], [153, 154], [155, 160]]}
{"doc_key": "ai-test-23", "ner": [[3, 5, "field"], [2, 9, "field"], [17, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 3, 5, "usage", "", true, false], [17, 18, 2, 9, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "approach", "utilised", "artificial", "intelligence", "and", "machine", "learning", "to", "allow", "researchers", "to", "visibly", "compare", "traditional", "and", "thermal", "facial", "images", "."], "sentence-detokenized": "This approach utilised artificial intelligence and machine learning to allow researchers to visibly compare traditional and thermal facial images.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 33], [34, 46], [47, 50], [51, 58], [59, 67], [68, 70], [71, 76], [77, 88], [89, 91], [92, 99], [100, 107], [108, 119], [120, 123], [124, 131], [132, 138], [139, 145], [145, 146]]}
{"doc_key": "ai-test-24", "ner": [[0, 2, "field"], [4, 5, "algorithm"], [12, 13, "task"], [16, 17, "misc"], [23, 25, "field"], [26, 27, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 5, 0, 2, "part-of", "", false, false], [4, 5, 12, 13, "topic", "", false, false], [12, 13, 16, 17, "origin", "", false, false], [23, 25, 0, 2, "part-of", "", false, false], [23, 25, 4, 5, "topic", "", false, false], [26, 27, 0, 2, "part-of", "", false, false], [26, 27, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "computer", "science", ",", "evolutionary", "computing", "is", "a", "family", "of", "algorithms", "for", "global", "optimisation", "inspired", "by", "biological", "evolution", ",", "and", "a", "subfield", "of", "artificial", "intelligence", "and", "soft", "computing", "that", "studies", "these", "algorithms", "."], "sentence-detokenized": "In computer science, evolutionary computing is a family of algorithms for global optimisation inspired by biological evolution, and a subfield of artificial intelligence and soft computing that studies these algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 33], [34, 43], [44, 46], [47, 48], [49, 55], [56, 58], [59, 69], [70, 73], [74, 80], [81, 93], [94, 102], [103, 105], [106, 116], [117, 126], [126, 127], [128, 131], [132, 133], [134, 142], [143, 145], [146, 156], [157, 169], [170, 173], [174, 178], [179, 188], [189, 193], [194, 201], [202, 207], [208, 218], [218, 219]]}
{"doc_key": "ai-test-25", "ner": [[7, 9, "metrics"], [13, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "some", "measures", "based", "on", "the", "confusion", "matrix", "can", "be", "combined", "with", "the", "mean", "squared", "error", "evaluated", "between", "raw", "model", "outputs", "and", "actual", "values", "."], "sentence-detokenized": "For example, some measures based on the confusion matrix can be combined with the mean squared error evaluated between raw model outputs and actual values.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [18, 26], [27, 32], [33, 35], [36, 39], [40, 49], [50, 56], [57, 60], [61, 63], [64, 72], [73, 77], [78, 81], [82, 86], [87, 94], [95, 100], [101, 110], [111, 118], [119, 122], [123, 128], [129, 136], [137, 140], [141, 147], [148, 154], [154, 155]]}
{"doc_key": "ai-test-26", "ner": [[6, 8, "product"], [11, 11, "researcher"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 8, 11, 11, "origin", "", false, false], [6, 8, 18, 18, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Most", "of", "them", "are", "results", "of", "the", "word2vec", "model", "developed", "by", "Mikolov", "et", "al", ".", "or", "variants", "of", "word2vec", "."], "sentence-detokenized": "Most of them are results of the word2vec model developed by Mikolov et al. or variants of word2vec.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 16], [17, 24], [25, 27], [28, 31], [32, 40], [41, 46], [47, 56], [57, 59], [60, 67], [68, 70], [71, 73], [73, 74], [75, 77], [78, 86], [87, 89], [90, 98], [98, 99]]}
{"doc_key": "ai-test-27", "ner": [[12, 12, "conference"], [15, 19, "conference"], [21, 21, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 21, 15, 19, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["During", "this", "time", ",", "a", "total", "of", "43", "publications", "were", "accepted", "by", "CVPR", "and", "the", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "."], "sentence-detokenized": "During this time, a total of 43 publications were accepted by CVPR and the International Conference on Computer Vision (ICCV).", "token2charspan": [[0, 6], [7, 11], [12, 16], [16, 17], [18, 19], [20, 25], [26, 28], [29, 31], [32, 44], [45, 49], [50, 58], [59, 61], [62, 66], [67, 70], [71, 74], [75, 88], [89, 99], [100, 102], [103, 111], [112, 118], [119, 120], [120, 124], [124, 125], [125, 126]]}
{"doc_key": "ai-test-28", "ner": [[0, 0, "product"], [10, 10, "field"], [20, 21, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 10, 10, "general-affiliation", "platform_for_education_about", false, false], [20, 21, 0, 0, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["AIBO", "has", "been", "much", "used", "as", "an", "inexpensive", "platform", "for", "AI", "education", "and", "research", "as", "it", "integrates", "a", "computer", ",", "Computer", "vision", "and", "articulators", "in", "a", "package", "that", "is", "much", "cheaper", "than", "traditional", "research", "robots", "."], "sentence-detokenized": "AIBO has been much used as an inexpensive platform for AI education and research as it integrates a computer, Computer vision and articulators in a package that is much cheaper than traditional research robots.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 18], [19, 23], [24, 26], [27, 29], [30, 41], [42, 50], [51, 54], [55, 57], [58, 67], [68, 71], [72, 80], [81, 83], [84, 86], [87, 97], [98, 99], [100, 108], [108, 109], [110, 118], [119, 125], [126, 129], [130, 142], [143, 145], [146, 147], [148, 155], [156, 160], [161, 163], [164, 168], [169, 176], [177, 181], [182, 193], [194, 202], [203, 209], [209, 210]]}
{"doc_key": "ai-test-29", "ner": [[5, 12, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "served", "as", "Programme", "Chair", "at", "the", "International", "Conference", "on", "Computer", "Vision", "2021", "."], "sentence-detokenized": "He served as Programme Chair at the International Conference on Computer Vision 2021.", "token2charspan": [[0, 2], [3, 9], [10, 12], [13, 22], [23, 28], [29, 31], [32, 35], [36, 49], [50, 60], [61, 63], [64, 72], [73, 79], [80, 84], [84, 85]]}
{"doc_key": "ai-test-30", "ner": [[0, 1, "researcher"], [6, 6, "organisation"], [15, 16, "organisation"], [25, 28, "organisation"], [34, 38, "product"], [40, 40, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 6, 6, "role", "", false, false], [0, 1, 15, 16, "role", "", true, false], [15, 16, 25, 28, "role", "develops_with", false, false], [34, 38, 15, 16, "artifact", "", false, false], [40, 40, 34, 38, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["After", "Scheinman", "received", "a", "grant", "from", "Unimation", "to", "develop", "his", "designs", ",", "he", "sold", "them", "to", "Unimation", ",", "which", "further", "developed", "them", "with", "the", "support", "of", "General", "Motors", "and", "later", "marketed", "them", "as", "the", "Programmable", "Universal", "Machine", "for", "Assembly", "(", "PUMA", ")", "."], "sentence-detokenized": "After Scheinman received a grant from Unimation to develop his designs, he sold them to Unimation, which further developed them with the support of General Motors and later marketed them as the Programmable Universal Machine for Assembly (PUMA).", "token2charspan": [[0, 5], [6, 15], [16, 24], [25, 26], [27, 32], [33, 37], [38, 47], [48, 50], [51, 58], [59, 62], [63, 70], [70, 71], [72, 74], [75, 79], [80, 84], [85, 87], [88, 97], [97, 98], [99, 104], [105, 112], [113, 122], [123, 127], [128, 132], [133, 136], [137, 144], [145, 147], [148, 155], [156, 162], [163, 166], [167, 172], [173, 181], [182, 186], [187, 189], [190, 193], [194, 206], [207, 216], [217, 224], [225, 228], [229, 237], [238, 239], [239, 243], [243, 244], [244, 245]]}
{"doc_key": "ai-test-31", "ner": [[6, 6, "task"], [7, 11, "task"], [15, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 15, 6, 6, "general-affiliation", "works_with", false, false], [15, 15, 7, 11, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "overview", "of", "calibration", "methods", "for", "binary", "classification", "and", "multiclass", "classification", "tasks", "is", "given", "by", "Gebel", "(", "2009", ")"], "sentence-detokenized": "An overview of calibration methods for binary classification and multiclass classification tasks is given by Gebel (2009)", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 34], [35, 38], [39, 45], [46, 60], [61, 64], [65, 75], [76, 90], [91, 96], [97, 99], [100, 105], [106, 108], [109, 114], [115, 116], [116, 120], [120, 121]]}
{"doc_key": "ai-test-32", "ner": [[6, 8, "task"], [10, 10, "task"], [14, 14, "task"], [16, 17, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "works", "in", "areas", "such", "as", "optical", "character", "recognition", "(", "OCR", ")", ",", "speech", "synthesis", ",", "speech", "recognition", "technology", "and", "electronic", "keyboard", "devices", "."], "sentence-detokenized": "He works in areas such as optical character recognition (OCR), speech synthesis, speech recognition technology and electronic keyboard devices.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 17], [18, 22], [23, 25], [26, 33], [34, 43], [44, 55], [56, 57], [57, 60], [60, 61], [61, 62], [63, 69], [70, 79], [79, 80], [81, 87], [88, 99], [100, 110], [111, 114], [115, 125], [126, 134], [135, 142], [142, 143]]}
{"doc_key": "ai-test-33", "ner": [[12, 14, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "newer", "and", "state", "-", "of", "-", "the", "-", "art", "techniques", ",", "the", "Kaldi", "toolkit", "can", "be", "used", "."], "sentence-detokenized": "For newer and state-of-the-art techniques, the Kaldi toolkit can be used.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 19], [19, 20], [20, 22], [22, 23], [23, 26], [26, 27], [27, 30], [31, 41], [41, 42], [43, 46], [47, 52], [53, 60], [61, 64], [65, 67], [68, 72], [72, 73]]}
{"doc_key": "ai-test-34", "ner": [[7, 10, "organisation"], [15, 17, "organisation"], [20, 24, "organisation"], [27, 28, "researcher"], [30, 44, "organisation"], [35, 42, "organisation"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Johnson", "-", "Laird", "is", "a", "Fellow", "of", "the", "American", "Philosophical", "Society", ",", "a", "Fellow", "of", "the", "Royal", "Society", ",", "a", "Fellow", "of", "the", "British", "Academy", ",", "a", "William", "James", "Fellow", "of", "the", "Society", "for", "Psychological", "Science", ",", "and", "a", "Fellow", "of", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Johnson-Laird is a Fellow of the American Philosophical Society, a Fellow of the Royal Society, a Fellow of the British Academy, a William James Fellow of the Society for Psychological Science, and a Fellow of the Cognitive Science Society.", "token2charspan": [[0, 7], [7, 8], [8, 13], [14, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 41], [42, 55], [56, 63], [63, 64], [65, 66], [67, 73], [74, 76], [77, 80], [81, 86], [87, 94], [94, 95], [96, 97], [98, 104], [105, 107], [108, 111], [112, 119], [120, 127], [127, 128], [129, 130], [131, 138], [139, 144], [145, 151], [152, 154], [155, 158], [159, 166], [167, 170], [171, 184], [185, 192], [192, 193], [194, 197], [198, 199], [200, 206], [207, 209], [210, 213], [214, 223], [224, 231], [232, 239], [239, 240]]}
{"doc_key": "ai-test-35", "ner": [[0, 9, "conference"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"], [20, 23, "algorithm"], [25, 30, "task"], [32, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 12, 0, 9, "physical", "", false, false], [11, 12, 0, 9, "temporal", "", false, false], [14, 15, 0, 9, "physical", "", false, false], [14, 15, 0, 9, "temporal", "", false, false], [17, 18, 0, 9, "physical", "", false, false], [17, 18, 0, 9, "temporal", "", false, false], [20, 23, 17, 18, "role", "extends", false, false], [25, 30, 17, 18, "role", "extends", false, false], [32, 32, 25, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["At", "the", "IEEE", "International", "Conference", "on", "Image", "Processing", "in", "2010", ",", "Rui", "Hu", ",", "Mark", "Banard", "and", "John", "Collomosse", "extended", "the", "HOG", "descriptor", "for", "use", "in", "sketch", "-", "based", "image", "retrieval", "(", "SBIR", ")", "."], "sentence-detokenized": "At the IEEE International Conference on Image Processing in 2010, Rui Hu, Mark Banard and John Collomosse extended the HOG descriptor for use in sketch-based image retrieval (SBIR).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 25], [26, 36], [37, 39], [40, 45], [46, 56], [57, 59], [60, 64], [64, 65], [66, 69], [70, 72], [72, 73], [74, 78], [79, 85], [86, 89], [90, 94], [95, 105], [106, 114], [115, 118], [119, 122], [123, 133], [134, 137], [138, 141], [142, 144], [145, 151], [151, 152], [152, 157], [158, 163], [164, 173], [174, 175], [175, 179], [179, 180], [180, 181]]}
{"doc_key": "ai-test-36", "ner": [[0, 0, "metrics"], [4, 4, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 4, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["BLEU", "uses", "a", "modified", "precision", "format", "to", "compare", "a", "candidate", "translation", "with", "multiple", "reference", "translations", "."], "sentence-detokenized": "BLEU uses a modified precision format to compare a candidate translation with multiple reference translations.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 20], [21, 30], [31, 37], [38, 40], [41, 48], [49, 50], [51, 60], [61, 72], [73, 77], [78, 86], [87, 96], [97, 109], [109, 110]]}
{"doc_key": "ai-test-37", "ner": [[32, 34, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "the", "case", "of", "a", "general", "math", "(", "Y", ",\\", "mathcal", "{", "B", "},\\", "nu", ")", "/", "math", "base", "space", "(", "i.e", ".", "a", "non-countable", "base", "space", ")", ",", "one", "typically", "considers", "the", "relative", "entropy", "."], "sentence-detokenized": "For the case of a general math (Y,\\ mathcal {B},\\ nu) / math base space (i.e. a non-countable base space), one typically considers the relative entropy.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 15], [16, 17], [18, 25], [26, 30], [31, 32], [32, 33], [33, 35], [36, 43], [44, 45], [45, 46], [46, 49], [50, 52], [52, 53], [54, 55], [56, 60], [61, 65], [66, 71], [72, 73], [73, 76], [76, 77], [78, 79], [80, 93], [94, 98], [99, 104], [104, 105], [105, 106], [107, 110], [111, 120], [121, 130], [131, 134], [135, 143], [144, 151], [151, 152]]}
{"doc_key": "ai-test-38", "ner": [[11, 11, "country"], [13, 15, "organisation"], [17, 17, "organisation"], [10, 22, "country"], [24, 25, "organisation"], [27, 27, "organisation"], [31, 33, "organisation"], [36, 36, "country"], [38, 43, "organisation"], [45, 45, "organisation"], [55, 55, "misc"], [56, 56, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[13, 15, 11, 11, "physical", "", false, false], [17, 17, 13, 15, "named", "", false, false], [24, 25, 10, 22, "physical", "", false, false], [27, 27, 24, 25, "named", "", false, false], [38, 43, 36, 36, "physical", "", false, false], [45, 45, 38, 43, "named", "", false, false], [55, 55, 56, 56, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "of", "October", "2011", ",", "already", "existing", "partnerships", "with", "the", "United", "States", "'", "National", "Park", "Service", "(", "NPS", ")", ",", "the", "United", "Kingdom", "'s", "Historic", "Scotland", "(", "HS", ")", ",", "the", "World", "Monuments", "Fund", ",", "and", "Mexico", "'s", "Instituto", "Nacional", "de", "Antropolog\u00eda", "y", "Historia", "(", "INAH", ")", "have", "been", "greatly", "expanded", ",", "according", "to", "the", "CyArk", "website"], "sentence-detokenized": "As of October 2011, already existing partnerships with the United States' National Park Service (NPS), the United Kingdom's Historic Scotland (HS), the World Monuments Fund, and Mexico's Instituto Nacional de Antropolog\u00eda y Historia (INAH) have been greatly expanded, according to the CyArk website", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 18], [18, 19], [20, 27], [28, 36], [37, 49], [50, 54], [55, 58], [59, 65], [66, 72], [72, 73], [74, 82], [83, 87], [88, 95], [96, 97], [97, 100], [100, 101], [101, 102], [103, 106], [107, 113], [114, 121], [121, 123], [124, 132], [133, 141], [142, 143], [143, 145], [145, 146], [146, 147], [148, 151], [152, 157], [158, 167], [168, 172], [172, 173], [174, 177], [178, 184], [184, 186], [187, 196], [197, 205], [206, 208], [209, 221], [222, 223], [224, 232], [233, 234], [234, 238], [238, 239], [240, 244], [245, 249], [250, 257], [258, 266], [266, 267], [268, 277], [278, 280], [281, 284], [285, 290], [291, 298]]}
{"doc_key": "ai-test-39", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [11, 11, "product"], [13, 13, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 11, 11, "part-of", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [11, 11, 6, 7, "general-affiliation", "", false, false], [13, 13, 6, 7, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kernel", "SVMs", "are", "available", "in", "many", "machine", "learning", "toolkits", ",", "including", "LIBSVM", ",", "MATLAB", "and", "others", "."], "sentence-detokenized": "Kernel SVMs are available in many machine learning toolkits, including LIBSVM, MATLAB and others.", "token2charspan": [[0, 6], [7, 11], [12, 15], [16, 25], [26, 28], [29, 33], [34, 41], [42, 50], [51, 59], [59, 60], [61, 70], [71, 77], [77, 78], [79, 85], [86, 89], [90, 96], [96, 97]]}
{"doc_key": "ai-test-40", "ner": [[0, 6, "misc"], [13, 14, "location"], [16, 16, "location"], [18, 19, "country"], [21, 25, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 6, 13, 14, "physical", "", false, false], [0, 6, 21, 25, "temporal", "", false, false], [13, 14, 16, 16, "physical", "", false, false], [16, 16, 18, 19, "physical", "", false, false], [21, 25, 13, 14, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "2009", "Loebner", "Prize", "Competition", "was", "held", "on", "6", "September", "2009", "at", "the", "Brighton", "Centre", ",", "Brighton", ",", "UK", "in", "conjunction", "with", "the", "Interspeech", "2009", "conference", "."], "sentence-detokenized": "The 2009 Loebner Prize Competition was held on 6 September 2009 at the Brighton Centre, Brighton, UK in conjunction with the Interspeech 2009 conference.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 34], [35, 38], [39, 43], [44, 46], [47, 48], [49, 58], [59, 63], [64, 66], [67, 70], [71, 79], [80, 86], [86, 87], [88, 96], [96, 97], [98, 100], [101, 103], [104, 115], [116, 120], [121, 124], [125, 136], [137, 141], [142, 152], [152, 153]]}
{"doc_key": "ai-test-41", "ner": [[2, 3, "product"], [10, 10, "product"], [16, 18, "product"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 21, 2, 3, "part-of", "", false, false], [19, 21, 10, 10, "part-of", "", false, false], [19, 21, 16, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "humanoid", "QRIO", "robot", "is", "designed", "as", "the", "successor", "to", "AIBO", "and", "runs", "the", "same", "basic", "R", "-", "CODE", "Aperios", "operating", "system", "."], "sentence-detokenized": "The humanoid QRIO robot is designed as the successor to AIBO and runs the same basic R-CODE Aperios operating system.", "token2charspan": [[0, 3], [4, 12], [13, 17], [18, 23], [24, 26], [27, 35], [36, 38], [39, 42], [43, 52], [53, 55], [56, 60], [61, 64], [65, 69], [70, 73], [74, 78], [79, 84], [85, 86], [86, 87], [87, 91], [92, 99], [100, 109], [110, 116], [116, 117]]}
{"doc_key": "ai-test-42", "ner": [[0, 1, "misc"], [5, 6, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 0, 1, "cause-effect", "", true, false], [11, 12, 0, 1, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Speech", "waveforms", "are", "generated", "from", "the", "HMMs", "themselves", "based", "on", "the", "maximum", "likelihood", "criterion", "."], "sentence-detokenized": "Speech waveforms are generated from the HMMs themselves based on the maximum likelihood criterion.", "token2charspan": [[0, 6], [7, 16], [17, 20], [21, 30], [31, 35], [36, 39], [40, 44], [45, 55], [56, 61], [62, 64], [65, 68], [69, 76], [77, 87], [88, 97], [97, 98]]}
{"doc_key": "ai-test-43", "ner": [[0, 2, "product"], [6, 8, "task"], [10, 12, "task"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 6, 8, "type-of", "", false, false], [0, 2, 10, 12, "type-of", "", false, false], [0, 2, 16, 16, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "is", "a", "free", "multilingual", "statistical", "machine", "translation", "and", "neural", "machine", "translation", "service", "developed", "by", "Google", "to", "translate", "texts", "and", "websites", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Google Translate is a free multilingual statistical machine translation and neural machine translation service developed by Google to translate texts and websites from one language to another.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 39], [40, 51], [52, 59], [60, 71], [72, 75], [76, 82], [83, 90], [91, 102], [103, 110], [111, 120], [121, 123], [124, 130], [131, 133], [134, 143], [144, 149], [150, 153], [154, 162], [163, 167], [168, 171], [172, 180], [181, 183], [184, 191], [191, 192]]}
{"doc_key": "ai-test-44", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [4, 17, "field"], [21, 23, "task"], [25, 26, "task"], [28, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[21, 23, 5, 6, "part-of", "", false, true], [21, 23, 8, 9, "part-of", "", false, true], [21, 23, 11, 12, "part-of", "", false, true], [25, 26, 5, 6, "part-of", "", false, true], [25, 26, 8, 9, "part-of", "", false, true], [25, 26, 11, 12, "part-of", "", false, true], [28, 31, 5, 6, "part-of", "", false, true], [28, 31, 8, 9, "part-of", "", false, true], [28, 31, 11, 12, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Skeletons", "are", "widely", "used", "in", "computer", "vision", ",", "image", "analysis", ",", "pattern", "recognition", "and", "digital", "image", "processing", "for", "purposes", "such", "as", "optical", "character", "recognition", ",", "fingerprint", "recognition", ",", "visual", "inspection", "or", "compression", "."], "sentence-detokenized": "Skeletons are widely used in computer vision, image analysis, pattern recognition and digital image processing for purposes such as optical character recognition, fingerprint recognition, visual inspection or compression.", "token2charspan": [[0, 9], [10, 13], [14, 20], [21, 25], [26, 28], [29, 37], [38, 44], [44, 45], [46, 51], [52, 60], [60, 61], [62, 69], [70, 81], [82, 85], [86, 93], [94, 99], [100, 110], [111, 114], [115, 123], [124, 128], [129, 131], [132, 139], [140, 149], [150, 161], [161, 162], [163, 174], [175, 186], [186, 187], [188, 194], [195, 205], [206, 208], [209, 220], [220, 221]]}
{"doc_key": "ai-test-45", "ner": [[0, 7, "conference"], [12, 14, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 7, 12, 14, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Competition", "is", "a", "benchmark", "in", "object", "classification", "and", "detection", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "The ImageNet Large Scale Visual Recognition Competition is a benchmark in object classification and detection with millions of images and hundreds of object classes.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 24], [25, 31], [32, 43], [44, 55], [56, 58], [59, 60], [61, 70], [71, 73], [74, 80], [81, 95], [96, 99], [100, 109], [110, 114], [115, 123], [124, 126], [127, 133], [134, 137], [138, 146], [147, 149], [150, 156], [157, 164], [164, 165]]}
{"doc_key": "ai-test-46", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [16, 20, "misc"], [22, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 16, 20, "part-of", "", false, false], [0, 0, 22, 23, "part-of", "", false, false], [4, 5, 16, 20, "part-of", "", false, false], [4, 5, 22, 23, "part-of", "", false, false], [7, 8, 16, 20, "part-of", "", false, false], [7, 8, 22, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Bengio", ",", "along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "are", "referred", "to", "by", "some", "as", "the", "godfathers", "of", "artificial", "intelligence", "and", "deep", "learning", "."], "sentence-detokenized": "Bengio, along with Geoffrey Hinton and Yann LeCun, are referred to by some as the godfathers of artificial intelligence and deep learning.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 18], [19, 27], [28, 34], [35, 38], [39, 43], [44, 49], [49, 50], [51, 54], [55, 63], [64, 66], [67, 69], [70, 74], [75, 77], [78, 81], [82, 92], [93, 95], [96, 106], [107, 119], [120, 123], [124, 128], [129, 137], [137, 138]]}
{"doc_key": "ai-test-47", "ner": [[5, 6, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "Life", "Member", "of", "IEEE", "."], "sentence-detokenized": "He is a Life Member of IEEE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 19], [20, 22], [23, 27], [27, 28]]}
{"doc_key": "ai-test-48", "ner": [[0, 1, "organisation"], [13, 18, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 13, 18, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NSA", "Bethesda", "is", "responsible", "for", "base", "operational", "support", "for", "its", "main", "tenant", ",", "Walter", "Reed", "National", "Military", "Medical", "Centre", "."], "sentence-detokenized": "NSA Bethesda is responsible for base operational support for its main tenant, Walter Reed National Military Medical Centre.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 31], [32, 36], [37, 48], [49, 56], [57, 60], [61, 64], [65, 69], [70, 76], [76, 77], [78, 84], [85, 89], [90, 98], [99, 107], [108, 115], [116, 122], [122, 123]]}
{"doc_key": "ai-test-49", "ner": [[6, 7, "field"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "three", "main", "learning", "paradigms", "are", "supervised", "learning", ",", "unsupervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "The three main learning paradigms are supervised learning, unsupervised learning and reinforcement learning.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 23], [24, 33], [34, 37], [38, 48], [49, 57], [57, 58], [59, 71], [72, 80], [81, 84], [85, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-test-50", "ner": [[2, 2, "task"], [4, 6, "task"], [8, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Examples", "include", "control", ",", "planning", "and", "scheduling", ",", "diagnostics", "and", "the", "ability", "to", "answer", "consumer", "questions", ",", "handwriting", "recognition", ",", "natural", "language", "understanding", ",", "speech", "recognition", "and", "facial", "recognition", "."], "sentence-detokenized": "Examples include control, planning and scheduling, diagnostics and the ability to answer consumer questions, handwriting recognition, natural language understanding, speech recognition and facial recognition.", "token2charspan": [[0, 8], [9, 16], [17, 24], [24, 25], [26, 34], [35, 38], [39, 49], [49, 50], [51, 62], [63, 66], [67, 70], [71, 78], [79, 81], [82, 88], [89, 97], [98, 107], [107, 108], [109, 120], [121, 132], [132, 133], [134, 141], [142, 150], [151, 164], [164, 165], [166, 172], [173, 184], [185, 188], [189, 195], [196, 207], [207, 208]]}
{"doc_key": "ai-test-51", "ner": [[8, 15, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1991", "he", "was", "elected", "a", "fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "1990", ",", "founding", "fellow", ")", "."], "sentence-detokenized": "In 1991 he was elected a fellow of the Association for the Advancement of Artificial Intelligence (1990, founding fellow).", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 22], [23, 24], [25, 31], [32, 34], [35, 38], [39, 50], [51, 54], [55, 58], [59, 70], [71, 73], [74, 84], [85, 97], [98, 99], [99, 103], [103, 104], [105, 113], [114, 120], [120, 121], [121, 122]]}
{"doc_key": "ai-test-52", "ner": [[11, 12, "misc"], [15, 16, "algorithm"], [29, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "by", "formulating", "the", "problem", "as", "the", "solution", "of", "a", "Toeplitz", "matrix", "and", "using", "Levinson", "recursion", ",", "we", "can", "relatively", "quickly", "estimate", "a", "filter", "with", "the", "smallest", "possible", "mean", "squared", "error", "."], "sentence-detokenized": "However, by formulating the problem as the solution of a Toeplitz matrix and using Levinson recursion, we can relatively quickly estimate a filter with the smallest possible mean squared error.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 23], [24, 27], [28, 35], [36, 38], [39, 42], [43, 51], [52, 54], [55, 56], [57, 65], [66, 72], [73, 76], [77, 82], [83, 91], [92, 101], [101, 102], [103, 105], [106, 109], [110, 120], [121, 128], [129, 137], [138, 139], [140, 146], [147, 151], [152, 155], [156, 164], [165, 173], [174, 178], [179, 186], [187, 192], [192, 193]]}
{"doc_key": "ai-test-53", "ner": [[5, 10, "conference"], [14, 20, "location"], [21, 22, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 10, 14, 20, "physical", "", false, false], [14, 20, 21, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2011", ",", "the", "15th", "edition", "of", "Campus", "Party", "Spain", "will", "take", "place", "at", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", "."], "sentence-detokenized": "In July 2011, the 15th edition of Campus Party Spain will take place at the City of Arts and Sciences in Valencia.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 22], [23, 30], [31, 33], [34, 40], [41, 46], [47, 52], [53, 57], [58, 62], [63, 68], [69, 71], [72, 75], [76, 80], [81, 83], [84, 88], [89, 92], [93, 101], [102, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-test-54", "ner": [[14, 14, "product"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Usually", "this", "is", "only", "possible", "at", "the", "very", "end", "of", "complex", "games", "such", "as", "chess", "or", "go", ",", "because", "it", "is", "not", "computationally", "feasible", "to", "look", "ahead", "to", "the", "end", "of", "the", "game", ",", "and", "instead", "the", "positions", "are", "given", "finite", "values", "as", "estimates", "of", "the", "degree", "of", "belief", "that", "one", "player", "or", "the", "other", "will", "win", "."], "sentence-detokenized": "Usually this is only possible at the very end of complex games such as chess or go, because it is not computationally feasible to look ahead to the end of the game, and instead the positions are given finite values as estimates of the degree of belief that one player or the other will win.", "token2charspan": [[0, 7], [8, 12], [13, 15], [16, 20], [21, 29], [30, 32], [33, 36], [37, 41], [42, 45], [46, 48], [49, 56], [57, 62], [63, 67], [68, 70], [71, 76], [77, 79], [80, 82], [82, 83], [84, 91], [92, 94], [95, 97], [98, 101], [102, 117], [118, 126], [127, 129], [130, 134], [135, 140], [141, 143], [144, 147], [148, 151], [152, 154], [155, 158], [159, 163], [163, 164], [165, 168], [169, 176], [177, 180], [181, 190], [191, 194], [195, 200], [201, 207], [208, 214], [215, 217], [218, 227], [228, 230], [231, 234], [235, 241], [242, 244], [245, 251], [252, 256], [257, 260], [261, 267], [268, 270], [271, 274], [275, 280], [281, 285], [286, 289], [289, 290]]}
{"doc_key": "ai-test-55", "ner": [[3, 27, "algorithm"], [26, 26, "algorithm"], [29, 30, "algorithm"], [33, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 27, 26, 26, "compare", "", false, false], [3, 27, 29, 30, "compare", "", false, false], [3, 27, 33, 35, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "difference", "between", "the", "multinomial", "logit", "model", "and", "a", "large", "number", "of", "other", "methods", ",", "models", ",", "algorithms", ",", "etc.", "with", "the", "same", "basic", "setup", "(", "perceptron", "algorithm", ",", "support", "vector", "machines", ",", "linear", "discriminant", "analysis", ",", "etc.", ")", "."], "sentence-detokenized": "The difference between the multinomial logit model and a large number of other methods, models, algorithms, etc. with the same basic setup (perceptron algorithm, support vector machines, linear discriminant analysis, etc.).", "token2charspan": [[0, 3], [4, 14], [15, 22], [23, 26], [27, 38], [39, 44], [45, 50], [51, 54], [55, 56], [57, 62], [63, 69], [70, 72], [73, 78], [79, 86], [86, 87], [88, 94], [94, 95], [96, 106], [106, 107], [108, 112], [113, 117], [118, 121], [122, 126], [127, 132], [133, 138], [139, 140], [140, 150], [151, 160], [160, 161], [162, 169], [170, 176], [177, 185], [185, 186], [187, 193], [194, 206], [207, 215], [215, 216], [217, 221], [221, 222], [222, 223]]}
{"doc_key": "ai-test-56", "ner": [[3, 6, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Published", "by", "the", "Association", "for", "Computational", "Linguistics", "."], "sentence-detokenized": "Published by the Association for Computational Linguistics.", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 28], [29, 32], [33, 46], [47, 58], [58, 59]]}
{"doc_key": "ai-test-57", "ner": [[0, 3, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "computerised", "face", "recognition", ",", "each", "face", "is", "represented", "by", "a", "large", "number", "of", "pixel", "values", "."], "sentence-detokenized": "In computerised face recognition, each face is represented by a large number of pixel values.", "token2charspan": [[0, 2], [3, 15], [16, 20], [21, 32], [32, 33], [34, 38], [39, 43], [44, 46], [47, 58], [59, 61], [62, 63], [64, 69], [70, 76], [77, 79], [80, 85], [86, 92], [92, 93]]}
{"doc_key": "ai-test-58", "ner": [[9, 15, "person"], [18, 21, "organisation"], [24, 25, "person"], [31, 36, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4], "relations": [[9, 15, 18, 21, "role", "", false, false], [24, 25, 31, 36, "origin", "", false, false], [24, 25, 31, 36, "role", "", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["In", "2002", ",", "the", "kidnapping", "and", "murder", "in", "Pakistan", "of", "his", "son", "Daniel", "Pearl", ",", "a", "journalist", "for", "the", "Wall", "Street", "Journal", ",", "led", "Judea", "and", "other", "family", "members", "and", "friends", "to", "establish", "the", "Daniel", "Pearl", "Foundation", "."], "sentence-detokenized": "In 2002, the kidnapping and murder in Pakistan of his son Daniel Pearl, a journalist for the Wall Street Journal, led Judea and other family members and friends to establish the Daniel Pearl Foundation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 23], [24, 27], [28, 34], [35, 37], [38, 46], [47, 49], [50, 53], [54, 57], [58, 64], [65, 70], [70, 71], [72, 73], [74, 84], [85, 88], [89, 92], [93, 97], [98, 104], [105, 112], [112, 113], [114, 117], [118, 123], [124, 127], [128, 133], [134, 140], [141, 148], [149, 152], [153, 160], [161, 163], [164, 173], [174, 177], [178, 184], [185, 190], [191, 201], [201, 202]]}
{"doc_key": "ai-test-59", "ner": [[4, 6, "organisation"], [16, 17, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 16, 17, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["From", "late", "2006", ",", "Red", "Envelope", "Entertainment", "also", "began", "producing", "original", "content", "with", "filmmakers", "such", "as", "John", "Waters", "."], "sentence-detokenized": "From late 2006, Red Envelope Entertainment also began producing original content with filmmakers such as John Waters.", "token2charspan": [[0, 4], [5, 9], [10, 14], [14, 15], [16, 19], [20, 28], [29, 42], [43, 47], [48, 53], [54, 63], [64, 72], [73, 80], [81, 85], [86, 96], [97, 101], [102, 104], [105, 109], [110, 116], [116, 117]]}
{"doc_key": "ai-test-60", "ner": [[6, 11, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "building", "is", "currently", "part", "of", "the", "Beth", "Israel", "Deaconess", "Medical", "Centre", "."], "sentence-detokenized": "The building is currently part of the Beth Israel Deaconess Medical Centre.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 25], [26, 30], [31, 33], [34, 37], [38, 42], [43, 49], [50, 59], [60, 67], [68, 74], [74, 75]]}
{"doc_key": "ai-test-61", "ner": [[15, 16, "field"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "common", "theme", "of", "this", "work", "is", "the", "adoption", "of", "a", "sign", "theoretic", "perspective", "on", "artificial", "intelligence", "and", "knowledge", "representation", "."], "sentence-detokenized": "The common theme of this work is the adoption of a sign theoretic perspective on artificial intelligence and knowledge representation.", "token2charspan": [[0, 3], [4, 10], [11, 16], [17, 19], [20, 24], [25, 29], [30, 32], [33, 36], [37, 45], [46, 48], [49, 50], [51, 55], [56, 65], [66, 77], [78, 80], [81, 91], [92, 104], [105, 108], [109, 118], [119, 133], [133, 134]]}
{"doc_key": "ai-test-62", "ner": [[0, 7, "task"], [9, 9, "task"], [20, 22, "task"], [40, 41, "task"], [43, 44, "task"], [46, 49, "task"], [51, 51, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 7, 20, 22, "type-of", "", false, false], [0, 7, 46, 49, "compare", "", false, false], [0, 7, 46, 49, "opposite", "", false, false], [9, 9, 0, 7, "named", "", false, false], [40, 41, 46, 49, "part-of", "", false, false], [43, 44, 46, 49, "part-of", "", false, false], [46, 49, 20, 22, "type-of", "", false, false], [51, 51, 46, 49, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["For", "example", ",", "the", "term", "neural", "machine", "translation", "(", "NMT", ")", "highlights", "the", "fact", "that", "deep", "learning", "-", "based", "approaches", "to", "machine", "translation", "directly", "learn", "sequence", "-", "to", "-", "sequence", "transformations", ",", "eliminating", "the", "need", "for", "intermediate", "steps", "such", "as", "word", "alignment", "and", "language", "modelling", "used", "in", "statistical", "machine", "translation", "(", "SMT", ")", "."], "sentence-detokenized": "For example, the term neural machine translation (NMT) highlights the fact that deep learning-based approaches to machine translation directly learn sequence-to-sequence transformations, eliminating the need for intermediate steps such as word alignment and language modelling used in statistical machine translation (SMT).", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 36], [37, 48], [49, 50], [50, 53], [53, 54], [55, 65], [66, 69], [70, 74], [75, 79], [80, 84], [85, 93], [93, 94], [94, 99], [100, 110], [111, 113], [114, 121], [122, 133], [134, 142], [143, 148], [149, 157], [157, 158], [158, 160], [160, 161], [161, 169], [170, 185], [185, 186], [187, 198], [199, 202], [203, 207], [208, 211], [212, 224], [225, 230], [231, 235], [236, 238], [239, 243], [244, 253], [254, 257], [258, 266], [267, 276], [277, 281], [282, 284], [285, 296], [297, 304], [305, 316], [317, 318], [318, 321], [321, 322], [322, 323]]}
{"doc_key": "ai-test-63", "ner": [[8, 10, "field"], [14, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 10, 14, 17, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Most", "of", "the", "research", "in", "the", "field", "of", "WSD", "has", "been", "carried", "out", "using", "Word", "Net", "as", "a", "reference", "semantic", "inventory", "."], "sentence-detokenized": "Most of the research in the field of WSD has been carried out using WordNet as a reference semantic inventory.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 20], [21, 23], [24, 27], [28, 33], [34, 36], [37, 40], [41, 44], [45, 49], [50, 57], [58, 61], [62, 67], [68, 72], [72, 75], [76, 78], [79, 80], [81, 90], [91, 99], [100, 109], [109, 110]]}
{"doc_key": "ai-test-64", "ner": [[2, 2, "misc"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 2, 2, "general-affiliation", "", false, true], [14, 15, 2, 2, "general-affiliation", "", false, true]], "relations_mapping_to_source": [0, 1], "sentence": ["Notable", "former", "PhD", "students", "and", "postdoctoral", "researchers", "in", "his", "group", "include", "Richard", "Zemel", "and", "Zoubin", "Ghahramani", "."], "sentence-detokenized": "Notable former PhD students and postdoctoral researchers in his group include Richard Zemel and Zoubin Ghahramani.", "token2charspan": [[0, 7], [8, 14], [15, 18], [19, 27], [28, 31], [32, 44], [45, 56], [57, 59], [60, 63], [64, 69], [70, 77], [78, 85], [86, 91], [92, 95], [96, 102], [103, 113], [113, 114]]}
{"doc_key": "ai-test-65", "ner": [[6, 9, "metrics"], [14, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 9, 14, 14, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Each", "prediction", "result", "or", "sample", "of", "the", "confusion", "matrix", "represents", "a", "point", "in", "the", "ROC", "space", "."], "sentence-detokenized": "Each prediction result or sample of the confusion matrix represents a point in the ROC space.", "token2charspan": [[0, 4], [5, 15], [16, 22], [23, 25], [26, 32], [33, 35], [36, 39], [40, 49], [50, 56], [57, 67], [68, 69], [70, 75], [76, 78], [79, 82], [83, 86], [87, 92], [92, 93]]}
{"doc_key": "ai-test-66", "ner": [[2, 2, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [16, 18, "product"], [21, 23, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 21, 23, "physical", "", false, false], [6, 7, 21, 23, "physical", "", false, false], [9, 10, 21, 23, "physical", "", false, false], [16, 18, 2, 2, "artifact", "", false, false], [16, 18, 6, 7, "artifact", "", false, false], [16, 18, 9, 10, "artifact", "", false, false], [16, 18, 21, 23, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "1997", "Thrun", "and", "his", "colleagues", "Wolfram", "Burgard", "and", "Dieter", "Fox", "developed", "the", "world", "'s", "first", "robotic", "tour", "guide", "at", "the", "Deutsches", "Museum", "Bonn", "(", "1997", ")", "."], "sentence-detokenized": "In 1997 Thrun and his colleagues Wolfram Burgard and Dieter Fox developed the world's first robotic tour guide at the Deutsches Museum Bonn (1997).", "token2charspan": [[0, 2], [3, 7], [8, 13], [14, 17], [18, 21], [22, 32], [33, 40], [41, 48], [49, 52], [53, 59], [60, 63], [64, 73], [74, 77], [78, 83], [83, 85], [86, 91], [92, 99], [100, 104], [105, 110], [111, 113], [114, 117], [118, 127], [128, 134], [135, 139], [140, 141], [141, 145], [145, 146], [146, 147]]}
{"doc_key": "ai-test-67", "ner": [[0, 1, "product"], [7, 7, "misc"], [24, 26, "field"], [28, 29, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 0, 1, "part-of", "", false, false], [24, 26, 0, 1, "usage", "", false, false], [28, 29, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Word", "Net", "is", "a", "lexical", "database", "containing", "semantic", "relationships", "between", "words", "in", "more", "than", "200", "languages", ".", "it", "s", "primary", "use", "is", "in", "automated", "natural", "language", "processing", "and", "artificial", "intelligence", "applications", "."], "sentence-detokenized": "WordNet is a lexical database containing semantic relationships between words in more than 200 languages. its primary use is in automated natural language processing and artificial intelligence applications.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 40], [41, 49], [50, 63], [64, 71], [72, 77], [78, 80], [81, 85], [86, 90], [91, 94], [95, 104], [104, 105], [106, 108], [108, 109], [110, 117], [118, 121], [122, 124], [125, 127], [128, 137], [138, 145], [146, 154], [155, 165], [166, 169], [170, 180], [181, 193], [194, 206], [206, 207]]}
{"doc_key": "ai-test-68", "ner": [[5, 7, "field"], [11, 15, "conference"], [17, 25, "conference"], [27, 27, "conference"], [29, 29, "conference"], [37, 38, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 15, 5, 7, "topic", "", false, false], [11, 15, 37, 38, "topic", "", false, false], [17, 25, 5, 7, "topic", "", false, false], [17, 25, 37, 38, "topic", "", false, false], [27, 27, 5, 7, "topic", "", false, false], [27, 27, 37, 38, "topic", "", false, false], [29, 29, 5, 7, "topic", "", false, false], [29, 29, 37, 38, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Conferences", "in", "the", "field", "of", "natural", "language", "processing", ",", "such", "as", "the", "Association", "for", "Computational", "Linguistics", ",", "North", "American", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "EMNLP", "and", "HLT", ",", "have", "started", "to", "include", "papers", "on", "speech", "processing", "."], "sentence-detokenized": "Conferences in the field of natural language processing, such as the Association for Computational Linguistics, North American Chapter of the Association for Computational Linguistics, EMNLP and HLT, have started to include papers on speech processing.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 24], [25, 27], [28, 35], [36, 44], [45, 55], [55, 56], [57, 61], [62, 64], [65, 68], [69, 80], [81, 84], [85, 98], [99, 110], [110, 111], [112, 117], [118, 126], [127, 134], [135, 137], [138, 141], [142, 153], [154, 157], [158, 171], [172, 183], [183, 184], [185, 190], [191, 194], [195, 198], [198, 199], [200, 204], [205, 212], [213, 215], [216, 223], [224, 230], [231, 233], [234, 240], [241, 251], [251, 252]]}
{"doc_key": "ai-test-69", "ner": [[3, 3, "programlang"], [19, 23, "misc"], [32, 35, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "number", "of", "Java", "programs", "use", "the", "dictionary", "to", "study", "variations", "in", "biomedical", "texts", "by", "associating", "words", "according", "to", "parts", "of", "speech", ",", "which", "can", "be", "helpful", "in", "web", "searches", "or", "searches", "in", "electronic", "medical", "records", "."], "sentence-detokenized": "A number of Java programs use the dictionary to study variations in biomedical texts by associating words according to parts of speech, which can be helpful in web searches or searches in electronic medical records.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 16], [17, 25], [26, 29], [30, 33], [34, 44], [45, 47], [48, 53], [54, 64], [65, 67], [68, 78], [79, 84], [85, 87], [88, 99], [100, 105], [106, 115], [116, 118], [119, 124], [125, 127], [128, 134], [134, 135], [136, 141], [142, 145], [146, 148], [149, 156], [157, 159], [160, 163], [164, 172], [173, 175], [176, 184], [185, 187], [188, 198], [199, 206], [207, 214], [214, 215]]}
{"doc_key": "ai-test-70", "ner": [[8, 8, "algorithm"], [10, 10, "algorithm"], [12, 12, "algorithm"], [14, 14, "algorithm"], [16, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "many", "more", "new", "algorithms", "such", "as", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", "and", "many", "others", "."], "sentence-detokenized": "There are many more new algorithms such as LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost and many others.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 19], [20, 23], [24, 34], [35, 39], [40, 42], [43, 50], [50, 51], [52, 62], [62, 63], [64, 74], [74, 75], [76, 83], [83, 84], [85, 94], [95, 98], [99, 103], [104, 110], [110, 111]]}
{"doc_key": "ai-test-71", "ner": [[6, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "sample", "application", "in", "Python", ":"], "sentence-detokenized": "This is a sample application in Python:", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 16], [17, 28], [29, 31], [32, 38], [38, 39]]}
{"doc_key": "ai-test-72", "ner": [[1, 1, "organisation"], [2, 2, "product"], [7, 9, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 2, 1, 1, "artifact", "made_by_company", false, false], [7, 9, 2, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Mattel", "Intellivision", "game", "console", "introduced", "the", "Intellivoice", "Voice", "Synthesis", "module", "in", "1982", "."], "sentence-detokenized": "The Mattel Intellivision game console introduced the Intellivoice Voice Synthesis module in 1982.", "token2charspan": [[0, 3], [4, 10], [11, 24], [25, 29], [30, 37], [38, 48], [49, 52], [53, 65], [66, 71], [72, 81], [82, 88], [89, 91], [92, 96], [96, 97]]}
{"doc_key": "ai-test-73", "ner": [[21, 22, "task"], [9, 15, "task"], [18, 18, "field"], [20, 20, "task"], [26, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 15, 21, 22, "part-of", "", false, false], [18, 18, 21, 22, "part-of", "", false, false], [20, 20, 21, 22, "part-of", "", false, false], [26, 30, 20, 20, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "has", "also", "worked", "on", "machine", "translation", ",", "both", "high", "-", "fidelity", "knowledge", "-", "based", "MT", "and", "machine", "learning", "for", "statistical", "machine", "translation", "(", "such", "as", "generalised", "example", "-", "based", "MT", ")", "."], "sentence-detokenized": "He has also worked on machine translation, both high-fidelity knowledge-based MT and machine learning for statistical machine translation (such as generalised example-based MT).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 21], [22, 29], [30, 41], [41, 42], [43, 47], [48, 52], [52, 53], [53, 61], [62, 71], [71, 72], [72, 77], [78, 80], [81, 84], [85, 92], [93, 101], [102, 105], [106, 117], [118, 125], [126, 137], [138, 139], [139, 143], [144, 146], [147, 158], [159, 166], [166, 167], [167, 172], [173, 175], [175, 176], [176, 177]]}
{"doc_key": "ai-test-74", "ner": [[0, 1, "misc"], [5, 5, "misc"], [21, 22, "algorithm"], [24, 25, "field"], [27, 28, "field"], [30, 30, "field"], [32, 33, "field"], [35, 35, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 21, 22, "general-affiliation", "", false, false], [0, 1, 24, 25, "general-affiliation", "", false, false], [0, 1, 27, 28, "general-affiliation", "", false, false], [0, 1, 30, 30, "general-affiliation", "", false, false], [0, 1, 32, 33, "general-affiliation", "", false, false], [0, 1, 35, 35, "general-affiliation", "", false, false], [5, 5, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "often", "called", "Mathematica", ")", "is", "a", "modern", "technical", "computing", "system", "covering", "most", "of", "the", "technical", "fields", ",", "including", "neural", "networks", ",", "machine", "learning", ",", "image", "processing", ",", "geometry", ",", "data", "science", ",", "visualisation", "and", "others", "."], "sentence-detokenized": "Wolfram Mathematica (often called Mathematica) is a modern technical computing system covering most of the technical fields, including neural networks, machine learning, image processing, geometry, data science, visualisation and others.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 26], [27, 33], [34, 45], [45, 46], [47, 49], [50, 51], [52, 58], [59, 68], [69, 78], [79, 85], [86, 94], [95, 99], [100, 102], [103, 106], [107, 116], [117, 123], [123, 124], [125, 134], [135, 141], [142, 150], [150, 151], [152, 159], [160, 168], [168, 169], [170, 175], [176, 186], [186, 187], [188, 196], [196, 197], [198, 202], [203, 210], [210, 211], [212, 225], [226, 229], [230, 236], [236, 237]]}
{"doc_key": "ai-test-75", "ner": [[2, 7, "product"], [12, 13, "researcher"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 17, 2, 7, "type-of", "", false, false], [17, 17, 12, 13, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "digitally", "operated", "and", "programmable", "robot", "was", "invented", "in", "1954", "by", "George", "Devol", "and", "eventually", "named", "Unimate", "."], "sentence-detokenized": "The first digitally operated and programmable robot was invented in 1954 by George Devol and eventually named Unimate.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 28], [29, 32], [33, 45], [46, 51], [52, 55], [56, 64], [65, 67], [68, 72], [73, 75], [76, 82], [83, 88], [89, 92], [93, 103], [104, 109], [110, 117], [117, 118]]}
{"doc_key": "ai-test-76", "ner": [[1, 1, "algorithm"], [3, 3, "algorithm"], [17, 18, "task"], [20, 21, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 3, 3, "compare", "", false, false], [3, 3, 17, 18, "general-affiliation", "", false, false], [3, 3, 20, 21, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Like", "DBNs", ",", "DBMs", "can", "learn", "complex", "and", "abstract", "internal", "representations", "of", "input", "in", "tasks", "such", "as", "object", "recognition", "or", "speech", "recognition", ",", "and", "use", "limited", ",", "labelled", "data", "to", "fine", "-", "tune", "representations", "built", "using", "a", "large", "set", "of", "unlabelled", "sensory", "input", "data", "."], "sentence-detokenized": "Like DBNs, DBMs can learn complex and abstract internal representations of input in tasks such as object recognition or speech recognition, and use limited, labelled data to fine-tune representations built using a large set of unlabelled sensory input data.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 15], [16, 19], [20, 25], [26, 33], [34, 37], [38, 46], [47, 55], [56, 71], [72, 74], [75, 80], [81, 83], [84, 89], [90, 94], [95, 97], [98, 104], [105, 116], [117, 119], [120, 126], [127, 138], [138, 139], [140, 143], [144, 147], [148, 155], [155, 156], [157, 165], [166, 170], [171, 173], [174, 178], [178, 179], [179, 183], [184, 199], [200, 205], [206, 211], [212, 213], [214, 219], [220, 223], [224, 226], [227, 237], [238, 245], [246, 251], [252, 256], [256, 257]]}
{"doc_key": "ai-test-77", "ner": [[8, 12, "task"], [0, 0, "conference"], [2, 4, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 12, "topic", "", false, false], [2, 4, 8, 12, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["ICCV", "and", "CVPR", "are", "the", "scientific", "conferences", "where", "vision", "-", "based", "activity", "recognition", "studies", "are", "frequently", "included", "."], "sentence-detokenized": "ICCV and CVPR are the scientific conferences where vision-based activity recognition studies are frequently included.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 17], [18, 21], [22, 32], [33, 44], [45, 50], [51, 57], [57, 58], [58, 63], [64, 72], [73, 84], [85, 92], [93, 96], [97, 107], [108, 116], [116, 117]]}
{"doc_key": "ai-test-78", "ner": [[0, 1, "field"], [4, 5, "algorithm"], [7, 7, "algorithm"], [17, 18, "metrics"], [20, 22, "metrics"], [25, 25, "metrics"], [38, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[4, 5, 0, 1, "part-of", "", false, false], [4, 5, 17, 18, "related-to", "finds", false, false], [4, 5, 20, 22, "related-to", "finds", false, false], [4, 5, 38, 39, "related-to", "", false, false], [7, 7, 4, 5, "named", "", false, false], [25, 25, 20, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "statistics", ",", "the", "expectation", "maximisation", "(", "EM", ")", "algorithm", "is", "an", "iterative", "method", "used", "to", "find", "maximum", "likelihood", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "estimates", "of", "parameters", "in", "statistical", "models", "where", "the", "model", "depends", "on", "unobservable", "latent", "variables", "."], "sentence-detokenized": "In statistics, the expectation maximisation (EM) algorithm is an iterative method used to find maximum likelihood or maximum a posteriori (MAP) estimates of parameters in statistical models where the model depends on unobservable latent variables.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 30], [31, 43], [44, 45], [45, 47], [47, 48], [49, 58], [59, 61], [62, 64], [65, 74], [75, 81], [82, 86], [87, 89], [90, 94], [95, 102], [103, 113], [114, 116], [117, 124], [125, 126], [127, 137], [138, 139], [139, 142], [142, 143], [144, 153], [154, 156], [157, 167], [168, 170], [171, 182], [183, 189], [190, 195], [196, 199], [200, 205], [206, 213], [214, 216], [217, 229], [230, 236], [237, 246], [246, 247]]}
{"doc_key": "ai-test-79", "ner": [[7, 8, "metrics"], [10, 13, "metrics"], [15, 16, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 13, 7, 8, "named", "", false, false], [18, 18, 15, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Similarly", ",", "researchers", "sometimes", "report", "a", "False", "Positive", "Rate", "(", "FPR", ")", "and", "a", "False", "Negative", "Rate", "(", "FNR", ")", "."], "sentence-detokenized": "Similarly, researchers sometimes report a False Positive Rate (FPR) and a False Negative Rate (FNR).", "token2charspan": [[0, 9], [9, 10], [11, 22], [23, 32], [33, 39], [40, 41], [42, 47], [48, 56], [57, 61], [62, 63], [63, 66], [66, 67], [68, 71], [72, 73], [74, 79], [80, 88], [89, 93], [94, 95], [95, 98], [98, 99], [99, 100]]}
{"doc_key": "ai-test-80", "ner": [[6, 9, "metrics"], [11, 13, "field"], [16, 17, "metrics"], [19, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 13, 6, 9, "usage", "", false, false], [19, 21, 16, 17, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "concept", "is", "similar", "to", "the", "signal", "to", "noise", "ratio", "used", "in", "the", "sciences", "and", "the", "confusion", "matrix", "used", "in", "artificial", "intelligence", "."], "sentence-detokenized": "This concept is similar to the signal to noise ratio used in the sciences and the confusion matrix used in artificial intelligence.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 23], [24, 26], [27, 30], [31, 37], [38, 40], [41, 46], [47, 52], [53, 57], [58, 60], [61, 64], [65, 73], [74, 77], [78, 81], [82, 91], [92, 98], [99, 103], [104, 106], [107, 117], [118, 130], [130, 131]]}
{"doc_key": "ai-test-81", "ner": [[0, 2, "field"], [10, 11, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"], [28, 33, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 10, 11, "general-affiliation", "", false, false], [0, 2, 19, 20, "general-affiliation", "", false, false], [0, 2, 22, 25, "general-affiliation", "", false, false], [28, 33, 0, 2, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Human", "Empowerment", "Code", "of", "Ethics", ",", "first", "proposed", "by", "Steve", "Mann", "in", "2004", "and", "revised", "in", "2013", "with", "Ray", "Kurzweil", "and", "Marvin", "Minsky", ",", "was", "finally", "approved", "at", "the", "Virtual", "Reality", "Toronto", "conference", "on", "25", "June", "2017", "."], "sentence-detokenized": "The Human Empowerment Code of Ethics, first proposed by Steve Mann in 2004 and revised in 2013 with Ray Kurzweil and Marvin Minsky, was finally approved at the Virtual Reality Toronto conference on 25 June 2017.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 26], [27, 29], [30, 36], [36, 37], [38, 43], [44, 52], [53, 55], [56, 61], [62, 66], [67, 69], [70, 74], [75, 78], [79, 86], [87, 89], [90, 94], [95, 99], [100, 103], [104, 112], [113, 116], [117, 123], [124, 130], [130, 131], [132, 135], [136, 143], [144, 152], [153, 155], [156, 159], [160, 167], [168, 175], [176, 183], [184, 194], [195, 197], [198, 200], [201, 205], [206, 210], [210, 211]]}
{"doc_key": "ai-test-82", "ner": [[2, 4, "person"], [10, 11, "organisation"], [17, 18, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 4, 10, 11, "role", "directed_for", false, false], [2, 4, 17, 18, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1913", "Walter", "R.", "Booth", "directed", "10", "films", "for", "the", "UK", "Kinoplastikon", ",", "possibly", "in", "collaboration", "with", "Cecil", "Hepworth", "."], "sentence-detokenized": "In 1913 Walter R. Booth directed 10 films for the UK Kinoplastikon, possibly in collaboration with Cecil Hepworth.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 17], [18, 23], [24, 32], [33, 35], [36, 41], [42, 45], [46, 49], [50, 52], [53, 66], [66, 67], [68, 76], [77, 79], [80, 93], [94, 98], [99, 104], [105, 113], [113, 114]]}
{"doc_key": "ai-test-83", "ner": [[14, 14, "location"], [8, 12, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 12, 14, 14, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "introduced", "their", "new", "robots", "at", "a", "fair", "organised", "at", "the", "Cow", "Palace", "in", "Chicago", "in", "1961", "."], "sentence-detokenized": "They introduced their new robots at a fair organised at the Cow Palace in Chicago in 1961.", "token2charspan": [[0, 4], [5, 15], [16, 21], [22, 25], [26, 32], [33, 35], [36, 37], [38, 42], [43, 52], [53, 55], [56, 59], [60, 63], [64, 70], [71, 73], [74, 81], [82, 84], [85, 89], [89, 90]]}
{"doc_key": "ai-test-84", "ner": [[1, 1, "product"], [5, 6, "task"], [9, 11, "field"], [15, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 5, 6, "usage", "", false, false], [1, 1, 9, 11, "usage", "", false, false], [1, 1, 15, 17, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Some", "chatbot", "applications", "use", "extensive", "word", "classification", "processes", ",", "natural", "language", "processing", "processors", "and", "sophisticated", "AI", ",", "while", "others", "simply", "scan", "generic", "keywords", "and", "generate", "responses", "using", "common", "phrases", "derived", "from", "an", "associated", "library", "or", "database", "."], "sentence-detokenized": "Some chatbot applications use extensive word classification processes, natural language processing processors and sophisticated AI, while others simply scan generic keywords and generate responses using common phrases derived from an associated library or database.", "token2charspan": [[0, 4], [5, 12], [13, 25], [26, 29], [30, 39], [40, 44], [45, 59], [60, 69], [69, 70], [71, 78], [79, 87], [88, 98], [99, 109], [110, 113], [114, 127], [128, 130], [130, 131], [132, 137], [138, 144], [145, 151], [152, 156], [157, 164], [165, 173], [174, 177], [178, 186], [187, 196], [197, 202], [203, 209], [210, 217], [218, 225], [226, 230], [231, 233], [234, 244], [245, 252], [253, 255], [256, 264], [264, 265]]}
{"doc_key": "ai-test-85", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "WaveNet", "model", "proposed", "in", "2016", "achieves", "great", "performance", "in", "speech", "quality", "."], "sentence-detokenized": "The WaveNet model proposed in 2016 achieves great performance in speech quality.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 43], [44, 49], [50, 61], [62, 64], [65, 71], [72, 79], [79, 80]]}
{"doc_key": "ai-test-86", "ner": [[4, 4, "product"], [7, 7, "misc"], [9, 10, "misc"], [12, 13, "misc"], [6, 16, "misc"], [18, 20, "organisation"], [22, 22, "organisation"], [24, 27, "organisation"], [29, 29, "organisation"], [31, 34, "organisation"], [36, 37, "organisation"], [39, 39, "organisation"], [41, 43, "organisation"], [46, 46, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 4, 7, 7, "general-affiliation", "", false, false], [4, 4, 9, 10, "general-affiliation", "", false, false], [4, 4, 12, 13, "general-affiliation", "", false, false], [4, 4, 6, 16, "general-affiliation", "", false, false], [18, 20, 4, 4, "usage", "", false, false], [22, 22, 4, 4, "usage", "", false, false], [24, 27, 4, 4, "usage", "", false, false], [29, 29, 4, 4, "usage", "", false, false], [31, 34, 4, 4, "usage", "", false, false], [36, 37, 4, 4, "usage", "", false, false], [39, 39, 4, 4, "usage", "", false, false], [41, 43, 4, 4, "usage", "", false, false], [46, 46, 4, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organisations", "known", "to", "use", "ALE", "for", "emergency", "management", ",", "disaster", "relief", ",", "ordinary", "communications", "or", "emergency", "response", ":", "American", "Red", "Cross", ",", "FEMA", ",", "Disaster", "Medical", "Assistance", "Teams", ",", "NATO", ",", "Federal", "Bureau", "of", "Investigation", ",", "United", "Nations", ",", "AT&T", ",", "Civil", "Air", "Patrol", ",", "(", "ARES", ")", "."], "sentence-detokenized": "Organisations known to use ALE for emergency management, disaster relief, ordinary communications or emergency response: American Red Cross, FEMA, Disaster Medical Assistance Teams, NATO, Federal Bureau of Investigation, United Nations, AT&T, Civil Air Patrol, (ARES).", "token2charspan": [[0, 13], [14, 19], [20, 22], [23, 26], [27, 30], [31, 34], [35, 44], [45, 55], [55, 56], [57, 65], [66, 72], [72, 73], [74, 82], [83, 97], [98, 100], [101, 110], [111, 119], [119, 120], [121, 129], [130, 133], [134, 139], [139, 140], [141, 145], [145, 146], [147, 155], [156, 163], [164, 174], [175, 180], [180, 181], [182, 186], [186, 187], [188, 195], [196, 202], [203, 205], [206, 219], [219, 220], [221, 227], [228, 235], [235, 236], [237, 241], [241, 242], [243, 248], [249, 252], [253, 259], [259, 260], [261, 262], [262, 266], [266, 267], [267, 268]]}
{"doc_key": "ai-test-87", "ner": [[4, 5, "algorithm"], [14, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "simplicity", ",", "the", "Kronecker", "delta", "is", "used", "here", "(", "the", "derivative", "of", "a", "sigmoid", "function", "is", "expressed", "by", "the", "function", "itself", ")", "."], "sentence-detokenized": "For simplicity, the Kronecker delta is used here (the derivative of a sigmoid function is expressed by the function itself).", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 29], [30, 35], [36, 38], [39, 43], [44, 48], [49, 50], [50, 53], [54, 64], [65, 67], [68, 69], [70, 77], [78, 86], [87, 89], [90, 99], [100, 102], [103, 106], [107, 115], [116, 122], [122, 123], [123, 124]]}
{"doc_key": "ai-test-88", "ner": [[11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "theory", "is", "philosophically", "based", "and", "was", "founded", "around", "1960", "by", "Ray", "Solomonoff", ".", "Samuel", "Rathmanner", "and", "Marcus", "Hutter", "."], "sentence-detokenized": "The theory is philosophically based and was founded around 1960 by Ray Solomonoff. Samuel Rathmanner and Marcus Hutter.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 29], [30, 35], [36, 39], [40, 43], [44, 51], [52, 58], [59, 63], [64, 66], [67, 70], [71, 81], [81, 82], [83, 89], [90, 100], [101, 104], [105, 111], [112, 118], [118, 119]]}
{"doc_key": "ai-test-89", "ner": [[11, 11, "product"], [4, 5, "misc"], [8, 9, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 4, 5, "type-of", "", false, false], [11, 11, 8, 9, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Originally", "conceived", "as", "a", "semantic", "network", "based", "on", "psycholinguistic", "principles", ",", "WordNet", ",", "a", "free", "database", ",", "has", "been", "extended", "with", "the", "addition", "of", "definitions", "and", "is", "now", "also", "seen", "as", "a", "dictionary", "."], "sentence-detokenized": "Originally conceived as a semantic network based on psycholinguistic principles, WordNet, a free database, has been extended with the addition of definitions and is now also seen as a dictionary.", "token2charspan": [[0, 10], [11, 20], [21, 23], [24, 25], [26, 34], [35, 42], [43, 48], [49, 51], [52, 68], [69, 79], [79, 80], [81, 88], [88, 89], [90, 91], [92, 96], [97, 105], [105, 106], [107, 110], [111, 115], [116, 124], [125, 129], [130, 133], [134, 142], [143, 145], [146, 157], [158, 161], [162, 164], [165, 168], [169, 173], [174, 178], [179, 181], [182, 183], [184, 194], [194, 195]]}
{"doc_key": "ai-test-90", "ner": [[2, 3, "field"], [14, 16, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 16, 2, 3, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Advances", "in", "computational", "imaging", "research", "are", "presented", "in", "a", "variety", "of", "settings", ",", "including", "SIGGRAPH", "and", "SIGGRAPH", "publications", "."], "sentence-detokenized": "Advances in computational imaging research are presented in a variety of settings, including SIGGRAPH and SIGGRAPH publications.", "token2charspan": [[0, 8], [9, 11], [12, 25], [26, 33], [34, 42], [43, 46], [47, 56], [57, 59], [60, 61], [62, 69], [70, 72], [73, 81], [81, 82], [83, 92], [93, 101], [102, 105], [106, 114], [115, 127], [127, 128]]}
{"doc_key": "ai-test-91", "ner": [[0, 0, "task"], [9, 9, "task"], [10, 13, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 0, 0, "part-of", "", false, false], [10, 13, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "considered", "as", "two", "separate", "problems", ",", "binary", "classification", "and", "multiclass", "classification", "."], "sentence-detokenized": "Classification can be considered as two separate problems, binary classification and multiclass classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 32], [33, 35], [36, 39], [40, 48], [49, 57], [57, 58], [59, 65], [66, 80], [81, 84], [85, 95], [96, 110], [110, 111]]}
{"doc_key": "ai-test-92", "ner": [[12, 13, "algorithm"], [16, 17, "algorithm"], [20, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 17, 12, 13, "type-of", "", false, false], [20, 20, 16, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Advanced", "gene", "finders", "for", "both", "prokaryotic", "and", "eukaryotic", "genomes", "typically", "use", "complex", "probabilistic", "models", "such", "as", "hidden", "Markov", "models", "(", "HMMs", ")", "to", "combine", "information", "from", "a", "variety", "of", "different", "signal", "and", "content", "measurements", "."], "sentence-detokenized": "Advanced gene finders for both prokaryotic and eukaryotic genomes typically use complex probabilistic models such as hidden Markov models (HMMs) to combine information from a variety of different signal and content measurements.", "token2charspan": [[0, 8], [9, 13], [14, 21], [22, 25], [26, 30], [31, 42], [43, 46], [47, 57], [58, 65], [66, 75], [76, 79], [80, 87], [88, 101], [102, 108], [109, 113], [114, 116], [117, 123], [124, 130], [131, 137], [138, 139], [139, 143], [143, 144], [145, 147], [148, 155], [156, 167], [168, 172], [173, 174], [175, 182], [183, 185], [186, 195], [196, 202], [203, 206], [207, 214], [215, 227], [227, 228]]}
{"doc_key": "ai-test-93", "ner": [[0, 0, "misc"], [3, 5, "misc"], [10, 10, "field"], [14, 14, "algorithm"], [17, 18, "algorithm"], [32, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6], "relations": [[0, 0, 10, 10, "part-of", "", false, false], [0, 0, 14, 14, "usage", "", false, false], [3, 5, 0, 0, "named", "", false, false], [17, 18, 0, 0, "origin", "", true, false], [32, 32, 0, 0, "origin", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5], "sentence": ["Neuroevolution", ",", "or", "neuro-evolution", ",", "is", "a", "form", "of", "artificial", "intelligence", "that", "uses", "evolutionary", "algorithms", "to", "create", "artificial", "neural", "networks", "(", "ANN", ")", ",", "parameters", ",", "topology", "and", "rules", ".", "and", "evolutionary", "robotics", "."], "sentence-detokenized": "Neuroevolution, or neuro-evolution, is a form of artificial intelligence that uses evolutionary algorithms to create artificial neural networks (ANN), parameters, topology and rules. and evolutionary robotics.", "token2charspan": [[0, 14], [14, 15], [16, 18], [19, 34], [34, 35], [36, 38], [39, 40], [41, 45], [46, 48], [49, 59], [60, 72], [73, 77], [78, 82], [83, 95], [96, 106], [107, 109], [110, 116], [117, 127], [128, 134], [135, 143], [144, 145], [145, 148], [148, 149], [149, 150], [151, 161], [161, 162], [163, 171], [172, 175], [176, 181], [181, 182], [183, 186], [187, 199], [200, 208], [208, 209]]}
{"doc_key": "ai-test-94", "ner": [[1, 1, "organisation"], [6, 6, "metrics"], [9, 9, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 1, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "IBM", "proposed", "and", "realised", "the", "BLEU", "system", ",", "Papineni", "et", "al", "."], "sentence-detokenized": "Since IBM proposed and realised the BLEU system, Papineni et al.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 22], [23, 31], [32, 35], [36, 40], [41, 47], [47, 48], [49, 57], [58, 60], [61, 63], [63, 64]]}
{"doc_key": "ai-test-95", "ner": [[10, 16, "conference"], [18, 18, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 18, 10, 16, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2009", ",", "experts", "at", "a", "conference", "organised", "by", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "discussed", "whether", "computers", "and", "robots", "could", "gain", "autonomy", "and", "how", "much", "of", "a", "threat", "or", "danger", "these", "capabilities", "might", "pose", "."], "sentence-detokenized": "In 2009, experts at a conference organised by the Association for the Advancement of Artificial Intelligence (AAAI) discussed whether computers and robots could gain autonomy and how much of a threat or danger these capabilities might pose.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 19], [20, 21], [22, 32], [33, 42], [43, 45], [46, 49], [50, 61], [62, 65], [66, 69], [70, 81], [82, 84], [85, 95], [96, 108], [109, 110], [110, 114], [114, 115], [116, 125], [126, 133], [134, 143], [144, 147], [148, 154], [155, 160], [161, 165], [166, 174], [175, 178], [179, 182], [183, 187], [188, 190], [191, 192], [193, 199], [200, 202], [203, 209], [210, 215], [216, 228], [229, 234], [235, 239], [239, 240]]}
{"doc_key": "ai-test-96", "ner": [[21, 23, "metrics"], [23, 24, "researcher"], [26, 27, "researcher"], [29, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[29, 34, 21, 23, "topic", "", false, false], [29, 34, 23, 24, "artifact", "", false, false], [29, 34, 26, 27, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["After", "boosting", ",", "a", "classifier", "built", "from", "200", "features", "can", "provide", "a", "95", "%", "detection", "rate", "under", "^{-5", "}", "/", "maths", "FALSE", "positive", "rate.P.", "Viola", ",", "M.", "Jones", ",", "Robust", "Real", "-", "time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "After boosting, a classifier built from 200 features can provide a 95% detection rate under ^{-5} / maths FALSE positive rate.P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 17], [18, 28], [29, 34], [35, 39], [40, 43], [44, 52], [53, 56], [57, 64], [65, 66], [67, 69], [69, 70], [71, 80], [81, 85], [86, 91], [92, 96], [96, 97], [98, 99], [100, 105], [106, 111], [112, 120], [121, 128], [129, 134], [134, 135], [136, 138], [139, 144], [144, 145], [146, 152], [153, 157], [157, 158], [158, 162], [163, 169], [170, 179], [179, 180], [181, 185], [185, 186]]}
{"doc_key": "ai-test-97", "ner": [[9, 9, "organisation"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "website", "was", "originally", "Perl", "-", "based", ",", "but", "IMDb", "no", "longer", "discloses", "which", "software", "it", "uses", "for", "security", "reasons", "."], "sentence-detokenized": "The website was originally Perl-based, but IMDb no longer discloses which software it uses for security reasons.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 26], [27, 31], [31, 32], [32, 37], [37, 38], [39, 42], [43, 47], [48, 50], [51, 57], [58, 67], [68, 73], [74, 82], [83, 85], [86, 90], [91, 94], [95, 103], [104, 111], [111, 112]]}
{"doc_key": "ai-test-98", "ner": [[9, 10, "researcher"], [12, 13, "researcher"], [15, 16, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "start", "-", "up", "was", "founded", "in", "2010", "by", "Demis", "Hassabis", ",", "Shane", "Legg", "and", "Mustafa", "Suleyman", "."], "sentence-detokenized": "The start-up was founded in 2010 by Demis Hassabis, Shane Legg and Mustafa Suleyman.", "token2charspan": [[0, 3], [4, 9], [9, 10], [10, 12], [13, 16], [17, 24], [25, 27], [28, 32], [33, 35], [36, 41], [42, 50], [50, 51], [52, 57], [58, 62], [63, 66], [67, 74], [75, 83], [83, 84]]}
{"doc_key": "ai-test-99", "ner": [[4, 7, "misc"], [8, 10, "metrics"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 4, 7, "type-of", "", false, false], [24, 25, 4, 7, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "very", "commonly", "used", "loss", "functions", "are", "the", "mean", "squared", "error", ",", "mathL", "(", "a", ")", "=", "a", "^", "2", "/", "math", "and", "the", "absolute", "loss", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "/", "math", "."], "sentence-detokenized": "Two very commonly used loss functions are the mean squared error, mathL (a) = a ^ 2 / math and the absolute loss, mathL (a) = | a | / math.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 27], [28, 37], [38, 41], [42, 45], [46, 50], [51, 58], [59, 64], [64, 65], [66, 71], [72, 73], [73, 74], [74, 75], [76, 77], [78, 79], [80, 81], [82, 83], [84, 85], [86, 90], [91, 94], [95, 98], [99, 107], [108, 112], [112, 113], [114, 119], [120, 121], [121, 122], [122, 123], [124, 125], [126, 127], [128, 129], [130, 131], [132, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-test-100", "ner": [[3, 5, "algorithm"], [11, 14, "algorithm"], [16, 16, "algorithm"], [19, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 11, 14, "type-of", "example_of", false, false], [11, 14, 19, 20, "related-to", "", false, false], [16, 16, 11, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "soft", "margin", "support", "vector", "machine", "described", "above", "is", "an", "example", "of", "empirical", "risk", "minimisation", "(", "ERM", ")", "for", "hinge", "loss", "."], "sentence-detokenized": "The soft margin support vector machine described above is an example of empirical risk minimisation (ERM) for hinge loss.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 23], [24, 30], [31, 38], [39, 48], [49, 54], [55, 57], [58, 60], [61, 68], [69, 71], [72, 81], [82, 86], [87, 99], [100, 101], [101, 104], [104, 105], [106, 109], [110, 115], [116, 120], [120, 121]]}
{"doc_key": "ai-test-101", "ner": [[5, 5, "field"], [10, 14, "task"], [0, 2, "task"], [22, 22, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 5, "origin", "", false, false], [0, 2, 10, 14, "type-of", "", false, false], [22, 22, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Neural", "machine", "translation", ",", "a", "deep", "learning", "-", "based", "approach", "to", "MT", ",", "has", "made", "rapid", "progress", "in", "recent", "years", ",", "and", "Google", "has", "announced", "that", "its", "translation", "services", "now", "use", "this", "technology", "instead", "of", "previous", "statistical", "methods", "."], "sentence-detokenized": "Neural machine translation, a deep learning-based approach to MT, has made rapid progress in recent years, and Google has announced that its translation services now use this technology instead of previous statistical methods.", "token2charspan": [[0, 6], [7, 14], [15, 26], [26, 27], [28, 29], [30, 34], [35, 43], [43, 44], [44, 49], [50, 58], [59, 61], [62, 64], [64, 65], [66, 69], [70, 74], [75, 80], [81, 89], [90, 92], [93, 99], [100, 105], [105, 106], [107, 110], [111, 117], [118, 121], [122, 131], [132, 136], [137, 140], [141, 152], [153, 161], [162, 165], [166, 169], [170, 174], [175, 185], [186, 193], [194, 196], [197, 205], [206, 217], [218, 225], [225, 226]]}
{"doc_key": "ai-test-102", "ner": [[10, 15, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "tends", "to", "provide", "very", "large", "performance", "gains", "when", "working", "with", "large", "corpora", "such", "as", "WordNet", "."], "sentence-detokenized": "This tends to provide very large performance gains when working with large corpora such as WordNet.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 21], [22, 26], [27, 32], [33, 44], [45, 50], [51, 55], [56, 63], [64, 68], [69, 74], [75, 82], [83, 87], [88, 90], [91, 98], [98, 99]]}
{"doc_key": "ai-test-103", "ner": [[0, 2, "task"], [5, 6, "field"], [17, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 17, 19, "part-of", "", false, false], [17, 19, 5, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Face", "detection", "is", "often", "used", "in", "biometrics", "as", "part", "of", "(", "or", "in", "combination", "with", ")", "a", "face", "recognition", "system", "."], "sentence-detokenized": "Face detection is often used in biometrics as part of (or in combination with) a face recognition system.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 23], [24, 28], [29, 31], [32, 42], [43, 45], [46, 50], [51, 53], [54, 55], [55, 57], [58, 60], [61, 72], [73, 77], [77, 78], [79, 80], [81, 85], [86, 97], [98, 104], [104, 105]]}
{"doc_key": "ai-test-104", "ner": [[2, 4, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["trained", "with", "maximum", "likelihood", "estimation", "."], "sentence-detokenized": "trained with maximum likelihood estimation.", "token2charspan": [[0, 7], [8, 12], [13, 20], [21, 31], [32, 42], [42, 43]]}
{"doc_key": "ai-test-105", "ner": [[4, 9, "organisation"], [10, 10, "location"], [16, 39, "organisation"], [27, 27, "country"], [31, 36, "organisation"], [37, 37, "country"], [33, 52, "organisation"]], "ner_mapping_to_source": [1, 2, 4, 5, 7, 8, 9], "relations": [[4, 9, 10, 10, "physical", "", false, false], [16, 39, 27, 27, "physical", "", false, false], [31, 36, 37, 37, "physical", "", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["Ltd", "in", "1996", ";", "Komatsu", "(", "Shanghai", ")", "Ltd", "in", "Shanghai", ",", "China", "in", "1996", ";", "Industrial", "Power", "Alliance", "Ltd", ",", "a", "joint", "venture", "with", "Cummins", "in", "Japan", "in", "1998", ";", "L", "&", "T-", "Komatsu", "Limited", "in", "India", "in", "1998", "(", "shares", "sold", "in", "2013", ")", ";", "and", "Komatsu", "Brasil", "International", "Ltda", "."], "sentence-detokenized": "Ltd in 1996; Komatsu (Shanghai) Ltd in Shanghai, China in 1996; Industrial Power Alliance Ltd, a joint venture with Cummins in Japan in 1998; L & T-Komatsu Limited in India in 1998 (shares sold in 2013); and Komatsu Brasil International Ltda.", "token2charspan": [[0, 3], [4, 6], [7, 11], [11, 12], [13, 20], [21, 22], [22, 30], [30, 31], [32, 35], [36, 38], [39, 47], [47, 48], [49, 54], [55, 57], [58, 62], [62, 63], [64, 74], [75, 80], [81, 89], [90, 93], [93, 94], [95, 96], [97, 102], [103, 110], [111, 115], [116, 123], [124, 126], [127, 132], [133, 135], [136, 140], [140, 141], [142, 143], [144, 145], [146, 148], [148, 155], [156, 163], [164, 166], [167, 172], [173, 175], [176, 180], [181, 182], [182, 188], [189, 193], [194, 196], [197, 201], [201, 202], [202, 203], [204, 207], [208, 215], [216, 222], [223, 236], [237, 241], [241, 242]]}
{"doc_key": "ai-test-106", "ner": [[0, 0, "organisation"], [4, 8, "misc"], [16, 17, "person"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[16, 17, 0, 0, "physical", "", false, false], [16, 17, 4, 8, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["dgp", "also", "hosts", "guest", "artists", "from", "time", "to", "time", "(", "for", "example", ",", "Oscar", "-", "winner", "Chris", "Landreth", "."], "sentence-detokenized": "dgp also hosts guest artists from time to time (for example, Oscar-winner Chris Landreth.", "token2charspan": [[0, 3], [4, 8], [9, 14], [15, 20], [21, 28], [29, 33], [34, 38], [39, 41], [42, 46], [47, 48], [48, 51], [52, 59], [59, 60], [61, 66], [66, 67], [67, 73], [74, 79], [80, 88], [88, 89]]}
{"doc_key": "ai-test-107", "ner": [[6, 21, "misc"], [13, 13, "misc"], [17, 20, "misc"], [26, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "currently", "includes", "four", "sub-competitions", ",", "the", "RoboMaster", "Robotics", "Competition", ",", "the", "RoboMaster", "Technical", "Competition", ",", "the", "ICRA", "RoboMaster", "Artificial", "Intelligence", "Competition", "and", "the", "new", "RoboMaster", "Youth", "Tournament", "."], "sentence-detokenized": "It currently includes four sub-competitions, the RoboMaster Robotics Competition, the RoboMaster Technical Competition, the ICRA RoboMaster Artificial Intelligence Competition and the new RoboMaster Youth Tournament.", "token2charspan": [[0, 2], [3, 12], [13, 21], [22, 26], [27, 43], [43, 44], [45, 48], [49, 59], [60, 68], [69, 80], [80, 81], [82, 85], [86, 96], [97, 106], [107, 118], [118, 119], [120, 123], [124, 128], [129, 139], [140, 150], [151, 163], [164, 175], [176, 179], [180, 183], [184, 187], [188, 198], [199, 204], [205, 215], [215, 216]]}
{"doc_key": "ai-test-108", "ner": [[7, 8, "field"], [14, 18, "algorithm"], [22, 23, "algorithm"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 22, 23, "usage", "", false, false], [7, 8, 25, 26, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "the", "early", "2000s", ",", "the", "dominant", "speech", "processing", "strategy", "began", "to", "shift", "away", "from", "the", "Hidden", "Markov", "model", "towards", "more", "modern", "neural", "networks", "and", "deep", "learning", "."], "sentence-detokenized": "In the early 2000s, the dominant speech processing strategy began to shift away from the Hidden Markov model towards more modern neural networks and deep learning.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 18], [18, 19], [20, 23], [24, 32], [33, 39], [40, 50], [51, 59], [60, 65], [66, 68], [69, 74], [75, 79], [80, 84], [85, 88], [89, 95], [96, 102], [103, 108], [109, 116], [117, 121], [122, 128], [129, 135], [136, 144], [145, 148], [149, 153], [154, 162], [162, 163]]}
{"doc_key": "ai-test-109", "ner": [[4, 9, "misc"], [23, 29, "metrics"], [31, 32, "metrics"], [38, 41, "metrics"], [44, 46, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[23, 29, 31, 32, "related-to", "equal", false, false], [38, 41, 44, 46, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "the", "case", "of", "the", "binary", "target", "ratio", ",", "an", "equivalent", "statement", "is", "that", "for", "each", "value", "of", "the", "sensitive", "features", ",", "the", "TRUE", "positive", "rate", "is", "equal", "to", "the", "FALSE", "positive", "rate", "(", "and", "therefore", "the", "FALSE", "negative", "rate", "is", "equal", "to", "the", "TRUE", "negative", "rate", ")", ":"], "sentence-detokenized": "In the case of the binary target ratio, an equivalent statement is that for each value of the sensitive features, the TRUE positive rate is equal to the FALSE positive rate (and therefore the FALSE negative rate is equal to the TRUE negative rate):", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 18], [19, 25], [26, 32], [33, 38], [38, 39], [40, 42], [43, 53], [54, 63], [64, 66], [67, 71], [72, 75], [76, 80], [81, 86], [87, 89], [90, 93], [94, 103], [104, 112], [112, 113], [114, 117], [118, 122], [123, 131], [132, 136], [137, 139], [140, 145], [146, 148], [149, 152], [153, 158], [159, 167], [168, 172], [173, 174], [174, 177], [178, 187], [188, 191], [192, 197], [198, 206], [207, 211], [212, 214], [215, 220], [221, 223], [224, 227], [228, 232], [233, 241], [242, 246], [246, 247], [247, 248]]}
{"doc_key": "ai-test-110", "ner": [[0, 0, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["MATLAB", "functionality", ","], "sentence-detokenized": "MATLAB functionality,", "token2charspan": [[0, 6], [7, 20], [20, 21]]}
{"doc_key": "ai-test-111", "ner": [[2, 2, "product"], [7, 8, "misc"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 2, 2, "part-of", "", false, false], [15, 17, 2, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "articulated", "robot", "is", "a", "robot", "with", "rotating", "joints", "(", "e.g.", "a", "legged", "robot", "or", "an", "industrial", "robot", ")", "."], "sentence-detokenized": "An articulated robot is a robot with rotating joints (e.g. a legged robot or an industrial robot).", "token2charspan": [[0, 2], [3, 14], [15, 20], [21, 23], [24, 25], [26, 31], [32, 36], [37, 45], [46, 52], [53, 54], [54, 58], [59, 60], [61, 67], [68, 73], [74, 76], [77, 79], [80, 90], [91, 96], [96, 97], [97, 98]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [6, 6, "product"], [9, 9, "product"], [13, 13, "misc"], [17, 18, "product"], [24, 27, "misc"], [31, 31, "location"], [30, 33, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 13, 13, "general-affiliation", "nationality", false, false], [0, 0, 24, 27, "usage", "", false, false], [0, 0, 31, 31, "physical", "", false, false], [6, 6, 0, 0, "named", "", false, false], [9, 9, 0, 0, "named", "", false, false], [31, 31, 30, 33, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "also", "known", "as", "Pandora", "Media", "or", "Pandora", "Radio", ")", "is", "an", "American", "music", "streaming", "and", "auto-suggestion", "system", "internet", "radio", "service", "powered", "by", "the", "Music", "Genome", "Project", "and", "headquartered", "in", "Oakland", ",", "California", "."], "sentence-detokenized": "Pandora (also known as Pandora Media or Pandora Radio) is an American music streaming and auto-suggestion system internet radio service powered by the Music Genome Project and headquartered in Oakland, California.", "token2charspan": [[0, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 30], [31, 36], [37, 39], [40, 47], [48, 53], [53, 54], [55, 57], [58, 60], [61, 69], [70, 75], [76, 85], [86, 89], [90, 105], [106, 112], [113, 121], [122, 127], [128, 135], [136, 143], [144, 146], [147, 150], [151, 156], [157, 163], [164, 171], [172, 175], [176, 189], [190, 192], [193, 200], [200, 201], [202, 212], [212, 213]]}
{"doc_key": "ai-test-113", "ner": [[5, 10, "organisation"], [13, 18, "organisation"], [24, 25, "conference"], [39, 39, "conference"], [41, 41, "conference"], [43, 43, "conference"], [45, 45, "conference"], [47, 47, "conference"], [49, 49, "conference"], [51, 51, "conference"], [53, 53, "conference"], [55, 55, "conference"], [58, 58, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "board", "member", "of", "the", "International", "Machine", "Learning", "Association", ",", "a", "member", "of", "the", "AAAI", "Executive", "council", ",", "was", "PC", "co-chair", "of", "ICML", "2011", ",", "and", "has", "served", "as", "a", "senior", "PC", "member", "at", "conferences", "such", "as", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "UAI", ",", "VLDB", ",", "WSDM", ",", "and", "WWW", "."], "sentence-detokenized": "He is a board member of the International Machine Learning Association, a member of the AAAI Executive council, was PC co-chair of ICML 2011, and has served as a senior PC member at conferences such as AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM, and WWW.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 13], [14, 20], [21, 23], [24, 27], [28, 41], [42, 49], [50, 58], [59, 70], [70, 71], [72, 73], [74, 80], [81, 83], [84, 87], [88, 92], [93, 102], [103, 110], [110, 111], [112, 115], [116, 118], [119, 127], [128, 130], [131, 135], [136, 140], [140, 141], [142, 145], [146, 149], [150, 156], [157, 159], [160, 161], [162, 168], [169, 171], [172, 178], [179, 181], [182, 193], [194, 198], [199, 201], [202, 206], [206, 207], [208, 212], [212, 213], [214, 219], [219, 220], [221, 225], [225, 226], [227, 230], [230, 231], [232, 238], [238, 239], [240, 243], [243, 244], [245, 249], [249, 250], [251, 255], [255, 256], [257, 260], [261, 264], [264, 265]]}
{"doc_key": "ai-test-114", "ner": [[0, 2, "researcher"], [5, 10, "organisation"], [12, 12, "organisation"], [15, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 10, "role", "", false, false], [12, 12, 5, 10, "named", "", false, false], [15, 16, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", "of", "the", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", "developed", "the", "Robocrane", ",", "in", "which", "the", "platform", "is", "suspended", "by", "six", "cables", "rather", "than", "supported", "by", "six", "jacks", "."], "sentence-detokenized": "James S. Albus of the National Institute of Standards and Technology (NIST) developed the Robocrane, in which the platform is suspended by six cables rather than supported by six jacks.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 17], [18, 21], [22, 30], [31, 40], [41, 43], [44, 53], [54, 57], [58, 68], [69, 70], [70, 74], [74, 75], [76, 85], [86, 89], [90, 99], [99, 100], [101, 103], [104, 109], [110, 113], [114, 122], [123, 125], [126, 135], [136, 138], [139, 142], [143, 149], [150, 156], [157, 161], [162, 171], [172, 174], [175, 178], [179, 184], [184, 185]]}
{"doc_key": "ai-test-115", "ner": [[2, 6, "algorithm"], [8, 9, "algorithm"], [12, 13, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 2, 6, "type-of", "", false, false], [12, 13, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "class", "of", "direct", "search", "algorithms", "are", "various", "evolutionary", "algorithms", "such", "as", "genetic", "algorithms", "."], "sentence-detokenized": "Another class of direct search algorithms are various evolutionary algorithms such as genetic algorithms.", "token2charspan": [[0, 7], [8, 13], [14, 16], [17, 23], [24, 30], [31, 41], [42, 45], [46, 53], [54, 66], [67, 77], [78, 82], [83, 85], [86, 93], [94, 104], [104, 105]]}
{"doc_key": "ai-test-116", "ner": [[0, 1, "organisation"], [3, 12, "misc"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 12, 0, 1, "named", "", false, false], [6, 7, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["KUKA", "is", "a", "German", "manufacturer", "of", "industrial", "robots", "and", "solutions", "for", "factory", "automation", "."], "sentence-detokenized": "KUKA is a German manufacturer of industrial robots and solutions for factory automation.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 16], [17, 29], [30, 32], [33, 43], [44, 50], [51, 54], [55, 64], [65, 68], [69, 76], [77, 87], [87, 88]]}
{"doc_key": "ai-test-117", "ner": [[4, 5, "misc"], [10, 11, "person"], [13, 19, "misc"], [21, 22, "person"], [24, 24, "misc"], [26, 28, "person"], [29, 30, "misc"], [32, 33, "person"], [35, 37, "misc"], [39, 42, "person"], [43, 46, "misc"], [48, 50, "person"], [51, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[10, 11, 4, 5, "usage", "", false, false], [13, 19, 10, 11, "artifact", "", false, false], [21, 22, 4, 5, "usage", "", false, false], [24, 24, 21, 22, "artifact", "", false, false], [26, 28, 4, 5, "usage", "", false, false], [29, 30, 26, 28, "artifact", "", false, false], [32, 33, 4, 5, "usage", "", false, false], [35, 37, 32, 33, "artifact", "", false, false], [39, 42, 4, 5, "usage", "", false, false], [43, 46, 39, 42, "artifact", "", false, false], [48, 50, 4, 5, "usage", "", false, false], [51, 54, 48, 50, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Other", "films", "shot", "in", "IMAX", "between", "2016", "and", "2020", "include", "Zack", "Snyder", "'s", "Batman", "v", "Superman", ":", "Dawn", "of", "Justice", ",", "Clint", "Eastwood", "'s", "Sully", ",", "Damien", "Chazelle", "'s", "First", "Man", ",", "Patty", "Jenkins", "'", "Wonder", "Woman", "1984", ",", "Cary", "Joji", "Fukunaga", "'s", "No", "Time", "to", "Die", "and", "Joseph", "Kosinski", "'s", "Top", "Gun", ":", "Maverick", "."], "sentence-detokenized": "Other films shot in IMAX between 2016 and 2020 include Zack Snyder's Batman v Superman: Dawn of Justice, Clint Eastwood's Sully, Damien Chazelle's First Man, Patty Jenkins' Wonder Woman 1984, Cary Joji Fukunaga's No Time to Die and Joseph Kosinski's Top Gun: Maverick.", "token2charspan": [[0, 5], [6, 11], [12, 16], [17, 19], [20, 24], [25, 32], [33, 37], [38, 41], [42, 46], [47, 54], [55, 59], [60, 66], [66, 68], [69, 75], [76, 77], [78, 86], [86, 87], [88, 92], [93, 95], [96, 103], [103, 104], [105, 110], [111, 119], [119, 121], [122, 127], [127, 128], [129, 135], [136, 144], [144, 146], [147, 152], [153, 156], [156, 157], [158, 163], [164, 171], [171, 172], [173, 179], [180, 185], [186, 190], [190, 191], [192, 196], [197, 201], [202, 210], [210, 212], [213, 215], [216, 220], [221, 223], [224, 227], [228, 231], [232, 238], [239, 247], [247, 249], [250, 253], [254, 257], [257, 258], [259, 267], [267, 268]]}
{"doc_key": "ai-test-118", "ner": [[4, 5, "misc"], [11, 13, "organisation"], [15, 15, "organisation"], [26, 26, "misc"], [33, 33, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 26, 26, "named", "", false, false], [11, 13, 4, 5, "usage", "", false, false], [11, 13, 33, 33, "physical", "", false, false], [15, 15, 11, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "trial", "of", "the", "MICR", "E13B", "font", "was", "shown", "to", "the", "American", "Bankers", "Association", "(", "ABA", ")", "in", "July", "1956", ",", "which", "adopted", "it", "as", "the", "MICR", "standard", "for", "negotiable", "instruments", "in", "the", "USA", "in", "1958", "."], "sentence-detokenized": "A trial of the MICR E13B font was shown to the American Bankers Association (ABA) in July 1956, which adopted it as the MICR standard for negotiable instruments in the USA in 1958.", "token2charspan": [[0, 1], [2, 7], [8, 10], [11, 14], [15, 19], [20, 24], [25, 29], [30, 33], [34, 39], [40, 42], [43, 46], [47, 55], [56, 63], [64, 75], [76, 77], [77, 80], [80, 81], [82, 84], [85, 89], [90, 94], [94, 95], [96, 101], [102, 109], [110, 112], [113, 115], [116, 119], [120, 124], [125, 133], [134, 137], [138, 148], [149, 160], [161, 163], [164, 167], [168, 171], [172, 174], [175, 179], [179, 180]]}
{"doc_key": "ai-test-119", "ner": [[0, 2, "misc"], [19, 20, "field"], [23, 24, "field"], [27, 27, "field"], [30, 30, "field"], [32, 32, "field"], [17, 34, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[19, 20, 0, 2, "usage", "", false, false], [23, 24, 19, 20, "part-of", "", false, false], [27, 27, 0, 2, "usage", "", false, false], [30, 30, 0, 2, "usage", "", false, false], [32, 32, 0, 2, "usage", "", false, false], [17, 34, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Local", "search", "algorithms", "have", "been", "widely", "applied", "to", "a", "large", "number", "of", "difficult", "computational", "problems", ",", "including", "problems", "in", "computer", "science", "(", "especially", "artificial", "intelligence", ")", ",", "mathematics", ",", "operations", "research", ",", "engineering", "and", "bioinformatics", "."], "sentence-detokenized": "Local search algorithms have been widely applied to a large number of difficult computational problems, including problems in computer science (especially artificial intelligence), mathematics, operations research, engineering and bioinformatics.", "token2charspan": [[0, 5], [6, 12], [13, 23], [24, 28], [29, 33], [34, 40], [41, 48], [49, 51], [52, 53], [54, 59], [60, 66], [67, 69], [70, 79], [80, 93], [94, 102], [102, 103], [104, 113], [114, 122], [123, 125], [126, 134], [135, 142], [143, 144], [144, 154], [155, 165], [166, 178], [178, 179], [179, 180], [181, 192], [192, 193], [194, 204], [205, 213], [213, 214], [215, 226], [227, 230], [231, 245], [245, 246]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [8, 8, "location"], [10, 10, "country"], [13, 14, "country"], [18, 19, "algorithm"], [24, 25, "algorithm"], [26, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 8, 8, "physical", "", false, false], [0, 1, 13, 14, "general-affiliation", "nationality", false, false], [0, 1, 18, 19, "general-affiliation", "topic_of_study", false, false], [0, 1, 24, 25, "general-affiliation", "topic_of_study", false, false], [8, 8, 10, 10, "physical", "", false, false], [24, 25, 26, 26, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "b.", "3", "September", "1947", ",", "Wallersdorf", ",", "Germany", ")", "is", "a", "German", "psychologist", "who", "studies", "bounded", "rationality", "and", "the", "use", "of", "heuristics", "in", "decision", "making", "."], "sentence-detokenized": "Gerd Gigerenzer (b. 3 September 1947, Wallersdorf, Germany) is a German psychologist who studies bounded rationality and the use of heuristics in decision making.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 19], [20, 21], [22, 31], [32, 36], [36, 37], [38, 49], [49, 50], [51, 58], [58, 59], [60, 62], [63, 64], [65, 71], [72, 84], [85, 88], [89, 96], [97, 104], [105, 116], [117, 120], [121, 124], [125, 128], [129, 131], [132, 142], [143, 145], [146, 154], [155, 161], [161, 162]]}
{"doc_key": "ai-test-121", "ner": [[2, 5, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["To", "minimise", "the", "mean", "squared", "error", "."], "sentence-detokenized": "To minimise the mean squared error.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 20], [21, 28], [29, 34], [34, 35]]}
{"doc_key": "ai-test-122", "ner": [[10, 14, "misc"], [16, 17, "organisation"], [33, 33, "field"], [45, 45, "misc"], [55, 64, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 14, 16, 17, "origin", "", false, false], [45, 45, 55, 64, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "even", "a", "formal", "language", "with", "a", "regulatory", "academy", ",", "such", "as", "Standard", "French", "with", "Acad\u00e9mie", "fran\u00e7aise", ",", "is", "classified", "as", "a", "natural", "language", "(", "e.g.", "in", "the", "field", "of", "natural", "language", "processing", ")", ",", "because", "its", "prescriptive", "points", "do", "not", "make", "it", "either", "constructed", "enough", "to", "be", "classified", "as", "a", "constructed", "language", "or", "controlled", "enough", "to", "be", "classified", "as", "a", "controlled", "natural", "language", "."], "sentence-detokenized": "However, even a formal language with a regulatory academy, such as Standard French with Acad\u00e9mie fran\u00e7aise, is classified as a natural language (e.g. in the field of natural language processing), because its prescriptive points do not make it either constructed enough to be classified as a constructed language or controlled enough to be classified as a controlled natural language.", "token2charspan": [[0, 7], [7, 8], [9, 13], [14, 15], [16, 22], [23, 31], [32, 36], [37, 38], [39, 49], [50, 57], [57, 58], [59, 63], [64, 66], [67, 75], [76, 82], [83, 87], [88, 96], [97, 106], [106, 107], [108, 110], [111, 121], [122, 124], [125, 126], [127, 134], [135, 143], [144, 145], [145, 149], [150, 152], [153, 156], [157, 162], [163, 165], [166, 173], [174, 182], [183, 193], [193, 194], [194, 195], [196, 203], [204, 207], [208, 220], [221, 227], [228, 230], [231, 234], [235, 239], [240, 242], [243, 249], [250, 261], [262, 268], [269, 271], [272, 274], [275, 285], [286, 288], [289, 290], [291, 302], [303, 311], [312, 314], [315, 325], [326, 332], [333, 335], [336, 338], [339, 349], [350, 352], [353, 354], [355, 365], [366, 373], [374, 382], [382, 383]]}
{"doc_key": "ai-test-123", "ner": [[11, 11, "metrics"], [14, 14, "metrics"], [16, 16, "metrics"], [34, 36, "metrics"], [38, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 16, 14, 14, "named", "", false, false], [38, 38, 34, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "a", "number", "of", "other", "metrics", ",", "most", "simply", "the", "accuracy", "or", "Correct", "Fraction", "(", "FC", ")", ",", "which", "measures", "the", "proportion", "of", "all", "samples", "that", "are", "correctly", "categorised", ";", "the", "complement", "is", "the", "False", "Fraction", "(", "FiC", ")", "."], "sentence-detokenized": "There are a number of other metrics, most simply the accuracy or Correct Fraction (FC), which measures the proportion of all samples that are correctly categorised; the complement is the False Fraction (FiC).", "token2charspan": [[0, 5], [6, 9], [10, 11], [12, 18], [19, 21], [22, 27], [28, 35], [35, 36], [37, 41], [42, 48], [49, 52], [53, 61], [62, 64], [65, 72], [73, 81], [82, 83], [83, 85], [85, 86], [86, 87], [88, 93], [94, 102], [103, 106], [107, 117], [118, 120], [121, 124], [125, 132], [133, 137], [138, 141], [142, 151], [152, 163], [163, 164], [165, 168], [169, 179], [180, 182], [183, 186], [187, 192], [193, 201], [202, 203], [203, 206], [206, 207], [207, 208]]}
{"doc_key": "ai-test-124", "ner": [[0, 0, "researcher"], [6, 9, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 9, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cardie", "became", "a", "member", "of", "the", "Association", "for", "Computational", "Linguistics", "in", "2016", "."], "sentence-detokenized": "Cardie became a member of the Association for Computational Linguistics in 2016.", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 22], [23, 25], [26, 29], [30, 41], [42, 45], [46, 59], [60, 71], [72, 74], [75, 79], [79, 80]]}
{"doc_key": "ai-test-125", "ner": [[14, 16, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "learning", "of", "the", "parameters", "math", "\\", "theta", "/", "math", "is", "usually", "done", "by", "maximum", "likelihood", "learning", "for", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i", ";\\", "theta", ")", "/", "math", "."], "sentence-detokenized": "The learning of the parameters math\\ theta / math is usually done by maximum likelihood learning for mathp (Y _ i | X _ i;\\ theta) / math.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 19], [20, 30], [31, 35], [35, 36], [37, 42], [43, 44], [45, 49], [50, 52], [53, 60], [61, 65], [66, 68], [69, 76], [77, 87], [88, 96], [97, 100], [101, 106], [107, 108], [108, 109], [110, 111], [112, 113], [114, 115], [116, 117], [118, 119], [120, 121], [121, 123], [124, 129], [129, 130], [131, 132], [133, 137], [137, 138]]}
{"doc_key": "ai-test-126", "ner": [[5, 6, "task"], [0, 3, "algorithm"], [8, 9, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 5, 6, "usage", "", true, false], [8, 9, 0, 3, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Non", "-negative", "matrix", "factorisation", "for", "cluster", "analysis", "and", "descriptive", "mining", "."], "sentence-detokenized": "Non-negative matrix factorisation for cluster analysis and descriptive mining.", "token2charspan": [[0, 3], [3, 12], [13, 19], [20, 33], [34, 37], [38, 45], [46, 54], [55, 58], [59, 70], [71, 77], [77, 78]]}
{"doc_key": "ai-test-127", "ner": [[0, 2, "field"], [5, 10, "field"], [16, 18, "field"], [20, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 18, 0, 2, "part-of", "", false, false], [16, 18, 5, 10, "part-of", "", false, false], [20, 22, 0, 2, "part-of", "", false, false], [20, 22, 5, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", "and", "the", "information", "technologies", "it", "enables", ",", "the", "ability", "of", "computers", "to", "perform", "natural", "language", "processing", "and", "machine", "learning", "has", "long", "been", "a", "challenge", "."], "sentence-detokenized": "In computer science and the information technologies it enables, the ability of computers to perform natural language processing and machine learning has long been a challenge.", "token2charspan": [[0, 2], [3, 11], [12, 19], [20, 23], [24, 27], [28, 39], [40, 52], [53, 55], [56, 63], [63, 64], [65, 68], [69, 76], [77, 79], [80, 89], [90, 92], [93, 100], [101, 108], [109, 117], [118, 128], [129, 132], [133, 140], [141, 149], [150, 153], [154, 158], [159, 163], [164, 165], [166, 175], [175, 176]]}
{"doc_key": "ai-test-128", "ner": [[3, 5, "algorithm"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 5, 9, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "Code", "for", "Gabor", "feature", "extraction", "from", "images", "in", "MATLAB", "can", "be", "found", "at"], "sentence-detokenized": "(Code for Gabor feature extraction from images in MATLAB can be found at", "token2charspan": [[0, 1], [1, 5], [6, 9], [10, 15], [16, 23], [24, 34], [35, 39], [40, 46], [47, 49], [50, 56], [57, 60], [61, 63], [64, 69], [70, 72]]}
{"doc_key": "ai-test-129", "ner": [[1, 15, "algorithm"], [19, 19, "task"], [21, 21, "task"], [23, 24, "task"], [26, 27, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["NeuralExpert", "centralises", "the", "design", "features", "around", "the", "type", "of", "problem", "the", "user", "wants", "the", "neural", "network", "to", "solve", "(", "Classification", ",", "Prediction", ",", "Function", "approximation", "or", "Cluster", "analysis", ")", "."], "sentence-detokenized": "NeuralExpert centralises the design features around the type of problem the user wants the neural network to solve (Classification, Prediction, Function approximation or Cluster analysis).", "token2charspan": [[0, 12], [13, 24], [25, 28], [29, 35], [36, 44], [45, 51], [52, 55], [56, 60], [61, 63], [64, 71], [72, 75], [76, 80], [81, 86], [87, 90], [91, 97], [98, 105], [106, 108], [109, 114], [115, 116], [116, 130], [130, 131], [132, 142], [142, 143], [144, 152], [153, 166], [167, 169], [170, 177], [178, 186], [186, 187], [187, 188]]}
{"doc_key": "ai-test-130", "ner": [[2, 4, "misc"], [28, 30, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "quantisation", "step", "size", "(", "\u0394", ")", "is", "small", "relative", "to", "the", "change", "in", "the", "signal", "being", "quantised", ",", "it", "is", "relatively", "easy", "to", "show", "that", "the", "mean", "squared", "error", "produced", "by", "such", "a", "rounding", "process", "will", "be", "approximately", "math", "\\", "Delta", "^", "2", "/", "12", "/", "math.math", "."], "sentence-detokenized": "When the quantisation step size (\u0394) is small relative to the change in the signal being quantised, it is relatively easy to show that the mean squared error produced by such a rounding process will be approximately math\\ Delta ^ 2 / 12 / math.math.", "token2charspan": [[0, 4], [5, 8], [9, 21], [22, 26], [27, 31], [32, 33], [33, 34], [34, 35], [36, 38], [39, 44], [45, 53], [54, 56], [57, 60], [61, 67], [68, 70], [71, 74], [75, 81], [82, 87], [88, 97], [97, 98], [99, 101], [102, 104], [105, 115], [116, 120], [121, 123], [124, 128], [129, 133], [134, 137], [138, 142], [143, 150], [151, 156], [157, 165], [166, 168], [169, 173], [174, 175], [176, 184], [185, 192], [193, 197], [198, 200], [201, 214], [215, 219], [219, 220], [221, 226], [227, 228], [229, 230], [231, 232], [233, 235], [236, 237], [238, 247], [247, 248]]}
{"doc_key": "ai-test-131", "ner": [[15, 17, "product"], [27, 30, "researcher"], [32, 33, "researcher"], [35, 37, "researcher"], [39, 40, "researcher"], [42, 44, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "creation", "of", "a", "rich", "lexicon", "with", "an", "appropriate", "ontology", "requires", "considerable", "effort", ",", "e.g.", "the", "Wordnet", "lexicon", "has", "required", "many", "man", "-", "years", "of", "effort", ".", "G.", "A", ".", "Miller", ",", "R.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Gross", ",", "K", ".", "Miller", "."], "sentence-detokenized": "The creation of a rich lexicon with an appropriate ontology requires considerable effort, e.g. the Wordnet lexicon has required many man-years of effort. G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 17], [18, 22], [23, 30], [31, 35], [36, 38], [39, 50], [51, 59], [60, 68], [69, 81], [82, 88], [88, 89], [90, 94], [95, 98], [99, 106], [107, 114], [115, 118], [119, 127], [128, 132], [133, 136], [136, 137], [137, 142], [143, 145], [146, 152], [152, 153], [154, 156], [157, 158], [158, 159], [160, 166], [166, 167], [168, 170], [171, 179], [179, 180], [181, 183], [184, 186], [187, 195], [195, 196], [197, 199], [200, 205], [205, 206], [207, 208], [208, 209], [210, 216], [216, 217]]}
{"doc_key": "ai-test-132", "ner": [[0, 0, "organisation"], [17, 20, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 20, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Kawasaki", "'s", "portfolio", "also", "includes", "retractable", "roofs", ",", "floors", "and", "other", "giant", "structures", ";", "the", "retractable", "surface", "of", "the", "Sapporo", "Dome", "is", "one", "example", "."], "sentence-detokenized": "Kawasaki's portfolio also includes retractable roofs, floors and other giant structures; the retractable surface of the Sapporo Dome is one example.", "token2charspan": [[0, 8], [8, 10], [11, 20], [21, 25], [26, 34], [35, 46], [47, 52], [52, 53], [54, 60], [61, 64], [65, 70], [71, 76], [77, 87], [87, 88], [89, 92], [93, 104], [105, 112], [113, 115], [116, 119], [120, 127], [128, 132], [133, 135], [136, 139], [140, 147], [147, 148]]}
{"doc_key": "ai-test-133", "ner": [[1, 1, "metrics"], [5, 7, "metrics"], [9, 11, "metrics"], [17, 18, "metrics"], [38, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 17, 18, "related-to", "", false, false], [1, 1, 38, 39, "opposite", "alternative_to", false, false], [5, 7, 1, 1, "type-of", "", false, false], [9, 11, 1, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["kappa", "statistics", ",", "such", "as", "Fleiss", "'", "kappa", "and", "Cohen", "'s", "kappa", ",", "are", "methods", "of", "calculating", "inter-rater", "reliability", "based", "on", "different", "assumptions", "about", "marginal", "or", "prior", "distributions", ",", "and", "are", "increasingly", "used", "as", "chance", "-", "corrected", "alternatives", "for", "accuracy", "in", "other", "contexts", "."], "sentence-detokenized": "kappa statistics, such as Fleiss' kappa and Cohen's kappa, are methods of calculating inter-rater reliability based on different assumptions about marginal or prior distributions, and are increasingly used as chance-corrected alternatives for accuracy in other contexts.", "token2charspan": [[0, 5], [6, 16], [16, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 39], [40, 43], [44, 49], [49, 51], [52, 57], [57, 58], [59, 62], [63, 70], [71, 73], [74, 85], [86, 97], [98, 109], [110, 115], [116, 118], [119, 128], [129, 140], [141, 146], [147, 155], [156, 158], [159, 164], [165, 178], [178, 179], [180, 183], [184, 187], [188, 200], [201, 205], [206, 208], [209, 215], [215, 216], [216, 225], [226, 238], [239, 242], [243, 251], [252, 254], [255, 260], [261, 269], [269, 270]]}
{"doc_key": "ai-test-134", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [18, 18, "researcher"], [27, 29, "algorithm"], [31, 35, "algorithm"], [37, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[4, 5, 18, 18, "role", "student_of", false, false], [7, 8, 18, 18, "role", "student_of", false, false], [10, 11, 18, 18, "role", "student_of", false, false], [13, 14, 18, 18, "role", "student_of", false, false], [31, 35, 4, 5, "origin", "", false, false], [31, 35, 7, 8, "origin", "", false, false], [31, 35, 10, 11, "origin", "", false, false], [31, 35, 13, 14, "origin", "", false, false], [31, 35, 18, 18, "origin", "", false, false], [31, 35, 27, 29, "type-of", "", false, false], [37, 37, 31, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Together", "with", "his", "students", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Graves", "and", "others", ",", "Schmidhuber", "published", "increasingly", "complex", "versions", "of", "a", "type", "of", "recurrent", "neural", "network", "called", "long", "short", "-", "term", "memory", "(", "LSTM", ")", "."], "sentence-detokenized": "Together with his students Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Graves and others, Schmidhuber published increasingly complex versions of a type of recurrent neural network called long short-term memory (LSTM).", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 26], [27, 31], [32, 42], [42, 43], [44, 49], [50, 54], [54, 55], [56, 60], [61, 68], [68, 69], [70, 74], [75, 81], [82, 85], [86, 92], [92, 93], [94, 105], [106, 115], [116, 128], [129, 136], [137, 145], [146, 148], [149, 150], [151, 155], [156, 158], [159, 168], [169, 175], [176, 183], [184, 190], [191, 195], [196, 201], [201, 202], [202, 206], [207, 213], [214, 215], [215, 219], [219, 220], [220, 221]]}
{"doc_key": "ai-test-135", "ner": [[4, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "The", "first", "Cobot", "KUKA", "LBR", "3", "is", "launched", "."], "sentence-detokenized": "2004 - The first Cobot KUKA LBR 3 is launched.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 16], [17, 22], [23, 27], [28, 31], [32, 33], [34, 36], [37, 45], [45, 46]]}
{"doc_key": "ai-test-136", "ner": [[11, 13, "algorithm"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Two", "shallow", "approaches", "used", "to", "train", "and", "then", "disambiguate", "are", "the", "Naive", "Bayes", "classifier", "and", "decision", "trees", "."], "sentence-detokenized": "Two shallow approaches used to train and then disambiguate are the Naive Bayes classifier and decision trees.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 27], [28, 30], [31, 36], [37, 40], [41, 45], [46, 58], [59, 62], [63, 66], [67, 72], [73, 78], [79, 89], [90, 93], [94, 102], [103, 108], [108, 109]]}
{"doc_key": "ai-test-137", "ner": [[5, 5, "misc"], [12, 13, "person"], [15, 17, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 12, 13, "origin", "", false, false], [5, 5, 15, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "practical", "forms", "of", "photography", "were", "introduced", "in", "January", "1839", "by", "Louis", "Daguerre", "and", "Henry", "Fox", "Talbot", "."], "sentence-detokenized": "The first practical forms of photography were introduced in January 1839 by Louis Daguerre and Henry Fox Talbot.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 25], [26, 28], [29, 40], [41, 45], [46, 56], [57, 59], [60, 67], [68, 72], [73, 75], [76, 81], [82, 90], [91, 94], [95, 100], [101, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-138", "ner": [[4, 4, "task"], [8, 8, "task"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 15, 16, "part-of", "task_part_of_field", false, false], [8, 8, 15, 16, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "speech", "synthesis", "combined", "with", "speech", "recognition", "allows", "interaction", "with", "mobile", "devices", "through", "language", "processing", "interfaces", "."], "sentence-detokenized": "For example, speech synthesis combined with speech recognition allows interaction with mobile devices through language processing interfaces.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 19], [20, 29], [30, 38], [39, 43], [44, 50], [51, 62], [63, 69], [70, 81], [82, 86], [87, 93], [94, 101], [102, 109], [110, 118], [119, 129], [130, 140], [140, 141]]}
{"doc_key": "ai-test-139", "ner": [[0, 0, "product"], [14, 14, "programlang"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 14, 14, "general-affiliation", "", false, false], [0, 0, 16, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Phidgets", "can", "be", "programmed", "using", "a", "variety", "of", "software", "and", "programming", "languages", ",", "from", "Java", "to", "Microsoft", "Excel", "."], "sentence-detokenized": "Phidgets can be programmed using a variety of software and programming languages, from Java to Microsoft Excel.", "token2charspan": [[0, 8], [9, 12], [13, 15], [16, 26], [27, 32], [33, 34], [35, 42], [43, 45], [46, 54], [55, 58], [59, 70], [71, 80], [80, 81], [82, 86], [87, 91], [92, 94], [95, 104], [105, 110], [110, 111]]}
{"doc_key": "ai-test-140", "ner": [[2, 3, "field"], [9, 10, "researcher"], [12, 15, "misc"], [22, 24, "field"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 10, "origin", "", false, false], [9, 10, 22, 24, "general-affiliation", "topic_of_study", false, false], [9, 10, 25, 26, "general-affiliation", "topic_of_study", false, false], [12, 15, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "machine", "learning", "was", "coined", "in", "1959", "by", "Arthur", "Samuel", ",", "an", "American", "IBM", "employee", "and", "pioneer", "in", "the", "field", "of", "computer", "games", "and", "artificial", "intelligence", "."], "sentence-detokenized": "The term machine learning was coined in 1959 by Arthur Samuel, an American IBM employee and pioneer in the field of computer games and artificial intelligence.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 25], [26, 29], [30, 36], [37, 39], [40, 44], [45, 47], [48, 54], [55, 61], [61, 62], [63, 65], [66, 74], [75, 78], [79, 87], [88, 91], [92, 99], [100, 102], [103, 106], [107, 112], [113, 115], [116, 124], [125, 130], [131, 134], [135, 145], [146, 158], [158, 159]]}
{"doc_key": "ai-test-141", "ner": [[13, 14, "misc"], [15, 16, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 16, 13, 14, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Fascinated", "by", "the", "technologies", "of", "the", "future", "and", "their", "relationship", "with", "art", ",", "Israeli", "poet", "David", "Avidan", "wanted", "to", "explore", "the", "use", "of", "computers", "for", "writing", "literature", "."], "sentence-detokenized": "Fascinated by the technologies of the future and their relationship with art, Israeli poet David Avidan wanted to explore the use of computers for writing literature.", "token2charspan": [[0, 10], [11, 13], [14, 17], [18, 30], [31, 33], [34, 37], [38, 44], [45, 48], [49, 54], [55, 67], [68, 72], [73, 76], [76, 77], [78, 85], [86, 90], [91, 96], [97, 103], [104, 110], [111, 113], [114, 121], [122, 125], [126, 129], [130, 132], [133, 142], [143, 146], [147, 154], [155, 165], [165, 166]]}
{"doc_key": "ai-test-142", "ner": [[13, 20, "misc"], [3, 3, "organisation"], [10, 10, "location"], [31, 33, "location"], [27, 30, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 13, 20, "part-of", "", false, false], [27, 30, 31, 33, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2017", ",", "Oxbotica", "trialled", "seven", "autonomous", "shuttle", "buses", "in", "Greenwich", "as", "part", "of", "the", "GATEway", "Project", ",", "travelling", "on", "a", "two", "-", "mile", "riverside", "route", "near", "the", "O2", "Arena", "in", "London", ",", "a", "route", "also", "used", "by", "pedestrians", "and", "cyclists", "."], "sentence-detokenized": "In 2017, Oxbotica trialled seven autonomous shuttle buses in Greenwich as part of the GATEway Project, travelling on a two-mile riverside route near the O2 Arena in London, a route also used by pedestrians and cyclists.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 17], [18, 26], [27, 32], [33, 43], [44, 51], [52, 57], [58, 60], [61, 70], [71, 73], [74, 78], [79, 81], [82, 85], [86, 93], [94, 101], [101, 102], [103, 113], [114, 116], [117, 118], [119, 122], [122, 123], [123, 127], [128, 137], [138, 143], [144, 148], [149, 152], [153, 155], [156, 161], [162, 164], [165, 171], [171, 172], [173, 174], [175, 180], [181, 185], [186, 190], [191, 193], [194, 205], [206, 209], [210, 218], [218, 219]]}
{"doc_key": "ai-test-143", "ner": [[9, 15, "task"], [16, 19, "metrics"], [26, 28, "misc"], [29, 29, "metrics"], [31, 31, "metrics"], [34, 34, "metrics"], [36, 36, "metrics"], [38, 40, "metrics"], [43, 43, "metrics"], [45, 45, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[16, 19, 26, 28, "related-to", "is_a", false, false], [16, 19, 29, 29, "usage", "", false, false], [16, 19, 31, 31, "usage", "", false, false], [29, 29, 34, 34, "named", "same", false, false], [31, 31, 45, 45, "named", "same", false, false], [34, 34, 43, 43, "opposite", "", false, false], [34, 34, 45, 45, "opposite", "", false, false], [36, 36, 34, 34, "named", "", false, false], [38, 40, 34, 34, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["An", "unrelated", "but", "widely", "used", "combination", "of", "basic", "statistics", "in", "the", "field", "of", "information", "retrieval", "is", "the", "F", "-", "score", ",", "the", "(", "possibly", "weighted", ")", "harmonic", "mean", "of", "recall", "and", "precision", ",", "where", "recall", "=", "sensitivity", "=", "TRUE", "positive", "rate", ",", "but", "specificity", "and", "precision", "are", "completely", "different", "measures", "."], "sentence-detokenized": "An unrelated but widely used combination of basic statistics in the field of information retrieval is the F-score, the (possibly weighted) harmonic mean of recall and precision, where recall = sensitivity = TRUE positive rate, but specificity and precision are completely different measures.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 23], [24, 28], [29, 40], [41, 43], [44, 49], [50, 60], [61, 63], [64, 67], [68, 73], [74, 76], [77, 88], [89, 98], [99, 101], [102, 105], [106, 107], [107, 108], [108, 113], [113, 114], [115, 118], [119, 120], [120, 128], [129, 137], [137, 138], [139, 147], [148, 152], [153, 155], [156, 162], [163, 166], [167, 176], [176, 177], [178, 183], [184, 190], [191, 192], [193, 204], [205, 206], [207, 211], [212, 220], [221, 225], [225, 226], [227, 230], [231, 242], [243, 246], [247, 256], [257, 260], [261, 271], [272, 281], [282, 290], [290, 291]]}
{"doc_key": "ai-test-144", "ner": [[0, 1, "field"], [10, 10, "field"], [12, 12, "field"], [14, 15, "field"], [17, 18, "field"], [26, 27, "product"], [29, 32, "product"], [34, 36, "product"], [37, 38, "product"], [8, 50, "product"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 10, "origin", "takes_inspiration_from", false, false], [0, 1, 12, 12, "origin", "takes_inspiration_from", false, false], [0, 1, 14, 15, "origin", "takes_inspiration_from", false, false], [0, 1, 17, 18, "origin", "takes_inspiration_from", false, false], [26, 27, 0, 1, "origin", "", false, false], [29, 32, 0, 1, "origin", "", false, false], [34, 36, 0, 1, "origin", "", false, false], [37, 38, 0, 1, "origin", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Neuromorphic", "engineering", "is", "an", "interdisciplinary", "subject", "inspired", "by", "biology", ",", "physics", ",", "mathematics", ",", "computer", "science", "and", "electronic", "engineering", "to", "design", "artificial", "neural", "systems", "such", "as", "vision", "systems", ",", "head", "-", "eye", "systems", ",", "auditory", "processors", "and", "autonomous", "robots", "whose", "physical", "architecture", "and", "design", "principles", "are", "based", "on", "biological", "nervous", "systems", "."], "sentence-detokenized": "Neuromorphic engineering is an interdisciplinary subject inspired by biology, physics, mathematics, computer science and electronic engineering to design artificial neural systems such as vision systems, head-eye systems, auditory processors and autonomous robots whose physical architecture and design principles are based on biological nervous systems.", "token2charspan": [[0, 12], [13, 24], [25, 27], [28, 30], [31, 48], [49, 56], [57, 65], [66, 68], [69, 76], [76, 77], [78, 85], [85, 86], [87, 98], [98, 99], [100, 108], [109, 116], [117, 120], [121, 131], [132, 143], [144, 146], [147, 153], [154, 164], [165, 171], [172, 179], [180, 184], [185, 187], [188, 194], [195, 202], [202, 203], [204, 208], [208, 209], [209, 212], [213, 220], [220, 221], [222, 230], [231, 241], [242, 245], [246, 256], [257, 263], [264, 269], [270, 278], [279, 291], [292, 295], [296, 302], [303, 313], [314, 317], [318, 323], [324, 326], [327, 337], [338, 345], [346, 353], [353, 354]]}
{"doc_key": "ai-test-145", "ner": [[0, 8, "metrics"], [11, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 0, 8, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "be", "more", "precise", ",", "the", "BIBO", "stability", "criterion", "requires", "the", "ROC", "of", "the", "system", "to", "include", "the", "unit", "circle", "."], "sentence-detokenized": "To be more precise, the BIBO stability criterion requires the ROC of the system to include the unit circle.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 18], [18, 19], [20, 23], [24, 28], [29, 38], [39, 48], [49, 57], [58, 61], [62, 65], [66, 68], [69, 72], [73, 79], [80, 82], [83, 90], [91, 94], [95, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-test-146", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "The", "programme", "has", "been", "rewritten", "in", "Java", "since", "1998", "."], "sentence-detokenized": "2 The programme has been rewritten in Java since 1998.", "token2charspan": [[0, 1], [2, 5], [6, 15], [16, 19], [20, 24], [25, 34], [35, 37], [38, 42], [43, 48], [49, 53], [53, 54]]}
{"doc_key": "ai-test-147", "ner": [[0, 1, "metrics"], [6, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 6, 9, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "MCC", "can", "be", "calculated", "directly", "from", "the", "confusion", "matrix", "using", "the", "formula", ":"], "sentence-detokenized": "The MCC can be calculated directly from the confusion matrix using the formula:", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 25], [26, 34], [35, 39], [40, 43], [44, 53], [54, 60], [61, 66], [67, 70], [71, 78], [78, 79]]}
{"doc_key": "ai-test-148", "ner": [[8, 13, "organisation"], [17, 24, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 13, 17, 24, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "developed", "by", "a", "team", "at", "the", "MIT", "-", "IBM", "Watson", "AI", "Lab", "and", "first", "presented", "at", "the", "2018", "International", "Conference", "on", "Learning", "Representations", "."], "sentence-detokenized": "It was developed by a team at the MIT-IBM Watson AI Lab and first presented at the 2018 International Conference on Learning Representations.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 29], [30, 33], [34, 37], [37, 38], [38, 41], [42, 48], [49, 51], [52, 55], [56, 59], [60, 65], [66, 75], [76, 78], [79, 82], [83, 87], [88, 101], [102, 112], [113, 115], [116, 124], [125, 140], [140, 141]]}
{"doc_key": "ai-test-149", "ner": [[2, 3, "metrics"], [15, 16, "metrics"], [14, 20, "metrics"], [42, 42, "metrics"], [44, 44, "metrics"], [47, 50, "metrics"], [53, 53, "metrics"], [55, 56, "metrics"], [57, 59, "metrics"], [62, 63, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[15, 16, 42, 42, "type-of", "", false, false], [15, 16, 47, 50, "related-to", "collapses_to_identity", false, false], [14, 20, 44, 44, "type-of", "", false, false], [14, 20, 47, 50, "related-to", "collapses_to_identity", false, false], [14, 20, 57, 59, "named", "same", false, false], [53, 53, 62, 63, "related-to", "collapses_to_identity", false, false], [55, 56, 62, 63, "related-to", "collapses_to_identity", false, false], [57, 59, 62, 63, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["When", "the", "ACTUAL", "prevalences", "for", "the", "two", "positive", "variables", "are", "equal", ",", "as", "assumed", "in", "Fleiss", "kappa", "and", "F", "-", "score", ",", "i.e.", "when", "the", "number", "of", "positive", "predictions", "matches", "the", "number", "of", "positive", "classes", "in", "the", "dichotomous", "case", ",", "the", "differential", "kappa", "and", "correlation", "measure", "identifies", "with", "Youden", "'s", "J", ",", "and", "recall", ",", "precision", "and", "F", "-", "score", "similarly", "identifies", "with", "accuracy", "."], "sentence-detokenized": "When the ACTUAL prevalences for the two positive variables are equal, as assumed in Fleiss kappa and F-score, i.e. when the number of positive predictions matches the number of positive classes in the dichotomous case, the differential kappa and correlation measure identifies with Youden's J, and recall, precision and F-score similarly identifies with accuracy.", "token2charspan": [[0, 4], [5, 8], [9, 15], [16, 27], [28, 31], [32, 35], [36, 39], [40, 48], [49, 58], [59, 62], [63, 68], [68, 69], [70, 72], [73, 80], [81, 83], [84, 90], [91, 96], [97, 100], [101, 102], [102, 103], [103, 108], [108, 109], [110, 114], [115, 119], [120, 123], [124, 130], [131, 133], [134, 142], [143, 154], [155, 162], [163, 166], [167, 173], [174, 176], [177, 185], [186, 193], [194, 196], [197, 200], [201, 212], [213, 217], [217, 218], [219, 222], [223, 235], [236, 241], [242, 245], [246, 257], [258, 265], [266, 276], [277, 281], [282, 288], [288, 290], [291, 292], [292, 293], [294, 297], [298, 304], [304, 305], [306, 315], [316, 319], [320, 321], [321, 322], [322, 327], [328, 337], [338, 348], [349, 353], [354, 362], [362, 363]]}
{"doc_key": "ai-test-150", "ner": [[0, 4, "misc"], [6, 6, "misc"], [9, 9, "conference"], [14, 17, "task"], [19, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 9, 9, "part-of", "", false, false], [0, 4, 9, 9, "physical", "", false, false], [0, 4, 9, 9, "temporal", "", false, false], [6, 6, 0, 4, "named", "", false, false], [14, 17, 0, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Building", "Educational", "Applications", "workshop", "(", "BEA", ")", "at", "NAACL", "2013", "hosted", "the", "inaugural", "NLI", "joi", "nt", "task", ".", "Tetreault", "et", "al", ",", "2013", "The", "competition", "resulted", "in", "29", "entries", "from", "teams", "around", "the", "world", ",", "24", "of", "which", "also", "published", "a", "paper", "describing", "their", "system", "and", "approach", "."], "sentence-detokenized": "The Building Educational Applications workshop (BEA) at NAACL 2013 hosted the inaugural NLI joint task. Tetreault et al, 2013 The competition resulted in 29 entries from teams around the world, 24 of which also published a paper describing their system and approach.", "token2charspan": [[0, 3], [4, 12], [13, 24], [25, 37], [38, 46], [47, 48], [48, 51], [51, 52], [53, 55], [56, 61], [62, 66], [67, 73], [74, 77], [78, 87], [88, 91], [92, 95], [95, 97], [98, 102], [102, 103], [104, 113], [114, 116], [117, 119], [119, 120], [121, 125], [126, 129], [130, 141], [142, 150], [151, 153], [154, 156], [157, 164], [165, 169], [170, 175], [176, 182], [183, 186], [187, 192], [192, 193], [194, 196], [197, 199], [200, 205], [206, 210], [211, 220], [221, 222], [223, 228], [229, 239], [240, 245], [246, 252], [253, 256], [257, 265], [265, 266]]}
{"doc_key": "ai-test-151", "ner": [[0, 3, "algorithm"], [5, 45, "algorithm"], [14, 17, "misc"], [20, 22, "misc"], [37, 38, "misc"], [42, 42, "algorithm"], [45, 45, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 5, 45, "type-of", "", false, false], [0, 3, 14, 17, "related-to", "finds", false, false], [20, 22, 14, 17, "type-of", "", false, false], [45, 45, 42, 42, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Viterbi", "algorithm", "is", "a", "dynamic", "programming", "algorithm", "used", "to", "find", "the", "most", "probable", "sequence", "of", "hidden", "states", ",", "called", "the", "Viterbi", "path", ",", "resulting", "in", "a", "sequence", "of", "observed", "events", ",", "especially", "in", "the", "context", "of", "Markov", "information", "sources", "and", "hidden", "Markov", "models", "(", "HMM", ")", "."], "sentence-detokenized": "The Viterbi algorithm is a dynamic programming algorithm used to find the most probable sequence of hidden states, called the Viterbi path, resulting in a sequence of observed events, especially in the context of Markov information sources and hidden Markov models (HMM).", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 24], [25, 26], [27, 34], [35, 46], [47, 56], [57, 61], [62, 64], [65, 69], [70, 73], [74, 78], [79, 87], [88, 96], [97, 99], [100, 106], [107, 113], [113, 114], [115, 121], [122, 125], [126, 133], [134, 138], [138, 139], [140, 149], [150, 152], [153, 154], [155, 163], [164, 166], [167, 175], [176, 182], [182, 183], [184, 194], [195, 197], [198, 201], [202, 209], [210, 212], [213, 219], [220, 231], [232, 239], [240, 243], [244, 250], [251, 257], [258, 264], [265, 266], [266, 269], [269, 270], [270, 271]]}
{"doc_key": "ai-test-152", "ner": [[0, 1, "field"], [3, 5, "algorithm"], [9, 9, "misc"], [12, 13, "algorithm"], [8, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 0, 1, "part-of", "", false, false], [3, 5, 9, 9, "general-affiliation", "", false, false], [3, 5, 12, 13, "related-to", "generalizes_from", false, false], [3, 5, 8, 16, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "statistics", ",", "multinomial", "logistic", "regression", "is", "a", "classification", "method", "that", "generalises", "logistic", "regression", "to", "multiclass", "classification", ",", "i.e.", "to", "more", "than", "two", "possible", "discrete", "outcomes", "."], "sentence-detokenized": "In statistics, multinomial logistic regression is a classification method that generalises logistic regression to multiclass classification, i.e. to more than two possible discrete outcomes.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 26], [27, 35], [36, 46], [47, 49], [50, 51], [52, 66], [67, 73], [74, 78], [79, 90], [91, 99], [100, 110], [111, 113], [114, 124], [125, 139], [139, 140], [141, 145], [146, 148], [149, 153], [154, 158], [159, 162], [163, 171], [172, 180], [181, 189], [189, 190]]}
{"doc_key": "ai-test-153", "ner": [[0, 2, "algorithm"], [10, 10, "field"], [12, 14, "field"], [17, 17, "task"], [19, 20, "task"], [22, 23, "task"], [25, 26, "researcher"], [28, 29, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 10, 10, "part-of", "", false, false], [0, 2, 12, 14, "part-of", "", false, false], [17, 17, 0, 2, "usage", "", true, false], [19, 20, 0, 2, "usage", "", true, false], [22, 23, 0, 2, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hidden", "Markov", "models", "are", "known", "for", "their", "applications", "in", "reinforcement", "learning", "and", "temporal", "pattern", "recognition", "such", "as", "speech", ",", "handwriting", "recognition", ",", "gesture", "recognition", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Hidden Markov models are known for their applications in reinforcement learning and temporal pattern recognition such as speech, handwriting recognition, gesture recognition, Thad Starner, Alex Pentland.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 30], [31, 34], [35, 40], [41, 53], [54, 56], [57, 70], [71, 79], [80, 83], [84, 92], [93, 100], [101, 112], [113, 117], [118, 120], [121, 127], [127, 128], [129, 140], [141, 152], [152, 153], [154, 161], [162, 173], [173, 174], [175, 179], [180, 187], [187, 188], [189, 193], [194, 202], [202, 203]]}
{"doc_key": "ai-test-154", "ner": [[20, 23, "metrics"], [25, 27, "misc"]], "ner_mapping_to_source": [1, 2], "relations": [[20, 23, 25, 27, "related-to", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Essentially", ",", "this", "means", "that", "the", "conditional", "probability", "of", "a", "word", ",", "given", "its", "history", ",", "is", "proportional", "to", "the", "maximum", "likelihood", "estimate", "of", "that", "n", "-", "gram", "if", "it", "has", "been", "seen", "more", "than", "k", "times", "in", "training", "."], "sentence-detokenized": "Essentially, this means that the conditional probability of a word, given its history, is proportional to the maximum likelihood estimate of that n-gram if it has been seen more than k times in training.", "token2charspan": [[0, 11], [11, 12], [13, 17], [18, 23], [24, 28], [29, 32], [33, 44], [45, 56], [57, 59], [60, 61], [62, 66], [66, 67], [68, 73], [74, 77], [78, 85], [85, 86], [87, 89], [90, 102], [103, 105], [106, 109], [110, 117], [118, 128], [129, 137], [138, 140], [141, 145], [146, 147], [147, 148], [148, 152], [153, 155], [156, 158], [159, 162], [163, 167], [168, 172], [173, 177], [178, 182], [183, 184], [185, 190], [191, 193], [194, 202], [202, 203]]}
{"doc_key": "ai-test-155", "ner": [[4, 5, "task"], [7, 8, "task"], [10, 13, "task"], [16, 19, "task"], [26, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[26, 28, 16, 19, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "interested", "in", "knowledge", "representation", ",", "commonsense", "reasoning", "and", "natural", "language", "understanding", "and", "believes", "that", "deep", "language", "understanding", "can", "currently", "only", "be", "achieved", "by", "significant", "manual", "engineering", "of", "semantically", "rich", "formalisms", "combined", "with", "statistical", "preferences", "."], "sentence-detokenized": "He is interested in knowledge representation, commonsense reasoning and natural language understanding and believes that deep language understanding can currently only be achieved by significant manual engineering of semantically rich formalisms combined with statistical preferences.", "token2charspan": [[0, 2], [3, 5], [6, 16], [17, 19], [20, 29], [30, 44], [44, 45], [46, 57], [58, 67], [68, 71], [72, 79], [80, 88], [89, 102], [103, 106], [107, 115], [116, 120], [121, 125], [126, 134], [135, 148], [149, 152], [153, 162], [163, 167], [168, 170], [171, 179], [180, 182], [183, 194], [195, 201], [202, 213], [214, 216], [217, 229], [230, 234], [235, 245], [246, 254], [255, 259], [260, 271], [272, 283], [283, 284]]}
{"doc_key": "ai-test-156", "ner": [[0, 0, "programlang"], [2, 2, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["JavaScript", ",", "Python", "or"], "sentence-detokenized": "JavaScript, Python or", "token2charspan": [[0, 10], [10, 11], [12, 18], [19, 21]]}
{"doc_key": "ai-test-157", "ner": [[0, 2, "misc"], [6, 7, "misc"], [11, 11, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 7, "part-of", "", false, false], [6, 7, 11, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Newcomb", "Awards", "are", "announced", "in", "AI", "Magazine", ",", "published", "by", "AAAI", "."], "sentence-detokenized": "The Newcomb Awards are announced in AI Magazine, published by AAAI.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 22], [23, 32], [33, 35], [36, 38], [39, 47], [47, 48], [49, 58], [59, 61], [62, 66], [66, 67]]}
{"doc_key": "ai-test-158", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "squared", "error", "on", "a", "test", "set", "of", "100", "samples", "is", "0.084", ",", "which", "is", "smaller", "than", "the", "non-normalised", "error", "."], "sentence-detokenized": "The mean squared error on a test set of 100 samples is 0.084, which is smaller than the non-normalised error.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 25], [26, 27], [28, 32], [33, 36], [37, 39], [40, 43], [44, 51], [52, 54], [55, 60], [60, 61], [62, 67], [68, 70], [71, 78], [79, 83], [84, 87], [88, 102], [103, 108], [108, 109]]}
{"doc_key": "ai-test-159", "ner": [[0, 3, "metrics"], [9, 11, "field"], [16, 22, "task"], [24, 24, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 11, 0, 3, "usage", "", false, false], [16, 22, 9, 11, "part-of", "task_part_of_field", false, false], [24, 24, 16, 22, "named", "", false, false], [27, 28, 9, 11, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "F", "-", "score", "is", "widely", "used", "in", "the", "natural", "language", "processing", "literature", ",", "for", "example", "in", "the", "evaluation", "of", "named", "entity", "recognition", "(", "NER", ")", "and", "word", "segmentation", "."], "sentence-detokenized": "The F-score is widely used in the natural language processing literature, for example in the evaluation of named entity recognition (NER) and word segmentation.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 21], [22, 26], [27, 29], [30, 33], [34, 41], [42, 50], [51, 61], [62, 72], [72, 73], [74, 77], [78, 85], [86, 88], [89, 92], [93, 103], [104, 106], [107, 112], [113, 119], [120, 131], [132, 133], [133, 136], [136, 137], [138, 141], [142, 146], [147, 159], [159, 160]]}
{"doc_key": "ai-test-160", "ner": [[0, 1, "product"], [4, 6, "product"], [15, 16, "misc"], [10, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 15, 16, "related-to", "performs_task", false, false], [0, 1, 10, 19, "related-to", "performs_task", false, false], [4, 6, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Chatbots", "are", "often", "used", "in", "dialogue", "systems", "for", "various", "purposes", "such", "as", "customer", "service", ",", "request", "routing", "or", "information", "gathering", "."], "sentence-detokenized": "Chatbots are often used in dialogue systems for various purposes such as customer service, request routing or information gathering.", "token2charspan": [[0, 8], [9, 12], [13, 18], [19, 23], [24, 26], [27, 35], [36, 43], [44, 47], [48, 55], [56, 64], [65, 69], [70, 72], [73, 81], [82, 89], [89, 90], [91, 98], [99, 106], [107, 109], [110, 121], [122, 131], [131, 132]]}
{"doc_key": "ai-test-161", "ner": [[3, 9, "conference"], [12, 22, "conference"], [27, 37, "conference"], [43, 43, "conference"], [47, 50, "conference"], [52, 53, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 22, 3, 9, "named", "", false, false], [27, 37, 3, 9, "named", "", false, false], [43, 43, 27, 37, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Notable", "journals", "include", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "later", "renamed", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "and", "since", "September", "2014", "renamed", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "-", "after", "merging", "with", "an", "ACM", "publication", ")", ",", "Computer", "Speech", "and", "Language", "and", "Speech", "Communication", "."], "sentence-detokenized": "Notable journals include IEEE Transactions on Speech and Audio Processing (later renamed IEEE Transactions on Audio, Speech and Language Processing and since September 2014 renamed IEEE/ACM Transactions on Audio, Speech and Language Processing - after merging with an ACM publication), Computer Speech and Language and Speech Communication.", "token2charspan": [[0, 7], [8, 16], [17, 24], [25, 29], [30, 42], [43, 45], [46, 52], [53, 56], [57, 62], [63, 73], [74, 75], [75, 80], [81, 88], [89, 93], [94, 106], [107, 109], [110, 115], [115, 116], [117, 123], [124, 127], [128, 136], [137, 147], [148, 151], [152, 157], [158, 167], [168, 172], [173, 180], [181, 185], [185, 186], [186, 189], [190, 202], [203, 205], [206, 211], [211, 212], [213, 219], [220, 223], [224, 232], [233, 243], [244, 245], [246, 251], [252, 259], [260, 264], [265, 267], [268, 271], [272, 283], [283, 284], [284, 285], [286, 294], [295, 301], [302, 305], [306, 314], [315, 318], [319, 325], [326, 339], [339, 340]]}
{"doc_key": "ai-test-162", "ner": [[0, 0, "algorithm"], [5, 6, "task"], [8, 9, "field"], [7, 12, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 0, 0, "usage", "", false, false], [5, 6, 8, 9, "part-of", "task_part_of_field", false, false], [5, 6, 7, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["EM", "is", "often", "used", "for", "data", "clustering", "in", "machine", "learning", "and", "computer", "vision", "."], "sentence-detokenized": "EM is often used for data clustering in machine learning and computer vision.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 16], [17, 20], [21, 25], [26, 36], [37, 39], [40, 47], [48, 56], [57, 60], [61, 69], [70, 76], [76, 77]]}
{"doc_key": "ai-test-163", "ner": [[8, 10, "metrics"], [23, 26, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 10, 23, 26, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["While", "there", "is", "no", "perfect", "way", "to", "describe", "the", "confusion", "matrix", "of", "TRUE", "and", "FALSE", "positives", "and", "negatives", "with", "a", "single", "number", ",", "Matthews", "correlation", "coefficient", "is", "generally", "considered", "one", "of", "the", "best", "such", "measures", "."], "sentence-detokenized": "While there is no perfect way to describe the confusion matrix of TRUE and FALSE positives and negatives with a single number, Matthews correlation coefficient is generally considered one of the best such measures.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 17], [18, 25], [26, 29], [30, 32], [33, 41], [42, 45], [46, 55], [56, 62], [63, 65], [66, 70], [71, 74], [75, 80], [81, 90], [91, 94], [95, 104], [105, 109], [110, 111], [112, 118], [119, 125], [125, 126], [127, 135], [136, 147], [148, 159], [160, 162], [163, 172], [173, 183], [184, 187], [188, 190], [191, 194], [195, 199], [200, 204], [205, 213], [213, 214]]}
{"doc_key": "ai-test-164", "ner": [[13, 13, "field"], [27, 29, "field"], [36, 36, "field"], [41, 42, "algorithm"], [44, 45, "task"], [47, 48, "algorithm"], [37, 55, "algorithm"], [58, 58, "algorithm"], [64, 66, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[36, 36, 27, 29, "part-of", "subfield", false, false], [41, 42, 36, 36, "part-of", "", false, true], [44, 45, 36, 36, "part-of", "", false, true], [47, 48, 36, 36, "part-of", "", false, true], [37, 55, 36, 36, "part-of", "", false, true], [58, 58, 36, 36, "part-of", "", false, true], [64, 66, 36, 36, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "the", "size", "and", "complexity", "of", "data", "sets", "increased", ",", "direct", "applied", "data", "analysis", "was", "augmented", "by", "indirect", ",", "automated", "data", "processing", ",", "aided", "by", "other", "discoveries", "in", "computer", "science", ",", "especially", "in", "the", "field", "of", "machine", "learning", ",", "such", "as", "neural", "networks", ",", "cluster", "analysis", ",", "genetic", "algorithms", "(", "1950s", ")", ",", "decision", "tree", "learning", "and", "decision", "rules", "(", "1960s", ")", ",", "and", "support", "vector", "machines", "(", "1990", "s", ")", "."], "sentence-detokenized": "As the size and complexity of data sets increased, direct applied data analysis was augmented by indirect, automated data processing, aided by other discoveries in computer science, especially in the field of machine learning, such as neural networks, cluster analysis, genetic algorithms (1950s), decision tree learning and decision rules (1960s), and support vector machines (1990s).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 15], [16, 26], [27, 29], [30, 34], [35, 39], [40, 49], [49, 50], [51, 57], [58, 65], [66, 70], [71, 79], [80, 83], [84, 93], [94, 96], [97, 105], [105, 106], [107, 116], [117, 121], [122, 132], [132, 133], [134, 139], [140, 142], [143, 148], [149, 160], [161, 163], [164, 172], [173, 180], [180, 181], [182, 192], [193, 195], [196, 199], [200, 205], [206, 208], [209, 216], [217, 225], [225, 226], [227, 231], [232, 234], [235, 241], [242, 250], [250, 251], [252, 259], [260, 268], [268, 269], [270, 277], [278, 288], [289, 290], [290, 295], [295, 296], [296, 297], [298, 306], [307, 311], [312, 320], [321, 324], [325, 333], [334, 339], [340, 341], [341, 346], [346, 347], [347, 348], [349, 352], [353, 360], [361, 367], [368, 376], [377, 378], [378, 382], [382, 383], [383, 384], [384, 385]]}
{"doc_key": "ai-test-165", "ner": [[4, 4, "researcher"], [9, 10, "misc"], [18, 19, "researcher"], [12, 22, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 4, 4, "artifact", "", false, false], [9, 10, 18, 19, "artifact", "", false, false], [9, 10, 12, 22, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "autumn", "2005", ",", "Thrun", "published", "a", "textbook", "entitled", "Probabilistic", "Robotics", "together", "with", "his", "long", "-", "time", "colleagues", "Dieter", "Fox", "and", "Wolfram", "Burgard", "."], "sentence-detokenized": "In autumn 2005, Thrun published a textbook entitled Probabilistic Robotics together with his long-time colleagues Dieter Fox and Wolfram Burgard.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 21], [22, 31], [32, 33], [34, 42], [43, 51], [52, 65], [66, 74], [75, 83], [84, 88], [89, 92], [93, 97], [97, 98], [98, 102], [103, 113], [114, 120], [121, 124], [125, 128], [129, 136], [137, 144], [144, 145]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "and", "Pereiramath", "are", "as", "follows", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum and Pereiramath are as follows:", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 37], [38, 49], [50, 53], [54, 56], [57, 64], [64, 65]]}
{"doc_key": "ai-test-167", "ner": [[0, 1, "task"], [3, 3, "task"], [7, 8, "field"], [14, 15, "field"], [18, 19, "field"], [21, 21, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 14, 15, "part-of", "task_part_of_field", false, false], [0, 1, 18, 19, "part-of", "task_part_of_field", false, false], [3, 3, 0, 1, "named", "", false, false], [14, 15, 7, 8, "part-of", "subfield", false, false], [18, 19, 7, 8, "part-of", "subfield", false, false], [21, 21, 18, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Question", "answering", "(", "QA", ")", "is", "a", "computer", "science", "discipline", "in", "the", "fields", "of", "information", "retrieval", "and", "natural", "language", "processing", "(", "NLP", ")", "that", "deals", "with", "building", "systems", "that", "automatically", "answer", "questions", "asked", "by", "humans", "in", "a", "natural", "language", "."], "sentence-detokenized": "Question answering (QA) is a computer science discipline in the fields of information retrieval and natural language processing (NLP) that deals with building systems that automatically answer questions asked by humans in a natural language.", "token2charspan": [[0, 8], [9, 18], [19, 20], [20, 22], [22, 23], [24, 26], [27, 28], [29, 37], [38, 45], [46, 56], [57, 59], [60, 63], [64, 70], [71, 73], [74, 85], [86, 95], [96, 99], [100, 107], [108, 116], [117, 127], [128, 129], [129, 132], [132, 133], [134, 138], [139, 144], [145, 149], [150, 158], [159, 166], [167, 171], [172, 185], [186, 192], [193, 202], [203, 208], [209, 211], [212, 218], [219, 221], [222, 223], [224, 231], [232, 240], [240, 241]]}
{"doc_key": "ai-test-168", "ner": [[9, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "the", "version", "of", "the", "metric", "used", "in", "NIST", "assessments", "prior", "to", "2009", "used", "the", "shortest", "reference", "sentence", "instead", "."], "sentence-detokenized": "However, the version of the metric used in NIST assessments prior to 2009 used the shortest reference sentence instead.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 20], [21, 23], [24, 27], [28, 34], [35, 39], [40, 42], [43, 47], [48, 59], [60, 65], [66, 68], [69, 73], [74, 78], [79, 82], [83, 91], [92, 101], [102, 110], [111, 118], [118, 119]]}
{"doc_key": "ai-test-169", "ner": [[5, 5, "person"], [15, 15, "product"]], "ner_mapping_to_source": [0, 2], "relations": [[5, 5, 15, 15, "related-to", "invests_in", false, false]], "relations_mapping_to_source": [0], "sentence": ["On", "27", "August", "2018", ",", "Toyota", "announced", "a", "$", "500", "million", "investment", "in", "Uber", "'s", "autonomous", "vehicles", "."], "sentence-detokenized": "On 27 August 2018, Toyota announced a $500 million investment in Uber's autonomous vehicles.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 17], [17, 18], [19, 25], [26, 35], [36, 37], [38, 39], [39, 42], [43, 50], [51, 61], [62, 64], [65, 69], [69, 71], [72, 82], [83, 91], [91, 92]]}
{"doc_key": "ai-test-170", "ner": [[3, 11, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sample", "maximum", "is", "a", "maximum", "likelihood", "estimator", "for", "the", "population", "maximum", ",", "but", "is", "biased", "as", "discussed", "above", "."], "sentence-detokenized": "The sample maximum is a maximum likelihood estimator for the population maximum, but is biased as discussed above.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 21], [22, 23], [24, 31], [32, 42], [43, 52], [53, 56], [57, 60], [61, 71], [72, 79], [79, 80], [81, 84], [85, 87], [88, 94], [95, 97], [98, 107], [108, 113], [113, 114]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [4, 4, "misc"], [7, 7, "metrics"], [16, 18, "algorithm"], [20, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 4, 4, "related-to", "overcomes", false, false], [0, 0, 7, 7, "related-to", "increases", false, false], [4, 4, 16, 18, "opposite", "", false, false], [4, 4, 20, 22, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LSI", "helps", "to", "overcome", "synonymy", "by", "increasing", "recall", ",", "one", "of", "the", "most", "problematic", "constraints", "of", "Boolean", "keyword", "queries", "and", "vector", "space", "models", "."], "sentence-detokenized": "LSI helps to overcome synonymy by increasing recall, one of the most problematic constraints of Boolean keyword queries and vector space models.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 21], [22, 30], [31, 33], [34, 44], [45, 51], [51, 52], [53, 56], [57, 59], [60, 63], [64, 68], [69, 80], [81, 92], [93, 95], [96, 103], [104, 111], [112, 119], [120, 123], [124, 130], [131, 136], [137, 143], [143, 144]]}
{"doc_key": "ai-test-172", "ner": [[0, 1, "task"], [18, 18, "programlang"], [20, 20, "programlang"], [22, 22, "programlang"], [24, 25, "programlang"], [27, 27, "programlang"], [29, 29, "programlang"], [31, 31, "programlang"], [33, 33, "programlang"], [35, 35, "programlang"], [37, 37, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 18, 18, "general-affiliation", "", false, false], [0, 1, 20, 20, "general-affiliation", "", false, false], [0, 1, 22, 22, "general-affiliation", "", false, false], [0, 1, 24, 25, "general-affiliation", "", false, false], [0, 1, 27, 27, "general-affiliation", "", false, false], [0, 1, 29, 29, "general-affiliation", "", false, false], [0, 1, 31, 31, "general-affiliation", "", false, false], [0, 1, 33, 33, "general-affiliation", "", false, false], [0, 1, 35, 35, "general-affiliation", "", false, false], [0, 1, 37, 37, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Data", "acquisition", "applications", "are", "usually", "controlled", "by", "software", "programmes", "developed", "using", "various", "general", "purpose", "programming", "languages", "such", "as", "Assembly", ",", "BASIC", ",", "C", ",", "C", "++", ",", "C#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", ",", "etc."], "sentence-detokenized": "Data acquisition applications are usually controlled by software programmes developed using various general purpose programming languages such as Assembly, BASIC, C, C++, C#, Fortran, Java, LabVIEW, Lisp, Pascal, etc.", "token2charspan": [[0, 4], [5, 16], [17, 29], [30, 33], [34, 41], [42, 52], [53, 55], [56, 64], [65, 75], [76, 85], [86, 91], [92, 99], [100, 107], [108, 115], [116, 127], [128, 137], [138, 142], [143, 145], [146, 154], [154, 155], [156, 161], [161, 162], [163, 164], [164, 165], [166, 167], [167, 169], [169, 170], [171, 173], [173, 174], [175, 182], [182, 183], [184, 188], [188, 189], [190, 197], [197, 198], [199, 203], [203, 204], [205, 211], [211, 212], [213, 217]]}
{"doc_key": "ai-test-173", "ner": [[3, 3, "organisation"], [6, 6, "product"], [10, 10, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 3, 3, "artifact", "", false, false], [6, 6, 10, 10, "physical", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2003", ",", "Honda", "aired", "the", "Cog", "advert", "in", "the", "UK", "and", "on", "the", "internet", "."], "sentence-detokenized": "In 2003, Honda aired the Cog advert in the UK and on the internet.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 20], [21, 24], [25, 28], [29, 35], [36, 38], [39, 42], [43, 45], [46, 49], [50, 52], [53, 56], [57, 65], [65, 66]]}
{"doc_key": "ai-test-174", "ner": [[0, 4, "conference"], [6, 9, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 6, 9, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Association", "for", "Computational", "Linguistics", "defines", "computational", "linguistics", "as", "follows", ":"], "sentence-detokenized": "The Association for Computational Linguistics defines computational linguistics as follows:", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 33], [34, 45], [46, 53], [54, 67], [68, 79], [80, 82], [83, 90], [90, 91]]}
{"doc_key": "ai-test-175", "ner": [[0, 2, "algorithm"], [9, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 11, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["Expectation", "-maximisation", "algorithms", "can", "be", "used", "to", "compute", "approximate", "maximum", "likelihood", "estimates", "of", "unknown", "state", "-", "space", "parameters", "within", "minimum", "variance", "filters", "and", "smoothers", "."], "sentence-detokenized": "Expectation-maximisation algorithms can be used to compute approximate maximum likelihood estimates of unknown state-space parameters within minimum variance filters and smoothers.", "token2charspan": [[0, 11], [11, 24], [25, 35], [36, 39], [40, 42], [43, 47], [48, 50], [51, 58], [59, 70], [71, 78], [79, 89], [90, 99], [100, 102], [103, 110], [111, 116], [116, 117], [117, 122], [123, 133], [134, 140], [141, 148], [149, 157], [158, 165], [166, 169], [170, 179], [179, 180]]}
{"doc_key": "ai-test-176", "ner": [[3, 3, "misc"], [6, 8, "person"], [10, 11, "person"], [13, 14, "person"], [17, 18, "misc"], [19, 20, "person"], [23, 24, "person"], [28, 28, "person"], [30, 31, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[6, 8, 3, 3, "role", "actor_in", false, false], [10, 11, 3, 3, "role", "actor_in", false, false], [13, 14, 3, 3, "role", "actor_in", false, false], [19, 20, 17, 18, "role", "model_for", false, false], [28, 28, 30, 31, "social", "family", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Correspondents", "included", "former", "Baywatch", "cast", "members", "Donna", "D'", "Errico", ",", "Carmen", "Electra", "and", "Traci", "Bingham", ",", "former", "Playboy", "Playmate", "Heidi", "Mark", ",", "comedian", "Arj", "Barker", "and", "identical", "twins", "Randy", "and", "Jason", "Sklar", "."], "sentence-detokenized": "Correspondents included former Baywatch cast members Donna D'Errico, Carmen Electra and Traci Bingham, former Playboy Playmate Heidi Mark, comedian Arj Barker and identical twins Randy and Jason Sklar.", "token2charspan": [[0, 14], [15, 23], [24, 30], [31, 39], [40, 44], [45, 52], [53, 58], [59, 61], [61, 67], [67, 68], [69, 75], [76, 83], [84, 87], [88, 93], [94, 101], [101, 102], [103, 109], [110, 117], [118, 126], [127, 132], [133, 137], [137, 138], [139, 147], [148, 151], [152, 158], [159, 162], [163, 172], [173, 178], [179, 184], [185, 188], [189, 194], [195, 200], [200, 201]]}
{"doc_key": "ai-test-177", "ner": [[8, 9, "task"], [11, 11, "task"], [16, 19, "product"], [22, 23, "task"], [25, 25, "task"], [30, 32, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 8, 9, "named", "", false, false], [16, 19, 8, 9, "general-affiliation", "", false, false], [25, 25, 22, 23, "named", "", false, false], [30, 32, 22, 23, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "is", "often", "used", "to", "produce", "representations", "for", "speech", "recognition", "(", "ASR", ")", ",", "such", "as", "the", "CMU", "Sphinx", "system", ",", "and", "speech", "synthesis", "(", "TTS", ")", ",", "such", "as", "the", "Festival", "system", "."], "sentence-detokenized": "It is often used to produce representations for speech recognition (ASR), such as the CMU Sphinx system, and speech synthesis (TTS), such as the Festival system.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 16], [17, 19], [20, 27], [28, 43], [44, 47], [48, 54], [55, 66], [67, 68], [68, 71], [71, 72], [72, 73], [74, 78], [79, 81], [82, 85], [86, 89], [90, 96], [97, 103], [103, 104], [105, 108], [109, 115], [116, 125], [126, 127], [127, 130], [130, 131], [131, 132], [133, 137], [138, 140], [141, 144], [145, 153], [154, 160], [160, 161]]}
{"doc_key": "ai-test-178", "ner": [[0, 1, "metrics"], [5, 5, "metrics"], [7, 16, "metrics"], [13, 13, "metrics"], [27, 28, "metrics"], [30, 30, "metrics"], [40, 41, "metrics"], [43, 43, "metrics"], [45, 47, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[5, 5, 0, 1, "named", "", false, false], [7, 16, 5, 5, "named", "", false, false], [13, 13, 0, 1, "named", "", false, false], [30, 30, 27, 28, "named", "", false, false], [43, 43, 40, 41, "named", "", false, false], [45, 47, 40, 41, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "Precision", "or", "TRUE", "Positive", "Rate", "(", "TPR", ")", ",", "also", "known", "as", "recall", ",", "is", "the", "ratio", "of", "people", "who", "test", "positive", "and", "are", "positive", "(", "TRUE", "Positive", ",", "TP", ")", "to", "all", "people", "who", "are", "actually", "positive", "(", "Condition", "Positive", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "The Precision or TRUE Positive Rate (TPR), also known as recall, is the ratio of people who test positive and are positive (TRUE Positive, TP) to all people who are actually positive (Condition Positive, CP = TP + FN).", "token2charspan": [[0, 3], [4, 13], [14, 16], [17, 21], [22, 30], [31, 35], [36, 37], [37, 40], [40, 41], [41, 42], [43, 47], [48, 53], [54, 56], [57, 63], [63, 64], [65, 67], [68, 71], [72, 77], [78, 80], [81, 87], [88, 91], [92, 96], [97, 105], [106, 109], [110, 113], [114, 122], [123, 124], [124, 128], [129, 137], [137, 138], [139, 141], [141, 142], [143, 145], [146, 149], [150, 156], [157, 160], [161, 164], [165, 173], [174, 182], [183, 184], [184, 193], [194, 202], [202, 203], [204, 206], [207, 208], [209, 211], [212, 213], [214, 216], [216, 217], [217, 218]]}
{"doc_key": "ai-test-179", "ner": [[1, 2, "task"], [9, 9, "conference"], [11, 12, "conference"], [14, 14, "conference"], [16, 18, "conference"], [20, 21, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6], "relations": [[9, 9, 1, 2, "topic", "", false, false], [11, 12, 1, 2, "topic", "", false, false], [14, 14, 1, 2, "topic", "", false, false], [16, 18, 1, 2, "topic", "", false, false], [20, 21, 1, 2, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4, 5], "sentence": ["Popular", "speech", "recognition", "conferences", "held", "every", "two", "years", "include", "SpeechTEK", "and", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", "and", "IEEE", "ASRU", "."], "sentence-detokenized": "Popular speech recognition conferences held every two years include SpeechTEK and SpeechTEK Europe, ICASSP, Interspeech/Eurospeech and IEEE ASRU.", "token2charspan": [[0, 7], [8, 14], [15, 26], [27, 38], [39, 43], [44, 49], [50, 53], [54, 59], [60, 67], [68, 77], [78, 81], [82, 91], [92, 98], [98, 99], [100, 106], [106, 107], [108, 119], [119, 120], [120, 130], [131, 134], [135, 139], [140, 144], [144, 145]]}
{"doc_key": "ai-test-180", "ner": [[0, 0, "researcher"], [4, 4, "researcher"], [15, 20, "product"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 0, 0, "artifact", "", false, false], [23, 23, 4, 4, "artifact", "", false, false], [23, 23, 15, 20, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Devol", "has", "collaborated", "with", "Engelberger", ",", "who", "serves", "as", "the", "company", "'s", "president", ",", "to", "design", "and", "manufacture", "an", "industrial", "robot", "under", "the", "Unimate", "brand", "."], "sentence-detokenized": "Devol has collaborated with Engelberger, who serves as the company's president, to design and manufacture an industrial robot under the Unimate brand.", "token2charspan": [[0, 5], [6, 9], [10, 22], [23, 27], [28, 39], [39, 40], [41, 44], [45, 51], [52, 54], [55, 58], [59, 66], [66, 68], [69, 78], [78, 79], [80, 82], [83, 89], [90, 93], [94, 105], [106, 108], [109, 119], [120, 125], [126, 131], [132, 135], [136, 143], [144, 149], [149, 150]]}
{"doc_key": "ai-test-181", "ner": [[0, 3, "algorithm"], [5, 8, "algorithm"], [9, 9, "algorithm"], [23, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 9, 9, "general-affiliation", "", false, false], [5, 8, 0, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "hidden", "Markov", "model", "(", "HMM", ")", "is", "a", "statistical", "Markov", "model", "in", "which", "the", "modelled", "system", "is", "assumed", "to", "be", "a", "Markov", "process", "with", "unobservable", "(", "hidden", ")", "states", "."], "sentence-detokenized": "The hidden Markov model (HMM) is a statistical Markov model in which the modelled system is assumed to be a Markov process with unobservable (hidden) states.", "token2charspan": [[0, 3], [4, 10], [11, 17], [18, 23], [24, 25], [25, 28], [28, 29], [30, 32], [33, 34], [35, 46], [47, 53], [54, 59], [60, 62], [63, 68], [69, 72], [73, 81], [82, 88], [89, 91], [92, 99], [100, 102], [103, 105], [106, 107], [108, 114], [115, 122], [123, 127], [128, 140], [141, 142], [142, 148], [148, 149], [150, 156], [156, 157]]}
{"doc_key": "ai-test-182", "ner": [[21, 24, "metrics"], [25, 25, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "feature", ",", "which", "is", "undesirable", "in", "many", "applications", ",", "has", "led", "researchers", "to", "use", "alternatives", "such", "as", "those", "based", "on", "mean", "absolute", "error", "or", "median", "."], "sentence-detokenized": "This feature, which is undesirable in many applications, has led researchers to use alternatives such as those based on mean absolute error or median.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 19], [20, 22], [23, 34], [35, 37], [38, 42], [43, 55], [55, 56], [57, 60], [61, 64], [65, 76], [77, 79], [80, 83], [84, 96], [97, 101], [102, 104], [105, 110], [111, 116], [117, 119], [120, 124], [125, 133], [134, 139], [140, 142], [143, 149], [149, 150]]}
{"doc_key": "ai-test-183", "ner": [[22, 23, "algorithm"], [30, 32, "field"], [35, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 23, 30, 32, "part-of", "", false, false], [22, 23, 35, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Such", "a", "sequence", "(", "which", "at", "each", "stage", "depends", "on", "the", "result", "of", "the", "search", "for", "previous", "attributes", ")", "is", "called", "a", "decision", "tree", "and", "is", "applied", "in", "the", "field", "of", "machine", "learning", "known", "as", "decision", "tree", "learning", "."], "sentence-detokenized": "Such a sequence (which at each stage depends on the result of the search for previous attributes) is called a decision tree and is applied in the field of machine learning known as decision tree learning.", "token2charspan": [[0, 4], [5, 6], [7, 15], [16, 17], [17, 22], [23, 25], [26, 30], [31, 36], [37, 44], [45, 47], [48, 51], [52, 58], [59, 61], [62, 65], [66, 72], [73, 76], [77, 85], [86, 96], [96, 97], [98, 100], [101, 107], [108, 109], [110, 118], [119, 123], [124, 127], [128, 130], [131, 138], [139, 141], [142, 145], [146, 151], [152, 154], [155, 162], [163, 171], [172, 177], [178, 180], [181, 189], [190, 194], [195, 203], [203, 204]]}
{"doc_key": "ai-test-184", "ner": [[0, 3, "task"], [5, 8, "algorithm"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 5, 8, "compare", "", false, false], [15, 16, 5, 8, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "with", "factor", "analysis", ",", "LCA", "can", "be", "used", "to", "classify", "cases", "according", "to", "their", "maximum", "likelihood", "class", "membership", "."], "sentence-detokenized": "As with factor analysis, LCA can be used to classify cases according to their maximum likelihood class membership.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 23], [23, 24], [25, 28], [29, 32], [33, 35], [36, 40], [41, 43], [44, 52], [53, 58], [59, 68], [69, 71], [72, 77], [78, 85], [86, 96], [97, 102], [103, 113], [113, 114]]}
{"doc_key": "ai-test-185", "ner": [[0, 2, "algorithm"], [5, 7, "metrics"], [9, 9, "metrics"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 5, 7, "usage", "", false, false], [5, 7, 11, 12, "related-to", "", false, false], [9, 9, 5, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Supervised", "neural", "networks", "using", "a", "mean", "squared", "error", "(", "MSE", ")", "cost", "function", "can", "use", "formal", "statistical", "methods", "to", "determine", "the", "confidence", "of", "the", "trained", "model", "."], "sentence-detokenized": "Supervised neural networks using a mean squared error (MSE) cost function can use formal statistical methods to determine the confidence of the trained model.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 32], [33, 34], [35, 39], [40, 47], [48, 53], [54, 55], [55, 58], [58, 59], [60, 64], [65, 73], [74, 77], [78, 81], [82, 88], [89, 100], [101, 108], [109, 111], [112, 121], [122, 125], [126, 136], [137, 139], [140, 143], [144, 151], [152, 157], [157, 158]]}
{"doc_key": "ai-test-186", "ner": [[14, 17, "algorithm"], [20, 22, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 17, 20, 22, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "can", "be", "expressed", "directly", "as", "a", "linear", "programme", ",", "but", "is", "also", "equivalent", "to", "the", "Tikhonov", "arrangement", "with", "the", "hinge", "loss", "function", ",", "mathV", "(", "f", "(", "x", ")", ",", "y", ")", "=\\", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "Maths", ":"], "sentence-detokenized": "This can be expressed directly as a linear programme, but is also equivalent to the Tikhonov arrangement with the hinge loss function, mathV (f (x), y) =\\ max (0, 1 - yf (x)) / Maths:", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 21], [22, 30], [31, 33], [34, 35], [36, 42], [43, 52], [52, 53], [54, 57], [58, 60], [61, 65], [66, 76], [77, 79], [80, 83], [84, 92], [93, 104], [105, 109], [110, 113], [114, 119], [120, 124], [125, 133], [133, 134], [135, 140], [141, 142], [142, 143], [144, 145], [145, 146], [146, 147], [147, 148], [149, 150], [150, 151], [152, 154], [155, 158], [159, 160], [160, 161], [161, 162], [163, 164], [165, 166], [167, 169], [170, 171], [171, 172], [172, 173], [173, 174], [175, 176], [177, 182], [182, 183]]}
{"doc_key": "ai-test-187", "ner": [[6, 6, "researcher"], [12, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "technique", "is", "described", "in", "Breiman", "'s", "original", "paper", "and", "implemented", "in", "the", "R", "package", "randomForest", "."], "sentence-detokenized": "The following technique is described in Breiman's original paper and implemented in the R package randomForest.", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 26], [27, 36], [37, 39], [40, 47], [47, 49], [50, 58], [59, 64], [65, 68], [69, 80], [81, 83], [84, 87], [88, 89], [90, 97], [98, 110], [110, 111]]}
{"doc_key": "ai-test-188", "ner": [[6, 7, "metrics"], [37, 38, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "image", "quality", "measurements", "such", "as", "PSNR", "are", "usually", "performed", "on", "fixed", "-", "resolution", "images", "and", "do", "not", "take", "into", "account", "some", "aspects", "of", "the", "human", "visual", "system", ",", "such", "as", "the", "variation", "in", "spatial", "resolution", "across", "the", "retina", "."], "sentence-detokenized": "Traditional image quality measurements such as PSNR are usually performed on fixed-resolution images and do not take into account some aspects of the human visual system, such as the variation in spatial resolution across the retina.", "token2charspan": [[0, 11], [12, 17], [18, 25], [26, 38], [39, 43], [44, 46], [47, 51], [52, 55], [56, 63], [64, 73], [74, 76], [77, 82], [82, 83], [83, 93], [94, 100], [101, 104], [105, 107], [108, 111], [112, 116], [117, 121], [122, 129], [130, 134], [135, 142], [143, 145], [146, 149], [150, 155], [156, 162], [163, 169], [169, 170], [171, 175], [176, 178], [179, 182], [183, 192], [193, 195], [196, 203], [204, 214], [215, 221], [222, 225], [226, 232], [232, 233]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 9, "person"], [10, 12, "person"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 17, "role", "", false, false], [3, 4, 16, 17, "role", "", false, false], [6, 9, 16, 17, "role", "", false, false], [16, 17, 10, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Dru", "and", "Macdonald", "Carey", "starred", "in", "Jack", "Broder", "'s", "colour", "production", "of", "Hannah", "Lee", ",", "released", "on", "19", "June", "1953", "."], "sentence-detokenized": "John Ireland, Joanne Dru and Macdonald Carey starred in Jack Broder's colour production of Hannah Lee, released on 19 June 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 55], [56, 60], [61, 67], [67, 69], [70, 76], [77, 87], [88, 90], [91, 97], [98, 101], [101, 102], [103, 111], [112, 114], [115, 117], [118, 122], [123, 127], [127, 128]]}
{"doc_key": "ai-test-190", "ner": [[4, 5, "task"], [9, 10, "field"], [16, 16, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 9, 10, "usage", "", false, false], [16, 16, 9, 10, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "process", "is", "called", "image", "registration", "and", "uses", "different", "computer", "vision", "methods", ",", "mostly", "related", "to", "tracking", "."], "sentence-detokenized": "This process is called image registration and uses different computer vision methods, mostly related to tracking.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 22], [23, 28], [29, 41], [42, 45], [46, 50], [51, 60], [61, 69], [70, 76], [77, 84], [84, 85], [86, 92], [93, 100], [101, 103], [104, 112], [112, 113]]}
{"doc_key": "ai-test-191", "ner": [[18, 19, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Let", "us", "now", "begin", "to", "explain", "the", "different", "possible", "relationships", "between", "the", "predicted", "and", "the", "actual", "outcome", ":", "Confusion", "matrix"], "sentence-detokenized": "Let us now begin to explain the different possible relationships between the predicted and the actual outcome: Confusion matrix", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [17, 19], [20, 27], [28, 31], [32, 41], [42, 50], [51, 64], [65, 72], [73, 76], [77, 86], [87, 90], [91, 94], [95, 101], [102, 109], [109, 110], [111, 120], [121, 127]]}
{"doc_key": "ai-test-192", "ner": [[0, 1, "product"], [2, 4, "misc"], [6, 6, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 2, 4, "part-of", "", false, false], [0, 1, 2, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "VOICEBOX", "speech", "processing", "toolbox", "for", "MATLAB", "implements", "the", "transformation", "and", "its", "inverse", "as", "follows", ":"], "sentence-detokenized": "The VOICEBOX speech processing toolbox for MATLAB implements the transformation and its inverse as follows:", "token2charspan": [[0, 3], [4, 12], [13, 19], [20, 30], [31, 38], [39, 42], [43, 49], [50, 60], [61, 64], [65, 79], [80, 83], [84, 87], [88, 95], [96, 98], [99, 106], [106, 107]]}
{"doc_key": "ai-test-193", "ner": [[0, 0, "programlang"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 8, 9, "general-affiliation", "", false, false], [0, 0, 11, 12, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "is", "a", "logic", "programming", "language", "associated", "with", "artificial", "intelligence", "and", "computational", "linguistics", "."], "sentence-detokenized": "Prolog is a logic programming language associated with artificial intelligence and computational linguistics.", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 17], [18, 29], [30, 38], [39, 49], [50, 54], [55, 65], [66, 78], [79, 82], [83, 96], [97, 108], [108, 109]]}
{"doc_key": "ai-test-194", "ner": [[0, 0, "researcher"], [9, 9, "field"], [11, 13, "field"], [17, 20, "organisation"], [23, 26, "organisation"], [30, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 9, 9, "related-to", "works_with_topic", false, false], [0, 0, 11, 13, "related-to", "works_with_topic", false, false], [0, 0, 17, 20, "role", "", false, false], [0, 0, 23, 26, "role", "", false, false], [0, 0, 30, 33, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "has", "received", "numerous", "honours", "for", "his", "contributions", "to", "neuroscience", "and", "psychology", ",", "including", "memberships", "in", "the", "Royal", "Society", "of", "London", ",", "the", "Royal", "Society", "of", "Canada", ",", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner has received numerous honours for his contributions to neuroscience and psychology, including memberships in the Royal Society of London, the Royal Society of Canada, and the National Academy of Sciences.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 28], [29, 36], [37, 40], [41, 44], [45, 58], [59, 61], [62, 74], [75, 78], [79, 89], [89, 90], [91, 100], [101, 112], [113, 115], [116, 119], [120, 125], [126, 133], [134, 136], [137, 143], [143, 144], [145, 148], [149, 154], [155, 162], [163, 165], [166, 172], [172, 173], [174, 177], [178, 181], [182, 190], [191, 198], [199, 201], [202, 210], [210, 211]]}
{"doc_key": "ai-test-195", "ner": [[12, 12, "field"], [16, 19, "task"], [20, 20, "task"], [23, 25, "task"], [26, 26, "task"], [28, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[16, 19, 12, 12, "part-of", "task_part_of_field", false, false], [20, 20, 12, 12, "part-of", "task_part_of_field", false, false], [23, 25, 12, 12, "part-of", "task_part_of_field", false, false], [26, 26, 12, 12, "part-of", "task_part_of_field", false, false], [28, 28, 12, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["By", "combining", "these", "operators", ",", "algorithms", "can", "be", "obtained", "for", "many", "image", "processing", "tasks", "such", "as", "feature", "extraction", ",", "image", "segmentation", ",", "image", "sharpening", ",", "image", "filtering", "and", "classification", "."], "sentence-detokenized": "By combining these operators, algorithms can be obtained for many image processing tasks such as feature extraction, image segmentation, image sharpening, image filtering and classification.", "token2charspan": [[0, 2], [3, 12], [13, 18], [19, 28], [28, 29], [30, 40], [41, 44], [45, 47], [48, 56], [57, 60], [61, 65], [66, 71], [72, 82], [83, 88], [89, 93], [94, 96], [97, 104], [105, 115], [115, 116], [117, 122], [123, 135], [135, 136], [137, 142], [143, 153], [153, 154], [155, 160], [161, 170], [171, 174], [175, 189], [189, 190]]}
{"doc_key": "ai-test-196", "ner": [[8, 12, "university"], [19, 21, "organisation"], [23, 24, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 24, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "of", "2017", ",", "he", "is", "a", "professor", "at", "the", "Coll\u00e8ge", "de", "France", "and", "has", "been", "the", "director", "of", "INSERM", "Unit", "562", ",", "Cognitive", "Neuroimaging", ",", "since", "1989", "."], "sentence-detokenized": "As of 2017, he is a professor at the Coll\u00e8ge de France and has been the director of INSERM Unit 562, Cognitive Neuroimaging, since 1989.", "token2charspan": [[0, 2], [3, 5], [6, 10], [10, 11], [12, 14], [15, 17], [18, 19], [20, 29], [30, 32], [33, 36], [37, 44], [45, 47], [48, 54], [55, 58], [59, 62], [63, 67], [68, 71], [72, 80], [81, 83], [84, 90], [91, 95], [96, 99], [99, 100], [101, 110], [111, 123], [123, 124], [125, 130], [131, 135], [135, 136]]}
{"doc_key": "ai-test-197", "ner": [[12, 14, "algorithm"], [16, 19, "algorithm"], [23, 23, "algorithm"], [25, 31, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 25, 31, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["There", "are", "many", "approaches", "to", "learn", "these", "embeddings", ",", "in", "particular", "using", "Bayesian", "clustering", "frameworks", "or", "energy", "-", "based", "frameworks", ",", "and", "recently", "TransE", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", "2013", ")", "."], "sentence-detokenized": "There are many approaches to learn these embeddings, in particular using Bayesian clustering frameworks or energy-based frameworks, and recently TransE (Conference on Neural Information Processing Systems 2013).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 25], [26, 28], [29, 34], [35, 40], [41, 51], [51, 52], [53, 55], [56, 66], [67, 72], [73, 81], [82, 92], [93, 103], [104, 106], [107, 113], [113, 114], [114, 119], [120, 130], [130, 131], [132, 135], [136, 144], [145, 151], [152, 153], [153, 163], [164, 166], [167, 173], [174, 185], [186, 196], [197, 204], [205, 209], [209, 210], [210, 211]]}
{"doc_key": "ai-test-198", "ner": [[4, 8, "metrics"], [7, 7, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 7, 4, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "is", "an", "alternative", "to", "the", "Word", "Error", "Rate", "used", "in", "many", "countries", "."], "sentence-detokenized": "It is an alternative to the Word Error Rate used in many countries.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 20], [21, 23], [24, 27], [28, 32], [33, 38], [39, 43], [44, 48], [49, 51], [52, 56], [57, 66], [66, 67]]}
{"doc_key": "ai-test-199", "ner": [[0, 0, "algorithm"], [22, 23, "task"], [25, 26, "task"], [28, 29, "task"], [31, 36, "task"], [35, 39, "task"], [41, 44, "task"], [46, 46, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[22, 23, 0, 0, "usage", "", false, false], [25, 26, 0, 0, "usage", "", false, false], [28, 29, 0, 0, "usage", "", false, false], [31, 36, 0, 0, "usage", "", false, false], [35, 39, 0, 0, "usage", "", false, false], [41, 44, 0, 0, "usage", "", false, false], [46, 46, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["ANNs", "have", "been", "used", "in", "a", "variety", "of", "tasks", ",", "including", "activities", "traditionally", "thought", "to", "be", "reserved", "for", "humans", ",", "such", "as", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "playing", "board", "and", "video", "games", ",", "medical", "diagnosis", ",", "and", "even", "painting", "."], "sentence-detokenized": "ANNs have been used in a variety of tasks, including activities traditionally thought to be reserved for humans, such as computer vision, speech recognition, machine translation, social network filtering, playing board and video games, medical diagnosis, and even painting.", "token2charspan": [[0, 4], [5, 9], [10, 14], [15, 19], [20, 22], [23, 24], [25, 32], [33, 35], [36, 41], [41, 42], [43, 52], [53, 63], [64, 77], [78, 85], [86, 88], [89, 91], [92, 100], [101, 104], [105, 111], [111, 112], [113, 117], [118, 120], [121, 129], [130, 136], [136, 137], [138, 144], [145, 156], [156, 157], [158, 165], [166, 177], [177, 178], [179, 185], [186, 193], [194, 203], [203, 204], [205, 212], [213, 218], [219, 222], [223, 228], [229, 234], [234, 235], [236, 243], [244, 253], [253, 254], [255, 258], [259, 263], [264, 272], [272, 273]]}
{"doc_key": "ai-test-200", "ner": [[0, 4, "product"], [6, 6, "product"], [25, 27, "field"], [29, 31, "field"], [33, 34, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 25, 27, "related-to", "", false, false], [0, 4, 33, 34, "general-affiliation", "", false, false], [6, 6, 0, 4, "named", "", false, false], [29, 31, 25, 27, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Modular", "Voice", "Recognition", "Framework", "(", "MARF", ")", "is", "an", "open", "source", "research", "platform", "and", "collection", "of", "voice", ",", "audio", ",", "speech", ",", "text", "and", "natural", "language", "processing", "(", "NLP", ")", "algorithms", "written", "in", "Java", "and", "organised", "into", "a", "modular", "and", "extensible", "framework", "that", "attempts", "to", "facilitate", "the", "addition", "of", "new", "algorithms", "."], "sentence-detokenized": "The Modular Voice Recognition Framework (MARF) is an open source research platform and collection of voice, audio, speech, text and natural language processing (NLP) algorithms written in Java and organised into a modular and extensible framework that attempts to facilitate the addition of new algorithms.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 29], [30, 39], [40, 41], [41, 45], [45, 46], [47, 49], [50, 52], [53, 57], [58, 64], [65, 73], [74, 82], [83, 86], [87, 97], [98, 100], [101, 106], [106, 107], [108, 113], [113, 114], [115, 121], [121, 122], [123, 127], [128, 131], [132, 139], [140, 148], [149, 159], [160, 161], [161, 164], [164, 165], [166, 176], [177, 184], [185, 187], [188, 192], [193, 196], [197, 206], [207, 211], [212, 213], [214, 221], [222, 225], [226, 236], [237, 246], [247, 251], [252, 260], [261, 263], [264, 274], [275, 278], [279, 287], [288, 290], [291, 294], [295, 305], [305, 306]]}
{"doc_key": "ai-test-201", "ner": [[12, 16, "organisation"], [20, 22, "country"], [24, 26, "organisation"], [29, 30, "organisation"], [35, 36, "task"], [53, 56, "organisation"], [59, 60, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[24, 26, 20, 22, "physical", "", false, false], [24, 26, 35, 36, "usage", "", false, false], [24, 26, 53, 56, "named", "", false, false], [29, 30, 20, 22, "physical", "", false, false], [29, 30, 35, 36, "usage", "", false, false], [53, 56, 59, 60, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "a", "report", "by", "civil", "liberties", "and", "rights", "campaigning", "organisation", "Big", "Brother", "Watch", "found", "that", "two", "police", "forces", "in", "the", "UK", ",", "South", "Wales", "Police", "and", "the", "Metropolitan", "Police", ",", "were", "using", "live", "facial", "recognition", "at", "public", "events", "and", "in", "public", "spaces", ".", "In", "September", "2019", ",", "it", "was", "ruled", "that", "South", "Wales", "Police", "'s", "use", "of", "facial", "recognition", "was", "legal", "."], "sentence-detokenized": "In 2018, a report by civil liberties and rights campaigning organisation Big Brother Watch found that two police forces in the UK, South Wales Police and the Metropolitan Police, were using live facial recognition at public events and in public spaces. In September 2019, it was ruled that South Wales Police's use of facial recognition was legal.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 20], [21, 26], [27, 36], [37, 40], [41, 47], [48, 59], [60, 72], [73, 76], [77, 84], [85, 90], [91, 96], [97, 101], [102, 105], [106, 112], [113, 119], [120, 122], [123, 126], [127, 129], [129, 130], [131, 136], [137, 142], [143, 149], [150, 153], [154, 157], [158, 170], [171, 177], [177, 178], [179, 183], [184, 189], [190, 194], [195, 201], [202, 213], [214, 216], [217, 223], [224, 230], [231, 234], [235, 237], [238, 244], [245, 251], [251, 252], [253, 255], [256, 265], [266, 270], [270, 271], [272, 274], [275, 278], [279, 284], [285, 289], [290, 295], [296, 301], [302, 308], [308, 310], [311, 314], [315, 317], [318, 324], [325, 336], [337, 340], [341, 346], [346, 347]]}
{"doc_key": "ai-test-202", "ner": [[0, 0, "product"], [4, 5, "programlang"], [14, 15, "field"], [17, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 5, "general-affiliation", "", false, false], [0, 0, 14, 15, "related-to", "", false, false], [0, 0, 17, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "has", "been", "ported", "to", "R", ",", "a", "freely", "available", "language", "and", "environment", "for", "statistical", "computing", "and", "graphics", "."], "sentence-detokenized": "ANIMAL has been ported to R, a freely available language and environment for statistical computing and graphics.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 22], [23, 25], [26, 27], [27, 28], [29, 30], [31, 37], [38, 47], [48, 56], [57, 60], [61, 72], [73, 76], [77, 88], [89, 98], [99, 102], [103, 111], [111, 112]]}
{"doc_key": "ai-test-203", "ner": [[0, 6, "algorithm"], [8, 12, "algorithm"], [15, 19, "algorithm"], [21, 21, "algorithm"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 6, 15, 19, "opposite", "alternative to", false, false], [8, 12, 0, 6, "named", "", false, false], [21, 21, 15, 19, "named", "", false, false], [24, 26, 0, 6, "usage", "", false, false], [24, 26, 15, 19, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "time", "-", "inhomogeneous", "hidden", "Bernoulli", "model", "(", "TI", "-", "HBM", ")", "is", "an", "alternative", "to", "the", "hidden", "Markov", "model", "(", "HMM", ")", "for", "automatic", "speech", "recognition", "."], "sentence-detokenized": "The time-inhomogeneous hidden Bernoulli model (TI-HBM) is an alternative to the hidden Markov model (HMM) for automatic speech recognition.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 22], [23, 29], [30, 39], [40, 45], [46, 47], [47, 49], [49, 50], [50, 53], [53, 54], [55, 57], [58, 60], [61, 72], [73, 75], [76, 79], [80, 86], [87, 93], [94, 99], [100, 101], [101, 104], [104, 105], [106, 109], [110, 119], [120, 126], [127, 138], [138, 139]]}
{"doc_key": "ai-test-204", "ner": [[4, 4, "organisation"], [12, 14, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 12, 14, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "July", "2016", ",", "Nvidia", "demonstrated", "a", "new", "foveated", "rendering", "method", "during", "SIGGRAPH", "that", "was", "allegedly", "invisible", "to", "users", "."], "sentence-detokenized": "In July 2016, Nvidia demonstrated a new foveated rendering method during SIGGRAPH that was allegedly invisible to users.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 20], [21, 33], [34, 35], [36, 39], [40, 48], [49, 58], [59, 65], [66, 72], [73, 81], [82, 86], [87, 90], [91, 100], [101, 110], [111, 113], [114, 119], [119, 120]]}
{"doc_key": "ai-test-205", "ner": [[4, 7, "misc"], [10, 11, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 7, 10, 11, "origin", "", false, false], [4, 7, 16, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Both", "are", "based", "on", "the", "speech", "act", "theory", "developed", "by", "John", "Searle", "in", "the", "1960s", "and", "Terry", "Winograd", "and", "Flores", "in", "the", "1970s", "."], "sentence-detokenized": "Both are based on the speech act theory developed by John Searle in the 1960s and Terry Winograd and Flores in the 1970s.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 17], [18, 21], [22, 28], [29, 32], [33, 39], [40, 49], [50, 52], [53, 57], [58, 64], [65, 67], [68, 71], [72, 77], [78, 81], [82, 87], [88, 96], [97, 100], [101, 107], [108, 110], [111, 114], [115, 120], [120, 121]]}
{"doc_key": "ai-test-206", "ner": [[0, 2, "algorithm"], [20, 20, "researcher"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 20, 20, "related-to", "", false, false], [23, 23, 20, 20, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Neural", "network", "models", "of", "concept", "formation", "and", "knowledge", "structure", "have", "led", "to", "powerful", "hierarchical", "models", "of", "knowledge", "organisation", "such", "as", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "Neural network models of concept formation and knowledge structure have led to powerful hierarchical models of knowledge organisation such as George Miller's Wordnet.", "token2charspan": [[0, 6], [7, 14], [15, 21], [22, 24], [25, 32], [33, 42], [43, 46], [47, 56], [57, 66], [67, 71], [72, 75], [76, 78], [79, 87], [88, 100], [101, 107], [108, 110], [111, 120], [121, 133], [134, 138], [139, 141], [142, 148], [149, 155], [155, 157], [158, 165], [165, 166]]}
{"doc_key": "ai-test-207", "ner": [[0, 1, "algorithm"], [13, 13, "field"], [16, 18, "product"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 13, 13, "part-of", "", false, false], [0, 1, 21, 23, "part-of", "", false, false], [16, 18, 13, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Template", "matching", "has", "various", "applications", "and", "is", "used", "in", "areas", "such", "as", "face", "recognition", "(", "see", "face", "recognition", "system", ")", "and", "medical", "image", "processing", "."], "sentence-detokenized": "Template matching has various applications and is used in areas such as face recognition (see face recognition system) and medical image processing.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 29], [30, 42], [43, 46], [47, 49], [50, 54], [55, 57], [58, 63], [64, 68], [69, 71], [72, 76], [77, 88], [89, 90], [90, 93], [94, 98], [99, 110], [111, 117], [117, 118], [119, 122], [123, 130], [131, 136], [137, 147], [147, 148]]}
{"doc_key": "ai-test-208", "ner": [[9, 11, "researcher"], [12, 13, "researcher"], [18, 26, "organisation"], [16, 28, "organisation"], [35, 36, "algorithm"], [39, 45, "conference"], [47, 47, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 11, 18, 26, "role", "", false, false], [9, 11, 39, 45, "physical", "", false, false], [9, 11, 39, 45, "temporal", "", false, false], [9, 11, 47, 47, "physical", "", false, false], [12, 13, 18, 26, "role", "", false, false], [12, 13, 39, 45, "temporal", "", false, false], [16, 28, 18, 26, "named", "", false, false], [39, 45, 35, 36, "topic", "", false, false], [47, 47, 39, 45, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["However", ",", "use", "only", "became", "widespread", "in", "2005", "when", "Navneet", "Dalal", "and", "Bill", "Triggs", ",", "researchers", "at", "the", "French", "National", "Research", "Institute", "for", "Computer", "Science", "and", "Automation", "(", "INRIA", ")", ",", "presented", "additional", "work", "on", "HOG", "descriptors", "at", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "However, use only became widespread in 2005 when Navneet Dalal and Bill Triggs, researchers at the French National Research Institute for Computer Science and Automation (INRIA), presented additional work on HOG descriptors at the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 17], [18, 24], [25, 35], [36, 38], [39, 43], [44, 48], [49, 56], [57, 62], [63, 66], [67, 71], [72, 78], [78, 79], [80, 91], [92, 94], [95, 98], [99, 105], [106, 114], [115, 123], [124, 133], [134, 137], [138, 146], [147, 154], [155, 158], [159, 169], [170, 171], [171, 176], [176, 177], [177, 178], [179, 188], [189, 199], [200, 204], [205, 207], [208, 211], [212, 223], [224, 226], [227, 230], [231, 241], [242, 244], [245, 253], [254, 260], [261, 264], [265, 272], [273, 284], [285, 286], [286, 290], [290, 291], [291, 292]]}
{"doc_key": "ai-test-209", "ner": [[3, 3, "university"], [16, 19, "organisation"], [15, 21, "organisation"], [25, 28, "field"], [33, 35, "researcher"], [37, 39, "researcher"], [42, 44, "researcher"], [47, 50, "organisation"], [54, 56, "organisation"], [61, 63, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[15, 21, 25, 28, "related-to", "", false, false], [33, 35, 15, 21, "physical", "", false, false], [33, 35, 15, 21, "role", "", false, false], [37, 39, 15, 21, "physical", "", false, false], [37, 39, 15, 21, "role", "", false, false], [42, 44, 15, 21, "physical", "", false, false], [42, 44, 15, 21, "role", "", false, false], [61, 63, 54, 56, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Before", "joining", "the", "Penn", "faculty", "in", "2002", ",", "he", "spent", "ten", "years", "(", "1991-2001", ")", "at", "AT", "&T", "Labs", "and", "Bell", "Labs", ",", "including", "heading", "the", "Artificial", "Intelligence", "department", "with", "colleagues", "such", "as", "Michael", "L.", "Littman", ",", "David", "A.", "McAllester", ",", "and", "Richard", "S.", "Sutton", ";", "the", "Secure", "Systems", "Research", "department", ";", "and", "the", "Machine", "Learning", "department", "with", "members", "such", "as", "Michael", "Collins", "and", "leader", ")", "."], "sentence-detokenized": "Before joining the Penn faculty in 2002, he spent ten years (1991-2001) at AT&T Labs and Bell Labs, including heading the Artificial Intelligence department with colleagues such as Michael L. Littman, David A. McAllester, and Richard S. Sutton; the Secure Systems Research department; and the Machine Learning department with members such as Michael Collins and leader).", "token2charspan": [[0, 6], [7, 14], [15, 18], [19, 23], [24, 31], [32, 34], [35, 39], [39, 40], [41, 43], [44, 49], [50, 53], [54, 59], [60, 61], [61, 70], [70, 71], [72, 74], [75, 77], [77, 79], [80, 84], [85, 88], [89, 93], [94, 98], [98, 99], [100, 109], [110, 117], [118, 121], [122, 132], [133, 145], [146, 156], [157, 161], [162, 172], [173, 177], [178, 180], [181, 188], [189, 191], [192, 199], [199, 200], [201, 206], [207, 209], [210, 220], [220, 221], [222, 225], [226, 233], [234, 236], [237, 243], [243, 244], [245, 248], [249, 255], [256, 263], [264, 272], [273, 283], [283, 284], [285, 288], [289, 292], [293, 300], [301, 309], [310, 320], [321, 325], [326, 333], [334, 338], [339, 341], [342, 349], [350, 357], [358, 361], [362, 368], [368, 369], [369, 370]]}
{"doc_key": "ai-test-210", "ner": [[5, 6, "field"], [13, 13, "field"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 6, 13, 13, "compare", "", false, false], [23, 24, 13, 13, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["When", "data", "is", "unlabelled", ",", "supervised", "learning", "is", "not", "possible", "and", "an", "unsupervised", "learning", "approach", "is", "required", ",", "which", "tries", "to", "find", "natural", "Cluster", "analysis", "into", "groups", "and", "then", "matches", "new", "data", "to", "these", "created", "groups", "."], "sentence-detokenized": "When data is unlabelled, supervised learning is not possible and an unsupervised learning approach is required, which tries to find natural Cluster analysis into groups and then matches new data to these created groups.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 23], [23, 24], [25, 35], [36, 44], [45, 47], [48, 51], [52, 60], [61, 64], [65, 67], [68, 80], [81, 89], [90, 98], [99, 101], [102, 110], [110, 111], [112, 117], [118, 123], [124, 126], [127, 131], [132, 139], [140, 147], [148, 156], [157, 161], [162, 168], [169, 172], [173, 177], [178, 185], [186, 189], [190, 194], [195, 197], [198, 203], [204, 211], [212, 218], [218, 219]]}
{"doc_key": "ai-test-211", "ner": [[2, 4, "field"], [14, 18, "organisation"], [25, 26, "field"], [28, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 4, 14, 18, "origin", "", false, false], [2, 4, 25, 26, "part-of", "", false, false], [2, 4, 28, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "area", "of", "computer", "science", "developed", "in", "the", "1950s", "at", "academic", "institutions", "such", "as", "the", "MIT", "A.I", ".", "Lab", ",", "initially", "as", "a", "branch", "of", "artificial", "intelligence", "and", "robotics", "."], "sentence-detokenized": "This area of computer science developed in the 1950s at academic institutions such as the MIT A.I. Lab, initially as a branch of artificial intelligence and robotics.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 21], [22, 29], [30, 39], [40, 42], [43, 46], [47, 52], [53, 55], [56, 64], [65, 77], [78, 82], [83, 85], [86, 89], [90, 93], [94, 97], [97, 98], [99, 102], [102, 103], [104, 113], [114, 116], [117, 118], [119, 125], [126, 128], [129, 139], [140, 152], [153, 156], [157, 165], [165, 166]]}
{"doc_key": "ai-test-212", "ner": [[8, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "can", "also", "be", "replaced", "by", "the", "following", "Log", "loss", "equation", ":"], "sentence-detokenized": "It can also be replaced by the following Log loss equation:", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 23], [24, 26], [27, 30], [31, 40], [41, 44], [45, 49], [50, 58], [58, 59]]}
{"doc_key": "ai-test-213", "ner": [[0, 3, "organisation"], [7, 10, "organisation"], [13, 18, "university"], [20, 20, "university"], [22, 23, "university"], [25, 28, "university"], [30, 31, "country"], [35, 35, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 3, 35, 35, "related-to", "research_leader_in_field", false, false], [7, 10, 0, 3, "named", "", false, false], [7, 10, 35, 35, "related-to", "research_leader_in_field", false, false], [13, 18, 35, 35, "related-to", "research_leader_in_field", false, false], [20, 20, 35, 35, "related-to", "research_leader_in_field", false, false], [22, 23, 35, 35, "related-to", "research_leader_in_field", false, false], [25, 28, 30, 31, "physical", "", false, false], [25, 28, 35, 35, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "Shirley", "Ryan", "AbilityLab", "(", "formerly", "the", "Rehabilitation", "Institute", "of", "Chicago", ")", ",", "the", "University", "of", "California", "at", "Berkeley", ",", "MIT", ",", "Stanford", "University", "and", "the", "University", "of", "Twente", "in", "the", "Netherlands", "are", "leaders", "in", "biomechatronics", "research", "."], "sentence-detokenized": "The Shirley Ryan AbilityLab (formerly the Rehabilitation Institute of Chicago), the University of California at Berkeley, MIT, Stanford University and the University of Twente in the Netherlands are leaders in biomechatronics research.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 27], [28, 29], [29, 37], [38, 41], [42, 56], [57, 66], [67, 69], [70, 77], [77, 78], [78, 79], [80, 83], [84, 94], [95, 97], [98, 108], [109, 111], [112, 120], [120, 121], [122, 125], [125, 126], [127, 135], [136, 146], [147, 150], [151, 154], [155, 165], [166, 168], [169, 175], [176, 178], [179, 182], [183, 194], [195, 198], [199, 206], [207, 209], [210, 225], [226, 234], [234, 235]]}
{"doc_key": "ai-test-214", "ner": [[27, 31, "metrics"], [43, 43, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Given", "a", "set", "of", "predicted", "values", "for", "X", "at", "various", "time", "periods", "and", "a", "corresponding", "set", "of", "actual", "values", ",", "a", "common", "evaluation", "technique", "is", "to", "use", "the", "mean", "squared", "prediction", "error", ";", "other", "measures", "are", "also", "available", "(", "see", "prediction", "#", "prediction", "accuracy", ")", "."], "sentence-detokenized": "Given a set of predicted values for X at various time periods and a corresponding set of actual values, a common evaluation technique is to use the mean squared prediction error; other measures are also available (see prediction # prediction accuracy).", "token2charspan": [[0, 5], [6, 7], [8, 11], [12, 14], [15, 24], [25, 31], [32, 35], [36, 37], [38, 40], [41, 48], [49, 53], [54, 61], [62, 65], [66, 67], [68, 81], [82, 85], [86, 88], [89, 95], [96, 102], [102, 103], [104, 105], [106, 112], [113, 123], [124, 133], [134, 136], [137, 139], [140, 143], [144, 147], [148, 152], [153, 160], [161, 171], [172, 177], [177, 178], [179, 184], [185, 193], [194, 197], [198, 202], [203, 212], [213, 214], [214, 217], [218, 228], [229, 230], [231, 241], [242, 250], [250, 251], [251, 252]]}
{"doc_key": "ai-test-215", "ner": [[13, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "measures", ",", "such", "as", "the", "proportion", "of", "correct", "predictions", "(", "also", "called", "accuracy", ")", ",", "are", "not", "useful", "when", "the", "two", "classes", "are", "of", "very", "different", "sizes", "."], "sentence-detokenized": "Other measures, such as the proportion of correct predictions (also called accuracy), are not useful when the two classes are of very different sizes.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 20], [21, 23], [24, 27], [28, 38], [39, 41], [42, 49], [50, 61], [62, 63], [63, 67], [68, 74], [75, 83], [83, 84], [84, 85], [86, 89], [90, 93], [94, 100], [101, 105], [106, 109], [110, 113], [114, 121], [122, 125], [126, 128], [129, 133], [134, 143], [144, 149], [149, 150]]}
{"doc_key": "ai-test-216", "ner": [[4, 5, "product"], [11, 15, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 11, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "alpha", "version", "of", "OpenCV", "was", "released", "publicly", "at", "the", "Computer", "Vision", "and", "Pattern", "Recognition", "Conference", "in", "2000", ",", "and", "five", "betas", "were", "released", "between", "2001", "and", "2005", "."], "sentence-detokenized": "The first alpha version of OpenCV was released publicly at the Computer Vision and Pattern Recognition Conference in 2000, and five betas were released between 2001 and 2005.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [24, 26], [27, 33], [34, 37], [38, 46], [47, 55], [56, 58], [59, 62], [63, 71], [72, 78], [79, 82], [83, 90], [91, 102], [103, 113], [114, 116], [117, 121], [121, 122], [123, 126], [127, 131], [132, 137], [138, 142], [143, 151], [152, 159], [160, 164], [165, 168], [169, 173], [173, 174]]}
{"doc_key": "ai-test-217", "ner": [[23, 25, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["On", "the", "same", "dataset", ",", "results", "are", "presented", "that", "correlate", "up", "to", "0.964", "with", "human", "judgement", "at", "the", "corpus", "level", ",", "compared", "to", "0.817", "for", "BLEU", "."], "sentence-detokenized": "On the same dataset, results are presented that correlate up to 0.964 with human judgement at the corpus level, compared to 0.817 for BLEU.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [19, 20], [21, 28], [29, 32], [33, 42], [43, 47], [48, 57], [58, 60], [61, 63], [64, 69], [70, 74], [75, 80], [81, 90], [91, 93], [94, 97], [98, 104], [105, 110], [110, 111], [112, 120], [121, 123], [124, 129], [130, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-test-218", "ner": [[4, 4, "metrics"], [17, 17, "metrics"], [19, 21, "metrics"], [23, 25, "metrics"], [30, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 17, 17, "compare", "", false, false], [4, 4, 19, 21, "compare", "", false, false], [4, 4, 23, 25, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["An", "early", "version", "of", "VMAF", "was", "shown", "to", "outperform", "other", "image", "and", "video", "quality", "metrics", "such", "as", "SSIM", ",", "PSNR", "-", "HVS", "and", "VQM", "-", "VFD", "in", "terms", "of", "prediction", "accuracy", "in", "three", "out", "of", "four", "datasets", "when", "compared", "to", "subjective", "ratings", "."], "sentence-detokenized": "An early version of VMAF was shown to outperform other image and video quality metrics such as SSIM, PSNR -HVS and VQM-VFD in terms of prediction accuracy in three out of four datasets when compared to subjective ratings.", "token2charspan": [[0, 2], [3, 8], [9, 16], [17, 19], [20, 24], [25, 28], [29, 34], [35, 37], [38, 48], [49, 54], [55, 60], [61, 64], [65, 70], [71, 78], [79, 86], [87, 91], [92, 94], [95, 99], [99, 100], [101, 105], [106, 107], [107, 110], [111, 114], [115, 118], [118, 119], [119, 122], [123, 125], [126, 131], [132, 134], [135, 145], [146, 154], [155, 157], [158, 163], [164, 167], [168, 170], [171, 175], [176, 184], [185, 189], [190, 198], [199, 201], [202, 212], [213, 220], [220, 221]]}
{"doc_key": "ai-test-219", "ner": [[20, 21, "task"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 21, 25, 26, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "example", ",", "the", "ambiguity", "of", "the", "word", "'", "mouse", "'", "(", "animal", "or", "device", ")", "is", "not", "related", "to", "machine", "translation", ",", "but", "to", "information", "retrieval", "."], "sentence-detokenized": "For example, the ambiguity of the word 'mouse' (animal or device) is not related to machine translation, but to information retrieval.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 26], [27, 29], [30, 33], [34, 38], [39, 40], [40, 45], [45, 46], [47, 48], [48, 54], [55, 57], [58, 64], [64, 65], [66, 68], [69, 72], [73, 80], [81, 83], [84, 91], [92, 103], [103, 104], [105, 108], [109, 111], [112, 123], [124, 133], [133, 134]]}
{"doc_key": "ai-test-220", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [9, 10, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 1, "usage", "", false, false], [9, 10, 6, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Geometric", "hashing", "was", "first", "proposed", "in", "computer", "vision", "for", "object", "recognition", "in", "2D", "and", "3D", ","], "sentence-detokenized": "Geometric hashing was first proposed in computer vision for object recognition in 2D and 3D,", "token2charspan": [[0, 9], [10, 17], [18, 21], [22, 27], [28, 36], [37, 39], [40, 48], [49, 55], [56, 59], [60, 66], [67, 78], [79, 81], [82, 84], [85, 88], [89, 91], [91, 92]]}
{"doc_key": "ai-test-221", "ner": [[16, 18, "field"], [2, 3, "field"], [5, 6, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 3, 16, 18, "part-of", "subfield", false, false], [5, 6, 16, 18, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Together", "with", "supervised", "learning", "and", "reinforcement", "learning", ",", "it", "forms", "one", "of", "the", "three", "main", "categories", "of", "machine", "learning", "."], "sentence-detokenized": "Together with supervised learning and reinforcement learning, it forms one of the three main categories of machine learning.", "token2charspan": [[0, 8], [9, 13], [14, 24], [25, 33], [34, 37], [38, 51], [52, 60], [60, 61], [62, 64], [65, 70], [71, 74], [75, 77], [78, 81], [82, 87], [88, 92], [93, 103], [104, 106], [107, 114], [115, 123], [123, 124]]}
{"doc_key": "ai-test-222", "ner": [[5, 6, "field"], [15, 15, "field"], [17, 18, "field"], [21, 21, "field"], [23, 24, "field"], [26, 29, "field"], [31, 32, "field"], [34, 35, "field"], [37, 37, "field"], [39, 40, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[5, 6, 15, 15, "part-of", "subfield", false, false], [5, 6, 17, 18, "part-of", "subfield", false, false], [5, 6, 21, 21, "part-of", "subfield", false, false], [5, 6, 23, 24, "part-of", "subfield", false, false], [5, 6, 26, 29, "part-of", "subfield", false, false], [5, 6, 31, 32, "part-of", "subfield", false, false], [5, 6, 34, 35, "part-of", "subfield", false, false], [5, 6, 37, 37, "part-of", "subfield", false, false], [5, 6, 39, 40, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Due", "to", "its", "generality", ",", "reinforcement", "learning", "is", "studied", "in", "many", "other", "disciplines", "such", "as", "games", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimisation", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Due to its generality, reinforcement learning is studied in many other disciplines such as games, control theory, operations research, information theory, simulation-based optimisation, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 21], [21, 22], [23, 36], [37, 45], [46, 48], [49, 56], [57, 59], [60, 64], [65, 70], [71, 82], [83, 87], [88, 90], [91, 96], [96, 97], [98, 105], [106, 112], [112, 113], [114, 124], [125, 133], [133, 134], [135, 146], [147, 153], [153, 154], [155, 165], [165, 166], [166, 171], [172, 184], [184, 185], [186, 197], [198, 205], [205, 206], [207, 212], [213, 225], [225, 226], [227, 237], [238, 241], [242, 249], [250, 260], [260, 261]]}
{"doc_key": "ai-test-223", "ner": [[0, 1, "field"], [6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "related-to", "", false, false], [0, 1, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pattern", "recognition", "is", "closely", "related", "to", "artificial", "intelligence", "and", "machine", "learning", ","], "sentence-detokenized": "Pattern recognition is closely related to artificial intelligence and machine learning,", "token2charspan": [[0, 7], [8, 19], [20, 22], [23, 30], [31, 38], [39, 41], [42, 52], [53, 65], [66, 69], [70, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-224", "ner": [[10, 11, "algorithm"], [13, 16, "field"], [17, 17, "field"], [29, 30, "task"], [32, 32, "task"], [34, 35, "task"], [37, 38, "algorithm"], [40, 42, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[10, 11, 13, 16, "related-to", "", false, false], [10, 11, 17, 17, "related-to", "", false, false], [29, 30, 10, 11, "usage", "", true, false], [32, 32, 10, 11, "usage", "", true, false], [34, 35, 10, 11, "usage", "", true, false], [37, 38, 10, 11, "usage", "", true, false], [40, 42, 10, 11, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "software", "is", "used", "to", "design", ",", "train", "and", "deploy", "neural", "network", "(", "supervised", "learning", "and", "unsupervised", "learning", ")", "models", "to", "perform", "a", "wide", "variety", "of", "tasks", "such", "as", "data", "mining", ",", "classification", ",", "function", "approximation", ",", "multivariate", "regression", "and", "time", "series", "forecasting", "."], "sentence-detokenized": "The software is used to design, train and deploy neural network (supervised learning and unsupervised learning) models to perform a wide variety of tasks such as data mining, classification, function approximation, multivariate regression and time series forecasting.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 20], [21, 23], [24, 30], [30, 31], [32, 37], [38, 41], [42, 48], [49, 55], [56, 63], [64, 65], [65, 75], [76, 84], [85, 88], [89, 101], [102, 110], [110, 111], [112, 118], [119, 121], [122, 129], [130, 131], [132, 136], [137, 144], [145, 147], [148, 153], [154, 158], [159, 161], [162, 166], [167, 173], [173, 174], [175, 189], [189, 190], [191, 199], [200, 213], [213, 214], [215, 227], [228, 238], [239, 242], [243, 247], [248, 254], [255, 266], [266, 267]]}
{"doc_key": "ai-test-225", "ner": [[8, 17, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2016", ",", "he", "was", "elected", "as", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2016, he was elected as a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 28], [29, 35], [36, 38], [39, 42], [43, 54], [55, 58], [59, 62], [63, 74], [75, 77], [78, 88], [89, 101], [101, 102]]}
{"doc_key": "ai-test-226", "ner": [[5, 9, "organisation"], [16, 21, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", "(", "since", "2005", ")", "and", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "(", "since", "2009", ")", ","], "sentence-detokenized": "He is a member of the National Academy of Sciences (since 2005) and the American Academy of Arts and Sciences (since 2009),", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 38], [39, 41], [42, 50], [51, 52], [52, 57], [58, 62], [62, 63], [64, 67], [68, 71], [72, 80], [81, 88], [89, 91], [92, 96], [97, 100], [101, 109], [110, 111], [111, 116], [117, 121], [121, 122], [122, 123]]}
{"doc_key": "ai-test-227", "ner": [[1, 5, "misc"], [10, 15, "product"], [18, 18, "country"], [17, 21, "country"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 15, 1, 5, "temporal", "", false, false], [10, 15, 18, 18, "physical", "", false, false], [10, 15, 17, 21, "physical", "", false, false], [10, 15, 25, 26, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "the", "1973", "Yom", "Kippur", "War", ",", "Soviet", "-", "backed", "surface", "-", "to", "-", "air", "missile", "batteries", "in", "Egypt", "and", "Syria", "inflicted", "heavy", "damage", "on", "Israeli", "warplanes", "."], "sentence-detokenized": "During the 1973 Yom Kippur War, Soviet-backed surface-to-air missile batteries in Egypt and Syria inflicted heavy damage on Israeli warplanes.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 26], [27, 30], [30, 31], [32, 38], [38, 39], [39, 45], [46, 53], [53, 54], [54, 56], [56, 57], [57, 60], [61, 68], [69, 78], [79, 81], [82, 87], [88, 91], [92, 97], [98, 107], [108, 113], [114, 120], [121, 123], [124, 131], [132, 141], [141, 142]]}
{"doc_key": "ai-test-228", "ner": [[3, 10, "product"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 16, 3, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Another", "resource", "is", "the", "(", "free", "but", "copyrighted", ")", "HTK", "book", "(", "and", "the", "accompanying", "HTK", "toolkit", ")", "."], "sentence-detokenized": "Another resource is the (free but copyrighted) HTK book (and the accompanying HTK toolkit).", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 23], [24, 25], [25, 29], [30, 33], [34, 45], [45, 46], [47, 50], [51, 55], [56, 57], [57, 60], [61, 64], [65, 77], [78, 81], [82, 89], [89, 90], [90, 91]]}
{"doc_key": "ai-test-229", "ner": [[4, 5, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "Taken", "at", "the", "2004", "AAAI", "Spring", "Symposium", ",", "where", "linguists", ",", "computer", "scientists", ",", "and", "other", "interested", "researchers", "brought", "their", "interests", "together", "for", "the", "first", "time", "and", "proposed", "common", "tasks", "and", "comparative", "data", "sets", "for", "systematic", "computational", "research", "on", "impact", ",", "attractiveness", ",", "subjectivity", ",", "and", "sentiment", "in", "texts", "."], "sentence-detokenized": "- Taken at the 2004 AAAI Spring Symposium, where linguists, computer scientists, and other interested researchers brought their interests together for the first time and proposed common tasks and comparative data sets for systematic computational research on impact, attractiveness, subjectivity, and sentiment in texts.", "token2charspan": [[0, 1], [2, 7], [8, 10], [11, 14], [15, 19], [20, 24], [25, 31], [32, 41], [41, 42], [43, 48], [49, 58], [58, 59], [60, 68], [69, 79], [79, 80], [81, 84], [85, 90], [91, 101], [102, 113], [114, 121], [122, 127], [128, 137], [138, 146], [147, 150], [151, 154], [155, 160], [161, 165], [166, 169], [170, 178], [179, 185], [186, 191], [192, 195], [196, 207], [208, 212], [213, 217], [218, 221], [222, 232], [233, 246], [247, 255], [256, 258], [259, 265], [265, 266], [267, 281], [281, 282], [283, 295], [295, 296], [297, 300], [301, 310], [311, 313], [314, 319], [319, 320]]}
{"doc_key": "ai-test-230", "ner": [[12, 13, "task"], [18, 19, "task"], [21, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "single", "grid", "can", "be", "analysed", "both", "in", "terms", "of", "content", "(", "visual", "inspection", ")", "and", "structure", "(", "cluster", "analysis", ",", "principal", "component", "analysis", "and", "various", "structural", "indices", "related", "to", "the", "complexity", "and", "diversity", "of", "ratings", ",", "which", "are", "the", "main", "techniques", "used", ")", "."], "sentence-detokenized": "A single grid can be analysed both in terms of content (visual inspection) and structure (cluster analysis, principal component analysis and various structural indices related to the complexity and diversity of ratings, which are the main techniques used).", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 17], [18, 20], [21, 29], [30, 34], [35, 37], [38, 43], [44, 46], [47, 54], [55, 56], [56, 62], [63, 73], [73, 74], [75, 78], [79, 88], [89, 90], [90, 97], [98, 106], [106, 107], [108, 117], [118, 127], [128, 136], [137, 140], [141, 148], [149, 159], [160, 167], [168, 175], [176, 178], [179, 182], [183, 193], [194, 197], [198, 207], [208, 210], [211, 218], [218, 219], [220, 225], [226, 229], [230, 233], [234, 238], [239, 249], [250, 254], [254, 255], [255, 256]]}
{"doc_key": "ai-test-231", "ner": [[3, 3, "organisation"], [12, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2018", ",", "Toyota", "was", "seen", "as", "a", "company", "that", "lagged", "behind", "in", "self", "-", "driving", "cars", "and", "needed", "innovation", "."], "sentence-detokenized": "In 2018, Toyota was seen as a company that lagged behind in self-driving cars and needed innovation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 24], [25, 27], [28, 29], [30, 37], [38, 42], [43, 49], [50, 56], [57, 59], [60, 64], [64, 65], [65, 72], [73, 77], [78, 81], [82, 88], [89, 99], [99, 100]]}
{"doc_key": "ai-test-232", "ner": [[39, 39, "misc"], [41, 42, "misc"], [36, 48, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "targets", "include", "natural", "objects", "such", "as", "land", ",", "sea", ",", "precipitation", "(", "such", "as", "rain", ",", "snow", "or", "hail", ")", ",", "sandstorms", ",", "animals", "(", "especially", "birds", ")", ",", "atmospheric", "turbulence", "and", "other", "atmospheric", "effects", "such", "as", "ionosphere", "reflections", ",", "meteor", "trails", "and", "three", "-", "body", "scattering", "spikes", "."], "sentence-detokenized": "These targets include natural objects such as land, sea, precipitation (such as rain, snow or hail), sandstorms, animals (especially birds), atmospheric turbulence and other atmospheric effects such as ionosphere reflections, meteor trails and three-body scattering spikes.", "token2charspan": [[0, 5], [6, 13], [14, 21], [22, 29], [30, 37], [38, 42], [43, 45], [46, 50], [50, 51], [52, 55], [55, 56], [57, 70], [71, 72], [72, 76], [77, 79], [80, 84], [84, 85], [86, 90], [91, 93], [94, 98], [98, 99], [99, 100], [101, 111], [111, 112], [113, 120], [121, 122], [122, 132], [133, 138], [138, 139], [139, 140], [141, 152], [153, 163], [164, 167], [168, 173], [174, 185], [186, 193], [194, 198], [199, 201], [202, 212], [213, 224], [224, 225], [226, 232], [233, 239], [240, 243], [244, 249], [249, 250], [250, 254], [255, 265], [266, 272], [272, 273]]}
{"doc_key": "ai-test-233", "ner": [[19, 19, "product"], [40, 40, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "planning", "and", "control", ",", "the", "main", "difference", "between", "humanoid", "robots", "and", "other", "types", "of", "robots", "(", "such", "as", "industrial", "ones", ")", "is", "that", "the", "robot", "'s", "movement", "must", "be", "human", "-", "like", ",", "using", "legged", "locomotion", ",", "especially", "bipedal", "walking", "."], "sentence-detokenized": "In planning and control, the main difference between humanoid robots and other types of robots (such as industrial ones) is that the robot's movement must be human-like, using legged locomotion, especially bipedal walking.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 23], [23, 24], [25, 28], [29, 33], [34, 44], [45, 52], [53, 61], [62, 68], [69, 72], [73, 78], [79, 84], [85, 87], [88, 94], [95, 96], [96, 100], [101, 103], [104, 114], [115, 119], [119, 120], [121, 123], [124, 128], [129, 132], [133, 138], [138, 140], [141, 149], [150, 154], [155, 157], [158, 163], [163, 164], [164, 168], [168, 169], [170, 175], [176, 182], [183, 193], [193, 194], [195, 205], [206, 213], [214, 221], [221, 222]]}
{"doc_key": "ai-test-234", "ner": [[0, 1, "algorithm"], [8, 10, "misc"], [11, 14, "metrics"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Gradient", "descent", "can", "take", "many", "iterations", "to", "calculate", "a", "local", "minimum", "with", "the", "required", "accuracy", "if", "the", "curvature", "in", "different", "directions", "for", "the", "given", "function", "is", "very", "different", "."], "sentence-detokenized": "Gradient descent can take many iterations to calculate a local minimum with the required accuracy if the curvature in different directions for the given function is very different.", "token2charspan": [[0, 8], [9, 16], [17, 20], [21, 25], [26, 30], [31, 41], [42, 44], [45, 54], [55, 56], [57, 62], [63, 70], [71, 75], [76, 79], [80, 88], [89, 97], [98, 100], [101, 104], [105, 114], [115, 117], [118, 127], [128, 138], [139, 142], [143, 146], [147, 152], [153, 161], [162, 164], [165, 169], [170, 179], [179, 180]]}
{"doc_key": "ai-test-235", "ner": [[0, 8, "misc"], [10, 10, "misc"], [17, 22, "conference"], [25, 28, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 8, 10, 10, "part-of", "", true, false], [17, 22, 25, 28, "physical", "", false, true]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "1997", "RoboCup", "2D", "Football", "Simulation", "League", "was", "the", "first", "RoboCup", "competition", "introduced", "in", "conjunction", "with", "the", "International", "Joint", "Conference", "on", "Artificial", "Intelligence", "held", "in", "Nagoya", ",", "Japan", "from", "23", "to", "29", "August", "1997", "."], "sentence-detokenized": "The 1997 RoboCup 2D Football Simulation League was the first RoboCup competition introduced in conjunction with the International Joint Conference on Artificial Intelligence held in Nagoya, Japan from 23 to 29 August 1997.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 19], [20, 28], [29, 39], [40, 46], [47, 50], [51, 54], [55, 60], [61, 68], [69, 80], [81, 91], [92, 94], [95, 106], [107, 111], [112, 115], [116, 129], [130, 135], [136, 146], [147, 149], [150, 160], [161, 173], [174, 178], [179, 181], [182, 188], [188, 189], [190, 195], [196, 200], [201, 203], [204, 206], [207, 209], [210, 216], [217, 221], [221, 222]]}
{"doc_key": "ai-test-236", "ner": [[6, 6, "programlang"], [13, 13, "programlang"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "options", "include", "an", "embedded", "Python", "environment", "and", "Rserve", "support", "with", "an", "R", "Console", "."], "sentence-detokenized": "Other programming options include an embedded Python environment and Rserve support with an R Console.", "token2charspan": [[0, 5], [6, 17], [18, 25], [26, 33], [34, 36], [37, 45], [46, 52], [53, 64], [65, 68], [69, 75], [76, 83], [84, 88], [89, 91], [92, 93], [94, 101], [101, 102]]}
{"doc_key": "ai-test-237", "ner": [[1, 1, "location"], [8, 9, "field"], [11, 11, "field"], [15, 16, "researcher"], [18, 19, "researcher"], [13, 22, "researcher"], [28, 28, "field"], [29, 37, "field"], [41, 42, "field"], [45, 47, "field"], [51, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[15, 16, 11, 11, "related-to", "contributes_to_field", true, false], [18, 19, 11, 11, "related-to", "contributes_to_field", true, false], [13, 22, 11, 11, "related-to", "contributes_to_field", true, false], [41, 42, 29, 37, "part-of", "", false, false], [45, 47, 41, 42, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["From", "Bonn", "he", "has", "made", "fundamental", "contributions", "to", "artificial", "intelligence", "and", "robotics", "(", "together", "with", "Wolfram", "Burgard", ",", "Dieter", "Fox", ",", "Sebastian", "Thrun", "among", "his", "students", ")", "and", "software", "engineering", ",", "especially", "in", "civil", "engineering", ",", "and", "to", "the", "development", "of", "information", "systems", ",", "especially", "in", "earth", "sciences", ".", "2016.2014", "won", "the", "AAAI", "Classic", "Article", "award", "."], "sentence-detokenized": "From Bonn he has made fundamental contributions to artificial intelligence and robotics (together with Wolfram Burgard, Dieter Fox, Sebastian Thrun among his students) and software engineering, especially in civil engineering, and to the development of information systems, especially in earth sciences. 2016.2014 won the AAAI Classic Article award.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 16], [17, 21], [22, 33], [34, 47], [48, 50], [51, 61], [62, 74], [75, 78], [79, 87], [88, 89], [89, 97], [98, 102], [103, 110], [111, 118], [118, 119], [120, 126], [127, 130], [130, 131], [132, 141], [142, 147], [148, 153], [154, 157], [158, 166], [166, 167], [168, 171], [172, 180], [181, 192], [192, 193], [194, 204], [205, 207], [208, 213], [214, 225], [225, 226], [227, 230], [231, 233], [234, 237], [238, 249], [250, 252], [253, 264], [265, 272], [272, 273], [274, 284], [285, 287], [288, 293], [294, 302], [302, 303], [304, 313], [314, 317], [318, 321], [322, 326], [327, 334], [335, 342], [343, 348], [348, 349]]}
{"doc_key": "ai-test-238", "ner": [[2, 11, "conference"], [19, 20, "location"], [22, 22, "location"], [24, 24, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 11, 19, 20, "physical", "", false, false], [19, 20, 22, 22, "physical", "", false, false], [22, 22, 24, 24, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "first", "edition", "of", "Campus", "Party", "in", "the", "USA", "will", "take", "place", "between", "20", "-", "22", "August", "at", "the", "TCF", "Center", "in", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "The first edition of Campus Party in the USA will take place between 20-22 August at the TCF Center in Detroit, Michigan.", "token2charspan": [[0, 3], [4, 9], [10, 17], [18, 20], [21, 27], [28, 33], [34, 36], [37, 40], [41, 44], [45, 49], [50, 54], [55, 60], [61, 68], [69, 71], [71, 72], [72, 74], [75, 81], [82, 84], [85, 88], [89, 92], [93, 99], [100, 102], [103, 110], [110, 111], [112, 120], [120, 121]]}
{"doc_key": "ai-test-239", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [0, 0, "researcher"], [10, 29, "misc"], [22, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 10, 29, "win-defeat", "", false, false], [7, 8, 10, 29, "win-defeat", "", false, false], [0, 0, 10, 29, "win-defeat", "", false, false], [10, 29, 22, 29, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Hinton", ",", "along", "with", "Yann", "LeCun", "and", "Yoshua", "Bengio", ",", "won", "the", "2018", "Turing", "Award", "for", "conceptual", "and", "engineering", "breakthroughs", "that", "make", "deep", "neural", "networks", "a", "critical", "component", "of", "computing", "."], "sentence-detokenized": "Hinton, along with Yann LeCun and Yoshua Bengio, won the 2018 Turing Award for conceptual and engineering breakthroughs that make deep neural networks a critical component of computing.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 18], [19, 23], [24, 29], [30, 33], [34, 40], [41, 47], [47, 48], [49, 52], [53, 56], [57, 61], [62, 68], [69, 74], [75, 78], [79, 89], [90, 93], [94, 105], [106, 119], [120, 124], [125, 129], [130, 134], [135, 141], [142, 150], [151, 152], [153, 161], [162, 171], [172, 174], [175, 184], [184, 185]]}
{"doc_key": "ai-test-240", "ner": [[0, 2, "product"], [8, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 8, 9, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Euler", "Math", "Toolbox", "uses", "a", "matrix", "language", "similar", "to", "MATLAB", ",", "a", "system", "that", "has", "been", "in", "development", "since", "the", "1970s", "."], "sentence-detokenized": "Euler Math Toolbox uses a matrix language similar to MATLAB, a system that has been in development since the 1970s.", "token2charspan": [[0, 5], [6, 10], [11, 18], [19, 23], [24, 25], [26, 32], [33, 41], [42, 49], [50, 52], [53, 59], [59, 60], [61, 62], [63, 69], [70, 74], [75, 78], [79, 83], [84, 86], [87, 98], [99, 104], [105, 108], [109, 114], [114, 115]]}
{"doc_key": "ai-test-241", "ner": [[8, 8, "programlang"], [10, 11, "programlang"], [13, 13, "programlang"], [15, 15, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "languages", "make", "this", "portably", "possible", "(", "e.g.", "Scheme", ",", "Common", "Lisp", ",", "Perl", "or", "D", ")", "."], "sentence-detokenized": "Some languages make this portably possible (e.g. Scheme, Common Lisp, Perl or D).", "token2charspan": [[0, 4], [5, 14], [15, 19], [20, 24], [25, 33], [34, 42], [43, 44], [44, 48], [49, 55], [55, 56], [57, 63], [64, 68], [68, 69], [70, 74], [75, 77], [78, 79], [79, 80], [80, 81]]}
{"doc_key": "ai-test-242", "ner": [[6, 6, "misc"], [8, 9, "researcher"], [11, 12, "researcher"], [26, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 8, 9, "artifact", "", false, false], [6, 6, 11, 12, "artifact", "", false, false], [6, 6, 26, 27, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1969", ",", "the", "famous", "book", "Perceptrons", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "showed", "that", "it", "is", "impossible", "for", "these", "classes", "of", "networks", "to", "learn", "an", "XOR", "function", "."], "sentence-detokenized": "In 1969, the famous book Perceptrons by Marvin Minsky and Seymour Papert showed that it is impossible for these classes of networks to learn an XOR function.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 19], [20, 24], [25, 36], [37, 39], [40, 46], [47, 53], [54, 57], [58, 65], [66, 72], [73, 79], [80, 84], [85, 87], [88, 90], [91, 101], [102, 105], [106, 111], [112, 119], [120, 122], [123, 131], [132, 134], [135, 140], [141, 143], [144, 147], [148, 156], [156, 157]]}
{"doc_key": "ai-test-243", "ner": [[1, 5, "misc"], [9, 9, "product"], [13, 18, "organisation"], [22, 27, "organisation"], [30, 35, "location"], [37, 37, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 18, 9, 9, "usage", "", false, false], [13, 18, 30, 35, "physical", "", false, false], [22, 27, 13, 18, "named", "", false, false], [30, 35, 37, 37, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Numerous", "Russian", "scientific", "and", "technical", "documents", "were", "translated", "using", "SYSTRAN", "under", "the", "auspices", "of", "the", "USAF", "Foreign", "Technology", "Division", "(", "later", "the", "National", "Air", "and", "Space", "Intelligence", "Centre", ")", "at", "Wright", "-", "Patterson", "Air", "Force", "Base", "in", "Ohio", "."], "sentence-detokenized": "Numerous Russian scientific and technical documents were translated using SYSTRAN under the auspices of the USAF Foreign Technology Division (later the National Air and Space Intelligence Centre) at Wright-Patterson Air Force Base in Ohio.", "token2charspan": [[0, 8], [9, 16], [17, 27], [28, 31], [32, 41], [42, 51], [52, 56], [57, 67], [68, 73], [74, 81], [82, 87], [88, 91], [92, 100], [101, 103], [104, 107], [108, 112], [113, 120], [121, 131], [132, 140], [141, 142], [142, 147], [148, 151], [152, 160], [161, 164], [165, 168], [169, 174], [175, 187], [188, 194], [194, 195], [196, 198], [199, 205], [205, 206], [206, 215], [216, 219], [220, 225], [226, 230], [231, 233], [234, 238], [238, 239]]}
{"doc_key": "ai-test-244", "ner": [[0, 3, "field"], [4, 5, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Semi-supervised", "learning", "lies", "between", "unsupervised", "learning", "(", "without", "any", "labelled", "training", "data", ")", "and", "supervised", "learning", "(", "with", "fully", "labelled", "training", "data", ")", "."], "sentence-detokenized": "Semi-supervised learning lies between unsupervised learning (without any labelled training data) and supervised learning (with fully labelled training data).", "token2charspan": [[0, 15], [16, 24], [25, 29], [30, 37], [38, 50], [51, 59], [60, 61], [61, 68], [69, 72], [73, 81], [82, 90], [91, 95], [95, 96], [97, 100], [101, 111], [112, 120], [121, 122], [122, 126], [127, 132], [133, 141], [142, 150], [151, 155], [155, 156], [156, 157]]}
{"doc_key": "ai-test-245", "ner": [[0, 29, "algorithm"], [9, 35, "algorithm"], [34, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 29, 9, 35, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ann", "-", "gram", "model", "is", "a", "type", "of", "probabilistic", "language", "model", "used", "to", "efficiently", "predict", "the", "next", "element", "in", "such", "a", "sequence", "in", "the", "form", "of", "an", "(", "n", "-", "1", ")", "ordered", "Markov", "model", "."], "sentence-detokenized": "The ann-gram model is a type of probabilistic language model used to efficiently predict the next element in such a sequence in the form of an (n - 1) ordered Markov model.", "token2charspan": [[0, 3], [4, 7], [7, 8], [8, 12], [13, 18], [19, 21], [22, 23], [24, 28], [29, 31], [32, 45], [46, 54], [55, 60], [61, 65], [66, 68], [69, 80], [81, 88], [89, 92], [93, 97], [98, 105], [106, 108], [109, 113], [114, 115], [116, 124], [125, 127], [128, 131], [132, 136], [137, 139], [140, 142], [143, 144], [144, 145], [146, 147], [148, 149], [149, 150], [151, 158], [159, 165], [166, 171], [171, 172]]}
{"doc_key": "ai-test-246", "ner": [[0, 2, "organisation"], [4, 4, "product"], [7, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 4, 4, "usage", "", false, false], [7, 14, 0, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Cleveland", "Clinic", "used", "Cyc", "to", "develop", "a", "natural", "language", "query", "interface", "of", "biomedical", "information", "covering", "decades", "of", "knowledge", "about", "cardiothoracic", "surgeries", "."], "sentence-detokenized": "The Cleveland Clinic used Cyc to develop a natural language query interface of biomedical information covering decades of knowledge about cardiothoracic surgeries.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 29], [30, 32], [33, 40], [41, 42], [43, 50], [51, 59], [60, 65], [66, 75], [76, 78], [79, 89], [90, 101], [102, 110], [111, 118], [119, 121], [122, 131], [132, 137], [138, 152], [153, 162], [162, 163]]}
{"doc_key": "ai-test-247", "ner": [[6, 6, "country"], [8, 8, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 6, 8, 8, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "incident", "strained", "relations", "between", "the", "US", "and", "Japan", "and", "resulted", "in", "the", "arrest", "and", "prosecution", "of", "two", "senior", "executives", ",", "as", "well", "as", "the", "imposition", "of", "sanctions", "on", "the", "company", "by", "both", "countries", "."], "sentence-detokenized": "The incident strained relations between the US and Japan and resulted in the arrest and prosecution of two senior executives, as well as the imposition of sanctions on the company by both countries.", "token2charspan": [[0, 3], [4, 12], [13, 21], [22, 31], [32, 39], [40, 43], [44, 46], [47, 50], [51, 56], [57, 60], [61, 69], [70, 72], [73, 76], [77, 83], [84, 87], [88, 99], [100, 102], [103, 106], [107, 113], [114, 124], [124, 125], [126, 128], [129, 133], [134, 136], [137, 140], [141, 151], [152, 154], [155, 164], [165, 167], [168, 171], [172, 179], [180, 182], [183, 187], [188, 197], [197, 198]]}
{"doc_key": "ai-test-248", "ner": [[7, 9, "algorithm"], [12, 15, "field"], [20, 25, "misc"], [31, 33, "misc"], [37, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 9, 12, 15, "type-of", "", false, false], [20, 25, 12, 15, "part-of", "", true, false], [31, 33, 12, 15, "part-of", "", true, false], [37, 37, 12, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["If", "the", "modelling", "is", "done", "with", "an", "artificial", "neural", "network", "or", "other", "machine", "learning", ",", "the", "optimisation", "of", "the", "parameters", "is", "called", "training", ",", "while", "the", "optimisation", "of", "the", "model", "hyperparameters", "is", "called", "tuning", "and", "usually", "uses", "cross-validation", "."], "sentence-detokenized": "If the modelling is done with an artificial neural network or other machine learning, the optimisation of the parameters is called training, while the optimisation of the model hyperparameters is called tuning and usually uses cross-validation.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 24], [25, 29], [30, 32], [33, 43], [44, 50], [51, 58], [59, 61], [62, 67], [68, 75], [76, 84], [84, 85], [86, 89], [90, 102], [103, 105], [106, 109], [110, 120], [121, 123], [124, 130], [131, 139], [139, 140], [141, 146], [147, 150], [151, 163], [164, 166], [167, 170], [171, 176], [177, 192], [193, 195], [196, 202], [203, 209], [210, 213], [214, 221], [222, 226], [227, 243], [243, 244]]}
{"doc_key": "ai-test-249", "ner": [[7, 7, "country"], [9, 9, "country"], [11, 12, "country"], [17, 19, "organisation"], [21, 21, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[17, 19, 21, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Localised", "versions", "of", "the", "site", "in", "the", "UK", ",", "India", "and", "Australia", "were", "discontinued", "following", "the", "acquisition", "of", "Rotten", "Tomatoes", "by", "Fandango", "."], "sentence-detokenized": "Localised versions of the site in the UK, India and Australia were discontinued following the acquisition of Rotten Tomatoes by Fandango.", "token2charspan": [[0, 9], [10, 18], [19, 21], [22, 25], [26, 30], [31, 33], [34, 37], [38, 40], [40, 41], [42, 47], [48, 51], [52, 61], [62, 66], [67, 79], [80, 89], [90, 93], [94, 105], [106, 108], [109, 115], [116, 124], [125, 127], [128, 136], [136, 137]]}
{"doc_key": "ai-test-250", "ner": [[0, 1, "task"], [13, 15, "metrics"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 13, 15, "related-to", "", false, false], [13, 15, 25, 26, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "NER", "model", "is", "one", "of", "a", "number", "of", "methods", "used", "to", "determine", "the", "accuracy", "of", "live", "captions", "in", "television", "broadcasts", "and", "events", "produced", "using", "speech", "recognition", "."], "sentence-detokenized": "The NER model is one of a number of methods used to determine the accuracy of live captions in television broadcasts and events produced using speech recognition.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 20], [21, 23], [24, 25], [26, 32], [33, 35], [36, 43], [44, 48], [49, 51], [52, 61], [62, 65], [66, 74], [75, 77], [78, 82], [83, 91], [92, 94], [95, 105], [106, 116], [117, 120], [121, 127], [128, 136], [137, 142], [143, 149], [150, 161], [161, 162]]}
{"doc_key": "ai-test-251", "ner": [[4, 7, "university"], [8, 13, "university"], [11, 11, "location"], [14, 18, "university"], [21, 27, "university"], [23, 24, "location"], [3, 33, "university"], [35, 36, "location"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8], "relations": [[8, 13, 11, 11, "physical", "", false, false], [14, 18, 23, 24, "physical", "", false, false], [21, 27, 23, 24, "physical", "", false, false], [3, 33, 35, 36, "physical", "", false, false]], "relations_mapping_to_source": [10, 11, 12, 13], "sentence": ["Atran", "has", "taught", "at", "Cambridge", "University", ",", "the", "Hebrew", "University", "in", "Jerusalem", ",", "the", "\u00c9cole", "pratique", "des", "hautes", "\u00e9tudes", "and", "the", "\u00c9cole", "Polytechnique", "in", "Paris", ",", "and", "the", "John", "Jay", "College", "of", "Criminal", "Justice", "in", "New", "York", "."], "sentence-detokenized": "Atran has taught at Cambridge University, the Hebrew University in Jerusalem, the \u00c9cole pratique des hautes \u00e9tudes and the \u00c9cole Polytechnique in Paris, and the John Jay College of Criminal Justice in New York.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 40], [40, 41], [42, 45], [46, 52], [53, 63], [64, 66], [67, 76], [76, 77], [78, 81], [82, 87], [88, 96], [97, 100], [101, 107], [108, 114], [115, 118], [119, 122], [123, 128], [129, 142], [143, 145], [146, 151], [151, 152], [153, 156], [157, 160], [161, 165], [166, 169], [170, 177], [178, 180], [181, 189], [190, 197], [198, 200], [201, 204], [205, 209], [209, 210]]}
{"doc_key": "ai-test-252", "ner": [[0, 0, "product"], [4, 6, "task"], [11, 12, "researcher"], [14, 14, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 6, "origin", "", false, false], [0, 0, 4, 6, "related-to", "", false, false], [4, 6, 14, 14, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "was", "an", "early", "natural", "language", "understanding", "computer", "programme", "developed", "by", "Terry", "Winograd", "at", "MIT", "in", "1968-", "1970"], "sentence-detokenized": "SHRDLU was an early natural language understanding computer programme developed by Terry Winograd at MIT in 1968-1970", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 19], [20, 27], [28, 36], [37, 50], [51, 59], [60, 69], [70, 79], [80, 82], [83, 88], [89, 97], [98, 100], [101, 104], [105, 107], [108, 113], [113, 117]]}
{"doc_key": "ai-test-253", "ner": [[0, 32, "misc"], [7, 8, "field"], [9, 17, "university"], [28, 28, "location"], [19, 19, "country"], [29, 29, "university"], [33, 50, "misc"], [36, 39, "field"], [40, 42, "university"], [62, 64, "misc"], [51, 51, "field"], [65, 65, "misc"], [55, 59, "university"], [72, 74, "field"], [78, 79, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[0, 32, 7, 8, "topic", "", false, false], [0, 32, 9, 17, "origin", "", false, false], [9, 17, 28, 28, "physical", "", false, false], [9, 17, 29, 29, "role", "affiliated_with", false, false], [28, 28, 19, 19, "physical", "", false, false], [33, 50, 36, 39, "topic", "", false, false], [33, 50, 40, 42, "origin", "", false, false], [62, 64, 51, 51, "topic", "", false, false], [65, 65, 55, 59, "origin", "", false, false], [65, 65, 72, 74, "topic", "", false, false], [78, 79, 55, 59, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["He", "received", "his", "bachelor", "'s", "degree", "in", "electronic", "engineering", "from", "B", ".", "M.S.", "College", "of", "Engineering", "in", "Bangalore", ",", "India", "in", "1982", ",", "where", "he", "was", "affiliated", "with", "Bangalore", "University", ",", "his", "master", "'s", "degree", "in", "electrical", "and", "computer", "engineering", "from", "Drexel", "University", "in", "1984", ",", "his", "master", "'s", "degree", "in", "computer", "science", "from", "the", "University", "of", "Wisconsin", "-", "Madison", "in", "1989", ",", "and", "his", "PhD", "in", "1990", ",", "where", "he", "worked", "on", "Artificial", "Intelligence", "and", "collaborated", "with", "Leonard", "Uhr", "."], "sentence-detokenized": "He received his bachelor's degree in electronic engineering from B. M.S. College of Engineering in Bangalore, India in 1982, where he was affiliated with Bangalore University, his master's degree in electrical and computer engineering from Drexel University in 1984, his master's degree in computer science from the University of Wisconsin-Madison in 1989, and his PhD in 1990, where he worked on Artificial Intelligence and collaborated with Leonard Uhr.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 24], [24, 26], [27, 33], [34, 36], [37, 47], [48, 59], [60, 64], [65, 66], [66, 67], [68, 72], [73, 80], [81, 83], [84, 95], [96, 98], [99, 108], [108, 109], [110, 115], [116, 118], [119, 123], [123, 124], [125, 130], [131, 133], [134, 137], [138, 148], [149, 153], [154, 163], [164, 174], [174, 175], [176, 179], [180, 186], [186, 188], [189, 195], [196, 198], [199, 209], [210, 213], [214, 222], [223, 234], [235, 239], [240, 246], [247, 257], [258, 260], [261, 265], [265, 266], [267, 270], [271, 277], [277, 279], [280, 286], [287, 289], [290, 298], [299, 306], [307, 311], [312, 315], [316, 326], [327, 329], [330, 339], [339, 340], [340, 347], [348, 350], [351, 355], [355, 356], [357, 360], [361, 364], [365, 368], [369, 371], [372, 376], [376, 377], [378, 383], [384, 386], [387, 393], [394, 396], [397, 407], [408, 420], [421, 424], [425, 437], [438, 442], [443, 450], [451, 454], [454, 455]]}
{"doc_key": "ai-test-254", "ner": [[6, 8, "metrics"], [4, 10, "metrics"], [19, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 10, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Accuracy", "is", "usually", "evaluated", "by", "the", "word", "error", "rate", "(", "WER", ")", ",", "while", "speed", "is", "measured", "by", "the", "real", "time", "factor", "."], "sentence-detokenized": "Accuracy is usually evaluated by the word error rate (WER), while speed is measured by the real time factor.", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 29], [30, 32], [33, 36], [37, 41], [42, 47], [48, 52], [53, 54], [54, 57], [57, 58], [58, 59], [60, 65], [66, 71], [72, 74], [75, 83], [84, 86], [87, 90], [91, 95], [96, 100], [101, 107], [107, 108]]}
{"doc_key": "ai-test-255", "ner": [[3, 4, "researcher"], [8, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 8, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1971", ",", "Terry", "Winograd", "developed", "an", "early", "natural", "language", "processing", "engine", "capable", "of", "interpreting", "naturally", "written", "commands", "in", "an", "environment", "governed", "by", "simple", "rules", "."], "sentence-detokenized": "In 1971, Terry Winograd developed an early natural language processing engine capable of interpreting naturally written commands in an environment governed by simple rules.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 33], [34, 36], [37, 42], [43, 50], [51, 59], [60, 70], [71, 77], [78, 85], [86, 88], [89, 101], [102, 111], [112, 119], [120, 128], [129, 131], [132, 134], [135, 146], [147, 155], [156, 158], [159, 165], [166, 171], [171, 172]]}
{"doc_key": "ai-test-256", "ner": [[17, 18, "field"], [0, 1, "researcher"], [3, 6, "researcher"], [8, 9, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[17, 18, 0, 1, "related-to", "", false, false], [17, 18, 3, 6, "related-to", "", false, false], [17, 18, 8, 9, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Marvin", "Minsky", ",", "Herbert", "A", ".", "Simon", "and", "Allen", "Newell", "are", "prominent", "names", "in", "the", "field", "of", "artificial", "intelligence", "."], "sentence-detokenized": "Marvin Minsky, Herbert A. Simon and Allen Newell are prominent names in the field of artificial intelligence.", "token2charspan": [[0, 6], [7, 13], [13, 14], [15, 22], [23, 24], [24, 25], [26, 31], [32, 35], [36, 41], [42, 48], [49, 52], [53, 62], [63, 68], [69, 71], [72, 75], [76, 81], [82, 84], [85, 95], [96, 108], [108, 109]]}
{"doc_key": "ai-test-257", "ner": [[9, 10, "field"], [30, 31, "field"], [33, 34, "field"], [37, 38, "field"], [47, 50, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[30, 31, 9, 10, "origin", "", true, false], [30, 31, 9, 10, "part-of", "", false, false], [30, 31, 37, 38, "compare", "", false, false], [33, 34, 9, 10, "origin", "", true, false], [33, 34, 9, 10, "part-of", "", false, false], [33, 34, 37, 38, "compare", "", false, false], [37, 38, 9, 10, "origin", "", true, false], [37, 38, 9, 10, "part-of", "", false, false], [37, 38, 47, 50, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "the", "second", "half", "of", "the", "twentieth", "century", ",", "electrical", "engineering", "split", "into", "several", "disciplines", "specialising", "in", "the", "design", "and", "analysis", "of", "systems", "that", "manipulate", "physical", "signals", ";", "examples", "include", "electronic", "engineering", "and", "computer", "engineering", ",", "while", "design", "engineering", "developed", "to", "deal", "with", "the", "functional", "design", "of", "user", "-", "machine", "interfaces", "."], "sentence-detokenized": "In the second half of the twentieth century, electrical engineering split into several disciplines specialising in the design and analysis of systems that manipulate physical signals; examples include electronic engineering and computer engineering, while design engineering developed to deal with the functional design of user-machine interfaces.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 21], [22, 25], [26, 35], [36, 43], [43, 44], [45, 55], [56, 67], [68, 73], [74, 78], [79, 86], [87, 98], [99, 111], [112, 114], [115, 118], [119, 125], [126, 129], [130, 138], [139, 141], [142, 149], [150, 154], [155, 165], [166, 174], [175, 182], [182, 183], [184, 192], [193, 200], [201, 211], [212, 223], [224, 227], [228, 236], [237, 248], [248, 249], [250, 255], [256, 262], [263, 274], [275, 284], [285, 287], [288, 292], [293, 297], [298, 301], [302, 312], [313, 319], [320, 322], [323, 327], [327, 328], [328, 335], [336, 346], [346, 347]]}
{"doc_key": "ai-test-258", "ner": [[6, 6, "metrics"], [8, 8, "metrics"], [11, 11, "metrics"], [45, 47, "metrics"], [60, 63, "metrics"], [64, 66, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 8, 8, "named", "", false, false], [45, 47, 60, 63, "named", "", false, false], [60, 63, 64, 66, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Perhaps", "the", "simplest", "statistic", "is", "the", "accuracy", "or", "Fraction", "Correct", "(", "FC", ")", ",", "which", "measures", "the", "proportion", "of", "all", "samples", "correctly", "classified", ";", "it", "is", "the", "ratio", "of", "the", "number", "of", "correct", "classifications", "to", "the", "total", "number", "of", "correct", "or", "incorrect", "classifications", ":", "(", "TP", "+", "TN", ")", "/", "Total", "Population", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "Perhaps the simplest statistic is the accuracy or Fraction Correct (FC), which measures the proportion of all samples correctly classified; it is the ratio of the number of correct classifications to the total number of correct or incorrect classifications: (TP + TN) / Total Population = (TP + TN) / (TP + TN + FP + FN).", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 30], [31, 33], [34, 37], [38, 46], [47, 49], [50, 58], [59, 66], [67, 68], [68, 70], [70, 71], [71, 72], [73, 78], [79, 87], [88, 91], [92, 102], [103, 105], [106, 109], [110, 117], [118, 127], [128, 138], [138, 139], [140, 142], [143, 145], [146, 149], [150, 155], [156, 158], [159, 162], [163, 169], [170, 172], [173, 180], [181, 196], [197, 199], [200, 203], [204, 209], [210, 216], [217, 219], [220, 227], [228, 230], [231, 240], [241, 256], [256, 257], [258, 259], [259, 261], [262, 263], [264, 266], [266, 267], [268, 269], [270, 275], [276, 286], [287, 288], [289, 290], [290, 292], [293, 294], [295, 297], [297, 298], [299, 300], [301, 302], [302, 304], [305, 306], [307, 309], [310, 311], [312, 314], [315, 316], [317, 319], [319, 320], [320, 321]]}
{"doc_key": "ai-test-259", "ner": [[20, 28, "conference"], [30, 32, "conference"], [34, 35, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[20, 28, 34, 35, "physical", "", false, false], [30, 32, 20, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "the", "academic", "community", ",", "important", "forums", "for", "research", "began", "in", "1995", "with", "the", "launch", "of", "the", "AAAI", "-", "sponsored", "First", "International", "Conference", "on", "Data", "Mining", "and", "Knowledge", "Discovery", "(", "KDD", "-", "95", ")", "in", "Montreal", "."], "sentence-detokenized": "In the academic community, important forums for research began in 1995 with the launch of the AAAI-sponsored First International Conference on Data Mining and Knowledge Discovery (KDD-95) in Montreal.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 25], [25, 26], [27, 36], [37, 43], [44, 47], [48, 56], [57, 62], [63, 65], [66, 70], [71, 75], [76, 79], [80, 86], [87, 89], [90, 93], [94, 98], [98, 99], [99, 108], [109, 114], [115, 128], [129, 139], [140, 142], [143, 147], [148, 154], [155, 158], [159, 168], [169, 178], [179, 180], [180, 183], [183, 184], [184, 186], [186, 187], [188, 190], [191, 199], [199, 200]]}
{"doc_key": "ai-test-260", "ner": [[9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "this", "approach", ",", "models", "are", "developed", "using", "different", "data", "mining", ",", "machine", "learning", "algorithms", "to", "predict", "users", "'", "rating", "of", "unrated", "items", "."], "sentence-detokenized": "In this approach, models are developed using different data mining, machine learning algorithms to predict users' rating of unrated items.", "token2charspan": [[0, 2], [3, 7], [8, 16], [16, 17], [18, 24], [25, 28], [29, 38], [39, 44], [45, 54], [55, 59], [60, 66], [66, 67], [68, 75], [76, 84], [85, 95], [96, 98], [99, 106], [107, 112], [112, 113], [114, 120], [121, 123], [124, 131], [132, 137], [137, 138]]}
{"doc_key": "ai-test-261", "ner": [[11, 11, "algorithm"], [15, 17, "algorithm"], [19, 20, "algorithm"], [24, 25, "misc"], [26, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 11, 15, 17, "related-to", "equivalent", false, false], [15, 17, 19, 20, "usage", "", false, false], [19, 20, 26, 29, "usage", "", false, false], [26, 29, 24, 25, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "light", "of", "the", "above", "discussion", ",", "we", "see", "that", "the", "SVM", "technique", "is", "equivalent", "to", "empirical", "risk", "with", "Tikhonov", "regularisation", ",", "where", "the", "loss", "function", "is", "the", "hinge", "loss"], "sentence-detokenized": "In light of the above discussion, we see that the SVM technique is equivalent to empirical risk with Tikhonov regularisation, where the loss function is the hinge loss", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 15], [16, 21], [22, 32], [32, 33], [34, 36], [37, 40], [41, 45], [46, 49], [50, 53], [54, 63], [64, 66], [67, 77], [78, 80], [81, 90], [91, 95], [96, 100], [101, 109], [110, 124], [124, 125], [126, 131], [132, 135], [136, 140], [141, 149], [150, 152], [153, 156], [157, 162], [163, 167]]}
{"doc_key": "ai-test-262", "ner": [[6, 7, "person"], [10, 11, "person"], [14, 14, "organisation"], [16, 17, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 17, 14, 14, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "2015", "edition", "was", "hosted", "by", "Molly", "McGrath", ",", "with", "Chris", "Rose", "and", "former", "UFC", "fighter", "Kenny", "Florian", "as", "commentators", "."], "sentence-detokenized": "The 2015 edition was hosted by Molly McGrath, with Chris Rose and former UFC fighter Kenny Florian as commentators.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 27], [28, 30], [31, 36], [37, 44], [44, 45], [46, 50], [51, 56], [57, 61], [62, 65], [66, 72], [73, 76], [77, 84], [85, 90], [91, 98], [99, 101], [102, 114], [114, 115]]}
{"doc_key": "ai-test-263", "ner": [[3, 5, "product"], [9, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [18, 20, "researcher"], [27, 27, "researcher"], [29, 31, "task"], [33, 33, "product"], [35, 37, "researcher"], [40, 41, "task"], [43, 43, "researcher"], [48, 49, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12], "relations": [[3, 5, 9, 11, "origin", "", false, false], [3, 5, 13, 14, "origin", "", false, false], [3, 5, 16, 17, "origin", "", false, false], [3, 5, 18, 20, "origin", "", false, false], [13, 14, 35, 37, "named", "same", false, false], [16, 17, 27, 27, "named", "same", false, false], [29, 31, 33, 33, "related-to", "", false, false], [33, 33, 27, 27, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 6, 7, 8], "sentence": ["A", "subset", "called", "Micro", "-", "Planner", "was", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "Sussman", "and", "Winograd", "1971", "and", "has", "been", "used", "in", "Winograd", "'s", "natural", "language", "comprehension", "programme", "SHRDLU", ",", "Eugene", "Charniak", "'s", "work", "on", "story", "comprehension", ",", "Thorne", "McCarty", "'s", "work", "on", "legal", "reasoning", "and", "several", "other", "projects", "."], "sentence-detokenized": "A subset called Micro-Planner was implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd Sussman and Winograd 1971 and has been used in Winograd's natural language comprehension programme SHRDLU, Eugene Charniak's work on story comprehension, Thorne McCarty's work on legal reasoning and several other projects.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [21, 22], [22, 29], [30, 33], [34, 45], [46, 48], [49, 55], [56, 59], [60, 67], [67, 68], [69, 75], [76, 84], [85, 88], [89, 94], [95, 103], [104, 111], [112, 115], [116, 124], [125, 129], [130, 133], [134, 137], [138, 142], [143, 147], [148, 150], [151, 159], [159, 161], [162, 169], [170, 178], [179, 192], [193, 202], [203, 209], [209, 210], [211, 217], [218, 226], [226, 228], [229, 233], [234, 236], [237, 242], [243, 256], [256, 257], [258, 264], [265, 272], [272, 274], [275, 279], [280, 282], [283, 288], [289, 298], [299, 302], [303, 310], [311, 316], [317, 325], [325, 326]]}
{"doc_key": "ai-test-264", "ner": [[0, 1, "product"], [6, 14, "product"], [15, 16, "task"], [18, 19, "task"], [21, 25, "task"], [26, 26, "task"], [28, 29, "task"], [33, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[6, 14, 0, 1, "usage", "", true, false], [15, 16, 6, 14, "part-of", "", true, false], [18, 19, 6, 14, "part-of", "", true, false], [21, 25, 6, 14, "part-of", "", true, false], [26, 26, 6, 14, "part-of", "", true, false], [28, 29, 6, 14, "part-of", "", true, false], [33, 34, 6, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Word", "Net", "has", "been", "used", "for", "a", "number", "of", "purposes", "in", "information", "systems", ",", "including", "word", "disambiguation", ",", "information", "retrieval", ",", "automatic", "text", "classification", ",", "automatic", "summarisation", ",", "machine", "translation", "and", "even", "automatic", "puzzle", "generation", "."], "sentence-detokenized": "WordNet has been used for a number of purposes in information systems, including word disambiguation, information retrieval, automatic text classification, automatic summarisation, machine translation and even automatic puzzle generation.", "token2charspan": [[0, 4], [4, 7], [8, 11], [12, 16], [17, 21], [22, 25], [26, 27], [28, 34], [35, 37], [38, 46], [47, 49], [50, 61], [62, 69], [69, 70], [71, 80], [81, 85], [86, 100], [100, 101], [102, 113], [114, 123], [123, 124], [125, 134], [135, 139], [140, 154], [154, 155], [156, 165], [166, 179], [179, 180], [181, 188], [189, 200], [201, 204], [205, 209], [210, 219], [220, 226], [227, 237], [237, 238]]}
{"doc_key": "ai-test-265", "ner": [[0, 0, "researcher"], [5, 5, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 5, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Keutzer", "was", "elected", "as", "an", "IEEE", "Fellow", "in", "1996", "."], "sentence-detokenized": "Keutzer was elected as an IEEE Fellow in 1996.", "token2charspan": [[0, 7], [8, 11], [12, 19], [20, 22], [23, 25], [26, 30], [31, 37], [38, 40], [41, 45], [45, 46]]}
{"doc_key": "ai-test-266", "ner": [[6, 10, "algorithm"], [53, 54, "misc"], [62, 63, "algorithm"], [65, 66, "algorithm"], [68, 69, "algorithm"], [71, 72, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[62, 63, 53, 54, "type-of", "", false, false], [65, 66, 53, 54, "type-of", "", false, false], [68, 69, 53, 54, "type-of", "", false, false], [71, 72, 53, 54, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "commonly", "used", "type", "of", "composition", "is", "the", "nonlinear", "weighted", "sum", ",", "where", "math", "\\", "textstyle", "f", "(", "x", ")", "=", "K", "\\", "left", "(", "\\", "sum", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "\\", "right", ")", "/", "math", ",", "math", "\\", "textstyle", "K", "/", "math", "(", "often", "called", "activation", "function", ")", "is", "some", "predefined", "function", "such", "as", "hyperbolic", "tangent", ",", "sigmoid", "function", ",", "softmax", "function", "or", "rectifier", "function", "."], "sentence-detokenized": "A commonly used type of composition is the nonlinear weighted sum, where math\\ textstyle f (x) = K\\ left (\\ sum _ i w _ i g _ i (x)\\ right) / math, math\\ textstyle K / math (often called activation function) is some predefined function such as hyperbolic tangent, sigmoid function, softmax function or rectifier function.", "token2charspan": [[0, 1], [2, 10], [11, 15], [16, 20], [21, 23], [24, 35], [36, 38], [39, 42], [43, 52], [53, 61], [62, 65], [65, 66], [67, 72], [73, 77], [77, 78], [79, 88], [89, 90], [91, 92], [92, 93], [93, 94], [95, 96], [97, 98], [98, 99], [100, 104], [105, 106], [106, 107], [108, 111], [112, 113], [114, 115], [116, 117], [118, 119], [120, 121], [122, 123], [124, 125], [126, 127], [128, 129], [129, 130], [130, 131], [131, 132], [133, 138], [138, 139], [140, 141], [142, 146], [146, 147], [148, 152], [152, 153], [154, 163], [164, 165], [166, 167], [168, 172], [173, 174], [174, 179], [180, 186], [187, 197], [198, 206], [206, 207], [208, 210], [211, 215], [216, 226], [227, 235], [236, 240], [241, 243], [244, 254], [255, 262], [262, 263], [264, 271], [272, 280], [280, 281], [282, 289], [290, 298], [299, 301], [302, 311], [312, 320], [320, 321]]}
{"doc_key": "ai-test-267", "ner": [[3, 3, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "film", "Westworld", ",", "female", "robots", "had", "sexual", "intercourse", "with", "human", "males", "as", "part", "of", "an", "imaginary", "holiday", "world", "in", "which", "human", "customers", "paid", "to", "participate", "."], "sentence-detokenized": "In the film Westworld, female robots had sexual intercourse with human males as part of an imaginary holiday world in which human customers paid to participate.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 21], [21, 22], [23, 29], [30, 36], [37, 40], [41, 47], [48, 59], [60, 64], [65, 70], [71, 76], [77, 79], [80, 84], [85, 87], [88, 90], [91, 100], [101, 108], [109, 114], [115, 117], [118, 123], [124, 129], [130, 139], [140, 144], [145, 147], [148, 159], [159, 160]]}
{"doc_key": "ai-test-268", "ner": [[5, 9, "task"], [23, 30, "task"], [31, 31, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 9, 23, 30, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Typically", ",", "the", "process", "starts", "with", "the", "extraction", "of", "terminology", "and", "concepts", "or", "noun", "phrases", "from", "plain", "text", "using", "linguistic", "processors", "such", "as", "part", "-", "of", "-", "speech", "tagging", "and", "phrase", "phrasing", "."], "sentence-detokenized": "Typically, the process starts with the extraction of terminology and concepts or noun phrases from plain text using linguistic processors such as part-of-speech tagging and phrase phrasing.", "token2charspan": [[0, 9], [9, 10], [11, 14], [15, 22], [23, 29], [30, 34], [35, 38], [39, 49], [50, 52], [53, 64], [65, 68], [69, 77], [78, 80], [81, 85], [86, 93], [94, 98], [99, 104], [105, 109], [110, 115], [116, 126], [127, 137], [138, 142], [143, 145], [146, 150], [150, 151], [151, 153], [153, 154], [154, 160], [161, 168], [169, 172], [173, 179], [180, 188], [188, 189]]}
{"doc_key": "ai-test-269", "ner": [[13, 14, "field"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 13, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "demonstrated", "its", "performance", "on", "a", "range", "of", "problems", "of", "interest", "to", "the", "machine", "learning", "community", ",", "including", "handwriting", "recognition", "."], "sentence-detokenized": "They demonstrated its performance on a range of problems of interest to the machine learning community, including handwriting recognition.", "token2charspan": [[0, 4], [5, 17], [18, 21], [22, 33], [34, 36], [37, 38], [39, 44], [45, 47], [48, 56], [57, 59], [60, 68], [69, 71], [72, 75], [76, 83], [84, 92], [93, 102], [102, 103], [104, 113], [114, 125], [126, 137], [137, 138]]}
{"doc_key": "ai-test-270", "ner": [[3, 3, "university"], [5, 5, "researcher"], [11, 12, "researcher"], [22, 22, "product"], [18, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 5, 3, 3, "physical", "", false, false], [5, 5, 3, 3, "role", "", false, false], [22, 22, 11, 12, "origin", "", false, false], [22, 22, 18, 21, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "studying", "at", "Stanford", ",", "Scheinman", "won", "a", "scholarship", "sponsored", "by", "George", "Devol", ",", "inventor", "of", "the", "first", "industrial", "robot", ",", "the", "Unimate", "."], "sentence-detokenized": "While studying at Stanford, Scheinman won a scholarship sponsored by George Devol, inventor of the first industrial robot, the Unimate.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [26, 27], [28, 37], [38, 41], [42, 43], [44, 55], [56, 65], [66, 68], [69, 75], [76, 81], [81, 82], [83, 91], [92, 94], [95, 98], [99, 104], [105, 115], [116, 121], [121, 122], [123, 126], [127, 134], [134, 135]]}
{"doc_key": "ai-test-271", "ner": [[4, 6, "task"], [8, 11, "metrics"], [13, 15, "metrics"], [20, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 8, 11, "usage", "", true, false], [13, 15, 8, 11, "named", "", false, false], [20, 24, 8, 11, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Although", "originally", "used", "to", "evaluate", "machine", "translations", ",", "the", "bilingual", "evaluation", "inadequacy", "(", "BLEU", ")", "has", "also", "been", "successfully", "used", "to", "evaluate", "paraphrase", "production", "models", "."], "sentence-detokenized": "Although originally used to evaluate machine translations, the bilingual evaluation inadequacy (BLEU) has also been successfully used to evaluate paraphrase production models.", "token2charspan": [[0, 8], [9, 19], [20, 24], [25, 27], [28, 36], [37, 44], [45, 57], [57, 58], [59, 62], [63, 72], [73, 83], [84, 94], [95, 96], [96, 100], [100, 101], [102, 105], [106, 110], [111, 115], [116, 128], [129, 133], [134, 136], [137, 145], [146, 156], [157, 167], [168, 174], [174, 175]]}
{"doc_key": "ai-test-272", "ner": [[0, 1, "organisation"], [6, 8, "organisation"], [5, 10, "organisation"], [13, 13, "product"], [15, 15, "country"], [17, 18, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 6, 8, "role", "licenses_to", false, false], [0, 1, 5, 10, "role", "licenses_to", false, false], [6, 8, 15, 15, "physical", "", false, false], [5, 10, 17, 18, "physical", "", false, false], [13, 13, 6, 8, "artifact", "produces", false, false], [13, 13, 5, 10, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Unimation", "later", "licensed", "its", "technology", "to", "Kawasaki", "Heavy", "Industries", "and", "GKN", ",", "producing", "Unimates", "in", "Japan", "and", "the", "UK", "respectively", "."], "sentence-detokenized": "Unimation later licensed its technology to Kawasaki Heavy Industries and GKN, producing Unimates in Japan and the UK respectively.", "token2charspan": [[0, 9], [10, 15], [16, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 57], [58, 68], [69, 72], [73, 76], [76, 77], [78, 87], [88, 96], [97, 99], [100, 105], [106, 109], [110, 113], [114, 116], [117, 129], [129, 130]]}
{"doc_key": "ai-test-273", "ner": [[19, 20, "conference"], [36, 38, "field"], [52, 57, "field"], [59, 59, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[36, 38, 52, 57, "compare", "", false, false], [59, 59, 52, 57, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Much", "of", "the", "confusion", "between", "these", "two", "research", "communities", "(", "which", "often", "have", "separate", "conferences", "and", "separate", "journals", ",", "ECML", "PKDD", "being", "a", "notable", "exception", ")", "stems", "from", "the", "underlying", "assumptions", "under", "which", "they", "operate", ":", "in", "machine", "learning", "performance", "is", "usually", "judged", "by", "the", "ability", "to", "reproduce", "known", "knowledge", ",", "while", "in", "knowledge", "discovery", "and", "data", "mining", "(", "KDD", ")", "the", "main", "task", "is", "the", "discovery", "of", "previously", "unknown", "knowledge", "."], "sentence-detokenized": "Much of the confusion between these two research communities (which often have separate conferences and separate journals, ECML PKDD being a notable exception) stems from the underlying assumptions under which they operate: in machine learning performance is usually judged by the ability to reproduce known knowledge, while in knowledge discovery and data mining (KDD) the main task is the discovery of previously unknown knowledge.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 29], [30, 35], [36, 39], [40, 48], [49, 60], [61, 62], [62, 67], [68, 73], [74, 78], [79, 87], [88, 99], [100, 103], [104, 112], [113, 121], [121, 122], [123, 127], [128, 132], [133, 138], [139, 140], [141, 148], [149, 158], [158, 159], [160, 165], [166, 170], [171, 174], [175, 185], [186, 197], [198, 203], [204, 209], [210, 214], [215, 222], [222, 223], [224, 226], [227, 234], [235, 243], [244, 255], [256, 258], [259, 266], [267, 273], [274, 276], [277, 280], [281, 288], [289, 291], [292, 301], [302, 307], [308, 317], [317, 318], [319, 324], [325, 327], [328, 337], [338, 347], [348, 351], [352, 356], [357, 363], [364, 365], [365, 368], [368, 369], [370, 373], [374, 378], [379, 383], [384, 386], [387, 390], [391, 400], [401, 403], [404, 414], [415, 422], [423, 432], [432, 433]]}
{"doc_key": "ai-test-274", "ner": [[0, 1, "algorithm"], [9, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 9, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Hidden", "Markov", "models", "form", "the", "basis", "of", "most", "modern", "automatic", "speech", "recognition", "systems", "."], "sentence-detokenized": "Hidden Markov models form the basis of most modern automatic speech recognition systems.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 25], [26, 29], [30, 35], [36, 38], [39, 43], [44, 50], [51, 60], [61, 67], [68, 79], [80, 87], [87, 88]]}
{"doc_key": "ai-test-275", "ner": [[3, 3, "location"], [5, 5, "country"], [10, 11, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 5, 5, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "company", "in", "Bangalore", ",", "India", ",", "specialising", "in", "online", "handwriting", "recognition", "software", "."], "sentence-detokenized": "A company in Bangalore, India, specialising in online handwriting recognition software.", "token2charspan": [[0, 1], [2, 9], [10, 12], [13, 22], [22, 23], [24, 29], [29, 30], [31, 43], [44, 46], [47, 53], [54, 65], [66, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-276", "ner": [[24, 25, "misc"], [47, 47, "metrics"], [49, 51, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[47, 47, 49, 51, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Do", "repeated", "translations", "converge", "to", "a", "single", "expression", "in", "both", "languages", "?", "That", "is", ",", "does", "the", "translation", "method", "show", "stasis", "or", "produce", "a", "canonical", "form", "?", "Does", "the", "translation", "stabilise", "without", "losing", "its", "original", "meaning", "?", "This", "metric", "has", "been", "criticised", "for", "not", "correlating", "well", "with", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "scores", "."], "sentence-detokenized": "Do repeated translations converge to a single expression in both languages? That is, does the translation method show stasis or produce a canonical form? Does the translation stabilise without losing its original meaning? This metric has been criticised for not correlating well with BLEU (BiLingual Evaluation Understudy) scores.", "token2charspan": [[0, 2], [3, 11], [12, 24], [25, 33], [34, 36], [37, 38], [39, 45], [46, 56], [57, 59], [60, 64], [65, 74], [74, 75], [76, 80], [81, 83], [83, 84], [85, 89], [90, 93], [94, 105], [106, 112], [113, 117], [118, 124], [125, 127], [128, 135], [136, 137], [138, 147], [148, 152], [152, 153], [154, 158], [159, 162], [163, 174], [175, 184], [185, 192], [193, 199], [200, 203], [204, 212], [213, 220], [220, 221], [222, 226], [227, 233], [234, 237], [238, 242], [243, 253], [254, 257], [258, 261], [262, 273], [274, 278], [279, 283], [284, 288], [289, 290], [290, 299], [300, 310], [311, 321], [321, 322], [323, 329], [329, 330]]}
{"doc_key": "ai-test-277", "ner": [[4, 9, "organisation"], [15, 20, "organisation"], [11, 12, "university"], [22, 22, "university"], [25, 26, "field"], [13, 32, "organisation"], [33, 36, "organisation"], [44, 47, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[15, 20, 11, 12, "part-of", "", false, false], [22, 22, 25, 26, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "holds", "fellowships", "from", "the", "American", "Association", "for", "Artificial", "Intelligence", ",", "Stanford", "University", "Centre", "for", "Advanced", "Study", "in", "the", "Behavioural", "Sciences", ",", "MIT", "Centre", "for", "Cognitive", "Science", ",", "Canadian", "Institute", "for", "Advanced", "Study", ",", "Canadian", "Psychological", "Association", ",", "and", "was", "elected", "a", "Fellow", "of", "the", "Royal", "Society", "of", "Canada", "in", "1998", "."], "sentence-detokenized": "He holds fellowships from the American Association for Artificial Intelligence, Stanford University Centre for Advanced Study in the Behavioural Sciences, MIT Centre for Cognitive Science, Canadian Institute for Advanced Study, Canadian Psychological Association, and was elected a Fellow of the Royal Society of Canada in 1998.", "token2charspan": [[0, 2], [3, 8], [9, 20], [21, 25], [26, 29], [30, 38], [39, 50], [51, 54], [55, 65], [66, 78], [78, 79], [80, 88], [89, 99], [100, 106], [107, 110], [111, 119], [120, 125], [126, 128], [129, 132], [133, 144], [145, 153], [153, 154], [155, 158], [159, 165], [166, 169], [170, 179], [180, 187], [187, 188], [189, 197], [198, 207], [208, 211], [212, 220], [221, 226], [226, 227], [228, 236], [237, 250], [251, 262], [262, 263], [264, 267], [268, 271], [272, 279], [280, 281], [282, 288], [289, 291], [292, 295], [296, 301], [302, 309], [310, 312], [313, 319], [320, 322], [323, 327], [327, 328]]}
{"doc_key": "ai-test-278", "ner": [[0, 0, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [16, 20, "misc"], [22, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 16, 20, "part-of", "", false, false], [0, 0, 22, 23, "part-of", "", false, false], [4, 5, 16, 20, "part-of", "", false, false], [4, 5, 22, 23, "part-of", "", false, false], [7, 8, 16, 20, "part-of", "", false, false], [7, 8, 22, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Hinton", "-", "along", "with", "Yoshua", "Bengio", "and", "Yann", "LeCun", "-", "are", "referred", "to", "by", "some", "as", "the", "godfathers", "of", "artificial", "intelligence", "and", "deep", "learning", "."], "sentence-detokenized": "Hinton - along with Yoshua Bengio and Yann LeCun - are referred to by some as the godfathers of artificial intelligence and deep learning.", "token2charspan": [[0, 6], [7, 8], [9, 14], [15, 19], [20, 26], [27, 33], [34, 37], [38, 42], [43, 48], [49, 50], [51, 54], [55, 63], [64, 66], [67, 69], [70, 74], [75, 77], [78, 81], [82, 92], [93, 95], [96, 106], [107, 119], [120, 123], [124, 128], [129, 137], [137, 138]]}
{"doc_key": "ai-test-279", "ner": [[6, 8, "product"], [18, 18, "misc"], [20, 20, "misc"], [22, 23, "product"], [26, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 8, 18, 18, "related-to", "", false, false], [6, 8, 20, 20, "related-to", "", false, false], [18, 18, 22, 23, "named", "same", false, false], [26, 27, 22, 23, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "lightweight", "open", "source", "speech", "project", "eSpeak", ",", "which", "has", "its", "own", "synthesis", "approach", ",", "has", "experimented", "with", "Mandarin", "and", "Cantonese", ".", "eSpeak", "was", "used", "by", "Google", "Translate", "from", "May", "2010", "to", "2010", "."], "sentence-detokenized": "The lightweight open source speech project eSpeak, which has its own synthesis approach, has experimented with Mandarin and Cantonese. eSpeak was used by Google Translate from May 2010 to 2010.", "token2charspan": [[0, 3], [4, 15], [16, 20], [21, 27], [28, 34], [35, 42], [43, 49], [49, 50], [51, 56], [57, 60], [61, 64], [65, 68], [69, 78], [79, 87], [87, 88], [89, 92], [93, 105], [106, 110], [111, 119], [120, 123], [124, 133], [133, 134], [135, 141], [142, 145], [146, 150], [151, 153], [154, 160], [161, 170], [171, 175], [176, 179], [180, 184], [185, 187], [188, 192], [192, 193]]}
{"doc_key": "ai-test-280", "ner": [[5, 8, "product"], [15, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 8, 15, 16, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Also", "released", "in", "1982", ",", "Software", "Automatic", "Mouth", "was", "the", "first", "commercial", "fully", "software", "voice", "synthesis", "programme", "."], "sentence-detokenized": "Also released in 1982, Software Automatic Mouth was the first commercial fully software voice synthesis programme.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 21], [21, 22], [23, 31], [32, 41], [42, 47], [48, 51], [52, 55], [56, 61], [62, 72], [73, 78], [79, 87], [88, 93], [94, 103], [104, 113], [113, 114]]}
{"doc_key": "ai-test-281", "ner": [[2, 4, "metrics"], [6, 6, "metrics"], [10, 10, "metrics"], [12, 12, "metrics"], [15, 24, "metrics"], [28, 29, "metrics"], [31, 31, "metrics"], [37, 41, "metrics"], [44, 46, "metrics"], [48, 48, "metrics"], [51, 51, "metrics"], [53, 53, "metrics"], [59, 63, "metrics"], [69, 70, "metrics"], [72, 72, "metrics"], [75, 82, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[6, 6, 2, 4, "named", "", false, false], [10, 10, 2, 4, "named", "", false, false], [12, 12, 2, 4, "named", "", false, false], [15, 24, 2, 4, "named", "", false, false], [31, 31, 28, 29, "named", "", false, false], [37, 41, 28, 29, "named", "", false, false], [48, 48, 44, 46, "named", "", false, false], [51, 51, 44, 46, "named", "", false, false], [53, 53, 44, 46, "named", "", false, false], [59, 63, 44, 46, "named", "", false, false], [72, 72, 69, 70, "named", "", false, false], [75, 82, 69, 70, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Column", "rates", "TRUE", "Positive", "Rate", "(", "TPR", ",", "a.k.a", ".", "Sensitivity", "or", "recall", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "with", "its", "complement", "FALSE", "Negative", "Rate", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ";", "and", "TRUE", "Negative", "Rate", "(", "TNR", ",", "a.k.a.", "Specificity", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", ",", "with", "its", "complement", "FALSE", "Positive", "Rate", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "Column rates TRUE Positive Rate (TPR, a.k.a. Sensitivity or recall) (TP/(TP+FN)), with its complement FALSE Negative Rate (FNR) (FN/(TP+FN)); and TRUE Negative Rate (TNR, a.k.a. Specificity, SPC) (TN/(TN+FP)), with its complement FALSE Positive Rate (FPR) (FP/(TN+FP)).", "token2charspan": [[0, 6], [7, 12], [13, 17], [18, 26], [27, 31], [32, 33], [33, 36], [36, 37], [38, 43], [43, 44], [45, 56], [57, 59], [60, 66], [66, 67], [68, 69], [69, 71], [71, 72], [72, 73], [73, 75], [75, 76], [76, 78], [78, 79], [79, 80], [80, 81], [82, 86], [87, 90], [91, 101], [102, 107], [108, 116], [117, 121], [122, 123], [123, 126], [126, 127], [128, 129], [129, 131], [131, 132], [132, 133], [133, 135], [135, 136], [136, 138], [138, 139], [139, 140], [140, 141], [142, 145], [146, 150], [151, 159], [160, 164], [165, 166], [166, 169], [169, 170], [171, 177], [178, 189], [189, 190], [191, 194], [194, 195], [196, 197], [197, 199], [199, 200], [200, 201], [201, 203], [203, 204], [204, 206], [206, 207], [207, 208], [208, 209], [210, 214], [215, 218], [219, 229], [230, 235], [236, 244], [245, 249], [250, 251], [251, 254], [254, 255], [256, 257], [257, 259], [259, 260], [260, 261], [261, 263], [263, 264], [264, 266], [266, 267], [267, 268], [268, 269]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 2, "person"], [14, 14, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 14, 14, "role", "working_with", false, false], [2, 2, 14, 14, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "and", "Weber", "have", "collaborated", "on", "many", "other", "robots", "and", "their", "experience", "working", "with", "Kismet"], "sentence-detokenized": "Edsinger and Weber have collaborated on many other robots and their experience working with Kismet", "token2charspan": [[0, 8], [9, 12], [13, 18], [19, 23], [24, 36], [37, 39], [40, 44], [45, 50], [51, 57], [58, 61], [62, 67], [68, 78], [79, 86], [87, 91], [92, 98]]}
{"doc_key": "ai-test-283", "ner": [[0, 0, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 11, 11, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["R", "functionality", "is", "also", "accessible", "from", "various", "scripting", "languages", "such", "as", "Python", "."], "sentence-detokenized": "R functionality is also accessible from various scripting languages such as Python.", "token2charspan": [[0, 1], [2, 15], [16, 18], [19, 23], [24, 34], [35, 39], [40, 47], [48, 57], [58, 67], [68, 72], [73, 75], [76, 82], [82, 83]]}
{"doc_key": "ai-test-284", "ner": [[0, 0, "programlang"], [11, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 13, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "was", "one", "of", "the", "first", "robot", "languages", "and", "was", "used", "in", "Unimate", "robots", "."], "sentence-detokenized": "VAL was one of the first robot languages and was used in Unimate robots.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 18], [19, 24], [25, 30], [31, 40], [41, 44], [45, 48], [49, 53], [54, 56], [57, 64], [65, 71], [71, 72]]}
{"doc_key": "ai-test-285", "ner": [[10, 17, "conference"], [19, 19, "conference"], [21, 22, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 17, 21, 22, "physical", "", false, false], [19, 19, 10, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["They", "first", "presented", "their", "database", "as", "a", "poster", "at", "the", "2009", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "in", "Florida", "."], "sentence-detokenized": "They first presented their database as a poster at the 2009 Conference on Computer Vision and Pattern Recognition (CVPR) in Florida.", "token2charspan": [[0, 4], [5, 10], [11, 20], [21, 26], [27, 35], [36, 38], [39, 40], [41, 47], [48, 50], [51, 54], [55, 59], [60, 70], [71, 73], [74, 82], [83, 89], [90, 93], [94, 101], [102, 113], [114, 115], [115, 119], [119, 120], [121, 123], [124, 131], [131, 132]]}
{"doc_key": "ai-test-286", "ner": [[0, 9, "misc"], [10, 10, "task"], [13, 13, "field"], [7, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 0, 9, "type-of", "", false, false], [13, 13, 0, 9, "type-of", "", false, false], [7, 16, 0, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Categorisation", "tasks", "where", "no", "labels", "are", "provided", "are", "called", "unsupervised", "classification", ",", "unsupervised", "learning", ",", "Cluster", "analysis", "."], "sentence-detokenized": "Categorisation tasks where no labels are provided are called unsupervised classification, unsupervised learning, Cluster analysis.", "token2charspan": [[0, 14], [15, 20], [21, 26], [27, 29], [30, 36], [37, 40], [41, 49], [50, 53], [54, 60], [61, 73], [74, 88], [88, 89], [90, 102], [103, 111], [111, 112], [113, 120], [121, 129], [129, 130]]}
{"doc_key": "ai-test-287", "ner": [[5, 6, "task"], [14, 15, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "is", "a", "need", "for", "object", "recognition", ",", "people", "recognition", "and", "positioning", "and", "further", "emotion", "recognition", "."], "sentence-detokenized": "There is a need for object recognition, people recognition and positioning and further emotion recognition.", "token2charspan": [[0, 5], [6, 8], [9, 10], [11, 15], [16, 19], [20, 26], [27, 38], [38, 39], [40, 46], [47, 58], [59, 62], [63, 74], [75, 78], [79, 86], [87, 94], [95, 106], [106, 107]]}
{"doc_key": "ai-test-288", "ner": [[6, 6, "misc"], [8, 10, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "process", "is", "complex", "and", "involves", "encoding", "and", "remembering", "or", "recalling", "."], "sentence-detokenized": "The process is complex and involves encoding and remembering or recalling.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 26], [27, 35], [36, 44], [45, 48], [49, 60], [61, 63], [64, 73], [73, 74]]}
{"doc_key": "ai-test-289", "ner": [[10, 11, "product"], [13, 16, "product"], [32, 54, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 13, 16, "named", "", false, false], [10, 11, 32, 54, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "also", "known", "as", "parallel", "robots", "or", "generalised", "Stewart", "platforms", "(", "in", "a", "Stewart", "platform", ",", "actuators", "are", "paired", "together", "at", "both", "the", "base", "and", "the", "platform", ")", ",", "are", "articulated", "robots", "that", "use", "similar", "mechanisms", "for", "the", "motion", "of", "either", "the", "robot", "at", "it", "s", "base", "or", "one", "or", "more", "manipulator", "arms", "."], "sentence-detokenized": "These systems, also known as parallel robots or generalised Stewart platforms (in a Stewart platform, actuators are paired together at both the base and the platform), are articulated robots that use similar mechanisms for the motion of either the robot at its base or one or more manipulator arms.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 25], [26, 28], [29, 37], [38, 44], [45, 47], [48, 59], [60, 67], [68, 77], [78, 79], [79, 81], [82, 83], [84, 91], [92, 100], [100, 101], [102, 111], [112, 115], [116, 122], [123, 131], [132, 134], [135, 139], [140, 143], [144, 148], [149, 152], [153, 156], [157, 165], [165, 166], [166, 167], [168, 171], [172, 183], [184, 190], [191, 195], [196, 199], [200, 207], [208, 218], [219, 222], [223, 226], [227, 233], [234, 236], [237, 243], [244, 247], [248, 253], [254, 256], [257, 259], [259, 260], [261, 265], [266, 268], [269, 272], [273, 275], [276, 280], [281, 292], [293, 297], [297, 298]]}
{"doc_key": "ai-test-290", "ner": [[1, 15, "field"], [4, 5, "field"], [18, 18, "field"], [19, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 15, 4, 5, "part-of", "subfield", false, false], [1, 15, 18, 18, "compare", "", false, false], [18, 18, 19, 19, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "vision", "as", "a", "systems", "engineering", "discipline", "can", "be", "considered", "separately", "from", "computer", "vision", "as", "a", "type", "of", "computer", "science", "."], "sentence-detokenized": "Machine vision as a systems engineering discipline can be considered separately from computer vision as a type of computer science.", "token2charspan": [[0, 7], [8, 14], [15, 17], [18, 19], [20, 27], [28, 39], [40, 50], [51, 54], [55, 57], [58, 68], [69, 79], [80, 84], [85, 93], [94, 100], [101, 103], [104, 105], [106, 110], [111, 113], [114, 122], [123, 130], [130, 131]]}
{"doc_key": "ai-test-291", "ner": [[3, 6, "algorithm"], [9, 10, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 6, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "activation", "function", "of", "LSTM", "gates", "is", "usually", "a", "logistic", "sigmoid", "function", "."], "sentence-detokenized": "The activation function of LSTM gates is usually a logistic sigmoid function.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 26], [27, 31], [32, 37], [38, 40], [41, 48], [49, 50], [51, 59], [60, 67], [68, 76], [76, 77]]}
{"doc_key": "ai-test-292", "ner": [[4, 6, "metrics"], [26, 29, "metrics"], [31, 31, "metrics"], [19, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 26, 29, "named", "", false, false], [4, 6, 19, 25, "named", "", false, false], [31, 31, 26, 29, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "other", "words", ",", "the", "sample", "mean", "is", "the", "(", "necessarily", "unique", ")", "efficient", "estimator", "and", "is", "therefore", "a", "maximum", "likelihood", "estimator", "as", "well", "as", "a", "minimum", "variance", "unbiased", "estimator", "(", "MVUE", ")", "."], "sentence-detokenized": "In other words, the sample mean is the (necessarily unique) efficient estimator and is therefore a maximum likelihood estimator as well as a minimum variance unbiased estimator (MVUE).", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 19], [20, 26], [27, 31], [32, 34], [35, 38], [39, 40], [40, 51], [52, 58], [58, 59], [60, 69], [70, 79], [80, 83], [84, 86], [87, 96], [97, 98], [99, 106], [107, 117], [118, 127], [128, 130], [131, 135], [136, 138], [139, 140], [141, 148], [149, 157], [158, 166], [167, 176], [177, 178], [178, 182], [182, 183], [183, 184]]}
{"doc_key": "ai-test-293", "ner": [[2, 3, "academicjournal"], [6, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [21, 21, "product"], [23, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 21, 21, "topic", "", false, false], [2, 3, 23, 25, "topic", "", false, false], [6, 8, 2, 3, "role", "", false, false], [10, 11, 2, 3, "role", "", false, false], [13, 14, 2, 3, "role", "", false, false], [21, 21, 23, 25, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["A", "2001", "Scientific", "American", "article", "by", "Berners", "-", "Lee", ",", "James", "Hendler", "and", "Ora", "Lassila", "predicts", "the", "evolution", "of", "the", "current", "Web", "towards", "the", "Semantic", "Web", "."], "sentence-detokenized": "A 2001 Scientific American article by Berners-Lee, James Hendler and Ora Lassila predicts the evolution of the current Web towards the Semantic Web.", "token2charspan": [[0, 1], [2, 6], [7, 17], [18, 26], [27, 34], [35, 37], [38, 45], [45, 46], [46, 49], [49, 50], [51, 56], [57, 64], [65, 68], [69, 72], [73, 80], [81, 89], [90, 93], [94, 103], [104, 106], [107, 110], [111, 118], [119, 122], [123, 130], [131, 134], [135, 143], [144, 147], [147, 148]]}
{"doc_key": "ai-test-294", "ner": [[0, 1, "misc"], [17, 18, "person"], [19, 20, "person"], [29, 31, "person"], [44, 44, "person"], [50, 54, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[17, 18, 0, 1, "role", "actor_in_work", false, false], [19, 20, 17, 18, "named", "", false, false], [19, 20, 17, 18, "origin", "", false, false], [29, 31, 19, 20, "part-of", "", false, false], [50, 54, 19, 20, "role", "auditioned_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Blade", "Runner", "used", "a", "number", "of", "actors", "who", "were", "less", "well", "-", "known", "at", "the", "time", ":", "Sean", "Young", "plays", "Rachael", ",", "an", "experimental", "replicant", "into", "which", "the", "memories", "of", "Tyrell", "'s", "niece", "are", "implanted", ",", "causing", "her", "to", "believe", "she", "is", "human", ";", "Sammon", ",", "pp.", "92", "-", "93", "Nina", "Axelrod", "auditioned", "for", "this", "role", "."], "sentence-detokenized": "Blade Runner used a number of actors who were less well-known at the time: Sean Young plays Rachael, an experimental replicant into which the memories of Tyrell's niece are implanted, causing her to believe she is human; Sammon, pp. 92-93 Nina Axelrod auditioned for this role.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 19], [20, 26], [27, 29], [30, 36], [37, 40], [41, 45], [46, 50], [51, 55], [55, 56], [56, 61], [62, 64], [65, 68], [69, 73], [73, 74], [75, 79], [80, 85], [86, 91], [92, 99], [99, 100], [101, 103], [104, 116], [117, 126], [127, 131], [132, 137], [138, 141], [142, 150], [151, 153], [154, 160], [160, 162], [163, 168], [169, 172], [173, 182], [182, 183], [184, 191], [192, 195], [196, 198], [199, 206], [207, 210], [211, 213], [214, 219], [219, 220], [221, 227], [227, 228], [229, 232], [233, 235], [235, 236], [236, 238], [239, 243], [244, 251], [252, 262], [263, 266], [267, 271], [272, 276], [276, 277]]}
{"doc_key": "ai-test-295", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [12, 15, "university"], [23, 26, "product"], [27, 27, "product"], [44, 44, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 12, 15, "physical", "", false, false], [3, 4, 12, 15, "physical", "", false, false], [6, 7, 12, 15, "physical", "", false, false], [9, 10, 12, 15, "physical", "", false, false], [12, 15, 44, 44, "physical", "", true, false], [23, 26, 12, 15, "temporal", "", false, false], [27, 27, 12, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Gerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "and", "Terry", "Winograd", "visited", "the", "University", "of", "Edinburgh", "in", "1971", "to", "spread", "the", "news", "about", "Micro", "-", "Planner", "and", "SHRDLU", "and", "to", "cast", "doubt", "on", "the", "uniform", "proof", "procedure", "approach", "that", "was", "the", "mainstay", "of", "the", "Edinburgh", "Logicians", "."], "sentence-detokenized": "Gerry Sussman, Eugene Charniak, Seymour Papert and Terry Winograd visited the University of Edinburgh in 1971 to spread the news about Micro-Planner and SHRDLU and to cast doubt on the uniform proof procedure approach that was the mainstay of the Edinburgh Logicians.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 21], [22, 30], [30, 31], [32, 39], [40, 46], [47, 50], [51, 56], [57, 65], [66, 73], [74, 77], [78, 88], [89, 91], [92, 101], [102, 104], [105, 109], [110, 112], [113, 119], [120, 123], [124, 128], [129, 134], [135, 140], [140, 141], [141, 148], [149, 152], [153, 159], [160, 163], [164, 166], [167, 171], [172, 177], [178, 180], [181, 184], [185, 192], [193, 198], [199, 208], [209, 217], [218, 222], [223, 226], [227, 230], [231, 239], [240, 242], [243, 246], [247, 256], [257, 266], [266, 267]]}
{"doc_key": "ai-test-296", "ner": [[0, 0, "researcher"], [8, 8, "field"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 12, 13, "role", "inspires", false, false], [0, 0, 15, 16, "role", "inspires", false, false], [0, 0, 18, 19, "role", "inspires", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Walter", "'s", "work", "inspired", "the", "next", "generation", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "Walter's work inspired the next generation of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 6], [6, 8], [9, 13], [14, 22], [23, 26], [27, 31], [32, 42], [43, 45], [46, 54], [55, 66], [67, 71], [72, 74], [75, 81], [82, 88], [88, 89], [90, 94], [95, 102], [103, 106], [107, 111], [112, 118], [118, 119]]}
{"doc_key": "ai-test-297", "ner": [[7, 7, "algorithm"], [8, 12, "researcher"], [16, 22, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 8, 12, "origin", "", false, false], [7, 7, 16, 22, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Later", ",", "a", "similar", "GPU", "-", "based", "CNN", "by", "Alex", "Krizhevsky", "et", "al", ".", "won", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "2012", "."], "sentence-detokenized": "Later, a similar GPU-based CNN by Alex Krizhevsky et al. won the ImageNet Large Scale Visual Recognition Challenge 2012.", "token2charspan": [[0, 5], [5, 6], [7, 8], [9, 16], [17, 20], [20, 21], [21, 26], [27, 30], [31, 33], [34, 38], [39, 49], [50, 52], [53, 55], [55, 56], [57, 60], [61, 64], [65, 73], [74, 79], [80, 85], [86, 92], [93, 104], [105, 114], [115, 119], [119, 120]]}
{"doc_key": "ai-test-298", "ner": [[0, 1, "misc"], [9, 10, "metrics"], [13, 20, "metrics"], [18, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[9, 10, 0, 1, "type-of", "", false, false], [13, 20, 0, 1, "type-of", "", false, false], [13, 20, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Loss", "functions", "commonly", "used", "for", "probabilistic", "classification", "include", "the", "log", "loss", "and", "the", "Brier", "score", "between", "predicted", "and", "TRUE", "probability", "distributions", "."], "sentence-detokenized": "Loss functions commonly used for probabilistic classification include the log loss and the Brier score between predicted and TRUE probability distributions.", "token2charspan": [[0, 4], [5, 14], [15, 23], [24, 28], [29, 32], [33, 46], [47, 61], [62, 69], [70, 73], [74, 77], [78, 82], [83, 86], [87, 90], [91, 96], [97, 102], [103, 110], [111, 120], [121, 124], [125, 129], [130, 141], [142, 155], [155, 156]]}
{"doc_key": "ai-test-299", "ner": [[4, 4, "organisation"], [17, 17, "field"], [12, 13, "organisation"], [8, 9, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 17, 17, "general-affiliation", "field_of_study", false, false], [4, 4, 8, 9, "part-of", "", false, false], [12, 13, 4, 4, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "May", "2016", ",", "NtechLab", "was", "among", "three", "Russian", "companies", "accepted", "by", "NIST", "for", "official", "testing", "of", "biometrics", "technology", "."], "sentence-detokenized": "In May 2016, NtechLab was among three Russian companies accepted by NIST for official testing of biometrics technology.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [13, 21], [22, 25], [26, 31], [32, 37], [38, 45], [46, 55], [56, 64], [65, 67], [68, 72], [73, 76], [77, 85], [86, 93], [94, 96], [97, 107], [108, 118], [118, 119]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "floating", "-", "point", "numbers", "only", "have", "a", "certain", "amount", "of", "mathematical", "precision", "."], "sentence-detokenized": "However, floating-point numbers only have a certain amount of mathematical precision.", "token2charspan": [[0, 7], [7, 8], [9, 17], [17, 18], [18, 23], [24, 31], [32, 36], [37, 41], [42, 43], [44, 51], [52, 58], [59, 61], [62, 74], [75, 84], [84, 85]]}
{"doc_key": "ai-test-301", "ner": [[10, 16, "conference"], [18, 18, "conference"]], "ner_mapping_to_source": [1, 2], "relations": [[18, 18, 10, 16, "named", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["During", "2015", ",", "several", "SenseTime", "papers", "were", "accepted", "to", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "During 2015, several SenseTime papers were accepted to the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 6], [7, 11], [11, 12], [13, 20], [21, 30], [31, 37], [38, 42], [43, 51], [52, 54], [55, 58], [59, 69], [70, 72], [73, 81], [82, 88], [89, 92], [93, 100], [101, 112], [113, 114], [114, 118], [118, 119], [119, 120]]}
{"doc_key": "ai-test-302", "ner": [[6, 8, "task"], [10, 10, "task"], [12, 13, "task"], [15, 18, "task"], [20, 21, "field"], [23, 35, "misc"], [26, 35, "conference"], [42, 49, "misc"], [47, 47, "conference"], [63, 68, "misc"], [67, 67, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[6, 8, 20, 21, "part-of", "task_part_of_field", false, false], [10, 10, 6, 8, "named", "", false, false], [12, 13, 20, 21, "part-of", "task_part_of_field", false, false], [15, 18, 12, 13, "named", "", false, false], [23, 35, 26, 35, "temporal", "", false, false], [42, 49, 47, 47, "temporal", "", false, false], [63, 68, 67, 67, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["He", "has", "co-developed", "optimal", "algorithms", "for", "Structure", "from", "Motion", "(", "SFM", "or", "Visual", "SLAM", ",", "simultaneous", "localisation", "and", "mapping", ",", "in", "Robotics", ";", "Best", "Paper", "Award", "at", "the", "1998", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ")", ",", "characterised", "their", "uncertainty", "(", "David", "Marr", "Award", "at", "ICCV", "1999", ")", "and", "also", "characterised", "the", "identifiability", "and", "observability", "of", "visual", "-", "inertial", "sensor", "fusion", "(", "Best", "Paper", "Award", "at", "Robotics", "2015", ")", "."], "sentence-detokenized": "He has co-developed optimal algorithms for Structure from Motion (SFM or Visual SLAM, simultaneous localisation and mapping, in Robotics; Best Paper Award at the 1998 Conference on Computer Vision and Pattern Recognition), characterised their uncertainty (David Marr Award at ICCV 1999) and also characterised the identifiability and observability of visual-inertial sensor fusion (Best Paper Award at Robotics 2015).", "token2charspan": [[0, 2], [3, 6], [7, 19], [20, 27], [28, 38], [39, 42], [43, 52], [53, 57], [58, 64], [65, 66], [66, 69], [70, 72], [73, 79], [80, 84], [84, 85], [86, 98], [99, 111], [112, 115], [116, 123], [123, 124], [125, 127], [128, 136], [136, 137], [138, 142], [143, 148], [149, 154], [155, 157], [158, 161], [162, 166], [167, 177], [178, 180], [181, 189], [190, 196], [197, 200], [201, 208], [209, 220], [220, 221], [221, 222], [223, 236], [237, 242], [243, 254], [255, 256], [256, 261], [262, 266], [267, 272], [273, 275], [276, 280], [281, 285], [285, 286], [287, 290], [291, 295], [296, 309], [310, 313], [314, 329], [330, 333], [334, 347], [348, 350], [351, 357], [357, 358], [358, 366], [367, 373], [374, 380], [381, 382], [382, 386], [387, 392], [393, 398], [399, 401], [402, 410], [411, 415], [415, 416], [416, 417]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Association", "for", "the", "Development", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Association for the Development of Artificial Intelligence,", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 44], [45, 48], [49, 52], [53, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-304", "ner": [[0, 1, "task"], [7, 8, "field"], [10, 11, "field"], [13, 14, "field"], [21, 22, "task"], [24, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 7, 8, "part-of", "task_part_of_field", false, false], [0, 1, 10, 11, "part-of", "task_part_of_field", false, false], [0, 1, 13, 14, "part-of", "task_part_of_field", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 24, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Edge", "detection", "is", "a", "fundamental", "tool", "in", "image", "processing", ",", "machine", "vision", "and", "computer", "vision", ",", "especially", "in", "the", "areas", "of", "feature", "detection", "and", "feature", "extraction", "."], "sentence-detokenized": "Edge detection is a fundamental tool in image processing, machine vision and computer vision, especially in the areas of feature detection and feature extraction.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 19], [20, 31], [32, 36], [37, 39], [40, 45], [46, 56], [56, 57], [58, 65], [66, 72], [73, 76], [77, 85], [86, 92], [92, 93], [94, 104], [105, 107], [108, 111], [112, 117], [118, 120], [121, 128], [129, 138], [139, 142], [143, 150], [151, 161], [161, 162]]}
{"doc_key": "ai-test-305", "ner": [[11, 12, "misc"], [34, 37, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "example", "of", "this", "would", "be", "a", "variable", "such", "as", "the", "outside", "temperature", "(", "mathtemp", "/", "math", ")", ",", "which", "in", "a", "given", "application", "(", "depending", "on", "the", "sensing", "apparatus", ")", "can", "be", "recorded", "to", "an", "accuracy", "of", "several", "decimal", "places", "."], "sentence-detokenized": "An example of this would be a variable such as the outside temperature (mathtemp/math), which in a given application (depending on the sensing apparatus) can be recorded to an accuracy of several decimal places.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 18], [19, 24], [25, 27], [28, 29], [30, 38], [39, 43], [44, 46], [47, 50], [51, 58], [59, 70], [71, 72], [72, 80], [80, 81], [81, 85], [85, 86], [86, 87], [88, 93], [94, 96], [97, 98], [99, 104], [105, 116], [117, 118], [118, 127], [128, 130], [131, 134], [135, 142], [143, 152], [152, 153], [154, 157], [158, 160], [161, 169], [170, 172], [173, 175], [176, 184], [185, 187], [188, 195], [196, 203], [204, 210], [210, 211]]}
{"doc_key": "ai-test-306", "ner": [[5, 6, "person"], [8, 9, "person"], [11, 12, "person"], [19, 20, "person"], [22, 22, "misc"], [26, 26, "misc"], [28, 29, "person"], [31, 31, "organisation"], [34, 35, "person"], [37, 37, "organisation"], [39, 40, "person"], [45, 45, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[28, 29, 22, 22, "part-of", "", false, false], [28, 29, 26, 26, "role", "", false, false], [34, 35, 31, 31, "role", "", false, false], [39, 40, 37, 37, "role", "youtuber", false, false], [45, 45, 39, 40, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "addition", "to", "returning", "judges", "Fon", "Davis", ",", "Jessica", "Chobot", "and", "Leland", "Melvin", ",", "celebrity", "guest", "judges", "include", "actor", "Clark", "Gregg", ",", "MythBusters", "host", "and", "former", "Battlebots", "founder", "Adam", "Savage", ",", "NFL", "tight", "end", "Vernon", "Davis", "and", "YouTube", "star", "Michael", "Stevens", "a.k.a", ".", "Vsauce", ".", "Vsauce", "."], "sentence-detokenized": "In addition to returning judges Fon Davis, Jessica Chobot and Leland Melvin, celebrity guest judges include actor Clark Gregg, MythBusters host and former Battlebots founder Adam Savage, NFL tight end Vernon Davis and YouTube star Michael Stevens a.k.a. Vsauce. Vsauce.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 24], [25, 31], [32, 35], [36, 41], [41, 42], [43, 50], [51, 57], [58, 61], [62, 68], [69, 75], [75, 76], [77, 86], [87, 92], [93, 99], [100, 107], [108, 113], [114, 119], [120, 125], [125, 126], [127, 138], [139, 143], [144, 147], [148, 154], [155, 165], [166, 173], [174, 178], [179, 185], [185, 186], [187, 190], [191, 196], [197, 200], [201, 207], [208, 213], [214, 217], [218, 225], [226, 230], [231, 238], [239, 246], [247, 252], [252, 253], [254, 260], [260, 261], [262, 268], [268, 269]]}
{"doc_key": "ai-test-307", "ner": [[14, 15, "algorithm"], [16, 20, "algorithm"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 15, 22, 24, "part-of", "", false, false], [16, 20, 22, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "these", "methods", "have", "never", "triumphed", "over", "the", "non-uniform", "internal", "hand", "-", "crafted", "Gaussian", "mixture", "model", "/", "Hidden", "Markov", "model", "(", "GMM", "-", "HMM", ")", "technology", "based", "on", "discriminatively", "trained", "generative", "models", "of", "speech", "."], "sentence-detokenized": "However, these methods have never triumphed over the non-uniform internal hand-crafted Gaussian mixture model/Hidden Markov model (GMM-HMM) technology based on discriminatively trained generative models of speech.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 22], [23, 27], [28, 33], [34, 43], [44, 48], [49, 52], [53, 64], [65, 73], [74, 78], [78, 79], [79, 86], [87, 95], [96, 103], [104, 109], [109, 110], [110, 116], [117, 123], [124, 129], [130, 131], [131, 134], [134, 135], [135, 138], [138, 139], [140, 150], [151, 156], [157, 159], [160, 176], [177, 184], [185, 195], [196, 202], [203, 205], [206, 212], [212, 213]]}
{"doc_key": "ai-test-308", "ner": [[4, 4, "product"], [6, 7, "programlang"], [9, 9, "programlang"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Software", "packages", "such", "as", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", "and", "SciPy", "provide", "convenient", "ways", "to", "implement", "these", "different", "methods", "."], "sentence-detokenized": "Software packages such as MATLAB, GNU Octave, Scilab and SciPy provide convenient ways to implement these different methods.", "token2charspan": [[0, 8], [9, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 37], [38, 44], [44, 45], [46, 52], [53, 56], [57, 62], [63, 70], [71, 81], [82, 86], [87, 89], [90, 99], [100, 105], [106, 115], [116, 123], [123, 124]]}
{"doc_key": "ai-test-309", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [8, 9, "task"], [18, 19, "researcher"], [20, 22, "university"], [24, 25, "researcher"], [26, 30, "organisation"], [32, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 8, 9, "related-to", "", false, false], [0, 2, 18, 19, "origin", "", false, false], [0, 2, 24, 25, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [18, 19, 20, 22, "physical", "", false, false], [18, 19, 20, 22, "role", "", false, false], [24, 25, 26, 30, "physical", "", false, false], [24, 25, 26, 30, "role", "", false, false], [32, 32, 26, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", ",", "a", "speech", "processing", "algorithm", ",", "was", "first", "proposed", "in", "1966", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "."], "sentence-detokenized": "Linear predictive coding (LPC), a speech processing algorithm, was first proposed in 1966 by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT).", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [30, 31], [32, 33], [34, 40], [41, 51], [52, 61], [61, 62], [63, 66], [67, 72], [73, 81], [82, 84], [85, 89], [90, 92], [93, 101], [102, 109], [110, 112], [113, 119], [120, 130], [131, 134], [135, 140], [141, 146], [147, 149], [150, 156], [157, 166], [167, 170], [171, 180], [181, 182], [182, 185], [185, 186], [186, 187]]}
{"doc_key": "ai-test-310", "ner": [[15, 24, "conference"], [26, 28, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[26, 28, 15, 24, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2006", ",", "for", "the", "25th", "anniversary", "of", "the", "algorithm", ",", "a", "workshop", "was", "held", "at", "the", "International", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "to", "summarise", "the", "latest", "contributions", "and", "variations", "to", "the", "original", "algorithm", ",", "mostly", "with", "the", "aim", "of", "improving", "the", "speed", "of", "the", "algorithm", ",", "the", "robustness", "and", "accuracy", "of", "the", "estimated", "solution", ",", "and", "reducing", "the", "dependence", "on", "user", "-", "defined", "constants", "."], "sentence-detokenized": "In 2006, for the 25th anniversary of the algorithm, a workshop was held at the International Conference on Computer Vision and Pattern Recognition (CVPR) to summarise the latest contributions and variations to the original algorithm, mostly with the aim of improving the speed of the algorithm, the robustness and accuracy of the estimated solution, and reducing the dependence on user-defined constants.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 21], [22, 33], [34, 36], [37, 40], [41, 50], [50, 51], [52, 53], [54, 62], [63, 66], [67, 71], [72, 74], [75, 78], [79, 92], [93, 103], [104, 106], [107, 115], [116, 122], [123, 126], [127, 134], [135, 146], [147, 148], [148, 152], [152, 153], [154, 156], [157, 166], [167, 170], [171, 177], [178, 191], [192, 195], [196, 206], [207, 209], [210, 213], [214, 222], [223, 232], [232, 233], [234, 240], [241, 245], [246, 249], [250, 253], [254, 256], [257, 266], [267, 270], [271, 276], [277, 279], [280, 283], [284, 293], [293, 294], [295, 298], [299, 309], [310, 313], [314, 322], [323, 325], [326, 329], [330, 339], [340, 348], [348, 349], [350, 353], [354, 362], [363, 366], [367, 377], [378, 380], [381, 385], [385, 386], [386, 393], [394, 403], [403, 404]]}
{"doc_key": "ai-test-311", "ner": [[4, 7, "university"], [10, 13, "organisation"], [15, 17, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "members", "went", "to", "the", "University", "of", "Debrecen", ",", "the", "Hungarian", "Academy", "of", "Sciences", ",", "E\u00f6tv\u00f6s", "Lor\u00e1nd", "University", ",", "etc", "."], "sentence-detokenized": "The members went to the University of Debrecen, the Hungarian Academy of Sciences, E\u00f6tv\u00f6s Lor\u00e1nd University, etc.", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 19], [20, 23], [24, 34], [35, 37], [38, 46], [46, 47], [48, 51], [52, 61], [62, 69], [70, 72], [73, 81], [81, 82], [83, 89], [90, 96], [97, 107], [107, 108], [109, 112], [112, 113]]}
{"doc_key": "ai-test-312", "ner": [[7, 7, "algorithm"], [2, 4, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 7, 2, 4, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["We", "introduce", "the", "loss", "function", "to", "extend", "SVM", "to", "cases", "where", "the", "data", "are", "not", "linearly", "separable", ","], "sentence-detokenized": "We introduce the loss function to extend SVM to cases where the data are not linearly separable,", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 21], [22, 30], [31, 33], [34, 40], [41, 44], [45, 47], [48, 53], [54, 59], [60, 63], [64, 68], [69, 72], [73, 76], [77, 85], [86, 95], [95, 96]]}
{"doc_key": "ai-test-313", "ner": [[0, 0, "programlang"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 10, 11, "origin", "", false, false], [0, 0, 13, 14, "origin", "", false, false], [0, 0, 16, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Logo", "is", "an", "educational", "programming", "language", "designed", "in", "1967", "by", "Wally", "Feurzeig", ",", "Seymour", "Papert", "and", "Cynthia", "Solomon", "."], "sentence-detokenized": "Logo is an educational programming language designed in 1967 by Wally Feurzeig, Seymour Papert and Cynthia Solomon.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 34], [35, 43], [44, 52], [53, 55], [56, 60], [61, 63], [64, 69], [70, 78], [78, 79], [80, 87], [88, 94], [95, 98], [99, 106], [107, 114], [114, 115]]}
{"doc_key": "ai-test-314", "ner": [[0, 3, "organisation"], [9, 19, "organisation"], [17, 20, "location"], [22, 22, "location"], [24, 24, "location"], [35, 38, "product"], [50, 53, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 3, 9, 19, "role", "works_for", false, false], [9, 19, 17, 20, "physical", "", false, false], [17, 20, 22, 22, "physical", "", false, false], [22, 22, 24, 24, "physical", "", false, false], [35, 38, 0, 3, "origin", "", false, false], [50, 53, 35, 38, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "Eyring", "Research", "Institute", "was", "instrumental", "in", "enabling", "the", "US", "Air", "Force", "Missile", "Directorate", ",", "based", "at", "Hill", "Air", "Force", "Base", "near", "Ogden", ",", "Utah", ",", "to", "produce", ",", "in", "great", "military", "secrecy", ",", "the", "Intelligent", "Systems", "Technology", "Software", "that", "formed", "the", "basis", "of", "what", "later", "became", "known", "as", "the", "Reagan", "Star", "Wars", "programme", "."], "sentence-detokenized": "The Eyring Research Institute was instrumental in enabling the US Air Force Missile Directorate, based at Hill Air Force Base near Ogden, Utah, to produce, in great military secrecy, the Intelligent Systems Technology Software that formed the basis of what later became known as the Reagan Star Wars programme.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 29], [30, 33], [34, 46], [47, 49], [50, 58], [59, 62], [63, 65], [66, 69], [70, 75], [76, 83], [84, 95], [95, 96], [97, 102], [103, 105], [106, 110], [111, 114], [115, 120], [121, 125], [126, 130], [131, 136], [136, 137], [138, 142], [142, 143], [144, 146], [147, 154], [154, 155], [156, 158], [159, 164], [165, 173], [174, 181], [181, 182], [183, 186], [187, 198], [199, 206], [207, 217], [218, 226], [227, 231], [232, 238], [239, 242], [243, 248], [249, 251], [252, 256], [257, 262], [263, 269], [270, 275], [276, 278], [279, 282], [283, 289], [290, 294], [295, 299], [300, 309], [309, 310]]}
{"doc_key": "ai-test-315", "ner": [[16, 20, "field"], [0, 3, "researcher"], [5, 6, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "F", ".", "Sowa", "and", "John", "Zachman", "(", "1992", ")", "have", "spent", "decades", "researching", "and", "developing", "emerging", "areas", "of", "computer", "science", "such", "as", "compilers", ",", "programming", "languages", "and", "system", "architecture", "."], "sentence-detokenized": "John F. Sowa and John Zachman (1992) have spent decades researching and developing emerging areas of computer science such as compilers, programming languages and system architecture.", "token2charspan": [[0, 4], [5, 6], [6, 7], [8, 12], [13, 16], [17, 21], [22, 29], [30, 31], [31, 35], [35, 36], [37, 41], [42, 47], [48, 55], [56, 67], [68, 71], [72, 82], [83, 91], [92, 97], [98, 100], [101, 109], [110, 117], [118, 122], [123, 125], [126, 135], [135, 136], [137, 148], [149, 158], [159, 162], [163, 169], [170, 182], [182, 183]]}
{"doc_key": "ai-test-316", "ner": [[6, 10, "algorithm"], [7, 9, "algorithm"], [13, 13, "algorithm"], [18, 19, "field"], [17, 22, "field"], [27, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 9, 6, 10, "named", "", false, false], [13, 13, 6, 10, "named", "", false, false], [18, 19, 6, 10, "usage", "", false, false], [17, 22, 6, 10, "usage", "", false, false], [27, 28, 6, 10, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Sobel", "operator", ",", "sometimes", "called", "the", "Sobel", "-", "Feldman", "operator", "or", "Sobel", "filter", ",", "is", "used", "in", "image", "processing", "and", "computer", "vision", ",", "especially", "in", "edge", "detection", "algorithms", "where", "it", "creates", "an", "image", "that", "emphasises", "edges", "."], "sentence-detokenized": "The Sobel operator, sometimes called the Sobel-Feldman operator or Sobel filter, is used in image processing and computer vision, especially in edge detection algorithms where it creates an image that emphasises edges.", "token2charspan": [[0, 3], [4, 9], [10, 18], [18, 19], [20, 29], [30, 36], [37, 40], [41, 46], [46, 47], [47, 54], [55, 63], [64, 66], [67, 72], [73, 79], [79, 80], [81, 83], [84, 88], [89, 91], [92, 97], [98, 108], [109, 112], [113, 121], [122, 128], [128, 129], [130, 140], [141, 143], [144, 148], [149, 158], [159, 169], [170, 175], [176, 178], [179, 186], [187, 189], [190, 195], [196, 200], [201, 211], [212, 217], [217, 218]]}
{"doc_key": "ai-test-317", "ner": [[0, 3, "algorithm"], [4, 4, "field"], [15, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 4, 4, "compare", "", false, false], [0, 3, 4, 4, "type-of", "", false, false], [0, 3, 15, 23, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["While", "LDA", "is", "a", "supervised", "learning", "algorithm", "that", "uses", "the", "labels", "of", "the", "data", ",", "PCA", "is", "a", "learning", "algorithm", "that", "ignores", "the", "labels", "."], "sentence-detokenized": "While LDA is a supervised learning algorithm that uses the labels of the data, PCA is a learning algorithm that ignores the labels.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 14], [15, 25], [26, 34], [35, 44], [45, 49], [50, 54], [55, 58], [59, 65], [66, 68], [69, 72], [73, 77], [77, 78], [79, 82], [83, 85], [86, 87], [88, 96], [97, 106], [107, 111], [112, 119], [120, 123], [124, 130], [130, 131]]}
{"doc_key": "ai-test-318", "ner": [[5, 5, "algorithm"], [7, 9, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "linear", "classification", "algorithms", "include", "Winnow", ",", "support", "vector", "machine", "and", "logistic", "regression", "."], "sentence-detokenized": "Other linear classification algorithms include Winnow, support vector machine and logistic regression.", "token2charspan": [[0, 5], [6, 12], [13, 27], [28, 38], [39, 46], [47, 53], [53, 54], [55, 62], [63, 69], [70, 77], [78, 81], [82, 90], [91, 101], [101, 102]]}
{"doc_key": "ai-test-319", "ner": [[0, 0, "product"], [4, 5, "programlang"], [15, 17, "product"], [19, 19, "programlang"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 4, 5, "general-affiliation", "", true, false], [0, 0, 15, 17, "general-affiliation", "", true, false], [0, 0, 19, 19, "general-affiliation", "", true, false], [0, 0, 21, 21, "general-affiliation", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["VTK", "consists", "of", "a", "C", "++", "class", "library", "and", "several", "interpreted", "interface", "layers", ",", "including", "Tcl", "/", "Tk", ",", "Java", "and", "Python", "."], "sentence-detokenized": "VTK consists of a C++ class library and several interpreted interface layers, including Tcl/Tk, Java and Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 17], [18, 19], [19, 21], [22, 27], [28, 35], [36, 39], [40, 47], [48, 59], [60, 69], [70, 76], [76, 77], [78, 87], [88, 91], [91, 92], [92, 94], [94, 95], [96, 100], [101, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-320", "ner": [[12, 14, "task"], [21, 23, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "also", "includes", "text", "processing", "noise", "generated", "by", "processing", "spontaneous", "speech", "using", "automatic", "speech", "recognition", "and", "printed", "or", "handwritten", "text", "using", "optical", "character", "recognition", "."], "sentence-detokenized": "It also includes text processing noise generated by processing spontaneous speech using automatic speech recognition and printed or handwritten text using optical character recognition.", "token2charspan": [[0, 2], [3, 7], [8, 16], [17, 21], [22, 32], [33, 38], [39, 48], [49, 51], [52, 62], [63, 74], [75, 81], [82, 87], [88, 97], [98, 104], [105, 116], [117, 120], [121, 128], [129, 131], [132, 143], [144, 148], [149, 154], [155, 162], [163, 172], [173, 184], [184, 185]]}
{"doc_key": "ai-test-321", "ner": [[0, 0, "researcher"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 9, 9, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "wrote", "several", "books", "and", "directed", "the", "development", "of", "WordNet", ",", "an", "online", "word", "link", "database", "that", "can", "be", "used", "by", "computer", "programmes", "."], "sentence-detokenized": "Miller wrote several books and directed the development of WordNet, an online word link database that can be used by computer programmes.", "token2charspan": [[0, 6], [7, 12], [13, 20], [21, 26], [27, 30], [31, 39], [40, 43], [44, 55], [56, 58], [59, 66], [66, 67], [68, 70], [71, 77], [78, 82], [83, 87], [88, 96], [97, 101], [102, 105], [106, 108], [109, 113], [114, 116], [117, 125], [126, 136], [136, 137]]}
{"doc_key": "ai-test-322", "ner": [[1, 1, "field"], [5, 12, "organisation"], [10, 22, "country"], [14, 15, "person"], [17, 19, "person"], [25, 26, "person"], [28, 29, "person"], [23, 23, "country"], [36, 39, "location"], [31, 32, "misc"], [33, 35, "person"], [41, 42, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[5, 12, 10, 22, "physical", "", false, false], [14, 15, 23, 23, "physical", "", false, false], [17, 19, 23, 23, "physical", "", false, false], [25, 26, 23, 23, "physical", "", false, false], [28, 29, 23, 23, "physical", "", false, false], [36, 39, 1, 1, "general-affiliation", "", false, false], [36, 39, 33, 35, "artifact", "", false, false], [31, 32, 33, 35, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Contemporary", "automata", "are", "represented", "by", "the", "Cabaret", "Mechanical", "Theatre", "in", "the", "United", "Kingdom", ",", "Dug", "North", "and", "Chomick", "+", "Meder", "in", "the", "United", "States", ",", "Arthur", "Ganson", ",", "Joe", "Jones", ",", "French", "artist", "Jacques", "Monestier", "'s", "Le", "D\u00e9fenseur", "du", "Temps", "and", "Fran\u00e7ois", "Junod", "in", "Switzerland", "."], "sentence-detokenized": "Contemporary automata are represented by the Cabaret Mechanical Theatre in the United Kingdom, Dug North and Chomick + Meder in the United States, Arthur Ganson, Joe Jones, French artist Jacques Monestier's Le D\u00e9fenseur du Temps and Fran\u00e7ois Junod in Switzerland.", "token2charspan": [[0, 12], [13, 21], [22, 25], [26, 37], [38, 40], [41, 44], [45, 52], [53, 63], [64, 71], [72, 74], [75, 78], [79, 85], [86, 93], [93, 94], [95, 98], [99, 104], [105, 108], [109, 116], [117, 118], [119, 124], [125, 127], [128, 131], [132, 138], [139, 145], [145, 146], [147, 153], [154, 160], [160, 161], [162, 165], [166, 171], [171, 172], [173, 179], [180, 186], [187, 194], [195, 204], [204, 206], [207, 209], [210, 219], [220, 222], [223, 228], [229, 232], [233, 241], [242, 247], [248, 250], [251, 262], [262, 263]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 21, 21, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "includes", "standard", "codefor", "/", "code", "and", "codewhile", "/", "code", "loops", ",", "but", "(", "as", "in", "other", "similar", "applications", "such", "as", "R", ")", "the", "use", "of", "vectorial", "notation", "is", "encouraged", "and", "is", "generally", "faster", "to", "execute", "."], "sentence-detokenized": "MATLAB includes standard codefor/code and codewhile/code loops, but (as in other similar applications such as R) the use of vectorial notation is encouraged and is generally faster to execute.", "token2charspan": [[0, 6], [7, 15], [16, 24], [25, 32], [32, 33], [33, 37], [38, 41], [42, 51], [51, 52], [52, 56], [57, 62], [62, 63], [64, 67], [68, 69], [69, 71], [72, 74], [75, 80], [81, 88], [89, 101], [102, 106], [107, 109], [110, 111], [111, 112], [113, 116], [117, 120], [121, 123], [124, 133], [134, 142], [143, 145], [146, 156], [157, 160], [161, 163], [164, 173], [174, 180], [181, 183], [184, 191], [191, 192]]}
{"doc_key": "ai-test-324", "ner": [[0, 0, "researcher"], [6, 9, "conference"], [15, 17, "field"], [19, 26, "misc"], [16, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 19, 26, "win-defeat", "", false, false], [0, 0, 16, 38, "win-defeat", "", false, false], [19, 26, 6, 9, "temporal", "", false, false], [19, 26, 15, 17, "topic", "", false, false], [16, 38, 6, 9, "temporal", "", false, false], [16, 38, 15, 17, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pausch", "received", "two", "awards", "from", "the", "Association", "for", "Computing", "Machinery", "in", "2007", "for", "his", "achievements", "in", "computer", "education", ":", "The", "Karl", "V", ".", "Karlstrom", "Outstanding", "Educator", "Award", "and", "the", "ACM", "SIGCSE", "Award", "for", "Outstanding", "Contributions", "to", "Computer", "Science", "Education", "."], "sentence-detokenized": "Pausch received two awards from the Association for Computing Machinery in 2007 for his achievements in computer education: The Karl V. Karlstrom Outstanding Educator Award and the ACM SIGCSE Award for Outstanding Contributions to Computer Science Education.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 26], [27, 31], [32, 35], [36, 47], [48, 51], [52, 61], [62, 71], [72, 74], [75, 79], [80, 83], [84, 87], [88, 100], [101, 103], [104, 112], [113, 122], [122, 123], [124, 127], [128, 132], [133, 134], [134, 135], [136, 145], [146, 157], [158, 166], [167, 172], [173, 176], [177, 180], [181, 184], [185, 191], [192, 197], [198, 201], [202, 213], [214, 227], [228, 230], [231, 239], [240, 247], [248, 257], [257, 258]]}
{"doc_key": "ai-test-325", "ner": [[2, 2, "person"], [7, 7, "product"], [8, 8, "product"], [10, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 2, 7, 7, "role", "sells", false, false], [7, 7, 8, 8, "general-affiliation", "", false, false], [7, 7, 10, 15, "physical", "shipped_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1960", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "shipped", "to", "General", "Motors", "in", "1961", "."], "sentence-detokenized": "In 1960 Devol personally sold the first Unimate robot, which was shipped to General Motors in 1961.", "token2charspan": [[0, 2], [3, 7], [8, 13], [14, 24], [25, 29], [30, 33], [34, 39], [40, 47], [48, 53], [53, 54], [55, 60], [61, 64], [65, 72], [73, 75], [76, 83], [84, 90], [91, 93], [94, 98], [98, 99]]}
{"doc_key": "ai-test-326", "ner": [[0, 1, "algorithm"], [5, 7, "field"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 0, 1, "usage", "", false, false], [11, 12, 5, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Semantic", "networks", "are", "used", "in", "natural", "language", "processing", "applications", "such", "as", "semantic", "parsing", "."], "sentence-detokenized": "Semantic networks are used in natural language processing applications such as semantic parsing.", "token2charspan": [[0, 8], [9, 17], [18, 21], [22, 26], [27, 29], [30, 37], [38, 46], [47, 57], [58, 70], [71, 75], [76, 78], [79, 87], [88, 95], [95, 96]]}
{"doc_key": "ai-test-327", "ner": [[3, 6, "field"], [7, 8, "field"], [10, 11, "task"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 8, 3, 6, "usage", "", false, false], [10, 11, 3, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Some", "successful", "applications", "of", "deep", "learning", "are", "computer", "vision", "and", "speech", "recognition", ".", "Honglak", "Lee", ",", "Roger", "Grosse", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y", ".", "Ng", "."], "sentence-detokenized": "Some successful applications of deep learning are computer vision and speech recognition. Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 4], [5, 15], [16, 28], [29, 31], [32, 36], [37, 45], [46, 49], [50, 58], [59, 65], [66, 69], [70, 76], [77, 88], [88, 89], [90, 97], [98, 101], [101, 102], [103, 108], [109, 115], [115, 116], [117, 123], [124, 133], [133, 134], [135, 141], [142, 143], [143, 144], [145, 147], [147, 148]]}
{"doc_key": "ai-test-328", "ner": [[3, 8, "product"], [13, 14, "misc"], [17, 17, "misc"], [23, 23, "product"], [28, 28, "task"], [30, 31, "task"], [33, 34, "task"], [36, 38, "field"], [40, 41, "task"], [43, 44, "field"], [46, 47, "task"], [49, 50, "task"], [52, 53, "task"], [55, 56, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[3, 8, 13, 14, "physical", "travels_to", false, false], [3, 8, 17, 17, "physical", "travels_to", false, false], [23, 23, 3, 8, "part-of", "", false, false], [23, 23, 3, 8, "role", "maintains", false, false], [23, 23, 28, 28, "related-to", "has_ability_to", false, false], [23, 23, 30, 31, "related-to", "has_ability_to", false, false], [23, 23, 33, 34, "related-to", "has_ability_to", false, false], [23, 23, 36, 38, "related-to", "has_ability_to", false, false], [23, 23, 40, 41, "related-to", "has_ability_to", false, false], [23, 23, 43, 44, "related-to", "has_ability_to", false, false], [23, 23, 46, 47, "related-to", "has_ability_to", false, false], [23, 23, 49, 50, "related-to", "has_ability_to", false, false], [23, 23, 52, 53, "related-to", "has_ability_to", false, false], [23, 23, 55, 56, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["In", "addition", "to", "protecting", "the", "Discovery", "One", "spacecraft", "systems", "during", "the", "interplanetary", "mission", "to", "Jupiter", "(", "or", "Saturn", "in", "the", "novel", ")", ",", "HAL", "is", "capable", "of", "speech", "synthesis", ",", "speech", "recognition", ",", "facial", "recognition", ",", "natural", "language", "processing", ",", "lip", "reading", ",", "art", "appreciation", ",", "affective", "computing", ",", "automated", "reasoning", ",", "spacecraft", "piloting", "and", "chess", "playing", "."], "sentence-detokenized": "In addition to protecting the Discovery One spacecraft systems during the interplanetary mission to Jupiter (or Saturn in the novel), HAL is capable of speech synthesis, speech recognition, facial recognition, natural language processing, lip reading, art appreciation, affective computing, automated reasoning, spacecraft piloting and chess playing.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 25], [26, 29], [30, 39], [40, 43], [44, 54], [55, 62], [63, 69], [70, 73], [74, 88], [89, 96], [97, 99], [100, 107], [108, 109], [109, 111], [112, 118], [119, 121], [122, 125], [126, 131], [131, 132], [132, 133], [134, 137], [138, 140], [141, 148], [149, 151], [152, 158], [159, 168], [168, 169], [170, 176], [177, 188], [188, 189], [190, 196], [197, 208], [208, 209], [210, 217], [218, 226], [227, 237], [237, 238], [239, 242], [243, 250], [250, 251], [252, 255], [256, 268], [268, 269], [270, 279], [280, 289], [289, 290], [291, 300], [301, 310], [310, 311], [312, 322], [323, 331], [332, 335], [336, 341], [342, 349], [349, 350]]}
{"doc_key": "ai-test-329", "ner": [[0, 1, "researcher"], [4, 4, "country"], [7, 8, "country"], [11, 11, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 4, 4, "physical", "", false, false], [0, 1, 7, 8, "physical", "", false, false], [0, 1, 11, 11, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dr", "Julesz", "emigrated", "from", "Hungary", "to", "the", "United", "States", "after", "the", "Soviet", "invasion", "of", "1956", "."], "sentence-detokenized": "Dr Julesz emigrated from Hungary to the United States after the Soviet invasion of 1956.", "token2charspan": [[0, 2], [3, 9], [10, 19], [20, 24], [25, 32], [33, 35], [36, 39], [40, 46], [47, 53], [54, 59], [60, 63], [64, 70], [71, 79], [80, 82], [83, 87], [87, 88]]}
{"doc_key": "ai-test-330", "ner": [[0, 0, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sigmoid", "function", "activation", "functions", "use", "a", "second", "nonlinear", "property", "for", "large", "inputs", ":", "math", "\\", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+\\", "exp", "(", "-", "v", "_", "i", ")", ")", "^", "{", "-1", "}", "/", "math", "."], "sentence-detokenized": "Sigmoid function activation functions use a second nonlinear property for large inputs: math\\ phi (v _ i) = (1 +\\ exp (-v _ i)) ^ {-1} / math.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 37], [38, 41], [42, 43], [44, 50], [51, 60], [61, 69], [70, 73], [74, 79], [80, 86], [86, 87], [88, 92], [92, 93], [94, 97], [98, 99], [99, 100], [101, 102], [103, 104], [104, 105], [106, 107], [108, 109], [109, 110], [111, 113], [114, 117], [118, 119], [119, 120], [120, 121], [122, 123], [124, 125], [125, 126], [126, 127], [128, 129], [130, 131], [131, 133], [133, 134], [135, 136], [137, 141], [141, 142]]}
{"doc_key": "ai-test-331", "ner": [[11, 13, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "probabilities", "are", "used", "to", "determine", "what", "the", "target", "is", "using", "maximum", "likelihood", "decision", "."], "sentence-detokenized": "These probabilities are used to determine what the target is using maximum likelihood decision.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 28], [29, 31], [32, 41], [42, 46], [47, 50], [51, 57], [58, 60], [61, 66], [67, 74], [75, 85], [86, 94], [94, 95]]}
{"doc_key": "ai-test-332", "ner": [[4, 10, "university"], [3, 16, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1984", "he", "moved", "to", "the", "University", "of", "Konstanz", "and", "in", "1990", "to", "the", "University", "of", "Salzburg", "."], "sentence-detokenized": "In 1984 he moved to the University of Konstanz and in 1990 to the University of Salzburg.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 16], [17, 19], [20, 23], [24, 34], [35, 37], [38, 46], [47, 50], [51, 53], [54, 58], [59, 61], [62, 65], [66, 76], [77, 79], [80, 88], [88, 89]]}
{"doc_key": "ai-test-333", "ner": [[6, 9, "metrics"], [10, 12, "metrics"], [14, 16, "metrics"], [18, 18, "metrics"], [20, 21, "metrics"], [23, 25, "metrics"], [28, 37, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 12, 6, 9, "origin", "based_on", false, false], [14, 16, 6, 9, "origin", "based_on", false, false], [18, 18, 6, 9, "origin", "based_on", false, false], [20, 21, 6, 9, "origin", "based_on", false, false], [23, 25, 6, 9, "origin", "based_on", false, false], [28, 37, 6, 9, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Some", "popular", "fitness", "functions", "based", "on", "the", "confusion", "matrix", "include", "sensitivity", "/", "specificity", ",", "recall", "/", "precision", ",", "F-measure", ",", "Jaccard", "similarity", ",", "Matthews", "correlation", "coefficient", "and", "the", "cost", "/", "gain", "matrix", ",", "which", "combines", "the", "costs", "and", "gains", "assigned", "to", "4", "different", "classification", "types", "."], "sentence-detokenized": "Some popular fitness functions based on the confusion matrix include sensitivity/specificity, recall/precision, F-measure, Jaccard similarity, Matthews correlation coefficient and the cost/gain matrix, which combines the costs and gains assigned to 4 different classification types.", "token2charspan": [[0, 4], [5, 12], [13, 20], [21, 30], [31, 36], [37, 39], [40, 43], [44, 53], [54, 60], [61, 68], [69, 80], [80, 81], [81, 92], [92, 93], [94, 100], [100, 101], [101, 110], [110, 111], [112, 121], [121, 122], [123, 130], [131, 141], [141, 142], [143, 151], [152, 163], [164, 175], [176, 179], [180, 183], [184, 188], [188, 189], [189, 193], [194, 200], [200, 201], [202, 207], [208, 216], [217, 220], [221, 226], [227, 230], [231, 236], [237, 245], [246, 248], [249, 250], [251, 260], [261, 275], [276, 281], [281, 282]]}
{"doc_key": "ai-test-334", "ner": [[6, 6, "product"], [8, 8, "product"], [10, 10, "product"], [12, 12, "product"], [14, 16, "programlang"], [27, 29, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[27, 29, 6, 6, "part-of", "", false, false], [27, 29, 8, 8, "part-of", "", false, false], [27, 29, 10, 10, "part-of", "", false, false], [27, 29, 12, 12, "part-of", "", false, false], [27, 29, 14, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Common", "numerical", "programming", "environments", "such", "as", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", "and", "the", "R", "language", "provide", "some", "of", "the", "simpler", "feature", "extraction", "techniques", "(", "e.g.", "principal", "component", "analysis", ")", "through", "built", "-", "in", "commands", "."], "sentence-detokenized": "Common numerical programming environments such as MATLAB, SciLab, NumPy, Sklearn and the R language provide some of the simpler feature extraction techniques (e.g. principal component analysis) through built-in commands.", "token2charspan": [[0, 6], [7, 16], [17, 28], [29, 41], [42, 46], [47, 49], [50, 56], [56, 57], [58, 64], [64, 65], [66, 71], [71, 72], [73, 80], [81, 84], [85, 88], [89, 90], [91, 99], [100, 107], [108, 112], [113, 115], [116, 119], [120, 127], [128, 135], [136, 146], [147, 157], [158, 159], [159, 163], [164, 173], [174, 183], [184, 192], [192, 193], [194, 201], [202, 207], [207, 208], [208, 210], [211, 219], [219, 220]]}
{"doc_key": "ai-test-335", "ner": [[0, 11, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Industrial", "robots", "have", "been", "implemented", "to", "co-operate", "with", "humans", "to", "perform", "industrial", "production", "tasks", "."], "sentence-detokenized": "Industrial robots have been implemented to co-operate with humans to perform industrial production tasks.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 27], [28, 39], [40, 42], [43, 53], [54, 58], [59, 65], [66, 68], [69, 76], [77, 87], [88, 98], [99, 104], [104, 105]]}
{"doc_key": "ai-test-336", "ner": [[6, 6, "field"], [8, 11, "researcher"], [21, 22, "field"], [24, 25, "field"], [20, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 21, 22, "related-to", "", false, false], [6, 6, 24, 25, "related-to", "", false, false], [6, 6, 20, 28, "related-to", "", false, false], [8, 11, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "the", "first", "published", "paper", "on", "CGs", ",", "John", "F", ".", "Sowa", "applied", "them", "to", "a", "wide", "variety", "of", "topics", "in", "artificial", "intelligence", ",", "computer", "science", "and", "cognitive", "science", "."], "sentence-detokenized": "In the first published paper on CGs, John F. Sowa applied them to a wide variety of topics in artificial intelligence, computer science and cognitive science.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [23, 28], [29, 31], [32, 35], [35, 36], [37, 41], [42, 43], [43, 44], [45, 49], [50, 57], [58, 62], [63, 65], [66, 67], [68, 72], [73, 80], [81, 83], [84, 90], [91, 93], [94, 104], [105, 117], [117, 118], [119, 127], [128, 135], [136, 139], [140, 149], [150, 157], [157, 158]]}
{"doc_key": "ai-test-337", "ner": [[0, 0, "metrics"], [3, 4, "metrics"], [7, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 3, 4, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "BLEU", "in", "calculating", "the", "penalty", "for", "brevity", ",", "as", "long", "as", "small", "differences", "in", "translation", "length", "do", "not", "affect", "the", "overall", "score", "too", "much", "."], "sentence-detokenized": "NIST also differs from BLEU in calculating the penalty for brevity, as long as small differences in translation length do not affect the overall score too much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 27], [28, 30], [31, 42], [43, 46], [47, 54], [55, 58], [59, 66], [66, 67], [68, 70], [71, 75], [76, 78], [79, 84], [85, 96], [97, 99], [100, 111], [112, 118], [119, 121], [122, 125], [126, 132], [133, 136], [137, 144], [145, 150], [151, 154], [155, 159], [159, 160]]}
{"doc_key": "ai-test-338", "ner": [[0, 6, "misc"], [14, 14, "conference"], [23, 25, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 6, 14, 14, "temporal", "", false, false], [0, 6, 23, 25, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "IJCAI", "Research", "Excellence", "Award", "is", "an", "award", "given", "twice", "a", "year", "at", "the", "IJCAI", "conference", "to", "researchers", "working", "in", "the", "field", "of", "artificial", "intelligence", "as", "a", "recognition", "of", "excellence", "in", "their", "careers", "."], "sentence-detokenized": "The IJCAI Research Excellence Award is an award given twice a year at the IJCAI conference to researchers working in the field of artificial intelligence as a recognition of excellence in their careers.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 29], [30, 35], [36, 38], [39, 41], [42, 47], [48, 53], [54, 59], [60, 61], [62, 66], [67, 69], [70, 73], [74, 79], [80, 90], [91, 93], [94, 105], [106, 113], [114, 116], [117, 120], [121, 126], [127, 129], [130, 140], [141, 153], [154, 156], [157, 158], [159, 170], [171, 173], [174, 184], [185, 187], [188, 193], [194, 201], [201, 202]]}
{"doc_key": "ai-test-339", "ner": [[0, 0, "researcher"], [5, 8, "conference"], [14, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 5, 8, "role", "", false, false], [0, 0, 14, 25, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lenat", "is", "one", "of", "the", "first", "members", "of", "AAAI", "and", "is", "the", "only", "person", "to", "sit", "on", "the", "Scientific", "Advisory", "Boards", "of", "both", "Microsoft", "and", "Apple", "."], "sentence-detokenized": "Lenat is one of the first members of AAAI and is the only person to sit on the Scientific Advisory Boards of both Microsoft and Apple.", "token2charspan": [[0, 5], [6, 8], [9, 12], [13, 15], [16, 19], [20, 25], [26, 33], [34, 36], [37, 41], [42, 45], [46, 48], [49, 52], [53, 57], [58, 64], [65, 67], [68, 71], [72, 74], [75, 78], [79, 89], [90, 98], [99, 105], [106, 108], [109, 113], [114, 123], [124, 127], [128, 133], [133, 134]]}
{"doc_key": "ai-test-340", "ner": [[0, 0, "algorithm"], [5, 6, "misc"], [10, 12, "metrics"], [19, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 6, "related-to", "minimise", false, false], [10, 12, 5, 6, "type-of", "", false, false], [19, 19, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autoencoders", "are", "trained", "to", "minimise", "reconstruction", "errors", "(", "such", "as", "mean", "squared", "error", ")", ",", "often", "referred", "to", "as", "losses", ":"], "sentence-detokenized": "Autoencoders are trained to minimise reconstruction errors (such as mean squared error), often referred to as losses:", "token2charspan": [[0, 12], [13, 16], [17, 24], [25, 27], [28, 36], [37, 51], [52, 58], [59, 60], [60, 64], [65, 67], [68, 72], [73, 80], [81, 86], [86, 87], [87, 88], [89, 94], [95, 103], [104, 106], [107, 109], [110, 116], [116, 117]]}
{"doc_key": "ai-test-341", "ner": [[29, 31, "misc"], [35, 35, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[35, 35, 29, 31, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "alternative", "to", "the", "use", "of", "definitions", "is", "to", "consider", "the", "overall", "word", "-", "sense", "relationship", "and", "compute", "the", "similarity", "of", "each", "word", "sense", "pair", "based", "on", "a", "specific", "lexical", "knowledge", "base", ",", "such", "as", "WordNet", "."], "sentence-detokenized": "An alternative to the use of definitions is to consider the overall word-sense relationship and compute the similarity of each word sense pair based on a specific lexical knowledge base, such as WordNet.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 21], [22, 25], [26, 28], [29, 40], [41, 43], [44, 46], [47, 55], [56, 59], [60, 67], [68, 72], [72, 73], [73, 78], [79, 91], [92, 95], [96, 103], [104, 107], [108, 118], [119, 121], [122, 126], [127, 131], [132, 137], [138, 142], [143, 148], [149, 151], [152, 153], [154, 162], [163, 170], [171, 180], [181, 185], [185, 186], [187, 191], [192, 194], [195, 202], [202, 203]]}
{"doc_key": "ai-test-342", "ner": [[0, 2, "algorithm"], [8, 11, "researcher"], [14, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 8, 11, "origin", "", false, false], [8, 11, 14, 16, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD", "-", "Lambda", "is", "a", "learning", "algorithm", "invented", "by", "Richard", "S.", "Sutton", "based", "on", "Arthur", "Samuel", "'s", "earlier", "work", "on", "temporal", "difference", "learning", "."], "sentence-detokenized": "TD-Lambda is a learning algorithm invented by Richard S. Sutton based on Arthur Samuel's earlier work on temporal difference learning.", "token2charspan": [[0, 2], [2, 3], [3, 9], [10, 12], [13, 14], [15, 23], [24, 33], [34, 42], [43, 45], [46, 53], [54, 56], [57, 63], [64, 69], [70, 72], [73, 79], [80, 86], [86, 88], [89, 96], [97, 101], [102, 104], [105, 113], [114, 124], [125, 133], [133, 134]]}
{"doc_key": "ai-test-343", "ner": [[1, 2, "field"], [0, 4, "field"], [7, 7, "task"], [13, 13, "task"], [15, 15, "task"], [20, 20, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 7, 1, 2, "part-of", "task_part_of_field", false, false], [7, 7, 0, 4, "part-of", "task_part_of_field", false, false], [13, 13, 7, 7, "named", "", false, false], [15, 15, 7, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "data", "mining", "and", "statistics", ",", "hierarchical", "clustering", "(", "also", "called", "hierarchical", "cluster", "analysis", "or", "HCA", ")", "is", "a", "cluster", "analysis", "method", "that", "aims", "to", "create", "a", "hierarchy", "of", "clusters", "."], "sentence-detokenized": "In data mining and statistics, hierarchical clustering (also called hierarchical cluster analysis or HCA) is a cluster analysis method that aims to create a hierarchy of clusters.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 18], [19, 29], [29, 30], [31, 43], [44, 54], [55, 56], [56, 60], [61, 67], [68, 80], [81, 88], [89, 97], [98, 100], [101, 104], [104, 105], [106, 108], [109, 110], [111, 118], [119, 127], [128, 134], [135, 139], [140, 144], [145, 147], [148, 154], [155, 156], [157, 166], [167, 169], [170, 178], [178, 179]]}
{"doc_key": "ai-test-344", "ner": [[3, 3, "algorithm"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "concept", "of", "deconvolution", "is", "widely", "used", "in", "signal", "processing", "and", "image", "processing", "techniques", "."], "sentence-detokenized": "The concept of deconvolution is widely used in signal processing and image processing techniques.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 28], [29, 31], [32, 38], [39, 43], [44, 46], [47, 53], [54, 64], [65, 68], [69, 74], [75, 85], [86, 96], [96, 97]]}
{"doc_key": "ai-test-345", "ner": [[0, 1, "algorithm"], [22, 23, "misc"], [26, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 22, 23, "related-to", "enhances", false, false], [0, 1, 22, 23, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cognitive", "maps", "serve", "to", "build", "and", "accumulate", "spatial", "knowledge", "by", "allowing", "the", "mind", "'s", "eye", "to", "visualise", "images", "in", "order", "to", "reduce", "cognitive", "load", "and", "increase", "recall", "and", "learning", "of", "information", "."], "sentence-detokenized": "Cognitive maps serve to build and accumulate spatial knowledge by allowing the mind's eye to visualise images in order to reduce cognitive load and increase recall and learning of information.", "token2charspan": [[0, 9], [10, 14], [15, 20], [21, 23], [24, 29], [30, 33], [34, 44], [45, 52], [53, 62], [63, 65], [66, 74], [75, 78], [79, 83], [83, 85], [86, 89], [90, 92], [93, 102], [103, 109], [110, 112], [113, 118], [119, 121], [122, 128], [129, 138], [139, 143], [144, 147], [148, 156], [157, 163], [164, 167], [168, 176], [177, 179], [180, 191], [191, 192]]}
{"doc_key": "ai-test-346", "ner": [[7, 7, "programlang"], [9, 10, "programlang"], [12, 12, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["typically", "provides", "bindings", "to", "languages", "such", "as", "Python", ",", "C", "++", ",", "Java", ")", "."], "sentence-detokenized": "typically provides bindings to languages such as Python, C++, Java).", "token2charspan": [[0, 9], [10, 18], [19, 27], [28, 30], [31, 40], [41, 45], [46, 48], [49, 55], [55, 56], [57, 58], [58, 60], [60, 61], [62, 66], [66, 67], [67, 68]]}
{"doc_key": "ai-test-347", "ner": [[1, 3, "product"], [5, 7, "product"], [15, 25, "task"], [22, 23, "task"], [27, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 15, 25, "usage", "", false, false], [1, 3, 22, 23, "usage", "", false, false], [1, 3, 27, 27, "usage", "", false, false], [5, 7, 1, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "voice", "user", "interface", "(", "VUI", ")", "enables", "spoken", "human", "interaction", "with", "computers", "by", "using", "speech", "recognition", "to", "understand", "spoken", "commands", "and", "Question", "answering", ",", "and", "typically", "text", "to", "speech", "to", "play", "back", "a", "response", "."], "sentence-detokenized": "A voice user interface (VUI) enables spoken human interaction with computers by using speech recognition to understand spoken commands and Question answering, and typically text to speech to play back a response.", "token2charspan": [[0, 1], [2, 7], [8, 12], [13, 22], [23, 24], [24, 27], [27, 28], [29, 36], [37, 43], [44, 49], [50, 61], [62, 66], [67, 76], [77, 79], [80, 85], [86, 92], [93, 104], [105, 107], [108, 118], [119, 125], [126, 134], [135, 138], [139, 147], [148, 157], [157, 158], [159, 162], [163, 172], [173, 177], [178, 180], [181, 187], [188, 190], [191, 195], [196, 200], [201, 202], [203, 211], [211, 212]]}
{"doc_key": "ai-test-348", "ner": [[0, 1, "programlang"], [3, 17, "misc"], [7, 7, "programlang"], [11, 14, "researcher"], [16, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 3, 17, "general-affiliation", "is_a", false, false], [0, 1, 7, 7, "general-affiliation", "made_with", false, false], [0, 1, 11, 14, "origin", "", false, false], [11, 14, 16, 17, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Jess", "is", "a", "rule", "engine", "for", "the", "Java", "platform", "developed", "by", "Ernest", "Friedman", "-", "Hill", "of", "Sandia", "National", "."], "sentence-detokenized": "Jess is a rule engine for the Java platform developed by Ernest Friedman-Hill of Sandia National.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 14], [15, 21], [22, 25], [26, 29], [30, 34], [35, 43], [44, 53], [54, 56], [57, 63], [64, 72], [72, 73], [73, 77], [78, 80], [81, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-test-349", "ner": [[1, 2, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 2, 13, 14, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "multilayer", "sensors", "with", "a", "hidden", "layer", ",", "more", "sophisticated", "algorithms", "such", "as", "back", "propagation", "should", "be", "used", "."], "sentence-detokenized": "For multilayer sensors with a hidden layer, more sophisticated algorithms such as back propagation should be used.", "token2charspan": [[0, 3], [4, 14], [15, 22], [23, 27], [28, 29], [30, 36], [37, 42], [42, 43], [44, 48], [49, 62], [63, 73], [74, 78], [79, 81], [82, 86], [87, 98], [99, 105], [106, 108], [109, 113], [113, 114]]}
{"doc_key": "ai-test-350", "ner": [[0, 1, "product"], [4, 6, "product"], [3, 17, "algorithm"], [22, 23, "field"], [27, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 6, 0, 1, "part-of", "", false, false], [4, 6, 3, 17, "usage", "", false, true], [3, 17, 22, 23, "related-to", "performs", false, false], [27, 32, 22, 23, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Google", "Translate", "'s", "neural", "machine", "translation", "system", "uses", "a", "large", "end", "-", "to", "-", "end", "artificial", "neural", "network", "that", "attempts", "to", "perform", "deep", "learning", ",", "in", "particular", "long", "short", "-", "term", "memory", "networks", "."], "sentence-detokenized": "Google Translate's neural machine translation system uses a large end-to-end artificial neural network that attempts to perform deep learning, in particular long short-term memory networks.", "token2charspan": [[0, 6], [7, 16], [16, 18], [19, 25], [26, 33], [34, 45], [46, 52], [53, 57], [58, 59], [60, 65], [66, 69], [69, 70], [70, 72], [72, 73], [73, 76], [77, 87], [88, 94], [95, 102], [103, 107], [108, 116], [117, 119], [120, 127], [128, 132], [133, 141], [141, 142], [143, 145], [146, 156], [157, 161], [162, 167], [167, 168], [168, 172], [173, 179], [180, 188], [188, 189]]}
{"doc_key": "ai-test-351", "ner": [[11, 11, "researcher"], [13, 13, "researcher"], [15, 15, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 23, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Various", "methods", "were", "developed", "in", "the", "1980s", "and", "early", "1990s", "by", "Werbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Pearlmutter", "and", "others", "."], "sentence-detokenized": "Various methods were developed in the 1980s and early 1990s by Werbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Pearlmutter and others.", "token2charspan": [[0, 7], [8, 15], [16, 20], [21, 30], [31, 33], [34, 37], [38, 43], [44, 47], [48, 53], [54, 59], [60, 62], [63, 69], [69, 70], [71, 79], [79, 80], [81, 89], [89, 90], [91, 97], [98, 109], [109, 110], [111, 115], [116, 126], [126, 127], [128, 139], [140, 143], [144, 150], [150, 151]]}
{"doc_key": "ai-test-352", "ner": [[1, 1, "organisation"], [2, 3, "organisation"], [8, 8, "organisation"], [11, 11, "task"], [17, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 8, 8, "role", "licenses_from", false, false], [2, 3, 1, 1, "named", "", false, false], [17, 17, 1, 1, "origin", "", false, false], [17, 17, 11, 11, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["|", "Apple", "Apple", "Inc", "initially", "licensed", "software", "from", "Nuance", "to", "provide", "speech", "recognition", "to", "its", "digital", "assistant", "Siri", "."], "sentence-detokenized": "| Apple Apple Inc initially licensed software from Nuance to provide speech recognition to its digital assistant Siri.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 17], [18, 27], [28, 36], [37, 45], [46, 50], [51, 57], [58, 60], [61, 68], [69, 75], [76, 87], [88, 90], [91, 94], [95, 102], [103, 112], [113, 117], [117, 118]]}
{"doc_key": "ai-test-353", "ner": [[0, 0, "organisation"], [3, 4, "misc"], [7, 8, "person"], [11, 13, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 4, "role", "releases_movies_in_genre", false, false], [7, 8, 0, 0, "role", "directs_for", false, false], [11, 13, 0, 0, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "released", "several", "3D", "westerns", "produced", "by", "Sam", "Katzman", "and", "directed", "by", "William", "Castle", "."], "sentence-detokenized": "Columbia released several 3D westerns produced by Sam Katzman and directed by William Castle.", "token2charspan": [[0, 8], [9, 17], [18, 25], [26, 28], [29, 37], [38, 46], [47, 49], [50, 53], [54, 61], [62, 65], [66, 74], [75, 77], [78, 85], [86, 92], [92, 93]]}
{"doc_key": "ai-test-354", "ner": [[9, 14, "field"], [12, 12, "field"], [15, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "includes", "knowledge", "and", "research", "in", "the", "fields", "of", "computer", "science", ",", "linguistics", "and", "computer", "engineering", "."], "sentence-detokenized": "It includes knowledge and research in the fields of computer science, linguistics and computer engineering.", "token2charspan": [[0, 2], [3, 11], [12, 21], [22, 25], [26, 34], [35, 37], [38, 41], [42, 48], [49, 51], [52, 60], [61, 68], [68, 69], [70, 81], [82, 85], [86, 94], [95, 106], [106, 107]]}
{"doc_key": "ai-test-355", "ner": [[5, 5, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", "is", "an", "example", "of", "R", "code", ":"], "sentence-detokenized": "Here is an example of R code:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 23], [24, 28], [28, 29]]}
{"doc_key": "ai-test-356", "ner": [[0, 2, "metrics"], [7, 10, "metrics"], [12, 16, "metrics"], [15, 18, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 7, 10, "part-of", "plotted_into", false, false], [0, 2, 15, 18, "part-of", "plotted_into", false, false], [12, 16, 7, 10, "named", "", false, false], [20, 20, 15, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "ROC", "curve", "is", "constructed", "by", "plotting", "the", "TRUE", "positive", "rate", "(", "TPR", ")", "against", "the", "FALSE", "positive", "rate", "(", "FPR", ")", "at", "various", "threshold", "settings", "."], "sentence-detokenized": "The ROC curve is constructed by plotting the TRUE positive rate (TPR) against the FALSE positive rate (FPR) at various threshold settings.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 28], [29, 31], [32, 40], [41, 44], [45, 49], [50, 58], [59, 63], [64, 65], [65, 68], [68, 69], [70, 77], [78, 81], [82, 87], [88, 96], [97, 101], [102, 103], [103, 106], [106, 107], [108, 110], [111, 118], [119, 128], [129, 137], [137, 138]]}
{"doc_key": "ai-test-357", "ner": [[2, 3, "field"], [6, 7, "researcher"], [0, 10, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 2, 3, "related-to", "researches_field", false, false], [0, 10, 2, 3, "related-to", "researches_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["After", "the", "machine", "learning", "research", "of", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", ",", "research", "stagnated", ","], "sentence-detokenized": "After the machine learning research of Marvin Minsky and Seymour Papert (1969), research stagnated,", "token2charspan": [[0, 5], [6, 9], [10, 17], [18, 26], [27, 35], [36, 38], [39, 45], [46, 52], [53, 56], [57, 64], [65, 71], [72, 73], [73, 77], [77, 78], [78, 79], [80, 88], [89, 98], [98, 99]]}
{"doc_key": "ai-test-358", "ner": [[6, 6, "task"], [9, 10, "programlang"], [12, 14, "product"], [17, 17, "programlang"], [19, 19, "product"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 6, 9, 10, "related-to", "used_to_build", false, false], [6, 6, 12, 14, "related-to", "used_to_build", false, false], [6, 6, 17, 17, "related-to", "used_to_build", false, false], [6, 6, 19, 19, "related-to", "used_to_build", false, false], [6, 6, 21, 21, "related-to", "used_to_build", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "programming", "environments", "used", "to", "create", "DAQ", "applications", "include", "ladder", "logic", ",", "Visual", "C", "++", ",", "Visual", "Basic", ",", "LabVIEW", "and", "MATLAB", "."], "sentence-detokenized": "Other programming environments used to create DAQ applications include ladder logic, Visual C++, Visual Basic, LabVIEW and MATLAB.", "token2charspan": [[0, 5], [6, 17], [18, 30], [31, 35], [36, 38], [39, 45], [46, 49], [50, 62], [63, 70], [71, 77], [78, 83], [83, 84], [85, 91], [92, 93], [93, 95], [95, 96], [97, 103], [104, 109], [109, 110], [111, 118], [119, 122], [123, 129], [129, 130]]}
{"doc_key": "ai-test-359", "ner": [[11, 16, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "metric", "is", "designed", "to", "address", "some", "of", "the", "problems", "found", "in", "the", "more", "popular", "BLEU", "metric", "and", "also", "to", "produce", "a", "good", "correlation", "with", "human", "judgement", "at", "the", "sentence", "or", "segment", "level", "."], "sentence-detokenized": "The metric is designed to address some of the problems found in the more popular BLEU metric and also to produce a good correlation with human judgement at the sentence or segment level.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 22], [23, 25], [26, 33], [34, 38], [39, 41], [42, 45], [46, 54], [55, 60], [61, 63], [64, 67], [68, 72], [73, 80], [81, 85], [86, 92], [93, 96], [97, 101], [102, 104], [105, 112], [113, 114], [115, 119], [120, 131], [132, 136], [137, 142], [143, 152], [153, 155], [156, 159], [160, 168], [169, 171], [172, 179], [180, 185], [185, 186]]}
{"doc_key": "ai-test-360", "ner": [[3, 5, "algorithm"], [8, 9, "algorithm"], [11, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "Dynamic", "Markov", "Networks", ",", "Convolutional", "neural", "network", "and", "Long", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "semantic", "correlations", "between", "consecutive", "video", "frames", "."], "sentence-detokenized": "Techniques such as Dynamic Markov Networks, Convolutional neural network and Long short-term memory are often used to exploit semantic correlations between consecutive video frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 72], [73, 76], [77, 81], [82, 87], [87, 88], [88, 92], [93, 99], [100, 103], [104, 109], [110, 114], [115, 117], [118, 125], [126, 134], [135, 147], [148, 155], [156, 167], [168, 173], [174, 180], [180, 181]]}
{"doc_key": "ai-test-361", "ner": [[3, 4, "product"], [7, 9, "product"], [14, 19, "product"], [23, 23, "product"], [36, 39, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 14, 19, "artifact", "", false, false], [3, 4, 36, 39, "named", "", false, false], [7, 9, 3, 4, "named", "", false, false], [23, 23, 14, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Mass", "-", "produced", "printed", "circuit", "boards", "(", "PCBs", ")", "are", "almost", "exclusively", "manufactured", "by", "pick", "-", "and", "-", "place", "robots", ",", "typically", "with", "SCARA", "manipulators", ",", "which", "remove", "small", "electronic", "components", "from", "strips", "or", "trays", "and", "place", "them", "on", "PCBs", "with", "great", "accuracy", "."], "sentence-detokenized": "Mass-produced printed circuit boards (PCBs) are almost exclusively manufactured by pick-and-place robots, typically with SCARA manipulators, which remove small electronic components from strips or trays and place them on PCBs with great accuracy.", "token2charspan": [[0, 4], [4, 5], [5, 13], [14, 21], [22, 29], [30, 36], [37, 38], [38, 42], [42, 43], [44, 47], [48, 54], [55, 66], [67, 79], [80, 82], [83, 87], [87, 88], [88, 91], [91, 92], [92, 97], [98, 104], [104, 105], [106, 115], [116, 120], [121, 126], [127, 139], [139, 140], [141, 146], [147, 153], [154, 159], [160, 170], [171, 181], [182, 186], [187, 193], [194, 196], [197, 202], [203, 206], [207, 212], [213, 217], [218, 220], [221, 225], [226, 230], [231, 236], [237, 245], [245, 246]]}
{"doc_key": "ai-test-362", "ner": [[4, 5, "field"], [15, 15, "algorithm"], [22, 23, "researcher"], [25, 26, "researcher"], [28, 31, "researcher"], [36, 37, "algorithm"], [39, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 15, 4, 5, "part-of", "", false, false], [15, 15, 22, 23, "origin", "", false, false], [15, 15, 25, 26, "origin", "", false, false], [15, 15, 28, 31, "origin", "", false, false], [15, 15, 36, 37, "type-of", "", false, false], [36, 37, 39, 40, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "the", "context", "of", "machine", "learning", ",", "where", "it", "is", "most", "widely", "applied", "today", ",", "LDA", "was", "independently", "reinvented", "in", "2003", "by", "David", "Blei", ",", "Andrew", "Ng", "and", "Michael", "I", ".", "Jordan", "and", "presented", "as", "a", "graphical", "model", "for", "topic", "discovery", "."], "sentence-detokenized": "In the context of machine learning, where it is most widely applied today, LDA was independently reinvented in 2003 by David Blei, Andrew Ng and Michael I. Jordan and presented as a graphical model for topic discovery.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 17], [18, 25], [26, 34], [34, 35], [36, 41], [42, 44], [45, 47], [48, 52], [53, 59], [60, 67], [68, 73], [73, 74], [75, 78], [79, 82], [83, 96], [97, 107], [108, 110], [111, 115], [116, 118], [119, 124], [125, 129], [129, 130], [131, 137], [138, 140], [141, 144], [145, 152], [153, 154], [154, 155], [156, 162], [163, 166], [167, 176], [177, 179], [180, 181], [182, 191], [192, 197], [198, 201], [202, 207], [208, 217], [217, 218]]}
{"doc_key": "ai-test-363", "ner": [[5, 8, "task"], [9, 11, "misc"], [14, 14, "metrics"], [16, 17, "metrics"], [18, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 8, 9, 11, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["Performance", "measured", "on", "test", "data", "of", "eight", "naive", "WSIs", "in", "various", "tauopathies", "resulted", "in", "recall", ",", "precision", "and", "F1", "scores", "of", "0.92", ",", "0.72", "and", "0.81", ",", "respectively", "."], "sentence-detokenized": "Performance measured on test data of eight naive WSIs in various tauopathies resulted in recall, precision and F1 scores of 0.92, 0.72 and 0.81, respectively.", "token2charspan": [[0, 11], [12, 20], [21, 23], [24, 28], [29, 33], [34, 36], [37, 42], [43, 48], [49, 53], [54, 56], [57, 64], [65, 76], [77, 85], [86, 88], [89, 95], [95, 96], [97, 106], [107, 110], [111, 113], [114, 120], [121, 123], [124, 128], [128, 129], [130, 134], [135, 138], [139, 143], [143, 144], [145, 157], [157, 158]]}
{"doc_key": "ai-test-364", "ner": [[5, 5, "field"], [10, 11, "field"], [14, 14, "field"], [20, 21, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 14, 14, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["With", "the", "help", "of", "advanced", "AR", "technologies", "(", "e.g.", "adding", "computer", "vision", ",", "incorporating", "AR", "cameras", "into", "the", "smartphone", "and", "object", "recognition", ")", "information", "about", "the", "real", "world", "around", "the", "user", "becomes", "interactive", "and", "digitally", "manipulated", "."], "sentence-detokenized": "With the help of advanced AR technologies (e.g. adding computer vision, incorporating AR cameras into the smartphone and object recognition) information about the real world around the user becomes interactive and digitally manipulated.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 25], [26, 28], [29, 41], [42, 43], [43, 47], [48, 54], [55, 63], [64, 70], [70, 71], [72, 85], [86, 88], [89, 96], [97, 101], [102, 105], [106, 116], [117, 120], [121, 127], [128, 139], [139, 140], [141, 152], [153, 158], [159, 162], [163, 167], [168, 173], [174, 180], [181, 184], [185, 189], [190, 197], [198, 209], [210, 213], [214, 223], [224, 235], [235, 236]]}
{"doc_key": "ai-test-365", "ner": [[3, 3, "researcher"], [7, 8, "organisation"], [14, 16, "field"], [26, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 7, 8, "role", "forms_company", false, false], [7, 8, 14, 16, "related-to", "works_with", false, false], [7, 8, 26, 26, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2014", ",", "Schmidhuber", "founded", "a", "company", "called", "Nnaisense", "to", "work", "on", "commercial", "applications", "of", "artificial", "intelligence", "in", "areas", "such", "as", "finance", ",", "heavy", "industry", "and", "driverless", "cars", "."], "sentence-detokenized": "In 2014, Schmidhuber founded a company called Nnaisense to work on commercial applications of artificial intelligence in areas such as finance, heavy industry and driverless cars.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 28], [29, 30], [31, 38], [39, 45], [46, 55], [56, 58], [59, 63], [64, 66], [67, 77], [78, 90], [91, 93], [94, 104], [105, 117], [118, 120], [121, 126], [127, 131], [132, 134], [135, 142], [142, 143], [144, 149], [150, 158], [159, 162], [163, 173], [174, 178], [178, 179]]}
{"doc_key": "ai-test-366", "ner": [[23, 26, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "not", "only", "changes", "the", "performance", "of", "all", "subsequent", "tests", "on", "the", "retained", "explanatory", "model", ",", "but", "can", "also", "change", "the", "bias", "and", "mean", "square", "error", "in", "the", "estimates", "."], "sentence-detokenized": "This not only changes the performance of all subsequent tests on the retained explanatory model, but can also change the bias and mean square error in the estimates.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 21], [22, 25], [26, 37], [38, 40], [41, 44], [45, 55], [56, 61], [62, 64], [65, 68], [69, 77], [78, 89], [90, 95], [95, 96], [97, 100], [101, 104], [105, 109], [110, 116], [117, 120], [121, 125], [126, 129], [130, 134], [135, 141], [142, 147], [148, 150], [151, 154], [155, 164], [164, 165]]}
{"doc_key": "ai-test-367", "ner": [[0, 0, "misc"], [7, 7, "algorithm"], [10, 11, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 0, 0, "usage", "", false, false], [7, 7, 10, 11, "topic", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Bigrams", "are", "used", "in", "the", "most", "successful", "language", "models", "for", "speech", "recognition", "."], "sentence-detokenized": "Bigrams are used in the most successful language models for speech recognition.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 19], [20, 23], [24, 28], [29, 39], [40, 48], [49, 55], [56, 59], [60, 66], [67, 78], [78, 79]]}
{"doc_key": "ai-test-368", "ner": [[3, 5, "field"], [8, 10, "misc"], [16, 18, "misc"], [22, 26, "organisation"], [29, 31, "misc"], [37, 42, "organisation"], [43, 45, "misc"], [49, 55, "organisation"], [59, 61, "misc"], [65, 69, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[8, 10, 3, 5, "topic", "", false, false], [16, 18, 22, 26, "origin", "", false, false], [29, 31, 37, 42, "origin", "", false, false], [43, 45, 49, 55, "origin", "", false, false], [59, 61, 65, 69, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["His", "research", "in", "cognitive", "psychology", "has", "won", "the", "Early", "Career", "Award", "(", "1984", ")", "and", "the", "Boyd", "McCandless", "Award", "(", "1986", ")", "from", "the", "American", "Psychological", "Association", ",", "the", "Troland", "Research", "Award", "(", "1993", ")", "from", "the", "National", "Academy", "of", "Sciences", ",", "the", "Henry", "Dale", "Award", "(", "2004", ")", "from", "the", "Royal", "Institute", "of", "Great", "Britain", ",", "and", "the", "George", "Miller", "Award", "(", "2010", ")", "from", "the", "Cognitive", "Neuroscience", "Society", "."], "sentence-detokenized": "His research in cognitive psychology has won the Early Career Award (1984) and the Boyd McCandless Award (1986) from the American Psychological Association, the Troland Research Award (1993) from the National Academy of Sciences, the Henry Dale Award (2004) from the Royal Institute of Great Britain, and the George Miller Award (2010) from the Cognitive Neuroscience Society.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 25], [26, 36], [37, 40], [41, 44], [45, 48], [49, 54], [55, 61], [62, 67], [68, 69], [69, 73], [73, 74], [75, 78], [79, 82], [83, 87], [88, 98], [99, 104], [105, 106], [106, 110], [110, 111], [112, 116], [117, 120], [121, 129], [130, 143], [144, 155], [155, 156], [157, 160], [161, 168], [169, 177], [178, 183], [184, 185], [185, 189], [189, 190], [191, 195], [196, 199], [200, 208], [209, 216], [217, 219], [220, 228], [228, 229], [230, 233], [234, 239], [240, 244], [245, 250], [251, 252], [252, 256], [256, 257], [258, 262], [263, 266], [267, 272], [273, 282], [283, 285], [286, 291], [292, 299], [299, 300], [301, 304], [305, 308], [309, 315], [316, 322], [323, 328], [329, 330], [330, 334], [334, 335], [336, 340], [341, 344], [345, 354], [355, 367], [368, 375], [375, 376]]}
{"doc_key": "ai-test-369", "ner": [[4, 4, "misc"], [6, 7, "product"], [11, 11, "researcher"], [13, 13, "researcher"], [23, 24, "researcher"], [20, 27, "researcher"], [18, 21, "task"], [29, 32, "researcher"], [34, 38, "researcher"], [39, 40, "task"], [42, 42, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[4, 4, 11, 11, "origin", "", false, false], [4, 4, 13, 13, "origin", "", false, false], [4, 4, 18, 21, "related-to", "used_for", false, false], [6, 7, 4, 4, "usage", "", false, false], [6, 7, 39, 40, "named", "", false, false], [23, 24, 4, 4, "usage", "", false, false], [23, 24, 29, 32, "named", "same", false, false], [20, 27, 4, 4, "usage", "", false, false], [20, 27, 34, 38, "named", "same", false, false], [39, 40, 42, 42, "usage", "", false, false]], "relations_mapping_to_source": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["The", "approach", "of", "using", "eigenfaces", "for", "face", "recognition", "was", "developed", "by", "Sirovich", "and", "Kirby", "(", "1987", ")", "and", "used", "in", "face", "classification", "by", "Matthew", "Turk", "and", "Alex", "Pentland", ".", "Turk", ",", "Matthew", "A", "and", "Pentland", ",", "Alex", "P", ".", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "The approach of using eigenfaces for face recognition was developed by Sirovich and Kirby (1987) and used in face classification by Matthew Turk and Alex Pentland. Turk, Matthew A and Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 21], [22, 32], [33, 36], [37, 41], [42, 53], [54, 57], [58, 67], [68, 70], [71, 79], [80, 83], [84, 89], [90, 91], [91, 95], [95, 96], [97, 100], [101, 105], [106, 108], [109, 113], [114, 128], [129, 131], [132, 139], [140, 144], [145, 148], [149, 153], [154, 162], [162, 163], [164, 168], [168, 169], [170, 177], [178, 179], [180, 183], [184, 192], [192, 193], [194, 198], [199, 200], [200, 201], [202, 206], [207, 218], [219, 224], [225, 235], [235, 236]]}
{"doc_key": "ai-test-370", "ner": [[5, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "lexical", "dictionary", "such", "as", "Word", "Net", "can", "then", "be", "used", "to", "understand", "the", "context", "."], "sentence-detokenized": "A lexical dictionary such as WordNet can then be used to understand the context.", "token2charspan": [[0, 1], [2, 9], [10, 20], [21, 25], [26, 28], [29, 33], [33, 36], [37, 40], [41, 45], [46, 48], [49, 53], [54, 56], [57, 67], [68, 71], [72, 79], [79, 80]]}
{"doc_key": "ai-test-371", "ner": [[0, 0, "misc"], [9, 9, "misc"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 9, 9, "part-of", "", false, false], [9, 9, 16, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hyponymy", "is", "the", "most", "frequently", "encoded", "relation", "among", "the", "synsets", "used", "in", "lexical", "databases", "such", "as", "WordNet", "."], "sentence-detokenized": "Hyponymy is the most frequently encoded relation among the synsets used in lexical databases such as WordNet.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 20], [21, 31], [32, 39], [40, 48], [49, 54], [55, 58], [59, 66], [67, 71], [72, 74], [75, 82], [83, 92], [93, 97], [98, 100], [101, 108], [108, 109]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [7, 8, "programlang"], [6, 10, "programlang"], [38, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 8, "general-affiliation", "", false, false], [0, 0, 6, 10, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "offers", "open", "-", "source", "libraries", "in", "C", "++", "and", "Java", ",", "but", "many", "clients", "rely", "on", "community", "-", "developed", "libraries", ",", "such", "as", "libraries", "that", "include", "embedded", "capabilities", "for", "retrieving", "(", "array", "-", "style", ")", "data", "from", "DAP", "servers", "."], "sentence-detokenized": "OPeNDAP offers open-source libraries in C++ and Java, but many clients rely on community-developed libraries, such as libraries that include embedded capabilities for retrieving (array-style) data from DAP servers.", "token2charspan": [[0, 7], [8, 14], [15, 19], [19, 20], [20, 26], [27, 36], [37, 39], [40, 41], [41, 43], [44, 47], [48, 52], [52, 53], [54, 57], [58, 62], [63, 70], [71, 75], [76, 78], [79, 88], [88, 89], [89, 98], [99, 108], [108, 109], [110, 114], [115, 117], [118, 127], [128, 132], [133, 140], [141, 149], [150, 162], [163, 166], [167, 177], [178, 179], [179, 184], [184, 185], [185, 190], [190, 191], [192, 196], [197, 201], [202, 205], [206, 213], [213, 214]]}
{"doc_key": "ai-test-373", "ner": [[4, 5, "misc"], [7, 7, "product"], [28, 29, "misc"], [42, 42, "organisation"], [44, 44, "product"], [46, 46, "organisation"], [48, 52, "product"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7], "relations": [[28, 29, 7, 7, "part-of", "", false, false], [44, 44, 42, 42, "artifact", "", false, false], [48, 52, 46, 46, "artifact", "", false, false]], "relations_mapping_to_source": [2, 3, 4], "sentence": ["On", "this", "page", ",", "Samurai", "Damashii", "exaggerated", "Senkousha", "as", "the", "crystallisation", "of", "four", "thousand", "years", "of", "Chinese", "scientific", "knowledge", ",", "commented", "on", "its", "crude", "design", "(", "e.g.", "the", "Chinese", "Ball", "on", "its", "crotch", ")", "and", "placed", "it", "s", "image", "between", "those", "of", "Honda", "'s", "ASIMO", "and", "Sony", "'s", "QRIO", "SDR", "-", "3", "X", "."], "sentence-detokenized": "On this page, Samurai Damashii exaggerated Senkousha as the crystallisation of four thousand years of Chinese scientific knowledge, commented on its crude design (e.g. the Chinese Ball on its crotch) and placed its image between those of Honda's ASIMO and Sony's QRIO SDR-3X.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 21], [22, 30], [31, 42], [43, 52], [53, 55], [56, 59], [60, 75], [76, 78], [79, 83], [84, 92], [93, 98], [99, 101], [102, 109], [110, 120], [121, 130], [130, 131], [132, 141], [142, 144], [145, 148], [149, 154], [155, 161], [162, 163], [163, 167], [168, 171], [172, 179], [180, 184], [185, 187], [188, 191], [192, 198], [198, 199], [200, 203], [204, 210], [211, 213], [213, 214], [215, 220], [221, 228], [229, 234], [235, 237], [238, 243], [243, 245], [246, 251], [252, 255], [256, 260], [260, 262], [263, 267], [268, 271], [271, 272], [272, 273], [273, 274], [274, 275]]}
{"doc_key": "ai-test-374", "ner": [[17, 18, "algorithm"], [9, 9, "product"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[17, 18, 9, 9, "part-of", "includes_functionality_of", false, false], [17, 18, 11, 11, "part-of", "includes_functionality_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "also", "many", "programming", "libraries", "(", "such", "as", "TensorFlow", ",", "Theano", ",", "etc.", ")", "that", "contain", "neural", "network", "functionality", "and", "can", "be", "used", "in", "specialised", "applications", "."], "sentence-detokenized": "There are also many programming libraries (such as TensorFlow, Theano, etc.) that contain neural network functionality and can be used in specialised applications.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 19], [20, 31], [32, 41], [42, 43], [43, 47], [48, 50], [51, 61], [61, 62], [63, 69], [69, 70], [71, 75], [75, 76], [77, 81], [82, 89], [90, 96], [97, 104], [105, 118], [119, 122], [123, 126], [127, 129], [130, 134], [135, 137], [138, 149], [150, 162], [162, 163]]}
{"doc_key": "ai-test-375", "ner": [[5, 8, "conference"], [10, 10, "organisation"], [12, 18, "conference"], [20, 20, "conference"], [22, 22, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "Association", "for", "Computing", "Machinery", ",", "IEEE", ",", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "IAPR", "and", "SPIE", "."], "sentence-detokenized": "He is a member of Association for Computing Machinery, IEEE, American Association for the Advancement of Science, IAPR and SPIE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 29], [30, 33], [34, 43], [44, 53], [53, 54], [55, 59], [59, 60], [61, 69], [70, 81], [82, 85], [86, 89], [90, 101], [102, 104], [105, 112], [112, 113], [114, 118], [119, 122], [123, 127], [127, 128]]}
{"doc_key": "ai-test-376", "ner": [[5, 5, "organisation"], [10, 11, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 10, 11, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "trial", "conducted", "by", "the", "RET", "in", "2011", "with", "facial", "recognition", "system", "cameras", "installed", "on", "trams", "ensured", "that", "people", "who", "were", "banned", "from", "boarding", "city", "trams", "could", "still", "make", "sure", "that", "they", "did", "not", "sneak", "onto", "the", "trams", "."], "sentence-detokenized": "A trial conducted by the RET in 2011 with facial recognition system cameras installed on trams ensured that people who were banned from boarding city trams could still make sure that they did not sneak onto the trams.", "token2charspan": [[0, 1], [2, 7], [8, 17], [18, 20], [21, 24], [25, 28], [29, 31], [32, 36], [37, 41], [42, 48], [49, 60], [61, 67], [68, 75], [76, 85], [86, 88], [89, 94], [95, 102], [103, 107], [108, 114], [115, 118], [119, 123], [124, 130], [131, 135], [136, 144], [145, 149], [150, 155], [156, 161], [162, 167], [168, 172], [173, 177], [178, 182], [183, 187], [188, 191], [192, 195], [196, 201], [202, 206], [207, 210], [211, 216], [216, 217]]}
{"doc_key": "ai-test-377", "ner": [[4, 5, "person"], [6, 6, "organisation"], [16, 17, "person"], [19, 20, "person"], [24, 25, "person"], [27, 28, "person"], [30, 31, "person"], [33, 34, "person"], [36, 38, "person"], [39, 40, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[4, 5, 6, 6, "role", "works_for", false, false], [16, 17, 6, 6, "role", "works_for", false, false], [19, 20, 6, 6, "role", "works_for", false, false], [24, 25, 6, 6, "role", "works_for", false, false], [27, 28, 6, 6, "role", "works_for", false, false], [30, 31, 6, 6, "role", "works_for", false, false], [33, 34, 6, 6, "role", "works_for", false, false], [36, 38, 6, 6, "role", "works_for", false, false], [39, 40, 6, 6, "role", "works_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Based", "on", "the", "popular", "Cole", "Porter", "Broadway", "musical", ",", "the", "film", "starred", "MGM", "'s", "singing", "team", "Howard", "Keel", "and", "Kathryn", "Grayson", ",", "accompanied", "by", "Ann", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Van", ",", "James", "Whitmore", ",", "Kurt", "Kasznar", "and", "Tommy", "Rall", "."], "sentence-detokenized": "Based on the popular Cole Porter Broadway musical, the film starred MGM's singing team Howard Keel and Kathryn Grayson, accompanied by Ann Miller, Keenan Wynn, Bobby Van, James Whitmore, Kurt Kasznar and Tommy Rall.", "token2charspan": [[0, 5], [6, 8], [9, 12], [13, 20], [21, 25], [26, 32], [33, 41], [42, 49], [49, 50], [51, 54], [55, 59], [60, 67], [68, 71], [71, 73], [74, 81], [82, 86], [87, 93], [94, 98], [99, 102], [103, 110], [111, 118], [118, 119], [120, 131], [132, 134], [135, 138], [139, 145], [145, 146], [147, 153], [154, 158], [158, 159], [160, 165], [166, 169], [169, 170], [171, 176], [177, 185], [185, 186], [187, 191], [192, 199], [200, 203], [204, 209], [210, 214], [214, 215]]}
{"doc_key": "ai-test-378", "ner": [[18, 21, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "applications", "should", "streamline", "call", "flows", ",", "minimise", "prompts", ",", "eliminate", "unnecessary", "duplication", "and", "allow", "for", "an", "elaborate", "mixed", "-initiative", "dialogue", "system", "that", "allows", "callers", "to", "enter", "several", "pieces", "of", "information", "in", "a", "single", "phrase", "and", "in", "any", "order", "or", "combination", "."], "sentence-detokenized": "Such applications should streamline call flows, minimise prompts, eliminate unnecessary duplication and allow for an elaborate mixed-initiative dialogue system that allows callers to enter several pieces of information in a single phrase and in any order or combination.", "token2charspan": [[0, 4], [5, 17], [18, 24], [25, 35], [36, 40], [41, 46], [46, 47], [48, 56], [57, 64], [64, 65], [66, 75], [76, 87], [88, 99], [100, 103], [104, 109], [110, 113], [114, 116], [117, 126], [127, 132], [132, 143], [144, 152], [153, 159], [160, 164], [165, 171], [172, 179], [180, 182], [183, 188], [189, 196], [197, 203], [204, 206], [207, 218], [219, 221], [222, 223], [224, 230], [231, 237], [238, 241], [242, 244], [245, 248], [249, 254], [255, 257], [258, 269], [269, 270]]}
{"doc_key": "ai-test-379", "ner": [[3, 4, "algorithm"], [7, 9, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 9, 3, 4, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Therefore", ",", "conventional", "gradient", "descent", "(", "or", "Stochastic", "gradient", "descent", ")", "methods", "can", "be", "adapted", ",", "where", "instead", "of", "taking", "a", "step", "in", "the", "direction", "of", "the", "gradient", "of", "the", "function", ",", "a", "step", "is", "taken", "in", "the", "direction", "of", "a", "vector", "chosen", "from", "the", "subgradient", "of", "the", "function", "."], "sentence-detokenized": "Therefore, conventional gradient descent (or Stochastic gradient descent) methods can be adapted, where instead of taking a step in the direction of the gradient of the function, a step is taken in the direction of a vector chosen from the subgradient of the function.", "token2charspan": [[0, 9], [9, 10], [11, 23], [24, 32], [33, 40], [41, 42], [42, 44], [45, 55], [56, 64], [65, 72], [72, 73], [74, 81], [82, 85], [86, 88], [89, 96], [96, 97], [98, 103], [104, 111], [112, 114], [115, 121], [122, 123], [124, 128], [129, 131], [132, 135], [136, 145], [146, 148], [149, 152], [153, 161], [162, 164], [165, 168], [169, 177], [177, 178], [179, 180], [181, 185], [186, 188], [189, 194], [195, 197], [198, 201], [202, 211], [212, 214], [215, 216], [217, 223], [224, 230], [231, 235], [236, 239], [240, 251], [252, 254], [255, 258], [259, 267], [267, 268]]}
{"doc_key": "ai-test-380", "ner": [[8, 10, "metrics"], [17, 17, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Assuming", "that", "the", "distortion", "is", "measured", "by", "the", "mean", "squared", "error", ",", "the", "distortion", "is", "given", "by", "D", ",:"], "sentence-detokenized": "Assuming that the distortion is measured by the mean squared error, the distortion is given by D,:", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 28], [29, 31], [32, 40], [41, 43], [44, 47], [48, 52], [53, 60], [61, 66], [66, 67], [68, 71], [72, 82], [83, 85], [86, 91], [92, 94], [95, 96], [96, 98]]}
{"doc_key": "ai-test-381", "ner": [[0, 0, "algorithm"], [4, 5, "field"], [18, 19, "task"], [21, 23, "task"], [24, 25, "task"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 4, 5, "part-of", "", false, false], [18, 19, 0, 0, "part-of", "", false, false], [21, 23, 0, 0, "part-of", "", false, false], [24, 25, 0, 0, "part-of", "", false, false], [28, 29, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["MLPs", "were", "a", "popular", "machine", "learning", "solution", "in", "the", "1980s", "and", "found", "applications", "in", "various", "fields", "such", "as", "speech", "recognition", ",", "image", "recognition", "and", "machine", "translation", "software", ",", "Neural", "networks", "."], "sentence-detokenized": "MLPs were a popular machine learning solution in the 1980s and found applications in various fields such as speech recognition, image recognition and machine translation software, Neural networks.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 19], [20, 27], [28, 36], [37, 45], [46, 48], [49, 52], [53, 58], [59, 62], [63, 68], [69, 81], [82, 84], [85, 92], [93, 99], [100, 104], [105, 107], [108, 114], [115, 126], [126, 127], [128, 133], [134, 145], [146, 149], [150, 157], [158, 169], [170, 178], [178, 179], [180, 186], [187, 195], [195, 196]]}
{"doc_key": "ai-test-382", "ner": [[0, 0, "researcher"], [2, 4, "misc"], [5, 8, "university"], [14, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 8, "physical", "", false, false], [0, 0, 5, 8, "role", "", false, false], [2, 4, 0, 0, "origin", "", false, false], [14, 17, 0, 0, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "received", "his", "PhD", "from", "the", "University", "of", "Toronto", "in", "1979", "under", "the", "supervision", "of", "C.", "Raymond", "Perrault", ","], "sentence-detokenized": "Allen received his PhD from the University of Toronto in 1979 under the supervision of C. Raymond Perrault,", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 22], [23, 27], [28, 31], [32, 42], [43, 45], [46, 53], [54, 56], [57, 61], [62, 67], [68, 71], [72, 83], [84, 86], [87, 89], [90, 97], [98, 106], [106, 107]]}
{"doc_key": "ai-test-383", "ner": [[0, 0, "product"], [4, 7, "field"], [10, 10, "product"], [12, 12, "product"], [14, 14, "product"], [20, 21, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 4, 7, "related-to", "supports", false, false], [10, 10, 4, 7, "type-of", "", true, false], [12, 12, 4, 7, "type-of", "", true, false], [14, 14, 4, 7, "type-of", "", true, false], [14, 14, 20, 21, "related-to", "converting_to", true, false], [24, 24, 4, 7, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["OpenCV", "supports", "some", "models", "from", "deep", "learning", "frameworks", "such", "as", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "after", "conversion", "to", "an", "ONNX", "model", ")", "and", "Caffe", "according", "to", "a", "defined", "list", "of", "supported", "layers", "."], "sentence-detokenized": "OpenCV supports some models from deep learning frameworks such as TensorFlow, Torch, PyTorch (after conversion to an ONNX model) and Caffe according to a defined list of supported layers.", "token2charspan": [[0, 6], [7, 15], [16, 20], [21, 27], [28, 32], [33, 37], [38, 46], [47, 57], [58, 62], [63, 65], [66, 76], [76, 77], [78, 83], [83, 84], [85, 92], [93, 94], [94, 99], [100, 110], [111, 113], [114, 116], [117, 121], [122, 127], [127, 128], [129, 132], [133, 138], [139, 148], [149, 151], [152, 153], [154, 161], [162, 166], [167, 169], [170, 179], [180, 186], [186, 187]]}
{"doc_key": "ai-test-384", "ner": [[0, 1, "researcher"], [6, 11, "organisation"], [13, 13, "organisation"], [23, 27, "organisation"], [20, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 6, 11, "role", "", false, false], [0, 1, 23, 27, "role", "", false, false], [0, 1, 20, 22, "related-to", "lectures_in", false, false], [13, 13, 6, 11, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Christensen", "was", "previously", "the", "Founding", "Chair", "of", "the", "European", "Robotics", "Research", "Network", "(", "EURON", ")", "and", "a", "Distinguished", "Lecturer", "in", "Robotics", "for", "the", "IEEE", "Robotics", "and", "Automation", "Society", "."], "sentence-detokenized": "Christensen was previously the Founding Chair of the European Robotics Research Network (EURON) and a Distinguished Lecturer in Robotics for the IEEE Robotics and Automation Society.", "token2charspan": [[0, 11], [12, 15], [16, 26], [27, 30], [31, 39], [40, 45], [46, 48], [49, 52], [53, 61], [62, 70], [71, 79], [80, 87], [88, 89], [89, 94], [94, 95], [96, 99], [100, 101], [102, 115], [116, 124], [125, 127], [128, 136], [137, 140], [141, 144], [145, 149], [150, 158], [159, 162], [163, 173], [174, 181], [181, 182]]}
{"doc_key": "ai-test-385", "ner": [[7, 7, "field"], [9, 11, "university"], [13, 13, "location"], [15, 19, "country"], [23, 23, "misc"], [25, 25, "field"], [29, 32, "organisation"], [28, 28, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[9, 11, 13, 13, "physical", "", false, false], [13, 13, 15, 19, "physical", "", false, false], [23, 23, 25, 25, "topic", "", false, false], [29, 32, 28, 28, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "received", "a", "master", "'s", "degree", "in", "mathematics", "from", "Samarkand", "State", "University", ",", "Samarkand", ",", "Uzbek", "Soviet", "Socialist", "Republic", "in", "1958", "and", "a", "doctorate", "in", "statistics", "from", "the", "Moscow", "Institute", "of", "Control", "Sciences", "in", "1964", "."], "sentence-detokenized": "He received a master's degree in mathematics from Samarkand State University, Samarkand, Uzbek Soviet Socialist Republic in 1958 and a doctorate in statistics from the Moscow Institute of Control Sciences in 1964.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 20], [20, 22], [23, 29], [30, 32], [33, 44], [45, 49], [50, 59], [60, 65], [66, 76], [76, 77], [78, 87], [87, 88], [89, 94], [95, 101], [102, 111], [112, 120], [121, 123], [124, 128], [129, 132], [133, 134], [135, 144], [145, 147], [148, 158], [159, 163], [164, 167], [168, 174], [175, 184], [185, 187], [188, 195], [196, 204], [205, 207], [208, 212], [212, 213]]}
{"doc_key": "ai-test-386", "ner": [[3, 5, "organisation"], [8, 10, "product"], [31, 33, "field"], [34, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 31, 33, "usage", "", false, false], [3, 5, 34, 36, "usage", "", false, false], [8, 10, 3, 5, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["However", ",", "work", "at", "Cycorp", "increasingly", "involves", "giving", "the", "Cyc", "system", "the", "ability", "to", "communicate", "with", "end", "users", "in", "natural", "language", "and", "assist", "in", "the", "ongoing", "process", "of", "knowledge", "creation", "through", "machine", "learning", "and", "natural", "language", "understanding", "."], "sentence-detokenized": "However, work at Cycorp increasingly involves giving the Cyc system the ability to communicate with end users in natural language and assist in the ongoing process of knowledge creation through machine learning and natural language understanding.", "token2charspan": [[0, 7], [7, 8], [9, 13], [14, 16], [17, 23], [24, 36], [37, 45], [46, 52], [53, 56], [57, 60], [61, 67], [68, 71], [72, 79], [80, 82], [83, 94], [95, 99], [100, 103], [104, 109], [110, 112], [113, 120], [121, 129], [130, 133], [134, 140], [141, 143], [144, 147], [148, 155], [156, 163], [164, 166], [167, 176], [177, 185], [186, 193], [194, 201], [202, 210], [211, 214], [215, 222], [223, 231], [232, 245], [245, 246]]}
{"doc_key": "ai-test-387", "ner": [[52, 52, "metrics"], [54, 54, "metrics"], [56, 56, "metrics"], [58, 59, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "if", "an", "optimal", "classifier", "is", "sought", "for", "the", "problem", ",", "the", "training", "dataset", "is", "used", "to", "train", "candidate", "algorithms", ",", "the", "validation", "dataset", "is", "used", "to", "compare", "their", "performance", "and", "decide", "which", "one", "to", "adopt", ",", "and", "finally", "the", "testing", "dataset", "is", "used", "to", "obtain", "performance", "characteristics", "such", "as", "accuracy", ",", "sensitivity", ",", "specificity", ",", "F-", "measure", ",", "etc", "."], "sentence-detokenized": "For example, if an optimal classifier is sought for the problem, the training dataset is used to train candidate algorithms, the validation dataset is used to compare their performance and decide which one to adopt, and finally the testing dataset is used to obtain performance characteristics such as accuracy, sensitivity, specificity, F-measure, etc.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 18], [19, 26], [27, 37], [38, 40], [41, 47], [48, 51], [52, 55], [56, 63], [63, 64], [65, 68], [69, 77], [78, 85], [86, 88], [89, 93], [94, 96], [97, 102], [103, 112], [113, 123], [123, 124], [125, 128], [129, 139], [140, 147], [148, 150], [151, 155], [156, 158], [159, 166], [167, 172], [173, 184], [185, 188], [189, 195], [196, 201], [202, 205], [206, 208], [209, 214], [214, 215], [216, 219], [220, 227], [228, 231], [232, 239], [240, 247], [248, 250], [251, 255], [256, 258], [259, 265], [266, 277], [278, 293], [294, 298], [299, 301], [302, 310], [310, 311], [312, 323], [323, 324], [325, 336], [336, 337], [338, 340], [340, 347], [347, 348], [349, 352], [352, 353]]}
{"doc_key": "ai-test-388", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "squared", "error", "is", "0.15", "."], "sentence-detokenized": "The mean squared error is 0.15.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 25], [26, 30], [30, 31]]}
{"doc_key": "ai-test-389", "ner": [[3, 4, "misc"], [8, 8, "organisation"], [12, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 3, 4, "role", "", false, false], [12, 12, 3, 4, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1979", "a", "Micromouse", "competition", "was", "organised", "by", "IEEE", "as", "shown", "in", "Spectrum", "magazine", "."], "sentence-detokenized": "In 1979 a Micromouse competition was organised by IEEE as shown in Spectrum magazine.", "token2charspan": [[0, 2], [3, 7], [8, 9], [10, 20], [21, 32], [33, 36], [37, 46], [47, 49], [50, 54], [55, 57], [58, 63], [64, 66], [67, 75], [76, 84], [84, 85]]}
{"doc_key": "ai-test-390", "ner": [[0, 1, "algorithm"], [6, 7, "field"], [11, 13, "task"], [15, 16, "task"], [18, 19, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 6, 7, "part-of", "", false, false], [11, 13, 6, 7, "part-of", "task_part_of_field", false, false], [15, 16, 6, 7, "part-of", "task_part_of_field", false, false], [18, 19, 6, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Gabor", "space", "is", "very", "useful", "in", "image", "processing", "applications", "such", "as", "optical", "character", "recognition", ",", "iris", "recognition", "and", "fingerprint", "recognition", "."], "sentence-detokenized": "Gabor space is very useful in image processing applications such as optical character recognition, iris recognition and fingerprint recognition.", "token2charspan": [[0, 5], [6, 11], [12, 14], [15, 19], [20, 26], [27, 29], [30, 35], [36, 46], [47, 59], [60, 64], [65, 67], [68, 75], [76, 85], [86, 97], [97, 98], [99, 103], [104, 115], [116, 119], [120, 131], [132, 143], [143, 144]]}
{"doc_key": "ai-test-391", "ner": [[7, 7, "programlang"], [6, 9, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", "through", "high", "-", "level", "interfaces", "to", "Java", "and", "Tcl", "."], "sentence-detokenized": "or through high-level interfaces to Java and Tcl.", "token2charspan": [[0, 2], [3, 10], [11, 15], [15, 16], [16, 21], [22, 32], [33, 35], [36, 40], [41, 44], [45, 48], [48, 49]]}
{"doc_key": "ai-test-392", "ner": [[10, 11, "algorithm"], [17, 19, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 17, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "recent", "research", ",", "kernel", "-", "based", "methods", "such", "as", "support", "vector", "machines", "have", "shown", "superior", "performance", "under", "supervised", "conditions", "."], "sentence-detokenized": "In recent research, kernel-based methods such as support vector machines have shown superior performance under supervised conditions.", "token2charspan": [[0, 2], [3, 9], [10, 18], [18, 19], [20, 26], [26, 27], [27, 32], [33, 40], [41, 45], [46, 48], [49, 56], [57, 63], [64, 72], [73, 77], [78, 83], [84, 92], [93, 104], [105, 110], [111, 121], [122, 132], [132, 133]]}
{"doc_key": "ai-test-393", "ner": [[19, 20, "misc"], [26, 27, "researcher"], [28, 28, "researcher"], [34, 35, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[26, 27, 34, 35, "usage", "", false, false], [28, 28, 34, 35, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["To", "illustrate", "the", "basic", "principles", "of", "the", "bagging", "process", ",", "the", "following", "is", "an", "analysis", "of", "the", "relationship", "between", "ozone", "and", "temperature", "(", "data", "taken", "from", "Rousseeuw", "and", "Leroy", "(", "1986", ")", ",", "analysis", "in", "R", ")", "."], "sentence-detokenized": "To illustrate the basic principles of the bagging process, the following is an analysis of the relationship between ozone and temperature (data taken from Rousseeuw and Leroy (1986), analysis in R).", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 23], [24, 34], [35, 37], [38, 41], [42, 49], [50, 57], [57, 58], [59, 62], [63, 72], [73, 75], [76, 78], [79, 87], [88, 90], [91, 94], [95, 107], [108, 115], [116, 121], [122, 125], [126, 137], [138, 139], [139, 143], [144, 149], [150, 154], [155, 164], [165, 168], [169, 174], [175, 176], [176, 180], [180, 181], [181, 182], [183, 191], [192, 194], [195, 196], [196, 197], [197, 198]]}
{"doc_key": "ai-test-394", "ner": [[0, 3, "organisation"], [11, 11, "product"], [18, 19, "product"], [21, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 11, 0, 3, "artifact", "", false, false], [18, 19, 0, 3, "artifact", "", false, false], [21, 23, 0, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Denso", "Wave", "is", "a", "subsidiary", "that", "manufactures", "automatic", "identification", "products", "(", "barcode", "readers", "and", "related", "products", ")", ",", "industrial", "robots", "and", "programmable", "logic", "controllers", "."], "sentence-detokenized": "Denso Wave is a subsidiary that manufactures automatic identification products (barcode readers and related products), industrial robots and programmable logic controllers.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 15], [16, 26], [27, 31], [32, 44], [45, 54], [55, 69], [70, 78], [79, 80], [80, 87], [88, 95], [96, 99], [100, 107], [108, 116], [116, 117], [117, 118], [119, 129], [130, 136], [137, 140], [141, 153], [154, 159], [160, 171], [171, 172]]}
{"doc_key": "ai-test-395", "ner": [[0, 5, "metrics"], [10, 10, "metrics"], [18, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 5, 18, 18, "compare", "", false, false], [10, 10, 0, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Whereas", "in", "bilingual", "assessment", "the", "understudy", "simply", "calculates", "n-", "gram", "precision", "by", "giving", "equal", "weight", "to", "each", ",", "NIST", "also", "calculates", "how", "informative", "a", "given", "n-", "gram", "is", "."], "sentence-detokenized": "Whereas in bilingual assessment the understudy simply calculates n-gram precision by giving equal weight to each, NIST also calculates how informative a given n-gram is.", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 31], [32, 35], [36, 46], [47, 53], [54, 64], [65, 67], [67, 71], [72, 81], [82, 84], [85, 91], [92, 97], [98, 104], [105, 107], [108, 112], [112, 113], [114, 118], [119, 123], [124, 134], [135, 138], [139, 150], [151, 152], [153, 158], [159, 161], [161, 165], [166, 168], [168, 169]]}
{"doc_key": "ai-test-396", "ner": [[15, 15, "algorithm"], [17, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "particular", ",", "they", "are", "used", "when", "calculating", "the", "probability", "of", "a", "tree", "(", "in", "Bayesian", "and", "maximum", "likelihood", "approaches", "to", "tree", "estimation", ")", "and", "to", "estimate", "the", "evolutionary", "distance", "between", "sequences", "from", "observed", "differences", "between", "sequences", "."], "sentence-detokenized": "In particular, they are used when calculating the probability of a tree (in Bayesian and maximum likelihood approaches to tree estimation) and to estimate the evolutionary distance between sequences from observed differences between sequences.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 19], [20, 23], [24, 28], [29, 33], [34, 45], [46, 49], [50, 61], [62, 64], [65, 66], [67, 71], [72, 73], [73, 75], [76, 84], [85, 88], [89, 96], [97, 107], [108, 118], [119, 121], [122, 126], [127, 137], [137, 138], [139, 142], [143, 145], [146, 154], [155, 158], [159, 171], [172, 180], [181, 188], [189, 198], [199, 203], [204, 212], [213, 224], [225, 232], [233, 242], [242, 243]]}
{"doc_key": "ai-test-397", "ner": [[0, 3, "conference"], [20, 21, "misc"], [23, 23, "misc"], [41, 48, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 20, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Audio", "Engineering", "Society", "recommends", "a", "sampling", "rate", "of", "48", "kHz", "for", "most", "applications", ",", "but", "accepts", "44.1", "kHz", "for", "Compact", "Disc", "(", "CD", ")", "and", "other", "consumer", "uses", ",", "32", "kHz", "for", "transmission", "-", "related", "applications", ",", "and", "96", "kHz", "for", "higher", "bandwidth", "or", "a", "relaxed", "anti-aliasing", "filter", "."], "sentence-detokenized": "The Audio Engineering Society recommends a sampling rate of 48 kHz for most applications, but accepts 44.1 kHz for Compact Disc (CD) and other consumer uses, 32 kHz for transmission-related applications, and 96 kHz for higher bandwidth or a relaxed anti-aliasing filter.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 29], [30, 40], [41, 42], [43, 51], [52, 56], [57, 59], [60, 62], [63, 66], [67, 70], [71, 75], [76, 88], [88, 89], [90, 93], [94, 101], [102, 106], [107, 110], [111, 114], [115, 122], [123, 127], [128, 129], [129, 131], [131, 132], [133, 136], [137, 142], [143, 151], [152, 156], [156, 157], [158, 160], [161, 164], [165, 168], [169, 181], [181, 182], [182, 189], [190, 202], [202, 203], [204, 207], [208, 210], [211, 214], [215, 218], [219, 225], [226, 235], [236, 238], [239, 240], [241, 248], [249, 262], [263, 269], [269, 270]]}
{"doc_key": "ai-test-398", "ner": [[5, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Resources", "have", "been", "prepared", "for", "Word", "Net", "for", "the", "sensemaking", "of", "words", "and", "concepts", "{", "{", "cite", "journal"], "sentence-detokenized": "Resources have been prepared for WordNet for the sensemaking of words and concepts {{cite journal", "token2charspan": [[0, 9], [10, 14], [15, 19], [20, 28], [29, 32], [33, 37], [37, 40], [41, 44], [45, 48], [49, 60], [61, 63], [64, 69], [70, 73], [74, 82], [83, 84], [84, 85], [85, 89], [90, 97]]}
{"doc_key": "ai-test-399", "ner": [[0, 4, "misc"], [22, 23, "person"], [28, 31, "person"], [37, 40, "person"], [48, 51, "organisation"], [62, 67, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[28, 31, 37, 40, "role", "acts_in", false, false], [48, 51, 37, 40, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["On", "the", "red", "-green", "anaglyph", ",", "viewers", "were", "presented", "with", "three", "reels", "of", "tests", "that", "included", "rural", "scenes", ",", "test", "shots", "of", "Marie", "Doro", ",", "a", "segment", "with", "John", "B", ".", "Mason", "playing", "a", "series", "of", "passages", "from", "Jim", "the", "Penman", "(", "a", "film", "released", "that", "year", "by", "Famous", "Players", "-", "Lasky", "but", "not", "in", "3D", ")", ",", "Oriental", "dancers", ",", "and", "a", "reel", "view", "of", "Niagara", "Falls", "."], "sentence-detokenized": "On the red-green anaglyph, viewers were presented with three reels of tests that included rural scenes, test shots of Marie Doro, a segment with John B. Mason playing a series of passages from Jim the Penman (a film released that year by Famous Players-Lasky but not in 3D), Oriental dancers, and a reel view of Niagara Falls.", "token2charspan": [[0, 2], [3, 6], [7, 10], [10, 16], [17, 25], [25, 26], [27, 34], [35, 39], [40, 49], [50, 54], [55, 60], [61, 66], [67, 69], [70, 75], [76, 80], [81, 89], [90, 95], [96, 102], [102, 103], [104, 108], [109, 114], [115, 117], [118, 123], [124, 128], [128, 129], [130, 131], [132, 139], [140, 144], [145, 149], [150, 151], [151, 152], [153, 158], [159, 166], [167, 168], [169, 175], [176, 178], [179, 187], [188, 192], [193, 196], [197, 200], [201, 207], [208, 209], [209, 210], [211, 215], [216, 224], [225, 229], [230, 234], [235, 237], [238, 244], [245, 252], [252, 253], [253, 258], [259, 262], [263, 266], [267, 269], [270, 272], [272, 273], [273, 274], [275, 283], [284, 291], [291, 292], [293, 296], [297, 298], [299, 303], [304, 308], [309, 311], [312, 319], [320, 325], [325, 326]]}
{"doc_key": "ai-test-400", "ner": [[7, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "special", "way", "of", "applying", "maximum", "likelihood", "estimation", "for", "this", "problem", "."], "sentence-detokenized": "This is a special way of applying maximum likelihood estimation for this problem.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 17], [18, 21], [22, 24], [25, 33], [34, 41], [42, 52], [53, 63], [64, 67], [68, 72], [73, 80], [80, 81]]}
{"doc_key": "ai-test-401", "ner": [[2, 6, "product"], [11, 11, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "integrates", "browser-", "friendly", "Web", "Servers", "and", "features", "of", "sitemaps", "and", "RSS", "feeds", "into", "a", "decentralised", "mechanism", "for", "computational", "biologists", "and", "bioinformaticians", "to", "openly", "publish", "and", "retrieve", "metadata", "about", "biomedical", "resources", "."], "sentence-detokenized": "It integrates browser-friendly Web Servers and features of sitemaps and RSS feeds into a decentralised mechanism for computational biologists and bioinformaticians to openly publish and retrieve metadata about biomedical resources.", "token2charspan": [[0, 2], [3, 13], [14, 22], [22, 30], [31, 34], [35, 42], [43, 46], [47, 55], [56, 58], [59, 67], [68, 71], [72, 75], [76, 81], [82, 86], [87, 88], [89, 102], [103, 112], [113, 116], [117, 130], [131, 141], [142, 145], [146, 163], [164, 166], [167, 173], [174, 181], [182, 185], [186, 194], [195, 203], [204, 209], [210, 220], [221, 230], [230, 231]]}
{"doc_key": "ai-test-402", "ner": [[4, 11, "misc"], [13, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "covered", "by", "American", "National", "Standards", "Institute", "/", "NISO", "standard", "Z39.50", "and", "International", "Organisation", "for", "Standardisation", "standard", "23950", "."], "sentence-detokenized": "It is covered by American National Standards Institute/NISO standard Z39.50 and International Organisation for Standardisation standard 23950.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 25], [26, 34], [35, 44], [45, 54], [54, 55], [55, 59], [60, 68], [69, 75], [76, 79], [80, 93], [94, 106], [107, 110], [111, 126], [127, 135], [136, 141], [141, 142]]}
{"doc_key": "ai-test-403", "ner": [[13, 16, "misc"], [23, 23, "metrics"], [17, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "encoder", "and", "decoder", "are", "trained", "to", "take", "an", "utterance", "and", "reproduce", "the", "one", "-", "shot", "distribution", "of", "a", "corresponding", "paraphrase", ",", "minimising", "complexity", "using", "simple", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The encoder and decoder are trained to take an utterance and reproduce the one-shot distribution of a corresponding paraphrase, minimising complexity using simple stochastic gradient descent.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 27], [28, 35], [36, 38], [39, 43], [44, 46], [47, 56], [57, 60], [61, 70], [71, 74], [75, 78], [78, 79], [79, 83], [84, 96], [97, 99], [100, 101], [102, 115], [116, 126], [126, 127], [128, 138], [139, 149], [150, 155], [156, 162], [163, 173], [174, 182], [183, 190], [190, 191]]}
{"doc_key": "ai-test-404", "ner": [[4, 5, "field"], [8, 10, "task"], [12, 17, "task"], [28, 32, "task"], [34, 40, "task"], [42, 47, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 10, 4, 5, "part-of", "task_part_of_field", false, false], [12, 17, 4, 5, "part-of", "task_part_of_field", false, false], [28, 32, 4, 5, "part-of", "task_part_of_field", false, false], [34, 40, 4, 5, "part-of", "task_part_of_field", false, false], [42, 47, 4, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "typical", "applications", "of", "pattern", "recognition", "techniques", "are", "automatic", "speech", "recognition", ",", "classification", "of", "text", "into", "various", "categories", "(", "e.g.", "spam", "/", "non", "-spam", "e-mail", "messages", ")", ",", "handwriting", "recognition", "on", "postal", "envelopes", ",", "automatic", "recognition", "of", "images", "of", "human", "faces", "or", "handwriting", "image", "extraction", "from", "medical", "forms", "."], "sentence-detokenized": "Other typical applications of pattern recognition techniques are automatic speech recognition, classification of text into various categories (e.g. spam/non-spam e-mail messages), handwriting recognition on postal envelopes, automatic recognition of images of human faces or handwriting image extraction from medical forms.", "token2charspan": [[0, 5], [6, 13], [14, 26], [27, 29], [30, 37], [38, 49], [50, 60], [61, 64], [65, 74], [75, 81], [82, 93], [93, 94], [95, 109], [110, 112], [113, 117], [118, 122], [123, 130], [131, 141], [142, 143], [143, 147], [148, 152], [152, 153], [153, 156], [156, 161], [162, 168], [169, 177], [177, 178], [178, 179], [180, 191], [192, 203], [204, 206], [207, 213], [214, 223], [223, 224], [225, 234], [235, 246], [247, 249], [250, 256], [257, 259], [260, 265], [266, 271], [272, 274], [275, 286], [287, 292], [293, 303], [304, 308], [309, 316], [317, 322], [322, 323]]}
{"doc_key": "ai-test-405", "ner": [[0, 1, "algorithm"], [10, 11, "field"], [13, 14, "task"], [16, 17, "task"], [19, 24, "task"], [23, 27, "task"], [7, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 11, 0, 1, "usage", "", false, false], [13, 14, 0, 1, "usage", "", false, false], [16, 17, 0, 1, "usage", "", false, false], [19, 24, 0, 1, "usage", "", false, false], [23, 27, 0, 1, "usage", "", false, false], [7, 31, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Neural", "networks", "have", "been", "used", "in", "tasks", "as", "diverse", "as", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "social", "network", "filtering", ",", "playing", "board", "and", "video", "games", ",", "and", "medical", "diagnosis", "."], "sentence-detokenized": "Neural networks have been used in tasks as diverse as computer vision, speech recognition, machine translation, social network filtering, playing board and video games, and medical diagnosis.", "token2charspan": [[0, 6], [7, 15], [16, 20], [21, 25], [26, 30], [31, 33], [34, 39], [40, 42], [43, 50], [51, 53], [54, 62], [63, 69], [69, 70], [71, 77], [78, 89], [89, 90], [91, 98], [99, 110], [110, 111], [112, 118], [119, 126], [127, 136], [136, 137], [138, 145], [146, 151], [152, 155], [156, 161], [162, 167], [167, 168], [169, 172], [173, 180], [181, 190], [190, 191]]}
{"doc_key": "ai-test-406", "ner": [[2, 3, "organisation"], [4, 4, "product"], [13, 13, "product"], [17, 17, "organisation"], [18, 19, "product"], [21, 21, "product"], [23, 25, "product"], [27, 27, "product"], [29, 29, "programlang"], [38, 39, "field"], [43, 43, "product"], [48, 48, "algorithm"], [50, 50, "algorithm"], [52, 52, "algorithm"], [56, 56, "product"], [64, 66, "task"], [70, 71, "algorithm"], [75, 75, "product"], [77, 77, "product"], [79, 81, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "relations": [[4, 4, 2, 3, "origin", "", false, false], [4, 4, 13, 13, "named", "same", false, false], [4, 4, 43, 43, "named", "same", false, false], [29, 29, 38, 39, "related-to", "used_for", false, false], [48, 48, 29, 29, "part-of", "", true, false], [48, 48, 43, 43, "origin", "", true, false], [50, 50, 29, 29, "part-of", "", true, false], [50, 50, 43, 43, "origin", "", true, false], [52, 52, 29, 29, "part-of", "", true, false], [52, 52, 43, 43, "origin", "", true, false], [56, 56, 64, 66, "related-to", "used_for", false, false], [70, 71, 56, 56, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Examples", "include", "Salford", "Systems", "CART", "(", "which", "licences", "proprietary", "code", "from", "the", "original", "CART", "authors", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "an", "open", "-", "source", "software", "environment", "for", "statistical", "computing", "that", "includes", "several", "CART", "implementations", "such", "as", "the", "rpart", ",", "party", "and", "randomForest", "packages", ")", ",", "Weka", "(", "a", "free", "and", "open", "-", "source", "data", "mining", "package", ",", "includes", "many", "decision", "tree", "algorithms", ")", ",", "Orange", ",", "KNIME", ",", "Microsoft", "SQL", "Server", "programming", "language", ")", "."], "sentence-detokenized": "Examples include Salford Systems CART (which licences proprietary code from the original CART authors), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (an open-source software environment for statistical computing that includes several CART implementations such as the rpart, party and randomForest packages), Weka (a free and open-source data mining package, includes many decision tree algorithms), Orange, KNIME, Microsoft SQL Server programming language).", "token2charspan": [[0, 8], [9, 16], [17, 24], [25, 32], [33, 37], [38, 39], [39, 44], [45, 53], [54, 65], [66, 70], [71, 75], [76, 79], [80, 88], [89, 93], [94, 101], [101, 102], [102, 103], [104, 107], [108, 112], [113, 120], [120, 121], [122, 132], [132, 133], [134, 137], [138, 148], [149, 154], [154, 155], [156, 162], [162, 163], [164, 165], [166, 167], [167, 169], [170, 174], [174, 175], [175, 181], [182, 190], [191, 202], [203, 206], [207, 218], [219, 228], [229, 233], [234, 242], [243, 250], [251, 255], [256, 271], [272, 276], [277, 279], [280, 283], [284, 289], [289, 290], [291, 296], [297, 300], [301, 313], [314, 322], [322, 323], [323, 324], [325, 329], [330, 331], [331, 332], [333, 337], [338, 341], [342, 346], [346, 347], [347, 353], [354, 358], [359, 365], [366, 373], [373, 374], [375, 383], [384, 388], [389, 397], [398, 402], [403, 413], [413, 414], [414, 415], [416, 422], [422, 423], [424, 429], [429, 430], [431, 440], [441, 444], [445, 451], [452, 463], [464, 472], [472, 473], [473, 474]]}
{"doc_key": "ai-test-407", "ner": [[0, 2, "algorithm"], [4, 7, "algorithm"], [12, 13, "researcher"], [15, 16, "university"], [18, 19, "researcher"], [20, 24, "organisation"], [26, 26, "organisation"], [34, 36, "researcher"], [33, 41, "researcher"], [42, 44, "organisation"], [56, 61, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 12, 13, "origin", "", false, false], [0, 2, 18, 19, "origin", "", false, false], [0, 2, 34, 36, "origin", "", false, false], [0, 2, 33, 41, "origin", "", false, false], [4, 7, 0, 2, "named", "", false, false], [12, 13, 15, 16, "physical", "", false, false], [12, 13, 15, 16, "role", "", false, false], [18, 19, 20, 24, "physical", "", false, false], [18, 19, 20, 24, "role", "", false, false], [26, 26, 20, 24, "named", "", false, false], [34, 36, 42, 44, "physical", "", false, false], [34, 36, 42, 44, "role", "", false, false], [33, 41, 42, 44, "physical", "", false, false], [33, 41, 42, 44, "role", "", false, false], [56, 61, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Linear", "predictive", "coding", "(", "LPC", ")", "was", "first", "developed", "in", "1966", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", ",", "and", "then", "further", "developed", "by", "Bishnu", "S.", "Atal", "and", "Manfred", "R.", "Schroeder", "at", "Bell", "Labs", "in", "the", "early", "to", "mid-1970s", ",", "becoming", "the", "basis", "for", "the", "first", "speech", "synthesiser", "DSP", "chips", "in", "the", "late", "1970s", "."], "sentence-detokenized": "Linear predictive coding (LPC) was first developed in 1966 by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT), and then further developed by Bishnu S. Atal and Manfred R. Schroeder at Bell Labs in the early to mid-1970s, becoming the basis for the first speech synthesiser DSP chips in the late 1970s.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [31, 34], [35, 40], [41, 50], [51, 53], [54, 58], [59, 61], [62, 70], [71, 78], [79, 81], [82, 88], [89, 99], [100, 103], [104, 109], [110, 115], [116, 118], [119, 125], [126, 135], [136, 139], [140, 149], [150, 151], [151, 154], [154, 155], [155, 156], [157, 160], [161, 165], [166, 173], [174, 183], [184, 186], [187, 193], [194, 196], [197, 201], [202, 205], [206, 213], [214, 216], [217, 226], [227, 229], [230, 234], [235, 239], [240, 242], [243, 246], [247, 252], [253, 255], [256, 265], [265, 266], [267, 275], [276, 279], [280, 285], [286, 289], [290, 293], [294, 299], [300, 306], [307, 318], [319, 322], [323, 328], [329, 331], [332, 335], [336, 340], [341, 346], [346, 347]]}
{"doc_key": "ai-test-408", "ner": [[0, 3, "metrics"], [8, 8, "metrics"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 0, 3, "part-of", "", false, false], [10, 10, 0, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "F", "-", "score", "is", "a", "combination", "of", "precision", "and", "recall", "and", "provides", "a", "single", "score", "."], "sentence-detokenized": "The F-score is a combination of precision and recall and provides a single score.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 16], [17, 28], [29, 31], [32, 41], [42, 45], [46, 52], [53, 56], [57, 65], [66, 67], [68, 74], [75, 80], [80, 81]]}
{"doc_key": "ai-test-409", "ner": [[0, 1, "field"], [5, 10, "task"], [12, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 10, 0, 1, "part-of", "task_part_of_field", false, false], [12, 18, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Image", "analysis", "tasks", "can", "be", "as", "simple", "as", "reading", "barcode", "labels", "or", "as", "complex", "as", "a", "face", "recognition", "system", "."], "sentence-detokenized": "Image analysis tasks can be as simple as reading barcode labels or as complex as a face recognition system.", "token2charspan": [[0, 5], [6, 14], [15, 20], [21, 24], [25, 27], [28, 30], [31, 37], [38, 40], [41, 48], [49, 56], [57, 63], [64, 66], [67, 69], [70, 77], [78, 80], [81, 82], [83, 87], [88, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-test-410", "ner": [[3, 8, "algorithm"], [26, 27, "algorithm"], [34, 36, "algorithm"], [39, 39, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[34, 36, 26, 27, "type-of", "", false, false], [39, 39, 34, 36, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "special", "case", "of", "linear", "support", "-", "vector", "machines", "can", "be", "solved", "more", "efficiently", "by", "the", "same", "type", "of", "algorithms", "to", "optimise", "its", "close", "cousin", ",", "logistic", "regression", ";", "this", "class", "of", "algorithms", "includes", "Stochastic", "gradient", "descent", "(", "e.g.", "PEGASOS", ")", "."], "sentence-detokenized": "The special case of linear support-vector machines can be solved more efficiently by the same type of algorithms to optimise its close cousin, logistic regression; this class of algorithms includes Stochastic gradient descent (e.g. PEGASOS).", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 19], [20, 26], [27, 34], [34, 35], [35, 41], [42, 50], [51, 54], [55, 57], [58, 64], [65, 69], [70, 81], [82, 84], [85, 88], [89, 93], [94, 98], [99, 101], [102, 112], [113, 115], [116, 124], [125, 128], [129, 134], [135, 141], [141, 142], [143, 151], [152, 162], [162, 163], [164, 168], [169, 174], [175, 177], [178, 188], [189, 197], [198, 208], [209, 217], [218, 225], [226, 227], [227, 231], [232, 239], [239, 240], [240, 241]]}
{"doc_key": "ai-test-411", "ner": [[1, 1, "product"], [4, 4, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 4, 4, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["When", "Siri", "on", "an", "iOS", "device", "is", "asked", "if", "you", "have", "a", "pet", ",", "one", "of", "the", "answers", "is", "I", "used", "to", "have", "an", "AIBO", "."], "sentence-detokenized": "When Siri on an iOS device is asked if you have a pet, one of the answers is I used to have an AIBO.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 15], [16, 19], [20, 26], [27, 29], [30, 35], [36, 38], [39, 42], [43, 47], [48, 49], [50, 53], [53, 54], [55, 58], [59, 61], [62, 65], [66, 73], [74, 76], [77, 78], [79, 83], [84, 86], [87, 91], [92, 94], [95, 99], [99, 100]]}
{"doc_key": "ai-test-412", "ner": [[0, 2, "task"], [4, 8, "metrics"], [10, 12, "metrics"], [13, 13, "metrics"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 8, 0, 2, "part-of", "", false, false], [10, 12, 4, 8, "named", "", false, false], [13, 13, 0, 2, "part-of", "", false, false], [16, 16, 13, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "information", "retrieval", ",", "the", "positive", "predictive", "value", "is", "called", "precision", "and", "the", "sensitivity", "is", "called", "recall", "."], "sentence-detokenized": "In information retrieval, the positive predictive value is called precision and the sensitivity is called recall.", "token2charspan": [[0, 2], [3, 14], [15, 24], [24, 25], [26, 29], [30, 38], [39, 49], [50, 55], [56, 58], [59, 65], [66, 75], [76, 79], [80, 83], [84, 95], [96, 98], [99, 105], [106, 112], [112, 113]]}
{"doc_key": "ai-test-413", "ner": [[9, 10, "field"], [12, 12, "task"], [14, 14, "task"], [16, 17, "task"], [31, 32, "task"], [34, 34, "task"], [36, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 12, 9, 10, "part-of", "task_part_of_field", false, false], [14, 14, 9, 10, "part-of", "task_part_of_field", false, false], [16, 17, 9, 10, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["His", "research", "has", "particularly", "focused", "on", "areas", "such", "as", "text", "mining", "(", "inference", ",", "categorisation", ",", "novelty", "detection", ")", "and", "new", "theoretical", "frameworks", "such", "as", "unified", "utility", "-", "based", "theory", "bridging", "information", "retrieval", ",", "Auto-summarisation", ",", "free", "text", "Question", "Answering", "and", "related", "tasks", "."], "sentence-detokenized": "His research has particularly focused on areas such as text mining (inference, categorisation, novelty detection) and new theoretical frameworks such as unified utility-based theory bridging information retrieval, Auto-summarisation, free text Question Answering and related tasks.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 29], [30, 37], [38, 40], [41, 46], [47, 51], [52, 54], [55, 59], [60, 66], [67, 68], [68, 77], [77, 78], [79, 93], [93, 94], [95, 102], [103, 112], [112, 113], [114, 117], [118, 121], [122, 133], [134, 144], [145, 149], [150, 152], [153, 160], [161, 168], [168, 169], [169, 174], [175, 181], [182, 190], [191, 202], [203, 212], [212, 213], [214, 232], [232, 233], [234, 238], [239, 243], [244, 252], [253, 262], [263, 266], [267, 274], [275, 280], [280, 281]]}
{"doc_key": "ai-test-414", "ner": [[0, 1, "product"], [6, 7, "product"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 0, 1, "part-of", "", false, false], [15, 16, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Delta", "robots", "have", "base", "-", "mounted", "rotary", "actuators", "that", "move", "a", "light", ",", "rigid", ",", "parallelogram", "arm", "."], "sentence-detokenized": "Delta robots have base-mounted rotary actuators that move a light, rigid, parallelogram arm.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 22], [22, 23], [23, 30], [31, 37], [38, 47], [48, 52], [53, 57], [58, 59], [60, 65], [65, 66], [67, 72], [72, 73], [74, 87], [88, 91], [91, 92]]}
{"doc_key": "ai-test-415", "ner": [[6, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated in a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [64, 66], [67, 76], [77, 83], [84, 86], [87, 94], [94, 95]]}
{"doc_key": "ai-test-416", "ner": [[3, 3, "field"], [29, 30, "task"], [36, 37, "task"], [42, 44, "task"], [46, 48, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[29, 30, 3, 3, "part-of", "task_part_of_field", false, false], [36, 37, 3, 3, "part-of", "task_part_of_field", false, false], [42, 44, 3, 3, "part-of", "task_part_of_field", false, false], [46, 48, 3, 3, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "actual", "data", "mining", "task", "is", "the", "semi-automated", "or", "automated", "analysis", "of", "large", "amounts", "of", "data", "to", "extract", "unknown", ",", "interesting", "patterns", "such", "as", "groups", "of", "data", "records", "(", "cluster", "analysis", ")", ",", "unusual", "records", "(", "anomaly", "detection", ")", "and", "dependencies", "(", "association", "rule", "mining", ",", "sequential", "pattern", "mining", ")", "."], "sentence-detokenized": "The actual data mining task is the semi-automated or automated analysis of large amounts of data to extract unknown, interesting patterns such as groups of data records (cluster analysis), unusual records (anomaly detection) and dependencies (association rule mining, sequential pattern mining).", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 22], [23, 27], [28, 30], [31, 34], [35, 49], [50, 52], [53, 62], [63, 71], [72, 74], [75, 80], [81, 88], [89, 91], [92, 96], [97, 99], [100, 107], [108, 115], [115, 116], [117, 128], [129, 137], [138, 142], [143, 145], [146, 152], [153, 155], [156, 160], [161, 168], [169, 170], [170, 177], [178, 186], [186, 187], [187, 188], [189, 196], [197, 204], [205, 206], [206, 213], [214, 223], [223, 224], [225, 228], [229, 241], [242, 243], [243, 254], [255, 259], [260, 266], [266, 267], [268, 278], [279, 286], [287, 293], [293, 294], [294, 295]]}
{"doc_key": "ai-test-417", "ner": [[11, 12, "product"], [0, 1, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sentiment", "analysis", "has", "proven", "to", "be", "a", "valuable", "technique", "for", "a", "recommender", "system", "."], "sentence-detokenized": "Sentiment analysis has proven to be a valuable technique for a recommender system.", "token2charspan": [[0, 9], [10, 18], [19, 22], [23, 29], [30, 32], [33, 35], [36, 37], [38, 46], [47, 56], [57, 60], [61, 62], [63, 74], [75, 81], [81, 82]]}
{"doc_key": "ai-test-418", "ner": [[2, 3, "misc"], [11, 11, "product"], [29, 29, "organisation"], [32, 34, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 11, 11, "usage", "", false, false], [29, 29, 32, 34, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Fortunately", ",", "the", "Germans", "had", "chosen", "the", "operating", "frequency", "of", "the", "Wotan", "system", "very", "badly", ";", "it", "operated", "at", "45", "MHz", ",", "the", "frequency", "of", "the", "powerful", "but", "dormant", "BBC", "television", "transmitter", "at", "Alexandra", "Palace", "."], "sentence-detokenized": "Fortunately, the Germans had chosen the operating frequency of the Wotan system very badly; it operated at 45 MHz, the frequency of the powerful but dormant BBC television transmitter at Alexandra Palace.", "token2charspan": [[0, 11], [11, 12], [13, 16], [17, 24], [25, 28], [29, 35], [36, 39], [40, 49], [50, 59], [60, 62], [63, 66], [67, 72], [73, 79], [80, 84], [85, 90], [90, 91], [92, 94], [95, 103], [104, 106], [107, 109], [110, 113], [113, 114], [115, 118], [119, 128], [129, 131], [132, 135], [136, 144], [145, 148], [149, 156], [157, 160], [161, 171], [172, 183], [184, 186], [187, 196], [197, 203], [203, 204]]}
{"doc_key": "ai-test-419", "ner": [[6, 12, "metrics"], [14, 15, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be formulated in a 2 \u00d7 2 contingency table or confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 34], [35, 37], [38, 39], [40, 41], [42, 43], [44, 45], [46, 57], [58, 63], [64, 66], [67, 76], [77, 83], [84, 86], [87, 94], [94, 95]]}
{"doc_key": "ai-test-420", "ner": [[0, 3, "misc"], [8, 9, "misc"], [12, 12, "product"], [14, 14, "product"], [16, 18, "product"], [27, 28, "misc"], [40, 44, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 12, 8, 9, "usage", "", false, false], [14, 14, 8, 9, "usage", "", false, false], [16, 18, 14, 14, "named", "", false, false], [27, 28, 8, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "Semantic", "Web", "applications", "and", "relatively", "popular", "implementations", "of", "RDF", "such", "as", "RSS", "and", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "resources", "tend", "to", "be", "deliberately", "represented", "by", "URIs", "that", "point", "to", "and", "can", "be", "used", "to", "access", "actual", "data", "on", "the", "World", "Wide", "Web", "."], "sentence-detokenized": "In Semantic Web applications and relatively popular implementations of RDF such as RSS and FOAF (Friend a Friend), resources tend to be deliberately represented by URIs that point to and can be used to access actual data on the World Wide Web.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 28], [29, 32], [33, 43], [44, 51], [52, 67], [68, 70], [71, 74], [75, 79], [80, 82], [83, 86], [87, 90], [91, 95], [96, 97], [97, 103], [104, 105], [106, 112], [112, 113], [113, 114], [115, 124], [125, 129], [130, 132], [133, 135], [136, 148], [149, 160], [161, 163], [164, 168], [169, 173], [174, 179], [180, 182], [183, 186], [187, 190], [191, 193], [194, 198], [199, 201], [202, 208], [209, 215], [216, 220], [221, 223], [224, 227], [228, 233], [234, 238], [239, 242], [242, 243]]}
{"doc_key": "ai-test-421", "ner": [[0, 7, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Association", "for", "the", "Development", "of", "Artificial", "Intelligence", "has", "analysed", "this", "issue", "in", "depth"], "sentence-detokenized": "The Association for the Development of Artificial Intelligence has analysed this issue in depth", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 35], [36, 38], [39, 49], [50, 62], [63, 66], [67, 75], [76, 80], [81, 86], [87, 89], [90, 95]]}
{"doc_key": "ai-test-422", "ner": [[5, 11, "product"], [14, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 14, 5, 11, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["What", "started", "as", "a", "curiosity", ",", "the", "Apple", "Macintosh", "'s", "speech", "system", "evolved", "into", "PlainTalk", ",", "a", "fully", "supported", "programme", "for", "people", "with", "vision", "problems", "."], "sentence-detokenized": "What started as a curiosity, the Apple Macintosh's speech system evolved into PlainTalk, a fully supported programme for people with vision problems.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 17], [18, 27], [27, 28], [29, 32], [33, 38], [39, 48], [48, 50], [51, 57], [58, 64], [65, 72], [73, 77], [78, 87], [87, 88], [89, 90], [91, 96], [97, 106], [107, 116], [117, 120], [121, 127], [128, 132], [133, 139], [140, 148], [148, 149]]}
{"doc_key": "ai-test-423", "ner": [[5, 5, "field"], [7, 8, "task"], [10, 11, "task"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 5, 5, "part-of", "task_part_of_field", false, false], [10, 11, 5, 5, "part-of", "task_part_of_field", false, false], [13, 14, 5, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Other", "uses", "of", "ontologies", "in", "NLP", "include", "information", "retrieval", ",", "information", "extraction", "and", "automatic", "summarisation", "."], "sentence-detokenized": "Other uses of ontologies in NLP include information retrieval, information extraction and automatic summarisation.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 24], [25, 27], [28, 31], [32, 39], [40, 51], [52, 61], [61, 62], [63, 74], [75, 85], [86, 89], [90, 99], [100, 113], [113, 114]]}
{"doc_key": "ai-test-424", "ner": [[5, 14, "organisation"], [15, 19, "organisation"], [22, 25, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Institute", "works", "closely", "with", "the", "Howard", "Hughes", "Medical", "Institute", "Janelia", "Farm", "Campus", ",", "the", "Allen", "Institute", "for", "Brain", "Science", "and", "the", "National", "Institutes", "of", "Health", "to", "develop", "better", "methods", "for", "reconstructing", "neuronal", "architectures", "."], "sentence-detokenized": "The Institute works closely with the Howard Hughes Medical Institute Janelia Farm Campus, the Allen Institute for Brain Science and the National Institutes of Health to develop better methods for reconstructing neuronal architectures.", "token2charspan": [[0, 3], [4, 13], [14, 19], [20, 27], [28, 32], [33, 36], [37, 43], [44, 50], [51, 58], [59, 68], [69, 76], [77, 81], [82, 88], [88, 89], [90, 93], [94, 99], [100, 109], [110, 113], [114, 119], [120, 127], [128, 131], [132, 135], [136, 144], [145, 155], [156, 158], [159, 165], [166, 168], [169, 176], [177, 183], [184, 191], [192, 195], [196, 210], [211, 219], [220, 233], [233, 234]]}
{"doc_key": "ai-test-425", "ner": [[1, 5, "product"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Recently", "Google", "announced", "that", "Google", "Translate", "translates", "enough", "text", "to", "fill", "about", "1", "million", "books", "in", "one", "day", "(", "2012", ")", "."], "sentence-detokenized": "Recently Google announced that Google Translate translates enough text to fill about 1 million books in one day (2012).", "token2charspan": [[0, 8], [9, 15], [16, 25], [26, 30], [31, 37], [38, 47], [48, 58], [59, 65], [66, 70], [71, 73], [74, 78], [79, 84], [85, 86], [87, 94], [95, 100], [101, 103], [104, 107], [108, 111], [112, 113], [113, 117], [117, 118], [118, 119]]}
{"doc_key": "ai-test-426", "ner": [[10, 14, "country"], [15, 15, "country"], [17, 17, "country"], [19, 19, "country"], [21, 21, "country"], [23, 24, "country"], [34, 35, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Events", "are", "organised", "worldwide", "and", "are", "most", "popular", "in", "the", "United", "Kingdom", ",", "the", "United", "States", ",", "Japan", ",", "Singapore", ",", "India", ",", "South", "Korea", "and", "are", "becoming", "popular", "in", "sub-continental", "countries", "such", "as", "Sri", "Lanka", "."], "sentence-detokenized": "Events are organised worldwide and are most popular in the United Kingdom, the United States, Japan, Singapore, India, South Korea and are becoming popular in sub-continental countries such as Sri Lanka.", "token2charspan": [[0, 6], [7, 10], [11, 20], [21, 30], [31, 34], [35, 38], [39, 43], [44, 51], [52, 54], [55, 58], [59, 65], [66, 73], [73, 74], [75, 78], [79, 85], [86, 92], [92, 93], [94, 99], [99, 100], [101, 110], [110, 111], [112, 117], [117, 118], [119, 124], [125, 130], [131, 134], [135, 138], [139, 147], [148, 155], [156, 158], [159, 174], [175, 184], [185, 189], [190, 192], [193, 196], [197, 202], [202, 203]]}
{"doc_key": "ai-test-427", "ner": [[5, 8, "programlang"], [12, 12, "programlang"], [14, 14, "programlang"], [16, 17, "programlang"], [19, 19, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "packages", "are", "primarily", "developed", "in", "R", ",", "but", "sometimes", "also", "in", "Java", ",", "C", ",", "C", "++", "and", "Fortran", "."], "sentence-detokenized": "These packages are primarily developed in R, but sometimes also in Java, C, C++ and Fortran.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 28], [29, 38], [39, 41], [42, 43], [43, 44], [45, 48], [49, 58], [59, 63], [64, 66], [67, 71], [71, 72], [73, 74], [74, 75], [76, 77], [77, 79], [80, 83], [84, 91], [91, 92]]}
{"doc_key": "ai-test-428", "ner": [[3, 9, "conference"], [11, 11, "conference"], [14, 14, "researcher"], [16, 16, "researcher"], [20, 21, "researcher"], [24, 25, "algorithm"], [30, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 11, 3, 9, "named", "", false, false], [14, 14, 3, 9, "physical", "", false, false], [14, 14, 3, 9, "role", "", false, false], [14, 14, 20, 21, "role", "teams_up_with", false, false], [14, 14, 24, 25, "usage", "", false, false], [16, 16, 3, 9, "physical", "", false, false], [16, 16, 3, 9, "role", "", false, false], [16, 16, 20, 21, "role", "teams_up_with", false, false], [16, 16, 24, 25, "usage", "", false, false], [20, 21, 3, 9, "physical", "", false, false], [20, 21, 3, 9, "role", "", false, false], [20, 21, 24, 25, "usage", "", false, false], [24, 25, 30, 35, "related-to", "used_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["As", "part", "of", "the", "2006", "European", "Conference", "on", "Computer", "Vision", "(", "ECCV", ")", ",", "Dalal", "and", "Triggs", ",", "together", "with", "Cordelia", "Schmid", ",", "applied", "HOG", "detectors", "to", "the", "problem", "of", "human", "detection", "in", "film", "and", "video", "."], "sentence-detokenized": "As part of the 2006 European Conference on Computer Vision (ECCV), Dalal and Triggs, together with Cordelia Schmid, applied HOG detectors to the problem of human detection in film and video.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 19], [20, 28], [29, 39], [40, 42], [43, 51], [52, 58], [59, 60], [60, 64], [64, 65], [65, 66], [67, 72], [73, 76], [77, 83], [83, 84], [85, 93], [94, 98], [99, 107], [108, 114], [114, 115], [116, 123], [124, 127], [128, 137], [138, 140], [141, 144], [145, 152], [153, 155], [156, 161], [162, 171], [172, 174], [175, 179], [180, 183], [184, 189], [189, 190]]}
{"doc_key": "ai-test-429", "ner": [[0, 3, "metrics"], [5, 5, "metrics"], [11, 12, "task"], [19, 21, "metrics"], [23, 23, "metrics"], [36, 36, "metrics"], [26, 28, "metrics"], [30, 30, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 3, 11, 12, "related-to", "measured_with", false, false], [5, 5, 11, 12, "related-to", "measured_with", false, false], [19, 21, 11, 12, "related-to", "measured_with", false, false], [23, 23, 19, 21, "named", "", false, false], [36, 36, 19, 21, "named", "", false, false], [30, 30, 26, 28, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "addition", "to", "sensitivity", "and", "specificity", ",", "the", "performance", "of", "a", "binary", "classification", "test", "can", "be", "measured", "by", "its", "positive", "predictive", "value", "(", "PPV", ")", "and", "negative", "predictive", "value", "(", "NPV", ")", ",", "also", "known", "as", "precision", "."], "sentence-detokenized": "In addition to sensitivity and specificity, the performance of a binary classification test can be measured by its positive predictive value (PPV) and negative predictive value (NPV), also known as precision.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 42], [42, 43], [44, 47], [48, 59], [60, 62], [63, 64], [65, 71], [72, 86], [87, 91], [92, 95], [96, 98], [99, 107], [108, 110], [111, 114], [115, 123], [124, 134], [135, 140], [141, 142], [142, 145], [145, 146], [147, 150], [151, 159], [160, 170], [171, 176], [177, 178], [178, 181], [181, 182], [182, 183], [184, 188], [189, 194], [195, 197], [198, 207], [207, 208]]}
{"doc_key": "ai-test-430", "ner": [[13, 16, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "models", "can", "give", "partial", "credit", "for", "overlapping", "matches", "(", "such", "as", "using", "the", "Jaccard", "index", "criterion", "."], "sentence-detokenized": "Such models can give partial credit for overlapping matches (such as using the Jaccard index criterion.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 28], [29, 35], [36, 39], [40, 51], [52, 59], [60, 61], [61, 65], [66, 68], [69, 74], [75, 78], [79, 86], [87, 92], [93, 102], [102, 103]]}
{"doc_key": "ai-test-431", "ner": [[12, 17, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "also", "illustrates", "philosophical", "issues", "and", "possible", "misunderstandings", "in", "the", "use", "of", "maximum", "likelihood", "estimators", "and", "likelihood", "functions", "in", "the", "case", "of", "single", "sample", "based", "estimation", "."], "sentence-detokenized": "It also illustrates philosophical issues and possible misunderstandings in the use of maximum likelihood estimators and likelihood functions in the case of single sample based estimation.", "token2charspan": [[0, 2], [3, 7], [8, 19], [20, 33], [34, 40], [41, 44], [45, 53], [54, 71], [72, 74], [75, 78], [79, 82], [83, 85], [86, 93], [94, 104], [105, 115], [116, 119], [120, 130], [131, 140], [141, 143], [144, 147], [148, 152], [153, 155], [156, 162], [163, 169], [170, 175], [176, 186], [186, 187]]}
