{"doc_key": "ai-test-1", "ner": [[5, 7, "algorithm"], [9, 9, "algorithm"], [13, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "generative", "model", "approaches", "include", "na\u00efve", "Bayes", "classifiers", ",", "Gaussian", "mixture", "models", "and", "variational", "automata", "coders", "."], "sentence-detokenized": "Typical generative model approaches include na\u00efve Bayes classifiers, Gaussian mixture models and variational automata coders.", "token2charspan": [[0, 7], [8, 18], [19, 24], [25, 35], [36, 43], [44, 49], [50, 55], [56, 67], [67, 68], [69, 77], [78, 85], [86, 92], [93, 96], [97, 108], [109, 117], [118, 124], [124, 125]]}
{"doc_key": "ai-test-2", "ner": [[4, 4, "organisation"], [10, 10, "conference"], [13, 18, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 10, 10, "role", "", false, false], [13, 18, 10, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Every", "two", "years", ",", "ELRA", "organises", "a", "major", "conference", "called", "LREC", ",", "the", "International", "Language", "Resources", "and", "Evaluation", "Conference", "."], "sentence-detokenized": "Every two years, ELRA organises a major conference called LREC, the International Language Resources and Evaluation Conference.", "token2charspan": [[0, 5], [6, 9], [10, 15], [15, 16], [17, 21], [22, 31], [32, 33], [34, 39], [40, 50], [51, 57], [58, 62], [62, 63], [64, 67], [68, 81], [82, 90], [91, 100], [101, 104], [105, 115], [116, 126], [126, 127]]}
{"doc_key": "ai-test-3", "ner": [[6, 11, "algorithm"], [14, 18, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "task", "is", "usually", "to", "derive", "the", "maximum", "likelihood", "estimate", "of", "the", "parameters", "of", "the", "HMM", ",", "given", "the", "output", "sequences", "."], "sentence-detokenized": "The task is usually to derive the maximum likelihood estimate of the parameters of the HMM, given the output sequences.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 19], [20, 22], [23, 29], [30, 33], [34, 41], [42, 52], [53, 61], [62, 64], [65, 68], [69, 79], [80, 82], [83, 86], [87, 90], [90, 91], [92, 97], [98, 101], [102, 108], [109, 118], [118, 119]]}
{"doc_key": "ai-test-4", "ner": [[4, 6, "algorithm"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Unlike", "neural", "networks", "and", "support", "vector", "machines", ",", "the", "AdaBoost", "training", "process", "selects", "only", "those", "features", "that", "are", "known", "to", "improve", "the", "predictive", "performance", "of", "the", "model", ",", "thus", "reducing", "the", "dimensionality", "of", "the", "model", "and", "potentially", "improving", "the", "execution", "time", ",", "since", "irrelevant", "features", "do", "not", "need", "to", "be", "computed", "."], "sentence-detokenized": "Unlike neural networks and support vector machines, the AdaBoost training process selects only those features that are known to improve the predictive performance of the model, thus reducing the dimensionality of the model and potentially improving the execution time, since irrelevant features do not need to be computed.", "token2charspan": [[0, 6], [7, 13], [14, 22], [23, 26], [27, 34], [35, 41], [42, 50], [50, 51], [52, 55], [56, 64], [65, 73], [74, 81], [82, 89], [90, 94], [95, 100], [101, 109], [110, 114], [115, 118], [119, 124], [125, 127], [128, 135], [136, 139], [140, 150], [151, 162], [163, 165], [166, 169], [170, 175], [175, 176], [177, 181], [182, 190], [191, 194], [195, 209], [210, 212], [213, 216], [217, 222], [223, 226], [227, 238], [239, 248], [249, 252], [253, 262], [263, 267], [267, 268], [269, 274], [275, 285], [286, 294], [295, 297], [298, 301], [302, 306], [307, 309], [310, 312], [313, 321], [321, 322]]}
{"doc_key": "ai-test-5", "ner": [[0, 5, "misc"], [10, 15, "misc"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 5, 10, 15, "part-of", "", false, false], [10, 15, 12, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "troponym", "is", "one", "of", "the", "possible", "relationships", "between", "verbs", "in", "the", "Word", "Net", "semantic", "network", "."], "sentence-detokenized": "A troponym is one of the possible relationships between verbs in the WordNet semantic network.", "token2charspan": [[0, 1], [2, 10], [11, 13], [14, 17], [18, 20], [21, 24], [25, 33], [34, 47], [48, 55], [56, 61], [62, 64], [65, 68], [69, 73], [73, 76], [77, 85], [86, 93], [93, 94]]}
{"doc_key": "ai-test-6", "ner": [[6, 8, "task"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 8, 9, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Frame", "language", "is", "a", "technique", "used", "to", "represent", "information", "in", "AI", "."], "sentence-detokenized": "Frame language is a technique used to represent information in AI.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 19], [20, 29], [30, 34], [35, 37], [38, 47], [48, 59], [60, 62], [63, 65], [65, 66]]}
{"doc_key": "ai-test-7", "ner": [[0, 0, "metrics"], [4, 9, "metrics"], [12, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 9, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "the", "Bilingual", "assessment", "contractor", "in", "that", "it", "calculates", "the", "shorthand", "penalty", "in", "that", "small", "variations", "in", "translation", "length", "do", "not", "affect", "the", "overall", "score", "as", "much", "."], "sentence-detokenized": "NIST also differs from the Bilingual assessment contractor in that it calculates the shorthand penalty in that small variations in translation length do not affect the overall score as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 26], [27, 36], [37, 47], [48, 58], [59, 61], [62, 66], [67, 69], [70, 80], [81, 84], [85, 94], [95, 102], [103, 105], [106, 110], [111, 116], [117, 127], [128, 130], [131, 142], [143, 149], [150, 152], [153, 156], [157, 163], [164, 167], [168, 175], [176, 181], [182, 184], [185, 189], [189, 190]]}
{"doc_key": "ai-test-8", "ner": [[15, 16, "algorithm"], [19, 21, "algorithm"], [30, 30, "field"], [39, 40, "algorithm"], [42, 44, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 16, 30, 30, "usage", "", false, false], [19, 21, 30, 30, "usage", "", false, false], [39, 40, 30, 30, "type-of", "", false, false], [42, 44, 30, 30, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "model", "is", "first", "fitted", "to", "a", "training", "database", ",", "The", "model", "(", "e.g.", "a", "neural", "network", "or", "a", "na\u00efve", "Bayesian", "classifier", ")", "is", "trained", "on", "the", "training", "database", "using", "supervised", "learning", "methods", ",", "such", "as", "optimisation", "methods", "like", "gradient", "descent", "or", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The model is first fitted to a training database, The model (e.g. a neural network or a na\u00efve Bayesian classifier) is trained on the training database using supervised learning methods, such as optimisation methods like gradient descent or stochastic gradient descent.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 18], [19, 25], [26, 28], [29, 30], [31, 39], [40, 48], [48, 49], [50, 53], [54, 59], [60, 61], [61, 65], [66, 67], [68, 74], [75, 82], [83, 85], [86, 87], [88, 93], [94, 102], [103, 113], [113, 114], [115, 117], [118, 125], [126, 128], [129, 132], [133, 141], [142, 150], [151, 156], [157, 167], [168, 176], [177, 184], [184, 185], [186, 190], [191, 193], [194, 206], [207, 214], [215, 219], [220, 228], [229, 236], [237, 239], [240, 250], [251, 259], [260, 267], [267, 268]]}
{"doc_key": "ai-test-9", "ner": [[0, 0, "product"], [8, 9, "task"], [11, 11, "task"], [13, 16, "task"], [18, 19, "task"], [24, 24, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 0, "usage", "", true, false], [11, 11, 0, 0, "usage", "", true, false], [13, 16, 0, 0, "usage", "", true, false], [18, 19, 0, 0, "usage", "", true, false], [24, 24, 0, 0, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["FrameNet", "has", "been", "used", "in", "applications", "such", "as", "question", "answering", ",", "paraphrasing", ",", "identifying", "meaning", "in", "text", "and", "extracting", "information", "either", "directly", "or", "through", "semantic", "role", "labeling", "tools", "."], "sentence-detokenized": "FrameNet has been used in applications such as question answering, paraphrasing, identifying meaning in text and extracting information either directly or through semantic role labeling tools.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 22], [23, 25], [26, 38], [39, 43], [44, 46], [47, 55], [56, 65], [65, 66], [67, 79], [79, 80], [81, 92], [93, 100], [101, 103], [104, 108], [109, 112], [113, 123], [124, 135], [136, 142], [143, 151], [152, 154], [155, 162], [163, 171], [172, 176], [177, 185], [186, 191], [191, 192]]}
{"doc_key": "ai-test-10", "ner": [[6, 6, "field"], [12, 12, "misc"], [15, 15, "product"], [18, 18, "misc"], [21, 21, "product"], [24, 25, "field"], [28, 28, "product"], [31, 33, "misc"], [36, 36, "product"], [38, 38, "product"], [40, 40, "product"], [43, 44, "misc"], [47, 48, "product"], [50, 51, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[15, 15, 12, 12, "general-affiliation", "", false, false], [21, 21, 18, 18, "general-affiliation", "", false, false], [28, 28, 24, 25, "general-affiliation", "", false, false], [36, 36, 31, 33, "type-of", "", false, false], [38, 38, 31, 33, "type-of", "", false, false], [40, 40, 31, 33, "type-of", "", false, false], [47, 48, 43, 44, "general-affiliation", "", false, false], [50, 51, 43, 44, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["These", "include", ",", "for", "example", ",", "data", "analysis", "and", "extraction", "tools", ",", "spreadsheets", "(", "e.g.", "Excel", ")", ",", "databases", "(", "e.g.", "Access", ")", ",", "statistical", "analysis", "(", "e.g.", "SAS", ")", ",", "general", "auditing", "software", "(", "e.g.", "ACL", ",", "Arbutus", ",", "EAS", ")", ",", "business", "intelligence", "(", "e.g.", "Crystal", "Reports", "and", "Business", "Objects", ")", ",", "etc", "."], "sentence-detokenized": "These include, for example, data analysis and extraction tools, spreadsheets (e.g. Excel), databases (e.g. Access), statistical analysis (e.g. SAS), general auditing software (e.g. ACL, Arbutus, EAS), business intelligence (e.g. Crystal Reports and Business Objects), etc.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 18], [19, 26], [26, 27], [28, 32], [33, 41], [42, 45], [46, 56], [57, 62], [62, 63], [64, 76], [77, 78], [78, 82], [83, 88], [88, 89], [89, 90], [91, 100], [101, 102], [102, 106], [107, 113], [113, 114], [114, 115], [116, 127], [128, 136], [137, 138], [138, 142], [143, 146], [146, 147], [147, 148], [149, 156], [157, 165], [166, 174], [175, 176], [176, 180], [181, 184], [184, 185], [186, 193], [193, 194], [195, 198], [198, 199], [199, 200], [201, 209], [210, 222], [223, 224], [224, 228], [229, 236], [237, 244], [245, 248], [249, 257], [258, 265], [265, 266], [266, 267], [268, 271], [271, 272]]}
{"doc_key": "ai-test-11", "ner": [[0, 1, "organisation"], [5, 6, "researcher"], [10, 10, "organisation"], [13, 14, "product"], [19, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 6, "origin", "", false, false], [5, 6, 10, 10, "role", "", false, false], [13, 14, 19, 20, "type-of", "", false, false], [19, 20, 5, 6, "origin", "introduced_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Rethink", "Robotics", "-", "founded", "by", "Rodney", "Brooks", ",", "formerly", "of", "iRobot", "-", "introduced", "Baxter", "in", "September", "2012", ",", "an", "industrial", "robot", "designed", "to", "interact", "safely", "with", "human", "workers", "nearby", "and", "programmable", "to", "perform", "simple", "tasks", "."], "sentence-detokenized": "Rethink Robotics - founded by Rodney Brooks, formerly of iRobot - introduced Baxter in September 2012, an industrial robot designed to interact safely with human workers nearby and programmable to perform simple tasks.", "token2charspan": [[0, 7], [8, 16], [17, 18], [19, 26], [27, 29], [30, 36], [37, 43], [43, 44], [45, 53], [54, 56], [57, 63], [64, 65], [66, 76], [77, 83], [84, 86], [87, 96], [97, 101], [101, 102], [103, 105], [106, 116], [117, 122], [123, 131], [132, 134], [135, 143], [144, 150], [151, 155], [156, 161], [162, 169], [170, 176], [177, 180], [181, 193], [194, 196], [197, 204], [205, 211], [212, 217], [217, 218]]}
{"doc_key": "ai-test-12", "ner": [[5, 6, "task"], [8, 9, "task"], [11, 14, "task"], [16, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 28, "task"], [32, 37, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Typical", "text", "mining", "tasks", "include", "text", "classification", ",", "text", "clustering", ",", "concept", "/", "entity", "mining", ",", "generating", "granular", "taxonomies", ",", "sentiment", "analysis", ",", "document", "summarisation", "and", "modelling", "entity", "relationships", "(", "i.e.", "learning", "to", "identify", "relationships", "between", "named", "entities", ")", "."], "sentence-detokenized": "Typical text mining tasks include text classification, text clustering, concept/entity mining, generating granular taxonomies, sentiment analysis, document summarisation and modelling entity relationships (i.e. learning to identify relationships between named entities).", "token2charspan": [[0, 7], [8, 12], [13, 19], [20, 25], [26, 33], [34, 38], [39, 53], [53, 54], [55, 59], [60, 70], [70, 71], [72, 79], [79, 80], [80, 86], [87, 93], [93, 94], [95, 105], [106, 114], [115, 125], [125, 126], [127, 136], [137, 145], [145, 146], [147, 155], [156, 169], [170, 173], [174, 183], [184, 190], [191, 204], [205, 206], [206, 210], [211, 219], [220, 222], [223, 231], [232, 245], [246, 253], [254, 259], [260, 268], [268, 269], [269, 270]]}
{"doc_key": "ai-test-13", "ner": [[5, 6, "metrics"], [11, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "stemming", "reduces", "the", "accuracy", "of", "such", "systems", ",", "i.e.", "the", "TRUE", "negative", "percentage", "."], "sentence-detokenized": "However, stemming reduces the accuracy of such systems, i.e. the TRUE negative percentage.", "token2charspan": [[0, 7], [7, 8], [9, 17], [18, 25], [26, 29], [30, 38], [39, 41], [42, 46], [47, 54], [54, 55], [56, 60], [61, 64], [65, 69], [70, 78], [79, 89], [89, 90]]}
{"doc_key": "ai-test-14", "ner": [[4, 5, "task"], [7, 8, "misc"], [13, 14, "misc"], [26, 26, "product"], [20, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 4, 5, "temporal", "", false, false], [13, 14, 7, 8, "named", "", false, false], [26, 26, 7, 8, "usage", "", false, false], [20, 28, 7, 8, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "special", "case", "of", "keyword", "detection", "is", "wake", "word", "(", "also", "known", "as", "hot", "word", ")", "detection", ",", "which", "is", "used", "by", "personal", "digital", "assistants", "like", "Alexa", "or", "Siri", "to", "wake", "you", "up", "when", "their", "name", "is", "spoken", "."], "sentence-detokenized": "A special case of keyword detection is wake word (also known as hot word) detection, which is used by personal digital assistants like Alexa or Siri to wake you up when their name is spoken.", "token2charspan": [[0, 1], [2, 9], [10, 14], [15, 17], [18, 25], [26, 35], [36, 38], [39, 43], [44, 48], [49, 50], [50, 54], [55, 60], [61, 63], [64, 67], [68, 72], [72, 73], [74, 83], [83, 84], [85, 90], [91, 93], [94, 98], [99, 101], [102, 110], [111, 118], [119, 129], [130, 134], [135, 140], [141, 143], [144, 148], [149, 151], [152, 156], [157, 160], [161, 163], [164, 168], [169, 174], [175, 179], [180, 182], [183, 189], [189, 190]]}
{"doc_key": "ai-test-15", "ner": [[0, 0, "programlang"], [9, 9, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 0, 0, "part-of", "", false, false], [11, 11, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prova", "is", "an", "open", "source", "programming", "language", "that", "combines", "Prolog", "and", "Java", "."], "sentence-detokenized": "Prova is an open source programming language that combines Prolog and Java.", "token2charspan": [[0, 5], [6, 8], [9, 11], [12, 16], [17, 23], [24, 35], [36, 44], [45, 49], [50, 58], [59, 65], [66, 69], [70, 74], [74, 75]]}
{"doc_key": "ai-test-16", "ner": [[6, 7, "organisation"], [3, 4, "organisation"], [13, 15, "product"], [25, 27, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 7, 3, 4, "part-of", "", false, false], [6, 7, 3, 4, "role", "sells", false, false], [6, 7, 25, 27, "role", "sells_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1987", ",", "Toshiba", "'s", "subsidiary", "Tocibai", "Machine", "was", "accused", "of", "illegally", "selling", "CNC", "milling", "equipment", "used", "to", "manufacture", "ultra", "-", "quiet", "submarine", "launchers", "to", "the", "Soviet", "Union", ",", "in", "violation", "of", "the", "CoCom", "agreement", ",", "an", "international", "embargo", "on", "certain", "COMECON", "countries", "."], "sentence-detokenized": "In 1987, Toshiba's subsidiary Tocibai Machine was accused of illegally selling CNC milling equipment used to manufacture ultra-quiet submarine launchers to the Soviet Union, in violation of the CoCom agreement, an international embargo on certain COMECON countries.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [16, 18], [19, 29], [30, 37], [38, 45], [46, 49], [50, 57], [58, 60], [61, 70], [71, 78], [79, 82], [83, 90], [91, 100], [101, 105], [106, 108], [109, 120], [121, 126], [126, 127], [127, 132], [133, 142], [143, 152], [153, 155], [156, 159], [160, 166], [167, 172], [172, 173], [174, 176], [177, 186], [187, 189], [190, 193], [194, 199], [200, 209], [209, 210], [211, 213], [214, 227], [228, 235], [236, 238], [239, 246], [247, 254], [255, 264], [264, 265]]}
{"doc_key": "ai-test-17", "ner": [[7, 10, "product"], [15, 20, "location"]], "ner_mapping_to_source": [1, 2], "relations": [[7, 10, 15, 20, "physical", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Engelberger", "'s", "most", "famous", "invention", ",", "the", "Unimate", "industrial", "robot", "arm", ",", "was", "inducted", "into", "the", "Robot", "Hall", "of", "Fame", "in", "2003", "."], "sentence-detokenized": "Engelberger's most famous invention, the Unimate industrial robot arm, was inducted into the Robot Hall of Fame in 2003.", "token2charspan": [[0, 11], [11, 13], [14, 18], [19, 25], [26, 35], [35, 36], [37, 40], [41, 48], [49, 59], [60, 65], [66, 69], [69, 70], [71, 74], [75, 83], [84, 88], [89, 92], [93, 98], [99, 103], [104, 106], [107, 111], [112, 114], [115, 119], [119, 120]]}
{"doc_key": "ai-test-18", "ner": [[3, 3, "misc"], [8, 8, "misc"], [10, 10, "person"], [15, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 8, 8, "usage", "", false, false], [10, 10, 15, 18, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Originally", "driven", "by", "static", "html", "web", "pages", "using", "CGI", ",", "Dalton", "'s", "work", "introduced", "an", "augmented", "reality", "-", "based", "Java", "interface", "with", "limited", "success", "."], "sentence-detokenized": "Originally driven by static html web pages using CGI, Dalton's work introduced an augmented reality-based Java interface with limited success.", "token2charspan": [[0, 10], [11, 17], [18, 20], [21, 27], [28, 32], [33, 36], [37, 42], [43, 48], [49, 52], [52, 53], [54, 60], [60, 62], [63, 67], [68, 78], [79, 81], [82, 91], [92, 99], [99, 100], [100, 105], [106, 110], [111, 120], [121, 125], [126, 133], [134, 141], [141, 142]]}
{"doc_key": "ai-test-19", "ner": [[4, 6, "task"], [11, 11, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 11, 11, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "publication", "of", "the", "LMF", "definition", "since", "its", "ratification", "by", "ISO", "(", "this", "document", "became", "(", "in", "2015", ")", "the", "ninth", "most", "cited", "LREC", "paper", "at", "LREC", "conferences", ")", ":"], "sentence-detokenized": "The first publication of the LMF definition since its ratification by ISO (this document became (in 2015) the ninth most cited LREC paper at LREC conferences):", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 24], [25, 28], [29, 32], [33, 43], [44, 49], [50, 53], [54, 66], [67, 69], [70, 73], [74, 75], [75, 79], [80, 88], [89, 95], [96, 97], [97, 99], [100, 104], [104, 105], [106, 109], [110, 115], [116, 120], [121, 126], [127, 131], [132, 137], [138, 140], [141, 145], [146, 157], [157, 158], [158, 159]]}
{"doc_key": "ai-test-20", "ner": [[0, 2, "metrics"], [14, 16, "metrics"], [17, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 16, 0, 2, "usage", "", false, false], [14, 16, 17, 21, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "confusion", "matrix", "or", "equivalence", "matrix", "is", "often", "used", "as", "a", "tool", "to", "validate", "the", "accuracy", "of", "the", "k", "-", "NN", "classification", "."], "sentence-detokenized": "The confusion matrix or equivalence matrix is often used as a tool to validate the accuracy of the k -NN classification.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 23], [24, 35], [36, 42], [43, 45], [46, 51], [52, 56], [57, 59], [60, 61], [62, 66], [67, 69], [70, 78], [79, 82], [83, 91], [92, 94], [95, 98], [99, 100], [101, 102], [102, 104], [105, 119], [119, 120]]}
{"doc_key": "ai-test-21", "ner": [[11, 12, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Decision", "tree", "learning", "is", "one", "of", "the", "predictive", "modelling", "techniques", "used", "in", "statistics", ",", "data", "mining", "and", "machine", "learning", "."], "sentence-detokenized": "Decision tree learning is one of the predictive modelling techniques used in statistics, data mining and machine learning.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 47], [48, 57], [58, 68], [69, 73], [74, 76], [77, 87], [87, 88], [89, 93], [94, 100], [101, 104], [105, 112], [113, 121], [121, 122]]}
{"doc_key": "ai-test-22", "ner": [[4, 6, "misc"], [19, 21, "algorithm"], [23, 23, "algorithm"]], "ner_mapping_to_source": [0, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["At", "run", "-time", ",", "the", "target", "phrase", "is", "superimposed", "on", "these", "minimal", "units", "by", "signal", "processing", "techniques", "such", "as", "linear", "predictive", "coding", ",", "PSOLA"], "sentence-detokenized": "At run-time, the target phrase is superimposed on these minimal units by signal processing techniques such as linear predictive coding, PSOLA", "token2charspan": [[0, 2], [3, 6], [6, 11], [11, 12], [13, 16], [17, 23], [24, 30], [31, 33], [34, 46], [47, 49], [50, 55], [56, 63], [64, 69], [70, 72], [73, 79], [80, 90], [91, 101], [102, 106], [107, 109], [110, 116], [117, 127], [128, 134], [134, 135], [136, 141]]}
{"doc_key": "ai-test-23", "ner": [[3, 4, "field"], [6, 8, "field"], [16, 19, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 19, 3, 4, "usage", "", true, false], [16, 19, 6, 8, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "approach", "used", "artificial", "intelligence", "and", "machine", "learning", "to", "allow", "researchers", "to", "visually", "compare", "conventional", "and", "thermal", "images", "of", "faces", "."], "sentence-detokenized": "This approach used artificial intelligence and machine learning to allow researchers to visually compare conventional and thermal images of faces.", "token2charspan": [[0, 4], [5, 13], [14, 18], [19, 29], [30, 42], [43, 46], [47, 54], [55, 63], [64, 66], [67, 72], [73, 84], [85, 87], [88, 96], [97, 104], [105, 117], [118, 121], [122, 129], [130, 136], [137, 139], [140, 145], [145, 146]]}
{"doc_key": "ai-test-24", "ner": [[4, 7, "algorithm"], [10, 11, "task"], [15, 16, "misc"], [21, 22, "field"], [24, 25, "field"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[4, 7, 10, 11, "topic", "", false, false], [10, 11, 15, 16, "origin", "", false, false], [21, 22, 4, 7, "topic", "", false, false], [24, 25, 4, 7, "topic", "", false, false]], "relations_mapping_to_source": [1, 2, 4, 6], "sentence": ["In", "computer", "science", ",", "evolutionary", "computation", "is", "the", "family", "of", "global", "optimisation", "algorithms", "inspired", "by", "biological", "evolution", "and", "the", "branch", "of", "artificial", "intelligence", "and", "soft", "computing", "that", "studies", "these", "algorithms", "."], "sentence-detokenized": "In computer science, evolutionary computation is the family of global optimisation algorithms inspired by biological evolution and the branch of artificial intelligence and soft computing that studies these algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 33], [34, 45], [46, 48], [49, 52], [53, 59], [60, 62], [63, 69], [70, 82], [83, 93], [94, 102], [103, 105], [106, 116], [117, 126], [127, 130], [131, 134], [135, 141], [142, 144], [145, 155], [156, 168], [169, 172], [173, 177], [178, 187], [188, 192], [193, 200], [201, 206], [207, 217], [217, 218]]}
{"doc_key": "ai-test-25", "ner": [[8, 9, "metrics"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "a", "measure", "based", "on", "a", "mixing", "matrix", "can", "be", "combined", "with", "the", "mean", "squared", "error", "estimated", "between", "the", "raw", "model", "results", "and", "the", "actual", "values", "."], "sentence-detokenized": "For example, a measure based on a mixing matrix can be combined with the mean squared error estimated between the raw model results and the actual values.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 14], [15, 22], [23, 28], [29, 31], [32, 33], [34, 40], [41, 47], [48, 51], [52, 54], [55, 63], [64, 68], [69, 72], [73, 77], [78, 85], [86, 91], [92, 101], [102, 109], [110, 113], [114, 117], [118, 123], [124, 131], [132, 135], [136, 139], [140, 146], [147, 153], [153, 154]]}
{"doc_key": "ai-test-26", "ner": [[8, 9, "product"], [12, 12, "researcher"], [19, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 12, 12, "origin", "", false, false], [8, 9, 19, 19, "named", "same", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Most", "of", "them", "are", "the", "results", "of", "the", "word2vec", "model", "developed", "by", "Mikolov", "and", "others", ",", "or", "variations", "of", "it", "."], "sentence-detokenized": "Most of them are the results of the word2vec model developed by Mikolov and others, or variations of it.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 16], [17, 20], [21, 28], [29, 31], [32, 35], [36, 44], [45, 50], [51, 60], [61, 63], [64, 71], [72, 75], [76, 82], [82, 83], [84, 86], [87, 97], [98, 100], [101, 103], [103, 104]]}
{"doc_key": "ai-test-27", "ner": [[0, 12, "conference"], [16, 19, "conference"], [15, 21, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 21, 16, 19, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["During", "this", "period", ",", "a", "total", "of", "43", "publications", "were", "recognised", "by", "CVPR", "and", "the", "International", "Conference", "on", "Computer", "Vision", "(", "ICCV", ")", "."], "sentence-detokenized": "During this period, a total of 43 publications were recognised by CVPR and the International Conference on Computer Vision (ICCV).", "token2charspan": [[0, 6], [7, 11], [12, 18], [18, 19], [20, 21], [22, 27], [28, 30], [31, 33], [34, 46], [47, 51], [52, 62], [63, 65], [66, 70], [71, 74], [75, 78], [79, 92], [93, 103], [104, 106], [107, 115], [116, 122], [123, 124], [124, 128], [128, 129], [129, 130]]}
{"doc_key": "ai-test-28", "ner": [[0, 0, "product"], [23, 24, "field"]], "ner_mapping_to_source": [0, 2], "relations": [[23, 24, 0, 0, "part-of", "", true, false]], "relations_mapping_to_source": [1], "sentence": ["AIBO", "has", "been", "widely", "used", "as", "a", "low", "-", "cost", "platform", "for", "AI", "training", "and", "research", ",", "as", "it", "includes", "a", "computer", ",", "computer", "vision", "and", "articulators", "in", "a", "package", "that", "is", "significantly", "cheaper", "than", "traditional", "research", "robots", "."], "sentence-detokenized": "AIBO has been widely used as a low-cost platform for AI training and research, as it includes a computer, computer vision and articulators in a package that is significantly cheaper than traditional research robots.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 20], [21, 25], [26, 28], [29, 30], [31, 34], [34, 35], [35, 39], [40, 48], [49, 52], [53, 55], [56, 64], [65, 68], [69, 77], [77, 78], [79, 81], [82, 84], [85, 93], [94, 95], [96, 104], [104, 105], [106, 114], [115, 121], [122, 125], [126, 138], [139, 141], [142, 143], [144, 151], [152, 156], [157, 159], [160, 173], [174, 181], [182, 186], [187, 198], [199, 207], [208, 214], [214, 215]]}
{"doc_key": "ai-test-29", "ner": [[6, 12, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "was", "the", "Programme", "Chair", "of", "the", "International", "Conference", "on", "Computer", "Vision", "2021", "."], "sentence-detokenized": "He was the Programme Chair of the International Conference on Computer Vision 2021.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 20], [21, 26], [27, 29], [30, 33], [34, 47], [48, 58], [59, 61], [62, 70], [71, 77], [78, 82], [82, 83]]}
{"doc_key": "ai-test-30", "ner": [[11, 11, "researcher"], [4, 6, "organisation"], [15, 16, "organisation"], [26, 27, "organisation"], [34, 40, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[11, 11, 4, 6, "role", "", false, false], [11, 11, 15, 16, "role", "", true, false], [15, 16, 26, 27, "role", "develops_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["After", "receiving", "a", "grant", "from", "Unimation", "to", "develop", "his", "designs", ",", "Scheinman", "sold", "these", "designs", "to", "Unimation", ",", "which", "further", "developed", "them", "with", "the", "support", "of", "General", "Motors", "and", "later", "marketed", "them", "as", "a", "Programmable", "Universal", "Machine", "for", "Assembly", "(", "PUMA", ")", "."], "sentence-detokenized": "After receiving a grant from Unimation to develop his designs, Scheinman sold these designs to Unimation, which further developed them with the support of General Motors and later marketed them as a Programmable Universal Machine for Assembly (PUMA).", "token2charspan": [[0, 5], [6, 15], [16, 17], [18, 23], [24, 28], [29, 38], [39, 41], [42, 49], [50, 53], [54, 61], [61, 62], [63, 72], [73, 77], [78, 83], [84, 91], [92, 94], [95, 104], [104, 105], [106, 111], [112, 119], [120, 129], [130, 134], [135, 139], [140, 143], [144, 151], [152, 154], [155, 162], [163, 169], [170, 173], [174, 179], [180, 188], [189, 193], [194, 196], [197, 198], [199, 211], [212, 221], [222, 229], [230, 233], [234, 242], [243, 244], [244, 248], [248, 249], [249, 250]]}
{"doc_key": "ai-test-31", "ner": [[11, 12, "task"], [14, 16, "task"], [0, 0, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 12, "general-affiliation", "works_with", false, false], [0, 0, 14, 16, "general-affiliation", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Gebel", "(", "2009", ")", "gives", "an", "overview", "of", "calibration", "methods", "for", "binary", "classification", "and", "multi-class", "classification", "tasks", "."], "sentence-detokenized": "Gebel (2009) gives an overview of calibration methods for binary classification and multi-class classification tasks.", "token2charspan": [[0, 5], [6, 7], [7, 11], [11, 12], [13, 18], [19, 21], [22, 30], [31, 33], [34, 45], [46, 53], [54, 57], [58, 64], [65, 79], [80, 83], [84, 95], [96, 110], [111, 116], [116, 117]]}
{"doc_key": "ai-test-32", "ner": [[3, 7, "task"], [10, 11, "task"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "work", "includes", "optical", "character", "recognition", "(", "OCR", ")", ",", "speech", "synthesis", ",", "speech", "recognition", "technology", "and", "electronic", "keyboards", "."], "sentence-detokenized": "His work includes optical character recognition (OCR), speech synthesis, speech recognition technology and electronic keyboards.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 25], [26, 35], [36, 47], [48, 49], [49, 52], [52, 53], [53, 54], [55, 61], [62, 71], [71, 72], [73, 79], [80, 91], [92, 102], [103, 106], [107, 117], [118, 127], [127, 128]]}
{"doc_key": "ai-test-33", "ner": [[7, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "newer", "and", "more", "advanced", "techniques", ",", "the", "Kaldi", "toolkit", "can", "be", "used", "."], "sentence-detokenized": "For newer and more advanced techniques, the Kaldi toolkit can be used.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 18], [19, 27], [28, 38], [38, 39], [40, 43], [44, 49], [50, 57], [58, 61], [62, 64], [65, 69], [69, 70]]}
{"doc_key": "ai-test-34", "ner": [[0, 4, "researcher"], [8, 10, "organisation"], [16, 17, "organisation"], [23, 24, "organisation"], [27, 28, "researcher"], [31, 35, "organisation"], [41, 43, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 4, 8, 10, "role", "", false, false], [0, 4, 16, 17, "role", "", false, false], [0, 4, 23, 24, "role", "", false, false], [0, 4, 31, 35, "role", "", false, false], [0, 4, 41, 43, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Johnson", "-", "Laird", "is", "a", "Fellow", "of", "the", "American", "Philosophical", "Society", ",", "a", "Fellow", "of", "the", "Royal", "Society", ",", "a", "Fellow", "of", "the", "British", "Academy", ",", "a", "William", "James", "Fellow", "of", "the", "Association", "for", "Psychological", "Science", "and", "a", "Fellow", "of", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Johnson-Laird is a Fellow of the American Philosophical Society, a Fellow of the Royal Society, a Fellow of the British Academy, a William James Fellow of the Association for Psychological Science and a Fellow of the Cognitive Science Society.", "token2charspan": [[0, 7], [7, 8], [8, 13], [14, 16], [17, 18], [19, 25], [26, 28], [29, 32], [33, 41], [42, 55], [56, 63], [63, 64], [65, 66], [67, 73], [74, 76], [77, 80], [81, 86], [87, 94], [94, 95], [96, 97], [98, 104], [105, 107], [108, 111], [112, 119], [120, 127], [127, 128], [129, 130], [131, 138], [139, 144], [145, 151], [152, 154], [155, 158], [159, 170], [171, 174], [175, 188], [189, 196], [197, 200], [201, 202], [203, 209], [210, 212], [213, 216], [217, 226], [227, 234], [235, 242], [242, 243]]}
{"doc_key": "ai-test-35", "ner": [[0, 8, "conference"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"], [20, 22, "algorithm"], [30, 30, "task"], [26, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[11, 12, 0, 8, "physical", "", false, false], [11, 12, 0, 8, "temporal", "", false, false], [14, 15, 0, 8, "physical", "", false, false], [14, 15, 0, 8, "temporal", "", false, false], [17, 18, 0, 8, "physical", "", false, false], [17, 18, 0, 8, "temporal", "", false, false], [20, 22, 17, 18, "role", "extends", false, false], [30, 30, 17, 18, "role", "extends", false, false], [26, 32, 30, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["At", "the", "IEEE", "International", "Conference", "on", "Image", "Processing", "in", "2010", ",", "Rui", "Hu", ",", "Mark", "Banard", "and", "John", "Collomosse", "extended", "the", "HOG", "descriptor", "for", "use", "in", "sketch", "-", "based", "image", "retrieval", "(", "SBIR", ")", "."], "sentence-detokenized": "At the IEEE International Conference on Image Processing in 2010, Rui Hu, Mark Banard and John Collomosse extended the HOG descriptor for use in sketch-based image retrieval (SBIR).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 25], [26, 36], [37, 39], [40, 45], [46, 56], [57, 59], [60, 64], [64, 65], [66, 69], [70, 72], [72, 73], [74, 78], [79, 85], [86, 89], [90, 94], [95, 105], [106, 114], [115, 118], [119, 122], [123, 133], [134, 137], [138, 141], [142, 144], [145, 151], [151, 152], [152, 157], [158, 163], [164, 173], [174, 175], [175, 179], [179, 180], [180, 181]]}
{"doc_key": "ai-test-36", "ner": [[0, 0, "metrics"], [6, 6, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["BLEU", "uses", "a", "modified", "form", "of", "accuracy", "to", "compare", "a", "candidate", "translation", "with", "several", "reference", "translations", "."], "sentence-detokenized": "BLEU uses a modified form of accuracy to compare a candidate translation with several reference translations.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 20], [21, 25], [26, 28], [29, 37], [38, 40], [41, 48], [49, 50], [51, 60], [61, 72], [73, 77], [78, 85], [86, 95], [96, 108], [108, 109]]}
{"doc_key": "ai-test-37", "ner": [[31, 32, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "the", "case", "of", "a", "general", "fundamental", "space", "math", "(", "Y", ",\\", "mathcal", "{", "B", "},\\", "nu", ")", "/", "math", "(", "i.e.", "a", "fundamental", "space", "that", "is", "not", "computable", ")", ",", "relative", "entropy", "is", "typically", "considered", "."], "sentence-detokenized": "In the case of a general fundamental space math (Y,\\ mathcal {B},\\ nu) / math (i.e. a fundamental space that is not computable), relative entropy is typically considered.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 16], [17, 24], [25, 36], [37, 42], [43, 47], [48, 49], [49, 50], [50, 52], [53, 60], [61, 62], [62, 63], [63, 66], [67, 69], [69, 70], [71, 72], [73, 77], [78, 79], [79, 83], [84, 85], [86, 97], [98, 103], [104, 108], [109, 111], [112, 115], [116, 126], [126, 127], [127, 128], [129, 137], [138, 145], [146, 148], [149, 158], [159, 169], [169, 170]]}
{"doc_key": "ai-test-38", "ner": [[8, 10, "country"], [11, 11, "organisation"], [13, 13, "organisation"], [17, 17, "organisation"], [19, 22, "organisation"], [26, 28, "organisation"], [32, 37, "organisation"], [39, 39, "organisation"], [46, 47, "misc"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 8, 9, 11], "relations": [[11, 11, 8, 10, "physical", "", false, false], [13, 13, 11, 11, "named", "", false, false], [19, 22, 17, 17, "named", "", false, false], [39, 39, 32, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 3, 5], "sentence": ["By", "October", "2011", ",", "existing", "partnerships", "with", "the", "US", "National", "Park", "Service", "(", "NPS", ")", ",", "Historic", "Scotland", "(", "HS", ")", "in", "the", "UK", ",", "the", "World", "Monuments", "Fund", "and", "Mexico", "'s", "Instituto", "Nacional", "de", "Antropolog\u00eda", "y", "Historia", "(", "INAH", ")", "had", "been", "significantly", "expanded", ",", "CyArk", "website", "."], "sentence-detokenized": "By October 2011, existing partnerships with the US National Park Service (NPS), Historic Scotland (HS) in the UK, the World Monuments Fund and Mexico's Instituto Nacional de Antropolog\u00eda y Historia (INAH) had been significantly expanded, CyArk website.", "token2charspan": [[0, 2], [3, 10], [11, 15], [15, 16], [17, 25], [26, 38], [39, 43], [44, 47], [48, 50], [51, 59], [60, 64], [65, 72], [73, 74], [74, 77], [77, 78], [78, 79], [80, 88], [89, 97], [98, 99], [99, 101], [101, 102], [103, 105], [106, 109], [110, 112], [112, 113], [114, 117], [118, 123], [124, 133], [134, 138], [139, 142], [143, 149], [149, 151], [152, 161], [162, 170], [171, 173], [174, 186], [187, 188], [189, 197], [198, 199], [199, 203], [203, 204], [205, 208], [209, 213], [214, 227], [228, 236], [236, 237], [238, 243], [244, 251], [251, 252]]}
{"doc_key": "ai-test-39", "ner": [[0, 4, "algorithm"], [8, 9, "field"], [14, 14, "product"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 4, 14, 14, "part-of", "", false, false], [0, 4, 16, 16, "part-of", "", false, false], [14, 14, 8, 9, "general-affiliation", "", false, false], [16, 16, 8, 9, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kernel", "-", "SVM", "models", "are", "available", "in", "many", "machine", "learning", "toolkits", ",", "such", "as", "LIBSVM", ",", "MATLAB", "and", "others", "."], "sentence-detokenized": "Kernel-SVM models are available in many machine learning toolkits, such as LIBSVM, MATLAB and others.", "token2charspan": [[0, 6], [6, 7], [7, 10], [11, 17], [18, 21], [22, 31], [32, 34], [35, 39], [40, 47], [48, 56], [57, 65], [65, 66], [67, 71], [72, 74], [75, 81], [81, 82], [83, 89], [90, 93], [94, 100], [100, 101]]}
{"doc_key": "ai-test-40", "ner": [[2, 4, "misc"], [12, 14, "location"], [15, 16, "location"], [18, 18, "country"], [20, 26, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 12, 14, "physical", "", false, false], [2, 4, 20, 26, "temporal", "", false, false], [12, 14, 15, 16, "physical", "", false, false], [15, 16, 18, 18, "physical", "", false, false], [20, 26, 12, 14, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "2009", "Loebner", "Prize", "competition", "took", "place", "on", "6", "September", "2009", "at", "the", "Brighton", "Centre", "in", "Brighton", ",", "UK", ",", "in", "conjunction", "with", "the", "Interspeech", "2009", "conference", "."], "sentence-detokenized": "The 2009 Loebner Prize competition took place on 6 September 2009 at the Brighton Centre in Brighton, UK, in conjunction with the Interspeech 2009 conference.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 34], [35, 39], [40, 45], [46, 48], [49, 50], [51, 60], [61, 65], [66, 68], [69, 72], [73, 81], [82, 88], [89, 91], [92, 100], [100, 101], [102, 104], [104, 105], [106, 108], [109, 120], [121, 125], [126, 129], [130, 141], [142, 146], [147, 157], [157, 158]]}
{"doc_key": "ai-test-41", "ner": [[2, 3, "product"], [11, 11, "product"], [17, 19, "product"], [20, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[20, 22, 2, 3, "part-of", "", false, false], [20, 22, 11, 11, "part-of", "", false, false], [20, 22, 17, 19, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "humanoid", "QRIO", "robot", "was", "designed", "as", "a", "successor", "to", "the", "AIBO", ",", "and", "has", "the", "same", "R", "-", "CODE", "Aperios", "operating", "system", "."], "sentence-detokenized": "The humanoid QRIO robot was designed as a successor to the AIBO, and has the same R-CODE Aperios operating system.", "token2charspan": [[0, 3], [4, 12], [13, 17], [18, 23], [24, 27], [28, 36], [37, 39], [40, 41], [42, 51], [52, 54], [55, 58], [59, 63], [63, 64], [65, 68], [69, 72], [73, 76], [77, 81], [82, 83], [83, 84], [84, 88], [89, 96], [97, 106], [107, 113], [113, 114]]}
{"doc_key": "ai-test-42", "ner": [[0, 1, "misc"], [4, 6, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 0, 1, "cause-effect", "", true, false], [11, 12, 0, 1, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Speech", "waveforms", "are", "generated", "from", "the", "HMM", "itself", "based", "on", "the", "maximum", "likelihood", "criterion", "."], "sentence-detokenized": "Speech waveforms are generated from the HMM itself based on the maximum likelihood criterion.", "token2charspan": [[0, 6], [7, 16], [17, 20], [21, 30], [31, 35], [36, 39], [40, 43], [44, 50], [51, 56], [57, 59], [60, 63], [64, 71], [72, 82], [83, 92], [92, 93]]}
{"doc_key": "ai-test-43", "ner": [[0, 3, "product"], [5, 8, "task"], [10, 10, "task"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 5, 8, "type-of", "", false, false], [0, 3, 10, 10, "type-of", "", false, false], [0, 3, 16, 17, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Google", "Translate", "is", "a", "free", "multilingual", "statistical", "machine", "translation", "and", "neural", "machine", "translation", "service", "developed", "by", "Google", "that", "allows", "you", "to", "translate", "text", "and", "web", "pages", "from", "one", "language", "to", "another", "."], "sentence-detokenized": "Google Translate is a free multilingual statistical machine translation and neural machine translation service developed by Google that allows you to translate text and web pages from one language to another.", "token2charspan": [[0, 6], [7, 16], [17, 19], [20, 21], [22, 26], [27, 39], [40, 51], [52, 59], [60, 71], [72, 75], [76, 82], [83, 90], [91, 102], [103, 110], [111, 120], [121, 123], [124, 130], [131, 135], [136, 142], [143, 146], [147, 149], [150, 159], [160, 164], [165, 168], [169, 172], [173, 178], [179, 183], [184, 187], [188, 196], [197, 199], [200, 207], [207, 208]]}
{"doc_key": "ai-test-44", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [14, 16, "field"], [20, 23, "task"], [25, 26, "task"], [28, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[20, 23, 5, 6, "part-of", "", false, true], [20, 23, 8, 9, "part-of", "", false, true], [20, 23, 11, 12, "part-of", "", false, true], [25, 26, 5, 6, "part-of", "", false, true], [25, 26, 8, 9, "part-of", "", false, true], [25, 26, 11, 12, "part-of", "", false, true], [28, 31, 5, 6, "part-of", "", false, true], [28, 31, 8, 9, "part-of", "", false, true], [28, 31, 11, 12, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Skeletons", "are", "widely", "used", "in", "computer", "vision", ",", "image", "analysis", ",", "pattern", "recognition", "and", "digital", "image", "processing", ",", "for", "example", "for", "optical", "character", "recognition", ",", "fingerprint", "recognition", ",", "visual", "inspection", "or", "compression", "."], "sentence-detokenized": "Skeletons are widely used in computer vision, image analysis, pattern recognition and digital image processing, for example for optical character recognition, fingerprint recognition, visual inspection or compression.", "token2charspan": [[0, 9], [10, 13], [14, 20], [21, 25], [26, 28], [29, 37], [38, 44], [44, 45], [46, 51], [52, 60], [60, 61], [62, 69], [70, 81], [82, 85], [86, 93], [94, 99], [100, 110], [110, 111], [112, 115], [116, 123], [124, 127], [128, 135], [136, 145], [146, 157], [157, 158], [159, 170], [171, 182], [182, 183], [184, 190], [191, 201], [202, 204], [205, 216], [216, 217]]}
{"doc_key": "ai-test-45", "ner": [[0, 8, "conference"], [9, 12, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 8, 9, 12, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "is", "an", "object", "classification", "and", "recognition", "benchmark", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "categories", "."], "sentence-detokenized": "The ImageNet Large Scale Visual Recognition Challenge is an object classification and recognition benchmark with millions of images and hundreds of object categories.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 24], [25, 31], [32, 43], [44, 53], [54, 56], [57, 59], [60, 66], [67, 81], [82, 85], [86, 97], [98, 107], [108, 112], [113, 121], [122, 124], [125, 131], [132, 135], [136, 144], [145, 147], [148, 154], [155, 165], [165, 166]]}
{"doc_key": "ai-test-46", "ner": [[2, 2, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [15, 16, "misc"], [12, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 15, 16, "part-of", "", false, false], [2, 2, 12, 19, "part-of", "", false, false], [6, 7, 15, 16, "part-of", "", false, false], [6, 7, 12, 19, "part-of", "", false, false], [9, 10, 15, 16, "part-of", "", false, false], [9, 10, 12, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Some", "call", "Bengio", ",", "along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "the", "godfathers", "of", "artificial", "intelligence", "and", "deep", "learning", "."], "sentence-detokenized": "Some call Bengio, along with Geoffrey Hinton and Yann LeCun, the godfathers of artificial intelligence and deep learning.", "token2charspan": [[0, 4], [5, 9], [10, 16], [16, 17], [18, 23], [24, 28], [29, 37], [38, 44], [45, 48], [49, 53], [54, 59], [59, 60], [61, 64], [65, 75], [76, 78], [79, 89], [90, 102], [103, 106], [107, 111], [112, 120], [120, 121]]}
{"doc_key": "ai-test-47", "ner": [[3, 3, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "an", "IEEE", "Life", "Fellow", "."], "sentence-detokenized": "He is an IEEE Life Fellow.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 13], [14, 18], [19, 25], [25, 26]]}
{"doc_key": "ai-test-48", "ner": [[0, 1, "organisation"], [16, 21, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 16, 21, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NSA", "Bethesda", "is", "responsible", "for", "the", "operational", "support", "of", "the", "base", "to", "its", "main", "tenant", ",", "Walter", "Reed", "National", "Military", "Medical", "Center", "."], "sentence-detokenized": "NSA Bethesda is responsible for the operational support of the base to its main tenant, Walter Reed National Military Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 31], [32, 35], [36, 47], [48, 55], [56, 58], [59, 62], [63, 67], [68, 70], [71, 74], [75, 79], [80, 86], [86, 87], [88, 94], [95, 99], [100, 108], [109, 117], [118, 125], [126, 132], [132, 133]]}
{"doc_key": "ai-test-49", "ner": [[6, 7, "field"], [9, 10, "field"], [12, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "three", "main", "learning", "paradigms", "are", "supervised", "learning", ",", "unsupervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "The three main learning paradigms are supervised learning, unsupervised learning and reinforcement learning.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 23], [24, 33], [34, 37], [38, 48], [49, 57], [57, 58], [59, 71], [72, 80], [81, 84], [85, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-test-50", "ner": [[2, 2, "task"], [4, 6, "task"], [11, 15, "task"], [17, 18, "task"], [20, 22, "task"], [24, 25, "task"], [27, 28, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Examples", "include", "supervision", ",", "planning", "and", "scheduling", ",", "the", "ability", "to", "answer", "diagnostic", "and", "consumer", "questions", ",", "handwriting", "recognition", ",", "natural", "language", "understanding", ",", "speech", "recognition", "and", "facial", "recognition", "."], "sentence-detokenized": "Examples include supervision, planning and scheduling, the ability to answer diagnostic and consumer questions, handwriting recognition, natural language understanding, speech recognition and facial recognition.", "token2charspan": [[0, 8], [9, 16], [17, 28], [28, 29], [30, 38], [39, 42], [43, 53], [53, 54], [55, 58], [59, 66], [67, 69], [70, 76], [77, 87], [88, 91], [92, 100], [101, 110], [110, 111], [112, 123], [124, 135], [135, 136], [137, 144], [145, 153], [154, 167], [167, 168], [169, 175], [176, 187], [188, 191], [192, 198], [199, 210], [210, 211]]}
{"doc_key": "ai-test-51", "ner": [[9, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1991", ",", "he", "was", "elected", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "1990", ",", "founding", "member", ")", "."], "sentence-detokenized": "In 1991, he was elected a member of the Association for the Advancement of Artificial Intelligence (1990, founding member).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [99, 100], [100, 104], [104, 105], [106, 114], [115, 121], [121, 122], [122, 123]]}
{"doc_key": "ai-test-52", "ner": [[11, 12, "misc"], [15, 16, "algorithm"], [28, 30, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "by", "formulating", "the", "problem", "as", "a", "solution", "to", "the", "Toeplitz", "matrix", "and", "using", "Levinson", "recursion", ",", "we", "can", "relatively", "quickly", "estimate", "a", "filter", "with", "the", "smallest", "mean", "square", "error", "."], "sentence-detokenized": "However, by formulating the problem as a solution to the Toeplitz matrix and using Levinson recursion, we can relatively quickly estimate a filter with the smallest mean square error.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 23], [24, 27], [28, 35], [36, 38], [39, 40], [41, 49], [50, 52], [53, 56], [57, 65], [66, 72], [73, 76], [77, 82], [83, 91], [92, 101], [101, 102], [103, 105], [106, 109], [110, 120], [121, 128], [129, 137], [138, 139], [140, 146], [147, 151], [152, 155], [156, 164], [165, 169], [170, 176], [177, 182], [182, 183]]}
{"doc_key": "ai-test-53", "ner": [[5, 8, "conference"], [12, 20, "location"], [13, 15, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 8, 12, 20, "physical", "", false, false], [12, 20, 13, 15, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2011", ",", "the", "15th", "Campus", "Party", "Spain", "will", "take", "place", "in", "Valencia", ",", "the", "city", "of", "arts", "and", "sciences", "."], "sentence-detokenized": "In July 2011, the 15th Campus Party Spain will take place in Valencia, the city of arts and sciences.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 22], [23, 29], [30, 35], [36, 41], [42, 46], [47, 51], [52, 57], [58, 60], [61, 69], [69, 70], [71, 74], [75, 79], [80, 82], [83, 87], [88, 91], [92, 100], [100, 101]]}
{"doc_key": "ai-test-54", "ner": [[16, 16, "product"], [18, 18, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Often", "this", "is", "usually", "only", "possible", "at", "the", "end", "of", "very", "complex", "games", ",", "such", "as", "chess", "or", "go", ",", "because", "it", "is", "not", "mathematically", "possible", "to", "look", "ahead", "to", "the", "end", "of", "the", "game", ",", "except", "at", "the", "end", "of", "the", "game", ",", "and", "instead", "positions", "are", "given", "finite", "values", ",", "which", "are", "estimates", "of", "how", "much", "they", "are", "believed", "to", "lead", "to", "a", "win", "for", "one", "player", "or", "another", "."], "sentence-detokenized": "Often this is usually only possible at the end of very complex games, such as chess or go, because it is not mathematically possible to look ahead to the end of the game, except at the end of the game, and instead positions are given finite values, which are estimates of how much they are believed to lead to a win for one player or another.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 21], [22, 26], [27, 35], [36, 38], [39, 42], [43, 46], [47, 49], [50, 54], [55, 62], [63, 68], [68, 69], [70, 74], [75, 77], [78, 83], [84, 86], [87, 89], [89, 90], [91, 98], [99, 101], [102, 104], [105, 108], [109, 123], [124, 132], [133, 135], [136, 140], [141, 146], [147, 149], [150, 153], [154, 157], [158, 160], [161, 164], [165, 169], [169, 170], [171, 177], [178, 180], [181, 184], [185, 188], [189, 191], [192, 195], [196, 200], [200, 201], [202, 205], [206, 213], [214, 223], [224, 227], [228, 233], [234, 240], [241, 247], [247, 248], [249, 254], [255, 258], [259, 268], [269, 271], [272, 275], [276, 280], [281, 285], [286, 289], [290, 298], [299, 301], [302, 306], [307, 309], [310, 311], [312, 315], [316, 319], [320, 323], [324, 330], [331, 333], [334, 341], [341, 342]]}
{"doc_key": "ai-test-55", "ner": [[3, 6, "algorithm"], [25, 26, "algorithm"], [32, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[3, 6, 25, 26, "compare", "", false, false], [3, 6, 32, 34, "compare", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["The", "difference", "between", "a", "multinomial", "logit", "model", "and", "a", "number", "of", "other", "methods", ",", "models", ",", "algorithms", ",", "etc.", "with", "the", "same", "basic", "setup", "(", "perceptron", "algorithm", ",", "support", "vector", "machines", ",", "linear", "discriminant", "analysis", ",", "etc", "."], "sentence-detokenized": "The difference between a multinomial logit model and a number of other methods, models, algorithms, etc. with the same basic setup (perceptron algorithm, support vector machines, linear discriminant analysis, etc.", "token2charspan": [[0, 3], [4, 14], [15, 22], [23, 24], [25, 36], [37, 42], [43, 48], [49, 52], [53, 54], [55, 61], [62, 64], [65, 70], [71, 78], [78, 79], [80, 86], [86, 87], [88, 98], [98, 99], [100, 104], [105, 109], [110, 113], [114, 118], [119, 124], [125, 130], [131, 132], [132, 142], [143, 152], [152, 153], [154, 161], [162, 168], [169, 177], [177, 178], [179, 185], [186, 198], [199, 207], [207, 208], [209, 212], [212, 213]]}
{"doc_key": "ai-test-56", "ner": [[0, 3, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Association", "for", "Computational", "Linguistics", ",", "published", "by"], "sentence-detokenized": "Association for Computational Linguistics, published by", "token2charspan": [[0, 11], [12, 15], [16, 29], [30, 41], [41, 42], [43, 52], [53, 55]]}
{"doc_key": "ai-test-57", "ner": [[3, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "a", "computerised", "face", "recognition", "system", ",", "each", "face", "is", "represented", "by", "a", "large", "number", "of", "pixel", "values", "."], "sentence-detokenized": "In a computerised face recognition system, each face is represented by a large number of pixel values.", "token2charspan": [[0, 2], [3, 4], [5, 17], [18, 22], [23, 34], [35, 41], [41, 42], [43, 47], [48, 52], [53, 55], [56, 67], [68, 70], [71, 72], [73, 78], [79, 85], [86, 88], [89, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-test-58", "ner": [[5, 6, "person"], [12, 15, "organisation"], [21, 22, "country"], [25, 25, "person"], [35, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 12, 15, "role", "", false, false], [5, 6, 21, 22, "physical", "", false, false], [25, 25, 35, 37, "origin", "", false, false], [25, 25, 35, 37, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2002", ",", "his", "son", "Daniel", "Pearl", ",", "a", "journalist", "working", "for", "the", "Wall", "Street", "Journal", ",", "was", "kidnapped", "and", "murdered", "in", "Pakistan", ",", "prompting", "Judea", "and", "other", "family", "and", "friends", "to", "set", "up", "the", "Daniel", "Pearl", "Foundation", "."], "sentence-detokenized": "In 2002, his son Daniel Pearl, a journalist working for the Wall Street Journal, was kidnapped and murdered in Pakistan, prompting Judea and other family and friends to set up the Daniel Pearl Foundation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 23], [24, 29], [29, 30], [31, 32], [33, 43], [44, 51], [52, 55], [56, 59], [60, 64], [65, 71], [72, 79], [79, 80], [81, 84], [85, 94], [95, 98], [99, 107], [108, 110], [111, 119], [119, 120], [121, 130], [131, 136], [137, 140], [141, 146], [147, 153], [154, 157], [158, 165], [166, 168], [169, 172], [173, 175], [176, 179], [180, 186], [187, 192], [193, 203], [203, 204]]}
{"doc_key": "ai-test-59", "ner": [[4, 6, "organisation"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 18, 19, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "late", "2006", ",", "Red", "Envelope", "Entertainment", "also", "expanded", "its", "production", "of", "original", "content", "with", "filmmakers", "such", "as", "John", "Waters", "."], "sentence-detokenized": "In late 2006, Red Envelope Entertainment also expanded its production of original content with filmmakers such as John Waters.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 26], [27, 40], [41, 45], [46, 54], [55, 58], [59, 69], [70, 72], [73, 81], [82, 89], [90, 94], [95, 105], [106, 110], [111, 113], [114, 118], [119, 125], [125, 126]]}
{"doc_key": "ai-test-60", "ner": [[6, 11, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "building", "is", "now", "part", "of", "the", "Beth", "Israel", "Deaconess", "Medical", "Center", "."], "sentence-detokenized": "The building is now part of the Beth Israel Deaconess Medical Center.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 19], [20, 24], [25, 27], [28, 31], [32, 36], [37, 43], [44, 53], [54, 61], [62, 68], [68, 69]]}
{"doc_key": "ai-test-61", "ner": [[15, 15, "field"], [18, 20, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["What", "these", "works", "have", "in", "common", "is", "the", "adoption", "of", "a", "sign-", "theoretic", "approach", "to", "AI", "and", "the", "representation", "of", "knowledge", "."], "sentence-detokenized": "What these works have in common is the adoption of a sign-theoretic approach to AI and the representation of knowledge.", "token2charspan": [[0, 4], [5, 10], [11, 16], [17, 21], [22, 24], [25, 31], [32, 34], [35, 38], [39, 47], [48, 50], [51, 52], [53, 58], [58, 67], [68, 76], [77, 79], [80, 82], [83, 86], [87, 90], [91, 105], [106, 108], [109, 118], [118, 119]]}
{"doc_key": "ai-test-62", "ner": [[5, 9, "task"], [19, 20, "task"], [39, 40, "task"], [42, 43, "task"], [48, 50, "task"], [52, 52, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [[39, 40, 48, 50, "part-of", "", false, false], [42, 43, 48, 50, "part-of", "", false, false], [48, 50, 19, 20, "type-of", "", false, false], [52, 52, 48, 50, "named", "", false, false]], "relations_mapping_to_source": [4, 5, 6, 7], "sentence": ["For", "example", ",", "the", "term", "neural", "machine", "translation", "(", "NMT", ")", "highlights", "the", "fact", "that", "deep", "learning", "-", "based", "machine", "translation", "approaches", "learn", "sequence", "-", "to", "-", "sequence", "transformations", "directly", ",", "avoiding", "the", "need", "for", "intermediate", "steps", "such", "as", "word", "alignment", "and", "language", "modelling", "that", "were", "used", "in", "statistical", "machine", "translation", "(", "SMT", ")", "."], "sentence-detokenized": "For example, the term neural machine translation (NMT) highlights the fact that deep learning-based machine translation approaches learn sequence-to-sequence transformations directly, avoiding the need for intermediate steps such as word alignment and language modelling that were used in statistical machine translation (SMT).", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 36], [37, 48], [49, 50], [50, 53], [53, 54], [55, 65], [66, 69], [70, 74], [75, 79], [80, 84], [85, 93], [93, 94], [94, 99], [100, 107], [108, 119], [120, 130], [131, 136], [137, 145], [145, 146], [146, 148], [148, 149], [149, 157], [158, 173], [174, 182], [182, 183], [184, 192], [193, 196], [197, 201], [202, 205], [206, 218], [219, 224], [225, 229], [230, 232], [233, 237], [238, 247], [248, 251], [252, 260], [261, 270], [271, 275], [276, 280], [281, 285], [286, 288], [289, 300], [301, 308], [309, 320], [321, 322], [322, 325], [325, 326], [326, 327]]}
{"doc_key": "ai-test-63", "ner": [[2, 2, "field"], [12, 15, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 12, 15, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Most", "of", "WSD", "'s", "research", "in", "this", "area", "has", "been", "done", "using", "Word", "Net", "as", "a", "reference", "sensory", "catalogue", "."], "sentence-detokenized": "Most of WSD's research in this area has been done using WordNet as a reference sensory catalogue.", "token2charspan": [[0, 4], [5, 7], [8, 11], [11, 13], [14, 22], [23, 25], [26, 30], [31, 35], [36, 39], [40, 44], [45, 49], [50, 55], [56, 60], [60, 63], [64, 66], [67, 68], [69, 78], [79, 86], [87, 96], [96, 97]]}
{"doc_key": "ai-test-64", "ner": [[13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Among", "the", "prominent", "former", "PhD", "students", "and", "post-doctoral", "researchers", "in", "his", "group", "are", "Richard", "Zemel", "and", "Zoubin", "Ghahramani", "."], "sentence-detokenized": "Among the prominent former PhD students and post-doctoral researchers in his group are Richard Zemel and Zoubin Ghahramani.", "token2charspan": [[0, 5], [6, 9], [10, 19], [20, 26], [27, 30], [31, 39], [40, 43], [44, 57], [58, 69], [70, 72], [73, 76], [77, 82], [83, 86], [87, 94], [95, 100], [101, 104], [105, 111], [112, 122], [122, 123]]}
{"doc_key": "ai-test-65", "ner": [[6, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Each", "prediction", "result", "or", "instance", "of", "the", "mixing", "matrix", "represents", "one", "point", "in", "the", "ROC", "space", "."], "sentence-detokenized": "Each prediction result or instance of the mixing matrix represents one point in the ROC space.", "token2charspan": [[0, 4], [5, 15], [16, 22], [23, 25], [26, 34], [35, 37], [38, 41], [42, 48], [49, 55], [56, 66], [67, 70], [71, 76], [77, 79], [80, 83], [84, 87], [88, 93], [93, 94]]}
{"doc_key": "ai-test-66", "ner": [[3, 3, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"], [17, 20, "product"], [21, 24, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 21, 24, "physical", "", false, false], [7, 8, 21, 24, "physical", "", false, false], [10, 11, 21, 24, "physical", "", false, false], [17, 20, 3, 3, "artifact", "", false, false], [17, 20, 7, 8, "artifact", "", false, false], [17, 20, 10, 11, "artifact", "", false, false], [17, 20, 21, 24, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["In", "1997", ",", "Thrun", "and", "his", "colleagues", "Wolfram", "Burgard", "and", "Dieter", "Fox", "developed", "the", "world", "'s", "first", "robotic", "tour", "guide", "for", "the", "Deutsches", "Museum", "Bonn", "(", "1997", ")", "."], "sentence-detokenized": "In 1997, Thrun and his colleagues Wolfram Burgard and Dieter Fox developed the world's first robotic tour guide for the Deutsches Museum Bonn (1997).", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 18], [19, 22], [23, 33], [34, 41], [42, 49], [50, 53], [54, 60], [61, 64], [65, 74], [75, 78], [79, 84], [84, 86], [87, 92], [93, 100], [101, 105], [106, 111], [112, 115], [116, 119], [120, 129], [130, 136], [137, 141], [142, 143], [143, 147], [147, 148], [148, 149]]}
{"doc_key": "ai-test-67", "ner": [[0, 3, "product"], [7, 7, "misc"], [23, 25, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 0, 3, "part-of", "", false, false], [23, 25, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Word", "Net", "is", "a", "lexical", "database", "of", "semantic", "relationships", "between", "words", "in", "over", "200", "languages", ".", "Word", "Net", "is", "primarily", "used", "in", "automated", "natural", "language", "processing", "and", "artificial", "intelligence", "applications", "."], "sentence-detokenized": "WordNet is a lexical database of semantic relationships between words in over 200 languages. WordNet is primarily used in automated natural language processing and artificial intelligence applications.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 12], [13, 20], [21, 29], [30, 32], [33, 41], [42, 55], [56, 63], [64, 69], [70, 72], [73, 77], [78, 81], [82, 91], [91, 92], [93, 97], [97, 100], [101, 103], [104, 113], [114, 118], [119, 121], [122, 131], [132, 139], [140, 148], [149, 159], [160, 163], [164, 174], [175, 187], [188, 200], [200, 201]]}
{"doc_key": "ai-test-68", "ner": [[2, 4, "field"], [9, 12, "conference"], [15, 23, "conference"], [25, 25, "conference"], [27, 29, "conference"], [35, 36, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 12, 2, 4, "topic", "", false, false], [9, 12, 35, 36, "topic", "", false, false], [15, 23, 2, 4, "topic", "", false, false], [15, 23, 35, 36, "topic", "", false, false], [25, 25, 2, 4, "topic", "", false, false], [25, 25, 35, 36, "topic", "", false, false], [27, 29, 2, 4, "topic", "", false, false], [27, 29, 35, 36, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Conferences", "on", "natural", "language", "processing", ",", "such", "as", "the", "Association", "for", "Computational", "Linguistics", ",", "the", "North", "American", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ",", "EMNLP", "and", "HLT", ",", "have", "started", "to", "organise", "presentations", "on", "speech", "processing", "."], "sentence-detokenized": "Conferences on natural language processing, such as the Association for Computational Linguistics, the North American Chapter of the Association for Computational Linguistics, EMNLP and HLT, have started to organise presentations on speech processing.", "token2charspan": [[0, 11], [12, 14], [15, 22], [23, 31], [32, 42], [42, 43], [44, 48], [49, 51], [52, 55], [56, 67], [68, 71], [72, 85], [86, 97], [97, 98], [99, 102], [103, 108], [109, 117], [118, 125], [126, 128], [129, 132], [133, 144], [145, 148], [149, 162], [163, 174], [174, 175], [176, 181], [182, 185], [186, 189], [189, 190], [191, 195], [196, 203], [204, 206], [207, 215], [216, 229], [230, 232], [233, 239], [240, 250], [250, 251]]}
{"doc_key": "ai-test-69", "ner": [[19, 21, "misc"], [32, 34, "misc"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "number", "of", "Java", "programs", "use", "a", "vocabulary", "to", "identify", "variations", "in", "biomedical", "texts", "by", "associating", "words", "by", "their", "parts", "of", "speech", ",", "which", "can", "be", "useful", "for", "online", "searches", "or", "searching", "electronic", "medical", "records", "."], "sentence-detokenized": "A number of Java programs use a vocabulary to identify variations in biomedical texts by associating words by their parts of speech, which can be useful for online searches or searching electronic medical records.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 16], [17, 25], [26, 29], [30, 31], [32, 42], [43, 45], [46, 54], [55, 65], [66, 68], [69, 79], [80, 85], [86, 88], [89, 100], [101, 106], [107, 109], [110, 115], [116, 121], [122, 124], [125, 131], [131, 132], [133, 138], [139, 142], [143, 145], [146, 152], [153, 156], [157, 163], [164, 172], [173, 175], [176, 185], [186, 196], [197, 204], [205, 212], [212, 213]]}
{"doc_key": "ai-test-70", "ner": [[7, 7, "algorithm"], [9, 9, "algorithm"], [11, 11, "algorithm"], [13, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "many", "newer", "algorithms", "such", "as", "LPBoost", ",", "TotalBoost", ",", "BrownBoost", ",", "xgboost", ",", "MadaBoost", "and", "others", "."], "sentence-detokenized": "There are many newer algorithms such as LPBoost, TotalBoost, BrownBoost, xgboost, MadaBoost and others.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 20], [21, 31], [32, 36], [37, 39], [40, 47], [47, 48], [49, 59], [59, 60], [61, 71], [71, 72], [73, 80], [80, 81], [82, 91], [92, 95], [96, 102], [102, 103]]}
{"doc_key": "ai-test-71", "ner": [[5, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "implementation", "in", "Python", ":"], "sentence-detokenized": "This is an example implementation in Python:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 33], [34, 36], [37, 43], [43, 44]]}
{"doc_key": "ai-test-72", "ner": [[0, 1, "organisation"], [6, 9, "task"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Mattel", "'s", "Intellivision", "games", "console", "offered", "the", "Intellivoice", "Voice", "Synthesis", "module", "in", "1982", "."], "sentence-detokenized": "Mattel's Intellivision games console offered the Intellivoice Voice Synthesis module in 1982.", "token2charspan": [[0, 6], [6, 8], [9, 22], [23, 28], [29, 36], [37, 44], [45, 48], [49, 61], [62, 67], [68, 77], [78, 84], [85, 87], [88, 92], [92, 93]]}
{"doc_key": "ai-test-73", "ner": [[4, 5, "task"], [8, 15, "task"], [17, 19, "field"], [20, 22, "task"], [26, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 15, 4, 5, "part-of", "", false, false], [17, 19, 4, 5, "part-of", "", false, false], [20, 22, 4, 5, "part-of", "", false, false], [26, 31, 20, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "also", "worked", "on", "machine", "translation", ",", "both", "high", "-", "precision", "knowledge", "-", "based", "machine", "translation", "and", "machine", "learning", "for", "statistical", "machine", "translation", "(", "such", "as", "generalised", "example", "-", "based", "machine", "translation", ")", "."], "sentence-detokenized": "He also worked on machine translation, both high-precision knowledge-based machine translation and machine learning for statistical machine translation (such as generalised example-based machine translation).", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 17], [18, 25], [26, 37], [37, 38], [39, 43], [44, 48], [48, 49], [49, 58], [59, 68], [68, 69], [69, 74], [75, 82], [83, 94], [95, 98], [99, 106], [107, 115], [116, 119], [120, 131], [132, 139], [140, 151], [152, 153], [153, 157], [158, 160], [161, 172], [173, 180], [180, 181], [181, 186], [187, 194], [195, 206], [206, 207], [207, 208]]}
{"doc_key": "ai-test-74", "ner": [[0, 1, "misc"], [4, 4, "misc"], [20, 21, "algorithm"], [23, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 32, "field"], [34, 34, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 20, 21, "general-affiliation", "", false, false], [0, 1, 23, 24, "general-affiliation", "", false, false], [0, 1, 26, 27, "general-affiliation", "", false, false], [0, 1, 29, 29, "general-affiliation", "", false, false], [0, 1, 31, 32, "general-affiliation", "", false, false], [0, 1, 34, 34, "general-affiliation", "", false, false], [4, 4, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Wolfram", "Mathematica", "(", "usually", "Mathematica", ")", "is", "a", "modern", "engineering", "computing", "system", "that", "covers", "most", "areas", "of", "engineering", "-", "including", "neural", "networks", ",", "machine", "learning", ",", "image", "processing", ",", "geometry", ",", "data", "science", ",", "visualizations", "and", "more", "."], "sentence-detokenized": "Wolfram Mathematica (usually Mathematica) is a modern engineering computing system that covers most areas of engineering - including neural networks, machine learning, image processing, geometry, data science, visualizations and more.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 28], [29, 40], [40, 41], [42, 44], [45, 46], [47, 53], [54, 65], [66, 75], [76, 82], [83, 87], [88, 94], [95, 99], [100, 105], [106, 108], [109, 120], [121, 122], [123, 132], [133, 139], [140, 148], [148, 149], [150, 157], [158, 166], [166, 167], [168, 173], [174, 184], [184, 185], [186, 194], [194, 195], [196, 200], [201, 208], [208, 209], [210, 224], [225, 228], [229, 233], [233, 234]]}
{"doc_key": "ai-test-75", "ner": [[2, 6, "product"], [10, 12, "researcher"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 21, 2, 6, "type-of", "", false, false], [19, 21, 10, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "digitally", "controlled", "and", "programmable", "robot", "was", "invented", "by", "George", "Devol", "in", "1954", ",", "and", "was", "eventually", "called", "the", "Unimate", "robot", "."], "sentence-detokenized": "The first digitally controlled and programmable robot was invented by George Devol in 1954, and was eventually called the Unimate robot.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 30], [31, 34], [35, 47], [48, 53], [54, 57], [58, 66], [67, 69], [70, 76], [77, 82], [83, 85], [86, 90], [90, 91], [92, 95], [96, 99], [100, 110], [111, 117], [118, 121], [122, 129], [130, 135], [135, 136]]}
{"doc_key": "ai-test-76", "ner": [[1, 1, "algorithm"], [3, 3, "algorithm"], [16, 18, "task"], [20, 21, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 1, 3, 3, "compare", "", false, false], [3, 3, 16, 18, "general-affiliation", "", false, false], [3, 3, 20, 21, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Like", "DBNs", ",", "DBMs", "can", "learn", "complex", "and", "abstract", "internal", "representations", "from", "input", ",", "for", "example", "in", "object", "recognition", "or", "speech", "recognition", ",", "using", "limited", ",", "labelled", "data", "to", "refine", "representations", "built", "from", "a", "large", "set", "of", "unlabelled", "sensory", "data", "."], "sentence-detokenized": "Like DBNs, DBMs can learn complex and abstract internal representations from input, for example in object recognition or speech recognition, using limited, labelled data to refine representations built from a large set of unlabelled sensory data.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 15], [16, 19], [20, 25], [26, 33], [34, 37], [38, 46], [47, 55], [56, 71], [72, 76], [77, 82], [82, 83], [84, 87], [88, 95], [96, 98], [99, 105], [106, 117], [118, 120], [121, 127], [128, 139], [139, 140], [141, 146], [147, 154], [154, 155], [156, 164], [165, 169], [170, 172], [173, 179], [180, 195], [196, 201], [202, 206], [207, 208], [209, 214], [215, 218], [219, 221], [222, 232], [233, 240], [241, 245], [245, 246]]}
{"doc_key": "ai-test-77", "ner": [[7, 10, "task"], [0, 0, "conference"], [2, 2, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 7, 10, "topic", "", false, false], [2, 2, 7, 10, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["ICCV", "and", "CVPR", "are", "scientific", "conferences", "where", "visual", "activity", "recognition", "is", "often", "discussed", "."], "sentence-detokenized": "ICCV and CVPR are scientific conferences where visual activity recognition is often discussed.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 17], [18, 28], [29, 40], [41, 46], [47, 53], [54, 62], [63, 74], [75, 77], [78, 83], [84, 93], [93, 94]]}
{"doc_key": "ai-test-78", "ner": [[0, 3, "field"], [6, 8, "algorithm"], [18, 18, "metrics"], [21, 22, "metrics"], [24, 24, "metrics"], [38, 39, "misc"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6], "relations": [[6, 8, 0, 3, "part-of", "", false, false], [6, 8, 18, 18, "related-to", "finds", false, false], [6, 8, 21, 22, "related-to", "finds", false, false], [6, 8, 38, 39, "related-to", "", false, false], [24, 24, 21, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5], "sentence": ["In", "statistics", ",", "the", "EM", "(", "expectation", "-", "maximization", ")", "algorithm", "is", "an", "iterative", "method", "for", "finding", "maximum", "likelihood", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "estimates", "of", "parameters", "in", "statistical", "models", "where", "the", "model", "depends", "on", "unobserved", "latent", "variables", "."], "sentence-detokenized": "In statistics, the EM (expectation-maximization) algorithm is an iterative method for finding maximum likelihood or maximum a posteriori (MAP) estimates of parameters in statistical models where the model depends on unobserved latent variables.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 21], [22, 23], [23, 34], [34, 35], [35, 47], [47, 48], [49, 58], [59, 61], [62, 64], [65, 74], [75, 81], [82, 85], [86, 93], [94, 101], [102, 112], [113, 115], [116, 123], [124, 125], [126, 136], [137, 138], [138, 141], [141, 142], [143, 152], [153, 155], [156, 166], [167, 169], [170, 181], [182, 188], [189, 194], [195, 198], [199, 204], [205, 212], [213, 215], [216, 226], [227, 233], [234, 243], [243, 244]]}
{"doc_key": "ai-test-79", "ner": [[7, 14, "metrics"], [17, 17, "metrics"], [15, 19, "metrics"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[15, 19, 17, 17, "named", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Similarly", ",", "researchers", "sometimes", "report", "both", "a", "FALSE", "Positive", "Rate", "(", "FPR", ")", "and", "a", "FALSE", "Negative", "Rate", "(", "FNR", ")", "."], "sentence-detokenized": "Similarly, researchers sometimes report both a FALSE Positive Rate (FPR) and a FALSE Negative Rate (FNR).", "token2charspan": [[0, 9], [9, 10], [11, 22], [23, 32], [33, 39], [40, 44], [45, 46], [47, 52], [53, 61], [62, 66], [67, 68], [68, 71], [71, 72], [73, 76], [77, 78], [79, 84], [85, 93], [94, 98], [99, 100], [100, 103], [103, 104], [104, 105]]}
{"doc_key": "ai-test-80", "ner": [[6, 11, "metrics"], [13, 14, "field"], [17, 18, "metrics"], [20, 22, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 14, 6, 11, "usage", "", false, false], [20, 22, 17, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "concept", "is", "similar", "to", "the", "signal", "-", "to", "-", "noise", "ratio", "used", "in", "science", "and", "the", "mixing", "matrix", "used", "in", "artificial", "intelligence", "."], "sentence-detokenized": "The concept is similar to the signal-to-noise ratio used in science and the mixing matrix used in artificial intelligence.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 25], [26, 29], [30, 36], [36, 37], [37, 39], [39, 40], [40, 45], [46, 51], [52, 56], [57, 59], [60, 67], [68, 71], [72, 75], [76, 82], [83, 89], [90, 94], [95, 97], [98, 108], [109, 121], [121, 122]]}
{"doc_key": "ai-test-81", "ner": [[5, 6, "field"], [11, 12, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [33, 38, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 11, 12, "general-affiliation", "", false, false], [5, 6, 18, 19, "general-affiliation", "", false, false], [5, 6, 21, 22, "general-affiliation", "", false, false], [33, 38, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Code", "of", "Ethics", "for", "Human", "Augmentation", ",", "originally", "proposed", "by", "Steve", "Mann", "in", "2004", "and", "refined", "by", "Ray", "Kurzweil", "and", "Marvin", "Minsky", "in", "2013", ",", "was", "finally", "ratified", "on", "25", "June", "2017", "at", "the", "Virtual", "Reality", "Toronto", "conference", "."], "sentence-detokenized": "The Code of Ethics for Human Augmentation, originally proposed by Steve Mann in 2004 and refined by Ray Kurzweil and Marvin Minsky in 2013, was finally ratified on 25 June 2017 at the Virtual Reality Toronto conference.", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 18], [19, 22], [23, 28], [29, 41], [41, 42], [43, 53], [54, 62], [63, 65], [66, 71], [72, 76], [77, 79], [80, 84], [85, 88], [89, 96], [97, 99], [100, 103], [104, 112], [113, 116], [117, 123], [124, 130], [131, 133], [134, 138], [138, 139], [140, 143], [144, 151], [152, 160], [161, 163], [164, 166], [167, 171], [172, 176], [177, 179], [180, 183], [184, 191], [192, 199], [200, 207], [208, 218], [218, 219]]}
{"doc_key": "ai-test-82", "ner": [[3, 5, "person"], [12, 12, "organisation"], [17, 19, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 12, 12, "role", "directed_for", false, false], [3, 5, 17, 19, "role", "collaborator", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1913", ",", "Walter", "R.", "Booth", "directed", "10", "films", "for", "the", "British", "Cinematoplastikon", ",", "presumably", "in", "collaboration", "with", "Cecil", "Hepworth", "."], "sentence-detokenized": "In 1913, Walter R. Booth directed 10 films for the British Cinematoplastikon, presumably in collaboration with Cecil Hepworth.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 18], [19, 24], [25, 33], [34, 36], [37, 42], [43, 46], [47, 50], [51, 58], [59, 76], [76, 77], [78, 88], [89, 91], [92, 105], [106, 110], [111, 116], [117, 125], [125, 126]]}
{"doc_key": "ai-test-83", "ner": [[12, 12, "location"], [9, 10, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 10, 12, 12, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["They", "demonstrated", "the", "new", "robot", "in", "1961", "at", "the", "Cow", "Palace", "in", "Chicago", "."], "sentence-detokenized": "They demonstrated the new robot in 1961 at the Cow Palace in Chicago.", "token2charspan": [[0, 4], [5, 17], [18, 21], [22, 25], [26, 31], [32, 34], [35, 39], [40, 42], [43, 46], [47, 50], [51, 57], [58, 60], [61, 68], [68, 69]]}
{"doc_key": "ai-test-84", "ner": [[9, 10, "field"], [14, 15, "field"]], "ner_mapping_to_source": [2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "chatbot", "applications", "use", "extensive", "word", "classification", "processes", ",", "natural", "language", "processors", "and", "advanced", "artificial", "intelligence", ",", "while", "others", "simply", "search", "for", "generic", "keywords", "and", "generate", "answers", "using", "common", "phrases", "retrieved", "from", "a", "library", "or", "database", "."], "sentence-detokenized": "Some chatbot applications use extensive word classification processes, natural language processors and advanced artificial intelligence, while others simply search for generic keywords and generate answers using common phrases retrieved from a library or database.", "token2charspan": [[0, 4], [5, 12], [13, 25], [26, 29], [30, 39], [40, 44], [45, 59], [60, 69], [69, 70], [71, 78], [79, 87], [88, 98], [99, 102], [103, 111], [112, 122], [123, 135], [135, 136], [137, 142], [143, 149], [150, 156], [157, 163], [164, 167], [168, 175], [176, 184], [185, 188], [189, 197], [198, 205], [206, 211], [212, 218], [219, 226], [227, 236], [237, 241], [242, 243], [244, 251], [252, 254], [255, 263], [263, 264]]}
{"doc_key": "ai-test-85", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "WaveNet", "model", "proposed", "in", "2016", "will", "achieve", "excellent", "performance", "in", "speech", "quality", "."], "sentence-detokenized": "The WaveNet model proposed in 2016 will achieve excellent performance in speech quality.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 39], [40, 47], [48, 57], [58, 69], [70, 72], [73, 79], [80, 87], [87, 88]]}
{"doc_key": "ai-test-86", "ner": [[4, 4, "product"], [5, 7, "misc"], [9, 10, "misc"], [12, 13, "misc"], [15, 18, "misc"], [21, 23, "organisation"], [25, 25, "organisation"], [27, 27, "organisation"], [32, 32, "organisation"], [34, 35, "organisation"], [37, 38, "organisation"], [40, 40, "organisation"], [42, 44, "organisation"], [47, 47, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[4, 4, 5, 7, "general-affiliation", "", false, false], [4, 4, 9, 10, "general-affiliation", "", false, false], [4, 4, 12, 13, "general-affiliation", "", false, false], [4, 4, 15, 18, "general-affiliation", "", false, false], [21, 23, 4, 4, "usage", "", false, false], [25, 25, 4, 4, "usage", "", false, false], [27, 27, 4, 4, "usage", "", false, false], [32, 32, 4, 4, "usage", "", false, false], [34, 35, 4, 4, "usage", "", false, false], [37, 38, 4, 4, "usage", "", false, false], [40, 40, 4, 4, "usage", "", false, false], [42, 44, 4, 4, "usage", "", false, false], [47, 47, 4, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Organizations", "known", "to", "use", "ALE", "for", "emergency", "management", ",", "disaster", "relief", ",", "routine", "communications", "or", "response", "to", "extraordinary", "situations", ":", "the", "American", "Red", "Cross", ",", "FEMA", ",", "Disaster", "Medical", "Assistance", "Teams", ",", "NATO", ",", "Federal", "Police", ",", "United", "Nations", ",", "AT&T", ",", "Civil", "Air", "Patrol", ",", "(", "ARES", ")", "."], "sentence-detokenized": "Organizations known to use ALE for emergency management, disaster relief, routine communications or response to extraordinary situations: the American Red Cross, FEMA, Disaster Medical Assistance Teams, NATO, Federal Police, United Nations, AT&T, Civil Air Patrol, (ARES).", "token2charspan": [[0, 13], [14, 19], [20, 22], [23, 26], [27, 30], [31, 34], [35, 44], [45, 55], [55, 56], [57, 65], [66, 72], [72, 73], [74, 81], [82, 96], [97, 99], [100, 108], [109, 111], [112, 125], [126, 136], [136, 137], [138, 141], [142, 150], [151, 154], [155, 160], [160, 161], [162, 166], [166, 167], [168, 176], [177, 184], [185, 195], [196, 201], [201, 202], [203, 207], [207, 208], [209, 216], [217, 223], [223, 224], [225, 231], [232, 239], [239, 240], [241, 245], [245, 246], [247, 252], [253, 256], [257, 263], [263, 264], [265, 266], [266, 270], [270, 271], [271, 272]]}
{"doc_key": "ai-test-87", "ner": [[3, 5, "algorithm"], [15, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "simplicity", ",", "Kronecker", "'s", "delta", "is", "used", "here", "(", "cf", ".", "the", "derivative", "of", "a", "sigmoid", "function", ",", "which", "is", "expressed", "by", "the", "function", "itself", ")", "."], "sentence-detokenized": "For simplicity, Kronecker's delta is used here (cf. the derivative of a sigmoid function, which is expressed by the function itself).", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 25], [25, 27], [28, 33], [34, 36], [37, 41], [42, 46], [47, 48], [48, 50], [50, 51], [52, 55], [56, 66], [67, 69], [70, 71], [72, 79], [80, 88], [88, 89], [90, 95], [96, 98], [99, 108], [109, 111], [112, 115], [116, 124], [125, 131], [131, 132], [132, 133]]}
{"doc_key": "ai-test-88", "ner": [[11, 12, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "theory", "is", "based", "on", "philosophical", "foundations", "and", "was", "established", "by", "Ray", "Solomonoff", "around", "1960", ".", "Samuel", "Rathmanner", "and", "Marcus", "Hutter", "."], "sentence-detokenized": "The theory is based on philosophical foundations and was established by Ray Solomonoff around 1960. Samuel Rathmanner and Marcus Hutter.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 36], [37, 48], [49, 52], [53, 56], [57, 68], [69, 71], [72, 75], [76, 86], [87, 93], [94, 98], [98, 99], [100, 106], [107, 117], [118, 121], [122, 128], [129, 135], [135, 136]]}
{"doc_key": "ai-test-89", "ner": [[0, 1, "product"], [12, 19, "misc"], [16, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 12, 19, "type-of", "", false, false], [0, 1, 16, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Word", "Net", "is", "a", "freely", "available", "database", ",", "originally", "designed", "as", "a", "semantic", "network", "based", "on", "psycholinguistic", "principles", ".", "It", "has", "been", "extended", "to", "include", "definitions", "and", "is", "now", "also", "considered", "a", "dictionary", "."], "sentence-detokenized": "WordNet is a freely available database, originally designed as a semantic network based on psycholinguistic principles. It has been extended to include definitions and is now also considered a dictionary.", "token2charspan": [[0, 4], [4, 7], [8, 10], [11, 12], [13, 19], [20, 29], [30, 38], [38, 39], [40, 50], [51, 59], [60, 62], [63, 64], [65, 73], [74, 81], [82, 87], [88, 90], [91, 107], [108, 118], [118, 119], [120, 122], [123, 126], [127, 131], [132, 140], [141, 143], [144, 151], [152, 163], [164, 167], [168, 170], [171, 174], [175, 179], [180, 190], [191, 192], [193, 203], [203, 204]]}
{"doc_key": "ai-test-90", "ner": [[2, 2, "field"], [14, 15, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 15, 2, 2, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Progress", "in", "computational", "imaging", "research", "is", "presented", "in", "a", "variety", "of", "venues", ",", "including", "SIGGRAPH", "publications", "and", "."], "sentence-detokenized": "Progress in computational imaging research is presented in a variety of venues, including SIGGRAPH publications and.", "token2charspan": [[0, 8], [9, 11], [12, 25], [26, 33], [34, 42], [43, 45], [46, 55], [56, 58], [59, 60], [61, 68], [69, 71], [72, 78], [78, 79], [80, 89], [90, 98], [99, 111], [112, 115], [115, 116]]}
{"doc_key": "ai-test-91", "ner": [[0, 0, "task"], [10, 11, "task"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 0, 0, "part-of", "", false, false], [13, 14, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "thought", "of", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multiclass", "classification", "."], "sentence-detokenized": "Classification can be thought of as two separate problems - binary classification and multiclass classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 29], [30, 32], [33, 35], [36, 39], [40, 48], [49, 57], [58, 59], [60, 66], [67, 81], [82, 85], [86, 96], [97, 111], [111, 112]]}
{"doc_key": "ai-test-92", "ner": [[18, 19, "algorithm"], [22, 22, "algorithm"]], "ner_mapping_to_source": [1, 2], "relations": [[22, 22, 18, 19, "named", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Advanced", "gene", "discovery", "tools", "for", "both", "prokaryotic", "and", "eukaryotic", "genomes", "typically", "use", "complex", "probabilistic", "models", ",", "such", "as", "hidden", "Markov", "models", "(", "HMMs", ")", ",", "to", "combine", "data", "from", "different", "signal", "and", "content", "measurements", "."], "sentence-detokenized": "Advanced gene discovery tools for both prokaryotic and eukaryotic genomes typically use complex probabilistic models, such as hidden Markov models (HMMs), to combine data from different signal and content measurements.", "token2charspan": [[0, 8], [9, 13], [14, 23], [24, 29], [30, 33], [34, 38], [39, 50], [51, 54], [55, 65], [66, 73], [74, 83], [84, 87], [88, 95], [96, 109], [110, 116], [116, 117], [118, 122], [123, 125], [126, 132], [133, 139], [140, 146], [147, 148], [148, 152], [152, 153], [153, 154], [155, 157], [158, 165], [166, 170], [171, 175], [176, 185], [186, 192], [193, 196], [197, 204], [205, 217], [217, 218]]}
{"doc_key": "ai-test-93", "ner": [[0, 0, "misc"], [1, 2, "misc"], [5, 6, "field"], [9, 10, "algorithm"], [13, 13, "algorithm"], [17, 17, "algorithm"], [27, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 5, 6, "part-of", "", false, false], [0, 0, 9, 10, "usage", "", false, false], [1, 2, 0, 0, "named", "", false, false], [13, 13, 0, 0, "origin", "", true, false], [17, 17, 13, 13, "named", "", false, false], [27, 28, 0, 0, "origin", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Neuroevolution", "is", "a", "form", "of", "artificial", "intelligence", "that", "uses", "evolutionary", "algorithms", "to", "create", "artificial", "neural", "networks", "(", "ANNs", ")", ",", "parameters", ",", "topology", "and", "rules", ".", "and", "evolutionary", "robotics", "."], "sentence-detokenized": "Neuroevolution is a form of artificial intelligence that uses evolutionary algorithms to create artificial neural networks (ANNs), parameters, topology and rules. and evolutionary robotics.", "token2charspan": [[0, 14], [15, 17], [18, 19], [20, 24], [25, 27], [28, 38], [39, 51], [52, 56], [57, 61], [62, 74], [75, 85], [86, 88], [89, 95], [96, 106], [107, 113], [114, 122], [123, 124], [124, 128], [128, 129], [129, 130], [131, 141], [141, 142], [143, 151], [152, 155], [156, 161], [161, 162], [163, 166], [167, 179], [180, 188], [188, 189]]}
{"doc_key": "ai-test-94", "ner": [[1, 1, "organisation"], [5, 7, "metrics"], [9, 9, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 1, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "IBM", "proposed", "and", "implemented", "the", "BLEU", "system", ",", "Papineni", "et", "al", "."], "sentence-detokenized": "Since IBM proposed and implemented the BLEU system, Papineni et al.", "token2charspan": [[0, 5], [6, 9], [10, 18], [19, 22], [23, 34], [35, 38], [39, 43], [44, 50], [50, 51], [52, 60], [61, 63], [64, 66], [66, 67]]}
{"doc_key": "ai-test-95", "ner": [[12, 16, "conference"], [10, 18, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 18, 12, 16, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2009", ",", "experts", "attended", "a", "conference", "hosted", "by", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "to", "discuss", "whether", "computers", "and", "robots", "can", "achieve", "autonomy", "and", "how", "much", "of", "a", "threat", "or", "danger", "these", "capabilities", "can", "pose", "."], "sentence-detokenized": "In 2009, experts attended a conference hosted by the Association for the Advancement of Artificial Intelligence (AAAI) to discuss whether computers and robots can achieve autonomy and how much of a threat or danger these capabilities can pose.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 16], [17, 25], [26, 27], [28, 38], [39, 45], [46, 48], [49, 52], [53, 64], [65, 68], [69, 72], [73, 84], [85, 87], [88, 98], [99, 111], [112, 113], [113, 117], [117, 118], [119, 121], [122, 129], [130, 137], [138, 147], [148, 151], [152, 158], [159, 162], [163, 170], [171, 179], [180, 183], [184, 187], [188, 192], [193, 195], [196, 197], [198, 204], [205, 207], [208, 214], [215, 220], [221, 233], [234, 237], [238, 242], [242, 243]]}
{"doc_key": "ai-test-96", "ner": [[22, 23, "researcher"], [25, 26, "researcher"], [28, 33, "task"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[28, 33, 22, 23, "artifact", "", false, false], [28, 33, 25, 26, "artifact", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["After", "boosting", ",", "a", "classifier", "of", "200", "features", "can", "produce", "a", "95", "%", "detection", "rate", "in", "^", "{", "-", "5", "}", "/", "P.", "Viola", ",", "M.", "Jones", ",", "Robust", "Real", "-", "time", "Object", "Detection", ",", "2001", "."], "sentence-detokenized": "After boosting, a classifier of 200 features can produce a 95% detection rate in ^ {-5} / P. Viola, M. Jones, Robust Real-time Object Detection, 2001.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 17], [18, 28], [29, 31], [32, 35], [36, 44], [45, 48], [49, 56], [57, 58], [59, 61], [61, 62], [63, 72], [73, 77], [78, 80], [81, 82], [83, 84], [84, 85], [85, 86], [86, 87], [88, 89], [90, 92], [93, 98], [98, 99], [100, 102], [103, 108], [108, 109], [110, 116], [117, 121], [121, 122], [122, 126], [127, 133], [134, 143], [143, 144], [145, 149], [149, 150]]}
{"doc_key": "ai-test-97", "ner": [[9, 9, "organisation"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "site", "was", "originally", "Perl", "-", "based", ",", "but", "IMDb", "no", "longer", "reveals", "which", "software", "it", "uses", "for", "security", "reasons", "."], "sentence-detokenized": "The site was originally Perl-based, but IMDb no longer reveals which software it uses for security reasons.", "token2charspan": [[0, 3], [4, 8], [9, 12], [13, 23], [24, 28], [28, 29], [29, 34], [34, 35], [36, 39], [40, 44], [45, 47], [48, 54], [55, 62], [63, 68], [69, 77], [78, 80], [81, 85], [86, 89], [90, 98], [99, 106], [106, 107]]}
{"doc_key": "ai-test-98", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Demis", "Hassabis", ",", "Shane", "Legg", "and", "Mustafa", "Suleyman", "founded", "the", "company", "in", "2010", "."], "sentence-detokenized": "Demis Hassabis, Shane Legg and Mustafa Suleyman founded the company in 2010.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 21], [22, 26], [27, 30], [31, 38], [39, 47], [48, 55], [56, 59], [60, 67], [68, 70], [71, 75], [75, 76]]}
{"doc_key": "ai-test-99", "ner": [[4, 5, "misc"], [7, 9, "metrics"], [23, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 9, 4, 5, "type-of", "", false, false], [23, 24, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "very", "commonly", "used", "loss", "functions", "are", "mean", "squared", "error", ",", "mathL", "(", "a", ")", "=", "a", "^", "2", "/", "math", ",", "and", "absolute", "loss", ",", "mathL", "(", "a", ")", "=", "|", "a", "|", "|", "/", "math", "."], "sentence-detokenized": "Two very commonly used loss functions are mean squared error, mathL (a) = a ^ 2 / math, and absolute loss, mathL (a) = | a | | / math.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 27], [28, 37], [38, 41], [42, 46], [47, 54], [55, 60], [60, 61], [62, 67], [68, 69], [69, 70], [70, 71], [72, 73], [74, 75], [76, 77], [78, 79], [80, 81], [82, 86], [86, 87], [88, 91], [92, 100], [101, 105], [105, 106], [107, 112], [113, 114], [114, 115], [115, 116], [117, 118], [119, 120], [121, 122], [123, 124], [125, 126], [127, 128], [129, 133], [133, 134]]}
{"doc_key": "ai-test-100", "ner": [[3, 5, "algorithm"], [12, 14, "algorithm"], [16, 16, "algorithm"], [19, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 5, 12, 14, "type-of", "example_of", false, false], [12, 14, 19, 20, "related-to", "", false, false], [16, 16, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "soft", "-margin", "support", "vector", "machine", "described", "above", "is", "an", "example", "of", "empirical", "risk", "minimisation", "(", "ERM", ")", "for", "hinge", "loss", "."], "sentence-detokenized": "The soft-margin support vector machine described above is an example of empirical risk minimisation (ERM) for hinge loss.", "token2charspan": [[0, 3], [4, 8], [8, 15], [16, 23], [24, 30], [31, 38], [39, 48], [49, 54], [55, 57], [58, 60], [61, 68], [69, 71], [72, 81], [82, 86], [87, 99], [100, 101], [101, 104], [104, 105], [106, 109], [110, 115], [116, 120], [120, 121]]}
{"doc_key": "ai-test-101", "ner": [[0, 2, "field"], [4, 4, "task"], [6, 8, "task"], [19, 20, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 8, 0, 2, "origin", "", false, false], [6, 8, 4, 4, "type-of", "", false, false], [19, 20, 6, 8, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "deep", "learning", "approach", "MT", ",", "neural", "machine", "translation", ",", "has", "made", "rapid", "progress", "in", "recent", "years", ",", "and", "Google", "has", "announced", "that", "its", "translation", "services", "now", "use", "this", "technique", "instead", "of", "the", "statistical", "methods", "of", "the", "past", "."], "sentence-detokenized": "The deep learning approach MT, neural machine translation, has made rapid progress in recent years, and Google has announced that its translation services now use this technique instead of the statistical methods of the past.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 26], [27, 29], [29, 30], [31, 37], [38, 45], [46, 57], [57, 58], [59, 62], [63, 67], [68, 73], [74, 82], [83, 85], [86, 92], [93, 98], [98, 99], [100, 103], [104, 110], [111, 114], [115, 124], [125, 129], [130, 133], [134, 145], [146, 154], [155, 158], [159, 162], [163, 167], [168, 177], [178, 185], [186, 188], [189, 192], [193, 204], [205, 212], [213, 215], [216, 219], [220, 224], [224, 225]]}
{"doc_key": "ai-test-102", "ner": [[10, 14, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "usually", "leads", "to", "very", "large", "performance", "improvements", "when", "working", "with", "large", "corporations", "like", "WordNet", "."], "sentence-detokenized": "This usually leads to very large performance improvements when working with large corporations like WordNet.", "token2charspan": [[0, 4], [5, 12], [13, 18], [19, 21], [22, 26], [27, 32], [33, 44], [45, 57], [58, 62], [63, 70], [71, 75], [76, 81], [82, 94], [95, 99], [100, 107], [107, 108]]}
{"doc_key": "ai-test-103", "ner": [[0, 1, "task"], [4, 5, "field"], [18, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 18, 20, "part-of", "", false, false], [18, 20, 4, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Facial", "recognition", "is", "used", "in", "biometrics", ",", "often", "as", "part", "of", "(", "or", "in", "combination", "with", ")", "a", "facial", "recognition", "system", "."], "sentence-detokenized": "Facial recognition is used in biometrics, often as part of (or in combination with) a facial recognition system.", "token2charspan": [[0, 6], [7, 18], [19, 21], [22, 26], [27, 29], [30, 40], [40, 41], [42, 47], [48, 50], [51, 55], [56, 58], [59, 60], [60, 62], [63, 65], [66, 77], [78, 82], [82, 83], [84, 85], [86, 92], [93, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-test-104", "ner": [[1, 4, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["trained", "with", "maximum", "likelihood", "estimation", "."], "sentence-detokenized": "trained with maximum likelihood estimation.", "token2charspan": [[0, 7], [8, 12], [13, 20], [21, 31], [32, 42], [42, 43]]}
{"doc_key": "ai-test-105", "ner": [[1, 2, "country"], [4, 8, "organisation"], [12, 12, "location"], [14, 14, "country"], [16, 19, "organisation"], [20, 21, "country"], [27, 27, "organisation"], [32, 36, "organisation"], [37, 37, "country"], [47, 51, "organisation"], [52, 53, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[4, 8, 12, 12, "physical", "", false, false], [12, 12, 14, 14, "physical", "", false, false], [16, 19, 20, 21, "physical", "", false, false], [32, 36, 37, 37, "physical", "", false, false], [47, 51, 52, 53, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Ltd.", "in", "Thailand", ",", "Komatsu", "(", "Shanghai", ")", "Ltd.", "in", "1996", "in", "Shanghai", ",", "China", ",", "Industrial", "Power", "Alliance", "Ltd.", "in", "Japan", ",", "a", "joint", "venture", "with", "Cummins", ",", "in", "1998", ",", "L&T", "-", "Komatsu", "Limited", "in", "India", "in", "1998", "(", "shares", "sold", "in", "2013", ")", "and", "Komatsu", "Brasil", "International", "Ltda", ".", "Brazil", "in", "1998", "."], "sentence-detokenized": "Ltd. in Thailand, Komatsu (Shanghai) Ltd. in 1996 in Shanghai, China, Industrial Power Alliance Ltd. in Japan, a joint venture with Cummins, in 1998, L&T-Komatsu Limited in India in 1998 (shares sold in 2013) and Komatsu Brasil International Ltda. Brazil in 1998.", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 25], [26, 27], [27, 35], [35, 36], [37, 41], [42, 44], [45, 49], [50, 52], [53, 61], [61, 62], [63, 68], [68, 69], [70, 80], [81, 86], [87, 95], [96, 100], [101, 103], [104, 109], [109, 110], [111, 112], [113, 118], [119, 126], [127, 131], [132, 139], [139, 140], [141, 143], [144, 148], [148, 149], [150, 153], [153, 154], [154, 161], [162, 169], [170, 172], [173, 178], [179, 181], [182, 186], [187, 188], [188, 194], [195, 199], [200, 202], [203, 207], [207, 208], [209, 212], [213, 220], [221, 227], [228, 241], [242, 246], [246, 247], [248, 254], [255, 257], [258, 262], [262, 263]]}
{"doc_key": "ai-test-106", "ner": [[0, 1, "organisation"], [5, 7, "misc"], [12, 13, "person"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[12, 13, 0, 1, "physical", "", false, false], [12, 13, 5, 7, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "dgp", "also", "occasionally", "hosts", "artists", "in", "residence", "(", "e.g.", "Oscar", "winner", "Chris", "Landreth", ")", "."], "sentence-detokenized": "The dgp also occasionally hosts artists in residence (e.g. Oscar winner Chris Landreth).", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 25], [26, 31], [32, 39], [40, 42], [43, 52], [53, 54], [54, 58], [59, 64], [65, 71], [72, 77], [78, 86], [86, 87], [87, 88]]}
{"doc_key": "ai-test-107", "ner": [[6, 9, "misc"], [12, 14, "misc"], [17, 20, "misc"], [24, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "currently", "includes", "four", "events", "-", "the", "RoboMaster", "Robotics", "Competition", ",", "the", "RoboMaster", "Technical", "Challenge", ",", "the", "ICRA", "RoboMaster", "AI", "Challenge", "and", "the", "new", "RoboMaster", "Youth", "Tournament", "."], "sentence-detokenized": "It currently includes four events - the RoboMaster Robotics Competition, the RoboMaster Technical Challenge, the ICRA RoboMaster AI Challenge and the new RoboMaster Youth Tournament.", "token2charspan": [[0, 2], [3, 12], [13, 21], [22, 26], [27, 33], [34, 35], [36, 39], [40, 50], [51, 59], [60, 71], [71, 72], [73, 76], [77, 87], [88, 97], [98, 107], [107, 108], [109, 112], [113, 117], [118, 128], [129, 131], [132, 141], [142, 145], [146, 149], [150, 153], [154, 164], [165, 170], [171, 181], [181, 182]]}
{"doc_key": "ai-test-108", "ner": [[16, 18, "algorithm"], [22, 23, "algorithm"], [25, 26, "field"]], "ner_mapping_to_source": [1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["By", "the", "early", "2000s", ",", "the", "dominant", "speech", "processing", "strategy", "began", "to", "move", "away", "from", "the", "Hidden", "Markov", "Model", "towards", "more", "modern", "neural", "networks", "and", "deep", "learning", "."], "sentence-detokenized": "By the early 2000s, the dominant speech processing strategy began to move away from the Hidden Markov Model towards more modern neural networks and deep learning.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 18], [18, 19], [20, 23], [24, 32], [33, 39], [40, 50], [51, 59], [60, 65], [66, 68], [69, 73], [74, 78], [79, 83], [84, 87], [88, 94], [95, 101], [102, 107], [108, 115], [116, 120], [121, 127], [128, 134], [135, 143], [144, 147], [148, 152], [153, 161], [161, 162]]}
{"doc_key": "ai-test-109", "ner": [[5, 7, "misc"], [10, 13, "metrics"], [16, 18, "metrics"], [24, 27, "metrics"], [30, 32, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[10, 13, 16, 18, "related-to", "equal", false, false], [24, 27, 30, 32, "related-to", "equal", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "equivalent", "expression", "for", "the", "binary", "target", "level", "is", "that", "the", "TRUE", "positive", "rate", "and", "the", "FALSE", "positive", "rate", "are", "equal", "(", "and", "hence", "the", "FALSE", "negative", "rate", "and", "the", "TRUE", "negative", "rate", "are", "equal", ")", "for", "each", "value", "of", "the", "sensitive", "characteristics", ":"], "sentence-detokenized": "Another equivalent expression for the binary target level is that the TRUE positive rate and the FALSE positive rate are equal (and hence the FALSE negative rate and the TRUE negative rate are equal) for each value of the sensitive characteristics:", "token2charspan": [[0, 7], [8, 18], [19, 29], [30, 33], [34, 37], [38, 44], [45, 51], [52, 57], [58, 60], [61, 65], [66, 69], [70, 74], [75, 83], [84, 88], [89, 92], [93, 96], [97, 102], [103, 111], [112, 116], [117, 120], [121, 126], [127, 128], [128, 131], [132, 137], [138, 141], [142, 147], [148, 156], [157, 161], [162, 165], [166, 169], [170, 174], [175, 183], [184, 188], [189, 192], [193, 198], [198, 199], [200, 203], [204, 208], [209, 214], [215, 217], [218, 221], [222, 231], [232, 247], [247, 248]]}
{"doc_key": "ai-test-110", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["MATLAB", "function", ","], "sentence-detokenized": "MATLAB function,", "token2charspan": [[0, 6], [7, 15], [15, 16]]}
{"doc_key": "ai-test-111", "ner": [[0, 4, "product"], [7, 7, "misc"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 0, 4, "part-of", "", false, false], [16, 17, 0, 4, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "articulated", "robot", "is", "a", "robot", "with", "rotating", "joints", "(", "e.g.", "a", "legged", "robot", "or", "an", "industrial", "robot", ")", "."], "sentence-detokenized": "An articulated robot is a robot with rotating joints (e.g. a legged robot or an industrial robot).", "token2charspan": [[0, 2], [3, 14], [15, 20], [21, 23], [24, 25], [26, 31], [32, 36], [37, 45], [46, 52], [53, 54], [54, 58], [59, 60], [61, 67], [68, 73], [74, 76], [77, 79], [80, 90], [91, 96], [96, 97], [97, 98]]}
{"doc_key": "ai-test-112", "ner": [[0, 0, "product"], [5, 6, "product"], [8, 9, "product"], [13, 13, "misc"], [18, 22, "product"], [23, 28, "misc"], [34, 34, "location"], [36, 36, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 0, 13, 13, "general-affiliation", "nationality", false, false], [0, 0, 23, 28, "usage", "", false, false], [0, 0, 34, 34, "physical", "", false, false], [5, 6, 0, 0, "named", "", false, false], [8, 9, 0, 0, "named", "", false, false], [34, 34, 36, 36, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Pandora", "(", "also", "known", "as", "Pandora", "Media", "or", "Pandora", "Radio", ")", "is", "an", "American", "music", "streaming", "service", "and", "automated", "recommendation", "system", "operated", "by", "the", "Music", "Genome", "Project", ",", "an", "internet", "radio", "service", "headquartered", "in", "Oakland", ",", "California", "."], "sentence-detokenized": "Pandora (also known as Pandora Media or Pandora Radio) is an American music streaming service and automated recommendation system operated by the Music Genome Project, an internet radio service headquartered in Oakland, California.", "token2charspan": [[0, 7], [8, 9], [9, 13], [14, 19], [20, 22], [23, 30], [31, 36], [37, 39], [40, 47], [48, 53], [53, 54], [55, 57], [58, 60], [61, 69], [70, 75], [76, 85], [86, 93], [94, 97], [98, 107], [108, 122], [123, 129], [130, 138], [139, 141], [142, 145], [146, 151], [152, 158], [159, 166], [166, 167], [168, 170], [171, 179], [180, 185], [186, 193], [194, 207], [208, 210], [211, 218], [218, 219], [220, 230], [230, 231]]}
{"doc_key": "ai-test-113", "ner": [[7, 10, "organisation"], [16, 17, "organisation"], [25, 26, "conference"], [38, 38, "conference"], [40, 40, "conference"], [42, 42, "conference"], [44, 44, "conference"], [46, 46, "conference"], [48, 48, "conference"], [50, 50, "conference"], [52, 52, "conference"], [54, 54, "conference"], [56, 56, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "board", "member", "of", "the", "International", "Machine", "Learning", "Society", ",", "has", "served", "on", "the", "AAAI", "board", ",", "was", "co-chair", "of", "the", "PC", "at", "ICML", "2011", ",", "and", "has", "served", "as", "PC", "senior", "member", "at", "conferences", "including", "AAAI", ",", "ICML", ",", "IJCAI", ",", "ISWC", ",", "KDD", ",", "SIGMOD", ",", "UAI", ",", "VLDB", ",", "WSDM", ",", "WWW", ",", "and", "others", "."], "sentence-detokenized": "He is a board member of the International Machine Learning Society, has served on the AAAI board, was co-chair of the PC at ICML 2011, and has served as PC senior member at conferences including AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM, WWW, and others.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 13], [14, 20], [21, 23], [24, 27], [28, 41], [42, 49], [50, 58], [59, 66], [66, 67], [68, 71], [72, 78], [79, 81], [82, 85], [86, 90], [91, 96], [96, 97], [98, 101], [102, 110], [111, 113], [114, 117], [118, 120], [121, 123], [124, 128], [129, 133], [133, 134], [135, 138], [139, 142], [143, 149], [150, 152], [153, 155], [156, 162], [163, 169], [170, 172], [173, 184], [185, 194], [195, 199], [199, 200], [201, 205], [205, 206], [207, 212], [212, 213], [214, 218], [218, 219], [220, 223], [223, 224], [225, 231], [231, 232], [233, 236], [236, 237], [238, 242], [242, 243], [244, 248], [248, 249], [250, 253], [253, 254], [255, 258], [259, 265], [265, 266]]}
{"doc_key": "ai-test-114", "ner": [[0, 5, "researcher"], [6, 10, "organisation"], [12, 12, "organisation"], [15, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 5, 6, 10, "role", "", false, false], [12, 12, 6, 10, "named", "", false, false], [15, 16, 0, 5, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["James", "S.", "Albus", "of", "the", "National", "Institute", "of", "Standards", "and", "Technology", "(", "NIST", ")", "developed", "the", "Robocrane", ",", "in", "which", "the", "platform", "hangs", "from", "six", "cables", "instead", "of", "being", "supported", "by", "six", "connectors", "."], "sentence-detokenized": "James S. Albus of the National Institute of Standards and Technology (NIST) developed the Robocrane, in which the platform hangs from six cables instead of being supported by six connectors.", "token2charspan": [[0, 5], [6, 8], [9, 14], [15, 17], [18, 21], [22, 30], [31, 40], [41, 43], [44, 53], [54, 57], [58, 68], [69, 70], [70, 74], [74, 75], [76, 85], [86, 89], [90, 99], [99, 100], [101, 103], [104, 109], [110, 113], [114, 122], [123, 128], [129, 133], [134, 137], [138, 144], [145, 152], [153, 155], [156, 161], [162, 171], [172, 174], [175, 178], [179, 189], [189, 190]]}
{"doc_key": "ai-test-115", "ner": [[3, 5, "algorithm"], [8, 9, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 3, 5, "type-of", "", false, false], [13, 14, 8, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Another", "class", "of", "direct", "search", "algorithms", "are", "various", "evolutionary", "algorithms", ",", "such", "as", "genetic", "algorithms", "."], "sentence-detokenized": "Another class of direct search algorithms are various evolutionary algorithms, such as genetic algorithms.", "token2charspan": [[0, 7], [8, 13], [14, 16], [17, 23], [24, 30], [31, 41], [42, 45], [46, 53], [54, 66], [67, 77], [77, 78], [79, 83], [84, 86], [87, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-test-116", "ner": [[0, 0, "organisation"], [3, 5, "misc"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 0, 0, "named", "", false, false], [6, 7, 0, 0, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["KUKA", "is", "a", "German", "manufacturer", "of", "industrial", "robots", "and", "factory", "automation", "solutions", "."], "sentence-detokenized": "KUKA is a German manufacturer of industrial robots and factory automation solutions.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 16], [17, 29], [30, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 73], [74, 83], [83, 84]]}
{"doc_key": "ai-test-117", "ner": [[3, 4, "misc"], [10, 10, "person"], [13, 19, "misc"], [21, 21, "person"], [24, 24, "misc"], [26, 26, "person"], [29, 30, "misc"], [32, 32, "person"], [35, 37, "misc"], [39, 40, "person"], [43, 46, "misc"], [48, 48, "person"], [51, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[10, 10, 3, 4, "usage", "", false, false], [13, 19, 10, 10, "artifact", "", false, false], [21, 21, 3, 4, "usage", "", false, false], [24, 24, 21, 21, "artifact", "", false, false], [26, 26, 3, 4, "usage", "", false, false], [29, 30, 26, 26, "artifact", "", false, false], [32, 32, 3, 4, "usage", "", false, false], [35, 37, 32, 32, "artifact", "", false, false], [39, 40, 3, 4, "usage", "", false, false], [43, 46, 39, 40, "artifact", "", false, false], [48, 48, 3, 4, "usage", "", false, false], [51, 54, 48, 48, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Other", "films", "shot", "on", "IMAX", "between", "2016", "and", "2020", "include", "Zack", "Snyder", "'s", "Batman", "v", "Superman", ":", "Dawn", "of", "Justice", ",", "Clint", "Eastwood", "'s", "Sully", ",", "Damien", "Chazelle", "'s", "First", "Man", ",", "Patty", "Jenkins", "'", "Wonder", "Woman", "1984", ",", "Cary", "Joji", "Fukunaga", "'s", "No", "Time", "to", "Die", "and", "Joseph", "Kosinski", "'s", "Top", "Gun", ":", "Maverick", "."], "sentence-detokenized": "Other films shot on IMAX between 2016 and 2020 include Zack Snyder's Batman v Superman: Dawn of Justice, Clint Eastwood's Sully, Damien Chazelle's First Man, Patty Jenkins' Wonder Woman 1984, Cary Joji Fukunaga's No Time to Die and Joseph Kosinski's Top Gun: Maverick.", "token2charspan": [[0, 5], [6, 11], [12, 16], [17, 19], [20, 24], [25, 32], [33, 37], [38, 41], [42, 46], [47, 54], [55, 59], [60, 66], [66, 68], [69, 75], [76, 77], [78, 86], [86, 87], [88, 92], [93, 95], [96, 103], [103, 104], [105, 110], [111, 119], [119, 121], [122, 127], [127, 128], [129, 135], [136, 144], [144, 146], [147, 152], [153, 156], [156, 157], [158, 163], [164, 171], [171, 172], [173, 179], [180, 185], [186, 190], [190, 191], [192, 196], [197, 201], [202, 210], [210, 212], [213, 215], [216, 220], [221, 223], [224, 227], [228, 231], [232, 238], [239, 247], [247, 249], [250, 253], [254, 257], [257, 258], [259, 267], [267, 268]]}
{"doc_key": "ai-test-118", "ner": [[0, 2, "misc"], [9, 13, "organisation"], [15, 15, "organisation"], [35, 37, "country"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[9, 13, 0, 2, "usage", "", false, false], [9, 13, 35, 37, "physical", "", false, false], [15, 15, 9, 13, "named", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["The", "MICR", "E13B", "typeface", "was", "presented", "as", "an", "experiment", "to", "the", "American", "Bankers", "Association", "(", "ABA", ")", "in", "July", "1956", ",", "which", "adopted", "it", "in", "1958", "as", "the", "MICR", "standard", "for", "writing", "negotiable", "documents", "in", "the", "United", "States", "."], "sentence-detokenized": "The MICR E13B typeface was presented as an experiment to the American Bankers Association (ABA) in July 1956, which adopted it in 1958 as the MICR standard for writing negotiable documents in the United States.", "token2charspan": [[0, 3], [4, 8], [9, 13], [14, 22], [23, 26], [27, 36], [37, 39], [40, 42], [43, 53], [54, 56], [57, 60], [61, 69], [70, 77], [78, 89], [90, 91], [91, 94], [94, 95], [96, 98], [99, 103], [104, 108], [108, 109], [110, 115], [116, 123], [124, 126], [127, 129], [130, 134], [135, 137], [138, 141], [142, 146], [147, 155], [156, 159], [160, 167], [168, 178], [179, 188], [189, 191], [192, 195], [196, 202], [203, 209], [209, 210]]}
{"doc_key": "ai-test-119", "ner": [[0, 2, "misc"], [18, 19, "field"], [22, 23, "field"], [26, 26, "field"], [28, 29, "field"], [31, 31, "field"], [33, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[18, 19, 0, 2, "usage", "", false, false], [22, 23, 18, 19, "part-of", "", false, false], [26, 26, 0, 2, "usage", "", false, false], [28, 29, 0, 2, "usage", "", false, false], [31, 31, 0, 2, "usage", "", false, false], [33, 33, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Local", "search", "algorithms", "are", "widely", "applied", "to", "a", "wide", "range", "of", "difficult", "computational", "problems", ",", "including", "problems", "in", "computer", "science", "(", "especially", "artificial", "intelligence", ")", ",", "mathematics", ",", "operations", "research", ",", "engineering", "and", "bioinformatics", "."], "sentence-detokenized": "Local search algorithms are widely applied to a wide range of difficult computational problems, including problems in computer science (especially artificial intelligence), mathematics, operations research, engineering and bioinformatics.", "token2charspan": [[0, 5], [6, 12], [13, 23], [24, 27], [28, 34], [35, 42], [43, 45], [46, 47], [48, 52], [53, 58], [59, 61], [62, 71], [72, 85], [86, 94], [94, 95], [96, 105], [106, 114], [115, 117], [118, 126], [127, 134], [135, 136], [136, 146], [147, 157], [158, 170], [170, 171], [171, 172], [173, 184], [184, 185], [186, 196], [197, 205], [205, 206], [207, 218], [219, 222], [223, 237], [237, 238]]}
{"doc_key": "ai-test-120", "ner": [[0, 1, "researcher"], [8, 8, "location"], [10, 10, "country"], [14, 14, "country"], [22, 23, "algorithm"], [20, 25, "algorithm"], [26, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 8, 8, "physical", "", false, false], [0, 1, 14, 14, "general-affiliation", "nationality", false, false], [0, 1, 22, 23, "general-affiliation", "topic_of_study", false, false], [0, 1, 20, 25, "general-affiliation", "topic_of_study", false, false], [8, 8, 10, 10, "physical", "", false, false], [20, 25, 26, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Gerd", "Gigerenzer", "(", "born", "3", "September", "1947", "in", "Wallersdorf", ",", "Germany", ")", "is", "a", "German", "psychologist", "who", "has", "studied", "the", "use", "of", "bounded", "rationality", "and", "heuristics", "in", "decision", "-", "making", "."], "sentence-detokenized": "Gerd Gigerenzer (born 3 September 1947 in Wallersdorf, Germany) is a German psychologist who has studied the use of bounded rationality and heuristics in decision-making.", "token2charspan": [[0, 4], [5, 15], [16, 17], [17, 21], [22, 23], [24, 33], [34, 38], [39, 41], [42, 53], [53, 54], [55, 62], [62, 63], [64, 66], [67, 68], [69, 75], [76, 88], [89, 92], [93, 96], [97, 104], [105, 108], [109, 112], [113, 115], [116, 123], [124, 135], [136, 139], [140, 150], [151, 153], [154, 162], [162, 163], [163, 169], [169, 170]]}
{"doc_key": "ai-test-121", "ner": [[2, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["minimise", "the", "mean", "square", "error", "."], "sentence-detokenized": "minimise the mean square error.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 24], [25, 30], [30, 31]]}
{"doc_key": "ai-test-122", "ner": [[12, 13, "misc"], [16, 17, "organisation"], [29, 35, "field"], [52, 53, "misc"], [63, 65, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 13, 16, 17, "origin", "", false, false], [52, 53, 63, 65, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["But", "even", "a", "formal", "language", "with", "a", "regulating", "academy", ",", "such", "as", "standard", "French", "and", "the", "Acad\u00e9mie", "fran\u00e7aise", ",", "is", "classified", "as", "a", "natural", "language", "(", "for", "example", ",", "in", "the", "field", "of", "natural", "language", "processing", ")", "because", "its", "prescriptive", "passages", "do", "not", "make", "it", "constructed", "enough", "to", "be", "classified", "as", "a", "constructed", "language", ",", "or", "controlled", "enough", "to", "be", "classified", "as", "a", "controlled", "natural", "language", "."], "sentence-detokenized": "But even a formal language with a regulating academy, such as standard French and the Acad\u00e9mie fran\u00e7aise, is classified as a natural language (for example, in the field of natural language processing) because its prescriptive passages do not make it constructed enough to be classified as a constructed language, or controlled enough to be classified as a controlled natural language.", "token2charspan": [[0, 3], [4, 8], [9, 10], [11, 17], [18, 26], [27, 31], [32, 33], [34, 44], [45, 52], [52, 53], [54, 58], [59, 61], [62, 70], [71, 77], [78, 81], [82, 85], [86, 94], [95, 104], [104, 105], [106, 108], [109, 119], [120, 122], [123, 124], [125, 132], [133, 141], [142, 143], [143, 146], [147, 154], [154, 155], [156, 158], [159, 162], [163, 168], [169, 171], [172, 179], [180, 188], [189, 199], [199, 200], [201, 208], [209, 212], [213, 225], [226, 234], [235, 237], [238, 241], [242, 246], [247, 249], [250, 261], [262, 268], [269, 271], [272, 274], [275, 285], [286, 288], [289, 290], [291, 302], [303, 311], [311, 312], [313, 315], [316, 326], [327, 333], [334, 336], [337, 339], [340, 350], [351, 353], [354, 355], [356, 366], [367, 374], [375, 383], [383, 384]]}
{"doc_key": "ai-test-123", "ner": [[11, 11, "metrics"], [13, 14, "metrics"], [16, 16, "metrics"], [36, 37, "metrics"], [39, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 16, 13, 14, "named", "", false, false], [39, 39, 36, 37, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["There", "are", "several", "other", "measures", ",", "the", "simplest", "of", "which", "is", "accuracy", ",", "Fraction", "Correct", "(", "FC", ")", ",", "which", "measures", "the", "proportion", "of", "correctly", "classified", "cases", "out", "of", "all", "cases", ";", "a", "complementary", "measure", "is", "Fraction", "Incorrect", "(", "FiC", ")", "."], "sentence-detokenized": "There are several other measures, the simplest of which is accuracy, Fraction Correct (FC), which measures the proportion of correctly classified cases out of all cases; a complementary measure is Fraction Incorrect (FiC).", "token2charspan": [[0, 5], [6, 9], [10, 17], [18, 23], [24, 32], [32, 33], [34, 37], [38, 46], [47, 49], [50, 55], [56, 58], [59, 67], [67, 68], [69, 77], [78, 85], [86, 87], [87, 89], [89, 90], [90, 91], [92, 97], [98, 106], [107, 110], [111, 121], [122, 124], [125, 134], [135, 145], [146, 151], [152, 155], [156, 158], [159, 162], [163, 168], [168, 169], [170, 171], [172, 185], [186, 193], [194, 196], [197, 205], [206, 215], [216, 217], [217, 220], [220, 221], [221, 222]]}
{"doc_key": "ai-test-124", "ner": [[0, 0, "researcher"], [5, 9, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 9, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cardie", "became", "a", "member", "of", "the", "Association", "for", "Computational", "Linguistics", "in", "2016", "."], "sentence-detokenized": "Cardie became a member of the Association for Computational Linguistics in 2016.", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 22], [23, 25], [26, 29], [30, 41], [42, 45], [46, 59], [60, 71], [72, 74], [75, 79], [79, 80]]}
{"doc_key": "ai-test-125", "ner": [[13, 16, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "learning", "of", "the", "parameters", "math", "\\", "theta", "/", "math", "is", "usually", "done", "by", "maximum", "reliability", "learning", "for", "mathp", "(", "Y", "_", "i", "|", "X", "_", "i", ";\\", "theta", ")", "/", "math", "."], "sentence-detokenized": "The learning of the parameters math\\ theta / math is usually done by maximum reliability learning for mathp (Y _ i | X _ i;\\ theta) / math.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 19], [20, 30], [31, 35], [35, 36], [37, 42], [43, 44], [45, 49], [50, 52], [53, 60], [61, 65], [66, 68], [69, 76], [77, 88], [89, 97], [98, 101], [102, 107], [108, 109], [109, 110], [111, 112], [113, 114], [115, 116], [117, 118], [119, 120], [121, 122], [122, 124], [125, 130], [130, 131], [132, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-test-126", "ner": [[0, 1, "task"], [3, 5, "algorithm"], [7, 8, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 0, 1, "usage", "", true, false], [7, 8, 3, 5, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cluster", "analysis", "and", "non-negative", "matrix", "factorization", "for", "descriptive", "mining", "."], "sentence-detokenized": "Cluster analysis and non-negative matrix factorization for descriptive mining.", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 33], [34, 40], [41, 54], [55, 58], [59, 70], [71, 77], [77, 78]]}
{"doc_key": "ai-test-127", "ner": [[0, 2, "field"], [5, 6, "field"], [25, 27, "field"], [29, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[25, 27, 0, 2, "part-of", "", false, false], [25, 27, 5, 6, "part-of", "", false, false], [29, 30, 0, 2, "part-of", "", false, false], [29, 30, 5, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", "and", "the", "computing", "technologies", "it", "enables", ",", "there", "has", "been", "a", "long", "-", "standing", "challenge", "to", "the", "ability", "of", "computers", "to", "perform", "natural", "language", "processing", "and", "machine", "learning", "."], "sentence-detokenized": "In computer science and the computing technologies it enables, there has been a long-standing challenge to the ability of computers to perform natural language processing and machine learning.", "token2charspan": [[0, 2], [3, 11], [12, 19], [20, 23], [24, 27], [28, 37], [38, 50], [51, 53], [54, 61], [61, 62], [63, 68], [69, 72], [73, 77], [78, 79], [80, 84], [84, 85], [85, 93], [94, 103], [104, 106], [107, 110], [111, 118], [119, 121], [122, 131], [132, 134], [135, 142], [143, 150], [151, 159], [160, 170], [171, 174], [175, 182], [183, 191], [191, 192]]}
{"doc_key": "ai-test-128", "ner": [[2, 5, "algorithm"], [8, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 5, 8, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "Code", "for", "extracting", "Gabor", "features", "from", "images", "in", "MATLAB", "can", "be", "found", "at"], "sentence-detokenized": "(Code for extracting Gabor features from images in MATLAB can be found at", "token2charspan": [[0, 1], [1, 5], [6, 9], [10, 20], [21, 26], [27, 35], [36, 40], [41, 47], [48, 50], [51, 57], [58, 61], [62, 64], [65, 70], [71, 73]]}
{"doc_key": "ai-test-129", "ner": [[0, 0, "misc"], [13, 15, "algorithm"], [19, 19, "task"], [21, 21, "task"], [23, 24, "task"], [26, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 13, 15, "general-affiliation", "", false, false], [0, 0, 19, 19, "related-to", "solves_problem_of_type", false, false], [0, 0, 21, 21, "related-to", "solves_problem_of_type", false, false], [0, 0, 23, 24, "related-to", "solves_problem_of_type", false, false], [0, 0, 26, 27, "related-to", "solves_problem_of_type", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["NeuralExpert", "centres", "the", "design", "specifications", "around", "the", "type", "of", "problem", "the", "user", "wants", "the", "neural", "network", "to", "solve", "(", "classification", ",", "prediction", ",", "function", "approximation", "or", "cluster", "analysis", ")", "."], "sentence-detokenized": "NeuralExpert centres the design specifications around the type of problem the user wants the neural network to solve (classification, prediction, function approximation or cluster analysis).", "token2charspan": [[0, 12], [13, 20], [21, 24], [25, 31], [32, 46], [47, 53], [54, 57], [58, 62], [63, 65], [66, 73], [74, 77], [78, 82], [83, 88], [89, 92], [93, 99], [100, 107], [108, 110], [111, 116], [117, 118], [118, 132], [132, 133], [134, 144], [144, 145], [146, 154], [155, 168], [169, 171], [172, 179], [180, 188], [188, 189], [189, 190]]}
{"doc_key": "ai-test-130", "ner": [[2, 6, "misc"], [31, 33, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "size", "of", "the", "quantization", "step", "(", "\u0394", ")", "is", "small", "relative", "to", "the", "variation", "in", "the", "signal", "to", "be", "quantized", ",", "it", "is", "relatively", "simple", "to", "show", "that", "the", "mean", "squared", "error", "produced", "by", "such", "a", "rounding", "operation", "is", "about", "math", "\\", "Delta", "^", "2", "/", "12", "/", "math.math", "."], "sentence-detokenized": "When the size of the quantization step (\u0394) is small relative to the variation in the signal to be quantized, it is relatively simple to show that the mean squared error produced by such a rounding operation is about math\\ Delta ^ 2 / 12 / math.math.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 20], [21, 33], [34, 38], [39, 40], [40, 41], [41, 42], [43, 45], [46, 51], [52, 60], [61, 63], [64, 67], [68, 77], [78, 80], [81, 84], [85, 91], [92, 94], [95, 97], [98, 107], [107, 108], [109, 111], [112, 114], [115, 125], [126, 132], [133, 135], [136, 140], [141, 145], [146, 149], [150, 154], [155, 162], [163, 168], [169, 177], [178, 180], [181, 185], [186, 187], [188, 196], [197, 206], [207, 209], [210, 215], [216, 220], [220, 221], [222, 227], [228, 229], [230, 231], [232, 233], [234, 236], [237, 238], [239, 248], [248, 249]]}
{"doc_key": "ai-test-131", "ner": [[16, 16, "product"], [24, 27, "researcher"], [29, 30, "researcher"], [32, 34, "researcher"], [36, 37, "researcher"], [39, 41, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Building", "a", "rich", "vocabulary", "and", "a", "suitable", "ontology", "requires", "considerable", "work", ",", "for", "example", ",", "the", "Wordnet", "vocabulary", "required", "several", "man", "-", "years", ".", "G.", "A", ".", "Miller", ",", "R.", "Beckwith", ",", "C.", "D.", "Fellbaum", ",", "D.", "Gross", ",", "K", ".", "Miller", "."], "sentence-detokenized": "Building a rich vocabulary and a suitable ontology requires considerable work, for example, the Wordnet vocabulary required several man-years. G. A. Miller, R. Beckwith, C. D. Fellbaum, D. Gross, K. Miller.", "token2charspan": [[0, 8], [9, 10], [11, 15], [16, 26], [27, 30], [31, 32], [33, 41], [42, 50], [51, 59], [60, 72], [73, 77], [77, 78], [79, 82], [83, 90], [90, 91], [92, 95], [96, 103], [104, 114], [115, 123], [124, 131], [132, 135], [135, 136], [136, 141], [141, 142], [143, 145], [146, 147], [147, 148], [149, 155], [155, 156], [157, 159], [160, 168], [168, 169], [170, 172], [173, 175], [176, 184], [184, 185], [186, 188], [189, 194], [194, 195], [196, 197], [197, 198], [199, 205], [205, 206]]}
{"doc_key": "ai-test-132", "ner": [[0, 1, "organisation"], [18, 19, "location"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Kawasaki", "'s", "range", "also", "includes", "retractable", "roofs", ",", "floors", "and", "other", "giant", "structures", ",", "one", "example", "being", "the", "Sapporo", "Dome", "'", "retractable", "surface", "'", "."], "sentence-detokenized": "Kawasaki's range also includes retractable roofs, floors and other giant structures, one example being the Sapporo Dome 'retractable surface'.", "token2charspan": [[0, 8], [8, 10], [11, 16], [17, 21], [22, 30], [31, 42], [43, 48], [48, 49], [50, 56], [57, 60], [61, 66], [67, 72], [73, 83], [83, 84], [85, 88], [89, 96], [97, 102], [103, 106], [107, 114], [115, 119], [120, 121], [121, 132], [133, 140], [140, 141], [141, 142]]}
{"doc_key": "ai-test-133", "ner": [[0, 1, "metrics"], [5, 7, "metrics"], [9, 11, "metrics"], [17, 18, "metrics"], [40, 41, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 17, 18, "related-to", "", false, false], [0, 1, 40, 41, "opposite", "alternative_to", false, false], [5, 7, 0, 1, "type-of", "", false, false], [9, 11, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Kappa", "statistics", ",", "such", "as", "Fleiss", "'", "kappa", "and", "Cohen", "'s", "kappa", ",", "are", "methods", "for", "calculating", "inter-rater", "reliability", "based", "on", "different", "assumptions", "about", "marginal", "distributions", "or", "prior", "distributions", ",", "and", "are", "increasingly", "used", "as", "chance", "-", "corrected", "alternatives", "to", "precision", "in", "other", "contexts", "."], "sentence-detokenized": "Kappa statistics, such as Fleiss' kappa and Cohen's kappa, are methods for calculating inter-rater reliability based on different assumptions about marginal distributions or prior distributions, and are increasingly used as chance-corrected alternatives to precision in other contexts.", "token2charspan": [[0, 5], [6, 16], [16, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 39], [40, 43], [44, 49], [49, 51], [52, 57], [57, 58], [59, 62], [63, 70], [71, 74], [75, 86], [87, 98], [99, 110], [111, 116], [117, 119], [120, 129], [130, 141], [142, 147], [148, 156], [157, 170], [171, 173], [174, 179], [180, 193], [193, 194], [195, 198], [199, 202], [203, 215], [216, 220], [221, 223], [224, 230], [230, 231], [231, 240], [241, 253], [254, 256], [257, 266], [267, 269], [270, 275], [276, 284], [284, 285]]}
{"doc_key": "ai-test-134", "ner": [[3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [12, 13, "researcher"], [17, 17, "researcher"], [23, 26, "algorithm"], [28, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 7], "relations": [[3, 4, 17, 17, "role", "student_of", false, false], [6, 7, 17, 17, "role", "student_of", false, false], [9, 10, 17, 17, "role", "student_of", false, false], [12, 13, 17, 17, "role", "student_of", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["With", "his", "students", "Sepp", "Hochreiter", ",", "Felix", "Gers", ",", "Fred", "Cummins", ",", "Alex", "Graves", "and", "others", ",", "Schmidhuber", "published", "increasingly", "sophisticated", "versions", "of", "a", "recursive", "neural", "network", "called", "long", "short", "-", "term", "memory", "(", "LSTM", ")", "."], "sentence-detokenized": "With his students Sepp Hochreiter, Felix Gers, Fred Cummins, Alex Graves and others, Schmidhuber published increasingly sophisticated versions of a recursive neural network called long short-term memory (LSTM).", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 22], [23, 33], [33, 34], [35, 40], [41, 45], [45, 46], [47, 51], [52, 59], [59, 60], [61, 65], [66, 72], [73, 76], [77, 83], [83, 84], [85, 96], [97, 106], [107, 119], [120, 133], [134, 142], [143, 145], [146, 147], [148, 157], [158, 164], [165, 172], [173, 179], [180, 184], [185, 190], [190, 191], [191, 195], [196, 202], [203, 204], [204, 208], [208, 209], [209, 210]]}
{"doc_key": "ai-test-135", "ner": [[4, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2004", "-", "The", "first", "Cobot", "KUKA", "LBR", "3", "is", "launched", "."], "sentence-detokenized": "2004 - The first Cobot KUKA LBR 3 is launched.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 16], [17, 22], [23, 27], [28, 31], [32, 33], [34, 36], [37, 45], [45, 46]]}
{"doc_key": "ai-test-136", "ner": [[12, 14, "algorithm"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "two", "superficial", "approaches", "used", "for", "training", "and", "subsequent", "separation", "are", "the", "Naive", "Bayes", "classifier", "and", "decision", "trees", "."], "sentence-detokenized": "The two superficial approaches used for training and subsequent separation are the Naive Bayes classifier and decision trees.", "token2charspan": [[0, 3], [4, 7], [8, 19], [20, 30], [31, 35], [36, 39], [40, 48], [49, 52], [53, 63], [64, 74], [75, 78], [79, 82], [83, 88], [89, 94], [95, 105], [106, 109], [110, 118], [119, 124], [124, 125]]}
{"doc_key": "ai-test-137", "ner": [[16, 16, "misc"], [4, 5, "person"], [7, 9, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 16, 4, 5, "origin", "", false, false], [16, 16, 7, 9, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "January", "1839", ",", "Louis", "Daguerre", "and", "Henry", "Fox", "Talbot", "introduced", "the", "first", "practical", "forms", "of", "photography", "."], "sentence-detokenized": "In January 1839, Louis Daguerre and Henry Fox Talbot introduced the first practical forms of photography.", "token2charspan": [[0, 2], [3, 10], [11, 15], [15, 16], [17, 22], [23, 31], [32, 35], [36, 41], [42, 45], [46, 52], [53, 63], [64, 67], [68, 73], [74, 83], [84, 89], [90, 92], [93, 104], [104, 105]]}
{"doc_key": "ai-test-138", "ner": [[3, 4, "task"], [7, 8, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "speech", "synthesis", "combined", "with", "speech", "recognition", "enables", "interaction", "with", "mobile", "devices", "through", "language", "processing", "interfaces", "."], "sentence-detokenized": "For example, speech synthesis combined with speech recognition enables interaction with mobile devices through language processing interfaces.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 19], [20, 29], [30, 38], [39, 43], [44, 50], [51, 62], [63, 70], [71, 82], [83, 87], [88, 94], [95, 102], [103, 110], [111, 119], [120, 130], [131, 141], [141, 142]]}
{"doc_key": "ai-test-139", "ner": [[0, 0, "product"], [12, 14, "programlang"], [15, 17, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 12, 14, "general-affiliation", "", false, false], [0, 0, 15, 17, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Phidgets", "can", "be", "programmed", "with", "a", "variety", "of", "software", "and", "programming", "languages", ",", "from", "Java", "to", "Microsoft", "Excel", "."], "sentence-detokenized": "Phidgets can be programmed with a variety of software and programming languages, from Java to Microsoft Excel.", "token2charspan": [[0, 8], [9, 12], [13, 15], [16, 26], [27, 31], [32, 33], [34, 41], [42, 44], [45, 53], [54, 57], [58, 69], [70, 79], [79, 80], [81, 85], [86, 90], [91, 93], [94, 103], [104, 109], [109, 110]]}
{"doc_key": "ai-test-140", "ner": [[2, 3, "field"], [9, 10, "researcher"], [12, 15, "misc"], [19, 20, "field"], [22, 23, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 10, "origin", "", false, false], [9, 10, 19, 20, "general-affiliation", "topic_of_study", false, false], [9, 10, 22, 23, "general-affiliation", "topic_of_study", false, false], [12, 15, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "term", "machine", "learning", "was", "coined", "in", "1959", "by", "Arthur", "Samuel", ",", "an", "American", "IBM", "employee", "and", "pioneer", "of", "computer", "games", "and", "artificial", "intelligence", "."], "sentence-detokenized": "The term machine learning was coined in 1959 by Arthur Samuel, an American IBM employee and pioneer of computer games and artificial intelligence.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 25], [26, 29], [30, 36], [37, 39], [40, 44], [45, 47], [48, 54], [55, 61], [61, 62], [63, 65], [66, 74], [75, 78], [79, 87], [88, 91], [92, 99], [100, 102], [103, 111], [112, 117], [118, 121], [122, 132], [133, 145], [145, 146]]}
{"doc_key": "ai-test-141", "ner": [[10, 11, "misc"], [12, 13, "person"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 10, 11, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Fascinated", "by", "future", "technology", "and", "its", "relationship", "with", "art", ",", "Israeli", "poet", "David", "Avidan", "wanted", "to", "explore", "the", "use", "of", "computers", "in", "literary", "writing", "."], "sentence-detokenized": "Fascinated by future technology and its relationship with art, Israeli poet David Avidan wanted to explore the use of computers in literary writing.", "token2charspan": [[0, 10], [11, 13], [14, 20], [21, 31], [32, 35], [36, 39], [40, 52], [53, 57], [58, 61], [61, 62], [63, 70], [71, 75], [76, 81], [82, 88], [89, 95], [96, 98], [99, 106], [107, 110], [111, 114], [115, 117], [118, 127], [128, 130], [131, 139], [140, 147], [147, 148]]}
{"doc_key": "ai-test-142", "ner": [[4, 5, "misc"], [9, 9, "organisation"], [16, 16, "location"], [27, 28, "location"], [29, 32, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 9, 4, 5, "part-of", "", false, false], [29, 32, 27, 28, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "part", "of", "the", "GATEway", "project", "in", "2017", ",", "Oxbotica", "trialled", "seven", "autonomous", "shuttle", "buses", "in", "Greenwich", ",", "running", "on", "a", "two", "-", "mile", "coastal", "path", "near", "London", "'s", "O2", "Arena", "on", "a", "route", "that", "is", "also", "used", "by", "pedestrians", "and", "cyclists", "."], "sentence-detokenized": "As part of the GATEway project in 2017, Oxbotica trialled seven autonomous shuttle buses in Greenwich, running on a two-mile coastal path near London's O2 Arena on a route that is also used by pedestrians and cyclists.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 22], [23, 30], [31, 33], [34, 38], [38, 39], [40, 48], [49, 57], [58, 63], [64, 74], [75, 82], [83, 88], [89, 91], [92, 101], [101, 102], [103, 110], [111, 113], [114, 115], [116, 119], [119, 120], [120, 124], [125, 132], [133, 137], [138, 142], [143, 149], [149, 151], [152, 154], [155, 160], [161, 163], [164, 165], [166, 171], [172, 176], [177, 179], [180, 184], [185, 189], [190, 192], [193, 204], [205, 208], [209, 217], [217, 218]]}
{"doc_key": "ai-test-143", "ner": [[4, 5, "task"], [15, 21, "metrics"], [26, 29, "misc"], [32, 33, "metrics"], [36, 36, "metrics"], [38, 38, "metrics"], [40, 42, "metrics"], [45, 45, "metrics"], [47, 47, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9], "relations": [[15, 21, 26, 29, "related-to", "is_a", false, false], [15, 21, 32, 33, "usage", "", false, false], [32, 33, 47, 47, "named", "same", false, false], [36, 36, 45, 45, "opposite", "", false, false], [36, 36, 47, 47, "opposite", "", false, false], [38, 38, 36, 36, "named", "", false, false], [40, 42, 36, 36, "named", "", false, false]], "relations_mapping_to_source": [0, 2, 4, 5, 6, 7, 8], "sentence": ["A", "combination", "of", "basic", "data", "retrieval", "statistics", ",", "unrelated", "but", "commonly", "used", ",", "is", "the", "F", "-", "score", ",", "which", "is", "the", "(", "possibly", "weighted", ")", "harmonic", "mean", "of", "the", "recall", "and", "precision", "values", ",", "where", "recall", "=", "sensitivity", "=", "TRULY", "positive", "proportion", ",", "but", "specificity", "and", "precision", "are", "completely", "different", "measures", "."], "sentence-detokenized": "A combination of basic data retrieval statistics, unrelated but commonly used, is the F-score, which is the (possibly weighted) harmonic mean of the recall and precision values, where recall = sensitivity = TRULY positive proportion, but specificity and precision are completely different measures.", "token2charspan": [[0, 1], [2, 13], [14, 16], [17, 22], [23, 27], [28, 37], [38, 48], [48, 49], [50, 59], [60, 63], [64, 72], [73, 77], [77, 78], [79, 81], [82, 85], [86, 87], [87, 88], [88, 93], [93, 94], [95, 100], [101, 103], [104, 107], [108, 109], [109, 117], [118, 126], [126, 127], [128, 136], [137, 141], [142, 144], [145, 148], [149, 155], [156, 159], [160, 169], [170, 176], [176, 177], [178, 183], [184, 190], [191, 192], [193, 204], [205, 206], [207, 212], [213, 221], [222, 232], [232, 233], [234, 237], [238, 249], [250, 253], [254, 263], [264, 267], [268, 278], [279, 288], [289, 297], [297, 298]]}
{"doc_key": "ai-test-144", "ner": [[0, 1, "field"], [8, 8, "field"], [10, 10, "field"], [12, 12, "field"], [14, 15, "field"], [7, 17, "field"], [26, 27, "product"], [29, 32, "product"], [34, 35, "product"], [37, 38, "product"], [50, 53, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 8, 8, "origin", "takes_inspiration_from", false, false], [0, 1, 10, 10, "origin", "takes_inspiration_from", false, false], [0, 1, 12, 12, "origin", "takes_inspiration_from", false, false], [0, 1, 14, 15, "origin", "takes_inspiration_from", false, false], [0, 1, 7, 17, "origin", "takes_inspiration_from", false, false], [26, 27, 0, 1, "origin", "", false, false], [29, 32, 0, 1, "origin", "", false, false], [34, 35, 0, 1, "origin", "", false, false], [37, 38, 0, 1, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Neuromorphic", "engineering", "is", "an", "interdisciplinary", "subject", "that", "uses", "biology", ",", "physics", ",", "mathematics", ",", "computer", "science", "and", "electronics", "to", "design", "artificial", "neural", "systems", ",", "such", "as", "vision", "systems", ",", "head", "-", "eye", "systems", ",", "auditory", "processors", "and", "autonomous", "robots", ",", "whose", "physical", "architecture", "and", "design", "principles", "are", "based", "on", "those", "of", "biological", "neural", "systems", "."], "sentence-detokenized": "Neuromorphic engineering is an interdisciplinary subject that uses biology, physics, mathematics, computer science and electronics to design artificial neural systems, such as vision systems, head-eye systems, auditory processors and autonomous robots, whose physical architecture and design principles are based on those of biological neural systems.", "token2charspan": [[0, 12], [13, 24], [25, 27], [28, 30], [31, 48], [49, 56], [57, 61], [62, 66], [67, 74], [74, 75], [76, 83], [83, 84], [85, 96], [96, 97], [98, 106], [107, 114], [115, 118], [119, 130], [131, 133], [134, 140], [141, 151], [152, 158], [159, 166], [166, 167], [168, 172], [173, 175], [176, 182], [183, 190], [190, 191], [192, 196], [196, 197], [197, 200], [201, 208], [208, 209], [210, 218], [219, 229], [230, 233], [234, 244], [245, 251], [251, 252], [253, 258], [259, 267], [268, 280], [281, 284], [285, 291], [292, 302], [303, 306], [307, 312], [313, 315], [316, 321], [322, 324], [325, 335], [336, 342], [343, 350], [350, 351]]}
{"doc_key": "ai-test-145", "ner": [[3, 6, "metrics"], [10, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 3, 6, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["More", "specifically", ",", "the", "BIBO", "stability", "criterion", "requires", "that", "the", "ROC", "of", "the", "system", "contains", "a", "unit", "circle", "."], "sentence-detokenized": "More specifically, the BIBO stability criterion requires that the ROC of the system contains a unit circle.", "token2charspan": [[0, 4], [5, 17], [17, 18], [19, 22], [23, 27], [28, 37], [38, 47], [48, 56], [57, 61], [62, 65], [66, 69], [70, 72], [73, 76], [77, 83], [84, 92], [93, 94], [95, 99], [100, 106], [106, 107]]}
{"doc_key": "ai-test-146", "ner": [[5, 6, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["2", "The", "programme", "was", "rewritten", "in", "Java", "from", "1998", "onwards", "."], "sentence-detokenized": "2 The programme was rewritten in Java from 1998 onwards.", "token2charspan": [[0, 1], [2, 5], [6, 15], [16, 19], [20, 29], [30, 32], [33, 37], [38, 42], [43, 47], [48, 55], [55, 56]]}
{"doc_key": "ai-test-147", "ner": [[0, 0, "metrics"], [5, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 8, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MCC", "can", "be", "calculated", "directly", "from", "the", "mixing", "matrix", "using", "the", "formula", ":"], "sentence-detokenized": "MCC can be calculated directly from the mixing matrix using the formula:", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 21], [22, 30], [31, 35], [36, 39], [40, 46], [47, 53], [54, 59], [60, 63], [64, 71], [71, 72]]}
{"doc_key": "ai-test-148", "ner": [[5, 10, "organisation"], [17, 23, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 10, 17, 23, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "developed", "by", "the", "MIT", "-", "IBM", "Watson", "AI", "Lab", "team", "and", "was", "first", "presented", "at", "the", "2018", "International", "Conference", "on", "Learning", "Representations", "."], "sentence-detokenized": "It was developed by the MIT-IBM Watson AI Lab team and was first presented at the 2018 International Conference on Learning Representations.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 23], [24, 27], [27, 28], [28, 31], [32, 38], [39, 41], [42, 45], [46, 50], [51, 54], [55, 58], [59, 64], [65, 74], [75, 77], [78, 81], [82, 86], [87, 100], [101, 111], [112, 114], [115, 123], [124, 139], [139, 140]]}
{"doc_key": "ai-test-149", "ner": [[2, 5, "metrics"], [16, 18, "metrics"], [20, 21, "metrics"], [47, 47, "metrics"], [54, 56, "metrics"], [59, 59, "metrics"], [61, 61, "metrics"], [63, 65, "metrics"], [70, 70, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6, 7, 8, 9], "relations": [[16, 18, 47, 47, "type-of", "", false, false], [16, 18, 54, 56, "related-to", "collapses_to_identity", false, false], [20, 21, 54, 56, "related-to", "collapses_to_identity", false, false], [20, 21, 63, 65, "named", "same", false, false], [59, 59, 70, 70, "related-to", "collapses_to_identity", false, false], [61, 61, 70, 70, "related-to", "collapses_to_identity", false, false], [63, 65, 70, 70, "related-to", "collapses_to_identity", false, false]], "relations_mapping_to_source": [0, 1, 3, 4, 5, 6, 7], "sentence": ["When", "the", "REAL", "occurrences", "of", "the", "two", "positive", "variables", "are", "the", "same", ",", "as", "assumed", "by", "Fleiss", "'", "kappa", "and", "F-", "scores", ",", "i.e.", "the", "number", "of", "positive", "predictions", "equals", "the", "number", "of", "positive", "classes", "in", "the", "dichotomous", "(", "two", "-", "class", ")", "case", ",", "the", "different", "kappa", "and", "correlation", "measures", "become", "identical", "to", "Youden", "'s", "J", ",", "and", "recall", ",", "precision", "and", "F", "-", "score", "are", "respectively", "identical", "to", "accuracy", "."], "sentence-detokenized": "When the REAL occurrences of the two positive variables are the same, as assumed by Fleiss' kappa and F-scores, i.e. the number of positive predictions equals the number of positive classes in the dichotomous (two-class) case, the different kappa and correlation measures become identical to Youden's J, and recall, precision and F-score are respectively identical to accuracy.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 25], [26, 28], [29, 32], [33, 36], [37, 45], [46, 55], [56, 59], [60, 63], [64, 68], [68, 69], [70, 72], [73, 80], [81, 83], [84, 90], [90, 91], [92, 97], [98, 101], [102, 104], [104, 110], [110, 111], [112, 116], [117, 120], [121, 127], [128, 130], [131, 139], [140, 151], [152, 158], [159, 162], [163, 169], [170, 172], [173, 181], [182, 189], [190, 192], [193, 196], [197, 208], [209, 210], [210, 213], [213, 214], [214, 219], [219, 220], [221, 225], [225, 226], [227, 230], [231, 240], [241, 246], [247, 250], [251, 262], [263, 271], [272, 278], [279, 288], [289, 291], [292, 298], [298, 300], [301, 302], [302, 303], [304, 307], [308, 314], [314, 315], [316, 325], [326, 329], [330, 331], [331, 332], [332, 337], [338, 341], [342, 354], [355, 364], [365, 367], [368, 376], [376, 377]]}
{"doc_key": "ai-test-150", "ner": [[7, 8, "misc"], [0, 5, "misc"], [9, 9, "conference"], [14, 17, "task"], [18, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 9, 9, "part-of", "", false, false], [7, 8, 9, 9, "physical", "", false, false], [7, 8, 9, 9, "temporal", "", false, false], [0, 5, 7, 8, "named", "", false, false], [14, 17, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Building", "Educational", "Applications", "(", "BEA", ")", "workshop", "at", "NAACL", "2013", "hosted", "the", "first", "joint", "NLI", "mission", ".", "Tetreault", "et", "al", ",", "2013", "29", "teams", "from", "around", "the", "world", "participated", "in", "the", "competition", ",", "24", "of", "which", "also", "published", "a", "paper", "describing", "their", "systems", "and", "approaches", "."], "sentence-detokenized": "The Building Educational Applications (BEA) workshop at NAACL 2013 hosted the first joint NLI mission. Tetreault et al, 2013 29 teams from around the world participated in the competition, 24 of which also published a paper describing their systems and approaches.", "token2charspan": [[0, 3], [4, 12], [13, 24], [25, 37], [38, 39], [39, 42], [42, 43], [44, 52], [53, 55], [56, 61], [62, 66], [67, 73], [74, 77], [78, 83], [84, 89], [90, 93], [94, 101], [101, 102], [103, 112], [113, 115], [116, 118], [118, 119], [120, 124], [125, 127], [128, 133], [134, 138], [139, 145], [146, 149], [150, 155], [156, 168], [169, 171], [172, 175], [176, 187], [187, 188], [189, 191], [192, 194], [195, 200], [201, 205], [206, 215], [216, 217], [218, 223], [224, 234], [235, 240], [241, 248], [249, 252], [253, 263], [263, 264]]}
{"doc_key": "ai-test-151", "ner": [[0, 2, "algorithm"], [5, 7, "algorithm"], [15, 16, "misc"], [19, 21, "misc"], [36, 36, "misc"], [41, 41, "algorithm"], [32, 44, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 5, 7, "type-of", "", false, false], [0, 2, 15, 16, "related-to", "finds", false, false], [19, 21, 15, 16, "type-of", "", false, false], [32, 44, 41, 41, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Viterbi", "algorithm", "is", "a", "dynamic", "programming", "algorithm", "for", "finding", "the", "most", "probable", "sequence", "of", "hidden", "states", ",", "called", "the", "Viterbi", "path", ",", "leading", "to", "a", "sequence", "of", "observed", "events", ",", "especially", "in", "the", "context", "of", "Markov", "data", "sources", "and", "hidden", "Markov", "models", "(", "HMMs", ")", "."], "sentence-detokenized": "The Viterbi algorithm is a dynamic programming algorithm for finding the most probable sequence of hidden states, called the Viterbi path, leading to a sequence of observed events, especially in the context of Markov data sources and hidden Markov models (HMMs).", "token2charspan": [[0, 3], [4, 11], [12, 21], [22, 24], [25, 26], [27, 34], [35, 46], [47, 56], [57, 60], [61, 68], [69, 72], [73, 77], [78, 86], [87, 95], [96, 98], [99, 105], [106, 112], [112, 113], [114, 120], [121, 124], [125, 132], [133, 137], [137, 138], [139, 146], [147, 149], [150, 151], [152, 160], [161, 163], [164, 172], [173, 179], [179, 180], [181, 191], [192, 194], [195, 198], [199, 206], [207, 209], [210, 216], [217, 221], [222, 229], [230, 233], [234, 240], [241, 247], [248, 254], [255, 256], [256, 260], [260, 261], [261, 262]]}
{"doc_key": "ai-test-152", "ner": [[0, 1, "field"], [3, 5, "algorithm"], [8, 10, "misc"], [12, 13, "algorithm"], [14, 18, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 5, 0, 1, "part-of", "", false, false], [3, 5, 8, 10, "general-affiliation", "", false, false], [3, 5, 12, 13, "related-to", "generalizes_from", false, false], [3, 5, 14, 18, "related-to", "generalizes_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "statistics", ",", "multinomial", "logistic", "regression", "is", "a", "classification", "method", "that", "generalises", "logistic", "regression", "to", "multicategorical", "classification", ",", "i.e.", "when", "there", "are", "more", "than", "two", "possible", "distinct", "outcomes", "."], "sentence-detokenized": "In statistics, multinomial logistic regression is a classification method that generalises logistic regression to multicategorical classification, i.e. when there are more than two possible distinct outcomes.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 26], [27, 35], [36, 46], [47, 49], [50, 51], [52, 66], [67, 73], [74, 78], [79, 90], [91, 99], [100, 110], [111, 113], [114, 130], [131, 145], [145, 146], [147, 151], [152, 156], [157, 162], [163, 166], [167, 171], [172, 176], [177, 180], [181, 189], [190, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-test-153", "ner": [[0, 2, "algorithm"], [8, 10, "field"], [12, 14, "field"], [18, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 8, 10, "part-of", "", false, false], [0, 2, 12, 14, "part-of", "", false, false], [18, 18, 0, 2, "usage", "", true, false], [20, 21, 0, 2, "usage", "", true, false], [23, 24, 0, 2, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hidden", "Markov", "models", "are", "known", "for", "their", "applications", "in", "reinforcement", "learning", "and", "temporal", "pattern", "recognition", ",", "such", "as", "speech", ",", "handwriting", "recognition", ",", "gesture", "recognition", ",", "Thad", "Starner", ",", "Alex", "Pentland", "."], "sentence-detokenized": "Hidden Markov models are known for their applications in reinforcement learning and temporal pattern recognition, such as speech, handwriting recognition, gesture recognition, Thad Starner, Alex Pentland.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 30], [31, 34], [35, 40], [41, 53], [54, 56], [57, 70], [71, 79], [80, 83], [84, 92], [93, 100], [101, 112], [112, 113], [114, 118], [119, 121], [122, 128], [128, 129], [130, 141], [142, 153], [153, 154], [155, 162], [163, 174], [174, 175], [176, 180], [181, 188], [188, 189], [190, 194], [195, 203], [203, 204]]}
{"doc_key": "ai-test-154", "ner": [[6, 7, "misc"], [32, 36, "metrics"], [39, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 39, 40, "named", "", false, false], [32, 36, 39, 40, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "essentially", "means", "that", "if", "an", "n-", "gram", "is", "seen", "more", "than", "k", "times", "in", "a", "training", "session", ",", "the", "conditional", "probability", "of", "a", "word", "based", "on", "its", "history", "is", "proportional", "to", "the", "maximum", "likelihood", "estimate", "of", "that", "particular", "n-", "gram", "."], "sentence-detokenized": "This essentially means that if an n-gram is seen more than k times in a training session, the conditional probability of a word based on its history is proportional to the maximum likelihood estimate of that particular n-gram.", "token2charspan": [[0, 4], [5, 16], [17, 22], [23, 27], [28, 30], [31, 33], [34, 36], [36, 40], [41, 43], [44, 48], [49, 53], [54, 58], [59, 60], [61, 66], [67, 69], [70, 71], [72, 80], [81, 88], [88, 89], [90, 93], [94, 105], [106, 117], [118, 120], [121, 122], [123, 127], [128, 133], [134, 136], [137, 140], [141, 148], [149, 151], [152, 164], [165, 167], [168, 171], [172, 179], [180, 190], [191, 199], [200, 202], [203, 207], [208, 218], [219, 221], [221, 225], [225, 226]]}
{"doc_key": "ai-test-155", "ner": [[4, 5, "task"], [7, 9, "task"], [11, 13, "task"], [17, 19, "task"], [25, 27, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[25, 27, 17, 19, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "interested", "in", "knowledge", "representation", ",", "common", "sense", "reasoning", "and", "natural", "language", "understanding", "and", "believes", "that", "deep", "language", "understanding", "can", "currently", "only", "be", "achieved", "by", "manually", "developing", "semantically", "rich", "formalisms", "combined", "with", "statistical", "preferences", "."], "sentence-detokenized": "He is interested in knowledge representation, common sense reasoning and natural language understanding and believes that deep language understanding can currently only be achieved by manually developing semantically rich formalisms combined with statistical preferences.", "token2charspan": [[0, 2], [3, 5], [6, 16], [17, 19], [20, 29], [30, 44], [44, 45], [46, 52], [53, 58], [59, 68], [69, 72], [73, 80], [81, 89], [90, 103], [104, 107], [108, 116], [117, 121], [122, 126], [127, 135], [136, 149], [150, 153], [154, 163], [164, 168], [169, 171], [172, 180], [181, 183], [184, 192], [193, 203], [204, 216], [217, 221], [222, 232], [233, 241], [242, 246], [247, 258], [259, 270], [270, 271]]}
{"doc_key": "ai-test-156", "ner": [[0, 1, "programlang"], [3, 3, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["in", "JavaScript", ",", "Python", "or"], "sentence-detokenized": "in JavaScript, Python or", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 21], [22, 24]]}
{"doc_key": "ai-test-157", "ner": [[0, 2, "misc"], [6, 7, "misc"], [11, 11, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 7, "part-of", "", false, false], [6, 7, 11, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Newcomb", "Awards", "are", "announced", "in", "AI", "Magazine", ",", "published", "by", "AAAI", "."], "sentence-detokenized": "The Newcomb Awards are announced in AI Magazine, published by AAAI.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 22], [23, 32], [33, 35], [36, 38], [39, 47], [47, 48], [49, 58], [59, 61], [62, 66], [66, 67]]}
{"doc_key": "ai-test-158", "ner": [[0, 4, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "mean", "squared", "error", "of", "the", "100", "sample", "test", "set", "is", "0.084", ",", "which", "is", "smaller", "than", "the", "unnormalised", "error", "."], "sentence-detokenized": "The mean squared error of the 100 sample test set is 0.084, which is smaller than the unnormalised error.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 22], [23, 25], [26, 29], [30, 33], [34, 40], [41, 45], [46, 49], [50, 52], [53, 58], [58, 59], [60, 65], [66, 68], [69, 76], [77, 81], [82, 85], [86, 98], [99, 104], [104, 105]]}
{"doc_key": "ai-test-159", "ner": [[0, 3, "metrics"], [9, 12, "field"], [22, 22, "task"], [21, 25, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 12, 0, 3, "usage", "", false, false], [22, 22, 9, 12, "part-of", "task_part_of_field", false, false], [21, 25, 22, 22, "named", "", false, false], [28, 29, 9, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "F", "-", "score", "has", "been", "widely", "used", "in", "the", "natural", "language", "processing", "literature", ",", "such", "as", "in", "the", "evaluation", "of", "named", "entity", "recognition", "(", "NER", ")", "and", "word", "segmentation", "."], "sentence-detokenized": "The F-score has been widely used in the natural language processing literature, such as in the evaluation of named entity recognition (NER) and word segmentation.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 15], [16, 20], [21, 27], [28, 32], [33, 35], [36, 39], [40, 47], [48, 56], [57, 67], [68, 78], [78, 79], [80, 84], [85, 87], [88, 90], [91, 94], [95, 105], [106, 108], [109, 114], [115, 121], [122, 133], [134, 135], [135, 138], [138, 139], [140, 143], [144, 148], [149, 161], [161, 162]]}
{"doc_key": "ai-test-160", "ner": [[0, 0, "product"], [4, 7, "product"], [16, 17, "misc"], [19, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 16, 17, "related-to", "performs_task", false, false], [0, 0, 19, 20, "related-to", "performs_task", false, false], [4, 7, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Chatbots", "are", "typically", "used", "in", "conversational", "systems", "for", "various", "purposes", ",", "such", "as", "customer", "service", ",", "request", "routing", "or", "data", "collection", "."], "sentence-detokenized": "Chatbots are typically used in conversational systems for various purposes, such as customer service, request routing or data collection.", "token2charspan": [[0, 8], [9, 12], [13, 22], [23, 27], [28, 30], [31, 45], [46, 53], [54, 57], [58, 65], [66, 74], [74, 75], [76, 80], [81, 83], [84, 92], [93, 100], [100, 101], [102, 109], [110, 117], [118, 120], [121, 125], [126, 136], [136, 137]]}
{"doc_key": "ai-test-161", "ner": [[3, 9, "conference"], [13, 21, "conference"], [27, 37, "conference"], [48, 51, "conference"], [53, 54, "conference"]], "ner_mapping_to_source": [0, 1, 2, 4, 5], "relations": [[13, 21, 3, 9, "named", "", false, false], [27, 37, 3, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Important", "journals", "include", "IEEE", "Transactions", "on", "Speech", "and", "Audio", "Processing", "(", "later", "renamed", "IEEE", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "and", "since", "September", "2014", "renamed", "IEEE", "/", "ACM", "Transactions", "on", "Audio", ",", "Speech", "and", "Language", "Processing", "-", "following", "its", "merger", "with", "the", "ACM", "journal", ")", ",", "Computer", "Speech", "and", "Language", "and", "Speech", "Communication", "."], "sentence-detokenized": "Important journals include IEEE Transactions on Speech and Audio Processing (later renamed IEEE Transactions on Audio, Speech and Language Processing and since September 2014 renamed IEEE/ACM Transactions on Audio, Speech and Language Processing - following its merger with the ACM journal), Computer Speech and Language and Speech Communication.", "token2charspan": [[0, 9], [10, 18], [19, 26], [27, 31], [32, 44], [45, 47], [48, 54], [55, 58], [59, 64], [65, 75], [76, 77], [77, 82], [83, 90], [91, 95], [96, 108], [109, 111], [112, 117], [117, 118], [119, 125], [126, 129], [130, 138], [139, 149], [150, 153], [154, 159], [160, 169], [170, 174], [175, 182], [183, 187], [187, 188], [188, 191], [192, 204], [205, 207], [208, 213], [213, 214], [215, 221], [222, 225], [226, 234], [235, 245], [246, 247], [248, 257], [258, 261], [262, 268], [269, 273], [274, 277], [278, 281], [282, 289], [289, 290], [290, 291], [292, 300], [301, 307], [308, 311], [312, 320], [321, 324], [325, 331], [332, 345], [345, 346]]}
{"doc_key": "ai-test-162", "ner": [[0, 2, "algorithm"], [6, 8, "task"], [9, 11, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 8, 0, 2, "usage", "", false, false], [6, 8, 9, 11, "part-of", "task_part_of_field", false, false], [6, 8, 13, 14, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "EM", "method", "is", "often", "used", "for", "data", "clustering", "in", "machine", "learning", "and", "computer", "vision", "."], "sentence-detokenized": "The EM method is often used for data clustering in machine learning and computer vision.", "token2charspan": [[0, 3], [4, 6], [7, 13], [14, 16], [17, 22], [23, 27], [28, 31], [32, 36], [37, 47], [48, 50], [51, 58], [59, 67], [68, 71], [72, 80], [81, 87], [87, 88]]}
{"doc_key": "ai-test-163", "ner": [[8, 11, "metrics"], [25, 27, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 11, 25, 27, "related-to", "described_by", false, false]], "relations_mapping_to_source": [0], "sentence": ["Although", "there", "is", "no", "perfect", "way", "to", "describe", "the", "mixing", "matrix", "of", "TRUE", "and", "FALSE", "positive", "and", "negative", "outcomes", "with", "a", "single", "number", ",", "the", "Matthews", "correlation", "coefficient", "is", "generally", "considered", "one", "of", "the", "best", "such", "measures", "."], "sentence-detokenized": "Although there is no perfect way to describe the mixing matrix of TRUE and FALSE positive and negative outcomes with a single number, the Matthews correlation coefficient is generally considered one of the best such measures.", "token2charspan": [[0, 8], [9, 14], [15, 17], [18, 20], [21, 28], [29, 32], [33, 35], [36, 44], [45, 48], [49, 55], [56, 62], [63, 65], [66, 70], [71, 74], [75, 80], [81, 89], [90, 93], [94, 102], [103, 111], [112, 116], [117, 118], [119, 125], [126, 132], [132, 133], [134, 137], [138, 146], [147, 158], [159, 170], [171, 173], [174, 183], [184, 194], [195, 198], [199, 201], [202, 205], [206, 210], [211, 215], [216, 224], [224, 225]]}
{"doc_key": "ai-test-164", "ner": [[12, 13, "field"], [29, 30, "field"], [33, 35, "field"], [39, 40, "algorithm"], [42, 43, "task"], [45, 46, "algorithm"], [51, 53, "algorithm"], [55, 56, "algorithm"], [62, 64, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[33, 35, 29, 30, "part-of", "subfield", false, false], [39, 40, 33, 35, "part-of", "", false, true], [42, 43, 33, 35, "part-of", "", false, true], [45, 46, 33, 35, "part-of", "", false, true], [51, 53, 33, 35, "part-of", "", false, true], [55, 56, 33, 35, "part-of", "", false, true], [62, 64, 33, 35, "part-of", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["As", "data", "sets", "have", "grown", "in", "size", "and", "complexity", ",", "direct", "practical", "data", "analysis", "has", "been", "complemented", "by", "indirect", ",", "automated", "data", "processing", ",", "supported", "by", "other", "inventions", "in", "computer", "science", ",", "especially", "in", "machine", "learning", ",", "such", "as", "neural", "networks", ",", "cluster", "analysis", ",", "genetic", "algorithms", "(", "1950s", ")", ",", "decision", "tree", "learning", "and", "decision", "rules", "(", "1960", "s", ")", "and", "support", "vector", "machines", "(", "1990", "s", ")", "."], "sentence-detokenized": "As data sets have grown in size and complexity, direct practical data analysis has been complemented by indirect, automated data processing, supported by other inventions in computer science, especially in machine learning, such as neural networks, cluster analysis, genetic algorithms (1950s), decision tree learning and decision rules (1960s) and support vector machines (1990s).", "token2charspan": [[0, 2], [3, 7], [8, 12], [13, 17], [18, 23], [24, 26], [27, 31], [32, 35], [36, 46], [46, 47], [48, 54], [55, 64], [65, 69], [70, 78], [79, 82], [83, 87], [88, 100], [101, 103], [104, 112], [112, 113], [114, 123], [124, 128], [129, 139], [139, 140], [141, 150], [151, 153], [154, 159], [160, 170], [171, 173], [174, 182], [183, 190], [190, 191], [192, 202], [203, 205], [206, 213], [214, 222], [222, 223], [224, 228], [229, 231], [232, 238], [239, 247], [247, 248], [249, 256], [257, 265], [265, 266], [267, 274], [275, 285], [286, 287], [287, 292], [292, 293], [293, 294], [295, 303], [304, 308], [309, 317], [318, 321], [322, 330], [331, 336], [337, 338], [338, 342], [342, 343], [343, 344], [345, 348], [349, 356], [357, 363], [364, 372], [373, 374], [374, 378], [378, 379], [379, 380], [380, 381]]}
{"doc_key": "ai-test-165", "ner": [[4, 4, "researcher"], [8, 9, "misc"], [17, 18, "researcher"], [20, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 4, 4, "artifact", "", false, false], [8, 9, 17, 18, "artifact", "", false, false], [8, 9, 20, 21, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "autumn", "2005", ",", "Thrun", "published", "the", "textbook", "Probabilistic", "Robotics", "together", "with", "his", "long", "-", "time", "colleagues", "Dieter", "Fox", "and", "Wolfram", "Burgard", "."], "sentence-detokenized": "In autumn 2005, Thrun published the textbook Probabilistic Robotics together with his long-time colleagues Dieter Fox and Wolfram Burgard.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 21], [22, 31], [32, 35], [36, 44], [45, 58], [59, 67], [68, 76], [77, 81], [82, 85], [86, 90], [90, 91], [91, 95], [96, 106], [107, 113], [114, 117], [118, 121], [122, 129], [130, 137], [137, 138]]}
{"doc_key": "ai-test-166", "ner": [[0, 2, "researcher"], [4, 5, "researcher"], [7, 7, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["John", "D.", "Lafferty", ",", "Andrew", "McCallum", "and", "Pereiramath", "as", "follows", ":"], "sentence-detokenized": "John D. Lafferty, Andrew McCallum and Pereiramath as follows:", "token2charspan": [[0, 4], [5, 7], [8, 16], [16, 17], [18, 24], [25, 33], [34, 37], [38, 49], [50, 52], [53, 60], [60, 61]]}
{"doc_key": "ai-test-167", "ner": [[1, 1, "task"], [0, 3, "task"], [9, 10, "field"], [15, 16, "field"], [19, 20, "field"], [22, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 1, 15, 16, "part-of", "task_part_of_field", false, false], [1, 1, 19, 20, "part-of", "task_part_of_field", false, false], [0, 3, 1, 1, "named", "", false, false], [15, 16, 9, 10, "part-of", "subfield", false, false], [19, 20, 9, 10, "part-of", "subfield", false, false], [22, 25, 19, 20, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Question", "Answering", "(", "QA", ")", "is", "a", "branch", "of", "computer", "science", "within", "the", "field", "of", "information", "retrieval", "and", "natural", "language", "processing", "(", "NLP", ")", ",", "which", "deals", "with", "the", "construction", "of", "systems", "that", "automatically", "answer", "questions", "asked", "by", "people", "in", "natural", "language", "."], "sentence-detokenized": "Question Answering (QA) is a branch of computer science within the field of information retrieval and natural language processing (NLP), which deals with the construction of systems that automatically answer questions asked by people in natural language.", "token2charspan": [[0, 8], [9, 18], [19, 20], [20, 22], [22, 23], [24, 26], [27, 28], [29, 35], [36, 38], [39, 47], [48, 55], [56, 62], [63, 66], [67, 72], [73, 75], [76, 87], [88, 97], [98, 101], [102, 109], [110, 118], [119, 129], [130, 131], [131, 134], [134, 135], [135, 136], [137, 142], [143, 148], [149, 153], [154, 157], [158, 170], [171, 173], [174, 181], [182, 186], [187, 200], [201, 207], [208, 217], [218, 223], [224, 226], [227, 233], [234, 236], [237, 244], [245, 253], [253, 254]]}
{"doc_key": "ai-test-168", "ner": [[9, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "the", "version", "of", "the", "metric", "used", "in", "NIST", "assessments", "prior", "to", "2009", "used", "the", "shortest", "benchmark", "term", "."], "sentence-detokenized": "However, the version of the metric used in NIST assessments prior to 2009 used the shortest benchmark term.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 20], [21, 23], [24, 27], [28, 34], [35, 39], [40, 42], [43, 47], [48, 59], [60, 65], [66, 68], [69, 73], [74, 78], [79, 82], [83, 91], [92, 101], [102, 106], [106, 107]]}
{"doc_key": "ai-test-169", "ner": [[5, 5, "person"], [16, 16, "product"]], "ner_mapping_to_source": [0, 2], "relations": [[5, 5, 16, 16, "related-to", "invests_in", false, false]], "relations_mapping_to_source": [0], "sentence": ["On", "27", "August", "2018", ",", "Toyota", "announced", "that", "it", "will", "invest", "$", "500", "million", "in", "Uber", "autonomous", "cars", "."], "sentence-detokenized": "On 27 August 2018, Toyota announced that it will invest $500 million in Uber autonomous cars.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 17], [17, 18], [19, 25], [26, 35], [36, 40], [41, 43], [44, 48], [49, 55], [56, 57], [57, 60], [61, 68], [69, 71], [72, 76], [77, 87], [88, 92], [92, 93]]}
{"doc_key": "ai-test-170", "ner": [[5, 11, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "sample", "maximum", "is", "the", "maximum", "likelihood", "estimator", "of", "the", "population", "maximum", ",", "but", "as", "noted", "above", ",", "it", "is", "biased", "."], "sentence-detokenized": "The sample maximum is the maximum likelihood estimator of the population maximum, but as noted above, it is biased.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 21], [22, 25], [26, 33], [34, 44], [45, 54], [55, 57], [58, 61], [62, 72], [73, 80], [80, 81], [82, 85], [86, 88], [89, 94], [95, 100], [100, 101], [102, 104], [105, 107], [108, 114], [114, 115]]}
{"doc_key": "ai-test-171", "ner": [[0, 0, "task"], [3, 3, "misc"], [6, 6, "metrics"], [15, 17, "algorithm"], [19, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 3, 3, "related-to", "overcomes", false, false], [0, 0, 6, 6, "related-to", "increases", false, false], [3, 3, 15, 17, "opposite", "", false, false], [3, 3, 19, 21, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LSI", "helps", "overcome", "synonymy", "by", "increasing", "recall", ",", "one", "of", "the", "most", "problematic", "limitations", "of", "Boolean", "keyword", "queries", "and", "vector", "space", "models", "."], "sentence-detokenized": "LSI helps overcome synonymy by increasing recall, one of the most problematic limitations of Boolean keyword queries and vector space models.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 27], [28, 30], [31, 41], [42, 48], [48, 49], [50, 53], [54, 56], [57, 60], [61, 65], [66, 77], [78, 89], [90, 92], [93, 100], [101, 108], [109, 116], [117, 120], [121, 127], [128, 133], [134, 140], [140, 141]]}
{"doc_key": "ai-test-172", "ner": [[21, 21, "programlang"], [23, 23, "programlang"], [25, 25, "programlang"], [27, 28, "programlang"], [30, 30, "programlang"], [32, 32, "programlang"], [34, 34, "programlang"], [36, 36, "programlang"], [38, 38, "programlang"], [40, 40, "programlang"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [], "relations_mapping_to_source": [], "sentence": ["Data", "collection", "applications", "are", "usually", "driven", "by", "software", "developed", "in", "a", "variety", "of", "general", "-", "purpose", "programming", "languages", ",", "such", "as", "Assembly", ",", "BASIC", ",", "C", ",", "C", "++", ",", "C#", ",", "Fortran", ",", "Java", ",", "LabVIEW", ",", "Lisp", ",", "Pascal", ",", "etc."], "sentence-detokenized": "Data collection applications are usually driven by software developed in a variety of general-purpose programming languages, such as Assembly, BASIC, C, C++, C#, Fortran, Java, LabVIEW, Lisp, Pascal, etc.", "token2charspan": [[0, 4], [5, 15], [16, 28], [29, 32], [33, 40], [41, 47], [48, 50], [51, 59], [60, 69], [70, 72], [73, 74], [75, 82], [83, 85], [86, 93], [93, 94], [94, 101], [102, 113], [114, 123], [123, 124], [125, 129], [130, 132], [133, 141], [141, 142], [143, 148], [148, 149], [150, 151], [151, 152], [153, 154], [154, 156], [156, 157], [158, 160], [160, 161], [162, 169], [169, 170], [171, 175], [175, 176], [177, 184], [184, 185], [186, 190], [190, 191], [192, 198], [198, 199], [200, 204]]}
{"doc_key": "ai-test-173", "ner": [[3, 3, "organisation"], [10, 10, "country"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2003", ",", "Honda", "launched", "its", "Cog", "advertisement", "in", "the", "UK", "and", "on", "the", "Internet", "."], "sentence-detokenized": "In 2003, Honda launched its Cog advertisement in the UK and on the Internet.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 27], [28, 31], [32, 45], [46, 48], [49, 52], [53, 55], [56, 59], [60, 62], [63, 66], [67, 75], [75, 76]]}
{"doc_key": "ai-test-174", "ner": [[0, 4, "conference"], [6, 8, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 4, 6, 8, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Association", "for", "Computational", "Linguistics", "defines", "computational", "linguistics", "as", ":"], "sentence-detokenized": "The Association for Computational Linguistics defines computational linguistics as:", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 33], [34, 45], [46, 53], [54, 67], [68, 79], [80, 82], [82, 83]]}
{"doc_key": "ai-test-175", "ner": [[0, 2, "algorithm"], [9, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 12, "related-to", "calculates", false, false]], "relations_mapping_to_source": [0], "sentence": ["Expectation", "maximization", "algorithms", "can", "be", "used", "to", "compute", "approximate", "maximum", "likelihood", "estimates", "of", "unknown", "spatial", "-", "space", "parameters", "in", "minimum", "variance", "filters", "and", "smoothers", "."], "sentence-detokenized": "Expectation maximization algorithms can be used to compute approximate maximum likelihood estimates of unknown spatial-space parameters in minimum variance filters and smoothers.", "token2charspan": [[0, 11], [12, 24], [25, 35], [36, 39], [40, 42], [43, 47], [48, 50], [51, 58], [59, 70], [71, 78], [79, 89], [90, 99], [100, 102], [103, 110], [111, 118], [118, 119], [119, 124], [125, 135], [136, 138], [139, 146], [147, 155], [156, 163], [164, 167], [168, 177], [177, 178]]}
{"doc_key": "ai-test-176", "ner": [[5, 7, "person"], [9, 10, "person"], [12, 13, "person"], [16, 17, "misc"], [18, 19, "person"], [22, 23, "person"], [27, 27, "person"], [29, 30, "person"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8], "relations": [[18, 19, 16, 17, "role", "model_for", false, false], [27, 27, 29, 30, "social", "family", false, false]], "relations_mapping_to_source": [3, 4], "sentence": ["Correspondents", "included", "former", "Baywatch", "actresses", "Donna", "D'", "Errico", ",", "Carmen", "Electra", "and", "Traci", "Bingham", ",", "former", "Playboy", "Playmate", "Heidi", "Mark", ",", "comedian", "Arj", "Barker", "and", "identical", "twins", "Randy", "and", "Jason", "Sklar", "."], "sentence-detokenized": "Correspondents included former Baywatch actresses Donna D'Errico, Carmen Electra and Traci Bingham, former Playboy Playmate Heidi Mark, comedian Arj Barker and identical twins Randy and Jason Sklar.", "token2charspan": [[0, 14], [15, 23], [24, 30], [31, 39], [40, 49], [50, 55], [56, 58], [58, 64], [64, 65], [66, 72], [73, 80], [81, 84], [85, 90], [91, 98], [98, 99], [100, 106], [107, 114], [115, 123], [124, 129], [130, 134], [134, 135], [136, 144], [145, 148], [149, 155], [156, 159], [160, 169], [170, 175], [176, 181], [182, 185], [186, 191], [192, 197], [197, 198]]}
{"doc_key": "ai-test-177", "ner": [[8, 9, "task"], [11, 11, "task"], [17, 20, "product"], [24, 25, "task"], [27, 27, "task"], [32, 35, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 11, 8, 9, "named", "", false, false], [17, 20, 8, 9, "general-affiliation", "", false, false], [27, 27, 24, 25, "named", "", false, false], [32, 35, 24, 25, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "is", "commonly", "used", "to", "generate", "presentations", "for", "speech", "recognition", "(", "ASR", ")", ",", "for", "example", "in", "CMU", "'s", "Sphinx", "system", ",", "and", "for", "speech", "synthesis", "(", "TTS", ")", ",", "for", "example", "in", "the", "Festival", "system", "."], "sentence-detokenized": "It is commonly used to generate presentations for speech recognition (ASR), for example in CMU's Sphinx system, and for speech synthesis (TTS), for example in the Festival system.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 19], [20, 22], [23, 31], [32, 45], [46, 49], [50, 56], [57, 68], [69, 70], [70, 73], [73, 74], [74, 75], [76, 79], [80, 87], [88, 90], [91, 94], [94, 96], [97, 103], [104, 110], [110, 111], [112, 115], [116, 119], [120, 126], [127, 136], [137, 138], [138, 141], [141, 142], [142, 143], [144, 147], [148, 155], [156, 158], [159, 162], [163, 171], [172, 178], [178, 179]]}
{"doc_key": "ai-test-178", "ner": [[0, 0, "metrics"], [2, 4, "metrics"], [6, 6, "metrics"], [12, 12, "metrics"], [21, 22, "metrics"], [24, 24, "metrics"], [32, 35, "metrics"], [37, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 7, 8], "relations": [[2, 4, 0, 0, "named", "", false, false], [6, 6, 2, 4, "named", "", false, false], [12, 12, 0, 0, "named", "", false, false], [24, 24, 21, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sensitivity", "or", "TRUE", "Positive", "Rate", "(", "TPR", ")", ",", "also", "known", "as", "recall", ",", "is", "the", "proportion", "of", "positive", "individuals", "(", "TRUE", "Positive", ",", "TP", ")", "out", "of", "all", "positive", "individuals", "(", "Condition", "Positive", ",", "CP", "=", "TP", "+", "FN", ")", "."], "sentence-detokenized": "Sensitivity or TRUE Positive Rate (TPR), also known as recall, is the proportion of positive individuals (TRUE Positive, TP) out of all positive individuals (Condition Positive, CP = TP + FN).", "token2charspan": [[0, 11], [12, 14], [15, 19], [20, 28], [29, 33], [34, 35], [35, 38], [38, 39], [39, 40], [41, 45], [46, 51], [52, 54], [55, 61], [61, 62], [63, 65], [66, 69], [70, 80], [81, 83], [84, 92], [93, 104], [105, 106], [106, 110], [111, 119], [119, 120], [121, 123], [123, 124], [125, 128], [129, 131], [132, 135], [136, 144], [145, 156], [157, 158], [158, 167], [168, 176], [176, 177], [178, 180], [181, 182], [183, 185], [186, 187], [188, 190], [190, 191], [191, 192]]}
{"doc_key": "ai-test-179", "ner": [[13, 13, "conference"], [15, 16, "conference"], [18, 18, "conference"], [20, 20, "conference"], [22, 22, "conference"], [24, 25, "conference"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Popular", "speech", "recognition", "conferences", "that", "take", "place", "annually", "or", "every", "two", "years", "include", "SpeechTEK", "and", "SpeechTEK", "Europe", ",", "ICASSP", ",", "Interspeech", "/", "Eurospeech", "and", "IEEE", "ASRU", "."], "sentence-detokenized": "Popular speech recognition conferences that take place annually or every two years include SpeechTEK and SpeechTEK Europe, ICASSP, Interspeech / Eurospeech and IEEE ASRU.", "token2charspan": [[0, 7], [8, 14], [15, 26], [27, 38], [39, 43], [44, 48], [49, 54], [55, 63], [64, 66], [67, 72], [73, 76], [77, 82], [83, 90], [91, 100], [101, 104], [105, 114], [115, 121], [121, 122], [123, 129], [129, 130], [131, 142], [143, 144], [145, 155], [156, 159], [160, 164], [165, 169], [169, 170]]}
{"doc_key": "ai-test-180", "ner": [[0, 0, "researcher"], [3, 3, "researcher"], [16, 18, "product"], [19, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[19, 22, 0, 0, "artifact", "", false, false], [19, 22, 3, 3, "artifact", "", false, false], [19, 22, 16, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Devol", "worked", "with", "Engelberger", ",", "who", "was", "the", "company", "'s", "CEO", ",", "to", "design", "and", "produce", "an", "industrial", "robot", "under", "the", "Unimate", "brand", "."], "sentence-detokenized": "Devol worked with Engelberger, who was the company's CEO, to design and produce an industrial robot under the Unimate brand.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 29], [29, 30], [31, 34], [35, 38], [39, 42], [43, 50], [50, 52], [53, 56], [56, 57], [58, 60], [61, 67], [68, 71], [72, 79], [80, 82], [83, 93], [94, 99], [100, 105], [106, 109], [110, 117], [118, 123], [123, 124]]}
{"doc_key": "ai-test-181", "ner": [[1, 3, "algorithm"], [0, 5, "algorithm"], [9, 11, "algorithm"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 3, 9, 11, "general-affiliation", "", false, false], [0, 5, 1, 3, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "Hidden", "Markov", "model", "(", "HMM", ")", "is", "a", "statistical", "Markov", "model", "in", "which", "the", "system", "being", "modelled", "is", "assumed", "to", "be", "a", "Markov", "process", "with", "undetected", "(", "hidden", ")", "states", "."], "sentence-detokenized": "A Hidden Markov model (HMM) is a statistical Markov model in which the system being modelled is assumed to be a Markov process with undetected (hidden) states.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 21], [22, 23], [23, 26], [26, 27], [28, 30], [31, 32], [33, 44], [45, 51], [52, 57], [58, 60], [61, 66], [67, 70], [71, 77], [78, 83], [84, 92], [93, 95], [96, 103], [104, 106], [107, 109], [110, 111], [112, 118], [119, 126], [127, 131], [132, 142], [143, 144], [144, 150], [150, 151], [152, 158], [158, 159]]}
{"doc_key": "ai-test-182", "ner": [[16, 18, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "feature", ",", "undesirable", "in", "many", "applications", ",", "has", "led", "researchers", "to", "use", "alternatives", "such", "as", "absolute", "standard", "error", "or", "median", "-", "based", "methods", "."], "sentence-detokenized": "This feature, undesirable in many applications, has led researchers to use alternatives such as absolute standard error or median-based methods.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 25], [26, 28], [29, 33], [34, 46], [46, 47], [48, 51], [52, 55], [56, 67], [68, 70], [71, 74], [75, 87], [88, 92], [93, 95], [96, 104], [105, 113], [114, 119], [120, 122], [123, 129], [129, 130], [130, 135], [136, 143], [143, 144]]}
{"doc_key": "ai-test-183", "ner": [[22, 27, "algorithm"], [30, 34, "field"], [37, 39, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 27, 30, 34, "part-of", "", false, false], [22, 27, 37, 39, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Such", "a", "sequence", "(", "which", "depends", "at", "each", "stage", "on", "the", "outcome", "of", "the", "exploration", "of", "the", "previous", "features", ")", "is", "called", "a", "decision", "tree", ",", "and", "is", "applied", "in", "the", "field", "of", "machine", "learning", "known", "as", "decision", "tree", "learning", "."], "sentence-detokenized": "Such a sequence (which depends at each stage on the outcome of the exploration of the previous features) is called a decision tree, and is applied in the field of machine learning known as decision tree learning.", "token2charspan": [[0, 4], [5, 6], [7, 15], [16, 17], [17, 22], [23, 30], [31, 33], [34, 38], [39, 44], [45, 47], [48, 51], [52, 59], [60, 62], [63, 66], [67, 78], [79, 81], [82, 85], [86, 94], [95, 103], [103, 104], [105, 107], [108, 114], [115, 116], [117, 125], [126, 130], [130, 131], [132, 135], [136, 138], [139, 146], [147, 149], [150, 153], [154, 159], [160, 162], [163, 170], [171, 179], [180, 185], [186, 188], [189, 197], [198, 202], [203, 211], [211, 212]]}
{"doc_key": "ai-test-184", "ner": [[1, 3, "task"], [5, 5, "algorithm"], [18, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 3, 5, 5, "compare", "", false, false], [18, 20, 5, 5, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "in", "factor", "analysis", ",", "LCA", "can", "be", "used", "to", "classify", "cases", "according", "to", "the", "categories", "they", "are", "most", "likely", "to", "belong", "to", "."], "sentence-detokenized": "As in factor analysis, LCA can be used to classify cases according to the categories they are most likely to belong to.", "token2charspan": [[0, 2], [3, 5], [6, 12], [13, 21], [21, 22], [23, 26], [27, 30], [31, 33], [34, 38], [39, 41], [42, 50], [51, 56], [57, 66], [67, 69], [70, 73], [74, 84], [85, 89], [90, 93], [94, 98], [99, 105], [106, 108], [109, 115], [116, 118], [118, 119]]}
{"doc_key": "ai-test-185", "ner": [[0, 2, "algorithm"], [6, 7, "metrics"], [4, 12, "misc"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[0, 2, 6, 7, "usage", "", false, false], [6, 7, 4, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Supervised", "neural", "networks", "using", "the", "Mean", "Squared", "Error", "(", "MSE", ")", "cost", "function", "can", "use", "formal", "statistical", "methods", "to", "determine", "the", "reliability", "of", "the", "trained", "model", "."], "sentence-detokenized": "Supervised neural networks using the Mean Squared Error (MSE) cost function can use formal statistical methods to determine the reliability of the trained model.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 32], [33, 36], [37, 41], [42, 49], [50, 55], [56, 57], [57, 60], [60, 61], [62, 66], [67, 75], [76, 79], [80, 83], [84, 90], [91, 102], [103, 110], [111, 113], [114, 123], [124, 127], [128, 139], [140, 142], [143, 146], [147, 154], [155, 160], [160, 161]]}
{"doc_key": "ai-test-186", "ner": [[16, 18, "algorithm"], [21, 23, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[16, 18, 21, 23, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "can", "be", "expressed", "directly", "as", "a", "linear", "program", ",", "but", "it", "is", "also", "equivalent", "to", "Tikhonov", "'s", "regularization", "with", "the", "hinge", "loss", "function", ",", "mathV", "(", "f", "(", "x", ")", ",", "y", ")", "=\\", "max", "(", "0", ",", "1", "-", "yf", "(", "x", ")", ")", "/", "math", ":"], "sentence-detokenized": "This can be expressed directly as a linear program, but it is also equivalent to Tikhonov's regularization with the hinge loss function, mathV (f (x), y) =\\ max (0, 1 - yf (x)) / math:", "token2charspan": [[0, 4], [5, 8], [9, 11], [12, 21], [22, 30], [31, 33], [34, 35], [36, 42], [43, 50], [50, 51], [52, 55], [56, 58], [59, 61], [62, 66], [67, 77], [78, 80], [81, 89], [89, 91], [92, 106], [107, 111], [112, 115], [116, 121], [122, 126], [127, 135], [135, 136], [137, 142], [143, 144], [144, 145], [146, 147], [147, 148], [148, 149], [149, 150], [151, 152], [152, 153], [154, 156], [157, 160], [161, 162], [162, 163], [163, 164], [165, 166], [167, 168], [169, 171], [172, 173], [173, 174], [174, 175], [175, 176], [177, 178], [179, 183], [183, 184]]}
{"doc_key": "ai-test-187", "ner": [[14, 18, "product"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "technique", "is", "described", "in", "Breiman", "'s", "original", "article", ",", "and", "is", "implemented", "in", "the", "R", "package", "randomForest", "."], "sentence-detokenized": "The following technique is described in Breiman's original article, and is implemented in the R package randomForest.", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 26], [27, 36], [37, 39], [40, 47], [47, 49], [50, 58], [59, 66], [66, 67], [68, 71], [72, 74], [75, 86], [87, 89], [90, 93], [94, 95], [96, 103], [104, 116], [116, 117]]}
{"doc_key": "ai-test-188", "ner": [[7, 7, "metrics"], [40, 40, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "image", "quality", "measurements", ",", "such", "as", "PSNR", ",", "are", "usually", "performed", "on", "fixed", "resolution", "images", "and", "do", "not", "take", "into", "account", "certain", "visual", "aspects", "of", "the", "human", "visual", "system", ",", "such", "as", "changes", "in", "the", "spatial", "resolution", "of", "the", "retina", "."], "sentence-detokenized": "Traditional image quality measurements, such as PSNR, are usually performed on fixed resolution images and do not take into account certain visual aspects of the human visual system, such as changes in the spatial resolution of the retina.", "token2charspan": [[0, 11], [12, 17], [18, 25], [26, 38], [38, 39], [40, 44], [45, 47], [48, 52], [52, 53], [54, 57], [58, 65], [66, 75], [76, 78], [79, 84], [85, 95], [96, 102], [103, 106], [107, 109], [110, 113], [114, 118], [119, 123], [124, 131], [132, 139], [140, 146], [147, 154], [155, 157], [158, 161], [162, 167], [168, 174], [175, 181], [181, 182], [183, 187], [188, 190], [191, 198], [199, 201], [202, 205], [206, 213], [214, 224], [225, 227], [228, 231], [232, 238], [238, 239]]}
{"doc_key": "ai-test-189", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [10, 12, "person"], [15, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 15, 18, "role", "", false, false], [3, 4, 15, 18, "role", "", false, false], [6, 7, 15, 18, "role", "", false, false], [15, 18, 10, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["John", "Ireland", ",", "Joanne", "Dru", "and", "Macdonald", "Carey", "starred", "in", "Jack", "Broder", "'s", "colour", "production", "Hannah", "Lee", ",", "which", "premiered", "on", "19", "June", "1953", "."], "sentence-detokenized": "John Ireland, Joanne Dru and Macdonald Carey starred in Jack Broder's colour production Hannah Lee, which premiered on 19 June 1953.", "token2charspan": [[0, 4], [5, 12], [12, 13], [14, 20], [21, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 55], [56, 60], [61, 67], [67, 69], [70, 76], [77, 87], [88, 94], [95, 98], [98, 99], [100, 105], [106, 115], [116, 118], [119, 121], [122, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-test-190", "ner": [[4, 5, "task"], [9, 10, "field"], [16, 16, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 9, 10, "usage", "", false, false], [16, 16, 9, 10, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "process", "is", "called", "image", "registration", "and", "uses", "various", "computer", "vision", "methods", ",", "mostly", "related", "to", "tracking", "."], "sentence-detokenized": "This process is called image registration and uses various computer vision methods, mostly related to tracking.", "token2charspan": [[0, 4], [5, 12], [13, 15], [16, 22], [23, 28], [29, 41], [42, 45], [46, 50], [51, 58], [59, 67], [68, 74], [75, 82], [82, 83], [84, 90], [91, 98], [99, 101], [102, 110], [110, 111]]}
{"doc_key": "ai-test-191", "ner": [[18, 19, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Let", "'s", "now", "start", "to", "explain", "the", "possible", "relationships", "between", "the", "predicted", "and", "the", "actual", "outcome", ":", "the", "mixing", "matrix"], "sentence-detokenized": "Let's now start to explain the possible relationships between the predicted and the actual outcome: the mixing matrix", "token2charspan": [[0, 3], [3, 5], [6, 9], [10, 15], [16, 18], [19, 26], [27, 30], [31, 39], [40, 53], [54, 61], [62, 65], [66, 75], [76, 79], [80, 83], [84, 90], [91, 98], [98, 99], [100, 103], [104, 110], [111, 117]]}
{"doc_key": "ai-test-192", "ner": [[2, 5, "misc"], [0, 1, "product"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "MATLAB", "VOICEBOX", "speech", "processing", "toolkit", "implements", "the", "transformation", "and", "its", "inverse", "as", "follows", ":"], "sentence-detokenized": "The MATLAB VOICEBOX speech processing toolkit implements the transformation and its inverse as follows:", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 26], [27, 37], [38, 45], [46, 56], [57, 60], [61, 75], [76, 79], [80, 83], [84, 91], [92, 94], [95, 102], [102, 103]]}
{"doc_key": "ai-test-193", "ner": [[0, 2, "programlang"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 8, 9, "general-affiliation", "", false, false], [0, 2, 11, 12, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Prolog", "is", "a", "logic", "programming", "language", "related", "to", "artificial", "intelligence", "and", "computational", "linguistics", "."], "sentence-detokenized": "Prolog is a logic programming language related to artificial intelligence and computational linguistics.", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 17], [18, 29], [30, 38], [39, 46], [47, 49], [50, 60], [61, 73], [74, 77], [78, 91], [92, 103], [103, 104]]}
{"doc_key": "ai-test-194", "ner": [[0, 1, "researcher"], [9, 9, "field"], [11, 11, "field"], [17, 20, "organisation"], [23, 26, "organisation"], [29, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 9, 9, "related-to", "works_with_topic", false, false], [0, 1, 11, 11, "related-to", "works_with_topic", false, false], [0, 1, 17, 20, "role", "", false, false], [0, 1, 23, 26, "role", "", false, false], [0, 1, 29, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Milner", "has", "received", "numerous", "awards", "for", "his", "contributions", "to", "neuroscience", "and", "psychology", ",", "including", "membership", "of", "the", "Royal", "Society", "of", "London", ",", "the", "Royal", "Society", "of", "Canada", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Milner has received numerous awards for his contributions to neuroscience and psychology, including membership of the Royal Society of London, the Royal Society of Canada and the National Academy of Sciences.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 28], [29, 35], [36, 39], [40, 43], [44, 57], [58, 60], [61, 73], [74, 77], [78, 88], [88, 89], [90, 99], [100, 110], [111, 113], [114, 117], [118, 123], [124, 131], [132, 134], [135, 141], [141, 142], [143, 146], [147, 152], [153, 160], [161, 163], [164, 170], [171, 174], [175, 178], [179, 187], [188, 195], [196, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-test-195", "ner": [[13, 14, "task"], [16, 17, "task"], [19, 20, "task"], [22, 25, "task"], [26, 26, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Combining", "these", "operators", "provides", "algorithms", "for", "many", "image", "processing", "tasks", ",", "such", "as", "feature", "extraction", ",", "image", "segmentation", ",", "image", "sharpening", ",", "image", "filtering", "and", "image", "classification", "."], "sentence-detokenized": "Combining these operators provides algorithms for many image processing tasks, such as feature extraction, image segmentation, image sharpening, image filtering and image classification.", "token2charspan": [[0, 9], [10, 15], [16, 25], [26, 34], [35, 45], [46, 49], [50, 54], [55, 60], [61, 71], [72, 77], [77, 78], [79, 83], [84, 86], [87, 94], [95, 105], [105, 106], [107, 112], [113, 125], [125, 126], [127, 132], [133, 143], [143, 144], [145, 150], [151, 160], [161, 164], [165, 170], [171, 185], [185, 186]]}
{"doc_key": "ai-test-196", "ner": [[9, 11, "university"], [21, 23, "organisation"], [25, 26, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[25, 26, 21, 23, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Since", "2017", ",", "he", "is", "a", "professor", "at", "the", "Coll\u00e8ge", "de", "France", "and", "since", "1989", ",", "he", "is", "the", "director", "of", "INSERM", "Unit", "562", ",", "Cognitive", "Neuroimaging", "."], "sentence-detokenized": "Since 2017, he is a professor at the Coll\u00e8ge de France and since 1989, he is the director of INSERM Unit 562, Cognitive Neuroimaging.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 14], [15, 17], [18, 19], [20, 29], [30, 32], [33, 36], [37, 44], [45, 47], [48, 54], [55, 58], [59, 64], [65, 69], [69, 70], [71, 73], [74, 76], [77, 80], [81, 89], [90, 92], [93, 99], [100, 104], [105, 108], [108, 109], [110, 119], [120, 132], [132, 133]]}
{"doc_key": "ai-test-197", "ner": [[10, 16, "algorithm"], [13, 15, "algorithm"], [20, 20, "algorithm"], [22, 28, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[20, 20, 22, 28, "temporal", "", false, true]], "relations_mapping_to_source": [0], "sentence": ["There", "are", "many", "approaches", "to", "learning", "these", "embeddings", ",", "notably", "Bayesian", "clustering", "or", "energy", "-", "based", "systems", "and", "more", "recently", "TransE", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", "2013", ")", "."], "sentence-detokenized": "There are many approaches to learning these embeddings, notably Bayesian clustering or energy-based systems and more recently TransE (Conference on Neural Information Processing Systems 2013).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 25], [26, 28], [29, 37], [38, 43], [44, 54], [54, 55], [56, 63], [64, 72], [73, 83], [84, 86], [87, 93], [93, 94], [94, 99], [100, 107], [108, 111], [112, 116], [117, 125], [126, 132], [133, 134], [134, 144], [145, 147], [148, 154], [155, 166], [167, 177], [178, 185], [186, 190], [190, 191], [191, 192]]}
{"doc_key": "ai-test-198", "ner": [[6, 7, "metrics"], [8, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 8, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "is", "an", "alternative", "to", "the", "Word", "Error", "Rate", "used", "in", "many", "countries", "."], "sentence-detokenized": "It is an alternative to the Word Error Rate used in many countries.", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 20], [21, 23], [24, 27], [28, 32], [33, 38], [39, 43], [44, 48], [49, 51], [52, 56], [57, 66], [66, 67]]}
{"doc_key": "ai-test-199", "ner": [[0, 0, "algorithm"], [12, 13, "task"], [15, 16, "task"], [18, 19, "task"], [21, 23, "task"], [25, 28, "task"], [30, 31, "task"], [42, 42, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[12, 13, 0, 0, "usage", "", false, false], [15, 16, 0, 0, "usage", "", false, false], [18, 19, 0, 0, "usage", "", false, false], [21, 23, 0, 0, "usage", "", false, false], [25, 28, 0, 0, "usage", "", false, false], [30, 31, 0, 0, "usage", "", false, false], [42, 42, 0, 0, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["VNEs", "have", "been", "used", "for", "a", "wide", "range", "of", "tasks", "such", "as", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "filtering", "social", "networks", ",", "board", "and", "video", "games", ",", "medical", "diagnostics", "and", "even", "activities", "traditionally", "reserved", "for", "humans", ",", "such", "as", "painting", "."], "sentence-detokenized": "VNEs have been used for a wide range of tasks such as computer vision, speech recognition, machine translation, filtering social networks, board and video games, medical diagnostics and even activities traditionally reserved for humans, such as painting.", "token2charspan": [[0, 4], [5, 9], [10, 14], [15, 19], [20, 23], [24, 25], [26, 30], [31, 36], [37, 39], [40, 45], [46, 50], [51, 53], [54, 62], [63, 69], [69, 70], [71, 77], [78, 89], [89, 90], [91, 98], [99, 110], [110, 111], [112, 121], [122, 128], [129, 137], [137, 138], [139, 144], [145, 148], [149, 154], [155, 160], [160, 161], [162, 169], [170, 181], [182, 185], [186, 190], [191, 201], [202, 215], [216, 224], [225, 228], [229, 235], [235, 236], [237, 241], [242, 244], [245, 253], [253, 254]]}
{"doc_key": "ai-test-200", "ner": [[0, 4, "product"], [6, 6, "product"], [26, 27, "field"], [31, 32, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[0, 4, 26, 27, "related-to", "", false, false], [0, 4, 31, 32, "general-affiliation", "", false, false], [6, 6, 0, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Modular", "Audio", "Recognition", "Framework", "(", "MARF", ")", "is", "an", "open", "source", "research", "platform", "and", "a", "collection", "of", "audio", ",", "voice", ",", "speech", ",", "text", "and", "natural", "language", "processing", "algorithms", "written", "in", "Java", ",", "organised", "in", "a", "modular", "and", "extensible", "framework", "that", "aims", "to", "facilitate", "the", "addition", "of", "new", "algorithms", "."], "sentence-detokenized": "The Modular Audio Recognition Framework (MARF) is an open source research platform and a collection of audio, voice, speech, text and natural language processing algorithms written in Java, organised in a modular and extensible framework that aims to facilitate the addition of new algorithms.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 29], [30, 39], [40, 41], [41, 45], [45, 46], [47, 49], [50, 52], [53, 57], [58, 64], [65, 73], [74, 82], [83, 86], [87, 88], [89, 99], [100, 102], [103, 108], [108, 109], [110, 115], [115, 116], [117, 123], [123, 124], [125, 129], [130, 133], [134, 141], [142, 150], [151, 161], [162, 172], [173, 180], [181, 183], [184, 188], [188, 189], [190, 199], [200, 202], [203, 204], [205, 212], [213, 216], [217, 227], [228, 237], [238, 242], [243, 247], [248, 250], [251, 261], [262, 265], [266, 274], [275, 277], [278, 281], [282, 292], [292, 293]]}
{"doc_key": "ai-test-201", "ner": [[6, 10, "organisation"], [22, 22, "country"], [26, 28, "organisation"], [31, 32, "organisation"], [36, 37, "task"], [51, 54, "organisation"], [57, 58, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[26, 28, 22, 22, "physical", "", false, false], [26, 28, 36, 37, "usage", "", false, false], [26, 28, 51, 54, "named", "", false, false], [31, 32, 22, 22, "physical", "", false, false], [31, 32, 36, 37, "usage", "", false, false], [51, 54, 57, 58, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "a", "report", "by", "Big", "Brother", "Watch", ",", "an", "advocacy", "group", "for", "civil", "liberties", "and", "rights", ",", "revealed", "that", "two", "UK", "police", "forces", ",", "South", "Wales", "Police", "and", "the", "Metropolitan", "Police", ",", "were", "using", "facial", "recognition", "at", "public", "events", "and", "in", "public", "spaces", ",", "and", "in", "September", "2019", ",", "South", "Wales", "Police", "'s", "use", "of", "facial", "recognition", "was", "found", "to", "be", "legal", "."], "sentence-detokenized": "In 2018, a report by Big Brother Watch, an advocacy group for civil liberties and rights, revealed that two UK police forces, South Wales Police and the Metropolitan Police, were using facial recognition at public events and in public spaces, and in September 2019, South Wales Police's use of facial recognition was found to be legal.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 10], [11, 17], [18, 20], [21, 24], [25, 32], [33, 38], [38, 39], [40, 42], [43, 51], [52, 57], [58, 61], [62, 67], [68, 77], [78, 81], [82, 88], [88, 89], [90, 98], [99, 103], [104, 107], [108, 110], [111, 117], [118, 124], [124, 125], [126, 131], [132, 137], [138, 144], [145, 148], [149, 152], [153, 165], [166, 172], [172, 173], [174, 178], [179, 184], [185, 191], [192, 203], [204, 206], [207, 213], [214, 220], [221, 224], [225, 227], [228, 234], [235, 241], [241, 242], [243, 246], [247, 249], [250, 259], [260, 264], [264, 265], [266, 271], [272, 277], [278, 284], [284, 286], [287, 290], [291, 293], [294, 300], [301, 312], [313, 316], [317, 322], [323, 325], [326, 328], [329, 334], [334, 335]]}
{"doc_key": "ai-test-202", "ner": [[0, 0, "product"], [4, 5, "programlang"], [14, 15, "field"], [17, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 5, "general-affiliation", "", false, false], [0, 0, 14, 15, "related-to", "", false, false], [0, 0, 17, 17, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["ANIMAL", "has", "been", "ported", "to", "R", ",", "a", "freely", "available", "language", "and", "environment", "for", "statistical", "computing", "and", "graphics", "."], "sentence-detokenized": "ANIMAL has been ported to R, a freely available language and environment for statistical computing and graphics.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 22], [23, 25], [26, 27], [27, 28], [29, 30], [31, 37], [38, 47], [48, 56], [57, 60], [61, 72], [73, 76], [77, 88], [89, 98], [99, 102], [103, 111], [111, 112]]}
{"doc_key": "ai-test-203", "ner": [[3, 6, "algorithm"], [0, 10, "algorithm"], [18, 18, "algorithm"], [21, 23, "algorithm"], [24, 26, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 18, 18, "opposite", "alternative to", false, false], [0, 10, 3, 6, "named", "", false, false], [21, 23, 18, 18, "named", "", false, false], [24, 26, 3, 6, "usage", "", false, false], [24, 26, 18, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "time", "-", "inhomogeneous", "hidden", "Bernoulli", "model", "(", "TI", "-", "HBM", ")", "is", "an", "alternative", "to", "the", "hidden", "Markov", "model", "(", "HMM", ")", "for", "automatic", "speech", "recognition", "."], "sentence-detokenized": "The time-inhomogeneous hidden Bernoulli model (TI-HBM) is an alternative to the hidden Markov model (HMM) for automatic speech recognition.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 22], [23, 29], [30, 39], [40, 45], [46, 47], [47, 49], [49, 50], [50, 53], [53, 54], [55, 57], [58, 60], [61, 72], [73, 75], [76, 79], [80, 86], [87, 93], [94, 99], [100, 101], [101, 104], [104, 105], [106, 109], [110, 119], [120, 126], [127, 138], [138, 139]]}
{"doc_key": "ai-test-204", "ner": [[4, 4, "organisation"], [12, 15, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 12, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "July", "2016", ",", "Nvidia", "introduced", "a", "new", "foveated", "rendering", "method", "at", "SIGGRAPH", ",", "which", "was", "claimed", "to", "be", "invisible", "to", "users", "."], "sentence-detokenized": "In July 2016, Nvidia introduced a new foveated rendering method at SIGGRAPH, which was claimed to be invisible to users.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 20], [21, 31], [32, 33], [34, 37], [38, 46], [47, 56], [57, 63], [64, 66], [67, 75], [75, 76], [77, 82], [83, 86], [87, 94], [95, 97], [98, 100], [101, 110], [111, 113], [114, 119], [119, 120]]}
{"doc_key": "ai-test-205", "ner": [[4, 15, "misc"], [10, 11, "researcher"], [18, 19, "researcher"], [21, 21, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 15, 10, 11, "origin", "", false, false], [4, 15, 18, 19, "origin", "", false, false], [4, 15, 21, 21, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Both", "are", "based", "on", "the", "speech", "act", "theory", "developed", "by", "John", "Searle", "in", "the", "1960s", "and", "developed", "by", "Terry", "Winograd", "and", "Flores", "in", "the", "1970s", "."], "sentence-detokenized": "Both are based on the speech act theory developed by John Searle in the 1960s and developed by Terry Winograd and Flores in the 1970s.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 17], [18, 21], [22, 28], [29, 32], [33, 39], [40, 49], [50, 52], [53, 57], [58, 64], [65, 67], [68, 71], [72, 77], [78, 81], [82, 91], [92, 94], [95, 100], [101, 109], [110, 113], [114, 120], [121, 123], [124, 127], [128, 133], [133, 134]]}
{"doc_key": "ai-test-206", "ner": [[0, 3, "algorithm"], [21, 21, "researcher"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 21, 21, "related-to", "", false, false], [24, 24, 21, 21, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Neural", "network", "models", "of", "concept", "formation", "and", "knowledge", "structure", "have", "opened", "up", "powerful", "hierarchical", "models", "of", "knowledge", "organisation", ",", "such", "as", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "Neural network models of concept formation and knowledge structure have opened up powerful hierarchical models of knowledge organisation, such as George Miller's Wordnet.", "token2charspan": [[0, 6], [7, 14], [15, 21], [22, 24], [25, 32], [33, 42], [43, 46], [47, 56], [57, 66], [67, 71], [72, 78], [79, 81], [82, 90], [91, 103], [104, 110], [111, 113], [114, 123], [124, 136], [136, 137], [138, 142], [143, 145], [146, 152], [153, 159], [159, 161], [162, 169], [169, 170]]}
{"doc_key": "ai-test-207", "ner": [[0, 1, "algorithm"], [12, 14, "field"], [17, 19, "product"], [22, 24, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 12, 14, "part-of", "", false, false], [0, 1, 22, 24, "part-of", "", false, false], [17, 19, 12, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Model", "matching", "has", "many", "applications", "and", "is", "used", ",", "for", "example", ",", "in", "face", "recognition", "(", "see", "facial", "recognition", "system", ")", "and", "medical", "image", "processing", "."], "sentence-detokenized": "Model matching has many applications and is used, for example, in face recognition (see facial recognition system) and medical image processing.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 23], [24, 36], [37, 40], [41, 43], [44, 48], [48, 49], [50, 53], [54, 61], [61, 62], [63, 65], [66, 70], [71, 82], [83, 84], [84, 87], [88, 94], [95, 106], [107, 113], [113, 114], [115, 118], [119, 126], [127, 132], [133, 143], [143, 144]]}
{"doc_key": "ai-test-208", "ner": [[15, 16, "researcher"], [18, 21, "researcher"], [22, 31, "organisation"], [26, 33, "organisation"], [39, 39, "algorithm"], [44, 50, "conference"], [40, 42, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 16, 22, 31, "role", "", false, false], [15, 16, 44, 50, "physical", "", false, false], [15, 16, 44, 50, "temporal", "", false, false], [15, 16, 40, 42, "physical", "", false, false], [18, 21, 22, 31, "role", "", false, false], [18, 21, 44, 50, "temporal", "", false, false], [26, 33, 22, 31, "named", "", false, false], [44, 50, 39, 39, "topic", "", false, false], [40, 42, 44, 50, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["However", ",", "it", "was", "only", "in", "2005", "that", "their", "use", "became", "widespread", ",", "when", "researchers", "Navneet", "Dalal", "and", "Bill", "Triggs", "of", "the", "French", "National", "Institute", "for", "Research", "in", "Computer", "Science", "and", "Automation", "(", "INRIA", ")", "presented", "further", "work", "on", "HOGs", "at", "the", "CVPR", "(", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ")", "."], "sentence-detokenized": "However, it was only in 2005 that their use became widespread, when researchers Navneet Dalal and Bill Triggs of the French National Institute for Research in Computer Science and Automation (INRIA) presented further work on HOGs at the CVPR (Conference on Computer Vision and Pattern Recognition).", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 15], [16, 20], [21, 23], [24, 28], [29, 33], [34, 39], [40, 43], [44, 50], [51, 61], [61, 62], [63, 67], [68, 79], [80, 87], [88, 93], [94, 97], [98, 102], [103, 109], [110, 112], [113, 116], [117, 123], [124, 132], [133, 142], [143, 146], [147, 155], [156, 158], [159, 167], [168, 175], [176, 179], [180, 190], [191, 192], [192, 197], [197, 198], [199, 208], [209, 216], [217, 221], [222, 224], [225, 229], [230, 232], [233, 236], [237, 241], [242, 243], [243, 253], [254, 256], [257, 265], [266, 272], [273, 276], [277, 284], [285, 296], [296, 297], [297, 298]]}
{"doc_key": "ai-test-209", "ner": [[3, 3, "university"], [15, 18, "organisation"], [20, 21, "organisation"], [34, 36, "researcher"], [38, 41, "researcher"], [43, 45, "researcher"], [48, 51, "organisation"], [55, 57, "organisation"], [60, 61, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9], "relations": [[34, 36, 20, 21, "physical", "", false, false], [34, 36, 20, 21, "role", "", false, false], [38, 41, 20, 21, "physical", "", false, false], [38, 41, 20, 21, "role", "", false, false], [43, 45, 20, 21, "physical", "", false, false], [43, 45, 20, 21, "role", "", false, false], [60, 61, 55, 57, "role", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "sentence": ["Before", "joining", "the", "Penn", "faculty", "in", "2002", ",", "he", "spent", "a", "decade", "(", "1991-2001", ")", "at", "AT", "&T", "Labs", "and", "Bell", "Labs", ",", "including", "leading", "the", "Artificial", "Intelligence", "Division", ",", "where", "he", "worked", "with", "Michael", "L.", "Littman", ",", "David", "A", ".", "McAllester", "and", "Richard", "S.", "Sutton", ",", "the", "Secure", "Systems", "Research", "Division", ",", "and", "the", "Machine", "Learning", "Division", "(", "including", "Michael", "Collins", "and", "the", "Director", ")", "."], "sentence-detokenized": "Before joining the Penn faculty in 2002, he spent a decade (1991-2001) at AT&T Labs and Bell Labs, including leading the Artificial Intelligence Division, where he worked with Michael L. Littman, David A. McAllester and Richard S. Sutton, the Secure Systems Research Division, and the Machine Learning Division (including Michael Collins and the Director).", "token2charspan": [[0, 6], [7, 14], [15, 18], [19, 23], [24, 31], [32, 34], [35, 39], [39, 40], [41, 43], [44, 49], [50, 51], [52, 58], [59, 60], [60, 69], [69, 70], [71, 73], [74, 76], [76, 78], [79, 83], [84, 87], [88, 92], [93, 97], [97, 98], [99, 108], [109, 116], [117, 120], [121, 131], [132, 144], [145, 153], [153, 154], [155, 160], [161, 163], [164, 170], [171, 175], [176, 183], [184, 186], [187, 194], [194, 195], [196, 201], [202, 203], [203, 204], [205, 215], [216, 219], [220, 227], [228, 230], [231, 237], [237, 238], [239, 242], [243, 249], [250, 257], [258, 266], [267, 275], [275, 276], [277, 280], [281, 284], [285, 292], [293, 301], [302, 310], [311, 312], [312, 321], [322, 329], [330, 337], [338, 341], [342, 345], [346, 354], [354, 355], [355, 356]]}
{"doc_key": "ai-test-210", "ner": [[6, 8, "field"], [14, 14, "field"], [25, 26, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 8, 14, 14, "compare", "", false, false], [25, 26, 14, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["When", "the", "data", "is", "unlabeled", ",", "supervised", "learning", "is", "not", "possible", ",", "but", "an", "unsupervised", "learning", "method", "is", "needed", ",", "which", "tries", "to", "find", "natural", "cluster", "analyses", "for", "groups", "and", "then", "map", "new", "data", "into", "these", "formed", "groups", "."], "sentence-detokenized": "When the data is unlabeled, supervised learning is not possible, but an unsupervised learning method is needed, which tries to find natural cluster analyses for groups and then map new data into these formed groups.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 16], [17, 26], [26, 27], [28, 38], [39, 47], [48, 50], [51, 54], [55, 63], [63, 64], [65, 68], [69, 71], [72, 84], [85, 93], [94, 100], [101, 103], [104, 110], [110, 111], [112, 117], [118, 123], [124, 126], [127, 131], [132, 139], [140, 147], [148, 156], [157, 160], [161, 167], [168, 171], [172, 176], [177, 180], [181, 184], [185, 189], [190, 194], [195, 200], [201, 207], [208, 214], [214, 215]]}
{"doc_key": "ai-test-211", "ner": [[3, 4, "field"], [14, 18, "organisation"], [25, 26, "field"], [28, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 14, 18, "origin", "", false, false], [3, 4, 25, 26, "part-of", "", false, false], [3, 4, 28, 28, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "field", "of", "computer", "science", "developed", "in", "the", "1950s", "in", "academic", "institutions", "such", "as", "MIT", "'s", "A.I", ".", "Lab", ",", "initially", "as", "a", "branch", "of", "artificial", "intelligence", "and", "robotics", "."], "sentence-detokenized": "This field of computer science developed in the 1950s in academic institutions such as MIT's A.I. Lab, initially as a branch of artificial intelligence and robotics.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 22], [23, 30], [31, 40], [41, 43], [44, 47], [48, 53], [54, 56], [57, 65], [66, 78], [79, 83], [84, 86], [87, 90], [90, 92], [93, 96], [96, 97], [98, 101], [101, 102], [103, 112], [113, 115], [116, 117], [118, 124], [125, 127], [128, 138], [139, 151], [152, 155], [156, 164], [164, 165]]}
{"doc_key": "ai-test-212", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "can", "also", "be", "replaced", "by", "the", "log", "-", "loss", "equation", "below", ":"], "sentence-detokenized": "It can also be replaced by the log-loss equation below:", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 23], [24, 26], [27, 30], [31, 34], [34, 35], [35, 39], [40, 48], [49, 54], [54, 55]]}
{"doc_key": "ai-test-213", "ner": [[0, 2, "organisation"], [5, 9, "organisation"], [13, 17, "university"], [19, 19, "university"], [21, 22, "university"], [25, 27, "university"], [28, 30, "country"], [35, 35, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 2, 35, 35, "related-to", "research_leader_in_field", false, false], [5, 9, 0, 2, "named", "", false, false], [5, 9, 35, 35, "related-to", "research_leader_in_field", false, false], [13, 17, 35, 35, "related-to", "research_leader_in_field", false, false], [19, 19, 35, 35, "related-to", "research_leader_in_field", false, false], [21, 22, 35, 35, "related-to", "research_leader_in_field", false, false], [25, 27, 28, 30, "physical", "", false, false], [25, 27, 35, 35, "related-to", "research_leader_in_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Shirley", "Ryan", "AbilityLab", "(", "formerly", "the", "Chicago", "Institute", "of", "Rehabilitation", ")", ",", "the", "University", "of", "California", "at", "Berkeley", ",", "MIT", ",", "Stanford", "University", "and", "the", "University", "of", "Twente", "in", "the", "Netherlands", "are", "leading", "players", "in", "biomechatronics", "research", "."], "sentence-detokenized": "Shirley Ryan AbilityLab (formerly the Chicago Institute of Rehabilitation), the University of California at Berkeley, MIT, Stanford University and the University of Twente in the Netherlands are leading players in biomechatronics research.", "token2charspan": [[0, 7], [8, 12], [13, 23], [24, 25], [25, 33], [34, 37], [38, 45], [46, 55], [56, 58], [59, 73], [73, 74], [74, 75], [76, 79], [80, 90], [91, 93], [94, 104], [105, 107], [108, 116], [116, 117], [118, 121], [121, 122], [123, 131], [132, 142], [143, 146], [147, 150], [151, 161], [162, 164], [165, 171], [172, 174], [175, 178], [179, 190], [191, 194], [195, 202], [203, 210], [211, 213], [214, 229], [230, 238], [238, 239]]}
{"doc_key": "ai-test-214", "ner": [[27, 34, "metrics"], [45, 45, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Given", "a", "set", "of", "predicted", "values", "and", "a", "corresponding", "set", "of", "actual", "values", "of", "X", "for", "different", "time", "periods", ",", "a", "common", "estimation", "technique", "is", "to", "use", "the", "mean", "squared", "value", "of", "the", "prediction", "error", ";", "other", "measures", "are", "available", "(", "see", "prediction", "#", "prediction", "accuracy", ")", "."], "sentence-detokenized": "Given a set of predicted values and a corresponding set of actual values of X for different time periods, a common estimation technique is to use the mean squared value of the prediction error; other measures are available (see prediction # prediction accuracy).", "token2charspan": [[0, 5], [6, 7], [8, 11], [12, 14], [15, 24], [25, 31], [32, 35], [36, 37], [38, 51], [52, 55], [56, 58], [59, 65], [66, 72], [73, 75], [76, 77], [78, 81], [82, 91], [92, 96], [97, 104], [104, 105], [106, 107], [108, 114], [115, 125], [126, 135], [136, 138], [139, 141], [142, 145], [146, 149], [150, 154], [155, 162], [163, 168], [169, 171], [172, 175], [176, 186], [187, 192], [192, 193], [194, 199], [200, 208], [209, 212], [213, 222], [223, 224], [224, 227], [228, 238], [239, 240], [241, 251], [252, 260], [260, 261], [261, 262]]}
{"doc_key": "ai-test-215", "ner": [[13, 16, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "measures", ",", "such", "as", "the", "proportion", "of", "correct", "predictions", "(", "also", "called", "accuracy", ")", ",", "are", "not", "useful", "when", "the", "two", "categories", "are", "of", "very", "different", "sizes", "."], "sentence-detokenized": "Other measures, such as the proportion of correct predictions (also called accuracy), are not useful when the two categories are of very different sizes.", "token2charspan": [[0, 5], [6, 14], [14, 15], [16, 20], [21, 23], [24, 27], [28, 38], [39, 41], [42, 49], [50, 61], [62, 63], [63, 67], [68, 74], [75, 83], [83, 84], [84, 85], [86, 89], [90, 93], [94, 100], [101, 105], [106, 109], [110, 113], [114, 124], [125, 128], [129, 131], [132, 136], [137, 146], [147, 152], [152, 153]]}
{"doc_key": "ai-test-216", "ner": [[5, 5, "product"], [13, 19, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 13, 19, "temporal", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "first", "alpha", "version", "of", "OpenCV", "was", "released", "to", "the", "public", "at", "the", "Computer", "Vision", "and", "Pattern", "Recognition", "Conference", "in", "2000", ",", "and", "five", "beta", "versions", "were", "released", "between", "2001", "and", "2005", "."], "sentence-detokenized": "The first alpha version of OpenCV was released to the public at the Computer Vision and Pattern Recognition Conference in 2000, and five beta versions were released between 2001 and 2005.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 23], [24, 26], [27, 33], [34, 37], [38, 46], [47, 49], [50, 53], [54, 60], [61, 63], [64, 67], [68, 76], [77, 83], [84, 87], [88, 95], [96, 107], [108, 118], [119, 121], [122, 126], [126, 127], [128, 131], [132, 136], [137, 141], [142, 150], [151, 155], [156, 164], [165, 172], [173, 177], [178, 181], [182, 186], [186, 187]]}
{"doc_key": "ai-test-217", "ner": [[24, 25, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["According", "to", "the", "results", "presented", ",", "the", "correlation", "with", "people", "'s", "estimates", "is", "as", "high", "as", "0.964", "at", "the", "corpus", "level", ",", "while", "the", "BLEU", "value", "is", "0.817", "for", "the", "same", "data", "."], "sentence-detokenized": "According to the results presented, the correlation with people's estimates is as high as 0.964 at the corpus level, while the BLEU value is 0.817 for the same data.", "token2charspan": [[0, 9], [10, 12], [13, 16], [17, 24], [25, 34], [34, 35], [36, 39], [40, 51], [52, 56], [57, 63], [63, 65], [66, 75], [76, 78], [79, 81], [82, 86], [87, 89], [90, 95], [96, 98], [99, 102], [103, 109], [110, 115], [115, 116], [117, 122], [123, 126], [127, 131], [132, 137], [138, 140], [141, 146], [147, 150], [151, 154], [155, 159], [160, 164], [164, 165]]}
{"doc_key": "ai-test-218", "ner": [[4, 4, "metrics"], [20, 20, "metrics"], [22, 24, "metrics"], [26, 30, "metrics"], [31, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 20, 20, "compare", "", false, false], [4, 4, 22, 24, "compare", "", false, false], [4, 4, 26, 30, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["An", "early", "version", "of", "VMAF", "has", "been", "shown", "to", "outperform", "other", "measures", "of", "image", "and", "video", "quality", ",", "such", "as", "SSIM", ",", "PSNR", "-", "HVS", "and", "VQM", "-", "VFD", ",", "in", "predictive", "accuracy", "on", "three", "out", "of", "four", "datasets", "when", "compared", "to", "subjective", "ratings", "."], "sentence-detokenized": "An early version of VMAF has been shown to outperform other measures of image and video quality, such as SSIM, PSNR -HVS and VQM-VFD, in predictive accuracy on three out of four datasets when compared to subjective ratings.", "token2charspan": [[0, 2], [3, 8], [9, 16], [17, 19], [20, 24], [25, 28], [29, 33], [34, 39], [40, 42], [43, 53], [54, 59], [60, 68], [69, 71], [72, 77], [78, 81], [82, 87], [88, 95], [95, 96], [97, 101], [102, 104], [105, 109], [109, 110], [111, 115], [116, 117], [117, 120], [121, 124], [125, 128], [128, 129], [129, 132], [132, 133], [134, 136], [137, 147], [148, 156], [157, 159], [160, 165], [166, 169], [170, 172], [173, 177], [178, 186], [187, 191], [192, 200], [201, 203], [204, 214], [215, 222], [222, 223]]}
{"doc_key": "ai-test-219", "ner": [[20, 21, "task"], [27, 29, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[20, 21, 27, 29, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["For", "example", ",", "the", "ambiguity", "of", "the", "word", "\"", "mouse", "\"", "(", "animal", "or", "device", ")", "is", "not", "relevant", "for", "machine", "translation", ",", "but", "it", "is", "relevant", "for", "information", "retrieval", "."], "sentence-detokenized": "For example, the ambiguity of the word \"mouse\" (animal or device) is not relevant for machine translation, but it is relevant for information retrieval.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 26], [27, 29], [30, 33], [34, 38], [39, 40], [40, 45], [45, 46], [47, 48], [48, 54], [55, 57], [58, 64], [64, 65], [66, 68], [69, 72], [73, 81], [82, 85], [86, 93], [94, 105], [105, 106], [107, 110], [111, 113], [114, 116], [117, 125], [126, 129], [130, 141], [142, 151], [151, 152]]}
{"doc_key": "ai-test-220", "ner": [[0, 1, "algorithm"], [9, 10, "field"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 1, "usage", "", false, false], [11, 12, 9, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Geometric", "fiddling", "was", "originally", "proposed", "in", "the", "field", "of", "computer", "vision", "to", "identify", "2D", "and", "3D", "objects", ","], "sentence-detokenized": "Geometric fiddling was originally proposed in the field of computer vision to identify 2D and 3D objects,", "token2charspan": [[0, 9], [10, 18], [19, 22], [23, 33], [34, 42], [43, 45], [46, 49], [50, 55], [56, 58], [59, 67], [68, 74], [75, 77], [78, 86], [87, 89], [90, 93], [94, 96], [97, 104], [104, 105]]}
{"doc_key": "ai-test-221", "ner": [[0, 10, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 15, 0, 10, "part-of", "subfield", false, false], [17, 18, 0, 10, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "is", "one", "of", "the", "three", "main", "categories", "of", "machine", "learning", ",", "along", "with", "supervised", "learning", "and", "reinforcement", "learning", "."], "sentence-detokenized": "It is one of the three main categories of machine learning, along with supervised learning and reinforcement learning.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 12], [13, 16], [17, 22], [23, 27], [28, 38], [39, 41], [42, 49], [50, 58], [58, 59], [60, 65], [66, 70], [71, 81], [82, 90], [91, 94], [95, 108], [109, 117], [117, 118]]}
{"doc_key": "ai-test-222", "ner": [[5, 6, "field"], [16, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 25, "field"], [27, 30, "field"], [32, 33, "field"], [35, 36, "field"], [38, 38, "field"], [40, 41, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[5, 6, 16, 16, "part-of", "subfield", false, false], [5, 6, 18, 19, "part-of", "subfield", false, false], [5, 6, 21, 22, "part-of", "subfield", false, false], [5, 6, 24, 25, "part-of", "subfield", false, false], [5, 6, 27, 30, "part-of", "subfield", false, false], [5, 6, 32, 33, "part-of", "subfield", false, false], [5, 6, 35, 36, "part-of", "subfield", false, false], [5, 6, 38, 38, "part-of", "subfield", false, false], [5, 6, 40, 41, "part-of", "subfield", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Because", "of", "its", "generality", ",", "reinforcement", "learning", "is", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "game", "and", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimization", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Because of its generality, reinforcement learning is studied in many other disciplines, such as game and control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 25], [25, 26], [27, 40], [41, 49], [50, 52], [53, 60], [61, 63], [64, 68], [69, 74], [75, 86], [86, 87], [88, 92], [93, 95], [96, 100], [101, 104], [105, 112], [113, 119], [119, 120], [121, 131], [132, 140], [140, 141], [142, 153], [154, 160], [160, 161], [162, 172], [172, 173], [173, 178], [179, 191], [191, 192], [193, 204], [205, 212], [212, 213], [214, 219], [220, 232], [232, 233], [234, 244], [245, 248], [249, 256], [257, 267], [267, 268]]}
{"doc_key": "ai-test-223", "ner": [[0, 2, "field"], [6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 7, "related-to", "", false, false], [0, 2, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Pattern", "recognition", "is", "closely", "related", "to", "artificial", "intelligence", "and", "machine", "learning", ","], "sentence-detokenized": "Pattern recognition is closely related to artificial intelligence and machine learning,", "token2charspan": [[0, 7], [8, 19], [20, 22], [23, 30], [31, 38], [39, 41], [42, 52], [53, 65], [66, 69], [70, 77], [78, 86], [86, 87]]}
{"doc_key": "ai-test-224", "ner": [[14, 15, "field"], [17, 18, "field"], [29, 30, "task"], [32, 32, "task"], [34, 35, "task"], [37, 38, "algorithm"], [40, 42, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "software", "is", "used", "to", "design", ",", "train", "and", "deploy", "neural", "network", "models", "(", "supervised", "learning", "and", "unsupervised", "learning", ")", "to", "perform", "a", "wide", "range", "of", "tasks", "such", "as", "data", "mining", ",", "classification", ",", "function", "approximation", ",", "multivariate", "regression", "and", "time", "series", "prediction", "."], "sentence-detokenized": "The software is used to design, train and deploy neural network models (supervised learning and unsupervised learning) to perform a wide range of tasks such as data mining, classification, function approximation, multivariate regression and time series prediction.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 20], [21, 23], [24, 30], [30, 31], [32, 37], [38, 41], [42, 48], [49, 55], [56, 63], [64, 70], [71, 72], [72, 82], [83, 91], [92, 95], [96, 108], [109, 117], [117, 118], [119, 121], [122, 129], [130, 131], [132, 136], [137, 142], [143, 145], [146, 151], [152, 156], [157, 159], [160, 164], [165, 171], [171, 172], [173, 187], [187, 188], [189, 197], [198, 211], [211, 212], [213, 225], [226, 236], [237, 240], [241, 245], [246, 252], [253, 263], [263, 264]]}
{"doc_key": "ai-test-225", "ner": [[9, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2016", ",", "he", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2016, he was elected a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [98, 99]]}
{"doc_key": "ai-test-226", "ner": [[6, 9, "organisation"], [16, 21, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", "(", "since", "2005", ")", "and", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "(", "since", "2009", ")", ","], "sentence-detokenized": "He is a member of the National Academy of Sciences (since 2005) and the American Academy of Arts and Sciences (since 2009),", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 38], [39, 41], [42, 50], [51, 52], [52, 57], [58, 62], [62, 63], [64, 67], [68, 71], [72, 80], [81, 88], [89, 91], [92, 96], [97, 100], [101, 109], [110, 111], [111, 116], [117, 121], [121, 122], [122, 123]]}
{"doc_key": "ai-test-227", "ner": [[0, 5, "misc"], [17, 17, "country"], [19, 19, "country"], [24, 25, "misc"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["During", "the", "1973", "Yom", "Kippur", "War", ",", "Soviet", "-supplied", "surface", "-", "to", "-", "air", "missile", "batteries", "from", "Egypt", "and", "Syria", "caused", "heavy", "damage", "to", "Israeli", "fighters", "."], "sentence-detokenized": "During the 1973 Yom Kippur War, Soviet-supplied surface-to-air missile batteries from Egypt and Syria caused heavy damage to Israeli fighters.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 19], [20, 26], [27, 30], [30, 31], [32, 38], [38, 47], [48, 55], [55, 56], [56, 58], [58, 59], [59, 62], [63, 70], [71, 80], [81, 85], [86, 91], [92, 95], [96, 101], [102, 108], [109, 114], [115, 121], [122, 124], [125, 132], [133, 141], [141, 142]]}
{"doc_key": "ai-test-228", "ner": [[9, 10, "product"], [15, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 16, 9, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Another", "resource", "(", "free", "but", "copyrighted", ")", "is", "the", "HTK", "book", "(", "and", "the", "accompanying", "HTK", "toolkit", ")", "."], "sentence-detokenized": "Another resource (free but copyrighted) is the HTK book (and the accompanying HTK toolkit).", "token2charspan": [[0, 7], [8, 16], [17, 18], [18, 22], [23, 26], [27, 38], [38, 39], [40, 42], [43, 46], [47, 50], [51, 55], [56, 57], [57, 60], [61, 64], [65, 77], [78, 81], [82, 89], [89, 90], [90, 91]]}
{"doc_key": "ai-test-229", "ner": [[5, 8, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["-", "was", "taken", "up", "in", "2004", "at", "the", "AAAI", "Spring", "Symposium", ",", "where", "linguists", ",", "computer", "scientists", "and", "other", "interested", "researchers", "for", "the", "first", "time", "coordinated", "their", "interests", "and", "proposed", "common", "tasks", "and", "reference", "data", "sets", "for", "systematic", "computational", "research", "on", "text", "effects", ",", "appeal", ",", "subjectivity", "and", "emotion", "."], "sentence-detokenized": "- was taken up in 2004 at the AAAI Spring Symposium, where linguists, computer scientists and other interested researchers for the first time coordinated their interests and proposed common tasks and reference data sets for systematic computational research on text effects, appeal, subjectivity and emotion.", "token2charspan": [[0, 1], [2, 5], [6, 11], [12, 14], [15, 17], [18, 22], [23, 25], [26, 29], [30, 34], [35, 41], [42, 51], [51, 52], [53, 58], [59, 68], [68, 69], [70, 78], [79, 89], [90, 93], [94, 99], [100, 110], [111, 122], [123, 126], [127, 130], [131, 136], [137, 141], [142, 153], [154, 159], [160, 169], [170, 173], [174, 182], [183, 189], [190, 195], [196, 199], [200, 209], [210, 214], [215, 219], [220, 223], [224, 234], [235, 248], [249, 257], [258, 260], [261, 265], [266, 273], [273, 274], [275, 281], [281, 282], [283, 295], [296, 299], [300, 307], [307, 308]]}
{"doc_key": "ai-test-230", "ner": [[3, 4, "task"], [9, 10, "task"], [12, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "content", "(", "visual", "inspection", ")", "and", "structure", "(", "cluster", "analysis", ",", "principal", "component", "analysis", "and", "various", "structural", "indices", "related", "to", "the", "complexity", "and", "scope", "of", "the", "classifications", "are", "the", "main", "techniques", "used", ")", "of", "a", "single", "grid", "can", "be", "analysed", "."], "sentence-detokenized": "The content (visual inspection) and structure (cluster analysis, principal component analysis and various structural indices related to the complexity and scope of the classifications are the main techniques used) of a single grid can be analysed.", "token2charspan": [[0, 3], [4, 11], [12, 13], [13, 19], [20, 30], [30, 31], [32, 35], [36, 45], [46, 47], [47, 54], [55, 63], [63, 64], [65, 74], [75, 84], [85, 93], [94, 97], [98, 105], [106, 116], [117, 124], [125, 132], [133, 135], [136, 139], [140, 150], [151, 154], [155, 160], [161, 163], [164, 167], [168, 183], [184, 187], [188, 191], [192, 196], [197, 207], [208, 212], [212, 213], [214, 216], [217, 218], [219, 225], [226, 230], [231, 234], [235, 237], [238, 246], [246, 247]]}
{"doc_key": "ai-test-231", "ner": [[3, 3, "organisation"], [13, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2018", ",", "Toyota", "was", "seen", "as", "lagging", "behind", "in", "the", "development", "of", "self", "-", "driving", "cars", "and", "in", "need", "of", "innovation", "."], "sentence-detokenized": "In 2018, Toyota was seen as lagging behind in the development of self-driving cars and in need of innovation.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 24], [25, 27], [28, 35], [36, 42], [43, 45], [46, 49], [50, 61], [62, 64], [65, 69], [69, 70], [70, 77], [78, 82], [83, 86], [87, 89], [90, 94], [95, 97], [98, 108], [108, 109]]}
{"doc_key": "ai-test-232", "ner": [[37, 38, "misc"], [40, 41, "misc"], [43, 45, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "include", "natural", "objects", "such", "as", "land", ",", "sea", ",", "rain", "(", "such", "as", "rain", ",", "snow", "or", "hail", ")", ",", "sandstorms", ",", "animals", "(", "especially", "birds", ")", ",", "atmospheric", "turbulence", "and", "other", "atmospheric", "effects", "such", "as", "ionospheric", "reflections", ",", "meteor", "trails", "and", "triple", "scattering", "spikes", "."], "sentence-detokenized": "These include natural objects such as land, sea, rain (such as rain, snow or hail), sandstorms, animals (especially birds), atmospheric turbulence and other atmospheric effects such as ionospheric reflections, meteor trails and triple scattering spikes.", "token2charspan": [[0, 5], [6, 13], [14, 21], [22, 29], [30, 34], [35, 37], [38, 42], [42, 43], [44, 47], [47, 48], [49, 53], [54, 55], [55, 59], [60, 62], [63, 67], [67, 68], [69, 73], [74, 76], [77, 81], [81, 82], [82, 83], [84, 94], [94, 95], [96, 103], [104, 105], [105, 115], [116, 121], [121, 122], [122, 123], [124, 135], [136, 146], [147, 150], [151, 156], [157, 168], [169, 176], [177, 181], [182, 184], [185, 196], [197, 208], [208, 209], [210, 216], [217, 223], [224, 227], [228, 234], [235, 245], [246, 252], [252, 253]]}
{"doc_key": "ai-test-233", "ner": [[40, 41, "misc"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "terms", "of", "design", "and", "control", ",", "the", "essential", "difference", "between", "humanoids", "and", "other", "types", "of", "robots", "(", "such", "as", "industrial", "robots", ")", "is", "that", "the", "robot", "'s", "movements", "must", "be", "human", "-", "like", ",", "using", "leg", "movements", ",", "especially", "bipedal", "walking", "."], "sentence-detokenized": "In terms of design and control, the essential difference between humanoids and other types of robots (such as industrial robots) is that the robot's movements must be human-like, using leg movements, especially bipedal walking.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 18], [19, 22], [23, 30], [30, 31], [32, 35], [36, 45], [46, 56], [57, 64], [65, 74], [75, 78], [79, 84], [85, 90], [91, 93], [94, 100], [101, 102], [102, 106], [107, 109], [110, 120], [121, 127], [127, 128], [129, 131], [132, 136], [137, 140], [141, 146], [146, 148], [149, 158], [159, 163], [164, 166], [167, 172], [172, 173], [173, 177], [177, 178], [179, 184], [185, 188], [189, 198], [198, 199], [200, 210], [211, 218], [219, 226], [226, 227]]}
{"doc_key": "ai-test-234", "ner": [[0, 1, "algorithm"], [8, 11, "misc"], [14, 14, "metrics"], [17, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Gradient", "descent", "can", "take", "several", "iterations", "to", "calculate", "the", "local", "minimum", "with", "the", "required", "accuracy", "if", "the", "curvature", "of", "the", "different", "directions", "is", "very", "different", "for", "the", "function", "in", "question", "."], "sentence-detokenized": "Gradient descent can take several iterations to calculate the local minimum with the required accuracy if the curvature of the different directions is very different for the function in question.", "token2charspan": [[0, 8], [9, 16], [17, 20], [21, 25], [26, 33], [34, 44], [45, 47], [48, 57], [58, 61], [62, 67], [68, 75], [76, 80], [81, 84], [85, 93], [94, 102], [103, 105], [106, 109], [110, 119], [120, 122], [123, 126], [127, 136], [137, 147], [148, 150], [151, 155], [156, 165], [166, 169], [170, 173], [174, 182], [183, 185], [186, 194], [194, 195]]}
{"doc_key": "ai-test-235", "ner": [[1, 6, "misc"], [15, 25, "conference"], [26, 26, "location"], [28, 29, "country"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[15, 25, 26, 26, "physical", "", false, true], [26, 26, 28, 29, "physical", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["The", "1997", "RoboCup", "2D", "Soccer", "Simulation", "League", "was", "the", "first", "RoboCup", "competition", "to", "be", "held", "in", "conjunction", "with", "the", "International", "Joint", "Conference", "on", "Artificial", "Intelligence", "in", "Nagoya", ",", "Japan", "from", "23", "-", "29", "August", "1997", "."], "sentence-detokenized": "The 1997 RoboCup 2D Soccer Simulation League was the first RoboCup competition to be held in conjunction with the International Joint Conference on Artificial Intelligence in Nagoya, Japan from 23-29 August 1997.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 19], [20, 26], [27, 37], [38, 44], [45, 48], [49, 52], [53, 58], [59, 66], [67, 78], [79, 81], [82, 84], [85, 89], [90, 92], [93, 104], [105, 109], [110, 113], [114, 127], [128, 133], [134, 144], [145, 147], [148, 158], [159, 171], [172, 174], [175, 181], [181, 182], [183, 188], [189, 193], [194, 196], [196, 197], [197, 199], [200, 206], [207, 211], [211, 212]]}
{"doc_key": "ai-test-236", "ner": [[15, 15, "product"]], "ner_mapping_to_source": [2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "options", "include", "an", "embedded", "Python", "environment", "and", "R", "console", ",", "and", "support", "for", "Rserve", "."], "sentence-detokenized": "Other programming options include an embedded Python environment and R console, and support for Rserve.", "token2charspan": [[0, 5], [6, 17], [18, 25], [26, 33], [34, 36], [37, 45], [46, 52], [53, 64], [65, 68], [69, 70], [71, 78], [78, 79], [80, 83], [84, 91], [92, 95], [96, 102], [102, 103]]}
{"doc_key": "ai-test-237", "ner": [[1, 1, "location"], [11, 12, "field"], [14, 14, "field"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [27, 28, "field"], [31, 32, "field"], [35, 36, "field"], [39, 40, "field"], [43, 46, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[17, 18, 14, 14, "related-to", "contributes_to_field", true, false], [20, 21, 14, 14, "related-to", "contributes_to_field", true, false], [23, 24, 14, 14, "related-to", "contributes_to_field", true, false], [35, 36, 31, 32, "part-of", "", false, false], [39, 40, 35, 36, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["From", "Bonn", ",", "he", "has", "been", "instrumental", "in", "the", "development", "of", "artificial", "intelligence", "and", "robotics", "(", "with", "Wolfram", "Burgard", ",", "Dieter", "Fox", "and", "Sebastian", "Thrun", ")", ",", "software", "engineering", ",", "especially", "civil", "engineering", ",", "and", "information", "systems", ",", "especially", "geosciences", ".", "won", "the", "AAAI", "Classic", "Paper", "Award", "2016.2014", "."], "sentence-detokenized": "From Bonn, he has been instrumental in the development of artificial intelligence and robotics (with Wolfram Burgard, Dieter Fox and Sebastian Thrun), software engineering, especially civil engineering, and information systems, especially geosciences. won the AAAI Classic Paper Award 2016.2014.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 13], [14, 17], [18, 22], [23, 35], [36, 38], [39, 42], [43, 54], [55, 57], [58, 68], [69, 81], [82, 85], [86, 94], [95, 96], [96, 100], [101, 108], [109, 116], [116, 117], [118, 124], [125, 128], [129, 132], [133, 142], [143, 148], [148, 149], [149, 150], [151, 159], [160, 171], [171, 172], [173, 183], [184, 189], [190, 201], [201, 202], [203, 206], [207, 218], [219, 226], [226, 227], [228, 238], [239, 250], [250, 251], [252, 255], [256, 259], [260, 264], [265, 272], [273, 278], [279, 284], [285, 294], [294, 295]]}
{"doc_key": "ai-test-238", "ner": [[2, 4, "conference"], [13, 16, "location"], [17, 18, "location"], [20, 20, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 4, 13, 16, "physical", "", false, false], [13, 16, 17, 18, "physical", "", false, false], [17, 18, 20, 20, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "first", "US", "Campus", "Party", "will", "take", "place", "on", "20", "-", "22", "August", "at", "the", "TCF", "Center", "in", "Detroit", ",", "Michigan", "."], "sentence-detokenized": "The first US Campus Party will take place on 20-22 August at the TCF Center in Detroit, Michigan.", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 25], [26, 30], [31, 35], [36, 41], [42, 44], [45, 47], [47, 48], [48, 50], [51, 57], [58, 60], [61, 64], [65, 68], [69, 75], [76, 78], [79, 86], [86, 87], [88, 96], [96, 97]]}
{"doc_key": "ai-test-239", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [0, 0, "researcher"], [13, 15, "misc"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 13, 15, "win-defeat", "", false, false], [7, 8, 13, 15, "win-defeat", "", false, false], [0, 0, 13, 15, "win-defeat", "", false, false], [13, 15, 23, 25, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Hinton", ",", "along", "with", "Yann", "LeCun", "and", "Yoshua", "Bengio", ",", "won", "the", "2018", "Turing", "Prize", "for", "conceptual", "and", "technical", "breakthroughs", "that", "have", "made", "deep", "neural", "networks", "a", "critical", "part", "of", "computing", "."], "sentence-detokenized": "Hinton, along with Yann LeCun and Yoshua Bengio, won the 2018 Turing Prize for conceptual and technical breakthroughs that have made deep neural networks a critical part of computing.", "token2charspan": [[0, 6], [6, 7], [8, 13], [14, 18], [19, 23], [24, 29], [30, 33], [34, 40], [41, 47], [47, 48], [49, 52], [53, 56], [57, 61], [62, 68], [69, 74], [75, 78], [79, 89], [90, 93], [94, 103], [104, 117], [118, 122], [123, 127], [128, 132], [133, 137], [138, 144], [145, 153], [154, 155], [156, 164], [165, 169], [170, 172], [173, 182], [182, 183]]}
{"doc_key": "ai-test-240", "ner": [[0, 3, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Euler", "Math", "Toolbox", "uses", "a", "MATLAB", "-", "like", "matrix", "language", "that", "has", "been", "developed", "since", "the", "1970s", "."], "sentence-detokenized": "The Euler Math Toolbox uses a MATLAB-like matrix language that has been developed since the 1970s.", "token2charspan": [[0, 3], [4, 9], [10, 14], [15, 22], [23, 27], [28, 29], [30, 36], [36, 37], [37, 41], [42, 48], [49, 57], [58, 62], [63, 66], [67, 71], [72, 81], [82, 87], [88, 91], [92, 97], [97, 98]]}
{"doc_key": "ai-test-241", "ner": [[7, 7, "programlang"], [9, 10, "programlang"], [12, 12, "programlang"], [14, 14, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "languages", "allow", "its", "portability", "(", "e.g.", "Scheme", ",", "Common", "Lisp", ",", "Perl", "or", "D", ")", "."], "sentence-detokenized": "Some languages allow its portability (e.g. Scheme, Common Lisp, Perl or D).", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 24], [25, 36], [37, 38], [38, 42], [43, 49], [49, 50], [51, 57], [58, 62], [62, 63], [64, 68], [69, 71], [72, 73], [73, 74], [74, 75]]}
{"doc_key": "ai-test-242", "ner": [[7, 8, "misc"], [0, 10, "researcher"], [12, 15, "researcher"], [29, 31, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 0, 10, "artifact", "", false, false], [7, 8, 12, 15, "artifact", "", false, false], [7, 8, 29, 31, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "1969", ",", "in", "the", "famous", "book", "Perceptrons", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", ",", "it", "was", "shown", "that", "it", "was", "impossible", "for", "these", "classes", "of", "networks", "to", "learn", "the", "XOR", "function", "."], "sentence-detokenized": "In 1969, in the famous book Perceptrons by Marvin Minsky and Seymour Papert, it was shown that it was impossible for these classes of networks to learn the XOR function.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 22], [23, 27], [28, 39], [40, 42], [43, 49], [50, 56], [57, 60], [61, 68], [69, 75], [75, 76], [77, 79], [80, 83], [84, 89], [90, 94], [95, 97], [98, 101], [102, 112], [113, 116], [117, 122], [123, 130], [131, 133], [134, 142], [143, 145], [146, 151], [152, 155], [156, 159], [160, 168], [168, 169]]}
{"doc_key": "ai-test-243", "ner": [[9, 13, "misc"], [0, 1, "product"], [16, 19, "organisation"], [23, 28, "organisation"], [30, 36, "location"], [37, 38, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[16, 19, 0, 1, "usage", "", false, false], [16, 19, 30, 36, "physical", "", false, false], [23, 28, 16, 19, "named", "", false, false], [30, 36, 37, 38, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SYSTRAN", "was", "used", "to", "translate", "a", "large", "number", "of", "Russian", "scientific", "and", "technical", "documents", "at", "the", "USAF", "Foreign", "Technology", "Division", "(", "later", "the", "National", "Air", "and", "Space", "Intelligence", "Center", ")", "at", "Wright", "-", "Patterson", "Air", "Force", "Base", "in", "Ohio", "."], "sentence-detokenized": "SYSTRAN was used to translate a large number of Russian scientific and technical documents at the USAF Foreign Technology Division (later the National Air and Space Intelligence Center) at Wright-Patterson Air Force Base in Ohio.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 19], [20, 29], [30, 31], [32, 37], [38, 44], [45, 47], [48, 55], [56, 66], [67, 70], [71, 80], [81, 90], [91, 93], [94, 97], [98, 102], [103, 110], [111, 121], [122, 130], [131, 132], [132, 137], [138, 141], [142, 150], [151, 154], [155, 158], [159, 164], [165, 177], [178, 184], [184, 185], [186, 188], [189, 195], [195, 196], [196, 205], [206, 209], [210, 215], [216, 220], [221, 223], [224, 228], [228, 229]]}
{"doc_key": "ai-test-244", "ner": [[0, 1, "field"], [5, 6, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Semi-supervised", "learning", "is", "situated", "between", "unsupervised", "learning", "(", "without", "marked", "training", "data", ")", "and", "supervised", "learning", "(", "with", "fully", "marked", "training", "data", ")", "."], "sentence-detokenized": "Semi-supervised learning is situated between unsupervised learning (without marked training data) and supervised learning (with fully marked training data).", "token2charspan": [[0, 15], [16, 24], [25, 27], [28, 36], [37, 44], [45, 57], [58, 66], [67, 68], [68, 75], [76, 82], [83, 91], [92, 96], [96, 97], [98, 101], [102, 112], [113, 121], [122, 123], [123, 127], [128, 133], [134, 140], [141, 149], [150, 154], [154, 155], [155, 156]]}
{"doc_key": "ai-test-245", "ner": [[0, 3, "algorithm"], [8, 10, "algorithm"], [23, 28, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 8, 10, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Ann", "grammar", "model", "is", "a", "kind", "of", "probabilistic", "language", "model", "that", "efficiently", "predicts", "the", "next", "item", "in", "such", "a", "sequence", "in", "the", "form", "of", "a", "Markov", "model", "of", "(", "n", "-", "1", ")", "order", "."], "sentence-detokenized": "The Ann grammar model is a kind of probabilistic language model that efficiently predicts the next item in such a sequence in the form of a Markov model of (n - 1) order.", "token2charspan": [[0, 3], [4, 7], [8, 15], [16, 21], [22, 24], [25, 26], [27, 31], [32, 34], [35, 48], [49, 57], [58, 63], [64, 68], [69, 80], [81, 89], [90, 93], [94, 98], [99, 103], [104, 106], [107, 111], [112, 113], [114, 122], [123, 125], [126, 129], [130, 134], [135, 137], [138, 139], [140, 146], [147, 152], [153, 155], [156, 157], [157, 158], [159, 160], [161, 162], [162, 163], [164, 169], [169, 170]]}
{"doc_key": "ai-test-246", "ner": [[0, 2, "organisation"], [5, 5, "product"], [8, 15, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 5, 5, "usage", "", false, false], [8, 15, 0, 2, "origin", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "Cleveland", "Clinic", "has", "used", "Cyc", "to", "develop", "a", "natural", "language", "query", "interface", "for", "biomedical", "data", ",", "covering", "decades", "of", "data", "on", "cardiac", "and", "thoracic", "surgery", "."], "sentence-detokenized": "The Cleveland Clinic has used Cyc to develop a natural language query interface for biomedical data, covering decades of data on cardiac and thoracic surgery.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 24], [25, 29], [30, 33], [34, 36], [37, 44], [45, 46], [47, 54], [55, 63], [64, 69], [70, 79], [80, 83], [84, 94], [95, 99], [99, 100], [101, 109], [110, 117], [118, 120], [121, 125], [126, 128], [129, 136], [137, 140], [141, 149], [150, 157], [157, 158]]}
{"doc_key": "ai-test-247", "ner": [[6, 6, "country"], [8, 8, "country"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 6, 8, 8, "opposite", "strained_relations", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "case", "strained", "relations", "between", "the", "US", "and", "Japan", "and", "led", "to", "the", "arrest", "and", "prosecution", "of", "two", "senior", "executives", "and", "the", "imposition", "of", "sanctions", "by", "both", "countries", "."], "sentence-detokenized": "The case strained relations between the US and Japan and led to the arrest and prosecution of two senior executives and the imposition of sanctions by both countries.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 27], [28, 35], [36, 39], [40, 42], [43, 46], [47, 52], [53, 56], [57, 60], [61, 63], [64, 67], [68, 74], [75, 78], [79, 90], [91, 93], [94, 97], [98, 104], [105, 115], [116, 119], [120, 123], [124, 134], [135, 137], [138, 147], [148, 150], [151, 155], [156, 165], [165, 166]]}
{"doc_key": "ai-test-248", "ner": [[4, 8, "algorithm"], [11, 12, "field"], [18, 18, "misc"], [30, 30, "misc"], [35, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 8, 11, 12, "type-of", "", false, false], [18, 18, 11, 12, "part-of", "", true, false], [30, 30, 11, 12, "part-of", "", true, false], [35, 38, 11, 12, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["If", "modelling", "is", "done", "with", "an", "artificial", "neural", "network", "or", "other", "machine", "learning", ",", "parameter", "optimisation", "is", "called", "training", ",", "while", "optimisation", "of", "the", "hyperparameters", "of", "a", "model", "is", "called", "tuning", ",", "and", "often", "uses", "the", "method", "of", "cross-validation", "."], "sentence-detokenized": "If modelling is done with an artificial neural network or other machine learning, parameter optimisation is called training, while optimisation of the hyperparameters of a model is called tuning, and often uses the method of cross-validation.", "token2charspan": [[0, 2], [3, 12], [13, 15], [16, 20], [21, 25], [26, 28], [29, 39], [40, 46], [47, 54], [55, 57], [58, 63], [64, 71], [72, 80], [80, 81], [82, 91], [92, 104], [105, 107], [108, 114], [115, 123], [123, 124], [125, 130], [131, 143], [144, 146], [147, 150], [151, 166], [167, 169], [170, 171], [172, 177], [178, 180], [181, 187], [188, 194], [194, 195], [196, 199], [200, 205], [206, 210], [211, 214], [215, 221], [222, 224], [225, 241], [241, 242]]}
{"doc_key": "ai-test-249", "ner": [[12, 12, "country"], [14, 14, "country"], [16, 18, "country"], [23, 24, "organisation"], [21, 21, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[23, 24, 21, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "localised", "versions", "of", "the", "site", ",", "which", "were", "available", "in", "the", "UK", ",", "India", "and", "Australia", ",", "were", "discontinued", "after", "Fandango", "acquired", "Rotten", "Tomatoes", "."], "sentence-detokenized": "The localised versions of the site, which were available in the UK, India and Australia, were discontinued after Fandango acquired Rotten Tomatoes.", "token2charspan": [[0, 3], [4, 13], [14, 22], [23, 25], [26, 29], [30, 34], [34, 35], [36, 41], [42, 46], [47, 56], [57, 59], [60, 63], [64, 66], [66, 67], [68, 73], [74, 77], [78, 87], [87, 88], [89, 93], [94, 106], [107, 112], [113, 121], [122, 130], [131, 137], [138, 146], [146, 147]]}
{"doc_key": "ai-test-250", "ner": [[11, 13, "metrics"], [18, 20, "task"]], "ner_mapping_to_source": [1, 2], "relations": [[11, 13, 18, 20, "related-to", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["The", "NER", "model", "is", "one", "of", "several", "methods", "used", "to", "determine", "the", "accuracy", "of", "live", "subtitles", "produced", "by", "speech", "recognition", "for", "television", "broadcasts", "and", "events", "."], "sentence-detokenized": "The NER model is one of several methods used to determine the accuracy of live subtitles produced by speech recognition for television broadcasts and events.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 20], [21, 23], [24, 31], [32, 39], [40, 44], [45, 47], [48, 57], [58, 61], [62, 70], [71, 73], [74, 78], [79, 88], [89, 97], [98, 100], [101, 107], [108, 119], [120, 123], [124, 134], [135, 145], [146, 149], [150, 156], [156, 157]]}
{"doc_key": "ai-test-251", "ner": [[0, 0, "researcher"], [4, 7, "university"], [10, 12, "university"], [13, 13, "location"], [15, 19, "university"], [21, 22, "university"], [23, 24, "location"], [27, 32, "university"], [33, 35, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 4, 7, "physical", "", false, false], [0, 0, 4, 7, "role", "", false, false], [0, 0, 10, 12, "physical", "", false, false], [0, 0, 10, 12, "role", "", false, false], [0, 0, 15, 19, "physical", "", false, false], [0, 0, 15, 19, "role", "", false, false], [0, 0, 21, 22, "physical", "", false, false], [0, 0, 21, 22, "role", "", false, false], [0, 0, 27, 32, "physical", "", false, false], [0, 0, 27, 32, "role", "", false, false], [10, 12, 13, 13, "physical", "", false, false], [15, 19, 23, 24, "physical", "", false, false], [21, 22, 23, 24, "physical", "", false, false], [27, 32, 33, 35, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Atran", "has", "taught", "at", "the", "University", "of", "Cambridge", ",", "the", "Hebrew", "University", "of", "Jerusalem", ",", "\u00c9cole", "pratique", "des", "hautes", "\u00e9tudes", "and", "\u00c9cole", "Polytechnique", "in", "Paris", ",", "and", "John", "Jay", "College", "of", "Criminal", "Justice", "in", "New", "York", "."], "sentence-detokenized": "Atran has taught at the University of Cambridge, the Hebrew University of Jerusalem, \u00c9cole pratique des hautes \u00e9tudes and \u00c9cole Polytechnique in Paris, and John Jay College of Criminal Justice in New York.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 23], [24, 34], [35, 37], [38, 47], [47, 48], [49, 52], [53, 59], [60, 70], [71, 73], [74, 83], [83, 84], [85, 90], [91, 99], [100, 103], [104, 110], [111, 117], [118, 121], [122, 127], [128, 141], [142, 144], [145, 150], [150, 151], [152, 155], [156, 160], [161, 164], [165, 172], [173, 175], [176, 184], [185, 192], [193, 195], [196, 199], [200, 204], [204, 205]]}
{"doc_key": "ai-test-252", "ner": [[0, 0, "product"], [4, 6, "task"], [11, 12, "researcher"], [13, 14, "university"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 4, 6, "origin", "", false, false], [0, 0, 4, 6, "related-to", "", false, false], [4, 6, 13, 14, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["SHRDLU", "was", "an", "early", "natural", "language", "understanding", "computer", "program", "developed", "by", "Terry", "Winograd", "at", "MIT", "between", "1968", "and", "1970", "."], "sentence-detokenized": "SHRDLU was an early natural language understanding computer program developed by Terry Winograd at MIT between 1968 and 1970.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 19], [20, 27], [28, 36], [37, 50], [51, 59], [60, 67], [68, 77], [78, 80], [81, 86], [87, 95], [96, 98], [99, 102], [103, 110], [111, 115], [116, 119], [120, 124], [124, 125]]}
{"doc_key": "ai-test-253", "ner": [[3, 6, "misc"], [7, 8, "field"], [9, 16, "university"], [17, 17, "location"], [19, 20, "country"], [28, 29, "university"], [32, 33, "misc"], [36, 39, "field"], [40, 42, "university"], [48, 49, "misc"], [52, 53, "field"], [57, 58, "misc"], [61, 67, "university"], [72, 73, "field"], [77, 78, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "relations": [[3, 6, 7, 8, "topic", "", false, false], [3, 6, 9, 16, "origin", "", false, false], [9, 16, 17, 17, "physical", "", false, false], [9, 16, 28, 29, "role", "affiliated_with", false, false], [17, 17, 19, 20, "physical", "", false, false], [32, 33, 36, 39, "topic", "", false, false], [32, 33, 40, 42, "origin", "", false, false], [48, 49, 52, 53, "topic", "", false, false], [57, 58, 61, 67, "origin", "", false, false], [57, 58, 72, 73, "topic", "", false, false], [77, 78, 61, 67, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["He", "earned", "a", "bachelor", "'s", "degree", "in", "electronics", "engineering", "from", "the", "B.M.S", ".", "College", "of", "Engineering", "in", "Bangalore", ",", "India", "in", "1982", ",", "when", "it", "was", "affiliated", "with", "Bangalore", "University", ",", "a", "master", "'s", "degree", "in", "electrical", "and", "computer", "engineering", "from", "Drexel", "University", "in", "1984", ",", "and", "a", "master", "'s", "degree", "in", "computer", "science", "in", "1989", "and", "a", "doctorate", "in", "1990", "from", "the", "University", "of", "Wisconsin", "-", "Madison", ",", "where", "he", "studied", "artificial", "intelligence", "and", "worked", "with", "Leonard", "Uhr", "."], "sentence-detokenized": "He earned a bachelor's degree in electronics engineering from the B.M.S. College of Engineering in Bangalore, India in 1982, when it was affiliated with Bangalore University, a master's degree in electrical and computer engineering from Drexel University in 1984, and a master's degree in computer science in 1989 and a doctorate in 1990 from the University of Wisconsin-Madison, where he studied artificial intelligence and worked with Leonard Uhr.", "token2charspan": [[0, 2], [3, 9], [10, 11], [12, 20], [20, 22], [23, 29], [30, 32], [33, 44], [45, 56], [57, 61], [62, 65], [66, 71], [71, 72], [73, 80], [81, 83], [84, 95], [96, 98], [99, 108], [108, 109], [110, 115], [116, 118], [119, 123], [123, 124], [125, 129], [130, 132], [133, 136], [137, 147], [148, 152], [153, 162], [163, 173], [173, 174], [175, 176], [177, 183], [183, 185], [186, 192], [193, 195], [196, 206], [207, 210], [211, 219], [220, 231], [232, 236], [237, 243], [244, 254], [255, 257], [258, 262], [262, 263], [264, 267], [268, 269], [270, 276], [276, 278], [279, 285], [286, 288], [289, 297], [298, 305], [306, 308], [309, 313], [314, 317], [318, 319], [320, 329], [330, 332], [333, 337], [338, 342], [343, 346], [347, 357], [358, 360], [361, 370], [370, 371], [371, 378], [378, 379], [380, 385], [386, 388], [389, 396], [397, 407], [408, 420], [421, 424], [425, 431], [432, 436], [437, 444], [445, 448], [448, 449]]}
{"doc_key": "ai-test-254", "ner": [[4, 8, "metrics"], [6, 13, "metrics"], [17, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 13, 4, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Accuracy", "is", "usually", "measured", "by", "the", "word", "error", "rate", "(", "WER", ")", ",", "while", "speed", "is", "measured", "by", "the", "real", "-", "time", "coefficient", "."], "sentence-detokenized": "Accuracy is usually measured by the word error rate (WER), while speed is measured by the real-time coefficient.", "token2charspan": [[0, 8], [9, 11], [12, 19], [20, 28], [29, 31], [32, 35], [36, 40], [41, 46], [47, 51], [52, 53], [53, 56], [56, 57], [57, 58], [59, 64], [65, 70], [71, 73], [74, 82], [83, 85], [86, 89], [90, 94], [94, 95], [95, 99], [100, 111], [111, 112]]}
{"doc_key": "ai-test-255", "ner": [[3, 4, "researcher"], [8, 9, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 8, 9, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1971", ",", "Terry", "Winograd", "developed", "an", "early", "natural", "language", "processing", "engine", "that", "could", "interpret", "naturally", "written", "commands", "in", "a", "simple", "rule", "-", "driven", "environment", "."], "sentence-detokenized": "In 1971, Terry Winograd developed an early natural language processing engine that could interpret naturally written commands in a simple rule-driven environment.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 23], [24, 33], [34, 36], [37, 42], [43, 50], [51, 59], [60, 70], [71, 77], [78, 82], [83, 88], [89, 98], [99, 108], [109, 116], [117, 125], [126, 128], [129, 130], [131, 137], [138, 142], [142, 143], [143, 149], [150, 161], [161, 162]]}
{"doc_key": "ai-test-256", "ner": [[17, 18, "field"], [0, 1, "researcher"], [3, 6, "researcher"], [8, 9, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[17, 18, 0, 1, "related-to", "", false, false], [17, 18, 3, 6, "related-to", "", false, false], [17, 18, 8, 9, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Marvin", "Minsky", ",", "Herbert", "A", ".", "Simon", "and", "Allen", "Newell", "are", "prominent", "figures", "in", "the", "field", "of", "artificial", "intelligence", "."], "sentence-detokenized": "Marvin Minsky, Herbert A. Simon and Allen Newell are prominent figures in the field of artificial intelligence.", "token2charspan": [[0, 6], [7, 13], [13, 14], [15, 22], [23, 24], [24, 25], [26, 31], [32, 35], [36, 41], [42, 48], [49, 52], [53, 62], [63, 70], [71, 73], [74, 77], [78, 83], [84, 86], [87, 97], [98, 110], [110, 111]]}
{"doc_key": "ai-test-257", "ner": [[9, 13, "field"], [31, 31, "field"], [33, 34, "field"], [37, 38, "field"], [47, 50, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[31, 31, 9, 13, "origin", "", true, false], [31, 31, 9, 13, "part-of", "", false, false], [31, 31, 37, 38, "compare", "", false, false], [33, 34, 9, 13, "origin", "", true, false], [33, 34, 9, 13, "part-of", "", false, false], [33, 34, 37, 38, "compare", "", false, false], [37, 38, 9, 13, "origin", "", true, false], [37, 38, 9, 13, "part-of", "", false, false], [37, 38, 47, 50, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["In", "the", "second", "half", "of", "the", "20th", "century", ",", "electrical", "engineering", "was", "divided", "into", "several", "disciplines", "specialising", "in", "the", "design", "and", "analysis", "of", "systems", "dealing", "with", "physical", "signals", ",", "such", "as", "electronics", "and", "computer", "engineering", ",", "while", "design", "engineering", "evolved", "to", "deal", "with", "the", "functional", "design", "of", "user", "and", "machine", "interfaces", "."], "sentence-detokenized": "In the second half of the 20th century, electrical engineering was divided into several disciplines specialising in the design and analysis of systems dealing with physical signals, such as electronics and computer engineering, while design engineering evolved to deal with the functional design of user and machine interfaces.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 18], [19, 21], [22, 25], [26, 30], [31, 38], [38, 39], [40, 50], [51, 62], [63, 66], [67, 74], [75, 79], [80, 87], [88, 99], [100, 112], [113, 115], [116, 119], [120, 126], [127, 130], [131, 139], [140, 142], [143, 150], [151, 158], [159, 163], [164, 172], [173, 180], [180, 181], [182, 186], [187, 189], [190, 201], [202, 205], [206, 214], [215, 226], [226, 227], [228, 233], [234, 240], [241, 252], [253, 260], [261, 263], [264, 268], [269, 273], [274, 277], [278, 288], [289, 295], [296, 298], [299, 303], [304, 307], [308, 315], [316, 326], [326, 327]]}
{"doc_key": "ai-test-258", "ner": [[5, 5, "metrics"], [7, 8, "metrics"], [10, 10, "metrics"], [47, 49, "metrics"], [56, 58, "metrics"], [62, 68, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[10, 10, 7, 8, "named", "", false, false], [47, 49, 56, 58, "named", "", false, false], [56, 58, 62, 68, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Perhaps", "the", "simplest", "statistic", "is", "accuracy", "or", "Fraction", "Correct", "(", "FC", ")", ",", "which", "measures", "the", "proportion", "of", "correctly", "classified", "cases", "out", "of", "all", "cases", ";", "it", "is", "the", "ratio", "of", "the", "number", "of", "correct", "classifications", "to", "the", "total", "number", "of", "correct", "or", "incorrect", "classifications", ":", "(", "TP", "+", "TN", ")", "/", "total", "population", "=", "(", "TP", "+", "TN", ")", "/", "(", "TP", "+", "TN", "+", "FP", "+", "FN", ")", "."], "sentence-detokenized": "Perhaps the simplest statistic is accuracy or Fraction Correct (FC), which measures the proportion of correctly classified cases out of all cases; it is the ratio of the number of correct classifications to the total number of correct or incorrect classifications: (TP + TN) / total population = (TP + TN) / (TP + TN + FP + FN).", "token2charspan": [[0, 7], [8, 11], [12, 20], [21, 30], [31, 33], [34, 42], [43, 45], [46, 54], [55, 62], [63, 64], [64, 66], [66, 67], [67, 68], [69, 74], [75, 83], [84, 87], [88, 98], [99, 101], [102, 111], [112, 122], [123, 128], [129, 132], [133, 135], [136, 139], [140, 145], [145, 146], [147, 149], [150, 152], [153, 156], [157, 162], [163, 165], [166, 169], [170, 176], [177, 179], [180, 187], [188, 203], [204, 206], [207, 210], [211, 216], [217, 223], [224, 226], [227, 234], [235, 237], [238, 247], [248, 263], [263, 264], [265, 266], [266, 268], [269, 270], [271, 273], [273, 274], [275, 276], [277, 282], [283, 293], [294, 295], [296, 297], [297, 299], [300, 301], [302, 304], [304, 305], [306, 307], [308, 309], [309, 311], [312, 313], [314, 316], [317, 318], [319, 321], [322, 323], [324, 326], [326, 327], [327, 328]]}
{"doc_key": "ai-test-259", "ner": [[14, 22, "conference"], [24, 26, "conference"], [33, 36, "location"], [32, 32, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[14, 22, 33, 36, "physical", "", false, false], [24, 26, 14, 22, "named", "", false, false], [32, 32, 14, 22, "role", "sponsors", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "the", "academic", "community", ",", "the", "main", "research", "forums", "began", "in", "1995", "with", "the", "first", "international", "conference", "on", "Data", "Mining", "and", "Knowledge", "Discovery", "(", "KDD", "-", "95", ")", ",", "sponsored", "by", "the", "AAAI", ",", "held", "in", "Montreal", "."], "sentence-detokenized": "In the academic community, the main research forums began in 1995 with the first international conference on Data Mining and Knowledge Discovery (KDD-95), sponsored by the AAAI, held in Montreal.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 25], [25, 26], [27, 30], [31, 35], [36, 44], [45, 51], [52, 57], [58, 60], [61, 65], [66, 70], [71, 74], [75, 80], [81, 94], [95, 105], [106, 108], [109, 113], [114, 120], [121, 124], [125, 134], [135, 144], [145, 146], [146, 149], [149, 150], [150, 152], [152, 153], [153, 154], [155, 164], [165, 167], [168, 171], [172, 176], [176, 177], [178, 182], [183, 185], [186, 194], [194, 195]]}
{"doc_key": "ai-test-260", "ner": [[9, 10, "field"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "this", "approach", ",", "models", "are", "developed", "using", "various", "data", "mining", "and", "machine", "learning", "algorithms", "to", "predict", "how", "users", "evaluate", "unclassified", "items", "."], "sentence-detokenized": "In this approach, models are developed using various data mining and machine learning algorithms to predict how users evaluate unclassified items.", "token2charspan": [[0, 2], [3, 7], [8, 16], [16, 17], [18, 24], [25, 28], [29, 38], [39, 44], [45, 52], [53, 57], [58, 64], [65, 68], [69, 76], [77, 85], [86, 96], [97, 99], [100, 107], [108, 111], [112, 117], [118, 126], [127, 139], [140, 145], [145, 146]]}
{"doc_key": "ai-test-261", "ner": [[14, 16, "algorithm"], [17, 19, "algorithm"], [25, 27, "misc"], [30, 31, "metrics"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[14, 16, 17, 19, "usage", "", false, false], [17, 19, 30, 31, "usage", "", false, false], [30, 31, 25, 27, "type-of", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["In", "light", "of", "the", "discussion", "above", ",", "we", "see", "that", "the", "SVM", "technique", "matches", "the", "empirical", "risk", "with", "Tikhonov", "regularization", ",", "where", "in", "this", "case", "the", "loss", "function", "is", "the", "hinge", "loss", "."], "sentence-detokenized": "In light of the discussion above, we see that the SVM technique matches the empirical risk with Tikhonov regularization, where in this case the loss function is the hinge loss.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 15], [16, 26], [27, 32], [32, 33], [34, 36], [37, 40], [41, 45], [46, 49], [50, 53], [54, 63], [64, 71], [72, 75], [76, 85], [86, 90], [91, 95], [96, 104], [105, 119], [119, 120], [121, 126], [127, 129], [130, 134], [135, 139], [140, 143], [144, 148], [149, 157], [158, 160], [161, 164], [165, 170], [171, 175], [175, 176]]}
{"doc_key": "ai-test-262", "ner": [[6, 7, "person"], [12, 13, "person"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "2015", "edition", "was", "hosted", "by", "Molly", "McGrath", ",", "with", "commentary", "by", "Chris", "Rose", "and", "former", "UFC", "fighter", "Kenny", "Florian", "."], "sentence-detokenized": "The 2015 edition was hosted by Molly McGrath, with commentary by Chris Rose and former UFC fighter Kenny Florian.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 27], [28, 30], [31, 36], [37, 44], [44, 45], [46, 50], [51, 61], [62, 64], [65, 70], [71, 75], [76, 79], [80, 86], [87, 90], [91, 98], [99, 104], [105, 112], [112, 113]]}
{"doc_key": "ai-test-263", "ner": [[17, 20, "product"], [0, 2, "researcher"], [4, 5, "researcher"], [7, 8, "researcher"], [9, 9, "researcher"], [13, 13, "researcher"], [31, 32, "task"], [35, 35, "product"], [37, 37, "researcher"], [40, 40, "task"], [44, 44, "researcher"], [49, 50, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12], "relations": [[17, 20, 0, 2, "origin", "", false, false], [17, 20, 4, 5, "origin", "", false, false], [17, 20, 7, 8, "origin", "", false, false], [17, 20, 9, 9, "origin", "", false, false], [4, 5, 37, 37, "named", "same", false, false], [7, 8, 13, 13, "named", "same", false, false], [31, 32, 35, 35, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 7], "sentence": ["Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "Sussman", ",", ",", "and", "Winograd", "implemented", "a", "subset", "called", "Micro", "-", "Planner", "in", "1971", ",", "and", "it", "was", "used", "in", "Winograd", "'s", "natural", "language", "understanding", "program", "SHRDLU", ",", "Eugene", "Charniak", "'s", "story", "understanding", "work", ",", "Thorne", "McCarty", "'s", "work", "on", "legal", "reasoning", "and", "some", "other", "projects", "."], "sentence-detokenized": "Gerald Jay Sussman, Eugene Charniak and Terry Winograd Sussman,, and Winograd implemented a subset called Micro-Planner in 1971, and it was used in Winograd's natural language understanding program SHRDLU, Eugene Charniak's story understanding work, Thorne McCarty's work on legal reasoning and some other projects.", "token2charspan": [[0, 6], [7, 10], [11, 18], [18, 19], [20, 26], [27, 35], [36, 39], [40, 45], [46, 54], [55, 62], [62, 63], [63, 64], [65, 68], [69, 77], [78, 89], [90, 91], [92, 98], [99, 105], [106, 111], [111, 112], [112, 119], [120, 122], [123, 127], [127, 128], [129, 132], [133, 135], [136, 139], [140, 144], [145, 147], [148, 156], [156, 158], [159, 166], [167, 175], [176, 189], [190, 197], [198, 204], [204, 205], [206, 212], [213, 221], [221, 223], [224, 229], [230, 243], [244, 248], [248, 249], [250, 256], [257, 264], [264, 266], [267, 271], [272, 274], [275, 280], [281, 290], [291, 294], [295, 299], [300, 305], [306, 314], [314, 315]]}
{"doc_key": "ai-test-264", "ner": [[0, 1, "product"], [5, 8, "product"], [16, 18, "task"], [20, 21, "task"], [23, 25, "task"], [27, 28, "task"], [30, 31, "task"], [34, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[5, 8, 0, 1, "usage", "", true, false], [16, 18, 5, 8, "part-of", "", true, false], [20, 21, 5, 8, "part-of", "", true, false], [23, 25, 5, 8, "part-of", "", true, false], [27, 28, 5, 8, "part-of", "", true, false], [30, 31, 5, 8, "part-of", "", true, false], [34, 36, 5, 8, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Word", "Net", "has", "been", "used", "in", "information", "systems", "for", "a", "variety", "of", "purposes", ",", "such", "as", "word", "sense", "extraction", ",", "information", "retrieval", ",", "automatic", "text", "classification", ",", "automatic", "summarisation", ",", "machine", "translation", "and", "even", "automatic", "crossword", "generation", "."], "sentence-detokenized": "WordNet has been used in information systems for a variety of purposes, such as word sense extraction, information retrieval, automatic text classification, automatic summarisation, machine translation and even automatic crossword generation.", "token2charspan": [[0, 4], [4, 7], [8, 11], [12, 16], [17, 21], [22, 24], [25, 36], [37, 44], [45, 48], [49, 50], [51, 58], [59, 61], [62, 70], [70, 71], [72, 76], [77, 79], [80, 84], [85, 90], [91, 101], [101, 102], [103, 114], [115, 124], [124, 125], [126, 135], [136, 140], [141, 155], [155, 156], [157, 166], [167, 180], [180, 181], [182, 189], [190, 201], [202, 205], [206, 210], [211, 220], [221, 230], [231, 241], [241, 242]]}
{"doc_key": "ai-test-265", "ner": [[0, 0, "researcher"], [7, 8, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 7, 8, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Keutzer", "was", "appointed", "a", "member", "of", "the", "IEEE", "in", "1996", "."], "sentence-detokenized": "Keutzer was appointed a member of the IEEE in 1996.", "token2charspan": [[0, 7], [8, 11], [12, 21], [22, 23], [24, 30], [31, 33], [34, 37], [38, 42], [43, 45], [46, 50], [50, 51]]}
{"doc_key": "ai-test-266", "ner": [[8, 10, "algorithm"], [53, 56, "misc"], [66, 67, "algorithm"], [69, 70, "algorithm"], [72, 74, "algorithm"], [76, 77, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[66, 67, 53, 56, "type-of", "", false, false], [69, 70, 53, 56, "type-of", "", false, false], [72, 74, 53, 56, "type-of", "", false, false], [76, 77, 53, 56, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["A", "widely", "used", "type", "of", "composition", "is", "the", "nonlinear", "weighted", "sum", ",", "where", "math", "\\", "textstyle", "f", "(", "x", ")", "=", "K", "\\", "left", "(", "\\", "sum", "_", "i", "w", "_", "i", "g", "_", "i", "(", "x", ")", "\\", "right", ")", "/", "math", ",", "where", "math", "\\", "textstyle", "K", "/", "math", "(", "commonly", "called", "the", "activation", "function", ")", "is", "a", "predefined", "function", ",", "such", "as", "a", "hyperbolic", "tangent", ",", "sigmoid", "function", ",", "soft", "maximum", "function", "or", "rectification", "function", "."], "sentence-detokenized": "A widely used type of composition is the nonlinear weighted sum, where math\\ textstyle f (x) = K\\ left (\\ sum _ i w _ i g _ i (x)\\ right) / math, where math\\ textstyle K / math (commonly called the activation function) is a predefined function, such as a hyperbolic tangent, sigmoid function, soft maximum function or rectification function.", "token2charspan": [[0, 1], [2, 8], [9, 13], [14, 18], [19, 21], [22, 33], [34, 36], [37, 40], [41, 50], [51, 59], [60, 63], [63, 64], [65, 70], [71, 75], [75, 76], [77, 86], [87, 88], [89, 90], [90, 91], [91, 92], [93, 94], [95, 96], [96, 97], [98, 102], [103, 104], [104, 105], [106, 109], [110, 111], [112, 113], [114, 115], [116, 117], [118, 119], [120, 121], [122, 123], [124, 125], [126, 127], [127, 128], [128, 129], [129, 130], [131, 136], [136, 137], [138, 139], [140, 144], [144, 145], [146, 151], [152, 156], [156, 157], [158, 167], [168, 169], [170, 171], [172, 176], [177, 178], [178, 186], [187, 193], [194, 197], [198, 208], [209, 217], [217, 218], [219, 221], [222, 223], [224, 234], [235, 243], [243, 244], [245, 249], [250, 252], [253, 254], [255, 265], [266, 273], [273, 274], [275, 282], [283, 291], [291, 292], [293, 297], [298, 305], [306, 314], [315, 317], [318, 331], [332, 340], [340, 341]]}
{"doc_key": "ai-test-267", "ner": [[0, 1, "misc"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "Westworld", ",", "female", "robots", "actually", "had", "intercourse", "with", "human", "men", "as", "part", "of", "a", "fictional", "holiday", "world", "that", "human", "customers", "paid", "to", "participate", "in", "."], "sentence-detokenized": "In Westworld, female robots actually had intercourse with human men as part of a fictional holiday world that human customers paid to participate in.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 20], [21, 27], [28, 36], [37, 40], [41, 52], [53, 57], [58, 63], [64, 67], [68, 70], [71, 75], [76, 78], [79, 80], [81, 90], [91, 98], [99, 104], [105, 109], [110, 115], [116, 125], [126, 130], [131, 133], [134, 145], [146, 148], [148, 149]]}
{"doc_key": "ai-test-268", "ner": [[6, 7, "task"], [21, 26, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 7, 21, 26, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Typically", ",", "the", "process", "starts", "by", "extracting", "terminology", "and", "concepts", "or", "noun", "phrases", "from", "plain", "text", "using", "linguistic", "processors", "such", "as", "part", "-", "of", "-", "speech", "tagging", "and", "phrase", "chunking", "."], "sentence-detokenized": "Typically, the process starts by extracting terminology and concepts or noun phrases from plain text using linguistic processors such as part-of-speech tagging and phrase chunking.", "token2charspan": [[0, 9], [9, 10], [11, 14], [15, 22], [23, 29], [30, 32], [33, 43], [44, 55], [56, 59], [60, 68], [69, 71], [72, 76], [77, 84], [85, 89], [90, 95], [96, 100], [101, 106], [107, 117], [118, 128], [129, 133], [134, 136], [137, 141], [141, 142], [142, 144], [144, 145], [145, 151], [152, 159], [160, 163], [164, 170], [171, 179], [179, 180]]}
{"doc_key": "ai-test-269", "ner": [[17, 18, "task"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "demonstrated", "its", "performance", "on", "several", "problems", "of", "interest", "to", "the", "machine", "learning", "community", ",", "such", "as", "handwriting", "recognition", "."], "sentence-detokenized": "They demonstrated its performance on several problems of interest to the machine learning community, such as handwriting recognition.", "token2charspan": [[0, 4], [5, 17], [18, 21], [22, 33], [34, 36], [37, 44], [45, 53], [54, 56], [57, 65], [66, 68], [69, 72], [73, 80], [81, 89], [90, 99], [99, 100], [101, 105], [106, 108], [109, 120], [121, 132], [132, 133]]}
{"doc_key": "ai-test-270", "ner": [[5, 5, "researcher"], [11, 12, "researcher"], [21, 21, "product"], [18, 19, "product"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[21, 21, 11, 12, "origin", "", false, false], [21, 21, 18, 19, "general-affiliation", "", false, false]], "relations_mapping_to_source": [2, 3], "sentence": ["While", "studying", "at", "Stanford", ",", "Scheinman", "received", "a", "scholarship", "sponsored", "by", "George", "Devol", ",", "inventor", "of", "the", "first", "industrial", "robot", ",", "Unimate", "."], "sentence-detokenized": "While studying at Stanford, Scheinman received a scholarship sponsored by George Devol, inventor of the first industrial robot, Unimate.", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [26, 27], [28, 37], [38, 46], [47, 48], [49, 60], [61, 70], [71, 73], [74, 80], [81, 86], [86, 87], [88, 96], [97, 99], [100, 103], [104, 109], [110, 120], [121, 126], [126, 127], [128, 135], [135, 136]]}
{"doc_key": "ai-test-271", "ner": [[7, 8, "task"], [12, 12, "metrics"], [11, 14, "metrics"], [23, 25, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 12, 12, "usage", "", true, false], [11, 14, 12, 12, "named", "", false, false], [23, 25, 12, 12, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Although", "it", "was", "originally", "used", "to", "evaluate", "machine", "translations", ",", "the", "Bilingual", "Underestimation", "(", "BLEU", ")", "has", "also", "been", "successfully", "used", "to", "evaluate", "paraphrase", "generation", "models", "."], "sentence-detokenized": "Although it was originally used to evaluate machine translations, the Bilingual Underestimation (BLEU) has also been successfully used to evaluate paraphrase generation models.", "token2charspan": [[0, 8], [9, 11], [12, 15], [16, 26], [27, 31], [32, 34], [35, 43], [44, 51], [52, 64], [64, 65], [66, 69], [70, 79], [80, 95], [96, 97], [97, 101], [101, 102], [103, 106], [107, 111], [112, 116], [117, 129], [130, 134], [135, 137], [138, 146], [147, 157], [158, 168], [169, 175], [175, 176]]}
{"doc_key": "ai-test-272", "ner": [[2, 2, "organisation"], [6, 9, "organisation"], [11, 11, "organisation"], [15, 15, "product"], [16, 17, "country"], [19, 19, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 6, 9, "role", "licenses_to", false, false], [2, 2, 11, 11, "role", "licenses_to", false, false], [6, 9, 16, 17, "physical", "", false, false], [11, 11, 19, 19, "physical", "", false, false], [15, 15, 6, 9, "artifact", "produces", false, false], [15, 15, 11, 11, "artifact", "produces", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Later", ",", "Unimation", "licensed", "its", "technology", "to", "Kawasaki", "Heavy", "Industries", "and", "GKN", ",", "which", "manufactured", "Unimation", "in", "Japan", "and", "England", "."], "sentence-detokenized": "Later, Unimation licensed its technology to Kawasaki Heavy Industries and GKN, which manufactured Unimation in Japan and England.", "token2charspan": [[0, 5], [5, 6], [7, 16], [17, 25], [26, 29], [30, 40], [41, 43], [44, 52], [53, 58], [59, 69], [70, 73], [74, 77], [77, 78], [79, 84], [85, 97], [98, 107], [108, 110], [111, 116], [117, 120], [121, 128], [128, 129]]}
{"doc_key": "ai-test-273", "ner": [[20, 21, "conference"], [36, 38, "field"], [53, 57, "field"], [59, 59, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[36, 38, 53, 57, "compare", "", false, false], [59, 59, 53, 57, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Much", "of", "the", "confusion", "between", "the", "two", "research", "communities", "(", "which", "often", "have", "separate", "conferences", "and", "separate", "journals", ",", "with", "ECML", "PKDD", "being", "a", "notable", "exception", ")", "stems", "from", "the", "basic", "assumptions", "underlying", "their", "work", ":", "in", "machine", "learning", ",", "performance", "is", "usually", "judged", "by", "the", "ability", "to", "reproduce", "known", "information", ",", "while", "in", "knowledge", "discovery", "and", "mining", "(", "KDD", ")", "the", "key", "task", "is", "to", "find", "previously", "unknown", "information", "."], "sentence-detokenized": "Much of the confusion between the two research communities (which often have separate conferences and separate journals, with ECML PKDD being a notable exception) stems from the basic assumptions underlying their work: in machine learning, performance is usually judged by the ability to reproduce known information, while in knowledge discovery and mining (KDD) the key task is to find previously unknown information.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 29], [30, 33], [34, 37], [38, 46], [47, 58], [59, 60], [60, 65], [66, 71], [72, 76], [77, 85], [86, 97], [98, 101], [102, 110], [111, 119], [119, 120], [121, 125], [126, 130], [131, 135], [136, 141], [142, 143], [144, 151], [152, 161], [161, 162], [163, 168], [169, 173], [174, 177], [178, 183], [184, 195], [196, 206], [207, 212], [213, 217], [217, 218], [219, 221], [222, 229], [230, 238], [238, 239], [240, 251], [252, 254], [255, 262], [263, 269], [270, 272], [273, 276], [277, 284], [285, 287], [288, 297], [298, 303], [304, 315], [315, 316], [317, 322], [323, 325], [326, 335], [336, 345], [346, 349], [350, 356], [357, 358], [358, 361], [361, 362], [363, 366], [367, 370], [371, 375], [376, 378], [379, 381], [382, 386], [387, 397], [398, 405], [406, 417], [417, 418]]}
{"doc_key": "ai-test-274", "ner": [[0, 0, "algorithm"], [9, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 9, 12, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Hidden", "Markov", "models", "are", "the", "basis", "of", "most", "modern", "automatic", "speech", "recognition", "systems", "."], "sentence-detokenized": "Hidden Markov models are the basis of most modern automatic speech recognition systems.", "token2charspan": [[0, 6], [7, 13], [14, 20], [21, 24], [25, 28], [29, 34], [35, 37], [38, 42], [43, 49], [50, 59], [60, 66], [67, 78], [79, 86], [86, 87]]}
{"doc_key": "ai-test-275", "ner": [[0, 2, "location"], [11, 11, "task"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": [",", "a", "Bangalore", ",", "India", "-", "based", "company", "specialising", "in", "online", "handwriting", "recognition", "software", "."], "sentence-detokenized": ", a Bangalore, India-based company specialising in online handwriting recognition software.", "token2charspan": [[0, 1], [2, 3], [4, 13], [13, 14], [15, 20], [20, 21], [21, 26], [27, 34], [35, 47], [48, 50], [51, 57], [58, 69], [70, 81], [82, 90], [90, 91]]}
{"doc_key": "ai-test-276", "ner": [[25, 27, "misc"], [53, 55, "metrics"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Do", "repeated", "translations", "translate", "into", "a", "single", "expression", "in", "both", "languages", "?", "In", "other", "words", ",", "is", "the", "translation", "method", "stationary", "or", "does", "it", "produce", "a", "canonical", "form", "?", "Does", "the", "translation", "become", "stationary", "without", "losing", "its", "original", "meaning", "?", "This", "measure", "has", "been", "criticised", "for", "not", "correlating", "well", "with", "the", "BLEU", "(", "BiLingual", "Evaluation", "Understudy", ")", "scores", "."], "sentence-detokenized": "Do repeated translations translate into a single expression in both languages? In other words, is the translation method stationary or does it produce a canonical form? Does the translation become stationary without losing its original meaning? This measure has been criticised for not correlating well with the BLEU (BiLingual Evaluation Understudy) scores.", "token2charspan": [[0, 2], [3, 11], [12, 24], [25, 34], [35, 39], [40, 41], [42, 48], [49, 59], [60, 62], [63, 67], [68, 77], [77, 78], [79, 81], [82, 87], [88, 93], [93, 94], [95, 97], [98, 101], [102, 113], [114, 120], [121, 131], [132, 134], [135, 139], [140, 142], [143, 150], [151, 152], [153, 162], [163, 167], [167, 168], [169, 173], [174, 177], [178, 189], [190, 196], [197, 207], [208, 215], [216, 222], [223, 226], [227, 235], [236, 243], [243, 244], [245, 249], [250, 257], [258, 261], [262, 266], [267, 277], [278, 281], [282, 285], [286, 297], [298, 302], [303, 307], [308, 311], [312, 316], [317, 318], [318, 327], [328, 338], [339, 349], [349, 350], [351, 357], [357, 358]]}
{"doc_key": "ai-test-277", "ner": [[6, 10, "organisation"], [15, 20, "organisation"], [12, 14, "university"], [22, 23, "university"], [26, 27, "field"], [30, 34, "organisation"], [37, 42, "organisation"], [48, 51, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[15, 20, 12, 14, "part-of", "", false, false], [22, 23, 26, 27, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "is", "a", "Fellow", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", ",", "Stanford", "University", "'s", "Graduate", "Research", "Centre", "for", "Behavioral", "Sciences", ",", "MIT", "'s", "Centre", "for", "Cognitive", "Science", ",", "the", "Canadian", "Institute", "for", "Advanced", "Study", ",", "the", "Canadian", "Psychological", "Association", ",", "and", "was", "elected", "a", "Fellow", "of", "the", "Royal", "Society", "of", "Canada", "in", "1998", "."], "sentence-detokenized": "He is a Fellow of the American Association for Artificial Intelligence, Stanford University's Graduate Research Centre for Behavioral Sciences, MIT's Centre for Cognitive Science, the Canadian Institute for Advanced Study, the Canadian Psychological Association, and was elected a Fellow of the Royal Society of Canada in 1998.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 30], [31, 42], [43, 46], [47, 57], [58, 70], [70, 71], [72, 80], [81, 91], [91, 93], [94, 102], [103, 111], [112, 118], [119, 122], [123, 133], [134, 142], [142, 143], [144, 147], [147, 149], [150, 156], [157, 160], [161, 170], [171, 178], [178, 179], [180, 183], [184, 192], [193, 202], [203, 206], [207, 215], [216, 221], [221, 222], [223, 226], [227, 235], [236, 249], [250, 261], [261, 262], [263, 266], [267, 270], [271, 278], [279, 280], [281, 287], [288, 290], [291, 294], [295, 300], [301, 308], [309, 311], [312, 318], [319, 321], [322, 326], [326, 327]]}
{"doc_key": "ai-test-278", "ner": [[2, 2, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [15, 16, "misc"], [12, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 15, 16, "part-of", "", false, false], [2, 2, 12, 19, "part-of", "", false, false], [6, 7, 15, 16, "part-of", "", false, false], [6, 7, 12, 19, "part-of", "", false, false], [9, 10, 15, 16, "part-of", "", false, false], [9, 10, 12, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Some", "call", "Hinton", "-", "along", "with", "Yoshua", "Bengio", "and", "Yann", "LeCun", "-", "the", "godfathers", "of", "artificial", "intelligence", "and", "deep", "learning", "."], "sentence-detokenized": "Some call Hinton - along with Yoshua Bengio and Yann LeCun - the godfathers of artificial intelligence and deep learning.", "token2charspan": [[0, 4], [5, 9], [10, 16], [17, 18], [19, 24], [25, 29], [30, 36], [37, 43], [44, 47], [48, 52], [53, 58], [59, 60], [61, 64], [65, 75], [76, 78], [79, 89], [90, 102], [103, 106], [107, 111], [112, 120], [120, 121]]}
{"doc_key": "ai-test-279", "ner": [[6, 10, "product"], [20, 20, "misc"], [22, 23, "misc"], [24, 24, "product"], [28, 29, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 10, 20, 20, "related-to", "", false, false], [6, 10, 22, 23, "related-to", "", false, false], [20, 20, 24, 24, "named", "same", false, false], [28, 29, 24, 24, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "lightweight", "open", "source", "speech", "project", "eSpeak", ",", "which", "has", "its", "own", "approach", "to", "synthesis", ",", "has", "been", "experimenting", "with", "Mandarin", "and", "Cantonese", ".", "eSpeak", "was", "used", "in", "Google", "Translate", "from", "May", "2010-2010", "."], "sentence-detokenized": "The lightweight open source speech project eSpeak, which has its own approach to synthesis, has been experimenting with Mandarin and Cantonese. eSpeak was used in Google Translate from May 2010-2010.", "token2charspan": [[0, 3], [4, 15], [16, 20], [21, 27], [28, 34], [35, 42], [43, 49], [49, 50], [51, 56], [57, 60], [61, 64], [65, 68], [69, 77], [78, 80], [81, 90], [90, 91], [92, 95], [96, 100], [101, 114], [115, 119], [120, 128], [129, 132], [133, 142], [142, 143], [144, 150], [151, 154], [155, 159], [160, 162], [163, 169], [170, 179], [180, 184], [185, 188], [189, 198], [198, 199]]}
{"doc_key": "ai-test-280", "ner": [[6, 10, "product"], [14, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 10, 14, 16, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["1982", "also", "saw", "the", "release", "of", "Software", "Automatic", "Mouth", ",", "the", "first", "commercial", "software", "voice", "synthesis", "program", "."], "sentence-detokenized": "1982 also saw the release of Software Automatic Mouth, the first commercial software voice synthesis program.", "token2charspan": [[0, 4], [5, 9], [10, 13], [14, 17], [18, 25], [26, 28], [29, 37], [38, 47], [48, 53], [53, 54], [55, 58], [59, 64], [65, 75], [76, 84], [85, 90], [91, 100], [101, 108], [108, 109]]}
{"doc_key": "ai-test-281", "ner": [[6, 8, "metrics"], [10, 10, "metrics"], [13, 13, "metrics"], [15, 15, "metrics"], [18, 25, "metrics"], [29, 31, "metrics"], [30, 30, "metrics"], [33, 43, "metrics"], [46, 48, "metrics"], [47, 50, "metrics"], [53, 53, "metrics"], [55, 55, "metrics"], [58, 65, "metrics"], [69, 71, "metrics"], [73, 73, "metrics"], [76, 83, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[10, 10, 6, 8, "named", "", false, false], [13, 13, 6, 8, "named", "", false, false], [15, 15, 6, 8, "named", "", false, false], [18, 25, 6, 8, "named", "", false, false], [30, 30, 29, 31, "named", "", false, false], [33, 43, 29, 31, "named", "", false, false], [47, 50, 46, 48, "named", "", false, false], [53, 53, 46, 48, "named", "", false, false], [55, 55, 46, 48, "named", "", false, false], [58, 65, 46, 48, "named", "", false, false], [73, 73, 69, 71, "named", "", false, false], [76, 83, 69, 71, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["The", "ratios", "in", "the", "column", "are", "TRUE", "Positive", "Rate", "(", "TPR", ",", "or", "sensitivity", "or", "recall", ")", "(", "TP", "/", "(", "TP", "+", "FN", ")", ")", ",", "supplemented", "by", "FALSE", "Negative", "Rate", "(", "FNR", ")", "(", "FN", "/", "(", "TP", "+", "FN", ")", ")", ";", "and", "TRUE", "Negative", "Rate", "(", "TNR", ",", "or", "specificity", ",", "SPC", ")", "(", "TN", "/", "(", "TN", "+", "FP", ")", ")", ",", "supplemented", "by", "FALSE", "Positive", "Rate", "(", "FPR", ")", "(", "FP", "/", "(", "TN", "+", "FP", ")", ")", "."], "sentence-detokenized": "The ratios in the column are TRUE Positive Rate (TPR, or sensitivity or recall) (TP / (TP + FN)), supplemented by FALSE Negative Rate (FNR) (FN / (TP + FN)); and TRUE Negative Rate (TNR, or specificity, SPC) (TN / (TN + FP)), supplemented by FALSE Positive Rate (FPR) (FP / (TN + FP)).", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 17], [18, 24], [25, 28], [29, 33], [34, 42], [43, 47], [48, 49], [49, 52], [52, 53], [54, 56], [57, 68], [69, 71], [72, 78], [78, 79], [80, 81], [81, 83], [84, 85], [86, 87], [87, 89], [90, 91], [92, 94], [94, 95], [95, 96], [96, 97], [98, 110], [111, 113], [114, 119], [120, 128], [129, 133], [134, 135], [135, 138], [138, 139], [140, 141], [141, 143], [144, 145], [146, 147], [147, 149], [150, 151], [152, 154], [154, 155], [155, 156], [156, 157], [158, 161], [162, 166], [167, 175], [176, 180], [181, 182], [182, 185], [185, 186], [187, 189], [190, 201], [201, 202], [203, 206], [206, 207], [208, 209], [209, 211], [212, 213], [214, 215], [215, 217], [218, 219], [220, 222], [222, 223], [223, 224], [224, 225], [226, 238], [239, 241], [242, 247], [248, 256], [257, 261], [262, 263], [263, 266], [266, 267], [268, 269], [269, 271], [272, 273], [274, 275], [275, 277], [278, 279], [280, 282], [282, 283], [283, 284], [284, 285]]}
{"doc_key": "ai-test-282", "ner": [[0, 0, "person"], [2, 2, "person"], [13, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 13, 16, "role", "working_with", false, false], [2, 2, 13, 16, "role", "working_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Edsinger", "and", "Weber", "also", "collaborated", "on", "many", "other", "robots", ",", "and", "their", "experience", "with", "the", "Kismet", "robot"], "sentence-detokenized": "Edsinger and Weber also collaborated on many other robots, and their experience with the Kismet robot", "token2charspan": [[0, 8], [9, 12], [13, 18], [19, 23], [24, 36], [37, 39], [40, 44], [45, 50], [51, 57], [57, 58], [59, 62], [63, 68], [69, 79], [80, 84], [85, 88], [89, 95], [96, 101]]}
{"doc_key": "ai-test-283", "ner": [[12, 12, "programlang"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["R", "functions", "are", "also", "available", "in", "several", "scripting", "languages", ",", "such", "as", "Python", "."], "sentence-detokenized": "R functions are also available in several scripting languages, such as Python.", "token2charspan": [[0, 1], [2, 11], [12, 15], [16, 20], [21, 30], [31, 33], [34, 41], [42, 51], [52, 61], [61, 62], [63, 67], [68, 70], [71, 77], [77, 78]]}
{"doc_key": "ai-test-284", "ner": [[0, 0, "programlang"], [12, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 14, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VAL", "was", "one", "of", "the", "first", "robot", "languages", ",", "and", "was", "used", "in", "Unimate", "robots", "."], "sentence-detokenized": "VAL was one of the first robot languages, and was used in Unimate robots.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 14], [15, 18], [19, 24], [25, 30], [31, 40], [40, 41], [42, 45], [46, 49], [50, 54], [55, 57], [58, 65], [66, 72], [72, 73]]}
{"doc_key": "ai-test-285", "ner": [[12, 19, "conference"], [14, 23, "conference"], [24, 24, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 19, 24, 24, "physical", "", false, false], [14, 23, 12, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["They", "presented", "their", "database", "for", "the", "first", "time", "as", "a", "poster", "at", "the", "2009", "Computer", "Vision", "and", "Pattern", "Recognition", "Conference", "(", "CVPR", ")", "in", "Florida", "."], "sentence-detokenized": "They presented their database for the first time as a poster at the 2009 Computer Vision and Pattern Recognition Conference (CVPR) in Florida.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 29], [30, 33], [34, 37], [38, 43], [44, 48], [49, 51], [52, 53], [54, 60], [61, 63], [64, 67], [68, 72], [73, 81], [82, 88], [89, 92], [93, 100], [101, 112], [113, 123], [124, 125], [125, 129], [129, 130], [131, 133], [134, 141], [141, 142]]}
{"doc_key": "ai-test-286", "ner": [[0, 1, "misc"], [6, 7, "task"], [9, 10, "field"], [12, 13, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 7, 0, 1, "type-of", "", false, false], [9, 10, 0, 1, "type-of", "", false, false], [12, 13, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Categorisation", "tasks", "without", "labelling", "are", "called", "unsupervised", "classification", ",", "unsupervised", "learning", "or", "cluster", "analysis", "."], "sentence-detokenized": "Categorisation tasks without labelling are called unsupervised classification, unsupervised learning or cluster analysis.", "token2charspan": [[0, 14], [15, 20], [21, 28], [29, 38], [39, 42], [43, 49], [50, 62], [63, 77], [77, 78], [79, 91], [92, 100], [101, 103], [104, 111], [112, 120], [120, 121]]}
{"doc_key": "ai-test-287", "ner": [[3, 4, "task"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "needs", "to", "identify", "objects", ",", "identify", "and", "locate", "people", "and", "recognise", "emotions", "."], "sentence-detokenized": "It needs to identify objects, identify and locate people and recognise emotions.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 20], [21, 28], [28, 29], [30, 38], [39, 42], [43, 49], [50, 56], [57, 60], [61, 70], [71, 79], [79, 80]]}
{"doc_key": "ai-test-288", "ner": [[6, 6, "misc"], [8, 8, "misc"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "process", "is", "complex", "and", "involves", "encoding", "and", "memorisation", "or", "recall", "."], "sentence-detokenized": "The process is complex and involves encoding and memorisation or recall.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 22], [23, 26], [27, 35], [36, 44], [45, 48], [49, 61], [62, 64], [65, 71], [71, 72]]}
{"doc_key": "ai-test-289", "ner": [[10, 11, "product"], [13, 16, "product"], [31, 32, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 13, 16, "named", "", false, false], [10, 11, 31, 32, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "also", "known", "as", "parallel", "robots", "or", "generalised", "Stewart", "platforms", "(", "in", "a", "Stewart", "platform", ",", "actuators", "are", "combined", "on", "both", "the", "platform", "and", "the", "chassis", ")", ",", "are", "articulated", "robots", "that", "use", "similar", "mechanisms", "to", "move", "either", "the", "robot", "chassis", "or", "one", "or", "more", "manipulator", "arms", "."], "sentence-detokenized": "These systems, also known as parallel robots or generalised Stewart platforms (in a Stewart platform, actuators are combined on both the platform and the chassis), are articulated robots that use similar mechanisms to move either the robot chassis or one or more manipulator arms.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 25], [26, 28], [29, 37], [38, 44], [45, 47], [48, 59], [60, 67], [68, 77], [78, 79], [79, 81], [82, 83], [84, 91], [92, 100], [100, 101], [102, 111], [112, 115], [116, 124], [125, 127], [128, 132], [133, 136], [137, 145], [146, 149], [150, 153], [154, 161], [161, 162], [162, 163], [164, 167], [168, 179], [180, 186], [187, 191], [192, 195], [196, 203], [204, 214], [215, 217], [218, 222], [223, 229], [230, 233], [234, 239], [240, 247], [248, 250], [251, 254], [255, 257], [258, 262], [263, 274], [275, 279], [279, 280]]}
{"doc_key": "ai-test-290", "ner": [[6, 7, "field"], [15, 17, "field"], [24, 25, "field"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[15, 17, 24, 25, "part-of", "subfield", false, false]], "relations_mapping_to_source": [2], "sentence": ["Machine", "vision", "as", "a", "discipline", "of", "systems", "engineering", "can", "be", "considered", "as", "a", "separate", "discipline", "from", "computer", "vision", ",", "which", "is", "a", "branch", "of", "computer", "science", "."], "sentence-detokenized": "Machine vision as a discipline of systems engineering can be considered as a separate discipline from computer vision, which is a branch of computer science.", "token2charspan": [[0, 7], [8, 14], [15, 17], [18, 19], [20, 30], [31, 33], [34, 41], [42, 53], [54, 57], [58, 60], [61, 71], [72, 74], [75, 76], [77, 85], [86, 96], [97, 101], [102, 110], [111, 117], [117, 118], [119, 124], [125, 127], [128, 129], [130, 136], [137, 139], [140, 148], [149, 156], [156, 157]]}
{"doc_key": "ai-test-291", "ner": [[4, 5, "algorithm"], [9, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 9, 11, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "activation", "function", "of", "LSTM", "ports", "is", "often", "a", "logistic", "sigmoid", "function", "."], "sentence-detokenized": "The activation function of LSTM ports is often a logistic sigmoid function.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 26], [27, 31], [32, 37], [38, 40], [41, 46], [47, 48], [49, 57], [58, 65], [66, 74], [74, 75]]}
{"doc_key": "ai-test-292", "ner": [[5, 6, "metrics"], [20, 22, "metrics"], [19, 29, "metrics"], [32, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 20, 22, "named", "", false, false], [5, 6, 32, 33, "named", "", false, false], [19, 29, 20, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "other", "words", ",", "the", "sample", "mean", "is", "a", "(", "necessarily", "unique", ")", "efficient", "estimator", "and", "therefore", "also", "the", "minimum", "variance", "unbiased", "estimator", "(", "MVUE", ")", "in", "addition", "to", "being", "the", "maximum", "likelihood", "estimator", "."], "sentence-detokenized": "In other words, the sample mean is a (necessarily unique) efficient estimator and therefore also the minimum variance unbiased estimator (MVUE) in addition to being the maximum likelihood estimator.", "token2charspan": [[0, 2], [3, 8], [9, 14], [14, 15], [16, 19], [20, 26], [27, 31], [32, 34], [35, 36], [37, 38], [38, 49], [50, 56], [56, 57], [58, 67], [68, 77], [78, 81], [82, 91], [92, 96], [97, 100], [101, 108], [109, 117], [118, 126], [127, 136], [137, 138], [138, 142], [142, 143], [144, 146], [147, 155], [156, 158], [159, 164], [165, 168], [169, 176], [177, 187], [188, 197], [197, 198]]}
{"doc_key": "ai-test-293", "ner": [[2, 3, "academicjournal"], [6, 8, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [20, 22, "product"], [23, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 20, 22, "topic", "", false, false], [2, 3, 23, 26, "topic", "", false, false], [6, 8, 2, 3, "role", "", false, false], [10, 11, 2, 3, "role", "", false, false], [13, 14, 2, 3, "role", "", false, false], [20, 22, 23, 26, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["A", "2001", "Scientific", "American", "article", "by", "Berners", "-", "Lee", ",", "James", "Hendler", "and", "Ora", "Lassila", "described", "the", "expected", "evolution", "of", "the", "current", "Web", "into", "a", "semantic", "Web", "."], "sentence-detokenized": "A 2001 Scientific American article by Berners-Lee, James Hendler and Ora Lassila described the expected evolution of the current Web into a semantic Web.", "token2charspan": [[0, 1], [2, 6], [7, 17], [18, 26], [27, 34], [35, 37], [38, 45], [45, 46], [46, 49], [49, 50], [51, 56], [57, 64], [65, 68], [69, 72], [73, 80], [81, 90], [91, 94], [95, 103], [104, 113], [114, 116], [117, 120], [121, 128], [129, 132], [133, 137], [138, 139], [140, 148], [149, 152], [152, 153]]}
{"doc_key": "ai-test-294", "ner": [[0, 1, "misc"], [14, 15, "person"], [17, 17, "person"], [38, 38, "person"], [45, 46, "person"]], "ner_mapping_to_source": [0, 1, 2, 4, 5], "relations": [[14, 15, 0, 1, "role", "actor_in_work", false, false], [17, 17, 14, 15, "named", "", false, false], [17, 17, 14, 15, "origin", "", false, false], [45, 46, 17, 17, "role", "auditioned_for", false, false]], "relations_mapping_to_source": [0, 1, 2, 4], "sentence": ["Blade", "Runner", "used", "several", "actors", "who", "were", "less", "well", "known", "at", "the", "time", ":", "Sean", "Young", "plays", "Rachael", ",", "an", "experimental", "replicant", "implanted", "with", "the", "memories", "of", "Tyrell", "'s", "niece", ",", "making", "her", "think", "she", "is", "human", ";", "Sammon", ",", "pp.", "92", "-", "93", ".", "Nina", "Axelrod", "auditioned", "for", "the", "role", "."], "sentence-detokenized": "Blade Runner used several actors who were less well known at the time: Sean Young plays Rachael, an experimental replicant implanted with the memories of Tyrell's niece, making her think she is human; Sammon, pp. 92-93. Nina Axelrod auditioned for the role.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 25], [26, 32], [33, 36], [37, 41], [42, 46], [47, 51], [52, 57], [58, 60], [61, 64], [65, 69], [69, 70], [71, 75], [76, 81], [82, 87], [88, 95], [95, 96], [97, 99], [100, 112], [113, 122], [123, 132], [133, 137], [138, 141], [142, 150], [151, 153], [154, 160], [160, 162], [163, 168], [168, 169], [170, 176], [177, 180], [181, 186], [187, 190], [191, 193], [194, 199], [199, 200], [201, 207], [207, 208], [209, 212], [213, 215], [215, 216], [216, 218], [218, 219], [220, 224], [225, 232], [233, 243], [244, 247], [248, 251], [252, 256], [256, 257]]}
{"doc_key": "ai-test-295", "ner": [[0, 1, "researcher"], [3, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [12, 15, "university"], [20, 24, "product"], [27, 27, "product"], [41, 41, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 1, 12, 15, "physical", "", false, false], [3, 4, 12, 15, "physical", "", false, false], [6, 7, 12, 15, "physical", "", false, false], [9, 10, 12, 15, "physical", "", false, false], [12, 15, 41, 41, "physical", "", true, false], [20, 24, 12, 15, "temporal", "", false, false], [27, 27, 12, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["Gerry", "Sussman", ",", "Eugene", "Charniak", ",", "Seymour", "Papert", "and", "Terry", "Winograd", "visited", "Edinburgh", "University", "in", "1971", "to", "spread", "the", "news", "about", "the", "Micro", "-", "Planner", "and", "the", "SHRDLU", "and", "to", "question", "the", "single", "proof", "of", "resolution", "that", "was", "a", "mainstay", "of", "Edinburgh", "logic", "researchers", "."], "sentence-detokenized": "Gerry Sussman, Eugene Charniak, Seymour Papert and Terry Winograd visited Edinburgh University in 1971 to spread the news about the Micro-Planner and the SHRDLU and to question the single proof of resolution that was a mainstay of Edinburgh logic researchers.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 21], [22, 30], [30, 31], [32, 39], [40, 46], [47, 50], [51, 56], [57, 65], [66, 73], [74, 83], [84, 94], [95, 97], [98, 102], [103, 105], [106, 112], [113, 116], [117, 121], [122, 127], [128, 131], [132, 137], [137, 138], [138, 145], [146, 149], [150, 153], [154, 160], [161, 164], [165, 167], [168, 176], [177, 180], [181, 187], [188, 193], [194, 196], [197, 207], [208, 212], [213, 216], [217, 218], [219, 227], [228, 230], [231, 240], [241, 246], [247, 258], [258, 259]]}
{"doc_key": "ai-test-296", "ner": [[7, 7, "field"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Walter", "'s", "work", "inspired", "later", "generations", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "Walter's work inspired later generations of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 6], [6, 8], [9, 13], [14, 22], [23, 28], [29, 40], [41, 43], [44, 52], [53, 64], [65, 69], [70, 72], [73, 79], [80, 86], [86, 87], [88, 92], [93, 100], [101, 104], [105, 109], [110, 116], [116, 117]]}
{"doc_key": "ai-test-297", "ner": [[7, 7, "algorithm"], [9, 10, "researcher"], [14, 21, "event"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 9, 10, "origin", "", false, false], [7, 7, 14, 21, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Later", ",", "a", "similar", "GPU", "-", "based", "CNN", "by", "Alex", "Krizhevsky", "and", "others", "won", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "2012", "."], "sentence-detokenized": "Later, a similar GPU-based CNN by Alex Krizhevsky and others won the ImageNet Large Scale Visual Recognition Challenge 2012.", "token2charspan": [[0, 5], [5, 6], [7, 8], [9, 16], [17, 20], [20, 21], [21, 26], [27, 30], [31, 33], [34, 38], [39, 49], [50, 53], [54, 60], [61, 64], [65, 68], [69, 77], [78, 83], [84, 89], [90, 96], [97, 108], [109, 118], [119, 123], [123, 124]]}
{"doc_key": "ai-test-298", "ner": [[0, 1, "misc"], [8, 10, "metrics"], [12, 13, "metrics"], [18, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 10, 0, 1, "type-of", "", false, false], [12, 13, 0, 1, "type-of", "", false, false], [12, 13, 18, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Loss", "functions", "commonly", "used", "in", "probability", "classification", "include", "log", "-", "loss", "and", "Brier", "scores", "between", "the", "predicted", "and", "actual", "probability", "distributions", "."], "sentence-detokenized": "Loss functions commonly used in probability classification include log-loss and Brier scores between the predicted and actual probability distributions.", "token2charspan": [[0, 4], [5, 14], [15, 23], [24, 28], [29, 31], [32, 43], [44, 58], [59, 66], [67, 70], [70, 71], [71, 75], [76, 79], [80, 85], [86, 92], [93, 100], [101, 104], [105, 114], [115, 118], [119, 125], [126, 137], [138, 151], [151, 152]]}
{"doc_key": "ai-test-299", "ner": [[4, 4, "organisation"], [19, 21, "field"], [15, 15, "organisation"], [9, 14, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 19, 21, "general-affiliation", "field_of_study", false, false], [4, 4, 9, 14, "part-of", "", false, false], [15, 15, 4, 4, "role", "admits_E2_to", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "May", "2016", ",", "NtechLab", "was", "one", "of", "three", "Russian", "companies", "to", "be", "admitted", "to", "NIST", "'s", "official", "testing", "of", "biometric", "technologies", "."], "sentence-detokenized": "In May 2016, NtechLab was one of three Russian companies to be admitted to NIST's official testing of biometric technologies.", "token2charspan": [[0, 2], [3, 6], [7, 11], [11, 12], [13, 21], [22, 25], [26, 29], [30, 32], [33, 38], [39, 46], [47, 56], [57, 59], [60, 62], [63, 71], [72, 74], [75, 79], [79, 81], [82, 90], [91, 98], [99, 101], [102, 111], [112, 124], [124, 125]]}
{"doc_key": "ai-test-300", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["However", ",", "floating", "figures", "only", "have", "a", "certain", "mathematical", "precision", "."], "sentence-detokenized": "However, floating figures only have a certain mathematical precision.", "token2charspan": [[0, 7], [7, 8], [9, 17], [18, 25], [26, 30], [31, 35], [36, 37], [38, 45], [46, 58], [59, 68], [68, 69]]}
{"doc_key": "ai-test-301", "ner": [[9, 16, "conference"], [12, 18, "conference"]], "ner_mapping_to_source": [1, 2], "relations": [[12, 18, 9, 16, "named", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["During", "2015", ",", "several", "SenseTime", "publications", "were", "accepted", "for", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "(", "CVPR", ")", "."], "sentence-detokenized": "During 2015, several SenseTime publications were accepted for the Conference on Computer Vision and Pattern Recognition (CVPR).", "token2charspan": [[0, 6], [7, 11], [11, 12], [13, 20], [21, 30], [31, 43], [44, 48], [49, 57], [58, 61], [62, 65], [66, 76], [77, 79], [80, 88], [89, 95], [96, 99], [100, 107], [108, 119], [120, 121], [121, 125], [125, 126], [126, 127]]}
{"doc_key": "ai-test-302", "ner": [[11, 13, "task"], [15, 15, "task"], [17, 18, "task"], [20, 23, "task"], [25, 26, "field"], [28, 30, "misc"], [32, 38, "conference"], [46, 48, "misc"], [49, 51, "conference"], [67, 69, "misc"], [71, 71, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[11, 13, 25, 26, "part-of", "task_part_of_field", false, false], [15, 15, 11, 13, "named", "", false, false], [17, 18, 25, 26, "part-of", "task_part_of_field", false, false], [20, 23, 17, 18, "named", "", false, false], [28, 30, 32, 38, "temporal", "", false, false], [46, 48, 49, 51, "temporal", "", false, false], [67, 69, 71, 71, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["He", "has", "been", "involved", "in", "the", "development", "of", "optimal", "algorithms", "for", "Structure", "From", "Motion", "(", "SFM", "or", "Visual", "SLAM", ",", "simultaneous", "localization", "and", "mapping", ",", "in", "robotics", ";", "Best", "Paper", "Award", "at", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", "1998", ")", ",", "characterizing", "its", "ambiguities", "(", "David", "Marr", "Award", "at", "ICCV", "1999", ")", ",", "also", "characterizing", "the", "detectability", "and", "observability", "of", "visual", "and", "inertial", "sensor", "fusion", "(", "Best", "Paper", "Award", "at", "Robotics", "2015", ")", "."], "sentence-detokenized": "He has been involved in the development of optimal algorithms for Structure From Motion (SFM or Visual SLAM, simultaneous localization and mapping, in robotics; Best Paper Award at Conference on Computer Vision and Pattern Recognition 1998), characterizing its ambiguities (David Marr Award at ICCV 1999), also characterizing the detectability and observability of visual and inertial sensor fusion (Best Paper Award at Robotics 2015).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 20], [21, 23], [24, 27], [28, 39], [40, 42], [43, 50], [51, 61], [62, 65], [66, 75], [76, 80], [81, 87], [88, 89], [89, 92], [93, 95], [96, 102], [103, 107], [107, 108], [109, 121], [122, 134], [135, 138], [139, 146], [146, 147], [148, 150], [151, 159], [159, 160], [161, 165], [166, 171], [172, 177], [178, 180], [181, 191], [192, 194], [195, 203], [204, 210], [211, 214], [215, 222], [223, 234], [235, 239], [239, 240], [240, 241], [242, 256], [257, 260], [261, 272], [273, 274], [274, 279], [280, 284], [285, 290], [291, 293], [294, 298], [299, 303], [303, 304], [304, 305], [306, 310], [311, 325], [326, 329], [330, 343], [344, 347], [348, 361], [362, 364], [365, 371], [372, 375], [376, 384], [385, 391], [392, 398], [399, 400], [400, 404], [405, 410], [411, 416], [417, 419], [420, 428], [429, 433], [433, 434], [434, 435]]}
{"doc_key": "ai-test-303", "ner": [[0, 2, "researcher"], [3, 3, "organisation"], [5, 5, "organisation"], [7, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Stephen", "H.", "Muggleton", "FBCS", ",", "FIET", ",", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", ","], "sentence-detokenized": "Stephen H. Muggleton FBCS, FIET, Association for the Advancement of Artificial Intelligence,", "token2charspan": [[0, 7], [8, 10], [11, 20], [21, 25], [25, 26], [27, 31], [31, 32], [33, 44], [45, 48], [49, 52], [53, 64], [65, 67], [68, 78], [79, 91], [91, 92]]}
{"doc_key": "ai-test-304", "ner": [[0, 3, "task"], [6, 8, "field"], [10, 11, "field"], [13, 14, "field"], [17, 19, "task"], [21, 21, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 6, 8, "part-of", "task_part_of_field", false, false], [0, 3, 10, 11, "part-of", "task_part_of_field", false, false], [0, 3, 13, 14, "part-of", "task_part_of_field", false, false], [0, 3, 17, 19, "part-of", "", false, false], [0, 3, 21, 21, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Edge", "detection", "is", "a", "fundamental", "tool", "in", "image", "processing", ",", "machine", "vision", "and", "computer", "vision", ",", "especially", "for", "feature", "detection", "and", "extraction", "."], "sentence-detokenized": "Edge detection is a fundamental tool in image processing, machine vision and computer vision, especially for feature detection and extraction.", "token2charspan": [[0, 4], [5, 14], [15, 17], [18, 19], [20, 31], [32, 36], [37, 39], [40, 45], [46, 56], [56, 57], [58, 65], [66, 72], [73, 76], [77, 85], [86, 92], [92, 93], [94, 104], [105, 108], [109, 116], [117, 126], [127, 130], [131, 141], [141, 142]]}
{"doc_key": "ai-test-305", "ner": [[9, 10, "misc"], [25, 28, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "example", "of", "this", "is", "a", "variable", "such", "as", "outdoor", "temperature", "(", "mathtemp", "/", "math", ")", ",", "which", "in", "a", "given", "application", "can", "be", "recorded", "to", "several", "decimal", "places", "(", "depending", "on", "the", "sensor", "device", ")", "."], "sentence-detokenized": "An example of this is a variable such as outdoor temperature (mathtemp/math), which in a given application can be recorded to several decimal places (depending on the sensor device).", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 18], [19, 21], [22, 23], [24, 32], [33, 37], [38, 40], [41, 48], [49, 60], [61, 62], [62, 70], [70, 71], [71, 75], [75, 76], [76, 77], [78, 83], [84, 86], [87, 88], [89, 94], [95, 106], [107, 110], [111, 113], [114, 122], [123, 125], [126, 133], [134, 141], [142, 148], [149, 150], [150, 159], [160, 162], [163, 166], [167, 173], [174, 180], [180, 181], [181, 182]]}
{"doc_key": "ai-test-306", "ner": [[0, 1, "person"], [3, 4, "person"], [6, 7, "person"], [17, 18, "person"], [20, 20, "misc"], [24, 24, "misc"], [26, 27, "person"], [29, 29, "organisation"], [32, 33, "person"], [37, 38, "person"], [40, 40, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11], "relations": [[26, 27, 20, 20, "part-of", "", false, false], [26, 27, 24, 24, "role", "", false, false], [32, 33, 29, 29, "role", "", false, false], [40, 40, 37, 38, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4], "sentence": ["Fon", "Davis", ",", "Jessica", "Chobot", "and", "Leland", "Melvin", "return", "as", "judges", ",", "with", "celebrity", "guests", "including", "actor", "Clark", "Gregg", ",", "MythBusters", "host", "and", "former", "Battlebots", "builder", "Adam", "Savage", ",", "NFL", "tight", "end", "Vernon", "Davis", "and", "YouTube", "star", "Michael", "Stevens", "aka", "Vsauce", "."], "sentence-detokenized": "Fon Davis, Jessica Chobot and Leland Melvin return as judges, with celebrity guests including actor Clark Gregg, MythBusters host and former Battlebots builder Adam Savage, NFL tight end Vernon Davis and YouTube star Michael Stevens aka Vsauce.", "token2charspan": [[0, 3], [4, 9], [9, 10], [11, 18], [19, 25], [26, 29], [30, 36], [37, 43], [44, 50], [51, 53], [54, 60], [60, 61], [62, 66], [67, 76], [77, 83], [84, 93], [94, 99], [100, 105], [106, 111], [111, 112], [113, 124], [125, 129], [130, 133], [134, 140], [141, 151], [152, 159], [160, 164], [165, 171], [171, 172], [173, 176], [177, 182], [183, 186], [187, 193], [194, 199], [200, 203], [204, 211], [212, 216], [217, 224], [225, 232], [233, 236], [237, 243], [243, 244]]}
{"doc_key": "ai-test-307", "ner": [[10, 11, "algorithm"], [14, 16, "algorithm"], [12, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 12, 23, "part-of", "", false, false], [14, 16, 12, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "these", "methods", "never", "overcame", "the", "non-uniform", "internal", "handcrafting", "Gaussian", "mixture", "model", "/", "hidden", "Markov", "model", "(", "GMM", "-", "HMM", ")", ",", "which", "is", "based", "on", "discriminatively", "trained", "speech", "generative", "models", "."], "sentence-detokenized": "However, these methods never overcame the non-uniform internal handcrafting Gaussian mixture model/hidden Markov model (GMM-HMM), which is based on discriminatively trained speech generative models.", "token2charspan": [[0, 7], [7, 8], [9, 14], [15, 22], [23, 28], [29, 37], [38, 41], [42, 53], [54, 62], [63, 75], [76, 84], [85, 92], [93, 98], [98, 99], [99, 105], [106, 112], [113, 118], [119, 120], [120, 123], [123, 124], [124, 127], [127, 128], [128, 129], [130, 135], [136, 138], [139, 144], [145, 147], [148, 164], [165, 172], [173, 179], [180, 190], [191, 197], [197, 198]]}
{"doc_key": "ai-test-308", "ner": [[4, 4, "product"], [6, 7, "programlang"], [9, 9, "programlang"], [11, 11, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Software", "packages", "such", "as", "MATLAB", ",", "GNU", "Octave", ",", "Scilab", "and", "SciPy", "provide", "convenient", "ways", "to", "apply", "these", "different", "methods", "."], "sentence-detokenized": "Software packages such as MATLAB, GNU Octave, Scilab and SciPy provide convenient ways to apply these different methods.", "token2charspan": [[0, 8], [9, 17], [18, 22], [23, 25], [26, 32], [32, 33], [34, 37], [38, 44], [44, 45], [46, 52], [53, 56], [57, 62], [63, 70], [71, 81], [82, 86], [87, 89], [90, 95], [96, 101], [102, 111], [112, 119], [119, 120]]}
{"doc_key": "ai-test-309", "ner": [[1, 2, "algorithm"], [0, 4, "algorithm"], [16, 17, "researcher"], [18, 20, "university"], [22, 23, "researcher"], [25, 28, "organisation"], [24, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7], "relations": [[1, 2, 16, 17, "origin", "", false, false], [1, 2, 22, 23, "origin", "", false, false], [0, 4, 1, 2, "named", "", false, false], [16, 17, 18, 20, "physical", "", false, false], [16, 17, 18, 20, "role", "", false, false], [22, 23, 25, 28, "physical", "", false, false], [22, 23, 25, 28, "role", "", false, false], [24, 32, 25, 28, "named", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Linear", "Predictive", "Coding", "(", "LPC", ")", ",", "a", "speech", "processing", "algorithm", ",", "was", "first", "proposed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", "."], "sentence-detokenized": "Linear Predictive Coding (LPC), a speech processing algorithm, was first proposed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [30, 31], [32, 33], [34, 40], [41, 51], [52, 61], [61, 62], [63, 66], [67, 72], [73, 81], [82, 84], [85, 93], [94, 101], [102, 104], [105, 111], [112, 122], [123, 126], [127, 132], [133, 138], [139, 141], [142, 148], [149, 158], [159, 162], [163, 172], [173, 174], [174, 177], [177, 178], [179, 181], [182, 186], [186, 187]]}
{"doc_key": "ai-test-310", "ner": [[16, 24, "conference"], [18, 28, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 28, 16, 24, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "2006", ",", "on", "the", "25th", "anniversary", "of", "the", "algorithm", ",", "a", "workshop", "was", "held", "at", "the", "International", "Conference", "on", "Computer", "Vision", "and", "Image", "Recognition", "(", "CVPR", ")", "to", "summarise", "the", "latest", "contributions", "and", "modifications", "to", "the", "original", "algorithm", ",", "mainly", "aimed", "at", "improving", "its", "speed", ",", "robustness", "and", "accuracy", "of", "the", "estimated", "solutions", ",", "and", "reducing", "the", "dependence", "on", "user", "-", "defined", "constants", "."], "sentence-detokenized": "In 2006, on the 25th anniversary of the algorithm, a workshop was held at the International Conference on Computer Vision and Image Recognition (CVPR) to summarise the latest contributions and modifications to the original algorithm, mainly aimed at improving its speed, robustness and accuracy of the estimated solutions, and reducing the dependence on user-defined constants.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 20], [21, 32], [33, 35], [36, 39], [40, 49], [49, 50], [51, 52], [53, 61], [62, 65], [66, 70], [71, 73], [74, 77], [78, 91], [92, 102], [103, 105], [106, 114], [115, 121], [122, 125], [126, 131], [132, 143], [144, 145], [145, 149], [149, 150], [151, 153], [154, 163], [164, 167], [168, 174], [175, 188], [189, 192], [193, 206], [207, 209], [210, 213], [214, 222], [223, 232], [232, 233], [234, 240], [241, 246], [247, 249], [250, 259], [260, 263], [264, 269], [269, 270], [271, 281], [282, 285], [286, 294], [295, 297], [298, 301], [302, 311], [312, 321], [321, 322], [323, 326], [327, 335], [336, 339], [340, 350], [351, 353], [354, 358], [358, 359], [359, 366], [367, 376], [376, 377]]}
{"doc_key": "ai-test-311", "ner": [[3, 5, "university"], [8, 12, "organisation"], [13, 15, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Members", "visited", "the", "University", "of", "Debrecen", ",", "the", "Hungarian", "Academy", "of", "Sciences", "and", "E\u00f6tv\u00f6s", "Lor\u00e1nd", "University", ",", "among", "others", "."], "sentence-detokenized": "Members visited the University of Debrecen, the Hungarian Academy of Sciences and E\u00f6tv\u00f6s Lor\u00e1nd University, among others.", "token2charspan": [[0, 7], [8, 15], [16, 19], [20, 30], [31, 33], [34, 42], [42, 43], [44, 47], [48, 57], [58, 65], [66, 68], [69, 77], [78, 81], [82, 88], [89, 95], [96, 106], [106, 107], [108, 113], [114, 120], [120, 121]]}
{"doc_key": "ai-test-312", "ner": [[2, 3, "algorithm"], [16, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 3, 16, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["To", "extend", "the", "SVM", "to", "cases", "where", "the", "data", "are", "not", "linearly", "separable", ",", "we", "introduce", "a", "loss", "function", ","], "sentence-detokenized": "To extend the SVM to cases where the data are not linearly separable, we introduce a loss function,", "token2charspan": [[0, 2], [3, 9], [10, 13], [14, 17], [18, 20], [21, 26], [27, 32], [33, 36], [37, 41], [42, 45], [46, 49], [50, 58], [59, 68], [68, 69], [70, 72], [73, 82], [83, 84], [85, 89], [90, 98], [98, 99]]}
{"doc_key": "ai-test-313", "ner": [[0, 2, "programlang"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 10, 11, "origin", "", false, false], [0, 2, 13, 14, "origin", "", false, false], [0, 2, 16, 17, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Logo", "is", "an", "educational", "programming", "language", "designed", "in", "1967", "by", "Wally", "Feurzeig", ",", "Seymour", "Papert", "and", "Cynthia", "Solomon", "."], "sentence-detokenized": "Logo is an educational programming language designed in 1967 by Wally Feurzeig, Seymour Papert and Cynthia Solomon.", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 22], [23, 34], [35, 43], [44, 52], [53, 55], [56, 60], [61, 63], [64, 69], [70, 78], [78, 79], [80, 87], [88, 94], [95, 98], [99, 106], [107, 114], [114, 115]]}
{"doc_key": "ai-test-314", "ner": [[0, 2, "organisation"], [4, 9, "organisation"], [10, 14, "location"], [16, 16, "location"], [17, 18, "location"], [26, 32, "product"], [35, 40, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 4, 9, "role", "works_for", false, false], [4, 9, 10, 14, "physical", "", false, false], [10, 14, 16, 16, "physical", "", false, false], [16, 16, 17, 18, "physical", "", false, false], [26, 32, 0, 2, "origin", "", false, false], [35, 40, 26, 32, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "Eyring", "Institute", "helped", "the", "US", "Air", "Force", "Missile", "Division", "at", "Hill", "Air", "Force", "Base", "near", "Ogden", ",", "Utah", ",", "to", "produce", "the", "military", "-", "secret", "intelligent", "systems", "technology", "software", "that", "was", "the", "basis", "for", "Reagan", "'s", "later", "Star", "Wars", "programme", "."], "sentence-detokenized": "The Eyring Institute helped the US Air Force Missile Division at Hill Air Force Base near Ogden, Utah, to produce the military-secret intelligent systems technology software that was the basis for Reagan's later Star Wars programme.", "token2charspan": [[0, 3], [4, 10], [11, 20], [21, 27], [28, 31], [32, 34], [35, 38], [39, 44], [45, 52], [53, 61], [62, 64], [65, 69], [70, 73], [74, 79], [80, 84], [85, 89], [90, 95], [95, 96], [97, 101], [101, 102], [103, 105], [106, 113], [114, 117], [118, 126], [126, 127], [127, 133], [134, 145], [146, 153], [154, 164], [165, 173], [174, 178], [179, 182], [183, 186], [187, 192], [193, 196], [197, 203], [203, 205], [206, 211], [212, 216], [217, 221], [222, 231], [231, 232]]}
{"doc_key": "ai-test-315", "ner": [[12, 13, "field"], [24, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Over", "the", "decades", ",", "he", "has", "researched", "and", "developed", "new", "areas", "of", "computer", "science", ",", "such", "as", "compilers", ",", "programming", "languages", "and", "system", "architecture", "John", "F", ".", "Sowa", "and", "John", "Zachman", "(", "1992", ")", "."], "sentence-detokenized": "Over the decades, he has researched and developed new areas of computer science, such as compilers, programming languages and system architecture John F. Sowa and John Zachman (1992).", "token2charspan": [[0, 4], [5, 8], [9, 16], [16, 17], [18, 20], [21, 24], [25, 35], [36, 39], [40, 49], [50, 53], [54, 59], [60, 62], [63, 71], [72, 79], [79, 80], [81, 85], [86, 88], [89, 98], [98, 99], [100, 111], [112, 121], [122, 125], [126, 132], [133, 145], [146, 150], [151, 152], [152, 153], [154, 158], [159, 162], [163, 167], [168, 175], [176, 177], [177, 181], [181, 182], [182, 183]]}
{"doc_key": "ai-test-316", "ner": [[0, 2, "algorithm"], [6, 10, "algorithm"], [12, 13, "algorithm"], [17, 19, "field"], [21, 22, "field"], [25, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 10, 0, 2, "named", "", false, false], [12, 13, 0, 2, "named", "", false, false], [17, 19, 0, 2, "usage", "", false, false], [21, 22, 0, 2, "usage", "", false, false], [25, 28, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "Sobel", "operator", ",", "sometimes", "called", "the", "Sobel", "-", "Feldman", "operator", "or", "Sobel", "filter", ",", "is", "used", "in", "image", "processing", "and", "computer", "vision", ",", "particularly", "in", "edge", "detection", "algorithms", ",", "where", "it", "creates", "an", "image", "with", "highlighted", "edges", "."], "sentence-detokenized": "The Sobel operator, sometimes called the Sobel-Feldman operator or Sobel filter, is used in image processing and computer vision, particularly in edge detection algorithms, where it creates an image with highlighted edges.", "token2charspan": [[0, 3], [4, 9], [10, 18], [18, 19], [20, 29], [30, 36], [37, 40], [41, 46], [46, 47], [47, 54], [55, 63], [64, 66], [67, 72], [73, 79], [79, 80], [81, 83], [84, 88], [89, 91], [92, 97], [98, 108], [109, 112], [113, 121], [122, 128], [128, 129], [130, 142], [143, 145], [146, 150], [151, 160], [161, 171], [171, 172], [173, 178], [179, 181], [182, 189], [190, 192], [193, 198], [199, 203], [204, 215], [216, 221], [221, 222]]}
{"doc_key": "ai-test-317", "ner": [[0, 0, "algorithm"], [3, 3, "field"], [17, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 3, 3, "compare", "", false, false], [0, 0, 3, 3, "type-of", "", false, false], [0, 0, 17, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["LDA", "is", "a", "supervised", "learning", "algorithm", "that", "takes", "advantage", "of", "the", "labels", "in", "the", "data", ",", "while", "PCA", "is", "a", "learning", "algorithm", "that", "ignores", "the", "labels", "."], "sentence-detokenized": "LDA is a supervised learning algorithm that takes advantage of the labels in the data, while PCA is a learning algorithm that ignores the labels.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 19], [20, 28], [29, 38], [39, 43], [44, 49], [50, 59], [60, 62], [63, 66], [67, 73], [74, 76], [77, 80], [81, 85], [85, 86], [87, 92], [93, 96], [97, 99], [100, 101], [102, 110], [111, 120], [121, 125], [126, 133], [134, 137], [138, 144], [144, 145]]}
{"doc_key": "ai-test-318", "ner": [[5, 5, "algorithm"], [7, 9, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "linear", "classification", "algorithms", "include", "Winnow", ",", "support", "vector", "machine", "and", "logistic", "regression", "."], "sentence-detokenized": "Other linear classification algorithms include Winnow, support vector machine and logistic regression.", "token2charspan": [[0, 5], [6, 12], [13, 27], [28, 38], [39, 46], [47, 53], [53, 54], [55, 62], [63, 69], [70, 77], [78, 81], [82, 90], [91, 101], [101, 102]]}
{"doc_key": "ai-test-319", "ner": [[0, 1, "product"], [16, 18, "product"], [20, 20, "programlang"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[0, 1, 16, 18, "general-affiliation", "", true, false], [0, 1, 20, 20, "general-affiliation", "", true, false], [0, 1, 22, 22, "general-affiliation", "", true, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["The", "VTK", "consists", "of", "a", "C", "++", "class", "library", "and", "several", "interpreted", "interface", "layers", "such", "as", "Tcl", "/", "Tk", ",", "Java", "and", "Python", "."], "sentence-detokenized": "The VTK consists of a C++ class library and several interpreted interface layers such as Tcl/Tk, Java and Python.", "token2charspan": [[0, 3], [4, 7], [8, 16], [17, 19], [20, 21], [22, 23], [23, 25], [26, 31], [32, 39], [40, 43], [44, 51], [52, 63], [64, 73], [74, 80], [81, 85], [86, 88], [89, 92], [92, 93], [93, 95], [95, 96], [97, 101], [102, 105], [106, 112], [112, 113]]}
{"doc_key": "ai-test-320", "ner": [[7, 9, "task"], [15, 18, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Text", "produced", "by", "processing", "spontaneous", "speech", "with", "automatic", "speech", "recognition", "and", "printed", "or", "handwritten", "text", "with", "optical", "character", "recognition", "also", "contains", "processing", "errors", "."], "sentence-detokenized": "Text produced by processing spontaneous speech with automatic speech recognition and printed or handwritten text with optical character recognition also contains processing errors.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 27], [28, 39], [40, 46], [47, 51], [52, 61], [62, 68], [69, 80], [81, 84], [85, 92], [93, 95], [96, 107], [108, 112], [113, 117], [118, 125], [126, 135], [136, 147], [148, 152], [153, 161], [162, 172], [173, 179], [179, 180]]}
{"doc_key": "ai-test-321", "ner": [[0, 0, "researcher"], [9, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 9, 9, "role", "directs_development_of", false, false]], "relations_mapping_to_source": [0], "sentence": ["Miller", "wrote", "several", "books", "and", "led", "the", "development", "of", "WordNet", ",", "an", "online", "database", "used", "by", "computer", "programs", "."], "sentence-detokenized": "Miller wrote several books and led the development of WordNet, an online database used by computer programs.", "token2charspan": [[0, 6], [7, 12], [13, 20], [21, 26], [27, 30], [31, 34], [35, 38], [39, 50], [51, 53], [54, 61], [61, 62], [63, 65], [66, 72], [73, 81], [82, 86], [87, 89], [90, 98], [99, 107], [107, 108]]}
{"doc_key": "ai-test-322", "ner": [[1, 1, "field"], [3, 5, "organisation"], [6, 8, "country"], [10, 11, "person"], [13, 15, "person"], [17, 18, "person"], [20, 21, "person"], [22, 24, "country"], [26, 30, "location"], [31, 32, "misc"], [33, 34, "person"], [36, 37, "person"], [38, 39, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[3, 5, 6, 8, "physical", "", false, false], [10, 11, 22, 24, "physical", "", false, false], [13, 15, 22, 24, "physical", "", false, false], [17, 18, 22, 24, "physical", "", false, false], [20, 21, 22, 24, "physical", "", false, false], [26, 30, 1, 1, "general-affiliation", "", false, false], [26, 30, 33, 34, "artifact", "", false, false], [31, 32, 33, 34, "named", "", false, false], [36, 37, 38, 39, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Modern", "automatons", "include", "Cabaret", "Mechanical", "Theatre", "in", "the", "UK", ",", "Dug", "North", "and", "Chomick", "+", "Meder", ",", "Arthur", "Ganson", ",", "Joe", "Jones", "in", "the", "US", ",", "Le", "D\u00e9fenseur", "du", "Temps", "by", "French", "artist", "Jacques", "Monestier", "and", "Fran\u00e7ois", "Junod", "in", "Switzerland", "."], "sentence-detokenized": "Modern automatons include Cabaret Mechanical Theatre in the UK, Dug North and Chomick + Meder, Arthur Ganson, Joe Jones in the US, Le D\u00e9fenseur du Temps by French artist Jacques Monestier and Fran\u00e7ois Junod in Switzerland.", "token2charspan": [[0, 6], [7, 17], [18, 25], [26, 33], [34, 44], [45, 52], [53, 55], [56, 59], [60, 62], [62, 63], [64, 67], [68, 73], [74, 77], [78, 85], [86, 87], [88, 93], [93, 94], [95, 101], [102, 108], [108, 109], [110, 113], [114, 119], [120, 122], [123, 126], [127, 129], [129, 130], [131, 133], [134, 143], [144, 146], [147, 152], [153, 155], [156, 162], [163, 169], [170, 177], [178, 187], [188, 191], [192, 200], [201, 206], [207, 209], [210, 221], [221, 222]]}
{"doc_key": "ai-test-323", "ner": [[0, 0, "product"], [22, 24, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 22, 24, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["MATLAB", "includes", "the", "usual", "codefor", "/", "code", "and", "codewhile", "/", "code", "loops", ",", "but", "(", "as", "in", "other", "similar", "applications", "such", "as", "R", ")", "it", "is", "preferable", "and", "often", "faster", "to", "use", "the", "vector", "notation", "."], "sentence-detokenized": "MATLAB includes the usual codefor/code and codewhile/code loops, but (as in other similar applications such as R) it is preferable and often faster to use the vector notation.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 25], [26, 33], [33, 34], [34, 38], [39, 42], [43, 52], [52, 53], [53, 57], [58, 63], [63, 64], [65, 68], [69, 70], [70, 72], [73, 75], [76, 81], [82, 89], [90, 102], [103, 107], [108, 110], [111, 112], [112, 113], [114, 116], [117, 119], [120, 130], [131, 134], [135, 140], [141, 147], [148, 150], [151, 154], [155, 158], [159, 165], [166, 174], [174, 175]]}
{"doc_key": "ai-test-324", "ner": [[3, 3, "researcher"], [8, 12, "conference"], [16, 19, "field"], [22, 29, "misc"], [32, 41, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 22, 29, "win-defeat", "", false, false], [3, 3, 32, 41, "win-defeat", "", false, false], [22, 29, 8, 12, "temporal", "", false, false], [22, 29, 16, 19, "topic", "", false, false], [32, 41, 8, 12, "temporal", "", false, false], [32, 41, 16, 19, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2007", ",", "Pausch", "received", "two", "awards", "from", "the", "Association", "for", "Computing", "Machinery", "for", "his", "achievements", "in", "computer", "science", "education", ":", "the", "Karl", "V", ".", "Karl", "Karlstrom", "Outstanding", "Educator", "Award", "and", "the", "ACM", "SIGCSE", "Award", "for", "Outstanding", "Contributions", "to", "Computer", "Science", "Education", "."], "sentence-detokenized": "In 2007, Pausch received two awards from the Association for Computing Machinery for his achievements in computer science education: the Karl V. Karl Karlstrom Outstanding Educator Award and the ACM SIGCSE Award for Outstanding Contributions to Computer Science Education.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 24], [25, 28], [29, 35], [36, 40], [41, 44], [45, 56], [57, 60], [61, 70], [71, 80], [81, 84], [85, 88], [89, 101], [102, 104], [105, 113], [114, 121], [122, 131], [131, 132], [133, 136], [137, 141], [142, 143], [143, 144], [145, 149], [150, 159], [160, 171], [172, 180], [181, 186], [187, 190], [191, 194], [195, 198], [199, 205], [206, 211], [212, 215], [216, 227], [228, 241], [242, 244], [245, 253], [254, 261], [262, 271], [271, 272]]}
{"doc_key": "ai-test-325", "ner": [[3, 3, "person"], [8, 12, "product"], [16, 18, "organisation"]], "ner_mapping_to_source": [0, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "delivered", "in", "1961", "to", "General", "Motors", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was delivered in 1961 to General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 75], [76, 78], [79, 83], [84, 86], [87, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-test-326", "ner": [[0, 1, "algorithm"], [5, 6, "field"], [11, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 0, 1, "usage", "", false, false], [11, 12, 5, 6, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Semantic", "webs", "are", "used", "in", "natural", "language", "processing", "applications", "such", "as", "semantic", "parsing", "."], "sentence-detokenized": "Semantic webs are used in natural language processing applications such as semantic parsing.", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 22], [23, 25], [26, 33], [34, 42], [43, 53], [54, 66], [67, 71], [72, 74], [75, 83], [84, 91], [91, 92]]}
{"doc_key": "ai-test-327", "ner": [[4, 5, "field"], [7, 8, "field"], [10, 11, "task"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[7, 8, 4, 5, "usage", "", false, false], [10, 11, 4, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Some", "successful", "applications", "of", "deep", "learning", "include", "computer", "vision", "and", "speech", "recognition", ".", "Honglak", "Lee", ",", "Roger", "Grosse", ",", "Rajesh", "Ranganath", ",", "Andrew", "Y", ".", "Ng", "."], "sentence-detokenized": "Some successful applications of deep learning include computer vision and speech recognition. Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng.", "token2charspan": [[0, 4], [5, 15], [16, 28], [29, 31], [32, 36], [37, 45], [46, 53], [54, 62], [63, 69], [70, 73], [74, 80], [81, 92], [92, 93], [94, 101], [102, 105], [105, 106], [107, 112], [113, 119], [119, 120], [121, 127], [128, 137], [137, 138], [139, 145], [146, 147], [147, 148], [149, 151], [151, 152]]}
{"doc_key": "ai-test-328", "ner": [[7, 10, "product"], [16, 16, "misc"], [19, 22, "misc"], [0, 26, "product"], [29, 30, "task"], [32, 33, "task"], [35, 36, "task"], [38, 40, "field"], [42, 43, "task"], [45, 46, "field"], [48, 49, "task"], [51, 52, "task"], [54, 55, "task"], [57, 57, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[7, 10, 16, 16, "physical", "travels_to", false, false], [7, 10, 19, 22, "physical", "travels_to", false, false], [0, 26, 7, 10, "part-of", "", false, false], [0, 26, 7, 10, "role", "maintains", false, false], [0, 26, 29, 30, "related-to", "has_ability_to", false, false], [0, 26, 32, 33, "related-to", "has_ability_to", false, false], [0, 26, 35, 36, "related-to", "has_ability_to", false, false], [0, 26, 38, 40, "related-to", "has_ability_to", false, false], [0, 26, 42, 43, "related-to", "has_ability_to", false, false], [0, 26, 45, 46, "related-to", "has_ability_to", false, false], [0, 26, 48, 49, "related-to", "has_ability_to", false, false], [0, 26, 51, 52, "related-to", "has_ability_to", false, false], [0, 26, 54, 55, "related-to", "has_ability_to", false, false], [0, 26, 57, 57, "related-to", "has_ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["In", "addition", "to", "being", "able", "to", "maintain", "Discovery", "One", "'s", "systems", "during", "an", "interplanetary", "mission", "to", "Jupiter", "(", "or", "Saturn", "in", "the", "novel", ")", ",", "HAL", "is", "capable", "of", "speech", "synthesis", ",", "speech", "recognition", ",", "face", "recognition", ",", "natural", "language", "processing", ",", "lip", "reading", ",", "art", "appreciation", ",", "affective", "computing", ",", "automated", "reasoning", ",", "spacecraft", "piloting", "and", "chess", "."], "sentence-detokenized": "In addition to being able to maintain Discovery One's systems during an interplanetary mission to Jupiter (or Saturn in the novel), HAL is capable of speech synthesis, speech recognition, face recognition, natural language processing, lip reading, art appreciation, affective computing, automated reasoning, spacecraft piloting and chess.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 20], [21, 25], [26, 28], [29, 37], [38, 47], [48, 51], [51, 53], [54, 61], [62, 68], [69, 71], [72, 86], [87, 94], [95, 97], [98, 105], [106, 107], [107, 109], [110, 116], [117, 119], [120, 123], [124, 129], [129, 130], [130, 131], [132, 135], [136, 138], [139, 146], [147, 149], [150, 156], [157, 166], [166, 167], [168, 174], [175, 186], [186, 187], [188, 192], [193, 204], [204, 205], [206, 213], [214, 222], [223, 233], [233, 234], [235, 238], [239, 246], [246, 247], [248, 251], [252, 264], [264, 265], [266, 275], [276, 285], [285, 286], [287, 296], [297, 306], [306, 307], [308, 318], [319, 327], [328, 331], [332, 337], [337, 338]]}
{"doc_key": "ai-test-329", "ner": [[0, 1, "researcher"], [3, 4, "country"], [5, 8, "country"], [11, 11, "country"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 3, 4, "physical", "", false, false], [0, 1, 5, 8, "physical", "", false, false], [0, 1, 11, 11, "cause-effect", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Dr", "Julesz", "moved", "from", "Hungary", "to", "the", "United", "States", "after", "the", "Soviet", "invasion", "in", "1956", "."], "sentence-detokenized": "Dr Julesz moved from Hungary to the United States after the Soviet invasion in 1956.", "token2charspan": [[0, 2], [3, 9], [10, 15], [16, 20], [21, 28], [29, 31], [32, 35], [36, 42], [43, 49], [50, 55], [56, 59], [60, 66], [67, 75], [76, 78], [79, 83], [83, 84]]}
{"doc_key": "ai-test-330", "ner": [[0, 0, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sigmoid", "activation", "functions", "use", "a", "second", "nonlinearity", "for", "large", "inputs", ":", "math", "\\", "phi", "(", "v", "_", "i", ")", "=", "(", "1", "+\\", "exp", "(", "-", "v", "_", "i", ")", ")", "^", "{", "-1", "}", "/", "math", "."], "sentence-detokenized": "Sigmoid activation functions use a second nonlinearity for large inputs: math\\ phi (v _ i) = (1 +\\ exp (-v _ i)) ^ {-1} / math.", "token2charspan": [[0, 7], [8, 18], [19, 28], [29, 32], [33, 34], [35, 41], [42, 54], [55, 58], [59, 64], [65, 71], [71, 72], [73, 77], [77, 78], [79, 82], [83, 84], [84, 85], [86, 87], [88, 89], [89, 90], [91, 92], [93, 94], [94, 95], [96, 98], [99, 102], [103, 104], [104, 105], [105, 106], [107, 108], [109, 110], [110, 111], [111, 112], [113, 114], [115, 116], [116, 118], [118, 119], [120, 121], [122, 126], [126, 127]]}
{"doc_key": "ai-test-331", "ner": [[13, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "probabilities", "are", "used", "to", "determine", "what", "the", "target", "is", ",", "using", "a", "maximum", "likelihood", "decision", "."], "sentence-detokenized": "These probabilities are used to determine what the target is, using a maximum likelihood decision.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 28], [29, 31], [32, 41], [42, 46], [47, 50], [51, 57], [58, 60], [60, 61], [62, 67], [68, 69], [70, 77], [78, 88], [89, 97], [97, 98]]}
{"doc_key": "ai-test-332", "ner": [[6, 8, "university"], [12, 16, "university"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1984", "he", "moved", "to", "the", "University", "of", "Konstanz", "and", "in", "1990", "to", "the", "University", "of", "Salzburg", "."], "sentence-detokenized": "In 1984 he moved to the University of Konstanz and in 1990 to the University of Salzburg.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 16], [17, 19], [20, 23], [24, 34], [35, 37], [38, 46], [47, 50], [51, 53], [54, 58], [59, 61], [62, 65], [66, 76], [77, 79], [80, 88], [88, 89]]}
{"doc_key": "ai-test-333", "ner": [[2, 2, "metrics"], [13, 15, "metrics"], [17, 19, "metrics"], [21, 21, "metrics"], [23, 24, "metrics"], [26, 28, "metrics"], [30, 33, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[13, 15, 2, 2, "origin", "based_on", false, false], [17, 19, 2, 2, "origin", "based_on", false, false], [21, 21, 2, 2, "origin", "based_on", false, false], [23, 24, 2, 2, "origin", "based_on", false, false], [26, 28, 2, 2, "origin", "based_on", false, false], [30, 33, 2, 2, "origin", "based_on", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Some", "popular", "confusion", "matrix", "-", "based", "goodness", "-", "of", "-", "fit", "functions", "include", "sensitivity", "/", "specificity", ",", "recovery", "/", "precision", ",", "F-measure", ",", "Jaccard", "similarity", ",", "Matthews", "correlation", "coefficient", "and", "cost", "/", "profit", "matrix", ",", "which", "combines", "the", "costs", "and", "profits", "determined", "for", "four", "different", "types", "of", "classification", "."], "sentence-detokenized": "Some popular confusion matrix-based goodness-of-fit functions include sensitivity/specificity, recovery/precision, F-measure, Jaccard similarity, Matthews correlation coefficient and cost/profit matrix, which combines the costs and profits determined for four different types of classification.", "token2charspan": [[0, 4], [5, 12], [13, 22], [23, 29], [29, 30], [30, 35], [36, 44], [44, 45], [45, 47], [47, 48], [48, 51], [52, 61], [62, 69], [70, 81], [81, 82], [82, 93], [93, 94], [95, 103], [103, 104], [104, 113], [113, 114], [115, 124], [124, 125], [126, 133], [134, 144], [144, 145], [146, 154], [155, 166], [167, 178], [179, 182], [183, 187], [187, 188], [188, 194], [195, 201], [201, 202], [203, 208], [209, 217], [218, 221], [222, 227], [228, 231], [232, 239], [240, 250], [251, 254], [255, 259], [260, 269], [270, 275], [276, 278], [279, 293], [293, 294]]}
{"doc_key": "ai-test-334", "ner": [[6, 6, "product"], [8, 8, "product"], [10, 10, "product"], [12, 12, "product"], [15, 16, "programlang"], [25, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[25, 27, 6, 6, "part-of", "", false, false], [25, 27, 8, 8, "part-of", "", false, false], [25, 27, 10, 10, "part-of", "", false, false], [25, 27, 12, 12, "part-of", "", false, false], [25, 27, 15, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Common", "numerical", "programming", "environments", "such", "as", "MATLAB", ",", "SciLab", ",", "NumPy", ",", "Sklearn", "and", "the", "R", "language", "provide", "some", "simpler", "feature", "extraction", "techniques", "(", "e.g.", "principal", "component", "analysis", ")", "using", "built", "-", "in", "commands", "."], "sentence-detokenized": "Common numerical programming environments such as MATLAB, SciLab, NumPy, Sklearn and the R language provide some simpler feature extraction techniques (e.g. principal component analysis) using built-in commands.", "token2charspan": [[0, 6], [7, 16], [17, 28], [29, 41], [42, 46], [47, 49], [50, 56], [56, 57], [58, 64], [64, 65], [66, 71], [71, 72], [73, 80], [81, 84], [85, 88], [89, 90], [91, 99], [100, 107], [108, 112], [113, 120], [121, 128], [129, 139], [140, 150], [151, 152], [152, 156], [157, 166], [167, 176], [177, 185], [185, 186], [187, 192], [193, 198], [198, 199], [199, 201], [202, 210], [210, 211]]}
{"doc_key": "ai-test-335", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Industrial", "robots", "have", "been", "deployed", "to", "collaborate", "with", "humans", "to", "perform", "industrial", "manufacturing", "tasks", "."], "sentence-detokenized": "Industrial robots have been deployed to collaborate with humans to perform industrial manufacturing tasks.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 27], [28, 36], [37, 39], [40, 51], [52, 56], [57, 63], [64, 66], [67, 74], [75, 85], [86, 99], [100, 105], [105, 106]]}
{"doc_key": "ai-test-336", "ner": [[6, 6, "field"], [8, 11, "researcher"], [20, 22, "field"], [24, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 20, 22, "related-to", "", false, false], [6, 6, 24, 25, "related-to", "", false, false], [6, 6, 27, 28, "related-to", "", false, false], [8, 11, 6, 6, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "his", "first", "published", "article", "on", "CG", ",", "John", "F", ".", "Sowa", "applied", "them", "to", "a", "wide", "range", "of", "topics", "in", "artificial", "intelligence", ",", "computer", "science", "and", "cognitive", "science", "."], "sentence-detokenized": "In his first published article on CG, John F. Sowa applied them to a wide range of topics in artificial intelligence, computer science and cognitive science.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 22], [23, 30], [31, 33], [34, 36], [36, 37], [38, 42], [43, 44], [44, 45], [46, 50], [51, 58], [59, 63], [64, 66], [67, 68], [69, 73], [74, 79], [80, 82], [83, 89], [90, 92], [93, 103], [104, 116], [116, 117], [118, 126], [127, 134], [135, 138], [139, 148], [149, 156], [156, 157]]}
{"doc_key": "ai-test-337", "ner": [[0, 0, "metrics"], [4, 4, "metrics"], [10, 11, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["NIST", "also", "differs", "from", "BLEU", "in", "the", "calculation", "of", "the", "shortness", "penalty", ",", "as", "small", "variations", "in", "the", "length", "of", "a", "turn", "do", "not", "affect", "the", "total", "score", "as", "much", "."], "sentence-detokenized": "NIST also differs from BLEU in the calculation of the shortness penalty, as small variations in the length of a turn do not affect the total score as much.", "token2charspan": [[0, 4], [5, 9], [10, 17], [18, 22], [23, 27], [28, 30], [31, 34], [35, 46], [47, 49], [50, 53], [54, 63], [64, 71], [71, 72], [73, 75], [76, 81], [82, 92], [93, 95], [96, 99], [100, 106], [107, 109], [110, 111], [112, 116], [117, 119], [120, 123], [124, 130], [131, 134], [135, 140], [141, 146], [147, 149], [150, 154], [154, 155]]}
{"doc_key": "ai-test-338", "ner": [[0, 7, "misc"], [18, 19, "field"]], "ner_mapping_to_source": [0, 2], "relations": [[0, 7, 18, 19, "topic", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["The", "IJCAI", "Award", "for", "Research", "Excellence", "is", "a", "bi-annual", "award", "presented", "at", "the", "IJCAI", "conference", "to", "researchers", "in", "AI", "in", "recognition", "of", "their", "career", "excellence", "."], "sentence-detokenized": "The IJCAI Award for Research Excellence is a bi-annual award presented at the IJCAI conference to researchers in AI in recognition of their career excellence.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 19], [20, 28], [29, 39], [40, 42], [43, 44], [45, 54], [55, 60], [61, 70], [71, 73], [74, 77], [78, 83], [84, 94], [95, 97], [98, 109], [110, 112], [113, 115], [116, 118], [119, 130], [131, 133], [134, 139], [140, 146], [147, 157], [157, 158]]}
{"doc_key": "ai-test-339", "ner": [[0, 0, "researcher"], [9, 12, "conference"], [20, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 9, 12, "role", "", false, false], [0, 0, 20, 27, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Lenat", "was", "one", "of", "the", "original", "members", "of", "the", "AAAI", "and", "is", "the", "only", "person", "to", "have", "served", "on", "the", "scientific", "advisory", "boards", "of", "both", "Microsoft", "and", "Apple", "."], "sentence-detokenized": "Lenat was one of the original members of the AAAI and is the only person to have served on the scientific advisory boards of both Microsoft and Apple.", "token2charspan": [[0, 5], [6, 9], [10, 13], [14, 16], [17, 20], [21, 29], [30, 37], [38, 40], [41, 44], [45, 49], [50, 53], [54, 56], [57, 60], [61, 65], [66, 72], [73, 75], [76, 80], [81, 87], [88, 90], [91, 94], [95, 105], [106, 114], [115, 121], [122, 124], [125, 129], [130, 139], [140, 143], [144, 149], [149, 150]]}
{"doc_key": "ai-test-340", "ner": [[0, 0, "algorithm"], [5, 6, "misc"], [10, 12, "metrics"], [17, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 6, "related-to", "minimise", false, false], [10, 12, 5, 6, "type-of", "", false, false], [17, 17, 5, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Autocoders", "are", "trained", "to", "minimise", "reconstruction", "errors", "(", "such", "as", "mean", "square", "error", ")", ",", "often", "called", "loss", ":"], "sentence-detokenized": "Autocoders are trained to minimise reconstruction errors (such as mean square error), often called loss:", "token2charspan": [[0, 10], [11, 14], [15, 22], [23, 25], [26, 34], [35, 49], [50, 56], [57, 58], [58, 62], [63, 65], [66, 70], [71, 77], [78, 83], [83, 84], [84, 85], [86, 91], [92, 98], [99, 103], [103, 104]]}
{"doc_key": "ai-test-341", "ner": [[27, 28, "misc"], [23, 32, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[23, 32, 27, 28, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "alternative", "to", "using", "definitions", "is", "to", "look", "at", "the", "overall", "word", "sense", "relatedness", "and", "calculate", "the", "similarity", "of", "each", "word", "sense", "pair", "based", "on", "a", "given", "lexical", "database", ",", "such", "as", "WordNet", "."], "sentence-detokenized": "An alternative to using definitions is to look at the overall word sense relatedness and calculate the similarity of each word sense pair based on a given lexical database, such as WordNet.", "token2charspan": [[0, 2], [3, 14], [15, 17], [18, 23], [24, 35], [36, 38], [39, 41], [42, 46], [47, 49], [50, 53], [54, 61], [62, 66], [67, 72], [73, 84], [85, 88], [89, 98], [99, 102], [103, 113], [114, 116], [117, 121], [122, 126], [127, 132], [133, 137], [138, 143], [144, 146], [147, 148], [149, 154], [155, 162], [163, 171], [171, 172], [173, 177], [178, 180], [181, 188], [188, 189]]}
{"doc_key": "ai-test-342", "ner": [[0, 4, "algorithm"], [9, 11, "researcher"], [15, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 4, 9, 11, "origin", "", false, false], [9, 11, 15, 17, "role", "work_based_on_work_of", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["TD", "-", "Lambda", "is", "a", "learning", "algorithm", "invented", "by", "Richard", "S.", "Sutton", ",", "based", "on", "Arthur", "Samuel", "'s", "earlier", "work", "on", "learning", "temporal", "difference", "."], "sentence-detokenized": "TD-Lambda is a learning algorithm invented by Richard S. Sutton, based on Arthur Samuel's earlier work on learning temporal difference.", "token2charspan": [[0, 2], [2, 3], [3, 9], [10, 12], [13, 14], [15, 23], [24, 33], [34, 42], [43, 45], [46, 53], [54, 56], [57, 63], [63, 64], [65, 70], [71, 73], [74, 80], [81, 87], [87, 89], [90, 97], [98, 102], [103, 105], [106, 114], [115, 123], [124, 134], [134, 135]]}
{"doc_key": "ai-test-343", "ner": [[0, 2, "field"], [4, 4, "field"], [6, 7, "task"], [13, 14, "task"], [12, 19, "task"], [20, 22, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 7, 0, 2, "part-of", "task_part_of_field", false, false], [6, 7, 4, 4, "part-of", "task_part_of_field", false, false], [13, 14, 6, 7, "named", "", false, false], [12, 19, 6, 7, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "data", "mining", "and", "statistics", ",", "hierarchical", "clustering", "(", "also", "known", "as", "hierarchical", "cluster", "analysis", "or", "HCA", ")", "is", "a", "cluster", "analysis", "method", "that", "aims", "to", "build", "a", "hierarchy", "of", "clusters", "."], "sentence-detokenized": "In data mining and statistics, hierarchical clustering (also known as hierarchical cluster analysis or HCA) is a cluster analysis method that aims to build a hierarchy of clusters.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 18], [19, 29], [29, 30], [31, 43], [44, 54], [55, 56], [56, 60], [61, 66], [67, 69], [70, 82], [83, 90], [91, 99], [100, 102], [103, 106], [106, 107], [108, 110], [111, 112], [113, 120], [121, 129], [130, 136], [137, 141], [142, 146], [147, 149], [150, 155], [156, 157], [158, 167], [168, 170], [171, 179], [179, 180]]}
{"doc_key": "ai-test-344", "ner": [[3, 4, "algorithm"], [8, 9, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 8, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "concept", "of", "deconvolution", "is", "widely", "used", "in", "signal", "processing", "and", "image", "processing", "techniques", "."], "sentence-detokenized": "The concept of deconvolution is widely used in signal processing and image processing techniques.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 28], [29, 31], [32, 38], [39, 43], [44, 46], [47, 53], [54, 64], [65, 68], [69, 74], [75, 85], [86, 96], [96, 97]]}
{"doc_key": "ai-test-345", "ner": [[0, 1, "algorithm"], [22, 23, "misc"], [26, 26, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 22, 23, "related-to", "enhances", false, false], [0, 1, 22, 23, "related-to", "reduces", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Cognitive", "maps", "can", "be", "used", "to", "build", "and", "collect", "spatial", "information", ",", "allowing", "the", "mind", "'s", "eye", "to", "visualise", "images", "to", "reduce", "cognitive", "load", "and", "enhance", "recall", "and", "learning", "."], "sentence-detokenized": "Cognitive maps can be used to build and collect spatial information, allowing the mind's eye to visualise images to reduce cognitive load and enhance recall and learning.", "token2charspan": [[0, 9], [10, 14], [15, 18], [19, 21], [22, 26], [27, 29], [30, 35], [36, 39], [40, 47], [48, 55], [56, 67], [67, 68], [69, 77], [78, 81], [82, 86], [86, 88], [89, 92], [93, 95], [96, 105], [106, 112], [113, 115], [116, 122], [123, 132], [133, 137], [138, 141], [142, 149], [150, 156], [157, 160], [161, 169], [169, 170]]}
{"doc_key": "ai-test-346", "ner": [[9, 9, "programlang"], [11, 12, "programlang"], [5, 14, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": [",", "which", "usually", "provides", "bindings", "for", "languages", "such", "as", "Python", ",", "C", "++", "and", "Java", ")", "."], "sentence-detokenized": ", which usually provides bindings for languages such as Python, C++ and Java).", "token2charspan": [[0, 1], [2, 7], [8, 15], [16, 24], [25, 33], [34, 37], [38, 47], [48, 52], [53, 55], [56, 62], [62, 63], [64, 65], [65, 67], [68, 71], [72, 76], [76, 77], [77, 78]]}
{"doc_key": "ai-test-347", "ner": [[0, 4, "product"], [12, 13, "task"], [17, 18, "task"], [27, 30, "task"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Voice", "User", "Interface", "(", "VUI", ")", "enables", "spoken", "interaction", "with", "computers", "using", "speech", "recognition", "to", "understand", "and", "respond", "to", "spoken", "commands", "and", ",", "in", "general", ",", "to", "convert", "text", "to", "speech", "to", "reproduce", "the", "response", "."], "sentence-detokenized": "Voice User Interface (VUI) enables spoken interaction with computers using speech recognition to understand and respond to spoken commands and, in general, to convert text to speech to reproduce the response.", "token2charspan": [[0, 5], [6, 10], [11, 20], [21, 22], [22, 25], [25, 26], [27, 34], [35, 41], [42, 53], [54, 58], [59, 68], [69, 74], [75, 81], [82, 93], [94, 96], [97, 107], [108, 111], [112, 119], [120, 122], [123, 129], [130, 138], [139, 142], [142, 143], [144, 146], [147, 154], [154, 155], [156, 158], [159, 166], [167, 171], [172, 174], [175, 181], [182, 184], [185, 194], [195, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-test-348", "ner": [[0, 0, "programlang"], [3, 8, "misc"], [12, 15, "researcher"], [16, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4], "relations": [[0, 0, 3, 8, "general-affiliation", "is_a", false, false], [0, 0, 12, 15, "origin", "", false, false], [12, 15, 16, 18, "role", "", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["Jess", "is", "a", "rules", "engine", "for", "the", "Java", "platform", ",", "developed", "by", "Ernest", "Friedman", "-", "Hill", "of", "Sandia", "National", "."], "sentence-detokenized": "Jess is a rules engine for the Java platform, developed by Ernest Friedman-Hill of Sandia National.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 15], [16, 22], [23, 26], [27, 30], [31, 35], [36, 44], [44, 45], [46, 55], [56, 58], [59, 65], [66, 74], [74, 75], [75, 79], [80, 82], [83, 89], [90, 98], [98, 99]]}
{"doc_key": "ai-test-349", "ner": [[0, 3, "algorithm"], [13, 13, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 3, 13, 13, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "multilayer", "perceptrons", "with", "a", "hidden", "layer", ",", "more", "sophisticated", "algorithms", "such", "as", "backpropagation", "must", "be", "used", "."], "sentence-detokenized": "In multilayer perceptrons with a hidden layer, more sophisticated algorithms such as backpropagation must be used.", "token2charspan": [[0, 2], [3, 13], [14, 25], [26, 30], [31, 32], [33, 39], [40, 45], [45, 46], [47, 51], [52, 65], [66, 76], [77, 81], [82, 84], [85, 100], [101, 105], [106, 108], [109, 113], [113, 114]]}
{"doc_key": "ai-test-350", "ner": [[0, 0, "product"], [3, 6, "product"], [10, 19, "algorithm"], [21, 22, "field"], [25, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 6, 0, 0, "part-of", "", false, false], [3, 6, 10, 19, "usage", "", false, true], [10, 19, 21, 22, "related-to", "performs", false, false], [25, 30, 21, 22, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Google", "Translate", "'s", "neural", "machine", "translation", "system", "uses", "a", "vast", ",", "top", "-", "to", "-", "bottom", "artificial", "neural", "network", "to", "perform", "deep", "learning", ",", "especially", "long", "short", "-", "term", "memory", "networks", "."], "sentence-detokenized": "Google Translate's neural machine translation system uses a vast, top-to-bottom artificial neural network to perform deep learning, especially long short-term memory networks.", "token2charspan": [[0, 6], [7, 16], [16, 18], [19, 25], [26, 33], [34, 45], [46, 52], [53, 57], [58, 59], [60, 64], [64, 65], [66, 69], [69, 70], [70, 72], [72, 73], [73, 79], [80, 90], [91, 97], [98, 105], [106, 108], [109, 116], [117, 121], [122, 130], [130, 131], [132, 142], [143, 147], [148, 153], [153, 154], [154, 158], [159, 165], [166, 174], [174, 175]]}
{"doc_key": "ai-test-351", "ner": [[0, 0, "researcher"], [2, 2, "researcher"], [4, 4, "researcher"], [6, 7, "researcher"], [9, 10, "researcher"], [12, 12, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Werbos", ",", "Williams", ",", "Robinson", ",", "J\u00fcrgen", "Schmidhuber", ",", "Sepp", "Hochreiter", ",", "Pearlmutter", "and", "others", "developed", "various", "methods", "to", "do", "this", "in", "the", "1980s", "and", "early", "1990s", "."], "sentence-detokenized": "Werbos, Williams, Robinson, J\u00fcrgen Schmidhuber, Sepp Hochreiter, Pearlmutter and others developed various methods to do this in the 1980s and early 1990s.", "token2charspan": [[0, 6], [6, 7], [8, 16], [16, 17], [18, 26], [26, 27], [28, 34], [35, 46], [46, 47], [48, 52], [53, 63], [63, 64], [65, 76], [77, 80], [81, 87], [88, 97], [98, 105], [106, 113], [114, 116], [117, 119], [120, 124], [125, 127], [128, 131], [132, 137], [138, 141], [142, 147], [148, 153], [153, 154]]}
{"doc_key": "ai-test-352", "ner": [[1, 1, "organisation"], [2, 3, "organisation"], [7, 8, "organisation"], [17, 18, "task"], [14, 14, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 7, 8, "role", "licenses_from", false, false], [2, 3, 1, 1, "named", "", false, false], [14, 14, 1, 1, "origin", "", false, false], [14, 14, 17, 18, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["|", "Apple", "Apple", "Inc", "originally", "licensed", "the", "Nuance", "software", "to", "enable", "its", "digital", "assistant", "Siri", "to", "use", "speech", "recognition", "."], "sentence-detokenized": "| Apple Apple Inc originally licensed the Nuance software to enable its digital assistant Siri to use speech recognition.", "token2charspan": [[0, 1], [2, 7], [8, 13], [14, 17], [18, 28], [29, 37], [38, 41], [42, 48], [49, 57], [58, 60], [61, 67], [68, 71], [72, 79], [80, 89], [90, 94], [95, 97], [98, 101], [102, 108], [109, 120], [120, 121]]}
{"doc_key": "ai-test-353", "ner": [[0, 0, "organisation"], [3, 4, "misc"], [7, 8, "person"], [12, 13, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 3, 4, "role", "releases_movies_in_genre", false, false], [7, 8, 0, 0, "role", "directs_for", false, false], [12, 13, 0, 0, "role", "directs_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Columbia", "released", "several", "3D", "westerns", "produced", "by", "Sam", "Katzman", "and", "directed", "by", "William", "Castle", "."], "sentence-detokenized": "Columbia released several 3D westerns produced by Sam Katzman and directed by William Castle.", "token2charspan": [[0, 8], [9, 17], [18, 25], [26, 28], [29, 37], [38, 46], [47, 49], [50, 53], [54, 61], [62, 65], [66, 74], [75, 77], [78, 85], [86, 92], [92, 93]]}
{"doc_key": "ai-test-354", "ner": [[9, 10, "field"], [12, 12, "field"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "contains", "information", "and", "research", "in", "the", "fields", "of", "computer", "science", ",", "linguistics", "and", "information", "technology", "."], "sentence-detokenized": "It contains information and research in the fields of computer science, linguistics and information technology.", "token2charspan": [[0, 2], [3, 11], [12, 23], [24, 27], [28, 36], [37, 39], [40, 43], [44, 50], [51, 53], [54, 62], [63, 70], [70, 71], [72, 83], [84, 87], [88, 99], [100, 110], [110, 111]]}
{"doc_key": "ai-test-355", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Here", "is", "an", "example", "of", "an", "R", "code", ":"], "sentence-detokenized": "Here is an example of an R code:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 21], [22, 24], [25, 26], [27, 31], [31, 32]]}
{"doc_key": "ai-test-356", "ner": [[0, 2, "metrics"], [7, 9, "metrics"], [8, 11, "metrics"], [16, 16, "metrics"], [14, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 7, 9, "part-of", "plotted_into", false, false], [0, 2, 16, 16, "part-of", "plotted_into", false, false], [8, 11, 7, 9, "named", "", false, false], [14, 18, 16, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "ROC", "curve", "is", "generated", "by", "plotting", "TRUE", "positive", "rate", "(", "TPR", ")", "against", "FALSE", "positive", "rate", "(", "FPR", ")", "at", "different", "thresholds", "."], "sentence-detokenized": "The ROC curve is generated by plotting TRUE positive rate (TPR) against FALSE positive rate (FPR) at different thresholds.", "token2charspan": [[0, 3], [4, 7], [8, 13], [14, 16], [17, 26], [27, 29], [30, 38], [39, 43], [44, 52], [53, 57], [58, 59], [59, 62], [62, 63], [64, 71], [72, 77], [78, 86], [87, 91], [92, 93], [93, 96], [96, 97], [98, 100], [101, 110], [111, 121], [121, 122]]}
{"doc_key": "ai-test-357", "ner": [[4, 5, "researcher"], [7, 8, "researcher"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "research", "stopped", "after", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", "did", "a", "machine", "learning", "study", ","], "sentence-detokenized": "The research stopped after Marvin Minsky and Seymour Papert (1969) did a machine learning study,", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 26], [27, 33], [34, 40], [41, 44], [45, 52], [53, 59], [60, 61], [61, 65], [65, 66], [67, 70], [71, 72], [73, 80], [81, 89], [90, 95], [95, 96]]}
{"doc_key": "ai-test-358", "ner": [[9, 10, "programlang"], [12, 14, "product"], [16, 17, "programlang"], [19, 19, "product"], [21, 21, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "programming", "environments", "used", "to", "build", "DAQ", "applications", "include", "ladder", "logic", ",", "Visual", "C", "++", ",", "Visual", "Basic", ",", "LabVIEW", "and", "MATLAB", "."], "sentence-detokenized": "Other programming environments used to build DAQ applications include ladder logic, Visual C++, Visual Basic, LabVIEW and MATLAB.", "token2charspan": [[0, 5], [6, 17], [18, 30], [31, 35], [36, 38], [39, 44], [45, 48], [49, 61], [62, 69], [70, 76], [77, 82], [82, 83], [84, 90], [91, 92], [92, 94], [94, 95], [96, 102], [103, 108], [108, 109], [110, 117], [118, 121], [122, 128], [128, 129]]}
{"doc_key": "ai-test-359", "ner": [[11, 16, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "measure", "was", "designed", "to", "correct", "some", "of", "the", "problems", "found", "in", "the", "more", "popular", "BLEU", "measure", "and", "to", "provide", "a", "good", "correlation", "with", "human", "judgement", "at", "the", "sentence", "or", "segment", "level", "."], "sentence-detokenized": "The measure was designed to correct some of the problems found in the more popular BLEU measure and to provide a good correlation with human judgement at the sentence or segment level.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 24], [25, 27], [28, 35], [36, 40], [41, 43], [44, 47], [48, 56], [57, 62], [63, 65], [66, 69], [70, 74], [75, 82], [83, 87], [88, 95], [96, 99], [100, 102], [103, 110], [111, 112], [113, 117], [118, 129], [130, 134], [135, 140], [141, 150], [151, 153], [154, 157], [158, 166], [167, 169], [170, 177], [178, 183], [183, 184]]}
{"doc_key": "ai-test-360", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "semantic", "correlations", "between", "successive", "video", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and long short-term memory are often used to exploit semantic correlations between successive video frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [83, 88], [88, 89], [89, 93], [94, 100], [101, 104], [105, 110], [111, 115], [116, 118], [119, 126], [127, 135], [136, 148], [149, 156], [157, 167], [168, 173], [174, 180], [180, 181]]}
{"doc_key": "ai-test-361", "ner": [[3, 7, "product"], [13, 19, "product"], [37, 39, "product"]], "ner_mapping_to_source": [1, 2, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Mass", "-", "produced", "printed", "circuit", "boards", "(", "PCBs", ")", "are", "manufactured", "almost", "exclusively", "using", "pick", "-", "and", "-", "place", "robots", ",", "usually", "SCARA", "manipulators", ",", "which", "remove", "small", "electronic", "components", "from", "tapes", "or", "trays", "and", "place", "them", "on", "PCBs", "with", "great", "precision", "."], "sentence-detokenized": "Mass-produced printed circuit boards (PCBs) are manufactured almost exclusively using pick-and-place robots, usually SCARA manipulators, which remove small electronic components from tapes or trays and place them on PCBs with great precision.", "token2charspan": [[0, 4], [4, 5], [5, 13], [14, 21], [22, 29], [30, 36], [37, 38], [38, 42], [42, 43], [44, 47], [48, 60], [61, 67], [68, 79], [80, 85], [86, 90], [90, 91], [91, 94], [94, 95], [95, 100], [101, 107], [107, 108], [109, 116], [117, 122], [123, 135], [135, 136], [137, 142], [143, 149], [150, 155], [156, 166], [167, 177], [178, 182], [183, 188], [189, 191], [192, 197], [198, 201], [202, 207], [208, 212], [213, 215], [216, 220], [221, 225], [226, 231], [232, 241], [241, 242]]}
{"doc_key": "ai-test-362", "ner": [[1, 2, "field"], [24, 25, "algorithm"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 21, "researcher"], [34, 35, "algorithm"], [36, 38, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[24, 25, 1, 2, "part-of", "", false, false], [24, 25, 12, 13, "origin", "", false, false], [24, 25, 15, 16, "origin", "", false, false], [24, 25, 18, 21, "origin", "", false, false], [24, 25, 34, 35, "type-of", "", false, false], [34, 35, 36, 38, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "machine", "learning", ",", "where", "it", "is", "most", "widely", "used", "today", ",", "David", "Blei", ",", "Andrew", "Ng", "and", "Michael", "I", ".", "Jordan", "independently", "rediscovered", "LDA", "in", "2003", ",", "and", "it", "was", "presented", "as", "a", "graphical", "model", "for", "topic", "discovery", "."], "sentence-detokenized": "In machine learning, where it is most widely used today, David Blei, Andrew Ng and Michael I. Jordan independently rediscovered LDA in 2003, and it was presented as a graphical model for topic discovery.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 26], [27, 29], [30, 32], [33, 37], [38, 44], [45, 49], [50, 55], [55, 56], [57, 62], [63, 67], [67, 68], [69, 75], [76, 78], [79, 82], [83, 90], [91, 92], [92, 93], [94, 100], [101, 114], [115, 127], [128, 131], [132, 134], [135, 139], [139, 140], [141, 144], [145, 147], [148, 151], [152, 161], [162, 164], [165, 166], [167, 176], [177, 182], [183, 186], [187, 192], [193, 202], [202, 203]]}
{"doc_key": "ai-test-363", "ner": [[6, 6, "task"], [12, 13, "misc"], [17, 19, "metrics"], [23, 24, "metrics"], [28, 30, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[6, 6, 12, 13, "related-to", "task_across_domain", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "performance", "of", "the", "eight", "na\u00efve", "WSI", "test", "data", "measured", "for", "different", "breakpoint", "options", "resulted", "in", "a", "recovery", "rate", "of", "0.92", ",", "an", "accuracy", "of", "0.72", "and", "an", "F1", "score", "of", "0.81", "."], "sentence-detokenized": "The performance of the eight na\u00efve WSI test data measured for different breakpoint options resulted in a recovery rate of 0.92, an accuracy of 0.72 and an F1 score of 0.81.", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 22], [23, 28], [29, 34], [35, 38], [39, 43], [44, 48], [49, 57], [58, 61], [62, 71], [72, 82], [83, 90], [91, 99], [100, 102], [103, 104], [105, 113], [114, 118], [119, 121], [122, 126], [126, 127], [128, 130], [131, 139], [140, 142], [143, 147], [148, 151], [152, 154], [155, 157], [158, 163], [164, 166], [167, 171], [171, 172]]}
{"doc_key": "ai-test-364", "ner": [[6, 7, "field"], [15, 16, "task"]], "ner_mapping_to_source": [1, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Advanced", "AR", "technologies", "(", "e.g.", "augmenting", "computer", "vision", ",", "connecting", "AR", "cameras", "to", "smartphones", "and", "object", "recognition", ")", "will", "make", "information", "about", "the", "real", "world", "around", "the", "user", "interactive", "and", "digitally", "actionable", "."], "sentence-detokenized": "Advanced AR technologies (e.g. augmenting computer vision, connecting AR cameras to smartphones and object recognition) will make information about the real world around the user interactive and digitally actionable.", "token2charspan": [[0, 8], [9, 11], [12, 24], [25, 26], [26, 30], [31, 41], [42, 50], [51, 57], [57, 58], [59, 69], [70, 72], [73, 80], [81, 83], [84, 95], [96, 99], [100, 106], [107, 118], [118, 119], [120, 124], [125, 129], [130, 141], [142, 147], [148, 151], [152, 156], [157, 162], [163, 169], [170, 173], [174, 178], [179, 190], [191, 194], [195, 204], [205, 215], [215, 216]]}
{"doc_key": "ai-test-365", "ner": [[3, 3, "researcher"], [5, 8, "organisation"], [14, 15, "field"], [24, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 5, 8, "role", "forms_company", false, false], [5, 8, 14, 15, "related-to", "works_with", false, false], [5, 8, 24, 26, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2014", ",", "Schmidhuber", "founded", "Nnaisense", ",", "a", "company", "working", "on", "commercial", "applications", "of", "AI", "in", "areas", "such", "as", "finance", ",", "heavy", "industry", "and", "self", "-", "driving", "cars", "."], "sentence-detokenized": "In 2014, Schmidhuber founded Nnaisense, a company working on commercial applications of AI in areas such as finance, heavy industry and self-driving cars.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 28], [29, 38], [38, 39], [40, 41], [42, 49], [50, 57], [58, 60], [61, 71], [72, 84], [85, 87], [88, 90], [91, 93], [94, 99], [100, 104], [105, 107], [108, 115], [115, 116], [117, 122], [123, 131], [132, 135], [136, 140], [140, 141], [141, 148], [149, 153], [153, 154]]}
{"doc_key": "ai-test-366", "ner": [[24, 27, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "not", "only", "changes", "the", "performance", "of", "all", "subsequent", "tests", "with", "the", "retained", "explanatory", "model", ",", "but", "can", "also", "introduce", "bias", "and", "change", "the", "mean", "squared", "error", "of", "the", "estimation", "."], "sentence-detokenized": "This not only changes the performance of all subsequent tests with the retained explanatory model, but can also introduce bias and change the mean squared error of the estimation.", "token2charspan": [[0, 4], [5, 8], [9, 13], [14, 21], [22, 25], [26, 37], [38, 40], [41, 44], [45, 55], [56, 61], [62, 66], [67, 70], [71, 79], [80, 91], [92, 97], [97, 98], [99, 102], [103, 106], [107, 111], [112, 121], [122, 126], [127, 130], [131, 137], [138, 141], [142, 146], [147, 154], [155, 160], [161, 163], [164, 167], [168, 178], [178, 179]]}
{"doc_key": "ai-test-367", "ner": [[0, 0, "misc"], [6, 7, "task"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Bigrams", "are", "used", "in", "most", "successful", "speech", "recognition", "language", "models", "."], "sentence-detokenized": "Bigrams are used in most successful speech recognition language models.", "token2charspan": [[0, 7], [8, 11], [12, 16], [17, 19], [20, 24], [25, 35], [36, 42], [43, 54], [55, 63], [64, 70], [70, 71]]}
{"doc_key": "ai-test-368", "ner": [[3, 4, "field"], [13, 15, "misc"], [20, 22, "misc"], [9, 12, "organisation"], [33, 35, "misc"], [28, 31, "organisation"], [41, 44, "misc"], [45, 49, "organisation"], [55, 58, "misc"], [59, 62, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[13, 15, 3, 4, "topic", "", false, false], [20, 22, 9, 12, "origin", "", false, false], [33, 35, 28, 31, "origin", "", false, false], [41, 44, 45, 49, "origin", "", false, false], [55, 58, 59, 62, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["His", "research", "in", "cognitive", "psychology", "has", "earned", "him", "the", "American", "Psychological", "Association", "'s", "Early", "Career", "Award", "(", "1984", ")", "and", "Boyd", "McCandless", "Award", "(", "1986", ")", ",", "the", "National", "Academy", "of", "Sciences", "'", "Troland", "Research", "Award", "(", "1993", ")", ",", "the", "Henry", "Dale", "Award", "of", "the", "Royal", "Institute", "of", "Science", "(", "2004", ")", "and", "the", "George", "Miller", "Award", "of", "the", "Cognitive", "Neuroscience", "Society", "(", "2010", ")", "."], "sentence-detokenized": "His research in cognitive psychology has earned him the American Psychological Association's Early Career Award (1984) and Boyd McCandless Award (1986), the National Academy of Sciences' Troland Research Award (1993), the Henry Dale Award of the Royal Institute of Science (2004) and the George Miller Award of the Cognitive Neuroscience Society (2010).", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 25], [26, 36], [37, 40], [41, 47], [48, 51], [52, 55], [56, 64], [65, 78], [79, 90], [90, 92], [93, 98], [99, 105], [106, 111], [112, 113], [113, 117], [117, 118], [119, 122], [123, 127], [128, 138], [139, 144], [145, 146], [146, 150], [150, 151], [151, 152], [153, 156], [157, 165], [166, 173], [174, 176], [177, 185], [185, 186], [187, 194], [195, 203], [204, 209], [210, 211], [211, 215], [215, 216], [216, 217], [218, 221], [222, 227], [228, 232], [233, 238], [239, 241], [242, 245], [246, 251], [252, 261], [262, 264], [265, 272], [273, 274], [274, 278], [278, 279], [280, 283], [284, 287], [288, 294], [295, 301], [302, 307], [308, 310], [311, 314], [315, 324], [325, 337], [338, 345], [346, 347], [347, 351], [351, 352], [352, 353]]}
{"doc_key": "ai-test-369", "ner": [[0, 1, "product"], [3, 11, "researcher"], [5, 13, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [25, 27, "task"], [29, 32, "researcher"], [34, 38, "researcher"], [39, 40, "task"], [42, 42, "misc"]], "ner_mapping_to_source": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[0, 1, 39, 40, "named", "", false, false], [20, 21, 29, 32, "named", "same", false, false], [23, 24, 34, 38, "named", "same", false, false], [39, 40, 42, 42, "usage", "", false, false]], "relations_mapping_to_source": [6, 8, 10, 11], "sentence": ["Feature", "recognition", "(", "Sirovich", "and", "Kirby", "(", "1987", ")", "developed", "the", "Sirovich", "and", "Kirby", "(", "1987", ")", "approach", "used", "by", "Matthew", "Turk", "and", "Alex", "Pentland", "for", "face", "classification", ".", "Turk", ",", "Matthew", "A", "and", "Pentland", ",", "Alex", "P", ".", "Face", "recognition", "using", "eigenfaces", "."], "sentence-detokenized": "Feature recognition (Sirovich and Kirby (1987) developed the Sirovich and Kirby (1987) approach used by Matthew Turk and Alex Pentland for face classification. Turk, Matthew A and Pentland, Alex P. Face recognition using eigenfaces.", "token2charspan": [[0, 7], [8, 19], [20, 21], [21, 29], [30, 33], [34, 39], [40, 41], [41, 45], [45, 46], [47, 56], [57, 60], [61, 69], [70, 73], [74, 79], [80, 81], [81, 85], [85, 86], [87, 95], [96, 100], [101, 103], [104, 111], [112, 116], [117, 120], [121, 125], [126, 134], [135, 138], [139, 143], [144, 158], [158, 159], [160, 164], [164, 165], [166, 173], [174, 175], [176, 179], [180, 188], [188, 189], [190, 194], [195, 196], [196, 197], [198, 202], [203, 214], [215, 220], [221, 231], [231, 232]]}
{"doc_key": "ai-test-370", "ner": [[6, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "lexical", "dictionary", ",", "such", "as", "WordNet", ",", "can", "then", "be", "used", "to", "understand", "the", "context", "."], "sentence-detokenized": "A lexical dictionary, such as WordNet, can then be used to understand the context.", "token2charspan": [[0, 1], [2, 9], [10, 20], [20, 21], [22, 26], [27, 29], [30, 37], [37, 38], [39, 42], [43, 47], [48, 50], [51, 55], [56, 58], [59, 69], [70, 73], [74, 81], [81, 82]]}
{"doc_key": "ai-test-371", "ner": [[0, 1, "misc"], [9, 9, "misc"], [16, 16, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 9, 9, "part-of", "", false, false], [9, 9, 16, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "hyponym", "is", "the", "most", "commonly", "encoded", "relationship", "between", "synsets", "used", "in", "vocabulary", "databases", "such", "as", "WordNet", "."], "sentence-detokenized": "A hyponym is the most commonly encoded relationship between synsets used in vocabulary databases such as WordNet.", "token2charspan": [[0, 1], [2, 9], [10, 12], [13, 16], [17, 21], [22, 30], [31, 38], [39, 51], [52, 59], [60, 67], [68, 72], [73, 75], [76, 86], [87, 96], [97, 101], [102, 104], [105, 112], [112, 113]]}
{"doc_key": "ai-test-372", "ner": [[0, 0, "organisation"], [6, 7, "programlang"], [5, 9, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 7, "general-affiliation", "", false, false], [0, 0, 5, 9, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["OPeNDAP", "provides", "open", "source", "libraries", "in", "C", "++", "and", "Java", ",", "but", "many", "customers", "rely", "on", "community", "-", "developed", "libraries", ",", "such", "as", "libraries", "with", "embedded", "features", "for", "retrieving", "(", "array", "-", "type", ")", "data", "from", "DAP", "servers", "."], "sentence-detokenized": "OPeNDAP provides open source libraries in C++ and Java, but many customers rely on community-developed libraries, such as libraries with embedded features for retrieving (array-type) data from DAP servers.", "token2charspan": [[0, 7], [8, 16], [17, 21], [22, 28], [29, 38], [39, 41], [42, 43], [43, 45], [46, 49], [50, 54], [54, 55], [56, 59], [60, 64], [65, 74], [75, 79], [80, 82], [83, 92], [92, 93], [93, 102], [103, 112], [112, 113], [114, 118], [119, 121], [122, 131], [132, 136], [137, 145], [146, 154], [155, 158], [159, 169], [170, 171], [171, 176], [176, 177], [177, 181], [181, 182], [183, 187], [188, 192], [193, 196], [197, 204], [204, 205]]}
{"doc_key": "ai-test-373", "ner": [[4, 5, "misc"], [8, 8, "product"], [29, 30, "misc"], [48, 48, "product"], [52, 55, "product"]], "ner_mapping_to_source": [0, 1, 3, 5, 7], "relations": [[29, 30, 8, 8, "part-of", "", false, false]], "relations_mapping_to_source": [2], "sentence": ["On", "that", "page", ",", "Samurai", "Damashii", "exaggerated", "the", "Senkousha", "as", "the", "culmination", "of", "four", "thousand", "years", "of", "Chinese", "scientific", "knowledge", ",", "commented", "on", "its", "crude", "design", "(", "e.g.", "a", "Chinese", "cannon", "in", "its", "branches", ")", "and", "put", "it", "s", "image", "in", "the", "company", "of", "images", "of", "Honda", "'s", "ASIMO", "and", "Sony", "'s", "QRIO", "SDR", "-", "3X", "as", "a", "juxtaposition", "."], "sentence-detokenized": "On that page, Samurai Damashii exaggerated the Senkousha as the culmination of four thousand years of Chinese scientific knowledge, commented on its crude design (e.g. a Chinese cannon in its branches) and put its image in the company of images of Honda's ASIMO and Sony's QRIO SDR-3X as a juxtaposition.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 21], [22, 30], [31, 42], [43, 46], [47, 56], [57, 59], [60, 63], [64, 75], [76, 78], [79, 83], [84, 92], [93, 98], [99, 101], [102, 109], [110, 120], [121, 130], [130, 131], [132, 141], [142, 144], [145, 148], [149, 154], [155, 161], [162, 163], [163, 167], [168, 169], [170, 177], [178, 184], [185, 187], [188, 191], [192, 200], [200, 201], [202, 205], [206, 209], [210, 212], [212, 213], [214, 219], [220, 222], [223, 226], [227, 234], [235, 237], [238, 244], [245, 247], [248, 253], [253, 255], [256, 261], [262, 265], [266, 270], [270, 272], [273, 277], [278, 281], [281, 282], [282, 284], [285, 287], [288, 289], [290, 303], [303, 304]]}
{"doc_key": "ai-test-374", "ner": [[21, 21, "product"], [23, 23, "product"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "also", "many", "programming", "libraries", "that", "include", "neural", "network", "functions", "and", "can", "be", "used", "for", "custom", "implementations", "(", "such", "as", "TensorFlow", ",", "Theano", ",", "etc.", ")", "."], "sentence-detokenized": "There are also many programming libraries that include neural network functions and can be used for custom implementations (such as TensorFlow, Theano, etc.).", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 19], [20, 31], [32, 41], [42, 46], [47, 54], [55, 61], [62, 69], [70, 79], [80, 83], [84, 87], [88, 90], [91, 95], [96, 99], [100, 106], [107, 122], [123, 124], [124, 128], [129, 131], [132, 142], [142, 143], [144, 150], [150, 151], [152, 156], [156, 157], [157, 158]]}
{"doc_key": "ai-test-375", "ner": [[6, 9, "conference"], [11, 11, "organisation"], [13, 19, "conference"], [21, 21, "conference"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "is", "a", "member", "of", "the", "Association", "for", "Computing", "Machinery", ",", "IEEE", ",", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "IAPR", "and", "SPIE", "."], "sentence-detokenized": "He is a member of the Association for Computing Machinery, IEEE, American Association for the Advancement of Science, IAPR and SPIE.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 14], [15, 17], [18, 21], [22, 33], [34, 37], [38, 47], [48, 57], [57, 58], [59, 63], [63, 64], [65, 73], [74, 85], [86, 89], [90, 93], [94, 105], [106, 108], [109, 116], [116, 117], [118, 122], [123, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-test-376", "ner": [[2, 2, "organisation"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 6, 7, "related-to", "runs_trials_with", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "2011", "RET", "trial", "of", "installing", "facial", "recognition", "cameras", "on", "trams", "ensured", "that", "people", "who", "were", "banned", "from", "entering", "the", "city", "'s", "trams", "did", "not", "sneak", "onto", "them", "anyway", "."], "sentence-detokenized": "A 2011 RET trial of installing facial recognition cameras on trams ensured that people who were banned from entering the city's trams did not sneak onto them anyway.", "token2charspan": [[0, 1], [2, 6], [7, 10], [11, 16], [17, 19], [20, 30], [31, 37], [38, 49], [50, 57], [58, 60], [61, 66], [67, 74], [75, 79], [80, 86], [87, 90], [91, 95], [96, 102], [103, 107], [108, 116], [117, 120], [121, 125], [125, 127], [128, 133], [134, 137], [138, 141], [142, 147], [148, 152], [153, 157], [158, 164], [164, 165]]}
{"doc_key": "ai-test-377", "ner": [[2, 4, "person"], [15, 16, "person"], [18, 19, "person"], [21, 22, "person"], [24, 25, "person"], [27, 28, "person"], [30, 31, "person"], [33, 34, "person"], [36, 37, "person"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [], "relations_mapping_to_source": [], "sentence": ["Adapted", "from", "Cole", "Porter", "'s", "popular", "Broadway", "musical", ",", "the", "film", "starred", "MGM", "singing", "duo", "Howard", "Keel", "and", "Kathryn", "Grayson", ",", "Ann", "Miller", ",", "Keenan", "Wynn", ",", "Bobby", "Van", ",", "James", "Whitmore", ",", "Kurt", "Kasznar", "and", "Tommy", "Rall", "."], "sentence-detokenized": "Adapted from Cole Porter's popular Broadway musical, the film starred MGM singing duo Howard Keel and Kathryn Grayson, Ann Miller, Keenan Wynn, Bobby Van, James Whitmore, Kurt Kasznar and Tommy Rall.", "token2charspan": [[0, 7], [8, 12], [13, 17], [18, 24], [24, 26], [27, 34], [35, 43], [44, 51], [51, 52], [53, 56], [57, 61], [62, 69], [70, 73], [74, 81], [82, 85], [86, 92], [93, 97], [98, 101], [102, 109], [110, 117], [117, 118], [119, 122], [123, 129], [129, 130], [131, 137], [138, 142], [142, 143], [144, 149], [150, 153], [153, 154], [155, 160], [161, 169], [169, 170], [171, 175], [176, 183], [184, 187], [188, 193], [194, 198], [198, 199]]}
{"doc_key": "ai-test-378", "ner": [[16, 19, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "applications", "should", "streamline", "calls", ",", "minimise", "prompts", ",", "eliminate", "unnecessary", "repetition", "and", "enable", "a", "complex", "mixed", "dialogue", "system", "that", "allows", "callers", "to", "enter", "multiple", "pieces", "of", "information", "in", "a", "single", "sentence", "and", "in", "any", "order", "or", "combination", "."], "sentence-detokenized": "Such applications should streamline calls, minimise prompts, eliminate unnecessary repetition and enable a complex mixed dialogue system that allows callers to enter multiple pieces of information in a single sentence and in any order or combination.", "token2charspan": [[0, 4], [5, 17], [18, 24], [25, 35], [36, 41], [41, 42], [43, 51], [52, 59], [59, 60], [61, 70], [71, 82], [83, 93], [94, 97], [98, 104], [105, 106], [107, 114], [115, 120], [121, 129], [130, 136], [137, 141], [142, 148], [149, 156], [157, 159], [160, 165], [166, 174], [175, 181], [182, 184], [185, 196], [197, 199], [200, 201], [202, 208], [209, 217], [218, 221], [222, 224], [225, 228], [229, 234], [235, 237], [238, 249], [249, 250]]}
{"doc_key": "ai-test-379", "ner": [[8, 14, "algorithm"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Thus", ",", "traditional", "gradient", "descent", "methods", "(", "or", "stochastic", "gradient", "descent", ")", "can", "be", "adapted", ",", "where", "instead", "of", "a", "step", "along", "the", "gradient", "of", "a", "function", ",", "a", "step", "is", "taken", "along", "the", "subgradient", "of", "the", "function", "in", "the", "direction", "of", "the", "selected", "vector", "."], "sentence-detokenized": "Thus, traditional gradient descent methods (or stochastic gradient descent) can be adapted, where instead of a step along the gradient of a function, a step is taken along the subgradient of the function in the direction of the selected vector.", "token2charspan": [[0, 4], [4, 5], [6, 17], [18, 26], [27, 34], [35, 42], [43, 44], [44, 46], [47, 57], [58, 66], [67, 74], [74, 75], [76, 79], [80, 82], [83, 90], [90, 91], [92, 97], [98, 105], [106, 108], [109, 110], [111, 115], [116, 121], [122, 125], [126, 134], [135, 137], [138, 139], [140, 148], [148, 149], [150, 151], [152, 156], [157, 159], [160, 165], [166, 171], [172, 175], [176, 187], [188, 190], [191, 194], [195, 203], [204, 206], [207, 210], [211, 220], [221, 223], [224, 227], [228, 236], [237, 243], [243, 244]]}
{"doc_key": "ai-test-380", "ner": [[6, 11, "metrics"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Assuming", "that", "the", "distortion", "is", "measured", "by", "the", "root", "mean", "square", "error", ",", "the", "distortion", "D", "is", "given", "by", ":"], "sentence-detokenized": "Assuming that the distortion is measured by the root mean square error, the distortion D is given by:", "token2charspan": [[0, 8], [9, 13], [14, 17], [18, 28], [29, 31], [32, 40], [41, 43], [44, 47], [48, 52], [53, 57], [58, 64], [65, 70], [70, 71], [72, 75], [76, 86], [87, 88], [89, 91], [92, 97], [98, 100], [100, 101]]}
{"doc_key": "ai-test-381", "ner": [[0, 0, "algorithm"], [22, 23, "task"], [25, 26, "task"], [32, 33, "product"]], "ner_mapping_to_source": [0, 2, 3, 5], "relations": [[22, 23, 0, 0, "part-of", "", false, false], [25, 26, 0, 0, "part-of", "", false, false], [32, 33, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [1, 2, 4], "sentence": ["MLPs", "were", "a", "popular", "machine", "learning", "solution", "in", "the", "1980s", ",", "and", "were", "applied", "in", "a", "wide", "range", "of", "fields", ",", "including", "speech", "recognition", ",", "image", "recognition", "and", "machine", "translation", "software", ",", "neural", "networks", "."], "sentence-detokenized": "MLPs were a popular machine learning solution in the 1980s, and were applied in a wide range of fields, including speech recognition, image recognition and machine translation software, neural networks.", "token2charspan": [[0, 4], [5, 9], [10, 11], [12, 19], [20, 27], [28, 36], [37, 45], [46, 48], [49, 52], [53, 58], [58, 59], [60, 63], [64, 68], [69, 76], [77, 79], [80, 81], [82, 86], [87, 92], [93, 95], [96, 102], [102, 103], [104, 113], [114, 120], [121, 132], [132, 133], [134, 139], [140, 151], [152, 155], [156, 163], [164, 175], [176, 184], [184, 185], [186, 192], [193, 201], [201, 202]]}
{"doc_key": "ai-test-382", "ner": [[0, 0, "researcher"], [3, 4, "misc"], [5, 9, "university"], [15, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 5, 9, "physical", "", false, false], [0, 0, 5, 9, "role", "", false, false], [3, 4, 0, 0, "origin", "", false, false], [15, 17, 0, 0, "role", "supervised", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Allen", "received", "his", "PhD", "from", "the", "University", "of", "Toronto", "in", "1979", "under", "the", "supervision", "of", "C.", "Raymond", "Perrault", ","], "sentence-detokenized": "Allen received his PhD from the University of Toronto in 1979 under the supervision of C. Raymond Perrault,", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 22], [23, 27], [28, 31], [32, 42], [43, 45], [46, 53], [54, 56], [57, 61], [62, 67], [68, 71], [72, 83], [84, 86], [87, 89], [90, 97], [98, 106], [106, 107]]}
{"doc_key": "ai-test-383", "ner": [[0, 0, "product"], [4, 7, "field"], [10, 10, "product"], [12, 12, "product"], [14, 14, "product"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6], "relations": [[0, 0, 4, 7, "related-to", "supports", false, false], [10, 10, 4, 7, "type-of", "", true, false], [12, 12, 4, 7, "type-of", "", true, false], [14, 14, 4, 7, "type-of", "", true, false], [22, 22, 4, 7, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5], "sentence": ["OpenCV", "supports", "some", "models", "of", "deep", "learning", "environments", "such", "as", "TensorFlow", ",", "Torch", ",", "PyTorch", "(", "after", "conversion", "to", "ONNX", ")", "and", "Caffe", "according", "to", "the", "list", "of", "supported", "layers", "."], "sentence-detokenized": "OpenCV supports some models of deep learning environments such as TensorFlow, Torch, PyTorch (after conversion to ONNX) and Caffe according to the list of supported layers.", "token2charspan": [[0, 6], [7, 15], [16, 20], [21, 27], [28, 30], [31, 35], [36, 44], [45, 57], [58, 62], [63, 65], [66, 76], [76, 77], [78, 83], [83, 84], [85, 92], [93, 94], [94, 99], [100, 110], [111, 113], [114, 118], [118, 119], [120, 123], [124, 129], [130, 139], [140, 142], [143, 146], [147, 151], [152, 154], [155, 164], [165, 171], [171, 172]]}
{"doc_key": "ai-test-384", "ner": [[2, 2, "researcher"], [10, 12, "organisation"], [9, 14, "organisation"], [18, 22, "organisation"], [26, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 2, 10, 12, "role", "", false, false], [2, 2, 18, 22, "role", "", false, false], [2, 2, 26, 26, "related-to", "lectures_in", false, false], [9, 14, 10, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Previously", ",", "Christensen", "was", "a", "founding", "member", "of", "the", "European", "Robotics", "Research", "Network", "(", "EURON", ")", "and", "an", "IEEE", "Robotics", "and", "Automation", "Society", "Distinguished", "Lecturer", "in", "Robotics", "."], "sentence-detokenized": "Previously, Christensen was a founding member of the European Robotics Research Network (EURON) and an IEEE Robotics and Automation Society Distinguished Lecturer in Robotics.", "token2charspan": [[0, 10], [10, 11], [12, 23], [24, 27], [28, 29], [30, 38], [39, 45], [46, 48], [49, 52], [53, 61], [62, 70], [71, 79], [80, 87], [88, 89], [89, 94], [94, 95], [96, 99], [100, 102], [103, 107], [108, 116], [117, 120], [121, 131], [132, 139], [140, 153], [154, 162], [163, 165], [166, 174], [174, 175]]}
{"doc_key": "ai-test-385", "ner": [[7, 7, "field"], [8, 11, "university"], [12, 13, "location"], [15, 19, "country"], [24, 25, "misc"], [26, 28, "field"], [30, 34, "organisation"], [29, 29, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[8, 11, 12, 13, "physical", "", false, false], [12, 13, 15, 19, "physical", "", false, false], [24, 25, 26, 28, "topic", "", false, false], [30, 34, 29, 29, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["He", "obtained", "a", "Master", "'s", "degree", "in", "Mathematics", "from", "Samarkand", "State", "University", "in", "Samarkand", ",", "Socialist", "Soviet", "Republic", "of", "Uzbekistan", "in", "1958", "and", "a", "PhD", "in", "Statistics", "from", "the", "Moscow", "Institute", "of", "Control", "Sciences", "in", "1964", "."], "sentence-detokenized": "He obtained a Master's degree in Mathematics from Samarkand State University in Samarkand, Socialist Soviet Republic of Uzbekistan in 1958 and a PhD in Statistics from the Moscow Institute of Control Sciences in 1964.", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 20], [20, 22], [23, 29], [30, 32], [33, 44], [45, 49], [50, 59], [60, 65], [66, 76], [77, 79], [80, 89], [89, 90], [91, 100], [101, 107], [108, 116], [117, 119], [120, 130], [131, 133], [134, 138], [139, 142], [143, 144], [145, 148], [149, 151], [152, 162], [163, 167], [168, 171], [172, 178], [179, 188], [189, 191], [192, 199], [200, 208], [209, 211], [212, 216], [216, 217]]}
{"doc_key": "ai-test-386", "ner": [[4, 4, "organisation"], [10, 12, "product"], [32, 33, "field"], [31, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 32, 33, "usage", "", false, false], [4, 4, 31, 37, "usage", "", false, false], [10, 12, 4, 4, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Increasingly", ",", "however", ",", "Cycorp", "is", "working", "to", "give", "the", "Cyc", "system", "the", "ability", "to", "communicate", "with", "end-users", "in", "natural", "language", "and", "to", "assist", "in", "the", "ongoing", "process", "of", "information", "generation", "through", "machine", "learning", "and", "natural", "language", "understanding", "."], "sentence-detokenized": "Increasingly, however, Cycorp is working to give the Cyc system the ability to communicate with end-users in natural language and to assist in the ongoing process of information generation through machine learning and natural language understanding.", "token2charspan": [[0, 12], [12, 13], [14, 21], [21, 22], [23, 29], [30, 32], [33, 40], [41, 43], [44, 48], [49, 52], [53, 56], [57, 63], [64, 67], [68, 75], [76, 78], [79, 90], [91, 95], [96, 105], [106, 108], [109, 116], [117, 125], [126, 129], [130, 132], [133, 139], [140, 142], [143, 146], [147, 154], [155, 162], [163, 165], [166, 177], [178, 188], [189, 196], [197, 204], [205, 213], [214, 217], [218, 225], [226, 234], [235, 248], [248, 249]]}
{"doc_key": "ai-test-387", "ner": [[56, 56, "metrics"], [58, 58, "metrics"], [60, 60, "metrics"], [62, 63, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "if", "one", "is", "looking", "for", "the", "most", "suitable", "classifier", "for", "a", "problem", ",", "the", "training", "dataset", "is", "used", "to", "train", "the", "candidate", "algorithms", ",", "the", "validation", "dataset", "is", "used", "to", "compare", "their", "performance", "and", "decide", "which", "one", "to", "choose", ",", "and", "finally", "the", "test", "dataset", "is", "used", "to", "obtain", "performance", "characteristics", "such", "as", "accuracy", ",", "sensitivity", ",", "specificity", ",", "F-", "measure", "and", "so", "on", "."], "sentence-detokenized": "For example, if one is looking for the most suitable classifier for a problem, the training dataset is used to train the candidate algorithms, the validation dataset is used to compare their performance and decide which one to choose, and finally the test dataset is used to obtain performance characteristics such as accuracy, sensitivity, specificity, F-measure and so on.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 19], [20, 22], [23, 30], [31, 34], [35, 38], [39, 43], [44, 52], [53, 63], [64, 67], [68, 69], [70, 77], [77, 78], [79, 82], [83, 91], [92, 99], [100, 102], [103, 107], [108, 110], [111, 116], [117, 120], [121, 130], [131, 141], [141, 142], [143, 146], [147, 157], [158, 165], [166, 168], [169, 173], [174, 176], [177, 184], [185, 190], [191, 202], [203, 206], [207, 213], [214, 219], [220, 223], [224, 226], [227, 233], [233, 234], [235, 238], [239, 246], [247, 250], [251, 255], [256, 263], [264, 266], [267, 271], [272, 274], [275, 281], [282, 293], [294, 309], [310, 314], [315, 317], [318, 326], [326, 327], [328, 339], [339, 340], [341, 352], [352, 353], [354, 356], [356, 363], [364, 367], [368, 370], [371, 373], [373, 374]]}
{"doc_key": "ai-test-388", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "average", "square", "error", "is", "0.15", "."], "sentence-detokenized": "The average square error is 0.15.", "token2charspan": [[0, 3], [4, 11], [12, 18], [19, 24], [25, 27], [28, 32], [32, 33]]}
{"doc_key": "ai-test-389", "ner": [[6, 10, "misc"], [4, 4, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 6, 10, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1979", ",", "the", "IEEE", "organised", "a", "Micromouse", "competition", ",", "which", "was", "featured", "in", "Spectrum", "magazine", "."], "sentence-detokenized": "In 1979, the IEEE organised a Micromouse competition, which was featured in Spectrum magazine.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 27], [28, 29], [30, 40], [41, 52], [52, 53], [54, 59], [60, 63], [64, 72], [73, 75], [76, 84], [85, 93], [93, 94]]}
{"doc_key": "ai-test-390", "ner": [[0, 2, "algorithm"], [12, 14, "task"], [16, 17, "task"], [19, 20, "task"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Gabor", "space", "is", "very", "useful", "for", "image", "processing", "applications", "such", "as", "optical", "character", "recognition", ",", "iris", "recognition", "and", "fingerprint", "recognition", "."], "sentence-detokenized": "The Gabor space is very useful for image processing applications such as optical character recognition, iris recognition and fingerprint recognition.", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 18], [19, 23], [24, 30], [31, 34], [35, 40], [41, 51], [52, 64], [65, 69], [70, 72], [73, 80], [81, 90], [91, 102], [102, 103], [104, 108], [109, 120], [121, 124], [125, 136], [137, 148], [148, 149]]}
{"doc_key": "ai-test-391", "ner": [[7, 7, "programlang"], [9, 9, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["or", "through", "high", "-", "level", "interfaces", "to", "Java", "and", "Tcl", "."], "sentence-detokenized": "or through high-level interfaces to Java and Tcl.", "token2charspan": [[0, 2], [3, 10], [11, 15], [15, 16], [16, 21], [22, 32], [33, 35], [36, 40], [41, 44], [45, 48], [48, 49]]}
{"doc_key": "ai-test-392", "ner": [[20, 20, "field"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "recent", "research", ",", "kernel", "-", "based", "methods", ",", "such", "as", "support", "vector", "machines", ",", "have", "shown", "superior", "performance", "in", "supervised", "methods", "."], "sentence-detokenized": "In recent research, kernel-based methods, such as support vector machines, have shown superior performance in supervised methods.", "token2charspan": [[0, 2], [3, 9], [10, 18], [18, 19], [20, 26], [26, 27], [27, 32], [33, 40], [40, 41], [42, 46], [47, 49], [50, 57], [58, 64], [65, 73], [73, 74], [75, 79], [80, 85], [86, 94], [95, 106], [107, 109], [110, 120], [121, 128], [128, 129]]}
{"doc_key": "ai-test-393", "ner": [[14, 14, "misc"], [23, 23, "researcher"], [25, 25, "researcher"], [32, 35, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 23, 32, 35, "usage", "", false, false], [25, 25, 32, 35, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["To", "illustrate", "the", "basic", "principles", "of", "bagging", ",", "an", "analysis", "of", "the", "relationship", "between", "ozone", "and", "temperature", "is", "presented", "below", "(", "data", "from", "Rousseeuw", "and", "Leroy", "(", "1986", ")", ",", "analysis", "done", "with", "the", "R", "program", ")", "."], "sentence-detokenized": "To illustrate the basic principles of bagging, an analysis of the relationship between ozone and temperature is presented below (data from Rousseeuw and Leroy (1986), analysis done with the R program).", "token2charspan": [[0, 2], [3, 13], [14, 17], [18, 23], [24, 34], [35, 37], [38, 45], [45, 46], [47, 49], [50, 58], [59, 61], [62, 65], [66, 78], [79, 86], [87, 92], [93, 96], [97, 108], [109, 111], [112, 121], [122, 127], [128, 129], [129, 133], [134, 138], [139, 148], [149, 152], [153, 158], [159, 160], [160, 164], [164, 165], [165, 166], [167, 175], [176, 180], [181, 185], [186, 189], [190, 191], [192, 199], [199, 200], [200, 201]]}
{"doc_key": "ai-test-394", "ner": [[0, 1, "organisation"], [18, 19, "product"], [21, 23, "product"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[18, 19, 0, 1, "artifact", "", false, false], [21, 23, 0, 1, "artifact", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["Denso", "Wave", "is", "a", "subsidiary", "that", "manufactures", "automatic", "identification", "products", "(", "barcode", "readers", "and", "related", "products", ")", ",", "industrial", "robots", "and", "programmable", "logic", "controllers", "."], "sentence-detokenized": "Denso Wave is a subsidiary that manufactures automatic identification products (barcode readers and related products), industrial robots and programmable logic controllers.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 15], [16, 26], [27, 31], [32, 44], [45, 54], [55, 69], [70, 78], [79, 80], [80, 87], [88, 95], [96, 99], [100, 107], [108, 116], [116, 117], [117, 118], [119, 129], [130, 136], [137, 140], [141, 153], [154, 159], [160, 171], [171, 172]]}
{"doc_key": "ai-test-395", "ner": [[2, 4, "metrics"], [7, 9, "metrics"], [21, 21, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[2, 4, 21, 21, "compare", "", false, false], [7, 9, 2, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Whereas", "the", "Bilingual", "evaluation", "understudy", "only", "calculates", "the", "accuracy", "of", "an", "n-", "gram", "and", "gives", "equal", "weight", "to", "each", "gram", ",", "NIST", "also", "calculates", "how", "informative", "a", "particular", "n-", "gram", "is", "."], "sentence-detokenized": "Whereas the Bilingual evaluation understudy only calculates the accuracy of an n-gram and gives equal weight to each gram, NIST also calculates how informative a particular n-gram is.", "token2charspan": [[0, 7], [8, 11], [12, 21], [22, 32], [33, 43], [44, 48], [49, 59], [60, 63], [64, 72], [73, 75], [76, 78], [79, 81], [81, 85], [86, 89], [90, 95], [96, 101], [102, 108], [109, 111], [112, 116], [117, 121], [121, 122], [123, 127], [128, 132], [133, 143], [144, 147], [148, 159], [160, 161], [162, 172], [173, 175], [175, 179], [180, 182], [182, 183]]}
{"doc_key": "ai-test-396", "ner": [[11, 11, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "particular", ",", "they", "are", "used", "in", "tree", "likelihood", "calculations", "(", "Bayesian", "and", "maximum", "likelihood", "approaches", "to", "tree", "estimation", ")", "and", "are", "used", "to", "estimate", "the", "evolutionary", "distance", "between", "sequences", "based", "on", "the", "observed", "differences", "between", "sequences", "."], "sentence-detokenized": "In particular, they are used in tree likelihood calculations (Bayesian and maximum likelihood approaches to tree estimation) and are used to estimate the evolutionary distance between sequences based on the observed differences between sequences.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 19], [20, 23], [24, 28], [29, 31], [32, 36], [37, 47], [48, 60], [61, 62], [62, 70], [71, 74], [75, 82], [83, 93], [94, 104], [105, 107], [108, 112], [113, 123], [123, 124], [125, 128], [129, 132], [133, 137], [138, 140], [141, 149], [150, 153], [154, 166], [167, 175], [176, 183], [184, 193], [194, 199], [200, 202], [203, 206], [207, 215], [216, 227], [228, 235], [236, 245], [245, 246]]}
{"doc_key": "ai-test-397", "ner": [[0, 3, "conference"], [22, 23, "misc"], [25, 25, "misc"], [54, 56, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[25, 25, 22, 23, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "Audio", "Engineering", "Society", "recommends", "a", "48", "kHz", "sample", "rate", "for", "most", "applications", ",", "but", "recognizes", "a", "44.1", "kHz", "sample", "rate", "for", "compact", "discs", "(", "CDs", ")", "and", "other", "consumer", "applications", ",", "a", "32", "kHz", "sample", "rate", "for", "transfer", "-", "related", "applications", ",", "and", "a", "96", "kHz", "sample", "rate", "for", "higher", "bandwidth", "or", "looser", "level", "protection", "filters", "."], "sentence-detokenized": "The Audio Engineering Society recommends a 48 kHz sample rate for most applications, but recognizes a 44.1 kHz sample rate for compact discs (CDs) and other consumer applications, a 32 kHz sample rate for transfer-related applications, and a 96 kHz sample rate for higher bandwidth or looser level protection filters.", "token2charspan": [[0, 3], [4, 9], [10, 21], [22, 29], [30, 40], [41, 42], [43, 45], [46, 49], [50, 56], [57, 61], [62, 65], [66, 70], [71, 83], [83, 84], [85, 88], [89, 99], [100, 101], [102, 106], [107, 110], [111, 117], [118, 122], [123, 126], [127, 134], [135, 140], [141, 142], [142, 145], [145, 146], [147, 150], [151, 156], [157, 165], [166, 178], [178, 179], [180, 181], [182, 184], [185, 188], [189, 195], [196, 200], [201, 204], [205, 213], [213, 214], [214, 221], [222, 234], [234, 235], [236, 239], [240, 241], [242, 244], [245, 248], [249, 255], [256, 260], [261, 264], [265, 271], [272, 281], [282, 284], [285, 291], [292, 297], [298, 308], [309, 316], [316, 317]]}
{"doc_key": "ai-test-398", "ner": [[0, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Word", "Net", "has", "resources", "for", "the", "affectivity", "of", "words", "and", "concepts", "{", "{", "cite", "journal"], "sentence-detokenized": "WordNet has resources for the affectivity of words and concepts {{cite journal", "token2charspan": [[0, 4], [4, 7], [8, 11], [12, 21], [22, 25], [26, 29], [30, 41], [42, 44], [45, 50], [51, 54], [55, 63], [64, 65], [65, 66], [66, 70], [71, 78]]}
{"doc_key": "ai-test-399", "ner": [[0, 7, "misc"], [21, 22, "person"], [27, 30, "person"], [34, 37, "person"], [39, 43, "organisation"], [63, 64, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[27, 30, 34, 37, "role", "acts_in", false, false], [39, 43, 34, 37, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["As", "a", "red", "and", "green", "anaglyph", ",", "the", "audience", "was", "shown", "three", "test", "discs", "containing", "rural", "scenes", ",", "test", "footage", "of", "Marie", "Doro", ",", "a", "clip", "of", "John", "B", ".", "Mason", "played", "several", "scenes", "from", "Jim", "the", "Penman", "(", "Famous", "Players", "-", "Lasky", "'s", "film", "released", "the", "same", "year", ",", "but", "not", "in", "3D", ")", ",", "oriental", "dancers", ",", "and", "a", "reel", "of", "Niagara", "Falls", "."], "sentence-detokenized": "As a red and green anaglyph, the audience was shown three test discs containing rural scenes, test footage of Marie Doro, a clip of John B. Mason played several scenes from Jim the Penman (Famous Players-Lasky's film released the same year, but not in 3D), oriental dancers, and a reel of Niagara Falls.", "token2charspan": [[0, 2], [3, 4], [5, 8], [9, 12], [13, 18], [19, 27], [27, 28], [29, 32], [33, 41], [42, 45], [46, 51], [52, 57], [58, 62], [63, 68], [69, 79], [80, 85], [86, 92], [92, 93], [94, 98], [99, 106], [107, 109], [110, 115], [116, 120], [120, 121], [122, 123], [124, 128], [129, 131], [132, 136], [137, 138], [138, 139], [140, 145], [146, 152], [153, 160], [161, 167], [168, 172], [173, 176], [177, 180], [181, 187], [188, 189], [189, 195], [196, 203], [203, 204], [204, 209], [209, 211], [212, 216], [217, 225], [226, 229], [230, 234], [235, 239], [239, 240], [241, 244], [245, 248], [249, 251], [252, 254], [254, 255], [255, 256], [257, 265], [266, 273], [273, 274], [275, 278], [279, 280], [281, 285], [286, 288], [289, 296], [297, 302], [302, 303]]}
{"doc_key": "ai-test-400", "ner": [[7, 9, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "special", "way", "of", "implementing", "maximum", "likelihood", "estimation", "for", "this", "problem", "."], "sentence-detokenized": "This is a special way of implementing maximum likelihood estimation for this problem.", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 17], [18, 21], [22, 24], [25, 37], [38, 45], [46, 56], [57, 67], [68, 71], [72, 76], [77, 84], [84, 85]]}
{"doc_key": "ai-test-401", "ner": [[0, 4, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["crawler", "-", "friendly", "web", "servers", ",", "and", "combines", "the", "features", "of", "sitemaps", "and", "RSS", "feeds", "into", "a", "distributed", "mechanism", "that", "allows", "computational", "biologists", "and", "bioinformatics", "experts", "to", "openly", "submit", "and", "retrieve", "metadata", "from", "biomedical", "resources", "."], "sentence-detokenized": "crawler-friendly web servers, and combines the features of sitemaps and RSS feeds into a distributed mechanism that allows computational biologists and bioinformatics experts to openly submit and retrieve metadata from biomedical resources.", "token2charspan": [[0, 7], [7, 8], [8, 16], [17, 20], [21, 28], [28, 29], [30, 33], [34, 42], [43, 46], [47, 55], [56, 58], [59, 67], [68, 71], [72, 75], [76, 81], [82, 86], [87, 88], [89, 100], [101, 110], [111, 115], [116, 122], [123, 136], [137, 147], [148, 151], [152, 166], [167, 174], [175, 177], [178, 184], [185, 191], [192, 195], [196, 204], [205, 213], [214, 218], [219, 229], [230, 239], [239, 240]]}
{"doc_key": "ai-test-402", "ner": [[4, 11, "misc"], [13, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "covered", "by", "American", "National", "Standards", "Institute", "/", "NISO", "standard", "Z39.50", "and", "International", "Organization", "for", "Standardization", "standard", "23950", "."], "sentence-detokenized": "It is covered by American National Standards Institute / NISO standard Z39.50 and International Organization for Standardization standard 23950.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 25], [26, 34], [35, 44], [45, 54], [55, 56], [57, 61], [62, 70], [71, 77], [78, 81], [82, 95], [96, 108], [109, 112], [113, 128], [129, 137], [138, 143], [143, 144]]}
{"doc_key": "ai-test-403", "ner": [[17, 18, "misc"], [21, 22, "metrics"], [25, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "encoder", "and", "decoder", "are", "trained", "to", "take", "the", "sentence", "and", "reproduce", "the", "corresponding", "paraphrase", "of", "the", "unary", "distribution", "by", "minimizing", "the", "perplexity", "using", "simple", "stochastic", "gradient", "descent", "."], "sentence-detokenized": "The encoder and decoder are trained to take the sentence and reproduce the corresponding paraphrase of the unary distribution by minimizing the perplexity using simple stochastic gradient descent.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 27], [28, 35], [36, 38], [39, 43], [44, 47], [48, 56], [57, 60], [61, 70], [71, 74], [75, 88], [89, 99], [100, 102], [103, 106], [107, 112], [113, 125], [126, 128], [129, 139], [140, 143], [144, 154], [155, 160], [161, 167], [168, 178], [179, 187], [188, 195], [195, 196]]}
{"doc_key": "ai-test-404", "ner": [[8, 10, "task"], [12, 17, "task"], [27, 30, "task"], [32, 36, "task"], [38, 44, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "typical", "applications", "of", "pattern", "recognition", "techniques", "include", "automatic", "speech", "recognition", ",", "classification", "of", "text", "into", "multiple", "categories", "(", "e.g.", "spam", "/", "non", "-", "spam", ")", ",", "handwriting", "recognition", "in", "envelopes", ",", "automatic", "recognition", "of", "facial", "images", "or", "extraction", "of", "handwriting", "images", "from", "medical", "forms", "."], "sentence-detokenized": "Other typical applications of pattern recognition techniques include automatic speech recognition, classification of text into multiple categories (e.g. spam/non-spam), handwriting recognition in envelopes, automatic recognition of facial images or extraction of handwriting images from medical forms.", "token2charspan": [[0, 5], [6, 13], [14, 26], [27, 29], [30, 37], [38, 49], [50, 60], [61, 68], [69, 78], [79, 85], [86, 97], [97, 98], [99, 113], [114, 116], [117, 121], [122, 126], [127, 135], [136, 146], [147, 148], [148, 152], [153, 157], [157, 158], [158, 161], [161, 162], [162, 166], [166, 167], [167, 168], [169, 180], [181, 192], [193, 195], [196, 205], [205, 206], [207, 216], [217, 228], [229, 231], [232, 238], [239, 245], [246, 248], [249, 259], [260, 262], [263, 274], [275, 281], [282, 286], [287, 294], [295, 300], [300, 301]]}
{"doc_key": "ai-test-405", "ner": [[0, 2, "algorithm"], [15, 16, "field"], [18, 19, "task"], [21, 22, "task"], [24, 26, "task"], [28, 32, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[15, 16, 0, 2, "usage", "", false, false], [18, 19, 0, 2, "usage", "", false, false], [21, 22, 0, 2, "usage", "", false, false], [24, 26, 0, 2, "usage", "", false, false], [28, 32, 0, 2, "usage", "", false, false], [35, 36, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Artificial", "neural", "networks", "have", "been", "used", "for", "a", "wide", "range", "of", "tasks", ",", "such", "as", "computer", "vision", ",", "speech", "recognition", ",", "machine", "translation", ",", "filtering", "social", "networks", ",", "playing", "board", "and", "video", "games", ",", "and", "medical", "diagnosis", "."], "sentence-detokenized": "Artificial neural networks have been used for a wide range of tasks, such as computer vision, speech recognition, machine translation, filtering social networks, playing board and video games, and medical diagnosis.", "token2charspan": [[0, 10], [11, 17], [18, 26], [27, 31], [32, 36], [37, 41], [42, 45], [46, 47], [48, 52], [53, 58], [59, 61], [62, 67], [67, 68], [69, 73], [74, 76], [77, 85], [86, 92], [92, 93], [94, 100], [101, 112], [112, 113], [114, 121], [122, 133], [133, 134], [135, 144], [145, 151], [152, 160], [160, 161], [162, 169], [170, 175], [176, 179], [180, 185], [186, 191], [191, 192], [193, 196], [197, 204], [205, 214], [214, 215]]}
{"doc_key": "ai-test-406", "ner": [[2, 3, "organisation"], [4, 4, "product"], [19, 19, "organisation"], [20, 21, "product"], [23, 23, "product"], [25, 27, "product"], [29, 29, "product"], [31, 31, "programlang"], [39, 40, "field"], [49, 49, "algorithm"], [51, 51, "algorithm"], [57, 57, "product"], [75, 75, "product"], [77, 77, "product"], [79, 81, "product"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 17, 18, 19], "relations": [[4, 4, 2, 3, "origin", "", false, false], [31, 31, 39, 40, "related-to", "used_for", false, false], [49, 49, 31, 31, "part-of", "", true, false], [51, 51, 31, 31, "part-of", "", true, false]], "relations_mapping_to_source": [0, 3, 4, 6], "sentence": ["Examples", "include", "Salford", "Systems", "CART", "(", "which", "has", "licensed", "the", "code", "owned", "by", "the", "original", "CART", "authors", ")", ",", "IBM", "SPSS", "Modeler", ",", "RapidMiner", ",", "SAS", "Enterprise", "Miner", ",", "Matlab", ",", "R", "(", "an", "open", "source", "software", "environment", "for", "statistical", "computing", ",", "which", "includes", "several", "CART", "implementations", "such", "as", "rpart", ",", "party", "and", "randomForest", "packages", ")", ",", "Weka", "(", "a", "free", "and", "open", "source", "data", "mining", "package", "that", "includes", "many", "decision", "tree", "algorithms", ")", ",", "Orange", ",", "KNIME", ",", "Microsoft", "SQL", "Server", "programming", "language", ")", "."], "sentence-detokenized": "Examples include Salford Systems CART (which has licensed the code owned by the original CART authors), IBM SPSS Modeler, RapidMiner, SAS Enterprise Miner, Matlab, R (an open source software environment for statistical computing, which includes several CART implementations such as rpart, party and randomForest packages), Weka (a free and open source data mining package that includes many decision tree algorithms), Orange, KNIME, Microsoft SQL Server programming language).", "token2charspan": [[0, 8], [9, 16], [17, 24], [25, 32], [33, 37], [38, 39], [39, 44], [45, 48], [49, 57], [58, 61], [62, 66], [67, 72], [73, 75], [76, 79], [80, 88], [89, 93], [94, 101], [101, 102], [102, 103], [104, 107], [108, 112], [113, 120], [120, 121], [122, 132], [132, 133], [134, 137], [138, 148], [149, 154], [154, 155], [156, 162], [162, 163], [164, 165], [166, 167], [167, 169], [170, 174], [175, 181], [182, 190], [191, 202], [203, 206], [207, 218], [219, 228], [228, 229], [230, 235], [236, 244], [245, 252], [253, 257], [258, 273], [274, 278], [279, 281], [282, 287], [287, 288], [289, 294], [295, 298], [299, 311], [312, 320], [320, 321], [321, 322], [323, 327], [328, 329], [329, 330], [331, 335], [336, 339], [340, 344], [345, 351], [352, 356], [357, 363], [364, 371], [372, 376], [377, 385], [386, 390], [391, 399], [400, 404], [405, 415], [415, 416], [416, 417], [418, 424], [424, 425], [426, 431], [431, 432], [433, 442], [443, 446], [447, 453], [454, 465], [466, 474], [474, 475], [475, 476]]}
{"doc_key": "ai-test-407", "ner": [[0, 2, "algorithm"], [4, 4, "algorithm"], [10, 11, "researcher"], [12, 14, "university"], [16, 17, "researcher"], [18, 22, "organisation"], [24, 27, "organisation"], [34, 36, "researcher"], [38, 40, "researcher"], [41, 43, "organisation"], [57, 61, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 2, 10, 11, "origin", "", false, false], [0, 2, 16, 17, "origin", "", false, false], [0, 2, 34, 36, "origin", "", false, false], [0, 2, 38, 40, "origin", "", false, false], [4, 4, 0, 2, "named", "", false, false], [10, 11, 12, 14, "physical", "", false, false], [10, 11, 12, 14, "role", "", false, false], [16, 17, 18, 22, "physical", "", false, false], [16, 17, 18, 22, "role", "", false, false], [24, 27, 18, 22, "named", "", false, false], [34, 36, 41, 43, "physical", "", false, false], [34, 36, 41, 43, "role", "", false, false], [38, 40, 41, 43, "physical", "", false, false], [38, 40, 41, 43, "role", "", false, false], [57, 61, 0, 2, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["Linear", "Predictive", "Coding", "(", "LPC", ")", "was", "first", "developed", "by", "Fumitada", "Itakura", "of", "Nagoya", "University", "and", "Shuzo", "Saito", "of", "Nippon", "Telegraph", "and", "Telephone", "(", "NTT", ")", "in", "1966", ".", "It", "was", "further", "developed", "by", "Bishnu", "S.", "Atal", "and", "Manfred", "R.", "Schroeder", "at", "Bell", "Labs", "in", "the", "early", "and", "mid-1970s", ",", "and", "became", "the", "basis", "for", "the", "first", "speech", "synthesizer", "DSP", "circuits", "in", "the", "late", "1970s", "."], "sentence-detokenized": "Linear Predictive Coding (LPC) was first developed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966. It was further developed by Bishnu S. Atal and Manfred R. Schroeder at Bell Labs in the early and mid-1970s, and became the basis for the first speech synthesizer DSP circuits in the late 1970s.", "token2charspan": [[0, 6], [7, 17], [18, 24], [25, 26], [26, 29], [29, 30], [31, 34], [35, 40], [41, 50], [51, 53], [54, 62], [63, 70], [71, 73], [74, 80], [81, 91], [92, 95], [96, 101], [102, 107], [108, 110], [111, 117], [118, 127], [128, 131], [132, 141], [142, 143], [143, 146], [146, 147], [148, 150], [151, 155], [155, 156], [157, 159], [160, 163], [164, 171], [172, 181], [182, 184], [185, 191], [192, 194], [195, 199], [200, 203], [204, 211], [212, 214], [215, 224], [225, 227], [228, 232], [233, 237], [238, 240], [241, 244], [245, 250], [251, 254], [255, 264], [264, 265], [266, 269], [270, 276], [277, 280], [281, 286], [287, 290], [291, 294], [295, 300], [301, 307], [308, 319], [320, 323], [324, 332], [333, 335], [336, 339], [340, 344], [345, 350], [350, 351]]}
{"doc_key": "ai-test-408", "ner": [[0, 3, "metrics"], [8, 8, "metrics"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 0, 3, "part-of", "", false, false], [10, 10, 0, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "F", "-", "score", "is", "the", "combination", "of", "accuracy", "and", "return", ",", "which", "gives", "one", "point", "."], "sentence-detokenized": "The F-score is the combination of accuracy and return, which gives one point.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 18], [19, 30], [31, 33], [34, 42], [43, 46], [47, 53], [53, 54], [55, 60], [61, 66], [67, 70], [71, 76], [76, 77]]}
{"doc_key": "ai-test-409", "ner": [[8, 9, "task"], [14, 15, "product"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Image", "analysis", "tasks", "can", "be", "as", "simple", "as", "reading", "barcodes", "or", "as", "sophisticated", "as", "facial", "recognition", "."], "sentence-detokenized": "Image analysis tasks can be as simple as reading barcodes or as sophisticated as facial recognition.", "token2charspan": [[0, 5], [6, 14], [15, 20], [21, 24], [25, 27], [28, 30], [31, 37], [38, 40], [41, 48], [49, 57], [58, 60], [61, 63], [64, 77], [78, 80], [81, 87], [88, 99], [99, 100]]}
{"doc_key": "ai-test-410", "ner": [[5, 7, "algorithm"], [26, 27, "algorithm"], [34, 36, "algorithm"], [39, 39, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[34, 36, 26, 27, "type-of", "", false, false], [39, 39, 34, 36, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "special", "case", "of", "linear", "support", "vector", "machines", "can", "be", "solved", "more", "efficiently", "by", "the", "same", "type", "of", "algorithms", "that", "optimize", "it", "s", "close", "cousin", ",", "logistic", "regression", ";", "this", "class", "of", "algorithms", "includes", "stochastic", "gradient", "descent", "(", "e.g.", "PEGASOS", ")", "."], "sentence-detokenized": "The special case of linear support vector machines can be solved more efficiently by the same type of algorithms that optimize its close cousin, logistic regression; this class of algorithms includes stochastic gradient descent (e.g. PEGASOS).", "token2charspan": [[0, 3], [4, 11], [12, 16], [17, 19], [20, 26], [27, 34], [35, 41], [42, 50], [51, 54], [55, 57], [58, 64], [65, 69], [70, 81], [82, 84], [85, 88], [89, 93], [94, 98], [99, 101], [102, 112], [113, 117], [118, 126], [127, 129], [129, 130], [131, 136], [137, 143], [143, 144], [145, 153], [154, 164], [164, 165], [166, 170], [171, 176], [177, 179], [180, 190], [191, 199], [200, 210], [211, 219], [220, 227], [228, 229], [229, 233], [234, 241], [241, 242], [242, 243]]}
{"doc_key": "ai-test-411", "ner": [[1, 1, "product"], [0, 4, "product"], [18, 19, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 0, 4, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["When", "Siri", "on", "iOS", "is", "asked", "Do", "you", "have", "a", "pet", "?", ",", "one", "answer", "is", "I", "had", "an", "AIBO", "."], "sentence-detokenized": "When Siri on iOS is asked Do you have a pet?, one answer is I had an AIBO.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 16], [17, 19], [20, 25], [26, 28], [29, 32], [33, 37], [38, 39], [40, 43], [43, 44], [44, 45], [46, 49], [50, 56], [57, 59], [60, 61], [62, 65], [66, 68], [69, 73], [73, 74]]}
{"doc_key": "ai-test-412", "ner": [[0, 2, "task"], [4, 8, "metrics"], [10, 10, "metrics"], [13, 13, "metrics"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 8, 0, 2, "part-of", "", false, false], [10, 10, 4, 8, "named", "", false, false], [13, 13, 0, 2, "part-of", "", false, false], [16, 16, 13, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "information", "retrieval", ",", "a", "positive", "predictive", "value", "is", "called", "accuracy", ",", "and", "sensitivity", "is", "called", "recovery", "."], "sentence-detokenized": "In information retrieval, a positive predictive value is called accuracy, and sensitivity is called recovery.", "token2charspan": [[0, 2], [3, 14], [15, 24], [24, 25], [26, 27], [28, 36], [37, 47], [48, 53], [54, 56], [57, 63], [64, 72], [72, 73], [74, 77], [78, 89], [90, 92], [93, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-test-413", "ner": [[9, 10, "field"], [12, 12, "task"], [14, 14, "task"], [16, 17, "task"], [31, 32, "task"], [34, 35, "task"], [37, 40, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 12, 9, 10, "part-of", "task_part_of_field", false, false], [14, 14, 9, 10, "part-of", "task_part_of_field", false, false], [16, 17, 9, 10, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["His", "research", "focused", "in", "particular", "on", "areas", "such", "as", "text", "mining", "(", "mining", ",", "categorisation", ",", "novelty", "detection", ")", "and", "new", "theoretical", "frameworks", "such", "as", "unified", "utility", "theory", ",", "which", "combines", "information", "retrieval", ",", "automatic", "summarisation", ",", "free", "text", "question", "answering", "and", "related", "tasks", "."], "sentence-detokenized": "His research focused in particular on areas such as text mining (mining, categorisation, novelty detection) and new theoretical frameworks such as unified utility theory, which combines information retrieval, automatic summarisation, free text question answering and related tasks.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 23], [24, 34], [35, 37], [38, 43], [44, 48], [49, 51], [52, 56], [57, 63], [64, 65], [65, 71], [71, 72], [73, 87], [87, 88], [89, 96], [97, 106], [106, 107], [108, 111], [112, 115], [116, 127], [128, 138], [139, 143], [144, 146], [147, 154], [155, 162], [163, 169], [169, 170], [171, 176], [177, 185], [186, 197], [198, 207], [207, 208], [209, 218], [219, 232], [232, 233], [234, 238], [239, 243], [244, 252], [253, 262], [263, 266], [267, 274], [275, 280], [280, 281]]}
{"doc_key": "ai-test-414", "ner": [[6, 8, "product"], [15, 16, "misc"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Delta", "robots", "have", "bottom", "-", "mounted", "rotary", "actuators", "that", "move", "a", "lightweight", ",", "rigid", ",", "parallel", "arm", "."], "sentence-detokenized": "Delta robots have bottom-mounted rotary actuators that move a lightweight, rigid, parallel arm.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 24], [24, 25], [25, 32], [33, 39], [40, 49], [50, 54], [55, 59], [60, 61], [62, 73], [73, 74], [75, 80], [80, 81], [82, 90], [91, 94], [94, 95]]}
{"doc_key": "ai-test-415", "ner": [[6, 12, "metrics"], [15, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "represented", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "a", "mixing", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be represented in a 2 \u00d7 2 contingency table or a mixing matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 35], [36, 38], [39, 40], [41, 42], [43, 44], [45, 46], [47, 58], [59, 64], [65, 67], [68, 69], [70, 76], [77, 83], [84, 86], [87, 94], [94, 95]]}
{"doc_key": "ai-test-416", "ner": [[29, 30, "task"], [36, 37, "task"], [42, 44, "task"], [46, 48, "task"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "actual", "task", "of", "data", "mining", "is", "the", "semi-automatic", "or", "automatic", "analysis", "of", "large", "amounts", "of", "data", "to", "extract", "unknown", ",", "interesting", "patterns", "such", "as", "groups", "of", "records", "(", "cluster", "analysis", ")", ",", "unusual", "records", "(", "outlier", "detection", ")", "and", "dependencies", "(", "association", "rule", "mining", ",", "sequential", "pattern", "mining", ")", "."], "sentence-detokenized": "The actual task of data mining is the semi-automatic or automatic analysis of large amounts of data to extract unknown, interesting patterns such as groups of records (cluster analysis), unusual records (outlier detection) and dependencies (association rule mining, sequential pattern mining).", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 18], [19, 23], [24, 30], [31, 33], [34, 37], [38, 52], [53, 55], [56, 65], [66, 74], [75, 77], [78, 83], [84, 91], [92, 94], [95, 99], [100, 102], [103, 110], [111, 118], [118, 119], [120, 131], [132, 140], [141, 145], [146, 148], [149, 155], [156, 158], [159, 166], [167, 168], [168, 175], [176, 184], [184, 185], [185, 186], [187, 194], [195, 202], [203, 204], [204, 211], [212, 221], [221, 222], [223, 226], [227, 239], [240, 241], [241, 252], [253, 257], [258, 264], [264, 265], [266, 276], [277, 284], [285, 291], [291, 292], [292, 293]]}
{"doc_key": "ai-test-417", "ner": [[0, 6, "task"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sentiment", "analysis", "has", "proven", "to", "be", "a", "valuable", "technique", "in", "the", "recommendation", "system", "."], "sentence-detokenized": "Sentiment analysis has proven to be a valuable technique in the recommendation system.", "token2charspan": [[0, 9], [10, 18], [19, 22], [23, 29], [30, 32], [33, 35], [36, 37], [38, 46], [47, 56], [57, 59], [60, 63], [64, 78], [79, 85], [85, 86]]}
{"doc_key": "ai-test-418", "ner": [[3, 4, "misc"], [11, 13, "product"], [34, 34, "organisation"], [38, 39, "location"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 11, 13, "usage", "", false, false], [34, 34, 38, 39, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["By", "chance", ",", "the", "Germans", "had", "chosen", "the", "operating", "frequency", "of", "the", "Wotan", "system", "very", "badly", ";", "it", "operated", "on", "45", "MHz", ",", "which", "happened", "to", "be", "the", "frequency", "of", "the", "powerful", "but", "dormant", "BBC", "television", "transmitter", "at", "Alexandra", "Palace", "."], "sentence-detokenized": "By chance, the Germans had chosen the operating frequency of the Wotan system very badly; it operated on 45 MHz, which happened to be the frequency of the powerful but dormant BBC television transmitter at Alexandra Palace.", "token2charspan": [[0, 2], [3, 9], [9, 10], [11, 14], [15, 22], [23, 26], [27, 33], [34, 37], [38, 47], [48, 57], [58, 60], [61, 64], [65, 70], [71, 77], [78, 82], [83, 88], [88, 89], [90, 92], [93, 101], [102, 104], [105, 107], [108, 111], [111, 112], [113, 118], [119, 127], [128, 130], [131, 133], [134, 137], [138, 147], [148, 150], [151, 154], [155, 163], [164, 167], [168, 175], [176, 179], [180, 190], [191, 202], [203, 205], [206, 215], [216, 222], [222, 223]]}
{"doc_key": "ai-test-419", "ner": [[6, 12, "metrics"], [15, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "represented", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "a", "mixing", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be represented in a 2 \u00d7 2 contingency table or a mixing matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 35], [36, 38], [39, 40], [41, 42], [43, 44], [45, 46], [47, 58], [59, 64], [65, 67], [68, 69], [70, 76], [77, 83], [84, 86], [87, 94], [94, 95]]}
{"doc_key": "ai-test-420", "ner": [[0, 3, "misc"], [8, 9, "misc"], [12, 12, "product"], [14, 14, "product"], [16, 18, "product"], [25, 26, "misc"], [34, 38, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[12, 12, 8, 9, "usage", "", false, false], [14, 14, 8, 9, "usage", "", false, false], [16, 18, 14, 14, "named", "", false, false], [25, 26, 8, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "semantic", "web", "applications", "and", "in", "relatively", "popular", "RDF", "applications", "such", "as", "RSS", "and", "FOAF", "(", "Friend", "a", "Friend", ")", ",", "resources", "are", "usually", "represented", "by", "URIs", ",", "which", "intentionally", "express", "the", "actual", "data", "on", "the", "World", "Wide", "Web", "and", "can", "be", "used", "to", "access", "it", "."], "sentence-detokenized": "In semantic web applications and in relatively popular RDF applications such as RSS and FOAF (Friend a Friend), resources are usually represented by URIs, which intentionally express the actual data on the World Wide Web and can be used to access it.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 28], [29, 32], [33, 35], [36, 46], [47, 54], [55, 58], [59, 71], [72, 76], [77, 79], [80, 83], [84, 87], [88, 92], [93, 94], [94, 100], [101, 102], [103, 109], [109, 110], [110, 111], [112, 121], [122, 125], [126, 133], [134, 145], [146, 148], [149, 153], [153, 154], [155, 160], [161, 174], [175, 182], [183, 186], [187, 193], [194, 198], [199, 201], [202, 205], [206, 211], [212, 216], [217, 220], [221, 224], [225, 228], [229, 231], [232, 236], [237, 239], [240, 246], [247, 249], [249, 250]]}
{"doc_key": "ai-test-421", "ner": [[0, 7, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "has", "carried", "out", "an", "in", "-", "depth", "study", "on", "the", "subject", "."], "sentence-detokenized": "The Association for the Advancement of Artificial Intelligence has carried out an in-depth study on the subject.", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 35], [36, 38], [39, 49], [50, 62], [63, 66], [67, 74], [75, 78], [79, 81], [82, 84], [84, 85], [85, 90], [91, 96], [97, 99], [100, 103], [104, 111], [111, 112]]}
{"doc_key": "ai-test-422", "ner": [[4, 8, "product"], [15, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 16, 4, 8, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Out", "of", "curiosity", ",", "Apple", "'s", "Macintosh", "speech", "system", "has", "evolved", "into", "a", "fully", "supported", "PlainTalk", "program", "for", "the", "visually", "impaired", "."], "sentence-detokenized": "Out of curiosity, Apple's Macintosh speech system has evolved into a fully supported PlainTalk program for the visually impaired.", "token2charspan": [[0, 3], [4, 6], [7, 16], [16, 17], [18, 23], [23, 25], [26, 35], [36, 42], [43, 49], [50, 53], [54, 61], [62, 66], [67, 68], [69, 74], [75, 84], [85, 94], [95, 102], [103, 106], [107, 110], [111, 119], [120, 128], [128, 129]]}
{"doc_key": "ai-test-423", "ner": [[4, 5, "field"], [7, 8, "task"], [10, 11, "task"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 4, 5, "part-of", "task_part_of_field", false, false], [10, 11, 4, 5, "part-of", "task_part_of_field", false, false], [13, 14, 4, 5, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Other", "uses", "of", "ontologies", "in", "NLP", "include", "information", "retrieval", ",", "information", "mining", "and", "automatic", "summarisation", "."], "sentence-detokenized": "Other uses of ontologies in NLP include information retrieval, information mining and automatic summarisation.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 24], [25, 27], [28, 31], [32, 39], [40, 51], [52, 61], [61, 62], [63, 74], [75, 81], [82, 85], [86, 95], [96, 109], [109, 110]]}
{"doc_key": "ai-test-424", "ner": [[7, 15, "organisation"], [18, 22, "organisation"], [25, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Institute", "has", "worked", "closely", "with", "the", "Janelia", "Farm", "Campus", "of", "the", "Howard", "Hughes", "Medical", "Institute", ",", "the", "Allen", "Institute", "for", "Brain", "Science", "and", "the", "National", "Institutes", "of", "Health", "to", "develop", "better", "methods", "for", "reconstructing", "neuronal", "cell", "architectures", "."], "sentence-detokenized": "The Institute has worked closely with the Janelia Farm Campus of the Howard Hughes Medical Institute, the Allen Institute for Brain Science and the National Institutes of Health to develop better methods for reconstructing neuronal cell architectures.", "token2charspan": [[0, 3], [4, 13], [14, 17], [18, 24], [25, 32], [33, 37], [38, 41], [42, 49], [50, 54], [55, 61], [62, 64], [65, 68], [69, 75], [76, 82], [83, 90], [91, 100], [100, 101], [102, 105], [106, 111], [112, 121], [122, 125], [126, 131], [132, 139], [140, 143], [144, 147], [148, 156], [157, 167], [168, 170], [171, 177], [178, 180], [181, 188], [189, 195], [196, 203], [204, 207], [208, 222], [223, 231], [232, 236], [237, 250], [250, 251]]}
{"doc_key": "ai-test-425", "ner": [[0, 0, "organisation"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 0, 0, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Google", "recently", "announced", "that", "Google", "Translate", "translates", "roughly", "enough", "text", "per", "day", "(", "2012", ")", "to", "fill", "a", "million", "books", "."], "sentence-detokenized": "Google recently announced that Google Translate translates roughly enough text per day (2012) to fill a million books.", "token2charspan": [[0, 6], [7, 15], [16, 25], [26, 30], [31, 37], [38, 47], [48, 58], [59, 66], [67, 73], [74, 78], [79, 82], [83, 86], [87, 88], [88, 92], [92, 93], [94, 96], [97, 101], [102, 103], [104, 111], [112, 117], [117, 118]]}
{"doc_key": "ai-test-426", "ner": [[7, 7, "country"], [10, 10, "country"], [12, 12, "country"], [14, 14, "country"], [16, 16, "country"], [18, 21, "country"], [33, 34, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Events", "are", "held", "worldwide", ",", "with", "the", "UK", ",", "the", "US", ",", "Japan", ",", "Singapore", ",", "India", "and", "South", "Korea", "being", "the", "most", "popular", ",", "and", "increasingly", "popular", "in", "sub-continental", "countries", "such", "as", "Sri", "Lanka", "."], "sentence-detokenized": "Events are held worldwide, with the UK, the US, Japan, Singapore, India and South Korea being the most popular, and increasingly popular in sub-continental countries such as Sri Lanka.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 25], [25, 26], [27, 31], [32, 35], [36, 38], [38, 39], [40, 43], [44, 46], [46, 47], [48, 53], [53, 54], [55, 64], [64, 65], [66, 71], [72, 75], [76, 81], [82, 87], [88, 93], [94, 97], [98, 102], [103, 110], [110, 111], [112, 115], [116, 128], [129, 136], [137, 139], [140, 155], [156, 165], [166, 170], [171, 173], [174, 177], [178, 183], [183, 184]]}
{"doc_key": "ai-test-427", "ner": [[5, 6, "programlang"], [11, 11, "programlang"], [13, 13, "programlang"], [15, 16, "programlang"], [18, 18, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "packages", "are", "developed", "mainly", "in", "R", "and", "sometimes", "also", "in", "Java", ",", "C", ",", "C", "++", "and", "Fortran", "."], "sentence-detokenized": "These packages are developed mainly in R and sometimes also in Java, C, C++ and Fortran.", "token2charspan": [[0, 5], [6, 14], [15, 18], [19, 28], [29, 35], [36, 38], [39, 40], [41, 44], [45, 54], [55, 59], [60, 62], [63, 67], [67, 68], [69, 70], [70, 71], [72, 73], [73, 75], [76, 79], [80, 87], [87, 88]]}
{"doc_key": "ai-test-428", "ner": [[4, 6, "conference"], [5, 11, "conference"], [14, 14, "researcher"], [16, 16, "researcher"], [19, 20, "researcher"], [25, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6], "relations": [[5, 11, 4, 6, "named", "", false, false], [14, 14, 4, 6, "physical", "", false, false], [14, 14, 4, 6, "role", "", false, false], [14, 14, 19, 20, "role", "teams_up_with", false, false], [16, 16, 4, 6, "physical", "", false, false], [16, 16, 4, 6, "role", "", false, false], [16, 16, 19, 20, "role", "teams_up_with", false, false], [19, 20, 4, 6, "physical", "", false, false], [19, 20, 4, 6, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6, 7, 9, 10], "sentence": ["As", "part", "of", "the", "2006", "European", "Conference", "on", "Computer", "Vision", "(", "ECCV", ")", ",", "Dalal", "and", "Triggs", "worked", "with", "Cordelia", "Schmid", "to", "apply", "HOG", "detectors", "to", "human", "detection", "in", "movies", "and", "videos", "."], "sentence-detokenized": "As part of the 2006 European Conference on Computer Vision (ECCV), Dalal and Triggs worked with Cordelia Schmid to apply HOG detectors to human detection in movies and videos.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 14], [15, 19], [20, 28], [29, 39], [40, 42], [43, 51], [52, 58], [59, 60], [60, 64], [64, 65], [65, 66], [67, 72], [73, 76], [77, 83], [84, 90], [91, 95], [96, 104], [105, 111], [112, 114], [115, 120], [121, 124], [125, 134], [135, 137], [138, 143], [144, 153], [154, 156], [157, 163], [164, 167], [168, 174], [174, 175]]}
{"doc_key": "ai-test-429", "ner": [[3, 3, "metrics"], [5, 7, "metrics"], [10, 11, "task"], [18, 22, "metrics"], [27, 28, "metrics"], [31, 33, "metrics"], [35, 35, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7], "relations": [[3, 3, 10, 11, "related-to", "measured_with", false, false], [5, 7, 10, 11, "related-to", "measured_with", false, false], [35, 35, 31, 33, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 5], "sentence": ["In", "addition", "to", "sensitivity", "and", "specificity", ",", "the", "performance", "of", "a", "binary", "classification", "test", "can", "be", "measured", "by", "positive", "predictive", "value", "(", "PPV", ")", ",", "also", "known", "as", "accuracy", ",", "and", "negative", "predictive", "value", "(", "NPV", ")", "."], "sentence-detokenized": "In addition to sensitivity and specificity, the performance of a binary classification test can be measured by positive predictive value (PPV), also known as accuracy, and negative predictive value (NPV).", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 26], [27, 30], [31, 42], [42, 43], [44, 47], [48, 59], [60, 62], [63, 64], [65, 71], [72, 86], [87, 91], [92, 95], [96, 98], [99, 107], [108, 110], [111, 119], [120, 130], [131, 136], [137, 138], [138, 141], [141, 142], [142, 143], [144, 148], [149, 154], [155, 157], [158, 166], [166, 167], [168, 171], [172, 180], [181, 191], [192, 197], [198, 199], [199, 202], [202, 203], [203, 204]]}
{"doc_key": "ai-test-430", "ner": [[14, 18, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "such", "models", ",", "partial", "credit", "can", "be", "given", "for", "overlapping", "correspondences", "(", "e.g.", "using", "the", "Jaccard", "index", "criterion", ")", "."], "sentence-detokenized": "In such models, partial credit can be given for overlapping correspondences (e.g. using the Jaccard index criterion).", "token2charspan": [[0, 2], [3, 7], [8, 14], [14, 15], [16, 23], [24, 30], [31, 34], [35, 37], [38, 43], [44, 47], [48, 59], [60, 75], [76, 77], [77, 81], [82, 87], [88, 91], [92, 99], [100, 105], [106, 115], [115, 116], [116, 117]]}
{"doc_key": "ai-test-431", "ner": [[11, 20, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "also", "points", "to", "philosophical", "issues", "and", "possible", "misunderstandings", "in", "the", "use", "of", "maximum", "likelihood", "estimators", "and", "likelihood", "functions", "in", "the", "case", "of", "single", "-", "sample", "estimation", "."], "sentence-detokenized": "It also points to philosophical issues and possible misunderstandings in the use of maximum likelihood estimators and likelihood functions in the case of single-sample estimation.", "token2charspan": [[0, 2], [3, 7], [8, 14], [15, 17], [18, 31], [32, 38], [39, 42], [43, 51], [52, 69], [70, 72], [73, 76], [77, 80], [81, 83], [84, 91], [92, 102], [103, 113], [114, 117], [118, 128], [129, 138], [139, 141], [142, 145], [146, 150], [151, 153], [154, 160], [160, 161], [161, 167], [168, 178], [178, 179]]}
