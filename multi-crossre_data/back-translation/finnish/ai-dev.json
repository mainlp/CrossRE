{"doc_key": "ai-dev-1", "ner": [[2, 2, "metrics"], [5, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 11, 2, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Here", ",", "accuracy", "is", "measured", "by", "the", "error", "rate", ",", "which", "is", "defined", "as", ":"], "sentence-detokenized": "Here, accuracy is measured by the error rate, which is defined as:", "token2charspan": [[0, 4], [4, 5], [6, 14], [15, 17], [18, 26], [27, 29], [30, 33], [34, 39], [40, 44], [44, 45], [46, 51], [52, 54], [55, 62], [63, 65], [65, 66]]}
{"doc_key": "ai-dev-2", "ner": [[4, 4, "algorithm"], [11, 12, "misc"], [16, 18, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 4, 11, 12, "type-of", "", false, false], [4, 4, 16, 18, "related-to", "", false, false], [4, 4, 19, 20, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["From", "this", "perspective", ",", "SVM", "is", "closely", "related", "to", "other", "fundamental", "classification", "algorithms", ",", "such", "as", "regularized", "least", "squares", "logistic", "regression", "."], "sentence-detokenized": "From this perspective, SVM is closely related to other fundamental classification algorithms, such as regularized least squares logistic regression.", "token2charspan": [[0, 4], [5, 9], [10, 21], [21, 22], [23, 26], [27, 29], [30, 37], [38, 45], [46, 48], [49, 54], [55, 66], [67, 81], [82, 92], [92, 93], [94, 98], [99, 101], [102, 113], [114, 119], [120, 127], [128, 136], [137, 147], [147, 148]]}
{"doc_key": "ai-dev-3", "ner": [[0, 1, "person"], [3, 4, "person"], [15, 16, "person"], [18, 18, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 0, 1, "named", "actor_plays_character", false, false], [3, 4, 0, 1, "origin", "actor_plays_character", false, false], [18, 18, 15, 16, "named", "actor_plays_character", false, false], [18, 18, 15, 16, "origin", "actor_plays_character", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Brion", "James", "plays", "Leon", "Kowalski", ",", "a", "fighting", "and", "working", "-", "class", "republican", ",", "and", "Joanna", "Cassidy", "plays", "Zhora", ",", "an", "assassin", "republican", "."], "sentence-detokenized": "Brion James plays Leon Kowalski, a fighting and working-class republican, and Joanna Cassidy plays Zhora, an assassin republican.", "token2charspan": [[0, 5], [6, 11], [12, 17], [18, 22], [23, 31], [31, 32], [33, 34], [35, 43], [44, 47], [48, 55], [55, 56], [56, 61], [62, 72], [72, 73], [74, 77], [78, 84], [85, 92], [93, 98], [99, 104], [104, 105], [106, 108], [109, 117], [118, 128], [128, 129]]}
{"doc_key": "ai-dev-4", "ner": [[21, 23, "product"], [20, 25, "product"], [19, 19, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 23, 19, 19, "physical", "", false, false], [20, 25, 21, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "image", ",", "which", "was", "scanned", ",", "stored", "and", "recreated", "as", "digital", "pixels", ",", "was", "displayed", "on", "the", "NIST", "Standards", "Eastern", "Automatic", "Computer", "(", "SEAC", ")", "."], "sentence-detokenized": "The first image, which was scanned, stored and recreated as digital pixels, was displayed on the NIST Standards Eastern Automatic Computer (SEAC).", "token2charspan": [[0, 3], [4, 9], [10, 15], [15, 16], [17, 22], [23, 26], [27, 34], [34, 35], [36, 42], [43, 46], [47, 56], [57, 59], [60, 67], [68, 74], [74, 75], [76, 79], [80, 89], [90, 92], [93, 96], [97, 101], [102, 111], [112, 119], [120, 129], [130, 138], [139, 140], [140, 144], [144, 145], [145, 146]]}
{"doc_key": "ai-dev-5", "ner": [[0, 6, "task"], [20, 21, "task"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 6, 20, 21, "part-of", "", false, false], [0, 6, 23, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Segmenting", "text", "into", "topics", "or", "discourse", "turns", "can", "be", "useful", "for", "some", "natural", "processing", "tasks", ":", "it", "can", "significantly", "improve", "information", "retrieval", "or", "speech", "recognition", "(", "by", "indexing", "/", "recognizing", "documents", "more", "precisely", "or", "by", "returning", "a", "specific", "part", "of", "a", "document", "that", "matches", "a", "query", ")", "."], "sentence-detokenized": "Segmenting text into topics or discourse turns can be useful for some natural processing tasks: it can significantly improve information retrieval or speech recognition (by indexing/recognizing documents more precisely or by returning a specific part of a document that matches a query).", "token2charspan": [[0, 10], [11, 15], [16, 20], [21, 27], [28, 30], [31, 40], [41, 46], [47, 50], [51, 53], [54, 60], [61, 64], [65, 69], [70, 77], [78, 88], [89, 94], [94, 95], [96, 98], [99, 102], [103, 116], [117, 124], [125, 136], [137, 146], [147, 149], [150, 156], [157, 168], [169, 170], [170, 172], [173, 181], [181, 182], [182, 193], [194, 203], [204, 208], [209, 218], [219, 221], [222, 224], [225, 234], [235, 236], [237, 245], [246, 250], [251, 253], [254, 255], [256, 264], [265, 269], [270, 277], [278, 279], [280, 285], [285, 286], [286, 287]]}
{"doc_key": "ai-dev-6", "ner": [[5, 8, "university"], [24, 25, "conference"], [20, 22, "university"], [34, 35, "researcher"], [37, 38, "researcher"], [40, 41, "researcher"], [43, 44, "researcher"], [46, 47, "researcher"], [49, 50, "researcher"], [52, 54, "researcher"], [56, 57, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[24, 25, 20, 22, "physical", "", false, false], [34, 35, 24, 25, "physical", "", false, false], [34, 35, 24, 25, "role", "", false, false], [34, 35, 24, 25, "temporal", "", false, false], [37, 38, 24, 25, "physical", "", false, false], [37, 38, 24, 25, "role", "", false, false], [37, 38, 24, 25, "temporal", "", false, false], [40, 41, 24, 25, "physical", "", false, false], [40, 41, 24, 25, "role", "", false, false], [40, 41, 24, 25, "temporal", "", false, false], [43, 44, 24, 25, "physical", "", false, false], [43, 44, 24, 25, "role", "", false, false], [43, 44, 24, 25, "temporal", "", false, false], [46, 47, 24, 25, "physical", "", false, false], [46, 47, 24, 25, "role", "", false, false], [46, 47, 24, 25, "temporal", "", false, false], [49, 50, 24, 25, "physical", "", false, false], [49, 50, 24, 25, "role", "", false, false], [49, 50, 24, 25, "temporal", "", false, false], [52, 54, 24, 25, "physical", "", false, false], [52, 54, 24, 25, "role", "", false, false], [52, 54, 24, 25, "temporal", "", false, false], [56, 57, 24, 25, "physical", "", false, false], [56, 57, 24, 25, "role", "", false, false], [56, 57, 24, 25, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "sentence": ["He", "organized", "such", "a", "symposium", "at", "Indiana", "University", "in", "1999", ",", "and", "in", "April", "2000", "he", "organized", "a", "larger", "symposium", "at", "Stanford", "University", "called", "Spiritual", "Robots", ",", "where", "he", "chaired", "a", "panel", "that", "included", "Ray", "Kurzweil", ",", "Hans", "Moravec", ",", "Kevin", "Kelly", ",", "Ralph", "Merkle", ",", "Bill", "Joy", ",", "Frank", "Drake", ",", "John", "Henry", "Holland", "and", "John", "Koza", "."], "sentence-detokenized": "He organized such a symposium at Indiana University in 1999, and in April 2000 he organized a larger symposium at Stanford University called Spiritual Robots, where he chaired a panel that included Ray Kurzweil, Hans Moravec, Kevin Kelly, Ralph Merkle, Bill Joy, Frank Drake, John Henry Holland and John Koza.", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 19], [20, 29], [30, 32], [33, 40], [41, 51], [52, 54], [55, 59], [59, 60], [61, 64], [65, 67], [68, 73], [74, 78], [79, 81], [82, 91], [92, 93], [94, 100], [101, 110], [111, 113], [114, 122], [123, 133], [134, 140], [141, 150], [151, 157], [157, 158], [159, 164], [165, 167], [168, 175], [176, 177], [178, 183], [184, 188], [189, 197], [198, 201], [202, 210], [210, 211], [212, 216], [217, 224], [224, 225], [226, 231], [232, 237], [237, 238], [239, 244], [245, 251], [251, 252], [253, 257], [258, 261], [261, 262], [263, 268], [269, 274], [274, 275], [276, 280], [281, 286], [287, 294], [295, 298], [299, 303], [304, 308], [308, 309]]}
{"doc_key": "ai-dev-7", "ner": [[5, 7, "metrics"], [8, 8, "metrics"], [12, 13, "metrics"], [14, 14, "metrics"], [20, 20, "metrics"], [40, 40, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 7, 20, 20, "named", "", false, false], [8, 8, 5, 7, "named", "", false, false], [12, 13, 40, 40, "named", "", false, false], [14, 14, 12, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "takes", "into", "account", "both", "the", "test", "accuracy", "p", "and", "the", "test", "recovery", "rate", "r", "when", "calculating", "the", "score", ":", "p", "is", "the", "number", "of", "true", "positives", "divided", "by", "the", "total", "number", "of", "positives", "returned", "by", "the", "classifier", ",", "and", "r", "is", "the", "number", "of", "true", "positives", "divided", "by", "the", "total", "number", "of", "relevant", "samples", "(", "all", "samples", "that", "should", "have", "been", "identified", "as", "positive", ")", "."], "sentence-detokenized": "It takes into account both the test accuracy p and the test recovery rate r when calculating the score: p is the number of true positives divided by the total number of positives returned by the classifier, and r is the number of true positives divided by the total number of relevant samples (all samples that should have been identified as positive).", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 21], [22, 26], [27, 30], [31, 35], [36, 44], [45, 46], [47, 50], [51, 54], [55, 59], [60, 68], [69, 73], [74, 75], [76, 80], [81, 92], [93, 96], [97, 102], [102, 103], [104, 105], [106, 108], [109, 112], [113, 119], [120, 122], [123, 127], [128, 137], [138, 145], [146, 148], [149, 152], [153, 158], [159, 165], [166, 168], [169, 178], [179, 187], [188, 190], [191, 194], [195, 205], [205, 206], [207, 210], [211, 212], [213, 215], [216, 219], [220, 226], [227, 229], [230, 234], [235, 244], [245, 252], [253, 255], [256, 259], [260, 265], [266, 272], [273, 275], [276, 284], [285, 292], [293, 294], [294, 297], [298, 305], [306, 310], [311, 317], [318, 322], [323, 327], [328, 338], [339, 341], [342, 350], [350, 351], [351, 352]]}
{"doc_key": "ai-dev-8", "ner": [[4, 6, "organisation"], [20, 22, "product"], [26, 28, "person"], [31, 32, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 20, 22, "artifact", "", false, false], [20, 22, 26, 28, "win-defeat", "", false, false], [20, 22, 31, 32, "win-defeat", "", true, false], [26, 28, 31, 32, "win-defeat", "lose", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "the", "acquisition", "of", "Google", ",", "the", "company", "has", "made", "several", "significant", "achievements", ",", "perhaps", "most", "notably", "the", "creation", "of", "AlphaGo", ",", "which", "beat", "world", "champion", "Lee", "Sedol", "in", "a", "complex", "Go", "game", "."], "sentence-detokenized": "Since the acquisition of Google, the company has made several significant achievements, perhaps most notably the creation of AlphaGo, which beat world champion Lee Sedol in a complex Go game.", "token2charspan": [[0, 5], [6, 9], [10, 21], [22, 24], [25, 31], [31, 32], [33, 36], [37, 44], [45, 48], [49, 53], [54, 61], [62, 73], [74, 86], [86, 87], [88, 95], [96, 100], [101, 108], [109, 112], [113, 121], [122, 124], [125, 132], [132, 133], [134, 139], [140, 144], [145, 150], [151, 159], [160, 163], [164, 169], [170, 172], [173, 174], [175, 182], [183, 185], [186, 190], [190, 191]]}
{"doc_key": "ai-dev-9", "ner": [[14, 15, "misc"], [31, 33, "product"], [50, 51, "misc"], [39, 56, "misc"], [59, 59, "product"]], "ner_mapping_to_source": [0, 2, 3, 4, 5], "relations": [[14, 15, 39, 56, "named", "same", false, false], [31, 33, 50, 51, "related-to", "", false, false], [31, 33, 39, 56, "usage", "", false, false], [31, 33, 59, 59, "usage", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4], "sentence": ["The", "representation", "of", "words", "in", "their", "context", "by", "fixed", "-", "size", "dense", "vectors", "(", "word", "embeddings", ")", "has", "become", "one", "of", "the", "most", "fundamental", "blocks", "in", "many", "NLP", "systems", ".", "An", "unsupervised", "disambiguation", "system", "uses", "the", "similarity", "between", "word", "embeddings", "in", "a", "fixed", "context", "window", "to", "select", "the", "most", "appropriate", "word", "embedding", "using", "a", "pre-trained", "word", "embedding", "model", "and", "WordNet", "."], "sentence-detokenized": "The representation of words in their context by fixed-size dense vectors (word embeddings) has become one of the most fundamental blocks in many NLP systems. An unsupervised disambiguation system uses the similarity between word embeddings in a fixed context window to select the most appropriate word embedding using a pre-trained word embedding model and WordNet.", "token2charspan": [[0, 3], [4, 18], [19, 21], [22, 27], [28, 30], [31, 36], [37, 44], [45, 47], [48, 53], [53, 54], [54, 58], [59, 64], [65, 72], [73, 74], [74, 78], [79, 89], [89, 90], [91, 94], [95, 101], [102, 105], [106, 108], [109, 112], [113, 117], [118, 129], [130, 136], [137, 139], [140, 144], [145, 148], [149, 156], [156, 157], [158, 160], [161, 173], [174, 188], [189, 195], [196, 200], [201, 204], [205, 215], [216, 223], [224, 228], [229, 239], [240, 242], [243, 244], [245, 250], [251, 258], [259, 265], [266, 268], [269, 275], [276, 279], [280, 284], [285, 296], [297, 301], [302, 311], [312, 317], [318, 319], [320, 331], [332, 336], [337, 346], [347, 352], [353, 356], [357, 364], [364, 365]]}
{"doc_key": "ai-dev-10", "ner": [[5, 5, "field"], [7, 8, "field"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Machine", "learning", "techniques", ",", "either", "supervised", "or", "unsupervised", "learning", ",", "have", "been", "used", "to", "automatically", "generate", "such", "rules", "."], "sentence-detokenized": "Machine learning techniques, either supervised or unsupervised learning, have been used to automatically generate such rules.", "token2charspan": [[0, 7], [8, 16], [17, 27], [27, 28], [29, 35], [36, 46], [47, 49], [50, 62], [63, 71], [71, 72], [73, 77], [78, 82], [83, 87], [88, 90], [91, 104], [105, 113], [114, 118], [119, 124], [124, 125]]}
{"doc_key": "ai-dev-11", "ner": [[3, 3, "researcher"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1969", ",", "Scheinman", "invented", "the", "Stanford", "arm", ","], "sentence-detokenized": "In 1969, Scheinman invented the Stanford arm,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 27], [28, 31], [32, 40], [41, 44], [44, 45]]}
{"doc_key": "ai-dev-12", "ner": [[2, 4, "metrics"], [9, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Since", "the", "log", "-", "loss", "is", "differentiable", ",", "a", "gradient", "-", "based", "method", "can", "be", "used", "to", "optimise", "the", "model", "."], "sentence-detokenized": "Since the log-loss is differentiable, a gradient-based method can be used to optimise the model.", "token2charspan": [[0, 5], [6, 9], [10, 13], [13, 14], [14, 18], [19, 21], [22, 36], [36, 37], [38, 39], [40, 48], [48, 49], [49, 54], [55, 61], [62, 65], [66, 68], [69, 73], [74, 76], [77, 85], [86, 89], [90, 95], [95, 96]]}
{"doc_key": "ai-dev-13", "ner": [[4, 6, "algorithm"], [8, 8, "algorithm"], [13, 15, "algorithm"], [18, 18, "field"], [28, 28, "task"], [30, 31, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [[4, 6, 18, 18, "part-of", "", false, false], [8, 8, 4, 6, "named", "", false, false], [13, 15, 4, 6, "named", "", false, false], [28, 28, 18, 18, "part-of", "", false, false], [30, 31, 18, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 4, 5], "sentence": ["In", "machine", "learning", ",", "support", "vector", "machines", "(", "SVMs", ",", "also", "known", "as", "support", "vector", "networks", ")", "are", "supervised", "learning", "models", "with", "learning", "algorithms", "that", "analyse", "data", "for", "classification", "and", "regression", "analyses", "."], "sentence-detokenized": "In machine learning, support vector machines (SVMs, also known as support vector networks) are supervised learning models with learning algorithms that analyse data for classification and regression analyses.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 28], [29, 35], [36, 44], [45, 46], [46, 50], [50, 51], [52, 56], [57, 62], [63, 65], [66, 73], [74, 80], [81, 89], [89, 90], [91, 94], [95, 105], [106, 114], [115, 121], [122, 126], [127, 135], [136, 146], [147, 151], [152, 159], [160, 164], [165, 168], [169, 183], [184, 187], [188, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-dev-14", "ner": [[10, 10, "task"], [9, 12, "task"], [29, 29, "metrics"], [31, 31, "metrics"], [33, 33, "researcher"], [35, 35, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 12, 10, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": [",", "(", "2002", ")", "as", "an", "automatic", "measure", "of", "machine", "translation", "(", "MT", ")", ",", "many", "other", "methods", "have", "been", "proposed", "to", "revise", "or", "improve", "it", ",", "such", "as", "TER", ",", "METEOR", ",", "Banerjee", "and", "Lavie", ",", "(", "2005", ")", "etc", "."], "sentence-detokenized": ", (2002) as an automatic measure of machine translation (MT), many other methods have been proposed to revise or improve it, such as TER, METEOR, Banerjee and Lavie, (2005) etc.", "token2charspan": [[0, 1], [2, 3], [3, 7], [7, 8], [9, 11], [12, 14], [15, 24], [25, 32], [33, 35], [36, 43], [44, 55], [56, 57], [57, 59], [59, 60], [60, 61], [62, 66], [67, 72], [73, 80], [81, 85], [86, 90], [91, 99], [100, 102], [103, 109], [110, 112], [113, 120], [121, 123], [123, 124], [125, 129], [130, 132], [133, 136], [136, 137], [138, 144], [144, 145], [146, 154], [155, 158], [159, 164], [164, 165], [166, 167], [167, 171], [171, 172], [173, 176], [176, 177]]}
{"doc_key": "ai-dev-15", "ner": [[2, 4, "misc"], [7, 7, "organisation"], [10, 10, "organisation"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 4, 10, 10, "origin", "", false, false], [10, 10, 7, 7, "part-of", "", false, false], [13, 14, 10, 10, "role", "", false, false], [16, 17, 10, 10, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "includes", "the", "upper", "ontology", "created", "by", "IEEE", "working", "group", "P1600.1", "(", "originally", "Ian", "Niles", "and", "Adam", "Pease", ")", "."], "sentence-detokenized": "It includes the upper ontology created by IEEE working group P1600.1 (originally Ian Niles and Adam Pease).", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 21], [22, 30], [31, 38], [39, 41], [42, 46], [47, 54], [55, 60], [61, 68], [69, 70], [70, 80], [81, 84], [85, 90], [91, 94], [95, 99], [100, 105], [105, 106], [106, 107]]}
{"doc_key": "ai-dev-16", "ner": [[0, 5, "misc"], [30, 32, "algorithm"], [34, 34, "algorithm"], [37, 38, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[30, 32, 0, 5, "part-of", "", true, false], [34, 34, 0, 5, "part-of", "", true, false], [37, 38, 34, 34, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "cryoelectron", "tomography", ",", "where", "a", "limited", "number", "of", "projections", "are", "acquired", "due", "to", "equipment", "limitations", "and", "to", "avoid", "damaging", "biological", "samples", ",", "it", "can", "be", "used", "in", "combination", "with", "compressive", "sensing", "techniques", "or", "regularisation", "(", "e.g.", "Huber", "loss", ")", "to", "improve", "reconstruction", "for", "better", "interpretation", "."], "sentence-detokenized": "In cryoelectron tomography, where a limited number of projections are acquired due to equipment limitations and to avoid damaging biological samples, it can be used in combination with compressive sensing techniques or regularisation (e.g. Huber loss) to improve reconstruction for better interpretation.", "token2charspan": [[0, 2], [3, 15], [16, 26], [26, 27], [28, 33], [34, 35], [36, 43], [44, 50], [51, 53], [54, 65], [66, 69], [70, 78], [79, 82], [83, 85], [86, 95], [96, 107], [108, 111], [112, 114], [115, 120], [121, 129], [130, 140], [141, 148], [148, 149], [150, 152], [153, 156], [157, 159], [160, 164], [165, 167], [168, 179], [180, 184], [185, 196], [197, 204], [205, 215], [216, 218], [219, 233], [234, 235], [235, 239], [240, 245], [246, 250], [250, 251], [252, 254], [255, 262], [263, 277], [278, 281], [282, 288], [289, 303], [303, 304]]}
{"doc_key": "ai-dev-17", "ner": [[6, 7, "programlang"], [10, 11, "algorithm"], [13, 14, "algorithm"], [17, 18, "algorithm"], [24, 26, "product"], [28, 29, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [[24, 26, 6, 7, "general-affiliation", "", true, false], [24, 26, 6, 7, "part-of", "", true, false], [28, 29, 24, 26, "role", "publishes", false, false]], "relations_mapping_to_source": [4, 5, 6], "sentence": ["The", "implementation", "of", "several", "bleaching", "methods", "in", "R", ",", "including", "ZCA", "bleaching", "and", "PCA", "bleaching", "but", "also", "CCA", "bleaching", ",", "is", "available", "in", "the", "whitening", "R", "package", "published", "in", "CRAN", "."], "sentence-detokenized": "The implementation of several bleaching methods in R, including ZCA bleaching and PCA bleaching but also CCA bleaching, is available in the whitening R package published in CRAN.", "token2charspan": [[0, 3], [4, 18], [19, 21], [22, 29], [30, 39], [40, 47], [48, 50], [51, 52], [52, 53], [54, 63], [64, 67], [68, 77], [78, 81], [82, 85], [86, 95], [96, 99], [100, 104], [105, 108], [109, 118], [118, 119], [120, 122], [123, 132], [133, 135], [136, 139], [140, 149], [150, 151], [152, 159], [160, 169], [170, 172], [173, 177], [177, 178]]}
{"doc_key": "ai-dev-18", "ner": [[29, 30, "product"], [32, 32, "product"], [33, 34, "product"], [36, 36, "product"], [38, 38, "product"], [40, 40, "product"], [43, 44, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[29, 30, 33, 34, "compare", "", false, false], [29, 30, 36, 36, "compare", "", false, false], [29, 30, 38, 38, "compare", "", false, false], [29, 30, 40, 40, "compare", "", false, false], [29, 30, 43, 44, "compare", "", false, false], [32, 32, 33, 34, "compare", "", false, false], [32, 32, 36, 36, "compare", "", false, false], [32, 32, 38, 38, "compare", "", false, false], [32, 32, 40, 40, "compare", "", false, false], [32, 32, 43, 44, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Today", ",", "the", "field", "has", "become", "even", "more", "daunting", "and", "complex", ",", "with", "the", "addition", "of", "languages", "and", "software", "for", "analysing", "and", "designing", "circuits", ",", "systems", "and", "signals", ",", "from", "MATLAB", "and", "Simulink", "to", "NumPy", ",", "VHDL", ",", "PSpice", ",", "Verilog", "and", "even", "Assembly", "language", "."], "sentence-detokenized": "Today, the field has become even more daunting and complex, with the addition of languages and software for analysing and designing circuits, systems and signals, from MATLAB and Simulink to NumPy, VHDL, PSpice, Verilog and even Assembly language.", "token2charspan": [[0, 5], [5, 6], [7, 10], [11, 16], [17, 20], [21, 27], [28, 32], [33, 37], [38, 46], [47, 50], [51, 58], [58, 59], [60, 64], [65, 68], [69, 77], [78, 80], [81, 90], [91, 94], [95, 103], [104, 107], [108, 117], [118, 121], [122, 131], [132, 140], [140, 141], [142, 149], [150, 153], [154, 161], [161, 162], [163, 167], [168, 174], [175, 178], [179, 187], [188, 190], [191, 196], [196, 197], [198, 202], [202, 203], [204, 210], [210, 211], [212, 219], [220, 223], [224, 228], [229, 237], [238, 246], [246, 247]]}
{"doc_key": "ai-dev-19", "ner": [[0, 1, "person"], [13, 15, "person"], [16, 19, "organisation"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[16, 19, 13, 15, "origin", "", false, false], [23, 23, 16, 19, "artifact", "builds", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Kiichiro", "Toyoda", "founded", "the", "company", "in", "1937", "as", "a", "spin", "-", "off", "of", "Sakichi", "Toyoda", "'s", "Toyota", "Industries", ",", "a", "company", "that", "created", "cars", "."], "sentence-detokenized": "Kiichiro Toyoda founded the company in 1937 as a spin-off of Sakichi Toyoda's Toyota Industries, a company that created cars.", "token2charspan": [[0, 8], [9, 15], [16, 23], [24, 27], [28, 35], [36, 38], [39, 43], [44, 46], [47, 48], [49, 53], [53, 54], [54, 57], [58, 60], [61, 68], [69, 75], [75, 77], [78, 84], [85, 95], [95, 96], [97, 98], [99, 106], [107, 111], [112, 119], [120, 124], [124, 125]]}
{"doc_key": "ai-dev-20", "ner": [[0, 6, "field"], [52, 55, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[52, 55, 0, 6, "origin", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Unsupervised", "learning", ",", "on", "the", "other", "hand", ",", "requires", "training", "data", "that", "has", "not", "been", "manually", "labeled", ",", "and", "seeks", "to", "find", "intrinsic", "patterns", "in", "the", "data", "that", "can", "be", "used", "to", "determine", "the", "correct", "output", "for", "new", "data", "instances", ".", "A", "combination", "of", "the", "two", "that", "has", "been", "recently", "studied", "is", "semi-supervised", "learning", ",", "which", "uses", "a", "combination", "of", "labeled", "and", "unlabeled", "data", "(", "typically", "a", "small", "amount", "of", "labeled", "data", "combined", "with", "a", "large", "amount", "of", "unlabeled", "data", ")", "."], "sentence-detokenized": "Unsupervised learning, on the other hand, requires training data that has not been manually labeled, and seeks to find intrinsic patterns in the data that can be used to determine the correct output for new data instances. A combination of the two that has been recently studied is semi-supervised learning, which uses a combination of labeled and unlabeled data (typically a small amount of labeled data combined with a large amount of unlabeled data).", "token2charspan": [[0, 12], [13, 21], [21, 22], [23, 25], [26, 29], [30, 35], [36, 40], [40, 41], [42, 50], [51, 59], [60, 64], [65, 69], [70, 73], [74, 77], [78, 82], [83, 91], [92, 99], [99, 100], [101, 104], [105, 110], [111, 113], [114, 118], [119, 128], [129, 137], [138, 140], [141, 144], [145, 149], [150, 154], [155, 158], [159, 161], [162, 166], [167, 169], [170, 179], [180, 183], [184, 191], [192, 198], [199, 202], [203, 206], [207, 211], [212, 221], [221, 222], [223, 224], [225, 236], [237, 239], [240, 243], [244, 247], [248, 252], [253, 256], [257, 261], [262, 270], [271, 278], [279, 281], [282, 297], [298, 306], [306, 307], [308, 313], [314, 318], [319, 320], [321, 332], [333, 335], [336, 343], [344, 347], [348, 357], [358, 362], [363, 364], [364, 373], [374, 375], [376, 381], [382, 388], [389, 391], [392, 399], [400, 404], [405, 413], [414, 418], [419, 420], [421, 426], [427, 433], [434, 436], [437, 446], [447, 451], [451, 452], [452, 453]]}
{"doc_key": "ai-dev-21", "ner": [[17, 17, "product"], [19, 19, "organisation"], [22, 22, "product"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[19, 19, 22, 22, "artifact", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Despite", "these", "commercial", "humanoid", "robots", ",", "there", "are", "some", "entertainment", "humanoid", "robots", ",", "such", "as", "Sony", "'s", "QRIO", "and", "Wow", "Wee", "'s", "RoboSapien", "."], "sentence-detokenized": "Despite these commercial humanoid robots, there are some entertainment humanoid robots, such as Sony's QRIO and Wow Wee's RoboSapien.", "token2charspan": [[0, 7], [8, 13], [14, 24], [25, 33], [34, 40], [40, 41], [42, 47], [48, 51], [52, 56], [57, 70], [71, 79], [80, 86], [86, 87], [88, 92], [93, 95], [96, 100], [100, 102], [103, 107], [108, 111], [112, 115], [116, 119], [119, 121], [122, 132], [132, 133]]}
{"doc_key": "ai-dev-22", "ner": [[0, 0, "researcher"], [5, 13, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 13, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Webber", "became", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "in", "1991", ","], "sentence-detokenized": "Webber became a member of the Association for the Advancement of Artificial Intelligence in 1991,", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 22], [23, 25], [26, 29], [30, 41], [42, 45], [46, 49], [50, 61], [62, 64], [65, 75], [76, 88], [89, 91], [92, 96], [96, 97]]}
{"doc_key": "ai-dev-23", "ner": [[6, 7, "field"], [21, 24, "task"]], "ner_mapping_to_source": [0, 2], "relations": [[21, 24, 6, 7, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "this", "company", ",", "he", "developed", "data", "mining", "and", "database", "technologies", ",", "in", "particular", "high", "-", "level", "ontologies", "for", "intelligence", "and", "automatic", "natural", "language", "understanding", "."], "sentence-detokenized": "In this company, he developed data mining and database technologies, in particular high-level ontologies for intelligence and automatic natural language understanding.", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 19], [20, 29], [30, 34], [35, 41], [42, 45], [46, 54], [55, 67], [67, 68], [69, 71], [72, 82], [83, 87], [87, 88], [88, 93], [94, 104], [105, 108], [109, 121], [122, 125], [126, 135], [136, 143], [144, 152], [153, 166], [166, 167]]}
{"doc_key": "ai-dev-24", "ner": [[20, 21, "misc"], [23, 26, "misc"], [28, 29, "misc"], [30, 31, "country"], [33, 35, "organisation"], [36, 37, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 21, 30, 31, "physical", "", false, false], [23, 26, 30, 31, "physical", "", false, false], [28, 29, 30, 31, "physical", "", false, false], [33, 35, 36, 37, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["However", ",", "in", "recent", "years", ",", "various", "e-services", "and", "related", "initiatives", "have", "been", "seen", "in", "developing", "countries", ",", "such", "as", "Project", "Nemmadi", ",", "MCA21", "Mission", "Mode", "Project", "or", "Digital", "India", "in", "India", ",", "Electronic", "Government", "Directorate", "in", "Pakistan", ",", "etc."], "sentence-detokenized": "However, in recent years, various e-services and related initiatives have been seen in developing countries, such as Project Nemmadi, MCA21 Mission Mode Project or Digital India in India, Electronic Government Directorate in Pakistan, etc.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 18], [19, 24], [24, 25], [26, 33], [34, 44], [45, 48], [49, 56], [57, 68], [69, 73], [74, 78], [79, 83], [84, 86], [87, 97], [98, 107], [107, 108], [109, 113], [114, 116], [117, 124], [125, 132], [132, 133], [134, 139], [140, 147], [148, 152], [153, 160], [161, 163], [164, 171], [172, 177], [178, 180], [181, 186], [186, 187], [188, 198], [199, 209], [210, 221], [222, 224], [225, 233], [233, 234], [235, 239]]}
{"doc_key": "ai-dev-25", "ner": [[1, 4, "misc"], [5, 6, "field"], [8, 8, "field"], [11, 13, "university"], [17, 20, "university"], [27, 29, "university"], [31, 34, "misc"], [35, 36, "field"], [40, 43, "misc"], [44, 45, "university"], [49, 50, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[1, 4, 5, 6, "topic", "", false, false], [1, 4, 8, 8, "topic", "", false, false], [1, 4, 11, 13, "origin", "", false, false], [11, 13, 17, 20, "part-of", "", false, false], [27, 29, 11, 13, "part-of", "", false, false], [31, 34, 35, 36, "topic", "", false, false], [31, 34, 44, 45, "origin", "", false, false], [40, 43, 44, 45, "origin", "", false, false], [44, 45, 49, 50, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["He", "obtained", "his", "PhD", "in", "radio", "physics", "and", "electronics", "from", "the", "Rajabazar", "Science", "College", "campus", "of", "the", "University", "of", "Calcutta", "in", "1979", "as", "a", "student", "of", "the", "Indian", "Statistical", "Institute", "and", "his", "second", "PhD", "in", "electrical", "engineering", "and", "received", "his", "Imperial", "College", "Diploma", "from", "Imperial", "College", ",", "University", "of", "London", "in", "1982", "."], "sentence-detokenized": "He obtained his PhD in radio physics and electronics from the Rajabazar Science College campus of the University of Calcutta in 1979 as a student of the Indian Statistical Institute and his second PhD in electrical engineering and received his Imperial College Diploma from Imperial College, University of London in 1982.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 19], [20, 22], [23, 28], [29, 36], [37, 40], [41, 52], [53, 57], [58, 61], [62, 71], [72, 79], [80, 87], [88, 94], [95, 97], [98, 101], [102, 112], [113, 115], [116, 124], [125, 127], [128, 132], [133, 135], [136, 137], [138, 145], [146, 148], [149, 152], [153, 159], [160, 171], [172, 181], [182, 185], [186, 189], [190, 196], [197, 200], [201, 203], [204, 214], [215, 226], [227, 230], [231, 239], [240, 243], [244, 252], [253, 260], [261, 268], [269, 273], [274, 282], [283, 290], [290, 291], [292, 302], [303, 305], [306, 312], [313, 315], [316, 320], [320, 321]]}
{"doc_key": "ai-dev-26", "ner": [[0, 1, "location"], [22, 24, "misc"], [30, 31, "misc"], [34, 36, "person"], [38, 39, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[22, 24, 0, 1, "temporal", "", false, false], [30, 31, 0, 1, "temporal", "", false, false], [34, 36, 30, 31, "role", "actor_in", false, false], [38, 39, 30, 31, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Expo", "II", "was", "announced", "as", "the", "world", "premiere", "of", "several", "3D", "films", "that", "have", "never", "been", "seen", "in", "3D", "before", ",", "including", "The", "Diamond", "Wizard", "and", "Universal", "'s", "short", "film", "Hawaiian", "Nights", ",", "starring", "Mamie", "Van", "Doren", "and", "Pinky", "Lee", "."], "sentence-detokenized": "Expo II was announced as the world premiere of several 3D films that have never been seen in 3D before, including The Diamond Wizard and Universal's short film Hawaiian Nights, starring Mamie Van Doren and Pinky Lee.", "token2charspan": [[0, 4], [5, 7], [8, 11], [12, 21], [22, 24], [25, 28], [29, 34], [35, 43], [44, 46], [47, 54], [55, 57], [58, 63], [64, 68], [69, 73], [74, 79], [80, 84], [85, 89], [90, 92], [93, 95], [96, 102], [102, 103], [104, 113], [114, 117], [118, 125], [126, 132], [133, 136], [137, 146], [146, 148], [149, 154], [155, 159], [160, 168], [169, 175], [175, 176], [177, 185], [186, 191], [192, 195], [196, 201], [202, 205], [206, 211], [212, 215], [215, 216]]}
{"doc_key": "ai-dev-27", "ner": [[3, 4, "researcher"], [14, 19, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 14, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1977", ",", "Ulf", "Grenander", "proposed", "the", "maximum", "square", "problem", "as", "a", "simplified", "model", "for", "estimating", "the", "maximum", "likelihood", "of", "patterns", "in", "digitized", "images", "."], "sentence-detokenized": "In 1977, Ulf Grenander proposed the maximum square problem as a simplified model for estimating the maximum likelihood of patterns in digitized images.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 22], [23, 31], [32, 35], [36, 43], [44, 50], [51, 58], [59, 61], [62, 63], [64, 74], [75, 80], [81, 84], [85, 95], [96, 99], [100, 107], [108, 118], [119, 121], [122, 130], [131, 133], [134, 143], [144, 150], [150, 151]]}
{"doc_key": "ai-dev-28", "ner": [[0, 1, "product"], [3, 4, "product"], [6, 8, "product"], [10, 11, "product"], [13, 15, "product"], [17, 20, "product"], [31, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[31, 31, 0, 1, "part-of", "", false, false], [31, 31, 3, 4, "part-of", "", false, false], [31, 31, 6, 8, "part-of", "", false, false], [31, 31, 10, 11, "part-of", "", false, false], [31, 31, 13, 15, "part-of", "", false, false], [31, 31, 17, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["iPhone", "4S", ",", "iPad", "3", ",", "iPad", "Mini", "1G", ",", "iPad", "Air", ",", "iPad", "Pro", "1G", ",", "iPod", "Touch", "5", "G", "and", "newer", "models", "include", "a", "more", "advanced", "voice", "assistant", "called", "Siri", "."], "sentence-detokenized": "iPhone 4S, iPad 3, iPad Mini 1G, iPad Air, iPad Pro 1G, iPod Touch 5G and newer models include a more advanced voice assistant called Siri.", "token2charspan": [[0, 6], [7, 9], [9, 10], [11, 15], [16, 17], [17, 18], [19, 23], [24, 28], [29, 31], [31, 32], [33, 37], [38, 41], [41, 42], [43, 47], [48, 51], [52, 54], [54, 55], [56, 60], [61, 66], [67, 68], [68, 69], [70, 73], [74, 79], [80, 86], [87, 94], [95, 96], [97, 101], [102, 110], [111, 116], [117, 126], [127, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-dev-29", "ner": [[7, 8, "metrics"], [11, 14, "metrics"], [16, 18, "metrics"], [47, 50, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[16, 18, 11, 14, "named", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["It", "is", "easy", "to", "check", "that", "the", "logistic", "loss", "and", "the", "binary", "cross", "-entropy", "loss", "(", "log", "-", "loss", ")", "are", "in", "fact", "the", "same", "(", "up", "to", "the", "multiplicative", "constant", "math", "\\", "frac", "{", "1", "}", "{", "The", "cross", "-entropy", "loss", "is", "closely", "related", "to", "the", "Kullback", "-", "Leibler", "divergence", "between", "the", "empirical", "distribution", "and", "the", "predicted", "distribution", "."], "sentence-detokenized": "It is easy to check that the logistic loss and the binary cross-entropy loss (log-loss) are in fact the same (up to the multiplicative constant math\\ frac {1} {The cross-entropy loss is closely related to the Kullback-Leibler divergence between the empirical distribution and the predicted distribution.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 13], [14, 19], [20, 24], [25, 28], [29, 37], [38, 42], [43, 46], [47, 50], [51, 57], [58, 63], [63, 71], [72, 76], [77, 78], [78, 81], [81, 82], [82, 86], [86, 87], [88, 91], [92, 94], [95, 99], [100, 103], [104, 108], [109, 110], [110, 112], [113, 115], [116, 119], [120, 134], [135, 143], [144, 148], [148, 149], [150, 154], [155, 156], [156, 157], [157, 158], [159, 160], [160, 163], [164, 169], [169, 177], [178, 182], [183, 185], [186, 193], [194, 201], [202, 204], [205, 208], [209, 217], [217, 218], [218, 225], [226, 236], [237, 244], [245, 248], [249, 258], [259, 271], [272, 275], [276, 279], [280, 289], [290, 302], [302, 303]]}
{"doc_key": "ai-dev-30", "ner": [[0, 2, "algorithm"], [11, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "EM", "algorithm", "is", "used", "to", "find", "the", "(", "local", ")", "maximum", "likelihood", "parameters", "of", "a", "statistical", "model", "in", "cases", "where", "the", "equations", "can", "not", "be", "solved", "directly", "."], "sentence-detokenized": "The EM algorithm is used to find the (local) maximum likelihood parameters of a statistical model in cases where the equations cannot be solved directly.", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 19], [20, 24], [25, 27], [28, 32], [33, 36], [37, 38], [38, 43], [43, 44], [45, 52], [53, 63], [64, 74], [75, 77], [78, 79], [80, 91], [92, 97], [98, 100], [101, 106], [107, 112], [113, 116], [117, 126], [127, 130], [130, 133], [134, 136], [137, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-dev-31", "ner": [[9, 11, "task"], [13, 14, "task"], [16, 17, "task"], [19, 19, "task"], [23, 27, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "research", "was", "fundamental", "to", "the", "development", "of", "modern", "speech", "synthesis", "techniques", ",", "blind", "readers", ",", "speech", "perception", "and", "recognition", "research", ",", "and", "motor", "theory", "of", "speech", "perception", "."], "sentence-detokenized": "This research was fundamental to the development of modern speech synthesis techniques, blind readers, speech perception and recognition research, and motor theory of speech perception.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 29], [30, 32], [33, 36], [37, 48], [49, 51], [52, 58], [59, 65], [66, 75], [76, 86], [86, 87], [88, 93], [94, 101], [101, 102], [103, 109], [110, 120], [121, 124], [125, 136], [137, 145], [145, 146], [147, 150], [151, 156], [157, 163], [164, 166], [167, 173], [174, 184], [184, 185]]}
{"doc_key": "ai-dev-32", "ner": [[0, 1, "product"], [2, 6, "misc"], [10, 12, "misc"], [14, 14, "product"], [16, 16, "product"], [18, 18, "product"], [21, 25, "programlang"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "Arduino", "Integrated", "Development", "Environment", "(", "IDE", ")", "is", "a", "cross", "-platform", "application", "(", "Windows", ",", "macOS", "and", "Linux", ")", "written", "in", "the", "Java", "programming", "language", "."], "sentence-detokenized": "The Arduino Integrated Development Environment (IDE) is a cross-platform application (Windows, macOS and Linux) written in the Java programming language.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 34], [35, 46], [47, 48], [48, 51], [51, 52], [53, 55], [56, 57], [58, 63], [63, 72], [73, 84], [85, 86], [86, 93], [93, 94], [95, 100], [101, 104], [105, 110], [110, 111], [112, 119], [120, 122], [123, 126], [127, 131], [132, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-dev-33", "ner": [[20, 22, "field"], [10, 11, "researcher"], [13, 15, "researcher"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[10, 11, 20, 22, "related-to", "works_with", false, false], [13, 15, 20, 22, "related-to", "works_with", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["Neuronetwork", "research", "came", "to", "a", "standstill", "after", "the", "publication", "of", "Marvin", "Minsky", "and", "Seymour", "Papert", "'s", "(", "1969", ")", "study", "on", "machine", "learning", "."], "sentence-detokenized": "Neuronetwork research came to a standstill after the publication of Marvin Minsky and Seymour Papert's (1969) study on machine learning.", "token2charspan": [[0, 12], [13, 21], [22, 26], [27, 29], [30, 31], [32, 42], [43, 48], [49, 52], [53, 64], [65, 67], [68, 74], [75, 81], [82, 85], [86, 93], [94, 100], [100, 102], [103, 104], [104, 108], [108, 109], [110, 115], [116, 118], [119, 126], [127, 135], [135, 136]]}
{"doc_key": "ai-dev-34", "ner": [[13, 14, "organisation"], [16, 16, "organisation"], [18, 21, "country"], [23, 26, "organisation"], [29, 29, "country"], [31, 32, "organisation"], [35, 35, "country"], [37, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[23, 26, 18, 21, "general-affiliation", "", false, false], [31, 32, 29, 29, "general-affiliation", "", false, false], [37, 37, 35, 35, "general-affiliation", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Only", "a", "few", "non-Japanese", "companies", "eventually", "managed", "to", "survive", "in", "this", "market", ":", "Adept", "Technology", ",", "St\u00e4ubli", ",", "the", "Swedish", "-", "Swiss", "company", "ABB", "Asea", "Brown", "Boveri", ",", "the", "German", "company", "KUKA", "Robotics", "and", "the", "Italian", "company", "Comau", "."], "sentence-detokenized": "Only a few non-Japanese companies eventually managed to survive in this market: Adept Technology, St\u00e4ubli, the Swedish-Swiss company ABB Asea Brown Boveri, the German company KUKA Robotics and the Italian company Comau.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 23], [24, 33], [34, 44], [45, 52], [53, 55], [56, 63], [64, 66], [67, 71], [72, 78], [78, 79], [80, 85], [86, 96], [96, 97], [98, 105], [105, 106], [107, 110], [111, 118], [118, 119], [119, 124], [125, 132], [133, 136], [137, 141], [142, 147], [148, 154], [154, 155], [156, 159], [160, 166], [167, 174], [175, 179], [180, 188], [189, 192], [193, 196], [197, 204], [205, 212], [213, 218], [218, 219]]}
{"doc_key": "ai-dev-35", "ner": [[9, 10, "conference"], [15, 15, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 15, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Research", "activities", "include", "an", "annual", "research", "conference", ",", "the", "RuleML", "Symposium", ",", "also", "known", "as", "RuleML", "."], "sentence-detokenized": "Research activities include an annual research conference, the RuleML Symposium, also known as RuleML.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 30], [31, 37], [38, 46], [47, 57], [57, 58], [59, 62], [63, 69], [70, 79], [79, 80], [81, 85], [86, 91], [92, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-dev-36", "ner": [[8, 9, "field"], [11, 12, "field"], [14, 14, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Concepts", "are", "used", "as", "formal", "tools", "or", "models", "in", "mathematics", ",", "computer", "science", ",", "databases", "and", "artificial", "intelligence", ",", "where", "they", "are", "sometimes", "called", "classes", ",", "schemas", "or", "categories", "."], "sentence-detokenized": "Concepts are used as formal tools or models in mathematics, computer science, databases and artificial intelligence, where they are sometimes called classes, schemas or categories.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 20], [21, 27], [28, 33], [34, 36], [37, 43], [44, 46], [47, 58], [58, 59], [60, 68], [69, 76], [76, 77], [78, 87], [88, 91], [92, 102], [103, 115], [115, 116], [117, 122], [123, 127], [128, 131], [132, 141], [142, 148], [149, 156], [156, 157], [158, 165], [166, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-dev-37", "ner": [[5, 8, "organisation"], [11, 14, "organisation"], [17, 18, "organisation"], [21, 23, "organisation"], [26, 28, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "received", "awards", "from", "the", "American", "Psychological", "Association", ",", "the", "National", "Academy", "of", "Sciences", ",", "the", "Royal", "Society", ",", "the", "Cognitive", "Neuroscience", "Society", "and", "the", "American", "Humanist", "Association", "."], "sentence-detokenized": "He has received awards from the American Psychological Association, the National Academy of Sciences, the Royal Society, the Cognitive Neuroscience Society and the American Humanist Association.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 22], [23, 27], [28, 31], [32, 40], [41, 54], [55, 66], [66, 67], [68, 71], [72, 80], [81, 88], [89, 91], [92, 100], [100, 101], [102, 105], [106, 111], [112, 119], [119, 120], [121, 124], [125, 134], [135, 147], [148, 155], [156, 159], [160, 163], [164, 172], [173, 181], [182, 193], [193, 194]]}
{"doc_key": "ai-dev-38", "ner": [[1, 2, "person"], [4, 5, "person"], [7, 8, "person"], [16, 17, "person"], [22, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[22, 28, 16, 17, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Starring", "Harrison", "Ford", ",", "Rutger", "Hauer", "and", "Sean", "Young", ",", "the", "film", "is", "loosely", "based", "on", "Philip", "K", ".", "Dick", "'s", "novel", "Do", "Androids", "Dream", "of", "Electric", "Sheep", "?", "(", "1968", ")", "."], "sentence-detokenized": "Starring Harrison Ford, Rutger Hauer and Sean Young, the film is loosely based on Philip K. Dick's novel Do Androids Dream of Electric Sheep? (1968).", "token2charspan": [[0, 8], [9, 17], [18, 22], [22, 23], [24, 30], [31, 36], [37, 40], [41, 45], [46, 51], [51, 52], [53, 56], [57, 61], [62, 64], [65, 72], [73, 78], [79, 81], [82, 88], [89, 90], [90, 91], [92, 96], [96, 98], [99, 104], [105, 107], [108, 116], [117, 122], [123, 125], [126, 134], [135, 140], [140, 141], [142, 143], [143, 147], [147, 148], [148, 149]]}
{"doc_key": "ai-dev-39", "ner": [[0, 1, "task"], [2, 5, "algorithm"], [10, 12, "field"], [14, 15, "task"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 2, 5, "usage", "", false, false], [0, 1, 10, 12, "part-of", "task_part_of_field", false, false], [0, 1, 14, 15, "part-of", "task_part_of_field", false, false], [0, 1, 17, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Image", "segmentation", "using", "k-means", "clustering", "algorithms", "has", "long", "been", "used", "in", "pattern", "recognition", ",", "object", "detection", "and", "medical", "imaging", "."], "sentence-detokenized": "Image segmentation using k-means clustering algorithms has long been used in pattern recognition, object detection and medical imaging.", "token2charspan": [[0, 5], [6, 18], [19, 24], [25, 32], [33, 43], [44, 54], [55, 58], [59, 63], [64, 68], [69, 73], [74, 76], [77, 84], [85, 96], [96, 97], [98, 104], [105, 114], [115, 118], [119, 126], [127, 134], [134, 135]]}
{"doc_key": "ai-dev-40", "ner": [[15, 15, "algorithm"], [17, 18, "algorithm"], [21, 21, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["General", "sampling", "of", "the", "typed", "normal", "can", "be", "done", "using", "approximations", "of", "the", "normal", "'s", "CDF", "and", "probit", "function", ",", "and", "R", "has", "a", "function", "codertnorm", "(", ")", "/", "code", "for", "sampling", "the", "typed", "normal", "."], "sentence-detokenized": "General sampling of the typed normal can be done using approximations of the normal's CDF and probit function, and R has a function codertnorm() / code for sampling the typed normal.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 23], [24, 29], [30, 36], [37, 40], [41, 43], [44, 48], [49, 54], [55, 69], [70, 72], [73, 76], [77, 83], [83, 85], [86, 89], [90, 93], [94, 100], [101, 109], [109, 110], [111, 114], [115, 116], [117, 120], [121, 122], [123, 131], [132, 142], [142, 143], [143, 144], [145, 146], [147, 151], [152, 155], [156, 164], [165, 168], [169, 174], [175, 181], [181, 182]]}
{"doc_key": "ai-dev-41", "ner": [[6, 8, "university"], [10, 11, "university"], [13, 15, "university"], [17, 19, "university"], [22, 24, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "also", "received", "honorary", "doctorates", "from", "Newcastle", "University", ",", "Surrey", "University", ",", "Tel", "Aviv", "University", ",", "Simon", "Fraser", "University", "and", "the", "University", "of", "Troms\u00f8", "."], "sentence-detokenized": "He has also received honorary doctorates from Newcastle University, Surrey University, Tel Aviv University, Simon Fraser University and the University of Troms\u00f8.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 20], [21, 29], [30, 40], [41, 45], [46, 55], [56, 66], [66, 67], [68, 74], [75, 85], [85, 86], [87, 90], [91, 95], [96, 106], [106, 107], [108, 113], [114, 120], [121, 131], [132, 135], [136, 139], [140, 150], [151, 153], [154, 160], [160, 161]]}
{"doc_key": "ai-dev-42", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "Java", "implementation", "that", "uses", "array", "indices", "based", "on", "zero", "and", "a", "handy", "method", "for", "printing", "the", "order", "of", "solved", "operations", ":"], "sentence-detokenized": "A Java implementation that uses array indices based on zero and a handy method for printing the order of solved operations:", "token2charspan": [[0, 1], [2, 6], [7, 21], [22, 26], [27, 31], [32, 37], [38, 45], [46, 51], [52, 54], [55, 59], [60, 63], [64, 65], [66, 71], [72, 78], [79, 82], [83, 91], [92, 95], [96, 101], [102, 104], [105, 111], [112, 122], [122, 123]]}
{"doc_key": "ai-dev-43", "ner": [[7, 8, "metrics"], [11, 12, "metrics"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Such", "networks", "are", "usually", "trained", "with", "a", "cross", "-entropy", "(", "or", "cross", "-entropy", ")", "framework", ",", "which", "is", "a", "non-linear", "transformation", "of", "multinomial", "logistic", "regression", "."], "sentence-detokenized": "Such networks are usually trained with a cross-entropy (or cross-entropy) framework, which is a non-linear transformation of multinomial logistic regression.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 25], [26, 33], [34, 38], [39, 40], [41, 46], [46, 54], [55, 56], [56, 58], [59, 64], [64, 72], [72, 73], [74, 83], [83, 84], [85, 90], [91, 93], [94, 95], [96, 106], [107, 121], [122, 124], [125, 136], [137, 145], [146, 156], [156, 157]]}
{"doc_key": "ai-dev-44", "ner": [[0, 0, "conference"], [3, 4, "misc"], [6, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["ACL", "has", "a", "European", "Chapter", "(", "European", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ")", "."], "sentence-detokenized": "ACL has a European Chapter (European Chapter of the Association for Computational Linguistics).", "token2charspan": [[0, 3], [4, 7], [8, 9], [10, 18], [19, 26], [27, 28], [28, 36], [37, 44], [45, 47], [48, 51], [52, 63], [64, 67], [68, 81], [82, 93], [93, 94], [94, 95]]}
{"doc_key": "ai-dev-45", "ner": [[3, 4, "researcher"], [6, 8, "researcher"], [27, 27, "misc"], [29, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 27, 27, "role", "", false, false], [6, 8, 27, 27, "role", "", false, false], [27, 27, 29, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "professors", ",", "Hal", "Abelson", "and", "Gerald", "Jay", "Sussman", ",", "decided", "to", "remain", "neutral", "-", "for", "the", "next", "30", "years", "their", "group", "was", "referred", "to", "variously", "as", "Switzerland", "and", "Project", "MAC", "."], "sentence-detokenized": "Two professors, Hal Abelson and Gerald Jay Sussman, decided to remain neutral - for the next 30 years their group was referred to variously as Switzerland and Project MAC.", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 27], [28, 31], [32, 38], [39, 42], [43, 50], [50, 51], [52, 59], [60, 62], [63, 69], [70, 77], [78, 79], [80, 83], [84, 87], [88, 92], [93, 95], [96, 101], [102, 107], [108, 113], [114, 117], [118, 126], [127, 129], [130, 139], [140, 142], [143, 154], [155, 158], [159, 166], [167, 170], [170, 171]]}
{"doc_key": "ai-dev-46", "ner": [[1, 2, "misc"], [4, 4, "researcher"], [6, 10, "university"], [18, 18, "organisation"], [26, 28, "organisation"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 2, 4, 4, "temporal", "", false, false], [4, 4, 18, 18, "physical", "", false, false], [4, 4, 18, 18, "role", "", false, false], [4, 4, 26, 28, "role", "", false, false], [26, 28, 6, 10, "part-of", "", false, false], [22, 25, 26, 28, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["After", "his", "PhD", ",", "Ghahramani", "joined", "the", "University", "of", "Toronto", "in", "1995", "as", "a", "postdoctoral", "researcher", "at", "the", "ITRC", ",", "working", "with", "Geoffrey", "Hinton", "in", "the", "Artificial", "Intelligence", "Laboratory", "."], "sentence-detokenized": "After his PhD, Ghahramani joined the University of Toronto in 1995 as a postdoctoral researcher at the ITRC, working with Geoffrey Hinton in the Artificial Intelligence Laboratory.", "token2charspan": [[0, 5], [6, 9], [10, 13], [13, 14], [15, 25], [26, 32], [33, 36], [37, 47], [48, 50], [51, 58], [59, 61], [62, 66], [67, 69], [70, 71], [72, 84], [85, 95], [96, 98], [99, 102], [103, 107], [107, 108], [109, 116], [117, 121], [122, 130], [131, 137], [138, 140], [141, 144], [145, 155], [156, 168], [169, 179], [179, 180]]}
{"doc_key": "ai-dev-47", "ner": [[23, 23, "metrics"], [21, 25, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[21, 25, 23, 23, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Subsequent", "work", "focused", "on", "solving", "these", "problems", ",", "but", "it", "was", "the", "advent", "of", "the", "modern", "computer", "and", "the", "widespread", "use", "of", "Maximum", "Likelihood", "(", "MLE", ")", "parameterisation", "techniques", "that", "really", "got", "the", "research", "going", "."], "sentence-detokenized": "Subsequent work focused on solving these problems, but it was the advent of the modern computer and the widespread use of Maximum Likelihood (MLE) parameterisation techniques that really got the research going.", "token2charspan": [[0, 10], [11, 15], [16, 23], [24, 26], [27, 34], [35, 40], [41, 49], [49, 50], [51, 54], [55, 57], [58, 61], [62, 65], [66, 72], [73, 75], [76, 79], [80, 86], [87, 95], [96, 99], [100, 103], [104, 114], [115, 118], [119, 121], [122, 129], [130, 140], [141, 142], [142, 145], [145, 146], [147, 163], [164, 174], [175, 179], [180, 186], [187, 190], [191, 194], [195, 203], [204, 209], [209, 210]]}
{"doc_key": "ai-dev-48", "ner": [[5, 7, "person"], [9, 10, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "series", "was", "produced", "by", "David", "Fincher", "and", "starred", "Kevin", "Spacey", "."], "sentence-detokenized": "The series was produced by David Fincher and starred Kevin Spacey.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 26], [27, 32], [33, 40], [41, 44], [45, 52], [53, 58], [59, 65], [65, 66]]}
{"doc_key": "ai-dev-49", "ner": [[15, 16, "metrics"], [22, 22, "algorithm"], [27, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[22, 22, 27, 33, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Due", "to", "computational", "power", "limitations", ",", "current", "in", "silico", "methods", "usually", "have", "to", "trade", "speed", "for", "accuracy", ";", "for", "example", ",", "fast", "protein", "docking", "methods", "are", "used", "instead", "of", "computationally", "expensive", "free", "energy", "calculations", "."], "sentence-detokenized": "Due to computational power limitations, current in silico methods usually have to trade speed for accuracy; for example, fast protein docking methods are used instead of computationally expensive free energy calculations.", "token2charspan": [[0, 3], [4, 6], [7, 20], [21, 26], [27, 38], [38, 39], [40, 47], [48, 50], [51, 57], [58, 65], [66, 73], [74, 78], [79, 81], [82, 87], [88, 93], [94, 97], [98, 106], [106, 107], [108, 111], [112, 119], [119, 120], [121, 125], [126, 133], [134, 141], [142, 149], [150, 153], [154, 158], [159, 166], [167, 169], [170, 185], [186, 195], [196, 200], [201, 207], [208, 220], [220, 221]]}
{"doc_key": "ai-dev-50", "ner": [[8, 9, "country"], [11, 11, "country"], [13, 13, "country"], [15, 15, "country"], [17, 17, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "had", "more", "than", "30", "offices", "in", "the", "United", "States", ",", "Canada", ",", "Mexico", ",", "Brazil", "and", "Argentina", "."], "sentence-detokenized": "It had more than 30 offices in the United States, Canada, Mexico, Brazil and Argentina.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 19], [20, 27], [28, 30], [31, 34], [35, 41], [42, 48], [48, 49], [50, 56], [56, 57], [58, 64], [64, 65], [66, 72], [73, 76], [77, 86], [86, 87]]}
{"doc_key": "ai-dev-51", "ner": [[5, 6, "field"], [9, 13, "product"], [15, 17, "algorithm"], [20, 21, "task"], [23, 24, "task"], [30, 31, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 13, 5, 6, "part-of", "", false, false], [9, 13, 15, 17, "usage", "", false, false], [20, 21, 5, 6, "part-of", "task_part_of_field", false, false], [20, 21, 30, 31, "related-to", "performs", false, false], [23, 24, 5, 6, "part-of", "task_part_of_field", false, false], [23, 24, 30, 31, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["An", "example", "of", "a", "typical", "computer", "vision", "computation", "pipeline", "for", "a", "face", "recognition", "system", "using", "k", "-", "NN", ",", "including", "feature", "extraction", "and", "dimension", "reduction", "preprocessing", "steps", "(", "usually", "implemented", "in", "OpenCV", ")", ":"], "sentence-detokenized": "An example of a typical computer vision computation pipeline for a face recognition system using k -NN, including feature extraction and dimension reduction preprocessing steps (usually implemented in OpenCV):", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 23], [24, 32], [33, 39], [40, 51], [52, 60], [61, 64], [65, 66], [67, 71], [72, 83], [84, 90], [91, 96], [97, 98], [99, 100], [100, 102], [102, 103], [104, 113], [114, 121], [122, 132], [133, 136], [137, 146], [147, 156], [157, 170], [171, 176], [177, 178], [178, 185], [186, 197], [198, 200], [201, 207], [207, 208], [208, 209]]}
{"doc_key": "ai-dev-52", "ner": [[8, 11, "algorithm"], [13, 13, "misc"], [15, 16, "misc"], [18, 18, "misc"], [22, 22, "programlang"], [24, 24, "product"], [28, 29, "algorithm"], [31, 33, "misc"], [35, 35, "misc"], [37, 37, "misc"], [39, 39, "misc"], [46, 46, "misc"], [49, 50, "misc"], [53, 54, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "has", "a", "rich", "feature", "set", ",", "libraries", "for", "constraint", "logic", "programming", ",", "multithreading", ",", "unit", "testing", ",", "GUI", ",", "interfaces", "to", "Java", ",", "ODBC", "and", "others", ",", "literate", "programming", ",", "a", "web", "server", ",", "SGML", ",", "RDF", ",", "RDFS", ",", "developer", "tools", "(", "including", "an", "IDE", "with", "a", "GUI", "debugger", "and", "a", "GUI", "profiler", ")", "and", "extensive", "documentation", "."], "sentence-detokenized": "It has a rich feature set, libraries for constraint logic programming, multithreading, unit testing, GUI, interfaces to Java, ODBC and others, literate programming, a web server, SGML, RDF, RDFS, developer tools (including an IDE with a GUI debugger and a GUI profiler) and extensive documentation.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 13], [14, 21], [22, 25], [25, 26], [27, 36], [37, 40], [41, 51], [52, 57], [58, 69], [69, 70], [71, 85], [85, 86], [87, 91], [92, 99], [99, 100], [101, 104], [104, 105], [106, 116], [117, 119], [120, 124], [124, 125], [126, 130], [131, 134], [135, 141], [141, 142], [143, 151], [152, 163], [163, 164], [165, 166], [167, 170], [171, 177], [177, 178], [179, 183], [183, 184], [185, 188], [188, 189], [190, 194], [194, 195], [196, 205], [206, 211], [212, 213], [213, 222], [223, 225], [226, 229], [230, 234], [235, 236], [237, 240], [241, 249], [250, 253], [254, 255], [256, 259], [260, 268], [268, 269], [270, 273], [274, 283], [284, 297], [297, 298]]}
{"doc_key": "ai-dev-53", "ner": [[0, 2, "field"], [8, 11, "misc"], [13, 15, "misc"], [18, 20, "misc"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[8, 11, 0, 2, "part-of", "", true, false], [8, 11, 18, 20, "type-of", "", false, false], [13, 15, 0, 2, "part-of", "", false, false], [13, 15, 18, 20, "type-of", "", false, false]], "relations_mapping_to_source": [0, 2, 3, 5], "sentence": ["In", "computer", "vision", "and", "image", "processing", ",", "the", "scale", "-", "space", "representation", "and", "Gaussian", "derivative", "operators", "are", "the", "canonical", "multiscale", "representation", "."], "sentence-detokenized": "In computer vision and image processing, the scale-space representation and Gaussian derivative operators are the canonical multiscale representation.", "token2charspan": [[0, 2], [3, 11], [12, 18], [19, 22], [23, 28], [29, 39], [39, 40], [41, 44], [45, 50], [50, 51], [51, 56], [57, 71], [72, 75], [76, 84], [85, 95], [96, 105], [106, 109], [110, 113], [114, 123], [124, 134], [135, 149], [149, 150]]}
{"doc_key": "ai-dev-54", "ner": [[7, 11, "organisation"], [17, 21, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 11, 17, 21, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "also", "chairman", "of", "the", "non-profit", "Neural", "Information", "Processing", "Systems", "Foundation", ",", "which", "oversees", "the", "annual", "Neural", "Information", "Processing", "Systems", "conference", "."], "sentence-detokenized": "He is also chairman of the non-profit Neural Information Processing Systems Foundation, which oversees the annual Neural Information Processing Systems conference.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 19], [20, 22], [23, 26], [27, 37], [38, 44], [45, 56], [57, 67], [68, 75], [76, 86], [86, 87], [88, 93], [94, 102], [103, 106], [107, 113], [114, 120], [121, 132], [133, 143], [144, 151], [152, 162], [162, 163]]}
{"doc_key": "ai-dev-55", "ner": [[1, 2, "task"], [11, 12, "metrics"], [6, 7, "misc"], [14, 15, "task"], [17, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 11, 12, "usage", "", false, false], [11, 12, 6, 7, "type-of", "", false, false], [14, 15, 17, 20, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "regression", "analysis", "problems", ",", "the", "loss", "function", "can", "be", "a", "quadratic", "error", ";", "in", "classification", ",", "cross", "-entropy", "can", "be", "used", "."], "sentence-detokenized": "In regression analysis problems, the loss function can be a quadratic error; in classification, cross-entropy can be used.", "token2charspan": [[0, 2], [3, 13], [14, 22], [23, 31], [31, 32], [33, 36], [37, 41], [42, 50], [51, 54], [55, 57], [58, 59], [60, 69], [70, 75], [75, 76], [77, 79], [80, 94], [94, 95], [96, 101], [101, 109], [110, 113], [114, 116], [117, 121], [121, 122]]}
{"doc_key": "ai-dev-56", "ner": [[0, 0, "researcher"], [17, 22, "conference"], [31, 32, "university"], [34, 35, "field"], [44, 49, "conference"]], "ner_mapping_to_source": [0, 2, 3, 4, 5], "relations": [[0, 0, 31, 32, "physical", "", false, false], [0, 0, 31, 32, "role", "", false, false], [0, 0, 44, 49, "role", "", false, false], [31, 32, 34, 35, "related-to", "subject_of_study_at", false, false]], "relations_mapping_to_source": [1, 2, 3, 5], "sentence": ["Lafferty", "served", "in", "many", "prestigious", "positions", ",", "including", ":", "co", "-chair", "and", "general", "chair", "of", "the", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", ")", "Foundation", "conferences", ";", "2", ")", "co-director", "of", "CMU", "'s", "new", "machine", "learning", "PhD", "program", ";", "3", ")", "associate", "editor", "of", "the", "Journal", "of", "Machine", "Learning", "Research", "."], "sentence-detokenized": "Lafferty served in many prestigious positions, including: co-chair and general chair of the (Conference on Neural Information Processing Systems) Foundation conferences; 2) co-director of CMU's new machine learning PhD program; 3) associate editor of the Journal of Machine Learning Research.", "token2charspan": [[0, 8], [9, 15], [16, 18], [19, 23], [24, 35], [36, 45], [45, 46], [47, 56], [56, 57], [58, 60], [60, 66], [67, 70], [71, 78], [79, 84], [85, 87], [88, 91], [92, 93], [93, 103], [104, 106], [107, 113], [114, 125], [126, 136], [137, 144], [144, 145], [146, 156], [157, 168], [168, 169], [170, 171], [171, 172], [173, 184], [185, 187], [188, 191], [191, 193], [194, 197], [198, 205], [206, 214], [215, 218], [219, 226], [226, 227], [228, 229], [229, 230], [231, 240], [241, 247], [248, 250], [251, 254], [255, 262], [263, 265], [266, 273], [274, 282], [283, 291], [291, 292]]}
{"doc_key": "ai-dev-57", "ner": [[0, 1, "misc"], [4, 4, "algorithm"], [6, 6, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 4, 0, 1, "type-of", "", false, false], [6, 6, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Convex", "algorithms", "such", "as", "AdaBoost", "and", "LogitBoost", "can", "be", "overwhelmed", "by", "random", "noise", ",", "so", "they", "can", "not", "learn", "basic", "and", "learnable", "combinations", "of", "weak", "hypotheses", "."], "sentence-detokenized": "Convex algorithms such as AdaBoost and LogitBoost can be overwhelmed by random noise, so they cannot learn basic and learnable combinations of weak hypotheses.", "token2charspan": [[0, 6], [7, 17], [18, 22], [23, 25], [26, 34], [35, 38], [39, 49], [50, 53], [54, 56], [57, 68], [69, 71], [72, 78], [79, 84], [84, 85], [86, 88], [89, 93], [94, 97], [97, 100], [101, 106], [107, 112], [113, 116], [117, 126], [127, 139], [140, 142], [143, 147], [148, 158], [158, 159]]}
{"doc_key": "ai-dev-58", "ner": [[0, 0, "product"], [3, 9, "product"], [11, 14, "algorithm"], [20, 20, "algorithm"], [23, 28, "task"], [30, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 9, "type-of", "", false, false], [0, 0, 11, 14, "usage", "", false, false], [0, 0, 20, 20, "usage", "", false, false], [20, 20, 23, 28, "related-to", "used_for", true, false], [20, 20, 30, 32, "related-to", "used_for", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Apertium", "is", "a", "low", "-", "pass", "machine", "translation", "system", "that", "uses", "finite", "-", "state", "transducers", "for", "all", "lexical", "transformations", "and", "hidden", "Markov", "patterns", "to", "mark", "up", "parts", "of", "speech", "or", "separate", "word", "classes", "."], "sentence-detokenized": "Apertium is a low-pass machine translation system that uses finite-state transducers for all lexical transformations and hidden Markov patterns to mark up parts of speech or separate word classes.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 17], [17, 18], [18, 22], [23, 30], [31, 42], [43, 49], [50, 54], [55, 59], [60, 66], [66, 67], [67, 72], [73, 84], [85, 88], [89, 92], [93, 100], [101, 116], [117, 120], [121, 127], [128, 134], [135, 143], [144, 146], [147, 151], [152, 154], [155, 160], [161, 163], [164, 170], [171, 173], [174, 182], [183, 187], [188, 195], [195, 196]]}
{"doc_key": "ai-dev-59", "ner": [[0, 2, "misc"], [14, 44, "metrics"], [32, 60, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 14, 44, "related-to", "", true, false], [14, 44, 32, 60, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "natural", "gradient", "mathE", "f", "(", "x", ")", "/", "math", ",", "as", "defined", "by", "Fisher", "'s", "information", "geometry", "(", "a", "measure", "of", "the", "information", "distance", "between", "probability", "distributions", "and", "the", "curvature", "of", "relative", "entropy", ")", ",", "now", "reads", "as", "follows", ":-", "Fisher", "'s", "information", "geometry", "(", "a", "measure", "of", "the", "information", "distance", "between", "probability", "distributions", "and", "the", "curvature", "of", "relative", "entropy", ")", "."], "sentence-detokenized": "The natural gradient mathE f (x) / math, as defined by Fisher's information geometry (a measure of the information distance between probability distributions and the curvature of relative entropy), now reads as follows:- Fisher's information geometry (a measure of the information distance between probability distributions and the curvature of relative entropy).", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 26], [27, 28], [29, 30], [30, 31], [31, 32], [33, 34], [35, 39], [39, 40], [41, 43], [44, 51], [52, 54], [55, 61], [61, 63], [64, 75], [76, 84], [85, 86], [86, 87], [88, 95], [96, 98], [99, 102], [103, 114], [115, 123], [124, 131], [132, 143], [144, 157], [158, 161], [162, 165], [166, 175], [176, 178], [179, 187], [188, 195], [195, 196], [196, 197], [198, 201], [202, 207], [208, 210], [211, 218], [218, 220], [221, 227], [227, 229], [230, 241], [242, 250], [251, 252], [252, 253], [254, 261], [262, 264], [265, 268], [269, 280], [281, 289], [290, 297], [298, 309], [310, 323], [324, 327], [328, 331], [332, 341], [342, 344], [345, 353], [354, 361], [361, 362], [362, 363]]}
{"doc_key": "ai-dev-60", "ner": [[0, 4, "programlang"], [7, 8, "product"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 0, 4, "origin", "", false, false], [10, 10, 0, 4, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "S", "programming", "language", "has", "inspired", "the", "S'", "PLUS", "and", "R", "systems", "."], "sentence-detokenized": "The S programming language has inspired the S' PLUS and R systems.", "token2charspan": [[0, 3], [4, 5], [6, 17], [18, 26], [27, 30], [31, 39], [40, 43], [44, 46], [47, 51], [52, 55], [56, 57], [58, 65], [65, 66]]}
{"doc_key": "ai-dev-61", "ner": [[5, 5, "product"], [13, 13, "product"], [8, 10, "product"], [15, 17, "researcher"], [19, 20, "researcher"], [22, 23, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 13, 13, "named", "same", false, false], [8, 10, 13, 13, "origin", "derived_from", false, false], [8, 10, 15, 17, "origin", "", false, false], [8, 10, 19, 20, "origin", "", false, false], [8, 10, 22, 23, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "most", "influential", "implementation", "of", "Planner", "was", "the", "Micro", "-", "Planner", "subset", "of", "Planner", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "."], "sentence-detokenized": "The most influential implementation of Planner was the Micro-Planner subset of Planner by Gerald Jay Sussman, Eugene Charniak and Terry Winograd.", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 35], [36, 38], [39, 46], [47, 50], [51, 54], [55, 60], [60, 61], [61, 68], [69, 75], [76, 78], [79, 86], [87, 89], [90, 96], [97, 100], [101, 108], [108, 109], [110, 116], [117, 125], [126, 129], [130, 135], [136, 144], [144, 145]]}
{"doc_key": "ai-dev-62", "ner": [[3, 6, "country"], [8, 10, "researcher"], [20, 20, "misc"], [21, 26, "university"], [33, 36, "misc"], [42, 43, "misc"], [47, 49, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [[8, 10, 3, 6, "general-affiliation", "from_country", false, false], [21, 26, 20, 20, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "1779", ",", "the", "German", "-", "Danish", "scientist", "Christian", "Gottlieb", "Kratzenstein", "won", "first", "prize", "in", "a", "competition", "announced", "by", "the", "Russian", "Imperial", "Academy", "of", "Sciences", "and", "Arts", "for", "a", "model", "he", "built", "of", "the", "human", "vocal", "tract", "that", "could", "produce", "five", "long", "vowel", "sounds", "(", "in", "the", "international", "phonetic", "alphabet", ")", ":"], "sentence-detokenized": "In 1779, the German-Danish scientist Christian Gottlieb Kratzenstein won first prize in a competition announced by the Russian Imperial Academy of Sciences and Arts for a model he built of the human vocal tract that could produce five long vowel sounds (in the international phonetic alphabet):", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 19], [19, 20], [20, 26], [27, 36], [37, 46], [47, 55], [56, 68], [69, 72], [73, 78], [79, 84], [85, 87], [88, 89], [90, 101], [102, 111], [112, 114], [115, 118], [119, 126], [127, 135], [136, 143], [144, 146], [147, 155], [156, 159], [160, 164], [165, 168], [169, 170], [171, 176], [177, 179], [180, 185], [186, 188], [189, 192], [193, 198], [199, 204], [205, 210], [211, 215], [216, 221], [222, 229], [230, 234], [235, 239], [240, 245], [246, 252], [253, 254], [254, 256], [257, 260], [261, 274], [275, 283], [284, 292], [292, 293], [293, 294]]}
{"doc_key": "ai-dev-63", "ner": [[2, 4, "product"], [6, 7, "misc"], [9, 14, "misc"], [31, 34, "misc"], [53, 53, "task"], [59, 60, "product"], [62, 62, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 4, 59, 60, "related-to", "supports_program", false, false], [2, 4, 62, 62, "related-to", "supports_program", false, false], [6, 7, 2, 4, "part-of", "", false, false], [9, 14, 2, 4, "part-of", "", false, false], [31, 34, 2, 4, "part-of", "", false, false], [53, 53, 2, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["New", "features", "in", "Office", "XP", "include", "smart", "tags", ",", "a", "menu", "-", "based", "search", "function", "that", "identifies", "different", "types", "of", "text", "in", "a", "document", "so", "users", "can", "perform", "additional", "tasks", ";", "a", "task", "panel", "interface", "that", "integrates", "popular", "menu", "bar", "commands", "on", "the", "right", "side", "of", "the", "screen", "for", "quick", "access", ";", "new", "document", "collaboration", "features", ",", "support", "for", "MSN", "Groups", "and", "SharePoint", ",", "and", "integrated", "handwriting", "recognition", "and", "speech", "recognition", "features", "."], "sentence-detokenized": "New features in Office XP include smart tags, a menu-based search function that identifies different types of text in a document so users can perform additional tasks; a task panel interface that integrates popular menu bar commands on the right side of the screen for quick access; new document collaboration features, support for MSN Groups and SharePoint, and integrated handwriting recognition and speech recognition features.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 22], [23, 25], [26, 33], [34, 39], [40, 44], [44, 45], [46, 47], [48, 52], [52, 53], [53, 58], [59, 65], [66, 74], [75, 79], [80, 90], [91, 100], [101, 106], [107, 109], [110, 114], [115, 117], [118, 119], [120, 128], [129, 131], [132, 137], [138, 141], [142, 149], [150, 160], [161, 166], [166, 167], [168, 169], [170, 174], [175, 180], [181, 190], [191, 195], [196, 206], [207, 214], [215, 219], [220, 223], [224, 232], [233, 235], [236, 239], [240, 245], [246, 250], [251, 253], [254, 257], [258, 264], [265, 268], [269, 274], [275, 281], [281, 282], [283, 286], [287, 295], [296, 309], [310, 318], [318, 319], [320, 327], [328, 331], [332, 335], [336, 342], [343, 346], [347, 357], [357, 358], [359, 362], [363, 373], [374, 385], [386, 397], [398, 401], [402, 408], [409, 420], [421, 429], [429, 430]]}
{"doc_key": "ai-dev-64", "ner": [[10, 12, "algorithm"], [13, 16, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 12, 13, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "many", "applications", ",", "the", "units", "of", "these", "networks", "use", "a", "sigmoid", "function", "as", "the", "activation", "function", "."], "sentence-detokenized": "In many applications, the units of these networks use a sigmoid function as the activation function.", "token2charspan": [[0, 2], [3, 7], [8, 20], [20, 21], [22, 25], [26, 31], [32, 34], [35, 40], [41, 49], [50, 53], [54, 55], [56, 63], [64, 72], [73, 75], [76, 79], [80, 90], [91, 99], [99, 100]]}
{"doc_key": "ai-dev-65", "ner": [[3, 3, "researcher"], [12, 17, "organisation"], [28, 34, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 12, 17, "role", "", false, false], [3, 3, 28, 34, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2001", ",", "Mehler", "was", "elected", "an", "Honorary", "Foreign", "Member", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "in", "2003", "he", "was", "elected", "a", "Fellow", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In 2001, Mehler was elected an Honorary Foreign Member of the American Academy of Arts and Sciences and in 2003 he was elected a Fellow of the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 27], [28, 30], [31, 39], [40, 47], [48, 54], [55, 57], [58, 61], [62, 70], [71, 78], [79, 81], [82, 86], [87, 90], [91, 99], [100, 103], [104, 106], [107, 111], [112, 114], [115, 118], [119, 126], [127, 128], [129, 135], [136, 138], [139, 142], [143, 151], [152, 163], [164, 167], [168, 171], [172, 183], [184, 186], [187, 194], [194, 195]]}
{"doc_key": "ai-dev-66", "ner": [[3, 6, "task"], [9, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 6, 9, 11, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Extending", "this", "concept", "to", "non", "-binary", "classifications", "leads", "to", "a", "mixing", "matrix", "."], "sentence-detokenized": "Extending this concept to non-binary classifications leads to a mixing matrix.", "token2charspan": [[0, 9], [10, 14], [15, 22], [23, 25], [26, 29], [29, 36], [37, 52], [53, 58], [59, 61], [62, 63], [64, 70], [71, 77], [77, 78]]}
{"doc_key": "ai-dev-67", "ner": [[14, 15, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "updated", "estimate", "of", "the", "variance", "of", "the", "measurement", "bias", "is", "obtained", "using", "the", "maximum", "likelihood", "calculation", "."], "sentence-detokenized": "An updated estimate of the variance of the measurement bias is obtained using the maximum likelihood calculation.", "token2charspan": [[0, 2], [3, 10], [11, 19], [20, 22], [23, 26], [27, 35], [36, 38], [39, 42], [43, 54], [55, 59], [60, 62], [63, 71], [72, 77], [78, 81], [82, 89], [90, 100], [101, 112], [112, 113]]}
{"doc_key": "ai-dev-68", "ner": [[0, 4, "field"], [5, 5, "algorithm"], [9, 12, "field"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 9, 12, "usage", "", true, false], [5, 5, 13, 14, "related-to", "", true, false], [9, 12, 0, 4, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "machine", "learning", ",", "a", "perceptron", "is", "an", "algorithm", "for", "supervised", "learning", "of", "binary", "classification", "."], "sentence-detokenized": "In machine learning, a perceptron is an algorithm for supervised learning of binary classification.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 22], [23, 33], [34, 36], [37, 39], [40, 49], [50, 53], [54, 64], [65, 73], [74, 76], [77, 83], [84, 98], [98, 99]]}
{"doc_key": "ai-dev-69", "ner": [[13, 18, "conference"], [21, 25, "conference"], [28, 34, "conference"], [37, 41, "conference"], [44, 48, "conference"]], "ner_mapping_to_source": [2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "also", "chaired", "several", "machine", "learning", "and", "vision", "conferences", ",", "including", "the", "Conference", "on", "Neural", "Information", "Processing", "Systems", ",", "the", "International", "Conference", "on", "Learning", "Representations", ",", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "the", "International", "Conference", "on", "Computer", "Vision", "and", "the", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "He has also chaired several machine learning and vision conferences, including the Conference on Neural Information Processing Systems, the International Conference on Learning Representations, the Conference on Computer Vision and Pattern Recognition, the International Conference on Computer Vision and the European Conference on Computer Vision.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 27], [28, 35], [36, 44], [45, 48], [49, 55], [56, 67], [67, 68], [69, 78], [79, 82], [83, 93], [94, 96], [97, 103], [104, 115], [116, 126], [127, 134], [134, 135], [136, 139], [140, 153], [154, 164], [165, 167], [168, 176], [177, 192], [192, 193], [194, 197], [198, 208], [209, 211], [212, 220], [221, 227], [228, 231], [232, 239], [240, 251], [251, 252], [253, 256], [257, 270], [271, 281], [282, 284], [285, 293], [294, 300], [301, 304], [305, 308], [309, 317], [318, 328], [329, 331], [332, 340], [341, 347], [347, 348]]}
{"doc_key": "ai-dev-70", "ner": [[0, 2, "algorithm"], [8, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "compression", "algorithm", "has", "also", "been", "used", "for", "facial", "recognition", "in", "the", "video", "series", "."], "sentence-detokenized": "The compression algorithm has also been used for facial recognition in the video series.", "token2charspan": [[0, 3], [4, 15], [16, 25], [26, 29], [30, 34], [35, 39], [40, 44], [45, 48], [49, 55], [56, 67], [68, 70], [71, 74], [75, 80], [81, 87], [87, 88]]}
{"doc_key": "ai-dev-71", "ner": [[0, 0, "task"], [14, 16, "conference"], [19, 24, "academicjournal"], [27, 27, "conference"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[14, 16, 0, 0, "topic", "", false, false], [19, 24, 0, 0, "topic", "", false, false], [27, 27, 19, 24, "role", "edited_by", false, false]], "relations_mapping_to_source": [0, 2, 4], "sentence": ["Dissemination", "is", "also", "part", "of", "ELRA", "'s", "mission", ",", "both", "through", "the", "organisation", "of", "the", "LREC", "conference", "and", "through", "the", "Language", "Resources", "and", "Evaluation", "Journal", "published", "by", "Springer", "."], "sentence-detokenized": "Dissemination is also part of ELRA's mission, both through the organisation of the LREC conference and through the Language Resources and Evaluation Journal published by Springer.", "token2charspan": [[0, 13], [14, 16], [17, 21], [22, 26], [27, 29], [30, 34], [34, 36], [37, 44], [44, 45], [46, 50], [51, 58], [59, 62], [63, 75], [76, 78], [79, 82], [83, 87], [88, 98], [99, 102], [103, 110], [111, 114], [115, 123], [124, 133], [134, 137], [138, 148], [149, 156], [157, 166], [167, 169], [170, 178], [178, 179]]}
{"doc_key": "ai-dev-72", "ner": [[0, 55, "field"], [10, 11, "field"], [13, 15, "field"], [17, 20, "field"], [54, 54, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 55, 54, 54, "named", "", false, false], [13, 15, 0, 55, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "linear", "time", "invariant", "(", "LTI", ")", "systems", "theory", ",", "control", "theory", "and", "digital", "signal", "processing", "or", "signal", "processing", ",", "the", "relationship", "between", "the", "input", "signal", ",", "math", "\\", "displaystyle", "x", "(", "t", ")", "/", "math", ",", "and", "the", "output", "signal", ",", "math", "\\", "displaystyle", "y", "(", "t", ")", "/", "math", ",", "of", "an", "LTI", "system", "is", "controlled", "by", "a", "convolution", "operation", ":"], "sentence-detokenized": "In linear time invariant (LTI) systems theory, control theory and digital signal processing or signal processing, the relationship between the input signal, math\\ displaystyle x(t)/math, and the output signal, math\\ displaystyle y(t)/math, of an LTI system is controlled by a convolution operation:", "token2charspan": [[0, 2], [3, 9], [10, 14], [15, 24], [25, 26], [26, 29], [29, 30], [31, 38], [39, 45], [45, 46], [47, 54], [55, 61], [62, 65], [66, 73], [74, 80], [81, 91], [92, 94], [95, 101], [102, 112], [112, 113], [114, 117], [118, 130], [131, 138], [139, 142], [143, 148], [149, 155], [155, 156], [157, 161], [161, 162], [163, 175], [176, 177], [177, 178], [178, 179], [179, 180], [180, 181], [181, 185], [185, 186], [187, 190], [191, 194], [195, 201], [202, 208], [208, 209], [210, 214], [214, 215], [216, 228], [229, 230], [230, 231], [231, 232], [232, 233], [233, 234], [234, 238], [238, 239], [240, 242], [243, 245], [246, 249], [250, 256], [257, 259], [260, 270], [271, 273], [274, 275], [276, 287], [288, 297], [297, 298]]}
{"doc_key": "ai-dev-73", "ner": [[16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 31, "field"], [33, 34, "product"], [36, 37, "field"], [39, 39, "field"], [41, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Because", "of", "its", "generality", ",", "the", "field", "is", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "game", "theory", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimisation", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Because of its generality, the field is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimisation, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 25], [25, 26], [27, 30], [31, 36], [37, 39], [40, 47], [48, 50], [51, 55], [56, 61], [62, 73], [73, 74], [75, 79], [80, 82], [83, 87], [88, 94], [94, 95], [96, 103], [104, 110], [110, 111], [112, 122], [123, 131], [131, 132], [133, 144], [145, 151], [151, 152], [153, 163], [163, 164], [164, 169], [170, 182], [182, 183], [184, 195], [196, 203], [203, 204], [205, 210], [211, 223], [223, 224], [225, 235], [236, 239], [240, 247], [248, 258], [258, 259]]}
{"doc_key": "ai-dev-74", "ner": [[0, 2, "algorithm"], [13, 14, "field"], [26, 27, "algorithm"], [31, 32, "algorithm"], [35, 35, "algorithm"], [36, 38, "researcher"], [40, 41, "researcher"], [43, 45, "researcher"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[13, 14, 0, 2, "usage", "", true, false], [26, 27, 13, 14, "part-of", "", true, false], [31, 32, 13, 14, "part-of", "", true, false], [35, 35, 13, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 2, 3, 4], "sentence": ["Stochastic", "gradient", "descent", "is", "a", "popular", "algorithm", "for", "training", "a", "wide", "range", "of", "machine", "learning", "models", ",", "such", "as", "(", "linear", ")", "support", "vector", "machines", ",", "logistic", "regression", "(", "see", "e.g.", "Vowpal", "Wabbit", ")", "and", "graphical", "models.Jenny", "Rose", "Finkel", ",", "Alex", "Kleeman", ",", "Christopher", "D.", "Manning", "(", "2008", ")", "."], "sentence-detokenized": "Stochastic gradient descent is a popular algorithm for training a wide range of machine learning models, such as (linear) support vector machines, logistic regression (see e.g. Vowpal Wabbit) and graphical models.Jenny Rose Finkel, Alex Kleeman, Christopher D. Manning (2008).", "token2charspan": [[0, 10], [11, 19], [20, 27], [28, 30], [31, 32], [33, 40], [41, 50], [51, 54], [55, 63], [64, 65], [66, 70], [71, 76], [77, 79], [80, 87], [88, 96], [97, 103], [103, 104], [105, 109], [110, 112], [113, 114], [114, 120], [120, 121], [122, 129], [130, 136], [137, 145], [145, 146], [147, 155], [156, 166], [167, 168], [168, 171], [172, 176], [177, 183], [184, 190], [190, 191], [192, 195], [196, 205], [206, 218], [219, 223], [224, 230], [230, 231], [232, 236], [237, 244], [244, 245], [246, 257], [258, 260], [261, 268], [269, 270], [270, 274], [274, 275], [275, 276]]}
{"doc_key": "ai-dev-75", "ner": [[8, 8, "organisation"], [11, 14, "product"], [18, 18, "country"], [21, 24, "university"], [25, 26, "location"], [28, 31, "university"], [32, 32, "location"], [34, 35, "university"], [36, 37, "location"], [39, 42, "university"], [43, 43, "location"], [45, 46, "university"], [47, 48, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 21, 24, "role", "donates_to", false, false], [8, 8, 28, 31, "role", "donates_to", false, false], [8, 8, 34, 35, "role", "donates_to", false, false], [8, 8, 39, 42, "role", "donates_to", false, false], [8, 8, 45, 46, "role", "donates_to", false, false], [11, 14, 8, 8, "origin", "donates", true, false], [21, 24, 25, 26, "physical", "", false, false], [25, 26, 18, 18, "physical", "", false, false], [28, 31, 32, 32, "physical", "", false, false], [32, 32, 18, 18, "physical", "", false, false], [34, 35, 36, 37, "physical", "", false, false], [36, 37, 18, 18, "physical", "", false, false], [39, 42, 43, 43, "physical", "", false, false], [43, 43, 18, 18, "physical", "", false, false], [45, 46, 47, 48, "physical", "", false, false], [47, 48, 18, 18, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "sentence": ["In", "August", "2011", ",", "it", "was", "announced", "that", "Hitachi", "will", "donate", "an", "electron", "microscope", "to", "each", "of", "five", "Indonesian", "universities", "(", "University", "of", "North", "Sumatra", "in", "Medan", ",", "Indonesian", "Christian", "University", "in", "Jakarta", ",", "Padjadjaran", "University", "in", "Bandung", ",", "Jenderal", "Soedirman", "University", "in", "Purwokerto", "and", "Muhammadiyah", "University", "in", "Malang", ")", "."], "sentence-detokenized": "In August 2011, it was announced that Hitachi will donate an electron microscope to each of five Indonesian universities (University of North Sumatra in Medan, Indonesian Christian University in Jakarta, Padjadjaran University in Bandung, Jenderal Soedirman University in Purwokerto and Muhammadiyah University in Malang).", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 18], [19, 22], [23, 32], [33, 37], [38, 45], [46, 50], [51, 57], [58, 60], [61, 69], [70, 80], [81, 83], [84, 88], [89, 91], [92, 96], [97, 107], [108, 120], [121, 122], [122, 132], [133, 135], [136, 141], [142, 149], [150, 152], [153, 158], [158, 159], [160, 170], [171, 180], [181, 191], [192, 194], [195, 202], [202, 203], [204, 215], [216, 226], [227, 229], [230, 237], [237, 238], [239, 247], [248, 257], [258, 268], [269, 271], [272, 282], [283, 286], [287, 299], [300, 310], [311, 313], [314, 320], [320, 321], [321, 322]]}
{"doc_key": "ai-dev-76", "ner": [[0, 0, "field"], [6, 7, "algorithm"], [9, 10, "algorithm"], [19, 20, "field"], [22, 26, "metrics"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Operational", "optimization", "techniques", ",", "such", "as", "linear", "programming", "or", "dynamic", "programming", ",", "are", "often", "impractical", "for", "large", "-", "scale", "software", "design", "problems", "because", "of", "their", "computational", "complexity", "."], "sentence-detokenized": "Operational optimization techniques, such as linear programming or dynamic programming, are often impractical for large-scale software design problems because of their computational complexity.", "token2charspan": [[0, 11], [12, 24], [25, 35], [35, 36], [37, 41], [42, 44], [45, 51], [52, 63], [64, 66], [67, 74], [75, 86], [86, 87], [88, 91], [92, 97], [98, 109], [110, 113], [114, 119], [119, 120], [120, 125], [126, 134], [135, 141], [142, 150], [151, 158], [159, 161], [162, 167], [168, 181], [182, 192], [192, 193]]}
{"doc_key": "ai-dev-77", "ner": [[0, 0, "metrics"], [6, 6, "metrics"], [8, 10, "metrics"], [15, 16, "metrics"], [20, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 6, "compare", "", false, false], [0, 0, 8, 10, "compare", "", false, false], [15, 16, 8, 10, "part-of", "", false, false], [20, 23, 8, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sensitivity", "is", "not", "the", "same", "as", "accuracy", "or", "positive", "predictive", "value", "(", "the", "ratio", "of", "true", "positives", "to", "the", "combined", "true", "and", "false", "positives", ")", ",", "which", "is", "as", "much", "about", "the", "proportion", "of", "true", "positives", "in", "the", "population", "being", "tested", "as", "it", "is", "about", "the", "test", "."], "sentence-detokenized": "Sensitivity is not the same as accuracy or positive predictive value (the ratio of true positives to the combined true and false positives), which is as much about the proportion of true positives in the population being tested as it is about the test.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 22], [23, 27], [28, 30], [31, 39], [40, 42], [43, 51], [52, 62], [63, 68], [69, 70], [70, 73], [74, 79], [80, 82], [83, 87], [88, 97], [98, 100], [101, 104], [105, 113], [114, 118], [119, 122], [123, 128], [129, 138], [138, 139], [139, 140], [141, 146], [147, 149], [150, 152], [153, 157], [158, 163], [164, 167], [168, 178], [179, 181], [182, 186], [187, 196], [197, 199], [200, 203], [204, 214], [215, 220], [221, 227], [228, 230], [231, 233], [234, 236], [237, 242], [243, 246], [247, 251], [251, 252]]}
{"doc_key": "ai-dev-78", "ner": [[0, 2, "person"], [8, 8, "product"], [11, 11, "person"], [29, 29, "person"], [37, 38, "person"], [49, 50, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6], "relations": [[8, 8, 0, 2, "artifact", "", false, false], [37, 38, 49, 50, "role", "convinces", false, false], [49, 50, 8, 8, "role", "producer", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Hampton", "Fancher", "'s", "script", "--", "not", "originally", "called", "Android", "-", "see", "Sammon", ",", "pp.", "32", "and", "38", "for", "an", "explanation", "--", "was", "given", "as", "an", "option", "in", "1977", ".", "Sammon", ",", "pp.", "23", "-", "30", ".", "Producer", "Michael", "Deeley", "took", "an", "interest", "in", "Fancher", "'s", "draft", "and", "convinced", "director", "Ridley", "Scott", "to", "shoot", "it", "."], "sentence-detokenized": "Hampton Fancher's script -- not originally called Android - see Sammon, pp. 32 and 38 for an explanation -- was given as an option in 1977. Sammon, pp. 23-30. Producer Michael Deeley took an interest in Fancher's draft and convinced director Ridley Scott to shoot it.", "token2charspan": [[0, 7], [8, 15], [15, 17], [18, 24], [25, 27], [28, 31], [32, 42], [43, 49], [50, 57], [58, 59], [60, 63], [64, 70], [70, 71], [72, 75], [76, 78], [79, 82], [83, 85], [86, 89], [90, 92], [93, 104], [105, 107], [108, 111], [112, 117], [118, 120], [121, 123], [124, 130], [131, 133], [134, 138], [138, 139], [140, 146], [146, 147], [148, 151], [152, 154], [154, 155], [155, 157], [157, 158], [159, 167], [168, 175], [176, 182], [183, 187], [188, 190], [191, 199], [200, 202], [203, 210], [210, 212], [213, 218], [219, 222], [223, 232], [233, 241], [242, 248], [249, 254], [255, 257], [258, 263], [264, 266], [266, 267]]}
{"doc_key": "ai-dev-79", "ner": [[3, 4, "task"], [6, 7, "task"], [10, 12, "misc"], [14, 15, "field"], [17, 19, "task"], [21, 25, "task"], [28, 31, "task"], [33, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 8, 9, 10], "relations": [], "relations_mapping_to_source": [], "sentence": ["Text", "analysis", "includes", "information", "retrieval", ",", "lexical", "analysis", "to", "explore", "word", "frequency", "distributions", ",", "pattern", "recognition", ",", "annotation", "/", "tagging", ",", "information", "mining", ",", "information", "extraction", "techniques", "including", "link", "and", "association", "analysis", ",", "visualisation", "and", "predictive", "analysis", "."], "sentence-detokenized": "Text analysis includes information retrieval, lexical analysis to explore word frequency distributions, pattern recognition, annotation/tagging, information mining, information extraction techniques including link and association analysis, visualisation and predictive analysis.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 34], [35, 44], [44, 45], [46, 53], [54, 62], [63, 65], [66, 73], [74, 78], [79, 88], [89, 102], [102, 103], [104, 111], [112, 123], [123, 124], [125, 135], [135, 136], [136, 143], [143, 144], [145, 156], [157, 163], [163, 164], [165, 176], [177, 187], [188, 198], [199, 208], [209, 213], [214, 217], [218, 229], [230, 238], [238, 239], [240, 253], [254, 257], [258, 268], [269, 277], [277, 278]]}
{"doc_key": "ai-dev-80", "ner": [[5, 5, "product"], [13, 14, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 5, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Several", "of", "the", "indicators", "use", "WordNet", ",", "a", "manually", "built", "lexical", "database", "of", "English", "words", "."], "sentence-detokenized": "Several of the indicators use WordNet, a manually built lexical database of English words.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 25], [26, 29], [30, 37], [37, 38], [39, 40], [41, 49], [50, 55], [56, 63], [64, 72], [73, 75], [76, 83], [84, 89], [89, 90]]}
{"doc_key": "ai-dev-81", "ner": [[6, 7, "field"], [9, 10, "task"], [12, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "system", "uses", "a", "combination", "of", "computational", "linguistics", ",", "data", "mining", "and", "data", "presentation", "techniques", "to", "find", "answers", "."], "sentence-detokenized": "The system uses a combination of computational linguistics, data mining and data presentation techniques to find answers.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 17], [18, 29], [30, 32], [33, 46], [47, 58], [58, 59], [60, 64], [65, 71], [72, 75], [76, 80], [81, 93], [94, 104], [105, 107], [108, 112], [113, 120], [120, 121]]}
{"doc_key": "ai-dev-82", "ner": [[6, 10, "metrics"], [13, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 10, 13, 13, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "measure", "of", "performance", ",", "the", "uncertainty", "factor", "has", "the", "advantage", "over", "accuracy", "alone", "in", "that", "it", "is", "not", "affected", "by", "the", "relative", "size", "of", "the", "different", "categories", "."], "sentence-detokenized": "As a measure of performance, the uncertainty factor has the advantage over accuracy alone in that it is not affected by the relative size of the different categories.", "token2charspan": [[0, 2], [3, 4], [5, 12], [13, 15], [16, 27], [27, 28], [29, 32], [33, 44], [45, 51], [52, 55], [56, 59], [60, 69], [70, 74], [75, 83], [84, 89], [90, 92], [93, 97], [98, 100], [101, 103], [104, 107], [108, 116], [117, 119], [120, 123], [124, 132], [133, 137], [138, 140], [141, 144], [145, 154], [155, 165], [165, 166]]}
{"doc_key": "ai-dev-83", "ner": [[8, 9, "algorithm"], [11, 12, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Researchers", "have", "tried", "several", "methods", ",", "such", "as", "optical", "flow", ",", "Kalman", "filtering", ",", "hidden", "Markov", "models", ",", "etc", "."], "sentence-detokenized": "Researchers have tried several methods, such as optical flow, Kalman filtering, hidden Markov models, etc.", "token2charspan": [[0, 11], [12, 16], [17, 22], [23, 30], [31, 38], [38, 39], [40, 44], [45, 47], [48, 55], [56, 60], [60, 61], [62, 68], [69, 78], [78, 79], [80, 86], [87, 93], [94, 100], [100, 101], [102, 105], [105, 106]]}
{"doc_key": "ai-dev-84", "ner": [[11, 15, "conference"], [28, 31, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "served", "as", "President", ",", "Vice", "President", "and", "Treasurer", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "as", "a", "member", "of", "the", "Board", "of", "Directors", "and", "Secretary", "of", "the", "Computing", "Research", "Association", "."], "sentence-detokenized": "He has served as President, Vice President and Treasurer of the Association for Computational Linguistics and as a member of the Board of Directors and Secretary of the Computing Research Association.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 26], [26, 27], [28, 32], [33, 42], [43, 46], [47, 56], [57, 59], [60, 63], [64, 75], [76, 79], [80, 93], [94, 105], [106, 109], [110, 112], [113, 114], [115, 121], [122, 124], [125, 128], [129, 134], [135, 137], [138, 147], [148, 151], [152, 161], [162, 164], [165, 168], [169, 178], [179, 187], [188, 199], [199, 200]]}
{"doc_key": "ai-dev-85", "ner": [[6, 6, "programlang"], [8, 8, "product"], [10, 10, "programlang"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 10, 10, "compare", "", false, false], [6, 6, 12, 13, "related-to", "supports", false, false], [8, 8, 10, 10, "compare", "", false, false], [8, 8, 12, 13, "related-to", "supports", false, false], [10, 10, 12, 13, "related-to", "supports", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Like", "other", "similar", "languages", "such", "as", "APL", "and", "MATLAB", ",", "R", "supports", "matrix", "arithmetic", "."], "sentence-detokenized": "Like other similar languages such as APL and MATLAB, R supports matrix arithmetic.", "token2charspan": [[0, 4], [5, 10], [11, 18], [19, 28], [29, 33], [34, 36], [37, 40], [41, 44], [45, 51], [51, 52], [53, 54], [55, 63], [64, 70], [71, 81], [81, 82]]}
{"doc_key": "ai-dev-86", "ner": [[6, 9, "organisation"], [16, 17, "researcher"], [18, 22, "university"], [26, 31, "misc"], [33, 33, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[16, 17, 18, 22, "role", "works_for", false, false]], "relations_mapping_to_source": [3], "sentence": ["On", "7", "June", "2014", ",", "in", "the", "Royal", "Society", "'s", "Turing", "Test", "Competition", ",", "organised", "by", "Kevin", "Warwick", "of", "the", "University", "of", "Reading", "to", "mark", "the", "60th", "anniversary", "of", "Turing", "'s", "death", ",", "Goostman", "won", "with", "33", "%", "of", "the", "judges", "convinced", "that", "the", "robot", "was", "human", "."], "sentence-detokenized": "On 7 June 2014, in the Royal Society's Turing Test Competition, organised by Kevin Warwick of the University of Reading to mark the 60th anniversary of Turing's death, Goostman won with 33% of the judges convinced that the robot was human.", "token2charspan": [[0, 2], [3, 4], [5, 9], [10, 14], [14, 15], [16, 18], [19, 22], [23, 28], [29, 36], [36, 38], [39, 45], [46, 50], [51, 62], [62, 63], [64, 73], [74, 76], [77, 82], [83, 90], [91, 93], [94, 97], [98, 108], [109, 111], [112, 119], [120, 122], [123, 127], [128, 131], [132, 136], [137, 148], [149, 151], [152, 158], [158, 160], [161, 166], [166, 167], [168, 176], [177, 180], [181, 185], [186, 188], [188, 189], [190, 192], [193, 196], [197, 203], [204, 213], [214, 218], [219, 222], [223, 228], [229, 232], [233, 238], [238, 239]]}
{"doc_key": "ai-dev-87", "ner": [[0, 2, "product"], [5, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "collaborative", "robot", ",", "or", "cobot", ",", "is", "a", "robot", "that", "can", "interact", "safely", "and", "efficiently", "with", "human", "workers", "to", "perform", "simple", "industrial", "tasks", "."], "sentence-detokenized": "A collaborative robot, or cobot, is a robot that can interact safely and efficiently with human workers to perform simple industrial tasks.", "token2charspan": [[0, 1], [2, 15], [16, 21], [21, 22], [23, 25], [26, 31], [31, 32], [33, 35], [36, 37], [38, 43], [44, 48], [49, 52], [53, 61], [62, 68], [69, 72], [73, 84], [85, 89], [90, 95], [96, 103], [104, 106], [107, 114], [115, 121], [122, 132], [133, 138], [138, 139]]}
{"doc_key": "ai-dev-88", "ner": [[11, 12, "field"], [17, 18, "task"], [20, 21, "task"], [23, 24, "task"], [26, 27, "task"], [29, 30, "task"], [32, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[17, 18, 11, 12, "part-of", "task_part_of_field", false, false], [20, 21, 11, 12, "part-of", "task_part_of_field", false, false], [23, 24, 11, 12, "part-of", "task_part_of_field", false, false], [26, 27, 11, 12, "part-of", "task_part_of_field", false, false], [29, 30, 11, 12, "part-of", "task_part_of_field", false, false], [32, 33, 11, 12, "part-of", "task_part_of_field", false, false], [35, 36, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["This", "general", "framework", "has", "been", "applied", "to", "a", "wide", "variety", "of", "computer", "vision", "problems", ",", "such", "as", "feature", "detection", ",", "feature", "classification", ",", "image", "segmentation", ",", "image", "matching", ",", "motion", "estimation", ",", "shape", "estimation", "and", "object", "recognition", "."], "sentence-detokenized": "This general framework has been applied to a wide variety of computer vision problems, such as feature detection, feature classification, image segmentation, image matching, motion estimation, shape estimation and object recognition.", "token2charspan": [[0, 4], [5, 12], [13, 22], [23, 26], [27, 31], [32, 39], [40, 42], [43, 44], [45, 49], [50, 57], [58, 60], [61, 69], [70, 76], [77, 85], [85, 86], [87, 91], [92, 94], [95, 102], [103, 112], [112, 113], [114, 121], [122, 136], [136, 137], [138, 143], [144, 156], [156, 157], [158, 163], [164, 172], [172, 173], [174, 180], [181, 191], [191, 192], [193, 198], [199, 209], [210, 213], [214, 220], [221, 232], [232, 233]]}
{"doc_key": "ai-dev-89", "ner": [[11, 16, "task"], [17, 19, "algorithm"], [8, 10, "algorithm"], [25, 25, "algorithm"], [34, 35, "algorithm"], [38, 39, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 16, 17, 19, "part-of", "", false, false], [11, 16, 8, 10, "usage", "", false, false], [17, 19, 25, 25, "named", "same", false, false], [25, 25, 34, 35, "related-to", "", false, false], [25, 25, 38, 39, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "many", "practical", "applications", ",", "the", "method", "of", "maximum", "likelihood", "is", "used", "to", "estimate", "the", "parameters", "of", "na\u00efve", "Bayesian", "models", ";", "that", "is", ",", "a", "na\u00efve", "Bayesian", "model", "can", "be", "worked", "with", "without", "adopting", "Bayesian", "likelihood", "or", "using", "Bayesian", "methods", "."], "sentence-detokenized": "In many practical applications, the method of maximum likelihood is used to estimate the parameters of na\u00efve Bayesian models; that is, a na\u00efve Bayesian model can be worked with without adopting Bayesian likelihood or using Bayesian methods.", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 30], [30, 31], [32, 35], [36, 42], [43, 45], [46, 53], [54, 64], [65, 67], [68, 72], [73, 75], [76, 84], [85, 88], [89, 99], [100, 102], [103, 108], [109, 117], [118, 124], [124, 125], [126, 130], [131, 133], [133, 134], [135, 136], [137, 142], [143, 151], [152, 157], [158, 161], [162, 164], [165, 171], [172, 176], [177, 184], [185, 193], [194, 202], [203, 213], [214, 216], [217, 222], [223, 231], [232, 239], [239, 240]]}
{"doc_key": "ai-dev-90", "ner": [[2, 4, "researcher"], [6, 7, "misc"], [11, 15, "university"], [17, 19, "researcher"], [21, 22, "misc"], [26, 26, "university"], [28, 28, "university"], [31, 31, "misc"], [37, 38, "university"], [46, 49, "misc"], [52, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[2, 4, 11, 15, "physical", "", false, false], [2, 4, 11, 15, "role", "", false, false], [2, 4, 17, 19, "social", "brothers", false, false], [6, 7, 2, 4, "named", "", false, false], [17, 19, 26, 26, "physical", "", false, false], [17, 19, 26, 26, "role", "", false, false], [17, 19, 28, 28, "physical", "", false, false], [17, 19, 28, 28, "role", "", false, false], [17, 19, 37, 38, "physical", "", false, false], [17, 19, 37, 38, "role", "", false, false], [21, 22, 17, 19, "named", "", false, false], [31, 31, 17, 19, "origin", "", false, false], [46, 49, 17, 19, "artifact", "", false, false], [46, 49, 52, 55, "part-of", "part", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Brothers", "-", "Victor", "Gershevich", "Katz", ",", "American", "mathematician", ",", "professor", "at", "the", "Massachusetts", "Institute", "of", "Technology", ";", "Mikhail", "Gershevich", "Katz", ",", "Israeli", "mathematician", ",", "graduate", "of", "Harvard", "and", "Columbia", "Universities", "(", "PhD", "1984", ")", ",", "professor", "at", "Bar-", "Ilan", "University", ",", "author", "of", "the", "monograph", "\"", "Systolic", "Geometry", "and", "Topology", "\"", "(", "Mathematical", "Surveys", "and", "Monographs", ",", "vol", "."], "sentence-detokenized": "Brothers - Victor Gershevich Katz, American mathematician, professor at the Massachusetts Institute of Technology; Mikhail Gershevich Katz, Israeli mathematician, graduate of Harvard and Columbia Universities (PhD 1984), professor at Bar-Ilan University, author of the monograph \"Systolic Geometry and Topology\" (Mathematical Surveys and Monographs, vol.", "token2charspan": [[0, 8], [9, 10], [11, 17], [18, 28], [29, 33], [33, 34], [35, 43], [44, 57], [57, 58], [59, 68], [69, 71], [72, 75], [76, 89], [90, 99], [100, 102], [103, 113], [113, 114], [115, 122], [123, 133], [134, 138], [138, 139], [140, 147], [148, 161], [161, 162], [163, 171], [172, 174], [175, 182], [183, 186], [187, 195], [196, 208], [209, 210], [210, 213], [214, 218], [218, 219], [219, 220], [221, 230], [231, 233], [234, 238], [238, 242], [243, 253], [253, 254], [255, 261], [262, 264], [265, 268], [269, 278], [279, 280], [280, 288], [289, 297], [298, 301], [302, 310], [310, 311], [312, 313], [313, 325], [326, 333], [334, 337], [338, 348], [348, 349], [350, 353], [353, 354]]}
{"doc_key": "ai-dev-91", "ner": [[3, 4, "person"], [10, 11, "conference"], [15, 19, "organisation"], [20, 27, "location"], [31, 31, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 10, 11, "physical", "", false, false], [3, 4, 10, 11, "role", "", false, false], [3, 4, 15, 19, "role", "", false, false], [15, 19, 20, 27, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2000", ",", "Manuel", "Toharia", ",", "a", "speaker", "at", "previous", "campus", "parties", "and", "director", "of", "the", "Pr\u00edncipe", "Felipe", "Science", "Museum", "in", "the", "art", "and", "science", "city", "of", "Valencia", ",", "suggested", "that", "Ragageles", "expand", "the", "event", "and", "make", "it", "more", "international", "by", "moving", "it", "to", "the", "famous", "museum", "."], "sentence-detokenized": "In 2000, Manuel Toharia, a speaker at previous campus parties and director of the Pr\u00edncipe Felipe Science Museum in the art and science city of Valencia, suggested that Ragageles expand the event and make it more international by moving it to the famous museum.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 23], [23, 24], [25, 26], [27, 34], [35, 37], [38, 46], [47, 53], [54, 61], [62, 65], [66, 74], [75, 77], [78, 81], [82, 90], [91, 97], [98, 105], [106, 112], [113, 115], [116, 119], [120, 123], [124, 127], [128, 135], [136, 140], [141, 143], [144, 152], [152, 153], [154, 163], [164, 168], [169, 178], [179, 185], [186, 189], [190, 195], [196, 199], [200, 204], [205, 207], [208, 212], [213, 226], [227, 229], [230, 236], [237, 239], [240, 242], [243, 246], [247, 253], [254, 260], [260, 261]]}
{"doc_key": "ai-dev-92", "ner": [[5, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Within", "20", "minutes", ",", "the", "facial", "recognition", "system", "will", "recognise", "personal", "data", "such", "as", "surname", ",", "ID", "and", "address", ",", "which", "will", "be", "displayed", "on", "the", "street", "on", "a", "billboard", "."], "sentence-detokenized": "Within 20 minutes, the facial recognition system will recognise personal data such as surname, ID and address, which will be displayed on the street on a billboard.", "token2charspan": [[0, 6], [7, 9], [10, 17], [17, 18], [19, 22], [23, 29], [30, 41], [42, 48], [49, 53], [54, 63], [64, 72], [73, 77], [78, 82], [83, 85], [86, 93], [93, 94], [95, 97], [98, 101], [102, 109], [109, 110], [111, 116], [117, 121], [122, 124], [125, 134], [135, 137], [138, 141], [142, 148], [149, 151], [152, 153], [154, 163], [163, 164]]}
{"doc_key": "ai-dev-93", "ner": [[6, 7, "field"], [9, 10, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Recent", "research", "has", "increasingly", "focused", "on", "unsupervised", "learning", "and", "semi-supervised", "learning", "."], "sentence-detokenized": "Recent research has increasingly focused on unsupervised learning and semi-supervised learning.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 32], [33, 40], [41, 43], [44, 56], [57, 65], [66, 69], [70, 85], [86, 94], [94, 95]]}
{"doc_key": "ai-dev-94", "ner": [], "ner_mapping_to_source": [], "relations": [], "relations_mapping_to_source": [], "sentence": ["Calculating", "this", "example", "with", "Python", "code", ":"], "sentence-detokenized": "Calculating this example with Python code:", "token2charspan": [[0, 11], [12, 16], [17, 24], [25, 29], [30, 36], [37, 41], [41, 42]]}
{"doc_key": "ai-dev-95", "ner": [[7, 8, "task"], [14, 15, "field"], [21, 24, "algorithm"], [18, 20, "algorithm"], [28, 30, "algorithm"], [33, 34, "researcher"], [36, 38, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[21, 24, 14, 15, "part-of", "", false, false], [21, 24, 28, 30, "type-of", "", false, false], [21, 24, 33, 34, "origin", "", false, false], [21, 24, 36, 38, "origin", "", false, false], [18, 20, 21, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Today", ",", "however", ",", "many", "aspects", "of", "speech", "recognition", "have", "been", "captured", "by", "a", "deep", "learning", "method", "called", "LSTM", "(", "Long", "short", "-", "term", "memory", ")", ",", "a", "recursive", "neural", "network", "published", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "in", "1997", "."], "sentence-detokenized": "Today, however, many aspects of speech recognition have been captured by a deep learning method called LSTM (Long short-term memory), a recursive neural network published by Sepp Hochreiter and J\u00fcrgen Schmidhuber in 1997.", "token2charspan": [[0, 5], [5, 6], [7, 14], [14, 15], [16, 20], [21, 28], [29, 31], [32, 38], [39, 50], [51, 55], [56, 60], [61, 69], [70, 72], [73, 74], [75, 79], [80, 88], [89, 95], [96, 102], [103, 107], [108, 109], [109, 113], [114, 119], [119, 120], [120, 124], [125, 131], [131, 132], [132, 133], [134, 135], [136, 145], [146, 152], [153, 160], [161, 170], [171, 173], [174, 178], [179, 189], [190, 193], [194, 200], [201, 212], [213, 215], [216, 220], [220, 221]]}
{"doc_key": "ai-dev-96", "ner": [[8, 8, "algorithm"], [17, 17, "algorithm"], [22, 22, "algorithm"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[8, 8, 22, 22, "named", "same", false, false], [17, 17, 22, 22, "compare", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "preliminary", "experimental", "results", "using", "noisy", "datasets", ",", "BrownBoost", "outperformed", "AdaBoost", "'s", "generalization", "error", ";", "however", ",", "LogitBoost", "performed", "as", "well", "as", "BrownBoost", "."], "sentence-detokenized": "In preliminary experimental results using noisy datasets, BrownBoost outperformed AdaBoost's generalization error; however, LogitBoost performed as well as BrownBoost.", "token2charspan": [[0, 2], [3, 14], [15, 27], [28, 35], [36, 41], [42, 47], [48, 56], [56, 57], [58, 68], [69, 81], [82, 90], [90, 92], [93, 107], [108, 113], [113, 114], [115, 122], [122, 123], [124, 134], [135, 144], [145, 147], [148, 152], [153, 155], [156, 166], [166, 167]]}
{"doc_key": "ai-dev-97", "ner": [[0, 1, "algorithm"], [5, 7, "researcher"], [8, 11, "country"], [14, 16, "researcher"], [21, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 7, "part-of", "", false, false], [5, 7, 8, 11, "physical", "", false, false], [21, 22, 14, 16, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Evolutionary", "programming", "was", "introduced", "by", "Lawrence", "J.", "Fogel", "in", "the", "United", "States", ",", "and", "John", "Henry", "Holland", "called", "his", "method", "the", "genetic", "algorithm", "."], "sentence-detokenized": "Evolutionary programming was introduced by Lawrence J. Fogel in the United States, and John Henry Holland called his method the genetic algorithm.", "token2charspan": [[0, 12], [13, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 54], [55, 60], [61, 63], [64, 67], [68, 74], [75, 81], [81, 82], [83, 86], [87, 91], [92, 97], [98, 105], [106, 112], [113, 116], [117, 123], [124, 127], [128, 135], [136, 145], [145, 146]]}
{"doc_key": "ai-dev-98", "ner": [[2, 2, "researcher"], [4, 4, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [1, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 10, 11, "role", "", false, false], [2, 2, 13, 14, "role", "", false, false], [2, 2, 16, 17, "role", "", false, false], [2, 2, 1, 20, "role", "", false, false], [4, 4, 10, 11, "role", "", false, false], [4, 4, 13, 14, "role", "", false, false], [4, 4, 16, 17, "role", "", false, false], [4, 4, 1, 20, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Calculations", "by", "Doug", ",", "Alan", "and", "their", "colleagues", "(", "including", "Marvin", "Minsky", ",", "Allen", "Newell", ",", "Edward", "Feigenbaum", "and", "John", "McCarthy", ")", "showed", "that", "this", "work", "would", "require", "1000-", "3000", "person", "-", "years", "of", "effort", ",", "well", "beyond", "the", "usual", "academic", "project", "model", "."], "sentence-detokenized": "Calculations by Doug, Alan and their colleagues (including Marvin Minsky, Allen Newell, Edward Feigenbaum and John McCarthy) showed that this work would require 1000-3000 person-years of effort, well beyond the usual academic project model.", "token2charspan": [[0, 12], [13, 15], [16, 20], [20, 21], [22, 26], [27, 30], [31, 36], [37, 47], [48, 49], [49, 58], [59, 65], [66, 72], [72, 73], [74, 79], [80, 86], [86, 87], [88, 94], [95, 105], [106, 109], [110, 114], [115, 123], [123, 124], [125, 131], [132, 136], [137, 141], [142, 146], [147, 152], [153, 160], [161, 166], [166, 170], [171, 177], [177, 178], [178, 183], [184, 186], [187, 193], [193, 194], [195, 199], [200, 206], [207, 210], [211, 216], [217, 225], [226, 233], [234, 239], [239, 240]]}
{"doc_key": "ai-dev-99", "ner": [[9, 12, "metrics"], [15, 17, "metrics"], [19, 22, "metrics"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[15, 17, 19, 22, "part-of", "implemented_in", false, false]], "relations_mapping_to_source": [1], "sentence": ["Common", "criteria", "are", "the", "mean", "square", "error", "criterion", "implemented", "in", "the", "MSECriterion", "software", "and", "the", "cross", "-entropy", "criterion", "implemented", "in", "the", "NLLCriterion", "software", "."], "sentence-detokenized": "Common criteria are the mean square error criterion implemented in the MSECriterion software and the cross-entropy criterion implemented in the NLLCriterion software.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 23], [24, 28], [29, 35], [36, 41], [42, 51], [52, 63], [64, 66], [67, 70], [71, 83], [84, 92], [93, 96], [97, 100], [101, 106], [106, 114], [115, 124], [125, 136], [137, 139], [140, 143], [144, 156], [157, 165], [165, 166]]}
{"doc_key": "ai-dev-100", "ner": [[0, 0, "researcher"], [13, 14, "organisation"], [16, 25, "misc"], [31, 34, "conference"], [45, 45, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 13, 14, "role", "", false, false], [0, 0, 31, 34, "role", "", false, false], [0, 0, 45, 45, "role", "", false, false], [16, 25, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Zurada", "has", "served", "the", "engineering", "community", "as", "a", "long", "-", "time", "volunteer", "of", "the", "IEEE", ":", "as", "IEEE", "Vice", "Chair", "(", "TAB", "Chair", ")", "in", "2014", ",", "as", "Chair", "of", "the", "IEEE", "Computational", "Intelligence", "Society", "in", "2004", "-", "05", ",", "and", "as", "a", "member", "of", "ADCOM", "in", "2009", "-", "14", ",", "2016", "-", "18", "and", "earlier", "years", "."], "sentence-detokenized": "Zurada has served the engineering community as a long-time volunteer of the IEEE: as IEEE Vice Chair (TAB Chair) in 2014, as Chair of the IEEE Computational Intelligence Society in 2004-05, and as a member of ADCOM in 2009-14, 2016-18 and earlier years.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 21], [22, 33], [34, 43], [44, 46], [47, 48], [49, 53], [53, 54], [54, 58], [59, 68], [69, 71], [72, 75], [76, 80], [80, 81], [82, 84], [85, 89], [90, 94], [95, 100], [101, 102], [102, 105], [106, 111], [111, 112], [113, 115], [116, 120], [120, 121], [122, 124], [125, 130], [131, 133], [134, 137], [138, 142], [143, 156], [157, 169], [170, 177], [178, 180], [181, 185], [185, 186], [186, 188], [188, 189], [190, 193], [194, 196], [197, 198], [199, 205], [206, 208], [209, 214], [215, 217], [218, 222], [222, 223], [223, 225], [225, 226], [227, 231], [231, 232], [232, 234], [235, 238], [239, 246], [247, 252], [252, 253]]}
{"doc_key": "ai-dev-101", "ner": [[3, 5, "field"], [8, 9, "field"], [11, 13, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 3, 5, "part-of", "", false, false], [11, 13, 3, 5, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "general", ",", "computational", "linguistics", "involves", "linguists", ",", "computer", "scientists", ",", "artificial", "intelligence", "experts", ",", "mathematicians", ",", "logicians", ",", "philosophers", ",", "cognitive", "scientists", ",", "cognitive", "psychologists", ",", "psycholinguists", ",", "anthropologists", "and", "neuroscientists", ",", "among", "others", "."], "sentence-detokenized": "In general, computational linguistics involves linguists, computer scientists, artificial intelligence experts, mathematicians, logicians, philosophers, cognitive scientists, cognitive psychologists, psycholinguists, anthropologists and neuroscientists, among others.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 25], [26, 37], [38, 46], [47, 56], [56, 57], [58, 66], [67, 77], [77, 78], [79, 89], [90, 102], [103, 110], [110, 111], [112, 126], [126, 127], [128, 137], [137, 138], [139, 151], [151, 152], [153, 162], [163, 173], [173, 174], [175, 184], [185, 198], [198, 199], [200, 215], [215, 216], [217, 232], [233, 236], [237, 252], [252, 253], [254, 259], [260, 266], [266, 267]]}
{"doc_key": "ai-dev-102", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "long", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "correlations", "between", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and long short-term memory are often used to exploit correlations between frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 82], [83, 88], [88, 89], [89, 93], [94, 100], [101, 104], [105, 110], [111, 115], [116, 118], [119, 126], [127, 139], [140, 147], [148, 154], [154, 155]]}
{"doc_key": "ai-dev-103", "ner": [[0, 0, "product"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Unimate", "was", "the", "first", "industrial", "robot", ","], "sentence-detokenized": "Unimate was the first industrial robot,", "token2charspan": [[0, 7], [8, 11], [12, 15], [16, 21], [22, 32], [33, 38], [38, 39]]}
{"doc_key": "ai-dev-104", "ner": [[8, 9, "researcher"], [11, 12, "researcher"], [0, 0, "researcher"], [3, 5, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 3, 5, "win-defeat", "", false, false], [11, 12, 3, 5, "win-defeat", "", false, false], [0, 0, 3, 5, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Bengio", "won", "the", "2018", "Turing", "Prize", "along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", "."], "sentence-detokenized": "Bengio won the 2018 Turing Prize along with Geoffrey Hinton and Yann LeCun.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 19], [20, 26], [27, 32], [33, 38], [39, 43], [44, 52], [53, 59], [60, 63], [64, 68], [69, 74], [74, 75]]}
{"doc_key": "ai-dev-105", "ner": [[7, 7, "country"], [21, 24, "misc"], [26, 26, "country"], [29, 31, "organisation"], [35, 36, "person"], [39, 40, "person"], [50, 53, "misc"], [54, 54, "country"], [60, 60, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[21, 24, 7, 7, "physical", "filmed_in", false, false], [35, 36, 29, 31, "role", "host", false, false], [39, 40, 29, 31, "role", "reporter", false, false], [50, 53, 7, 7, "physical", "filmed_in", false, false], [50, 53, 54, 54, "physical", "distributed_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Other", "series", "were", "also", "filmed", "at", "the", "UK", "venue", "for", "specific", "sectors", "of", "the", "global", "market", ",", "including", "two", "series", "of", "Robot", "Wars", "Extreme", "Warriors", "featuring", "US", "competitors", "for", "the", "TNN", "network", "(", "hosted", "by", "Mick", "Foley", "and", "with", "Rebecca", "Grant", "as", "a", "pit", "editor", ")", ",", "two", "series", "of", "Dutch", "Robot", "Wars", "for", "Dutch", "distribution", "and", "one", "series", "for", "Germany", "."], "sentence-detokenized": "Other series were also filmed at the UK venue for specific sectors of the global market, including two series of Robot Wars Extreme Warriors featuring US competitors for the TNN network (hosted by Mick Foley and with Rebecca Grant as a pit editor), two series of Dutch Robot Wars for Dutch distribution and one series for Germany.", "token2charspan": [[0, 5], [6, 12], [13, 17], [18, 22], [23, 29], [30, 32], [33, 36], [37, 39], [40, 45], [46, 49], [50, 58], [59, 66], [67, 69], [70, 73], [74, 80], [81, 87], [87, 88], [89, 98], [99, 102], [103, 109], [110, 112], [113, 118], [119, 123], [124, 131], [132, 140], [141, 150], [151, 153], [154, 165], [166, 169], [170, 173], [174, 177], [178, 185], [186, 187], [187, 193], [194, 196], [197, 201], [202, 207], [208, 211], [212, 216], [217, 224], [225, 230], [231, 233], [234, 235], [236, 239], [240, 246], [246, 247], [247, 248], [249, 252], [253, 259], [260, 262], [263, 268], [269, 274], [275, 279], [280, 283], [284, 289], [290, 302], [303, 306], [307, 310], [311, 317], [318, 321], [322, 329], [329, 330]]}
{"doc_key": "ai-dev-106", "ner": [[6, 6, "researcher"], [11, 11, "product"], [25, 27, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 11, 11, "role", "", false, false], [25, 27, 11, 11, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "several", "years", "from", "1986", ",", "Miller", "led", "the", "development", "of", "WordNet", ",", "a", "large", "computer", "-", "readable", "electronic", "reference", "work", "that", "can", "be", "used", "in", "search", "engines", ",", "for", "example", "."], "sentence-detokenized": "For several years from 1986, Miller led the development of WordNet, a large computer-readable electronic reference work that can be used in search engines, for example.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 22], [23, 27], [27, 28], [29, 35], [36, 39], [40, 43], [44, 55], [56, 58], [59, 66], [66, 67], [68, 69], [70, 75], [76, 84], [84, 85], [85, 93], [94, 104], [105, 114], [115, 119], [120, 124], [125, 128], [129, 131], [132, 136], [137, 139], [140, 146], [147, 154], [154, 155], [156, 159], [160, 167], [167, 168]]}
{"doc_key": "ai-dev-107", "ner": [[3, 3, "algorithm"], [7, 10, "algorithm"], [13, 15, "researcher"], [20, 24, "organisation"], [28, 30, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 13, 15, "origin", "", false, false], [3, 3, 28, 30, "win-defeat", "", false, false], [7, 10, 13, 15, "origin", "", false, false], [7, 10, 28, 30, "win-defeat", "", false, false], [13, 15, 20, 24, "physical", "", false, false], [13, 15, 20, 24, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Since", "2009", ",", "recursive", "neural", "networks", "and", "deep", "feedforward", "neural", "networks", "developed", "by", "J\u00fcrgen", "Schmidhuber", "'s", "research", "group", "at", "the", "Swiss", "artificial", "intelligence", "laboratory", "IDSIA", "have", "won", "several", "international", "handwriting", "competitions", "."], "sentence-detokenized": "Since 2009, recursive neural networks and deep feedforward neural networks developed by J\u00fcrgen Schmidhuber's research group at the Swiss artificial intelligence laboratory IDSIA have won several international handwriting competitions.", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 21], [22, 28], [29, 37], [38, 41], [42, 46], [47, 58], [59, 65], [66, 74], [75, 84], [85, 87], [88, 94], [95, 106], [106, 108], [109, 117], [118, 123], [124, 126], [127, 130], [131, 136], [137, 147], [148, 160], [161, 171], [172, 177], [178, 182], [183, 186], [187, 194], [195, 208], [209, 220], [221, 233], [233, 234]]}
{"doc_key": "ai-dev-108", "ner": [[5, 8, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "software", "is", "implemented", "in", "C", "++", "and", "is", "packaged", "in", "Python", "."], "sentence-detokenized": "The software is implemented in C++ and is packaged in Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 30], [31, 32], [32, 34], [35, 38], [39, 41], [42, 50], [51, 53], [54, 60], [60, 61]]}
{"doc_key": "ai-dev-109", "ner": [[3, 11, "country"], [14, 15, "misc"], [19, 20, "misc"], [33, 33, "misc"], [34, 35, "misc"], [36, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[19, 20, 3, 11, "temporal", "", false, false], [19, 20, 14, 15, "artifact", "", false, false], [19, 20, 36, 37, "physical", "", false, false], [34, 35, 33, 33, "named", "", false, false], [34, 35, 36, 37, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1857", ",", "at", "the", "request", "of", "the", "Tokugawa", "shogunate", ",", "a", "group", "of", "Dutch", "engineers", "began", "work", "on", "Nagasaki", "Yotetsushuo", ",", "a", "modern", ",", "Western", "-", "style", "foundry", "and", "shipyard", "near", "the", "Dutch", "Dejima", "settlement", "in", "Nagasaki", "."], "sentence-detokenized": "In 1857, at the request of the Tokugawa shogunate, a group of Dutch engineers began work on Nagasaki Yotetsushuo, a modern, Western-style foundry and shipyard near the Dutch Dejima settlement in Nagasaki.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 39], [40, 49], [49, 50], [51, 52], [53, 58], [59, 61], [62, 67], [68, 77], [78, 83], [84, 88], [89, 91], [92, 100], [101, 112], [112, 113], [114, 115], [116, 122], [122, 123], [124, 131], [131, 132], [132, 137], [138, 145], [146, 149], [150, 158], [159, 163], [164, 167], [168, 173], [174, 180], [181, 191], [192, 194], [195, 203], [203, 204]]}
{"doc_key": "ai-dev-110", "ner": [[8, 11, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["We", "make", "as", "precise", "as", "possible", "by", "measuring", "the", "mean", "squared", "error", "between", "the", "math", "/", "mathematics", "and", "the", "math", "\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", "/", "math", ":", "we", "want", "the", "math", "(", "y", "-\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", ")", "^", "2", "/", "math", "to", "be", "minimal", "both", "for", "mathx", "_", "1", ",\\", "points", ",", "x", "_n", "/", "math", "and", "for", "points", "outside", "our", "sample", "."], "sentence-detokenized": "We make as precise as possible by measuring the mean squared error between the math/mathematics and the math\\ hat {f} (x; D) / math: we want the math (y -\\ hat {f} (x; D)) ^ 2 / math to be minimal both for mathx _ 1,\\ points, x _n / math and for points outside our sample.", "token2charspan": [[0, 2], [3, 7], [8, 10], [11, 18], [19, 21], [22, 30], [31, 33], [34, 43], [44, 47], [48, 52], [53, 60], [61, 66], [67, 74], [75, 78], [79, 83], [83, 84], [84, 95], [96, 99], [100, 103], [104, 108], [108, 109], [110, 113], [114, 115], [115, 116], [116, 117], [118, 119], [119, 120], [120, 121], [122, 123], [123, 124], [125, 126], [127, 131], [131, 132], [133, 135], [136, 140], [141, 144], [145, 149], [150, 151], [151, 152], [153, 155], [156, 159], [160, 161], [161, 162], [162, 163], [164, 165], [165, 166], [166, 167], [168, 169], [169, 170], [170, 171], [172, 173], [174, 175], [176, 177], [178, 182], [183, 185], [186, 188], [189, 196], [197, 201], [202, 205], [206, 211], [212, 213], [214, 215], [215, 217], [218, 224], [224, 225], [226, 227], [228, 230], [231, 232], [233, 237], [238, 241], [242, 245], [246, 252], [253, 260], [261, 264], [265, 271], [271, 272]]}
{"doc_key": "ai-dev-111", "ner": [[6, 7, "researcher"], [13, 17, "organisation"], [22, 26, "product"], [33, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 7, 13, 17, "role", "", false, false], [22, 26, 13, 17, "temporal", "", false, false], [22, 26, 33, 35, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "then", "extended", "an", "invitation", "to", "Wydner", "to", "attend", "the", "annual", "meeting", "of", "the", "American", "Translators", "Association", "the", "following", "October", ",", "when", "Weidner", "'s", "machine", "translation", "system", "was", "the", "hoped", "-", "for", "breakthrough", "in", "machine", "translation", "."], "sentence-detokenized": "He then extended an invitation to Wydner to attend the annual meeting of the American Translators Association the following October, when Weidner's machine translation system was the hoped-for breakthrough in machine translation.", "token2charspan": [[0, 2], [3, 7], [8, 16], [17, 19], [20, 30], [31, 33], [34, 40], [41, 43], [44, 50], [51, 54], [55, 61], [62, 69], [70, 72], [73, 76], [77, 85], [86, 97], [98, 109], [110, 113], [114, 123], [124, 131], [131, 132], [133, 137], [138, 145], [145, 147], [148, 155], [156, 167], [168, 174], [175, 178], [179, 182], [183, 188], [188, 189], [189, 192], [193, 205], [206, 208], [209, 216], [217, 228], [228, 229]]}
{"doc_key": "ai-dev-112", "ner": [[7, 7, "conference"], [6, 11, "conference"], [0, 0, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 11, 7, 7, "named", "", false, false], [6, 11, 7, 7, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Google", "researchers", "presented", "the", "work", "at", "the", "2018", "NeurIPS", "conference", "(", "NeurIPS", ")", "."], "sentence-detokenized": "Google researchers presented the work at the 2018 NeurIPS conference (NeurIPS).", "token2charspan": [[0, 6], [7, 18], [19, 28], [29, 32], [33, 37], [38, 40], [41, 44], [45, 49], [50, 57], [58, 68], [69, 70], [70, 77], [77, 78], [78, 79]]}
{"doc_key": "ai-dev-113", "ner": [[0, 4, "algorithm"], [10, 11, "algorithm"], [14, 17, "metrics"], [22, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 4, 10, 11, "usage", "", false, false], [10, 11, 14, 17, "related-to", "", true, false], [14, 17, 22, 27, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Baum", "-", "Welch", "algorithm", "uses", "the", "well", "-", "known", "EM", "algorithm", "to", "find", "the", "maximum", "likelihood", "estimate", "for", "the", "parameters", "of", "the", "hidden", "Markov", "model", "given", "a", "set", "of", "observed", "feature", "vectors", "."], "sentence-detokenized": "The Baum-Welch algorithm uses the well-known EM algorithm to find the maximum likelihood estimate for the parameters of the hidden Markov model given a set of observed feature vectors.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 14], [15, 24], [25, 29], [30, 33], [34, 38], [38, 39], [39, 44], [45, 47], [48, 57], [58, 60], [61, 65], [66, 69], [70, 77], [78, 88], [89, 97], [98, 101], [102, 105], [106, 116], [117, 119], [120, 123], [124, 130], [131, 137], [138, 143], [144, 149], [150, 151], [152, 155], [156, 158], [159, 167], [168, 175], [176, 183], [183, 184]]}
{"doc_key": "ai-dev-114", "ner": [[0, 9, "product"], [11, 11, "product"], [32, 33, "misc"], [39, 48, "product"], [54, 59, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[0, 9, 11, 11, "compare", "", false, false], [32, 33, 11, 11, "part-of", "", false, false], [39, 48, 11, 11, "part-of", "", false, false], [54, 59, 11, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": [")", "In", "addition", "to", "the", "taxonomic", "information", "contained", "in", "OpenCyc", ",", "ResearchCyc", "contains", "considerably", "more", "semantic", "information", "(", "i.e.", "other", "facts", "and", "rules", "of", "thumb", ")", "related", "to", "the", "concepts", "in", "its", "knowledge", "base", ";", "it", "also", "includes", "an", "extensive", "vocabulary", ",", "English", "-", "language", "parsing", "and", "creation", "tools", ",", "and", "Java", "-", "based", "interfaces", "for", "data", "editing", "and", "querying", "."], "sentence-detokenized": ") In addition to the taxonomic information contained in OpenCyc, ResearchCyc contains considerably more semantic information (i.e. other facts and rules of thumb) related to the concepts in its knowledge base; it also includes an extensive vocabulary, English-language parsing and creation tools, and Java-based interfaces for data editing and querying.", "token2charspan": [[0, 1], [2, 4], [5, 13], [14, 16], [17, 20], [21, 30], [31, 42], [43, 52], [53, 55], [56, 63], [63, 64], [65, 76], [77, 85], [86, 98], [99, 103], [104, 112], [113, 124], [125, 126], [126, 130], [131, 136], [137, 142], [143, 146], [147, 152], [153, 155], [156, 161], [161, 162], [163, 170], [171, 173], [174, 177], [178, 186], [187, 189], [190, 193], [194, 203], [204, 208], [208, 209], [210, 212], [213, 217], [218, 226], [227, 229], [230, 239], [240, 250], [250, 251], [252, 259], [259, 260], [260, 268], [269, 276], [277, 280], [281, 289], [290, 295], [295, 296], [297, 300], [301, 305], [305, 306], [306, 311], [312, 322], [323, 326], [327, 331], [332, 339], [340, 343], [344, 352], [352, 353]]}
{"doc_key": "ai-dev-115", "ner": [[0, 1, "algorithm"], [4, 4, "task"], [8, 10, "field"], [12, 13, "field"], [15, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 4, 4, "type-of", "", false, false], [4, 4, 8, 10, "part-of", "task_part_of_field", false, false], [4, 4, 12, 13, "part-of", "task_part_of_field", false, false], [4, 4, 15, 17, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Hough", "transform", "is", "a", "feature", "extraction", "technique", "used", "in", "image", "analysis", ",", "computer", "vision", "and", "digital", "image", "processing", "."], "sentence-detokenized": "Hough transform is a feature extraction technique used in image analysis, computer vision and digital image processing.", "token2charspan": [[0, 5], [6, 15], [16, 18], [19, 20], [21, 28], [29, 39], [40, 49], [50, 54], [55, 57], [58, 63], [64, 72], [72, 73], [74, 82], [83, 89], [90, 93], [94, 101], [102, 107], [108, 118], [118, 119]]}
{"doc_key": "ai-dev-116", "ner": [[8, 12, "product"], [3, 3, "organisation"], [19, 19, "product"], [21, 22, "researcher"], [25, 26, "organisation"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[19, 19, 21, 22, "artifact", "", false, false], [25, 26, 3, 3, "role", "supported", false, false]], "relations_mapping_to_source": [3, 4], "sentence": ["In", "1978", ",", "Unimation", "developed", "the", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "robot", "with", "the", "support", "of", "Vicarmista", "(", "Victor", "Scheinman", ")", "and", "General", "Motors", "."], "sentence-detokenized": "In 1978, Unimation developed the PUMA (Programmable Universal Machine for Assembly) robot with the support of Vicarmista (Victor Scheinman) and General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 28], [29, 32], [33, 37], [38, 39], [39, 51], [52, 61], [62, 69], [70, 73], [74, 82], [82, 83], [84, 89], [90, 94], [95, 98], [99, 106], [107, 109], [110, 120], [121, 122], [122, 128], [129, 138], [138, 139], [140, 143], [144, 151], [152, 158], [158, 159]]}
{"doc_key": "ai-dev-117", "ner": [[6, 9, "algorithm"], [0, 1, "researcher"], [3, 4, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 9, 0, 1, "origin", "", false, false], [6, 9, 3, 4, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "proposed", "the", "LSTM", "in", "1997", "."], "sentence-detokenized": "Sepp Hochreiter and J\u00fcrgen Schmidhuber proposed the LSTM in 1997.", "token2charspan": [[0, 4], [5, 15], [16, 19], [20, 26], [27, 38], [39, 47], [48, 51], [52, 56], [57, 59], [60, 64], [64, 65]]}
{"doc_key": "ai-dev-118", "ner": [[6, 12, "metrics"], [14, 16, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "results", "can", "be", "presented", "as", "a", "2", "\u00d7", "2", "contingency", "table", "or", "a", "mixture", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four results can be presented as a 2 \u00d7 2 contingency table or a mixture matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 20], [21, 23], [24, 33], [34, 36], [37, 38], [39, 40], [41, 42], [43, 44], [45, 56], [57, 62], [63, 65], [66, 67], [68, 75], [76, 82], [83, 85], [86, 93], [93, 94]]}
{"doc_key": "ai-dev-119", "ner": [[9, 9, "conference"], [12, 13, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "was", "also", "very", "influential", "in", "the", "establishment", "of", "ELRA", "and", "the", "LREC", "conference", "."], "sentence-detokenized": "He was also very influential in the establishment of ELRA and the LREC conference.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 28], [29, 31], [32, 35], [36, 49], [50, 52], [53, 57], [58, 61], [62, 65], [66, 70], [71, 81], [81, 82]]}
{"doc_key": "ai-dev-120", "ner": [[12, 13, "product"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "popular", "application", "of", "serial", "robots", "in", "today", "'s", "industry", "is", "the", "SCARA", "robot", ",", "which", "has", "four", "degrees", "of", "freedom", "."], "sentence-detokenized": "A popular application of serial robots in today's industry is the SCARA robot, which has four degrees of freedom.", "token2charspan": [[0, 1], [2, 9], [10, 21], [22, 24], [25, 31], [32, 38], [39, 41], [42, 47], [47, 49], [50, 58], [59, 61], [62, 65], [66, 71], [72, 77], [77, 78], [79, 84], [85, 88], [89, 93], [94, 101], [102, 104], [105, 112], [112, 113]]}
{"doc_key": "ai-dev-121", "ner": [[16, 21, "conference"], [15, 25, "conference"], [26, 30, "conference"], [38, 38, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[15, 25, 16, 21, "named", "", false, false], [38, 38, 26, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "one", "of", "the", "founding", "members", "and", "former", "chair", "(", "2006-2008", ")", "of", "the", "Special", "Interest", "Group", "on", "Web", "as", "Corpus", "(", "SIGWAC", ")", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "one", "of", "the", "founding", "organisers", "of", "SENSEVAL", "."], "sentence-detokenized": "He was one of the founding members and former chair (2006-2008) of the Special Interest Group on Web as Corpus (SIGWAC) of the Association for Computational Linguistics and one of the founding organisers of SENSEVAL.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 13], [14, 17], [18, 26], [27, 34], [35, 38], [39, 45], [46, 51], [52, 53], [53, 62], [62, 63], [64, 66], [67, 70], [71, 78], [79, 87], [88, 93], [94, 96], [97, 100], [101, 103], [104, 110], [111, 112], [112, 118], [118, 119], [120, 122], [123, 126], [127, 138], [139, 142], [143, 156], [157, 168], [169, 172], [173, 176], [177, 179], [180, 183], [184, 192], [193, 203], [204, 206], [207, 215], [215, 216]]}
{"doc_key": "ai-dev-122", "ner": [[0, 0, "product"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 5, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["LinguaStream", "provides", "a", "comprehensive", "Java", "API", "as", "a", "platform", "."], "sentence-detokenized": "LinguaStream provides a comprehensive Java API as a platform.", "token2charspan": [[0, 12], [13, 21], [22, 23], [24, 37], [38, 42], [43, 46], [47, 49], [50, 51], [52, 60], [60, 61]]}
{"doc_key": "ai-dev-123", "ner": [[11, 11, "programlang"], [14, 16, "misc"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 19, 21, "type-of", "", false, false], [14, 16, 19, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "robot", "kit", "is", "Android", "-", "based", "and", "is", "programmed", "using", "Java", ",", "the", "Blocks", "programming", "interface", "or", "other", "Android", "programming", "systems", "."], "sentence-detokenized": "The robot kit is Android-based and is programmed using Java, the Blocks programming interface or other Android programming systems.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 16], [17, 24], [24, 25], [25, 30], [31, 34], [35, 37], [38, 48], [49, 54], [55, 59], [59, 60], [61, 64], [65, 71], [72, 83], [84, 93], [94, 96], [97, 102], [103, 110], [111, 122], [123, 130], [130, 131]]}
{"doc_key": "ai-dev-124", "ner": [[7, 7, "algorithm"], [9, 10, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "linked", "list", "definition", "method", "specifies", "a", "depth", "or", "breadth", "search", "."], "sentence-detokenized": "The linked list definition method specifies a depth or breadth search.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 26], [27, 33], [34, 43], [44, 45], [46, 51], [52, 54], [55, 62], [63, 69], [69, 70]]}
{"doc_key": "ai-dev-125", "ner": [[20, 21, "task"], [25, 28, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "areas", "can", "indicate", "the", "presence", "of", "objects", "or", "parts", "of", "objects", "in", "the", "image", "and", "can", "be", "used", "for", "object", "identification", "and", "/", "or", "video", "tracking", "of", "objects", "."], "sentence-detokenized": "These areas can indicate the presence of objects or parts of objects in the image and can be used for object identification and/or video tracking of objects.", "token2charspan": [[0, 5], [6, 11], [12, 15], [16, 24], [25, 28], [29, 37], [38, 40], [41, 48], [49, 51], [52, 57], [58, 60], [61, 68], [69, 71], [72, 75], [76, 81], [82, 85], [86, 89], [90, 92], [93, 97], [98, 101], [102, 108], [109, 123], [124, 127], [127, 128], [128, 130], [131, 136], [137, 145], [146, 148], [149, 156], [156, 157]]}
{"doc_key": "ai-dev-126", "ner": [[3, 5, "algorithm"], [7, 7, "product"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 3, 5, "type-of", "", false, false], [7, 7, 14, 15, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "a", "semantic", "network", "is", "WordNet", ",", "the", "lexical", "database", "of", "the", "English", "language", "."], "sentence-detokenized": "An example of a semantic network is WordNet, the lexical database of the English language.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 24], [25, 32], [33, 35], [36, 43], [43, 44], [45, 48], [49, 56], [57, 65], [66, 68], [69, 72], [73, 80], [81, 89], [89, 90]]}
{"doc_key": "ai-dev-127", "ner": [[0, 3, "task"], [7, 8, "field"], [10, 11, "field"], [21, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 7, 8, "part-of", "", false, false], [0, 3, 10, 11, "named", "same", false, false], [0, 3, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Speech", "recognition", "is", "an", "interdisciplinary", "field", "of", "computer", "science", "and", "computational", "linguistics", "that", "develops", "methods", "and", "technologies", "that", "enable", "computers", "to", "recognise", "and", "translate", "spoken", "language", "into", "text", "."], "sentence-detokenized": "Speech recognition is an interdisciplinary field of computer science and computational linguistics that develops methods and technologies that enable computers to recognise and translate spoken language into text.", "token2charspan": [[0, 6], [7, 18], [19, 21], [22, 24], [25, 42], [43, 48], [49, 51], [52, 60], [61, 68], [69, 72], [73, 86], [87, 98], [99, 103], [104, 112], [113, 120], [121, 124], [125, 137], [138, 142], [143, 149], [150, 159], [160, 162], [163, 172], [173, 176], [177, 186], [187, 193], [194, 202], [203, 207], [208, 212], [212, 213]]}
{"doc_key": "ai-dev-128", "ner": [[0, 0, "field"], [6, 9, "misc"], [13, 15, "field"], [16, 17, "task"], [19, 20, "task"], [41, 41, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 41, 41, "named", "same", false, false], [13, 15, 0, 0, "part-of", "subfield", false, false], [16, 17, 0, 0, "part-of", "", false, false], [16, 17, 13, 15, "part-of", "", false, false], [19, 20, 13, 15, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["AI", "has", "received", "the", "most", "attention", "in", "applied", "ontology", "in", "areas", "such", "as", "natural", "language", "processing", "in", "machines", "and", "information", "representation", ",", "but", "ontology", "modifiers", "are", "often", "used", "in", "many", "domains", ",", "such", "as", "education", ",", "without", "the", "intention", "of", "promoting", "AI", "."], "sentence-detokenized": "AI has received the most attention in applied ontology in areas such as natural language processing in machines and information representation, but ontology modifiers are often used in many domains, such as education, without the intention of promoting AI.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 19], [20, 24], [25, 34], [35, 37], [38, 45], [46, 54], [55, 57], [58, 63], [64, 68], [69, 71], [72, 79], [80, 88], [89, 99], [100, 102], [103, 111], [112, 115], [116, 127], [128, 142], [142, 143], [144, 147], [148, 156], [157, 166], [167, 170], [171, 176], [177, 181], [182, 184], [185, 189], [190, 197], [197, 198], [199, 203], [204, 206], [207, 216], [216, 217], [218, 225], [226, 229], [230, 239], [240, 242], [243, 252], [253, 255], [255, 256]]}
{"doc_key": "ai-dev-129", "ner": [[7, 8, "algorithm"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 11, 12, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["This", "update", "rule", "is", "in", "fact", "a", "stochastic", "gradient", "update", "of", "linear", "regression", "."], "sentence-detokenized": "This update rule is in fact a stochastic gradient update of linear regression.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 19], [20, 22], [23, 27], [28, 29], [30, 40], [41, 49], [50, 56], [57, 59], [60, 66], [67, 77], [77, 78]]}
{"doc_key": "ai-dev-130", "ner": [[7, 12, "organisation"], [16, 22, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "was", "elected", "a", "Fellow", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "of", "the", "National", "Academy", "of", "Sciences", ",", "and", "has", "received", "several", "awards", ":"], "sentence-detokenized": "He was elected a Fellow of the American Academy of Arts and Sciences and of the National Academy of Sciences, and has received several awards:", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 16], [17, 23], [24, 26], [27, 30], [31, 39], [40, 47], [48, 50], [51, 55], [56, 59], [60, 68], [69, 72], [73, 75], [76, 79], [80, 88], [89, 96], [97, 99], [100, 108], [108, 109], [110, 113], [114, 117], [118, 126], [127, 134], [135, 141], [141, 142]]}
{"doc_key": "ai-dev-131", "ner": [[11, 12, "person"], [14, 17, "person"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "latest", "thinking", "on", "Honda", "'s", "strategy", "was", "put", "forward", "by", "Gary", "Hamel", "and", "C.", "K", ".", "Prahalad", "in", "1989", "."], "sentence-detokenized": "The latest thinking on Honda's strategy was put forward by Gary Hamel and C. K. Prahalad in 1989.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 22], [23, 28], [28, 30], [31, 39], [40, 43], [44, 47], [48, 55], [56, 58], [59, 63], [64, 69], [70, 73], [74, 76], [77, 78], [78, 79], [80, 88], [89, 91], [92, 96], [96, 97]]}
{"doc_key": "ai-dev-132", "ner": [[1, 1, "metrics"], [4, 6, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 4, 6, "related-to", "calculates", true, false], [1, 1, 19, 19, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Whereas", "BLEU", "simply", "calculates", "the", "accuracy", "of", "an", "n-", "gram", "by", "adding", "an", "equal", "weight", "to", "each", "gram", ",", "NIST", "also", "calculates", "how", "informative", "a", "given", "n-", "gram", "is", "."], "sentence-detokenized": "Whereas BLEU simply calculates the accuracy of an n-gram by adding an equal weight to each gram, NIST also calculates how informative a given n-gram is.", "token2charspan": [[0, 7], [8, 12], [13, 19], [20, 30], [31, 34], [35, 43], [44, 46], [47, 49], [50, 52], [52, 56], [57, 59], [60, 66], [67, 69], [70, 75], [76, 82], [83, 85], [86, 90], [91, 95], [95, 96], [97, 101], [102, 106], [107, 117], [118, 121], [122, 133], [134, 135], [136, 141], [142, 144], [144, 148], [149, 151], [151, 152]]}
{"doc_key": "ai-dev-133", "ner": [[3, 14, "misc"], [6, 6, "conference"], [7, 9, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 14, 6, 6, "temporal", "", false, false], [7, 9, 6, 6, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "awarded", "the", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "Lifetime", "Achievement", "Award", "2019", "."], "sentence-detokenized": "He was awarded the Association for Computational Linguistics (ACL) Lifetime Achievement Award 2019.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 18], [19, 30], [31, 34], [35, 48], [49, 60], [61, 62], [62, 65], [65, 66], [67, 75], [76, 87], [88, 93], [94, 98], [98, 99]]}
{"doc_key": "ai-dev-134", "ner": [[0, 2, "researcher"], [8, 11, "organisation"], [6, 19, "organisation"], [20, 21, "conference"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 8, 11, "role", "", false, false], [0, 2, 20, 21, "role", "", false, false], [6, 19, 8, 11, "named", "", false, false], [23, 23, 20, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sycara", "is", "a", "member", "of", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", "and", "the", "American", "Association", "for", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Sycara is a member of the Institute of Electrical and Electronics Engineers (IEEE) and the American Association for Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 18], [19, 21], [22, 25], [26, 35], [36, 38], [39, 49], [50, 53], [54, 65], [66, 75], [76, 77], [77, 81], [81, 82], [83, 86], [87, 90], [91, 99], [100, 111], [112, 115], [116, 126], [127, 139], [140, 141], [141, 145], [145, 146], [146, 147]]}
{"doc_key": "ai-dev-135", "ner": [[13, 13, "misc"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "following", "MATLAB", "code", "presents", "a", "concrete", "solution", "to", "solve", "the", "group", "of", "non-linear", "equations", "presented", "in", "the", "previous", "section", "."], "sentence-detokenized": "The following MATLAB code presents a concrete solution to solve the group of non-linear equations presented in the previous section.", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 34], [35, 36], [37, 45], [46, 54], [55, 57], [58, 63], [64, 67], [68, 73], [74, 76], [77, 87], [88, 97], [98, 107], [108, 110], [111, 114], [115, 123], [124, 131], [131, 132]]}
{"doc_key": "ai-dev-136", "ner": [[4, 6, "product"], [14, 15, "field"], [37, 38, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 14, 15, "related-to", "trained_by", true, false], [4, 6, 37, 38, "related-to", "trained_by", true, false], [14, 15, 37, 38, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "many", "cases", ",", "pattern", "recognition", "systems", "are", "trained", "on", "labelled", "training", "data", "(", "supervised", "learning", ")", ",", "but", "when", "labelled", "data", "is", "not", "available", ",", "other", "algorithms", "can", "be", "used", "to", "find", "previously", "unknown", "patterns", "(", "unsupervised", "learning", ")", "."], "sentence-detokenized": "In many cases, pattern recognition systems are trained on labelled training data (supervised learning), but when labelled data is not available, other algorithms can be used to find previously unknown patterns (unsupervised learning).", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 22], [23, 34], [35, 42], [43, 46], [47, 54], [55, 57], [58, 66], [67, 75], [76, 80], [81, 82], [82, 92], [93, 101], [101, 102], [102, 103], [104, 107], [108, 112], [113, 121], [122, 126], [127, 129], [130, 133], [134, 143], [143, 144], [145, 150], [151, 161], [162, 165], [166, 168], [169, 173], [174, 176], [177, 181], [182, 192], [193, 200], [201, 209], [210, 211], [211, 223], [224, 232], [232, 233], [233, 234]]}
{"doc_key": "ai-dev-137", "ner": [[5, 8, "researcher"], [9, 10, "country"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 8, 9, 10, "physical", "", false, false], [5, 8, 23, 24, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "was", "first", "used", "by", "Lawrence", "J.", "Fogel", "in", "the", "US", "in", "1960", "to", "use", "simulated", "evolution", "as", "a", "learning", "process", "to", "create", "artificial", "intelligence", "."], "sentence-detokenized": "It was first used by Lawrence J. Fogel in the US in 1960 to use simulated evolution as a learning process to create artificial intelligence.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 17], [18, 20], [21, 29], [30, 32], [33, 38], [39, 41], [42, 45], [46, 48], [49, 51], [52, 56], [57, 59], [60, 63], [64, 73], [74, 83], [84, 86], [87, 88], [89, 97], [98, 105], [106, 108], [109, 115], [116, 126], [127, 139], [139, 140]]}
{"doc_key": "ai-dev-138", "ner": [[0, 2, "field"], [8, 9, "field"], [14, 15, "field"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 8, 9, "part-of", "", false, false], [14, 15, 8, 9, "part-of", "", false, false], [17, 18, 8, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Reinforcement", "learning", "is", "one", "of", "the", "three", "basic", "machine", "learning", "paradigms", ",", "along", "with", "supervised", "learning", "and", "unsupervised", "learning", "."], "sentence-detokenized": "Reinforcement learning is one of the three basic machine learning paradigms, along with supervised learning and unsupervised learning.", "token2charspan": [[0, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 42], [43, 48], [49, 56], [57, 65], [66, 75], [75, 76], [77, 82], [83, 87], [88, 98], [99, 107], [108, 111], [112, 124], [125, 133], [133, 134]]}
{"doc_key": "ai-dev-139", "ner": [[4, 5, "field"], [10, 12, "programlang"], [29, 30, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 29, 30, "usage", "applies", false, false], [10, 12, 29, 30, "usage", "applies", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "such", "cases", ",", "cloud", "computing", "and", "the", "open", "source", "R", "programming", "language", "can", "help", "smaller", "banks", "to", "adopt", "risk", "analytics", "and", "support", "branch", "-", "level", "monitoring", "by", "applying", "predictive", "analytics", "."], "sentence-detokenized": "In such cases, cloud computing and the open source R programming language can help smaller banks to adopt risk analytics and support branch-level monitoring by applying predictive analytics.", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 20], [21, 30], [31, 34], [35, 38], [39, 43], [44, 50], [51, 52], [53, 64], [65, 73], [74, 77], [78, 82], [83, 90], [91, 96], [97, 99], [100, 105], [106, 110], [111, 120], [121, 124], [125, 132], [133, 139], [139, 140], [140, 145], [146, 156], [157, 159], [160, 168], [169, 179], [180, 189], [189, 190]]}
{"doc_key": "ai-dev-140", "ner": [[0, 1, "researcher"], [14, 15, "algorithm"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 19, 20, "named", "same", false, false], [14, 15, 0, 1, "origin", "proves_function", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["George", "Cybenko", "proved", "one", "of", "the", "first", "versions", "of", "the", "theorem", "in", "1989", "for", "sigmoid", "function", "activation", "functions", ".", "Cybenko", "G.", "(", "1989", ")", ",", "2", "(", "4", ")", ",", "303-314", "."], "sentence-detokenized": "George Cybenko proved one of the first versions of the theorem in 1989 for sigmoid function activation functions. Cybenko G. (1989), 2 (4), 303-314.", "token2charspan": [[0, 6], [7, 14], [15, 21], [22, 25], [26, 28], [29, 32], [33, 38], [39, 47], [48, 50], [51, 54], [55, 62], [63, 65], [66, 70], [71, 74], [75, 82], [83, 91], [92, 102], [103, 112], [112, 113], [114, 121], [122, 124], [125, 126], [126, 130], [130, 131], [131, 132], [133, 134], [135, 136], [136, 137], [137, 138], [138, 139], [140, 147], [147, 148]]}
{"doc_key": "ai-dev-141", "ner": [[5, 6, "algorithm"], [9, 10, "metrics"], [13, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 5, 6, "part-of", "", false, false], [13, 19, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "this", "process", ",", "known", "as", "cross-validation", ",", "the", "MSE", "is", "often", "called", "the", "mean", "squared", "prediction", "error", "and", "is", "calculated", "as", "follows"], "sentence-detokenized": "In this process, known as cross-validation, the MSE is often called the mean squared prediction error and is calculated as follows", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 22], [23, 25], [26, 42], [42, 43], [44, 47], [48, 51], [52, 54], [55, 60], [61, 67], [68, 71], [72, 76], [77, 84], [85, 95], [96, 101], [102, 105], [106, 108], [109, 119], [120, 122], [123, 130]]}
{"doc_key": "ai-dev-142", "ner": [[0, 0, "task"], [4, 8, "task"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["OMR", "generally", "differs", "from", "optical", "character", "recognition", "(", "OCR", ")", "in", "that", "it", "does", "not", "require", "a", "complex", "image", "recognition", "system", "."], "sentence-detokenized": "OMR generally differs from optical character recognition (OCR) in that it does not require a complex image recognition system.", "token2charspan": [[0, 3], [4, 13], [14, 21], [22, 26], [27, 34], [35, 44], [45, 56], [57, 58], [58, 61], [61, 62], [63, 65], [66, 70], [71, 73], [74, 78], [79, 82], [83, 90], [91, 92], [93, 100], [101, 106], [107, 118], [119, 125], [125, 126]]}
{"doc_key": "ai-dev-143", "ner": [[9, 10, "location"], [12, 12, "location"], [14, 14, "location"], [15, 18, "location"], [20, 21, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 14, 14, "physical", "", false, false], [15, 18, 12, 12, "physical", "", false, false], [20, 21, 12, 12, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2018", "and", "2019", ",", "the", "championships", "were", "held", "in", "Houston", "and", "Detroit", ",", "Michigan", "at", "the", "TCF", "Center", "and", "Ford", "Field", "."], "sentence-detokenized": "In 2018 and 2019, the championships were held in Houston and Detroit, Michigan at the TCF Center and Ford Field.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 16], [16, 17], [18, 21], [22, 35], [36, 40], [41, 45], [46, 48], [49, 56], [57, 60], [61, 68], [68, 69], [70, 78], [79, 81], [82, 85], [86, 89], [90, 96], [97, 100], [101, 105], [106, 111], [111, 112]]}
{"doc_key": "ai-dev-144", "ner": [[0, 0, "task"], [10, 11, "task"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 0, 0, "part-of", "", false, false], [13, 14, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "thought", "of", "as", "two", "separate", "problems", "-", "binary", "classification", "and", "multiclass", "classification", "."], "sentence-detokenized": "Classification can be thought of as two separate problems - binary classification and multiclass classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 29], [30, 32], [33, 35], [36, 39], [40, 48], [49, 57], [58, 59], [60, 66], [67, 81], [82, 85], [86, 96], [97, 111], [111, 112]]}
{"doc_key": "ai-dev-145", "ner": [[4, 5, "product"], [8, 9, "product"], [12, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 4, 5, "type-of", "", false, false], [12, 13, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "examples", "of", "popular", "parallel", "robots", "are", "the", "Stewart", "platform", "and", "the", "Delta", "robot", "."], "sentence-detokenized": "Two examples of popular parallel robots are the Stewart platform and the Delta robot.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 23], [24, 32], [33, 39], [40, 43], [44, 47], [48, 55], [56, 64], [65, 68], [69, 72], [73, 78], [79, 84], [84, 85]]}
{"doc_key": "ai-dev-146", "ner": [[0, 9, "algorithm"], [22, 23, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 9, 22, 23, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "However", ",", "the", "ReLU", "activation", "function", ",", "which", "is", "not", "differentiable", "at", "0", ",", "has", "become", "quite", "popular", ",", "for", "example", "on", "AlexNet", ".", ")"], "sentence-detokenized": "(However, the ReLU activation function, which is not differentiable at 0, has become quite popular, for example on AlexNet.)", "token2charspan": [[0, 1], [1, 8], [8, 9], [10, 13], [14, 18], [19, 29], [30, 38], [38, 39], [40, 45], [46, 48], [49, 52], [53, 67], [68, 70], [71, 72], [72, 73], [74, 77], [78, 84], [85, 90], [91, 98], [98, 99], [100, 103], [104, 111], [112, 114], [115, 122], [122, 123], [123, 124]]}
{"doc_key": "ai-dev-147", "ner": [[0, 4, "metrics"], [7, 9, "task"], [15, 15, "task"], [17, 18, "task"], [20, 21, "task"], [24, 24, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 4, 24, 24, "named", "", true, false], [7, 9, 0, 4, "usage", "", true, false], [15, 15, 7, 9, "part-of", "", false, false], [17, 18, 7, 9, "part-of", "", false, false], [20, 21, 7, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "F", "-", "score", "is", "often", "used", "in", "information", "retrieval", "to", "measure", "the", "performance", "of", "searches", ",", "document", "classification", "and", "query", "classification", ",", "so", "F_beta", "is", "widely", "used", "."], "sentence-detokenized": "The F-score is often used in information retrieval to measure the performance of searches, document classification and query classification, so F_beta is widely used.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 20], [21, 25], [26, 28], [29, 40], [41, 50], [51, 53], [54, 61], [62, 65], [66, 77], [78, 80], [81, 89], [89, 90], [91, 99], [100, 114], [115, 118], [119, 124], [125, 139], [139, 140], [141, 143], [144, 150], [151, 153], [154, 160], [161, 165], [165, 166]]}
{"doc_key": "ai-dev-148", "ner": [[18, 18, "algorithm"], [17, 20, "algorithm"], [23, 24, "algorithm"], [26, 26, "algorithm"], [29, 30, "algorithm"], [32, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[17, 20, 18, 18, "named", "", false, false], [26, 26, 23, 24, "named", "", false, false], [32, 32, 29, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "is", "done", "by", "modelling", "the", "received", "signal", "and", "then", "using", "a", "statistical", "estimation", "method", "such", "as", "maximum", "likelihood", "(", "ML", ")", ",", "majority", "voting", "(", "MV", ")", "or", "posterior", "estimation", "(", "MAP", ")", "to", "decide", "which", "item", "in", "the", "library", "best", "fits", "the", "model", "built", "from", "the", "received", "signal", "."], "sentence-detokenized": "This is done by modelling the received signal and then using a statistical estimation method such as maximum likelihood (ML), majority voting (MV) or posterior estimation (MAP) to decide which item in the library best fits the model built from the received signal.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 15], [16, 25], [26, 29], [30, 38], [39, 45], [46, 49], [50, 54], [55, 60], [61, 62], [63, 74], [75, 85], [86, 92], [93, 97], [98, 100], [101, 108], [109, 119], [120, 121], [121, 123], [123, 124], [124, 125], [126, 134], [135, 141], [142, 143], [143, 145], [145, 146], [147, 149], [150, 159], [160, 170], [171, 172], [172, 175], [175, 176], [177, 179], [180, 186], [187, 192], [193, 197], [198, 200], [201, 204], [205, 212], [213, 217], [218, 222], [223, 226], [227, 232], [233, 238], [239, 243], [244, 247], [248, 256], [257, 263], [263, 264]]}
{"doc_key": "ai-dev-149", "ner": [[0, 0, "researcher"], [3, 4, "misc"], [7, 7, "field"], [8, 13, "university"], [18, 21, "misc"], [22, 22, "field"], [24, 26, "university"], [32, 33, "misc"], [34, 37, "field"], [38, 40, "university"], [46, 55, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 0, 8, 13, "physical", "", false, false], [0, 0, 8, 13, "role", "", false, false], [0, 0, 24, 26, "physical", "", false, false], [0, 0, 24, 26, "role", "", false, false], [0, 0, 38, 40, "physical", "", false, false], [0, 0, 38, 40, "role", "", false, false], [3, 4, 0, 0, "origin", "", false, false], [3, 4, 7, 7, "topic", "", false, false], [18, 21, 0, 0, "origin", "", false, false], [18, 21, 22, 22, "topic", "", false, false], [32, 33, 0, 0, "origin", "", false, false], [32, 33, 34, 37, "topic", "", false, false], [46, 55, 32, 33, "named", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Sowa", "received", "a", "bachelor", "'s", "degree", "in", "mathematics", "from", "the", "Massachusetts", "Institute", "of", "Technology", "in", "1962", ",", "a", "master", "'s", "degree", "in", "applied", "mathematics", "from", "Harvard", "University", "in", "1966", ",", "and", "a", "doctorate", "in", "computer", "science", "from", "the", "Vrije", "Universiteit", "Brussel", "in", "1999", "for", "his", "dissertation", "Knowledge", "Representation", ":", "Logical", ",", "Philosophical", ",", "and", "Computational", "Foundations", "."], "sentence-detokenized": "Sowa received a bachelor's degree in mathematics from the Massachusetts Institute of Technology in 1962, a master's degree in applied mathematics from Harvard University in 1966, and a doctorate in computer science from the Vrije Universiteit Brussel in 1999 for his dissertation Knowledge Representation: Logical, Philosophical, and Computational Foundations.", "token2charspan": [[0, 4], [5, 13], [14, 15], [16, 24], [24, 26], [27, 33], [34, 36], [37, 48], [49, 53], [54, 57], [58, 71], [72, 81], [82, 84], [85, 95], [96, 98], [99, 103], [103, 104], [105, 106], [107, 113], [113, 115], [116, 122], [123, 125], [126, 133], [134, 145], [146, 150], [151, 158], [159, 169], [170, 172], [173, 177], [177, 178], [179, 182], [183, 184], [185, 194], [195, 197], [198, 206], [207, 214], [215, 219], [220, 223], [224, 229], [230, 242], [243, 250], [251, 253], [254, 258], [259, 262], [263, 266], [267, 279], [280, 289], [290, 304], [304, 305], [306, 313], [313, 314], [315, 328], [328, 329], [330, 333], [334, 347], [348, 359], [359, 360]]}
{"doc_key": "ai-dev-150", "ner": [[1, 2, "task"], [18, 18, "metrics"], [20, 21, "metrics"], [23, 24, "metrics"]], "ner_mapping_to_source": [0, 2, 3, 4], "relations": [[18, 18, 1, 2, "part-of", "", true, false], [20, 21, 1, 2, "part-of", "", true, false], [23, 24, 1, 2, "part-of", "", true, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Since", "paraphrase", "identification", "can", "be", "represented", "as", "a", "classification", "problem", ",", "most", "conventional", "evaluation", "metrics", ",", "such", "as", "accuracy", ",", "f1", "score", "or", "ROC", "curve", ",", "work", "relatively", "well", "."], "sentence-detokenized": "Since paraphrase identification can be represented as a classification problem, most conventional evaluation metrics, such as accuracy, f1 score or ROC curve, work relatively well.", "token2charspan": [[0, 5], [6, 16], [17, 31], [32, 35], [36, 38], [39, 50], [51, 53], [54, 55], [56, 70], [71, 78], [78, 79], [80, 84], [85, 97], [98, 108], [109, 116], [116, 117], [118, 122], [123, 125], [126, 134], [134, 135], [136, 138], [139, 144], [145, 147], [148, 151], [152, 157], [157, 158], [159, 163], [164, 174], [175, 179], [179, 180]]}
{"doc_key": "ai-dev-151", "ner": [[16, 20, "algorithm"], [26, 27, "algorithm"], [29, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 20, 26, 27, "opposite", "not_suited_for", false, false], [16, 20, 29, 30, "opposite", "not_suited_for", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "makes", "it", "practical", "for", "analysing", "large", "datasets", "(", "hundreds", "or", "thousands", "of", "taxa", ")", "and", "bootstrapping", "studies", ",", "for", "which", "other", "analysis", "methods", "(", "e.g.", "maximum", "parsimony", ",", "maximum", "likelihood", ")", "may", "be", "computationally", "too", "expensive", "."], "sentence-detokenized": "This makes it practical for analysing large datasets (hundreds or thousands of taxa) and bootstrapping studies, for which other analysis methods (e.g. maximum parsimony, maximum likelihood) may be computationally too expensive.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 37], [38, 43], [44, 52], [53, 54], [54, 62], [63, 65], [66, 75], [76, 78], [79, 83], [83, 84], [85, 88], [89, 102], [103, 110], [110, 111], [112, 115], [116, 121], [122, 127], [128, 136], [137, 144], [145, 146], [146, 150], [151, 158], [159, 168], [168, 169], [170, 177], [178, 188], [188, 189], [190, 193], [194, 196], [197, 212], [213, 216], [217, 226], [226, 227]]}
{"doc_key": "ai-dev-152", "ner": [[3, 3, "programlang"], [5, 6, "programlang"], [7, 12, "organisation"], [9, 14, "organisation"], [25, 39, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 5], "relations": [[9, 14, 7, 12, "named", "", false, false], [25, 39, 3, 3, "role", "submits", true, false], [25, 39, 5, 6, "role", "submits", true, false], [25, 39, 7, 12, "role", "submits_to", true, false]], "relations_mapping_to_source": [1, 2, 3, 4], "sentence": ["Submission", "of", "the", "DAML", "+", "OIL", "language", "to", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", "in", "2002", "Work", "by", "the", "DAML", "editors", "and", "the", "ad", "hoc", "Joint", "Committee", "on", "Markup", "Languages", "of", "the", "European", "Union", "and", "the", "United", "States", "."], "sentence-detokenized": "Submission of the DAML + OIL language to the World Wide Web Consortium (W3C) in 2002 Work by the DAML editors and the ad hoc Joint Committee on Markup Languages of the European Union and the United States.", "token2charspan": [[0, 10], [11, 13], [14, 17], [18, 22], [23, 24], [25, 28], [29, 37], [38, 40], [41, 44], [45, 50], [51, 55], [56, 59], [60, 70], [71, 72], [72, 75], [75, 76], [77, 79], [80, 84], [85, 89], [90, 92], [93, 96], [97, 101], [102, 109], [110, 113], [114, 117], [118, 120], [121, 124], [125, 130], [131, 140], [141, 143], [144, 150], [151, 160], [161, 163], [164, 167], [168, 176], [177, 182], [183, 186], [187, 190], [191, 197], [198, 204], [204, 205]]}
{"doc_key": "ai-dev-153", "ner": [[3, 4, "misc"], [7, 8, "misc"], [10, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 3, 4, "part-of", "", true, false], [10, 16, 3, 4, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "non-linear", "normalization", "is", "when", "the", "normalization", "follows", "a", "sigmoid", "function", ";", "in", "this", "case", ",", "the", "normalized", "image", "is", "calculated", "according", "to", "the", "formula"], "sentence-detokenized": "An example of non-linear normalization is when the normalization follows a sigmoid function; in this case, the normalized image is calculated according to the formula", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 24], [25, 38], [39, 41], [42, 46], [47, 50], [51, 64], [65, 72], [73, 74], [75, 82], [83, 91], [91, 92], [93, 95], [96, 100], [101, 105], [105, 106], [107, 110], [111, 121], [122, 127], [128, 130], [131, 141], [142, 151], [152, 154], [155, 158], [159, 166]]}
{"doc_key": "ai-dev-154", "ner": [[5, 5, "metrics"], [10, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 10, 11, "related-to", "used_together", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "found", "that", "accuracy", "is", "usually", "combined", "with", "recall", "accuracy", "to", "solve", "this", "problem", "."], "sentence-detokenized": "It has been found that accuracy is usually combined with recall accuracy to solve this problem.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 17], [18, 22], [23, 31], [32, 34], [35, 42], [43, 51], [52, 56], [57, 63], [64, 72], [73, 75], [76, 81], [82, 86], [87, 94], [94, 95]]}
{"doc_key": "ai-dev-155", "ner": [[5, 7, "metrics"], [10, 13, "metrics"], [19, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 22, 10, 13, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Commonly", "used", "measures", "are", "the", "mean", "square", "error", "and", "the", "root", "mean", "square", "error", ",", "the", "latter", "being", "used", "in", "the", "Netflix", "Prize", "."], "sentence-detokenized": "Commonly used measures are the mean square error and the root mean square error, the latter being used in the Netflix Prize.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 26], [27, 30], [31, 35], [36, 42], [43, 48], [49, 52], [53, 56], [57, 61], [62, 66], [67, 73], [74, 79], [79, 80], [81, 84], [85, 91], [92, 97], [98, 102], [103, 105], [106, 109], [110, 117], [118, 123], [123, 124]]}
{"doc_key": "ai-dev-156", "ner": [[10, 13, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "August", "2016", ",", "a", "research", "programme", "was", "announced", "with", "University", "College", "Hospital", "to", "develop", "an", "algorithm", "to", "automatically", "distinguish", "between", "healthy", "and", "cancerous", "tissues", "in", "the", "head", "and", "neck", "."], "sentence-detokenized": "In August 2016, a research programme was announced with University College Hospital to develop an algorithm to automatically distinguish between healthy and cancerous tissues in the head and neck.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 17], [18, 26], [27, 36], [37, 40], [41, 50], [51, 55], [56, 66], [67, 74], [75, 83], [84, 86], [87, 94], [95, 97], [98, 107], [108, 110], [111, 124], [125, 136], [137, 144], [145, 152], [153, 156], [157, 166], [167, 174], [175, 177], [178, 181], [182, 186], [187, 190], [191, 195], [195, 196]]}
{"doc_key": "ai-dev-157", "ner": [[13, 15, "organisation"], [18, 21, "organisation"], [24, 27, "organisation"], [30, 35, "organisation"], [38, 44, "organisation"], [48, 51, "organisation"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["Posner", "'s", "theoretical", "and", "empirical", "contributions", "have", "been", "recognized", "by", "membership", "in", "the", "American", "Psychological", "Association", ",", "the", "Association", "for", "Psychological", "Science", ",", "the", "Society", "of", "Experimental", "Psychologists", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "Posner's theoretical and empirical contributions have been recognized by membership in the American Psychological Association, the Association for Psychological Science, the Society of Experimental Psychologists, the American Academy of Arts and Sciences, the American Association for the Advancement of Science, and the National Academy of Sciences.", "token2charspan": [[0, 6], [6, 8], [9, 20], [21, 24], [25, 34], [35, 48], [49, 53], [54, 58], [59, 69], [70, 72], [73, 83], [84, 86], [87, 90], [91, 99], [100, 113], [114, 125], [125, 126], [127, 130], [131, 142], [143, 146], [147, 160], [161, 168], [168, 169], [170, 173], [174, 181], [182, 184], [185, 197], [198, 211], [211, 212], [213, 216], [217, 225], [226, 233], [234, 236], [237, 241], [242, 245], [246, 254], [254, 255], [256, 259], [260, 268], [269, 280], [281, 284], [285, 288], [289, 300], [301, 303], [304, 311], [311, 312], [313, 316], [317, 320], [321, 329], [330, 337], [338, 340], [341, 349], [349, 350]]}
{"doc_key": "ai-dev-158", "ner": [[2, 3, "product"], [7, 8, "field"], [11, 12, "task"], [16, 16, "task"], [18, 18, "task"], [22, 23, "task"], [25, 25, "task"], [28, 29, "field"], [31, 32, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 3, 7, 8, "usage", "", false, false], [11, 12, 7, 8, "part-of", "", false, false], [16, 16, 7, 8, "part-of", "", false, false], [18, 18, 16, 16, "named", "", false, false], [22, 23, 7, 8, "part-of", "", false, false], [25, 25, 22, 23, "named", "", false, false], [28, 29, 7, 8, "part-of", "", false, false], [31, 32, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["These", "intelligent", "chatbots", "use", "all", "kinds", "of", "artificial", "intelligence", ",", "including", "image", "moderation", "and", "natural", "language", "understanding", "(", "NLU", ")", ",", "natural", "language", "generation", "(", "NLG", ")", ",", "machine", "learning", "and", "deep", "learning", "."], "sentence-detokenized": "These intelligent chatbots use all kinds of artificial intelligence, including image moderation and natural language understanding (NLU), natural language generation (NLG), machine learning and deep learning.", "token2charspan": [[0, 5], [6, 17], [18, 26], [27, 30], [31, 34], [35, 40], [41, 43], [44, 54], [55, 67], [67, 68], [69, 78], [79, 84], [85, 95], [96, 99], [100, 107], [108, 116], [117, 130], [131, 132], [132, 135], [135, 136], [136, 137], [138, 145], [146, 154], [155, 165], [166, 167], [167, 170], [170, 171], [171, 172], [173, 180], [181, 189], [190, 193], [194, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-dev-159", "ner": [[6, 6, "metrics"], [7, 11, "metrics"], [14, 14, "metrics"], [17, 24, "metrics"], [31, 31, "metrics"], [33, 33, "metrics"], [36, 43, "metrics"], [47, 49, "metrics"], [51, 51, "metrics"], [54, 60, "metrics"], [65, 68, "metrics"], [70, 70, "metrics"], [73, 80, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[7, 11, 6, 6, "named", "", false, false], [14, 14, 6, 6, "named", "", false, false], [17, 24, 6, 6, "named", "", false, false], [33, 33, 31, 31, "named", "", false, false], [36, 43, 31, 31, "named", "", false, false], [51, 51, 47, 49, "named", "", false, false], [54, 60, 47, 49, "named", "", false, false], [70, 70, 65, 68, "named", "", false, false], [73, 80, 65, 68, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "ratios", "of", "the", "rows", "are", "the", "positive", "predictive", "value", "(", "PPV", ",", "or", "precision", ")", "(", "TP", "/", "(", "TP", "+", "FP", ")", ")", ",", "complemented", "by", "the", "false", "discovery", "rate", "(", "FDR", ")", "(", "FP", "/", "(", "TP", "+", "FP", ")", ")", ";", "and", "the", "negative", "predictive", "value", "(", "NPV", ")", "(", "TN", "/", "(", "TN", "+", "FN", ")", ")", ",", "complemented", "by", "the", "false", "exclusion", "rate", "(", "FOR", ")", "(", "FN", "/", "(", "TN", "+", "FN", ")", ")", "."], "sentence-detokenized": "The ratios of the rows are the positive predictive value (PPV, or precision) (TP / (TP + FP)), complemented by the false discovery rate (FDR) (FP / (TP + FP)); and the negative predictive value (NPV) (TN / (TN + FN)), complemented by the false exclusion rate (FOR) (FN / (TN + FN)).", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 17], [18, 22], [23, 26], [27, 30], [31, 39], [40, 50], [51, 56], [57, 58], [58, 61], [61, 62], [63, 65], [66, 75], [75, 76], [77, 78], [78, 80], [81, 82], [83, 84], [84, 86], [87, 88], [89, 91], [91, 92], [92, 93], [93, 94], [95, 107], [108, 110], [111, 114], [115, 120], [121, 130], [131, 135], [136, 137], [137, 140], [140, 141], [142, 143], [143, 145], [146, 147], [148, 149], [149, 151], [152, 153], [154, 156], [156, 157], [157, 158], [158, 159], [160, 163], [164, 167], [168, 176], [177, 187], [188, 193], [194, 195], [195, 198], [198, 199], [200, 201], [201, 203], [204, 205], [206, 207], [207, 209], [210, 211], [212, 214], [214, 215], [215, 216], [216, 217], [218, 230], [231, 233], [234, 237], [238, 243], [244, 253], [254, 258], [259, 260], [260, 263], [263, 264], [265, 266], [266, 268], [269, 270], [271, 272], [272, 274], [275, 276], [277, 279], [279, 280], [280, 281], [281, 282]]}
{"doc_key": "ai-dev-160", "ner": [[8, 8, "misc"], [15, 15, "algorithm"], [16, 19, "algorithm"], [24, 24, "algorithm"], [22, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[16, 19, 15, 15, "named", "", false, false], [22, 26, 24, 24, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "data", "is", "a", "mixture", "of", "sitemaps", "and", "RSS", ",", "and", "has", "been", "generated", "using", "an", "information", "model", "(", "IM", ")", "and", "biomedical", "resource", "ontology", "(", "BRO", ")", "."], "sentence-detokenized": "The data is a mixture of sitemaps and RSS, and has been generated using an information model (IM) and biomedical resource ontology (BRO).", "token2charspan": [[0, 3], [4, 8], [9, 11], [12, 13], [14, 21], [22, 24], [25, 33], [34, 37], [38, 41], [41, 42], [43, 46], [47, 50], [51, 55], [56, 65], [66, 71], [72, 74], [75, 86], [87, 92], [93, 94], [94, 96], [96, 97], [98, 101], [102, 112], [113, 121], [122, 130], [131, 132], [132, 135], [135, 136], [136, 137]]}
{"doc_key": "ai-dev-161", "ner": [[1, 2, "task"], [6, 9, "algorithm"], [11, 17, "algorithm"], [23, 25, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 11, 17, "origin", "based_on", false, false], [11, 17, 6, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Recent", "text", "recognition", "is", "based", "on", "a", "recursive", "neural", "network", "(", "long", "-", "term", "short", "-", "term", "memory", ")", "and", "does", "not", "require", "a", "language", "model", "."], "sentence-detokenized": "Recent text recognition is based on a recursive neural network (long-term short-term memory) and does not require a language model.", "token2charspan": [[0, 6], [7, 11], [12, 23], [24, 26], [27, 32], [33, 35], [36, 37], [38, 47], [48, 54], [55, 62], [63, 64], [64, 68], [68, 69], [69, 73], [74, 79], [79, 80], [80, 84], [85, 91], [91, 92], [93, 96], [97, 101], [102, 105], [106, 113], [114, 115], [116, 124], [125, 130], [130, 131]]}
{"doc_key": "ai-dev-162", "ner": [[1, 2, "misc"], [4, 5, "metrics"], [8, 10, "algorithm"], [14, 14, "metrics"], [16, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 1, 2, "type-of", "", false, false], [8, 10, 4, 5, "related-to", "", true, false], [14, 14, 1, 2, "type-of", "", false, false], [16, 18, 14, 14, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Popular", "loss", "functions", "are", "hinge", "loss", "(", "for", "linear", "SVM", "models", ")", "and", "log", "loss", "(", "for", "logistic", "regression", ")", "."], "sentence-detokenized": "Popular loss functions are hinge loss (for linear SVM models) and log loss (for logistic regression).", "token2charspan": [[0, 7], [8, 12], [13, 22], [23, 26], [27, 32], [33, 37], [38, 39], [39, 42], [43, 49], [50, 53], [54, 60], [60, 61], [62, 65], [66, 69], [70, 74], [75, 76], [76, 79], [80, 88], [89, 99], [99, 100], [100, 101]]}
{"doc_key": "ai-dev-163", "ner": [[0, 0, "metrics"], [10, 15, "metrics"], [16, 18, "metrics"], [22, 23, "metrics"], [21, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 10, 15, "compare", "", false, false], [0, 0, 22, 23, "compare", "", false, false], [16, 18, 10, 15, "named", "", false, false], [21, 25, 22, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SSIM", "is", "designed", "to", "improve", "on", "traditional", "methods", "such", "as", "peak", "signal", "-", "to", "-", "noise", "ratio", "(", "PSNR", ")", "and", "mean", "square", "error", "(", "MSE", ")", "."], "sentence-detokenized": "SSIM is designed to improve on traditional methods such as peak signal-to-noise ratio (PSNR) and mean square error (MSE).", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 19], [20, 27], [28, 30], [31, 42], [43, 50], [51, 55], [56, 58], [59, 63], [64, 70], [70, 71], [71, 73], [73, 74], [74, 79], [80, 85], [86, 87], [87, 91], [91, 92], [93, 96], [97, 101], [102, 108], [109, 114], [115, 116], [116, 119], [119, 120], [120, 121]]}
{"doc_key": "ai-dev-164", "ner": [[10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "work", "inspired", "later", "generations", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "His work inspired later generations of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 23], [24, 35], [36, 38], [39, 47], [48, 59], [60, 64], [65, 67], [68, 74], [75, 81], [81, 82], [83, 87], [88, 95], [96, 99], [100, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-dev-165", "ner": [[11, 11, "algorithm"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[19, 20, 11, 11, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "addition", ",", "pulse", "training", "is", "not", "differentiable", ",", "which", "makes", "spinal", "transplantation", "-", "based", "training", "methods", "such", "as", "gradient", "resuscitation", "impossible", "."], "sentence-detokenized": "In addition, pulse training is not differentiable, which makes spinal transplantation-based training methods such as gradient resuscitation impossible.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 18], [19, 27], [28, 30], [31, 34], [35, 49], [49, 50], [51, 56], [57, 62], [63, 69], [70, 85], [85, 86], [86, 91], [92, 100], [101, 108], [109, 113], [114, 116], [117, 125], [126, 139], [140, 150], [150, 151]]}
{"doc_key": "ai-dev-166", "ner": [[6, 9, "metrics"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 9, 15, 17, "related-to", "describes", false, false]], "relations_mapping_to_source": [0], "sentence": ["These", "relationships", "can", "be", "easily", "represented", "by", "a", "mixing", "matrix", ",", "a", "table", "that", "describes", "the", "accuracy", "of", "the", "classification", "model", "."], "sentence-detokenized": "These relationships can be easily represented by a mixing matrix, a table that describes the accuracy of the classification model.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 26], [27, 33], [34, 45], [46, 48], [49, 50], [51, 57], [58, 64], [64, 65], [66, 67], [68, 73], [74, 78], [79, 88], [89, 92], [93, 101], [102, 104], [105, 108], [109, 123], [124, 129], [129, 130]]}
{"doc_key": "ai-dev-167", "ner": [[7, 15, "conference"], [6, 14, "conference"], [0, 0, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 14, 7, 15, "named", "", false, false], [0, 0, 7, 15, "physical", "", false, false], [0, 0, 7, 15, "role", "", false, false], [0, 0, 7, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Google", "researchers", "presented", "their", "work", "at", "the", "2018", "NeurIPS", "(", "Conference", "on", "Neural", "Information", "Processing", "Systems", ")", "."], "sentence-detokenized": "Google researchers presented their work at the 2018 NeurIPS (Conference on Neural Information Processing Systems).", "token2charspan": [[0, 6], [7, 18], [19, 28], [29, 34], [35, 39], [40, 42], [43, 46], [47, 51], [52, 59], [60, 61], [61, 71], [72, 74], [75, 81], [82, 93], [94, 104], [105, 112], [112, 113], [113, 114]]}
{"doc_key": "ai-dev-168", "ner": [[2, 2, "university"], [11, 11, "product"], [17, 19, "misc"], [16, 16, "conference"], [25, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[11, 11, 17, 19, "win-defeat", "", false, false], [17, 19, 16, 16, "temporal", "", false, false], [25, 29, 16, 16, "part-of", "", false, false], [25, 29, 16, 16, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["While", "at", "Duke", ",", "he", "worked", "on", "the", "automatic", "crossword", "puzzle", "PROVERB", ",", "which", "won", "the", "AAAI", "Outstanding", "Paper", "Award", "in", "1999", "and", "competed", "in", "the", "American", "Crossword", "Puzzle", "Tournament", "."], "sentence-detokenized": "While at Duke, he worked on the automatic crossword puzzle PROVERB, which won the AAAI Outstanding Paper Award in 1999 and competed in the American Crossword Puzzle Tournament.", "token2charspan": [[0, 5], [6, 8], [9, 13], [13, 14], [15, 17], [18, 24], [25, 27], [28, 31], [32, 41], [42, 51], [52, 58], [59, 66], [66, 67], [68, 73], [74, 77], [78, 81], [82, 86], [87, 98], [99, 104], [105, 110], [111, 113], [114, 118], [119, 122], [123, 131], [132, 134], [135, 138], [139, 147], [148, 157], [158, 164], [165, 175], [175, 176]]}
{"doc_key": "ai-dev-169", "ner": [[5, 6, "location"], [8, 8, "location"], [17, 17, "country"], [19, 19, "country"], [21, 21, "country"], [23, 23, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 6, 8, 8, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "company", "was", "headquartered", "in", "Rochester", "Hills", ",", "Michigan", ",", "and", "had", "10", "regional", "offices", "in", "the", "US", ",", "Canada", ",", "Mexico", "and", "Brazil", "."], "sentence-detokenized": "The company was headquartered in Rochester Hills, Michigan, and had 10 regional offices in the US, Canada, Mexico and Brazil.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 29], [30, 32], [33, 42], [43, 48], [48, 49], [50, 58], [58, 59], [60, 63], [64, 67], [68, 70], [71, 79], [80, 87], [88, 90], [91, 94], [95, 97], [97, 98], [99, 105], [105, 106], [107, 113], [114, 117], [118, 124], [124, 125]]}
{"doc_key": "ai-dev-170", "ner": [[12, 12, "product"], [14, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "joins", "a", "collection", "of", "historically", "significant", "robots", ",", "including", "the", "early", "Unimate", "and", "Odetics", "Odex", "1", "."], "sentence-detokenized": "It joins a collection of historically significant robots, including the early Unimate and Odetics Odex 1.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 21], [22, 24], [25, 37], [38, 49], [50, 56], [56, 57], [58, 67], [68, 71], [72, 77], [78, 85], [86, 89], [90, 97], [98, 102], [103, 104], [104, 105]]}
{"doc_key": "ai-dev-171", "ner": [[11, 12, "organisation"], [14, 15, "researcher"], [22, 29, "misc"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[14, 15, 11, 12, "physical", "", false, false], [14, 15, 11, 12, "role", "", false, false], [14, 15, 22, 29, "win-defeat", "", false, false]], "relations_mapping_to_source": [2, 3, 4], "sentence": ["The", "guest", "editor", "for", "the", "issue", "is", "David", "'s", "former", "colleague", "at", "NIST", ",", "Judah", "Levine", ",", "the", "latest", "recipient", "of", "the", "I.I.I", ".", "award", ".", "The", "Rabi", "Award", "recipient", "."], "sentence-detokenized": "The guest editor for the issue is David's former colleague at NIST, Judah Levine, the latest recipient of the I.I.I. award. The Rabi Award recipient.", "token2charspan": [[0, 3], [4, 9], [10, 16], [17, 20], [21, 24], [25, 30], [31, 33], [34, 39], [39, 41], [42, 48], [49, 58], [59, 61], [62, 66], [66, 67], [68, 73], [74, 80], [80, 81], [82, 85], [86, 92], [93, 102], [103, 105], [106, 109], [110, 115], [115, 116], [117, 122], [122, 123], [124, 127], [128, 132], [133, 138], [139, 148], [148, 149]]}
{"doc_key": "ai-dev-172", "ner": [[12, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "can", "be", "arranged", "in", "a", "2", "\u00d7", "2", "contingency", "table", "(", "mixing", "matrix", ")", ",", "where", "the", "test", "result", "is", "usually", "on", "the", "vertical", "axis", "and", "the", "actual", "state", "on", "the", "horizontal", "axis", "."], "sentence-detokenized": "These can be arranged in a 2 \u00d7 2 contingency table (mixing matrix), where the test result is usually on the vertical axis and the actual state on the horizontal axis.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 21], [22, 24], [25, 26], [27, 28], [29, 30], [31, 32], [33, 44], [45, 50], [51, 52], [52, 58], [59, 65], [65, 66], [66, 67], [68, 73], [74, 77], [78, 82], [83, 89], [90, 92], [93, 100], [101, 103], [104, 107], [108, 116], [117, 121], [122, 125], [126, 129], [130, 136], [137, 142], [143, 145], [146, 149], [150, 160], [161, 165], [165, 166]]}
{"doc_key": "ai-dev-173", "ner": [[0, 4, "product"], [8, 8, "product"], [10, 10, "product"], [12, 13, "product"], [16, 18, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 8, 8, "part-of", "", false, false], [0, 4, 10, 10, "part-of", "", false, false], [0, 4, 12, 13, "part-of", "", false, false], [0, 4, 16, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Apple", "'s", "iOS", "operating", "system", ",", "used", "on", "iPhone", ",", "iPad", "and", "iPod", "Touch", ",", "uses", "VoiceOver", "speech", "synthesis", "."], "sentence-detokenized": "Apple's iOS operating system, used on iPhone, iPad and iPod Touch, uses VoiceOver speech synthesis.", "token2charspan": [[0, 5], [5, 7], [8, 11], [12, 21], [22, 28], [28, 29], [30, 34], [35, 37], [38, 44], [44, 45], [46, 50], [51, 54], [55, 59], [60, 65], [65, 66], [67, 71], [72, 81], [82, 88], [89, 98], [98, 99]]}
{"doc_key": "ai-dev-174", "ner": [[7, 11, "conference"], [14, 17, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "the", "best", "system", "feeding", "the", "MUC", "-", "7", "system", "received", "an", "F", "-", "measure", "of", "93.39", "%", ",", "while", "the", "human", "feeders", "received", "97.6", "%", "and", "96.95", "%", "."], "sentence-detokenized": "For example, the best system feeding the MUC-7 system received an F-measure of 93.39%, while the human feeders received 97.6% and 96.95%.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 36], [37, 40], [41, 44], [44, 45], [45, 46], [47, 53], [54, 62], [63, 65], [66, 67], [67, 68], [68, 75], [76, 78], [79, 84], [84, 85], [85, 86], [87, 92], [93, 96], [97, 102], [103, 110], [111, 119], [120, 124], [124, 125], [126, 129], [130, 135], [135, 136], [136, 137]]}
{"doc_key": "ai-dev-175", "ner": [[11, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 15, 11, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "is", "done", "using", "standard", "neural", "network", "training", "algorithms", "such", "as", "stochastic", "gradient", "descent", "and", "backpropagation", "."], "sentence-detokenized": "This is done using standard neural network training algorithms such as stochastic gradient descent and backpropagation.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 18], [19, 27], [28, 34], [35, 42], [43, 51], [52, 62], [63, 67], [68, 70], [71, 81], [82, 90], [91, 98], [99, 102], [103, 118], [118, 119]]}
{"doc_key": "ai-dev-176", "ner": [[0, 1, "organisation"], [15, 16, "country"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 15, 16, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Rotten", "Tomatoes", "is", "a", "Top", "1000", "site", ",", "ranked", "around", "400th", "worldwide", "and", "150th", "in", "the", "US", "alone", ",", "according", "to", "Alexa", "."], "sentence-detokenized": "Rotten Tomatoes is a Top 1000 site, ranked around 400th worldwide and 150th in the US alone, according to Alexa.", "token2charspan": [[0, 6], [7, 15], [16, 18], [19, 20], [21, 24], [25, 29], [30, 34], [34, 35], [36, 42], [43, 49], [50, 55], [56, 65], [66, 69], [70, 75], [76, 78], [79, 82], [83, 85], [86, 91], [91, 92], [93, 102], [103, 105], [106, 111], [111, 112]]}
{"doc_key": "ai-dev-177", "ner": [[17, 19, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "general", ",", "all", "learning", "shows", "a", "gradual", "change", "over", "time", ",", "but", "it", "is", "illustrated", "by", "the", "sigmoid", "function", ",", "which", "looks", "different", "depending", "on", "the", "time", "scale", "of", "the", "observation", "."], "sentence-detokenized": "In general, all learning shows a gradual change over time, but it is illustrated by the sigmoid function, which looks different depending on the time scale of the observation.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 24], [25, 30], [31, 32], [33, 40], [41, 47], [48, 52], [53, 57], [57, 58], [59, 62], [63, 65], [66, 68], [69, 80], [81, 83], [84, 87], [88, 95], [96, 104], [104, 105], [106, 111], [112, 117], [118, 127], [128, 137], [138, 140], [141, 144], [145, 149], [150, 155], [156, 158], [159, 162], [163, 174], [174, 175]]}
{"doc_key": "ai-dev-178", "ner": [[0, 1, "metrics"], [5, 7, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 5, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["SSD", "is", "also", "known", "as", "mean", "square", "error", "."], "sentence-detokenized": "SSD is also known as mean square error.", "token2charspan": [[0, 3], [4, 6], [7, 11], [12, 17], [18, 20], [21, 25], [26, 32], [33, 38], [38, 39]]}
{"doc_key": "ai-dev-179", "ner": [[0, 2, "algorithm"], [4, 5, "algorithm"], [7, 9, "algorithm"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 22, 23, "related-to", "can_be_related_to", true, false], [4, 5, 22, 23, "related-to", "can_be_related_to", true, false], [7, 9, 22, 23, "related-to", "can_be_related_to", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", ",", "neural", "networks", "or", "na\u00efve", "Bayesian", "classifiers", "could", "be", "used", "in", "combination", "with", "measures", "of", "model", "quality", "such", "as", "balanced", "accuracy", "."], "sentence-detokenized": "Decision tree learning, neural networks or na\u00efve Bayesian classifiers could be used in combination with measures of model quality such as balanced accuracy.", "token2charspan": [[0, 8], [9, 13], [14, 22], [22, 23], [24, 30], [31, 39], [40, 42], [43, 48], [49, 57], [58, 69], [70, 75], [76, 78], [79, 83], [84, 86], [87, 98], [99, 103], [104, 112], [113, 115], [116, 121], [122, 129], [130, 134], [135, 137], [138, 146], [147, 155], [155, 156]]}
{"doc_key": "ai-dev-180", "ner": [[14, 14, "conference"], [20, 24, "conference"], [25, 27, "misc"], [32, 35, "product"], [41, 45, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[25, 27, 20, 24, "origin", "", false, false], [25, 27, 20, 24, "temporal", "", false, false], [32, 35, 25, 27, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "is", "a", "past", "president", "(", "1979", ")", "and", "Fellow", "(", "2011", ")", "of", "ACL", ",", "a", "co-recipient", "of", "the", "1992", "Association", "for", "Computing", "Machinery", "Software", "Systems", "Award", "for", "the", "development", "of", "the", "Interlisp", "programming", "system", ",", "and", "a", "Fellow", "of", "the", "Association", "for", "Computing", "Machinery", "."], "sentence-detokenized": "He is a past president (1979) and Fellow (2011) of ACL, a co-recipient of the 1992 Association for Computing Machinery Software Systems Award for the development of the Interlisp programming system, and a Fellow of the Association for Computing Machinery.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 22], [23, 24], [24, 28], [28, 29], [30, 33], [34, 40], [41, 42], [42, 46], [46, 47], [48, 50], [51, 54], [54, 55], [56, 57], [58, 70], [71, 73], [74, 77], [78, 82], [83, 94], [95, 98], [99, 108], [109, 118], [119, 127], [128, 135], [136, 141], [142, 145], [146, 149], [150, 161], [162, 164], [165, 168], [169, 178], [179, 190], [191, 197], [197, 198], [199, 202], [203, 204], [205, 211], [212, 214], [215, 218], [219, 230], [231, 234], [235, 244], [245, 254], [254, 255]]}
{"doc_key": "ai-dev-181", "ner": [[7, 8, "researcher"], [10, 13, "researcher"], [3, 3, "researcher"], [0, 2, "researcher"], [26, 29, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[7, 8, 26, 29, "related-to", "", false, false], [10, 13, 26, 29, "related-to", "", false, false], [3, 3, 26, 29, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Cade", "Metz", "considers", "Bengio", ",", "along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "to", "be", "one", "of", "the", "three", "people", "most", "responsible", "for", "the", "advances", "in", "deep", "learning", "in", "the", "1990s", "and", "2000s", "."], "sentence-detokenized": "Cade Metz considers Bengio, along with Geoffrey Hinton and Yann LeCun, to be one of the three people most responsible for the advances in deep learning in the 1990s and 2000s.", "token2charspan": [[0, 4], [5, 9], [10, 19], [20, 26], [26, 27], [28, 33], [34, 38], [39, 47], [48, 54], [55, 58], [59, 63], [64, 69], [69, 70], [71, 73], [74, 76], [77, 80], [81, 83], [84, 87], [88, 93], [94, 100], [101, 105], [106, 117], [118, 121], [122, 125], [126, 134], [135, 137], [138, 142], [143, 151], [152, 154], [155, 158], [159, 164], [165, 168], [169, 174], [174, 175]]}
{"doc_key": "ai-dev-182", "ner": [[0, 2, "field"], [4, 5, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "information", "theory", "and", "computer", "science", ",", "code", "is", "generally", "considered", "to", "be", "an", "algorithm", "that", "uniquely", "represents", "symbols", "from", "one", "source", "alphabet", "by", "encoded", "strings", "that", "may", "be", "in", "another", "target", "alphabet", "."], "sentence-detokenized": "In information theory and computer science, code is generally considered to be an algorithm that uniquely represents symbols from one source alphabet by encoded strings that may be in another target alphabet.", "token2charspan": [[0, 2], [3, 14], [15, 21], [22, 25], [26, 34], [35, 42], [42, 43], [44, 48], [49, 51], [52, 61], [62, 72], [73, 75], [76, 78], [79, 81], [82, 91], [92, 96], [97, 105], [106, 116], [117, 124], [125, 129], [130, 133], [134, 140], [141, 149], [150, 152], [153, 160], [161, 168], [169, 173], [174, 177], [178, 180], [181, 183], [184, 191], [192, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-dev-183", "ner": [[8, 9, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 8, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "fairly", "simple", "non", "-linear", "function", ",", "a", "sigmoid", "function", "such", "as", "a", "logistic", "function", ",", "also", "has", "an", "easily", "computable", "derivative", ",", "which", "can", "be", "important", "when", "calculating", "weight", "updates", "online", "."], "sentence-detokenized": "A fairly simple non-linear function, a sigmoid function such as a logistic function, also has an easily computable derivative, which can be important when calculating weight updates online.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 19], [19, 26], [27, 35], [35, 36], [37, 38], [39, 46], [47, 55], [56, 60], [61, 63], [64, 65], [66, 74], [75, 83], [83, 84], [85, 89], [90, 93], [94, 96], [97, 103], [104, 114], [115, 125], [125, 126], [127, 132], [133, 136], [137, 139], [140, 149], [150, 154], [155, 166], [167, 173], [174, 181], [182, 188], [188, 189]]}
{"doc_key": "ai-dev-184", "ner": [[0, 0, "person"], [4, 4, "location"], [6, 6, "location"], [8, 10, "country"], [13, 13, "country"], [17, 18, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 4, 4, "physical", "", false, false], [4, 4, 6, 6, "physical", "", false, false], [6, 6, 8, 10, "physical", "", false, false], [6, 6, 13, 13, "physical", "", false, false], [6, 6, 17, 18, "physical", "", false, false], [13, 13, 8, 10, "origin", "", false, false], [17, 18, 13, 13, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["\u010capek", "was", "born", "in", "Hronov", ",", "Bohemia", "(", "Austria", "-", "Hungary", ",", "later", "Czechoslovakia", ",", "now", "the", "Czech", "Republic", ")", "in", "1887", "."], "sentence-detokenized": "\u010capek was born in Hronov, Bohemia (Austria-Hungary, later Czechoslovakia, now the Czech Republic) in 1887.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 17], [18, 24], [24, 25], [26, 33], [34, 35], [35, 42], [42, 43], [43, 50], [50, 51], [52, 57], [58, 72], [72, 73], [74, 77], [78, 81], [82, 87], [88, 96], [96, 97], [98, 100], [101, 105], [105, 106]]}
{"doc_key": "ai-dev-185", "ner": [[7, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "specialised", "software", "can", "tell", "you", "about", "RSS", "."], "sentence-detokenized": "Some specialised software can tell you about RSS.", "token2charspan": [[0, 4], [5, 16], [17, 25], [26, 29], [30, 34], [35, 38], [39, 44], [45, 48], [48, 49]]}
{"doc_key": "ai-dev-186", "ner": [[6, 6, "task"], [9, 12, "task"], [17, 17, "task"], [19, 21, "task"], [28, 30, "task"], [32, 33, "task"], [38, 39, "task"], [42, 44, "product"], [46, 47, "product"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8, 9], "relations": [[6, 6, 9, 12, "related-to", "", true, false], [6, 6, 17, 17, "related-to", "", true, false], [32, 33, 28, 30, "usage", "", true, false], [42, 44, 38, 39, "type-of", "", false, false], [46, 47, 38, 39, "type-of", "", false, false]], "relations_mapping_to_source": [0, 2, 3, 4, 5], "sentence": ["Aspects", "of", "ontology", "editors", "include", ":", "visual", "navigation", "capabilities", "in", "the", "knowledge", "model", ",", "inference", "engines", "and", "extraction", ",", "support", "for", "modules", ",", "import", "and", "export", "of", "foreign", "knowledge", "representation", "languages", "for", "ontology", "matching", ",", "and", "support", "for", "meta", "ontologies", "such", "as", "OWL", "-", "S", ",", "Dublin", "Core", ",", "etc", "."], "sentence-detokenized": "Aspects of ontology editors include: visual navigation capabilities in the knowledge model, inference engines and extraction, support for modules, import and export of foreign knowledge representation languages for ontology matching, and support for meta ontologies such as OWL-S, Dublin Core, etc.", "token2charspan": [[0, 7], [8, 10], [11, 19], [20, 27], [28, 35], [35, 36], [37, 43], [44, 54], [55, 67], [68, 70], [71, 74], [75, 84], [85, 90], [90, 91], [92, 101], [102, 109], [110, 113], [114, 124], [124, 125], [126, 133], [134, 137], [138, 145], [145, 146], [147, 153], [154, 157], [158, 164], [165, 167], [168, 175], [176, 185], [186, 200], [201, 210], [211, 214], [215, 223], [224, 232], [232, 233], [234, 237], [238, 245], [246, 249], [250, 254], [255, 265], [266, 270], [271, 273], [274, 277], [277, 278], [278, 279], [279, 280], [281, 287], [288, 292], [292, 293], [294, 297], [297, 298]]}
{"doc_key": "ai-dev-187", "ner": [[0, 1, "organisation"], [5, 10, "misc"], [14, 15, "task"], [21, 22, "field"], [25, 25, "misc"], [27, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 10, 0, 1, "origin", "", false, false], [14, 15, 5, 10, "part-of", "", false, false], [21, 22, 5, 10, "part-of", "", false, false], [25, 25, 21, 22, "type-of", "", false, false], [27, 29, 21, 22, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "FBI", "has", "also", "launched", "its", "next", "-", "generation", "identification", "programme", ",", "which", "includes", "facial", "recognition", "as", "well", "as", "more", "traditional", "biometric", "identifiers", "such", "as", "fingerprints", "and", "iris", "scans", "that", "can", "be", "extracted", "from", "both", "criminal", "and", "civil", "databases", "."], "sentence-detokenized": "The FBI has also launched its next-generation identification programme, which includes facial recognition as well as more traditional biometric identifiers such as fingerprints and iris scans that can be extracted from both criminal and civil databases.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 16], [17, 25], [26, 29], [30, 34], [34, 35], [35, 45], [46, 60], [61, 70], [70, 71], [72, 77], [78, 86], [87, 93], [94, 105], [106, 108], [109, 113], [114, 116], [117, 121], [122, 133], [134, 143], [144, 155], [156, 160], [161, 163], [164, 176], [177, 180], [181, 185], [186, 191], [192, 196], [197, 200], [201, 203], [204, 213], [214, 218], [219, 223], [224, 232], [233, 236], [237, 242], [243, 252], [252, 253]]}
{"doc_key": "ai-dev-188", "ner": [[3, 4, "person"], [11, 12, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2016", ",", "Samantha", "Ponder", "was", "added", "as", "presenter", "to", "replace", "Molly", "McGrath", "."], "sentence-detokenized": "In 2016, Samantha Ponder was added as presenter to replace Molly McGrath.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 17], [18, 24], [25, 28], [29, 34], [35, 37], [38, 47], [48, 50], [51, 58], [59, 64], [65, 72], [72, 73]]}
{"doc_key": "ai-dev-189", "ner": [[3, 6, "algorithm"], [18, 22, "misc"], [24, 24, "misc"], [26, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "a", "counter", "-", "matching", "algorithm", "commonly", "used", "for", "machine", "play", "of", "two", "-", "player", "games", "(", "Tic", "-", "tac", "-", "toe", ",", "chess", ",", "Go", ",", "etc.", ")", "."], "sentence-detokenized": "This is a counter-matching algorithm commonly used for machine play of two-player games (Tic-tac-toe, chess, Go, etc.).", "token2charspan": [[0, 4], [5, 7], [8, 9], [10, 17], [17, 18], [18, 26], [27, 36], [37, 45], [46, 50], [51, 54], [55, 62], [63, 67], [68, 70], [71, 74], [74, 75], [75, 81], [82, 87], [88, 89], [89, 92], [92, 93], [93, 96], [96, 97], [97, 100], [100, 101], [102, 107], [107, 108], [109, 111], [111, 112], [113, 117], [117, 118], [118, 119]]}
{"doc_key": "ai-dev-190", "ner": [[7, 8, "field"], [10, 11, "field"], [13, 14, "field"], [21, 22, "field"], [24, 25, "field"], [27, 28, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "related", "to", "the", "fields", "of", "computer", "vision", "or", "machine", "vision", "and", "medical", "imaging", ",", "and", "makes", "extensive", "use", "of", "image", "recognition", ",", "digital", "geometry", "and", "signal", "processing", "."], "sentence-detokenized": "It is related to the fields of computer vision or machine vision and medical imaging, and makes extensive use of image recognition, digital geometry and signal processing.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 20], [21, 27], [28, 30], [31, 39], [40, 46], [47, 49], [50, 57], [58, 64], [65, 68], [69, 76], [77, 84], [84, 85], [86, 89], [90, 95], [96, 105], [106, 109], [110, 112], [113, 118], [119, 130], [130, 131], [132, 139], [140, 148], [149, 152], [153, 159], [160, 170], [170, 171]]}
{"doc_key": "ai-dev-191", "ner": [[0, 9, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "in", "a", "face", "recognition", "system", ",", "the", "input", "is", "an", "image", "of", "a", "person", "'s", "face", ",", "and", "the", "output", "tag", "is", "the", "person", "'s", "name", "."], "sentence-detokenized": "For example, in a face recognition system, the input is an image of a person's face, and the output tag is the person's name.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 15], [16, 17], [18, 22], [23, 34], [35, 41], [41, 42], [43, 46], [47, 52], [53, 55], [56, 58], [59, 64], [65, 67], [68, 69], [70, 76], [76, 78], [79, 83], [83, 84], [85, 88], [89, 92], [93, 99], [100, 103], [104, 106], [107, 110], [111, 117], [117, 119], [120, 124], [124, 125]]}
{"doc_key": "ai-dev-192", "ner": [[0, 1, "organisation"], [3, 4, "product"], [8, 10, "product"], [19, 20, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 3, 4, "artifact", "", false, false], [3, 4, 8, 10, "part-of", "", false, false], [8, 10, 3, 4, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Apple", "Inc", "introduced", "Face", "ID", "in", "the", "flagship", "i", "Phone", "X", "as", "the", "successor", "to", "the", "fingerprint", "-", "based", "Touch", "ID", "system", "."], "sentence-detokenized": "Apple Inc introduced Face ID in the flagship iPhone X as the successor to the fingerprint-based Touch ID system.", "token2charspan": [[0, 5], [6, 9], [10, 20], [21, 25], [26, 28], [29, 31], [32, 35], [36, 44], [45, 46], [46, 51], [52, 53], [54, 56], [57, 60], [61, 70], [71, 73], [74, 77], [78, 89], [89, 90], [90, 95], [96, 101], [102, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-dev-193", "ner": [[3, 5, "metrics"], [8, 9, "metrics"], [24, 27, "metrics"], [30, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Or", "combining", "the", "F", "-", "measure", "with", "the", "R-", "square", "estimated", "for", "the", "raw", "output", "of", "the", "model", "and", "the", "target", ",", "or", "the", "cost", "/", "benefit", "matrix", "with", "the", "correlation", "coefficient", ",", "and", "so", "on", "."], "sentence-detokenized": "Or combining the F-measure with the R-square estimated for the raw output of the model and the target, or the cost/benefit matrix with the correlation coefficient, and so on.", "token2charspan": [[0, 2], [3, 12], [13, 16], [17, 18], [18, 19], [19, 26], [27, 31], [32, 35], [36, 38], [38, 44], [45, 54], [55, 58], [59, 62], [63, 66], [67, 73], [74, 76], [77, 80], [81, 86], [87, 90], [91, 94], [95, 101], [101, 102], [103, 105], [106, 109], [110, 114], [114, 115], [115, 122], [123, 129], [130, 134], [135, 138], [139, 150], [151, 162], [162, 163], [164, 167], [168, 170], [171, 173], [173, 174]]}
{"doc_key": "ai-dev-194", "ner": [[0, 7, "conference"], [8, 12, "location"], [14, 14, "location"], [17, 20, "location"], [21, 22, "location"], [24, 24, "country"], [29, 33, "location"], [37, 43, "location"], [36, 36, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 7, 8, 12, "physical", "", false, false], [0, 7, 17, 20, "physical", "", false, false], [0, 7, 29, 33, "physical", "", false, false], [0, 7, 37, 43, "physical", "", false, false], [8, 12, 14, 14, "physical", "", false, false], [17, 20, 21, 22, "physical", "", false, false], [21, 22, 24, 24, "physical", "", false, false], [29, 33, 36, 36, "physical", "", false, false], [37, 43, 36, 36, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "Campus", "Party", "has", "been", "held", "in", "Spain", "at", "the", "Colegio", "Miguel", "Hern\u00e1ndez", ",", "Ceulaj", "and", "the", "Benalm\u00e1dena", "Municipal", "Sports", "Arena", "in", "M\u00e1laga", ",", "Spain", ",", "as", "well", "as", "at", "the", "Valencia", "Provincial", "Fair", "and", "the", "Valencia", "City", "of", "Arts", "and", "Sciences", "over", "the", "past", "15", "years", "."], "sentence-detokenized": "The Campus Party has been held in Spain at the Colegio Miguel Hern\u00e1ndez, Ceulaj and the Benalm\u00e1dena Municipal Sports Arena in M\u00e1laga, Spain, as well as at the Valencia Provincial Fair and the Valencia City of Arts and Sciences over the past 15 years.", "token2charspan": [[0, 3], [4, 10], [11, 16], [17, 20], [21, 25], [26, 30], [31, 33], [34, 39], [40, 42], [43, 46], [47, 54], [55, 61], [62, 71], [71, 72], [73, 79], [80, 83], [84, 87], [88, 99], [100, 109], [110, 116], [117, 122], [123, 125], [126, 132], [132, 133], [134, 139], [139, 140], [141, 143], [144, 148], [149, 151], [152, 154], [155, 158], [159, 167], [168, 178], [179, 183], [184, 187], [188, 191], [192, 200], [201, 205], [206, 208], [209, 213], [214, 217], [218, 226], [227, 231], [232, 235], [236, 240], [241, 243], [244, 249], [249, 250]]}
{"doc_key": "ai-dev-195", "ner": [[0, 0, "product"], [13, 13, "programlang"], [16, 16, "product"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[13, 13, 0, 0, "general-affiliation", "", false, false], [16, 16, 13, 13, "part-of", "", false, false], [22, 22, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 3], "sentence": ["gnuplot", "can", "be", "used", "with", "various", "programming", "languages", "to", "describe", "data", ",", "including", "Perl", "(", "via", "PDL", "and", "CPAN", "packages", ")", ",", "Python", "(", "via", ")", "."], "sentence-detokenized": "gnuplot can be used with various programming languages to describe data, including Perl (via PDL and CPAN packages), Python (via).", "token2charspan": [[0, 7], [8, 11], [12, 14], [15, 19], [20, 24], [25, 32], [33, 44], [45, 54], [55, 57], [58, 66], [67, 71], [71, 72], [73, 82], [83, 87], [88, 89], [89, 92], [93, 96], [97, 100], [101, 105], [106, 114], [114, 115], [115, 116], [117, 123], [124, 125], [125, 128], [128, 129], [129, 130]]}
{"doc_key": "ai-dev-196", "ner": [[3, 5, "product"], [20, 20, "conference"], [22, 22, "conference"], [37, 37, "conference"], [39, 39, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[20, 20, 3, 5, "topic", "", false, false], [22, 22, 3, 5, "topic", "", false, false], [37, 37, 3, 5, "topic", "", false, false], [39, 39, 3, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "field", "of", "spoken", "dialogue", "systems", "is", "quite", "broad", ",", "encompassing", "both", "research", "(", "presented", "at", "scientific", "conferences", "such", "as", "SIGdial", "and", "Interspeech", ")", "and", "the", "broad", "industrial", "sector", "(", "which", "has", "its", "own", "conferences", "such", "as", "SpeechTek", "and", "AVIOS", ")", "."], "sentence-detokenized": "The field of spoken dialogue systems is quite broad, encompassing both research (presented at scientific conferences such as SIGdial and Interspeech) and the broad industrial sector (which has its own conferences such as SpeechTek and AVIOS).", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 28], [29, 36], [37, 39], [40, 45], [46, 51], [51, 52], [53, 65], [66, 70], [71, 79], [80, 81], [81, 90], [91, 93], [94, 104], [105, 116], [117, 121], [122, 124], [125, 132], [133, 136], [137, 148], [148, 149], [150, 153], [154, 157], [158, 163], [164, 174], [175, 181], [182, 183], [183, 188], [189, 192], [193, 196], [197, 200], [201, 212], [213, 217], [218, 220], [221, 230], [231, 234], [235, 240], [240, 241], [241, 242]]}
{"doc_key": "ai-dev-197", "ner": [[3, 6, "field"], [10, 11, "task"], [13, 15, "task"], [17, 19, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 11, 3, 6, "part-of", "task_part_of_field", false, false], [13, 15, 3, 6, "part-of", "task_part_of_field", false, false], [17, 19, 3, 6, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "challenges", "of", "natural", "language", "processing", "are", "often", "related", "to", "speech", "recognition", ",", "natural", "language", "understanding", "and", "natural", "language", "production", "."], "sentence-detokenized": "The challenges of natural language processing are often related to speech recognition, natural language understanding and natural language production.", "token2charspan": [[0, 3], [4, 14], [15, 17], [18, 25], [26, 34], [35, 45], [46, 49], [50, 55], [56, 63], [64, 66], [67, 73], [74, 85], [85, 86], [87, 94], [95, 103], [104, 117], [118, 121], [122, 129], [130, 138], [139, 149], [149, 150]]}
{"doc_key": "ai-dev-198", "ner": [[5, 5, "product"], [5, 9, "product"], [31, 32, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 5, 9, "part-of", "", false, false], [5, 5, 31, 32, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "such", "as", "Siri", "on", "iOS", ",", "use", "a", "similar", "pattern", "recognition", "technology", "to", "text", "-", "based", "systems", ",", "but", "in", "the", "former", ",", "user", "input", "is", "provided", "by", "speech", "recognition", "."], "sentence-detokenized": "These systems, such as Siri on iOS, use a similar pattern recognition technology to text-based systems, but in the former, user input is provided by speech recognition.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 22], [23, 27], [28, 30], [31, 34], [34, 35], [36, 39], [40, 41], [42, 49], [50, 57], [58, 69], [70, 80], [81, 83], [84, 88], [88, 89], [89, 94], [95, 102], [102, 103], [104, 107], [108, 110], [111, 114], [115, 121], [121, 122], [123, 127], [128, 133], [134, 136], [137, 145], [146, 148], [149, 155], [156, 167], [167, 168]]}
{"doc_key": "ai-dev-199", "ner": [[0, 7, "algorithm"], [20, 21, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 7, 20, 21, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["More", "exotic", "goodness", "-", "of", "-", "fit", "functions", "to", "examine", "the", "granularity", "of", "the", "model", "are", "the", "area", "under", "the", "ROC", "curve", "and", "the", "rank", "measure", "."], "sentence-detokenized": "More exotic goodness-of-fit functions to examine the granularity of the model are the area under the ROC curve and the rank measure.", "token2charspan": [[0, 4], [5, 11], [12, 20], [20, 21], [21, 23], [23, 24], [24, 27], [28, 37], [38, 40], [41, 48], [49, 52], [53, 64], [65, 67], [68, 71], [72, 77], [78, 81], [82, 85], [86, 90], [91, 96], [97, 100], [101, 104], [105, 110], [111, 114], [115, 118], [119, 123], [124, 131], [131, 132]]}
{"doc_key": "ai-dev-200", "ner": [[2, 3, "product"], [7, 10, "researcher"], [14, 17, "product"], [23, 25, "organisation"], [22, 27, "organisation"], [36, 38, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 7, 10, "origin", "", false, false], [7, 10, 23, 25, "role", "", false, false], [14, 17, 7, 10, "origin", "", false, false], [22, 27, 23, 25, "named", "", false, false], [36, 38, 23, 25, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "term", "semantic", "web", "was", "coined", "by", "Tim", "Berners", "-", "Lee", ",", "inventor", "of", "the", "World", "Wide", "Web", "and", "head", "of", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "which", "oversees", "the", "development", "of", "proposed", "semantic", "web", "standards", "."], "sentence-detokenized": "The term semantic web was coined by Tim Berners-Lee, inventor of the World Wide Web and head of the World Wide Web Consortium (W3C), which oversees the development of proposed semantic web standards.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 25], [26, 32], [33, 35], [36, 39], [40, 47], [47, 48], [48, 51], [51, 52], [53, 61], [62, 64], [65, 68], [69, 74], [75, 79], [80, 83], [84, 87], [88, 92], [93, 95], [96, 99], [100, 105], [106, 110], [111, 114], [115, 125], [126, 127], [127, 130], [130, 131], [131, 132], [133, 138], [139, 147], [148, 151], [152, 163], [164, 166], [167, 175], [176, 184], [185, 188], [189, 198], [198, 199]]}
{"doc_key": "ai-dev-201", "ner": [[0, 1, "task"], [7, 7, "task"], [14, 17, "product"], [21, 22, "product"], [19, 24, "product"], [27, 28, "product"], [35, 36, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 14, 17, "opposite", "", false, false], [0, 1, 21, 22, "opposite", "", false, false], [0, 1, 27, 28, "opposite", "", false, false], [0, 1, 35, 36, "part-of", "", false, false], [7, 7, 0, 1, "named", "", false, false], [19, 24, 21, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Machine", "translation", ",", "sometimes", "referred", "to", "as", "MT", "(", "not", "to", "be", "confused", "with", "computer", "-", "aided", "translation", ",", "machine", "-", "aided", "translation", "(", "MAHT", ")", "or", "interactive", "translation", ")", ",", "is", "a", "branch", "of", "computational", "linguistics", "that", "studies", "the", "use", "of", "software", "to", "translate", "text", "or", "speech", "from", "one", "language", "into", "another", "."], "sentence-detokenized": "Machine translation, sometimes referred to as MT (not to be confused with computer-aided translation, machine-aided translation (MAHT) or interactive translation), is a branch of computational linguistics that studies the use of software to translate text or speech from one language into another.", "token2charspan": [[0, 7], [8, 19], [19, 20], [21, 30], [31, 39], [40, 42], [43, 45], [46, 48], [49, 50], [50, 53], [54, 56], [57, 59], [60, 68], [69, 73], [74, 82], [82, 83], [83, 88], [89, 100], [100, 101], [102, 109], [109, 110], [110, 115], [116, 127], [128, 129], [129, 133], [133, 134], [135, 137], [138, 149], [150, 161], [161, 162], [162, 163], [164, 166], [167, 168], [169, 175], [176, 178], [179, 192], [193, 204], [205, 209], [210, 217], [218, 221], [222, 225], [226, 228], [229, 237], [238, 240], [241, 250], [251, 255], [256, 258], [259, 265], [266, 270], [271, 274], [275, 283], [284, 288], [289, 296], [296, 297]]}
{"doc_key": "ai-dev-202", "ner": [[1, 4, "product"], [11, 13, "university"], [14, 15, "researcher"], [17, 18, "researcher"], [39, 43, "location"], [41, 41, "location"], [47, 52, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 4, 14, 15, "artifact", "", false, false], [1, 4, 17, 18, "artifact", "", false, false], [14, 15, 11, 13, "physical", "", false, false], [14, 15, 11, 13, "role", "", false, false], [17, 18, 11, 13, "physical", "", false, false], [17, 18, 11, 13, "role", "", false, false], [39, 43, 41, 41, "physical", "", false, false], [47, 52, 39, 43, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Early", "cross", "-language", "MT", "systems", "were", "also", "built", "in", "the", "1970s", "at", "Stanford", "by", "Roger", "Schank", "and", "Yorick", "Wilks", ";", "the", "former", "became", "the", "basis", "of", "a", "commercial", "money", "transfer", "system", ",", "and", "the", "latter", "'s", "code", "is", "preserved", "at", "the", "Boston", "Computer", "Museum", "as", "the", "first", "cross", "-", "language", "machine", "translation", "system", "."], "sentence-detokenized": "Early cross-language MT systems were also built in the 1970s at Stanford by Roger Schank and Yorick Wilks; the former became the basis of a commercial money transfer system, and the latter's code is preserved at the Boston Computer Museum as the first cross-language machine translation system.", "token2charspan": [[0, 5], [6, 11], [11, 20], [21, 23], [24, 31], [32, 36], [37, 41], [42, 47], [48, 50], [51, 54], [55, 60], [61, 63], [64, 72], [73, 75], [76, 81], [82, 88], [89, 92], [93, 99], [100, 105], [105, 106], [107, 110], [111, 117], [118, 124], [125, 128], [129, 134], [135, 137], [138, 139], [140, 150], [151, 156], [157, 165], [166, 172], [172, 173], [174, 177], [178, 181], [182, 188], [188, 190], [191, 195], [196, 198], [199, 208], [209, 211], [212, 215], [216, 222], [223, 231], [232, 238], [239, 241], [242, 245], [246, 251], [252, 257], [257, 258], [258, 266], [267, 274], [275, 286], [287, 293], [293, 294]]}
{"doc_key": "ai-dev-203", "ner": [[0, 2, "researcher"], [7, 11, "conference"], [8, 14, "conference"], [21, 26, "conference"], [28, 29, "conference"], [35, 40, "organisation"], [48, 48, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 7, 11, "role", "", false, false], [0, 2, 21, 26, "role", "", false, false], [0, 2, 35, 40, "role", "", false, false], [0, 2, 48, 48, "role", "", false, false], [8, 14, 7, 11, "named", "", false, false], [28, 29, 21, 26, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sycara", "served", "as", "Program", "Chair", "of", "the", "Second", "International", "Semantic", "Web", "Conference", "(", "ISWC", "2003", ")", ",", "General", "Chair", "of", "the", "Second", "International", "Conference", "on", "Autonomous", "Agents", "(", "Agents", "98", ")", ",", "Chair", "of", "the", "Steering", "Committee", "of", "the", "Agents", "Conference", "(", "1999-2001", ")", "and", "Chair", "of", "the", "AAAI", "Fellowship", "(", "1993-1999", ")", ";"], "sentence-detokenized": "Sycara served as Program Chair of the Second International Semantic Web Conference (ISWC 2003), General Chair of the Second International Conference on Autonomous Agents (Agents 98), Chair of the Steering Committee of the Agents Conference (1999-2001) and Chair of the AAAI Fellowship (1993-1999);", "token2charspan": [[0, 6], [7, 13], [14, 16], [17, 24], [25, 30], [31, 33], [34, 37], [38, 44], [45, 58], [59, 67], [68, 71], [72, 82], [83, 84], [84, 88], [89, 93], [93, 94], [94, 95], [96, 103], [104, 109], [110, 112], [113, 116], [117, 123], [124, 137], [138, 148], [149, 151], [152, 162], [163, 169], [170, 171], [171, 177], [178, 180], [180, 181], [181, 182], [183, 188], [189, 191], [192, 195], [196, 204], [205, 214], [215, 217], [218, 221], [222, 228], [229, 239], [240, 241], [241, 250], [250, 251], [252, 255], [256, 261], [262, 264], [265, 268], [269, 273], [274, 284], [285, 286], [286, 295], [295, 296], [296, 297]]}
{"doc_key": "ai-dev-204", "ner": [[11, 11, "conference"], [13, 16, "conference"], [18, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 16, 11, 11, "named", "", false, false], [18, 20, 11, 11, "part-of", "", false, false], [18, 20, 11, 11, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2016", ",", "he", "was", "selected", "as", "the", "recipient", "of", "the", "ACL", "(", "Association", "for", "Computational", "Linguistics", ")", "Lifetime", "Achievement", "Award", "."], "sentence-detokenized": "In 2016, he was selected as the recipient of the ACL (Association for Computational Linguistics) Lifetime Achievement Award.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 24], [25, 27], [28, 31], [32, 41], [42, 44], [45, 48], [49, 52], [53, 54], [54, 65], [66, 69], [70, 83], [84, 95], [95, 96], [97, 105], [106, 117], [118, 123], [123, 124]]}
{"doc_key": "ai-dev-205", "ner": [[0, 1, "researcher"], [3, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", ",", "Y", ".", "Bengio", ",", "P.", "Frasconi", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Sepp Hochreiter, Y. Bengio, P. Frasconi and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 15], [15, 16], [17, 18], [18, 19], [20, 26], [26, 27], [28, 30], [31, 39], [40, 43], [44, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-206", "ner": [[3, 3, "product"], [6, 7, "misc"], [5, 12, "programlang"], [17, 23, "product"], [35, 35, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 5, 12, "usage", "", false, false], [5, 12, 6, 7, "type-of", "", false, false], [5, 12, 17, 23, "related-to", "", false, false], [35, 35, 3, 3, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["For", "example", ",", "A.L.I.C.E.", "uses", "an", "annotation", "language", "called", "AIML", ",", "which", "is", "specific", "to", "its", "function", "as", "a", "dialog", "system", ",", "and", "has", "since", "been", "adopted", "by", "several", "other", "developers", "of", "so", "-", "called", "Alicebots", "."], "sentence-detokenized": "For example, A.L.I.C.E. uses an annotation language called AIML, which is specific to its function as a dialog system, and has since been adopted by several other developers of so-called Alicebots.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 23], [24, 28], [29, 31], [32, 42], [43, 51], [52, 58], [59, 63], [63, 64], [65, 70], [71, 73], [74, 82], [83, 85], [86, 89], [90, 98], [99, 101], [102, 103], [104, 110], [111, 117], [117, 118], [119, 122], [123, 126], [127, 132], [133, 137], [138, 145], [146, 148], [149, 156], [157, 162], [163, 173], [174, 176], [177, 179], [179, 180], [180, 186], [187, 196], [196, 197]]}
{"doc_key": "ai-dev-207", "ner": [[9, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2000", ",", "he", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2000, he was elected a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 25], [26, 32], [33, 35], [36, 39], [40, 51], [52, 55], [56, 59], [60, 71], [72, 74], [75, 85], [86, 98], [98, 99]]}
{"doc_key": "ai-dev-208", "ner": [[0, 2, "misc"], [4, 7, "misc"], [10, 15, "misc"], [23, 25, "algorithm"], [34, 35, "field"], [37, 38, "field"], [40, 41, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 10, 15, "type-of", "", false, false], [0, 2, 34, 35, "related-to", "performs", true, false], [0, 2, 37, 38, "related-to", "performs", true, false], [0, 2, 40, 41, "related-to", "performs", true, false], [4, 7, 0, 2, "named", "", false, false], [23, 25, 10, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Learning", "Classifier", "Systems", "(", "LCS", ")", "are", "a", "family", "of", "rule", "-", "based", "machine", "learning", "algorithms", "that", "combine", "a", "discovery", "component", ",", "typically", "a", "genetic", "algorithm", ",", "and", "a", "learning", "component", "that", "performs", "either", "supervised", "learning", ",", "reinforcement", "learning", "or", "unsupervised", "learning", "."], "sentence-detokenized": "Learning Classifier Systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, typically a genetic algorithm, and a learning component that performs either supervised learning, reinforcement learning or unsupervised learning.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 29], [29, 32], [32, 33], [34, 37], [38, 39], [40, 46], [47, 49], [50, 54], [54, 55], [55, 60], [61, 68], [69, 77], [78, 88], [89, 93], [94, 101], [102, 103], [104, 113], [114, 123], [123, 124], [125, 134], [135, 136], [137, 144], [145, 154], [154, 155], [156, 159], [160, 161], [162, 170], [171, 180], [181, 185], [186, 194], [195, 201], [202, 212], [213, 221], [221, 222], [223, 236], [237, 245], [246, 248], [249, 261], [262, 270], [270, 271]]}
{"doc_key": "ai-dev-209", "ner": [[15, 15, "algorithm"], [14, 18, "algorithm"], [25, 26, "algorithm"], [28, 30, "misc"], [38, 43, "algorithm"], [46, 49, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[15, 15, 25, 26, "origin", "", false, false], [15, 15, 28, 30, "usage", "", false, false], [14, 18, 15, 15, "named", "", false, false], [38, 43, 28, 30, "type-of", "", false, false], [38, 43, 46, 49, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "unknown", "parameters", "of", "each", "vector", "\u03b2subk", "/", "sub", "are", "typically", "jointly", "estimated", "by", "maximum", "a", "posteriori", "(", "MAP", ")", "estimation", ",", "an", "extension", "of", "maximum", "likelihood", "using", "regularization", "of", "the", "weights", "to", "prevent", "pathological", "solutions", "(", "usually", "a", "quadratic", "regularization", "function", "equivalent", "to", "imposing", "a", "zero-mean", "Gaussian", "prior", "distribution", "on", "the", "weights", ",", "but", "other", "distributions", "are", "also", "possible", ")", "."], "sentence-detokenized": "The unknown parameters of each vector \u03b2subk/sub are typically jointly estimated by maximum a posteriori (MAP) estimation, an extension of maximum likelihood using regularization of the weights to prevent pathological solutions (usually a quadratic regularization function equivalent to imposing a zero-mean Gaussian prior distribution on the weights, but other distributions are also possible).", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 25], [26, 30], [31, 37], [38, 43], [43, 44], [44, 47], [48, 51], [52, 61], [62, 69], [70, 79], [80, 82], [83, 90], [91, 92], [93, 103], [104, 105], [105, 108], [108, 109], [110, 120], [120, 121], [122, 124], [125, 134], [135, 137], [138, 145], [146, 156], [157, 162], [163, 177], [178, 180], [181, 184], [185, 192], [193, 195], [196, 203], [204, 216], [217, 226], [227, 228], [228, 235], [236, 237], [238, 247], [248, 262], [263, 271], [272, 282], [283, 285], [286, 294], [295, 296], [297, 306], [307, 315], [316, 321], [322, 334], [335, 337], [338, 341], [342, 349], [349, 350], [351, 354], [355, 360], [361, 374], [375, 378], [379, 383], [384, 392], [392, 393], [393, 394]]}
{"doc_key": "ai-dev-210", "ner": [[9, 9, "researcher"], [12, 12, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 12, 9, 9, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "hierarchical", "structure", "of", "words", "is", "explicitly", "mapped", "in", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "The hierarchical structure of words is explicitly mapped in George Miller's Wordnet.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 29], [30, 35], [36, 38], [39, 49], [50, 56], [57, 59], [60, 66], [67, 73], [73, 75], [76, 83], [83, 84]]}
{"doc_key": "ai-dev-211", "ner": [[0, 6, "conference"], [11, 14, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 14, 0, 6, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", "is", "a", "benchmark", "for", "object", "classification", "and", "recognition", ",", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "categories", "."], "sentence-detokenized": "The ImageNet Large Scale Visual Recognition Challenge is a benchmark for object classification and recognition, with millions of images and hundreds of object categories.", "token2charspan": [[0, 3], [4, 12], [13, 18], [19, 24], [25, 31], [32, 43], [44, 53], [54, 56], [57, 58], [59, 68], [69, 72], [73, 79], [80, 94], [95, 98], [99, 110], [110, 111], [112, 116], [117, 125], [126, 128], [129, 135], [136, 139], [140, 148], [149, 151], [152, 158], [159, 169], [169, 170]]}
{"doc_key": "ai-dev-212", "ner": [[0, 2, "misc"], [21, 21, "misc"], [23, 24, "person"], [28, 28, "misc"], [33, 34, "person"], [38, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[21, 21, 0, 2, "general-affiliation", "", false, false], [28, 28, 0, 2, "general-affiliation", "", false, false], [28, 28, 23, 24, "artifact", "", false, false], [38, 40, 0, 2, "general-affiliation", "", false, false], [38, 40, 33, 34, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "science", "fiction", ",", "female", "-", "looking", "robots", "are", "often", "made", "into", "maids", "and", "sex", "slaves", ",", "as", "in", "the", "film", "Westworld", ",", "Paul", "J.", "McAuley", "'s", "novel", "Fairyland", "(", "1995", ")", "and", "Lester", "del", "Rey's", "short", "story", "Helen", "O'", "Loy", "(", "1938", ")", ",", "and", "sometimes", "into", "warriors", ",", "killers", "or", "workers", "."], "sentence-detokenized": "In science fiction, female-looking robots are often made into maids and sex slaves, as in the film Westworld, Paul J. McAuley's novel Fairyland (1995) and Lester del Rey's short story Helen O'Loy (1938), and sometimes into warriors, killers or workers.", "token2charspan": [[0, 2], [3, 10], [11, 18], [18, 19], [20, 26], [26, 27], [27, 34], [35, 41], [42, 45], [46, 51], [52, 56], [57, 61], [62, 67], [68, 71], [72, 75], [76, 82], [82, 83], [84, 86], [87, 89], [90, 93], [94, 98], [99, 108], [108, 109], [110, 114], [115, 117], [118, 125], [125, 127], [128, 133], [134, 143], [144, 145], [145, 149], [149, 150], [151, 154], [155, 161], [162, 165], [166, 171], [172, 177], [178, 183], [184, 189], [190, 192], [192, 195], [196, 197], [197, 201], [201, 202], [202, 203], [204, 207], [208, 217], [218, 222], [223, 231], [231, 232], [233, 240], [241, 243], [244, 251], [251, 252]]}
{"doc_key": "ai-dev-213", "ner": [[0, 1, "task"], [3, 4, "task"], [6, 7, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["answering", "questions", ",", "speech", "recognition", "and", "machine", "translation", "."], "sentence-detokenized": "answering questions, speech recognition and machine translation.", "token2charspan": [[0, 9], [10, 19], [19, 20], [21, 27], [28, 39], [40, 43], [44, 51], [52, 63], [63, 64]]}
{"doc_key": "ai-dev-214", "ner": [[5, 6, "researcher"], [7, 13, "organisation"], [15, 19, "location"], [21, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 4], "relations": [[5, 6, 7, 13, "role", "", false, false], [7, 13, 15, 19, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "a", "groundbreaking", "paper", ",", "Harry", "Blum", "of", "the", "Air", "Force", "Cambridge", "Research", "Laboratories", "at", "Hanscom", "Air", "Force", "Base", "in", "Bedford", ",", "Massachusetts", ",", "defined", "the", "shape", "of", "the", "central", "axis", "for", "skeleton", "calculation", "using", "an", "intuitive", "model", "of", "fire", "spread", "in", "a", "grass", "field", "with", "a", "given", "field", "shape", "."], "sentence-detokenized": "In a groundbreaking paper, Harry Blum of the Air Force Cambridge Research Laboratories at Hanscom Air Force Base in Bedford, Massachusetts, defined the shape of the central axis for skeleton calculation using an intuitive model of fire spread in a grass field with a given field shape.", "token2charspan": [[0, 2], [3, 4], [5, 19], [20, 25], [25, 26], [27, 32], [33, 37], [38, 40], [41, 44], [45, 48], [49, 54], [55, 64], [65, 73], [74, 86], [87, 89], [90, 97], [98, 101], [102, 107], [108, 112], [113, 115], [116, 123], [123, 124], [125, 138], [138, 139], [140, 147], [148, 151], [152, 157], [158, 160], [161, 164], [165, 172], [173, 177], [178, 181], [182, 190], [191, 202], [203, 208], [209, 211], [212, 221], [222, 227], [228, 230], [231, 235], [236, 242], [243, 245], [246, 247], [248, 253], [254, 259], [260, 264], [265, 266], [267, 272], [273, 278], [279, 284], [284, 285]]}
{"doc_key": "ai-dev-215", "ner": [[12, 12, "algorithm"], [14, 14, "algorithm"], [17, 18, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 12, 17, 18, "compare", "", false, false], [14, 14, 17, 18, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Unlike", "boosting", "algorithms", "that", "analytically", "minimize", "the", "convex", "loss", "function", "(", "e.g.", "AdaBoost", "and", "LogitBoost", ")", ",", "Brown", "Boost", "solves", "the", "two", "equations", "and", "two", "unknown", "systems", "using", "standard", "numerical", "methods", "."], "sentence-detokenized": "Unlike boosting algorithms that analytically minimize the convex loss function (e.g. AdaBoost and LogitBoost), BrownBoost solves the two equations and two unknown systems using standard numerical methods.", "token2charspan": [[0, 6], [7, 15], [16, 26], [27, 31], [32, 44], [45, 53], [54, 57], [58, 64], [65, 69], [70, 78], [79, 80], [80, 84], [85, 93], [94, 97], [98, 108], [108, 109], [109, 110], [111, 116], [116, 121], [122, 128], [129, 132], [133, 136], [137, 146], [147, 150], [151, 154], [155, 162], [163, 170], [171, 176], [177, 185], [186, 195], [196, 203], [203, 204]]}
{"doc_key": "ai-dev-216", "ner": [[0, 1, "researcher"], [9, 12, "misc"], [18, 22, "conference"], [24, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 9, 12, "win-defeat", "", false, false], [0, 1, 18, 22, "role", "", false, false], [24, 24, 18, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Getoor", "has", "received", "several", "awards", "for", "best", "publications", ",", "an", "NSF", "Career", "Award", "and", "is", "an", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "Fellow", "."], "sentence-detokenized": "Getoor has received several awards for best publications, an NSF Career Award and is an Association for the Advancement of Artificial Intelligence (AAAI) Fellow.", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 27], [28, 34], [35, 38], [39, 43], [44, 56], [56, 57], [58, 60], [61, 64], [65, 71], [72, 77], [78, 81], [82, 84], [85, 87], [88, 99], [100, 103], [104, 107], [108, 119], [120, 122], [123, 133], [134, 146], [147, 148], [148, 152], [152, 153], [154, 160], [160, 161]]}
{"doc_key": "ai-dev-217", "ner": [[0, 1, "misc"], [6, 10, "misc"], [15, 16, "misc"], [21, 25, "misc"], [30, 31, "misc"], [35, 39, "university"], [44, 52, "misc"], [57, 65, "misc"], [70, 74, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["ACM", "Fellow", "(", "2015", ")", "br", "Association", "for", "Computational", "Linguistics", "Fellow", "(", "2011", ")", "br", "AAAI", "Fellow", "(", "1994", ")", "br", "International", "Speech", "Communication", "Association", "Fellow", "(", "2011", ")", "br", "Honorary", "Doctorate", "(", "Hedersdoktor", ")", "KTH", "Royal", "Institute", "of", "Technology", "(", "2007", ")", "br", "Columbia", "Engineering", "School", "Alumni", "Association", "Distinguished", "Faculty", "Teaching", "Award", "(", "2009", ")", "br", "IEEE", "James", "L.", "Flanagan", "Speech", "and", "Audio", "Processing", "Award", "(", "2011", ")", "br", "ISCA", "Medal", "for", "Scientific", "Achievement", "(", "2011", ")"], "sentence-detokenized": "ACM Fellow (2015) br Association for Computational Linguistics Fellow (2011) br AAAI Fellow (1994) br International Speech Communication Association Fellow (2011) br Honorary Doctorate (Hedersdoktor) KTH Royal Institute of Technology (2007) br Columbia Engineering School Alumni Association Distinguished Faculty Teaching Award (2009) br IEEE James L. Flanagan Speech and Audio Processing Award (2011) br ISCA Medal for Scientific Achievement (2011)", "token2charspan": [[0, 3], [4, 10], [11, 12], [12, 16], [16, 17], [18, 20], [21, 32], [33, 36], [37, 50], [51, 62], [63, 69], [70, 71], [71, 75], [75, 76], [77, 79], [80, 84], [85, 91], [92, 93], [93, 97], [97, 98], [99, 101], [102, 115], [116, 122], [123, 136], [137, 148], [149, 155], [156, 157], [157, 161], [161, 162], [163, 165], [166, 174], [175, 184], [185, 186], [186, 198], [198, 199], [200, 203], [204, 209], [210, 219], [220, 222], [223, 233], [234, 235], [235, 239], [239, 240], [241, 243], [244, 252], [253, 264], [265, 271], [272, 278], [279, 290], [291, 304], [305, 312], [313, 321], [322, 327], [328, 329], [329, 333], [333, 334], [335, 337], [338, 342], [343, 348], [349, 351], [352, 360], [361, 367], [368, 371], [372, 377], [378, 388], [389, 394], [395, 396], [396, 400], [400, 401], [402, 404], [405, 409], [410, 415], [416, 419], [420, 430], [431, 442], [443, 444], [444, 448], [448, 449]]}
{"doc_key": "ai-dev-218", "ner": [[6, 6, "university"], [14, 15, "task"], [26, 28, "metrics"], [32, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[26, 28, 32, 37, "opposite", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["The", "frustrating", "result", "of", "the", "same", "Stanford", "study", "(", "and", "other", "attempts", "to", "improve", "naming", "translations", ")", "is", "that", "in", "many", "cases", "the", "sub-optimal", "score", "for", "bilingual", "evaluation", "of", "translation", "drops", "when", "translation", "methods", "for", "named", "entities", "are", "included", "."], "sentence-detokenized": "The frustrating result of the same Stanford study (and other attempts to improve naming translations) is that in many cases the sub-optimal score for bilingual evaluation of translation drops when translation methods for named entities are included.", "token2charspan": [[0, 3], [4, 15], [16, 22], [23, 25], [26, 29], [30, 34], [35, 43], [44, 49], [50, 51], [51, 54], [55, 60], [61, 69], [70, 72], [73, 80], [81, 87], [88, 100], [100, 101], [102, 104], [105, 109], [110, 112], [113, 117], [118, 123], [124, 127], [128, 139], [140, 145], [146, 149], [150, 159], [160, 170], [171, 173], [174, 185], [186, 191], [192, 196], [197, 208], [209, 216], [217, 220], [221, 226], [227, 235], [236, 239], [240, 248], [248, 249]]}
{"doc_key": "ai-dev-219", "ner": [[0, 0, "organisation"], [11, 13, "organisation"], [16, 21, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 13, "role", "works_with", false, false], [0, 0, 16, 21, "role", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Medtronic", "uses", "the", "PM", "data", "collected", "and", "collaborates", "with", "researchers", "at", "Johns", "Hopkins", "Hospital", "and", "the", "University", "of", "Washington", "School", "of", "Medicine", "to", "help", "answer", "specific", "questions", "about", "heart", "disease", ",", "such", "as", "whether", "a", "weak", "heart", "causes", "arrhythmias", "or", "vice", "versa", "."], "sentence-detokenized": "Medtronic uses the PM data collected and collaborates with researchers at Johns Hopkins Hospital and the University of Washington School of Medicine to help answer specific questions about heart disease, such as whether a weak heart causes arrhythmias or vice versa.", "token2charspan": [[0, 9], [10, 14], [15, 18], [19, 21], [22, 26], [27, 36], [37, 40], [41, 53], [54, 58], [59, 70], [71, 73], [74, 79], [80, 87], [88, 96], [97, 100], [101, 104], [105, 115], [116, 118], [119, 129], [130, 136], [137, 139], [140, 148], [149, 151], [152, 156], [157, 163], [164, 172], [173, 182], [183, 188], [189, 194], [195, 202], [202, 203], [204, 208], [209, 211], [212, 219], [220, 221], [222, 226], [227, 232], [233, 239], [240, 251], [252, 254], [255, 259], [260, 265], [265, 266]]}
{"doc_key": "ai-dev-220", "ner": [[9, 9, "misc"], [12, 13, "person"], [15, 16, "person"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[12, 13, 9, 9, "role", "", false, false], [15, 16, 9, 9, "role", "", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["It", "was", "followed", "by", "Paramount", "'s", "first", "feature", "film", "Sangaree", ",", "starring", "Fernando", "Lamas", "and", "Arlene", "Dahl", "."], "sentence-detokenized": "It was followed by Paramount's first feature film Sangaree, starring Fernando Lamas and Arlene Dahl.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 18], [19, 28], [28, 30], [31, 36], [37, 44], [45, 49], [50, 58], [58, 59], [60, 68], [69, 77], [78, 83], [84, 87], [88, 94], [95, 99], [99, 100]]}
{"doc_key": "ai-dev-221", "ner": [[0, 2, "programlang"], [8, 10, "researcher"], [12, 13, "researcher"], [17, 18, "organisation"], [20, 21, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 8, 10, "origin", "", false, false], [0, 2, 12, 13, "origin", "", false, false], [8, 10, 17, 18, "physical", "", false, false], [8, 10, 17, 18, "role", "", false, false], [12, 13, 20, 21, "physical", "", false, false], [12, 13, 20, 21, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["KRL", "is", "a", "knowledge", "representation", "language", "developed", "by", "Daniel", "G.", "Bobrow", "and", "Terry", "Winograd", "while", "working", "at", "Xerox", "PARC", "and", "Stanford", "University", "."], "sentence-detokenized": "KRL is a knowledge representation language developed by Daniel G. Bobrow and Terry Winograd while working at Xerox PARC and Stanford University.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 18], [19, 33], [34, 42], [43, 52], [53, 55], [56, 62], [63, 65], [66, 72], [73, 76], [77, 82], [83, 91], [92, 97], [98, 105], [106, 108], [109, 114], [115, 119], [120, 123], [124, 132], [133, 143], [143, 144]]}
{"doc_key": "ai-dev-222", "ner": [[20, 28, "conference"], [0, 1, "researcher"], [3, 4, "researcher"], [6, 10, "researcher"], [12, 15, "researcher"], [35, 36, "task"], [37, 40, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[20, 28, 35, 36, "topic", "", true, false], [0, 1, 20, 28, "physical", "", false, false], [0, 1, 20, 28, "role", "", false, false], [0, 1, 20, 28, "temporal", "", false, false], [3, 4, 20, 28, "physical", "", false, false], [3, 4, 20, 28, "role", "", false, false], [3, 4, 20, 28, "temporal", "", false, false], [6, 10, 20, 28, "physical", "", false, false], [6, 10, 20, 28, "role", "", false, false], [6, 10, 20, 28, "temporal", "", false, false], [12, 15, 20, 28, "physical", "", false, false], [12, 15, 20, 28, "role", "", false, false], [12, 15, 20, 28, "temporal", "", false, false], [35, 36, 37, 40, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Qiang", "Zhu", ",", "Shai", "Avidan", ",", "Mei-Chen", "Yeh", ",", "Mei-Chen", "Yeh", "and", "Kwang", "-", "Ting", "Cheng", "presented", "an", "algorithm", "at", "the", "IEEE", "Computer", "Vision", "and", "Image", "Recognition", "Conference", "in", "2006", "that", "can", "significantly", "speed", "up", "human", "identification", "using", "HOG", "imaging", "techniques", "."], "sentence-detokenized": "Qiang Zhu, Shai Avidan, Mei-Chen Yeh, Mei-Chen Yeh and Kwang-Ting Cheng presented an algorithm at the IEEE Computer Vision and Image Recognition Conference in 2006 that can significantly speed up human identification using HOG imaging techniques.", "token2charspan": [[0, 5], [6, 9], [9, 10], [11, 15], [16, 22], [22, 23], [24, 32], [33, 36], [36, 37], [38, 46], [47, 50], [51, 54], [55, 60], [60, 61], [61, 65], [66, 71], [72, 81], [82, 84], [85, 94], [95, 97], [98, 101], [102, 106], [107, 115], [116, 122], [123, 126], [127, 132], [133, 144], [145, 155], [156, 158], [159, 163], [164, 168], [169, 172], [173, 186], [187, 192], [193, 195], [196, 201], [202, 216], [217, 222], [223, 226], [227, 234], [235, 245], [245, 246]]}
{"doc_key": "ai-dev-223", "ner": [[0, 2, "researcher"], [6, 7, "conference"], [10, 12, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 7, "role", "", false, false], [0, 2, 10, 12, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hayes", "is", "a", "founding", "member", "of", "the", "AAAI", "and", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Hayes is a founding member of the AAAI and the Cognitive Science Society.", "token2charspan": [[0, 5], [6, 8], [9, 10], [11, 19], [20, 26], [27, 29], [30, 33], [34, 38], [39, 42], [43, 46], [47, 56], [57, 64], [65, 72], [72, 73]]}
{"doc_key": "ai-dev-224", "ner": [[0, 1, "misc"], [4, 5, "field"], [7, 8, "field"], [10, 11, "field"], [13, 13, "field"], [15, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 32, "field"], [38, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[0, 1, 4, 5, "part-of", "", false, false], [0, 1, 4, 5, "usage", "", false, false], [0, 1, 7, 8, "part-of", "", false, false], [0, 1, 7, 8, "usage", "", false, false], [0, 1, 10, 11, "part-of", "", false, false], [0, 1, 10, 11, "usage", "", false, false], [0, 1, 13, 13, "part-of", "", false, false], [0, 1, 13, 13, "usage", "", false, false], [0, 1, 15, 16, "part-of", "", false, false], [0, 1, 15, 16, "usage", "", false, false], [0, 1, 18, 19, "part-of", "", false, false], [0, 1, 18, 19, "usage", "", false, false], [0, 1, 21, 22, "part-of", "", false, false], [0, 1, 21, 22, "usage", "", false, false], [0, 1, 24, 24, "part-of", "", false, false], [0, 1, 24, 24, "usage", "", false, false], [0, 1, 26, 27, "part-of", "", false, false], [0, 1, 26, 27, "usage", "", false, false], [0, 1, 29, 29, "part-of", "", false, false], [0, 1, 29, 29, "usage", "", false, false], [0, 1, 31, 32, "part-of", "", false, false], [0, 1, 31, 32, "usage", "", false, false], [0, 1, 38, 39, "part-of", "", false, false], [0, 1, 38, 39, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "sentence": ["Time", "series", "are", "used", "in", "statistics", ",", "signal", "processing", ",", "pattern", "recognition", ",", "econometrics", ",", "mathematical", "finance", ",", "weather", "forecasting", ",", "earthquake", "prediction", ",", "electroencephalography", ",", "weather", "engineering", ",", "astronomy", ",", "telecommunications", "engineering", "and", "a", "wide", "range", "of", "applied", "science", "and", "engineering", "fields", "involving", "time", "measurements", "."], "sentence-detokenized": "Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, earthquake prediction, electroencephalography, weather engineering, astronomy, telecommunications engineering and a wide range of applied science and engineering fields involving time measurements.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 23], [24, 34], [34, 35], [36, 42], [43, 53], [53, 54], [55, 62], [63, 74], [74, 75], [76, 88], [88, 89], [90, 102], [103, 110], [110, 111], [112, 119], [120, 131], [131, 132], [133, 143], [144, 154], [154, 155], [156, 178], [178, 179], [180, 187], [188, 199], [199, 200], [201, 210], [210, 211], [212, 230], [231, 242], [243, 246], [247, 248], [249, 253], [254, 259], [260, 262], [263, 270], [271, 278], [279, 282], [283, 294], [295, 301], [302, 311], [312, 316], [317, 329], [329, 330]]}
{"doc_key": "ai-dev-225", "ner": [[14, 15, "metrics"], [37, 39, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "principle", ",", "an", "exact", "return", "can", "be", "solved", "in", "its", "feasible", "range", "using", "maximum", "likelihood", ",", "but", "this", "implies", "solving", "a", "bounded", "or", "regularized", "cutting", "problem", ",", "such", "as", "a", "minimum", "cut", ",", "which", "is", "typically", "NP", "-", "complete", "."], "sentence-detokenized": "In principle, an exact return can be solved in its feasible range using maximum likelihood, but this implies solving a bounded or regularized cutting problem, such as a minimum cut, which is typically NP-complete.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 16], [17, 22], [23, 29], [30, 33], [34, 36], [37, 43], [44, 46], [47, 50], [51, 59], [60, 65], [66, 71], [72, 79], [80, 90], [90, 91], [92, 95], [96, 100], [101, 108], [109, 116], [117, 118], [119, 126], [127, 129], [130, 141], [142, 149], [150, 157], [157, 158], [159, 163], [164, 166], [167, 168], [169, 176], [177, 180], [180, 181], [182, 187], [188, 190], [191, 200], [201, 203], [203, 204], [204, 212], [212, 213]]}
{"doc_key": "ai-dev-226", "ner": [[5, 6, "task"], [14, 14, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[14, 14, 5, 6, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["in", "it", "s", "work", "on", "pedestrian", "detection", ",", "which", "was", "first", "filmed", "at", "the", "BMVC", "in", "2009", "."], "sentence-detokenized": "in its work on pedestrian detection, which was first filmed at the BMVC in 2009.", "token2charspan": [[0, 2], [3, 5], [5, 6], [7, 11], [12, 14], [15, 25], [26, 35], [35, 36], [37, 42], [43, 46], [47, 52], [53, 59], [60, 62], [63, 66], [67, 71], [72, 74], [75, 79], [79, 80]]}
{"doc_key": "ai-dev-227", "ner": [[16, 23, "conference"], [0, 3, "researcher"], [7, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 3, 16, 23, "physical", "", false, false], [0, 3, 16, 23, "role", "", false, false], [0, 3, 7, 15, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2007", ",", "Terzopoulos", "was", "awarded", "the", "first", "IEEE", "PAMI", "Computer", "Vision", "Distinguished", "Researcher", "Award", "at", "the", "International", "Conference", "on", "Computer", "Vision", "for", "his", "pioneering", "and", "sustained", "research", "on", "deformation", "models", "and", "their", "applications", "."], "sentence-detokenized": "In 2007, Terzopoulos was awarded the first IEEE PAMI Computer Vision Distinguished Researcher Award at the International Conference on Computer Vision for his pioneering and sustained research on deformation models and their applications.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 24], [25, 32], [33, 36], [37, 42], [43, 47], [48, 52], [53, 61], [62, 68], [69, 82], [83, 93], [94, 99], [100, 102], [103, 106], [107, 120], [121, 131], [132, 134], [135, 143], [144, 150], [151, 154], [155, 158], [159, 169], [170, 173], [174, 183], [184, 192], [193, 195], [196, 207], [208, 214], [215, 218], [219, 224], [225, 237], [237, 238]]}
{"doc_key": "ai-dev-228", "ner": [[0, 2, "task"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "cluster", "analysis", ",", "or", "cluster", "analysis", ",", "data", "points", "are", "classified", "into", "clusters", "so", "that", "items", "belonging", "to", "the", "same", "cluster", "are", "as", "similar", "as", "possible", ",", "while", "items", "belonging", "to", "different", "clusters", "are", "as", "different", "as", "possible", "."], "sentence-detokenized": "In cluster analysis, or cluster analysis, data points are classified into clusters so that items belonging to the same cluster are as similar as possible, while items belonging to different clusters are as different as possible.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 23], [24, 31], [32, 40], [40, 41], [42, 46], [47, 53], [54, 57], [58, 68], [69, 73], [74, 82], [83, 85], [86, 90], [91, 96], [97, 106], [107, 109], [110, 113], [114, 118], [119, 126], [127, 130], [131, 133], [134, 141], [142, 144], [145, 153], [153, 154], [155, 160], [161, 166], [167, 176], [177, 179], [180, 189], [190, 198], [199, 202], [203, 205], [206, 215], [216, 218], [219, 227], [227, 228]]}
{"doc_key": "ai-dev-229", "ner": [[8, 9, "field"], [17, 19, "task"], [21, 22, "field"], [23, 26, "field"], [31, 32, "task"], [34, 34, "misc"]], "ner_mapping_to_source": [0, 2, 3, 4, 7, 8], "relations": [[8, 9, 21, 22, "named", "", false, false], [23, 26, 21, 22, "part-of", "", false, false]], "relations_mapping_to_source": [1, 4], "sentence": ["(", "2005", ")", ",", "three", "different", "perspectives", "on", "text", "mining", "can", "be", "distinguished", ",", "namely", "text", "mining", "as", "knowledge", "mining", ",", "text", "mining", "as", "text", "knowledge", "mining", "and", "text", "mining", "as", "knowledge", "discovery", "in", "databases.Hotho", ",", "A.", ",", "N\u00fcrnberger", ",", "A.", "and", "Paa\u00df", ",", "G.", "(", "2005", ")", "."], "sentence-detokenized": "(2005), three different perspectives on text mining can be distinguished, namely text mining as knowledge mining, text mining as text knowledge mining and text mining as knowledge discovery in databases.Hotho, A., N\u00fcrnberger, A. and Paa\u00df, G. (2005).", "token2charspan": [[0, 1], [1, 5], [5, 6], [6, 7], [8, 13], [14, 23], [24, 36], [37, 39], [40, 44], [45, 51], [52, 55], [56, 58], [59, 72], [72, 73], [74, 80], [81, 85], [86, 92], [93, 95], [96, 105], [106, 112], [112, 113], [114, 118], [119, 125], [126, 128], [129, 133], [134, 143], [144, 150], [151, 154], [155, 159], [160, 166], [167, 169], [170, 179], [180, 189], [190, 192], [193, 208], [208, 209], [210, 212], [212, 213], [214, 224], [224, 225], [226, 228], [229, 232], [233, 237], [237, 238], [239, 241], [242, 243], [243, 247], [247, 248], [248, 249]]}
{"doc_key": "ai-dev-230", "ner": [[0, 2, "product"], [15, 21, "location"], [22, 22, "location"], [24, 24, "location"], [26, 27, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 15, 21, "related-to", "developed_for", false, false], [15, 21, 22, 22, "physical", "", false, false], [22, 22, 24, 24, "physical", "", false, false], [26, 27, 0, 2, "role", "buys", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Rancho", "Arm", "was", "developed", "as", "a", "robotic", "arm", "to", "assist", "disabled", "patients", "at", "the", "Rancho", "Los", "Amigos", "National", "Rehabilitation", "Center", "in", "Downey", ",", "California", ";", "Stanford", "University", "purchased", "this", "computer", "-", "controlled", "arm", "in", "1963", "."], "sentence-detokenized": "The Rancho Arm was developed as a robotic arm to assist disabled patients at the Rancho Los Amigos National Rehabilitation Center in Downey, California; Stanford University purchased this computer-controlled arm in 1963.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 18], [19, 28], [29, 31], [32, 33], [34, 41], [42, 45], [46, 48], [49, 55], [56, 64], [65, 73], [74, 76], [77, 80], [81, 87], [88, 91], [92, 98], [99, 107], [108, 122], [123, 129], [130, 132], [133, 139], [139, 140], [141, 151], [151, 152], [153, 161], [162, 172], [173, 182], [183, 187], [188, 196], [196, 197], [197, 207], [208, 211], [212, 214], [215, 219], [219, 220]]}
{"doc_key": "ai-dev-231", "ner": [[0, 1, "university"], [3, 3, "researcher"], [8, 11, "organisation"], [18, 21, "organisation"], [25, 26, "researcher"], [28, 30, "researcher"], [43, 43, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 0, 1, "physical", "", false, false], [3, 3, 0, 1, "role", "", false, false], [3, 3, 8, 11, "role", "founder", false, false], [3, 3, 18, 21, "role", "founder", false, false], [18, 21, 43, 43, "physical", "", false, false], [25, 26, 18, 21, "role", "founder", false, false], [28, 30, 18, 21, "role", "founder", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["At", "UCSD", ",", "Norman", "was", "a", "co-founder", "of", "the", "Cognitive", "Science", "Institute", "and", "one", "of", "the", "organizers", "of", "the", "Cognitive", "Science", "Society", "(", "along", "with", "Roger", "Schank", ",", "Allan", "M.", "Collins", "and", "others", ")", ",", "which", "held", "it", "s", "first", "meeting", "on", "the", "UCSD", "campus", "in", "1979", "."], "sentence-detokenized": "At UCSD, Norman was a co-founder of the Cognitive Science Institute and one of the organizers of the Cognitive Science Society (along with Roger Schank, Allan M. Collins and others), which held its first meeting on the UCSD campus in 1979.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 21], [22, 32], [33, 35], [36, 39], [40, 49], [50, 57], [58, 67], [68, 71], [72, 75], [76, 78], [79, 82], [83, 93], [94, 96], [97, 100], [101, 110], [111, 118], [119, 126], [127, 128], [128, 133], [134, 138], [139, 144], [145, 151], [151, 152], [153, 158], [159, 161], [162, 169], [170, 173], [174, 180], [180, 181], [181, 182], [183, 188], [189, 193], [194, 196], [196, 197], [198, 203], [204, 211], [212, 214], [215, 218], [219, 223], [224, 230], [231, 233], [234, 238], [238, 239]]}
{"doc_key": "ai-dev-232", "ner": [[7, 8, "product"], [10, 11, "product"], [13, 14, "product"], [16, 18, "product"], [20, 21, "product"], [23, 28, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 21, 16, 18, "type-of", "", false, false], [23, 28, 16, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "commonly", "used", "robot", "configurations", "are", "jointed", "robots", ",", "SCARA", "robots", ",", "delta", "robots", "and", "cartesian", "coordinate", "robots", "(", "gantry", "robots", "or", "x", "-", "y", "-", "z", "robots", ")", "."], "sentence-detokenized": "The most commonly used robot configurations are jointed robots, SCARA robots, delta robots and cartesian coordinate robots (gantry robots or x-y-z robots).", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 28], [29, 43], [44, 47], [48, 55], [56, 62], [62, 63], [64, 69], [70, 76], [76, 77], [78, 83], [84, 90], [91, 94], [95, 104], [105, 115], [116, 122], [123, 124], [124, 130], [131, 137], [138, 140], [141, 142], [142, 143], [143, 144], [144, 145], [145, 146], [147, 153], [153, 154], [154, 155]]}
{"doc_key": "ai-dev-233", "ner": [[8, 8, "programlang"], [9, 10, "misc"], [15, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 8, 8, "part-of", "", false, false], [15, 15, 9, 10, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Alternatively", ",", "it", "can", "be", "used", "directly", "with", "Perl", "Module", "TM", "(", "which", "also", "supports", "LTM", ")", "."], "sentence-detokenized": "Alternatively, it can be used directly with Perl Module TM (which also supports LTM).", "token2charspan": [[0, 13], [13, 14], [15, 17], [18, 21], [22, 24], [25, 29], [30, 38], [39, 43], [44, 48], [49, 55], [56, 58], [59, 60], [60, 65], [66, 70], [71, 79], [80, 83], [83, 84], [84, 85]]}
{"doc_key": "ai-dev-234", "ner": [[7, 12, "country"], [8, 9, "organisation"], [17, 17, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 7, 12, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "competition", "was", "won", "by", "a", "team", "from", "Newton", "Labs", "in", "the", "US", ",", "and", "aired", "on", "CNN", "."], "sentence-detokenized": "The competition was won by a team from Newton Labs in the US, and aired on CNN.", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 23], [24, 26], [27, 28], [29, 33], [34, 38], [39, 45], [46, 50], [51, 53], [54, 57], [58, 60], [60, 61], [62, 65], [66, 71], [72, 74], [75, 78], [78, 79]]}
{"doc_key": "ai-dev-235", "ner": [[0, 4, "misc"], [11, 12, "person"], [15, 16, "person"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 12, 0, 4, "role", "directs", false, false], [15, 16, 0, 4, "role", "acts_in", false, false], [18, 19, 0, 4, "role", "acts_in", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Butler", "'s", "in", "Love", ",", "a", "short", "film", "directed", "by", "David", "Arquette", ",", "starring", "Elizabeth", "Berkley", "and", "Thomas", "Jane", "was", "released", "on", "23", "June", "2008", "."], "sentence-detokenized": "The Butler's in Love, a short film directed by David Arquette, starring Elizabeth Berkley and Thomas Jane was released on 23 June 2008.", "token2charspan": [[0, 3], [4, 10], [10, 12], [13, 15], [16, 20], [20, 21], [22, 23], [24, 29], [30, 34], [35, 43], [44, 46], [47, 52], [53, 61], [61, 62], [63, 71], [72, 81], [82, 89], [90, 93], [94, 100], [101, 105], [106, 109], [110, 118], [119, 121], [122, 124], [125, 129], [130, 134], [134, 135]]}
{"doc_key": "ai-dev-236", "ner": [[3, 4, "product"], [10, 12, "field"], [19, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 19, 19, "general-affiliation", "", false, false], [10, 12, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "Word", "Net", "is", "a", "resource", "that", "contains", "a", "taxonomy", "of", "elements", "that", "are", "the", "meanings", "of", "English", "words", "."], "sentence-detokenized": "For example, WordNet is a resource that contains a taxonomy of elements that are the meanings of English words.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [17, 20], [21, 23], [24, 25], [26, 34], [35, 39], [40, 48], [49, 50], [51, 59], [60, 62], [63, 71], [72, 76], [77, 80], [81, 84], [85, 93], [94, 96], [97, 104], [105, 110], [110, 111]]}
{"doc_key": "ai-dev-237", "ner": [[1, 3, "product"], [7, 7, "product"], [9, 9, "product"], [14, 15, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 1, 3, "type-of", "", false, false], [7, 7, 14, 15, "related-to", "ability_to", false, false], [9, 9, 1, 3, "type-of", "", false, false], [9, 9, 14, 15, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Existing", "humanoid", "robot", "systems", ",", "such", "as", "ASIMO", "and", "QRIO", ",", "use", "many", "motors", "for", "locomotion", "."], "sentence-detokenized": "Existing humanoid robot systems, such as ASIMO and QRIO, use many motors for locomotion.", "token2charspan": [[0, 8], [9, 17], [18, 23], [24, 31], [31, 32], [33, 37], [38, 40], [41, 46], [47, 50], [51, 55], [55, 56], [57, 60], [61, 65], [66, 72], [73, 76], [77, 87], [87, 88]]}
{"doc_key": "ai-dev-238", "ner": [[0, 0, "metrics"], [8, 9, "metrics"], [11, 11, "metrics"], [13, 18, "misc"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 9, 0, 0, "part-of", "", false, false], [11, 11, 0, 0, "part-of", "", false, false], [13, 18, 0, 0, "part-of", "", false, false], [20, 20, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LEPOR", "is", "designed", "using", "the", "factors", "of", "enhanced", "length", "penalty", ",", "accuracy", ",", "n", "-", "gram", "word", "order", "penalty", "and", "recall", "."], "sentence-detokenized": "LEPOR is designed using the factors of enhanced length penalty, accuracy, n-gram word order penalty and recall.", "token2charspan": [[0, 5], [6, 8], [9, 17], [18, 23], [24, 27], [28, 35], [36, 38], [39, 47], [48, 54], [55, 62], [62, 63], [64, 72], [72, 73], [74, 75], [75, 76], [76, 80], [81, 85], [86, 91], [92, 99], [100, 103], [104, 110], [110, 111]]}
{"doc_key": "ai-dev-239", "ner": [[0, 7, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "based", "on", "the", "Bilingual", "evaluation", "understudy", ",", "but", "with", "some", "modifications", "."], "sentence-detokenized": "It is based on the Bilingual evaluation understudy, but with some modifications.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 14], [15, 18], [19, 28], [29, 39], [40, 50], [50, 51], [52, 55], [56, 60], [61, 65], [66, 79], [79, 80]]}
{"doc_key": "ai-dev-240", "ner": [[5, 8, "product"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "implementation", "using", "MATLAB", "/", "Octave", ":"], "sentence-detokenized": "This is an example implementation using MATLAB/Octave:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 33], [34, 39], [40, 46], [46, 47], [47, 53], [53, 54]]}
{"doc_key": "ai-dev-241", "ner": [[11, 11, "programlang"], [13, 13, "programlang"], [15, 15, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "designed", "for", "use", "with", "several", "computer", "languages", ",", "including", "Python", ",", "Ruby", "and", "Scheme", "."], "sentence-detokenized": "It is designed for use with several computer languages, including Python, Ruby and Scheme.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 18], [19, 22], [23, 27], [28, 35], [36, 44], [45, 54], [54, 55], [56, 65], [66, 72], [72, 73], [74, 78], [79, 82], [83, 89], [89, 90]]}
{"doc_key": "ai-dev-242", "ner": [[0, 0, "researcher"], [7, 7, "organisation"], [13, 14, "conference"], [19, 20, "academicjournal"], [26, 28, "organisation"], [32, 37, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 7, 7, "role", "", false, false], [0, 0, 13, 14, "role", "", false, false], [0, 0, 19, 20, "role", "", false, false], [0, 0, 26, 28, "role", "", false, false], [0, 0, 32, 37, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hayes", "has", "served", "as", "Secretary", "of", "the", "AISB", ",", "President", "and", "Trustee", "of", "the", "IJCAI", ",", "Associate", "Editor", "of", "Artificial", "Intelligence", "magazine", ",", "Governor", "of", "the", "Cognitive", "Science", "Society", "and", "President", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "."], "sentence-detokenized": "Hayes has served as Secretary of the AISB, President and Trustee of the IJCAI, Associate Editor of Artificial Intelligence magazine, Governor of the Cognitive Science Society and President of the American Association for Artificial Intelligence.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 32], [33, 36], [37, 41], [41, 42], [43, 52], [53, 56], [57, 64], [65, 67], [68, 71], [72, 77], [77, 78], [79, 88], [89, 95], [96, 98], [99, 109], [110, 122], [123, 131], [131, 132], [133, 141], [142, 144], [145, 148], [149, 158], [159, 166], [167, 174], [175, 178], [179, 188], [189, 191], [192, 195], [196, 204], [205, 216], [217, 220], [221, 231], [232, 244], [244, 245]]}
{"doc_key": "ai-dev-243", "ner": [[4, 14, "misc"], [16, 20, "misc"], [23, 24, "person"], [27, 32, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 24, 4, 14, "role", "directed_by", false, false], [23, 24, 16, 20, "role", "directed_by", false, false], [23, 24, 27, 32, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "of", "them", ",", "Now", "is", "the", "Time", "(", "to", "Put", "On", "Your", "Glasses", ")", "and", "Around", "is", "Around", ",", "were", "directed", "by", "Norman", "McLaren", "in", "1951", "for", "the", "Canadian", "National", "Film", "Board", "."], "sentence-detokenized": "Two of them, Now is the Time (to Put On Your Glasses) and Around is Around, were directed by Norman McLaren in 1951 for the Canadian National Film Board.", "token2charspan": [[0, 3], [4, 6], [7, 11], [11, 12], [13, 16], [17, 19], [20, 23], [24, 28], [29, 30], [30, 32], [33, 36], [37, 39], [40, 44], [45, 52], [52, 53], [54, 57], [58, 64], [65, 67], [68, 74], [74, 75], [76, 80], [81, 89], [90, 92], [93, 99], [100, 107], [108, 110], [111, 115], [116, 119], [120, 123], [124, 132], [133, 141], [142, 146], [147, 152], [152, 153]]}
{"doc_key": "ai-dev-244", "ner": [[4, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "aim", "of", "a", "recommendation", "system", "is", "to", "predict", "the", "target", "user", "'s", "preference", "for", "a", "product", "."], "sentence-detokenized": "The aim of a recommendation system is to predict the target user's preference for a product.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 12], [13, 27], [28, 34], [35, 37], [38, 40], [41, 48], [49, 52], [53, 59], [60, 64], [64, 66], [67, 77], [78, 81], [82, 83], [84, 91], [91, 92]]}
{"doc_key": "ai-dev-245", "ner": [[0, 0, "algorithm"], [7, 7, "field"], [9, 9, "field"], [11, 12, "field"], [14, 16, "field"], [18, 18, "field"], [20, 21, "field"], [23, 23, "field"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 7, 7, "part-of", "", true, false], [0, 0, 9, 9, "part-of", "", true, false], [0, 0, 11, 12, "part-of", "", true, false], [0, 0, 14, 16, "part-of", "", true, false], [0, 0, 18, 18, "part-of", "", true, false], [0, 0, 20, 21, "part-of", "", true, false], [0, 0, 23, 23, "part-of", "", true, false], [0, 0, 25, 26, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Convolution", "has", "applications", "in", "areas", "such", "as", "probability", ",", "statistics", ",", "computer", "vision", ",", "natural", "language", "processing", ",", "image", "and", "signal", "processing", ",", "engineering", "and", "differential", "equations", "."], "sentence-detokenized": "Convolution has applications in areas such as probability, statistics, computer vision, natural language processing, image and signal processing, engineering and differential equations.", "token2charspan": [[0, 11], [12, 15], [16, 28], [29, 31], [32, 37], [38, 42], [43, 45], [46, 57], [57, 58], [59, 69], [69, 70], [71, 79], [80, 86], [86, 87], [88, 95], [96, 104], [105, 115], [115, 116], [117, 122], [123, 126], [127, 133], [134, 144], [144, 145], [146, 157], [158, 161], [162, 174], [175, 184], [184, 185]]}
{"doc_key": "ai-dev-246", "ner": [[0, 0, "field"], [3, 5, "task"], [7, 8, "task"], [10, 10, "task"], [11, 12, "task"], [14, 15, "task"], [18, 18, "task"], [20, 21, "task"], [23, 23, "task"], [26, 27, "task"], [29, 29, "field"], [31, 31, "field"], [33, 35, "field"], [37, 37, "field"], [39, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[0, 0, 3, 5, "part-of", "", true, false], [0, 0, 7, 8, "part-of", "", true, false], [0, 0, 10, 10, "part-of", "", true, false], [0, 0, 11, 12, "part-of", "", true, false], [0, 0, 14, 15, "part-of", "", true, false], [0, 0, 18, 18, "part-of", "", true, false], [0, 0, 20, 21, "part-of", "", true, false], [0, 0, 23, 23, "part-of", "", true, false], [0, 0, 26, 27, "part-of", "", true, false], [0, 0, 29, 29, "part-of", "", true, false], [0, 0, 31, 31, "part-of", "", true, false], [0, 0, 33, 35, "part-of", "", true, false], [0, 0, 37, 37, "part-of", "", true, false], [0, 0, 39, 39, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["DSP", "applications", "include", "audio", "signal", "processing", ",", "audio", "compression", ",", "digital", "image", "processing", ",", "video", "compression", ",", "speech", "processing", ",", "speech", "recognition", ",", "digital", "communications", ",", "digital", "synthesizers", ",", "radar", ",", "sonar", ",", "financial", "signal", "processing", ",", "seismology", "and", "biomedicine", "."], "sentence-detokenized": "DSP applications include audio signal processing, audio compression, digital image processing, video compression, speech processing, speech recognition, digital communications, digital synthesizers, radar, sonar, financial signal processing, seismology and biomedicine.", "token2charspan": [[0, 3], [4, 16], [17, 24], [25, 30], [31, 37], [38, 48], [48, 49], [50, 55], [56, 67], [67, 68], [69, 76], [77, 82], [83, 93], [93, 94], [95, 100], [101, 112], [112, 113], [114, 120], [121, 131], [131, 132], [133, 139], [140, 151], [151, 152], [153, 160], [161, 175], [175, 176], [177, 184], [185, 197], [197, 198], [199, 204], [204, 205], [206, 211], [211, 212], [213, 222], [223, 229], [230, 240], [240, 241], [242, 252], [253, 256], [257, 268], [268, 269]]}
{"doc_key": "ai-dev-247", "ner": [[11, 12, "misc"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "20", "February", "1912", "-", "11", "August", "2011", ")", "was", "an", "American", "inventor", "best", "known", "for", "creating", "the", "first", "industrial", "robot", ",", "Unimate", "."], "sentence-detokenized": "(20 February 1912 - 11 August 2011) was an American inventor best known for creating the first industrial robot, Unimate.", "token2charspan": [[0, 1], [1, 3], [4, 12], [13, 17], [18, 19], [20, 22], [23, 29], [30, 34], [34, 35], [36, 39], [40, 42], [43, 51], [52, 60], [61, 65], [66, 71], [72, 75], [76, 84], [85, 88], [89, 94], [95, 105], [106, 111], [111, 112], [113, 120], [120, 121]]}
{"doc_key": "ai-dev-248", "ner": [[1, 3, "researcher"], [5, 7, "researcher"], [9, 9, "researcher"], [16, 17, "algorithm"], [20, 22, "algorithm"], [28, 30, "task"], [31, 31, "algorithm"], [37, 38, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[1, 3, 16, 17, "related-to", "writes_about", true, false], [5, 7, 16, 17, "related-to", "writes_about", true, false], [9, 9, 16, 17, "related-to", "writes_about", true, false], [16, 17, 20, 22, "related-to", "", true, false], [28, 30, 31, 31, "related-to", "", true, false], [37, 38, 31, 31, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["With", "David", "E.", "Rumelhart", "and", "Ronald", "J.", "Williams", ",", "Hinton", "co-authored", "a", "1986", "paper", "popularizing", "the", "backpropagation", "algorithm", "for", "training", "multilayer", "neural", "networks", ",", "the", "dramatic", "milestone", "in", "image", "recognition", "of", "AlexNet", ",", "designed", "by", "his", "student", "Alex", "Krizhevsky", "{{", "cite", "web"], "sentence-detokenized": "With David E. Rumelhart and Ronald J. Williams, Hinton co-authored a 1986 paper popularizing the backpropagation algorithm for training multilayer neural networks, the dramatic milestone in image recognition of AlexNet, designed by his student Alex Krizhevsky {{cite web", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 34], [35, 37], [38, 46], [46, 47], [48, 54], [55, 66], [67, 68], [69, 73], [74, 79], [80, 92], [93, 96], [97, 112], [113, 122], [123, 126], [127, 135], [136, 146], [147, 153], [154, 162], [162, 163], [164, 167], [168, 176], [177, 186], [187, 189], [190, 195], [196, 207], [208, 210], [211, 218], [218, 219], [220, 228], [229, 231], [232, 235], [236, 243], [244, 248], [249, 259], [260, 262], [262, 266], [267, 270]]}
{"doc_key": "ai-dev-249", "ner": [[10, 14, "metrics"], [9, 22, "metrics"], [25, 29, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["When", "the", "predicted", "value", "is", "uniformly", "distributed", ",", "the", "root", "mean", "square", "of", "the", "error", ",", "the", "root", "mean", "square", "of", "the", "error", "or", "the", "median", "of", "the", "absolute", "deviation", "can", "be", "used", "to", "summarise", "the", "errors", "."], "sentence-detokenized": "When the predicted value is uniformly distributed, the root mean square of the error, the root mean square of the error or the median of the absolute deviation can be used to summarise the errors.", "token2charspan": [[0, 4], [5, 8], [9, 18], [19, 24], [25, 27], [28, 37], [38, 49], [49, 50], [51, 54], [55, 59], [60, 64], [65, 71], [72, 74], [75, 78], [79, 84], [84, 85], [86, 89], [90, 94], [95, 99], [100, 106], [107, 109], [110, 113], [114, 119], [120, 122], [123, 126], [127, 133], [134, 136], [137, 140], [141, 149], [150, 159], [160, 163], [164, 166], [167, 171], [172, 174], [175, 184], [185, 188], [189, 195], [195, 196]]}
{"doc_key": "ai-dev-250", "ner": [[0, 1, "algorithm"], [9, 10, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 9, 10, "part-of", "", true, false], [0, 1, 13, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Conceptual", "clustering", "developed", "mainly", "in", "the", "1980s", "as", "a", "machine", "learning", "paradigm", "for", "unsupervised", "learning", "."], "sentence-detokenized": "Conceptual clustering developed mainly in the 1980s as a machine learning paradigm for unsupervised learning.", "token2charspan": [[0, 10], [11, 21], [22, 31], [32, 38], [39, 41], [42, 45], [46, 51], [52, 54], [55, 56], [57, 64], [65, 73], [74, 82], [83, 86], [87, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-dev-251", "ner": [[1, 4, "product"], [30, 33, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "machine", "translator", "is", "unable", "to", "identify", "the", "named", "entities", ",", "they", "may", "be", "mistranslated", "as", "ordinary", "nouns", ",", "which", "would", "probably", "not", "affect", "the", "sub-lingual", "classification", "of", "the", "bilingual", "evaluation", "of", "the", "translation", ",", "but", "would", "change", "the", "readability", "of", "the", "text", "."], "sentence-detokenized": "If the machine translator is unable to identify the named entities, they may be mistranslated as ordinary nouns, which would probably not affect the sub-lingual classification of the bilingual evaluation of the translation, but would change the readability of the text.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 25], [26, 28], [29, 35], [36, 38], [39, 47], [48, 51], [52, 57], [58, 66], [66, 67], [68, 72], [73, 76], [77, 79], [80, 93], [94, 96], [97, 105], [106, 111], [111, 112], [113, 118], [119, 124], [125, 133], [134, 137], [138, 144], [145, 148], [149, 160], [161, 175], [176, 178], [179, 182], [183, 192], [193, 203], [204, 206], [207, 210], [211, 222], [222, 223], [224, 227], [228, 233], [234, 240], [241, 244], [245, 256], [257, 259], [260, 263], [264, 268], [268, 269]]}
{"doc_key": "ai-dev-252", "ner": [[0, 1, "researcher"], [10, 11, "misc"], [12, 18, "conference"], [20, 22, "location"], [24, 24, "country"], [38, 39, "researcher"], [48, 50, "university"], [53, 54, "researcher"], [56, 57, "researcher"], [59, 60, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10], "relations": [[0, 1, 10, 11, "related-to", "writes_about", false, false], [0, 1, 12, 18, "temporal", "", true, false], [12, 18, 20, 22, "physical", "", false, false], [20, 22, 24, 24, "physical", "", false, false], [53, 54, 48, 50, "physical", "", false, false], [53, 54, 48, 50, "role", "", false, false], [56, 57, 48, 50, "physical", "", false, false], [56, 57, 48, 50, "role", "", false, false], [59, 60, 48, 50, "physical", "", false, false], [59, 60, 48, 50, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 6, 7, 8, 9, 10, 11], "sentence": ["Roger", "Schank", ",", "1969", ",", "A", "conceptual", "dependency", "parser", "for", "natural", "language", "Proceedings", "of", "the", "1969", "on", "Computational", "linguistics", ",", "S\u00e5ng", "-", "S\u00e4by", ",", "Sweden", ",", "pages", "1-", "3", "This", "model", ",", "partly", "influenced", "by", "the", "work", "of", "Sydney", "Lamb", ",", "was", "widely", "used", "by", "Schank", "'s", "students", "at", "Yale", "University", ",", "including", "Robert", "Wilensky", ",", "Wendy", "Lehnert", "and", "Janet", "Kolodner", "."], "sentence-detokenized": "Roger Schank, 1969, A conceptual dependency parser for natural language Proceedings of the 1969 on Computational linguistics, S\u00e5ng-S\u00e4by, Sweden, pages 1-3 This model, partly influenced by the work of Sydney Lamb, was widely used by Schank's students at Yale University, including Robert Wilensky, Wendy Lehnert and Janet Kolodner.", "token2charspan": [[0, 5], [6, 12], [12, 13], [14, 18], [18, 19], [20, 21], [22, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 71], [72, 83], [84, 86], [87, 90], [91, 95], [96, 98], [99, 112], [113, 124], [124, 125], [126, 130], [130, 131], [131, 135], [135, 136], [137, 143], [143, 144], [145, 150], [151, 153], [153, 154], [155, 159], [160, 165], [165, 166], [167, 173], [174, 184], [185, 187], [188, 191], [192, 196], [197, 199], [200, 206], [207, 211], [211, 212], [213, 216], [217, 223], [224, 228], [229, 231], [232, 238], [238, 240], [241, 249], [250, 252], [253, 257], [258, 268], [268, 269], [270, 279], [280, 286], [287, 295], [295, 296], [297, 302], [303, 310], [311, 314], [315, 320], [321, 329], [329, 330]]}
{"doc_key": "ai-dev-253", "ner": [[2, 4, "algorithm"], [6, 6, "algorithm"], [16, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[6, 6, 2, 4, "named", "", false, false], [16, 16, 2, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 2], "sentence": ["The", "Improved", "maximum", "likelihood", "method", "(", "IMLM", ")", "is", "a", "combination", "of", "two", "MLM", "(", "maximum", "likelihood", ")", "estimators", "."], "sentence-detokenized": "The Improved maximum likelihood method (IMLM) is a combination of two MLM (maximum likelihood) estimators.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 31], [32, 38], [39, 40], [40, 44], [44, 45], [46, 48], [49, 50], [51, 62], [63, 65], [66, 69], [70, 73], [74, 75], [75, 82], [83, 93], [93, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-dev-254", "ner": [[25, 26, "metrics"], [29, 30, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[29, 30, 25, 26, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["These", "methods", "can", "also", "be", "used", "to", "analyse", "the", "output", "of", "the", "programme", "and", "its", "usefulness", ",", "and", "may", "therefore", "include", "an", "analysis", "of", "its", "mix", "matrix", "(", "or", "mix", "table", ")", "."], "sentence-detokenized": "These methods can also be used to analyse the output of the programme and its usefulness, and may therefore include an analysis of its mix matrix (or mix table).", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 22], [23, 25], [26, 30], [31, 33], [34, 41], [42, 45], [46, 52], [53, 55], [56, 59], [60, 69], [70, 73], [74, 77], [78, 88], [88, 89], [90, 93], [94, 97], [98, 107], [108, 115], [116, 118], [119, 127], [128, 130], [131, 134], [135, 138], [139, 145], [146, 147], [147, 149], [150, 153], [154, 159], [159, 160], [160, 161]]}
{"doc_key": "ai-dev-255", "ner": [[0, 0, "product"], [5, 6, "researcher"], [8, 9, "researcher"], [11, 14, "researcher"], [17, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 6, "origin", "", false, false], [0, 0, 8, 9, "origin", "", false, false], [0, 0, 11, 14, "origin", "", false, false], [0, 0, 17, 24, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SURF", "was", "first", "published", "by", "Herbert", "Bay", ",", "Tinne", "Tuytelaars", "and", "Luc", "Van", "Gool", "and", "presented", "at", "the", "European", "Conference", "on", "Computer", "Vision", "in", "2006", "."], "sentence-detokenized": "SURF was first published by Herbert Bay, Tinne Tuytelaars and Luc Van Gool and presented at the European Conference on Computer Vision in 2006.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 24], [25, 27], [28, 35], [36, 39], [39, 40], [41, 46], [47, 57], [58, 61], [62, 65], [66, 69], [70, 74], [75, 78], [79, 88], [89, 91], [92, 95], [96, 104], [105, 115], [116, 118], [119, 127], [128, 134], [135, 137], [138, 142], [142, 143]]}
{"doc_key": "ai-dev-256", "ner": [[0, 2, "task"], [7, 8, "field"], [10, 11, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 7, 8, "part-of", "", false, false], [0, 2, 10, 11, "part-of", "", false, false], [0, 2, 13, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OCR", "is", "the", "field", "of", "research", "in", "image", "recognition", ",", "artificial", "intelligence", "and", "computer", "vision", "."], "sentence-detokenized": "OCR is the field of research in image recognition, artificial intelligence and computer vision.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [17, 19], [20, 28], [29, 31], [32, 37], [38, 49], [49, 50], [51, 61], [62, 74], [75, 78], [79, 87], [88, 94], [94, 95]]}
{"doc_key": "ai-dev-257", "ner": [[4, 7, "metrics"], [9, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 15, 9, 13, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Continuing", "the", "example", "using", "the", "maximum", "likelihood", "estimator", ",", "the", "noise", "probability", "density", "function", "(", "pdf", ")", "for", "a", "single", "sample", "mathwn", "/", "math", "is", "as", "follows"], "sentence-detokenized": "Continuing the example using the maximum likelihood estimator, the noise probability density function (pdf) for a single sample mathwn / math is as follows", "token2charspan": [[0, 10], [11, 14], [15, 22], [23, 28], [29, 32], [33, 40], [41, 51], [52, 61], [61, 62], [63, 66], [67, 72], [73, 84], [85, 92], [93, 101], [102, 103], [103, 106], [106, 107], [108, 111], [112, 113], [114, 120], [121, 127], [128, 134], [135, 136], [137, 141], [142, 144], [145, 147], [148, 155]]}
{"doc_key": "ai-dev-258", "ner": [[0, 1, "field"], [4, 5, "task"], [7, 8, "task"], [10, 11, "task"], [13, 14, "task"], [16, 18, "task"], [20, 20, "task"], [22, 22, "task"], [24, 25, "task"], [27, 28, "task"], [30, 32, "task"], [34, 35, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[4, 5, 0, 1, "part-of", "", false, false], [7, 8, 0, 1, "part-of", "", false, false], [10, 11, 0, 1, "part-of", "", false, false], [13, 14, 0, 1, "part-of", "", false, false], [16, 18, 0, 1, "part-of", "", false, false], [20, 20, 0, 1, "part-of", "", false, false], [22, 22, 0, 1, "part-of", "", false, false], [24, 25, 0, 1, "part-of", "", false, false], [27, 28, 0, 1, "part-of", "", false, false], [30, 32, 0, 1, "part-of", "", false, false], [34, 35, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Computational", "vision", "domains", "include", "scene", "reconstruction", ",", "event", "detection", ",", "video", "tracking", ",", "object", "recognition", ",", "3D", "pose", "estimation", ",", "learning", ",", "indexing", ",", "motion", "estimation", ",", "visual", "servoing", ",", "3D", "scene", "modelling", "and", "image", "restoration", "."], "sentence-detokenized": "Computational vision domains include scene reconstruction, event detection, video tracking, object recognition, 3D pose estimation, learning, indexing, motion estimation, visual servoing, 3D scene modelling and image restoration.", "token2charspan": [[0, 13], [14, 20], [21, 28], [29, 36], [37, 42], [43, 57], [57, 58], [59, 64], [65, 74], [74, 75], [76, 81], [82, 90], [90, 91], [92, 98], [99, 110], [110, 111], [112, 114], [115, 119], [120, 130], [130, 131], [132, 140], [140, 141], [142, 150], [150, 151], [152, 158], [159, 169], [169, 170], [171, 177], [178, 186], [186, 187], [188, 190], [191, 196], [197, 206], [207, 210], [211, 216], [217, 228], [228, 229]]}
{"doc_key": "ai-dev-259", "ner": [[10, 16, "conference"], [0, 3, "researcher"], [6, 8, "misc"], [17, 18, "conference"], [27, 27, "researcher"], [29, 29, "researcher"], [23, 23, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 16, 17, 18, "named", "", false, false], [0, 3, 6, 8, "win-defeat", "", false, false], [0, 3, 23, 23, "related-to", "writes_about", true, false], [6, 8, 10, 16, "temporal", "", false, false], [27, 27, 6, 8, "win-defeat", "", false, true], [27, 27, 23, 23, "related-to", "writes_about", true, false], [29, 29, 6, 8, "win-defeat", "", false, true], [29, 29, 23, 23, "related-to", "writes_about", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["In", "2013", ",", "Terzopoulos", "was", "awarded", "the", "Helmholtz", "Prize", "at", "the", "International", "Conference", "on", "Computer", "Vision", "in", "1987", "for", "his", "ICCV", "paper", "on", "active", "contour", "models", "with", "Kass", "and", "Witkin", "."], "sentence-detokenized": "In 2013, Terzopoulos was awarded the Helmholtz Prize at the International Conference on Computer Vision in 1987 for his ICCV paper on active contour models with Kass and Witkin.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 20], [21, 24], [25, 32], [33, 36], [37, 46], [47, 52], [53, 55], [56, 59], [60, 73], [74, 84], [85, 87], [88, 96], [97, 103], [104, 106], [107, 111], [112, 115], [116, 119], [120, 124], [125, 130], [131, 133], [134, 140], [141, 148], [149, 155], [156, 160], [161, 165], [166, 169], [170, 176], [176, 177]]}
{"doc_key": "ai-dev-260", "ner": [[18, 23, "task"], [25, 27, "algorithm"], [29, 30, "algorithm"], [32, 34, "algorithm"], [36, 37, "algorithm"], [39, 40, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 23, 25, 27, "usage", "", true, false], [18, 23, 29, 30, "usage", "", true, false], [18, 23, 32, 34, "usage", "", true, false], [18, 23, 36, 37, "usage", "", true, false], [18, 23, 39, 40, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["If", "the", "regularisation", "function", "There", "are", "many", "algorithms", "for", "solving", "such", "problems", ",", "the", "most", "popular", "of", "which", "in", "the", "context", "of", "linear", "classification", "are", "stochastic", "gradient", "descent", ",", "gradient", "descent", ",", "L", "-", "BFGS", ",", "coordinate", "descent", "and", "Newton", "'s", "methods", "."], "sentence-detokenized": "If the regularisation function There are many algorithms for solving such problems, the most popular of which in the context of linear classification are stochastic gradient descent, gradient descent, L-BFGS, coordinate descent and Newton's methods.", "token2charspan": [[0, 2], [3, 6], [7, 21], [22, 30], [31, 36], [37, 40], [41, 45], [46, 56], [57, 60], [61, 68], [69, 73], [74, 82], [82, 83], [84, 87], [88, 92], [93, 100], [101, 103], [104, 109], [110, 112], [113, 116], [117, 124], [125, 127], [128, 134], [135, 149], [150, 153], [154, 164], [165, 173], [174, 181], [181, 182], [183, 191], [192, 199], [199, 200], [201, 202], [202, 203], [203, 207], [207, 208], [209, 219], [220, 227], [228, 231], [232, 238], [238, 240], [241, 248], [248, 249]]}
{"doc_key": "ai-dev-261", "ner": [[13, 15, "algorithm"], [2, 3, "researcher"], [5, 7, "researcher"]], "ner_mapping_to_source": [0, 2, 3], "relations": [[13, 15, 2, 3, "origin", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Invented", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "in", "1997", ",", "LSTM", "(", "Long", "Short", "Short", "Memory", ")", "networks", "have", "set", "accuracy", "records", "in", "many", "application", "areas", "."], "sentence-detokenized": "Invented by Sepp Hochreiter and J\u00fcrgen Schmidhuber in 1997, LSTM (Long Short Short Memory) networks have set accuracy records in many application areas.", "token2charspan": [[0, 8], [9, 11], [12, 16], [17, 27], [28, 31], [32, 38], [39, 50], [51, 53], [54, 58], [58, 59], [60, 64], [65, 66], [66, 70], [71, 76], [77, 82], [83, 89], [89, 90], [91, 99], [100, 104], [105, 108], [109, 117], [118, 125], [126, 128], [129, 133], [134, 145], [146, 151], [151, 152]]}
{"doc_key": "ai-dev-262", "ner": [[0, 0, "product"], [3, 6, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 3, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["TN", "was", "developed", "at", "Massachusetts", "General", "Hospital", "and", "tested", "in", "a", "number", "of", "scenarios", ",", "including", "identifying", "smoking", "status", ",", "family", "history", "of", "coronary", "heart", "disease", "and", "sleep", "disorder", "patients", ","], "sentence-detokenized": "TN was developed at Massachusetts General Hospital and tested in a number of scenarios, including identifying smoking status, family history of coronary heart disease and sleep disorder patients,", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 33], [34, 41], [42, 50], [51, 54], [55, 61], [62, 64], [65, 66], [67, 73], [74, 76], [77, 86], [86, 87], [88, 97], [98, 109], [110, 117], [118, 124], [124, 125], [126, 132], [133, 140], [141, 143], [144, 152], [153, 158], [159, 166], [167, 170], [171, 176], [177, 185], [186, 194], [194, 195]]}
{"doc_key": "ai-dev-263", "ner": [[3, 3, "researcher"], [16, 18, "organisation"]], "ner_mapping_to_source": [0, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "delivered", "in", "1961", "to", "General", "Motors", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was delivered in 1961 to General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 75], [76, 78], [79, 83], [84, 86], [87, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-dev-264", "ner": [[0, 2, "conference"], [12, 13, "location"], [15, 15, "location"], [17, 19, "country"], [29, 30, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 12, 13, "physical", "", false, false], [12, 13, 15, 15, "physical", "", false, false], [15, 15, 17, 19, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Campus", "Party", "Europe", "took", "place", "from", "14", "to", "18", "April", "2010", "in", "Caja", "M\u00e1gica", ",", "Madrid", ",", "Spain", ",", "with", "800", "participants", "from", "all", "27", "Member", "States", "of", "the", "European", "Union", "."], "sentence-detokenized": "Campus Party Europe took place from 14 to 18 April 2010 in Caja M\u00e1gica, Madrid, Spain, with 800 participants from all 27 Member States of the European Union.", "token2charspan": [[0, 6], [7, 12], [13, 19], [20, 24], [25, 30], [31, 35], [36, 38], [39, 41], [42, 44], [45, 50], [51, 55], [56, 58], [59, 63], [64, 70], [70, 71], [72, 78], [78, 79], [80, 85], [85, 86], [87, 91], [92, 95], [96, 108], [109, 113], [114, 117], [118, 120], [121, 127], [128, 134], [135, 137], [138, 141], [142, 150], [151, 156], [156, 157]]}
{"doc_key": "ai-dev-265", "ner": [[4, 4, "organisation"], [6, 8, "organisation"], [14, 17, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 17, 4, 4, "origin", "", false, false], [14, 17, 6, 8, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2016", ",", "DeepMind", "and", "Moorfields", "Eye", "Hospital", "announced", "a", "collaboration", "to", "develop", "AI", "applications", "for", "healthcare", "."], "sentence-detokenized": "In July 2016, DeepMind and Moorfields Eye Hospital announced a collaboration to develop AI applications for healthcare.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 22], [23, 26], [27, 37], [38, 41], [42, 50], [51, 60], [61, 62], [63, 76], [77, 79], [80, 87], [88, 90], [91, 103], [104, 107], [108, 118], [118, 119]]}
{"doc_key": "ai-dev-266", "ner": [[6, 7, "misc"], [11, 13, "university"], [15, 15, "university"], [17, 18, "university"], [20, 21, "university"], [23, 23, "university"], [25, 25, "university"], [28, 31, "university"], [33, 34, "university"], [36, 37, "university"], [39, 39, "university"], [42, 44, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[6, 7, 11, 13, "physical", "", false, false], [6, 7, 15, 15, "physical", "", false, false], [6, 7, 17, 18, "physical", "", false, false], [6, 7, 20, 21, "physical", "", false, false], [6, 7, 23, 23, "physical", "", false, false], [6, 7, 25, 25, "physical", "", false, false], [6, 7, 28, 31, "physical", "", false, false], [6, 7, 33, 34, "physical", "", false, false], [6, 7, 36, 37, "physical", "", false, false], [6, 7, 39, 39, "physical", "", false, false], [6, 7, 42, 44, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Eleven", "different", "institutions", "were", "eventually", "awarded", "PR2", "prizes", ",", "including", "the", "University", "of", "Freiburg", ",", "Bosch", ",", "Georgia", "Tech", ",", "KU", "Leuven", ",", "MIT", ",", "Stanford", ",", "the", "Technical", "University", "of", "Munich", ",", "UC", "Berkeley", ",", "U", "Penn", ",", "USC", "and", "the", "University", "of", "Tokyo", "."], "sentence-detokenized": "Eleven different institutions were eventually awarded PR2 prizes, including the University of Freiburg, Bosch, Georgia Tech, KU Leuven, MIT, Stanford, the Technical University of Munich, UC Berkeley, U Penn, USC and the University of Tokyo.", "token2charspan": [[0, 6], [7, 16], [17, 29], [30, 34], [35, 45], [46, 53], [54, 57], [58, 64], [64, 65], [66, 75], [76, 79], [80, 90], [91, 93], [94, 102], [102, 103], [104, 109], [109, 110], [111, 118], [119, 123], [123, 124], [125, 127], [128, 134], [134, 135], [136, 139], [139, 140], [141, 149], [149, 150], [151, 154], [155, 164], [165, 175], [176, 178], [179, 185], [185, 186], [187, 189], [190, 198], [198, 199], [200, 201], [202, 206], [206, 207], [208, 211], [212, 215], [216, 219], [220, 230], [231, 233], [234, 239], [239, 240]]}
{"doc_key": "ai-dev-267", "ner": [[3, 3, "metrics"], [5, 5, "metrics"], [7, 7, "metrics"], [9, 9, "metrics"], [18, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 18, 19, "part-of", "", false, false], [5, 5, 18, 19, "part-of", "", false, false], [7, 7, 18, 19, "part-of", "", false, false], [9, 9, 18, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "numbers", "of", "TP", ",", "TN", ",", "FP", "and", "FN", "are", "usually", "stored", "in", "a", "table", "called", "a", "mixing", "matrix", "."], "sentence-detokenized": "The numbers of TP, TN, FP and FN are usually stored in a table called a mixing matrix.", "token2charspan": [[0, 3], [4, 11], [12, 14], [15, 17], [17, 18], [19, 21], [21, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 44], [45, 51], [52, 54], [55, 56], [57, 62], [63, 69], [70, 71], [72, 78], [79, 85], [85, 86]]}
{"doc_key": "ai-dev-268", "ner": [[7, 8, "metrics"], [10, 11, "metrics"], [13, 14, "metrics"], [17, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "feature", "set", "is", "usually", "used", "as", "information", "gain", ",", "cross", "-entropy", ",", "mutual", "information", "and", "the", "ratio", "of", "coefficients", "."], "sentence-detokenized": "The feature set is usually used as information gain, cross-entropy, mutual information and the ratio of coefficients.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 18], [19, 26], [27, 31], [32, 34], [35, 46], [47, 51], [51, 52], [53, 58], [58, 66], [66, 67], [68, 74], [75, 86], [87, 90], [91, 94], [95, 100], [101, 103], [104, 116], [116, 117]]}
{"doc_key": "ai-dev-269", "ner": [[10, 11, "task"], [13, 14, "task"], [16, 16, "task"], [18, 18, "task"], [22, 22, "task"], [21, 24, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[21, 24, 22, 22, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "successfully", "applied", "to", "problems", "as", "diverse", "as", "robot", "control", ",", "lift", "scheduling", ",", "telecommunications", ",", "buttons", "and", "the", "game", "Go", "(", "AlphaGo", ")", "."], "sentence-detokenized": "It has been successfully applied to problems as diverse as robot control, lift scheduling, telecommunications, buttons and the game Go (AlphaGo).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 24], [25, 32], [33, 35], [36, 44], [45, 47], [48, 55], [56, 58], [59, 64], [65, 72], [72, 73], [74, 78], [79, 89], [89, 90], [91, 109], [109, 110], [111, 118], [119, 122], [123, 126], [127, 131], [132, 134], [135, 136], [136, 143], [143, 144], [144, 145]]}
{"doc_key": "ai-dev-270", "ner": [[11, 12, "misc"], [19, 23, "university"], [24, 25, "location"], [27, 27, "location"], [31, 34, "location"], [37, 41, "location"], [42, 43, "location"], [44, 45, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 12, 19, 23, "physical", "", false, false], [19, 23, 24, 25, "physical", "", false, false], [24, 25, 27, 27, "physical", "", false, false], [31, 34, 37, 41, "physical", "", false, false], [37, 41, 42, 43, "physical", "", false, false], [42, 43, 44, 45, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "the", "inaugural", "year", "of", "Mission", "8", ",", "the", "American", "venue", "was", "held", "on", "the", "campus", "of", "the", "Georgia", "Institute", "of", "Technology", "in", "Atlanta", ",", "Georgia", ",", "and", "the", "Asian", "/", "Pacific", "venue", "was", "held", "at", "the", "Beihang", "University", "Gymnasium", "in", "Beijing", ",", "China", "."], "sentence-detokenized": "In 2018, the inaugural year of Mission 8, the American venue was held on the campus of the Georgia Institute of Technology in Atlanta, Georgia, and the Asian/Pacific venue was held at the Beihang University Gymnasium in Beijing, China.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 22], [23, 27], [28, 30], [31, 38], [39, 40], [40, 41], [42, 45], [46, 54], [55, 60], [61, 64], [65, 69], [70, 72], [73, 76], [77, 83], [84, 86], [87, 90], [91, 98], [99, 108], [109, 111], [112, 122], [123, 125], [126, 133], [133, 134], [135, 142], [142, 143], [144, 147], [148, 151], [152, 157], [157, 158], [158, 165], [166, 171], [172, 175], [176, 180], [181, 183], [184, 187], [188, 195], [196, 206], [207, 216], [217, 219], [220, 227], [227, 228], [229, 234], [234, 235]]}
{"doc_key": "ai-dev-271", "ner": [[0, 2, "field"], [6, 10, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 6, 10, "origin", "", false, false], [0, 2, 6, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "is", "strongly", "related", "to", "pattern", "recognition", "and", "has", "its", "origins", "in", "artificial", "intelligence", "."], "sentence-detokenized": "Machine learning is strongly related to pattern recognition and has its origins in artificial intelligence.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 28], [29, 36], [37, 39], [40, 47], [48, 59], [60, 63], [64, 67], [68, 71], [72, 79], [80, 82], [83, 93], [94, 106], [106, 107]]}
{"doc_key": "ai-dev-272", "ner": [[13, 16, "product"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "comes", "with", "3", "Java", "games", ",", "controlled", "by", "remote", "control", "and", "displayed", "on", "the", "LCD", "screen", "."], "sentence-detokenized": "It comes with 3 Java games, controlled by remote control and displayed on the LCD screen.", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 15], [16, 20], [21, 26], [26, 27], [28, 38], [39, 41], [42, 48], [49, 56], [57, 60], [61, 70], [71, 73], [74, 77], [78, 81], [82, 88], [88, 89]]}
{"doc_key": "ai-dev-273", "ner": [[9, 18, "task"], [0, 2, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 9, 18, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Optical", "motion", "capture", "is", "a", "commercially", "successful", "but", "specialised", "computer", "vision", "-", "based", "technique", "for", "estimating", "jointed", "body", "position", "."], "sentence-detokenized": "Optical motion capture is a commercially successful but specialised computer vision-based technique for estimating jointed body position.", "token2charspan": [[0, 7], [8, 14], [15, 22], [23, 25], [26, 27], [28, 40], [41, 51], [52, 55], [56, 67], [68, 76], [77, 83], [83, 84], [84, 89], [90, 99], [100, 103], [104, 114], [115, 122], [123, 127], [128, 136], [136, 137]]}
{"doc_key": "ai-dev-274", "ner": [[0, 1, "organisation"], [9, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 9, 10, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "SMC", "is", "very", "similar", "to", "the", "more", "popular", "Jaccard", "index", "."], "sentence-detokenized": "The SMC is very similar to the more popular Jaccard index.", "token2charspan": [[0, 3], [4, 7], [8, 10], [11, 15], [16, 23], [24, 26], [27, 30], [31, 35], [36, 43], [44, 51], [52, 57], [57, 58]]}
{"doc_key": "ai-dev-275", "ner": [[0, 0, "product"], [2, 6, "product"], [8, 14, "product"], [20, 22, "researcher"], [27, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 14, "named", "", false, false], [0, 0, 20, 22, "artifact", "", false, false], [0, 0, 27, 27, "artifact", "", false, false], [2, 6, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", "or", "Programmable", "Universal", "Manipulation", "Arm", ")", "is", "an", "industrial", "robot", "arm", "developed", "by", "Victor", "Scheinman", "at", "the", "pioneering", "robotics", "company", "Unimation", "."], "sentence-detokenized": "PUMA (Programmable Universal Machine for Assembly or Programmable Universal Manipulation Arm) is an industrial robot arm developed by Victor Scheinman at the pioneering robotics company Unimation.", "token2charspan": [[0, 4], [5, 6], [6, 18], [19, 28], [29, 36], [37, 40], [41, 49], [50, 52], [53, 65], [66, 75], [76, 88], [89, 92], [92, 93], [94, 96], [97, 99], [100, 110], [111, 116], [117, 120], [121, 130], [131, 133], [134, 140], [141, 150], [151, 153], [154, 157], [158, 168], [169, 177], [178, 185], [186, 195], [195, 196]]}
{"doc_key": "ai-dev-276", "ner": [[4, 4, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "written", "in", "Python", "."], "sentence-detokenized": "It is written in Python.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 23], [23, 24]]}
{"doc_key": "ai-dev-277", "ner": [[0, 0, "misc"], [1, 2, "misc"], [13, 13, "field"], [15, 16, "field"], [18, 18, "field"], [24, 25, "field"], [27, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7], "relations": [[0, 0, 1, 2, "related-to", "metric_for", true, false], [0, 0, 13, 13, "part-of", "", false, false], [0, 0, 15, 16, "part-of", "", false, false], [0, 0, 18, 18, "part-of", "", false, false], [0, 0, 24, 25, "part-of", "", false, false], [0, 0, 27, 30, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6], "sentence": ["Bandwidth", "in", "hertz", "is", "a", "key", "concept", "in", "many", "fields", ",", "such", "as", "electronics", ",", "information", "theory", ",", "digital", "communications", ",", "radio", "communications", ",", "signal", "processing", "and", "spectroscopy", ",", "and", "is", "one", "of", "the", "determinants", "of", "the", "capacity", "of", "a", "given", "communication", "channel", "."], "sentence-detokenized": "Bandwidth in hertz is a key concept in many fields, such as electronics, information theory, digital communications, radio communications, signal processing and spectroscopy, and is one of the determinants of the capacity of a given communication channel.", "token2charspan": [[0, 9], [10, 12], [13, 18], [19, 21], [22, 23], [24, 27], [28, 35], [36, 38], [39, 43], [44, 50], [50, 51], [52, 56], [57, 59], [60, 71], [71, 72], [73, 84], [85, 91], [91, 92], [93, 100], [101, 115], [115, 116], [117, 122], [123, 137], [137, 138], [139, 145], [146, 156], [157, 160], [161, 173], [173, 174], [175, 178], [179, 181], [182, 185], [186, 188], [189, 192], [193, 205], [206, 208], [209, 212], [213, 221], [222, 224], [225, 226], [227, 232], [233, 246], [247, 254], [254, 255]]}
{"doc_key": "ai-dev-278", "ner": [[8, 8, "algorithm"], [10, 10, "algorithm"], [16, 19, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 16, 19, "part-of", "", false, false], [10, 10, 16, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["If", "convex", "loss", "is", "used", "(", "as", "in", "AdaBoost", ",", "LogitBoost", "and", "all", "members", "of", "the", "AnyBoost", "family", "of", "algorithms", ")", ",", "an", "example", "with", "a", "higher", "margin", "will", "be", "given", "less", "(", "or", "equal", ")", "weight", "than", "an", "example", "with", "a", "lower", "margin", "."], "sentence-detokenized": "If convex loss is used (as in AdaBoost, LogitBoost and all members of the AnyBoost family of algorithms), an example with a higher margin will be given less (or equal) weight than an example with a lower margin.", "token2charspan": [[0, 2], [3, 9], [10, 14], [15, 17], [18, 22], [23, 24], [24, 26], [27, 29], [30, 38], [38, 39], [40, 50], [51, 54], [55, 58], [59, 66], [67, 69], [70, 73], [74, 82], [83, 89], [90, 92], [93, 103], [103, 104], [104, 105], [106, 108], [109, 116], [117, 121], [122, 123], [124, 130], [131, 137], [138, 142], [143, 145], [146, 151], [152, 156], [157, 158], [158, 160], [161, 166], [166, 167], [168, 174], [175, 179], [180, 182], [183, 190], [191, 195], [196, 197], [198, 203], [204, 210], [210, 211]]}
{"doc_key": "ai-dev-279", "ner": [[0, 0, "researcher"], [7, 8, "researcher"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 7, 8, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Sepp", "Hochreiter", "'s", "diploma", "thesis", "from", "1991", "Sepp", "Hochreiter", "."], "sentence-detokenized": "Sepp Hochreiter's diploma thesis from 1991 Sepp Hochreiter.", "token2charspan": [[0, 4], [5, 15], [15, 17], [18, 25], [26, 32], [33, 37], [38, 42], [43, 47], [48, 58], [58, 59]]}
{"doc_key": "ai-dev-280", "ner": [[5, 5, "algorithm"], [4, 7, "algorithm"], [14, 14, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"], [26, 28, "algorithm"], [31, 32, "algorithm"], [34, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[4, 7, 5, 5, "named", "", false, false], [17, 19, 26, 28, "related-to", "", true, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["Typical", "discriminative", "models", "include", "logistic", "regression", "(", "LR", ")", ",", "support", "vector", "machines", "(", "SVM", ")", ",", "conditional", "random", "fields", "(", "CRF", ")", "(", "defined", "on", "an", "undirected", "graph", ")", ",", "decision", "trees", ",", "neural", "networks", "and", "many", "others", "."], "sentence-detokenized": "Typical discriminative models include logistic regression (LR), support vector machines (SVM), conditional random fields (CRF) (defined on an undirected graph), decision trees, neural networks and many others.", "token2charspan": [[0, 7], [8, 22], [23, 29], [30, 37], [38, 46], [47, 57], [58, 59], [59, 61], [61, 62], [62, 63], [64, 71], [72, 78], [79, 87], [88, 89], [89, 92], [92, 93], [93, 94], [95, 106], [107, 113], [114, 120], [121, 122], [122, 125], [125, 126], [127, 128], [128, 135], [136, 138], [139, 141], [142, 152], [153, 158], [158, 159], [159, 160], [161, 169], [170, 175], [175, 176], [177, 183], [184, 192], [193, 196], [197, 201], [202, 208], [208, 209]]}
{"doc_key": "ai-dev-281", "ner": [[11, 14, "metrics"], [33, 36, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "then", "also", "possible", "to", "use", "these", "probabilities", "and", "estimate", "the", "mean", "squared", "error", "(", "or", "some", "other", "equivalent", "measure", ")", "between", "the", "probabilities", "and", "the", "true", "values", "and", "combine", "this", "with", "a", "mixture", "matrix", "to", "create", "very", "powerful", "logistic", "regression", "goodness", "-", "of", "-", "fit", "functions", "."], "sentence-detokenized": "It is then also possible to use these probabilities and estimate the mean squared error (or some other equivalent measure) between the probabilities and the true values and combine this with a mixture matrix to create very powerful logistic regression goodness-of-fit functions.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 15], [16, 24], [25, 27], [28, 31], [32, 37], [38, 51], [52, 55], [56, 64], [65, 68], [69, 73], [74, 81], [82, 87], [88, 89], [89, 91], [92, 96], [97, 102], [103, 113], [114, 121], [121, 122], [123, 130], [131, 134], [135, 148], [149, 152], [153, 156], [157, 161], [162, 168], [169, 172], [173, 180], [181, 185], [186, 190], [191, 192], [193, 200], [201, 207], [208, 210], [211, 217], [218, 222], [223, 231], [232, 240], [241, 251], [252, 260], [260, 261], [261, 263], [263, 264], [264, 267], [268, 277], [277, 278]]}
{"doc_key": "ai-dev-282", "ner": [[0, 1, "product"], [6, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 6, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VoiceOver", "was", "first", "introduced", "in", "2005", "in", "Mac", "OS", "X", "Tiger", "(", "10.4", ")", "."], "sentence-detokenized": "VoiceOver was first introduced in 2005 in Mac OS X Tiger (10.4).", "token2charspan": [[0, 9], [10, 13], [14, 19], [20, 30], [31, 33], [34, 38], [39, 41], [42, 45], [46, 48], [49, 50], [51, 56], [57, 58], [58, 62], [62, 63], [63, 64]]}
{"doc_key": "ai-dev-283", "ner": [[12, 16, "algorithm"], [17, 21, "misc"], [25, 29, "metrics"], [30, 32, "algorithm"], [62, 64, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 16, 17, 21, "related-to", "applied_to", false, false], [25, 29, 17, 21, "type-of", "", false, false], [25, 29, 30, 32, "related-to", "used_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "practice", ",", "machine", "learning", "algorithms", "cope", "with", "this", "either", "by", "using", "a", "concave", "approximation", "of", "the", "0", "-", "1", "loss", "function", "(", "such", "as", "the", "hinge", "loss", "of", "a", "support", "vector", "machine", ")", ",", "which", "is", "easier", "to", "optimize", ",", "or", "by", "making", "assumptions", "on", "the", "distribution", "mathP", "(", "x", ",", "y", ")", "/", "math", "(", "and", "thus", "cease", "to", "be", "agnostic", "learning", "algorithms", ",", "for", "which", "the", "above", "result", "holds", ")", "."], "sentence-detokenized": "In practice, machine learning algorithms cope with this either by using a concave approximation of the 0-1 loss function (such as the hinge loss of a support vector machine), which is easier to optimize, or by making assumptions on the distribution mathP (x, y) / math (and thus cease to be agnostic learning algorithms, for which the above result holds).", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 20], [21, 29], [30, 40], [41, 45], [46, 50], [51, 55], [56, 62], [63, 65], [66, 71], [72, 73], [74, 81], [82, 95], [96, 98], [99, 102], [103, 104], [104, 105], [105, 106], [107, 111], [112, 120], [121, 122], [122, 126], [127, 129], [130, 133], [134, 139], [140, 144], [145, 147], [148, 149], [150, 157], [158, 164], [165, 172], [172, 173], [173, 174], [175, 180], [181, 183], [184, 190], [191, 193], [194, 202], [202, 203], [204, 206], [207, 209], [210, 216], [217, 228], [229, 231], [232, 235], [236, 248], [249, 254], [255, 256], [256, 257], [257, 258], [259, 260], [260, 261], [262, 263], [264, 268], [269, 270], [270, 273], [274, 278], [279, 284], [285, 287], [288, 290], [291, 299], [300, 308], [309, 319], [319, 320], [321, 324], [325, 330], [331, 334], [335, 340], [341, 347], [348, 353], [353, 354], [354, 355]]}
{"doc_key": "ai-dev-284", "ner": [[0, 0, "misc"], [11, 13, "field"], [19, 20, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 13, "usage", "", false, false], [0, 0, 19, 20, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Westworld", "(", "1973", ")", "was", "the", "first", "feature", "film", "to", "use", "digital", "image", "processing", "for", "photography", "to", "simulate", "the", "android", "perspective", "."], "sentence-detokenized": "Westworld (1973) was the first feature film to use digital image processing for photography to simulate the android perspective.", "token2charspan": [[0, 9], [10, 11], [11, 15], [15, 16], [17, 20], [21, 24], [25, 30], [31, 38], [39, 43], [44, 46], [47, 50], [51, 58], [59, 64], [65, 75], [76, 79], [80, 91], [92, 94], [95, 103], [104, 107], [108, 115], [116, 127], [127, 128]]}
{"doc_key": "ai-dev-285", "ner": [[6, 8, "task"], [10, 11, "task"], [13, 14, "task"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "now", "also", "commonly", "used", "in", "speech", "recognition", ",", "speech", "synthesis", ",", "diary", "annotation", ",", "Xavier", "Anguera", "et", "al", "."], "sentence-detokenized": "It is now also commonly used in speech recognition, speech synthesis, diary annotation, Xavier Anguera et al.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 14], [15, 23], [24, 28], [29, 31], [32, 38], [39, 50], [50, 51], [52, 58], [59, 68], [68, 69], [70, 75], [76, 86], [86, 87], [88, 94], [95, 102], [103, 105], [106, 108], [108, 109]]}
{"doc_key": "ai-dev-286", "ner": [[8, 11, "algorithm"], [16, 17, "algorithm"], [20, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 17, 8, 11, "type-of", "", false, false], [20, 22, 8, 11, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Here", "math", "\\", "sigma", "/", "math", "is", "an", "element-", "specific", "activation", "function", ",", "such", "as", "a", "sigmoid", "function", "or", "an", "adjusted", "linear", "unit", "."], "sentence-detokenized": "Here math\\ sigma/math is an element-specific activation function, such as a sigmoid function or an adjusted linear unit.", "token2charspan": [[0, 4], [5, 9], [9, 10], [11, 16], [16, 17], [17, 21], [22, 24], [25, 27], [28, 36], [36, 44], [45, 55], [56, 64], [64, 65], [66, 70], [71, 73], [74, 75], [76, 83], [84, 92], [93, 95], [96, 98], [99, 107], [108, 114], [115, 119], [119, 120]]}
{"doc_key": "ai-dev-287", "ner": [[10, 11, "algorithm"], [21, 21, "misc"], [23, 23, "misc"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "phonetic", "approaches", "(", "i.e.", "all", "models", "based", "on", "the", "Hidden", "Markov", "Model", ")", "required", "separate", "components", "and", "training", "for", "the", "phonetic", ",", "acoustic", "and", "language", "models", "."], "sentence-detokenized": "Traditional phonetic approaches (i.e. all models based on the Hidden Markov Model) required separate components and training for the phonetic, acoustic and language models.", "token2charspan": [[0, 11], [12, 20], [21, 31], [32, 33], [33, 37], [38, 41], [42, 48], [49, 54], [55, 57], [58, 61], [62, 68], [69, 75], [76, 81], [81, 82], [83, 91], [92, 100], [101, 111], [112, 115], [116, 124], [125, 128], [129, 132], [133, 141], [141, 142], [143, 151], [152, 155], [156, 164], [165, 171], [171, 172]]}
{"doc_key": "ai-dev-288", "ner": [[0, 3, "algorithm"], [6, 8, "field"], [10, 11, "field"], [12, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 12, 14, "related-to", "used_for", false, false], [6, 8, 0, 3, "usage", "", false, false], [10, 11, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Roberts", "cross", "operator", "is", "used", "in", "image", "processing", "and", "computer", "vision", "to", "detect", "edges", "."], "sentence-detokenized": "The Roberts cross operator is used in image processing and computer vision to detect edges.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 37], [38, 43], [44, 54], [55, 58], [59, 67], [68, 74], [75, 77], [78, 84], [85, 90], [90, 91]]}
{"doc_key": "ai-dev-289", "ner": [[2, 4, "metrics"], [24, 24, "metrics"]], "ner_mapping_to_source": [1, 2], "relations": [[2, 4, 24, 24, "opposite", "", false, false]], "relations_mapping_to_source": [1], "sentence": ["Sensitivity", "and", "specificity", "values", "are", "not", "dependent", "on", "the", "percentage", "of", "positive", "cases", "in", "the", "population", "of", "interest", "(", "unlike", ",", "for", "example", ",", "precision", ")", "."], "sentence-detokenized": "Sensitivity and specificity values are not dependent on the percentage of positive cases in the population of interest (unlike, for example, precision).", "token2charspan": [[0, 11], [12, 15], [16, 27], [28, 34], [35, 38], [39, 42], [43, 52], [53, 55], [56, 59], [60, 70], [71, 73], [74, 82], [83, 88], [89, 91], [92, 95], [96, 106], [107, 109], [110, 118], [119, 120], [120, 126], [126, 127], [128, 131], [132, 139], [139, 140], [141, 150], [150, 151], [151, 152]]}
{"doc_key": "ai-dev-290", "ner": [[13, 14, "algorithm"], [5, 6, "misc"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 6, 13, 14, "topic", "", false, false], [5, 6, 7, 8, "artifact", "", false, false], [5, 6, 10, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["However", ",", "the", "1969", "book", "Perceptrons", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "made", "perceptron", "models", "very", "unpopular", "."], "sentence-detokenized": "However, the 1969 book Perceptrons by Marvin Minsky and Seymour Papert made perceptron models very unpopular.", "token2charspan": [[0, 7], [7, 8], [9, 12], [13, 17], [18, 22], [23, 34], [35, 37], [38, 44], [45, 51], [52, 55], [56, 63], [64, 70], [71, 75], [76, 86], [87, 93], [94, 98], [99, 108], [108, 109]]}
{"doc_key": "ai-dev-291", "ner": [[3, 5, "conference"], [0, 1, "organisation"], [19, 20, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 19, 20, "topic", "", false, false], [0, 1, 3, 5, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["NIST", "'s", "annual", "Document", "Understanding", "Conferences", "have", "developed", "advanced", "evaluation", "criteria", "for", "techniques", "that", "take", "on", "the", "challenge", "of", "multi-document", "summarization", "."], "sentence-detokenized": "NIST's annual Document Understanding Conferences have developed advanced evaluation criteria for techniques that take on the challenge of multi-document summarization.", "token2charspan": [[0, 4], [4, 6], [7, 13], [14, 22], [23, 36], [37, 48], [49, 53], [54, 63], [64, 72], [73, 83], [84, 92], [93, 96], [97, 107], [108, 112], [113, 117], [118, 120], [121, 124], [125, 134], [135, 137], [138, 152], [153, 166], [166, 167]]}
{"doc_key": "ai-dev-292", "ner": [[0, 2, "product"], [25, 27, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 2, 25, 27, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "parallel", "manipulator", "is", "designed", "so", "that", "each", "chain", "is", "usually", "short", "and", "simple", "and", "can", "therefore", "be", "rigid", "against", "unwanted", "movements", ",", "compared", "to", "a", "serial", "manipulator", "."], "sentence-detokenized": "The parallel manipulator is designed so that each chain is usually short and simple and can therefore be rigid against unwanted movements, compared to a serial manipulator.", "token2charspan": [[0, 3], [4, 12], [13, 24], [25, 27], [28, 36], [37, 39], [40, 44], [45, 49], [50, 55], [56, 58], [59, 66], [67, 72], [73, 76], [77, 83], [84, 87], [88, 91], [92, 101], [102, 104], [105, 110], [111, 118], [119, 127], [128, 137], [137, 138], [139, 147], [148, 150], [151, 152], [153, 159], [160, 171], [171, 172]]}
{"doc_key": "ai-dev-293", "ner": [[26, 26, "misc"], [28, 30, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "the", "manipulator", "that", "makes", "the", "robot", "move", ",", "and", "the", "design", "of", "these", "systems", "can", "be", "classified", "into", "several", "general", "types", ",", "such", "as", "SCARA", "and", "Cartesian", "coordinate", "robots", ",", "which", "use", "different", "coordinate", "systems", "to", "control", "the", "machine", "'s", "arms", "."], "sentence-detokenized": "It is the manipulator that makes the robot move, and the design of these systems can be classified into several general types, such as SCARA and Cartesian coordinate robots, which use different coordinate systems to control the machine's arms.", "token2charspan": [[0, 2], [3, 5], [6, 9], [10, 21], [22, 26], [27, 32], [33, 36], [37, 42], [43, 47], [47, 48], [49, 52], [53, 56], [57, 63], [64, 66], [67, 72], [73, 80], [81, 84], [85, 87], [88, 98], [99, 103], [104, 111], [112, 119], [120, 125], [125, 126], [127, 131], [132, 134], [135, 140], [141, 144], [145, 154], [155, 165], [166, 172], [172, 173], [174, 179], [180, 183], [184, 193], [194, 204], [205, 212], [213, 215], [216, 223], [224, 227], [228, 235], [235, 237], [238, 242], [242, 243]]}
{"doc_key": "ai-dev-294", "ner": [[0, 3, "country"], [11, 14, "organisation"], [17, 22, "organisation"], [25, 28, "organisation"], [31, 33, "organisation"], [36, 42, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 14, 0, 3, "physical", "", false, false], [17, 22, 0, 3, "physical", "", false, false], [25, 28, 0, 3, "physical", "", false, false], [31, 33, 0, 3, "physical", "", false, false], [36, 42, 0, 3, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "United", "States", ",", "he", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "Linguistic", "Society", "of", "America", ",", "the", "American", "Philosophical", "Association", "and", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In the United States, he is a member of the National Academy of Sciences, the American Academy of Arts and Sciences, the Linguistic Society of America, the American Philosophical Association and the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 20], [20, 21], [22, 24], [25, 27], [28, 29], [30, 36], [37, 39], [40, 43], [44, 52], [53, 60], [61, 63], [64, 72], [72, 73], [74, 77], [78, 86], [87, 94], [95, 97], [98, 102], [103, 106], [107, 115], [115, 116], [117, 120], [121, 131], [132, 139], [140, 142], [143, 150], [150, 151], [152, 155], [156, 164], [165, 178], [179, 190], [191, 194], [195, 198], [199, 207], [208, 219], [220, 223], [224, 227], [228, 239], [240, 242], [243, 250], [250, 251]]}
{"doc_key": "ai-dev-295", "ner": [[9, 10, "algorithm"], [11, 13, "algorithm"], [20, 20, "algorithm"], [27, 28, "algorithm"], [29, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 10, 20, 20, "named", "", false, false], [11, 13, 9, 10, "named", "", false, false], [20, 20, 27, 28, "compare", "", false, false], [20, 20, 29, 34, "related-to", "performs", false, false], [27, 28, 29, 34, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["They", "rose", "to", "prominence", "with", "the", "popularity", "of", "the", "support", "vector", "machine", "(", "SVM", ")", "in", "the", "1990s", ",", "when", "SVM", "was", "found", "to", "be", "competitive", "with", "neural", "networks", "in", "areas", "such", "as", "handwriting", "recognition", "."], "sentence-detokenized": "They rose to prominence with the popularity of the support vector machine (SVM) in the 1990s, when SVM was found to be competitive with neural networks in areas such as handwriting recognition.", "token2charspan": [[0, 4], [5, 9], [10, 12], [13, 23], [24, 28], [29, 32], [33, 43], [44, 46], [47, 50], [51, 58], [59, 65], [66, 73], [74, 75], [75, 78], [78, 79], [80, 82], [83, 86], [87, 92], [92, 93], [94, 98], [99, 102], [103, 106], [107, 112], [113, 115], [116, 118], [119, 130], [131, 135], [136, 142], [143, 151], [152, 154], [155, 160], [161, 165], [166, 168], [169, 180], [181, 192], [192, 193]]}
{"doc_key": "ai-dev-296", "ner": [[2, 3, "misc"], [9, 9, "misc"], [13, 17, "algorithm"], [25, 26, "misc"], [30, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 9, 9, "usage", "", false, false], [2, 3, 25, 26, "usage", "", false, false], [9, 9, 13, 17, "origin", "result_of_algorithm", false, false], [25, 26, 30, 32, "origin", "result_of_algorithm", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "empirical", "whitening", "transformation", "is", "obtained", "by", "estimating", "the", "covariance", "(", "e.g.", ",", "using", "the", "maximum", "likelihood", "method", ")", "and", "then", "constructing", "a", "corresponding", "estimated", "whitening", "matrix", "(", "e.g.", ",", "using", "Cholesky", "decomposition", ")", "."], "sentence-detokenized": "The empirical whitening transformation is obtained by estimating the covariance (e.g., using the maximum likelihood method) and then constructing a corresponding estimated whitening matrix (e.g., using Cholesky decomposition).", "token2charspan": [[0, 3], [4, 13], [14, 23], [24, 38], [39, 41], [42, 50], [51, 53], [54, 64], [65, 68], [69, 79], [80, 81], [81, 85], [85, 86], [87, 92], [93, 96], [97, 104], [105, 115], [116, 122], [122, 123], [124, 127], [128, 132], [133, 145], [146, 147], [148, 161], [162, 171], [172, 181], [182, 188], [189, 190], [190, 194], [194, 195], [196, 201], [202, 210], [211, 224], [224, 225], [225, 226]]}
{"doc_key": "ai-dev-297", "ner": [[0, 2, "organisation"], [8, 10, "product"], [24, 25, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 0, 2, "artifact", "", false, false], [24, 25, 0, 2, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["IAI", "is", "the", "world", "'s", "largest", "manufacturer", "of", "Cartesian", "coordinate", "robots", "and", "an", "established", "market", "leader", "in", "low", "-", "cost", ",", "high", "-", "performance", "SCARA", "robots", "."], "sentence-detokenized": "IAI is the world's largest manufacturer of Cartesian coordinate robots and an established market leader in low-cost, high-performance SCARA robots.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [16, 18], [19, 26], [27, 39], [40, 42], [43, 52], [53, 63], [64, 70], [71, 74], [75, 77], [78, 89], [90, 96], [97, 103], [104, 106], [107, 110], [110, 111], [111, 115], [115, 116], [117, 121], [121, 122], [122, 133], [134, 139], [140, 146], [146, 147]]}
{"doc_key": "ai-dev-298", "ner": [[11, 12, "field"], [14, 15, "field"], [17, 18, "field"], [20, 21, "field"], [23, 24, "field"], [26, 27, "field"], [29, 29, "field"], [31, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["Formal", "concept", "analysis", "is", "applied", "in", "practice", "in", "fields", "such", "as", "data", "mining", ",", "text", "mining", ",", "machine", "learning", ",", "knowledge", "management", ",", "semantic", "web", ",", "software", "development", ",", "chemistry", "and", "biology", "."], "sentence-detokenized": "Formal concept analysis is applied in practice in fields such as data mining, text mining, machine learning, knowledge management, semantic web, software development, chemistry and biology.", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 26], [27, 34], [35, 37], [38, 46], [47, 49], [50, 56], [57, 61], [62, 64], [65, 69], [70, 76], [76, 77], [78, 82], [83, 89], [89, 90], [91, 98], [99, 107], [107, 108], [109, 118], [119, 129], [129, 130], [131, 139], [140, 143], [143, 144], [145, 153], [154, 165], [165, 166], [167, 176], [177, 180], [181, 188], [188, 189]]}
{"doc_key": "ai-dev-299", "ner": [[0, 2, "field"], [4, 6, "field"], [10, 11, "field"], [17, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 6, 17, 19, "part-of", "", false, false], [10, 11, 4, 6, "named", "", false, false], [17, 19, 0, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 2, 3], "sentence": ["In", "computer", "science", ",", "computational", "learning", "theory", "(", "or", "just", "learning", "theory", ")", "is", "a", "branch", "of", "artificial", "intelligence", "that", "studies", "the", "design", "and", "analysis", "of", "machine", "learning", "algorithms", "."], "sentence-detokenized": "In computer science, computational learning theory (or just learning theory) is a branch of artificial intelligence that studies the design and analysis of machine learning algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 34], [35, 43], [44, 50], [51, 52], [52, 54], [55, 59], [60, 68], [69, 75], [75, 76], [77, 79], [80, 81], [82, 88], [89, 91], [92, 102], [103, 115], [116, 120], [121, 128], [129, 132], [133, 139], [140, 143], [144, 152], [153, 155], [156, 163], [164, 172], [173, 183], [183, 184]]}
{"doc_key": "ai-dev-300", "ner": [[0, 1, "algorithm"], [3, 6, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 6, 0, 1, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "Filtering", "(", "CF", ")", "is", "a", "technique", "used", "in", "recommender", "systems", "."], "sentence-detokenized": "Collaborative Filtering (CF) is a technique used in recommender systems.", "token2charspan": [[0, 13], [14, 23], [24, 25], [25, 27], [27, 28], [29, 31], [32, 33], [34, 43], [44, 48], [49, 51], [52, 63], [64, 71], [71, 72]]}
{"doc_key": "ai-dev-301", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "FALSE", "positivity", "rate", "is", "the", "proportion", "of", "all", "negative", "test", "results", "that", "still", "give", "a", "positive", "test", "result", ",", "i.e.", "the", "conditional", "probability", "of", "a", "positive", "test", "result", "if", "there", "was", "no", "event", "."], "sentence-detokenized": "The FALSE positivity rate is the proportion of all negative test results that still give a positive test result, i.e. the conditional probability of a positive test result if there was no event.", "token2charspan": [[0, 3], [4, 9], [10, 20], [21, 25], [26, 28], [29, 32], [33, 43], [44, 46], [47, 50], [51, 59], [60, 64], [65, 72], [73, 77], [78, 83], [84, 88], [89, 90], [91, 99], [100, 104], [105, 111], [111, 112], [113, 117], [118, 121], [122, 133], [134, 145], [146, 148], [149, 150], [151, 159], [160, 164], [165, 171], [172, 174], [175, 180], [181, 184], [185, 187], [188, 193], [193, 194]]}
{"doc_key": "ai-dev-302", "ner": [[1, 15, "misc"], [37, 37, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 15, 37, 37, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "VLDB", "'", "8", ":", "Proceedings", "of", "the", "34th", "International", "Conference", "on", "Very", "Large", "Data", "Bases", ",", "pages", "422--433", ".", "showed", "that", "the", "given", "values", "of", "mathC", "/", "math", "and", "mathK", "/", "math", "generally", "imply", "relatively", "low", "accuracy", "for", "iteratively", "computed", "SimRank", "scores", "."], "sentence-detokenized": "In VLDB '8: Proceedings of the 34th International Conference on Very Large Data Bases, pages 422--433. showed that the given values of mathC / math and mathK / math generally imply relatively low accuracy for iteratively computed SimRank scores.", "token2charspan": [[0, 2], [3, 7], [8, 9], [9, 10], [10, 11], [12, 23], [24, 26], [27, 30], [31, 35], [36, 49], [50, 60], [61, 63], [64, 68], [69, 74], [75, 79], [80, 85], [85, 86], [87, 92], [93, 101], [101, 102], [103, 109], [110, 114], [115, 118], [119, 124], [125, 131], [132, 134], [135, 140], [141, 142], [143, 147], [148, 151], [152, 157], [158, 159], [160, 164], [165, 174], [175, 180], [181, 191], [192, 195], [196, 204], [205, 208], [209, 220], [221, 229], [230, 237], [238, 244], [244, 245]]}
{"doc_key": "ai-dev-303", "ner": [[5, 6, "misc"], [7, 7, "misc"], [14, 14, "person"], [16, 18, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 5, 6, "general-affiliation", "", false, false], [7, 7, 14, 14, "artifact", "", false, false], [7, 7, 16, 18, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "June", "2015", ",", "the", "science", "drama", "Sense8", "debuted", ",", "written", "and", "produced", "by", "Wachowski", "and", "J.", "Michael", "Straczynski", "."], "sentence-detokenized": "In June 2015, the science drama Sense8 debuted, written and produced by Wachowski and J. Michael Straczynski.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 17], [18, 25], [26, 31], [32, 38], [39, 46], [46, 47], [48, 55], [56, 59], [60, 68], [69, 71], [72, 81], [82, 85], [86, 88], [89, 96], [97, 108], [108, 109]]}
{"doc_key": "ai-dev-304", "ner": [[1, 1, "misc"], [6, 8, "product"], [27, 29, "misc"], [36, 36, "country"], [38, 38, "country"], [40, 40, "country"], [42, 42, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 1, 6, 8, "topic", "", false, false], [36, 36, 27, 29, "type-of", "", false, false], [38, 38, 27, 29, "type-of", "", false, false], [40, 40, 27, 29, "type-of", "", false, false], [42, 42, 27, 29, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Although", "Eurotra", "never", "delivered", "a", "functioning", "multilingual", "language", "system", ",", "the", "project", "had", "far", "-", "reaching", ",", "long", "-", "term", "effects", "on", "the", "burgeoning", "language", "industries", "of", "European", "Member", "States", ",", "particularly", "the", "southern", "countries", "of", "Greece", ",", "Italy", ",", "Spain", "and", "Portugal", "."], "sentence-detokenized": "Although Eurotra never delivered a functioning multilingual language system, the project had far-reaching, long-term effects on the burgeoning language industries of European Member States, particularly the southern countries of Greece, Italy, Spain and Portugal.", "token2charspan": [[0, 8], [9, 16], [17, 22], [23, 32], [33, 34], [35, 46], [47, 59], [60, 68], [69, 75], [75, 76], [77, 80], [81, 88], [89, 92], [93, 96], [96, 97], [97, 105], [105, 106], [107, 111], [111, 112], [112, 116], [117, 124], [125, 127], [128, 131], [132, 142], [143, 151], [152, 162], [163, 165], [166, 174], [175, 181], [182, 188], [188, 189], [190, 202], [203, 206], [207, 215], [216, 225], [226, 228], [229, 235], [235, 236], [237, 242], [242, 243], [244, 249], [250, 253], [254, 262], [262, 263]]}
{"doc_key": "ai-dev-305", "ner": [[0, 0, "algorithm"], [5, 8, "task"], [16, 20, "task"]], "ner_mapping_to_source": [0, 1, 3], "relations": [[5, 8, 0, 0, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Autocoding", "has", "been", "successfully", "applied", "to", "machine", "translation", "of", "human", "languages", ",", "commonly", "referred", "to", "as", "neural", "machine", "translation", "(", "NMT", ")", "."], "sentence-detokenized": "Autocoding has been successfully applied to machine translation of human languages, commonly referred to as neural machine translation (NMT).", "token2charspan": [[0, 10], [11, 14], [15, 19], [20, 32], [33, 40], [41, 43], [44, 51], [52, 63], [64, 66], [67, 72], [73, 82], [82, 83], [84, 92], [93, 101], [102, 104], [105, 107], [108, 114], [115, 122], [123, 134], [135, 136], [136, 139], [139, 140], [140, 141]]}
{"doc_key": "ai-dev-306", "ner": [[7, 9, "metrics"], [11, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Popular", "examples", "of", "probabilistic", "fitness", "functions", "include", "maximum", "likelihood", "estimation", "and", "hinge", "loss", "."], "sentence-detokenized": "Popular examples of probabilistic fitness functions include maximum likelihood estimation and hinge loss.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 33], [34, 41], [42, 51], [52, 59], [60, 67], [68, 78], [79, 89], [90, 93], [94, 99], [100, 104], [104, 105]]}
{"doc_key": "ai-dev-307", "ner": [[0, 1, "field"], [11, 12, "task"], [14, 15, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 0, 1, "part-of", "", false, false], [14, 15, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Data", "mining", "is", "a", "related", "field", "of", "research", "that", "focuses", "on", "analysing", "data", "through", "unsupervised", "learning", "."], "sentence-detokenized": "Data mining is a related field of research that focuses on analysing data through unsupervised learning.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 16], [17, 24], [25, 30], [31, 33], [34, 42], [43, 47], [48, 55], [56, 58], [59, 68], [69, 73], [74, 81], [82, 94], [95, 103], [103, 104]]}
{"doc_key": "ai-dev-308", "ner": [[0, 1, "algorithm"], [13, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 13, 14, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "filtering", "involves", "techniques", "to", "connect", "people", "with", "similar", "interests", "and", "create", "a", "recommendation", "system", "based", "on", "this", "."], "sentence-detokenized": "Collaborative filtering involves techniques to connect people with similar interests and create a recommendation system based on this.", "token2charspan": [[0, 13], [14, 23], [24, 32], [33, 43], [44, 46], [47, 54], [55, 61], [62, 66], [67, 74], [75, 84], [85, 88], [89, 95], [96, 97], [98, 112], [113, 119], [120, 125], [126, 128], [129, 133], [133, 134]]}
{"doc_key": "ai-dev-309", "ner": [[1, 6, "algorithm"], [15, 18, "product"]], "ner_mapping_to_source": [0, 2], "relations": [[15, 18, 1, 6, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Several", "WordNet", "-", "based", "word", "similarity", "algorithms", "have", "been", "implemented", "in", "a", "Perl", "package", "called", "WordNet", ":", ":", "Similarity", "."], "sentence-detokenized": "Several WordNet-based word similarity algorithms have been implemented in a Perl package called WordNet:: Similarity.", "token2charspan": [[0, 7], [8, 15], [15, 16], [16, 21], [22, 26], [27, 37], [38, 48], [49, 53], [54, 58], [59, 70], [71, 73], [74, 75], [76, 80], [81, 88], [89, 95], [96, 103], [103, 104], [104, 105], [106, 116], [116, 117]]}
{"doc_key": "ai-dev-310", "ner": [[12, 13, "conference"], [15, 15, "conference"], [4, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[15, 15, 12, 13, "named", "", false, false], [4, 5, 12, 13, "temporal", "", false, false], [7, 8, 12, 13, "temporal", "", false, false], [10, 11, 12, 13, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Another", "article", "presented", "by", "Erik", "Miller", ",", "Nicholas", "Matsakis", "and", "Paul", "Viola", "in", "CVPR", "(", "CVPR", "2000", ")", "will", "also", "be", "discussed", "."], "sentence-detokenized": "Another article presented by Erik Miller, Nicholas Matsakis and Paul Viola in CVPR (CVPR 2000) will also be discussed.", "token2charspan": [[0, 7], [8, 15], [16, 25], [26, 28], [29, 33], [34, 40], [40, 41], [42, 50], [51, 59], [60, 63], [64, 68], [69, 74], [75, 77], [78, 82], [83, 84], [84, 88], [89, 93], [93, 94], [95, 99], [100, 104], [105, 107], [108, 117], [117, 118]]}
{"doc_key": "ai-dev-311", "ner": [[0, 0, "algorithm"], [8, 12, "misc"], [15, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 15, 17, "compare", "", false, false], [15, 17, 8, 12, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["QC", "has", "not", "been", "evaluated", "against", "traditional", "modern", "clustering", "algorithms", ",", "with", "the", "exception", "of", "the", "Jaccard", "index", "."], "sentence-detokenized": "QC has not been evaluated against traditional modern clustering algorithms, with the exception of the Jaccard index.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 15], [16, 25], [26, 33], [34, 45], [46, 52], [53, 63], [64, 74], [74, 75], [76, 80], [81, 84], [85, 94], [95, 97], [98, 101], [102, 109], [110, 115], [115, 116]]}
{"doc_key": "ai-dev-312", "ner": [[2, 7, "misc"], [8, 12, "misc"], [14, 16, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 12, 2, 7, "physical", "", false, false], [8, 12, 14, 16, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "the", "VEX", "World", "Robotics", "Championships", ",", "a", "Parade", "of", "Nations", "will", "take", "place", "in", "Freedom", "Hall", ",", "with", "hundreds", "of", "students", "from", "over", "30", "countries", "."], "sentence-detokenized": "During the VEX World Robotics Championships, a Parade of Nations will take place in Freedom Hall, with hundreds of students from over 30 countries.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 20], [21, 29], [30, 43], [43, 44], [45, 46], [47, 53], [54, 56], [57, 64], [65, 69], [70, 74], [75, 80], [81, 83], [84, 91], [92, 96], [96, 97], [98, 102], [103, 111], [112, 114], [115, 123], [124, 128], [129, 133], [134, 136], [137, 146], [146, 147]]}
{"doc_key": "ai-dev-313", "ner": [[8, 10, "metrics"], [5, 7, "metrics"], [15, 17, "metrics"], [13, 13, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 7, 8, 10, "named", "", false, false], [13, 13, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Other", "measures", "of", "accuracy", "include", "SWER", "(", "Single", "Word", "Error", "Rate", ")", "and", "CSR", "(", "Command", "Success", "Rate", ")", "."], "sentence-detokenized": "Other measures of accuracy include SWER (Single Word Error Rate) and CSR (Command Success Rate).", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [27, 34], [35, 39], [40, 41], [41, 47], [48, 52], [53, 58], [59, 63], [63, 64], [65, 68], [69, 72], [73, 74], [74, 81], [82, 89], [90, 94], [94, 95], [95, 96]]}
{"doc_key": "ai-dev-314", "ner": [[7, 8, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "presented", "their", "methodology", "and", "results", "at", "SIGGRAPH", "2000", "."], "sentence-detokenized": "They presented their methodology and results at SIGGRAPH 2000.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 32], [33, 36], [37, 44], [45, 47], [48, 56], [57, 61], [61, 62]]}
{"doc_key": "ai-dev-315", "ner": [[0, 5, "conference"], [8, 18, "misc"], [16, 18, "conference"], [22, 27, "researcher"], [35, 36, "researcher"], [40, 42, "conference"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "KDD", "conference", "originated", "from", "the", "KDD", "(", "Knowledge", "Discovery", "and", "Data", "Mining", ")", "workshops", "of", "the", "AAAI", "conferences", ",", "organised", "by", "Gregory", "I", ".", "Piatetsky", "-", "Shapiro", "in", "1989", ",", "1991", "and", "1993", "and", "Usama", "Fayyad", "in", "1994", ".", "Machinery", "|", "ACM", "."], "sentence-detokenized": "The KDD conference originated from the KDD (Knowledge Discovery and Data Mining) workshops of the AAAI conferences, organised by Gregory I. Piatetsky-Shapiro in 1989, 1991 and 1993 and Usama Fayyad in 1994. Machinery | ACM.", "token2charspan": [[0, 3], [4, 7], [8, 18], [19, 29], [30, 34], [35, 38], [39, 42], [43, 44], [44, 53], [54, 63], [64, 67], [68, 72], [73, 79], [79, 80], [81, 90], [91, 93], [94, 97], [98, 102], [103, 114], [114, 115], [116, 125], [126, 128], [129, 136], [137, 138], [138, 139], [140, 149], [149, 150], [150, 157], [158, 160], [161, 165], [165, 166], [167, 171], [172, 175], [176, 180], [181, 184], [185, 190], [191, 197], [198, 200], [201, 205], [205, 206], [207, 216], [217, 218], [219, 222], [222, 223]]}
{"doc_key": "ai-dev-316", "ner": [[9, 10, "conference"], [12, 12, "conference"], [18, 21, "organisation"], [16, 23, "organisation"], [30, 31, "conference"], [27, 33, "conference"], [37, 43, "conference"], [45, 45, "conference"], [52, 54, "conference"], [56, 56, "conference"], [62, 65, "conference"], [64, 67, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[12, 12, 9, 10, "named", "", false, false], [16, 23, 18, 21, "named", "", false, false], [27, 33, 30, 31, "named", "", false, false], [45, 45, 37, 43, "named", "", false, false], [56, 56, 52, 54, "named", "", false, false], [64, 67, 62, 65, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["He", "is", "an", "elected", "member", "of", "the", "Association", "for", "Computing", "Machinery", "(", "ACM", ")", ",", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", ",", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", ",", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "the", "American", "Association", "for", "Advancement", "of", "Science", "(", "AAAS", ")", "and", "the", "Society", "for", "Optics", "and", "Photonics", "Technology", "(", "SPIE", ")", "."], "sentence-detokenized": "He is an elected member of the Association for Computing Machinery (ACM), the Institute of Electrical and Electronics Engineers (IEEE), the International Association for Pattern Recognition (IAPR), the Association for the Advancement of Artificial Intelligence (AAAI), the American Association for Advancement of Science (AAAS) and the Society for Optics and Photonics Technology (SPIE).", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 16], [17, 23], [24, 26], [27, 30], [31, 42], [43, 46], [47, 56], [57, 66], [67, 68], [68, 71], [71, 72], [72, 73], [74, 77], [78, 87], [88, 90], [91, 101], [102, 105], [106, 117], [118, 127], [128, 129], [129, 133], [133, 134], [134, 135], [136, 139], [140, 153], [154, 165], [166, 169], [170, 177], [178, 189], [190, 191], [191, 195], [195, 196], [196, 197], [198, 201], [202, 213], [214, 217], [218, 221], [222, 233], [234, 236], [237, 247], [248, 260], [261, 262], [262, 266], [266, 267], [267, 268], [269, 272], [273, 281], [282, 293], [294, 297], [298, 309], [310, 312], [313, 320], [321, 322], [322, 326], [326, 327], [328, 331], [332, 335], [336, 343], [344, 347], [348, 354], [355, 358], [359, 368], [369, 379], [380, 381], [381, 385], [385, 386], [386, 387]]}
{"doc_key": "ai-dev-317", "ner": [[0, 1, "field"], [3, 4, "field"], [16, 17, "field"], [30, 31, "field"], [50, 51, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 16, 17, "named", "", false, false], [3, 4, 30, 31, "named", "", false, false], [30, 31, 50, 51, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Machine", "learning", "and", "data", "mining", "often", "use", "the", "same", "methods", "and", "overlap", "significantly", ",", "but", "while", "machine", "learning", "focuses", "on", "prediction", "based", "on", "known", "features", "learned", "from", "training", "data", ",", "data", "mining", "focuses", "on", "finding", "(", "previously", ")", "unknown", "features", "in", "the", "data", "(", "this", "is", "the", "analysis", "phase", "of", "database", "mining", ")", "."], "sentence-detokenized": "Machine learning and data mining often use the same methods and overlap significantly, but while machine learning focuses on prediction based on known features learned from training data, data mining focuses on finding (previously) unknown features in the data (this is the analysis phase of database mining).", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 25], [26, 32], [33, 38], [39, 42], [43, 46], [47, 51], [52, 59], [60, 63], [64, 71], [72, 85], [85, 86], [87, 90], [91, 96], [97, 104], [105, 113], [114, 121], [122, 124], [125, 135], [136, 141], [142, 144], [145, 150], [151, 159], [160, 167], [168, 172], [173, 181], [182, 186], [186, 187], [188, 192], [193, 199], [200, 207], [208, 210], [211, 218], [219, 220], [220, 230], [230, 231], [232, 239], [240, 248], [249, 251], [252, 255], [256, 260], [261, 262], [262, 266], [267, 269], [270, 273], [274, 282], [283, 288], [289, 291], [292, 300], [301, 307], [307, 308], [308, 309]]}
{"doc_key": "ai-dev-318", "ner": [[0, 0, "product"], [4, 4, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 4, "general-affiliation", "", false, false], [0, 0, 4, 4, "related-to", "runs_on", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Indy", "is", "written", "in", "Java", ",", "so", "it", "works", "on", "most", "modern", "operating", "systems", "."], "sentence-detokenized": "Indy is written in Java, so it works on most modern operating systems.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 23], [23, 24], [25, 27], [28, 30], [31, 36], [37, 39], [40, 44], [45, 51], [52, 61], [62, 69], [69, 70]]}
{"doc_key": "ai-dev-319", "ner": [[0, 0, "algorithm"], [6, 6, "algorithm"], [3, 9, "algorithm"], [15, 16, "algorithm"], [17, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 6, "type-of", "", true, false], [3, 9, 6, 6, "named", "", false, false], [15, 16, 6, 6, "type-of", "", true, false], [17, 19, 15, 16, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["NMF", "is", "an", "application", "of", "nonnegative", "quadratic", "programming", "(", "NQP", ")", ",", "just", "like", "the", "support", "vector", "machine", "(", "SVM", ")", "."], "sentence-detokenized": "NMF is an application of nonnegative quadratic programming (NQP), just like the support vector machine (SVM).", "token2charspan": [[0, 3], [4, 6], [7, 9], [10, 21], [22, 24], [25, 36], [37, 46], [47, 58], [59, 60], [60, 63], [63, 64], [64, 65], [66, 70], [71, 75], [76, 79], [80, 87], [88, 94], [95, 102], [103, 104], [104, 107], [107, 108], [108, 109]]}
{"doc_key": "ai-dev-320", "ner": [[8, 9, "misc"], [12, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 12, 12, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["The", "method", "is", "based", "on", "the", "estimation", "of", "conditional", "probabilities", "using", "a", "non-parametric", "maximum", "likelihood", "method", ",", "which", "leads", "to", "the", "following", "results"], "sentence-detokenized": "The method is based on the estimation of conditional probabilities using a non-parametric maximum likelihood method, which leads to the following results", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 26], [27, 37], [38, 40], [41, 52], [53, 66], [67, 72], [73, 74], [75, 89], [90, 97], [98, 108], [109, 115], [115, 116], [117, 122], [123, 128], [129, 131], [132, 135], [136, 145], [146, 153]]}
{"doc_key": "ai-dev-321", "ner": [[7, 7, "algorithm"], [9, 11, "algorithm"], [13, 15, "metrics"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Basic", "concepts", "related", "to", "spectral", "estimation", "include", "autocorrelation", ",", "multivariate", "Fourier", "transform", ",", "mean", "square", "error", "and", "entropy", "."], "sentence-detokenized": "Basic concepts related to spectral estimation include autocorrelation, multivariate Fourier transform, mean square error and entropy.", "token2charspan": [[0, 5], [6, 14], [15, 22], [23, 25], [26, 34], [35, 45], [46, 53], [54, 69], [69, 70], [71, 83], [84, 91], [92, 101], [101, 102], [103, 107], [108, 114], [115, 120], [121, 124], [125, 132], [132, 133]]}
{"doc_key": "ai-dev-322", "ner": [[0, 3, "algorithm"], [11, 11, "field"], [13, 13, "algorithm"], [15, 17, "algorithm"], [19, 20, "task"], [22, 22, "field"], [24, 24, "field"], [26, 27, "task"], [29, 30, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 3, 11, 11, "part-of", "", false, false], [0, 3, 13, 13, "part-of", "", false, false], [0, 3, 15, 17, "part-of", "", false, false], [0, 3, 19, 20, "part-of", "", false, false], [0, 3, 22, 22, "part-of", "", false, false], [0, 3, 24, 24, "part-of", "", false, false], [0, 3, 26, 27, "part-of", "", false, false], [0, 3, 29, 30, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "core", "methods", "have", "a", "wide", "range", "of", "applications", ",", "including", "geostatistics", ",", "kriging", ",", "inverse", "distance", "weighting", ",", "3D", "reconstruction", ",", "bioinformatics", ",", "chemoinformatics", ",", "data", "mining", "and", "handwriting", "recognition", "."], "sentence-detokenized": "The core methods have a wide range of applications, including geostatistics, kriging, inverse distance weighting, 3D reconstruction, bioinformatics, chemoinformatics, data mining and handwriting recognition.", "token2charspan": [[0, 3], [4, 8], [9, 16], [17, 21], [22, 23], [24, 28], [29, 34], [35, 37], [38, 50], [50, 51], [52, 61], [62, 75], [75, 76], [77, 84], [84, 85], [86, 93], [94, 102], [103, 112], [112, 113], [114, 116], [117, 131], [131, 132], [133, 147], [147, 148], [149, 165], [165, 166], [167, 171], [172, 178], [179, 182], [183, 194], [195, 206], [206, 207]]}
{"doc_key": "ai-dev-323", "ner": [[16, 19, "product"], [15, 21, "product"], [26, 30, "product"], [32, 32, "product"], [35, 37, "product"], [39, 41, "product"], [43, 45, "product"], [47, 49, "product"], [53, 54, "product"], [56, 57, "product"], [61, 66, "product"], [69, 71, "product"]], "ner_mapping_to_source": [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[16, 19, 35, 37, "compare", "", false, false], [16, 19, 39, 41, "compare", "", false, false], [16, 19, 43, 45, "compare", "", false, false], [16, 19, 47, 49, "compare", "", false, false], [16, 19, 53, 54, "compare", "", false, false], [16, 19, 56, 57, "compare", "", false, false], [16, 19, 61, 66, "compare", "", false, false], [16, 19, 69, 71, "compare", "", false, false], [15, 21, 16, 19, "named", "", false, false], [26, 30, 35, 37, "compare", "", false, false], [26, 30, 39, 41, "compare", "", false, false], [26, 30, 43, 45, "compare", "", false, false], [26, 30, 47, 49, "compare", "", false, false], [26, 30, 53, 54, "compare", "", false, false], [26, 30, 56, 57, "compare", "", false, false], [26, 30, 61, 66, "compare", "", false, false], [26, 30, 69, 71, "compare", "", false, false], [32, 32, 26, 30, "named", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19], "sentence": ["Robots", "can", "be", "autonomous", "or", "semi-autonomous", "and", "range", "from", "humanoids", ",", "such", "as", "Honda", "'s", "Advanced", "Step", "in", "Innovative", "Mobility", "(", "ASIMO", ")", "and", "TOSY", "'s", "TOSY", "Ping", "Pong", "Playing", "Robot", "(", "TOPIO", ")", ",", "to", "industrial", "robots", ",", "medical", "surgical", "robots", ",", "patient", "assistant", "robots", ",", "dog", "therapy", "robots", ",", "collectively", "programmed", "swarm", "robots", ",", "UAV", "robots", "such", "as", "the", "General", "Atomics", "MQ", "-", "1", "Predator", "and", "even", "microscopic", "nanoelectronic", "robots", "."], "sentence-detokenized": "Robots can be autonomous or semi-autonomous and range from humanoids, such as Honda's Advanced Step in Innovative Mobility (ASIMO) and TOSY's TOSY Ping Pong Playing Robot (TOPIO), to industrial robots, medical surgical robots, patient assistant robots, dog therapy robots, collectively programmed swarm robots, UAV robots such as the General Atomics MQ-1 Predator and even microscopic nanoelectronic robots.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 24], [25, 27], [28, 43], [44, 47], [48, 53], [54, 58], [59, 68], [68, 69], [70, 74], [75, 77], [78, 83], [83, 85], [86, 94], [95, 99], [100, 102], [103, 113], [114, 122], [123, 124], [124, 129], [129, 130], [131, 134], [135, 139], [139, 141], [142, 146], [147, 151], [152, 156], [157, 164], [165, 170], [171, 172], [172, 177], [177, 178], [178, 179], [180, 182], [183, 193], [194, 200], [200, 201], [202, 209], [210, 218], [219, 225], [225, 226], [227, 234], [235, 244], [245, 251], [251, 252], [253, 256], [257, 264], [265, 271], [271, 272], [273, 285], [286, 296], [297, 302], [303, 309], [309, 310], [311, 314], [315, 321], [322, 326], [327, 329], [330, 333], [334, 341], [342, 349], [350, 352], [352, 353], [353, 354], [355, 363], [364, 367], [368, 372], [373, 384], [385, 399], [400, 406], [406, 407]]}
{"doc_key": "ai-dev-324", "ner": [[0, 0, "product"], [2, 3, "product"], [19, 27, "university"], [8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"], [17, 18, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 8, 9, "artifact", "", false, false], [0, 0, 11, 12, "artifact", "", false, false], [0, 0, 14, 15, "artifact", "", false, false], [0, 0, 17, 18, "artifact", "", false, false], [2, 3, 8, 9, "artifact", "", false, false], [2, 3, 11, 12, "artifact", "", false, false], [2, 3, 14, 15, "artifact", "", false, false], [2, 3, 17, 18, "artifact", "", false, false], [8, 9, 19, 27, "physical", "", false, false], [11, 12, 19, 27, "physical", "", false, false], [14, 15, 19, 27, "physical", "", false, false], [17, 18, 19, 27, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Freddy", "and", "Freddy", "II", "were", "robots", "built", "by", "Pat", "Ambler", ",", "Robin", "Popplestone", ",", "Austin", "Tate", "and", "Donald", "Mitchie", "at", "the", "University", "of", "Edinburgh", "'s", "School", "of", "Computing", ",", "capable", "of", "assembling", "blocks", "of", "wood", "in", "hours", "."], "sentence-detokenized": "Freddy and Freddy II were robots built by Pat Ambler, Robin Popplestone, Austin Tate and Donald Mitchie at the University of Edinburgh's School of Computing, capable of assembling blocks of wood in hours.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 20], [21, 25], [26, 32], [33, 38], [39, 41], [42, 45], [46, 52], [52, 53], [54, 59], [60, 71], [71, 72], [73, 79], [80, 84], [85, 88], [89, 95], [96, 103], [104, 106], [107, 110], [111, 121], [122, 124], [125, 134], [134, 136], [137, 143], [144, 146], [147, 156], [156, 157], [158, 165], [166, 168], [169, 179], [180, 186], [187, 189], [190, 194], [195, 197], [198, 203], [203, 204]]}
{"doc_key": "ai-dev-325", "ner": [[5, 5, "location"], [7, 7, "country"], [14, 17, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 7, 7, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "spent", "his", "childhood", "in", "Paris", ",", "France", ",", "where", "his", "parents", "had", "moved", "from", "Lithuania", "in", "the", "early", "1920s", "."], "sentence-detokenized": "He spent his childhood in Paris, France, where his parents had moved from Lithuania in the early 1920s.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 22], [23, 25], [26, 31], [31, 32], [33, 39], [39, 40], [41, 46], [47, 50], [51, 58], [59, 62], [63, 68], [69, 73], [74, 83], [84, 86], [87, 90], [91, 96], [97, 102], [102, 103]]}
{"doc_key": "ai-dev-326", "ner": [[2, 3, "researcher"], [6, 10, "misc"], [11, 16, "organisation"], [17, 18, "university"], [27, 33, "university"], [38, 41, "university"], [44, 46, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 3, 6, 10, "role", "", false, false], [2, 3, 17, 18, "physical", "", false, false], [2, 3, 27, 33, "role", "", false, false], [2, 3, 38, 41, "role", "", false, false], [2, 3, 44, 46, "role", "", false, false], [6, 10, 11, 16, "part-of", "", false, false], [11, 16, 17, 18, "part-of", "", false, false], [38, 41, 27, 33, "part-of", "", false, false], [44, 46, 27, 33, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Previously", ",", "Dr.", "Paulos", "was", "the", "Cooper-", "Siegel", "Associate", "Professor", "in", "the", "Department", "of", "Computer", "Science", "at", "Carnegie", "Mellon", "University", ",", "where", "he", "was", "a", "faculty", "member", "at", "the", "Human", "-", "Computer", "Interaction", "Institute", ",", "as", "well", "as", "at", "the", "Robotics", "Institute", "and", "the", "Entertainment", "Technology", "Center", "."], "sentence-detokenized": "Previously, Dr. Paulos was the Cooper-Siegel Associate Professor in the Department of Computer Science at Carnegie Mellon University, where he was a faculty member at the Human-Computer Interaction Institute, as well as at the Robotics Institute and the Entertainment Technology Center.", "token2charspan": [[0, 10], [10, 11], [12, 15], [16, 22], [23, 26], [27, 30], [31, 38], [38, 44], [45, 54], [55, 64], [65, 67], [68, 71], [72, 82], [83, 85], [86, 94], [95, 102], [103, 105], [106, 114], [115, 121], [122, 132], [132, 133], [134, 139], [140, 142], [143, 146], [147, 148], [149, 156], [157, 163], [164, 166], [167, 170], [171, 176], [176, 177], [177, 185], [186, 197], [198, 207], [207, 208], [209, 211], [212, 216], [217, 219], [220, 222], [223, 226], [227, 235], [236, 245], [246, 249], [250, 253], [254, 267], [268, 278], [279, 285], [285, 286]]}
{"doc_key": "ai-dev-327", "ner": [[3, 4, "researcher"], [5, 7, "university"], [10, 11, "product"], [16, 20, "product"], [24, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 5, 7, "physical", "", false, false], [3, 4, 5, 7, "role", "", false, false], [10, 11, 3, 4, "artifact", "", false, false], [10, 11, 16, 20, "type-of", "", false, false], [10, 11, 24, 25, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1969", ",", "Victor", "Scheinman", "at", "Stanford", "University", "invented", "the", "Stanford", "Arm", ",", "a", "fully", "electric", "6", "-", "axis", "articulated", "robot", "designed", "to", "enable", "arm", "solution", "."], "sentence-detokenized": "In 1969, Victor Scheinman at Stanford University invented the Stanford Arm, a fully electric 6-axis articulated robot designed to enable arm solution.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 25], [26, 28], [29, 37], [38, 48], [49, 57], [58, 61], [62, 70], [71, 74], [74, 75], [76, 77], [78, 83], [84, 92], [93, 94], [94, 95], [95, 99], [100, 111], [112, 117], [118, 126], [127, 129], [130, 136], [137, 140], [141, 149], [149, 150]]}
{"doc_key": "ai-dev-328", "ner": [[5, 5, "product"], [15, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 15, 16, "related-to", "", false, false], [5, 5, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "creation", "and", "implementation", "of", "chatbots", "is", "still", "an", "emerging", "field", ",", "strongly", "related", "to", "artificial", "intelligence", "and", "machine", "learning", ",", "so", "while", "the", "solutions", "offered", "have", "obvious", "advantages", ",", "they", "have", "some", "important", "limitations", "in", "terms", "of", "functionality", "and", "use", "cases", "."], "sentence-detokenized": "The creation and implementation of chatbots is still an emerging field, strongly related to artificial intelligence and machine learning, so while the solutions offered have obvious advantages, they have some important limitations in terms of functionality and use cases.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 31], [32, 34], [35, 43], [44, 46], [47, 52], [53, 55], [56, 64], [65, 70], [70, 71], [72, 80], [81, 88], [89, 91], [92, 102], [103, 115], [116, 119], [120, 127], [128, 136], [136, 137], [138, 140], [141, 146], [147, 150], [151, 160], [161, 168], [169, 173], [174, 181], [182, 192], [192, 193], [194, 198], [199, 203], [204, 208], [209, 218], [219, 230], [231, 233], [234, 239], [240, 242], [243, 256], [257, 260], [261, 264], [265, 270], [270, 271]]}
{"doc_key": "ai-dev-329", "ner": [[0, 1, "university"], [4, 5, "product"], [16, 17, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 0, 1, "part-of", "", true, false], [16, 17, 4, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Carnegie", "Mellon", "University", "'s", "Sphinx", "toolkit", "is", "one", "place", "to", "start", "learning", "about", "and", "experimenting", "with", "speech", "recognition", "."], "sentence-detokenized": "Carnegie Mellon University's Sphinx toolkit is one place to start learning about and experimenting with speech recognition.", "token2charspan": [[0, 8], [9, 15], [16, 26], [26, 28], [29, 35], [36, 43], [44, 46], [47, 50], [51, 56], [57, 59], [60, 65], [66, 74], [75, 80], [81, 84], [85, 98], [99, 103], [104, 110], [111, 122], [122, 123]]}
{"doc_key": "ai-dev-330", "ner": [[2, 3, "misc"], [13, 17, "misc"], [19, 19, "misc"], [24, 24, "university"], [25, 26, "location"], [28, 29, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 13, 17, "temporal", "", false, false], [19, 19, 13, 17, "named", "", false, false], [19, 19, 25, 26, "physical", "", false, false], [24, 24, 19, 19, "role", "", false, false], [25, 26, 28, 29, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "official", "RoboCup", "competition", "was", "preceded", "by", "the", "(", "often", "unrecognised", ")", "first", "international", "micro", "-robot", "football", "tournament", "(", "MIROSOT", ")", ",", "organised", "by", "KAIST", "in", "Taejon", ",", "Korea", "in", "November", "1996", "."], "sentence-detokenized": "The official RoboCup competition was preceded by the (often unrecognised) first international micro-robot football tournament (MIROSOT), organised by KAIST in Taejon, Korea in November 1996.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 32], [33, 36], [37, 45], [46, 48], [49, 52], [53, 54], [54, 59], [60, 72], [72, 73], [74, 79], [80, 93], [94, 99], [99, 105], [106, 114], [115, 125], [126, 127], [127, 134], [134, 135], [135, 136], [137, 146], [147, 149], [150, 155], [156, 158], [159, 165], [165, 166], [167, 172], [173, 175], [176, 184], [185, 189], [189, 190]]}
{"doc_key": "ai-dev-331", "ner": [[31, 33, "misc"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", "to", "the", "normal", "serial", "loss", "calculation", "(", "1-", "yf", "(", "x", ")", ")", "for", "(", "1-", "yf", "(", "x", ")", ")", "_", "+", "/", "math", "for", "signed", "data", ",", "the", "loss", "function", "math", "(", "-", "1", "|", "f", "(", "x", ")", "|", ")", "_", "+", "/", "math", "is", "introduced", "for", "unsigned", "data", "by", "giving", "mathy", "=\\", "the", "operator", "name", "{", "sign", "}", "{", "f", "(", "x", ")", "}", "/", "math", "."], "sentence-detokenized": "In addition to the normal serial loss calculation (1-yf (x)) for (1-yf (x)) _ + / math for signed data, the loss function math (-1 | f (x) |) _ + / math is introduced for unsigned data by giving mathy =\\ the operator name {sign} {f (x)} / math.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 25], [26, 32], [33, 37], [38, 49], [50, 51], [51, 53], [53, 55], [56, 57], [57, 58], [58, 59], [59, 60], [61, 64], [65, 66], [66, 68], [68, 70], [71, 72], [72, 73], [73, 74], [74, 75], [76, 77], [78, 79], [80, 81], [82, 86], [87, 90], [91, 97], [98, 102], [102, 103], [104, 107], [108, 112], [113, 121], [122, 126], [127, 128], [128, 129], [129, 130], [131, 132], [133, 134], [135, 136], [136, 137], [137, 138], [139, 140], [140, 141], [142, 143], [144, 145], [146, 147], [148, 152], [153, 155], [156, 166], [167, 170], [171, 179], [180, 184], [185, 187], [188, 194], [195, 200], [201, 203], [204, 207], [208, 216], [217, 221], [222, 223], [223, 227], [227, 228], [229, 230], [230, 231], [232, 233], [233, 234], [234, 235], [235, 236], [237, 238], [239, 243], [243, 244]]}
{"doc_key": "ai-dev-332", "ner": [[3, 3, "misc"], [9, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 9, 11, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "particular", ",", "RLS", "is", "designed", "to", "minimise", "the", "mean", "squared", "error", "between", "predicted", "values", "and", "ACTUAL", "entries", "through", "regularisation", "."], "sentence-detokenized": "In particular, RLS is designed to minimise the mean squared error between predicted values and ACTUAL entries through regularisation.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 21], [22, 30], [31, 33], [34, 42], [43, 46], [47, 51], [52, 59], [60, 65], [66, 73], [74, 83], [84, 90], [91, 94], [95, 101], [102, 109], [110, 117], [118, 132], [132, 133]]}
{"doc_key": "ai-dev-333", "ner": [[5, 7, "algorithm"], [10, 11, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 10, 11, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "essence", ",", "this", "combines", "maximum", "likelihood", "estimation", "with", "a", "regularisation", "procedure", "that", "favours", "simpler", "models", "over", "more", "complex", "ones", "."], "sentence-detokenized": "In essence, this combines maximum likelihood estimation with a regularisation procedure that favours simpler models over more complex ones.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 16], [17, 25], [26, 33], [34, 44], [45, 55], [56, 60], [61, 62], [63, 77], [78, 87], [88, 92], [93, 100], [101, 108], [109, 115], [116, 120], [121, 125], [126, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-dev-334", "ner": [[0, 3, "metrics"], [9, 9, "metrics"], [11, 11, "metrics"], [13, 14, "misc"], [16, 17, "misc"], [29, 33, "algorithm"], [34, 37, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[9, 9, 0, 3, "named", "", false, false], [11, 11, 0, 3, "named", "", false, false], [13, 14, 16, 17, "related-to", "", false, false], [13, 14, 29, 33, "related-to", "ratio", false, false], [29, 33, 34, 37, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "true", "positive", "proportion", "(", "also", "known", "as", "the", "sensitivity", ",", "recall", "or", "detection", "probability", "math", "discrimination", "threshold", ")", "of", "the", "detection", "probability", "on", "the", "y", "-axis", "relative", "to", "the", "cumulative", "distribution", "function", "of", "the", "false", "alarm", "probability", "on", "the", "x-", "axis", "."], "sentence-detokenized": "The true positive proportion (also known as the sensitivity, recall or detection probability math discrimination threshold) of the detection probability on the y-axis relative to the cumulative distribution function of the false alarm probability on the x-axis.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 28], [29, 30], [30, 34], [35, 40], [41, 43], [44, 47], [48, 59], [59, 60], [61, 67], [68, 70], [71, 80], [81, 92], [93, 97], [98, 112], [113, 122], [122, 123], [124, 126], [127, 130], [131, 140], [141, 152], [153, 155], [156, 159], [160, 161], [161, 166], [167, 175], [176, 178], [179, 182], [183, 193], [194, 206], [207, 215], [216, 218], [219, 222], [223, 228], [229, 234], [235, 246], [247, 249], [250, 253], [254, 256], [256, 260], [260, 261]]}
{"doc_key": "ai-dev-335", "ner": [[1, 1, "misc"], [3, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 1, 1, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "English", ",", "Word", "Net", "is", "an", "example", "of", "a", "semantic", "network", "."], "sentence-detokenized": "In English, WordNet is an example of a semantic network.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 16], [16, 19], [20, 22], [23, 25], [26, 33], [34, 36], [37, 38], [39, 47], [48, 55], [55, 56]]}
{"doc_key": "ai-dev-336", "ner": [[5, 7, "product"], [10, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Long", "-", "term", "use", "of", "speech", "recognition", "software", "in", "combination", "with", "word", "processing", "software", "has", "shown", "the", "benefits", "of", "short", "-", "term", "memory", "enhancement", "for", "AVM", "patients", "treated", "by", "resection", "."], "sentence-detokenized": "Long-term use of speech recognition software in combination with word processing software has shown the benefits of short-term memory enhancement for AVM patients treated by resection.", "token2charspan": [[0, 4], [4, 5], [5, 9], [10, 13], [14, 16], [17, 23], [24, 35], [36, 44], [45, 47], [48, 59], [60, 64], [65, 69], [70, 80], [81, 89], [90, 93], [94, 99], [100, 103], [104, 112], [113, 115], [116, 121], [121, 122], [122, 126], [127, 133], [134, 145], [146, 149], [150, 153], [154, 162], [163, 170], [171, 173], [174, 183], [183, 184]]}
{"doc_key": "ai-dev-337", "ner": [[4, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Its", "founding", "editors", "were", "Ron", "Sun", ",", "Vasant", "Honavar", "and", "Gregg", "Oden", "(", "1999-2014", ")", "."], "sentence-detokenized": "Its founding editors were Ron Sun, Vasant Honavar and Gregg Oden (1999-2014).", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 25], [26, 29], [30, 33], [33, 34], [35, 41], [42, 49], [50, 53], [54, 59], [60, 64], [65, 66], [66, 75], [75, 76], [76, 77]]}
{"doc_key": "ai-dev-338", "ner": [[5, 8, "product"], [11, 13, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 8, 11, 13, "opposite", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Their", "\"", "parallel", "\"", "difference", "from", "the", "serial", "manipulator", "is", "that", "the", "main", "character", "(", "or", "\"", "arm", "\"", ")", "of", "this", "linkage", "(", "or", "\"", "arm", "\"", ")", "is", "directly", "connected", "to", "its", "chassis", "by", "several", "(", "usually", "three", "or", "six", ")", "separate", "and", "independent", "linkages", ",", "which", "operate", "simultaneously", "."], "sentence-detokenized": "Their \"parallel\" difference from the serial manipulator is that the main character (or \"arm\") of this linkage (or \"arm\") is directly connected to its chassis by several (usually three or six) separate and independent linkages, which operate simultaneously.", "token2charspan": [[0, 5], [6, 7], [7, 15], [15, 16], [17, 27], [28, 32], [33, 36], [37, 43], [44, 55], [56, 58], [59, 63], [64, 67], [68, 72], [73, 82], [83, 84], [84, 86], [87, 88], [88, 91], [91, 92], [92, 93], [94, 96], [97, 101], [102, 109], [110, 111], [111, 113], [114, 115], [115, 118], [118, 119], [119, 120], [121, 123], [124, 132], [133, 142], [143, 145], [146, 149], [150, 157], [158, 160], [161, 168], [169, 170], [170, 177], [178, 183], [184, 186], [187, 190], [190, 191], [192, 200], [201, 204], [205, 216], [217, 225], [225, 226], [227, 232], [233, 240], [241, 255], [255, 256]]}
{"doc_key": "ai-dev-339", "ner": [[5, 6, "researcher"], [16, 17, "researcher"], [18, 19, "researcher"], [21, 22, "researcher"], [24, 25, "researcher"], [27, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "thesis", "advisor", "was", "Professor", "Cordell", "Green", ",", "and", "his", "thesis", "/", "oral", "committee", "included", "Professors", "Edward", "Feigenbaum", "Joshua", "Lederberg", ",", "Paul", "Cohen", ",", "Allen", "Newell", ",", "Herbert", "Simon", ",", "."], "sentence-detokenized": "His thesis advisor was Professor Cordell Green, and his thesis/oral committee included Professors Edward Feigenbaum Joshua Lederberg, Paul Cohen, Allen Newell, Herbert Simon,.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 22], [23, 32], [33, 40], [41, 46], [46, 47], [48, 51], [52, 55], [56, 62], [62, 63], [63, 67], [68, 77], [78, 86], [87, 97], [98, 104], [105, 115], [116, 122], [123, 132], [132, 133], [134, 138], [139, 144], [144, 145], [146, 151], [152, 158], [158, 159], [160, 167], [168, 173], [173, 174], [174, 175]]}
{"doc_key": "ai-dev-340", "ner": [[3, 5, "metrics"], [7, 10, "metrics"], [12, 14, "metrics"], [16, 18, "metrics"], [20, 24, "metrics"], [26, 28, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "functions", "include", "mean", "square", "error", ",", "root", "mean", "square", "error", ",", "mean", "absolute", "error", ",", "relative", "square", "error", ",", "relative", "root", "mean", "square", "error", ",", "relative", "absolute", "error", "and", "others", "."], "sentence-detokenized": "Such functions include mean square error, root mean square error, mean absolute error, relative square error, relative root mean square error, relative absolute error and others.", "token2charspan": [[0, 4], [5, 14], [15, 22], [23, 27], [28, 34], [35, 40], [40, 41], [42, 46], [47, 51], [52, 58], [59, 64], [64, 65], [66, 70], [71, 79], [80, 85], [85, 86], [87, 95], [96, 102], [103, 108], [108, 109], [110, 118], [119, 123], [124, 128], [129, 135], [136, 141], [141, 142], [143, 151], [152, 160], [161, 166], [167, 170], [171, 177], [177, 178]]}
{"doc_key": "ai-dev-341", "ner": [[0, 9, "programlang"], [2, 2, "programlang"], [4, 4, "product"], [6, 7, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Python", ",", "Java", "and", "MATLAB", "/", "OCTAVE", "bindings", "are", "available", "."], "sentence-detokenized": "Python, Java and MATLAB / OCTAVE bindings are available.", "token2charspan": [[0, 6], [6, 7], [8, 12], [13, 16], [17, 23], [24, 25], [26, 32], [33, 41], [42, 45], [46, 55], [55, 56]]}
{"doc_key": "ai-dev-342", "ner": [[0, 5, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "MATLAB", "implementation", "can", "be", "found", "at", "."], "sentence-detokenized": "The MATLAB implementation can be found at.", "token2charspan": [[0, 3], [4, 10], [11, 25], [26, 29], [30, 32], [33, 38], [39, 41], [41, 42]]}
{"doc_key": "ai-dev-343", "ner": [[0, 5, "researcher"], [8, 9, "field"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"], [22, 25, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[8, 9, 0, 5, "origin", "", false, false], [8, 9, 13, 14, "origin", "", false, false], [8, 9, 16, 17, "origin", "", false, false], [8, 9, 19, 20, "origin", "", false, false], [8, 9, 22, 25, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["John", "McCarthy", "is", "one", "of", "the", "founders", "of", "artificial", "intelligence", ",", "along", "with", "Alan", "Turing", ",", "Marvin", "Minsky", ",", "Allen", "Newell", "and", "Herbert", "A", ".", "Simon", "."], "sentence-detokenized": "John McCarthy is one of the founders of artificial intelligence, along with Alan Turing, Marvin Minsky, Allen Newell and Herbert A. Simon.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 23], [24, 27], [28, 36], [37, 39], [40, 50], [51, 63], [63, 64], [65, 70], [71, 75], [76, 80], [81, 87], [87, 88], [89, 95], [96, 102], [102, 103], [104, 109], [110, 116], [117, 120], [121, 128], [129, 130], [130, 131], [132, 137], [137, 138]]}
{"doc_key": "ai-dev-344", "ner": [[10, 11, "product"], [18, 18, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "parallel", "manipulator", "is", "a", "mechanical", "system", "that", "uses", "multiple", "serial", "manipulators", "to", "support", "a", "single", "platform", "or", "endpoint", "."], "sentence-detokenized": "A parallel manipulator is a mechanical system that uses multiple serial manipulators to support a single platform or endpoint.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 27], [28, 38], [39, 45], [46, 50], [51, 55], [56, 64], [65, 71], [72, 84], [85, 87], [88, 95], [96, 97], [98, 104], [105, 113], [114, 116], [117, 125], [125, 126]]}
{"doc_key": "ai-dev-345", "ner": [[0, 0, "product"], [7, 7, "product"], [9, 15, "product"], [26, 27, "misc"], [29, 29, "misc"], [31, 32, "misc"], [34, 38, "task"], [40, 43, "product"], [45, 46, "product"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 7, 0, 0, "part-of", "", false, false], [9, 15, 7, 7, "named", "", false, false], [26, 27, 7, 7, "part-of", "", false, false], [29, 29, 7, 7, "part-of", "", false, false], [31, 32, 7, 7, "part-of", "", false, false], [34, 38, 7, 7, "part-of", "", false, false], [40, 43, 7, 7, "part-of", "", false, false], [45, 46, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 2, 3, 4, 5, 6, 7, 8], "sentence": ["GATE", "includes", "an", "information", "extraction", "system", "called", "ANNIE", "(", "A", "Nearly", "-", "New", "Information", "Extraction", "System", ")", ",", "which", "is", "a", "set", "of", "modules", "that", "include", "a", "tokenizer", ",", "gazetteer", ",", "sentence", "parser", ",", "part", "-of", "-", "speech", "tagging", ",", "named", "entity", "recognition", "transducer", "and", "coreference", "tagger", "."], "sentence-detokenized": "GATE includes an information extraction system called ANNIE (A Nearly-New Information Extraction System), which is a set of modules that include a tokenizer, gazetteer, sentence parser, part-of-speech tagging, named entity recognition transducer and coreference tagger.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 28], [29, 39], [40, 46], [47, 53], [54, 59], [60, 61], [61, 62], [63, 69], [69, 70], [70, 73], [74, 85], [86, 96], [97, 103], [103, 104], [104, 105], [106, 111], [112, 114], [115, 116], [117, 120], [121, 123], [124, 131], [132, 136], [137, 144], [145, 146], [147, 156], [156, 157], [158, 167], [167, 168], [169, 177], [178, 184], [184, 185], [186, 190], [190, 193], [193, 194], [194, 200], [201, 208], [208, 209], [210, 215], [216, 222], [223, 234], [235, 245], [246, 249], [250, 261], [262, 268], [268, 269]]}
{"doc_key": "ai-dev-346", "ner": [[2, 5, "university"], [13, 15, "country"], [22, 25, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "graduated", "from", "Moscow", "State", "University", "and", "in", "November", "1978", "he", "left", "for", "the", "United", "States", "thanks", "to", "the", "personal", "intervention", "of", "Senator", "Edward", "M.", "Kennedy", "."], "sentence-detokenized": "He graduated from Moscow State University and in November 1978 he left for the United States thanks to the personal intervention of Senator Edward M. Kennedy.", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 24], [25, 30], [31, 41], [42, 45], [46, 48], [49, 57], [58, 62], [63, 65], [66, 70], [71, 74], [75, 78], [79, 85], [86, 92], [93, 99], [100, 102], [103, 106], [107, 115], [116, 128], [129, 131], [132, 139], [140, 146], [147, 149], [150, 157], [157, 158]]}
{"doc_key": "ai-dev-347", "ner": [[3, 6, "organisation"], [10, 15, "misc"], [18, 18, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 6, 10, 15, "win-defeat", "", false, false], [10, 15, 18, 18, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2017", ",", "DeepMind", "'s", "AlphaGo", "team", "was", "awarded", "the", "first", "IJCAI", "Marvin", "Minsky", "Medal", "for", "excellence", "in", "AI", "."], "sentence-detokenized": "In 2017, DeepMind's AlphaGo team was awarded the first IJCAI Marvin Minsky Medal for excellence in AI.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 17], [17, 19], [20, 27], [28, 32], [33, 36], [37, 44], [45, 48], [49, 54], [55, 60], [61, 67], [68, 74], [75, 80], [81, 84], [85, 95], [96, 98], [99, 101], [101, 102]]}
{"doc_key": "ai-dev-348", "ner": [[4, 5, "misc"], [9, 9, "misc"], [16, 18, "misc"], [20, 20, "misc"], [25, 27, "misc"]], "ner_mapping_to_source": [0, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "ways", "in", "which", "anomalous", "propagation", "is", "observed", "include", "tropospheric", "scattering", ",", "meteoric", "scattering", ",", "refraction", "in", "ionised", "regions", "and", "ionospheric", "layers", ",", "and", "reflection", "from", "the", "ionosphere", "."], "sentence-detokenized": "Other ways in which anomalous propagation is observed include tropospheric scattering, meteoric scattering, refraction in ionised regions and ionospheric layers, and reflection from the ionosphere.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 19], [20, 29], [30, 41], [42, 44], [45, 53], [54, 61], [62, 74], [75, 85], [85, 86], [87, 95], [96, 106], [106, 107], [108, 118], [119, 121], [122, 129], [130, 137], [138, 141], [142, 153], [154, 160], [160, 161], [162, 165], [166, 176], [177, 181], [182, 185], [186, 196], [196, 197]]}
{"doc_key": "ai-dev-349", "ner": [[2, 2, "field"], [0, 7, "field"], [10, 10, "field"], [12, 13, "field"], [15, 16, "field"], [18, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 10, 10, "part-of", "", false, false], [2, 2, 12, 13, "part-of", "", false, false], [2, 2, 15, 16, "part-of", "", false, false], [2, 2, 18, 20, "part-of", "", false, false], [0, 7, 2, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Natural", "language", "processing", "(", "NLP", ")", "is", "a", "field", "of", "linguistics", ",", "computer", "science", ",", "computer", "engineering", "and", "artificial", "intelligence", "that", "deals", "with", "the", "interaction", "between", "computers", "and", "human", "(", "natural", ")", "languages", ",", "and", "in", "particular", "how", "computers", "can", "be", "programmed", "to", "process", "and", "analyse", "large", "amounts", "of", "natural", "language", "data", "."], "sentence-detokenized": "Natural language processing (NLP) is a field of linguistics, computer science, computer engineering and artificial intelligence that deals with the interaction between computers and human (natural) languages, and in particular how computers can be programmed to process and analyse large amounts of natural language data.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 29], [29, 32], [32, 33], [34, 36], [37, 38], [39, 44], [45, 47], [48, 59], [59, 60], [61, 69], [70, 77], [77, 78], [79, 87], [88, 99], [100, 103], [104, 114], [115, 127], [128, 132], [133, 138], [139, 143], [144, 147], [148, 159], [160, 167], [168, 177], [178, 181], [182, 187], [188, 189], [189, 196], [196, 197], [198, 207], [207, 208], [209, 212], [213, 215], [216, 226], [227, 230], [231, 240], [241, 244], [245, 247], [248, 258], [259, 261], [262, 269], [270, 273], [274, 281], [282, 287], [288, 295], [296, 298], [299, 306], [307, 315], [316, 320], [320, 321]]}
{"doc_key": "ai-dev-350", "ner": [[8, 9, "organisation"], [11, 12, "organisation"], [14, 15, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "active", "youth", "-", "led", "climate", "groups", "include", "Extinction", "Rebellion", ",", "Sunrise", "Movement", ",", "SustainUS", "and", "others", ",", "operating", "at", "both", "international", "and", "local", "level", "."], "sentence-detokenized": "Other active youth-led climate groups include Extinction Rebellion, Sunrise Movement, SustainUS and others, operating at both international and local level.", "token2charspan": [[0, 5], [6, 12], [13, 18], [18, 19], [19, 22], [23, 30], [31, 37], [38, 45], [46, 56], [57, 66], [66, 67], [68, 75], [76, 84], [84, 85], [86, 95], [96, 99], [100, 106], [106, 107], [108, 117], [118, 120], [121, 125], [126, 139], [140, 143], [144, 149], [150, 155], [155, 156]]}
