{"doc_key": "ai-dev-1", "ner": [[2, 3, "metrics"], [7, 8, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 2, 3, "part-of", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Here", ",", "accuracy", "is", "measured", "by", "the", "error", "rate", ",", "which", "is", "defined", "as", "follows", ":"], "sentence-detokenized": "Here, accuracy is measured by the error rate, which is defined as follows:", "token2charspan": [[0, 4], [4, 5], [6, 14], [15, 17], [18, 26], [27, 29], [30, 33], [34, 39], [40, 44], [44, 45], [46, 51], [52, 54], [55, 62], [63, 65], [66, 73], [73, 74]]}
{"doc_key": "ai-dev-2", "ner": [[6, 6, "algorithm"], [13, 14, "misc"], [18, 20, "algorithm"], [21, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 13, 14, "type-of", "", false, false], [6, 6, 18, 20, "related-to", "", false, false], [6, 6, 21, 22, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["From", "this", "point", "of", "view", ",", "SVM", "is", "closely", "related", "to", "other", "fundamental", "classification", "algorithms", ",", "such", "as", "regularized", "least", "squares", "logistic", "regression", "."], "sentence-detokenized": "From this point of view, SVM is closely related to other fundamental classification algorithms, such as regularized least squares logistic regression.", "token2charspan": [[0, 4], [5, 9], [10, 15], [16, 18], [19, 23], [23, 24], [25, 28], [29, 31], [32, 39], [40, 47], [48, 50], [51, 56], [57, 68], [69, 83], [84, 94], [94, 95], [96, 100], [101, 103], [104, 115], [116, 121], [122, 129], [130, 138], [139, 149], [149, 150]]}
{"doc_key": "ai-dev-3", "ner": [[0, 1, "person"], [3, 6, "person"], [14, 15, "person"], [17, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 6, 0, 1, "named", "actor_plays_character", false, false], [3, 6, 0, 1, "origin", "actor_plays_character", false, false], [17, 19, 14, 15, "named", "actor_plays_character", false, false], [17, 19, 14, 15, "origin", "actor_plays_character", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Brion", "James", "plays", "Leon", "Kowalski", ",", "a", "hard", "-", "working", "combat", "replicant", ",", "and", "Joanna", "Cassidy", "plays", "Zhora", ",", "an", "assassin", "replicant", "."], "sentence-detokenized": "Brion James plays Leon Kowalski, a hard-working combat replicant, and Joanna Cassidy plays Zhora, an assassin replicant.", "token2charspan": [[0, 5], [6, 11], [12, 17], [18, 22], [23, 31], [31, 32], [33, 34], [35, 39], [39, 40], [40, 47], [48, 54], [55, 64], [64, 65], [66, 69], [70, 76], [77, 84], [85, 90], [91, 96], [96, 97], [98, 100], [101, 109], [110, 119], [119, 120]]}
{"doc_key": "ai-dev-4", "ner": [[18, 21, "product"], [23, 23, "product"], [16, 16, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 21, 16, 16, "physical", "", false, false], [23, 23, 18, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "first", "image", "to", "be", "scanned", ",", "stored", "and", "recreated", "in", "digital", "pixels", "was", "posted", "on", "NIST", "'s", "Standards", "Eastern", "Automatic", "Computer", "(", "SEAC", ")", "."], "sentence-detokenized": "The first image to be scanned, stored and recreated in digital pixels was posted on NIST's Standards Eastern Automatic Computer (SEAC).", "token2charspan": [[0, 3], [4, 9], [10, 15], [16, 18], [19, 21], [22, 29], [29, 30], [31, 37], [38, 41], [42, 51], [52, 54], [55, 62], [63, 69], [70, 73], [74, 80], [81, 83], [84, 88], [88, 90], [91, 100], [101, 108], [109, 118], [119, 127], [128, 129], [129, 133], [133, 134], [134, 135]]}
{"doc_key": "ai-dev-5", "ner": [[0, 6, "task"], [20, 21, "task"], [23, 24, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 6, 20, 21, "part-of", "", false, false], [0, 6, 23, 24, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Segmenting", "text", "into", "topics", "or", "speech", "exchanges", "could", "be", "useful", "in", "some", "natural", "processing", "tasks", ":", "it", "can", "significantly", "improve", "information", "retrieval", "or", "speech", "recognition", "(", "by", "indexing", "/", "recognising", "documents", "more", "accurately", "or", "by", "providing", "as", "output", "the", "specific", "part", "of", "a", "document", "that", "matches", "the", "query", ")", "."], "sentence-detokenized": "Segmenting text into topics or speech exchanges could be useful in some natural processing tasks: it can significantly improve information retrieval or speech recognition (by indexing/recognising documents more accurately or by providing as output the specific part of a document that matches the query).", "token2charspan": [[0, 10], [11, 15], [16, 20], [21, 27], [28, 30], [31, 37], [38, 47], [48, 53], [54, 56], [57, 63], [64, 66], [67, 71], [72, 79], [80, 90], [91, 96], [96, 97], [98, 100], [101, 104], [105, 118], [119, 126], [127, 138], [139, 148], [149, 151], [152, 158], [159, 170], [171, 172], [172, 174], [175, 183], [183, 184], [184, 195], [196, 205], [206, 210], [211, 221], [222, 224], [225, 227], [228, 237], [238, 240], [241, 247], [248, 251], [252, 260], [261, 265], [266, 268], [269, 270], [271, 279], [280, 284], [285, 292], [293, 296], [297, 302], [302, 303], [303, 304]]}
{"doc_key": "ai-dev-6", "ner": [[4, 7, "university"], [24, 25, "conference"], [5, 28, "university"], [36, 37, "researcher"], [39, 40, "researcher"], [42, 43, "researcher"], [45, 46, "researcher"], [48, 49, "researcher"], [51, 52, "researcher"], [54, 56, "researcher"], [59, 60, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[24, 25, 5, 28, "physical", "", false, false], [36, 37, 24, 25, "physical", "", false, false], [36, 37, 24, 25, "role", "", false, false], [36, 37, 24, 25, "temporal", "", false, false], [39, 40, 24, 25, "physical", "", false, false], [39, 40, 24, 25, "role", "", false, false], [39, 40, 24, 25, "temporal", "", false, false], [42, 43, 24, 25, "physical", "", false, false], [42, 43, 24, 25, "role", "", false, false], [42, 43, 24, 25, "temporal", "", false, false], [45, 46, 24, 25, "physical", "", false, false], [45, 46, 24, 25, "role", "", false, false], [45, 46, 24, 25, "temporal", "", false, false], [48, 49, 24, 25, "physical", "", false, false], [48, 49, 24, 25, "role", "", false, false], [48, 49, 24, 25, "temporal", "", false, false], [51, 52, 24, 25, "physical", "", false, false], [51, 52, 24, 25, "role", "", false, false], [51, 52, 24, 25, "temporal", "", false, false], [54, 56, 24, 25, "physical", "", false, false], [54, 56, 24, 25, "role", "", false, false], [54, 56, 24, 25, "temporal", "", false, false], [59, 60, 24, 25, "physical", "", false, false], [59, 60, 24, 25, "role", "", false, false], [59, 60, 24, 25, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "sentence": ["In", "1999", ",", "at", "Indiana", "University", ",", "he", "organized", "such", "a", "symposium", ",", "and", "in", "April", "2000", ",", "he", "organized", "a", "larger", "symposium", "entitled", "Spiritual", "Robots", "at", "Stanford", "University", ",", "where", "he", "moderated", "a", "panel", "of", "Ray", "Kurzweil", ",", "Hans", "Moravec", ",", "Kevin", "Kelly", ",", "Ralph", "Merkle", ",", "Bill", "Joy", ",", "Frank", "Drake", ",", "John", "Henry", "Holland", ",", "and", "John", "Koza", "."], "sentence-detokenized": "In 1999, at Indiana University, he organized such a symposium, and in April 2000, he organized a larger symposium entitled Spiritual Robots at Stanford University, where he moderated a panel of Ray Kurzweil, Hans Moravec, Kevin Kelly, Ralph Merkle, Bill Joy, Frank Drake, John Henry Holland, and John Koza.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 19], [20, 30], [30, 31], [32, 34], [35, 44], [45, 49], [50, 51], [52, 61], [61, 62], [63, 66], [67, 69], [70, 75], [76, 80], [80, 81], [82, 84], [85, 94], [95, 96], [97, 103], [104, 113], [114, 122], [123, 132], [133, 139], [140, 142], [143, 151], [152, 162], [162, 163], [164, 169], [170, 172], [173, 182], [183, 184], [185, 190], [191, 193], [194, 197], [198, 206], [206, 207], [208, 212], [213, 220], [220, 221], [222, 227], [228, 233], [233, 234], [235, 240], [241, 247], [247, 248], [249, 253], [254, 257], [257, 258], [259, 264], [265, 270], [270, 271], [272, 276], [277, 282], [283, 290], [290, 291], [292, 295], [296, 300], [301, 305], [305, 306]]}
{"doc_key": "ai-dev-7", "ner": [[6, 6, "metrics"], [7, 7, "metrics"], [9, 9, "metrics"], [10, 10, "metrics"], [19, 31, "metrics"], [39, 39, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 6, 19, 31, "named", "", false, false], [7, 7, 6, 6, "named", "", false, false], [9, 9, 39, 39, "named", "", false, false], [10, 10, 9, 9, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "takes", "into", "account", "both", "the", "precision", "p", "and", "recall", "r", "of", "the", "test", "to", "calculate", "the", "score", ":", "p", "is", "the", "number", "of", "correct", "positives", "divided", "by", "the", "number", "of", "all", "positives", "returned", "by", "the", "classifier", ",", "and", "r", "is", "the", "number", "of", "correct", "positives", "divided", "by", "the", "number", "of", "all", "relevant", "samples", "(", "all", "samples", "that", "should", "have", "been", "identified", "as", "positive", ")", "."], "sentence-detokenized": "It takes into account both the precision p and recall r of the test to calculate the score: p is the number of correct positives divided by the number of all positives returned by the classifier, and r is the number of correct positives divided by the number of all relevant samples (all samples that should have been identified as positive).", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 21], [22, 26], [27, 30], [31, 40], [41, 42], [43, 46], [47, 53], [54, 55], [56, 58], [59, 62], [63, 67], [68, 70], [71, 80], [81, 84], [85, 90], [90, 91], [92, 93], [94, 96], [97, 100], [101, 107], [108, 110], [111, 118], [119, 128], [129, 136], [137, 139], [140, 143], [144, 150], [151, 153], [154, 157], [158, 167], [168, 176], [177, 179], [180, 183], [184, 194], [194, 195], [196, 199], [200, 201], [202, 204], [205, 208], [209, 215], [216, 218], [219, 226], [227, 236], [237, 244], [245, 247], [248, 251], [252, 258], [259, 261], [262, 265], [266, 274], [275, 282], [283, 284], [284, 287], [288, 295], [296, 300], [301, 307], [308, 312], [313, 317], [318, 328], [329, 331], [332, 340], [340, 341], [341, 342]]}
{"doc_key": "ai-dev-8", "ner": [[1, 2, "organisation"], [23, 23, "product"], [31, 34, "person"], [38, 38, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 2, 23, 23, "artifact", "", false, false], [23, 23, 31, 34, "win-defeat", "", false, false], [23, 23, 38, 38, "win-defeat", "", true, false], [31, 34, 38, 38, "win-defeat", "lose", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "Google", "'s", "acquisition", ",", "the", "company", "has", "seen", "a", "number", "of", "significant", "achievements", ",", "perhaps", "the", "most", "notable", "being", "the", "creation", "of", "AlphaGo", ",", "a", "program", "that", "beat", "world", "champion", "Lee", "Sedol", "at", "the", "complex", "game", "of", "Go", "."], "sentence-detokenized": "Since Google's acquisition, the company has seen a number of significant achievements, perhaps the most notable being the creation of AlphaGo, a program that beat world champion Lee Sedol at the complex game of Go.", "token2charspan": [[0, 5], [6, 12], [12, 14], [15, 26], [26, 27], [28, 31], [32, 39], [40, 43], [44, 48], [49, 50], [51, 57], [58, 60], [61, 72], [73, 85], [85, 86], [87, 94], [95, 98], [99, 103], [104, 111], [112, 117], [118, 121], [122, 130], [131, 133], [134, 141], [141, 142], [143, 144], [145, 152], [153, 157], [158, 162], [163, 168], [169, 177], [178, 181], [182, 187], [188, 190], [191, 194], [195, 202], [203, 207], [208, 210], [211, 213], [213, 214]]}
{"doc_key": "ai-dev-9", "ner": [[17, 18, "misc"], [31, 31, "field"], [35, 38, "product"], [54, 55, "misc"], [18, 60, "misc"], [63, 63, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[17, 18, 31, 31, "part-of", "", false, false], [17, 18, 18, 60, "named", "same", false, false], [35, 38, 54, 55, "related-to", "", false, false], [35, 38, 18, 60, "usage", "", false, false], [35, 38, 63, 63, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "representation", "of", "words", "taking", "into", "account", "their", "context", "by", "means", "of", "dense", "fixed", "-dimensional", "vectors", "(", "word", "embeddings", ")", "has", "become", "one", "of", "the", "most", "fundamental", "building", "blocks", "in", "many", "NLP", "systems", ".", "An", "unsupervised", "disambiguation", "system", "uses", "the", "similarity", "between", "word", "meanings", "in", "a", "fixed", "context", "window", "to", "select", "the", "most", "appropriate", "word", "meaning", "using", "a", "pre-trained", "word", "embedding", "model", "and", "WordNet", "."], "sentence-detokenized": "The representation of words taking into account their context by means of dense fixed-dimensional vectors (word embeddings) has become one of the most fundamental building blocks in many NLP systems. An unsupervised disambiguation system uses the similarity between word meanings in a fixed context window to select the most appropriate word meaning using a pre-trained word embedding model and WordNet.", "token2charspan": [[0, 3], [4, 18], [19, 21], [22, 27], [28, 34], [35, 39], [40, 47], [48, 53], [54, 61], [62, 64], [65, 70], [71, 73], [74, 79], [80, 85], [85, 97], [98, 105], [106, 107], [107, 111], [112, 122], [122, 123], [124, 127], [128, 134], [135, 138], [139, 141], [142, 145], [146, 150], [151, 162], [163, 171], [172, 178], [179, 181], [182, 186], [187, 190], [191, 198], [198, 199], [200, 202], [203, 215], [216, 230], [231, 237], [238, 242], [243, 246], [247, 257], [258, 265], [266, 270], [271, 279], [280, 282], [283, 284], [285, 290], [291, 298], [299, 305], [306, 308], [309, 315], [316, 319], [320, 324], [325, 336], [337, 341], [342, 349], [350, 355], [356, 357], [358, 369], [370, 374], [375, 384], [385, 390], [391, 394], [395, 402], [402, 403]]}
{"doc_key": "ai-dev-10", "ner": [[5, 6, "field"], [8, 9, "field"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Machine", "learning", "techniques", ",", "whether", "supervised", "learning", "or", "unsupervised", "learning", ",", "have", "been", "used", "to", "automatically", "induce", "such", "rules", "."], "sentence-detokenized": "Machine learning techniques, whether supervised learning or unsupervised learning, have been used to automatically induce such rules.", "token2charspan": [[0, 7], [8, 16], [17, 27], [27, 28], [29, 36], [37, 47], [48, 56], [57, 59], [60, 72], [73, 81], [81, 82], [83, 87], [88, 92], [93, 97], [98, 100], [101, 114], [115, 121], [122, 126], [127, 132], [132, 133]]}
{"doc_key": "ai-dev-11", "ner": [[3, 3, "researcher"], [6, 7, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[6, 7, 3, 3, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "1969", ",", "Scheinman", "invented", "the", "Stanford", "arm", ","], "sentence-detokenized": "In 1969, Scheinman invented the Stanford arm,", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 18], [19, 27], [28, 31], [32, 40], [41, 44], [44, 45]]}
{"doc_key": "ai-dev-12", "ner": [[1, 2, "metrics"], [7, 14, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Since", "Log", "loss", "is", "differentiable", ",", "a", "gradient", "-", "based", "method", "can", "be", "used", "to", "optimize", "the", "model", "."], "sentence-detokenized": "Since Log loss is differentiable, a gradient-based method can be used to optimize the model.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 17], [18, 32], [32, 33], [34, 35], [36, 44], [44, 45], [45, 50], [51, 57], [58, 61], [62, 64], [65, 69], [70, 72], [73, 81], [82, 85], [86, 91], [91, 92]]}
{"doc_key": "ai-dev-13", "ner": [[1, 2, "field"], [5, 6, "algorithm"], [8, 8, "algorithm"], [4, 13, "algorithm"], [16, 16, "field"], [28, 28, "task"], [30, 31, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 6, 16, 16, "part-of", "", false, false], [8, 8, 5, 6, "named", "", false, false], [4, 13, 5, 6, "named", "", false, false], [16, 16, 1, 2, "part-of", "subfield", false, false], [28, 28, 16, 16, "part-of", "", false, false], [30, 31, 16, 16, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "machine", "learning", ",", "support", "vector", "machines", "(", "SVMs", ",", "or", "support", "vector", "networks", ")", "are", "supervised", "learning", "models", "with", "learning", "algorithms", "that", "analyze", "the", "data", "used", "for", "classification", "and", "regression", "analysis", "."], "sentence-detokenized": "In machine learning, support vector machines (SVMs, or support vector networks) are supervised learning models with learning algorithms that analyze the data used for classification and regression analysis.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 28], [29, 35], [36, 44], [45, 46], [46, 50], [50, 51], [52, 54], [55, 62], [63, 69], [70, 78], [78, 79], [80, 83], [84, 94], [95, 103], [104, 110], [111, 115], [116, 124], [125, 135], [136, 140], [141, 148], [149, 152], [153, 157], [158, 162], [163, 166], [167, 181], [182, 185], [186, 196], [197, 205], [205, 206]]}
{"doc_key": "ai-dev-14", "ner": [[9, 10, "task"], [12, 12, "task"], [29, 29, "metrics"], [31, 31, "metrics"], [33, 33, "researcher"], [35, 35, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[12, 12, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "2002", ")", "as", "an", "automatic", "metric", "for", "evaluating", "machine", "translation", "(", "MT", ")", ",", "many", "other", "methods", "have", "been", "proposed", "to", "revise", "or", "improve", "it", ",", "such", "as", "TER", ",", "METEOR", ",", "Banerjee", "and", "Lavie", ",", "(", "2005", ")", "etc", "."], "sentence-detokenized": "(2002) as an automatic metric for evaluating machine translation (MT), many other methods have been proposed to revise or improve it, such as TER, METEOR, Banerjee and Lavie, (2005) etc.", "token2charspan": [[0, 1], [1, 5], [5, 6], [7, 9], [10, 12], [13, 22], [23, 29], [30, 33], [34, 44], [45, 52], [53, 64], [65, 66], [66, 68], [68, 69], [69, 70], [71, 75], [76, 81], [82, 89], [90, 94], [95, 99], [100, 108], [109, 111], [112, 118], [119, 121], [122, 129], [130, 132], [132, 133], [134, 138], [139, 141], [142, 145], [145, 146], [147, 153], [153, 154], [155, 163], [164, 167], [168, 173], [173, 174], [175, 176], [176, 180], [180, 181], [182, 185], [185, 186]]}
{"doc_key": "ai-dev-15", "ner": [[3, 4, "misc"], [9, 9, "organisation"], [10, 10, "organisation"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 10, 10, "origin", "", false, false], [10, 10, 9, 9, "part-of", "", false, false], [16, 17, 10, 10, "role", "", false, false], [19, 20, 10, 10, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["It", "includes", "a", "superior", "ontology", ",", "created", "by", "the", "IEEE", "P1600.1", "working", "group", "(", "originally", "by", "Ian", "Niles", "and", "Adam", "Pease", ")", "."], "sentence-detokenized": "It includes a superior ontology, created by the IEEE P1600.1 working group (originally by Ian Niles and Adam Pease).", "token2charspan": [[0, 2], [3, 11], [12, 13], [14, 22], [23, 31], [31, 32], [33, 40], [41, 43], [44, 47], [48, 52], [53, 60], [61, 68], [69, 74], [75, 76], [76, 86], [87, 89], [90, 93], [94, 99], [100, 103], [104, 108], [109, 114], [114, 115], [115, 116]]}
{"doc_key": "ai-dev-16", "ner": [[1, 2, "misc"], [32, 34, "algorithm"], [36, 37, "algorithm"], [40, 43, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[32, 34, 1, 2, "part-of", "", true, false], [36, 37, 1, 2, "part-of", "", true, false], [40, 43, 36, 37, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "cryo-electron", "tomography", ",", "where", "the", "limited", "number", "of", "projections", "is", "acquired", "due", "to", "hardware", "limitations", "and", "to", "avoid", "damage", "to", "the", "biological", "specimen", ",", "it", "can", "be", "used", "in", "conjunction", "with", "compressive", "sensing", "techniques", "or", "regularization", "functions", "(", "e.g.", "Huber", "loss", ")", "to", "improve", "reconstruction", "for", "better", "interpretation", "."], "sentence-detokenized": "In cryo-electron tomography, where the limited number of projections is acquired due to hardware limitations and to avoid damage to the biological specimen, it can be used in conjunction with compressive sensing techniques or regularization functions (e.g. Huber loss) to improve reconstruction for better interpretation.", "token2charspan": [[0, 2], [3, 16], [17, 27], [27, 28], [29, 34], [35, 38], [39, 46], [47, 53], [54, 56], [57, 68], [69, 71], [72, 80], [81, 84], [85, 87], [88, 96], [97, 108], [109, 112], [113, 115], [116, 121], [122, 128], [129, 131], [132, 135], [136, 146], [147, 155], [155, 156], [157, 159], [160, 163], [164, 166], [167, 171], [172, 174], [175, 186], [187, 191], [192, 203], [204, 211], [212, 222], [223, 225], [226, 240], [241, 250], [251, 252], [252, 256], [257, 262], [263, 267], [267, 268], [269, 271], [272, 279], [280, 294], [295, 298], [299, 305], [306, 320], [320, 321]]}
{"doc_key": "ai-dev-17", "ner": [[4, 4, "misc"], [10, 10, "algorithm"], [13, 13, "algorithm"], [18, 18, "algorithm"], [7, 27, "product"], [30, 30, "product"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6], "relations": [[10, 10, 4, 4, "type-of", "", false, false], [13, 13, 4, 4, "type-of", "", false, false], [18, 18, 4, 4, "type-of", "", false, false], [30, 30, 7, 27, "role", "publishes", false, false]], "relations_mapping_to_source": [1, 2, 3, 6], "sentence": ["An", "implementation", "of", "several", "whitening", "procedures", "in", "R", ",", "including", "ZCA", "whitening", "and", "PCA", "whitening", "as", "well", "as", "CCA", "whitening", ",", "is", "available", "in", "the", "R", "whitening", "package", "published", "on", "CRAN", "."], "sentence-detokenized": "An implementation of several whitening procedures in R, including ZCA whitening and PCA whitening as well as CCA whitening, is available in the R whitening package published on CRAN.", "token2charspan": [[0, 2], [3, 17], [18, 20], [21, 28], [29, 38], [39, 49], [50, 52], [53, 54], [54, 55], [56, 65], [66, 69], [70, 79], [80, 83], [84, 87], [88, 97], [98, 100], [101, 105], [106, 108], [109, 112], [113, 122], [122, 123], [124, 126], [127, 136], [137, 139], [140, 143], [144, 145], [146, 155], [156, 163], [164, 173], [174, 176], [177, 181], [181, 182]]}
{"doc_key": "ai-dev-18", "ner": [[29, 29, "product"], [31, 31, "product"], [33, 33, "product"], [35, 35, "product"], [37, 37, "product"], [39, 39, "product"], [42, 43, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[29, 29, 33, 33, "compare", "", false, false], [29, 29, 35, 35, "compare", "", false, false], [29, 29, 37, 37, "compare", "", false, false], [29, 29, 39, 39, "compare", "", false, false], [29, 29, 42, 43, "compare", "", false, false], [31, 31, 33, 33, "compare", "", false, false], [31, 31, 35, 35, "compare", "", false, false], [31, 31, 37, 37, "compare", "", false, false], [31, 31, 39, 39, "compare", "", false, false], [31, 31, 42, 43, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Today", ",", "the", "field", "has", "become", "even", "more", "complex", "and", "intimidating", "with", "the", "addition", "of", "languages", "and", "software", "for", "circuit", ",", "system", "and", "signal", "analysis", "and", "design", ",", "from", "MATLAB", "and", "Simulink", "to", "NumPy", ",", "VHDL", ",", "PSpice", ",", "Verilog", "and", "even", "Assembly", "language", "."], "sentence-detokenized": "Today, the field has become even more complex and intimidating with the addition of languages and software for circuit, system and signal analysis and design, from MATLAB and Simulink to NumPy, VHDL, PSpice, Verilog and even Assembly language.", "token2charspan": [[0, 5], [5, 6], [7, 10], [11, 16], [17, 20], [21, 27], [28, 32], [33, 37], [38, 45], [46, 49], [50, 62], [63, 67], [68, 71], [72, 80], [81, 83], [84, 93], [94, 97], [98, 106], [107, 110], [111, 118], [118, 119], [120, 126], [127, 130], [131, 137], [138, 146], [147, 150], [151, 157], [157, 158], [159, 163], [164, 170], [171, 174], [175, 183], [184, 186], [187, 192], [192, 193], [194, 198], [198, 199], [200, 206], [206, 207], [208, 215], [216, 219], [220, 224], [225, 233], [234, 242], [242, 243]]}
{"doc_key": "ai-dev-19", "ner": [[5, 6, "person"], [18, 19, "person"], [13, 17, "organisation"], [23, 23, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[13, 17, 18, 19, "origin", "", false, false], [23, 23, 13, 17, "artifact", "builds", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "company", "was", "founded", "by", "Kiichiro", "Toyoda", "in", "1937", "as", "a", "division", "of", "Toyota", "Industries", ",", "founded", "by", "Sakichi", "Toyoda", ",", "to", "create", "automobiles", "."], "sentence-detokenized": "The company was founded by Kiichiro Toyoda in 1937 as a division of Toyota Industries, founded by Sakichi Toyoda, to create automobiles.", "token2charspan": [[0, 3], [4, 11], [12, 15], [16, 23], [24, 26], [27, 35], [36, 42], [43, 45], [46, 50], [51, 53], [54, 55], [56, 64], [65, 67], [68, 74], [75, 85], [85, 86], [87, 94], [95, 97], [98, 105], [106, 112], [112, 113], [114, 116], [117, 123], [124, 135], [135, 136]]}
{"doc_key": "ai-dev-20", "ner": [[0, 4, "field"], [54, 55, "field"]], "ner_mapping_to_source": [0, 1], "relations": [[54, 55, 0, 4, "origin", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["Unsupervised", "learning", ",", "on", "the", "other", "hand", ",", "involves", "training", "data", "that", "has", "not", "been", "manually", "labeled", "and", "attempts", "to", "find", "inherent", "patterns", "in", "the", "data", "that", "can", "then", "be", "used", "to", "determine", "the", "correct", "output", "value", "for", "new", "instances", "of", "data", "...", "A", "combination", "of", "the", "two", "that", "has", "been", "explored", "recently", "is", "semi-supervised", "learning", ",", "which", "uses", "a", "combination", "of", "labeled", "and", "unlabeled", "data", "(", "usually", "a", "small", "set", "of", "labeled", "data", "combined", "with", "a", "large", "amount", "of", "unlabeled", "data", ")", "."], "sentence-detokenized": "Unsupervised learning, on the other hand, involves training data that has not been manually labeled and attempts to find inherent patterns in the data that can then be used to determine the correct output value for new instances of data... A combination of the two that has been explored recently is semi-supervised learning, which uses a combination of labeled and unlabeled data (usually a small set of labeled data combined with a large amount of unlabeled data).", "token2charspan": [[0, 12], [13, 21], [21, 22], [23, 25], [26, 29], [30, 35], [36, 40], [40, 41], [42, 50], [51, 59], [60, 64], [65, 69], [70, 73], [74, 77], [78, 82], [83, 91], [92, 99], [100, 103], [104, 112], [113, 115], [116, 120], [121, 129], [130, 138], [139, 141], [142, 145], [146, 150], [151, 155], [156, 159], [160, 164], [165, 167], [168, 172], [173, 175], [176, 185], [186, 189], [190, 197], [198, 204], [205, 210], [211, 214], [215, 218], [219, 228], [229, 231], [232, 236], [236, 239], [240, 241], [242, 253], [254, 256], [257, 260], [261, 264], [265, 269], [270, 273], [274, 278], [279, 287], [288, 296], [297, 299], [300, 315], [316, 324], [324, 325], [326, 331], [332, 336], [337, 338], [339, 350], [351, 353], [354, 361], [362, 365], [366, 375], [376, 380], [381, 382], [382, 389], [390, 391], [392, 397], [398, 401], [402, 404], [405, 412], [413, 417], [418, 426], [427, 431], [432, 433], [434, 439], [440, 446], [447, 449], [450, 459], [460, 464], [464, 465], [465, 466]]}
{"doc_key": "ai-dev-21", "ner": [[19, 19, "organisation"], [20, 21, "product"], [23, 24, "organisation"], [25, 26, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[20, 21, 19, 19, "artifact", "", false, false], [23, 24, 25, 26, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Despite", "these", "humanoid", "robots", "for", "utilitarian", "uses", ",", "there", "are", "some", "humanoid", "robots", "for", "entertainment", "purposes", ",", "such", "as", "Sony", "'s", "QRIO", "and", "Wow", "Wee", "'s", "RoboSapien", "."], "sentence-detokenized": "Despite these humanoid robots for utilitarian uses, there are some humanoid robots for entertainment purposes, such as Sony's QRIO and Wow Wee's RoboSapien.", "token2charspan": [[0, 7], [8, 13], [14, 22], [23, 29], [30, 33], [34, 45], [46, 50], [50, 51], [52, 57], [58, 61], [62, 66], [67, 75], [76, 82], [83, 86], [87, 100], [101, 109], [109, 110], [111, 115], [116, 118], [119, 123], [123, 125], [126, 130], [131, 134], [135, 138], [139, 142], [142, 144], [145, 155], [155, 156]]}
{"doc_key": "ai-dev-22", "ner": [[0, 0, "researcher"], [6, 12, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 6, 12, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Webber", "became", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "in", "1991", ","], "sentence-detokenized": "Webber became a member of the Association for the Advancement of Artificial Intelligence in 1991,", "token2charspan": [[0, 6], [7, 13], [14, 15], [16, 22], [23, 25], [26, 29], [30, 41], [42, 45], [46, 49], [50, 61], [62, 64], [65, 75], [76, 88], [89, 91], [92, 96], [96, 97]]}
{"doc_key": "ai-dev-23", "ner": [[5, 6, "field"], [8, 8, "field"], [19, 22, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 22, 5, 6, "part-of", "task_part_of_field", false, false], [19, 22, 8, 8, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["At", "this", "company", "he", "developed", "data", "mining", "and", "database", "technologies", ",", "specifically", "high", "-", "level", "ontologies", "for", "intelligence", "and", "natural", "language", "machine", "understanding", "."], "sentence-detokenized": "At this company he developed data mining and database technologies, specifically high-level ontologies for intelligence and natural language machine understanding.", "token2charspan": [[0, 2], [3, 7], [8, 15], [16, 18], [19, 28], [29, 33], [34, 40], [41, 44], [45, 53], [54, 66], [66, 67], [68, 80], [81, 85], [85, 86], [86, 91], [92, 102], [103, 106], [107, 119], [120, 123], [124, 131], [132, 140], [141, 148], [149, 162], [162, 163]]}
{"doc_key": "ai-dev-24", "ner": [[13, 14, "misc"], [16, 19, "misc"], [24, 25, "misc"], [27, 27, "country"], [29, 30, "organisation"], [32, 32, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[13, 14, 27, 27, "physical", "", false, false], [16, 19, 27, 27, "physical", "", false, false], [24, 25, 27, 27, "physical", "", false, false], [29, 30, 32, 32, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["However", ",", "in", "recent", "years", ",", "various", "e-services", "and", "related", "initiatives", "such", "as", "Nemmadi", "Project", ",", "MCA21", "Mission", "Mode", "Project", "or", "even", "more", ",", "Digital", "India", "in", "India", ";", "e-Government", "Directorate", "in", "Pakistan", ";", "etc.", ",", "can", "be", "observed", "in", "developing", "countries", "."], "sentence-detokenized": "However, in recent years, various e-services and related initiatives such as Nemmadi Project, MCA21 Mission Mode Project or even more, Digital India in India; e-Government Directorate in Pakistan; etc., can be observed in developing countries.", "token2charspan": [[0, 7], [7, 8], [9, 11], [12, 18], [19, 24], [24, 25], [26, 33], [34, 44], [45, 48], [49, 56], [57, 68], [69, 73], [74, 76], [77, 84], [85, 92], [92, 93], [94, 99], [100, 107], [108, 112], [113, 120], [121, 123], [124, 128], [129, 133], [133, 134], [135, 142], [143, 148], [149, 151], [152, 157], [157, 158], [159, 171], [172, 183], [184, 186], [187, 195], [195, 196], [197, 201], [201, 202], [203, 206], [207, 209], [210, 218], [219, 221], [222, 232], [233, 242], [242, 243]]}
{"doc_key": "ai-dev-25", "ner": [[0, 0, "misc"], [2, 3, "field"], [5, 6, "field"], [8, 10, "university"], [14, 16, "university"], [25, 29, "university"], [31, 31, "misc"], [33, 34, "field"], [39, 42, "misc"], [44, 45, "university"], [47, 49, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 0, 2, 3, "topic", "", false, false], [0, 0, 5, 6, "topic", "", false, false], [0, 0, 8, 10, "origin", "", false, false], [8, 10, 14, 16, "part-of", "", false, false], [25, 29, 8, 10, "part-of", "", false, false], [31, 31, 33, 34, "topic", "", false, false], [31, 31, 44, 45, "origin", "", false, false], [39, 42, 44, 45, "origin", "", false, false], [44, 45, 47, 49, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["D.", "in", "Radio", "Physics", "and", "Electronics", "from", "the", "Rajabazar", "Science", "College", "campus", "of", "the", "University", "of", "Calcutta", "in", "1979", ",", "as", "a", "student", "of", "the", "Indian", "Statistical", "Institute", ",", "and", "another", "Ph.D.", "in", "Electrical", "Engineering", ",", "along", "with", "a", "degree", "from", "Imperial", "College", ",", "Imperial", "College", ",", "University", "of", "London", ",", "in", "1982", "."], "sentence-detokenized": "D. in Radio Physics and Electronics from the Rajabazar Science College campus of the University of Calcutta in 1979, as a student of the Indian Statistical Institute, and another Ph.D. in Electrical Engineering, along with a degree from Imperial College, Imperial College, University of London, in 1982.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 19], [20, 23], [24, 35], [36, 40], [41, 44], [45, 54], [55, 62], [63, 70], [71, 77], [78, 80], [81, 84], [85, 95], [96, 98], [99, 107], [108, 110], [111, 115], [115, 116], [117, 119], [120, 121], [122, 129], [130, 132], [133, 136], [137, 143], [144, 155], [156, 165], [165, 166], [167, 170], [171, 178], [179, 184], [185, 187], [188, 198], [199, 210], [210, 211], [212, 217], [218, 222], [223, 224], [225, 231], [232, 236], [237, 245], [246, 253], [253, 254], [255, 263], [264, 271], [271, 272], [273, 283], [284, 286], [287, 293], [293, 294], [295, 297], [298, 302], [302, 303]]}
{"doc_key": "ai-dev-26", "ner": [[0, 1, "location"], [19, 21, "misc"], [27, 28, "misc"], [30, 32, "person"], [34, 35, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 21, 0, 1, "temporal", "", false, false], [27, 28, 0, 1, "temporal", "", false, false], [30, 32, 27, 28, "role", "actor_in", false, false], [34, 35, 27, 28, "role", "actor_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Expo", "II", "announced", "the", "world", "premiere", "of", "several", "films", "that", "have", "never", "before", "been", "seen", "in", "3D", ",", "including", "The", "Diamond", "Wizard", "and", "the", "Universal", "short", "film", "Hawaiian", "Nights", "starring", "Mamie", "Van", "Doren", "and", "Pinky", "Lee", "."], "sentence-detokenized": "Expo II announced the world premiere of several films that have never before been seen in 3D, including The Diamond Wizard and the Universal short film Hawaiian Nights starring Mamie Van Doren and Pinky Lee.", "token2charspan": [[0, 4], [5, 7], [8, 17], [18, 21], [22, 27], [28, 36], [37, 39], [40, 47], [48, 53], [54, 58], [59, 63], [64, 69], [70, 76], [77, 81], [82, 86], [87, 89], [90, 92], [92, 93], [94, 103], [104, 107], [108, 115], [116, 122], [123, 126], [127, 130], [131, 140], [141, 146], [147, 151], [152, 160], [161, 167], [168, 176], [177, 182], [183, 186], [187, 192], [193, 196], [197, 202], [203, 206], [206, 207]]}
{"doc_key": "ai-dev-27", "ner": [[7, 8, "researcher"], [16, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[7, 8, 16, 18, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "maximum", "subdimension", "problem", "was", "proposed", "by", "Ulf", "Grenander", "in", "1977", "as", "a", "simplified", "model", "for", "maximum", "likelihood", "estimation", "of", "patterns", "in", "digitized", "images", "."], "sentence-detokenized": "The maximum subdimension problem was proposed by Ulf Grenander in 1977 as a simplified model for maximum likelihood estimation of patterns in digitized images.", "token2charspan": [[0, 3], [4, 11], [12, 24], [25, 32], [33, 36], [37, 45], [46, 48], [49, 52], [53, 62], [63, 65], [66, 70], [71, 73], [74, 75], [76, 86], [87, 92], [93, 96], [97, 104], [105, 115], [116, 126], [127, 129], [130, 138], [139, 141], [142, 151], [152, 158], [158, 159]]}
{"doc_key": "ai-dev-28", "ner": [[0, 1, "product"], [3, 4, "product"], [6, 8, "product"], [10, 11, "product"], [13, 15, "product"], [17, 20, "product"], [33, 33, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[33, 33, 0, 1, "part-of", "", false, false], [33, 33, 3, 4, "part-of", "", false, false], [33, 33, 6, 8, "part-of", "", false, false], [33, 33, 10, 11, "part-of", "", false, false], [33, 33, 13, 15, "part-of", "", false, false], [33, 33, 17, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["iPhone", "4S", ",", "iPad", "3", ",", "iPad", "Mini", "1G", ",", "iPad", "Air", ",", "iPad", "Pro", "1G", ",", "iPod", "Touch", "5", "G", "and", "later", "versions", "all", "come", "with", "a", "more", "advanced", "voice", "assistant", "called", "Siri", "."], "sentence-detokenized": "iPhone 4S, iPad 3, iPad Mini 1G, iPad Air, iPad Pro 1G, iPod Touch 5G and later versions all come with a more advanced voice assistant called Siri.", "token2charspan": [[0, 6], [7, 9], [9, 10], [11, 15], [16, 17], [17, 18], [19, 23], [24, 28], [29, 31], [31, 32], [33, 37], [38, 41], [41, 42], [43, 47], [48, 51], [52, 54], [54, 55], [56, 60], [61, 66], [67, 68], [68, 69], [70, 73], [74, 79], [80, 88], [89, 92], [93, 97], [98, 102], [103, 104], [105, 109], [110, 118], [119, 124], [125, 134], [135, 141], [142, 146], [146, 147]]}
{"doc_key": "ai-dev-29", "ner": [[6, 7, "metrics"], [9, 11, "metrics"], [14, 15, "metrics"], [45, 48, "metrics"], [54, 57, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[9, 11, 45, 48, "named", "", false, false], [14, 15, 9, 11, "named", "", false, false], [45, 48, 54, 57, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["It", "is", "easy", "to", "verify", "that", "log", "loss", "and", "binary", "cross", "-entropy", "loss", "(", "Log", "loss", ")", "are", "in", "fact", "the", "same", "(", "up", "to", "a", "multiplicative", "constant", "math", "\\", "frac", "{", "1", "}", "{", "\\", "log", "(", "2", ")", "}", "/", "math", ")", ".", "The", "cross", "-entropy", "loss", "is", "closely", "related", "to", "the", "Kullback", "-", "Leibler", "divergence", "between", "the", "empirical", "distribution", "and", "the", "predicted", "distribution", "."], "sentence-detokenized": "It is easy to verify that log loss and binary cross-entropy loss (Log loss) are in fact the same (up to a multiplicative constant math\\ frac {1} {\\ log (2)} / math) . The cross-entropy loss is closely related to the Kullback-Leibler divergence between the empirical distribution and the predicted distribution.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 13], [14, 20], [21, 25], [26, 29], [30, 34], [35, 38], [39, 45], [46, 51], [51, 59], [60, 64], [65, 66], [66, 69], [70, 74], [74, 75], [76, 79], [80, 82], [83, 87], [88, 91], [92, 96], [97, 98], [98, 100], [101, 103], [104, 105], [106, 120], [121, 129], [130, 134], [134, 135], [136, 140], [141, 142], [142, 143], [143, 144], [145, 146], [146, 147], [148, 151], [152, 153], [153, 154], [154, 155], [155, 156], [157, 158], [159, 163], [163, 164], [165, 166], [167, 170], [171, 176], [176, 184], [185, 189], [190, 192], [193, 200], [201, 208], [209, 211], [212, 215], [216, 224], [224, 225], [225, 232], [233, 243], [244, 251], [252, 255], [256, 265], [266, 278], [279, 282], [283, 286], [287, 296], [297, 309], [309, 310]]}
{"doc_key": "ai-dev-30", "ner": [[0, 2, "algorithm"], [8, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "EM", "algorithm", "is", "used", "to", "find", "the", "maximum", "likelihood", "(", "local", ")", "parameters", "of", "a", "statistical", "model", "in", "cases", "where", "the", "equations", "can", "not", "be", "solved", "directly", "."], "sentence-detokenized": "The EM algorithm is used to find the maximum likelihood (local) parameters of a statistical model in cases where the equations cannot be solved directly.", "token2charspan": [[0, 3], [4, 6], [7, 16], [17, 19], [20, 24], [25, 27], [28, 32], [33, 36], [37, 44], [45, 55], [56, 57], [57, 62], [62, 63], [64, 74], [75, 77], [78, 79], [80, 91], [92, 97], [98, 100], [101, 106], [107, 112], [113, 116], [117, 126], [127, 130], [130, 133], [134, 136], [137, 143], [144, 152], [152, 153]]}
{"doc_key": "ai-dev-31", "ner": [[10, 11, "task"], [14, 18, "task"], [23, 23, "task"], [26, 27, "task"], [33, 37, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "research", "has", "been", "fundamental", "to", "the", "development", "of", "modern", "speech", "synthesis", "techniques", ",", "reading", "machines", "for", "the", "blind", ",", "the", "study", "of", "speech", "perception", "and", "speech", "recognition", ",", "and", "the", "development", "of", "motor", "theory", "of", "speech", "perception", "."], "sentence-detokenized": "This research has been fundamental to the development of modern speech synthesis techniques, reading machines for the blind, the study of speech perception and speech recognition, and the development of motor theory of speech perception.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 22], [23, 34], [35, 37], [38, 41], [42, 53], [54, 56], [57, 63], [64, 70], [71, 80], [81, 91], [91, 92], [93, 100], [101, 109], [110, 113], [114, 117], [118, 123], [123, 124], [125, 128], [129, 134], [135, 137], [138, 144], [145, 155], [156, 159], [160, 166], [167, 178], [178, 179], [180, 183], [184, 187], [188, 199], [200, 202], [203, 208], [209, 215], [216, 218], [219, 225], [226, 236], [236, 237]]}
{"doc_key": "ai-dev-32", "ner": [[1, 1, "product"], [0, 4, "misc"], [6, 6, "misc"], [10, 12, "misc"], [15, 15, "product"], [17, 17, "product"], [19, 19, "product"], [24, 24, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[0, 4, 1, 1, "origin", "", false, false], [0, 4, 10, 12, "type-of", "", false, false], [0, 4, 15, 15, "related-to", "program_for", false, false], [0, 4, 17, 17, "related-to", "program_for", false, false], [0, 4, 19, 19, "related-to", "program_for", false, false], [0, 4, 24, 24, "related-to", "program_for", false, false], [6, 6, 0, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["The", "Arduino", "Integrated", "Development", "Environment", "(", "IDE", ")", "is", "a", "cross", "-platform", "application", "(", "for", "Windows", ",", "macOS", "and", "Linux", ")", "written", "in", "the", "Java", "programming", "language", "."], "sentence-detokenized": "The Arduino Integrated Development Environment (IDE) is a cross-platform application (for Windows, macOS and Linux) written in the Java programming language.", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 34], [35, 46], [47, 48], [48, 51], [51, 52], [53, 55], [56, 57], [58, 63], [63, 72], [73, 84], [85, 86], [86, 89], [90, 97], [97, 98], [99, 104], [105, 108], [109, 114], [114, 115], [116, 123], [124, 126], [127, 130], [131, 135], [136, 147], [148, 156], [156, 157]]}
{"doc_key": "ai-dev-33", "ner": [[0, 1, "algorithm"], [8, 9, "field"], [12, 13, "researcher"], [15, 16, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 8, 9, "opposite", "", false, false], [12, 13, 8, 9, "related-to", "works_with", false, false], [15, 16, 8, 9, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Neural", "network", "research", "stagnated", "after", "the", "publication", "of", "machine", "learning", "research", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "(", "1969", ")", "."], "sentence-detokenized": "Neural network research stagnated after the publication of machine learning research by Marvin Minsky and Seymour Papert (1969).", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 33], [34, 39], [40, 43], [44, 55], [56, 58], [59, 66], [67, 75], [76, 84], [85, 87], [88, 94], [95, 101], [102, 105], [106, 113], [114, 120], [121, 122], [122, 126], [126, 127], [127, 128]]}
{"doc_key": "ai-dev-34", "ner": [[18, 19, "organisation"], [21, 21, "organisation"], [24, 26, "country"], [28, 31, "organisation"], [34, 34, "country"], [36, 37, "organisation"], [40, 40, "country"], [42, 42, "organisation"]], "ner_mapping_to_source": [0, 1, 3, 4, 5, 6, 7, 8], "relations": [[28, 31, 24, 26, "general-affiliation", "", false, false], [36, 37, 34, 34, "general-affiliation", "", false, false], [42, 42, 40, 40, "general-affiliation", "", false, false]], "relations_mapping_to_source": [1, 2, 3], "sentence": ["Only", "a", "few", "non-Japanese", "companies", "have", "finally", "managed", "to", "survive", "in", "this", "market", ",", "the", "most", "important", "being", "Adept", "Technology", ",", "St\u00e4ubli", ",", "the", "Swedish", "-", "Swiss", "company", "ABB", "Asea", "Brown", "Boveri", ",", "the", "German", "company", "KUKA", "Robotics", "and", "the", "Italian", "company", "Comau", "."], "sentence-detokenized": "Only a few non-Japanese companies have finally managed to survive in this market, the most important being Adept Technology, St\u00e4ubli, the Swedish-Swiss company ABB Asea Brown Boveri, the German company KUKA Robotics and the Italian company Comau.", "token2charspan": [[0, 4], [5, 6], [7, 10], [11, 23], [24, 33], [34, 38], [39, 46], [47, 54], [55, 57], [58, 65], [66, 68], [69, 73], [74, 80], [80, 81], [82, 85], [86, 90], [91, 100], [101, 106], [107, 112], [113, 123], [123, 124], [125, 132], [132, 133], [134, 137], [138, 145], [145, 146], [146, 151], [152, 159], [160, 163], [164, 168], [169, 174], [175, 181], [181, 182], [183, 186], [187, 193], [194, 201], [202, 206], [207, 215], [216, 219], [220, 223], [224, 231], [232, 239], [240, 245], [245, 246]]}
{"doc_key": "ai-dev-35", "ner": [[9, 10, "conference"], [17, 17, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 17, 9, 10, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Research", "activities", "include", "an", "annual", "research", "conference", ",", "the", "RuleML", "Symposium", ",", "also", "known", "for", "short", "as", "RuleML", "."], "sentence-detokenized": "Research activities include an annual research conference, the RuleML Symposium, also known for short as RuleML.", "token2charspan": [[0, 8], [9, 19], [20, 27], [28, 30], [31, 37], [38, 46], [47, 57], [57, 58], [59, 62], [63, 69], [70, 79], [79, 80], [81, 85], [86, 91], [92, 95], [96, 101], [102, 104], [105, 111], [111, 112]]}
{"doc_key": "ai-dev-36", "ner": [[9, 9, "field"], [11, 12, "field"], [14, 14, "field"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Concepts", "are", "used", "as", "formal", "tools", "or", "models", "in", "mathematics", ",", "computer", "science", ",", "databases", "and", "artificial", "intelligence", ",", "where", "they", "are", "sometimes", "referred", "to", "as", "classes", ",", "schemes", "or", "categories", "."], "sentence-detokenized": "Concepts are used as formal tools or models in mathematics, computer science, databases and artificial intelligence, where they are sometimes referred to as classes, schemes or categories.", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 20], [21, 27], [28, 33], [34, 36], [37, 43], [44, 46], [47, 58], [58, 59], [60, 68], [69, 76], [76, 77], [78, 87], [88, 91], [92, 102], [103, 115], [115, 116], [117, 122], [123, 127], [128, 131], [132, 141], [142, 150], [151, 153], [154, 156], [157, 164], [164, 165], [166, 173], [174, 176], [177, 187], [187, 188]]}
{"doc_key": "ai-dev-37", "ner": [[6, 8, "organisation"], [11, 14, "organisation"], [16, 16, "organisation"], [19, 21, "organisation"], [25, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "received", "awards", "from", "the", "American", "Psychological", "Association", ",", "the", "National", "Academy", "of", "Sciences", ",", "Royal", ",", "the", "Cognitive", "Neuroscience", "Society", ",", "and", "the", "American", "Humanities", "Association", "."], "sentence-detokenized": "He has received awards from the American Psychological Association, the National Academy of Sciences, Royal, the Cognitive Neuroscience Society, and the American Humanities Association.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 22], [23, 27], [28, 31], [32, 40], [41, 54], [55, 66], [66, 67], [68, 71], [72, 80], [81, 88], [89, 91], [92, 100], [100, 101], [102, 107], [107, 108], [109, 112], [113, 122], [123, 135], [136, 143], [143, 144], [145, 148], [149, 152], [153, 161], [162, 172], [173, 184], [184, 185]]}
{"doc_key": "ai-dev-38", "ner": [[1, 2, "person"], [4, 5, "person"], [7, 8, "person"], [22, 26, "person"], [28, 34, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[28, 34, 22, 26, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Starring", "Harrison", "Ford", ",", "Rutger", "Hauer", "and", "Sean", "Young", "in", "the", "lead", "roles", ",", "the", "film", "is", "based", "on", "the", "novel", "by", "Philip", "K", ".", "Dick", "'s", "\"", "Do", "Androids", "Dream", "of", "Electric", "Sheep", "?", "\"", "(", "1968", ")", "."], "sentence-detokenized": "Starring Harrison Ford, Rutger Hauer and Sean Young in the lead roles, the film is based on the novel by Philip K. Dick's \"Do Androids Dream of Electric Sheep?\" (1968).", "token2charspan": [[0, 8], [9, 17], [18, 22], [22, 23], [24, 30], [31, 36], [37, 40], [41, 45], [46, 51], [52, 54], [55, 58], [59, 63], [64, 69], [69, 70], [71, 74], [75, 79], [80, 82], [83, 88], [89, 91], [92, 95], [96, 101], [102, 104], [105, 111], [112, 113], [113, 114], [115, 119], [119, 121], [122, 123], [123, 125], [126, 134], [135, 140], [141, 143], [144, 152], [153, 158], [158, 159], [159, 160], [161, 162], [162, 166], [166, 167], [167, 168]]}
{"doc_key": "ai-dev-39", "ner": [[0, 1, "task"], [3, 5, "algorithm"], [11, 12, "field"], [14, 15, "task"], [17, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 3, 5, "usage", "", false, false], [0, 1, 11, 12, "part-of", "task_part_of_field", false, false], [0, 1, 14, 15, "part-of", "task_part_of_field", false, false], [0, 1, 17, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Image", "segmentation", "using", "k-means", "clustering", "algorithms", "has", "long", "been", "used", "for", "pattern", "recognition", ",", "object", "detection", "and", "medical", "imaging", "."], "sentence-detokenized": "Image segmentation using k-means clustering algorithms has long been used for pattern recognition, object detection and medical imaging.", "token2charspan": [[0, 5], [6, 18], [19, 24], [25, 32], [33, 43], [44, 54], [55, 58], [59, 63], [64, 68], [69, 73], [74, 77], [78, 85], [86, 97], [97, 98], [99, 105], [106, 115], [116, 119], [120, 127], [128, 135], [135, 136]]}
{"doc_key": "ai-dev-40", "ner": [[14, 14, "algorithm"], [16, 17, "algorithm"], [20, 20, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["General", "sampling", "from", "the", "truncated", "normal", "can", "be", "performed", "using", "approximations", "of", "the", "normal", "CDF", "and", "probit", "function", ",", "and", "R", "has", "a", "codertnorm", "(", ")", "/", "code", "function", "for", "generating", "truncated", "-", "norm", "samples", "."], "sentence-detokenized": "General sampling from the truncated normal can be performed using approximations of the normal CDF and probit function, and R has a codertnorm() / code function for generating truncated-norm samples.", "token2charspan": [[0, 7], [8, 16], [17, 21], [22, 25], [26, 35], [36, 42], [43, 46], [47, 49], [50, 59], [60, 65], [66, 80], [81, 83], [84, 87], [88, 94], [95, 98], [99, 102], [103, 109], [110, 118], [118, 119], [120, 123], [124, 125], [126, 129], [130, 131], [132, 142], [142, 143], [143, 144], [145, 146], [147, 151], [152, 160], [161, 164], [165, 175], [176, 185], [185, 186], [186, 190], [191, 198], [198, 199]]}
{"doc_key": "ai-dev-41", "ner": [[8, 10, "university"], [12, 12, "university"], [14, 16, "university"], [18, 20, "university"], [23, 25, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "also", "received", "honorary", "doctorates", "from", "the", "Universities", "of", "Newcastle", ",", "Surrey", ",", "Tel", "Aviv", "University", ",", "Simon", "Fraser", "University", "and", "the", "University", "of", "Troms\u00f8", "."], "sentence-detokenized": "He has also received honorary doctorates from the Universities of Newcastle, Surrey, Tel Aviv University, Simon Fraser University and the University of Troms\u00f8.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 20], [21, 29], [30, 40], [41, 45], [46, 49], [50, 62], [63, 65], [66, 75], [75, 76], [77, 83], [83, 84], [85, 88], [89, 93], [94, 104], [104, 105], [106, 111], [112, 118], [119, 129], [130, 133], [134, 137], [138, 148], [149, 151], [152, 158], [158, 159]]}
{"doc_key": "ai-dev-42", "ner": [[1, 1, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "Java", "implementation", "using", "zero", "-", "based", "array", "indexes", ",", "along", "with", "a", "convenient", "method", "for", "printing", "the", "resolved", "order", "of", "operations", ":"], "sentence-detokenized": "A Java implementation using zero-based array indexes, along with a convenient method for printing the resolved order of operations:", "token2charspan": [[0, 1], [2, 6], [7, 21], [22, 27], [28, 32], [32, 33], [33, 38], [39, 44], [45, 52], [52, 53], [54, 59], [60, 64], [65, 66], [67, 77], [78, 84], [85, 88], [89, 97], [98, 101], [102, 110], [111, 116], [117, 119], [120, 130], [130, 131]]}
{"doc_key": "ai-dev-43", "ner": [[7, 12, "metrics"], [22, 24, "algorithm"]], "ner_mapping_to_source": [1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "networks", "are", "usually", "trained", "in", "the", "cross", "-entropy", "(", "or", "cross", "-entropy", ")", "regime", ",", "which", "provides", "a", "nonlinear", "variant", "of", "multinomial", "logistic", "regression", "."], "sentence-detokenized": "Such networks are usually trained in the cross-entropy (or cross-entropy) regime, which provides a nonlinear variant of multinomial logistic regression.", "token2charspan": [[0, 4], [5, 13], [14, 17], [18, 25], [26, 33], [34, 36], [37, 40], [41, 46], [46, 54], [55, 56], [56, 58], [59, 64], [64, 72], [72, 73], [74, 80], [80, 81], [82, 87], [88, 96], [97, 98], [99, 108], [109, 116], [117, 119], [120, 131], [132, 140], [141, 151], [151, 152]]}
{"doc_key": "ai-dev-44", "ner": [[0, 0, "conference"], [3, 3, "misc"], [4, 13, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["ACL", "has", "a", "European", "Chapter", "(", "European", "Chapter", "of", "the", "Association", "for", "Computational", "Linguistics", ")", "."], "sentence-detokenized": "ACL has a European Chapter (European Chapter of the Association for Computational Linguistics).", "token2charspan": [[0, 3], [4, 7], [8, 9], [10, 18], [19, 26], [27, 28], [28, 36], [37, 44], [45, 47], [48, 51], [52, 63], [64, 67], [68, 81], [82, 93], [93, 94], [94, 95]]}
{"doc_key": "ai-dev-45", "ner": [[3, 4, "researcher"], [6, 8, "researcher"], [22, 22, "misc"], [24, 25, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 4, 22, 22, "role", "", false, false], [6, 8, 22, 22, "role", "", false, false], [22, 22, 24, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "professors", ",", "Hal", "Abelson", "and", "Gerald", "Jay", "Sussman", ",", "chose", "to", "remain", "neutral", "-", "their", "group", "was", "referred", "to", "variously", "as", "Switzerland", "and", "Project", "MAC", "for", "the", "next", "30", "years", "."], "sentence-detokenized": "Two professors, Hal Abelson and Gerald Jay Sussman, chose to remain neutral - their group was referred to variously as Switzerland and Project MAC for the next 30 years.", "token2charspan": [[0, 3], [4, 14], [14, 15], [16, 19], [20, 27], [28, 31], [32, 38], [39, 42], [43, 50], [50, 51], [52, 57], [58, 60], [61, 67], [68, 75], [76, 77], [78, 83], [84, 89], [90, 93], [94, 102], [103, 105], [106, 115], [116, 118], [119, 130], [131, 134], [135, 142], [143, 146], [147, 150], [151, 154], [155, 159], [160, 162], [163, 168], [168, 169]]}
{"doc_key": "ai-dev-46", "ner": [[2, 3, "misc"], [5, 7, "researcher"], [9, 11, "university"], [16, 16, "organisation"], [21, 23, "organisation"], [27, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 5, 7, "temporal", "", false, false], [5, 7, 16, 16, "physical", "", false, false], [5, 7, 16, 16, "role", "", false, false], [5, 7, 21, 23, "role", "", false, false], [21, 23, 9, 11, "part-of", "", false, false], [27, 28, 21, 23, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["After", "earning", "his", "PhD", ",", "Ghahramani", "moved", "to", "the", "University", "of", "Toronto", "in", "1995", "as", "an", "ITRC", "Postdoctoral", "Fellow", "in", "the", "Artificial", "Intelligence", "Laboratory", ",", "working", "with", "Geoffrey", "Hinton", "."], "sentence-detokenized": "After earning his PhD, Ghahramani moved to the University of Toronto in 1995 as an ITRC Postdoctoral Fellow in the Artificial Intelligence Laboratory, working with Geoffrey Hinton.", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 21], [21, 22], [23, 33], [34, 39], [40, 42], [43, 46], [47, 57], [58, 60], [61, 68], [69, 71], [72, 76], [77, 79], [80, 82], [83, 87], [88, 100], [101, 107], [108, 110], [111, 114], [115, 125], [126, 138], [139, 149], [149, 150], [151, 158], [159, 163], [164, 172], [173, 179], [179, 180]]}
{"doc_key": "ai-dev-47", "ner": [[25, 27, "metrics"], [29, 31, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[29, 31, 25, 27, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Subsequent", "work", "has", "focused", "on", "solving", "these", "problems", ",", "but", "research", "only", "took", "off", "with", "the", "advent", "of", "the", "modern", "computer", "and", "the", "popularisation", "of", "maximum", "likelihood", "parameterisation", "(", "MLE", ")", "techniques", "."], "sentence-detokenized": "Subsequent work has focused on solving these problems, but research only took off with the advent of the modern computer and the popularisation of maximum likelihood parameterisation (MLE) techniques.", "token2charspan": [[0, 10], [11, 15], [16, 19], [20, 27], [28, 30], [31, 38], [39, 44], [45, 53], [53, 54], [55, 58], [59, 67], [68, 72], [73, 77], [78, 81], [82, 86], [87, 90], [91, 97], [98, 100], [101, 104], [105, 111], [112, 120], [121, 124], [125, 128], [129, 143], [144, 146], [147, 154], [155, 165], [166, 182], [183, 184], [184, 187], [187, 188], [189, 199], [199, 200]]}
{"doc_key": "ai-dev-48", "ner": [[5, 7, "person"], [9, 10, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "series", "was", "produced", "by", "David", "Fincher", "and", "starred", "Kevin", "Spacey", "."], "sentence-detokenized": "The series was produced by David Fincher and starred Kevin Spacey.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 23], [24, 26], [27, 32], [33, 40], [41, 44], [45, 52], [53, 58], [59, 65], [65, 66]]}
{"doc_key": "ai-dev-49", "ner": [[16, 16, "metrics"], [23, 24, "algorithm"], [30, 32, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[23, 24, 30, 32, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Because", "of", "computational", "power", "limitations", ",", "current", "in", "silico", "methods", "usually", "have", "to", "substitute", "speed", "for", "accuracy", ";", "for", "example", ",", "using", "fast", "protein", "docking", "methods", "instead", "of", "computationally", "expensive", "free", "energy", "calculations", "."], "sentence-detokenized": "Because of computational power limitations, current in silico methods usually have to substitute speed for accuracy; for example, using fast protein docking methods instead of computationally expensive free energy calculations.", "token2charspan": [[0, 7], [8, 10], [11, 24], [25, 30], [31, 42], [42, 43], [44, 51], [52, 54], [55, 61], [62, 69], [70, 77], [78, 82], [83, 85], [86, 96], [97, 102], [103, 106], [107, 115], [115, 116], [117, 120], [121, 128], [128, 129], [130, 135], [136, 140], [141, 148], [149, 156], [157, 164], [165, 172], [173, 175], [176, 191], [192, 201], [202, 206], [207, 213], [214, 226], [226, 227]]}
{"doc_key": "ai-dev-50", "ner": [[7, 7, "country"], [9, 9, "country"], [11, 11, "country"], [13, 13, "country"], [15, 15, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "had", "over", "30", "locations", "in", "the", "US", ",", "Canada", ",", "Mexico", ",", "Brazil", "and", "Argentina", "."], "sentence-detokenized": "It had over 30 locations in the US, Canada, Mexico, Brazil and Argentina.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 14], [15, 24], [25, 27], [28, 31], [32, 34], [34, 35], [36, 42], [42, 43], [44, 50], [50, 51], [52, 58], [59, 62], [63, 72], [72, 73]]}
{"doc_key": "ai-dev-51", "ner": [[5, 6, "field"], [11, 13, "product"], [15, 17, "algorithm"], [23, 24, "task"], [26, 27, "task"], [32, 32, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 13, 5, 6, "part-of", "", false, false], [11, 13, 15, 17, "usage", "", false, false], [23, 24, 5, 6, "part-of", "task_part_of_field", false, false], [23, 24, 32, 32, "related-to", "performs", false, false], [26, 27, 5, 6, "part-of", "task_part_of_field", false, false], [26, 27, 32, 32, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["An", "example", "of", "a", "typical", "computer", "vision", "computational", "pipeline", "for", "a", "facial", "recognition", "system", "using", "k", "-", "NN", ",", "including", "pre-processing", "steps", "for", "feature", "extraction", "and", "size", "reduction", "(", "usually", "implemented", "with", "OpenCV", ")", ":"], "sentence-detokenized": "An example of a typical computer vision computational pipeline for a facial recognition system using k -NN, including pre-processing steps for feature extraction and size reduction (usually implemented with OpenCV):", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 23], [24, 32], [33, 39], [40, 53], [54, 62], [63, 66], [67, 68], [69, 75], [76, 87], [88, 94], [95, 100], [101, 102], [103, 104], [104, 106], [106, 107], [108, 117], [118, 132], [133, 138], [139, 142], [143, 150], [151, 161], [162, 165], [166, 170], [171, 180], [181, 182], [182, 189], [190, 201], [202, 206], [207, 213], [213, 214], [214, 215]]}
{"doc_key": "ai-dev-52", "ner": [[9, 11, "algorithm"], [13, 13, "misc"], [15, 16, "misc"], [22, 22, "programlang"], [24, 24, "product"], [28, 29, "algorithm"], [31, 32, "misc"], [34, 34, "misc"], [36, 36, "misc"], [38, 38, "misc"], [45, 45, "misc"], [47, 47, "misc"], [49, 50, "misc"]], "ner_mapping_to_source": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "has", "a", "rich", "feature", "set", ",", "libraries", "for", "constrained", "logic", "programming", ",", "multithreading", ",", "unit", "testing", ",", "GUI", ",", "interfacing", "with", "Java", ",", "ODBC", "and", "others", ",", "literate", "programming", ",", "web", "server", ",", "SGML", ",", "RDF", ",", "RDFS", ",", "development", "tools", "(", "including", "an", "IDE", "with", "debugger", "and", "GUI", "profiler", ")", "and", "extensive", "documentation", "."], "sentence-detokenized": "It has a rich feature set, libraries for constrained logic programming, multithreading, unit testing, GUI, interfacing with Java, ODBC and others, literate programming, web server, SGML, RDF, RDFS, development tools (including an IDE with debugger and GUI profiler) and extensive documentation.", "token2charspan": [[0, 2], [3, 6], [7, 8], [9, 13], [14, 21], [22, 25], [25, 26], [27, 36], [37, 40], [41, 52], [53, 58], [59, 70], [70, 71], [72, 86], [86, 87], [88, 92], [93, 100], [100, 101], [102, 105], [105, 106], [107, 118], [119, 123], [124, 128], [128, 129], [130, 134], [135, 138], [139, 145], [145, 146], [147, 155], [156, 167], [167, 168], [169, 172], [173, 179], [179, 180], [181, 185], [185, 186], [187, 190], [190, 191], [192, 196], [196, 197], [198, 209], [210, 215], [216, 217], [217, 226], [227, 229], [230, 233], [234, 238], [239, 247], [248, 251], [252, 255], [256, 264], [264, 265], [266, 269], [270, 279], [280, 293], [293, 294]]}
{"doc_key": "ai-dev-53", "ner": [[4, 5, "field"], [7, 8, "field"], [13, 14, "misc"], [17, 19, "misc"], [15, 24, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 14, 4, 5, "part-of", "", true, false], [13, 14, 7, 8, "part-of", "", false, false], [13, 14, 15, 24, "type-of", "", false, false], [17, 19, 4, 5, "part-of", "", false, false], [17, 19, 7, 8, "part-of", "", false, false], [17, 19, 15, 24, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "the", "field", "of", "computer", "vision", "and", "image", "processing", ",", "the", "notion", "of", "scale", "space", "representation", "and", "Gaussian", "derivative", "operators", "represent", "a", "canonical", "multiscale", "representation", "."], "sentence-detokenized": "In the field of computer vision and image processing, the notion of scale space representation and Gaussian derivative operators represent a canonical multiscale representation.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 15], [16, 24], [25, 31], [32, 35], [36, 41], [42, 52], [52, 53], [54, 57], [58, 64], [65, 67], [68, 73], [74, 79], [80, 94], [95, 98], [99, 107], [108, 118], [119, 128], [129, 138], [139, 140], [141, 150], [151, 161], [162, 176], [176, 177]]}
{"doc_key": "ai-dev-54", "ner": [[5, 10, "organisation"], [7, 23, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 10, 7, 23, "role", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "is", "also", "president", "of", "the", "Neural", "Information", "Processing", "Systems", "Foundation", ",", "a", "non-profit", "organization", "that", "oversees", "the", "annual", "Neural", "Information", "Processing", "Systems", "Conference", "."], "sentence-detokenized": "He is also president of the Neural Information Processing Systems Foundation, a non-profit organization that oversees the annual Neural Information Processing Systems Conference.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 20], [21, 23], [24, 27], [28, 34], [35, 46], [47, 57], [58, 65], [66, 76], [76, 77], [78, 79], [80, 90], [91, 103], [104, 108], [109, 117], [118, 121], [122, 128], [129, 135], [136, 147], [148, 158], [159, 166], [167, 177], [177, 178]]}
{"doc_key": "ai-dev-55", "ner": [[1, 3, "task"], [5, 7, "metrics"], [13, 14, "misc"], [23, 23, "task"], [17, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 3, 5, 7, "usage", "", false, false], [5, 7, 13, 14, "type-of", "", false, false], [23, 23, 17, 18, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["For", "regression", "analysis", "problems", ",", "the", "squared", "error", "can", "be", "used", "as", "a", "loss", "function", "and", "the", "cross", "-entropy", "can", "be", "used", "for", "classification", "."], "sentence-detokenized": "For regression analysis problems, the squared error can be used as a loss function and the cross-entropy can be used for classification.", "token2charspan": [[0, 3], [4, 14], [15, 23], [24, 32], [32, 33], [34, 37], [38, 45], [46, 51], [52, 55], [56, 58], [59, 63], [64, 66], [67, 68], [69, 73], [74, 82], [83, 86], [87, 90], [91, 96], [96, 104], [105, 108], [109, 111], [112, 116], [117, 120], [121, 135], [135, 136]]}
{"doc_key": "ai-dev-56", "ner": [[0, 2, "researcher"], [17, 20, "conference"], [19, 19, "conference"], [28, 28, "university"], [29, 35, "field"], [43, 47, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 17, 20, "role", "", false, false], [0, 2, 28, 28, "physical", "", false, false], [0, 2, 28, 28, "role", "", false, false], [0, 2, 43, 47, "role", "", false, false], [17, 20, 19, 19, "named", "same", false, false], [28, 28, 29, 35, "related-to", "subject_of_study_at", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Lafferty", "has", "held", "numerous", "prestigious", "positions", ",", "including", "1", ")", "program", "co-chair", "and", "general", "co-chair", "of", "the", "Neural", "Information", "Processing", "Systems", "Foundation", "conferences", ";", "2", ")", "co-director", "of", "CMU", "'s", "new", "PhD", "program", "in", "machine", "learning", ";", "3", ")", "associate", "editor", "of", "the", "Journal", "of", "Machine", "Learning", "Research"], "sentence-detokenized": "Lafferty has held numerous prestigious positions, including 1) program co-chair and general co-chair of the Neural Information Processing Systems Foundation conferences; 2) co-director of CMU's new PhD program in machine learning; 3) associate editor of the Journal of Machine Learning Research", "token2charspan": [[0, 8], [9, 12], [13, 17], [18, 26], [27, 38], [39, 48], [48, 49], [50, 59], [60, 61], [61, 62], [63, 70], [71, 79], [80, 83], [84, 91], [92, 100], [101, 103], [104, 107], [108, 114], [115, 126], [127, 137], [138, 145], [146, 156], [157, 168], [168, 169], [170, 171], [171, 172], [173, 184], [185, 187], [188, 191], [191, 193], [194, 197], [198, 201], [202, 209], [210, 212], [213, 220], [221, 229], [229, 230], [231, 232], [232, 233], [234, 243], [244, 250], [251, 253], [254, 257], [258, 265], [266, 268], [269, 276], [277, 285], [286, 294]]}
{"doc_key": "ai-dev-57", "ner": [[0, 1, "misc"], [5, 5, "algorithm"], [7, 7, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 0, 1, "type-of", "", false, false], [7, 7, 0, 1, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Convex", "algorithms", ",", "such", "as", "AdaBoost", "and", "LogitBoost", ",", "can", "be", "defeated", "by", "random", "noise", ",", "so", "they", "can", "not", "learn", "basic", "and", "learnable", "combinations", "of", "weak", "hypotheses", "."], "sentence-detokenized": "Convex algorithms, such as AdaBoost and LogitBoost, can be defeated by random noise, so they cannot learn basic and learnable combinations of weak hypotheses.", "token2charspan": [[0, 6], [7, 17], [17, 18], [19, 23], [24, 26], [27, 35], [36, 39], [40, 50], [50, 51], [52, 55], [56, 58], [59, 67], [68, 70], [71, 77], [78, 83], [83, 84], [85, 87], [88, 92], [93, 96], [96, 99], [100, 105], [106, 111], [112, 115], [116, 125], [126, 138], [139, 141], [142, 146], [147, 157], [157, 158]]}
{"doc_key": "ai-dev-58", "ner": [[0, 0, "product"], [3, 7, "product"], [10, 12, "algorithm"], [19, 22, "algorithm"], [23, 28, "task"], [30, 32, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 3, 7, "type-of", "", false, false], [0, 0, 10, 12, "usage", "", false, false], [0, 0, 19, 22, "usage", "", false, false], [19, 22, 23, 28, "related-to", "used_for", true, false], [19, 22, 30, 32, "related-to", "used_for", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Apertium", "is", "a", "shallow", "transfer", "machine", "translation", "system", "that", "uses", "finite", "state", "transducers", "for", "all", "its", "lexical", "transformations", "and", "hidden", "Markov", "models", "for", "part", "-", "of", "-", "speech", "tagging", "or", "word", "category", "disambiguation", "."], "sentence-detokenized": "Apertium is a shallow transfer machine translation system that uses finite state transducers for all its lexical transformations and hidden Markov models for part-of-speech tagging or word category disambiguation.", "token2charspan": [[0, 8], [9, 11], [12, 13], [14, 21], [22, 30], [31, 38], [39, 50], [51, 57], [58, 62], [63, 67], [68, 74], [75, 80], [81, 92], [93, 96], [97, 100], [101, 104], [105, 112], [113, 128], [129, 132], [133, 139], [140, 146], [147, 153], [154, 157], [158, 162], [162, 163], [163, 165], [165, 166], [166, 172], [173, 180], [181, 183], [184, 188], [189, 197], [198, 212], [212, 213]]}
{"doc_key": "ai-dev-59", "ner": [[0, 2, "misc"], [15, 17, "metrics"], [30, 31, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 2, 15, 17, "related-to", "", true, false], [15, 17, 30, 31, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "natural", "gradient", "of", "mathE", "f", "(", "x", ")", "/", "math", ",", "which", "follows", "the", "Fisher", "informational", "metric", "(", "a", "measure", "of", "the", "informational", "distance", "between", "probability", "distributions", "and", "the", "relative", "entropy", "curvature", ")", ",", "is", "now", "as", "follows"], "sentence-detokenized": "The natural gradient of mathE f (x) / math, which follows the Fisher informational metric (a measure of the informational distance between probability distributions and the relative entropy curvature), is now as follows", "token2charspan": [[0, 3], [4, 11], [12, 20], [21, 23], [24, 29], [30, 31], [32, 33], [33, 34], [34, 35], [36, 37], [38, 42], [42, 43], [44, 49], [50, 57], [58, 61], [62, 68], [69, 82], [83, 89], [90, 91], [91, 92], [93, 100], [101, 103], [104, 107], [108, 121], [122, 130], [131, 138], [139, 150], [151, 164], [165, 168], [169, 172], [173, 181], [182, 189], [190, 199], [199, 200], [200, 201], [202, 204], [205, 208], [209, 211], [212, 219]]}
{"doc_key": "ai-dev-60", "ner": [[0, 3, "programlang"], [6, 9, "product"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 9, 0, 3, "origin", "", false, false], [11, 11, 0, 3, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "S", "programming", "language", "inspired", "the", "S", "'", "-", "PLUS", "and", "R", "systems", "."], "sentence-detokenized": "The S programming language inspired the S'-PLUS and R systems.", "token2charspan": [[0, 3], [4, 5], [6, 17], [18, 26], [27, 35], [36, 39], [40, 41], [41, 42], [42, 43], [43, 47], [48, 51], [52, 53], [54, 61], [61, 62]]}
{"doc_key": "ai-dev-61", "ner": [[5, 5, "product"], [8, 8, "product"], [12, 14, "product"], [18, 20, "researcher"], [22, 23, "researcher"], [25, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 5, 8, 8, "named", "same", false, false], [12, 14, 8, 8, "origin", "derived_from", false, false], [12, 14, 18, 20, "origin", "", false, false], [12, 14, 22, 23, "origin", "", false, false], [12, 14, 25, 26, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "most", "influential", "implementation", "of", "Planner", "was", "the", "Planner", "subset", ",", "called", "Micro", "-", "Planner", ",", "implemented", "by", "Gerald", "Jay", "Sussman", ",", "Eugene", "Charniak", "and", "Terry", "Winograd", "."], "sentence-detokenized": "The most influential implementation of Planner was the Planner subset, called Micro-Planner, implemented by Gerald Jay Sussman, Eugene Charniak and Terry Winograd.", "token2charspan": [[0, 3], [4, 8], [9, 20], [21, 35], [36, 38], [39, 46], [47, 50], [51, 54], [55, 62], [63, 69], [69, 70], [71, 77], [78, 83], [83, 84], [84, 91], [91, 92], [93, 104], [105, 107], [108, 114], [115, 118], [119, 126], [126, 127], [128, 134], [135, 143], [144, 147], [148, 153], [154, 162], [162, 163]]}
{"doc_key": "ai-dev-62", "ner": [[3, 5, "country"], [7, 9, "researcher"], [20, 20, "misc"], [19, 25, "university"], [34, 35, "misc"], [42, 42, "misc"], [48, 51, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7], "relations": [[7, 9, 3, 5, "general-affiliation", "from_country", false, false], [19, 25, 20, 20, "general-affiliation", "nationality", false, false]], "relations_mapping_to_source": [1, 2], "sentence": ["In", "1779", ",", "German", "-", "Danish", "scientist", "Christian", "Gottlieb", "Kratzenstein", "won", "first", "prize", "in", "a", "competition", "announced", "by", "the", "Imperial", "Russian", "Academy", "of", "Sciences", "and", "Arts", "for", "the", "models", "he", "built", "of", "the", "human", "vocal", "tract", "that", "could", "produce", "the", "five", "long", "vowels", "(", "in", "the", "notation", "of", "the", "international", "phonetic", "alphabet", ":"], "sentence-detokenized": "In 1779, German-Danish scientist Christian Gottlieb Kratzenstein won first prize in a competition announced by the Imperial Russian Academy of Sciences and Arts for the models he built of the human vocal tract that could produce the five long vowels (in the notation of the international phonetic alphabet:", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [15, 16], [16, 22], [23, 32], [33, 42], [43, 51], [52, 64], [65, 68], [69, 74], [75, 80], [81, 83], [84, 85], [86, 97], [98, 107], [108, 110], [111, 114], [115, 123], [124, 131], [132, 139], [140, 142], [143, 151], [152, 155], [156, 160], [161, 164], [165, 168], [169, 175], [176, 178], [179, 184], [185, 187], [188, 191], [192, 197], [198, 203], [204, 209], [210, 214], [215, 220], [221, 228], [229, 232], [233, 237], [238, 242], [243, 249], [250, 251], [251, 253], [254, 257], [258, 266], [267, 269], [270, 273], [274, 287], [288, 296], [297, 305], [305, 306]]}
{"doc_key": "ai-dev-63", "ner": [[3, 4, "product"], [6, 7, "misc"], [10, 14, "misc"], [32, 34, "misc"], [53, 54, "task"], [59, 60, "product"], [62, 64, "product"], [68, 68, "task"], [71, 73, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[3, 4, 59, 60, "related-to", "supports_program", false, false], [3, 4, 62, 64, "related-to", "supports_program", false, false], [6, 7, 3, 4, "part-of", "", false, false], [10, 14, 3, 4, "part-of", "", false, false], [32, 34, 3, 4, "part-of", "", false, false], [53, 54, 3, 4, "part-of", "", false, false], [68, 68, 3, 4, "part-of", "", false, false], [71, 73, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["New", "features", "in", "Office", "XP", "include", "Smart", "Labels", ",", "a", "selection", "-", "based", "search", "function", "that", "recognizes", "different", "types", "of", "text", "in", "a", "document", "so", "users", "can", "take", "additional", "actions", ";", "a", "task", "pane", "interface", "that", "consolidates", "popular", "menu", "bar", "commands", "to", "the", "right", "side", "of", "the", "screen", "for", "easy", "access", ";", "new", "document", "collaboration", "capabilities", ",", "support", "for", "MSN", "Groups", "and", "SharePoint", ";", "and", "built", "-", "in", "handwriting", "recognition", "and", "speech", "recognition", "capabilities", "."], "sentence-detokenized": "New features in Office XP include Smart Labels, a selection-based search function that recognizes different types of text in a document so users can take additional actions; a task pane interface that consolidates popular menu bar commands to the right side of the screen for easy access; new document collaboration capabilities, support for MSN Groups and SharePoint; and built-in handwriting recognition and speech recognition capabilities.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 22], [23, 25], [26, 33], [34, 39], [40, 46], [46, 47], [48, 49], [50, 59], [59, 60], [60, 65], [66, 72], [73, 81], [82, 86], [87, 97], [98, 107], [108, 113], [114, 116], [117, 121], [122, 124], [125, 126], [127, 135], [136, 138], [139, 144], [145, 148], [149, 153], [154, 164], [165, 172], [172, 173], [174, 175], [176, 180], [181, 185], [186, 195], [196, 200], [201, 213], [214, 221], [222, 226], [227, 230], [231, 239], [240, 242], [243, 246], [247, 252], [253, 257], [258, 260], [261, 264], [265, 271], [272, 275], [276, 280], [281, 287], [287, 288], [289, 292], [293, 301], [302, 315], [316, 328], [328, 329], [330, 337], [338, 341], [342, 345], [346, 352], [353, 356], [357, 367], [367, 368], [369, 372], [373, 378], [378, 379], [379, 381], [382, 393], [394, 405], [406, 409], [410, 416], [417, 428], [429, 441], [441, 442]]}
{"doc_key": "ai-dev-64", "ner": [[11, 12, "algorithm"], [15, 16, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 12, 15, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "many", "applications", ",", "the", "units", "of", "these", "networks", "apply", "a", "sigmoid", "function", "as", "an", "activation", "function", "."], "sentence-detokenized": "In many applications, the units of these networks apply a sigmoid function as an activation function.", "token2charspan": [[0, 2], [3, 7], [8, 20], [20, 21], [22, 25], [26, 31], [32, 34], [35, 40], [41, 49], [50, 55], [56, 57], [58, 65], [66, 74], [75, 77], [78, 80], [81, 91], [92, 100], [100, 101]]}
{"doc_key": "ai-dev-65", "ner": [[3, 4, "researcher"], [12, 17, "organisation"], [29, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 12, 17, "role", "", false, false], [3, 4, 29, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2001", ",", "Mehler", "was", "elected", "a", "Foreign", "Honorary", "Fellow", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "and", "in", "2003", "he", "was", "elected", "a", "Fellow", "of", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In 2001, Mehler was elected a Foreign Honorary Fellow of the American Academy of Arts and Sciences, and in 2003 he was elected a Fellow of the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 27], [28, 29], [30, 37], [38, 46], [47, 53], [54, 56], [57, 60], [61, 69], [70, 77], [78, 80], [81, 85], [86, 89], [90, 98], [98, 99], [100, 103], [104, 106], [107, 111], [112, 114], [115, 118], [119, 126], [127, 128], [129, 135], [136, 138], [139, 142], [143, 151], [152, 163], [164, 167], [168, 171], [172, 183], [184, 186], [187, 194], [194, 195]]}
{"doc_key": "ai-dev-66", "ner": [[4, 6, "task"], [10, 11, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 10, 11, "cause-effect", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Extending", "this", "concept", "to", "non", "-binary", "classifications", "leads", "to", "the", "confusion", "matrix", "."], "sentence-detokenized": "Extending this concept to non-binary classifications leads to the confusion matrix.", "token2charspan": [[0, 9], [10, 14], [15, 22], [23, 25], [26, 29], [29, 36], [37, 52], [53, 58], [59, 61], [62, 65], [66, 75], [76, 82], [82, 83]]}
{"doc_key": "ai-dev-67", "ner": [[13, 14, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["An", "updated", "estimate", "of", "the", "measurement", "noise", "variance", "can", "be", "obtained", "from", "the", "maximum", "likelihood", "calculation"], "sentence-detokenized": "An updated estimate of the measurement noise variance can be obtained from the maximum likelihood calculation", "token2charspan": [[0, 2], [3, 10], [11, 19], [20, 22], [23, 26], [27, 38], [39, 44], [45, 53], [54, 57], [58, 60], [61, 69], [70, 74], [75, 78], [79, 86], [87, 97], [98, 109]]}
{"doc_key": "ai-dev-68", "ner": [[1, 2, "field"], [4, 5, "algorithm"], [8, 11, "field"], [9, 10, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[4, 5, 8, 11, "usage", "", true, false], [4, 5, 9, 10, "related-to", "", true, false], [8, 11, 1, 2, "type-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "machine", "learning", ",", "the", "perceptron", "is", "a", "supervised", "binary", "classification", "learning", "algorithm", "."], "sentence-detokenized": "In machine learning, the perceptron is a supervised binary classification learning algorithm.", "token2charspan": [[0, 2], [3, 10], [11, 19], [19, 20], [21, 24], [25, 35], [36, 38], [39, 40], [41, 51], [52, 58], [59, 73], [74, 82], [83, 92], [92, 93]]}
{"doc_key": "ai-dev-69", "ner": [[9, 10, "field"], [18, 22, "conference"], [25, 29, "conference"], [36, 38, "conference"], [41, 45, "conference"], [12, 53, "conference"]], "ner_mapping_to_source": [0, 2, 3, 4, 5, 6], "relations": [[18, 22, 9, 10, "topic", "", false, false], [25, 29, 9, 10, "topic", "", false, false], [36, 38, 9, 10, "topic", "", false, false], [41, 45, 9, 10, "topic", "", false, false], [12, 53, 9, 10, "topic", "", false, false]], "relations_mapping_to_source": [0, 2, 4, 6, 8], "sentence": ["He", "has", "also", "served", "as", "area", "chair", "for", "several", "machine", "learning", "and", "vision", "conferences", ",", "including", "the", "Conference", "on", "Neural", "Information", "Processing", "Systems", ",", "the", "International", "Conference", "on", "Learning", "Representations", ",", "the", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "the", "International", "Conference", "on", "Computer", "Vision", ",", "and", "the", "European", "Conference", "on", "Computer", "Vision", "."], "sentence-detokenized": "He has also served as area chair for several machine learning and vision conferences, including the Conference on Neural Information Processing Systems, the International Conference on Learning Representations, the Conference on Computer Vision and Pattern Recognition, the International Conference on Computer Vision, and the European Conference on Computer Vision.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 21], [22, 26], [27, 32], [33, 36], [37, 44], [45, 52], [53, 61], [62, 65], [66, 72], [73, 84], [84, 85], [86, 95], [96, 99], [100, 110], [111, 113], [114, 120], [121, 132], [133, 143], [144, 151], [151, 152], [153, 156], [157, 170], [171, 181], [182, 184], [185, 193], [194, 209], [209, 210], [211, 214], [215, 225], [226, 228], [229, 237], [238, 244], [245, 248], [249, 256], [257, 268], [268, 269], [270, 273], [274, 287], [288, 298], [299, 301], [302, 310], [311, 317], [317, 318], [319, 322], [323, 326], [327, 335], [336, 346], [347, 349], [350, 358], [359, 365], [365, 366]]}
{"doc_key": "ai-dev-70", "ner": [[0, 2, "algorithm"], [8, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 10, 0, 2, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "condensation", "algorithm", "was", "also", "used", "for", "the", "facial", "recognition", "system", "in", "a", "video", "sequence", "."], "sentence-detokenized": "The condensation algorithm was also used for the facial recognition system in a video sequence.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 30], [31, 35], [36, 40], [41, 44], [45, 48], [49, 55], [56, 67], [68, 74], [75, 77], [78, 79], [80, 85], [86, 94], [94, 95]]}
{"doc_key": "ai-dev-71", "ner": [[0, 3, "task"], [6, 7, "organisation"], [19, 19, "conference"], [24, 28, "academicjournal"], [32, 32, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 19, 0, 3, "topic", "", false, false], [19, 19, 6, 7, "origin", "", false, false], [24, 28, 0, 3, "topic", "", false, false], [24, 28, 6, 7, "origin", "", true, false], [32, 32, 24, 28, "role", "edited_by", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Dissemination", "of", "information", "is", "part", "of", "ELRA", "'s", "mission", ",", "which", "is", "achieved", "both", "through", "the", "organisation", "of", "the", "LREC", "conference", "and", "through", "the", "Language", "Resources", "and", "Evaluation", "Journal", ",", "published", "by", "Springer", "."], "sentence-detokenized": "Dissemination of information is part of ELRA's mission, which is achieved both through the organisation of the LREC conference and through the Language Resources and Evaluation Journal, published by Springer.", "token2charspan": [[0, 13], [14, 16], [17, 28], [29, 31], [32, 36], [37, 39], [40, 44], [44, 46], [47, 54], [54, 55], [56, 61], [62, 64], [65, 73], [74, 78], [79, 86], [87, 90], [91, 103], [104, 106], [107, 110], [111, 115], [116, 126], [127, 130], [131, 138], [139, 142], [143, 151], [152, 161], [162, 165], [166, 176], [177, 184], [184, 185], [186, 195], [196, 198], [199, 207], [207, 208]]}
{"doc_key": "ai-dev-72", "ner": [[1, 8, "field"], [11, 12, "field"], [14, 14, "field"], [15, 19, "field"], [6, 56, "field"], [61, 62, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[1, 8, 6, 56, "named", "", false, false], [14, 14, 1, 8, "named", "", false, false], [61, 62, 11, 12, "part-of", "", true, false], [61, 62, 14, 14, "part-of", "", true, false], [61, 62, 6, 56, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "linear", "time", "-", "invariant", "(", "LTI", ")", "systems", "theory", ",", "control", "theory", "and", "digital", "signal", "processing", "or", "signal", "processing", ",", "the", "relationship", "between", "the", "input", "signal", ",", "math", "\\", "displaystyle", "x", "(", "t", ")", "/", "math", ",", "and", "the", "output", "signal", ",", "math", "\\", "displaystyle", "y", "(", "t", ")", "/", "math", ",", "of", "an", "LTI", "system", "is", "governed", "by", "a", "convolution", "operation", ":"], "sentence-detokenized": "In linear time-invariant (LTI) systems theory, control theory and digital signal processing or signal processing, the relationship between the input signal, math\\ displaystyle x (t)/ math, and the output signal, math\\ displaystyle y (t)/ math, of an LTI system is governed by a convolution operation:", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [15, 24], [25, 26], [26, 29], [29, 30], [31, 38], [39, 45], [45, 46], [47, 54], [55, 61], [62, 65], [66, 73], [74, 80], [81, 91], [92, 94], [95, 101], [102, 112], [112, 113], [114, 117], [118, 130], [131, 138], [139, 142], [143, 148], [149, 155], [155, 156], [157, 161], [161, 162], [163, 175], [176, 177], [178, 179], [179, 180], [180, 181], [181, 182], [183, 187], [187, 188], [189, 192], [193, 196], [197, 203], [204, 210], [210, 211], [212, 216], [216, 217], [218, 230], [231, 232], [233, 234], [234, 235], [235, 236], [236, 237], [238, 242], [242, 243], [244, 246], [247, 249], [250, 253], [254, 260], [261, 263], [264, 272], [273, 275], [276, 277], [278, 289], [290, 299], [299, 300]]}
{"doc_key": "ai-dev-73", "ner": [[16, 16, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 31, "field"], [33, 34, "product"], [36, 37, "field"], [39, 39, "field"], [41, 42, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["Because", "of", "its", "generality", ",", "this", "field", "is", "studied", "in", "many", "other", "disciplines", ",", "such", "as", "game", "theory", ",", "control", "theory", ",", "operations", "research", ",", "information", "theory", ",", "simulation", "-", "based", "optimization", ",", "multi-agent", "systems", ",", "swarm", "intelligence", ",", "statistics", "and", "genetic", "algorithms", "."], "sentence-detokenized": "Because of its generality, this field is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, statistics and genetic algorithms.", "token2charspan": [[0, 7], [8, 10], [11, 14], [15, 25], [25, 26], [27, 31], [32, 37], [38, 40], [41, 48], [49, 51], [52, 56], [57, 62], [63, 74], [74, 75], [76, 80], [81, 83], [84, 88], [89, 95], [95, 96], [97, 104], [105, 111], [111, 112], [113, 123], [124, 132], [132, 133], [134, 145], [146, 152], [152, 153], [154, 164], [164, 165], [165, 170], [171, 183], [183, 184], [185, 196], [197, 204], [204, 205], [206, 211], [212, 224], [224, 225], [226, 236], [237, 240], [241, 248], [249, 259], [259, 260]]}
{"doc_key": "ai-dev-74", "ner": [[0, 2, "algorithm"], [15, 16, "field"], [19, 20, "algorithm"], [26, 27, "algorithm"], [33, 34, "algorithm"], [38, 38, "algorithm"], [39, 41, "researcher"], [43, 44, "researcher"], [46, 48, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[15, 16, 0, 2, "usage", "", true, false], [19, 20, 15, 16, "part-of", "", true, false], [26, 27, 15, 16, "part-of", "", true, false], [33, 34, 15, 16, "part-of", "", true, false], [38, 38, 15, 16, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Stochastic", "gradient", "descent", "is", "a", "popular", "algorithm", "for", "training", "a", "wide", "range", "of", "models", "in", "machine", "learning", ",", "including", "support", "vector", "(", "linear", ")", "machines", ",", "logistic", "regression", "(", "see", ",", "e.g.", ",", "Vowpal", "Wabbit", ")", ",", "and", "graphical", "models.Jenny", "Rose", "Finkel", ",", "Alex", "Kleeman", ",", "Christopher", "D.", "Manning", "(", "2008", ")", "."], "sentence-detokenized": "Stochastic gradient descent is a popular algorithm for training a wide range of models in machine learning, including support vector (linear) machines, logistic regression (see, e.g., Vowpal Wabbit), and graphical models.Jenny Rose Finkel, Alex Kleeman, Christopher D. Manning (2008).", "token2charspan": [[0, 10], [11, 19], [20, 27], [28, 30], [31, 32], [33, 40], [41, 50], [51, 54], [55, 63], [64, 65], [66, 70], [71, 76], [77, 79], [80, 86], [87, 89], [90, 97], [98, 106], [106, 107], [108, 117], [118, 125], [126, 132], [133, 134], [134, 140], [140, 141], [142, 150], [150, 151], [152, 160], [161, 171], [172, 173], [173, 176], [176, 177], [178, 182], [182, 183], [184, 190], [191, 197], [197, 198], [198, 199], [200, 203], [204, 213], [214, 226], [227, 231], [232, 238], [238, 239], [240, 244], [245, 252], [252, 253], [254, 265], [266, 268], [269, 276], [277, 278], [278, 282], [282, 283], [283, 284]]}
{"doc_key": "ai-dev-75", "ner": [[8, 8, "organisation"], [12, 13, "product"], [20, 20, "country"], [22, 25, "university"], [27, 27, "location"], [29, 31, "university"], [33, 33, "location"], [35, 35, "university"], [38, 38, "location"], [40, 42, "university"], [44, 44, "location"], [46, 47, "university"], [49, 49, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[8, 8, 22, 25, "role", "donates_to", false, false], [8, 8, 29, 31, "role", "donates_to", false, false], [8, 8, 35, 35, "role", "donates_to", false, false], [8, 8, 40, 42, "role", "donates_to", false, false], [8, 8, 46, 47, "role", "donates_to", false, false], [12, 13, 8, 8, "origin", "donates", true, false], [22, 25, 27, 27, "physical", "", false, false], [27, 27, 20, 20, "physical", "", false, false], [29, 31, 33, 33, "physical", "", false, false], [33, 33, 20, 20, "physical", "", false, false], [35, 35, 38, 38, "physical", "", false, false], [38, 38, 20, 20, "physical", "", false, false], [40, 42, 44, 44, "physical", "", false, false], [44, 44, 20, 20, "physical", "", false, false], [46, 47, 49, 49, "physical", "", false, false], [49, 49, 20, 20, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "sentence": ["In", "August", "2011", ",", "it", "was", "announced", "that", "Hitachi", "would", "donate", "an", "electron", "microscope", "to", "each", "of", "five", "universities", "in", "Indonesia", "(", "University", "of", "North", "Sumatra", "in", "Medan", ",", "Indonesian", "Christian", "University", "in", "Jakarta", ",", "Padjadjaran", "University", "in", "Bandung", ",", "Jenderal", "Soedirman", "University", "in", "Purwokerto", "and", "Muhammadiyah", "University", "in", "Malang", ")", "."], "sentence-detokenized": "In August 2011, it was announced that Hitachi would donate an electron microscope to each of five universities in Indonesia (University of North Sumatra in Medan, Indonesian Christian University in Jakarta, Padjadjaran University in Bandung, Jenderal Soedirman University in Purwokerto and Muhammadiyah University in Malang).", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 18], [19, 22], [23, 32], [33, 37], [38, 45], [46, 51], [52, 58], [59, 61], [62, 70], [71, 81], [82, 84], [85, 89], [90, 92], [93, 97], [98, 110], [111, 113], [114, 123], [124, 125], [125, 135], [136, 138], [139, 144], [145, 152], [153, 155], [156, 161], [161, 162], [163, 173], [174, 183], [184, 194], [195, 197], [198, 205], [205, 206], [207, 218], [219, 229], [230, 232], [233, 240], [240, 241], [242, 250], [251, 260], [261, 271], [272, 274], [275, 285], [286, 289], [290, 302], [303, 313], [314, 316], [317, 323], [323, 324], [324, 325]]}
{"doc_key": "ai-dev-76", "ner": [[2, 2, "field"], [0, 3, "field"], [7, 8, "algorithm"], [10, 11, "algorithm"], [20, 21, "field"], [26, 27, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 0, 3, "part-of", "", false, false], [2, 2, 20, 21, "related-to", "", true, false], [2, 2, 26, 27, "related-to", "", true, false], [7, 8, 2, 2, "type-of", "", false, false], [10, 11, 2, 2, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Operations", "research", "optimization", "techniques", ",", "such", "as", "linear", "programming", "or", "dynamic", "programming", ",", "are", "often", "impractical", "for", "large", "-", "scale", "software", "engineering", "problems", "because", "of", "their", "computational", "complexity", "."], "sentence-detokenized": "Operations research optimization techniques, such as linear programming or dynamic programming, are often impractical for large-scale software engineering problems because of their computational complexity.", "token2charspan": [[0, 10], [11, 19], [20, 32], [33, 43], [43, 44], [45, 49], [50, 52], [53, 59], [60, 71], [72, 74], [75, 82], [83, 94], [94, 95], [96, 99], [100, 105], [106, 117], [118, 121], [122, 127], [127, 128], [128, 133], [134, 142], [143, 154], [155, 163], [164, 171], [172, 174], [175, 180], [181, 194], [195, 205], [205, 206]]}
{"doc_key": "ai-dev-77", "ner": [[0, 0, "metrics"], [6, 6, "metrics"], [8, 10, "metrics"], [15, 15, "metrics"], [18, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 6, 6, "compare", "", false, false], [0, 0, 8, 10, "compare", "", false, false], [15, 15, 8, 10, "part-of", "", false, false], [18, 20, 8, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sensitivity", "is", "not", "the", "same", "as", "accuracy", "or", "positive", "predictive", "value", "(", "the", "ratio", "of", "TRUE", "to", "combined", "TRUE", "and", "FALSE", "positive", "results", ")", ",", "which", "is", "a", "statement", "about", "the", "proportion", "of", "true", "positive", "results", "in", "the", "tested", "population", "as", "well", "as", "the", "test", "."], "sentence-detokenized": "Sensitivity is not the same as accuracy or positive predictive value (the ratio of TRUE to combined TRUE and FALSE positive results), which is a statement about the proportion of true positive results in the tested population as well as the test.", "token2charspan": [[0, 11], [12, 14], [15, 18], [19, 22], [23, 27], [28, 30], [31, 39], [40, 42], [43, 51], [52, 62], [63, 68], [69, 70], [70, 73], [74, 79], [80, 82], [83, 87], [88, 90], [91, 99], [100, 104], [105, 108], [109, 114], [115, 123], [124, 131], [131, 132], [132, 133], [134, 139], [140, 142], [143, 144], [145, 154], [155, 160], [161, 164], [165, 175], [176, 178], [179, 183], [184, 192], [193, 200], [201, 203], [204, 207], [208, 214], [215, 225], [226, 228], [229, 233], [234, 236], [237, 240], [241, 245], [245, 246]]}
{"doc_key": "ai-dev-78", "ner": [[0, 1, "person"], [8, 8, "product"], [11, 11, "person"], [25, 25, "person"], [33, 34, "person"], [38, 38, "person"], [44, 45, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 38, 38, "named", "same", false, false], [8, 8, 0, 1, "artifact", "", false, false], [33, 34, 44, 45, "role", "convinces", false, false], [44, 45, 8, 8, "role", "producer", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Hampton", "Fancher", "'s", "Scenario", "!!!--", "Not", "originally", "titled", "Android", "--", "See", "Sammon", ",", "pp.", "32", "and", "38", "for", "explanation", "--", "was", "optioned", "in", "1977", ".", "Sammon", ",", "pp.", "23", "-", "30", ".", "Producer", "Michael", "Deeley", "became", "interested", "in", "Fancher", "'s", "project", "and", "convinced", "director", "Ridley", "Scott", "to", "film", "it", "."], "sentence-detokenized": "Hampton Fancher's Scenario!!!-- Not originally titled Android -- See Sammon, pp. 32 and 38 for explanation -- was optioned in 1977. Sammon, pp. 23-30. Producer Michael Deeley became interested in Fancher's project and convinced director Ridley Scott to film it.", "token2charspan": [[0, 7], [8, 15], [15, 17], [18, 26], [26, 31], [32, 35], [36, 46], [47, 53], [54, 61], [62, 64], [65, 68], [69, 75], [75, 76], [77, 80], [81, 83], [84, 87], [88, 90], [91, 94], [95, 106], [107, 109], [110, 113], [114, 122], [123, 125], [126, 130], [130, 131], [132, 138], [138, 139], [140, 143], [144, 146], [146, 147], [147, 149], [149, 150], [151, 159], [160, 167], [168, 174], [175, 181], [182, 192], [193, 195], [196, 203], [203, 205], [206, 213], [214, 217], [218, 227], [228, 236], [237, 243], [244, 249], [250, 252], [253, 257], [258, 260], [260, 261]]}
{"doc_key": "ai-dev-79", "ner": [[0, 1, "field"], [3, 4, "task"], [6, 7, "task"], [10, 12, "misc"], [14, 15, "field"], [17, 19, "task"], [21, 22, "task"], [24, 25, "field"], [28, 31, "task"], [33, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[3, 4, 0, 1, "part-of", "", false, false], [6, 7, 0, 1, "part-of", "", false, false], [10, 12, 0, 1, "part-of", "", false, false], [14, 15, 0, 1, "part-of", "", false, false], [17, 19, 0, 1, "part-of", "", false, false], [21, 22, 0, 1, "part-of", "", false, false], [24, 25, 0, 1, "part-of", "", false, false], [28, 31, 0, 1, "part-of", "", false, false], [33, 33, 0, 1, "part-of", "", false, false], [35, 36, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "sentence": ["Text", "analysis", "involves", "information", "retrieval", ",", "lexical", "analysis", "to", "study", "word", "frequency", "distribution", ",", "pattern", "recognition", ",", "tagging", "/", "annotation", ",", "information", "extraction", ",", "data", "mining", "techniques", "including", "link", "and", "association", "analysis", ",", "visualization", "and", "predictive", "analysis", "."], "sentence-detokenized": "Text analysis involves information retrieval, lexical analysis to study word frequency distribution, pattern recognition, tagging/annotation, information extraction, data mining techniques including link and association analysis, visualization and predictive analysis.", "token2charspan": [[0, 4], [5, 13], [14, 22], [23, 34], [35, 44], [44, 45], [46, 53], [54, 62], [63, 65], [66, 71], [72, 76], [77, 86], [87, 99], [99, 100], [101, 108], [109, 120], [120, 121], [122, 129], [129, 130], [130, 140], [140, 141], [142, 153], [154, 164], [164, 165], [166, 170], [171, 177], [178, 188], [189, 198], [199, 203], [204, 207], [208, 219], [220, 228], [228, 229], [230, 243], [244, 247], [248, 258], [259, 267], [267, 268]]}
{"doc_key": "ai-dev-80", "ner": [[3, 3, "product"], [12, 13, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[12, 13, 3, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Several", "indicators", "use", "WordNet", ",", "a", "hand", "-", "built", "lexical", "database", "of", "English", "words", "."], "sentence-detokenized": "Several indicators use WordNet, a hand-built lexical database of English words.", "token2charspan": [[0, 7], [8, 18], [19, 22], [23, 30], [30, 31], [32, 33], [34, 38], [38, 39], [39, 44], [45, 52], [53, 61], [62, 64], [65, 72], [73, 78], [78, 79]]}
{"doc_key": "ai-dev-81", "ner": [[8, 9, "field"], [11, 12, "task"], [14, 18, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "system", "uses", "a", "combination", "of", "techniques", "from", "computational", "linguistics", ",", "information", "retrieval", "and", "knowledge", "representation", "to", "find", "answers", "."], "sentence-detokenized": "The system uses a combination of techniques from computational linguistics, information retrieval and knowledge representation to find answers.", "token2charspan": [[0, 3], [4, 10], [11, 15], [16, 17], [18, 29], [30, 32], [33, 43], [44, 48], [49, 62], [63, 74], [74, 75], [76, 87], [88, 97], [98, 101], [102, 111], [112, 126], [127, 129], [130, 134], [135, 142], [142, 143]]}
{"doc_key": "ai-dev-82", "ner": [[5, 7, "metrics"], [13, 13, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 7, 13, 13, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "performance", "indicator", ",", "the", "uncertainty", "coefficient", "has", "the", "advantage", "over", "simple", "precision", "because", "it", "is", "not", "affected", "by", "the", "relative", "sizes", "of", "the", "different", "classes", "."], "sentence-detokenized": "As a performance indicator, the uncertainty coefficient has the advantage over simple precision because it is not affected by the relative sizes of the different classes.", "token2charspan": [[0, 2], [3, 4], [5, 16], [17, 26], [26, 27], [28, 31], [32, 43], [44, 55], [56, 59], [60, 63], [64, 73], [74, 78], [79, 85], [86, 95], [96, 103], [104, 106], [107, 109], [110, 113], [114, 122], [123, 125], [126, 129], [130, 138], [139, 144], [145, 147], [148, 151], [152, 161], [162, 169], [169, 170]]}
{"doc_key": "ai-dev-83", "ner": [[9, 10, "algorithm"], [12, 13, "algorithm"], [15, 16, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Researchers", "have", "tried", "a", "number", "of", "methods", "such", "as", "optical", "flow", ",", "Kalman", "filtering", ",", "hidden", "Markov", "models", ",", "etc", "."], "sentence-detokenized": "Researchers have tried a number of methods such as optical flow, Kalman filtering, hidden Markov models, etc.", "token2charspan": [[0, 11], [12, 16], [17, 22], [23, 24], [25, 31], [32, 34], [35, 42], [43, 47], [48, 50], [51, 58], [59, 63], [63, 64], [65, 71], [72, 81], [81, 82], [83, 89], [90, 96], [97, 103], [103, 104], [105, 108], [108, 109]]}
{"doc_key": "ai-dev-84", "ner": [[15, 18, "conference"], [37, 39, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "served", "as", "President", ",", "Vice", "President", ",", "and", "Secretary", "-", "Treasurer", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "was", "a", "member", "of", "the", "Board", "of", "Directors", "and", "Secretary", "of", "the", "Board", "of", "Directors", "of", "the", "Computing", "Research", "Association", "."], "sentence-detokenized": "He has served as President, Vice President, and Secretary-Treasurer of the Association for Computational Linguistics and was a member of the Board of Directors and Secretary of the Board of Directors of the Computing Research Association.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 16], [17, 26], [26, 27], [28, 32], [33, 42], [42, 43], [44, 47], [48, 57], [57, 58], [58, 67], [68, 70], [71, 74], [75, 86], [87, 90], [91, 104], [105, 116], [117, 120], [121, 124], [125, 126], [127, 133], [134, 136], [137, 140], [141, 146], [147, 149], [150, 159], [160, 163], [164, 173], [174, 176], [177, 180], [181, 186], [187, 189], [190, 199], [200, 202], [203, 206], [207, 216], [217, 225], [226, 237], [237, 238]]}
{"doc_key": "ai-dev-85", "ner": [[5, 5, "programlang"], [7, 7, "product"], [9, 9, "programlang"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 9, 9, "compare", "", false, false], [5, 5, 11, 12, "related-to", "supports", false, false], [7, 7, 9, 9, "compare", "", false, false], [7, 7, 11, 12, "related-to", "supports", false, false], [9, 9, 11, 12, "related-to", "supports", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Like", "similar", "languages", "such", "as", "APL", "and", "MATLAB", ",", "R", "supports", "matrix", "arithmetic", "."], "sentence-detokenized": "Like similar languages such as APL and MATLAB, R supports matrix arithmetic.", "token2charspan": [[0, 4], [5, 12], [13, 22], [23, 27], [28, 30], [31, 34], [35, 38], [39, 45], [45, 46], [47, 48], [49, 57], [58, 64], [65, 75], [75, 76]]}
{"doc_key": "ai-dev-86", "ner": [[7, 8, "misc"], [12, 13, "organisation"], [17, 18, "researcher"], [21, 23, "university"], [27, 32, "misc"], [34, 34, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[7, 8, 12, 13, "physical", "", false, false], [7, 8, 27, 32, "temporal", "", false, false], [17, 18, 7, 8, "role", "arranges", false, false], [17, 18, 21, 23, "role", "works_for", false, false], [34, 34, 7, 8, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["On", "7", "June", "2014", ",", "in", "a", "Turing", "test", "competition", "at", "the", "Royal", "Society", ",", "organised", "by", "Kevin", "Warwick", "of", "the", "University", "of", "Reading", "to", "mark", "the", "60th", "anniversary", "of", "Turing", "'s", "death", ",", "Goostman", "won", "after", "33", "%", "of", "the", "judges", "were", "convinced", "that", "the", "robot", "was", "human", "."], "sentence-detokenized": "On 7 June 2014, in a Turing test competition at the Royal Society, organised by Kevin Warwick of the University of Reading to mark the 60th anniversary of Turing's death, Goostman won after 33% of the judges were convinced that the robot was human.", "token2charspan": [[0, 2], [3, 4], [5, 9], [10, 14], [14, 15], [16, 18], [19, 20], [21, 27], [28, 32], [33, 44], [45, 47], [48, 51], [52, 57], [58, 65], [65, 66], [67, 76], [77, 79], [80, 85], [86, 93], [94, 96], [97, 100], [101, 111], [112, 114], [115, 122], [123, 125], [126, 130], [131, 134], [135, 139], [140, 151], [152, 154], [155, 161], [161, 163], [164, 169], [169, 170], [171, 179], [180, 183], [184, 189], [190, 192], [192, 193], [194, 196], [197, 200], [201, 207], [208, 212], [213, 222], [223, 227], [228, 231], [232, 237], [238, 241], [242, 247], [247, 248]]}
{"doc_key": "ai-dev-87", "ner": [[1, 2, "product"], [4, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 4, 1, 2, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "collaborative", "robot", "or", "cobot", "is", "a", "robot", "that", "can", "interact", "safely", "and", "effectively", "with", "human", "workers", "while", "performing", "simple", "industrial", "tasks", "."], "sentence-detokenized": "A collaborative robot or cobot is a robot that can interact safely and effectively with human workers while performing simple industrial tasks.", "token2charspan": [[0, 1], [2, 15], [16, 21], [22, 24], [25, 30], [31, 33], [34, 35], [36, 41], [42, 46], [47, 50], [51, 59], [60, 66], [67, 70], [71, 82], [83, 87], [88, 93], [94, 101], [102, 107], [108, 118], [119, 125], [126, 136], [137, 142], [142, 143]]}
{"doc_key": "ai-dev-88", "ner": [[11, 12, "field"], [17, 17, "task"], [16, 19, "task"], [21, 22, "task"], [24, 25, "task"], [27, 28, "task"], [30, 32, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[17, 17, 11, 12, "part-of", "task_part_of_field", false, false], [16, 19, 11, 12, "part-of", "task_part_of_field", false, false], [21, 22, 11, 12, "part-of", "task_part_of_field", false, false], [24, 25, 11, 12, "part-of", "task_part_of_field", false, false], [27, 28, 11, 12, "part-of", "task_part_of_field", false, false], [30, 32, 11, 12, "part-of", "task_part_of_field", false, false], [35, 36, 11, 12, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["This", "general", "framework", "has", "been", "applied", "to", "a", "wide", "variety", "of", "computer", "vision", "problems", ",", "including", "feature", "detection", "and", "classification", ",", "image", "segmentation", ",", "image", "matching", ",", "motion", "estimation", ",", "shape", "index", "computation", ",", "and", "object", "recognition", "."], "sentence-detokenized": "This general framework has been applied to a wide variety of computer vision problems, including feature detection and classification, image segmentation, image matching, motion estimation, shape index computation, and object recognition.", "token2charspan": [[0, 4], [5, 12], [13, 22], [23, 26], [27, 31], [32, 39], [40, 42], [43, 44], [45, 49], [50, 57], [58, 60], [61, 69], [70, 76], [77, 85], [85, 86], [87, 96], [97, 104], [105, 114], [115, 118], [119, 133], [133, 134], [135, 140], [141, 153], [153, 154], [155, 160], [161, 169], [169, 170], [171, 177], [178, 188], [188, 189], [190, 195], [196, 201], [202, 213], [213, 214], [215, 218], [219, 225], [226, 237], [237, 238]]}
{"doc_key": "ai-dev-89", "ner": [[5, 6, "task"], [10, 10, "algorithm"], [13, 13, "algorithm"], [8, 27, "algorithm"], [32, 32, "algorithm"], [31, 37, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[5, 6, 10, 10, "part-of", "", false, false], [5, 6, 13, 13, "usage", "", false, false], [10, 10, 8, 27, "named", "same", false, false], [8, 27, 32, 32, "related-to", "", false, false], [8, 27, 31, 37, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "many", "practical", "applications", ",", "parameter", "estimation", "for", "naive", "Bayes", "models", "uses", "the", "maximum", "likelihood", "method", ";", "in", "other", "words", ",", "one", "can", "work", "with", "the", "naive", "Bayes", "model", "without", "accepting", "Bayesian", "likelihood", "or", "without", "using", "Bayesian", "methods", "."], "sentence-detokenized": "In many practical applications, parameter estimation for naive Bayes models uses the maximum likelihood method; in other words, one can work with the naive Bayes model without accepting Bayesian likelihood or without using Bayesian methods.", "token2charspan": [[0, 2], [3, 7], [8, 17], [18, 30], [30, 31], [32, 41], [42, 52], [53, 56], [57, 62], [63, 68], [69, 75], [76, 80], [81, 84], [85, 92], [93, 103], [104, 110], [110, 111], [112, 114], [115, 120], [121, 126], [126, 127], [128, 131], [132, 135], [136, 140], [141, 145], [146, 149], [150, 155], [156, 161], [162, 167], [168, 175], [176, 185], [186, 194], [195, 205], [206, 208], [209, 216], [217, 222], [223, 231], [232, 239], [239, 240]]}
{"doc_key": "ai-dev-90", "ner": [[2, 2, "researcher"], [6, 9, "misc"], [11, 14, "university"], [3, 18, "researcher"], [20, 21, "misc"], [25, 25, "university"], [27, 27, "university"], [30, 30, "misc"], [37, 64, "university"], [45, 48, "misc"], [50, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[2, 2, 11, 14, "physical", "", false, false], [2, 2, 11, 14, "role", "", false, false], [2, 2, 3, 18, "social", "brothers", false, false], [6, 9, 2, 2, "named", "", false, false], [3, 18, 25, 25, "physical", "", false, false], [3, 18, 25, 25, "role", "", false, false], [3, 18, 27, 27, "physical", "", false, false], [3, 18, 27, 27, "role", "", false, false], [3, 18, 37, 64, "physical", "", false, false], [3, 18, 37, 64, "role", "", false, false], [20, 21, 3, 18, "named", "", false, false], [30, 30, 3, 18, "origin", "", false, false], [45, 48, 3, 18, "artifact", "", false, false], [45, 48, 50, 53, "part-of", "part", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["Brothers", "-", "Victor", "Gershevich", "Katz", ",", "American", "mathematician", ",", "professor", "at", "Massachusetts", "Institute", "of", "Technology", ";", "Mikhail", "Gershevich", "Katz", ",", "Israeli", "mathematician", ",", "graduate", "of", "Harvard", "and", "Columbia", "Universities", "(", "Ph.D.", ",", "1984", ")", ",", "professor", "at", "Bar-", "Ilan", "University", ",", "author", "of", "the", "monograph", "Systolic", "Geometry", "and", "Topology", "(", "Mathematical", "Surveys", "and", "Monographs", ",", "vol", ".", "I", ",", "no.", "1", ",", "Bucharest", ",", "USA", ")", "."], "sentence-detokenized": "Brothers - Victor Gershevich Katz, American mathematician, professor at Massachusetts Institute of Technology; Mikhail Gershevich Katz, Israeli mathematician, graduate of Harvard and Columbia Universities (Ph.D. , 1984), professor at Bar-Ilan University, author of the monograph Systolic Geometry and Topology (Mathematical Surveys and Monographs, vol. I, no. 1, Bucharest, USA).", "token2charspan": [[0, 8], [9, 10], [11, 17], [18, 28], [29, 33], [33, 34], [35, 43], [44, 57], [57, 58], [59, 68], [69, 71], [72, 85], [86, 95], [96, 98], [99, 109], [109, 110], [111, 118], [119, 129], [130, 134], [134, 135], [136, 143], [144, 157], [157, 158], [159, 167], [168, 170], [171, 178], [179, 182], [183, 191], [192, 204], [205, 206], [206, 211], [212, 213], [214, 218], [218, 219], [219, 220], [221, 230], [231, 233], [234, 238], [238, 242], [243, 253], [253, 254], [255, 261], [262, 264], [265, 268], [269, 278], [279, 287], [288, 296], [297, 300], [301, 309], [310, 311], [311, 323], [324, 331], [332, 335], [336, 346], [346, 347], [348, 351], [351, 352], [353, 354], [354, 355], [356, 359], [360, 361], [361, 362], [363, 372], [372, 373], [374, 377], [377, 378], [378, 379]]}
{"doc_key": "ai-dev-91", "ner": [[3, 4, "person"], [10, 11, "conference"], [16, 19, "organisation"], [21, 27, "location"], [31, 31, "person"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 10, 11, "physical", "", false, false], [3, 4, 10, 11, "role", "", false, false], [3, 4, 16, 19, "role", "", false, false], [16, 19, 21, 27, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "2000", ",", "Manuel", "Toharia", ",", "a", "speaker", "at", "previous", "Campus", "Parties", "and", "director", "of", "the", "Pr\u00edncipe", "Felipe", "Science", "Museum", "in", "Valencia", "'s", "City", "of", "Arts", "and", "Sciences", ",", "suggested", "that", "Ragageles", "expand", "and", "make", "the", "event", "more", "international", "by", "moving", "it", "to", "the", "famous", "museum", "."], "sentence-detokenized": "In 2000, Manuel Toharia, a speaker at previous Campus Parties and director of the Pr\u00edncipe Felipe Science Museum in Valencia's City of Arts and Sciences, suggested that Ragageles expand and make the event more international by moving it to the famous museum.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 23], [23, 24], [25, 26], [27, 34], [35, 37], [38, 46], [47, 53], [54, 61], [62, 65], [66, 74], [75, 77], [78, 81], [82, 90], [91, 97], [98, 105], [106, 112], [113, 115], [116, 124], [124, 126], [127, 131], [132, 134], [135, 139], [140, 143], [144, 152], [152, 153], [154, 163], [164, 168], [169, 178], [179, 185], [186, 189], [190, 194], [195, 198], [199, 204], [205, 209], [210, 223], [224, 226], [227, 233], [234, 236], [237, 239], [240, 243], [244, 250], [251, 257], [257, 258]]}
{"doc_key": "ai-dev-92", "ner": [[5, 7, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Within", "20", "minutes", ",", "a", "facial", "recognition", "system", "identifies", "personal", "information", ",", "including", "last", "name", ",", "ID", "number", "and", "address", ",", "which", "is", "displayed", "on", "the", "street", "on", "an", "advertising", "screen", "."], "sentence-detokenized": "Within 20 minutes, a facial recognition system identifies personal information, including last name, ID number and address, which is displayed on the street on an advertising screen.", "token2charspan": [[0, 6], [7, 9], [10, 17], [17, 18], [19, 20], [21, 27], [28, 39], [40, 46], [47, 57], [58, 66], [67, 78], [78, 79], [80, 89], [90, 94], [95, 99], [99, 100], [101, 103], [104, 110], [111, 114], [115, 122], [122, 123], [124, 129], [130, 132], [133, 142], [143, 145], [146, 149], [150, 156], [157, 159], [160, 162], [163, 174], [175, 181], [181, 182]]}
{"doc_key": "ai-dev-93", "ner": [[6, 7, "field"], [9, 11, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Recent", "research", "has", "increasingly", "focused", "on", "unsupervised", "learning", "and", "semi-supervised", "learning", "algorithms", "."], "sentence-detokenized": "Recent research has increasingly focused on unsupervised learning and semi-supervised learning algorithms.", "token2charspan": [[0, 6], [7, 15], [16, 19], [20, 32], [33, 40], [41, 43], [44, 56], [57, 65], [66, 69], [70, 85], [86, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-dev-94", "ner": [[4, 5, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Calculating", "this", "example", "using", "Python", "code", ":"], "sentence-detokenized": "Calculating this example using Python code:", "token2charspan": [[0, 11], [12, 16], [17, 24], [25, 30], [31, 37], [38, 42], [42, 43]]}
{"doc_key": "ai-dev-95", "ner": [[7, 10, "task"], [15, 16, "field"], [19, 23, "algorithm"], [25, 25, "algorithm"], [29, 31, "algorithm"], [34, 35, "researcher"], [37, 38, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[19, 23, 15, 16, "part-of", "", false, false], [19, 23, 29, 31, "type-of", "", false, false], [19, 23, 34, 35, "origin", "", false, false], [19, 23, 37, 38, "origin", "", false, false], [25, 25, 19, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Today", ",", "however", ",", "many", "aspects", "of", "speech", "recognition", "have", "been", "taken", "up", "by", "a", "deep", "learning", "method", "called", "Long", "short", "-", "term", "memory", "(", "LSTM", ")", ",", "a", "recurrent", "neural", "network", "published", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "in", "1997", "."], "sentence-detokenized": "Today, however, many aspects of speech recognition have been taken up by a deep learning method called Long short-term memory (LSTM), a recurrent neural network published by Sepp Hochreiter and J\u00fcrgen Schmidhuber in 1997.", "token2charspan": [[0, 5], [5, 6], [7, 14], [14, 15], [16, 20], [21, 28], [29, 31], [32, 38], [39, 50], [51, 55], [56, 60], [61, 66], [67, 69], [70, 72], [73, 74], [75, 79], [80, 88], [89, 95], [96, 102], [103, 107], [108, 113], [113, 114], [114, 118], [119, 125], [126, 127], [127, 131], [131, 132], [132, 133], [134, 135], [136, 145], [146, 152], [153, 160], [161, 170], [171, 173], [174, 178], [179, 189], [190, 193], [194, 200], [201, 212], [213, 215], [216, 220], [220, 221]]}
{"doc_key": "ai-dev-96", "ner": [[14, 16, "algorithm"], [18, 18, "algorithm"], [8, 23, "algorithm"]], "ner_mapping_to_source": [1, 2, 3], "relations": [[18, 18, 8, 23, "compare", "", false, false]], "relations_mapping_to_source": [2], "sentence": ["In", "preliminary", "experimental", "results", "with", "noisy", "datasets", ",", "BrownBoost", "outperformed", "the", "generalization", "error", "of", "AdaBoost", ";", "however", ",", "LogitBoost", "performed", "as", "well", "as", "BrownBoost", "."], "sentence-detokenized": "In preliminary experimental results with noisy datasets, BrownBoost outperformed the generalization error of AdaBoost; however, LogitBoost performed as well as BrownBoost.", "token2charspan": [[0, 2], [3, 14], [15, 27], [28, 35], [36, 40], [41, 46], [47, 55], [55, 56], [57, 67], [68, 80], [81, 84], [85, 99], [100, 105], [106, 108], [109, 117], [117, 118], [119, 126], [126, 127], [128, 138], [139, 148], [149, 151], [152, 156], [157, 159], [160, 170], [170, 171]]}
{"doc_key": "ai-dev-97", "ner": [[0, 1, "algorithm"], [5, 7, "researcher"], [10, 10, "country"], [13, 15, "researcher"], [19, 20, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 5, 7, "part-of", "", false, false], [5, 7, 10, 10, "physical", "", false, false], [19, 20, 13, 15, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Evolutionary", "programming", "was", "introduced", "by", "Lawrence", "J.", "Fogel", "in", "the", "USA", ",", "while", "John", "Henry", "Holland", "called", "his", "method", "genetic", "algorithm", "."], "sentence-detokenized": "Evolutionary programming was introduced by Lawrence J. Fogel in the USA, while John Henry Holland called his method genetic algorithm.", "token2charspan": [[0, 12], [13, 24], [25, 28], [29, 39], [40, 42], [43, 51], [52, 54], [55, 60], [61, 63], [64, 67], [68, 71], [71, 72], [73, 78], [79, 83], [84, 89], [90, 97], [98, 104], [105, 108], [109, 115], [116, 123], [124, 133], [133, 134]]}
{"doc_key": "ai-dev-98", "ner": [[2, 2, "researcher"], [4, 4, "researcher"], [10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"], [19, 20, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 2, 10, 11, "role", "", false, false], [2, 2, 13, 14, "role", "", false, false], [2, 2, 16, 17, "role", "", false, false], [2, 2, 19, 20, "role", "", false, false], [4, 4, 10, 11, "role", "", false, false], [4, 4, 13, 14, "role", "", false, false], [4, 4, 16, 17, "role", "", false, false], [4, 4, 19, 20, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Calculations", "by", "Doug", ",", "Alan", "and", "their", "colleagues", "(", "including", "Marvin", "Minsky", ",", "Allen", "Newell", ",", "Edward", "Feigenbaum", "and", "John", "McCarthy", ")", "indicated", "that", "this", "effort", "would", "require", "between", "1000", "and", "3000", "person", "-", "years", ",", "well", "above", "the", "standard", "academic", "project", "model", "."], "sentence-detokenized": "Calculations by Doug, Alan and their colleagues (including Marvin Minsky, Allen Newell, Edward Feigenbaum and John McCarthy) indicated that this effort would require between 1000 and 3000 person-years, well above the standard academic project model.", "token2charspan": [[0, 12], [13, 15], [16, 20], [20, 21], [22, 26], [27, 30], [31, 36], [37, 47], [48, 49], [49, 58], [59, 65], [66, 72], [72, 73], [74, 79], [80, 86], [86, 87], [88, 94], [95, 105], [106, 109], [110, 114], [115, 123], [123, 124], [125, 134], [135, 139], [140, 144], [145, 151], [152, 157], [158, 165], [166, 173], [174, 178], [179, 182], [183, 187], [188, 194], [194, 195], [195, 200], [200, 201], [202, 206], [207, 212], [213, 216], [217, 225], [226, 234], [235, 242], [243, 248], [248, 249]]}
{"doc_key": "ai-dev-99", "ner": [[5, 7, "metrics"], [11, 11, "metrics"], [14, 16, "metrics"], [19, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 7, 11, 11, "part-of", "implemented_in", false, false], [14, 16, 19, 19, "part-of", "implemented_in", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "common", "criteria", "are", "the", "mean", "squared", "error", "criterion", "implemented", "in", "MSECriterion", "and", "the", "cross", "-entropy", "criterion", "implemented", "in", "NLLCriterion", "."], "sentence-detokenized": "The common criteria are the mean squared error criterion implemented in MSECriterion and the cross-entropy criterion implemented in NLLCriterion.", "token2charspan": [[0, 3], [4, 10], [11, 19], [20, 23], [24, 27], [28, 32], [33, 40], [41, 46], [47, 56], [57, 68], [69, 71], [72, 84], [85, 88], [89, 92], [93, 98], [98, 106], [107, 116], [117, 128], [129, 131], [132, 144], [144, 145]]}
{"doc_key": "ai-dev-100", "ner": [[0, 0, "researcher"], [11, 11, "organisation"], [15, 26, "misc"], [28, 31, "conference"], [37, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 11, 11, "role", "", false, false], [0, 0, 28, 31, "role", "", false, false], [0, 0, 37, 37, "role", "", false, false], [15, 26, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Zurada", "has", "served", "the", "engineering", "profession", "as", "a", "long", "-", "time", "IEEE", "volunteer", ":", "as", "IEEE", "Vice", "President", "for", "Technical", "Activities", "(", "TAB", "Chair", ")", "in", "2014", ",", "IEEE", "Computational", "Intelligence", "Society", "President", "in", "2004-2005", ",", "and", "ADCOM", "member", "in", "2009-2014", ",", "2016", "-", "18", ",", "and", "previous", "years", "."], "sentence-detokenized": "Zurada has served the engineering profession as a long-time IEEE volunteer: as IEEE Vice President for Technical Activities (TAB Chair) in 2014, IEEE Computational Intelligence Society President in 2004-2005, and ADCOM member in 2009-2014, 2016-18, and previous years.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 21], [22, 33], [34, 44], [45, 47], [48, 49], [50, 54], [54, 55], [55, 59], [60, 64], [65, 74], [74, 75], [76, 78], [79, 83], [84, 88], [89, 98], [99, 102], [103, 112], [113, 123], [124, 125], [125, 128], [129, 134], [134, 135], [136, 138], [139, 143], [143, 144], [145, 149], [150, 163], [164, 176], [177, 184], [185, 194], [195, 197], [198, 207], [207, 208], [209, 212], [213, 218], [219, 225], [226, 228], [229, 238], [238, 239], [240, 244], [244, 245], [245, 247], [247, 248], [249, 252], [253, 261], [262, 267], [267, 268]]}
{"doc_key": "ai-dev-101", "ner": [[3, 6, "field"], [12, 13, "field"], [15, 17, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[12, 13, 3, 6, "part-of", "", false, false], [15, 17, 3, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "general", ",", "computational", "linguistics", "relies", "on", "the", "involvement", "of", "linguists", ",", "computer", "scientists", ",", "artificial", "intelligence", "experts", ",", "mathematicians", ",", "logicians", ",", "philosophers", ",", "cognitive", "scientists", ",", "cognitive", "psychologists", ",", "psycholinguists", ",", "anthropologists", "and", "neuroscientists", ",", "among", "others", "."], "sentence-detokenized": "In general, computational linguistics relies on the involvement of linguists, computer scientists, artificial intelligence experts, mathematicians, logicians, philosophers, cognitive scientists, cognitive psychologists, psycholinguists, anthropologists and neuroscientists, among others.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 25], [26, 37], [38, 44], [45, 47], [48, 51], [52, 63], [64, 66], [67, 76], [76, 77], [78, 86], [87, 97], [97, 98], [99, 109], [110, 122], [123, 130], [130, 131], [132, 146], [146, 147], [148, 157], [157, 158], [159, 171], [171, 172], [173, 182], [183, 193], [193, 194], [195, 204], [205, 218], [218, 219], [220, 235], [235, 236], [237, 252], [253, 256], [257, 272], [272, 273], [274, 279], [280, 286], [286, 287]]}
{"doc_key": "ai-dev-102", "ner": [[3, 5, "algorithm"], [7, 9, "algorithm"], [11, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Techniques", "such", "as", "dynamic", "Markov", "networks", ",", "convolutional", "neural", "networks", "and", "short", "-", "term", "memory", "are", "often", "used", "to", "exploit", "correlations", "between", "frames", "."], "sentence-detokenized": "Techniques such as dynamic Markov networks, convolutional neural networks and short-term memory are often used to exploit correlations between frames.", "token2charspan": [[0, 10], [11, 15], [16, 18], [19, 26], [27, 33], [34, 42], [42, 43], [44, 57], [58, 64], [65, 73], [74, 77], [78, 83], [83, 84], [84, 88], [89, 95], [96, 99], [100, 105], [106, 110], [111, 113], [114, 121], [122, 134], [135, 142], [143, 149], [149, 150]]}
{"doc_key": "ai-dev-103", "ner": [[0, 0, "product"], [4, 5, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Unimate", "was", "the", "first", "industrial", "robot", ","], "sentence-detokenized": "Unimate was the first industrial robot,", "token2charspan": [[0, 7], [8, 11], [12, 15], [16, 21], [22, 32], [33, 38], [38, 39]]}
{"doc_key": "ai-dev-104", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [10, 13, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[2, 3, 10, 13, "win-defeat", "", false, false], [5, 6, 10, 13, "win-defeat", "", false, false], [8, 8, 10, 13, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Together", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "won", "the", "2018", "Turing", "Award", "."], "sentence-detokenized": "Together with Geoffrey Hinton and Yann LeCun, Bengio won the 2018 Turing Award.", "token2charspan": [[0, 8], [9, 13], [14, 22], [23, 29], [30, 33], [34, 38], [39, 44], [44, 45], [46, 52], [53, 56], [57, 60], [61, 65], [66, 72], [73, 78], [78, 79]]}
{"doc_key": "ai-dev-105", "ner": [[8, 8, "country"], [23, 24, "misc"], [26, 26, "country"], [30, 31, "organisation"], [35, 36, "person"], [39, 41, "person"], [50, 52, "misc"], [57, 57, "country"], [62, 62, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[23, 24, 8, 8, "physical", "filmed_in", false, false], [35, 36, 30, 31, "role", "host", false, false], [39, 41, 30, 31, "role", "reporter", false, false], [50, 52, 8, 8, "physical", "filmed_in", false, false], [50, 52, 57, 57, "physical", "distributed_in", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Additional", "series", "were", "filmed", "on", "location", "in", "the", "UK", "for", "certain", "sectors", "of", "the", "global", "market", ",", "including", "two", "series", "of", "Robot", "Wars", "Extreme", "Warriors", "with", "US", "contestants", "for", "the", "TNN", "network", "(", "presented", "by", "Mick", "Foley", ",", "with", "Rebecca", "Grant", "as", "box", "office", "reporter", ")", ",", "two", "series", "of", "Dutch", "Robot", "Wars", "for", "distribution", "in", "the", "Netherlands", "and", "one", "series", "for", "Germany", "."], "sentence-detokenized": "Additional series were filmed on location in the UK for certain sectors of the global market, including two series of Robot Wars Extreme Warriors with US contestants for the TNN network (presented by Mick Foley, with Rebecca Grant as box office reporter), two series of Dutch Robot Wars for distribution in the Netherlands and one series for Germany.", "token2charspan": [[0, 10], [11, 17], [18, 22], [23, 29], [30, 32], [33, 41], [42, 44], [45, 48], [49, 51], [52, 55], [56, 63], [64, 71], [72, 74], [75, 78], [79, 85], [86, 92], [92, 93], [94, 103], [104, 107], [108, 114], [115, 117], [118, 123], [124, 128], [129, 136], [137, 145], [146, 150], [151, 153], [154, 165], [166, 169], [170, 173], [174, 177], [178, 185], [186, 187], [187, 196], [197, 199], [200, 204], [205, 210], [210, 211], [212, 216], [217, 224], [225, 230], [231, 233], [234, 237], [238, 244], [245, 253], [253, 254], [254, 255], [256, 259], [260, 266], [267, 269], [270, 275], [276, 281], [282, 286], [287, 290], [291, 303], [304, 306], [307, 310], [311, 322], [323, 326], [327, 330], [331, 337], [338, 341], [342, 349], [349, 350]]}
{"doc_key": "ai-dev-106", "ner": [[8, 8, "researcher"], [13, 13, "product"], [27, 28, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 8, 13, 13, "role", "", false, false], [27, 28, 13, 13, "usage", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "several", "years", ",", "beginning", "in", "1986", ",", "Miller", "led", "the", "development", "of", "WordNet", ",", "a", "large", "electronic", "reference", "that", "can", "be", "used", "in", "applications", "such", "as", "search", "engines", "."], "sentence-detokenized": "For several years, beginning in 1986, Miller led the development of WordNet, a large electronic reference that can be used in applications such as search engines.", "token2charspan": [[0, 3], [4, 11], [12, 17], [17, 18], [19, 28], [29, 31], [32, 36], [36, 37], [38, 44], [45, 48], [49, 52], [53, 64], [65, 67], [68, 75], [75, 76], [77, 78], [79, 84], [85, 95], [96, 105], [106, 110], [111, 114], [115, 117], [118, 122], [123, 125], [126, 138], [139, 143], [144, 146], [147, 153], [154, 161], [161, 162]]}
{"doc_key": "ai-dev-107", "ner": [[3, 3, "algorithm"], [4, 9, "algorithm"], [12, 13, "researcher"], [19, 23, "organisation"], [27, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 12, 13, "origin", "", false, false], [3, 3, 27, 29, "win-defeat", "", false, false], [4, 9, 12, 13, "origin", "", false, false], [4, 9, 27, 29, "win-defeat", "", false, false], [12, 13, 19, 23, "physical", "", false, false], [12, 13, 19, 23, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Since", "2009", ",", "recurrent", "neural", "networks", "and", "advanced", "neural", "networks", "developed", "in", "J\u00fcrgen", "Schmidhuber", "'s", "research", "group", "at", "the", "Swiss", "artificial", "intelligence", "laboratory", "IDSIA", "have", "won", "several", "international", "handwriting", "competitions", "..."], "sentence-detokenized": "Since 2009, recurrent neural networks and advanced neural networks developed in J\u00fcrgen Schmidhuber's research group at the Swiss artificial intelligence laboratory IDSIA have won several international handwriting competitions...", "token2charspan": [[0, 5], [6, 10], [10, 11], [12, 21], [22, 28], [29, 37], [38, 41], [42, 50], [51, 57], [58, 66], [67, 76], [77, 79], [80, 86], [87, 98], [98, 100], [101, 109], [110, 115], [116, 118], [119, 122], [123, 128], [129, 139], [140, 152], [153, 163], [164, 169], [170, 174], [175, 178], [179, 186], [187, 200], [201, 212], [213, 225], [225, 228]]}
{"doc_key": "ai-dev-108", "ner": [[5, 6, "programlang"], [11, 11, "programlang"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "software", "is", "implemented", "in", "C", "++", "and", "is", "wrapped", "for", "Python", "."], "sentence-detokenized": "The software is implemented in C++ and is wrapped for Python.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 27], [28, 30], [31, 32], [32, 34], [35, 38], [39, 41], [42, 49], [50, 53], [54, 60], [60, 61]]}
{"doc_key": "ai-dev-109", "ner": [[7, 9, "country"], [14, 15, "misc"], [21, 21, "misc"], [34, 36, "misc"], [37, 38, "misc"], [20, 39, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[21, 21, 7, 9, "temporal", "", false, false], [21, 21, 14, 15, "artifact", "", false, false], [21, 21, 20, 39, "physical", "", false, false], [37, 38, 34, 36, "named", "", false, false], [37, 38, 20, 39, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1857", ",", "at", "the", "request", "of", "the", "Tokugawa", "shogunate", ",", "a", "group", "of", "Dutch", "engineers", "began", "work", "on", "the", "Nagasaki", "Yotetsusho", ",", "a", "modern", ",", "Western", "-", "style", "foundry", "and", "shipyard", "near", "the", "Dutch", "settlement", "of", "Dejima", "in", "Nagasaki", "."], "sentence-detokenized": "In 1857, at the request of the Tokugawa shogunate, a group of Dutch engineers began work on the Nagasaki Yotetsusho, a modern, Western-style foundry and shipyard near the Dutch settlement of Dejima in Nagasaki.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 23], [24, 26], [27, 30], [31, 39], [40, 49], [49, 50], [51, 52], [53, 58], [59, 61], [62, 67], [68, 77], [78, 83], [84, 88], [89, 91], [92, 95], [96, 104], [105, 115], [115, 116], [117, 118], [119, 125], [125, 126], [127, 134], [134, 135], [135, 140], [141, 148], [149, 152], [153, 161], [162, 166], [167, 170], [171, 176], [177, 187], [188, 190], [191, 197], [198, 200], [201, 209], [209, 210]]}
{"doc_key": "ai-dev-110", "ner": [[9, 11, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["We", "specify", "as", "best", "we", "can", "by", "measuring", "the", "mean", "squared", "error", "between", "mathhy", "/", "math", "and", "math", "\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", "/", "math", ":", "we", "want", "math", "(", "y", "-\\", "hat", "{", "f", "}", "(", "x", ";", "D", ")", ")", "^2", "/", "math", "to", "be", "minimum", ",", "both", "for", "mathx", "_", "1", ",\\", "points", ",", "x", "_n", "/", "math", "and", "for", "points", "outside", "our", "sample", "."], "sentence-detokenized": "We specify as best we can by measuring the mean squared error between mathhy / math and math\\ hat {f} (x; D) / math: we want math(y -\\ hat {f} (x; D))^2 / math to be minimum, both for mathx _ 1,\\ points, x _n / math and for points outside our sample.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 18], [19, 21], [22, 25], [26, 28], [29, 38], [39, 42], [43, 47], [48, 55], [56, 61], [62, 69], [70, 76], [77, 78], [79, 83], [84, 87], [88, 92], [92, 93], [94, 97], [98, 99], [99, 100], [100, 101], [102, 103], [103, 104], [104, 105], [106, 107], [107, 108], [109, 110], [111, 115], [115, 116], [117, 119], [120, 124], [125, 129], [129, 130], [130, 131], [132, 134], [135, 138], [139, 140], [140, 141], [141, 142], [143, 144], [144, 145], [145, 146], [147, 148], [148, 149], [149, 150], [150, 152], [153, 154], [155, 159], [160, 162], [163, 165], [166, 173], [173, 174], [175, 179], [180, 183], [184, 189], [190, 191], [192, 193], [193, 195], [196, 202], [202, 203], [204, 205], [206, 208], [209, 210], [211, 215], [216, 219], [220, 223], [224, 230], [231, 238], [239, 242], [243, 249], [249, 250]]}
{"doc_key": "ai-dev-111", "ner": [[6, 7, "researcher"], [14, 17, "organisation"], [23, 27, "product"], [24, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 7, 14, 17, "role", "", false, false], [23, 27, 14, 17, "temporal", "", false, false], [23, 27, 24, 34, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "subsequently", "extended", "an", "invitation", "to", "Wydner", "to", "attend", "the", "annual", "meeting", "of", "the", "American", "Translators", "Association", "the", "following", "October", ",", "where", "the", "Weidner", "machine", "translation", "system", "was", "presented", "as", "a", "breakthrough", "in", "machine", "translation", "."], "sentence-detokenized": "He subsequently extended an invitation to Wydner to attend the annual meeting of the American Translators Association the following October, where the Weidner machine translation system was presented as a breakthrough in machine translation.", "token2charspan": [[0, 2], [3, 15], [16, 24], [25, 27], [28, 38], [39, 41], [42, 48], [49, 51], [52, 58], [59, 62], [63, 69], [70, 77], [78, 80], [81, 84], [85, 93], [94, 105], [106, 117], [118, 121], [122, 131], [132, 139], [139, 140], [141, 146], [147, 150], [151, 158], [159, 166], [167, 178], [179, 185], [186, 189], [190, 199], [200, 202], [203, 204], [205, 217], [218, 220], [221, 228], [229, 240], [240, 241]]}
{"doc_key": "ai-dev-112", "ner": [[8, 16, "conference"], [14, 16, "conference"], [2, 2, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 16, 8, 16, "named", "", false, false], [14, 16, 8, 16, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Researchers", "from", "Google", "presented", "their", "work", "at", "the", "2018", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "Conference", "."], "sentence-detokenized": "Researchers from Google presented their work at the 2018 Neural Information Processing Systems (NeurIPS) Conference.", "token2charspan": [[0, 11], [12, 16], [17, 23], [24, 33], [34, 39], [40, 44], [45, 47], [48, 51], [52, 56], [57, 63], [64, 75], [76, 86], [87, 94], [95, 96], [96, 103], [103, 104], [105, 115], [115, 116]]}
{"doc_key": "ai-dev-113", "ner": [[0, 4, "algorithm"], [10, 11, "algorithm"], [14, 17, "metrics"], [23, 26, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 4, 10, 11, "usage", "", false, false], [10, 11, 14, 17, "related-to", "", true, false], [14, 17, 23, 26, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Baum", "-", "Welch", "algorithm", "uses", "the", "well", "-", "known", "EM", "algorithm", "to", "find", "the", "maximum", "likelihood", "estimate", "of", "the", "parameters", "of", "a", "hidden", "Markov", "model", "given", "a", "set", "of", "observed", "feature", "vectors", "."], "sentence-detokenized": "The Baum-Welch algorithm uses the well-known EM algorithm to find the maximum likelihood estimate of the parameters of a hidden Markov model given a set of observed feature vectors.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 14], [15, 24], [25, 29], [30, 33], [34, 38], [38, 39], [39, 44], [45, 47], [48, 57], [58, 60], [61, 65], [66, 69], [70, 77], [78, 88], [89, 97], [98, 100], [101, 104], [105, 115], [116, 118], [119, 120], [121, 127], [128, 134], [135, 140], [141, 146], [147, 148], [149, 152], [153, 155], [156, 164], [165, 172], [173, 180], [180, 181]]}
{"doc_key": "ai-dev-114", "ner": [[9, 9, "product"], [11, 11, "product"], [31, 32, "misc"], [38, 45, "product"], [48, 50, "programlang"], [51, 56, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 9, 11, 11, "compare", "", false, false], [31, 32, 11, 11, "part-of", "", false, false], [38, 45, 11, 11, "part-of", "", false, false], [51, 56, 11, 11, "part-of", "", false, false], [51, 56, 48, 50, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": [")", "In", "addition", "to", "the", "taxonomic", "information", "contained", "in", "OpenCyc", ",", "ResearchCyc", "includes", "much", "more", "semantic", "knowledge", "(", "e.g.", ",", "additional", "facts", "and", "ground", "rules", ")", "involving", "the", "concepts", "in", "its", "knowledge", "base", ";", "it", "also", "includes", "a", "large", "lexicon", ",", "English", "parsing", "and", "generation", "tools", ",", "and", "Java", "-", "based", "interfaces", "for", "knowledge", "editing", "and", "querying", "."], "sentence-detokenized": ") In addition to the taxonomic information contained in OpenCyc, ResearchCyc includes much more semantic knowledge (e.g., additional facts and ground rules) involving the concepts in its knowledge base; it also includes a large lexicon, English parsing and generation tools, and Java-based interfaces for knowledge editing and querying.", "token2charspan": [[0, 1], [2, 4], [5, 13], [14, 16], [17, 20], [21, 30], [31, 42], [43, 52], [53, 55], [56, 63], [63, 64], [65, 76], [77, 85], [86, 90], [91, 95], [96, 104], [105, 114], [115, 116], [116, 120], [120, 121], [122, 132], [133, 138], [139, 142], [143, 149], [150, 155], [155, 156], [157, 166], [167, 170], [171, 179], [180, 182], [183, 186], [187, 196], [197, 201], [201, 202], [203, 205], [206, 210], [211, 219], [220, 221], [222, 227], [228, 235], [235, 236], [237, 244], [245, 252], [253, 256], [257, 267], [268, 273], [273, 274], [275, 278], [279, 283], [283, 284], [284, 289], [290, 300], [301, 304], [305, 314], [315, 322], [323, 326], [327, 335], [335, 336]]}
{"doc_key": "ai-dev-115", "ner": [[0, 2, "algorithm"], [5, 9, "task"], [10, 11, "field"], [13, 14, "field"], [16, 18, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 5, 9, "type-of", "", false, false], [5, 9, 10, 11, "part-of", "task_part_of_field", false, false], [5, 9, 13, 14, "part-of", "task_part_of_field", false, false], [5, 9, 16, 18, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Hough", "transform", "is", "a", "feature", "extraction", "technique", "used", "in", "image", "analysis", ",", "computer", "vision", "and", "digital", "image", "processing", "."], "sentence-detokenized": "The Hough transform is a feature extraction technique used in image analysis, computer vision and digital image processing.", "token2charspan": [[0, 3], [4, 9], [10, 19], [20, 22], [23, 24], [25, 32], [33, 43], [44, 53], [54, 58], [59, 61], [62, 67], [68, 76], [76, 77], [78, 86], [87, 93], [94, 97], [98, 105], [106, 111], [112, 122], [122, 123]]}
{"doc_key": "ai-dev-116", "ner": [[4, 4, "product"], [6, 10, "product"], [16, 16, "organisation"], [18, 18, "product"], [20, 21, "researcher"], [26, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[4, 4, 6, 10, "named", "", false, false], [4, 4, 16, 16, "artifact", "", false, false], [4, 4, 18, 18, "origin", "developed_from", false, false], [18, 18, 20, 21, "artifact", "", false, false], [26, 27, 16, 16, "role", "supported", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1978", ",", "the", "PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ")", "robot", "was", "developed", "by", "Unimation", "of", "Vicarm", "(", "Victor", "Scheinman", ")", "and", "supported", "by", "General", "Motors", "."], "sentence-detokenized": "In 1978, the PUMA (Programmable Universal Machine for Assembly) robot was developed by Unimation of Vicarm (Victor Scheinman) and supported by General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 17], [18, 19], [19, 31], [32, 41], [42, 49], [50, 53], [54, 62], [62, 63], [64, 69], [70, 73], [74, 83], [84, 86], [87, 96], [97, 99], [100, 106], [107, 108], [108, 114], [115, 124], [124, 125], [126, 129], [130, 139], [140, 142], [143, 150], [151, 157], [157, 158]]}
{"doc_key": "ai-dev-117", "ner": [[0, 0, "algorithm"], [6, 7, "researcher"], [9, 10, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 7, "origin", "", false, false], [0, 0, 9, 10, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["LSTM", "was", "proposed", "in", "1997", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "LSTM was proposed in 1997 by Sepp Hochreiter and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 8], [9, 17], [18, 20], [21, 25], [26, 28], [29, 33], [34, 44], [45, 48], [49, 55], [56, 67], [67, 68]]}
{"doc_key": "ai-dev-118", "ner": [[11, 12, "metrics"], [16, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "four", "outcomes", "can", "be", "formulated", "in", "a", "2", "\u00d7", "2", "contingency", "table", "or", "in", "a", "confusion", "matrix", "as", "follows", ":"], "sentence-detokenized": "The four outcomes can be formulated in a 2 \u00d7 2 contingency table or in a confusion matrix as follows:", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 24], [25, 35], [36, 38], [39, 40], [41, 42], [43, 44], [45, 46], [47, 58], [59, 64], [65, 67], [68, 70], [71, 72], [73, 82], [83, 89], [90, 92], [93, 100], [100, 101]]}
{"doc_key": "ai-dev-119", "ner": [[9, 9, "conference"], [12, 13, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "also", "contributed", "a", "lot", "to", "the", "establishment", "of", "ELRA", "and", "the", "LREC", "conference", "."], "sentence-detokenized": "He also contributed a lot to the establishment of ELRA and the LREC conference.", "token2charspan": [[0, 2], [3, 7], [8, 19], [20, 21], [22, 25], [26, 28], [29, 32], [33, 46], [47, 49], [50, 54], [55, 58], [59, 62], [63, 67], [68, 78], [78, 79]]}
{"doc_key": "ai-dev-120", "ner": [[11, 18, "misc"], [22, 23, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[22, 23, 11, 18, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "popular", "application", "for", "series", "robots", "in", "today", "'s", "industry", "is", "the", "pick", "-", "and", "-", "place", "assembly", "robot", ",", "called", "the", "SCARA", "robot", ",", "which", "has", "four", "degrees", "of", "freedom", "."], "sentence-detokenized": "A popular application for series robots in today's industry is the pick-and-place assembly robot, called the SCARA robot, which has four degrees of freedom.", "token2charspan": [[0, 1], [2, 9], [10, 21], [22, 25], [26, 32], [33, 39], [40, 42], [43, 48], [48, 50], [51, 59], [60, 62], [63, 66], [67, 71], [71, 72], [72, 75], [75, 76], [76, 81], [82, 90], [91, 96], [96, 97], [98, 104], [105, 108], [109, 114], [115, 120], [120, 121], [122, 127], [128, 131], [132, 136], [137, 144], [145, 147], [148, 155], [155, 156]]}
{"doc_key": "ai-dev-121", "ner": [[15, 23, "conference"], [25, 25, "conference"], [29, 32, "conference"], [41, 41, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[25, 25, 15, 23, "named", "", false, false], [41, 41, 29, 32, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "one", "of", "the", "founding", "members", "and", "former", "chair", "(", "2006-2008", ")", "of", "the", "Special", "Interest", "Group", "on", "the", "Web", "as", "a", "Corpus", "(", "SIGWAC", ")", "of", "the", "Association", "for", "Computational", "Linguistics", "and", "also", "one", "of", "the", "founding", "organizers", "of", "SENSEVAL", "."], "sentence-detokenized": "He was one of the founding members and former chair (2006-2008) of the Special Interest Group on the Web as a Corpus (SIGWAC) of the Association for Computational Linguistics and also one of the founding organizers of SENSEVAL.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 13], [14, 17], [18, 26], [27, 34], [35, 38], [39, 45], [46, 51], [52, 53], [53, 62], [62, 63], [64, 66], [67, 70], [71, 78], [79, 87], [88, 93], [94, 96], [97, 100], [101, 104], [105, 107], [108, 109], [110, 116], [117, 118], [118, 124], [124, 125], [126, 128], [129, 132], [133, 144], [145, 148], [149, 162], [163, 174], [175, 178], [179, 183], [184, 187], [188, 190], [191, 194], [195, 203], [204, 214], [215, 217], [218, 226], [226, 227]]}
{"doc_key": "ai-dev-122", "ner": [[4, 6, "product"], [8, 9, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 4, 6, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["As", "a", "platform", ",", "LinguaStream", "offers", "an", "extensive", "Java", "API", "."], "sentence-detokenized": "As a platform, LinguaStream offers an extensive Java API.", "token2charspan": [[0, 2], [3, 4], [5, 13], [13, 14], [15, 27], [28, 34], [35, 37], [38, 47], [48, 52], [53, 56], [56, 57]]}
{"doc_key": "ai-dev-123", "ner": [[11, 11, "programlang"], [14, 16, "misc"], [19, 21, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 19, 21, "type-of", "", false, false], [14, 16, 19, 21, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "robot", "kit", "is", "Android", "-", "based", "and", "is", "programmed", "using", "Java", ",", "the", "Blocks", "programming", "interface", "or", "other", "Android", "programming", "systems", "."], "sentence-detokenized": "The robot kit is Android-based and is programmed using Java, the Blocks programming interface or other Android programming systems.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 16], [17, 24], [24, 25], [25, 30], [31, 34], [35, 37], [38, 48], [49, 54], [55, 59], [59, 60], [61, 64], [65, 71], [72, 83], [84, 93], [94, 96], [97, 102], [103, 110], [111, 122], [123, 130], [130, 131]]}
{"doc_key": "ai-dev-124", "ner": [[12, 12, "algorithm"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "method", "of", "defining", "the", "linked", "list", "specifies", "the", "use", "of", "a", "depth", "search", "or", "a", "breadth", "search", "."], "sentence-detokenized": "The method of defining the linked list specifies the use of a depth search or a breadth search.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 22], [23, 26], [27, 33], [34, 38], [39, 48], [49, 52], [53, 56], [57, 59], [60, 61], [62, 67], [68, 74], [75, 77], [78, 79], [80, 87], [88, 94], [94, 95]]}
{"doc_key": "ai-dev-125", "ner": [[20, 21, "task"], [25, 27, "task"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "regions", "could", "signal", "the", "presence", "of", "objects", "or", "parts", "of", "objects", "in", "the", "image", "domain", ",", "with", "applications", "for", "object", "recognition", "and", "/", "or", "object", "video", "tracking", "."], "sentence-detokenized": "These regions could signal the presence of objects or parts of objects in the image domain, with applications for object recognition and/or object video tracking.", "token2charspan": [[0, 5], [6, 13], [14, 19], [20, 26], [27, 30], [31, 39], [40, 42], [43, 50], [51, 53], [54, 59], [60, 62], [63, 70], [71, 73], [74, 77], [78, 83], [84, 90], [90, 91], [92, 96], [97, 109], [110, 113], [114, 120], [121, 132], [133, 136], [136, 137], [137, 139], [140, 146], [147, 152], [153, 161], [161, 162]]}
{"doc_key": "ai-dev-126", "ner": [[4, 5, "algorithm"], [7, 7, "product"], [10, 10, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 4, 5, "type-of", "", false, false], [7, 7, 10, 10, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "a", "semantic", "network", "is", "WordNet", ",", "an", "English", "lexical", "database", "."], "sentence-detokenized": "An example of a semantic network is WordNet, an English lexical database.", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 15], [16, 24], [25, 32], [33, 35], [36, 43], [43, 44], [45, 47], [48, 55], [56, 63], [64, 72], [72, 73]]}
{"doc_key": "ai-dev-127", "ner": [[0, 2, "task"], [7, 8, "field"], [10, 11, "field"], [21, 25, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 7, 8, "part-of", "", false, false], [0, 2, 10, 11, "named", "same", false, false], [0, 2, 10, 11, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Speech", "recognition", "is", "an", "interdisciplinary", "subfield", "of", "computer", "science", "and", "computational", "linguistics", "that", "develops", "methodologies", "and", "technologies", "that", "enable", "computers", "to", "recognize", "and", "translate", "spoken", "language", "into", "text", "."], "sentence-detokenized": "Speech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methodologies and technologies that enable computers to recognize and translate spoken language into text.", "token2charspan": [[0, 6], [7, 18], [19, 21], [22, 24], [25, 42], [43, 51], [52, 54], [55, 63], [64, 71], [72, 75], [76, 89], [90, 101], [102, 106], [107, 115], [116, 129], [130, 133], [134, 146], [147, 151], [152, 158], [159, 168], [169, 171], [172, 181], [182, 185], [186, 195], [196, 202], [203, 211], [212, 216], [217, 221], [221, 222]]}
{"doc_key": "ai-dev-128", "ner": [[0, 1, "field"], [10, 11, "misc"], [16, 18, "field"], [20, 20, "task"], [22, 23, "task"], [46, 46, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 1, 46, 46, "named", "same", false, false], [16, 18, 0, 1, "part-of", "subfield", false, false], [20, 20, 0, 1, "part-of", "", false, false], [20, 20, 16, 18, "part-of", "", false, false], [22, 23, 16, 18, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Artificial", "intelligence", "has", "received", "the", "most", "attention", "in", "terms", "of", "ontology", "applied", "to", "subfields", "such", "as", "natural", "language", "processing", "in", "machine", "and", "knowledge", "representation", ",", "but", "ontology", "editors", "are", "often", "used", "in", "a", "range", "of", "fields", "such", "as", "education", ",", "with", "no", "intention", "of", "contributing", "to", "artificial", "intelligence", "."], "sentence-detokenized": "Artificial intelligence has received the most attention in terms of ontology applied to subfields such as natural language processing in machine and knowledge representation, but ontology editors are often used in a range of fields such as education, with no intention of contributing to artificial intelligence.", "token2charspan": [[0, 10], [11, 23], [24, 27], [28, 36], [37, 40], [41, 45], [46, 55], [56, 58], [59, 64], [65, 67], [68, 76], [77, 84], [85, 87], [88, 97], [98, 102], [103, 105], [106, 113], [114, 122], [123, 133], [134, 136], [137, 144], [145, 148], [149, 158], [159, 173], [173, 174], [175, 178], [179, 187], [188, 195], [196, 199], [200, 205], [206, 210], [211, 213], [214, 215], [216, 221], [222, 224], [225, 231], [232, 236], [237, 239], [240, 249], [249, 250], [251, 255], [256, 258], [259, 268], [269, 271], [272, 284], [285, 287], [288, 298], [299, 311], [311, 312]]}
{"doc_key": "ai-dev-129", "ner": [[9, 12, "algorithm"], [14, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[9, 12, 14, 15, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["This", "update", "rule", "is", "in", "fact", "the", "update", "of", "the", "stochastic", "gradient", "descent", "for", "linear", "regression", "."], "sentence-detokenized": "This update rule is in fact the update of the stochastic gradient descent for linear regression.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 19], [20, 22], [23, 27], [28, 31], [32, 38], [39, 41], [42, 45], [46, 56], [57, 65], [66, 73], [74, 77], [78, 84], [85, 95], [95, 96]]}
{"doc_key": "ai-dev-130", "ner": [[8, 13, "organisation"], [16, 19, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "has", "been", "elected", "a", "Fellow", "of", "the", "American", "Academy", "of", "Arts", "and", "Sciences", "and", "the", "National", "Academy", "of", "Sciences", "and", "has", "received", "a", "number", "of", "awards", ":"], "sentence-detokenized": "He has been elected a Fellow of the American Academy of Arts and Sciences and the National Academy of Sciences and has received a number of awards:", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 21], [22, 28], [29, 31], [32, 35], [36, 44], [45, 52], [53, 55], [56, 60], [61, 64], [65, 73], [74, 77], [78, 81], [82, 90], [91, 98], [99, 101], [102, 110], [111, 114], [115, 118], [119, 127], [128, 129], [130, 136], [137, 139], [140, 146], [146, 147]]}
{"doc_key": "ai-dev-131", "ner": [[7, 7, "organisation"], [12, 13, "person"], [15, 18, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 7, 12, 13, "related-to", "written_about_by", false, false], [7, 7, 15, 18, "related-to", "written_about_by", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "recent", "school", "of", "thought", "on", "Honda", "strategy", "was", "presented", "by", "Gary", "Hamel", "and", "C.", "K", ".", "Prahalad", "in", "1989", "."], "sentence-detokenized": "The most recent school of thought on Honda strategy was presented by Gary Hamel and C. K. Prahalad in 1989.", "token2charspan": [[0, 3], [4, 8], [9, 15], [16, 22], [23, 25], [26, 33], [34, 36], [37, 42], [43, 51], [52, 55], [56, 65], [66, 68], [69, 73], [74, 79], [80, 83], [84, 86], [87, 88], [88, 89], [90, 98], [99, 101], [102, 106], [106, 107]]}
{"doc_key": "ai-dev-132", "ner": [[1, 1, "metrics"], [4, 6, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 1, 4, 6, "related-to", "calculates", true, false], [1, 1, 20, 20, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["While", "BLEU", "simply", "calculates", "the", "precision", "of", "an", "n-", "gram", "by", "adding", "an", "equal", "weight", "to", "each", "of", "them", ",", "NIST", "also", "calculates", "how", "informative", "a", "particular", "n-", "gram", "is", "."], "sentence-detokenized": "While BLEU simply calculates the precision of an n-gram by adding an equal weight to each of them, NIST also calculates how informative a particular n-gram is.", "token2charspan": [[0, 5], [6, 10], [11, 17], [18, 28], [29, 32], [33, 42], [43, 45], [46, 48], [49, 51], [51, 55], [56, 58], [59, 65], [66, 68], [69, 74], [75, 81], [82, 84], [85, 89], [90, 92], [93, 97], [97, 98], [99, 103], [104, 108], [109, 119], [120, 123], [124, 135], [136, 137], [138, 148], [149, 151], [151, 155], [156, 158], [158, 159]]}
{"doc_key": "ai-dev-133", "ner": [[5, 8, "misc"], [10, 14, "conference"], [16, 16, "conference"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 8, 10, 14, "temporal", "", false, false], [16, 16, 10, 14, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["He", "was", "honored", "with", "the", "2019", "Lifetime", "Achievement", "Award", "from", "the", "Association", "for", "Computational", "Linguistics", "(", "ACL", ")", "."], "sentence-detokenized": "He was honored with the 2019 Lifetime Achievement Award from the Association for Computational Linguistics (ACL).", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 19], [20, 23], [24, 28], [29, 37], [38, 49], [50, 55], [56, 60], [61, 64], [65, 76], [77, 80], [81, 94], [95, 106], [107, 108], [108, 111], [111, 112], [112, 113]]}
{"doc_key": "ai-dev-134", "ner": [[0, 1, "researcher"], [6, 11, "organisation"], [13, 13, "organisation"], [17, 21, "conference"], [23, 23, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 1, 6, 11, "role", "", false, false], [0, 1, 17, 21, "role", "", false, false], [13, 13, 6, 11, "named", "", false, false], [23, 23, 17, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Sycara", "is", "a", "member", "of", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", "and", "the", "American", "Association", "for", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Sycara is a member of the Institute of Electrical and Electronics Engineers (IEEE) and the American Association for Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 9], [10, 11], [12, 18], [19, 21], [22, 25], [26, 35], [36, 38], [39, 49], [50, 53], [54, 65], [66, 75], [76, 77], [77, 81], [81, 82], [83, 86], [87, 90], [91, 99], [100, 111], [112, 115], [116, 126], [127, 139], [140, 141], [141, 145], [145, 146], [146, 147]]}
{"doc_key": "ai-dev-135", "ner": [[2, 2, "product"], [11, 12, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[2, 2, 11, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "following", "MATLAB", "code", "demonstrates", "a", "concrete", "solution", "for", "solving", "the", "nonlinear", "system", "of", "equations", "presented", "in", "the", "previous", "section", ":", "See", "also"], "sentence-detokenized": "The following MATLAB code demonstrates a concrete solution for solving the nonlinear system of equations presented in the previous section: See also", "token2charspan": [[0, 3], [4, 13], [14, 20], [21, 25], [26, 38], [39, 40], [41, 49], [50, 58], [59, 62], [63, 70], [71, 74], [75, 84], [85, 91], [92, 94], [95, 104], [105, 114], [115, 117], [118, 121], [122, 130], [131, 138], [138, 139], [140, 143], [144, 148]]}
{"doc_key": "ai-dev-136", "ner": [[0, 3, "product"], [13, 37, "field"]], "ner_mapping_to_source": [0, 2], "relations": [[0, 3, 13, 37, "related-to", "trained_by", true, false]], "relations_mapping_to_source": [1], "sentence": ["Pattern", "recognition", "systems", "are", "in", "many", "cases", "trained", "on", "labeled", "training", "data", "(", "supervised", "learning", ")", ",", "but", "when", "labeled", "data", "is", "not", "available", ",", "other", "algorithms", "may", "be", "used", "to", "discover", "previously", "unknown", "patterns", "(", "unsupervised", "learning", ")", "."], "sentence-detokenized": "Pattern recognition systems are in many cases trained on labeled training data (supervised learning), but when labeled data is not available, other algorithms may be used to discover previously unknown patterns (unsupervised learning).", "token2charspan": [[0, 7], [8, 19], [20, 27], [28, 31], [32, 34], [35, 39], [40, 45], [46, 53], [54, 56], [57, 64], [65, 73], [74, 78], [79, 80], [80, 90], [91, 99], [99, 100], [100, 101], [102, 105], [106, 110], [111, 118], [119, 123], [124, 126], [127, 130], [131, 140], [140, 141], [142, 147], [148, 158], [159, 162], [163, 165], [166, 170], [171, 173], [174, 182], [183, 193], [194, 201], [202, 210], [211, 212], [212, 224], [225, 233], [233, 234], [234, 235]]}
{"doc_key": "ai-dev-137", "ner": [[5, 7, "researcher"], [10, 10, "country"], [23, 24, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 7, 10, 10, "physical", "", false, false], [5, 7, 23, 24, "related-to", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["It", "was", "first", "used", "by", "Lawrence", "J.", "Fogel", "in", "the", "USA", "in", "1960", "to", "use", "simulated", "evolution", "as", "a", "learning", "process", "to", "generate", "artificial", "intelligence", "."], "sentence-detokenized": "It was first used by Lawrence J. Fogel in the USA in 1960 to use simulated evolution as a learning process to generate artificial intelligence.", "token2charspan": [[0, 2], [3, 6], [7, 12], [13, 17], [18, 20], [21, 29], [30, 32], [33, 38], [39, 41], [42, 45], [46, 49], [50, 52], [53, 57], [58, 60], [61, 64], [65, 74], [75, 84], [85, 87], [88, 89], [90, 98], [99, 106], [107, 109], [110, 118], [119, 129], [130, 142], [142, 143]]}
{"doc_key": "ai-dev-138", "ner": [[0, 1, "field"], [10, 10, "field"], [15, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 10, 10, "part-of", "", false, false], [15, 16, 10, 10, "part-of", "", false, false], [18, 19, 10, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Reinforcement", "learning", "is", "one", "of", "the", "three", "basic", "paradigms", "of", "machine", "learning", ",", "along", "with", "supervised", "learning", "and", "unsupervised", "learning", "."], "sentence-detokenized": "Reinforcement learning is one of the three basic paradigms of machine learning, along with supervised learning and unsupervised learning.", "token2charspan": [[0, 13], [14, 22], [23, 25], [26, 29], [30, 32], [33, 36], [37, 42], [43, 48], [49, 58], [59, 61], [62, 69], [70, 78], [78, 79], [80, 85], [86, 90], [91, 101], [102, 110], [111, 114], [115, 127], [128, 136], [136, 137]]}
{"doc_key": "ai-dev-139", "ner": [[4, 5, "field"], [12, 12, "programlang"], [28, 29, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 5, 28, 29, "usage", "applies", false, false], [12, 12, 28, 29, "usage", "applies", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "such", "cases", ",", "cloud", "computing", "and", "the", "open", "source", "programming", "language", "R", "can", "help", "smaller", "banks", "adopt", "risk", "analytics", "and", "support", "branch", "-", "level", "monitoring", "by", "applying", "predictive", "analytics", "."], "sentence-detokenized": "In such cases, cloud computing and the open source programming language R can help smaller banks adopt risk analytics and support branch-level monitoring by applying predictive analytics.", "token2charspan": [[0, 2], [3, 7], [8, 13], [13, 14], [15, 20], [21, 30], [31, 34], [35, 38], [39, 43], [44, 50], [51, 62], [63, 71], [72, 73], [74, 77], [78, 82], [83, 90], [91, 96], [97, 102], [103, 107], [108, 117], [118, 121], [122, 129], [130, 136], [136, 137], [137, 142], [143, 153], [154, 156], [157, 165], [166, 176], [177, 186], [186, 187]]}
{"doc_key": "ai-dev-140", "ner": [[11, 12, "researcher"], [19, 20, "algorithm"], [22, 23, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 22, 23, "named", "same", false, false], [19, 20, 11, 12, "origin", "proves_function", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["One", "of", "the", "first", "versions", "of", "the", "theorem", "was", "proved", "by", "George", "Cybenko", "in", "1989", "for", "activation", "functions", "with", "sigmoid", "function", ".", "Cybenko", "G.", "(", "1989", ")", ",", "2", "(", "4", ")", ",", "303-314", "."], "sentence-detokenized": "One of the first versions of the theorem was proved by George Cybenko in 1989 for activation functions with sigmoid function. Cybenko G. (1989), 2 (4), 303-314.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [17, 25], [26, 28], [29, 32], [33, 40], [41, 44], [45, 51], [52, 54], [55, 61], [62, 69], [70, 72], [73, 77], [78, 81], [82, 92], [93, 102], [103, 107], [108, 115], [116, 124], [124, 125], [126, 133], [134, 136], [137, 138], [138, 142], [142, 143], [143, 144], [145, 146], [147, 148], [148, 149], [149, 150], [150, 151], [152, 159], [159, 160]]}
{"doc_key": "ai-dev-141", "ner": [[8, 10, "algorithm"], [11, 12, "metrics"], [16, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 8, 10, "part-of", "", false, false], [16, 20, 11, 12, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "this", "process", ",", "which", "is", "known", "as", "cross-validation", ",", "the", "MSE", "is", "often", "called", "the", "mean", "squared", "error", "of", "prediction", "and", "is", "calculated", "as", "follows"], "sentence-detokenized": "In this process, which is known as cross-validation, the MSE is often called the mean squared error of prediction and is calculated as follows", "token2charspan": [[0, 2], [3, 7], [8, 15], [15, 16], [17, 22], [23, 25], [26, 31], [32, 34], [35, 51], [51, 52], [53, 56], [57, 60], [61, 63], [64, 69], [70, 76], [77, 80], [81, 85], [86, 93], [94, 99], [100, 102], [103, 113], [114, 117], [118, 120], [121, 131], [132, 134], [135, 142]]}
{"doc_key": "ai-dev-142", "ner": [[3, 3, "task"], [6, 8, "task"], [10, 12, "task"], [16, 17, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[3, 3, 6, 8, "compare", "", false, false], [6, 8, 16, 17, "part-of", "", false, false], [10, 12, 6, 8, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "general", ",", "OMR", "differs", "from", "Optical", "Character", "Recognition", "(", "OCR", ")", "in", "that", "a", "complicated", "pattern", "recognition", "engine", "is", "not", "required", "."], "sentence-detokenized": "In general, OMR differs from Optical Character Recognition (OCR) in that a complicated pattern recognition engine is not required.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 23], [24, 28], [29, 36], [37, 46], [47, 58], [59, 60], [60, 63], [63, 64], [65, 67], [68, 72], [73, 74], [75, 86], [87, 94], [95, 106], [107, 113], [114, 116], [117, 120], [121, 129], [129, 130]]}
{"doc_key": "ai-dev-143", "ner": [[10, 10, "location"], [12, 12, "location"], [14, 14, "location"], [16, 17, "location"], [19, 20, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[12, 12, 14, 14, "physical", "", false, false], [16, 17, 12, 12, "physical", "", false, false], [19, 20, 12, 12, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2018", "and", "2019", ",", "the", "championships", "were", "held", "in", "Houston", "and", "Detroit", ",", "Michigan", "at", "TCF", "Center", "and", "Ford", "Field", "."], "sentence-detokenized": "In 2018 and 2019, the championships were held in Houston and Detroit, Michigan at TCF Center and Ford Field.", "token2charspan": [[0, 2], [3, 7], [8, 11], [12, 16], [16, 17], [18, 21], [22, 35], [36, 40], [41, 45], [46, 48], [49, 56], [57, 60], [61, 68], [68, 69], [70, 78], [79, 81], [82, 85], [86, 92], [93, 96], [97, 101], [102, 107], [107, 108]]}
{"doc_key": "ai-dev-144", "ner": [[0, 0, "task"], [9, 10, "task"], [12, 12, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 10, 0, 0, "part-of", "", false, false], [12, 12, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Classification", "can", "be", "viewed", "as", "two", "distinct", "problems", "-", "binary", "classification", "and", "multi-class", "classification", "."], "sentence-detokenized": "Classification can be viewed as two distinct problems - binary classification and multi-class classification.", "token2charspan": [[0, 14], [15, 18], [19, 21], [22, 28], [29, 31], [32, 35], [36, 44], [45, 53], [54, 55], [56, 62], [63, 77], [78, 81], [82, 93], [94, 108], [108, 109]]}
{"doc_key": "ai-dev-145", "ner": [[4, 5, "product"], [8, 9, "product"], [11, 13, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 4, 5, "type-of", "", false, false], [11, 13, 4, 5, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Two", "examples", "of", "popular", "parallel", "robots", "are", "the", "Stewart", "platform", "and", "the", "Delta", "robot", "."], "sentence-detokenized": "Two examples of popular parallel robots are the Stewart platform and the Delta robot.", "token2charspan": [[0, 3], [4, 12], [13, 15], [16, 23], [24, 32], [33, 39], [40, 43], [44, 47], [48, 55], [56, 64], [65, 68], [69, 72], [73, 78], [79, 84], [84, 85]]}
{"doc_key": "ai-dev-146", "ner": [[4, 6, "algorithm"], [22, 22, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 22, 22, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["(", "However", ",", "the", "ReLU", "activation", "function", ",", "which", "is", "not", "set", "to", "0", ",", "has", "become", "quite", "popular", ",", "e.g.", "in", "AlexNet", ")", "."], "sentence-detokenized": "(However, the ReLU activation function, which is not set to 0, has become quite popular, e.g. in AlexNet).", "token2charspan": [[0, 1], [1, 8], [8, 9], [10, 13], [14, 18], [19, 29], [30, 38], [38, 39], [40, 45], [46, 48], [49, 52], [53, 56], [57, 59], [60, 61], [61, 62], [63, 66], [67, 73], [74, 79], [80, 87], [87, 88], [89, 93], [94, 96], [97, 104], [104, 105], [105, 106]]}
{"doc_key": "ai-dev-147", "ner": [[0, 3, "metrics"], [8, 9, "task"], [12, 12, "task"], [15, 15, "task"], [16, 19, "task"], [22, 22, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 22, 22, "named", "", true, false], [8, 9, 0, 3, "usage", "", true, false], [12, 12, 8, 9, "part-of", "", false, false], [15, 15, 8, 9, "part-of", "", false, false], [16, 19, 8, 9, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "F", "-", "score", "is", "often", "used", "in", "information", "retrieval", "to", "measure", "search", "performance", ",", "document", "classification", "and", "query", "classification", ",", "so", "F_beta", "is", "widely", "used", "."], "sentence-detokenized": "The F-score is often used in information retrieval to measure search performance, document classification and query classification, so F_beta is widely used.", "token2charspan": [[0, 3], [4, 5], [5, 6], [6, 11], [12, 14], [15, 20], [21, 25], [26, 28], [29, 40], [41, 50], [51, 53], [54, 61], [62, 68], [69, 80], [80, 81], [82, 90], [91, 105], [106, 109], [110, 115], [116, 130], [130, 131], [132, 134], [135, 141], [142, 144], [145, 151], [152, 156], [156, 157]]}
{"doc_key": "ai-dev-148", "ner": [[18, 18, "algorithm"], [20, 20, "algorithm"], [23, 24, "algorithm"], [26, 26, "algorithm"], [17, 31, "algorithm"], [33, 33, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 20, 18, 18, "named", "", false, false], [26, 26, 23, 24, "named", "", false, false], [33, 33, 17, 31, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["This", "is", "done", "by", "modelling", "the", "received", "signal", ",", "then", "using", "a", "statistical", "estimation", "method", "such", "as", "maximum", "likelihood", "(", "ML", ")", ",", "majority", "vote", "(", "MV", ")", "or", "maximum", "a", "posteriori", "(", "MAP", ")", "to", "make", "a", "decision", "on", "which", "target", "in", "the", "library", "best", "fits", "the", "model", "built", "using", "the", "received", "signal", "."], "sentence-detokenized": "This is done by modelling the received signal, then using a statistical estimation method such as maximum likelihood (ML), majority vote (MV) or maximum a posteriori (MAP) to make a decision on which target in the library best fits the model built using the received signal.", "token2charspan": [[0, 4], [5, 7], [8, 12], [13, 15], [16, 25], [26, 29], [30, 38], [39, 45], [45, 46], [47, 51], [52, 57], [58, 59], [60, 71], [72, 82], [83, 89], [90, 94], [95, 97], [98, 105], [106, 116], [117, 118], [118, 120], [120, 121], [121, 122], [123, 131], [132, 136], [137, 138], [138, 140], [140, 141], [142, 144], [145, 152], [153, 154], [155, 165], [166, 167], [167, 170], [170, 171], [172, 174], [175, 179], [180, 181], [182, 190], [191, 193], [194, 199], [200, 206], [207, 209], [210, 213], [214, 221], [222, 226], [227, 231], [232, 235], [236, 241], [242, 247], [248, 253], [254, 257], [258, 266], [267, 273], [273, 274]]}
{"doc_key": "ai-dev-149", "ner": [[0, 0, "researcher"], [3, 4, "misc"], [7, 23, "field"], [10, 13, "university"], [18, 19, "misc"], [22, 22, "field"], [25, 26, "university"], [32, 32, "misc"], [34, 37, "field"], [38, 40, "university"], [48, 57, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 0, 10, 13, "physical", "", false, false], [0, 0, 10, 13, "role", "", false, false], [0, 0, 25, 26, "physical", "", false, false], [0, 0, 25, 26, "role", "", false, false], [0, 0, 38, 40, "physical", "", false, false], [0, 0, 38, 40, "role", "", false, false], [3, 4, 0, 0, "origin", "", false, false], [3, 4, 7, 23, "topic", "", false, false], [18, 19, 0, 0, "origin", "", false, false], [18, 19, 22, 22, "topic", "", false, false], [32, 32, 0, 0, "origin", "", false, false], [32, 32, 34, 37, "topic", "", false, false], [48, 57, 32, 32, "named", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "sentence": ["Sowa", "received", "a", "bachelor", "'s", "degree", "in", "mathematics", "from", "the", "Massachusetts", "Institute", "of", "Technology", "in", "1962", ",", "a", "master", "'s", "degree", "in", "applied", "mathematics", "from", "Harvard", "University", "in", "1966", ",", "and", "a", "PhD", "in", "computer", "science", "from", "the", "Vrije", "Universiteit", "Brussel", "in", "1999", ",", "with", "a", "thesis", "entitled", "Knowledge", "Representation", ":", "Logical", ",", "Philosophical", ",", "and", "Computational", "Foundations", "."], "sentence-detokenized": "Sowa received a bachelor's degree in mathematics from the Massachusetts Institute of Technology in 1962, a master's degree in applied mathematics from Harvard University in 1966, and a PhD in computer science from the Vrije Universiteit Brussel in 1999, with a thesis entitled Knowledge Representation: Logical, Philosophical, and Computational Foundations.", "token2charspan": [[0, 4], [5, 13], [14, 15], [16, 24], [24, 26], [27, 33], [34, 36], [37, 48], [49, 53], [54, 57], [58, 71], [72, 81], [82, 84], [85, 95], [96, 98], [99, 103], [103, 104], [105, 106], [107, 113], [113, 115], [116, 122], [123, 125], [126, 133], [134, 145], [146, 150], [151, 158], [159, 169], [170, 172], [173, 177], [177, 178], [179, 182], [183, 184], [185, 188], [189, 191], [192, 200], [201, 208], [209, 213], [214, 217], [218, 223], [224, 236], [237, 244], [245, 247], [248, 252], [252, 253], [254, 258], [259, 260], [261, 267], [268, 276], [277, 286], [287, 301], [301, 302], [303, 310], [310, 311], [312, 325], [325, 326], [327, 330], [331, 344], [345, 356], [356, 357]]}
{"doc_key": "ai-dev-150", "ner": [[1, 2, "task"], [8, 9, "task"], [18, 18, "metrics"], [20, 21, "metrics"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 2, 8, 9, "general-affiliation", "", false, false], [18, 18, 1, 2, "part-of", "", true, false], [20, 21, 1, 2, "part-of", "", true, false], [24, 25, 1, 2, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Since", "paraphrase", "recognition", "can", "be", "presented", "as", "a", "classification", "problem", ",", "most", "standard", "evaluation", "metrics", ",", "such", "as", "accuracy", ",", "f1", "score", "or", "an", "ROC", "curve", ",", "do", "relatively", "well", "."], "sentence-detokenized": "Since paraphrase recognition can be presented as a classification problem, most standard evaluation metrics, such as accuracy, f1 score or an ROC curve, do relatively well.", "token2charspan": [[0, 5], [6, 16], [17, 28], [29, 32], [33, 35], [36, 45], [46, 48], [49, 50], [51, 65], [66, 73], [73, 74], [75, 79], [80, 88], [89, 99], [100, 107], [107, 108], [109, 113], [114, 116], [117, 125], [125, 126], [127, 129], [130, 135], [136, 138], [139, 141], [142, 145], [146, 151], [151, 152], [153, 155], [156, 166], [167, 171], [171, 172]]}
{"doc_key": "ai-dev-151", "ner": [[19, 19, "algorithm"], [30, 31, "algorithm"], [33, 34, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[19, 19, 30, 31, "opposite", "not_suited_for", false, false], [19, 19, 33, 34, "opposite", "not_suited_for", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["This", "makes", "it", "practical", "for", "the", "analysis", "of", "large", "datasets", "(", "hundreds", "or", "thousands", "of", "taxa", ")", "and", "for", "bootstrapping", ",", "for", "which", "other", "means", "of", "analysis", "(", "e.g.", ",", "maximum", "parsimony", ",", "maximum", "likelihood", ")", "may", "be", "computationally", "prohibitive", "."], "sentence-detokenized": "This makes it practical for the analysis of large datasets (hundreds or thousands of taxa) and for bootstrapping, for which other means of analysis (e.g., maximum parsimony, maximum likelihood) may be computationally prohibitive.", "token2charspan": [[0, 4], [5, 10], [11, 13], [14, 23], [24, 27], [28, 31], [32, 40], [41, 43], [44, 49], [50, 58], [59, 60], [60, 68], [69, 71], [72, 81], [82, 84], [85, 89], [89, 90], [91, 94], [95, 98], [99, 112], [112, 113], [114, 117], [118, 123], [124, 129], [130, 135], [136, 138], [139, 147], [148, 149], [149, 153], [153, 154], [155, 162], [163, 172], [172, 173], [174, 181], [182, 192], [192, 193], [194, 197], [198, 200], [201, 216], [217, 228], [228, 229]]}
{"doc_key": "ai-dev-152", "ner": [[5, 5, "programlang"], [9, 12, "organisation"], [14, 20, "organisation"], [3, 24, "programlang"], [28, 39, "organisation"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[14, 20, 9, 12, "named", "", false, false], [28, 39, 5, 5, "role", "submits", true, false], [28, 39, 9, 12, "role", "submits_to", true, false]], "relations_mapping_to_source": [1, 3, 4], "sentence": ["Submission", "of", "the", "DAML", "+", "OIL", "language", "to", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", "in", "2002", ",", "representing", "the", "work", "of", "the", "DAML", "contractors", "and", "the", "Joint", "European", "Union", "/", "United", "States", "Ad", "Hoc", "Committee", "on", "Markup", "Languages", "."], "sentence-detokenized": "Submission of the DAML + OIL language to the World Wide Web Consortium (W3C) in 2002, representing the work of the DAML contractors and the Joint European Union/United States Ad Hoc Committee on Markup Languages.", "token2charspan": [[0, 10], [11, 13], [14, 17], [18, 22], [23, 24], [25, 28], [29, 37], [38, 40], [41, 44], [45, 50], [51, 55], [56, 59], [60, 70], [71, 72], [72, 75], [75, 76], [77, 79], [80, 84], [84, 85], [86, 98], [99, 102], [103, 107], [108, 110], [111, 114], [115, 119], [120, 131], [132, 135], [136, 139], [140, 145], [146, 154], [155, 160], [160, 161], [161, 167], [168, 174], [175, 177], [178, 181], [182, 191], [192, 194], [195, 201], [202, 211], [211, 212]]}
{"doc_key": "ai-dev-153", "ner": [[3, 3, "misc"], [7, 8, "misc"], [11, 12, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[7, 8, 3, 3, "part-of", "", true, false], [11, 12, 3, 3, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["An", "example", "of", "nonlinear", "normalization", "is", "when", "the", "normalization", "follows", "a", "sigmoid", "function", ",", "in", "this", "case", "the", "normalized", "image", "is", "calculated", "according", "to", "the", "formula"], "sentence-detokenized": "An example of nonlinear normalization is when the normalization follows a sigmoid function, in this case the normalized image is calculated according to the formula", "token2charspan": [[0, 2], [3, 10], [11, 13], [14, 23], [24, 37], [38, 40], [41, 45], [46, 49], [50, 63], [64, 71], [72, 73], [74, 81], [82, 90], [90, 91], [92, 94], [95, 99], [100, 104], [105, 108], [109, 119], [120, 125], [126, 128], [129, 139], [140, 149], [150, 152], [153, 156], [157, 164]]}
{"doc_key": "ai-dev-154", "ner": [[5, 5, "metrics"], [10, 10, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[5, 5, 10, 10, "related-to", "used_together", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "pointed", "out", "that", "precision", "is", "usually", "paired", "with", "recall", "to", "overcome", "this", "problem", "."], "sentence-detokenized": "It was pointed out that precision is usually paired with recall to overcome this problem.", "token2charspan": [[0, 2], [3, 6], [7, 14], [15, 18], [19, 23], [24, 33], [34, 36], [37, 44], [45, 51], [52, 56], [57, 63], [64, 66], [67, 75], [76, 80], [81, 88], [88, 89]]}
{"doc_key": "ai-dev-155", "ner": [[4, 4, "metrics"], [5, 13, "metrics"], [21, 22, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[21, 22, 5, 13, "usage", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Commonly", "used", "metrics", "are", "mean", "squared", "error", "and", "root", "mean", "square", "error", ",", "the", "latter", "of", "which", "is", "used", "in", "the", "Netflix", "Prize", "."], "sentence-detokenized": "Commonly used metrics are mean squared error and root mean square error, the latter of which is used in the Netflix Prize.", "token2charspan": [[0, 8], [9, 13], [14, 21], [22, 25], [26, 30], [31, 38], [39, 44], [45, 48], [49, 53], [54, 58], [59, 65], [66, 71], [71, 72], [73, 76], [77, 83], [84, 86], [87, 92], [93, 95], [96, 100], [101, 103], [104, 107], [108, 115], [116, 121], [121, 122]]}
{"doc_key": "ai-dev-156", "ner": [[8, 10, "organisation"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "August", "2016", ",", "a", "research", "program", "with", "University", "College", "Hospital", "was", "announced", "with", "the", "goal", "of", "developing", "an", "algorithm", "that", "can", "automatically", "distinguish", "between", "healthy", "and", "cancerous", "tissues", "in", "the", "head", "and", "neck", "areas", "."], "sentence-detokenized": "In August 2016, a research program with University College Hospital was announced with the goal of developing an algorithm that can automatically distinguish between healthy and cancerous tissues in the head and neck areas.", "token2charspan": [[0, 2], [3, 9], [10, 14], [14, 15], [16, 17], [18, 26], [27, 34], [35, 39], [40, 50], [51, 58], [59, 67], [68, 71], [72, 81], [82, 86], [87, 90], [91, 95], [96, 98], [99, 109], [110, 112], [113, 122], [123, 127], [128, 131], [132, 145], [146, 157], [158, 165], [166, 173], [174, 177], [178, 187], [188, 195], [196, 198], [199, 202], [203, 207], [208, 211], [212, 216], [217, 222], [222, 223]]}
{"doc_key": "ai-dev-157", "ner": [[3, 3, "researcher"], [16, 18, "organisation"], [21, 24, "organisation"], [27, 30, "organisation"], [33, 38, "organisation"], [41, 47, "organisation"], [51, 54, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 3, 16, 18, "role", "", false, false], [3, 3, 21, 24, "role", "", false, false], [3, 3, 27, 30, "role", "", false, false], [3, 3, 33, 38, "role", "", false, false], [3, 3, 41, 47, "role", "", false, false], [3, 3, 51, 54, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "impact", "of", "Posner", "'s", "theoretical", "and", "empirical", "contributions", "has", "been", "recognized", "through", "membership", "in", "the", "American", "Psychological", "Association", ",", "the", "Association", "for", "Psychological", "Science", ",", "the", "Society", "of", "Experimental", "Psychologists", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", ",", "and", "the", "National", "Academy", "of", "Sciences", "."], "sentence-detokenized": "The impact of Posner's theoretical and empirical contributions has been recognized through membership in the American Psychological Association, the Association for Psychological Science, the Society of Experimental Psychologists, the American Academy of Arts and Sciences, the American Association for the Advancement of Science, and the National Academy of Sciences.", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 20], [20, 22], [23, 34], [35, 38], [39, 48], [49, 62], [63, 66], [67, 71], [72, 82], [83, 90], [91, 101], [102, 104], [105, 108], [109, 117], [118, 131], [132, 143], [143, 144], [145, 148], [149, 160], [161, 164], [165, 178], [179, 186], [186, 187], [188, 191], [192, 199], [200, 202], [203, 215], [216, 229], [229, 230], [231, 234], [235, 243], [244, 251], [252, 254], [255, 259], [260, 263], [264, 272], [272, 273], [274, 277], [278, 286], [287, 298], [299, 302], [303, 306], [307, 318], [319, 321], [322, 329], [329, 330], [331, 334], [335, 338], [339, 347], [348, 355], [356, 358], [359, 367], [367, 368]]}
{"doc_key": "ai-dev-158", "ner": [[2, 2, "product"], [7, 8, "field"], [11, 12, "task"], [14, 16, "task"], [18, 18, "task"], [21, 23, "task"], [25, 25, "task"], [28, 29, "field"], [31, 32, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[2, 2, 7, 8, "usage", "", false, false], [11, 12, 7, 8, "part-of", "", false, false], [14, 16, 7, 8, "part-of", "", false, false], [18, 18, 14, 16, "named", "", false, false], [21, 23, 7, 8, "part-of", "", false, false], [25, 25, 21, 23, "named", "", false, false], [28, 29, 7, 8, "part-of", "", false, false], [31, 32, 7, 8, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["These", "intelligent", "chatbots", "use", "all", "types", "of", "artificial", "intelligence", "such", "as", "image", "moderation", "and", "natural", "language", "understanding", "(", "NLU", ")", ",", "natural", "language", "generation", "(", "NLG", ")", ",", "machine", "learning", "and", "deep", "learning", "."], "sentence-detokenized": "These intelligent chatbots use all types of artificial intelligence such as image moderation and natural language understanding (NLU), natural language generation (NLG), machine learning and deep learning.", "token2charspan": [[0, 5], [6, 17], [18, 26], [27, 30], [31, 34], [35, 40], [41, 43], [44, 54], [55, 67], [68, 72], [73, 75], [76, 81], [82, 92], [93, 96], [97, 104], [105, 113], [114, 127], [128, 129], [129, 132], [132, 133], [133, 134], [135, 142], [143, 151], [152, 162], [163, 164], [164, 167], [167, 168], [168, 169], [170, 177], [178, 186], [187, 190], [191, 195], [196, 204], [204, 205]]}
{"doc_key": "ai-dev-159", "ner": [[6, 6, "metrics"], [10, 10, "metrics"], [15, 18, "metrics"], [21, 22, "metrics"], [31, 31, "metrics"], [34, 34, "metrics"], [23, 44, "metrics"], [7, 49, "metrics"], [51, 51, "metrics"], [54, 61, "metrics"], [30, 68, "metrics"], [70, 70, "metrics"], [73, 80, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[10, 10, 6, 6, "named", "", false, false], [15, 18, 6, 6, "named", "", false, false], [21, 22, 6, 6, "named", "", false, false], [34, 34, 31, 31, "named", "", false, false], [23, 44, 31, 31, "named", "", false, false], [51, 51, 7, 49, "named", "", false, false], [54, 61, 7, 49, "named", "", false, false], [70, 70, 30, 68, "named", "", false, false], [73, 80, 30, 68, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["The", "ratios", "in", "the", "rows", "are", "Positive", "Predictive", "Value", "(", "PPV", ",", "also", "known", "as", "Precision", ")", "(", "TP", "/", "(", "TP", "+", "FP", ")", ")", ",", "with", "the", "complement", "False", "Discovery", "Rate", "(", "FDR", ")", "(", "FP", "/", "(", "TP", "+", "FP", ")", ")", ";", "and", "Negative", "Predictive", "Value", "(", "NPV", ")", "(", "TN", "/", "(", "TN", "+", "FN", ")", ")", ",", "with", "the", "complement", "False", "Omission", "Rate", "(", "FOR", ")", "(", "FN", "/", "(", "TN", "+", "FN", ")", ")", "."], "sentence-detokenized": "The ratios in the rows are Positive Predictive Value (PPV, also known as Precision) (TP / (TP + FP)), with the complement False Discovery Rate (FDR) (FP / (TP + FP)); and Negative Predictive Value (NPV) (TN / (TN + FN)), with the complement False Omission Rate (FOR) (FN / (TN + FN)).", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 17], [18, 22], [23, 26], [27, 35], [36, 46], [47, 52], [53, 54], [54, 57], [57, 58], [59, 63], [64, 69], [70, 72], [73, 82], [82, 83], [84, 85], [85, 87], [88, 89], [90, 91], [91, 93], [94, 95], [96, 98], [98, 99], [99, 100], [100, 101], [102, 106], [107, 110], [111, 121], [122, 127], [128, 137], [138, 142], [143, 144], [144, 147], [147, 148], [149, 150], [150, 152], [153, 154], [155, 156], [156, 158], [159, 160], [161, 163], [163, 164], [164, 165], [165, 166], [167, 170], [171, 179], [180, 190], [191, 196], [197, 198], [198, 201], [201, 202], [203, 204], [204, 206], [207, 208], [209, 210], [210, 212], [213, 214], [215, 217], [217, 218], [218, 219], [219, 220], [221, 225], [226, 229], [230, 240], [241, 246], [247, 255], [256, 260], [261, 262], [262, 265], [265, 266], [267, 268], [268, 270], [271, 272], [273, 274], [274, 276], [277, 278], [279, 281], [281, 282], [282, 283], [283, 284]]}
{"doc_key": "ai-dev-160", "ner": [[8, 8, "misc"], [14, 15, "algorithm"], [17, 17, "algorithm"], [20, 22, "algorithm"], [24, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[17, 17, 14, 15, "named", "", false, false], [24, 24, 20, 22, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "information", "is", "a", "mixture", "of", "sitemaps", "and", "RSS", "and", "is", "created", "using", "the", "Information", "Model", "(", "IM", ")", "and", "Biomedical", "Resource", "Ontology", "(", "BRO", ")", "."], "sentence-detokenized": "The information is a mixture of sitemaps and RSS and is created using the Information Model (IM) and Biomedical Resource Ontology (BRO).", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 20], [21, 28], [29, 31], [32, 40], [41, 44], [45, 48], [49, 52], [53, 55], [56, 63], [64, 69], [70, 73], [74, 85], [86, 91], [92, 93], [93, 95], [95, 96], [97, 100], [101, 111], [112, 120], [121, 129], [130, 131], [131, 134], [134, 135], [135, 136]]}
{"doc_key": "ai-dev-161", "ner": [[1, 4, "task"], [7, 9, "algorithm"], [11, 14, "algorithm"], [21, 22, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 4, 11, 14, "origin", "based_on", false, false], [11, 14, 7, 9, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Recent", "text", "recognition", "is", "based", "on", "a", "recurrent", "neural", "network", "(", "short", "-", "term", "memory", ")", "and", "does", "not", "require", "a", "linguistic", "model", "."], "sentence-detokenized": "Recent text recognition is based on a recurrent neural network (short-term memory) and does not require a linguistic model.", "token2charspan": [[0, 6], [7, 11], [12, 23], [24, 26], [27, 32], [33, 35], [36, 37], [38, 47], [48, 54], [55, 62], [63, 64], [64, 69], [69, 70], [70, 74], [75, 81], [81, 82], [83, 86], [87, 91], [92, 95], [96, 103], [104, 105], [106, 116], [117, 122], [122, 123]]}
{"doc_key": "ai-dev-162", "ner": [[1, 2, "misc"], [4, 5, "metrics"], [8, 9, "algorithm"], [12, 13, "metrics"], [16, 17, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 5, 1, 2, "type-of", "", false, false], [8, 9, 4, 5, "related-to", "", true, false], [12, 13, 1, 2, "type-of", "", false, false], [16, 17, 12, 13, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Popular", "loss", "functions", "include", "hinge", "loss", "(", "for", "linear", "SVMs", ")", "and", "logarithmic", "loss", "(", "for", "logistic", "regression", ")", "."], "sentence-detokenized": "Popular loss functions include hinge loss (for linear SVMs) and logarithmic loss (for logistic regression).", "token2charspan": [[0, 7], [8, 12], [13, 22], [23, 30], [31, 36], [37, 41], [42, 43], [43, 46], [47, 53], [54, 58], [58, 59], [60, 63], [64, 75], [76, 80], [81, 82], [82, 85], [86, 94], [95, 105], [105, 106], [106, 107]]}
{"doc_key": "ai-dev-163", "ner": [[0, 0, "metrics"], [10, 16, "metrics"], [18, 18, "metrics"], [21, 23, "metrics"], [25, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 10, 16, "compare", "", false, false], [0, 0, 21, 23, "compare", "", false, false], [18, 18, 10, 16, "named", "", false, false], [25, 25, 21, 23, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SSIM", "is", "designed", "to", "improve", "on", "traditional", "methods", "such", "as", "maximum", "signal", "-", "to", "-", "noise", "ratio", "(", "PSNR", ")", "and", "mean", "squared", "error", "(", "MSE", ")", "."], "sentence-detokenized": "SSIM is designed to improve on traditional methods such as maximum signal-to-noise ratio (PSNR) and mean squared error (MSE).", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 19], [20, 27], [28, 30], [31, 42], [43, 50], [51, 55], [56, 58], [59, 66], [67, 73], [73, 74], [74, 76], [76, 77], [77, 82], [83, 88], [89, 90], [90, 94], [94, 95], [96, 99], [100, 104], [105, 112], [113, 118], [119, 120], [120, 123], [123, 124], [124, 125]]}
{"doc_key": "ai-dev-164", "ner": [[10, 11, "researcher"], [13, 14, "researcher"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "work", "inspired", "subsequent", "generations", "of", "robotics", "researchers", "such", "as", "Rodney", "Brooks", ",", "Hans", "Moravec", "and", "Mark", "Tilden", "."], "sentence-detokenized": "His work inspired subsequent generations of robotics researchers such as Rodney Brooks, Hans Moravec and Mark Tilden.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 28], [29, 40], [41, 43], [44, 52], [53, 64], [65, 69], [70, 72], [73, 79], [80, 86], [86, 87], [88, 92], [93, 100], [101, 104], [105, 109], [110, 116], [116, 117]]}
{"doc_key": "ai-dev-165", "ner": [[11, 13, "algorithm"], [18, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[18, 19, 11, 13, "origin", "based_on", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "addition", ",", "pulse", "shaping", "is", "not", "differentiable", ",", "which", "eliminates", "backpropagation", "-", "based", "shaping", "methods", "such", "as", "gradient", "descent", "."], "sentence-detokenized": "In addition, pulse shaping is not differentiable, which eliminates backpropagation-based shaping methods such as gradient descent.", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 18], [19, 26], [27, 29], [30, 33], [34, 48], [48, 49], [50, 55], [56, 66], [67, 82], [82, 83], [83, 88], [89, 96], [97, 104], [105, 109], [110, 112], [113, 121], [122, 129], [129, 130]]}
{"doc_key": "ai-dev-166", "ner": [[8, 9, "metrics"], [15, 17, "metrics"], [19, 19, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 15, 17, "related-to", "describes", false, false], [15, 17, 19, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "relationships", "can", "easily", "be", "represented", "by", "a", "confusion", "matrix", ",", "a", "table", "that", "describes", "the", "accuracy", "of", "a", "classification", "model", "."], "sentence-detokenized": "These relationships can easily be represented by a confusion matrix, a table that describes the accuracy of a classification model.", "token2charspan": [[0, 5], [6, 19], [20, 23], [24, 30], [31, 33], [34, 45], [46, 48], [49, 50], [51, 60], [61, 67], [67, 68], [69, 70], [71, 76], [77, 81], [82, 91], [92, 95], [96, 104], [105, 107], [108, 109], [110, 124], [125, 130], [130, 131]]}
{"doc_key": "ai-dev-167", "ner": [[2, 10, "conference"], [8, 10, "conference"], [14, 14, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 10, 2, 10, "named", "", false, false], [14, 14, 2, 10, "physical", "", false, false], [14, 14, 2, 10, "role", "", false, false], [14, 14, 2, 10, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["At", "the", "2018", "Neural", "Information", "Processing", "Systems", "(", "NeurIPS", ")", "Conference", ",", "researchers", "from", "Google", "presented", "the", "paper"], "sentence-detokenized": "At the 2018 Neural Information Processing Systems (NeurIPS) Conference, researchers from Google presented the paper", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 18], [19, 30], [31, 41], [42, 49], [50, 51], [51, 58], [58, 59], [60, 70], [70, 71], [72, 83], [84, 88], [89, 95], [96, 105], [106, 109], [110, 115]]}
{"doc_key": "ai-dev-168", "ner": [[4, 4, "university"], [14, 14, "product"], [19, 21, "misc"], [25, 25, "conference"], [11, 33, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[14, 14, 19, 21, "win-defeat", "", false, false], [19, 21, 25, 25, "temporal", "", false, false], [11, 33, 25, 25, "part-of", "", false, false], [11, 33, 25, 25, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["During", "his", "time", "at", "Duke", ",", "he", "worked", "on", "an", "automated", "crossword", "solver", ",", "PROVERB", ",", "which", "won", "an", "Outstanding", "Paper", "Award", "in", "1999", "from", "AAAI", "and", "participated", "in", "the", "American", "Crossword", "Puzzle", "Tournament", "."], "sentence-detokenized": "During his time at Duke, he worked on an automated crossword solver, PROVERB, which won an Outstanding Paper Award in 1999 from AAAI and participated in the American Crossword Puzzle Tournament.", "token2charspan": [[0, 6], [7, 10], [11, 15], [16, 18], [19, 23], [23, 24], [25, 27], [28, 34], [35, 37], [38, 40], [41, 50], [51, 60], [61, 67], [67, 68], [69, 76], [76, 77], [78, 83], [84, 87], [88, 90], [91, 102], [103, 108], [109, 114], [115, 117], [118, 122], [123, 127], [128, 132], [133, 136], [137, 149], [150, 152], [153, 156], [157, 165], [166, 175], [176, 182], [183, 193], [193, 194]]}
{"doc_key": "ai-dev-169", "ner": [[2, 3, "location"], [5, 7, "location"], [15, 15, "country"], [17, 17, "country"], [19, 19, "country"], [21, 21, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[2, 3, 5, 7, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Headquartered", "in", "Rochester", "Hills", ",", "Michigan", ",", "the", "company", "had", "10", "regional", "locations", "in", "the", "US", ",", "Canada", ",", "Mexico", "and", "Brazil", "."], "sentence-detokenized": "Headquartered in Rochester Hills, Michigan, the company had 10 regional locations in the US, Canada, Mexico and Brazil.", "token2charspan": [[0, 13], [14, 16], [17, 26], [27, 32], [32, 33], [34, 42], [42, 43], [44, 47], [48, 55], [56, 59], [60, 62], [63, 71], [72, 81], [82, 84], [85, 88], [89, 91], [91, 92], [93, 99], [99, 100], [101, 107], [108, 111], [112, 118], [118, 119]]}
{"doc_key": "ai-dev-170", "ner": [[12, 12, "product"], [14, 16, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "joins", "a", "collection", "of", "historically", "significant", "robots", "that", "includes", "an", "early", "Unimate", "and", "Odetics", "Odex", "1", "."], "sentence-detokenized": "It joins a collection of historically significant robots that includes an early Unimate and Odetics Odex 1.", "token2charspan": [[0, 2], [3, 8], [9, 10], [11, 21], [22, 24], [25, 37], [38, 49], [50, 56], [57, 61], [62, 70], [71, 73], [74, 79], [80, 87], [88, 91], [92, 99], [100, 104], [105, 106], [106, 107]]}
{"doc_key": "ai-dev-171", "ner": [[8, 9, "researcher"], [13, 13, "organisation"], [15, 16, "researcher"], [26, 33, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[8, 9, 13, 13, "physical", "", false, false], [8, 9, 13, 13, "role", "", false, false], [15, 16, 13, 13, "physical", "", false, false], [15, 16, 13, 13, "role", "", false, false], [15, 16, 26, 33, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["A", "guest", "editor", "for", "this", "issue", "will", "be", "David", "'s", "former", "colleague", "at", "NIST", ",", "Judah", "Levine", ",", "who", "is", "the", "most", "recent", "recipient", "of", "the", "I", ".", "I", ".", "I", ".", "Rabi", "Award", "."], "sentence-detokenized": "A guest editor for this issue will be David's former colleague at NIST, Judah Levine, who is the most recent recipient of the I. I. I. Rabi Award.", "token2charspan": [[0, 1], [2, 7], [8, 14], [15, 18], [19, 23], [24, 29], [30, 34], [35, 37], [38, 43], [43, 45], [46, 52], [53, 62], [63, 65], [66, 70], [70, 71], [72, 77], [78, 84], [84, 85], [86, 89], [90, 92], [93, 96], [97, 101], [102, 108], [109, 118], [119, 121], [122, 125], [126, 127], [127, 128], [129, 130], [130, 131], [132, 133], [133, 134], [135, 139], [140, 145], [145, 146]]}
{"doc_key": "ai-dev-172", "ner": [[12, 13, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["These", "can", "be", "arranged", "in", "a", "2", "\u00d7", "2", "contingency", "table", "(", "confusion", "matrix", ")", ",", "conventionally", "with", "the", "test", "result", "on", "the", "vertical", "axis", "and", "the", "actual", "state", "on", "the", "horizontal", "axis", "."], "sentence-detokenized": "These can be arranged in a 2 \u00d7 2 contingency table (confusion matrix), conventionally with the test result on the vertical axis and the actual state on the horizontal axis.", "token2charspan": [[0, 5], [6, 9], [10, 12], [13, 21], [22, 24], [25, 26], [27, 28], [29, 30], [31, 32], [33, 44], [45, 50], [51, 52], [52, 61], [62, 68], [68, 69], [69, 70], [71, 85], [86, 90], [91, 94], [95, 99], [100, 106], [107, 109], [110, 113], [114, 122], [123, 127], [128, 131], [132, 135], [136, 142], [143, 148], [149, 151], [152, 155], [156, 166], [167, 171], [171, 172]]}
{"doc_key": "ai-dev-173", "ner": [[0, 4, "product"], [7, 7, "product"], [9, 9, "product"], [11, 12, "product"], [14, 16, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 4, 7, 7, "part-of", "", false, false], [0, 4, 9, 9, "part-of", "", false, false], [0, 4, 11, 12, "part-of", "", false, false], [0, 4, 14, 16, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Apple", "iOS", "operating", "system", "used", "on", "iPhone", ",", "iPad", "and", "iPod", "Touch", "uses", "VoiceOver", "speech", "synthesis", "."], "sentence-detokenized": "The Apple iOS operating system used on iPhone, iPad and iPod Touch uses VoiceOver speech synthesis.", "token2charspan": [[0, 3], [4, 9], [10, 13], [14, 23], [24, 30], [31, 35], [36, 38], [39, 45], [45, 46], [47, 51], [52, 55], [56, 60], [61, 66], [67, 71], [72, 81], [82, 88], [89, 98], [98, 99]]}
{"doc_key": "ai-dev-174", "ner": [[8, 10, "conference"], [16, 18, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "example", ",", "the", "best", "system", "that", "entered", "MUC", "-", "7", "scored", "93.39", "%", "of", "the", "F", "-", "measure", ",", "while", "the", "human", "commentators", "scored", "97.6", "%", "and", "96.95", "%", "."], "sentence-detokenized": "For example, the best system that entered MUC-7 scored 93.39% of the F-measure, while the human commentators scored 97.6% and 96.95%.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 16], [17, 21], [22, 28], [29, 33], [34, 41], [42, 45], [45, 46], [46, 47], [48, 54], [55, 60], [60, 61], [62, 64], [65, 68], [69, 70], [70, 71], [71, 78], [78, 79], [80, 85], [86, 89], [90, 95], [96, 108], [109, 115], [116, 120], [120, 121], [122, 125], [126, 131], [131, 132], [132, 133]]}
{"doc_key": "ai-dev-175", "ner": [[11, 13, "algorithm"], [15, 15, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[15, 15, 11, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["This", "is", "achieved", "using", "standard", "neural", "network", "training", "algorithms", "such", "as", "stochastic", "gradient", "descent", "with", "backpropagation", "."], "sentence-detokenized": "This is achieved using standard neural network training algorithms such as stochastic gradient descent with backpropagation.", "token2charspan": [[0, 4], [5, 7], [8, 16], [17, 22], [23, 31], [32, 38], [39, 46], [47, 55], [56, 66], [67, 71], [72, 74], [75, 85], [86, 94], [95, 102], [103, 107], [108, 123], [123, 124]]}
{"doc_key": "ai-dev-176", "ner": [[0, 1, "organisation"], [20, 20, "country"], [25, 25, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 20, 20, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Rotten", "Tomatoes", "is", "a", "top", "1000", "site", ",", "ranking", "around", "number", "400", "globally", "and", "in", "the", "top", "150", "for", "the", "US", "alone", ",", "according", "to", "Alexa", "rankings", "."], "sentence-detokenized": "Rotten Tomatoes is a top 1000 site, ranking around number 400 globally and in the top 150 for the US alone, according to Alexa rankings.", "token2charspan": [[0, 6], [7, 15], [16, 18], [19, 20], [21, 24], [25, 29], [30, 34], [34, 35], [36, 43], [44, 50], [51, 57], [58, 61], [62, 70], [71, 74], [75, 77], [78, 81], [82, 85], [86, 89], [90, 93], [94, 97], [98, 100], [101, 106], [106, 107], [108, 117], [118, 120], [121, 126], [127, 135], [135, 136]]}
{"doc_key": "ai-dev-177", "ner": [[16, 17, "algorithm"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "general", ",", "all", "forms", "of", "learning", "exhibit", "incremental", "change", "over", "time", ",", "but", "describe", "a", "sigmoid", "function", "that", "has", "different", "aspects", "depending", "on", "the", "time", "scale", "of", "observation", "."], "sentence-detokenized": "In general, all forms of learning exhibit incremental change over time, but describe a sigmoid function that has different aspects depending on the time scale of observation.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 15], [16, 21], [22, 24], [25, 33], [34, 41], [42, 53], [54, 60], [61, 65], [66, 70], [70, 71], [72, 75], [76, 84], [85, 86], [87, 94], [95, 103], [104, 108], [109, 112], [113, 122], [123, 130], [131, 140], [141, 143], [144, 147], [148, 152], [153, 158], [159, 161], [162, 173], [173, 174]]}
{"doc_key": "ai-dev-178", "ner": [[0, 0, "metrics"], [5, 7, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 5, 7, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["SSD", "is", "also", "known", "as", "mean", "squared", "error", "."], "sentence-detokenized": "SSD is also known as mean squared error.", "token2charspan": [[0, 3], [4, 6], [7, 11], [12, 17], [18, 20], [21, 25], [26, 33], [34, 39], [39, 40]]}
{"doc_key": "ai-dev-179", "ner": [[0, 2, "algorithm"], [4, 5, "algorithm"], [8, 10, "algorithm"], [22, 23, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 22, 23, "related-to", "can_be_related_to", true, false], [4, 5, 22, 23, "related-to", "can_be_related_to", true, false], [8, 10, 22, 23, "related-to", "can_be_related_to", true, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Decision", "tree", "learning", ",", "neural", "networks", "or", "a", "naive", "Bayes", "classifier", "could", "be", "used", "in", "combination", "with", "model", "quality", "measures", "such", "as", "balanced", "accuracy", "."], "sentence-detokenized": "Decision tree learning, neural networks or a naive Bayes classifier could be used in combination with model quality measures such as balanced accuracy.", "token2charspan": [[0, 8], [9, 13], [14, 22], [22, 23], [24, 30], [31, 39], [40, 42], [43, 44], [45, 50], [51, 56], [57, 67], [68, 73], [74, 76], [77, 81], [82, 84], [85, 96], [97, 101], [102, 107], [108, 115], [116, 124], [125, 129], [130, 132], [133, 141], [142, 150], [150, 151]]}
{"doc_key": "ai-dev-180", "ner": [[15, 15, "conference"], [20, 24, "conference"], [19, 27, "misc"], [33, 37, "product"], [42, 45, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 27, 20, 24, "origin", "", false, false], [19, 27, 20, 24, "temporal", "", false, false], [33, 37, 19, 27, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["He", "is", "a", "past", "president", "(", "1979", ")", "and", "inaugural", "member", "(", "2011", ")", "of", "ACL", ",", "co-recipient", "of", "the", "1992", "Association", "for", "Computing", "Machinery", "Software", "Systems", "Award", "for", "his", "contribution", "to", "the", "Interlisp", "programming", "system", ",", "and", "a", "Fellow", "of", "the", "Association", "for", "Computing", "Machinery", "."], "sentence-detokenized": "He is a past president (1979) and inaugural member (2011) of ACL, co-recipient of the 1992 Association for Computing Machinery Software Systems Award for his contribution to the Interlisp programming system, and a Fellow of the Association for Computing Machinery.", "token2charspan": [[0, 2], [3, 5], [6, 7], [8, 12], [13, 22], [23, 24], [24, 28], [28, 29], [30, 33], [34, 43], [44, 50], [51, 52], [52, 56], [56, 57], [58, 60], [61, 64], [64, 65], [66, 78], [79, 81], [82, 85], [86, 90], [91, 102], [103, 106], [107, 116], [117, 126], [127, 135], [136, 143], [144, 149], [150, 153], [154, 157], [158, 170], [171, 173], [174, 177], [178, 187], [188, 199], [200, 206], [206, 207], [208, 211], [212, 213], [214, 220], [221, 223], [224, 227], [228, 239], [240, 243], [244, 253], [254, 263], [263, 264]]}
{"doc_key": "ai-dev-181", "ner": [[2, 3, "researcher"], [5, 6, "researcher"], [8, 8, "researcher"], [12, 13, "researcher"], [25, 26, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[2, 3, 25, 26, "related-to", "", false, false], [5, 6, 25, 26, "related-to", "", false, false], [8, 8, 25, 26, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Along", "with", "Geoffrey", "Hinton", "and", "Yann", "LeCun", ",", "Bengio", "is", "considered", "by", "Cade", "Metz", "to", "be", "one", "of", "the", "three", "people", "most", "responsible", "for", "advancing", "deep", "learning", "in", "the", "1990s", "and", "2000s", "."], "sentence-detokenized": "Along with Geoffrey Hinton and Yann LeCun, Bengio is considered by Cade Metz to be one of the three people most responsible for advancing deep learning in the 1990s and 2000s.", "token2charspan": [[0, 5], [6, 10], [11, 19], [20, 26], [27, 30], [31, 35], [36, 41], [41, 42], [43, 49], [50, 52], [53, 63], [64, 66], [67, 71], [72, 76], [77, 79], [80, 82], [83, 86], [87, 89], [90, 93], [94, 99], [100, 106], [107, 111], [112, 123], [124, 127], [128, 137], [138, 142], [143, 151], [152, 154], [155, 158], [159, 164], [165, 168], [169, 174], [174, 175]]}
{"doc_key": "ai-dev-182", "ner": [[1, 2, "field"], [4, 5, "field"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "information", "theory", "and", "computer", "science", ",", "a", "code", "is", "usually", "thought", "of", "as", "an", "algorithm", "that", "uniquely", "represents", "symbols", "from", "a", "source", "alphabet", "by", "encoded", "strings", ",", "which", "may", "be", "in", "another", "target", "alphabet", "."], "sentence-detokenized": "In information theory and computer science, a code is usually thought of as an algorithm that uniquely represents symbols from a source alphabet by encoded strings, which may be in another target alphabet.", "token2charspan": [[0, 2], [3, 14], [15, 21], [22, 25], [26, 34], [35, 42], [42, 43], [44, 45], [46, 50], [51, 53], [54, 61], [62, 69], [70, 72], [73, 75], [76, 78], [79, 88], [89, 93], [94, 102], [103, 113], [114, 121], [122, 126], [127, 128], [129, 135], [136, 144], [145, 147], [148, 155], [156, 163], [163, 164], [165, 170], [171, 174], [175, 177], [178, 180], [181, 188], [189, 195], [196, 204], [204, 205]]}
{"doc_key": "ai-dev-183", "ner": [[7, 8, "algorithm"], [13, 14, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 14, 7, 8, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "fairly", "simple", "nonlinear", "function", ",", "the", "sigmoid", "function", ",", "such", "as", "the", "logistic", "function", ",", "also", "has", "an", "easy", "-", "to", "-", "calculate", "derivative", ",", "which", "can", "be", "important", "when", "calculating", "weight", "updates", "in", "the", "network", "."], "sentence-detokenized": "A fairly simple nonlinear function, the sigmoid function, such as the logistic function, also has an easy-to-calculate derivative, which can be important when calculating weight updates in the network.", "token2charspan": [[0, 1], [2, 8], [9, 15], [16, 25], [26, 34], [34, 35], [36, 39], [40, 47], [48, 56], [56, 57], [58, 62], [63, 65], [66, 69], [70, 78], [79, 87], [87, 88], [89, 93], [94, 97], [98, 100], [101, 105], [105, 106], [106, 108], [108, 109], [109, 118], [119, 129], [129, 130], [131, 136], [137, 140], [141, 143], [144, 153], [154, 158], [159, 170], [171, 177], [178, 185], [186, 188], [189, 192], [193, 200], [200, 201]]}
{"doc_key": "ai-dev-184", "ner": [[0, 3, "person"], [4, 4, "location"], [6, 6, "location"], [8, 10, "country"], [13, 13, "country"], [17, 18, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 4, 4, "physical", "", false, false], [4, 4, 6, 6, "physical", "", false, false], [6, 6, 8, 10, "physical", "", false, false], [6, 6, 13, 13, "physical", "", false, false], [6, 6, 17, 18, "physical", "", false, false], [13, 13, 8, 10, "origin", "", false, false], [17, 18, 13, 13, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "sentence": ["\u010capek", "was", "born", "in", "Hronov", ",", "Bohemia", "(", "Austria", "-", "Hungary", ",", "later", "Czechoslovakia", ",", "now", "the", "Czech", "Republic", ")", "in", "1887", "."], "sentence-detokenized": "\u010capek was born in Hronov, Bohemia (Austria-Hungary, later Czechoslovakia, now the Czech Republic) in 1887.", "token2charspan": [[0, 5], [6, 9], [10, 14], [15, 17], [18, 24], [24, 25], [26, 33], [34, 35], [35, 42], [42, 43], [43, 50], [50, 51], [52, 57], [58, 72], [72, 73], [74, 77], [78, 81], [82, 87], [88, 96], [96, 97], [98, 100], [101, 105], [105, 106]]}
{"doc_key": "ai-dev-185", "ner": [[8, 8, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["Some", "specialized", "programs", "can", "tell", "the", "story", "of", "RSS", "."], "sentence-detokenized": "Some specialized programs can tell the story of RSS.", "token2charspan": [[0, 4], [5, 16], [17, 25], [26, 29], [30, 34], [35, 38], [39, 44], [45, 47], [48, 51], [51, 52]]}
{"doc_key": "ai-dev-186", "ner": [[6, 7, "task"], [11, 12, "task"], [14, 14, "task"], [16, 16, "task"], [19, 20, "task"], [27, 30, "task"], [31, 32, "task"], [35, 40, "task"], [41, 43, "product"], [45, 46, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[6, 7, 11, 12, "related-to", "", true, false], [6, 7, 14, 14, "related-to", "", true, false], [6, 7, 16, 16, "related-to", "", true, false], [31, 32, 27, 30, "usage", "", true, false], [41, 43, 35, 40, "type-of", "", false, false], [45, 46, 35, 40, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Aspects", "of", "ontology", "editors", "include", ":", "visual", "navigation", "capabilities", "within", "the", "knowledge", "model", ",", "inference", "and", "extraction", "engines", ";", "module", "support", ";", "import", "and", "export", "of", "foreign", "knowledge", "representation", "languages", "for", "ontology", "matching", ";", "and", "meta", "-ontology", "support", ",", "such", "as", "OWL", "-", "S", ",", "Dublin", "Core", ",", "etc", "."], "sentence-detokenized": "Aspects of ontology editors include: visual navigation capabilities within the knowledge model, inference and extraction engines; module support; import and export of foreign knowledge representation languages for ontology matching; and meta-ontology support, such as OWL-S, Dublin Core, etc.", "token2charspan": [[0, 7], [8, 10], [11, 19], [20, 27], [28, 35], [35, 36], [37, 43], [44, 54], [55, 67], [68, 74], [75, 78], [79, 88], [89, 94], [94, 95], [96, 105], [106, 109], [110, 120], [121, 128], [128, 129], [130, 136], [137, 144], [144, 145], [146, 152], [153, 156], [157, 163], [164, 166], [167, 174], [175, 184], [185, 199], [200, 209], [210, 213], [214, 222], [223, 231], [231, 232], [233, 236], [237, 241], [241, 250], [251, 258], [258, 259], [260, 264], [265, 267], [268, 271], [271, 272], [272, 273], [273, 274], [275, 281], [282, 286], [286, 287], [288, 291], [291, 292]]}
{"doc_key": "ai-dev-187", "ner": [[0, 1, "organisation"], [6, 9, "misc"], [12, 13, "task"], [19, 19, "field"], [23, 23, "misc"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[6, 9, 0, 1, "origin", "", false, false], [12, 13, 6, 9, "part-of", "", false, false], [19, 19, 6, 9, "part-of", "", false, false], [23, 23, 19, 19, "type-of", "", false, false], [25, 26, 19, 19, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "FBI", "has", "also", "instituted", "the", "Next", "Generation", "Identification", "program", "to", "include", "facial", "recognition", "as", "well", "as", "more", "traditional", "biometrics", ",", "such", "as", "fingerprints", "and", "iris", "scans", ",", "which", "can", "be", "extracted", "from", "both", "criminal", "and", "civil", "databases", "."], "sentence-detokenized": "The FBI has also instituted the Next Generation Identification program to include facial recognition as well as more traditional biometrics, such as fingerprints and iris scans, which can be extracted from both criminal and civil databases.", "token2charspan": [[0, 3], [4, 7], [8, 11], [12, 16], [17, 27], [28, 31], [32, 36], [37, 47], [48, 62], [63, 70], [71, 73], [74, 81], [82, 88], [89, 100], [101, 103], [104, 108], [109, 111], [112, 116], [117, 128], [129, 139], [139, 140], [141, 145], [146, 148], [149, 161], [162, 165], [166, 170], [171, 176], [176, 177], [178, 183], [184, 187], [188, 190], [191, 200], [201, 205], [206, 210], [211, 219], [220, 223], [224, 229], [230, 239], [239, 240]]}
{"doc_key": "ai-dev-188", "ner": [[5, 7, "person"], [14, 15, "person"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["For", "the", "2016", "season", ",", "Samantha", "Ponder", "has", "been", "added", "as", "host", ",", "replacing", "Molly", "McGrath", "."], "sentence-detokenized": "For the 2016 season, Samantha Ponder has been added as host, replacing Molly McGrath.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 19], [19, 20], [21, 29], [30, 36], [37, 40], [41, 45], [46, 51], [52, 54], [55, 59], [59, 60], [61, 70], [71, 76], [77, 84], [84, 85]]}
{"doc_key": "ai-dev-189", "ner": [[3, 5, "algorithm"], [15, 19, "misc"], [21, 21, "misc"], [23, 23, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "an", "adversarial", "search", "algorithm", "commonly", "used", "for", "automated", "two", "-", "player", "games", "(", "Tic", "-", "tac", "-", "toe", ",", "chess", ",", "Go", ",", "etc.", ")", "."], "sentence-detokenized": "It is an adversarial search algorithm commonly used for automated two-player games (Tic-tac-toe, chess, Go, etc.).", "token2charspan": [[0, 2], [3, 5], [6, 8], [9, 20], [21, 27], [28, 37], [38, 46], [47, 51], [52, 55], [56, 65], [66, 69], [69, 70], [70, 76], [77, 82], [83, 84], [84, 87], [87, 88], [88, 91], [91, 92], [92, 95], [95, 96], [97, 102], [102, 103], [104, 106], [106, 107], [108, 112], [112, 113], [113, 114]]}
{"doc_key": "ai-dev-190", "ner": [[5, 6, "field"], [8, 9, "field"], [11, 12, "field"], [18, 19, "field"], [21, 22, "field"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "involves", "the", "fields", "of", "computer", "vision", "or", "machine", "vision", "and", "medical", "imaging", "and", "makes", "extensive", "use", "of", "pattern", "recognition", ",", "digital", "geometry", "and", "signal", "processing", "."], "sentence-detokenized": "It involves the fields of computer vision or machine vision and medical imaging and makes extensive use of pattern recognition, digital geometry and signal processing.", "token2charspan": [[0, 2], [3, 11], [12, 15], [16, 22], [23, 25], [26, 34], [35, 41], [42, 44], [45, 52], [53, 59], [60, 63], [64, 71], [72, 79], [80, 83], [84, 89], [90, 99], [100, 103], [104, 106], [107, 114], [115, 126], [126, 127], [128, 135], [136, 144], [145, 148], [149, 155], [156, 166], [166, 167]]}
{"doc_key": "ai-dev-191", "ner": [[2, 6, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "a", "facial", "recognition", "system", ",", "for", "example", ",", "an", "image", "of", "a", "person", "'s", "face", "would", "be", "the", "input", "and", "the", "output", "label", "would", "be", "that", "person", "'s", "name", "."], "sentence-detokenized": "In a facial recognition system, for example, an image of a person's face would be the input and the output label would be that person's name.", "token2charspan": [[0, 2], [3, 4], [5, 11], [12, 23], [24, 30], [30, 31], [32, 35], [36, 43], [43, 44], [45, 47], [48, 53], [54, 56], [57, 58], [59, 65], [65, 67], [68, 72], [73, 78], [79, 81], [82, 85], [86, 91], [92, 95], [96, 99], [100, 106], [107, 112], [113, 118], [119, 121], [122, 126], [127, 133], [133, 135], [136, 140], [140, 141]]}
{"doc_key": "ai-dev-192", "ner": [[0, 2, "organisation"], [4, 5, "product"], [9, 11, "product"], [20, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 4, 5, "artifact", "", false, false], [4, 5, 9, 11, "part-of", "", false, false], [9, 11, 4, 5, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Apple", "Inc.", "has", "introduced", "Face", "ID", "on", "the", "flagship", "i", "Phone", "X", "as", "the", "successor", "to", "the", "fingerprint", "-", "based", "Touch", "ID", "biometric", "authentication", "system", "."], "sentence-detokenized": "Apple Inc. has introduced Face ID on the flagship iPhone X as the successor to the fingerprint-based Touch ID biometric authentication system.", "token2charspan": [[0, 5], [6, 10], [11, 14], [15, 25], [26, 30], [31, 33], [34, 36], [37, 40], [41, 49], [50, 51], [51, 56], [57, 58], [59, 61], [62, 65], [66, 75], [76, 78], [79, 82], [83, 94], [94, 95], [95, 100], [101, 106], [107, 109], [110, 119], [120, 134], [135, 141], [141, 142]]}
{"doc_key": "ai-dev-193", "ner": [[3, 5, "metrics"], [8, 9, "metrics"], [20, 24, "metrics"], [27, 28, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Or", "combine", "the", "F", "-", "measure", "with", "the", "R-", "squared", "evaluated", "for", "the", "raw", "model", "output", "and", "objective", ";", "or", "the", "cost", "/", "gain", "matrix", "with", "the", "correlation", "coefficient", ",", "and", "so", "on", "."], "sentence-detokenized": "Or combine the F-measure with the R-squared evaluated for the raw model output and objective; or the cost/gain matrix with the correlation coefficient, and so on.", "token2charspan": [[0, 2], [3, 10], [11, 14], [15, 16], [16, 17], [17, 24], [25, 29], [30, 33], [34, 36], [36, 43], [44, 53], [54, 57], [58, 61], [62, 65], [66, 71], [72, 78], [79, 82], [83, 92], [92, 93], [94, 96], [97, 100], [101, 105], [105, 106], [106, 110], [111, 117], [118, 122], [123, 126], [127, 138], [139, 150], [150, 151], [152, 155], [156, 158], [159, 161], [161, 162]]}
{"doc_key": "ai-dev-194", "ner": [[6, 14, "conference"], [17, 19, "location"], [21, 21, "location"], [24, 28, "location"], [30, 30, "location"], [32, 36, "country"], [39, 42, "location"], [45, 49, "location"], [51, 51, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[6, 14, 17, 19, "physical", "", false, false], [6, 14, 24, 28, "physical", "", false, false], [6, 14, 39, 42, "physical", "", false, false], [6, 14, 45, 49, "physical", "", false, false], [17, 19, 21, 21, "physical", "", false, false], [24, 28, 30, 30, "physical", "", false, false], [30, 30, 32, 36, "physical", "", false, false], [39, 42, 51, 51, "physical", "", false, false], [45, 49, 51, 51, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["For", "the", "past", "15", "years", ",", "the", "Spanish", "edition", "of", "Campus", "Party", "has", "been", "held", "at", "the", "Colegio", "Miguel", "Hern\u00e1ndez", ",", "Ceulaj", "and", "the", "Municipal", "Sports", "Arena", "of", "Benalm\u00e1dena", "in", "Malaga", ",", "Spain", ",", "as", "well", "as", "at", "the", "County", "Fair", "of", "Valencia", "and", "the", "City", "of", "Arts", "and", "Sciences", "in", "Valencia", "."], "sentence-detokenized": "For the past 15 years, the Spanish edition of Campus Party has been held at the Colegio Miguel Hern\u00e1ndez, Ceulaj and the Municipal Sports Arena of Benalm\u00e1dena in Malaga, Spain, as well as at the County Fair of Valencia and the City of Arts and Sciences in Valencia.", "token2charspan": [[0, 3], [4, 7], [8, 12], [13, 15], [16, 21], [21, 22], [23, 26], [27, 34], [35, 42], [43, 45], [46, 52], [53, 58], [59, 62], [63, 67], [68, 72], [73, 75], [76, 79], [80, 87], [88, 94], [95, 104], [104, 105], [106, 112], [113, 116], [117, 120], [121, 130], [131, 137], [138, 143], [144, 146], [147, 158], [159, 161], [162, 168], [168, 169], [170, 175], [175, 176], [177, 179], [180, 184], [185, 187], [188, 190], [191, 194], [195, 201], [202, 206], [207, 209], [210, 218], [219, 222], [223, 226], [227, 231], [232, 234], [235, 239], [240, 243], [244, 252], [253, 255], [256, 264], [264, 265]]}
{"doc_key": "ai-dev-195", "ner": [[0, 0, "product"], [13, 13, "programlang"], [16, 16, "product"], [18, 18, "product"], [22, 22, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 13, 0, 0, "general-affiliation", "", false, false], [16, 16, 13, 13, "part-of", "", false, false], [18, 18, 13, 13, "part-of", "", false, false], [22, 22, 0, 0, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["gnuplot", "can", "be", "used", "from", "various", "programming", "languages", "to", "graph", "data", ",", "including", "Perl", "(", "via", "PDL", "and", "CPAN", "packages", ")", ",", "Python", "(", "via", ")", "."], "sentence-detokenized": "gnuplot can be used from various programming languages to graph data, including Perl (via PDL and CPAN packages), Python (via).", "token2charspan": [[0, 7], [8, 11], [12, 14], [15, 19], [20, 24], [25, 32], [33, 44], [45, 54], [55, 57], [58, 63], [64, 68], [68, 69], [70, 79], [80, 84], [85, 86], [86, 89], [90, 93], [94, 97], [98, 102], [103, 111], [111, 112], [112, 113], [114, 120], [121, 122], [122, 125], [125, 126], [126, 127]]}
{"doc_key": "ai-dev-196", "ner": [[3, 5, "product"], [19, 19, "conference"], [21, 21, "conference"], [35, 35, "conference"], [37, 37, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[19, 19, 3, 5, "topic", "", false, false], [21, 21, 3, 5, "topic", "", false, false], [35, 35, 3, 5, "topic", "", false, false], [37, 37, 3, 5, "topic", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "field", "of", "spoken", "dialogue", "systems", "is", "quite", "broad", "and", "includes", "research", "(", "presented", "at", "scientific", "conferences", "such", "as", "SIGdial", "and", "Interspeech", ")", "and", "an", "important", "industrial", "sector", "(", "with", "its", "own", "meetings", "such", "as", "SpeechTek", "and", "AVIOS", ")", "."], "sentence-detokenized": "The field of spoken dialogue systems is quite broad and includes research (presented at scientific conferences such as SIGdial and Interspeech) and an important industrial sector (with its own meetings such as SpeechTek and AVIOS).", "token2charspan": [[0, 3], [4, 9], [10, 12], [13, 19], [20, 28], [29, 36], [37, 39], [40, 45], [46, 51], [52, 55], [56, 64], [65, 73], [74, 75], [75, 84], [85, 87], [88, 98], [99, 110], [111, 115], [116, 118], [119, 126], [127, 130], [131, 142], [142, 143], [144, 147], [148, 150], [151, 160], [161, 171], [172, 178], [179, 180], [180, 184], [185, 188], [189, 192], [193, 201], [202, 206], [207, 209], [210, 219], [220, 223], [224, 229], [229, 230], [230, 231]]}
{"doc_key": "ai-dev-197", "ner": [[2, 4, "field"], [7, 8, "task"], [10, 12, "task"], [14, 16, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 2, 4, "part-of", "task_part_of_field", false, false], [10, 12, 2, 4, "part-of", "task_part_of_field", false, false], [14, 16, 2, 4, "part-of", "task_part_of_field", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Challenges", "in", "natural", "language", "processing", "frequently", "involve", "speech", "recognition", ",", "natural", "language", "understanding", "and", "natural", "language", "generation", "."], "sentence-detokenized": "Challenges in natural language processing frequently involve speech recognition, natural language understanding and natural language generation.", "token2charspan": [[0, 10], [11, 13], [14, 21], [22, 30], [31, 41], [42, 52], [53, 60], [61, 67], [68, 79], [79, 80], [81, 88], [89, 97], [98, 111], [112, 115], [116, 123], [124, 132], [133, 143], [143, 144]]}
{"doc_key": "ai-dev-198", "ner": [[5, 5, "product"], [8, 10, "product"], [38, 39, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 8, 10, "part-of", "", false, false], [5, 5, 38, 39, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["These", "systems", ",", "such", "as", "Siri", "in", "the", "iOS", "operating", "system", ",", "operate", "on", "a", "pattern", "recognition", "technique", "similar", "to", "text", "-", "based", "systems", ",", "but", "in", "the", "case", "of", "the", "former", ",", "user", "input", "is", "done", "through", "speech", "recognition", "."], "sentence-detokenized": "These systems, such as Siri in the iOS operating system, operate on a pattern recognition technique similar to text-based systems, but in the case of the former, user input is done through speech recognition.", "token2charspan": [[0, 5], [6, 13], [13, 14], [15, 19], [20, 22], [23, 27], [28, 30], [31, 34], [35, 38], [39, 48], [49, 55], [55, 56], [57, 64], [65, 67], [68, 69], [70, 77], [78, 89], [90, 99], [100, 107], [108, 110], [111, 115], [115, 116], [116, 121], [122, 129], [129, 130], [131, 134], [135, 137], [138, 141], [142, 146], [147, 149], [150, 153], [154, 160], [160, 161], [162, 166], [167, 172], [173, 175], [176, 180], [181, 188], [189, 195], [196, 207], [207, 208]]}
{"doc_key": "ai-dev-199", "ner": [[1, 3, "algorithm"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 3, 13, 14, "related-to", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["More", "exotic", "fitness", "features", "that", "explore", "model", "granularity", "include", "the", "area", "under", "the", "ROC", "curve", "and", "the", "rank", "measure", "."], "sentence-detokenized": "More exotic fitness features that explore model granularity include the area under the ROC curve and the rank measure.", "token2charspan": [[0, 4], [5, 11], [12, 19], [20, 28], [29, 33], [34, 41], [42, 47], [48, 59], [60, 67], [68, 71], [72, 76], [77, 82], [83, 86], [87, 90], [91, 96], [97, 100], [101, 104], [105, 109], [110, 117], [117, 118]]}
{"doc_key": "ai-dev-200", "ner": [[7, 10, "researcher"], [17, 17, "product"], [15, 25, "organisation"], [27, 27, "organisation"], [2, 40, "product"]], "ner_mapping_to_source": [1, 2, 3, 4, 5], "relations": [[7, 10, 15, 25, "role", "", false, false], [17, 17, 7, 10, "origin", "", false, false], [27, 27, 15, 25, "named", "", false, false], [2, 40, 15, 25, "artifact", "", false, false]], "relations_mapping_to_source": [1, 2, 3, 4], "sentence": ["The", "term", "Semantic", "Web", "was", "coined", "by", "Tim", "Berners", "-", "Lee", ",", "inventor", "of", "the", "World", "Wide", "Web", "and", "director", "of", "the", "World", "Wide", "Web", "Consortium", "(", "W3C", ")", ",", "which", "oversees", "the", "development", "of", "proposed", "standards", "for", "the", "Semantic", "Web", "."], "sentence-detokenized": "The term Semantic Web was coined by Tim Berners-Lee, inventor of the World Wide Web and director of the World Wide Web Consortium (W3C), which oversees the development of proposed standards for the Semantic Web.", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 21], [22, 25], [26, 32], [33, 35], [36, 39], [40, 47], [47, 48], [48, 51], [51, 52], [53, 61], [62, 64], [65, 68], [69, 74], [75, 79], [80, 83], [84, 87], [88, 96], [97, 99], [100, 103], [104, 109], [110, 114], [115, 118], [119, 129], [130, 131], [131, 134], [134, 135], [135, 136], [137, 142], [143, 151], [152, 155], [156, 167], [168, 170], [171, 179], [180, 189], [190, 193], [194, 197], [198, 206], [207, 210], [210, 211]]}
{"doc_key": "ai-dev-201", "ner": [[0, 1, "task"], [5, 5, "task"], [12, 12, "product"], [15, 18, "product"], [21, 21, "product"], [24, 25, "product"], [32, 33, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 1, 12, 12, "opposite", "", false, false], [0, 1, 15, 18, "opposite", "", false, false], [0, 1, 24, 25, "opposite", "", false, false], [0, 1, 32, 33, "part-of", "", false, false], [5, 5, 0, 1, "named", "", false, false], [21, 21, 15, 18, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Machine", "translation", ",", "sometimes", "abbreviated", "MT", "(", "not", "to", "be", "confused", "with", "computer-assisted", "translation", ",", "machine", "-", "assisted", "human", "translation", "(", "MAHT", ")", "or", "interactive", "translation", ")", ",", "is", "a", "subfield", "of", "computational", "linguistics", "that", "studies", "the", "use", "of", "computer", "programs", "to", "translate", "text", "or", "speech", "from", "one", "language", "into", "another", "."], "sentence-detokenized": "Machine translation, sometimes abbreviated MT (not to be confused with computer-assisted translation, machine-assisted human translation (MAHT) or interactive translation), is a subfield of computational linguistics that studies the use of computer programs to translate text or speech from one language into another.", "token2charspan": [[0, 7], [8, 19], [19, 20], [21, 30], [31, 42], [43, 45], [46, 47], [47, 50], [51, 53], [54, 56], [57, 65], [66, 70], [71, 88], [89, 100], [100, 101], [102, 109], [109, 110], [110, 118], [119, 124], [125, 136], [137, 138], [138, 142], [142, 143], [144, 146], [147, 158], [159, 170], [170, 171], [171, 172], [173, 175], [176, 177], [178, 186], [187, 189], [190, 203], [204, 215], [216, 220], [221, 228], [229, 232], [233, 236], [237, 239], [240, 248], [249, 257], [258, 260], [261, 270], [271, 275], [276, 278], [279, 285], [286, 290], [291, 294], [295, 303], [304, 308], [309, 316], [316, 317]]}
{"doc_key": "ai-dev-202", "ner": [[5, 6, "product"], [10, 10, "university"], [15, 16, "researcher"], [18, 19, "researcher"], [45, 46, "location"], [44, 44, "location"], [2, 53, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 6, 15, 16, "artifact", "", false, false], [5, 6, 18, 19, "artifact", "", false, false], [15, 16, 10, 10, "physical", "", false, false], [15, 16, 10, 10, "role", "", false, false], [18, 19, 10, 10, "physical", "", false, false], [18, 19, 10, 10, "role", "", false, false], [45, 46, 44, 44, "physical", "", false, false], [2, 53, 45, 46, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["The", "first", "interlingual", "machine", "translation", "systems", "were", "also", "built", "at", "Stanford", "in", "the", "1970s", "by", "Roger", "Schank", "and", "Yorick", "Wilks", ";", "the", "former", "became", "the", "basis", "of", "a", "commercial", "system", "for", "transferring", "funds", ",", "and", "the", "code", "of", "the", "latter", "is", "preserved", "at", "the", "Boston", "Computer", "Museum", "as", "the", "first", "interlingual", "machine", "translation", "system", "."], "sentence-detokenized": "The first interlingual machine translation systems were also built at Stanford in the 1970s by Roger Schank and Yorick Wilks; the former became the basis of a commercial system for transferring funds, and the code of the latter is preserved at the Boston Computer Museum as the first interlingual machine translation system.", "token2charspan": [[0, 3], [4, 9], [10, 22], [23, 30], [31, 42], [43, 50], [51, 55], [56, 60], [61, 66], [67, 69], [70, 78], [79, 81], [82, 85], [86, 91], [92, 94], [95, 100], [101, 107], [108, 111], [112, 118], [119, 124], [124, 125], [126, 129], [130, 136], [137, 143], [144, 147], [148, 153], [154, 156], [157, 158], [159, 169], [170, 176], [177, 180], [181, 193], [194, 199], [199, 200], [201, 204], [205, 208], [209, 213], [214, 216], [217, 220], [221, 227], [228, 230], [231, 240], [241, 243], [244, 247], [248, 254], [255, 263], [264, 270], [271, 273], [274, 277], [278, 283], [284, 296], [297, 304], [305, 316], [317, 323], [323, 324]]}
{"doc_key": "ai-dev-203", "ner": [[0, 5, "researcher"], [8, 9, "conference"], [12, 13, "conference"], [6, 25, "conference"], [27, 28, "conference"], [34, 37, "organisation"], [45, 45, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 5, 8, 9, "role", "", false, false], [0, 5, 6, 25, "role", "", false, false], [0, 5, 34, 37, "role", "", false, false], [0, 5, 45, 45, "role", "", false, false], [12, 13, 8, 9, "named", "", false, false], [27, 28, 6, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Sycara", "was", "Program", "Chair", "of", "the", "Second", "International", "Semantic", "Web", "Conference", "(", "ISWC", "2003", ")", ";", "General", "Chair", "of", "the", "Second", "International", "Conference", "on", "Autonomous", "Agents", "(", "Agents", "98", ")", ";", "Chair", "of", "the", "Agents", "Conference", "Steering", "Committee", "(", "1999-2001", ")", ";", "Chair", "of", "the", "AAAI", "Fellowship", "(", "1993-1999", ")", ";"], "sentence-detokenized": "Sycara was Program Chair of the Second International Semantic Web Conference (ISWC 2003); General Chair of the Second International Conference on Autonomous Agents (Agents 98); Chair of the Agents Conference Steering Committee (1999-2001); Chair of the AAAI Fellowship (1993-1999);", "token2charspan": [[0, 6], [7, 10], [11, 18], [19, 24], [25, 27], [28, 31], [32, 38], [39, 52], [53, 61], [62, 65], [66, 76], [77, 78], [78, 82], [83, 87], [87, 88], [88, 89], [90, 97], [98, 103], [104, 106], [107, 110], [111, 117], [118, 131], [132, 142], [143, 145], [146, 156], [157, 163], [164, 165], [165, 171], [172, 174], [174, 175], [175, 176], [177, 182], [183, 185], [186, 189], [190, 196], [197, 207], [208, 216], [217, 226], [227, 228], [228, 237], [237, 238], [238, 239], [240, 245], [246, 248], [249, 252], [253, 257], [258, 268], [269, 270], [270, 279], [279, 280], [280, 281]]}
{"doc_key": "ai-dev-204", "ner": [[11, 11, "conference"], [13, 16, "conference"], [18, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[13, 16, 11, 11, "named", "", false, false], [18, 20, 11, 11, "part-of", "", false, false], [18, 20, 11, 11, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2016", ",", "she", "was", "chosen", "as", "the", "winner", "of", "the", "ACL", "(", "Association", "for", "Computational", "Linguistics", ")", "Lifetime", "Achievement", "Award", "."], "sentence-detokenized": "In 2016, she was chosen as the winner of the ACL (Association for Computational Linguistics) Lifetime Achievement Award.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 23], [24, 26], [27, 30], [31, 37], [38, 40], [41, 44], [45, 48], [49, 50], [50, 61], [62, 65], [66, 79], [80, 91], [91, 92], [93, 101], [102, 113], [114, 119], [119, 120]]}
{"doc_key": "ai-dev-205", "ner": [[0, 1, "researcher"], [3, 5, "researcher"], [7, 8, "researcher"], [10, 11, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", ",", "Y", ".", "Bengio", ",", "P.", "Frasconi", "and", "J\u00fcrgen", "Schmidhuber", "."], "sentence-detokenized": "Sepp Hochreiter, Y. Bengio, P. Frasconi and J\u00fcrgen Schmidhuber.", "token2charspan": [[0, 4], [5, 15], [15, 16], [17, 18], [18, 19], [20, 26], [26, 27], [28, 30], [31, 39], [40, 43], [44, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-206", "ner": [[3, 3, "product"], [6, 7, "misc"], [9, 9, "programlang"], [19, 20, "product"], [34, 34, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 9, 9, "usage", "", false, false], [9, 9, 6, 7, "type-of", "", false, false], [9, 9, 19, 20, "related-to", "", false, false], [34, 34, 3, 3, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["For", "example", ",", "A.L.I.C.E.", "uses", "a", "markup", "language", "called", "AIML", ",", "which", "is", "specific", "to", "its", "function", "as", "a", "dialogue", "system", "and", "has", "since", "been", "adopted", "by", "various", "other", "developers", "of", "so", "-", "called", "Alicebots", "."], "sentence-detokenized": "For example, A.L.I.C.E. uses a markup language called AIML, which is specific to its function as a dialogue system and has since been adopted by various other developers of so-called Alicebots.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 23], [24, 28], [29, 30], [31, 37], [38, 46], [47, 53], [54, 58], [58, 59], [60, 65], [66, 68], [69, 77], [78, 80], [81, 84], [85, 93], [94, 96], [97, 98], [99, 107], [108, 114], [115, 118], [119, 122], [123, 128], [129, 133], [134, 141], [142, 144], [145, 152], [153, 158], [159, 169], [170, 172], [173, 175], [175, 176], [176, 182], [183, 192], [192, 193]]}
{"doc_key": "ai-dev-207", "ner": [[10, 16, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "2000", ",", "she", "was", "elected", "a", "Fellow", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "."], "sentence-detokenized": "In 2000, she was elected a Fellow of the Association for the Advancement of Artificial Intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 16], [17, 24], [25, 26], [27, 33], [34, 36], [37, 40], [41, 52], [53, 56], [57, 60], [61, 72], [73, 75], [76, 86], [87, 99], [99, 100]]}
{"doc_key": "ai-dev-208", "ner": [[0, 2, "misc"], [4, 4, "misc"], [10, 15, "misc"], [24, 25, "algorithm"], [34, 35, "field"], [37, 37, "field"], [40, 41, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 2, 10, 15, "type-of", "", false, false], [0, 2, 34, 35, "related-to", "performs", true, false], [0, 2, 37, 37, "related-to", "performs", true, false], [0, 2, 40, 41, "related-to", "performs", true, false], [4, 4, 0, 2, "named", "", false, false], [24, 25, 10, 15, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Learning", "Classification", "Systems", "(", "LCS", ")", "are", "a", "family", "of", "rule", "-", "based", "machine", "learning", "algorithms", "that", "combine", "a", "discovery", "component", ",", "usually", "a", "genetic", "algorithm", ",", "with", "a", "learning", "component", "that", "performs", "either", "supervised", "learning", ",", "reinforcement", "learning", "or", "unsupervised", "learning", "."], "sentence-detokenized": "Learning Classification Systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, usually a genetic algorithm, with a learning component that performs either supervised learning, reinforcement learning or unsupervised learning.", "token2charspan": [[0, 8], [9, 23], [24, 31], [32, 33], [33, 36], [36, 37], [38, 41], [42, 43], [44, 50], [51, 53], [54, 58], [58, 59], [59, 64], [65, 72], [73, 81], [82, 92], [93, 97], [98, 105], [106, 107], [108, 117], [118, 127], [127, 128], [129, 136], [137, 138], [139, 146], [147, 156], [156, 157], [158, 162], [163, 164], [165, 173], [174, 183], [184, 188], [189, 197], [198, 204], [205, 215], [216, 224], [224, 225], [226, 239], [240, 248], [249, 251], [252, 264], [265, 273], [273, 274]]}
{"doc_key": "ai-dev-209", "ner": [[14, 16, "algorithm"], [18, 18, "algorithm"], [27, 29, "algorithm"], [32, 32, "misc"], [40, 42, "algorithm"], [50, 53, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[14, 16, 27, 29, "origin", "", false, false], [14, 16, 32, 32, "usage", "", false, false], [18, 18, 14, 16, "named", "", false, false], [40, 42, 32, 32, "type-of", "", false, false], [40, 42, 50, 53, "compare", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "unknown", "parameters", "in", "each", "\u03b2subk", "/", "sub", "vector", "are", "usually", "jointly", "estimated", "by", "maximum", "a", "posteriori", "(", "MAP", ")", "estimation", ",", "which", "is", "an", "extension", "of", "maximum", "likelihood", "that", "uses", "weight", "regularization", "to", "prevent", "pathological", "solutions", "(", "usually", "a", "quadratic", "regularization", "function", ",", "which", "is", "equivalent", "to", "placing", "a", "zero-mean", "Gaussian", "prior", "distribution", "over", "the", "weights", ",", "but", "other", "distributions", "are", "possible", ")", "."], "sentence-detokenized": "The unknown parameters in each \u03b2subk/sub vector are usually jointly estimated by maximum a posteriori (MAP) estimation, which is an extension of maximum likelihood that uses weight regularization to prevent pathological solutions (usually a quadratic regularization function, which is equivalent to placing a zero-mean Gaussian prior distribution over the weights, but other distributions are possible).", "token2charspan": [[0, 3], [4, 11], [12, 22], [23, 25], [26, 30], [31, 36], [36, 37], [37, 40], [41, 47], [48, 51], [52, 59], [60, 67], [68, 77], [78, 80], [81, 88], [89, 90], [91, 101], [102, 103], [103, 106], [106, 107], [108, 118], [118, 119], [120, 125], [126, 128], [129, 131], [132, 141], [142, 144], [145, 152], [153, 163], [164, 168], [169, 173], [174, 180], [181, 195], [196, 198], [199, 206], [207, 219], [220, 229], [230, 231], [231, 238], [239, 240], [241, 250], [251, 265], [266, 274], [274, 275], [276, 281], [282, 284], [285, 295], [296, 298], [299, 306], [307, 308], [309, 318], [319, 327], [328, 333], [334, 346], [347, 351], [352, 355], [356, 363], [363, 364], [365, 368], [369, 374], [375, 388], [389, 392], [393, 401], [401, 402], [402, 403]]}
{"doc_key": "ai-dev-210", "ner": [[10, 11, "researcher"], [13, 13, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[13, 13, 10, 11, "artifact", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["The", "hierarchical", "structure", "of", "words", "has", "been", "explicitly", "mapped", "in", "George", "Miller", "'s", "Wordnet", "."], "sentence-detokenized": "The hierarchical structure of words has been explicitly mapped in George Miller's Wordnet.", "token2charspan": [[0, 3], [4, 16], [17, 26], [27, 29], [30, 35], [36, 39], [40, 44], [45, 55], [56, 62], [63, 65], [66, 72], [73, 79], [79, 81], [82, 89], [89, 90]]}
{"doc_key": "ai-dev-211", "ner": [[9, 14, "conference"], [21, 24, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[21, 24, 9, 14, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["An", "illustration", "of", "their", "capabilities", "is", "provided", "by", "the", "ImageNet", "Large", "Scale", "Visual", "Recognition", "Challenge", ";", "this", "is", "a", "benchmark", "in", "object", "classification", "and", "detection", ",", "with", "millions", "of", "images", "and", "hundreds", "of", "object", "classes", "."], "sentence-detokenized": "An illustration of their capabilities is provided by the ImageNet Large Scale Visual Recognition Challenge; this is a benchmark in object classification and detection, with millions of images and hundreds of object classes.", "token2charspan": [[0, 2], [3, 15], [16, 18], [19, 24], [25, 37], [38, 40], [41, 49], [50, 52], [53, 56], [57, 65], [66, 71], [72, 77], [78, 84], [85, 96], [97, 106], [106, 107], [108, 112], [113, 115], [116, 117], [118, 127], [128, 130], [131, 137], [138, 152], [153, 156], [157, 166], [166, 167], [168, 172], [173, 181], [182, 184], [185, 191], [192, 195], [196, 204], [205, 207], [208, 214], [215, 222], [222, 223]]}
{"doc_key": "ai-dev-212", "ner": [[1, 2, "misc"], [23, 23, "misc"], [25, 27, "person"], [30, 30, "misc"], [35, 37, "person"], [40, 42, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[23, 23, 1, 2, "general-affiliation", "", false, false], [30, 30, 1, 2, "general-affiliation", "", false, false], [30, 30, 25, 27, "artifact", "", false, false], [40, 42, 1, 2, "general-affiliation", "", false, false], [40, 42, 35, 37, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "science", "fiction", ",", "female", "robots", "are", "often", "produced", "for", "use", "as", "domestic", "servants", "and", "sex", "slaves", ",", "as", "seen", "in", "the", "film", "Westworld", ",", "Paul", "J.", "McAuley", "'s", "novel", "Fairyland", "(", "1995", ")", "and", "Lester", "del", "Rey's", "short", "story", "Helen", "O'", "Loy", "(", "1938", ")", ",", "and", "sometimes", "as", "warriors", ",", "killers", "or", "workers", "."], "sentence-detokenized": "In science fiction, female robots are often produced for use as domestic servants and sex slaves, as seen in the film Westworld, Paul J. McAuley's novel Fairyland (1995) and Lester del Rey's short story Helen O'Loy (1938), and sometimes as warriors, killers or workers.", "token2charspan": [[0, 2], [3, 10], [11, 18], [18, 19], [20, 26], [27, 33], [34, 37], [38, 43], [44, 52], [53, 56], [57, 60], [61, 63], [64, 72], [73, 81], [82, 85], [86, 89], [90, 96], [96, 97], [98, 100], [101, 105], [106, 108], [109, 112], [113, 117], [118, 127], [127, 128], [129, 133], [134, 136], [137, 144], [144, 146], [147, 152], [153, 162], [163, 164], [164, 168], [168, 169], [170, 173], [174, 180], [181, 184], [185, 190], [191, 196], [197, 202], [203, 208], [209, 211], [211, 214], [215, 216], [216, 220], [220, 221], [221, 222], [223, 226], [227, 236], [237, 239], [240, 248], [248, 249], [250, 257], [258, 260], [261, 268], [268, 269]]}
{"doc_key": "ai-dev-213", "ner": [[0, 1, "task"], [3, 4, "task"], [6, 7, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Question", "answering", ",", "speech", "recognition", "and", "machine", "translation", "."], "sentence-detokenized": "Question answering, speech recognition and machine translation.", "token2charspan": [[0, 8], [9, 18], [18, 19], [20, 26], [27, 38], [39, 42], [43, 50], [51, 62], [62, 63]]}
{"doc_key": "ai-dev-214", "ner": [[5, 7, "researcher"], [9, 13, "organisation"], [15, 18, "location"], [20, 20, "location"], [22, 22, "location"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 7, 9, 13, "role", "", false, false], [9, 13, 15, 18, "physical", "", false, false], [15, 18, 20, 20, "physical", "", false, false], [20, 20, 22, 22, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "his", "landmark", "paper", ",", "Harry", "Blum", "of", "the", "Cambridge", "Air", "Force", "Research", "Laboratories", "at", "Hanscom", "Air", "Force", "Base", ",", "Bedford", ",", "Massachusetts", ",", "defined", "a", "median", "axis", "for", "calculating", "the", "skeleton", "of", "a", "shape", "using", "an", "intuitive", "model", "of", "fire", "propagation", "in", "a", "grass", "field", ",", "where", "the", "field", "is", "shaped", "like", "the", "given", "shape", "."], "sentence-detokenized": "In his landmark paper, Harry Blum of the Cambridge Air Force Research Laboratories at Hanscom Air Force Base, Bedford, Massachusetts, defined a median axis for calculating the skeleton of a shape using an intuitive model of fire propagation in a grass field, where the field is shaped like the given shape.", "token2charspan": [[0, 2], [3, 6], [7, 15], [16, 21], [21, 22], [23, 28], [29, 33], [34, 36], [37, 40], [41, 50], [51, 54], [55, 60], [61, 69], [70, 82], [83, 85], [86, 93], [94, 97], [98, 103], [104, 108], [108, 109], [110, 117], [117, 118], [119, 132], [132, 133], [134, 141], [142, 143], [144, 150], [151, 155], [156, 159], [160, 171], [172, 175], [176, 184], [185, 187], [188, 189], [190, 195], [196, 201], [202, 204], [205, 214], [215, 220], [221, 223], [224, 228], [229, 240], [241, 243], [244, 245], [246, 251], [252, 257], [257, 258], [259, 264], [265, 268], [269, 274], [275, 277], [278, 284], [285, 289], [290, 293], [294, 299], [300, 305], [305, 306]]}
{"doc_key": "ai-dev-215", "ner": [[15, 15, "algorithm"], [17, 17, "algorithm"], [20, 21, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[15, 15, 20, 21, "compare", "", false, false], [17, 17, 20, 21, "compare", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["However", ",", "unlike", "boosting", "algorithms", "that", "analytically", "minimize", "a", "convex", "loss", "function", "(", "e.g.", ",", "AdaBoost", "and", "LogitBoost", ")", ",", "Brown", "Boost", "solves", "a", "system", "of", "two", "equations", "and", "two", "unknowns", "using", "standard", "numerical", "methods", "."], "sentence-detokenized": "However, unlike boosting algorithms that analytically minimize a convex loss function (e.g., AdaBoost and LogitBoost), BrownBoost solves a system of two equations and two unknowns using standard numerical methods.", "token2charspan": [[0, 7], [7, 8], [9, 15], [16, 24], [25, 35], [36, 40], [41, 53], [54, 62], [63, 64], [65, 71], [72, 76], [77, 85], [86, 87], [87, 91], [91, 92], [93, 101], [102, 105], [106, 116], [116, 117], [117, 118], [119, 124], [124, 129], [130, 136], [137, 138], [139, 145], [146, 148], [149, 152], [153, 162], [163, 166], [167, 170], [171, 179], [180, 185], [186, 194], [195, 204], [205, 212], [212, 213]]}
{"doc_key": "ai-dev-216", "ner": [[0, 1, "researcher"], [9, 11, "misc"], [19, 25, "conference"], [27, 27, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 1, 9, 11, "win-defeat", "", false, false], [0, 1, 19, 25, "role", "", false, false], [27, 27, 19, 25, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Getoor", "has", "received", "several", "best", "paper", "awards", ",", "an", "NSF", "career", "award", ",", "and", "is", "a", "member", "of", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", "."], "sentence-detokenized": "Getoor has received several best paper awards, an NSF career award, and is a member of the Association for the Advancement of Artificial Intelligence (AAAI).", "token2charspan": [[0, 6], [7, 10], [11, 19], [20, 27], [28, 32], [33, 38], [39, 45], [45, 46], [47, 49], [50, 53], [54, 60], [61, 66], [66, 67], [68, 71], [72, 74], [75, 76], [77, 83], [84, 86], [87, 90], [91, 102], [103, 106], [107, 110], [111, 122], [123, 125], [126, 136], [137, 149], [150, 151], [151, 155], [155, 156], [156, 157]]}
{"doc_key": "ai-dev-217", "ner": [[0, 1, "misc"], [6, 12, "misc"], [15, 16, "misc"], [21, 25, "misc"], [30, 32, "misc"], [36, 40, "university"], [45, 53, "misc"], [58, 66, "misc"], [71, 75, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [], "relations_mapping_to_source": [], "sentence": ["ACM", "Fellow", "(", "2015", ")", "br", "Association", "for", "Computational", "Linguistics", "Fellow", "(", "2011", ")", "br", "AAAI", "Fellow", "(", "1994", ")", "br", "International", "Speech", "Communication", "Association", "Fellow", "(", "2011", ")", "br", "Doctor", "Honoris", "Causa", "(", "Hedersdoktor", ")", "KTH", "Royal", "Institute", "of", "Technology", "(", "2007", ")", "br", "Columbia", "Engineering", "School", "Alumni", "Association", "Distinguished", "Faculty", "Teaching", "award", "(", "2009", ")", "br", "IEEE", "James", "L.", "Flanagan", "Speech", "and", "Audio", "Processing", "Award", "(", "2011", ")", "br", "ISCA", "Medal", "for", "Scientific", "Achievement", "(", "2011", ")"], "sentence-detokenized": "ACM Fellow (2015) br Association for Computational Linguistics Fellow (2011) br AAAI Fellow (1994) br International Speech Communication Association Fellow (2011) br Doctor Honoris Causa (Hedersdoktor) KTH Royal Institute of Technology (2007) br Columbia Engineering School Alumni Association Distinguished Faculty Teaching award (2009) br IEEE James L. Flanagan Speech and Audio Processing Award (2011) br ISCA Medal for Scientific Achievement (2011)", "token2charspan": [[0, 3], [4, 10], [11, 12], [12, 16], [16, 17], [18, 20], [21, 32], [33, 36], [37, 50], [51, 62], [63, 69], [70, 71], [71, 75], [75, 76], [77, 79], [80, 84], [85, 91], [92, 93], [93, 97], [97, 98], [99, 101], [102, 115], [116, 122], [123, 136], [137, 148], [149, 155], [156, 157], [157, 161], [161, 162], [163, 165], [166, 172], [173, 180], [181, 186], [187, 188], [188, 200], [200, 201], [202, 205], [206, 211], [212, 221], [222, 224], [225, 235], [236, 237], [237, 241], [241, 242], [243, 245], [246, 254], [255, 266], [267, 273], [274, 280], [281, 292], [293, 306], [307, 314], [315, 323], [324, 329], [330, 331], [331, 335], [335, 336], [337, 339], [340, 344], [345, 350], [351, 353], [354, 362], [363, 369], [370, 373], [374, 379], [380, 390], [391, 396], [397, 398], [398, 402], [402, 403], [404, 406], [407, 411], [412, 417], [418, 421], [422, 432], [433, 444], [445, 446], [446, 450], [450, 451]]}
{"doc_key": "ai-dev-218", "ner": [[6, 6, "university"], [15, 15, "task"], [24, 26, "metrics"], [14, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[24, 26, 14, 36, "opposite", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["A", "frustrating", "result", "of", "the", "same", "Stanford", "study", "(", "and", "other", "attempts", "to", "improve", "name", "recognition", "translation", ")", "is", "that", "often", "a", "decrease", "in", "bilingual", "translation", "underachievement", "scores", "will", "result", "from", "the", "inclusion", "of", "named", "entity", "translation", "methods", "."], "sentence-detokenized": "A frustrating result of the same Stanford study (and other attempts to improve name recognition translation) is that often a decrease in bilingual translation underachievement scores will result from the inclusion of named entity translation methods.", "token2charspan": [[0, 1], [2, 13], [14, 20], [21, 23], [24, 27], [28, 32], [33, 41], [42, 47], [48, 49], [49, 52], [53, 58], [59, 67], [68, 70], [71, 78], [79, 83], [84, 95], [96, 107], [107, 108], [109, 111], [112, 116], [117, 122], [123, 124], [125, 133], [134, 136], [137, 146], [147, 158], [159, 175], [176, 182], [183, 187], [188, 194], [195, 199], [200, 203], [204, 213], [214, 216], [217, 222], [223, 229], [230, 241], [242, 249], [249, 250]]}
{"doc_key": "ai-dev-219", "ner": [[0, 0, "organisation"], [11, 13, "organisation"], [15, 20, "university"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 13, "role", "works_with", false, false], [0, 0, 15, 20, "role", "works_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Medtronic", "uses", "data", "collected", "by", "PM", "and", "collaborates", "with", "researchers", "at", "Johns", "Hopkins", "Hospital", "and", "Washington", "University", "School", "of", "Medicine", "to", "answer", "specific", "questions", "about", "heart", "disease", ",", "such", "as", "whether", "weak", "hearts", "cause", "arrhythmias", "or", "vice", "versa", "."], "sentence-detokenized": "Medtronic uses data collected by PM and collaborates with researchers at Johns Hopkins Hospital and Washington University School of Medicine to answer specific questions about heart disease, such as whether weak hearts cause arrhythmias or vice versa.", "token2charspan": [[0, 9], [10, 14], [15, 19], [20, 29], [30, 32], [33, 35], [36, 39], [40, 52], [53, 57], [58, 69], [70, 72], [73, 78], [79, 86], [87, 95], [96, 99], [100, 110], [111, 121], [122, 128], [129, 131], [132, 140], [141, 143], [144, 150], [151, 159], [160, 169], [170, 175], [176, 181], [182, 189], [189, 190], [191, 195], [196, 198], [199, 206], [207, 211], [212, 218], [219, 224], [225, 236], [237, 239], [240, 244], [245, 250], [250, 251]]}
{"doc_key": "ai-dev-220", "ner": [[0, 0, "organisation"], [5, 5, "misc"], [8, 9, "person"], [11, 12, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 0, 0, "artifact", "made_by_studio", false, false], [8, 9, 5, 5, "role", "", false, false], [11, 12, 5, 5, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Paramount", "'s", "first", "film", ",", "Sangaree", ",", "starring", "Fernando", "Lamas", "and", "Arlene", "Dahl", ",", "followed", "."], "sentence-detokenized": "Paramount's first film, Sangaree, starring Fernando Lamas and Arlene Dahl, followed.", "token2charspan": [[0, 9], [9, 11], [12, 17], [18, 22], [22, 23], [24, 32], [32, 33], [34, 42], [43, 51], [52, 57], [58, 61], [62, 68], [69, 73], [73, 74], [75, 83], [83, 84]]}
{"doc_key": "ai-dev-221", "ner": [[0, 0, "programlang"], [8, 10, "researcher"], [12, 14, "researcher"], [17, 18, "organisation"], [20, 21, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 8, 10, "origin", "", false, false], [0, 0, 12, 14, "origin", "", false, false], [8, 10, 17, 18, "physical", "", false, false], [8, 10, 17, 18, "role", "", false, false], [12, 14, 20, 21, "physical", "", false, false], [12, 14, 20, 21, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["KRL", "is", "a", "knowledge", "representation", "language", "developed", "by", "Daniel", "G.", "Bobrow", "and", "Terry", "Winograd", "while", "working", "at", "Xerox", "PARC", "and", "Stanford", "University", ",", "respectively", "."], "sentence-detokenized": "KRL is a knowledge representation language developed by Daniel G. Bobrow and Terry Winograd while working at Xerox PARC and Stanford University, respectively.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 18], [19, 33], [34, 42], [43, 52], [53, 55], [56, 62], [63, 65], [66, 72], [73, 76], [77, 82], [83, 91], [92, 97], [98, 105], [106, 108], [109, 114], [115, 119], [120, 123], [124, 132], [133, 143], [143, 144], [145, 157], [157, 158]]}
{"doc_key": "ai-dev-222", "ner": [[3, 10, "conference"], [12, 13, "researcher"], [15, 16, "researcher"], [18, 19, "researcher"], [22, 25, "researcher"], [33, 34, "task"], [36, 38, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[3, 10, 33, 34, "topic", "", true, false], [12, 13, 3, 10, "physical", "", false, false], [12, 13, 3, 10, "role", "", false, false], [12, 13, 3, 10, "temporal", "", false, false], [15, 16, 3, 10, "physical", "", false, false], [15, 16, 3, 10, "role", "", false, false], [15, 16, 3, 10, "temporal", "", false, false], [18, 19, 3, 10, "physical", "", false, false], [18, 19, 3, 10, "role", "", false, false], [18, 19, 3, 10, "temporal", "", false, false], [22, 25, 3, 10, "physical", "", false, false], [22, 25, 3, 10, "role", "", false, false], [22, 25, 3, 10, "temporal", "", false, false], [33, 34, 36, 38, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "sentence": ["At", "the", "2006", "IEEE", "Conference", "on", "Computer", "Vision", "and", "Pattern", "Recognition", ",", "Qiang", "Zhu", ",", "Shai", "Avidan", ",", "Mei-Chen", "Yeh", ",", "and", "Kwang", "-", "Ting", "Cheng", "presented", "an", "algorithm", "that", "enables", "significantly", "accelerated", "human", "detection", "using", "HOG", "descriptor", "methods", "."], "sentence-detokenized": "At the 2006 IEEE Conference on Computer Vision and Pattern Recognition, Qiang Zhu, Shai Avidan, Mei-Chen Yeh, and Kwang-Ting Cheng presented an algorithm that enables significantly accelerated human detection using HOG descriptor methods.", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 16], [17, 27], [28, 30], [31, 39], [40, 46], [47, 50], [51, 58], [59, 70], [70, 71], [72, 77], [78, 81], [81, 82], [83, 87], [88, 94], [94, 95], [96, 104], [105, 108], [108, 109], [110, 113], [114, 119], [119, 120], [120, 124], [125, 130], [131, 140], [141, 143], [144, 153], [154, 158], [159, 166], [167, 180], [181, 192], [193, 198], [199, 208], [209, 214], [215, 218], [219, 229], [230, 237], [237, 238]]}
{"doc_key": "ai-dev-223", "ner": [[0, 0, "researcher"], [6, 6, "conference"], [9, 11, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 6, 6, "role", "", false, false], [0, 0, 9, 11, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Hayes", "is", "a", "founding", "member", "of", "AAAI", "and", "the", "Cognitive", "Science", "Society", "."], "sentence-detokenized": "Hayes is a founding member of AAAI and the Cognitive Science Society.", "token2charspan": [[0, 5], [6, 8], [9, 10], [11, 19], [20, 26], [27, 29], [30, 34], [35, 38], [39, 42], [43, 52], [53, 60], [61, 68], [68, 69]]}
{"doc_key": "ai-dev-224", "ner": [[0, 3, "misc"], [5, 5, "field"], [7, 8, "field"], [10, 11, "field"], [13, 13, "field"], [15, 16, "field"], [18, 19, "field"], [21, 22, "field"], [24, 24, "field"], [26, 26, "field"], [29, 29, "field"], [31, 34, "field"], [40, 41, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "relations": [[0, 3, 5, 5, "part-of", "", false, false], [0, 3, 5, 5, "usage", "", false, false], [0, 3, 7, 8, "part-of", "", false, false], [0, 3, 7, 8, "usage", "", false, false], [0, 3, 10, 11, "part-of", "", false, false], [0, 3, 10, 11, "usage", "", false, false], [0, 3, 13, 13, "part-of", "", false, false], [0, 3, 13, 13, "usage", "", false, false], [0, 3, 15, 16, "part-of", "", false, false], [0, 3, 15, 16, "usage", "", false, false], [0, 3, 18, 19, "part-of", "", false, false], [0, 3, 18, 19, "usage", "", false, false], [0, 3, 21, 22, "part-of", "", false, false], [0, 3, 21, 22, "usage", "", false, false], [0, 3, 24, 24, "part-of", "", false, false], [0, 3, 24, 24, "usage", "", false, false], [0, 3, 26, 26, "part-of", "", false, false], [0, 3, 26, 26, "usage", "", false, false], [0, 3, 29, 29, "part-of", "", false, false], [0, 3, 29, 29, "usage", "", false, false], [0, 3, 31, 34, "part-of", "", false, false], [0, 3, 31, 34, "usage", "", false, false], [0, 3, 40, 41, "part-of", "", false, false], [0, 3, 40, 41, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "sentence": ["Time", "series", "are", "used", "in", "statistics", ",", "signal", "processing", ",", "pattern", "recognition", ",", "econometrics", ",", "mathematical", "finance", ",", "weather", "forecasting", ",", "earthquake", "prediction", ",", "electroencephalography", ",", "control", "engineering", ",", "astronomy", ",", "communications", "engineering", ",", "and", "generally", "in", "any", "field", "of", "applied", "science", "and", "engineering", "that", "involves", "time", "measurements", "."], "sentence-detokenized": "Time series are used in statistics, signal processing, pattern recognition, econometrics, mathematical finance, weather forecasting, earthquake prediction, electroencephalography, control engineering, astronomy, communications engineering, and generally in any field of applied science and engineering that involves time measurements.", "token2charspan": [[0, 4], [5, 11], [12, 15], [16, 20], [21, 23], [24, 34], [34, 35], [36, 42], [43, 53], [53, 54], [55, 62], [63, 74], [74, 75], [76, 88], [88, 89], [90, 102], [103, 110], [110, 111], [112, 119], [120, 131], [131, 132], [133, 143], [144, 154], [154, 155], [156, 178], [178, 179], [180, 187], [188, 199], [199, 200], [201, 210], [210, 211], [212, 226], [227, 238], [238, 239], [240, 243], [244, 253], [254, 256], [257, 260], [261, 266], [267, 269], [270, 277], [278, 285], [286, 289], [290, 301], [302, 306], [307, 315], [316, 320], [321, 333], [333, 334]]}
{"doc_key": "ai-dev-225", "ner": [[13, 14, "metrics"], [37, 39, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "principle", ",", "exact", "recovery", "can", "be", "solved", "in", "its", "feasible", "range", "using", "maximum", "likelihood", ",", "but", "this", "is", "equivalent", "to", "solving", "a", "constrained", "or", "regularized", "cutting", "problem", ",", "such", "as", "minimum", "bisection", ",", "which", "is", "usually", "NP", "-", "complete", "."], "sentence-detokenized": "In principle, exact recovery can be solved in its feasible range using maximum likelihood, but this is equivalent to solving a constrained or regularized cutting problem, such as minimum bisection, which is usually NP-complete.", "token2charspan": [[0, 2], [3, 12], [12, 13], [14, 19], [20, 28], [29, 32], [33, 35], [36, 42], [43, 45], [46, 49], [50, 58], [59, 64], [65, 70], [71, 78], [79, 89], [89, 90], [91, 94], [95, 99], [100, 102], [103, 113], [114, 116], [117, 124], [125, 126], [127, 138], [139, 141], [142, 153], [154, 161], [162, 169], [169, 170], [171, 175], [176, 178], [179, 186], [187, 196], [196, 197], [198, 203], [204, 206], [207, 214], [215, 217], [217, 218], [218, 226], [226, 227]]}
{"doc_key": "ai-dev-226", "ner": [[2, 3, "task"], [11, 11, "conference"]], "ner_mapping_to_source": [0, 1], "relations": [[11, 11, 2, 3, "topic", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["in", "their", "pedestrian", "detection", "work", ",", "which", "was", "first", "described", "at", "BMVC", "in", "2009", "."], "sentence-detokenized": "in their pedestrian detection work, which was first described at BMVC in 2009.", "token2charspan": [[0, 2], [3, 8], [9, 19], [20, 29], [30, 34], [34, 35], [36, 41], [42, 45], [46, 51], [52, 61], [62, 64], [65, 69], [70, 72], [73, 77], [77, 78]]}
{"doc_key": "ai-dev-227", "ner": [[5, 9, "conference"], [11, 11, "researcher"], [13, 21, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 11, 5, 9, "physical", "", false, false], [11, 11, 5, 9, "role", "", false, false], [11, 11, 13, 21, "win-defeat", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "2007", ",", "at", "the", "International", "Conference", "on", "Computer", "Vision", ",", "Terzopoulos", "received", "the", "inaugural", "IEEE", "PAMI", "Computer", "Vision", "Distinguished", "Researcher", "Award", "for", "pioneering", "and", "sustained", "research", "in", "the", "field", "of", "deformable", "models", "and", "their", "applications", "."], "sentence-detokenized": "In 2007, at the International Conference on Computer Vision, Terzopoulos received the inaugural IEEE PAMI Computer Vision Distinguished Researcher Award for pioneering and sustained research in the field of deformable models and their applications.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 29], [30, 40], [41, 43], [44, 52], [53, 59], [59, 60], [61, 72], [73, 81], [82, 85], [86, 95], [96, 100], [101, 105], [106, 114], [115, 121], [122, 135], [136, 146], [147, 152], [153, 156], [157, 167], [168, 171], [172, 181], [182, 190], [191, 193], [194, 197], [198, 203], [204, 206], [207, 217], [218, 224], [225, 228], [229, 234], [235, 247], [247, 248]]}
{"doc_key": "ai-dev-228", "ner": [[0, 0, "task"], [1, 4, "task"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 1, 4, "named", "same", false, false]], "relations_mapping_to_source": [0], "sentence": ["Cluster", "analysis", "or", "group", "analysis", "involves", "assigning", "data", "points", "to", "groups", "so", "that", "items", "in", "the", "same", "group", "are", "as", "similar", "as", "possible", ",", "while", "items", "belonging", "to", "different", "groups", "are", "as", "different", "as", "possible", "."], "sentence-detokenized": "Cluster analysis or group analysis involves assigning data points to groups so that items in the same group are as similar as possible, while items belonging to different groups are as different as possible.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 25], [26, 34], [35, 43], [44, 53], [54, 58], [59, 65], [66, 68], [69, 75], [76, 78], [79, 83], [84, 89], [90, 92], [93, 96], [97, 101], [102, 107], [108, 111], [112, 114], [115, 122], [123, 125], [126, 134], [134, 135], [136, 141], [142, 147], [148, 157], [158, 160], [161, 170], [171, 177], [178, 181], [182, 184], [185, 194], [195, 197], [198, 206], [206, 207]]}
{"doc_key": "ai-dev-229", "ner": [[11, 12, "field"], [18, 19, "task"], [21, 23, "field"], [25, 26, "field"], [28, 28, "field"], [31, 32, "field"], [35, 36, "task"], [38, 38, "misc"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6, 7, 8], "relations": [[18, 19, 11, 12, "part-of", "task_part_of_field", false, false], [25, 26, 21, 23, "part-of", "", false, false], [31, 32, 28, 28, "part-of", "", false, false], [35, 36, 31, 32, "part-of", "", false, false], [38, 38, 31, 32, "part-of", "", false, false]], "relations_mapping_to_source": [3, 4, 5, 6, 7], "sentence": ["(", "2005", ")", ",", "we", "can", "distinguish", "three", "different", "perspectives", "of", "text", "mining", ",", "namely", "text", "mining", "as", "information", "extraction", ",", "text", "mining", "as", "text", "data", "mining", "and", "text", "mining", "as", "data", "mining", "process", "(", "knowledge", "discovery", "in", "databases", ")", ".", "Hotho", ",", "A.", ",", "N\u00fcrnberger", ",", "A.", "and", "Paa\u00df", ",", "G.", "(", "2005", ")", "."], "sentence-detokenized": "(2005), we can distinguish three different perspectives of text mining, namely text mining as information extraction, text mining as text data mining and text mining as data mining process (knowledge discovery in databases).Hotho, A., N\u00fcrnberger, A. and Paa\u00df, G. (2005).", "token2charspan": [[0, 1], [1, 5], [5, 6], [6, 7], [8, 10], [11, 14], [15, 26], [27, 32], [33, 42], [43, 55], [56, 58], [59, 63], [64, 70], [70, 71], [72, 78], [79, 83], [84, 90], [91, 93], [94, 105], [106, 116], [116, 117], [118, 122], [123, 129], [130, 132], [133, 137], [138, 142], [143, 149], [150, 153], [154, 158], [159, 165], [166, 168], [169, 173], [174, 180], [181, 188], [189, 190], [190, 199], [200, 209], [210, 212], [213, 222], [222, 223], [223, 224], [224, 229], [229, 230], [231, 233], [233, 234], [235, 245], [245, 246], [247, 249], [250, 253], [254, 258], [258, 259], [260, 262], [263, 264], [264, 268], [268, 269], [269, 270]]}
{"doc_key": "ai-dev-230", "ner": [[0, 2, "product"], [15, 20, "location"], [22, 22, "location"], [24, 24, "location"], [34, 35, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 2, 15, 20, "related-to", "developed_for", false, false], [15, 20, 22, 22, "physical", "", false, false], [22, 22, 24, 24, "physical", "", false, false], [34, 35, 0, 2, "role", "buys", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "Rancho", "Arm", "was", "developed", "as", "a", "robotic", "arm", "to", "help", "disabled", "patients", "at", "the", "Rancho", "Los", "Amigos", "National", "Rehabilitation", "Center", "in", "Downey", ",", "California", ";", "this", "computer", "-", "controlled", "arm", "was", "purchased", "by", "Stanford", "University", "in", "1963", "."], "sentence-detokenized": "The Rancho Arm was developed as a robotic arm to help disabled patients at the Rancho Los Amigos National Rehabilitation Center in Downey, California; this computer-controlled arm was purchased by Stanford University in 1963.", "token2charspan": [[0, 3], [4, 10], [11, 14], [15, 18], [19, 28], [29, 31], [32, 33], [34, 41], [42, 45], [46, 48], [49, 53], [54, 62], [63, 71], [72, 74], [75, 78], [79, 85], [86, 89], [90, 96], [97, 105], [106, 120], [121, 127], [128, 130], [131, 137], [137, 138], [139, 149], [149, 150], [151, 155], [156, 164], [164, 165], [165, 175], [176, 179], [180, 183], [184, 193], [194, 196], [197, 205], [206, 216], [217, 219], [220, 224], [224, 225]]}
{"doc_key": "ai-dev-231", "ner": [[3, 3, "researcher"], [10, 13, "organisation"], [11, 23, "organisation"], [27, 28, "researcher"], [30, 32, "researcher"], [1, 45, "university"]], "ner_mapping_to_source": [1, 2, 3, 4, 5, 6], "relations": [[3, 3, 10, 13, "role", "founder", false, false], [3, 3, 11, 23, "role", "founder", false, false], [11, 23, 1, 45, "physical", "", false, false], [27, 28, 11, 23, "role", "founder", false, false], [30, 32, 11, 23, "role", "founder", false, false]], "relations_mapping_to_source": [2, 3, 4, 5, 6], "sentence": ["At", "UCSD", ",", "Norman", "was", "one", "of", "the", "founders", "of", "the", "Cognitive", "Science", "Institute", "and", "one", "of", "the", "organizers", "of", "the", "Cognitive", "Science", "Society", "(", "along", "with", "Roger", "Schank", ",", "Allan", "M.", "Collins", "and", "others", ")", ",", "which", "held", "it", "s", "first", "meeting", "on", "the", "UCSD", "campus", "in", "1979", "."], "sentence-detokenized": "At UCSD, Norman was one of the founders of the Cognitive Science Institute and one of the organizers of the Cognitive Science Society (along with Roger Schank, Allan M. Collins and others), which held its first meeting on the UCSD campus in 1979.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 19], [20, 23], [24, 26], [27, 30], [31, 39], [40, 42], [43, 46], [47, 56], [57, 64], [65, 74], [75, 78], [79, 82], [83, 85], [86, 89], [90, 100], [101, 103], [104, 107], [108, 117], [118, 125], [126, 133], [134, 135], [135, 140], [141, 145], [146, 151], [152, 158], [158, 159], [160, 165], [166, 168], [169, 176], [177, 180], [181, 187], [187, 188], [188, 189], [190, 195], [196, 200], [201, 203], [203, 204], [205, 210], [211, 218], [219, 221], [222, 225], [226, 230], [231, 237], [238, 240], [241, 245], [245, 246]]}
{"doc_key": "ai-dev-232", "ner": [[7, 7, "product"], [10, 10, "product"], [13, 13, "product"], [16, 17, "product"], [20, 20, "product"], [23, 27, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[20, 20, 16, 17, "type-of", "", false, false], [23, 27, 16, 17, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "most", "commonly", "used", "robot", "configurations", "are", "articulated", "robots", ",", "SCARA", "robots", ",", "delta", "robots", "and", "Cartesian", "coordinate", "robots", "(", "gantry", "robots", "or", "x", "-", "y", "-", "z", "robots", ")", "."], "sentence-detokenized": "The most commonly used robot configurations are articulated robots, SCARA robots, delta robots and Cartesian coordinate robots (gantry robots or x-y-z robots).", "token2charspan": [[0, 3], [4, 8], [9, 17], [18, 22], [23, 28], [29, 43], [44, 47], [48, 59], [60, 66], [66, 67], [68, 73], [74, 80], [80, 81], [82, 87], [88, 94], [95, 98], [99, 108], [109, 119], [120, 126], [127, 128], [128, 134], [135, 141], [142, 144], [145, 146], [146, 147], [147, 148], [148, 149], [149, 150], [151, 157], [157, 158], [158, 159]]}
{"doc_key": "ai-dev-233", "ner": [[9, 9, "programlang"], [10, 11, "misc"], [16, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[10, 11, 9, 9, "part-of", "", false, false], [16, 16, 10, 11, "related-to", "compatible_with", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Alternatively", ",", "it", "can", "be", "used", "directly", "with", "the", "Perl", "TM", "module", "(", "which", "also", "supports", "LTM", ")", "."], "sentence-detokenized": "Alternatively, it can be used directly with the Perl TM module (which also supports LTM).", "token2charspan": [[0, 13], [13, 14], [15, 17], [18, 21], [22, 24], [25, 29], [30, 38], [39, 43], [44, 47], [48, 52], [53, 55], [56, 62], [63, 64], [64, 69], [70, 74], [75, 83], [84, 87], [87, 88], [88, 89]]}
{"doc_key": "ai-dev-234", "ner": [[5, 5, "country"], [8, 11, "organisation"], [16, 16, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 11, 5, 5, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "was", "won", "by", "a", "US", "team", "from", "Newton", "Labs", "and", "the", "competition", "was", "broadcast", "on", "CNN", "."], "sentence-detokenized": "It was won by a US team from Newton Labs and the competition was broadcast on CNN.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 13], [14, 15], [16, 18], [19, 23], [24, 28], [29, 35], [36, 40], [41, 44], [45, 48], [49, 60], [61, 64], [65, 74], [75, 77], [78, 81], [81, 82]]}
{"doc_key": "ai-dev-235", "ner": [[0, 4, "misc"], [11, 13, "person"], [15, 16, "person"], [18, 19, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[11, 13, 0, 4, "role", "directs", false, false], [15, 16, 0, 4, "role", "acts_in", false, false], [18, 19, 0, 4, "role", "acts_in", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Butler", "'s", "in", "Love", ",", "a", "short", "film", "directed", "by", "David", "Arquette", "and", "starring", "Elizabeth", "Berkley", "and", "Thomas", "Jane", ",", "was", "released", "on", "23", "June", "2008", "."], "sentence-detokenized": "The Butler's in Love, a short film directed by David Arquette and starring Elizabeth Berkley and Thomas Jane, was released on 23 June 2008.", "token2charspan": [[0, 3], [4, 10], [10, 12], [13, 15], [16, 20], [20, 21], [22, 23], [24, 29], [30, 34], [35, 43], [44, 46], [47, 52], [53, 61], [62, 65], [66, 74], [75, 84], [85, 92], [93, 96], [97, 103], [104, 108], [108, 109], [110, 113], [114, 122], [123, 125], [126, 128], [129, 133], [134, 138], [138, 139]]}
{"doc_key": "ai-dev-236", "ner": [[3, 4, "product"], [11, 11, "field"], [18, 18, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 4, 18, 18, "general-affiliation", "", false, false], [11, 11, 3, 4, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["For", "example", ",", "Word", "Net", "is", "a", "resource", "that", "includes", "a", "taxonomy", "whose", "elements", "are", "the", "meanings", "of", "English", "words", "."], "sentence-detokenized": "For example, WordNet is a resource that includes a taxonomy whose elements are the meanings of English words.", "token2charspan": [[0, 3], [4, 11], [11, 12], [13, 17], [17, 20], [21, 23], [24, 25], [26, 34], [35, 39], [40, 48], [49, 50], [51, 59], [60, 65], [66, 74], [75, 78], [79, 82], [83, 91], [92, 94], [95, 102], [103, 108], [108, 109]]}
{"doc_key": "ai-dev-237", "ner": [[1, 3, "product"], [7, 7, "product"], [9, 9, "product"], [16, 16, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 7, 1, 3, "type-of", "", false, false], [7, 7, 16, 16, "related-to", "ability_to", false, false], [9, 9, 1, 3, "type-of", "", false, false], [9, 9, 16, 16, "related-to", "ability_to", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Existing", "humanoid", "robot", "systems", ",", "such", "as", "ASIMO", "and", "QRIO", ",", "use", "multiple", "motors", "to", "achieve", "locomotion", "."], "sentence-detokenized": "Existing humanoid robot systems, such as ASIMO and QRIO, use multiple motors to achieve locomotion.", "token2charspan": [[0, 8], [9, 17], [18, 23], [24, 31], [31, 32], [33, 37], [38, 40], [41, 46], [47, 50], [51, 55], [55, 56], [57, 60], [61, 69], [70, 76], [77, 79], [80, 87], [88, 98], [98, 99]]}
{"doc_key": "ai-dev-238", "ner": [[0, 0, "metrics"], [5, 6, "metrics"], [9, 9, "metrics"], [11, 15, "misc"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[5, 6, 0, 0, "part-of", "", false, false], [9, 9, 0, 0, "part-of", "", false, false], [11, 15, 0, 0, "part-of", "", false, false], [17, 17, 0, 0, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["LEPOR", "is", "designed", "with", "improved", "length", "penalty", "factors", ",", "precision", ",", "n-", "gram", "word", "order", "penalty", "and", "recall", "."], "sentence-detokenized": "LEPOR is designed with improved length penalty factors, precision, n-gram word order penalty and recall.", "token2charspan": [[0, 5], [6, 8], [9, 17], [18, 22], [23, 31], [32, 38], [39, 46], [47, 54], [54, 55], [56, 65], [65, 66], [67, 69], [69, 73], [74, 78], [79, 84], [85, 92], [93, 96], [97, 103], [103, 104]]}
{"doc_key": "ai-dev-239", "ner": [[0, 8, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "based", "on", "the", "bilingual", "student", "assessment", "metric", ",", "but", "with", "some", "modifications", "."], "sentence-detokenized": "It is based on the bilingual student assessment metric, but with some modifications.", "token2charspan": [[0, 2], [3, 5], [6, 11], [12, 14], [15, 18], [19, 28], [29, 36], [37, 47], [48, 54], [54, 55], [56, 59], [60, 64], [65, 69], [70, 83], [83, 84]]}
{"doc_key": "ai-dev-240", "ner": [[6, 6, "product"], [8, 8, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["This", "is", "an", "example", "implementation", "in", "MATLAB", "/", "Octave", ":"], "sentence-detokenized": "This is an example implementation in MATLAB / Octave:", "token2charspan": [[0, 4], [5, 7], [8, 10], [11, 18], [19, 33], [34, 36], [37, 43], [44, 45], [46, 52], [52, 53]]}
{"doc_key": "ai-dev-241", "ner": [[12, 12, "programlang"], [14, 14, "programlang"], [16, 16, "programlang"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "designed", "to", "be", "used", "with", "several", "computer", "languages", ",", "including", "Python", ",", "Ruby", "and", "Scheme", "."], "sentence-detokenized": "It is designed to be used with several computer languages, including Python, Ruby and Scheme.", "token2charspan": [[0, 2], [3, 5], [6, 14], [15, 17], [18, 20], [21, 25], [26, 30], [31, 38], [39, 47], [48, 57], [57, 58], [59, 68], [69, 75], [75, 76], [77, 81], [82, 85], [86, 92], [92, 93]]}
{"doc_key": "ai-dev-242", "ner": [[0, 0, "researcher"], [6, 6, "organisation"], [12, 12, "conference"], [17, 18, "academicjournal"], [23, 25, "organisation"], [31, 35, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 0, 6, 6, "role", "", false, false], [0, 0, 12, 12, "role", "", false, false], [0, 0, 17, 18, "role", "", false, false], [0, 0, 23, 25, "role", "", false, false], [0, 0, 31, 35, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Hayes", "has", "served", "as", "secretary", "of", "AISB", ",", "president", "and", "trustee", "of", "IJCAI", ",", "associate", "editor", "of", "Artificial", "Intelligence", ",", "governor", "of", "the", "Cognitive", "Science", "Society", ",", "and", "president", "of", "the", "American", "Association", "for", "Artificial", "Intelligence", "."], "sentence-detokenized": "Hayes has served as secretary of AISB, president and trustee of IJCAI, associate editor of Artificial Intelligence, governor of the Cognitive Science Society, and president of the American Association for Artificial Intelligence.", "token2charspan": [[0, 5], [6, 9], [10, 16], [17, 19], [20, 29], [30, 32], [33, 37], [37, 38], [39, 48], [49, 52], [53, 60], [61, 63], [64, 69], [69, 70], [71, 80], [81, 87], [88, 90], [91, 101], [102, 114], [114, 115], [116, 124], [125, 127], [128, 131], [132, 141], [142, 149], [150, 157], [157, 158], [159, 162], [163, 172], [173, 175], [176, 179], [180, 188], [189, 200], [201, 204], [205, 215], [216, 228], [228, 229]]}
{"doc_key": "ai-dev-243", "ner": [[4, 14, "misc"], [16, 18, "misc"], [23, 24, "person"], [29, 33, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[23, 24, 4, 14, "role", "directed_by", false, false], [23, 24, 16, 18, "role", "directed_by", false, false], [23, 24, 29, 33, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Two", "of", "them", ",", "Now", "is", "the", "Time", "(", "to", "Put", "On", "Your", "Glasses", ")", "and", "Around", "is", "Around", ",", "were", "directed", "by", "Norman", "McLaren", "in", "1951", "for", "the", "National", "Film", "Board", "of", "Canada", "."], "sentence-detokenized": "Two of them, Now is the Time (to Put On Your Glasses) and Around is Around, were directed by Norman McLaren in 1951 for the National Film Board of Canada.", "token2charspan": [[0, 3], [4, 6], [7, 11], [11, 12], [13, 16], [17, 19], [20, 23], [24, 28], [29, 30], [30, 32], [33, 36], [37, 39], [40, 44], [45, 52], [52, 53], [54, 57], [58, 64], [65, 67], [68, 74], [74, 75], [76, 80], [81, 89], [90, 92], [93, 99], [100, 107], [108, 110], [111, 115], [116, 119], [120, 123], [124, 132], [133, 137], [138, 143], [144, 146], [147, 153], [153, 154]]}
{"doc_key": "ai-dev-244", "ner": [[1, 2, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "recommender", "system", "aims", "to", "predict", "a", "target", "user", "'s", "preferences", "for", "an", "item", "."], "sentence-detokenized": "A recommender system aims to predict a target user's preferences for an item.", "token2charspan": [[0, 1], [2, 13], [14, 20], [21, 25], [26, 28], [29, 36], [37, 38], [39, 45], [46, 50], [50, 52], [53, 64], [65, 68], [69, 71], [72, 76], [76, 77]]}
{"doc_key": "ai-dev-245", "ner": [[0, 0, "algorithm"], [5, 5, "field"], [7, 7, "field"], [9, 10, "field"], [12, 13, "field"], [16, 16, "field"], [19, 20, "field"], [22, 22, "field"], [24, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[0, 0, 5, 5, "part-of", "", true, false], [0, 0, 7, 7, "part-of", "", true, false], [0, 0, 9, 10, "part-of", "", true, false], [0, 0, 12, 13, "part-of", "", true, false], [0, 0, 16, 16, "part-of", "", true, false], [0, 0, 19, 20, "part-of", "", true, false], [0, 0, 22, 22, "part-of", "", true, false], [0, 0, 24, 25, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["Convolution", "has", "applications", "that", "include", "probability", ",", "statistics", ",", "computer", "vision", ",", "natural", "language", "processing", ",", "image", "processing", "and", "signal", "processing", ",", "engineering", "and", "differential", "equations", "."], "sentence-detokenized": "Convolution has applications that include probability, statistics, computer vision, natural language processing, image processing and signal processing, engineering and differential equations.", "token2charspan": [[0, 11], [12, 15], [16, 28], [29, 33], [34, 41], [42, 53], [53, 54], [55, 65], [65, 66], [67, 75], [76, 82], [82, 83], [84, 91], [92, 100], [101, 111], [111, 112], [113, 118], [119, 129], [130, 133], [134, 140], [141, 151], [151, 152], [153, 164], [165, 168], [169, 181], [182, 191], [191, 192]]}
{"doc_key": "ai-dev-246", "ner": [[0, 0, "field"], [3, 4, "task"], [7, 7, "task"], [10, 10, "task"], [11, 11, "task"], [12, 12, "task"], [14, 15, "task"], [17, 18, "task"], [20, 21, "task"], [23, 23, "task"], [26, 27, "task"], [29, 29, "field"], [31, 31, "field"], [33, 35, "field"], [37, 37, "field"], [39, 39, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "relations": [[0, 0, 3, 4, "part-of", "", true, false], [0, 0, 7, 7, "part-of", "", true, false], [0, 0, 10, 10, "part-of", "", true, false], [0, 0, 11, 11, "part-of", "", true, false], [0, 0, 12, 12, "part-of", "", true, false], [0, 0, 14, 15, "part-of", "", true, false], [0, 0, 17, 18, "part-of", "", true, false], [0, 0, 20, 21, "part-of", "", true, false], [0, 0, 23, 23, "part-of", "", true, false], [0, 0, 26, 27, "part-of", "", true, false], [0, 0, 29, 29, "part-of", "", true, false], [0, 0, 31, 31, "part-of", "", true, false], [0, 0, 33, 35, "part-of", "", true, false], [0, 0, 37, 37, "part-of", "", true, false], [0, 0, 39, 39, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], "sentence": ["DSP", "applications", "include", "audio", "signal", "processing", ",", "audio", "compression", ",", "digital", "image", "processing", ",", "video", "compression", ",", "speech", "processing", ",", "speech", "recognition", ",", "digital", "communications", ",", "digital", "synthesizers", ",", "radar", ",", "sonar", ",", "financial", "signal", "processing", ",", "seismology", "and", "biomedicine", "."], "sentence-detokenized": "DSP applications include audio signal processing, audio compression, digital image processing, video compression, speech processing, speech recognition, digital communications, digital synthesizers, radar, sonar, financial signal processing, seismology and biomedicine.", "token2charspan": [[0, 3], [4, 16], [17, 24], [25, 30], [31, 37], [38, 48], [48, 49], [50, 55], [56, 67], [67, 68], [69, 76], [77, 82], [83, 93], [93, 94], [95, 100], [101, 112], [112, 113], [114, 120], [121, 131], [131, 132], [133, 139], [140, 151], [151, 152], [153, 160], [161, 175], [175, 176], [177, 184], [185, 197], [197, 198], [199, 204], [204, 205], [206, 211], [211, 212], [213, 222], [223, 229], [230, 240], [240, 241], [242, 252], [253, 256], [257, 268], [268, 269]]}
{"doc_key": "ai-dev-247", "ner": [[13, 14, "misc"], [20, 20, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["(", "February", "20", ",", "1912", "-", "August", "11", ",", "2011", ")", "was", "an", "American", "inventor", ",", "best", "known", "for", "creating", "Unimate", ",", "the", "first", "industrial", "robot", "."], "sentence-detokenized": "(February 20, 1912 - August 11, 2011) was an American inventor, best known for creating Unimate, the first industrial robot.", "token2charspan": [[0, 1], [1, 9], [10, 12], [12, 13], [14, 18], [19, 20], [21, 27], [28, 30], [30, 31], [32, 36], [36, 37], [38, 41], [42, 44], [45, 53], [54, 62], [62, 63], [64, 68], [69, 74], [75, 78], [79, 87], [88, 95], [95, 96], [97, 100], [101, 106], [107, 117], [118, 123], [123, 124]]}
{"doc_key": "ai-dev-248", "ner": [[2, 4, "researcher"], [6, 8, "researcher"], [10, 10, "researcher"], [21, 23, "algorithm"], [26, 28, "algorithm"], [34, 35, "task"], [30, 31, "algorithm"], [41, 42, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[2, 4, 21, 23, "related-to", "writes_about", true, false], [6, 8, 21, 23, "related-to", "writes_about", true, false], [10, 10, 21, 23, "related-to", "writes_about", true, false], [21, 23, 26, 28, "related-to", "", true, false], [34, 35, 30, 31, "related-to", "", true, false], [41, 42, 30, 31, "origin", "", false, true]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["Along", "with", "David", "E.", "Rumelhart", "and", "Ronald", "J.", "Williams", ",", "Hinton", "co-authored", "a", "highly", "cited", "paper", "published", "in", "1986", "that", "popularized", "the", "backpropagation", "algorithm", "for", "training", "multilayer", "neural", "networks", ",", "Alex", "Net", "'s", "Dramatic", "Image", "Recognition", "Repercussion", "designed", "by", "his", "student", "Alex", "Krizhevsky", "{{", "cite", "web"], "sentence-detokenized": "Along with David E. Rumelhart and Ronald J. Williams, Hinton co-authored a highly cited paper published in 1986 that popularized the backpropagation algorithm for training multilayer neural networks, AlexNet's Dramatic Image Recognition Repercussion designed by his student Alex Krizhevsky {{cite web", "token2charspan": [[0, 5], [6, 10], [11, 16], [17, 19], [20, 29], [30, 33], [34, 40], [41, 43], [44, 52], [52, 53], [54, 60], [61, 72], [73, 74], [75, 81], [82, 87], [88, 93], [94, 103], [104, 106], [107, 111], [112, 116], [117, 128], [129, 132], [133, 148], [149, 158], [159, 162], [163, 171], [172, 182], [183, 189], [190, 198], [198, 199], [200, 204], [204, 207], [207, 209], [210, 218], [219, 224], [225, 236], [237, 249], [250, 258], [259, 261], [262, 265], [266, 273], [274, 278], [279, 289], [290, 292], [292, 296], [297, 300]]}
{"doc_key": "ai-dev-249", "ner": [[9, 9, "metrics"], [10, 15, "metrics"], [17, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "the", "predicted", "value", "is", "continuously", "distributed", ",", "the", "mean", "squared", "error", ",", "mean", "squared", "error", "or", "median", "absolute", "deviation", "can", "be", "used", "to", "summarize", "the", "errors", "."], "sentence-detokenized": "If the predicted value is continuously distributed, the mean squared error, mean squared error or median absolute deviation can be used to summarize the errors.", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 22], [23, 25], [26, 38], [39, 50], [50, 51], [52, 55], [56, 60], [61, 68], [69, 74], [74, 75], [76, 80], [81, 88], [89, 94], [95, 97], [98, 104], [105, 113], [114, 123], [124, 127], [128, 130], [131, 135], [136, 138], [139, 148], [149, 152], [153, 159], [159, 160]]}
{"doc_key": "ai-dev-250", "ner": [[0, 1, "algorithm"], [9, 9, "field"], [10, 14, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 9, 9, "part-of", "", true, false], [0, 1, 10, 14, "part-of", "", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Conceptual", "clustering", "developed", "mainly", "in", "the", "1980s", "as", "a", "machine", "learning", "paradigm", "for", "unsupervised", "learning", "."], "sentence-detokenized": "Conceptual clustering developed mainly in the 1980s as a machine learning paradigm for unsupervised learning.", "token2charspan": [[0, 10], [11, 21], [22, 31], [32, 38], [39, 41], [42, 45], [46, 51], [52, 54], [55, 56], [57, 64], [65, 73], [74, 82], [83, 86], [87, 99], [100, 108], [108, 109]]}
{"doc_key": "ai-dev-251", "ner": [[9, 10, "product"], [27, 29, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["If", "named", "entities", "can", "not", "be", "recognized", "by", "the", "machine", "translator", ",", "they", "may", "be", "mistranslated", "as", "common", "nouns", ",", "which", "would", "most", "likely", "not", "affect", "the", "bilingual", "evaluation", "surrogate", "rating", "of", "the", "translation", ",", "but", "would", "change", "the", "readability", "of", "the", "text", "for", "people", "."], "sentence-detokenized": "If named entities cannot be recognized by the machine translator, they may be mistranslated as common nouns, which would most likely not affect the bilingual evaluation surrogate rating of the translation, but would change the readability of the text for people.", "token2charspan": [[0, 2], [3, 8], [9, 17], [18, 21], [21, 24], [25, 27], [28, 38], [39, 41], [42, 45], [46, 53], [54, 64], [64, 65], [66, 70], [71, 74], [75, 77], [78, 91], [92, 94], [95, 101], [102, 107], [107, 108], [109, 114], [115, 120], [121, 125], [126, 132], [133, 136], [137, 143], [144, 147], [148, 157], [158, 168], [169, 178], [179, 185], [186, 188], [189, 192], [193, 204], [204, 205], [206, 209], [210, 215], [216, 222], [223, 226], [227, 238], [239, 241], [242, 245], [246, 250], [251, 254], [255, 261], [261, 262]]}
{"doc_key": "ai-dev-252", "ner": [[0, 1, "researcher"], [10, 11, "misc"], [12, 18, "conference"], [20, 22, "location"], [24, 24, "country"], [38, 39, "researcher"], [45, 45, "researcher"], [49, 50, "university"], [54, 55, "researcher"], [57, 58, "researcher"], [60, 61, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "relations": [[0, 1, 10, 11, "related-to", "writes_about", false, false], [0, 1, 12, 18, "temporal", "", true, false], [12, 18, 20, 22, "physical", "", false, false], [20, 22, 24, 24, "physical", "", false, false], [45, 45, 49, 50, "physical", "", false, false], [45, 45, 49, 50, "role", "", false, false], [54, 55, 49, 50, "physical", "", false, false], [54, 55, 49, 50, "role", "", false, false], [57, 58, 49, 50, "physical", "", false, false], [57, 58, 49, 50, "role", "", false, false], [60, 61, 49, 50, "physical", "", false, false], [60, 61, 49, 50, "role", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Roger", "Schank", ",", "1969", ",", "A", "conceptual", "dependency", "parser", "for", "natural", "language", "Proceedings", "of", "the", "1969", "on", "Computational", "linguistics", ",", "S\u00e5ng", "-", "S\u00e4by", ",", "Sweden", ",", "pages", "1-", "3", "This", "model", ",", "partly", "influenced", "by", "the", "work", "of", "Sydney", "Lamb", ",", "was", "widely", "used", "by", "Schank", "'s", "students", "at", "Yale", "University", ",", "such", "as", "Robert", "Wilensky", ",", "Wendy", "Lehnert", "and", "Janet", "Kolodner", "."], "sentence-detokenized": "Roger Schank, 1969, A conceptual dependency parser for natural language Proceedings of the 1969 on Computational linguistics, S\u00e5ng-S\u00e4by, Sweden, pages 1-3 This model, partly influenced by the work of Sydney Lamb, was widely used by Schank's students at Yale University, such as Robert Wilensky, Wendy Lehnert and Janet Kolodner.", "token2charspan": [[0, 5], [6, 12], [12, 13], [14, 18], [18, 19], [20, 21], [22, 32], [33, 43], [44, 50], [51, 54], [55, 62], [63, 71], [72, 83], [84, 86], [87, 90], [91, 95], [96, 98], [99, 112], [113, 124], [124, 125], [126, 130], [130, 131], [131, 135], [135, 136], [137, 143], [143, 144], [145, 150], [151, 153], [153, 154], [155, 159], [160, 165], [165, 166], [167, 173], [174, 184], [185, 187], [188, 191], [192, 196], [197, 199], [200, 206], [207, 211], [211, 212], [213, 216], [217, 223], [224, 228], [229, 231], [232, 238], [238, 240], [241, 249], [250, 252], [253, 257], [258, 268], [268, 269], [270, 274], [275, 277], [278, 284], [285, 293], [293, 294], [295, 300], [301, 308], [309, 312], [313, 318], [319, 327], [327, 328]]}
{"doc_key": "ai-dev-253", "ner": [[2, 4, "algorithm"], [6, 6, "algorithm"], [13, 13, "algorithm"], [3, 18, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[6, 6, 2, 4, "named", "", false, false], [13, 13, 2, 4, "named", "", false, false], [3, 18, 2, 4, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Improved", "Maximum", "Likelihood", "Method", "(", "IMLM", ")", "is", "a", "combination", "of", "two", "MLM", "(", "maximum", "likelihood", ")", "estimators", "."], "sentence-detokenized": "The Improved Maximum Likelihood Method (IMLM) is a combination of two MLM (maximum likelihood) estimators.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 31], [32, 38], [39, 40], [40, 44], [44, 45], [46, 48], [49, 50], [51, 62], [63, 65], [66, 69], [70, 73], [74, 75], [75, 82], [83, 93], [93, 94], [95, 105], [105, 106]]}
{"doc_key": "ai-dev-254", "ner": [[19, 21, "metrics"], [24, 25, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[24, 25, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["These", "methods", "may", "also", "analyse", "the", "output", "of", "a", "program", "and", "its", "usefulness", "and", "therefore", "may", "involve", "analysis", "of", "the", "confusion", "matrix", "(", "or", "confusion", "table", ")", "."], "sentence-detokenized": "These methods may also analyse the output of a program and its usefulness and therefore may involve analysis of the confusion matrix (or confusion table).", "token2charspan": [[0, 5], [6, 13], [14, 17], [18, 22], [23, 30], [31, 34], [35, 41], [42, 44], [45, 46], [47, 54], [55, 58], [59, 62], [63, 73], [74, 77], [78, 87], [88, 91], [92, 99], [100, 108], [109, 111], [112, 115], [116, 125], [126, 132], [133, 134], [134, 136], [137, 146], [147, 152], [152, 153], [153, 154]]}
{"doc_key": "ai-dev-255", "ner": [[0, 0, "product"], [5, 6, "researcher"], [8, 9, "researcher"], [11, 15, "researcher"], [19, 24, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 6, "origin", "", false, false], [0, 0, 8, 9, "origin", "", false, false], [0, 0, 11, 15, "origin", "", false, false], [0, 0, 19, 24, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["SURF", "was", "first", "published", "by", "Herbert", "Bay", ",", "Tinne", "Tuytelaars", "and", "Luc", "Van", "Gool", "and", "was", "presented", "at", "the", "European", "Computer", "Vision", "Conference", "in", "2006", "."], "sentence-detokenized": "SURF was first published by Herbert Bay, Tinne Tuytelaars and Luc Van Gool and was presented at the European Computer Vision Conference in 2006.", "token2charspan": [[0, 4], [5, 8], [9, 14], [15, 24], [25, 27], [28, 35], [36, 39], [39, 40], [41, 46], [47, 57], [58, 61], [62, 65], [66, 69], [70, 74], [75, 78], [79, 82], [83, 92], [93, 95], [96, 99], [100, 108], [109, 117], [118, 124], [125, 135], [136, 138], [139, 143], [143, 144]]}
{"doc_key": "ai-dev-256", "ner": [[0, 0, "task"], [7, 8, "field"], [10, 11, "field"], [13, 14, "field"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 0, 7, 8, "part-of", "", false, false], [0, 0, 10, 11, "part-of", "", false, false], [0, 0, 13, 14, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["OCR", "is", "a", "field", "of", "research", "in", "pattern", "recognition", ",", "artificial", "intelligence", "and", "computer", "vision", "."], "sentence-detokenized": "OCR is a field of research in pattern recognition, artificial intelligence and computer vision.", "token2charspan": [[0, 3], [4, 6], [7, 8], [9, 14], [15, 17], [18, 26], [27, 29], [30, 37], [38, 49], [49, 50], [51, 61], [62, 74], [75, 78], [79, 87], [88, 94], [94, 95]]}
{"doc_key": "ai-dev-257", "ner": [[5, 7, "metrics"], [10, 12, "algorithm"], [14, 14, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[14, 14, 10, 12, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Continuing", "the", "example", "using", "the", "maximum", "likelihood", "estimator", ",", "the", "probability", "density", "function", "(", "pdf", ")", "of", "the", "noise", "for", "a", "mathwn", "/", "math", "sample", "is"], "sentence-detokenized": "Continuing the example using the maximum likelihood estimator, the probability density function (pdf) of the noise for a mathwn/math sample is", "token2charspan": [[0, 10], [11, 14], [15, 22], [23, 28], [29, 32], [33, 40], [41, 51], [52, 61], [61, 62], [63, 66], [67, 78], [79, 86], [87, 95], [96, 97], [97, 100], [100, 101], [102, 104], [105, 108], [109, 114], [115, 118], [119, 120], [121, 127], [127, 128], [128, 132], [133, 139], [140, 142]]}
{"doc_key": "ai-dev-258", "ner": [[2, 3, "field"], [5, 6, "task"], [8, 9, "task"], [11, 12, "task"], [14, 15, "task"], [17, 18, "task"], [21, 21, "task"], [23, 23, "task"], [25, 26, "task"], [28, 29, "task"], [31, 33, "task"], [35, 36, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[5, 6, 2, 3, "part-of", "", false, false], [8, 9, 2, 3, "part-of", "", false, false], [11, 12, 2, 3, "part-of", "", false, false], [14, 15, 2, 3, "part-of", "", false, false], [17, 18, 2, 3, "part-of", "", false, false], [21, 21, 2, 3, "part-of", "", false, false], [23, 23, 2, 3, "part-of", "", false, false], [25, 26, 2, 3, "part-of", "", false, false], [28, 29, 2, 3, "part-of", "", false, false], [31, 33, 2, 3, "part-of", "", false, false], [35, 36, 2, 3, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Subdomains", "of", "computer", "vision", "include", "scene", "reconstruction", ",", "event", "detection", ",", "video", "tracking", ",", "object", "recognition", ",", "3D", "position", "estimation", ",", "learning", ",", "indexing", ",", "motion", "estimation", ",", "visual", "servoing", ",", "3D", "scene", "modelling", "and", "image", "restoration", "."], "sentence-detokenized": "Subdomains of computer vision include scene reconstruction, event detection, video tracking, object recognition, 3D position estimation, learning, indexing, motion estimation, visual servoing, 3D scene modelling and image restoration.", "token2charspan": [[0, 10], [11, 13], [14, 22], [23, 29], [30, 37], [38, 43], [44, 58], [58, 59], [60, 65], [66, 75], [75, 76], [77, 82], [83, 91], [91, 92], [93, 99], [100, 111], [111, 112], [113, 115], [116, 124], [125, 135], [135, 136], [137, 145], [145, 146], [147, 155], [155, 156], [157, 163], [164, 174], [174, 175], [176, 182], [183, 191], [191, 192], [193, 195], [196, 201], [202, 211], [212, 215], [216, 221], [222, 233], [233, 234]]}
{"doc_key": "ai-dev-259", "ner": [[5, 9, "conference"], [11, 11, "researcher"], [13, 15, "misc"], [18, 18, "conference"], [21, 21, "researcher"], [23, 23, "researcher"], [25, 27, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[5, 9, 18, 18, "named", "", false, false], [11, 11, 13, 15, "win-defeat", "", false, false], [11, 11, 25, 27, "related-to", "writes_about", true, false], [13, 15, 5, 9, "temporal", "", false, false], [21, 21, 13, 15, "win-defeat", "", false, true], [21, 21, 25, 27, "related-to", "writes_about", true, false], [23, 23, 13, 15, "win-defeat", "", false, true], [23, 23, 25, 27, "related-to", "writes_about", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "sentence": ["In", "2013", ",", "at", "the", "International", "Conference", "on", "Computer", "Vision", ",", "Terzopoulos", "received", "the", "Helmholtz", "Prize", "for", "his", "1987", "paper", "with", "Kass", "and", "Witkin", "on", "active", "contour", "models", "."], "sentence-detokenized": "In 2013, at the International Conference on Computer Vision, Terzopoulos received the Helmholtz Prize for his 1987 paper with Kass and Witkin on active contour models.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 11], [12, 15], [16, 29], [30, 40], [41, 43], [44, 52], [53, 59], [59, 60], [61, 72], [73, 81], [82, 85], [86, 95], [96, 101], [102, 105], [106, 109], [110, 114], [115, 120], [121, 125], [126, 130], [131, 134], [135, 141], [142, 144], [145, 151], [152, 159], [160, 166], [166, 167]]}
{"doc_key": "ai-dev-260", "ner": [[18, 19, "task"], [21, 23, "algorithm"], [25, 26, "algorithm"], [28, 30, "algorithm"], [32, 33, "algorithm"], [35, 36, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[18, 19, 21, 23, "usage", "", true, false], [18, 19, 25, 26, "usage", "", true, false], [18, 19, 28, 30, "usage", "", true, false], [18, 19, 32, 33, "usage", "", true, false], [18, 19, 35, 36, "usage", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["If", "the", "regularization", "function", "There", "are", "many", "algorithms", "for", "solving", "such", "problems", ";", "among", "the", "best", "known", "for", "linear", "classification", "are", "Stochastic", "gradient", "descent", ")", "gradient", "descent", ",", "L", "-", "BFGS", ",", "coordinate", "descent", "and", "Newton", "methods", "."], "sentence-detokenized": "If the regularization function There are many algorithms for solving such problems; among the best known for linear classification are Stochastic gradient descent) gradient descent, L-BFGS, coordinate descent and Newton methods.", "token2charspan": [[0, 2], [3, 6], [7, 21], [22, 30], [31, 36], [37, 40], [41, 45], [46, 56], [57, 60], [61, 68], [69, 73], [74, 82], [82, 83], [84, 89], [90, 93], [94, 98], [99, 104], [105, 108], [109, 115], [116, 130], [131, 134], [135, 145], [146, 154], [155, 162], [162, 163], [164, 172], [173, 180], [180, 181], [182, 183], [183, 184], [184, 188], [188, 189], [190, 200], [201, 208], [209, 212], [213, 219], [220, 227], [227, 228]]}
{"doc_key": "ai-dev-261", "ner": [[0, 2, "algorithm"], [5, 5, "algorithm"], [10, 11, "researcher"], [13, 14, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 2, 10, 11, "origin", "", false, false], [5, 5, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Short", "Term", "Memory", "Lattices", "(", "LSTM", ")", "were", "invented", "by", "Sepp", "Hochreiter", "and", "J\u00fcrgen", "Schmidhuber", "in", "1997", "and", "have", "set", "accuracy", "records", "in", "several", "application", "areas", "."], "sentence-detokenized": "Short Term Memory Lattices (LSTM) were invented by Sepp Hochreiter and J\u00fcrgen Schmidhuber in 1997 and have set accuracy records in several application areas.", "token2charspan": [[0, 5], [6, 10], [11, 17], [18, 26], [27, 28], [28, 32], [32, 33], [34, 38], [39, 47], [48, 50], [51, 55], [56, 66], [67, 70], [71, 77], [78, 89], [90, 92], [93, 97], [98, 101], [102, 106], [107, 110], [111, 119], [120, 127], [128, 130], [131, 138], [139, 150], [151, 156], [156, 157]]}
{"doc_key": "ai-dev-262", "ner": [[0, 1, "product"], [4, 6, "organisation"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 4, 6, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["TN", "was", "developed", "at", "Massachusetts", "General", "Hospital", "and", "has", "been", "tested", "in", "several", "scenarios", ",", "including", "extraction", "of", "smoking", "status", ",", "family", "history", "of", "coronary", "artery", "disease", ",", "identification", "of", "patients", "with", "sleep", "disorders", ","], "sentence-detokenized": "TN was developed at Massachusetts General Hospital and has been tested in several scenarios, including extraction of smoking status, family history of coronary artery disease, identification of patients with sleep disorders,", "token2charspan": [[0, 2], [3, 6], [7, 16], [17, 19], [20, 33], [34, 41], [42, 50], [51, 54], [55, 58], [59, 63], [64, 70], [71, 73], [74, 81], [82, 91], [91, 92], [93, 102], [103, 113], [114, 116], [117, 124], [125, 131], [131, 132], [133, 139], [140, 147], [148, 150], [151, 159], [160, 166], [167, 174], [174, 175], [176, 190], [191, 193], [194, 202], [203, 207], [208, 213], [214, 223], [223, 224]]}
{"doc_key": "ai-dev-263", "ner": [[3, 3, "researcher"], [8, 9, "product"], [17, 18, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 8, 9, "role", "sells", false, false], [8, 9, 17, 18, "physical", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "1960", ",", "Devol", "personally", "sold", "the", "first", "Unimate", "robot", ",", "which", "was", "delivered", "in", "1961", "to", "General", "Motors", "."], "sentence-detokenized": "In 1960, Devol personally sold the first Unimate robot, which was delivered in 1961 to General Motors.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 14], [15, 25], [26, 30], [31, 34], [35, 40], [41, 48], [49, 54], [54, 55], [56, 61], [62, 65], [66, 75], [76, 78], [79, 83], [84, 86], [87, 94], [95, 101], [101, 102]]}
{"doc_key": "ai-dev-264", "ner": [[0, 3, "conference"], [13, 14, "location"], [16, 16, "location"], [18, 18, "country"], [31, 31, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 3, 13, 14, "physical", "", false, false], [13, 14, 16, 16, "physical", "", false, false], [16, 16, 18, 18, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["Campus", "Party", "Europe", "took", "place", "on", "14", "-", "18", "April", "2010", "at", "the", "Caja", "M\u00e1gica", "in", "Madrid", ",", "Spain", ",", "with", "800", "participants", "from", "each", "of", "the", "27", "EU", "Member", "States", "."], "sentence-detokenized": "Campus Party Europe took place on 14-18 April 2010 at the Caja M\u00e1gica in Madrid, Spain, with 800 participants from each of the 27 EU Member States.", "token2charspan": [[0, 6], [7, 12], [13, 19], [20, 24], [25, 30], [31, 33], [34, 36], [36, 37], [37, 39], [40, 45], [46, 50], [51, 53], [54, 57], [58, 62], [63, 69], [70, 72], [73, 79], [79, 80], [81, 86], [86, 87], [88, 92], [93, 96], [97, 109], [110, 114], [115, 119], [120, 122], [123, 126], [127, 129], [130, 132], [133, 139], [140, 146], [146, 147]]}
{"doc_key": "ai-dev-265", "ner": [[9, 9, "organisation"], [11, 13, "organisation"], [16, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[16, 20, 9, 9, "origin", "", false, false], [16, 20, 11, 13, "origin", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "July", "2016", ",", "a", "collaboration", "was", "announced", "between", "DeepMind", "and", "Moorfields", "Eye", "Hospital", "to", "develop", "artificial", "intelligence", "applications", "for", "healthcare", "."], "sentence-detokenized": "In July 2016, a collaboration was announced between DeepMind and Moorfields Eye Hospital to develop artificial intelligence applications for healthcare.", "token2charspan": [[0, 2], [3, 7], [8, 12], [12, 13], [14, 15], [16, 29], [30, 33], [34, 43], [44, 51], [52, 60], [61, 64], [65, 75], [76, 79], [80, 88], [89, 91], [92, 99], [100, 110], [111, 123], [124, 136], [137, 140], [141, 151], [151, 152]]}
{"doc_key": "ai-dev-266", "ner": [[3, 3, "misc"], [12, 14, "university"], [16, 16, "university"], [18, 19, "university"], [21, 22, "university"], [24, 24, "university"], [26, 26, "university"], [28, 31, "university"], [33, 34, "university"], [36, 37, "university"], [39, 39, "university"], [42, 44, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[3, 3, 12, 14, "physical", "", false, false], [3, 3, 16, 16, "physical", "", false, false], [3, 3, 18, 19, "physical", "", false, false], [3, 3, 21, 22, "physical", "", false, false], [3, 3, 24, 24, "physical", "", false, false], [3, 3, 26, 26, "physical", "", false, false], [3, 3, 28, 31, "physical", "", false, false], [3, 3, 33, 34, "physical", "", false, false], [3, 3, 36, 37, "physical", "", false, false], [3, 3, 39, 39, "physical", "", false, false], [3, 3, 42, 44, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], "sentence": ["Finally", ",", "eleven", "PR2s", "were", "awarded", "to", "different", "institutions", ",", "including", "the", "University", "of", "Freiburg", ",", "Bosch", ",", "Georgia", "Tech", ",", "KU", "Leuven", ",", "MIT", ",", "Stanford", ",", "Technical", "University", "of", "Munich", ",", "UC", "Berkeley", ",", "U", "Penn", ",", "USC", "and", "the", "University", "of", "Tokyo", "."], "sentence-detokenized": "Finally, eleven PR2s were awarded to different institutions, including the University of Freiburg, Bosch, Georgia Tech, KU Leuven, MIT, Stanford, Technical University of Munich, UC Berkeley, U Penn, USC and the University of Tokyo.", "token2charspan": [[0, 7], [7, 8], [9, 15], [16, 20], [21, 25], [26, 33], [34, 36], [37, 46], [47, 59], [59, 60], [61, 70], [71, 74], [75, 85], [86, 88], [89, 97], [97, 98], [99, 104], [104, 105], [106, 113], [114, 118], [118, 119], [120, 122], [123, 129], [129, 130], [131, 134], [134, 135], [136, 144], [144, 145], [146, 155], [156, 166], [167, 169], [170, 176], [176, 177], [178, 180], [181, 189], [189, 190], [191, 192], [193, 197], [197, 198], [199, 202], [203, 206], [207, 210], [211, 221], [222, 224], [225, 230], [230, 231]]}
{"doc_key": "ai-dev-267", "ner": [[1, 1, "metrics"], [3, 3, "metrics"], [5, 5, "metrics"], [7, 7, "metrics"], [18, 19, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[1, 1, 18, 19, "part-of", "", false, false], [3, 3, 18, 19, "part-of", "", false, false], [5, 5, 18, 19, "part-of", "", false, false], [7, 7, 18, 19, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["The", "TP", ",", "TN", ",", "FP", "and", "FN", "counts", "are", "usually", "kept", "in", "a", "table", "known", "as", "a", "confusion", "matrix", "."], "sentence-detokenized": "The TP, TN, FP and FN counts are usually kept in a table known as a confusion matrix.", "token2charspan": [[0, 3], [4, 6], [6, 7], [8, 10], [10, 11], [12, 14], [15, 18], [19, 21], [22, 28], [29, 32], [33, 40], [41, 45], [46, 48], [49, 50], [51, 56], [57, 62], [63, 65], [66, 67], [68, 77], [78, 84], [84, 85]]}
{"doc_key": "ai-dev-268", "ner": [[6, 7, "metrics"], [9, 10, "metrics"], [12, 13, "metrics"], [15, 16, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["As", "a", "set", "of", "features", ",", "information", "gain", ",", "cross", "-entropy", ",", "mutual", "information", "and", "odds", "ratio", "are", "usually", "used", "."], "sentence-detokenized": "As a set of features, information gain, cross-entropy, mutual information and odds ratio are usually used.", "token2charspan": [[0, 2], [3, 4], [5, 8], [9, 11], [12, 20], [20, 21], [22, 33], [34, 38], [38, 39], [40, 45], [45, 53], [53, 54], [55, 61], [62, 73], [74, 77], [78, 82], [83, 88], [89, 92], [93, 100], [101, 105], [105, 106]]}
{"doc_key": "ai-dev-269", "ner": [[9, 10, "task"], [12, 13, "task"], [15, 15, "task"], [17, 17, "task"], [19, 19, "task"], [21, 21, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[21, 21, 19, 19, "named", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["It", "has", "been", "successfully", "applied", "to", "various", "problems", "including", "robot", "control", ",", "elevator", "programming", ",", "telecommunications", ",", "checkers", "and", "Go", "(", "AlphaGo", ")", "."], "sentence-detokenized": "It has been successfully applied to various problems including robot control, elevator programming, telecommunications, checkers and Go (AlphaGo).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 24], [25, 32], [33, 35], [36, 43], [44, 52], [53, 62], [63, 68], [69, 76], [76, 77], [78, 86], [87, 98], [98, 99], [100, 118], [118, 119], [120, 128], [129, 132], [133, 135], [136, 137], [137, 144], [144, 145], [145, 146]]}
{"doc_key": "ai-dev-270", "ner": [[11, 15, "misc"], [19, 23, "university"], [25, 25, "location"], [27, 27, "location"], [12, 35, "location"], [40, 42, "location"], [44, 44, "location"], [46, 46, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [[11, 15, 19, 23, "physical", "", false, false], [19, 23, 25, 25, "physical", "", false, false], [25, 25, 27, 27, "physical", "", false, false], [12, 35, 40, 42, "physical", "", false, false], [40, 42, 44, 44, "physical", "", false, false], [44, 44, 46, 46, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["In", "2018", ",", "the", "inaugural", "year", "of", "Mission", "8", ",", "the", "U.S.", "venue", "was", "held", "on", "the", "campus", "of", "the", "Georgia", "Institute", "of", "Technology", "in", "Atlanta", ",", "Georgia", ",", "and", "the", "Asia", "/", "Pacific", "venue", "was", "held", "in", "the", "gymnasium", "of", "Beihang", "University", "in", "Beijing", ",", "China", "."], "sentence-detokenized": "In 2018, the inaugural year of Mission 8, the U.S. venue was held on the campus of the Georgia Institute of Technology in Atlanta, Georgia, and the Asia/Pacific venue was held in the gymnasium of Beihang University in Beijing, China.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 22], [23, 27], [28, 30], [31, 38], [39, 40], [40, 41], [42, 45], [46, 50], [51, 56], [57, 60], [61, 65], [66, 68], [69, 72], [73, 79], [80, 82], [83, 86], [87, 94], [95, 104], [105, 107], [108, 118], [119, 121], [122, 129], [129, 130], [131, 138], [138, 139], [140, 143], [144, 147], [148, 152], [152, 153], [153, 160], [161, 166], [167, 170], [171, 175], [176, 178], [179, 182], [183, 192], [193, 195], [196, 203], [204, 214], [215, 217], [218, 225], [225, 226], [227, 232], [232, 233]]}
{"doc_key": "ai-dev-271", "ner": [[0, 1, "field"], [6, 7, "field"], [11, 12, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 1, 6, 7, "origin", "", false, false], [0, 1, 6, 7, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Machine", "learning", "is", "closely", "related", "to", "pattern", "recognition", "and", "comes", "from", "artificial", "intelligence", "."], "sentence-detokenized": "Machine learning is closely related to pattern recognition and comes from artificial intelligence.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 27], [28, 35], [36, 38], [39, 46], [47, 58], [59, 62], [63, 68], [69, 73], [74, 84], [85, 97], [97, 98]]}
{"doc_key": "ai-dev-272", "ner": [[4, 4, "programlang"], [16, 17, "product"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "comes", "with", "3", "Java", "games", "that", "are", "controlled", "by", "remote", "control", "and", "displayed", "on", "the", "LCD", "screen", "."], "sentence-detokenized": "It comes with 3 Java games that are controlled by remote control and displayed on the LCD screen.", "token2charspan": [[0, 2], [3, 8], [9, 13], [14, 15], [16, 20], [21, 26], [27, 31], [32, 35], [36, 46], [47, 49], [50, 56], [57, 64], [65, 68], [69, 78], [79, 81], [82, 85], [86, 89], [90, 96], [96, 97]]}
{"doc_key": "ai-dev-273", "ner": [[1, 15, "task"], [17, 19, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[17, 19, 1, 15, "type-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "computer", "vision", "-", "based", "but", "specialised", "and", "commercially", "successful", "technique", "for", "estimating", "articulated", "body", "position", "is", "optical", "motion", "capture", "."], "sentence-detokenized": "A computer vision-based but specialised and commercially successful technique for estimating articulated body position is optical motion capture.", "token2charspan": [[0, 1], [2, 10], [11, 17], [17, 18], [18, 23], [24, 27], [28, 39], [40, 43], [44, 56], [57, 67], [68, 77], [78, 81], [82, 92], [93, 104], [105, 109], [110, 118], [119, 121], [122, 129], [130, 136], [137, 144], [144, 145]]}
{"doc_key": "ai-dev-274", "ner": [[0, 0, "organisation"], [8, 9, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 0, 8, 9, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["SMC", "is", "very", "similar", "to", "the", "more", "popular", "Jaccard", "index", "."], "sentence-detokenized": "SMC is very similar to the more popular Jaccard index.", "token2charspan": [[0, 3], [4, 6], [7, 11], [12, 19], [20, 22], [23, 26], [27, 31], [32, 39], [40, 47], [48, 53], [53, 54]]}
{"doc_key": "ai-dev-275", "ner": [[0, 0, "product"], [2, 6, "product"], [9, 12, "product"], [21, 22, "researcher"], [27, 27, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 9, 12, "named", "", false, false], [0, 0, 21, 22, "artifact", "", false, false], [0, 0, 27, 27, "artifact", "", false, false], [2, 6, 0, 0, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["PUMA", "(", "Programmable", "Universal", "Machine", "for", "Assembly", ",", "or", "Programmable", "Universal", "Manipulation", "Arm", ")", "is", "an", "industrial", "robotic", "arm", "developed", "by", "Victor", "Scheinman", "at", "pioneering", "robotics", "company", "Unimation", "."], "sentence-detokenized": "PUMA (Programmable Universal Machine for Assembly, or Programmable Universal Manipulation Arm) is an industrial robotic arm developed by Victor Scheinman at pioneering robotics company Unimation.", "token2charspan": [[0, 4], [5, 6], [6, 18], [19, 28], [29, 36], [37, 40], [41, 49], [49, 50], [51, 53], [54, 66], [67, 76], [77, 89], [90, 93], [93, 94], [95, 97], [98, 100], [101, 111], [112, 119], [120, 123], [124, 133], [134, 136], [137, 143], [144, 153], [154, 156], [157, 167], [168, 176], [177, 184], [185, 194], [194, 195]]}
{"doc_key": "ai-dev-276", "ner": [[4, 4, "programlang"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "written", "in", "Python", "."], "sentence-detokenized": "It is written in Python.", "token2charspan": [[0, 2], [3, 5], [6, 13], [14, 16], [17, 23], [23, 24]]}
{"doc_key": "ai-dev-277", "ner": [[1, 1, "misc"], [0, 2, "misc"], [11, 11, "field"], [13, 14, "field"], [16, 17, "field"], [22, 23, "field"], [25, 25, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7], "relations": [[1, 1, 0, 2, "related-to", "metric_for", true, false], [1, 1, 11, 11, "part-of", "", false, false], [1, 1, 13, 14, "part-of", "", false, false], [1, 1, 16, 17, "part-of", "", false, false], [1, 1, 22, 23, "part-of", "", false, false], [1, 1, 25, 25, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6], "sentence": ["Hertz", "bandwidth", "is", "a", "central", "concept", "in", "many", "fields", ",", "including", "electronics", ",", "information", "theory", ",", "digital", "communications", ",", "radio", "communications", ",", "signal", "processing", "and", "spectroscopy", ",", "and", "is", "one", "of", "the", "determinants", "of", "the", "capacity", "of", "a", "particular", "communications", "channel", "."], "sentence-detokenized": "Hertz bandwidth is a central concept in many fields, including electronics, information theory, digital communications, radio communications, signal processing and spectroscopy, and is one of the determinants of the capacity of a particular communications channel.", "token2charspan": [[0, 5], [6, 15], [16, 18], [19, 20], [21, 28], [29, 36], [37, 39], [40, 44], [45, 51], [51, 52], [53, 62], [63, 74], [74, 75], [76, 87], [88, 94], [94, 95], [96, 103], [104, 118], [118, 119], [120, 125], [126, 140], [140, 141], [142, 148], [149, 159], [160, 163], [164, 176], [176, 177], [178, 181], [182, 184], [185, 188], [189, 191], [192, 195], [196, 208], [209, 211], [212, 215], [216, 224], [225, 227], [228, 229], [230, 240], [241, 255], [256, 263], [263, 264]]}
{"doc_key": "ai-dev-278", "ner": [[9, 9, "algorithm"], [11, 11, "algorithm"], [17, 20, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[9, 9, 17, 20, "part-of", "", false, false], [11, 11, 17, 20, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["If", "a", "convex", "loss", "is", "used", "(", "as", "in", "AdaBoost", ",", "LogitBoost", "and", "all", "members", "of", "the", "AnyBoost", "family", "of", "algorithms", ")", ",", "then", "an", "example", "with", "a", "higher", "margin", "will", "receive", "a", "lower", "(", "or", "equal", ")", "weight", "than", "an", "example", "with", "a", "lower", "margin", "."], "sentence-detokenized": "If a convex loss is used (as in AdaBoost, LogitBoost and all members of the AnyBoost family of algorithms), then an example with a higher margin will receive a lower (or equal) weight than an example with a lower margin.", "token2charspan": [[0, 2], [3, 4], [5, 11], [12, 16], [17, 19], [20, 24], [25, 26], [26, 28], [29, 31], [32, 40], [40, 41], [42, 52], [53, 56], [57, 60], [61, 68], [69, 71], [72, 75], [76, 84], [85, 91], [92, 94], [95, 105], [105, 106], [106, 107], [108, 112], [113, 115], [116, 123], [124, 128], [129, 130], [131, 137], [138, 144], [145, 149], [150, 157], [158, 159], [160, 165], [166, 167], [167, 169], [170, 175], [175, 176], [177, 183], [184, 188], [189, 191], [192, 199], [200, 204], [205, 206], [207, 212], [213, 219], [219, 220]]}
{"doc_key": "ai-dev-279", "ner": [[0, 7, "researcher"]], "ner_mapping_to_source": [1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Sepp", "Hochreiter", "'s", "1991", "diploma", "thesis", "Sepp", "Hochreiter", "."], "sentence-detokenized": "Sepp Hochreiter's 1991 diploma thesis Sepp Hochreiter.", "token2charspan": [[0, 4], [5, 15], [15, 17], [18, 22], [23, 30], [31, 37], [38, 42], [43, 53], [53, 54]]}
{"doc_key": "ai-dev-280", "ner": [[4, 5, "algorithm"], [7, 7, "algorithm"], [10, 12, "algorithm"], [14, 14, "algorithm"], [17, 19, "algorithm"], [21, 21, "algorithm"], [27, 28, "algorithm"], [31, 32, "algorithm"], [34, 35, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "relations": [[7, 7, 4, 5, "named", "", false, false], [14, 14, 10, 12, "named", "", false, false], [17, 19, 27, 28, "related-to", "", true, false], [21, 21, 17, 19, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["Typical", "discriminative", "models", "include", "logistic", "regression", "(", "LR", ")", ",", "support", "vector", "machines", "(", "SVM", ")", ",", "conditional", "random", "fields", "(", "CRF", ")", "(", "specified", "on", "an", "undirected", "graph", ")", ",", "decision", "trees", ",", "neural", "networks", "and", "many", "others", "."], "sentence-detokenized": "Typical discriminative models include logistic regression (LR), support vector machines (SVM), conditional random fields (CRF) (specified on an undirected graph), decision trees, neural networks and many others.", "token2charspan": [[0, 7], [8, 22], [23, 29], [30, 37], [38, 46], [47, 57], [58, 59], [59, 61], [61, 62], [62, 63], [64, 71], [72, 78], [79, 87], [88, 89], [89, 92], [92, 93], [93, 94], [95, 106], [107, 113], [114, 120], [121, 122], [122, 125], [125, 126], [127, 128], [128, 137], [138, 140], [141, 143], [144, 154], [155, 160], [160, 161], [161, 162], [163, 171], [172, 177], [177, 178], [179, 185], [186, 194], [195, 198], [199, 203], [204, 210], [210, 211]]}
{"doc_key": "ai-dev-281", "ner": [[11, 13, "metrics"], [32, 34, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["It", "is", "also", "possible", "to", "use", "these", "probabilities", "and", "evaluate", "the", "mean", "squared", "error", "(", "or", "other", "similar", "measure", ")", "between", "the", "probabilities", "and", "the", "true", "values", ",", "then", "combine", "with", "the", "confusion", "matrix", "to", "create", "highly", "efficient", "fitness", "functions", "for", "logistic", "regression", "."], "sentence-detokenized": "It is also possible to use these probabilities and evaluate the mean squared error (or other similar measure) between the probabilities and the true values, then combine with the confusion matrix to create highly efficient fitness functions for logistic regression.", "token2charspan": [[0, 2], [3, 5], [6, 10], [11, 19], [20, 22], [23, 26], [27, 32], [33, 46], [47, 50], [51, 59], [60, 63], [64, 68], [69, 76], [77, 82], [83, 84], [84, 86], [87, 92], [93, 100], [101, 108], [108, 109], [110, 117], [118, 121], [122, 135], [136, 139], [140, 143], [144, 148], [149, 155], [155, 156], [157, 161], [162, 169], [170, 174], [175, 178], [179, 188], [189, 195], [196, 198], [199, 205], [206, 212], [213, 222], [223, 230], [231, 240], [241, 244], [245, 253], [254, 264], [264, 265]]}
{"doc_key": "ai-dev-282", "ner": [[0, 1, "product"], [7, 10, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 7, 10, "part-of", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["VoiceOver", "was", "first", "introduced", "in", "2005", "in", "Mac", "OS", "X", "Tiger", "(", "10.4", ")", "."], "sentence-detokenized": "VoiceOver was first introduced in 2005 in Mac OS X Tiger (10.4).", "token2charspan": [[0, 9], [10, 13], [14, 19], [20, 30], [31, 33], [34, 38], [39, 41], [42, 45], [46, 48], [49, 50], [51, 56], [57, 58], [58, 62], [62, 63], [63, 64]]}
{"doc_key": "ai-dev-283", "ner": [[13, 14, "algorithm"], [19, 21, "misc"], [26, 29, "metrics"], [32, 34, "algorithm"], [64, 69, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[13, 14, 19, 21, "related-to", "applied_to", false, false], [26, 29, 19, 21, "type-of", "", false, false], [26, 29, 32, 34, "related-to", "used_for", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["In", "practice", ",", "machine", "learning", "algorithms", "cope", "with", "this", "either", "by", "using", "a", "convex", "approximation", "of", "the", "0", "-", "1", "loss", "function", "(", "such", "as", "the", "hinge", "-", "type", "loss", "for", "the", "Support", "Vector", "Machine", ")", ",", "which", "is", "easier", "to", "optimize", ",", "or", "by", "imposing", "assumptions", "on", "the", "mathP", "(", "x", ",", "y", ")", "/", "math", "distribution", "(", "and", "thus", "ceasing", "to", "be", "agnostic", "learning", "algorithms", "to", "which", "the", "above", "result", "applies", ")", "."], "sentence-detokenized": "In practice, machine learning algorithms cope with this either by using a convex approximation of the 0-1 loss function (such as the hinge-type loss for the Support Vector Machine), which is easier to optimize, or by imposing assumptions on the mathP(x, y)/math distribution (and thus ceasing to be agnostic learning algorithms to which the above result applies).", "token2charspan": [[0, 2], [3, 11], [11, 12], [13, 20], [21, 29], [30, 40], [41, 45], [46, 50], [51, 55], [56, 62], [63, 65], [66, 71], [72, 73], [74, 80], [81, 94], [95, 97], [98, 101], [102, 103], [103, 104], [104, 105], [106, 110], [111, 119], [120, 121], [121, 125], [126, 128], [129, 132], [133, 138], [138, 139], [139, 143], [144, 148], [149, 152], [153, 156], [157, 164], [165, 171], [172, 179], [179, 180], [180, 181], [182, 187], [188, 190], [191, 197], [198, 200], [201, 209], [209, 210], [211, 213], [214, 216], [217, 225], [226, 237], [238, 240], [241, 244], [245, 250], [250, 251], [251, 252], [252, 253], [254, 255], [255, 256], [256, 257], [257, 261], [262, 274], [275, 276], [276, 279], [280, 284], [285, 292], [293, 295], [296, 298], [299, 307], [308, 316], [317, 327], [328, 330], [331, 336], [337, 340], [341, 346], [347, 353], [354, 361], [361, 362], [362, 363]]}
{"doc_key": "ai-dev-284", "ner": [[0, 0, "misc"], [11, 13, "field"], [22, 22, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 11, 13, "usage", "", false, false], [0, 0, 22, 22, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Westworld", "(", "1973", ")", "was", "the", "first", "feature", "film", "to", "use", "digital", "image", "processing", "to", "simulate", "the", "point", "of", "view", "of", "an", "android", "."], "sentence-detokenized": "Westworld (1973) was the first feature film to use digital image processing to simulate the point of view of an android.", "token2charspan": [[0, 9], [10, 11], [11, 15], [15, 16], [17, 20], [21, 24], [25, 30], [31, 38], [39, 43], [44, 46], [47, 50], [51, 58], [59, 64], [65, 75], [76, 78], [79, 87], [88, 91], [92, 97], [98, 100], [101, 105], [106, 108], [109, 111], [112, 119], [119, 120]]}
{"doc_key": "ai-dev-285", "ner": [[8, 9, "task"], [11, 12, "task"], [14, 14, "task"], [16, 17, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Currently", ",", "it", "is", "also", "commonly", "used", "in", "speech", "recognition", ",", "speech", "synthesis", ",", "diarization", ",", "Xavier", "Anguera", "et", "al", "."], "sentence-detokenized": "Currently, it is also commonly used in speech recognition, speech synthesis, diarization, Xavier Anguera et al.", "token2charspan": [[0, 9], [9, 10], [11, 13], [14, 16], [17, 21], [22, 30], [31, 35], [36, 38], [39, 45], [46, 57], [57, 58], [59, 65], [66, 75], [75, 76], [77, 88], [88, 89], [90, 96], [97, 104], [105, 107], [108, 110], [110, 111]]}
{"doc_key": "ai-dev-286", "ner": [[9, 16, "algorithm"], [18, 19, "algorithm"], [22, 24, "algorithm"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[18, 19, 9, 16, "type-of", "", false, false], [22, 24, 9, 16, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Here", ",", "math", "/", "sigma", "/", "math", "is", "an", "element", "-", "wise", "activation", "function", ",", "such", "as", "a", "sigmoid", "function", "or", "a", "rectified", "linear", "unit", "."], "sentence-detokenized": "Here, math/sigma/math is an element-wise activation function, such as a sigmoid function or a rectified linear unit.", "token2charspan": [[0, 4], [4, 5], [6, 10], [10, 11], [11, 16], [16, 17], [17, 21], [22, 24], [25, 27], [28, 35], [35, 36], [36, 40], [41, 51], [52, 60], [60, 61], [62, 66], [67, 69], [70, 71], [72, 79], [80, 88], [89, 91], [92, 93], [94, 103], [104, 110], [111, 115], [115, 116]]}
{"doc_key": "ai-dev-287", "ner": [[12, 14, "algorithm"], [24, 24, "misc"], [26, 26, "misc"], [28, 29, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["Traditional", "phonetic", "-", "based", "approaches", "(", "e.g.", "all", "models", "based", "on", "the", "hidden", "Markov", "model", ")", "have", "required", "separate", "components", "and", "training", "for", "the", "pronunciation", ",", "acoustic", "and", "linguistic", "model", "."], "sentence-detokenized": "Traditional phonetic-based approaches (e.g. all models based on the hidden Markov model) have required separate components and training for the pronunciation, acoustic and linguistic model.", "token2charspan": [[0, 11], [12, 20], [20, 21], [21, 26], [27, 37], [38, 39], [39, 43], [44, 47], [48, 54], [55, 60], [61, 63], [64, 67], [68, 74], [75, 81], [82, 87], [87, 88], [89, 93], [94, 102], [103, 111], [112, 122], [123, 126], [127, 135], [136, 139], [140, 143], [144, 157], [157, 158], [159, 167], [168, 171], [172, 182], [183, 188], [188, 189]]}
{"doc_key": "ai-dev-288", "ner": [[0, 3, "algorithm"], [7, 8, "field"], [10, 11, "field"], [13, 14, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[0, 3, 13, 14, "related-to", "used_for", false, false], [7, 8, 0, 3, "usage", "", false, false], [10, 11, 0, 3, "usage", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "Roberts", "cross", "operator", "is", "used", "in", "image", "processing", "and", "computer", "vision", "for", "edge", "detection", "."], "sentence-detokenized": "The Roberts cross operator is used in image processing and computer vision for edge detection.", "token2charspan": [[0, 3], [4, 11], [12, 17], [18, 26], [27, 29], [30, 34], [35, 37], [38, 43], [44, 54], [55, 58], [59, 67], [68, 74], [75, 78], [79, 83], [84, 93], [93, 94]]}
{"doc_key": "ai-dev-289", "ner": [[0, 0, "metrics"], [2, 2, "metrics"], [25, 25, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 25, 25, "opposite", "", false, false], [2, 2, 25, 25, "opposite", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Sensitivity", "and", "specificity", "values", "do", "not", "take", "into", "account", "the", "percentage", "of", "positive", "cases", "in", "the", "population", "of", "interest", "(", "unlike", ",", "for", "example", ",", "accuracy", ")", "."], "sentence-detokenized": "Sensitivity and specificity values do not take into account the percentage of positive cases in the population of interest (unlike, for example, accuracy).", "token2charspan": [[0, 11], [12, 15], [16, 27], [28, 34], [35, 37], [38, 41], [42, 46], [47, 51], [52, 59], [60, 63], [64, 74], [75, 77], [78, 86], [87, 92], [93, 95], [96, 99], [100, 110], [111, 113], [114, 122], [123, 124], [124, 130], [130, 131], [132, 135], [136, 143], [143, 144], [145, 153], [153, 154], [154, 155]]}
{"doc_key": "ai-dev-290", "ner": [[2, 2, "algorithm"], [1, 15, "misc"], [8, 9, "researcher"], [11, 12, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[1, 15, 2, 2, "topic", "", false, false], [1, 15, 8, 9, "artifact", "", false, false], [1, 15, 11, 12, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["But", "perceptron", "models", "were", "made", "very", "unpopular", "by", "Marvin", "Minsky", "and", "Seymour", "Papert", "'s", "book", "Perceptrons", ",", "published", "in", "1969", "."], "sentence-detokenized": "But perceptron models were made very unpopular by Marvin Minsky and Seymour Papert's book Perceptrons, published in 1969.", "token2charspan": [[0, 3], [4, 14], [15, 21], [22, 26], [27, 31], [32, 36], [37, 46], [47, 49], [50, 56], [57, 63], [64, 67], [68, 75], [76, 82], [82, 84], [85, 89], [90, 101], [101, 102], [103, 112], [113, 115], [116, 120], [120, 121]]}
{"doc_key": "ai-dev-291", "ner": [[3, 5, "conference"], [0, 0, "organisation"], [18, 20, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 5, 18, 20, "topic", "", false, false], [0, 0, 3, 5, "role", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["NIST", "'s", "annual", "Document", "Understanding", "Conferences", "have", "developed", "sophisticated", "evaluation", "criteria", "for", "techniques", "that", "accept", "the", "challenge", "of", "summarizing", "multiple", "documents", "."], "sentence-detokenized": "NIST's annual Document Understanding Conferences have developed sophisticated evaluation criteria for techniques that accept the challenge of summarizing multiple documents.", "token2charspan": [[0, 4], [4, 6], [7, 13], [14, 22], [23, 36], [37, 48], [49, 53], [54, 63], [64, 77], [78, 88], [89, 97], [98, 101], [102, 112], [113, 117], [118, 124], [125, 128], [129, 138], [139, 141], [142, 153], [154, 162], [163, 172], [172, 173]]}
{"doc_key": "ai-dev-292", "ner": [[1, 1, "product"], [2, 27, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[1, 1, 2, 27, "compare", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["A", "parallel", "manipulator", "is", "designed", "so", "that", "each", "chain", "is", "usually", "short", ",", "simple", "and", "thus", "can", "be", "rigid", "against", "unwanted", "movement", ",", "compared", "to", "a", "series", "manipulator", "."], "sentence-detokenized": "A parallel manipulator is designed so that each chain is usually short, simple and thus can be rigid against unwanted movement, compared to a series manipulator.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 34], [35, 37], [38, 42], [43, 47], [48, 53], [54, 56], [57, 64], [65, 70], [70, 71], [72, 78], [79, 82], [83, 87], [88, 91], [92, 94], [95, 100], [101, 108], [109, 117], [118, 126], [126, 127], [128, 136], [137, 139], [140, 141], [142, 148], [149, 160], [160, 161]]}
{"doc_key": "ai-dev-293", "ner": [[26, 26, "misc"], [28, 30, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "manipulator", "is", "what", "makes", "the", "robot", "move", ",", "and", "the", "design", "of", "these", "systems", "can", "be", "classified", "into", "several", "common", "types", ",", "such", "as", "the", "SCARA", "and", "Cartesian", "coordinate", "robot", ",", "which", "use", "different", "coordinate", "systems", "to", "direct", "the", "machine", "arms", "."], "sentence-detokenized": "The manipulator is what makes the robot move, and the design of these systems can be classified into several common types, such as the SCARA and Cartesian coordinate robot, which use different coordinate systems to direct the machine arms.", "token2charspan": [[0, 3], [4, 15], [16, 18], [19, 23], [24, 29], [30, 33], [34, 39], [40, 44], [44, 45], [46, 49], [50, 53], [54, 60], [61, 63], [64, 69], [70, 77], [78, 81], [82, 84], [85, 95], [96, 100], [101, 108], [109, 115], [116, 121], [121, 122], [123, 127], [128, 130], [131, 134], [135, 140], [141, 144], [145, 154], [155, 165], [166, 171], [171, 172], [173, 178], [179, 182], [183, 192], [193, 203], [204, 211], [212, 214], [215, 221], [222, 225], [226, 233], [234, 238], [238, 239]]}
{"doc_key": "ai-dev-294", "ner": [[2, 3, "country"], [11, 14, "organisation"], [17, 22, "organisation"], [25, 28, "organisation"], [31, 33, "organisation"], [37, 43, "organisation"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[11, 14, 2, 3, "physical", "", false, false], [17, 22, 2, 3, "physical", "", false, false], [25, 28, 2, 3, "physical", "", false, false], [31, 33, 2, 3, "physical", "", false, false], [37, 43, 2, 3, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "the", "United", "States", ",", "he", "is", "a", "member", "of", "the", "National", "Academy", "of", "Sciences", ",", "the", "American", "Academy", "of", "Arts", "and", "Sciences", ",", "the", "Linguistic", "Society", "of", "America", ",", "the", "American", "Philosophical", "Association", ",", "and", "the", "American", "Association", "for", "the", "Advancement", "of", "Science", "."], "sentence-detokenized": "In the United States, he is a member of the National Academy of Sciences, the American Academy of Arts and Sciences, the Linguistic Society of America, the American Philosophical Association, and the American Association for the Advancement of Science.", "token2charspan": [[0, 2], [3, 6], [7, 13], [14, 20], [20, 21], [22, 24], [25, 27], [28, 29], [30, 36], [37, 39], [40, 43], [44, 52], [53, 60], [61, 63], [64, 72], [72, 73], [74, 77], [78, 86], [87, 94], [95, 97], [98, 102], [103, 106], [107, 115], [115, 116], [117, 120], [121, 131], [132, 139], [140, 142], [143, 150], [150, 151], [152, 155], [156, 164], [165, 178], [179, 190], [190, 191], [192, 195], [196, 199], [200, 208], [209, 220], [221, 224], [225, 228], [229, 240], [241, 243], [244, 251], [251, 252]]}
{"doc_key": "ai-dev-295", "ner": [[8, 11, "algorithm"], [13, 13, "algorithm"], [20, 21, "algorithm"], [27, 28, "algorithm"], [33, 34, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[8, 11, 20, 21, "named", "", false, false], [13, 13, 8, 11, "named", "", false, false], [20, 21, 27, 28, "compare", "", false, false], [20, 21, 33, 34, "related-to", "performs", false, false], [27, 28, 33, 34, "related-to", "performs", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["They", "became", "very", "important", "with", "the", "popularity", "of", "the", "Support", "Vector", "Machine", "(", "SVM", ")", "in", "the", "1990s", ",", "when", "SVM", "was", "found", "to", "be", "competitive", "with", "neural", "networks", "in", "tasks", "such", "as", "handwriting", "recognition", "."], "sentence-detokenized": "They became very important with the popularity of the Support Vector Machine (SVM) in the 1990s, when SVM was found to be competitive with neural networks in tasks such as handwriting recognition.", "token2charspan": [[0, 4], [5, 11], [12, 16], [17, 26], [27, 31], [32, 35], [36, 46], [47, 49], [50, 53], [54, 61], [62, 68], [69, 76], [77, 78], [78, 81], [81, 82], [83, 85], [86, 89], [90, 95], [95, 96], [97, 101], [102, 105], [106, 109], [110, 115], [116, 118], [119, 121], [122, 133], [134, 138], [139, 145], [146, 154], [155, 157], [158, 163], [164, 168], [169, 171], [172, 183], [184, 195], [195, 196]]}
{"doc_key": "ai-dev-296", "ner": [[3, 3, "misc"], [9, 11, "misc"], [14, 15, "algorithm"], [2, 24, "misc"], [29, 30, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 3, 9, 11, "usage", "", false, false], [3, 3, 2, 24, "usage", "", false, false], [9, 11, 14, 15, "origin", "result_of_algorithm", false, false], [2, 24, 29, 30, "origin", "result_of_algorithm", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["An", "empirical", "whitening", "transformation", "is", "obtained", "by", "estimating", "the", "covariance", "(", "e.g.", ",", "by", "maximum", "likelihood", ")", "and", "subsequently", "constructing", "a", "corresponding", "estimated", "whitening", "matrix", "(", "e.g.", ",", "by", "Cholesky", "decomposition", ")", "."], "sentence-detokenized": "An empirical whitening transformation is obtained by estimating the covariance (e.g., by maximum likelihood) and subsequently constructing a corresponding estimated whitening matrix (e.g., by Cholesky decomposition).", "token2charspan": [[0, 2], [3, 12], [13, 22], [23, 37], [38, 40], [41, 49], [50, 52], [53, 63], [64, 67], [68, 78], [79, 80], [80, 84], [84, 85], [86, 88], [89, 96], [97, 107], [107, 108], [109, 112], [113, 125], [126, 138], [139, 140], [141, 154], [155, 164], [165, 174], [175, 181], [182, 183], [183, 187], [187, 188], [189, 191], [192, 200], [201, 214], [214, 215], [215, 216]]}
{"doc_key": "ai-dev-297", "ner": [[0, 2, "organisation"], [8, 9, "product"], [24, 24, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 9, 0, 2, "artifact", "", false, false], [24, 24, 0, 2, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["IAI", "is", "the", "world", "'s", "largest", "manufacturer", "of", "Cartesian", "coordinate", "robots", "and", "is", "an", "established", "leader", "in", "low", "-", "cost", ",", "high", "-", "performance", "SCARA", "robots", "."], "sentence-detokenized": "IAI is the world's largest manufacturer of Cartesian coordinate robots and is an established leader in low-cost, high-performance SCARA robots.", "token2charspan": [[0, 3], [4, 6], [7, 10], [11, 16], [16, 18], [19, 26], [27, 39], [40, 42], [43, 52], [53, 63], [64, 70], [71, 74], [75, 77], [78, 80], [81, 92], [93, 99], [100, 102], [103, 106], [106, 107], [107, 111], [111, 112], [113, 117], [117, 118], [118, 129], [130, 135], [136, 142], [142, 143]]}
{"doc_key": "ai-dev-298", "ner": [[10, 11, "field"], [13, 14, "field"], [16, 17, "field"], [19, 20, "field"], [22, 23, "field"], [25, 26, "field"], [28, 28, "field"], [30, 30, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7], "relations": [], "relations_mapping_to_source": [], "sentence": ["Formal", "concept", "analysis", "finds", "practical", "applications", "in", "areas", "such", "as", "data", "mining", ",", "text", "mining", ",", "machine", "learning", ",", "knowledge", "management", ",", "semantic", "web", ",", "software", "development", ",", "chemistry", "and", "biology", "."], "sentence-detokenized": "Formal concept analysis finds practical applications in areas such as data mining, text mining, machine learning, knowledge management, semantic web, software development, chemistry and biology.", "token2charspan": [[0, 6], [7, 14], [15, 23], [24, 29], [30, 39], [40, 52], [53, 55], [56, 61], [62, 66], [67, 69], [70, 74], [75, 81], [81, 82], [83, 87], [88, 94], [94, 95], [96, 103], [104, 112], [112, 113], [114, 123], [124, 134], [134, 135], [136, 144], [145, 148], [148, 149], [150, 158], [159, 170], [170, 171], [172, 181], [182, 185], [186, 193], [193, 194]]}
{"doc_key": "ai-dev-299", "ner": [[1, 2, "field"], [4, 4, "field"], [10, 11, "field"], [17, 18, "field"], [29, 31, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[4, 4, 17, 18, "part-of", "", false, false], [4, 4, 29, 31, "topic", "", false, false], [10, 11, 4, 4, "named", "", false, false], [17, 18, 1, 2, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["In", "computer", "science", ",", "computational", "learning", "theory", "(", "or", "just", "learning", "theory", ")", "is", "a", "subfield", "of", "artificial", "intelligence", "devoted", "to", "the", "study", "of", "the", "design", "and", "analysis", "of", "machine", "learning", "algorithms", "."], "sentence-detokenized": "In computer science, computational learning theory (or just learning theory) is a subfield of artificial intelligence devoted to the study of the design and analysis of machine learning algorithms.", "token2charspan": [[0, 2], [3, 11], [12, 19], [19, 20], [21, 34], [35, 43], [44, 50], [51, 52], [52, 54], [55, 59], [60, 68], [69, 75], [75, 76], [77, 79], [80, 81], [82, 90], [91, 93], [94, 104], [105, 117], [118, 125], [126, 128], [129, 132], [133, 138], [139, 141], [142, 145], [146, 152], [153, 156], [157, 165], [166, 168], [169, 176], [177, 185], [186, 196], [196, 197]]}
{"doc_key": "ai-dev-300", "ner": [[0, 1, "algorithm"], [3, 3, "algorithm"], [10, 11, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 3, 0, 1, "named", "", false, false], [10, 11, 0, 1, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Collaborative", "filtering", "(", "CF", ")", "is", "a", "technique", "used", "by", "recommender", "systems", "."], "sentence-detokenized": "Collaborative filtering (CF) is a technique used by recommender systems.", "token2charspan": [[0, 13], [14, 23], [24, 25], [25, 27], [27, 28], [29, 31], [32, 33], [34, 43], [44, 48], [49, 51], [52, 63], [64, 71], [71, 72]]}
{"doc_key": "ai-dev-301", "ner": [[0, 3, "metrics"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "FALSE", "positive", "rate", "is", "the", "proportion", "of", "all", "negative", "results", "that", "still", "give", "positive", "results", ",", "i.e.", "the", "conditional", "probability", "of", "a", "positive", "test", "result", "for", "an", "event", "that", "was", "not", "present", "."], "sentence-detokenized": "The FALSE positive rate is the proportion of all negative results that still give positive results, i.e. the conditional probability of a positive test result for an event that was not present.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 23], [24, 26], [27, 30], [31, 41], [42, 44], [45, 48], [49, 57], [58, 65], [66, 70], [71, 76], [77, 81], [82, 90], [91, 98], [98, 99], [100, 104], [105, 108], [109, 120], [121, 132], [133, 135], [136, 137], [138, 146], [147, 151], [152, 158], [159, 162], [163, 165], [166, 171], [172, 176], [177, 180], [181, 184], [185, 192], [192, 193]]}
{"doc_key": "ai-dev-302", "ner": [[1, 15, "misc"], [38, 38, "metrics"], [42, 42, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[1, 15, 38, 38, "topic", "", false, false], [1, 15, 42, 42, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "VLDB", "'", "8", ":", "Proceedings", "of", "the", "34th", "International", "Conference", "on", "Very", "Large", "Data", "Bases", ",", "pages", "422--433", ".", "showed", "that", "the", "values", "given", "for", "mathC", "/", "math", "and", "mathK", "/", "math", "generally", "imply", "a", "relatively", "low", "accuracy", "of", "iteratively", "calculated", "SimRank", "scores", "."], "sentence-detokenized": "In VLDB '8: Proceedings of the 34th International Conference on Very Large Data Bases, pages 422--433. showed that the values given for mathC/math and mathK/math generally imply a relatively low accuracy of iteratively calculated SimRank scores.", "token2charspan": [[0, 2], [3, 7], [8, 9], [9, 10], [10, 11], [12, 23], [24, 26], [27, 30], [31, 35], [36, 49], [50, 60], [61, 63], [64, 68], [69, 74], [75, 79], [80, 85], [85, 86], [87, 92], [93, 101], [101, 102], [103, 109], [110, 114], [115, 118], [119, 125], [126, 131], [132, 135], [136, 141], [141, 142], [142, 146], [147, 150], [151, 156], [156, 157], [157, 161], [162, 171], [172, 177], [178, 179], [180, 190], [191, 194], [195, 203], [204, 206], [207, 218], [219, 229], [230, 237], [238, 244], [244, 245]]}
{"doc_key": "ai-dev-303", "ner": [[1, 4, "misc"], [5, 5, "misc"], [17, 18, "person"], [20, 22, "person"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[5, 5, 1, 4, "general-affiliation", "", false, false], [5, 5, 17, 18, "artifact", "", false, false], [5, 5, 20, 22, "artifact", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "sci", "-", "fi", "drama", "Sense8", "debuted", "in", "June", "2015", ",", "which", "was", "written", "and", "produced", "by", "The", "Wachowskis", "and", "J.", "Michael", "Straczynski", "."], "sentence-detokenized": "The sci-fi drama Sense8 debuted in June 2015, which was written and produced by The Wachowskis and J. Michael Straczynski.", "token2charspan": [[0, 3], [4, 7], [7, 8], [8, 10], [11, 16], [17, 23], [24, 31], [32, 34], [35, 39], [40, 44], [44, 45], [46, 51], [52, 55], [56, 63], [64, 67], [68, 76], [77, 79], [80, 83], [84, 94], [95, 98], [99, 101], [102, 109], [110, 121], [121, 122]]}
{"doc_key": "ai-dev-304", "ner": [[1, 1, "misc"], [7, 9, "product"], [25, 29, "misc"], [35, 35, "country"], [37, 37, "country"], [39, 39, "country"], [41, 41, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[1, 1, 7, 9, "topic", "", false, false], [35, 35, 25, 29, "type-of", "", false, false], [37, 37, 25, 29, "type-of", "", false, false], [39, 39, 25, 29, "type-of", "", false, false], [41, 41, 25, 29, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Although", "Eurotra", "has", "never", "delivered", "a", "functioning", "machine", "translation", "system", ",", "the", "project", "has", "had", "a", "long", "-", "term", "impact", "on", "developing", "language", "industries", "in", "European", "Member", "States", ",", "particularly", "in", "the", "southern", "countries", "of", "Greece", ",", "Italy", ",", "Spain", "and", "Portugal", "."], "sentence-detokenized": "Although Eurotra has never delivered a functioning machine translation system, the project has had a long-term impact on developing language industries in European Member States, particularly in the southern countries of Greece, Italy, Spain and Portugal.", "token2charspan": [[0, 8], [9, 16], [17, 20], [21, 26], [27, 36], [37, 38], [39, 50], [51, 58], [59, 70], [71, 77], [77, 78], [79, 82], [83, 90], [91, 94], [95, 98], [99, 100], [101, 105], [105, 106], [106, 110], [111, 117], [118, 120], [121, 131], [132, 140], [141, 151], [152, 154], [155, 163], [164, 170], [171, 177], [177, 178], [179, 191], [192, 194], [195, 198], [199, 207], [208, 217], [218, 220], [221, 227], [227, 228], [229, 234], [234, 235], [236, 241], [242, 245], [246, 254], [254, 255]]}
{"doc_key": "ai-dev-305", "ner": [[0, 1, "algorithm"], [7, 8, "task"], [19, 21, "task"], [23, 23, "task"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[7, 8, 0, 1, "usage", "", true, false], [19, 21, 7, 8, "named", "", false, false], [23, 23, 19, 21, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2], "sentence": ["The", "autoencoder", "has", "been", "successfully", "applied", "to", "machine", "translation", "of", "human", "languages", ",", "which", "is", "usually", "referred", "to", "as", "neural", "machine", "translation", "(", "NMT", ")", "."], "sentence-detokenized": "The autoencoder has been successfully applied to machine translation of human languages, which is usually referred to as neural machine translation (NMT).", "token2charspan": [[0, 3], [4, 15], [16, 19], [20, 24], [25, 37], [38, 45], [46, 48], [49, 56], [57, 68], [69, 71], [72, 77], [78, 87], [87, 88], [89, 94], [95, 97], [98, 105], [106, 114], [115, 117], [118, 120], [121, 127], [128, 135], [136, 147], [148, 149], [149, 152], [152, 153], [153, 154]]}
{"doc_key": "ai-dev-306", "ner": [[9, 11, "metrics"], [13, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["Popular", "examples", "of", "probability", "-", "based", "fitness", "functions", "include", "maximum", "likelihood", "estimation", "and", "hinge", "loss", "."], "sentence-detokenized": "Popular examples of probability-based fitness functions include maximum likelihood estimation and hinge loss.", "token2charspan": [[0, 7], [8, 16], [17, 19], [20, 31], [31, 32], [32, 37], [38, 45], [46, 55], [56, 63], [64, 71], [72, 82], [83, 93], [94, 97], [98, 103], [104, 108], [108, 109]]}
{"doc_key": "ai-dev-307", "ner": [[0, 1, "field"], [11, 13, "task"], [15, 16, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 13, 0, 1, "part-of", "", false, false], [15, 16, 0, 1, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Data", "mining", "is", "a", "related", "field", "of", "study", "that", "focuses", "on", "exploratory", "data", "analysis", "through", "unsupervised", "learning", "."], "sentence-detokenized": "Data mining is a related field of study that focuses on exploratory data analysis through unsupervised learning.", "token2charspan": [[0, 4], [5, 11], [12, 14], [15, 16], [17, 24], [25, 30], [31, 33], [34, 39], [40, 44], [45, 52], [53, 55], [56, 67], [68, 72], [73, 81], [82, 89], [90, 102], [103, 111], [111, 112]]}
{"doc_key": "ai-dev-308", "ner": [[0, 1, "algorithm"], [13, 14, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[0, 1, 13, 14, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Collaborative", "filtering", "includes", "techniques", "for", "matching", "people", "with", "similar", "interests", "and", "creating", "a", "referral", "system", "based", "on", "this", "."], "sentence-detokenized": "Collaborative filtering includes techniques for matching people with similar interests and creating a referral system based on this.", "token2charspan": [[0, 13], [14, 23], [24, 32], [33, 43], [44, 47], [48, 56], [57, 63], [64, 68], [69, 76], [77, 86], [87, 90], [91, 99], [100, 101], [102, 110], [111, 117], [118, 123], [124, 126], [127, 131], [131, 132]]}
{"doc_key": "ai-dev-309", "ner": [[5, 8, "algorithm"], [13, 13, "programlang"], [3, 18, "product"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[3, 18, 5, 8, "type-of", "", false, false], [3, 18, 13, 13, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["A", "number", "of", "WordNet", "-", "based", "word", "similarity", "algorithms", "are", "implemented", "in", "a", "Perl", "package", "called", "WordNet", "::", "Similarity", "."], "sentence-detokenized": "A number of WordNet-based word similarity algorithms are implemented in a Perl package called WordNet::Similarity.", "token2charspan": [[0, 1], [2, 8], [9, 11], [12, 19], [19, 20], [20, 25], [26, 30], [31, 41], [42, 52], [53, 56], [57, 68], [69, 71], [72, 73], [74, 78], [79, 86], [87, 93], [94, 101], [101, 103], [103, 113], [113, 114]]}
{"doc_key": "ai-dev-310", "ner": [[5, 5, "conference"], [8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [], "relations_mapping_to_source": [], "sentence": ["Another", "paper", ",", "presented", "at", "CVPR", "2000", "by", "Erik", "Miller", ",", "Nicholas", "Matsakis", "and", "Paul", "Viola", ",", "will", "also", "be", "discussed", "."], "sentence-detokenized": "Another paper, presented at CVPR 2000 by Erik Miller, Nicholas Matsakis and Paul Viola, will also be discussed.", "token2charspan": [[0, 7], [8, 13], [13, 14], [15, 24], [25, 27], [28, 32], [33, 37], [38, 40], [41, 45], [46, 52], [52, 53], [54, 62], [63, 71], [72, 75], [76, 80], [81, 86], [86, 87], [88, 92], [93, 97], [98, 100], [101, 110], [110, 111]]}
{"doc_key": "ai-dev-311", "ner": [[0, 0, "algorithm"], [10, 11, "misc"], [16, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 16, 17, "compare", "", false, false], [16, 17, 10, 11, "type-of", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["QC", "has", "not", "been", "evaluated", "in", "comparison", "with", "traditional", "modern", "clustering", "algorithms", ",", "apart", "from", "the", "Jaccard", "index", "."], "sentence-detokenized": "QC has not been evaluated in comparison with traditional modern clustering algorithms, apart from the Jaccard index.", "token2charspan": [[0, 2], [3, 6], [7, 10], [11, 15], [16, 25], [26, 28], [29, 39], [40, 44], [45, 56], [57, 63], [64, 74], [75, 85], [85, 86], [87, 92], [93, 97], [98, 101], [102, 109], [110, 115], [115, 116]]}
{"doc_key": "ai-dev-312", "ner": [[2, 5, "misc"], [8, 15, "misc"], [11, 15, "location"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[8, 15, 2, 5, "physical", "", false, false], [8, 15, 11, 15, "temporal", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["During", "the", "VEX", "Robotics", "World", "Championship", ",", "a", "Parade", "of", "Nations", "is", "held", "in", "Freedom", "Hall", ",", "with", "hundreds", "of", "students", "from", "over", "30", "countries", "participating", "."], "sentence-detokenized": "During the VEX Robotics World Championship, a Parade of Nations is held in Freedom Hall, with hundreds of students from over 30 countries participating.", "token2charspan": [[0, 6], [7, 10], [11, 14], [15, 23], [24, 29], [30, 42], [42, 43], [44, 45], [46, 52], [53, 55], [56, 63], [64, 66], [67, 71], [72, 74], [75, 82], [83, 87], [87, 88], [89, 93], [94, 102], [103, 105], [106, 114], [115, 119], [120, 124], [125, 127], [128, 137], [138, 151], [151, 152]]}
{"doc_key": "ai-dev-313", "ner": [[5, 7, "metrics"], [10, 10, "metrics"], [13, 15, "metrics"], [17, 17, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [[10, 10, 5, 7, "named", "", false, false], [17, 17, 13, 15, "named", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Other", "measures", "of", "accuracy", "include", "single", "word", "error", "rate", "(", "SWER", ")", "and", "command", "success", "rate", "(", "CSR", ")", "."], "sentence-detokenized": "Other measures of accuracy include single word error rate (SWER) and command success rate (CSR).", "token2charspan": [[0, 5], [6, 14], [15, 17], [18, 26], [27, 34], [35, 41], [42, 46], [47, 52], [53, 57], [58, 59], [59, 63], [63, 64], [65, 68], [69, 76], [77, 84], [85, 89], [90, 91], [91, 94], [94, 95], [95, 96]]}
{"doc_key": "ai-dev-314", "ner": [[7, 8, "conference"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["They", "presented", "their", "method", "and", "results", "in", "SIGGRAPH", "2000", "."], "sentence-detokenized": "They presented their method and results in SIGGRAPH 2000.", "token2charspan": [[0, 4], [5, 14], [15, 20], [21, 27], [28, 31], [32, 39], [40, 42], [43, 51], [52, 56], [56, 57]]}
{"doc_key": "ai-dev-315", "ner": [[0, 4, "conference"], [13, 13, "misc"], [7, 16, "misc"], [18, 19, "conference"], [25, 30, "researcher"], [39, 40, "researcher"], [44, 46, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 4, 13, 13, "origin", "", false, false], [13, 13, 18, 19, "physical", "", false, false], [13, 13, 18, 19, "temporal", "", false, false], [13, 13, 25, 30, "origin", "", false, false], [13, 13, 39, 40, "origin", "", false, false], [7, 16, 13, 13, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["The", "KDD", "conference", "grew", "out", "of", "the", "Knowledge", "Discovery", "and", "Data", "Mining", "(", "KDD", ")", "workshops", "held", "at", "AAAI", "conferences", ",", "which", "were", "initiated", "by", "Gregory", "I", ".", "Piatetsky", "-", "Shapiro", "in", "1989", ",", "1991", "and", "1993", "and", "by", "Usama", "Fayyad", "in", "1994", ".", "Machines", "|", "ACM", "."], "sentence-detokenized": "The KDD conference grew out of the Knowledge Discovery and Data Mining (KDD) workshops held at AAAI conferences, which were initiated by Gregory I. Piatetsky-Shapiro in 1989, 1991 and 1993 and by Usama Fayyad in 1994. Machines | ACM.", "token2charspan": [[0, 3], [4, 7], [8, 18], [19, 23], [24, 27], [28, 30], [31, 34], [35, 44], [45, 54], [55, 58], [59, 63], [64, 70], [71, 72], [72, 75], [75, 76], [77, 86], [87, 91], [92, 94], [95, 99], [100, 111], [111, 112], [113, 118], [119, 123], [124, 133], [134, 136], [137, 144], [145, 146], [146, 147], [148, 157], [157, 158], [158, 165], [166, 168], [169, 173], [173, 174], [175, 179], [180, 183], [184, 188], [189, 192], [193, 195], [196, 201], [202, 208], [209, 211], [212, 216], [216, 217], [218, 226], [227, 228], [229, 232], [232, 233]]}
{"doc_key": "ai-dev-316", "ner": [[8, 11, "conference"], [13, 13, "conference"], [17, 22, "organisation"], [24, 24, "organisation"], [28, 32, "conference"], [34, 34, "conference"], [38, 44, "conference"], [46, 46, "conference"], [50, 55, "conference"], [57, 57, "conference"], [62, 67, "conference"], [69, 69, "conference"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "relations": [[13, 13, 8, 11, "named", "", false, false], [24, 24, 17, 22, "named", "", false, false], [34, 34, 28, 32, "named", "", false, false], [46, 46, 38, 44, "named", "", false, false], [57, 57, 50, 55, "named", "", false, false], [69, 69, 62, 67, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5], "sentence": ["He", "has", "been", "elected", "a", "Fellow", "of", "the", "Association", "for", "Computing", "Machinery", "(", "ACM", ")", ",", "the", "Institute", "of", "Electrical", "and", "Electronics", "Engineers", "(", "IEEE", ")", ",", "the", "International", "Association", "for", "Pattern", "Recognition", "(", "IAPR", ")", ",", "the", "Association", "for", "the", "Advancement", "of", "Artificial", "Intelligence", "(", "AAAI", ")", ",", "the", "American", "Association", "for", "Advancement", "of", "Science", "(", "AAAS", ")", ",", "and", "the", "Society", "for", "Optics", "and", "Photonics", "Technology", "(", "SPIE", ")", "."], "sentence-detokenized": "He has been elected a Fellow of the Association for Computing Machinery (ACM), the Institute of Electrical and Electronics Engineers (IEEE), the International Association for Pattern Recognition (IAPR), the Association for the Advancement of Artificial Intelligence (AAAI), the American Association for Advancement of Science (AAAS), and the Society for Optics and Photonics Technology (SPIE).", "token2charspan": [[0, 2], [3, 6], [7, 11], [12, 19], [20, 21], [22, 28], [29, 31], [32, 35], [36, 47], [48, 51], [52, 61], [62, 71], [72, 73], [73, 76], [76, 77], [77, 78], [79, 82], [83, 92], [93, 95], [96, 106], [107, 110], [111, 122], [123, 132], [133, 134], [134, 138], [138, 139], [139, 140], [141, 144], [145, 158], [159, 170], [171, 174], [175, 182], [183, 194], [195, 196], [196, 200], [200, 201], [201, 202], [203, 206], [207, 218], [219, 222], [223, 226], [227, 238], [239, 241], [242, 252], [253, 265], [266, 267], [267, 271], [271, 272], [272, 273], [274, 277], [278, 286], [287, 298], [299, 302], [303, 314], [315, 317], [318, 325], [326, 327], [327, 331], [331, 332], [332, 333], [334, 337], [338, 341], [342, 349], [350, 353], [354, 360], [361, 364], [365, 374], [375, 385], [386, 387], [387, 391], [391, 392], [392, 393]]}
{"doc_key": "ai-dev-317", "ner": [[3, 3, "field"], [0, 17, "field"], [4, 31, "field"], [47, 53, "task"]], "ner_mapping_to_source": [1, 2, 3, 4], "relations": [[3, 3, 4, 31, "named", "", false, false], [4, 31, 47, 53, "related-to", "", true, false]], "relations_mapping_to_source": [1, 2], "sentence": ["Machine", "learning", "and", "data", "mining", "often", "use", "the", "same", "methods", "and", "overlap", "significantly", ",", "but", "while", "machine", "learning", "focuses", "on", "prediction", "based", "on", "known", "properties", "learned", "from", "training", "data", ",", "data", "mining", "focuses", "on", "discovering", "(", "previously", ")", "unknown", "properties", "in", "the", "data", "(", "this", "is", "the", "knowledge", "discovery", "analysis", "stage", "of", "database", "discovery", ")", "."], "sentence-detokenized": "Machine learning and data mining often use the same methods and overlap significantly, but while machine learning focuses on prediction based on known properties learned from training data, data mining focuses on discovering (previously) unknown properties in the data (this is the knowledge discovery analysis stage of database discovery).", "token2charspan": [[0, 7], [8, 16], [17, 20], [21, 25], [26, 32], [33, 38], [39, 42], [43, 46], [47, 51], [52, 59], [60, 63], [64, 71], [72, 85], [85, 86], [87, 90], [91, 96], [97, 104], [105, 113], [114, 121], [122, 124], [125, 135], [136, 141], [142, 144], [145, 150], [151, 161], [162, 169], [170, 174], [175, 183], [184, 188], [188, 189], [190, 194], [195, 201], [202, 209], [210, 212], [213, 224], [225, 226], [226, 236], [236, 237], [238, 245], [246, 256], [257, 259], [260, 263], [264, 268], [269, 270], [270, 274], [275, 277], [278, 281], [282, 291], [292, 301], [302, 310], [311, 316], [317, 319], [320, 328], [329, 338], [338, 339], [339, 340]]}
{"doc_key": "ai-dev-318", "ner": [[0, 0, "product"], [4, 4, "programlang"], [11, 11, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[0, 0, 4, 4, "general-affiliation", "", false, false], [0, 0, 4, 4, "related-to", "runs_on", true, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Indy", "is", "written", "in", "Java", "and", "therefore", "runs", "on", "most", "modern", "operating", "systems", "."], "sentence-detokenized": "Indy is written in Java and therefore runs on most modern operating systems.", "token2charspan": [[0, 4], [5, 7], [8, 15], [16, 18], [19, 23], [24, 27], [28, 37], [38, 42], [43, 45], [46, 50], [51, 57], [58, 67], [68, 75], [75, 76]]}
{"doc_key": "ai-dev-319", "ner": [[0, 0, "algorithm"], [5, 7, "algorithm"], [9, 9, "algorithm"], [15, 17, "algorithm"], [19, 19, "algorithm"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[0, 0, 5, 7, "type-of", "", true, false], [9, 9, 5, 7, "named", "", false, false], [15, 17, 5, 7, "type-of", "", true, false], [19, 19, 15, 17, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3], "sentence": ["NMF", "is", "an", "instance", "of", "non-negative", "quadratic", "programming", "(", "NQP", ")", ",", "as", "is", "the", "support", "vector", "machine", "(", "SVM", ")", "."], "sentence-detokenized": "NMF is an instance of non-negative quadratic programming (NQP), as is the support vector machine (SVM).", "token2charspan": [[0, 3], [4, 6], [7, 9], [10, 18], [19, 21], [22, 34], [35, 44], [45, 56], [57, 58], [58, 61], [61, 62], [62, 63], [64, 66], [67, 69], [70, 73], [74, 81], [82, 88], [89, 96], [97, 98], [98, 101], [101, 102], [102, 103]]}
{"doc_key": "ai-dev-320", "ner": [[8, 9, "misc"], [12, 14, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[8, 9, 12, 14, "usage", "", true, false]], "relations_mapping_to_source": [0], "sentence": ["The", "method", "is", "based", "on", "the", "estimation", "of", "conditional", "probabilities", "using", "the", "non-parametric", "maximum", "likelihood", "method", "leading", "to"], "sentence-detokenized": "The method is based on the estimation of conditional probabilities using the non-parametric maximum likelihood method leading to", "token2charspan": [[0, 3], [4, 10], [11, 13], [14, 19], [20, 22], [23, 26], [27, 37], [38, 40], [41, 52], [53, 66], [67, 72], [73, 76], [77, 91], [92, 99], [100, 110], [111, 117], [118, 125], [126, 128]]}
{"doc_key": "ai-dev-321", "ner": [[8, 8, "algorithm"], [10, 13, "algorithm"], [15, 18, "metrics"], [20, 20, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "basic", "concepts", "involved", "in", "spectral", "estimation", "include", "autocorrelation", ",", "multi", "-D", "Fourier", "transform", ",", "root", "mean", "square", "error", "and", "entropy", "."], "sentence-detokenized": "The basic concepts involved in spectral estimation include autocorrelation, multi-D Fourier transform, root mean square error and entropy.", "token2charspan": [[0, 3], [4, 9], [10, 18], [19, 27], [28, 30], [31, 39], [40, 50], [51, 58], [59, 74], [74, 75], [76, 81], [81, 83], [84, 91], [92, 101], [101, 102], [103, 107], [108, 112], [113, 119], [120, 125], [126, 129], [130, 137], [137, 138]]}
{"doc_key": "ai-dev-322", "ner": [[4, 5, "algorithm"], [10, 10, "field"], [12, 12, "algorithm"], [14, 16, "algorithm"], [18, 19, "task"], [21, 23, "field"], [25, 26, "task"], [28, 29, "task"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 6, 7, 8], "relations": [[4, 5, 10, 10, "part-of", "", false, false], [4, 5, 12, 12, "part-of", "", false, false], [4, 5, 14, 16, "part-of", "", false, false], [4, 5, 18, 19, "part-of", "", false, false], [4, 5, 21, 23, "part-of", "", false, false], [4, 5, 25, 26, "part-of", "", false, false], [4, 5, 28, 29, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 5, 6, 7], "sentence": ["The", "application", "areas", "of", "kernel", "methods", "are", "diverse", "and", "include", "geostatistics", ",", "kriging", ",", "inverse", "distance", "weighting", ",", "3D", "reconstruction", ",", "bioinformatics", ",", "chemoinformatics", ",", "information", "extraction", "and", "handwriting", "recognition", "."], "sentence-detokenized": "The application areas of kernel methods are diverse and include geostatistics, kriging, inverse distance weighting, 3D reconstruction, bioinformatics, chemoinformatics, information extraction and handwriting recognition.", "token2charspan": [[0, 3], [4, 15], [16, 21], [22, 24], [25, 31], [32, 39], [40, 43], [44, 51], [52, 55], [56, 63], [64, 77], [77, 78], [79, 86], [86, 87], [88, 95], [96, 104], [105, 114], [114, 115], [116, 118], [119, 133], [133, 134], [135, 149], [149, 150], [151, 167], [167, 168], [169, 180], [181, 191], [192, 195], [196, 207], [208, 219], [219, 220]]}
{"doc_key": "ai-dev-323", "ner": [[13, 13, "organisation"], [15, 19, "product"], [21, 21, "product"], [24, 24, "organisation"], [26, 30, "product"], [32, 32, "product"], [36, 36, "product"], [39, 40, "product"], [43, 44, "product"], [47, 54, "product"], [53, 53, "product"], [56, 57, "product"], [62, 67, "product"], [71, 72, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], "relations": [[15, 19, 13, 13, "artifact", "", false, false], [15, 19, 36, 36, "compare", "", false, false], [15, 19, 39, 40, "compare", "", false, false], [15, 19, 43, 44, "compare", "", false, false], [15, 19, 47, 54, "compare", "", false, false], [15, 19, 53, 53, "compare", "", false, false], [15, 19, 56, 57, "compare", "", false, false], [15, 19, 62, 67, "compare", "", false, false], [15, 19, 71, 72, "compare", "", false, false], [21, 21, 15, 19, "named", "", false, false], [26, 30, 24, 24, "artifact", "", false, false], [26, 30, 36, 36, "compare", "", false, false], [26, 30, 39, 40, "compare", "", false, false], [26, 30, 43, 44, "compare", "", false, false], [26, 30, 47, 54, "compare", "", false, false], [26, 30, 53, 53, "compare", "", false, false], [26, 30, 56, 57, "compare", "", false, false], [26, 30, 62, 67, "compare", "", false, false], [26, 30, 71, 72, "compare", "", false, false], [32, 32, 26, 30, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "sentence": ["Robots", "can", "be", "autonomous", "or", "semi-autonomous", "and", "range", "from", "humanoids", ",", "such", "as", "Honda", "'s", "Advanced", "Step", "in", "Innovative", "Mobility", "(", "ASIMO", ")", "and", "TOSY", "'s", "TOSY", "Ping", "Pong", "Playing", "Robot", "(", "TOPIO", ")", ",", "to", "industrial", "robots", ",", "medical", "surgery", "robots", ",", "patient", "assistance", "robots", ",", "dog", "therapy", "robots", ",", "collectively", "programmed", "swarm", "robots", ",", "UAV", "drones", ",", "such", "as", "the", "General", "Atomics", "MQ", "-", "1", "Predator", ",", "and", "even", "microscopic", "nanorobots", "."], "sentence-detokenized": "Robots can be autonomous or semi-autonomous and range from humanoids, such as Honda's Advanced Step in Innovative Mobility (ASIMO) and TOSY's TOSY Ping Pong Playing Robot (TOPIO), to industrial robots, medical surgery robots, patient assistance robots, dog therapy robots, collectively programmed swarm robots, UAV drones, such as the General Atomics MQ-1 Predator, and even microscopic nanorobots.", "token2charspan": [[0, 6], [7, 10], [11, 13], [14, 24], [25, 27], [28, 43], [44, 47], [48, 53], [54, 58], [59, 68], [68, 69], [70, 74], [75, 77], [78, 83], [83, 85], [86, 94], [95, 99], [100, 102], [103, 113], [114, 122], [123, 124], [124, 129], [129, 130], [131, 134], [135, 139], [139, 141], [142, 146], [147, 151], [152, 156], [157, 164], [165, 170], [171, 172], [172, 177], [177, 178], [178, 179], [180, 182], [183, 193], [194, 200], [200, 201], [202, 209], [210, 217], [218, 224], [224, 225], [226, 233], [234, 244], [245, 251], [251, 252], [253, 256], [257, 264], [265, 271], [271, 272], [273, 285], [286, 296], [297, 302], [303, 309], [309, 310], [311, 314], [315, 321], [321, 322], [323, 327], [328, 330], [331, 334], [335, 342], [343, 350], [351, 353], [353, 354], [354, 355], [356, 364], [364, 365], [366, 369], [370, 374], [375, 386], [387, 397], [397, 398]]}
{"doc_key": "ai-dev-324", "ner": [[0, 0, "product"], [2, 4, "product"], [9, 16, "university"], [18, 19, "researcher"], [21, 22, "researcher"], [24, 25, "researcher"], [27, 28, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[0, 0, 18, 19, "artifact", "", false, false], [0, 0, 21, 22, "artifact", "", false, false], [0, 0, 24, 25, "artifact", "", false, false], [0, 0, 27, 28, "artifact", "", false, false], [2, 4, 18, 19, "artifact", "", false, false], [2, 4, 21, 22, "artifact", "", false, false], [2, 4, 24, 25, "artifact", "", false, false], [2, 4, 27, 28, "artifact", "", false, false], [18, 19, 9, 16, "physical", "", false, false], [21, 22, 9, 16, "physical", "", false, false], [24, 25, 9, 16, "physical", "", false, false], [27, 28, 9, 16, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "sentence": ["Freddy", "and", "Freddy", "II", "were", "robots", "built", "at", "the", "University", "of", "Edinburgh", "'s", "School", "of", "Computer", "Science", "by", "Pat", "Ambler", ",", "Robin", "Popplestone", ",", "Austin", "Tate", "and", "Donald", "Mitchie", "and", "were", "capable", "of", "assembling", "wooden", "blocks", "in", "a", "matter", "of", "hours", "."], "sentence-detokenized": "Freddy and Freddy II were robots built at the University of Edinburgh's School of Computer Science by Pat Ambler, Robin Popplestone, Austin Tate and Donald Mitchie and were capable of assembling wooden blocks in a matter of hours.", "token2charspan": [[0, 6], [7, 10], [11, 17], [18, 20], [21, 25], [26, 32], [33, 38], [39, 41], [42, 45], [46, 56], [57, 59], [60, 69], [69, 71], [72, 78], [79, 81], [82, 90], [91, 98], [99, 101], [102, 105], [106, 112], [112, 113], [114, 119], [120, 131], [131, 132], [133, 139], [140, 144], [145, 148], [149, 155], [156, 163], [164, 167], [168, 172], [173, 180], [181, 183], [184, 194], [195, 201], [202, 208], [209, 211], [212, 213], [214, 220], [221, 223], [224, 229], [229, 230]]}
{"doc_key": "ai-dev-325", "ner": [[6, 6, "location"], [8, 8, "country"], [16, 16, "country"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[6, 6, 8, 8, "physical", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["He", "spent", "his", "childhood", "years", "in", "Paris", ",", "France", ",", "where", "his", "parents", "had", "emigrated", "from", "Lithuania", "in", "the", "early", "1920s", "."], "sentence-detokenized": "He spent his childhood years in Paris, France, where his parents had emigrated from Lithuania in the early 1920s.", "token2charspan": [[0, 2], [3, 8], [9, 12], [13, 22], [23, 28], [29, 31], [32, 37], [37, 38], [39, 45], [45, 46], [47, 52], [53, 56], [57, 64], [65, 68], [69, 78], [79, 83], [84, 93], [94, 96], [97, 100], [101, 106], [107, 112], [112, 113]]}
{"doc_key": "ai-dev-326", "ner": [[2, 3, "researcher"], [6, 11, "misc"], [12, 15, "organisation"], [17, 19, "university"], [28, 32, "university"], [39, 40, "university"], [43, 45, "university"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[2, 3, 6, 11, "role", "", false, false], [2, 3, 17, 19, "physical", "", false, false], [2, 3, 28, 32, "role", "", false, false], [2, 3, 39, 40, "role", "", false, false], [2, 3, 43, 45, "role", "", false, false], [6, 11, 12, 15, "part-of", "", false, false], [12, 15, 17, 19, "part-of", "", false, false], [39, 40, 28, 32, "part-of", "", false, false], [43, 45, 28, 32, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["Previously", ",", "Dr.", "Paulos", "held", "the", "Cooper-", "Siegel", "Associate", "Professorship", "in", "the", "School", "of", "Computer", "Science", "at", "Carnegie", "Mellon", "University", ",", "where", "he", "was", "a", "professor", "in", "the", "Human", "-", "Computer", "Interaction", "Institute", ",", "with", "courtesy", "appointments", "in", "the", "Robotics", "Institute", "and", "the", "Entertainment", "Technology", "Center", "."], "sentence-detokenized": "Previously, Dr. Paulos held the Cooper-Siegel Associate Professorship in the School of Computer Science at Carnegie Mellon University, where he was a professor in the Human-Computer Interaction Institute, with courtesy appointments in the Robotics Institute and the Entertainment Technology Center.", "token2charspan": [[0, 10], [10, 11], [12, 15], [16, 22], [23, 27], [28, 31], [32, 39], [39, 45], [46, 55], [56, 69], [70, 72], [73, 76], [77, 83], [84, 86], [87, 95], [96, 103], [104, 106], [107, 115], [116, 122], [123, 133], [133, 134], [135, 140], [141, 143], [144, 147], [148, 149], [150, 159], [160, 162], [163, 166], [167, 172], [172, 173], [173, 181], [182, 193], [194, 203], [203, 204], [205, 209], [210, 218], [219, 231], [232, 234], [235, 238], [239, 247], [248, 257], [258, 261], [262, 265], [266, 279], [280, 290], [291, 297], [297, 298]]}
{"doc_key": "ai-dev-327", "ner": [[3, 4, "researcher"], [6, 7, "university"], [10, 10, "product"], [14, 22, "product"], [11, 28, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4], "relations": [[3, 4, 6, 7, "physical", "", false, false], [3, 4, 6, 7, "role", "", false, false], [10, 10, 3, 4, "artifact", "", false, false], [10, 10, 14, 22, "type-of", "", false, false], [10, 10, 11, 28, "related-to", "", true, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["In", "1969", ",", "Victor", "Scheinman", "of", "Stanford", "University", "invented", "the", "Stanford", "Arm", ",", "a", "6", "-", "axis", ",", "fully", "electric", ",", "articulated", "robot", "designed", "to", "enable", "an", "arm", "solution", "."], "sentence-detokenized": "In 1969, Victor Scheinman of Stanford University invented the Stanford Arm, a 6-axis, fully electric, articulated robot designed to enable an arm solution.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 15], [16, 25], [26, 28], [29, 37], [38, 48], [49, 57], [58, 61], [62, 70], [71, 74], [74, 75], [76, 77], [78, 79], [79, 80], [80, 84], [84, 85], [86, 91], [92, 100], [100, 101], [102, 113], [114, 119], [120, 128], [129, 131], [132, 138], [139, 141], [142, 145], [146, 154], [154, 155]]}
{"doc_key": "ai-dev-328", "ner": [[5, 5, "product"], [15, 16, "field"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[5, 5, 15, 16, "related-to", "", false, false], [5, 5, 18, 19, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["The", "creation", "and", "implementation", "of", "chatbots", "is", "still", "an", "emerging", "field", ",", "closely", "related", "to", "artificial", "intelligence", "and", "machine", "learning", ",", "so", "the", "solutions", "on", "offer", ",", "while", "having", "obvious", "advantages", ",", "have", "some", "important", "limitations", "in", "terms", "of", "functionalities", "and", "use", "cases", "."], "sentence-detokenized": "The creation and implementation of chatbots is still an emerging field, closely related to artificial intelligence and machine learning, so the solutions on offer, while having obvious advantages, have some important limitations in terms of functionalities and use cases.", "token2charspan": [[0, 3], [4, 12], [13, 16], [17, 31], [32, 34], [35, 43], [44, 46], [47, 52], [53, 55], [56, 64], [65, 70], [70, 71], [72, 79], [80, 87], [88, 90], [91, 101], [102, 114], [115, 118], [119, 126], [127, 135], [135, 136], [137, 139], [140, 143], [144, 153], [154, 156], [157, 162], [162, 163], [164, 169], [170, 176], [177, 184], [185, 195], [195, 196], [197, 201], [202, 206], [207, 216], [217, 228], [229, 231], [232, 237], [238, 240], [241, 256], [257, 260], [261, 264], [265, 270], [270, 271]]}
{"doc_key": "ai-dev-329", "ner": [[7, 9, "university"], [11, 12, "product"], [22, 25, "task"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[11, 12, 7, 9, "part-of", "", true, false], [22, 25, 11, 12, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "terms", "of", "freely", "available", "resources", ",", "Carnegie", "Mellon", "University", "'s", "Sphinx", "toolkit", "is", "a", "place", "to", "start", "both", "to", "learn", "about", "speech", "recognition", "and", "to", "start", "experimenting", "."], "sentence-detokenized": "In terms of freely available resources, Carnegie Mellon University's Sphinx toolkit is a place to start both to learn about speech recognition and to start experimenting.", "token2charspan": [[0, 2], [3, 8], [9, 11], [12, 18], [19, 28], [29, 38], [38, 39], [40, 48], [49, 55], [56, 66], [66, 68], [69, 75], [76, 83], [84, 86], [87, 88], [89, 94], [95, 97], [98, 103], [104, 108], [109, 111], [112, 117], [118, 123], [124, 130], [131, 142], [143, 146], [147, 149], [150, 155], [156, 169], [169, 170]]}
{"doc_key": "ai-dev-330", "ner": [[0, 3, "misc"], [13, 22, "misc"], [19, 24, "misc"], [26, 26, "university"], [28, 28, "location"], [30, 30, "country"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 3, 13, 22, "temporal", "", false, false], [19, 24, 13, 22, "named", "", false, false], [19, 24, 28, 28, "physical", "", false, false], [26, 26, 19, 24, "role", "", false, false], [28, 28, 30, 30, "physical", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "official", "RoboCup", "competition", "was", "preceded", "by", "the", "first", "(", "often", "unrecognised", ")", "international", "Micro", "Robot", "World", "Cup", "(", "MIROSOT", ")", "football", "tournament", ",", "organised", "by", "KAIST", "in", "Taejon", ",", "Korea", "in", "November", "1996", "."], "sentence-detokenized": "The official RoboCup competition was preceded by the first (often unrecognised) international Micro Robot World Cup (MIROSOT) football tournament, organised by KAIST in Taejon, Korea in November 1996.", "token2charspan": [[0, 3], [4, 12], [13, 20], [21, 32], [33, 36], [37, 45], [46, 48], [49, 52], [53, 58], [59, 60], [60, 65], [66, 78], [78, 79], [80, 93], [94, 99], [100, 105], [106, 111], [112, 115], [116, 117], [117, 124], [124, 125], [126, 134], [135, 145], [145, 146], [147, 156], [157, 159], [160, 165], [166, 168], [169, 175], [175, 176], [177, 182], [183, 185], [186, 194], [195, 199], [199, 200]]}
{"doc_key": "ai-dev-331", "ner": [[5, 6, "metrics"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["In", "addition", "to", "the", "standard", "hinge", "loss", "calculation", "(", "1-", "yf", "(", "x", ")", ")", "_", "+", "/", "math", "for", "labeled", "data", ",", "a", "math", "loss", "function", "(", "-", "1", "|", "f", "(", "x", ")", "|", ")", "_", "+", "/", "math", "is", "introduced", "for", "unlabeled", "data", "by", "letting", "mathy", "=\\", "operatorname", "{", "sign", "}", "{", "f", "(", "x", ")", "}", "/", "math", "."], "sentence-detokenized": "In addition to the standard hinge loss calculation (1-yf (x)) _ + / math for labeled data, a math loss function (-1 | f (x) |) _ + / math is introduced for unlabeled data by letting mathy =\\ operatorname {sign} {f (x)} / math.", "token2charspan": [[0, 2], [3, 11], [12, 14], [15, 18], [19, 27], [28, 33], [34, 38], [39, 50], [51, 52], [52, 54], [54, 56], [57, 58], [58, 59], [59, 60], [60, 61], [62, 63], [64, 65], [66, 67], [68, 72], [73, 76], [77, 84], [85, 89], [89, 90], [91, 92], [93, 97], [98, 102], [103, 111], [112, 113], [113, 114], [114, 115], [116, 117], [118, 119], [120, 121], [121, 122], [122, 123], [124, 125], [125, 126], [127, 128], [129, 130], [131, 132], [133, 137], [138, 140], [141, 151], [152, 155], [156, 165], [166, 170], [171, 173], [174, 181], [182, 187], [188, 190], [191, 203], [204, 205], [205, 209], [209, 210], [211, 212], [212, 213], [214, 215], [215, 216], [216, 217], [217, 218], [219, 220], [221, 225], [225, 226]]}
{"doc_key": "ai-dev-332", "ner": [[3, 3, "misc"], [9, 12, "metrics"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 3, 9, 12, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "particular", ",", "RLS", "is", "designed", "to", "minimize", "the", "root", "mean", "square", "error", "between", "the", "predicted", "values", "and", "the", "TRUE", "labels", ",", "subject", "to", "regularization", "."], "sentence-detokenized": "In particular, RLS is designed to minimize the root mean square error between the predicted values and the TRUE labels, subject to regularization.", "token2charspan": [[0, 2], [3, 13], [13, 14], [15, 18], [19, 21], [22, 30], [31, 33], [34, 42], [43, 46], [47, 51], [52, 56], [57, 63], [64, 69], [70, 77], [78, 81], [82, 91], [92, 98], [99, 102], [103, 106], [107, 111], [112, 118], [118, 119], [120, 127], [128, 130], [131, 145], [145, 146]]}
{"doc_key": "ai-dev-333", "ner": [[4, 6, "algorithm"], [9, 10, "algorithm"]], "ner_mapping_to_source": [0, 1], "relations": [[4, 6, 9, 10, "related-to", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Essentially", ",", "it", "combines", "maximum", "likelihood", "estimation", "with", "a", "regularisation", "procedure", "that", "favours", "simpler", "models", "over", "more", "complex", "models", "."], "sentence-detokenized": "Essentially, it combines maximum likelihood estimation with a regularisation procedure that favours simpler models over more complex models.", "token2charspan": [[0, 11], [11, 12], [13, 15], [16, 24], [25, 32], [33, 43], [44, 54], [55, 59], [60, 61], [62, 76], [77, 86], [87, 91], [92, 99], [100, 107], [108, 114], [115, 119], [120, 124], [125, 132], [133, 139], [139, 140]]}
{"doc_key": "ai-dev-334", "ner": [[0, 4, "metrics"], [10, 10, "metrics"], [12, 12, "metrics"], [15, 16, "misc"], [19, 20, "misc"], [30, 32, "algorithm"], [38, 40, "misc"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6], "relations": [[10, 10, 0, 4, "named", "", false, false], [12, 12, 0, 4, "named", "", false, false], [15, 16, 19, 20, "related-to", "", false, false], [15, 16, 30, 32, "related-to", "ratio", false, false], [30, 32, 38, 40, "related-to", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["The", "true", "-", "positive", "rate", "is", "also", "known", "as", "the", "sensitivity", ",", "recall", "or", "mathematical", "detection", "probability", "at", "the", "discrimination", "threshold", ")", "of", "the", "y", "-axis", "detection", "probability", "to", "the", "cumulative", "distribution", "function", "of", "the", "x", "-", "axis", "false", "alarm", "probability", "."], "sentence-detokenized": "The true-positive rate is also known as the sensitivity, recall or mathematical detection probability at the discrimination threshold) of the y-axis detection probability to the cumulative distribution function of the x-axis false alarm probability.", "token2charspan": [[0, 3], [4, 8], [8, 9], [9, 17], [18, 22], [23, 25], [26, 30], [31, 36], [37, 39], [40, 43], [44, 55], [55, 56], [57, 63], [64, 66], [67, 79], [80, 89], [90, 101], [102, 104], [105, 108], [109, 123], [124, 133], [133, 134], [135, 137], [138, 141], [142, 143], [143, 148], [149, 158], [159, 170], [171, 173], [174, 177], [178, 188], [189, 201], [202, 210], [211, 213], [214, 217], [218, 219], [219, 220], [220, 224], [225, 230], [231, 236], [237, 248], [248, 249]]}
{"doc_key": "ai-dev-335", "ner": [[1, 1, "misc"], [3, 4, "product"]], "ner_mapping_to_source": [0, 1], "relations": [[3, 4, 1, 1, "general-affiliation", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["In", "English", ",", "Word", "Net", "is", "an", "example", "of", "a", "semantic", "network", "."], "sentence-detokenized": "In English, WordNet is an example of a semantic network.", "token2charspan": [[0, 2], [3, 10], [10, 11], [12, 16], [16, 19], [20, 22], [23, 25], [26, 33], [34, 36], [37, 38], [39, 47], [48, 55], [55, 56]]}
{"doc_key": "ai-dev-336", "ner": [[5, 7, "product"], [11, 12, "product"], [25, 26, "misc"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[25, 26, 5, 7, "usage", "", false, false], [25, 26, 11, 12, "usage", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["Long", "-", "term", "use", "of", "speech", "recognition", "software", "in", "conjunction", "with", "word", "processors", "has", "shown", "benefits", "for", "short", "-", "term", "memory", "consolidation", "in", "patients", "with", "cerebral", "AVM", "who", "have", "been", "treated", "by", "resection", "."], "sentence-detokenized": "Long-term use of speech recognition software in conjunction with word processors has shown benefits for short-term memory consolidation in patients with cerebral AVM who have been treated by resection.", "token2charspan": [[0, 4], [4, 5], [5, 9], [10, 13], [14, 16], [17, 23], [24, 35], [36, 44], [45, 47], [48, 59], [60, 64], [65, 69], [70, 80], [81, 84], [85, 90], [91, 99], [100, 103], [104, 109], [109, 110], [110, 114], [115, 121], [122, 135], [136, 138], [139, 147], [148, 152], [153, 161], [162, 165], [166, 169], [170, 174], [175, 179], [180, 187], [188, 190], [191, 200], [200, 201]]}
{"doc_key": "ai-dev-337", "ner": [[8, 9, "researcher"], [11, 12, "researcher"], [14, 15, "researcher"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["The", "founding", "editors", "-", "in", "-", "chief", "were", "Ron", "Sun", ",", "Vasant", "Honavar", "and", "Gregg", "Oden", "(", "1999", "to", "2014", ")", "."], "sentence-detokenized": "The founding editors-in-chief were Ron Sun, Vasant Honavar and Gregg Oden (1999 to 2014).", "token2charspan": [[0, 3], [4, 12], [13, 20], [20, 21], [21, 23], [23, 24], [24, 29], [30, 34], [35, 38], [39, 42], [42, 43], [44, 50], [51, 58], [59, 62], [63, 68], [69, 73], [74, 75], [75, 79], [80, 82], [83, 87], [87, 88], [88, 89]]}
{"doc_key": "ai-dev-338", "ner": [[10, 11, "product"], [15, 17, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [[10, 11, 15, 17, "opposite", "", false, false]], "relations_mapping_to_source": [0], "sentence": ["Their", "\"", "parallel", "\"", "distinction", ",", "as", "opposed", "to", "a", "series", "manipulator", ",", "is", "that", "the", "end", "effector", "(", "or", "\"", "hand", "\"", ")", "of", "this", "link", "(", "or", "\"", "arm", "\"", ")", "is", "connected", "directly", "to", "it", "s", "base", "by", "a", "number", "of", "separate", "and", "independent", "links", "(", "usually", "three", "or", "six", ")", "operating", "simultaneously", "."], "sentence-detokenized": "Their \"parallel\" distinction, as opposed to a series manipulator, is that the end effector (or \"hand\") of this link (or \"arm\") is connected directly to its base by a number of separate and independent links (usually three or six) operating simultaneously.", "token2charspan": [[0, 5], [6, 7], [7, 15], [15, 16], [17, 28], [28, 29], [30, 32], [33, 40], [41, 43], [44, 45], [46, 52], [53, 64], [64, 65], [66, 68], [69, 73], [74, 77], [78, 81], [82, 90], [91, 92], [92, 94], [95, 96], [96, 100], [100, 101], [101, 102], [103, 105], [106, 110], [111, 115], [116, 117], [117, 119], [120, 121], [121, 124], [124, 125], [125, 126], [127, 129], [130, 139], [140, 148], [149, 151], [152, 154], [154, 155], [156, 160], [161, 163], [164, 165], [166, 172], [173, 175], [176, 184], [185, 188], [189, 200], [201, 206], [207, 208], [208, 215], [216, 221], [222, 224], [225, 228], [228, 229], [230, 239], [240, 254], [254, 255]]}
{"doc_key": "ai-dev-339", "ner": [[5, 9, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 24, "researcher"], [26, 27, "researcher"], [29, 30, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["His", "thesis", "advisor", "was", "Professor", "Cordell", "Green", ",", "and", "the", "thesis", "/", "oral", "committee", "consisted", "of", "Professors", "Edward", "Feigenbaum", ",", "Joshua", "Lederberg", ",", "Paul", "Cohen", ",", "Allen", "Newell", ",", "Herbert", "Simon", ",", "."], "sentence-detokenized": "His thesis advisor was Professor Cordell Green, and the thesis/oral committee consisted of Professors Edward Feigenbaum, Joshua Lederberg, Paul Cohen, Allen Newell, Herbert Simon,.", "token2charspan": [[0, 3], [4, 10], [11, 18], [19, 22], [23, 32], [33, 40], [41, 46], [46, 47], [48, 51], [52, 55], [56, 62], [62, 63], [63, 67], [68, 77], [78, 87], [88, 90], [91, 101], [102, 108], [109, 119], [119, 120], [121, 127], [128, 137], [137, 138], [139, 143], [144, 149], [149, 150], [151, 156], [157, 163], [163, 164], [165, 172], [173, 178], [178, 179], [179, 180]]}
{"doc_key": "ai-dev-340", "ner": [[4, 4, "metrics"], [7, 8, "metrics"], [11, 13, "metrics"], [15, 17, "metrics"], [19, 27, "metrics"], [28, 28, "metrics"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Such", "functions", "include", "mean", "squared", "error", ",", "mean", "squared", "error", ",", "mean", "absolute", "error", ",", "relative", "quadratic", "error", ",", "relative", "quadratic", "error", ",", "relative", "quadratic", "error", ",", "relative", "absolute", "error", "and", "others", "."], "sentence-detokenized": "Such functions include mean squared error, mean squared error, mean absolute error, relative quadratic error, relative quadratic error, relative quadratic error, relative absolute error and others.", "token2charspan": [[0, 4], [5, 14], [15, 22], [23, 27], [28, 35], [36, 41], [41, 42], [43, 47], [48, 55], [56, 61], [61, 62], [63, 67], [68, 76], [77, 82], [82, 83], [84, 92], [93, 102], [103, 108], [108, 109], [110, 118], [119, 128], [129, 134], [134, 135], [136, 144], [145, 154], [155, 160], [160, 161], [162, 170], [171, 179], [180, 185], [186, 189], [190, 196], [196, 197]]}
{"doc_key": "ai-dev-341", "ner": [[4, 4, "programlang"], [6, 6, "programlang"], [8, 8, "product"], [10, 10, "programlang"]], "ner_mapping_to_source": [0, 1, 2, 3], "relations": [], "relations_mapping_to_source": [], "sentence": ["There", "are", "links", "in", "Python", ",", "Java", "and", "MATLAB", "/", "OCTAVE", "."], "sentence-detokenized": "There are links in Python, Java and MATLAB / OCTAVE.", "token2charspan": [[0, 5], [6, 9], [10, 15], [16, 18], [19, 25], [25, 26], [27, 31], [32, 35], [36, 42], [43, 44], [45, 51], [51, 52]]}
{"doc_key": "ai-dev-342", "ner": [[1, 1, "product"]], "ner_mapping_to_source": [0], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "MATLAB", "implementation", "can", "be", "found", "on", "the", "website", "."], "sentence-detokenized": "A MATLAB implementation can be found on the website.", "token2charspan": [[0, 1], [2, 8], [9, 23], [24, 27], [28, 30], [31, 36], [37, 39], [40, 43], [44, 51], [51, 52]]}
{"doc_key": "ai-dev-343", "ner": [[0, 1, "researcher"], [9, 10, "field"], [14, 15, "researcher"], [17, 18, "researcher"], [20, 21, "researcher"], [23, 26, "researcher"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[9, 10, 0, 1, "origin", "", false, false], [9, 10, 14, 15, "origin", "", false, false], [9, 10, 17, 18, "origin", "", false, false], [9, 10, 20, 21, "origin", "", false, false], [9, 10, 23, 26, "origin", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["John", "McCarthy", "is", "one", "of", "the", "founding", "fathers", "of", "artificial", "intelligence", ",", "along", "with", "Alan", "Turing", ",", "Marvin", "Minsky", ",", "Allen", "Newell", "and", "Herbert", "A", ".", "Simon", "."], "sentence-detokenized": "John McCarthy is one of the founding fathers of artificial intelligence, along with Alan Turing, Marvin Minsky, Allen Newell and Herbert A. Simon.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 20], [21, 23], [24, 27], [28, 36], [37, 44], [45, 47], [48, 58], [59, 71], [71, 72], [73, 78], [79, 83], [84, 88], [89, 95], [95, 96], [97, 103], [104, 110], [110, 111], [112, 117], [118, 124], [125, 128], [129, 136], [137, 138], [138, 139], [140, 145], [145, 146]]}
{"doc_key": "ai-dev-344", "ner": [[10, 12, "product"], [19, 20, "misc"]], "ner_mapping_to_source": [0, 1], "relations": [], "relations_mapping_to_source": [], "sentence": ["A", "parallel", "manipulator", "is", "a", "mechanical", "system", "that", "uses", "multiple", "manipulators", "in", "series", "to", "support", "a", "single", "platform", "or", "end", "effect", "."], "sentence-detokenized": "A parallel manipulator is a mechanical system that uses multiple manipulators in series to support a single platform or end effect.", "token2charspan": [[0, 1], [2, 10], [11, 22], [23, 25], [26, 27], [28, 38], [39, 45], [46, 50], [51, 55], [56, 64], [65, 77], [78, 80], [81, 87], [88, 90], [91, 98], [99, 100], [101, 107], [108, 116], [117, 119], [120, 123], [124, 130], [130, 131]]}
{"doc_key": "ai-dev-345", "ner": [[0, 0, "product"], [3, 4, "task"], [7, 7, "product"], [9, 15, "product"], [26, 26, "misc"], [29, 29, "misc"], [32, 35, "misc"], [36, 40, "task"], [44, 47, "product"], [41, 51, "product"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "relations": [[7, 7, 0, 0, "part-of", "", false, false], [7, 7, 3, 4, "type-of", "", false, false], [9, 15, 7, 7, "named", "", false, false], [26, 26, 7, 7, "part-of", "", false, false], [29, 29, 7, 7, "part-of", "", false, false], [32, 35, 7, 7, "part-of", "", false, false], [36, 40, 7, 7, "part-of", "", false, false], [44, 47, 7, 7, "part-of", "", false, false], [41, 51, 7, 7, "part-of", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4, 5, 6, 7, 8], "sentence": ["GATE", "includes", "an", "information", "extraction", "system", "called", "ANNIE", "(", "A", "Nearly", "-", "New", "Information", "Extraction", "System", ")", ",", "which", "is", "a", "set", "of", "modules", "comprising", "a", "tokenizer", ",", "a", "gazetteer", ",", "a", "sentence", "separator", ",", "a", "part", "-", "of", "-", "speech", "tagger", ",", "a", "named", "entity", "recognition", "transducer", "and", "a", "coreference", "tagger", "."], "sentence-detokenized": "GATE includes an information extraction system called ANNIE (A Nearly-New Information Extraction System), which is a set of modules comprising a tokenizer, a gazetteer, a sentence separator, a part-of-speech tagger, a named entity recognition transducer and a coreference tagger.", "token2charspan": [[0, 4], [5, 13], [14, 16], [17, 28], [29, 39], [40, 46], [47, 53], [54, 59], [60, 61], [61, 62], [63, 69], [69, 70], [70, 73], [74, 85], [86, 96], [97, 103], [103, 104], [104, 105], [106, 111], [112, 114], [115, 116], [117, 120], [121, 123], [124, 131], [132, 142], [143, 144], [145, 154], [154, 155], [156, 157], [158, 167], [167, 168], [169, 170], [171, 179], [180, 189], [189, 190], [191, 192], [193, 197], [197, 198], [198, 200], [200, 201], [201, 207], [208, 214], [214, 215], [216, 217], [218, 223], [224, 230], [231, 242], [243, 253], [254, 257], [258, 259], [260, 271], [272, 278], [278, 279]]}
{"doc_key": "ai-dev-346", "ner": [[3, 7, "university"], [15, 16, "country"], [24, 27, "person"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["He", "graduated", "from", "Moscow", "State", "University", ",", "and", "in", "November", "1978", "he", "went", "to", "the", "United", "States", ",", "thanks", "to", "the", "personal", "intervention", "of", "Senator", "Edward", "M.", "Kennedy", "..."], "sentence-detokenized": "He graduated from Moscow State University, and in November 1978 he went to the United States, thanks to the personal intervention of Senator Edward M. Kennedy...", "token2charspan": [[0, 2], [3, 12], [13, 17], [18, 24], [25, 30], [31, 41], [41, 42], [43, 46], [47, 49], [50, 58], [59, 63], [64, 66], [67, 71], [72, 74], [75, 78], [79, 85], [86, 92], [92, 93], [94, 100], [101, 103], [104, 107], [108, 116], [117, 129], [130, 132], [133, 140], [141, 147], [148, 150], [151, 158], [158, 161]]}
{"doc_key": "ai-dev-347", "ner": [[4, 6, "organisation"], [8, 13, "misc"], [18, 19, "field"]], "ner_mapping_to_source": [0, 1, 2], "relations": [[4, 6, 8, 13, "win-defeat", "", false, false], [8, 13, 18, 19, "topic", "", false, false]], "relations_mapping_to_source": [0, 1], "sentence": ["In", "2017", ",", "the", "DeepMind", "AlphaGo", "team", "received", "the", "inaugural", "IJCAI", "Marvin", "Minsky", "Medal", "for", "outstanding", "achievement", "in", "artificial", "intelligence", "."], "sentence-detokenized": "In 2017, the DeepMind AlphaGo team received the inaugural IJCAI Marvin Minsky Medal for outstanding achievement in artificial intelligence.", "token2charspan": [[0, 2], [3, 7], [7, 8], [9, 12], [13, 21], [22, 29], [30, 34], [35, 43], [44, 47], [48, 57], [58, 63], [64, 70], [71, 77], [78, 83], [84, 87], [88, 99], [100, 111], [112, 114], [115, 125], [126, 138], [138, 139]]}
{"doc_key": "ai-dev-348", "ner": [[4, 7, "misc"], [9, 14, "misc"], [23, 28, "misc"], [29, 29, "misc"], [34, 34, "misc"]], "ner_mapping_to_source": [0, 2, 3, 4, 5], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "ways", "in", "which", "anomalous", "propagation", "occurs", "are", "through", "troposcatter", "causing", "irregularities", "in", "the", "troposphere", ",", "scattering", "due", "to", "meteorites", ",", "refraction", "in", "ionised", "regions", "and", "layers", "of", "the", "ionosphere", "and", "reflection", "from", "the", "ionosphere", "."], "sentence-detokenized": "Other ways in which anomalous propagation occurs are through troposcatter causing irregularities in the troposphere, scattering due to meteorites, refraction in ionised regions and layers of the ionosphere and reflection from the ionosphere.", "token2charspan": [[0, 5], [6, 10], [11, 13], [14, 19], [20, 29], [30, 41], [42, 48], [49, 52], [53, 60], [61, 73], [74, 81], [82, 96], [97, 99], [100, 103], [104, 115], [115, 116], [117, 127], [128, 131], [132, 134], [135, 145], [145, 146], [147, 157], [158, 160], [161, 168], [169, 176], [177, 180], [181, 187], [188, 190], [191, 194], [195, 205], [206, 209], [210, 220], [221, 225], [226, 229], [230, 240], [240, 241]]}
{"doc_key": "ai-dev-349", "ner": [[0, 2, "field"], [4, 6, "field"], [10, 10, "field"], [12, 13, "field"], [15, 16, "field"], [18, 20, "field"]], "ner_mapping_to_source": [0, 1, 2, 3, 4, 5], "relations": [[0, 2, 10, 10, "part-of", "", false, false], [0, 2, 12, 13, "part-of", "", false, false], [0, 2, 15, 16, "part-of", "", false, false], [0, 2, 18, 20, "part-of", "", false, false], [4, 6, 0, 2, "named", "", false, false]], "relations_mapping_to_source": [0, 1, 2, 3, 4], "sentence": ["Natural", "language", "processing", "(", "NLP", ")", "is", "a", "subfield", "of", "linguistics", ",", "computer", "science", ",", "information", "engineering", "and", "artificial", "intelligence", "that", "deals", "with", "the", "interactions", "between", "computers", "and", "human", "(", "natural", ")", "languages", ",", "in", "particular", "how", "computers", "can", "be", "programmed", "to", "process", "and", "analyse", "large", "amounts", "of", "data", "in", "natural", "language", "."], "sentence-detokenized": "Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering and artificial intelligence that deals with the interactions between computers and human (natural) languages, in particular how computers can be programmed to process and analyse large amounts of data in natural language.", "token2charspan": [[0, 7], [8, 16], [17, 27], [28, 29], [29, 32], [32, 33], [34, 36], [37, 38], [39, 47], [48, 50], [51, 62], [62, 63], [64, 72], [73, 80], [80, 81], [82, 93], [94, 105], [106, 109], [110, 120], [121, 133], [134, 138], [139, 144], [145, 149], [150, 153], [154, 166], [167, 174], [175, 184], [185, 188], [189, 194], [195, 196], [196, 203], [203, 204], [205, 214], [214, 215], [216, 218], [219, 229], [230, 233], [234, 243], [244, 247], [248, 250], [251, 261], [262, 264], [265, 272], [273, 276], [277, 284], [285, 290], [291, 298], [299, 301], [302, 306], [307, 309], [310, 317], [318, 326], [326, 327]]}
{"doc_key": "ai-dev-350", "ner": [[6, 7, "organisation"], [9, 10, "organisation"], [12, 12, "organisation"]], "ner_mapping_to_source": [0, 1, 2], "relations": [], "relations_mapping_to_source": [], "sentence": ["Other", "active", "youth", "climate", "groups", "include", "Extinction", "Rebellion", ",", "Sunrise", "Movement", ",", "SustainUS", ",", "among", "others", ",", "working", "both", "transnationally", "and", "locally", "."], "sentence-detokenized": "Other active youth climate groups include Extinction Rebellion, Sunrise Movement, SustainUS, among others, working both transnationally and locally.", "token2charspan": [[0, 5], [6, 12], [13, 18], [19, 26], [27, 33], [34, 41], [42, 52], [53, 62], [62, 63], [64, 71], [72, 80], [80, 81], [82, 91], [91, 92], [93, 98], [99, 105], [105, 106], [107, 114], [115, 119], [120, 135], [136, 139], [140, 147], [147, 148]]}
